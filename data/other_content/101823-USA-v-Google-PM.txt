6392
1

IN THE UNITED STATES DISTRICT COURT
FOR THE DISTRICT OF COLUMBIA

2
3
4

UNITED STATES OF AMERICA,
et al.,
Plaintiffs,

Civil Action
No. 1:20-cv-3010

5

vs.

6

GOOGLE, LLC,

Washington, DC
October 18, 2023
1:32 p.m.

7

Defendant.
_____________________________/

Day 24
Afternoon Session

8
9
10

TRANSCRIPT OF BENCH TRIAL
BEFORE THE HONORABLE AMIT P. MEHTA
UNITED STATES DISTRICT JUDGE

11
12
13
14

APPEARANCES:
For DOJ Plaintiffs:

U.S. Department of Justice
1100 L Street, NW
Washington, DC 20005

15

MEAGAN BELLSHAW

16

U.S. Department of Justice
450 Fifth Street, NW
Washington, DC 20001

17
18

DAVID DAHLQUIST

19

U.S Department of Justice
209 South LaSalle Street, Suite 600
Chicago, IL 60604

20
21
22
23
24
25

KENNETH DINTZER

For Plaintiffs
State of Colorado &
State of Nebraska:

WILLIAM CAVANAUGH, JR.

Patterson, Belknap, Webb & Tyler, LLP
1133 Avenue of the Americas #2200
Suite 2200
New York, NY 10036

6393
1

APPEARANCES CONT:

2

For Plaintiff
State of Colorado:

3

JONATHAN SALLET
STEVEN KAUFMANN

Colorado Department of Law
CPS/Antitrust Section
1300 Broadway, 7th Floor
Denver, CO 80203

4
5
6
7
8

For Defendant Google:

JOHN SCHMIDTLEIN
KENNETH SMURZYNSKI

Williams & Connolly, LLP
680 Maine Avenue, SW
Washington, DC 20024

9
10

WENDY HUANG WASZMER

11

Wilson, Sonsini, Goodrich & Rosati
1301 Avenue of the Americas, 40th Fl.
New York, NY 10019

12
13
14
15
16
17
18
19
20
21
22
23
24
25

Court Reporter:

JEFF HOOK

Official Court Reporter
U.S. District & Bankruptcy Courts
333 Constitution Avenue, NW
Washington, DC 20001

6394
I N D E X

1
2

WITNESS

3

P. PANDURANG NAYAK

PAGE

4

Cross-Examination by Mr. Dintzer

6395

5

Redirect Examination by Mr. Smurzynski

6468

6
7
8
E X H I B I T S

9

PAGE

10

EXHIBIT

11

Exhibit UPX680

.....Admitted into evidence.....

6435

12

Exhibit UPX2034

.....Admitted into evidence.....

6451

13

Exhibit UPX2026

.....Admitted into evidence.....

6455

14

Exhibit UPX2022

.....Admitted into evidence.....

6458

15

Exhibit UPX2027

.....Admitted into evidence.....

6462

16

Exhibit UPX2033

.....Admitted into evidence.....

6465

17
18
19
20
21
22
23
24
25

6395
1

P R O C E E D I N G S

2

THE COURT:

Welcome back, everybody.

3

We're ready to proceed, Mr. Dintzer?

4

MR. DINTZER:

Yes, Your Honor.

The defense helped us and

5

worked with us, and I think we're going to be able to do this

6

in open court.

7

THE COURT:

8

MR. DINTZER:

9

Good.
And they'll let me know if I wander outside

the line.

10

THE COURT:

11

MR. DINTZER:

12

THE COURT:

13

MR. DINTZER:

14

CROSS-EXAMINATION OF P. PANDURANG NAYAK

15
16
17

Okay.
May we approach?

Sure.
Thank you.

BY MR. DINTZER:
Q.

Good afternoon, sir.

My name is Kenneth Dintzer.

Nice to meet you.

18

A.

Nice to meet you.

19

Q.

I'm going to start off with a broad question.

How

20

much user data does Google maintain at this point?

21

in a search about Taylor Swift, how long will any system at all

22

in Google have that recorded?

23

A.

So if I put

I don't know if I can give a specific answer, but I

24

think to the extent that it is anonymized and de-identified, I

25

think they may well keep it -- I don't know that they would

6396
1

delete it.

2

Q.

Oh, forever?

3

A.

Well --

4

Q.

Forever's a long time.

5

A.

Forever's a long time, so I would not say that.

6

Q.

Indefinitely?

7

A.

But, yeah, I'm not aware -- I'm not the expert on how

8

long they store logs.

9

but I'm not aware of that.

10
11

Q.

Okay.

So it's possible that they delete it,

And so -- and just to be clear, sir, you've

never worked at Microsoft; is that right?

12

A.

I have not worked at Microsoft.

13

Q.

And if I asked you detailed questions about how their

14

search stack worked and the modules for it, you wouldn't know;

15

is that right?

16

A.

17
18
19

I wouldn't -- I might hazard a guess, but that would

be what it would be.
Q.

And it's true for both Google's and Bing's search

systems, they're proprietary; is that right?

20

A.

I think most of it is proprietary, yeah.

21

Q.

And so somebody who hasn't actually had realtime

22

experience working on one of those systems wouldn't know how

23

they work or how to work them; is that fair?

24
25

A.

Again, they might understand the overall principles,

because those are sort of maybe well understood, but the

6397
1
2
3

details, probably not.
Q.

And do you agree with the statement that Microsoft

used more machine learning than Google in 2014 and 2015?

4

A.

5

learning, yes.

6

Q.

7

We had heard that Microsoft uses a lot of machine

And had you heard that Microsoft was using more

machine learning than Google in 2015, '16, '17?

8

A.

No, that I had not heard.

9

Q.

You talked about Google's index size.

10

In 2020, the

index was about 400 billion documents; is that right?

11

A.

I don't know the specific number, but maybe.

12

Q.

Okay.

13
14
15
16
17

And -- but I think you testified that that

number had come down; is that right?
A.

There was a period of time when that number did come

down.
Q.

And the decrease in size was concerning to the

engineers like you at Google?

18

A.

Because we want to build a comprehensive index, yes.

19

Q.

And all else equal, bigger is better for an index?

20

A.

Other than the fact that all else is rarely equal --

21

Q.

Fair enough.

22

A.

But we do want to create a comprehensive index, yes.

23
24
25

I think that's fair to say.
Q.

And a bigger index -- wherever you're starting from, a

bigger index requires more investment, right?

6398
1
2

A.

It requires not just more investment, but bigger is

not necessarily better, because you might fill it with junk.

3

Q.

Well, fair enough.

4

A.

So you need a fair amount of investment to figure out

5

what you're going to fill that with.

And you can keep the size

6

of the index the same if you decrease the amount of junk in it.

7

Q.

Fair enough.

8

A.

Which will still improve the quality of the index.

9

Q.

Fair enough.

My question, though, is if you want to

10

increase the amount of information that the index holds, you

11

would have to spend more money, right?

12

A.

I mean, certainly that could be one way to do it.

13

But, again, I think figuring out how to get more information in

14

would be another way, right, by removing stuff that is not good

15

information.

16

Q.

17

Has Google increased the overall carrying capacity of

its index in the past three years?

18

A.

The past three years?

19

Q.

Yeah.

So just -- I understand what you're saying

20

about quality, and that's not my question.

21

time, over the past three years, do you know if its capacity is

22

now X plus?

23

A.

24
25

If it held X at one

So I don't know in the past three years if there's

been a specific change in the size of the index.
Q.

Now, on receiving a query -- and you talked about some

6399
1

of this, Google uses the index to retrieve pages matching the

2

query, right?

3

A.

Yes.

4

Q.

And typically there are many results matching the

5

query?

6

A.

Yes.

7

Q.

And a simple match could yield as many as 10,000,000

8

results, right?

9

A.

Yes.

10

Q.

Okay.

And I'm going to go to the demonstrative that

11

you all prepared, which I think is really helpful.

12

DXD17.002 -- and if I could convey upon you to pull it up.

13

Let's go to

So we were talking about how Google goes from one circle

14

to the other, as part of your direct.

15

called core algorithms to bring that down to a set of about 200

16

documents, right?

17

A.

Several hundred, yes.

18

Q.

Several hundred.

19
20
21

Google uses what you've

And I'm just going to write "core

algorithm," because I'm probably going to use that.
And those algorithms give the documents initial rankings
or scores, right?

22

A.

Yes.

23

Q.

And once Google has the smaller set of documents, then

24
25

the deep learning can be used to adjust the score?
A.

Yes.

6400
1

Q.

The core ranking algorithms are critical, because if

2

they don't bring up the right documents, then, for the most

3

part, the deep learning systems can't do their role in figuring

4

out which are the best ones?

5

A.

Some of the deep learning systems are also involved in

6

the retrieval process, like we discussed, like the RankEmbed

7

system.

8

Q.

Yes, but --

9

A.

But unless we retrieve the right documents, you can't

10
11
12

score them, yes.
Q.

But most of the retrieval process happens under the

core system, right?

13

A.

Other than, as I said, the RankEmbed thing also does

14

retrieval.

15

THE COURT:

I'm sorry, you said RankEmbed?

16

THE WITNESS:

Yes.

RankEmbed bought one of those deep

17

learning systems that also does retrieval.

18

BY MR. DINTZER:

19
20

Q.

And we're going to come back to that.

But the ranking

system -- the core gives them scoring, right?

21

A.

Yes.

22

Q.

And the core algorithms are critical, because if they

23

don't bring up the right documents, then even RankEmbed doesn't

24

go back and redo the work that the core system is supposed to

25

do, right?

6401
1

A.

I mean, it could, but -- so right now it doesn't, yes.

2

Q.

And at the end, each page that matches a query, it

3

gets a score?

4

A.

Yes.

5

Q.

And then Google sorts the scores, and that's what's

6

used in part for Google to present to the users?

7

A.

Yes.

8

Q.

Now, Google puts a bunch of different things on its

9

SERP, right?

10

A.

Yes.

11

Q.

And if I use this term SERP, we'll both understand

12

it's a search engine results page?

13

A.

Yes.

14

Q.

Web results are only one of the things that come --

15

that get shown on the SERP?

16

A.

That is correct.

17

Q.

And web results are scored with something called an IR

18

score, right?

19

A.

That's right.

20

Q.

And IR stands for information retrieval?

21

A.

Yes.

22

Q.

And you talked about search features earlier, and

23

search features are basically some of the other things that

24

appear on the SERP that are not the web results?

25

A.

That is correct.

6402
1
2

Q.

And those features get a different score, they don't

get an IR score, right?

3

A.

They do get a score, but yes.

4

Q.

So let's go to DXD1705, and this is one of the

5

demonstratives.

Just let me know when you're there, sir.

6

A.

Oh, this one here?

7

Q.

Yes, sir.

8

A.

Okay.

9

Q.

And so just to level set here, what you've included --

And you're welcome to use the screen.

10

and I understand this was talking about the machine learning,

11

right?

12

A.

Yes, yes.

13

Q.

So you left off the core systems on this?

14

A.

Yes.

15

Q.

And so one of the core systems is navboost, right?

16

A.

Yes.

17

Q.

And navboost dates to a long time ago, right?

18

mean --

19

A.

Yes.

20

Q.

-- it's all the way off the screen?

21

A.

Yes.

22

Q.

So remind me, is navboost all the way back to 2005?

23

A.

It's somewhere in that range.

24
25

I

It might even be before

that.
Q.

And it's been updated.

It's not the same old navboost

6403
1

that it was back then?

2

A.

No.

3

Q.

And another one is glue, right?

4

A.

Glue is just another name for navboost that includes

5
6

all of the other features on the page.
Q.

Right.

I was going to get there later, but we can do

7

that now.

8

right?

9

A.

Yes.

10

Q.

And glue does everything else that's on the page

11

Navboost does web results, just like we discussed,

that's not web results, right?

12

A.

That is correct.

13

Q.

Together they help find the stuff and rank the stuff

14

that ultimately shows up on our SERP?

15

A.

That is true.

16

Q.

Now let's go to DXD17-4.

17
18
19
20
21

They're both signals into that, yes.
So navboost helps us get

from the green ring to the blue ring, right?
A.

No, navboost doesn't help you -- I mean, it's

certainly a factor, but it's not the only factor by any means.
Q.

Fair enough.

Navboost and glue are factors that help

us get from the green ring to the blue ring?

22

A.

Not glue, just navboost.

23

Q.

Oh, because this is just web results?

24

A.

Yes.

25

Q.

And glue works on all those other things?

6404
1

A.

Which is much later in the stack.

2

Q.

Okay.

And this sort of helps -- the Court asked the

3

question -- and I'm going to try to help us through the Court's

4

question, which is:

How do these pieces fit together?

5

So what happens is navboost is reaching in, and after the

6

set has been culled to the green ring, navboost reaches in and

7

helps pull us -- a lot of the documents, not all of them, into

8

the blue ring; is that right?

9

A.

It helps.

It's certainly a factor, yes.

10

Q.

And then in machine learning -- we're going to get to

11

these -- they then take a look at that set, and they may say,

12

well, we need a few more to add to it.

13

that they do is once you've got the navboost set, they then try

14

to figure out which are the better ones and sort through them?
A.

15

But one of the things

I wouldn't characterize it as the navboost set, but

16

once we get it down to the smaller set, that's what they work

17

on.

18

factor.

19

Q.

And navboost is a factor there, but by no means the only

Now, the core ranking algorithms, those are -- I think

20

you also, in your deposition, called them traditional systems,

21

right?

22

A.

23
24
25

I don't remember that phrase, but maybe that's a

reasonable characterization.
Q.

They need to operate with many more documents than the

machine learning documents, right?

6405
1

A.

Yes, that's correct.

2

Q.

And that's -- I think it's important for the Court to

3

understand.

4

of documents and figuring out things about it.

5

learning is kind of -- is more looking at a much smaller set,

6

right?

7

A.

8

also, yes.

9

These -- not glue.

Navboost is looking at a lot
Machine

And it's not just navboost, it's all the other factors

THE COURT:

Just to be clear, you're talking about in

10

the -- what you've called the search stack, none of those are

11

the sequencing?

12

THE WITNESS:

Yes.

So it's the thing that culls from a

13

lot of documents to fewer documents, yes.

14

BY MR. DINTZER:

15
16

Q.

Now, the navboost system memorizes past clicks that

have been issued for past queries, right?

17

A.

Yes.

18

Q.

It's trained on user data?

19

A.

Yes, it is.

20

Q.

And navboost memorizes this information for all

21

queries received in the past 13 months?

22

A.

That is correct.

23

Q.

And before 2017, navboost memorized this information

24
25

for all queries received for 18 months?
A.

Yes.

6406
1
2

Q.

Now, you talked about reducing the amount of data used

by navboost, I think that you looked at a document.

3

A.

Yes, we did.

4

Q.

And I'm going to ask if we can go back to that

5
6

document, and that's DX108, please.
THE COURT:

Can I interrupt for a moment, I'm sorry, just

7

to make sure I understand this conceptually.

8

already explained this, but what's the relationship between the

9

index and the culling function that navboost is a signal for?

10

THE WITNESS:

I think you've

So when you have a query, you need to go and

11

retrieve documents from the index that match the query.

The

12

core of that is the index itself.

13

every word, what are the pages on which that word occurs.

14

so -- this is called an inverted index for various reasons.

15

And so the core of the retrieval mechanism is looking at the

16

words in the query, walking down the list -- it's called the

17

postings list -- and intersecting the postings list.

18

the core retrieval mechanism.

19

lists all the way to the end because it will be too long, you

20

sort the index in such a way that the likely good pages, which

21

are high quality -- so sometimes these are sorted by page rank,

22

for example, that's been done in the past, are sort of earlier

23

in the thing.

Remember, the index is for
And

This is

And because you can't walk the

24

And once you've retrieved enough documents to get it down

25

to tens of thousands, you hope that you have enough documents.

6407
1

So this is the core of the retrieval mechanism, is using the

2

index to walk down these postings lists and intersect them so

3

that all the words in the query are retrieved.

4
5
6

THE COURT:

And the ranking is done only after you have

culled it to the tens of thousands?
THE WITNESS:

Exactly.

So that's -- the next phase is to

7

say, okay, now I've got tens of thousands.

8

use a bunch of signals to rank them so that I get a smaller set

9

of several hundred.

10

phase of ranking which, among other things, uses the machine

11

learning.

12

THE COURT:

13

BY MR. DINTZER:

14
15

Q.

Now I'm going to

And then I can send it on for the next

Okay, thank you.

Let's see if I can get this right.

So index, it gets

culled to tens of thousands?

16

A.

Yes.

17

Q.

Navboost gets us to 2- to 300?

18

imprecise.

19

A.

I understand it's

I wouldn't quite say navboost gets us to 2- to 300,

20

because there might be lots of documents that don't have

21

clicks.

22

only factor.

23

Q.

24
25

So I think it is fair to say that navboost is not the

Okay.

And are there other core systems here that are

taking us from 10K to 300?
A.

Yes.

All of our core topicality signals, our page

6408
1

rank signals, our localization signals.

2

signals in there that look at these tens of thousands of

3

documents and together create a score that then you extract the

4

top few hundred from there.

5
6

Q.

There's all kinds of

And then deep learning gives it a chance to work with

that?

7

A.

Yeah.

8

Q.

And then we talked about glue.

Glue gets a chance to

9

add search features that aren't -- this is all just web, gets a

10

chance to add search features that aren't retrieved through the

11

web, right?

12

A.

So, once again, even for the search features that are

13

added up, glue is one signal.

It's not, again, the only

14

signal.

15

this.

16

other inputs, other signals also.

So I would not characterize it as glue gets to do

It's the Tangram system that does that, which takes

17

Q.

Right.

18

A.

Tangram used to be called Tetris, yes.

19

Q.

And it was called Tetris because it was putting the

20

pieces together on the search engine results page?

21

A.

Maybe.

22

Q.

Okay.

23

Tangram used to be called Tetris, right?

But glue is giving one of the signals to figure

out what are the best search features for the Tetris --

24

A.

It's one of the signals, yes.

25

Q.

And then that finally takes us to the SERP?

6409
1

A.

Yeah.

2

Q.

Now let's go to DX108.

3

that Google gave you.

4

A.

I am there.

5

Q.

Okay.

6

That will be in the binder

Let me know when you're there, sir.

And so this reduction that you talked about,

this took place in 2017, right?

7

A.

Yes.

8

Q.

And Google ran several experiments before reducing the

9
10

data used in its navboost model, right?
A.

I have not looked at this carefully to know if they

11

did, but I'd be surprised if they did not run several

12

experiments.

13

Q.

14
15
16
17

So you weren't involved in the 2017 ablation studies

that led to the reduction?
A.

I was involved in the decision to launch it, but I did

not actively work on it.
Q.

But you wouldn't have signed off on reducing the

18

amount of data that navboost used without a fair amount of

19

experimentation to sign off on it, right?

20

A.

Without adequate experimentation, yes.

21

Q.

And we can look at the document.

The three types of

22

experiments were -- involved random traffic evaluation

23

experiments, right?

24

A.

Yes.

25

Q.

We can go to page 129.

6410
1

A.

Yeah.

2

Q.

And if you look under the heading Overview.

3

A.

Yeah.

4

Q.

Oh, I'm sorry, at the top, "experiment types," do you

5

see that?

We have the random traffic experiment?

6

A.

Yeah.

7

Q.

That was -- and then the second one was an impact to

8

traffic.

9

A.

Yes.

10

Q.

And that was a side-by-side experiment?

11

A.

Yes.

12

Q.

And a side-by-side experiment is where Google takes

Do you see that?

13

sort of -- it's A/B, whatever the standard is and whatever it

14

wants to test against it, and it puts them together in front of

15

the evaluator, right?

16

A.

Yes.

17

Q.

And then the evaluator picks which of the two are

18

better on a side-by-side test, and it uses that information to

19

make sure that this is what it wants to do, right?

20

A.

Yes.

21

Q.

And in deciding to go from 18 months to 13 months,

22

that was a big choice, a big decision, right?

23

A.

It was a decision.

24

Q.

An important one, right?

25

A.

I mean, there are many important decisions we take, so

6411
1
2

I wouldn't go there.
Q.

But yes.

Well, I appreciate that you make many important

3

decisions, sir.

4

actual data that you're training navboost on, that was an

5

important decision for Google, right?

6

A.

7

don't think.

8

Q.

But the decision to reduce the amount of

In the scheme of things, it wasn't so important, I

Okay.

And so then the next thing that your team

9

did -- or the people who worked for you did is they did a live

10

experiment, right?

11

A.

Okay, yes.

12

Q.

A live experiment is when some users are shown X and

13

some users are shown Y, and you figure out if the users that

14

are shown one or the other are getting the better or the same

15

experience, right?

16

A.

Actually, these are so-called mode server experiments,

17

where results from the two sides are interleaved in this way,

18

and so users only see one ordering, which is the interleaved

19

ordering.

20

Q.

I see.

And then you figure out which ones they click

21

on so you can use that to determine which are the better

22

results?

23

A.

24
25

Yeah, and so there's a particular technique to decide

which side is better.
Q.

That would be an example of using click data to run an

6412
1

experiment?

2

A.

Yes.

3

Q.

Now, users are served results in part based on their

4

locale, right?

5

A.

Yes.

6

Q.

The meaning of a word in a query can change depending

7

on where you are?

8

A.

Yes.

9

Q.

And if you're a football fan in the United States, you

10

like to root for people to move something that's oblong and

11

brown, and if you're a football fan in the UK, then you're

12

rooting for somebody to kick something that's round, right?

13

A.

Absolutely.

14

Q.

And if you're searching for pizza, the word "pizza,"

15

you want a pizza restaurant -- I think you mentioned this in

16

your direct -- around the corner from you, not necessarily the

17

best pizza place in the world?

18

A.

That's right.

19

Q.

And navboost, navboost slices -- I think you used the

20

word "slice" in your deposition.

21

information; is that right?

Navboost slices the locale

22

A.

The navboost does slice locale information, yes.

23

Q.

And it slices the data information that it has in it

24

by locale?

25

A.

Yes.

6413
1
2

Q.

Navboost also slices the data information by mobile

versus desktop?

3

A.

Yes, it does.

4

Q.

And slicing here means that navboost is creating

5

different datasets for each of these categories?

6

A.

That is correct.

7

Q.

And there are differences in user intent on mobile and

8

desktop.

9

A.

Yes.

10

Q.

You used the Bank of America example?

11

A.

Yes, I did.

12

Q.

To some extent, that's navboost, right, picking the --

I think you talked about this in your direct?

13

oh, we're looking for local branches, we're not looking for

14

online banking?

15

A.

Navboost certainly provides that signal, yes.

16

Q.

Now, you're familiar with the Search Quality

17

Newsletter; is that right?

18

A.

Yes, I am.

19

Q.

And what is it?

20

A.

It's a newsletter I publish weekly.

21

Q.

The newsletters are usually an in-depth article going

22

to the technical details of some particular subject; is that

23

right?

24

A.

Yes, that is correct.

25

Q.

And you view them as an educational tool?

6414
1

A.

Yes.

2

Q.

So we're going to go in the binder that I handed you.

3

In the binder that I handed you, we're going to go to 1087.

4

MR. DINTZER:

This is admitted, Your Honor.

5

Q.

And just let me know when you have it there, sir.

6

A.

Yes, I'm there.

7

Q.

Thank you.

And so this is an example of the

8

newsletter from third quarter -- from August 11th to

9

August 15th, 2014; is that right?

10

A.

That is correct.

11

Q.

We're going to go to the page with the Bates number --

12

it's three pages in, with the Bates number 1720 at the bottom.

13

A.

Yeah.

14

Q.

Okay.

15

And at the top it says -- and you would have

seen this newsletter, right?

16

A.

I would have seen it, yes.

17

Q.

And it says:

"Given this, a question which we need to

18

answer is whether mobile search is different from desktop

19

search.

20

question, we conducted some analyses, focusing on user intents

21

and behaviors."

If so, how are they different?

To answer to this

22

Do you see that?

23

A.

Yes.

24

Q.

And that's what this article discusses, the analysis

25

between mobile and desktop?

6415
1

A.

Yes.

2

Q.

And then we go to the next page, X1721, and there's a

3

heading that says:

"Top intents of mobile dominant queries."

4

Do you see that?

5

A.

Yes.

6

Q.

And what does "top intents" mean there, sir, just that

7
8

term?
A.

I think they're looking at -- for queries that are

9

mobile-dominant, what kind of intents do users have.

10

mobile queries at large, but queries that are mobile-dominant

11

that is usually -- that the occurrence on mobile is

12

meaningfully higher than on desktop.

13

Q.

Okay.

Not for

And so the -- so we combined some things here.

14

I just want to break them down.

15

more on mobile or is it the fact that their being on mobile

16

means something different than if they had been issued by a

17

desktop?

18

A.

19
20
21
22
23
24
25

No, the mobile-dominant part says they occur more

frequently on mobile.
Q.

Is it the fact that they occur

That's the table further up there.

And the top intent is that I have some sort of mobile

intent when I put it in?
A.

So then the question is for those mobile-dominant

queries, the question is what was the intent on those queries.
Q.

Okay.

And then to the next page, we have the heading

"Top intents of desktop-dominant queries."

6416
1

Do you see that?

2

A.

That is correct.

3

Q.

It says -- after the box it says:

"The top intent

4

includes queries for work."

5

Do you see that?

6

A.

Yes.

7

Q.

"More specifically, there are many queries" -- "many

8

queries related to professional or industrial office work, and

9

also queries for school homework."

10

Do you see that?

11

A.

Yes.

12

Q.

So for people searching on desktop, they are more

13

likely to be at work or at school, right?

14

A.

They could be at home, I guess.

15

Q.

But doing homework or schoolwork?

16

A.

I think people other than students are also at home

17

doing other kinds of research.

18

that the only desktop users are students.

19

Q.

Well, that's fair.

I would not generalize to say

But it does say that there are

20

many queries related to professional or industrial office

21

work --

22

A.

23
24
25

Certainly, there are many queries, but there are many

other queries also is what it says.
Q.

Fair enough.

No, you're right.

I didn't mean to

gather all the queries and just put them in as workers.

Now,

6417
1

for people searching -- I'm sorry, for each query, Google

2

tracks what kind of device it is made on.

3

the difference between desktop and mobile, right?

That's how it knows

4

A.

Yes.

5

Q.

And if we go to the bottom of this page, it says:

6

"Divergence in intent for common mobile desktop queries."

7

Do you see that?

8

A.

Yes.

9

Q.

And this is going to flop over to the next page:

10

"This group is probably the most interesting slice, because

11

mobile users sometimes have different intents, even for the

12

same queries."

13

And that's what you were talking about, right?

14

A.

That's right.

15

Q.

And I think doing the math you said it was 6 percent

16

on one and 6 percent on the other, right?

17

didn't -- that's not in the document, I didn't --

18

A.

Is that what -- I

Well, I was referring to this other chart here,

19

actually, that I got the number slightly off.

But you see the

20

desktop-dominant, mobile-dominant and the mixture queries,

21

which occur sort of with the same frequency, that was roughly

22

the 66 --

23

Q.

Okay, so --

24

A.

-- 86, this is what I was referring to.

25

Q.

And you got there before me so I couldn't tell you,

6418
1
2

we're not really supposed to say those numbers, but okay.
So those indicate -- I'm not going to repeat them, but

3

those numbers indicate which ones are desktop-dominant, which

4

ones are mobile-dominant, that are the same types of queries

5

but people have a desktop or mobile interest in those, right?

6

A.

No.

The way to think about this is these are queries

7

that occur both on desktop and mobile, because most queries

8

occur both on desktop and mobile.

9

the number of -- the relative amount of queries on -- the

10

distribution on mobile is higher for these queries, for the

11

mobile-dominant queries, than on desktop; that is, the fraction

12

of occurrence of these queries on desktop is lower.

13
14

Q.

But these are queries where

Oh, so that's all you were saying.

You were talking

about the percentage -- frequency of these queries?

15

A.

That's roughly what this is saying.

16

Q.

No, but earlier in your -- when you were testifying

17

when Google was asking you questions, when you talked about

18

this, you talked about a 6 percent and a 6 percent.

19

what you were talking about?

Is that

20

A.

That's what I was talking about.

21

Q.

I see, okay.

22

A.

I might have been confused a little.

23

Q.

No, I --

24

A.

This is what -- I was referring to this particular

25

table.

6419
1

Q.

Okay, I misunderstood.

I appreciate that, sir.

2

Now, it's important for Google or any general search

3

engine to get it right and to know which -- for those ones that

4

are overlapped, the ones where it's the same term but it means

5

it did something different on mobile and desktop, it's

6

important that a general search engine can get that right,

7

correct?

8

A.

I mean, it's, again, important on the borders.

If you

9

think about it, suppose you get it wrong, right.

10

you use -- let's say on mobile, let's go back to the Bank of

11

America case, right.

12

looking for the map, the locations of ATMs, and you use --

13

essentially use the desktop model.

14

Bank of America home page at the top, and then you'd have shown

15

the map.

16

loss.

17

looking for.

18

So suppose

And you didn't get it that users were

Then you'd have shown the

From an overall user perspective, it's not that big a

You scroll a little bit and you get the map that you're

So -- but on the borders, we would, of course, prefer to

19

show the map first because we want to optimize it.

20

point is if we don't optimize it, it's not that big a loss,

21

because users can still get to the information they're looking

22

for with a little scrolling.

23
24
25

Q.

My only

Do you know if that secondary information would be on

the main screen when they pulled it up on their phone?
A.

I don't know whether it would be on -- like, if it

6420
1

went the other way, if the map was much larger, if we took the

2

mobile model and brought it to -- well, the desktop, of course,

3

is bigger.

4

Sometimes it might be on the second screen or whatever.

5

will depend on the specifics of it.

6

scrolling will get them where they want.

7

like it to be as optimal as possible, so I don't want to

8

minimize that.

9

users won't be served with the slightly less optimal solution.

10

Q.

So it will depend on the specifics of the details.
That

But a little bit of
We, of course, would

But in the scheme of things, it's not as if

Now, beyond the difference between desktop and mobile,

11

people in different locales could have the different intent

12

with the same search term, right?

13

A.

So this was your football example, for example, yes.

14

Q.

Or even more specifically -- and I'm talking here now,

15

we're looking at the document.

We're at page X1723 at the

16

bottom.

17

"Desktop users meant Norton Publishing Company, whereas mobile

18

users wanted to find a pub named Norton"?

It says, in the first example, bracket Norton Pub:

19

A.

Yes.

20

Q.

And then farther down it says:

21
22

"For example, in

mobile navboost."
So Google has a specific navboost for mobile; is that

23

right?

24

A.

It's one of the slices, yes.

25

Q.

That's the mobile slice?

6421
1

A.

Yes.

2

Q.

And that's also true on user data, right?

3

A.

Yes, yes, it is navboost.

4

Q.

"For example, in mobile navboost, the top and third

5

clicked results for Norton Pub are about a pub in Rochester,

6

New York.

7

looks good, but people not in the Rochester, New York, area are

8

not likely to be satisfied with this.

9

would want other Norton Pubs in their regions, if any, or

10

prefer the Norton Publishing site, even, when searching on a

11

mobile phone."

For people in Rochester, the recommended result

People outside Rochester

12

Do you see that?

13

A.

I followed everything you said, but I wasn't sure --

14

Q.

Oh, I'm sorry, it was at the bottom of 1723 and the

15

top of 1724.

16

A.

Oh, I see it here.

17

Q.

And the whole point is beyond just different countries

Yes, yes, okay.

18

and different meanings of terms, actually localized data of

19

whether I'm in Rochester, New York or Southern California, what

20

I mean when I'm searching for Norton Pub may be completely

21

different?

22

A.

That is true.

23

Q.

Now, you talked about the importance of evaluation as

24
25

part of the search product development?
A.

If I can go back to your question for --

6422
1

Q.

Sure.

2

A.

-- just a moment.

3

Q.

Please.

4

A.

I think you're absolutely right that location matters,

5

and this was the point I was making:

6

Rochester, New York, right, we need some way to, in that case,

7

retrieve the Norton Pub document.

8

techniques to retrieve businesses close to your particular

9

location so that users can get served.

10

navboost only after they're retrieved in the first place.

11

Q.

12

documents?

13

A.

That when you're in

So we have a whole bunch of

Remember, you get

You're saying that's sort of the first culling of

It's in the first culling of documents, is you make

14

sure that you get these local documents coming in, and then you

15

present them to the user and they can interact with it and

16

create navboost and so forth.

17

Q.

Is one of the things that's helpful for Google when

18

local storekeepers go on their website and, like, update the

19

times that they're open and stuff like that, provide that kind

20

of information?

21
22

A.

I mean, that is a useful thing for a user, certainly.

I'm not sure what your question actually is referring to.

23

Q.

24

So I was turning to the evaluation.

25

Well, actually, I'll come back to that.
Evaluation is a

critical part of the search product development; is that right?

6423
1

A.

Yes, it is.

2

Q.

And you talked about the IS score on your direct exam?

3

A.

Yes, I did.

4

Q.

And that score is computed from rater rankings, right?

5

A.

Yes, it is.

6

Q.

So that's always a human metric?

7

A.

Yes, it is.

8

Q.

And I think we had a demonstrative that I wanted to

9

ask you about.

10

A.

Which folder is this in?

11

Q.

I'm sorry, this is in -- it's in the black binder, the

12

slides.

13

A.

This one?

14

Q.

Yes, sir.

15

A.

What was it, 17?

16

Q.

It should be the second page in there, sir, 17.003.

17

A.

Yeah.

18

Q.

The "regularly test search quality," do you see that?

19

A.

Yes.

20

Q.

And I think you said you had 16,000 human testers

21

If we could go to DXD17.003.

Thank you.

around the world; is that right?

22

A.

That is correct.

23

Q.

I'm just trying to understand some of these numbers.

24

The blue bar, let's say from 2020, human rater quality tests,

25

what qualifies as a human rater quality test?

6424
1

A.

So we have query sets created in various ways as

2

samples of our query stream where we have results that have

3

been rated by raters.

4

way of rapidly experimenting with any ranking change.

5

Q.

And we use this -- these query sets as a

I think we should capture that just so we understand.

6

So what you do is you have a query set, and it may be -- how

7

many are in a query set?

8

A.

It depends on the particular query set.

9

Q.

Are we talking dozens or hundreds, just so I can get

10

the --

11

A.

No, let's say 15,000.

12

Q.

Okay, 15,000.

And so you run this through the system,

13

and you get output that you then have human raters look at,

14

right?

15

A.

Yeah, so these are constantly running in general, so

16

raters have already given ratings for some of them.

17

run an experiment that brings up additional results, and then

18

you'd get those rated.

19

Q.

Okay.

You might

So you have basically a place where you have

20

put the past evaluations of these 15,000 queries, put them into

21

a box?

22

A.

Yeah.

23

Q.

And then if you've got an engineer here who is very

24

interested about this experiment or that experiment, they do

25

that experiment by looking at some of these experiments that

6425
1

you've already put in the box?
A.

2
3

No, we haven't put the experiments in the box.

I misunderstood what the box was.
Q.

4

I just want to make sure I understand what the 757,000

5

is.

6

people to look at output, right?

7
8

Maybe

This doesn't mean 757,000 times you've organized groups of

A.

No.

What -- so here's the thing:

Let's say we have a

query set of let's say 15,000 queries, all right.

9

Q.

Yes.

10

A.

We look at all the results for these 15,000 queries.

11

Q.

Okay.

12

A.

And we get them rated by our raters.

13

Q.

So human raters are looking at these?

14

A.

At all of them, and they provide ratings.

15

So you get

an IS score for the query set as a whole.

16

Q.

For the set?

17

A.

Yeah, you get an IS score for that.

Then along comes

18

an engineer, and they've got a clever idea for improving

19

ranking.

20

Q.

Right.

21

A.

So they implement their change.

And they come to this

22

query set, and they run this query set through that change and

23

get a different set of results -- or maybe the same set of

24

results in a different ordering.

25

Q.

I see.

6426
1

A.

They've got something going.

Now, of this, many of

2

the results that they produce we already have ratings from the

3

past, right.

4

have ratings on.

5

about this.

6

we'll get an IS score for the experimental set.

7

Q.

And there will be some results that they won't
So we'll send those to raters to say tell us

So now all the results have ratings again, and so

So this number, 616,386, these are not unique

8

experiments where the entire 15,000 set is ranked and scored

9

again?

10

A.

11

of overlap.

12

wouldn't be a very good situation to have, right.

13

changes change a few results.

14

of results, in which case you don't even have to get new

15

ratings, or sometimes they add new results and you get ratings

16

for those.

17

iterate rapidly on experimental changes.

They're ranked -- not by raters, because there's a lot
Changes don't change everything, right.

That

So most

Maybe they change the ordering

So it's a very powerful way of being able to

18

Q.

Okay.

So now --

19

A.

That's why there are so many of them.

20

Q.

And I didn't mean to interrupt.

21

So now let's talk about the human raters side-by-side.

I apologize, sir.

22

Those are ones where people actually get the two, the old and

23

the one being tested side-by-side, and human beings have to

24

actually score every single one of those --

25

A.

That is correct.

6427
1

Q.

-- to figure out?

2

A.

That is correct, which is why there are many fewer of

3
4
5

those, because that's a slower process.
Q.

But when you decide to do it, you decide -- Google

decides to invest money in having that --

6

A.

Yes --

7

Q.

-- process done?

8

A.

-- absolutely.

9

THE COURT:

Sorry to interrupt, but just help me

10

understand what the unit is here.

11

what?

12

THE WITNESS:

13

THE COURT:

14

THE WITNESS:

15

In other words, 616,386

Experiments.

Those are individual experiments?
Individual experiments.

Because they're

easy to run, people tend to run a lot of them.

16

THE COURT:

I see.

17

THE WITNESS:

These are just --

You just run it on your machine, you get a

18

new ranking.

19

additional human rater information.

20

back and forth between trying an idea and seeing whether it's

21

any good.

22

Usually, it doesn't require any or very little
So it allows a very rapid

That's why there are so many of them here.

THE COURT:

I see.

And would it be accurate to say that

23

something that falls in this column is less likely to need

24

approval, for example, to run those than something that is a

25

live experiment?

6428
1

THE WITNESS:

It is true that live experiments require

2

more approval of various sorts.

3

require very little or no approval.

4

experimentation as easy as possible, because we want people to

5

experiment.

THE COURT:

7

BY MR. DINTZER:

9

Q.

As a rule, we try to make

So there is that.

6

8

The ones in the blue column

Gotcha, okay.

Thank you.

So IS is Google's primary top level measure of

quality, right?

10

A.

Yes.

11

Q.

And sometimes IS-scored documents are fed -- used to

12

train the different modules, models in Google search stack,

13

right?

14

A.

Yes.

15

Q.

And sometimes -- and -- but IS rating has different

16

pros and cons compared to using click data to train those same

17

systems, right?

18

A.

Yes.

19

Q.

One advantage of click data has over IS data is clicks

20

give a measure of the actual user performance?

21

A.

That is correct.

22

Q.

So if I want to know how to hang a 500-pound picture

23

and I've had some experience doing that before, when I'm

24

looking at the search results, I bring that knowledge to it,

25

whereas the human rater is looking at something, and they may

6429
1

not know how to evaluate those search results?
A.

2

That is correct.

But what we ask the human raters to

3

do is to put themselves in the shoes of the typical user that

4

might be there, because the raters are a representation of the

5

users.

6

experience of hanging a 500-pound piece of art, and so they

7

might actually be interested in understanding the steps.

8

Certainly, an expert user who knows all about how to do this

9

may not find those results as compelling because they might be

10

looking for something more advanced.

11

because none of this talks about personalizing results to a

12

particular user.

13

representation of what users -- your general user is looking

14

for.

15
16
17
18

And most users maybe are unlikely to have had the

Q.

That is certainly true,

But raters are supposed to be a

But users have a better sense of what they intend when

they issue the query than a rater can possibly have?
A.

That is -- every user clearly comes with an intent,

which you can only hope to guess.

19

Q.

So IS data is more coarse than search results; is that

20

correct?

21

A.

Is more coarse than?

22

Q.

Yes.

23

A.

Than what?

24

Q.

Search results.

25

A.

IS data is actually rating of search results, so I'm

6430
1

not sure I --

2

Q.

Let me try --

3

A.

-- quite understood --

4

Q.

I'll come back to that one, that's fair.

5

That's a --

I need to come back to that.

6

Now, for the longest time, Google didn't use a lot of --

7

where are we -- oh, there we go, a lot of machine learning; is

8

that right?

9

A.

For a lot of time?

10

Q.

For a long time, up until -- up until what year did

11
12

Google start using machine learning?
A.

So it depends on what we mean by machine learning.

13

Certainly, for deep learning -- which is what we talked about

14

at length this morning, we started using deep learning in 2015.

15

But other forms of machine learning, things like decision trees

16

and other methods for machine learning, we had started using

17

earlier.

18

Q.

19
20

And you believe that the core systems and the machine

learning systems, that they're complementary, right?
A.

I mean, in some ways they can also refer to -- point

21

in the same direction.

22

They're additive, certainly.

23

Q.

24

ranking score?

25

A.

They're not necessarily complementary.

And they all contribute in different ways to the final

Yes, that is true.

6431
1
2

Q.

The main three deep learning models Google uses in

ranking are RankBrain; is that right?

3

A.

Yes.

4

Q.

DeepRank?

5

A.

Yes.

6

Q.

And RankEmbed BERT, right?

7

A.

Yes, yes.

8

Q.

These three deep learning models are trained in part

9

on click and query data; is that right?

10

A.

That is correct.

11

Q.

So let's start with RankBrain.

RankBrain looks at the

12

top 20 or 30 documents and may adjust their initial score; is

13

that right?

14

A.

That is correct.

15

Q.

And RankBrain is an expensive process to run?

16

A.

It's certainly more expensive than some of our other

17
18

ranking components.
Q.

So that's, in part, one of the reasons why you just

19

wait until you're down to the final 20 or 30 before you run

20

RankBrain?

21

A.

That is correct.

22

Q.

RankBrain is too expensive to run on hundreds or

23

thousands of results?

24

A.

That is correct.

25

Q.

RankBrain is trained on queries across all languages

6432
1

and locales Google operates in?

2

A.

I think so, yes.

3

Q.

And then it's fine-tuned on IS data?

4

A.

That is correct.

5

Q.

But it is not possible to train RankBrain on only

6

human rater data, right?

7

A.

No, you can't.

8

Q.

And each time RankBrain is retrained, it is with fresh

9

data, right?

10

A.

It's with -- yes, with new data, yeah.

11

Q.

And for years, RankBrain was trained on 13 months

12

worth of click and query data; is that right?

13

A.

I think initially it started with the same amount as

14

navboost, yes.

15

Q.

16

MR. SMURZYNSKI:

And now -Your Honor, if I could just -- a number

17

of these months, days and what, we've already deliberately put

18

in redacted boxes in the exam we did this morning.

19

caution.

20

MR. DINTZER:

21

looking at a document.

22

Q.

So I'd just

No, no, I appreciate -- it's easier when I'm
I will make an effort.

I understand.

Now, RankBrain needs to be trained at a regular

23

cadence, because otherwise it would be blind to new events,

24

right?

25

A.

That certainly is a factor, yes.

6433
1

Q.

2

right?

3

A.

Yes, I did.

4

Q.

And you also discussed BERT, right?

5

A.

Yes.

6

Q.

And an application of BERT, when BERT is used for

7

Now, you discussed DeepRank in your testimony; is that

ranking, is DeepRank, right?

8

A.

Yes.

9

Q.

And so, I mean, it's not BERT, but it is -- it's from

10

BERT.

When BERT is used for ranking, that's DeepRank?

11

A.

That's correct.

12

Q.

And DeepRank is trained on user data?

13

A.

Yes, it is.

14

Q.

Let's go to UPX860.

15

THE COURT:

Can I interject with a question.

When you

16

talk about a number of months of user data, can you tell me

17

what that means?

18

the data that Google has collected over 13 months or is it

19

something else?

20
21

Are we talking about quite literally all of

THE WITNESS:

It's the queries and the clicks that

occurred over that period of time.

22

THE COURT:

From all users?

23

THE WITNESS:

From all users.

You might train the model

24

on only some subset of the users, such as, say, U.S. users if

25

you're launching just a U.S. model.

But to the extent that

6434
1

you're launching a global model, it will look at all users,

2

yes.

3

THE COURT:

4

BY MR. DINTZER:

5

Q.

Understood, thank you.

The thing about -- I'm just going to jump off of that

6

question.

When you think about months of data -- so if we

7

think about sort of the unit of a month, Google -- a month of

8

data today is not the exact same measurement as a month of data

9

three years ago, right?

10

A.

It's not exactly the same, no.

11

Q.

Because as Google's usage has gone up, that same month

12

will have more clicks and queries in it, right?

13

A.

It will have somewhat more clicks and queries, yes.

14

Q.

So if we measured -- if we compared a month of Google

15

data and a month of Bing data -- I'm not going to ask you for

16

the multiple, I'm going to provide it as just a hypothetical.

17

Let's just say, hypothetically, Google had seven times as many

18

clicks and queries as Google in a given month.

19

data for Google is seven times bigger than the month of data

20

for Bing, because it's not an absolute measurement, it's just

21

how much was gathered in that month, right?

That month of

22

A.

If that number is correct, then yes.

23

Q.

I just wanted to get -- because we're talking about

24

months, but in reality we're talking about -- what's the

25

measure when you get to this volume?

Is it -- it's not

6435
1

terabytes, it's --

2

A.

I don't know what the number is.

3

Q.

Anyways, it's off the charts.

4

for each general search engine, right?

5

A.

That is true.

6

Q.

So we were on UPX860.

7

But it's not the same

You're familiar with this

document, sir; is that right?

8

A.

I don't know.

9

Q.

Apparently this was a presentation -- I can show you

10

the cover -- this was a presentation made in 2019?

11

A.

Okay.

12

Q.

Okay.

13

MR. DINTZER:

14

So let's go to...
We'll offer this, Your Honor.

My notes are

shy here, so it's unclear whether it's in, but we'll offer.

15

MR. SMURZYNSKI:

16

THE COURT:

17

I mean, I may have seen it, but --

We have no objection.

So UPX860 will be admitted, if it's not

already.

18

(Exhibit UPX860 admitted into evidence)

19

MR. DINTZER:

20

Q.

Thank you, Your Honor.

So this is a 2019 review, and we talked about

21

DeepRank.

22

eight.

And so let's go to 4417, at the bottom; it's slide

It says:

"Serving DeepRank at the top."

23

Do you see that?

24

A.

Yes.

25

Q.

And we've kept the numbers off, so we're not going to

6436
1

say the numbers.

It says -- the second bullet -- the first

2

bullet under the second black bullet, it says:

3

understands long-tail user need as it trains on" -- and I can't

4

say the number, but it's not an actual number, it's a greater

5

than number.

6

Do you see that?

7

A.

Yes, I do.

8

Q.

Of data, okay.

"RankBrain

So -- and when it says "trains on,"

9

that means that data is used to train the system; is that

10

right?

11

A.

Yes.

12

Q.

And then it says:

13

"DeepRank understands language and

has common-sense."

14

Do you see that?

15

A.

Yes.

16

Q.

And those are two different things.

The ranking part

17

and the understanding language part, those are two separate

18

things, right?

19

A.

20
21
22
23

The understanding language leads to ranking.

So

DeepRank does ranking also.
Q.

But they are related, but they're not -- this is

referring to them as separate items, correct?
A.

I mean, both RankBrain and DeepRank do ranking, so I'm

24

not sure that they're separate items.

25

about something else.

So maybe you're talking

6437
1

Q.

2

THE COURT:

3

So let's go to the next -- the black bullet.
I'm sorry, the number that's in the box that

you just testified about, that is a magnitude relative to what?
THE WITNESS:

4

So I don't actually recognize this number.

5

And certainly, in its current usage, it's more like 2X or some

6

small number of X.

7

but that's what it says here, so I'll take it.

8

BY MR. DINTZER:
Q.

9

So I don't recognize the number in here,

And at the top there -- of that bullet it says:

10

DeepRank replace RankBrain?

11

Do you see that?

12

A.

Yes.

13

Q.

And you agree with that?

14

A.

Yeah, I mean, I think that's not an unreasonable

"Does

No, complementary strengths."

15

position, though over time they are becoming less

16

complementary.

17

more complementary, but DeepRank is taking on more and more of

18

that capability now.
Q.

19
20

The next black bullet there says:

And the answer, I think you said the same thing today, is
no?

23

A.

Yeah.

24

Q.

And the reason explains is:

25

"Are we turning

ranking entirely over to deep learning?"

21
22

At the time that this was done, maybe they were

various protections to limit model."

"Still a black box,

6438
1

Do you see that?

2

A.

Yes.

3

Q.

And the deep learning was a black box back then, and

4

Google didn't want to trust it with all of its analysis,

5

correct?

6

A.

I think it's risky for Google -- or for anyone else,

7

for that matter, to turn over everything to a system like these

8

deep learning systems as an end-to-end top level function.

9

think it makes it very hard to control.

10
11

Q.

And then the next point is:

I

"Deep learning still

doesn't scale as well as traditional data mining."

12

Do you see that?

13

A.

Yes.

14

Q.

And traditional data mining, that's click query data,

15

right?

16

A.

I don't know exactly what is meant there.

I think of

17

data mining as looking at data and extracting insights that you

18

might use in certain ways.

19

build ranking systems was looking at data to carefully craft

20

ranking functions.

21

not sure exactly what is meant in this document here.

So the way we used to traditionally

I would call that data mining also.

22

Q.

But what you're describing is navboost, right?

23

A.

No, no, no.

So I'm

Navboost could be one thing, but even the

24

careful ranking functions that we created as a form of data

25

mining where we looked at data to figure out like how can we

6439
1

generalize what we are seeing, the data need not be a lot of

2

data.

3

extract insights that allow you to generalize.

4

is a very broad term in that sense.

5
6

It could be a small amount of data.

Q.

Okay.

You're trying to
So data mining

No further questions on that document, sir.

you could go to DX134.

7

A.

Is that in --

8

Q.

That's in the binder that the defendants gave you.

9

It's the zero to BERT document.

10

A.

Yeah.

11

Q.

And let's go to Page 5213.

12

you're there.

13

A.

14

MR. DINTZER:

And can I say this one?

counsel, because --

16

MR. SMURZYNSKI:

18

Just let me know when

Yeah.

15

17

If

I will check with

You can proceed on this one, yes.

BY MR. DINTZER:
Q.

Okay.

The second bullet here says -- under the

19

heading of "training," it says:

"We can potentially do even

20

better by pre-training on our own task-specific large corpus."

21

Do you see that?

22

A.

Yes.

23

Q.

"User feedback at the core of most search systems."

24

Do you see that?

25

A.

Yes, I see that.

6440
1

Q.

When it says user feedback, that's click data, right?

2

A.

That is correct.

3

Q.

And then if we can go to page 5231 of this document.

4

Just let me know when you're there.

5

A.

Yes.

6

Q.

And it says "BERT limitations."

7

So you talked about

BERT with the Court, right?

8

A.

Excuse me?

9

Q.

You talked about BERT with the Court?

10

A.

Yes, I did.

11

Q.

And this page has some of BERT's limitations.

I hate

12

to down-talk the old guy, but -- so the third bullet here says:

13

"Does not subsume big memorization systems, navboost, QBST, et

14

cetera."

15

Do you see that?

16

A.

Yes, I do.

17

Q.

And that's accurate, right?

18

A.

I mean, it does not subsume memorization, no.

19

Q.

And then we go to 5233.

20

there.

21

A.

Yes.

22

Q.

And it says -- at the second bullet it says -- the

23

heading is:

And let me know when you're

"Rapid progress is straining evaluation."

24

Do you see that?

25

A.

Yes.

6441
1

Q.

"Performance that rocks metrics may not impress

2

users."

3

years of experience on a query topic.

4

minutes to grasp the topic."

5

Do you see that?

6

A.

Yes, I do.

7

Q.

And that touches on one of the things we talked about,

And then under that it says:

"Users may have hours to
Raters have only a few

8

how humans working as actual users evaluate results in a

9

different way than human raters, right?

10

A.

They definitely do.

11

context, yes.

12

Q.

I mean, they have different

And so even a system that scores high on an IS, that

13

might not translate to actual quality for the actual users,

14

correct?

15

A.

It might not.

16

Q.

No further questions on that document.

17

A.

And yet I will say it seems to.

This is what the

18

growth experiments showed, that people actually like

19

improvements in IS and they use search more.

20

may not be satisfied by the IS improvement, absolutely.

21

aggregate, it appears that IS is well correlated with

22

helpfulness to users at large.

23
24
25

Q.

Specific users

And when you say in the aggregate, that means across

the entire corpus of Google users, correct?
A.

But in

Across the corpus of Google users, yes.

6442
1

Q.

Let's go to UPX2029.

2

A.

Is that in --

3

Q.

That is in the binder that we have given you.

4

let me know when you're there, sir.

5

A.

6

MR. DINTZER:

Your Honor, we'll offer this.

7

THE WITNESS:

Excuse me?

8

MR. DINTZER:

I'm sorry, just one second.

9

THE COURT:

10

MR. DINTZER:

11

THE COURT:

12

MR. SMURZYNSKI:

Yes, I am.

That was directed to me.
That's not a question for you, sir.

Any objection, counsel?
It's just going to take me a second,

13

because we got this last night at 10:00 o'clock.

14

it's --

15
16

Just

MR. DINTZER:

But I think

We can go ahead, Your Honor, and we can jump

back to them afterwards, if that's okay with the Court.

17

MR. SMURZYNSKI:

18

THE COURT:

19

BY MR. DINTZER:

We have no objection.

Okay, terrific.

Thank you, counsel.

20

Q.

So what is this document, sir?

Do you recognize it?

21

A.

It looks like a ranking newsletter.

22

Q.

And is this something you would see in the normal

23

course?

24

A.

Yes, I would.

25

Q.

And let's go to the second page of it, 8074.

6443
1

A.

Yes.

2

Q.

And the heading is:

3

Do you see that?

4

A.

Yes, I do.

5

Q.

And it says:

Why DeepRank?

"We started using deep learning and web

6

ranking several years ago, first in the form of RankBrain and

7

then RankEmbed.

8

of systems."

DeepRank is the latest edition to this family

9

Do you see that?

10

A.

Yes, I do.

11

Q.

And these are machine learning systems, the ones we've

12

talked about, right?

13

A.

Yes.

14

Q.

And then it says -- a little bit farther down in the

15

middle of the next paragraph -- actually, let's stay there.

16

The next sentence says:

17

relevance gains, but also ties ranking more tightly to the

18

broader field of language understanding."

"DeepRank not only gives significant

19

Do you see that?

20

A.

Yes, I do.

21

Q.

Go down to the middle paragraph in the next -- the

22

middle of the paragraph.

23

require some amount of language understanding paired with as

24

much world knowledge as possible."

25

Do you see that?

It says:

"Effective ranking seems to

6444
1

A.

I'm not sure I see it.

2

Q.

No, of course, and it's right in the middle of that --

3

I believe what you said --

the second paragraph under "Why DeepRank?"

4

A.

Oh, yes, I see it.

5

Q.

So to rank organic links, the system needs both

6

Yes.

language understanding and world knowledge?

7

A.

Yes.

8

Q.

And DeepRank does the language understanding, right?

9

A.

Well, I mean, it's -- that's probably an

10

oversimplification.

I suspect it also has world knowledge

11

built into it.

12

Q.

You don't know?

13

A.

I mean, this is what the network learned.

14

part of --

15

Q.

The black box?

16

A.

Exactly.

This is

So it's learned something about language

17

understanding, and I'm confident it learned something about

18

world knowledge, but I would be hard-pressed to give you a

19

crisp statement on these.

20

things.

21

Q.

22

These are sort of inferred kind of

Let's go farther down.

The paragraph that begins "in

general," do you see that?

23

A.

Yes.

24

Q.

"In general, effective language understanding seems to

25

require deep computation and a modest amount of data."

6445
1

Do you agree with that sentence?

2

A.

Yeah, for some definition of modest, I suppose.

3

Q.

The next part is:

4

"In contrast, world knowledge is

all about data; the more the better."

5

Do you see that?

6

A.

I see that, yes.

7

Q.

World knowledge part of ranking requires data, right?

8

A.

Yes.

9

Q.

No further questions on that document, sir.

10

THE COURT:

11

I'm sorry, in this context, what does "world

knowledge" mean in this context?
THE WITNESS:

12

That's a very good question.

One of the

13

interesting things is you get a lot of world knowledge from the

14

web.

15

trained on the web -- you've seen ChatGPT, Bard and so forth,

16

they have a lot of world knowledge because they're trained on

17

the web.

18

specific facts about it.

And today, with these large language models that are

So you need that data.

They know all kinds of

But you need something like this.

In search, you can get the world knowledge because you

19
20

have an index and you retrieve documents, and those documents

21

that you retrieve gives you world knowledge as to what's going

22

on.

23

and so that's -- you need some way to get at that.

24

BY MR. DINTZER:

25

But world knowledge is deep and complicated and complex,

Q.

We'll come back to this, but Bard is not part of

6446
1

Google's search systems, right?

2

A.

Bard is not part of Google's search systems, no.

3

Q.

And am I right that for launches, Google combines

4

different sources of data to make an informed decision about

5

whether to go forward?

6

A.

Yes, that's correct.

7

Q.

And these data come from human evaluations, live

8

traffic -- and live traffic studies; is that right?
A.

9

That, and together with things like capacity and cost

10

and those types of things.

11

too.

And complexity, we look at that,

12

Q.

And I think -- did you say cost?

13

A.

The expense of running these things in terms of

14
15
16
17

latency and those types of factors.
Q.

But also just the cost of paying for whatever the

system is that -A.

We think of it as capacity.

We don't think in terms

18

of cost per se.

We have a certain capacity.

19

latency budget.

We want to keep it within all of those things.

20
21

Q.

Okay.

We have a certain

So your capacity budget is dollar constrained,

though, correct?

22

A.

I'm sure there is some constraint of that sort.

23

Q.

So still on UPX2029, I just have one more set of

24
25

questions, sir.
A.

Yeah.

We're at page 8075.

6447
1

Q.

2

Do you see that?

3

A.

Yes.

4

Q.

And in the middle of that paragraph it says:

5

It has a bullet:

DeepRank.

"Training is also more computationally expensive."

6

Do you see that?

7

A.

Yes.

8

Q.

What does that mean, computationally expensive?

9

A.

So training -- so DeepRank is this bold model which

10

uses these transformers which looks at the sequences of things.

11

And it needs to look at -- it turns out training transformer

12

models is more expensive than training straightforward

13

feedforward networks like Google Brain or RankBrain.

14

cheaper to train.

15

that sense, more computation is required.

16

it's solving a harder problem.

17

Q.

Those are

And so you need -- it's more expensive in
Because, in a sense,

And then the next paragraph begins:

"Consequently,

18

DeepRank seems to have the capacity to learn the understanding

19

of language and common-sense that raters rely on to guesstimate

20

relevance, but not nearly enough capacity to learn the vast

21

amount of world knowledge needed to completely encode user

22

preferences."

23

Do you see that?

24

A.

I see that, yes.

25

Q.

And because of the cost of training DeepRank, it

6448
1

doesn't have the deep world knowledge element that we've been

2

talking about; is that right?

3

A.

That's what this is implying.

Whether it could or not

4

is a separate question.

Whether, in fact, if you just trained

5

on logs you could do this.

6

transformer-based models today are being trained for ChatGPT,

7

for Bard, for SGE and so forth, on web data to give them the

8

world knowledge.

9

whether it's possible or not here.

But after all, the same kinds of

So I don't think this is a claim about

10

Q.

Right, it's just talking about the expense?

11

A.

To the extent that we could use it, yes.

12

Q.

Another deep learning system Google uses in search is

13

called the RankEmbed BERT.

14

doesn't roll off the tongue.

15

A.

We've got that one there.

That one

Well, it's RankEmbed that was augmented to use the

16

BERT algorithm, the BERT structure, that's what it is.

17

RankEmbed was launched earlier without BERT.

18

augmented it with BERT so it was even better at understanding

19

the language.

20

Q.

RankEmbed BERT

And I'm not going to say the percentage, because I

21

think that those are off limits, but RankEmbed BERT is trained

22

on click and query data, right?

23

A.

Yes, it is.

24

Q.

And then it's fine-tuned on human IS rater data?

25

A.

Yes, it is.

6449
1
2

Q.

And it needs to be retrained so that the training data

reflects the fresh events?

3

A.

Yes.

4

Q.

Getting back to, you know, we talked about this idea

5

that a month of Google data is different than a month of Bing

6

data.

7

had to use more months to train its machine language so that it

8

kept the amount of data that it was getting constant, that

9

would be less fresh, right, because you would have to have more

10

months of data to train them on?

11

If Google had a smaller amount of data per month, and it

A.

I mean, that's not immediately clear, because as long

12

as you have the data from the freshest month, you get a taste

13

for that fresh data.

14

empirical question.

Whether that's enough or not is an

15

Q.

You don't know the answer to that question?

16

A.

I don't know the answer to that question.

17

Q.

But the quality of RankEmbed BERT can slowly start to

18

go down if you're not retraining it with fresh data; is that

19

right?

20

A.

Just going back to that previous question, it's worth

21

noting that when we trained RankEmbed BERT, we'd take a small

22

fraction of the traffic.

23

don't need all of those -- whatever the days of data that

24

was -- that DeepRank used, it took some small fraction of that

25

traffic.

So that's an example of where you

So having some exposure to the fresh data is actually

6450
1

quite valuable, which is why I'm saying it's an empirical

2

question as to whether it is enough or not.

3

Q.

Okay.

4

A.

And not one that I can blanket make a statement about.

5

Q.

All things being equal, though, more -- data that is

6
7

fresher is more valuable than data that is older?
A.

Not always the case, as we've discussed in the case of

8

the turkey recipe.

9

all things in that sense are rarely equal.

10

Q.

Okay.

The fresh data may not be the best data, so

User data, click and query data, fresher user

11

click and query data is typically more valuable than older

12

click and query data, correct?

13

A.

Again, it depends on the query, and it depends on this

14

thing -- there are situations where the older data is actually

15

more valuable.

16

questions to say, well, what exactly is happening.

17

clearly situations where fresh data is better, but there are

18

also cases where the older data is more valuable.

So I think these are all sort of empirical
There are

19

Q.

Does Google have a way of measuring how valuable the

20

older data is?

21

A.

We have not explicitly measured that.

22

Q.

Traditional systems work by looking up documents in

23

the index, like you would use an index in the back of a book;

24

is that right?

25

A.

That is correct.

6451
1
2

Q.

The core ranking algorithms retrieve most of the

documents that will be scored?

3

A.

Yes.

4

Q.

RankEmbed identifies a few more documents to add those

5

identified by the traditional retrieval?

6

A.

That is correct, for some definition of few.

7

Q.

You talked about MUM; is that right?

8

A.

That is correct.

9

Q.

If we could go to UPX2034.

10

This is something you

wrote in 2021; is that right?

11

A.

Just a moment.

12

Q.

Oh, please, take your time.

13

A.

Ah, yes.

14

Q.

So this is a blog post you wrote; is that right?

15

A.

Yes.

16

Q.

And this is about MUM, right?

17

A.

Yes, it is.

18

Q.

And if we could go to the third page of this, of

19

UPX...

20

MR. DINTZER:

21

Google's website.

Oh, well, we'll offer it.

22

MR. SMURZYNSKI:

23

THE COURT:

24

(Exhibit UPX2034 admitted into evidence)

25

BY MR. DINTZER:

No objection.

Okay, it will be admitted.

This is from

6452
1
2

Q.

At the top of the third page you write:

"Training and

running advanced AI models can be energy consumptive"?

3

A.

Yes.

4

Q.

That's because there's a lot of computation going on

5

there, right?

6

A.

Yes.

7

Q.

And that can be expensive?

8

A.

Yes.

9

Q.

And then you write:

"Another benefit of training

10

smaller application-specific models is that the energy costs of

11

the larger base model, such as MUM, are amortized over many

12

other different applications."

13

Do you see that?

14

A.

That is correct.

15

Q.

And running the AI model, such as MUM, can be more

16
17

expensive than the core models that we looked at?
A.

Yes.

I just want to emphasize that the difficulty --

18

I mean, certainly they will be more expensive, no question

19

about that.

20

models at the latency that you need and the throughput that you

21

need is very, very hard.

22

sub second latencies, to get them at the QPS that we need to

23

run it, is very, very difficult.

24

expensive.

25

Q.

But the bigger thing is running those bigger

Okay.

Running things at such scale to get

It's not just that it's

When you say those bigger models, you mean like

6453
1

MUM?

2

A.

Yes.

3

Q.

I just wanted to make sure I understood that.

4

Then two paragraphs farther down it says:

"New language

5

models like MUM have enormous potential to transform our

6

ability to understand language and information about the

7

world."

8

A.

Yes.

9

Q.

"And while they may be powerful, they do not make our

10

existing systems obsolete."

11

You believed that when you wrote it?

12

A.

Excuse me?

13

Q.

You believed that when you wrote it?

14

A.

I believed that when I wrote it, and I still believe

Q.

Okay.

15
16

it.
"Today, Google search employs hundreds of

17

algorithms and machine learning models, none of which are

18

wholly reliant on any singular large model."

19

And that's still true, right?

20

A.

21

MR. DINTZER:

22

Yes.
And, Your Honor, I'm going to change gears.

This might be a good place.

23

THE COURT:

Okay.

24

MR. DINTZER:

25

do to edit, Your Honor.

How much longer do you think you have?

Probably another hour.

I'll see what I can

6454
1

THE COURT:

Why don't we take the next 15 minutes to see

2

if that can be --

3

MR. DINTZER:

4

THE COURT:

5

(Recess taken at 2:55 p.m.)

6

(Back on the record at 3:16 p.m.)

7

THE COURT:

8

examination.

9

BY MR. DINTZER:

10

Q.

Thank you, Your Honor.

-- trimmed down.

Okay, thank you.

I'm glad you've applied navboost to your

Sir, we're going to go in your book to UPX2026.

11

That's the book we gave you.

And it's a very -- it's a big

12

document.

13

you feel like you need to look at the whole document, we'll

14

hand it up, but it's like 400 pages.

15

"Search Platforms Summit," and then "Welcome."

We've given you an excerpt of the pages that -- if

The title of this is

16

Do you see that?

17

A.

Yes, I do.

18

Q.

And what is the Search Platform Summit?

19

A.

Search platforms is one of the four divisions within

20

the search team.

It's a sister organization to the search

21

quality team that I'm part of.

22

had, presumably for the whole team or maybe some appropriate

23

subset of the team.

24

MR. DINTZER:

25

MR. SMURZYNSKI:

This is the summit that they

And we'll offer this, Your Honor.
So, Your Honor, we have a number of

6455
1

pages.

2

be a deck that was produced by Google, and in that case we

3

would not object.

But it may be that there's a need for a

4

complete document.

It may be that there isn't a need for a

5

complete document.

But having just received it, we'd want that

6

opportunity to review it.

7

We haven't reviewed the whole document.

THE COURT:

Okay.

It appears to

But with those caveats.

So we'll admit this excerpt, subject to

8

the completeness request made by Google's counsel.

9

(Exhibit UPX2026 admitted into evidence)

10

MR. DINTZER:

11
12

And we're giving them a whole one now, Your

Honor, so that they have access to it.
Q.

Sir, we're going to go to page -- I think it's the

13

second page that you're seeing here, it's Bates numbered 7122.

14

Just let me know when you get there.

15

A.

Yes, I got there.

16

Q.

Okay.

17

slow."

And the heading is:

"Some queries are really

18

Do you see that?

19

A.

Yes, I see it.

20

Q.

And it says the queries, but actually this is about

21

latency, right?

22

A.

This is about latency, yes.

23

Q.

And this is the time it takes for Google to answer the

24

queries?

25

A.

That's -- I think that's what it is, yes.

6456
1

Q.

And at the bottom the notes say:

"It turns out a

2

bunch of queries are really slow for our users."

And then if

3

you jump down it says:

4

takes more than X for the user to get the answer."

"One in four times they get issued, it

5

Do you see that?

6

A.

Yes, I see that.

7

Q.

And is that amount of time, the seconds, longer than

8

Google would want it to be?

9

A.

It is indeed.

10

Q.

I'm going to go to the next page, 7123.

11

Do you see

that?

12

A.

Yes, I do.

13

Q.

And the heading is:

14

Do you see that?

15

A.

Yes.

16

Q.

And this is on mobile, right, these are mobile pages?

17

A.

At least on the left they look like mobile pages.

18
19
20

"Bing appears faster."

I

assume the right, also, they're mobile pages.
Q.

And at the top it says:

"Bing first result arrives

sooner X percent of the time."

21

Do you see that?

22

A.

Yes, I see that.

23

Q.

And what we're seeing here is Google loading a

24

document and then Bing loading the same document, and the

25

comparison of how fast Bing is loading it versus Google.

Do

6457
1

you see that?

2

A.

Yes, I think so.

3

Q.

And then if we go to the next page, 7124, and the

4

heading is:

"Deja vu."

5

Right, do you see that?

6

A.

Yes.

7

Q.

And it says:

"We haven't been focusing enough on low

8

latency."

That's one of the comments.

And the footnotes say:

9

"Every couple of years we sound the alarm, have a code yellow,

10

but we keep ending up back here again."

11

Do you see that?

12

A.

Yes, I do.

13

Q.

Do you remember when this was an issue that was raised

14

up to you, that Google's latency was significantly slower than

15

Bing's?

16

A.

17
18

I don't remember the specific instance, but this

has -- this kind of thing has been raised with me, yes.
Q.

Do you remember Google instituting a response to this

19

specific set of events where Google found that it was slower

20

than Bing on mobile?

21

A.

22

MR. DINTZER:

23

Yes.

I think we did take action, yes.
Let's go to UPX2022.

Your Honor.

24

MR. SMURZYNSKI:

25

THE COURT:

No objection.

It will be admitted.

And we'll offer this,

6458
1
2

(Exhibit UPX2022 admitted into evidence)
BY MR. DINTZER:

3

Q.

Do you recognize this document, sir, Google v. Bing?

4

A.

I think I have seen this, yes.

5

Q.

And it's a summary of findings.

This is June 2017:

6

"Looking specifically at mobile queries on browsers, Bing

7

consistently serves search results faster than Google today."

8

A.

Yes.

9

Q.

And then number one says:

10

"Bing results arrive

approximately 300 milliseconds faster."

11

A.

Yes.

12

Q.

Do you recall what Project Folly was?

13

A.

Folly was an attempt at instituting a set of projects

14

and policies and processes to decrease latency.

15

Q.

16

latency?

17

A.

And with the specific goal of catching Bing on

Well, I don't know that they made that the specific

18

goal.

19

and they've consistently done that since then.

20

They would set themselves goals of decreasing latency,

Q.

And what are the elements that cause -- let me try it

21

a different way.

How can a company like Bing -- like Google

22

lower latency?

23

lower latency is a good thing, right?

And just so that we get the directions right,

24

A.

Lower latency is a good thing, yes.

25

Q.

So what variables can come into play to lower latency?

6459
1

A.

I think that there are many, many factors that go into

2

this.

So let's start with the -- what's on the search results

3

page.

There's been a big push to enrich the search experience,

4

because users like more visual pages with lots of images.

5

so as there has been a push to have more images on the page,

6

pages have become more heavy.

7

become more expensive in terms of latency, and that has been a

8

big factor.

9

otherwise cleverly encode them has been some of the work that

10

goes on in decreasing that kind of latency.

11
12

Q.

And

Downloading those images has

So finding ways to either compress those images or

And that would be an investment in engineering and

coding and the like?

13

A.

That is correct.

14

Q.

And another way of addressing --

15

A.

And also in process, because it's not as if there is

16

one singular team that does it, it's distributed across many

17

different teams.

18

sort of applying best practices here.

19

involved also.

20

Q.

21
22

So you need to make sure that all teams are
So there's process

Another way that a general search engine can reduce

latency is investment in servers and other hardware, right?
A.

Well, before you get there, there are other factors

23

that go into it, which is as we improve search, such as running

24

ML models and things, the work that you do in constructing the

25

SERP itself goes up.

And so there are efficiencies that you

6460
1
2

need to have in there that allows you to decrease latency also.
Q.

Okay.

And then getting back to my question:

The

3

investment in servers and hardware, that can also reduce

4

latency?

5

A.

So that may or may not be the case, right.

It is true

6

that when servers are heavily loaded, when there are traffic

7

peaks, adding extra machines can reduce latency.

8

servers get heavily loaded, then the requests sort of back up

9

one behind the other, and you have to wait for the previous

10

request to finish before you can start.

11

than at very peak times, servers don't run hot, they run at

12

sort of a lower capacity.

13

compute, so that's not the problem.

14

Because when

But typically, other

In those cases, there's plenty of

Some of these other factors are a problem.

The way your

15

software is structured, for example, we have a strategy -- a

16

historical strategy of constructing the whole SERP and then

17

shipping it back.

18

more of a streaming strategy that figures out what should be at

19

the top and sends it back while you're still working on the

20

rest of it.

21

machines -- adding machines is only one thing, and that only

22

addresses one fairly narrow aspect of the problem.

23

Q.

And instead of doing that, you should have

So there are lots of things you can do.

I think

Thinking about the machines, also building servers

24

closer to individuals so that there's less travel time between

25

the servers and the individuals, that also can reduce latency?

6461
1

A.

So you make a good point that the transport layer, the

2

connection between the user and Google, is another factor.

3

that is affected by things like where Google servers are, but

4

it's also affected by the user's own network connectivity with

5

their ISP, you know, is it over wifi, is it over a mobile

6

network.

7

user's own network connectivity sort of factors into this.

8

Q.

I guess we don't have dial-up anymore.

And

But the

Let's go to the second page of 2022, under the

9

heading, "Background."

And it says:

"Background.

As part of

10

the Folly effort, it was observed that today Bing appears to

11

serve search results faster than Google.

12

cases found, the query 'San Diego to LAX train' takes 3.69

13

seconds for content downloaded on Google versus only 565

14

milliseconds for Bing."

In one of the worst

15

Do you see that?

16

A.

Yes, I do.

17

Q.

And that was one of the things that was raising

18
19

concern at Google?
A.

Well, certainly having one query by itself is -- I

20

mean, it's concerning that it should take a long time, but just

21

feels like an outright bug to me more than anything else.

22

don't know exactly what happened with that query.

23

Q.

But that's a long time?

24

A.

But that's a long time.

25

Q.

I'm sorry, I didn't mean to interrupt.

I

6462
1

A.

Go ahead.

Go ahead.

2

Q.

Under the next heading it says -- under 2014 latency

3

lab study it says:

"The question has come up before.

In 2014

4

latency lab studies, Bing was faster than Google, mainly due to

5

it's lack of SSL."

6

Do you see that?

7

A.

Yes, I do.

8

Q.

So the latency issue had been one with respect to Bing

9

for a while?

10

A.

It was certainly back then in 2014 also.

11

Q.

And Google invested in engineering and work and time

12

to try to reduce the distance in latency between it and Bing,

13

right?

14

A.

15
16
17

I think more than thinking about it as Bing, I would

say Google invested in reducing its latency.
MR. DINTZER:

And so let's go to 2027.

We'll offer, Your

Honor.

18

MR. SMURZYNSKI:

19

THE COURT:

20

(Exhibit UPX2027 admitted into evidence)

21

MR. DINTZER:

22
23
24
25

No objection.

2027 is admitted.

Thank you.

BY MR. DINTZER:
Q.

Sir, this is an e-mail chain that you were on from

June 19th, 2017; is that right?
A.

Yes, it is.

6463
1
2

Q.

Let's go to the third page under analysis and tools.

Do you see that?

3

A.

Yeah.

4

Q.

And it says:

5

"Google v. Bing comparative analysis.

Bing results arrive 300 milliseconds faster."

6

Do you see that?

7

A.

Yes.

8

Q.

And so that's the same thing that we were talking

9

about, the 300 milliseconds, right?

10

A.

I think so.

11

Q.

Okay.

12

And then let's go to the first page, and we see

an e-mail from Nicholas Lim.

And who is Nicholas Lim?

13

A.

Honestly, I don't know.

14

Q.

Okay.

15

And you'll see that he writes:

"Hi, all.

Here's the latest Folly search latency update."

16

A.

Yes.

17

Q.

And the too long, did not read summary says:

"The

18

Folly program has defined two explicit goals to tackle head and

19

tail latency, reduce mean latency by 300 milliseconds and

20

reduce terrible" -- I'm not supposed to say that number --

21

"searches from" -- and I'm not supposed to say those numbers.

22

Do you see that?

23

A.

Yes.

24

Q.

So that happens to be the same 300 milliseconds as the

25

Bing distance, right?

6464
1

A.

Those numbers are certainly the same, yes.

2

Q.

Okay, okay.

And then it says:

"Nine cross-server

3

client product workstreams have been defined to meet these

4

ambitious goals and change culture to maintain latency

5

improvements."

6

Do you see that?

7

A.

Where is this?

8

Q.

That's the very next sentence after the TL;DR that I

9

just read.

10

A.

Oh, yes.

11

Q.

So this was an instance when Google -- I mean, this is

Yes.

12

an investment, cross-server client product workstreams, Google

13

invested a number of people to look at this problem, right?

14

A.

Yes.

But I want to call your attention to the "change

15

culture to maintain latency improvements," because this gets to

16

the heart of why latency goes up.

17

focused on quality, not just of things like ranking, but also

18

the user experience.

19

improve the user experience and so forth.

20

not necessarily experts on things like latency.

21

improve the user experience, maybe by adding more images, maybe

22

by doing more work, maybe going to more back ends to build a

23

more comprehensive page, latency goes up.

24
25

A lot of teams are very

And that's their focus, is to really
And these teams are

And that's what they're talking about:

And as we

How do we get a

culture change to make sure that all the hard work that this

6465
1

team does to reduce latency isn't eaten up by quality

2

improvements by other teams.

3
4

Q.

Okay.

Do you know if Bing ever -- if Google ever

caught Bing on latency?

5

A.

No, I don't know.

6

Q.

Let's go to UPX2033.

7

This is an April 21st, 2020

e-mail chain that you're on?

8

A.

9

MR. DINTZER:

10

MR. SMURZYNSKI:

11

THE COURT:

12

(Exhibit UPX2033 admitted into evidence)

13

Yes.
We'll offer this, Your Honor.
No objection.

It will be admitted.

BY MR. DINTZER:

14

Q.

Who's Mr. Gomes, Benedict Gomes?

15

A.

He used to be my boss at that time, I think.

16
17

He used

to be heading search.
Q.

And he writes at the bottom e-mail -- and this is

18

April 20th -- and just to remind us all, that was sort of right

19

after COVID shutdown.

20

the next COVID update goes over the key priorities as I see

21

them, probably in descending order.

22

all of these."

He writes:

23

Do you see that?

24

A.

Yes.

25

Q.

And number one was:

"Hey, I want to make sure

We can't obviously cover

"Query sets and side-by-sides on

6466
1

key COVID queries."

2

Do you see that?

3

A.

Yes, I do.

4

Q.

And that was that side-by-side testing that we talked

5

about for COVID queries?

6

A.

Yes.

7

Q.

And he wanted to do that testing to see how Google was

8

doing?

9

A.

Yes.

10

Q.

And then you write back and you write:

11

"We do have a

good query set where we've done a side-by-side with Bing."

12

Do you see that?

13

A.

Yes.

14

Q.

So the testing that Google did with respect to Bing on

15
16

COVID was a side-by-side?
A.

Well, we've certainly done a side-by-side.

I don't

17

know whether that's exactly what he's referring to here, but we

18

clearly did do a side-by-side with Bing, yes.

19

Q.

And you write:

"Overall, we do very well, but the

20

team is drilling into the loss cases to see what we can

21

improve."

22

Right?

23

A.

Yes.

24

Q.

And so Google was looking at the times when Bing might

25

have done better than Google?

6467
1

A.

Yes.

2

Q.

And you talked about how Google looks at Bing for

3

latency and for quality, and that's something that Google has

4

done for the past 10, 12 years, right?

5

A.

Yes.

But we've also looked at other places where

6

people find information.

7

TikTok, for example.

8
9
10

Q.

We've done similar exercises with

Do you know if there's been a latency test against

Google and TikTok?
A.

No, there wouldn't be a latency test because they're

11

very different experiences.

So there can't be a latency

12

test --

13

Q.

Do you do IS scores with TikTok?

14

A.

We can't do IS because it's a different experience.

15

But, it's a place where people turn to find information also,

16

which is sort of the broader point of what we are doing here.

17
18

Q.

Finally, sir, you're aware that there's a history

function for the chatrooms that Google uses?

19

A.

Yes.

20

Q.

You know it's history on, history off, right?

21

A.

Yes.

22

Q.

And you're familiar with the fact that some of the

23

rooms default to history on or history off, right?

24

A.

Yes.

25

Q.

You understood before this case was filed that history

6468
1

off meant that the chats would be destroyed or deleted after a

2

certain amount of time?

3

A.

Yes.

4

Q.

And from time to time, you asked people to turn

5
6
7

history off before or during your chats?
A.

Well, I've certainly done that, because at the time

there was a policy at Google to have history off.

8

Q.

And you --

9

A.

And I just wanted to be compliant with that policy.

10

Q.

You understood Google's policy was that history off

11

for chats amongst Google employees?

12

A.

13

MR. DINTZER:

14

Yes.
No further questions, Your Honor.

the witness.

15

THE COURT:

16

Any redirect -- oh, Mr. Cavanaugh?

17

MR. CAVANAUGH:

No questions for the witness.

18

MR. SMURZYNSKI:

Very briefly, Your Honor.

19

REDIRECT EXAMINATION OF P. PANDURANG NAYAK

20
21
22

We pass

Okay.

Thank you, Counsel.

BY MR. SMURZYNSKI:
Q.

Dr. Nayak, starting with this topic of latency, we

heard the term Folly.

What does Folly stand for?

23

A.

Actually, I really don't know.

24

Q.

Well, I will -- let me direct your attention to 2027.

25

A.

This is in which --

6469
1
2
3
4

Q.

It's in the white binder.

It's one of the documents

you just looked at.
In the middle of the page there's the e-mail from Nicholas
Lim, and the first CC refers to a group.

5

A.

Oh, Friends of Low Latency.

6

Q.

Does that refresh your recollection as to what Folly

7

stands for?

8

A.

Yes, Friends of Low Latency.

9

Q.

Fundamentally, what is latency a result of when Google

10
11

search is returning a search results page?
A.

So latency is a result of many different factors.

It

12

depends on the amount of work you do on the server side to get

13

the best results.

14

machine learning, constructing the features, all of that is

15

factored in.

16

transport latency.

17

sending the bits across the wire.

18

only the speed of the network, but also how heavy the page is,

19

how many features you have, how many images you have and so

20

forth.

21

JavaScript you have to download onto the client.

So all this going to the index, running the

This is server-side latency.

Then there is the

This is related to the latency of actually
And that is affected by not

Plus, if you want to -- an interactive page, how much

22

And then there is the latency that is on the client

23

itself, which is actually running the JavaScript to render the

24

page.

25

how all this is done:

And in all this is all of the architectural elements of
Do you do all the work once up front and

6470
1

send it all down; do you construct it as a streaming protocol

2

so that it looks like it's faster because the important stuff

3

is coming sooner.

4

https for security, because that takes a little time to encrypt

5

and decrypt things.

6
7

Q.

It also depends on things like do you do

So there's many factors that go into it.

Could Google reduce its latency by spending less time

trying to produce quality results on the server side?

8

A.

I mean, that's -- if we could do that, that would be

9

wonderful.

10

server side has to do with the fact that we think that this is

11

useful to users.

12

improving the quality.

13

balance that.

14

figure out how to balance those things, optimize those things.

15

That's the hard work that needs to happen, is how you balance

16

these different factors, because they're really sort of

17

incomparable.

18

Q.

But the reason we have a lot of sort of code on the

That's why we've added those features.

It's

And so one has to figure out how to

If it doesn't go to latency cost, we have to

And in general, how has Google approached that

19

trade-off between tolerating some amount of latency and making

20

sure that it delivers quality results to users?

21

A.

We have tried to -- in the past, it used to be that

22

each time people launched things, this would go to a latency --

23

a latency tzar kind of thing to say what kind of latency was

24

this incurring.

25

because quality or experience was really quite the important

But they couldn't really stop the launch,

6471
1

thing for us to do.

We didn't want to trade that off.

And so

2

they would work to make sure that we instituted the best

3

practices.

4

great experience for users, and so latency would creep up as a

5

result of that.

But, at the end of the day, we wanted to build a

6

More recently, we have other process changes where

7

different teams have been given latency budgets that they can

8

work under, and that seems to be working better as a way of

9

keeping things in check.

10

we've made to enable this kind of thing.

11

Q.

So there's various process changes

You were asked a couple questions before our break

12

about mobile and desktop.

13

queries?

14

A.

Does location matter on desktop

Location matters on desktop also.

If I come and

15

search for weather on desktop, I hope I would get weather in

16

Washington, D.C. as against, you know, in Chicago.

17

Q.

And has Google used that knowledge from desktop

18

queries and how location has mattered in desktop queries

19

historically in its mobile applications?

20

A.

Yes, absolutely.

21

Q.

Counsel for plaintiffs drew a number of diagrams on

22

the chart over there.

23

them.

24

retrieve results?

25

Navboost figured quite prominently in

Is navboost the only core algorithm that Google uses to

A.

No, absolutely not.

6472
1
2
3

Q.

How many signals does Google use, of which navboost is

A.

I mean, overall, there's a lot of signals.

one?
You know,

4

maybe over a hundred signals.

But for retrieving documents,

5

the document itself is perhaps the most important thing, those

6

postings lists that we have that we use to retrieve documents

7

from.

8

to the tens of thousands.

9

factors, again.

10

retrieval type algorithms which cull topicality and things,

11

which are really important.

12

reliability of results, that's another big factor.

13

localization type things that go on there.

14

navboost also in that.

15

THE COURT:

That's perhaps the most important thing, to get it down
And then after that, there are many

There are sort of code IR type, information

There is page quality.

I'm sorry to interrupt.

The
There's

And there is

Can I ask you to give

16

me a sense of where navboost is in the hierarchy of important

17

variables.

18

would you rank it in terms of its significance in that process?

19

Is it top 10 percent, 25 percent, top half?

THE WITNESS:

Where

I mean, it's hard to give sort of a rank

20

ordering like this.

I will say navboost is important, right.

21

So I don't want to minimize it in any way.

22

that there are plenty of other signals that are also important,

23

like the ones I mentioned.

24

of these things.

25

like, the index to the documents.

But I will also say

And you can't really turn off some

I don't know what it would mean to turn off,
That is in some ways like

6473
1

the most important thing, the words on the page and so forth,

2

right.

3

say that navboost is one of the important signals that we have.

So it's a little hard to judge in that way.

4

THE COURT:

5

BY MR. SMURZYNSKI:

6

Q.

So I would

Thank you.

And, finally, you were asked some questions about a

7

blog post that you had written, and you were talking about the

8

expense of MUM in terms of energy and compute.

9

address the fact that the MUM model, in the teacher sense, has

10

expense in terms of both energy and compute in serving results

11

through its system?

How does Google

12

A.

So the truth is we don't run the MUM model in

13

production.

14

every query at run time.

15

So what we do there is to train other smaller models using the

16

special training, like the classifier we talked about, which is

17

a much simpler model.

18

production to serve the use cases.

So it's not as if the MUM model is running for

19

MR. SMURZYNSKI:

20

THE COURT:

It's too big and too slow for that.

And we run those simpler models in

Thank you.

Thank you.

21

your time and testimony.

22

THE WITNESS:

23

THE COURT:

24

(Witness not present)

25

THE COURT:

I have no further questions.

Dr. Nayak, thank you very much for

Thank you so much for having me.

Have a good evening.

So I take it we've come to the end of the day

6474
1

in terms of evidentiary presentation.

2

witnesses, correct, Mr. Cavanaugh -- or at least that's our

3

hope?

4
5
6

MR. CAVANAUGH:

So tomorrow we have two

Yes, Your Honor, we have two witnesses.

We don't anticipate a closed session with either one.
THE COURT:

Okay.

Help me with timing, because tomorrow

7

is our last day, and I want to make sure we have enough time to

8

finish both.

9

MR. CAVANAUGH:

We will have plenty of time.

10

we'll end a little early.

11

THE COURT:

12

Mr. Schmidtlein, did you want to add anything?

13

MR. SCHMIDTLEIN:

14

MS. WASZMER:

15
16

Okay.

I anticipate

Fine, terrific.

No, Your Honor.

Good afternoon, Your Honor.

Wendy Waszmer

for Google.
Just with the two witnesses Mr. Cavanaugh mentioned, I

17

think he and we do not have any confidentiality issues.

18

There's just one item I've raised with counsel for Microsoft

19

about, I believe, Mr. Cavanaugh's second witness, the Sky

20

witness, Mr. Vallez.

21

that could come up, depending on what the States' scope is.

22

We've proposed a way that we could do it in open court, I

23

believe we should be able to do it, but Microsoft counsel just

24

needs some time today to think about it.

25

I've just flagged one potential document

So, as of now, I think they just wanted me to reserve

6475
1

their ability to come in tomorrow and raise it if they do need

2

sealing, but we've proposed a way to do it in open court.

3

THE COURT:

Okay.

Thank you, I appreciate it.

4

So, as I said earlier, what we'll do sort of here forward

5

is I will ask counsel to just give me a heads up about

6

anticipated closed sessions for the next day.

7

What was the name of the witness, I'm sorry?

8

MR. SCHMIDTLEIN:

9

may have this issue.

10

THE COURT:

11

MR. SCHMIDTLEIN:

12

THE COURT:

13

So I'll -- you know, what I will do is we'll post

14

something this evening just providing notice, and anyone that

15

would like to be heard the next morning about it can.

16

Hopefully, we'll get this resolved and it won't be an issue,

17

but we'll proceed in that fashion.

18
19
20

Vallez, V-A-L-L-E-Z, is the witness that

What's the first name?
Paul.

Paul, okay, great.

MR. CAVANAUGH:

He'll be the second witness tomorrow, Your

Honor.
THE COURT:

Okay.

So if you expect, Mr. Cavanaugh, to

21

finish early, what I would propose is that our discussion about

22

any -- the proposed modifications that the New York Times has

23

made, that we push that to the end of the day.

24

able to give their counsel a general time where we think we

25

might end up.

I'd like to be

6476
1

MR. CAVANAUGH:

I gave Mr. Sommer a prediction of 3:30.

I

2

think if we went with 4:00 o'clock, Your Honor, I think we'd be

3

safe.

4

THE COURT:

Well, why don't I just tell him 3:30, because

5

that's about usually when we -- that may work, so great.

6

we'll notify them about that.

7

Okay, anything else?

8

MR. DINTZER:

9

MR. CAVANAUGH:

10

MR. SCHMIDTLEIN:

11

THE COURT:

So

Not from the DOJ plaintiffs, Your Honor.
No.
No, Your Honor.

Just one last thing on my list, then.

So we

12

have now have had the opportunity to review and make now

13

available -- and we'll post a minute order to this effect as

14

well -- the previously closed sessions for Mr. Yoo, Mr. Lehman

15

and Mr. Roszak.

16

say, before we conducted a line-by-line evaluation, we did

17

request input from the parties.

18

evaluation of their proposals, and applied the Hubbard factors

19

to those proposals.

20

recognize that one in six probably certainly favor disclosure.

21

And given the nature of some of this, certainly I think those

22

factors favor disclosure.

23

As before, we did conduct -- well, I should

We did conduct a line-by-line

Just, again, in terms of those factors, I

There are other aspects of the requests for sealing that I

24

think, however, arguably outweigh the request for disclosure.

25

And specifically they relate to, in this case, concerns about

6477
1

making public information that hasn't previously been made

2

public, which is a factor to consider.

3

competitive harm, specifically in this case to Google, since

4

all three of those witnesses related to them.

5

And the potential for

So just applying all of those factors -- and I'm not going

6

to -- applying those factors, these are sort of the general

7

categories of -- general subject matters that we did agree to

8

redact.

9

e-mail addresses; two, code names and internal projects --

10

excuse me, code names and internal terms for projects that are

11

not otherwise public -- and I'm speaking just in terms of the

12

code name itself.

13

Again, one, personally identifying information, like

We also have -- as has been consistent with what has been

14

done today, that to the extent that there's proprietary

15

information revealed in the transcripts about how certain

16

systems or features work, including any data inputs and

17

programming details -- for example, the number of training

18

examples for a search algorithm or the number of pages that a

19

search engine indexes, those were numbers that we thought were

20

proprietary and arguably trade secrets for Google that we did

21

accept the proposed redactions.

22

We did not, however, accept all of them.

For example,

23

sort of high-level statements about one firm's product by

24

another firm, including results of product comparisons with

25

other firms, some of which we've heard about today in open

6478
1

court, such as Google's internal quality assessments about

2

Bing, we did not redact.

3

Similarly, there was -- I think it was with Mr. Roszak,

4

there was a discussion of an internal Google assessment of

5

Bing's -- what it would take for Bing essentially to become the

6

default for Apple, and some of the financial calculations that

7

Google was estimating about what it would take for Bing to

8

potentially secure that default.

9

Those we did not redact.

And then we did not redact what we thought of as sort of a

10

high-level description of certain features of technology,

11

particularly that that's been around for a long time, which I

12

think has sort of been consistent with the way we treated it

13

today -- so a high-level description of what the technology is.

14

But, again, the particular inputs we did not -- we did redact

15

the particular inputs, because I thought those were more

16

aligned with trade secrets that, if disclosed, could result in

17

competitive harm, okay.

18

So with that, is there anything else?

19

adjourn for the evening.

20

MR. DINTZER:

21

THE COURT:

22
23
24
25

Then we will

Not from us, Your Honor.

Thank you all very much.

morning.
(Proceedings adjourned at 3:54 p.m.)

We'll see you in the

BY MR. DINTZER: - again

6480

6475/11 6475/19
6428/22 6429/6
actively [1]
2
6476/3 6476/10
6409/16
5213 [1] 6439/11
BY MR. DINTZER:
20 [2] 6431/12
6478/20
actual [6] 6411/4
5231 [1] 6440/3
6431/19
[15] 6395/14
6428/20 6436/4
THE WITNESS: [15]
5233 [1] 6440/19
6400/17 6405/13
200 [1] 6399/15
6400/15 6405/11
6441/8 6441/13
565 [1] 6461/13
6407/12 6428/6
20001 [2] 6392/17
6406/9 6407/5
6441/13
6434/3 6437/7
6393/25
6
6427/11 6427/13
actually [19]
6439/16 6442/18
20005 [1] 6392/15
6 percent [4]
6427/16 6427/25
6396/21 6411/16
6445/23 6451/24
20024 [1] 6393/9
6417/15 6417/16
6433/19 6433/22
6417/19 6421/18
6454/8 6458/1
2005 [1] 6402/22
6418/18 6418/18
6437/3 6442/6
6422/22 6422/23
6462/21 6465/12
2014 [5] 6397/3
600 [1] 6392/19
6445/11 6472/18
6426/22 6426/24
6414/9 6462/2
BY MR.
60604 [1] 6392/20 6429/7 6429/25
6473/21
6462/3 6462/10
SMURZYNSKI: [2]
616,386 [2]
6437/4 6441/18
6468/19 6473/4
2015 [3] 6397/3
'
6426/7 6427/10
6443/15 6449/25
6397/7 6430/14
MR. CAVANAUGH:
6395 [1] 6394/4
'16 [1] 6397/7
6450/14 6455/20
[6] 6468/16
2017 [5] 6405/23
6435 [1] 6394/11
'17 [1] 6397/7
6468/23 6469/16
6474/3 6474/8
6409/6 6409/13
6451 [1] 6394/12
'San [1] 6461/12
6469/23
6475/17 6475/25
6458/5 6462/24
6455 [1] 6394/13 add [6] 6404/12
6476/8
2019 [2] 6435/10
.
6458 [1] 6394/14
6408/9 6408/10
6435/20
MR. DINTZER: [26] .....Admitted [6]
6462 [1] 6394/15
6426/15 6451/4
6395/3 6395/7
2020 [3] 6397/9
6394/11 6394/12
6465 [1] 6394/16
6474/12
6395/10 6395/12
6423/24 6465/6
6394/13 6394/14
6468 [1] 6394/5
added [2] 6408/13
6414/3 6432/19
2021 [1] 6451/10
6394/15 6394/16
66 [1] 6417/22
6470/11
6435/12 6435/18
2022 [1] 6461/8
680 [1] 6393/9
adding [3] 6460/7
6439/13 6442/5
2023 [1] 6392/5
1
6460/21 6464/21
6442/7 6442/9
2027 [3] 6462/16 7
10 [1] 6467/4
additional [2]
6442/14 6451/19
6462/19 6468/24
10 percent [1]
7122 [1] 6455/13
6424/17 6427/19
6453/20 6453/23
209
[1] 6392/19
6472/17
7123 [1] 6456/10 additive [1]
6454/2 6454/23
20th [1] 6465/18 7124 [1] 6457/3
10,000,000 [1]
6430/22
6455/9 6457/21
21st [1] 6465/6
6399/7
757,000 [2]
address [1]
6462/15 6462/20
10019 [1] 6393/12 2200 [2] 6392/23
6425/4 6425/5
6473/9
6465/8 6468/12
10036 [1] 6392/24 6392/23
7th [1] 6393/4
addresses [2]
6476/7 6478/19
24 [1] 6392/7
1087 [1] 6414/3
6460/22 6477/9
MR. SCHMIDTLEIN: 10:00 [1] 6442/13 25 percent [1]
8
addressing [1]
6472/17
[4] 6474/12
10K [1] 6407/24
80203 [1] 6393/5
6459/14
6475/7 6475/10
2:55
p.m [1]
1100 [1] 6392/14
8074 [1] 6442/25 adequate [1]
6476/9
6454/5
1133 [1] 6392/23
8075 [1] 6446/24
6409/20
MR. SMURZYNSKI:
2X [1] 6437/5
11th [1] 6414/8
86 [1] 6417/24
adjourn [1]
[12] 6432/15
12 years [1]
6478/19
3
6435/14 6439/15
A
6467/4
adjourned
[1]
3.69 [1] 6461/12 A/B [1] 6410/13
6442/11 6442/16
129 [1] 6409/25
6478/23
30 [2] 6431/12
6451/21 6454/24
ability [2]
13 [1] 6405/21
adjust [2]
6431/19
6457/23 6462/17
6453/6 6475/1
13 months [3]
6399/24 6431/12
300 [3] 6407/17
6465/9 6468/17
ablation [1]
6410/21 6432/11
admit
[1] 6455/7
6407/19 6407/24
6473/18
6409/13
6433/18
admitted
[12]
300 milliseconds
MS. WASZMER: [1] 1300 [1] 6393/4
able [4] 6395/5
6414/4
6435/16
[5] 6458/10
6474/13
6426/16 6474/23
1301 [1] 6393/11
6435/18 6451/23
6463/5 6463/9
THE COURT: [47]
6475/24
15 [1] 6454/1
6451/24 6455/9
6463/19 6463/24
6395/1 6395/6
above [1] 6479/5
15,000 [6]
6457/25 6458/1
3010 [1] 6392/4
6395/9 6395/11
above-entitled [1] 6462/19 6462/20
6424/11 6424/12
6393/24
333 [1]
6400/14 6405/8
6479/5
6424/20 6425/8
6465/11 6465/12
3:16 p.m [1]
6406/5 6407/3
absolute [1]
6425/10 6426/8
advanced
[2]
6454/6
6407/11 6427/8
6434/20
15th [1] 6414/9
6429/10 6452/2
6476/1
3:30
[2]
6427/12 6427/15
absolutely [6]
16,000 [1]
advantage [1]
6476/4
6427/21 6428/5
6412/13 6422/4
6423/20
6428/19
3:54 p.m [1]
6433/14 6433/21
6427/8 6441/20
17 [1] 6423/15
affected [3]
6478/23
6434/2 6435/15
6471/20 6471/25
17.003 [1]
6461/3 6461/4
6437/1 6442/8
accept
[2]
6423/16
6469/17
4
6442/10 6442/17
6477/21 6477/22
1720 [1] 6414/12
afternoon
[3]
400 [1] 6454/14
6445/9 6451/22
access [1]
1723 [1] 6421/14
6392/7
6395/16
400 billion [1]
6453/22 6453/25
6455/11
1724 [1] 6421/15
6474/14
6397/10
6454/3 6454/6
accurate [2]
18 [1] 6392/5
afterwards
[1]
40th [1] 6393/11
6455/6 6457/24
6427/22 6440/17
18 months [2]
6442/16
4417 [1] 6435/21 across [5]
6462/18 6465/10
6405/24 6410/21
again [13]
450 [1] 6392/17
6468/14 6472/14
6431/25 6441/23
19th [1] 6462/24
6396/24 6398/13
4:00 [1] 6476/2
6473/3 6473/19
6441/25 6459/16
1:20-cv-3010 [1]
6408/12 6408/13
6473/22 6473/24
6469/17
6392/4
6419/8 6426/5
5
6474/5 6474/10
action [2] 6392/3 6426/9 6450/13
1:32 [1] 6392/6
500-pound [2]
6475/2 6475/9
6457/21
6457/10 6472/9

again... - brings

6481

6413/21 6414/24
anonymized [1]
become [3] 6459/6 6457/20 6458/3
6395/24
6459/7 6478/5
6458/6 6458/9
aspect [1]
again... [3]
6460/22
6458/15 6458/21
anticipate [2]
becoming [1]
6476/19 6477/8
6474/5 6474/9
6437/15
6461/10 6461/14
aspects [1]
6478/14
6476/23
6462/4 6462/8
anticipated [1]
begins [2]
against [3]
6475/6
6444/21 6447/17
6462/12 6462/14
assessment [1]
6410/14 6467/8
6478/4
6463/4 6463/5
Antitrust [1]
behaviors [1]
6471/16
6393/4
6414/21
6463/25 6465/3
assessments [1]
aggregate [2]
6478/1
anymore [1]
behind [1] 6460/9 6465/4 6466/11
6441/21 6441/23
6461/6
6466/14 6466/18
assume [1]
beings [1]
ago [3] 6402/17
6456/18
6426/23
6466/24 6467/2
Anyways [1]
6434/9 6443/6
6435/3
6478/2 6478/5
ATMs [1] 6419/12 Belknap [1]
agree [4] 6397/2
6392/22
6478/7
apologize [1]
attempt [1]
6437/13 6445/1
6426/20
6458/13
BELLSHAW [1]
Bing's [3]
6477/7
6392/16
6396/18 6457/15
Apparently [1]
attention [2]
Ah [1] 6451/13
6435/9
6464/14 6468/24
BENCH [1] 6392/10 6478/5
6442/15
ahead [3]
appear [1]
augmented [2]
Benedict [1]
bit [3] 6419/16
6462/1 6462/1
6401/24
6448/15 6448/18
6465/14
6420/5 6443/14
AI [2] 6452/2
APPEARANCES [2]
August [2] 6414/8 benefit [1]
bits [1] 6469/17
6452/15
6392/12 6393/1
6414/9
6452/9
black [7] 6423/11
al [1] 6392/3
6436/2 6437/1
appears [4]
August 11th [1]
BERT [20] 6431/6
alarm [1] 6457/9
6441/21 6455/1
6414/8
6433/4 6433/6
6437/19 6437/24
algorithm [4]
6456/13 6461/10
6433/6 6433/9
6438/3 6444/15
August 15th [1]
6399/19 6448/16
6414/9
6433/10 6433/10
Apple [1] 6478/6
blanket [1]
6471/23 6477/18
6439/9 6440/6
6450/4
application [2]
available [1]
algorithms [8]
6476/13
6440/7 6440/9
6433/6 6452/10
blind [1] 6432/23
6399/15 6399/20
6448/13 6448/16
blog [2] 6451/14
application-specif Avenue [4]
6400/1 6400/22
6392/23 6393/9
6448/16 6448/17
6473/7
ic [1] 6452/10
6404/19 6451/1
6393/11 6393/24
6448/17 6448/18
blue [5] 6403/17
applications [2]
6453/17 6472/10
6448/21 6449/17
6403/21 6404/8
6452/12 6471/19
aware [3] 6396/7
aligned [1]
6396/9 6467/17
6449/21
6423/24 6428/2
applied [2]
6478/16
6454/7 6476/18
BERT's [1]
bold [1] 6447/9
allow [1] 6439/3
B
6440/11
book [3] 6450/23
applying [3]
allows [2]
back [27] 6395/2 best [7] 6400/4
6454/10 6454/11
6459/18 6477/5
6427/19 6460/1
6400/19 6400/24
6408/23 6412/17
6477/6
borders [2]
along [1] 6425/17
6402/22 6403/1
6450/8 6459/18
6419/8 6419/18
appreciate [4]
always [2] 6423/6
6406/4 6419/10
6469/13 6471/2
6411/2 6419/1
boss [1] 6465/15
6450/7
6421/25 6422/23
6432/20 6475/3
better [14]
both [9] 6396/18
ambitious [1]
6427/20 6430/4
6397/19 6398/2
6401/11 6403/15
approach [1]
6464/4
6430/5 6438/3
6404/14 6410/18
6418/7 6418/8
6395/11
AMERICA [4]
6442/16 6445/25
6411/14 6411/21
6436/23 6444/5
approached [1]
6392/3 6413/10
6449/4 6449/20
6411/24 6429/15
6473/10 6474/8
6470/18
6419/11 6419/14
6450/23 6454/6
6439/20 6445/4
bottom [7]
appropriate [1]
Americas [2]
6457/10 6460/2
6448/18 6450/17
6414/12 6417/5
6454/22
6392/23 6393/11
6460/8 6460/17
6466/25 6471/8
6420/16 6421/14
approval [3]
AMIT [1] 6392/10
6460/19 6462/10
6435/21 6456/1
6427/24 6428/2
beyond [2]
among [1] 6407/10
6464/22 6466/10
6420/10 6421/17
6465/17
6428/3
amongst [1]
big [10] 6410/22 bought [1]
approximately [1] Background [2]
6468/11
6461/9 6461/9
6410/22 6419/15
6400/16
6458/10
amortized [1]
6419/20 6440/13
box [9] 6416/3
April [2] 6465/6 balance [3]
6452/11
6470/13 6470/14
6454/11 6459/3
6424/21 6425/1
6465/18
amount [19]
6470/15
6459/8 6472/12
6425/2 6425/3
April 20th [1]
6398/4 6398/6
Bank [3] 6413/10
6473/14
6437/2 6437/24
6465/18
6398/10 6406/1
6419/10 6419/14
6438/3 6444/15
bigger [9]
April 21st [1]
6409/18 6409/18
banking [1]
6397/19 6397/24
6465/6
boxes [1] 6432/18
6411/3 6418/9
6413/14
6397/25 6398/1
bracket [1]
architectural [1]
6432/13 6439/2
Bankruptcy [1]
6420/3 6434/19
6420/16
6469/24
6443/23 6444/25
6393/24
6452/19 6452/19
Brain [1] 6447/13
area [1] 6421/7
6447/21 6449/6
bar [1] 6423/24
6452/25
branches [1]
arguably [2]
6449/8 6456/7
Bard [4] 6445/15 billion [1]
6413/13
6476/24 6477/20
6468/2 6469/12
6445/25 6446/2
6397/10
break [2] 6415/14
around [3]
6470/19
6448/7
6412/16 6423/21
binder [7] 6409/2 6471/11
analyses [1]
base [1] 6452/11
6478/11
6414/2 6414/3
briefly [1]
6414/20
6468/18
6423/11 6439/8
arrive [2] 6458/9 based [2] 6412/3
analysis [4]
6448/6
6463/5
6442/3 6469/1
bring [4] 6399/15
6414/24 6438/4
basically [2]
arrives [1]
Bing [32] 6434/15 6400/2 6400/23
6463/1 6463/4
6401/23 6424/19
6428/24
6456/19
6434/20 6449/5
And you [1]
Bates [3] 6414/11 6456/13 6456/19
brings [1]
art [1] 6429/6
6468/8
6414/12 6455/13
6424/17
6456/24 6456/25
article [2]

A

broad - content

6482

6431/17
6450/4 6452/2
6469/22
cetera [1]
6440/14
6452/7 6452/15
close [1] 6422/8 comprehensive [3]
broad [2] 6395/19
6453/24 6454/2
chain [2] 6462/23 closed [3] 6474/5 6397/18 6397/22
6439/4
6465/7
6464/23
6458/21 6458/25
6475/6 6476/14
broader [2]
6459/20 6460/3
chance [3] 6408/5 closer [1]
compress [1]
6443/18 6467/16
6408/8 6408/10
6459/8
6460/7 6460/10
6460/24
Broadway [1]
6460/20 6460/25
change [12]
computation [3]
CO [1] 6393/5
6393/4
6398/24 6412/6
6444/25 6447/15
6466/20 6471/7
coarse [2]
brought [1]
6424/4 6425/21
6452/4
6472/15 6475/15
6429/19 6429/21
6420/2
6425/22 6426/11
computationally
capability [1]
code [6] 6457/9
brown [1] 6412/11
6426/13 6426/13
6437/18
6470/9 6472/9
[2] 6447/5
browsers [1]
6447/8
6477/9 6477/10
6453/21 6464/4
capacity [9]
6458/6
6398/16 6398/21
6477/12
6464/14 6464/25
compute [3]
budget [2]
6460/13 6473/8
6446/9 6446/17
coding [1]
changes [5]
6446/19 6446/20
6473/10
6446/18 6446/20
6459/12
6426/11 6426/13
budgets [1]
6447/18 6447/20
6426/17 6471/6
computed [1]
collected [1]
6471/7
6423/4
6460/12
6433/18
6471/9
bug [1] 6461/21
conceptually [1]
capture [1]
Colorado [3]
characterization
build [4] 6397/18
6406/7
6424/5
6392/21 6393/2
[1] 6404/23
6438/19 6464/22
6393/3
concern [1]
careful [1]
characterize [2]
6471/3
6461/18
6438/24
6404/15 6408/14
COLUMBIA [1]
building [1]
concerning [2]
carefully [2]
chart [2] 6417/18 6392/1
6460/23
6397/16 6461/20
6409/10 6438/19
6471/22
column [2]
built [1] 6444/11
concerns [1]
carrying [1]
charts [1] 6435/3 6427/23 6428/2
bullet [10]
6476/25
6398/16
combined [1]
ChatGPT [2]
6436/1 6436/2
6415/13
conduct [2]
case [10] 6419/11 6445/15 6448/6
6436/2 6437/1
6476/15 6476/17
6422/6 6426/14
combines [1]
chatrooms [1]
6437/9 6437/19
6450/7 6450/7
6446/3
6467/18
conducted [2]
6439/18 6440/12
6414/20 6476/16
6455/2 6460/5
chats [3] 6468/1 coming [2]
6440/22 6447/1
6467/25 6476/25
6422/14 6470/3
6468/5 6468/11
confident [1]
bunch [4] 6401/8
6444/17
6477/3
comments [1]
cheaper [1]
6407/8 6422/7
6457/8
confidentiality
cases [5] 6450/18 6447/14
6456/2
6460/12 6461/12
check [2] 6439/14 common [3] 6417/6 [1] 6474/17
businesses [1]
6466/20 6473/18
6471/9
6436/13 6447/19
confused [1]
6422/8
6418/22
catching [1]
Chicago [2]
common-sense [2]
6458/15
6392/20 6471/16
6436/13 6447/19
connection [1]
C
6461/2
categories [2]
choice [1]
company [2]
cadence [1]
6413/5
6477/7
6410/22
6420/17
6458/21
connectivity
[2]
6432/23
6461/4 6461/7
caught [1] 6465/4 circle [1]
comparative [1]
calculations [1]
6463/4
Connolly [1]
cause [1] 6458/20 6399/13
6478/6
6393/8
6392/3 compared [2]
caution
[1]
Civil
[1]
California [1]
6432/19
6448/8
6428/16
6434/14
cons
[1] 6428/16
claim
[1]
6421/19
Consequently
[1]
CAVANAUGH
[5]
classifier
[1]
comparison
[1]
call [2] 6438/20
6447/17
6392/22
6468/16
6473/16
6456/25
6464/14
6474/2 6474/16
consider [1]
clear [3] 6396/10 comparisons [1]
called [11]
6477/2
6475/20
6405/9
6449/11
6477/24
6399/15 6401/17
consistent [2]
Cavanaugh's [1]
clearly [3]
compelling [1]
6404/20 6405/10
6477/13 6478/12
6474/19
6429/17 6450/17
6429/9
6406/14 6406/16
6466/18
consistently
[2]
caveats
[1]
competitive
[2]
6408/17 6408/18
6458/7 6458/19
6455/6
6477/3 6478/17
clever [1]
6408/19 6411/16
6425/18
CC [1] 6469/4
complementary [5] constant [1]
6448/13
6449/8
6430/19 6430/21
certain
[6]
cleverly
[1]
can [51] 6395/23
6438/18 6446/18
6437/10 6437/16
6459/9
constantly [1]
6398/5 6399/24
6424/15
6446/18 6468/2
6437/17
click [12]
6403/6 6406/4
6477/15
6478/10
6411/20
6411/25
Constitution
[1]
complete
[2]
6406/6 6407/9
6393/24
6455/4 6455/5
6428/16 6428/19
certainly [21]
6407/14 6409/21
6398/12 6403/19
6431/9 6432/12
constrained [1]
completely [2]
6409/25 6411/21
6446/20
6404/9
6413/15
6421/20
6447/21
6438/14
6440/1
6412/6 6419/6
6416/22
6422/21
6448/22
6450/10
constraint
[1]
completeness
[1]
6419/21 6421/25
6446/22
6429/8
6429/10
6455/8
6450/11
6450/12
6422/9 6422/15
6430/13 6430/22
construct [1]
complex [1]
clicked [1]
6424/9 6429/16
6470/1
6431/16 6432/25
6445/22
6421/5
6429/18 6430/20
6437/5
6452/18
constructing
[3]
complexity
[1]
clicks
[7]
6433/15 6433/16
6459/24
6460/16
6461/19
6462/10
6446/10
6405/15
6407/21
6435/9 6438/25
6469/14
6464/1 6466/16
6428/19 6433/20
compliant [1]
6439/14 6439/16
6468/6
6476/20
6468/9
6434/12
6434/13
consumptive
[1]
6439/19 6440/3
6452/2
6476/21
6434/18
complicated [1]
6442/15 6442/15
CONT [1] 6393/1
certify [1]
client [4] 6464/3 6445/22
6445/19 6449/17
6479/4
6464/12 6469/21
content [1]
components [1]

B

content... - discussed

6483

6443/2 6443/7
6471/18
6448/22 6448/24
CPS/Antitrust [1]
6443/16 6444/3
6393/4
6449/1 6449/5
desktop-dominant
content... [1]
6444/8 6447/1
[3] 6415/25
craft [1] 6438/19 6449/6 6449/6
6461/13
6447/9 6447/18
6417/20 6418/3
6449/8 6449/10
create [3]
context [3]
6447/25 6449/24
6397/22 6408/3
6449/12 6449/13
destroyed [1]
6441/11 6445/10
6468/1
6422/16
6449/18 6449/23
default [3]
6445/11
6467/23 6478/6
6449/25 6450/5
detailed [1]
created [2]
contrast [1]
6478/8
6396/13
6424/1 6438/24
6450/6 6450/8
6445/3
6450/8 6450/10
Defendant [2]
details [4]
creating [1]
contribute [1]
6397/1 6413/22
6413/4
6450/10 6450/11
6392/7 6393/7
6430/23
6420/3 6477/17
6450/12 6450/14
creep [1] 6471/4
defendants [1]
control [1]
6439/8
determine [1]
crisp [1] 6444/19 6450/17 6450/18
6438/9
6411/21
6450/20 6477/16
critical [3]
defense [1]
convey [1]
6400/1 6400/22
6395/4
development [2]
datasets [1]
6399/12
6421/24 6422/25
6422/25
6413/5
defined [2]
core [21] 6399/15
6463/18 6464/3
device [1] 6417/2
cross [4] 6394/4 DATE [1] 6479/10
6399/18 6400/1
6395/14 6464/2
diagrams [1]
dates [1] 6402/17 definitely [1]
6400/12 6400/20
6471/21
6464/12
DAVID [1] 6392/18 6441/10
6400/22 6400/24
dial [1] 6461/6
Cross-Examination day [6] 6392/7
definition [2]
6402/13 6402/15
6471/3 6473/25
6445/2 6451/6
dial-up [1]
[2] 6394/4
6404/19 6406/12
6461/6
6395/14
6474/7 6475/6
Deja [1] 6457/4
6406/15 6406/18
6475/23
cross-server [2]
delete [2] 6396/1 Diego [1] 6461/12
6407/1 6407/23
6464/2 6464/12
6396/8
difference [2]
days [2] 6432/17
6407/25 6430/18
6417/3 6420/10
6449/23
cull [1] 6472/10
deleted [1]
6439/23 6451/1
6468/1
differences [1]
culled [3] 6404/6 DC [5] 6392/5
6452/16 6471/23
6413/7
6407/5 6407/15
6392/15 6392/17
deliberately [1]
corner [1]
6393/9 6393/25
6432/17
different [31]
culling [3]
6412/16
6401/8 6402/1
6406/9 6422/11
de [1] 6395/24
delivers [1]
corpus [3]
6413/5 6414/18
6470/20
6422/13
de-identified [1]
6439/20 6441/24
6414/19 6415/16
demonstrative [2]
culls [1] 6405/12 6395/24
6441/25
6417/11 6419/5
6399/10 6423/8
decide [3]
culture [3]
correlated [1]
6411/23 6427/4
6464/4 6464/15
demonstratives [1] 6420/11 6420/11
6441/21
6421/17 6421/18
6427/4
6402/5
6464/25
cost [6] 6446/9
decides [1]
Denver [1] 6393/5 6421/21 6425/23
current [1]
6446/12 6446/15
6425/24 6428/12
6427/5
6437/5
Department [4]
6446/18 6447/25
6428/15 6430/23
6392/14 6392/16
deciding [1]
cv [1] 6392/4
6470/13
6436/16 6441/9
6410/21
6392/19 6393/3
costs [1] 6452/10 D
decision [7]
depend [2] 6420/3 6441/10 6446/4
counsel [10]
D.C [1] 6471/16
6449/5 6452/12
6409/15 6410/22
6420/5
6439/15 6442/11
DAHLQUIST [1]
6458/21 6459/17
6410/23 6411/3
depending [2]
6442/18 6455/8
6392/18
6467/11 6467/14
6411/5 6430/15
6412/6 6474/21
6468/15 6471/21
data [81] 6395/20 6446/4
6469/11 6470/16
depends [6]
6474/18 6474/23
6405/18 6406/1
6471/7
6424/8 6430/12
decisions [2]
6475/5 6475/24
6409/9 6409/18
6410/25 6411/3
6450/13 6450/13
difficult [1]
countries [1]
6411/4 6411/25
6452/23
6469/12 6470/3
deck [1] 6455/2
6421/17
6412/23 6413/1
difficulty [1]
decrease [4]
deposition [2]
couple [2] 6457/9
6421/2 6421/18
6452/17
6397/16 6398/6
6404/20 6412/20
6471/11
6428/16 6428/19
6458/14 6460/1
depth [1] 6413/21 DINTZER [4]
course [5]
6428/19 6429/19
6392/13 6394/4
decreasing [2]
descending [1]
6419/18 6420/2
6429/25 6431/9
6395/3 6395/16
6458/18 6459/10
6465/21
6420/6 6442/23
6432/3 6432/6
direct [5]
decrypt [1]
describing [1]
6444/2
6432/9 6432/10
6399/14 6412/16
6470/5
6438/22
court [13] 6392/1
6432/12 6433/12
6413/8 6423/2
deep [18] 6399/24 description [2]
6393/23 6393/23
6433/16 6433/18
6468/24
6400/3 6400/5
6478/10 6478/13
6395/6 6404/2
6434/6 6434/8
6400/16 6408/5
directed [1]
desktop [29]
6405/2 6440/7
6434/8 6434/15
6442/9
6430/13 6430/14
6413/2 6413/8
6440/9 6442/16
6434/15 6434/19
6431/1 6431/8
6414/18 6414/25
direction [1]
6474/22 6475/2
6434/19 6436/8
6430/21
6437/20 6438/3
6415/12 6415/17
6478/1 6479/3
6436/9 6438/11
6438/8 6438/10
6415/25 6416/12
directions [1]
Court's [1]
6438/14 6438/14
6458/22
6443/5 6444/25
6416/18 6417/3
6404/3
6438/17 6438/17
6445/22 6448/1
6417/6 6417/20
disclosed [1]
Courts [1]
6438/19 6438/20
6478/16
6448/12
6418/3 6418/5
6393/24
6438/24 6438/25
6418/7 6418/8
disclosure [3]
DeepRank [22]
cover [2] 6435/10
6439/1 6439/2
6476/20 6476/22
6431/4 6433/1
6418/11 6418/12
6465/21
6439/2 6439/3
6476/24
6433/7 6433/10
6419/5 6419/13
COVID [5] 6465/19
6440/1 6444/25
6433/12 6435/21
6420/2 6420/10
discussed [5]
6465/20 6466/1
6445/4 6445/7
6400/6 6403/7
6435/22 6436/12
6420/17 6471/12
6466/5 6466/15
6445/17 6446/4
6433/1 6433/4
6436/20 6436/23
6471/12 6471/14
CPS [1] 6393/4
6446/7 6448/7
6450/7
6437/10 6437/17
6471/15 6471/17

C

discusses - explicit

6484

6397/15 6399/15
6479/5
excuse [4] 6440/8
effort [2]
6404/16 6406/16
6432/21 6461/10
equal [4] 6397/19 6442/7 6453/12
discusses [1]
6477/10
6406/24 6407/2
eight [1] 6435/22 6397/20 6450/5
6414/24
6415/14 6420/20
exercises [1]
either [2] 6459/8 6450/9
discussion [2]
6467/6
6431/19 6440/12
6474/5
essentially [2]
6475/21 6478/4
6443/14 6443/21
6419/13 6478/5
EXHIBIT [13]
element [1]
distance [2]
6394/10 6394/11
6444/21 6449/18
6448/1
estimating [1]
6462/12 6463/25
6394/12 6394/13
6453/4 6454/4
6478/7
elements [2]
distributed [1]
6394/14 6394/15
6456/3 6470/1
6458/20 6469/24
et [2] 6392/3
6459/16
6394/16 6435/18
6472/7
6440/13
else [9] 6397/19
distribution [1]
6451/24 6455/9
6397/20 6403/10
down-talk [1]
evaluate [2]
6418/10
6458/1 6462/20
6440/12
6433/19 6436/25
6429/1 6441/8
DISTRICT [4]
6465/12
6438/6 6461/21
download [1]
evaluation [7]
6392/1 6392/1
6469/21
6476/7 6478/18
6409/22 6421/23
existing [1]
6392/11 6393/24
6453/10
6422/24 6422/24
downloaded [1]
emphasize [1]
Divergence [1]
6461/13
6452/17
6440/23 6476/16
expect [1]
6417/6
6475/20
6476/18
Downloading [1]
empirical [3]
divisions [1]
6459/6
6449/14 6450/1
expense [4]
evaluations [2]
6454/19
6446/13 6448/10
6424/20 6446/7
dozens [1] 6424/9 6450/15
document [25]
6473/8 6473/10
DR [1] 6464/8
employees [1]
evaluator [2]
6406/2 6406/5
6468/11
6410/15 6410/17
expensive [12]
Dr. [2] 6468/21
6409/21 6417/17
6473/20
employs [1]
even [11] 6400/23 6431/15 6431/16
6420/15 6422/7
6431/22 6447/5
6453/16
6402/23 6408/12
Dr. Nayak [2]
6432/21 6435/7
6447/8 6447/12
6468/21 6473/20
6417/11 6420/14
enable [1]
6438/21 6439/5
6447/14 6452/7
6471/10
6421/10 6426/14
drew [1] 6471/21
6439/9 6440/3
6452/16 6452/18
6438/23 6439/19
drilling [1]
encode [2]
6441/16 6442/20
6452/24 6459/7
6466/20
6447/21 6459/9
6441/12 6448/18
6445/9 6454/12
experience [12]
due [1] 6462/4
encrypt [1]
evening [3]
6454/13 6455/1
6396/22 6411/15
6473/23 6475/14
during [1] 6468/5 6470/4
6455/4 6455/5
6428/23 6429/6
6478/19
DX108 [2] 6406/5 end [9] 6401/2
6456/24 6456/24
6441/3 6459/3
6409/2
6406/19 6438/8
events [3]
6458/3 6472/5
6464/18 6464/19
6438/8 6471/3
6432/23 6449/2
DX134 [1] 6439/6
6474/20
6464/21 6467/14
6457/19
DXD17 [1] 6403/16 6473/25 6474/10
documents [32]
6470/25 6471/4
6475/23 6475/25
DXD17-4 [1]
everybody [1]
6397/10 6399/16
6403/16
6395/2
experiences [1]
end-to-end [1]
6399/20 6399/23
6467/11
6438/8
DXD17.002 [1]
evidence [12]
6400/2 6400/9
6399/12
6394/11 6394/12
experiment [13]
ending [1]
6400/23 6404/7
6457/10
6394/13 6394/14
6410/4 6410/5
DXD17.003 [1]
6404/24 6404/25
6394/15 6394/16
6410/10 6410/12
6423/9
ends [1] 6464/22
6405/4 6405/13
6411/10 6411/12
energy [4] 6452/2 6435/18 6451/24
DXD1705 [1]
6405/13 6406/11
6452/10 6473/8
6455/9 6458/1
6412/1 6424/17
6402/4
6406/24 6406/25
6473/10
6462/20 6465/12
6424/24 6424/24
6407/20 6408/3
E
6424/25 6427/25
engine [7]
evidentiary [1]
6422/12 6422/13
e-mail [6]
6401/12 6408/20
6474/1
6428/5
6422/14 6428/11
6462/23 6463/12
6419/3 6419/6
exact [1] 6434/8 experimental [2]
6431/12 6445/20
6465/7 6465/17
6435/4 6459/20
6426/6 6426/17
exactly [8]
6445/20 6450/22
6469/3 6477/9
6477/19
6407/6 6434/10
experimentation
6451/2 6451/4
earlier [6]
6438/16 6438/21
engineer [2]
[3] 6409/19
6469/1 6472/4
6401/22 6406/22
6424/23 6425/18
6444/16 6450/16
6409/20 6428/4
6472/6 6472/25
6418/16 6430/17
6461/22 6466/17
engineering [2]
experimenting [1]
DOJ [2] 6392/13
6448/17 6475/4
6459/11 6462/11
6424/4
exam [2] 6423/2
6476/8
early [2] 6474/10 engineers [1]
6432/18
experiments [13]
dollar [1]
6475/21
6397/17
6409/8 6409/12
examination [5]
6446/20
easier [1]
6394/4 6394/5
6409/22 6409/23
enormous [1]
dominant [11]
6432/20
6453/5
6395/14 6454/8
6411/16 6424/25
6415/3 6415/9
easy [2] 6427/15 enough [13]
6468/19
6425/2 6426/8
6415/10 6415/18
6428/4
6397/21 6398/3
6427/12 6427/13
example [15]
6415/22 6415/25
eaten [1] 6465/1
6398/7 6398/9
6406/22 6411/25
6427/14 6428/1
6417/20 6417/20
edit [1] 6453/25
6403/20 6406/24
6413/10 6414/7
6441/18
6418/3 6418/4
edition [1]
6406/25 6416/24
6420/13 6420/13
expert [2] 6396/7
6418/11
6443/7
6447/20 6449/13
6420/16 6420/20
6429/8
done [13] 6406/22
educational [1]
6450/2 6457/7
6421/4 6427/24
experts [1]
6407/4 6427/7
6413/25
6474/7
6449/22 6460/15
6464/20
6437/16 6458/19
effect [1]
enrich [1] 6459/3 6467/7 6477/17
explained [1]
6466/11 6466/16
6476/13
6406/8
entire [2] 6426/8 6477/22
6466/25 6467/4
effective [2]
6441/24
examples [1]
explains [1]
6467/6 6468/6
6443/22 6444/24
6477/18
6437/24
entirely [1]
6469/25 6477/14
efficiencies [1]
6437/20
excerpt [2]
explicit [1]
down [20] 6397/13
6459/25
6454/12 6455/7
6463/18
entitled [1]

D

explicitly - heading

6485

6467/18
6475/10
6461/1 6466/11
features [13]
6401/22 6401/23
6473/23 6474/14
functions [2]
fit [1] 6404/4
explicitly [1]
6438/20 6438/24
6402/1 6403/5
Fl [1] 6393/11
Goodrich [1]
6450/21
6408/9 6408/10
6393/11
Fundamentally [1]
flagged [1]
exposure [1]
6469/9
6408/12 6408/23
6474/20
GOOGLE [91]
6449/25
6469/14 6469/19
Floor [1] 6393/4 further [6]
Google's [11]
extent [5]
6415/19 6439/5
6470/11 6477/16
6396/18 6397/9
flop [1] 6417/9
6395/24 6413/12
6478/10
6428/8 6434/11
focus [1] 6464/18 6441/16 6445/9
6433/25 6448/11
6468/13 6473/19
6446/1 6446/2
fed [1] 6428/11
focused [1]
6477/14
6464/17
6451/21 6455/8
feedback [2]
extra [1] 6460/7
G
6439/23 6440/1
6457/14 6468/10
focusing [2]
extract [2]
gains [1] 6443/17 6478/1
6414/20 6457/7
feedforward [1]
6408/3 6439/3
gather [1]
6447/13
folder [1]
Gotcha [1] 6428/6
extracting [1]
6416/25
6423/10
feel [1] 6454/13
grasp [1] 6441/4
6438/17
gathered [1]
feels [1] 6461/21 followed [1]
great [3] 6471/4
6434/21
6421/13
6475/12 6476/5
few [6] 6404/12
F
gave [4] 6409/3
6408/4
6426/13
6458/12
Folly
[8]
greater
[1]
fact [7] 6397/20
6439/8 6454/11
6441/3
6451/4
6458/13
6461/10
6436/4
6415/14 6415/15
6476/1
6451/6
6463/15 6463/18
green [3] 6403/17
6448/4 6467/22
gears [1] 6453/21 6403/21 6404/6
6405/13
6468/22
6468/22
fewer
[2]
6470/10 6473/9
general [12]
6427/2
6469/6
group [2] 6417/10
factor [11]
6419/2 6419/6
6443/18
6469/4
field
[1]
football
[3]
6403/19 6403/19
6424/15 6429/13
6392/17
6412/9
6412/11
Fifth
[1]
groups
[1] 6425/5
6404/9 6404/17
6435/4 6444/22
6398/4
6420/13
figure
[9]
growth
[1]
6404/18 6407/22
6444/24 6459/20
6404/14
6408/22
6441/18
footnotes
[1]
6432/25 6459/8
6470/18 6475/24
6411/13 6411/20
6457/8
guess [4] 6396/16
6461/2 6472/12
6477/6 6477/7
6427/1
6438/25
6416/14 6429/18
For
Plaintiffs
[1]
6477/2
generalize [3]
6470/12 6470/14
6392/21
6461/6
factored [1]
6416/17 6439/1
figured
[1]
foregoing
[1]
guesstimate
[1]
6469/15
6439/3
6471/22
6479/4
6447/19
factors [16]
gets [8] 6401/3
figures [1]
forever [1]
guy [1] 6440/12
6403/20 6405/7
6407/14 6407/17
6460/18
6396/2
6446/14 6459/1
H
6407/19 6408/8
figuring [3]
Forever's [2]
6459/22 6460/14
6408/9 6408/14
half [1] 6472/17
6398/13 6400/3
6396/4 6396/5
6461/7 6469/11
6464/15
hand [1] 6454/14
6405/4
6438/24
form
[2]
6470/5 6470/16
given [7] 6414/17 handed [2] 6414/2
6467/25
6443/6
filed
[1]
6472/9 6476/18
6414/3
fill [2] 6398/2
forms [1] 6430/15 6424/16 6434/18
6476/19 6476/22
6442/3 6454/12
hang [1] 6428/22
6398/5
6422/16
forth
[7]
6477/5 6477/6
6471/7 6476/21
hanging [1]
6430/23 6427/20 6445/15
facts [1] 6445/18 final [2]
gives [4] 6400/20 6429/6
6431/19
6448/7
6464/19
fair [13] 6396/23
6408/5 6443/16
happen [1]
6469/20 6473/1
finally [3]
6397/21 6397/23
6445/21
6470/15
6408/25
6467/17
forward
[2]
6398/3 6398/4
giving [2]
happened [1]
6446/5
6475/4
6473/6
6398/7 6398/9
6461/22
found [2] 6457/19 6408/22 6455/10
financial [1]
6403/20 6407/21
glad [1] 6454/7
happening [1]
6461/12
6478/6
6409/18 6416/19
find [5] 6403/13 four [2] 6454/19 global [1] 6434/1 6450/16
6416/24 6430/4
glue [12] 6403/3 happens [3]
6456/3
6420/18 6429/9
fairly [1]
6403/4 6403/10
6400/11 6404/5
6467/6
6467/15
fraction
[3]
6460/22
6403/20 6403/22
6463/24
6418/11
6449/22
finding
[1]
falls [1] 6427/23
6403/25 6405/3
hard [7] 6438/9
6449/24
6459/8
familiar [3]
6408/8 6408/8
6444/18 6452/21
frequency [2]
findings [1]
6413/16 6435/6
6408/13 6408/14
6464/25 6470/15
6417/21
6418/14
6458/5
6467/22
6408/22
6472/19 6473/2
6432/3
frequently
[1]
fine
[3]
family [1] 6443/7
goal [2] 6458/15 hard-pressed [1]
6415/19
6448/24
6474/11
fan [2] 6412/9
6458/18
6444/18
fresh [8] 6432/8
fine-tuned [2]
6412/11
goals [3] 6458/18 harder [1]
6449/2 6449/9
6432/3 6448/24
farther [4]
6463/18 6464/4
6447/16
6449/13 6449/18
finish [3]
6420/20 6443/14
goes [6] 6399/13 hardware [2]
6449/25
6450/8
6460/10
6474/8
6444/21 6453/4
6459/10 6459/25
6459/21 6460/3
6450/17
6475/21
fashion [1]
6464/16 6464/23
harm [2] 6477/3
6477/24
fresher
[2]
firm
[1]
6475/17
6465/20
6478/17
6450/6 6450/10
fast [1] 6456/25 firm's [1]
Gomes [2] 6465/14 hate [1] 6440/11
6477/23
freshest
[1]
faster [7]
6465/14
hazard [1]
firms [1] 6477/25 6449/12
6456/13 6458/7
6396/16
good [15] 6395/7
Friends
[2]
first
[11]
6458/10 6461/11
6395/16 6398/14
head [1] 6463/18
6469/5
6469/8
6419/19
6420/16
6462/4 6463/5
heading [12]
6422/10 6422/11
front [2] 6410/14 6406/20 6421/7
6470/2
6426/12 6427/21
6410/2 6415/3
6469/25
6422/13 6436/1
6476/20
favor [2]
6445/12 6453/22
6415/24 6439/19
6443/6
6456/19
function
[3]
6476/22
6458/23 6458/24
6440/23 6443/2
6406/9 6438/8
6463/11 6469/4

E

heading... - Justice

6486

6394/16 6403/15
6398/15 6401/20
6419/2 6419/6
6468/18 6474/4
6404/7 6424/20
6405/20 6405/23
6419/8 6470/2
6474/13 6474/14
heading... [6]
6435/18 6444/11
6410/18 6412/21
6470/25 6472/5
6475/19 6476/2
6455/16 6456/13
6451/24 6455/9
6412/22 6412/23
6472/7 6472/11
6476/8 6476/10
6457/4 6461/9
6458/1 6458/25
6413/1 6419/21
6472/16 6472/20
6478/20
6462/2 6465/16
6459/1 6459/23
6419/23 6422/20
6472/22 6473/1
HONORABLE [1]
heads [1] 6475/5
6461/7 6462/20
6427/19 6453/6
6473/3
6392/10
heard [6] 6397/4
6465/12 6466/20
6467/6 6467/15
HOOK [3] 6393/23 imprecise [1]
6397/6 6397/8
6470/5
6472/9 6477/1
6407/18
6479/3 6479/10
6468/22 6475/15
6477/8 6477/15
inverted [1]
hope [4] 6406/25 impress [1]
6477/25
6406/14
6441/1
6429/18 6471/15
informed [1]
heart [1] 6464/16
6446/4
6474/3
invest [1] 6427/5
improve [5]
heavily [2]
6398/8 6459/23
invested [3]
initial [2]
Hopefully [1]
6460/6 6460/8
6462/11 6462/15
6464/19 6464/21
6399/20 6431/12
6475/16
heavy [2] 6459/6
6464/13
6466/21
initially [1]
hot [1] 6460/11
6469/18
6432/13
investment [7]
hour [1] 6453/24 improvement [1]
6398/20
held [1]
6441/20
input [1] 6476/17 6397/25 6398/1
hours [1] 6441/2
help [6] 6403/13
6398/4 6459/11
inputs [4]
https [1] 6470/4 improvements [4]
6403/18 6403/20
6459/21 6460/3
6408/16 6477/16
HUANG [1] 6393/10 6441/19 6464/5
6404/3 6427/9
6464/12
6464/15 6465/2
6478/14 6478/15
Hubbard [1]
6474/6
6476/18
involved [5]
improving [2]
insights [2]
helped [1] 6395/4
6400/5 6409/13
6438/17 6439/3
human [15] 6423/6 6425/18 6470/12
helpful [2]
6409/15 6409/22
6423/20 6423/24
instance [2]
in-depth [1]
6399/11 6422/17
6459/19
6457/16 6464/11
6413/21
6423/25 6424/13
helpfulness [1]
6425/13 6426/21
IR [4] 6401/17
instead [1]
included [1]
6441/22
6401/20 6402/2
6460/17
6402/9
6426/23 6427/19
helps [4] 6403/16
6472/9
6428/25 6429/2
instituted [1]
includes [2]
6404/2 6404/7
6471/2
6403/4 6416/4
6432/6 6441/9
is that [1]
6404/9
6446/16
6446/7 6448/24
instituting [2]
including [2]
here's [2] 6425/7
6457/18 6458/13
IS-scored [1]
humans [1] 6441/8 6477/16 6477/24
6463/15
6428/11
intend [1]
incomparable [1]
hundred [5]
Hey [1] 6465/19
6429/15
6470/17
6399/17 6399/18
ISP [1] 6461/5
Hi [1] 6463/14
6407/9 6408/4
intent [8] 6413/7 issue [5] 6429/16
increase [1]
hierarchy [1]
6457/13 6462/8
6415/20 6415/21
6398/10
6472/4
6472/16
6475/9 6475/16
6415/23 6416/3
increased [1]
hundreds [3]
high [5] 6406/21
6417/6 6420/11
6398/16
6424/9 6431/22
issued [3]
6441/12 6477/23
6405/16 6415/16
6429/17
6453/16
incurring [1]
6478/10 6478/13
6456/3
6470/24
intents [6]
hypothetical [1]
high-level [3]
6434/16
issues [1]
indeed [1] 6456/9 6414/20 6415/3
6477/23 6478/10
6474/17
6415/6 6415/9
hypothetically [1] Indefinitely [1]
6478/13
6415/25 6417/11
6396/6
6434/17
item [1] 6474/18
higher [2]
items [2] 6436/22
index [26] 6397/9 interact [1]
6415/12 6418/10
I
6436/24
6422/15
6397/10 6397/18
historical [1]
idea [3] 6425/18
6397/19 6397/22
iterate [1]
interactive [1]
6460/16
6427/20 6449/4
6426/17
6469/20
6397/24 6397/25
historically [1]
identified [2]
6398/6 6398/8
interest [1]
6471/19
J
6395/24 6451/5
6418/5
6398/10 6398/17
history [9]
JavaScript [2]
identifies [1]
6398/24 6399/1
interested [2]
6467/17 6467/20
6469/21 6469/23
6451/4
6424/24 6429/7
6406/9 6406/11
6467/20 6467/23
JEFF [3] 6393/23
identifying [1]
6406/12 6406/12
interesting [2]
6467/23 6467/25
6479/3 6479/10
6477/8
6417/10 6445/13
6406/14 6406/20
6468/5 6468/7
JOHN [1] 6393/7
IL [1] 6392/20
6407/2 6407/14
interject [1]
6468/10
JONATHAN [1]
images [6] 6459/4 6445/20 6450/23
6433/15
holds [1] 6398/10
6393/2
6459/5 6459/6
6450/23 6469/13
interleaved [2]
home [3] 6416/14
6459/8 6464/21
JR [1] 6392/22
6411/17 6411/18
6472/25
6416/16 6419/14
6469/19
judge [2] 6392/11
internal [4]
indexes [1]
homework [2]
6473/2
immediately [1]
6477/9 6477/10
6477/19
6416/9 6416/15
6449/11
jump [3] 6434/5
6478/1 6478/4
indicate [2]
Honestly [1]
6442/15 6456/3
impact [1] 6410/7 6418/2 6418/3
interrupt [5]
6463/13
June [2] 6458/5
implement [1]
6406/6 6426/20
individual [2]
Honor [26] 6395/4 6425/21
6462/24
6427/9 6461/25
6427/13 6427/14
6414/4 6432/16
June 19th [1]
implying [1]
6472/15
individuals [2]
6435/13 6435/19
6462/24
6448/3
6460/24 6460/25
intersect [1]
6442/6 6442/15
June 2017 [1]
importance [1]
6407/2
industrial [2]
6453/21 6453/25
6458/5
6421/23
6416/8 6416/20
intersecting [1]
6454/3 6454/24
junk [2] 6398/2
important [19]
6406/17
inferred [1]
6454/25 6455/11
6405/2 6410/24
6444/19
into [22] 6394/11 6398/6
6457/23 6462/17
6410/25 6411/2
Justice [3]
6394/12 6394/13
information [22]
6465/9 6468/13
6392/14 6392/16
6411/5 6411/6
6394/14 6394/15
6398/10 6398/13

H

Justice... - may

6487

6474/2
6422/4 6422/9
latency [57]
M
6446/14 6446/19
6471/12 6471/14
led [1] 6409/14
Justice... [1]
machine [19]
6452/20 6455/21
6471/18
left [2] 6402/13
6392/19
6397/3 6397/4
6456/17
6455/22 6457/8
locations [1]
6397/7 6402/10
6457/14 6458/14
6419/12
Lehman [1]
K
6404/10 6404/25
6476/14
6458/16 6458/18
logs [2] 6396/8
KAUFMANN [1]
6405/4 6407/10
6458/22 6458/23
6448/5
length [1]
6393/3
6427/17 6430/7
6430/14
6458/24 6458/25
long [14] 6395/21
keep [4] 6395/25
6430/11 6430/12
6459/7 6459/10
6396/4 6396/5
less [6] 6420/9
6398/5 6446/19
6430/15 6430/16
6459/21 6460/1
6427/23 6437/15
6396/8 6402/17
6457/10
6430/18 6443/11
6460/4 6460/7
6449/9 6460/24
6406/19 6430/10
keeping [1]
6449/7 6453/17
6460/25 6462/2
6470/6
6436/3 6449/11
6471/9
6469/14
6462/4 6462/8
6461/20 6461/23
level [6] 6402/9
KENNETH [3]
machines [4]
6462/12 6462/15
6428/8 6438/8
6461/24 6463/17
6392/13 6393/8
6460/7 6460/21
6463/15
6463/19
6477/23
6478/10
6478/11
6395/16
6460/21 6460/23
6463/19 6464/4
6478/13
long-tail [1]
kept [2] 6435/25
magnitude [1]
6464/15 6464/16
6436/3
likely [4]
6449/8
6437/3
6464/20
6464/23
6406/20
6416/13
longer
[2]
key [2] 6465/20
mail [6] 6462/23
6465/1 6465/4
6421/8 6427/23
6453/23 6456/7
6466/1
6463/12 6465/7
6467/3
6467/8
6463/12
longest
[1]
Lim
[3]
kick [1] 6412/12
6465/17 6469/3
6467/10 6467/11
6430/6
6463/12 6469/4
kind [10] 6405/5
6477/9
6468/21 6469/5
limit [1] 6437/25 look [13] 6404/11
6415/9 6417/2
main [2] 6419/24
6469/8 6469/9
6408/2 6409/21
limitations [2]
6422/19 6444/19
6431/1
6469/11
6469/15
6410/2 6424/13
6440/6
6440/11
6457/17 6459/10
Maine [1] 6393/9
6469/16 6469/16
6425/6 6425/10
limits [1]
6470/23 6470/23
mainly [1] 6462/4
6469/22
6470/6
6434/1 6446/10
6448/21
6471/10
maintain [3]
6470/13 6470/19
6447/11 6454/13
line [5] 6395/9
kinds [4] 6408/1
6395/20 6464/4
6470/22 6470/23
6456/17 6464/13
6476/16 6476/16
6416/17 6445/17
6464/15
6470/23 6471/4
6476/17 6476/17
looked [6] 6406/2
6448/5
makes [1] 6438/9
6471/7
6409/10 6438/25
line-by-line [2]
knowledge [17]
making [3] 6422/5
6403/6
6476/16
6476/17
6452/16 6467/5
later
[2]
6428/24 6443/24
6470/19 6477/1
6404/1
6469/2
links [1] 6444/5
6444/6 6444/10
many [26] 6399/4
latest [2] 6443/7 list [4] 6406/16 looking [22]
6444/18 6445/3
6399/7 6404/24
6463/15
6406/17 6406/17
6405/3 6405/5
6445/7 6445/11
6410/25 6411/2
6476/11
6406/15 6413/13
launch [2]
6445/13 6445/16
6416/7 6416/7
6409/15 6470/24
lists [3] 6406/19 6413/13 6415/8
6445/19 6445/21
6416/20 6416/22
6407/2 6472/6
6419/12 6419/17
launched [2]
6445/22 6447/21
6416/22 6424/7
6448/17 6470/22
6419/21 6420/15
literally [1]
6448/1 6448/8
6426/1 6426/19
6433/17
6424/25 6425/13
launches [1]
6471/17
6427/2 6427/21
6446/3
6428/24 6428/25
little [10]
knows [2] 6417/2
6434/17 6452/11
6418/22 6419/16
6429/10 6429/13
launching [2]
6429/8
6459/1 6459/1
6433/25 6434/1
6419/22 6420/5
6432/21 6438/17
6459/16 6469/11
6427/18 6428/3
6438/19 6450/22
Law [1] 6393/3
L
6469/19 6469/19
6443/14 6470/4
6458/6 6466/24
LAX [1] 6461/12
lab [2] 6462/3
6470/5 6472/1
6473/2 6474/10
layer [1] 6461/1
looks [6] 6421/7
6462/4
6472/8
6431/11 6442/21
leads [1] 6436/19 live [6] 6411/9
lack [1] 6462/5
map [5] 6419/12
6447/10 6467/2
learn [2] 6447/18 6411/12 6427/25
language [15]
6419/15 6419/16
6447/20
6428/1
6446/7
6470/2
6436/12 6436/17
6419/19 6420/1
6446/8
learned [3]
loss [3] 6419/16
6436/19 6443/18
match [2] 6399/7
6444/13 6444/16
6419/20 6466/20
LLC [1] 6392/6
6443/23 6444/6
6406/11
6444/17
6392/22
LLP
[2]
lot
[16] 6397/4
6444/8 6444/16
matches [1]
6393/8
6404/7 6405/3
learning [32]
6444/24 6445/14
6401/2
6397/3 6397/5
loaded [2] 6460/6 6405/13 6426/10
6447/19 6448/19
matching [2]
6397/7 6399/24
6460/8
6427/15 6430/6
6449/7 6453/4
6399/1 6399/4
6400/3
6400/5
6430/7 6430/9
loading
[3]
6453/6
math [1] 6417/15
6400/17 6402/10
6456/23 6456/24
6439/1 6445/13
languages [1]
matter [3] 6438/7
6404/10
6404/25
6456/25
6445/16 6452/4
6431/25
6471/12 6479/5
local [3] 6413/13 6464/16 6470/9
large [5] 6415/10 6405/5 6407/11
mattered [1]
6408/5 6430/7
6422/14 6422/18
6472/3
6439/20 6441/22
6471/18
6430/11
6430/12
6412/4
locale
[4]
lots
[3] 6407/20
6445/14 6453/18
matters [3]
6412/20 6412/22
6459/4 6460/20
larger [2] 6420/1 6430/13 6430/14
6422/4 6471/14
6430/15
6430/16
6412/24
low
[3] 6457/7
6452/11
6477/7
6430/19 6431/1
6469/5 6469/8
locales [2]
LaSalle [1]
may [20] 6395/11
6431/8 6437/20
6420/11 6432/1
lower [6] 6418/12
6392/19
6395/25 6404/11
6438/3
6438/8
6458/22 6458/23
localization
[2]
last [3] 6442/13
6421/20 6424/6
6438/10 6443/5
6408/1 6472/13
6458/24 6458/25
6474/7 6476/11
6428/25 6429/9
6443/11 6448/12
6460/12
localized [1]
latencies [1]
6431/12 6435/8
6453/17 6469/14
6421/18
6452/22
6441/1 6441/2
least [2] 6456/17 location [5]

J

may... - network

6488

6450/5 6450/6
6405/23
6456/18 6457/20
6403/4 6475/7
6450/11 6450/15
6458/6 6461/5
6475/10 6477/12
memorizes [2]
may... [9]
6450/18 6451/4
6405/15 6405/20
6471/12 6471/19
named [1] 6420/18
6441/20 6450/8
6452/15 6452/18
mentioned [3]
mobile-dominant
names [2] 6477/9
6453/9 6455/3
6456/4 6459/4
6412/15 6472/23
6477/10
[7] 6415/9
6455/4 6460/5
6459/5 6459/6
6474/16
6415/10 6415/18
narrow [1]
6460/5 6475/9
6459/7 6460/18
6415/22 6417/20
6460/22
methods [1]
6476/5
6461/21 6462/14
6430/16
6418/4 6418/11
nature [1]
maybe [15]
6464/21 6464/22
6476/21
metric [1] 6423/6 mode [1] 6411/16
6396/25 6397/11
metrics [1]
model [15] 6409/9 6464/22 6464/23
navboost [54]
6404/22 6408/21
6471/6 6478/15
6441/1
6419/13 6420/2
6402/15 6402/17
6425/2 6425/23
6433/23 6433/25
6402/22 6402/25
morning [4]
Microsoft [7]
6426/13 6429/5
6430/14 6432/18
6396/11 6396/12
6434/1 6437/25
6403/4 6403/7
6436/24 6437/16
6475/15 6478/22
6397/2 6397/4
6447/9 6452/11
6403/16 6403/18
6454/22 6464/21
6397/6 6474/18
6452/15 6453/18
most [12] 6396/20 6403/20 6403/22
6464/21 6464/22
6400/2 6400/11
6474/23
6473/9 6473/12
6404/5 6404/6
6472/4
6417/10 6418/7
6473/13 6473/17
6404/13 6404/15
middle [6]
MEAGAN [1]
6443/15 6443/21
6426/12 6429/5
6404/17 6405/3
models [16]
6392/16
6443/22 6444/2
6428/12 6431/1
6439/23 6451/1
6405/7 6405/15
mean [35] 6398/12
6447/4 6469/3
6431/8 6445/14
6472/5 6472/7
6405/20 6405/23
6401/1 6402/18
6447/12 6448/6
6473/1
6406/2 6406/9
might [18]
6403/18 6410/25
6396/16 6396/24
6452/2 6452/10
6407/17 6407/19
move [1] 6412/10
6415/6 6416/24
6398/2 6402/23
6452/16 6452/20
6407/21 6409/9
Mr. [14] 6395/3
6419/8 6421/20
6407/20 6418/22
6452/25 6453/5
6465/14 6468/16
6409/18 6411/4
6422/21 6425/5
6420/4 6424/16
6453/17 6459/24
6474/2 6474/12
6412/19 6412/19
6426/20 6430/12
6429/4 6429/7
6473/15 6473/17
6474/16 6474/19
6412/20 6412/22
6430/20 6433/9
6429/9 6433/23
6474/20 6475/20
6413/1 6413/4
modest [2]
6435/8 6436/23
6438/18 6441/13
6444/25 6445/2
6476/1 6476/14
6413/12 6413/15
6437/14 6440/18
6441/15 6453/22
6476/14 6476/15
6420/21 6420/22
modifications [1]
6441/10 6444/9
6466/24 6475/25
6475/22
6478/3
6421/3 6421/4
6444/13 6445/11
6422/10 6422/16
milliseconds [6]
modules [2]
Mr. Cavanaugh [4]
6447/8 6449/11
6458/10 6461/14
6396/14 6428/12
6468/16 6474/2
6432/14 6438/22
6452/18 6452/25
6463/5 6463/9
6438/23 6440/13
moment [3] 6406/6 6474/16 6475/20
6461/20 6461/25
6463/19 6463/24
6422/2 6451/11
6454/7 6471/22
Mr. Cavanaugh's
6463/19 6464/11
6471/23 6472/1
minimize [2]
money [2] 6398/11 [1] 6474/19
6470/8 6472/3
6420/8 6472/21
6427/5
6472/14 6472/16
Mr. Dintzer [1]
6472/19 6472/24
6472/20 6473/3
mining [6]
month [14] 6434/7 6395/3
meaning [1]
6438/11 6438/14
6434/7 6434/8
Mr. Gomes [1]
NAYAK [5] 6394/3
6412/6
6438/17 6438/20
6434/11 6434/14
6465/14
6395/14 6468/19
meaningfully [1]
6438/25 6439/3
6434/15 6434/18
6468/21 6473/20
Mr. Lehman [1]
6415/12
6434/18 6434/19
6476/14
minute [1]
nearly [1]
meanings [1]
6476/13
6434/21 6449/5
6447/20
Mr. Roszak [2]
6421/18
6449/5 6449/6
6476/15 6478/3
Nebraska [1]
minutes [2]
means [8] 6403/19
6449/12
6392/22
6441/4 6454/1
Mr. Schmidtlein
6404/17 6413/4
[1] 6474/12
necessarily [4]
misunderstood [2] months [12]
6415/16 6419/4
6405/21 6405/24
6398/2 6412/16
6419/1 6425/3
Mr. Sommer [1]
6433/17 6436/9
6410/21 6410/21
6476/1
6430/21 6464/20
mixture [1]
6441/23
6432/11 6432/17
6417/20
Mr. Vallez [1]
need [24] 6398/4
meant [4] 6420/17
6433/16 6433/18
6474/20
6404/12 6404/24
ML [1] 6459/24
6438/16 6438/21
6434/6 6434/24
6406/10 6414/17
Mr. Yoo [1]
mobile [44]
6468/1
6449/7 6449/10
6476/14
6422/6 6427/23
6413/1 6413/7
measure [3]
6414/18 6414/25
more [57] 6397/3 much [12] 6395/20 6430/5 6436/3
6428/8 6428/20
6397/6 6397/25
6404/1 6405/5
6439/1 6445/17
6415/3 6415/9
6434/25
6398/1 6398/11
6420/1 6434/21
6445/18 6445/23
6415/10 6415/10
measured [2]
6398/13 6404/12
6443/24 6453/23
6447/14 6449/23
6415/11 6415/15
6434/14 6450/21
6404/24 6405/5
6469/20 6473/17
6452/20 6452/21
6415/15 6415/18
measurement [2]
6415/15 6415/18
6473/20 6473/22
6452/22 6454/13
6415/19 6415/20
6434/8 6434/20
6416/7 6416/12
6478/21
6455/3 6455/4
6415/22 6417/3
measuring [1]
6420/14 6428/2
6459/17 6460/1
6417/6 6417/11
multiple [1]
6450/19
6429/10 6429/19
6434/16
6475/1
6417/20 6418/4
mechanism [3]
6429/21 6431/16
6418/5 6418/7
MUM [10] 6451/7
needed [1]
6406/15 6406/18
6434/12 6434/13
6451/16 6452/11
6447/21
6418/8 6418/10
6407/1
6437/5 6437/17
6452/15 6453/1
6418/11 6419/5
needs [6] 6432/22
meet [3] 6395/17
6437/17 6437/17
6453/5 6473/8
6444/5 6447/11
6419/10 6420/2
6395/18 6464/3
6441/19 6443/17
6473/9 6473/12
6449/1 6470/15
6420/10 6420/17
MEHTA [1] 6392/10
6445/4 6446/23
6473/13
6474/24
6420/21 6420/22
memorization [2]
6447/5 6447/12
6420/25 6421/4
network [5]
6440/13 6440/18
N
6447/14 6447/15
6444/13 6461/4
6421/11 6456/16
memorized [1]
name [5] 6395/16
6449/7 6449/9
6461/6 6461/7
6456/16 6456/17

M

network... - people

6489

6406/24 6408/12
6476/13
6451/18 6452/1
numbered [1]
6455/13
6469/25
6455/12 6455/13
ordering [5]
network... [1]
6411/18 6411/19
6456/10 6457/3
numbers [8]
one [62] 6396/22
6469/18
6418/1 6418/3
6398/12 6398/20
6425/24 6426/13
6459/3 6459/5
networks [1]
6423/23 6435/25
6399/13 6400/16
6472/20
6461/8 6463/1
6447/13
6436/1 6463/21
6401/14 6402/4
6463/11 6464/23
organic [1]
new [13] 6392/24
6464/1 6477/19
6402/6 6402/15
6444/5
6469/3 6469/10
6393/12 6421/6
6403/3 6404/12
6469/18 6469/20
NW [3] 6392/14
organization [1]
6421/7 6421/19
6392/17 6393/24
6408/13 6408/22
6454/20
6469/24 6472/11
6422/6 6426/14
6408/24 6410/7
6473/1
NY [2] 6392/24
organized [1]
6426/15 6427/18
6393/12
6410/24 6411/14
6425/5
page 8075 [1]
6432/10 6432/23
6411/18 6417/16
6446/24
otherwise [3]
6453/4 6475/22
O
6420/24 6422/17
6432/23 6459/9
page X1723 [1]
newsletter [5]
o'clock [2]
6423/13 6426/23
6477/11
6420/15
6413/17 6413/20
6442/13 6476/2
6426/24 6428/19
out [15] 6398/4
pages [13] 6399/1
6414/8 6414/15
object [1] 6455/3 6430/4 6431/18
6398/13 6400/4
6406/13 6406/20
6442/21
objection [7]
6438/23 6439/14
6404/14 6405/4
6414/12 6454/12
newsletters [1]
6435/15 6442/11
6439/16 6441/7
6408/23 6411/13
6454/14 6455/1
6413/21
6442/17 6451/22
6442/8 6445/12
6411/20 6427/1
6456/16 6456/17
next [22] 6407/6
6457/24 6462/18
6446/23 6448/13
6438/25 6447/11
6456/18 6459/4
6407/9 6411/8
6465/10
6448/13 6450/4
6456/1 6460/18
6459/6 6477/18
6415/2 6415/24
oblong [1]
6454/19 6455/10
6470/12 6470/14
paired [1]
6417/9 6437/1
6412/10
6456/3 6457/8
6443/23
output [2]
6437/19 6438/10
observed [1]
6458/9 6459/16
6424/13 6425/6
PANDURANG [3]
6443/15 6443/16
6461/10
6460/9 6460/21
6394/3 6395/14
outright [1]
6443/21 6445/3
obsolete [1]
6460/22 6461/11
6468/19
6461/21
6447/17 6454/1
6453/10
6461/17 6461/19
paragraph [7]
outside [2]
6456/10 6457/3
obviously [1]
6462/8 6465/25
6443/15 6443/21
6395/8 6421/8
6462/2 6464/8
6465/21
6469/1 6470/12
6443/22 6444/3
outweigh [1]
6465/20 6475/6
occur [5] 6415/14 6472/2 6473/3
6444/21 6447/4
6476/24
6475/15
6415/18 6417/21
6474/5 6474/18
over [14] 6398/21 6447/17
Nice [2] 6395/17
6418/7 6418/8
6474/20 6476/11
6417/9 6428/19
paragraphs [1]
6395/18
occurred [1]
6476/20 6477/8
6453/4
6433/18 6433/21
Nicholas [3]
6433/21
6477/23
6437/15 6437/20
part [18] 6399/14
6463/12 6463/12
occurrence [2]
6400/3 6401/6
6438/7 6452/11
ones [11] 6400/4
6469/3
6415/11 6418/12
6404/14 6411/20
6412/3 6415/18
6461/5 6461/5
6442/13
night [1]
occurs [1]
6418/3 6418/4
6421/24 6422/25
6465/20 6471/22
Nine [1] 6464/2
6406/13
6419/3 6419/4
6431/8 6431/18
6472/4
none [3] 6405/10
October [1]
6426/22 6428/2
6436/16 6436/17
overall [5]
6429/11 6453/17
6392/5
6443/11 6472/23
6444/14 6445/3
6396/24 6398/16
normal [1]
of addressing [1] online [1]
6445/7 6445/25
6419/15 6466/19
6442/22
6459/14
6413/14
6446/2 6454/21
6472/3
Norton [8]
off [21] 6395/19 only [20] 6401/14 overlap [1]
6461/9
6420/16 6420/17
6402/13 6402/20
6403/19 6404/17
6426/11
particular [8]
6420/18 6421/5
6409/17 6409/19
6407/4 6407/22
6411/23 6413/22
overlapped [1]
6421/9 6421/10
6417/19 6434/5
6408/13 6411/18
6418/24 6422/8
6419/4
6421/20 6422/7
6435/3 6435/25
6416/18 6419/19
oversimplification 6424/8 6429/12
notes [2] 6435/13
6448/14 6448/21
6422/10 6429/18
6478/14 6478/15
[1] 6444/10
6456/1
6467/20 6467/23
6432/5 6433/24
particularly [1]
Overview [1]
notice [1]
6468/1 6468/5
6441/3 6443/16
6478/11
6410/2
6475/14
6468/7 6468/10
6460/21 6460/21
parties [1]
own [3] 6439/20
notify [1] 6476/6
6470/19 6471/1
6461/13 6469/18
6476/17
6461/4 6461/7
noting [1]
6472/23 6472/24
6471/23
pass [1] 6468/13
6449/21
offer [8] 6435/13 onto [1] 6469/21 P
past [12] 6398/17
number [27]
6435/14 6442/6
p.m [4] 6392/6
6398/18 6398/21
open [5] 6395/6
6397/11 6397/13
6451/20 6454/24
6454/5 6454/6
6398/23 6405/15
6422/19 6474/22
6397/14 6414/11
6457/22 6462/16
6478/23
6405/16 6405/21
6475/2 6477/25
6414/12 6417/19
6465/9
page [42] 6394/2
6406/22 6424/20
operate [1]
6418/9 6426/7
6394/10 6401/2
office [2] 6416/8 6404/24
6426/3 6467/4
6432/16 6433/16
6416/20
6401/12 6403/5
6470/21
operates [1]
6434/22 6435/2
6403/10 6406/21
Official [2]
6432/1
Patterson [1]
6436/4 6436/4
6393/23 6479/3
6407/25 6408/20
6392/22
opportunity [2]
6436/5 6437/2
6409/25 6414/11
old [3] 6402/25
6455/6 6476/12
Paul [2] 6475/11
6437/4 6437/6
6426/22 6440/12
6415/2 6415/24
6475/12
optimal [2]
6437/6 6454/25
6417/5 6417/9
older [5] 6450/6
6420/7 6420/9
paying [1]
6458/9 6463/20
6450/11 6450/14
6419/14 6420/15
6446/15
optimize [3]
6464/13 6465/25
6450/18 6450/20
6423/16 6439/11
6419/19 6419/20
peak [1] 6460/11
6471/21 6477/17
6440/3 6440/11
once [6] 6399/23
6470/14
peaks [1] 6460/7
6477/18
6404/13 6404/16
people [20]
order [2] 6465/21 6442/25 6446/24

N

people... - ranking

6465/20
plenty [3]
6460/12 6472/22
probably [7]
people... [20]
6474/9
6397/1 6399/19
6411/9 6412/10
6417/10 6444/9
plus [2] 6398/22
6416/12 6416/16
6469/20
6453/24 6465/21
6417/1 6418/5
point [8] 6395/20 6476/20
6420/11 6421/6
6419/20 6421/17
problem [5]
6421/7 6421/8
6422/5 6430/20
6447/16 6460/13
6425/6 6426/22
6438/10 6461/1
6460/14 6460/22
6427/15 6428/4
6467/16
6464/13
6441/18 6464/13
policies [1]
proceed [3]
6467/6 6467/15
6458/14
6395/3 6439/16
6468/4 6470/22
policy [3] 6468/7 6475/17
per [2] 6446/18
6468/9 6468/10
proceedings [2]
6449/6
6478/23 6479/5
position [1]
percent [7]
6437/15
process [10]
6417/15 6417/16
6400/6 6400/11
possible [6]
6418/18 6418/18
6396/8 6420/7
6427/3 6427/7
6456/20 6472/17
6428/4 6432/5
6431/15 6459/15
6472/17
6443/24 6448/9
6459/18 6471/6
percentage [2]
6471/9 6472/18
possibly [1]
6418/14 6448/20
6429/16
processes [1]
performance [2]
6458/14
post [4] 6451/14
6428/20 6441/1
6473/7 6475/13
produce [2]
perhaps [2]
6426/2 6470/7
6476/13
6472/5 6472/7
produced [1]
postings [4]
period [2]
6455/2
6406/17 6406/17
6397/14 6433/21
6407/2 6472/6
product [6]
personalizing [1]
6421/24 6422/25
potential [3]
6429/11
6464/3 6464/12
6453/5 6474/20
personally [1]
6477/23 6477/24
6477/2
6477/8
production [2]
potentially [2]
perspective [1]
6473/13 6473/18
6439/19 6478/8
6419/15
pound [2] 6428/22 professional [2]
phase [2] 6407/6
6416/8 6416/20
6429/6
6407/10
program [1]
powerful [2]
6419/24
phone [2]
6463/18
6426/16 6453/9
6421/11
programming [1]
practices [2]
phrase [1]
6477/17
6459/18 6471/3
6404/22
progress [1]
pre [1] 6439/20
picking [1]
6440/23
pre-training [1]
6413/12
6439/20
Project [1]
picks [1] 6410/17
6458/12
prediction [1]
picture [1]
6476/1
projects [3]
6428/22
6458/13 6477/9
prefer [2]
piece [1] 6429/6
6477/10
6419/18 6421/10
pieces [2] 6404/4
prominently [1]
preferences [1]
6408/20
6471/22
6447/22
pizza [4] 6412/14
proposals [2]
prepared [1]
6412/14 6412/15
6476/18 6476/19
6399/11
6412/17
propose [1]
present [3]
place [6] 6409/6
6475/21
6401/6 6422/15
6412/17 6422/10
6473/24
proposed [4]
6424/19 6453/22
6474/22 6475/2
presentation [3]
6467/15
6475/22 6477/21
6435/9 6435/10
places [1] 6467/5
6474/1
proprietary [4]
Plaintiff [1]
6396/19 6396/20
pressed [1]
6393/2
6477/14 6477/20
6444/18
plaintiffs [5]
pros [1] 6428/16
presumably [1]
6392/4 6392/13
6454/22
protections [1]
6392/21 6471/21
6437/25
previous [2]
6476/8
6449/20 6460/9
protocol [1]
Platform [1]
6470/1
previously [2]
6454/18
6476/14 6477/1
provide [3]
platforms [2]
6422/19 6425/14
primary [1]
6454/15 6454/19
6434/16
6428/8
play [1] 6458/25
provides [1]
principles [1]
please [3] 6406/5
6413/15
6396/24
6422/3 6451/12
providing [1]
priorities [1]

P

6490

6475/14
6466/5 6471/13
6471/18 6471/18
pub [6] 6420/16
6420/18 6421/5
query [36]
6421/5 6421/20
6398/25 6399/2
6422/7
6399/5 6401/2
public [3] 6477/1 6406/10 6406/11
6477/2 6477/11
6406/16 6407/3
6412/6 6417/1
publish [1]
6413/20
6424/1 6424/2
6424/3 6424/6
Publishing [2]
6420/17 6421/10
6424/7 6424/8
6425/8 6425/15
Pubs [1] 6421/9
6425/22 6425/22
pull [2] 6399/12
6404/7
6429/16 6431/9
6432/12 6438/14
pulled [1]
6419/24
6441/3 6448/22
6450/10 6450/11
push [3] 6459/3
6459/5 6475/23
6450/12 6450/13
6461/12 6461/19
put [9] 6395/20
6415/21 6416/25
6461/22 6465/25
6424/20 6424/20
6466/11 6473/14
6425/1 6425/2
question for [1]
6429/3 6432/17
6421/25
puts [2] 6401/8
quite [6] 6407/19
6410/14
6430/3 6433/17
6450/1 6470/25
putting [1]
6408/19
6471/22

Q

R

QBST [1] 6440/13
QPS [1] 6452/22
qualifies [1]
6423/25
quality [20]
6398/8 6398/20
6406/21 6413/16
6423/18 6423/24
6423/25 6428/9
6441/13 6449/17
6454/21 6464/17
6465/1 6467/3
6470/7 6470/12
6470/20 6470/25
6472/11 6478/1
quarter [1]
6414/8
queries [48]
6405/16 6405/21
6405/24 6415/3
6415/8 6415/10
6415/10 6415/23
6415/23 6415/25
6416/4 6416/7
6416/8 6416/9
6416/20 6416/22
6416/23 6416/25
6417/6 6417/12
6417/20 6418/4
6418/6 6418/7
6418/8 6418/9
6418/10 6418/11
6418/12 6418/14
6424/20 6425/8
6425/10 6431/25
6433/20 6434/12
6434/13 6434/18
6455/16 6455/20
6455/24 6456/2
6458/6 6466/1

raise [1] 6475/1
raised [3]
6457/13 6457/17
6474/18
raising [1]
6461/17
ran [1] 6409/8
random [2]
6409/22 6410/5
range [1] 6402/23
rank [7] 6403/13
6406/21 6407/8
6408/1 6444/5
6472/18 6472/19
RankBrain [16]
6431/2 6431/11
6431/11 6431/15
6431/20 6431/22
6431/25 6432/5
6432/8 6432/11
6432/22 6436/2
6436/23 6437/10
6443/6 6447/13
ranked [2] 6426/8
6426/10
RankEmbed [15]
6400/6 6400/13
6400/15 6400/16
6400/23 6431/6
6443/7 6448/13
6448/15 6448/17
6448/17 6448/21
6449/17 6449/21
6451/4
ranking [28]
6400/1 6400/19
6404/19 6407/4
6407/10 6424/4
6425/19 6427/18
6430/24 6431/2

ranking... - screen

6491

6411/25 6424/12
6405/21 6405/24
6426/13 6426/14
6418/9 6437/3
6424/17 6425/22
6455/5
6426/15 6428/24
relevance [2]
ranking... [18]
6427/15 6427/15
6429/1 6429/9
6443/17 6447/20
receiving [1]
6431/17 6433/7
6427/17 6427/24
6398/25
6429/11 6429/19
reliability [1]
6433/10 6436/16
6431/15 6431/19
6429/24 6429/25
6472/12
recently [1]
6436/19 6436/20
6431/22 6452/23
6471/6
6431/23 6441/8
reliant [1]
6436/23 6437/20
6460/11 6460/11
6458/7 6458/9
Recess [1] 6454/5 6453/18
6438/19 6438/20
6473/12 6473/14
6459/2 6461/11
recipe [1] 6450/8 rely [1] 6447/19
6438/24 6442/21
6473/17
6463/5 6469/10
recognize [5]
remember [6]
6443/6 6443/17
6437/4 6437/6
6469/13 6470/7
6404/22 6406/12
running [10]
6443/22 6445/7
6424/15 6446/13
6442/20 6458/3
6470/20 6471/24
6422/9 6457/13
6451/1 6464/17
6452/2 6452/15
6476/20
6472/12 6473/10
6457/16 6457/18
rankings [2]
6452/19 6452/21
6477/24
recollection [1]
remind [2]
6399/20 6423/4
6459/23 6469/13
6469/6
6402/22 6465/18
retrained [2]
rapid [2] 6427/19
6469/23 6473/13
6432/8 6449/1
recommended [1]
removing [1]
6440/23
6421/6
6398/14
retraining [1]
rapidly [2]
S
6449/18
record [2] 6454/6 render [1]
6424/4 6426/17
safe [1] 6476/3
6479/5
6469/23
retrieval [10]
rarely [2]
SALLET [1] 6393/2
recorded [1]
repeat [1] 6418/2 6400/6 6400/11
6397/20 6450/9
same [22] 6398/6
6395/22
6400/14 6400/17
replace [1]
rated [3] 6424/3
6402/25 6411/14
6401/20 6406/15
redact [5] 6477/8 6437/10
6424/18 6425/12
6417/12 6417/21
6478/2 6478/8
6406/18 6407/1
Reporter [3]
rater [8] 6423/4
6418/4 6419/4
6478/9 6478/14
6451/5 6472/10
6393/23 6393/23
6423/24 6423/25
6420/12 6425/23
6479/3
redacted [1]
retrieve [10]
6427/19 6428/25
6428/16 6430/21
6432/18
representation [2] 6399/1 6400/9
6429/16 6432/6
6432/13 6434/8
6406/11 6422/7
6429/4 6429/13
redactions [1]
6448/24
6434/10 6434/11
6477/21
6422/8 6445/20
request [4]
raters [14]
6435/3 6437/21
6445/21 6451/1
6455/8 6460/10
redirect [3]
6424/3 6424/13
6448/5 6456/24
6394/5 6468/16
6471/24 6472/6
6476/17 6476/24
6424/16 6425/12
6463/8 6463/24
6468/19
retrieved [4]
requests [2]
6425/13 6426/4
6464/1
6406/24 6407/3
6460/8 6476/23
redo [1] 6400/24
6426/10 6426/21
samples [1]
6408/10 6422/10
require [5]
reduce [10]
6429/2 6429/4
6424/2
6427/18 6428/1
6411/3 6459/20
retrieving [1]
6429/12 6441/3
satisfied [2]
6472/4
6428/3 6443/23
6460/3 6460/7
6441/9 6447/19
6421/8 6441/20
6444/25
6460/25 6462/12
returning [1]
rating [2]
saying [5]
6469/10
6463/19 6463/20
required [1]
6428/15 6429/25
6398/19 6418/13
6447/15
6465/1 6470/6
revealed [1]
ratings [7]
6418/15 6422/11
6477/15
requires [3]
reducing [4]
6424/16 6425/14
6450/1
6397/25 6398/1
6406/1 6409/8
review [3]
6426/2 6426/4
scale [2] 6438/11
6435/20 6455/6
6445/7
6409/17 6462/15
6426/5 6426/15
6452/21
6476/12
research [1]
reduction [2]
6426/15
scheme [2] 6411/6
6416/17
6409/5 6409/14
reviewed [1]
reaches [1]
6420/8
6455/1
refer [1] 6430/20 reserve [1]
6404/6
SCHMIDTLEIN [2]
6474/25
right [154]
refer to [1]
reaching [1]
6393/7 6474/12
6430/20
ring [6] 6403/17
resolved [1]
6404/5
school [2] 6416/9
6475/16
6403/17 6403/21
referring [6]
read [2] 6463/17
6416/13
6403/21 6404/6
6417/18 6417/24
respect [2]
6464/9
schoolwork [1]
6462/8 6466/14
6404/8
6418/24 6422/22
ready [1] 6395/3
6416/15
6436/22 6466/17
response [1]
risky [1] 6438/6
reality [1]
scope [1] 6474/21
Rochester [6]
refers [1] 6469/4 6457/18
6434/24
score [16]
6421/5 6421/6
rest [1] 6460/20
reflects [1]
really [11]
6399/24 6400/10
6421/7 6421/8
6449/2
restaurant [1]
6399/11 6418/1
6401/3 6401/18
6421/19 6422/6
6412/15
refresh [1]
6455/16 6456/2
6402/1 6402/2
6469/6
result [6] 6421/6 rocks [1] 6441/1
6464/18 6468/23
6402/3 6408/3
6456/19 6469/9
role [1] 6400/3
regions [1]
6470/16 6470/24
6423/2 6423/4
6469/11 6471/5
6421/9
roll [1] 6448/14
6470/25 6472/11
6478/16
rooms [1] 6467/23 6425/15 6425/17
regular [1]
6472/23
6426/6 6426/24
6432/22
results [47]
root [1] 6412/10
realtime [1]
6430/24 6431/12
6399/4 6399/8
rooting [1]
regularly [1]
6396/21
scored [4]
6412/12
6401/12 6401/14
6423/18
reason [2]
6401/17 6426/8
6401/17 6401/24
Rosati [1]
relate [1]
6437/24 6470/9
6428/11 6451/2
6393/11
6403/7 6403/11
6476/25
reasonable [1]
scores [4]
6403/23 6408/20
Roszak [2]
related [5]
6404/23
6399/21 6401/5
6476/15 6478/3
6411/17 6411/22
6416/8 6416/20
reasons [2]
6441/12 6467/13
6412/3 6421/5
6436/21 6469/16
roughly [2]
6406/14 6431/18
scoring [1]
6417/21 6418/15
6424/2 6424/17
6477/4
recall [1]
6425/10 6425/23
round [1] 6412/12 6400/20
relationship [1]
6458/12
screen [4] 6402/7
6425/24 6426/2
6406/8
rule [1] 6428/3
received [3]
6402/20 6419/24
6426/3 6426/5
run [18] 6409/11
relative [2]

R

screen... - started

6492

6443/22 6444/24
6399/17 6399/18
6456/20 6470/3
6473/17 6473/17
6447/18 6471/8
6407/9 6409/8
sorry [13]
single [1]
screen... [1]
6409/11 6443/6
6400/15 6406/6
6426/24
send [3] 6407/9
6420/4
6426/4 6470/1
6410/4 6417/1
SGE [1] 6448/7
singular [2]
scroll [1]
6421/14 6423/11
6453/18 6459/16
sending [1]
shipping [1]
6419/16
6469/17
6460/17
6427/9 6437/2
sister [1]
scrolling [2]
6442/8 6445/10
6454/20
sends [1] 6460/19 shoes [1] 6429/3
6419/22 6420/6
6461/25 6472/15
sense [9] 6429/15 show [2] 6419/19 site [1] 6421/10
se [1] 6446/18
6436/13 6439/4
6435/9
6475/7
situation [1]
sealing [2]
6447/15 6447/15
6426/12
showed [1]
sort [28] 6396/25
6475/2 6476/23
6447/19 6450/9
6441/18
6404/2 6404/14
situations [2]
search [53]
6472/16 6473/9
6406/20 6406/22
shown [6] 6401/15 6450/14 6450/17
6395/21 6396/14
6411/12 6411/13
6410/13 6415/20
sentence [3]
six [1] 6476/20
6396/18 6401/12
6443/16 6445/1
6411/14 6419/13
6417/21 6422/11
size [4] 6397/9
6401/22 6401/23
6464/8
6419/14
6434/7 6444/19
6397/16 6398/5
6405/10 6408/9
6446/22 6450/15
separate [4]
shows [1] 6403/14 6398/24
6408/10 6408/12
6436/17 6436/22
6459/18 6460/8
shutdown [1]
Sky [1] 6474/19
6408/20 6408/23
6436/24 6448/4
6465/19
slice [4] 6412/20 6460/12 6461/7
6413/16 6414/18
6465/18 6467/16
6412/22 6417/10
sequences [1]
shy [1] 6435/14
6414/19 6419/2
6447/10
6470/9 6470/16
side [26] 6410/10 6420/25
6419/6 6420/12
6410/10 6410/12
6472/9 6472/19
sequencing [1]
slices [5]
6421/24 6422/25
6405/11
6410/12 6410/18
6475/4 6477/6
6412/19 6412/20
6423/18 6428/12
6410/18 6411/24
6477/23 6478/9
6412/23 6413/1
SERP [8] 6401/9
6428/24 6429/1
6401/11 6401/15
6426/21 6426/21
6478/12
6420/24
6429/19 6429/24
6401/24 6403/14
6426/23 6426/23
sorted [1]
slicing [1]
6429/25 6435/4
6408/25 6459/25
6465/25 6466/4
6406/21
6413/4
6439/23 6441/19
6460/16
6466/4 6466/11
slide [1] 6435/21 sorts [2] 6401/5
6445/19 6446/1
6428/2
serve [2] 6461/11 6466/11 6466/15
slides [1]
6446/2 6448/12
6473/18
6466/15 6466/16
6423/12
sound [1] 6457/9
6453/16 6454/15
served [3] 6412/3 6466/16 6466/18
slightly [2]
sources [1]
6454/18 6454/19
6420/9 6422/9
6466/18 6469/12
6417/19 6420/9
6446/4
6454/20 6454/20
6469/15 6470/7
server [7]
slow [3] 6455/17 South [1] 6392/19
6458/7 6459/2
6411/16 6464/2
6470/10
6456/2 6473/14
Southern [1]
6459/3 6459/20
6464/12 6469/12
side-by-side [10] slower [3] 6427/3 6421/19
6459/23 6461/11
6469/15 6470/7
6410/10 6410/12
6457/14 6457/19
speaking [1]
6463/15 6465/16
6470/10
6410/18 6426/21
6477/11
slowly [1]
6469/10 6469/10
6426/23 6466/4
6449/17
server-side [1]
special [1]
6471/15 6477/18
6466/11 6466/15
6469/15
6473/16
small [4] 6437/6
6477/19
6466/16 6466/18
6439/2 6449/21
servers [8]
specific [12]
searches [1]
6459/21 6460/3
6449/24
6395/23 6397/11
side-by-sides [1]
6463/21
6465/25
6460/6 6460/8
6398/24 6420/22
smaller [7]
searching [5]
6460/11 6460/23
6439/20 6441/19
sides [2] 6411/17 6399/23 6404/16
6412/14 6416/12
6465/25
6460/25 6461/3
6405/5 6407/8
6445/18 6452/10
6417/1 6421/10
6449/6 6452/10
6457/16 6457/19
serves [1] 6458/7 sign [1] 6409/19
6421/20
6458/15 6458/17
serving [2]
signal [4] 6406/9 6473/15
second [16]
6435/22 6473/10
6408/13 6408/14
SMURZYNSKI [2]
specifically [5]
6410/7 6420/4
6413/15
6393/8 6394/5
6416/7 6420/14
session [2]
6423/16 6436/1
6392/7 6474/5
6458/6 6476/25
signals [14]
so-called [1]
6436/2 6439/18
6403/15 6407/8
6411/16
6477/3
sessions [2]
6440/22 6442/8
6475/6 6476/14
6407/25 6408/1
software [1]
specifics [2]
6442/12 6442/25
6408/1 6408/2
6460/15
6420/3 6420/5
set [27] 6399/15
6444/3 6452/22
6399/23 6402/9
6408/16 6408/22
solution [1]
speed [1] 6469/18
6455/13 6461/8
6404/6 6404/11
6408/24 6472/1
6420/9
spend [1] 6398/11
6474/19 6475/18
6404/13 6404/15
6472/3 6472/4
solving [1]
spending [1]
secondary [1]
6404/16 6405/5
6472/22 6473/3
6447/16
6470/6
6419/23
6407/8 6424/6
signed [1]
somebody [2]
SSL [1] 6462/5
seconds [2]
6424/7 6424/8
6409/17
6396/21 6412/12
stack [4] 6396/14
6456/7 6461/13
6425/8 6425/15
6404/1 6405/10
significance [1]
sometimes [6]
secrets [2]
6425/16 6425/22
6472/18
6406/21 6417/11
6428/12
6477/20 6478/16
6425/22 6425/23
6420/4 6426/15
significant [1]
stand [1] 6468/22
Section [1]
6425/23 6426/6
6443/16
6428/11 6428/15
standard [1]
6393/4
6426/8 6446/23
6410/13
significantly [1] somewhat [1]
secure [1] 6478/8
6457/19 6458/13
6457/14
6434/13
stands [2]
security [1]
6458/18 6466/11
6401/20 6469/7
similar [1]
somewhere [1]
6470/4
6467/6
6402/23
sets [3] 6424/1
start [6] 6395/19
seeing [4]
6424/3 6465/25
Similarly [1]
Sommer [1] 6476/1 6430/11 6431/11
6427/20 6439/1
6449/17 6459/2
seven [2] 6434/17 6478/3
Sonsini [1]
6455/13 6456/23
6434/19
6460/10
simple [1] 6399/7 6393/11
seems [5] 6441/17
several [6]
sooner [2]
started [4]
simpler [2]

S

started... - transcript

6493

6440/9 6441/7
tested [1]
summary [2]
tomorrow [4]
6426/23
6458/5 6463/17
6474/1 6474/6
6443/12 6449/4
started... [4]
6475/1 6475/18
6451/7 6466/4
testers [1]
summit [3]
6430/14 6430/16
6423/20
6454/15 6454/18
6467/2 6473/16
tongue [1]
6432/13 6443/5
6454/21
6448/14
testified [2]
talking [18]
starting [2]
6397/12 6437/3
6399/13 6402/10
suppose [3]
took [3] 6409/6
6397/24 6468/21
6419/9 6419/9
6420/1 6449/24
6405/9 6417/13
testifying [1]
State [3] 6392/21
6418/16
6445/2
6418/13 6418/19
tool [1] 6413/25
6392/22 6393/2
6418/20 6420/14
testimony [2]
supposed [5]
tools [1] 6463/1
statement [3]
6433/1 6473/21
6400/24 6418/1
6424/9 6433/17
top [21] 6408/4
6397/2 6444/19
6429/12 6463/20
6410/4 6414/14
6434/23 6434/24
testing [3]
6450/4
6466/4 6466/7
6463/21
6415/3 6415/6
6436/24 6448/2
statements [1]
6466/14
6415/20 6415/25
sure [20] 6395/12 6448/10 6463/8
6477/23
6406/7 6410/19
6464/24 6473/7
tests [1] 6423/24 6416/3 6419/14
STATES [4] 6392/1
6421/13 6422/1
6421/4 6421/15
talks [1] 6429/11 Tetris [4]
6392/3 6392/11
6422/14 6422/22
6428/8 6431/12
6408/17 6408/18
Tangram [3]
6412/9
6425/4 6430/1
6435/22 6437/9
6408/15 6408/17
6408/19 6408/23
States' [1]
6436/24 6438/21
6438/8 6452/1
6408/18
thinking [2]
6474/21
6444/1 6446/22
6456/19 6460/19
6460/23 6462/14
task [1] 6439/20
stay [1] 6443/15
6453/3 6459/17
6472/17 6472/17
task-specific [1] third [6] 6414/8
steps [1] 6429/7
6464/25 6465/19
6439/20
6421/4 6440/12
topic [3] 6441/3
STEVEN [1] 6393/3
6470/20 6471/2
6441/4 6468/21
taste [1] 6449/12 6451/18 6452/1
still [8] 6398/8
6474/7
6463/1
topicality [2]
Taylor [1]
6419/21 6437/24
6395/21
surprised [1]
though [4] 6398/9 6407/25 6472/10
6438/10 6446/23
6409/11
6437/15 6446/21
touches [1]
teacher [1]
6453/14 6453/19
6441/7
6473/9
6450/5
suspect [1]
6460/19
6444/10
tracks [1] 6417/2
team [8] 6411/8
thought [3]
stop [1] 6470/24
6454/20 6454/21
6477/19 6478/9
trade [4] 6470/19
SW [1] 6393/9
store [1] 6396/8
6471/1 6477/20
6478/15
Swift [1] 6395/21 6454/22 6454/23
storekeepers [1]
6478/16
6459/16 6465/1
system [15]
thousands [7]
6422/18
6466/20
6395/21 6400/7
6406/25 6407/5
trade-off [1]
straightforward
6470/19
6400/12 6400/20
teams [6] 6459/17 6407/7 6407/15
[1] 6447/12
6459/17 6464/16
6400/24 6405/15
6408/2 6431/23
traditional [5]
straining [1]
6404/20 6438/11
6464/19 6465/2
6408/15 6424/12
6472/8
6440/23
6438/14 6450/22
6471/7
6436/9 6438/7
three [10]
strategy [3]
6451/5
6441/12 6444/5
6398/17 6398/18
technical [1]
6460/15 6460/16
6413/22
6446/16 6448/12
6398/21 6398/23
traditionally [1]
6460/18
6473/11
6409/21 6414/12
6438/18
technique [1]
stream [1] 6424/2
6411/23
6431/1 6431/8
systems [23]
traffic [8]
streaming [2]
6396/19 6396/22
6434/9 6477/4
6409/22 6410/5
techniques [1]
6460/18 6470/1
6422/8
6400/3 6400/5
6410/8 6446/8
three years [1]
Street [3]
6400/17 6402/13
6434/9
6446/8 6449/22
technology [2]
6392/14 6392/17
6478/10 6478/13
6402/15 6404/20
6449/25 6460/6
throughput [1]
6392/19
6407/23 6428/17
6452/20
tend [1] 6427/15
train [9] 6428/12
strengths [1]
6430/18 6430/19
6428/16 6432/5
tens [6] 6406/25 ties [1] 6443/17
6437/10
6407/5 6407/7
6438/8 6438/19
6433/23 6436/9
tightly [1]
structure [1]
6407/15 6408/2
6439/23 6440/13
6443/17
6447/14 6449/7
6448/16
6472/8
6443/8 6443/11
TikTok [3] 6467/7 6449/10 6473/15
structured [1]
6446/1 6446/2
6467/9 6467/13
terabytes [1]
train' [1]
6460/15
6435/1
6450/22 6453/10
times [8] 6422/19 6461/12
students [2]
6477/16
6425/5 6434/17
term [6] 6401/11
trained [12]
6416/16 6416/18
6415/7 6419/4
6434/19 6456/3
6405/18 6431/8
studies [3]
T
6420/12 6439/4
6460/11 6466/24
6431/25 6432/11
6409/13 6446/8
table [2] 6415/19 6468/22
6475/22
6432/22 6433/12
6462/4
6418/25
terms [11]
timing [1] 6474/6 6445/15 6445/16
study [1] 6462/3
tackle [1]
6421/18 6446/13
title [1] 6454/14 6448/4 6448/6
stuff [5] 6398/14
6463/18
6446/17 6459/7
6448/21 6449/21
TL [1] 6464/8
6403/13 6403/13
tail [2] 6436/3
6472/18 6473/8
today [11] 6434/8 training [13]
6422/19 6470/2
6463/19
6473/10 6474/1
6437/21 6445/14
6411/4 6439/19
sub [1] 6452/22
talk [3] 6426/21
6476/19 6477/10
6448/6 6453/16
6439/20 6447/5
subject [3]
6433/16 6440/12
6477/11
6458/7 6461/10
6447/9 6447/11
6413/22 6455/7
talked [22]
6474/24 6477/14
6447/12 6447/25
terrible [1]
6477/7
6397/9 6398/25
6463/20
6477/25 6478/13
6449/1 6452/1
subset [2]
6401/22 6406/1
6452/9 6473/16
terrific [2]
together [6]
6433/24 6454/23
6408/8 6409/5
6442/18 6474/11
6403/13 6404/4
6477/17
subsume [2]
6413/8 6418/17
6408/3 6408/20
test [7] 6410/14
trains [2] 6436/3
6440/13 6440/18
6418/18 6421/23
6410/18 6423/18
6410/14 6446/9
6436/8
Suite [2] 6392/19
6423/2 6430/13
6423/25 6467/8
tolerating [1]
transcript [2]
6392/23
6435/20 6440/6
6467/10 6467/12
6470/19
6392/10 6479/4

S

transcripts - words

6494

6399/1 6399/14
6430/20 6430/23
UPX2034 [3]
6394/12 6451/9
6407/10 6410/18
6438/18 6459/8
transcripts [1]
U.S [6] 6392/14
6451/24
6431/1 6447/10
6472/25
6477/15
6392/16 6392/19
6448/12 6467/18
UPX680 [1]
weather [2]
6393/24 6433/24
transform [1]
6394/11
6471/23
6471/15 6471/15
6453/5
6433/25
UPX860 [4]
using [9] 6397/6 web [13] 6401/14
transformer [2]
UK [1] 6412/11
6433/14 6435/6
6407/1 6411/25
6401/17 6401/24
6447/11 6448/6
ultimately [1]
6435/16 6435/18
6428/16 6430/11
6403/7 6403/11
6403/14
transformer-based
6403/23 6408/9
usage [2] 6434/11 6430/14 6430/16
[1] 6448/6
unclear [1]
6437/5
6443/5 6473/15
6408/11 6443/5
6435/14
transformers [1]
6445/14 6445/15
use [19] 6399/19 usually [4]
6447/10
under [11]
6401/11 6402/7
6413/21 6415/11
6445/17 6448/7
6400/11 6410/2
translate [1]
6407/8 6411/21
6427/18 6476/5
Webb [1] 6392/22
6441/13
6436/2 6439/18
6419/10 6419/12
website [2]
6441/2 6444/3
transport [2]
V
6419/13 6424/3
6422/18 6451/21
6461/1 6469/16
6461/8 6462/2
V-A-L-L-E-Z [1]
6430/6 6438/18
weekly [1]
6462/2
6463/1
travel [1]
6475/8
6441/19 6448/11
6413/20
6460/24
6471/8
Vallez [2]
6448/15 6449/7
welcome [3]
treated [1]
understands [2]
6474/20 6475/8
6450/23 6472/1
6395/2 6402/7
6478/12
6436/3 6436/12
valuable [6]
6472/6 6473/18
6454/15
trees [1] 6430/15 understood [6]
6450/1 6450/6
used [20] 6397/3
WENDY [2] 6393/10
TRIAL [1] 6392/10 6396/25 6430/3
6450/11 6450/15
6399/24 6401/6
6474/14
tried [1] 6470/21 6434/3 6453/3
6450/18 6450/19
6406/1 6408/17
weren't [1]
6467/25 6468/10
trimmed [1]
variables [2]
6408/18 6409/9
6409/13
6454/4
unique [1] 6426/7
6458/25 6472/17
6409/18 6412/19
what's [6] 6401/5
true [11] 6396/18 unit [2] 6427/10
various [5]
6413/10 6428/11
6406/8 6434/24
6403/15 6421/2
6434/7
6406/14 6424/1
6433/6 6433/10
6445/21 6459/2
6421/22 6428/1
UNITED [4] 6392/1
6428/2 6437/25
6436/9 6438/18
6475/10
6429/10 6430/25
6392/3 6392/11
6471/9
6449/24 6465/15
whereas [2]
6435/5 6453/19
6412/9
vast [1] 6447/20
6465/15 6470/21
6420/17 6428/25
6460/5 6479/4
unless [1] 6400/9
versus [3] 6413/2 wherever [1]
6471/17
trust [1] 6438/4 unlikely [1]
6456/25 6461/13
6397/24
useful [2]
truth [1] 6473/12 6429/5
view [1] 6413/25 white [1] 6469/1
6422/21 6470/11
unreasonable [1]
try [6] 6404/3
user [27] 6395/20 visual [1] 6459/4 Who's [1] 6465/14
6437/14
6404/13 6428/3
volume [1]
6405/18 6413/7
whole [8] 6421/17
6430/2 6458/20
up [27] 6399/12
6434/25
6422/7 6425/15
6414/20 6419/15
6400/2 6400/23
6462/12
vu [1] 6457/4
6454/13 6454/22
6421/2 6422/15
6403/14 6408/13
trying [4]
6455/1 6455/10
6422/21 6428/20
6415/19 6419/24
6423/23 6427/20
W
6460/16
6429/3 6429/8
6424/17 6430/10
6439/2 6470/7
wait [2] 6431/19 wholly [1]
6429/12 6429/13
6430/10 6434/11
tuned [2] 6432/3
6460/9
6453/18
6429/17 6433/12
6450/22 6454/14
6448/24
walk [2] 6406/18 wifi [1] 6461/5
6433/16 6436/3
turkey [1] 6450/8 6457/10 6457/14
6407/2
6439/23 6440/1
WILLIAM [1]
6459/25 6460/8
turn [5] 6438/7
walking [1]
6392/22
6447/21 6450/10
6461/6 6462/3
6467/15 6468/4
6406/16
6450/10 6456/4
Williams [1]
6464/16 6464/23
6472/23 6472/24
wander [1] 6395/8 6393/8
6461/2 6464/18
6465/1 6469/25
turning [2]
wants [2] 6410/14 Wilson [1]
6464/19 6464/21
6471/4 6474/21
6422/24 6437/19
6393/11
user's [2] 6461/4 6410/19
turns [2] 6447/11 6475/5 6475/25
Washington [6]
6461/7
wire [1] 6469/17
6456/1
update [3]
within [2]
users [37] 6401/6 6392/5 6392/15
6422/18 6463/15
two [11] 6410/17
6392/17 6393/9
6446/19 6454/19
6411/12 6411/13
6465/20
6411/17 6426/22
6393/25 6471/16
6411/13 6411/18
without [3]
6436/16 6436/17
updated [1]
WASZMER [2]
6409/18 6409/20
6412/3 6415/9
6402/25
6453/4 6463/18
6393/10 6474/14
6448/17
6416/18 6417/11
6474/1 6474/4
upon [1] 6399/12
way [26] 6398/12 witness [9]
6419/11 6419/21
6474/16 6477/9
UPX [1] 6451/19
6398/14 6402/20
6394/2 6468/14
6420/9 6420/17
Tyler [1] 6392/22 UPX2022 [3]
6402/22 6406/19
6468/17 6473/24
6420/18 6422/9
6394/14 6457/22
type [3] 6472/9
6406/20 6411/17
6474/19 6474/20
6429/5 6429/5
6458/1
6472/10 6472/13
6418/6 6420/1
6475/7 6475/8
6429/13 6429/15
types [5] 6409/21 UPX2026 [3]
6422/6 6424/4
6475/18
6433/22 6433/23
6394/13 6454/10
6410/4 6418/4
6426/16 6438/18
6433/24 6433/24
witnesses [4]
6455/9
6446/10 6446/14
6441/9 6445/23
6474/2 6474/4
6434/1 6441/2
UPX2027 [2]
typical [1]
6450/19 6458/21
6474/16 6477/4
6441/2 6441/8
6394/15 6462/20
6429/3
6459/14 6459/20
6441/13 6441/19
wonderful [1]
UPX2029 [2]
typically [3]
6460/14 6471/8
6441/22 6441/24
6470/9
6442/1 6446/23
6399/4 6450/11
6472/21 6473/2
6441/25 6456/2
word [5] 6406/13
6460/10
UPX2033 [3]
6474/22 6475/2
6459/4 6470/11
6406/13 6412/6
6394/16 6465/6
tzar [1] 6470/23
6478/12
6470/20 6471/4
6412/14 6412/20
6465/12
uses [10] 6397/4 ways [6] 6424/1
words [4] 6406/16

T

U

words... - zero

6495

Yoo [1] 6476/14
York [7] 6392/24
words... [3]
6393/12 6421/6
6407/3 6427/10
6421/7 6421/19
6473/1
6422/6 6475/22
work [23] 6396/23
you use [1]
6396/23 6400/24
6419/10
6404/16 6408/5
you were [1]
6409/16 6416/4
6418/19
6416/8 6416/13
6416/21 6450/22
Z
6459/9 6459/24
zero [1] 6439/9
6462/11 6464/22
6464/25 6469/12
6469/25 6470/15
6471/2 6471/8
6476/5 6477/16
worked [5] 6395/5
6396/11 6396/12
6396/14 6411/9
workers [1]
6416/25
working [4]
6396/22 6441/8
6460/19 6471/8
works [1] 6403/25
workstreams [2]
6464/3 6464/12
world [18]
6412/17 6423/21
6443/24 6444/6
6444/10 6444/18
6445/3 6445/7
6445/10 6445/13
6445/16 6445/19
6445/21 6445/22
6447/21 6448/1
6448/8 6453/7
worst [1] 6461/11
worth [2] 6432/12
6449/20
write [6] 6399/18
6452/1 6452/9
6466/10 6466/10
6466/19
writes [3]
6463/14 6465/17
6465/19
written [1]
6473/7
wrong [1] 6419/9
wrote [5] 6451/10
6451/14 6453/11
6453/13 6453/14

W

X
X1721 [1]
X1723 [1]

6415/2
6420/15

Y
year [1] 6430/10
years [10]
6398/17 6398/18
6398/21 6398/23
6432/11 6434/9
6441/3 6443/6
6457/9 6467/4
yellow [1] 6457/9
yield [1] 6399/7

