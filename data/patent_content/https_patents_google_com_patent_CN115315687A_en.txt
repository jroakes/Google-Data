CN115315687A - System for filtering displayed content at Operating System (OS) level - Google Patents
System for filtering displayed content at Operating System (OS) level Download PDFInfo
- Publication number
- CN115315687A CN115315687A CN202080098486.0A CN202080098486A CN115315687A CN 115315687 A CN115315687 A CN 115315687A CN 202080098486 A CN202080098486 A CN 202080098486A CN 115315687 A CN115315687 A CN 115315687A
- Authority
- CN
- China
- Prior art keywords
- application
- content item
- content
- filtering
- user device
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2221/00—Indexing scheme relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/21—Indexing scheme relating to G06F21/00 and subgroups addressing additional information or applications relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/2149—Restricted operating environment
Abstract
Methods, systems, and apparatus for filtering content at the operating system level. In one aspect, a method comprises: accessing, at a user device, data comprising a content item to be presented by an application executing on the user device; prior to presentation of the content by the application: for each content item, determining, at the user device and by a filtering model, whether the content item is rendered by the application or filtered by the filtering model, for each content item determined to be rendered by the application, allowing the application to render the content item, and for each content item determined to be filtered, preventing, by the filtering model, the rendering of the content item by the application by a system-level filtering operation performed at an operating system level and separate from an application level at which the application is executed.
Description
Technical Field
Content filtering is performed for various reasons. For example, the content may be filtered to prevent children from being exposed to content that is not suitable for viewing when young. The content may also be filtered to prevent "showking", i.e. revealing key episode events of a television program or movie. Content may also be filtered based on gender, race, or religion to prevent harassment to individuals.
Background
In the context of the internet, filtering is typically done on the service side and is often application specific. For example, a search engine may enable a "secure search" setting that prevents non-truncated (explicit) search results from being provided to a user device running a browser. However, the "secure search" setting is only applicable to searches by search engines, and does not prevent exposure to content from other websites if the user navigates to other websites.
As another example, the operating system may restrict installation of certain applications, such as applications that are ranked as "PG-14" in an application store. However, if the application is not ranked, the application may still be installed.
Most existing content filtering solutions are suitable for specific situations, but do not address the problem of filtering content that is independent of the website (in the case of a browser) or other environment (in the case of an application other than a browser). Moreover, restricting the installation of a particular application does not achieve many filtering goals, as many general-purpose applications (e.g., instant messaging applications, email applications) may still be installed and expose undesirable content to users.
Disclosure of Invention
This specification relates to a system and method for analyzing and filtering undesirable content prior to presentation of digital content to a user on a user device. More specifically, the systems and methods described below analyze, at a user device, content to be presented on the user device and filter content of undesirable items before presenting the content to a user of the user device.
In an embodiment, the filtering system operates at the Operating System (OS) level on the user device, as opposed to operating at the application level for a particular application. As used in this specification, operating at the OS level means an operation having a higher authority (privilege) of access than the following operation at the application level and/or the following operation performed by the operating system: wherein the operation processes the content to be displayed. For example, data to be rendered on a screen display may be processed to identify content to be filtered. The entire content of the screen may be processed or only some content may be processed, for example only images may be processed.
As yet another example, OS-level operations may access data processed by a plurality of different applications and may be operations that affect the presentation of data by a plurality of different applications. In contrast, the application level operation is the following: the operation may only be able to access the data that is being processed by the application to which it belongs, and not affect other applications. Thus, by operating at the OS level, the filtering system is agnostic to the applications for which the filtering system can filter its content.
One example method includes the following operations. The method accesses, at a user device, data comprising a plurality of content items to be presented by an application executing on the user device. The content items may be words, phrases, images, video and audio. Typically, content items are being processed by applications for presentation by the applications in UIs for text, images and video, as well as through audio output systems for audio.
Before content is presented by an application, a filtering model determines whether content items are presented by the application or filtered by the filtering model. The determined properties depend on the content type and the filtering model. For example, for a text filter filtering model, text may be compared to a list of forbidden words and phrases; conversely, if the filtering model takes into account the semantic interpretations of the sentences and paragraphs, the entire sentence and paragraph may be filtered based on the determined semantic interpretations. Any suitable filtering model may be used, depending on the robustness and maturity of the filtering (cryptography) desired, and depending on the type of content being filtered.
For each content item determined to be presented by the application, the filtering model allows the application to present the content item. Instead, for each content item determined to be filtered, the filtering model filters that content item. More specifically, the filtering model prevents presentation of content items by an application through system-level filtering operations performed at the operating system level and separate from the application level at which the application is executed. This can be achieved, for example, by: opaque obscurations are presented over filtered text, images and video, or filtered audio is suppressed or bleeped.
In some implementations, the filter elements that filter the content items are selectable and the user can select them to allow the content items to be presented. The filtering model may take this into account and adjust its parameters for future filtering operations. For example, opaque obscuration may be selectable and, once selected, removed to allow the filtered content to be presented. Similarly, when audio is suppressed, the filtering model may cause the device to declare that audio is suppressed and to declare what commands are used to allow the filtered audio to be presented if the user desires to listen to the audio, e.g., "the song you will hear contains non-truncated lyrics, and i will beep to silence the non-truncated words so that you cannot hear them. However, if you do not find such content objectionable, say "let me hear it," i do not beep to silence the unabridged words. "
In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of: accessing, at a user device, data comprising a plurality of content items to be presented by an application executing on the user device; prior to presentation of the content by the application: for each content item, determining, at the user device and by a filtering model, whether the content item is rendered by the application or filtered by the filtering model, for each content item determined to be rendered by the application, allowing the application to render the content item, and for each content item determined to be filtered, preventing the rendering of the content item by the application by a system-level filtering operation performed at an operating system level and separate from an application level at which the application is executed. Other embodiments of this aspect include corresponding systems, apparatus, and computer programs, configured to perform the actions of the methods, and encoded on computer storage devices.
Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages. By filtering at the OS level, the filtering process described below can filter particular content across multiple applications and independently of each application. This reduces the likelihood of filter leaks that might otherwise occur when filtering in a canonical application. For example, filtering pornographic content within a search engine may prevent pornographic content from being provided as a search result. However, if the user navigates to a site hosting the content, or if the user receives the content via email or instant messaging, the same pornographic content may be provided. In contrast, operating system level filtering allows a user device to implement a filtering process for particular content for all applications that provide content for consumption by the user.
The analysis and filtering of the content is done independently of the application presenting the content. This solves the problems associated with the complexity and resources that accompany the separate filtering process for each application. When filtering is only done at the application level, separate processing must be implemented in each application, and thus each application may consume additional processing resources (e.g., image, video, text, and audio processing) when determining whether to filter content. Such implementation of separate processes may not be possible in every application; for example, the device may not be able to control the processes running on the application, and thus providing effective filtering presents challenges.
Furthermore, the filtering described below may be done solely on the user device, and thus the user's preferences need not be handled at the server level. This reduces the amount of network traffic required when a user changes his or her filtering preferences. For example, when a user desires to change his or her filtering preferences for a particular set of search results, the search results need not be resent. In addition, the filtering performed on the user device protects the user's information about filtering preferences from being leaked to third parties and used for other purposes (e.g., advertising) than filtering.
Additionally, filtering on the device reduces the resources required for such filtering when it is done on the server side, since content filtering, such as video filtering, is done only on the device of the user who desires such filtering.
Another advantage is the ability to filter content received in encrypted form at a device. Because the content is decrypted by an application (e.g., a chat application), the content is "plaintext" prior to presentation. Thus, circumvention of filtering by encryption is broken (defeat) at the device. Furthermore, the filtering process need not include encryption/decryption processes, thus simplifying content analysis and filtering.
The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 is a block diagram of an example user device showing an abstraction level for an operating system.
FIG. 2 is a block diagram of an example text application executing at the application level of an operating system.
FIG. 3 is a flow diagram of an example process of filtering content generated for presentation to a user.
Detailed Description
User devices such as cellular phones, smart phones, PDAs, tablet style computers have become very popular and an integral part of our daily lives. Now, the vast majority of the population is exposed (access) to one or more of these devices to access digital content through them. These devices are generally capable of performing a variety of tasks, such as browsing the internet, messaging, e-mail, downloading content, and executing different applications, as well as a variety of other functions.
Most of the tasks performed by these devices expose some digital content to the user. For example, chat applications allow a user to send digital content, such as text messages, images, audio, and video, to another user. The browser application allows access to digital content through internet searches or digital advertisements. Other examples of such applications may include streaming video applications, online games, and cloud-based applications.
In all of the above cases where digital content is accessed by an application and presented to a user by a user device, there is always a risk that the user may be exposed to: content that is not suitable for a particular user (e.g., adult content for children), or content that the user may not want to view (e.g., a drama), or may be content that is to be filtered from the presentation. The systems and methods described below allow a user device to filter such content by filtering across multiple applications simultaneously at the OS level.
These and additional features are described in more detail below.
FIG. 1 is a block diagram of an example user device 100 illustrating the functionality of the user device 100 in presenting digital content to a user. The user device 100 has an application level 120, where applications execute within the operating system of the user device 100. The operating system operates at the OS level 140, e.g., kernel mode or system level operation, such as a text handler (handler), video handler, or audio handler, while the application operates at the application level 120 outside the OS level 140, e.g., a user mode that has lower privilege than the root user (root) mode, or an operation that occurs within the application environment. In general, an application operating at the application level 120 will only have access to data specific to that application, while a process operating at the OS level 140 will have access to data for many applications operating at the application level 120.
As shown in fig. 1, the chat application 122, browser application 124, music application 126, and video application 128 operate at an application level 120. The user device also includes an I/O system 160, the I/O system 160 including a display system 170 that renders application data for the application. The I/O system 160 also includes a speaker system 180, the speaker system 180 generating audio dependent on the application executing at the application level 120.
The application executing at the application level 120 generates a digital content item for presentation to the user on the user device 100. The content item may be each of an image, a set of video frames, text, and a continuous portion of audio (e.g., one second increments of audio). When a user interacts with a particular application through a user device, the digital content of the particular application is presented directly to the user. For example, if a user is interacting with the browser application 124, the browser application 124 is rendered directly on a display system 170 within the I/O system 160 of the user device 100 along with the digital content of the browser application 124. Similarly, when a user interacts with music application 126, the music is played directly using speaker system 180 within I/O system 160.
The filtering model 150 is implemented at the OS level 140. The filtering model 150 may receive as input digital content generated by an application executing at the application level 120; processing the input; and identifying content to filter. Upon identifying content to filter, the filtering model 150 prevents the user device 100 from presenting the content to the user. How the filtering model identifies the content to be filtered, and how the content is actually filtered, will be described in more detail below.
The filtering model 150 operates at the Operating System (OS) level (or simply "system level") on the user device 100, as opposed to operating at the application level for a particular application. As used in this specification, an operation at the OS level is an operation having access with higher authority than an operation at the application level. For example, an OS-level operation may access data processed by a plurality of different applications and may be an operation that affects the presentation of data by a plurality of different applications.
The filtering model 150 may be implemented as one or more machine learning models that include a plurality of parameters that have been trained to identify certain content, such as pornography, visceral words, and the like. For example, in some implementations, the filtering model 150 can be a collection of various models that can interpret different types of content, such as a skin detection model for video, various object detection models, and a word detection model. The filtering model 150 may process images, video, text, and even audio to detect content to be filtered.
In some implementations, the filtering model 150 determines whether to filter content based on user preferences 152. The preferences may specify what types of content, if any, are to be filtered. For example, the filtering model 150 may be capable of detecting multiple types of content-pornography, visceral speech, bloody smell, and so forth. After being set by the user, the user preferences 152 may specify what types of content (if any) are to be filtered. Assuming that the user desires to filter pornography only, content identified as dirty or bloody fish will not be filtered.
In some implementations and depending on the user preferences 152, the particular digital content will not be presented to the user at all when it is determined that the particular digital content is to be filtered. In other implementations, particular digital content may be processed and a modified, filtered version of the image presented to the user. For example, particular digital content may be blurred, pixelated, muted, or otherwise attenuated before presentation to a user.
These different operations are filtering operations performed by the filtering model 150 at the OS level. For example, the filtering model 150 may access a library of filtering operations, such as for blurring of images and videos, for muting of audio, and for deletion or blurring of text. Thus, the image and video to be filtered are blurred, the audio to be filtered is muted, and the text to be filtered is deleted or blurred.
In some implementations, when presenting filtered content, the user can select the filtered content to present the content. For example, in the case of an image or text, the user may select a blurred image or text, and the blurred content will be presented. Alternatively, a particular user may be assigned an administrator role, and if the user is not an administrator, the ability to present filtered content will not be available to the user. In some implementations, the filtering model 150 can update itself based on the user's actions to view the originally filtered digital content.
Fig. 2 is a block diagram illustrating an example chat application in which a sender is sending digital content from a user device 210 to a recipient at a user device 220. The two user devices 210 and 220 are connected by a network 230 so that digital content can be transferred from one device to the other. Network 230 includes a Local Area Network (LAN), a Wide Area Network (WAN), the Internet, or a combination thereof. In some implementations, the chat application and network 230 can enable more than two user devices to communicate over the network, where multiple user devices can simultaneously send and receive digital content.
A sender uses user device 210 to send digital content to a recipient on user device 220. The sender first transmits an image 252 of the tree, which is transmitted over the network 230. In some implementations, the chat application can encrypt the image 252 so that the chat application on the recipient's user device can decrypt it. When the chat application executing on the recipient's user device 220 receives the encrypted image 252, the chat application decrypts the encrypted image 252 to recover the image 262. The chat application on device 220 provides image 262 to filtering model 150. When the filtering model 150 determines that the image 262 is not to be filtered, the image 262 is presented on a display of the user device 220 for presentation to the recipient. More generally, the above examples show that any data received in encrypted form and then decrypted by an application may be examined for filtering after decryption and before rendering.
The sender again uses the user device 210 to send the image 254 to the recipient over the network 230. After decryption, the chat application on device 220 provides image 264 to filtering model 150. When the filtering model 150 determines that the image 264 is to be filtered (e.g., the image depicts content that the user of the user device 220 has specified for filtering in the user preferences 152), the image 264 is rendered on the display along with the opaque layer 266 on the image such that the image is occluded from presentation to the recipient. As described above, in some implementations, filtered content may be presented. For example, in some embodiments, the opaque layer 266 is selectable and the user may select the opaque layer to view the image 264.
With respect to text data, the filtering model 150 may process the text data and detect text in the image, such as by optical character recognition. The filtering model 150 may include a semantic interpretation model to identify and extract meaningful textual data. Upon receiving text data, the semantic interpretation model utilizes a semantic detection algorithm to extract the meaning associated with the text. The filtering model 150 may then determine whether the semantic interpretation of the content item is a prohibited semantic interpretation, such as listed in a prohibited semantic interpretation list. If so, the text may be filtered.
In some implementations, the filtering model 150 can further include an emotion (sentiment) analysis model to determine emotions associated with the text data. In some implementations, the models are based on machine learning algorithms that include parameters adjusted to learn rules of natural language by training on a set of examples (such as a large corpus or a collection of sentences), and perform statistical inference. After performing the text analysis and extracting the meaning of the text data, the filtering system determines whether to filter the text data based on user preferences. For example, textual content related to a sexual or regulated substance may be filtered based on user preferences.
In some implementations, the model 150 can be trained to identify portions of text to filter. These portions may be identified by content title or topic identifier. For example, the article may include a title "playthrough alert" indicating that the text following the title includes a playthrough of a movie. For example, the model 150 may be trained to filter all text in the article following the "drama alarm" heading. Other text filters may include filtering based on words matching prohibited words.
With respect to audio, the filtering model 150 may process audio to detect speech and other types of content (e.g., different styles of music, such as classical, country, jazz, metal, etc.). For example, a music application 126 executing within the application level 120 may use the speaker system 180 to play audio songs. The user may desire to filter the lyrics without pruning. In such an embodiment, the filtering model 150 would process the audio data to detect non-truncated words. After determining that a particular word in the song is non-abridged, and based on user preferences, the filtering system 150 may filter out the words, such as by suppressing audio or adding a censored beep effect in place of the word while music is playing on the user device 100.
In other implementations, the content may be tagged with descriptors that describe the content, and the model 150 may determine the content based on the tags.
FIG. 3 is a flow diagram of an example process 300 for filtering digital content generated by an application executing at the application level. Process 300 is implemented in a computer system, such as user device 100 implementing model 150.
After the filtering model 150 receives the digital content as input, the process 300 determines whether to render or filter the digital content (320). If process 300 determines that the content is to be presented, the process presents the digital content to the user (330). For example, upon determining that digital content to be presented in the user interface of application 120 is not to be filtered, the digital content is provided as input to I/O system 160. The I/O system 160 then renders the digital content on the display system 170 for presentation to the user.
If the digital content is determined to be filtered, process 300 presents an optional opaque layer on the digital content or portion of the digital content that is determined to be inappropriate (340). For example, after the user device 210 receives the image 254, and upon determining that the image 254 is to be filtered, the filtering system 150 presents an optional opaque layer 266 over the image for presentation, thereby obscuring inappropriate content. Other filtering methods include not presenting the content at all, or blurring, pixelating, pruning, or otherwise weakening the content before it is presented to the user.
When presenting an opaque layer over the filtered content, the user may desire to see the filtered content. Upon selection of the opaque layer, the user may be provided with the option to view the unchanged digital content. Based on the user's actions, the filtering system may update the user preferences (350). In some implementations, the user preferences may be independent of user feedback, where the user may specify filtering parameters that do not change based on user actions.
Where the systems discussed herein collect or may utilize personal information about a user, the user may be provided with an opportunity to control whether applications or features collect user information (e.g., information about the user's social network, social actions or activities, profession, the user's preferences, or the user's current location), or whether and/or how to receive content that may be more relevant to the user. In addition, certain data may be processed in one or more ways to remove personal identity information before it is stored or used. For example, the identity of the user may be processed such that personally identifiable information for the user cannot be determined, or the geographic location of the user at which the location information is obtained (such as a city, zip code, or state level) may be generalized such that a particular location of the user cannot be determined. Thus, the user may control how the content server collects and uses information about the user.
Embodiments of the subject matter and the operations described in this specification can be implemented in the following: digital electronic circuitry, or computer software, firmware, or hardware (including the structures disclosed in this specification and their structural equivalents), or combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on computer storage media for execution by, or to control the operation of, data processing apparatus.
The computer storage medium may be or be included in: a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more thereof. Further, while a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage medium may also be or be included in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification may be implemented as operations performed by data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple ones or combinations of the foregoing. The apparatus can comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment may implement a variety of different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with the instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Further, the computer may be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), to name a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and storage devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; as well as CDROM and DVD-ROM discs. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having: a display device for displaying information to a user, such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor; and a keyboard and a pointing device, such as a mouse or a trackball, by which a user can provide input to the computer. Other types of devices may also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. Further, the computer may interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on the user's user device in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes: a back-end component, e.g., as a data server; or include middleware components, such as application servers; or include a front-end component, such as a user computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification; or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network ("LAN") and a wide area network ("WAN"), the internet (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing system may include a user and a server. A user and server are generally remote from each other and typically interact through a communication network. The relationship of user and server arises by virtue of computer programs running on the respective computers and having a user-server relationship to each other. In some embodiments, the server transmits data (e.g., an HTML page) to the user device (e.g., for purposes of displaying data to a user interacting with the user device and receiving user input from the user). Data generated at the user device (e.g., a result of the user interaction) may be received at the server from the user device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any features or of what may be claimed, but rather as descriptions of features specific to particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Further, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some implementations, multitasking and parallel processing may be advantageous.
Claims (17)
1. A computer-implemented method, comprising:
accessing, at a user device, data comprising a plurality of content items to be presented by an application executing on the user device;
prior to presentation of the content by the application:
for each content item, determining, at a user device and by a filtering model, whether the content item is presented by the application or filtered by the filtering model;
for each content item determined to be presented by the application, allowing the application to present the content item; and is provided with
For each content item determined to be filtered, preventing presentation of the content item by the application through the filtering model at the user device and through system-level filtering operations performed at an operating system level and separate from an application level at which the application is executed.
2. The computer-implemented method of claim 1, wherein accessing, at the user device, data comprising a plurality of content items to be presented by the application executing on the user device comprises:
capturing, from the application, a content item that has been processed by the application for presentation by the application.
3. The computer-implemented method of claim 2, wherein capturing, from the application, the content item that has been processed by the application for presentation by the application comprises: capturing the content item that the application has decrypted.
4. The computer-implemented method of claim 2, wherein capturing, from the application, the content item that has been processed by the application for presentation by the application comprises: textual data to be presented by the application in a graphical user interface is captured, and each content item is one of a word or a phrase.
5. The computer-implemented method of claim 4, wherein determining, at the user device and by the filtering model, whether the content item is presented by the application or filtered by the filtering model comprises:
determining whether the content item is a prohibited content item listed in a prohibited content item list; and
determining that the content item is to be filtered by the filtering model when the content item is determined to be a prohibited content item listed in the prohibited content item list.
6. The computer-implemented method of claim 4, wherein determining, at the user device and by the filtering model, whether the content item is presented by the application or filtered by the filtering model comprises:
performing semantic interpretation on the content item according to the semantic interpretation model;
determining whether the semantic interpretation of the content item is a prohibited semantic interpretation listed in a prohibited semantic interpretation list;
content items determined to have words and phrases determined to be semantic interpretations of prohibited semantic interpretations listed in the list of prohibited semantic interpretations are filtered.
7. The computer-implemented method of claim 4, wherein filtering presentation of the content item by the application through a filtering model at the user device and through system-level filtering operations performed at an operating system level and separate from an application level executing the application comprises:
rendering an opaque layer only on the words or phrases determined to be filtered.
8. The computer-implemented method of claim 7, wherein:
opaque layers are optional; and
in response to selection of the opaque layer, the filtering model removes the opaque layer and presents the word or phrase determined to be filtered.
9. The computer-implemented method of claim 2, wherein capturing, from the application, the content item that has been processed by the application for presentation by the application comprises: image or video data to be presented by the application in a graphical user interface is captured.
10. The computer-implemented method of claim 9, wherein determining, at the user device and by the filtering model, whether the content item is presented by the application or filtered by the filtering model comprises:
determining a content item tag describing a subject of the content of the image or video;
determining, based on the subject matter of the content item, whether the content item is a prohibited content item listed in a prohibited content item list;
determining that the content item is to be filtered by the filtering model when the content item is determined to be a prohibited content item listed in the prohibited content item list.
11. The computer-implemented method of claim 9, wherein determining, at the user device and by the filtering model, whether the content item is presented by the application or filtered by the filtering model comprises:
performing image processing on the image or video to determine a subject of the content of the image or video;
determining whether the content item is a prohibited content item listed in a prohibited content item list based on the topic of the content item;
determining that the content item is to be filtered by the filtering model when the content item is determined to be a prohibited content item listed in the prohibited content item list.
12. The computer-implemented method of claim 9, wherein filtering presentation of the content item by the application through the filtering model at the user device and through the system-level filtering operations performed at the operating system level and separate from an application level at which the application is executed comprises:
rendering an opaque layer only on the image or video determined to be filtered.
13. The computer-implemented method of claim 12, wherein:
the opaque layer is optional; and
in response to selection of the opaque layer, the filtering model removes the opaque layer and presents the image or video determined to be filtered.
14. The computer-implemented method of claim 2, wherein capturing, from the application, the content item that has been processed by the application for presentation by the application comprises: audio data to be rendered by the application through audio output is captured.
15. The method of claim 1, wherein the filtering model is a predefined model, and wherein:
filtering, by the filtering model at the user device and by the system-level filtering operations performed at the operating system level and separate from an application level executing the application, presentation of the content item by the application comprises:
presenting an optional opaque layer only on content items determined to be filtered;
in response to selection of the opaque layer:
the filtering model removes the opaque layer and presents the content determined to be filtered; and
updating the filtering model based on the selection.
16. A system, comprising:
a user equipment comprising data processing means; and
a non-transitory computer readable medium storing instructions executable by the data processing apparatus and that, upon such execution, cause the data processing apparatus to perform operations comprising:
accessing, at the user device, data comprising a plurality of content items to be presented by an application executing on the user device;
prior to presenting the content by the application:
for each content item, determining, at the user device and by a filtering model, whether the content item is presented by the application or filtered by the filtering model;
for each content item determined to be presented by the application, allowing the application to present the content item; and
for each content item determined to be filtered, preventing presentation of the content item by the application through the filtering model at the user device and through a system level filtering operation performed at an operating system level and separate from an application level at which the application is executed.
17. A non-transitory computer-readable medium storing instructions executable by data processing apparatus of a user device and, upon such execution, causing the data processing apparatus to perform operations comprising:
accessing, at the user device, data comprising a plurality of content items to be presented by an application executing on the user device;
prior to presentation of the content by the application:
for each content item, determining, at the user device and by a filtering model, whether the content item is presented by the application or filtered by the filtering model;
for each content item determined to be presented by the application, allowing the application to present the content item; and
for each content item determined to be filtered, the application is prevented from rendering the content item by the filtering model at the user device and by system-level filtering operations performed at an operating system level and separate from an application level at which the application is executed.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/022695 WO2021183140A1 (en) | 2020-03-13 | 2020-03-13 | System for filtering displayed content at the os level |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115315687A true CN115315687A (en) | 2022-11-08 |
Family
ID=70277476
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080098486.0A Pending CN115315687A (en) | 2020-03-13 | 2020-03-13 | System for filtering displayed content at Operating System (OS) level |
Country Status (4)
Country | Link |
---|---|
US (1) | US20230096274A1 (en) |
EP (1) | EP4111305A1 (en) |
CN (1) | CN115315687A (en) |
WO (1) | WO2021183140A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20230028296A1 (en) * | 2021-07-26 | 2023-01-26 | Automated Controversy Detection, Inc. | Methods and systems for redaction and display of topic-filtered data |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060075507A1 (en) * | 2001-09-06 | 2006-04-06 | Sonic Solutions | Secure protocols for use with microsoft directshow filters |
US20130117464A1 (en) * | 2011-11-03 | 2013-05-09 | Microsoft Corporation | Personalized media filtering based on content |
EP3278251B1 (en) * | 2015-08-12 | 2024-04-10 | Samsung Electronics Co., Ltd. | Method for masking content displayed on electronic device |
BR102016007265B1 (en) * | 2016-04-01 | 2022-11-16 | Samsung Eletrônica da Amazônia Ltda. | MULTIMODAL AND REAL-TIME METHOD FOR FILTERING SENSITIVE CONTENT |
US10031977B1 (en) * | 2017-01-26 | 2018-07-24 | Rena Maycock | Data content filter |
US20200065864A1 (en) * | 2018-08-27 | 2020-02-27 | Oath Inc. | System and method for determining emotionally compatible content and application thereof |
US20220277435A1 (en) * | 2021-03-01 | 2022-09-01 | Kyndryl, Inc. | Cognitive filtering of content from shared screen display |
-
2020
- 2020-03-13 US US17/909,894 patent/US20230096274A1/en active Pending
- 2020-03-13 EP EP20718445.8A patent/EP4111305A1/en active Pending
- 2020-03-13 CN CN202080098486.0A patent/CN115315687A/en active Pending
- 2020-03-13 WO PCT/US2020/022695 patent/WO2021183140A1/en unknown
Also Published As
Publication number | Publication date |
---|---|
EP4111305A1 (en) | 2023-01-04 |
US20230096274A1 (en) | 2023-03-30 |
WO2021183140A1 (en) | 2021-09-16 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11488070B2 (en) | Iterative classifier training on online social networks | |
JP6568609B2 (en) | Grammar model for structured search queries | |
Russell | Mining the social web: data mining Facebook, Twitter, LinkedIn, Google+, GitHub, and more | |
US10223464B2 (en) | Suggesting filters for search on online social networks | |
JP5970624B1 (en) | Filter suggestions for structured queries on online social networks | |
US9338047B1 (en) | Detecting content on a social network using browsing patterns | |
US8032527B2 (en) | Search filtering | |
WO2017080400A1 (en) | Information recommendation method and device | |
KR20110063752A (en) | Content recommendations based on browsing information | |
KR20190064641A (en) | Creating recommendations using the Deep Learning model | |
Kröger et al. | Is my phone listening in? On the feasibility and detectability of mobile eavesdropping | |
EP3814958A1 (en) | Dynamic application content analysis | |
CN115210692A (en) | Interface and mode selection for digital motion execution | |
US20120151381A1 (en) | Defining actions for data streams via icons | |
Le et al. | Skillbot: Identifying risky content for children in alexa skills | |
Buzzi | Children and YouTube: access to safe content | |
Li et al. | Privacy-preserving script sharing in gui-based programming-by-demonstration systems | |
US20230096274A1 (en) | System for filtering displayed content at the os level | |
Gisdakis et al. | Android privacy C (R) ache: reading your external storage and sensors for fun and profit | |
US20220292144A1 (en) | Provision of different content pages based on varying user interactions with a single content item | |
Adak et al. | Mining the online infosphere: A survey | |
JP2022527671A (en) | Mute content across platforms | |
Solanki et al. | MapperDroid: Verifying app capabilities from description to permissions and API calls | |
Ma et al. | “Hello, Fellow Villager!”: Perceptions and Impact of Displaying Users’ Locations on Weibo | |
US20230176843A1 (en) | App Store Information Page Customization |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |