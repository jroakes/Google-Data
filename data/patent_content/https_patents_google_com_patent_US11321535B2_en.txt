US11321535B2 - Hierarchical annotation of dialog acts - Google Patents
Hierarchical annotation of dialog acts Download PDFInfo
- Publication number
- US11321535B2 US11321535B2 US16/337,830 US201716337830A US11321535B2 US 11321535 B2 US11321535 B2 US 11321535B2 US 201716337830 A US201716337830 A US 201716337830A US 11321535 B2 US11321535 B2 US 11321535B2
- Authority
- US
- United States
- Prior art keywords
- annotation
- root
- dialog
- records
- record
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/22—Indexing; Data structures therefor; Storage structures
- G06F16/2228—Indexing structures
- G06F16/2246—Trees, e.g. B+trees
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/011—Arrangements for interaction with the human body, e.g. for user immersion in virtual reality
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/31—Indexing; Data structures therefor; Storage structures
- G06F16/316—Indexing structures
- G06F16/322—Trees
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/12—Use of codes for handling textual entities
- G06F40/137—Hierarchical processing, e.g. outlines
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/169—Annotation, e.g. comment data or footnotes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
- G06F40/35—Discourse or dialogue representation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/01—Dynamic search techniques; Heuristics; Dynamic trees; Branch-and-bound
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L13/00—Speech synthesis; Text to speech systems
- G10L13/02—Methods for producing synthetic speech; Speech synthesisers
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1822—Parsing for meaning understanding
Definitions
- Computing devices can include an electronic assistant that responds to verbal communications of a user of the computing device in a conversational manner.
- the user may speak something that the electronic assistant responds to, e.g., via synthesized speech using audio output.
- the response by the electronic assistant may include a question for the user to respond to.
- the user and the computing device may engage in a conversation.
- the conversation can result in the electronic assistant performing a task or may just be interactional (e.g., telling a joke or providing insight).
- Implementations provide a system for annotating conversations between a user and an electronic assistant in a hierarchical manner that can be used to improve the quality of the electronic assistant over time (e.g., by improving ranking signals used in machine learning).
- Implementations provide a flexible hierarchical structure for describing the conversation and relating dialog acts—both the user's and the electronic assistant's—over the course of the conversation.
- Each dialog act may be represented as a separate tree in the conversation with annotations modeled as nodes in the tree and arcs connecting nodes in different trees that have an interrelationship.
- child nodes identify parent nodes.
- Some implementations may include post-processing of the annotation records, i.e., an offline mode, to add information to the annotation records not available in an online mode, i.e., when the records in the hierarchical structure are generated.
- Such information may include the links between responses and requests that cannot be made with information available in real-time.
- a method may include generating a first annotation tree for an annotated dialog act.
- the first annotation tree includes a root node for the dialog act and leaf nodes for each non-null annotation tag for the dialog act.
- the dialog act is associated with a conversation identifier.
- the leaf nodes of the first annotation tree including a previous discourse node corresponding to a previous discourse tag in the annotated dialog act.
- the method also includes generating an annotation identifier for each node in the first annotation tree, the annotation identifiers being unique within the conversation identifier.
- the method can also include writing an annotation record for each node.
- a record for the root node lacks a parent identifier; a record for non-root nodes include a parent identifier, the parent identifier referencing the annotation identifier of the parent; and the record for the previous discourse node including an annotation identifier for a corresponding subsequent discourse node, the subsequent discourse node being a leaf node in a second annotation tree also associated with the conversation identifier.
- Generating the annotation tree for the annotated dialog act may include: determining that a first subordinate dialog act and a second subordinate dialog act share a common tag and a common parent; and inserting a node in the annotation tree that is a child of a node for the common parent and is a parent of a node for the first subordinate dialog act, of a node for the second subordinate dialog act, and of a node for the common tag, wherein the node for the first subordinate dialog act and the node for the second subordinate dialog act each lack a child node corresponding to the common tag.
- the method may further comprise accessing the annotation records in response to a query and returning annotation records determined to be responsive to the query.
- the method may further comprise accessing the annotation records to generate training examples for a dialog management engine; and training the dialog management engine using the training examples.
- the method may further comprise accessing the annotation records to identify failure patterns.
- the annotation record for each node may include text corresponding to the node.
- the annotation records may be stored in an unordered list.
- the first annotation tree may represent a first turn in the conversation and the second annotation tree may represent a second turn in the conversation, the first turn and the second turn may be separated by at least one intervening turn.
- the record for the root node may include an indication of a speaker for the dialog act.
- the record for the root node and at least some of the plurality of non-root records may further include an indication of a speaker for the dialog act.
- the annotation tag may be selected from the group including a subsequent discourse tag, a dialog act type, and a previous discourse tag.
- the annotation tag may be selected from the group including a subsequent discourse tag, a dialog act type, a dialog error type and a previous discourse tag.
- Non-root records having an annotation tag that represents a previous discourse tag may further include an annotation identifier of another annotation record, the other record having an annotation tag that represents a subsequent discourse tag.
- At least some of the non-root records further include an annotation tag.
- At least some of the annotation tags may represent a text span.
- At least one of the dialog acts may represent an operational action performed by a user.
- the method may further comprise receiving input dialog acts from a dialog input device and receiving output dialog acts for output via a dialog output device.
- a system comprising: at least one processor; a dialog input device; a dialog output device; and memory storing instructions that, when executed by the at least one processor performs operations including: receiving input dialog acts from the dialog input device and receiving output dialog acts for output via the dialog output device, and generating hierarchical annotation records for annotations of the input dialog acts and for annotations of the output dialog acts, wherein the hierarchical annotation records for a dialog act include: a root record specifying a conversation identifier and an annotation identifier, a plurality of non-root records including: an annotation identifier, and a parent identifier, the parent identifier being an annotation identifier of another record, wherein at least some of the non-root records further include an annotation tag.
- the root record may further include an indication of a speaker for the dialog act.
- the root record and at least some of the plurality of non-root records may further include an indication of a speaker for the dialog act.
- the annotation tag may be selected from the group including a subsequent discourse tag, a dialog act type, and a previous discourse tag.
- the annotation tag may be selected from the group including a subsequent discourse tag, a dialog act type, a dialog error, and a previous discourse tag.
- the non-root records may have an annotation tag that represents a previous discourse tag further include an annotation identifier of another annotation record, the other record having an annotation tag that represents a subsequent discourse tag.
- At least some of the annotation tags may represent a text span.
- At least one of the dialog acts may represent an operational action performed by a user of the system.
- the operations may also comprise determining that a first non-root record associated with a root record for a first conversation identifier links to a second non-root record associated with a root record for a second conversation identifier, generating a first new non-root record identifying the second non-root record in the parent identifier and having an annotation tag that represents a subsequent discourse, and generating a second new non-root record identifying the first non-root record in the parent identifier, having an annotation tag that represents a previous discourse and identifying the annotation identifier for the first new non-root record, wherein the first conversation identifier and the second conversation identifiers are not sequential.
- a system includes at least one processor, a dialog input device, a dialog output device, and a data store of hierarchical annotation records.
- the hierarchical annotation records include root records and non-root records. Each root record specifies a conversation identifier and an annotation identifier.
- Each non-root record includes an annotation identifier and a parent identifier, the parent identifier being an annotation identifier of another record. At least some of the non-root records further include an annotation tag.
- the system also includes memory storing instructions that, when executed by the at least one processor performs operations.
- the operations may include receiving an input dialog act from the dialog input device, generating a first new root record and first non-root records for the input dialog act, receiving an output dialog act for output via the dialog output device that is responsive to the input dialog act, and generating a second new root record and second non-root records for the output dialog act, at least one of the second non-root records including an annotation tag linking back to a record of the first non-root records.
- Linking back to a record of the first non-root records may include generating the record with a subsequent discourse tag, the record having a parent identifier of an existing first non-root record.
- the annotation tag may be selected from the group including a subsequent discourse tag, a dialog act type, and a previous discourse tag. At least some of the first non-root nodes may include a tag that represents a text span of the input dialog act.
- a computer program product embodied on a computer-readable storage device includes instructions that, when executed by at least one processor formed in a substrate, cause a computing device to perform any of the disclosed methods, operations, or processes.
- a system comprising at least one processor and a memory storing instructions that, when executed by the at least one processor performs operations in accordance with the methods, operations or processes as disclosed above.
- Another general aspect includes a system and/or a method for annotating dialog acts, substantially as shown in and/or described in connection with at least one of the figures, and as set forth more completely in the claims.
- annotation structure includes parent identifiers rather than children
- additional annotations can be added in real time and the dialog acts can be stored in an unordered list.
- the additional annotations can link a conversation that occurs over a long period, e.g., days.
- annotations can be added by multiple calls to a dialog manager, making the structure flexible.
- the structure also aids querying over annotation tags because the system captures interrelations between the system and user in a highly structured way.
- the annotation records can be queried for all questions answered with a “yes/no” answer in which the user also expressed a verbal sigh (which may be captured in an annotation tag) and, using the parent links, the dialog acts relating to these answers can be quickly identified and returned.
- a query may use the records to identify all abandoned conversations, e.g., a subsequent discourse tag that does not have a previous discourse tag. These conversations may be provided to a model that identifies a pattern to the conversations. The pattern may be provided to developers so to identify areas where the dialog acts of the electronic assistant can be improved.
- the hierarchical structure provides a smaller memory footprint by avoiding duplication of annotations. For example, an annotation that applies to multiple children in the tree can be stored once at the common parent rather than at each node.
- the hierarchical annotation records are theoretically sound and semantically correct. This allows implementations to be robust to any kind of dialog as opposed to being scoped to system-driven dialogs.
- the hierarchical annotation records disclosed herein which attach machine-readable semantics to dialog acts, enable high-precision processing of conversations.
- the hierarchical structure enables the system to pinpoint parts of the dialog act that correspond to specific annotations. Thus, for example, different parts of a complex, compound dialog act can be precisely annotated.
- annotations can be freely defined.
- the system supports annotations based on theoretical definitions, it can also support annotations generated by a specific dialog manager, making them flexible and customizable, which supports flexible querying and training.
- the hierarchical annotation schema also allows various annotations to be linked backwards, which enables easier post-processing and data collection. This contrasts with dialog metric tracking done on a turn-by-turn basis, with the assumption that a dialog acts are sequential, e.g., a dialog act on the N+1 turn is directly related to the dialog action the N turn.
- the unordered list nature of disclosed implementations allows a dialog act on the NA turn to be linked to any turn ⁇ N (e.g. not sequential). This enables generation of quantitative metrics for concepts such as “which previous interaction is the current user's dialog act referring to?” and “how long ago was that reference?” in real time as well as to analyze forward references in retrospect, e.g., identifying for some historical dialog act subsequent dialog acts that referred to the historical act in whole or in part. Such forward references are possible due to the unordered list nature of disclosed implementations.
- implementations offer a high level of precision, which is important for measuring quality correctly.
- improved device performance is a facet of the above description.
- the hierarchical organization of annotations for dialog makes the dialog searchable, e.g., via a search query over the tree, and reduces the need to search large corpuses of dialog for such annotations.
- Hierarchical annotation of dialog acts also provides a contextual framework for those annotations that would not otherwise be possible for the device processor to develop. This reduces demands on computation resources, memory usage, and battery use in a client or local device. In cases where a device is operated in client-server mode, this also reduces the client server communication demand and data usage.
- FIG. 1 is a block diagram illustrating an example system in accordance with the disclosed subject matter.
- FIG. 2 is a block diagram illustrating another example system in accordance with the disclosed subject matter.
- FIG. 3 is a block diagram illustrating an example of initial annotation trees for two dialog acts in a conversation, in accordance with the disclosed subject matter.
- FIG. 4 is a block diagram illustrating an example of final annotation trees for the dialog acts of FIG. 3 in accordance with the disclosed subject matter.
- FIG. 5 is a block diagram illustrating example hierarchical annotation records generated from the final tree-based annotation of FIG. 4 in accordance with the disclosed subject matter.
- FIG. 6 illustrates a flow diagram of an example process for generating records in a hierarchical annotation structure of conversational dialog acts, in accordance with disclosed implementations.
- FIG. 7 shows an example of a computer device that can be used to implement the described techniques.
- FIG. 8 shows an example of a distributed computer device that can be used to implement the described techniques.
- FIG. 9 shows an example flow diagram of an example process for assembling records in a hierarchical annotation structure of conversation dialog acts in response to receiving a query, in accordance with disclosed implementations.
- FIG. 1 is a block diagram of a conversational hierarchical annotation system in accordance with an example implementation.
- the system 100 may be used to generate annotation records in a flexible hierarchical schema.
- the depiction of system 100 in FIG. 1 is a single computing device but implementations may also move some of the components to a server, making system 100 a client-server system, as illustrated in more detail in FIG. 2 .
- one or more components may be combined into a single module or engine, and some capabilities of the illustrated components may be performed by separate engines.
- a user of the computing device may indicate that portions of the processing be performed at a server. The user may also control whether the hierarchical annotation records are stored and where such storage occurs. Thus, implementations are not limited to the exact configurations illustrated.
- the hierarchical annotation system 100 includes a computing device 105 .
- the computing device may be implemented in a personal computer, for example a laptop computer, a smartphone, a tablet, a desktop computer, a wearable device, a home appliance, etc.
- the computing device 105 may be an example of computer device 700 , as depicted in FIG. 7 .
- the computing device 105 may include one or more processors formed in a substrate (not illustrated) configured to execute one or more machine executable instructions or pieces of software, firmware, or a combination thereof.
- the processors can be semiconductor-based—that is, the processors can include semiconductor material that can perform digital logic.
- the computing device 105 can also include one or more computer memories.
- the memories may be configured to store one or more pieces of data, either temporarily, permanently, semi-permanently, or a combination thereof.
- the memories may include any type of storage device that stores information in a format that can be read and/or executed by the one or more processors.
- the memories may include volatile memory, non-volatile memory, or a combination thereof, and store modules or engines that, when executed by the one or more processors, perform certain operations.
- the modules may be stored in an external storage device and loaded into the memory of computing device 105 .
- the computing device 105 may include dialog input-output device(s) 110 .
- the dialog input/output devices 110 may include hardware that enables the electronic assistant 120 to receive input from the user 180 or provide a response to the user 180 .
- Input from the user may be vocal, e.g., in the form of speech.
- Input from the user may also be non-vocal, e.g., text provided by the user.
- the output can, similarly, be speech-based or text-based.
- Common dialog input/output devices include a microphone and speaker and/or a keyboard (virtual or physical) and a display.
- the hierarchical annotation system 100 is discussed primarily in the context of a spoken conversation using a microphone and speaker but implementations include other conversational modes, such as those held in a messaging application.
- the modules of the hierarchical annotation system 100 may include an electronic assistant 120 .
- the electronic assistant 120 may be configured to obtain input from the dialog input/output devices 110 , to process the input, and to provide a response to the dialog input/output devices 110 .
- the electronic assistant 120 may include a dialog management engine 122 , a speech engine 124 , and a dialog annotation engine 126 .
- the speech engine 124 can use a suitable speech-to-text process to convert received vocal inputs into a text string.
- a non-vocal input received as text may also be passed to the speech engine 124 (e.g., via typing other text selection).
- the non-vocal input may be text recognized in an image.
- a user 180 may take a photograph using a camera (not illustrated) communicatively connected to the computing device 105 and the image may be provided to the speech engine 124 .
- the speech engine 124 may perform recognition on the image to discover text to be used as input.
- the non-vocal input may be an entity recognized in the image.
- the speech engine 124 may perform entity recognition on the image to determine an entity from a knowledge base included in the image and use a description of the entity as text input.
- the input, whether vocal or non-vocal is referred to as a dialog act.
- a dialog act includes vocal input, non-vocal input, or a combination of vocal and non-vocal input.
- a dialog act can also include operational actions performed by a user.
- pressing a power-off button may be a dialog act.
- An output provided by the electronic assistant 120 is also a dialog act.
- the speech engine 124 may convert the output dialog act to a sound file that can be played by the input/output devices 110 or may provide text of the dialog act for display on input/output devices 110 .
- the dialog management engine 122 may manage one or more dialogs. This includes maintaining a state of the dialog, e.g., what question is being answered, so that the electronic assistant 120 can properly interpret received audio associated with the dialog. In particular, the accuracy of the electronic assistant 120 in correctly interpreting the received audio can be improved by knowing what type of response is requested by the user 180 . For example, the dialog management engine 122 may determine that the user has requested a task to be performed. The dialog management engine 122 may also include a machine-learning algorithm capable of conversing with the user, e.g., by generating a conversational response that does not respond to a specific task. Dialog management engine 122 can use conventional or later developed techniques to generate a response to the user. As indicated above, the response is also considered a dialog act.
- the electronic assistant 120 annotates the dialog act to mark important characteristics of the dialog act, such as whether the dialog act is a request, a statement, an answer to a request, not comprehendible, etc.
- DAMSL Dialog Act Markup in Several Layers. The following represents two dialog acts from a sample dialog between a user and an electronic assistant:
- the electronic assistant 120 may annotate the dialog acts as follows:
- DAE represents a DialogActError tag that records error information, such as whether the dialog act is intelligible and whether the dialog act was successfully completed.
- DAT represents a DialogActType tag that characterizes the semantic content of the dialog act.
- SD is a SubsequentDiscourse tag that captures the effect the dialog act may have on subsequent interactions and/or constrains the future beliefs and actions of the participants.
- PD is a PreviousDiscourse tag that is an indication of how the current dialog act relates to previous discourse.
- each dialog act (also referred to as an utterance, although the dialog act is not limited to vocal inputs and may include typewritten or recognition inputs as described above), may be divided into one or more subordinate dialog acts (e.g., sub-utterance) based on the characteristics of different portions of the dialog act.
- the electronic assistant's response is divided into three subordinate dialog acts. The first is an assertive statement, the second is a reasserted statement, and the third is an information request.
- Implementations can use any annotation scheme and is not limited to the use of the annotation tags or annotation scheme illustrated.
- implementations may include internal information about how the system generated a response for the electronic assistant.
- Implementations may also include annotations that represent links to external resources that were used when interpreting the user input or when generating the system response.
- Annotations may include attributes about the environment, e.g., whether it was noisy or quiet, whether the input was vocal or non-vocal, etc.
- Annotations can be any tag and value pair mapped to all or a portion of the dialog act.
- Annotations (the tag and its possible values) can be unique to, and defined by, a particular dialog manager within the electronic assistant 120 .
- different dialog managers operating with the electronic assistant 120 may define different annotations.
- the electronic assistant 120 may include a dialog annotation engine 126 , which may use the annotations to generate a hierarchical representation that can be stored in a machine-readable form as hierarchical annotation records 140 .
- This hierarchical representation can be used to derive insights for the electronic assistant 120 to improve the quality of the dialog acts provided by the electronic assistant 120 over time.
- the operation of the dialog annotation engine 126 may be controlled by the user 180 .
- the dialog annotation engine 126 may operate only with permission of the user.
- the hierarchical annotation records 140 generated with the user's permission can be used to train the dialog management engine 122 , creating a personalized engine that is specific to the user and recognizes his or her way of interacting with the electronic assistant.
- Such personalized training of the dialog management engine 122 provides higher quality responses from the electronic assistant 120 .
- the hierarchical annotation records 140 can be used to identify dialogs where users frequently ask multiple clarifying questions before advancing. Identifying such “hot spots” can lead to improving the prompt of the electronic assistant, so that the clarifying questions are not needed.
- annotated dialog records may be provided to a machine learning algorithm trained to identify such ‘hot spots’ and suggest or generate an appropriate fix to the prompt.
- a machine-learning algorithm may be used to identify forward references, e.g., for a particular dialog act, one or more subsequent dialog acts that refer back to the particular dialog act in whole or in part.
- the system 100 may also aggregate hierarchical annotation records 140 across many users to drive general purpose quality improvements.
- the system 100 may also use the hierarchical annotation records 140 to create a more helpful graphical user interface that indicates to the user that part of the system response is intending to refer back to a previous dialog act, even if it was not immediately preceding the response.
- the dialog annotation engine 126 may start with the annotated utterance and generate a node for each utterance, each sub-utterance, and each annotation flag. This generates a tree-based structure for the utterance.
- FIG. 3 illustrates a block diagram of an example annotation tree 305 of the example user utterance and an annotation tree 320 for the electronic assistant utterance disclosed above.
- all annotation tags are listed as leaf nodes of the utterance or sub-utterance they apply to.
- the dialog annotation engine 126 may prune any leaf nodes corresponding to null annotation tags.
- all DAE annotation tags are empty and their corresponding nodes would be removed, or would never be generated.
- the dialog annotation engine 126 may move any leaf nodes for annotation tags that are common to all children to the parent. Because the DAT tag for sub-utterance nodes 330 , 335 , and 340 applies to each child, the dialog annotation engine 126 may move the leaf node up a level to the parent utterance node 325 . In some implementations, the dialog annotation engine 126 may generate a sub-utterance when some but not all children have an annotation flag in common.
- sub-utterance node 330 and sub-utterance node 335 both share a previous discourse tag that refers back to the same inquiry node.
- the dialog annotation engine 126 may add a level to the tree, making node 330 and node 335 the children on a common parent sub-utterance node, which is a child of node 325 .
- the common tag, PD may become a leaf node of the common parent node.
- the finalized annotation trees 305 and 320 are illustrated in FIG. 4 .
- the parent node 325 of tree 320 has a DAT tag node as a leaf node, which means it applies to all sub-utterance nodes for the parent.
- the sub-utterance node 345 has been inserted and is the parent of sub-utterance nodes 330 and 335 .
- the leaf node for the previous discourse tag is associated with the sub-utterance node 345 , so it applies to both sub-utterance node 330 and sub-utterance node 335 . All leaf nodes corresponding to null or empty tags have been removed.
- the dialog annotation engine 126 has added a link 405 from the previous discourse node to the subsequent discourse node that it corresponds to.
- the dialog annotation engine 126 has linked the two trees in the context of the conversation.
- node 345 would not be generated and node 330 and node 335 would keep their respective PD nodes.
- the dialog annotation engine 126 adds a second link, which links the PD node of the sub-utterance node 335 to its corresponding SD node.
- the annotation trees of FIGS. 3 and 4 illustrate, the arrows point upwards, from the children to the parent. This reference to the parent allows the annotations to be preserved as an unordered list.
- the root of an annotation tree is a node without a parent.
- FIG. 5 is a block diagram illustrating example hierarchical annotation records generated from the final tree-based annotation of FIG. 4 in accordance with the disclosed subject matter.
- the hierarchical annotation records of FIG. 5 are examples of hierarchical annotation records 140 of FIG. 1 and FIG. 2 .
- Each record may have different attributes depending on its function in the tree.
- the conversation identifier may be generated by the electronic assistant 120 at the start of the conversation. This identifier may be used for the lifetime of the conversation.
- a conversation may be defined differently by different electronic assistants and can be context based.
- the dialog annotation engine 126 uses the conversation identifier provided by the electronic assistant 120 .
- the dialog annotation engine 126 logs the conversation identifier once for each turn.
- the conversation identifier can be included in the root node of the annotation tree because the annotation tree represents one turn in the conversation.
- the conversation identifier could also be stored in each annotation record, although this uses additional memory resources but could speed some queries.
- the conversation identifier is not included in any annotation records
- Each root node may also include an indication of the speaker.
- Each tree represents a turn, or dialog act, taken by one of the speakers in the conversation.
- the speaker identifier may be included only in the root node, which represents the entire dialog act, although in some implementations the speaker can be identified in subordinate acts as well. Including the speaker in each node uses more memory resources but can result in improved query processing speed. Whether to include the speaker or other characteristics common in each node rather than in the parent node is a tradeoff between memory usage and query speed.
- Each node in the annotation tree e.g., utterance, sub-utterance, or tag
- each annotation record has an ID unique to the record.
- This identifier is generated in real-time, e.g., as the conversation is ongoing, and is referred to as the annotation identifier.
- Records for nodes that are not the root node each has a parent identifier, which includes the annotation identifier of the parent node.
- each record that is not a root node includes attributes that identify the node.
- the record with annotation identifier 1113 indicates the node is for a DAT tag and includes the value of the DAT tag.
- the record with annotation identifier 1116 indicates the node is for a previous discourse (PD) tag and includes the value for that tag.
- the node includes the annotation identifier of the subsequent discourse node that corresponds to the previous discourse tag.
- the link 405 of FIG. 4 between the response (PD) and the request (SD) is recorded in the PD node as the annotation identifier of the corresponding SD node.
- the dialog annotation engine 126 creates a structure that links the annotation trees and provides context for the conversation. This context can help the electronic assistant learn how to better respond to the user. For example if a user responds to a question by the electronic assistant with a question, this may be an indication that the question was unclear. This knowledge can be used to change the dialog flow in future dialogs.
- the text span corresponding to a dialog act node or a subordinate dialog act node may be included in the annotation record. Such inclusion is optional. As illustrated in FIG. 5 , no order in the annotation records is assumed.
- annotation records are an unordered list.
- the inclusion of the parent identifier is what makes the hierarchical structure discoverable.
- the annotation records may include additional information not illustrated in FIG. 5 .
- a particular dialog manager may include information in one or more of the dialog act or subordinate dialog act nodes as part of an extension to the annotation schema.
- the structure is customizable for various dialog tasks.
- the dialog annotation engine may store the annotation records, e.g., the records illustrated in FIG. 5 , to a data storage device, such as hierarchical annotation records 140 .
- the hierarchical annotation records may then be available for querying or training of models for the electronic assistant 120 .
- FIG. 2 is a block diagram illustrating another example system in accordance with the disclosed subject matter.
- the example hierarchical annotation system 100 of FIG. 2 includes a client device 205 and a server 207 .
- the client device 205 is similar to the computing device 105 of FIG. 1 but includes an electronic assistant client 210 rather than the fully-functional electronic assistant 120 .
- the electronic assistant client 210 can include some of the functionality of the electronic assistant 120 , for example a speech engine 124 that converts audio input from the user 180 to text.
- the electronic assistant client 210 may provide the input from the user to the server 207 via a network, such as network 250 .
- Network 250 may be for example, the Internet, or the network 250 can be a wired or wireless local area network (LAN), wide area network (WAN), etc., implemented using, for example, gateway devices, bridges, switches, and/or so forth. Network 250 may also represent a cellular communications network. Via the network 250 , the server 207 may communicate with and transmit data to/from client devices 205 and 208 , and client device 205 may communicate with other client devices 208 (not shown). Client device 208 may include components similar to those described in regards to client device 205 .
- LAN local area network
- WAN wide area network
- Network 250 may also represent a cellular communications network.
- the server 207 may communicate with and transmit data to/from client devices 205 and 208
- client device 205 may communicate with other client devices 208 (not shown).
- Client device 208 may include components similar to those described in regards to client device 205 .
- the server 207 may be a computing device or devices that take the form of a number of different devices, for example a standard server, a group of such servers, or a rack server system.
- server 207 may be implemented in a distributed manner across multiple computing devices.
- server 207 may be implemented in a personal computer, for example a laptop computer.
- the server 207 may be an example of computer device 700 , as depicted in FIG. 7 , or system 800 , as depicted in FIG. 8 .
- the server 207 may include an electronic assistant 220 that includes at least some of the functionality of the electronic assistant 120 of FIG. 1 .
- the electronic assistant 220 may include the dialog annotation engine 126 and the dialog management engine 122 .
- the server 207 may store the hierarchical annotation records 140 .
- the server 207 may be in communication with multiple client devices, e.g., client device 205 and client device 208 , via the network 250 .
- the hierarchical annotation system 100 represents one example configuration and implementations may incorporate other configurations. For example, some implementations may combine one or more of the components of the dialog annotation engine 126 , the dialog management engine 122 , and the speech engine 124 a single module or engine. Furthermore, one or more of the components of the electronic assistant 220 , the dialog annotation engine 126 , the dialog management engine 122 , the speech engine 124 , and/or the electronic assistant client 210 may be combined into a single engine. In addition, the hierarchical annotation records may be distributed across multiple computing devices, or may be stored at the client device 205 . Thus implementations are not limited to the exact configurations illustrated.
- the users may be provided with an opportunity to control whether programs or features collect the user information or to control whether and/or how to receive content that may be more relevant to the user.
- certain data may be treated in one or more ways before it is stored or used, so that personally identifiable information is removed.
- search records may be treated so that no personally identifiable information can be determined and/or a user's geographic location may be generalized where location information is obtained (such as to a city, ZIP code, or state level), so that a particular location of a user cannot be determined.
- location information such as to a city, ZIP code, or state level
- FIG. 6 illustrates a flow diagram of an example process 600 for generating records in a hierarchical annotation structure of conversational dialog acts, in accordance with disclosed implementations.
- Process 600 may be performed by a hierarchical annotation system, such as system 100 of FIG. 1 or system 200 of FIG. 2 .
- Process 600 may be used to generate hierarchical annotation records for a dialog, which can be easily searched and used to improve the quality of an electronic assistant that engages with the user in a conversation.
- the order of the steps in process 600 is exemplary and the order can be re-arranged, some steps may be combined, and some steps may be optional.
- Process 600 may begin with an annotated dialog act ( 605 ).
- the dialog act represents a turn taken by one speaker who is party to a conversation.
- the dialog act can originate from a user or from an electronic assistant.
- the annotation includes tags that characterize all or part of the dialog act.
- the annotation is similar to the DAMSL dialog annotation protocol.
- the system may create a node in an annotation tree for each dialog act and for each subordinate dialog act, connecting the subordinate dialog act to its parent ( 610 ). Each root node may be given a conversation identifier, which identifies the conversation the dialog act belongs to.
- the system may also generate a leaf node for some or all of the annotation tags.
- the annotation tag nodes point to the dialog act or subordinate dialog act to which they apply.
- the system if it generated nodes for null tags may prune those tags from the annotation tree ( 615 ). Null tags typically convey no useful information and need not be tracked.
- the system may identify leaf nodes for annotation tags that apply to more than one subordinate dialog act node and may move the leaf node from the children to the parent ( 620 ), thereby reducing the number of leaf nodes. For example, when every subordinate dialog act has a node that represents the same tag and the same value for the tag, the system may remove the node for the tag from each child node and generate a respective node that is dependent on the parent node.
- the system may generate a new subordinate dialog act node when two or more, but less than all children of an dialog act or subordinate dialog act node share an annotation tag with the same value.
- the system generates subordinate dialog act node 345 of FIG. 4 and makes subordinate dialog act node 330 and subordinate dialog act node 345 children of node 345 , while also moving the PD node from nodes 330 and 335 to node 345 in the annotation tree 320 of FIG. 4 .
- the system may assign an annotation identifier to each node ( 625 ) that is unique within the conversation.
- the system may also map a child node to its parent ( 630 ), e.g., by recording the parent annotation identifier in attributes of the child node.
- the system may also link any previous discourse nodes to their corresponding subsequent discourse node in another annotation tree ( 635 ).
- the system may generate an annotation record for each node ( 640 ), storing the annotation records in a data store.
- the system may include a process that runs periodically to add information to the annotation records.
- the system may not have all the information it needs in real-time to make the links from the responses (e.g., the previous discourse nodes) to their corresponding requests (e.g., SD nodes). This can occur, for example when a user switches context in a conversation but then returns to the original context. Finding the correct request can require more processing time than a real-time linkage would allow or may be impossible in real-time.
- a user may refer back to a task included in a dialog act from the previous week.
- the SD tag (subsequent discourse) may have been null or characterized differently. Only with the benefit of hindsight can the SD tag be added to the older annotation tree.
- the system may perform additional analysis on a periodic basis (e.g., nightly, hourly, weekly) in an “offline” or “batch” mode to add the links (step 635 ) to the annotation records.
- additional information may include annotations that indicate additional actions taken by the user, such as pressing a power-off button to terminate the conversation.
- additional information may include adding or changing the tags for a dialog act, e.g., adding an SD tag with the benefit of hindsight.
- the system may provide sample annotation records for a conversation to a human rater who verifies that the links are proper.
- the offline or batch processing may also be part of a quality analysis process that identifies areas of improvement in the dialog generated by the system, when users have given permission for such analysis.
- the labels and hierarchical nature of the annotation records allow for targeted, specific queries of the records.
- the hierarchical, unordered annotation records can be queried to identify particular areas of failure.
- the annotation records can be queried to identify the most frequently corrected information fields in an action, e.g., identifying from ten data fields in a restaurant reservation, which information field is corrected most often as part of the reservation action.
- the annotation records can be queried to identify situations where the user responds to a question with a question rather than a statement, or responds with an answer but asks a follow-on question.
- annotation records may be shared with a server, after removing any personally identifying information, so that patterns can be identified across users.
- the annotation records can be provided to machine-learned models to identify patterns of failure, e.g., assistant responses which led to questions, abandonment, or verbal indications of annoyance (e.g., a sigh). Identifying these bottleneck and failure patterns can help developers of the electronic assistant identify and improve specific functionality in the electronic assistant, which improves dialog responses and interactions with the user. The linkages in the annotation records make such analysis possible.
- FIG. 7 shows an example of a generic computer device 700 , which may be operated as server 110 , and/or client 150 of FIG. 1 , which may be used with the techniques described here.
- Computing device 700 is intended to represent various example forms of computing devices, such as laptops, desktops, workstations, personal digital assistants, cellular telephones, smartphones, tablets, servers, and other computing devices, including wearable devices.
- the components shown here, their connections and relationships, and their functions, are meant to be examples only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
- Computing device 700 includes a processor 702 , memory 704 , a storage device 706 , and expansion ports 710 connected via an interface 708 .
- computing device 700 may include transceiver 746 , communication interface 744 , and a GPS (Global Positioning System) receiver module 748 , among other components, connected via interface 708 .
- Device 700 may communicate wirelessly through communication interface 744 , which may include digital signal processing circuitry where necessary.
- Each of the components 702 , 704 , 706 , 708 , 710 , 740 , 744 , 746 , and 748 may be mounted on a common motherboard or in other manners as appropriate.
- the processor 702 can process instructions for execution within the computing device 700 , including instructions stored in the memory 704 or on the storage device 706 to display graphical information for a GUI on an external input/output device, such as display 716 .
- Display 716 may be a monitor or a flat touchscreen display.
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 700 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 704 stores information within the computing device 700 .
- the memory 704 is a volatile memory unit or units.
- the memory 704 is a non-volatile memory unit or units.
- the memory 704 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the memory 704 may include expansion memory provided through an expansion interface.
- the storage device 706 is capable of providing mass storage for the computing device 700 .
- the storage device 706 may be or include a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in such a computer-readable medium.
- the computer program product may also include instructions that, when executed, perform one or more methods, such as those described above.
- the computer- or machine-readable medium is a storage device such as the memory 704 , the storage device 706 , or memory on processor 702 .
- the interface 708 may be a high speed controller that manages bandwidth-intensive operations for the computing device 700 or a low speed controller that manages lower bandwidth-intensive operations, or a combination of such controllers.
- An external interface 740 may be provided so as to enable near area communication of device 700 with other devices.
- controller 708 may be coupled to storage device 706 and expansion port 714 .
- the expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 700 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 730 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system. In addition, it may be implemented in a computing device, such as a laptop computer 732 , personal computer 734 , or tablet/smart phone 736 . An entire system may be made up of multiple computing devices 700 communicating with each other. Other configurations are possible.
- FIG. 8 shows an example of a generic computer device 800 , which may be server 110 of FIG. 1 , which may be used with the techniques described here.
- Computing device 800 is intended to represent various example forms of large-scale data processing devices, such as servers, blade servers, datacenters, mainframes, and other large-scale computing devices.
- Computing device 800 may be a distributed system having multiple processors, possibly including network attached storage nodes, that are interconnected by one or more communication networks.
- the components shown here, their connections and relationships, and their functions, are meant to be examples only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
- Distributed computing system 800 may include any number of computing devices 880 .
- Computing devices 880 may include a server or rack servers, mainframes, etc. communicating over a local or wide-area network, dedicated optical links, modems, bridges, routers, switches, wired or wireless networks, etc.
- each computing device may include multiple racks.
- computing device 880 a includes multiple racks 858 a - 858 n .
- Each rack may include one or more processors, such as processors 852 a - 852 n and 862 a - 862 n .
- the processors may include data processors, network attached storage devices, and other computer controlled devices.
- one processor may operate as a master processor and control the scheduling and data distribution tasks.
- Processors may be interconnected through one or more rack switches 858 , and one or more racks may be connected through switch 878 .
- Switch 878 may handle communications between multiple connected computing devices 880 .
- Each rack may include memory, such as memory 854 and memory 864 , and storage, such as 856 and 866 .
- Storage 856 and 866 may provide mass storage and may include volatile or non-volatile storage, such as network-attached disks, floppy disks, hard disks, optical disks, tapes, flash memory or other similar solid state memory devices, or an array of devices, including devices in a storage area network or other configurations.
- Storage 856 or 866 may be shared between multiple processors, multiple racks, or multiple computing devices and may include a computer-readable medium storing instructions executable by one or more of the processors.
- Memory 854 and 864 may include, e.g., volatile memory unit or units, a non-volatile memory unit or units, and/or other forms of computer-readable media, such as a magnetic or optical disks, flash memory, cache, Random Access Memory (RAM), Read Only Memory (ROM), and combinations thereof. Memory, such as memory 854 may also be shared between processors 852 a - 852 n . Data structures, such as an index, may be stored, for example, across storage 856 and memory 854 .
- Computing device 880 may include other components not shown, such as controllers, buses, input/output devices, communications modules, etc.
- An entire system such as system 100 , may be made up of multiple computing devices 880 communicating with each other.
- device 880 a may communicate with devices 880 b , 880 c , and 880 d , and these may collectively be known as system 100 .
- system 100 of FIG. 1 may include one or more computing devices 880 . Some of the computing devices may be located geographically close to each other, and others may be located geographically distant.
- the layout of system 800 is an example only and the system may take on other layouts or configurations.
- FIG. 9 illustrates a flow diagram of an example process 900 for assembling records in a hierarchical annotation structure of conversation dialog acts in response to receiving a query, in accordance with disclosed implementations.
- Process 900 may be performed by a hierarchical annotation system, such as system 100 of FIG. 1 or system 200 of FIG. 2 .
- the order of the steps in process 900 is exemplary and the order can be re-arranged, some steps may be combined, and some steps may be optional.
- Process 900 may begin with a system receiving a query ( 905 ).
- the system may identify annotation records responsive to the query ( 910 ), and identify parent records of the responsive records ( 915 ). Further, the system may identify linked records using the record identifier in a previous discourse tag ( 920 ). Moreover, the system may reassemble the responsive records into a tree.
- Various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- a programmable processor which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
Abstract
Description
-
- DAE:< >
- DAT:TASK
- SD:STATEMENT_ASSERT
- PD:ANSWER
-
- DAE:< >
- DAT:TASK
- SD:STATEMENT REASSERT
- PD:ANSWER
-
- DAE:< >
- DAT:TASK
- SD:INFO_REQUEST
- PD:< >
Claims (19)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/337,830 US11321535B2 (en) | 2016-10-04 | 2017-09-28 | Hierarchical annotation of dialog acts |
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201662403932P | 2016-10-04 | 2016-10-04 | |
US201715717355A | 2017-09-27 | 2017-09-27 | |
PCT/US2017/053909 WO2018067368A1 (en) | 2016-10-04 | 2017-09-28 | Hierarchical annotation of dialog acts |
US16/337,830 US11321535B2 (en) | 2016-10-04 | 2017-09-28 | Hierarchical annotation of dialog acts |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US201715717355A Continuation | 2016-10-04 | 2017-09-27 |
Publications (2)
Publication Number | Publication Date |
---|---|
US20200012720A1 US20200012720A1 (en) | 2020-01-09 |
US11321535B2 true US11321535B2 (en) | 2022-05-03 |
Family
ID=60081308
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/337,830 Active 2038-08-29 US11321535B2 (en) | 2016-10-04 | 2017-09-28 | Hierarchical annotation of dialog acts |
Country Status (2)
Country | Link |
---|---|
US (1) | US11321535B2 (en) |
WO (1) | WO2018067368A1 (en) |
Families Citing this family (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP7187545B2 (en) | 2017-09-28 | 2022-12-12 | オラクル・インターナショナル・コーポレイション | Determining Cross-Document Rhetorical Connections Based on Parsing and Identifying Named Entities |
US11809825B2 (en) | 2017-09-28 | 2023-11-07 | Oracle International Corporation | Management of a focused information sharing dialogue based on discourse trees |
US11107006B2 (en) | 2017-12-05 | 2021-08-31 | discourse.ai, Inc. | Visualization, exploration and shaping conversation data for artificial intelligence-based automated interlocutor training |
US10896670B2 (en) | 2017-12-05 | 2021-01-19 | discourse.ai, Inc. | System and method for a computer user interface for exploring conversational flow with selectable details |
US11004013B2 (en) | 2017-12-05 | 2021-05-11 | discourse.ai, Inc. | Training of chatbots from corpus of human-to-human chats |
US10929611B2 (en) | 2017-12-05 | 2021-02-23 | discourse.ai, Inc. | Computer-based interlocutor understanding using classifying conversation segments |
WO2019161207A1 (en) * | 2018-02-15 | 2019-08-22 | DMAI, Inc. | System and method for conversational agent via adaptive caching of dialogue tree |
WO2019161241A1 (en) | 2018-02-15 | 2019-08-22 | DMAI, Inc. | System and method for identifying a point of interest based on intersecting visual trajectories |
CN112204564A (en) | 2018-02-15 | 2021-01-08 | 得麦股份有限公司 | System and method for speech understanding via integrated audio and visual based speech recognition |
WO2019203859A1 (en) * | 2018-04-19 | 2019-10-24 | Google Llc | Dependency graph conversation modeling for use in conducting human-to-computer dialog sessions with a computer-implemented automated assistant |
EP3791292A1 (en) | 2018-05-09 | 2021-03-17 | Oracle International Corporation | Constructing imaginary discourse trees to improve answering convergent questions |
US10783877B2 (en) * | 2018-07-24 | 2020-09-22 | Accenture Global Solutions Limited | Word clustering and categorization |
US11556698B2 (en) * | 2019-10-22 | 2023-01-17 | Oracle International Corporation | Augmenting textual explanations with complete discourse trees |
US11580298B2 (en) | 2019-11-14 | 2023-02-14 | Oracle International Corporation | Detecting hypocrisy in text |
US11604928B2 (en) * | 2020-04-30 | 2023-03-14 | International Business Machines Corporation | Efficiently managing predictive changes for a conversational agent |
US20220353210A1 (en) * | 2021-04-29 | 2022-11-03 | International Business Machines Corporation | Altering automated conversation systems |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050053283A1 (en) * | 2003-08-21 | 2005-03-10 | Microsoft Corporation | Electronic ink processing |
US20070016614A1 (en) | 2005-07-15 | 2007-01-18 | Novy Alon R J | Method and apparatus for providing structured data for free text messages |
US20100131274A1 (en) | 2008-11-26 | 2010-05-27 | At&T Intellectual Property I, L.P. | System and method for dialog modeling |
US20140297268A1 (en) * | 2011-09-19 | 2014-10-02 | Personetics Technologies Ltd. | Advanced System and Method for Automated-Context-Aware-Dialog with Human Users |
CN104462024A (en) | 2014-10-29 | 2015-03-25 | 百度在线网络技术（北京）有限公司 | Method and device for generating dialogue action strategy model |
US11094320B1 (en) * | 2014-12-22 | 2021-08-17 | Amazon Technologies, Inc. | Dialog visualization |
-
2017
- 2017-09-28 US US16/337,830 patent/US11321535B2/en active Active
- 2017-09-28 WO PCT/US2017/053909 patent/WO2018067368A1/en active Application Filing
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050053283A1 (en) * | 2003-08-21 | 2005-03-10 | Microsoft Corporation | Electronic ink processing |
US20070016614A1 (en) | 2005-07-15 | 2007-01-18 | Novy Alon R J | Method and apparatus for providing structured data for free text messages |
US20100131274A1 (en) | 2008-11-26 | 2010-05-27 | At&T Intellectual Property I, L.P. | System and method for dialog modeling |
US20140297268A1 (en) * | 2011-09-19 | 2014-10-02 | Personetics Technologies Ltd. | Advanced System and Method for Automated-Context-Aware-Dialog with Human Users |
CN104462024A (en) | 2014-10-29 | 2015-03-25 | 百度在线网络技术（北京）有限公司 | Method and device for generating dialogue action strategy model |
US11094320B1 (en) * | 2014-12-22 | 2021-08-17 | Amazon Technologies, Inc. | Dialog visualization |
Non-Patent Citations (9)
Title |
---|
Allan, et al.; "Draft of DAMSL: Dialog Act Markup in Several Layers;" Available at: www.cs.cmu.edu/afs/cs/Web/People/dgroup/papers/manual - 2.1 ps; 32 pages; dated Oct. 18, 1997. |
China National Intellectual Property Administration; Notice of Allowance issued in Application No. 201710914486.3; 4 pages; dated Jun. 7, 2021. |
China National Intellectual Property; Notification of First Office Action issue in Application No. 201710914486.3; 22 pages; dated Aug. 12, 2020. |
European Patent Office—International Searching Authority; International Search Report and the Written Opinion of PCT Serial No. PCT/US2017/053909; dated Dec. 14, 2017. |
German Patent Office; Office Action issued in Application No. 10 2017 121 780.0; 16 pages; dated Mar. 29, 2021. |
Lemon et al.; Multi-tasking and Collaborative Activities in Dialogue Systems; Center for the Study of Language and Inforamtion; 12 pages; dated Jul. 11, 2002. |
United Kingdom Intellectual Property Office; Combiend Search and Examination Report issued in Application No. 1715647.2 dated Feb. 13, 2018 dated Feb. 13, 2018. |
United Kingdom Intellectual Property Office; Office Action issued in Application No. 1715647.2 dated Jan. 29, 2020. |
United Kingdom Intellectual Property Office; Office Action issued in Application No. 1715647.2 dated Oct. 29, 2019. |
Also Published As
Publication number | Publication date |
---|---|
WO2018067368A1 (en) | 2018-04-12 |
US20200012720A1 (en) | 2020-01-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11321535B2 (en) | Hierarchical annotation of dialog acts | |
CN108446290B (en) | Streaming real-time conversation management | |
US11394667B2 (en) | Chatbot skills systems and methods | |
US10235999B1 (en) | Voice application platform | |
US10636425B2 (en) | Voice application platform | |
JP6977103B2 (en) | Modulation of packetized audio signals | |
CN114503115A (en) | Generating rich action items | |
JP2024023311A (en) | Techniques for building knowledge graphs within limited knowledge domains | |
WO2018036555A1 (en) | Session processing method and apparatus | |
US8103646B2 (en) | Automatic tagging of content based on a corpus of previously tagged and untagged content | |
CN111837116B (en) | Method for automatically constructing or updating dialog flow management model of dialog type AI system | |
US11355123B2 (en) | Network data aligning | |
JP2021089758A (en) | Feedback controller for data transmission | |
JP2021518007A (en) | Computer support using an artificial intelligence knowledge base | |
TW200900966A (en) | Client input method | |
US11126938B2 (en) | Targeted data element detection for crowd sourced projects with machine learning | |
US10963496B2 (en) | Method for capturing and updating database entries of CRM system based on voice commands | |
KR101891498B1 (en) | Method, computer device and computer readable recording medium for multi domain service resolving the mixture of multi-domain intents in interactive ai agent system | |
JP2022547598A (en) | Techniques for interactive processing using contextual data | |
US11645138B2 (en) | Diagnosing and resolving technical issues | |
CN107894829B (en) | Hierarchical annotation of conversational actions | |
US10509627B2 (en) | User interface sound emanation activity classification | |
US20230169272A1 (en) | Communication framework for automated content generation and adaptive delivery | |
CA3102093A1 (en) | Voice application platform | |
US20220180865A1 (en) | Runtime topic change analyses in spoken dialog contexts |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ELSON, DAVID;ROSS, BENJAMIN;EISENBERG, DAVID;AND OTHERS;SIGNING DATES FROM 20170921 TO 20170928;REEL/FRAME:048984/0693Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:048989/0491Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE AFTER FINAL ACTION FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |