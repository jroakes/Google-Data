US6452979B1 - Soft output decoder for convolutional codes - Google Patents
Soft output decoder for convolutional codes Download PDFInfo
- Publication number
- US6452979B1 US6452979B1 US09/656,189 US65618900A US6452979B1 US 6452979 B1 US6452979 B1 US 6452979B1 US 65618900 A US65618900 A US 65618900A US 6452979 B1 US6452979 B1 US 6452979B1
- Authority
- US
- United States
- Prior art keywords
- recursion
- window
- state
- trellis
- backward
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- H—ELECTRICITY
- H03—ELECTRONIC CIRCUITRY
- H03M—CODING; DECODING; CODE CONVERSION IN GENERAL
- H03M13/00—Coding, decoding or code conversion, for error detection or error correction; Coding theory basic assumptions; Coding bounds; Error probability evaluation methods; Channel models; Simulation or testing of codes
- H03M13/37—Decoding methods or techniques, not specific to the particular type of coding provided for in groups H03M13/03 - H03M13/35
- H03M13/39—Sequence estimation, i.e. using statistical methods for the reconstruction of the original codes
- H03M13/3905—Maximum a posteriori probability [MAP] decoding or approximations thereof based on trellis or lattice decoding, e.g. forward-backward algorithm, log-MAP decoding, max-log-MAP decoding
-
- H—ELECTRICITY
- H03—ELECTRONIC CIRCUITRY
- H03M—CODING; DECODING; CODE CONVERSION IN GENERAL
- H03M13/00—Coding, decoding or code conversion, for error detection or error correction; Coding theory basic assumptions; Coding bounds; Error probability evaluation methods; Channel models; Simulation or testing of codes
- H03M13/29—Coding, decoding or code conversion, for error detection or error correction; Coding theory basic assumptions; Coding bounds; Error probability evaluation methods; Channel models; Simulation or testing of codes combining two or more codes or code structures, e.g. product codes, generalised product codes, concatenated codes, inner and outer codes
- H03M13/2957—Turbo codes and decoding
-
- H—ELECTRICITY
- H03—ELECTRONIC CIRCUITRY
- H03M—CODING; DECODING; CODE CONVERSION IN GENERAL
- H03M13/00—Coding, decoding or code conversion, for error detection or error correction; Coding theory basic assumptions; Coding bounds; Error probability evaluation methods; Channel models; Simulation or testing of codes
- H03M13/37—Decoding methods or techniques, not specific to the particular type of coding provided for in groups H03M13/03 - H03M13/35
- H03M13/39—Sequence estimation, i.e. using statistical methods for the reconstruction of the original codes
- H03M13/3972—Sequence estimation, i.e. using statistical methods for the reconstruction of the original codes using sliding window techniques or parallel windows
Definitions
- This invention relates generally to communication systems, and more particularly to soft output decoders for use in a receiver of a convolutional code communication system.
- Convolutional codes are often used in digital communication systems to protect transmitted information.
- an outgoing code vector may be described using a trellis diagram whose complexity is determined by the constraint length of the encoder. Although computational complexity increases with increasing constraint length, the robustness of the coding also increases with constraint length.
- a practical soft-decision decoder such as a Viterbi decoder as is known in the art, uses a trellis structure to perform an optimum search for the maximum likelihood transmitted code vector.
- Coders for various communications systems such as Direct Sequence Code Division Multiple Access (DS-CDMA) standard IS-95 and Global System for Mobile Communications (GSM) employ convolutional codes for error correction.
- DS-CDMA Direct Sequence Code Division Multiple Access
- GSM Global System for Mobile Communications
- Turbo codes have been developed that outperform conventional coding techniques.
- Turbo codes are generally composed of two or more convolutional codes and turbo interleavers.
- Turbo decoding is iterative using a soft output decoder to decode the constituent convolutional codes.
- the soft output decoder provides a reliability measure on each information bit, which helps the soft output decoder decode the other convolutional codes.
- the soft output decoder is usually a MAP (maximum a posterior) decoder, which uses both backward and forward decoding to determine the soft output.
- MAP decoding is usually limited to a sub-optimal approximation. All of these variants require both forward and backward decoding over the block.
- FIG. 1 shows a trellis diagram for a first prior art soft output decoder technique
- FIG. 2 shows a trellis diagram for a second prior art soft output decoder technique
- FIG. 3 shows a trellis diagram for a third prior art soft output decoder technique
- FIG. 4 shows an expanded graphical representation of the diagram of FIG. 3
- FIG. 5 shows an alternate expanded graphical representation of the diagram of FIG. 3
- FIG. 6 shows a trellis diagram for a soft output decoder technique
- FIG. 7 shows a block diagram of a soft output decoder according to the trellis diagram according to FIG. 6;
- FIGS. 8A and 8B show an expanded graphical representation of the trellis diagram of FIG. 6.
- FIG. 9 shows a flow chart of a soft output decoder method for a decoder according to FIGS. 6-8.
- a decoder performs efficient soft-output decoding of convolutional codes.
- the soft-output decoder includes two trellis decoders for decoding the sequence of signals received over the channel.
- the decoder uses forward and backward recursions through a window of length w trellis sections, wherein w is much less than N (N being the frame length or trellis length).
- forward state metrics ⁇
- backward state metrics ⁇
- a computationally efficient decoder initiates backward learning from a single state. The single state is identified from the forward recursion through the window (the forward state metrics) without the need to process the entire trellis length. The decoder's performance is effectively the same as that using full trellis learning without the memory requirements or complexity of a full trellis decoder.
- convolutional codes such as turbo codes are graphically represented as a trellis, as shown in FIG. 1 .
- Maximum a posteriori (MAP) type decoders (log-MAP, MAP, max-log-MAP, constant-log-MAP, etc.) utilize forward and backward generalized Viterbi recursions on the trellis in order to provide soft outputs, as is known in the art.
- the MAP decoder minimizes the decoded bit error probability for each information bit based on all received bits.
- Typical prior art MAP decoders require a large memory to support decoding.
- the MAP bit probability can be broken into the past (beginning of trellis to the present state), the present state (branch metric for the current value), and the future (end of trellis to current value). More specifically, the MAP decoder performs forward and backward recursions up to a present state wherein the past and future probabilities are used along with the present branch metric to generate an output decision.
- the principles of providing hard and soft output decisions are well known in the art, and several variations of the above described decoding methods exist.
- SISO soft input-soft output
- FIG. 1 shows a trellis diagram for this algorithm for an 8-state convolutional code, which can be used in a turbo code.
- turbo coders are constructed with interleavers and constituent codes, which are usually systematic convolutional codes, but can alternately be block codes.
- MAP algorithms not only minimize the probability of error for an information bit given the received sequence, they also provide the probability that the information bit is either a 1 or 0 given the received sequence.
- the BCJR algorithm provides a soft output decision for each bit position (trellis section) wherein the influences of the soft inputs within the block are broken into contributions from the past (earlier soft inputs), the present soft input, and the future (later soft inputs).
- This decoder algorithm requires a forward and a backward generalized Viterbi recursion on the trellis to arrive at an optimal soft output for each trellis section, or stage.
- a posteriori probabilities or more commonly the log-likelihood ratio (LLR) of the probabilities, are passed between SISO decoding steps in iterative turbo decoding.
- LLR log-likelihood ratio
- the probability that the decoded bit is equal to 1 (or 0) in the trellis given the received sequence is composed of a product of terms due to the Markov property of the code.
- the Markov property states that the past and the future are independent given the present.
- the present, ⁇ t (n,m) is the probability of being in state m at time t and generating the symbol ⁇ t when the previous state at time t ⁇ 1 was n.
- the present operates as a branch metric.
- the past, ⁇ t (m) is the probability of being in state m at time t with the received sequence ⁇ t , . . .
- ⁇ t (m) is probability of generating the received sequence ⁇ t+1 , . . . ⁇ n ⁇ from state m at time t.
- the LLR in equation (1) requires both the forward and backward recursions to be available at time t.
- the BCJR method requires N*M state updates for the backward recursion (M state updates per trellis section, N trellis sections in the code) and 1 provides optimal performance.
- a backward recursion is first performed by a processor across the entire block (as shown in FIG. 1) and stored in memory.
- a forward recursion is then performed by the processor.
- the results of the backward and forward recursions are used with the present state and stored future state to arrive at a soft output decision for each stage.
- the processor operates on each state twice, once to generate and store the backward recursion states, and once to generate the forward recursion state.
- the sliding window technique does not require a significant amount memory, but is computationally complex. Specifically, instead of an entire backward recursion being performed and stored, only a partial backward recursion is performed (and not stored) to determine each state. For each present state, the algorithm initializes the future recursion at a learning period that is P away from the present state and at an initial state that is unknown. Future probabilities are calculated backwardly from the unknown future point, not from the known end of the trellis. The length P (learning period) is set such that by the time the partial backward recursion reaches the present state, the future probabilities are most likely correct. P depends on the rate and constraint length of the code and the expected channel conditions.
- P is typically between 16 and 32, and P is some multiple of the constraint length.
- the disadvantage of this decoder is that the partial backward recursion is started with equally likely (unknown states) and is allowed to iterate until it reaches the present window. This is a sub-optimal algorithm as the sliding window causes degradation from true MAP performance, similar to the effects of finite traceback in a conventional Viterbi algorithm, increasing the probability of decoded bit error.
- the processor operates on each state P times (throughput of 1/P) and has an output delay of P.
- this algorithm requires P times the complexity, which can only be reduced by adding more processing.
- the sliding window method reduces the memory requirement from N*M, which is needed in the BCJR method, to a relatively insignificant amount for the recursion. Assuming double buffering, the amount of memory is only 2M, and can be safely ignored in the analysis.
- the Viterbi sliding window method of FIG. 3 reduces the large increase in computational complexity of the prior art sliding window method by performing processing in small blocks.
- the backward recursion is started at time t+2L, and the backward recursion values are stored from time t+L to time t.
- the forward recursion and output likelihood computation are then performed over the block of time t to time t+L.
- Memory is reduced from NM (the number of sections in the block times the number of states) down to LM (the number of sections in the window times the number of states), while only doubling the computational complexity.
- a decoder using the Viterbi sliding window differs from the previously described sliding window technique by providing a window that slides forward in blocks rather than a symbol at a time.
- a sliding window is defined having a length L that is equal to the previously described learning period P.
- L is some fraction of the total trellis length, N, and the window slides from the beginning to the end of the trellis in steps of length L.
- FIG. 4 shows an expanded diagram of the graph of FIG. 3 with a time component added.
- a forward processor performs a forward recursion over a first window from stage 0 to L and stores the information while over the same time period a backward processor performs a backward recursion from stage 2L to L to define a known state at the end of the first window at stage L at time L.
- a second backward recursion operates from time L to 2L over stage L to 0 to define the soft outputs over the first window.
- the soft decisions can be reversed and output in order (which clearly occurs after a delay of 2L), the memory is cleared, the window stage slides forward a length of L, and the process repeats.
- throughput can be increased.
- FIG. 5 shows an alternative result for the graph of FIG. 3 using an additional backward processor.
- the forward processor performs a forward recursion over a first window from stage 0 to L and stores the information while over the same time period the backward processor performs a backward recursion from stage 2L to L to define a known state at the end of the first window at stage L at time L.
- a second backward recursion operates from time L to 2L over stage L to 0 to define the soft outputs over the first window.
- the forward and additional backward processor start a second cycle by beginning to process information the second window (from stage L to 2L).
- the soft decisions for the first window are output while the forward recursion and backward learning period for the second window have already been completed. Then a second backward recursion for the second window is performed to obtain the soft outputs for the second window.
- this technique doubles the throughput. Twice the memory is needed as the information of the forward recursion for the first window is being used while the forward recursion for the second window is being stored.
- decoders (specifically of FIGS. 4 and 5) suffer from the problem that they are sub-optimal. These decoders must start at trellis stage 0 and/or trellis stage N in order to initiate recursion from an optimum state. Starting at stage N requires backward recursion of coefficients over the entire length of the trellis, introducing substantial timing and memory capacity issues. Starting at any other location in the trellis requires consideration of all possible states as the starting state, introducing potential degradation of performance.
- FIG. 6 shows a trellis diagram utilizing an improved decoding method.
- the trellis code is obtained from a coded sequence of signals represented by a trellis of length N in a communication system, as simplified in FIG. 7 .
- a signal travels through an antenna 102 to a receiver 104 and demodulator 106 , as is known in the art.
- the demodulator may be a digital demodulator following an analog-to-digital (A/D) converter, for example.
- A/D analog-to-digital
- the demodulated signal is loaded into a frame buffer 106 .
- a forward recursion processor 110 and backward recursion processor 112 operate on the block.
- the present invention differs from the previously described sliding window technique of FIGS. 3-5 in that it is an optimal technique wherein both forward and backward recursions in each window begin from a known state.
- the present invention performs a forward recursion from the front of the window over a length L+I.
- forward recursion coefficients Care generated and saved over length L+I beginning from the known state at the beginning of the window.
- S max is optimum in the sense that it lies with high probability along the optimal path through the trellis.
- Backward recursion occurs during a training period beginning from the optimum state S max at stage L+I and moving to stage L.
- the soft values can be generated from the backward recursion decoder as the decoder moves from section L to the starting point. After reaching location 0 (time t 0 ), the decoder slides L+I sections to the right as the new starting point for forward recursions, and forward recursions are performed to generate a new optimum state at a location 2L+I sections from the starting point to. This process of sliding, forward recursions, and backward recursions is repeated until the entire trellis block is decoded.
- the sliding window of decoded sections has a length L.
- L may be of any length, such that an integer multiple of L equals the total trellis length N.
- a non-integer multiple of L may equal the trellis length N.
- the window slides from the beginning to the end of the trellis in steps of length L.
- forward recursion processor 110 performs a forward recursion (using a generalized Viterbi algorithm) moving from the known beginning state of the window to an initial end point at least I trellis stages beyond the end of a window of length L to be decoded.
- the value I is greater than the controllability index (i.e., the number of branches through the trellis required to connect a given state to any other state). For example, where there are 8 states, I will preferably be greater than 3 (where the decoder can move up to two states in each stage step).
- the forward recursion metrics are optimum values because the forward recursion metrics are derived during a recursion process beginning from the known end state of the previous window.
- the backward recursion is performed by the backward recursion processor 112 , starting with a learning period initiated at the optimum state found at the end of the forward recursion process.
- the backward recursion coefficients ⁇ i (m) are computed and combined with the forward recursion coefficients ⁇ t (m) stored in memory 114 and branch metrics from which decoder 116 outputs the soft output decisions as they are generated.
- the forward recursion processor slides forward an L+I stages and the process is repeated for the second window and each subsequent window until the entire block is decoded.
- processors 110 and 112 operate within adjacent windows simultaneously.
- the forward recursion processor 112 decodes a portion of the trellis for the subsequent adjacent window starting from the last stage that forward recursion state metrics were generated for the previous window.
- a set of forward recursion state metrics are preferably defined for the subsequent window and stored in memory 114 . This leaves the backward recursion processor 112 available to begin decoding the next window immediately after the present window is processed.
- each window could be used for each window, or a circular buffer could be used wherein each forward recursion state metrics for a subsequent window replace backward recursion state metrics for the present window as the soft outputs are generated.
- the forward and backward processors operate concurrently until all of the windows within the block are decoded.
- the advantage of the present invention is that the backward recursion for the soft output decoder starts from a single state which lies with high probability along the optimal path through the trellis, in contrast to the prior art.
- the performance of the decoder was simulated and compared to turbo decoding that decodes and stores the full trellis block backward recursion decoding. The performance was found to be substantially the same for both MAX-log-MAP turbo decoding and Log-MAP decoding.
- FIGS. 8 a and 8 b show expanded diagrams of the graph of FIG. 6 with a time component added.
- the forward recursion processor 110 performs a first forward recursion from stage 0 to L+I.
- I can have any value so long as I is greater than the number of sections required to move between any two states. Additionally, the larger I is, the better the results will be.
- the backward recursion is performed first over I sections starting with state S max to identify the starting state at the end of window L, and then through the window L.
- the present invention computes each soft output in accordance with known turbo coding techniques, such as those represented in the Bahl et al. paper (BCJR algorithm) cited above.
- the advantage of the present invention is that it provides comparable output to the full block turbo decoder, but using significantly less memory and introducing much less delay.
- FIG. 9 shows a flow chart representing a method 200 of decoding a received convolutionally coded sequence of signals represented by a trellis of block length N, in accordance with the present invention (also see FIG. 6 ).
- a first step 202 is receiving w soft-input symbols (a prior Log Likelihood Ratios), where L+I ⁇ w ⁇ N, is received.
- N is the length of the trellis, and it is preferably much longer than w.
- the forward recursion decoder 110 decodes forwardly over length L+I such that coefficients a are calculated and saved in memory for all states within the sections L+I.
- the state in the last section having the largest ⁇ is identified, as indicated in step 204 .
- This state is selected to be the starting point for backward recursion.
- the backward recursion decoder performs backward recursion over a learning period of length 1 .
- a generalized Viterbi algorithm may for example be used.
- the training period over length I can be any length, although the longer the length I, the more reliable the state will be at the end of backward recursion trellis point L.
- the training period I must be sufficiently long to insure that the trellis has an opportunity to open to its full spread (all possible states) by the end of the learning period.
- the learning period I will preferably be much larger than the minimum length necessary for the trellis to open fully.
- the next step 210 is decoding the window using backward recursion from stage L at the end of the window to the beginning of the window.
- the length L can be variable or it can of any predetermined fixed length.
- the window length L can be selected such that the length is independent of the constraint length of the convolutional code. Alternatively it can be set to a multiple of the constraint length of the convolutional code for convenience.
- alphas calculated in step 204 , betas calculated in step 210 , and branch metrics are used to generate soft metrics, which may be stored in buffers so that they can be output in forward order.
- alphas and betas can both be stored and the soft outputs for the window can be generated in forward order from the stored alphas and betas. This alternative has the disadvantage that it would introduce additional delay and require more memory.
- the soft outputs are calculated at each stage of the forward recursion process using the forward recursion state metrics, the branch metrics, and the stored backward recursion state metrics, and outputting the soft output for that stage (trellis section).
- the recursion updates and soft outputs are calculated using a MAP type algorithm, such as the MAP algorithm or one of the MAP derivatives which include log-MAP, max-log-MAP, constant-log-MAP, and the like.
- the decoder can be “slid” forward a distance L+I sections (step 214 ) such that forward recursion begins at the end of the previous forward recursion. In this manner the forward recursion starts at a previously determined known state and forward recursion state metrics for particular sections are not repeatedly generated.
- the above steps 204 through 210 are repeated for the subsequent window. This process continues until all of the windows in the trellis block N are processed.
- the end of the trellis is detected in decision step 212 .
- stage N has a known state. Accordingly, once stage N is reached in the forward direction, that state is selected as the beginning state for backward recursion and training is not required prior to backward recursion for the last window of the frame (block N).
- a forward recursion for a subsequent window can occur at the same time that a backward recursion is occurring in an earlier window.
- the processing for the second window begins while the first window is being processed.
- the further step includes repeating the above steps, wherein inputting a next window starting at the end of the presently selected window, and wherein the decoding and calculating steps for the next window occur one step out of sequence and concurrently with the processing of the present window. This additional step saves processing time, although some additional memory is required.
- a single processor can be used for forward and backward. If a single processor is used, forward recursion will first occur through windows L and 2 L, followed by backward recursion through window 2 L (training) and window L, followed by forward recursion through window 3 L, followed by backward recursion through window 3 L (training) and window 2 L, followed by forward recursion through window 4 L, followed by backward recursion through window 4 L (training) and window 3 L, and continuing in this manner to the end of the block such that the entire block of length N is decoded.
- the present invention provides performance substantially the same as a decoder using backward recursion through the entire block of N stages prior to outputting soft metrics, but operates with increased throughput and substantially less memory for backward recursion. While specific components and functions of the soft output decoder for convolutional codes are described above, fewer or additional functions could be employed by one skilled in the art within the broad scope of the present invention, and the invention should be limited only by the appended claims.
Abstract
Description
Claims (20)
Priority Applications (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/656,189 US6452979B1 (en) | 2000-09-06 | 2000-09-06 | Soft output decoder for convolutional codes |
AU2001285330A AU2001285330A1 (en) | 2000-09-06 | 2001-08-28 | Soft output decoder for convolutional codes |
PCT/US2001/026787 WO2002021701A1 (en) | 2000-09-06 | 2001-08-28 | Soft output decoder for convolutional codes |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/656,189 US6452979B1 (en) | 2000-09-06 | 2000-09-06 | Soft output decoder for convolutional codes |
Publications (1)
Publication Number | Publication Date |
---|---|
US6452979B1 true US6452979B1 (en) | 2002-09-17 |
Family
ID=24632017
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/656,189 Expired - Lifetime US6452979B1 (en) | 2000-09-06 | 2000-09-06 | Soft output decoder for convolutional codes |
Country Status (3)
Country | Link |
---|---|
US (1) | US6452979B1 (en) |
AU (1) | AU2001285330A1 (en) |
WO (1) | WO2002021701A1 (en) |
Cited By (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20010044919A1 (en) * | 2000-05-05 | 2001-11-22 | Edmonston Brian S. | Method and apparatus for improved perormance sliding window decoding |
US20020097816A1 (en) * | 2000-10-16 | 2002-07-25 | Sim Myung Sub | Device and method for decoding turbo codes |
US20020198681A1 (en) * | 2001-06-13 | 2002-12-26 | Kouritzin Michael A. | Flexible efficient branching particle tracking algorithms |
US20030038212A1 (en) * | 1999-12-09 | 2003-02-27 | Torsten Niemeyer | Guide assembly for a missile |
US20030066019A1 (en) * | 2001-09-06 | 2003-04-03 | Interdigital Technology Corporation | Pipeline architecture for maximum a posteriori (MAP) decoders |
US20030093753A1 (en) * | 2001-11-15 | 2003-05-15 | Nec Corporation | Error correction code decoding device |
US20030110438A1 (en) * | 2001-12-07 | 2003-06-12 | Pan Ju Yan | Turbo decoder, and a MAP decoder component of the turbo decoder |
US20030154441A1 (en) * | 2002-01-21 | 2003-08-14 | Esko Nieminen | Method and apparatus for producing path metrics in trellis |
US20050091566A1 (en) * | 2003-04-23 | 2005-04-28 | Stmicroelectronics N.V. | Method of blindly detecting a transport format of an incident convolutional encoded signal, and corresponding convolutional code decoder |
US20050166128A1 (en) * | 2002-03-27 | 2005-07-28 | Siemens Aktiengesellschaft | Method for decoding data sequence that has been encoded with the help of a binary convolution code |
US7154965B2 (en) | 2002-10-08 | 2006-12-26 | President And Fellows Of Harvard College | Soft detection of data symbols in the presence of intersymbol interference and timing error |
US20070162837A1 (en) * | 2000-06-30 | 2007-07-12 | Nokia Corporation | Method and arrangement for decoding a convolutionally encoded codeword |
KR100744367B1 (en) | 2004-05-24 | 2007-07-30 | 삼성전자주식회사 | The Apparatus And Method for Turbo Decording With Variable sliding window size |
US20070242781A1 (en) * | 2004-05-18 | 2007-10-18 | Patrick Galili | Turbo Decoder Input Reordering |
US20090067554A1 (en) * | 2007-09-10 | 2009-03-12 | Mbit Wireless, Inc. | High throughput and low latency map decoder |
US20090249172A1 (en) * | 2008-03-26 | 2009-10-01 | Qualcomm Incorporated | Methods and apparatus for improved decoding of bursts that include multiple concatenated protocol data units |
US20120210197A1 (en) * | 2011-02-15 | 2012-08-16 | Samsung Electronics Co. Ltd. | Apparatus and method for decoding in communication system |
US20130120867A1 (en) * | 2008-01-22 | 2013-05-16 | Agere Systems Llc | Methods and Apparatus for Map Detection with Reduced Complexity |
US20130141257A1 (en) * | 2011-12-01 | 2013-06-06 | Broadcom Corporation | Turbo decoder metrics initialization |
US20160204803A1 (en) * | 2015-01-12 | 2016-07-14 | Mstar Semiconductor, Inc. | Decoding method for convolutionally coded signal |
US10439645B2 (en) * | 2014-08-13 | 2019-10-08 | Accelercomm Limited | Fully parallel turbo decoding |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
GB2426898B (en) * | 2005-06-02 | 2007-05-23 | Toshiba Res Europ Ltd | Wireless communications apparatus |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5933462A (en) * | 1996-11-06 | 1999-08-03 | Qualcomm Incorporated | Soft decision output decoder for decoding convolutionally encoded codewords |
EP1115209A1 (en) | 2000-01-07 | 2001-07-11 | Motorola, Inc. | Apparatus and method for performing parallel siso decoding |
-
2000
- 2000-09-06 US US09/656,189 patent/US6452979B1/en not_active Expired - Lifetime
-
2001
- 2001-08-28 AU AU2001285330A patent/AU2001285330A1/en not_active Abandoned
- 2001-08-28 WO PCT/US2001/026787 patent/WO2002021701A1/en active Application Filing
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5933462A (en) * | 1996-11-06 | 1999-08-03 | Qualcomm Incorporated | Soft decision output decoder for decoding convolutionally encoded codewords |
EP1115209A1 (en) | 2000-01-07 | 2001-07-11 | Motorola, Inc. | Apparatus and method for performing parallel siso decoding |
Non-Patent Citations (6)
Title |
---|
Claude Berrou, Alain Glavieux and Puny Thitimajshima, "Near Shannon Limit Error-Correcting Coding and Decoding: Turbo-Codes (1)", IEEE 1993, 7 pages. |
Jachim Hagenauer and Peter Hoeher, "A Viterbi Algorithm with Soft-Decision Outputs and its Applications", IEEE 1989, 7 pages. |
L.R. Bahl, J. Cocke, F. Jelinek and J. Raviv, "Optimal Decoding of Linear Codes for Minimizing Symbol Error Rate", IEEE Transactions on Information Theory, Mar. 1974, 4 pages. |
Meir Ariel and Jakov Snyders, "Error-Trellises for Convolutional Codes-Part I: Construction", IEEE Transactions on Communications, vol. 46, No. 12, Dec. 1998, 10 pages. |
Meir Ariel and Jakov Snyders, "Error-Trellises for Convolutional Codes-Part II: Decoding Methods", IEEE Transactions on Communications, vol. 47, No. 7, Jul. 1999, 10 pages. |
Patrick Robertson, Emmanuelle Villebrun and Peter Hoeher, "A Comparison of Optimal and Sub-Optimal MAP Decoding Algorithms Operating in the Log Domain", IEEE 1995, 5 pages. |
Cited By (36)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030038212A1 (en) * | 1999-12-09 | 2003-02-27 | Torsten Niemeyer | Guide assembly for a missile |
US20010044919A1 (en) * | 2000-05-05 | 2001-11-22 | Edmonston Brian S. | Method and apparatus for improved perormance sliding window decoding |
US20070162837A1 (en) * | 2000-06-30 | 2007-07-12 | Nokia Corporation | Method and arrangement for decoding a convolutionally encoded codeword |
US20020097816A1 (en) * | 2000-10-16 | 2002-07-25 | Sim Myung Sub | Device and method for decoding turbo codes |
US7003041B2 (en) * | 2000-10-16 | 2006-02-21 | Lg Electronics Inc. | Device and method for decoding turbo codes |
US20020198681A1 (en) * | 2001-06-13 | 2002-12-26 | Kouritzin Michael A. | Flexible efficient branching particle tracking algorithms |
US20030066019A1 (en) * | 2001-09-06 | 2003-04-03 | Interdigital Technology Corporation | Pipeline architecture for maximum a posteriori (MAP) decoders |
US8316285B2 (en) | 2001-09-06 | 2012-11-20 | Interdigital Technology Corporation | Pipeline architecture for maximum a posteriori (MAP) decoders |
US6961921B2 (en) * | 2001-09-06 | 2005-11-01 | Interdigital Technology Corporation | Pipeline architecture for maximum a posteriori (MAP) decoders |
US20060005111A1 (en) * | 2001-09-06 | 2006-01-05 | Interdigital Technology Corporation | Pipeline architecture for maximum a posteriori (MAP) decoders |
US7908545B2 (en) | 2001-09-06 | 2011-03-15 | Interdigital Technology Corporation | Pipeline architecture for maximum a posteriori (MAP) decoders |
US20070118791A1 (en) * | 2001-09-06 | 2007-05-24 | Interdigital Technology Corporation | Pipeline architecture for maximum a posteriori (MAP) decoders |
US7181670B2 (en) | 2001-09-06 | 2007-02-20 | Interdigital Technology Corporation | Pipeline architecture for maximum a posteriori (MAP) decoders |
US20030093753A1 (en) * | 2001-11-15 | 2003-05-15 | Nec Corporation | Error correction code decoding device |
US7178090B2 (en) * | 2001-11-15 | 2007-02-13 | Nec Corporation | Error correction code decoding device |
US20030110438A1 (en) * | 2001-12-07 | 2003-06-12 | Pan Ju Yan | Turbo decoder, and a MAP decoder component of the turbo decoder |
US20030154441A1 (en) * | 2002-01-21 | 2003-08-14 | Esko Nieminen | Method and apparatus for producing path metrics in trellis |
US7165210B2 (en) | 2002-01-21 | 2007-01-16 | Nokia Corporation | Method and apparatus for producing path metrics in trellis |
US20050166128A1 (en) * | 2002-03-27 | 2005-07-28 | Siemens Aktiengesellschaft | Method for decoding data sequence that has been encoded with the help of a binary convolution code |
US7143334B2 (en) * | 2002-03-27 | 2006-11-28 | Siemens Aktiengesellschaft | Method for decoding data sequence encoded with aid of binary convolution code |
US7154965B2 (en) | 2002-10-08 | 2006-12-26 | President And Fellows Of Harvard College | Soft detection of data symbols in the presence of intersymbol interference and timing error |
US20050091566A1 (en) * | 2003-04-23 | 2005-04-28 | Stmicroelectronics N.V. | Method of blindly detecting a transport format of an incident convolutional encoded signal, and corresponding convolutional code decoder |
US20070242781A1 (en) * | 2004-05-18 | 2007-10-18 | Patrick Galili | Turbo Decoder Input Reordering |
US9071279B2 (en) * | 2004-05-18 | 2015-06-30 | Nxp, B.V. | Turbo decoder input reordering |
KR100744367B1 (en) | 2004-05-24 | 2007-07-30 | 삼성전자주식회사 | The Apparatus And Method for Turbo Decording With Variable sliding window size |
US8358713B2 (en) | 2007-09-10 | 2013-01-22 | Sarath Babu Govindarajulu | High throughput and low latency map decoder |
US20090067554A1 (en) * | 2007-09-10 | 2009-03-12 | Mbit Wireless, Inc. | High throughput and low latency map decoder |
US8908812B2 (en) * | 2008-01-22 | 2014-12-09 | Agere Systems Llc | Methods and apparatus for map detection with reduced complexity |
US20130120867A1 (en) * | 2008-01-22 | 2013-05-16 | Agere Systems Llc | Methods and Apparatus for Map Detection with Reduced Complexity |
US20090249172A1 (en) * | 2008-03-26 | 2009-10-01 | Qualcomm Incorporated | Methods and apparatus for improved decoding of bursts that include multiple concatenated protocol data units |
US8843811B2 (en) * | 2011-02-15 | 2014-09-23 | Samsung Electronics Co., Ltd. | Apparatus and method for decoding in communication system |
US20120210197A1 (en) * | 2011-02-15 | 2012-08-16 | Samsung Electronics Co. Ltd. | Apparatus and method for decoding in communication system |
US20130141257A1 (en) * | 2011-12-01 | 2013-06-06 | Broadcom Corporation | Turbo decoder metrics initialization |
US10439645B2 (en) * | 2014-08-13 | 2019-10-08 | Accelercomm Limited | Fully parallel turbo decoding |
US20160204803A1 (en) * | 2015-01-12 | 2016-07-14 | Mstar Semiconductor, Inc. | Decoding method for convolutionally coded signal |
US10116337B2 (en) * | 2015-01-12 | 2018-10-30 | Mstar Semiconductor, Inc. | Decoding method for convolutionally coded signal |
Also Published As
Publication number | Publication date |
---|---|
WO2002021701A1 (en) | 2002-03-14 |
AU2001285330A1 (en) | 2002-03-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6452979B1 (en) | Soft output decoder for convolutional codes | |
US6829313B1 (en) | Sliding window turbo decoder | |
US6901117B1 (en) | Soft output decoder for convolutional codes | |
EP1314254B1 (en) | Iteration terminating for turbo decoder | |
US6885711B2 (en) | Turbo decoder with multiple scale selections | |
US6192501B1 (en) | High data rate maximum a posteriori decoder for segmented trellis code words | |
US6393076B1 (en) | Decoding of turbo codes using data scaling | |
US6856657B1 (en) | Soft output decoder for convolutional codes | |
US6999531B2 (en) | Soft-decision decoding of convolutionally encoded codeword | |
US6868132B1 (en) | Soft output decoder for convolutional codes | |
EP1471677A1 (en) | Method of blindly detecting a transport format of an incident convolutional encoded signal, and corresponding convolutional code decoder | |
JP2003514427A (en) | Method for decoding encoded data having entropy code, and corresponding decoding device and transmission system | |
US6513140B2 (en) | Method and device for decoding convolutional codes | |
US20030101402A1 (en) | Hard-output iterative decoder | |
US6857101B1 (en) | Apparatus and method of storing reference vector of state metric | |
US7031406B1 (en) | Information processing using a soft output Viterbi algorithm | |
KR100369422B1 (en) | Soft output decoder for convolutional codes | |
US20030101407A1 (en) | Selectable complexity turbo coding system | |
US20030110438A1 (en) | Turbo decoder, and a MAP decoder component of the turbo decoder | |
WO2002021784A1 (en) | Soft-output error-trellis decoder for convolutional codes | |
US20050172200A1 (en) | Data receiving method and apparatus | |
US20030101403A1 (en) | Turbo decoder and its calculation methods having a state metric | |
EP1178613A1 (en) | Apparatus and method for determining an abort criterion in an iterative detection process | |
US7237177B2 (en) | Method of calculating internal signals for use in a map algorithm |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ARIEL, MEIR;AMRANI, OFER;MEIDAN, REUVEN;REEL/FRAME:011145/0261Effective date: 20000828 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
CC | Certificate of correction | ||
FPAY | Fee payment |
Year of fee payment: 4 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282Effective date: 20120622 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034432/0001Effective date: 20141028 |