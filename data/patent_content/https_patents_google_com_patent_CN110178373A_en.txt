CN110178373A - For the termination in advance based on multi-level machine learning in the sector search of Video coding - Google Patents
For the termination in advance based on multi-level machine learning in the sector search of Video coding Download PDFInfo
- Publication number
- CN110178373A CN110178373A CN201780083311.0A CN201780083311A CN110178373A CN 110178373 A CN110178373 A CN 110178373A CN 201780083311 A CN201780083311 A CN 201780083311A CN 110178373 A CN110178373 A CN 110178373A
- Authority
- CN
- China
- Prior art keywords
- block
- classifier
- coding
- training
- subregion
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/189—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding
- H04N19/192—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding the adaptation method, adaptation tool or adaptation type being iterative or recursive
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/119—Adaptive subdivision aspects, e.g. subdivision of a picture into rectangular or non-rectangular coding blocks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/65—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using error resilience
- H04N19/66—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using error resilience involving data partitioning, i.e. separation of data into packets or partitions according to importance
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/90—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using coding techniques not provided for in groups H04N19/10-H04N19/85, e.g. fractals
- H04N19/96—Tree coding, e.g. quad-tree coding
Abstract
Whether classifier carries out subregion to the block in frame during the prediction using recursive partitioning for determining.The block of coding is generated using the block in recursive partitioning coding training video frame.Block generation for coding includes the training example whether value and the instruction block of the coding in recursive partitioning for the feature extracted in the block encoded from each are partitioned smaller piece of label.Use and is directed to different block size training classifiers from the associated trained example of block size as the input of machine-learning process.In the frame of encoded video sequence, whether the output of classifier is determined during coding to input block subregion.
Description
Background technique
Digital video can be used for for example wide via the remote business meeting of video conference, HD video entertainment, video
The video that announcement or user generate is shared.The mass data as involved in video data needs high performance compression for passing
Defeated and storage.Therefore it provides the high-resolution video by the traffic channel with finite bandwidth will be advantageous.
Summary of the invention
This application involves the coding and decodings of video stream data to be used for transmission or store.Disclosed herein is for making
With the system for the Video coding of the sector search based on multi-level machine learning terminated in advance, the aspect of method and apparatus.
The one side of method described herein includes using recursive partitioning, is repeatedly compiled by using different the encoding option collection
Code training video frame generates the block of coding.This method further includes, for the block of multiple codings with first size, from having
An encoding block in the block of the multiple coding of first size extracts the training of the block feature in the feature set for definition
Value, and the label whether instruction is partitioned smaller piece with the encoding block of first size is associated with trained values
(for example, forming training example).Finally, using the training example of the block for the multiple coding with first size ---
Trained values and associated label --- the first classifier of Lai Xunlian, the first classifier are used from first piece with first size
Whether at least some block features obtained during coding will be to first piece of further subregions to determine.
It is the device described herein including non-transitory memory and processor on one side.The processor is configured as
It executes instruction stored in memory and encodes the block in training video frame to use recursive partitioning to generate encoding block, generate
The training example of the encoding block, each training example include the value of the block feature extracted from encoding block and indicate in recurrence
Whether the encoding block is partitioned smaller piece of label in subregion, and training is used for the classifier of different block sizes, needle
Trained example associated with the block size is used to come as the input of machine-learning process each classifier of a block size
Training, and whether each classifier be configured to determine that during coding will be to input block subregion.
It on the other hand is a kind of device, wherein processor is configured as executing instruction stored in memory to select to have
There is the block of the video frame of maximum predicted block size, encodes the block without being based on scheduled feature set from the block to the block subregion
Extraction of values uses described value that the first classifier is applied to the block as input, and the first classifier is for having maximum predicted
There is instruction to stop the of sector search for the binary classifier (binary classifier) of the block of block size, binary classifier
One output and instruction continue the second output of sector search, and the case where the first classifier generates the first output of the block
Under, the block that non-subregion is encoded includes in the video bit stream of coding.
The variation of these and other aspects will be described in further detail below.
Detailed description of the invention
Description herein refers to attached drawing, wherein identical appended drawing reference refers to identical part in all several views.
Fig. 1 is the figure according to the calculating equipment of the realization of the disclosure.
Fig. 2 is the figure of the calculating and communication system according to the realization of the disclosure.
Fig. 3 is the figure according to the video flowing for coding and decoding of the realization of the disclosure.
Fig. 4 is the block diagram according to the encoder of the realization of the disclosure.
Fig. 5 is the block diagram according to the decoder of the realization of the disclosure.
Fig. 6 is the figure according to a part of the frame of the subregion of the realization of the disclosure.
Fig. 7 is to show the figure of the decision tree for recursive partitioning of the binary classifier for three block size ranks.
Fig. 8 is the flow chart according to the process for training classifier of the realization of the disclosure.
Fig. 9 is according to the realization of the disclosure for modifying the mistake with finalization classifier using additional verify data
The flow chart of journey.
Figure 10 A is the figure according to a part of the frame of first the encoding option collection subregion.
Figure 10 B is the figure according to a part of the frame of second the encoding option collection subregion.
Figure 11 is the figure using the feature extraction of the part of the frame of Figure 10 A and Figure 10 B of subregion.
Figure 12 is according to the realization of the disclosure for during coding to the flow chart of the process of frame subregion.
Specific embodiment
Video compression scheme may include that every piece image or frame are divided into the smaller part of such as block and used
Limitation includes the technology of the information for each block to generate output bit flow in the output.The bit of coding can be flowed into
Row decoding from the information of limitation to re-create block and source images.It in some implementations, can be by reducing spatial redundancy, subtracting
Few time redundancy or combinations thereof includes information for each block to limit in the output.
It is compiled by using the similitude between frame with using the data of the relatively small amount of reference frame based on one or more
Code frame can reduce time redundancy, and the reference frame can be the previous coding of video flowing, decoded and reconstruct frame.
Reducing time redundancy may include that the reference frame for corresponding to each subregion to the block subregion in frame, basis identifies in advance
It surveys block and the difference between subregion and prediction block is determined as residual block.Reducing spatial redundancy may include to the block in frame point
Area, basis correspond to the present frame identification prediction block of each subregion and the difference between subregion and prediction block are determined as residual error
Block.Then identical as partitions sizes, more smaller than subregion or bigger residual block is transformed into frequency domain using transformation.
Video coder-decoder can use large-scale partitions sizes.For example, such as with 64 × 64 Pixel Dimensions
The coding unit of block (sometimes referred to as super block) can recursively be decomposed into downwards always the block with the small size to 4 × 4 pixels.
Exhaustive search can be carried out to find the optimally partitioned of coding unit.In the sector search, encoder is possible to each
Subregion executes coded treatment and can be selected by lowest error value optimally partitioned.It is, for example, possible to use rate-distortion (RD)
Error or cost, for example, selection provides the subregion of minimum RD cost.Although ensuring coding quality, which is being calculated
On be complicated and consume a large amount of computing resource.
In order to accelerate cataloged procedure, can be used establish the termination criteria terminated in advance for sector search based on threshold
The technology of value.Standard is for assessing partitioned nodes to check whether current partition size is subjected to as final choice.If can be with
Receive to be final choice, does not then analyze its child node.Terminate the search to branch.This is still that the upper cost of calculating is very high
(expensive) process, particularly with high definition (HD) editing.
Accelerate sector search process without sacrifice quality based on multi-level machine learning on the contrary, teaching herein describes
Termination scheme in advance.Machine learning is used to train the classifier of block size rank.Classifier is determined for given subregion section
The child node that point continues searching the partitioned nodes, which still executes, to be terminated in advance and using current block size as final size.Here
It is multi-level fault-tolerant according to the having of the size of block different (for example, being measured in RD increased costs) to refer to using term
The training of (for example, binary) classifier.After the environment that scheme can be incorporated to is discussed first, realization is discussed below based on more
The additional details for terminating scheme in advance of class machine study.
Fig. 1 is the figure according to the calculating equipment 100 of the realization of the disclosure.Shown in calculating equipment 100 include communication interface
110, communication unit 120, user interface (UI) 130, processor 140, memory 150, instruction 160 and power supply 170.Such as this paper institute
It uses, term " calculating equipment " includes being able to carry out appointing for any method or its any part or multiple portions disclosed herein
The combination of what unit or unit.
Calculating equipment 100 can be fixed calculating equipment, such as personal computer (PC), server, work station, small-sized meter
Calculation machine or mainframe computer；Or mobile computing device, such as mobile phone, personal digital assistant (PDA), laptop computer or flat
Plate computer.While shown as individual unit, but any one or more elements for calculating equipment 100 are desirably integrated into any number
In the individual physical unit of amount.For example, UI 130 and processor 140 can integrate in first physical unit and memory
150 can integrate in the second physical unit.
Communication interface 110 can be wireless antenna as shown in the figure, such as ethernet port, infrared port, serial port
Wired connection port or can be connect with wired or wireless electronic communication media 180 any other is wired or wireless
Unit.
Communication unit 120, which can be configured as, transmits via communication media 180 or receives signal.For example, as shown, logical
Letter unit 120 is operatively coupled to the antenna for being configured as being communicated at communication interface 110 via wireless signal.For example,
As shown, communication unit 120 is operatively coupled to antenna, which is configured as at communication interface 110 via wireless communication
It number is communicated.Although not being explicitly illustrated in Fig. 1, communication unit 120 be can be configured as via such as radio frequency (RF), ultraviolet
Any wired or wireless communication medium of line (UV), visible light, optical fiber, route or combinations thereof sends, receives or both.Although figure
1 shows single communication unit 120 and single communication interface 110, and any amount of communication unit and any quantity can be used
Communication interface.
UI 130 may include any unit that can be interacted with user, such as virtually or physically miniature keyboard, touch tablet,
Display, touch display, loudspeaker, microphone, video camera, sensor or any combination thereof.As shown, UI 130 can be with
It is operatively coupled with processor or is operatively coupled with any other element of the calculating equipment 100 of such as power supply 170.
Although showing individual unit, UI 130 may include one or more physical units.For example, UI 130 may include for with
Family carries out the audio interface of voice communication and the touch display of the communication for carrying out view-based access control model and touch with user.To the greatest extent
Pipe is shown as individual unit, and communication interface 110, communication unit 120 and UI 130 or part thereof can be configured as combination
Unit.For example, what communication interface 110, communication unit 120 and UI 130 can be implemented as capable of connecting with external touch screen equipment
Communication port.
Processor 140 may include that can manipulate or handle signal that is present or developing later or any of other information sets
Standby or system, processor 140 include optical processor, quantum processor, molecular processor or combinations thereof.For example, processor 140
It may include application specific processor, digital signal processor (DSP), multi-microprocessor, one or more associated with DSP core
Microprocessor, controller, microcontroller, specific integrated circuit (ASIC), field programmable gate array (FPGA), programmable logic
Array, programmable logic controller (PLC), microcode, firmware, any kind of integrated circuit (IC), state machine or any combination thereof.
As it is used herein, term " processor " includes single processor or multiple processors.Processor can be with communication interface
110, communication unit 120, UI 130, memory 150, instruction 160, power supply 170 or any combination thereof are operatively coupled.
Memory 150 may include that any non-transitory computer is available or computer-readable medium, such as can be such as
Any tangible device including, storage, transmission or transmission 160 or associated there any information of instruction, memory 150 can be with
It is used for using or connecting processor 140 by processor 140.Non-transitory computer is available or computer-readable medium can be with
It is such as solid state drive, storage card, removable medium, read-only memory (ROM), random access memory (RAM) including hard
Disk, floppy disk, CD any kind of disk, magnetic or optical card, specific integrated circuit (ASIC) or be suitable for storage e-mail
Any kind of non-transitory medium or any combination thereof of breath.Memory 150 can be for example, by memory bus (not yet explicitly
Show) it is connected to such as processor 140.
Instruction 160 may include the finger for executing any method or its any part or multiple portions disclosed herein
Show.Instruction 160 can be realized with hardware, software or any combination thereof.For example, instruction 160 can be implemented as being stored in storage
Information in device 150, such as computer program, instruction 160 can be executed any as described herein to execute by processor 140
Corresponding method, algorithm, aspect or combinations thereof.Instruction 160 or part thereof can be implemented as including as described herein for executing
Any method, algorithm, aspect or combinations thereof specialized hardware application specific processor or circuit.The part of instruction 160 can be across
Multiple processors on uniform machinery or different machines are distributed or across such as local area network, wide area network, internet or combinations thereof
Network distribution.
Power supply 170 can be used to any suitable equipment of the power supply of communication equipment 110.For example, power supply 170 may include
Cable power；One or more dry cells, such as ni-Cd (NiCd), nickel zinc (NiZn), ni-mh (NiMH), lithium ion (Li-
ion)；Solar battery；Fuel cell；Or any other equipment that can be powered for communication equipment 110.Communication interface 110 is led to
Believe that unit 120, UI 130, processor 140, instruction 160, memory 150 or any combination thereof can be with power supplys 170 operationally
Coupling.
While shown as individual element, communication interface 110, communication unit 120, UI 130, processor 140, instruction
160, power supply 170, memory 150 or any combination thereof can integrate on one or more electronic units, circuit or chip.
Fig. 2 is the figure of the calculating and communication system 200 according to the realization of the disclosure.It calculates and communication system 200 can wrap
Include one or more calculate and communication equipment 100A/100B/100C, one or more access point 210A/210B, one or more
Network 220 or combinations thereof.For example, calculate and communication system 200 be multiple access system, it is described calculating and communication system 200 to
It such as calculates and one or more wired or wireless communication equipment of communication equipment 100A/100B/100C provides such as voice, number
According to, video, message, broadcast or combinations thereof communication.Although Fig. 2 shows three to calculate and communication equipment 100A/ in order to simple
100B/100C, two access point 210A/210B and a network 220, can be used it is any amount of calculating and communication equipment,
Access point and network.
It calculates and communication equipment 100A/100B/100C is, for example, to calculate equipment, all calculating equipment as shown in Figure 1
100.It can be user equipment, such as mobile computing device, meter on knee with communication equipment 100A/100B as shown, calculating
Calculation machine, thin-client or smart phone, and calculate and can be server, such as mainframe or cluster with communication equipment 100C.
Although will calculate and communication equipment 100A/100B is described as user equipment and will calculate to be described as servicing with communication equipment 100C
Device, any calculating and communication equipment can be with some or all functions of execute server, some or all function of user equipment
Or some or all function of server and user equipment.
Each is calculated and communication equipment 100A/100B/100C can be configured as execution wired or wireless communication.Example
Such as, it calculates and communication equipment 100A/100B/100C is configured as transmitting or receiving wired or wireless communication signal and can wrap
Include user equipment (UE), movement station, fixation or moving user unit, cellular phone, personal computer, tablet computer, server,
Consumption electronic product or any similar devices.Although each calculating and communication equipment 100A/100B/100C are shown as single list
Member, calculates and communication equipment may include any amount of interconnection element.
Each access point 210A/210B can be configured as via wired or wireless communication link 180A/180B/180C
With any kind of equipment calculated and communication equipment 100A/100B/100C, network 220 or both communicate.For example, access point
210A/210B includes base station, base transceiver station (BTS), node B, enhancement mode node B (eNode-B), home node-b
(HNode-B), it wireless router, cable router, hub, repeater, interchanger or any similar wired or wireless sets
It is standby.Although each access point 210A/210B is shown as individual unit, access point may include any amount of interconnection element.
Network 220 can be configured as by wired or wireless communication link provide service --- such as voice, data,
Using the combination of the, networking telephone (VoIP) or any other communication protocol or communication protocol --- any kind of network.Example
Such as, network 220 be local area network (LAN), wide area network (WAN), Virtual Private Network (VPN), Mobile or cellular telephone net, internet or
Any other electronic communication mode.Communication protocol, such as transmission control protocol (TCP), User Datagram Protocol can be used in network
Discuss (UDP), Internet protocol (IP), real-time transport protocol (RTP), hypertext transfer protocol (HTTP) or combinations thereof.
It calculates and communication equipment 100A/100B/100C can be wired or wireless logical using one or more via network 220
Letter link is communicated with one another by the combination of wired and wireless communication link.For example, as shown, calculating and communication equipment
100A/100B is communicated via wireless communication link 180A/180B and is calculated with communication equipment 100C via wired communications links
180C communication.Any wired or wireless communication chain can be used in any one of calculating and communication equipment 100A/100B/100C
Road or multiple links are communicated.For example, first calculate and communication equipment 100A using the communication link of the first kind via the
One access point 210A communication, the second calculating and communication equipment 100B are using the communication link of Second Type via the second access point
210B carry out communication and third calculate and communication equipment 100C using third type communication link via third access point (not
Show) it is communicated.Similarly, access point 210A/210B can be via the wired or wireless communication chain of one or more types
Road 230A/230B is communicated with network 220.While figure 2 show that calculating and communication equipment 100A/ via the communication of network 220
100B/100C, calculates and communication equipment 100A/100B/100C can be via any amount of such as directly wired or wireless logical
The communication link of letter link communicates with one another.
It calculates and other realizations of communication system 200 is possible.For example, in the implementation, network 220 can be ad-
Hock network and one or more of it can be omitted access point 210A/210B.It calculates and communication system 200 may include figure
Unshowned equipment, unit or element in 2.For example, calculate and communication system 200 may include more multi-communication devices, network and
Access point.
Fig. 3 is the figure of the video flowing 300 for coding and decoding of realization according to the present invention.Video flowing 300 --- it is all
Such as by the video flowing of video camera capture or the video flowing generated by calculating equipment --- it may include video sequence 310.Video sequence
310 may include a series of consecutive frames 320.Although showing three consecutive frames 320, video sequence 310 may include any amount of
Consecutive frame 320.Each frame 330 from consecutive frame 320 can indicate the single image from video flowing.Frame 330 can wrap
Include block 340.Although not shown in FIG. 3, block may include pixel.For example, block may include 16 × 16 pixel groups, 8 × 8 pixels
Group, 8 × 16 pixel groups or any other pixel group.Unless otherwise indicated herein, term " block " may include super block, macro block, sub-block,
Any other part of segment, piece or frame.Frame, block, pixel or combinations thereof may include display information, such as luminance information, coloration
Information can be used for storing, modify, transmitting or display of video streams or any other part thereof of information.
Fig. 4 is the block diagram of the encoder 400 of realization according to the present invention.Encoder 400 can be all as shown in Figure 1
It calculates and is embodied as example being stored in the equipment of equipment 100 or calculating shown in Figure 2 and communication equipment 100A/100B/100C
Computer software programs in the data storage cell of all memories as shown in Figure 1 150.Computer software programs can wrap
It includes the machine instruction that can be executed by the processor of all processors 140 as shown in Figure 1 and equipment such as this paper institute can be made
State ground encoded video data.Encoder 400 can be implemented as including for example calculating the specialized hardware in equipment 100.
Encoder 400 can encode the input video stream 402 of all video flowings as shown in Figure 3 300 to generate coding (pressure
Contracting) bit stream 404.In some implementations, encoder 400 may include the positive road for generating the bit stream 404 of compression
Diameter.Forward path may include predicting unit 410, converter unit 420, quantifying unit 430, entropy code unit 440 within the frame/frames
Or any combination thereof.In some implementations, encoder 400 may include (being indicated by dashed connection line) reconstruct path to reconstruct
The block of (future) after frame is used to encode.Reconstruct path may include quantifying unit 450, inverse transformation block 460, reconstruct list
Member 470, loop filtering unit 480 or any combination thereof.The other structures variation of encoder 400 can be used for encoded video stream 402.
In order to encode to video flowing 402, each frame in video flowing 402 can be handled in blocks.Therefore, may be used
To identify current block from the block in frame and current block can be encoded.
At predicting unit 410 within the frame/frames, can be used in the intra prediction in single frame or can be can be from frame
Current block is encoded to the inter-prediction of frame.Intra prediction may include according in previously encoded and reconstruct present frame
Sample generates prediction block.Inter-prediction may include that the sample in the reference frame previously constructed according to one or more generates prediction
Block.Generating prediction block for the current block in present frame may include that execution estimation is appropriate in instruction reference frame to generate
Reference block motion vector.
Predicting unit 410 subtracts prediction block from current block (original block) to generate residual block within the frame/frames.Converter unit
420 execute block-based transformation, and the transformation may include the transformation coefficient being transformed to residual block in such as frequency domain.Based on block
The example of transformation include that Karhunen-Loeve transformation (KLT), discrete cosine transform (DCT) and singular value decomposition convert
(SVD).In this example, DCT may include that block is transformed to frequency domain.DCT may include using the transformation series based on spatial frequency
Numerical value, low-limit frequency (that is, DC) coefficient is located at the upper left side of matrix and highest frequency coefficient is located at the lower right of matrix.
Transformation coefficient is converted to discrete magnitude by quantifying unit 430, and the discrete magnitude can be referred to as the transformation coefficient of quantization
Or quantization level.The transformation coefficient that can be quantified by 440 Duis of entropy code unit carries out entropy coding to generate the coefficient of entropy coding.
Entropy coding may include being measured using probability distribution.Entropy encoded coefficients and information for decoding block comprising used pre-
Type, motion vector and quantizer values are surveyed, the bit stream 404 of compression can be output to.Such as run length volume can be used
The various technologies of code (RLE) and zero RLE format the bit stream 404 of compression.
Reconstruct path can be used for maintaining encoder 400 and the corresponding decoder of all decoders 500 as shown in Figure 5 it
Between reference frame synchronization.Decoding process discussed below can be similar to by reconstructing path, and it is single to be included in quantization herein
Quantization is carried out to the transformation coefficient of quantization at member 450 and the transformation coefficient for going quantization is carried out at inverse transformation block 460
Inverse transformation is to generate derivative residual block.Reconfiguration unit 470 will be added to by the prediction block that predicting unit 410 generates within the frame/frames
Derivative residual block is to create the block of reconstruct.Loop filtering unit 480 is applied to the block of reconstruct to reduce the mistake of such as block artifacts
Very.
Other variations of encoder 400 can be used for encoding the bit stream 404 of compression.For example, the encoder based on non-shifting
400 may not need converter unit 420 and directly quantify residual block.In some implementations, quantifying unit 430 and quantifying unit is gone
450 can be combined into individual unit.
Fig. 5 is the block diagram of the decoder 500 of realization according to the present invention.Decoder 500 can be all as shown in Figure 1
It calculates and is embodied as example being stored in the equipment of equipment 100 or calculating shown in Figure 2 and communication equipment 100A/100B/100C
Computer software programs in the data storage cell of all memories as shown in Figure 1 150.Computer software programs can wrap
It includes the machine instruction that can be executed by the processor of all processors 140 as shown in Figure 1 and equipment such as this paper institute can be made
State ground decoding video data.Decoder 500 can be implemented as including for example calculating the specialized hardware in equipment 100.
Decoder 500 receives the bit stream 502 of compression, all bit streams 404 compressed as shown in Figure 4 and decodes pressure
The bit stream 502 of contracting is to generate outputting video streams 504.Shown decoder 500 includes entropy decoding unit 510, goes quantization single
First 520, inverse transformation block 530, within the frame/frames predicting unit 540, reconfiguration unit 550, loop filtering unit 560, deblocking filtering
Unit 570 or any combination thereof.The other structures variation of decoder 500 can be used for decoding the bit stream 502 of compression.
Entropy decoding unit 510 decodes the bit stream 502 of compression using such as context adaptive binary arithmetic decoding
Interior data element is to generate the transformation series manifold of quantization.The transformation coefficient of 520 pairs of quantifying unit quantizations is gone to carry out quantization simultaneously
And inverse transformation block 530, to going the transformation coefficient of quantization to carry out inverse transformation to generate derivative residual block, the derivative residual block can
It is corresponding with the derivative residual block generated with the inverse transformation block 460 as shown in Fig. 4.Predicting unit 540 uses within the frame/frames
Decoded head information generates prediction block corresponding with the prediction block created in encoder 400 from the bit stream 502 of compression.
At reconfiguration unit 550, prediction block is added to derivative residual block to create the block of reconstruct.Loop filtering unit 560 is applied
In the block of reconstruct to reduce block artifacts.Deblocking filtering unit 570 is applied to the block of reconstruct to reduce block distortion and by result
Output is outputting video streams 504.
Other variations of decoder 500 can be used for decoding the bit stream 502 of compression.For example, decoder 500 may not need
Deblocking filtering unit 570 and generate outputting video streams 504.
Fig. 6 is the figure according to a part 600 of the frame of all frames 330 as shown in Figure 3 of the realization of the disclosure.As schemed
Show, the part 600 of frame includes four 64 × 64 pieces 610 in two rows and two column in matrix or Cartesian plane.At certain
In a little realizations, 64 × 64 pieces are maximum coding unit, N=64.Each 64 × 64 pieces may include four 32 × 32 pieces 620.
Each 32 × 32 pieces may include four 16 × 16 pieces 630.Each 16 × 16 pieces may include four 8 × 8 pieces 640.Often
One 8 × 8 pieces 640 may include four 4 × 4 pieces 650.Each 4 × 4 piece 650 includes 16 pixels, and described piece 650 can be with
It indicates in four rows and four column in the corresponding block of each of Cartesian plane or matrix.Pixel includes indicating to catch in frame
The information of the image obtained, such as luminance information, colouring information and location information.In this example, all as shown 16 × 16
The block of block of pixels includes luminance block 660, and the luminance block 660 includes luminance pixel 662 and two chrominance blocks, such as U or Cb
Chrominance block 670 and V or Cr chrominance block 680, each chrominance block include chroma pixel 690.As shown, luminance block 660 includes
16 × 16 luminance pixel 662, and each chrominance block 670/680 includes 8 × 8 chroma pixel 690 as shown in the figure.To the greatest extent
Pipe shows a kind of piece of arrangement, but any arrangement can be used.It, in some implementations, can be with although Fig. 6 shows N × N block
Using N × M block, wherein N ≠ M.It is, for example, possible to use 32 × 64 pieces, 64 × 32 pieces, 16 × 32 pieces, 32 × 16 pieces or it is any its
The block of his size.In some implementations, N × 2N block, 2N × N block or combinations thereof can be used.
Fig. 6 illustrates how the sector search encoded using user video recursively to decompose showing for four 64 × 64 blocks
Example.Video coding may include the coding of orderly block rank.The coding of orderly block rank includes suitable with the scanning of such as grid
Block in the sequential encoding frame of sequence, in the raster scanning sequence from the BOB(beginning of block) in the upper left corner of the part of frame or frame and
It advances from left to right and from top row to bottom row along row, identifies that each block is subsequently used in processing, to identify and process block.For example,
64 × 64 pieces in the top row and left column of frame can be the block of first coding and close to 64 × 64 pieces on the right side of first block
It can be the block of second coding.Second row at top can be the row of the second coding, so that in the right column of the first row
64 × 64 pieces after 64 × 64 pieces in the left column of the second row of coding.Other scanning sequencies including wavefront, level, vertical etc. are
It is possible.
Carrying out coding to block may include using quadtree coding, and the quadtree coding may include suitable with grid scanning
Smaller piece unit (also referred to as sub-block) in sequence encoding block.For example, 64 shown in the lower left corner of the part of frame shown in Fig. 6
× 64 pieces can be used quadtree coding to encode, wherein 32 × 32 pieces of coding upper left, 32 × 32 pieces of upper right are then encoded,
Then then 32 × 32 pieces of encoded left encode 32 × 32 pieces of bottom right.Can be used quadtree coding to each 32 ×
32 block codings, wherein 16 × 16 pieces of coding upper left, 16 × 16 pieces of upper right are then encoded, then the 16 × 16 of encoded left
Then block encodes 16 × 16 pieces of bottom right.Quadtree coding can be used to each 16 × 16 block coding, wherein encoding upper left
8 × 8 pieces, then encode 8 × 8 pieces of upper right, then the 8 × 8 of encoded left piece, then encode 8 × 8 pieces of bottom right.It can be with
Using quadtree coding to each 8 × 8 block coding, wherein encoding 4 × 4 pieces of upper left, 4 × 4 block codes of upper right are then encoded,
Then then 4 × 4 pieces of encoded left encode 4 × 4 pieces of bottom right.In some implementations, 8 can be omitted for 16 × 16 pieces
× 8 pieces and quadtree coding can be used to 16 × 16 block codings, wherein 4 × 4 pieces of coding upper left, then scanned with grid
4 × 4 pieces of others in 16 × 16 pieces of sequential encoding.
Video coding may include pressing for example, by omitting certain information in primitive frame according to the frame of corresponding coding
Contracting includes the information in primitive frame or input frame.For example, coding may include reducing spectral redundancy, reducing spatial redundancy, subtract
Few time redundancy or combinations thereof.
Reducing spectral redundancy may include using based on luminance component (Y) and two chromatic components (U and V or Cb and Cr)
Color model, the color model are referred to as YUV or YCbCr color model or color space.Using YUV color model (rather than
RGB color model or space) include the luminance component of a part for indicating frame using relatively great amount of information and uses phase
Each corresponding chromatic component of the part of frame is indicated a small amount of information.For example, a part of frame is by may include
It the high-resolution luminance component of 16 × 16 block of pixels and is indicated by two low resolution chromatic components, each coloration point
This of frame is partially shown as 8 × 8 block of pixels by amount.Pixel indicates the value in such as 0 to 255 ranges and can be used for example
Eight bits carry out storage or transmission.Although describing the disclosure with reference to YUV color model, any color model can be used
Reducing spatial redundancy may include that block is transformed to frequency domain using the transformation of such as discrete cosine transform (DCT).It is all
The transform coefficient values based on spatial frequency can be used to execute in the unit of the encoder of converter unit 420 as shown in Figure 4
DCT。
Reducing time redundancy may include using the similitude of interframe to use the opposite of reference frame based on one or more
A small amount of data carry out coded frame.Reference frame can be the previous coding of video flowing, decoded and reconstruct frame.For example, current
The block or pixel of frame can be similar to spatially corresponding piece or pixel of reference frame.The block or pixel of present frame can be similar to
The block or pixel of reference frame at different spatial, so that reducing time redundancy includes the block or picture generated in instruction present frame
The motion information of space parallax exclusive or translation between the position and the corresponding position of block or pixel in reference frame of element.
Reducing time redundancy can also include identifying reference frame corresponding with the current block of present frame or pixel or reference
Block or pixel in a part of frame.For example, for for encode present frame current block or pixel optimical block or pixel and
Search for a part of (for example, stored in memory) reference frame or reference frame.Search can identify the block of reference frame, for
The block of the reference frame minimizes the difference of the pixel value between reference block and current block during referred to as motion search.At certain
In a little realizations, the part of the reference frame of search is restricted in motion search.For example, search reference frame part (for example,
Region of search) may include reference frame a limited number of row.In this example, identification reference block includes calculating in region of search
Cost function between the pixel of block and the pixel of current block, the summation (SAD) of such as absolute difference.
The spatial diversity between current block in the position and present frame of reference block in reference frame can be expressed as moving
Vector.The difference of pixel value between reference block and current block is referred to as differential data, residual error data or residual block.It is moved generating
Vector is referred to as estimation and can be based on using the position of cartesian coordinate that the pixel of current block is designated as fx,y.Class
As, based on using the position of cartesian coordinate that the pixel of the region of search in reference frame is designated as rx,y.It can be based on for example
SAD between the pixel of present frame and the respective pixel of reference frame determines the motion vector (MV) of current block.
Although for the sake of clarity indicating that frame can be in any data knot to describe herein with reference to the matrix of frame or Descartes
Stored in structure, transmit, handle or any combination thereof, allow to effectively indicate pixel value for frame or image.For example, frame can
To store, transmit in the two dimensional data structure of the matrix shown in such as or in the one-dimensional data structure of such as vector array,
Processing or any combination thereof.The expression --- two-dimensional representation shown in such as --- of frame can correspond to rendering of the frame as image
In physical location.For example, the position in the upper left corner of the block in the upper left corner of frame corresponds to a left side of the frame as the rendering of image
Physical location in upper angle.
Video coding to current block may include that optimal coding mode is identified from multiple candidate coding patterns, described
Optimal decoding mode provides the flexibility of vision signal of the processing with various statistical properties and compression effect can be improved
Rate.For example, video encoder assesses several candidate coding patterns to identify the forced coding mode to block, the optimal coding
Mode can be the coding mode for minimizing the error metrics of such as RD cost of current block.In some implementations, by being based on
Similitude between current block and corresponding prediction block limits available candidate coding pattern collection to reduce search candidate code mould
The complexity of formula.
By improving block-based code efficiency for block subregion is one or more subregions, the subregion can be rectangle
Subregion, including square.It in some implementations, the use of the Video coding of subregion include being selected from multiple candidate partition schemes
Partition scheme.For example, the candidate partition scheme for 64 × 64 coding unit may include size from 4 × 4 to 64 × 64
Rectangular dimension subregion, such as 4 × 4,4 × 8,8 × 4,8 × 8,8 × 16,16 × 8,16 × 16,16 × 32,32 × 16,32 × 32,
32 × 64,64 × 32 or 64 × 64.It in some implementations, the use of the Video coding of subregion include complete sector search, it is described
Complete sector search includes being encoded and being selected most to coding unit by using each available candidate partition scheme
Good scheme generates the scheme of the smallest rate-distortion or cost, such as to select partition scheme.
As described herein encoded video frame includes identifying the square partition for encoding current block with scanning sequency consideration
Case.It identifies partition scheme and can include determining that be the list of the maximum coding unit size with 64 × 64 as shown by block coding
Block subregion is still multiple subregions by a subregion, as shown, the multiple subregion and such as 32 × 32 piece 620,16 × 16 pieces
630 or 8 × 8 piece 640 of sub-block is corresponding, and can include determining whether sub-block subregion to be lesser point one or more
Area.For example, 64 × 64 pieces can be with subregion for four 32 × 32 subregions.Three subregions in four 32 × 32 subregions can be encoded to
32 × 32 subregions and the 4th 32 × 32 subregion can subregion be further four 16 × 16 subregions.In four 16 × 16 subregions
Three can be encoded to 16 × 16 subregions and the 4th 16 × 16 subregion can subregion be further four 8 × 8 subregions, often
One 8 × 8 subregion can be encoded to 8 × 8 subregions.In some implementations, identification partition scheme may include using region policy decision
Tree.
Since Fig. 7, sector search according to the teaching of this article is more fully described.Fig. 7 is shown for three blocks
The figure of the decision tree 700 for recursive partitioning of the binary classifier of size class.More specifically and as briefly mentioned above
It arrives, is determined using classifier for given partitioned nodes based on the termination scheme of multi-level machine learning and continue search downwards
The final block size for terminating in advance and taking current block size as specific branch is still executed to its child node.
With reference to the example of Fig. 7, it is related to executing down toward each block size rank of minimum block size (being herein 4 × 4) and hangs down
Straight subregion, horizontal partitioning, segmentation subregion or zoneless decision.In specific block size rank, most about any subregion
Good decision can be based on the error amount of such as RD cost calculation.That is, calculation rate (for example, bit number of partition encoding)
With distortion (for example, error compared with primitive frame in reconstructed frame).Compared with level of distortion (for example, minimum RD cost) most
Low rate indicates the optimally partitioned of block size rank.If block size level without subregion, does not consider further dividing to child node
Area.In addition, if selection vertical partitioning or horizontal partitioning, do not consider the further subregion to child node.If having selected segmentation
Subregion, can be to the further subregion of child node.
As an example, it is 64 × 64 that no subregion, which results in final block size, when maximum coding unit is 64 × 64 pieces
Pixel.However, it is possible to further to 64 × 64 pieces of subregions.For example, 64 × 64 pieces of vertical partitioning include two subregions (and most
Whole block size is 32 × 64 pixels), 64 × 64 pieces of horizontal partitioning include that (and final block size is 64 × 32 pictures to two subregions
Element) and 64 × 64 pieces of segmentation subregion include each for 32 × 32 4 subregions.When encoding 32 × 32 pieces, 32 × 32 pieces
Without subregion result in final block size be 32 × 32 pixels.It, can be further when 32 × 32 pieces of subregions are segmentation subregions
To 32 × 32 pieces of subregions.For example, 32 × 32 pieces of vertical partitioning includes that (and final block size is 16 × 32 pictures for two subregions
Element), 32 × 32 pieces of horizontal partitioning include two subregions (and final block size is 32 × 16 pixels) and 32 × 32 pieces
Segmentation subregion includes that each is 16 × 16 4 subregions.Similarly, final block size is resulted in without subregion be for 16 × 16 pieces
16 × 16 pixels.It, can be further to 16 × 16 pieces of subregions when 16 × 16 pieces of subregions are segmentation subregions.For example, 16 × 16
The vertical partitioning of block includes two including two subregions (and final block size is 8 × 16 pixels), 16 × 16 pieces of horizontal partitioning
It is 8 × 8 four points that a subregion (and final block size is 16 × 8 pixels) and 16 × 16 pieces of segmentation subregion, which include each,
Area.8 × 8 pieces without subregion cause final block size be 8 × 8 pixels.It, can be into one when 8 × 8 pieces of subregions are segmentation subregions
8 × 8 pieces of subregion of step.For example, 8 × 8 pieces of vertical partitioning includes two subregions (and final block size is 4 × 8 pixels), 8 × 8
The horizontal partitioning of block includes two subregions (and final block size is 8 × 4 pixels) and 8 × 8 pieces of segmentation subregion includes every
One is 4 × 4 four subregions.In this example, smallest partition is having a size of 4 × 4 pixels.
According to the teaching of this article decision can be terminated in advance in certain or all block size ranks.It can be directed to each
One classifier of a block size rank training.In the example shown in Fig. 7, real to block size 64 × 64,32 × 32 and 16 × 16
It now terminates in advance and trains three classifiers for being expressed as C64, C32 and C16.That is, considering that there are 64 × 64 pictures
When the block of the block size of element, 32 × 32 pixels or 16 × 16 pixels, the classifier that the block size can be used is carried out about to block
Subregion is not still to the decision of termination in advance of block subregion (do also referred to as subregion/without region policy decision).When carrying out decision, can incite somebody to action
Vertical partitioning mode, horizontal partitioning mode and segmentation compartment model are compared with no subregion.Although being illustrated by way of example three
It is a to terminate decision in advance, it can be for more or fewer block size ranks (in some instances, including subregion can be can be carried out
Each rank) it arranges to terminate the quantity of decision.
Fig. 8 is the flow chart according to the process 800 for training classifier of the realization of the disclosure.Process 800 can be by
The processor of the processor 140 of such as Fig. 1 in conjunction with the encoder of the encoder 400 in such as Fig. 4 is realized.Process 800 can
To be realized by the instruction of the instruction 160 of such as Fig. 1.
Training classifier first relates to prepare training data.Prepare training data with reference to the 802-810 description in Fig. 8.?
At 802, training frames are received.It can be received by accessing the storage frame being stored in such as memory of memory 150
Training frames.Training frames can be received from external source by communication unit 120.It can read, obtain or with other in any way
Mode receives training frames.Training frames can be selected from one or more training video sequences.In this example, four training are come from
20 frames of video are used as training frames.Training frames can have image, and described image has different characteristics.For example, instruction
Practicing frame can have the background content varied less in color in frame, the foreground object with edge, screen projection content
Deng.When encoding training frames, different features allows training frames to provide various training datas for different block sizes.In the example
In, different block sizes is N × N, wherein N=64,32 and 16, but other block sizes can be used.
Next begin to use the multiple coded frame of different the encoding option (referred to herein as parameter) to generate coding 804
Block.It may include the first frame for selecting training frames that encoding block is generated at 804.There is no specific sequences in need of consideration in frame
Column, and term first frame and to frame other with reference to being only used for for frame being distinguished from each other out.Generating encoding block at 804 can be with
The encoding option collection is selected including each example to coded frame.For each example of coded frame, the encoding option collection can be with
Including quantization parameter, resolution ratio etc..Some or all value that the encoding option is concentrated can change for each frame.For example,
Resolution ratio can be concentrated at least two the encoding options and keep identical, and quantization parameter is for each collection variation.Show another
In example, quantization parameter is identical at least two the encoding options concentration.A variety of the encoding option collection be it is possible, described a variety of
The encoding option is concentrated, it may be desirable to which at least one value and/or at least one volume of the encoding option are concentrated in each the encoding option in ground
Code option is different.
Coding choosing can be obtained by establishing for correspondingly encoding the different target bit rates of each training frames
Item collection.Bit rate is the measurement of the number of the bit transmitted in the time span of setting.Different target bit rates are related to not
The different values of same the encoding option and/or the encoding option.Therefore, the use for the different target bit rates of training frames is led
Training data is caused to consider the different coding option or parameter of identical input content (for example, input frame).It in this example, can be to every
One frame uses 10-14 different target bit rates.
Zonal coding first is used at 804 with reference to as described in the example of Fig. 6 using each of the encoding option collection
Frame.In summary, block is considered with scanning sequency.Not to block subregion --- that is, first with maximum coding unit size
Consider block.These blocks can be such as 64 × 64 pieces, all 64 × 64 piece 610 as shown in Figure 6.Different can be used can be used
Prediction mode --- such as one or more inter-frame forecast modes, one or more intra prediction modes or different interframe are pre-
The combination of survey mode and intra prediction mode --- encode each block.In some implementations, using all available prediction moulds
Formula encoding block.
Can by each piece recursively subregion be different compartment models.For example, can according in Fig. 7 decision tree (
Referred to as partition tree) 700 using horizontal partitioning mode, vertical partitioning mode or segmentation compartment model come to block subregion.In partition tree
At 700 each node, different available prediction mode coded sub-blocks (the also referred to as block or block of subregion) are used.In partition tree
At 700 each node, all available prediction mode coded sub-blocks can be used.Available prediction mode can be used
All different combinations carry out coded sub-blocks.For the sub-block in each encoding block and block combination (for example, in each node
Place), calculate the error amount of such as RD cost.Compartment model (including the nothing for each piece is selected based on minimum error amount
Compartment model) and prediction mode.
Although it is contemplated that each available prediction mode, the technology for reducing the quantity of the prediction mode of test can be with
Teaching herein is used together.
The process for generating the block of coding for first the encoding option collection at 804 can be by reference to the example in Figure 10 A
It checks, Figure 10 A is the figure according to a part of the frame of first the encoding option collection subregion.Assuming that the part is N × N block, wherein N
=64, it is handled with raster scanning sequence, considers entire block first.Consider for zoneless part various prediction modes it
Afterwards, consider other prediction modes and compartment model.Assuming that the decision tree 700 of application drawing 7, following consideration vertical partitioning mode,
Horizontal partitioning mode and segmentation compartment model and various prediction modes.For four N/2 × N/2 blocks of segmentation compartment model
Each of (sub-block A-D) considers vertical partitioning mode, horizontal partitioning mode and segmentation compartment model and various prediction moulds
Formula.For example, segmentation compartment model leads to four N/4 × N/4 blocks (sub-block A0-A3) for sub-block A.For segmentation compartment model
Each sub-block A0-A3, consider vertical partitioning mode, horizontal partitioning mode and segmentation compartment model and various prediction moulds
Formula.Continuing with block A the process until reaching the smallest prediction block size.It is generating for three block size rank training two
In the example of the training example of meta classifier C64, C32 and C16, record encodes the optimum way of each block and uses later
Make the associated label of training example.
Identical processing is executed for each of sub-block B, sub-block C and sub-block D.That is, recursively by sub-block
Subregion (also referred to as recursively decomposes).At each node, assesses different prediction modes and select optimal prediction mould
Formula.According to the information, the error amount at each node is determined.
Using first the encoding option collection, display is optimally partitioned for the part.For the part in Figure 10 A, nothing is encoded
The error amount of N × N block of subregion is higher than the summation of the error amount of four N/2 × N/2 blocks (sub-block A-D) of coding, and lower than coding
The summation of the error amount of two vertical N/2 × N blocks in the vertical partitioning mode of the part and the level for encoding the part
The summation of the error amount of two horizontal N × N/2 blocks in compartment model.The error amount for encoding zoneless sub-block A, which is higher than, to be compiled
The summation of the error amount of four N/4 × N/4 blocks (sub-block A0-A3) of code, and two in the vertical partitioning mode lower than coded sub-blocks A
The summation of error amount of a vertical N/4 × N/2 block and two horizontal N/2 in the horizontal partitioning mode of coded sub-blocks A
The summation of the error amount of × N/4 block.Encode each for three N/4 × N/4 blocks that zoneless label is sub-block A0, A1 and A2
Error amount be lower than compartment model --- vertical partitioning mode (two N/8 × N/4 blocks), horizontal partitioning mode (two N/4 × N/
8 pieces) and segmentation compartment model (four N/8 × N/8 blocks) --- each of error amount summation.In contrast, it compiles
The error amount for N/4 × N/4 block that the zoneless label of code is sub-block A3 is higher than four N/8 × N/8 blocks (sub-block A30-A33) of coding
Error amount summation, and lower than coded sub-blocks A3 vertical partitioning mode in two vertical N/8 × N/4 blocks error amount
Summation and coded sub-blocks A3 horizontal partitioning mode in two horizontal N/4 × N/8 blocks error amount summation.
Two N/2 × N/2 blocks for being sub-block B and sub-block C about label encode zoneless each (sub-block B0 and C0)
Error amount be lower than compartment model --- vertical partitioning mode (two N/4 × N/2 blocks), horizontal partitioning mode (two N/2 × N/
4 pieces) and segmentation compartment model (four N/4 × N/4 blocks) --- each of error amount summation and according to decision
The summation of each of the Fractionation regimen of tree 700 error amount of compartment model.In some implementations, node, subregion are reached
One in mode when not resulting in the node of lower error amount, does not execute further subregion.Therefore, once it is determined that sub-block B
There is lower mistake than any one of vertical partitioning mode, horizontal partitioning mode or segmentation compartment model without subregion with C
Difference, it is convenient to omit by the subregion for the block that segmentation compartment model generates.
The error amount for encoding N/2 × N/2 block that zoneless label is sub-block D is higher than coding and is generated by segmentation compartment model
Four N/4 × N/4 blocks (sub-block D0-D3) error amount summation, and lower than coded sub-blocks D vertical partitioning mode in two
The summation of error amount of a vertical N/4 × N/2 block and two horizontal N/2 in the horizontal partitioning mode of coded sub-blocks D
The summation of the error amount of × N/4 block.In this example, label is the further subregion of four N/4 × N/4 blocks of sub-block D0-D3
The reduction of error amount is not resulted in, therefore sub-block D0-D3 indicates the best or optimum partition of sub-block D.
The subregion of Figure 10 A is obtained using first the encoding option collection.Figure 10 B is the frame using second encoding parameter collection subregion
Partial figure.In this example, the part in Figure 10 B is identical as the part in Figure 10 A, but due to different the encoding option collection
Use, subregion is different.Execute the identical processing with reference to Figure 10 A description.That is, being used according to decision tree 700
By the partial recursive subregion (the also referred to as recursively decomposition) of different prediction modes.At each node, error amount is determined.
Lowest error value determines the subregion at the node.
About Figure 10 B, be illustrated by way of example using second the encoding option collection the part it is optimally partitioned.Use nothing point
The error amount that area encodes the part (that is, entire N × N block) is higher than four N/ that coding is generated from the segmentation compartment model of the part
The summation of the error amount of 2 × N/2 block (label is sub-block A-D), and lower than two in the vertical partitioning mode for encoding the part
The summation of the error amount of vertical N/2 × N block and encode two horizontal N × N/2 in the horizontal partitioning mode of the part
The summation of the error amount of block.
About the N/2 × N/2 block subregion for being sub-block A to label, the error amount for encoding zoneless sub-block A is higher than from level
The summation of the error amount for two N/2 × N/4 blocks (sub-block A0 and A1) that compartment model generates, and it is vertical lower than coded sub-blocks A
Four N/4 × N/4 blocks in the segmentation compartment model of two vertical N/4 × N/2 blocks and coded sub-blocks A in compartment model
Error amount summation.Because horizontal partitioning mode does not have further compartment model in the example in figure 7, son is omitted
The further processing of block A0 and A1.That is, not executing the further subregion at each node.Similarly, it encodes
N/2 × N/2 block error amount that zoneless label is sub-block B is higher than two N/4 × N/2 that coding is generated from vertical partitioning mode
The summation of the error amount of block (sub-block B0 and B1), and two horizontal N/2 in the horizontal partitioning mode lower than coded sub-blocks B ×
The summation of the error amount of four N/4 × N/4 blocks in the segmentation compartment model of N/4 block and coded sub-blocks B.Because Fig. 7's
Vertical partitioning mode does not have further compartment model in example, so omitting being further processed for sub-block B0 and B1.
It is more muti-piece by N/2 × N/2 block subregion that the label in Figure 10 B is sub-block C.Encode the mistake of zoneless sub-block C
Difference is higher than the summation for encoding the error amount of the four N/4 × N/4 blocks (sub-block C0-C3) generated by segmentation compartment model, and low
The horizontal partitioning mode of two vertical N/4 × N/2 blocks and coded sub-blocks C in the vertical partitioning mode of coded sub-blocks C
In two horizontal N/2 × N/4 blocks error amount summation.Encode in zoneless four N/4 × N/4 blocks three (that is,
Sub-block C0, C1 and C2) each of error amount be lower than compartment model --- vertical partitioning mode (two N/8 × N/4 blocks),
Each of horizontal partitioning mode (two N/8 × N/4 blocks) and segmentation compartment model (four N/8 × N/8 blocks) ---
The summation of error amount.In contrast, encode zoneless last N/4 × N/4 block (sub-block C3) error amount be higher than coding from
Divide the summation of the error amount for four N/8 × N/8 blocks (sub-block C30-C33) that compartment model generates, and is lower than coded sub-blocks C3
Vertical partitioning mode in two vertical N/8 × N/4 blocks and coded sub-blocks C3 horizontal partitioning mode in two water
The summation of the error amount of flat N/4 × N/8 block.
Finally, and being also in this way, encoding the label in zoneless Figure 10 B is sub-block D for the sub-block D in Figure 10 A
The error amount of N/2 × N/2 block be higher than the mistake of four N/4 × N/4 blocks (sub-block D0-D3) that coding is generated by segmentation compartment model
The summation of difference, and it is total lower than the error amount of two vertical N/4 × N/2 blocks in the vertical partitioning mode of coded sub-blocks D
With and the horizontal partitioning mode of coded sub-blocks D in two horizontal N/2 × N/4 blocks error amount summation.In the example
In, label is that the further subregion of four N/4 × N/4 blocks of sub-block D0-D3 does not result in the reduction of error amount, therefore sub-block D0-
The best or optimum partition of D3 expression sub-block D.
Figure 10 A and 10B illustrate a part that same frame is encoded using two different the encoding option collection.At 804 pair
The rest part of frame similarly subregion and is encoded to generate the block of coding.It is encoded at 804 by using different the encoding options
After block of the frame to generate coding, process 800 extracts feature from training data and tags for each example.In Fig. 8
Example in, include the feature that feature set at 806 based on definition extracts block from feature is extracted in training data.Also such as Fig. 8
Shown, it may include at 808 that label is associated with the feature of block for tagging for each example.It is retouched with reference to the example of Figure 11
State the processing at 806 and 808.
Figure 11 is the figure using the feature extraction of a part of the frame of Figure 10 A and Figure 10 B of subregion.In this example, it mentions
The data taken are shown in single table, but this is not required.Multiple tables can be used.The data of extraction can be in a variety of forms
Storage.The data of extraction can store in one or more different files.For example, the data extracted can be according to the ruler of block
It is very little to store.In Figure 11, each training example 1- training example 13 is associated with the block in Figure 10 A, for the figure
Block in 10A has carried out region policy decision and each training example 14- training example 26 is associated with the block in Figure 10 B, right
Block in Figure 10 B has carried out region policy decision.For each block, extracts feature 1 and be used as to feature K corresponding to feature
Block corresponding value.
From in high definition (HD) video flowing obtain training data example in, for example, for training block feature and
Therefore the feature of the block extracted at 806 may include six or more.In one example, 1) feature of block includes:
The rate cost without compartment model of current block；2) the distortion cost without compartment model of current block；3) current block without subregion mould
The size (if any) of the motion vector of formula；4) in last frame positioned at the block to exist together, in present frame above block with
And certain or all compartment models of the block in the left side in present frame；5) multiple non-zero systems without compartment model of current block are encoded
Number；And 6) quantizer (Q) value or quantized level of current block or frame.The feature of any block that information is provided can be used.It uses
The feature of block can be limited to available piece of encoder when with raster scanning sequence to current block subregion of feature.For example, block
Feature can exclude when only subregion at specific block node is completed or after completing it is those of known.
When using the video flowing of low resolution, it is possible to reduce form the quantity of the feature of the feature set of definition.Replacement
The feature with lesser amount of value or selection can be used in ground or additionally.One or two of these options cause to instruct
Practice the lesser characteristic dimension of data set.Which reduce to during the on-line testing terminated in advance training and use linear classification
The computing cost of device.
It tags at 808 for each training example.For example, will instruction encoding block whether the label of subregion and the spy of block
Sign is associated.The label of each training example is determined by the optimum partition decision of current block node.In the example of fig. 11, it marks
Number " 1 " instruction current block node is final optimal selection, that is, not to the further subregion of node.Label " 0 " instruction is needed into one
Step search, i.e., to the further subregion of node.Because teaching herein describes binary classifier, these labels are not specified to be made
Specific further compartment model (for example, horizontal partitioning mode, vertical partitioning mode or segmentation compartment model).Change sentence
It talks about, binary classifier is specified to the further subregion of block still not subregion, but does not specify the subregion mould for further subregion
Formula.Multi-tag classifier can be trained further discriminate between compartment model (for example, horizontal partitioning mode, vertical partitioning mode or
Divide compartment model) to further speed up cataloged procedure.
Once be extracted the feature of block at 806 and be associated with label at 808, process 800 executed at 810 about
The inquiry that whether there is more multiframe is concentrated in training video frame.If it is, process 800 back to 804 with reference Figure 10 A and
The similar method of Figure 10 B description encodes new frame by using different the encoding options to generate the block of coding.If opposite
At 810 without others frames, then process 800 proceed to 812 with train classifier with determine whether need during coding into
One step is to block subregion.
As it was earlier mentioned, the size for different blocks generates classifier, the size of block is N × N, N/2 in this example
× N/2 and N/4 × N/4.In some cases, the size of block may include N/8 × N/8, so that generating four classifiers.Value N
64 can be equal to.If value N is greater than 64, additional classifier can be generated.
There is corresponding value to the block feature of each training Cass collection.In some implementations, using absolute value.?
Training classifier may include training classifier using training example at 812.However, the absolute value of each characteristic dimension can
Energy can great changes will take place.Before training classifier, dimension normalization can be executed to feature before training.Although a variety of
Different normalization schemes or technology be it is possible, the present disclosure describes the marks for each feature vector or value x in dimension i
The method (also referred to as standardization normalization scheme or technology herein) of standardization, in which:
In equation (1), xiIt is original feature vector, and x 'iIt is normalized feature vector.In other words, xiIt is dimension
Spend the original value and x ' of the feature at iiIt is the normalized value of the feature at dimension i.Equation (1) also uses this feature dimension
Mean value in iAnd standard deviation sigmai.Normalized value can be arranged in the table similar to Figure 11, or can use similar
Data store otherwise.For example, the normalized value of feature 1 to feature K can replace the feature 1 in Figure 11 to feature K
(for example, V11To V26K) original value.
It the use of for normalized standardized method is simple and effective compared with other technologies.For example, using tool
There is the softmax of sigmoid function to be related to an exponent arithmetic, division arithmetic and several addition/subtraction operations are twice with normalizing
Change the characteristic dimension in each training example.In contrast, standardized method is transported using a subtraction and a division
(multiplication can be easily modified to) is calculated for normalizing.Normalization can also be in coding stage for each assessment
Block node, therefore it can be desirable to simple technology in the calculating for being related to low overhead compared with other normalization technologies.In addition to mark
Except quasi- difference or standard deviation is replaced, one or more variance yields can be used.
After normalization, training is used for determining classification during coding whether will further to block subregion at 812
Device may include for the individual linear binary classifier of each block size training.It can be executed on the basis of block size
Normalization and training at 812.For example, in normalized, it, can also be by each other than each characteristic dimension i
Block size calculates average valueAnd standard deviationi.In the example in figure 7, exist correspondingly with N × N block, N/2 × N/2 block and
N/4 × N/4 block associated three classifiers C64, C32 and C16.
In the example that the encoding option collection summarized in using Figure 11 encodes frame, training example 1 and training example
14 is associated with the subregion of N × N block.In general, using examples more more than example provided herein training.In training example 1
The value V of characteristic dimension 111With the value V of the characteristic dimension 1 in training example 14141It can be used for the average value of characteristic dimension 1With
Standard deviation sigma1Calculating.Similarly, for training the phase of the residue character to characteristic dimension K in example 1 and training example 14
The value answered can be used for the calculating of the average and standard deviation of each feature (for example, the value V in training example 11KIt is real with training
Value V in example 1414It can be used for the mean value of characteristic dimension KAnd standard deviation sigmaKCalculating).Using at 812 should be (for example, normalizing
Change) data train classifier C64 as the input of machine-learning process.Training classifier C64 does not need specific machine
Learning process.In general, can be expected to use the machine-learning process of supervised learning, because example input (that is, each feature
Value) and their desired output (i.e., if subregion or not subregion) can be used for generating input be mapped as the general of output
Rule.Convolutional neural networks (CNN) and support vector machines (SVM) are can be in machine learning used in the training at 812
The example of process.
Equally in Figure 11, example 2-5 and training example 15-18 and corresponding N/2 × N/2 (i.e. 32 × 32) block are trained
Subregion is associated.The value V of training example 2-5 and the characteristic dimension 1 in training example 15-1821-V51And V151-V181It can be used for
In the average value of the characteristic dimension 1 of the block size levelAnd standard deviation sigma1Calculating.Similarly, for training example 2-5
It can be used for the flat of each characteristic dimension with the corresponding value of the residue character to characteristic dimension K in training example 15-18
The calculating of mean value and standard deviation is (for example, value V2K–V5KWith value V15K–V18KIt can be used for the mean value of characteristic dimension KAnd standard deviation sigmaK
Calculating).(for example, normalized) data are used to train classifier as the input of machine-learning process at 812
C32.For training the machine-learning process of classifier C32 can be identical as training the machine-learning process of classifier C64
Or it is different.
Finally, training example 6-13 and training example 19-26 are associated with N/4 × N/4 (i.e. 16 × 16) subregion of block.Instruction
Practice the value V of example 6-13 and the characteristic dimension 1 in training example 19-2661–V131With value V191–V261It can be used in the block size
The average value of the characteristic dimension 1 of levelAnd standard deviation sigma1Calculating.Similarly, for training example 6-13 and training example
The corresponding value of the residue character to characteristic dimension K in 19-26 can be used for the average and standard deviation of each feature
It calculates (for example, value V6K–V13KWith value V19K–V26KIt can be used for the mean value of characteristic dimension KAnd standard deviation sigmaKCalculating).At 812
(for example, normalized) data are used to train classifier C16 as the input of machine-learning process.For training classifier
The machine-learning process of C16 can with for training the machine-learning process of classifier C32 and classifier C64 identical or different.
For binary classification, distribute to during the training period each training example weighted value can be it is identical.However,
In the context of Video coding, positive sample (being in this case no blockette) mistake is classified as negative sample (blockette)
Any RD increased costs are not will lead to.That is, this mistake classification not will lead to any increase (massless damage of error amount
It loses).In contrast, negative sample (being in this case blockette) mistake being classified as positive sample (no blockette) can increase
Error amount, such as RD cost.Based on the fact, the maximum that can be used at 812 for controlling the error amount allowed is increased
Additional authentication data collection modifies trained classifier.
Fig. 9 is according to the realization of the disclosure for modifying the process with finalization classifier using additional authentication data
900 flow chart.Process 900 can be by the processor of such as Fig. 1 in conjunction with the encoder of the encoder 400 in such as Fig. 4
140 processor is realized.Process 900 can be realized by the instruction of the instruction 160 of such as Fig. 1.Process 900 is also referred to as testing
Demonstrate,prove classifier.
At 902, prepare validation data set.Multiple verifying video frames can be used to prepare validation data set.With reference
Method similar described in reception training frames at 802 receives verifying frame.In one example, it at 902, comes from
80 frames of four video sequences can be used for preparing validation data set.The preparation of validation data set is with identical with training set
Mode carries out.That is, by verifying frame to each, it can be by generating coding by coded frame as described in 804
Block, as described in 806 feature set based on definition extract the feature of block and the block for encoding instruction as described in 808 whether by
The label of subregion and the feature of block are associated, to prepare validation data set.Hereafter normalization can be executed as described in 812.
Do not terminate in advance the validation data set that is prepared of ground for determine by the classifier decision previously trained in advance eventually
The increase of the error amount only generated.Since at 904, encoded using the classifier of pre-training for preparing validation data set
Block.The classifier of pre-training is the classifier generated at 812.Sequentially (that is, pressing scanning sequency) it can consider each of frame
A block, and whether sector search process is terminated using corresponding classifier come decision according to the size of block.It can be suitable by scanning
Sequence considers each piece to carry out subregion, but each block can be grouped into for example from most according to the decision tree for subregion
Arrive the smallest prediction block size greatly to be suitable for the single of corresponding block size for verifying and (and if applicable, adjusting)
Classifier.Process 900 shown in Fig. 9 describes an example, explains in greater detail below, based on by this in the example
The average coding cost that verify data caused by terminating in advance caused by classifier is concentrated increases the classifier for carrying out adjusting training.
Using classifier encoding block 904 may include the value for the feature for extracting the block at present node as classifier
Input.These values herein are also referred to as the feature of extraction to quote.The feature of block may include for training classifier
Feature.After extracting feature, the feature of extraction can be normalized.Normalization technology can be identical as discussing at 812.
At 904, it is used as the input of N × N classifier to the feature that N × N block extracts, is C64 here.Each N × N
The output of the classifier of block is binary value, i.e., 0 or 1.The instruction of value 0 is to current N × N block subregion, and the instruction of value 1 is not to block point
Area.If output valve is 1, the further subregion of current N × N block will not occur.If output valve is 0, test is vertical
Compartment model, horizontal partitioning mode and segmentation compartment model and different prediction modes.Use point for leading to lowest error value
Area selects the compartment model of current N × N block.
At 906, the termination error in advance of classifier are calculated using the block of coding.In advance termination error indicate by with do not mention
The preceding coding (for example, the forced coding with minimum RD cost is as example) that terminates is compared to the error that termination subregion generates in advance
Increase (the also referred to as reduction of code efficiency).The block of all codings of identical size can be calculated and shift to an earlier date termination error, then
Averagely shift to an earlier date termination error or otherwise combine and shifts to an earlier date termination error to obtain the single value for indicating termination error in advance.It can
By the way that the region policy decision of the block with current size divides those blocks with what is carried out when preparing validation data set at 902
Area's decision is compared to that the block being limited to using terminating in advance will be calculated.Verify data concentrates the block quilt for the current size not terminated
It uses.
In the example of processing below, by termination error in advance be calculated as by RD increased costs caused by terminating in advance with
Do not terminate the ratio of best RD cost when ground encodes in advance.RD increased costs are terminated by trained classifier without blockette
Optimum prediction be more than that the verify data prepared from 902 concentrates best RD cost when encoding with not terminating in advance learnt
Amount.In order to normalize the value so that for comparison purposes, each of block of current size that can averagely terminate in this way mentions
Average value is concentrated the overall error of the block terminated in advance obtained by preceding termination error divided by the verify data prepared from 902.Knot
Fruit value indicates the termination error in advance of the classifier.It is possible for calculating the other methods of termination error in advance.
At 908, by termination error in advance compared with (for example, preset) error threshold.Error threshold can also be recognized
For be from verify data concentrate verifying frame in block subregion the error amount for terminating generation in advance maximum allowable increase.
In one example, the error threshold of classifier C64 is 0.1%, but other values are possible.With biggish image
In the case where in the case where the tolerance of deterioration or not considering bandwidth, error threshold may be higher.If terminated in advance at 908
Error is higher than error threshold, then it is current to adjust by using training example re -training classifier to proceed to 910 for process 900
The parameter of classifier.Adjust classifier parameters to maximize the block terminated in advance, and keep simultaneously in advance termination error in error
Under threshold value.Adjustment classifier parameters can be realized by several mode.A kind of side of adjustment classifier parameters may be implemented
Formula is the weighted value for the one or more features that modification is applied in classifier.For example, will be without blockette (positive sample) mistake point
Class is that blockette (negative sample) not will lead to RD increased costs, but not vice versa.That is, carrying out mistake point to negative sample
Class will lead to RD increased costs.For this reason, can use in machine learning algorithm is all positive samples and negative sample
The weighting scheme of allocation unit power, the RD cost as caused by wrong classification block increases weight in proportion in the weighting scheme
Add the ratio with the average RD cost in video.The ratio can be controlled by the factor or value λ, the factor or value λ control
Overall Weight balance between positive sample and negative sample and classifier performance caused by therefore influencing.During verifying, such as
Fruit classifier is unsatisfactory for threshold value standard (that is, being yes to the response of the inquiry at 908), then the value of adjustable λ.Then, as joined
It examines described in 812, uses the current classifier of the new value re -training of training dataset and λ, the current classification of re -training
Device leads to the classifier parameters of one or more adjustment of classifier.It is then possible to repeated authentication.It can be with the instruction after repeated authentication
Experienced iterative process meets standard until current classifier.
More specifically, referring again to FIGS. 9, process 900 may return to 904 to use modification after adjustment at 910
Classifier the block of the size with current block is encoded.Can be recalculated at 906 termination error in advance and
At 908 compared with error threshold.In response to the inquiry at 908, as long as termination error are greater than error threshold in advance, at 910
The sequence can be repeated after adjusting parameter.
When termination error in advance are not higher than error threshold, the response to the inquiry at 908 is no.It stores and works as at 912
After preceding classifier, process 900 terminates.
Although above description show to whether the test of the current classifier of re -training be in advance termination error whether
Greater than error threshold, the test can be modified as illustrated in fig. 9.That is, it may be desirable to define small positive value E, E can be used for
Re -training classifier is determined whether based on termination error in advance and the degree of closeness of error threshold.If termination error in advance
Close to error threshold (difference is in E), then it can be omitted or terminate the re -training classifier at 910.Otherwise, that is, in advance
Termination error far from error threshold in the case where (at 908 | in advance termination error-error threshold | > E), instructed again at 910
Practice classifier.Value E reflection can be promoted in the training using machine-learning process in practice by the flexibility of result
The convergence of scheme.If use value E, value E can be determined by experiment, and can different or phase for each classifier
Together.
The block with identical size concentrated using verify data is to other classifiers --- i.e. N/2 × N/2 classifier (example
Such as, C32) and N/4 × N/4 classifier (for example, C16) --- repetitive process 900.
It is similar in N/2 × N/2 rank and N/4 × N/4 rank adjusting scheme to described in N × N level.Mistake classification
Biggish piece would generally bring bigger increased costs.That is, if biggish piece of mistake that will be such as 64 × 64 pieces point
Class is no blockette, and it should be blockette, then the lesser piece of phase with such as 32 × 32 pieces or 16 × 16 pieces of mistake classification
Than will lead to more mass losses.In order to ensure coding quality while accelerating coding, can encourage having a size of 32 × 32
It is terminated in advance with 16 × 16 pieces more than 64 × 64 pieces.Therefore more high threshold is used to classifier C32.The error threshold of classifier C32
Value can be higher than the error threshold of classifier C64 by 50% or more.
Similarly, the error threshold of classifier C16 can be greater than the error threshold of classifier C64, and classifier C16
Error threshold can be equal to or more than the error threshold of classifier C32.In this example, the error threshold of classifier C16 can compare
The error threshold height of classifier C32 is no more than 50%.
In this example, not to N/8 × N/8 block training classifier, but smallest partition (that is, prediction block) size includes N/
16 × N/16 pixel.Therefore, feature is not extracted for inputting to classifier to determine whether subregion N/8 × N/8 block.
When verifying all classifiers (and being adjusted according to being applicable in), them are saved for encoded video frame sequence.
Figure 12 is realization according to the present invention for during coding to the flow chart of the process 1200 of frame subregion.Process 1200 can be with
Use the classifier of as with reference to described by Fig. 8 and Fig. 9 training.Process 1200 can by with the encoder 400 in such as Fig. 4
The processor of the processor 140 for such as Fig. 1 that encoder combines is realized.Process 1200 can pass through the instruction 160 of such as Fig. 1
Instruction is realized.
With scanning sequency, such as raster scanning sequence to the block iteration in frame implementation procedure 1200.Since at 1202,
Each block of block node can be assessed with implementation procedure 1200.At 1202, selection block node is as the current block to be assessed
Node is so as to subregion.Block node can be the largest prediction block size, so that the current block considered is with the size
Block.For example, block can be block 610 as shown in Figure 6.In this example, block is N × N block, wherein N=64.
Selection block node further includes the block that prediction forms block node at 1202.Predict that the block for forming block node may include
Prediction block is generated for each of multiple available prediction models for current block and is generated and each prediction block
Associated residual error.The encoder that such as above-mentioned encoder 400 can be used correspondingly codes and decodes residual error.It can be with
Select optimum prediction mode of the prediction mode with lowest error value as the current block at block node.
At 1204, the value of feature is extracted from block based on the feature set of definition.Feature is extracted to be input to current block
In classifier at node.The feature of extraction may include the feature for training classifier.Can desirably, the normalizing at 1204
Change feature.Normalization characteristic may include referring to normalized as described above at 812 normalize (for example, making at 1204
With the mean value and standard deviation of training example).The value of training dataset can store or otherwise together with classifier
Encoder is set to can be used the value of training dataset with implementation procedure 1200.
When normalized to each feature, the mean value of each characteristic dimension i is usedAnd standard deviation sigmai.Upper
In the description in face, due to the presence of training dataset or validation data set, mean value can get before the codingAnd standard deviation sigmai,
Whichever is applicable.That is, for example, use the characteristic value extracted at 1204 as the classifier to 1206
Before input, training dataset can be used to calculate the mean value of each characteristic dimension iAnd standard deviation sigmai.However, in process
In 1200, as selected and considered at 1202 and 1204, feature is sequentially extracted from the block in frame.Return in above-mentioned standard
In one variation changed, the value of feature i and the value (if any) of the feature i before current block can be used, with adaptive
Ground calculates mean valueAnd standard deviation sigma1.That is, mean value can be recalculated at each block nodeAnd standard deviation sigmai。
The value for calculating can be limited to reduce the complexity of the calculating during process 1200.For example, can tire out in coded frame
Product value is simultaneously normalized block by block and then abandons these values when starting and encoding next frame.Limit another skill calculated
Art is the maximum quantity with value, so that each new value increases sum until reaching maximum quantity, then new value starts to replace
Change old value (for example, n advanced-first go out).Although compared with using mean value and the standard deviation from training dataset less
It is useful, it is this it is standardized realize can also the preparation of the validation data set at 902, at 904 use classifier encoding block
Or both in realize.
After normalizing at 1204, the feature of extraction is used to carry out application class device as input at 1206.The example
In classifier be binary classifier C64.The output of binary classifier can be 0 or 1.At 1208, the output of classifier is true
Whether the current block at block node before settled terminates in advance.At 1208, determined at current block if exported based on feature
The subregion of block will stop, then current partition and prediction mode are accepted as the final optimal selection of video block subregion.For example, value 0
It can indicate to block subregion, and the instruction of value 1 is not to block subregion.At 1210, sector search stops.Then with scanning sequency under
One N × N block repetitive process 1200.
In contrast, at 1208, determine that the subregion of current block will continue if exported based on feature, before process 1200
1212 are entered to use available compartment model to continue sector search.For example, to the sector search of N × N block may include by N ×
N block subregion is the block of the block of vertical partitioning mode, the block of horizontal partitioning mode and segmentation compartment model.In segmentation compartment model
In, the classifier that lower piece of rank can be used (here, assesses each sub-block as example C32) to determine whether to execute
It terminates in advance.In this example, the segmentation compartment model of N × N block leads to four N/2 × N/2 blocks, four N/2 × N/2 blocks
Each of form corresponding block node with repetitive process 1200 since 1202.
In next piece of node, such as at N/2 × N/2 node, the feature set at 1204 based on definition extracts current block
Feature and normalization.Be used as to the feature that block extracts (is here to the classifier corresponding with current block size at 1206
C32 input).The output of classifier for being terminated decision in advance at 1208.If the output of classifier indicates to stop
Sector search, then process 1200 proceeds to 1210 to stop the sector search to current block node.For example, at block node
In the case that N/2 × N/2 block is first, second of N × N block of subregion or third block, considered with scanning sequency next
A block.In the case where N/2 × N/2 block is the last blocks of situation in scanning sequency, then with scanning sequency to next N × N
Block repetitive process 1200.
In contrast, at 1208, if the feature output based on extraction determines that the subregion of current block will continue, process
1200 proceed to 1212 to use available compartment model to continue sector search.Processing at 1212 can with above for N × N
It is executed in the same manner described in block.That is, may include by N/2 × N/2 to the sector search of current N/2 × N/2 block
Block subregion is the block of vertical partitioning mode, the block of horizontal partitioning mode and segmentation compartment model block.In this example, N/2 ×
The segmentation compartment model of N/2 block leads to four N/4 × N/4 blocks, and each of described four N/4 × N/4 blocks form corresponding
Block node is with repetitive process 1200 since 1202.Before considering next N/2 × N/2 block for dividing from N × N block or
If before not yet considering the last one N/2 × N/2 block in current N × N block and proceeding to next N × N block,
Each of four N/4 × N/4 blocks block is successively considered as block node at 1202.
In next piece of node, such as at N/4 × N/4 node, the feature set at 1204 based on definition extracts current block
Feature and normalization.The feature that block extracts is used as to the classifier corresponding with current block size at 1206, is here
C16.The output of classifier for being terminated decision in advance at 1208.If the output instruction of classifier stops subregion and searches
Rope, then process 1200 proceeds to 1210 to stop the sector search to current block node.For example, N/4 at block node ×
In the case that N/4 block is first, second of N/2 × N/2 block of subregion or third block, considered with scanning sequency next
Block.In the case where N/4 × N/4 block is the last blocks of situation in scanning sequency, then with scanning sequency to next N × N block
Repetitive process 1200.
On the contrary, determining that the subregion of current block will continue if exported based on feature, process 1200 proceeds at 1208
1212 to use available compartment model to continue sector search.Processing at 1212 can with above for described in N × N block
It executes in the same manner.That is, may include by N/4 × N/4 block subregion to the sector search of current N/4 × N/4 block being vertical
The straight block of compartment model, the block of horizontal partitioning mode and segmentation compartment model block.In this example, the segmentation of N/4 × N/4 block
Compartment model leads to four N/8 × N/8 blocks, further to each of four N/8 × N/8 blocks subregion.However, at this
Without the classifier for N/8 × N/8 block in example, therefore not to current block node repetitive process 1200.It can be used vertical
Directly, horizontal or segmentation compartment model routinely carries out subregion to block.Considering the smallest prediction block size, such as N/16 × N/16
When pixel, the further subregion for any compartment model for leading to lowest error value is not considered.Alternatively, processing is with scanning sequency
Back to next N × N block.
The processing sequence of the above process 1200 realizes the recursive partitioning of the block in frame.
After executing the termination in advance based on machine learning, multi-level error control scheme proposed in this paper controls matter
Amount loses and maximizes processing speed.
The rank of faults-tolerant control can be adaptively adjusted for each classifier.More specifically, can be to biggish
The classifier of block, such as C64 realize tightened up faults-tolerant control, and in the classifier of lower piece of grade, such as C32 and C16
Keep relevantly lenient control.Search process follows orderly depth --- and first traversal is being commented in the first traversal
Father node is assessed before estimating child node.For example, further being assessed having a size of 32 × 32 and 16 × 16 pieces downwards possibly into tree
64 × 64 pieces are assessed before.If 64 × 64 pieces of mistakes are classified as zoneless piece but actually it should be blockette,
This will lead to than mistake classification 32 × 32 pieces or 16 × 16 pieces of more mass losses.Therefore, in order to ensure coding quality and add
Fast subregion is encouraged lesser piece and is terminated in advance before biggish piece.
Word " example " used herein or " aspect " are to indicate to be used as example, example or explanation.Here depicted as
Any aspect of " example " or " aspect " or design are not necessarily to be construed as than other aspects or design more preferably or more advantage.Phase
Instead, using word " example " or " for the use of " be intended to that concept is presented in specific ways.As used in this specification, term "or"
It is intended to indicate that the "or" of inclusive rather than exclusive "or".That is, it is unless otherwise indicated or clear from the context,
Otherwise " X includes A or B " is intended to indicate that any natural inclusive arrangement.That is, if X includes A；X includes B；Or X
Including A and B, then meeting " X includes A or B " under any afore-mentioned.In addition, being used in the application and appended claims
The article " one " and "one" it is generally understood that indicate " one or more ", unless otherwise indicated or from context clearly needle
To singular.In addition, otherwise term " realization " or the use of " aspect " are not intended to indicate phase in full text except description of being far from it
Same embodiment or realization.As it is used herein, term " determination " and " identification " or its any variation include using institute in Fig. 1
One or more of equipment shown is selected, is found out, calculating, searching, receiving, determining, establishing, obtaining in any way or with it
His mode is identified or is determined.
In addition, to simplify the explanation, although drawings and the description herein may include sequence or series of steps or stage,
But the element of method disclosed herein can occur in various orders and/or simultaneously.In addition, the element of method disclosed herein
It can occur with being not known together with the other elements for presenting and describing herein.In addition, and non-required method described herein institute
There is member usually to realize the method according to disclosed theme.
The calculating of such as dispatching station and/or receiving station etc and communication equipment (and be stored thereon and/or be executed by it
Algorithm, method, instruction etc.) realization can be realized with hardware, software or any combination thereof.Hardware may include for example calculating
Machine, intellectual property (IP) core, specific integrated circuit (ASIC), programmable logic array, optical processor, Programmable logical controller
Device, microcode, microcontroller, server, microprocessor, digital signal processor or any other suitable circuit.In right
In it is required that, term " processor " be should be understood that either individually or in combination comprising any aforementioned hardware.Term " signal " and " number
According to " be used interchangeably.In addition, calculating must not necessarily realize with the part of communication equipment in an identical manner.
In addition, in the implementation, computer program can be used to realize, in the calculating with communication equipment for example, calculating
When machine program executes, any corresponding method, algorithm and/or instruction described herein are executed.Additionally or alternatively, for example,
It can be used comprising special purpose computer/processing for executing any method described herein, algorithm or the specialized hardware of instruction
Device.
The dispatching station for realizing encoder and the receiving station for realizing decoder can calculating for example in Real-time Video System
It is realized on machine.Alternatively, dispatching station can realize on the server and receiving station can be real in the equipment separated with server
It is existing, such as handheld communication devices.In this case, it is encoded video that encoder 400, which can be used, by research content in dispatching station
Signal and by the video signal transmission after coding to communication equipment.Then, then that decoder 500 can be used is right for communication equipment
The vision signal of coding is decoded.Alternatively, communication equipment can decode the content being locally stored on a communications device, for example,
It is not the content transmitted by dispatching station.It is available using calculating with other suitable implementations of communication equipment.For example, connecing
Receipts station can be usually fixed personal computer rather than portable communications are set and/or the equipment including encoder 400
It also may include decoder 500.
In addition, it is all or part of realize can using can from such as tangible computer available or computer-readable medium
The form of the computer program product of access.Computer is available or computer-readable medium can be can for example visibly
Include, store, transmitting or transfer program uses or connect any equipment that any processor uses for any processor.Medium
It can be such as electronics, magnetic, optical, electromagnetic or semiconductor devices.Other suitable media are also available.
Above-mentioned realization has been described to be readily appreciated that the application is not limiting.On the contrary, the application includes appended
Various modifications and equivalent arrangement in scope of the claims, the range should be endowed broadest interpretation, to allow comprising law
All such modifications and equivalent structure.
Claims (20)
1. a kind of method, comprising:
Using recursive partitioning, training video frame is repeatedly encoded by using different coding choice sets to generate the block of coding；
For the block of multiple codings with first size:
From the trained values of the block feature in the feature set extracted in the block of the coding with the first size for definition；And
By instruction have the first size the coding block whether be partitioned smaller piece label and the training
Value is associated；And
Using the trained values and the associated label, for the block of the multiple coding with the first size
The first classifier of training, first classifier use the block feature obtained from first piece with the first size
At least some of value during coding whether will be to first piece of further subregion to determine.
2. according to the method described in claim 1, wherein, the feature set of the definition is the resolution based on the training video frame
Rate.
3. method according to claim 1 or 2 further comprises:
Before training first classifier, the corresponding block using the normalization of normalization scheme in the block feature is special
The trained values of sign.
4. according to the method described in claim 3, wherein, the normalization scheme is standardization normalization scheme.
5. the method according to any one of the preceding claims further comprises:
For the block of multiple codings with the second size:
From the trained values of the block feature in the feature set extracted in the block of the coding with second size for the definition；
And
By instruction have second size the coding block whether be partitioned smaller piece label and the training
Value is associated；And
Using the trained values of the block for the multiple coding with second size and through associated label, come
The second classifier of training, second classifier are come using the value of at least some of the block feature obtained from second piece
Whether determination during coding will be to second piece of further subregion with second size.
6. according to the method described in claim 5, wherein, described second piece is described first piece generated by segmentation compartment model
Sectorized block.
7. method according to claim 5 or 6, wherein the classifier parameters of first classifier with by terminating in advance
First maximum allowable increase of the error amount that the block progress subregion in the verifying video frame with the first size is generated
Amount is associated, and the classifier parameters of second classifier regard the verifying with second size with by terminating in advance
The second maximum allowable incrementss of error amount that block in frequency frame carries out subregion and generates are associated, and described the first of error amount is most
Big the described second maximum allowable incrementss for allowing incrementss to be lower than error amount.
8. the method according to any one of the preceding claims, wherein different the encoding option collection, which results from, to be made
The training video frame is encoded with different target bit rates.
9. method described in any one of -6 according to claim 1, further comprises:
By using recursive partitioning, encoding verification video frame prepares validation data set for the first time；
When first classifier is applied to each block to determine to the block subregion or not subregion, coding has institute again
State the block in the verifying video frame of first size；
It calculates and is terminated in the verifying video frame due to application first classifier and preparing the validation data set
When do not terminate block in advance termination error；And
It is described in advance termination error be more than error threshold when, adjust described first by the first classifier described in re -training
The parameter of classifier.
10. according to the method described in claim 9, wherein, the termination error in advance are to due to application first classification
Device and terminate and described piece in the verifying video frame that does not terminate when preparing the validation data set encoded
Increase of the rate-distortion cost on the minimum rate-distortion cost encoded to described piece from the validation data set.
11. the method according to any one of the preceding claims further comprises:
For each of the video frame with first size block, first classifier is used by following
Encoded video frame:
Feature set based on the definition extracts feature from described piece；
First classifier is applied to described piece using extracted feature；And
Determine whether to stop the sector search to described piece using the output of first classifier.
12. the method according to any one of the preceding claims, wherein first classifier is that have described in stopping
First output of sector search and the second binary classifier exported for continuing the sector search.
13. a kind of device, comprising:
Non-transitory memory；And
Processor, the processor is configured to execute the instruction that is stored in the non-transitory memory with:
The block of coding is generated using the block in recursive partitioning coding training video frame；
The training example of the block of the coding is generated, each training example includes the value of the block feature extracted from the block of coding
And whether the block of instruction coding described in the recursive partitioning is partitioned the label of more fritter；And
Training is used for the classifier of different block sizes, each classifier use for block size is related to the block size
The trained example of connection trains each classifier as the input of machine-learning process, and each classifier is matched
Whether be set to determination during coding will be to input block subregion.
14. device according to claim 13, wherein the processor is configured to generating the training by following
Example:
From the described value of the block feature in the feature set for extracting definition in the block of the coding；And
Normalization is used for the described value of the trained example before the training classifier.
15. device described in 3 or 14 according to claim 1, wherein the classifier includes the block size for 64 × 64 pixels
The first classifier, for 32 × 32 pixels block size the second classifier and the block size for 16 × 16 pixels the
Three classifiers.
16. device described in any one of 3-15 according to claim 1, wherein the processor is configured to: when the instruction
When white silk example is associated with the block of coding of subregion non-in the recursive partitioning, by distributing for the first value next life to the label
At the trained example.
17. a kind of device, comprising:
Non-transitory memory；And
Processor, the processor is configured to execute the instruction that is stored in the non-transitory memory with:
Select the block with the video frame of maximum predicted block size；
Described piece is encoded without to described piece of subregion；
Based on scheduled feature set from extraction of values in described piece；
Use described value as input, the first classifier that machine-learning process will be used to generate is applied to described piece, and described the
One classifier is the binary classifier for the block with the maximum predicted block size, and there is the binary classifier instruction to stop
Only the first output of sector search and the second output of the instruction continuation sector search；And
In the case where first classifier generates the described first output to described piece, the block that non-subregion is encoded includes
In the video bit stream of coding.
18. device according to claim 17, wherein described the applied when the video frame has first resolution
One classifier is different from first classifier applied when the video frame has second resolution.
19. device described in 7 or 18 according to claim 1, wherein the processor is configured to: it is used for using described value
Described value is normalized before being input to first classifier.
20. device described in any one of 7-19 according to claim 1, wherein the processor is configured to: described
In the case that one classifier generates second output to described piece, by being possible point according to further sector search
Area's mode and the further sector search are impossible compartment models to described piece of subregion, to encode described piece.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/425,362 US10382770B2 (en) | 2017-02-06 | 2017-02-06 | Multi-level machine learning-based early termination in partition search for video encoding |
US15/425,362 | 2017-02-06 | ||
PCT/US2017/059280 WO2018144085A1 (en) | 2017-02-06 | 2017-10-31 | Multi-level machine learning-based early termination in partition search for video coding |
Publications (2)
Publication Number | Publication Date |
---|---|
CN110178373A true CN110178373A (en) | 2019-08-27 |
CN110178373B CN110178373B (en) | 2023-06-20 |
Family
ID=60628155
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780083311.0A Active CN110178373B (en) | 2017-02-06 | 2017-10-31 | Method and apparatus for training a classifier and for encoding and decoding video frames |
Country Status (4)
Country | Link |
---|---|
US (2) | US10382770B2 (en) |
EP (1) | EP3577897A1 (en) |
CN (1) | CN110178373B (en) |
WO (1) | WO2018144085A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110581990A (en) * | 2019-09-25 | 2019-12-17 | 杭州当虹科技股份有限公司 | TU (TU) recursion fast algorithm suitable for HEVC (high efficiency video coding) 4K and 8K ultra-high definition coding |
CN112819150A (en) * | 2019-11-18 | 2021-05-18 | 浙江大学 | Prediction block generation method and device based on neural network |
Families Citing this family (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10552432B2 (en) * | 2016-10-12 | 2020-02-04 | Salesforce.Com, Inc. | Ranking search results using hierarchically organized machine learning based models |
WO2019009448A1 (en) * | 2017-07-06 | 2019-01-10 | 삼성전자 주식회사 | Method and device for encoding or decoding image |
US11412220B2 (en) | 2017-12-14 | 2022-08-09 | Interdigital Vc Holdings, Inc. | Texture-based partitioning decisions for video compression |
US11012696B2 (en) * | 2018-05-03 | 2021-05-18 | Dell Products L.P. | Reducing an amount of storage used to store surveillance videos |
US10499081B1 (en) * | 2018-06-19 | 2019-12-03 | Sony Interactive Entertainment Inc. | Neural network powered codec |
US10685282B2 (en) * | 2018-07-25 | 2020-06-16 | WaveOne Inc. | Machine-learning based video compression |
US10869036B2 (en) | 2018-09-18 | 2020-12-15 | Google Llc | Receptive-field-conforming convolutional models for video coding |
US11025907B2 (en) * | 2019-02-28 | 2021-06-01 | Google Llc | Receptive-field-conforming convolution models for video coding |
EP3743855A1 (en) * | 2018-09-18 | 2020-12-02 | Google LLC | Receptive-field-conforming convolution models for video coding |
US10674152B2 (en) * | 2018-09-18 | 2020-06-02 | Google Llc | Efficient use of quantization parameters in machine-learning models for video coding |
CN109635157B (en) * | 2018-10-30 | 2021-05-25 | 北京奇艺世纪科技有限公司 | Model generation method, video search method, device, terminal and storage medium |
US10863206B2 (en) * | 2018-11-08 | 2020-12-08 | Alibaba Group Holding Limited | Content-weighted deep residual learning for video in-loop filtering |
US10855988B2 (en) * | 2018-12-19 | 2020-12-01 | Qualcomm Incorporated | Adaptive prediction structures |
CN113767400A (en) * | 2019-03-21 | 2021-12-07 | 谷歌有限责任公司 | Using rate distortion cost as a loss function for deep learning |
EP4002277A4 (en) * | 2019-08-14 | 2023-02-22 | LG Electronics Inc. | Point cloud data transmission device, point cloud data transmission method, point cloud data reception device and point cloud data reception method |
CN110781960B (en) * | 2019-10-25 | 2022-06-28 | Oppo广东移动通信有限公司 | Training method, classification method, device and equipment of video classification model |
US11388401B2 (en) * | 2020-06-26 | 2022-07-12 | Google Llc | Extended transform partitions for video compression |
CN113329226B (en) * | 2021-05-28 | 2022-12-20 | 北京字节跳动网络技术有限公司 | Data generation method and device, electronic equipment and storage medium |
WO2023081509A1 (en) * | 2021-11-08 | 2023-05-11 | Beijing Dajia Internet Information Technology Co., Ltd | Cross-component sample adaptive offset |
WO2023167514A1 (en) * | 2022-03-03 | 2023-09-07 | Samsung Electronics Co., Ltd. | System and method for training artificial intelligence models for in-loop filters |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160065959A1 (en) * | 2014-08-26 | 2016-03-03 | Lyrical Labs Video Compression Technology, LLC | Learning-based partitioning for video encoding |
CN105430396A (en) * | 2015-12-15 | 2016-03-23 | 浙江大学 | Video coding method capable of deciding sizes of coding blocks by means of classification |
CN105430391A (en) * | 2015-12-04 | 2016-03-23 | 上海交通大学 | Intra-frame coding unit rapid selection method based on logical regression classifier |
CN106162167A (en) * | 2015-03-26 | 2016-11-23 | 中国科学院深圳先进技术研究院 | Efficient video coding method based on study |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8010471B2 (en) * | 2007-07-13 | 2011-08-30 | Microsoft Corporation | Multiple-instance pruning for learning efficient cascade detectors |
CA2638465A1 (en) * | 2007-08-01 | 2009-02-01 | Jean-Yves Chouinard | Learning filters for enhancing the quality of block coded still and video images |
-
2017
- 2017-02-06 US US15/425,362 patent/US10382770B2/en active Active
- 2017-10-31 EP EP17811396.5A patent/EP3577897A1/en not_active Ceased
- 2017-10-31 CN CN201780083311.0A patent/CN110178373B/en active Active
- 2017-10-31 WO PCT/US2017/059280 patent/WO2018144085A1/en active Application Filing
-
2019
- 2019-07-19 US US16/516,383 patent/US10812813B2/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160065959A1 (en) * | 2014-08-26 | 2016-03-03 | Lyrical Labs Video Compression Technology, LLC | Learning-based partitioning for video encoding |
CN106162167A (en) * | 2015-03-26 | 2016-11-23 | 中国科学院深圳先进技术研究院 | Efficient video coding method based on study |
CN105430391A (en) * | 2015-12-04 | 2016-03-23 | 上海交通大学 | Intra-frame coding unit rapid selection method based on logical regression classifier |
CN105430396A (en) * | 2015-12-15 | 2016-03-23 | 浙江大学 | Video coding method capable of deciding sizes of coding blocks by means of classification |
Non-Patent Citations (3)
Title |
---|
HU QIANG ET AL: "《2016 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)》", 28 July 2016 * |
XIAOLIN SHEN ET AL: "《Eurasip Journal on Image and Video Processing》", 1 January 2013 * |
ZHANG YUN ET AL: ""Maching Learning-Based Coding Unit Depth Decisions for Flexible Complexity Allocation in High Efficiency Video Coding"", 《《IEEE TRANSACTION ON IMAGE PROCESSING, IEEE SERVICE CENTER》》 * |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110581990A (en) * | 2019-09-25 | 2019-12-17 | 杭州当虹科技股份有限公司 | TU (TU) recursion fast algorithm suitable for HEVC (high efficiency video coding) 4K and 8K ultra-high definition coding |
CN112819150A (en) * | 2019-11-18 | 2021-05-18 | 浙江大学 | Prediction block generation method and device based on neural network |
CN112819150B (en) * | 2019-11-18 | 2024-05-07 | 浙江大学 | Prediction block generation method and device based on neural network |
Also Published As
Publication number | Publication date |
---|---|
CN110178373B (en) | 2023-06-20 |
US20190342561A1 (en) | 2019-11-07 |
US10812813B2 (en) | 2020-10-20 |
US20180227585A1 (en) | 2018-08-09 |
WO2018144085A1 (en) | 2018-08-09 |
US10382770B2 (en) | 2019-08-13 |
EP3577897A1 (en) | 2019-12-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN110178373A (en) | For the termination in advance based on multi-level machine learning in the sector search of Video coding | |
US10848765B2 (en) | Rate/distortion/RDcost modeling with machine learning | |
US20230199179A1 (en) | Image and video coding using machine learning prediction coding models | |
CN111868751A (en) | Using non-linear functions applied to quantization parameters in a machine learning model for video coding | |
CN107852495A (en) | Low time delay video code twice | |
US10701398B2 (en) | Context adaptive scan order for entropy coding | |
US11956447B2 (en) | Using rate distortion cost as a loss function for deep learning | |
US11019341B2 (en) | Efficient context handling in arithmetic coding | |
CN107027033A (en) | Paster for video compress is copied | |
CN107743706A (en) | Hypermutation changes video code | |
CN107465923A (en) | Adaptive overlapping block prediction in the video coding of variable block length | |
CN107302701A (en) | Decode interpolation filter type | |
US11849113B2 (en) | Quantization constrained neural image coding | |
CN107465925A (en) | Adaptive overlapping block prediction in the video coding of variable block length | |
CN107079156B (en) | Method for alternate block constrained decision mode coding | |
CN108353193A (en) | Based on it is multiple based on the model of figure by using the method and apparatus of transformation encoding/decoding video signal | |
US20240098280A1 (en) | Video Coding With Guided Machine Learning Restoration | |
US20230291925A1 (en) | Inter-Intra Prediction With Implicit Models | |
CN116783890A (en) | Chroma transform type determination |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |