CN104298710A - Automatic discovery of popular landmarks - Google Patents
Automatic discovery of popular landmarks Download PDFInfo
- Publication number
- CN104298710A CN104298710A CN201410455635.0A CN201410455635A CN104298710A CN 104298710 A CN104298710 A CN 104298710A CN 201410455635 A CN201410455635 A CN 201410455635A CN 104298710 A CN104298710 A CN 104298710A
- Authority
- CN
- China
- Prior art keywords
- user
- image
- inquiry
- cluster
- terrestrial reference
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/29—Geographical information databases
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/51—Indexing; Data structures therefor; Storage structures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5838—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using colour
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5846—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using extracted text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/5866—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using information manually generated, e.g. tags, keywords, comments, manually generated location and time information
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/587—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using geographical or spatial information, e.g. location
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F7/00—Methods or arrangements for processing data by operating upon the order or content of the data handled
- G06F7/06—Arrangements for sorting, selecting, merging, or comparing data on individual record carriers
- G06F7/08—Sorting, i.e. grouping record carriers in numerical or other ordered sequence according to the classification of at least some of the information they carry
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/97—Determining parameters from multiple pictures
Abstract
The invention relates to an automatic discovery of popular landmarks. In one embodiment, the present invention provides a method for populating and updating a database of images of landmarks. The method includes the steps of geo-clustering geo-tagged images according to geographic proximity to generate one or more geo-clusters, and visual-clustering the one or more geo-clusters according to image similarity to generate one or more visual clusters. In another embodiment, the present invention provides a system for identifying landmarks from digital images. The system includes the following components: a database of geo-tagged images; a landmark database; a geo-clustering module; and a visual clustering module. In other embodiments, the present invention may be a method of enhancing user queries to retrieve images of landmarks, or a method of automatically tagging a new digital image with text labels.
Description
Division explanation
The application belongs to the divisional application that the applying date is the Chinese patent application 200980127106.5 on May 12nd, 2009.
Technical field
Present invention relates in general to digital image set, relate more specifically to the welcome terrestrial reference (landmark) identified in large-scale digital image set.
Background technology
Along with the interconnectivity that the use increase of digital picture, the capacity of digital storage media and availability increase and provided by the digital transmission media of such as the Internet, the crowd that quantity increases day by day may have access to further large-scale digital picture storehouse.The people with broad interest from various positions all over the world takes the photo of various theme, and those photos such as can be used on the internet.Such as, the digital photos from various terrestrial reference all over the world and tourist destination can be taken by the people with the different levels of skill of taking pictures, and is posted (post) on web.Photo can illustrate from different angles and the identical terrestrial reference from identical or different distance shooting.
In order to utilize the information be included in these large-scale digital picture storehouses, it is necessary that organize described storehouse.Such as, in the digital picture website of such as Google photo or Picasa, originate in advanced menu, people can drill through downwards (drill down) to for its photo can detailed theme include.As an alternative, people can search for one or more websites with digital photos.Such as, the image of the terrestrial reference be associated with the welcome tourist destination list of announcing has been downloaded in some travel information websites.
But, there is no the known system that automatically can extract the information of such as most popular tourist famous-city from these large sets.Along with photo new is in a large number added to these digital image sets, may be infeasible, user is can increase complete with the consistent mode handmarking photo of the serviceability of those digital image sets.Therefore required, automatically can identify and mark the system and method for the welcome terrestrial reference in large-scale digital image set.
Summary of the invention
In one embodiment, the present invention is a kind of for filling (populate) and upgrading the method for landmark image database, described method comprises: carry out geographical cluster (geo-cluster) to generate one or more geographical cluster (geo-cluster) according to geographic proximity to geographical marking (geo-tagged) image, and according to image similarity to one or more geographical cluster vision cluster to generate one or more vision cluster.
In another embodiment, the present invention is a kind of for the system from digital image understanding terrestrial reference, and it comprises following assembly: geographical marking image data base; Landmark data storehouse; The geographical cluster module communicated with described geographical marking image data base, wherein said geographical marking image is gathered the one or more geographical cluster of composition; And the vision cluster module to communicate with described geographical cluster module, wherein said one or more geographical cluster is gathered the one or more vision cluster of composition, and wherein vision company-data is stored in landmark data storehouse.
In a further embodiment, the present invention be a kind of enhancing be used for searching floor signal image user inquiry method, comprise with the next stage: receive user inquiry; Identify the one or more trigger words in user's inquiry; The one or more corresponding label (tag) corresponding with one or more trigger word is selected from landmark data storehouse; And inquire about with the label supplement user of one or more correspondence, generate user's inquiry of supplement.
In another embodiment again, the present invention is the method for the digital picture that a kind of automatic marking is new, comprise with the next stage: compared by the image in new digital picture and landmark image database, wherein landmark image database comprises the vision cluster of the image of one or more terrestrial reference; And based on the new digital picture of at least one label for labelling of at least one in described vision cluster.
Accompanying drawing explanation
With reference to embodiments of the invention, the example of these embodiments can illustrate in the accompanying drawings.These accompanying drawings be intended to illustrate and unrestricted.Although generally describe the present invention in the linguistic context of these embodiments, should be understood that, this is not intended to scope of the present invention to be limited in these specific embodiments.
Fig. 1 is the system being used for filling and upgrading landmark image database according to an embodiment of the invention.
Fig. 2 shows the high-level process flow diagram of the method realizing one embodiment of the present of invention.
Fig. 3 shows the process flow diagram operated more in detail of the geographical clustering phase shown in Fig. 2 in one embodiment.
Fig. 4 shows the process flow diagram operated more in detail of the geographical cluster establishing stage shown in Fig. 3 in one embodiment.
Fig. 5 shows the process flow diagram operated more in detail of the vision clustering phase shown in Fig. 2 in one embodiment.
Fig. 6 is the graphical user interface used in one embodiment of the invention.
Fig. 7 is the method for renewal landmark image database according to an embodiment of the invention.
Fig. 8 is that the landmark information that stored of use according to an embodiment of the invention is to strengthen the method for user's inquiry.
Fig. 9 is that the annotation automatically that is used for according to an embodiment of the invention comprises the method for the image of terrestrial reference.
Figure 10 is the example user interface screen shown about the terrestrial reference of choice criteria retrieval of specifying according to user and the information of corresponding cluster according to an embodiment of the invention.
Figure 11 is the process flow diagram of the operation illustrated according to one embodiment of present invention for safeguarding cluster and ground calibration method.
Figure 12 is that the example user interface shown about the details of a vision cluster according to an embodiment of the invention is shielded.
Figure 13 is the process flow diagram of the operation of the method illustrated according to one embodiment of present invention for safeguarding vision cluster.
Embodiment
Although describe the present invention at this with reference to the illustrative embodiment being used for application-specific, should be understood that, the present invention is not limited thereto.The instruction that those skilled in the art is used in this will be recognized additional modifications, application and will be the embodiment in a large amount of extra field utilized wherein in scope of the present invention and the present invention.
The present invention includes for automatically identifying and the method and system of object in breakdown figures image.Such as, embodiments of the invention can identify, classify and sort based on addressable digital image set on the internet tourism terrestrial reference most popular.Method and system of the present invention can make it possible to effective maintenance of up-to-date list to most popular tourism position and image collection, and the popularity of position of wherein travelling can be estimated by the quantity that user is posted to the image on the Internet by this position.
Figure 1 illustrates welcome terrestrial reference recognition system 100 according to an embodiment of the invention.Processing module 101 comprises geographical cluster module 102 and vision cluster module 103.Vision cluster module 103 can also comprise popularity module 104.Described below the processing capacity of module 102-104: describe geographical cluster module 102 about Fig. 3-4; Vision cluster module is described about Fig. 5.The processing capacity of module 102-104 can be realized in the combination of software, hardware or more.Such as, module 102-104 can be embodied as software module completely, the hardware of such as field programmable gate array (FPGA) maybe can be used to realize some functions of geographical cluster module 102.It will be appreciated by those skilled in the art that processing module 101 can comprise the additional assemblies and module helping function of the present invention.Such as, processing module 101 can comprise one or more processor, storer, memory device, for being connected to the module of the external unit comprising graphical user interface 130, geographical marking image library 110 and landmark data storehouse system 120.
The index 122 that landmark data storehouse system 120 can comprise landmark data storehouse 121 and be associated.Landmark data storehouse system 120 can be co-located at same place platform with module 101 or can discretely locate.Landmark data storehouse 121 can comprise the set of the terrestrial reference that system 100 identifies.The information stored for each terrestrial reference in landmark data storehouse 121 can comprise the image of terrestrial reference or image list, image and feature templates and the metadata comprising geographic coordinate, time and user profile from image.Landmark data storehouse 121 can also comprise vision cluster needed for the process in processing module 101 and geographical cluster data.Index 122 can comprise according to such as unrestricted popularity, geographic area, time or the index that to be arranged in by terrestrial reference as the one or more order in other user-defined standard of interested theme in landmark data storehouse 121.Link 141 can be comprise such as unrestricted, any one or combination in the interconnection mechanism of periphery component interconnection (PCI) bus, IEEE 1394 fire-wire interfaces, Ethernet interface or IEEE 802.11 interface.
User interface 130 allows user or other external entity and disposal system 101, landmark data storehouse system 120 and geographical marking image library 110 mutual.Can use and comprise such as unrestricted, user interface 130 is connected to other entity of system 100 by any one or combination in the interconnection mechanism of pci bus, IEEE 1394 fire-wire interfaces, Ethernet interface or IEEE 802.11 interface.One or more in graphical user interface, web interface and application programming interface can be comprised in user interface 130.
Geographical marking image library 110 can comprise the one or more digital geographical marking image library across one or more network distribution.It will be appreciated by those skilled in the art that the set that storehouse 110 can also be embodied as and point to throughout the link of the addressable geographical marking image collection of network distribution.Can also by be produced on distributed location can the copy (such as, download and be stored in local storage) of all or part of image realize storehouse 110.In certain embodiments, a part for geographical marking image library may reside on the processing platform identical with disposal system 101 and/or landmark data storehouse system 120.The different geographical marking image collections forming geographical marking image library 110 can pass through the internet interconnection of the Internet, Intranet or other form.Disposal system 101 using from geographical marking image library can image as input.In certain embodiments, the standard graphical format of such as GIF can when being stored in storehouse 110 by the image from distributed image set or be converted into before being input to processing module 101.Embodiment can also require the standardization of other form, such as reduces or strengthens resolution, or performs the process to image before following: when storing the image on storehouse 110 or before being input to processing module 101.Can be used by link 142 and 143 comprise such as unrestricted, and storehouse 110 is connected to other assembly of system by any one or combination in the interconnection mechanism of pci bus, IEEE 1394 fire-wire interfaces, Ethernet interface or IEEE 802.11 interface.
Fig. 2 be use from image library 110 geocoding creation of image or upgrade the process flow diagram of process 200 of one embodiment of the present of invention in landmark data storehouse 121.Process 200 comprises two main process stage: geographical clustering phase 201 and vision clustering phase 202.Given geocoding digital image set, such as large-scale various tourist famous-city digital image sets, usable image can be divided into discrete group based on the geographic location code of each photo by geographical clustering phase 201.Geographical clustering phase is used in geocoding available in each photo image to be separated into relatively rapidly different groups or geographical cluster.Can utilize pre-configured parameter, the image comprised within it is considered to belong to the default radii of same geographical cluster.Then the geographical cluster generated at geographical clustering phase 201 can be input to vision clustering phase 202.At vision clustering phase 202, system contemplates separates the image in each geographical cluster by the image cluster (that is, vision cluster) based on image similarity the image in each geographical cluster being divided into again same target or terrestrial reference.Notice, generally speaking, at least partly because the geographical cluster of comparison film set has more been included in the geographical location information in each photo, so the vision cluster cost less of the geographical cluster of the comparison film set computationally same image collection of comparison.Such as, by contrast, vision cluster 202 can comprise perform Object identifying, proper vector generate and to image each in the comparison of each discernible object, then compare the proper vector of different images.
In certain embodiments, can will comprise the image that is associated and/or the vision cluster information quoted of the image be associated is stored in the database in such as landmark data storehouse 121.Be stored in image in landmark data storehouse 121 and/or virtual image can use and allow one or more indexes 122 of the vision cluster stored based on the configurable standard access comprising popularity to visit.Such as, the vision cluster stored can process with the popularity module 104 of the sequential access allowing the quantity according to uniqueness (unique) user that have submitted image to each cluster by upgrading index 122.
In certain embodiments, selected vision cluster can stand user and consult and/or can be processed further by computer program.Such as, alternatively, meet specified value, such as there is the image being less than predetermined quantity, vision cluster can stand user and consult.User can revise one or more vision cluster by comprising following behavior: deleted image, add image or image is re-assigned to another cluster.User can also specify new label information or amendment current label information.It will be appreciated by those skilled in the art that processing vision cluster according to the external data received from user or computer program can require that system performs extra function to safeguard the consistance of geographical cluster and the vision cluster information be stored in Database Systems 120.
The processing stage that Fig. 3 showing two, create geographical cluster 301 and the geographical cluster 302 of checking, the described stage is included in geographical clustering phase 201 in some embodiments of the invention.Create geographical cluster 301 can comprise and use one or more predefine radius parameter to determine an image whether in the geographical radius of another image based on the geographic location code on two images.Notice, geographical clustering algorithm may need the geographic position coding considering the position of actual instruction camera instead of the position of object or terrestrial reference.The geographical marking of comparison film can be realized by some devices, and described device comprises the human-edited of GIF (EXIF) label of digital camera, the GPS device be separated with camera together with adapting software, the instrument using the such as Google earth or the comparison film with GPS ability.The method of geographical marking is generally known in this area, does not therefore describe in the disclosure.Further, although the geographical cluster radius of acquiescence can be suitable for interested most of terrestrial reference or object, some terrestrial references may need different cluster radius parameters to produce the most poly-group to image.In the stage 301, generate the cluster of one or more image based on geographic proximity.
At geographical cluster Qualify Phase 302, can based on selected standard verify create in the geographical cluster that geographical clustering phase 301 generates each.Such as, in one embodiment of the invention, target can be guarantee to select reasonably to comprise tourism terrestrial reference for each the geographical cluster processed further, i.e. welcome terrestrial reference.Correspondingly, validation criteria can be that only process has the geographical cluster of the image from the unique users more than predetermined threshold further.Such as have at least predetermined quantity the validation criteria that have submitted the unique users of the image of same terrestrial reference may other buildings of the filtering attractive force that has nothing welcome, structures and the scenic spots and historical sites, park, the chain of mountains, landscape etc. image.Such as, the enthusiasm house-owner putting up the picture in the house recently built of the not too popular attractive force of oneself unlikely puts up the image of some quantity in his house, is considerable compared with the quantity of the image of any welcome terrestrial reference that wherein quantity of this image is puted up with all users by the Internet digital image set website.In one embodiment, per threshold value can be set for season and/or every geographic area.In other embodiments, can first analyze geographical cluster by the distribution for unique users and derive threshold value.In other embodiment again, threshold value can be set for the terrestrial reference of each type.To the aforementioned description of the method for arranging threshold value only for illustration of object.It will be appreciated by those skilled in the art that to there is other methods many, geographical cluster can be verified according to the focus used each time by it.
Fig. 4 illustrates the further details 301 of the process in geographical clustering phase in one embodiment of the invention.For each geographical marking image, can duplication stages 401-405.For each the geographical marking image still not belonging to cluster, determine the distance from image to each cluster in the stage 401.Distance is determined can based on the geographic coordinate at the center of image.Such as, in one embodiment, distance can be the moving average picture centre from the center of image to cluster, the center of each in the image that wherein moving average is updated and moving average can be calculated as in cluster when new image is added to cluster average.In the stage 402, make the decision of whether mating with existing cluster about image.The geographic coordinate of the image in the region that decision can define based on the predetermined radii of the center geographic coordinate falling into distance cluster.Predetermined radii can such as based on basis, every geographic area, the analysis based on the centre coordinate to the image in each cluster or the type based on terrestrial reference.If think that image is the coupling to existing cluster, then add image to this cluster in the stage 403.Otherwise, create new cluster in the stage 404.Image added to existing cluster or create new cluster, may need to calculate some cluster parameters, the geographic center coordinate of such as cluster.When process 301 for input geographical marking image set and after completing, geographical cluster collection should be used.Geographical cluster can be stored as together with the information be associated a part for geographical marking image library 110 or processing module 101 another memory device addressable.If other metadata that the information be associated with each image or geographical cluster can comprise geographic position and Description Image is available, distribute to the additional positional information (that is, specifying the text mark in country and city) of the text label of image and the geographical location information based on image.
Fig. 5 is the detailed view of vision clustering phase 202 in one embodiment of the invention.For each the geographical cluster generated in the stage 201, duplication stages 501-505.Input to vision clustering phase 202 is the geographical cluster collection produced in the stage 201.Output from vision clustering phase 202 is about the one or more vision clusters of each in the geographical cluster of input.Each vision cluster should comprise and has same such as welcome tourist site target image.Vision cluster collection can collect all images describing specific landmark with various camera angle, camera distance and light condition.Whether this vision cluster collection comprises all images with specific landmark and only has those images, is the validity of vision clustering method and the function of parameter.No matter whether vision cluster collection has all images of comprising specific landmark and only has those images, and instruction of the present disclosure is all applicable.For geographical cluster, the stage 501 creates the index of the image in cluster.Index can be the list of the image in cluster, it has and comprises original image or to the quoting of original image, the image (such as, the low resolution version of original image), one or more image template and the proper vector that derive from original image, user ID, geographical marking, temporal information and the data element of any label that distributed.In the stage 502, each image in geographical cluster is mated with corresponding index.Matching process 502, for each image in geographical cluster, generates quoting matching image.After matching process 502, index for each image, can comprise quoting other matching images all in this geographical cluster.Coupling in stage 502 can comprise Object identifying in each image to identify the interested object of such as terrestrial reference, to generate the proper vector of the object that each identifies, then comparative feature vector is to obtain match information.Relatively can based on distributing to the configurable numerical score of the feature be included in proper vector and two Images Classifications being become the configurable digital threshold that coupling is right.The method of the Object identifying in image and generating feature vector is well-known in this area.Such as, at International Conference on Computer Vision (in September, 1999) the 1150-1157 page of Corfu of Greece, in " the Object recognition from local scale-invariant features " of David G.Lowe, describe the method for the Object identifying in image.
In the stage 503, based on the index generated at stage 501-502 and coupling, generate matching area figure.In matching area figure, node is image, and the relation between link indicating image among the nodes.Such as, according to the stage 502 mate image to the link that can have between which.In the stage 504, matching area figure is used to generate vision cluster.In brief, vision cluster is the subtree of the connection after leaving out weak link based on the extra process in the stage 504 in matching area figure.Weak link can be with the link of matching characteristic being less than number of thresholds when image mates based on image or feature templates.The link of not mating specific characteristic collection can be taken as weak link by some embodiments.If available, the text mark agreement between the image in cluster can be another standard.Further, the quantity of the image in cluster can be considered when leaving out weak link, to minimize the cluster with considerably less image.It will be appreciated by those skilled in the art that except described here except those, leaving out weak link can based on multiple standards.Finally, vision company-data is preserved in the stage 505.Vision cluster can be saved in landmark data storehouse 121.Together with outside the image of each vision cluster and object information, other related data can be preserved, include but not limited to describe one or more text mark of cluster and one or more images of special representative's cluster.Such as can generate by the text mark of each composing images merging vision cluster the text mark describing this vision cluster.One or more images of special representative's vision cluster can be useful for display in such as welcome tourist site target index.
In another embodiment of the present invention, the user rs authentication to the vision cluster generated is achieved.Fig. 6 illustrates graphical user interface 601, and it can show the image in each vision cluster to user, and provides the ability of various aspects of each cluster of human-edited to user.Such as, graphical user interface can the vision cluster of retrieve stored in landmark data storehouse 621, and the vision cluster after editor is write back to same database 621.Graphical user interface 601 can comprise cluster mark module 602, and it allows user new text mark to be distributed to each cluster and/or image and/or revises the text mark of current distribution of each cluster and/or image.Such as, cluster mark module 602 can show each cluster and its current text mark, and distributes to the mark of the individual images in cluster, and allows user's amendment to distribute to the text mark of cluster.Cluster merges module 603 and user can be allowed to merge or split cluster.To so artificial merging of cluster or to split can be that user is desired after having checked the image in one or more cluster.Cluster editor module 604 can allow user add from cluster or delete individual images.Module 604 can be useful when the inferior expression of the terrestrial reference of the correspondence of artificial removal's cluster and for the artificial one or more new image adding the terrestrial reference of the correspondence of cluster.Except above-mentioned points, embodiments of the invention can provide various option when user and system 100 are mutual to user.
Turn back to Fig. 1, in certain embodiments, popularity module 104 can calculate the popularity score value of each vision cluster, and correspondingly carries out rank to vision cluster.For accessing the one or more popularity ranks that can calculate based on popularity module in the index 122 of terrestrial reference database 121.The popularity score value of cluster can one or more based in following: the quantity of the sum of the image in cluster, the quantity that contribute to the unique users of image to cluster, the image in a certain predetermined radii at the center of vision cluster or the image with unique users identifier.Should be understood that, can also use and not have in other method above-described to calculate popularity score value.
In another embodiment of the present invention, progressively landmark data storehouse is generated.Fig. 7 is the example process that may be used for progressively generating landmark data storehouse.In stage 701 by other device by recently can geographical marking download image to local store or make recently can geographical marking image can use processing module 101.In the stage 702, all available geographical marking image comprising new geographical marking image realizes geographical cluster.Geographical cluster is described about Fig. 3-4 above.In the stage 703, the geographical cluster produced by the stage 702 stands vision cluster.Vision cluster is described about Fig. 5 above.After completing vision cluster, in the stage 704, some embodiments can propagate the part or all of change of Client-initiated to the previous cluster in the vision cluster be previously stored in landmark data storehouse.Such as, the label that user can be distributed or revise is propagated to new cluster.Alternatively, in the stage 705, new vision cluster can stand user rs authentication and human-edited.Describe the user interactions of some types about Fig. 6 above.
The system 100 with landmark data storehouse 121 can enable many application.Such as, landmark data storehouse 121 may be used for supplement user inquiry to make inquiry more focus on.Fig. 8 illustrates the process that may be used in an embodiment augments user's inquiry.Can resolve for predetermined trigger word set the user's inquiry received in the stage 802.Such as, the such as city name in " Paris " may be used for triggering the terrestrial reference in city, and vice versa.After identifying the trigger word in inquiry, can for those trigger words search landmark data storehouse be to identify the label word be associated in the stage 803.Continue example above, the trigger word in " Paris " can impel search to find " Eiffel Tower ".In the stage 804, then the identified label word be associated is used for augmenting inquiry string.Inquiry string after such supplement can be useful for finding relevant information widely.
Figure 9 illustrates Another application in one embodiment of the invention.Process 900 may be used for the on-line automatic mark to digital picture.Such as, in the stage 901, the image in new digital picture and landmark image database is compared.If find the image of one or more coupling, then the Computer image genration label in the stage 902 based on all couplings.In the stage 903, with the image that the label for labelling recently generated is new.
Figure 10 illustrates user interface 1000 in one embodiment of the invention, wherein the terrestrial reference collection according to user's input selection, and shows the details of the vision cluster about the terrestrial reference selected by each.The terrestrial reference that the standard of specifying according to user is selected can be shown in each region of such as 1010.Terrestrial reference selected by each can also have the region for receiving user's input, such as check box 1040.For the terrestrial reference shown by each, the summary lists of vision cluster can be shown.The summary lists of vision cluster can be shown, it is made to be clearly shown as belonging to specific shown terrestrial reference, such as, the summary lists for the vision cluster of the terrestrial reference shown by first can be included in the viewing area 1010 corresponding with the terrestrial reference shown by first.Each entry 1020 for the summary lists of the vision cluster of shown terrestrial reference can have corresponding position and input with the user received specific to this cluster, such as corresponds to the check box 1030 of the vision cluster represented in 1020.Each entry 1020 can comprise about cluster descriptor 1022 and be used for retrieving the link 1021 of further details.Such as, about the descriptor of each cluster can comprise image quantity, with regard to the popularity with regard to the unique users of cluster contribution plot picture or the quantity of author, whether to be manually modified about cluster or any visit information of authenticated information and such as key.Link 1021 comprises for the image of cluster selected by retrieval and the link method of individual images related data, the hyperlink that such as user can navigate.
Figure 11 shows the process flow diagram of the process relevant with interface 1000 in one embodiment of the present of invention.In the stage 1110, user specifies one or more choice criteria, such as country, city, area and/or other keyword.The information that the user comprising keyword specifies can be used for based on the tag search image distributing to image.User can also specify other search criteria, the minimum pouplarity of all terrestrial references as shown and have the terrestrial reference of image of the minimum number that user submits to.Such as, user may wish to check that at least 10 Egyptian isolated users are that it submitted the terrestrial reference of image to.User can also specify the terrestrial reference of the image only with at least specified quantity just should be shown.For each terrestrial reference meeting the choice criteria that user specifies, duplication stages 1112 to 1120.In the stage 1112, find the one or more terrestrial references meeting the choice criteria that user specifies.For the terrestrial reference selected by each, duplication stages 1114 to 1116 has the vision cluster of selected terrestrial reference with display.In the stage 1114, select vision cluster, and in the stage 1116, the information of display description 1020 vision cluster.Such as, for each vision cluster, the quantity of image, the unique users identifier of image or the quantity of author, the link, other visit information etc. with the image visited in cluster can be shown.For each the vision cluster shown in the stage 1116, user's tablet pattern of such as check box 1030 can be shown and make described user's tablet pattern can be used in user's input.
In the stage 1118, make the determination about whether there are the more vision clusters corresponding with selected terrestrial reference to be shown.If for selected terrestrial reference, more vision clusters are not waited to be shown, then in the stage 1120, show the information about terrestrial reference.Such as, the information of quantity etc. of the Name & Location of such as terrestrial reference, popularity, image can be shown.For each terrestrial reference of display in the stage 1120, corresponding user's tablet pattern can also be shown, and make described user's tablet pattern can be used in user's input.Such as, in Fig. 10, check box 1040 can receive the user corresponding with the terrestrial reference shown in region 1010 and inputs.In the stage 1122, make and determining about whether there is target to be extraly shown.If shown the terrestrial reference of the choice criteria that all users of meeting specify, then in the stage 1124, receive the user corresponding with vision cluster and input.The user corresponding with vision cluster inputs such as can indicate and merges one or more cluster or make one or more cluster go to associate with selected terrestrial reference.In the stage 1126, correspondingly process vision cluster.In the stage 1128, receive the user corresponding with each terrestrial reference and input.The user corresponding with each terrestrial reference inputs such as can indicate and merges and/or delete one or more terrestrial reference.
Figure 12 user wherein shown in one embodiment of the invention can check the user interface 1200 of the information about selected vision cluster.Interface 1200 can be included in one or more example image of the vision cluster which show selected by representative region 1210, list the region 1220 of the data of description element set of the details of each image comprised in vision cluster wherein and show the region 1230 of selected image wherein.Region 1220, for each image in selected cluster, can comprise user's tablet pattern of the correspondence of descriptor 1224 and such as check box 1222.Descriptor 1224 can comprise, such as unrestricted, is used for retrieving the link of corresponding image, about the author information of the data of image and temporal information, image and label information.Region 1230 can show the image from the list retrieval of display 1220.In region 1230, the image of display can be such as unrestricted, enables user check interested district 1232 in shown image.Such as, the ability verifying the interested district in any image can allow user to determine better, and specific image is in the well-formedness in current cluster.
Figure 13 shows the process flow diagram of the process relevant with interface 1200 in one embodiment.In the stage 1310, receive the user's input selecting vision cluster.In the stage 1312, such as, select in region 1210 and show the one or more images of vision cluster selected by representative.In the stage 1314, such as, in region 1220, show the information about each image in selected cluster.Information is listed about each various data element, and described various data element comprises such as unrestricted, is used for retrieving the link of corresponding image, about the author information of the data of image and temporal information, image and label information.The image can also listed for each shows user's tablet pattern of such as check box 1222, and makes described user's input picture can be used in user's input.In the stage 1316, receive user's input.In the stage 1318, process vision cluster according to received user input.Such as, can from selected cluster deleted image, some label informations etc. can be changed.
In one embodiment of the invention, use well-known computing machine to realize system of the present invention described here and assembly.Such computing machine can be to perform any commercialization of function described here and well-known computing machine, the computing machine that such as can obtain from International Business Machines (IBM), Apple, Silicon Graphics company, Sun, HP, Dell, Compaq, Digital, Cray etc.
Comprise there is steering logic (software) stored therein computing machine can with or any device of computer-readable recording medium or manufactured goods be referred to herein as computer program or program storage device.This includes but not limited to computing machine, primary memory, hard disk or moveable storage unit.Such computer program with steering logic that is stored therein, that impel such data processing equipment to operate like that as the described herein when being performed by one or more data processing equipment represents embodiments of the invention.
Should be appreciated that embodiment part instead of summary of the invention and summary part are intended to for explaining claim.Summary of the invention and summary part can illustrate the of the present invention one or more and exemplary embodiment of not all that inventor considers, therefore summary of the invention and summary part are not intended to limit the present invention and appended claim by any way.
Above by means of illustrating that the functional configuration block of realization of the function of specifying and relation thereof is to describe the present invention.In this case be convenient to describe, at random define the border of these functional configuration blocks.Can limit alternative border, as long as the function of specifying described and relation thereof are duly executed.
The aforementioned description of specific embodiment discloses general characteristic of the present invention so fully, make other people can when not deviating from general thoughts of the present invention, easily revise and/or adjust the various application of general characteristic of the present invention for such specific embodiment by the knowledge be applied in the technology of this area, and need not excessive experiment be carried out.Therefore, based on the instruction provided at this and guidance, such adjustment and amendment are intended in the implication and scope of the equivalent of the disclosed embodiments.Should be understood that, be used for describing and unrestriced object in this word or term, therefore the term of this instructions or word should be explained according to described instruction and instructing by technician.
Width of the present invention and scope by any one restriction of above-mentioned exemplary embodiment, but should only should not limit according to claims and equivalent thereof.
Claims (16)
1. strengthen a method for user's inquiry of searching floor signal image, comprising:
Receive user's inquiry;
Identify the one or more trigger words in described user inquiry;
The one or more corresponding label corresponding with described one or more trigger word is selected from landmark data storehouse;
Described user inquiry is augmented with the label of described one or more correspondence, and
Generate user's inquiry of supplement.
2. the method for claim 1, comprises further:
User's inquiry based on described supplement carrys out retrieving images.
3. the method for claim 1, comprises further:
Utilize specific popularity standard to augment described user inquiry.
4. the method for claim 1, comprises further:
User's inquiry based on described supplement carrys out retrieving images;
According to specific popularity standard, retrieved image is sorted.
5. the method for claim 1, comprises further:
Utilize specific popularity standard to augment described user inquiry, wherein said popularity standard comprises the popularity of terrestrial reference, and the popularity of described terrestrial reference is based on the quantity of the unique users identifier be associated with the image with each terrestrial reference.
6. strengthen a system for user's inquiry of searching floor signal image, comprising:
For receiving the device of user's inquiry;
For identifying the device of the one or more trigger words in described user inquiry;
For selecting the device of the one or more corresponding label corresponding with described one or more trigger word from landmark data storehouse;
For augmenting the device of described user inquiry with the label of described one or more correspondence, and
For generating the device of user's inquiry of supplement.
7. system as claimed in claim 6, comprises further:
For carrying out the device of retrieving images based on user's inquiry of described supplement.
8. system as claimed in claim 6, comprises further:
For utilizing specific popularity standard to augment the device of described user inquiry.
9. system as claimed in claim 6, comprises further:
For carrying out the device of retrieving images based on user's inquiry of described supplement;
For the device sorted to retrieved image according to specific popularity standard.
10. system as claimed in claim 6, comprises further:
For utilizing specific popularity standard to augment the device of described user inquiry, wherein said popularity standard comprises the popularity of terrestrial reference, and the popularity of described terrestrial reference is based on the quantity of the unique users identifier be associated with the image with each terrestrial reference.
The method that 11. 1 kinds of users strengthening searching floor signal image inquire about, comprising:
Receive user's inquiry;
Identify the one or more trigger words in described user inquiry;
The one or more corresponding label corresponding with described one or more trigger word is selected from landmark data storehouse;
Augment described user inquiry with the label of described one or more correspondence, generate user's inquiry of supplement;
Based on the one or more terrestrial reference of user's query and search of described supplement;
Generate the user interface comprising described one or more terrestrial reference; And
One or more summary lists is shown, and wherein each summary lists is corresponding in the terrestrial reference retrieved.
12. methods as claimed in claim 11, wherein each summary lists comprises the descriptor about described terrestrial reference.
13. methods as claimed in claim 11, wherein each summary lists comprises and can be used to retrieve about the link of the further details of described image.
14. methods as claimed in claim 11, wherein each summary lists comprises for receiving the position inputted specific to the user of selected image.
15. methods as claimed in claim 11, wherein each summary lists comprises the popularity information about selected image.
16. methods as claimed in claim 11, wherein each summary lists comprises the information about whether selected image has been modified.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/119,359 US8676001B2 (en) | 2008-05-12 | 2008-05-12 | Automatic discovery of popular landmarks |
US12/119,359 | 2008-05-12 | ||
CN200980127106.5A CN102089761B (en) | 2008-05-12 | 2009-05-12 | Automatic discovery of popular landmarks |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN200980127106.5A Division CN102089761B (en) | 2008-05-12 | 2009-05-12 | Automatic discovery of popular landmarks |
Publications (2)
Publication Number | Publication Date |
---|---|
CN104298710A true CN104298710A (en) | 2015-01-21 |
CN104298710B CN104298710B (en) | 2018-05-18 |
Family
ID=41266941
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN200980127106.5A Active CN102089761B (en) | 2008-05-12 | 2009-05-12 | Automatic discovery of popular landmarks |
CN201410455635.0A Active CN104298710B (en) | 2008-05-12 | 2009-05-12 | Automatically welcome terrestrial reference is found |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN200980127106.5A Active CN102089761B (en) | 2008-05-12 | 2009-05-12 | Automatic discovery of popular landmarks |
Country Status (5)
Country | Link |
---|---|
US (4) | US8676001B2 (en) |
JP (2) | JP5476369B2 (en) |
KR (1) | KR101579634B1 (en) |
CN (2) | CN102089761B (en) |
WO (1) | WO2009139844A2 (en) |
Families Citing this family (104)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20170286434A1 (en) * | 2005-10-26 | 2017-10-05 | Cortica, Ltd. | System and method for signature-based clustering of multimedia content elements |
US8525825B2 (en) | 2008-02-27 | 2013-09-03 | Google Inc. | Using image content to facilitate navigation in panoramic image data |
KR101659097B1 (en) * | 2008-04-14 | 2016-09-22 | 티피 비전 홀딩 비.브이. | Method and apparatus for searching a plurality of stored digital images |
US8676001B2 (en) | 2008-05-12 | 2014-03-18 | Google Inc. | Automatic discovery of popular landmarks |
US8406531B2 (en) | 2008-05-15 | 2013-03-26 | Yahoo! Inc. | Data access based on content of image recorded by a mobile device |
US9646025B2 (en) * | 2008-05-27 | 2017-05-09 | Qualcomm Incorporated | Method and apparatus for aggregating and presenting data associated with geographic locations |
EP2297703A1 (en) | 2008-06-03 | 2011-03-23 | ETH Zurich | Method and system for generating a pictorial reference database using geographical information |
JP2009301416A (en) * | 2008-06-16 | 2009-12-24 | Kddi Corp | Content classification apparatus, content retrieval apparatus, content retrieval system and computer program |
US8788493B2 (en) | 2008-06-30 | 2014-07-22 | Verizon Patent And Licensing Inc. | Digital image tagging apparatuses, systems, and methods |
TWI390177B (en) * | 2008-11-24 | 2013-03-21 | Inst Information Industry | Poi recommending apparatus and methods, and storage media |
US8396287B2 (en) | 2009-05-15 | 2013-03-12 | Google Inc. | Landmarks from digital photo collections |
JP5268787B2 (en) * | 2009-06-04 | 2013-08-21 | キヤノン株式会社 | Information processing apparatus, control method therefor, and program |
US8768313B2 (en) * | 2009-08-17 | 2014-07-01 | Digimarc Corporation | Methods and systems for image or audio recognition processing |
US8121618B2 (en) | 2009-10-28 | 2012-02-21 | Digimarc Corporation | Intuitive computing methods and systems |
US20110184949A1 (en) * | 2010-01-25 | 2011-07-28 | Jiebo Luo | Recommending places to visit |
US9465993B2 (en) | 2010-03-01 | 2016-10-11 | Microsoft Technology Licensing, Llc | Ranking clusters based on facial image analysis |
US20110211737A1 (en) * | 2010-03-01 | 2011-09-01 | Microsoft Corporation | Event Matching in Social Networks |
US20110292230A1 (en) | 2010-05-28 | 2011-12-01 | Winters Dustin L | Method for managing privacy of digital images |
US9703895B2 (en) * | 2010-06-11 | 2017-07-11 | Microsoft Technology Licensing, Llc | Organizing search results based upon clustered content |
US20110310088A1 (en) * | 2010-06-17 | 2011-12-22 | Microsoft Corporation | Personalized navigation through virtual 3d environments |
US8385593B2 (en) * | 2010-06-18 | 2013-02-26 | Google Inc. | Selecting representative images for establishments |
US8270684B2 (en) | 2010-07-27 | 2012-09-18 | Google Inc. | Automatic media sharing via shutter click |
US8724910B1 (en) * | 2010-08-31 | 2014-05-13 | Google Inc. | Selection of representative images |
US8581997B2 (en) | 2010-10-28 | 2013-11-12 | Intellectual Ventures Fund 83 Llc | System for locating nearby picture hotspots |
US8442716B2 (en) | 2010-10-31 | 2013-05-14 | Microsoft Corporation | Identifying physical locations of entities |
KR20130139302A (en) * | 2010-11-01 | 2013-12-20 | 큐브 리스 아이엔시. | Creating and linking 3d spatial objects with dynamic data, and visualizing said objects in geographic information systems |
US8655889B2 (en) * | 2010-12-10 | 2014-02-18 | Microsoft Corporation | Autonomous mobile blogging |
US8533187B2 (en) | 2010-12-23 | 2013-09-10 | Google Inc. | Augmentation of place ranking using 3D model activity in an area |
US8566325B1 (en) | 2010-12-23 | 2013-10-22 | Google Inc. | Building search by contents |
WO2012090017A1 (en) * | 2010-12-30 | 2012-07-05 | Telefonaktiebolaget L M Ericsson (Publ) | Method of building a geo-tree |
US20120213404A1 (en) | 2011-02-18 | 2012-08-23 | Google Inc. | Automatic event recognition and cross-user photo clustering |
US9552376B2 (en) | 2011-06-09 | 2017-01-24 | MemoryWeb, LLC | Method and apparatus for managing digital files |
US10453226B1 (en) * | 2011-07-26 | 2019-10-22 | Google Llc | Presenting information on a map |
US9280545B2 (en) * | 2011-11-09 | 2016-03-08 | Microsoft Technology Licensing, Llc | Generating and updating event-based playback experiences |
US9165206B2 (en) * | 2011-12-12 | 2015-10-20 | Google Inc. | Updating point of interest data based on an image |
CN103164480A (en) * | 2011-12-13 | 2013-06-19 | 北京千橡网景科技发展有限公司 | Method and equipment used for recommending interest points in social network |
CN103207879B (en) * | 2012-01-17 | 2016-03-30 | 阿里巴巴集团控股有限公司 | The generation method and apparatus of image index |
CN103294712B (en) * | 2012-02-29 | 2016-09-21 | 三星电子（中国）研发中心 | Hot spot area in real time commending system and method |
JP2013207357A (en) * | 2012-03-27 | 2013-10-07 | Sony Corp | Server, client terminal, system, and program |
US8996305B2 (en) * | 2012-06-07 | 2015-03-31 | Yahoo! Inc. | System and method for discovering photograph hotspots |
US9020278B2 (en) * | 2012-06-08 | 2015-04-28 | Samsung Electronics Co., Ltd. | Conversion of camera settings to reference picture |
US9391792B2 (en) | 2012-06-27 | 2016-07-12 | Google Inc. | System and method for event content stream |
CN103577400A (en) * | 2012-07-18 | 2014-02-12 | 三星电子（中国）研发中心 | Location information providing method and system |
US9036865B2 (en) * | 2012-09-12 | 2015-05-19 | International Business Machines Corporation | Location determination for an object using visual data |
US20140072226A1 (en) * | 2012-09-13 | 2014-03-13 | International Business Machines Corporation | Searching and Sorting Image Files |
US9677886B2 (en) * | 2013-02-10 | 2017-06-13 | Qualcomm Incorporated | Method and apparatus for navigation based on media density along possible routes |
US9311640B2 (en) | 2014-02-11 | 2016-04-12 | Digimarc Corporation | Methods and arrangements for smartphone payments and transactions |
US9208170B1 (en) | 2013-03-15 | 2015-12-08 | Google Inc. | Classifying natural mapping features |
US9230191B2 (en) * | 2013-03-15 | 2016-01-05 | Dropbox, Inc. | Presentation and organization of content |
EP2782058A1 (en) * | 2013-03-20 | 2014-09-24 | Valuetainment AG | Information system to obtain an exposition rating of a geographical area |
US9465513B2 (en) * | 2013-04-11 | 2016-10-11 | General Electric Company | Visual representation of map navigation history |
CN103198162B (en) * | 2013-04-28 | 2016-08-31 | 冠捷显示科技（厦门）有限公司 | A kind of picture browsing exchange method |
CN103488769B (en) * | 2013-09-27 | 2017-06-06 | 中国科学院自动化研究所 | A kind of search method of landmark information based on multimedia min ing |
US9069794B1 (en) * | 2013-10-11 | 2015-06-30 | Google Inc. | Determining location information for images using landmark, caption, and metadata location data |
US9531722B1 (en) | 2013-10-31 | 2016-12-27 | Google Inc. | Methods for generating an activity stream |
US9542457B1 (en) | 2013-11-07 | 2017-01-10 | Google Inc. | Methods for displaying object history information |
US9614880B1 (en) | 2013-11-12 | 2017-04-04 | Google Inc. | Methods for real-time notifications in an activity stream |
US10242080B1 (en) * | 2013-11-20 | 2019-03-26 | Google Llc | Clustering applications using visual metadata |
US9471834B1 (en) * | 2013-11-22 | 2016-10-18 | Google Inc. | System and method for updating map views |
US9509772B1 (en) | 2014-02-13 | 2016-11-29 | Google Inc. | Visualization and control of ongoing ingress actions |
WO2015134364A1 (en) * | 2014-03-04 | 2015-09-11 | Google Inc. | Schematic representation of geographic locations |
USD780777S1 (en) | 2014-04-22 | 2017-03-07 | Google Inc. | Display screen with graphical user interface or portion thereof |
US9934222B2 (en) | 2014-04-22 | 2018-04-03 | Google Llc | Providing a thumbnail image that follows a main image |
USD781317S1 (en) | 2014-04-22 | 2017-03-14 | Google Inc. | Display screen with graphical user interface or portion thereof |
USD781318S1 (en) | 2014-04-22 | 2017-03-14 | Google Inc. | Display screen with graphical user interface or portion thereof |
US9972121B2 (en) * | 2014-04-22 | 2018-05-15 | Google Llc | Selecting time-distributed panoramic images for display |
US9536199B1 (en) | 2014-06-09 | 2017-01-03 | Google Inc. | Recommendations based on device usage |
CN105338479B (en) | 2014-06-09 | 2020-03-10 | 阿里巴巴集团控股有限公司 | Information processing method and device based on places |
US9507791B2 (en) | 2014-06-12 | 2016-11-29 | Google Inc. | Storage system user interface with floating file collection |
US10078781B2 (en) | 2014-06-13 | 2018-09-18 | Google Llc | Automatically organizing images |
US9870420B2 (en) | 2015-01-19 | 2018-01-16 | Google Llc | Classification and storage of documents |
US9495614B1 (en) | 2015-02-27 | 2016-11-15 | Google Inc. | Verifying labels for images using image recognition |
US9754413B1 (en) | 2015-03-26 | 2017-09-05 | Google Inc. | Method and system for navigating in panoramic images using voxel maps |
RU2015111646A (en) * | 2015-03-31 | 2016-10-20 | Общество С Ограниченной Ответственностью "Яндекс" | SYSTEM AND METHOD OF RANKING POINTS OF INTEREST WITH USE OF PHOTO RATING |
RU2015125820A (en) | 2015-06-30 | 2017-01-10 | Общество С Ограниченной Ответственностью "Яндекс" | METHOD AND SERVER FOR PROCESSING USER REQUEST FOR PROVIDING RECOMMENDED AREA OF INTEREST |
US10467284B2 (en) | 2015-08-03 | 2019-11-05 | Google Llc | Establishment anchoring with geolocated imagery |
US10169659B1 (en) * | 2015-09-24 | 2019-01-01 | Amazon Technologies, Inc. | Video summarization using selected characteristics |
CN107710197B (en) | 2015-09-28 | 2021-08-17 | 谷歌有限责任公司 | Sharing images and image albums over a communication network |
KR102465332B1 (en) * | 2015-12-29 | 2022-11-11 | 에스케이플래닛 주식회사 | User equipment, control method thereof and computer readable medium having computer program recorded thereon |
US10664719B2 (en) | 2016-02-12 | 2020-05-26 | Adobe Inc. | Accurate tag relevance prediction for image search |
US10235623B2 (en) * | 2016-02-12 | 2019-03-19 | Adobe Inc. | Accurate tag relevance prediction for image search |
TWI626428B (en) * | 2016-03-29 | 2018-06-11 | 群邁通訊股份有限公司 | Route planning system and method |
US10007867B2 (en) * | 2016-04-04 | 2018-06-26 | Google Llc | Systems and methods for identifying entities directly from imagery |
US10628463B2 (en) * | 2016-04-07 | 2020-04-21 | Adobe Inc. | Applying geo-tags to digital media captured without location information |
CN106528807A (en) * | 2016-11-15 | 2017-03-22 | 杭州壹晨仟阳科技有限公司 | Landmark registration method, device and equipment and landmark query method and device |
CN106991404B (en) * | 2017-04-10 | 2019-06-28 | 山东师范大学 | Ground mulching update method and system based on crowd-sourced geodata |
EP3568787B1 (en) | 2017-05-17 | 2024-04-10 | Google LLC | Automatic image sharing with designated users over a communication network |
EP3702929A4 (en) * | 2017-10-24 | 2021-01-13 | Panasonic Intellectual Property Management Co., Ltd. | Content management device, content management system, and control method |
CN109725980B (en) * | 2017-10-27 | 2023-05-16 | 伊姆西Ip控股有限责任公司 | Method, apparatus and computer readable medium for generating mirror image tags |
US11232115B2 (en) * | 2018-04-11 | 2022-01-25 | Nokia Technologies Oy | Identifying functional zones within a geographic region |
CN108829801B (en) * | 2018-06-06 | 2020-11-20 | 大连理工大学 | Event trigger word extraction method based on document level attention mechanism |
CN109255365B (en) * | 2018-07-26 | 2021-09-28 | 河海大学 | Geographic suitability classification method based on K-medoids algorithm |
CN109583484B (en) * | 2018-11-14 | 2022-04-05 | 西北工业大学 | Automatic selection method for three-type sea area landmark points |
CN111209419B (en) * | 2018-11-20 | 2023-09-19 | 浙江宇视科技有限公司 | Image data storage method and device |
US10936178B2 (en) | 2019-01-07 | 2021-03-02 | MemoryWeb, LLC | Systems and methods for analyzing and organizing digital photos and videos |
US11025837B2 (en) | 2019-03-27 | 2021-06-01 | ROVl GUIDES, INC. | Replacing a background portion of an image |
WO2020198677A1 (en) * | 2019-03-27 | 2020-10-01 | Rovi Guides, Inc. | Replacing a background portion of an image |
US10944921B2 (en) | 2019-03-27 | 2021-03-09 | Rovi Guides, Inc. | Replacing a background portion of an image |
US10887531B2 (en) | 2019-03-27 | 2021-01-05 | Rovi Guides, Inc. | Replacing a background portion of an image |
US10848920B1 (en) * | 2019-09-17 | 2020-11-24 | Microsoft Technology Licensing, Llc | Generation of precise geospatial coordinates |
US11182612B2 (en) * | 2019-10-28 | 2021-11-23 | The Chinese University Of Hong Kong | Systems and methods for place recognition based on 3D point cloud |
CN111325249B (en) * | 2020-02-10 | 2022-05-17 | 上海携旅信息技术有限公司 | Image season-based discrimination method, system, electronic device and medium |
KR102310446B1 (en) * | 2020-12-31 | 2021-10-07 | (주)트레블씨투비 | Apparatus for identifying landmarks irrespective of location change based on deep learning model and method therefor |
CN113435443B (en) * | 2021-06-28 | 2023-04-18 | 中国兵器装备集团自动化研究所有限公司 | Method for automatically identifying landmark from video |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1432947A (en) * | 2001-12-29 | 2003-07-30 | Lg电子株式会社 | Multimedia object searchine device and method |
CN1816809A (en) * | 2003-06-30 | 2006-08-09 | 皇家飞利浦电子股份有限公司 | Enhanced organization and retrieval of digital images |
WO2008045704A1 (en) * | 2006-10-10 | 2008-04-17 | Microsoft Corporation | Identifying sight for a location |
WO2008055120A2 (en) * | 2006-10-30 | 2008-05-08 | Seeqpod, Inc. | System and method for summarizing search results |
Family Cites Families (71)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH07168855A (en) | 1993-09-21 | 1995-07-04 | Toshiba Corp | Information recording/reproducing device |
JP3307843B2 (en) | 1996-10-30 | 2002-07-24 | 松下電器産業株式会社 | Map display device in hypertext structure |
AU3639699A (en) * | 1998-04-13 | 1999-11-01 | Eyematic Interfaces, Inc. | Wavelet-based facial motion capture for avatar animation |
JPH11328194A (en) * | 1998-05-13 | 1999-11-30 | Nippon Telegr & Teleph Corp <Ntt> | Keyword retrieval method and device and storage medium storing keyword retrieval program |
US6711293B1 (en) * | 1999-03-08 | 2004-03-23 | The University Of British Columbia | Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image |
JP2000259669A (en) | 1999-03-12 | 2000-09-22 | Ntt Data Corp | Document classification device and its method |
US6411724B1 (en) | 1999-07-02 | 2002-06-25 | Koninklijke Philips Electronics N.V. | Using meta-descriptors to represent multimedia information |
JP2002010178A (en) | 2000-06-19 | 2002-01-11 | Sony Corp | Image managing system and method for managing image as well as storage medium |
US7233942B2 (en) * | 2000-10-10 | 2007-06-19 | Truelocal Inc. | Method and apparatus for providing geographically authenticated electronic documents |
JP3437555B2 (en) | 2001-03-06 | 2003-08-18 | キヤノン株式会社 | Specific point detection method and device |
GB0114271D0 (en) | 2001-06-12 | 2001-08-01 | Univ Manchester | Parameterisation |
JP2004021717A (en) | 2002-06-18 | 2004-01-22 | Toshiba Corp | Spatial data analyzer, spatial data analyzing program, and spatial data analyzing method |
US7911497B2 (en) * | 2003-04-25 | 2011-03-22 | Lockheed Martin Corporation | Method and apparatus for video on demand |
JP4388301B2 (en) * | 2003-05-08 | 2009-12-24 | オリンパス株式会社 | Image search apparatus, image search method, image search program, and recording medium recording the program |
US7313574B2 (en) | 2003-10-02 | 2007-12-25 | Nokia Corporation | Method for clustering and querying media items |
US20060015497A1 (en) * | 2003-11-26 | 2006-01-19 | Yesvideo, Inc. | Content-based indexing or grouping of visual images, with particular use of image similarity to effect same |
WO2005055138A2 (en) * | 2003-11-26 | 2005-06-16 | Yesvideo, Inc. | Statical modeling of a visual image for use in determining similarity between visual images |
US20060020597A1 (en) * | 2003-11-26 | 2006-01-26 | Yesvideo, Inc. | Use of image similarity in summarizing a collection of visual images |
US7697792B2 (en) * | 2003-11-26 | 2010-04-13 | Yesvideo, Inc. | Process-response statistical modeling of a visual image for use in determining similarity between visual images |
DE102004046563B4 (en) * | 2004-09-24 | 2008-01-03 | Aerodyn Energiesysteme Gmbh | Wind energy plant with fully integrated machine set |
US7707239B2 (en) | 2004-11-01 | 2010-04-27 | Scenera Technologies, Llc | Using local networks for location information and image tagging |
US7574409B2 (en) * | 2004-11-04 | 2009-08-11 | Vericept Corporation | Method, apparatus, and system for clustering and classification |
US7643686B2 (en) * | 2004-11-17 | 2010-01-05 | Eastman Kodak Company | Multi-tiered image clustering by event |
US7653249B2 (en) * | 2004-11-17 | 2010-01-26 | Eastman Kodak Company | Variance-based event clustering for automatically classifying images |
US8027832B2 (en) | 2005-02-11 | 2011-09-27 | Microsoft Corporation | Efficient language identification |
US8732175B2 (en) | 2005-04-21 | 2014-05-20 | Yahoo! Inc. | Interestingness ranking of media objects |
US7760917B2 (en) | 2005-05-09 | 2010-07-20 | Like.Com | Computer-implemented method for performing similarity searches |
US7353114B1 (en) * | 2005-06-27 | 2008-04-01 | Google Inc. | Markup language for an interactive geographic information system |
WO2007013432A1 (en) | 2005-07-26 | 2007-02-01 | Matsushita Electric Industrial Co., Ltd. | Image data management device and image data management method |
US7840558B2 (en) * | 2005-11-04 | 2010-11-23 | Microsoft Corporation | Geo-tagged based listing service and mapping engine |
US8098899B2 (en) * | 2005-11-14 | 2012-01-17 | Fujifilm Corporation | Landmark search system for digital camera, map data, and method of sorting image data |
JP2007142672A (en) | 2005-11-16 | 2007-06-07 | Fujifilm Corp | Method and device for image classification, and digital camera |
US7663671B2 (en) * | 2005-11-22 | 2010-02-16 | Eastman Kodak Company | Location based image classification with map segmentation |
JP2007179368A (en) * | 2005-12-28 | 2007-07-12 | Mekiki Creates Co Ltd | Image editing support system, apparatus, method and program |
EP1816836A3 (en) * | 2005-12-30 | 2010-01-13 | LG Electronics Inc. | Apparatus and method for managing images of mobile terminal |
JP2007194948A (en) * | 2006-01-19 | 2007-08-02 | Fujifilm Corp | Image-editing device and image-editing program |
US7725451B2 (en) * | 2006-01-23 | 2010-05-25 | Microsoft Corporation | Generating clusters of images for search results |
JP4671235B2 (en) | 2006-01-26 | 2011-04-13 | 田岡化学工業株式会社 | Method for producing fluorene derivative |
KR100641791B1 (en) | 2006-02-14 | 2006-11-02 | (주)올라웍스 | Tagging Method and System for Digital Data |
US20070208776A1 (en) * | 2006-03-06 | 2007-09-06 | Microsoft Corporation | Assignment of metadata |
JP2007316876A (en) | 2006-05-25 | 2007-12-06 | Hitachi Ltd | Document retrieval program |
WO2007146298A2 (en) * | 2006-06-12 | 2007-12-21 | Metacarta, Inc. | Systems and methods for hierarchical organization and presentation of geographic search results |
JP2007334505A (en) | 2006-06-13 | 2007-12-27 | Mitsubishi Electric Corp | Facility retrieval system, and mobile terminal and server to be used for the system |
US7739221B2 (en) * | 2006-06-28 | 2010-06-15 | Microsoft Corporation | Visual and multi-dimensional search |
JP2008033399A (en) | 2006-07-26 | 2008-02-14 | Fujifilm Corp | Information providing system |
US7657504B2 (en) | 2006-10-10 | 2010-02-02 | Microsoft Corporation | User interface for displaying images of sights |
US8037051B2 (en) * | 2006-11-08 | 2011-10-11 | Intertrust Technologies Corporation | Matching and recommending relevant videos and media to individual search engine results |
JP4891740B2 (en) | 2006-11-22 | 2012-03-07 | 株式会社日立製作所 | Content search apparatus and content search method |
US20080118160A1 (en) * | 2006-11-22 | 2008-05-22 | Nokia Corporation | System and method for browsing an image database |
JP2008165303A (en) | 2006-12-27 | 2008-07-17 | Fujifilm Corp | Content registration device, content registration method and content registration program |
JP4672692B2 (en) | 2007-03-14 | 2011-04-20 | 株式会社東芝 | Word recognition system and word recognition program |
US20080268876A1 (en) * | 2007-04-24 | 2008-10-30 | Natasha Gelfand | Method, Device, Mobile Terminal, and Computer Program Product for a Point of Interest Based Scheme for Improving Mobile Visual Searching Functionalities |
US8155399B2 (en) | 2007-06-12 | 2012-04-10 | Utc Fire & Security Corporation | Generic face alignment via boosting |
WO2008152805A1 (en) | 2007-06-14 | 2008-12-18 | Panasonic Corporation | Image recognizing apparatus and image recognizing method |
US20080320036A1 (en) | 2007-06-22 | 2008-12-25 | Winter Gentle E | Automatic data collection |
US7870227B2 (en) * | 2007-07-31 | 2011-01-11 | Yahoo! Inc. | System and method for merging internet protocol address to location data from multiple sources |
US10318110B2 (en) * | 2007-08-13 | 2019-06-11 | Oath Inc. | Location-based visualization of geo-referenced context |
US20080104040A1 (en) * | 2007-09-26 | 2008-05-01 | Ramakrishna Krishnamsetty C | Visually intuitive search method |
US9612126B2 (en) * | 2007-12-03 | 2017-04-04 | Nokia Technologies Oy | Visual travel guide |
US8150098B2 (en) * | 2007-12-20 | 2012-04-03 | Eastman Kodak Company | Grouping images by location |
US8019536B2 (en) * | 2007-12-28 | 2011-09-13 | At&T Intellectual Property I, L.P. | Methods, devices, and computer program products for geo-tagged photographic image augmented GPS navigation |
US7925653B2 (en) * | 2008-02-27 | 2011-04-12 | General Electric Company | Method and system for accessing a group of objects in an electronic document |
US8676001B2 (en) * | 2008-05-12 | 2014-03-18 | Google Inc. | Automatic discovery of popular landmarks |
US20090292685A1 (en) * | 2008-05-22 | 2009-11-26 | Microsoft Corporation | Video search re-ranking via multi-graph propagation |
US8086048B2 (en) * | 2008-05-23 | 2011-12-27 | Yahoo! Inc. | System to compile landmark image search results |
US8126249B2 (en) | 2008-05-30 | 2012-02-28 | Optasia Medical Limited | Methods of and system for detection and tracking of osteoporosis |
US20100076976A1 (en) | 2008-09-06 | 2010-03-25 | Zlatko Manolov Sotirov | Method of Automatically Tagging Image Data |
US8037011B2 (en) | 2008-09-15 | 2011-10-11 | Motorola Mobility, Inc. | Method and apparatus for recommending content items |
US20100205176A1 (en) * | 2009-02-12 | 2010-08-12 | Microsoft Corporation | Discovering City Landmarks from Online Journals |
US8483715B2 (en) | 2009-03-26 | 2013-07-09 | Yahoo! Inc. | Computer based location identification using images |
US8396287B2 (en) | 2009-05-15 | 2013-03-12 | Google Inc. | Landmarks from digital photo collections |
-
2008
- 2008-05-12 US US12/119,359 patent/US8676001B2/en active Active
-
2009
- 2009-05-12 CN CN200980127106.5A patent/CN102089761B/en active Active
- 2009-05-12 KR KR1020107027837A patent/KR101579634B1/en active IP Right Grant
- 2009-05-12 JP JP2011509474A patent/JP5476369B2/en active Active
- 2009-05-12 WO PCT/US2009/002916 patent/WO2009139844A2/en active Application Filing
- 2009-05-12 CN CN201410455635.0A patent/CN104298710B/en active Active
-
2012
- 2012-09-14 US US13/619,652 patent/US9014511B2/en active Active
-
2014
- 2014-02-07 JP JP2014021923A patent/JP5766830B2/en active Active
-
2015
- 2015-04-06 US US14/680,000 patent/US9483500B2/en active Active
-
2016
- 2016-10-03 US US15/284,075 patent/US10289643B2/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1432947A (en) * | 2001-12-29 | 2003-07-30 | Lg电子株式会社 | Multimedia object searchine device and method |
CN1816809A (en) * | 2003-06-30 | 2006-08-09 | 皇家飞利浦电子股份有限公司 | Enhanced organization and retrieval of digital images |
WO2008045704A1 (en) * | 2006-10-10 | 2008-04-17 | Microsoft Corporation | Identifying sight for a location |
WO2008055120A2 (en) * | 2006-10-30 | 2008-05-08 | Seeqpod, Inc. | System and method for summarizing search results |
Non-Patent Citations (1)
Title |
---|
SHANE AHERN等: "World Explorer: Visualizing Aggregate Data from Unstructured Text in Geo-Referenced Collections", 《IEEE JCDL》 * |
Also Published As
Publication number | Publication date |
---|---|
US9483500B2 (en) | 2016-11-01 |
JP2011520208A (en) | 2011-07-14 |
US20150213057A1 (en) | 2015-07-30 |
US20130138685A1 (en) | 2013-05-30 |
JP5766830B2 (en) | 2015-08-19 |
WO2009139844A3 (en) | 2010-04-15 |
US20090279794A1 (en) | 2009-11-12 |
US8676001B2 (en) | 2014-03-18 |
CN104298710B (en) | 2018-05-18 |
US9014511B2 (en) | 2015-04-21 |
KR20110016936A (en) | 2011-02-18 |
JP2014081964A (en) | 2014-05-08 |
WO2009139844A2 (en) | 2009-11-19 |
US20170024415A1 (en) | 2017-01-26 |
CN102089761A (en) | 2011-06-08 |
CN102089761B (en) | 2014-10-15 |
JP5476369B2 (en) | 2014-04-23 |
US10289643B2 (en) | 2019-05-14 |
KR101579634B1 (en) | 2016-01-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN102089761B (en) | Automatic discovery of popular landmarks | |
US8724909B2 (en) | Method and system for generating a pictorial reference database using geographical information | |
US9817895B2 (en) | Associating video content with geographic maps | |
US8873857B2 (en) | Mobile image search and indexing system and method | |
US20080027985A1 (en) | Generating spatial multimedia indices for multimedia corpuses | |
CN101842788A (en) | Method, apparatus and computer program product for performing a visual search using grid-based feature organization | |
Ji et al. | When location meets social multimedia: A survey on vision-based recognition and mining for geo-social multimedia analytics | |
Ivanov et al. | Geotag propagation in social networks based on user trust model | |
EP2377055A1 (en) | Mobile image search and indexing system and method | |
Purificato et al. | Multimedia and geographic data integration for cultural heritage information retrieval | |
Qian et al. | On combining social media and spatial technology for POI cognition and image localization | |
US20110055253A1 (en) | Apparatus and methods for integrated management of spatial/geographic contents | |
Larson et al. | The benchmark as a research catalyst: Charting the progress of geo-prediction for social multimedia | |
GENTILE | Using Flickr geotags to find similar tourism destinations | |
Luberg et al. | Sights, titles and tags: mining a worldwide photo database for sightseeing | |
Girdhar et al. | Mobile Visual Search for Digital Heritage Applications | |
JP6509280B2 (en) | Method and system for providing image search results utilizing model information | |
Papadopoulos et al. | Tourism knowledge discovery in social multimedia | |
KR101702767B1 (en) | System and method for searching document according to access right and type of document using bit | |
Heras et al. | Searching and Mining Large Collections of Geospatial Data (GeoSearch 2023) Nov. 13, 2023, Hamburg, Germany |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
GR01 | Patent grant | ||
GR01 | Patent grant |