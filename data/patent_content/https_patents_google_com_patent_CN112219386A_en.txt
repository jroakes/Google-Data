CN112219386A - Graphic user interface of voice response system - Google Patents
Graphic user interface of voice response system Download PDFInfo
- Publication number
- CN112219386A CN112219386A CN201880094242.8A CN201880094242A CN112219386A CN 112219386 A CN112219386 A CN 112219386A CN 201880094242 A CN201880094242 A CN 201880094242A CN 112219386 A CN112219386 A CN 112219386A
- Authority
- CN
- China
- Prior art keywords
- information
- computing device
- entity
- module
- user interface
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 230000004044 response Effects 0.000 title claims abstract description 99
- 230000002452 interceptive effect Effects 0.000 claims abstract description 49
- 238000004891 communication Methods 0.000 claims description 75
- 238000000034 method Methods 0.000 claims description 69
- 238000010801 machine learning Methods 0.000 claims description 30
- 230000000977 initiatory effect Effects 0.000 claims description 4
- 230000002401 inhibitory effect Effects 0.000 claims 1
- 230000000153 supplemental effect Effects 0.000 description 22
- 230000006870 function Effects 0.000 description 19
- 238000010586 diagram Methods 0.000 description 12
- 230000008569 process Effects 0.000 description 11
- 238000013528 artificial neural network Methods 0.000 description 10
- 230000003993 interaction Effects 0.000 description 9
- 238000012545 processing Methods 0.000 description 9
- 238000005516 engineering process Methods 0.000 description 7
- 238000013507 mapping Methods 0.000 description 6
- 230000008901 benefit Effects 0.000 description 5
- 238000003066 decision tree Methods 0.000 description 5
- 230000003287 optical effect Effects 0.000 description 5
- 230000009471 action Effects 0.000 description 4
- 230000005540 biological transmission Effects 0.000 description 4
- 230000008859 change Effects 0.000 description 4
- 230000033001 locomotion Effects 0.000 description 4
- 230000000306 recurrent effect Effects 0.000 description 4
- 230000001413 cellular effect Effects 0.000 description 3
- 238000013145 classification model Methods 0.000 description 3
- 230000008878 coupling Effects 0.000 description 3
- 238000010168 coupling process Methods 0.000 description 3
- 238000005859 coupling reaction Methods 0.000 description 3
- 230000007774 longterm Effects 0.000 description 3
- 238000004806 packaging method and process Methods 0.000 description 3
- 238000012546 transfer Methods 0.000 description 3
- 238000013473 artificial intelligence Methods 0.000 description 2
- 230000006399 behavior Effects 0.000 description 2
- 239000003795 chemical substances by application Substances 0.000 description 2
- 239000003086 colorant Substances 0.000 description 2
- 238000001514 detection method Methods 0.000 description 2
- 239000000835 fiber Substances 0.000 description 2
- 238000012417 linear regression Methods 0.000 description 2
- 230000011664 signaling Effects 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- WQZGKKKJIJFFOK-GASJEMHNSA-N Glucose Natural products OC[C@H]1OC(O)[C@H](O)[C@@H](O)[C@@H]1O WQZGKKKJIJFFOK-GASJEMHNSA-N 0.000 description 1
- 230000001133 acceleration Effects 0.000 description 1
- 230000003044 adaptive effect Effects 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000037147 athletic performance Effects 0.000 description 1
- 230000002457 bidirectional effect Effects 0.000 description 1
- 238000013527 convolutional neural network Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 238000011982 device technology Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000007613 environmental effect Effects 0.000 description 1
- 239000008103 glucose Substances 0.000 description 1
- 238000009499 grossing Methods 0.000 description 1
- 238000010348 incorporation Methods 0.000 description 1
- 230000001939 inductive effect Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000007477 logistic regression Methods 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 230000000116 mitigating effect Effects 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000003058 natural language processing Methods 0.000 description 1
- 230000001537 neural effect Effects 0.000 description 1
- 230000008520 organization Effects 0.000 description 1
- 230000000737 periodic effect Effects 0.000 description 1
- 238000013139 quantization Methods 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 238000012706 support-vector machine Methods 0.000 description 1
- 230000008093 supporting effect Effects 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
- 238000012795 verification Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M1/00—Substation equipment, e.g. for use by subscribers
- H04M1/72—Mobile telephones; Cordless telephones, i.e. devices for establishing wireless links to base stations without route selection
- H04M1/724—User interfaces specially adapted for cordless or mobile telephones
- H04M1/72403—User interfaces specially adapted for cordless or mobile telephones with means for local support of applications that increase the functionality
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/0482—Interaction with lists of selectable items, e.g. menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q20/00—Payment architectures, schemes or protocols
- G06Q20/30—Payment architectures, schemes or protocols characterised by the use of specific devices or networks
- G06Q20/32—Payment architectures, schemes or protocols characterised by the use of specific devices or networks using wireless devices
- G06Q20/326—Payment applications installed on the mobile devices
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M3/00—Automatic or semi-automatic exchanges
- H04M3/42—Systems providing special services or facilities to subscribers
- H04M3/487—Arrangements for providing information services, e.g. recorded voice services or time announcements
- H04M3/493—Interactive information services, e.g. directory enquiries ; Arrangements therefor, e.g. interactive voice response [IVR] systems or voice portals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/1066—Session management
- H04L65/1101—Session protocols
- H04L65/1104—Session initiation protocol [SIP]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M2203/00—Aspects of automatic or semi-automatic exchanges
- H04M2203/25—Aspects of automatic or semi-automatic exchanges related to user interface aspects of the telephonic communication service
- H04M2203/251—Aspects of automatic or semi-automatic exchanges related to user interface aspects of the telephonic communication service where a voice mode or a visual mode can be used interchangeably
- H04M2203/253—Aspects of automatic or semi-automatic exchanges related to user interface aspects of the telephonic communication service where a voice mode or a visual mode can be used interchangeably where a visual mode is used instead of a voice mode
- H04M2203/254—Aspects of automatic or semi-automatic exchanges related to user interface aspects of the telephonic communication service where a voice mode or a visual mode can be used interchangeably where a visual mode is used instead of a voice mode where the visual mode comprises menus
Abstract
A system is described that includes a mobile device that receives a user request to initiate a telephone call to an entity associated with an Interactive Voice Response (IVR) interface of an IVR system. The system obtains information about a hierarchy of options associated with the interactive voice response system and causes a Graphical User Interface (GUI) for navigating the hierarchy of options associated with the interactive voice response system to be displayed on the mobile device. The system converts the user input associated with the GUI into an input recognized by the IVR system, and the mobile device outputs the converted input to the entity along with other information needed by the entity to perform the input-based operation. In response, the system updates the GUI based on the additional information received from the IVR system.
Description
Background
Many entities (e.g., businesses, governments, etc.) rely on Interactive Voice Response (IVR) systems to handle incoming telephone traffic. The IVR system presents audible prompts to the caller and obtains dial-tone multi-frequency (DTMF) tones ("touch tones"), voice responses, or other user inputs to navigate the caller between nodes of the IVR system. IVR systems typically require a caller to navigate from a standard starting point (e.g., greeting and menu) in the IVR system to a desired destination in the IVR system. A caller may be required to interact with a speech recognition or key entry system for a long period of time to traverse a series of intermediate nodes before eventually reaching a destination node. In some cases, the user may simply want to speak to a person or perform a simple task. However, some IVR systems may challenge performing even the simplest tasks, which may cause the user to be frustrated or universally avoided with the IVR system.
Disclosure of Invention
In general, techniques of this disclosure may be directed to ways of leveraging Graphical User Interfaces (GUIs) and other supporting features to augment existing IVR systems. The example system automatically builds a GUI on top of an IVR system of an entity (e.g., a business enterprise, a non-profit organization, a government office, or any other public or private entity that maintains the IVR system) in which a user may perform various tasks associated with the entity that may be difficult, if not impossible, to perform using the IVR system alone. A computing device (e.g., a mobile phone) may obtain user input to initiate a telephone call with an entity. During a telephone call, the computing device may display a GUI based on a menu hierarchy of the IVR system instead of (or in addition to) presenting an audible interface of the IVR system, but also configured to receive non-voice and non-touch inputs (either as an alternative or in addition to the voice and touch inputs) to perform tasks using the IVR system, as well as other more complex tasks that extend the IVR system functionality and are conducted through the GUI. In some cases, the GUI may interface with other components (e.g., digital assistants, other applications, etc.) executing at the entity or on the computing device, enabling even more complex or user-specific tasks to be performed.
In this way, the techniques of this disclosure may provide a better user experience when interfacing with IVR systems in a manner that takes advantage of the display and other capabilities of modern computing devices to more quickly and better address the needs of a particular user. An example system that relies on a GUI may perform tasks with less input and less time than would be required to perform the number of voice and touch inputs and perform similar tasks using an IVR system alone. In this way, through more efficient interfacing with the IVR system, the described techniques may reduce the duration of calls into the IVR system, thereby freeing up resources of the IVR system and the telecommunications network to handle additional calls or perform other tasks. Advantageously, the IVR system itself may maintain independently functioning functionality, if desired, so that conventional interaction may occur with devices that are not available and/or do not require additional functionality. Accordingly, the techniques of this disclosure may incorporate the advantages of IVR systems while mitigating perceived drawbacks (e.g., inherently presenting options linearly through an audio interface).
Throughout this disclosure, examples are described in which a computing device and/or computing system may analyze information (e.g., context information, user and/or device data, etc.). However, the system can only use the information after the computing device and/or computing system receives explicit permission from the user of the computing device and/or computing system. For example, in the case discussed below where a computing device and/or computing system may collect information about user interactions of a user with an application executing at the computing device or computing system, various users may be provided with an opportunity to provide input to control whether programs or functions of the computing device and/or computing system may collect and utilize the information. The individual users may further be provided with an opportunity to control what the program or function may or may not be able to do with the information.
Further, the collected information may be pre-processed in one or more ways to remove personally identifiable information prior to transmission, storage, or other use of the collected information by the computing device and/or computing system. For example, before the example computing system stores user interaction data associated with an application executing at a computing device, the example computing system may pre-process the data to ensure that any user identification information or device identification information embedded in the data is removed. Thus, the user may control whether information is collected about the user and the user device, and if such information is collected, how the computing device and/or computing system will use such information.
In one example, a method is described, the method comprising: receiving, by a mobile device, a user request to initiate a telephone call to an entity that relies on an interactive voice response system; obtaining information regarding a hierarchy of options associated with the interactive voice response system; outputting, by the mobile device and for display, a graphical user interface for navigating the one hierarchy of options associated with the interactive voice response system; receiving, by a mobile device, one or more user inputs associated with a graphical user interface; converting one or more user inputs associated with the graphical user interface into one or more corresponding inputs recognized by the interactive voice response system; outputting, by the mobile device to the entity, an indication of the one or more corresponding inputs and other information required by the entity to perform the operation in response to the one or more corresponding inputs; in response to outputting the indication of the one or more corresponding inputs and other information, the graphical user interface is updated based on additional information received by the mobile device.
In another example, a computer-readable storage medium is described that includes instructions that, when executed, cause at least one processor to: receiving, by a mobile device, a user request to initiate a telephone call to an entity that relies on an interactive voice response system; obtaining information regarding a hierarchy of options associated with the interactive voice response system; outputting, by the mobile device and for display, a graphical user interface for navigating the one hierarchy of options associated with the interactive voice response system; receiving, by a mobile device, one or more user inputs associated with the graphical user interface; converting one or more user inputs associated with the graphical user interface into one or more corresponding inputs recognized by the interactive voice response system; outputting, by the mobile device to the entity, an indication of the one or more corresponding inputs and other information required by the entity to perform the operation in response to the one or more corresponding inputs; in response to outputting the indication of the one or more corresponding inputs and other information, the graphical user interface is updated based on additional information received by the mobile device.
In another example, a computing system is described that includes at least one processor configured to perform operations comprising: receiving, by a mobile device, a user request to initiate a telephone call to an entity that relies on an interactive voice response system; obtaining information regarding a hierarchy of options associated with the interactive voice response system; outputting, by the mobile device and for display, a graphical user interface for navigating a hierarchy of options associated with the interactive voice response system; receiving, by a mobile device, one or more user inputs associated with the graphical user interface; converting one or more user inputs associated with the graphical user interface into one or more corresponding inputs recognized by the interactive voice response system; outputting, by the mobile device to the entity, an indication of the one or more corresponding inputs and other information required by the entity to perform the operation in response to the one or more corresponding inputs; in response to outputting the indication of the one or more corresponding inputs and other information, the graphical user interface is updated based on additional information received by the mobile device.
In another example, a system is described that includes means for receiving a user request to initiate a telephone call to an entity that relies on an interactive voice response system; means for obtaining information regarding a hierarchy of options associated with the interactive voice response system; means for outputting for display a graphical user interface for navigating options of the one hierarchy associated with the interactive voice response system; means for receiving one or more user inputs related to a graphical user interface; means for converting one or more user inputs associated with the graphical user interface into one or more corresponding inputs recognized by the interactive voice response system; means for outputting to the entity an indication of the one or more corresponding inputs and an indication of other information required by the entity to perform an operation in response to the one or more corresponding inputs; and means for updating the graphical user interface based on the additional information received by the mobile device in response to outputting the indication of the one or more corresponding inputs and other information.
The details of one or more examples are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the disclosure will be apparent from the description and drawings, and from the claims.
Drawings
Fig. 1 is a conceptual diagram illustrating an example system configured to provide an enhanced user interface to an IVR system according to one or more aspects of the present disclosure.
Fig. 2 is a block diagram illustrating an example computing device configured to provide an enhanced user interface to an IVR system in accordance with one or more aspects of the present disclosure.
Fig. 3 is a block diagram illustrating an example computing system configured to provide an enhanced user interface to an IVR system in accordance with one or more aspects of the present disclosure.
Fig. 4 is a block diagram illustrating an example entity system configured to provide an enhanced user interface to an IVR system in accordance with one or more aspects of the present disclosure.
Fig. 5 is a conceptual diagram illustrating an example system configured to provide an enhanced user interface to an IVR system according to one or more aspects of the present disclosure.
Fig. 6 is a flow diagram illustrating example operations performed by an example computing system configured to provide an enhanced user interface to an IVR system according to one or more aspects of the present disclosure.
Detailed Description
Fig. 1 is a conceptual diagram illustrating an example system configured to provide an enhanced user interface to an Interactive Voice Response (IVR) system according to one or more aspects of the present disclosure. The system 100 of fig. 1 includes a computing device 110, an entity system 180, and a computing system 160 communicatively coupled to a network 130. Although operations attributed to system 100 are primarily described as being performed by computing system 160, entity system 180, and computing devices, in some examples, operations of system 100 may be performed by additional or fewer computing devices and systems than shown in fig. 1. For example, entity system 180 and computing device 110 may each include some or all of the functionality of computing system 160, and vice versa.
Network 130 represents any public or private communication network used to transfer data between computing systems, servers, and computing devices. Network 130 may be a Public Switched Telephone Network (PSTN), a wireless network (e.g., cellular, WiFi, and/or other wireless networks), a wired network (e.g., a Local Area Network (LAN), a Wide Area Network (WAN), the internet, etc.), an Internet Protocol (IP) telephone network (e.g., a voice over IP (VoIP) network), or any other type of communications network. Network 130 may include one or more network hubs, network switches, network routers, or any other network devices operatively coupled to each other to provide for the exchange of information between computing system 160, entity system 180, and computing device 110. Computing system 160, entity system 180, and computing device 110 may send and receive data across network 130 using any suitable communication technology.
The computing system 160 includes a telephony GUI module 162 and the entity system 180 includes an IVR system 182. Computing device 110 includes a User Interface (UI) module 120, a phone module 122, and further includes a User Interface Component (UIC)112 configured to output a user interface 114. Modules 120, 122, 162, and 182 may perform operations described herein using software, hardware, firmware, or a mixture of hardware, software, and firmware executing in and/or in one of computing device 110, computing system 160, and entity system 180. Computing device 110, computing system 160, and entity system 180 may use the plurality of processors or the plurality of device execution modules 120, 122, 162, and 182 as virtual machines executing on underlying hardware, as one or more services of an operating system or computing platform, and/or as one or more executable programs on an application layer of the computing platform. In some examples, computing device 110, computing system 160, and entity system 180 may download any of modules 120, 122, 162, and 182 from an application store (e.g., an application store) or other database. In some examples, computing device 110, computing system 160, and entity system 180 are preloaded with modules 120, 122, 162, and 182 during production and before being provided to a user.
Although computing system 160 is shown in fig. 1 as including phone GUI module 162, entity system 180 includes IVR system 182, and computing device 110 includes UIC112, UI module 120, and phone module 122, modules 120, 122, 162, and 182 and their functionality may be distributed differently among computing device 110, computing system 160, and entity system 180. As one example, in some cases, entity system 180 or computing device 110 may include all or part of the functionality of phone GUI module 162.
The UIC112 of the computing device 110 may serve as an input and/or output device for the computing device 110. UIC112 may be implemented using various techniques. For example, UIC112 may function as an input device using a presence-sensitive input screen, microphone technology, infrared sensor technology, or other input device for receiving user input. UIC112 may serve as an output device configured to present output to a user using any one or more of a display device, speaker technology, haptic feedback technology, or other output device technology for outputting information to a user. UIC112 may be used by computing device 110 to output a GUI (e.g., user interface 114) for display.
In some examples, UI module 120 may receive an indication of one or more user inputs detected at UIC112 and may output information regarding the user inputs to phone module 122 or any other application or component of computing device 110 that expects the user inputs. For example, UIC112 may detect user input and send data regarding the user input to UI module 120. UI module 120 may generate one or more touch events based on the detected input. The touch event may include information characterizing the user input, such as a location component (e.g., x, y coordinates) of the user input, a time component (e.g., when the user input is received), a force component (e.g., an amount of pressure applied by the user input), or other data related to the user input (e.g., velocity, acceleration, direction, density, etc.). Based on the location information of the touch events generated from the user input, UI module 120 may determine that the detected user input is associated with telephony module 122 and may send an indication of the one or more touch events to telephony module 122 for further interpretation.
The IVR system 182 of the entity system 180 provides interactive phone menu functionality to the entity system 180. In other words, the IVR system 182 may handle incoming telephone call traffic from (at least among) external devices (e.g., computing device 110) into the entity system 180. The IVR system 182 may include multiple nodes corresponding to different operations, functions, or modes of the entity system 180. The IVR system 182 provides an interface to connect human customers of the entity system 180 with people or systems (e.g., voice message systems) associated with the entity system 180. A human customer or other user of the IVR system 182 may interact with the IVR system 182 via a telephone call to navigate an interactive menu of the IVR system 182. For example, when placing a telephone call from computing device 110 to entity system 180, a user of computing device 110 may provide various voice responses or DTMF tones (sometimes referred to as "touch tones") to computing device 110, which are transmitted to entity system 180 via network 130. The entity system 180 may use voice responses or DTMF tones as inputs to the IVR system 182 to transition the IVR system 182 from one node to the next until the IVR system 182 reaches the destination node. At the destination node, the IVR system 182 may perform some operation or connect the user to an operator such as a human or machine (e.g., a robotic, assisted, or other Artificial Intelligence (AI) -based operator).
The phone module 122 is a component of the computing device 110 for handling phone functionality of the computing device 110. For example, the phone module 122 may be an application or component of a computing platform or operating system of the computing device 110. The phone module 122 may perform outgoing call operations, for example, by initiating a phone call with an external device such as the entity system 180. The phone module 122 may also process incoming phone calls, for example, by performing operations to accept and support phone calls between the computing device 110 and external devices. The phone module 122 may also perform operations to facilitate existing phone calls, such as by merging calls, placing calls on hold, accepting, rejecting, or forwarding calls, and other phone related operations.
Generally, the telephony GUI module 162 of the computing system 160 interacts with the entity system 180 and the computing device 110 to cause the telephony module 122 to present the user interface 114, i.e., an enhanced GUI associated with the IVR system 182. In some examples, the telephony GUI module 162 provides services to one or more entity subscribers, such as the entity system 180, where each client invoked to a particular entity subscriber is provided with an automatically generated GUI associated with the particular entity subscriber's existing IVR system. By having a computing device, such as computing device 110, generate a supplemental IVR system GUI, such as user interface 114 or other similar GUI, telephony GUI module 162 may enable computing device 110 and other clients of entity system 180 to perform various tasks associated with entity system 180 that may be difficult, if not impossible, to perform using IVR system 182 alone. The phone GUI module 162 may analyze information about the input detected at the user interface 114 and share the information with the entity system 180 for further processing. The phone GUI module 162 may analyze the information obtained from the IVR system 182 and the entity system 180 and use the information to cause the computing device 110 to update or change the user interface 114. In this manner, the telephony GUI module 162 may enable the computing device 110 to provide a better user experience when the user interacts with the IVR system 182 in a manner that utilizes the UIC112 and other functionality of the computing device 110 to more quickly and better address the needs of a particular user.
In operation, the computing device 110 may receive a user request to initiate a telephone call to the IVR system 182. For example, the user may provide input to the UIC112 that is interpreted by the telephony module 122 as a command to establish a telecommunications session over the network 130 through the IVR system 182.
Before or during the telephone call, the telephony GUI module 162 may obtain information regarding one of the hierarchically structured options associated with the interactive voice response interface of the IVR system 182. For example, the phone GUI module 162 may interact 180 with the entity system to determine a list of options, prompts, or inputs associated with the IVR system 182 that link options from one level to the next level, as well as other information associated with the IVR system 182. Further, the phone GUI module 162 may obtain information about the IVR system 182 and the entity system 180, such as the entity's hours of operation, days of operation, wait time, or availability of operators associated with different nodes of the IVR system 182, and so forth.
The phone GUI module may create a mapping to the interfaces of the IVR system 182 and then rely on the mapping to build the user interface 114. For example, the telephony GUI module 162 may make a series of calls to different destination nodes within the IVR system 182 to traverse various different possible paths between the nodes of the IVR system 182, and may record the hierarchical relationships between the nodes, the prompts occurring at each node, and the voice or touch-tone responses used to proceed to the different nodes. That is, the phone GUI module 162 may be connected to the IVR system 182 through a communication network, such as the network 130. The phone GUI module 162 may process information obtained from the IVR system 182 (e.g., audio, IMS data, CS data, SIP signaling data, or other similar telecommunications information including signals used to generate the enhanced GUI of the IVR system 182). The phone GUI module 162 may interpret the information obtained from the IVR system 182 as text or graphical representations into the build user interface 114, for example, using speech recognition, machine learning, or other speech/data processing techniques.
In some examples, the entity system 180 may provide information about the IVR system 182 to the phone GUI module 162 as a requirement to subscribe to GUI generation services of the phone GUI module 162. For example, the IVR system 182 may send an indication of the mapping of the IVR system 182 to the computing system 160 via the network 130.
The IVR system 182 may exchange information between the entity system 180 and the computing system 160 over one or more communication channels established within the network 130. In some cases, a single communication channel between entity system 180 and computing system 160 is used to implement the telephone call and send additional information that can be used by telephone GUI module 162 to generate user interface 114. Sometimes, a dedicated telephone channel and a different data channel between entity system 180 and computing system 160 are used. For example, the computing system 160 and the entity system 180 may connect over the internet or via a dedicated data channel established between the computing system 160 and the entity system 180 to exchange data to generate a GUI for the IVR system 182.
The phone GUI module 162 may refresh or update information about the IVR system 182 over time when changes to the IVR system 182 are detected and/or in response to receiving updated information from the IVR system 182 to alert the computing system 160 of the changes. The phone GUI module 162 may perform periodic or occasional mapping verification operations, for example, by reconnecting with the IVR system 182 and reissuing previously used commands to determine whether a different command is needed to reach the node currently mapped to the previous command. For example, for each node, the telephony GUI module 162 may compare information obtained from the IVR system 182 at each node with desired information maintained by the telephony GUI module 162. The phone GUI module 162 may, for example, use voice recognition, machine learning, or other voice/data processing techniques to determine whether the user interface 114 needs updating based on information obtained from the IVR system 182, and if so, how to update the user interface 114 based on the updated information.
In operation, in continuing the previous example, prior to or during the telephone call established between the computing device 110 and the IVR system 182, the telephony GUI module 162 may send information to the telephony module 122 that causes the UIC112 to display the user interface 114. In other words, in response to a user request to initiate a telephone call to the IVR system 182, the telephone module 122 or the IVR system 182 may alert the telephony GUI module 162 regarding the telephone call and trigger the telephony GUI module 162 to send display instructions or other information required by the telephone module 122 to output the user interface 114 to the telephone module 122 for display. Based on the display instructions from the telephony GUI module 162, the computing device 110 may output for display a user interface 114 for navigating one of the hierarchy options associated with the interactive voice response interface of the IVR system 182. For example, phone module 122 may interpret display instructions or other information obtained from phone GUI module 162 to send commands to UI module 120 to cause UIC112 to display user interface 114.
As shown in the example of FIG. 1, the user interface 114 includes various graphical indications of the nodes of the IVR system 182. For example, the user interface 114 includes respective graphical indications of an account setup node, an account status node, a new order node, a payment node, a speaking representative node, a request call back node, and a more options or search node. Other types of nodes may exist and many different graphical representations of these nodes are possible. The user interface 114 may include text, images, graphics, video, audio, or other features associated with each graphical representation of each node.
The computing device 110 may receive one or more user inputs associated with the user interface 114. For example, a user may provide touch or gesture input or voice input detected by the UIC112 at or near the location where the UIC112 displays the graphical representation of the talking representative node. UI module 120 may recognize the input and send information related to the input to phone module 122 for interpretation with respect to user interface 114.
The computing device 110 may convert one or more user inputs associated with the user interface 114 into one or more corresponding inputs associated with the IVR system 182. For example, using information provided by the phone GUI module 162 to render the user interface 114 on the computing device 110, the phone module 122 may map user input to functions or commands recognizable to the IVR system 182 to take appropriate action based on the user input. For example, the telephony module 122 may determine a touch tone, voice prompt, SIP signal, circuit switched command, or other command that will cause the IVR system 182 to connect the computing device 110 to the appropriate IVR system node.
The computing device 110 may output an indication of the one or more corresponding inputs to the entity via a telecommunication session established to effectuate the telephone call. For example, the telephony module 122 may communicate the corresponding input determined by the telephony module 122 to the IVR system 182 to cause the IVR system 182 to connect the computing device 110 with an appropriate node of the IVR system 182 (e.g., a node of the carrier that transfers the caller to the entity system 180). For example, the telephony module 122 may send the determined touch tone, voice prompt, SIP signal, CS command, or other command to the IVR system 182 that causes the IVR system 182 to connect the established telephone call between the computing device 110 and the IVR system 182 to the appropriate IVR system node.
The computing device 110 may receive additional information regarding one of the hierarchical options associated with the interactive voice response interface and the update user interface 114 based on the additional information. For example, the telephony GUI module 162 and the telephony module 122 may not have information about the current latency associated with the IVR system 182 until user input is detected at the speech representational graphical representation of the user interface 114. In some examples, the telephony module 122 may determine a current latency associated with the selected node of the IVR system 182 as the additional information via a SIP signal extracted from IMS data associated with the telephone call between the computing device 110 and the entity system 180. In some examples, an assistant service accessible to computing device 110 may determine the wait time based on observations of the wait time of other users of IVR system 182 or other similar systems. In any event, the telephony module 122 may determine the current latency associated with the selected node of the IVR system 182 as additional information. The telephony module 122 can cause the UI module 120 and UIC112 to update the user interface 114 to reflect the current wait time and alternate node options (e.g., callback options) of the IVR system 182. The UIC112 may output a graphical representation of the latency and the alternate nodes as part of the user interface 114, and the user of the computing device 110 may continue interaction with the IVR system 182 by providing additional input to the user interface 114, e.g., placed to hold a request to terminate a telephone call on behalf of speaking or to call back with the IVR system 182 when the current latency is less than a time threshold (e.g., zero or more minutes, seconds, etc.).
As such, depending on the described techniques of this disclosure, the system may provide a GUI generation service through which the system may perform IVR-related tasks based on fewer user inputs or less time as compared to the number and time of speech and key inputs required to perform similar tasks using traditional user interfaces of other IVR systems. As such, the described techniques may reduce the duration or number of incoming communications received by the IVR system, with the potential to free up resources of the IVR system and the communication network used to communicate with the IVR system, thereby enabling the IVR system and the communication network to handle additional calls or perform other tasks that otherwise cannot be accomplished.
In some examples, the system may implement more reliable business calls depending on the described techniques of this disclosure. That is, because interaction with an IVR system may require complex inputs, such as multi-digit DTMF inputs (e.g., entering a credit card number, etc.), the described techniques may reduce inaccurate inputs, as they may enable the IVR system to provide a more intuitive interface that is less likely to receive incorrect inputs, and the user may intuitively verify the accuracy of their inputs before submitting them to the IVR system. Furthermore, it may be more secure to provide such information via a GUI interface rather than via voice prompts.
In some examples, depending on the described techniques of this disclosure, the system may not need to first attempt to identify the input language (e.g., english, spanish, etc.) before providing the enhanced GUI. That is, using enhanced SIP signals as described herein, the IVR system may identify the preferred language of the user based on SIP signals received from the user device indicating its language preference, thus avoiding providing welcome statements in multiple languages.
FIG. 2 is a block diagram illustrating an example computing device configured to provide an enhanced user interface to an interactive voice response system in accordance with one or more aspects of the present disclosure. Fig. 2 is described in the context of fig. 1. For example, computing device 210 of fig. 2 is an example of computing device 110 of fig. 1. Fig. 2 shows only one particular example of computing device 210, and many other examples of computing device 210 may be used in other instances and may include a subset of the components included in example computing device 210, or may include additional components not shown in fig. 2.
As shown in the example of fig. 2, computing device 210 includes User Interface Component (UIC)212, one or more processors 240, one or more communication units 242, one or more input components 244, one or more output components 246, and one or more storage components 248. UIC212 includes output component 202 and input component 204. The storage components 248 of the computing device 210 include the UI module 220, the assistance module 224, the context module 228, and the telephony module 222. The telephony module 22 includes a telephony channel interface 223A and a supplemental data channel interface 223B.
One or more communication units 242 of computing device 210 may communicate with external devices via one or more wired and/or wireless networks by sending and/or receiving network signals over one or more networks. Examples of communication unit 242 include a network interface card (e.g., such as an ethernet card), an optical transceiver, a radio frequency transceiver, a GPS receiver, or any other type of telecommunication device that can send and/or receive information over a network, such as network 130 of fig. 1. Other examples of communication units 242 may include short wave radios, cellular voice or data radios, wireless network radios, as well as Universal Serial Bus (USB) controllers, VoIP-type, IMS-type, and CS-type telephone transceivers, and other telephone devices.
One or more input components 244 of computing device 210 may receive input. Examples of inputs are tactile, audio and video inputs. In one example, input component 242 of computing device 210 includes a presence-sensitive input device (e.g., touch screen, PSD), mouse, keyboard, voice response system, camera, microphone, or any other type of device for detecting human or machine input. In some examples, input components 242 may include one or more sensor components, one or more location sensors (GPS components, Wi-Fi components, cellular components), one or more temperature sensors, one or more motion sensors (e.g., accelerometers, gyroscopes), one or more pressure sensors (e.g., barometers), one or more ambient light sensors, and one or more other sensors (e.g., microphones, cameras, infrared proximity sensors, hygrometers, etc.). Other sensors may include heart rate sensors, magnetometers, glucose sensors, hygrometer sensors, olfactory sensors, compass sensors, step counter sensors, to name a few other non-limiting examples.
One or more output components 246 of the computing device 110 may generate output. Examples of outputs are tactile, audio and video outputs. In one example, output components 246 of computing device 210 include a PSD, sound card, video graphics adapter card, speaker, Cathode Ray Tube (CRT) monitor, Liquid Crystal Display (LCD), or any other type of device for generating output to a person or machine.
UIC212 of computing device 210 may be similar to UIC112 of computing device 110 and include output component 202 and input component 204. Output component 202 can be a display component, such as a screen on which information is displayed by UIC212 and input component 204 can be a presence-sensitive input component, such as a touch of a capacitive sensor, that detects an object at and/or near output component 202. Output component 202 and input component 204 may be speaker and microphone pairs or any other combination of one or more input and output components (e.g., input component 244 and output component 244). In the example of fig. 2, UIC212 may present a user interface (such as user interface 114 of fig. 1).
As one example range, presence-sensitive input component 204 may detect objects within two inches or less of output component 202, such as one or more fingers, a stylus, or one or more other input units. The input component 204 can determine the location (e.g., [ x, y ] coordinates) of the output component 202 where the object was detected. In another example range, the input component 204 may detect an object that is six inches or no more than six inches from the output component 202, and other ranges are possible. The input component 204 may determine the position of the output component 202 selected by the user's finger using capacitive, inductive, and/or optical recognition techniques. In some examples, the input component 204 also provides output to the user using tactile, auditory, or visual stimuli as described for the output component 202.
UIC212 of computing device 210 may detect a two-dimensional and/or three-dimensional gesture as input from a user of computing device 210. For example, a sensor of UIC212 may detect a motion of the user (e.g., moving one or more hands, arms, fingers, other body parts, a pen, a stylus, etc.) within a threshold distance of the sensor of UIC 212. UIC212 may determine a two-dimensional or three-dimensional vector representation of motion and relate the vector representation to gesture input having multiple dimensions (e.g., a hand wave, a pinch, a clap, a brush stroke, etc.). In other words, the UIC212 may detect multi-dimensional gestures without requiring the user to make gestures at or near the screen or surface on which the UIC212 outputs information for display. Alternatively, the UIC212 may detect multi-dimensional gestures performed at or near a sensor that may or may not be located near a screen or surface on which the UIC212 outputs information for display.
While shown as an internal component of computing device 210, UIC212 may also represent an external component that shares a data path with computing device 210 to send and/or receive input and output. For example, UIC212, in one example, represents a built-in component of computing device 210 that is located within an external packaging of computing device 210 and physically connected to the external packaging of computing device 210 (e.g., a screen on a mobile phone). In another example, UIC212 represents an external component of computing device 210 (e.g., a monitor, projector, etc., which shares a wired and/or wireless data path with computing device 210) that is located outside of and physically separate from the packaging or housing of computing device 210.
One or more storage components 248 within computing device 210 may store information that is processed during operation of computing device 210 (e.g., computing device 210 may store data that is accessed by modules 220, 222, 224, and 226 and operating platform 228 during execution by computing device 210). In some examples, storage component 248 is a temporary memory, meaning that the primary purpose of storage component 248 is not long-term storage. Storage component 248 on computing device 210 may be configured for short-term storage of information as volatile memory and therefore does not retain stored content if power is removed. Examples of volatile memory include Random Access Memory (RAM), Dynamic Random Access Memory (DRAM), Static Random Access Memory (SRAM), and other forms of volatile memory known in the art.
In some examples, storage component 248 also includes one or more computer-readable storage media. In some examples, storage component 248 includes one or more non-transitory computer-readable storage media. Storage component 248 may be configured to store a greater amount of information than is typically stored by volatile memory. Storage component 248 may be further configured to store information as non-volatile storage space for long periods of time and retain information after power on/off cycles. Examples of non-volatile memory include magnetic hard disks, optical disks, floppy disks, flash memory, or forms of electrically programmable memory (EPROM) or electrically erasable and programmable memory (EEPROM). Storage component 248 may store program instructions and/or information (e.g., data) associated with modules 220, 222, 224, and 226. Storage component 248 may include a memory configured to store data or other information associated with notification queue 232, modules 220, 222, 224, and 226.
The one or more processors 240 may implement the functions and/or execute instructions associated with the computing device 210. Examples of processor 240 include an application processor, a display controller, an auxiliary processor, one or more sensor hubs, and any other hardware configured to function as a processor, processing unit, or processing device. Modules 220, 222, 224, and 226 may be operated by processor 240 to perform various actions, operations, or functions of computing device 210. For example, processor 240 of computing device 210 may retrieve and execute instructions stored by storage component 248 that cause processor 240 to perform the operations described herein due to modules 220, 222, 224, and 226. The instructions, when executed by the processor 240, may cause the computing device 210 to store information within the storage component 248.
The assistance module 224 and the context module 226 are components of the computing device 210 that are configured to collect and provide additional information to the telephony module 222 to enable the telephony module 222 to provide an enhanced GUI experience for an IVR system, such as the IVR system 182 of fig. 1. Other components of computing device 210, such as computing system 160 and entity system 180 of fig. 1, as well as other external devices or systems, may similarly obtain additional information from assistance module 224 and context module 226 to support enhanced GUI services, e.g., similar to the services provided by system 100 of fig. 1. The assistance module 224 outputs information obtained about the computing device 110 or the user of the computing device 110 through interaction with the user and assistance services provided by the assistance module 224, and the context module 226 outputs context information associated with the computing device 110 or the user of the computing device 110.
The term "contextual information" as used throughout this disclosure refers to any possible information that may be used by a computing system and/or computing device (such as computing device 210) to provide enhanced GUI services during a telephone call to an IVR system. The context information may include: device location and/or sensory information, user topics of interest (e.g., "things" that a user likes, which are typically maintained as a user interest graph or some other type of data structure), contact information associated with the user (e.g., personal contact information of the user and information about friends, colleagues, social media connections, family, etc. of the user), search history, location history, long-term and short-term tasks, calendar information, application usage history, purchase history, items tagged as favorites, electronic bookmarks, and other information that computing device 210 may collect about the user of computing device 210 from interactions with computing device 210.
Further, the context information may include information about the operational state of the computing device. For example, an application executing at a given time or at a particular location is an example of information about the operational state of a computing device. Other examples of contextual information indicative of the operational state of the computing device include, but are not limited to, the position of a switch, the battery level, whether the device is plugged into a wall outlet or otherwise operatively coupled to another device and/or machine, user authentication information (e.g., which user is currently authenticating or is the current user of the device), whether the device is operating in an "airplane" mode, a standby mode, a full power mode, the operational state of the radio, a communication unit, input devices and output devices, and so forth.
In contrast to "context information," the term "context" refers to a particular state of each feature from a set of features associated with a computing device and/or a user of the computing device at a particular time. The context may indicate characteristics associated with the physical and/or virtual environment of the user and/or computing device at a particular location and/or time. As some examples, the context of the computing device may specify acoustic fingerprints, video fingerprints, locations, movement trajectories, directions, speeds, place names, street addresses, place types, buildings, weather conditions and traffic conditions at different locations and times. As some other examples, the context of the computing device may specify a calendar event, meeting, or other event associated with a location or time.
In some examples, the context of the computing device may specify any web page addresses accessed at a particular time, one or more text entries made in data fields of the web page at a particular time, including search or browsing history, product purchases made at a particular time, product wish lists, product registries, and other application usage data associated with various locations and times. The context of the computing device may further specify audio and/or video accessed or broadcast at various locations and times in the presence of the computing device, television or cable/satellite broadcasts accessed or broadcast at various locations and times in the presence of the computing device, and information about other services accessed by the computing device at various locations and times.
When collecting, storing, and using contextual information or any other user or device data, the computing device 210 takes precautionary measures to ensure that user privacy is preserved. That is, the computing device 210 may only collect, store, and analyze context information if the computing device 210 receives explicit permission from various users from whom the context information originates. For example, where the computing device 210 may collect information to provide an enhanced GUI experience for an IVR system, a user of the computing device 210 may be provided with an opportunity to provide input to the computing device 210 to control whether the computing device 210 may collect and utilize their information. The various users may further be provided with an opportunity to control what computing device 210 may or may not use the information to do.
Any data collected by computing device 210 may be pre-processed in one or more ways to remove personally identifiable information before being transmitted to computing device 210 for storage or other use by computing device 210. For example, prior to the computing device 210 collecting the context information, the computing device 210 may pre-process the context information to ensure that any user identification information or device identification information embedded in the context information is removed prior to being stored or transferred by the computing device 210 to an external computing device or system. The user may have full control over whether context information is collected and, if so, how the computing device 210 uses this information.
The assistance module 224 enables the computing device 210 to receive natural language input (e.g., dialog) via the computing device 210 to perform "real world" tasks. The assistance module 224 may be programmed or may adapt over time to learn how and to accomplish specific tasks, such as scheduling certain types of appointments. For such tasks, the assistance module 224 performs natural language processing techniques of user input (e.g., speaking, typing, etc.) to make the user experience as natural as possible, allowing the user to type or speak speech as normal to others without having to adapt their language to that of the machine.
The phone module 222 may include all of the functionality of the phone module 122 of the computing device 110 of fig. 1 and may perform similar operations as the phone module 122 to handle the phone functionality of the computing device 210. As part of handling the telephony functionality, the telephony module 222 may communicate with external systems and devices, such as the computing system 160 and the entity system 180, to provide an IVR system, such as the IVR system 182, with a GUI for interaction. The telephony module 222 may communicate with the UI module 220, the assistance module 224, and the context module 226 to provide a GUI for interacting with the IVR system.
The telephony module 222 is configured to enable the computing device 210 to interact with telephony services provided over a telecommunications network, such as the network 130 (e.g., a CS network, an IP packet-switched network, etc.). Additionally or alternatively, the phone module 222 is configured to enable the computing device 210 to interact with telephony services provided over the internet according to one or more public or private communication protocols and standards. The phone module 222 may initiate and receive phone calls on behalf of the computing device 210. For example, the telephony module 222 can interact with a communications unit 242 that exchanges telephony information over the network 130.
The telephony module 222 includes a telephony channel interface 223A and, in some examples, a supplemental data channel interface 223B. The telephony channel interface 223A and the supplemental data channel interface 223B are collectively referred to as "interfaces 223" such that the telephony module 222 can communicate information to external entities, such as the entity system 180.
The phone module 222 may exchange voice call information using the phone channel interface 223A to enable the computing device 210 to make digital phone calls with external entities. For example, the phone module 222 may encode, decode, interpret, and perform operations during a digital telephone call between the computing device 210 and an external entity in response to one or more commands or signals embedded in a voice data stream exchanged between the computing device 210 and an external entity, such as the entity system 180. The phone module 222 may process the voice call data stream in accordance with IMS and SIP, VoIP, or other telecommunications protocols. The telephone module 222 may send DTMF codes, spoken responses, IMS and SIP messaging, or other inputs to the DTR system 182 using the telephone channel interface 223A.
In some cases, in addition to the telephony channel interface 223A, the telephony module 222 may also include a supplemental data channel interface 223B to exchange information with other computing systems in addition to the type of information that has been received via the telephony channel interface 223A to facilitate IVR system GUI services. Examples of other information may include: contextual information, payment or transaction information, user information, information about the computing device 210, and other types of information. Rather than sending DTMF codes, voice responses, or other inputs to the IVR system 182 that have been sent by the telephony module 222 using interface 223A, the telephony module 222 may send information using the supplemental data channel interface 223B. By way of example, the telephony module 222 may exchange information with the IVR system 182 that enables the IVR system 182 to perform operations outside of the capabilities typical of IVR systems 182. For example, operations are required that convey more information than can be exchanged using DTMF codes or IMS and SIP messaging.
In some examples, a telephone survey may benefit from the techniques of this disclosure. That is, in a telephone survey, the IVR system may contact the user's mobile device and typically ask the user to "use your touch keypad to provide answers to questions in which a negative response is pressed by '0' and a positive response is pressed by '1', or the IVR system may prompt the user to enter" satisfaction "in which" 0 "is highly unsatisfactory," 1 "is largely unsatisfactory," 2 "is of no concern," 3 "is somewhat satisfactory, and" 4 "is highly satisfactory. Prompting the user one after another for each question may result in a long, boring, and time-consuming survey. However, the techniques of this disclosure may enable a mobile phone to automatically provide GUI-based surveys to improve user experience and make collecting survey responses more efficient.
The telephony module 222 may obtain other information from the computing system 160, the entity system 180, or other devices or systems of the IVR system GUI service provider. The telephony module 222 may output other information to the computing system 160, the entity system 180, or other devices or systems of the IVR system GUI service provider. The telephony module 222 may obtain from the module 224 and/or the module 226 or share with the module 224 and/or the module 226 a portion of other information that the telephony module 222 exchanges with other devices or systems of the computing system 160, the entity system 180, or the IVR system GUI service provider. For example, the phone module 222 may send the aiding generated information obtained from the aiding module 224 to the computing system 160 or the entity system 180. In some cases, the phone module 222 may send the context information collected by the context module 226 to the computing system 160 or the entity system 180.
FIG. 3 is a block diagram illustrating an example computing system configured to provide an enhanced user interface to an interactive voice response system in accordance with one or more aspects of the present disclosure. Fig. 3 is described in the context of fig. 1. For example, computing system 360 of fig. 3 is an example of computing system 160 of fig. 1. Fig. 3 shows only one particular example of computing system 160, and many other examples of computing system 160 may be used in other instances and may include a subset of the components included in example computing system 160, or may include additional components not shown in fig. 3.
The one or more memory components 376 include a phone GUI module 362, a communications module 366, and an optional assistance module 364. The phone GUI module 362 includes a GUI control module 365, the GUI control module 365 including a Machine Learning (ML) model 367. The communication module 366 includes a telephony channel interface 323A and a supplemental data channel interface 323B.
The communication module 366 is configured to control the communication unit 372 to manage one or more network communication interfaces of the computing system 360. The communication module 366 includes a telephony channel interface 323A and optionally a supplemental data channel interface 323B (collectively "interfaces 323").
Interface 323 is similar to interface 223 of phone module 222 of computing device 210. That is, the communication module 366 may transmit and/or receive telephone information via the telephone channel interface 323A. The communication module 366 can send and/or receive other information via the supplemental data channel interface 323B. The communication module 366 may exchange (transmit and/or receive) information via the interface 323 on behalf of the assistance module 364 and the telephony GUI module 362 as part of the services provided by the telephony GUI module 362.
The phone GUI module 362 manages network-accessible IVR system GUI services. The phone GUI module 362 is similar to and may include at least some of the same functionality as the phone GUI module 162 of the computing system 160. That is, the telephony GUI module 362 can interact with the communication module 366 and the communication unit 372 to communicate with external entities (e.g., entity system 180) and external devices (e.g., computing devices 110, 210) to facilitate an enhanced GUI experience at the external devices when the external devices call the external entities' IVR systems.
The GUI control module 365 of the telephony GUI module 362 outputs instructions for generating an IVR system GUI at a computing device, such as computing devices 110, 210. The GUI control module 365 may generate instructions based on information received from the communication module 366 and/or the assistance module 364. For example, the GUI control module 365 may observe IMS data obtained via the telephony channel interface 323A. The IMS data may be part of an IMS data flow that occurs during a telephone call between subscribing entities and/or computing devices. The GUI control module 365 may include one or more rules or filters for identifying SIP signals within the IMS data that, when identified, may cause changes or updates to the information contained in the IVR system GUI.
The GUI control module 365 may obtain additional information about a user of a computing device, such as the computing devices 110, 210, in order to generate instructions for producing an IVR system GUI at the computing device. Under the express permission of the user associated with the additional information, GUI control module 365 may cause phone GUI module 362 to share the additional information with a subscribing entity system, such as entity system 180, to enable the entity system to perform operations that would otherwise not be possible, at least not more difficult, without the additional information. Where computing system 360 includes assistance module 364, GUI control module 365 can communicate with assistance module 364 to obtain at least some additional information about the computing device. In some cases, GUI control module 365 interfaces with external entities and computing devices to obtain additional information about the computing devices. For example, the GUI control module 365 may communicate with the IVR system 182 of the entity system 180 and/or the phone modules 122, 222 of the computing devices 110, 210 to obtain additional information about the user's computing device.
The GUI control module 365 may obtain additional information about the entity systems or IVR systems, such as the entity system 180 and the IVR system 182, to generate instructions at the user's computer for producing an IVR system GUI associated with the IVR system. The GUI control module 365 may cause the telephony GUI module 362 to share additional information with computing devices, such as the computing devices 110, 210, to enable the computing devices to update or change information presented in the IVR system GUI. Where computing system 360 includes assistance module 364, GUI control module 365 can communicate with assistance module 364 to obtain at least some additional information about the computing device. In some cases, the GUI control module 365 interfaces with external entities and computing devices to obtain additional information about the subscribing entity. For example, the GUI control module 365 may communicate with the IVR system 182 of the entity system 180 and/or the telephony module 122, 222 of the computing device 110, 210 to obtain additional information about the IVR system 182.
In some examples, the additional information collected by the GUI control module 365 about the entity system or the IVR system includes status information associated with various nodes of the IVR system, including: expected wait time for connecting to a node, average wait time for connecting to a node, actual wait time for waiting to connect to a node, account status information of a caller, order delivery information, cost of items or services, and availability information, among others. In some examples, just like dynamic state information, the additional information may include static information, such as directory information, technical support recommendations, and other types of additional information that may or may not change over time. In addition to obtaining additional information about the user or entity's IVR system of the computing device, the GUI control module 365 can also make predictions about the user or IVR system.
The Machine Learning (ML) model 367 is a machine learning model that is trained based on past telephone calls between one or more computing devices, such as computing devices 110, 210 and other devices, and one or more IVR systems, including IVR system 182 and other IVR systems, to make predictions about the user and the IVR system. In some embodiments, ML model 367 is trained to receive one or more types of input data, and in response, to provide one or more types of output data. Examples of input data and corresponding output data include previously observed latencies for traversing a portion of an IVR system node, and corresponding rules for deriving expected latencies for future traversals of a given context. Another example of input data and corresponding output data includes, for a given context, previously traversed paths through the nodes of the IVR system, and corresponding procedures that predict future paths through the various nodes of the IVR system.
In any case, the input data may include one or more characteristics associated with the instance, context, or illustration. Given the features associated with a particular instance, context, for example, ML model 367 may output a prediction of the instance, context, or example. For example, based on previously observed telephone calls to the IVR system, the ML model 367 may determine characteristics of the previously observed telephone calls, context information about the device used to make the previous telephone calls, etc., and generate rules for predicting what may happen during future telephone calls to the IVR system given similar context.
The ML model 367 can be or include one or more of a variety of different types of machine learning models. In particular, in some embodiments, ML model 367 may perform classification, regression, clustering, anomaly detection, recommendation generation, and/or other tasks. Examples of different types of machine learning models include: classifier models, such as linear classification models; secondary classification models and regression models, such as simple linear regression models; a multivariate linear regression model; a logistic regression model; a stepwise regression model; a multivariate adaptive regression spline; locally estimated scatter plot smoothing models, and the like. Other types of models include decision tree based models, such as classification and/or regression trees; iteration dichotomy 3 decision tree; c4.5 decision tree; the chi-square automatic interaction detection decision tree; making a decision on a stump; conditional decision trees, etc.; kernel machines, support vector machines, and instance-based learning models, such as learning vector quantization models; a self-organizing map model; local weighted learning models, etc. In some embodiments, ML model 367 may be or include one or more nearest neighbor models, e.g., k nearest neighbor classification models; k nearest neighbor regression models, etc.; bayesian models, such as naive bayesian models; a Gaussian naive Bayes model; a polynomial naive bayes model; averaging a dependent estimator; a Bayesian network; a Bayesian belief network; hidden markov models, etc.
In some embodiments, the ML model 367 may be or include one or more artificial neural networks (also referred to simply as neural networks), including neural networks comprising multiple layers, so-called "deep" networks, feed-forward networks, recursive network neural networks, including long-term short-term (LSTM) recurrent neural networks; a gated loop unit; a bidirectional recurrent neural network; a continuous-time recurrent neural network; a neural history compressor; an echo state network; an Elman network; a jordan network; a recurrent neural network; a Hopfield network; a fully-cycled network; sequence-to-sequence configuration, etc. In some embodiments, ML model 367 may be or include one or more convolutional neural networks, generating networks, such as generating resistivities or other forms of artificial neural networks, such as deep boltzmann machines; entering a belief network; a stacked autoencoder, etc. Any of the neural networks described herein may be combined (e.g., stacked) to form a more complex network.
In some implementations, the ML model 367 can provide the output data in one or more recommended forms. For example, the ML model 367 may be a recommendation system or engine. As an example, given input data describing previous results of certain entities (e.g., scores, rankings, or ratings indicative of success or enjoyment), the ML model 367 may output suggestions or recommendations of one or more additional entities that are expected to have a desired result based on the previous results (e.g., derive scores, rankings, or ratings indicative of success or enjoyment). As one example, given input data describing a context of a computing device, such as computing device 110 of fig. 1, a recommendation system, such as computing system 360, may output suggestions or recommendations that the user traverses to a "call back node" of the IVR system rather than speaking to a given particular context (e.g., time of day) or based on an expected or actual latency associated with speaking to a delegate node.
The GUI control module 365 may rely on the ML model 367 to infer additional information about the computing device or IVR system user (i.e., similar to that obtained directly from the assistance module 364, the IVR system 182, or the telephony module 222). For example, the ML model 367 may predict additional information about a user from inferences or rules given from observations of past behavior of the user for an IVR system or other IVR systems. In a similar manner, the ML model 367 may predict additional information about the user from inferences or rules drawn from observations of past behavior of the IVR system or other users of other IVR systems. The ML model 367 may predict additional information about an IVR system based on inferences or rules drawn from observations of past telephone calls to the IVR system or other IVR systems.
Fig. 4 is a block diagram illustrating an example entity system configured to provide an enhanced user interface to an interactive voice response system in accordance with one or more aspects of the present disclosure. Fig. 4 is described in the context of fig. 1. For example, entity system 480 of FIG. 4 is an example of entity system 180 of FIG. 1. Fig. 4 shows only one particular example of an entity system 480, and many other examples of entity systems 480 may be used in other instances and may include a subset of the components included in the example entity system 480, or may include additional components not shown in fig. 4.
The entity system 480 includes one or more processors 470, one or more communication units 472, and one or more storage components 476, all communicatively coupled via one or more communication channels 474. Processor 470, communication unit 472, storage component 476, and communication channel 474 are similar to processors 240, 370, communication units 242, 372, communication channels 250, 374, and storage components 248, 376, respectively, of computing system 210, computing system 360.
The one or more storage components 476 include an IVR system 482, a communication module 466, and a carrier GUI module 484. Communications module 466 includes a telephony channel interface 423A and a supplemental data channel interface 423B. The communication module 466 is similar to the communication module 366 in that the communication module 466 is configured to control the communication unit 472 to manage one or more network communication interfaces of the computing system 460.
The IVR system 482 and operator GUI module 484 provide IVR services on behalf of the entity system 480. Similar to the IVR system 182 of the entity system 180, the IVR system 482 controls telephony functions of IVR services provided by the entity system 480 by including some or all of the same functions of the IVR system 182. The carrier GUI module 484 provides the entity system 480 with a user interface from which users associated with the entity system 480 can manage and interact with users who have called client devices of the IVR system 482.
The IVR system 482 manages a set of nodes (e.g., trees or other hierarchical data structures) respectively associated with one or more functions of the IVR system. The IVR system 482 traverses from one node to the next using rules. The rules take as input user input including DTMF codes, voice responses, etc., and traverse from the current node to the next node based on the user input. In some examples, each node of the IVR system 482 includes one or more associated functions, operations, or features.
For example, a node may include a callback function and a wait-and-hold option. If the IVR system 482 recognizes an input that selects the callback function, the IVR system 482 may store the user's telephone number in the stack and may output (e.g., via the telephone channel interface 423A or the supplemental data channel interface 423B) an indication of the expected time of day that the user should expect a callback. The IVR system 482 may automatically connect to the user's computing device when the user's phone number reaches the output of the stack. If the IVR system 482 recognizes an input that selects the hold-waiting function, the IVR system 482 may store the user's phone number in the stack of the IVR system 482 until the next node is traversed, where an operator associated with the entity system 180 may remove the phone number from the stack and interact with the user.
The IVR system 482 may perform operations in response to a telephone communication data stream received at the telephone channel interface 423A. Additionally, unlike other IVR systems, the IVR system 482 may perform advanced functions using additional information that flashes from the telephonic communications data stream, or in some examples, may perform advanced functions using additional information obtained from a supplemental data channel interface (i.e., outside of the telephonic communications data stream).
For example, the IVR system 482 may process the IMS data stream to perform operations based on conventional telephony commands and signals embedded in the data stream. Additionally, the IVR system 482 may decode hidden features, parameters, and messages encoded into the IMS data stream, which enables the IVR system 482 to perform more complex operations. For example, rather than requiring the user to enter DTMF codes or voice prompts, but rather to enter account numbers, social security numbers, credit card numbers, addresses, telephone numbers, or any other personally identifiable or other sensitive information using a telephone keypad, the IVR system 482 may obtain such sensitive information or additional information by subscribing to an IVR system GUI service, where the provider system or client computing device transmits transmissions of other personally identifiable information or other sensitive information using one of the interfaces 423. In this manner, by utilizing a telephonic communications network, transmissions of sensitive information between entities and client devices may be more secure than other forms of transmissions (e.g., web interfaces or other less secure media). Furthermore, by utilizing multiple channel channels (e.g., a telephone channel interface and a supplemental data channel interface), the IVR system 482 is less susceptible to hacking or snooping and is therefore more secure than other IVR systems that exchange information primarily over a single telephone communication channel.
The operator GUI module 484 provides a user interface into the IVR system 482 from which an operator may interact with clients of the IVR system 482. The GUI module 484 benefits from the enhanced functionality of the IVR system 482 compared to other IVR systems because it can access additional information about the client (e.g., obtained via one of the interfaces 423). The GUI module 484 may provide a more useful carrier experience for users of the IVR system 482, thereby providing a better customer experience (e.g., reduced annoyance, reduced time consumption, etc.) when a client connects to the IVR system 482.
For example, the supplemental data channel interface 423B may cause a client device (such as computing device 110) to provide payment information for a service requested via the IVR system 482. This payment information may be stored by the e-wallet of the client device, and the e-wallet may send the payment information to the carrier GUI module 484 via the supplemental data channel interface 423B, for example, to approve or reject the order. As another example, a client device may connect with the IVR system 482 to update an address of an account associated with the entity system 480. Rather than requiring the user of the client device to provide DTMF codes or speak voice input to the operator of the IVR system 482, the user may simply click on a GUI element on the client device to send an electronic address book entry to the entity system 480. In response to receiving the electronic address book entry, the carrier GUI module 484 can cause the carrier's display to present a graphical indication of the entry from which the carrier can read aloud the text of the entry via the telephone connection to the client device so that the user of the client device can verbally confirm the accuracy of the entry.
Fig. 5 is a conceptual diagram illustrating an example system configured to provide an enhanced user interface to an interactive voice response system according to one or more aspects of the present disclosure. System 500 of fig. 5 includes computing device 510, computing system 560, entity system 580, and network 530. Entity system 580 outputs operator user interface 515 for display, and computing device 510 outputs user interface 514 for display.
Fig. 5 is described in the context of fig. 1-4. For example, entity system 580 of fig. 5 is an example of entity systems 180, 480 of fig. 1 and 4. Network 530 of fig. 5 is an example of network 130 of fig. 1. Computing system 560 of fig. 5 is an example of computing systems 160, 360 of fig. 1 and 3. Computing device 510 of fig. 5 is an example of computing devices 110, 210 of fig. 1 and 2. Fig. 5 shows only one particular example of system 500, and many other examples of system 500 may be used in other instances and may include a subset of the components included in example system 500, or may include additional components not shown in fig. 5.
In accordance with techniques of this disclosure, the computing device 510 may initiate a telephone call to an IVR system of the entity system 580. Instead of outputting an audible interface associated with the IVR system, the computing device 510 may output for display a user interface 514, i.e., an IVR system GUI associated with the entity system 580. The computing device 510 may access services provided by the computing system 560 to obtain instructions needed to render the user interface 514 locally on the computing device 510.
Regardless, the initial screen of the user interface 514 includes a generic welcome message indicating the name of the user's account (e.g., "customer A"). The components of system 500 may exchange additional information beyond traditional types of telephony information to provide user interface 514. For example, a phone GUI module executing at computing system 560 may obtain an indication of the user's account name and other types of additional information from ancillary services accessible to entity system 580 and/or computing system 560 to customize the user experience. The phone GUI module may send instructions to the computing device 510 that cause the phone module of the computing device 510 to include aspects of the additional information at various portions of the user interface 514.
Similar techniques for providing an IVR system GUI at a client computing device, such as computing device 510, may be applied to entity systems, such as entity system 580, to provide a carrier-side IVR system GUI. For example, as can be seen from the juxtaposition of the screens of user interfaces 514 and 515 in fig. 5, when the computing device 510 is displaying a welcome screen associated with the user interface 514, the entity system is displaying a main status screen associated with the IVR system of the entity system 580 to the carrier user. Just as computing device 510 may obtain additional information to update the status of user interface 514, entity system 580 may obtain additional information, including status information, caller information, account information, etc., to enable entity system 580 to track the user's progress through the nodes of the IVR system and display progress indications within user interface 515.
For example, after the user navigates to the "new order" node of the IVR system and selects an action to place a new order via the user interface 514, the user interface 515 may display an order page to the operator that shows customer A's order pending. Now, at the "place new order" node, the user selects the action for paying for the new order via the user interface 514. The computing system 510 may automatically send payment information to the entity system 580 to process the new order. For example, the payment information may be sent to entity system 580 via encoded messages within or outside of a telephony (e.g., IMS) data stream using a supplemental data channel established between components of system 500.
In some examples, during the phone call, the computing device 510 may obtain, via the computing system 560, status information associated with a particular option of the one hierarchy of options of the IVR system of the entity system 580. For example, using a supplemental data channel or via the same telephone channel used to place the telephone call, the computing device 510 may obtain an indication of the expected latency associated with the IVR system of the entity system 580.
The computing device 510 may output a status indicator associated with a particular option for display as part of the user interface 514. For example, the computing device 510 may use the status information (e.g., the desired wait time) to generate a graphical element that is included in the user interface 514 by the computing device 510 to indicate the status information to a user of the computing device 510. In fig. 5, the computing device 510 displays text indicating an expected wait time of 5m for speaking with the carrier as an indication of status information in the user interface 514. Other examples of presence status indicators include the use of various shapes, sizes, colors, animations, and other types of graphical elements, images, and objects.
In response to obtaining updated state information associated with the particular option, computing device 510 may update the state indicator based on the updated state information associated with the particular option. For example, during a phone call, computing device 510 may obtain updated state information associated with a particular option via computing system 560. For example, using a supplemental data channel, or via the same telephone channel used to place the telephone call, the computing device 510 may obtain an indication of an updated expected wait time associated with the IVR system of the entity system 580. For example, since one of the operators associated with entity system 580 must return home earlier on the day, and since entity system 580 reduces the bandwidth for handling incoming calls, the expected latency has increased from 5m to 15 m. The computing device 510 may cause the user interface 514 to display updated text indicating that the expected wait time for speaking with the carrier has become 10 m. In some examples, the updated status indicator may include updated text, graphical elements, images, objects using various shapes, sizes, colors, animations, etc. to make the change known to the user of the computing device 510.
Fig. 6 is a flow diagram illustrating example operations performed by an example computing system configured to provide an enhanced user interface to an interactive voice response system according to one or more aspects of the present disclosure. Fig. 6 is described in the context of fig. 1. For example, operations 600 through 614 may be performed by computing device 110, computing system 160, or a combination of computing device 110 and computing system 160 of system 100. Operations 616-620 may be performed by entity system 180 of system 100 of fig. 1. Operations 600 through 620 may be performed in a different order than shown in fig. 6 or with more or fewer operations.
In accordance with techniques of this disclosure, the computing device 110 may receive a user request to initiate a telephone call to an entity system 180 that relies on the IVR system 182 (600). For example, UI module 120 may detect, via UIC112, a user input that causes computing device 110 to launch a telephony application. In response to the user input, phone module 122 can initiate a phone call to entity system 180.
In some examples, computing device 110 may be configured to display an IVR system GUI or not. For example, UI module 120 may cause UIC112 to display selectable elements for switching, opening and closing, access to IVR system GUI services provided by computing system 160. In response to receiving information from UI module 120 regarding user selection of options for computing device 110 to enable the graphical user interface whenever a telephone call is made to the IVR system, phone module 122 may cause the UIC to output user interface 114 for display. In the event that the user does not select this option, the computing device 110 may display a default telephone user interface, including graphical indications of a keypad, and the like. However, where the user selects options for the IVR GUI, the computing device 110 may perform operations 602-606 to display the user interface 114 instead of the default telephony user interface of the computing device 110.
In other examples, the phone GUI module 162 performs a series of calls to different nodes of the IVR system 182 to automatically generate a map of the IVR system 182. And in other examples, the phone GUI module 162 may obtain information of options associated with the IVR system 182 to generate a node map of the IVR system 182 based on information collected from other phone GUI modules executing at other computing systems. In some cases, the phone GUI module 162 may execute a machine learning model to predict information about options associated with the IVR system 182.
In some examples, the telephony module 222 suppresses or selectively enables aspects of the audible interface associated with the IVR system 182 that are output by the IVR system 182. For example, the computing device 110 may receive audio associated with the IVR system 182 using the phone module 222 while the user interface 114 is displayed. At times, the telephony module 222 may cause the computing device 110 to refrain from outputting at least some audio related to the IVR system 182 when outputting the user interface 113 for display. For example, when the phone module 222 recognizes a list of menu options that are machine-generated speech or read aloud, the phone module 222 may suppress the audio because the user prefers to interact with the user interface 114.
During the telephone call, in response to detecting the unrecorded person's voice from the audio associated with the IVR system 182, the phone module 222 may cause the computing device 110 to output, via the UIC112, at least a portion of the audio associated with the IVR system 182 that includes the unrecorded person's voice. In other words, if the human operator goes online during the communication session between the IVR system 182 and the computing device 110, the computing device 110 may automatically avoid throttling the audio interface of the IVR system 182. In this case, the phone module 222 may stop displaying the user interface 114 or may continue displaying the user interface 114. For example, the operator may intervene during an IVR session with the computing device 110 in response to receiving a command requesting assistance in placing an order. After answering the customer's question, the customer may click within the user interface 114 to send payment for the order. An electronic payment service accessible from the computing device 110 may transfer money to a user account of the entity system 180. When the payment is passed, the operator can speak over the phone to confirm that the payment has been received.
However, in this example, the auxiliary service does not contain information about the status of the pending order because the order is still in hand at entity system 180. Thus, the telephony module 222 requests additional information about the pending order from the IVR system 182.
With additional information regarding a particular order, the IVR system 182 may perform an order status lookup operation to obtain information regarding the pending order without requiring the user of the computing device 110 or the operator of the IVR system 182 to have to provide any input specifying a particular order.
In response to outputting the indication of the one or more corresponding inputs and other information, computing device 110 or computing system 160 may update user interface 114 based on the additional information received by computing device 110 (612). For example, using information obtained from the entity system 180, the phone GUI module 162 may generate an order status page of the user interface 114 from which the user of the computing device 110 may view information about the location of the order in the processing cycle at the entity.
The computing device 110 may display an updated user interface 114 based on the results (614). For example, the phone module 222 may receive updated instructions from the phone GUI module 162 that cause the user interface 114 to reflect information about the location of the order in the processing cycle at the entity.
In some examples, a telephone call may be dropped or otherwise interrupted (e.g., due to human error, technical error, environmental factors, etc.). To improve the user experience, the phone GUI module 162 and the phone module 222 may perform operations to automatically save the user state with respect to the IVR system 182. For example, the telephony module 222 may store a session identifier associated with a telephone call to the IVR system 182. The session identifier may be embedded in the IMS flow and also stored by entity system 180. Entity system 180 and telephony module 222 may store a record of the respective telephone calls, including information such as: current node, additional information, previous nodes, previous selections, and other information about the call. In this way, in response to an interruption in the telecommunications session between the entity system 180 and the computing device 110, the telephony module 122 and the IVR system 182 may automatically reestablish the telecommunications session using the session identifier. After the telecommunications session is reestablished to correspond to the state of the user interface 114 prior to the interruption, the telephony module 222 can cause the state of the user interface 114.
Clause 1. A method, comprising: receiving, by a mobile device, a user request to initiate a telephone call to an entity that relies on an interactive voice response system; obtaining information regarding a hierarchy of options associated with the interactive voice response system; outputting, by the mobile device and for display, a graphical user interface for navigating the one hierarchy of options associated with the interactive voice response system; receiving, by a mobile device, one or more user inputs associated with a graphical user interface; converting one or more user inputs associated with the graphical user interface into one or more corresponding inputs recognized by the interactive voice response system; outputting, by the mobile device to the entity, an indication of the one or more corresponding inputs and other information required by the entity to perform the operation in response to the one or more corresponding inputs; and in response to outputting the indication of the one or more corresponding inputs and other information, updating the graphical user interface based on additional information received by the mobile device.
Clause 2. The method according to clause 1, wherein the other information required by the entity to perform the operation includes user-specific information maintained by a digital assistant executing at the mobile device or a mobile payment application executing at the mobile device.
Clause 3. The method of any of clauses 1 or 2, wherein the other information required by the entity to perform the operation includes user-specific information other than a name of the user or a telephone number associated with the user.
Clause 4. The method according to any of clauses 1-3, further comprising: during a telephone call: obtaining status information associated with a particular one of the options of the one hierarchy; outputting a status indicator associated with the particular option for display as part of a graphical user interface; and in response to obtaining updated state information associated with the particular option, updating the state indicator based on the updated state information associated with the particular option.
Clause 5. The method of clause 4, wherein at least one of: the state information or updated state information is obtained from a machine learning model trained based on past telephone calls between the mobile device and the entity or at least one of the other mobile telephones and the entity; or obtain status information or updated status information from the entity.
Clause 6. The method of any of clauses 1-5, wherein outputting for display a graphical user interface comprises: detecting a user selection of an option for enabling a mobile device of a graphical user interface; in response to detecting the user selection, a graphical user interface is output for display instead of a default phone user interface of the mobile device.
Clause 7. The method of any of clauses 1-6, wherein the indication of the one or more corresponding inputs is output to the entity via the first communication channel; other information required by the entity to perform the operation in response to the one or more corresponding inputs is output to the entity via the second communication channel.
Clause 8. The method of clause 7, wherein the first communication channel comprises a second communication channel and uses an internet protocol multimedia subsystem having a session initiation protocol.
Clause 9. The method according to any of clauses 1-8, wherein at least one of: obtaining information about the one hierarchy option from the entity via a communication channel; or receiving the additional information via the communication channel or from a machine learning model that learned the additional information.
Clause 10. The method of any of clauses 1-9, wherein a graphical user interface for navigating the one hierarchy of options associated with the interactive voice-response interface is output for display, the graphical user interface comprising: receiving, by the mobile device, audio associated with the interactive voice response interface while outputting for display the graphical user interface; when the graphical user interface is output for display, the mobile device disables output of at least some audio associated with the interactive voice response interface.
Clause 11. The method according to clause 10, further comprising: during a telephone call: in response to detecting the unrecorded person's voice from the audio associated with the interactive voice response interface, outputting, by the mobile device, at least a portion of the audio associated with the interactive voice response interface that includes the unrecorded person's voice.
Clause 12. The method according to any of clauses 1-11, further comprising: storing a session identifier for the telephone call; and automatically reestablishing the telecommunications session using the session identifier in response to the interruption in the telecommunications session, wherein a state of the graphical user interface after reestablishing the telecommunications session corresponds to a state of the graphical user interface prior to the interruption.
Clause 13. A computing system comprising at least one processor configured to perform the method of any of clauses 1-12.
Clause 14. A computing system comprising means for performing the method of any of clauses 1-12.
Clause 15. A computer-readable storage medium comprising instructions that when executed cause at least one processor to perform the method of any of clauses 1-12. By way of example, and not limitation, such computer-readable storage media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, flash memory, or any other storage medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also, any connection is properly termed a computer-readable medium. For example, if the instructions are transmitted from a website, server, or other remote source using a coaxial cable, fiber optic cable, twisted pair, Digital Subscriber Line (DSL), or wireless technologies such as infrared, radio, and microwave, then the definition of medium includes coaxial cable, fiber optic cable, twisted pair, DSL, or wireless technologies such as infrared, radio, and microwave. However, it should be understood that computer-readable storage media and data storage media do not include connections, carrier waves, signals, or other transitory media, but are instead directed to non-transitory, tangible storage media. Disk and disc, as used herein, includes Compact Disc (CD), laser disc, optical disc, Digital Versatile Disc (DVD), floppy disk and blu-ray disc where disks usually reproduce data magnetically, while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer-readable media.
The instructions may be executed by one or more processors, such as one or more Digital Signal Processors (DSPs), general purpose microprocessors, an Application Specific Integrated Circuits (ASICs), field programmable logic arrays (FPGAs), or other equivalent integrated or discrete logic circuitry. Thus, as used herein, the term "processor" may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. In addition, in some aspects, the functionality described herein may be provided within dedicated hardware and/or software modules. Also, the techniques may be fully implemented in one or more circuits or logic elements.
The techniques of this disclosure may be implemented in a variety of devices or apparatuses, including a wireless handset, an Integrated Circuit (IC), or a set of ICs (e.g., a chipset). Various components, modules, or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques, but do not necessarily require realization by different hardware units. Rather, as noted above, the various units may be combined in hardware units, or provided by a collection of hardware units including one or more processor interoperations as noted above, in conjunction with suitable software and/or firmware.
Various embodiments have been described. These and other embodiments are within the scope of the following claims.
Claims (15)
1. A method, comprising:
receiving, by a mobile device, a user request to initiate a telephone call to an entity that relies on an interactive voice response system;
obtaining information regarding a hierarchy of options associated with the interactive voice response system;
outputting, by the mobile device and for display, a graphical user interface for navigating the one hierarchy of options associated with the interactive voice response system;
receiving, by the mobile device, one or more user inputs associated with the graphical user interface;
converting the one or more user inputs associated with the graphical user interface into one or more corresponding inputs recognized by the interactive voice response system;
outputting, by the mobile device to the entity, an indication of the one or more corresponding inputs and other information required by the entity to perform an operation in response to the one or more corresponding inputs; and
in response to outputting the indication of the one or more corresponding inputs and the other information, updating the graphical user interface based on additional information received by the mobile device.
2. The method of claim 1, wherein the other information required by the entity to perform the operation includes user-specific information maintained by a digital assistant executing at the mobile device or a mobile payment application executing at the mobile device.
3. The method of claim 1 or 2, wherein the other information required by the entity to perform the operation includes user-specific information other than a name of a user or a phone number associated with the user.
4. The method according to any one of claims 1-3, further comprising:
during the telephone call:
obtaining status information associated with a particular one of the options of the one hierarchy;
outputting, for display as part of the graphical user interface, a status indicator associated with the particular option; and
in response to obtaining updated status information associated with the particular option, updating the status indicator based on the updated status information associated with the particular option.
5. The method of claim 4, wherein at least one of:
the state information or the updated state information is obtained from a machine learning model trained based on past phone calls between the mobile device and the entity or at least one of the other mobile phones and the entity; or
The status information or the updated status information is obtained from the entity.
6. The method of any of claims 1-5, wherein outputting for display the graphical user interface comprises:
detecting a user selection of an option of the mobile device for enabling the graphical user interface; and
in response to detecting the user selection, outputting for display the graphical user interface instead of a default phone user interface of the mobile device.
7. The method of any one of claims 1-6, wherein:
the indication of the one or more corresponding inputs is output to the entity via a first communication channel; and
the other information required by the entity to perform the operation in response to the one or more corresponding inputs is output to the entity via a second communication channel.
8. The method of claim 7, wherein the first communication channel comprises the second communication channel and uses an internet protocol multimedia subsystem with session initiation protocol.
9. The method of any of claims 1-8, wherein at least one of:
information about the one hierarchy option is obtained from the entity via a communication channel; or
The additional information is received via the communication channel or from a machine learning model that learned the additional information.
10. The method of any of claims 1-9, wherein the graphical user interface for navigating the one hierarchy of options associated with the interactive voice response interface is output for display, the graphical user interface comprising:
receiving, by the mobile device, audio associated with the interactive voice response interface while the graphical user interface is output for display; and
inhibiting, by the mobile device, output of at least some of the audio associated with the interactive voice response interface while the graphical user interface is output for display.
11. The method of claim 10, further comprising:
during the telephone call:
in response to detecting an unrecorded person's voice from the audio associated with the interactive voice response interface, outputting, by the mobile device, at least a portion of the audio associated with the interactive voice response interface that includes the unrecorded person's voice.
12. The method according to any one of claims 1-11, further comprising:
storing a session identifier for the telephone call;
automatically reestablishing the telecommunications session using the session identifier in response to an interruption in the telecommunications session, wherein a state of the graphical user interface after reestablishing the telecommunications session corresponds to a state of the graphical user interface prior to the interruption.
13. A computing system comprising at least one processor configured to perform the method of any of claims 1-12.
14. A computing system comprising means for performing the method of any of claims 1-12.
15. A computer-readable storage medium comprising instructions that when executed cause at least one processor to perform the method of any of claims 1-12.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202310905918.XA CN117061487A (en) | 2018-06-29 | 2018-07-16 | Graphical user interface for a speech responsive system |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862691701P | 2018-06-29 | 2018-06-29 | |
US62/691,701 | 2018-06-29 | ||
PCT/US2018/042289 WO2020005302A1 (en) | 2018-06-29 | 2018-07-16 | Graphical user interface for a voice response system |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202310905918.XA Division CN117061487A (en) | 2018-06-29 | 2018-07-16 | Graphical user interface for a speech responsive system |
Publications (1)
Publication Number | Publication Date |
---|---|
CN112219386A true CN112219386A (en) | 2021-01-12 |
Family
ID=63244957
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202310905918.XA Pending CN117061487A (en) | 2018-06-29 | 2018-07-16 | Graphical user interface for a speech responsive system |
CN201880094242.8A Pending CN112219386A (en) | 2018-06-29 | 2018-07-16 | Graphic user interface of voice response system |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202310905918.XA Pending CN117061487A (en) | 2018-06-29 | 2018-07-16 | Graphical user interface for a speech responsive system |
Country Status (4)
Country | Link |
---|---|
US (1) | US20210250438A1 (en) |
CN (2) | CN117061487A (en) |
DE (1) | DE112018007785T5 (en) |
WO (1) | WO2020005302A1 (en) |
Families Citing this family (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10896048B1 (en) | 2018-08-30 | 2021-01-19 | Express Scripts Strategie Development, Inc. | Systems and methods for user interface adaptation for per-user metrics |
US11645093B2 (en) * | 2018-08-30 | 2023-05-09 | Express Scripts Strategic Development, Inc. | Systems and methods for user interface adaptation for per-user metrics |
US20210281681A1 (en) * | 2020-03-06 | 2021-09-09 | PAG Financial International LLC | Systems and methods for operating an interactive voice response system |
Citations (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040120484A1 (en) * | 2002-12-20 | 2004-06-24 | J. M. Buzbee Family Limited Partnership | Telephonic interface for a visual presentation of a hierarchy of menus and automated call-back |
CN101453525A (en) * | 2007-11-30 | 2009-06-10 | 国际商业机器公司 | Method and apparatus for restoring conversation between customer equipments and IVR system |
CN103250402A (en) * | 2010-08-24 | 2013-08-14 | 株式会社克尔盖特 | Voice-screen ARS service system, method for providing same, and computer-eadable recording medium |
US20140134979A1 (en) * | 2012-11-14 | 2014-05-15 | Apple Inc. | Integrated Approach for Visual Dialing |
US20140270106A1 (en) * | 2013-03-14 | 2014-09-18 | Timothy Barlow | Method and system for interactive telephone waiting |
CN105120117A (en) * | 2015-08-27 | 2015-12-02 | 北京羽乐创新科技有限公司 | Call interaction method and device |
CN105162996A (en) * | 2014-07-18 | 2015-12-16 | 上海触乐信息科技有限公司 | Intelligent service interaction platform apparatus, system, and implementing method |
CN105208228A (en) * | 2015-08-31 | 2015-12-30 | 努比亚技术有限公司 | Method and device for realizing self-service |
CN106034184A (en) * | 2015-03-16 | 2016-10-19 | 中兴通讯股份有限公司 | Method and device for selecting service provider service |
US20160337516A1 (en) * | 2015-05-11 | 2016-11-17 | Ebay Inc. | User device detection and integration for an ivr system |
US9538005B1 (en) * | 2014-09-19 | 2017-01-03 | Amazon Technologies, Inc. | Automated response system |
CN106453219A (en) * | 2016-05-29 | 2017-02-22 | 陈清勇 | Method and system for dialing hotline through service item pre-registration before calling |
CN106993089A (en) * | 2017-03-23 | 2017-07-28 | 中国联合网络通信集团有限公司 | The method and apparatus that voice menu is shown |
US20180041625A1 (en) * | 2011-08-09 | 2018-02-08 | At&T Intellectual Property I, L.P. | Graphical interactive visual response system and method |
Family Cites Families (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7092738B2 (en) * | 2002-12-20 | 2006-08-15 | International Business Machines Corporation | Navigation of interactive voice response application using a wireless communications device graphical user interface |
US9680994B2 (en) * | 2010-07-06 | 2017-06-13 | Millind Mittal | Method and apparatus for data channel augmented auto attended voice response systems |
US9542074B2 (en) * | 2011-10-13 | 2017-01-10 | Nuance Communications, Inc. | Method and apparatus for enhancing an interactive voice response (IVR) system |
US20130108030A1 (en) * | 2011-10-27 | 2013-05-02 | Shamir Shmuel Snir | System and Method for Creating Parallel Graphical Interface for Voice Menu |
US10469655B2 (en) * | 2018-03-21 | 2019-11-05 | Avaya Inc. | Call reconstruction sequenced application |
-
2018
- 2018-07-16 US US16/973,977 patent/US20210250438A1/en active Pending
- 2018-07-16 WO PCT/US2018/042289 patent/WO2020005302A1/en active Application Filing
- 2018-07-16 CN CN202310905918.XA patent/CN117061487A/en active Pending
- 2018-07-16 CN CN201880094242.8A patent/CN112219386A/en active Pending
- 2018-07-16 DE DE112018007785.3T patent/DE112018007785T5/en active Pending
Patent Citations (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040120484A1 (en) * | 2002-12-20 | 2004-06-24 | J. M. Buzbee Family Limited Partnership | Telephonic interface for a visual presentation of a hierarchy of menus and automated call-back |
CN101453525A (en) * | 2007-11-30 | 2009-06-10 | 国际商业机器公司 | Method and apparatus for restoring conversation between customer equipments and IVR system |
CN103250402A (en) * | 2010-08-24 | 2013-08-14 | 株式会社克尔盖特 | Voice-screen ARS service system, method for providing same, and computer-eadable recording medium |
US20180041625A1 (en) * | 2011-08-09 | 2018-02-08 | At&T Intellectual Property I, L.P. | Graphical interactive visual response system and method |
US20140134979A1 (en) * | 2012-11-14 | 2014-05-15 | Apple Inc. | Integrated Approach for Visual Dialing |
US20140270106A1 (en) * | 2013-03-14 | 2014-09-18 | Timothy Barlow | Method and system for interactive telephone waiting |
CN105162996A (en) * | 2014-07-18 | 2015-12-16 | 上海触乐信息科技有限公司 | Intelligent service interaction platform apparatus, system, and implementing method |
US9538005B1 (en) * | 2014-09-19 | 2017-01-03 | Amazon Technologies, Inc. | Automated response system |
CN106034184A (en) * | 2015-03-16 | 2016-10-19 | 中兴通讯股份有限公司 | Method and device for selecting service provider service |
US20160337516A1 (en) * | 2015-05-11 | 2016-11-17 | Ebay Inc. | User device detection and integration for an ivr system |
CN105120117A (en) * | 2015-08-27 | 2015-12-02 | 北京羽乐创新科技有限公司 | Call interaction method and device |
CN105208228A (en) * | 2015-08-31 | 2015-12-30 | 努比亚技术有限公司 | Method and device for realizing self-service |
CN106453219A (en) * | 2016-05-29 | 2017-02-22 | 陈清勇 | Method and system for dialing hotline through service item pre-registration before calling |
CN106993089A (en) * | 2017-03-23 | 2017-07-28 | 中国联合网络通信集团有限公司 | The method and apparatus that voice menu is shown |
Non-Patent Citations (1)
Title |
---|
帅青红主编: "《电子支付与结算》", 30 September 2011, 大连：东北财经大学出版社 * |
Also Published As
Publication number | Publication date |
---|---|
DE112018007785T5 (en) | 2021-05-20 |
US20210250438A1 (en) | 2021-08-12 |
WO2020005302A1 (en) | 2020-01-02 |
CN117061487A (en) | 2023-11-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11810562B2 (en) | Reducing the need for manual start/end-pointing and trigger phrases | |
CN112136175B (en) | Voice interaction for accessing calling functionality of companion device at primary device | |
JP6492069B2 (en) | Environment-aware interaction policy and response generation | |
EP3493202A1 (en) | Far-field extension for digital assistant services | |
JP2021072137A (en) | Cross-device handoffs | |
JP2020025272A (en) | System and method for emergency call initiated by voice command | |
CN117221452A (en) | Synchronous communication using voice and text | |
KR20200007925A (en) | Delayed Response by Operational Assistant | |
KR102624148B1 (en) | Automatic navigation of interactive voice response (IVR) trees on behalf of human users | |
CN110462647B (en) | Electronic device and method for executing functions of electronic device | |
KR102472010B1 (en) | Electronic device and method for executing function of electronic device | |
EP3504702A1 (en) | Systems and methods for artifical intelligence voice evolution | |
CN112219386A (en) | Graphic user interface of voice response system | |
CN111429896B (en) | Voice interaction for accessing calling functionality of companion device at primary device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
RJ01 | Rejection of invention patent application after publication | ||
RJ01 | Rejection of invention patent application after publication |
Application publication date: 20210112 |