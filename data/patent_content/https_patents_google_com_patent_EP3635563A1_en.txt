EP3635563A1 - Application analysis with flexible post-processing - Google Patents
Application analysis with flexible post-processingInfo
- Publication number
- EP3635563A1 EP3635563A1 EP18779956.4A EP18779956A EP3635563A1 EP 3635563 A1 EP3635563 A1 EP 3635563A1 EP 18779956 A EP18779956 A EP 18779956A EP 3635563 A1 EP3635563 A1 EP 3635563A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- application
- post
- issue
- processor
- artifacts
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000004458 analytical method Methods 0.000 title claims abstract description 32
- 238000012805 post-processing Methods 0.000 title claims abstract description 28
- 238000012360 testing method Methods 0.000 claims abstract description 111
- 230000003993 interaction Effects 0.000 claims abstract description 62
- 238000000034 method Methods 0.000 claims abstract description 53
- 238000012545 processing Methods 0.000 claims description 24
- 238000003860 storage Methods 0.000 claims description 20
- 238000004519 manufacturing process Methods 0.000 claims description 12
- 238000011156 evaluation Methods 0.000 claims description 11
- 230000009193 crawling Effects 0.000 claims description 9
- 230000004913 activation Effects 0.000 claims description 8
- 238000000605 extraction Methods 0.000 claims description 8
- 230000003213 activating effect Effects 0.000 claims description 5
- 230000000694 effects Effects 0.000 claims description 5
- 238000003825 pressing Methods 0.000 claims description 5
- 230000007704 transition Effects 0.000 claims description 5
- 238000007906 compression Methods 0.000 claims description 3
- 230000006835 compression Effects 0.000 claims description 2
- 230000008569 process Effects 0.000 abstract description 15
- 238000013459 approach Methods 0.000 description 7
- 238000004891 communication Methods 0.000 description 7
- 238000010586 diagram Methods 0.000 description 7
- 238000013507 mapping Methods 0.000 description 7
- 238000011161 development Methods 0.000 description 5
- 230000006870 function Effects 0.000 description 3
- 238000012552 review Methods 0.000 description 3
- 238000013522 software testing Methods 0.000 description 3
- 230000009471 action Effects 0.000 description 2
- 238000013500 data storage Methods 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 230000002547 anomalous effect Effects 0.000 description 1
- 230000003190 augmentative effect Effects 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 239000002131 composite material Substances 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 239000003344 environmental pollutant Substances 0.000 description 1
- 239000011521 glass Substances 0.000 description 1
- 230000003116 impacting effect Effects 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 238000011835 investigation Methods 0.000 description 1
- 230000004807 localization Effects 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 230000008520 organization Effects 0.000 description 1
- 231100000719 pollutant Toxicity 0.000 description 1
- 229910052710 silicon Inorganic materials 0.000 description 1
- 239000010703 silicon Substances 0.000 description 1
- 238000004088 simulation Methods 0.000 description 1
- 230000003997 social interaction Effects 0.000 description 1
- 230000005236 sound signal Effects 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/36—Preventing errors by testing or debugging software
- G06F11/3668—Software testing
- G06F11/3672—Test management
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/36—Preventing errors by testing or debugging software
- G06F11/3668—Software testing
- G06F11/3672—Test management
- G06F11/3688—Test management for test execution, e.g. scheduling of test suites
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/36—Preventing errors by testing or debugging software
- G06F11/3664—Environments for testing or debugging software
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/36—Preventing errors by testing or debugging software
- G06F11/3668—Software testing
- G06F11/3672—Test management
- G06F11/3692—Test management for test results analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/30—Creation or generation of source code
- G06F8/38—Creation or generation of source code for implementing user interfaces
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/70—Software maintenance or management
- G06F8/71—Version control; Configuration management
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/455—Emulation; Interpretation; Software simulation, e.g. virtualisation or emulation of application or operating system execution engines
Definitions
- Electronic devices play integral roles in manufacturing, healthcare, commerce, social interaction, entertainment, and communication. For example, most people consider their smart phone to be a critical part of their daily lives. Electronic devices include personal computing devices like smart phones, notebook computers, tablet computers, smart watches and other wearable devices, game consoles, televisions, and other entertainment devices. Electronic devices also include more utilitarian items like smart speakers, safety devices with sensors to detect heat or pollutants, security devices that detect unauthorized activity, and Internet of Things (IoT) devices. Further, electronic devices with computing power are embedded in many different types of modem equipment, from medical devices to household appliances and from vehicles to industrial tools. Thus, electronic devices are manufactured in a multitude of sizes, form factors, and capabilities for an even greater array of purposes.
- IoT Internet of Things
- An executable application includes code, instructions, software, and so forth that can be executed by one or more processors to provide some functionality or to realize a device feature.
- applications were included with the purchase of electronic devices, or customers purchased applications in a box containing a physical medium, such as a floppy disk that stored the application.
- a physical medium such as a floppy disk that stored the application.
- new versions of applications were produced relatively infrequently, such as annually.
- an application is provided to an application runner, which executes the application.
- the application runner crawls through various user interface (UI) screens from a user interaction perspective. Based on different UI screens that are uncovered (e.g. different UI screens that represent different application states, with each application state corresponding to a respective UI screen of the different UI screens), the application runner generates a set of artifacts that includes metadata pertinent to different types of potential issues with operation of the application.
- UI user interface
- Potential issues can represent anomalous data, problems, UI errors, or unplanned behaviors that cause or are indicative of application operation that fails to achieve an intended feature or expected result. These different types of potential issues can include one or more of an accessibility issue, a UI issue, a UI appearance issue, a memory usage issue, a string compression issue, a stability issue, processor utilization issues, a multi-threading implementation issue, a network usage issue, or other type of issue.
- the set of artifacts can be organized into a directed graph based on emulated user interactions. Alternatively, the set of artifacts can be organized by test cases or feature.
- the directed graph may have multiple nodes and multiple edges, with each respective node corresponding to a respective UI screen of the multiple UI screens or representative of an application state of the multiple application states, and with each edge respectively representative of a user interaction that effects a transition from a first UI screen to a second UI screen of the multiple screens.
- Multiple different post-processors are provided access to the set of artifacts, with each respective post-processor corresponding to a respective type of issue.
- a given post-processor processes the set of artifacts by traversing the metadata, extracting relevant portions thereof, evaluating the extracted metadata, and producing a report indicative of any potential issues for the type of issue corresponding to the given post-processor.
- one test suite can be used to generate a set of artifacts that is relevant to multiple different types of potential application issues and duplication of efforts and resources to produce multiple different test suites can be avoided.
- a new post-processor for a different type of issue can be applied that processes the set of artifacts without materially changing the test suite.
- a problem-submission post-processor can review the reports provided by other post-processors to produce a problem report that highlights more pertinent issues (e.g. higher priority issues in terms of frequency of occurrence or potential end-user impact) that are identified for manual consideration.
- the method comprises loading an application to be analyzed and obtaining a test suite including multiple test cases, with each test case corresponding to at least one feature of the application.
- the method also comprises crawling the application from a user interaction perspective.
- the crawling includes activating user interaction elements based on the multiple test cases of the test suite to cause the application to produce multiple user interface (UI) screens.
- the crawling also includes determining multiple application states produced by the application, with each respective application state corresponding to a respective UI screen of the multiple UI screens.
- the method additionally comprises generating a set of artifacts based on the multiple application states.
- the method further comprises processing the set of artifacts to investigate multiple types of issues pertaining to operation of the application.
- the electronic device comprises one or more processors and one or more computer-readable storage media storing instructions that are executable by the one or more processors.
- the computer- readable storage media include an application configured to offer multiple features and a test suite including multiple test cases, with each test case corresponding to at least one feature of the multiple features.
- the computer-readable storage media also include an application runner configured to run the application (e.g., execute or simulate execution of the application) using the test suite.
- the application runner includes an application crawler configured to traverse the application from a user interaction perspective and to provide metadata based on the test suite.
- the application runner also includes an artifact generator configured to generate a set of artifacts based on the metadata.
- the computer-readable storage media further include multiple post-processors configured to access the set of artifacts, with each respective post-processor configured to use the set of artifacts to investigate a respective type of issue of multiple types of issues pertaining to operation of the application.
- the electronic device includes one or more computer-readable storage media storing processor-executable instructions that, responsive to execution by one or more processors, cause the electronic device to perform operations.
- the operations comprise running an application to be analyzed and emulating, based on a test suite, activation of user interaction elements to cause the application to produce multiple UI screens.
- the operations that are performed also comprise determining multiple application states produced by the application, with each respective application state corresponding to a respective UI screen of the multiple UI screens.
- the operations that are performed additionally comprise generating a set of artifacts based on the multiple application states, with the set of artifacts including a UI screen of the multiple UI screens for each application state of the multiple application states.
- the operations that are performed further comprise processing the set of artifacts using a first post-processor to investigate a first type of issue pertaining to operation of the application and producing, based on the processing, a first report corresponding to the first type of issue.
- the system comprises an application configured to offer multiple features and a test suite including multiple test cases, with each test case corresponding to at least one feature of the multiple features.
- the system also comprises an application runner configured to run the application using the test suite.
- the application runner comprises means for crawling the application from a user interaction perspective to provide metadata based on the test suite.
- the application runner also comprises means for generating a set of artifacts based on the metadata.
- the system further comprises post-processor means for processing the set of artifacts, the post-processor means configured to use the set of artifacts to investigate multiple types of issues pertaining to operation of the application.
- Fig. 1 illustrates an example environment, including an application analyzer having an application runner and multiple post-processors, in which application analysis with flexible post-processing can be implemented.
- Fig. 2 depicts, for an example mapping application, two example user interface (UI) screens that illustrate a crawl between the two UI screens as part of an example application analysis.
- UI user interface
- Fig. 3 illustrates an example application runner that includes an application crawler and an artifact generator that can generate a set of artifacts.
- Fig. 4 illustrates an example application crawler in conjunction with an artifact generator and multiple post-processors that can each produce a respective report of multiple reports.
- Fig. 5 illustrates an example set of artifacts that is depicted as a directed graph having multiple nodes and edges that can be representative of UI screens and UI linkages therebetween.
- Fig. 6 illustrates an example post-processor that can process a set of artifacts in accordance with a corresponding type of issue to produce a report for that type of issue.
- Fig. 7 illustrates an example problem submission post-processor for handling issues reported by one or more other post-processors to identify those more pertinent for manual consideration.
- Fig. 8 illustrates example methods for implementing application analysis with flexible post-processing.
- Fig. 9 illustrates other example methods for implementing application analysis with flexible post-processing.
- Fig. 10 illustrates various components of an example electronic device that can implement application analysis with flexible post-processing in accordance with one or more implementations.
- the application may be executed responsive to a test case that is designed to look for problems in a particular area of concern, such as memory issues or user interface (UI) issues.
- Each test case is designed to test the application to produce metadata that pertains to the corresponding area of concern.
- modem applications even those that run on a smart phone or a wearable device such as augmented reality (AR) glasses, are quite complex.
- a testing apparatus may employ dozens or hundreds of test cases designed to elicit metadata for that area. With multiple areas of concern, multiple sets of test cases are created, with each set of test cases corresponding to a respective area. Further, some test cases are relevant to general usage or provide a foundation for subsequently applying other test cases. With these test cases all totaled together, a suite of test cases may include thousands of interrelated test cases.
- test cases are a detail-oriented and time-consuming endeavor. Hence, a test suite having hundreds, or thousands, of test cases represents a substantial investment of time, expertise, and other resources.
- Existing approaches to analyzing an application involve applying multiple test cases, or a homogenous test suite, to the application to produce metadata for each particular area of concern. The metadata can then be manually reviewed to determine if there are issues for the particular area. A different, specialized test suite is created for each such area of concern, and the application analysis is repeated with each specialized test suite.
- the resources and costs invested in creating each test suite for each potential problem area are duplicated many times. In other words, a significant portion of the efforts devoted to discovering problematic issues with an application are directed to creating each test case, which effort is often repeated across multiple areas of concern. This existing approach is therefore slow, costly, and wasteful of application-development resources.
- an application analyzer which runs on one or more electronic devices, includes a binary manager and an application runner.
- the binary manager loads an application to the application runner.
- the application runner includes an application executor, an application crawler, an artifact generator, and a test suite interface.
- the application executor executes the application.
- the application crawler traverses through various user interface (UI) screens from a user interaction perspective, such as by activating user interaction elements.
- UI user interface
- the artifact generator Based on different UI screens that are uncovered, the artifact generator generates a set of artifacts that includes metadata pertinent to the different types of issues with operation of the application.
- This set of artifacts may include, for example, a directed graph in which each node corresponds to a UI screen, or an application state, or some combination thereof, and so forth.
- Multiple different post-processors are provided access to the set of artifacts, with each respective post-processor corresponding to a respective type of issue.
- a given post-processor processes the set of artifacts by traversing the metadata, extracting relevant portions thereof, evaluating the extracted metadata, and producing a report.
- the report is indicative of any potential issues for the type of issue corresponding to the given post-processor.
- a new post-processor for a different type of issue can be produced that processes the set of artifacts without changing the test suite.
- one test suite can be used to generate a set of artifacts that is relevant to multiple different types of potential application issues.
- Respective ones of different pluggable post-processors can be applied to the set of artifacts to discover issues that pertain to different respective issue types. In these manners, duplication of efforts and resources to produce multiple different test suites—such as one test suite per issue type— can be avoided.
- Example implementations in various levels of detail are discussed below with reference to the associated figures.
- the discussion below first sets forth an example operating environment and then describes example schemes, techniques, and hardware.
- Example methods are described next with reference to various flow diagrams, and the discussion concludes with an example electronic device and aspects related thereto.
- Fig. 1 illustrates an example environment 100 that includes an application analyzer 108 having an application runner 120 and multiple post-processors 116.
- the application analyzer 108 can implement application analysis with flexible post-processing.
- the environment 100 also includes at least one application 110.
- the environment 100 further includes one or more electronic devices 102. As shown, there are multiple electronic devices 102-1 ... 102-h, with“n” representing some positive integer.
- Each electronic device 102 includes at least one processor 104 and at least one computer-readable storage medium 106.
- the storage medium 106 can store executable code, such as one or more programs, one or more modules, processor-executable instructions, at least one application, and so forth.
- the processor 104 can execute the code or processor- executable instructions to perform some method, effect a process, implement a scheme, realize at least a portion of the application analyzer 108, and so forth.
- An electronic device 102 can comprise a portable device, such as a smart phone or a notebook computer; a desktop computer; a server computer or rack; a portion of cloud computing resources; and so forth.
- at least a portion of the application analyzer 108 can be executed on a portable device.
- the application analyzer 108 can be executed on a workstation computer.
- the application analyzer 108 can be executed by a distributed computing system extracted from infrastructure providing cloud computing functionality. Further, in an example combined implementation, cloud infrastructure or a server computer interoperates with a portable device such as a tablet computer to realize the application analyzer 108. For instance, some application execution can be performed via emulation on server processors and some application execution can be performed on a mobile device targeted by the application. Also, the application analyzer 108 can be implemented fully or partially using a client- server architecture or using at least one library.
- the application analyzer 108 includes at least one test suite 114, at least one post-processor 116, at least one binary manager 118, and at least one application runner 120.
- the application runner 120 can interact with multiple post-processors 116-1, 116-2 ... 116-n, with“n” representing some positive integer.
- the variable“n” is used herein in various contexts, and a value thereof can be the same or different in the various contexts.
- the application runner 120 includes an application crawler 122 and a set of artifacts 124.
- the binary manager 118 controls interactions between, or access to, the application runner 120, the test suite 114, the multiple post-processors 116-1 to 116-n, and the application 110.
- the binary manager 118 can launch the application runner 120, retrieve the test suite 114, and activate selected post-processors 116.
- the binary manager 118 can also load or otherwise provide access to the application 110.
- the application 110 provides or offers multiple features 112-1 to 112-n.
- the features 112 enable certain functionalities, tools, interactions, and so forth to be provided to a user of the application 110.
- Features 112 can be described in terms of different relative levels or categories of abstraction.
- a feature 112 may comprise electronic communication, word processing, image manipulation, web browsing, database management, and so forth.
- a feature 112 may comprise searching, taking a photo, providing a print preview, communicating with a printer, updating a display, updating a social media feed, accessing contacts, posting an item to a social network, and so forth.
- a feature 112 may comprise accepting text input, displaying a“clickable” virtual button, zooming into a display, reading out text or providing other functionality for accessibility purposes, and so forth.
- the multiple features 112-1 to H2-n can be defined at different levels of abstraction or in alternative manners.
- the binary manager 118 provides the application 110 to the application runner 120, which can run the application (e.g., execute the application or simulate execution of the application).
- the application crawler 122 interacts with the application 110 to test various features 112 from a user interaction perspective based on the contents of the test suite 114. User interaction and user interface (UI) screens are described below with reference to Fig. 2.
- the application crawler 122 collects metadata produced by the application 110. From the metadata, the application runner 120 produces a set of artifacts 124.
- the set of artifacts 124 includes data that is organized (e.g., into a directed graph, by feature 112, or by test case) to enable investigation into multiple types of issues pertaining to operation of the application.
- Each post-processor 116 is tailored to investigate a respective type of issue.
- a new post-processor 116 can be added to investigate a new issue type without changing the test suite 114, or at least without rewriting the test suite 114.
- the binary manager 118 can coordinate interactions between the various modules, applications, and other components while operating via the one or more processors 104 and the one or more storage media 106 of one or more of the multiple electronic devices 102-1 to 102-h.
- the processor 104 can execute processor-executable instructions or code stored by the computer-readable storage medium 106 to cause the at least one electronic device 102 to perform operations or implement various device functionalities.
- the processor 104 is implemented as a general-purpose processor (e.g., a multicore central-processing unit (CPU)), an application-specific integrated circuit (ASIC), or a system-on-chip (SoC) in which other components of the electronic device can be integrated therein.
- the processor 104 is implemented as multiple processor cores or a multicore processor configured to operate in parallel or as part of a distributed processing system.
- the storage medium 106 may include any suitable type of memory media or storage media, such as read-only memory (ROM), programmable ROM (PROM), random access memory (RAM), dynamic RAM (DRAM), static RAM (SRAM), or Flash memory.
- ROM read-only memory
- PROM programmable ROM
- RAM random access memory
- DRAM dynamic RAM
- SRAM static RAM
- Flash memory Flash memory
- the storage medium 106 of the electronic device 102 is implemented as at least one hardware-based storage medium, which does not include transitory signals or carrier waves.
- the storage medium 106 stores firmware, an operating system, modules, and/or applications of the electronic device 102 as instructions, code, or other information.
- the instructions or code can be executed by the processor 104 to implement various functionalities of the electronic device 102, such as those related to application analysis, software testing, problem reporting, software debugging, code optimization, combinations thereof, and so forth.
- the storage medium 106 stores processor-executable instructions or code to implement the application analyzer 108.
- Fig. 2 depicts, for an example mapping application 210, two example user interface (UI) screens 202 that illustrate an example crawl 200 between the two UI screens.
- the crawl 200 can be performed in manners analogous to crawling the world wide web (WWW), with URL links of web pages being analogous to user interaction elements 204 of UI screens 202, except that directions of the crawl 200 and the content of user inputs can be guided by test cases (as described below with reference to Fig. 3).
- WWW world wide web
- URL links of web pages being analogous to user interaction elements 204 of UI screens 202, except that directions of the crawl 200 and the content of user inputs can be guided by test cases (as described below with reference to Fig. 3).
- test cases as described below with reference to Fig. 3
- Each UI screen 202 includes various UI elements that are visible to a user, or otherwise observable by a user (e.g., as haptic or auditory content). Some UI elements are capable of being observed, but not interacted with. Other UI elements, however, enable a user to interact with them. These UI elements are referred to herein as user interaction elements 204. Eight example user interaction elements 204 are explicitly indicated, but more or fewer may be present.
- the first UI screen 202-1 includes an area for a map display 208.
- a text entry box 204-6 is above the map display 208.
- the text entry box 204-6 includes a menu activation element 204-2 and a voice interaction activation element 204-1.
- the area of the map display 208 includes multiple virtual buttons: an upper button 204-4 and a lower button 204-5.
- a swipe interaction element 204-3 may be present, even though it would not be visually depicted by an actual first UI screen 202-1.
- a swipe interaction element generally (or a long-press, a pinch, or another multi-fingered gesture interaction)
- an application 110 can be affected by a user.
- a downward motion that activates the swiping interaction element 204-3 scrolls the portion of the map that is visible in the map display 208.
- the visible user interaction elements 204 can behave similarly to gesture- related interaction elements. For example, pressing the upper button 204-4 can activate a menu to change an appearance of the map display 208 (e.g., toggling from roads to terrain). Pressing the lower button 204-5 can activate a navigational function of the mapping application 210 (e.g., to display a box for entering a destination or a route on the map display 208 or to enable a pin-dropping feature). Pressing the menu activation element 204-2 can cause a drop-down or slide-out menu to be displayed that presents additional options, settings, or features that are made available by the mapping application 210. Pressing the voice interaction activation element 204-1 can cause the mapping application 210 to access a microphone of an associated device to detect sound and cause the corresponding spoken words to be displayed.
- the text entry box 204-6 is activated by, for instance, touching the text entry box 204-6. Touching the text entry box 204-6 causes a corresponding user interaction linkage 206 to be followed or navigated from the first UI screen 202-1 to the second UI screen 202-2.
- the activation of the text entry box 204-6 causes a different UI screen 202 to be displayed.
- a keyboard 204-7 is presented in the second UI screen 202-2. The keyboard 204-7 enables user entry of text into the text entry box 204-6.
- the addition of text e.g.,“Mountain V..”
- the suggestions list 204-8 can also serve as a user interaction element 204 because selection of a suggestion elevates that selected suggestion into the text entry box 204-6 and can initiate an associated search or display for the suggestion.
- the navigation over the user interaction linkage 206 produces a new UI screen 202 that differs from the previous UI screen 202 in at least one non-trivial way (e.g., by more than text, by the addition of a different user interaction element 204, and so forth).
- the application crawler 122 (as a component of the application runner 120 of Fig. 1) causes an application 110 to create each UI screen 202 by looking for, identifying, and then activating various user interaction elements 204 based on a test suite 114.
- the application crawler 122 crawls the application 110 as part of an execution thereof from a user interaction perspective. Additional example implementations of the application runner 120 are described below with reference to Fig. 3.
- Fig. 3 illustrates generally at 300 an example application runner 120 that includes an application crawler 122 and an artifact generator 308.
- the application runner 120 also includes a test suite interface 304, an application executor 306, and a post-processor interface 310.
- the test suite 114 includes multiple test cases 302-1 to 302-n, with“n” representing some positive integer.
- each test case 302 is designed to target or test at least one feature 112 of the application 110. To fully test a given feature 112, especially one defined at a relatively higher or middle level, multiple test cases 302 may target different aspects of a given feature 112 or target the given feature 112 under different scenarios or application modes.
- the“n” features 112 may have a quantity that is different from the“n” test cases 302.
- the application executor 306 causes the application 110 to execute.
- the application executor 306 may execute the application 110 on the actual hardware that the application 110 is to be disseminated to (e.g., a targeted electronic device), in a virtual machine of a server electronic device, using a platform provided by cloud computing functionality, and so forth.
- the application crawler 122 interacts with the application executor 306 so that the multiple test cases 302 can be applied to the execution of the application 110. To do so, the application crawler 122 receives the test cases 302 from the test suite interface 304. In effect, the test suite interface 304 obtains the test suite 114 and forwards the multiple test cases 302 to the application crawler 122.
- the application crawler 122 crawls the application 110 across multiple UI screens 202 from a user interaction perspective, as described above with reference to Fig. 2.
- the application crawler 122 causes the execution to produce metadata, such as UI screens 202 and application state data, which are described below with reference to Figs. 4 and 5.
- the artifact generator 308 uses the metadata to generate a set of artifacts 124.
- the set of artifacts 124 can include at least a portion of the metadata in a form that is organized to be accessible by multiple post-processors 116.
- the set of artifacts 124 can enable the metadata to be explored so that each different post-processor 116 can extract and evaluate the particular metadata that is pertinent to the type of issue with which the post-processor 116 is designed to analyze.
- the post-processor interface 310 provides a mechanism for each post-processor 116 of multiple different types of post-processors 116-1 to 116-n to access the set of artifacts 124.
- Fig. 4 illustrates generally at 400 an example application crawler 122 in conjunction with an artifact generator 308 and multiple post-processors 116-1 to 116-n.
- the application crawler 122 includes a screen inspector 402, a user emulator 404, and a state determiner 406.
- Each respective post-processor 116 of the multiple post-processors 116-1 to 116-n corresponds to a respective issue type 410 of the multiple issue types 410-1 to 410-n, with“n” representing some positive integer.
- Fig. 4 also depicts multiple reports 408-1 to 408-n, with“n” representing some positive integer.
- the variable“n” is used in various situations for multiple components throughout this disclosure, a numerical value for the variable“n” may differ both for different components and in different situations.
- the screen inspector 402 inspects a UI screen 202 (of Fig. 2) to locate a user interaction element 204 thereof.
- the user emulator 404 activates the user interaction element 204 in accordance with at least one test case 302.
- the state determiner 406 determine multiple application states from multiple UI screens 202. For example, the state determiner 406 can ascertain if changes to a UI screen are sufficient to identify the UI screen as a new application state (e.g., mere changes to text are usually insufficiently substantial to warrant identification of a new application state). Additionally or alternatively, the state determiner 406 can determine metadata 412 for each application state of the multiple application states.
- the application states, UI screen snapshots, and other metadata 412 are provided from the application crawler 122 to the artifact generator 308.
- the artifact generator 308 generates the set of artifacts 124 from the metadata 412.
- the post-processor interface 310 provides access to the set of artifacts 124 to multiple post-processors 116-1 to H6-n.
- the post-processing can be separated from the application runner 120 (e.g., as shown in FIG. 3) and/or the test suite 114. This enables the post-processing to be modifiable and extensible without substantially changing the execution or simulation code or significantly rewriting the test suite 114.
- each post-processor 116 can be tuned to consider a different issue type 410.
- the types of issues 410 pertain to different respective types of problems that can potentially impact operation of the application 110 being analyzed.
- Example types of issues 410 include user interface issues, accessibility issues, memory usage issues, network usage issues, stability issues, processor utilization issues, string-compression issues, and so forth.
- User interface issues can include whether the UI elements are visible, avoid overlapping with each other, and so forth.
- Accessibility issues e.g.,“A11Y” or“ally” issues
- each virtual button or other user interaction element 204 can be coded to aurally describe its function or purpose.
- Memory usage issues can include memory leak issues, memory spike, memory localization issues, and so forth.
- Network usage can include frequency of access, average bandwidth, and so forth. Stability issues pertain to whether an application crashes, can handle unexpected inputs gracefully, and so forth.
- Processor utilization issues can relate to how much time or what percentage of time or processing capability an application consumes.
- a post-processor 116 can also modify (e.g., expand or update) the set of artifacts 124. Another post-processor 116 can then access the modified set of artifacts 124.
- the modifying post-processor 116 can store an indication of the modifications.
- a custom post-processor 116 can be created for an application 110 that analyzes operation of application-specific features 112, such as intended arrangements or interrelationships among particular UI elements.
- each respective post-processor 116 of the multiple post-processors 116-1 to 116-n corresponds to a respective issue type 410 of the multiple issue types 410-1 to 410-n.
- Each respective post-processor 116 of the multiple post-processors 116-1 to 116-n produces a respective report 408 of the multiple reports 408-1 to 408-n.
- each respective report 408 of the multiple reports 408-1 to 408-n also corresponds to a respective issue type 410 of the multiple issue types 410-1 to 410-n, such as UI issues or memory usage issues.
- Example approaches to the artifact generator 308 generating a set of artifacts 124 for post-processing are described below with reference to Fig. 5.
- Example approaches to implementing a post-processor 116 and applying the post-processor 116 to the set of artifacts 124 to produce a report 408 are described below with reference to Fig. 6.
- Example automated approaches to reviewing the multiple reports 408-1 to 408-n are described below with reference to Fig. 7.
- Fig. 5 illustrates an example set of artifacts 124 that is organized as a directed graph 500 having multiple nodes 502 and multiple edges 504.
- each node 502 represents an application state 510 or corresponds to a UI screen 202.
- Each edge 504 represents or corresponds to a user interaction linkage 206.
- the application crawler 122 e.g., of Figs. 3 and 4
- obtains the metadata 412 as the crawl 200 (of Fig. 2) is expanded by navigating between different UI screens 202 via various user interaction elements 204 using multiple user interaction linkages 206.
- the artifact generator 308 organizes the resulting metadata 412 into the directed graph 500 to produce the set of artifacts 124.
- the artifact generator 308 overlays identifying information on parts of the directed graph 500.
- Each UI screen 202 of each respective node 502 is assigned a screen identification 508, which can be based on one or more names or identifiers of the user interaction elements 204 that are included in the UI screen 202.
- the artifact generator 308 also assigns a navigation identifier 506 to each user interaction linkage 206 corresponding to each edge 504.
- the navigation identifier 506 for an edge 504 can be derived from the screen identifications 508 of the origin and destination sides of the edge 504.
- a screen identification 508 of an origin node 502 from which an edge 504 originates can be concatenated with a screen identification 508 of a destination node 502 to which the edge 504 points to produce a navigation identifier 506 for the edge 504.
- a user interaction element 204 can also be assigned an identifier (not shown), such as one that includes a navigation identifier 506 for a corresponding user interaction linkage 206 in combination with other information.
- the graph 500 can contain a list of triples. Each triple is a three-element data structure. A current screen is included because a stable screen identifier, the screen identification 508, is generated. Thus, each triple has a screen identification 508 to represent the current state. Specifically, the triple can have a current state, a transition action in the middle, and finally a destination state. In other words, using a triple and starting from a current state, an action is performed to transition to a destination state.
- the artifact generator 308 works with the application crawler 122 to produce the directed graph 500 from the metadata 412 that is created during the crawl 200 (of Fig. 2).
- the artifact generator 308 captures a snapshot of the UI screen 202 for each determined state of the application 110.
- the artifact generator 308 also obtains and records state data, which is representative of the application state 510 for the included or associated UI screen 202. Different types of state data can be obtained for the application state 510 to account for different types of issues 410 that a given post-processor 116 may be looking for or to otherwise more fully provide a picture of how an application is impacting an electronic device.
- Examples of the application state 510 include: a memory usage state 510-1, a network usage state 510-2, a processor utilization state 510-3, and so forth.
- the UI screen 202 represents the state, and the application state 510 can correspond to the UI screen 202. In other implementations, the application state 510 can include the UI screen 202.
- Fig. 6 illustrates generally at 600 an example post-processor 116 that can process a set of artifacts 124 in accordance with a corresponding type of issue 410 to produce a report 408.
- the set of artifacts 124 includes a directed graph 500.
- the post-processor 116 includes a traversing module 602, an extraction module 604, an evaluation module 606, and a report production module 608.
- Each module includes one or more parameters that specify how metadata is handled relative to a corresponding type of issue 410.
- the traversing module 602 traverses the set of artifacts 124 to obtain state data resulting from the simulated or emulated user execution of the application 110 that is being analyzed.
- the metadata 412 of Fig. 4 is organized as the directed graph 500, so the traversing module 602 traverses the directed graph 500 to analyze the nodes 502 thereof.
- the extraction module 604 includes at least one filter 610.
- the filter 610 is tuned to a type of issue 410 corresponding to the post-processor 116.
- the extraction module 604 can extract from the directed graph 500 traversed state data based on the filter 610.
- the extraction module 604 can use the filter 610 to affirmatively identify data items that are relevant to the corresponding issue type 410 or to exclude data items that are not relevant to the corresponding issue type 410 (e.g., processor utilization data may be omitted for a memory usage issue type). Updating parameters of the filter 610 can therefore adjust which data items are extracted.
- the evaluation module 606 evaluates the extracted state data based on the type of issue 410 corresponding to the post-processor 116 using one or more rules 612.
- Each rule 612 is likewise based on the type of issue 410.
- Each rule 612 for a type of issue 410 may include at least one parameter (e.g., a condition) for use in determining whether state data for a type of issue 410 is problematic and can result in the application operating in a way that is different from its intended operation.
- a rule 612 may include an instantaneous threshold for memory spike issues or an algorithm to detect if two different user interaction elements 204 overlap one another.
- Updating parameters of a rule 612 of the evaluation module 606 can therefore adjust which data items are considered to violate or comport with a rule of the corresponding issue type 410.
- Example evaluations and associated rules 612 are described below.
- the report production module 608 produces the report 408 using the evaluated state data from the evaluation module 606.
- the report 408 is indicative of one or more problematic issues with an operation of the application 110 that pertain to the type of issue 410 corresponding to the post-processor 116.
- Example scenarios are described here for post-processors 116 with different respective example issue types 410 and therefore different filters 610 or rules 612.
- the filter 610 of the extraction module 604 identifies UI elements of each traversed screenshot of a UI screen 202.
- the evaluation module 606 evaluates each identified UI element for appearance purposes based on one or more rules 612. For instance, the evaluation module 606 can evaluate identified UI elements to ensure that each UI element that is intended to be visible is in a top display layer and/or not overlapping another UI element.
- the report production module 608 can add an entry to the report 408 for each UI element that fails to meet a designated set of UI element guidelines.
- the filter 610 of the extraction module 604 identifies UI elements of each traversed screenshot of a UI screen 202.
- the evaluation module 606 evaluates each UI element to ensure that each UI element comports with each accessibility rule 612 relevant to that UI element. For instance, the UI element may be checked to verify that the UI element has text earmarked to be read aloud to describe its function.
- the report production module 608 can include in the report 408 an entry for each UI element that fails to meet the designated accessibility rules along with an indication of which rule 612 is violated.
- the filter 610 of the extraction module 604 identifies memory usage state data 510-1 (of Fig. 5) from the application states 510 of multiple nodes 502.
- the evaluation module 606 compares recorded memory usage values to at least one memory utilization threshold of a rule 612.
- the memory utilization threshold may be expressed in terms of an amount of memory that is currently storing data for the application 110, a range of addresses over which the application is storing data (even if there are addressable locations that are available within that range), a rate of memory access or bandwidth, and so forth. If a memory usage value extracted from the memory usage state data 510-1 exceeds the memory utilization threshold of a rule 612, then evaluation module 606 can issue a violation notice or an alert.
- the report production module 608 can include in the report 408 an entry for an issue identifying the memory state 510 or the node 502 and providing indicia of the problem with the memory usage issue (e.g., an alert for average memory utilization or an alert for highest instantaneous memory utilization, such as a memory spike).
- Fig. 7 illustrates, generally at 700, an example problem submission post processor 116-h for handling issues 706 reported by one or more other post-processors 116 to identify those issues 706 that are more pertinent for manual consideration.
- an automated report-production system can result in numerous issues to be considered manually by programmers, application debuggers, and other software engineers. Because time and resources are limited, software engineers may not be able to review each and every reported issue. To accommodate this potentially overwhelming scenario, a problem submission post-processor H6-n can be implemented to produce a problem report 408-n that identifies, for manual consideration by software engineers, issues 706 that are inferred to be more pertinent.
- an example problem submission post-processor H6-n includes a selection module 702, a deduplication module 704, and a report production module 608.
- Each other post-processor 116 of multiple post-processors 116-1 to H6-(n-l) produces a respective report 408 of multiple reports 408-1 to 408-(n-l).
- Each report 408 includes at least one issue 706, and many reports 408 may individually include dozens or even hundreds of issues 706.
- the problem submission post-processor H6-n can be responsible for processing“n” issues 706-1 ... 706-n, with“n” representing an integer that can reach into the thousands or higher.
- the problem submission post-processor 116-n can operate on the issues 706 of each report 408 sequentially or of the multiple reports 408-1 to 408-(n-l) in parallel.
- the selection module 702 performs a selection operation 712 based on at least one ranking criterion 708.
- the selection module 702 can rank issues 706 based on the ranking criterion 708.
- a crash issue 706 can be assigned a higher priority than a memory spike issue 706 in accordance with one ranking criterion 708.
- relative sizes of memory spikes or relative amounts of UI element overlap can be used as different ranking criteria 708.
- Other schemes can alternatively be implemented.
- an issue cap threshold can also be instituted that sets a maximum number of issues to be selected as reportable problems for forwarding to software engineers.
- the cap threshold can be relative to a given application version or during any single time period (e.g., each day).
- the selection module 702 can prioritize the importance of issues using at least one ranking criterion 708 and apply a cap threshold to facilitate a narrowing of the issues 706 that are to be reported as problems for manual consideration. These selected issues 706 are made available to the deduplication module 704.
- the deduplication module 704 performs a deduplication operation 714 on the selected issues to remove duplicate problem issues and thereby produce deduplication results. To do so, the deduplication module 704 can access a problem database 710 that includes multiple issues 706, each of which is stored in association with a respective problem signature 716.
- the application state 510 or other state data can be used to compute a problem signature 716 for each issue 706 under analysis— e.g., each issue that has been previously forwarded for manual consideration or each issue currently being processed as a selected issue.
- the deduplication module 704 can rely on structured data to measure a similarity between a newly selected issue and an existing issue.
- structured data can include stack traces for crashes and leak traces for memory leaks. If the problem signatures 716 for two issues are identical or sufficiently close (e.g., based on a similarity threshold), one of the two issues (e.g., the newer one or the one with less state data) can be omitted from reporting. In this manner, the deduplication module 704 can remove duplicate issues to save software engineers additional time. In alternative implementations, the deduplication operation 714 can be performed prior to the selection operation 712 or at least partially in parallel.
- Those issues 706 that are not filtered out by the selection operation 712 or diverted by the deduplication operation 714 are passed to the report production module 608.
- the report production module 608 produces the problem report 408-n with problem issues 706 that include fewer than all of the multiple issues 706-1 to 706-n to facilitate manual consideration of those issues 706 that are determined to be more important and non-duplicative.
- the problem-submission post-processor H6-n can review the reports 408-1 to 408-(n-l) provided by other post-processors 116-1 to H6-(n-l) to produce a problem report 408-n that identifies more pertinent issues 706 that are highlighted for manual consideration by software engineers.
- the problem report 408-n can present the reported issues 706 in an inferred order of importance based on the at least one ranking criterion 708.
- Example methods are described below with reference to various flow diagrams of Figs. 8 and 9. These methods relate to application analysis with flexible post processing. Aspects of these methods maybe implemented in, for example, hardware (e.g., fixed logic circuitry or general-purpose processors), firmware, or some combination thereof. These techniques may be realized using one or more of the electronic devices or components shown in Figs. 1-7 or 10 (an electronic device 1000 is described in Fig. 10 below), which devices or components may be further divided, combined, and so on. The electronic devices and components of these figures generally represent firmware, hardware, IC chips, circuits, or a combination thereof. Thus, these figures illustrate some of the many possible systems or apparatuses capable of implementing the described techniques.
- Fig. 8 illustrates example methods for implementing application analysis with flexible post-processing at a flow diagram 800.
- the flow diagram 800 includes five operations 802-810.
- an application to be analyzed is loaded.
- a binary manager 118 or an application executor 306 can load an application 110 that is to be analyzed.
- a test suite including multiple test cases is obtained, with each test case corresponding to at least one feature of the application.
- a test suite interface 304 can obtain a test suite 114 including multiple test cases 302-1 to 302-n, with each test case 302 corresponding to at least one feature 112 of the application 110.
- the application is crawled from a user interaction perspective.
- the application crawler 122 can crawl the application 110 from a user interaction perspective.
- a screen inspector 402 can identify user interaction elements 204 on different UI screens 202.
- user interaction elements are activated based on the multiple test cases of the test suite to cause the application to produce multiple user interface (UI) screens.
- UI user interface
- a user emulator 404 can activate user interaction elements 204 to cause the application 110 to produce multiple UI screens 202 based on the multiple test cases 302 of the test suite 114.
- multiple application states that are produced by the application are determined, with each respective application state corresponding to a respective UI screen of the multiple UI screens.
- a state determiner 406 can determine multiple application states 510 produced by the application 110. Each respective application state 510 corresponds to a respective UI screen 202 of the multiple UI screens 202.
- a set of artifacts is generated based on the multiple application states.
- an artifact generator 308 can generate a set of artifacts 124 based on the multiple application states 510.
- the multiple application states 510 can include snapshots of the multiple UI screens 202 as well as the state data.
- the set of artifacts is processed to investigate multiple types of issues pertaining to operation of the application. For example, after the crawling of the application 110 by the application crawler 122, the multiple post-processors 116-1 to H6-n can process the set of artifacts 124 to respectively investigate multiple types of issues 410-1 to 4l0-n that pertain to operation of the application 110.
- the operation of the application 110 may relate to aspects of the application 110 that are readily apparent to a user (e.g., visual aspects, speed of operation, or stability) or aspects that are not readily apparent to a user (e.g., network usage, processor utilization, multi-threading implementation, or memory usage).
- aspects of the application 110 that are readily apparent to a user (e.g., visual aspects, speed of operation, or stability) or aspects that are not readily apparent to a user (e.g., network usage, processor utilization, multi-threading implementation, or memory usage).
- Fig. 9 illustrates example methods for implementing application analysis with flexible post-processing at a flow diagram 900.
- the flow diagram 900 includes six operations 902-912.
- an application to be analyzed is run.
- an application runner 120 can use an application executor 306 to execute (e.g., run on native or target hardware; run on other, general hardware; or simulate execution) of an application 110 that is to be analyzed.
- an application executor 306 e.g., run on native or target hardware; run on other, general hardware; or simulate execution
- activation of user interaction elements is emulated to cause the application to produce multiple user interface (UI) screens.
- UI user interface
- a user emulator 404 of an application crawler 122 can activate user interaction elements 204 to cause the application 110 to produce multiple UI screens 202 by traversing user interaction linkages 206.
- multiple application states that are produced by the application are determined, with each respective application state corresponding to a respective UI screen of the multiple UI screens.
- a state determiner 406 of the application crawler 122 can determine multiple application states 510 that are produced by the application 110.
- each respective application state 510 can correspond to a respective UI screen 202 of the multiple UI screens 202.
- a set of artifacts is generated based on the multiple application states, with the set of artifacts including a UI screen of the multiple UI screens for each application state of the multiple application states.
- an artifact generator 308 can generate a set of artifacts 124 based on the multiple application states 510.
- the set of artifacts 124 can include a UI screen 202 of the multiple UI screens 202 for each application state 510 of the multiple application states 510.
- the set of artifacts 124 can be formulated as a directed graph 500 in which nodes 502 represent application states 510 or UI screens 202 and edges 504 represent transitions between states and screens.
- the set of artifacts is processed using a first post-processor to investigate a first type of issue pertaining to operation of the application.
- a first post-processor 116-1 can process the set of artifacts 124 to investigate a first type of issue 410-1 pertaining to operation of the application 110.
- a first report corresponding to the first type of issue is produced.
- the first post-processor 116-1 can produce a first report 408-1 corresponding to the first type of issue 410-1.
- a second post-processor 116-2 can process the set of artifacts 124 to investigate a second type of issue 410-2 and produce a second report 408-2 corresponding to the second type of issue 410-2.
- the first and second post-processors 116-1 and 116-2 can operate sequentially or at least partially in parallel.
- Fig. 10 illustrates various components of an example electronic device 1000 that can implement application analysis with flexible post-processing in accordance with one or more implementations as described with reference to any of the previous Figs. 1-8.
- the electronic device 1000 may be implemented as any one or combination of a fixed or mobile device; a local or a distributed device; in any form of a computer, such as a portable, end-user, or server computer; in any form of electronic device, such as communication, phone, navigation, gaming, audio, camera, messaging, media playback, consumer, business, and/or other type of electronic device, including a workstation, a virtualized machine, or distributed cloud-computing apparatus.
- Electronic device 1000 includes communication transceivers 1002 that enable wired and/or wireless communication of device data 1004, such as received data, transmitted data, or other information as described above.
- Example communication transceivers 1002 include NFC transceivers, WPAN radios compliant with various IEEE 802.15 (BluetoothTM) standards, WLAN radios compliant with any of the various IEEE 802.11 (WiFiTM) standards, WWAN (3GPP-compliant) radios for cellular telephony, wireless metropolitan area network (WMAN) radios compliant with various IEEE 802.16 (WiMAXTM) standards, and wired local area network (LAN) Ethernet transceivers.
- WPAN compliant with various IEEE 802.15 (BluetoothTM) standards
- WWAN (3GPP-compliant) radios for cellular telephony wireless metropolitan area network (WMAN) radios compliant with various IEEE 802.16 (WiMAXTM) standards
- the electronic device 1000 may also include one or more data input ports 1006 via which any type of data, media content, and/or other inputs can be received, such as user-selectable inputs, messages, applications, music, television content, recorded video content, and any other type of audio, video, and/or image data received from any content and/or data source.
- the data input ports 1006 may include USB ports, coaxial cable ports, and other serial or parallel connectors (including internal connectors) for flash memory, DVDs, CDs, and the like. These data input ports 1006 may be used to couple the electronic device to components, peripherals, or accessories such as keyboards, microphones, or cameras.
- the electronic device 1000 of this example includes at least one processor 1008 (e.g., any one or more of application processors, microprocessors, digital-signal processors (DSPs), controllers, and the like), which can include a combined processor and memory system (e.g., implemented as part of an SoC), that processes (e.g., executes) computer-executable instructions stored on computer-readable media to control operation of the device.
- the processor 1008 may be implemented as an application processor, embedded controller, microcontroller, SoC, and the like.
- a processor or processing system may be implemented at least partially in hardware, which can include components of an integrated circuit or on-chip system, a digital- signal processor (DSP), an application- specific integrated circuit (ASIC), a field-programmable gate array (FPGA), a complex programmable logic device (CPLD), and other implementations in silicon and/or other hardware.
- DSP digital- signal processor
- ASIC application- specific integrated circuit
- FPGA field-programmable gate array
- CPLD complex programmable logic device
- the electronic device 1000 can be implemented with any one or combination of electronic circuitry, which may include software, hardware, firmware, or fixed logic circuitry that is implemented in connection with processing and control circuits, which are generally indicated at 1010 (as electronic circuitry 1010).
- This electronic circuitry 1010 can implement executable or hardware-based modules (not shown) through logic circuitry and/or hardware (e.g., such as an FPGA), and so forth.
- the electronic device 1000 can include a system bus, interconnect, crossbar, or data transfer system that couples the various components within the device.
- a system bus or interconnect can include any one or combination of different bus structures, such as a memory bus or memory controller, a peripheral bus, a universal serial bus, and/or a processor or local bus that utilizes any of a variety of bus architectures.
- the electronic device 1000 also includes one or more memory devices 1012 that enable data storage, examples of which include random access memory (RAM), non-volatile memory (e.g., read-only memory (ROM), flash memory, EPROM, and EEPROM), and a disk storage device.
- RAM random access memory
- non-volatile memory e.g., read-only memory (ROM), flash memory, EPROM, and EEPROM
- EEPROM electrically erasable programmable read-only memory
- the memory device(s) 1012 provide data storage mechanisms to store the device data 1004, other types of code and/or data, and various device applications 1020 (e.g., software applications or programs).
- an operating system 1014 can be maintained as software instructions within the memory device 1012 and executed by the processor 1008.
- the electronic device 1000 also includes an audio and/or video processing system 1016 that processes audio data and/or passes through the audio and video data to an audio system 1018 and/or to a display system 1022 (e.g., a video buffer or a screen of a smart phone or camera).
- the audio system 1018 and/or the display system 1022 may include any devices that process, display, and/or otherwise render audio, video, display, and/or image data.
- Display data and audio signals can be communicated to an audio component and/or to a display component via an RF (radio frequency) link, S-video link, HDMI (high-definition multimedia interface), composite video link, component video link, DVI (digital video interface), analog audio connection, or other similar communication link, such as media data port 1024.
- the audio system 1018 and/or the display system 1022 are external or separate components of the electronic device 1000.
- the display system 1022 can be an integrated component of the example electronic device 1000, such as part of an integrated touch interface.
- the electronic device 1000 of Fig. 10 is an example implementation of the electronic devices 102 of Fig. 1.
- the processor 1008 is an example of the processor 104.
- the memory device 1012 is an example of the computer-readable storage medium 106 (CRM), as further indicated by the illustrated application analyzer 108.
- the electronic device 1000 may further include an application 110 to be analyzed.
- the principles of application analysis with flexible post-processing as described herein can be implemented by, or in conjunction with, the electronic device 1000 of Fig. 10.
Abstract
Description
Claims
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762609304P | 2017-12-21 | 2017-12-21 | |
US16/109,453 US11055209B2 (en) | 2017-12-21 | 2018-08-22 | Application analysis with flexible post-processing |
PCT/US2018/050951 WO2019125546A1 (en) | 2017-12-21 | 2018-09-13 | Application analysis with flexible post-processing |
Publications (2)
Publication Number | Publication Date |
---|---|
EP3635563A1 true EP3635563A1 (en) | 2020-04-15 |
EP3635563B1 EP3635563B1 (en) | 2022-11-02 |
Family
ID=66951143
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP18779956.4A Active EP3635563B1 (en) | 2017-12-21 | 2018-09-13 | Application analysis with flexible post-processing |
Country Status (4)
Country | Link |
---|---|
US (1) | US11055209B2 (en) |
EP (1) | EP3635563B1 (en) |
CN (1) | CN110959153B (en) |
WO (1) | WO2019125546A1 (en) |
Families Citing this family (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110442772A (en) * | 2019-08-13 | 2019-11-12 | 深圳司南数据服务有限公司 | A kind of intelligence grinds report generation method and terminal |
CN112527362A (en) * | 2021-02-08 | 2021-03-19 | 鹏城实验室 | FPGA test program updating method and device, electronic equipment and storage medium |
US20220358162A1 (en) * | 2021-05-04 | 2022-11-10 | Jpmorgan Chase Bank, N.A. | Method and system for automated feedback monitoring in real-time |
Family Cites Families (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050108630A1 (en) * | 2003-11-19 | 2005-05-19 | Wasson Mark D. | Extraction of facts from text |
CA2553552A1 (en) * | 2004-02-11 | 2005-08-25 | Spi Dynamics, Inc. | System and method for testing web applications with recursive discovery and analysis |
US7379846B1 (en) * | 2004-06-29 | 2008-05-27 | Sun Microsystems, Inc. | System and method for automated problem diagnosis |
US8296722B2 (en) * | 2008-10-06 | 2012-10-23 | International Business Machines Corporation | Crawling of object model using transformation graph |
US9043919B2 (en) * | 2008-10-21 | 2015-05-26 | Lookout, Inc. | Crawling multiple markets and correlating |
US9367680B2 (en) * | 2008-10-21 | 2016-06-14 | Lookout, Inc. | System and method for mobile communication device application advisement |
US8745592B1 (en) | 2010-01-08 | 2014-06-03 | Google Inc. | Input selection for automatic test suite generation |
CN102404281B (en) * | 2010-09-09 | 2014-08-13 | 北京神州绿盟信息安全科技股份有限公司 | Website scanning device and method |
US9881050B2 (en) * | 2010-10-29 | 2018-01-30 | Orange | Method and system to recommend applications from an application market place to a new device |
US8880588B2 (en) * | 2010-10-29 | 2014-11-04 | Fujitsu Limited | Technique for stateless distributed parallel crawling of interactive client-server applications |
US8990183B2 (en) * | 2012-06-06 | 2015-03-24 | Microsoft Technology Licensing, Llc | Deep application crawling |
US9317693B2 (en) * | 2012-10-22 | 2016-04-19 | Rapid7, Llc | Systems and methods for advanced dynamic analysis scanning |
US9396237B1 (en) * | 2013-02-12 | 2016-07-19 | Focus IP Inc. | Monitoring applications for infringement |
US9171003B2 (en) * | 2013-03-15 | 2015-10-27 | Western Digital Technologies, Inc. | Shared media crawler database method and system |
US20150095305A1 (en) * | 2013-09-30 | 2015-04-02 | International Business Machines Corporation | Detecting multistep operations when interacting with web applications |
US10078502B2 (en) * | 2014-06-19 | 2018-09-18 | Fujitsu Limited | Verification of a model of a GUI-based application |
CN107341398B (en) * | 2016-04-29 | 2020-07-07 | 腾讯科技（深圳）有限公司 | Program evaluation method and device |
CN106021112A (en) * | 2016-05-31 | 2016-10-12 | 腾讯科技（深圳）有限公司 | Program testing system, method and device |
CN106294159B (en) * | 2016-08-12 | 2018-05-22 | 腾讯科技（深圳）有限公司 | A kind of control method of screenshotss and screenshotss control device |
-
2018
- 2018-08-22 US US16/109,453 patent/US11055209B2/en active Active
- 2018-09-13 CN CN201880049868.7A patent/CN110959153B/en active Active
- 2018-09-13 WO PCT/US2018/050951 patent/WO2019125546A1/en unknown
- 2018-09-13 EP EP18779956.4A patent/EP3635563B1/en active Active
Also Published As
Publication number | Publication date |
---|---|
WO2019125546A1 (en) | 2019-06-27 |
EP3635563B1 (en) | 2022-11-02 |
US11055209B2 (en) | 2021-07-06 |
CN110959153B (en) | 2023-12-08 |
US20190196947A1 (en) | 2019-06-27 |
CN110959153A (en) | 2020-04-03 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11880270B2 (en) | Pruning and prioritizing event data for analysis | |
US10346292B2 (en) | Software component recommendation based on multiple trace runs | |
CN110741354B (en) | Presenting differences between code entity calls | |
JP2019520649A (en) | Process visualization platform | |
CN109325195A (en) | Rendering method and system, computer equipment, the computer storage medium of browser | |
US9053241B2 (en) | Scripting application with role identification | |
EP3635563B1 (en) | Application analysis with flexible post-processing | |
US9135591B1 (en) | Analysis and assessment of software library projects | |
EP3069266B1 (en) | Determination of production vs. development uses from tracer data | |
US9658948B2 (en) | Workload mapper for potential problem areas using modules and defect data | |
US10540360B2 (en) | Identifying relationship instances between entities | |
US20230289444A1 (en) | Data traffic characterization prioritization | |
US10275595B2 (en) | System and method for characterizing malware | |
US20120290342A1 (en) | Product lifecycle management techniques | |
US8689196B2 (en) | Display of data from parallel programming contexts | |
US20160371169A1 (en) | Use case fingerprinting and capture store | |
US20150006498A1 (en) | Dynamic search system | |
US9972109B2 (en) | Implementing out of order access to reversal operations in images | |
US8539171B2 (en) | Analysis and timeline visualization of storage channels | |
WO2022230189A1 (en) | Test support device, test support method, and program | |
KR20190120983A (en) | Apparatus and method for testinig appalication | |
CN114969759A (en) | Asset safety assessment method, device, terminal and medium for industrial robot system | |
CN116361803A (en) | Vulnerability detection method and device | |
CN115202720A (en) | Data display method, device, equipment and storage medium | |
US20190057017A1 (en) | Correlation Of Function Calls To Functions In Asynchronously Executed Threads |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: UNKNOWN |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE INTERNATIONAL PUBLICATION HAS BEEN MADE |
|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: REQUEST FOR EXAMINATION WAS MADE |
|
17P | Request for examination filed |
Effective date: 20200110 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
DAV | Request for validation of the european patent (deleted) | ||
DAX | Request for extension of the european patent (deleted) | ||
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
INTG | Intention to grant announced |
Effective date: 20220126 |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: REQUEST FOR EXAMINATION WAS MADE |
|
INTC | Intention to grant announced (deleted) | ||
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
INTG | Intention to grant announced |
Effective date: 20220713 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE PATENT HAS BEEN GRANTED |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EPRef country code: ATRef legal event code: REFRef document number: 1529250Country of ref document: ATKind code of ref document: TEffective date: 20221115 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602018042594Country of ref document: DE |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: FPRef country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG9D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 1529250Country of ref document: ATKind code of ref document: TEffective date: 20221102 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20230302Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20230202Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: RSFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20230302Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20230203 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230506 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SMFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602018042594Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102Ref country code: ALFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102 |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
26N | No opposition filed |
Effective date: 20230803 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: NLPayment date: 20230926Year of fee payment: 6Ref country code: GBPayment date: 20230927Year of fee payment: 6 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20221102 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: DEPayment date: 20230927Year of fee payment: 6 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |