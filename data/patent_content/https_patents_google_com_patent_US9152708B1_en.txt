BACKGROUND
This specification relates to presenting content.
Users can access videos through video hosting websites. These video hosting websites allow users to search for videos, for example, by submitting a query containing one or more keywords. Once a user identifies a video of interest, these video hosting websites display the video, for example, on a video watch page. The watch page includes the video itself, and may also include other information. For example, the watch page can include links to related videos for the video being displayed or advertisements relevant to the video being displayed.
SUMMARY
In general, one aspect of the subject matter described in this specification can be embodied in methods that include the actions of maintaining a store of data, the data associating each of a plurality of target videos with a respective plurality of co-watched videos for the target video, wherein each co-watched video for a target video was viewed by a user within a time window of when the same user viewed the target video, the data further associating each co-watched video with one or more keywords for the co-watched video; generating, for each target video in the plurality of target videos, one or more target video specific clusters of co-watched videos for the target video, wherein the clusters are generated according to the keywords for each co-watched video; and storing data identifying the clusters for each target video, wherein the data indexes the clusters for each target video according to the corresponding target video. Other embodiments of this aspect include corresponding systems, apparatus, and computer programs recorded on computer storage devices, each configured to perform the operations of the methods.
These and other embodiments can each optionally include one or more of the following features. The method can further include selecting content related to a first target video according to the clusters for the first target video. The content can be a first co-watched video selected from one of the clusters for the first target video.
The method can further include selecting a plurality of related videos for a first target video, the selecting comprising identifying the clusters for the first target video from the stored data, and selecting a co-watched video from each of the clusters. The method can further include, for each target video: determining a score for each cluster associated with the target video; and identifying one or more clusters as being off-topic for the target video according to the scores.
Each co-watched cluster can be associated with one or more keywords. The method can further include receiving input requesting presentation of a first target video; identifying content to present with the first target video according to one or more of the keywords associated with the clusters for the first target video; and presenting the first target video along with the content. The content can be an advertisement.
The method can further include receiving data identifying a set of initial videos responsive to a query; selecting a cluster of co-watched videos for an initial target video selected from the initial videos, wherein the cluster of co-watched videos is selected according to how well the keywords associated with the cluster match the query; and presenting one or more of the initial videos and one or more of the co-watched videos from the selected cluster in response to the query. The method can further include receiving data identifying a set of target videos responsive to a query, wherein the target videos are ordered according to a respective result score for each target video, and wherein the target videos include a first target video having a first rank and a second target video having a second rank below the first rank; determining that the second target video is in a cluster of co-watched videos for the first target video; and presenting the target videos in a different order according to a score adjustment for the second target video.
Each co-watched video for a target video can have been viewed by a user after the user submitted a first search query, and the target video can have been viewed by the user after the user submitted a second search query, and the first search query can be similar to the second search query. One or more of the co-watched videos for a target video can have been selected by a user from a watch page on which the user viewed the target video. The time window can be defined by an amount of time. The time window can be defined by a number of videos viewed by the user. The keywords for each video can include keywords from a title associated with the video. The keywords for each video can include a query submitted by a user, wherein the user viewed the video after the video was presented as a search result for the query.
In general, another aspect of the subject matter described in this specification can be embodied in methods that include the actions of storing data for each of a plurality of target videos, the data for each target video associating the target video with one or more clusters of co-watched video for the target video; receiving input from a user requesting presentation of a first target video; selecting a plurality of related videos for the first target video, the selecting comprising: identifying two or more of the clusters for the first target video from the stored data; and selecting a co-watched video from each of the identified clusters; and presenting the first target video along with a representation of each of the plurality of related videos. Other embodiments of this aspect include corresponding systems, apparatus, and computer programs recorded on computer storage devices, each configured to perform the operations of the methods.
These and other embodiments can each optionally include one or more of the following features. The method can further include identifying one or more clusters as being off-topic for the target video, wherein the identified clusters are each cluster for the first target video except the off-topic clusters. Identifying one or more clusters as being off-topic for the target video can include determining a cluster score for each of clusters, wherein the cluster score is determined from a respective co-watched score for each video in the cluster; and identifying each cluster whose cluster score does not satisfy a threshold as an off-topic cluster.
The data for each target video can further include a video score for each video in each cluster. Selecting a co-watched video from each of one or more of the clusters can include selecting the co-watched video in each of the one or more clusters having a highest video score of co-watched videos in the cluster. The video score for each co-watched video in each cluster can be derived from a co-watched score for the co-watched video and the target video.
The representation of each of the plurality of related videos can be a selectable user interface element on a graphical user interface. The selectable user interface element can include a hyperlink.
Each co-watched video for a target video can have been viewed by a user within a time window of when the same user viewed the target video. Each co-watched video for a target video can have been viewed by a user after the user submitted a first search query, and the target video can have been viewed by the user after the user submitted a second search query, and the first search query can be similar to the second search query. One or more of the co-watched videos for a target video can have been selected by a user from a watch page on which the user viewed the target video. The time window can be defined by an amount of time. The time window can be defined by a number of videos viewed by the user.
In general, another aspect of the subject matter described in this specification can be embodied in methods that include the actions of storing data for each of a plurality of target videos, the data for each target video identifying one or more clusters of co-watched videos for the target video, wherein each cluster is associated with one or more keywords for the cluster; receiving input requesting presentation of a first target video; identifying first content to present with the first target video, wherein the first content is content matching one or more keywords for the clusters of co-watched videos for the first target video; and presenting the first target video along with the first content. Other embodiments of this aspect include corresponding systems, apparatus, and computer programs recorded on computer storage devices, each configured to perform the operations of the methods.
These and other embodiments can each optionally include one or more of the following features. Identifying first content to present with the first target video can include: storing associations between keywords and content; matching one or more of the keywords for the clusters of co-watched videos for the target video to one or more keywords associated with first content; and identifying the first content to present with the first target video. Matching one or more of the keywords for the clusters of co-watched videos for the target video to one or more keywords associated with the first content can include: identifying one or more of the clusters of co-watched videos as off-topic clusters; and matching one or more of the keywords for clusters other than the off-topic clusters to the keywords associated with the first content. Identifying one or more clusters as being off-topic for the target video can include determining a cluster score for each of the clusters, wherein the cluster score is determined from a respective co-watched score for each video in the cluster; and identifying each cluster whose cluster score does not satisfy a threshold as an off-topic cluster. The first content can be an advertisement.
Each co-watched video for a target video can have been viewed by a user within a time window of when the same user viewed the target video. Each co-watched video for a target video can have been viewed by a user after the user submitted a first search query, and the target video can have been viewed by the user after the user submitted a second search query, and the first search query can be similar to the second search query. One or more of the co-watched videos for a target video can have been selected by a user from a watch page on which the user viewed the target video. The time window can be defined by an amount of time. The time window can be defined by a number of videos viewed by the user.
In general, another aspect of the subject matter described in this specification can be embodied in methods that include the actions of storing data for each of a plurality of target videos, the data for each target video associating the target video with one or more clusters of co-watched videos for the target video, wherein each cluster is associated with one or more keywords; receiving a query and obtaining data identifying initial videos responsive to the query; selecting a cluster of co-watched videos for an initial target video selected from the initial videos responsive to the query, wherein the cluster of co-watched videos is selected according to how well the keywords associated with the cluster match the query; generating an augmented list of responsive videos, the augmented list including the initial videos and one or more of the co-watched videos in the selected cluster; and presenting the augmented list of videos in response to the query. Other embodiments of this aspect include corresponding systems, apparatus, and computer programs recorded on computer storage devices, each configured to perform the operations of the methods.
These and other embodiments can each optionally include one or more of the following features. The method can further include selecting a cluster of co-watched videos for each of a group of the initial target videos, wherein the augmented set of videos further includes one or more of the co-watched videos in each selected cluster. Each of the initial videos can have an associated result score and the group of the initial target videos can include all initial target videos whose result score satisfies a threshold. Each of the initial videos can have an associated result score and the group of the initial target videos includes a number of highest scored videos chosen from the initial videos.
Each cluster of co-watched videos can have an order. The method can further include ordering the co-watched videos in the augmented list of video search results in the same order the co-watched videos have in the cluster of co-watched videos. The search results for the co-watched videos can immediately follow the search result for the corresponding initial target video in the augmented list of video search results, without any intervening search results. Each cluster of co-watched videos can be ordered according to a video score for each video in the list, and the video score for each co-watched video can be derived from a quality score of the co-watched video and a co-watched score for the co-watched video and the target video. The method can further include determining that the number of initial search results does not satisfy a threshold.
Each co-watched video for a target video can have been viewed by a user within a time window of when the same user viewed the target video. Each co-watched video for a target video can have been viewed by a user after the user submitted a first search query, and the target video can have been viewed by the user after the user submitted a second search query, and the first search query can be similar to the second search query. One or more of the co-watched videos for a target video can have been selected by a user from a watch page on which the user viewed the target video. The time window can be defined by an amount of time. The time window can be defined by a number of videos viewed by the user.
In general, another aspect of the subject matter described in this specification can be embodied in methods that include the actions of storing data for each of a plurality of target videos, the data for each target video associating the target video with one or more clusters of co-watched videos for the target video; receiving a query and obtaining data identifying target videos responsive to the query, wherein the target videos are ranked according to a respective score for each target video, and wherein the target videos include a first target video having a first rank and a second target video having a second rank below the first rank; determining a score adjustment for the second target video according to a determination that the second target video is included in a cluster of co-watched videos for the first target video; and presenting the initial videos in an order according to the scores and score adjustments for the videos. Other embodiments of this aspect include corresponding systems, apparatus, and computer programs recorded on computer storage devices, each configured to perform the operations of the methods.
These and other embodiments can each optionally include one or more of the following features. Each co-watched cluster can be associated with one or more keywords. The method can further include selecting the cluster of co-watched videos for the first target video according to how well the keywords associated with the cluster match the query. The method can further include determining that the first target video has a result score that exceeds a threshold before determining a score adjustment for the second target video. The score adjustment for the second target video can be determined according to a co-watched score for the second target video and the first target video. The score adjustment can have an initial value if the co-watched score is below a first threshold and a capped value if the co-watched score is above a second threshold.
Each co-watched video for a target video can have been viewed by a user within a time window of when the same user viewed the target video. Each co-watched video for a target video can have been viewed by a user after the user submitted a first search query, and the target video was viewed by the user after the user submitted a second search query, and the first search query is similar to the second search query. One or more of the co-watched videos for a target video can have been selected by a user from a watch page on which the user viewed the target video. The time window can be defined by an amount of time. The time window can be defined by a number of videos viewed by the user.
Particular embodiments of the subject matter described in this specification can be implemented so as to realize one or more of the following advantages. Co-watched videos for a particular target video can be clustered by keywords associated with the videos. These clusters can be used to generate more diverse sets of related video suggestions for the target video. Keywords associated with the cluster can be used as a representation of the target video. These keywords can be used to trigger related content for a given video, including advertisements. The keywords can be used by classifiers to classify the videos. The clusters can also be used to increase the number of search results responsive to a given query, or to modify the ranking of search results responsive to the query.
The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
BRIEF DESCRIPTION OF THE DRAWINGS
FIG. 1 illustrates an example keyword-based clustering engine.
FIG. 2 illustrates an example technique for identifying co-watched videos.
FIG. 3A illustrates user interactions with video search results over time, and the resulting co-watched video data.
FIG. 3B illustrates an example watch page user interface displaying a video.
FIG. 4 illustrates an example technique for generating target-video specific clusters of co-watched videos.
FIG. 5 illustrates an example technique for using clusters of co-watched videos to identify diverse related videos for a target video.
FIG. 6 illustrates an example technique for using keywords associated with clusters of co-watched videos for a given target video to identify content to present along with the target video.
FIG. 7 illustrates an example video search system for providing search results relevant to submitted queries.
FIG. 8 illustrates an example technique for using clusters of co-watched videos to generate an augmented list of search results responsive to a query.
FIG. 9 illustrates an example technique for using clusters of co-watched videos to re-order a list of search results responsive to a query.
Like reference numbers and designations in the various drawings indicate like elements.
DETAILED DESCRIPTION
FIG. 1 illustrates an example keyword-based clustering engine 102. The keyword-based clustering engine 102 receives data 104 associating target videos with co-watched videos and data 106 associating videos with keywords. The system processes this data to generate, for each target video, keyword-based clusters of co-watched videos for the target video.
The target videos to co-watched videos data 104 associates target videos with their co-watched videos. In general, a video is a co-watched video for a target video if a user watches the co-watched video within a time window of when the same user watches the target video. Examples of time windows are described below, with reference to FIG. 2. A user watches a video when the user causes the video to be played on his or her computer. Users can watch the co-watched video and then the target video, or can watch the target video and then the co-watched video. Additional criteria for determining when a video is a co-watched video can also be used, as described below with reference to FIGS. 2-3B. The target videos to co-watched videos data can be generated, for example, as described below with reference to FIG. 2.
In some implementations, the target videos to co-watched videos data 104 also includes a co-watched score for each co-watched video and target video. The co-watched score for a co-watched video and a target video is derived from the number of times users watched the co-watched video within the time window of when the users watched the target video. The co-watched score can be a weighted measure, where each time the video is watched is weighted by a factor derived from an amount of time, or a number of watched videos, between when the target video and the co-watched video were watched. The factor can be derived, for example, from a step function, a linear function, a logarithmic function, or some other function. The co-watched score for a co-watched video can also be weighted, for example, by an aggregate click-through-rate for the video, e.g., the number of times users selected the video divided by the number of times an option to select the video was presented to users.
The video to keywords data 106 associates each of the co-watched videos with keywords for the co-watched video. In some implementations, the keywords associated with the co-watched video are selected from metadata for the video. Metadata is information about the video that is associated with the video and can include, for example, one or more of a title of the video, a description of the video, and labels identifying the contents of the video. Metadata can be data included in a video file for the video, data that is separate from the video file for a video, or both.
In some implementations, the keywords associated with the co-watched video are derived from search logs. A search log can include entries associating a query with a video presented as a search result for the query and selected by a user. A user selects a video, for example, by clicking on the video, therefore causing the video to be played. Each search log entry can additionally include the length of time the user viewed the video after the video was selected. The keywords are derived from the search logs, for example, by selecting one or more search queries associated with the video in a search log entry. In some implementations, all search queries are associated with the video as keywords. In other implementations, fewer than all of the search queries are associated with the video as keywords. In these implementations, the search queries associated with the video as keywords can be, for example, a top number of queries most frequently associated with the video in the search log. In some of these implementations, the length of time the video was watched must exceed a threshold for the association to be counted. The threshold can be an absolute amount of time or a percentage of the length of the video.
Other techniques for associating keywords with videos can also be used, either in addition to, or as an alternative to, the techniques described above. For example, the keywords can be selected from anchor text from anchors that link to the video.
The keyword-based clustering engine 102 identifies the clusters for a given target video 108 by clustering the co-watched videos associated with the target video in the target-videos to co-watched videos data 104 according to the keywords associated with the co-watched videos in the data 106. The keyword-based clustering engine 102 can perform this clustering, for example, using conventional clustering techniques on the keywords.
In some implementations, the system first generates a pseudo-query from the keywords associated with each video, and then clusters videos based on the pseudo queries, for example, using conventional clustering techniques. Conventional techniques can be used to generate the pseudo-queries from the keywords. These conventional techniques can include, for example, stemming keywords and removing keywords that are stop words.
Other conventional keyword-based clustering techniques can alternatively be used in addition to pseudo-query clustering techniques.
In some implementations, the keyword-based clustering engine 102 ranks the co-watched videos in each target-specific cluster for a given target video relative to the other co-watched videos in the cluster. The keyword-based clustering engine 102 determines the ranks according to a video score for each video. The video score can be determined, for example, from the co-watched score for the co-watched video and the target video, a quality score for the co-watched video, or both.
The quality score is a query-independent measure of the quality of the co-watched video. For example, the quality score can be derived from a number of web pages, or number of web pages having a quality score above a threshold, that link to the video. Alternatively or additionally, the quality score can be derived from a number of times that users watched the video. The quality score can be received, for example, from a search engine or a video hosting system.
In some implementations, the keyword-based clustering engine 102 associates each cluster for a target video with the keywords used to generate the cluster. For example, if the clusters are generated according to pseudo-queries, the pseudo-query for each cluster can be associated with the cluster.
FIG. 2 illustrates an example technique 200 for identifying co-watched videos. For convenience, the example technique 200 will be described in reference to a system that performs the technique 200. The system can be, for example, a video hosting system.
The system maintains log data identifying videos watched by a user (202). The log data is preferably anonymized for user privacy protection, for example, as described below. The log data is made up of records of individual user interactions with individual videos watched by users. User interactions can include, for example, using controls for video playback, e.g., play, pause, fast-forward, and rewind. User interactions can also include interactions with the video hosting system, e.g., entering a new search for videos or selecting a different video to watch.
Each record in the log data includes an identifier of the user, an identifier of the video, an identification of the interaction, a length of the interaction, and a time the interaction took place. The identifier of the user is preferably anonymized for privacy protection. For example, each user can be identified by an Internet protocol (IP) address of a corresponding user device used by the user, or can be identified according to a unique random number that is associated with the IP address of the user device. Thus, the user data is not associated with and does not identify a particular user. Other anonymization processes, such as hashing, encryption and obfuscation techniques, can also be used to ensure that user privacy is protected.
The system determines whether a user positively interacted with each video (204). In some implementations, merely watching any part of the video is considered a positive interaction. In other implementations, the system examines a user's individual interactions with the video to determine if the interactions are positive or negative. For example, if the user viewed the video for at least a threshold amount of time, the system can identify the viewing interaction as a positive interaction. The threshold can be an absolute amount of time or a percentage of the length of the video. The threshold can be determined, for example, empirically, to trade off between identifying too many, and too few, viewings as positive interactions. In some implementations, the threshold is the entire length of the video. Another signal the system can consider is whether the user rewound some or all of the video. Rewinding the video is a positive interaction because it indicates the user found some part of the video worth watching again. The system can compare the amount rewound to a threshold to determine if the rewinding signifies a positive interaction.
As another example, the system can determine whether the user rated the video. For example, if the user assigned a positive rating to the video, the user's interactions with the video can be identified as positive interactions.
The system can also identify various negative interactions, for example, viewing a video for less than a threshold amount of time or assigning a low rating to the video. Other negative interactions include, for example, performing another search or opening another web page, as both of these actions may indicate that the user was not satisfied with the video.
The system then determines whether the overall user interactions of a particular user with the video was positive or negative. For example, if the majority of the user interactions for a user and a video were positive, the system determines the overall user interaction for the user with the video was positive. Similarly, if the majority of the user interactions of the user with the video were negative, the system determines that the overall user interaction for the user with the video was negative.
The system identifies co-watched videos (206). The system first identifies co-watched videos for individual users, and then aggregates this data across all users.
To determine co-watched videos for individual users, the system sequences the videos watched by each user in time, according to when the user watched the video. Two videos are co-watched when a user's overall interactions with both videos during a window of time were positive. The window of time can be defined, for example, by an amount of time or a number of videos.
In some implementations, the window of time is a predetermined window of time, for example, that is determined empirically, for example, according to estimates of how long users tend to browse videos on the same topic. In other implementations, the window of time is a dynamic window of time that can vary based on various factors including user activity level and whether a user performs a search during a viewing session. For example, the window of time can be shorter when a user activity level is high, e.g., when the user views videos in rapid succession. As another example, the time window can be determined so that it never spans a user search. For example, if a user views video A, enters a search query, and enters video b, the time window should not include both videos A and B. As yet another example, the time window can be determined so that it only spans similar user searches. For example, if a user searched for a query, viewed video A, then entered a similar query, and viewed video B, the time window could be defined to include both video A and video B. Two queries are similar, for example, when they differ in the use of synonyms, stop words, or small spelling differences. For example, the system can apply conventional stemming, normalization, and stop word removal techniques to both queries. After that is done, if the resulting queries have more than a threshold number of words in common, the system can determine that the two queries are similar. In some implementations, the threshold is 100%. Other thresholds can also be used.
In some implementations, the system only identifies videos as being co-watched when they were watched within a time window of each other and under specific circumstances. For example, the system might require that the videos be selected from a video search results page after the same search, or after similar queries. Alternatively, the system might require that a co-watched video be selected from a watch page for a target video. In some implementations, the system requires that either the videos be selected from a video search results page after the same or similar searches or that the co-watched video be selected from a watch page for a target video. An example of videos selected from a video search results page after the same or similar searches and an example of a video selected from a watch page are described below, with reference to FIGS. 3A and 3B.
Once the system determines the co-watched videos for individual users, the system aggregates the data to generate the target video to co-watched video data 104 described above with reference to FIG. 1. The system can determine a number of times a given video is co-watched with a given target video. Sometimes the co-watched association is two way, for example, if video A is co-watched for video B, then video B is co-watched for video A. Sometimes, the co-watched association is one way, for example, video A is co-watched for video B, but video B is not co-watched for video A. For example, this one way association can be used when a video A is viewed from the watch page for video B, as described below with reference to FIG. 3B. In some implementations, the association is one way when video A has a number of co-watched videos satisfying a threshold, and otherwise is two way.
In some implementations, the system only associates a co-watched video with a target video when the co-watched score for the co-watched video and the target video satisfies, e.g., exceeds, a threshold. The system can determine a co-watched score for a given target video and co-watched video according to the number of times the co-watched video was identified as a co-watched video for the target video, as described above with reference to FIG. 1.
FIG. 3A illustrates user interactions with video search results over time, and the resulting co-watched video data.
The user first views search results in a video search user interface 302 that are responsive to the search query “Search A” 304. The video search user interface 302 displays video search results 306, 308, and 310 that are responsive to the query 304.
The user selects, e.g., clicks on, video search results responsive to the query and is taken to video watch pages for each selected video. The user can watch each video from its video watch page. In FIG. 3A, the user selects the search result 306 for video A, watches video A, and then returns to the search result page, selects the search result 310 for video C, and then watches video C.
The user then submits a second query 312 in the search user interface 302. This second query is for “Search A′.” The user is presented with search results 314 and 316, and selects search result 314 for Video D.
Co-watched data 318 is generated from these user interactions. For example, the user watched video A and video C after the same query “Search A” 304. Therefore, the co-watched data associates videos A and C. The user watched video D after submitting the search query “Search A′” 312. Although the queries 304 and 312 are not identical, they are sufficiently similar, for example, according to the standards described above with reference to FIG. 1, to relate video D to videos A and C as co-watched videos. This association is also reflected in the co-watched data.
FIG. 3B illustrates an example watch page user interface 352 displaying video F 354. The watch page includes video F 354 and also includes representations of related videos 356 for video F 354. The representations of the related videos 356 are presented as selectable user interface elements. The selectable user interface elements include a title of the video (e.g., “Video G”), a description of the video (e.g., “Description of Video G”), and an image representing the video, for example, a frame from the video. Other selectable user interface elements can alternatively be used. A user can view one of the related videos by selecting the selectable user interface element corresponding to the video.
For example, in FIG. 3B, a user selects video H 358. The co-watched video data 360 therefore indicates that video H is a co-watched video for video F. Because video H was watched from a watch page of video F, the association is a one-way association. Therefore video F is not a co-watched video for video H.
FIG. 4 illustrates an example technique 400 for generating target-video specific clusters of co-watched videos. For convenience, the example technique 400 will be described in reference to a system that performs the technique 400. The system can be, for example, the keyword-based clustering engine 102.
The system maintains a store of data associating target videos with co-watched videos, and data associating each co-watched video with one or more keywords (402). This data is described in more detail above with reference to FIGS. 1-3.
The system generates, for each target video, one or more target video-specific clusters of co-watched videos (404). The clusters are generated according to keywords associated with the co-watched videos. For example, the system can generate the clusters as described above with reference to FIG. 1.
The system stores data identifying the clusters for each target video (406). The data indexes the clusters for each target video according to the target video.
Once generated, the clusters for each target video can be used in various applications, some examples of which are given below.
FIG. 5 illustrates an example technique 500 for using clusters of co-watched videos to identify diverse related videos for a target video. For convenience, the example technique 500 will be described in reference to a system that performs the technique 500. The system can be, for example, a video hosting system.
The system stores data associating target videos with one or more clusters of co-watched videos for the target video (502). The data can be generated, for example, as described above with reference to FIGS. 1-4.
The system receives input requesting presentation of a target video (504). The input is received, for example, when a user requests that a watch page for the target video be presented. The user can make this request by entering a URL associated with a watch page for the target video, or by selecting a selectable user interface element to indicate that the watch page for the target video should be displayed. The selectable user interface element can be a search result or a related video representation, for example, as described above with reference to FIGS. 3A and 3B.
The system selects related videos for the target video from the stored data (506). The system makes this selection by selecting two or more of the clusters for the first target video from the stored data, and then selecting a co-watched video from each selected cluster.
In some implementations, the system identifies each cluster for the first target video as being on-topic or off-topic. Off-topic clusters are clusters that are only tangentially related to the first target video. In some implementations, off-topic clusters are determined according to a cluster score for each cluster. The cluster score is derived from a co-watched score for each video in the cluster and the target video. The co-watched score for a co-watched video and a target video is described above with reference to FIG. 1. The cluster score for a cluster can be determined, for example, by summing, averaging, or otherwise combining the co-watched scores for the co-watched videos in the cluster. If the cluster score of a cluster fails to satisfy a threshold, the cluster is an off-topic cluster. In some implementations, the threshold is a pre-determined value determined, for example, empirically, to trade off between identifying too many clusters as off-topic clusters and identifying too few clusters as off-topic clusters. In other implementations, the threshold is determined relative to the cluster scores for the clusters associated with the first target video. For example, the threshold can be the median cluster score of the clusters.
In some implementations, the system selects the co-watched video from each cluster that has a highest video score of each video in the cluster. The video score for a co-watched video can be derived, for example, as described above with reference to FIG. 1, from the co-watched score for the co-watched video and the target video, a quality score of the target video, or both. In other implementations, the system selects a co-watched video at random from each cluster. In some implementations, the system selects more than one co-watched video from each cluster.
The system presents the target video and a representation of each related video (508). The system presents the target video and the representation of each related video, for example, by generating a watch page from which a user can play the target video and select from among the related videos. An example watch page is described above with reference to FIG. 3B.
The representation of each related video can be a selectable user interface element on a graphical user interface. For example, the selectable user interface element can include a hyperlink in the watch page. The representation can optionally include details about the related video, for example, the title of the video, the description of the video, or a frame from the video, for example, as described above with reference to FIG. 3B.
FIG. 6 illustrates an example technique 600 for using keywords associated with clusters of co-watched videos for a given target video to identify content to present along with the target video. For convenience, the example technique 600 will be described in reference to a system that performs the technique 600. The system can be, for example, a video hosting system.
The system stores clusters of co-watched videos for target videos and keywords associated with each cluster (602). The system associates the clusters with their respective target videos. The clusters and keywords can be generated, for example, as described above with reference to FIGS. 1-4.
The system receives input requesting presentation of a first target video (604). The input can be received, for example, as described above with reference to FIG. 5.
The system identifies content to present with the target video according to the keywords associated with the clusters of co-watched videos for the target video (606). To aid in this identification, the system stores data associating keywords with content. The content can be, for example, advertisements, videos, images, or multimedia content. The system identifies the content by matching the keywords from the clusters of co-watched videos for the target video to keywords associated with a particular piece of content, and then identifying the particular content. The system can use conventional techniques for performing this matching. When keywords for the clusters match multiple pieces of content, the system can select one of the matching pieces of content, for example, using conventional techniques.
In some implementations, the system uses keywords associated with only some of the clusters of co-watched videos for the target video. For example, the system can calculate a cluster score for each of the clusters, as described above with reference to FIG. 5, and use only keywords associated with clusters whose cluster scores satisfy a threshold, or a number of top-scoring clusters. In some implementations, the system identifies one or more of the clusters as off-topic clusters and does not use the keywords associated with the off-topic clusters. The system can identify an off-topic cluster, for example, as described above with reference to FIG. 5.
The system presents the target video along with the identified content (608). The system presents the target video and the identified content, for example, by generating a watch page where a user can play the target video and view and optionally interact with the content.
FIG. 7 illustrates an example video search system 714 for providing search results, e.g., videos, relevant to submitted queries as can be implemented in an Internet, an intranet, or other client and server environment. The video search system 714 is an example information retrieval system.
A user 702 interacts with the video search system 714 through a client device 704. For example, the client device 704 can be or include a computer (e.g., a personal computer, a mobile phone, etc.) coupled to the search system 714 through a wired or wireless local area network (LAN) or wide area network (WAN), e.g., the Internet. In some implementations, the video search system 714 and the client device 704 are both implemented in the same machine. For example, a user can install a desktop search application on the client device 704. The client device 704 will generally include a random access memory (RAM) 706 and a processor 708.
A user 702 submits a query 710 to a video search engine 730 within the video search system 714. When the user 702 submits a query 710, the query 710 is transmitted through a network to the search system 714. The video search system 714 can be implemented as, for example, computer programs running on one or more computers in one or more locations that are coupled to each other through a network. In some implementations, the video search system 714 includes an video index database 722 and a video search engine 730. The video search system 714 responds to the query 710 by generating search results 728, which are transmitted through the network to the client device 704 in a form that can be presented to the user 702 (e.g., in a search results web page to be displayed in a web browser running on the client device 704). For example, the search results can include videos responsive to the user query.
When the query 710 is received by the video search engine 730, the video search engine 730 identifies videos that match the query 710. The video search engine 730 will generally include a video indexing engine 720 that indexes videos found by the search system 714, for example, documents found while crawling the Internet, a video index database 722 that stores the index information, and a ranking engine 752 (or other software) to rank the videos that match the query 710, for example, according to a result score associated with each video by the video search engine 730. The result score can be a query-independent measure of the quality of the video, a query-specific measure of how well the video matches the query, or a score derived from both a query-independent measure and a query specific measure. The search engine 730 transmits the search results 728 through the network to the client device 704 for presentation to the user 702.
FIG. 8 illustrates an example technique 800 for using clusters of co-watched videos to generate an augmented list of search results responsive to a query. For convenience, the example technique 800 will be described in reference to a system that performs the technique 800. The system can be, for example, the search system 714 described above with reference to FIG. 7.
The system stores clusters of co-watched videos for target videos (802). The data can be generated, for example, as described above with reference to FIGS. 1-4. The data further associates each cluster with one or more keywords. These keywords can be, for example, the keywords associated with the clusters as described above with reference to FIG. 1.
The system receives a query and obtains initial videos responsive to the query (804). The query and initial videos can be obtained through a search system, for example, as described above with reference to FIG. 7.
The system selects a cluster of co-watched videos for an initial target video (806). The cluster is selected according to how well the keywords associated with the cluster match the query. The system selects the cluster for the initial target video whose keywords best match the query. In some implementations, the system provides the keywords and the query to a match engine that generates a match score representing the quality of the match between the keywords and the query. The system can then select the cluster whose keywords have the best match score. The quality of the match can be measured according to various techniques including string comparison techniques such as edit distance. In some implementations, normalizations and synonym substitutions are also applied to the keywords and the query to determine the quality of the match.
In some implementations, the match score for the best matching cluster must additionally satisfy a threshold in order for the cluster to be selected. The threshold can be determined, for example, empirically, based on an analysis of match scores of various clusters.
The system generates an augmented list of responsive videos including the initial videos and one or more of the co-watched videos in the selected cluster (808).
In some implementations, the co-watched videos in each cluster for the target video are ordered. For example, the co-watched videos in a cluster can be ordered according to a video score derived from a co-watched score for the target video and each co-watched video, a quality score for each co-watched video, or both, as described above with reference to FIG. 1. In these implementations, the one or more co-watched videos selected from a cluster can be, for example, the top scoring videos. Alternatively, the one or more co-watched videos can be selected at random from the cluster.
In some implementations, when the system adds the co-watched videos from a cluster to the augmented list of videos, the system maintains the order the co-watched videos had in the cluster. In some implementations, the co-watched videos for a given initial video appear immediately after the initial video in the augmented list of videos. For example, if video A is associated with a cluster of videos including video B, video C, and video D, ranked in that order, then the augmented list would include video A, video B, video C, and video D, in that order.
In some implementations, the system identifies a group of multiple initial videos responsive to the query. The system selects a cluster of co-watched videos for each of the group of initial videos for inclusion in the augmented list of responsive videos. In these implementations, the augmented list of videos further includes one or more videos from each selected cluster.
When the initial videos have associated result scores or ranks, e.g., determined by the search engine that identified the initial videos, the system can select the group of multiple initial videos according to the result scores or ranks of the initial videos. For example, the system can select all initial videos whose result score satisfies a threshold. As another example, the system can identify a number of top-scoring initial videos, e.g., a number of top-ranked initial videos.
The system presents the augmented list of videos in response to the query (810). For example, the system can send the augmented list of videos to a user device for presentation to a user, as described above with reference to FIG. 7. The videos can be presented in a search results page, for example, as described above with reference to FIG. 3A.
FIG. 9 illustrates an example technique 900 for using clusters of co-watched videos to re-order search results responsive to a query. For convenience, the example technique 900 will be described in reference to a system that performs the technique 900. The system can be, for example, the search system 714 described above with reference to FIG. 7.
The technique described in FIG. 9 promotes videos that are in co-watched clusters for higher-ranked videos. The intuition is that if a first video is highly ranked, and users often watch the first video with the second video, then the second video should have its rank increased.
The system stores clusters of co-watched videos for target videos (902). The clusters can be generated, for example, as described above with reference to FIGS. 1-4.
The system receives a query and obtains data identifying initial videos responsive to the query (904). Each initial video has a result score, and the initial videos are ranked according to their result scores. The result scores can be determined by a search engine. The initial videos include a first target video and a second target video ranked below the first target video, i.e., a second target video having a result score lower than the result score of the first target video. The query and initial videos can be obtained through a search system, for example, as described above with reference to FIG. 7.
The system determines a score adjustment for the second target video (906). The system determines the score adjustment for the second target video according to a determination that the second target video is included in a cluster of co-watched videos for the first target video.
The value of the score adjustment is determined according to a co-watched score for the second target video and the first target video. The score adjustment can also be determined according to additional factors, for example, a result score assigned to the first target video by a search engine. In some implementations, the score adjustment is capped on either the lower or the upper end. For example, the score adjustment can always have an initial value if the co-watched score is less than a first threshold, or can always have a capped value if the co-watched score is greater than a second threshold.
In some implementations, each cluster of co-watched videos for the first target video is associated with one or more keywords, for example, as described above with reference to FIG. 1. In these implementations, the system can select the cluster of co-watched videos for the first target video according to how well the keywords for the cluster match the query, for example, as described above with reference to FIG. 8.
In some implementations, the system determines that the first target video has a result score that satisfies a threshold, or a rank that satisfies a threshold, before the system determines the score adjustment. The result score or rank can be determined, for example, by a search engine as described above with reference to FIG. 7. The threshold can be determined, for example, empirically, based on an analysis of result scores or ranks of search results and an empirical estimate of how good those search results are. The empirical estimate can be determined from human evaluation, or based on data collected for the search results, for example, a click through rate for the search result and a query.
The system presents the initial videos in an order that reflects the score adjustment for the second target video (908). For example, the system can determine an adjusted score for the second target video by applying the score adjustment to the result score for the video and then re-ranking the videos according to the result scores and adjusted scores. Applying the score adjustment to the result score can include, for example, multiplying the result score by the score adjustment or adding the score adjustment to the score. The results can be presented, for example, as described above with reference to FIG. 8.
In some implementations, the system determine score adjustments for multiple videos as described above, applies the score adjustments to the result scores for each of the multiple videos to determine adjusted scores for the videos, and then re-ranks the videos according to the adjusted scores.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a computer storage medium for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions can be encoded on a propagated signal that is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. The computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them.
The term “data processing apparatus” encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing or executing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a universal serial bus (USB) flash drive), to name just a few.
Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to a web browser on a user's client device in response to requests received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), e.g., the Internet.
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, while the foregoing discussion describes clustering co-watched videos, similar techniques can be applied to clustering other types of content including, for example, audio files, documents, images, and multimedia presentations. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In certain implementations, multitasking and parallel processing may be advantageous.