CN108541321A - Program code is mapped to the technique of compiling of the programmable graphics processing hardware platform of high-performance, high effect - Google Patents
Program code is mapped to the technique of compiling of the programmable graphics processing hardware platform of high-performance, high effect Download PDFInfo
- Publication number
- CN108541321A CN108541321A CN201680080956.4A CN201680080956A CN108541321A CN 108541321 A CN108541321 A CN 108541321A CN 201680080956 A CN201680080956 A CN 201680080956A CN 108541321 A CN108541321 A CN 108541321A
- Authority
- CN
- China
- Prior art keywords
- kernel
- processor
- data
- program code
- template
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/41—Compilation
- G06F8/44—Encoding
- G06F8/447—Target code generation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5061—Partitioning or combining of resources
- G06F9/5077—Logical partitioning of resources; Management or configuration of virtualized resources
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2200/00—Indexing scheme for image data processing or generation, in general
- G06T2200/28—Indexing scheme for image data processing or generation, in general involving image processing hardware
Abstract
The present invention describes a kind of method.The method includes compiling the program code for the image processor with programmable templates processor, the programmable templates processor executes channel and shift-register circuit structure composition by corresponding two dimension.Said program code forms for realizing directed acyclic graph and by multiple kernels, these kernels will execute in each template processor, wherein compiling include it is following any one：Number of cores in recognize program code is different from the number of the template processor in image processor；Identify that the computational intensity of at least one of kernel is higher than another in kernel；And the resource requirement of recognize program code is more than the memory capacity of image processor.Compiling further comprises in response to any one of identified above, executing following any one：Level fusion kernel；Vertical fusion kernel；One in kernel is split into multiple kernels；Divide kernel spacing into multiple space partition zone kernels；Directed acyclic graph is divided into smaller figure.
Description
Related application
The application is asked in " the Compiler of 2 months U.S. Provisional Application No. 62/300,684 submitted for 26th in 2016
Techniques For Mapping Program Code To A High Performance、Power Efficient、
The equity of Programmable Image Processing Hardware Platform ", full text are incorporated by reference into this
Text.
Technical field
The technical field of the present invention relates generally to image procossing, and more particularly relating to program code being mapped to can
Program the technique of compiling of image processing hardware platform (programmable graphics of such as high-performance, high effect handle hardware platform).
Background technology
Image procossing is usually directed to the pixel value that processing is organized into array.Here, the two-dimensional array capture figure of spatial organization
The two-dimensional nature of picture (additional dimension may include time (for example, two-dimensional image sequence) and data type (for example, color)).
Under normal conditions, pixelated array value is provided by having generated static image or frame sequence with the camera of capture movement image.Traditional
Image processor typically exhibits two kinds of extreme cases.
The first is extreme execute as in general processor or class general processor (for example, enhancing with vector instruction
General processor) on the image processing tasks of software program that execute.Although the first extreme usually offer highly versatile is answered
With Software Development Platform, but its using more fine-grained data structure and relevant expense (for example, instruction obtains and decoding,
The processing of on piece and the outer data of piece speculates execution), it is a large amount of to eventually lead to the per unit data consumption during executing program code
Energy.
Second of opposite extreme data block that fixed function hard-wired circuitry is applied to bigger.Using directly applying to
The power consumption of per unit data is greatly reduced in the data block of larger (relative to the finer grain) of custom design circuit.However, using
It is limited that the fixed function circuit of custom design typically results in the task-set that processor is able to carry out.As such, second it is extreme in lack
Weary extensive general programmed environment (this is extreme associated with the first).
A technique for the applied software development chance providing highly versatile is combined with improve per unit data the effect of
Platform is still ideal but missing solution.
Invention content
The present invention describes a kind of method.The method includes compiling for the image procossing with programmable templates processor
The program code of device, the programmable templates processor execute channel and shift-register circuit structure group by corresponding two dimension
At.Said program code forms for realizing directed acyclic graph and by multiple kernels, these kernels will be handled in each template
Executed on device, wherein compiling include it is following any one：Identify that the number of cores in said program code is different from described image
The number of template processor in processor；Identify the computational intensity of at least one of described kernel higher than in the kernel
Another；And the resource requirement of identification said program code is more than the memory capacity of described image processor.It is compiled into
One step includes, and in response to any one of identified above, executes following any one：Level fusion kernel；In vertical fusion
Core；One in kernel is split into multiple kernels；Divide kernel spacing into multiple space partition zone kernels；By directed acyclic graph
It is divided into smaller figure.
The present invention describes a kind of equipment.The equipment includes being directed to the image with programmable templates processor for compiling
The device of the program code of processor, the programmable templates processor execute channel and shift register electricity by corresponding two dimension
Line structure forms.Said program code forms for realizing directed acyclic graph and by multiple kernels, these kernels will be each
It is executed in template processor, wherein the device for compiling includes being used for following any one device：Identify described program generation
Number of cores in code is different from the number of the template processor in described image processor；Identify at least one in the kernel
A computational intensity is higher than another in the kernel；And the resource requirement of identification said program code is more than the figure
As the memory capacity of processor.The device for compiling further comprises in response to any one in identified above
It is a to execute the device of following any one：Level fusion kernel；Vertical fusion kernel；One in the kernel is split into
Multiple kernels；Divide kernel spacing into multiple space partition zone kernels；Directed acyclic graph is divided into smaller figure.
Description of the drawings
Following description and attached drawing are for being explained the embodiment of the present invention.In the accompanying drawings：
Fig. 1 shows the embodiment of image processor hardware structure；
Fig. 2 a, Fig. 2 b, Fig. 2 c, Fig. 2 d and Fig. 2 e are depicted is parsed into list by image data analyzing at line-group, by line-group
And the operation that list is executed using overlapping template；
Fig. 3 a show the embodiment of template processor；
Fig. 3 b show the embodiment of the coding line of template processor；
Fig. 4 shows the embodiment of the Data Computation Unit in template processor；
Fig. 5 a, Fig. 5 b, Fig. 5 c, Fig. 5 d, Fig. 5 e, Fig. 5 f, Fig. 5 g, Fig. 5 h, Fig. 5 i, Fig. 5 j and 5k are depicted to be moved using two dimension
Bit array and execution channel array determine the example of a pair of adjacent output pixel value by being overlapped template；
Fig. 6 shows to integrate the embodiment for the cell for executing channel array and two-dimensional shift array；
Fig. 7 shows the process of exploitation and real-time image processing program code；
Fig. 8 is related to configuring the process of image processor；
Fig. 9 a and Fig. 9 b are related to the operation of line buffer unit；
Figure 10 a and Figure 10 b are related to DAG program flows；
Figure 11 a, Figure 11 b and Figure 11 c are related to pipeline program stream；
Figure 12 a and Figure 12 b are related to horizontal kernel fusion process.
Figure 13 a, Figure 13 b and Figure 13 c are related to vertical kernel fusion process.
Figure 14 is related to endomitosis process；
Figure 15 is related to pattern zoning process；
Figure 16 is related to DAG/ assembly line cutting procedures；
Figure 17 a show Compilation Method；
Figure 17 b show program code development environment；
Figure 18 shows exemplary computing system.
Specific implementation mode
A. image processor hardware structure and operation
Fig. 1 shows the embodiment of the framework 100 of hardware-implemented image processor.Image processor may, for example, be volume
The target of device is translated, which is by hardware processor by the program code conversion write for the virtual processor in simulated environment
The program code actually executed.As shown in Figure 1, framework 100 includes by network 104 (for example, network-on-chip (NOC), including piece
Upper exchange network, on piece loop network or other kinds of network) with multiple template processor unit 102_1 to 102_N and right
Multiple line buffer unit 101_1 to 101_M that the form builder unit 103_1 to 103_N answered is interconnected.In a kind of embodiment
In, any line buffer unit can be connected to any form builder and corresponding template processor by network 104.
In one embodiment, program code is compiled and is loaded into corresponding template processor 102 previous to execute
(for example, according to the mode that designs and implements, program code can also be loaded into the image processing operations defined by software developer
On the related form builder 103 of template processor).It, can be by the way that the first pipeline stages will be used at least some examples
The first kernel program be loaded into the first template processor 102_1, will add for the second kernel program of the second pipeline stages
It is downloaded to that the second template processor 102_2 is medium to realize image processing pipeline, wherein the first of the first kernel execution pipeline
The function of grade, the function etc. of the second level of the second kernel execution pipeline, and additional control stream method is installed, so that output
Image data is transmitted to the next stage of assembly line from the level-one of assembly line.
In other configurations, image processor may be implemented as the two or more with operation same kernel program code
The parallel machine of template processor 102_1,102_2.For example, can be by being handled across each multiple template for being performed both by identical function
The extension frame of device handles the image data stream of high density and high data rate.
In another other configurations, any DAG of substantially kernel can be loaded on hardware processor, this is to pass through
Using the respective kernel setup template processor of the program code of template processor itself and by control appropriate in DAG designs
System stream hook is configured to the input for the next kernel for being directed to the output image from a kernel in hardware.
As generalized flowsheet, the frame of image data, which is received by macro I/O units 105 and is transmitted to line based on frame by frame, to be delayed
Rush one or more of device unit 101.Certain line buffer unit by the frame of its image data be parsed into image data compared with
Then line-group is transmitted to specific form builder by zonule, referred to as " line-group " by network 104.It is complete or " complete "
Single line-group can for example be made of that (for the sake of simplicity, this specification will be main the data of multiple continuous full lines of frame or permutation
It is related to continuous row).The line-group of image data is further parsed into the smaller area of image data, referred to as " table by form builder
It is single ", and the list is submitted into its corresponding template processor.
In the case of being flowed with the image processing pipeline individually inputted or DAG, it is however generally that, input frame is directed into
Identical line buffer unit 101_1, the line buffer unit are directed to table by image data analyzing at line-group and by line-group
The code of the first kernel in single generator 103_1, the corresponding positive execution pipeline/DAG of template processor 102_1.In mould
After the line-group that sheet processor 102_1 handles it completes operation, output line mass-sending is sent to " downstream " line by form builder 103_1
(under some use situations, output line-group can be sent back to previously once sent the same of input line-group to buffer unit 101_2
Line buffer unit 101_1).
Then, it indicates in other their own form builders and template processor (for example, form builder 103_2
With template processor 102_2) on next stage/operation in assembly line/DAG for executing one or more " consumer " kernel from
Line downstream buffer unit 101_2 receives the image data generated by the first template processor 102_1.In this way, exist
" producer " kernel for being operated in first template processor outputs it data forwarding to being operated in the second template processor
" consumer " kernel, wherein consistent with the design of entire assembly line or DAG, consumer kernels execute after producer's kernel
Next task-set.
Template processor 102 is designed to operate in multiple overlapping templates of image data simultaneously.Multiple overlapping templates
The size of list is effectively determined with the internal hardware processing capacity of template processor.Here, in template processor 102, hold
Row of channels array consistently operates, handled simultaneously by the image data surface region of multiple overlapping template coverings.
As detailed below, in various embodiments, the two dimension that the list of image data is loaded into template processor 102 is posted
In storage array structure.By the way that mass data is moved in hundreds of circulations space, for example, as single load operation, and
And processing task is directly followed by executed to data by execution channel array, use list and two-dimentional register array structure quilt
It is considered effectively to provide power consumption improvement.In addition, being readily able to using execution channel array and the offer of corresponding register array
The different templates size of programmed/configured.
Fig. 2 a to Fig. 2 e show the parsing activity of line buffer unit 101, form builder unit 103 with high level more
Fine granularity parsing activity and the template of template processor 102 for being coupled to form builder unit 103 handle movable implementation
Example.
Fig. 2 a depict the embodiment of the input frame 201 of image data.It is (every that Fig. 2 a also depict three overlapping templates 202
A template has the size of the pixel of 3 pixels × 3) skeleton diagram, template processor is designed to be operated in these templates.
The output pixel that each self-generating of each template exports image data is highlighted with filled black.For the sake of simplicity, three overlappings
Template 202 is depicted as only being overlapped in vertical direction.It should be appreciated that in fact, template processor can be designed to
All there is overlapping template on both vertically and horizontally.
As shown in Figure 2 a, it due to the vertically superposed template 202 in template processor, is grasped on it in single template processor
There are wideband image data in the frame of work.Discuss as follows, in one embodiment, template processor in a manner of from left to right across
Image real time transfer is overlapped the data (and then repeating next line collection with sequence from top to bottom) in template.Therefore, with template
Processor continues to be carried forward its operation, and the number of the output pixel block of filled black increases to the right level.As described above, line
It is defeated from being enough template processor is made to operate in multiple upcoming periods of expansion that buffer unit 101 is responsible for parsing
Enter the line-group of the input image data of frame.The illustrative plot of line-group is illustrated as shadow region 203.In one embodiment, line
Buffer unit 101 is it will be appreciated that sending/receiving the Different Dynamic of line-group to/from form builder.For example, being known as according to one kind
The pattern of " complete group " transmits the complete overall with line of image data between online buffer unit and form builder.According to second
Kind is known as the pattern of " virtual high ", initially line-group of the transmission with overall with row subset.Then, successively with smaller (being less than overall with)
The remaining row of fragment delivery.
As the line-group 203 of input image data is defined by line buffer unit and is transmitted to form builder unit, table
Line-group is further parsed into the finer list of the hardware limitation of more accurate matching template processor by single generator unit.More
Specifically, described further below, in one embodiment, each template processor is made of two-dimensional shift register array.
Two-dimensional shift register array substantially promotes image data shift often to channel array " lower section ", wherein shift mode is executed
A execution channel operates the data in its each self-template and (is handled in its own template that is, each executing channel
Information to generate the output for the template).In one embodiment, list is " filling " or is otherwise loaded into two
Tie up the surface region of the input image data in shift register array.
As detailed below, in various embodiments, the multiple two dimension deposits that can be shifted on any period be there are in fact
Device data Layer.For convenience, the most contents in this specification will simply use term " two-dimensional shift register " etc.
To refer to the structure of two-dimentional register data layer as the one or more that has and can shift.
Therefore, as shown in Figure 2 b, form builder parses the initial list 204 from line-group 203 and provides it to
Template processor (here, data form corresponds to the shadow region usually indicated by reference numeral 204).Such as Fig. 2 c and Fig. 2 d institutes
Show, template processor is effectively moving overlapping template 202 on list in a manner of from left to right and to input picture number
According to list operated.As shown in Figure 2 d, the pixel number that output valve can be calculated from the data in list is depleted and (does not have
Other location of pixels may have the output valve that the information out of list determines).For the sake of simplicity, the boundary of image is had ignored
Region.
As shown in Figure 2 e, form builder provides next list 205 and continues to operate for template processor again.It should refer to
Go out, template starts when being operated on next list, the initial position of template be exhausted from first list a little to the right
Next process (as shown in preceding Fig. 2 d).Using new table 205, when masterplate processor is in a manner of identical with the first list of processing
When being operated to new table, masterplate will simply continue to move right.
It should be pointed out that due to the borderline region of the template around output pixel position, the data and second of the first list 204
There are some overlappings between the data of list 205.This overlapping overlapped data can be repeatedly transmitted by form builder twice Lai
Carry out simple process.In an alternative embodiment, for next list is fed to template processor, form builder can be after
It is continuous only to send new data to template processor, and template processor reuses the overlapped data from previous list.
B. the design and operation of template processor
Fig. 3 a show the embodiment of template processor framework 300.As shown in figure 3, template processor, which includes data, calculates list
Member 301, scalar processor 302 and associated memory 303 and I/O units 304.Data Computation Unit 301 includes executing
Channel array 305, two-dimensional shift array structure 306 and independent random access memory associated with the specific row or column of array
Device 307.
I/O units 304 are responsible for " input " data form received from form builder being loaded into Data Computation Unit 301
In and simultaneously " output " data form storage of self-template in future processor in form builder.In one embodiment, will
Form data is loaded into the row/column for needing the list that will be received to be parsed into image data in Data Computation Unit 301 and will
The row/column of image data is loaded into two-dimensional shift register structure 306 or executes the corresponding arbitrary access of the row/column of channel array
In memory 307 (as detailed below).If list is initially loaded into memory 307, execute each in channel array 305
It is a execute channel can again in due course (for example, with load instruction just before being operated to worksheet data) by table
Forms data is loaded into from random access memory 307 in two-dimensional shift register structure 306.Complete by data form (no matter
Directly from form builder or from memory 307) be loaded into register architecture 306 after, execute the execution of channel array 305
Channel carries out operation to data and finally arrives form builder or write-in using the data of completion as list directly " writing back "
In random access memory 307.If later, I/O units 304 obtain data to form output from random access memory 307
List is then forward it to form builder.
Scalar processor 302 includes cyclelog 309, and the program of template processor is read from scalar memory 303
Code instructs and these instructions is published to the execution channel executed in channel array 305.In one embodiment, individually
Identical instruction is broadcast to all execution channels in array 305, to realize the similar SIMD from Data Computation Unit 301
Behavior.In one embodiment, it is read from scalar memory 303 and is published to the execution channel for executing channel array 305
The instruction format of instruction include very long instruction word (VLIW) type format, it includes more than one operation code to make every instruction.Another
In a kind of embodiment, VLIW formats include instruct by each ALU for executing channel mathematical functions executed ALU operation code (such as
It is lower described, in one embodiment, the ALU operation that more than one can be specified traditional) and (its guidance of storage operation code
For specific execution channel or execute the storage operation gathered in channel).
Term " executing channel " refers to the set for the one or more execution units for being able to carry out instruction (for example, can hold
The logic circuit of row instruction).However, in various embodiments, it can includes more similar in addition to execution unit to execute channel
The function of processor.For example, in addition to one or more execution units, execute channel can also include instruction to being received into
The decoded logic circuit of row, the or in the case of design of more similar MIMD, execution channel can also include to instruct into
Row code fetch and decoded logic circuit.About the method for similar MIMD, although mainly describing centralized program controlling party herein
Method, but may be implemented in various alternate embodiments more distributed methods (e.g., including each of array 305 executes channel
Interior program code and cyclelog).
Execute channel array 305, cyclelog 309 and two-dimensional shift register structure 306 be combined as can be extensive
The hardware platform of adaptation/configuration provides extensive programmable functions.For example, applied software development person can program with it is various not
The kernel of congenerous and size (for example, template size), as long as each execution channel is able to carry out various functions and can be light
Pine accesses the input image data close to any output array position.
Other than serving as the data storage area of the image data operated by execution channel array 305, random access memory
Device 307 can also retain one or more look-up tables.It in various embodiments, can also the instantiation in scalar memory 303
One or more scalar look-up tables.
Scalar lookup is related to the identical data value of the identical look-up table from same index being transmitted to execution channel array
Channel is executed each of in 305.In various embodiments, above-mentioned VLIW instruction format is extended to further include scalar operations code,
The search operation executed by scalar processor is directed in scalar look-up table by it.Specifying the index same with operation code can be
Immediate operand is derived from some other data storage location.Anyway, in one embodiment, scalar memory is come from
The lookup of interior scalar look-up table relates in essence to be broadcast to execute by identical data value during the identical clock cycle to lead to
All execution channels in channel array 305.The other details for using and operating about look-up table are further provided below.
Fig. 3 b summarize the embodiment of VLIW instruction word discussed herein above.As shown in Figure 3b, VLIW instruction word format includes
Three fields individually instructed：(1) scalar instruction 351 are executed by scalar processor；(2) ALU instruction 352, it is logical by executing
Corresponding ALU in channel array is broadcasted and is executed in a manner of SIMD；3) memory instructions 353, broadcasted in a manner of the SIMD of part and
It executes and (for example, if along the identical random access memory of execution channels share for executing same a line in channel array, comes
Each one from not going together executes that channel is practical to execute instruction that (format of memory instructions 353 may include identification
The operand which execution channel from every row executes instruction)).
It further include the field 354 of one or more immediate operands.Instruction 351,352,353 can be identified with instruction format
Which of use which immediate operand information.Each in instruction 351,352,353 also includes their own defeated
Enter operand and result information (for example, being posted for the local register of ALU operation and the local for memory reference instruction
Storage and storage address).In one embodiment, other two instructions are executed in the execution channel executed in channel array
352, before any of 353, scalar instruction 351 is executed by scalar processor.That is, it includes executing to execute VLIW words
The period 1 of scalar instruction 351 is followed by the second round that can execute other instructions 352,353 (it should be pointed out that various
It with parallel execution of instructions 352 and 353), can in embodiment.
In one embodiment, by scalar processor execute scalar instruction include be published to form builder with from/to
The memory or 2D shift registers of Data Computation Unit load/store the order of list.Here, the operation energy of form builder
Operation or its dependent variable of line buffer unit are enough depended on, these variables prevent operation feed-forward nets form builder from completing scalar
The periodicity needed for any order that processor is sent out.As such, in one embodiment, scalar instruction 351 corresponds to or with it
The order that his mode promotes to send out to form builder also includes in other two instruction fields 352,353 without operation
(NOOP) any VLIW words instructed.Then, the NOOP instruction cycles of program code Input Command Word section 352,353, Zhi Daobiao
Single generator completes its loading/storing from/to Data Computation Unit.Here, after being ordered to form builder publication, scalar
The bit for the interlock register that form builder is reset after completing to order can be arranged in processor.During NOOP is recycled, mark
Amount processor monitors the bit of mutual lock-bit.When scalar processor detects that its order is completed in form builder, start again at
It is normal to execute.
Fig. 4 shows the embodiment of data computation module 401.As shown in figure 4, data computation module 401 includes executing channel
Array 405 is logically located at " top " of two-dimensional shift register array structure 406.As described above, in various embodiments
In, the image data list provided by form builder is loaded into two-dimensional shift register 406.Then, channel pair is executed
Form data from register architecture 406 is operated.
It is fixed relative to one another in place with shift register structure 406 to execute channel array 405.However, shift register battle array
Data in row 406 are shifted by strategy and in a manner of coordinating, and data are handled so as to execute each of channel array and execute channel
Interior different templates.As such, each executing the output image values for the different pixels that channel determines in the output list just generated.From
The framework of Fig. 4 it is clear that execute channel array 405 include vertically adjacent to execution channel and horizontally adjacent execution
Channel, therefore be overlapped template and be not only arranged vertically but also horizontally arranged.
Some notable architectural features of Data Computation Unit 401 include that size ratio executes 405 broader displacement of channel array
Register architecture 406.That is, executing " haloing (halo) " except channel array 405 there are register 409.Although
Show that haloing 409 is present in the both sides for executing channel array, but according to embodiment, haloing can reside in execution channel array
405 less side (side) or more side (three sides or four sides).When data are in execution channel 405 " lower section " displacement, haloing 405
For providing " spilling " space to overflow the data except the boundary for executing channel array 405.As a kind of simple case, work as place
When managing the leftmost pixel of template, 5 × 5 templates centered on the right hand edge for executing channel array 405 need further to
Move to right four haloing register positions.For ease of drawing, when the register of in nominal embodiment both sides (right side, downside) has
When horizontal connection and vertical connection, Fig. 4, which shows the register on the right side of haloing only, to be had on the downside of horizontal shift connection and haloing
Register only has vertical movement connection.In various embodiments, haloing region is held not including corresponding execution channel logic
Row image processing commands (for example, ALU is not present).However, each memory access unit (M) is present in haloing regional location
Each in so that each haloing register position individually can load data and storing data into from memory and deposit
Reservoir.
Additional overflow space is provided by random access memory 407, which is coupled in array
Often row and/or each column or some parts (execute in channel array for example, random access memory can be assigned to across 4 rows
It executes channel and 2 row executes in " region " in channel.For the sake of simplicity, remaining content of the application will relate generally to based on row and/
Or the allocation plan of row).Here, if the kernel operation for executing channel require its handle two-dimensional shift register array 406 it
Outer pixel value (some image procossing routines may require this point), then image data plane can further overflow, for example, from
Haloing region 409 is spilt into random access memory 407.For example, it is contemplated that 6X6 templates, wherein hardware, which are included in, executes channel
The right hand edge of array overflows the haloing region of only four storage elements to executing on the right of channel.In this case, it needs data
Outside further right shift to the right hand edge of haloing 409, with complete processing template.Then, it is displaced to except haloing region 409
Data will be spilt into random access memory 407.It is further provided below at the template of random access memory 407 and Fig. 3
Manage the other application of device.
Fig. 5 a to Fig. 5 k demonstrate image data shift as described above and are posted to the two-dimensional shift for executing channel array " lower section "
The Working Examples of mode in storage array.As shown in Figure 5 a, in the data for describing two-dimensional shift array with the first array 507
Hold, and is described by frame 505 and execute channel array.Lead in addition, simplifying adjacent execute of two for depicting and executing in channel array
Road 510.In the simplification describes 510, each channel that executes includes register R1, can receive the number from shift register
According to, receive from ALU export (for example, showing as the accumulator across the period) data or by output data be written output purpose
Ground.
It is each to execute channel in local register R2 also with the content in its " lower section " in two-dimensional shift array.Cause
This, R1 is to execute the physical register in channel, and R2 is the physical register of two-dimensional shift register array.Executing channel includes
The ALU that the operand provided by R1 and/or R2 can be operated.Described further below, in one embodiment, it shifts
Register actually by every array position there are multiple storage/register elements (" depth ") to realize, but displacement activity limits
In a storage element plane (for example, each cycle can only be shifted there are one storage element plane.Fig. 5 a to Fig. 5 k depict this
One in a little deeper register positions, for storing from the corresponding result X for executing channel.For ease of diagram, deeper
Result register is drawn on beside its paring registers R2 rather than below.
Fig. 5 a to Fig. 5 k, which are concentrated on, calculates two templates, their middle position and a pair for executing description in channel array
Channel position 511 is executed to be aligned.For ease of diagram, this is plotted as horizontal neighbours to executing channel 510, in fact, according to
Following example, they are vertical neighbours.
First as illustrated in fig. 5 a, channel is executed centered on their central template position.Figure 5b shows that held by two
The object code that row of channels executes.As shown in Figure 5 b, the program code in two execution channels promotes in shift register array
Data shift downwards a position and one position of right shift.This makes two to execute the left side that channel snaps to each template
Upper angle.Then, program code promotes in each position the data (in R2) to be loaded into R1.
As shown in Figure 5 c, program code next promote this to execute channel by the data in shift register array to the left
A mobile unit, this makes the value on the right of each corresponding position for executing channel be displaced in each execution channel position.
Then, the value (preceding value) in Rl is added with the new value executed in channel position (in R2) is had shifted to.As a result it is written into R1.
As fig 5d, it repeats as above with regard to the identical process described in Fig. 5 c, it includes the upper value A executed in channel that this, which leads to result R1 at this time,
+ the B+C and lower value F+G+H executed in channel.At this point, two execute the upper of all processed each template in channel
Row.It should be pointed out that spilling into the haloing region (if there are haloing regions in left side) executed on the left of channel array or spilling into
In random access memory (if haloing region is not present in the left side for executing channel array).
As depicted in fig. 5e, next program code promotes one unit of the data upward displacement in shift register array,
This causes two execution channels to be aligned with the right hand edge of the center row of their own template.The register R1 in two execution channels
It is currently included the summation of the most r value of template top row and center row.In the template that Fig. 5 f and Fig. 5 g demonstrations execute channel across two
Between the continuing advances that are moved to the left of row.Accumulative addition continues, so that at the end of the processing of Fig. 5 g, two execution channels all include
The summation of the top row of their own template and the value of center row.
Fig. 5 h show another displacement for making each lowermost row alignment for executing the corresponding template in channel.Fig. 5 i and Fig. 5 j
It shows to continue to be displaced to completion processing during executing the template in channel at two.Fig. 5 k show to make each execution channel and its
Correct position in a data array is aligned and writes the result into additional shift therein.
In the example of Fig. 5 a to Fig. 5 k, it is noted that the object code for shifting function may include identification (X, Y)
The direction of the displacement indicated in coordinate and the instruction format of size.For example, the object code for one position of upward displacement can
To be expressed as SHIFT 0 ,+1 in object code.As a further example, one position of right shift can indicate in object code
For SHIFT+1,0.In various embodiments, can also be specified in object code by a relatively large margin displacement (for example, SHIFT 0,
+2).Here, if 2D shift register hardwares only support each cycle to shift a position, which can be by machine interpretation
To need multiple periods execution or 2D shift register hardwares that can be designed to that each cycle is supported to shift more than one position
It sets.Subsequent embodiment is described more fully.
Fig. 6 shows that array executes another more detailed description (haloing of the cell of channel and shift register structure
Register in region does not include corresponding execution channel).In one embodiment, with execute channel array in each position
Associated channel and the register space of executing passes through the instantiation electricity as shown in FIG. 6 at each node for executing channel array
Road is realized.As shown in fig. 6, cell includes being coupled to holding for the register file 602 being made of four register R2 to R5
Row of channels 601.During any period, executing channel 601 can read or be written to any of from register R1 to R5
Enter.For needing the instruction of two input operands, the two operations can be retrieved any of from R1 to R5 by executing channel
Number.
In one embodiment, realize that two-dimensional shift register structure is by allowing register R2 during signal period
To any of R4 (unique) content by output multiplexer " removal " to one in the register file of its neighbour, and
And if its neighbour makes the displacement between neighbours be on the same direction (for example, all executing logical by inputoutput multiplexer 604
Road shifted left all executes channel right shift etc.), then the content of any of register R2 to R4 (unique) is replaced
For from the content of corresponding register " immigration ".Although same register often removes its content and replaces in same period to move
The content entered, but multiplexer arrangement 603,604 allows to use different displacements during same period in same register file
Source and shifted target register.
As shown in Figure 6, it is noted that during shift sequence, execute channel and remove content from its register file 602
To each in its up and down neighbours.Identical shift sequence is cooperateed with, it is also that content is adjacent up and down from it to execute channel
Placed in the middle specific one moves into its register file.Furthermore removing target and move into source should be with the phase in all execution channels
It is consistent (for example, if being moved out to right neighbours, should be moved into from left neighbours) with direction of displacement.
Although in one embodiment, each cycle allows often to execute the content that channel only shifts a register, other
Embodiment can allow the content for being moved in and out more than one register.For example, if by multiplexer circuit as shown in FIG. 6
603,604 the second example is attached in the design of Fig. 6, then two registers can be removed/moved into during same period
Content.Certainly, in each cycle allows the embodiment of content for only shifting a register, by being consumed between mathematical operation
The displacement of multiple registers can occur between mathematical operation for more clock cycle (for example, by between mathematical operation
Two shift operations are consumed, the content of two registers can be shifted between mathematical operation).
If removing the full content less than the register file for executing channel during shift sequence, it is noted that every
The content of a non-removal register for executing channel retains (not shifting) in situ.As such, any by the non-of content displacement replacement
Displacement content remains in across shift cycle and executes channel.It is each to execute memory cell (" M ") what is observed in channel
For from/to loaded with the row in execution channel and/or the associated RAM space of row executed in channel array/
Store data.It is here, M units serve as the reason of standard M units, it can not be logical from/to executing commonly used in loading/storing
The data that the register space in road itself loads/stores.In various embodiments, the primary operational of M units is by data from originally
Ground register write-in memory and from memory read data and it is written into local register.
About the ISA operation code of the ALU units support by hardware execution paths 601, in various embodiments, by hardware
Mathematical operations code and virtual execution channel that ALU is supported (for example, ADD, SUB, MOV, MUL, MAD, ABS, DIV, SHL, SHR,
MIN/MAX, SEL, AND, OR, XOR, NOT) support mathematical operations code integrate (for example, substantially same).As upper
It states, memory reference instruction can be executed by executing channel 601, to obtain/deposit from/to their associated random access memory
Store up data.In addition, hardware execution paths 601 support shifting function instruction (right, left, upper and lower) so that two-dimensional shift register knot
Data displacement in structure.As described above, program control instruction is mainly executed by the scalar processor of template processor.
C. the operation of the configuration of image processor and line buffer unit
Fig. 7 shows the high-level view of image processor technology platform comprising virtual image processing environment 701, practical figure
As processing hardware 703 and for will be that high-level code that virtual processing environment 701 is write translates to 703 physics of actual hardware and holds
The compiler 702 of capable object code.As detailed below, virtual processing environment 701 can developed and be customized to be easy to apply
The visual application aspect of building process is general extensively.After developer 704 completes program code development, compiler
702 are directed to the code write in virtual processing environment 701 translation the object code of actual hardware 703.
In various embodiments, the program code that hardware platform is write is write using unique virtual code, this is virtual
Code includes the instruction set with load instruction and store instruction, their instruction format is by input array position and output array
Station location marker is such as X, Y coordinates.In various embodiments, X, Y coordinates information can essentially be programmed into hardware platform
In and by each identification/understanding in its component.This, which is different from, for example translates to X, Y coordinates (for example, in compiler)
Different information.For example, in the case of two-dimensional shift register structure in template processor, X, Y coordinates information is translated
It is moved for register shift.In contrast, the other parts of hardware platform can be received specifically and be understood with higher Virtual Agent
The X, Y coordinates information of the code original expression of rank.
As shown in figure 8, program code developers are expressed Data Position with specific instruction format with virtual code rank 801
For X, Y coordinates.During compiler level, virtual code be translated for the program code actually handled by hardware (object code) with
And it is loaded into the correspondence configuration information in hardware configuration (for example, register) space.As shown in figure 8, in one embodiment, it is special
The object code for determining kernel is loaded into the program space of scalar processor 805 of template processor.
As a part for configuration process, the configuration software executed on scalar processor 805 is by configuration information appropriate
811,812 it is loaded into the form builder unit 803 and line buffer unit 801 for being coupled to template processor 802, the line is slow
Rush device unit will generate for template processor 802 new table, with operate or receive by template processor 802 generate through
The list of reason.Here, in general, remaining able to consider list according to the X, Y coordinates of whole image.That is, once
Image or frame (for example, according to often capable pixel number, pixel number and columns of line number, each column) are defined, remains able to use X, Y coordinates
Refer to any part or the position of image.
As such, in various embodiments, any of form builder unit 803 and line buffer unit 801 or this
The two is configured with information 811,812 in its corresponding configuration space 806,807, these information establish information platform, is sat with X, Y
Mark therefrom identifies the specific location and/or region (for example, line-group, list) of image or frame.Various embodiment/use on the way,
X, Y coordinates can be the identical X, Y coordinates expressed with virtual code rank.
The image of number of the example of such information for example including the movable line-group in line buffer unit, each line-group
Size is (for example, as one group of four X, Y coordinates (one, each angle) or a pair of of X, Y coordinates (nearlyr inferior horn one, higher upper angle
One)) or absolute image width and picture altitude, template size (be expressed as X, Y value, be used for the list of definition template processor
The size of a template and/or the area for being overlapped template), list and/or line-group size be (for example, with item identical with picture size
Part is specified but has smaller size) etc..In addition, line buffer unit 701 can at least be programmed with additional configuration information, it is all
The number of the producer's kernel such as write and read the line-group managed by line buffer unit 801 consumer kernels number
Mesh.Also typically include channel number and/or size associated with image data as configuration information.
Only for example, Fig. 9 a are depicted defines the line-group in image using X, Y coordinates.Here, can in image 901
Observe N number of line-group 901_1,901_2 ..., 901_N.It can be seen that from Fig. 9 a by referring to for example defining line-group in image
The X, Y coordinates of one or more of angle point can be easy to define each line-group.As such, in various embodiments, for fixed
The line-group title or other data structures of the specific line-group of justice may include X, Y coordinates associated with line-group position, so as to special
Identify the line-group.
Brief review Fig. 8, it is noted that Fig. 8 shows that during operation form builder 803 can be for example, by including
The X, Y coordinates information of data area needed for definition and ask " next " line-group (or one of line-group from line buffer unit 801
Point).Fig. 9 a show name " overall with " line-group being only made of complete image data lines.In the alternative configuration for being known as " virtual high "
In, line buffer unit 801 initially only transmits overall with row of the first top of line-group as image data.Then, it is given birth to by list
It grows up to be a useful person specially to ask the follow-up downlink of line-group and separately be requested less than the continuous chunking of overall with row.As such, form builder
It is repeatedly asked, to obtain complete line-group.Here, each such request can by can belong to next part X,
Y coordinate defines next part.
As shown in figure 9b, line buffer unit includes storing the memory 901 of line-group 902_1 to 902_N (for example, static
Or dynamic random access memory (SRAM or DRAM)).Memory 901 can be together with realizing line buffer unit (and for example
Form builder and template processor) same circuits together on piece realize or piece outside realize.Fig. 9 b are shown as memory 901
Interior specific image/frame generates the activity between the various kernels of consumption line-group 902_1 to 902_N.
As shown in figure 9b, new line mass-sending is sent to line buffer unit 901 by producer's kernel K1, so as in the separated time
Example P1, P2 are stored in memory 901 to PN.Producer's kernel is executed in the template processor for generating new data list
K1.The form builder for being coupled to template processor adds up list to form line-group and line-group is forwarded to line buffer list
Member, the line buffer unit are stored in memory.
In addition, as shown in figure 9b, there are two consumer kernel K2, K3, they are to the line that is generated by producer's kernel K1
Group 902_1 to 902_N is operated.Here, consumer kernels K2 and K3 receive the first line-group in time C21 and C31 respectively
902_1.Obviously, after time C21 and C31 appears in time P1.Other limitations may be not present.For example, time C21 and/or
Before or after C31 can appear in any time of P2 to PN.Here, the corresponding form builder for kernel K2 and K3 exists
Time suitable for their corresponding kernels asks next line-group.If any of kernel K2, K3 are asked before time P1
Line-group 902_1, then the request is idle always is actually written by line-group 902_1 after memory 901.
It is contemplated that from any of kernel K2 and K3 or the two for all line-group 902_1 to 902_N's
Request may reach before time P1.Therefore, consumer kernels can ask line-group at any time.However, line-group is turned
Consumer kernels are dealt into, because these line-groups of these consumer kernel requests are limited by producer's kernel K1 and can generate line-group
Rate.In various embodiments, consumer kernels sequentially ask line-group and (kernel K2 is in the time for same received in sequence line-group
C22 to C2N received in sequence line-group 902_2 to 902_N).For the sake of simplicity, describe in unique producer only for specific line-group
Core.It is contemplated that various embodiments can be designed that different producers that identical line-group is written (for example, until complete
Portion producer just allows to service consumer after all having been written into line-group).
In the case of no producer's kernel (because consumer kernels be processor DAG process flows in first
A kernel), image data frame can be sent in memory 901 (for example, via direct memory access (DMA) (DMA) or come
From camera) and it is resolvable to line-group.(because producer's kernel is processor entirety journey in the case of no consumer kernels
The last one kernel in sequence flow), as a result line-group can be combined to form output frame.
D. the application of kernel and structure
Figure 10 a show the example of the structure that the application software write in virtual environment can be taken and form.Such as Figure 10 a
It is shown, it is contemplated that program code handles one or more frames of input image data 1001, with to input image data 1001
Carry out some integral transformations.Pass through the program code operated by the associated layout sequence pair input image data of developer
The transformation is realized in the operation of 1002 one or more kernels.
For example, as shown in Figure 10 a, handling each input picture first by using the first kernel K1, realizing integral transformation.
Then, kernel K2 operations export image caused by kernel K1.Then, kernel K3_1 or K3_2 operations are produced by kernel K2
Output image in each.Then, kernel K4 operations export image caused by kernel K3_1/K3_2.Kernel K3_1
Can be identical kernel with K3_2, it is intended to accelerate disposed of in its entirety or they can be with by applying parallel processing at K3 grades
Kernel is different (for example, kernel K3_1 operates the input picture of the first concrete type, and K3_2 pairs second of kernel
The different types of input picture of kind is operated).
As such, larger general image processing sequence can take image processing pipeline or directed acyclic graph (DAG)
Form, and development environment can be provided as the expression of the practical program code just developed to developer's presentation (here, flowing water
Line is understood to a kind of form of DAG).Kernel can individually be developed by developer and/or kernel can be by providing any bottom
The entity of technology (such as actual signal processor hardware and/or its design) and/or by third party (for example, being development environment
The supplier for the kernel software write) it provides.Like this, it is contemplated that nominal development environment will can be with various sides including developer
Formula freely " connects " kernel " library " of the overall flow to realize its large-scale development temporarily.It is expected that as a this library part
Some basic core contents may include kernel for providing any one or more of following primary image processing task：Volume
Product, denoising, color space conversion, edge and Corner Detection, sharpening, white balance, gamma correction, tone mapping, matrix multiplication, figure
As registration, pyramid construction, wavelet transformation, piecemeal discrete cosine and Fourier transformation.
As described above, in various embodiments, each kernel is run in the template processor of its own.For example, referring to
Figure 10 a, kernel K1 are run in the first template processor, and kernel K2 is run in the second template processor, etc..In addition, such as
It is upper described, it generates kernel and is interacted by line buffer unit with consumption kernel.
Figure 10 b depict the mode for the DAG flows that image processor can be configured to realize Figure 10 a.Such as Figure 10 b institutes
Show, line buffer unit 1001_1 (LBU_1) receives input image stream and the frame received is parsed into line-group.Exchange network
It is configured to for line-group to be routed to the first template processor 1002_1 for executing kernel K1 from LBU_1.Output from kernel K1
Image is formatted as line-group and is forwarded to the second line buffer unit 1001_2 (LBU_2).Then, these line-groups are turned
It is dealt into the second template processor for executing kernel K2.
According to Figure 10 a, image information can be any of from kernel K2 " segmentation " to kernel K3_1 or K3_2 in.
This, for example, kernel K3_1 and K3_2 can be handled and the associated different channels of the general image just handled.For example, kernel K3_
1 can handle red (R) image, and kernel K3_2 can handle green (G) image and blue (B) image.Alternatively, K3_1 can
To handle visual pattern, and kernel K3_2 can handle depth image (for example, from time-of-flight depth imaging camera together with vision
Image is shot together).Anyway, whole channels of image are all handled by kernel K1 and K2, but the different channels of image are used
Different kernel K3_1 and K3_2 is handled.In addition, kernel K3_1 and K3_2 can be identical (for example, extreme numerical value are intensive)
The independent example of program code, and two template processors are used in by executing the place to accelerate to K3 functions parallel
Reason.
Anyway, above-mentioned " segmentation " promotes some line-group image informations from kernel K2 to be buffered to third line buffer
In unit 1001_3 (LBU_3) and other line-group image informations from kernel K2 is promoted to be buffered to the 4th line buffer unit
In 1001_4 (LBU_4).The line-group being buffered in LBU_3 line buffer units is forwarded to the third template for executing kernel K3_1
Processor 1002_3.The line-group being buffered in LBU_4 line buffer units is forwarded at the 4th template for executing kernel K3_2
Manage device 1002_4.Output line-group from kernel K3_1 and K3_2 is buffered to the 5th line buffer unit 1001_4 respectively
(LBU_5) and in the 6th line buffer unit 1001_5 (LBU_6).Then, from LBU_5 and LBU_6 line buffer units
Line-group is passed to the 5th template processor 1002_5 for executing kernel K4.It should be pointed out that the line-group of segmentation is at the 5th template
Merge again at reason device 1002_5.
Figure 11 a and Figure 11 b are related to more direct pipelining technique, wherein each template processor is from preceding Primary Receive line-group
And provide line-group for rear stage.Specifically, line buffer unit 1101_1 (LBU_1), 1101_2 (LBU_2), 1101_3
(LBU_3), 1101_4 (LBU_4) feeds corresponding template processor 1102_1,1102_ for executing kernel K1, K2, K3 and K4 respectively
2、1102_3、1102_4.Template processor 1102_1,1102_2,1102_3,1102_4 also distinguish feed lines buffer unit
1101_2(LBU_2)、1101_3(LBU_3)、1101_4(LBU_4)、1101_5(LBU_5)。
Figure 11 c show another pipelining technique, substantially execute two assembly lines (K1-K3-...) and (K2- parallel
K4-...).This configuration can be used in by execute parallel accelerate assembly line (for example, kernel K1 is identical as K2, and
Kernel K3 is identical as K4), or use two different assembly lines (for example, at an assembly line according to image data context
A kind of channel is managed, another pipeline processes another kind channel).
In each figure in Figure 11 a, Figure 11 b and Figure 11 c, it is noted that need to connection network 1004/1104 into
The different configuration of row, by will pass through it is appropriate in a manner of template processor is connected to source line-group and place line-group.
In various embodiments, image processor include configuration space appropriate (for example, using configuration register and/or
Random access memory (the scalar memory of such as scalar processor) is realized), wherein it is a large amount of to realize to retain configuration information
Any one of various configurations (for example, DAG, image processing pipeline).Some exemplary configuration parameters include：(1) source images
Number (such as the number of the source image frame of system is flowed into from the main memory of camera or large computer system)；(2) line-group number
Mesh (sum of the line-group configured in system center line buffer unit)；(3) collapsible form processor number (collapsible form in system
The sum of processor)；(4) (it is defeated that a template processor can handle more than one to the input line-group number per template processor
Enter picture frame, Num_Input_LGs_perStencil is essentially indicate that template processor will handle the number of different input picture frames
Mesh)；(5) per template processor output line-group number (template processor can handle more than one output picture frame,
Num_Output_LGs_perStencil is essentially indicate that template processor will handle the number of different output picture frames)；(6)
Consumer numbers per line-group are (for each line-group configured in each line buffer unit, Num_Cons_per_LG index lines
Group has the number of consumer).Any feature, structure or operation based on above system, system can receive other kinds of
Configuration information.
E. automatic DAG/ assembly lines code refactoring process
Using the above-mentioned basic principle of the image processor configuration and operation described in previous section, this part describes compiler
Certain restructuring procedures in a manner of the more effective whole implementation for realizing DAG can be executed to the DAG of kernel.As described above, stream
Waterline is understood to a kind of form of DAG.
Here, compiler can be programmed to identify certain inefficient or other problematic DAG structures and reconstruct automatically
DAG, to mitigate inefficient and/or elimination problem.In various embodiments, software program development tool can allow program developer
The prompt that compiler can be used for executing program code one or more transformation is provided, it is as further described below, low to solve
Effect problem.
Can include but is not limited to by inefficient or problem the example in compiler detects and responds DAG：(1) kernel
Compared with other kernels in DAG especially have more computational complexity；(2) DAG includes than the template processing in image processor
The more or fewer kernels of device；(3) limited line buffer unit memory space and/or limited instruction memory size.Figure
12a/ Figure 12 b/ Figure 12 c to Figure 16 describe that compiler can be designed to respond to can in some that these inefficient/problems are realized
Row reconstruct.
Figure 12 a and Figure 12 b are for " level fusion " code refactoring.In the case where level merges, as figure 12 a shows,
Multiple kernels (for example, each stream from identical kernel) of DAG are merged into single kernel.Here, Figure 12 a show have
The source code sequence 1201 of independent K2 and K3 kernels.After being reconstructed by compiler, fresh code sequence 1202 is created, wherein in
Core K2 and K3 are combined into single kernel K2/K3.
For example, compiler can be in response to there is kernel more smaller than other kernels in DAG/ assembly lines and by executing level
Fusion.Here, the fusion of kernel will generate the kernel of bigger, it is more more comparable than other kernels in size/computational intensity
Property.Alternatively or in combination, compiler can be in response to executing in original DAG in the presence of more kernels are deposited than template processor
Level fusion.Here, fusion will reduce the sum of the kernel in DAG (ideally, so that no longer than in image processor
The number of template processor).
In various embodiments, horizontal fusion merges the program code of multiple kernels independent of each other (for example, merging two
Kernel, the first kernel do not receive as the input information by karyogenesis in second).In addition, the kernel of horizontal fusion can receive
The output information that input information and/or offer from same kernel are consumed for same kernel.Figure 12 a show former case,
The kernel K2 and K3 of middle fusion receive the input information from kernel K1.
Figure 12 b show the embodiment of realization level fusion.Here, what the K2/K3 kernels of neotectonics were designed to just to merge
The concatenation of kernel.That is, in the embodiment of Figure 12 b, new kernel K2/K3 is made of the program code of kernel K3, the journey
Sequence code immediately begins to execute after the program code of kernel K2 executes 1203.Particularly, new kernel K2/K3 receiving and kernel
The identical input information of combination and offer output information identical with the combination of kernel K2 and K3 of K2 and K3., it is noted once again that
Can receive and input from identical or different line buffer unit, and export their corresponding outputs can be supplied to it is identical
Or different line buffer unit.
Here, 2a referring to Fig.1, if kernel K1 is two different line buffer units (First Line bufferings of feeding K2
Second line buffer unit of device unit and feeding K3) generate line buffered data, then it is not necessarily to reprogramming flow (kernel K2/K3
The parts K2 read from the line buffer unit generated for K2, and the parts K3 of kernel K2/K3 are slow from the line generated for K3
It is read in punching).If kernel K2 and K3 are all the consumer of the identical data from kernel K1 (that is, kernel K1 is only written one
Line buffer unit and K2 and K3 are read from the line buffer unit), then be again without the data flow of reprogramming.
Under this situation, the part K2 and K3 of kernel K2/K3 is all consumed from identical line buffer unit.Similar application by analogy is in kernel
The output line buffer unit of K2/K3.
In various embodiments, compiler should perceive the kernel operation institute of fusion according to space velocity (per kernel
Call the pixel of processing).It may not be to write identical rate operation with original here, the kernel just merged is possible.For example, due to
The difference of image resolution ratio, these kernels may not consume the equal number of period when executing their corresponding algorithms.Example
Such as, down-sampling kernel may must need more two-dimensional shift register shifting functions than another kernel of non-lower sampling
It is operated in wider image area.
Therefore, down-sampling kernel calling more more than karyophthisis in non-lower sampling before it is completed.For example, in down-sampling
Core may consume 16 periods before it is completed, and non-lower sampling kernel may only consume 4 periods before it is completed.It is complete
It can lead to the sequence problem of line buffer unit at the difference of rate, the period which completes every time is entire
It is constant in the length of run of kernel.Therefore, the code of compiler modification kernel so that they consume the period of approximately the same number, with
Their corresponding algorithms are executed completely.By doing so, line buffer need not be adjusted to completely not during intermediate core executes
Same kernel algorithm completion rate.
Therefore, in one embodiment, compiler adds one or more to each kernel for completing to consume the less period
Cycle, so that kernel for example completes consumption and completes consumption every time compared with the kernel of the multicycle equal number of period every time.For example,
In the examples described above, non-lower sampling kernel will be modified to run four cycles of its algorithm before it is completed.Although through repairing
The kernel changed is with the data of its four times compared to establishment of primary original version for executing operation, but modified kernel completes it at it
Before will consume 16 periods, this is identical as down-sampling kernel.It is contemplated that compiler can change the speed of more than one kernel
Rate, can be by the rate matched public domination period to reach whole kernels.
Figure 13 a to Figure 13 c are related to vertically merging.In the case of vertical fusion, as depicted in fig. 13 a, the kernel just merged
Between there are producer/consumer relationships.For example, as depicted in fig. 13 a, kernel K1 is that (kernel K2 is interior by the producer of kernel K2
The consumer of core K1).After being reconstructed by kernel, new kernel K1/K2 is generated, executes the work(of the kernel K1 and K2 of fusion
Energy.
Figure 13 b show the structure of new kernel.Here, the concatenation consumption kernel K2 after kernel K1, to realize correctly production
Survivor/consumer relationships.The input of new kernel K1/K2 corresponds to the input of kernel K1, and the output of new kernel K1/K2 corresponds to
In the output of kernel K2.Compiler can for example be less than in response to the computational complexity of the kernel just merged in other in DAG
There are kernels more more than template processor in image processor in core and/or DAG and determines to apply vertical fusion.
If the consumption kernel portion of the kernel vertically merged needs haloing region to execute its task, vertically merging
In the case of be likely to occur problem.Look back the discussion of figure 4 above, in various embodiments, the two-dimensional shift in template processor
The size of register can accommodate the haloing region 409 except the region for extending to storage output pixel value.
Here, if vertically the consumption kernel portion of fusion kernel needs the content in haloing region, it can not be immediately
Output to generating kernel portion operates.That is, the output data generated by producer, which will remain in, executes channel
It " lower section " and may not extend in haloing region.If consumption kernel portion needs the image data in haloing region, if
Consumption kernel portion immediately after starts to operate generating to the output result of producer part, then haloing data will be unavailable.
A solution is the beginning of delay consumption kernel portion, to ensure that producer's kernel portion waits until consumption kernel
Start just to generate haloing area data when operation.Figure 13 c show the exemplary description of the solution.Here, borderline region
1301 correspond to producer's kernel portion execution passage area, and borderline region 1302 correspond to reside in producer's kernel
Haloing region except partial execution passage area 1301.
In contrast, borderline region 1303 corresponds to after producer's kernel portion generates output in region 1301
The execution passage area that consumption kernel portion is just operating.Borderline region 1304 corresponds to the execution for residing in consumer kernel portions
Haloing region around passage area 1303.Figure 13 c hypothesis template processing is along same a line list to table in a manner of from left to right
It is singly operated, until completing the processing to the row list, will start to handle next line list at this time.
The beginning that kernel portion is consumed by delay, being capable of intentionally existing offset between applying zone 1301 and 1303
Or phase difference, until generate kernel portion generate for consumption kernel portion using and it is relatively fixed with as shown in figure 13 c
The output of position offset.Particularly, it using this offset, has been used by karyogenesis in producer and for consumption kernel portion
Image data exports the execution passage area 1303 but also " filling " its halo region of not only " filling " consumption kernel portion
1304.As such, there is consumption kernel portion it to be computed correctly the data needed for the output valve in region 1303, and it is allowed in trial
The beading process of the K1 of K2 is followed by before operation K1 next time.
In nominal embodiment, producer's kernel outputs it data write line buffer unit, and consume kernel from
Data are read in identical line buffer unit.However, just merging and executing in generation in identical template processor at this time
Core part and consumption kernel portion, therefore the output data generated by generation kernel portion may remain in template processor local
(for example, in memory of template processor RAM407 and/or form builder), rather than write back line buffer unit.As such,
Consumption kernel portion not reads data from line buffer unit, but is read from the memory of template processor local defeated
Go out data.
Therefore, it is possible to avoid the complete Writing/Reading sequence between template processor and line buffer unit.Generating kernel portion
In the embodiment that other consumer of the output divided are not merged with generation kernel portion, the output for generating kernel portion is write from outside
Enter line buffer unit, therefore external consumption kernel can receive the data of producer.
For similar reasons, it is more than positive that Figure 13 c, which are also shown by the size of the image data of template processor actual treatment,
The size of the image of reason.Specifically, additional area of space 1305,1306 is handled by producer's kernel portion so that producer
Kernel portion can generate the haloing data needed for consumer kernel portions.
Figure 14 depicts another limitation for being properly termed as " fission segmentation ".In the case where fissioning segmentation, larger kernel
It is broken down into multiple smaller kernels.For example, as shown in figure 14, the large-scale initial kernel K with subgraph A to F is broken down into two
Kernel K1 and K2, wherein new kernel K1 includes subgraph A to D, and new kernel K2 includes subgraph E and F.For example, if just dividing
The computational complexity of kernel K higher than in DAG other kernels and/or its instruct area of coverage excessive and be unsuitable for template processor
Command memory can then be applied fission segmentation by compiler.
A part as reconstruct, it is noted that " store_sheet " command/instruction and " load_sheet " are ordered/referred to
Order is newly inserted at the time of dividing larger kernel code in entire code.Specifically, from the example of Figure 14 can be seen that compared with
Big kernel K is divided in joint 1401, it is noted that and the output of subgraph D is modified to information table memory list, and subgraph E
Input is modified to load information information.
As above it is discussed in detail, due to there are two-dimensional shift register array, image data list being interior in template processor
The basic input data structure and output data structure of core.As such, before interior nuclear energy enough operates data form, it must
Data form must be loaded into the two-dimentional register space of template processor first.Equally, when kernel completion once executes it
When core algorithm, template processor RAM is written from two-dimensional shift register for the data form that it outputs it and/or list generates
Device RAM.
The part for requiring unanimously to apply fission segmentation with these Data Structures is the kernel output (Figure 14 newly created
In subgraph D output) and newly create kernel input (input of the subgraph E in Figure 14).The former needs to store list life
It enables the output data list from two-dimensional shift register array is written, and the former needs load table single command to read input
The input data list of two-dimensional shift register array.It should be pointed out that Store_Sheet and Load_Sheet orders also correspond to
Communication between kernel and line buffer unit (line buffer is made of multiple lists).As such, before fission, subgraph D is not
Direct feed lines buffer unit, and after fission, it does so.Similarly, before fission, subgraph E is not directly from line
Buffer unit receives, and after fusion, it will be such.
In one embodiment, compiler is designed to apply segmentation joint in some region or larger kernel K
1401 so that independent kernel K1, the K2 newly created approximately equals in size/calculating intensity.In some instances, this may promote
Compiler is set to apply segmentation joint 1401 by iterative cycles.For example, subgraph D and E may be implemented to recycle, wherein program circuit
Subgraph D is returned to from subgraph E, until cycle is completed.
In the case where dividing the incision cycle of joint 1401, in addition compiler changes program code so as to recycle this status
It cuts.Herein, it is noted that fission segmentation 1401 as shown in figure 14 substantially creates new with producer/consumer relationships
Kernel.That is, the kernel K2 newly created from kernel K1 output it line buffer be written line buffer unit read by
The line buffer that kernel K1 is created.As such, executing the preceding iteration of cycle by K1, the trailing iteration of cycle is executed by K2.
In another embodiment, compiler will not attempt have data dependence between segmentation previous ones and successive iterations
Property cycle, but entire cycle is maintained in same kernel.Apply as such, the presence of cycle may influence compiler selection
Divide the position (around them, rather than passing through them) of joint 1401.
Figure 15 depicts another compiler restructuring procedure for being known as " space partition zone ".As shown in figure 15, space partition zone needs
The original design kernel that larger image operates in pairs is copied into the phase for being designed to only be operated to a part of image
With in multiple kernels of core algorithm.
Here, in the example plot of Figure 15, original kernel K1 is designed to operate whole image 1501.It compiles
It translates device and substantially replicates kernel K1 so that DAG includes two examples of Kl codes, i.e. Kl_1 and Kl_2.Compiler is further repaiied
The basic Kl codes for changing the kernel newly created, to only relate to the image section that they should be handled.In the example of fig. 15, kernel
K1_1 only operates the left-half 1501_1 of image 1501, and right half parts of the kernel K1_2 only to image 1501
1501_2 is operated.
As such, the kernel code for rebuilding kernel Kl_1 is only asked to reside in the left-half of image 1501 by compiler
Line buffered data in 1501_1, and by the code for rebuilding kernel K1_2 only to ask to reside in the right half part of image 1501
Line buffered data in 1501_2.Through looking back, kernel software can be indicated with its X, Y coordinates to ask line buffer, various
In embodiment, compiler needs the reconstruction of kernel K1 and K2 to reformat line buffer request, corresponds to kernel with specified
The coordinate for the image section that should be handled.
For example, once having received the input line buffered data for the left-half 1501_1 for being enough to handle image, kernel K1_
1 will avoid request across the coordinate of whole image width, but ask next line image data.Similarly, when under start to process
When one line buffered data, kernel Kl_2 will be deviated with the X-axis corresponding to image half (for example, kernel is not in coordinate 0, Y
Point requires next line buffer, but will be in coordinate W/2, and Y points ask next line buffer, and wherein W is whole image
1501 along X-axis width.
According to the principle of the coordinate value of the requested line buffered data of above-mentioned adjustment, other picture portions arrangement is also feasible.
In an exemplary embodiment, original kernel K1 be designed to from single line buffer unit read whole image and
It outputs it data and another single line buffer unit is written.After space partition zone, kernel Kl_1 and Kl_2 all can be referred to figure
As (or producer's kernel of the input picture of kernel Kl_1, Kl_2 can be by for single source line buffer unit that data are resident
It is reconfigured as two copies of image two individual line buffer units are written, kernel Kl_1 and Kl_2 are therefrom read respectively
It takes).However, as shown in figure 15, in one embodiment, each in kernel K1_1 and K1_2 writes their output data
Enter two individual line buffer unit LB_1 and LB_2.
In one embodiment, applying the reason of this limitation is, as above about described in Fig. 9 a and Fig. 9 b, line buffer
Unit can serve multiple consumer, but can only handle a producer.As such, single line buffer unit can not handle and
From the output of both kernel Kl_1 and Kl_2 (each kernel must be written into the line buffer unit of its own).Therefore, as schemed
Shown in 15, consumption kernel K2 is also redeployed as a part for space partition zone reconstruct, with from two different line buffer lists
Member reads image data (the LB_1 reservation left image datas, and LB_2 reservations for two difference half portions that it is needed for image
Right image data).That is, kernel K2 is reconstructed, request is sent out to LB_1 if it needs left-side images, and if
It needs right image data then to send out request to LB_2.For example, if the algorithm of K2 operates whole image, K2
It can be reconstructed into and the two half-unit of image is merged into single image.
Figure 16 is related to another code refactoring process of referred to as " figure segmentation ".In the case where figure is divided, DAG processing
Data volume be more than image processor internal storage requirement.As such, DAG must be divided into multiple DAG, wherein each
DAG handles the data volume in the internal storage space limitation of image processor.Here, in various embodiments, line buffer list
Member, list generator and template processor respectively have relevant memory.If the memory requirement of single DAG is deposited more than these
The capacity of one or more of reservoir then creates multiple DAG.
The example that establishment DAG1608 is shown in Figure 16, the purpose is to repeat 1601 down-sampling of great input picture to be
In smaller low-density output image 1607.DAG/ assembly lines 1608 are made of six kernel K1 to K6, wherein each kernel will
Larger input picture down-sampling is smaller output image (for example, larger 1601 down-sampling of input picture is by kernel K1
1602 down-sampling of image is smaller image 1603 by smaller image 1602, kernel K2, and kernel K3 is by 1603 down-sampling of image
For smaller image 1604 etc.).
In such as 1601 great embodiment of initial input image, it is less likely to make total data/instruction/context
It is fitted in the internal storage space of image processor.As such, in response, compiler will analyze the memory of kernel K1 to K6
Resource requirement and by initial larger DAG/ assembly lines 1608 be parsed into one group smaller DAG/ assembly lines 1609,1610,
1611, they will sequentially be operated and each of which need not internal storages more more than available resources in image processor
Resource.
The discussion of Fig. 1 is looked back, DAG starts the input data from external memory being loaded into line buffer unit,
And terminate after external memory being written from the output data of line buffer unit.Therefore, the initial DAG/ flowing water of Figure 16
When line 1608 is included in the input of kernel K1 by the input data from external memory be transmitted to the order of line buffer unit/
The output data from line buffer unit is transmitted to external memory when instructing, but also being included in the output of kernel K6
Command/instruction.
Original larger DAG/ assembly lines 1608 are parsed into smaller DAG/ assembly lines 1609,1610,1611 in compiler
Later, compiler will be additionally inserted into command/instruction in the input of kernel K2 and K4 (that is, in new smaller DAG/ assembly lines
When 1610 and 1611 input) in the line buffer unit that is loaded into the input data from external memory.Compiler is also
(that is, in output of new smaller DAG/ assembly lines 1609 and 1610) when the output for being inserted in kernel K1 and K3 will be come from into line
The output data of buffer unit is loaded into the command/instruction in external memory.It should be pointed out that be inserted into these newer commands/
The position of instruction, original DAG/ assembly lines 1608 are specified to/from line buffer unit rather than external memory writing/reading data
(because the kernel in same DAG/ assembly lines is each other by line buffer unit feeding/acquisition).As such, compiler will delete this
A little original directive/instructions.
It should be pointed out that described various reconstruct may finally be executed in response to any of the above described inefficiency problem.For example, exist
After a series of fusions, compiler can finally execute figure segmentation.
It is pointed out in discussion in front, kernel itself may be when being finally compiled into object code by many branches and phase
Close the large complicated software routines of basic code block composition.As such, the subgraph itself in kernel ought may also finally be compiled into mesh
It is made of multiple branches and elementary object code block when marking code.
Figure 17 a show the method for example executed by compiler as described above.As illustrated in fig 17 a, the method includes
1701, for the program code of image processor, which has executes channel and displacement by corresponding two dimension for compiling
The programmable templates processor of register circuit structure composition, said program code is for realizing directed acyclic graph and by multiple
Kernel forms, these kernels will execute in each template processor, wherein compiling include it is following any one：Identify journey
Number of cores in sequence code is different from the number of the template processor in image processor；Identify at least one of kernel
Computational intensity is higher than another in kernel；The resource requirement of recognize program code is more than that the memory of image processor holds
Amount.This method further comprises 1702 in response to any one of identified above, executes following any one：In level fusion
Core；Vertical fusion kernel；One in the kernel is split into multiple kernels；Divide kernel spacing into multiple space partition zones
Kernel；Directed acyclic graph is divided into smaller figure.
Figure 17 b are depicted when compiling is in the image processor (image procossing such as with any of the above described hardware characteristics
Device) on execute program code when, can be with the applied software development and simulated environment of any of above compiler process adapted
1721.Here, developer can be by developing synthesis with the strategy sequence arrangement kernel consistent with whole expected image transformation
Image processing function (for example, every level-one in assembly line execute special image processing tasks image processing pipeline, some its
Routine set etc. as defined in his DAG).It can call kernel and/or developer that can develop in one or more customizations from library 1722
Core.
Kernel in library 1722 can by kernel third-party vendor and/or any Floor layer Technology supplier (for example,
The supplier of hardware platform including target hardware image processor or the supplier of target hardware image processor) (example is provided
Such as, it is provided as its design or as actual hardware).
As for customized development kernel, in many cases, developer only needs to write program code for single thread 1723.Also
It is to say, developer only need to be by reference to the input pixel value relative to output pixel position (for example, opposite using aforementioned location
Memory reference instruction format) write the program code for determining single output pixel value.In the operation for meeting single thread 1723
Afterwards, development environment can then instantiate multiple examples of thread code automatically on corresponding virtual processor, to realize operation
Kernel on the processor array in imaging surface region.Imaging surface region can be a part (such as line-group) for picture frame.
In various embodiments, customization thread program code be written into virtual processor ISA object code (or compiling
To the high-level language of virtual processor ISA object codes).Customization kernel program code can be executed in dry run environment
Simulation is executed, which includes the virtual processor for accessing the memory according to memory model tissue.Here, real
The software model (object-oriented or otherwise) of exampleization virtual processor 1724 and memory 1725 comprising the model.
Then, the execution of 1724 simulation thread code 1723 of virtual processor model.In the performance for meeting thread, its is larger
After any larger function belonging to kernel and the kernel, it is integrally compiled into the realistic objective code of bottom hardware.Entire mould
Near-ring border 1721 may be implemented as the software run in computer system (for example, work station) 1726.
F. embodiment is realized
It is necessary to note that above-mentioned various image processor architecture features are not necessarily limited to traditional image procossing, because
This can be applied to can (or can not) other application for promoting image processor to be characterized again.For example, if above-mentioned each
Any one of kind image processor architectural feature is used to create and/or generates and/or rendering animation, and non-process
Actual camera image, then image processor can be characterized as being graphics processing unit.In addition, above-mentioned image processor architecture is special
Sign can be applied to other technologies application, such as video processing, visual processes, image recognition and/or machine learning.By this
Mode application, image processor can (for example, as coprocessor) and more general processor (for example, it is computing system
CPU or computing system CPU a part) it is integrated, or can be the independent processor in computing system.
Above-mentioned hardware design embodiment can be embodied in semiconductor chip and/or be presented as final laying semiconductor
The description of the circuit design of manufacturing process.In the latter case, the description of this circuit can take (for example, VHDL or
Verilog) Method at Register Transfer Level (RTL) circuit description, gate level circuit description, transistor level circuitry description or mask description or
The form of various combinations.Circuit description is usually embodied in computer readable storage medium, and (such as CD-ROM or other kinds of is deposited
Storage technology) on.
It will recognize from previous section, image processor as described above can be on the computer systems with hardware realization
(for example, as processing the camera from handheld device data handheld device system on chip (SOC) a part).Scheming
In the case of hardware circuit being presented as processor, it is noted that can directly be handled from camera reception by image processor
Image data.Here, image processor can be a part for discrete camera, or the computing system with integrated camera
A part.In the latter case, system storage that can be directly from camera or from computing system receives image data (example
Such as, its image data is sent to system storage rather than image processor by camera).It is otherwise noted that institute in previous section
Many functions of description can be adapted for graphics processor unit (rendering animation).
Figure 18 provides the exemplary description of computing system.Many components of computing system described below are suitable for having collection
At the computing system (for example, handheld device of such as smart phone or Tablet PC) of camera and related image processor.
Those of ordinary skill will easily distinguish the two.In addition, the computing system of Figure 18 further includes being permitted for high performance computing system
Multiple features, such as work station for realizing the development environment discussed above with reference to Figure 17 c.
As shown in figure 18, basic calculating system may include that (it may include for example multiple logical to central processing unit 1801
With process cores 1815_1 to 1215_N and the main memory controller being arranged on multi-core processor or application processor
1817), system storage 1802, display 1803 (for example, touch screen, tablet), local wired point-to-point link (for example,
USB) interface 1804, various network I/O functions 1805 (such as Ethernet interface and/or cellular modem subsystem), nothing
Line LAN (for example, WiFi) interface 1806, wireless point-to-point link (for example, bluetooth) interface 1807 and global positioning system connect
Mouth 1808, various sensors 12091 to 1809_N, one or more cameras 1810, battery 1811, power supply management control unit
1812, loud speaker and microphone 1813 and audio encoder/decoder 1814.
Application processor or multi-core processor 1850 may include one or more general procedure cores in its CPU 1201
1815, one or more graphics processing units 1816, memory management functions 1817 (for example, Memory Controller), I/O controls
Function 1818 and image processing unit 1819.General procedure core 1815 usually executes the operating system of computing system and using soft
Part.Graphics processing unit 1816 usually executes graphics intensive function, is believed with for example generating the figure presented on display 1803
Breath.Memory control function 1817 is docked with system storage 1802, with to/from 1802 writing/reading data of system storage.
The power consumption of 1812 usual control system 1800 of power supply management control unit.
Image processing unit 1819 can according to any image processing unit embodiment being described in detail in previous section come
It realizes.Alternatively or in combination, IPU 1819 is coupled to any one of GPU 1816 and CPU 1801 or both conduct
Its coprocessor.In addition, in various embodiments, GPU 1816 can be implemented as the arbitrary image processor of above-detailed
Feature.
Touch-screen display 1803, communication interface 1804-1807, GPS interface 1808, sensor 1809,1810 and of camera
Each in speaker/microphone, codec 1813,1814 can be considered as relative to the various of entire computing system
The I/O (for example, input and/or output) of form, in the appropriate case, the entire computing system also includes that integrated periphery is set
Standby (for example, one or more cameras 1810).According to embodiment, the various I/O components in these I/O components can be integrated in
On application processor/multi-core processor 1850, or chip exterior or application processor/multi-core processor 1850 can be located at
Package outside.
In one embodiment, one or more cameras 1810 include between capable of measuring object in camera and its visual field
Depth depth camera.Application processor or other processors general-purpose CPU (or with instruction execution pipeline to hold
Other functional blocks of line program code) on the application software, operating system software, device driver software and/or the firmware that execute can
To execute any of the above described function.
The embodiment of the present invention may include various processes as described above.It is executable that these processes can be embodied in machine
In instruction.These instructions may be used to general or specialized processor and execute certain processes.Alternatively, these processes can be by wrapping
Specific hardware components containing hardwired and/or programmable logic for implementation procedure or the computer module by programming and fixed
Any combinations of hardware component processed execute.
The element of the present invention can also be provided as the machine readable media for storing machine-executable instruction.Machine can
Read medium can include but is not limited to floppy disk, CD, CD-ROM and magneto-optic disk, FLASH memory, ROM, RAM, EPROM,
EEPROM, magnetic or optical card, communications media or other types media/machine readable media suitable for storing e-command.For example,
The present invention can be used as computer program to download, which can be by the number that is embodied in carrier wave or other propagation mediums
It is believed that number being transmitted to from remote computer (for example, server) via communication link (for example, modem or network connection)
Requesting computer (for example, client).
In the foregoing specification, the present invention is described by with reference to the specific illustrative embodiment of the present invention.However,
In the case of not departing from broader spirit and scope of the present invention as described in the appended claims, it is clear that can be made to it various
Modification and change.Therefore, the description and the appended drawings should be considered as illustrative and not limiting property meaning.
Claims (according to the 19th article of modification of treaty)
1. a kind of method, including：
For the program code of the image processor with programmable process cores, each process cores include that two dimension executes channel for compiling
Array circuit structure and two-dimensional shift register array circuit structure, said program code for realizing directed acyclic graph and by
Multiple kernel compositions, the kernel will each execute on the different disposal core in the process cores, wherein the compiling packet
It includes：
(a) determine that the number of the kernel in said program code is different from the number of the process cores in described image processor；
(b) in response to above-mentioned (a), any one during execution is following is to change the kernel for realizing the directed acyclic graph
Number：
Level fusion kernel；
Vertical fusion kernel；
Divide kernel spacing into multiple space partition zone kernels；
Directed acyclic graph is divided into multiple directed acyclic graphs.
2. according to the method described in claim 1, wherein, level fusion kernel further comprises concatenated programs stream so that first
Kernel is merged prior to the second fusion kernel.
3. according to the method described in claim 2, wherein, level fusion kernel further comprises changing the first fusion kernel
Each at least one of the second fusion kernel completes consumed calling.
4. according to the method described in claim 3, wherein, the modification further comprises one or more cycle being added to table
It levies and merges the few fusion kernel of kernel than another to complete the consumed period every time.
5. according to the method described in any one preceding claims, wherein vertical fusion kernel further comprises applying program generation
Code is to postpone the beginning of consumption fusion kernel.
6. according to the method described in claim 5, wherein, apply the delay, described vertically melted with ensuring to reside to execute
Close kernel process cores execute channel array except register space haloing region will include consumption fusion kernel institute according to
Bad data.
7. according to the method described in any one preceding claims, wherein about it is above-mentioned a), process cores be more than kernel.
8. according to the method described in any one preceding claims, wherein the space partition zone further comprises adjusting described more
The X, Y coordinates value of kernel in a space partition zone kernel so that the multiple space partition zone kernel refers to their own image
Part.
9. according to the method described in any one preceding claims, wherein directed acyclic graph is divided into multiple directed acyclic graphs
Further comprise adding the memory stored data into outside described image processor in one in exporting small routine
Instruction and/or order and in another in inputting the small routine addition from depositing outside described image processor
Reservoir loads the instruction and/or order of data.
10. according to the method described in claim 9, wherein, the multiple directed acyclic graph is configured to write-in each and exists
Corresponding line buffer unit in described image processor.
11. a kind of method, including：
For the program code of the image processor with programmable process cores, each process cores include that two dimension executes channel for compiling
Array circuit structure and two-dimensional shift register array circuit structure, said program code for realizing directed acyclic graph and by
Multiple kernel compositions, the kernel will each execute on the different disposal core in the process cores, wherein the compiling packet
It includes：
(a) determine that the computational intensity of at least one of described kernel is higher than another in the kernel；
(b) in response to above-mentioned (a), any one during execution is following：
Level fusion kernel；
Vertical fusion kernel；
One in the kernel is split into multiple kernels；
Divide kernel spacing into multiple space partition zone kernels；
Directed acyclic graph is divided into multiple directed acyclic graphs.
12. according to the method for claim 11, wherein level fusion kernel further comprises concatenated programs stream so that the
One fusion kernel is prior to the second fusion kernel.
13. method according to claim 11 or 12, wherein vertical fusion kernel further comprise applying program code with
The beginning of delay consumption fusion kernel.
14. the method according to any one of claim 11 to 13, wherein split into one in the kernel more
A kernel further comprises：The instruction and/or order of data table memory list are added in one in exporting the multiple kernel,
The data form will be by that will execute the two-dimensional shift register array structures of the process cores of a kernel in the multiple kernel
It provides；And in another in inputting the multiple kernel addition load data form instruction and/or order, the number
To be loaded into according to list will execute the two-dimensional shift register array of the process cores of another kernel in the multiple kernel
In structure.
15. the method according to any one of claim 11 to 14, wherein space partition zone further comprises described in adjustment
The X, Y coordinates value of kernel in multiple space partition zone kernels so that the multiple space partition zone kernel refers to their own figure
As part.
16. the method according to any one of claim 11 to 15, wherein be divided into directed acyclic graph multiple oriented
Acyclic figure further comprises that addition stores data at described image in one in exporting small routine as a result
It is added when another in the instruction and/or order of the memory outside reason device and the small routine as a result described in input
The instruction and/or order of data are loaded from the memory outside described image processor.
17. a kind of method, including：
For the program code of the image processor with programmable process cores, each process cores include that two dimension executes channel for compiling
Array circuit structure and two-dimensional shift register array circuit structure, said program code for realizing directed acyclic graph and by
Multiple kernel compositions, the kernel will each execute on the different disposal core in the process cores, wherein the compiling packet
It includes：
(a) determine that the resource requirement of said program code is more than the memory capacity of described image processor；
(b) in response to above-mentioned (a), any one during execution is following：
One in the kernel is split into multiple kernels；
Divide kernel spacing into multiple space partition zone kernels；
Directed acyclic graph is divided into multiple directed acyclic graphs.
18. according to the method for claim 17, wherein space partition zone further comprises adjusting in the multiple space partition zone
The X, Y coordinates value of kernel in core so that the multiple space partition zone kernel refers to their own image section.
19. the method according to claim 17 or 18, wherein be divided into multiple directed acyclic graphs into one directed acyclic graph
Addition stores data into the finger of the memory outside described image processor when step is included in one in output small routine
Enable and/or order and in another in inputting the small routine addition from the memory outside described image processor
Load the instruction and/or order of data.
20. according to the method for claim 19, wherein described image processor is included in generation and consumption in different disposal
The line buffer unit of image data is stored and forwarded between the kernel executed on core, and wherein, multiple directed acyclic graph quilts
The corresponding line buffer unit being configured in the line buffer unit of the write-in each in described image processor.
21. a kind of machine readable storage comprising the program code for executing the method described in any one preceding claims is situated between
Matter.
Claims (21)
1. a kind of method, including：
For the program code of the image processor with programmable templates processor, each template processor includes two dimension for compiling
Channel and shift-register circuit structure are executed, said program code is for realizing directed acyclic graph and by multiple core groups
At the kernel will execute on the corresponding template processor in the template processor, wherein the compiling includes：
(a) determine that the number of the kernel in said program code is different from the number of the template processor in described image processor
Mesh；
(b) in response to above-mentioned (a), any one during execution is following：
Level fusion kernel；
Vertical fusion kernel；
Divide kernel spacing into multiple space partition zone kernels；
Directed acyclic graph is divided into multiple directed acyclic graphs.
2. according to the method described in claim 1, wherein, level fusion kernel further comprises concatenated programs stream so that first
Kernel is merged prior to the second fusion kernel.
3. according to the method described in claim 2, wherein, level fusion kernel further comprises changing the first fusion kernel
Each at least one of the second fusion kernel completes consumed calling.
4. according to the method described in claim 3, wherein, the modification further comprises one or more cycle being added to tool
Have and completes the consumed less fusion kernel of calling every time.
5. according to the method described in any one preceding claims, wherein vertical fusion kernel further comprises applying program generation
Code is to postpone the beginning of consumption fusion kernel.
6. according to the method described in claim 5, wherein, apply the delay, described vertically melted with ensuring to reside to execute
The haloing region for executing the register space except channel space for closing the template processor of kernel will include consumption fusion kernel
The data relied on.
7. according to the method described in any one preceding claims, wherein template processor is more than kernel.
8. according to the method described in any one preceding claims, wherein the space partition zone further comprises adjusting described more
The X, Y coordinates value of kernel in a space partition zone kernel so that the multiple space partition zone kernel refers to their own image
Part.
9. according to the method described in any one preceding claims, wherein directed acyclic graph is divided into multiple directed acyclic graphs
Further comprise adding the memory stored data into outside described image processor in one in exporting small routine
Instruction and/or order and in another in inputting the small routine addition from depositing outside described image processor
Reservoir loads the instruction and/or order of data.
10. according to the method described in claim 9, wherein, the multiple directed acyclic graph is configured to write-in each and exists
Corresponding line buffer unit in described image processor.
11. a kind of method, including：
For the program code of the image processor with programmable templates processor, each template processor includes two dimension for compiling
Channel and shift-register circuit structure are executed, said program code is for realizing directed acyclic graph and by multiple core groups
At the kernel will execute on the corresponding template processor in the template processor, wherein the compiling includes：
(a) determine that the computational intensity of at least one of described kernel is higher than another in the kernel；
(b) in response to above-mentioned (a), any one during execution is following：
Level fusion kernel；
Vertical fusion kernel；
One in the kernel is split into multiple kernels；
Divide kernel spacing into multiple space partition zone kernels；
Directed acyclic graph is divided into multiple directed acyclic graphs.
12. according to the method for claim 11, wherein level fusion kernel further comprises concatenated programs stream so that the
One fusion kernel is prior to the second fusion kernel.
13. method according to claim 11 or 12, wherein vertical fusion kernel further comprise applying program code with
The beginning of delay consumption fusion kernel.
14. the method according to any one of claim 11 to 13, wherein split into one in the kernel more
A kernel further comprise the instruction and/or order of the addition data table memory list in one in exporting the multiple kernel with
And in another in inputting the multiple kernel addition load data form instruction and/or order.
15. the method according to any one of claim 11 to 14, wherein space partition zone further comprises described in adjustment
The X, Y coordinates value of kernel in multiple space partition zone kernels so that the multiple space partition zone kernel refers to their own figure
As part.
16. the method according to any one of claim 11 to 15, wherein be divided into directed acyclic graph multiple oriented
Acyclic figure, which further comprises adding in one in exporting small routine, to be stored data into outside described image processor
The instruction and/or order of memory and in another in inputting the small routine addition from outside described image processor
The instruction and/or order of the memory load data in portion.
17. a kind of method, including：
For the program code of the image processor with programmable templates processor, each template processor includes two dimension for compiling
Channel and shift-register circuit structure are executed, said program code is for realizing directed acyclic graph and by multiple core groups
At the kernel will execute on the corresponding template processor in the template processor, wherein the compiling includes：
(a) determine that the resource requirement of said program code is more than the memory capacity of described image processor；
(b) in response to above-mentioned (a), any one during execution is following：
One in the kernel is split into multiple kernels；
Divide kernel spacing into multiple space partition zone kernels；
Directed acyclic graph is divided into multiple directed acyclic graphs.
18. according to the method for claim 17, wherein space partition zone further comprises adjusting in the multiple space partition zone
The X, Y coordinates value of kernel in core so that the multiple space partition zone kernel refers to their own image section.
19. the method according to claim 17 or 18, wherein be divided into multiple directed acyclic graphs into one directed acyclic graph
Addition stores data into the finger of the memory outside described image processor when step is included in one in output small routine
Enable and/or order and in another in inputting the small routine addition from the memory outside described image processor
Load the instruction and/or order of data.
20. according to the method for claim 19, wherein the multiple directed acyclic graph is configured to write-in each and exists
Corresponding line buffer unit in described image processor.
21. a kind of machine readable storage comprising the program code for executing the method described in any one preceding claims is situated between
Matter.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201662300684P | 2016-02-26 | 2016-02-26 | |
US62/300,684 | 2016-02-26 | ||
US15/389,113 US10387988B2 (en) | 2016-02-26 | 2016-12-22 | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform |
US15/389,113 | 2016-12-22 | ||
PCT/US2016/068932 WO2017146816A1 (en) | 2016-02-26 | 2016-12-28 | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform |
Publications (2)
Publication Number | Publication Date |
---|---|
CN108541321A true CN108541321A (en) | 2018-09-14 |
CN108541321B CN108541321B (en) | 2023-04-18 |
Family
ID=59678542
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680080956.4A Active CN108541321B (en) | 2016-02-26 | 2016-12-28 | Compilation technique for mapping program code onto a high-performance, power-efficient programmable image processing hardware platform |
Country Status (7)
Country | Link |
---|---|
US (3) | US10387988B2 (en) |
EP (1) | EP3420527B1 (en) |
JP (2) | JP6704056B2 (en) |
KR (1) | KR102009906B1 (en) |
CN (1) | CN108541321B (en) |
TW (2) | TWI614689B (en) |
WO (1) | WO2017146816A1 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110399124A (en) * | 2019-07-19 | 2019-11-01 | 浪潮电子信息产业股份有限公司 | A kind of code generating method, device, equipment and readable storage medium storing program for executing |
CN112558938A (en) * | 2020-12-16 | 2021-03-26 | 中国科学院空天信息创新研究院 | Machine learning workflow scheduling method and system based on directed acyclic graph |
CN116484822A (en) * | 2023-06-26 | 2023-07-25 | 和创（北京）科技股份有限公司 | Form field expression circular dependency calculation method and device |
Families Citing this family (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10204396B2 (en) * | 2016-02-26 | 2019-02-12 | Google Llc | Compiler managed memory for image processor |
US10387988B2 (en) * | 2016-02-26 | 2019-08-20 | Google Llc | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform |
CN108885776B (en) * | 2016-03-24 | 2022-09-27 | 富士胶片株式会社 | Image processing apparatus, image processing method, and storage medium |
US10534639B2 (en) * | 2017-07-06 | 2020-01-14 | Bitfusion.io, Inc. | Virtualization of multiple coprocessors |
JP2019074967A (en) * | 2017-10-17 | 2019-05-16 | キヤノン株式会社 | Filter processor and method for controlling the same |
EP3707855A1 (en) | 2017-11-09 | 2020-09-16 | Nchain Holdings Limited | System for securing verification key from alteration and verifying validity of a proof of correctness |
JP7208990B2 (en) | 2017-11-09 | 2023-01-19 | エヌチェーン ライセンシング アーゲー | Systems and methods for ensuring correct execution of computer programs using mediator computer systems |
KR20200096248A (en) | 2017-12-13 | 2020-08-11 | 엔체인 홀딩스 리미티드 | Systems and methods for securely sharing cryptographic materials |
US10983583B2 (en) * | 2018-08-23 | 2021-04-20 | Apple Inc. | Electronic display reduced blanking duration systems and methods |
JP2022500755A (en) * | 2018-09-11 | 2022-01-04 | ホアウェイ・テクノロジーズ・カンパニー・リミテッド | Heterogeneous scheduling for sequential DAG |
KR102023855B1 (en) * | 2018-12-05 | 2019-09-20 | 전자부품연구원 | Deep Learning Running Hardware Accelerator |
CN110147236B (en) * | 2019-04-30 | 2023-01-31 | 创新先进技术有限公司 | Code compiling method and device |
US10552121B1 (en) * | 2019-05-07 | 2020-02-04 | Capital One Services, Llc | System and method for dynamic process flow control based on real-time events |
DE102019129362B4 (en) | 2019-10-30 | 2023-09-07 | Chie-Hee Cho-Nöth | Device and method for measuring the core temperature of a human or animal body under MRI conditions |
KR102490539B1 (en) * | 2019-12-30 | 2023-01-19 | 주식회사 모레 | Method for generating program for use in accelerator for deep learning |
WO2021137669A1 (en) * | 2019-12-30 | 2021-07-08 | 매니코어소프트주식회사 | Method for generating program for accelerator for deep learning |
JP7459954B2 (en) | 2020-09-28 | 2024-04-02 | 日本電気株式会社 | Information processing device, information processing method, and information processing program |
CN112860267B (en) * | 2021-04-23 | 2021-07-30 | 武汉深之度科技有限公司 | Kernel cutting method and computing device |
BE1029306B1 (en) * | 2021-04-30 | 2023-07-14 | Zebra Technologies | INDUSTRIAL ETHERNET CONFIGURATION TOOL WITH PREVIEW FUNCTIONS |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101556543A (en) * | 2008-04-09 | 2009-10-14 | 辉达公司 | Execution of retargetted graphics processor accelerated code by a general purpose processor |
US20130091507A1 (en) * | 2011-10-11 | 2013-04-11 | Nec Laboratories America, Inc. | Optimizing data warehousing applications for gpus using dynamic stream scheduling and dispatch of fused and split kernels |
CN103870246A (en) * | 2012-12-10 | 2014-06-18 | 辉达公司 | Compiler-controlled region scheduling for simd execution of threads |
US20140204232A1 (en) * | 2013-01-24 | 2014-07-24 | Analog Devices Technology | Descriptor-based stream processor for image processing and method associated therewith |
CN110574011A (en) * | 2017-05-12 | 2019-12-13 | 谷歌有限责任公司 | Determination of memory allocation per line buffer unit |
Family Cites Families (84)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US156284A (en) | 1874-10-27 | Improvement in railway-car brakes | ||
US4445177A (en) | 1981-05-22 | 1984-04-24 | Data General Corporation | Digital data processing system utilizing a unique arithmetic logic unit for handling uniquely identifiable addresses for operands and instructions |
DE3851005T2 (en) | 1987-06-01 | 1995-04-20 | Applied Intelligent Syst Inc | Parallel neighboring processing system and method. |
US4935894A (en) | 1987-08-31 | 1990-06-19 | Motorola, Inc. | Multi-processor, multi-bus system with bus interface comprising FIFO register stocks for receiving and transmitting data and control information |
US5253308A (en) | 1989-06-21 | 1993-10-12 | Amber Engineering, Inc. | Massively parallel digital image data processor using pixel-mapped input/output and relative indexed addressing |
WO1994009595A1 (en) | 1991-09-20 | 1994-04-28 | Shaw Venson M | Method and apparatus including system architecture for multimedia communications |
JP3482660B2 (en) | 1993-09-08 | 2003-12-22 | ソニー株式会社 | Image data processing apparatus and image data processing method |
US5612693A (en) | 1994-12-14 | 1997-03-18 | International Business Machines Corporation | Sliding window data compression using a toroidal bit shift register |
JP3573755B2 (en) | 1996-01-15 | 2004-10-06 | シーメンス アクチエンゲゼルシヤフト | Image processing processor |
US5892962A (en) | 1996-11-12 | 1999-04-06 | Lucent Technologies Inc. | FPGA-based processor |
US6366289B1 (en) | 1998-07-17 | 2002-04-02 | Microsoft Corporation | Method and system for managing a display image in compressed and uncompressed blocks |
US6587158B1 (en) | 1998-07-23 | 2003-07-01 | Dvdo, Inc. | Method and apparatus for reducing on-chip memory in vertical video processing |
US7010177B1 (en) | 1998-08-27 | 2006-03-07 | Intel Corporation | Portability of digital images |
EP1164544B1 (en) | 1999-03-16 | 2011-11-02 | Hamamatsu Photonics K.K. | High-speed vision sensor |
JP3922859B2 (en) | 1999-12-28 | 2007-05-30 | 株式会社リコー | Image processing apparatus, image processing method, and computer-readable recording medium storing program for causing computer to execute the method |
US6745319B1 (en) | 2000-02-18 | 2004-06-01 | Texas Instruments Incorporated | Microprocessor with instructions for shuffling and dealing data |
US6728862B1 (en) | 2000-05-22 | 2004-04-27 | Gazelle Technology Corporation | Processor array and parallel data processing methods |
US6728722B1 (en) | 2000-08-28 | 2004-04-27 | Sun Microsystems, Inc. | General data structure for describing logical data spaces |
US7286717B2 (en) | 2001-10-31 | 2007-10-23 | Ricoh Company, Ltd. | Image data processing device processing a plurality of series of data items simultaneously in parallel |
JP4146654B2 (en) | 2002-02-28 | 2008-09-10 | 株式会社リコー | Image processing circuit, composite image processing circuit, and image forming apparatus |
US9170812B2 (en) | 2002-03-21 | 2015-10-27 | Pact Xpp Technologies Ag | Data processing system having integrated pipelined array data processor |
WO2003088033A1 (en) | 2002-04-09 | 2003-10-23 | University Of Rochester | Multiplier-based processor-in-memory architectures for image and graphics processing |
AU2003286131A1 (en) | 2002-08-07 | 2004-03-19 | Pact Xpp Technologies Ag | Method and device for processing data |
US7624174B2 (en) * | 2003-05-22 | 2009-11-24 | Microsoft Corporation | Self-learning method and system for detecting abnormalities |
US20060044576A1 (en) | 2004-07-30 | 2006-03-02 | Kabushiki Kaisha Toshiba | Apparatus for image processing |
US8578389B1 (en) * | 2004-05-04 | 2013-11-05 | Oracle America, Inc. | Method and system for merging directed acyclic graphs representing data flow codes |
US7667764B2 (en) | 2004-06-04 | 2010-02-23 | Konica Minolta Holdings, Inc. | Image sensing apparatus |
JP4219887B2 (en) | 2004-12-28 | 2009-02-04 | 富士通マイクロエレクトロニクス株式会社 | Image processing apparatus and image processing method |
ATE504043T1 (en) | 2005-04-28 | 2011-04-15 | Univ Edinburgh | RECONFIGURABLE INSTRUCTION CELL ARRAY |
US7882339B2 (en) | 2005-06-23 | 2011-02-01 | Intel Corporation | Primitives to enhance thread-level speculation |
US7953158B2 (en) * | 2005-06-30 | 2011-05-31 | Intel Corporation | Computation transformations for streaming applications on multiprocessors |
JP2007067917A (en) | 2005-08-31 | 2007-03-15 | Matsushita Electric Ind Co Ltd | Image data processing apparatus |
US7602974B2 (en) | 2005-10-21 | 2009-10-13 | Mobilic Technology (Cayman) Corp. | Universal fixed-pixel-size ISP scheme |
FR2895103B1 (en) | 2005-12-19 | 2008-02-22 | Dxo Labs Sa | METHOD AND SYSTEM FOR PROCESSING DIGITAL DATA |
US7802073B1 (en) | 2006-03-29 | 2010-09-21 | Oracle America, Inc. | Virtual core management |
US8438365B2 (en) * | 2006-10-06 | 2013-05-07 | Calos Fund Limited Liability Company | Efficient data loading in a data-parallel processor |
US20080111823A1 (en) | 2006-11-13 | 2008-05-15 | Faraday Technology Corp. | Graphics processing system |
EP1927949A1 (en) * | 2006-12-01 | 2008-06-04 | Thomson Licensing | Array of processing elements with local registers |
US8321849B2 (en) | 2007-01-26 | 2012-11-27 | Nvidia Corporation | Virtual architecture and instruction set for parallel thread computing |
US20080244222A1 (en) | 2007-03-30 | 2008-10-02 | Intel Corporation | Many-core processing using virtual processors |
JP4389976B2 (en) | 2007-06-29 | 2009-12-24 | ブラザー工業株式会社 | Image processing apparatus and image processing program |
JP4844853B2 (en) | 2007-09-05 | 2011-12-28 | 国立大学法人東北大学 | Solid-state imaging device and driving method thereof |
US8174534B2 (en) * | 2007-12-06 | 2012-05-08 | Via Technologies, Inc. | Shader processing systems and methods |
US8106914B2 (en) * | 2007-12-07 | 2012-01-31 | Nvidia Corporation | Fused multiply-add functional unit |
US7995845B2 (en) * | 2008-01-30 | 2011-08-09 | Qualcomm Incorporated | Digital signal pattern detection and classification using kernel fusion |
CN102047241B (en) * | 2008-05-30 | 2014-03-12 | 先进微装置公司 | Local and global data share |
JP4999791B2 (en) | 2008-06-30 | 2012-08-15 | キヤノン株式会社 | Information processing apparatus, control method thereof, and program |
US9690591B2 (en) | 2008-10-30 | 2017-06-27 | Intel Corporation | System and method for fusing instructions queued during a time window defined by a delay counter |
US8456480B2 (en) * | 2009-01-14 | 2013-06-04 | Calos Fund Limited Liability Company | Method for chaining image-processing functions on a SIMD processor |
KR101572879B1 (en) * | 2009-04-29 | 2015-12-01 | 삼성전자주식회사 | Dynamic parallel system and method for parallel application program |
US9354944B2 (en) * | 2009-07-27 | 2016-05-31 | Advanced Micro Devices, Inc. | Mapping processing logic having data-parallel threads across processors |
US20110055495A1 (en) | 2009-08-28 | 2011-03-03 | Qualcomm Incorporated | Memory Controller Page Management Devices, Systems, and Methods |
US8976195B1 (en) | 2009-10-14 | 2015-03-10 | Nvidia Corporation | Generating clip state for a batch of vertices |
US8436857B2 (en) | 2009-10-20 | 2013-05-07 | Oracle America, Inc. | System and method for applying level of detail schemes |
US8595428B2 (en) | 2009-12-22 | 2013-11-26 | Intel Corporation | Memory controller functionalities to support data swizzling |
US8856496B2 (en) | 2010-04-27 | 2014-10-07 | Via Technologies, Inc. | Microprocessor that fuses load-alu-store and JCC macroinstructions |
US8749667B2 (en) | 2010-08-02 | 2014-06-10 | Texas Instruments Incorporated | System and method for maintaining maximum input rate while up-scaling an image vertically |
US8508612B2 (en) | 2010-09-30 | 2013-08-13 | Apple Inc. | Image signal processor line buffer configuration for processing ram image data |
US8797323B2 (en) * | 2011-01-18 | 2014-08-05 | Intel Corporation | Shadowing dynamic volumetric media |
WO2012105174A1 (en) | 2011-01-31 | 2012-08-09 | パナソニック株式会社 | Program generation device, program generation method, processor device, and multiprocessor system |
US9092267B2 (en) | 2011-06-20 | 2015-07-28 | Qualcomm Incorporated | Memory sharing in graphics processing unit |
US20130027416A1 (en) | 2011-07-25 | 2013-01-31 | Karthikeyan Vaithianathan | Gather method and apparatus for media processing accelerators |
JP5742651B2 (en) | 2011-10-15 | 2015-07-01 | コニカミノルタ株式会社 | Image processing apparatus, linkage method, and linkage program |
JP5746100B2 (en) | 2011-12-27 | 2015-07-08 | 京セラドキュメントソリューションズ株式会社 | Image forming apparatus |
US8823736B2 (en) * | 2012-01-20 | 2014-09-02 | Intel Corporation | Graphics tiling architecture with bounding volume hierarchies |
US10244246B2 (en) | 2012-02-02 | 2019-03-26 | Texas Instruments Incorporated | Sub-pictures for pixel rate balancing on multi-core platforms |
US9235769B2 (en) | 2012-03-15 | 2016-01-12 | Herta Security, S.L. | Parallel object detection method for heterogeneous multithreaded microarchitectures |
TWI520598B (en) | 2012-05-23 | 2016-02-01 | 晨星半導體股份有限公司 | Image processing apparatus and image processing method |
WO2013178245A1 (en) * | 2012-05-29 | 2013-12-05 | Qatar Foundation | A graphics processing unit controller, host system, and methods |
US9232139B2 (en) | 2012-07-24 | 2016-01-05 | Apple Inc. | Image stabilization using striped output transformation unit |
US9378181B2 (en) | 2012-11-09 | 2016-06-28 | Intel Corporation | Scalable computing array |
US8954992B2 (en) | 2013-03-15 | 2015-02-10 | Lenovo Enterprise Solutions (Singapore) Pte. Ltd. | Distributed and scaled-out network switch and packet processing |
US20150277904A1 (en) | 2014-03-28 | 2015-10-01 | Roger Espasa | Method and apparatus for performing a plurality of multiplication operations |
US9818166B2 (en) * | 2015-01-16 | 2017-11-14 | Intel Corporation | Graph-based application programming interface architectures with producer/consumer nodes for enhanced image processing parallelism |
US9749548B2 (en) | 2015-01-22 | 2017-08-29 | Google Inc. | Virtual linebuffers for image signal processors |
US10095479B2 (en) | 2015-04-23 | 2018-10-09 | Google Llc | Virtual image processor instruction set architecture (ISA) and memory model and exemplary target hardware having a two-dimensional shift array structure |
US9756268B2 (en) | 2015-04-23 | 2017-09-05 | Google Inc. | Line buffer unit for image processor |
US10291813B2 (en) | 2015-04-23 | 2019-05-14 | Google Llc | Sheet generator for image processor |
US9785423B2 (en) | 2015-04-23 | 2017-10-10 | Google Inc. | Compiler for translating between a virtual image processor instruction set architecture (ISA) and target hardware having a two-dimensional shift array structure |
US9769356B2 (en) | 2015-04-23 | 2017-09-19 | Google Inc. | Two dimensional shift array for image processor |
US9965824B2 (en) | 2015-04-23 | 2018-05-08 | Google Llc | Architecture for high performance, power efficient, programmable image processing |
US9772852B2 (en) | 2015-04-23 | 2017-09-26 | Google Inc. | Energy efficient processor core architecture for image processor |
CN105023289A (en) | 2015-07-08 | 2015-11-04 | 成都梦工厂网络信息有限公司 | Graphic image three-dimensional processing platform |
US10387988B2 (en) * | 2016-02-26 | 2019-08-20 | Google Llc | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform |
-
2016
- 2016-12-22 US US15/389,113 patent/US10387988B2/en active Active
- 2016-12-28 KR KR1020187022160A patent/KR102009906B1/en active IP Right Grant
- 2016-12-28 CN CN201680080956.4A patent/CN108541321B/en active Active
- 2016-12-28 JP JP2018539837A patent/JP6704056B2/en active Active
- 2016-12-28 WO PCT/US2016/068932 patent/WO2017146816A1/en active Application Filing
- 2016-12-28 EP EP16829467.6A patent/EP3420527B1/en active Active
- 2016-12-30 TW TW105144288A patent/TWI614689B/en active
- 2016-12-30 TW TW106140542A patent/TWI635443B/en active
-
2017
- 2017-06-20 US US15/628,480 patent/US10387989B2/en active Active
-
2019
- 2019-08-01 US US16/529,633 patent/US20200020069A1/en not_active Abandoned
- 2019-12-02 JP JP2019218095A patent/JP6858239B2/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101556543A (en) * | 2008-04-09 | 2009-10-14 | 辉达公司 | Execution of retargetted graphics processor accelerated code by a general purpose processor |
US20130091507A1 (en) * | 2011-10-11 | 2013-04-11 | Nec Laboratories America, Inc. | Optimizing data warehousing applications for gpus using dynamic stream scheduling and dispatch of fused and split kernels |
CN103870246A (en) * | 2012-12-10 | 2014-06-18 | 辉达公司 | Compiler-controlled region scheduling for simd execution of threads |
US20140204232A1 (en) * | 2013-01-24 | 2014-07-24 | Analog Devices Technology | Descriptor-based stream processor for image processing and method associated therewith |
CN110574011A (en) * | 2017-05-12 | 2019-12-13 | 谷歌有限责任公司 | Determination of memory allocation per line buffer unit |
Non-Patent Citations (1)
Title |
---|
WM CHAO，ET AL.: "Pyramid Architecture for 3840 X 2160 Quad Full High Definition 30 Frames/s Video Acquisition", 《IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY》 * |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110399124A (en) * | 2019-07-19 | 2019-11-01 | 浪潮电子信息产业股份有限公司 | A kind of code generating method, device, equipment and readable storage medium storing program for executing |
CN110399124B (en) * | 2019-07-19 | 2022-04-22 | 浪潮电子信息产业股份有限公司 | Code generation method, device, equipment and readable storage medium |
CN112558938A (en) * | 2020-12-16 | 2021-03-26 | 中国科学院空天信息创新研究院 | Machine learning workflow scheduling method and system based on directed acyclic graph |
CN112558938B (en) * | 2020-12-16 | 2021-11-09 | 中国科学院空天信息创新研究院 | Machine learning workflow scheduling method and system based on directed acyclic graph |
CN116484822A (en) * | 2023-06-26 | 2023-07-25 | 和创（北京）科技股份有限公司 | Form field expression circular dependency calculation method and device |
CN116484822B (en) * | 2023-06-26 | 2023-09-01 | 和创（北京）科技股份有限公司 | Form field expression circular dependency calculation method and device |
Also Published As
Publication number | Publication date |
---|---|
EP3420527B1 (en) | 2021-07-14 |
TW201810036A (en) | 2018-03-16 |
US10387988B2 (en) | 2019-08-20 |
KR102009906B1 (en) | 2019-08-12 |
US10387989B2 (en) | 2019-08-20 |
EP3420527A1 (en) | 2019-01-02 |
CN108541321B (en) | 2023-04-18 |
TWI614689B (en) | 2018-02-11 |
US20170287103A1 (en) | 2017-10-05 |
US20170249716A1 (en) | 2017-08-31 |
TWI635443B (en) | 2018-09-11 |
JP2020061168A (en) | 2020-04-16 |
KR20180100372A (en) | 2018-09-10 |
JP6858239B2 (en) | 2021-04-14 |
US20200020069A1 (en) | 2020-01-16 |
JP6704056B2 (en) | 2020-06-03 |
TW201800940A (en) | 2018-01-01 |
JP2019508802A (en) | 2019-03-28 |
WO2017146816A1 (en) | 2017-08-31 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN108541321A (en) | Program code is mapped to the technique of compiling of the programmable graphics processing hardware platform of high-performance, high effect | |
JP7202987B2 (en) | Architecture for High Performance, Power Efficient, Programmable Image Processing | |
US11182138B2 (en) | Compiler for translating between a virtual image processor instruction set architecture (ISA) and target hardware having a two-dimensional shift array structure | |
JP6793162B2 (en) | Line buffer unit for image processor | |
US10216487B2 (en) | Virtual image processor instruction set architecture (ISA) and memory model and exemplary target hardware having a two-dimensional shift array structure | |
CN107430760A (en) | Two-dimensional shift array for image processor | |
JP6750022B2 (en) | Macro I/O unit for image processor |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |