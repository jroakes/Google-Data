CN107690305A - Image is produced from video - Google Patents
Image is produced from video Download PDFInfo
- Publication number
- CN107690305A CN107690305A CN201680030438.1A CN201680030438A CN107690305A CN 107690305 A CN107690305 A CN 107690305A CN 201680030438 A CN201680030438 A CN 201680030438A CN 107690305 A CN107690305 A CN 107690305A
- Authority
- CN
- China
- Prior art keywords
- equipment
- frame
- seizure
- video
- movement
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B13/00—Burglar, theft or intruder alarms
- G08B13/18—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength
- G08B13/189—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems
- G08B13/194—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems using image scanning and comparing systems
- G08B13/196—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems using image scanning and comparing systems using television cameras
- G08B13/19602—Image analysis to detect motion of the intruder, e.g. by frame subtraction
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/02—Detecting, measuring or recording pulse, heart rate, blood pressure or blood flow; Combined pulse/heart-rate/blood pressure determination; Evaluating a cardiovascular condition not otherwise provided for, e.g. using combinations of techniques provided for in this group with electrocardiography or electroauscultation; Heart catheters for measuring blood pressure
- A61B5/02007—Evaluating blood vessel condition, e.g. elasticity, compliance
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/2343—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/02—Detecting, measuring or recording pulse, heart rate, blood pressure or blood flow; Combined pulse/heart-rate/blood pressure determination; Evaluating a cardiovascular condition not otherwise provided for, e.g. using combinations of techniques provided for in this group with electrocardiography or electroauscultation; Heart catheters for measuring blood pressure
- A61B5/021—Measuring pressure in heart or blood vessels
- A61B5/0215—Measuring pressure in heart or blood vessels by means inserted into the body
- A61B5/02158—Measuring pressure in heart or blood vessels by means inserted into the body provided with two or more sensor elements
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/02—Detecting, measuring or recording pulse, heart rate, blood pressure or blood flow; Combined pulse/heart-rate/blood pressure determination; Evaluating a cardiovascular condition not otherwise provided for, e.g. using combinations of techniques provided for in this group with electrocardiography or electroauscultation; Heart catheters for measuring blood pressure
- A61B5/026—Measuring blood flow
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/02—Detecting, measuring or recording pulse, heart rate, blood pressure or blood flow; Combined pulse/heart-rate/blood pressure determination; Evaluating a cardiovascular condition not otherwise provided for, e.g. using combinations of techniques provided for in this group with electrocardiography or electroauscultation; Heart catheters for measuring blood pressure
- A61B5/026—Measuring blood flow
- A61B5/0265—Measuring blood flow using electromagnetic means, e.g. electromagnetic flowmeter
- A61B5/027—Measuring blood flow using electromagnetic means, e.g. electromagnetic flowmeter using catheters
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/48—Other medical applications
- A61B5/4836—Diagnosis combined with treatment in closed-loop systems or methods
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/68—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient
- A61B5/6846—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient specially adapted to be brought in contact with an internal body part, i.e. invasive
- A61B5/6847—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient specially adapted to be brought in contact with an internal body part, i.e. invasive mounted on an invasive device
- A61B5/6851—Guide wires
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/68—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient
- A61B5/6846—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient specially adapted to be brought in contact with an internal body part, i.e. invasive
- A61B5/6847—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient specially adapted to be brought in contact with an internal body part, i.e. invasive mounted on an invasive device
- A61B5/6852—Catheters
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/72—Signal processing specially adapted for physiological signals or for diagnostic purposes
- A61B5/7235—Details of waveform analysis
- A61B5/7246—Details of waveform analysis using correlation, e.g. template matching or determination of similarity
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/74—Details of notification to user or communication with user or patient ; user input means
- A61B5/742—Details of notification to user or communication with user or patient ; user input means using visual displays
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/74—Details of notification to user or communication with user or patient ; user input means
- A61B5/7475—User input or interface means, e.g. keyboard, pointing device, joystick
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/02—Input arrangements using manually operated switches, e.g. using keyboards or dials
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/20—Analysis of motion
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/40—Scenes; Scene-specific elements in video content
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B13/00—Burglar, theft or intruder alarms
- G08B13/18—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength
- G08B13/189—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems
- G08B13/194—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems using image scanning and comparing systems
- G08B13/196—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems using image scanning and comparing systems using television cameras
- G08B13/19602—Image analysis to detect motion of the intruder, e.g. by frame subtraction
- G08B13/19606—Discriminating between target movement or movement in an area of interest and other non-signicative movements, e.g. target movements induced by camera shake or movements of pets, falling leaves, rotating fan
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/61—Control of cameras or camera modules based on recognised objects
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/63—Control of cameras or camera modules by using electronic viewfinders
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/68—Control of cameras or camera modules for stable pick-up of the scene, e.g. compensating for camera body vibrations
- H04N23/681—Motion detection
- H04N23/6812—Motion detection based on additional sensors, e.g. acceleration sensors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/68—Control of cameras or camera modules for stable pick-up of the scene, e.g. compensating for camera body vibrations
- H04N23/682—Vibration or motion blur correction
- H04N23/683—Vibration or motion blur correction performed by a processor, e.g. controlling the readout of an image memory
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/14—Picture signal circuitry for video frequency region
- H04N5/144—Movement detection
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B2560/00—Constructional details of operational features of apparatus; Accessories for medical measuring apparatus
- A61B2560/02—Operational features
- A61B2560/0223—Operational features of calibration, e.g. protocols for calibrating sensors
- A61B2560/0238—Means for recording calibration data
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B2560/00—Constructional details of operational features of apparatus; Accessories for medical measuring apparatus
- A61B2560/04—Constructional details of apparatus
- A61B2560/0475—Special features of memory means, e.g. removable memory cards
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B2562/00—Details of sensors; Constructional details of sensor housings or probes; Accessories for sensors
- A61B2562/02—Details of sensors specially adapted for in-vivo measurements
- A61B2562/0247—Pressure sensors
Abstract
Embodiment relates generally to produce still image from video or the successive frame of series.In some embodiments, a kind of method, which includes receiving, catches equipment frame captured while at least two dimensions move.Methods described further comprises analyzing the frame to determine relative to the seizure equipment changes in position of the object at least two frames that the object's position caused by the movement during shooting time changes caused by object movement in the scene.Methods described further comprises being at least partially based on the variability of the object to determine one or more target subjects that the seizure equipment is caught during shooting time.One or more still images are generated from least one of multiple frames with the target subject.
Description
Background technology
The convenience of digital camera causes such as video caused by user together with widely using for internet communication
It is more popular with the image of photo etc.Theirs are remained with traditional alignment shooting formula (point and shoot) camera
While value, camera technique can be also integrated among many equipment, such as smart phone, PDA, intelligent watch, flat board
Computer, laptop computer.Enable camera technique available conveniently by user, there is provided to capture originally due to failing to catch
And the possibility for the landscape being missed.
The content of the invention
Embodiment relates generally to produce one or more from a series of still images --- such as video --- of scene
Individual still image.In some embodiments, a kind of method can be received by seizure equipment in shooting using computing device
Between during the video that is caught.The shooting time can be related to catching equipment while video is caught at least two dimensions
Move.Methods described can further be handled multiple frames of the video using the computing device and be detected relative
In the movement due to object in the scene catching object variation of the equipment caused by the movement during shooting time
Variability of the caused object at least two frames.The computing device can be at least partially based on the change of object
Property and determine one or more target subjects.The target subject is at least one expected focus in video and can be institute
State the main body for catching equipment during at least a portion of shooting time in pointed and seizure scene.The computing device
The multiple frames that can be based further on having at least one of video of the target subject and generate one or more quiet
State image.In some respects, the video before the shooting to video when it is determined that the threshold value for catching equipment starts mobile by
The seizure equipment is caught automatically.The threshold value, which starts movement, can include two or more mobilities.In some embodiment party
In formula, threshold value, which starts mobile detection, can be related to the threshold value change for the environment temperature that the seizure equipment is detected.One
In a little embodiments, threshold value start be used for initiating during movement can be based, at least in part, at least one previously shooting time to
At least one movement of the seizure equipment of the manual seizure of a few video.Following article is on described by Fig. 2A, 2B and 2C, catching
This movement for catching equipment may be at three dimensions according to x-axis, y-axis and z-axis direction.In this case, Ke Yitong
Cross and identify the target subject using equipment is caught to object progress triangulation in frame.
In some respects, methods described can include analyzing the frame in video the mould for including target subject with identification
Paste the start frame started.Methods described may further include the focusing frame before the start frame with having fuzzy target
The fuzzy frame of main body carries out overlapping so that the target subject described in the focusing frame to be alignd with the fuzzy frame.In some sides
Face, methods described can include rotating the orientation of one selected in one or more of still images, and
Utilize the content of a still image selected described in the fills in the frame from the video.
In yet other embodiments, a kind of the tangible, non-transient of such as medium for store instruction is discussed
Recordable, computer readable storage devices, the instruction make when being captured performed by the one or more processors of equipment
It must operate and be carried out.The non-transitory computer-readable medium can be caused by seizure equipment with store instruction, the instruction
Catch video automatically during shooting time.The instruction can cause one or more mobility quilts of the seizure equipment
Receive.For example, the one or more sensors for catching equipment can detect and provide mobility.The instruction can be with
So that being at least partially based on one or more of mobilities determines that the threshold value for catching equipment starts movement, it is one or more
The individual mobility instruction intention for catching equipment and obtaining image, and activation utilizes when it is determined that the threshold value starts mobile
The seizure equipment is caught automatically during shooting time to video.In some embodiments, the instruction can make
The seizure equipment must be detected during at least a portion of shooting time in the movement of at least two dimensions.The instruction can be with
So that determine relative to pair caused by movement detected during catching at least a portion of equipment in shooting time
The variational object caused by object movement in the scene of elephant in multiple frames of video at least two
Variability in frame.In addition, the instruction can cause the movement of the variability for being at least partially based on object and seizure equipment
It is determined that one or more target subjects.From multiple at least one of video with one or more of target subjects
Frame, the instruction can to generate one or more still images.
In some embodiments, one or more of mobilities can include the ring that the seizure equipment is detected
The threshold value of border temperature changes.In some other embodiments, one or more of mobilities include ambient light, pressure and red
The threshold value of one or more of outer light changes.The threshold value, which starts movement, can be at least partially based on the two of the seizure equipment
The combination of individual or more mobility.
Sometimes, the equipment that catches can be in three dimensions movement according to x-axis, y-axis and z-axis direction, and is used to know
Other target subject frame processing can be further used in frame using catch equipment to object progress triangulation.
In some embodiments, the frame processing that the second computing device is carried out can be further used for determining wherein first
It is able to detect that the fuzzy start frame of target subject；Determine the focusing frame before the start frame；By the focusing frame and tool
The fuzzy frame for having fuzzy object main body carries out overlapping；And by the mesh in target subject and the fuzzy frame in the focusing frame
Mark main body alignment.In some embodiments, frame processing can be further used for selected in one or more still images
The orientation of one rotated, and utilize a static state selected described in the fills in the frame from the video
The content of image.
In other embodiment, a kind of image capture system is provided and can include one or more processors
And the memory coupled to the processor.The memory can be configured as the instruction that storage is such as applied, the finger
Order causes one or more of processors to receive the video for catching the scene that equipment is caught during shooting time, described to regard
Frequency includes movement of the seizure equipment at least two dimensions.The system may further determine that to be set relative to the seizure
Variability in standby at least two frames in the object of the movement during shooting time in multiple frames from the video.Institute
The system of stating can be at least partially based on the object variability and it is described catch equipment movement come determine it is described seizure set
Standby pointed one or more target subjects during at least a portion of shooting time, and from one or more
Multiple frames at least one of video in individual target subject identify one or more still images to be deposited
Storage.
In some embodiments, the video can be before the seizure to video it is determined that the threshold value for catching equipment opens
Caught automatically by the seizure equipment when dynamic mobile.The threshold value starts movement can be based on to two or more mobilities
Detection.The mobility can include the environment temperature for the seizure equipment that two or more sensors are detected, accelerate
Degree, orientation, height above sea level, inclination and it is in rotary moving in two or more.The threshold value starts mobile detection can be including described
The threshold value for catching the environment temperature that equipment is detected changes.The threshold value startup movement can be based, at least in part, at least one
It is used for initiating at least one movement of the seizure equipment of the manual seizure of at least one video during previous shooting time.At some
In embodiment, the movement for catching equipment may be at three dimensions according to x-axis, y-axis and z-axis direction, and identification target
Main body may further include in frame using catch equipment to object carry out triangulation.
In some embodiments, the instruction can be with further such that one or more of or processor determines wherein
The fuzzy start frame of target subject is able to detect that first；Determine the focusing frame before the start frame；By the focusing frame
It is overlapping with the fuzzy frame progress with fuzzy object main body；And by the target subject and the fuzzy frame in the focusing frame
Target subject alignment.In some embodiments, the instruction can be with further such that one or more of processors pair
The orientation of one selected in one or more still images is rotated, and is utilized in the frame from the video
Hold the content of a filling selected still image.
In some embodiments, a kind of device (apparatus) can be provided and including for receiving by catching
The device (means) of the video for the scene that equipment is caught during shooting time, the video include the seizure equipment and existed
The movement of at least two dimensions.Such means for receiving (means) can for example include described device (apparatus)
Interface.Described device (apparatus) may further include for analyze the frame of the video with determine relative to due to
It is described catch object caused by movement of the equipment during shooting time it is variational due to the object in the scene
The variational device (means) of the object at least two frames caused by mobile.Described device (apparatus) can wrap
At least a portion phase to determine the seizure equipment in shooting time is included for being at least partially based on the variability of the object
Between pointed one or more target subjects device (means).It is such to be used to determine one or more target subjects
Device (means) can for example include the selection component of described device.Described device can also include being used for from the mesh
Marking multiple frames at least one of video in main body identifies one or more still images for the device of storage
(means) the selection component and/or establishment component of described device, are such as passed through.
Brief description of the drawings
Fig. 1 is to illustrate wherein implement showing from the various aspects of video generation still image in image capture system
The concept map of example environment；
Fig. 2A, 2B and 2C are that diagram catches the concept map that equipment shoots the example of video during capture phase；
Fig. 3 a and 3b are the flow charts of instantiation procedure, and wherein Fig. 3 a show the pre-captured stage, and Fig. 3 b then show and caught
Frame processing and generation still image after catching；
Fig. 4 is that diagram is implemented from the seizure equipment in the image capture system of the process of video generation still image and calculating
The schematic diagram of the selected exemplary components of equipment；All accompanying drawings are all according to the disclosure.
Embodiment
In various embodiments, a kind of image capture system is provided from a series of companies caught using equipment is caught
The instrument of continuous picture frame --- such as video --- generation still image.Described image, which catches system and can provided, to be made it possible to pair
Image carries out the method after pre-captured, seizure and seizure.In some embodiments, during the pre-captured stage, equipment is caught
It can be triggered and catch equipment setting to catch image and/or automatic reparation automatically or change to catch image.Catching rank
During section, such as the series of successive frames of video or continuous image shooting etc can be captured.In some embodiments, shooting
During time, catch equipment and fluctuated during at least a portion of capture phase in all directions.The stage after seizure, institute
Stating image capture system can select and handle one or more of caught frame so as to produce still image.The frame can
With the various views including orienting clapped scene from different seizure equipment, they are used to produce one or more of the scene
Individual still image.
In some embodiments, for catching picture frame, selecting frame and processing frame to produce the process of still image
Some or all of can be performed in identical equipment, such as catch equipment.In some other embodiments, the pre-captured
The seizure of process and frame can perform on one device --- and equipment is for example caught, and selects, edit and produce static map
Process can perform on another after the seizure of picture --- for example, such as client/server or cloud-type framework
Computing device.Equipment for the various processes of generation still image described herein can be mobile device, desk-top calculating
Machine etc..
The seizure equipment can shoot video, such as frame each second 24 (fps) at various rates to 30fps, or with
Such as 60fps, 120fps and 240fps higher rate, and the speed of even more high.In some embodiments, it is described to set
It is standby can with such as 2fps to 5fps or 10fps --- such as 3fps --- various speed in continuous capturing pattern (continuous shooting mould
Formula) under shoot a series of frame.The speed can keep constant during shooting, such as can change, such as
Started with such as 3-10fps fast velocity, be then then slow rate.Can be in single continuous shooting in single image file
Catch the frame of various quantity, such as 10 to 15 frames or more than 15 frames, such as 20 to 40 frames.
Described image seizure system provides the Effective selection of a large amount of frames so as to create the still image of lesser amt, described
Still image can be used in a variety of ways, such as stored, shared, watched.For example, it can catch and analyze more than number
Hundred or thousands of frame of video to produce single or several still images.The still image can be regarded in video from described
The one or more frames or partial frame of frequency are created or replicated and electronically stored segmentation, such as photo.
The embodiment that described image catches system can be to attempting to be aided in from the user of scene capture still image.
User may be interested in bat picture, but is so that seizure equipment (for example, camera, smart phone camera etc.) the ready time can
The risk for losing picture chance can be faced with.Prepare equipment and the excessive time is expended with shooting figure sector-meeting.For example, prepare to catch equipment
May include open catch equipment (for example, start, from dormancy awakening, unblock, or otherwise activation catch equipment) or
Person stops catching another operation of equipment, starts camera applications (for example, in smart phone, tablet PC or wearable setting
Standby upper loading software application；Enter camera mode, etc. in individual camera), camera applications loading is waited (for example, in intelligence
In the random access memory of phone) so that camera is focused (for example, manually focusing, auto-focusing etc.) in main body, with
And activation capture button.In other contexts or for miscellaneous equipment, prepare seizure equipment and may also contain other behaviour
Make, regulation resolution ratio, frame per second, color mode etc..It is probably to lose to prepare to catch the consequence that the time-bands needed for equipment are come
Take a picture or otherwise catch the chance of moment.
In an illustrated examples, slider is likely encountered the mountain lion run and the slider may attempt to quickly catch
Catch the picture of this animal.The slider is used for capture apparatus taking out his or her pocket and shoots the available of mountain lion photo
(for example, one second or shorter) very short during time.Increasingly complex, the slider can also while attempting to shoot photo
Slope can just be slided.If the slider can capture fast and easily the moment with mountain lion would is that it is favourable.
The camera technique for the platform aspired for stability and focused is for wanting the slider of shooting clear and complete animal painting
For can bring challenges.In some embodiments, described image catches system and provides a kind of quick response instrument, and it causes
Slider can be by simply pulling out seizure equipment and automatically snapping scene --- for example keep lock in the seizure equipment
While determining --- and obtain the still image of high quality.The slider can avoid for activation camera technique and so that catch
Catch the needs of equipment focusing.
In some instances, the seizure equipment can be scanned with angle so as to obtain regarding for scene at various orientations
Frequently.Therefore, the seizure equipment can be while video be caught in horizontal level, upright position or any angled fixed
To being held.The seizure equipment is also possible to random or free form direction occur in two dimension or three-dimensional during shooting
The mobile scene to be caught with substantially drawing.For example, the slider be able to will clap when mountain lion passes through his or her path
Equipment is taken the photograph from side to opposite side pan.
In some embodiments, catching equipment can be relatively constantly held, but the people for gripping camera but may
It is moved or rotates.For example, the slider to be jumped, or the dancer of wearing camera may catch dancer around other
While dance.Therefore, catch equipment movement and be inferred to relative motion be present between seizure equipment and scene.At some
In embodiment, such relative movement can be identified, and be compensated in some cases when producing image.
In the case of slider, slider by rugged landform to while traveling under mountain, catch equipment can be with
The video of mountain lion scene is caught while being moved with the general direction for the mountain lion run.Described image catches system can be with
Main body and seizure both equipment movement clap this and look the video for being difficult to catch, and produce the one or more of the mountain lion
Fully static image.
In the examples described above, catching equipment can detect that slider catches the intention of the scene with mountain lion, and make
The start recording video for response.For example, temperature sensor can be included by catching equipment, its detect seizure equipment from pocket or
External temperature when being removed in sack declines.Ambient lighting meter may also detect that the increase of outside illumination.Accelerometer, gyro
Instrument and/or compass can then detect the movement and directed change for catching equipment when it is moved in place.
In some embodiments, catching for video can be swashed being locked and being in the seizure equipment of screen saver mode
It is living.The seizure equipment simultaneously need not be unlocked such that automatic seizure video.In some instances, seizure can be swashed automatically
It is living.In some instances, catching can be activated based on the user action such as gesture, voice command.
Catching the automatic activation of equipment can enable to perform when some things interested occur or in user
Picture catching is carried out while other movable, for example, detecting jump in skiing, sliding or other events of interest；
Go hunting or on foot when detect the appearance of animal and catch video automatically；Image etc. is caught automatically when being at play or watch motion.
In addition, automatic catch can be fixed camera in the base (for example, purse, head are fixed, be worn on around neck in user
Deng) when used.For example, the seizure equipment installed in neck can automatically detect the presence of people and trigger automatically to that
The video of people is caught.
The stage after seizure, other files from the video or successive frame that catch equipment can be processed to determine full
One or more frames of some selection standard of foot.The selection standard can include the description of target subject.Described image is caught
System can for example determine the target main body of the video or file by analyzing each frame.Video or continuous wherein
During at least a portion for the shooting time that frame is captured, equipment is caught --- such as catch equipment camera lens, aperture or other
Catch component --- it can point to or the target subject is caught towards target subject.
In the example of slider, some frame of video may comprise at least some and such as snow, sky of mountain lion
With a large amount of surroundings of tree etc.Described image seizure system can analyze the object in each frame, and determine institute in frame
The special object --- such as mountain lion --- of description is moving.Object can be followed due to catching equipment, so mobile object
It can be the shared element in many frames.Described image catches system can be by mobile object with not showed in background and prospect
It is compared for other objects that the equipment that is captured is followed.
In the case of slider, described image, which catches system, can select target subject of the mountain lion as video, without
It is to be confirmed as static various other objects in the scene, such as tree, snow and sky.Even if it can capture around more
Object, can also frame by frame determine that the type on periphery is varied from, such as video capture multiple different trees, snowfall region and
Sky portion.However, it is possible to it is well established that the video only captures a mountain lion.Therefore, described image catch system can be with
The object for being inferred to be followed is target subject rather than the peripheral objects of change.
In some embodiments, the target subject can be determined by user's input.For example, user can catch
The target subject object that caught frame is checked in equipment and is described by touching at least one frame is come selection target master
Body, chosen from the selection of possibility target subject for being presented to user, target subject, and image are stated with text mode
Seizure system can identify the target subject in the frame using natural language processing and image identification, using phonetic entry or
Person is other to input forms to identify target subject.
Described image catch one in the video that system can select to include target subject or series of successive frames or
Multiple frames.In some embodiments, the new still image being not present in any one institute's captured frame can be created.
In some embodiments, the content of each frame in video or series can be used when creating still image.For example,
One frame can be selected for editor and content can be quoted or merged from other frames so as to obtain pair of main body
Burnt better image, reducing the motion of main body influences, and improves the color characteristic of main body, improves dynamic range, such as from shadow region
Domain is moved to main body of bright areas, etc..
Sometimes, one or more frames with target subject can be further processed is connected with improving from video or series
The quality of the still image of continuous frame.As an example, the defects of for example fuzzy in frame interested, can be by accessing its in video
The content of its frame and be corrected.In some embodiments, the part of multiple frames or frame can be stitched together to complete
Object, such as target subject.Further, since the loss of data caused by the suture on non-matching border can utilize and come from other frames
Content and be filled.Some examples of editor are described below with respect to Fig. 1.
Fig. 1, which is illustrated, is wherein used for the example context for implementing some embodiments of image capture system 100.In some implementations
In mode, image capture system 100 can include catching equipment 106 to catch the video of scene 104 or a system by user 102
Row successive frame.System 100 may further include computing device 120 to handle the video and generate the static map of scene 104
Picture.In some embodiments, computing device 120, which can be integrated in, catches in equipment 106.In other embodiment,
Catching equipment 106 and computing device 120 can be communicated with the generation of the still image of implement scene 104 with across a network 112.Figure
As seizure system 100 causes the usual and uncomfortable of scene 104 for being played even in all children as shown in Figure 1 of user 102 etc
It is also easy to capture the still image of high quality under conditions of preferably.
In the example depicted in fig. 1, user 102 can will purposely catch equipment 106 and be moved to direction from resting position
The orientation of the scene, and such movement can be interpreted to catch the user view of scene 104.In some embodiments
In, catching some mobilities of equipment can be come by using one or more sensors associated with catching equipment 106
Detection.The sensor, which can be internally positioned in, to be caught within equipment, is fixed to the surface for catching equipment, is removedly connect
It is bonded to and catches equipment, etc..Mobile module can be provided to solve pyroelectric sensor number by representing the sensing data of mobility
According to.One or more mobilities can be recognized as meeting that instruction user catches one or more images by the mobile module
The threshold value of intention starts movement.Furthermore, it is possible in the presence of the intention that can be recognized as user's seizure image and activate oneself of image
The dynamic other forms for catching and/or repairing or change seizure equipment and set.Some additional morphologicals can include gesture, the language of user
The position, etc. of equipment occurs, caught for sound order, the detection of special body, event.
Ready position can be moved into so as to catch scene from static by catching equipment 106.In various embodiments,
Catching equipment 106 can detect that the threshold value for catching equipment 106 starts mobile and automatically begins to video due to catching equipment 106
Or the seizure of serial successive frame, the threshold value start the intention that mobile instruction user catches video.The startup movement can wrap
Include and represent that catch equipment 106 exists from resting position to the various mobilities for the change for catching ready position, the seizure equipment
The seizure ready position prepares photographed scene.In some embodiments, exposure, focusing, HDR, filter etc.
Various trap settings can also be repaired automatically based on the detected mobility for for example catching equipment orientation etc
Or change.The resting position can catch the optional position of equipment 106, be not proposed in the equipment and be located in institute
Rheme is put to catch image.For example, catching equipment 106 may be placed among pocket, sack, knapsack, coat-sleeve etc..In some realities
Apply in mode, other non-capture functions can be performed while in resting position by catching equipment 106.For example, catch equipment
106 can be held progress call, text, Email, object for appreciation game, online etc. by user.In some instances, catch just
Thread position, which can include gripping, catches equipment 106 to cause camera lens towards target subject or in target master in face of scene
The general direction of body.In one example, substantially vertical (or horizontal) position of equipment can be included by catching ready position, wherein
Camera aperture or camera lens are not blocked (for example, different when being placed on from equipment in user's pocket).In some instances, catch just
The seizure equipment that thread position can be sensed based on such as one or more sensors motion (for example, by equipment lifting some amount,
Slewing etc.) determine.
Mobility can be included to catching the physically changed of equipment 106 or mobile detection.For example, in some embodiment party
In formula, mobility can include the acceleration of equipment.For example, catching equipment 106 goes to the movement for catching ready position with catching
The mobile phase ratio for catching the difference in functionality that equipment execution such as sends text etc may be at higher rate.Rate of acceleration can also compare
Other actions are slower, such as slower than the speed that seizure equipment is dropped towards ground.The threshold value or scope of rate of acceleration can be caught
A kind of instruction of the intention of image.
The camera lens that another example of mobility can include wherein catching equipment 106 are directed away from catching for user
Catch the directed change of equipment 106.Therefore, threshold value mobility can be from such as level or keep flat orientation (for example, representing that seizure is set
The 180 degree of standby faced downwards represents to catch 360 degree of device side upward) a directional-rotation to wherein camera lens
The orientation increment of upward position (such as 90 degree of rotations) outwardly.Some catch equipment orientation (such as horizontal cross position) can be with table
User is shown with to want to catch the possibility increased of video.In addition, the certain tilt for catching equipment may be constructed mobile spy
Property.
In another example, threshold level or Level Change can be as the another of the intention that can indicate seizure image
Kind mobility.In some instances, the altimeter or barometer for catching equipment can detect height above sea level.In some embodiments
In, such as physical characteristic of the user of user's height etc can be used to seizure device height being defined as mobility.Example
Such as, catch equipment by child's gripping come shooting image height may than be grown up gripping device height it is shorter.In some implementations
In mode, it can be highly varied from based on the environment context for catching equipment.Such as, if it is determined that catch equipment and be in movement
Vehicle in, such as determined by GPS or accelerometer, then compared with the seizure device height of standing user, it is high to catch equipment
Degree can be directed to the user being seated and be decreased to appropriate height.
It is related to the position that other mobilities of the detection of physics movement can include catching equipment 106.For example, catch
Equipment 106, which can be determined that, for example positions or is positioned in other places by the GPS in seizure equipment 106, in such as
Mark etc popular picture catching position or its near.In some embodiments, the popularity of position can be based on user
Preference.For example, image capture system can in the index be detected, stored and access the previous behavior of user and can access
Database, such as it is stored in the database of remote location.In some embodiments, user can be accessed in shooting before
Between shot the position of image manually using catching equipment 106.
Described image, which catches system, can also access the previous web models of user, Email or other communications to determine
The event that user position of special interest and/or user arrange in calendar.For example, user may issue her will
The party of her child is participated in school's theater in specific date and time.Such as gps coordinate theater locations and event when
Between can be stored in as mobility in index.It is determined being in the position when catching equipment 106 --- for example in event
Place is registered or the gps coordinate by matching is determined --- and during to event time, catching equipment 106 can be by certainly
It is dynamic to activate to catch image.
In some embodiments, catching the position of equipment can refer to compared with other seizure equipment of the position
Show the intention in the position capture image.For example, if other seizure equipment of some quantity in the position are being caught
Image and the image caught is uploaded to social media site, then the position is probably independent or combined other detected
Mobility triggers the mobility caught automatically together.In some embodiments, the mobility of such as position etc can
With the prompting for the other mobilities for causing monitoring such as to catch equipment Acceleration and orientation etc for catching equipment, and
Activation is automatic when threshold value starts mobile catches.
Mobility can also be included from the various conditions change caught detected by equipment 106.For example, the condition of expression becomes
The mobility of change can include catching the change that equipment 106 is exposed to ambient temperature therein.Internal temperature changes
It can be detected as mobility.Such temperature change can for example catch equipment 106 from pocket, knapsack or barrier
Occur during taking-up.Temperature can catch equipment march to or exposed to open environment to shoot video when become cooler.
It is outer in the environment for catching equipment that other mobilities of expression condition change can include seizure equipment
The change of portion's light.For example, in some instances, such as chest, pocket, the back of the body can be stored in when static by catching equipment 106
In the dark surrounds of bag etc. and it is moved into the environment with more light.Light change can be when preparing to catch image by having
Institute increased lumen detects.
The mobility that sensor is detected may further include infrared light.For example, body heat or motion can be by
Infrared sensor detects and the change of infrared light can indicate to catch the intention of image.In some embodiments, it is mobile
Characteristic can include the thermal change compared with background heat from object.In other embodiment, pressure can be made
It is sensed for mobility.It can be detected when threshold value starts mobile and use other mobilities.
In some embodiments, threshold value starts the multiple mobilities that can be detected of movement and met, such as two
It is individual or more, three or more, etc..In some embodiments, threshold value start movement can by such as acceleration, height and
The particular combination of the mobility of orientation is reached.Some combinations of mobility can change for determining to start mobile threshold
Value.For example, the detection that seizure equipment 106 is in ad-hoc location may cause automatic trigger of one additional mobility of requirement to be caught
Catch equipment.As a comparison, catch equipment and be in the detections of other positions and then may require two or more mobilities and could reach
Start to threshold value and move.
In some embodiments, detected mobility can be endowed the possibility for the intention for representing to catch image
The numerical value of property.Threshold value, which starts movement, to be reached by one or more mobility numerical value, and the numerical value can be combined and comment
Estimate to reach special value threshold value.For example, numerical value can be had by catching the movement that equipment goes to substantially horizontal transversal orientation
3, the acceleration rate in particular range can have numerical value 5, and the height change in particular range can have
There is numerical value 2.Total value 10 can sufficiently achieve threshold value and start automatic video frequency seizure that is mobile and triggering seizure equipment.
In some embodiments, for starting mobile mobility and/or threshold value can be pre-arranged and base
In the action for the intention for being confirmed as instruction user seizure image or the availability evidence of seizure device data.Such availability
Evidence can include the behavior of the user study group for the startup movement for being considered representative of the user of shooting photo and video.
In some embodiments, described image, which catches system, can utilize the action for the specific user for catching equipment 106
And apply the various learning arts of such as neutral net process.For example, benchmark mobility can manually catch image when quilt
It is detected and stored in the index.The benchmark mobility can be used to change each seed ginseng for the intention that instruction catches image
Number, such as adjusting --- for example increase or reduce --- threshold value, increases new mobility, changes the combination of mobility, change
Become threshold value and start movement, etc..By this way, the automatic seizure to image is adapted to the speciality of user.
In some embodiments, image capture system 100 can enable the user for catching equipment to specify and/or together
The use for some information of anticipating, this can include image capture system 100 and use and store with catching image and catching equipment
Using associated behavior, identity information of people identified in recognisable image, etc..For example, image capture system 100 can
The multiple choices used of customizing messages are used to specify and/or agree to provide the user.It is for example, relevant specified and/or same
The selection of meaning can be with specific seizure equipment, the application for catching equipment and component, individual images, all images, individual photograph album, institute
There is photograph album etc. associated.The selection can be implemented in a variety of ways.For example, image capture system 100 can cause button
Or check box is such as displayed on by various selections on a display device 108.In some embodiments, system 100 causes social activity
The user of network can generally specify and/or agree to the purposes for being used for face recognition using their image.
Some information of the systematic collection relevant user discussed herein or the situation that some information are used
Under, user can be provided to control program or feature for make image capture system adapt to user learning art in whether
Collect user profile (for example, the social networks of relevant user, the prior images of user's selection, social action or activity, occupation,
The preference of user or the information of the current location of user), or to how to select and/or handle caught possibility and user's phase
The chance that the image of pass is controlled.
In addition, some data can be processed in one or more ways before it is by storage or use, and cause certain
A little information are removed.For example, the identity of user can be processed and so that information can not be determined for user, or can be with
Carrying out vague generalization processing to the geographical position for obtaining the user at positional information, (such as processing is the level in city, ZIP codes or state
Do not cause the ad-hoc location that can not determine user).Therefore, how user can collect and using relevant to image capture system
The information of the user is controlled by.
Various sensors in seizure equipment 106 can detect characteristic that can be mobile as the startup for catching equipment 106
Condition changes.Data can be fed to by one or more sensors catches the mobile module in equipment 106 to determine that data become
Change the threshold quantity for whether meeting to be used to refer to the startup movement for catching equipment 106.The example of such sensor can include phase
It is machine, gyroscope, accelerometer, barometer, compass, temperature sensor, proximity sensor, ambient irradiance sensor, microphone, complete
Ball alignment sensor, radio transceiver, capacitive touch screen, resistive touch sensor, fingerprint sensor, biometric pass
Sensor, infrared imaging sensor, pressure sensor, magnetic field sensor, humidity sensor, clock etc..
Multiple sensors of mobility can be detected including one or more of following：For determining linear acceleration
And detect the accelerometer with mobile associated gravity；For detecting angular velocity of rotation, transversal orientation, inclination, rolling, pitching
With the gyroscope of deflection；For determine to catch equipment 106 on the orientation (for example, where be the north) in magnetic field of the earth and with
Tesla is the magnetometer or compass that unit (magnetic force unit) measures magnetic field intensity；For measuring the air pressure for the position for catching equipment
Meter；For detect catch equipment 106 whether close to user positioning proximity sensor, for example, user ear instruction make
With telephony feature rather than shooting photo or video；For determining the GPS of position by being connected with multiple satellites.At some
In embodiment, temperature sensor can detect the temperature change for catching device external.In some embodiments, equipment is caught
106 can include optical sensor, such as in each position caught in equipment 106 --- including in display screen side and tool
There are various angular distributions --- ambient lighting meter.There may also be other sensors.
In some embodiments, sensor can be used to detection and may indicate that the intention for stopping picture catching or threshold value are whole
The mobility only moved.Start the various sensing datas for described by movement, representing mobility as described above for threshold value
It can be detected, catch the acceleration of equipment, orientation, in rotary moving, height above sea level, position, exterior light, external temperature etc..
When threshold value terminates mobile, video seizure can be terminated automatically and be transferred to the stage after seizure by catching equipment.
In fig. 1 it is shown that the seizure equipment 106 of smart phone type.The appropriate of any other type can be applied to catch
Equipment is caught to be used together with current system, such as personal digital assistant, tablet PC, mobile internet device, numeral are quiet
State camera, digital video camera, personal navigation equipment, watch, head mounted display and other wearable devices, other movements
Equipment, etc..Seizure equipment 106 according to each embodiment can catch video or series of successive frames --- for example
Burst mode --- any computing device.
In some embodiments, described image, which catches system, can be used as mobile computing device (for example, smart phone)
On Mobile solution operated.Other embodiment is any type of including being utilized as browser application or independent utility
The image capture system of computing device operation.One example can be user terminal/server framework, wherein video or continuous series
Frame can catch equipment from client and provide to computing device server, and caused still image can be from the server
It is provided to client.In another example, all data storages and calculating can be at one of such as seizure equipment 106
Performed in equipment.
In some embodiments, catching the display screen 108 in equipment 106 can be used to show that camera technique is caught
View, catch the state notifying of equipment 106 --- in such as recording process, or show for asking to enter the frame that is caught
The user interface of row processing.In some embodiments, display may not work during automatic video frequency is caught, and can
The video being currently just captured can not be shown.In these cases, the display can keep dark or can show to catch
Other functions of camera view can be excluded by catching in equipment 106.
Display screen 108 can be TFT (thin film transistor (TFT)), liquid crystal display, OLED (Organic Light Emitting Diode) display,
Head mounted display, or other appropriate Display Techniques.In some embodiments, display screen 108 is multiple point touching sensitivity
Screen.User can carry out quick the caught video and/or quiet checked using the order of amplification, percussion, rolling, stroke etc.
State image.In some embodiments, various other inputs can be received by catching equipment 106, and such as voice command and keyboard strike
Hit.It is to be appreciated that the seizure equipment 106 with other types of display screen 108 or no display screen 108 can also
It is used to be used to the video capture component of image capture system 100.
During capture phase, video or the system of scene can be caught during shooting time by catching equipment 106
Row successive frame.In some embodiments, catching equipment 106 can move during shooting in all directions, such as Fig. 2A-C
Shown in example.Fig. 2A shows the first frame 204 in the video of scene 200.Fig. 2 B show the scene caught after frame 204
200 frame 208.Fig. 2 C show the frame 212 in some time after the frame 208 shown in Fig. 2 B in scene 200.
During shooting time, catching equipment 106 can for example exist along x-axis, y-axis and/or z-axis and any direction combination
All directions move.Path of the seizure equipment 106 during seizure can be free form without predefined voyage.
In some embodiments, catching movement of the equipment during shooting time can also include changing catching equipment
Orientation, such as laterally (horizontal orientation), longitudinal direction (vertical orientation), and any angle therebetween, such as it is horizontal and vertical between
45 degree.For example, catch while path of the equipment during shooting can be the orientation of equipment in rotary moving angled sweeps
Move so as to be created that the path of essentially completed arch, partial dome or part circular or circle.It is caused to be captured
Frame can be intersection of the transverse views (zero degree) followed by the angled view for longitudinal view (about 90 degree), this results in
The scene delineations of partial dome.Continue the example, longitudinal view (about 90 degree) in the partial dome further can after
The angled view for transverse views (about 180 degree) is followed by, this results in the description of complete arch.This is continued to show
Example, the transverse views (about 180 degree) of the arch can form part circular followed by longitudinal view (about 270 degree)
Description, or proceed to transverse views (about 360 degree) so as to formed the complete circle of scene describe.
In some embodiments, catching movement of the equipment during shooting time can include for example along one or more
Axis x, y or z change the position for catching equipment.During seizure, the totality of target subject 202 can be pointed to by catching equipment 106
Direction, the target subject 202 are a cat in this example.For example, during shooting time, catching equipment can be on mesh
Mark main body 202 is moved along the x-axis with substantially horizontal direction.Catching equipment can also substantially hang down on target subject 202
Moved along y-axis in straight direction.In addition, catching equipment can move along z-axis towards or away from target subject 202.In some implementations
In mode, catch equipment 106 and need not focus on target subject.Sometimes, as shown in Fig. 2A and 2C, target subject 202 is only
It is captured in the object 206,214 that some can be represented in frame 204,212.As shown in Figure 2 B, frame 208 can be described
Whole target subject object 210.
In some embodiments, target subject object can be by comparison object main body relative to static background trees
Movement and further consider to catch movement of the equipment during shooting time to determine.Catch equipment movement can x,
Y and/or z is assessed in direction, such as carries out triangulation to catching equipment by using scene.
In some embodiments, threshold value can be chosen to have by depicting the frame 208 of whole target subject object 210
Quality produces still image.However, frame 204 and 212 can also be chosen, such as it is determined including target subject in these frames
In the case of the substantial portions of object 206,214.The frame can be edited to from other in the series of frames for catching scene
Frame adds the lack part of target subject 202.Frame can also be edited to improve quality, such as reduce fuzzy, improvement and measure, moisten
Color etc. is adornd, such as by the way that the pixel of other frames in series of frames is quoted or added for compiled frame.
With reference to figure 1, in some embodiments, catching equipment 106 can be asked with across a network 112 to the transmission of computing device 120
From video or continuous series frame generation still image during asking with the stage after seizure.Such as the frame of video can also across a network
112 are transferred into computing device 120 to be handled.In some embodiments, frame of the computing device 120 to such as video
Reception can be used for triggering computing device 120 and handling the video, regardless of whether sending or receiving request.
In some embodiments, the sensing data for catching equipment can such as be carried from equipment is caught by network 112
It is supplied to computing device.Sensing data can include representing the mobile number for catching mobility of the equipment during shooting time
According to.Mobile data can represent to catch the physical change of equipment or movement and catch condition of the equipment during shooting time to become
Change, light, pressure etc..As described above, sensing data can be from each sensor collection caught in equipment.
In each embodiment, catching equipment and computing device can independently or associated working is to implement rank after seizure
Section.For example, computing device for example can be regarded selectively from seizure device request individual frame rather than completely based on partial analysis
Frequently.Catch equipment the low resolution version of video can also be handled (for example, being directed to bandwidth limited device) and with
The frame of the low resolution sends instruction to generate still image to computing device together.In some embodiments, catch
Equipment can be pre-processed to video to identify some frames by computing device handle, etc..
In some embodiments, after seizure during the stage, the processor 122 of computing device 120 can analyze one
Or multiple caught frames (for example, frame 206,210 and 214).Can detect one or more objects in frame, and one or
Multiple objects can be characterized as being the target subject (for example, child, mountain lion etc.) of video.Selection component 216 can select video
In to create one or more frames of one or more still images from it.Selection standard can include identification target subject, with
And determine to describe at least one of frame of the target subject.Selection standard can also include before selection information, such as
Selection before the social connections people of user or user to still image.In some embodiments, it can access user's
Image albums or other images are stored to determine the user preference of still image for selection standard.
Continue the processing, the conspicuousness of each object can be determined using selecting component 126 to analyze frame, and
And corresponding conspicuousness numerical value can be stored in the index 128 in memory 124.Being considered as significant object can be by
For producing one or more still images from video.Selection standard can also include the quality of frame, be described in such as frame
The background or prospect described in the part of target subject, frame, brightness, fuzzy etc..In some embodiments, meet that threshold value is selected
Still image can be selected as by selecting the frame of standard.
In some embodiments, the selection standard can be based on user behavior and preference and be dynamically updated.For example,
If others special object is such as known by face recognition in one or more frame of video or such as wild animal is schemed
The object type of picture is confirmed as being welcome by user, then the frame with the special object can be selected for static map
Picture.In some embodiments, described image, which catches system, can access the image library of user to determine object preference.For with
Family is considered as that welcome object may be changed with the time and selection standard can also be changed correspondingly.
The establishment component 130 of computing device 120 can be captured frame-editing and/or structure from selected one or more
New still image, to be for example adjusted for any flaw in framing.In some embodiments, in frame interested
The object described may be found to be fuzzy and this fuzzy can be handled.For example, the object can also be
It is identified in consecutive frame or other frames in video sequence.In case of need, the frame with the object can be in frame
Be transferred in sequence with it is overlapping, and cause overlapping frame in institute's identification object be aligned.The object of one or more frames it is overlapping
Obscuring so as to generate higher-quality still image in frame interested can be reduced.
Content from two or more frames can also be combined by the establishment component otherwise.At some
In example, at least a portion of frame can be merged with frame interested so as to for example lack the one or more of target subject
Lose part and be added to frame interested.Frame can be combined and be stitched together more completely to be described with creating to scene.
In some embodiments, frame can be analyzed and with scarce with the object --- such as target subject --- in frame interested
Losing those frames for the content that part matches can be stitched together.
Video or continuous series frame captured by mobile seizure equipment are likely to be at various orientations and angle.For example, one
A little frames are probably that laterally, some are then longitudinal directions, and some are in angle therebetween.Frame can be along vertical boundary, horizontal boundary
Or combined along nonsymmetry boundary.For example, frame can be sewn according to diagonal relationships for frame cross-mode or
The corner of frame is sutured.In some embodiments, a series of frame in views or a part of of frame can be in various orientations
Between rotated, for example, the frame in series is probably longitudinal view, transverse views and angled view so as to form scene
Arch, partial dome or circular description.The frame or partial frame can be redirected and be stitched together as required,
And alternatively it is added to describe other frames of scene, so as to form the still image of the scene.
In some embodiments, frame interested can be rotated, from the content of other frames in video since filling,
It is cut using other technologies, smooth or editor, to produce the still image of high quality.Sometimes, after the seizure for processing
During stage, the component that creates can change the orientation of still image.
After the treatment, caused one or more still images can be stored, and such as be stored in computing device
In 120 data storage 132.In some embodiments, the still image can be transferred into seizure equipment with across a network 112
106 to be shown, additional editor, be further sent to other computing devices, issue such as social media site net
On standing, and/or stored.
In some embodiments, the frame processing can be performed by seizure equipment, be set in one or more remote computations
It is standby to perform, or performed by seizure equipment and one or more computing devices joint.In addition, the frame processing can be in seizure
After be immediately performed, or can perform a little later.For example, processing can perform in default future time, performed with regular intervals,
Or performed according to the request of the user of seizure equipment, other users or equipment.Video or serial successive frame can be stored,
Backup, abandon, labeled as " automatic to catch ", etc..
Fig. 3 a and 3b are the flow charts of instantiation procedure, and wherein Fig. 3 a show the pre-captured stage 300, and Fig. 3 b are then shown
Frame processing and generation still image 320 after seizure.
Pre-captured process can be performed by the processor in seizure equipment 106.In pre-captured rank as described above
During section, one or more sensor collection sensing datas.In fig. 3 a, sensing data directly receives 302 from sensor,
Received from sensor database collection, etc..It can start in decision block 304 from sensing data recognition threshold and move.If
The sensing data do not meet to start mobile threshold value, then other sensing data can be received in frame 302 and
Start mobile for threshold value and be monitored.
In frame 306, threshold value starts movement can be with the seizure of trigger frame, such as video or series of successive frames.In some realities
Apply in mode, during capture phase, sensing data can be received in frame 308, and be monitored to determine in frame 310 and be
It is no to be determined that threshold value terminates movement.The sensing data received in frame 308 during seizure can with frame 302 received with
It is identical or different to trigger the sensing data caught.If sensing data does not meet to terminate mobile threshold value, in addition
Sensing data can be received in frame 308 and terminate mobile for threshold value and be monitored.In frame 312, threshold value terminates movement
The end of the seizure to frame can be triggered.The process can alternatively be moved to the stage after seizure, such as shown in Fig. 3 b.
In embodiments described herein, the processor 122 of computing device 120 can perform described step
Suddenly, such as by the selection component 126 in memory 124 or by catching equipment 106.In frame 322, video or series are continuous
Frame is such as received from the intermediate equipment of the component such as server that catch equipment 106, catch equipment 106.For producing
The stage can be applied to any speed and utilize the video caught during various seizure equipment after the seizure of still image
Or serial successive frame.It can especially be caught with the video that 60 frame (fps) for example per second or higher high-speed are caught from described image
Catch system benefit.
Frame can in various orders or group is accessed and analysis.For example, in some embodiments, can order or non-
Sequentially all frames are analyzed, the subset of frame can be analyzed, or can occur to handle the different subsets of frame
Successive ignition.The quantity of analyzed frame, which can be at least partially dependent on, catches speed (number of pictures per second) and video or series even
Continue the length of frame and be varied from.In some embodiments, hundreds of or thousands of frames can be analyzed.
In frame 324, the movement in frame and static object can be identified.Can using various process identification technologies come
Identify object represented in frame.It is, for example, possible to use trees and sky segmentation, face detection, such as face recognition, nerve net
The various learning arts of network process and other processes or the process combination for identification object.Process identification process can be special
Due to the image type handled.For example, natural image can be examined using the object to generally being found in nature
The process identification technology of survey.Such identification technique can form entirety with image capture system 100.Image capture system 100
Identification algorithm technology can also be accessed by the software outside image capture system 100 or hardware.
In some embodiments, in order to which identification objects, image capture system 100 can be by objects (for example, the figure of object
Picture) compared with benchmark image and match.In some embodiments, image capture system 100 may search for benchmark image
To identify any one or more benchmark images for the object being similar in image.In some embodiments, for
Determine benchmark image, image capture system 100 can extract feature to be analyzed from the image of object, and then by that
A little features are compared with those in one or more benchmark images.For example, image capture system 100 can analyze such as face
Relative position, the size and/or shape of the characteristics of objects of portion's characteristic, physical characteristics etc..In some embodiments, picture catching
System 100 can use from the collected data of analysis and by the object in image with have match or one of similar features or
Multiple benchmark images are matched.In some embodiments, image capture system 100 can enter professional etiquette to multiple benchmark images
Format, and the object data boil down to from those images had to the compound expression of information (for example, characteristics of objects data),
And then the object in image and compound expression are compared to carry out face recognition.In some embodiments, depending on
The positional information and the context of surroundings that frequency frame is captured can be used in process identification.For example, can be in tennis
Netman is picked out on and can pick out child near school or playground.
In some cases, the object in image may look like the multiple benchmark associated with the object in identical category
Image.So, the object associated with the object in image just has high probability and the object (example associated with benchmark image
Such as, mountain lion) it is same type.
In some embodiments, in order to facilitate process identification, image capture system 100 can be distinguished using feature based
Geometry identification technique.Image capture system 100, which can also use, to be based on characteristics of objects being extracted as numerical value to be compared
Statistical method photometric analysis technology.It can also be used when by the object in image compared with one or more benchmark
The combination of geometry and photometric method.
Other identification techniques can be used.For example, image capture system 100 can use following identification technique, it is used
One or more in principal component analysis, linear discriminant analysis, elastic bunch graph matching, HMM and dynamic link matching
It is individual.It will be appreciated that image capture system 100 can use identification technique that is other known or subsequently researching and developing and/or be
System.
In some embodiments, image capture system 100 can generate the object in instruction image and given reference map
The output for the possibility (or probability) that picture matches.In some embodiments, the output can be represented as measuring (or number
Word value), the percentage confidence level that the object in such as image matches with given benchmark image.For example, numerical value 1.0 can represent
100% matching confidence level.This for example can occur when the image compared is identical or almost identical.The numerical value can be compared with
It is low, for example, have 50% chance match when be 0.5.Other types of output is possible.For example, in some embodiments
In, the output can be the confidence score of matching.
The change of the pixel cluster of such as object can be identified between sequence frames.Process in frame 324 can identify
The object being change from frame to frame, such as change position, expression-form etc., and further can change together between frames to looking
Object group sorted out.Furthermore it is possible to the object caused by the seizure equipment 106 being moved during shooting time
Change (for example, mobility as represented by mobile data), because the object in scene is mobile and it is same to catch equipment 106
Change caused by mobile and the change caused by catching the remains stationary of equipment 106 the object in scene is mobile it
Between be distinguish between.
As previously described, catching the movement of equipment 106 can be detected by sensor.For example, one or more add
Speed meter, gyroscope and/or barometer can provide mobile message, such as movement in the two dimension in x and y directions.At some
In embodiment, for example, auto-focusing etc sensor can determine depth and calculate to image distance catch equipment 106 away from
From.The range data can be used to carry out triangulation to catching the distance between equipment 106 and object.It can use each
The method of kind triangulation.Using triangulation, in addition to the movement in x and y directions, can also determine about mobile depth
Z-axis data.In a manner of this analysis one, two or three-dimensional movement, image capture system 100 can be calculated due to catching equipment
Change caused by 106 movement.Existed for example, the mobile data for catching equipment can be received and explained with determining to catch equipment
Movement during the seizure of frame.
Baseline can by the variable quantity that will occur in the case of object in the scene remains stationary in frame and
The object's position change caused by catching the movement of equipment 106 is determined between frames.Object variation between frame
Baseline value can be compared with the object variation between observed frame, so that it is determined that being based solely on the shifting of camera movement
The degree that object moves between frames outside dynamic.Object movement can be isolated and be used to further determine that video or series even
The target subject of continuous frame.Frame with target subject can be identified in decision block 326.In some embodiments, have
At least one of frame for the target subject described can be used to further analyze.As shown in frame 328, there is no target master
The frame of body can then not be used to select still image with ignored.
In frame 330, the frame with target subject can be analyzed to further determine that the quality of the frame.In decision block
332, it may be determined that whether the frame meets threshold quality.Threshold quality can include various qualitative factors, such as be retouched in frame
The destination object for the significant quantity painted or whole destination object.Qualitative factor can also include the amount distortion of frame, pseudomorphism, noise,
Acutance, contrast, brightness, dynamic range, color accuracy, vignetting, exposure, lateral chromatic aberration, Lens Flare, color moire fringes
Deng.Other qualitative factors are possible, such as factors based on user preference.
If the quality of frame is believed to satisfy threshold value, the frame can be marked as still image, as shown in frame 334.
If the quality is less than threshold value, the frame can be ignored as shown in frame 336.In some embodiments, together
Sample as shown in frame 336, can be edited --- such as smooth --- produced so as to improve by the frame with the quality for being less than threshold value
The quality of image.
In some embodiments, selected frame alternatively can reduce the fuzzy and right of object by editor 338
The movement for catching equipment compensates.The determination for catching the three-dimensional mobile --- such as x, y and/or z direction --- of equipment can be with
Contribute to analysis fuzzy and may by the movement of object in the scene, catch equipment 106 and move or combinations thereof institute
Caused other image deflects, shade, dynamic range, focusing etc..Frame can be checked to determine to show frame sequence
One or more frames of middle defect starting, the defect such as object obscure.The frame shot before start frame, such as immediately
Do not have defective frame in terms of object defect before the start frame, can carry out time-shifting and cause it is described in previous frame and
Defective frame --- such as fuzzy frame --- is overlapping.Such as the defects of fuzzy object object can be with for example preceding zero defect frame
The zero defect object of focusing object align so as to producing single zero defect image, such as the clearly object of the combination using frame
Image.
Can to frame using other edit scenarios to improve picture quality, such as mitigate in noise, including video and be not present
The situation during frame of the clear description including object.In these cases, distinguish movement caused by catching equipment 106 and
Practical object movement in scene can be used to infer the desirable image of object, such as object is for example focused in the object
Etc no defect in the case of will look how.Sequence frames can be analyzed with each of to determine rendered object
The change speed of individual aspect, the color and shape of all objects as shown in some sequence frames in this way of the aspect.It is described to change
Should be how when change can be averaged so that it is determined that the aspect of institute's rendered object is in no defect --- such as focusing ---
Occur.Once it is determined that the zero defect outward appearance of such as focusing, it is possible to the various smoothing techniques of application, coloring, intensity modification and its
Its edit tool is to generate the still image of the desired description with object --- such as different pictures ---.
In fig 3b, whether the steps in decision-making of frame 340 is established has other frame to analyze in video.If there is in addition
Frame, then the process carry out to step 306 to identify movement and the stationary objects in next frame.However, if it is determined that do not have
Other frame, then in some embodiments, in frame 342, image capture system 100 can transmit (for example, to catch equipment
106) or storage (for example, in data storage 132) one or more selected by still image.
It should be appreciated that point out unless otherwise, otherwise for any process discussed in this article, each
Within the scope of kind of embodiment, it is understood that there may be what is performed or be executed in parallel with similar or replaceable order is other, more
Few or interchangeable step.In various embodiments, the operation for operating and being performed in response to another is in preceding operation
It is not carried out in the case of not successful.In addition, it is described as wrapping from an equipment to the step of another equipment transmission data
Include and the data are sent among network 112 for miscellaneous equipment.But the miscellaneous equipment may not receive the number
According to.Similarly, miscellaneous equipment transmission may not included by being described as a step of equipment receives data from another equipment
Data.
In Fig. 4, shown according to the embodiment of image capture system catch equipment 106 and computing device 120 with
And their at least some components.
One or more controllers, such as input controller for indicating input element can be included by catching equipment 106
402 and the camera controller 404 of the seizure for controlling image, and processor 410.
One or more sensors 406 can provide data to mobile module 408.The mobile module can determine to move
Whether characteristic meets threshold value, and can further determine whether the combination of the mobility from one or more sensors is full
The threshold value that sufficient instruction user catches the intention of image starts movement.
Index 412 can store the various data that can be accessed by mobile module 408, such as mobility and previous user
Behavior.The previous user behavioral data can be it is determined that be referenced during various processes parameter.For example, for initiating or stopping catching
The prior user action for catching image can be that user is set or changed threshold value startup and terminates movement.Moreover, when selecting frame, use
Previously the selection to frame can be referenced to determine selection standard at family.Index can be with the standard of such as threshold value and scope etc
Change and be dynamically updated.Various storages can also be included by catching equipment 106, can such as be stored wherein compiled and former
The storage 414 of beginning image.
Seizure equipment 106 at the interface 420 of computing device 120 and can calculate from wave point 416 by network 112
Equipment 120 is communicated.Interface 416 and 420 makes it possible to by one or more networks 112 and remote equipment (for example, catching
Equipment, server, other computing devices) communicated.Interface 416 and 420 can include Ethernet Adaptation Unit, USB (general strings
Row bus), radio interconnected component, or other interfaces or special purpose interface based on wired or wireless standard.
Computing device 120 can include one or more processors 122 and memory 124.Processor 122, which can be handled, to be referred to
Order is so as to the execution in computing device 120, including is stored in the instruction in memory 124 or in data storage 132.Processor can
To coordinate to computing device component, the component such as apply, by the wirelessly or non-wirelessly communication of interface.In some realities
Apply in mode, multiple processors and bus can be used.
Processor 410,122 may be implemented as the chip for including the chip of independent and multiple simulation numeral processor
Group.Processor can also be implemented using various frameworks.For example, processor 410,122 can be that (sophisticated vocabulary calculates CISC
Machine) processor, RISC (Reduced Instruction Set Computer) processors or MISC (minimum instruction collection computer) processor.
" processor " includes any appropriate hardware and/or software systems, mechanism of processing data, signal or other information
Or component.Processor can be included with general Central Processing Unit, multiple processing units, the special circuit for realizing function
System, or other systems.Handle and geographical position need not be limited to or there is time restriction.For example, processor
Can " real-time ", " offline ", its function performed with " batch mode " etc..The some of processing can be by different (or identical)
Processing system performs in different time and diverse location.
Memory 124 stores the information in computing device 120.Memory 124 can be any appropriate data storage, deposit
Reservoir and/or non-transitory computer-readable storage media, including electronic storage device, such as random access memory (RAM),
Read-only storage (ROM), magnetic storage apparatus (hard disk drive etc.), flash memory, optical storage apparatus (CD, DVD etc.), disk or
CD, or suitable for store instruction (for example, program or software instruction) so as to by other tangible mediums of computing device.Example
Such as, the tangible medium of such as hardware storage device, which can be used to storage, includes the control logic of executable instruction.The instruction
Can also be comprised in electronic signal or be provided as electronic signal, for example, with from server (for example, distributed system
And/or cloud computing system) delivering software be service (SaaS) form.
One or more processors 122 and memory 124 can be implemented to select component 126, establishment component 130 and data to deposit
Storage 132.Computing device 120 can also include storage and select component 126 to analyze and select frame for utilizing and utilize establishment group
Part 130 produces the index 128 of the useful data of still image.Index 128 in data can include previous user behavioral data,
The preference that social connections people behavior, user are inputted, and the seizure for image and/or other data of selection.It is for example, special
Fixed hobby target subject or the quality threshold of frame can be inputted based on the selection before user to frame, web issues, user
Preference etc. is sorted out in the index.Index data may further include the image library of user or groups of users and the figure
As preference can be accessed to determine.
Data storage 132 and storage 414 can keep applying and other data.It is former that data storage can be utilized to storage
The various edit versions of beginning image and image.At least a portion of described information can also be stored in the He of computing device 120
Catch on disc driver or the other computer readable storage devices (not shown) in equipment 106.Such storage device bag
Include floppy device, hard disc apparatus, compact disk equipment or tape unit, flash memory or other similar solid-state memory devices, Huo Zheshe
Standby array.
Also referred to as the computer program of program, software, software application or code can also include instruction, and the instruction exists
All one or more methods of those as described herein are carried out when being performed.The computer program can calculated such as
It is embodied as in the information carrier of machine or machine readable media with tangible form, the computer or machine readable media for example store
Memory on device 124, storage device or processor 122.Machine readable media is to be used to provide to programmable processor
Arbitrary computer program product, device or the equipment of machine instruction or data.
Computing device 120 can be implemented in many different forms.In some embodiments, computing device 120 can be with
It is replaced by one or more networked servers, the server in such as system for cloud computing.In some embodiments, it can be with
Implement in the personal computer of such as desktop computer.
Any appropriate programming language and programming technique can be used to implement the routine of specific embodiment.It can use
The different programming techniques of such as process or object-oriented.The routine can be held in single processing equipment or multiple processors
OK.Although step, operation or calculating and can be provided with particular order, the order can be with different specific embodiments
It is varied from.In particular embodiments, being illustrated as continuous multiple steps in this specification can be performed simultaneously.
Numerous embodiments have been described.Optional embodiment party can be described using the feature described by conditional statement
Formula.As will be by known to those skilled in the art, functional block, method, apparatus and system described in the disclosure can be by
Integrate or be divided into the various combination of system, equipment and functional block.Although on its particular implementation to specific implementation
Mode is described, but these particular implementations are only illustrative and not restrictive.It is general illustrated by example
Thought can apply to other examples and embodiment.Therefore, can carry out it is various modification without departing from the disclosure spirit and
Scope, and other embodiment is in scope of the following claims.
Claims (20)
1. a kind of computer-implemented method for generating one or more still images, methods described include：
The video of the scene caught by seizure equipment during shooting time is received, wherein the seizure equipment is in the shooting
Moved during time at least two dimensions；
Multiple frames of the video are analyzed to determine due to the movement relative to the seizure equipment during the shooting time
Movement of the object in the scene caused by least two frames of the object in the multiple frame in variability；
And
It is based at least partially on the variability of the object and determines the seizure equipment in the shooting time at least
The one or more target subjects caught during a part；And
One or more is generated based on the multiple frame at least one of video with the target subject
Still image.
2. according to the method for claim 1, wherein the video before the seizure to the video it is determined that described catch
Catch when the threshold value of equipment starts mobile and caught automatically by the seizure equipment, wherein the threshold value starts and mobile includes two or more
More mobilities.
3. according to the method for claim 2, wherein described two or more mobilities are included by the seizure equipment institute
The threshold value of the environment temperature detected changes.
4. the one or more sensors according to the method for claim 1, further comprised from the seizure equipment receive
The sensing data of mobile data including the seizure equipment during the shooting time.
5. according to the method for claim 1, wherein the movement for catching equipment is according to x-axis, y-axis and z-axis direction
Three dimensions, and wherein, identification target subject further comprises in the multiple frame using the seizure equipment to institute
State object and carry out triangulation.
6. according to the method for claim 1, start frame is further comprised determining that, can be detected first in the start frame
To the fuzzy of the target subject；Identify the focusing frame before the start frame；By the focusing frame and there is fuzzy object master
The fuzzy frame of body carries out overlapping；And by the fuzzy mesh in the target subject and the fuzzy frame in the focusing frame
Mark main body alignment.
7. according to the method for claim 1, further comprise to one selected in one or more of still images
The orientation of individual still image is rotated, and utilizes one selected described in the fills in the frame from the video
The content of still image.
8. a kind of non-transitory computer-readable medium of store instruction, the instruction is in the one or more by seizure equipment
Cause one or more of processors when performed by reason device：
Receive one or more mobilities of the seizure equipment；
It is based at least partially on one or more of mobilities and determines that the threshold value startup of the seizure equipment is moved, described one
Individual or multiple mobility instruction intentions for catching equipment and obtaining image；
Activation is caught using the seizure equipment during shooting time to the automatic of video when it is determined that the threshold value starts mobile
Catch；
The seizure equipment is detected during at least a portion of the shooting time in the movement of at least two dimensions；
It is determined that relative to caused by seizure equipment movement detected during at least a portion of the shooting time
Object the variational object caused by object movement in the scene the video multiple frames
In at least two frames in variability；
The variability and the movement for catching equipment for being based at least partially on the object determine one or more
Individual target subject；And
One is generated from the multiple frame at least one of video with one or more of target subjects
Or multiple still images.
9. non-transitory computer-readable medium according to claim 8, wherein, one or more of mobility bags
The threshold value for including the environment temperature detected by the seizure equipment changes.
10. non-transitory computer-readable medium according to claim 9, wherein, one or more of mobilities
Threshold value including one or more of ambient light, pressure and infrared light changes.
11. non-transitory computer-readable medium according to claim 9, wherein, the threshold value starts mobile at least portion
Divide the combination of two or more mobilities of the ground based on the seizure equipment.
12. non-transitory computer-readable medium according to claim 8, wherein, the movement for catching equipment is in
According to the three of x-axis, y-axis and z-axis direction dimensions, and wherein, the instruction is further such that one or more of processing
Device carries out triangulation to determine one or more of target masters using the seizure equipment in the frame to the object
Body.
13. non-transitory computer-readable medium according to claim 8, wherein, the instruction is further such that described
One or more processors determine start frame, can detect the fuzzy of the target subject first in the start frame；Really
Focusing frame before the fixed start frame；The focusing frame is overlapping with the fuzzy frame progress with fuzzy object main body；And
The target subject in the focusing frame is alignd with the target subject in the fuzzy frame.
14. non-transitory computer-readable medium according to claim 8, wherein, the instruction is further such that described
One or more processors rotate to the orientation of a still image selected in one or more of still images,
And the content using a still image selected described in the fills in the frame from the video.
15. a kind of system for generating one or more still images, the system includes：
One or more processors；And
Coupled to the memory of one or more of processors, the memory is configured as store instruction, and the instruction exists
Cause one or more of or processor during by one or more of computing devices：
The video of the scene caught by seizure equipment during shooting time is received, the video includes the seizure equipment and existed
The movement of at least two dimensions；
It is determined that the object of the movement relative to the seizure equipment during the shooting time is from the video
The variability at least two frames in multiple frames；
Be based at least partially on the object the variability and it is described catch equipment the movement come determine one or
Multiple target subjects, the seizure equipment point to one or more of targets during at least a portion of the shooting time
Main body；And
The multiple frame identification one at least one of video from one or more of target subjects
Individual or multiple still images are for storage.
16. system according to claim 15, wherein, the video is before the seizure to the video detecting
Caught automatically by the seizure equipment when stating the threshold value startup movement for catching equipment, wherein, it is to be based on that the threshold value, which starts movement,
Detection to one or more mobilities of the seizure equipment.
17. system according to claim 16, wherein, the mobility includes being detected by two or more sensors
The environment temperature of the seizure equipment, acceleration, orientation, height above sea level, inclination and it is in rotary moving in two or more.
18. system according to claim 16, wherein, the threshold value starts movement and is based at least partially at least one
It is used for initiating at least one movement of the seizure equipment of the manual seizure of at least one video during previous shooting time.
19. system according to claim 15, wherein, the movement for catching equipment is according to x-axis, y-axis and z-axis side
To three dimensions, and identification target subject further comprise in the frame using it is described seizure equipment the object is entered
Row triangulation.
20. system according to claim 15, wherein, the instruction is further such that one or more of or processing
Device：
Start frame is determined, is able to detect that the fuzzy of the target subject first in the start frame；
Determine the focusing frame before the start frame；
The focusing frame is overlapping with the fuzzy frame progress with fuzzy object main body；And
The target subject in the focusing frame is alignd with the fuzzy object main body in the fuzzy frame.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/801,261 US9846815B2 (en) | 2015-07-16 | 2015-07-16 | Image production from video |
US14/801,261 | 2015-07-16 | ||
PCT/US2016/042617 WO2017011795A1 (en) | 2014-08-22 | 2016-07-15 | Image production from video |
Publications (2)
Publication Number | Publication Date |
---|---|
CN107690305A true CN107690305A (en) | 2018-02-13 |
CN107690305B CN107690305B (en) | 2020-10-23 |
Family
ID=56738185
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680030438.1A Active CN107690305B (en) | 2015-07-16 | 2016-07-15 | Generating images from video |
Country Status (4)
Country | Link |
---|---|
US (3) | US9846815B2 (en) |
EP (1) | EP3323236B1 (en) |
KR (1) | KR101988152B1 (en) |
CN (1) | CN107690305B (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN114342357A (en) * | 2019-09-06 | 2022-04-12 | 谷歌有限责任公司 | Event-based recording |
Families Citing this family (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9846815B2 (en) * | 2015-07-16 | 2017-12-19 | Google Inc. | Image production from video |
US10460196B2 (en) * | 2016-08-09 | 2019-10-29 | Adobe Inc. | Salient video frame establishment |
WO2018074047A1 (en) * | 2016-10-18 | 2018-04-26 | シャープ株式会社 | Information processing device, electronic device, and control method and control program of information processing device |
US20180177178A1 (en) * | 2016-12-22 | 2018-06-28 | Ria Bhakta | Animal Deterrent Apparatus |
US11030732B2 (en) * | 2017-04-14 | 2021-06-08 | Sony Interactive Entertainment Inc. | Information processing device, information processing system, and image processing method for generating a sum picture by adding pixel values of multiple pictures |
US10402043B1 (en) | 2017-08-10 | 2019-09-03 | Gopro, Inc. | Systems and methods for indicating highlights within spherical videos |
US10270967B1 (en) * | 2017-11-30 | 2019-04-23 | Gopro, Inc. | Auto-recording of media data |
SG10201913955VA (en) * | 2019-12-31 | 2021-07-29 | Sensetime Int Pte Ltd | Image recognition method and apparatus, and computer-readable storage medium |
US11227396B1 (en) * | 2020-07-16 | 2022-01-18 | Meta Platforms, Inc. | Camera parameter control using face vectors for portal |
US20230319232A1 (en) * | 2022-04-05 | 2023-10-05 | Qualcomm Incorporated | Automatic video record functionality |
US11849186B1 (en) * | 2022-06-14 | 2023-12-19 | Western Digital Technologies, Inc. | Data storage device and method for enabling metadata-based seek points for media access |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2002037179A2 (en) * | 2000-11-01 | 2002-05-10 | Koninklijke Philips Electronics N.V. | Method and apparatus for tracking an object using a camera in a hand-held processing device |
US6504569B1 (en) * | 1998-04-22 | 2003-01-07 | Grass Valley (U.S.), Inc. | 2-D extended image generation from 3-D data extracted from a video sequence |
US20090231453A1 (en) * | 2008-02-20 | 2009-09-17 | Sony Corporation | Image processing apparatus, image processing method, and program |
US20130053007A1 (en) * | 2011-08-24 | 2013-02-28 | Microsoft Corporation | Gesture-based input mode selection for mobile devices |
US8401242B2 (en) * | 2011-01-31 | 2013-03-19 | Microsoft Corporation | Real-time camera tracking using depth maps |
US20140147000A1 (en) * | 2012-11-23 | 2014-05-29 | National Taiwan University | Image tracking device and image tracking method thereof |
Family Cites Families (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP1704710A4 (en) | 2003-12-24 | 2007-09-19 | Walker Digital Llc | Method and apparatus for automatically capturing and managing images |
EP1793580B1 (en) * | 2005-12-05 | 2016-07-27 | Microsoft Technology Licensing, LLC | Camera for automatic image capture having plural capture modes with different capture triggers |
US8287281B2 (en) * | 2006-12-06 | 2012-10-16 | Microsoft Corporation | Memory training via visual journal |
KR100857090B1 (en) * | 2006-12-07 | 2008-09-05 | 엘지전자 주식회사 | Apparatus and method for controling camera operation by detected temperature |
US20090324098A1 (en) | 2008-06-27 | 2009-12-31 | Sony Ericsson Mobile Communications Ab | Mobile phone with selective photographic system and method |
US9177455B2 (en) * | 2009-05-07 | 2015-11-03 | Perpcast, Inc. | Personal safety system, method, and apparatus |
US8624998B2 (en) | 2009-06-05 | 2014-01-07 | Apple Inc. | Camera image selection based on detected device movement |
US9357118B2 (en) | 2010-02-15 | 2016-05-31 | Sony Corporation | Photograph prediction including automatic photograph recording with autofocus and method |
FR2969353A1 (en) * | 2010-12-20 | 2012-06-22 | St Ericsson Sa | METHOD FOR PRODUCING A PANORAMIC IMAGE FROM A VIDEO SEQUENCE AND APPARATUS FOR IMPLEMENTING SAID METHOD |
US20120315016A1 (en) * | 2011-06-12 | 2012-12-13 | Hei Tao Fung | Multi-Purpose Image and Video Capturing Device |
US20130010109A1 (en) * | 2011-07-08 | 2013-01-10 | Asia Optical Co., Inc. | Trail camera |
US9596398B2 (en) | 2011-09-02 | 2017-03-14 | Microsoft Technology Licensing, Llc | Automatic image capture |
US9001265B2 (en) * | 2013-02-12 | 2015-04-07 | Non-Typical, Inc. | Illumination assembly for a scouting camera |
EP2782318A1 (en) * | 2013-03-18 | 2014-09-24 | Koninklijke KPN N.V. | Allocating resources between network nodes for providing a network node function |
US9833031B2 (en) * | 2013-05-23 | 2017-12-05 | Accenture Global Services Limited | Safety accessory with situational awareness and data retention |
US9846815B2 (en) * | 2015-07-16 | 2017-12-19 | Google Inc. | Image production from video |
JP5866674B1 (en) * | 2014-07-29 | 2016-02-17 | パナソニックＩｐマネジメント株式会社 | Imaging device |
EP3007106A1 (en) * | 2014-10-08 | 2016-04-13 | Thomson Licensing | Method and apparatus for determining a detection of a defective object in an image sequence as a misdetection |
-
2015
- 2015-07-16 US US14/801,261 patent/US9846815B2/en active Active
-
2016
- 2016-07-15 KR KR1020177031439A patent/KR101988152B1/en active IP Right Grant
- 2016-07-15 CN CN201680030438.1A patent/CN107690305B/en active Active
- 2016-07-15 EP EP16753734.9A patent/EP3323236B1/en active Active
-
2017
- 2017-12-14 US US15/842,547 patent/US10289923B2/en active Active
-
2019
- 2019-05-13 US US16/411,023 patent/US10872259B2/en active Active
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6504569B1 (en) * | 1998-04-22 | 2003-01-07 | Grass Valley (U.S.), Inc. | 2-D extended image generation from 3-D data extracted from a video sequence |
WO2002037179A2 (en) * | 2000-11-01 | 2002-05-10 | Koninklijke Philips Electronics N.V. | Method and apparatus for tracking an object using a camera in a hand-held processing device |
US20090231453A1 (en) * | 2008-02-20 | 2009-09-17 | Sony Corporation | Image processing apparatus, image processing method, and program |
US8401242B2 (en) * | 2011-01-31 | 2013-03-19 | Microsoft Corporation | Real-time camera tracking using depth maps |
US20130053007A1 (en) * | 2011-08-24 | 2013-02-28 | Microsoft Corporation | Gesture-based input mode selection for mobile devices |
US20140147000A1 (en) * | 2012-11-23 | 2014-05-29 | National Taiwan University | Image tracking device and image tracking method thereof |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN114342357A (en) * | 2019-09-06 | 2022-04-12 | 谷歌有限责任公司 | Event-based recording |
CN114342357B (en) * | 2019-09-06 | 2023-12-08 | 谷歌有限责任公司 | Event-based recording |
US11895433B2 (en) | 2019-09-06 | 2024-02-06 | Google Llc | Event based recording |
Also Published As
Publication number | Publication date |
---|---|
US9846815B2 (en) | 2017-12-19 |
CN107690305B (en) | 2020-10-23 |
KR20170133441A (en) | 2017-12-05 |
KR101988152B1 (en) | 2019-06-11 |
US10872259B2 (en) | 2020-12-22 |
EP3323236B1 (en) | 2020-09-16 |
US10289923B2 (en) | 2019-05-14 |
US20190266428A1 (en) | 2019-08-29 |
US20180107888A1 (en) | 2018-04-19 |
EP3323236A1 (en) | 2018-05-23 |
US20170017855A1 (en) | 2017-01-19 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107690305A (en) | Image is produced from video | |
US20200412975A1 (en) | Content capture with audio input feedback | |
US11544884B2 (en) | Virtual clothing try-on | |
CN108702448A (en) | Unmanned plane image-pickup method and unmanned plane | |
US20220206675A1 (en) | Avatar customization system | |
CN117897734A (en) | Interactive fashion control based on body gestures | |
WO2017011795A1 (en) | Image production from video | |
CN116830158A (en) | Music reaction animation of human character | |
CN116114258A (en) | User interface for pose driven virtual effects | |
US20230269345A1 (en) | Recorded sound thumbnail | |
US20220398775A1 (en) | Localization processing service | |
CN116261850A (en) | Bone tracking for real-time virtual effects | |
CN117957043A (en) | Controlling AR games on fashion items | |
WO2023055825A1 (en) | 3d upper garment tracking | |
CN110047115B (en) | Star image shooting method and device, computer equipment and storage medium | |
US20230138677A1 (en) | Customized animation from video | |
KR102369494B1 (en) | Method, device and server for tracing golf play | |
CN117136404A (en) | Neural network for extracting accompaniment from song | |
JP6063697B2 (en) | Apparatus, method and program for image display | |
US11983826B2 (en) | 3D upper garment tracking | |
US20240152217A1 (en) | User avatar movement control using an augmented reality eyewear device | |
US20240069626A1 (en) | Timelapse re-experiencing system | |
US20230251767A1 (en) | Messaging system for resurfacing content items | |
US20230350427A1 (en) | Landing an autonomous drone with gestures | |
WO2024102820A1 (en) | User control of avatar movement using augmented reality devices |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |