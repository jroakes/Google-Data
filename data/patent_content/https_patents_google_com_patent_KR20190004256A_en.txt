KR20190004256A - Mutual noise estimation for video - Google Patents
Mutual noise estimation for video Download PDFInfo
- Publication number
- KR20190004256A KR20190004256A KR1020187018635A KR20187018635A KR20190004256A KR 20190004256 A KR20190004256 A KR 20190004256A KR 1020187018635 A KR1020187018635 A KR 1020187018635A KR 20187018635 A KR20187018635 A KR 20187018635A KR 20190004256 A KR20190004256 A KR 20190004256A
- Authority
- KR
- South Korea
- Prior art keywords
- variance
- video
- frame
- noise
- blocks
- Prior art date
Links
- 230000002123 temporal effect Effects 0.000 claims abstract description 27
- 238000000034 method Methods 0.000 claims description 54
- 230000006870 function Effects 0.000 claims description 47
- 238000009826 distribution Methods 0.000 claims description 10
- 238000004590 computer program Methods 0.000 claims description 8
- 230000006835 compression Effects 0.000 claims description 7
- 238000007906 compression Methods 0.000 claims description 7
- 238000001914 filtration Methods 0.000 claims description 7
- 238000006243 chemical reaction Methods 0.000 claims description 6
- 230000011218 segmentation Effects 0.000 claims description 6
- 230000008569 process Effects 0.000 claims description 5
- 230000001131 transforming effect Effects 0.000 claims description 4
- 238000003860 storage Methods 0.000 description 14
- 238000010586 diagram Methods 0.000 description 10
- 230000000875 corresponding effect Effects 0.000 description 8
- 230000008859 change Effects 0.000 description 3
- 239000006185 dispersion Substances 0.000 description 3
- 239000000284 extract Substances 0.000 description 3
- 238000004088 simulation Methods 0.000 description 3
- 230000005540 biological transmission Effects 0.000 description 2
- 230000001413 cellular effect Effects 0.000 description 2
- 238000004891 communication Methods 0.000 description 2
- 230000002596 correlated effect Effects 0.000 description 2
- 238000013500 data storage Methods 0.000 description 2
- 230000000694 effects Effects 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 230000008901 benefit Effects 0.000 description 1
- 239000003086 colorant Substances 0.000 description 1
- 238000005315 distribution function Methods 0.000 description 1
- 238000000605 extraction Methods 0.000 description 1
- 230000037406 food intake Effects 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 230000002441 reversible effect Effects 0.000 description 1
- 230000011273 social behavior Effects 0.000 description 1
- 230000001360 synchronised effect Effects 0.000 description 1
Images
Classifications
-
- G06T5/70—
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/14—Picture signal circuitry for video frequency region
- H04N5/21—Circuitry for suppressing or minimising disturbance, e.g. moiré or halo
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T5/00—Image enhancement or restoration
- G06T5/001—Image restoration
- G06T5/002—Denoising; Smoothing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/10—Image acquisition modality
- G06T2207/10016—Video; Image sequence
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20021—Dividing image into blocks, subimages or windows
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20172—Image enhancement details
- G06T2207/20182—Noise reduction or smoothing in the temporal domain; Spatio-temporal filtering
Abstract
구현예들은 비디오에 대한 상호 노이즈 추정을 개시한다. 한 방법은, 비디오의 프레임들의 각각의 프레임의 강도 값들에 대한 최적 프레임 노이즈 분산 - 최적 비디오 노이즈 분산은 프레임 내의 균일 블록들의 강도 값들의 공간 분산과 시간 분산 사이의 결정된 관계에 기초함 - 을 결정하는 단계, 비디오의 프레임들의 최적 프레임 노이즈 분산에 기초하여 비디오에 대한 최적 비디오 노이즈 분산을 식별하는 단계, 비디오의 각각의 프레임에 대해, 최적 비디오 노이즈 분산보다 작은 공간 분산을 갖는 블록들 중 하나 이상을 선택 - 하나 이상의 프레임은 균일 블록으로서 선택됨 - 하는 단계, 및 비디오의 노이즈 신호를 추정하기 위해 선택된 균일 블록들을 이용하는 단계를 포함한다.Implementations disclose mutual noise estimation for video. One way is to determine that the optimal frame noise variance-optimal video noise variance for the intensity values of each frame of the video is based on a determined relationship between the spatial variance and the temporal variance of the intensity values of the uniform blocks in the frame Identifying an optimal video noise variance for a video based on an optimal frame noise variance of frames of video; selecting, for each frame of video, one or more of the blocks having a spatial variance less than the optimal video noise variance; - selecting one or more frames as a uniform block, and using selected uniform blocks to estimate the noise signal of the video.
Description
본 개시내용은 비디오 처리 분야에 관한 것으로, 특히 비디오에 대한 상호 노이즈 추정에 관한 것이다.This disclosure relates to the field of video processing, and more particularly to the mutual noise estimation for video.
비디오는 종종, 비디오 취득, 레코딩, 처리, 및 전송 동안에 생성되는 노이즈에 의해 손상된다. 노이즈란, 촬영중인 물체에 존재하지 않는 이미지의 밝기 또는 색상 정보에서의 무작위 변화를 지칭할 수 있다. 노이즈는, 비디오 압축, 분할, 포맷 변환, 움직임 추정, 노이즈 제거 및 필터링 등의 많은 비디오 처리 애플리케이션의 효과 및 성능에 영향을 미치면서 비디오의 시각적 품질을 저하시킨다. 이러한 비디오 처리 애플리케이션의 결과는, 노이즈 신호에 대한 정확한 정보가 이용가능할 때 개선될 수 있다. 비디오 노이즈 추정의 정확성은 신호 및 노이즈 처리 분야에서 중요한 요소이다.Video is often corrupted by noise generated during video acquisition, recording, processing, and transmission. Noise can refer to a random change in brightness or color information of an image that does not exist in the object being shot. Noise degrades the visual quality of video while affecting the effects and performance of many video processing applications such as video compression, segmentation, format conversion, motion estimation, noise removal and filtering. The result of this video processing application can be improved when accurate information about the noise signal is available. The accuracy of video noise estimation is an important factor in signal and noise processing.
이하에서는 본 개시내용의 일부 양태들의 기본적인 이해를 제공하기 위하여 본 개시내용의 간략화된 요약을 제공한다. 이 요약은 본 개시내용의 광범위한 개요는 아니다. 이것은, 본 개시내용의 주요한 또는 결정적인 요소들을 확인하기 위한 것도 아니며, 본 개시내용의 특정한 구현의 범위 또는 청구항들의 범위를 정하기 위한 것도 않는다. 그 유일한 목적은 이하에서 제공되는 더욱 상세한 설명에 대한 서두로서 본 개시내용의 몇 가지 개념을 간략화된 형태로 제공하는 것이다.The following presents a simplified summary of the disclosure in order to provide a basic understanding of some aspects of the disclosure. This summary is not an extensive overview of this disclosure. It is not intended to identify key or critical elements of the disclosure, nor is it intended to limit the scope of any particular implementation or range of claims. Its sole purpose is to present some concepts of the present disclosure in a simplified form as a prelude to the more detailed description that is presented below.
본 개시내용의 한 양태에서, 방법은, 처리 디바이스에 의해, 비디오의 프레임들의 각각의 프레임의 강도 값들에 대한 최적 프레임 노이즈 분산(optimal frame noise variance) - 최적 프레임 노이즈 분산은 프레임 내의 균일 블록들의 강도 값들의 공간 분산과 시간 분산 사이의 결정된 관계에 기초함 - 을 결정하는 단계; 비디오의 프레임들의 최적 프레임 노이즈 분산에 기초하여 비디오에 대한 최적 비디오 노이즈 분산을 식별하는 단계; 비디오의 각각의 프레임에 대해, 최적 비디오 노이즈 분산보다 작은 공간 분산을 갖는 블록들 중 하나 이상을 선택하는 단계 - 하나 이상의 선택된 블록들은 균일 블록들로서 라벨링됨 -; 및 처리 디바이스에 의해, 비디오의 노이즈 신호를 추정하기 위해 선택된 균일 블록들을 이용하는 단계를 포함한다.In one aspect of the present disclosure, a method includes determining, by a processing device, an optimal frame noise variance for intensity values of each frame of frames of video, Based on a determined relationship between the spatial variance of the values and the time variance; Identifying an optimal video noise variance for video based on optimal frame noise variance of frames of video; Selecting, for each frame of video, one or more of the blocks having a spatial variance less than the optimal video noise variance, wherein the one or more selected blocks are labeled as uniform blocks; And using the uniform blocks selected by the processing device to estimate the noise signal of the video.
한 구현에서, 블록들 각각은 프레임의 N × N 픽셀들을 포함하고, N은 양수(positive number)이다. 또한, 블록들 각각은 적어도 절반-중첩될 수 있다. 이 방법은, 비디오의 추정된 노이즈 신호를 이용하여 비디오를 처리하는 단계를 더 포함하고, 여기서, 비디오의 처리는, 비디오 압축, 분할, 포맷 변환, 움직임 추정, 노이즈 제거, 또는 필터링 중 하나 이상을 포함할 수 있다.In one implementation, each of the blocks includes N x N pixels of the frame, and N is a positive number. Also, each of the blocks may be at least half-overlapping. The method further comprises processing the video using the estimated noise signal of the video wherein the processing of the video includes at least one of video compression, segmentation, format conversion, motion estimation, noise removal, or filtering .
한 구현에서, 각각의 프레임에 대한 최적 프레임 노이즈 분산을 결정하는 단계는, 프레임 내의 각각의 블록의 공간 분산을 계산하는 단계; 프레임 내의 각각의 블록의 시간 분산을 계산하는 단계; 공간 분산과 시간 분산 사이의 결정된 관계에 기초하여 그리고 균일 블록들 사이의 노이즈 공분산이 일정한 값이라는 가정에 기초하여 프레임의 블록들의 시간 분산들 각각을 각각의 변환된 시간 분산으로 변환하는 단계; 프레임의 공간 분산들에 제1 함수 - 제1 함수는 분산 값들의 범위에 대한 분산 값 'x' 보다 작은 공간 분산을 갖는 프레임 내의 블록들에 관한 공간 분산들의 평균을 제공함 - 를 적용하는 단계; 프레임의 변환된 시간 분산들에 제2 함수 - 제1 함수는 분산 값들의 범위에 대한 분산 값 'x'보다 작은 변환된 시간 분산을 갖는 프레임 내의 블록들에 관한 변환된 시간 분산들의 평균을 제공함 - 를 적용하는 단계; 및 적용된 제1 함수와 적용된 제2 함수의 교점에 기초하여 프레임에 대한 최적 프레임 노이즈 분산 값을 선택하는 단계를 더 포함할 수 있다.In one implementation, determining an optimal frame noise variance for each frame comprises: calculating spatial variance of each block in the frame; Calculating a time variance of each block in the frame; Transforming each of the temporal variances of the blocks of the frame into respective transformed temporal variances based on a determined relationship between spatial variance and temporal variance and on the assumption that the noise covariance between the uniform blocks is a constant value; Applying a first function to a spatial variance of a frame, the first function providing an average of spatial variances for blocks in a frame having a spatial variance less than a variance value 'x' for a range of variance values; The second function on the transformed time distributions of the frame - the first function provides an average of the transformed time distributions on the blocks in the frame with the transformed time variance smaller than the variance value 'x' for the range of variance values - ; And selecting an optimal frame noise variance value for the frame based on an intersection of the applied first function and the applied second function.
일부 구현에서, 시간 분산은 프레임 이전 및 이후에 결정된 수의 프레임들을 이용한다. 또한, 분산 값들의 범위는 0으로부터 프레임에 대한 공간 분산 및 시간 분산의 집합의 합집합에 관한 최대 분산까지의 분산 값들을 포함할 수 있다. 한 구현에서, 교점은 V(x)의 절대 최대값보다 작고, 여기서, V(x)는 x의 분산 값에서 적용된 제1 함수와 적용된 제2 함수 사이의 차의 분산을 포함한다. 또한, 각각의 프레임의 강도 값은 프레임 내의 픽셀의 수치 값을 포함할 수 있고, 여기서, 수치 값은 픽셀의 그레이 레벨 값에 대응한다. 각각의 프레임의 강도 값은 또한, 프레임 내의 픽셀의 수치 값을 포함할 수 있고, 여기서, 수치 값은 픽셀의 컬러 채널 값에 대응한다. 또한, 최적 비디오 노이즈 분산은 비디오 세트의 프레임들의 최적 프레임 노이즈 분산들의 중앙값일 수 있다.In some implementations, the time variance uses a determined number of frames before and after the frame. The range of variance values may also include variance values from zero to the maximum variance for the union of the set of spatial variance and time variance for the frame. In one implementation, the intersection is less than the absolute maximum of V (x), where V (x) comprises the variance of the difference between the applied first function and the applied second function at the variance of x. In addition, the intensity value of each frame may include a numerical value of a pixel in a frame, wherein the numerical value corresponds to a gray level value of the pixel. The intensity value of each frame may also include a numerical value of a pixel in a frame, where the numerical value corresponds to the color channel value of the pixel. Also, the optimal video noise variance may be the median value of the optimal frame noise variances of the frames of the video set.
전술된 방법 및 여기서 설명되는 다양한 구현들의 동작들을 수행하기 위한 컴퓨팅 디바이스가 개시된다. 전술된 방법 및 여기서 설명된 다양한 구현들과 연관된 동작들을 수행하기 위한 명령어들을 저장하는 (예를 들어, 비일시적 컴퓨터 판독가능 저장 매체이지만, 통신 네트워크를 통해 전송되는 신호 등의 일시적 신호를 또한 포함하는) 컴퓨터 프로그램 제품도 역시 개시된다.A computing device for performing the above-described method and the operations of the various implementations described herein is disclosed. (E.g., non-volatile computer-readable storage medium, but also includes temporary signals such as signals transmitted over a communications network) that store instructions for performing the operations described herein and the operations associated with the various implementations described herein ) A computer program product is also disclosed.
본 개시내용의 제2 양태에서, (비일시적 머신 판독가능 저장 매체 등의) 컴퓨터 프로그램 제품은, 실행될 때 처리 디바이스로 하여금 동작들을 수행하게 하는 명령어들을 저장하며, 동작들은: 비디오의 프레임 내의 각각의 블록에 대한 강도 값들의 공간 분산을 계산하는 동작; 프레임 내의 각각의 블록의 강도 값들에 대한 시간 분산을 계산하는 동작; 공간 분산과 시간 분산 사이의 결정된 관계에 기초하여 그리고 비디오 내의 균일 블록들 사이의 노이즈 공분산이 일정한 값이라는 가정에 기초하여 프레임의 블록들의 시간 분산들 각각을 변환된 시간 분산으로 변환하는 동작; 프레임의 공간 분산들에 제1 함수 - 제1 함수는 분산 값들의 범위에 대한 분산 값 'x' 보다 작은 공간 분산 값을 갖는 프레임 내의 블록들에 관한 공간 분산들의 평균을 제공함 - 를 적용하는 동작; 프레임의 변환된 시간 분산들에 제2 함수 - 제2 함수는 분산 값들의 범위에 대한 분산 값 'x'보다 작은 변환된 시간 분산 값을 갖는 프레임 내의 블록들에 관한 변환된 시간 분산들의 평균을 제공함 - 를 적용하는 동작; 및 적용된 제1 함수와 적용된 제2 함수의 교점에 기초하여 프레임에 대한 최적 프레임 노이즈 분산 값을 선택하는 동작을 포함한다. 본 개시내용의 이 양태는, 프로세서 및 명령어들을 저장하는 메모리(저장 매체)를 포함하는 시스템으로서, 또는 명령어들을 실행할 때 프로세서에 의해 수행되는 방법으로서 대안적으로 정의될 수 있다.In a second aspect of the present disclosure, a computer program product (such as a non-transitory machine-readable storage medium) stores instructions for causing a processing device to perform operations when executed, the operations comprising: Calculating a spatial variance of intensity values for the block; Calculating a time variance for intensity values of each block in the frame; Transforming each of the temporal variances of blocks of the frame into a transformed temporal variance based on a determined relationship between spatial variance and temporal variance and on the assumption that the noise covariance between uniform blocks in the video is constant; Applying a first function to a spatial variance of the frame, the first function providing an average of spatial variance for blocks in the frame having a spatial variance value less than the variance value 'x' for the range of variance values; The second function on the transformed time distributions of the frame - the second function provides an average of the transformed time distributions on the blocks in the frame having a transformed time variance value smaller than the variance value 'x' for the range of variance values - applying an operation; And selecting an optimal frame noise variance value for the frame based on the intersection of the applied first function and the applied second function. This aspect of the present disclosure may be alternatively defined as a system comprising a processor (memory medium) for storing a processor and instructions, or as a method performed by a processor when executing instructions.
본 개시내용의 제3 양태에서, 시스템은: 메모리; 및 메모리에 결합된 처리 디바이스를 포함하고, 처리 디바이스는: 결정된 타입의 비디오 캡처 디바이스에 대응하는 비디오 세트의 각각의 비디오에 대한 최적 비디오 노이즈 분산 - 최적 비디오 노이즈 분산은 비디오 세트의 프레임들 각각 내의 균일 블록들의 공간 분산과 시간 분산 사이의 결정된 관계에 기초함 - 을 식별하고, 식별된 최적 비디오 노이즈 분산에 기초하여 결정된 타입의 비디오 캡처 디바이스에 대응하는 노이즈 모델을 생성하며; 결정된 타입의 비디오 캡처 디바이스에 대한 노이즈 모델을 저장하고; 결정된 타입의 비디오 캡처 디바이스에 의해 캡처된 것으로 표시된 업로드된 비디오를 노이즈 제거하기 위해 저장된 노이즈 모델을 적용한다. 본 개시내용의 이 양태는, 처리 디바이스(프로세서)에 의해 실행되는 단계들을 포함하는 방법으로서, 또는 프로세서에 의해 구현될 때 프로세서로 하여금 방법을 실행하게 하는 명령어들을 저장하는 (비일시적인 컴퓨터-판독가능 저장 매체, 또는 통신 신호 등의) 컴퓨터 프로그램 제품으로서 대안적으로 정의될 수 있다.In a third aspect of the present disclosure, a system comprises: a memory; And a processing device coupled to the memory, the processing device comprising: means for determining a best video noise variance-best video noise variance for each video of the video set corresponding to the determined type of video capture device, Based on a determined relationship between spatial variance of blocks and temporal variance, and generating a noise model corresponding to a video capture device of a determined type based on the identified optimal video noise variance; Storing a noise model for a video capture device of a determined type; And applies the stored noise model to remove the noise of the uploaded video marked as captured by the determined type of video capture device. This aspect of the present disclosure may be implemented as a method including steps executed by a processing device (processor), or as a method of storing instructions that, when implemented by a processor, cause the processor to perform the method Storage media, or communication signals). ≪ / RTI >
(예를 들어, "최적 비디오 노이즈 분산"에서와 같은) 용어 "최적"은 식별된 임의의 값, 특히 물리량을 나타내는 값을 지정하기 위해 본 문서에서 사용된다. 이것은 소정 목적을 위해 이용하는 최상의 값이라고 여겨질 수 있다.The term " optimal " (as in " optimal video noise variance ", for example) is used in this document to designate any value identified, particularly a value representing a physical quantity. This can be considered the best value to use for some purposes.
본 개시내용이, 첨부된 도면들에서, 제한이 아니라 예로서 설명된다.
도 1은 본 개시내용의 구현예들이 구현될 수 있는 예시적인 네트워크 아키텍처를 나타내는 블록도이다.
도 2는 본 개시내용의 한 구현에 따른 노이즈 추정 컴포넌트의 블록도이다.
도 3은 한 구현에 따른 비디오에 대한 상호 노이즈 추정을 위한 방법을 나타내는 흐름도이다.
도 4는 한 구현에 따른 비디오에 대한 상호 노이즈 추정을 위한 또 다른 방법을 나타내는 흐름도이다.
도 5는 한 구현에 따른 비디오에 대한 상호 노이즈 추정을 이용하여 비디오 캡처 디바이스를 위한 노이즈 모델을 생성하기 위한 방법을 나타내는 흐름도이다.
도 6은 한 구현에 따른 컴퓨터 시스템의 한 구현예를 나타내는 블록도이다.The present disclosure is illustrated by way of example, and not by way of limitation, in the accompanying drawings.
1 is a block diagram illustrating an exemplary network architecture in which implementations of the present disclosure may be implemented.
2 is a block diagram of a noise estimation component in accordance with one implementation of the present disclosure.
3 is a flow chart illustrating a method for reciprocal noise estimation for video in accordance with one implementation.
4 is a flow chart illustrating yet another method for mutual noise estimation for video in accordance with one implementation.
5 is a flow diagram illustrating a method for generating a noise model for a video capture device using a reciprocal noise estimate for video in accordance with one implementation.
6 is a block diagram illustrating one implementation of a computer system in accordance with one implementation.
본 개시내용의 양태 및 구현들이 비디오에 대한 상호 노이즈 추정에 대해 설명된다. 비디오는 종종, 비디오 취득, 레코딩, 처리, 및 전송 동안에 생성되는 노이즈에 의해 손상된다. 노이즈란, 레코딩중인 물체에 존재하지 않는 이미지의 밝기 또는 색상 정보에서의 무작위 변화를 지칭할 수 있다. 특정 비디오에 존재하는 노이즈의 정확한 추정은, 비디오 압축, 분할, 포맷 변환, 움직임 추정, 노이즈 제거 및 필터링 등의 많은 비디오 처리 애플리케이션에 대해 유용하다. 비디오에 존재하는 추정된 노이즈 레벨은 대응하는 비디오 처리 애플리케이션의 파라미터들을 튜닝하는데 이용될 수 있다. 이러한 비디오 처리 애플리케이션의 결과는 추정된 노이즈 레벨에 대한 정확한 정보가 이용가능할 때 개선될 수 있다.Aspects and implementations of the present disclosure are described with respect to mutual noise estimation for video. Video is often corrupted by noise generated during video acquisition, recording, processing, and transmission. Noise may refer to a random change in brightness or color information of an image that is not present in the object being recorded. Accurate estimation of the noise present in a particular video is useful for many video processing applications such as video compression, segmentation, format conversion, motion estimation, noise removal and filtering. The estimated noise level present in the video may be used to tune the parameters of the corresponding video processing application. The result of this video processing application can be improved when accurate information about the estimated noise level is available.
일반적으로, 비디오 노이즈 추정 시스템은 비디오의 비디오 프레임들에서 가장 강도-균일한 블록을 식별한다. 식별된 강도-균일 블록들 내의 임의의 강도 변화는 노이즈인 것으로 가정된다. 비디오 프레임의 블록이란, 프레임의 픽셀들의 서브세트를 포함하는 비디오 프레임의 일부를 지칭할 수 있다. 강도란, 비디오 프레임 내의 픽셀의 수치 값을 지칭할 수 있다. 예를 들어, 그레이 스케일 이미지에서, 강도는 각각의 픽셀에서의 그레이 레벨 값이다 (예를 들어, 127은 220보다 어두움). 또 다른 예에서, 컬러 이미지에서, 강도는 컬러 이미지 내의 각각의 컬러 채널 (예를 들어, 적색, 녹색, 청색 (RGB) 컬러 채널)의 수치 값에 기초하여 결정될 수 있다. 본 명세서에서 사용될 때, "균일(homogeneous)"이라는 용어는, 일률적인 외관(예를 들어, 텍스쳐가 없이, 블록 전체에 걸쳐 일관적으로 단일의 컬러)을 갖는 것을 지칭할 수 있다. 유사하게, 강도-균일 블록(또는 단지 "균일 블록")이란, 블록의 픽셀들 사이에서 강도 값의 변화가 거의 또는 전혀 없는 비디오 프레임의 블록, 또는 특히, 균일성을 갖는 블록을 나타내는 균일성 기준을 충족하는 블록을 지칭할 수 있다. 이 기준은, 임계값 아래의 균일성을 나타내는 균일성 파라미터를 갖는 블록의 관점에서 표현될 수 있다.In general, a video noise estimation system identifies the most intensity-uniform blocks in video frames of video. Any intensity variation within the identified intensity-uniform blocks is assumed to be noise. A block of a video frame may refer to a portion of a video frame that includes a subset of the pixels of the frame. Strength can refer to a numerical value of a pixel in a video frame. For example, in a grayscale image, the intensity is the gray level value at each pixel (e.g., 127 is darker than 220). In another example, in a color image, the intensity may be determined based on the numerical value of each color channel (e.g., red, green, blue (RGB) color channel) in the color image. As used herein, the term " homogeneous " may refer to having a uniform appearance (e.g., a single color consistently throughout the block, without a texture). Similarly, an intensity-uniform block (or simply " uniform block ") refers to a block of video frames with little or no change in intensity value between pixels of the block, Can be referred to as " block " This criterion can be expressed in terms of blocks with uniformity parameters that indicate uniformity below the threshold.
일부 종래의 비디오 노이즈 추정 시스템은 노이즈 레벨을 추정하기 위해 순전히 비디오의 시간 정보에 의존하는 반면, 다른 종래의 비디오 노이즈 추정 시스템은 순전히 공간 정보에 의존한다. 역시 다른 종래의 비디오 노이즈 추정 시스템은 비디오의 공간-시간 영역에 의존한다. 그러나, 일반적으로 모든 종래의 비디오 노이즈 추정 시스템은 부정확한 미리정의된 임계값 및/또는 비디오의 균일 블록에 대한 부정확한 가정 중 어느 하나 또는 양쪽 모두에 의존한다. 부정확한 미리정의된 임계값의 예는, 블록들의 상위 X %를 균일 블록으로 선택하는 것을 포함할 수 있다. 부정확한 가정의 예는, 균일 블록들을 식별하기 위해 상위 X개의 가장 균일한 블록들의 중앙값 분산(median variance)을 기준 분산으로 설정하는 것일 수 있다.Some conventional video noise estimation systems rely purely on the temporal information of the video to estimate the noise level, while other conventional video noise estimation systems depend purely on spatial information. Still other conventional video noise estimation systems rely on the space-time domain of the video. In general, however, all conventional video noise estimation systems rely on either or both of an incorrect predefined threshold and / or an incorrect assumption for a uniform block of video. An example of an incorrect predefined threshold may include selecting the top X% of blocks as a uniform block. An example of an incorrect assumption may be to set the median variance of the top X most uniform blocks to the reference variance to identify the uniform blocks.
그 결과, 이러한 종래의 시스템의 정확도는 이들 미리정의된 임계값 및/또는 가정에 기초한 균일 블록들의 선택에 예속된다. 이것은 비디오 내의 노이즈의 과대평가 또는 과소평가로 이어질 수 있다. 또한, 종래의 비디오 노이즈 추정 시스템은 또한, 상이한 강도들을 갖는 비디오 프레임 내의 영역들에 대해 동일한 전력을 갖는 것으로 노이즈 신호를 제한한다. 노이즈는 상이한 강도들 및 컬러들에 대해 상이할 수 있으므로, 종래의 비디오 노이즈 추정 시스템은 일반적으로 포괄적인 세트의 노이즈-대표 블록들을 선택하는데 실패하고 부정확한 노이즈 추정으로 이어진다.As a result, the accuracy of these conventional systems is subject to the selection of uniform blocks based on these predefined thresholds and / or assumptions. This can lead to overestimation or underestimation of noise in the video. In addition, conventional video noise estimation systems also limit the noise signal to have the same power for regions in a video frame with different intensities. Since noise may be different for different intensities and colors, conventional video noise estimation systems generally fail to select a comprehensive set of noise-representative blocks and lead to inaccurate noise estimates.
종래의 비디오 노이즈 추정 시스템과는 달리, 본 개시내용의 구현은, 고정된 임계값 및 미리정의된 노이즈 모델 가정을 이용하는 것이 아니라, 비디오의 프레임들의 2개의 노이즈 분산(공간적 및 시간적)을 동적으로 결정함으로써 균일 블록을 식별한다. 본 개시내용의 구현들의 비디오 노이즈 추정 컴포넌트는, 비디오의 각각의 프레임에서 균일한 공간-시간 블록(균일 블록)을 식별함으로써 비디오 내의 노이즈를 추정한다.Unlike a conventional video noise estimation system, the implementation of the present disclosure does not use a fixed threshold and predefined noise model assumptions, but rather dynamically determines two noise variances (spatial and temporal) of frames of video Thereby identifying a uniform block. The video noise estimation component of the implementations of the present disclosure estimates the noise in the video by identifying a uniform space-time block (uniform block) in each frame of video.
비디오 노이즈 추정 컴포넌트는 초기에 비디오의 프레임들 내의 블록들의 강도의 공간 분산 및 시간 분산을 결정한다. 그 다음, 노이즈 추정 컴포넌트는 프레임에 대한 최적 프레임 노이즈 분산을 결정한다. 최적 프레임 노이즈 분산은, 블록들이 강도에 있어서 균일할 때 존재하는 공간 분산 및 시간 분산 사이의 결정된 관계에 기초한다. 그러면, 이 최적 프레임 노이즈 분산은 비디오에서 균일 블록들을 식별하는데 이용될 수 있고, 여기서 식별된 균일 블록들은 서로 비교될 때 강도 및/또는 색상에서 달라질 수 있다. 이러한 균일 블록들은 비디오의 노이즈 신호를 추정하는데 이용될 수 있다.The video noise estimation component initially determines the spatial variance and time variance of the intensity of the blocks within the frames of the video. The noise estimation component then determines the optimal frame noise variance for the frame. The optimal frame noise variance is based on a determined relationship between spatial dispersion and temporal variance that exist when the blocks are uniform in intensity. This optimal frame noise variance may then be used to identify the uniform blocks in the video, where the identified uniform blocks may vary in intensity and / or color when compared to each other. These uniform blocks can be used to estimate the noise signal of the video.
본 개시내용의 구현들은 블록이 강도에 있어서 균일할 때 존재하는 공간 분산 및 시간 분산 사이의 결정된 관계에 기초하는 최적 프레임 노이즈 분산을 선택함으로써 종래의 비디오 노이즈 추정 시스템에 비해 기술적 이점을 제공한다. 본 개시내용의 구현들은 또한, 노이즈 추정 프로세스의 효율을 향상시킴으로써 비디오 노이즈 추정에 대한 기술적 개선을 제공하여 비디오 내의 노이즈 신호를 더욱 정확하게 식별하고 추출한다. 본 개시내용의 구현들에 의해 제공되는 노이즈 신호의 정확한 식별 및 추출은, 비디오 처리 애플리케이션에 대한 더욱 정확한 노이즈 추정을 야기하고, 비디오의 더 나은 시각적 품질로 이어진다.The implementations of the present disclosure provide a technical advantage over conventional video noise estimation systems by selecting an optimal frame noise variance based on a determined relationship between spatial dispersion and temporal variance that exist when the block is uniform in intensity. Implementations of the present disclosure also provide a technical improvement to video noise estimation by improving the efficiency of the noise estimation process to more accurately identify and extract noise signals in video. Accurate identification and extraction of noise signals provided by implementations of the present disclosure leads to more accurate noise estimation for video processing applications and leads to better visual quality of the video.
간소화 및 간략화를 위해 본 개시내용은 종종 비디오를 참조한다. 그러나, 본 개시내용의 교시는 일반적으로 미디어 아이템들에 적용되며, 예를 들어, 비디오, 오디오, 텍스트, 이미지, 프로그램 명령어 등을 포함한 다양한 타입의 콘텐츠 또는 미디어 아이템에 적용될 수 있다.For simplicity and simplicity, the present disclosure often refers to video. However, the teachings of the present disclosure generally apply to media items and may be applied to various types of content or media items, including, for example, video, audio, text, images, program instructions,
도 1은 본 개시내용의 한 구현에 따른 예시적인 시스템 아키텍처(100)를 나타낸다. 시스템 아키텍처(100)는, 클라이언트 디바이스들(110A 내지 110Z), 네트워크(105), 데이터 저장소(106), 콘텐츠 공유 플랫폼(120) 및 서버(130)를 포함한다. 한 구현에서, 네트워크(105)는, 공중 네트워크(예를 들어, 인터넷), 사설 네트워크(예를 들어, 근거리 통신망(LAN), 또는 광역 네트워크(WAN)), 유선 네트워크(예를 들어, Ethernet 네트워크), 무선 네트워크(예를 들어, 802.11 네트워크 또는 WiFi 네트워크), 셀룰러 네트워크(예를 들어, 롱텀 에볼루션(LTE) 네트워크), 라우터, 허브, 스위치, 서버 컴퓨터, 및/또는 이들의 조합을 포함할 수 있다. 한 구현에서, 데이터 저장소(106)는, 메모리(예를 들어, 랜덤 액세스 메모리), 캐쉬, 드라이브(예를 들어, 하드 드라이브), 플래시 드라이브, 데이터베이스 시스템, 또는 데이터를 저장할 수 있는 다른 타입의 컴포넌트 또는 디바이스일 수 있다. 데이터 저장소(106)는 또한, 복수의 컴퓨팅 디바이스(예를 들어, 복수의 서버 컴퓨터)에 걸쳐 있는 복수의 저장 컴포넌트(예를 들어, 복수의 드라이브 또는 복수의 데이터베이스)를 포함할 수 있다.Figure 1 illustrates an
클라이언트 디바이스(110A 내지 110Z)는 각각 개인용 컴퓨터(PC), 랩탑, 모바일 전화, 스마트폰, 태블릿 컴퓨터, 넷북 컴퓨터, 네트워크-접속된 텔레비전 등의 컴퓨팅 디바이스를 포함할 수 있다. 일부 구현에서, 클라이언트 디바이스(110A 내지 110Z)는 또한, "사용자 디바이스"라고 부를 수도 있다. 각각의 클라이언트 디바이스는 미디어 뷰어(111)를 포함한다. 한 구현에서, 미디어 뷰어(111)는, 사용자가, 이미지, 비디오, 웹페이지, 문서 등의 콘텐츠를 보는 것을 허용하는 애플리케이션일 수 있다. 예를 들어, 미디어 뷰어(111)는, 웹 서버에 의해 서빙되는 콘텐츠(예를 들어, HTML 페이지 등의 웹 페이지, 디지털 미디어 아이템 등)를 액세스, 회수, 프리젠팅, 및/또는 네비게이트할 수 있는 웹 브라우저일 수 있다. 미디어 뷰어(111)는, 콘텐츠(예를 들어, 웹페이지, 미디어 뷰어)를 사용자에게 렌더링, 디스플레이, 및/또는 프리젠팅할 수 있다. 미디어 뷰어(111)는 또한, 웹페이지(예를 들어, 온라인 판매자에 의해 판매되는 제품에 대한 정보를 제공할 수 있는 웹페이지)에 임베딩되는 임베딩형 미디어 플레이어(예를 들어, Flash® 플레이어 또는 HTML5 플레이어)를 디스플레이할 수 있다. 또 다른 예에서, 미디어 뷰어(111)는 사용자가 디지털 미디어 아이템(예를 들어, 디지털 비디오, 디지털 이미지, 전자 서적 등)을 보는 것을 허용하는 단독형 애플리케이션(예를 들어, 모바일 애플리케이션 또는 앱)일 수 있다. 본 개시내용의 양태들에 따르면, 미디어 뷰어(111)는 모바일 디바이스로부터의 라이브 비디오 스트리밍에 대한 품질 및 사용자 경험을 향상시키기 위해 집결된 네트워크 통계를 활용하는 콘텐츠 공유 플랫폼 애플리케이션일 수 있다.The client devices 110A-110Z may each comprise a computing device such as a personal computer (PC), a laptop, a mobile phone, a smart phone, a tablet computer, a netbook computer, a network-connected television, In some implementations, client devices 110A-110Z may also be referred to as " user devices ". Each client device includes a media viewer 111. In one implementation, media viewer 111 may be an application that allows a user to view content such as images, video, web pages, documents, and the like. For example, the media viewer 111 can access, retrieve, present, and / or navigate content (e.g., web pages such as HTML pages, digital media items, etc.) served by a web server Lt; / RTI > The media viewer 111 may render, display, and / or present content (e.g., a web page, a media viewer) to a user. The media viewer 111 may also include an embedded media player (e.g., a Flash® player or HTML5) embedded in a web page (eg, a web page that can provide information about a product sold by an online merchant) Player) can be displayed. In another example, the media viewer 111 is a standalone application (e.g., a mobile application or an app) that allows a user to view digital media items (e.g., digital video, digital images, electronic books, . According to aspects of the present disclosure, the media viewer 111 may be a content sharing platform application that utilizes aggregated network statistics to improve the quality and user experience for live video streaming from mobile devices.
미디어 뷰어(111)는, 서버(130) 및/또는 콘텐츠 공유 플랫폼(120)에 의해 클라이언트 디바이스들(110A 내지 110Z)에 제공될 수 있다. 예를 들어, 미디어 뷰어(111)는, 콘텐츠 공유 플랫폼(120)에 의해 제공되는 웹페이지에 임베딩되는 임베딩형 미디어 플레이어일 수 있다. 또 다른 예에서, 미디어 뷰어(111)는 서버(130)로부터 다운로드되는 애플리케이션일 수 있다.The media viewer 111 may be provided to the client devices 110A through 110Z by the server 130 and / or the
한 구현에서 콘텐츠 공유 플랫폼(120)에 의해 수행되는 것으로 설명되는 기능은 또한, 적절하다면 다른 구현에서 클라이언트 디바이스(110A 내지 110Z) 상에서 수행될 수 있다는 점에 유의해야 한다. 또한, 특정한 컴포넌트로 인한 기능은 함께 동작하는 상이한 또는 복수의 컴포넌트들에 의해 수행될 수 있다. 콘텐츠 공유 플랫폼(120)은 또한, 적절한 애플리케이션 프로그래밍 인터페이스를 통해 다른 시스템이나 디바이스에 제공되는 서비스로서 액세스될 수 있으므로, 웹사이트에서의 이용으로 제한되지 않는다.It should be noted that the functions described as being performed by the
한 구현에서, 콘텐츠 공유 플랫폼(120)은, 사용자에게 미디어 아이템으로의 액세스를 제공하거나 및/또는 사용자에게 미디어 아이템을 제공하는데 이용될 수 있는, 하나 이상의 컴퓨팅 디바이스(예를 들어, 랙마운트 서버, 라우터 컴퓨터, 서버 컴퓨터, 개인용 컴퓨터, 메인프레임 컴퓨터, 랩탑 컴퓨터, 태블릿 컴퓨터, 데스크탑 컴퓨터 등), 데이터 저장소(예를 들어, 하드 디스크, 메모리, 데이터베이스), 네트워크, 소프트웨어 컴포넌트, 및/또는 하드웨어 컴포넌트일 수 있다. 예를 들어, 콘텐츠 공유 플랫폼(120)은, 사용자가, 미디어 아이템을 소비, 업로드, 검색, 찬성("좋아요"), 싫어요, 및/또는 코멘트하는 것을 허용할 수 있다. 콘텐츠 공유 플랫폼(120)은 또한, 사용자에게 미디어 아이템에 대한 액세스를 제공하는데 이용될 수 있는 웹사이트(예를 들어, 웹페이지) 또는 애플리케이션 백엔드 소프트웨어를 포함할 수 있다.In one implementation,
본 개시내용의 구현들에서, "사용자"는 단일 개인으로서 표현될 수 있다. 그러나, 본 개시내용의 다른 구현들은 사용자들의 집합 및/또는 자동화된 소스에 의해 제어되는 엔티티로서의 "사용자"를 포함한다. 예를 들어, 소셜 네트워크에서 커뮤니티로 연합된 개별 사용자들의 집합은 "사용자"로서 간주될 수 있다. 또 다른 예에서, 자동화된 소비자는, 콘텐츠 공유 플랫폼(120)의 토픽 채널 등의 자동화된 섭취 파이프라인(ingestion pipeline)일 수 있다.In implementations of the present disclosure, " user " may be represented as a single individual. However, other implementations of the present disclosure include a " user " as an entity that is controlled by a collection of users and / or automated sources. For example, a collection of individual users associated with a community in a social network may be considered a " user ". In another example, the automated consumer may be an automated ingestion pipeline, such as a topic channel of the
콘텐츠 공유 플랫폼(120)은 미디어 아이템(121) 등의 데이터 콘텐츠를 호스팅할 수 있다. 데이터 콘텐츠는, 사용자에 의해 선택된 디지털 콘텐츠, 사용자에 의해 이용가능하게 된 디지털 콘텐츠, 사용자에 의해 업로드된 디지털 콘텐츠, 콘텐츠 제공자에 의해 선택된 디지털 콘텐츠, 방송자에 의해 선택된 디지털 콘텐츠 등일 수 있다. 미디어 아이템(121)의 예로서는, 디지털 비디오, 디지털 영화, 디지털 사진, 디지털 음악, 웹사이트 콘텐츠, 소셜 미디어 업데이트, 전자 서적(ebook), 전자 잡지, 디지털 신문, 디지털 오디오 북, 전자 저널, 웹 블로그, RSS(real simple syndication) 피드, 전자 코믹 북, 소프트웨어 애플리케이션 등이 포함될 수 있지만, 이것으로 제한되지 않는다. 일부 구현에서, 미디어 아이템(121)은 콘텐츠 아이템이라고도 지칭된다.The
미디어 아이템(121)은 인터넷을 통해 및/또는 모바일 디바이스 애플리케이션을 통해 소비될 수 있다. 간결화와 단순화를 위해, 본 개시내용 전체에 걸쳐 미디어 아이템(121)의 예로서 (이하에서는 비디오라고도 하는) 온라인 비디오가 이용된다. 여기서 사용될 때, "미디어", "미디어 아이템", "온라인 미디어 아이템", "디지털 미디어", "디지털 미디어 아이템", "콘텐츠", 및 "콘텐츠 아이템"은, 디지털 미디어 아이템을 엔티티에 프리젠팅하도록 구성된, 소프트웨어, 펌웨어, 또는 하드웨어를 이용하여 실행되거나 로딩될 수 있는 전자적 파일을 포함할 수 있다. 한 구현에서, 콘텐츠 공유 플랫폼(120)은 데이터 저장소(106)를 이용하여 미디어 아이템(121)을 저장할 수 있다.The media item 121 may be consumed via the Internet and / or through a mobile device application. For brevity and simplicity, online video (also referred to herein as video) is used as an example of media item 121 throughout this disclosure. As used herein, "media", "media items", "online media items", "digital media", "digital media items", "content", and "content items" Or may comprise an electronic file that may be constructed or executed using software, firmware, or hardware. In one implementation, the
한 구현에서, 서버(130)는 하나 이상의 컴퓨팅 디바이스(예를 들어, 랙 마운트 서버, 서버 컴퓨터 등)일 수 있다. 한 구현에서, 서버(130)는 콘텐츠 공유 플랫폼(120)에 포함될 수 있다. 한 예로서, 클라이언트 디바이스들(110A-110Z)의 사용자들은 각각, 데이터 저장소(106)에 저장된 하나 이상의 비디오를 다운로드 및/또는 스트리밍하기 위해 네트워크(105)를 통해 서버(130)에 요청을 전송할 수 있다. 또한, 클라이언트 디바이스들(110A-110A)의 사용자들은 네트워크(105)를 통해 서버(130)에 요청을 전송하여 클라이언트 디바이스(110A-110Z)에 저장된 및/또는 캡처된 하나 이상의 비디오를 서버(130)에 업로드할 수 있다.In one implementation, the server 130 may be one or more computing devices (e.g., a rackmount server, a server computer, etc.). In one implementation, the server 130 may be included in the
본 개시내용의 구현들에서, 서버(130)는 노이즈 추정 컴포넌트(140)를 포함할 수 있다. 노이즈 추정 컴포넌트(140)는 비디오로부터 노이즈 신호를 추출하고 비디오의 노이즈 레벨을 추정한다. 비디오 내의 노이즈를 추출하고 추정하기 위해, 노이즈 추정 컴포넌트(140)는 비디오의 각각의 프레임에서 균일한 공간-시간 블록(본질적으로 균일 블록이라고도 함)을 식별할 수 있다. 전술된 바와 같이, 균일이라는 용어는 일률적인 외관(즉, 텍스쳐없이 전체적으로 일관적으로 단일의 색상)을 갖는 것을 지칭할 수 있다. 균일 블록은, 비디오의 프레임들에 대한 공간 및 시간 분산에 대한 2개의 노이즈 방정식을 풀어서 구해진다. 노이즈 추정 컴포넌트(140)는 비디오 내의 균일한 블록들에 대해 존재하는 공간적 및 시간적 노이즈 분산들 사이의 세트 관계를 제공하는 구성된 파라미터들에 기초하여 비디오에 대한 노이즈 추정을 제공한다. 또한, 노이즈 추정 컴포넌트(140)는 다양한 강도 및 컬러를 갖는 비디오의 프레임들 내의 블록들을 고려한다.In implementations of the present disclosure, the server 130 may include a
일부 구현 예에서, 서버(130)의 노이즈 추정 컴포넌트(140)는 콘텐츠 공유 플랫폼(120)과 상호작용하여 모바일 디바이스로부터의 라이브 비디오 스트리밍에 대한 품질 및 사용자 경험을 향상시키기 위해 집결된 네트워크 통계를 활용할 수 있다. 별개의 컴포넌트들로서 도시되고 설명되었지만, 노이즈 추정 컴포넌트(140)는 서버(130) 및/또는 콘텐츠 공유 플랫폼(120)에서 단일 컴포넌트로서 구현될 수도 있다. 노이즈 추정 컴포넌트(140)와 그 특정한 기능의 추가 설명이 도 2를 참조하여 이하에서 더 상세히 설명된다.In some implementations, the
본 개시내용의 구현들이 콘텐츠 공유 플랫폼 및 콘텐츠 공유 플랫폼에 업로드된 비디오에 대한 상호 노이즈 추정과 관련하여 설명되지만, 이 구현들은 사용자들 사이의 연결을 제공하는 임의의 타입의 소셜 네트워크에도 역시 일반적으로 적용될 수 있다. 본 개시내용의 구현은 사용자에게 채널 가입을 제공하는 콘텐츠 공유 플랫폼으로 제한되지 않는다.Although implementations of the present disclosure are described in terms of a content sharing platform and a mutual noise estimate for video uploaded to a content sharing platform, these implementations are also generally applicable to any type of social network that provides a connection between users . Implementations of the present disclosure are not limited to a content sharing platform that provides channel subscription to a user.
여기서 논의되는 시스템이 사용자들에 대한 개인 정보를 수집(예를 들어, 미디어 뷰어(111)로부터의 네트워크 통계의 수집, 네트워크 접속 데이터의 수집 등)하거나 개인 정보를 이용할 수 있는 상황에서, 사용자들에게는, 콘텐츠 공유 플랫폼(120)이 사용자 정보(예를 들어, 사용자의 소셜 네트워크, 소셜 행위 또는 활동, 사용자의 직업, 사용자의 선호사항, 또는 사용자의 현재 위치에 대한 정보)를 수집할지를 제어하거나 사용자와 더욱 관련성이 있을 수 있는 콘텐츠를 콘텐츠 공유 플랫폼(120)으로부터 수신할지의 여부 및/또는 수신하는 방법을 제어할 기회가 제공될 수 있다. 또한, 소정의 데이터는 저장되거나 이용되기 전에 하나 이상의 방식으로 취급될 수 있어서, 개인 식별 정보가 제거될 수 있다. 예를 들어, 사용자의 신원은 그 사용자에 대해 어떠한 개인 식별 정보도 판정될 수 없도록 취급되거나, (도시, ZIP 코드, 또는 주 레벨 등에 관한) 위치 정보가 얻어지는 경우 사용자의 특정한 위치가 판정될 수 없도록 사용자의 지리적 위치가 일반화될 수 있다. 따라서, 사용자는, 사용자에 대해 정보가 어떻게 수집되고 콘텐츠 공유 플랫폼(120)에 의해 어떻게 이용될지에 관해 제어할 수 있다.In situations where the system discussed herein is capable of collecting personal information about users (e.g., collecting network statistics from media viewer 111, collecting network connection data, etc.) or using personal information, , The
도 2는 본 개시내용의 한 구현에 따른 노이즈 추정 컴포넌트(140)를 나타내는 블록도이다. 전술된 바와 같이, 노이즈 추정 컴포넌트(140)는 단일 소셜 네트워크와 상호작용할 수 있거나, (예를 들어, 다른 제3자 소셜 네트워크에 의해 이용되는 콘텐츠 공유 플랫폼의 서비스로서 제공되는) 복수의 소셜 네트워크들 사이에서 이용될 수 있다.2 is a block diagram illustrating a
한 구현에서, 노이즈 추정 컴포넌트(140)는, 프레임 분할기(210), 공간 분산 결정기(220), 시간 분산 결정기(230), 노이즈 공분산 컴포넌트(240), 시간 분산 변환기(250), 평균 분산 결정기(260), 최적 노이즈 분산 결정기(270), 균일 블록 식별자(280) 및 디바이스 타입 노이즈 모델 컴포넌트(290)를 포함한다. 일반성의 손실없이 노이즈 추정 컴포넌트(140)에는 더 많거나 더 적은 수의 컴포넌트들이 포함될 수 있다. 예를 들어, 모듈들 중 2개는 단일의 모듈로 결합되거나, 모듈들 중 하나는 2개 이상의 모듈로 분할될 수도 있다. 한 구현에서, 모듈들 중 하나 이상은 상이한 컴퓨팅 디바이스들 상에 상주할 수 있다(예를 들어, 상이한 서버 컴퓨터들, 단일 클라이언트 디바이스 상에, 또는 복수의 클라이언트 디바이스들 사이에 분산되는 등). 또한, 모듈들 중 하나 이상은, 상이한 콘텐츠 공유 플랫폼들, 제3자 소셜 네트워크들, 및/또는 외부 서버들 상에 상주할 수 있다.In one implementation, the
노이즈 추정 컴포넌트(140)는 데이터 저장소(106)에 통신가능하게 결합된다. 예를 들어, 노이즈 추정 컴포넌트(140)는 네트워크를 통해 (예를 들어, 도 1에 나타낸 바와 같이 네트워크(105)를 통해) 데이터 저장소(106)에 결합될 수 있다. 데이터 저장소(106)는, 메모리(예를 들어, 랜덤 액세스 메모리), 캐쉬, 드라이브(예를 들어, 하드 드라이브), 플래시 드라이브, 데이터베이스 시스템, 또는 데이터를 저장할 수 있는 다른 타입의 컴포넌트 또는 디바이스일 수 있다. 데이터 저장소(106)는 또한, 복수의 컴퓨팅 디바이스(예를 들어, 복수의 서버 컴퓨터)에 걸쳐 있는 복수의 저장 컴포넌트(예를 들어, 복수의 드라이브 또는 복수의 데이터베이스)를 포함할 수 있다. 데이터 저장소(106)는, 미디어 아이템 데이터(290), 노이즈 추정 데이터(291) 및 디바이스 타입 노이즈 모델 데이터(292)를 포함한다.The
전술된 바와 같이, 노이즈 추정 컴포넌트(140)는 비디오로부터 노이즈 신호를 추출하고 비디오의 노이즈 레벨을 추정할 수 있다. 비디오 내의 노이즈를 추출하고 추정하기 위해, 노이즈 추정 컴포넌트(140)는 비디오의 각각의 프레임에서 균일한 공간-시간 블록(균일 블록)을 식별할 수 있다.As described above, the
공간-시간적 균일 블록들을 식별하기 위해, 노이즈 추정 컴포넌트(140)는 먼저 프레임 분할기(210)를 기동하여 비디오의 비디오 프레임을 블록들로 분할한다. (여기서는 I(x, y, t)로도 지칭되는) It(x, y)는 비디오에서 프레임 't'의 강도 이미지라고 가정한다. 강도 이미지(강도)는 이미지 내의 위치 (x, y)에 있는 픽셀에 대응하는 수치 값을 지칭할 수 있다. 예를 들어, 그레이 스케일 이미지에서, 강도는 각각의 픽셀에서의 그레이 레벨 값이다(예를 들어, 127은 220보다 어두움). 또 다른 예에서, 컬러 이미지에서, 강도는 컬러 이미지 내의 각각의 컬러 채널(예를 들어, 적색, 녹색, 청색 (RGB) 컬러 채널)의 수치 값에 기초하여 결정될 수 있다. 비디오는 데이터 저장소(106) 내에 미디어 아이템 데이터(290)로서 저장될 수 있다. 노이즈 추정 컴포넌트(140)는 노이즈 추정 프로세스를 수행하여 프레임 t에서 노이즈 신호를 포함하는 일률적인/균일한 블록을 식별한다.To identify the spatially-temporally uniform blocks, the
블록들은 N × N 픽셀의 크기를 갖는 절반-중첩된 블록들일 수 있고(예를 들어, 프레임의 제1 블록 내의 픽셀들의 절반은 또한, 프레임의 제2 블록의 멤버일 수 있는 등등), 여기서 N은 양수이다. 예를 들어, 1920 x 1080 비디오의 경우 N은 32일 수 있다. 프레임 't'에서의 절반-중첩된 블록 'B'의 예시적인 표현은 다음과 같을 수 있다:The blocks may be half-nested blocks having a size of N by N pixels (e.g., one half of the pixels in the first block of the frame may also be members of the second block of the frame, etc.), where N Is a positive number. For example, N may be 32 for 1920 x 1080 video. An exemplary representation of the half-nested block 'B' in frame 't' may be:
여기서 xi, yi는 집합 [0, ..., N - 1]의 요소들이다.Where x i , y i are elements of the set [0, ..., N - 1].
u, v는 프레임 't'내의 블록 'B'의 상대적 위치를 나타내는 인덱스이다(예를 들어, 프레임 't'에 Z개의 블록이 있다고 가정하면, u, v는 집합 [0, .... Z-1]의 요소들이다).u, v is an index indicating the relative position of block 'B' in frame 't' (for example, assuming that there are Z blocks in frame 't' Z-1].
프레임의 모든 블록에 대해, 공간 분산 결정기(220)는 블록의 공간 분산을 계산한다. 블록의 공간 분산은 블록의 픽셀들의 강도 분산이다. 한 구현에서, 블록의 공간 분산은 다음과 같이 계산될 수 있다:For all blocks of the frame, the spatial variance determiner 220 calculates the spatial variance of the block. The spatial variance of the block is the intensity variance of the pixels of the block. In one implementation, the spatial variance of the block can be computed as:
여기서here
이고,ego,
E(.)는 집합의 평균값(mean value)을 반환한다. 프레임 t의 각각의 블록 B의 공간 분산은 집합 Sp에서 집결될 수 있다.E (.) Returns the mean value of the set. The spatial variance of each block B of frame t may be gathered at a set S p .
시간 분산 결정기(230)는 또한, 프레임 t에서 모든 블록 B에 대해, 공간 분산과는 별도로, 시간 분산을 계산한다. 블록의 시간 분산은 프레임 t의 전후의 M개의 프레임들을 이용하여 시간 분산 결정기(230)에 의해 계산된다. 이전 프레임들은 z = 1, ..., M에 대한 I(x, y, t-z)이고 다음 프레임들은 z = 1, ..., M에 대한 I(x, y, t+z)이다. 한 구현에서, 블록의 시간 분산은 다음과 같이 계산될 수 있다:The time variance determiner 230 also calculates time variance for all blocks B in frame t, separately from spatial variance. The time variance of the block is calculated by the time variance decider 230 using M frames before and after frame t. The previous frames are I (x, y, t-z) for z = 1, ..., M and the following frames are I (x, y, t + z) for z = 1, ..., In one implementation, the time variance of the block can be calculated as:
여기서,here,
한 구현에서, 움직임 보상 알고리즘이 적용되어 이전 프레임 및 다음 프레임들을 프레임 I(x, y, t) 내로 투사한다. 그 다음, 시간 분산이, z = t-M, ..., t+M(총 2M + 1개의 프레임)에 대해 모든 움직임-보상된 프레임들 I(x, y, z)에 걸친 각각의 픽셀에 대해 계산된다. 결과 프레임은 D(x, y)라고 지칭될 수 있다. D(x, y)의 분산이 모든 블록 B에 대해 계산되고, 집합 St에 추가된다.In one implementation, a motion compensation algorithm is applied to project the previous and next frames into frame I (x, y, t). The time variance is then calculated for each pixel over all motion-compensated frames I (x, y, z) for z = tM, ..., t + M (total 2M + . The resulting frame may be referred to as D (x, y). The variance of D (x, y) is calculated for all blocks B and added to the set S t .
노이즈 공분산 컴포넌트(240)는 본 개시내용의 구현들의 노이즈 추정을 수행할 때 노이즈 추정 컴포넌트(140)가 준수하는 조건을 설정한다. 이론적으로, 전술된 방식으로 계산되어 Sp와 St에서 집결되는 공간 및 시간 분산은 다음과 같은 방정식을 설정한다:The
여기서 s 및 t는 공간 및 시간 노이즈 전력이고, 여기서 Var(.)는 분산 함수이며, Where s and t are the spatial and temporal noise powers, where Var (.) Is the dispersion function,
여기서, 노이즈 공분산 컴포넌트(240)는 노이즈 공분산이 고정된 것으로 가정되는 조건을 설정한다(백색 노이즈에 대해서는 0이고 상관된 노이즈에 대해서는 0이 아닌 상수). 그 결과, 균일 블록들은 다음과 같은 방정식을 만족해야 한다.Here, the
즉, 최대 노이즈 전력이 v이면, 균일 블록들의 공간 노이즈 전력은 v보다 작을 것으로 예상되고, 균일 블록들에 대해 계산된 노이즈 공분산 That is, if the maximum noise power is v, the spatial noise power of the uniform blocks is expected to be less than v, and the noise covariance
노이즈 공분산 컴포넌트(240)를 통해 조건들을 설정함으로써, 균일 블록들이 이하의 설명에 따라 검출될 수 있다. 초기 문제로서, 시간 분산 변환기(250)는 노이즈 공분산을 0으로 설정하고, 집합 St의 모든 시간 노이즈 분산 t를 다음으로 변환한다:By setting the conditions via the
(2M+1) * t / 2M.(2M + 1) * t / 2M.
시간 변화 변환기(250)에 의해 수행되는 변환은, 전술된 균일 블록들에 대한 공간 분산과 시간 분산 사이의 결정된 관계에 기초한다.The transform performed by the time variant transformer 250 is based on the determined relationship between the spatial variance and the temporal variance for the uniform blocks described above.
그 다음, 평균 분산 결정기(260)는, 최대 노이즈 전력, x(0 내지 집합 Sp 및 St의 합집합에 대한 최대 분산의 범위 내에 있음)을 입력으로서 취하는 함수 Ps(x)를 정의하고, x보다 작은 (Sp에 집결된) 공간 분산을 갖는 블록들에 대한 공간 분산들의 평균을 반환한다. 유사하게, 평균 분산 결정기(260)는, 입력으로서 최대 노이즈 전력 x를 취하는 함수 Pt(x)를 정의하고, x보다 작은 (St에 집결된) 시간 분산을 갖는 블록들에 대한 시간 분산들의 평균을 반환한다.The
그 다음, 최적 노이즈 분산 결정기(270)는 프레임에 대한 최적 노이즈 분산을 식별한다. 노이즈 공분산 컴포넌트(240)에 의해 설정된 조건들에 기초하여, 균일 블록들의 공간 및 변환된 시간 노이즈 분산들 사이의 차이는 실제 최대 노이즈 전력 v에 대한 일정한 값이어야 한다. 따라서, 0부터 v까지의, 두 함수 Ps(x) 및 Pt(x) 상의 모든 대응하는 점 사이의 거리는 고정될 것으로 예상된다. 이것은, 0부터 v까지의 점들에 대한 (Ps(x)-Pt (x))의 분산이 0에 가까워야 한다는 것을 의미한다. y = 0 내지 x에 대해 평균 함수는 E(x) = Mean (Ps(y)-Pt(y))로서 정의될 수 있고, 분산 함수는 V(x) = Var (Ps(y)-Pt(y))로서 정의될 수 있다. 여기서, E(x)는 x의 노이즈 전력에서 추정된 노이즈 공분산 The optimal
후속해서, 최적 노이즈 분산 결정기(270)는, v가 다음과 같이 되도록, 실제 노이즈 전력 (분산) v(여기서는 최적 프레임 노이즈 분산이라 칭함)를 식별할 수 있다:Subsequently, the optimal
(1) V(x) 상의 절대 최대값보다 작도록,(1) less than the absolute maximum value on V (x)
(2)는 Ps(x)와 (Pt(x)+(x))의 교점이도록; 및(2) is the intersection of P s (x) and (P t (x) + (x)); And
(3) V(v)는 0에 가깝도록(예를 들어, 절대 최대값에서의 V(x)의 임계 퍼센트 미만; 예를 들어 절대 최대값에서 V(x)의 5% 미만이어야 함).(3) V (v) should be close to zero (for example, less than a threshold percentage of V (x) at an absolute maximum; e.g., less than 5% of V (x) at an absolute maximum).
비디오의 각각의 프레임에 대한 최적 프레임 노이즈 분산을 결정한 후에, 최적 노이즈 분산 결정기(270)는 비디오의 최적 최대 노이즈 전력(여기서는 최적 비디오 노이즈 분산이라고도 함)을 식별할 수 있다. 한 구현에서, 최적 비디오 노이즈 분산은, 비디오의 프레임들 각각에 대해 결정된 모든 최적 프레임 노이즈 분산들의 중앙값이다.After determining the optimal frame noise variance for each frame of video, optimal
비디오의 최적 비디오 노이즈 분산을 이용하여, 균일 블록 식별자(280)는, 최적 비디오 노이즈 분산보다 작은 공간 분산을 갖는 블록들을 균일 블록들로서 선택할 수 있다. 식별된 균일 블록은 비디오의 노이즈 신호 추정에 이용될 수 있다.Using the optimal video noise variance of the video, the
한 구현에서, 각각의 프레임의 최적 프레임 노이즈 분산 뿐만 아니라, 비디오의 최적 비디오 노이즈 분산은 노이즈 추정 데이터(291)로서 데이터 저장소(106)에 저장될 수 있다. 노이즈 추정 컴포넌트(140)에 의해 수행되는 전술된 노이즈 추정 프로세스는, 상이한 비디오 캡처 디바이스들에 의해 캡처된 비디오 세트(예를 들어, 데이터 저장소(106)의 미디어 아이템 데이터(290)로서 저장됨)에 대한 노이즈를 추정하는데 이용될 수 있다. 비디오 캡처 디바이스의 각각의 타입은 고유한 노이즈 특성 및/또는 고유한 노이즈 모델을 가질 수 있다. 디바이스 타입 노이즈 모델 컴포넌트(290)는, 저장된 노이즈 추정 데이터(291)를 분석하여 각각의 타입의 비디오 캡처 디바이스에 대한 노이즈 모델을 추출 및 생성할 수 있다. 후속해서, 각각의 타입의 비디오 캡처 디바이스에 대한 디바이스 노이즈 모델은, 특정한 비디오 캡처 디바이스에 의해 업로드된 비디오에 대해 적용되는 비디오 처리 애플리케이션(예를 들어, 노이즈 제거)에서 이용될 수 있다.In one implementation, the optimal video noise variance of the video as well as the optimal frame noise variance of each frame may be stored in the
도 3은 본 개시내용의 일부 구현들에 따른 비디오에 대한 상호 노이즈 추정을 위한 방법(300)을 나타내는 흐름도이다. 이 방법(300)은, 하드웨어(예를 들어, 회로, 전용 로직, 프로그래머블 로직, 마이크로코드 등), 소프트웨어(예를 들어, 하드웨어 시뮬레이션을 수행하기 위해 처리 디바이스 상에서 실행되는 명령어), 또는 이들의 조합을 포함하는 처리 로직에 의해 수행될 수 있다.3 is a flow diagram illustrating a
설명의 간소화를 위해, 본 개시내용의 방법들은 일련의 행위로서 도시되고 설명된다. 그러나, 본 개시내용에 따른 행위들은 다양한 순서로 및/또는 동시에 발생할 수 있고, 다른 행위들은 제시되지 않거나 여기서 설명되지 않는다. 또한, 개시된 주제에 따른 방법들을 구현하기 위해 모든 예시된 행위들이 요구되는 것은 아닐 수도 있다. 또한, 본 분야의 통상의 기술자라면, 이 방법들은 대안으로서 상태도 또는 이벤트들을 통해 일련의 상관된 상태들로서 표현될 수 있다는 것을 이해하고 인정해야 한다. 추가로, 본 명세서에서 개시된 방법들은 이러한 방법들의 컴퓨팅 디바이스로의 이송 및 전달을 용이하게 하기 위해 제조품에 저장될 수 있다는 것을 이해해야 한다. 용어 "제조품(article)"은, 여기서 사용될 때, 임의의 컴퓨터-판독가능 디바이스나 저장 매체로부터 액세스될 수 있는 컴퓨터 프로그램을 포괄하기 위한 것이다. 한 구현에서, 방법(300)은, 도 2에 도시된 바와 같이, 노이즈 추정 컴포넌트(140)에 의해 수행될 수 있다.For purposes of simplicity of explanation, the methods of the present disclosure are shown and described as a series of acts. However, the acts in accordance with the present disclosure may occur in various orders and / or concurrently, and other acts are not presented or described herein. In addition, not all illustrated acts may be required to implement methods in accordance with the disclosed subject matter. It should also be appreciated and appreciated by those of ordinary skill in the art that these methods may alternatively be represented as a series of correlated states through state diagrams or events. Additionally, it should be appreciated that the methods described herein may be stored in an article of manufacture to facilitate transport and transfer of such methods to a computing device. The term " article " when used herein is intended to encompass a computer program that can be accessed from any computer-readable device or storage medium. In one implementation, the
방법(300)은 블록 310에서 시작하고, 여기서, 비디오의 각각의 프레임에 대해, 최적 프레임 노이즈 분산 값이 프레임 내의 균일 블록들의 공간 및 시간 분산들 사이의 결정된 관계에 기초하여 결정된다. 그 다음, 블록 320에서, 비디오에 대한 최적 비디오 노이즈 분산이 비디오의 최적 프레임 노이즈 분산에 기초하여 식별된다. 최적 프레임 노이즈 분산은 전술된 바와 같이 블록 310에서 결정된 것이다. 한 구현에서, 최적 비디오 노이즈 분산은 비디오 내의 프레임들의 최적 프레임 노이즈 분산들의 중앙값이다.The
후속해서, 블록 330에서, 비디오의 각각의 프레임에 대해, 최적 비디오 노이즈 분산보다 작은 공간 분산을 갖는 블록들이 선택된다. 한 구현에서, 이들 선택된 블록들은 비디오의 균일 블록으로서 간주된다. 마지막으로, 블록 340에서, 선택된 균일 블록들은 비디오에 대한 노이즈 신호를 추정하는데 이용된다. 한 구현에서, 추정된 노이즈 신호는 비디오의 처리에 이용된다. 처리는, 몇 가지 예를 거명하자면, 비디오 압축, 분할, 포맷 변환, 움직임 추정, 노이즈 제거, 및/또는 필터링을 포함할 수 있지만, 이것으로 제한되는 것은 아니다.Subsequently, at
도 4는 본 개시내용의 한 구현에 따른 비디오에 대한 상호 노이즈 추정을 위한 또 다른 방법(400)을 나타내는 흐름도이다. 이 방법(400)은, 하드웨어(예를 들어, 회로, 전용 로직, 프로그래머블 로직, 마이크로코드 등), 소프트웨어(예를 들어, 하드웨어 시뮬레이션을 수행하기 위해 처리 디바이스 상에서 실행되는 명령어), 또는 이들의 조합을 포함하는 처리 로직에 의해 수행될 수 있다. 한 구현에서, 방법(400)은, 도 2에 도시된 바와 같이, 노이즈 추정 컴포넌트(140)에 의해 수행될 수 있다.4 is a flow diagram illustrating another
방법(400)은, 비디오의 프레임이 동일한 크기의 픽셀 블록들로 분할되는 블록 410에서 시작한다. 한 구현에서, 블록들은 절반-중첩된 블록들이다. 블록 420에서, 각각의 블록에 대해, 블록에 대한 강도의 공간 분산이 계산된다. 그 다음, 블록 430에서, 각각의 블록에 대해, 블록에 대한 강도의 시간 분산이 계산된다. 한 구현에서, 프레임 이전 및 이후에 결정된 수의 프레임들이 블록의 시간 분산을 계산하는데 이용된다.The
후속해서, 블록 440에서, 각각의 프레임에 대해, 프레임의 블록들의 시간 분산이 변환된다. 한 구현에서, 시간 분산은 공간 분산과 시간 분산 사이의 구성된 관계에 기초하여 그리고 프레임 내의 균일 블록들에 대해 공분산 값 0이 존재한다는 가정에 기초하여 변환된다.Subsequently, at
블록 450에서, 각각의 프레임에 대해, 공간 분산들의 평균을 제공하기 위해 제1 함수가 적용된다. 공간 분산의 평균은, 0부터 최대 분산까지의 분산 값 범위에 대한 분산 값 'x'보다 작은 공간 분산을 갖는 블록들에 대해 계산된다. 최대 분산은 블록들 420 및 430에서 계산된 공간 분산 및 시간 분산 집합의 합집합이다.At
블록 460에서, 각각의 프레임에 대해, 블록 440으로부터 변환된 시간 분산의 평균을 제공하기 위해 제2 함수가 적용된다. 변환된 시간 분산의 평균은, 0부터 최대 분산까지의 분산 값 범위에 대한 분산 값 'x'보다 작은 변환된 시간 분산을 갖는 블록들에 대해 계산된다. 최대 분산은 블록들 420 및 430에서 계산된 공간 분산 및 시간 분산 집합의 합집합이다.At
후속해서, 블록 470에서, 각각의 프레임에 대해, 최적 프레임 노이즈 분산이 적용된 제1 함수와 적용된 제2 함수의 교점에 기초하여 식별된다. 한 구현에서, 교점은 V(x)의 절대 최대값보다 작고, 여기서 V(x)는 제1 함수와 제2 함수 사이의 차이의 분산이다. 마지막으로, 블록 480에서, 비디오에 대한 최적 비디오 노이즈 분산은 (블록(470)에서 식별된) 비디오의 프레임들의 식별된 최적 프레임 노이즈 분산들의 중앙값으로서 식별된다.Subsequently, at
한 구현에서, 최적 비디오 노이즈 분산은 비디오 내의 균일 블록들을 선택하고 비디오에 대한 노이즈 신호를 추정하는데 이용될 수 있으며, 여기서 노이즈 신호는 비디오의 처리에 이용된다. 한 구현에서, 처리는, 몇 가지 예를 거명하자면, 비디오 압축, 분할, 포맷 변환, 움직임 추정, 노이즈 제거, 및/또는 필터링을 포함할 수 있다.In one implementation, optimal video noise variance can be used to select uniform blocks in the video and estimate the noise signal for the video, where the noise signal is used to process the video. In one implementation, the processing may include video compression, segmentation, format conversion, motion estimation, noise removal, and / or filtering, to name a few examples.
도 5는 본 개시내용의 구현에 따른 비디오에 대한 상호 노이즈 추정을 이용하여 비디오 캡처 디바이스에 대한 노이즈 모델을 생성하기 위한 방법(500)을 나타내는 흐름도이다. 이 방법(500)은, 하드웨어(예를 들어, 회로, 전용 로직, 프로그래머블 로직, 마이크로코드 등), 소프트웨어(예를 들어, 하드웨어 시뮬레이션을 수행하기 위해 처리 디바이스 상에서 실행되는 명령어), 또는 이들의 조합을 포함하는 처리 로직에 의해 수행될 수 있다. 한 구현에서, 방법(500)은, 도 2에 도시된 바와 같이, 노이즈 추정 컴포넌트(140)에 의해 수행될 수 있다.5 is a flow diagram illustrating a
방법(500)은, 결정된 타입의 비디오 캡처 디바이스에 대응하는 비디오 세트의 각각의 비디오에 대해 최적 비디오 노이즈 분산이 식별되는 블록 510에서 시작한다. 한 구현에서, 최적 비디오 노이즈 분산은 비디오의 프레임들의 최적 프레임 노이즈 분산들의 중앙값이다. 최적 프레임 노이즈 분산은 프레임들 각각 내의 블록들의 공간 분산과 시간 분산 사이의 결정된 관계에 기초한다.The
블록 520에서, 결정된 타입의 비디오 캡처 디바이스에 대응하는 노이즈 모델이 비디오의 식별된 최적 비디오 노이즈 분산에 기초하여 생성된다. 후속해서, 블록 530에서, 결정된 타입의 비디오 캡처 디바이스에 대한 노이즈 모델이 저장된다. 마지막으로, 블록 540에서, 저장된 노이즈 모델이 적용되어 결정된 타입의 비디오 캡처 디바이스에 의해 캡처된 것으로 표시된 하나 이상의 업로드된 비디오를 노이즈 제거한다.At
도 6은, 머신으로 하여금 여기서 논의된 방법론들 중 임의의 하나 이상을 수행하게 하기 위한 명령어 세트가 실행될 수 있는 컴퓨터 시스템(600)의 예시적 형태로 된 머신의 도식적 표현을 나타낸다. 대안적 구현에서, 머신은, 근거리 통신망(LAN), 인트라넷, 엑스트라넷, 또는 인터넷 내의 다른 머신들에 접속(예를 들어, 네트워킹)될 수 있다. 머신은 클라이언트-서버 머신 환경에서 서버 또는 클라이언트 머신의 용량에서 또는 피어-투-피어(또는 분산형) 네트워크 환경에서 피어 머신으로서 동작할 수 있다. 머신은, 개인용 컴퓨터(PC), 태블릿 PC, 셋탑 박스(STB), PDA(personal digital assistant), 셀룰러 전화, 웹 어플라이언스, 서버, 네트워크 라우터, 스위치 또는 브릿지, 또는 머신에 의해 취해지는 동작을 명시하는 한 세트의 명령어를 (순차적 또는 기타의 방식) 실행할 수 있는 임의의 머신일 수 있다.Figure 6 illustrates a graphical representation of a machine in an exemplary form of a
또한, 단일의 머신만이 예시되어 있지만, 용어 "머신"은, 여기서 논의된 방법론들 중 임의의 하나 이상을 수행하기 위해 개별적으로 또는 공동으로 한 세트(또는 복수 세트)의 명령어를 실행하는 머신들의 임의의 집합을 포함하는 것으로 간주되어야 할 것이다. 한 구현에서, 컴퓨터 시스템(600)은 도 1 및 도 2와 관련하여 설명된 바와 같이, 노이즈 추정 컴포넌트(140)를 실행하는 서버 디바이스(102) 등의 서버 디바이스를 나타낼 수 있다. 또 다른 구현에서, 컴퓨터 시스템(600)은 클라이언트 디바이스(110A-110Z) 등의 클라이언트 디바이스를 나타낼 수 있다.Also, although only a single machine is illustrated, the term " machine " is intended to encompass all types of machines that execute a set (or sets of) instructions individually or collectively to perform any one or more of the methodologies discussed herein It should be regarded as including any set. In one implementation,
예시적 컴퓨터 시스템(600)은, 버스(630)를 통해 서로 통신하는, 처리 디바이스(602), 메인 메모리(604)(예를 들어, 판독 전용 메모리(ROM), 플래시 메모리, (싱크로너스 DRAM(SDRAM) 또는 램버스 DRAM(RDRAM) 등의) 동적 랜덤 액세스 메모리(DRAM), 정적 메모리(606)(예를 들어, 플래시 메모리, 정적 랜덤 액세스 메모리(SRAM) 등), 및 데이터 저장 디바이스(618)를 포함한다. 여기서 설명된 다양한 버스를 통해 제공되는 임의의 신호는 다른 신호와 멀티플렉싱될 수 있고 하나 이상의 공통 버스를 통해 제공될 수 있다. 추가로, 회로 컴포넌트들 또는 블록들 사이의 상호접속은 버스로서 또는 단일 신호선으로서 도시될 수 있다. 버스들 각각은 대안으로서 하나 이상의 단일 신호선일 수도 있고 단일 신호선들 각각은 대안으로서 버스일 수도 있다.
처리 디바이스(602)는, 마이크로프로세서, 중앙 처리 유닛 등의, 하나 이상의 범용 처리 디바이스를 나타낸다. 더 구체적으로는, 처리 디바이스는, CISC(complex instruction set computing) 마이크로프로세서, RISC(reduced instruction set computer) 마이크로프로세서, VLIW(very long instruction word) 마이크로프로세서, 또는 다른 명령어 세트들을 구현하는 프로세서나 명령어 세트들의 조합을 구현하는 프로세서들일 수 있다. 처리 디바이스(602)는 또한, 주문형 집적 회로(application specific integrated circuit)(ASIC), 필드 프로그래머블 게이트 어레이(field programmable gate array)(FPGA), 디지털 신호 프로세서(digital signal processor)(DSP), 네트워크 프로세서 등의 하나 이상의 특별-목적 처리 디바이스일 수도 있다. 처리 디바이스(602)는 여기서 논의된 동작들과 단계들을 수행하기 위한 처리 로직(626)을 실행하도록 구성된다.The processing device 602 represents one or more general purpose processing devices, such as a microprocessor, a central processing unit, or the like. More specifically, the processing device may be a processor or instruction set implementing a complex instruction set computing (CISC) microprocessor, a reduced instruction set computer (RISC) microprocessor, a very long instruction word (VLIW) microprocessor, Lt; RTI ID = 0.0 > a < / RTI > The processing device 602 may also be an application specific integrated circuit (ASIC), a field programmable gate array (FPGA), a digital signal processor (DSP), a network processor, Lt; / RTI > special-purpose processing device. The processing device 602 is configured to execute the processing logic 626 for performing the operations and steps discussed herein.
컴퓨터 시스템(600)은 네트워크 인터페이스 디바이스(608)를 더 포함할 수 있다. 컴퓨터 시스템(600)은 또한, 비디오 디스플레이 유닛(610)(예를 들어, 액정 디스플레이(LCD) 또는 음극선관(CRT)), 영숫자 입력 디바이스(612)(예를 들어, 키보드), 커서 제어 디바이스(614)(예를 들어, 마우스), 및 신호 생성 디바이스(616)(예를 들어, 스피커)를 포함할 수 있다.The
데이터 저장 디바이스(618)는, 여기서 설명된 기능들의 임의의 하나 이상의 방법론을 구현하는 하나 이상의 세트의 명령어(622)(예를 들어, 소프트웨어)가 저장되어 있는 (머신-판독가능 저장 매체라고도 하는) 컴퓨터-판독가능 저장 매체(628)를 포함할 수 있다. 명령어(622)는 또한, 컴퓨터 시스템(600)에 의한 그 실행 동안에, 완전히 또는 적어도 부분적으로, 메인 메모리(604) 내에 및/또는 처리 디바이스(602) 내에 존재할 수 있다; 메인 메모리(604)와 처리 디바이스(602)는 또한 머신-판독가능 저장 매체를 구성한다. 명령어(622)는 또한, 네트워크 인터페이스 디바이스(608)를 이용하여 네트워크(620)를 통해 전송되거나 수신될 수 있다.The data storage device 618 may also include one or more sets of instructions 622 (e.g., software) that implement any one or more of the functions described herein (also referred to as machine-readable storage media) And a computer-readable storage medium 628. The instructions 622 may also reside entirely or at least partially within the main memory 604 and / or within the processing device 602 during its execution by the
컴퓨터-판독가능 저장 매체(628)는 또한, 여기서 설명된 바와 같이, 비디오에 대한 상호 노이즈 추정을 위한 방법을 수행하는 명령어들을 저장하는데 이용될 수 있다. 컴퓨터-판독가능 저장 매체(628)가 예시적인 구현에서 단일의 매체로서 도시되어 있지만, 용어 "머신-판독가능 매체"는 하나 이상의 명령어 세트를 저장하는 단일 매체 또는 복수의 매체(예를 들어, 중앙집중형 또는 분산형 데이터베이스, 및/또는 연관된 캐쉬 및 서버)를 포함하는 것으로 간주되어야 한다. 머신-판독가능 매체는, 머신(예를 들어, 컴퓨터)에 의해 판독가능 형태로 정보(예를 들어, 소프트웨어, 처리 애플리케이션)를 저장하기 위한 임의의 메커니즘을 포함한다. 머신-판독가능 매체는, 자기적 저장 매체(예를 들어, 플로피 디스켓), 광학적 저장 매체(예를 들어, CD-ROM); 광자기 저장 매체; 판독 전용 메모리(ROM); 랜덤-액세스 메모리(RAM); 소거가능한 프로그래머블 메모리(예를 들어, EPROM 및 EEPROM); 플래시 메모리; 또는 전자적 명령어들을 저장하기에 적합한 또 다른 타입의 매체를 포함할 수 있지만, 이것으로 제한되는 것은 아니다.The computer-readable storage medium 628 may also be used to store instructions that, as described herein, perform a method for mutual noise estimation on video. Although the computer-readable storage medium 628 is shown as a single medium in an exemplary implementation, the term " machine-readable medium " refers to a medium or medium that stores one or more sets of instructions, A centralized or distributed database, and / or associated caches and servers). The machine-readable medium includes any mechanism for storing information (e.g., software, processing applications) in a form readable by a machine (e.g., a computer). The machine-readable medium may include magnetic storage media (e.g., floppy diskettes), optical storage media (e.g., CD-ROMs); A magneto-optical storage medium; A read only memory (ROM); Random-access memory (RAM); Erasable programmable memory (e. G., EPROM and EEPROM); Flash memory; Or any other type of media suitable for storing electronic instructions.
상기의 설명은, 본 개시내용의 수 개의 구현들의 양호한 이해를 제공하기 위하여, 특정한 시스템, 컴포넌트, 방법 등의 예와 같은 수 많은 특정한 상세사항을 개시한다. 그러나, 본 개시내용의 적어도 일부의 구현들은 이들 특정한 상세사항 없이도 실시될 수 있다는 것은 본 기술분야의 통상의 기술자에게 명백할 것이다. 다른 예에서, 본 개시내용을 불필요하게 흐리게 하지 않기 위하여, 널리 공지된 컴포넌트들 또는 방법들은 상세히 설명되지 않거나 간단한 블록도 형태로 제시된다. 따라서, 특정한 상세사항은 단지 예시일 뿐이다. 특정한 구현들은 이들 예시적인 상세사항으로부터 달라질 수도 있고 여전히 본 개시내용의 범위 내에 있는 것으로 고려될 수 있다.The foregoing description discloses numerous specific details, such as examples of particular systems, components, methods, and so forth, in order to provide a thorough understanding of several implementations of the present disclosure. However, it will be apparent to those of ordinary skill in the art that implementations of at least some of the present teachings may be practiced without these specific details. In other instances, well-known components or methods are not described in detail or shown in simplified block diagram form in order not to unnecessarily obscure the present disclosure. Accordingly, the specific details are merely illustrative. Certain implementations may vary from these exemplary details and still be considered within the scope of the present disclosure.
본 명세서 전체에 걸쳐 "한 구현" 또는 "구현"이라는 말은, 그 구현과 관련하여 기술되는 특정한 피처, 구조, 또는 특성이 적어도 하나의 구현에 포함된다는 것을 의미한다. 따라서, 본 명세서의 다양한 곳에서 나타나는 문구 "한 구현에서" 또는 "구현에서"는, 반드시 모두가 동일한 구현을 지칭하는 것은 아니다. 또한, 용어 "또는"은 배타적인 "또는"이 아니라 포함적인 "또는"을 의미하고자 한다.The word "one implementation" or "an implementation" throughout this specification means that a particular feature, structure, or characteristic described in connection with the implementation is included in at least one implementation. The appearances of the phrase " in one embodiment " or " in an implementation " in various places in the specification are therefore not necessarily all referring to the same embodiment. Also, the word " or " is intended to mean " exclusive " or " not inclusive "
여기서의 방법들의 동작들이 특정한 순서로 도시되고 설명되었지만, 각각의 방법의 동작들의 순서는, 소정의 동작들이 역순으로 수행되거나 소정의 동작이 적어도 부분적으로 다른 동작들과 동시에 수행되도록 변경될 수 있다. 또 다른 구현에서, 별개의 동작들의 명령어들 또는 서브-동작들은 간헐적인 및/또는 교대적인 방식일 수도 있다.Although the operations of the methods herein are shown and described in a particular order, the order of operations of each method may be varied such that certain operations are performed in reverse order or that certain operations are performed at least partially concurrently with other operations. In yet another implementation, the instructions or sub-operations of the separate operations may be in an intermittent and / or alternate manner.
Claims (20)
처리 디바이스에 의해, 비디오의 프레임들의 각각의 프레임의 강도 값들에 대한 최적 프레임 노이즈 분산(optimal frame noise variance) - 상기 최적 프레임 노이즈 분산은 상기 프레임 내의 균일 블록들의 강도 값들의 공간 분산과 시간 분산 사이의 결정된 관계에 기초함 - 을 결정하는 단계;
상기 비디오의 프레임들의 최적 프레임 노이즈 분산들에 기초하여 상기 비디오에 대한 최적 비디오 노이즈 분산을 식별하는 단계;
상기 비디오의 각각의 프레임에 대해, 상기 최적 비디오 노이즈 분산보다 작은 공간 분산을 갖는 상기 블록들 중 하나 이상을 선택하는 단계 - 상기 하나 이상의 선택된 블록은 상기 균일 블록들로서 라벨링됨 -; 및
상기 처리 디바이스에 의해, 상기 비디오의 노이즈 신호를 추정하기 위해 상기 선택된 균일 블록들을 이용하는 단계
를 포함하는 방법.As a method,
An optimal frame noise variance for intensity values of each frame of frames of video, by the processing device, wherein said optimal frame noise variance is a function of the difference between the spatial variance and the temporal variance of the intensity values of the uniform blocks in said frame. Based on the determined relationship;
Identifying an optimal video noise variance for the video based on optimal frame noise variances of the frames of the video;
Selecting, for each frame of the video, one or more of the blocks having a spatial variance less than the optimal video noise variance, the one or more selected blocks being labeled as the uniform blocks; And
Using the selected uniform blocks to estimate a noise signal of the video, by the processing device
≪ / RTI >
상기 프레임 내의 각각의 블록의 상기 공간 분산을 계산하는 단계;
상기 프레임 내의 각각의 블록의 상기 시간 분산을 계산하는 단계;
상기 공간 분산과 상기 시간 분산 사이의 상기 결정된 관계에 기초하여 그리고 상기 균일 블록들 사이의 노이즈 공분산이 일정한 값이라는 가정에 기초하여 상기 프레임의 블록들의 시간 분산들 각각을 각각의 변환된 시간 분산들로 변환하는 단계;
상기 프레임 내의 상기 공간 분산들에 제1 함수 - 상기 제1 함수는 분산 값들의 범위에 대한 분산 값 'x' 보다 작은 공간 분산들을 갖는 상기 프레임 내의 상기 블록들에 관한 상기 공간 분산들의 평균을 제공함 - 를 적용하는 단계;
상기 프레임 내의 상기 변환된 시간 분산들에 제2 함수 - 상기 제2 함수는 상기 분산 값들의 범위에 대한 상기 분산 값 'x'보다 작은 변환된 시간 분산들을 갖는 상기 프레임 내의 상기 블록들에 관한 상기 변환된 시간 분산들의 평균을 제공함 - 를 적용하는 단계; 및
상기 적용된 제1 함수와 상기 적용된 제2 함수의 교점에 기초하여 상기 프레임에 대한 상기 최적 프레임 노이즈 분산 값을 선택하는 단계
를 포함하는, 방법.2. The method of claim 1, wherein determining the optimal frame noise variance for each frame comprises:
Calculating the spatial variance of each block in the frame;
Calculating the time variance of each block in the frame;
Based on the determined relationship between the spatial variance and the temporal variance, and based on the assumption that the noise covariance between the uniform blocks is a constant value, transforming each of the temporal variances of the blocks of the frame into respective transformed temporal variances Converting;
Wherein the first function provides an average of the spatial variances with respect to the blocks in the frame having spatial variances less than a variance value 'x' for a range of variance values for the spatial variances within the frame, ;
A second function on the transformed time distributions in the frame, the second function including transforms on the blocks in the frame having transformed time variances less than the variance value 'x' for the range of variance values; Providing an average of the time distributions that are obtained; And
Selecting an optimal frame noise variance value for the frame based on an intersection of the applied first function and the applied second function
/ RTI >
비디오의 프레임 내의 각각의 블록에 대한 강도 값들의 공간 분산을 계산하는 동작;
상기 프레임 내의 각각의 블록의 상기 강도 값들에 대한 시간 분산을 계산하는 동작;
상기 공간 분산과 상기 시간 분산 사이의 결정된 관계에 기초하여 그리고 상기 비디오 내의 균일 블록들 사이의 노이즈 공분산이 일정한 값이라는 가정에 기초하여 상기 프레임의 블록들의 시간 분산들 각각을 변환된 시간 분산들로 변환하는 동작;
상기 프레임 내의 상기 공간 분산들에 제1 함수 - 상기 제1 함수는 분산 값들의 범위에 대한 분산 값 'x' 보다 작은 공간 분산 값들을 갖는 상기 프레임 내의 상기 블록들에 관한 상기 공간 분산들의 평균을 제공함 - 를 적용하는 동작;
상기 프레임 내의 상기 변환된 시간 분산들에 제2 함수 - 상기 제2 함수는 상기 분산 값들의 범위에 대한 분산 값 'x'보다 작은 변환된 시간 분산 값들을 갖는 상기 프레임 내의 상기 블록들에 관한 상기 변환된 시간 분산들의 평균을 제공함 - 를 적용하는 동작; 및
상기 적용된 제1 함수와 상기 적용된 제2 함수의 교점에 기초하여 상기 프레임에 대한 최적 프레임 노이즈 분산 값을 선택하는 동작
을 포함하는, 컴퓨터 프로그램 제품.15. A computer program product storing instructions that, when executed, cause a processing device to perform operations comprising:
Calculating a spatial variance of intensity values for each block within a frame of video;
Calculating a time variance for the intensity values of each block in the frame;
Transforming each of the temporal variances of the blocks of the frame into transformed temporal variances based on a determined relationship between the spatial variance and the temporal variance and on the assumption that the noise covariance between uniform blocks in the video is a constant value Operation;
A first function on the spatial distributions within the frame, the first function providing an average of the spatial variances for the blocks in the frame having spatial variance values less than a variance value 'x' for a range of variance values - applying an operation;
A second function on the transformed time distributions in the frame, the second function having a transform on the blocks in the frame having transformed time variance values smaller than a variance value 'x' for the range of variance values; Providing an average of the time distributions that are obtained; And
Selecting an optimal frame noise variance value for the frame based on an intersection of the applied first function and the applied second function
And a computer program product.
상기 비디오에 대한 최적 비디오 노이즈 분산 - 상기 최적 비디오 노이즈 분산은 상기 비디오의 프레임들의 상기 최적 프레임 노이즈 분산들의 중앙값을 포함함 - 을 식별하는 동작;
상기 비디오의 각각의 프레임에 대해, 상기 최적 비디오 노이즈 분산보다 작은 공간 분산을 갖는 상기 블록들 중 하나 이상을 선택하는 동작 - 상기 하나 이상의 선택된 블록은 균일 블록들로서 라벨링됨 -; 및
상기 처리 디바이스에 의해, 상기 비디오의 노이즈 신호를 추정하기 위해 상기 균일 블록들을 이용하는 동작
을 더 포함하는, 컴퓨터 프로그램 제품.13. The method of claim 12, wherein the operations comprise:
Identifying an optimal video noise variance for the video, the optimal video noise variance comprising a median of the optimal frame noise variances of frames of the video;
Selecting, for each frame of the video, one or more of the blocks having a spatial variance less than the optimal video noise variance, the one or more selected blocks being labeled as uniform blocks; And
Using the uniform blocks to estimate a noise signal of the video by the processing device
The computer program product further comprising:
메모리; 및
상기 메모리에 결합된 처리 디바이스
를 포함하고, 상기 처리 디바이스는:
결정된 타입의 비디오 캡처 디바이스에 대응하는 비디오 세트의 각각의 비디오에 대한 최적 비디오 노이즈 분산 - 상기 최적 비디오 노이즈 분산은 상기 비디오 세트의 상기 프레임들 각각 내의 균일 블록들의 공간 분산과 시간 분산 사이의 결정된 관계에 기초함 - 을 식별하고,
상기 식별된 최적 비디오 노이즈 분산들에 기초하여 상기 결정된 타입의 비디오 캡처 디바이스에 대응하는 노이즈 모델을 생성하며;
상기 결정된 타입의 비디오 캡처 디바이스에 대한 상기 노이즈 모델을 저장하고;
상기 결정된 타입의 비디오 캡처 디바이스에 의해 캡처된 것으로 표시된 업로드된 비디오들을 노이즈 제거하기 위해 상기 저장된 노이즈 모델을 적용하는, 시스템.As a system,
Memory; And
A processing device coupled to the memory
The processing device comprising:
An optimal video noise variance for each video of a video set corresponding to a determined type of video capture device, said optimal video noise variance being a determined relationship between spatial variance and time variance of uniform blocks within each of said frames of said video set A base box,
Generate a noise model corresponding to the determined type of video capture device based on the identified best video noise variances;
Store the noise model for a video capture device of the determined type;
And applying the stored noise model to remove noise from uploaded videos marked as being captured by the video capture device of the determined type.
상기 프레임 내의 각각의 블록의 상기 공간 분산을 계산하고;
상기 프레임 내의 각각의 블록의 상기 시간 분산을 계산하며;
상기 균일 블록들의 상기 공간 분산과 상기 시간 분산 사이의 상기 결정된 관계에 기초하여 그리고 상기 균일 블록들 사이의 노이즈 공분산이 일정한 값이라는 가정에 기초하여 상기 프레임의 블록들의 시간 분산 각각을 변환된 시간 분산으로 변환하고;
상기 프레임 내의 상기 공간 분산들에 제1 함수 - 상기 제1 함수는 분산 값들의 범위에 대한 분산 값 'x' 보다 작은 공간 분산들을 갖는 상기 프레임 내의 상기 블록들에 관한 상기 공간 분산들의 평균을 제공함 - 를 적용하며;
상기 프레임 내의 상기 변환된 시간 분산들에 제2 함수 - 상기 제1 함수는 상기 분산 값들의 범위에 대한 분산 값 'x'보다 작은 변환된 시간 분산들을 갖는 상기 프레임 내의 상기 블록들에 관한 상기 변환된 시간 분산들의 평균을 제공함 - 를 적용하고;
상기 적용된 제1 함수와 상기 적용된 제2 함수의 교점에 기초하여 상기 프레임에 대한 상기 최적 프레임 노이즈 분산 값을 선택함으로써
각각의 프레임에 대한 상기 최적 프레임 노이즈 분산을 식별하도록 구성되는, 시스템.20. The apparatus of claim 19,
Calculating the spatial variance of each block in the frame;
Calculate the time variance of each block in the frame;
Based on the determined relationship between the spatial variance of the uniform blocks and the temporal variance and on the assumption that the noise covariance between the uniform blocks is a constant value, Convert;
Wherein the first function provides an average of the spatial variances with respect to the blocks in the frame having spatial variances less than a variance value 'x' for a range of variance values for the spatial variances within the frame, Lt; / RTI >
A second function on the transformed time distributions in the frame, the first function having a transformed time variance that is less than a variance value 'x' for the range of variance values, Applying an average of the time variances;
By selecting the optimal frame noise variance value for the frame based on the intersection of the applied first function and the applied second function
And to identify the optimal frame noise variance for each frame.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/609,826 US10674045B2 (en) | 2017-05-31 | 2017-05-31 | Mutual noise estimation for videos |
US15/609,826 | 2017-05-31 | ||
PCT/US2018/021840 WO2018222240A1 (en) | 2017-05-31 | 2018-03-09 | Mutual noise estimation for videos |
Publications (2)
Publication Number | Publication Date |
---|---|
KR20190004256A true KR20190004256A (en) | 2019-01-11 |
KR102099030B1 KR102099030B1 (en) | 2020-04-08 |
Family
ID=61764160
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020187018635A KR102099030B1 (en) | 2017-05-31 | 2018-03-09 | Mutual noise estimation for video |
Country Status (6)
Country | Link |
---|---|
US (1) | US10674045B2 (en) |
EP (1) | EP3631752B1 (en) |
JP (1) | JP6616008B2 (en) |
KR (1) | KR102099030B1 (en) |
CN (1) | CN109328372B (en) |
WO (1) | WO2018222240A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20210141697A (en) * | 2019-07-29 | 2021-11-23 | 지티이 코포레이션 | Video denoising method, device and computer readable storage medium |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2019112558A1 (en) * | 2017-12-05 | 2019-06-13 | Google Llc | Noise reduction method for high dynamic range videos |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5500685A (en) * | 1993-10-15 | 1996-03-19 | Avt Communications Limited | Wiener filter for filtering noise from a video signal |
US20120019667A1 (en) * | 2010-07-26 | 2012-01-26 | Sony Corporation | Method and device for adaptive noise measurement of a video signal |
WO2016185708A1 (en) * | 2015-05-18 | 2016-11-24 | 日本電気株式会社 | Image processing device, image processing method, and storage medium |
Family Cites Families (53)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5844627A (en) * | 1995-09-11 | 1998-12-01 | Minerya System, Inc. | Structure and method for reducing spatial noise |
US6067125A (en) * | 1997-05-15 | 2000-05-23 | Minerva Systems | Structure and method for film grain noise reduction |
US6244514B1 (en) * | 1998-04-20 | 2001-06-12 | Ayao Wada | Smart card for storage and retrieval of digitally compressed color images |
US6295382B1 (en) * | 1998-05-22 | 2001-09-25 | Ati Technologies, Inc. | Method and apparatus for establishing an adaptive noise reduction filter |
FR2791496B1 (en) * | 1999-03-26 | 2001-10-19 | Gemplus Card Int | COUNTERMEASUREMENT METHODS IN AN ELECTRONIC COMPONENT USING AN ELLIPTICAL CURVE TYPE PUBLIC KEY CRYTOGRAPHY ALGORITHM |
KR100327385B1 (en) * | 2000-07-18 | 2002-03-13 | Lg Electronics Inc | Spatio-temporal three-dimensional noise filter |
FR2828977B1 (en) * | 2001-08-21 | 2003-12-05 | Nextream Sa | DEVICE AND METHOD FOR ESTIMATING THE NOISE LEVEL, NOISE REDUCTION SYSTEM AND ENCODING SYSTEM COMPRISING SUCH A DEVICE |
DE60312981D1 (en) * | 2003-08-26 | 2007-05-16 | St Microelectronics Srl | Method and system for canceling the interlacing process during the presentation of video images |
JP2005080301A (en) * | 2003-09-01 | 2005-03-24 | Matsushita Electric Ind Co Ltd | Dynamic image encoding method and dynamic image decoding method |
US7822286B2 (en) * | 2003-11-07 | 2010-10-26 | Mitsubishi Electric Research Laboratories, Inc. | Filtering artifacts in images with 3D spatio-temporal fuzzy filters |
US7295616B2 (en) * | 2003-11-17 | 2007-11-13 | Eastman Kodak Company | Method and system for video filtering with joint motion and noise estimation |
US20050107982A1 (en) * | 2003-11-17 | 2005-05-19 | Zhaohui Sun | Method and system for noise estimation from video sequence |
KR100624421B1 (en) * | 2004-05-04 | 2006-09-19 | 삼성전자주식회사 | Apparatus and method for filtering digital image signal |
KR100599133B1 (en) * | 2004-06-08 | 2006-07-13 | 삼성전자주식회사 | Noise measurement apparatus for image signal and a method thereof |
KR20050119422A (en) * | 2004-06-16 | 2005-12-21 | 삼성전자주식회사 | Method and apparatus for estimating noise of input image based on motion compenstion and, method for eliminating noise of input image and for encoding video using noise estimation method, and recording medium for storing a program to implement the method |
US7715645B2 (en) * | 2004-11-17 | 2010-05-11 | Samsung Electronics Co., Ltd. | Methods to estimate noise variance from a video sequence |
ATE530015T1 (en) * | 2005-01-18 | 2011-11-15 | Lg Electronics Inc | ARRANGEMENT FOR REMOVAL OF NOISE FROM A VIDEO SIGNAL |
KR100672328B1 (en) * | 2005-01-18 | 2007-01-24 | 엘지전자 주식회사 | Apparatus for estimation noise level of video signal |
US20070223057A1 (en) * | 2006-03-21 | 2007-09-27 | Sony Corporation | Method of estimating noise in spatial filtering of images |
US7652788B2 (en) * | 2006-06-23 | 2010-01-26 | Nokia Corporation | Apparatus, method, mobile station and computer program product for noise estimation, modeling and filtering of a digital image |
TWI361618B (en) * | 2006-12-26 | 2012-04-01 | Realtek Semiconductor Corp | Method and device for estimating noise |
US7643011B2 (en) * | 2007-01-03 | 2010-01-05 | Apple Inc. | Noise detection in multi-touch sensors |
US20080310677A1 (en) * | 2007-06-18 | 2008-12-18 | Weismuller Thomas P | Object detection system and method incorporating background clutter removal |
TW200901751A (en) * | 2007-06-20 | 2009-01-01 | Sunplus Technology Co Ltd | System and method for estimating noise in a video frame |
TW200906170A (en) * | 2007-07-18 | 2009-02-01 | Sunplus Technology Co Ltd | Image noise estimation system and method |
US8982947B2 (en) * | 2007-07-20 | 2015-03-17 | The Hong Kong University Of Science And Technology | Rate control and video denoising for noisy video data |
US7941297B2 (en) * | 2008-04-10 | 2011-05-10 | Ati Technologies Ulc | Noise measurement in video images |
US8149336B2 (en) * | 2008-05-07 | 2012-04-03 | Honeywell International Inc. | Method for digital noise reduction in low light video |
KR101556593B1 (en) * | 2008-07-15 | 2015-10-02 | 삼성전자주식회사 | Method for Image Processing |
US20110182356A1 (en) * | 2008-07-25 | 2011-07-28 | Satya Ghosh Ammu | A method for the estimation of spatio-temporal homogeneity in video sequences |
CN101504769B (en) * | 2009-03-23 | 2014-07-16 | 上海视涛电子科技有限公司 | Self-adaptive noise intensity estimation method based on encoder frame work |
US8279345B2 (en) * | 2009-07-21 | 2012-10-02 | Qualcomm Incorporated | System and method for random noise estimation in a sequence of images |
SG10201408613UA (en) * | 2009-10-30 | 2015-02-27 | Agency Science Tech & Res | Methods, Devices, And Computer Readable Mediums For Processing A Digital Picture |
US9173629B2 (en) * | 2009-11-18 | 2015-11-03 | Kabushiki Kaisha Toshiba | Ultrasonic diagnostic apparatus and ultrasonic image processing apparatus |
US8923546B2 (en) * | 2010-07-02 | 2014-12-30 | Digimarc Corporation | Assessment of camera phone distortion for digital watermarking |
US9392267B2 (en) * | 2010-12-15 | 2016-07-12 | Tektronix, Inc. | System and methods to measure noise and to generate picture quality prediction from source having no reference |
JP2012231389A (en) | 2011-04-27 | 2012-11-22 | Sony Corp | Image processing apparatus, image processing method, and program |
US8761540B2 (en) | 2011-06-14 | 2014-06-24 | Kabushiki Kaisha Toshiba | Method and system for estimating noise level |
US9819879B2 (en) * | 2011-07-12 | 2017-11-14 | Samsung Electronics Co., Ltd. | Image filtering apparatus and method based on noise prediction using infrared ray (IR) intensity |
TW201322769A (en) * | 2011-11-28 | 2013-06-01 | Sunplus Technology Co Ltd | Motion vector refining device, motion interpolation apparatus and video refining method thereof |
JP6082304B2 (en) * | 2012-04-17 | 2017-02-15 | キヤノン株式会社 | Image processing apparatus and processing method thereof |
US9053551B2 (en) * | 2012-05-23 | 2015-06-09 | International Business Machines Corporation | Vessel identification using shape and motion mapping for coronary angiogram sequences |
TWI501628B (en) * | 2013-01-08 | 2015-09-21 | Novatek Microelectronics Corp | Noise estimation apparatus and method thereof |
US9686537B2 (en) * | 2013-02-05 | 2017-06-20 | Google Inc. | Noise models for image processing |
TWI511559B (en) * | 2013-02-07 | 2015-12-01 | Altek Semiconductor Corp | Image processing method |
US9159121B2 (en) * | 2014-02-18 | 2015-10-13 | Signal Processing, Inc. | Method for image denoising |
US20170178309A1 (en) | 2014-05-15 | 2017-06-22 | Wrnch Inc. | Methods and systems for the estimation of different types of noise in image and video signals |
US9852353B2 (en) * | 2014-11-12 | 2017-12-26 | Adobe Systems Incorporated | Structure aware image denoising and noise variance estimation |
CN104717402B (en) * | 2015-04-01 | 2017-12-01 | 中国科学院自动化研究所 | A kind of Space-time domain combines noise estimating system |
CN104796583B (en) * | 2015-05-14 | 2017-11-21 | 上海兆芯集成电路有限公司 | Camera noise model produces and application method and the device using this method |
US20160343113A1 (en) * | 2015-05-18 | 2016-11-24 | Sharp Laboratories Of America, Inc. | System for enhanced images |
CN105208376B (en) * | 2015-08-28 | 2017-09-12 | 青岛中星微电子有限公司 | A kind of digital noise reduction method and apparatus |
CN106251318B (en) * | 2016-09-29 | 2023-05-23 | 杭州雄迈集成电路技术股份有限公司 | Denoising device and method for sequence image |
-
2017
- 2017-05-31 US US15/609,826 patent/US10674045B2/en active Active
-
2018
- 2018-03-09 KR KR1020187018635A patent/KR102099030B1/en active IP Right Grant
- 2018-03-09 WO PCT/US2018/021840 patent/WO2018222240A1/en active Application Filing
- 2018-03-09 CN CN201880000736.5A patent/CN109328372B/en active Active
- 2018-03-09 JP JP2018533940A patent/JP6616008B2/en active Active
- 2018-03-09 EP EP18713114.9A patent/EP3631752B1/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5500685A (en) * | 1993-10-15 | 1996-03-19 | Avt Communications Limited | Wiener filter for filtering noise from a video signal |
US20120019667A1 (en) * | 2010-07-26 | 2012-01-26 | Sony Corporation | Method and device for adaptive noise measurement of a video signal |
WO2016185708A1 (en) * | 2015-05-18 | 2016-11-24 | 日本電気株式会社 | Image processing device, image processing method, and storage medium |
Non-Patent Citations (1)
Title |
---|
Mohammed Ghazal ET AL:"A Real-Time Technique for Spatio-Temporal Video Noise Estimation", IEEE Transactions on Circuits and Systems for Video Technology, Volume: 17, Dec. 2007(2007.12.31.) 1부.* * |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20210141697A (en) * | 2019-07-29 | 2021-11-23 | 지티이 코포레이션 | Video denoising method, device and computer readable storage medium |
Also Published As
Publication number | Publication date |
---|---|
CN109328372B (en) | 2022-09-23 |
EP3631752B1 (en) | 2022-01-05 |
JP6616008B2 (en) | 2019-12-04 |
EP3631752A1 (en) | 2020-04-08 |
CN109328372A (en) | 2019-02-12 |
WO2018222240A1 (en) | 2018-12-06 |
US10674045B2 (en) | 2020-06-02 |
JP2019524000A (en) | 2019-08-29 |
US20180352118A1 (en) | 2018-12-06 |
KR102099030B1 (en) | 2020-04-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP3533232B1 (en) | Bitrate optimization for multi-representation encoding using playback statistics | |
EP3542537B1 (en) | Leveraging aggregated network statistics for enhancing quality and user experience for live video streaming from mobile devices | |
KR102316968B1 (en) | Complexity Adaptive Single-Pass to 2-Pass Transcoding | |
Poddar et al. | Non‐parametric modified histogram equalisation for contrast enhancement | |
CN109844736B (en) | Summarizing video content | |
CN109308469B (en) | Method and apparatus for generating information | |
JP7451716B2 (en) | Optimal format selection for video players based on expected visual quality | |
CN108595448B (en) | Information pushing method and device | |
CN105100164A (en) | Network service recommendation method and device | |
KR102099030B1 (en) | Mutual noise estimation for video | |
CN111523400A (en) | Video representative frame extraction method and device | |
US11838600B2 (en) | System and method for modelling access requests to multi-channel content sharing platforms | |
WO2016014105A1 (en) | Systems and methods for selecting ink colors | |
CN108804435B (en) | Method and apparatus for determining current screen heat value | |
KR102663852B1 (en) | Optimal format selection for video players based on predicted visual quality using machine learning | |
US20230020043A1 (en) | Method for identifying new audiences for content of a content provider | |
CN114205642B (en) | Video image processing method and device | |
Jia et al. | Efficient video quality assessment via 3D-gradient similarity deviation | |
KR20240065323A (en) | Optimal format selection for video players based on predicted visual quality using machine learning | |
CN116932789A (en) | Content search method, device, terminal, storage medium, and program product | |
CN116416483A (en) | Computer-implemented method, apparatus, and computer program product | |
CN114885073A (en) | Video denoising method and device, storage medium and electronic equipment | |
CN115222622A (en) | Image processing method, image processing device, electronic equipment and computer readable storage medium | |
Kato et al. | Upgradation of Ultralow‐Gradation Images by Using Spatial Features | |
Phan | Semi-automatic depth map generation in unconstrained images and video sequences for 2d to stereoscopic 3d conversion |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A201 | Request for examination | ||
E902 | Notification of reason for refusal | ||
E701 | Decision to grant or registration of patent right | ||
GRNT | Written decision to grant |