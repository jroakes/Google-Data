US7299173B2 - Method and apparatus for speech detection using time-frequency variance - Google Patents
Method and apparatus for speech detection using time-frequency variance Download PDFInfo
- Publication number
- US7299173B2 US7299173B2 US10/060,511 US6051102A US7299173B2 US 7299173 B2 US7299173 B2 US 7299173B2 US 6051102 A US6051102 A US 6051102A US 7299173 B2 US7299173 B2 US 7299173B2
- Authority
- US
- United States
- Prior art keywords
- speech
- power
- band
- sub
- frequency
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active - Reinstated, expires
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/78—Detection of presence or absence of voice signals
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/03—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 characterised by the type of extracted parameters
- G10L25/18—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 characterised by the type of extracted parameters the extracted parameters being spectral information of each sub-band
Definitions
- the present invention relates to speech detection and, more particularly, relates to improved approaches to efficiently detect speech presence in a noisy environment by way of frequency and temporal considerations.
- automatic speech recognition needs to be activated by uttering a particular word sequence such as keywords.
- a particular word sequence such as keywords.
- keywords For example, if a desktop personal computer has a speech recognizer for dictation or command control, it is desirable to activate the recognizer in the middle of the conversations in his or her office by uttering a keyword. This process of recognizing the keyword from continuous speech waveform is called keyword scanning. This would require the recognizer constantly recognizing the incoming speech and spotting those keywords. Nevertheless, the recognizer cannot be used to constantly monitor the incoming speech because it takes huge computational resources. Some other techniques that demand much less computations and memories have to be utilized to reduce the burden of speech recognizer.
- Speech detection techniques are ways of eliminating silence segments from speech utterances so that speech recognizer can be speed up and do not wasting a lot of time on those silences or even misrecognize silence as speech.
- Speech detection techniques are often based on the speech waveform and utilize features such as short-time energy, zero crossing and etc. The same can be used to hypothesize keyword if some other features such as pitch, duration and voicing can be used in junction with word end-pointing techniques.
- the keyword hypothesis will be over generated, it still can reduce a large proportion of computations since the recognizer will only process these hypotheses.
- Accurate speech presence detection also conserves power and processing time for portable electronic devices such as cellular telephones.
- a speech recognition algorithm must find the utterances to determine if they are in fact language. This places a burden on computational complexity of processors and is a resource drain on portable electronic devices.
- a speech detection approach having computational efficiency as well as accuracy is needed.
- the inventors of the present invention have discovered that there is a high variance associated with voiced speech such as vowels and the low variance associated with silences and wide-band noise. Speech presence can be efficiently detected in a noisy environment by way of frequency and temporal considerations using this variance.
- Speech presence is detected by first bandpass filtering the speech to split it into banks of sub-bands.
- a matrix of shift registers secondly store each sub-band of speech.
- a power determining circuit determines individual power measurements of the speech stored in each shift register element.
- a combining circuit combines the individual power measurements to provide a variance for the individual shift registers.
- a comparator circuit finally compares the variance with at least one threshold to indicate whether speech is detected.
- the present invention can be implemented by software in a microprocessor, digital signal processor or combinations with discrete components.
- FIG. 1 illustrates a schematic block diagram of a time-frequency matrix and variance circuit for speech detection according to the present invention
- FIG. 2 illustrates a detailed schematic block diagram of one matrix element of FIG. 1 for determining power measurements used in the speech detection according to the present invention
- FIG. 3 illustrates a flow chart diagram for performing time-frequency matrix to detect speech according to the present invention.
- FIG. 1 illustrates a schematic block diagram of the time-frequency matrix and variance circuit for speech detection according to the present invention.
- a microphone 110 gathers speech often in a noisy environment.
- amplifier and analog to digital converter 120 amplifies and conditions the electrical speech signal received by the microphone 110 and converts the electrical speech signal to digital speech sampled in time.
- the digital speech is sampled at preferably an 8 kHz sampling frequency and stored in frames preferably having a 10 millisecond duration.
- a preemphasis circuit 130 operates on the digital speech to equalize its power spectrum to make its frequency spectrum more flat.
- a digital signal processing emphasis of 1-0.9 Z ⁇ 1 is preferred to equalize the input signal and derive a preemphasized output signal.
- Low band bandpass filter 141 , mid band bandpass filter 143 and high band bandpass filter 145 split the preemphasized digital speech signal into a bank of preferably three sub-bands. Although a bank of three sub-bands is preferred, two or more sub-bands will work depending on the level of processing power and degree of detection accuracy needed for a noisy environment. It is preferred that the bandpass filters 141 , 143 and 145 divide the speech signal into somewhat equal sub-bands between 100 Hz and 3,000 Hz as follows.
- the low band bandpass filter 141 preferably has a band between 100 Hz and 1267 Hz
- the mid and bandpass filter 143 preferably has a bandpass between 1267 Hz and 2433 Hz.
- the high band bandpass filter 145 preferably has a bandpass between 2433 Hz and 3600 Hz. Different band widths can be used for each sub-band.
- a matrix of shift registers 150 receives the three sub-bands from the bandpass filters 141 , 143 and 145 .
- the shift registers 150 store each of the sub-bands and shifted to a next register location for each frame.
- a total of three frames are stored in the shift registers, thus creating a three-by-three matrix Y ij consisting of matrix elements Y 11 , Y 12 , Y 13 , Y 21 , Y 22 , Y 23 , Y 31 , Y 32 and Y 33 .
- This matrix stores the speech information by way of both frequency and temporal considerations.
- Each of the three-by-three matrix elements contains sub-registers 250 for storing multiple samples k within a frame.
- a power measurement X ij is derived from the contents of the sub-registers.
- the calculation of the power measurements X ij for each sub-band over a frame i within a preferred 10 ms frame duration is performed by
- the calculations of the power measurements X ij are preferably calculated within each of the matrix elements Y ij of the shift register 150 .
- the power measurement calculation sums the squares of each of the power samples for a particular sub-band over time. More detail for the preferred calculation of the power measurement for a sub-band across a number of samples in the shift register elements will later be described with reference to FIG. 2 in more detail.
- a variance combining circuit 160 can be performed calculations of the power measurements.
- a variance is a mathematical relationship known in digital speech processing as defined in elementary digital signal processing textbooks as such as Digital Communications , equations 1.1.65 or 1.1.66, by Proakis on page 17, published in 1989.
- the present invention applies a variance to a time-frequency power measurement to detect speech presence.
- a variance combining circuit 160 calculates the variance of the plurality of power measurements for each sub-band and each frame. Calculating the variance VAR of the plurality of power measurements X ij for each sub-band j for each frame index i is calculated by
- VAR ⁇ X ij 2 n - ( ⁇ X ij n ) 2 ( 2 )
- a comparator 170 compares the variance VAR with a threshold to determine whether or not the presence of speech is detected. When the variance is above the threshold, the presence of speech is detected, and a speech detection indication signal 180 is output.
- the threshold is preferably a fixed level however a variable threshold under certain conditions will yield more favorable results.
- a variable threshold can depend on determined by using an average of the past history of non-speech frames. Further, multiple thresholds can be implemented, one for clearly speech, one for clearly unspeech. A decision is made upon a transition over either of these thresholds.
- the presence of speech indicated by the speech detection indication signal 180 can be used to gate on and off a speech recognition unit.
- the detection of the presence of speech is useful to gate and off a speech recognition unit so that the speech recognition unit does not need to operate continuously. This saves processing time that can be used for other purposes and/or conserves power, which reduces battery consumption in a portable electronic device.
- battery savings are achieved by freeing up the processor for other functions when speech presence is accurately determined.
- the speech presence detection circuit does not require full activation of a recognition code so its more efficient. Reduction of miss-recognition is also achieved when using better speech presence accuracy.
- the speech detection indications are also useful for other devices such as speaker phones.
- FIG. 2 illustrates a detailed schematic block diagram of the preferred construction of a plurality of sub-registers 250 and a power calculation circuit 259 for determining power measurements used in the speech detection according to the present invention.
- the preferred calculation of the power measurement for a sub-band, across a number of samples in one matrix element, is illustrated.
- the a plurality of sub-registers 250 and a power calculation circuit 259 are within one of the nine three-by-three matrix elements Y ij illustrated in FIG. 1 .
- a plurality 250 of sub-register elements 251 , 252 , 253 through 255 receive the filtered sub-band speech from a bandpass filter of FIG. 1 .
- Each sub-register element contains a speech sample S ijk for a given time and frequency sub-band.
- Sub-register element 252 corresponds to a second sample index and sub-register element 253 corresponds to a third sample index.
- a total of up to n sample indexes k are possible.
- a power calculation circuit 259 calculates the average power among the sub-register elements for the given frame i and sub-band j.
- the average power X ij is calculated using the above equation (1).
- Each power calculation circuit 259 corresponds to one of the shift register elements in the matrix of FIG. 1 .
- the output of the power calculation circuit 259 connects to the variance combining circuit 160 of FIG. 1 .
- FIG. 3 illustrates a flow chart diagram for performing time-frequency matrix to detect speech according to the present invention.
- speech is received, often in a noisy environment.
- the received speech is preemphasized to improve recognition accuracy by equalizing the power spectrum of the speech signal to flatten its frequency spectrum.
- step 330 to the speech is bandpass filtered into sub-bands.
- a power calculation is made in step 340 for the various samples over the various sub-bands.
- a power calculation is made in step 342 over the samples for the various sub-bands after delaying one frame in step 341 .
- a power calculation is made in step 344 over the samples for the various sub-bands after delaying to frames in step 343 .
- a variance is calculated using the power calculations derived above over frequency and over time. This variance is compared in step 360 with at least one threshold 370 to indicate that speech presence is detected at output 380 when the variance is above the threshold.
- DSPs digital signal processors
- other microprocessors such techniques could instead be implemented wholly or partially as discrete components.
- certain well known digital processing techniques are mathematically equivalent to one another and can be represented in different ways depending on the choice of implementation. For example the square of the terms in the variance calculation and/or power calculation can be substituted for absolute values without affecting the results.
Abstract
Description
-
- wherein i is the frame index;
- wherein j is a frequency sub-band index;
- wherein k is the sample index within a frame; and
- wherein Sijk is the speech samples for a given frame index i, a given frequency sub-band j and a given sample index k.
-
- wherein i is the frame index;
- wherein j is a frequency sub-band index;
- wherein Xij is the power for a given time sample index i and a given frequency sub-band j.
Claims (10)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/060,511 US7299173B2 (en) | 2002-01-30 | 2002-01-30 | Method and apparatus for speech detection using time-frequency variance |
PCT/US2002/040533 WO2003065352A1 (en) | 2002-01-30 | 2002-12-18 | Method and apparatus for speech detection using time-frequency variance |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/060,511 US7299173B2 (en) | 2002-01-30 | 2002-01-30 | Method and apparatus for speech detection using time-frequency variance |
Publications (2)
Publication Number | Publication Date |
---|---|
US20030144840A1 US20030144840A1 (en) | 2003-07-31 |
US7299173B2 true US7299173B2 (en) | 2007-11-20 |
Family
ID=27610002
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US10/060,511 Active - Reinstated 2024-11-19 US7299173B2 (en) | 2002-01-30 | 2002-01-30 | Method and apparatus for speech detection using time-frequency variance |
Country Status (2)
Country | Link |
---|---|
US (1) | US7299173B2 (en) |
WO (1) | WO2003065352A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110145001A1 (en) * | 2009-12-10 | 2011-06-16 | At&T Intellectual Property I, L.P. | Automated detection and filtering of audio advertisements |
Families Citing this family (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7302017B2 (en) * | 2002-06-18 | 2007-11-27 | General Dynamics C4 Systems, Inc. | System and method for adaptive matched filter signal parameter measurement |
US20050119881A1 (en) * | 2003-12-02 | 2005-06-02 | Seidman James L. | Method for automatic gain control of encoded digital audio streams |
DE102004049347A1 (en) * | 2004-10-08 | 2006-04-20 | Micronas Gmbh | Circuit arrangement or method for speech-containing audio signals |
EP1903833A1 (en) * | 2006-09-21 | 2008-03-26 | Phonic Ear Incorporated | Feedback cancellation in a sound system |
US20080085013A1 (en) * | 2006-09-21 | 2008-04-10 | Phonic Ear Inc. | Feedback cancellation in a sound system |
US20080107277A1 (en) * | 2006-10-12 | 2008-05-08 | Phonic Ear Inc. | Classroom sound amplification system |
US20080170712A1 (en) * | 2007-01-16 | 2008-07-17 | Phonic Ear Inc. | Sound amplification system |
US8886523B2 (en) * | 2010-04-14 | 2014-11-11 | Huawei Technologies Co., Ltd. | Audio decoding based on audio class with control code for post-processing modes |
FR2997250A1 (en) * | 2012-10-23 | 2014-04-25 | France Telecom | DETECTING A PREDETERMINED FREQUENCY BAND IN AUDIO CODE CONTENT BY SUB-BANDS ACCORDING TO PULSE MODULATION TYPE CODING |
CN106571146B (en) | 2015-10-13 | 2019-10-15 | 阿里巴巴集团控股有限公司 | Noise signal determines method, speech de-noising method and device |
US9978392B2 (en) * | 2016-09-09 | 2018-05-22 | Tata Consultancy Services Limited | Noisy signal identification from non-stationary audio signals |
CN113362813A (en) * | 2021-06-30 | 2021-09-07 | 北京搜狗科技发展有限公司 | Voice recognition method and device and electronic equipment |
Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4222115A (en) * | 1978-03-13 | 1980-09-09 | Purdue Research Foundation | Spread spectrum apparatus for cellular mobile communication systems |
US4461024A (en) | 1980-12-09 | 1984-07-17 | The Secretary Of State For Industry In Her Britannic Majesty's Government Of The United Kingdom Of Great Britain And Northern Ireland | Input device for computer speech recognition system |
US4827519A (en) * | 1985-09-19 | 1989-05-02 | Ricoh Company, Ltd. | Voice recognition system using voice power patterns |
US5097510A (en) * | 1989-11-07 | 1992-03-17 | Gs Systems, Inc. | Artificial intelligence pattern-recognition-based noise reduction system for speech processing |
WO1996002911A1 (en) | 1992-10-05 | 1996-02-01 | Matsushita Electric Industrial Co., Ltd. | Speech detection device |
US5617508A (en) | 1992-10-05 | 1997-04-01 | Panasonic Technologies Inc. | Speech detection device for the detection of speech end points based on variance of frequency band limited energy |
US5659622A (en) | 1995-11-13 | 1997-08-19 | Motorola, Inc. | Method and apparatus for suppressing noise in a communication system |
US5692104A (en) | 1992-12-31 | 1997-11-25 | Apple Computer, Inc. | Method and apparatus for detecting end points of speech activity |
US5732392A (en) * | 1995-09-25 | 1998-03-24 | Nippon Telegraph And Telephone Corporation | Method for speech detection in a high-noise environment |
US5826230A (en) * | 1994-07-18 | 1998-10-20 | Matsushita Electric Industrial Co., Ltd. | Speech detection device |
EP0945854A2 (en) | 1998-03-24 | 1999-09-29 | Matsushita Electric Industrial Co., Ltd. | Speech detection system for noisy conditions |
US5963901A (en) * | 1995-12-12 | 1999-10-05 | Nokia Mobile Phones Ltd. | Method and device for voice activity detection and a communication device |
US5991718A (en) | 1998-02-27 | 1999-11-23 | At&T Corp. | System and method for noise threshold adaptation for voice activity detection in nonstationary noise environments |
WO2001011606A1 (en) | 1999-08-04 | 2001-02-15 | Ericsson, Inc. | Voice activity detection in noisy speech signal |
US6278972B1 (en) * | 1999-01-04 | 2001-08-21 | Qualcomm Incorporated | System and method for segmentation and recognition of speech signals |
US6397050B1 (en) * | 1999-04-12 | 2002-05-28 | Rockwell Collins, Inc. | Multiband squelch method and apparatus |
US6591234B1 (en) * | 1999-01-07 | 2003-07-08 | Tellabs Operations, Inc. | Method and apparatus for adaptively suppressing noise |
US6711536B2 (en) * | 1998-10-20 | 2004-03-23 | Canon Kabushiki Kaisha | Speech processing apparatus and method |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4860360A (en) * | 1987-04-06 | 1989-08-22 | Gte Laboratories Incorporated | Method of evaluating speech |
US5323337A (en) * | 1992-08-04 | 1994-06-21 | Loral Aerospace Corp. | Signal detector employing mean energy and variance of energy content comparison for noise detection |
-
2002
- 2002-01-30 US US10/060,511 patent/US7299173B2/en active Active - Reinstated
- 2002-12-18 WO PCT/US2002/040533 patent/WO2003065352A1/en not_active Application Discontinuation
Patent Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4222115A (en) * | 1978-03-13 | 1980-09-09 | Purdue Research Foundation | Spread spectrum apparatus for cellular mobile communication systems |
US4461024A (en) | 1980-12-09 | 1984-07-17 | The Secretary Of State For Industry In Her Britannic Majesty's Government Of The United Kingdom Of Great Britain And Northern Ireland | Input device for computer speech recognition system |
US4827519A (en) * | 1985-09-19 | 1989-05-02 | Ricoh Company, Ltd. | Voice recognition system using voice power patterns |
US5097510A (en) * | 1989-11-07 | 1992-03-17 | Gs Systems, Inc. | Artificial intelligence pattern-recognition-based noise reduction system for speech processing |
WO1996002911A1 (en) | 1992-10-05 | 1996-02-01 | Matsushita Electric Industrial Co., Ltd. | Speech detection device |
US5617508A (en) | 1992-10-05 | 1997-04-01 | Panasonic Technologies Inc. | Speech detection device for the detection of speech end points based on variance of frequency band limited energy |
US5692104A (en) | 1992-12-31 | 1997-11-25 | Apple Computer, Inc. | Method and apparatus for detecting end points of speech activity |
US5826230A (en) * | 1994-07-18 | 1998-10-20 | Matsushita Electric Industrial Co., Ltd. | Speech detection device |
US5732392A (en) * | 1995-09-25 | 1998-03-24 | Nippon Telegraph And Telephone Corporation | Method for speech detection in a high-noise environment |
US5659622A (en) | 1995-11-13 | 1997-08-19 | Motorola, Inc. | Method and apparatus for suppressing noise in a communication system |
US5963901A (en) * | 1995-12-12 | 1999-10-05 | Nokia Mobile Phones Ltd. | Method and device for voice activity detection and a communication device |
US5991718A (en) | 1998-02-27 | 1999-11-23 | At&T Corp. | System and method for noise threshold adaptation for voice activity detection in nonstationary noise environments |
EP0945854A2 (en) | 1998-03-24 | 1999-09-29 | Matsushita Electric Industrial Co., Ltd. | Speech detection system for noisy conditions |
US6711536B2 (en) * | 1998-10-20 | 2004-03-23 | Canon Kabushiki Kaisha | Speech processing apparatus and method |
US6278972B1 (en) * | 1999-01-04 | 2001-08-21 | Qualcomm Incorporated | System and method for segmentation and recognition of speech signals |
US6591234B1 (en) * | 1999-01-07 | 2003-07-08 | Tellabs Operations, Inc. | Method and apparatus for adaptively suppressing noise |
US6397050B1 (en) * | 1999-04-12 | 2002-05-28 | Rockwell Collins, Inc. | Multiband squelch method and apparatus |
WO2001011606A1 (en) | 1999-08-04 | 2001-02-15 | Ericsson, Inc. | Voice activity detection in noisy speech signal |
Non-Patent Citations (1)
Title |
---|
John G. Proakis; "1.1.3 Statistical Averages of Random Variables"; Digital Communications, Second Edition; 1989; McGraw-Hill, Inc., pp. 17. |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110145001A1 (en) * | 2009-12-10 | 2011-06-16 | At&T Intellectual Property I, L.P. | Automated detection and filtering of audio advertisements |
US8457771B2 (en) * | 2009-12-10 | 2013-06-04 | At&T Intellectual Property I, L.P. | Automated detection and filtering of audio advertisements |
US20130268103A1 (en) * | 2009-12-10 | 2013-10-10 | At&T Intellectual Property I, L.P. | Automated detection and filtering of audio advertisements |
US9183177B2 (en) * | 2009-12-10 | 2015-11-10 | At&T Intellectual Property I, L.P. | Automated detection and filtering of audio advertisements |
US20160085858A1 (en) * | 2009-12-10 | 2016-03-24 | At&T Intellectual Property I, L.P. | Automated detection and filtering of audio advertisements |
US9703865B2 (en) * | 2009-12-10 | 2017-07-11 | At&T Intellectual Property I, L.P. | Automated detection and filtering of audio advertisements |
US10146868B2 (en) * | 2009-12-10 | 2018-12-04 | At&T Intellectual Property I, L.P. | Automated detection and filtering of audio advertisements |
Also Published As
Publication number | Publication date |
---|---|
US20030144840A1 (en) | 2003-07-31 |
WO2003065352A1 (en) | 2003-08-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN108198547B (en) | Voice endpoint detection method and device, computer equipment and storage medium | |
EP2089877B1 (en) | Voice activity detection system and method | |
KR100312919B1 (en) | Method and apparatus for speaker recognition | |
US7756700B2 (en) | Perceptual harmonic cepstral coefficients as the front-end for speech recognition | |
US8140330B2 (en) | System and method for detecting repeated patterns in dialog systems | |
CN102194452B (en) | Voice activity detection method in complex background noise | |
US7299173B2 (en) | Method and apparatus for speech detection using time-frequency variance | |
JPS58134698A (en) | Voice recognition method and apparatus | |
Zaw et al. | The combination of spectral entropy, zero crossing rate, short time energy and linear prediction error for voice activity detection | |
Athineos et al. | LP-TRAP: Linear predictive temporal patterns | |
Ishizuka et al. | Noise robust voice activity detection based on periodic to aperiodic component ratio | |
Mistry et al. | Overview: Speech recognition technology, mel-frequency cepstral coefficients (mfcc), artificial neural network (ann) | |
Kitaoka et al. | Development of VAD evaluation framework CENSREC-1-C and investigation of relationship between VAD and speech recognition performance | |
US8103512B2 (en) | Method and system for aligning windows to extract peak feature from a voice signal | |
JP3413862B2 (en) | Voice section detection method | |
Alam et al. | Regularized minimum variance distortionless response-based cepstral features for robust continuous speech recognition | |
Sorin et al. | The ETSI extended distributed speech recognition (DSR) standards: client side processing and tonal language recognition evaluation | |
Golipour et al. | A new approach for phoneme segmentation of speech signals. | |
JPH01255000A (en) | Apparatus and method for selectively adding noise to template to be used in voice recognition system | |
Verteletskaya et al. | Pitch detection algorithms and voiced/unvoiced classification for noisy speech | |
Saha et al. | Modified mel-frequency cepstral coefficient | |
Fan et al. | Power-normalized PLP (PNPLP) feature for robust speech recognition | |
Jing et al. | Auditory-modeling inspired methods of feature extraction for robust automatic speech recognition | |
Goh et al. | Fast wavelet-based pitch period detector for speech signals | |
KR0171004B1 (en) | Basic frequency using samdf and ratio technique of the first format frequency |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MA, CHANGXUE;RANDOLPH, MARK;REEL/FRAME:012567/0995Effective date: 20020130 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282Effective date: 20120622 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034420/0001Effective date: 20141028 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20191120 |
|
PRDP | Patent reinstated due to the acceptance of a late maintenance fee |
Effective date: 20201001 |
|
FEPP | Fee payment procedure |
Free format text: SURCHARGE, PETITION TO ACCEPT PYMT AFTER EXP, UNINTENTIONAL (ORIGINAL EVENT CODE: M1558); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYFree format text: PETITION RELATED TO MAINTENANCE FEES GRANTED (ORIGINAL EVENT CODE: PMFG); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYFree format text: PETITION RELATED TO MAINTENANCE FEES FILED (ORIGINAL EVENT CODE: PMFP); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |