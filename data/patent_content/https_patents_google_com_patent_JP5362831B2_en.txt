JP5362831B2 - Video coding system and method using configuration reference frame - Google Patents
Video coding system and method using configuration reference frame Download PDFInfo
- Publication number
- JP5362831B2 JP5362831B2 JP2011526953A JP2011526953A JP5362831B2 JP 5362831 B2 JP5362831 B2 JP 5362831B2 JP 2011526953 A JP2011526953 A JP 2011526953A JP 2011526953 A JP2011526953 A JP 2011526953A JP 5362831 B2 JP5362831 B2 JP 5362831B2
- Authority
- JP
- Japan
- Prior art keywords
- frame
- reference frame
- macroblock
- series
- frames
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/80—Details of filtering operations specially adapted for video compression, e.g. for pixel interpolation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/137—Motion inside a coding unit, e.g. average field, frame or block difference
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/105—Selection of the reference unit for prediction within a chosen coding or prediction mode, e.g. adaptive choice of position and number of pixels used for prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/107—Selection of coding mode or of prediction mode between spatial and temporal predictive coding, e.g. picture refresh
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/117—Filters, e.g. for pre-processing or post-processing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/127—Prioritisation of hardware or computational resources
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/137—Motion inside a coding unit, e.g. average field, frame or block difference
- H04N19/139—Analysis of motion vectors, e.g. their magnitude, direction, variance or reliability
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/172—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a picture, frame or field
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/179—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being a scene or a shot
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/20—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video object coding
- H04N19/23—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video object coding with coding of regions that are present throughout a whole video segment, e.g. sprites, background or mosaic
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/527—Global motion vector estimation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/60—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding
- H04N19/61—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding in combination with predictive coding
Description
関連出願の相互参照
本出願は、２００８年９月１１日に出願された米国仮特許出願第６１／０９６，１８９号の優先権を主張している、２００８年１２月５日に出願された米国特許出願第１２／３２９，０４１号の優先権を主張しており、ここで両出願の内容全体を本明細書に参照として組み入れる。
CROSS REFERENCE TO RELATED APPLICATIONS This application claims the priority of US Provisional Patent Application No. 61 / 096,189, filed on Sep. 11, 2008, filed on Dec. 5, 2008. No. 12 / 329,041 is claimed and the entire contents of both applications are hereby incorporated herein by reference.
本発明は、一般に動画符号化と復号化に関する。 The present invention generally relates to video encoding and decoding.
今日の増加しつつある多数のアプリケーションでは、例えば、テレビ会議による遠隔会議、高精細動画エンターテイメント、動画広告、およびユーザー生成動画の共有を含む様々な目的のためにデジタル動画を利用している。技術の進歩につれて、たとえ限られた帯域幅の通信チャネルを介して送信されても、人々は動画品質と高解像度動画に大きな期待を抱いている。 A growing number of applications today use digital video for a variety of purposes including, for example, teleconferencing via video conferencing, high definition video entertainment, video advertising, and sharing of user generated video. As technology advances, people have great expectations for video quality and high-resolution video, even if transmitted over a limited bandwidth communication channel.
帯域幅消費を制限しながら、高品質の動画送信を可能にするために、現在および将来のバージョンを含む、ＶＰｘ（ニューヨーク市、クリフトンパーク、Ｏｎ２ Ｔｅｃｈｎｏｌｏｇｉｅｓ社により普及された），ＩＴＵ−Ｔ ＶＣＥＧ（Ｖｉｄｅｏ Ｃｏｄｉｎｇ
Ｅｘｐｅｒｔｓ Ｇｒｏｕｐ：ＩＴＵ−Ｔ動画符号化専門家グループ）およびＩＳＯ／ＩＥＣ ＭＰＥＧ（Ｍｏｖｉｎｇ Ｐｉｃｔｕｒｅ Ｅｘｐｅｒｔｓ Ｇｒｏｕｐ：ＩＳＯ／ＩＥＣ動画像専門家グループによって普及された）標準であるＨ．２６４などの、独自仕様フォーマットを含む多数の動画圧縮方式が知られている。Ｈ．２６４は、ＭＰＥＧ−４ Ｐａｒｔ１０またはＭＰＥＧ−４ ＡＶＣ（正式には、ＩＳＯ／ＩＥＣ １４４９６−１０）としても知られている。
VPx (populated by On2 Technologies, New York City, Clifton Park), ITU-T VCEG, including current and future versions, to enable high quality video transmission while limiting bandwidth consumption Video Coding
Experts Group: ITU-T Video Coding Expert Group) and ISO / IEC MPEG (moving Picture Experts Group: popularized by ISO / IEC Video Expert Group) standards. A number of video compression schemes including proprietary formats such as H.264 are known. H. H.264 is also known as MPEG-4
これらの圧縮方式は、動画情報を送信するのに必要なデータ量を最小限に抑える予測技術を用いることができる。予測技術により、複数の過去に送信されたフレームおよびこれから送信するフレームを順不同に送信し、フレーム中のマクロブロックの潜在的参照フレーム予測子（potential reference frame predictors）として用いるのを考慮することができる。例えば、ＭＰＥＧ標準やＨ．２６４標準などの動画圧縮方式により、フレームを順不同に送信し、前方向予測または双方向予測を用いて、より良い予測子を生成することができる。また、例えば、Ｈ．２６４動画圧縮標準では、複数の過去の参照フレームを予測子として用いることができる。 These compression methods can use a prediction technique that minimizes the amount of data required to transmit moving image information. Prediction techniques allow for considering multiple previously transmitted frames and frames to be transmitted out of order and using them as potential reference frame predictors for macroblocks in the frame . For example, MPEG standards and H.264 standards. By using a moving picture compression method such as the H.264 standard, frames can be transmitted out of order, and a better predictor can be generated using forward prediction or bidirectional prediction. Also, for example, H. In the H.264 video compression standard, a plurality of past reference frames can be used as predictors.
本発明の実施形態は、後続フレームの予測に用いる参照バッファを満たすのに用いられるビットストリーム情報の範囲内で送信する能力を備えている。この情報は、その後表示されない構成参照フレーム（constructed reference frame）に対応する。 Embodiments of the present invention have the ability to transmit within the bitstream information used to fill the reference buffer used to predict subsequent frames. This information corresponds to a constructed reference frame that is not subsequently displayed.
本発明の一実施形態は、一連の原動画フレームから取得される一連のデジタル動画フレームを表示する方法である。本実施形態によれば、この方法は、エンコーダを用いて構成参照フレームを生成することと、構成参照フレームを用いて一連の原動画フレームを圧縮して、後続する復号処理のための圧縮デジタル動画信号を含むビットストリームを取得することとを含む。構成参照フレームは復号されるが、後続する表示処理の間に、一連のデジタル動画フレームから除去される。 One embodiment of the present invention is a method for displaying a series of digital video frames obtained from a series of original video frames. According to this embodiment, the method includes generating a configuration reference frame using an encoder, compressing a series of original video frames using the configuration reference frame, and a compressed digital video for subsequent decoding processing. Obtaining a bitstream including the signal. The configuration reference frame is decoded but removed from the series of digital video frames during subsequent display processing.
一連のデジタル動画フレームから構成参照フレームを抽出する方法を含む、本発明のこれらおよびその他の実施形態を以下にさらに詳しく説明する。 These and other embodiments of the present invention are described in further detail below, including methods for extracting composition reference frames from a series of digital video frames.
ここでは、添付図面を参照して説明を行い、複数の図面にわたり、同一参照符号は同一部位を示す。 Here, description will be made with reference to the accompanying drawings, and the same reference numerals denote the same parts throughout the drawings.
図１について説明する。ＶＰ８やＨ．２６４などの動画符号化フォーマットは、動画ストリーム１１の一定のレイヤ階層を規定している。レイヤの最上位レベルは、動画シーケンス１３である。次のレベルにおいて、動画シーケンス１３は、単一のフレーム１７にさらに再分割可能な多数の隣接フレーム１５から構成されている。次のレベルにおいて、フレーム１７は、一連の固定サイズマクロブロックから構成され、例えば、フレーム１７の表示画素の１６×１６ブロックに対応する圧縮データを含んでいる。各マクロブロックは、対応する画素の輝度(luminance)データと色(chrominance)データを含んでいる。マクロブロック２０は、１６×８画素群または８×１６画素群などの任意の他の適切なサイズからも構成できる。マクロブロック２０は、ブロックにさらに再分割される。例えば、１ブロックは、４×４画素群であり、この画素群は、対応する画素の輝度データと色データをさらに記述できる。また、ブロックは、８×８、８×４、および４×８画素などの任意の他の適切なサイズからも構成できる。
With reference to FIG. VP8 and H. A moving image encoding format such as H.264 defines a certain layer hierarchy of the moving
図２について説明する。一実施形態によれば、入力動画ストリーム１６を符号化するには、エンコーダ１４が、前方向パス（実線で示す）の以下の機能、すなわち、イントラ／インター予測１８、変換１９、量子化２２、およびエントロピー符号化２４を実行して、符号化ビットストリーム２６を生成する。エンコーダ１４は、再構成パス（点線で示す）も有し、フレームを再構成して、さらなるマクロブロックを符号化する。エンコーダ１４は、再構成パスの以下の機能、すなわち、逆量子化２８、逆変換３０、再構成３２、およびループフィルタ処理３４を実行する。エンコーダ１４のその他の構造的変形を用いて、ビットストリーム２６を符号化できる。
With reference to FIG. According to one embodiment, to encode the
入力動画ストリーム１６を符号化するとき、入力動画ストリーム１６中の各フレーム１７は、マクロブロック単位で処理される。イントラ／インター予測ステージ１８で、イントラ予測モードまたはインター予測モードのいずれかを用いて、各マクロブロックが符号化される。いずれにしても、再構成フレームに基づいて、予測マクロブロックを形成できる。イントラ予測の場合、予測マクロブロックは、予め符号化され、再構成されている現フレームのサンプルから予測マクロブロックが形成される。一方、インター予測の場合、ここでさらに詳述するように、予測マクロブロックは、１つ以上の構成参照フレームから形成される。
When the input moving
次に、図２についてさらに説明する。予測マクロブロックが、現マクロブロックから引かれ、残差(residual)マクロブロック（残差）を生成する。変換ステージ１９で、残差を変換符号化し、量子化ステージ２２で、残差を量子化して、一組の量子化変換係数を生成する。次いで、量子化変換係数は、エントロピー符号化ステージ２４で、エントロピー符号化される。エントロピー符号化係数は、用いた予測モードの種類、動きベクトル、および量子化値などの、マクロブロックを復号するのに必要な情報と一緒に、圧縮ビットストリーム２６に出力される。
Next, FIG. 2 will be further described. A predicted macroblock is subtracted from the current macroblock to generate a residual macroblock (residual). The
図２の再構成パスは、エンコーダとデコーダ双方が、マクロブロックを復号するのに必要な同じ参照フレームを確実に用いるようにする。以下に詳述する、復号処理時に実行される処理に類似する再構成パスは、逆量子化ステージ２８で、変換された係数を逆量子化することと、逆変換ステージ３０で、この係数を逆変換して、微分残差マクロブロック(derivative residual macroblock)（微分残差）を生成することとを含む。再構成ステージ３２で、予測マクロブロックが微分残差に加えられ、再構成マクロブロックを生成する。ループフィルタ３４を再構成マクロブロックに適用して、ブロッキング歪を低減させる。
The reconstruction pass of FIG. 2 ensures that both the encoder and decoder use the same reference frame needed to decode the macroblock. The reconstruction path similar to the processing executed during the decoding process, which will be described in detail below, is to inverse-quantize the transformed coefficient at the
図３について説明する。一実施形態によれば、圧縮ビットストリーム２６を復号するには、デコーダ２１は、上述したエンコーダ１４の再構成パスと類似する、以下の処理、すなわち、エントロピー復号２５、逆量子化２７、逆変換２９、イントラ／インター予測２３、再構成３１、ループフィルタ３４、およびデブロッキングフィルタ処理３３を実行して、出力動画ストリーム３５を生成する。デコーダ２１のその他の構造上の変形を用いて、圧縮ビットストリーム２６を復号することができる。
With reference to FIG. According to one embodiment, to decode the
圧縮ビットストリーム２６を復号するとき、エントロピー復号ステージ２５（例えば、コンテキスト適応型バイナリ算術符号化(Context Adaptive Binary Arithmetic Coding)
を用いて）で、データ要素をエントロピー復号して、一組の量子化係数(quantized coefficients)を生成できる。逆量子化ステージ２７で、この係数を逆量子化し、逆変換ステージ２９で、この係数を逆変換して、エンコーダ１４の再構成ステージで生成された微分残差と同一の微分残差を生成する。イントラ／インターステージ２３で、圧縮ビットストリーム２６から復号されたヘッダ情報を用いて、デコーダ２１は、エンコーダ１４で生成されたのと同じ予測マクロブロックを生成する。また、再構成ステージ３１で、予測マクロブロックが、微分残差に加えられて、再構成マクロブロックを生成する。ループフィルタ３４を再構成マクロブロックに適用して、ブロッキングアーチファクト(artifacts：画像の乱れ)をさらに低減できる。また、デブロッキングフィルタ３３を再構成マクロブロッ
クに適用して、ブロッキング歪を低減し、出力画像ストリーム３５として、その結果が出力される。
When decoding the
The data elements can be entropy decoded to generate a set of quantized coefficients. This coefficient is inversely quantized by the
再度、エンコーダ１４について説明する。動画符号化方式は、ロスレスまたはロス圧縮アルゴリズムを用いて、動画信号を圧縮し、各フレーム、または一連のフレームの各フレームのブロックを圧縮する。上記の説明から理解できるように、イントラフレーム符号化
は、当該フレームからのデータを用いてフレームを符号化することを指し、一方、インター符号化は、他のいわゆる、「参照」フレームに基づいて、フレームを符号化することを含む方式などの予測符号化方式を指す。例えば、動画信号は、しばしば時間冗長性(temporal redundancy)を示し、ここにおいて、フレームの時間上の順序が互いに近いフレーム
が、お互いに一致または部分的に一致する部分を少なくとも有している。エンコーダは、この時間冗長性を利用して、現フレームと１つ以上の参照フレームとの間の差に関してフレームを符号化することで、符号化データのサイズを低減させることができる。
The
動画エンコーダは、符号化されているフレームのブロックを１つ以上の他のフレームの部分に一致させる、動き補償に基づくアルゴリズム(motion compensation based algorithms)を用いることができる。符号化フレームのブロックは、参照フレームの一致部分に対してフレーム中でシフトされてよい。このシフトは、動きベクトルにより特徴付けられる。ブロックと参照フレームの部分的一致部分との間の差は、残差(residual)に関して特徴付けられる。このため、エンコーダ１４は、１つ以上の動きベクトル(motion vector)と
フレームの特定分割(particular partitioning)の残差とを含むデータとしてのフレーム
を復号し得る。フレームを符号化するブロックの特定分割は、例えば、歪(distortion)がある符号化サイズを、符号化の結果として取得されたフレームの内容に対してバランスを取る費用関数(cost function)をほぼ最小化することで選択し得る。
Video encoders can use motion compensation based algorithms that match blocks of the frame being encoded to portions of one or more other frames. The block of encoded frames may be shifted in the frame relative to the matching portion of the reference frame. This shift is characterized by a motion vector. The difference between the block and the partially matching part of the reference frame is characterized with respect to the residual. Thus, the
上記に簡単に述べたように、多くの動画コーディングアルゴリズムでは、最初に、各画像をマクロブロックに分割する。そして、各マクロブロックは、例えば動き補償などの、ある形態の予測コーディング方式を用いてコード化される。いくつかの動画コーディング標準では、それらのコード化において、異なる種類の予測マクロブロックを用いる。１つのシナリオでは、マクロブロックは、以下の３種類のうちの１つである。１）そのコード化の際に、他の画像からの情報を用いないイントラ（Ｉ）マクロブロック、２）１つ先行する画像からの情報を用いる片方向予測（Ｐ）マクロブロック、３）１つ先行する画像と１つ将来の画像からの情報を用いる双方向予測（Ｂ）マクロブロック。 As mentioned briefly above, many video coding algorithms first divide each image into macroblocks. Each macroblock is then coded using some form of predictive coding scheme, such as motion compensation. Some video coding standards use different types of predictive macroblocks in their coding. In one scenario, the macroblock is one of the following three types. 1) Intra (I) macroblock that does not use information from other images during the encoding, 2) One-way prediction (P) macroblock that uses information from one preceding image, 3) One Bi-directional prediction (B) macroblock using information from the previous image and one future image.
高品質の圧縮動画の生成を容易にするには、符号化差を最小にするため、ベストマッチング参照フレーム(best matching reference frame)が役立ち、これにより、通常、符号
化がよりコンパクトになる。現在、例えば、米国出願公開第２００５／０２８６６２９号に示すように、エンコーダが、予測処理で用いるベストマッチングブロックを見つけることができるように、参照フレームは、過去のフレーム、将来のフレーム、またはイントラフレームに基づいている。しかしながら、現在用いられている参照フレームは、エンドユーザに表示される実際のフレームに基づいている。
To facilitate the generation of high quality compressed video, a best matching reference frame is useful to minimize the coding difference, which usually makes the coding more compact. Currently, the reference frame can be a past frame, a future frame, or an intra frame so that the encoder can find the best matching block to use in the prediction process, as shown, for example, in US Patent Application Publication No. 2005/0286629. Based on. However, currently used reference frames are based on actual frames displayed to the end user.
その結果、いくつかの問題が生じることになる。主要な問題は、上記の参照フレームが、最高品質の参照データを提供せず、低品質の動画圧縮になる可能性があることである。 As a result, several problems arise. The main problem is that the above reference frame does not provide the highest quality reference data and may result in low quality video compression.
対照的に、ここで説明したエンコーダ１４により生成され、用いられた参照フレームが、構成参照フレーム(constructed reference frame)であり、ビットストリームに符号化
され、その後に送信されたフレームの符号化を向上させる画像データフレームである。従来の参照フレームと異なり、構成参照フレームは、ユーザーに表示されない。ここで述べた技術の柔軟性により、構成参照フレームは、動画ストリームの生の画像フレームまたはユーザーに表示されるフレームと同じ大きささえ有し得ない。それどころか、構成参照フレームは、予測子(predictor)としての役割を果たし、過去に送信されたフレームが与え
るものよりもより良い予測選択の機会を後続のフレームに与える。構成参照フレームの生成は、ビットストリームにより定義されていない。それどころか、考えられる最良の構成参照フレームを生成することは、エンコーダに残された作業である。このように、参照フレームを構成する計算は、デコーダではなくエンコーダが行っている。
In contrast, the reference frame generated and used by the
本発明の一実施形態では、数個の現フレームデータの予測子として、１つ以上の構成参照フレームバッファを用いている。これは、動き補償予測用と、非動き補償予測(non motion compensated prediction)用のこれらのフレームバッファの使用を含む。また、典型
的な双方向予測モードのように、構成参照フレームと実際の参照フレームとを組み合わせて予測する用法も扱っている。
In one embodiment of the present invention, one or more configuration reference frame buffers are used as predictors of several current frame data. This includes the use of these frame buffers for motion compensated prediction and non motion compensated prediction. Moreover, the usage which predicts combining a structure reference frame and an actual reference frame like typical bi-directional prediction mode is also dealt with.
一般に、構成参照フレームは、多数の方法により構築され、様々に用いて、符号化することができる。特殊な例を説明する前に、先ず、構成参照フレームを構築する方法を以下に全般的に説明する。 In general, a configuration reference frame is constructed by a number of methods and can be used and encoded in various ways. Before describing a special example, first, a method for constructing a configuration reference frame will be generally described below.
構成参照フレームを生成する第１の方法によれば、当該フレームが画像フレームシーケンスに通常現れるであろう前のいつかに、既存のフレームのコピーが、ビットストリームに符号化される。ここでの符号化の関連パラメータは、参照フレームの符号化品質または「ブースト(boost)」である。構成参照フレームの信頼性が高ければ高いほど、そのフレ
ームのより有用で正確な符号化ができる。逆に、限定された予測値を持つ参照フレームは、非常に高いレベルの精度に符号化する必要はない。この第１の方法において、このフレームのコピーは、通常平均品質よりもいくらか高い品質で符号化されるが、必ずしもそうとは限られない。
According to a first method of generating a configuration reference frame, a copy of an existing frame is encoded into a bitstream sometime before the frame will normally appear in an image frame sequence. The relevant parameter for encoding here is the encoding quality or “boost” of the reference frame. The higher the reliability of the configuration reference frame, the more useful and accurate the encoding of that frame is. Conversely, a reference frame with a limited prediction value need not be encoded with a very high level of accuracy. In this first method, this copy of the frame is encoded with somewhat higher quality than normal average quality, but this is not necessarily so.
この構成参照フレームを用いて、従来の技術により他のフレームを符号化する。ビットストリーム中で、構成参照フレームの符号化に用いられる目標フレームに遭遇したとき、既存のフレームのコピー、すなわち、構成参照フレームを参照して符号化される。こうした符号化は、例えば、低品質レベルで、または構成参照フレームの符号化に用いられるより低いブーストによって行われる。 Using this configuration reference frame, another frame is encoded by a conventional technique. When a target frame used to encode a configuration reference frame is encountered in the bitstream, it is encoded with reference to a copy of the existing frame, ie, the configuration reference frame. Such encoding is performed, for example, at a low quality level or with a lower boost used to encode constituent reference frames.
構成参照フレームを生成する別の方法は、上記のように、目標フレームを選択することと、時間フィルタ処理(temporal filtering)を用いて、目標フレームの中心にあるいくつかの原フレームからの動画ノイズを除去することを含む。こうした構成参照フレームを図４に示す。時間フィルタ処理は、例えば、ここで内容全体を本明細書に参照として組み入れる米国特許第６，１７８，２０５号に記載されているような、例えば、動き補償閾値ブラーフィルタ(motion-compensated threshold blur filter)を用いて、エンコーダにより適用できる。フレームごとに異なる動画ノイズを除去することで、構成参照フレームを複数フレーム用のより一層良い予測子にし、動画ストリームのデータ圧縮を向上させる。 Another method of generating a configuration reference frame is to select a target frame and use temporal filtering as described above to detect video noise from several original frames in the center of the target frame. Removing. Such a configuration reference frame is shown in FIG. Temporal filtering may be performed, for example, as described in US Pat. No. 6,178,205, the entire contents of which are hereby incorporated by reference herein, for example, motion-compensated threshold blur filter. Can be applied by an encoder. By removing different video noise for each frame, the configuration reference frame is made a better predictor for multiple frames and data compression of the video stream is improved.
図５を参照して、さらに可能な実施形態を示す。第１に、ステップ３６で、目標参照として、フレームが選択される。そして、当該フレームの各マクロブロックに対して、以下のステップが実行される。ステップ３８で、フレームのマクロブロックが選択され、当該フレームのベストマッチングマクロブロックが、いくつかの候補フレームから見付けられる。つまり、ステップ４０で、全ての他のフレームから選択したマクロブロックに動き探索を行うことで、いくつかの候補フレームから各候補マクロブロックがテストされる。すなわち、目標参照フレームで選択されたマクロブロックに最も類似するいくつかの候補フレームの各々から候補マクロブロックが特定される。例えば、目標参照フレーム中の選択したマクロブロックに突出(nose)が存在する場合、類似画像特性を含むマクロブロックが、候補フレームから選択されるだろう。ステップ４２で、各候補マクロブロックに対してエラースコアが計算される。エラースコアは、候補マクロブロックとその他の全候補マクロブロックとの間の差の全合計を測定する。ステップ４４で、全エラースコアが最低の候補マクロブロックが、マスターとして選択される。ステップ４６で、マスターが構成参照フレームにコピーされる。目標参照フレームの各マクロブロックに対してステップ３８〜４８が実行され、ステップ４８の後のステップ５０で、何等かの残りのマクロブロックが
存在するか否か問い合わせる。マクロブロックが存在しなければ、処理が終了する。そうでなければ、ステップ３８に処理が戻り、目標参照フレームの次のマクロブロックに対して、ステップ３８〜４８を繰り返し実行する。マクロブロックを参照して、この方法を説明したが、画素の任意のサイズのブロックを用いることができる。
With reference to FIG. 5, a further possible embodiment is shown. First, at
構成参照フレームを生成する第３の方法は、背景抽出(background extraction)および
／または動き分割(motion segmentation)を用いて、符号化する高品質の背景フレームの
みを生成することである。背景からの抽出と動き分割の各種技術は、従来において公知である。一般に、大きな動きベクトル（つまり、高速で移動している）を有するブロックが、前景(foreground)であると考えられ、構成参照フレームにコピーされない。これに対して、（０．０）動きベクトルまたは他の小さな動きベクトル（つまり、低速で移動している）が、背景であると考えられ、構成参照フレームにコピーされる。
A third method of generating the configuration reference frame is to generate only high quality background frames to encode using background extraction and / or motion segmentation. Various techniques for background extraction and motion division are known in the art. In general, blocks with large motion vectors (ie, moving at high speed) are considered to be the foreground and are not copied to the constituent reference frames. In contrast, (0.0) motion vectors or other small motion vectors (ie moving slowly) are considered background and are copied to the constituent reference frames.
もちろん、この方法は、高品質の背景フレームのみを生成することを記述しているが、符号化された構成フレームの数について理論上は制限がない。従って、前景と背景を分離した構成参照フレームにセグメント化することも可能である。 Of course, this method describes generating only high-quality background frames, but there is no theoretical limit on the number of encoded constituent frames. Therefore, it is also possible to segment into a configuration reference frame in which the foreground and the background are separated.
上述しなかったが、記載したように参照フレームの使用を容易にするために、構成参照フレームで用いるアルファチャンネルの符号化が、望ましいかもしれない。 Although not described above, encoding the alpha channel used in the constituent reference frame may be desirable to facilitate the use of the reference frame as described.
構成参照フレームを生成する別の方法は、画像の超解像度(image super resolution)を用いて、目標フレームと異なるサイズのフレームを生成することである。符号化されている実際の動画のサイズと寸法に参照フレームが正確に一致する必要性はない。例えば、ズームアウト(zoom out)、パン(pan)、または回転では、大きな領域が、いくつかのフレー
ムにわたり低速で現れる。原フレームよりも大きな構成参照フレームは、境界(border)領域のより高品質の予測を行うことができる。
Another way to generate the configuration reference frame is to generate a frame of a different size than the target frame using image super resolution. There is no need for the reference frame to exactly match the size and dimensions of the actual video being encoded. For example, in zoom out, pan, or rotation, a large area appears slowly over several frames. A configuration reference frame larger than the original frame can perform a higher quality prediction of the border region.
上記の構成参照フレームを生成する１つの方法を、図６に例として示す。第１のステップ５２で、開始フレームＮが選択される。ステップ５４で、開始フレームＮからフレームＮ＋Ｘまで、各フレームＡに対し、いくつかのステップの実行が開始する。ここで、Ｘは整数である。具体的に言うと、ステップ５４で、フレームＡが、開始フレームＮに設定され、ステップ５６で、エンコーダ１４は、フレームＡの数がＮ＋Ｘ個のフレームの数より大きいか否かチェックする。フレーム数より大きくなければ、ステップ５８で、エンコーダ１４は、現フレームＡを開始フレームＮに一致させる最適グローバル動きベクトルを見つける。最適グローバル動きベクトルは、全探索またはダイヤモンド探索などのグローバル動きベクトル探索方法により見つけることができる。上記の方法は、例えば、Ｄａｎｅ
他「Ｅｆｆｉｃｉｅｎｔ Ｍｏｔｉｏｎ Ａｃｃｕｒａｃｙ Ｓｅａｒｃｈ ｆｏｒ Ｇｌｏｂａｌ Ｍｏｔｉｏｎ Ｖｅｃｔｏｒ Ｃｏｄｉｎｇ」，信号、システム、およびコンピュータに関する第１４回アシロマ会議，ＡＣＳＳＣ'０６，２００６年１０〜１１
月、１０７２〜１０７５ページ．に記載されている。
One method of generating the above configuration reference frame is shown as an example in FIG. In a first step 52, the start frame N is selected. In
Other "Efficient Motion Accurate Search for Global Motion Vector Coding", 14th Asilomar Conference on Signals, Systems, and Computers, ACSSC '06, 2006 10-11
Month, 1072-1075 pages. It is described in.
ステップ５８の後、ステップ６０でフレームがインクリメントされ、ステップ５４で、新しいフレームが現フレームＡになる。ステップ５６で示したように、現フレームＡの数が、Ｎ＋Ｘ個のフレームの数より大きくなるまで、ステップ５６，５８，６０が繰り返し実行される。次いで、ステップ６２に処理が進み、ここでグローバル動きベクトルを用いて、お互いの上部に整列したとき、フレームの全セットをカバーする境界領域(bounding region)が生成される。次のステップ６４で、原フレームよりも寸法が大きい新しい画像
が生成される。この新しい画像は、動き回る全領域(the entire region as it is moved about)をカバーする十分な大きさであるのが好ましい。
After
ステップ６４で、グローバル動きベクトルを見つけ、一組の動画フレームと完全に境が接する新しい画像を生成した後に、新しい画像の各画素に対して残りのステップが実行される。すなわち、ステップ６６で、新しい画像の画素が選択される。ステップ６８で、開始フレームＮ〜フレームＮ＋Ｘまで各フレームＡに対して以下のステップが実行されるように、フレームＡが開始フレームＮに再設定される。最初に、ステップ７０で、エンコーダ１４は、フレームＡの数が、Ｎ＋Ｘ個のフレームの数より大きいか否かチェックする。フレームの数より大きくなければ、エンコーダ１４は、ステップ７１で、選択した画素が現フレームＡにあるか否か問い合わせる。ステップ７１で、選択した画素が、現フレームＡにある場合は、ステップ７２に処理が進み、ここでエンコーダ１４は、候補セットに当該画素を加える。そして、ステップ７３に処理が進み、ここでフレームがインクリメントされる。ステップ７１で、選択した画素が、現フレームＡにない場合は、ステップ７３に直接処理が進み、フレームをインクリメントする。次に、ステップ６８で、インクリメントされたフレームが、現フレームＡとして設定され、ステップ７１で、新しいフレームセットに対して、選択した画素を探索する。フレームセットの各フレームに対してこの処理を終了して、候補セットを生成する。いったん、選択した画素に対して全フレームをチェックすると（ステップ７０で、問い合わせに対するＹｅｓ応答で示した）、ステップ７４に処理が進み、ここでいくつかのステップが、候補セットに対して実行される。
At
すなわち、ステップ７４で、候補セットから最新の画素が選択され、候補セットの残りの各画素が、その最新の画素と比較される。具体的に言うと、ステップ７５で、候補セットの画素が選択される。ステップ７６で、エンコーダ１４は、当該画素の輝度が、最新の画素の輝度から離れた所定の閾値より大きいか否か判断する。この所定の閾値は、実験で求められ、フレームの画素の輝度範囲に部分的に依存している。選択した画素の輝度が、最新の画素の輝度から離れた所定の閾値より大きいのであれば、ステップ７７で、その画素が候補セットから削除される。ステップ７８で、候補セットの全画素が、チェックされた場合（および、ステップ７６で問い合わせに対するｎｏ応答により候補セットに残った、あるいはステップ７６で、問い合わせへのＹｅｓ応答により、ステップ７７で、候補セットから削除されたのであれば）、ステップ７９に処理が進む。そうでなければ、ステップ７５で、候補セットから新しい画素が選択されて、ステップ７６で、最新の画素と比較される。
That is, at
ステップ７９で、候補セットに残っている画素の平均輝度が計算される。この平均輝度は、一例として、フレーム中の画素の位置に基づく、重み付け平均であってよい。次に、ステップ８０で、この平均輝度が、新しい画像から生成された構成参照フレームの現画素輝度値として格納される。すなわち、平均輝度値が、候補セットを生成するのに用いた新しい画像から選択された画素の画素位置に関連して格納される。ステップ８２で、エンコーダ１４は、新しい画像の全画素が、探索されたか否か問い合わせる。探索された場合には、処理を終了する。探索されていなければ、ステップ６６で、新しい画像の次の画素が選択される。その画素の候補セットが選択され、平均輝度値が割り当てられるように、ステップ７０〜８０の処理を繰り返し実行する。
In
構成参照フレームを生成する第５の方法は、各ブロックまたはフレーム中のマクロブロックにスコアを付けるスコア付け方法論を用いることと、全フレームの全スコアを計算することとを含む。このスコアは、既存のどのフレームが、参照フレームを構成するのに用いられたのか選択するのに用いることができる（つまり、適時測定されるどのオフセットが、現フレームと構成参照フレームの構築に用いられたフレームとの間に設定されるのか）。いくつかのスコア付け基準を用いることができる。例えば、このスコア付け基準(scoring criteria)は、イントラ予測対インター予測の誤り率を含むことができる。この場合、この誤り率が高ければ高いほど、使用可能な時間オフセットが大きくなり、適用可能なブーストも大きくなる。別の基準が動きベクトルである。動きが少なければ少ないほど、
時間オフセットとブーストを大きくなる。また、別の基準がズームイン対ズームアウトであり、また別の基準が、予測品質の減衰率である。
A fifth method of generating a configuration reference frame includes using a scoring methodology that scores each block or macroblock in the frame and calculating the total score for all frames. This score can be used to select which existing frame was used to construct the reference frame (i.e. which offset measured in time is used to construct the current frame and the constituent reference frame). Set to the specified frame). Several scoring criteria can be used. For example, the scoring criteria can include intra prediction versus inter prediction error rates. In this case, the higher the error rate, the greater the usable time offset and the greater the applicable boost. Another criterion is the motion vector. The less movement, the more
Increase time offset and boost. Another criterion is zoom-in vs. zoom-out, and another criterion is the decay rate of predicted quality.
次に述べるのが、構成参照フレームに関するさらなる詳細、更新間隔、および適用すべきビットレートブーストである。 The following are further details regarding the configuration reference frame, the update interval, and the bit rate boost to be applied.
本発明の特定の一実施形態において、２パス符号化機構を用いて、構成参照フレームの用途、頻度、および品質を決定する。ある他の実施形態は、１パスエンコーダに実装され、異なる測定基準を用いるかもしれない。 In one particular embodiment of the invention, a two pass encoding mechanism is used to determine the usage, frequency, and quality of the configuration reference frame. Certain other embodiments may be implemented in a one-pass encoder and use different metrics.
第１のパスにおいて、ビデオクリップの特徴に関する情報、つまり、一連の原フレームまたは画像が収集される。各マクロブロックは、２つの方法のうちの１つ、すなわち単純ＤＣ予測イントラモード、または動きベクトルを用い、前のフレーム再構成バッファを参照するインター予測モードの２つの方法のうちの１つで符号化される。 In the first pass, information about the characteristics of the video clip, ie a series of original frames or images, is collected. Each macroblock is coded in one of two ways: simple DC prediction intra mode, or one of two methods of inter prediction mode using motion vectors and referring to the previous frame reconstruction buffer. It becomes.
両方の符号化方式に対して、再構成エラースコアが記録され、イントラモードのフレームと、イントラモードまたは動き補償インターモードのベストモードのいずれかのフレームの累積スコアのレコードが保持される。通例、ベストモードは、インターコーディングモードである。従って、以下の説明において、インターコーディングモードは、必ずしも各フレームに対するベストモードではないが、累積ベストスコアは、フレームのインターエラースコアと呼ばれる。 For both coding schemes, the reconstruction error score is recorded, and a record of the cumulative score of the intra mode frame and either the intra mode or the best mode of motion compensated inter mode is maintained. Typically, the best mode is the intercoding mode. Therefore, in the following description, the intercoding mode is not necessarily the best mode for each frame, but the accumulated best score is referred to as the inter error score of the frame.
ベストモードがイントラではなくインターであるマクロブロックのパーセンテージ、ゼロ（ヌル）動きベクトルが選択されるインターコードッド(coded)マクロブロックのパー
センテージ、および用いた動きベクトルに関する要約情報のレコードも保持される。
Records of the percentage of macroblocks whose best mode is inter rather than intra, the percentage of intercoded macroblocks for which zero (null) motion vectors are selected, and summary information about the motion vectors used are also maintained.
ゼロ（ヌル）動きベクトルが選択される、インターコードッドマクロブロックのパーセンテージは、どれくらいの画像が静止画であるかを示す。 The percentage of intercoded macroblocks for which a zero (null) motion vector is selected indicates how many images are still images.
用いた動きベクトルに関する要約情報は、非ゼロベクトルが用いられるマクロブロックの数、合計値、および動きベクトル成分（ｘ、ｙ）の各々の絶対値の合計を含む。これらのことから、フレームの平均動きベクトル（ある正値と負値がある場合、それらは相殺し得る）と、フレームの平均動きベクトルの大きさを計算することができる。 The summary information about the motion vectors used includes the number of macroblocks for which non-zero vectors are used, the total value, and the sum of the absolute values of each of the motion vector components (x, y). From these, it is possible to calculate the average motion vector of the frame (if there are certain positive and negative values, they can cancel) and the size of the average motion vector of the frame.
第１のパスで収集された情報の用途の１つは、構成参照フレームを符号化すべきか否か、またはどれ位の頻度で構成参照フレームを符号化すべきか、およびどれ位多くのビットを構成参照フレームに使うべきか否か決定することであり、これは符号化機構の第２のパスを含む。ある実施形態では、平均品質よりも多少高い品質で（つまり、高いレベルのブースト）、構成参照フレームが符号化される。 One of the uses of the information collected in the first pass is whether to configure the configuration reference frame, how often to configure the configuration reference frame, and how many bits to configure Determining whether to use for the reference frame, which includes the second pass of the encoding mechanism. In some embodiments, the constituent reference frames are encoded with a slightly higher quality than the average quality (ie, a high level of boost).
「ブースト」された構成参照フレームを符号化して得た利益は、短いフレーム列中のあるフレームから他のフレームまでの予測品質に大部分依存していることである。こうした参照フレームを構成する、一実施形態に関して上記で簡単に述べたように、これを立証するために用いた測定法は、イントラ／インター比であってもよい。イントラ／インター比率は、フレームの累積インター（またはベスト）エラースコアで割ったフレームの合計イントラエラースコア比（第１のパスで測定）である。大きなイントラ／インター比（ＩＩＲａｔｉｏ）は、インターコーディングを用いることは、大きな利益があることを示しており、同様に、当該フレームが先行するフレームにより良好に予測されることを示している。 The benefit gained by encoding a “boosted” configuration reference frame is that it largely depends on the prediction quality from one frame to the other in the short frame sequence. As briefly described above with respect to one embodiment that constitutes such a reference frame, the measurement method used to verify this may be an intra / inter ratio. The intra / inter ratio is the total intra error score ratio (measured in the first pass) of the frame divided by the cumulative inter (or best) error score of the frame. A large intra / inter ratio (IIRatio) indicates that there is a significant benefit to using intercoding, as well as that the frame is better predicted by the preceding frame.
構成参照フレームが、関連し得るフレーム列に対して、以下に説明するように、また図７に関して示したように、一定の最大間隔（Ｍａｘ＿ｉｎｔｅｒｖａｌ）まで、ブーストスコアが計算される。最初に、ステップ８４で、開始フレームＮが選択される。次に、Ｎ〜Ｎ＋Ｍａｘ＿ｉｎｔｅｒｖａｌまでの各フレームＡに対して、いくつかのステップが実行される。すなわち、ステップ８６で、現フレームＡが、最初に開始フレームＮに設定され、後述するように、現フレームＡがインクリメントされる。ステップ８８に示すように、いったん現フレームＡの数が、Ｎ＋Ｍａｘ＿ｉｎｔｅｒｖａｌ個のフレームの数より大きくなると、処理が終了する。現フレームＡの数が、Ｎ＋Ｍａｘ＿ｉｎｔｅｒｖａｌ個のフレームの数を超えない限り、ステップ９０の処理が繰り返される。
The boost score is calculated up to a certain maximum interval (Max_interval), as described below, and as shown with respect to FIG. Initially, at
テップ９０で、変数ＴｈｉｓＦｒａｍｅＤｅｃａｙＲａｔｅが、変数Ｎｅｘｔｆｒａｍｅ％ＩｎｔｅｒＣｏｄｅｄに等しくなるように設定される。変数ＴｈｉｓＦｒａｍｅＤｅｃａｙＲａｔｅは、フレームＡの減衰率を表す。また、変数Ｎｅｘｔｆｒａｍｅ％ＩｎｔｅｒＣｏｄｅｄは、上述したレコードであり、符号化のベストモードがイントラ符号化ではなくインター符号化であるマクロブロックのパーセンテージの次のフレームに対し保持される。Ｎｅｘｔｆｒａｍｅ％ＩｎｔｅｒＣｏｄｅｄの数が小さい場合、これは、現フレームにより次のフレームの多数のブロックも予測品質が低い（そのため、最後には、イントラ符号化されることになる）ことを示している。
At
ステップ９０の後のエンコーダ１４による処理は、ステップ９２に進み、ここで変数ＤｉｓｔａｎｃｅＦａｃｔｏｒが設定される。ステップ９２で計算されたＤｉｓｔａｎｃｅＦａｃｔｏｒは、一般に、フレームのブーストの望ましさと実行すべきブーストの相対量を示す。基本的に、以下にさらに詳述するように、これはＢｏｏｓｔＳｃｏｒｅの算定に用いられる乗数である。ブーストの最小化または削除のために動きが早いことが好適となるので、動き量が多ければ多いほど、ＤｉｓｔａｎｃｅＦａｃｔｏｒの値はより小さくなる。同様に、フレーム中の動きが遅いことを示している場合、高いレベルのブーストが望ましいので、これは、ＤｉｓｔａｎｃｅＦａｃｔｏｒのより大きな値により反映される。ステップ９２で、この場合、３００．０で割った変数ＴｈｉｓＦｒａｍｅＡｖｅｒａｇｅＭｏｔｉｏｎＶｅｃｔｏｒＬｅｎｇｔｈに等しくなるように、ＤｉｓｔａｎｃｅＦａｃｔｏｒが設定される。この除数は、変数ＴｈｉｓＦｒａｍｅＡｖｅｒａｇｅＭｏｔｉｏｎＶｅｃｔｏｒＬｅｎｇｔｈが指定される画素単位の数に部分的に基づいている。この場合、その変数ＴｈｉｓＦｒａｍｅＡｖｅｒａｇｅＭｏｔｉｏｎＶｅｃｔｏｒＬｅｎｇｔｈは、１／８画素単位で指定される。変数ＴｈｉｓＦｒａｍｅＡｖｅｒａｇｅＭｏｔｉｏｎＶｅｃｔｏｒＬｅｎｇｔｈは、上述した動きベクトルに関する要約情報から計算された現フレームの平均動きベクトルである。ここで、乗数３００は、約３００／８画素の平均動きベクトルを表し、実験により求めた。これはブーストをフレームに適用するのが望ましくないことを示す高レベルの動きである。上述したように、除数は、変数ＴｈｉｓＦｒａｍｅＡｖｅｒａｇｅＭｏｔｉｏｎＶｅｃｔｏｒＬｅｎｇｔｈが指定される画素単位の数に部分的に基づいている。また、フレームのサイズに基づくこともできる。例えば、正しいブーストが適用されるように、ＨＤは、おそらく大きな除数を必要とするだろう。
The processing by the
次のステップ９４で、変数ＤｉｓｔａｎｃｅＦａｃｔｏｒが、数１．０と比較される。ＤｉｓｔａｎｃｅＦａｃｔｏｒが、１．０以下である場合、ステップ９６で、ＤｉｓｔａｎｃｅＦａｃｔｏｒは、１．０ＤｉｓｔａｎｃｅＦａｃｔｏｒに設定される。そうでなければ、ステップ９８で、ＤｉｓｔａｎｃｅＦａｃｔｏｒはゼロに設定される。ＤｉｓｔａｎｃｅＦａｃｔｏｒの設定に関わらず、ステップ１００に処理が進み、ここでエンコーダ１４は、ＤｉｓｔａｎｃｅＦａｃｔｏｒを変数ＴｈｉｓＦｒａｍｅＤｅｃａｙＲａｔｅと比較する。ステップ１００で、ＤｉｓｔａｎｃｅＦａｃｔｏｒが、ＴｈｉｓＦｒａｍｅＤｅｃａｙＲａｔｅより小さい場合、ステップ１０２に処理が進み、ここで可変ＴｈｉｓＦｒａｍｅＤｅｃａｙＲａｔｅは、ＤｉｓｔａｎｃｅＦａｃｔｏｒ値を取る。次に、ステッ
プ１０４に処理が進む。ステップ１００で、ＤｉｓｔａｎｃｅＦａｃｔｏｒが、ＴｈｉｓＦｒａｍｅＤｅｃａｙＲａｔｅ以上である場合、ステップ１０４に処理が進む。
In the
ステップ１０４で、変数ＤｉｓｔａｎｃｅＦａｃｔｏｒは、変数ＴｈｉｓＦｒａｍｅＤｅｃａｙＲａｔｅにより乗算されたＤｅｃａｙＦａｃｔｏｒの前の値に等しくなるように設定される。ＤｅｃａｙＦａｃｔｏｒは、１．０から始まる値であり、第１のパスでインターコード化された次のフレーム中のブロックの％に応じて、各フレームと共に減少する（変数ＴｈｉｓＦｒａｍｅＤｅｃａｙＲａｔｅにより示したように）。上述したように、Ｎｅｘｔｆｒａｍｅ％ＩｎｔｅｒＣｏｄｅｄ数が少ない場合、これは、現フレームによる次のフレームの多数のブロックの予測品質が低い（そのため、最後には、イントラコード化されることになる）ことを示している。従って、いったんマクロブロックが、シーケンスで一度イントラコード化されると、そのマクロブロックに対し、シーケンスの反対側のフレーム間の予測リンクが、壊れることが想定される。ＤｅｃａｙＦａｃｔｏｒは、どれほど良くこの予測リンクが維持されるのかについて比較的粗い測定基準(metric)を提供する。
At
一実施形態において、現フレーム中の動きレベルが大きかった場合（第１のパス(first
pass)で測定したように）、ＤｅｃａｙＦａｃｔｏｒも低減し得る。上述したように、ＴｈｉｓＦｒａｍｅＡｖｅｒａｇｅＭｏｔｉｏｎＶｅｃｔｏｒＬｅｎｇｔｈは、この例において、１／８画素単位で指定される。フレームのイントラコード化レベルが高い場合と同様に、非常に高速の動き（大きな動きベクトル）が、シーケンスの両端間の予測リンク品質を低減させることが想定される。
In one embodiment, if the motion level in the current frame is high (first pass (first
DecayFactor can also be reduced as measured by pass). As described above, ThisFrameAverageMotionVectorLength is specified in units of 1/8 pixel in this example. As with the high intra-coding level of the frame, it is assumed that very fast motion (large motion vector) reduces the predicted link quality between the ends of the sequence.
ステップ１０４の後、ステップ１０６に処理が進む。ステップ１０６で、変数ＢｏｏｓｔＳｃｏｒｅが、前のＢｏｏｓｔＳｃｏｒｅと、および、ＩＩＲａｔｉｏ，ＭｕｌｔｉｐｌｉｅｒＶａｌｕｅ，ＤｅｃａｙＦａｃｔｏｒおよびＺｏｏｍＦａｃｔｏｒの乗算結果との合計に更新される。ＩＩＲａｔｉｏとＤｅｃａｙＦａｃｔｏｒは上述したとおりである。ＭｕｌｔｉｐｌｉｅｒＶａｌｕｅは、エンコーダ１４で用いられ、特定のビデオクリップまたはアプリケーション種別のブーストレベルを調節する粗機構(coarse mechanism)を提供する。ＺｏｏｍＦａｃｔｏｒは、内側を向いている動きベクトルの数に対する外側を向いている現フレーム中の動きベクトルの数に基づく値である。ズームアウトしたとき、ブーストを大きくすることが望ましい。逆に、ズームインしたとき、ブーストを小さくすることが望ましい。ＺｏｏｍＦａｃｔｏｒの値を求める１つの方法は、外側を向いた各ベクトルをインクリメントし、内側を向いた各ベクトルをデクリメントするカウンタを設定することである。ベクトルの数で割ったとき、−１と＋１との間の値が結果として得られる。縮尺が０と＋２との間にシフトされるので、その結果、ＺｏｏｍＦａｃｔｏｒの値が０と＋２との間になる。ズームアウトしたとき、ＺｏｏｍＦａｃｔｏｒの値は大きくなり（つまり、この例では１．０より大きい）、逆に、ズームインしたとき、ＺｏｏｍＦａｃｔｏｒの値は小さくなる。ＢｏｏｓｔＳｃｏｒｅは、Ｎ〜Ｎ＋Ｍａｘ＿ｉｎｔｅｒｖａｌまでのフレームの符号化に用いられる構成参照フレームの望ましいブーストを表す。
After
ステップ１０８で、エンコーダ１４は、次のフレームに進み、処理ループは、最大間隔に達するまで、または一実施形態によれば、ブレークアウト条件セットが満たされるまで継続して実行される。ブレークアウト条件を用いることで、適切な場合、構成参照フレーム更新の間に、エンコーダ１４が、より短い間隔を選択できるようにする。
At
図８を参照して、ブレークアウト条件を用いる一実施形態を説明する。ブレークアウト条件の存在をチェックする図８のステップは、図７に示す方法の所定の間隔で定期的に実行される。このステップは、所定の時間間隔で、またはステップ１０８でフレームがインクリメントされるときなどの、図７の処理の特定の所定の時間間隔で実行することができ
る。
With reference to FIG. 8, an embodiment using breakout conditions will be described. The step of FIG. 8 that checks for the existence of a breakout condition is performed periodically at predetermined intervals of the method shown in FIG. This step can be performed at predetermined time intervals or at certain predetermined time intervals of the process of FIG. 7, such as when the frame is incremented at
図８において、ステップ１１０で、フレーム数が、最初に変数Ｍａｘ＿ｉｎｔｅｒｖａｌと比較される。図７に関して説明したように、フレーム数は、現フレーム値Ａである。変数Ｍｉｎ＿ｉｎｔｅｒｖａｌは、連続構成参照フレーム間の予め定義された最小フレーム数である。フレーム数が、この最小値より上でなければ、エンコーダ１４は、ブレークアウトできない、つまりエンコーダ１４は、次の構成参照フレームのより短い間隔を選択することができない。
In FIG. 8, at
フレーム数が、Ｍｉｎ＿ｉｎｔｅｒｖａｌの値より大きければ、残りのブレークアウト条件がチェックされる。ブレークアウト条件が満たされ、ブレークアウトが起こらなければならない、つまり図７の処理が、現フレームＡで終了しなければならないことを示すために、ブレークアウト条件の１つだけが示されればよく、フレームのＭａｘ＿ｉｎｔｅｒｖａｌの数を超える構成参照フレームの使用間隔を短縮する。例えば、Ｍａｘ＿ｉｎｔｅｒｖａｌは、３０フレームで、Ｍｉｎ＿ｉｎｔｅｒｖａｌは、４フレームである。フレームレートが低くなればなるほど、Ｍａｘ＿ｉｎｔｅｒｖａｌの値は、小さくなければならない。これらのステップは、特定の順序で示されているが、解析の実際の順序には関係がない。 If the number of frames is greater than the value of Min_interval, the remaining breakout conditions are checked. Only one of the breakout conditions needs to be indicated to indicate that the breakout condition is satisfied and that a breakout must occur, i.e., the process of FIG. The use interval of the configuration reference frame exceeding the number of Max_intervals of the frame is shortened. For example, Max_interval is 30 frames, and Min_interval is 4 frames. The lower the frame rate, the smaller the value of Max_interval. These steps are shown in a specific order, but are not related to the actual order of analysis.
最初に、ステップ１１２で、変数ＭｙＲａｔｉｏＡｃｃｕｍｕｌａｔｏｒの値がチェックされる。ＭｙＲａｔｉｏＡｃｃｕｍｕｌａｔｏｒは、動きの特徴について第１のパスで収集された情報を用いて求められる値である。ＭｙＲａｔｉｏＡｃｃｕｍｕｌａｔｏｒは、各フレームの平均絶対動きベクトルを平均動きベクトルで割った結果を累積し、基本的に、フレーム中の動きのランダムさの測度である。大きな値は、ズームの場合にそうであるように、例えば、画像の反対側のベクトルが反対方向を向いている場合に、フレームの正と負のベクトルが互いに相殺されたことを示している。１．０に近づく値は、全ベクトルが大まかに同じ方向を向いていることを示している（例えば、パンのときのように）。そのような場合において、新しい構成参照フレームは必要でない。 First, at step 112, the value of the variable MyRatioAccumulator is checked. MyRatioAccumulator is a value obtained using the information collected in the first pass with respect to the feature of motion. MyRatioAccumulator accumulates the results of dividing the average absolute motion vector of each frame by the average motion vector, and is basically a measure of the randomness of the motion in the frame. A large value indicates that the positive and negative vectors of the frame have canceled each other, for example when the opposite vector of the image is pointing in the opposite direction, as is the case with zoom. A value approaching 1.0 indicates that all vectors are roughly pointing in the same direction (eg, when panning). In such a case, a new configuration reference frame is not necessary.
ステップ１１２で、可変ＭｙＲａｔｉｏＡｃｃｕｍｕｌａｔｏｒが、６０より大きければ、ステップ１１４で、ブレークアウト条件が満たされる。値が６０であることは、この場合、構成参照フレームをより頻繁に生成させることの望ましさを示している。値６０は、ほんの一例であり、上述したような（例えば、フレームサイズと動きベクトルの長さ）などの原フレーム(source frame)の特徴に基づいて、他の値を用いることもできる。
If the variable MyRatioAccumulator is greater than 60 at step 112, the breakout condition is satisfied at
ステップ１１２で、可変ＭｙＲａｔｉｏＡｃｃｕｍｕｌａｔｏｒが、６０以下であれば、残りのブレークアウト条件を解析するために、ステップ１１６に進み、ここで、変数ＡｂｓＭｙＩｎＯｕｔＡｃｃｕｍｕｌａｔｏｒがチェックされる。ＡｂｓＭｙＩｎＯｕｔＡｃｃｕｍｕｌａｔｏｒもまた、動きの特徴についての第１のパスで収集した情報を用いて求められた値である。より具体的に言うと、ＡｂｓＭｙＩｎＯｕｔＡｃｃｕｍｕｌａｔｏｒは、画像の中心方向を向いているベクトルと比較して、画像の中心から離れた方向を向いているベクトルのバランスを示しており、ＺｏｏｍＦａｃｔｏｒに関して説明したものと同様に計算できる。これは、ズームイン条件からズームアウト条件を区別するのに役立つ。ステップ１１６で、変数ＡｂｓＭｙＩｎＯｕｔＡｃｃｕｍｕｌａｔｏｒの値が２より大きければ、ステップ１１４で、ブレークアウト条件が満たされ、新たな構成参照フレームが望ましくなる。そうでなければ、ステップ１１８に処理が進み、最後のブレークアウト条件をチェックする。値２は、実験で求められた閾値であり、フレームサイズや動きベクトルの長さなどの特徴に基づいて変化する。
At step 112, if the variable MyRatioAccumulator is less than or equal to 60, proceed to step 116 to analyze the remaining breakout conditions, where the variable AbsMyInOutAccumulator is checked. AbsMyInOutAccumulator is also a value determined using the information collected in the first pass on motion features. More specifically, AbsMyInOutAccumulator shows the balance of vectors facing away from the center of the image compared to vectors facing the center of the image, similar to that described for ZoomFactor. Can be calculated. This helps distinguish the zoom-out condition from the zoom-in condition. If the value of variable AbsMyInOutAccumulator is greater than 2 at
ステップ１１８で、ＢｏｏｓｔＳｃｏｒｅが、前のＢｏｏｓｔＳｃｏｒｅ（Ｐｒｅｖｉ
ｏｕｓＢｏｏｓｔＳｃｏｒｅ）と比較される。ＢｏｏｓｔＳｃｏｒｅが、ＰｒｅｖｉｏｕｓＢｏｏｓｔＳｃｏｒｅ＋２より小さければ、あるフレームから次のフレームまでのブーストスコアの増加率が、閾値量未満に低下する状況が起こる。そのため、ステップ１１８で、ＢｏｏｓｔＳｃｏｒｅが、ＰｒｅｖｉｏｕｓＢｏｏｓｔＳｃｏｒｅ＋２未満であれば、ステップ１１４で、ブレークアウト条件が満たされ、新たな構成参照フレームが望ましくなる。そうでなければ、全ブレークアウト条件がチェックされ、ブレークアウト条件処理が終了する。図７の処理が再開する。
At
ousBoostScore). If BoostScore is smaller than PreviousBoostScore + 2, a situation occurs in which the boost score increase rate from one frame to the next frame falls below the threshold amount. Therefore, if BoostScore is less than PreviousBoostScore + 2 in
ステップ１１８での値２．０は、図７で判断されたように、前の構成参照フレームと後続の参照フレームとの間の間隔が、非常に大きくなる（つまり、前の構成参照フレームを用いて、非常に多くのフレームが符号化されている）ように、シーケンスの両端の予測品質が、最小の容認可能なレベル以下に低下して、前の構成参照フレームと後続の参照フレームとの間の間隔が大きすぎる（すなわち、前の参照構成フレームを用いて符号化されたフレームが多すぎる）ことを示す指標である。値２．０は、現フレームの図７のステップ１１６で説明した、ＩＩＲａｔｉｏ＊ＭｕｌｔｉｐｌｉｅｒＶａｌｕｅ＊ＤｅｃａｙＦａｃｔｏｒ＊ＺｏｏｍＦａｃｔｏｒの計算に対応し、その計算の変数の所与の範囲の実験に基づいて求められる。
A value of 2.0 at
図７，８に関して説明したアルゴリズムは、Ｍｉｎ＿ｉｎｔｅｒｖａｌフレームとＭａｘ＿ｉｎｔｅｒｖａｌフレーム間の推奨更新間隔を示す。また、これは、今回の更新の推奨ビット割当て（または、ビットブースト）を示す。ここで述べた例において、推奨ビット割当ては、１００＊ＢｏｏｓｔＳｃｏｒｅ／１６であり、これは百分率ビット割当てへの正規化である。換言すれば、ＢｏｏｓｔＳｃｏｒｅは、利用可能なビットの割当てに用いられる構成参照フレームの各々に対する相対値であり、メモリ、構成参照フレーム数等に依存する。 The algorithm described with reference to FIGS. 7 and 8 indicates the recommended update interval between the Min_interval frame and the Max_interval frame. This also indicates the recommended bit allocation (or bit boost) for this update. In the example described here, the recommended bit allocation is 100 * BoostScore / 16, which is a normalization to a percentage bit allocation. In other words, BoostScore is a relative value for each of the configuration reference frames used for allocation of available bits and depends on the memory, the number of configuration reference frames, and the like.
ところが、図７，８において決定された結果に関わらず、上述したような、構成参照フレームの更新が適切でないかもしれない状況も相変わらず残っている。 However, regardless of the results determined in FIGS. 7 and 8, there still remains a situation where the update of the configuration reference frame may not be appropriate as described above.
一実施形態において、更新された構成参照フレームが、望ましいか否か判断するのに以下の基準が用いられる。シーケンスのＢｏｏｓｔＳｃｏｒｅが、閾値量を超えて（構成参照フレームがフレームシーケンスと良好な相関を示す）、シーケンス中のフレームのＤｅｃａｙＦａｃｔｏｒの平均値が閾値を超えて（シーケンスにわたり、良好な予測を示す）、かつ高速ズームが検出されなかった（特に、画像データに画像が残っているズーム条件）場合は、更新するのが望ましい。これらの基準は、実行されたとき、新しい構成参照フレームが、図８の解析に応じて示される各ループの後で、好適にチェックされる。これらの条件の１つが、満たされないと、次の構成参照フレームの処理を継続する。より具体的に言うと、前の構成参照フレームを用いて現フレームが符号化され、図７の計算が次のフレームで再開し、図８の条件が再度満たされて以前の間隔で新しい構成参照フレームの望ましさが示されない限り、Ｍａｘ＿ｉｎｔｅｒｖａｌまで処理が継続する。 In one embodiment, the following criteria are used to determine whether an updated configuration reference frame is desirable: If the BoostScore of the sequence exceeds the threshold amount (the configuration reference frame shows good correlation with the frame sequence), the average DecayFactor of the frames in the sequence exceeds the threshold (shows good prediction across the sequence) If high-speed zoom is not detected (in particular, zoom conditions in which an image remains in the image data), it is desirable to update. When these criteria are executed, new configuration reference frames are preferably checked after each loop shown in response to the analysis of FIG. If one of these conditions is not met, processing of the next configuration reference frame continues. More specifically, the current frame is encoded using the previous configuration reference frame, the calculation of FIG. 7 resumes with the next frame, the condition of FIG. 8 is satisfied again, and the new configuration reference is made at the previous interval. As long as the desirability of the frame is not indicated, processing continues until Max_interval.
妥当性、構成参照フレームの間隔とブースト、または類似するものを判断するために上記で定義したアルゴリズムは、双方向予測をサポートしているエンコーダ／デコーダにおいて、連続Ｐフフレーム間のＢフレームの最適数、およびＰフレームとＢフレーム間のビット分布を定義するのに用いることができることに注意されたい。 The algorithm defined above to determine validity, configuration reference frame spacing and boost, or the like, is an optimal B frame between consecutive P frames in an encoder / decoder that supports bi-directional prediction. Note that it can be used to define the number and bit distribution between P and B frames.
構成参照フレームは、エンドユーザに表示される必要がなく（つまり、最終的な復号動画出力に含む必要がない）、かつ実際の画像に対応させる必要もない。そうであるから、構成参照フレームのサイズと構成は任意であり、エンコーダ１４によりプログラムで決定して、符号化品質を最適化できる。
The configuration reference frame does not need to be displayed to the end user (that is, does not need to be included in the final decoded moving image output) and does not need to correspond to an actual image. As such, the size and configuration of the configuration reference frame is arbitrary, and can be determined by the program by the
１つの利点が、構成参照フレームを生成するのに用いた計算を再実行する必要がないことである。よって、計算コストが高い処理は、エンコーダ１４を用いて、構成参照フレームを取得することができるが、この処理はデコーダ２１で実行する必要がないので、より高速、より軽量で、より効率的な復号化が可能になる。
One advantage is that the calculations used to generate the configuration reference frame do not need to be re-executed. Therefore, a process with a high calculation cost can obtain a configuration reference frame using the
本発明の理解を容易にするため、上記の実施形態を説明したが、本発明を限定するものではない。それどころか、本発明は、添付クレームの範囲内に含まれる様々な変更例と等価な構成を網羅することを意図している。ここで範囲とは、上記の全ての変更例と法により許されている等価な構成を包合するために、最も広い解釈に一致する。 In order to facilitate understanding of the present invention, the above embodiment has been described, but the present invention is not limited thereto. On the contrary, the invention is intended to cover configurations equivalent to various modifications included within the scope of the appended claims. Here, the scope corresponds to the broadest interpretation in order to encompass all the variations described above and equivalent configurations permitted by law.
Claims (16)
エンコーダを用いて構成参照フレームを生成することと、
前記構成参照フレームを前記デコーダに送信するためビットストリームに符号化することと、
後続する復号処理のための前記ビットストリームに含めるために、前記構成参照フレームを用いて、前記一連の原動画フレームを圧縮して、圧縮デジタル動画信号を取得することと、
後続する表示処理の間に、前記構成参照フレームが、前記一連の復号動画フレームから削除されることを示すことと
を含み、
前記一連の復号動画フレームは前記圧縮デジタル動画信号から得られ、
前記一連の原動画フレームを圧縮して、圧縮デジタル動画信号を取得することには、
前記一連の原動画フレームの各マクロブロックの予測マクロブロックを形成することであって、前記一連の原動画フレームの少なくともいくつかのマクロブロックの前記予測マクロブロックが、前記構成参照フレームを用いてインター予測によって形成されることと、
関連する前記予測マクロブロックを用いて、前記一連の原動画フレームの各マクロブロックの残差マクロブロックを生成することと、
前記一連の原動画フレームの各マクロブロックの前記残差マクロブロックを符号化して前記圧縮デジタル動画信号を取得することと、
を含むことを特徴とする方法。 A method of encoding a series of original video frames sent to a decoder and generating a series of decoded video frames for display,
Generating a configuration reference frame using an encoder;
Encoding the configuration reference frame into a bitstream for transmission to the decoder;
Compressing the series of original video frames using the configuration reference frame to include a compressed digital video signal for inclusion in the bitstream for subsequent decoding processing ;
During the subsequent display processing, the configuration reference frame, viewed contains a to indicate that it is removed from the series of decoded video frames,
The series of decoded video frames is obtained from the compressed digital video signal;
In order to compress the series of original video frames and obtain a compressed digital video signal,
Forming a predicted macroblock of each macroblock of the series of original video frames, wherein the predicted macroblocks of at least some macroblocks of the series of original video frames are interleaved using the configuration reference frame. Being formed by prediction,
Generating a residual macroblock for each macroblock of the series of original video frames using the associated predicted macroblock;
Encoding the residual macroblock of each macroblock of the series of original video frames to obtain the compressed digital video signal;
Wherein the free Mukoto a.
前記構成参照フレームを符号化することは、前記既存の原フレームが連続してその順番で現れる前に、前記既存の原フレームのコピーを符号化することを含み、
前記一連の原動画フレームを圧縮することは、前記構成参照フレームを用いて、前記既存の原フレームを連続してその順番で符号化することを含むことを特徴とする請求項１に記載の方法。 The configuration reference frame is a copy of an existing original frame;
To encode the configuration reference frame includes said existing original frame before appearing in that order successively, to encode a copy of the existing source frame,
The method of claim 1, wherein compressing the series of original video frames includes sequentially encoding the existing original frames in the order using the configuration reference frame. .
ここで、前記既存の原フレームを連続してその順番で符号化することは、前記第１の品質レベルと異なる第２の品質レベルで、前記既存の原フレームを符号化することを含むことを特徴とする請求項２に記載の方法。 Encoding the existing original frame includes encoding the copy at a first quality level;
Here, continuously encoding the existing original frames in the order includes encoding the existing original frames at a second quality level different from the first quality level. The method of claim 2 , wherein the method is characterized in that:
時間フィルタを用いて、いくつかの原フレームから動画ノイズを除去することと、
前記いくつかの原フレームの各マクロブロックのエラースコアを計算することと、
最低のエラースコアを有する各原フレームのマクロブロックを前記構成参照フレームにコピーすることを含むことを特徴とする請求項１に記載の方法。 Using the encoder to generate the configuration reference frame
Using a temporal filter to remove video noise from some original frames;
Calculating an error score for each macroblock of the number of original frames;
The method of claim 1, comprising copying a macroblock of each original frame having a lowest error score to the constituent reference frame.
前記いくつかの原フレームにわたり、複数の画素を含む複数のマクロブロックの各々の動きベクトルを計算することと、
所定の制限値未満の動きベクトルを有するマクロブロックを前記構成参照フレームにコピーすることを含むことを特徴とする請求項５に記載の方法。 Generating the configuration reference frame includes:
Wherein throughout the several original frame, and calculating the respective motion vectors of a plurality of macro blocks comprising a plurality of pixels,
6. The method of claim 5, comprising copying a macroblock having a motion vector less than a predetermined limit value into the constituent reference frame.
前記構成参照フレームは、画像超解像度を用いて現れた前記所定のサイズよりも大きいサイズを有することを特徴とする請求項１に記載の方法。 The series of original image frames has a predetermined size;
The method of claim 1, wherein the configuration reference frame has a size that is larger than the predetermined size that appeared using image super-resolution.
開始フレームＮを取得することと、
Ｘが正の整数である開始フレームＮからフレームＮ＋Ｘまでの各フレームＡに一致するグローバル動きベクトルを見つけることと、
前記グローバル動きベクトルを用いてお互いの上部に整列されたとき、前記一連の原動画フレームをカバーする境界領域を生成することと、
動き回ったとき、前記境界領域全体をカバーするのに十分な大きさの新しい画像を生成することと、
前記新しい画像中の前記複数の画素の各々のフレームシーケンスから複数の候補画素を生成することと、ここで前記複数の画素の各々はそれぞれの候補セットに関連付けられており、
前記各候補セットの各々の平均輝度値を計算することと、
前記構成参照フレーム中の画素として、前記新しい画像中の前記複数の画素に関連付けられる前記平均輝度値を記憶することとを含むことを特徴とする請求項７に記載の方法。 Using the encoder to generate the configuration reference frame is:
Obtaining a start frame N;
Finding a global motion vector matching each frame A from start frame N to frame N + X where X is a positive integer;
Generating a boundary region that covers the series of original video frames when aligned on top of each other using the global motion vector;
Generating a new image large enough to cover the entire border region when moving around;
Generating a plurality of candidate pixels from each frame sequence of the plurality of pixels in the new image, wherein each of the plurality of pixels is associated with a respective candidate set;
Calculating an average luminance value for each of the candidate sets;
8. The method of claim 7, comprising storing the average luminance value associated with the plurality of pixels in the new image as pixels in the configuration reference frame.
前記原フレームの各々の全スコアを計算することと、
前記全スコアに基づき、前記構成参照フレームを生成するために、前記原フレームの１つを選択することを含むことを特徴とする請求項１または２に記載の方法。 Scoring each macroblock containing multiple pixels in several original frames based on scoring criteria;
Calculating a total score for each of the original frames;
3. A method according to claim 1 or 2, comprising selecting one of the original frames to generate the configuration reference frame based on the total score.
前記圧縮デジタル動画信号を含むビットストリームから構成参照フレームを復号することと、
前記一連の原動画フレームを復号化して、前記一連の復号動画フレームを生成することと、
後続する表示処理の間に、前記一連の復号動画フレームから前記構成参照フレームが削除されることと、
を含み、
前記一連の原動画フレームを復号化して、前記一連の復号動画フレームを生成することすることには、
前記一連の原動画フレームの各マクロブロックの予測マクロブロックを生成することであって、前記一連の原動画フレームの少なくともいくつかのマクロブロックの前記予測マクロブロックが、前記構成参照フレームを用いてインター予測によって形成されたものであることと、
前記一連の原動画フレームの各マクロブロックの残差マクロブロックを復号化することであって、各残差マクロブロックが前記圧縮デジタル動画信号内で符号化されたものであることと、
前記予測マクロブロックと前記一連の原動画フレームの各マクロブロックに関連付けられた前記残差マクロブロックとを組み合わせることにより、前記一連の原動画フレームの各マクロブロックを再構成して、前記一連の復号化された動画フレームを生成することと、
を含むことを特徴とする方法。 Method for decoding for display compressed digital video signal obtained by compressing a series of original video frames,
And decoding the bit stream or we configure the reference frame including the compressed digital video signal,
Decoding the series of original video frames to generate the series of decoded video frames ;
During the subsequent display process, and that said series of decoded video reference frames before Ki構 consists frame is removed,
Including
Decoding the series of original video frames to generate the series of decoded video frames,
Generating a predicted macroblock of each macroblock of the series of original video frames, wherein the predicted macroblocks of at least some macroblocks of the series of original video frames are interleaved using the configuration reference frame. That it was formed by prediction,
Decoding a residual macroblock of each macroblock of the series of original video frames, each residual macroblock being encoded within the compressed digital video signal;
Reconstructing each macroblock of the series of original video frames by combining the prediction macroblock and the residual macroblock associated with each macroblock of the series of original video frames, and decoding the series of decoding Generating a streamed video frame,
A method comprising the steps of:
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US9618908P | 2008-09-11 | 2008-09-11 | |
US61/096,189 | 2008-09-11 | ||
US12/329,041 | 2008-12-05 | ||
US12/329,041 US8385404B2 (en) | 2008-09-11 | 2008-12-05 | System and method for video encoding using constructed reference frame |
PCT/US2009/056448 WO2010030732A2 (en) | 2008-09-11 | 2009-09-10 | System and method for video encoding using constructed reference frame |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2012502590A JP2012502590A (en) | 2012-01-26 |
JP5362831B2 true JP5362831B2 (en) | 2013-12-11 |
Family
ID=41799270
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2011526953A Active JP5362831B2 (en) | 2008-09-11 | 2009-09-10 | Video coding system and method using configuration reference frame |
Country Status (7)
Country | Link |
---|---|
US (5) | US8385404B2 (en) |
EP (1) | EP2327212A4 (en) |
JP (1) | JP5362831B2 (en) |
KR (1) | KR20110059853A (en) |
CN (1) | CN102150429B (en) |
CA (1) | CA2736886A1 (en) |
WO (1) | WO2010030732A2 (en) |
Families Citing this family (76)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7983835B2 (en) | 2004-11-03 | 2011-07-19 | Lagassey Paul J | Modular intelligent transportation system |
US8385404B2 (en) | 2008-09-11 | 2013-02-26 | Google Inc. | System and method for video encoding using constructed reference frame |
KR101060495B1 (en) * | 2009-03-19 | 2011-08-30 | 주식회사 코아로직 | Encoding device and method and multimedia device including the encoding device |
US7917618B1 (en) * | 2009-03-24 | 2011-03-29 | Amazon Technologies, Inc. | Monitoring web site content |
KR101379185B1 (en) * | 2009-04-14 | 2014-03-31 | 에스케이 텔레콤주식회사 | Prediction Mode Selection Method and Apparatus and Video Enoding/Decoding Method and Apparatus Using Same |
KR101611437B1 (en) * | 2009-10-28 | 2016-04-26 | 삼성전자주식회사 | Method and apparatus for encoding/decoding image by referencing to a plurality of frames |
JP2011223293A (en) * | 2010-04-09 | 2011-11-04 | Hitachi Ltd | Image encoding method, image encoding apparatus, image decoding method, and image decoding apparatus |
US9020043B2 (en) | 2010-05-10 | 2015-04-28 | Google Inc. | Pathway indexing in flexible partitioning |
US8503528B2 (en) | 2010-09-15 | 2013-08-06 | Google Inc. | System and method for encoding video using temporal filter |
US8611415B1 (en) | 2010-11-15 | 2013-12-17 | Google Inc. | System and method for coding using improved motion estimation |
US8842723B2 (en) * | 2011-01-03 | 2014-09-23 | Apple Inc. | Video coding system using implied reference frames |
EP4120686B1 (en) * | 2011-01-07 | 2023-08-23 | Ntt Docomo, Inc. | Predictive encoding method, predictive encoding device, and predictive encoding program of motion vector, and, predictive decoding method, predictive decoding device, and predictive decoding program of motion vector |
US8990435B2 (en) | 2011-01-17 | 2015-03-24 | Mediatek Inc. | Method and apparatus for accessing data of multi-tile encoded picture stored in buffering apparatus |
US9497466B2 (en) * | 2011-01-17 | 2016-11-15 | Mediatek Inc. | Buffering apparatus for buffering multi-partition video/image bitstream and related method thereof |
US8638854B1 (en) * | 2011-04-07 | 2014-01-28 | Google Inc. | Apparatus and method for creating an alternate reference frame for video compression using maximal differences |
US9154799B2 (en) | 2011-04-07 | 2015-10-06 | Google Inc. | Encoding and decoding motion via image segmentation |
US8787454B1 (en) * | 2011-07-13 | 2014-07-22 | Google Inc. | Method and apparatus for data compression using content-based features |
EP2751990A4 (en) | 2011-08-29 | 2015-04-22 | Icvt Ltd | Controlling a video content system |
FR2980068A1 (en) * | 2011-09-13 | 2013-03-15 | Thomson Licensing | METHOD FOR ENCODING AND RECONSTRUCTING A BLOCK OF PIXELS AND CORRESPONDING DEVICES |
CN103828370B (en) | 2011-10-31 | 2017-11-03 | 联发科技股份有限公司 | Buffer unit, way to play for time and entropy decoder |
EP2777276B1 (en) * | 2011-11-08 | 2019-05-01 | Nokia Technologies Oy | Reference picture handling |
US20130201328A1 (en) * | 2012-02-08 | 2013-08-08 | Hing Ping Michael CHUNG | Multimedia processing as a service |
US9262670B2 (en) | 2012-02-10 | 2016-02-16 | Google Inc. | Adaptive region of interest |
US11039138B1 (en) | 2012-03-08 | 2021-06-15 | Google Llc | Adaptive coding of prediction modes using probability distributions |
US9609341B1 (en) | 2012-04-23 | 2017-03-28 | Google Inc. | Video data encoding and decoding using reference picture lists |
WO2013162980A2 (en) | 2012-04-23 | 2013-10-31 | Google Inc. | Managing multi-reference picture buffers for video data coding |
EP2670151A1 (en) * | 2012-05-28 | 2013-12-04 | Tektronix Inc. | Heuristic method for drop frame detection in digital baseband video |
US9014266B1 (en) | 2012-06-05 | 2015-04-21 | Google Inc. | Decimated sliding windows for multi-reference prediction in video coding |
CN102833535B (en) * | 2012-07-03 | 2017-08-25 | 深圳市云宙多媒体技术有限公司 | A kind of reference frame screening technique, device based on macro block statistical information |
US10003793B2 (en) | 2012-10-01 | 2018-06-19 | Google Technology Holdings LLC | Processing of pulse code modulation (PCM) parameters |
US9819965B2 (en) * | 2012-11-13 | 2017-11-14 | Intel Corporation | Content adaptive transform coding for next generation video |
US9883198B2 (en) * | 2012-11-13 | 2018-01-30 | Intel Corporation | Video codec architecture for next generation video |
WO2014120368A1 (en) * | 2013-01-30 | 2014-08-07 | Intel Corporation | Content adaptive entropy coding for next generation video |
US20140254659A1 (en) | 2013-03-11 | 2014-09-11 | Mediatek Inc. | Video coding method using at least evaluated visual quality and related video coding apparatus |
US9756331B1 (en) * | 2013-06-17 | 2017-09-05 | Google Inc. | Advance coded reference prediction |
RU2666635C2 (en) | 2013-10-14 | 2018-09-11 | МАЙКРОСОФТ ТЕКНОЛОДЖИ ЛАЙСЕНСИНГ, ЭлЭлСи | Features of base colour index map mode for video and image coding and decoding |
CN105723712B (en) * | 2013-10-14 | 2019-06-28 | 韩国电子通信研究院 | Image coding/decoding method and equipment based on multilayer |
MX2016004705A (en) | 2013-10-14 | 2016-07-18 | Microsoft Technology Licensing Llc | Features of intra block copy prediction mode for video and image coding and decoding. |
US11109036B2 (en) | 2013-10-14 | 2021-08-31 | Microsoft Technology Licensing, Llc | Encoder-side options for intra block copy prediction mode for video and image coding |
WO2015085575A1 (en) * | 2013-12-13 | 2015-06-18 | Mediatek Singapore Pte. Ltd. | Methods for background residual prediction |
US10390034B2 (en) | 2014-01-03 | 2019-08-20 | Microsoft Technology Licensing, Llc | Innovations in block vector prediction and estimation of reconstructed sample values within an overlap area |
WO2015100726A1 (en) | 2014-01-03 | 2015-07-09 | Microsoft Corporation | Block vector prediction in video and image coding/decoding |
US11284103B2 (en) | 2014-01-17 | 2022-03-22 | Microsoft Technology Licensing, Llc | Intra block copy prediction with asymmetric partitions and encoder-side search patterns, search ranges and approaches to partitioning |
US10542274B2 (en) | 2014-02-21 | 2020-01-21 | Microsoft Technology Licensing, Llc | Dictionary encoding and decoding of screen content |
JP2017512026A (en) * | 2014-03-04 | 2017-04-27 | マイクロソフト テクノロジー ライセンシング，エルエルシー | Block inversion and skip mode in intra block copy prediction |
CN105493505B (en) | 2014-06-19 | 2019-08-06 | 微软技术许可有限责任公司 | Unified intra block duplication and inter-frame forecast mode |
EP2980793A1 (en) * | 2014-07-28 | 2016-02-03 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Encoder, decoder, system and methods for encoding and decoding |
EP3202150B1 (en) | 2014-09-30 | 2021-07-21 | Microsoft Technology Licensing, LLC | Rules for intra-picture prediction modes when wavefront parallel processing is enabled |
DE102014220809A1 (en) * | 2014-10-14 | 2016-04-14 | Siemens Aktiengesellschaft | Apparatus and method for detecting a moving object |
WO2016085231A1 (en) | 2014-11-27 | 2016-06-02 | 주식회사 케이티 | Video signal processing method and device |
KR102551609B1 (en) * | 2014-11-27 | 2023-07-05 | 주식회사 케이티 | Method and apparatus for processing a video signal |
US9591325B2 (en) | 2015-01-27 | 2017-03-07 | Microsoft Technology Licensing, Llc | Special case handling for merged chroma blocks in intra block copy prediction mode |
JP6558071B2 (en) * | 2015-05-20 | 2019-08-14 | 富士通コネクテッドテクノロジーズ株式会社 | Wireless communication apparatus, wireless communication program, and wireless communication method |
CN106664405B (en) | 2015-06-09 | 2020-06-09 | 微软技术许可有限责任公司 | Robust encoding/decoding of escape-coded pixels with palette mode |
CN106331700B (en) | 2015-07-03 | 2019-07-19 | 华为技术有限公司 | Method, encoding device and the decoding device of reference picture coding and decoding |
CN106954082A (en) * | 2016-01-07 | 2017-07-14 | 中兴通讯股份有限公司 | Video coding-decoding method, coding and decoding device and system |
CN107396138A (en) * | 2016-05-17 | 2017-11-24 | 华为技术有限公司 | A kind of video coding-decoding method and equipment |
CN106534871B (en) * | 2016-12-06 | 2019-06-07 | 北京大学 | The coding method of Video Codec and coding/decoding method |
US10448013B2 (en) | 2016-12-22 | 2019-10-15 | Google Llc | Multi-layer-multi-reference prediction using adaptive temporal filtering |
US20180302455A1 (en) * | 2017-04-18 | 2018-10-18 | Facebook, Inc. | Systems and methods for adjusting video transmission bitrates |
EP3396952B1 (en) * | 2017-04-25 | 2019-04-17 | Axis AB | Method and image processing unit for forming a video stream |
NL2018969B1 (en) | 2017-05-23 | 2018-12-04 | Boskalis Bv Baggermaatschappij | Method and system for forming structures in fluid, especially under water |
CN109151469B (en) * | 2017-06-15 | 2020-06-30 | 腾讯科技（深圳）有限公司 | Video coding method, device and equipment |
CN109698850B (en) * | 2017-10-23 | 2022-06-07 | 北京京东尚科信息技术有限公司 | Processing method and system |
US10986349B2 (en) | 2017-12-29 | 2021-04-20 | Microsoft Technology Licensing, Llc | Constraints on locations of reference blocks for intra block copy prediction |
CN108363387B (en) * | 2018-01-11 | 2021-04-16 | 驭势科技（北京）有限公司 | Sensor control method and device |
US10623736B2 (en) * | 2018-06-14 | 2020-04-14 | Telefonaktiebolaget Lm Ericsson (Publ) | Tile selection and bandwidth optimization for providing 360° immersive video |
US10419738B1 (en) | 2018-06-14 | 2019-09-17 | Telefonaktiebolaget Lm Ericsson (Publ) | System and method for providing 360° immersive video based on gaze vector information |
US10567780B2 (en) | 2018-06-14 | 2020-02-18 | Telefonaktiebolaget Lm Ericsson (Publ) | System and method for encoding 360° immersive video |
WO2020006690A1 (en) * | 2018-07-03 | 2020-01-09 | 深圳市大疆创新科技有限公司 | Video processing method and device |
US10841662B2 (en) | 2018-07-27 | 2020-11-17 | Telefonaktiebolaget Lm Ericsson (Publ) | System and method for inserting advertisement content in 360° immersive video |
US10951885B2 (en) | 2018-08-30 | 2021-03-16 | Google Llc | Adaptive temporal filtering for alternate frame reference rendering |
US10757389B2 (en) | 2018-10-01 | 2020-08-25 | Telefonaktiebolaget Lm Ericsson (Publ) | Client optimization for providing quality control in 360° immersive video during pause |
US20230059035A1 (en) * | 2021-08-23 | 2023-02-23 | Netflix, Inc. | Efficient encoding of film grain noise |
GB2610397A (en) * | 2021-09-02 | 2023-03-08 | Samsung Electronics Co Ltd | Encoding and decoding video data |
CN114466199A (en) * | 2022-04-12 | 2022-05-10 | 宁波康达凯能医疗科技有限公司 | Reference frame generation method and system applicable to VVC (variable valve timing) coding standard |
Family Cites Families (218)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DE3629472A1 (en) | 1986-08-29 | 1988-03-03 | Licentia Gmbh | METHOD FOR MOTION-COMPENSATED PICTURE-TO-PICTURE PREDICTION CODING |
ATE74219T1 (en) | 1987-06-02 | 1992-04-15 | Siemens Ag | METHOD FOR DETERMINING MOTION VECTOR FIELDS FROM DIGITAL IMAGE SEQUENCES. |
EP0466981B1 (en) | 1990-07-20 | 1997-02-26 | Koninklijke Philips Electronics N.V. | Motion vector processing device |
EP0533195A2 (en) | 1991-09-20 | 1993-03-24 | Sony Corporation | Picture signal encoding and/or decoding apparatus |
JP3263960B2 (en) | 1991-10-22 | 2002-03-11 | ソニー株式会社 | Motion vector encoder and decoder |
JPH05137131A (en) * | 1991-11-13 | 1993-06-01 | Sony Corp | Inter-frame motion predicting method |
US5442458A (en) | 1991-12-18 | 1995-08-15 | Eastman Kodak Company | Method and associated apparatus for encoding bitplanes for improved coding efficiency |
US5461423A (en) | 1992-05-29 | 1995-10-24 | Sony Corporation | Apparatus for generating a motion vector with half-pixel precision for use in compressing a digital motion picture signal |
US5289276A (en) | 1992-06-19 | 1994-02-22 | General Electric Company | Method and apparatus for conveying compressed video data over a noisy communication channel |
JPH06197334A (en) * | 1992-07-03 | 1994-07-15 | Sony Corp | Picture signal coding method, picture signal decoding method, picture signal coder, picture signal decoder and picture signal recording medium |
US5371841A (en) | 1992-07-31 | 1994-12-06 | Eastman Kodak Company | Progressive bit plane reconstruction method |
US5389068A (en) | 1992-09-01 | 1995-02-14 | Kimberly-Clark Corporation | Tampon applicator |
WO1994018799A1 (en) | 1993-02-03 | 1994-08-18 | Qualcomm Incorporated | Interframe video encoding and decoding system |
US5717394A (en) | 1993-02-10 | 1998-02-10 | Ricoh Company Ltd. | Method and apparatus for encoding and decoding data |
US5586285A (en) | 1993-02-19 | 1996-12-17 | Intel Corporation | Method and circuitry for increasing reserve memory in a solid state memory disk |
US6236682B1 (en) | 1993-03-08 | 2001-05-22 | Sony Corporation | Video motion vector detection including rotation and/or zoom vector generation |
US6327304B1 (en) | 1993-05-12 | 2001-12-04 | The Duck Corporation | Apparatus and method to digitally compress video signals |
US6181822B1 (en) | 1993-05-12 | 2001-01-30 | The Duck Corporation | Data compression apparatus and method |
FI94306C (en) | 1993-07-15 | 1995-08-10 | Nokia Technology Gmbh | Method for determining motion vectors of small TV image segments |
US5398068A (en) | 1993-09-02 | 1995-03-14 | Trustees Of Princeton University | Method and apparatus for determining motion vectors for image sequences |
US5999641A (en) | 1993-11-18 | 1999-12-07 | The Duck Corporation | System for manipulating digitized image objects in three dimensions |
JP3046224B2 (en) * | 1994-07-26 | 2000-05-29 | 三星電子株式会社 | Constant bit rate coding method and apparatus and tracking method for fast search using the same |
KR100213018B1 (en) | 1994-07-30 | 1999-08-02 | 윤종용 | Apparatus for encoding moving picture |
DE69619002T2 (en) | 1995-03-10 | 2002-11-21 | Toshiba Kawasaki Kk | Image coding - / - decoding device |
KR0181034B1 (en) * | 1995-03-18 | 1999-05-01 | 배순훈 | Method and apparatus for detecting motion vector using feature point based motion estimation |
KR0178198B1 (en) | 1995-03-28 | 1999-05-01 | 배순훈 | Apparatus for encoding an image signal |
US5936673A (en) | 1995-05-26 | 1999-08-10 | Intel Corporation | Temporal tile staggering for block based video compression |
US5568200A (en) | 1995-06-07 | 1996-10-22 | Hitachi America, Ltd. | Method and apparatus for improved video display of progressively refreshed coded video |
AU6376296A (en) | 1995-07-11 | 1997-02-10 | Telefonaktiebolaget Lm Ericsson (Publ) | Video coding |
EP1274253A3 (en) | 1995-08-29 | 2005-10-12 | Sharp Kabushiki Kaisha | Video coding device and video decoding device with a motion compensated interframe prediction |
GB9519923D0 (en) | 1995-09-29 | 1995-11-29 | Philips Electronics Nv | Motion estimation for predictive image coding |
GB2308262B (en) | 1995-12-16 | 1999-08-04 | Paul Gordon Wilkins | Method for analysing the content of a video signal |
US5912676A (en) | 1996-06-14 | 1999-06-15 | Lsi Logic Corporation | MPEG decoder frame memory interface which is reconfigurable for different frame store architectures |
US6084912A (en) | 1996-06-28 | 2000-07-04 | Sarnoff Corporation | Very low bit rate video coding/decoding method and apparatus |
US5926226A (en) | 1996-08-09 | 1999-07-20 | U.S. Robotics Access Corp. | Method for adjusting the quality of a video coder |
US6075875A (en) | 1996-09-30 | 2000-06-13 | Microsoft Corporation | Segmentation of image features using hierarchical analysis of multi-valued image data and weighted averaging of segmentation results |
US5748789A (en) * | 1996-10-31 | 1998-05-05 | Microsoft Corporation | Transparent block skipping in object-based video coding systems |
US5828848A (en) * | 1996-10-31 | 1998-10-27 | Sensormatic Electronics Corporation | Method and apparatus for compression and decompression of video data streams |
US6956573B1 (en) * | 1996-11-15 | 2005-10-18 | Sarnoff Corporation | Method and apparatus for efficiently representing storing and accessing video information |
US6072537A (en) * | 1997-01-06 | 2000-06-06 | U-R Star Ltd. | Systems for producing personalized video clips |
US5991447A (en) | 1997-03-07 | 1999-11-23 | General Instrument Corporation | Prediction and coding of bi-directionally predicted video object planes for interlaced digital video |
US6005980A (en) | 1997-03-07 | 1999-12-21 | General Instrument Corporation | Motion estimation and compensation of video object planes for interlaced digital video |
US6115420A (en) | 1997-03-14 | 2000-09-05 | Microsoft Corporation | Digital video signal encoder and encoding method |
US6359929B1 (en) | 1997-07-04 | 2002-03-19 | Matsushita Electric Industrial Co., Ltd. | Image predictive decoding method, image predictive decoding apparatus, image predictive coding apparatus, and data storage medium |
US6108383A (en) | 1997-07-15 | 2000-08-22 | On2.Com, Inc. | Method and apparatus for compression and decompression of video images |
KR100244291B1 (en) | 1997-07-30 | 2000-02-01 | 구본준 | Method for motion vector coding of moving picture |
US6292837B1 (en) | 1997-10-30 | 2001-09-18 | Daniel Miller | Apparatus and method for non-sequential image data transmission and display |
DE69834902T2 (en) | 1997-11-17 | 2007-02-01 | Koninklijke Philips Electronics N.V. | MOTION COMPENSATED PREDICTIVE PICTURE CODING AND DECODING |
KR100523908B1 (en) | 1997-12-12 | 2006-01-27 | 주식회사 팬택앤큐리텔 | Apparatus and method for encoding video signal for progressive scan image |
US6178205B1 (en) * | 1997-12-12 | 2001-01-23 | Vtel Corporation | Video postfiltering with motion-compensated temporal filtering and/or spatial-adaptive filtering |
US6335985B1 (en) * | 1998-01-07 | 2002-01-01 | Kabushiki Kaisha Toshiba | Object extraction apparatus |
EP0940774A3 (en) | 1998-03-05 | 2000-07-05 | Matsushita Electric Industrial Co., Ltd. | Motion vector coding and decoding apparatus and method |
JP3856262B2 (en) | 1998-03-09 | 2006-12-13 | 日本ビクター株式会社 | Motion compensation encoding apparatus, motion compensation encoding method, and motion compensation code recording medium |
JPH11289544A (en) | 1998-04-02 | 1999-10-19 | Sony Corp | Motion detector and its method |
US6895051B2 (en) * | 1998-10-15 | 2005-05-17 | Nokia Mobile Phones Limited | Video data encoder and decoder |
US6222174B1 (en) | 1999-03-05 | 2001-04-24 | Hewlett-Packard Company | Method of correlating immediately acquired and previously stored feature information for motion sensing |
US6499060B1 (en) * | 1999-03-12 | 2002-12-24 | Microsoft Corporation | Media coding for loss recovery with remotely predicted data units |
JP3302939B2 (en) | 1999-03-12 | 2002-07-15 | アールシーエー トムソン ライセンシング コーポレイシヨン | Video signal decompressor for independently compressed even and odd field data |
US7085319B2 (en) | 1999-04-17 | 2006-08-01 | Pts Corporation | Segment-based encoding system using segment hierarchies |
US7050503B2 (en) * | 1999-04-17 | 2006-05-23 | Pts Corporation | Segment-based encoding system using residue coding by basis function coefficients |
US6115076A (en) * | 1999-04-20 | 2000-09-05 | C-Cube Semiconductor Ii, Inc. | Compressed video recording device with non-destructive effects addition |
US6330281B1 (en) * | 1999-08-06 | 2001-12-11 | Richfx Ltd. | Model-based view extrapolation for interactive virtual reality systems |
US6735249B1 (en) | 1999-08-11 | 2004-05-11 | Nokia Corporation | Apparatus, and associated method, for forming a compressed motion vector field utilizing predictive motion coding |
US6658618B1 (en) | 1999-09-02 | 2003-12-02 | Polycom, Inc. | Error recovery method for video compression coding using multiple reference buffers and a message channel |
US6671319B1 (en) | 1999-12-28 | 2003-12-30 | Sony Corporation | Methods and apparatus for motion estimation using neighboring macroblocks |
US6718308B1 (en) * | 2000-02-22 | 2004-04-06 | Daniel L. Nolting | Media presentation system controlled by voice to text commands |
CN1366778A (en) * | 2000-04-27 | 2002-08-28 | 皇家菲利浦电子有限公司 | Video compression |
US6711211B1 (en) | 2000-05-08 | 2004-03-23 | Nokia Mobile Phones Ltd. | Method for encoding and decoding video information, a motion compensated video encoder and a corresponding decoder |
GB2403618A (en) | 2000-05-10 | 2005-01-05 | Picturetel Corp | Video coding using multiple buffers |
GB2381403B (en) | 2000-05-10 | 2004-12-01 | Picturetel Corp | Video coding using multiple buffers |
KR100708091B1 (en) | 2000-06-13 | 2007-04-16 | 삼성전자주식회사 | Frame rate converter using bidirectional motion vector and method thereof |
FI120125B (en) * | 2000-08-21 | 2009-06-30 | Nokia Corp | Image Coding |
US6661842B1 (en) | 2000-09-22 | 2003-12-09 | General Dynamics Decision Systems, Inc. | Methods and apparatus for error-resilient video coding |
US6763067B2 (en) * | 2000-10-10 | 2004-07-13 | Sarnoff Corporation | Rate control for bitstream re-encoding |
US6774929B1 (en) * | 2000-11-03 | 2004-08-10 | Avotec Inc. | Shielded video projection system for MRI |
US6765963B2 (en) | 2001-01-03 | 2004-07-20 | Nokia Corporation | Video decoder architecture and method for using same |
AU2002250278A1 (en) | 2001-03-07 | 2002-09-19 | Pts Corporation | Local constraints for motion estimation |
JP2002271788A (en) | 2001-03-08 | 2002-09-20 | Monolith Co Ltd | Image coding method and device and image decoding method and device |
US6625310B2 (en) * | 2001-03-23 | 2003-09-23 | Diamondback Vision, Inc. | Video segmentation using statistical pixel modeling |
JP2002330440A (en) | 2001-05-01 | 2002-11-15 | Sony Corp | Image transmission method, program for the image transmission method, recording medium for recording the program for the image transmission method, and image transmitter |
JP2007325304A (en) * | 2001-05-30 | 2007-12-13 | Victor Co Of Japan Ltd | Mpeg data recording and reproducing method |
JP4596227B2 (en) * | 2001-06-27 | 2010-12-08 | ソニー株式会社 | COMMUNICATION DEVICE AND METHOD, COMMUNICATION SYSTEM, RECORDING MEDIUM, AND PROGRAM |
US7027654B1 (en) | 2001-08-16 | 2006-04-11 | On2 Technologies | Video compression system |
JP4717285B2 (en) | 2001-08-24 | 2011-07-06 | キヤノン株式会社 | Scanning optical device and image forming apparatus using the same |
US7643559B2 (en) | 2001-09-14 | 2010-01-05 | Ntt Docomo, Inc. | Coding method, decoding method, coding apparatus, decoding apparatus, image processing system, coding program, and decoding program |
US6856701B2 (en) | 2001-09-14 | 2005-02-15 | Nokia Corporation | Method and system for context-based adaptive binary arithmetic coding |
US6847467B2 (en) * | 2001-11-01 | 2005-01-25 | Hewlett-Packard Development Company, L.P. | Method and apparatus for low memory rendering |
JP2004007379A (en) | 2002-04-10 | 2004-01-08 | Toshiba Corp | Method for encoding moving image and method for decoding moving image |
JP3923898B2 (en) | 2002-01-18 | 2007-06-06 | 株式会社東芝 | Image coding method and apparatus |
US6944222B2 (en) | 2002-03-04 | 2005-09-13 | Koninklijke Philips Electronics N.V. | Efficiency FGST framework employing higher quality reference frames |
KR101108661B1 (en) * | 2002-03-15 | 2012-01-25 | 노키아 코포레이션 | Method for coding motion in a video sequence |
WO2003084235A1 (en) | 2002-03-28 | 2003-10-09 | British Telecommunications Public Limited Company | Video pre-processing |
JP4355156B2 (en) | 2002-04-16 | 2009-10-28 | パナソニック株式会社 | Image decoding method and image decoding apparatus |
DE60314935T2 (en) | 2002-04-16 | 2007-12-20 | Robert Bosch Gmbh | Method and unit for bit stream decoding |
US20030206193A1 (en) * | 2002-04-17 | 2003-11-06 | Keizo Sato | Communication control system and storage medium for storing image transfer program |
TW577227B (en) * | 2002-04-23 | 2004-02-21 | Ind Tech Res Inst | Method and apparatus for removing background of visual content |
US7023923B2 (en) * | 2002-04-29 | 2006-04-04 | Koninklijke Philips Electronics N.V. | Motion compensated temporal filtering based on multiple reference frames for wavelet based coding |
EP1372113B1 (en) | 2002-06-11 | 2005-10-19 | STMicroelectronics S.r.l. | Variable bit rate video encoding method and device |
AU2003236900A1 (en) * | 2002-06-12 | 2003-12-31 | British Telecommunications Public Limited Company | Video pre-processing |
US6909749B2 (en) | 2002-07-15 | 2005-06-21 | Pts Corporation | Hierarchical segment-based motion vector encoding and decoding |
KR100865034B1 (en) | 2002-07-18 | 2008-10-23 | 엘지전자 주식회사 | Method for predicting motion vector |
US8384790B2 (en) * | 2002-08-20 | 2013-02-26 | Hewlett-Packard Development Company, L.P. | Video image enhancement method and apparatus using reference and auxiliary frames |
US7072394B2 (en) | 2002-08-27 | 2006-07-04 | National Chiao Tung University | Architecture and method for fine granularity scalable video coding |
JP3977716B2 (en) * | 2002-09-20 | 2007-09-19 | 株式会社東芝 | Video encoding / decoding method and apparatus |
TWI224928B (en) * | 2002-12-27 | 2004-12-01 | Newsoft Technology Corp | Real-time MPEG video encoding method to keep output synchronization of video and audio |
US8040949B2 (en) | 2003-01-09 | 2011-10-18 | The Regents Of The University Of California | Video encoding methods and devices |
KR100504824B1 (en) * | 2003-04-08 | 2005-07-29 | 엘지전자 주식회사 | A device and a method of revising image signal with block error |
FR2854019B1 (en) * | 2003-04-16 | 2005-09-16 | Medialive | SCREENING, UNLOCKING AND SECURED DISTRIBUTION OF AUDIOVISUAL SEQUENCES FROM VIDEO ENCODERS BASED ON WAVELET PROCESSING |
US20050008240A1 (en) * | 2003-05-02 | 2005-01-13 | Ashish Banerji | Stitching of video for continuous presence multipoint video conferencing |
US8824553B2 (en) | 2003-05-12 | 2014-09-02 | Google Inc. | Video compression method |
US7728840B2 (en) | 2003-09-04 | 2010-06-01 | Texas Instruments Incorporated | Sliding data buffering for image processing |
FI115589B (en) | 2003-10-14 | 2005-05-31 | Nokia Corp | Encoding and decoding redundant images |
JP4702059B2 (en) | 2003-12-22 | 2011-06-15 | 日本電気株式会社 | Method and apparatus for encoding moving picture |
US7889792B2 (en) | 2003-12-24 | 2011-02-15 | Apple Inc. | Method and system for video encoding using a variable number of B frames |
US7346106B1 (en) * | 2003-12-30 | 2008-03-18 | Apple Inc. | Robust multi-pass variable bit rate encoding |
US7492820B2 (en) | 2004-02-06 | 2009-02-17 | Apple Inc. | Rate control for video coder employing adaptive linear regression bits modeling |
KR100531895B1 (en) * | 2004-02-26 | 2005-11-29 | 엘지전자 주식회사 | Apparatus and method for concealing block error of image in mobile communication system |
US20050207490A1 (en) | 2004-03-18 | 2005-09-22 | Wang Jason N | Stored picture index for AVC coding |
JP2005294977A (en) | 2004-03-31 | 2005-10-20 | Ulead Systems Inc | Two-path video encoding method and system using sliding window |
CN1939066B (en) * | 2004-04-02 | 2012-05-23 | 汤姆森许可贸易公司 | Method and apparatus for complexity scalable video decoder |
KR101099884B1 (en) * | 2004-04-23 | 2011-12-28 | 히또시 기야 | Moving picture data encoding method, decoding method, terminal device for executing them, and bi-directional interactive system |
US7515637B2 (en) | 2004-05-21 | 2009-04-07 | Broadcom Advanced Compression Group, Llc | Video decoding for motion compensation with weighted prediction |
WO2005125198A2 (en) * | 2004-06-09 | 2005-12-29 | Nielsen Media Research, Inc. | Methods and apparatus to identify viewing information |
US20050286629A1 (en) | 2004-06-25 | 2005-12-29 | Adriana Dumitras | Coding of scene cuts in video sequences using non-reference frames |
US8111752B2 (en) * | 2004-06-27 | 2012-02-07 | Apple Inc. | Encoding mode pruning during video encoding |
US7953152B1 (en) | 2004-06-28 | 2011-05-31 | Google Inc. | Video compression and encoding method |
US7681104B1 (en) * | 2004-08-09 | 2010-03-16 | Bakbone Software, Inc. | Method for erasure coding data across a plurality of data stores in a network |
FR2874292B1 (en) | 2004-08-10 | 2007-01-26 | Thales Sa | METHOD FOR FORMING FRAMES OF A VIDEO SEQUENCE |
US20060050695A1 (en) | 2004-09-07 | 2006-03-09 | Nokia Corporation | System and method for using redundant representations in streaming applications |
DE202004013984U1 (en) | 2004-09-08 | 2006-01-19 | Mekra Lang Gmbh & Co. Kg | camera system |
US20060062481A1 (en) | 2004-09-21 | 2006-03-23 | Markus Suvanto | Apparatuses, computer program product and method for bit rate control of digital image encoder |
KR100679022B1 (en) * | 2004-10-18 | 2007-02-05 | 삼성전자주식회사 | Video coding and decoding method using inter-layer filtering, video ecoder and decoder |
JP2006174415A (en) * | 2004-11-19 | 2006-06-29 | Ntt Docomo Inc | Image decoding apparatus, image decoding program, image decoding method, image encoding apparatus, image encoding program, and image encoding method |
US7792192B2 (en) * | 2004-11-19 | 2010-09-07 | Analog Devices, Inc. | System and method for sub-pixel interpolation in motion vector estimation |
US7466867B2 (en) * | 2004-11-26 | 2008-12-16 | Taiwan Imagingtek Corporation | Method and apparatus for image compression and decompression |
US7406053B2 (en) | 2004-12-13 | 2008-07-29 | Hewlett-Packard Development Company, L.P. | Methods and systems for controlling the number of computations involved in computing the allocation of resources given resource constraints |
US7817723B2 (en) | 2004-12-14 | 2010-10-19 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E. V. | Apparatus and method of optimizing motion estimation parameters for encoding a video signal |
US7671894B2 (en) * | 2004-12-17 | 2010-03-02 | Mitsubishi Electric Research Laboratories, Inc. | Method and system for processing multiview videos for view synthesis using skip and direct modes |
US8634413B2 (en) * | 2004-12-30 | 2014-01-21 | Microsoft Corporation | Use of frame caching to improve packet loss recovery |
WO2006078115A1 (en) | 2005-01-21 | 2006-07-27 | Samsung Electronics Co., Ltd. | Video coding method and apparatus for efficiently predicting unsynchronized frame |
US8514933B2 (en) | 2005-03-01 | 2013-08-20 | Qualcomm Incorporated | Adaptive frame skipping techniques for rate controlled video encoding |
KR100703770B1 (en) | 2005-03-25 | 2007-04-06 | 삼성전자주식회사 | Video coding and decoding using weighted prediction, and apparatus for the same |
US8718140B1 (en) * | 2005-05-12 | 2014-05-06 | Visualon, Inc. | Encoding video data |
US7529199B1 (en) | 2005-05-31 | 2009-05-05 | Cisco Technology, Inc. | System and method for resolving conflicts in proxy routing information associated with multicast distribution trees |
US20060285598A1 (en) | 2005-06-17 | 2006-12-21 | Jarno Tulkki | Apparatuses, computer program product and method for digital image quality improvement |
US20070009034A1 (en) | 2005-07-05 | 2007-01-11 | Jarno Tulkki | Apparatuses, computer program product, and method for digital image processing |
JP5020953B2 (en) | 2005-07-18 | 2012-09-05 | エレクトロニクス アンド テレコミュニケーションズ リサーチ インスチチュート | Predictive encoding / decoding apparatus and method using temporal and inter-view reference video buffer |
KR100746006B1 (en) | 2005-07-19 | 2007-08-06 | 삼성전자주식회사 | Method and apparatus for encoding and decoding in temporal direct mode hierarchical B structure adaptive |
US20080130988A1 (en) * | 2005-07-22 | 2008-06-05 | Mitsubishi Electric Corporation | Image encoder and image decoder, image encoding method and image decoding method, image encoding program and image decoding program, and computer readable recording medium recorded with image encoding program and computer readable recording medium recorded with image decoding program |
US8229983B2 (en) * | 2005-09-27 | 2012-07-24 | Qualcomm Incorporated | Channel switch frame |
US20070076982A1 (en) * | 2005-09-30 | 2007-04-05 | Petrescu Doina I | System and method for video stabilization |
TWI271106B (en) | 2005-10-25 | 2007-01-11 | Novatek Microelectronics Corp | Apparatus and method for motion estimation supporting multiple video compression standards |
WO2007053557A1 (en) | 2005-10-31 | 2007-05-10 | Cyberoptics Corporation | Electronics assembly machine with embedded solder paste inspection |
CA2633819C (en) | 2005-12-08 | 2016-12-06 | Vidyo, Inc. | Systems and methods for error resilience and random access in video communication systems |
CN1980334A (en) * | 2005-12-09 | 2007-06-13 | 英业达股份有限公司 | Video-picture composition code transmission method |
US8107537B2 (en) | 2006-02-02 | 2012-01-31 | Sharp Laboratories Of America, Inc. | Picture layer rate control for video encoding |
US20070199011A1 (en) | 2006-02-17 | 2007-08-23 | Sony Corporation | System and method for high quality AVC encoding |
US7924925B2 (en) | 2006-02-24 | 2011-04-12 | Freescale Semiconductor, Inc. | Flexible macroblock ordering with reduced data traffic and power consumption |
JP4466589B2 (en) * | 2006-03-06 | 2010-05-26 | 住友電気工業株式会社 | PON system and terminal device registration method |
US8750387B2 (en) * | 2006-04-04 | 2014-06-10 | Qualcomm Incorporated | Adaptive encoder-assisted frame rate up conversion |
US8184712B2 (en) * | 2006-04-30 | 2012-05-22 | Hewlett-Packard Development Company, L.P. | Robust and efficient compression/decompression providing for adjustable division of computational complexity between encoding/compression and decoding/decompression |
BRPI0714022A2 (en) | 2006-07-06 | 2012-12-04 | Thomson Licensing | method and apparatus for separating frame number and / or image order count (poc) for multi-view video encoding and decoding |
CN101491099B (en) | 2006-07-11 | 2011-09-21 | 汤姆森特许公司 | Methods and apparatus using virtual reference pictures |
EP2041984A4 (en) | 2006-07-17 | 2009-08-05 | Thomson Licensing | Method and apparatus for adapting a default encoding of a digital video signal during a scene change period |
EP2084669A4 (en) * | 2006-08-08 | 2009-11-11 | Digital Media Cartridge Ltd | System and method for cartoon compression |
CN102752597A (en) * | 2006-08-28 | 2012-10-24 | 汤姆森许可贸易公司 | Method and apparatus for determining expected distortion in decoded video blocks |
KR101356207B1 (en) * | 2006-10-13 | 2014-02-03 | 삼성전자주식회사 | / Method and apparatus for encoding /decoding data |
US20080115185A1 (en) | 2006-10-31 | 2008-05-15 | Microsoft Corporation | Dynamic modification of video properties |
US8923393B2 (en) | 2006-11-02 | 2014-12-30 | Qualcomm Incorporated | Apparatus and method of reduced reference frame search in video encoding |
KR101365567B1 (en) | 2007-01-04 | 2014-02-20 | 삼성전자주식회사 | Method and apparatus for prediction video encoding, and method and apparatus for prediction video decoding |
JP2008124772A (en) | 2006-11-13 | 2008-05-29 | Hitachi Ltd | Coding device and coding method |
KR100803611B1 (en) * | 2006-11-28 | 2008-02-15 | 삼성전자주식회사 | Method and apparatus for encoding video, method and apparatus for decoding video |
CA2676219C (en) * | 2007-01-23 | 2017-10-24 | Euclid Discoveries, Llc | Computer method and apparatus for processing image data |
US8837591B2 (en) * | 2007-01-26 | 2014-09-16 | Telefonaktiebolaget L M Ericsson (Publ) | Image block classification |
JP2008187694A (en) * | 2007-01-31 | 2008-08-14 | Matsushita Electric Ind Co Ltd | Image encoder and method thereof |
US10194175B2 (en) * | 2007-02-23 | 2019-01-29 | Xylon Llc | Video coding with embedded motion |
JPWO2008108372A1 (en) | 2007-03-05 | 2010-06-17 | 日本電気株式会社 | Weighted prediction information calculation method, apparatus, program, video encoding method, apparatus, and program |
US8494049B2 (en) * | 2007-04-09 | 2013-07-23 | Cisco Technology, Inc. | Long term reference frame management with error video feedback for compressed video communication |
US8310521B2 (en) * | 2007-04-30 | 2012-11-13 | Microsoft Corp. | Insertion of virtual video into live video |
WO2008137432A2 (en) * | 2007-05-01 | 2008-11-13 | Dyyno | Sharing of information and formatting information for transmission over a communication network |
US8917775B2 (en) | 2007-05-02 | 2014-12-23 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding and decoding multi-view video data |
KR100962696B1 (en) * | 2007-06-07 | 2010-06-11 | 주식회사 이시티 | Format for encoded stereoscopic image data file |
US8477852B2 (en) | 2007-06-20 | 2013-07-02 | Nvidia Corporation | Uniform video decoding and display |
KR20090004658A (en) | 2007-07-02 | 2009-01-12 | 엘지전자 주식회사 | Digital broadcasting system and method of processing data in digital broadcasting system |
JP5098081B2 (en) * | 2007-07-19 | 2012-12-12 | オリンパス株式会社 | Image processing method and image processing apparatus |
US8121197B2 (en) * | 2007-11-13 | 2012-02-21 | Elemental Technologies, Inc. | Video encoding and decoding using parallel processors |
KR101213704B1 (en) | 2007-12-05 | 2012-12-18 | 삼성전자주식회사 | Method and apparatus for video coding and decoding based on variable color format |
US8953685B2 (en) | 2007-12-10 | 2015-02-10 | Qualcomm Incorporated | Resource-adaptive video interpolation or extrapolation with motion level analysis |
US8189668B2 (en) | 2007-12-18 | 2012-05-29 | Vixs Systems, Inc. | Video codec with shared intra-prediction module and method for use therewith |
US8179976B2 (en) * | 2008-01-11 | 2012-05-15 | Apple Inc. | Control of video decoder for reverse playback operation |
US8275033B2 (en) * | 2008-01-15 | 2012-09-25 | Sony Corporation | Picture mode selection for video transcoding |
US9055301B2 (en) | 2008-03-18 | 2015-06-09 | Texas Instruments Incorporated | Changing motion estimation precision to maintain encoding within desired time |
EP2104105A1 (en) * | 2008-03-20 | 2009-09-23 | British Telecommunications Public Limited Company | Digital audio and video clip encoding |
WO2010005691A1 (en) | 2008-06-16 | 2010-01-14 | Dolby Laboratories Licensing Corporation | Rate control model adaptation based on slice dependencies for video coding |
US8908763B2 (en) * | 2008-06-25 | 2014-12-09 | Qualcomm Incorporated | Fragmented reference in temporal compression for video coding |
JP4978575B2 (en) * | 2008-06-25 | 2012-07-18 | 富士通株式会社 | Image coding method and image coding program in thin client system |
EP2150060A1 (en) * | 2008-07-28 | 2010-02-03 | Alcatel, Lucent | Method and arrangement for video encoding |
US8385404B2 (en) | 2008-09-11 | 2013-02-26 | Google Inc. | System and method for video encoding using constructed reference frame |
US8325796B2 (en) | 2008-09-11 | 2012-12-04 | Google Inc. | System and method for video coding using adaptive segmentation |
US8326075B2 (en) | 2008-09-11 | 2012-12-04 | Google Inc. | System and method for video encoding using adaptive loop filter |
JPWO2010035733A1 (en) | 2008-09-24 | 2012-02-23 | ソニー株式会社 | Image processing apparatus and method |
US8831087B2 (en) | 2008-10-06 | 2014-09-09 | Qualcomm Incorporated | Efficient prediction mode selection |
US8189666B2 (en) | 2009-02-02 | 2012-05-29 | Microsoft Corporation | Local picture identifier and computation of co-located information |
US9774882B2 (en) | 2009-07-04 | 2017-09-26 | Dolby Laboratories Licensing Corporation | Encoding and decoding architectures for format compatible 3D video delivery |
US7974233B2 (en) | 2009-07-29 | 2011-07-05 | Wiviu Technology Inc. | Systems and methods for transmitting and receiving data streams with feedback information over a lossy network |
US8976860B2 (en) | 2009-09-23 | 2015-03-10 | Texas Instruments Incorporated | Method and apparatus for determination of motion estimation search window area utilizing adaptive sliding window algorithm |
US8503528B2 (en) | 2010-09-15 | 2013-08-06 | Google Inc. | System and method for encoding video using temporal filter |
US9008181B2 (en) | 2011-01-24 | 2015-04-14 | Qualcomm Incorporated | Single reference picture list utilization for interprediction video coding |
US8965140B1 (en) * | 2011-01-31 | 2015-02-24 | Teradici Corporation | Method and apparatus for encoding mixed content image sequences |
US9154799B2 (en) | 2011-04-07 | 2015-10-06 | Google Inc. | Encoding and decoding motion via image segmentation |
US8638854B1 (en) | 2011-04-07 | 2014-01-28 | Google Inc. | Apparatus and method for creating an alternate reference frame for video compression using maximal differences |
WO2012178008A1 (en) | 2011-06-22 | 2012-12-27 | General Instrument Corporation | Construction of combined list using temporal distance |
US20140169449A1 (en) | 2011-07-05 | 2014-06-19 | Telefonaktiebolaget L M Ericsson (Publ) | Reference picture management for layered video |
US9451271B2 (en) | 2011-07-21 | 2016-09-20 | Blackberry Limited | Adaptive filtering based on pattern information |
US10277915B2 (en) | 2011-11-07 | 2019-04-30 | Qualcomm Incorporated | Signaling quantization matrices for video coding |
US9525861B2 (en) | 2012-03-14 | 2016-12-20 | Qualcomm Incorporated | Disparity vector prediction in video coding |
WO2013162980A2 (en) | 2012-04-23 | 2013-10-31 | Google Inc. | Managing multi-reference picture buffers for video data coding |
US9014266B1 (en) | 2012-06-05 | 2015-04-21 | Google Inc. | Decimated sliding windows for multi-reference prediction in video coding |
-
2008
- 2008-12-05 US US12/329,041 patent/US8385404B2/en active Active
-
2009
- 2009-09-10 KR KR1020117006212A patent/KR20110059853A/en not_active Application Discontinuation
- 2009-09-10 CN CN2009801357282A patent/CN102150429B/en active Active
- 2009-09-10 JP JP2011526953A patent/JP5362831B2/en active Active
- 2009-09-10 WO PCT/US2009/056448 patent/WO2010030732A2/en active Application Filing
- 2009-09-10 CA CA2736886A patent/CA2736886A1/en not_active Abandoned
- 2009-09-10 EP EP09813575A patent/EP2327212A4/en not_active Withdrawn
-
2012
- 2012-10-23 US US13/658,396 patent/US9374596B2/en active Active
-
2016
- 2016-06-20 US US15/186,800 patent/US10165306B2/en active Active
-
2018
- 2018-12-17 US US16/221,853 patent/US11375240B2/en active Active
-
2022
- 2022-06-08 US US17/834,972 patent/US20220303583A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US10165306B2 (en) | 2018-12-25 |
US20100061461A1 (en) | 2010-03-11 |
US9374596B2 (en) | 2016-06-21 |
WO2010030732A3 (en) | 2010-06-10 |
US20160309192A1 (en) | 2016-10-20 |
CN102150429B (en) | 2013-11-20 |
WO2010030732A2 (en) | 2010-03-18 |
KR20110059853A (en) | 2011-06-07 |
US11375240B2 (en) | 2022-06-28 |
JP2012502590A (en) | 2012-01-26 |
WO2010030732A9 (en) | 2010-11-04 |
US20220303583A1 (en) | 2022-09-22 |
EP2327212A2 (en) | 2011-06-01 |
CA2736886A1 (en) | 2010-03-18 |
US20130044817A1 (en) | 2013-02-21 |
US20190124363A1 (en) | 2019-04-25 |
CN102150429A (en) | 2011-08-10 |
US8385404B2 (en) | 2013-02-26 |
EP2327212A4 (en) | 2012-11-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP5362831B2 (en) | Video coding system and method using configuration reference frame | |
JP5467141B2 (en) | Scalable video coding with lower layer filtering | |
JP3072035B2 (en) | Two-stage video film compression method and system | |
US8275035B2 (en) | Video coding apparatus | |
US9392280B1 (en) | Apparatus and method for using an alternate reference frame to decode a video frame | |
JP4875007B2 (en) | Moving picture coding apparatus, moving picture coding method, and moving picture decoding apparatus | |
JP7015183B2 (en) | Image coding device and its control method and program | |
JP4632049B2 (en) | Video coding method and apparatus | |
EP3329678B1 (en) | Method and apparatus for compressing video data | |
KR101375667B1 (en) | Method and apparatus for Video encoding and decoding | |
US6697430B1 (en) | MPEG encoder | |
KR20150135457A (en) | Method for encoding a plurality of input images and storage medium and device for storing program | |
US6804299B2 (en) | Methods and systems for reducing requantization-originated generational error in predictive video streams using motion compensation | |
US8654844B1 (en) | Intra frame beating effect reduction | |
CN114793282A (en) | Neural network based video compression with bit allocation | |
JP4399794B2 (en) | Image coding apparatus and image coding method | |
US7809057B1 (en) | Methods for intra beating reduction in video compression | |
WO2010023782A1 (en) | Image display device, image recording and reproduction device, and image processing method | |
JP2007020216A (en) | Encoding apparatus, encoding method, filtering apparatus and filtering method | |
Son et al. | Enhanced Prediction Algorithm for Near-lossless Image Compression with Low Complexity and Low Latency | |
JP2020141376A (en) | Image encoding apparatus, control method thereof, and program | |
JP2005323252A (en) | Image encoding device and image decoding device | |
JP2007006533A (en) | Encoding apparatus, encoding method, filter processing apparatus and filter processing method |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20120730 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20130206 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20130212 |
|
A601 | Written request for extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A601Effective date: 20130501 |
|
A602 | Written permission of extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A602Effective date: 20130510 |
|
A601 | Written request for extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A601Effective date: 20130611 |
|
A602 | Written permission of extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A602Effective date: 20130618 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20130704 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20130820 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20130904 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 5362831Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150Free format text: JAPANESE INTERMEDIATE CODE: R150 |
|
RD02 | Notification of acceptance of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: R3D02 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
S533 | Written request for registration of change of name |
Free format text: JAPANESE INTERMEDIATE CODE: R313533 |
|
R350 | Written notification of registration of transfer |
Free format text: JAPANESE INTERMEDIATE CODE: R350 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |