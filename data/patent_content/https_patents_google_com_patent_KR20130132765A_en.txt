KR20130132765A - State-dependent query response - Google Patents
State-dependent query response Download PDFInfo
- Publication number
- KR20130132765A KR20130132765A KR1020137005771A KR20137005771A KR20130132765A KR 20130132765 A KR20130132765 A KR 20130132765A KR 1020137005771 A KR1020137005771 A KR 1020137005771A KR 20137005771 A KR20137005771 A KR 20137005771A KR 20130132765 A KR20130132765 A KR 20130132765A
- Authority
- KR
- South Korea
- Prior art keywords
- computing device
- response
- query
- output
- search
- Prior art date
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/438—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/248—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3325—Reformulation based on results of preceding query
- G06F16/3326—Reformulation based on results of preceding query using relevance feedback from the user, e.g. relevance feedback on documents, documents sets, document terms or passages
- G06F16/3328—Reformulation based on results of preceding query using relevance feedback from the user, e.g. relevance feedback on documents, documents sets, document terms or passages using graphical result space presentation or visualisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3329—Natural language query formulation or dialogue systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/3332—Query translation
- G06F16/3334—Selection or weighting of terms from queries, including natural language queries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/338—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/34—Browsing; Visualisation therefor
- G06F16/345—Summarisation for human users
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
- G06F16/638—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/9038—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9538—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/186—Templates
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/40—Processing or translation of natural language
- G06F40/58—Use of machine translation, e.g. for multi-lingual retrieval, for server-side translation for client devices or for real-time translation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L13/00—Speech synthesis; Text to speech systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/28—Constructional details of speech recognition systems
- G10L15/30—Distributed recognition, e.g. in client-server systems, for mobile phones or network applications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M1/00—Substation equipment, e.g. for use by subscribers
- H04M1/60—Substation equipment, e.g. for use by subscribers including speech amplifiers
- H04M1/6033—Substation equipment, e.g. for use by subscribers including speech amplifiers for providing handsfree use or a loudspeaker mode in telephone sets
- H04M1/6041—Portable telephones adapted for handsfree use
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M1/00—Substation equipment, e.g. for use by subscribers
- H04M1/72—Mobile telephones; Cordless telephones, i.e. devices for establishing wireless links to base stations without route selection
- H04M1/724—User interfaces specially adapted for cordless or mobile telephones
- H04M1/72448—User interfaces specially adapted for cordless or mobile telephones with means for adapting the functionality of the device according to specific conditions
- H04M1/72454—User interfaces specially adapted for cordless or mobile telephones with means for adapting the functionality of the device according to specific conditions according to context-related or environment-related conditions
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N1/00—Scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission; Details thereof
- H04N1/00002—Diagnosis, testing or measuring; Detecting, analysing or monitoring not otherwise provided for
- H04N1/00026—Methods therefor
- H04N1/00029—Diagnosis, i.e. identifying a problem by comparison with a normal state
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N1/00—Scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission; Details thereof
- H04N1/00002—Diagnosis, testing or measuring; Detecting, analysing or monitoring not otherwise provided for
- H04N1/00026—Methods therefor
- H04N1/00042—Monitoring, i.e. observation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04R—LOUDSPEAKERS, MICROPHONES, GRAMOPHONE PICK-UPS OR LIKE ACOUSTIC ELECTROMECHANICAL TRANSDUCERS; DEAF-AID SETS; PUBLIC ADDRESS SYSTEMS
- H04R29/00—Monitoring arrangements; Testing arrangements
- H04R29/004—Monitoring arrangements; Testing arrangements for microphones
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/225—Feedback of the input speech
Abstract
일반적으로, 본 명세서에서 설명된 내용(subject matter)은 검색 쿼리를 정의하는 사용자 입력을 수신하는 단계, 및 검색 쿼리를 서버 시스템으로 제공하는 단계를 위한 방법들, 시스템들, 및 프로그램 제품에 구현될 수 있다. 검색 쿼리에 응답하여 검색 엔진 시스템이 판단한 정보는 컴퓨팅 장치에서 수신된다. 컴퓨팅 장치는 제1 상태에 있는 것으로 식별되며, 적어도 정보의 일부를 청각적으로 출력하기 위한 제1 출력 모드가 선택된다. 제1 출력 모드는 제1 출력 모드 및 제2 출력 모드의 집합체로부터 선택된다. 제2 출력 모드는 컴퓨팅 장치가 제2 상태에 있는 것에 응답하여 선택되며, 정보의 적어도 일부를 시각적으로 출력하기 위한 것이며 정보의 적어도 일부를 청각적으로 출력하기 위한 것은 아니다. 정보의 적어도 일부는 청각적으로 출력된다.In general, the subject matter described herein may be implemented in methods, systems, and program products for receiving user input that defines a search query and providing the search query to a server system. Can be. Information determined by the search engine system in response to the search query is received at the computing device. The computing device is identified as being in a first state, and a first output mode for selecting at least a portion of the information audibly is selected. The first output mode is selected from the aggregate of the first output mode and the second output mode. The second output mode is selected in response to the computing device being in the second state and is for visually outputting at least a portion of the information and not for outputting at least a portion of the information. At least part of the information is output acoustically.
Description
본 문헌은 일반적으로 정보에 대한 컴퓨터화된(computerized) 검색을 수행하기 위한 기술들, 방법들, 및 메카니즘들(mechanisms)을 설명한다. This document generally describes techniques, methods, and mechanisms for performing computerized retrieval of information.
본 출원은 2010년 8월 6일에 출원되고, 상태-종속 쿼리 응답이라고 명명된, 미국 출원 제12/851,879호에 대한 우선권을 주장한다. 이 미국 출원은 본 출원에 참조로서 포함된다.This application claims priority to US application Ser. No. 12 / 851,879, filed August 6, 2010, and designated as state-dependent query response. This US application is incorporated herein by reference.
어플리케이션폰들 또는 스마트폰들(smartphones)과 같은, 특정한 모바일 컴퓨팅 장치들의 사용자들은 그들 장치들에 대하여 발화(spoken) 입력을 제공할 수 있다. 예를 들어, 사용자는 샌프란시스코(San Francisco) 내의 피자집들(pizza places)을 알아보는 검색 결과의 리스트를 제공받기 위하여 버튼을 누르고 쿼리(query) ＂샌프란시스코 피자집들＂을 발화한다. 또한 사용자는, 예를 들어, 물리적 또는 가상의 키보드를 이용한 문자 입력을 제공할 수 있다. 모바일 폰은 사용자에게 검색 결과들의 시각적 디스플레이를 제공하기 위한 디스플레이 장치를 포함할 수 있다. 또한 모바일 폰 사용자에게 청각적으로 정보를 제공하기 위한 하나 이상의 스피커들을 포함할 수 있다. 예를 들어, 스피커는 전화 통화(telephone call) 또는 음악으로부터 오디오를 출력할 수 있다.Users of certain mobile computing devices, such as application phones or smartphones, may provide a spoken input for those devices. For example, a user presses a button and fires a query “San Francisco Pizzerias” to be provided with a list of search results for finding pizza places in San Francisco. The user may also provide text input using, for example, a physical or virtual keyboard. The mobile phone can include a display device for providing a visual display of search results to a user. It may also include one or more speakers for providing audible information to the mobile phone user. For example, the speaker may output audio from a telephone call or music.
본 명세서는 상태-종속 쿼리 응답을 수행하기 위한 기술들, 방법들, 시스템들, 및 메카니즘들을 기술한다. 일 예에 있어서, 시스템은 모바일 컴퓨팅 장치의 맥락에 따라, 사용자에게 응답을 시각적으로, 청각적으로, 또는 둘 다(both) 제공할 지를 판단할 수 있다. 예를 들어, 모바일 컴퓨팅 장치의 사용자는 서버 시스템에 대하여 음성 또는 문자 쿼리를 제출하기 위하여 컴퓨팅 장치를 사용할 수 있다. 서버 시스템은 쿼리에 응답한 검색 결과들을 알아볼 수 있으며, 검색 결과들을 모바일 컴퓨팅 장치에 전송할 수 있다. 또한, 서버 시스템은 쿼리의 제출 이후에 사용자가 추가적인 사용자 입력을 제공하지 않아도 쿼리에 대한 대답을 제공하는 요약 쿼리 응답을 생성할 수 있다. 요약된 응답은 청각적으로 제공되도록 포맷될 수 있다 (예를 들어, 요약된 응답은 시각적으로 제공될 수 있는 것보다 짧고, 이야기하기에 알맞은(speakable) 산문체로 번역된 데이터를 가져 이해할 수 있는 방법에 따라 데이터 통신할 수 있다). 서버 시스템이 요약 쿼리 응답을 돌려보내고 모바일 컴퓨팅 장치가 기정의된(predefined) 상태에 있는 경우, 모바일 컴퓨팅 장치는 청각적으로 응답을 출력할 수 있다. 요약 쿼리 응답은 구글 원 박스(GOOGLE One Box) 검색 결과 내에 시각적으로 사용자에게 제공될 수 있는 것을 청각적으로 표현할 수 있다.This disclosure describes techniques, methods, systems, and mechanisms for performing state-dependent query responses. In one example, the system can determine whether to provide a response visually, audiographically, or both to the user, depending on the context of the mobile computing device. For example, a user of a mobile computing device can use the computing device to submit a voice or text query to a server system. The server system can retrieve the search results in response to the query and can send the search results to the mobile computing device. In addition, the server system may generate a summary query response that provides an answer to the query after the user submits the query without providing additional user input. The summarized response may be formatted to be presented audibly (eg, the summarized response may be shorter than it can be provided visually and understandable with translated data in spoken prose) Can communicate data). If the server system returns a summary query response and the mobile computing device is in a predefined state, the mobile computing device may acoustically output the response. The summary query response may audibly express what may be presented to the user visually within the Google One Box search results.
다양한 실시예들에 있어서, 만일 모바일 컴퓨팅 장치 내의 근접 센서가 근접 센서와 가까이에 물체가 있는 것을 감지하거나, 또는 부품 시장(aftermarket)의 스피커 및 마이크 시스템이 모바일 컴퓨팅 장치에 연결된다면, 모바일 컴퓨팅 장치는 기정의된 상태에 있는다. 예를 들어, 만일 장치가 사용자의 귀와 가까이 있거나 또는 특정한 타입의 도크 내에 있는 것으로 판단되면, (사용자가 스크린을 볼 수 없거나 그들의 시선을 길(road)에 둘 필요가 있기 때문에) 시스템은 청각적 출력이 요구되는 것으로 판단할 수 있고, 시각적 포맷 대신에 또는 그에 부가하여, 자동적으로 출력이 청각적 포맷에 있는 출력을 제공하도록 선택할 수 있다. 다양한 실시예들에 있어서, 검색 결과들은 시각적으로 출력되나, 청각적으로 출력되지 않는다. 다양한 실시예들에 있어서, 요약 쿼리 응답은 청각적으로 출력되는 것에 더하여 시각적으로 출력될 수 있다. In various embodiments, if a proximity sensor in the mobile computing device detects an object in proximity to the proximity sensor, or if an aftermarket speaker and microphone system is connected to the mobile computing device, the mobile computing device may Is in a predefined state. For example, if the device is determined to be close to the user's ear or in a particular type of dock, the system may output audio output (because the user cannot see the screen or need to keep their eyes on the road). This may be determined to be required, and instead of or in addition to the visual format, the output may automatically be selected to provide an output in the audio format. In various embodiments, the search results are visually output, but not acoustically. In various embodiments, the summary query response may be visually output in addition to the audio output.
일반적으로, 본 명세서에서 설명된 내용의 한 측면은 컴퓨터-판독 가능한 저장 매체에 실제로(tangibly) 내장되며, 프로세서가 동작들을 실행할 수 있도록 하는 명령들을 포함하는 컴퓨터 프로그램 제품에 구현될 수 있다. 동작들은, 컴퓨팅 장치에 의하여, 검색 쿼리를 정의하는 사용자 입력을 수신하는 단계, 및 상기 컴퓨팅 장치와 원격인 서버 시스템으로 상기 검색 쿼리를 제공하는 단계를 포함한다. 상기 동작들은, 컴퓨팅 장치에 의하여, 상기 검색 쿼리에 응답하여 상기 서버 시스템의 검색 엔진 시스템에서 판단한 정보를 수신하는 단계를 포함한다. 상기 동작들은, 컴퓨팅 장치에 의하여, 상기 컴퓨팅 장치가 제1 상태에 있는 것으로 식별하고, 이에 응답하여, 상기 정보의 적어도 일부를 청각적으로 출력하기 위한 제1 출력 모드를 선택하는 단계를 포함한다. 상기 제1 출력 모드는 상기 제1 출력 모드 및 제2 출력 모드를 포함하는 집합체(collection)로부터 선택된다. 상기 제2 출력 모드는 상기 컴퓨팅 장치가 상기 정보의 상기 적어도 일부를 청각적으로 출력하는 것이 아니라 시각적으로 출력하기 위한 제2 상태에 있는 것에 대한 응답으로 선택된다. 상기 동작들은, 상기 컴퓨팅 장치에 의하여 그리고 상기 식별의 결과로서, 상기 정보의 적어도 일부를 청각적으로 출력하는 단계를 포함한다. In general, one aspect of the subject matter described herein is tangibly embedded in a computer-readable storage medium and may be implemented in a computer program product that includes instructions that enable a processor to execute operations. The operations include receiving, by a computing device, user input defining a search query, and providing the search query to a server system remote from the computing device. The operations include receiving, by a computing device, information determined by a search engine system of the server system in response to the search query. The operations include, by a computing device, identifying the computing device as in a first state and, in response, selecting a first output mode for audibly outputting at least a portion of the information. The first output mode is selected from a collection comprising the first output mode and the second output mode. The second output mode is selected in response to the computing device being in a second state for visually outputting rather than audibly outputting the at least a portion of the information. The operations include audibly outputting at least a portion of the information by the computing device and as a result of the identification.
본 명세서에서 설명된 내용의 다른 측면은 컴퓨터에서 수행되는 방법에 대하여 구현될 수 있다. 상기 방법은, 서버 시스템에 의하여 그리고 컴퓨팅 장치로부터, 사용자에 의하여 상기 컴퓨팅 장치에 입력된 검색 쿼리를 수신하는 단계를 포함한다. 상기 방법은, 상기 서버 시스템에 의하여, 상기 검색 쿼리에 응답하여 문서들을 식별한 검색 결과들을 판단하는 단계를 포함한다. 상기 방법은, 상기 서버 시스템에 의하여, 상기 검색 쿼리에 응답한 하나 이상의 상기 문서들로부터의 정보에 기초하여, 상기 검색 쿼리에 응답한 요약 쿼리 응답을 생성하는 단계를 포함한다. 상기 요약 쿼리 응답은 상기 검색 결과들을 생성하는 데에 사용되는 템플릿과 상이한 템플릿에 기초하여 생성된다. 상기 방법은, 상기 서버 시스템에 의하여 그리고 상기 컴퓨팅 장치에 대하여, 상기 검색 결과들과 상기 요약 쿼리 응답을 제공하는 단계를 포함한다. 상기 검색 결과들과 요약된 쿼리 응답을 제공하는 것은, 상기 컴퓨팅 장치로 하여금 상기 컴퓨팅 장치가 제1 상태에 있는 것으로 판단하도록 하며, 이에 응답하여, 적어도 상기 요약 쿼리 응답을 청각적으로 출력하기 위한 제1 출력 모드를 선택하도록 한다. 상기 제1 모드는 상기 제1 출력 모드 및 제2 출력 모드의 집합체로부터 선택되며, 상기 제2 출력 모드는 상기 컴퓨팅 장치가 적어도 상기 검색 결과들을 시각적으로 출력하되 상기 요약 쿼리 응답은 청각적으로 출력하지 않도록 하는 제2 상태에 있는 것으로 판단된 것에 응답하여 선택된다. Other aspects of the subject matter described herein may be implemented with respect to a method performed on a computer. The method includes receiving a search query entered by the user by the server system and by the computing device. The method includes determining, by the server system, search results identifying documents in response to the search query. The method includes generating, by the server system, a summary query response in response to the search query based on information from one or more of the documents in response to the search query. The summary query response is generated based on a template different from the template used to generate the search results. The method includes providing, by the server system and to the computing device, the search results and the summary query response. Providing the query response summarized with the search results may cause the computing device to determine that the computing device is in a first state and, in response, at least to output at least the summary query response. 1 Select the output mode. The first mode is selected from a collection of the first output mode and the second output mode, wherein the second output mode allows the computing device to visually output at least the search results but not the summary query response. Selected in response to the determined being in the second state.
본 명세서에서 설명된 내용의 또 다른 측면은 컴퓨터 실행 시스템에 대하여 구현될 수 있다. 상기 시스템은 검색 쿼리에 응답한 서버 시스템 정보를 수신하는 검색 쿼리 인터페이스를 포함한다. 상기 정보는 (i) 상기 검색 쿼리에 응답하여 문서를 식별한 다수의 검색 결과들, 및 (ii) 상기 다수의 검색 결과들에 더하여, 그리고 상기 검색 쿼리에 응답한 문서의 콘텐츠로부터 생성되는 요약 쿼리 응답을 포함한다. 상기 시스템은 상기 컴퓨팅 장치가 제1 상태 또는 제2 상태에 있는지 여부를 식별하도록 프로그램 된 컴퓨팅 장치 상태 판단기를 포함한다. 상기 시스템은, 만일 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 판단되면 상기 다수의 검색 결과들의 저장된 시각적 표현(representation)를 출력하기 위하여 선택하거나, 만일 상기 컴퓨팅 장치가 상기 제2 상태에 있는 것으로 판단되면 상기 요약 쿼리 응답의 저장된 청각적 표현을 출력하기 위하여 선택하는 쿼리 결과 제시기를 포함한다. 상기 시스템은, 상기 쿼리 결과 제시기에 의하여 선택된 출력에 기초하여, 상기 다수의 검색 결과들의 시각적 표현과 상기 요약 쿼리 응답의 청각적 표현을 선택적으로 출력하기 위한 오디오 및 시각적 출력 장치들을 포함한다. Another aspect of the subject matter described herein may be implemented with respect to a computer implemented system. The system includes a search query interface for receiving server system information in response to a search query. The information is a summary query generated from (i) a plurality of search results identifying a document in response to the search query, and (ii) in addition to the plurality of search results and from the content of the document responsive to the search query. Include a response. The system includes a computing device state determiner programmed to identify whether the computing device is in a first state or a second state. The system selects to output a stored visual representation of the plurality of search results if the computing device is determined to be in the first state, or if the computing device is in the second state And a query result presenter for selecting to output the stored auditory representation of the summary query response. The system includes audio and visual output devices for selectively outputting a visual representation of the plurality of search results and an audio representation of the summary query response based on the output selected by the query result presenter.
이들 및 다른 구현예들(implementations)은 하나 이상의 아래의 특징들을 선택적으로 포함할 수 있다. 상기 검색 쿼리를 정의하는 상기 수신된 사용자 입력은 키보드와 함께 제공될 수 있다. 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것을 식별하는 단계는, 상기 컴퓨팅 장치의 사용자에 의하여 상기 컴퓨팅 장치가 설치된 외부 스피커 및 외부 마이크와 통신하는 것을 판단하는 단계를 포함할 수 있다. 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것을 판단하는 단계는, 상기 컴퓨팅 장치의 센서를 이용하여, 상기 컴퓨팅 장치에 의하여 인지되는 물체가 가까이에 있는지를 판단하는 단계를 포함할 수 있다. These and other implementations may optionally include one or more of the following features. The received user input defining the search query may be provided with a keyboard. Identifying that the computing device is in the first state may include determining, by a user of the computing device, communication with an external speaker and an external microphone on which the computing device is installed. The determining that the computing device is in the first state may include determining whether an object recognized by the computing device is near by using a sensor of the computing device.
상기 컴퓨팅 장치가 물체와 가까지 않지 않는 것으로 판단된 경우, 상기 컴퓨팅 장치는 상기 제2 상태에 있는 것으로 판단될 수 있다. 상기 컴퓨팅 장치는 상기 검색 쿼리를 정의하는 사용자 입력이 수신될 때에 상기 제2 상태에 있을 수 있다. 상기 정보는 상기 검색 쿼리에 응답하고, (a) 기정의된 단어들을 포함하는 문장 템플릿 및 (b) 상기 검색 쿼리에 응답하여 식별되는 문서로부터의 콘텐츠를 이용하여 구축되는 사람이 이해할 수 있는 산문 문체를 포함하는, 요약 쿼리 응답을 포함할 수 있다. If it is determined that the computing device is not close to the object, the computing device may be determined to be in the second state. The computing device may be in the second state when a user input defining the search query is received. The information can be understood by a prose stylistic in response to the search query and constructed using (a) a sentence template containing predefined words and (b) content from a document identified in response to the search query. It may include a summary query response, including.
상기 정보는 상기 검색 쿼리에 응답하여 각각 문서를 식별하는 다수의 검색 결과들을 포함할 수 있다. 상기 다수의 검색 결과들은 (a) 기정의된 단어들을 포함하는 문장 템플릿 및 (b) 상기 검색 쿼리에 응답하여 식별된 문서로부터의 콘텐츠를 이용하여 구축되는 사람이 이해할 수 있는 산문 문체를 포함하지 않을 수 있다. 상기 청각적 출력은 상기 사람이 이해할 수 있는 산문 문체에 기초할 수 있다. 상기 요약 쿼리 응답은 디스플레이 내에 시각적으로 출력될 수 있다. 상기 디스플레이는 사용자-선택 가능한 프롬프트를 포함할 수 있다. 상기 검색 결과들은 상기 프롬프트의 선택에 응답하여 디스플레이 될 수 있다. 상기 검색 결과들은 상기 프롬프트의 선택에 응답하여 청각적으로 출력되지 않을 수 있다. 상기 검색 결과들은 상기 청각적 출력 이후, 그리고 상기 프롬프트를 선택하는 사용자 입력을 수신하는 것에 응답하여 시각적으로 디스플레이 될 수 있다. The information may include a plurality of search results, each identifying a document in response to the search query. The plurality of search results may not include (a) a sentence template containing predefined words and (b) a prose grammar that is understandable to a person constructed using content from a document identified in response to the search query. Can be. The auditory output may be based on prose stylistic that the human understands. The summary query response may be visually output within the display. The display may include a user-selectable prompt. The search results may be displayed in response to the selection of the prompt. The search results may not be output acoustically in response to the selection of the prompt. The search results may be displayed visually after the audio output and in response to receiving a user input selecting the prompt.
상기 검색 결과들은 상기 프롬프트를 선택하는 사용자 입력을 수신하기 이전에는 시각적으로 디스플레이 되지 않을 수 있다. 상기 요약 쿼리 응답 및 상기 다수의 검색 결과들 모두의 시각적 디스플레이가 제공될 수 있다. 상기 요약 쿼리 응답은 상기 정보를 수신한 다음에 사용자 입력을 수신하지 않고도 청각적으로 출력될 수 있다. 상기 다수의 검색 결과들은 상기 정보를 수신한 이후에 상기 사용자 입력이 제공되지 않으면 청각적으로 출력되지 않을 수 있다. 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 식별하는 것은, 상기 검색 쿼리가 수신되었을 때에 상기 컴퓨팅 장치가 상기 제1 상태 또는 상기 제2 상태에 있었는지 여부에 종속되지 않을 수 있다. The search results may not be visually displayed before receiving a user input of selecting the prompt. A visual display of both the summary query response and the plurality of search results may be provided. The summary query response may be output acoustically after receiving the information without receiving user input. The plurality of search results may not be output acoustically if the user input is not provided after receiving the information. Identifying that the computing device is in the first state may not depend on whether the computing device was in the first state or the second state when the search query was received.
상기 요약 쿼리 응답을 생성하는 단계는 상기 하나 이상의 문서들 내의 하나 이상의 기지정된 영역들로부터 데이터를 선택하는 단계, 및 기지정된 단어들 및 상기 하나 이상의 기지정된 영역들로부터의 데이터 양자로부터 구축된 사람이 이해할 수 있는 문장을 생성하기 위하여, 상기 정보를 기정의된 단어들을 포함하는 템플릿의 슬롯들로 위치시키는 단계를 포함할 수 있다. 상기 요약 쿼리 응답은, 그를 위하여 상기 요약 쿼리 응답이 생성되는, 검색 쿼리들의 정의된 리스트 내에 상기 검색 쿼리가 있는 것을 식별하는 것에 응답하여 , 상기 서버 시스템에 의하여 생성될 수 있다. 상기 요약 쿼리 응답은, 그로부터 상기 요약 쿼리 응답이 구축되는, 하나 이상의 문서들이 결정된 검색 결과인 것을 식별하는 것에 응답하여 상기 서버 시스템에 의하여 생성될 수 있다. Generating the summary query response includes selecting data from one or more predetermined regions in the one or more documents, and a person constructed from both known words and data from the one or more predetermined regions. In order to generate an understandable sentence, the method may include placing the information into slots of a template including predefined words. The summary query response may be generated by the server system in response to identifying that the search query is within a defined list of search queries for which the summary query response is generated. The summary query response may be generated by the server system in response to identifying that one or more documents from which the summary query response is built are the determined search results.
상기 쿼리 결과 제시기는, 상기 컴퓨팅 장치가 상기 제1 상태에 있는 경우, 상기 요약 쿼리 응답의 청각적 표현을 출력하도록 선택하지 않을 수 있다. 상기 쿼리 결과 제시기는, 상기 컴퓨팅 장치가 상기 제2 상태에 있는 경우, 상기 요약 쿼리 응답의 시각적 표현을 출력하도록 선택할 수 있다. 상기 컴퓨팅 장치가 (i) 제2 상태에 있고 (ii) 상기 요약 쿼리 응답의 청각적 표현을 출력하는 경우, 상기 시각적 출력 장치는 상기 검색 결과들 또는 상기 요약 쿼리 응답의 시각적 표현을 출력하지 않을 수 있다. The query result presenter may not choose to output an auditory representation of the summary query response when the computing device is in the first state. The query result presenter may select to output a visual representation of the summary query response when the computing device is in the second state. If the computing device is (i) in a second state and (ii) outputs an audio representation of the summary query response, the visual output device may not output the search results or the visual representation of the summary query response. have.
아래의 기재에서 설명된 구현예들의 대안으로서, 본 개시는 또한 다음의 구현예들을 포함한다:As an alternative to the embodiments described in the following description, the present disclosure also includes the following embodiments:
구현예 1은 컴퓨터-판독 가능한 저장 매체에 실제로 내정되며, 프로세서에 의하여 실행될 때 동작들을 수행하도록 하는 명령들을 포함하는 컴퓨터 프로그램 제품에 관한 것이다. 상기 동작들은: 컴퓨팅 장치에 의하여, 검색 쿼리를 정의하는 사용자 입력을 수신하는 단계, 및 상기 컴퓨팅 장치와 원격인 서버 시스템으로 상기 검색 쿼리를 제공하는 단계; 상기 컴퓨팅 장치에 의하여, 상기 검색 쿼리에 응답하여 상기 서버 시스템의 검색 엔진 시스템으로부터 판단된 정보를 수신하는 단계; 상기 컴퓨팅 장치에 의하여, 상기 컴퓨팅 장치가 제1 상태에 있는 것으로 식별하고, 이에 응답하여 적어도 상기 정보의 일부를 청각적으로 출력하기 위한 제1 출력 모드를 선택하는 단계; 및 상기 컴퓨팅 장치에 의하여 그리고 상기 식별하는 단계의 결과로서, 상기 정보의 상기 적어도 일부를 출력하는 단계를 포함한다. 여기서 상기 제1 출력 모드는 상기 제1 출력 모드 및 제2 출력 모드의 집합체로부터 선택되며, 상기 제2 출력 모드는, 상기 컴퓨팅 장치가 제2 상태에 있는 것으로 판단되는 것에 응답하여 선택되며, 상기 정보의 적어도 일부를 시각적으로 출력하기 위한 것이고 상기 정보의 상기 적어도 일부를 청각적으로 출력하지 않는다.
구현예 2는 구현예 1의 상기 컴퓨터 프로그램 제품에 관련되며, 상기 상기 검색 쿼리를 정의하는 상기 수신된 사용자 입력은 키보드와 함께 제공된다.Embodiment 2 relates to the computer program product of
구현예 3은 구현예 1 내지 2 중 어느 하나의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 식별하는 단계는, 상기 컴퓨팅 장치의 사용자에 의하여 상기 컴퓨팅 장치가 외부 스피커 및 외부 마이크와 통신하는 상태에 있는 것을 판단하는 단계를 포함한다. Embodiment 3 relates to the computer program product of any one of
구현예 4는 구현예 1 내지 4 중 어느 하나의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 식별하는 단계는, 상기 컴퓨팅 장치의 센서를 이용하여, 상기 컴퓨팅 장치에 의하여 인식된 물체와 상기 컴퓨팅 장치가 가까이 있는 것을 판단하는 단계를 포함한다. Embodiment 4 relates to the computer program product of any one of
구현예 5는 구현예 4의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 컴퓨팅 장치가 물체와 가까이 있지 않는 것으로 판단되는 경우 상기 컴퓨팅 장치는 상기 제2 상태에 있는 것으로 판단되며, 상기 검색 쿼리를 정의하는 상기 사용자 입력이 수신되었을 경우, 상기 컴퓨팅 장치는 상기 제2 상태에 있는 것으로 판단된다. Embodiment 5 relates to the computer program product of Embodiment 4, wherein if it is determined that the computing device is not in proximity to an object, the computing device is determined to be in the second state, and wherein the computing query defines the search query If a user input is received, the computing device is determined to be in the second state.
구현예 6은 구현예 1 내지 5의 어느 하나의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 정보는 (i) 상기 검색 쿼리에 응답하며, (a) 기정의된 단어들을 포함하는 문장 템플릿; 및 (ii) 상기 검색 쿼리에 응답한 문서들을 각각 식별하는 다수의 검색 결과들을 사용하여 구축된, 사람이 이해할 수 있는 산문 문체를 포함한다. 상기 다수의 검색 결과들은 (a) 기정의된 단어들을 포함하는 문장 템플릿 및 (b) 상기 검색 쿼리에 응답하여 식별되는 문서들로부터의 콘텐츠를 사용하여 구축되는, 사람이 이해할 수 있는 산문 문장을 포함하지 않는다. Embodiment 6 relates to the computer program product of any one of
구현예 7은 구현예 6의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 청각적 출력은 상기 사람이 이해할 수 있는 산문 문체에 기초한다. Embodiment 7 relates to the computer program product of Embodiment 6, wherein the auditory output is based on a prose style that the human may understand.
구현예 8은 구현예 7의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 요약 쿼리 응답은 디스플레이 내에 시각적으로 출력된다. 상기 디스플레이는 사용자-선택 가능한 프롬프트를 포함하며, 상기 동작들은, 상기 프롬프트의 선택에 응답하여, 상기 검색 결과들을 디스플레이 하는 단계를 더 포함한다. Implementation 8 relates to the computer program product of Embodiment 7 wherein the summary query response is visually output within the display. The display includes a user-selectable prompt and the operations further comprise displaying the search results in response to the selection of the prompt.
구현예 9는 구현예 8의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 검색 결과는, 상기 프롬프트의 선택에 응답하여, 청각적으로 출력되지 않는다. Embodiment 9 relates to the computer program product of Embodiment 8, wherein the search results are not output acoustically in response to the selection of the prompt.
구현예 10은 구현예 8의 컴퓨터 프로그램 제품과 관련되며, 상기 동작들은, 상기 청각적 출력 이후에 그리고 상기 프롬프트를 선택하는 사용자 입력을 수신함에 응답하여 상기 검색 결과들을 시각적으로 디스플레이 하는 단계를 더 포함하며, 상기 검색 결과들은, 상기 프롬프트를 선택하는 사용자 입력을 수신하기 전에는 시각적으로 디스플레이 되지 않는다.Implementation 10 relates to the computer program product of Embodiment 8, wherein the operations further comprise visually displaying the search results after the audio output and in response to receiving a user input selecting the prompt. The search results are not visually displayed until the user input for selecting the prompt is received.
구현예 11은 구현예 7의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 동작들은 상기 요약 쿼리 응답 및 상기 다수의 검색 결과들 양자의 시각적 디스플레이를 제공하는 단계를 더 포함한다. 상기 요약 쿼리 응답은 상기 정보를 수신한 다음에 사용자 입력을 수신하지 않아도 청각적으로 출력되나, 상기 다수의 검색 결과들은 상기 정보를 수신한 다음에 사용자 입력이 없으면 청각적으로 출력되지 않는다. Implementation 11 relates to the computer program product of Embodiment 7, wherein the operations further comprise providing a visual display of both the summary query response and the plurality of search results. The summary query response is output acoustically even after receiving the information without receiving a user input, but the plurality of search results are not output acoustically if there is no user input after receiving the information.
구현예 12는 구현예 1 내지 4 및 6 내지 11 중 어느 하나의 상기 컴퓨터 프로그램 제품과 관련되며, 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 식별하는 것은, 상기 검색 쿼리가 수신되었을 때에 상기 컴퓨팅 장치가 상기 제1 상태 또는 상기 제2 상태에 있었는지에 종속되지 않는다. Embodiment 12 relates to the computer program product of any of
구현예 13은 컴퓨터-실행의 방법에 관련되며, 상기 방법은: 서버 시스템에 의하여 그리고 컴퓨팅 장치로부터, 사용자에 의하여 상기 컴퓨팅 장치로 입력되는 검색 쿼리를 수신하는 단계; 서버 시스템에 의하여, 상기 검색 쿼리에 응답한 문서들을 식별하는 검색 결과들을 판단하는 단계; 서버 시스템에 의하여, 상기 검색 쿼리에 응답하고, 상기 검색 쿼리에 응답한 하나 이상의 문서들로부터의 정보에 기초하여 요약 쿼리 응답을 생성하는 단계 (상기 요약 쿼리 응답은 상기 검색 쿼리를 생성하는 데에 사용되는 템플릿과 상이한 템플릿에 기초함); 및 상기 서버 시스템에 의하여 그리고 상기 컴퓨팅 장치에 대하여, 상기 검색 결과들 및 요약 쿼리 응답을 제공하는 단계를 포함한다. 상기 검색 결과들 및 요약 쿼리 응답을 제공함에 따라 상기 컴퓨팅 장치는: (i) 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 판단하고, 이에 응답하여, 적어도 상기 요약 쿼리 응답을 청각적으로 출력하기 위한 제1 출력 모드를 선택하고 (상기 제1 모드는 상기 제1 출력 모드 및 상기 제2 출력 모드의 집합체로부터 선택되며, 상기 제2 출력 모드는 상기 컴퓨팅 장치가 제2 상태에 있는 것에 대한 응답으로 선택되며, 상기 제2 출력 모드는 적어도 상기 검색 결과들을 시각적으로 출력하고 상기 요약 쿼리 응답을 청각적으로 출력하지 않음), 그리고 (ii) 적어도 상기 요약 쿼리 응답을 청각적으로 출력한다.Implementation 13 relates to a method of computer-implementing, the method comprising: receiving a search query entered by a user by a user and by a server system; Determining, by a server system, search results identifying documents that have been answered in the search query; Generating, by a server system, a summary query response based on information from one or more documents in response to the search query, wherein the summary query response is used to generate the search query. Based on a template different from that of the template); And providing, by the server system and to the computing device, the search results and a summary query response. In providing the search results and a summary query response, the computing device is configured to: (i) determine that the computing device is in the first state and, in response, at least to audibly output the summary query response. Select a first output mode (the first mode is selected from an aggregate of the first output mode and the second output mode, the second output mode being selected in response to the computing device being in a second state) The second output mode visually outputs at least the search results and does not output the summary query response aurally), and (ii) at least audibly outputs the summary query response.
구현예 14는 구현예 13의 상기 방법과 관련되며, 상기 요약 쿼리 응답을 생성하는 단계는 상기 하나 이상의 문서 내의 하나 이상의 기지정된 영역들로부터 데이터를 선택하는 단계, 및 기정의된 단어들 및 상기 하나 이상의 기지정된 영역들로부터의 데이터 양자로부터 구축된 사람이 이해할 수 있는 문장을 생성하기 위하여, 상기 기지정된 단어들을 포함하는 템플릿 내의 슬롯에 상기 정보를 위치시키는 단계를 포함한다.Embodiment 14 relates to the method of Embodiment 13, wherein generating the summary query response comprises selecting data from one or more predetermined regions in the one or more documents, and predefined words and the one Positioning the information in a slot in a template containing the predetermined words to produce a human understandable sentence constructed from both data from the above known areas.
구현예 15는 구현예 13 내지 14 중 어느 하나의 상기 방법과 관련되며, 상기 요약 쿼리 응답은, 상기 검색 쿼리들에 대하여 생성되며, 검색 쿼리들의 정의된 리스트 내에 상기 검색 쿼리가 있다는 것을 식별하는 것에 응답하여 상기 서버 시스템에 의하여 생성된다.Embodiment 15 relates to the method of any of Embodiments 13 to 14, wherein the summary query response is generated for the search queries, to identify that the search query is within a defined list of search queries. In response, generated by the server system.
구현예 16은 구현예 13 내지 14 중 어느 하나의 상기 방법과 관련되며, 상기 요약 쿼리 응답은, 상기 요약 쿼리 응답을 구축할 수 있는, 하나 이상의 문서들이 판단된 검색 결과인 것을 식별하는 것에 응답하여 상기 서버 시스템에 의하여 생성된다. Embodiment 16 relates to the method of any of Embodiments 13 to 14, wherein the summary query response is in response to identifying that one or more documents are determined search results capable of building the summary query response. It is generated by the server system.
구현예 17은 컴퓨터-실행 시스템과 관련되며, 컴퓨터 실행-시스템은: 검색 쿼리에 응답한 정보를 서버 시스템으로부터 수신하는 검색 쿼리 인터페이스 (상기 정보는 (i) 검색 쿼리에 응답한 문서들을 식별하는 다수의 검색 결과들, 및 (ii) 상기 다수의 검색 결과들에 더하여, 상기 검색 쿼리에 응답한 문서들의 콘텐츠로부터 생성되는 요약 쿼리 응답을 포함함); 상기 컴퓨팅 장치가 제1 상태 또는 제2 상태에 있는지 여부를 식별하도록 프로그램되는 컴퓨팅 장치 상태 판단기; 만일 상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 판단되면 상기 다수의 검색 결과들의 저장된 시각적 표현을 출력하도록 선택하고, 상기 컴퓨팅 장치가 상기 제2 상태에 있는 것으로 판단되면 상기 요약 쿼리 응답의 저장된 청각적 표현을 출력하도록 선택하는 쿼리 결과 제시기; 및 상기 쿼리 결과 제시기에 의하여 선택된 상기 출력에 기초하여 상기 다수의 검색 결과들의 시각적 표현 및 상기 요약 쿼리 응답의 청각적 표준을 선택적으로 출력하기 위한 오디오 및 비주얼 출력 장치들을 포함한다.Implementation 17 relates to a computer-executable system, the computer-implementing system comprising: a search query interface for receiving information from a server system in response to a search query, the information comprising (i) a plurality of documents that identify a search query; Search results, and (ii) in addition to the plurality of search results, a summary query response generated from the content of documents responsive to the search query; A computing device state determiner programmed to identify whether the computing device is in a first state or a second state; If it is determined that the computing device is in the first state, it is selected to output a stored visual representation of the plurality of search results; and if it is determined that the computing device is in the second state, the stored auditory of the summary query response A query result presenter that selects to output the representation; And audio and visual output devices for selectively outputting a visual representation of the plurality of search results and an auditory standard of the summary query response based on the output selected by the query result presenter.
구현예 18은 구현예 17의 상기 시스템과 관련되며, 상기 쿼리 결과 제시기는, 상기 컴퓨팅 장치가 상기 제1 상태에 있는 경우, 상기 요약 쿼리 응답의 상기 청각적 표현을 출력하도록 선택하지 않는다.Implementation 18 relates to the system of implementation 17, wherein the query result presenter does not select to output the auditory representation of the summary query response when the computing device is in the first state.
구현예 19는 구현예 17 내지 18 중 어느 하나의 상기 시스템과 관련되며, 상기 쿼리 결과 제시기는 추가적으로, 상기 컴퓨팅 장치가 상기 제2 상태에 있는 경우, 상기 요약 쿼리 응답의 시각적 표현을 출력하도록 선택한다.Implementation 19 relates to the system of any of Embodiments 17-18, wherein the query result presenter additionally selects to output a visual representation of the summary query response when the computing device is in the second state. .
구현예 20은 구현예 17 내지 18 중 어느 하나의 상기 시스템과 관련되며, 상기 비주얼 출력 장치는, 상기 컴퓨팅 장치가 (i) 상기 제2 상태에 있고 (ii) 상기 요약 쿼리 응답의 상기 청각적 표현을 출력하는 경우, 상기 검색 결과들 또는 상기 요약 쿼리 응답의 시각적 표현을 출력하지 않는다. Embodiment 20 relates to the system of any of Embodiments 17 to 18, wherein the visual output device is configured such that the computing device is (i) in the second state and (ii) the auditory representation of the summary query response. In the case of outputting, the visual representation of the search results or the summary query response is not output.
다른 구현예들은 컴퓨터-판독 가능한 저장 매체 내에 내장되어 상술한 동작들을 수행하는 방법들을 포함한다. 다른 구현예들은, 하나 이상의 처리 장치들에 의하여 수행되었을 경우, 상술한 방법들에 따른 동작을을 수행하는 명령들을 저장하는, 컴퓨터-판독 가능한 저장 장치들을 포함한다. 다른 구현예들은, 하나 이상의 처리 장치들을 이용하여 상기 동작들을 수행하도록 구성된, 컴퓨터- 판독 가능한 저장 장치 또는 저장 매체를 포함하는 시스템들 및 장비들(apparatus)을 포함한다. Other implementations include methods embedded in a computer-readable storage medium for performing the above-described operations. Other implementations include computer-readable storage devices that, when performed by one or more processing devices, store instructions for performing an operation in accordance with the methods described above. Other implementations include systems and apparatuses that include a computer-readable storage device or storage medium configured to perform the operations using one or more processing devices.
어떤 경우에 있어서, 특정한 실시예들은 하나 이상의 아래의 장점들을 달성할 수 있다. 만일 모바일 컴퓨팅 장치가 청각적 출력이 이로운 상태에 있는 것으로 판단되면, 쿼리에 대한 응답의 일부는 청각적으로 사용자에게 출력될 수 있다. 모바일 컴퓨팅 장치의 디스플레이를 응시하는 일이 없이 사용자의 현재 업무에 대한 시선을 유지시킬 수 있음에 따라 사용자 안전이 향상될 수 있다. 청각적으로 출력된 정보는 특별하게 관련된 쿼리 응답의 일부일 수 있으며, 따라서 사용자는 쿼리에 응답한 모든 정보가 청각적으로 출력되어 압도되지(overwhelmed with) 않을 수 있다. In some cases, certain embodiments may achieve one or more of the following advantages. If the mobile computing device determines that the auditory output is in a beneficial state, then a portion of the response to the query may be auditoryly output to the user. User safety can be improved by keeping an eye on the user's current work without staring at the display of the mobile computing device. The auditory output information may be part of a particularly relevant query response, so that the user may not be overwhelmed with all the information that responded to the query.
하나 이상의 실시예에 대한 세부 사항들은 이하의 기재와 첨부된 도면에서 설명된다. 다른 특징들, 목적들, 및 장점들은 본 기재 및 도면, 그리고 청구항들로부터 명백해질 것이다.The details of one or more embodiments are set forth in the following description and the annexed drawings. Other features, objects, and advantages will be apparent from the description and drawings, and from the claims.
도 1은 상태-종속 쿼리 응답을 개념적으로 나타낸 도면이다.
도 2는 상태-종속 쿼리 응답을 수행하기 위한 흐름도이다.
도 3은 컴퓨팅 장치에 대한 청각적 출력 이행을 도시한 도면이다.
도 4는 컴퓨팅 장치에 대한 시각적 출력 이행을 도시한 도면이다.
도 5는 상태-종속 쿼리 응답을 수행하기 위한 예시적인 시스템이다.
도 6은 본 명세서에서 설명된 시스템들과 방법들을 구현하기 위하여 사용될 수 있는 시스템의 개념도이다.
도 7은 본 명세서에서 설명된 시스템들 및 방법들을 구현하는 데에, 클라이언트 또는 서버 또는 복수의 서버들로서, 사용될 수 있는 컴퓨팅 장치들의 블록도이다.
다양한 도면들에서 동일한 참조부호들은 동일한 요소들을 지시한다. 1 conceptually illustrates a state-dependent query response.
2 is a flow diagram for performing a state-dependent query response.
3 illustrates an acoustic output implementation for a computing device.
4 illustrates a visual output implementation for a computing device.
5 is an example system for performing a state-dependent query response.
6 is a conceptual diagram of a system that may be used to implement the systems and methods described herein.
7 is a block diagram of computing devices that may be used as a client or server or a plurality of servers in implementing the systems and methods described herein.
Like reference symbols in the various drawings indicate like elements.
본 문헌은 일반적으로 상태-종속 쿼리 응답을 설명한다. 컴퓨팅 장치의 사용자는 컴퓨팅 장치에 문자 또는 음성 쿼리를 제공할 수 있다. 컴퓨팅 장치는 서버 시스템에 쿼리를 제출할 수 있고, 서버 시스템은 쿼리에 응답한 문서들을 찾아보기 위한 검색 엔진을 포함한다. 또한 서버 시스템은 쿼리에 응답하여 찾아낸 문서들의 하나 이상에서의 데이터에 기초한 요약 쿼리 응답(summarized query response)을 생성할 수 있다. 찾아낸 문서들에 상응하는 요약 쿼리 응답과 검색 결과들은 컴퓨팅 장치에 전송될 수 있다. This document generally describes a state-dependent query response. The user of the computing device may provide a text or voice query to the computing device. The computing device may submit a query to the server system, which includes a search engine to look up the documents that responded to the query. The server system may also generate a summarized query response based on data in one or more of the documents found in response to the query. Summary query responses and search results corresponding to the found documents may be sent to the computing device.
컴퓨팅 장치는 그 장치가 정보를 청각적으로 제공하기 위한 상태에 있는 지를 판단할 수 있다. 만일 그렇다면, 요약 쿼리 응답은 모바일 컴퓨팅 장치의 사용자에게 청각적으로 출력될 수 있다. 만일 그렇지 않다면, 요약 쿼리 응답은 모바일 컴퓨팅 장치의 사용자에게 시각적으로 출력된다 (청각적으로 출력되지 않을 수 있다). 검색 결과들은, 자동적으로 또는 검색 결과들의 제시(presentation)를 요청하기 위한 사용자-입력을 수신함에 따라, 청각적으로 또는 시각적으로 나타내어질 수 있다.The computing device may determine whether the device is in a state for providing information audibly. If so, the summary query response may be audibly output to the user of the mobile computing device. If not, the summary query response is visually output (may not be audio) to the user of the mobile computing device. The search results may be presented audibly or visually, either automatically or upon receiving a user-input to request a presentation of the search results.
실례(illustration)에 있어서, 모바일 폰의 사용자인 수잔(Susan)은 회사에서 집으로 오는 버스를 탄다. 수잔은 버스의 확성기(loudspeakers)를 통하여 재생되고 있는 노래의 제목을 맞추는 것에 흥미가 있을 수 있다. 수잔은 그녀의 전화를 꺼내어(pulls out), 웹 쿼리를 타이핑하기 위한 버튼을 선택하고, ＂가사 you could travel the world but nothing comes close to the golden coast＂를 타이핑한다. In the illustration, Susan, a mobile phone user, takes a bus from home to work. Susan may be interested in matching the title of a song being played through loudspeakers on the bus. Susan pulls her phone out, selects a button to type in a web query, and types the words you could travel the world but nothing comes close to the golden coast.
수잔의 전화는 검색 엔진 시스템에 쿼리를 전송하고, 검색 엔진은 쿼리에 응답한 웹 페이지를 찾아내어, 상응하는 검색 결과를 선택한다. 검색 결과들은 수잔의 모바일 폰으로 전송되어 검색 결과들이 시각적으로 디스플레이 된다. 디스플레이 된 각각의 검색 결과들은 상응하는 웹 페이지의 제목, 웹 페이지의 본문의 텍스트의 일부분, 웹 페이지로의 링크, 및 웹 페이지를 위한 URI(uniform resource identifier)를 포함한다. 수잔은, 검색 결과들의 제목들로부터, 버스 스피커를 통하여 재생되고 있는 노래가 케이티 페리(Katy Perry)의 ＂California Gurls＂라고 말할 수 있다. Susan's phone sends a query to the search engine system, which finds the web page that responded to the query and selects the corresponding search result. The search results are sent to Susan's mobile phone and the search results are visually displayed. Each search result displayed includes the title of the corresponding web page, a portion of the text of the body of the web page, a link to the web page, and a uniform resource identifier (URI) for the web page. From the titles of the search results, Susan can say that the song being played through the bus speaker is Katy Perry's “California Gurls”.
수잔은 버스의 스피커를 통하여 그 날의 주식 시장이 크게 등락했다는 DJ 방송을 듣는다. 수잔은 그녀의 주식은 어떠하였는지에 대하여 흥미가 있다. 따라서, 수잔은 그녀의 모바일 컴퓨팅 장치에 의하여 디스플레이 되고 있는 쿼리-입력 텍스트 박스를 선택하고, 장치의 키보드를 이용하여 쿼리 ＂TGT 주식＂을 제출한다. 여기서 TGT는 TARGET CORP의 티커 심볼(ticker symbol)이다. 쿼리의 제출에 응답하여, 수잔의 모바일 폰은 웹 사이트들에 대한 검색 결과들의 리스트를 디스플레이 한다. 그러나, 검색 결과의 맨 위에는, TARGET CORP. 주식에 관련된 요약 쿼리 응답이 있다. Susan hears a DJ on the bus's speaker that the stock market of the day has fluctuated greatly. Susan is interested in how her stock was. Accordingly, Susan selects the query-entry text box that is being displayed by her mobile computing device and submits the query “TGT Stock” using the device's keyboard. Where TGT is a ticker symbol of TARGET CORP. In response to the submission of the query, Susan's mobile phone displays a list of search results for the web sites. However, at the top of the search results, TARGET CORP. There is a summary query response related to the stock.
요약 쿼리 응답은 그날 하루 전체의 주식 시세의 시각적 그래프, 주식의 현재 가격, 주식의 개장 순가격(opening price), 개장 순가격으로부터 주식의 백분율 변화, 하루 동안 주식의 최고가 및 최저가, 하루 동안 주식 거래량, 및 회사의 시가 총액(market capitalization)을 포함할 수 있다. 요약 쿼리 응답의 일부 정보는 서버 시스템에 의하여 생성될 수 있으며, 이들 일부 정보는 쿼리에 대하여 고유할 수 있다 (예를 들어, 모든 주식 쿼리들 사이에서 막대 그래프는 같지 않으며, 제3 자 웹 사이트로부터의 데이터에 근거하지 않으면서, 그래프 그 자체로 서버 시스템에 의하여 생성된 것일 수 있다).The summary query response is a visual graph of stock quotes throughout the day, the current price of the stock, the opening price of the stock, the percentage change in the stock from the opening net price, the highest and lowest stock prices for the day, and stock volume for the day. , And market capitalization of the company. Some information in the summary query response may be generated by the server system, and some of this information may be unique for the query (eg, the bar graph is not the same among all stock queries, and from a third party website). The graph itself may be generated by the server system without being based on the data of < RTI ID = 0.0 >
요약 쿼리 응답은 검색 결과들과 달리 시각적으로 나타날 수 있다. 요약의 구조적인 제시를 식별하는 템플릿에 근거하여 요약 쿼리 응답이 생성될 수 있으며, 여기서 요약의 구조적인 제시는 검색 결과들의 구조적인 제시와는 다르다. 요약 쿼리 응답의 디스플레이 (예를 들어, 그래프의 특징, 및 주식 시세)는 리스트 내에 디스플레이 되는 검색 결과들에 의하여 찾아내어진 하나 이상의 문서들의 콘텐츠에 의하여 정의될 수 있다. 따라서, 요약 쿼리 응답은 쿼리에 특별하게 관련된 정보를 디스플레이 하며, 검색 결과에 응답하여 수잔에게 디스플레이 되는 첫 번째 화면에 있을 수 있다. 수잔은 그렇지 않으면 이러한 정보를 보기 위하여 검색 결과를 선택할 필요가 있을 수 있다. 대신에, 정보는 검색 결과 페이지의 맨 위에 읽기-쉬운(easy-to-read) 형태로 나타날 수 있다. Summary query responses may appear visually unlike search results. A summary query response can be generated based on a template that identifies the structural presentation of the summary, where the structural presentation of the summary is different from the structural presentation of the search results. The display of the summary query response (eg, graph features, and stock quotes) may be defined by the content of one or more documents found by the search results displayed in the list. Thus, the summary query response displays information specifically related to the query and may be on the first screen displayed to Susan in response to the search results. Susan may otherwise need to select a search result to view this information. Instead, the information may appear in an easy-to-read form at the top of the search results page.
일부 실시예들에 있어서, 주식 데이터에 대한 요약 쿼리 응답은 특정한 쿼리들(예를 들어, 단일 쿼리에 있어서, 단어 ＂주식＂ 그리고 티커 심볼, 또는 쿼리로서 티커 심볼 단독)에 응답하여 나타난다. 주식 요약은 특정한 웹 문서(예를 들어, www.stocks.com의 ＂TGT＂ 페이지)로부터의 정보로 채워질 수 있다. 일부 실시예들에 있어서, 쿼리에 대한 상위 다섯 검색 결과들의 하나가 특정한 웹 결과에 대한 검색 결과인 경우, 주식 요약이 나타난다. 따라서, 웹 사이트(예를 들어, www.stocks.com) 는 주어진 쿼리에 대하여 특별하게 관련된 것으로 지정될 수 있으며, 그리고 그 웹 사이트의 특정한 웹 문서에 대한 검색 결과가, 검색 결과로서 나타나는 경우 (예를 들어, TGT 페이지), 특정한 웹 문서로부터 데이터가 도출되어 요약 쿼리 응답의 일부분들로서 채워지는 데에 사용될 수도 있다. In some embodiments, a summary query response for stock data appears in response to certain queries (eg, the word “stock” and the ticker symbol in a single query, or the ticker symbol alone as a query). The stock summary may be populated with information from a particular web document (eg, the “TGT” page at www.stocks.com). In some embodiments, if one of the top five search results for the query is a search result for a particular web result, a stock summary appears. Thus, a web site (e.g. www.stocks.com) can be designated as particularly relevant for a given query, and if a search result for a particular web document of that web site appears as a search result (e.g., For example, a TGT page) may be used to derive data from a particular web document and populate it as part of a summary query response.
수잔은 주식 정보의 요약이 유용하다는 것을 알게 되고, 검색 시스템을 이용하는 것에 기초하여, 특정한 ＂대답＂을 이끌어내는 적어도 일부 쿼리들에 대하여 나타나는 정보들의 요약이 인식할 수 있다(discernable)는 것을 알 수 있다. 웹 사이트가 쿼리의 다양한 변화에 대한 ＂대답＂을 제공하는 데이터베이스를 가지는 경우에, 쿼리들에 대한 요약들이 나타날 수 있다. 예를 들어, 요약은 사용자가 영화 제목을 타이핑하는 것에 응답하여 나타날 수 있다. 요약은 영화 길이(movie length), 영화 등급(motion picture rating), 사용자 리뷰의 요약, 및 사용자 근처의 상영 시간을 찾기 위한 텍스트 입력 박스를 보여줄 수 있다. Susan finds that a summary of stock information is useful, and based on using a search system, knows that a summary of the information that appears for at least some of the queries that lead to a particular "answer" is discernible. have. If the web site has a database that provides "answers" to various changes to the query, summaries for the queries may appear. For example, the summary may appear in response to the user typing a movie title. The summary may show a text entry box to find movie length, motion picture rating, summary of user reviews, and show time near the user.
요약 쿼리 응답은, 사용자가, 쿼리로서, 다른 단어와 함께 단어 ＂정의하다(define)＂ 또는 ＂정의(definition)＂를 타이핑하는 때에 쿼리 내의 단어에 대한 정의를 나타내고 제공할 수 있다. 다양한 실시예들에 있어서, 쿼리가 뮤지컬 아티스트의 이름을 포함하는 경우, 요약들은 뮤지컬 아티스트에 대한 정보를 디스플레이 할 수 있다. 사용자가 비행기 편명(flight name)을 포함하는 쿼리를 제출하는 경우, 요약들은 여행 정보를 디스플레이 할 수 있다. 사용자가 어떤 위치에 대한 시간을 요청하는 경우, 예를 들어, 사용자가 ＂런던(London) 내의 시간＂을 타이핑하면, 요약들은 지리적 위치의 현재 시간을 디스플레이 할 수 있다. 서버 시스템이 배달에 대한 추적 번호(tracking number)로서 식별할 수 있는 번호를 쿼리가 포함하는 경우, 요약은 발송된 패키지의 추적 정보를 디스플레이 할 수 있다. 쿼리가 해답이 나오지 않은(unanswered) 수치 계산(numerical calculation) (예를 들어, 5 + 4)을 포함하는 경우, 요약들은 수치 계산에 대한 응답을 디스플레이 할 수 있다. The summary query response may represent and provide a definition for a word in the query when the user types, as a query, a word "define" or "definition" with another word. In various embodiments, if the query includes the name of a musical artist, the summaries may display information about the musical artist. If the user submits a query that includes a flight name, the summaries may display travel information. If the user requests a time for a location, for example, if the user types a time in London, the summaries may display the current time of the geographic location. If the query includes a number that the server system can identify as a tracking number for the delivery, the summary may display tracking information of the package sent. If the query includes an unanswered numerical calculation (eg, 5 + 4), the summaries may display the response to the numerical calculation.
수잔의 버스는 이제 그녀가 하루 동안 차를 주차해 놓는 주차장에 도착한다. 수잔은 버스에서 내려, 그녀의 차로 가는 길에, ＂WMT 주식＂을 타이핑한다. 여기서 WMT는 월-마트 스토어스(WAL-MART STORES INC.)의 주식 시세기(stock ticker)이다. 수잔은 차에 도착하면서 쿼리 ＂제출＂ 버튼을 누르고, 이에 따라서 그녀의 차 내에 설치한 전화 도크(telephone dock) 내에 모바일 폰을 놓는다(place).Susan's bus now arrives at the parking lot where she parks her car for one day. Susan gets off the bus and on the way to her car, she types WMT stock. WMT is the stock ticker of WAL-MART STORES INC. Susan arrives at the car and presses the query “Submit” button, thereby placing the mobile phone in a telephone dock installed in her car.
앞서와 같이, 수잔의 모바일 폰은 서버 시스템으로 쿼리를 제출하고, 서버 시스템으로부터 WMT 주식에 대한 요약 쿼리 응답과 검색 결과 리스트를 수신한다. 이 때에, 그러나, 수잔의 모바일 폰은 그녀의 전화가 도크 내에 위치한 것을 감지한다. 이에 대한 응답으로, 수잔의 모바일 폰은 검색 쿼리에 응답한 정보의 적어도 일부분이 청각적으로 출력되어야 한다고 판단한다. As before, Susan's mobile phone submits a query to the server system and receives a summary query response and a list of search results for the WMT stock from the server system. At this time, however, Susan's mobile phone senses that her phone is located in the dock. In response, Susan's mobile phone determines that at least a portion of the information responsive to the search query should be output acoustically.
수잔의 모바일 폰은 WMT 주식에 대한 요약 쿼리 응답을 오디오 형식(form)으로 변환하기 위한 다른 템플릿(template)을 이용한다. 따라서, 수잔의 자동차 스피커는 ＂월-마트 스토어스의 현재 주식 시세는 51 달러 41 센트, 오늘의 개장 순가격 51 달러 55 센트에서 0.2 퍼센트 하락하였습니다. ＂라고 말한다. Susan's mobile phone uses a different template for converting summary query responses for WMT stocks into an audio form. As a result, Susan's car speakers fell 0.2 percent from the September-Mart Stores current stock price of $ 51.41 cents and today's net opening price of $ 51.55 cents. Say ＂.
만일 그녀가 모바일 폰을 도크 내에 놓지 않으면, 수잔의 모바일 폰은 동일한 스크린을 디스플레이 할 수 있다. 그러나, 모바일 폰이 도크 내에 있는 상태에서는, 요약 쿼리 응답이 청각적으로 출력된다. 일부 실시예들에 있어서, 청각적 출력은 검색 결과들을 포함한다. 일부 실시예들에 있어서, 수잔으로부터 사용자-입력을 수신한 이후에 있어서만, 청각적 출력이 검색 결과들을 포함한다. 따라서, 수잔의 모바일 폰은 검색 쿼리들에 대한 응답으로서 (i) 검색 쿼리들이 요약 쿼리 응답을 산출하는(yield) 경우, 그리고 (ii) 모바일 폰이 정보를 청각적으로 제시하는 상태 (예를 들어, 모바일 폰이 도크 내에 있거나, 모바일 폰이 사용자의 귀(ear) 근처에 있거나, 또는 모바일 폰에 블루투스 장치가 무선으로 연결되어 있는 경우) 에 있는 경우, 정보의 일부분을 선택적으로 출력할 수 있다. If she does not place the mobile phone in the dock, Susan's mobile phone may display the same screen. However, with the mobile phone in the dock, the summary query response is audibly output. In some embodiments, the auditory output includes search results. In some embodiments, only after receiving user-input from Susan, the audio output includes search results. Thus, Susan's mobile phone responds to search queries: (i) when the search queries yield a summary query response, and (ii) the mobile phone is audibly presenting information (e.g., , If the mobile phone is in a dock, the mobile phone is near the user's ear, or is in a wireless connection with a Bluetooth device to the mobile phone).
다양한 실시예들에 있어서, 검색 쿼리에 응답한 정보가 정보의 요약을 포함하지 않은 경우, 또는 모바일 폰이 정보를 청각적으로 제시하는 상태에 있지 않은 경우에 청각적 출력은 발생하지 않는다. 청각적 출력은 모바일 폰 상의 검색 어플리케이션에 의하여, 또는 검색 시스템으로부터 수신된 리소스들(resources)에 의하여 요청될 수 있다. 따라서 청각적 출력은, 모바일 폰 상의 다수의 어플리케이션들이, 정보를, 시각적으로, 대신에 또는 그에 더해서 청각적으로 출력하도록 하는 모드로 진입하도록 작동하는, ＂글로벌(global)＂ 모드에 대한 응답이 아닐 수 있다. 청각적 출력은 검색 쿼리에 응답한 정보의 출력에 구애될 수 있다(particular to).In various embodiments, no acoustic output occurs if the information responsive to the search query does not include a summary of the information, or if the mobile phone is not in a state of presenting the information acoustically. Acoustic output may be requested by a search application on a mobile phone or by resources received from a search system. Thus, the audio output may not be a response to the global mode, in which a number of applications on the mobile phone operate to enter a mode that outputs information visually instead of or in addition to the audio. Can be. Acoustic output can be tied to the output of information in response to a search query (particular to).
일부 실시예들에 있어서, 수잔의 모바일 폰은 검색 결과들을 청각적으로 출력하지 않을 수 있다. 따라서, 만일 수잔이 검색 결과들에 대한 정보를 보기를 원한다면, 그녀는 모바일 폰의 디스플레이를 보아야만 한다. 일부 실시예들에 있어서, 검색 결과들은 모바일 폰 상에 디스플레이 되지 않을 수 있고, 수잔은 모바일 폰에 대하여 검색 결과를 디스플레이 하도록 유발하는(prompt) 촉각적 또는 청각적인 사용자-입력을 제공하여야만 할 수도 있다. 검색 결과들은 촉각적 또는 청각적 사용자-입력에 응답하여 수잔에게 청각적으로 출력될 수 있다. In some embodiments, Susan's mobile phone may not acoustically output search results. Thus, if Susan wants to see information about the search results, she must look at the display of the mobile phone. In some embodiments, search results may not be displayed on the mobile phone, and Susan may have to provide tactile or auditory user-inputs that prompt to display the search results for the mobile phone. . The search results may be audibly output to Susan in response to tactile or auditory user-input.
도 1은 상태-종속 쿼리 응답을 개념적으로 도시한 도면이다. 이 도면에 있어서, 사용자(102)는 모바일 폰(106)으로 쿼리(104a 또는 104b)를 제출한다. 모바일 폰(106)은 쿼리를 서버 시스템으로 전송하고, 서버 시스템은 검색 결과들(116a 내지 116c)과 요약 쿼리 응답(118)을 리턴한다. 모바일 폰(106)은 요약 출력 박스(120) 내에 요약 쿼리 응답(118)의 시각적 디스플레이를 제공한다. 또한 모바일 폰(106)은 모바일 폰이 물체 (예를 들어, 사용자의 귀)의 근방에 가까이 위치하는 지를 판단한다. 따라서, 모바일 폰(106)은 요약 쿼리 응답(118)의 청각적 출력을 제시한다. 1 conceptually illustrates a state-dependent query response. In this figure,
보다 구체적으로, 사용자(102)는 텍스트 입력 또는 음성 입력, 각각을 이용하여 서버 시스템(110)에 대하여 쿼리(104a 또는 104b)를 제출할 수 있다. 예를 들어, 사용자(102)는 터치스크린 디스플레이 상의 쿼리-입력 텍스트 박스를 그의 손가락으로 누를 수 있다. 쿼리-입력 텍스트 박스의 선택에 따라, 사용자는 서버 시스템(110)에 제출하기 위한 쿼리를 타이핑하기 위하여 실제의 또는 가상의 키보드를 사용할 수 있다. More specifically,
또 다른 실시예에 있어서, 사용자(102)는 음성 쿼리를 제출할 수 있다. 예를 들어, 사용자(10)는 모바일 폰(106) 측면의 물리적 버튼을 선택하고, ＂삐(beep)＂ 소리가 나는 것을 기다린 후에 모바일 폰(106)의 마이크로 발화하고 물리적 버튼의 선택을 해제할 수 있다. 또 다른 실시예에 있어서, 사용자(102)는, 모바일 컴퓨팅 장치(106)의 터치 스크린 상에, 마이크를 묘사한 인터페이스 요소를 선택할 수도 있다. 사용자(102)는 발화할 수 있고, 모바일 폰(106)은 사용자(102)가 더 이상 발화하지 않는 것으로 모바일 폰(106)이 판단할 때까지 녹음할 수 있다. In yet another embodiment,
모바일 폰(106)은 네트워크 (예를 들어, 인터넷) 를 통하여 서버 시스템(110)으로 텍스트 쿼리(108a) 또는 수신된 음성 쿼리(108b)를 전송할 수 있다. 서버 시스템(110)은 검색 엔진(112)을 포함할 수 있다. 검색 엔진(112)은 검색 쿼리(108)에 응답한 검색 결과를 알아낼 수 있다.
쿼리 응답 요약기(114)는 검색 쿼리에 응답한 요약 쿼리 응답을 알아낼 수 있다. 예를 들어, 만일 쿼리가 다수의 기-지정된(pre-designated) 쿼리 중의 하나이거나, 또는 검색 엔진(112)에 의하여 알아낸 검색 결과들 중 어느 하나가 기-지정된 문서로 식별되면, 요약 쿼리 응답은 기-지정된 문서 내의 콘텐츠에 기초하여 생성될 수 있다. The
요약 쿼리 응답은 템플릿에 의하여 특정된 일부 정보를 포함할 수 있으며, 일부 정보는 하나 이상의 검색 결과들 (또는 검색 결과들에 상응하는 하나 이상의 문서들) 로부터 도출된다. 템플릿은 검색 결과들을 생성하는 데에 사용되는 템플릿들과는 구조적으로 상이하다. The summary query response may include some information specified by the template, where some information is derived from one or more search results (or one or more documents corresponding to the search results). The template is structurally different from the templates used to generate search results.
검색 결과들(116a 내지 116c)과 요약 쿼리 응답(118)은 서버 시스템(110)으로부터 모바일 컴퓨팅 장치(106)로 전송될 수 있다. 모바일 컴퓨팅 장치는 검색 쿼리에 응답하여 수신된 정보가 요약 쿼리 응답(118)을 포함하고 있는지를 판단할 수 있다. 따라서, 검색 결과들(116a 내지 116c)을 디스플레이 하는 대신에, 모바일 폰은 요약 쿼리 응답(118)을 제시하는 다이얼로그(dialog) 박스(120)를 디스플레이 할 수 있다. 다이얼로그 박스(120)는 ＂텍사스 주 휴스턴의 날씨＂라는 제목을 포함할 수 있고, 휴스턴의 날씨를 설명하는 단편적인 정보들(snippets of information)을 포함할 수 있다. Search results 116a-116c and
모바일 폰(106)은, 모바일 폰이 적어도 일부 정보를 청각적으로 출력하는 상태에 있는 지를 판단할 수도 있다. 따라서, 모바일 폰은 (예를 들어, 요약 쿼리 응답(118)에 포함된 정보의 일부분을 청각적으로 출력하는 것을 통하여) 요약 쿼리 응답(118)을 청각적으로 출력할 수 있다. 이 실시예에 있어서, 모바일 폰(106)은 ＂텍사스 주 휴스턴의 날씨는 95도이며 맑습니다＂라고 출력한다. 출력된 음성은 요약 쿼리 응답(118)에 기초하여 모바일 폰(106)에서 합성될 수 있다. 일부 실시예들에 있어서, 합성된 음성은 요약 쿼리 응답(118)과 함께 또는 대신에 보내어 진다. 일부 실시예들에 있어서, 모바일 컴퓨팅 장치(106)는 서버 시스템(110)에 대하여, 모바일 컴퓨팅 장치(106)가 이미 수신하였을 수 있는, 요약 쿼리 응답(118)에 대한 합성된 음성을 제공해 달라고 요청한다.The
어느 하나의 경우에 있어서, 모바일 컴퓨팅 장치(106) 또는 서버 시스템(110)은 음성 템플릿을 사용하여 합성된 음성을 생성할 수 있다. 예시적인 음성 템플릿은: ＂<위치>의 날씨는 <온도>도 이며 <현재 예보>＂, 여기서 변수들은 요약 쿼리 응답(118)으로부터 도출된다. 다양한 실시예들에 있어서, 요약 쿼리 응답(118)의 청각적 출력은 모바일 컴퓨팅 장치(106)에 의하여 생성되며, 모바일 폰이 정보를 청각적으로 출력하는 상태에 있는 동안에는 다이얼로그 박스(120) 내에 제시되는 요약 쿼리 응답의 시각적 출력은 보이지 않는다. In either case,
본 명세서에서는 검색 결과들과 요약 쿼리 응답들을 전송하는 것뿐만 아니라, 검색 결과들과 요약 쿼리 응답들을 시각적으로 그리고 청각적으로 출력하는 것에 대하여 논의하고 있으나, 데이터의 전송과 출력은 콘텐츠에 따라 상이해질 수 있다. 예를 들어, 요약 쿼리 응답으로서 전송되는 정보는 마크-업 코드와 텍스트 데이터를 포함할 수도 있다. 요약 쿼리 응답이 디스플레이 되는 경우, 마크-업 코드는 디스플레이 되지 않을 수 있고, 텍스트 데이터는 디스플레이 될 수 있다. 요약 쿼리 응답이 청각적으로 출력되는 경우, 텍스트 데이터의 일부분은 합성된 음성으로서 청각적으로 출력될 수 있고, 문장 흐름을 향상시키기 위하여 추가적인 단어들을 포함할 수 있다. 명확성을 위하여, 설명하는 콘텐츠가 상이해질 수 있더라도, 본 명세서에서는 검색 결과들과 요약 쿼리 응답들의 전송, 수신, 및 출력을 설명한다. 그와 관계없이, 검색 결과들과 요약 쿼리 응답들의 모든 표현들(representations)이 동일한 전송된 검색 결과들 또는 요약 쿼리 응답들로부터 기인한 것일 수 있다. In this specification, not only the transmission of search results and summary query responses, but also the visual and audio output of search results and summary query responses are discussed, but the transmission and output of data may vary depending on the content. Can be. For example, the information sent as a summary query response may include mark-up code and text data. If the summary query response is displayed, the mark-up code may not be displayed and the text data may be displayed. When the summary query response is audibly output, a portion of the text data may be audibly output as synthesized speech and may include additional words to enhance sentence flow. For clarity, the description herein describes the transmission, reception, and output of search results and summary query responses, although the content described may be different. Regardless, all representations of search results and summary query responses may be from the same transmitted search results or summary query responses.
도 2는 상태-종속 쿼리 응답을 수행하기 위한 흐름도이다. 박스 202 에서, 모바일 컴퓨팅 장치는 쿼리에 응답한 정보를 수신한다. 정보는 서버 시스템으로부터 수신될 수 있으며, 정보는 모바일 컴퓨팅 장치의 사용자에 의하여 정의되며, 서버 시스템에 대하여 쿼리로서 제출된 음성 쿼리 또는 텍스트 쿼리에 응답하여 서버 시스템에 의하여 생성된 것일 수 있다. 2 is a flow diagram for performing a state-dependent query response. In box 202, the mobile computing device receives information in response to the query. The information may be received from a server system, the information being defined by a user of the mobile computing device, and may be generated by the server system in response to a voice query or text query submitted as a query to the server system.
정보는 다수의 검색 결과들(204)를 포함할 수 있다. 각 검색 결과는 단일 웹 페이지를 식별하고 웹 문서의 콘텐츠를 서술하는 텍스트의 블록을 제공한다. 또한 정보는 요약 쿼리 응답(206)을 포함할 수 있다. 검색 결과들과 요약 쿼리 응답은 검색 쿼리에 응답하여 모바일 컴퓨팅 장치에 대하여 제공되는 HTML 웹 문서 안에서 함께 수신될 수 있다. 다양한 실시예들에 있어서, 검색 결과들(204)과 요약 쿼리 응답(206)은 모바일 컴퓨팅 장치에 의한 별개의 요청에 응답하여 모바일 컴퓨팅 장치에 개별적으로 수신된다. The information may include a number of search results 204. Each search result identifies a single web page and provides a block of text that describes the content of the web document. The information may also include a summary query response 206. The search results and summary query response may be received together in an HTML web document provided for the mobile computing device in response to the search query. In various embodiments, search results 204 and summary query response 206 are received separately at the mobile computing device in response to a separate request by the mobile computing device.
박스 208에서, 모바일 컴퓨팅 장치가 시각적 상태에 있는지 또는 청각적 상태에 있는지에 대한 판단이 이루어진다. 모바일 컴퓨팅 장치 내의 근접(proximity) 센서가 근접 센서와 가까운 곳의 물체를 감지하는 경우, 모바일 컴퓨팅 장치가 청각적 상태에 있는 것으로 판단할 수 있다. 근접 센서와 가까이에 물체가 있다는 것은 모바일 컴퓨팅 장치가 뒤집혀(face down) 있거나, 사용자의 주머니에 있거나, 사용자가 귀에 대고 있는 (따라서 사용자는 스크린을 볼 수 없다) 것을 지시할 수 있다. 일부 실시예들에 있어서, 광(light) 센서는 (예를 들어, 야외에서 물체가 지속적으로 존재하는 때에는 센서가 물체와 직면하거나(up against) 또는 근처에 있는 경우에 많은 빛이 센서로 도달하지 않기 때문에) 모바일 폰이 물체 근처에 있는 지를 판단하는 데에 사용된다. At
다양한 실시예들에 있어서, 근접 센서가 모바일 컴퓨팅 장치와 물체가 가까이 있는 것으로 지시하기 이전에, 움직임(motion) 센서 (예를 들어, 가속도계(accelerator) 또는 자이로스코프(gyroscope))는 전화기가 기설정된(predetermined) 방식으로 움직여지면, 전화기가 청각적 상태에 있는 것으로 판단된다. 예를 들어, (물체가 근접 센서와 가까이 있는지를 지시하는 근접 센서와 함께) 모바일 폰이 사용자의 귀에 있다는 것을 지시하는 상태에 모바일 폰이 있다고 하기 위하여 상향(upward) 움직임이 감지될 필요가 있다. 또 다른 실시예에 있어서, (물체가 근접 센서와 가까이 있는지를 지시하는 근접 센서와 함께) 모바일 폰이 표면으로 뒤집혔다는 (flipped over) 것을 지시하기 위하여 수평 플리핑 움직임이 감지될 필요가 있다. In various embodiments, a motion sensor (eg, an accelerometer or gyroscope) is configured before the proximity sensor indicates that the object is close to the mobile computing device. When moved in a predetermined manner, it is determined that the phone is in an auditory state. For example, an upward movement needs to be detected to say that the mobile phone is in a state indicating that the mobile phone is in the user's ear (along with the proximity sensor indicating that the object is close to the proximity sensor). In another embodiment, horizontal flipping movement needs to be detected to indicate that the mobile phone has been flipped over to the surface (with a proximity sensor indicating that the object is close to the proximity sensor).
일부 실시예들에 있어서, 모바일 컴퓨팅 장치가 도킹되면(docked), 모바일 컴퓨팅 장치가 청각적 상태에 있는 것으로 판단될 수 있다. 모바일 컴퓨팅 장치의 암 포트(female port)가 상응하는 수 단자(male terminal)에 위치하는 경우, 모바일 컴퓨팅 장치가 도킹될 수 있다. 모바일 컴퓨팅 장치는 도크 내의 전자 장치들과 통신하여 수 단자가 실제로 도크 내의 수 단자인지, 그리고 도크의 타입(type)을 알아낸다. 일부 실시예들에 있어서, 포트는 헤드폰에 대한 오디오 입력과 출력 잭(jack)이 아니다. 포트는, 적어도 일부에 있어서, 휴대용 컴퓨팅 장치의 충전을 위하여 사용될 수 있다. In some embodiments, when the mobile computing device is docked, it may be determined that the mobile computing device is in an auditory state. If the female port of the mobile computing device is located at the corresponding male terminal, the mobile computing device may be docked. The mobile computing device communicates with the electronic devices in the dock to find out if the male terminal is actually a male terminal in the dock and the type of the dock. In some embodiments, the port is not an audio input and output jack for the headphones. The port may, at least in part, be used for charging a portable computing device.
일부 실시예들에 있어서, 외부 스피커와 마이크가 모바일 컴퓨팅 장치에 통신적으로 연결된 경우, 휴대용 컴퓨팅 장치는 청각적 상태에 있는 것으로 판단될 수 있다. 외부 스피커와 마이크는, 모바일 컴퓨팅 장치에 대하여, 물리적으로 또는 무선으로, 연결될 수 있다. 외부 스피커와 마이크는 모바일 컴퓨팅 장치에 결합되도록 포함되는 것이 아니며, 모바일 컴퓨팅 장치의 부품으로서 제조되는 마이크와 스피커에 대하여 추가적인 것이다. 외부 스피커와 마이크에 연결됨에 따라, 모바일 컴퓨팅 장치의 디폴트 스피커와 마이크는 꺼진다(turn off). In some embodiments, when the external speaker and microphone are communicatively connected to the mobile computing device, the portable computing device may be determined to be in an auditory state. External speakers and microphones may be connected to the mobile computing device, either physically or wirelessly. External speakers and microphones are not included to be coupled to the mobile computing device but are additional to microphones and speakers that are manufactured as part of a mobile computing device. As connected to external speakers and microphones, the default speakers and microphones of the mobile computing device are turned off.
예시적인 외부 스피커들과 마이크들은 모바일 폰과 무선으로 통신하여 사용자에게 오디오를 재생하여 주고 음성 입력을 수신하기 위한 원-이어 블루투스 헤드셋(one-ear bluetooth headset)을 포함한다. 또 다른 실시예는 모바일 폰의 오디오 입력 잭을 통하여 모바일 폰과 연결되는 유선 헤드폰들을 포함한다. Exemplary external speakers and microphones include a one-ear bluetooth headset for wirelessly communicating with a mobile phone to play audio to a user and to receive voice input. Yet another embodiment includes wired headphones that connect with the mobile phone through an audio input jack of the mobile phone.
모바일 컴퓨팅 장치가 청각적 상태에 있는 것으로 판단되지 않은 경우에는 모바일 컴퓨팅 장치가 시각적 상태에 있는 것으로 판단될 수 있다. 따라서, 모바일 컴퓨팅 장치의 디폴트 상태는 시각적 상태일 수 있다.If it is not determined that the mobile computing device is in an auditory state, the mobile computing device may be determined to be in a visual state. Thus, the default state of the mobile computing device may be a visual state.
박스 210에 있어서, 모바일 컴퓨팅 장치는 시각적 상태에 있는 것으로 판단되어, 이후에 수신된 정보를 시각적으로 디스플레이 한다. 수신된 정보가 요약 쿼리 응답은 포함하지 않지만, 검색 결과들은 포함하는 경우의 실시예들에 있어서, 모바일 컴퓨팅 장치는 검색 결과들만을 디스플레이 할 수 있다 (박스 212). 수신된 정보가 요약 쿼리 응답과 검색 결과들 모두를 포함하는 경우의 실시예에 있어서, 모바일 컴퓨팅 장치는 요약 쿼리 응답 (또는 상술한 바와 같이, 이들의 표현) 과 동시에 검색 결과들 (예를 들어, 웹 브라우저 내의 단일 웹 페이지)을 디스플레이 할 수 있다. (박스 214). 또한, 수신된 정보가 요약 쿼리 응답과 검색 결과들을 모두 포함하는 경우의 실시예에 있어서, 모바일 컴퓨팅 장치는 처음에 요약 쿼리 응답을 디스플레이 하고 나서, 시간 간격 이후에, 검색 결과들을 디스플레이 할 수 있다 (박스 216). 검색 결과들은 사용자가 검색 결과들의 디스플레이를 작동시키는(invoke) 사용자-입력을 제공한 이후에 디스플레이 될 수 있다.In box 210, the mobile computing device is determined to be in a visual state, and subsequently visually displays the received information. In embodiments where the received information does not include a summary query response, but includes search results, the mobile computing device may display only the search results (box 212). In an embodiment where the received information includes both a summary query response and search results, the mobile computing device may retrieve the search results (eg, a representation thereof) simultaneously with the summary query response (or a representation thereof, as described above). Display a single web page in a web browser). (Box 214). Further, in an embodiment where the received information includes both a summary query response and search results, the mobile computing device may initially display the summary query response and then display the search results after a time interval. Box 216). The search results may be displayed after the user provides user-input that invokes the display of the search results.
박스 218에 있어서, 모바일 컴퓨팅 장치는 청각적 상태에 있는 것으로 판단되어, 쿼리에 대한 응답으로서 수신된 정보의 일부분으로서 요약 쿼리 응답이 수신되었는지에 대한 판단이 수행된다. 예를 들어, 만일 검색 쿼리가 기지정된 쿼리 (예를 들어, 단어 ＂날씨＂와 위치에 포함되는 쿼리) 에 대한 것이거나, 검색 쿼리에 대한 응답으로서 식별된 검색 결과들이 기지정된 검색 결과에 포함된 경우 (예를 들어, ＂weather.com＂ 웹 페이지에 대한 검색 결과이며, 이것이 특정한 위치에 대한 날씨를 제시함), 요약 쿼리 응답은 수신된 정보의 일부일 수 있다. 이와는 달리, 수신된 정보는 검색 결과들만을 포함하거나 (그리고 요약 쿼리 응답을 포함하지 않고), 또는 박스 218에 있어서 긍정적인 판단을 위하여 필요한 특정한 형태의 요약 쿼리 응답을 포함하지 않을 수 있다. In box 218, the mobile computing device is determined to be in an auditory state, and a determination is made as to whether a summary query response has been received as part of the information received as a response to the query. For example, if a search query is for a known query (eg, a query included in the word “weather and location”), or the search results identified as a response to the search query are included in the known search results. If (eg, a search result for the “weather.com” web page, which suggests weather for a particular location), the summary query response may be part of the received information. Alternatively, the received information may include only search results (and not include a summary query response), or may not include the specific type of summary query response required for a positive decision in box 218.
박스 220에 있어서, 모바일 컴퓨팅 장치는 요약 쿼리 응답을 수신하지 않고, 이에 따라, 검색 결과들이 제시된다. 검색 결과들은 시각적으로 (박스 222) 또는 청각적으로 (박스 224) 제시될 수 있다.In
박스 226에 있어서, 모바일 컴퓨팅 장치는 청각적 상태에 있고, 요약 쿼리 응답을 수신한다. 따라서, 도 3 및 4와 관련하여 설명된 동작들이 수행된다. In box 226, the mobile computing device is in an auditory state and receives a summary query response. Thus, the operations described in connection with FIGS. 3 and 4 are performed.
도 3은 컴퓨팅 장치를 위한 청각적 출력 이행(transition)을 도시한 도면이다. 모바일 컴퓨팅 장치는 청각적 출력을 위한 상태에 있는 것으로 판단되고 (도 2에 참조된 바와 같이) 요약 쿼리 응답을 수신한 것으로 판단될 수 있다. 박스 302에 있어서, 요약 쿼리 응답은 청각적으로 출력된다. 예를 들어 모바일 컴퓨팅 장치는, 쿼리 ＂내포(connote)의 정의＂에 대한 응답으로, ＂＂내포에 대한 정의는… 함축, 간접적으로 표현 또는 말하다＂라는 단어를 ＂발화＂할 수 있다. 본 명세서를 통틀어 설명하는 바와 같이, 청각적 발화는 ,요약 쿼리 응답을 대표하는, 상응하는 시각적 제시와 함께, 또는 시각적 제시 없이 수행될 수 있다. 3 is an illustration of an audio output transition for a computing device. The mobile computing device may be determined to be in a state for auditory output and may have received a summary query response (as referenced in FIG. 2). In box 302, the summary query response is output acoustically. For example, a mobile computing device may respond to a query "definition of connotation", and the definition of "containment" is defined by. The word implied, indirectly expressed or spoken can be uttered. As described throughout this specification, auditory speech may be performed with or without a corresponding visual presentation, representing a summary query response.
박스 308에 있어서, 모바일 컴퓨팅 장치는 검색 결과들의 청각적 출력을 제공하지 않는다. 대신에, 검색 결과들은 사용자에게 시각적으로만 출력될 수 있다. In box 308, the mobile computing device does not provide an acoustic output of the search results. Instead, search results may only be output visually to the user.
박스 306에 있어서, 모바일 컴퓨팅 장치는 프롬프트(prompt)에 대한 사용자의 선택에 응답하여 검색 결과들 (또는 그들의 대표) 을 청각적으로 출력한다. 예를 들어, 모바일 컴퓨팅 장치가 ＂내포＂에 대한 정의를 언급하는 것에 따라, 모바일 컴퓨팅 장치는 ＂당신의 쿼리 ＇내포의 정의＇에 대한 검색 결과들을 듣기 위해서는 ＇검색 결과들＇이라고 말하세요.＂라고 말할 수 있다. 사용자가 ＂검색 결과들＂이라고 말하는 것에 응답하여, 모바일 컴퓨팅 장치는 다수의 검색 결과들의 요약 (예를 들어, 제목, 그리고 각 검색 결과들에 대한 텍스트의 선택된 부분들)을 ＂발화＂할 수 있다. 일부 실시예들에 있어서, 모바일 컴퓨팅 장치가 물리적 사용자-입력 (예를 들어, 물리적 버튼 또는 터치스크린 상의 사용자 인터페이스 요소에 대한 사용자-선택)을 수신하는 것에 응답하여 모바일 컴퓨팅 장치에 의하여 검색 결과들이 ＂발화＂될 수 있다. In
박스 310에 있어서, 모바일 컴퓨팅 장치는 프롬프트에 대한 사용자 선택이 없이도 검색 결과들을 출력한다. 박스 306과는 반대로, 청각적 출력은 사용자가 사용자 입력을 제공하지 않고 일어날 수 있다. 예를 들어, 모바일 컴퓨팅 장치가 내포에 대한 요약된 정의를 언급한 이후, 모바일 컴퓨팅 장치는 ＂첫 번째 검색 결과…프리 딕셔너리 온라인(free dictionary online)에 의한 내포의 정의…문자 그대로의 의미에 더하여 암시하다… 선택하려면 ＇첫 번째＇라고 말하세요…＂, ＂두 번째 검색 결과…＂ 등을 말할 수 있다. 검색 결과들의 출력을 유발하는 사용자 입력이 없이도 검색 결과들은 청각적으로 출력될 수 있다.In box 310, the mobile computing device outputs search results without user selection for a prompt. In contrast to
도 4는 컴퓨팅 장치에 대한 시각적 출력 이행을 도시한 도면이다. 모바일 컴퓨팅 장치는 청각적 출력을 위한 상태에 있는 것으로 판단되고 (도 2에 참조된 바와 같이) 요약 쿼리 응답을 수신한 것으로 판단될 수 있다. 다양한 실시예들에 있어서, 아래에서 설명되는 다양한 시각적 출력 이행들은 도 3을 참조하여 설명된 청각적 출력 이행들과 어떠한 조합으로도 일어날 수 있다. 4 illustrates a visual output implementation for a computing device. The mobile computing device may be determined to be in a state for auditory output and may have received a summary query response (as referenced in FIG. 2). In various embodiments, the various visual output implementations described below may occur in any combination with the audio output implementations described with reference to FIG. 3.
모바일 컴퓨팅 장치(400)는, 검색 쿼리의 제출과 검색 쿼리에 대한 응답으로 수신되는 정보의 수신에 응답하여 디스플레이 되는, 다이얼로그 박스(402)를 디스플레이하고 있다. 다이얼로그 박스(402)는 요약 쿼리 응답을 시각적으로 제시한다. 쿼리 박스는 ＂텍사스 주 휴스턴의 날씨＂라고 제목이 붙여지고, 텍사스 주 휴스턴의 날씨를 나타내는 데이터들의 요약을 포함하는 세부 항목(details) 박스(404)를 포함한다. 이 실시예에 있어서, 모바일 컴퓨팅 장치는 검색 쿼리들을 전혀 디스플레이 하지 않고 있으며, 모바일 컴퓨팅 장치가 검색 결과를 디스플레이 하도록 하는 ＂검색 결과 보기＂ 그래픽 인터페이스 요소(406)를 포함한다. The
＂검색 결과 보기＂ 그래픽 인터페이스 요소(406)의 사용자 선택에 따라, 모바일 컴퓨팅 장치(430)의 디스플레이가 제시될 수 있다. 다이얼로그 박스(432)는 추가적인 정보를 포함하기 위하여 확장될 수 있다. 예를 들어, ＂검색 결과 보기＂ 인터페이스 요소(406)는 검색 결과(436) 및 검색 결과(438)로 대체될 수 있다. 이 실시예에 있어서, 세부 항목 박스(434)는 줄어들어 세부 항목 박스(404)만큼의 정보를 포함하지 않을 수 있다. 일부 실시예들에 있어서, 세부 항목 박스(434)는 세부 항목 박스(404)와 같은 정보를 포함한다. 모바일 컴퓨팅 장치(430)의 사용자는 디스플레이를 아래로 스크롤 하여 추가적인 검색 결과들을 볼 수 있다. “View Search Results” Depending on the user selection of the
모바일 컴퓨팅 장치(430)의 디스플레이에 대한 대안으로, ＂검색 결과 보기＂ 그래픽 인터페이스 요소(406)의 사용자 선택에 따라, 모바일 컴퓨팅 장치(460)의 디스플레이가 제시될 수 있다. 이 실시예에 있어서, 디스플레이는 웹 페이지를 변환한(rendered) 웹 브라우저를 제시한다. 웹 브라우저의 제목 바(462)는 검색에 있어서 사용된 쿼리를 디스플레이 한다. 이 실시예에 있어서, 텍스트 또는 음성 쿼리의 콘텐츠가 ＂휴스턴 날씨＂ 였기 때문에, 제목 바는 ＂검색 - 휴스턴 날씨＂ 라고 한다. 또한 웹 브라우저는 변환된 웹 페이지에 대한 URI를 디스플레이 하기 위한 어드레스 바(464)를 제시한다. As an alternative to the display of the
웹 페이지의 본문 부분(466)은 쿼리의 제출에 응답하여 수신된 리소스들에 기초하여 변환된 콘텐츠들을 디스플레이 한다. 웹 페이지의 상부(468)는 쿼리 ＂휴스턴 날씨＂에 대한 요약 쿼리 응답을 디스플레이 한다. 요약 쿼리 응답은 템플릿에 따라 구조화될 수 있으며, 템플릿으로부터 기정의된 단어들을 포함할 수 있고, 웹 페이지의 하부(470)에 디스플레이 된 검색 결과들과 달리 구조화되었을 수 있다. The
다양한 실시예들에 있어서, 요약 쿼리 응답은 모바일 컴퓨팅 장치(400)에 의하여 제시된 바와 같이 다이얼로그 박스(402)에 디스플레이 되지 않는다. 이러한 실시예들에 있어서, 검색 쿼리의 제출에 응답한 정보의 초기 디스플레이는 모바일 컴퓨팅 장치(430) 또는 모바일 컴퓨팅 장치(460)이다. In various embodiments, the summary query response is not displayed in
도 4의 다양한 시각적 출력 이행은 도 3의 어떠한 청각적 출력 이행과도 조합될 수 있다. 예를 들어, 청각적 출력 요약 쿼리 응답 (박스 302)은 모바일 컴퓨팅 장치(460)의 디스플레이 동안에 출력되거나, 청각적 출력이 검색 결과 (박스 310)로 이행되는 동안에 모바일 컴퓨팅 장치(460)의 디스플레이는 유지될 수 있다. 또 다른 실시예에 따라, 청각적 출력 요약 쿼리 응답 (박스 302)는 모바일 컴퓨팅 장치(400)의 디스플레이 동안에 출력될 수 있고, ＂검색 결과 보기＂ 인터페이스 요소(406)의 사용자-선택에 따라서 어떠한 검색 결과들의 청각적 출력도 일어나지 않는다 (박스 308) (그리고 휴대 장치(430) 또는 휴대 장치(460)의 디스플레이로의 시각적 이행이 이루어진다). The various visual output transitions of FIG. 4 may be combined with any auditory output transition of FIG. 3. For example, the auditory output summary query response (box 302) may be output during the display of the
도 5는 상태-종속 쿼리 응답을 수행하기 위한 시스템의 일 실시예를 나타낸 도면이다. 시스템은 모바일 컴퓨팅 장치(500)와 서버 시스템(550)을 포함한다. 모바일 컴퓨팅 장치는 네트워크, 예를 들어, 인터넷을 통하여 서버 시스템(550)과 통신한다. 5 illustrates one embodiment of a system for performing a state-dependent query response. The system includes a
모바일 컴퓨팅 장치(500)는 쿼리 입력 인터페이스(502)를 포함한다. 쿼리 입력 인터페이스(502)는 모바일 컴퓨팅 장치에서 쿼리들의 사용자-정의를 수신하기 위한 동작들을 수행한다. 예를 들어 쿼리 입력 인터페이스(502)는 사용자의 버튼 입력에 응답하여 사용자-발화 쿼리의 오디오 파일을 기록하기 위한 동작들을 수행할 수 있다. 또 다른 실시예에 있어서, 쿼리 입력 인터페이스(502)는 검색 쿼리에 대하여 지정된 텍스트 영역(field)에 대한 사용자의 키 입력(key strokes)을 기록할 수 있다. 쿼리 입력 인터페이스(502)는 기록된 오디오 파일 또는 키 입력을 서버 시스템(550)에 전송할 수 있다. 일부 실시예들에 있어서, 쿼리 입력 인터페이스(502)는 제출된 쿼리에 응답한 정보를 수신하고, 수신된 정보를 상태 판단(504), 쿼리 결과 제시기(506), 또는 웹 브라우저(508)로 전달한다.
서버 시스템(550)은 발화된 음성 쿼리가 기록된 오디오 파일의 트랜스크립션(transcription)을 판단하기 위한 음성 인식 시스템(552)을 포함한다. 음성 인식 시스템(552)은 기록된 오디오 파일 내에서 발화된 단어들에 상응하는 텍스트 단어들을 확률론적으로(probabilistically) 판단하기 위하여 언어 모형(language model)에 접근할 수 있다. 음성 인식 시스템(552)은 사람이 이해할 수 있는(human-understandable) 언어로 텍스트 단어들을 출력할 수 있다.
검색 엔진 시스템(554)은 검색 쿼리를 텍스트 형태로 수신하고, 검색 쿼리에 응답하여 검색 결과들을 알아낼 수 있다. 예를 들어, 검색 엔진 시스템(554)은 인터넷 상의 웹사이트들을 방문하여 웹사이트들로부터 데이터를 모으고, 쪼개서(parse), 저장함으로써 빠르고 정확한 정보 도출(retrieval)을 용이하게 하는 인덱스를 생성하는 웹 크롤러(crawler)를 포함할 수 있다. 검색 쿼리는 검색 쿼리와 관련된 문서들의 등급화된 세트(ranked set)를 알아내기 위하여 인덱스에 대항하여 실행된다(run against). 검색 엔진(554)는, 모바일 컴퓨팅 장치(500)로의 전송을 위하여, 각각 문서의 정보를 알아내는 검색 결과들의 상응하는 세트를 제공한다. Search engine system 554 may receive a search query in text form and retrieve search results in response to the search query. For example, a search engine system 554 visits websites on the Internet, gathers, parses, and stores data from the websites, thereby creating an index that facilitates fast and accurate retrieval. (crawler) may be included. The search query is run against the index to find a ranked set of documents associated with the search query. The search engine 554 provides a corresponding set of search results, each of which retrieves the information of the document, for transmission to the
쿼리 응답 요약기(556)는 쿼리에 대하여 요약 쿼리 응답이 생성되어야만 하는지를 판단하고, 만일 그렇다면, 요약 쿼리 응답을 생성한다. 요약 쿼리 응답은 쿼리 응답 요약기(556)에 의하여 생성되어 모바일 컴퓨팅 장치(500)의 사용자에게 디스플레이 하기 위한 정보의 세트이다. 요약 쿼리 응답은 쿼리에 ＂대답＂하여 모바일 컴퓨팅 장치(500)의 사용자가 쿼리에 대한 대답을 얻기 위하여 검색 결과를 선택할 필요가 없게 할 수 있다. 따라서, 요약 쿼리 응답은 콘텐츠 요약기(556)의 개발자(developer)가 생성한 템플릿을 이용하여 생성될 수 있다. 여기서 템플릿은 특정한 정보 리소스로부터 끌어내어진 데이터에 대한 ＂슬롯들(slots)＂을 포함한다. Query response summarizer 556 determines whether a summary query response should be generated for the query, and if so, generates a summary query response. The summary query response is a set of information generated by the query response summarizer 556 for display to a user of the
실시예로서, 검색 쿼리가 ＂마멋(marmot)의 정의＂인 경우에 요약 쿼리 응답이 생성될 수 있다. 요약 쿼리 응답은, 모바일 컴퓨팅 장치(500)에 의하여 변환되는 경우, 쿼리에 대하여 ＂대답＂하는 정보의 디스플레이를 제시하는, HTML 코드를 포함할 수 있다. 예를 들어, 요약 쿼리 응답은 ＂마멋에 대한 정의＂라는 제목, 사전을 묘사하는 아이콘, 텍스트 정의 ＂짧고 숱이 많은 꼬리를 가지고 체격이 다부지며(stocky) 거친-털로 덮여있는 굴(窟)을 파는 설치류(rodent)＂, 및 그 정의의 소스를 식별하는 URI를 포함할 수 있다. 이 실시예에 있어서, 제목은, 템플릿으로부터의 ＂에 대한 정의(Definition for)＂ 라는 단어를 이용하여 부분적으로 생성되고, 쿼리 ＂마멋＂에 의하여 식별된 단어를 이용하여 부분적으로 생성된, ＂마멋에 대한 정의＂라는 사람이 이해할 수 있는 문장을 포함할 수 있다. 일부 실시예들에 있어서, 사람이 이해할 수 있는 문장은, 정의의 소스로부터의 단어들을 이용하여 부분적으로 생성된다. As an example, a summary query response may be generated if the search query is a definition of a marmot. The summary query response may include HTML code that, when translated by the
반면에, 검색 결과들은 요약 쿼리 응답과 상이하게 구조화될 수 있으며, 요약 쿼리 응답에 대한 템플릿과 상이한 템플릿을 이용하여 생성될 수 있다. 서버 시스템(550)은 쿼리에 대한 단일 요약 쿼리 응답을 생성할 수 있으나, 요약에 대한 응답으로 다수의 검색 결과들을 알아낼 수 있다. 각 검색 결과들에 대한 제목은 검색 결과에 의하여 정의될 수 있으며, 이와는 달리 요약 쿼리 응답에 대한 제목은, 적어도 부분적으로는, 요약 쿼리 응답에 대한 템플릿에 의하여 정의될 수 있다. 요약 쿼리 응답에 대한 콘텐츠의 소스는 검색 쿼리에 대한 응답으로서 식별되는 문서들 중의 하나일 수 있으며, 이를 위하여 검색 결과가 디스플레이 된다. On the other hand, the search results can be structured differently from the summary query response and generated using a template different from the template for the summary query response. The
서버 시스템(550)은 검색 결과들과 요약 쿼리 응답을 모바일 컴퓨팅 장치(500)로 전송할 수 있다. 검색 결과들과 요약 쿼리 응답을 수신하는 것에 응답하여, 상태 판단기(504)는 모바일 컴퓨팅 장치(500)의 상태를 판단할 수 있다. 일부 실시예들에 있어서, 검색 결과들과 요약 쿼리 응답은 모바일 컴퓨팅 장치(500)로 하여금 상태 판단기(504)에 대하여 모바일 컴퓨팅 장치(500)의 상태를 판단하도록 요청하도록 하는 정보를 포함하는 웹 페이지의 일부분으로서 전송된다. 일부 실시예들에 있어서, 상태 판단기(504)는 검색 결과들과 요약 쿼리 응답을 수신한 이후에, 검색 결과들과 요약 쿼리 응답의 수신에 대한 직접적인 결과로서 상태를 판단한다.The
상태 판단기(504)는 상태에 따른 모바일 컴퓨팅 장치(500)의 모드를 작동시킬 수 있다. 예를 들어, 만일 검색 결과들과 요약 쿼리 응답이 수신된 경우, 모바일 컴퓨팅 장치의 근접 센서가 모바일 컴퓨팅 장치(500)가 물체의 근처에 있는 것을 감지한다면, 검색 쿼리에 대한 응답으로 청각적으로 정보를 출력하기 위한 모드가 작동될 수 있다. 만일 스피커를 포함하는 외부 장치가 모바일 컴퓨팅 장치에 통신적으로 연결되었다면, 정보를 청각적으로 출력하기 위한 모드가 작동될 수 있다. 만일 모바일 컴퓨팅 장치가 도킹되었다고 판단되면, 정보를 출력하기 위한 모드가 작동될 수 있다. 만일 모바일 컴퓨팅 장치가 상술한 어떠한 상태들에도 있는 것으로 판단되지 않았다면, 검색 쿼리에 응답하여 정보를 시각적으로 출력하기 위한 모드가 작동될 수 있다. The
쿼리 결과 제시기(506)는 서버 시스템으로부터 검색 결과들과 요약 쿼리 응답을 수신할 수 있다. 쿼리 결과 제시기(506)는, 예를 들어, 도 2 내지 도 4를 참조하여서 설명한 바와 같이, 청각적으로 그리고 시각적으로 정보를 출력하기 위한 동작을 수행할 수 있다. 일 실시예로서, 쿼리 결과 제시기(506)는 상태 판단기(504)에 의하여 설정된 바에 따라, 휴대 컴퓨팅 장치가 청각적 모드에 있는 것에 기초하여 요약 쿼리 응답을 청각적으로 출력하도록 판단할 수 있다.
일부 실시예들에 있어서, 요약 쿼리 응답 내의 텍스트를 합성된 음성으로 변환하는 것에 의하여 (예를 들어, 모바일 컴퓨팅 장치 단독으로 또는 서버 시스템(550)과의 통신을 통하여) 수신된 요약 쿼리 응답은 청각적으로 출력될 수 있다. 일부 실시예들에 있어서, 요약 쿼리 응답은, 요약 쿼리 응답의 시각적 묘사를 제시하기 위한 데이터, 및 요약 쿼리 응답을 청각적으로 제시하기 위한 데이터 (예를 들어, 시각적 묘사를 표현하기 위한 데이터와는 상이한 음성 녹음 또는 텍스트의 세트, 그리고 이들로부터 합성된 오디오가 생성될 수 있음) 를 포함한다. In some embodiments, the summary query response received by converting text in the summary query response into synthesized speech (eg, via mobile computing device alone or via communication with server system 550) may be audible. Can be output. In some embodiments, the summary query response may comprise data for presenting a visual depiction of the summary query response, and data for audibly presenting the summary query response (eg, data for representing a visual depiction). Different voice recordings or sets of text, and synthesized audio from them can be generated).
일부 실시예들에 있어서, 요약 쿼리 응답을 청각적으로 출력하는 것은 모바일 컴퓨팅 장치(500)가, 서버 시스템(550)으로 하여금, 요약 쿼리 응답 내의 데이터로부터 합성된 음성을 생성하기 위한 템플릿을 적용하도록 지원하거나 요청하는 것을 포함한다. 예를 들어, 검색 쿼리의 제출에 응답하여 모바일 컴퓨팅 장치(500)로 웹 페이지가 제공될 수 있다. 웹 페이지는 다수의 상이한 검색 결과들을 디스플레이 하기 위한 마크-업 코드, 및 요약 쿼리 응답을 디스플레이 하기 위한 마크-업 코드를 포함할 수 있다. 모바일 컴퓨팅 장치는 합성된 음성 생성을 위하여, 요약 쿼리 응답에 대한 마크-업 코드를 텍스트로 변환하는 템플릿을 이용할 수 있다. In some embodiments, audibly outputting the summary query response may cause the
＂마멋에 대한 정의＂ 쿼리가 제출된 상기 실시예를 참조로 하면, 요약 쿼리 응답을 생성하는 데에 이용되는 마크-업 코드에 대하여 템플릿이 적용될 수 있다. 템플릿의 적용은 ＂그 마멋에 대한 짧고 숱이 많은 꼬리를 가지고 체격이 다부지며 거친-털로 덮여있는 굴을 파는 설치류이다.＂라는 텍스트의 생성에 이르게 할 수 있다. 생성된 텍스트는 합성된 음성으로서 출력될 수 있다. 이 실시예에 있어서, 템플릿을 이용하여 생성된 텍스트는 (요약 쿼리 응답의 시각적 묘사에서 제시된 바와 같은) 아이콘이나 문서의 소스를 참조로 하지 않으며, ＂그(The)＂와 ＂이다(is)＂라는 단어를 추가한다. 따라서, 템플릿은 요약 쿼리 응답을 시각적으로 묘사하기 위한 정보를 인간 청취자에 의하여 보다 이해할 수 있는 형태로 만든다.With reference to the above embodiment where a definition of a bot query is submitted, a template may be applied to the mark-up code used to generate the summary query response. The application of the template is a burrowing rodent with short, thin tails and a rough-hair covered tail for the dog marmot, which can lead to the creation of the text. The generated text may be output as synthesized voice. In this embodiment, the text generated using the template does not refer to the source of the icon or document (as shown in the visual depiction of the summary query response), but is The and is. Add the word Thus, the template makes the information for visual depiction of the summary query response in a form more humane understandable.
모바일 컴퓨팅 장치(500)는 웹 브라우저(508)를 포함한다. 웹 브라우저는 쿼리 결과 제시기(506)를 포함할 수 있다. 다른 말로 하면, 청각적 출력과 시각적 출력을 제시하기 위한 명령들과 청각적 출력과 시각적 출력에 의하여 정의되는 콘텐츠는 리소스들에 포함될 수 있다. 리소스들은 특정한 URI 에서 리소스들에 대한 요청에 대한 응답으로 서버 시스템으로부터 웹 브라우저(508)가 수신한 것이다.
이제 도 6을 참조하면, 본 명세서에서 설명되는 시스템들과 방법들에 사용될 수 있는 시스템이 개념적인 도면이 도시된다. 모바일 컴퓨팅 장치(610)는 기지국(640)과 무선으로 통신할 수 있으며, 기지국은 모바일 컴퓨팅 장치가 네트워크(650)를 통하여 수많은 서비스들(660)에 접근할 수 있도록 제공할 수 있다. Referring now to FIG. 6, there is shown a conceptual diagram of a system that may be used in the systems and methods described herein. The
본 도면에서, 모바일 컴퓨팅 장치(610)는 모바일 컴퓨팅 장치(610)의 사용자에게 콘텐츠를 제공하기 위한 터치스크린 디스플레이 장치(612)를 포함하는 핸드헬드(handheld) 모바일 폰 (예를 들어, 스마트폰 또는 어플리케이션 폰)으로 도시되었다. 모바일 컴퓨팅 장치(610)는 모바일 컴퓨팅 장치(610)의 동작에 영향을 미치는 사용자-입력을 수신하기 위한 다양한 입력 장치들 (예를 들어, 키보드(614)와 터치스크린 디스플레이 장치(612)을 포함한다. 다른 구현예들(implementations)에 있어서, 모바일 컴퓨팅 장치(610)는 랩탑 컴퓨터, 태플릿 컴퓨터, 개인 휴대정보 단말기(personal digital assistant), 내장형 시스템 (예를 들어, 자동차 내비게이션 시스템), 데스크탑 컴퓨터, 또는 컴퓨터화된 워크스테이션일 수 있다. In this figure,
모바일 컴퓨팅 장치(610)는 다양한 시각적, 청각적, 그리고 촉각적 사용자-출력 메커니즘들을 가질 수 있다. 예시적인 시각적 출력 메커니즘은 디스플레이 장치(612)로, 비디오, 그래픽, 이미지, 그리고 보여지는 사용자 인터페이스와 결합된 텍스트를 시각적으로 디스플레이 할 수 있다. 예를 들어, 디스플레이 장치(612)는 3.7인치AMOLED 스크린일 수 있다. 다른 시각적 출력 메커니즘들은 LED 상태의 발광체들 (예를 들어, 발광체는 음성메일(voicemail)이 수신되면 깜박거림) 을 포함할 수 있다.
예시적인 촉각적 출력 메커니즘은 진동 알림(예를 들어, )수신 전화를 사용자에게 알리기 위하여 진동하거나 터치스크린(612)을 통하여 사용자 접촉을 확인함을 위한 균형 잡히지 않은 무게와 연결된 작은 전기 모터이다. 나아가, 모바일 컴퓨팅 장치(610)는 전기적 신호를 소리, 예를 들어 음악, 청각적 알림, 또는 전화 통화에 대한 개별적인 음성으로 변환하는 하나 이상의 스피커를 포함할 수 있다. An exemplary tactile output mechanism is a small electric motor coupled with an unbalanced weight for vibrating to notify a user of a vibration notification (eg,) incoming call or for confirming user contact via the
사용자-입력을 수신하기 위한 예시적인 메커니즘은 키보드(614)를 포함하며, 키보드는 풀 쿼티(full qwerty) 키보드 또는 ＇0-9＇, ＇*＇, 및 ＇#＇ 디지트들을 위한 키들을 포함하는 전통적인 키보드일 수 있다. 키보드(614)는 사용자가 키보드 키를 물리적으로 접촉하거나 누르는 경우에 입력을 수신한다. 사용자의 트랙볼(616) 조작 또는 트랙패드와의 상호작용은 사용자가 모바일 컴퓨팅 장치(610)에 대하여 방향 그리고 회전 정도에 대한 정보를 공급할 수 있도록 한다 (예를 들어, 디스플레이 장치(612) 상의 커서의 위치를 조작). An example mechanism for receiving user-input includes a
모바일 컴퓨팅 장치(610)는 터치스크린 디스플레이 장치(612)와의 물리적 접촉 위치를 판단할 수 있다 (예를 들어, 손가락 또는 스타일러스(stylus)에 의한 접촉의 위치). 터치스크린(612)을 이용하여, 다양한 ＂가상의＂ 입력 메커니즘들이 생산될 수 있으며, 여기서 사용자는 그래픽 사용자 인터페이스 요소에 접촉하는 것에 의하여 터치스크린(612) 상에 묘사된 그래픽 사용자 인터페이스 요소와 상호 작용할 수 있다. ＂가상의＂ 입력 메커니즘의 일 예는 ＂소프트웨어 키보드＂ 이며, 여기서 키보드는 터치스크린 상에 디스플레이 되어 사용자는 각 키에 상응하는 터치스크린(612)의 영역을 누르는 것에 의하여 키들을 선택한다. The
모바일 컴퓨팅 장치(610)는 기계적인 또는 터치 감도가 좋은(touch sensitive) 버튼들(618a 내지 618d)을 포함할 수 있다. 추가적으로, 모바일 컴퓨팅 장치는 하나 이상의 스피커들(620)에 의한 출력의 볼륨을 조정하기 위한 버튼들, 그리고 모바일 컴퓨팅 장치를 켜거나 끄기 위한 버튼을 포함할 수 있다. 마이크(622)는 모바일 컴퓨팅 장치(610)가 청각적인 소리를 전기적 신호로 변환할 수 있도록 하여 디지털적으로 부호화되어 컴퓨터-판독 가능한(readable) 메모리에 저장되거나, 또 다른 컴퓨팅 장치에 전송될 수 있도록 한다. 또한, 모바일 컴퓨팅 장치(610)는 디지털 나침반(digital compass), 가속도계, 근접 센서들, 그리고 주변(ambient) 광 센서들을 포함할 수 있다.
운영 체제는 모바일 컴퓨팅 장치들의 하드웨어 (예를 들어, 입력/출력 메커니즘들 및 컴퓨터-판독 가능한 매체로부터 도출되는 명령들을 수행하는 프로세서)와 소프트웨어 사이의 인터페이스를 제공할 수 있다. 예시적인 운영 체제들은 안드로이드(ANDROID) 모바일 장치 플랫폼; 애플 아이폰/맥 OS X 운영 체제들; 마이크로소프트 윈도우즈 7/윈도우즈 모바일 운영 체제들; 심비안(SYMBIAN) 운영 체제; 림(RIM) 블랙베리 운영 체제; 팜(PALM) 웹 운영 체제; 다양한 유닉스-향(向)(UNIX-flavored) 운영 체제들; 또는 컴퓨터화된 장치들을 위한 전매(proprietary) 운영 체제를 포함한다. 운영 체제는 컴퓨팅 장치와 사용자 사이의 상호작용을 용이하게 하는 어플리케이션 프로그램들의 실행을 위한 플랫폼을 제공할 수 있다. The operating system can provide an interface between the hardware of the mobile computing devices (eg, a processor that performs instructions derived from input / output mechanisms and computer-readable media) and software. Exemplary operating systems include an Android (ANDROID) mobile device platform; Apple iPhone / Mac OS X operating systems; Microsoft Windows 7 / Windows Mobile Operating Systems; Symbian operating system; RIM BlackBerry operating system; PALM web operating system; Various UNIX-flavored operating systems; Or a proprietary operating system for computerized devices. The operating system can provide a platform for the execution of application programs that facilitate the interaction between the computing device and the user.
모바일 컴퓨팅 장치(610)는 터치스크린(612)과 함께 그래픽 사용자 인터페이스를 제시할 수 있다. 그래픽 사용자 인터페이스는 하나 이상의 그래픽 인터페이스 요소의 집합체이며 정적(static)이거나 (예를 들어, 디스플레이는 시간의 간격이 흘러도 동일하게 유지되도록 나타날 수 있으며), 또는 동적일 수 있다 (예를 들어, 그래픽 사용자 인터페이스는 사용자 입력이 없이도 움직이는(animate) 그래픽 사용자 요소를 포함한다).The
그래픽 인터페이스 요소는 텍스트, 선들, 형태들, 이미지들, 또는 그들의 조합들일 수 있다. 예를 들어, 그래픽 인터페이스 요소는 데스크탑 상에 디스플레이 된 아이콘 그리고 아이콘과 연관된 텍스트일 수 있다. 일부 실시예들에 있어서, 그래픽 인터페이스 요소는 사용자-입력으로 선택 가능할 수 있다. 예를 들어, 사용자는 그래픽 인터페이스 요소의 디스플레이에 상응하는 터치스크린의 영역을 누름으로써 그래픽 인터페이스 요소를 선택할 수 있다. 일부 실시예들에 있어서, 사용자는 트랙볼을 조작하여 단일 그래픽 인터페이스 요소가 초점이 맞추어지도록 강조(highlight)할 수 있다. 그래픽 인터페이스 요소의 사용자-선택은 모바일 컴퓨팅 장치에 의하여 기-정의된 행위를 작동할 수 있다. 일부 실시예들에 있어서, 선택할 수 있는 그래픽 인터페이스 요소들은 부가적으로 또는 대안적으로 키보드(604) 상의 버튼에 상응한다. 버튼의 사용자-선택은 기-정의된 행위를 작동할 수 있다.The graphical interface element can be text, lines, shapes, images, or combinations thereof. For example, the graphical interface element can be an icon displayed on the desktop and text associated with the icon. In some embodiments, the graphical interface element may be selectable by user-input. For example, a user can select a graphical interface element by pressing an area of the touchscreen that corresponds to the display of the graphical interface element. In some embodiments, the user can manipulate the trackball to highlight a single graphical interface element in focus. User-selection of the graphical interface element may operate pre-defined behavior by the mobile computing device. In some embodiments, selectable graphical interface elements additionally or alternatively correspond to buttons on the keyboard 604. The user-selection of the button may activate a pre-defined action.
일부 실시예들에 있어서, 운영 체제는 모바일 컴퓨팅 장치(610)를 켜는 것에 따라, 모바일 컴퓨팅 장치(610)를 휴지 상태(sleep)로부터 활성화하는 것, 모바일 컴퓨팅 장치(610)를 ＂언라킹(unlocking)＂함에 따라, 또는 ＂홈＂ 버튼(618c)의 사용자-선택 수신에 따라서 디스플레이 되는 ＂데스크탑＂ 사용자 인터페이스를 제공한다. 데스크탑 그래픽 인터페이스는, 사용자-입력에 의하여 선택되면, 상응하는 어플리케이션 프로그램들을 작동하는 다수의 아이콘들을 디스플레이 할 수 있다. 작동된 어플리케이션 프로그램은 어플리케이션 프로그램이 종료되거나 또는 시야에서 가려질 때까지 데스크탑 그래픽 인터페이스를 대체하여 제시될 수 있다. In some embodiments, as the operating system turns on the
사용자-입력은 모바일 컴퓨팅 장치(610) 동작의 순서를 조작할 수 있다. 예를 들어, 단일-동작(single-action) 사용자 입력 (예를 들어, 터치스크린의 단일 태핑, 터치스크린을 가로지르는 스와이핑, 버튼 접촉, 또는 동시에 이들을 조합한 것) 은 사용자 인터페이스의 디스플레이를 변화시키는 동작을 작동할 수 있다. 사용자-입력이 없이는, 특정한 시간에 사용자 인터페이스는 변하지 않을 수 있다. 예를 들어, 터치스크린(612)에 대한 멀티-터치 사용자 입력은 지도 어플리케이션이 수 초(seconds) 이후에 줌-인 되도록 디폴트되어 있더라도, 지도 어플리케이션에 있어서 위치에 대하여 ＂줌-인＂ 하도록 작동할 수 있다.The user-input may manipulate the order of operation of the
또한, 데스크탑 그래픽 인터페이스는 ＂위젯(widget)＂을 디스플레이 할 수 있다. 위젯은 실행되는 어플리케이션과 연관되는 하나 이상의 그래픽 인터페이스 요소이며, 실행되는 어플리케이션 프로그램에 의하여 제어되는 데스크탑 콘텐츠 상에 디스플레이 한다. 위젯의 어플리케이션 프로그램은 모바일 폰과 함께 시작될 수 있다. 나아가, 위젯은 전체 디스플레이에 초점을 맞추지 않는다. 대신에, 위젯은 단지 데스크탑의 작은 영역만을 ＂소유(own)＂하여, 콘텐츠를 디스플레이하고 데스크탑의 일부 내에서 터치스크린 사용자-입력을 수신한다. In addition, the desktop graphical interface can display “widgets”. A widget is one or more graphical interface elements associated with an executed application and displayed on desktop content controlled by the executed application program. The application program of the widget may be started with the mobile phone. Furthermore, the widget does not focus on the entire display. Instead, the widget only owns a small area of the desktop, displaying content and receiving touchscreen user-input within a portion of the desktop.
모바일 컴퓨팅 장치(610)는 하나 이상의 위치-식별 메커니즘을 포함할 수 있다. 위치-식별 메커니즘은 운영 체제와 어플리케이션 프로그램의 모바일 폰의 지리적 위치를 측정을 제공하는 하드웨어 및 소프트웨어의 집합체를 포함할 수 있다. 위치-식별 메커니즘은 위성-기반 항법(positioning) 기술, 기지국 전송 안테나 식별, 다중 기지국 삼각법(triangulation), 인터넷 접근 지점(access point) IP 위치 판단, 검색 엔진 쿼리들에 기초한 사용자 위치의 추론(inferential) 식별, 및 사용자-제공 위치의 식별(예를 들어 위치에 대한 ＂체크 인＂)을 사용할 수 있다.
모바일 컴퓨팅 장치(610)는 다른 어플리케이션 모듈과 하드웨어를 포함할 수 있다. 호출 핸들링 유닛은 수신 전화의 지시를 수신하여 수신 전화에 대하여 응답할 수 있는 사용자 능력을 제공한다. 미디어 플레이어는 사용자가 모바일 컴퓨팅 장치(610)의 로컬 메모리에 저장된 음악을 듣거나 영화를 보도록 해준다. 모바일 컴퓨팅 장치(610)는 디지털 카메라 센서, 및 상응하는 이미지 및 비디오 캡쳐 및 편집 소프트웨어를 포함할 수 있다. 인터넷 브라우저는 웹 페이지에 상응하는 주소를 타이핑하는 것에 의하여, 또는 웹 페이지에 대한 링크를 선택하는 것에 의하여 사용자가 웹 페이지로의 콘텐츠를 볼 수 있도록 해준다.
모바일 컴퓨팅 장치(610)는 기지국(640)과 무선으로 정보를 통신하기 위한 안테나를 포함할 수 있다. 기지국(640)은 모바일 컴퓨팅 장치가 지리적으로 이동함에 따라서 네트워크(650)를 통하여 통신을 유지할 수 있도록 해주는 기지국들 집합체 (예를 들어, 모바일 폰 셀룰러 네트워크) 내의 많은 기지국들 중 하나일 수 있다. 컴퓨팅 장치(610)는, 대안적으로 또는 부가적으로, Wi-Fi 라우터 또는 유선 연결 (예를 들어, 이더넷, USB 또는 FIREWIRE) 를 통하여 네트워크(650)와 통신할 수 있다. 또한 컴퓨팅 장치(610)는 블루투스 프로토콜들을 이용하여 다른 컴퓨팅 장치들과 무선으로 통신하거나, 또는 애드-혹 무선 네트워크를 쓸 수 있다. The
기지국들의 네트워크를 동작하는 서비스 제공자는 모바일 컴퓨팅 장치(610)를 네트워크에 연결하여 모바일 컴퓨팅 장치(610)와 다른 서비스들(660)을 제공하는 다른 컴퓨터화된 장치들과 통신할 수 있도록 한다. 서비스들(660)이 상이한 네트워크들을 통하여 제공될 수 있다고 하더라도 (예를 들어, 서비스 제공자의 내부 네트워크, 공중 교환 전화망(Public Switched Telephone Network), 및 인터넷), 네트워크(650)는 단일 네트워크로서 도시되었다. 서비스 제공자는 모바일 컴퓨팅 장치(610)와 서비스들(660)과 연관된 컴퓨팅 장치들 사이의 정보 패킷들과 음성 데이터를 라우팅 하는 서버 시스템(652)을 동작할 수 있다. A service provider operating a network of base stations connects the
네트워크(650)는 모바일 컴퓨팅 장치(610)와 또 다른 컴퓨팅 장치 사이에 음성 또는 팩스 통신을 구축하기 위하여 모바일 컴퓨팅 장치(610)를 공중 교환 전화망(PSTN)(662)에 연결할 수 있다. 예를 들어, 서비스 제공자 서버 시스템(652)은 모바일 컴퓨팅 장치(610)에 대한수신 전화에 대한 지시를 PSTN(662)으로부터 수신할 수 있다. 반대로, 모바일 컴퓨팅 장치(610)는 PSTN(662)을 통하여 접근 가능한 장치와 연관된 전화 번호로 전화 통화를 개시하는 통신을 서비스 제공자 서버 시스템(652)으로 보낼 수 있다. The
네트워크(650)는, PSTN과 반대로, 모바일 컴퓨팅 장치(610)를 IP 네트워크를 통하여 음성 통신을 라우팅 하는 인터넷 전화 통화 규약(Voice over Internet Protocol, VoIP) 서비스(664)와 연결할 수 있다. 예를 들어, 모바일 컴퓨팅 장치(610)의 사용자는 VoIP 어플리케이션을 작동하고 프로그램을 이용하여 호출(Call)을 개시할 수 있다. 서비스 제공자 서버 시스템(652)은 호출로부터의 음성 데이터를 VoIP 서비스로 전달할 수 있으며, VoIP 서비스는 인터넷을 통하여, 연결의 마지막 단계(Final leg)를 위하여 잠재적으로 PSTN을 사용하는, 상응하는 컴퓨팅 장치로 호출을 라우팅 할 수 있다, The
어플리케이션 스토어(666)는 모바일 컴퓨팅 장치(610)의 사용자로 하여금, 사용자가 네트워크(650)를 통하여 다운로드 하여 모바일 컴퓨팅 장치(610)에 설치할 수 있는 어플리케이션 프로그램들이 원격으로 저장된 리스트를 브라우즈 할 수 있도록 한다. 어플리케이션 스토어(666)는 제3자 어플리케이션 개발자에 의하여 개발된 어플리케이션들의 저장소(repository)로서의 역할을 할 수 있다. 모바일 컴퓨팅 장치(610)에 설치된 어플리케이션 프로그램은, 어플리케이션 프로그램에 대하여 지정된 서버 시스템들과 네트워크(650)를 통하여 통신할 수 있다. 예를 들어, VoIP어플리케이션 프로그램이 어플리케이션 스토어(666)로부터 다운로드 되어, 사용자가 VoIP 서비스(664)와 통신할 수 있도록 한다. The
모바일 컴퓨팅 장치(610)는 네트워크(650)를 통하여 인터넷(668) 상의 콘텐츠에 접근할 수 있다. 예를 들어, 모바일 컴퓨팅 장치(610)의 사용자는 지정된 URI 에 접근 가능한 원격 컴퓨팅 장치들로부터 데이터를 요청하는 웹 브라우저를 작동할 수 있다. 다양한 실시예들에 있어서, 서비스들(660)의 일부는 인터넷을 통하여 접근 가능하다.
모바일 컴퓨팅 장치는 개인용 컴퓨터(670)와 통신할 수 있다. 예를 들어, 개인용 컴퓨터(670)는 모바일 컴퓨팅 장치(610)의 사용자를 위한 집 컴퓨터일 수 있다. 따라서, 사용자는 그의 개인용 컴퓨터(670)로부터 미디어를 스트리밍 할 stream) 수 있다. 또한 사용자는 그의 개인용 컴퓨터(670)의 파일 구조를 보고, 컴퓨터화된 장치들 사이에서 선택된 문서들을 전송할 수 있다. The mobile computing device can communicate with a
음성 인식 서비스(672)는 모바일 컴퓨팅 장치의 마이크(622)로 기록된 음성 통신 데이터를 수신하여, 음성 통신을 상응하는 텍스트 데이터로 번역할 수 있다. 일부 실시예들에 있어서, 번역된 텍스트는 검색 엔진에 대하여 웹 쿼리로서 제공되어, 이에 응답하는 검색 엔진 검색 결과들이 모바일 컴퓨팅 장치(610)에 전송된다. The
모바일 컴퓨팅 장치(610)는 소셜(social) 네트워크(674)와 통신할 수 있다. 소셜 네트워크는 수 많은 구성원을 포함할 수 있으며, 이들 중 일부는 지인들(acquaintances)로 연관되는 것을 허용된다. 모바일 컴퓨팅 장치(610)의 어플리케이션 프로그램들은 모바일 컴퓨팅 장치의 사용자의 지인들에 기초하여 소셜 네트워크(674)에 접근하여 정보를 도출할 수 있다. 예를 들어, ＂주소록(address book)＂ 어플리케이션 프로그램은 사용자의 지인들에 대한 전화 번호들을 도출할 수 있다. 다양한 실시예들에 있어서, 콘텐츠는 사용자와 다른 구성원들 사이의 소셜 네트워크 거리에 기초하여 모바일 컴퓨팅 장치(610)에 전달(deliver)될 수 있다. 예를 들어, 광고와 뉴스 기사 콘텐츠는, 이러한 콘텐츠에 대하여 사용자와 ＂친한(close)＂ 구성원들에 의하여 상호작용하는 정도에 기초하여 사용자에 대하여 선택될 수 있다. (예를 들어, 구성원은 ＂친구들＂ 또는 ＂친구들의 친구들＂).
모바일 컴퓨팅 장치(610)는 네트워크(650)를 통하여 연락처(676)의 개인적인 세트에 접근할 수 있다. 각 연락처는 개인을 식별하고 개인에 대한 정보 (예를 들어, 전화번호, 이메일 주소, 및 생일)를 포함할 수 있다. 연락처의 세트가 모바일 컴퓨팅 장치(610)와는 원격으로 관리되기 때문에, 사용자는 공통의 연락처의 세트로서 다수의 장치들을 통하여 연락처(676)에 접근하고 유지할 수 있다.
모바일 컴퓨팅 장치(610)는 클라우드-기반 어플리케이션 프로그램들(678)에 접근할 수 있다. 클라우드-컴퓨팅은 모바일 컴퓨팅 장치(610)로부터 원격으로 관리되고, 웹 브라우저 또는 전용(dedicated) 프로그램을 이용하여 장치(610)에 의하여 접근될 수 있는 어플리케이션 프로그램들 (예를 들어, 워드 프로세서 또는 이메일 프로그램)을 제공한다. 예시적인 클라우드-기반 어플리케이션 프로그램은 구글 문서도구(GOOGLE DOCS) 워드 프로세서 및 스프레드시트 서비스, 구글 지메일(GMAIL) 웹메일 서비스, 및 피카사(PICASA) 사진 관리자를 포함한다.
지도 서비스(680)는 모바일 컴퓨팅 장치(610)에 거리 지도, 경로 안내 정보, 및 위성 이미지들을 제공할 수 있다. 예시적인 지도 서비스는 구글 지도(GOOGLE MAPS) 이다. 또한, 지도 서비스(680)는 쿼리를 수신하고 특정-위치(location-specific) 결과들을 리턴할 수 있다. 예를 들어, 모바일 컴퓨팅 장치(610)는 모바일 컴퓨팅 장치의 측정된 위치와 ＂피자집들＂에 대한 사용자-입력 쿼리를 지도 서비스(680)로 보낼 수 있다. 지도 서비스(680)는 인접한 ＂피자집들＂의 지리적인 위치를 식별하는 ＂표식들(markers)＂을 중첩한(superimpose) 거리 지도를 리턴할 수 있다. The
턴-바이-턴 서비스(682)는 사용자-제공 목적지에 대한 턴-바이-턴 방향(directions)을 모바일 컴퓨팅 장치(610)에 제공할 수 있다. 예를 들어, 턴-바이-턴 서비스(682)는, 장치(610)의 사용자에게 목적지로의 길을 안내하는 음성 명령들과 중첩된 화살표들을 제공하기 위한 데이터를 따라서, 장치의 측정된 위치의 거리-수준 뷰를 장치(610)에 스트리밍 할 수 있다. Turn-by-
미디어 스트리밍 (684)의 다양한 형태들은 모바일 컴퓨팅 장치(610)에 의하여 요청될 수 있다. 예를 들어, 컴퓨팅 장치(610)는 기-기록된 비디오 파일, 라이브 텔레비전 프로그램, 또는 라이브 라디오 프로그램에 대한 스트림을 요청할 수 있다. 미디어를 스트리밍 하기 위한 예시적인 서비스들은 유투브(YOUTUBE) 및 판도라(PANDORA)를 포함한다. Various forms of
마이크로 블로깅(micro-blogging) 서비스(686)는 모바일 컴퓨팅 장치(610)로부터 포스트의 수신자를 식별할 수 없는 사용자-입력 포스트를 수신할 수 있다. 마이크로-블로깅 서비스(686)는 사용자에게 구독을 동의한 마이크로-블로깅 서비스(686)의 다른 구성원들에게 포스트를 퍼뜨릴(disseminate) 수 있다.
검색 엔진(688)은 모바일 컴퓨팅 장치(610)로부터 사용자-입력된 문자 또는 구두(verbal) 쿼리들을 수신하여, 쿼리에 응답한 인터넷-접근 가능한 문서들의 집합을 판단하고, 응답한 문서들에 대한 검색 결과들의 리스트를 디스플레이 하기 위한 정보를 장치(610)에 제공할 수 있다. 구두 쿼리가 수신된 경우의 실시예에 있어서, 음성 인식 서비스(672)는 수신된 오디오를 검색 엔진에 보내지는 문자 쿼리로 번역할 수 있다.
이들 그리고 다른 서비스들은 서버 시스템(690) 내에 구현될 수 있다. 서버 시스템은 서비스 또는 서비스의 집합을 제공하는 하드웨어 및 소프트웨어의 조합일 수 있다. 예를 들어, 물리적으로 분리되고 네트워킹된 컴퓨터화된 장치들의 집합은 함께 논리적인 서버 시스템 유닛으로 동작하여 수 많은 개별 컴퓨팅 장치들에 대한 서비스를 제공하기 위하여 필요한 동작들을 처리한다. These and other services may be implemented within
다양한 구현예들에 있어서, 또 다른 동작 (예를 들어, 판단이나 식별)에 대한 ＂응답으로＂ 수행되는 동작들은, 만일 선행 동작이 성공적이지 않다면 (예를 들어, 만일 판단이 수행되지 않았다면), 수행되지 않는다. 본 명세서 내에서 조건적인 언어로 설명된 특징들은 선택적인 구현예들을 설명할 수 있다. 일부 실시예들에 있어서, 제1 장치로부터 제2 장치로 ＂전송하는 것＂은 제1 장치가 제2 장치에 의한 수신을 위하여 네트워크 안으로 데이터를 위치시키는 것을 의미하지만, 제2 장치가 데이터를 수신하는 것을 포함하지는 않는다. 반대로, 제1 장치로부터 ＂수신하는 것＂은 네트워크로부터 데이터를 수신하는 것을 포함하지만, 제1 장치가 데이터를 전송하는 것을 포함하지는 않는다. In various implementations, the operations performed in response to another action (eg, determination or identification) may be performed if the preceding action is not successful (eg, if the determination was not performed). Not performed. Features described in a conditional language within this specification may describe optional implementations. In some embodiments, “transmitting” from a first device to a second device means that the first device places data into the network for reception by the second device, but the second device receives the data. It doesn't include doing. In contrast, “receiving” from the first device includes receiving data from the network, but does not include transmitting the data from the first device.
도 7 은 본 문서에 기술된 시스템 및 방법들을 수행하기 위해 클라이언트 또는 서버 또는 복수개의 서버들로써 사용될 수 있는 컴퓨팅 장치(700, 750)의 블록 다이어그램이다. 컴퓨팅 장치(700)는 랩탑, 데스트탑, 워크스테이션, PDA, 서버, 블레이드(blade) 서버, 메인프레임, 및 그 밖의 적절한 컴퓨터들과 같은 다양한 형태의 디지털 컴퓨터를 나타내기 위해 사용된다. 컴퓨팅 장치(750)는 PDA, 셀룰러 전화, 스마트폰, 및 그 밖의 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치를 나타내기 위해 사용된다. 부가적으로, 컴퓨팅 장치(700 또는 750)는 USB 플래쉬 드라이브를 포함할 수 있다. USB 플래쉬 드라이브는 운영 체제 및 다른 애플리케이션을 저장할 수 있다. USB 플래쉬 드라이브는, 무선 송신기 또는 또 다른 컴퓨팅 장치의 USB 포트에 삽입될 수 있는USB 커넥터와 같은 입/출력 컴포넌트를 포함할 수 있다. 여기에 보여지는 컴포넌트들, 그 연결 및 관계, 및 그 기능들은 단지 예시적인 것을 의미하고, 본 명세서에서 설명하거나 또는 청구된 발명의 실시예를 제한하는 것을 의미하지 않는다.7 is a block diagram of a computing device 700, 750 that may be used as a client or server or a plurality of servers to perform the systems and methods described herein. Computing device 700 is used to represent various forms of digital computers, such as laptops, desktops, workstations, PDAs, servers, blade servers, mainframes, and other suitable computers. Computing device 750 is used to represent various forms of mobile devices, such as PDAs, cellular telephones, smartphones, and other similar computing devices. Additionally, computing device 700 or 750 may comprise a USB flash drive. USB flash drives can store operating systems and other applications. The USB flash drive can include input / output components, such as a USB connector, which can be inserted into a USB port of a wireless transmitter or another computing device. The components, connections and relationships, and functions thereof shown herein are meant to be exemplary only and are not meant to limit the embodiments of the invention described or claimed herein.
컴퓨팅 장치(700)는 프로세서(702), 메모리(704), 저장 장치(706), 메모리(704)에 접속하는 고속 인터페이스(708)와 고속 확장 포트(710), 및 저속 버스(714)와 저장 장치(706)에 접속하는 저속 인터페이스(712)를 포함한다. 각 구성요소(702, 704, 706, 708, 710, 및 712)는 다양한 버스들을 사용하여 서로 접속되고, 일반적인 마더보드 또는 적절한 경우 다른 방식으로 탑재될 수 있다. 프로세서(702)는 컴퓨팅 장치(700) 내에서 실행하기 위한 명령어를 처리할 수 있으며, 이러한 명령어에는, 고속 인터페이스(708)에 연결된 디스플레이(716)와 같은 외장 입/출력 장치상에서 GUI용 그래픽 정보를 디스플레이 하기 위해, 메모리(704) 또는 저장 장치(706)에 저장되는 명령어가 포함된다. 다른 실시예에서, 다중 프로세서 및/또는 다중 버스는 적절한 경우, 다중 메모리 및 메모리 타입과 함께 사용될 수 있다. 또한, 다중 컴퓨팅 장치(700)는 각 장치가 필요 동작의 부분을 제공하는 형태(예를 들어, 서버 뱅크, 블레이드 서버의 그룹, 또는 다중 프로세서 시스템)로 접속될 수 있다.Computing device 700 stores with processor 702,
메모리(704)는 컴퓨팅 장치(700)내에 정보를 저장한다. 일 실시예에서, 메모리(704)는 휘발성 메모리 유닛 또는 유닛들이다. 또 다른 실시예에서, 메모리(704)는 비휘발성 메모리 유닛 또는 유닛들이다. 또한, 메모리(704)는 마그네틱 또는 광 디스크와 같은 다른 형태의 컴퓨터 판독가능 매체일 수 있다.
저장 장치(706)는 컴퓨팅 장치(700)를 위한 대용량 저장소(mass storage)를 제공할 수 있다. 일 실시예에서, 저장 장치(706)는 플로피 디스크 장치, 하드 디스크 장치, 광 디스크 장치, 또는 테이프 장치, 플래쉬 메모리 또는 다른 유사한 고체 상태(solid state) 메모리 장치, 또는 저장 영역 네트워크 또는 다른 구성에 존재하는 장치를 포함하는 장치 배열(array)일 수 있다. 컴퓨터 프로그램 제품은 정보 캐리어(information carrier) 내에 유형적으로 구체화될 수 있다. 또한, 컴퓨터 프로그램 제품은 실행될 때, 상술한 것과 같은 하나 이상의 방법을 수행하는 명령어를 포함할 수 있다. 정보 캐리어는 메모리(704), 저장 장치(706), 프로세서(702)상의 메모리, 또는 전파된 신호와 같은 컴퓨터 또는 기계 판독가능 매체이다.The
저속 제어부(712)가 저대역-집약적 동작(lower bandwidth-intensive operations)을 관리하는 반면, 고속 제어부(708)는 컴퓨팅 장치(700)에 대한 대역-집약적 동작을 관리한다. 이러한 기능들의 배치는 단지 예시적인 것이다. 일 실시예에서, 고속 제어부(708)는 메모리(704), 디스플레이(716)(예를 들어, 그래픽 프로세서 또는 가속기를 통함)에 연결되고, 다양한 확장 카드(도시되지 않음)을 수용할 수 있는 고속 확장 포트(710)에 연결된다. 일부 실시예에서는, 저속 제어부(712)는 저장 장치(706) 및 저속 확장 포트(714)에 연결된다. 다양한 통신 포트(예를 들어, USB, 블루투스, 이더넷, 무선 이더넷)를 포함할 수 있는 저속 확장 포트는 키보드, 포인팅 장치, 스캐너와 같은 하나 이상의 입/출력 장치들에 연결되거나, 또는 예컨대 네트워크 어댑터를 통하여, 스위치나 라우터와 같은 네트워킹 장치에 연결될 수 있다.The
컴퓨팅 장치(700)는 도면에 도시된 바와 같이, 다양한 다른 형태로 구현될 수 있다. 예를 들어, 컴퓨팅 장치(700)는 표준 서버(720)로 구현되거나 이러한 서버들의 그룹에서 다수 회 구현될 수 있다. 또한, 컴퓨팅 장치(700)는 랙 서버 시스템(724)의 부분으로서 구현될 수 있다. 이에 더하여, 컴퓨팅 장치(700)는 랩탑 컴퓨터(722)와 같은 개인용 컴퓨터내에 구현될 수 있다. 선택적으로, 컴퓨팅 장치 (700)로부터의 구성요소는 장치(750)와 같은 모바일 장치(도시되지 않음)내 다른 구성요소와 조합될 수 있다. 이러한 장치 각각은 하나 이상의 컴퓨팅 장치(700, 750)를 포함하고, 전체 시스템은 서로 통신하는 다중 컴퓨팅 장치(700, 750)로 구성될 수 있다.The computing device 700 may be implemented in various other forms, as shown in the figure. For example, computing device 700 may be implemented as standard server 720 or multiple times in a group of such servers. In addition, computing device 700 may be implemented as part of
컴퓨팅 장치(750)는 여러 구성요소 중에서 프로세서(752), 메모리(764), 디스플레이(754)와 같은 입/출력 장치, 통신 인터페이스(766), 및 트랜스시버(768)를 포함한다. 또한, 장치(750)에는 추가적인 저장소를 제공하기 위하여, 마이크로 드라이브 또는 다른 장치와 같은 저장 장치가 제공될 수 있다. 각 구성요소(750, 752, 764, 754, 766, 및 768)는 다양한 버스를 이용하여 서로 접속되고, 구성요소의 몇몇은 통상의 마더보드에 탑재되거나 적절한 다른 방법으로 탑재될 수 있다.The computing device 750 includes a
프로세서(752)는 컴퓨팅 장치(750) 내에서 명령어를 실행하며, 이 명령어에는 메모리(764)에 저장된 명령어가 포함된다. 프로세서는 개별적이고 다중의 아날로그 및 디지털 프로세서를 포함하는 칩들의 칩 세트로서 구현될 수 있다. 부가적으로, 프로세서는 복수의 아키텍처 중 임의의 아키텍처를 사용하여 구현될 수 있다. 예를 들어, 프로세서(752)는 CISC(Complex Instruction Set Computers) 프로세서, RISC(Reduced Instruction Set Computer) 프로세서, 또는 MISC(Minimal Instruction Set Computer) 프로세서일 수 있다. 프로세서는, 예를 들어, 사용자 인터페이스의 컨트롤, 장치(750)에 의해 실행되는 애플리케이션, 및 컴퓨팅 장치(750)에 의한 무선 통신과 같은 장치(750)의 다른 구성요소들 사이에 조정을 제공할 수 있다.
프로세서(752)는 제어 인터페이스(758) 및 디스플레이(754)에 연결된 디스플레이 인터페이스(756)를 통해 사용자와 통신할 수 있다. 디스플레이(754)는, 예를 들어, TFT LCD(Thin-Film-Tansistor Liquid Crystal Display) 또는 OLED(Organic Light Emitting Diode) 디스플레이, 또는 다른 적절한 디스플레이 기술일 수 있다. 디스플레이 인터페이스(756)는 그래픽 및 다른 정보를 사용자에게 나타내기 위해 디스플레이(754)를 구동하는 적절한 회로를 포함할 수 있다. 제어 인터페이스(758)는 사용자로부터 명령들을 수신하고, 프로세서(752)에 제출하기 위해 그 명령들을 변환한다. 더욱이, 확장 인터페이스(762)는 장치(750)와 다른 장치들간에 근거리 통신이 가능하도록 하기 위해, 프로세서(752)와의 통신에 제공될 수 있다. 확장 인터페이스(762)는, 예를 들어, 일부 실시예에서는 유선 통신을 제공하고 다른 실시예에서 무선 통신을 제공하며, 또한 다중 인터페이스가 사용될 수 있다.The
메모리(764)는 컴퓨팅 장치(750)내에 정보를 저장한다. 메모리(764)는 컴퓨터 판독가능 매체 또는 미디어, 휘발성 메모리 유닛 또는 유닛들, 또는 비휘발성 메모리 유닛 또는 유닛들 중 하나 이상으로서 구현될 수 있다. 또한, 확장 메모리(774)가 제공되어, 예를 들어 SIMM(Single In Line Memory Module) 카드 인터페이스를 포함하는 확장 인터페이스(774)를 통해 장치(750)에 접속될 수 있다. 이러한 확장 메모리(774)는 장치(750)를 위한 여분의 저장 공간을 제공할 수 있고, 또한 어플리케이션 또는 장치(750)를 위한 다른 정보를 저장할 수 있다. 특히, 확장 메모리(774)는 상술된 프로세스를 실행하거나 보조하기 위한 명령어를 포함하고, 또한 보안 정보를 포함할 수 있다. 따라서, 예를 들어, 확장 메모리(774)는 장치(750)용 보안 모듈(security module)로서 제공될 수 있고, 장치(750)의 안전한 사용을 가능하게 하는 명령어로 프로그램 될 수 있다. 더욱이, 보안 어플리케이션은, 해킹할 수 없는 방식(non-hackable manner)으로 SIMM 카드상에 식별 정보를 위치시킨 것과 같은 추가적 정보와 함께 SIMM 카드를 통해 제공될 수 있다.
메모리는 아래에서 논의되는 것과 같이 예를 들어, 플래시 메모리 및/또는 NVRAM 메모리를 포함할 수 있다. 일 실시예에서, 컴퓨터 프로그램 제품은 정보 캐리어에 유형적으로 구체화된다. 컴퓨터 프로그램 제품은 실행될 때, 상술된 것과 같은 하나 이상의 방법을 수행하는 명령어를 포함한다. 정보 캐리어는 메모리(764), 확장 메모리(774), 프로세서(752)상의 메모리, 또는 예를 들어 트랜스시버(768) 또는 확장 인터페이스(762)를 통해 수신될 수 있는 전달된 신호와 같은 컴퓨터-또는 기계-판독가능 매체이다.The memory may include, for example, flash memory and / or NVRAM memory, as discussed below. In one embodiment, the computer program product is tangibly embodied in an information carrier. The computer program product, when executed, comprises instructions for performing one or more methods as described above. The information carrier may be a computer- or machine such as a
장치(750)는 디지털 신호 처리 회로를 필요에 따라 포함하는 통신 인터페이스(766)를 통해 무선으로 통신할 수 있다. 통신 인터페이스(766)는 GSM 음성 호, SMS, EMS, 또는 MMS 메시징, CDMA, TDMA, PDC, WCDMA, CDMA2000, 또는 GPRS 등과 같은 다양한 모드 또는 프로토콜 하에서의 통신을 제공할 수 있다. 이러한 통신은 예를 들어, 무선-주파수 트랜스시버(768)를 통해 수행될 수 있다. 또한, 단거리(short range) 통신은 예를 들어, 블루투스, WiFi, 또는 다른 이러한 트랜스시버(도시되지 않음)를 사용하여 수행될 수 있다. 이에 더하여, GPS(Global Position System) 수신기 모듈(770)은 추가적인 항법- 및 위치- 관련 무선 데이터를 장치(750)에 제공할 수 있다. 이 무선 데이터는 장치(750)에서 실행중인 어플리케이션에 의해 적절하게 사용될 수 있다.The device 750 can communicate wirelessly through a
또한, 장치(750)는 사용자로부터의 발화 정보(spoken information)를 수신하고, 그 발화 정보를 사용 가능한 디지털 정보로 변환하는 오디오 코덱(760)을 이용하여, 청각적으로 통신할 수 있다. 또한, 오디오 코덱(760)은 예를 들어, 장치(750)의 핸드셋 내의 스피커를 통하는 것과 같이 해서, 사용자가 들을 수 있는 음성을 생성한다. 이러한 음성은 음성 전화 호출로부터의 음성을 포함할 수 있고, 녹음된 음성(예를 들어, 음성 메시지, 음악 파일 등)은 포함할 수 있고, 또한 장치(750) 상에서 동작하는 애플리케이션에 의해 생성된 음성을 포함할 수 있다.In addition, the device 750 may audibly communicate with an
컴퓨팅 장치(750)는 도면에 도시된 바와 같이, 복수의 다양한 형태로 구현될 수 있다. 예를 들어, 컴퓨팅 장치(750)는 셀룰러 전화(780)로서 구현될 수 있다. 또한, 컴퓨팅 장치(750)는 스마트폰(782), PDA, 또는 다른 유사한 모바일 장치의 일부로서 구현될 수 있다.The computing device 750 may be implemented in a number of different forms, as shown in the figure. For example, computing device 750 may be implemented as
본 명세서에 설명된 다양한 시스템과 방법의 여러 실시예는 디지털 전자 회로, 집적 회로, 특정 목적으로 설계된 ASICs(application specific integrated circuits), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합으로 실현될 수 있다. 실시예에는 하나 이상의 컴퓨터 프로그램의 실시예가 포함되고, 이 컴퓨터 프로그램은 프로그램 가능한 시스템 상에서 실행가능 및/또는 해석가능(interpretable)하며, 프로그램 가능한 시스템은 저장 시스템에 연결되어 데이터와 명령을 송수신하는, 전용 또는 범용인 적어도 하나의 프로그램 가능한 프로세서, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치를 포함한다.Various embodiments of the various systems and methods described herein may be realized with digital electronic circuits, integrated circuits, application specific integrated circuits (ASICs) designed for specific purposes, computer hardware, firmware, software, and / have. Embodiments include embodiments of one or more computer programs that are executable and / or interpretable on a programmable system, and a programmable system is coupled to a storage system for transmitting and receiving instructions At least one programmable processor, at least one input device, and at least one output device.
이러한 컴퓨터 프로그램(또한, 프로그램, 소프트웨어, 소프트웨어 애플리케이션, 또는 코드라 함)은 프로그램 가능한 프로세서용 기계 명령을 포함하고, 고레벨 절차 및/또는 객체지향 프로그래밍 언어, 및/또는 어셈블리/기계 언어로 구현될 수 있다. 본 명세서에 사용되는 바와 같이, 용어 ＂기계-판독가능 매체＂, ＂컴퓨터-판독가능 매체＂는 기계 명령 및/또는 데이터를 프로그램 가능한 프로세서에 제공하는데 사용되는, 임의의 컴퓨터 프로그램 제품, 장치 및/또는 장치(예를 들어, 자기 디스크, 광디스크, 메모리, 프로그램 가능한 로직 장치(PLD))를 지칭하며, 기계-판독가능 신호로서의 기계 명령을 수신하는 기계-판독가능 매체도 포함된다. 용어 ＂기계-판독가능 신호＂는 기계 명령 및/또는 데이터를 프로그램 가능한 프로세서에 제공하는데 사용되는 임의의 신호를 지칭한다.Such computer programs (also referred to as programs, software, software applications, or code) may include machine instructions for a programmable processor and may be implemented in a high-level procedure and / or object-oriented programming language, and / have. As used herein, the terms "machine-readable medium" and "computer-readable medium" refer to any computer program product, apparatus and / or computer program product, Or machine-readable medium that refers to a device (e.g., magnetic disk, optical disk, memory, programmable logic device (PLD)) and receives machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide a machine instruction and / or data to a programmable processor.
사용자와의 상호작용을 제공하기 위하여, 본 명세서에 설명되는 시스템과 방법은, 정보를 사용자에게 디스플레이 하는 디스플레이 장치(예를 들어, 음극선관(CRT) 또는 LCD(liquid crystal display) 모니터) 및 사용자가 컴퓨터에 입력하는데 사용하는 키보드와 포인팅 장치(예를 들어, 마우스 또는 트랙볼)를 구비한 컴퓨터상에서 구현될 수 있다. 다른 카테고리의 장치도 사용자와의 상호작용을 제공하기 위하여 사용될 수 있다. 예를 들어, 사용자에게 제공되는 피드백은 지각 피드백(시각, 청각 또는 촉각 피드백)의 임의 형태가 될 수 있고, 사용자로부터의 입력은 음향(acoustic), 음성(speech) 또는 촉각 입력을 포함하는 임의 형태로 수신될 수 있다.To provide for interaction with a user, the systems and methods described herein include a display device (e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor) for displaying information to a user, May be implemented on a computer having a keyboard and a pointing device (e.g., a mouse or trackball) for input to a computer. Other categories of devices may also be used to provide interactions with the user. For example, the feedback provided to the user may be any form of the perceptual feedback (visual, auditory, or tactile feedback), and the input from the user may be any form of acoustic, Lt; / RTI >
본 명세서에 설명된 다양한 시스템과 방법은, 백엔드 구성요소(예를 들어, 데이터 서버), 또는 미들웨어 구성요소(예를 들어, 애플리케이션 서버) 또는 전치(frontend) 구성요소(예를 들어, 본 명세서에 설명된 시스템 및 방법의 실시예와 상호작용하기 위해 사용자가 사용할 수 있는 그래픽 사용자 인터페이스(GUI) 또는 웹 브라우저를 구비한 클라이언트 컴퓨터) 또는 이러한 백엔드, 미들웨어 또는 전치(frontend) 구성요소의 임의 조합을 포함하는 컴퓨팅 시스템으로 구현될 수 있다. 시스템의 구성요소는 임의 형태 또는 디지털 데이터 통신의 매체(예를 들어, 통신 네트워크)에 의해 상호접속될 수 있다. 통신 네트워크의 예는 근거리 네트워크(LAN), 광역 네트워크(WAN), 및 인터넷을 포함한다.The various systems and methods described herein may be implemented with a backend component (e.g., a data server), or a middleware component (e.g., an application server) or a frontend component (e.g., A client computer with a graphical user interface (GUI) or web browser that a user can use to interact with embodiments of the described systems and methods), or any combination of such backend, middleware, or frontend components And the like. The components of the system may be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (LAN), a wide area network (WAN), and the Internet.
컴퓨팅 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 떨어져 있고, 통신 네트워크를 통해 상호 작용한다. 클라이언트와 서버의 관계는, 각 컴퓨터에서 실행 중이며 서로에 대하여 클라이언트-서버 관계를 갖는 컴퓨터 프로그램들에 의해 발생한다.The computing system may include a client and a server. Clients and servers are generally separate from each other and interact through a communications network. The relationship between a client and a server is generated by computer programs running on each computer and having a client-server relationship to each other.
다수의 실시예들이 위에서 상세하게 설명되었으나, 다른 변경들이 가능하다. 나아가, 본 명세서에서 설명된 시스템들과 방법들을 수행하기 위한 다른 메커니즘들이 사용될 수 있다. 더욱이, 도면에서 묘사된 논리 흐름은 희망하는 결과를 달성하기 위해, 도시된 특정 순서 또는 시계열적 순서일 필요는 없다. 다른 단계들이 제공되거나, 그로부터 단계들이 제거될 수 있으며, 다른 구성요소들이 설명된 시스템에 추가되거나 그로부터 제거될 수 있다. 따라서 다른 실시예는 후술하는 청구범위의 범위 내에 속한다.While a number of embodiments have been described in detail above, other variations are possible. Furthermore, other mechanisms for performing the systems and methods described herein may be used. Moreover, the logic flow depicted in the figures need not be the specific sequence or time-series sequence shown, in order to achieve the desired result. Other steps may be provided, or steps may be removed therefrom, and other components may be added to or removed from the described system. Accordingly, other embodiments are within the scope of the following claims.
Claims (20)
컴퓨팅 장치에 의하여, 검색 쿼리를 정의하는 사용자 입력을 수신하고, 상기 검색 쿼리를 상기 컴퓨팅 장치와 원격인(remote) 서버 시스템으로 제공하는 단계;
상기 컴퓨팅 장치에 의하여, 상기 검색 쿼리에 응답하여 상기 서버 시스템의 검색 엔진 시스템에서 판단된 정보를 수신하는 단계;
상기 컴퓨팅 장치에 의하여, 상기 컴퓨팅 장치가 제1 상태에 있는 것으로 식별하고, 이에 응답하여, 상기 정보의 적어도 일부를 청각적으로 출력하기 위한 제1 출력 모드를 선택하는 단계 (상기 제1 출력 모드는 상기 제1 출력 모드 및 제2 출력 모드를 포함하는 집합체(collection)로부터 선택되며, 상기 제2 출력 모드는 상기 컴퓨팅 장치가 상기 정보의 상기 적어도 일부를 청각적으로 출력하는 것이 아니라 시각적으로 출력하기 위한 제2 상태에 있는 것에 대한 응답으로 선택됨); 및
상기 컴퓨팅 장치에 의하여 그리고 상기 식별의 결과로서, 상기 정보의 적어도 상기 일부를 청각적으로 출력하는 단계를 포함하는 컴퓨터 프로그램 제품.A computer program product tangibly embedded in a computer-readable storage medium, the computer program product comprising instructions for performing operations when executed by a processor, the operations comprising:
Receiving, by a computing device, user input defining a search query, and providing the search query to a server system remote from the computing device;
Receiving, by the computing device, information determined by a search engine system of the server system in response to the search query;
Identifying, by the computing device, that the computing device is in a first state, and in response, selecting a first output mode for acoustically outputting at least a portion of the information (the first output mode being A collection including the first output mode and a second output mode, wherein the second output mode is for visually outputting the computing device rather than acoustically outputting the at least a portion of the information. Selected in response to being in the second state); And
And audibly outputting at least the portion of the information by the computing device and as a result of the identification.
상기 검색 쿼리를 정의하는 상기 수신된 사용자 입력은 키보드로 제공되는 컴퓨터 프로그램 제품.The method according to claim 1,
And the received user input defining the search query is provided by a keyboard.
상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 식별하는 단계는, 상기 컴퓨팅 장치의 사용자에 의하여 상기 컴퓨팅 장치가 외장 스피커 및 외장 마이크와 통신하는 상태에 있는 것을 판단하는 단계를 포함하는 컴퓨터 프로그램 제품.The method according to any one of claims 1 and 2,
Identifying the computing device as in the first state comprises determining by the user of the computing device that the computing device is in communication with an external speaker and an external microphone.
상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 식별하는 단계는, 상기 컴퓨팅 장치의 센서를 이용하여, 상기 컴퓨팅 장치에 의하여 인지되는 물체와 가까이 있는 것을 판단하는 단계를 포함하는 컴퓨터 프로그램 제품.The method according to any one of claims 1 and 2,
Identifying the computing device as in the first state comprises using a sensor of the computing device to determine that the computing device is in proximity to an object recognized by the computing device.
상기 컴퓨팅 장치가 물체와 가까지 있지 않은 것으로 판단되는 경우에 상기 컴퓨팅 장치는 상기 제2 상태에 있는 것으로 판단되고,
상기 검색 쿼리를 정의하는 상기 사용자 입력이 수신된 경우에 상기 컴퓨팅 장치는 상기 제2 상태에 있는 것으로 판단되는 컴퓨터 프로그램 제품.The method of claim 4,
If it is determined that the computing device is not far from the object, the computing device is determined to be in the second state,
And the computing device is determined to be in the second state when the user input defining the search query is received.
(i) 상기 검색 쿼리에 응답하고, (a) 기정의된 단어들을 포함하는 문장 템플릿 및 (b) 상기 검색 쿼리에 응답하여 식별된 문서로부터의 콘텐츠를 이용하여 구축된 사람이 이해할 수 있는(human-understandable) 산문 문체(prose sentence)를 포함하는, 요약 쿼리 응답; 및
(ii) 상기 검색 쿼리에 응답한 문서를 각각 식별하는 다수의 검색 결과들 (상기 다수의 검색 결과들은 (a) 기정의된 단어들을 포함하는 문장 템플릿 및 (b) 상기 검색 쿼리에 응답하여 식별된 문서로부터의 콘텐츠를 이용하여 구축된 사람이 이해할 수 있는 산문 문장을 포함하지 않음) 을 포함하는 컴퓨터 프로그램 제품.The method of claim 1, wherein the information is:
human constructable using (i) a response template in response to the search query and (a) a sentence template containing predefined words and (b) content from a document identified in response to the search query a summary query response, including an understandable prose sentence; And
(ii) a plurality of search results, each identifying a document responsive to the search query, wherein the plurality of search results are (a) a sentence template containing predefined words and (b) identified in response to the search query Computer program product comprising a prose sentence understandable to a person constructed using content from a document).
상기 청각적 출력은 상기 사람이 이해할 수 있는 산문 문장에 기초한 컴퓨터 프로그램 제품.The method of claim 6,
And said audio output is based on a prose sentence understandable to said person.
상기 요약 쿼리 응답은 디스플레이 내에서 시각적으로 출력되며:
상기 디스플레이는 사용자-선택 가능한 프롬프트를 포함하고, 그리고
상기 동작들은 상기 프롬프트의 선택에 응답하여, 상기 검색 결과들을 디스플레이 하는 단계를 더 포함하는 컴퓨터 프로그램 제품.The method of claim 7,
The summary query response is visually output within the display:
The display includes a user-selectable prompt, and
The operations further comprise displaying the search results in response to selecting the prompt.
상기 검색 결과들은 상기 프롬프트를 선택하는 것에 응답하여 청각적으로 출력되지 않는 컴퓨터 프로그램 제품.The method according to claim 8,
And the search results are not output acoustically in response to selecting the prompt.
상기 동작들은, 상기 청각적 출력 이후에 그리고 상기 프롬프트를 선택하는 사용자 입력을 수신하는 것에 응답하여 상기 검색 결과들을 시각적으로 디스플레이 하는 단계를 더 포함하며, 상기 검색 결과들은 상기 프롬프트를 선택하는 상기 사용자 입력을 수신하기 이전에는 시각적으로 디스플레이 되지 않는 컴퓨터 프로그램 제품.The method according to claim 8,
The operations further include visually displaying the search results after the audio output and in response to receiving a user input of selecting the prompt, wherein the search results comprise the user input of selecting the prompt. A computer program product that is not visually displayed before receiving it.
상기 요약 쿼리 응답 및 상기 다수의 검색 결과들 모두의 시각적 디스플레이를 제공하는 단계를 더 포함하며, 상기 요약 쿼리 응답은 상기 정보를 수신한 이후에 사용자 입력이 없어도 청각적으로 출력되나, 상기 다수의 검색 결과들은 상기 정보를 수신한 이후에 사용자 입력이 제공되지 않으면 청각적으로 출력되지 않는 컴퓨터 프로그램 제품.The method of claim 7,
Providing a visual display of both the summary query response and the plurality of search results, wherein the summary query response is output acoustically without user input after receiving the information, The results are not output acoustically unless user input is provided after receiving the information.
상기 컴퓨팅 장치가 상기 제1 상태에 있는 것으로 식별하는 것은, 상기 검색 쿼리가 수신된 때에 상기 컴퓨팅 장치가 상기 제1 상태에 있었는지 또는 상기 제2 상태에 있었는지 여부에 종속되지 않는 컴퓨터 프로그램 제품.The method according to any one of claims 1 to 4, and 6 to 11,
Identifying that the computing device is in the first state is not dependent upon whether the computing device was in the first state or in the second state when the search query was received.
서버 시스템에 의하여 그리고 컴퓨팅 장치로부터, 사용자에 의하여 상기 컴퓨팅 장치로 입력된 검색 쿼리를 수신하는 단계;
상기 서버 시스템에 의하여, 상기 검색 쿼리에 응답한 문서들을 식별하는 검색 결과들을 판단하는 단계;
상기 서버 시스템에 의하여, 상기 검색 쿼리에 응답한 하나 이상의 상기 문서들로부터의 정보에 기초하여 상기 검색 쿼리에 응답한 요약 쿼리 응답을 생성하는 단계 (상기 요약 쿼리 응답은 상기 검색 결과들을 생성하는 데에 사용되는 템플릿과 상이한 템플릿에 기초하여 생성됨); 및
상기 서버 시스템에 의하여 그리고 상기 컴퓨팅 장치로, 상기 검색 결과들 및 상기 요약 쿼리 응답을 제공하는 단계를 포함하고,
상기 검색 결과들 및 상기 요약 쿼리 응답의 제공에 의하여 상기 컴퓨팅 장치는:
(i) 상기 컴퓨팅 장치가 제1 상태에 있는 것으로 판단하고, 이에 대응하여, 적어도 상기 요약 쿼리 응답을 청각적으로 출력하기 위한 제1 출력 모드를 선택하고 (상기 제1 모드는 상기 제1 출력 모드 및 제2 출력 모드의 집합체로부터 선택되며, 상기 제2 출력 모드는 상기 컴퓨팅 장치가 적어도 상기 검색 결과들을 시각적으로 출력하고 상기 요약 쿼리 응답을 청각적으로 출력하지 않도록 하기 위한 제2 상태에 있는 것에 대한 응답으로 선택됨), 그리고
(ii) 적어도 상기 요약 쿼리 응답을 청각적으로 출력하는 방법.In a computer-implemented method,
Receiving, by a server system and from a computing device, a search query entered by the user by the user;
Determining, by the server system, search results identifying documents that have been answered in the search query;
Generating, by the server system, a summary query response responsive to the search query based on information from one or more of the documents responsive to the search query, wherein the summary query response is used to generate the search results. Generated based on a template different from the template used); And
Providing, by the server system and to the computing device, the search results and the summary query response,
By providing the search results and the summary query response, the computing device:
(i) determine that the computing device is in a first state, and correspondingly, select a first output mode for at least audibly outputting the summary query response (the first mode being the first output mode). And a second output mode, wherein the second output mode is for being in a second state such that the computing device does not visually output at least the search results and does not audibly output the summary query response. Selected as a response), and
(ii) audibly outputting at least the summary query response.
상기 요약 쿼리 응답을 생성하는 단계는 상기 하나 이상의 문서들 내에서 하나 이상의 기지정된 영역들로부터 데이터를 선택하는 단계, 및 기지정된 단어들 및 상기 하나 이상의 기지정된 영역들로부터의 상기 데이터 양자(both)로부터 구축된, 사람이 이해할 수 있는 문장을 생성하기 위하여, 기지정된 단어들을 포함하는 템플릿 내의 슬롯들에 상기 정보를 위치시키는 단계를 포함하는 방법.The method according to claim 13,
Generating the summary query response includes selecting data from one or more predetermined regions within the one or more documents, and both the known words and the data from the one or more predetermined regions. Positioning the information in slots in a template that includes predetermined words, to produce a human understandable sentence constructed from:
상기 요약 쿼리 응답은, 상기 요약 쿼리 응답이 생성되도록 하는 검색 쿼리들의 정의된 리스트 내에 상기 검색 쿼리가 있는 것을 식별하는 것에 응답하여, 상기 서버 시스템에 의하여 생성되는 방법.The method according to any one of claims 13 and 14,
And the summary query response is generated by the server system in response to identifying that the search query is within a defined list of search queries that cause the summary query response to be generated.
상기 요약 쿼리 응답은, 상기 요약 쿼리 응답이 구축되는 하나 이상의 문서들이 판단된 검색 결과라고 식별하는 것에 응답하여, 상기 서버 시스템에 의하여 생성되는 방법.The method according to any one of claims 13 and 14,
And the summary query response is generated by the server system in response to identifying the one or more documents for which the summary query response is constructed are determined search results.
검색 쿼리에 응답하여 서버 시스템으로부터 정보를 수신하는 쿼리 인터페이스 (상기 정보는 (i) 상기 검색 쿼리에 응답한 문서들을 식별하는 다수의 검색 결과들, 및 (ii) 상기 다수의 검색 결과들에 더하여, 그리고 상기 검색 쿼리에 응답한 문서의 콘텐츠로부터 생성되는 요약 쿼리 응답을 포함함);
컴퓨팅 장치가 제1 상태 또는 제2 상태에 있는지 여부를 식별하도록 프로그램 된 컴퓨팅 장치 상태 판단기;
만일 상기 컴퓨팅 장치가 상기 제1 상태에 있다고 판단된다면 상기 다수의 검색 결과들의 저장된 시각적 표현(representation)을 출력하도록 선택하고, 만일 상기 컴퓨팅 장치가 상기 제2 상태에 있는 것으로 판단된다면 상기 요약 쿼리 응답의 저장된 청각적 표현을 출력하도록 선택하는 쿼리 결과 제시기; 및
상기 쿼리 결과 제시기에 의하여 선택된 상기 출력에 기초하여 상기 다수의 검색 결과들의 시각적 표현 및 상기 요약 쿼리 응답의 청각적 표현을 선택적으로 출력하기 위한 오디오 및 시각적 출력 장치들을 포함하는 시스템.In a computer-implemented system:
A query interface for receiving information from a server system in response to a search query, the information comprising (i) a plurality of search results identifying documents that have responded to the search query, and (ii) in addition to the plurality of search results, And a summary query response generated from the content of the document responsive to the search query;
A computing device state determiner programmed to identify whether the computing device is in a first state or a second state;
If it is determined that the computing device is in the first state, select to output a stored visual representation of the plurality of search results; if it is determined that the computing device is in the second state, the summary query response A query result presenter selecting to output a stored auditory representation; And
Audio and visual output devices for selectively outputting a visual representation of the plurality of search results and an audio representation of the summary query response based on the output selected by the query result presenter.
상기 쿼리 결과 제시기는 상기 컴퓨팅 장치가 상기 제1 상태에 있는 경우에 상기 요약 쿼리 응답의 상기 청각적 표현을 출력하도록 선택하지 않는 시스템.18. The method of claim 17,
The query result presenter does not select to output the auditory representation of the summary query response when the computing device is in the first state.
상기 쿼리 결과 제시기는 추가적으로 상기 컴퓨팅 장치가 상기 제2 상태에 있는 경우에 상기 요약 쿼리 응답의 시각적 표현을 출력하도록 선택하는 시스템.The method according to any one of claims 17 and 18,
The query result presenter further selects to output a visual representation of the summary query response when the computing device is in the second state.
상기 컴퓨팅 장치가 (i) 상기 제2 상태에 있고, (ii) 상기 요약 쿼리 응답의 상기 청각적 표현을 출력하면, 상기 시각적 출력 시스템은 상기 검색 결과들 또는 상기 요약 쿼리 응답의 시각적 표현을 출력하지 않는 시스템.The method according to any one of claims 17 and 18,
If the computing device is (i) in the second state and (ii) outputs the audio representation of the summary query response, the visual output system does not output the visual representation of the search results or the summary query response. System does not.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/851,879 | 2010-08-06 | ||
US12/851,879 US10496714B2 (en) | 2010-08-06 | 2010-08-06 | State-dependent query response |
PCT/US2011/045566 WO2012018658A1 (en) | 2010-08-06 | 2011-07-27 | State-dependent query response |
Related Child Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020187005837A Division KR101894499B1 (en) | 2010-08-06 | 2011-07-27 | State-dependent query response |
KR1020167017348A Division KR20160081995A (en) | 2010-08-06 | 2011-07-27 | State-dependent query response |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20130132765A true KR20130132765A (en) | 2013-12-05 |
Family
ID=44629886
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020167017348A KR20160081995A (en) | 2010-08-06 | 2011-07-27 | State-dependent query response |
KR1020137005771A KR20130132765A (en) | 2010-08-06 | 2011-07-27 | State-dependent query response |
KR1020187005837A KR101894499B1 (en) | 2010-08-06 | 2011-07-27 | State-dependent query response |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020167017348A KR20160081995A (en) | 2010-08-06 | 2011-07-27 | State-dependent query response |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020187005837A KR101894499B1 (en) | 2010-08-06 | 2011-07-27 | State-dependent query response |
Country Status (6)
Country | Link |
---|---|
US (7) | US10496714B2 (en) |
EP (3) | EP3093780A1 (en) |
KR (3) | KR20160081995A (en) |
CN (2) | CN103250204B (en) |
AU (1) | AU2011285995B2 (en) |
WO (1) | WO2012018658A1 (en) |
Families Citing this family (38)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8392411B2 (en) * | 2010-05-20 | 2013-03-05 | Google Inc. | Automatic routing of search results |
US10423672B2 (en) * | 2010-10-04 | 2019-09-24 | Excalibur Ip, Llc | Network resource-specific search assistance |
US20120117184A1 (en) * | 2010-11-08 | 2012-05-10 | Aixin Liu | Accessing Android Media Resources from Sony Dash |
JP5315368B2 (en) * | 2011-02-28 | 2013-10-16 | 株式会社日立製作所 | Document processing device |
US20120251016A1 (en) * | 2011-04-01 | 2012-10-04 | Kenton Lyons | Techniques for style transformation |
US9785968B1 (en) * | 2011-07-01 | 2017-10-10 | Google Inc. | Selecting content based on user actions and preferences associates with a same time period in a previous year |
WO2013122269A1 (en) * | 2012-02-13 | 2013-08-22 | 엘지전자 주식회사 | Method for providing user interface on terminal |
KR101978297B1 (en) * | 2012-06-11 | 2019-08-28 | 에스케이플래닛 주식회사 | System for data common service, apparatus and method for data common service |
US9769512B2 (en) * | 2012-11-08 | 2017-09-19 | Time Warner Cable Enterprises Llc | System and method for delivering media based on viewer behavior |
US9721587B2 (en) * | 2013-01-24 | 2017-08-01 | Microsoft Technology Licensing, Llc | Visual feedback for speech recognition system |
US9894312B2 (en) * | 2013-02-22 | 2018-02-13 | The Directv Group, Inc. | Method and system for controlling a user receiving device using voice commands |
TWI502487B (en) * | 2013-10-24 | 2015-10-01 | Hooloop Corp | Methods for voice management, and related devices and computer program prodcuts |
US20150261312A1 (en) | 2014-03-15 | 2015-09-17 | Hovsep Giragossian | Talking multi-surface keyboard |
WO2016033006A1 (en) * | 2014-08-25 | 2016-03-03 | Shorr Arthur | A mask that provides privacy in telephone communications conducted in public |
US9581696B2 (en) | 2014-12-22 | 2017-02-28 | Google Inc. | Image sensor and light source driver integrated in a same semiconductor package |
KR101620779B1 (en) * | 2015-01-08 | 2016-05-17 | 네이버 주식회사 | Method and system for providing retargeting search services |
US10594809B2 (en) * | 2015-03-31 | 2020-03-17 | International Business Machines Corporation | Aggregation of web interactions for personalized usage |
US9852131B2 (en) * | 2015-05-18 | 2017-12-26 | Google Llc | Techniques for providing visual translation cards including contextually relevant definitions and examples |
WO2016185809A1 (en) * | 2015-05-19 | 2016-11-24 | ソニー株式会社 | Information processing apparatus, information processing method, and program |
US10739960B2 (en) * | 2015-09-22 | 2020-08-11 | Samsung Electronics Co., Ltd. | Performing application-specific searches using touchscreen-enabled computing devices |
US9678954B1 (en) * | 2015-10-29 | 2017-06-13 | Google Inc. | Techniques for providing lexicon data for translation of a single word speech input |
US10685029B2 (en) * | 2015-11-23 | 2020-06-16 | Google Llc | Information ranking based on properties of a computing device |
US20170161319A1 (en) * | 2015-12-08 | 2017-06-08 | Rovi Guides, Inc. | Systems and methods for generating smart responses for natural language queries |
US10079021B1 (en) * | 2015-12-18 | 2018-09-18 | Amazon Technologies, Inc. | Low latency audio interface |
CN108009177A (en) * | 2016-10-28 | 2018-05-08 | 百度在线网络技术（北京）有限公司 | A kind of information interacting method, server and client side |
US10339769B2 (en) * | 2016-11-18 | 2019-07-02 | Google Llc | Server-provided visual output at a voice interface device |
SG10202106125YA (en) * | 2016-12-13 | 2021-07-29 | QSIC Pty Ltd | Sound management method and system |
CN108231073B (en) * | 2016-12-16 | 2021-02-05 | 深圳富泰宏精密工业有限公司 | Voice control device, system and control method |
KR102366617B1 (en) | 2017-03-28 | 2022-02-23 | 삼성전자주식회사 | Method for operating speech recognition service and electronic device supporting the same |
US10671602B2 (en) | 2017-05-09 | 2020-06-02 | Microsoft Technology Licensing, Llc | Random factoid generation |
US20190066669A1 (en) * | 2017-08-29 | 2019-02-28 | Google Inc. | Graphical data selection and presentation of digital content |
EP3679539B1 (en) * | 2017-09-06 | 2021-12-22 | Landis+Gyr Innovations, Inc. | Voice-activated energy management system |
US11037554B1 (en) * | 2017-09-12 | 2021-06-15 | Wells Fargo Bank, N.A. | Network of domain knowledge based conversational agents |
US10803077B2 (en) * | 2018-04-30 | 2020-10-13 | Facebook, Inc. | Applying templates to customize presentation of content based on surface type |
JP7086710B2 (en) * | 2018-05-17 | 2022-06-20 | 株式会社ユニバーサルエンターテインメント | Information provision system |
EP3605530B1 (en) * | 2018-08-03 | 2021-01-20 | Vestel Elektronik Sanayi ve Ticaret A.S. | Method and apparatus for responding to a voice command |
CN110238842A (en) * | 2019-04-30 | 2019-09-17 | 北京云迹科技有限公司 | Remote playing method and device for robot |
US11099664B2 (en) | 2019-10-11 | 2021-08-24 | Hovsep Giragossian | Talking multi-surface keyboard |
Family Cites Families (47)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6466232B1 (en) * | 1998-12-18 | 2002-10-15 | Tangis Corporation | Method and system for controlling presentation of information to a user based on the user's condition |
US7844594B1 (en) | 1999-06-18 | 2010-11-30 | Surfwax, Inc. | Information search, retrieval and distillation into knowledge objects |
US6601026B2 (en) | 1999-09-17 | 2003-07-29 | Discern Communications, Inc. | Information retrieval by natural language querying |
US7392185B2 (en) * | 1999-11-12 | 2008-06-24 | Phoenix Solutions, Inc. | Speech based learning/training system using semantic decoding |
US20010032244A1 (en) * | 1999-11-15 | 2001-10-18 | Neustel Michael S. | Internet based help system |
WO2001053970A2 (en) * | 2000-01-24 | 2001-07-26 | Neuronia Ltd. | A system and method for matching requests for information with sources thereof |
US20020137505A1 (en) | 2000-02-18 | 2002-09-26 | Eiche Steven A. | Audio detection for hands-free wireless |
US6999932B1 (en) * | 2000-10-10 | 2006-02-14 | Intel Corporation | Language independent voice-based search system |
JP4240807B2 (en) | 2000-12-25 | 2009-03-18 | 日本電気株式会社 | Mobile communication terminal device, voice recognition method, and recording medium recording the program |
US7027987B1 (en) | 2001-02-07 | 2006-04-11 | Google Inc. | Voice interface for a search engine |
US7289606B2 (en) | 2001-10-01 | 2007-10-30 | Sandeep Sibal | Mode-swapping in multi-modal telephonic applications |
US20030130894A1 (en) * | 2001-11-30 | 2003-07-10 | Alison Huettner | System for converting and delivering multiple subscriber data requests to remote subscribers |
US7519607B2 (en) * | 2002-08-14 | 2009-04-14 | Anderson Iv Robert | Computer-based system and method for generating, classifying, searching, and analyzing standardized text templates and deviations from standardized text templates |
US20040243545A1 (en) * | 2003-05-29 | 2004-12-02 | Dictaphone Corporation | Systems and methods utilizing natural language medical records |
US7360151B1 (en) * | 2003-05-27 | 2008-04-15 | Walt Froloff | System and method for creating custom specific text and emotive content message response templates for textual communications |
US7321852B2 (en) * | 2003-10-28 | 2008-01-22 | International Business Machines Corporation | System and method for transcribing audio files of various languages |
US7650170B2 (en) * | 2004-03-01 | 2010-01-19 | Research In Motion Limited | Communications system providing automatic text-to-speech conversion features and related methods |
US7996372B2 (en) * | 2005-01-18 | 2011-08-09 | Mercury Communications Group, Llc | Automated response to solicited and unsolicited communications and automated collection and management of data extracted therefrom |
JP2006323690A (en) | 2005-05-19 | 2006-11-30 | Sony Corp | Retrieval device, program and retrieval method |
CN1889170B (en) * | 2005-06-28 | 2010-06-09 | 纽昂斯通讯公司 | Method and system for generating synthesized speech based on recorded speech template |
US7672931B2 (en) | 2005-06-30 | 2010-03-02 | Microsoft Corporation | Searching for content using voice search queries |
US7574348B2 (en) * | 2005-07-08 | 2009-08-11 | Microsoft Corporation | Processing collocation mistakes in documents |
US20070050374A1 (en) | 2005-09-01 | 2007-03-01 | Fang Zhao | Novel intelligent search engine |
US8073700B2 (en) | 2005-09-12 | 2011-12-06 | Nuance Communications, Inc. | Retrieval and presentation of network service results for mobile device using a multimodal browser |
US20070067305A1 (en) * | 2005-09-21 | 2007-03-22 | Stephen Ives | Display of search results on mobile device browser with background process |
US7633076B2 (en) | 2005-09-30 | 2009-12-15 | Apple Inc. | Automated response to and sensing of user activity in portable devices |
US7730081B2 (en) | 2005-10-18 | 2010-06-01 | Microsoft Corporation | Searching based on messages |
US7477909B2 (en) | 2005-10-31 | 2009-01-13 | Nuance Communications, Inc. | System and method for conducting a search using a wireless mobile device |
US8751327B2 (en) * | 2006-03-20 | 2014-06-10 | Amazon Technologies, Inc. | Facilitating content generation via messaging system interactions |
JP2007272463A (en) * | 2006-03-30 | 2007-10-18 | Toshiba Corp | Information retrieval device, information retrieval method, and information retrieval program |
US8341112B2 (en) * | 2006-05-19 | 2012-12-25 | Microsoft Corporation | Annotation by search |
US7966324B2 (en) | 2006-05-30 | 2011-06-21 | Microsoft Corporation | Personalizing a search results page based on search history |
US20080005679A1 (en) * | 2006-06-28 | 2008-01-03 | Microsoft Corporation | Context specific user interface |
US7890499B1 (en) | 2006-07-28 | 2011-02-15 | Google Inc. | Presentation of search results with common subject matters |
US20100174544A1 (en) | 2006-08-28 | 2010-07-08 | Mark Heifets | System, method and end-user device for vocal delivery of textual data |
US20080071544A1 (en) * | 2006-09-14 | 2008-03-20 | Google Inc. | Integrating Voice-Enabled Local Search and Contact Lists |
US20080177708A1 (en) | 2006-11-01 | 2008-07-24 | Koollage, Inc. | System and method for providing persistent, dynamic, navigable and collaborative multi-media information packages |
US7895175B2 (en) * | 2006-11-15 | 2011-02-22 | Yahoo! Inc. | Client-side federated search |
CN101216829B (en) * | 2007-12-28 | 2010-06-02 | 丁景涛 | Content search system, apparatus and method |
US8856097B2 (en) * | 2008-01-30 | 2014-10-07 | Yahoo! Inc. | System and/or method for obtaining of user generated content boxes |
US8626249B2 (en) * | 2008-08-12 | 2014-01-07 | T-Mobile Usa, Inc. | Charging station that operates as an intermediary device between mobile devices and other devices |
US7962500B2 (en) * | 2008-10-24 | 2011-06-14 | Yahoo! Inc. | Digital image retrieval by aggregating search results based on visual annotations |
US9978365B2 (en) * | 2008-10-31 | 2018-05-22 | Nokia Technologies Oy | Method and system for providing a voice interface |
US8635528B2 (en) | 2008-11-06 | 2014-01-21 | Nexplore Technologies, Inc. | System and method for dynamic search result formatting |
US20110065428A1 (en) * | 2009-09-16 | 2011-03-17 | At&T Intellectual Property I, L.P | Systems and methods for selecting an output modality in a mobile device |
US8219146B2 (en) * | 2009-11-06 | 2012-07-10 | Sony Corporation | Audio-only user interface mobile phone pairing |
US9244924B2 (en) * | 2012-04-23 | 2016-01-26 | Sri International | Classification, search, and retrieval of complex video events |
-
2010
- 2010-08-06 US US12/851,879 patent/US10496714B2/en active Active
-
2011
- 2011-07-27 KR KR1020167017348A patent/KR20160081995A/en not_active Application Discontinuation
- 2011-07-27 KR KR1020137005771A patent/KR20130132765A/en active Application Filing
- 2011-07-27 CN CN201180044944.3A patent/CN103250204B/en active Active
- 2011-07-27 EP EP16175483.3A patent/EP3093780A1/en not_active Ceased
- 2011-07-27 CN CN201610562696.6A patent/CN105955703B/en active Active
- 2011-07-27 EP EP16175481.7A patent/EP3093779A1/en not_active Ceased
- 2011-07-27 WO PCT/US2011/045566 patent/WO2012018658A1/en active Application Filing
- 2011-07-27 KR KR1020187005837A patent/KR101894499B1/en active IP Right Grant
- 2011-07-27 EP EP11741386.4A patent/EP2601651A1/en not_active Ceased
- 2011-07-27 AU AU2011285995A patent/AU2011285995B2/en active Active
- 2011-09-30 US US13/249,678 patent/US20120036151A1/en not_active Abandoned
-
2016
- 2016-02-05 US US15/016,614 patent/US10599729B2/en active Active
- 2016-02-05 US US15/016,707 patent/US10496718B2/en active Active
-
2017
- 2017-03-16 US US15/460,696 patent/US10621253B2/en active Active
-
2020
- 2020-03-05 US US16/810,069 patent/US11216522B2/en active Active
-
2021
- 2021-12-29 US US17/646,388 patent/US20220121719A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US10496714B2 (en) | 2019-12-03 |
EP3093780A1 (en) | 2016-11-16 |
US10621253B2 (en) | 2020-04-14 |
EP2601651A1 (en) | 2013-06-12 |
KR20180023073A (en) | 2018-03-06 |
KR101894499B1 (en) | 2018-09-04 |
US11216522B2 (en) | 2022-01-04 |
US20160156758A1 (en) | 2016-06-02 |
US20120036121A1 (en) | 2012-02-09 |
US10496718B2 (en) | 2019-12-03 |
US20200201924A1 (en) | 2020-06-25 |
US10599729B2 (en) | 2020-03-24 |
AU2011285995A1 (en) | 2013-02-28 |
CN103250204B (en) | 2016-12-21 |
KR20160081995A (en) | 2016-07-08 |
CN103250204A (en) | 2013-08-14 |
EP3093779A1 (en) | 2016-11-16 |
WO2012018658A1 (en) | 2012-02-09 |
US20170185691A1 (en) | 2017-06-29 |
CN105955703A (en) | 2016-09-21 |
US20120036151A1 (en) | 2012-02-09 |
US20160154881A1 (en) | 2016-06-02 |
CN105955703B (en) | 2019-06-14 |
US20220121719A1 (en) | 2022-04-21 |
AU2011285995B2 (en) | 2014-10-23 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11216522B2 (en) | State-dependent query response | |
US11386915B2 (en) | Remote invocation of mobile device actions | |
US10839805B2 (en) | Disambiguating input based on context | |
US9251793B2 (en) | Method, apparatus, and system for automatically monitoring for voice input based on context | |
CN107111492A (en) | Across all equipment scaling personal digital assistant agency | |
KR20130056252A (en) | Automatic routing using search results | |
CN104541325A (en) | Mixed model speech recognition | |
US9275034B1 (en) | Exceptions to action invocation from parsing rules |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A201 | Request for examination | ||
E902 | Notification of reason for refusal | ||
E90F | Notification of reason for final refusal | ||
A107 | Divisional application of patent |