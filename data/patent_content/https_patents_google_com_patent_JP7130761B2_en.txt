JP7130761B2 - System and method for voice-based activation of custom device actions - Google Patents
System and method for voice-based activation of custom device actions Download PDFInfo
- Publication number
- JP7130761B2 JP7130761B2 JP2020546986A JP2020546986A JP7130761B2 JP 7130761 B2 JP7130761 B2 JP 7130761B2 JP 2020546986 A JP2020546986 A JP 2020546986A JP 2020546986 A JP2020546986 A JP 2020546986A JP 7130761 B2 JP7130761 B2 JP 7130761B2
- Authority
- JP
- Japan
- Prior art keywords
- action
- command
- identifier
- actions
- device action
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000009471 action Effects 0.000 title claims description 520
- 238000000034 method Methods 0.000 title claims description 111
- 230000004913 activation Effects 0.000 title description 4
- 238000012545 processing Methods 0.000 claims description 157
- 230000004044 response Effects 0.000 claims description 109
- 230000005236 sound signal Effects 0.000 claims description 93
- 238000004891 communication Methods 0.000 claims description 62
- 230000003993 interaction Effects 0.000 claims description 41
- 230000005540 biological transmission Effects 0.000 claims description 13
- 230000002452 interceptive effect Effects 0.000 claims description 11
- 238000013507 mapping Methods 0.000 claims description 11
- 238000012360 testing method Methods 0.000 claims description 4
- 230000003213 activating effect Effects 0.000 claims description 3
- 230000000694 effects Effects 0.000 claims description 3
- 230000000977 initiatory effect Effects 0.000 claims 3
- 230000000875 corresponding effect Effects 0.000 description 75
- 238000013515 script Methods 0.000 description 13
- 238000004590 computer program Methods 0.000 description 11
- 238000010586 diagram Methods 0.000 description 10
- 230000008569 process Effects 0.000 description 9
- 230000000007 visual effect Effects 0.000 description 6
- 230000006870 function Effects 0.000 description 4
- 230000004888 barrier function Effects 0.000 description 3
- 238000010411 cooking Methods 0.000 description 3
- 239000000284 extract Substances 0.000 description 3
- 230000000670 limiting effect Effects 0.000 description 3
- 230000007246 mechanism Effects 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 230000003068 static effect Effects 0.000 description 3
- 238000013459 approach Methods 0.000 description 2
- 238000003491 array Methods 0.000 description 2
- 239000003795 chemical substances by application Substances 0.000 description 2
- 230000001276 controlling effect Effects 0.000 description 2
- 238000002059 diagnostic imaging Methods 0.000 description 2
- 230000014509 gene expression Effects 0.000 description 2
- 230000010354 integration Effects 0.000 description 2
- 238000010801 machine learning Methods 0.000 description 2
- 238000007726 management method Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000009877 rendering Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000008093 supporting effect Effects 0.000 description 2
- 230000001960 triggered effect Effects 0.000 description 2
- 239000011800 void material Substances 0.000 description 2
- 230000003190 augmentative effect Effects 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 230000009849 deactivation Effects 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 238000003058 natural language processing Methods 0.000 description 1
- 230000002085 persistent effect Effects 0.000 description 1
- 230000001737 promoting effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000011273 social behavior Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1822—Parsing for meaning understanding
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/183—Speech classification or search using natural language modelling using context dependencies, e.g. language models
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/28—Constructional details of speech recognition systems
- G10L15/30—Distributed recognition, e.g. in client-server systems, for mobile phones or network applications
Description
関連出願の相互参照
本出願は、2018年3月7日に出願された「DISTRIBUTED IDENTIFICATION IN NETWORKED SYSTEM」と題する米国仮特許出願第62/640,007号の利益および優先権を主張し、その全体が参照により本明細書に組み込まれる。
CROSS-REFERENCE TO RELATED APPLICATIONS This application claims the benefit of and priority to U.S. Provisional Patent Application No. 62/640,007, entitled "DISTRIBUTED IDENTIFICATION IN NETWORKED SYSTEM," filed March 7, 2018, the entirety of which is incorporated by reference. incorporated herein by.
デジタル仮想アシスタント(DVA:Digital virtual assistant)は、クライアントデバイスと対話することができる。たとえば、クライアントデバイスのユーザは、音声ベースまたはチャットベースの照会を介して、オンラインタスク、たとえば、オンライン検索またはオンライン取引を起動することができる。DVAは、クライアントデバイスとのハンズフリー対話を可能にすることができる。 A digital virtual assistant (DVA) can interact with a client device. For example, a client device user can initiate an online task, such as an online search or an online transaction, via a voice-based or chat-based inquiry. A DVA can enable hands-free interaction with a client device.
本開示の少なくとも1つの態様によれば、クライアントデバイスとの音声ベース対話を可能にするためのデータ処理システムは、通信インターフェース、メモリ、デバイスアクションカスタマイゼーション構成要素、および自然言語プロセッサ構成要素を備えることができる。通信インターフェースは、デバイスアクションデータおよびデバイスアクションデータに関連付けられた識別子をコンピューティングデバイスから受信することができる。デバイスアクションデータは、複数のクライアントデバイスによってサポートされる複数のデバイスアクション、および複数のデバイス実行可能コマンドを示すことができる。複数のデバイス実行可能コマンドの各デバイス実行可能コマンドは、複数のデバイスアクションのうちの対応するデバイスアクションの実行をトリガするように構成され得る。メモリは、デバイスアクションデータを記憶することができる。デバイスアクションカスタマイゼーション構成要素は、デバイスアクションデータを識別子にマッピングすることができる。通信インターフェースは、オーディオ信号および識別子を複数のクライアントデバイスのうちのクライアントデバイスから受信することができる。オーディオ信号は、音声ベース照会に応答してクライアントデバイスによって取得され得る。自然言語プロセッサ構成要素は、複数のクライアントデバイスによってサポートされる複数のデバイスアクションのうちのデバイスアクションを、識別子、およびオーディオ信号に関連付けられたコンテンツを使用して識別することができる。デバイスアクションカスタマイゼーション構成要素は、デバイスアクションに対応する、複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドを識別することができる。通信インターフェースは、デバイスアクションを遂行させるために、音声ベース照会に応答した実行のためのデバイス実行可能コマンドをクライアントデバイスへ送信することができる。 According to at least one aspect of the present disclosure, a data processing system for enabling voice-based interaction with a client device can comprise a communication interface, a memory, a device action customization component, and a natural language processor component. can. The communication interface can receive device action data and an identifier associated with the device action data from the computing device. The device action data may indicate multiple device actions and multiple device executable commands supported by multiple client devices. Each device-executable command of the plurality of device-executable commands may be configured to trigger execution of a corresponding one of the plurality of device actions. The memory can store device action data. A device action customization component can map device action data to identifiers. A communication interface can receive an audio signal and an identifier from a client device of the plurality of client devices. An audio signal may be obtained by the client device in response to the voice-based inquiry. A natural language processor component can identify a device action of a plurality of device actions supported by a plurality of client devices using the identifier and content associated with the audio signal. A device action customization component can identify a device executable command of a plurality of device executable commands that corresponds to the device action. The communication interface can transmit device-executable commands for execution in response to voice-based queries to the client device to cause device actions to be performed.
本開示の少なくとも1つの態様は、クライアントデバイスとの音声ベース対話を可能にする方法に関する。方法は、受信するデータ処理システムがデバイスアクションデータおよびデバイスアクションデータに関連付けられた識別子をコンピューティングデバイスから受信することを含むことができる。デバイスアクションデータは、複数のクライアントデバイスによってサポートされる複数のデバイスアクション、および複数のデバイス実行可能コマンドを示すことができる。複数のデバイス実行可能コマンドの各デバイス実行可能コマンドは、複数のデバイスアクションのうちの対応するデバイスアクションの実行をトリガすることができる。方法は、データ処理システムが、デバイスアクションデータをメモリの中に記憶することを含むことができる。方法は、データ処理システムが、デバイスアクションデータを識別子にマッピングすることを含むことができる。方法は、データ処理システムが、オーディオ信号および識別子を複数のクライアントデバイスのうちのクライアントデバイスから受信することを含むことができる。オーディオ信号は、音声ベース照会に応答してクライアントデバイスによって取得され得る。方法は、データ処理システムが、複数のクライアントデバイスによってサポートされる複数のデバイスアクションのうちのデバイスアクションを、識別子、およびオーディオ信号に関連付けられたコンテンツを使用して識別することを含むことができる。方法は、データ処理システムが、デバイスアクションに対応する、複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドを識別することを含むことができる。方法は、データ処理システムが、デバイスアクションを遂行させるために、音声ベース照会に応答した実行のためのデバイス実行可能コマンドをクライアントデバイスへ送信することを含むことができる。 At least one aspect of the present disclosure relates to a method of enabling voice-based interaction with a client device. The method may include the receiving data processing system receiving from the computing device the device action data and an identifier associated with the device action data. The device action data may indicate multiple device actions and multiple device executable commands supported by multiple client devices. Each device-executable command of the plurality of device-executable commands can trigger execution of a corresponding one of the plurality of device actions. The method may include the data processing system storing device action data in memory. The method can include the data processing system mapping device action data to identifiers. The method may include a data processing system receiving an audio signal and an identifier from a client device of a plurality of client devices. An audio signal may be obtained by the client device in response to the voice-based inquiry. The method may include a data processing system identifying a device action of a plurality of device actions supported by a plurality of client devices using an identifier and content associated with the audio signal. The method may include the data processing system identifying a device-executable command of a plurality of device-executable commands that corresponds to the device action. The method may include the data processing system sending device-executable commands for execution in response to the voice-based query to the client device to cause the device action to be performed.
本開示の少なくとも1つの態様によれば、音声ベース対話をサポートするための電子デバイスが提供される。電子デバイスは、オーディオレシーバ、通信インターフェース、およびコマンド実行構成要素を含むことができる。オーディオレシーバは、入力音声ベース照会に対応するオーディオ信号を生成することができる。電子デバイスは、リモートデータ処理システムによって保持されるデバイスアクションデータ、およびデバイスアクションデータの識別子に関連付けられ得る。デバイスアクションデータは、デバイスアクションデータに関連付けられた電子デバイスによってサポートされる、複数のデバイスアクションおよび複数のデバイス実行可能コマンドを含むことができる。各デバイス実行可能コマンドは、複数のデバイスアクションのうちの対応するデバイスアクションの実行をトリガするように構成され得る。通信インターフェースは、音声ベース照会に応答して識別子およびオーディオ信号をリモートデータ処理システムへ送信することができる。リモートデータ処理システムは、複数のデバイスアクションおよび複数のデバイス実行可能コマンドに識別子をマッピングする1つまたは複数のデータ構造を保持することができる。通信インターフェースは、オーディオ信号の送信に応答して複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドをリモートデータ処理システムから受信することができる。デバイス実行可能コマンドは、識別子、オーディオ信号、および1つまたは複数のデータ構造に基づいてデータ処理システムによって識別され得る。コマンド実行構成要素は、デバイスアクションを実行するためのデバイス実行可能コマンドを実行するように構成され得る。 According to at least one aspect of the present disclosure, an electronic device is provided for supporting voice-based interaction. Electronic devices can include audio receivers, communication interfaces, and command execution components. An audio receiver can generate an audio signal corresponding to the input speech-based query. An electronic device may be associated with device action data maintained by a remote data processing system and an identifier for the device action data. The device action data can include multiple device actions and multiple device executable commands supported by the electronic device associated with the device action data. Each device executable command may be configured to trigger execution of a corresponding one of multiple device actions. The communication interface can transmit the identifier and an audio signal to the remote data processing system in response to the voice-based inquiry. A remote data processing system may maintain one or more data structures that map identifiers to device actions and device executable commands. The communication interface is capable of receiving device-executable commands of the plurality of device-executable commands from the remote data processing system in response to transmitting the audio signal. A device-executable command may be identified by a data processing system based on an identifier, an audio signal, and one or more data structures. The command execution component may be configured to execute device executable commands for performing device actions.
本開示の少なくとも1つの態様によれば、音声ベース対話をサポートする方法が提供される。方法は、電子デバイスが、入力音声ベース照会に対応するオーディオ信号を生成することを含むことができる。電子デバイスは、リモートデータ処理システムによって保持されるデバイスアクションデータ、およびデバイスアクションデータの識別子に関連付けられ得る。デバイスアクションデータは、デバイスアクションデータに関連付けられた電子デバイスによってサポートされる、複数のデバイスアクションおよび複数のデバイス実行可能コマンドを含むことができる。各デバイス実行可能コマンドは、複数のデバイスアクションのうちの対応するデバイスアクションの実行をトリガするように構成され得る。方法は、電子デバイスが、音声ベース照会に応答して識別子およびオーディオ信号をリモートデータ処理システムへ送信することを含むことができる。リモートデータ処理システムは、複数のデバイスアクションおよび複数のデバイス実行可能コマンドに識別子をマッピングする1つまたは複数のデータ構造を保持することができる。方法は、電子デバイスが、オーディオ信号の送信に応答して複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドをリモートデータ処理システムから受信することを含むことができる。デバイス実行可能コマンドは、識別子、オーディオ信号、および1つまたは複数のデータ構造に基づいてデータ処理システムによって識別され得る。方法は、電子デバイスが、デバイスアクションを実行するためのデバイス実行可能コマンドを実行することを含むことができる。 According to at least one aspect of the present disclosure, a method of supporting voice-based interaction is provided. The method can include the electronic device generating an audio signal corresponding to the input speech-based query. An electronic device may be associated with device action data maintained by a remote data processing system and an identifier for the device action data. The device action data can include multiple device actions and multiple device executable commands supported by the electronic device associated with the device action data. Each device executable command may be configured to trigger execution of a corresponding one of multiple device actions. The method may include the electronic device transmitting the identifier and the audio signal to the remote data processing system in response to the voice-based query. A remote data processing system may maintain one or more data structures that map identifiers to device actions and device executable commands. The method may include the electronic device receiving device-executable commands of the plurality of device-executable commands from the remote data processing system in response to transmitting the audio signal. A device-executable command may be identified by a data processing system based on an identifier, an audio signal, and one or more data structures. The method can include an electronic device executing a device-executable command to perform a device action.
本開示の少なくとも1つの態様によれば、音声ベース対話に応答してコンテンツを提供するためのデータ処理システムが提供される。データ処理システムは、メモリ、デバイスアクションカスタマイゼーション構成要素、通信インターフェース、および自然言語プロセッサ構成要素、ならびにコンテンツ選択器構成要素を含むことができる。メモリは、複数の電子デバイスによってサポートされる複数のデバイスアクションコマンドペアを含むデバイスアクションデータを記憶することができる。各デバイスアクションコマンドペアは、複数のデバイスアクションのそれぞれのデバイスアクション、およびそれぞれのデバイスアクションの遂行をトリガするための複数のデバイス実行可能コマンドのそれぞれのデバイス実行可能コマンドを含むことができる。デバイスアクションカスタマイゼーション構成要素は、複数の電子デバイスによってサポートされる複数のデバイスアクションコマンドペアの各々に識別子をマッピングすることができる。通信インターフェースは、識別子、および音声ベース照会に応答して電子デバイスによって取得された信号を電子デバイスから受信することができる。自然言語プロセッサ構成要素は、オーディオ信号に関連付けられたコンテンツ、および識別子を使用して、複数のデバイスアクションコマンドペアのうちのデバイスアクションコマンドペアを識別することができる。デバイスアクションカスタマイゼーション構成要素は、デバイスアクションデータまたはデバイスコマンドペアに基づいて音声ベース照会のコンテキストを識別することができる。コンテンツ選択器構成要素は、音声ベース照会のコンテキストに基づいてデジタルコンポーネントを選択することができる。通信インターフェースは、デジタルコンポーネント、およびデバイスアクションコマンドペアに関連付けられたデバイス実行可能コマンドを、電子デバイスへ送信することができる。デバイス実行可能コマンドは、実行されたとき、デバイスアクションコマンドペアに関連付けられたデバイスアクションを遂行させることができ、デジタルコンポーネントは、電子デバイスによって提示(すなわちレンダリング)され得る。 According to at least one aspect of the present disclosure, a data processing system is provided for providing content in response to voice-based interaction. The data processing system can include memory, device action customization components, communication interfaces, and natural language processor components, as well as content selector components. The memory can store device action data including multiple device action command pairs supported by multiple electronic devices. Each device action command pair may include a respective device action of a plurality of device actions and a respective device executable command of a plurality of device executable commands for triggering performance of the respective device action. A device action customization component can map an identifier to each of multiple device action command pairs supported by multiple electronic devices. The communication interface can receive from the electronic device the identifier and the signal obtained by the electronic device in response to the voice-based inquiry. A natural language processor component can use content associated with the audio signal and an identifier to identify a device action command pair of the plurality of device action command pairs. A device action customization component can identify the context of a voice-based query based on device action data or device command pairs. A content selector component can select digital components based on the context of the speech-based query. The communication interface can transmit the digital component and the device executable command associated with the device action command pair to the electronic device. A device-executable command, when executed, can cause the device action associated with the device-action command pair to be performed, and the digital component can be presented (ie, rendered) by the electronic device.
本開示の少なくとも1つの態様によれば、音声ベース対話に応答してコンテンツを提供する方法が提供される。方法は、データ処理システムが、複数の電子デバイスによってサポートされる複数のデバイスアクションコマンドペアを含むデバイスアクションデータをメモリの中に記憶することを含むことができる。各デバイスアクションコマンドペアは、複数のデバイスアクションのそれぞれのデバイスアクション、およびそれぞれのデバイスアクションの遂行をトリガするための複数のデバイス実行可能コマンドのそれぞれのデバイス実行可能コマンドを含むことができる。方法は、データ処理システムが、複数の電子デバイスによってサポートされる複数のデバイスアクションコマンドペアの各々に識別子をマッピングすることを含むことができる。方法は、データ処理システムが、識別子、および音声ベース照会に応答して電子デバイスによって取得されたオーディオ信号を電子デバイスから受信することを含むことができる。方法は、データ処理システムが、オーディオ信号に関連付けられたコンテンツ、および識別子を使用して、複数のデバイスアクションコマンドペアのうちのデバイスアクションコマンドペアを識別することを含むことができる。方法は、データ処理システムが、デバイスアクションデータまたはデバイスコマンドペアに基づいて音声ベース照会のコンテキストを識別することを含むことができる。方法は、データ処理システムが、音声ベース照会のコンテキストに基づいてデジタルコンポーネントを選択することを含むことができる。方法は、データ処理システムが、デジタルコンポーネント、およびデバイスアクションコマンドペアに関連付けられたデバイス実行可能コマンドを、電子デバイスへ送信することを含むことができる。デバイスアクションを遂行させるためのデバイス実行可能コマンドは、デバイスアクションコマンドペアに関連付けられ得、デジタルコンポーネントは、電子デバイスによって提示され得る。 According to at least one aspect of the present disclosure, a method of providing content in response to voice-based interaction is provided. The method may include the data processing system storing in memory device action data including a plurality of device action command pairs supported by a plurality of electronic devices. Each device action command pair may include a respective device action of a plurality of device actions and a respective device executable command of a plurality of device executable commands for triggering performance of the respective device action. The method may include the data processing system mapping an identifier to each of a plurality of device action command pairs supported by a plurality of electronic devices. The method may include a data processing system receiving from the electronic device an identifier and an audio signal obtained by the electronic device in response to the voice-based query. The method may include a data processing system identifying device action command pairs of a plurality of device action command pairs using content associated with the audio signal and an identifier. The method may include the data processing system identifying context for the voice-based query based on device action data or device command pairs. The method can include the data processing system selecting digital components based on the context of the speech-based query. The method may include the data processing system sending a digital component and a device executable command associated with the device action command pair to the electronic device. Device-executable commands for performing device actions can be associated with device-action command pairs, and digital components can be presented by the electronic device.
これらおよび他の態様および実装形態が以下で詳細に説明される。上記の情報および以下の発明を実施するための形態は、様々な態様および実装形態の例示的な例を含み、特許請求される態様および実装形態の本質および特性を理解するための概要またはフレームワークを提供する。図面は、様々な態様および実装形態の例示およびさらなる理解をもたらし、本明細書の一部の中に組み込まれ、本明細書の一部を構成する。 These and other aspects and implementations are described in detail below. The information above and the Detailed Description below contain illustrative examples of various aspects and implementations and provide an overview or framework for understanding the nature and characteristics of the claimed aspects and implementations. I will provide a. The drawings provide illustration and further understanding of various aspects and implementations, and are incorporated in and constitute a part of this specification.
添付図面は、一定の縮尺で描画されるものではない。様々な図面における同様の参照番号および指定は、同様の要素を示す。明快のために、すべての構成要素がすべての図面の中で標示され得るとは限らない。 The accompanying drawings are not drawn to scale. Like reference numbers and designations in the various drawings indicate like elements. For the sake of clarity, not all components may be labeled in all drawings.
以下に後続することは、第2当事者デバイス、第3当事者アプリケーション、またはそれらの組合せとのオーディオベース(またはチャットベース)の対話を可能にするための方法、装置、およびシステムに関係する様々な概念およびその実装形態の、より詳細な説明である。上記で紹介され以下でさらに詳細に説明する様々な概念は、数多くのやり方のうちのいずれかで実施され得る。 What follows are various concepts related to methods, apparatus, and systems for enabling audio-based (or chat-based) interactions with second party devices, third party applications, or combinations thereof. and its implementation. The various concepts introduced above and described in further detail below can be implemented in any of numerous ways.
オンラインプラットフォームに関連付けられたクライアントデバイスとの音声ベース(オーディオベース)またはチャットベースの対話を可能にするために、オンラインプラットフォームの中にデジタル仮想アシスタント(DVA)が統合され得る。たとえば、クライアントデバイスのユーザは、音声ベースまたはチャットベースの照会を介して、オンラインタスク、たとえば、オンライン検索またはオンライン取引を起動することができる。DVAは、音声ベースまたはチャットベースの照会を解釈することができ、音声ベースまたはチャットベースの照会の中で要求されたオンラインアクションを起動することができる。概して、DVA能力を有するクライアントデバイスはまた、ユーザの照会を履行するために、それぞれのユーザとのオーディオ会話に従事することができる。ユーザとの意味のある会話を行うとともにユーザの音声ベース照会を正確にサービスするDVA能力は、ユーザエクスペリエンスを著しく高めるので、対応するクライアントデバイスに重大な価値を加える。詳細には、DVAは、クライアントデバイスとのハンズフリー対話を可能にする。加えて、音声ベースまたはチャットベースの入力の正確な解釈、および意味のある応答を伴うと、DVAは、知覚可能なユーザデバイス会話を可能にすることによってクライアントデバイスとのユーザの対話を人間らしくする。 A digital virtual assistant (DVA) may be integrated within the online platform to enable voice-based (audio-based) or chat-based interaction with a client device associated with the online platform. For example, a client device user can initiate an online task, such as an online search or an online transaction, via a voice-based or chat-based inquiry. The DVA can interpret voice-based or chat-based queries and initiate online actions requested within voice-based or chat-based queries. Generally, client devices with DVA capabilities are also able to engage in audio conversations with their respective users in order to fulfill their queries. The DVA's ability to conduct meaningful conversations with users and accurately service their voice-based queries significantly enhances the user experience and thus adds significant value to corresponding client devices. Specifically, DVA enables hands-free interaction with client devices. In addition, with accurate interpretation of voice-based or chat-based input and meaningful responses, DVA humanizes user interactions with client devices by enabling perceptible user device conversations.
対応するクライアントデバイスとのチャットベースまたは音声ベースの対話を可能にするために、オンラインプラットフォームおよび対応するクライアントデバイスの中にDVAが統合され得る。たとえば、DVA機能を実施する1つまたは複数のリモートサーバと通信することが可能なモバイルデバイスまたはスマートホームデバイスのオペレーティングシステム(OS)の中に、DVAクライアント(またはDVAソフトウェアエージェント)が統合され得る。DVA機能を実施するOSおよび1つまたは複数のサーバは、本明細書で第1当事者プロバイダと呼ぶ同じエンティティまたはプロバイダによって提供され得る。そのような統合手法は、それぞれの第2当事者デバイスが、DVAに関連する機能およびサービスをサポートすることを可能にするために、DVAを提供する第1当事者プロバイダとは異なる第2当事者デバイスプロバイダ(たとえば、相手先商標製造会社(OEM)、デバイスメーカー、またはデバイスベンダ)が、自身のDVAを実装できるか、またはDVAエージェントがその中に統合されたOSを採用できるかのいずれかであることを示唆する。両方のオプションは、広い領域の第2当事者デバイスにわたるDVAの拡張にとって限定または障壁を課する。これらの限定および障壁は、(たとえば、第1当事者プロバイダまたは第2当事者プロバイダとは異なる)第3当事者プロバイダによって実装される第3当事者アプリケーション(たとえば、モバイルアプリケーションまたはクライアントアプリケーション)との音声ベース対話が第1当事者デバイスまたは第2当事者デバイスにおいて動作することを可能にするようにDVAの使用を拡張することにも当てはまる。 A DVA may be integrated within the online platform and corresponding client device to enable chat-based or voice-based interaction with the corresponding client device. For example, a DVA client (or DVA software agent) may be integrated within the operating system (OS) of a mobile or smart home device capable of communicating with one or more remote servers implementing DVA functionality. The OS and one or more servers implementing the DVA functionality may be provided by the same entity or provider, referred to herein as the first party provider. Such an integration approach uses a different second party device provider ( For example, an original equipment manufacturer (OEM), device manufacturer, or device vendor) can either implement its own DVA or adopt an OS with a DVA agent integrated within it. Suggest. Both options impose limitations or barriers to the extension of DVA over large areas of second party devices. These limitations and barriers imply that voice-based interaction with a third party application (e.g., mobile application or client application) implemented by a third party provider (e.g., different from a first party provider or second party provider) is The same applies to extending the use of DVA to allow it to operate on a first party device or a second party device.
第2当事者デバイスプロバイダにとって、既存のOSを修正すること、またはDVAクライアントを統合する新たなOSを採用することは、問題を起こすことがあり、技術的に重荷となることがあり、かつコストがかかることがある。OSに変更が行われることにならなくても、それぞれの第1当事者プロバイダの既存のDVAを使用することは、第2当事者デバイスのプロバイダが、そのDVAプラットフォームまたはDVAサーバと通信するとともにそれぞれの第2当事者デバイスにサービスするための(たとえば、クラウドサーバを経由した)クラウド存在感を保持することを、必要とする場合がある。また、それぞれの第1当事者プロバイダの既存のDVAを使用すると、第2当事者デバイスのプロバイダには、彼らのデバイスとの音声ベース対話を差別化し、または競合者よりも多くの差異化された経験を顧客に提供するためのカスタマイゼーションの柔軟性が、あるとしてもほんのわずかにしか与えられない。たとえば、所与の第2当事者デバイスとの音声ベース対話において使用される語彙の範囲および領域は、(たとえば、他のデバイスとの音声ベース対話において使用される語彙の範囲および領域と比較して)比較的狭く特有であり得る。詳細には、(たとえば、所与のタイプまたはモデルの)各デバイスは、他のデバイスによってサポートされるデバイスアクションとは異なってよいデバイスアクションの対応する特定のセットをサポートし得る。デバイスとのユーザ相互作用が、通常は対応するデバイスアクションをトリガすることを伴うので、所与のタイプまたはモデルのデバイスによってサポートされるデバイスアクションを規定する狭い語彙範囲を使用することは、DVAシステムが所与のタイプまたはモデルのデバイスにもっと良好にサービスする助けとなることができる。DAVシステムは、音声ベース照会を解釈しそのような照会への知覚可能な応答を提供する際の、その確度を改善することができる。本明細書で使用するとき、DVAシステムとは、サーバ側のDVA機能を提供するデータ処理システムを指す。 For a second party device provider, modifying an existing OS or adopting a new OS that integrates a DVA client can be problematic, technically burdensome, and costly. It may take Even if no changes are made to the OS, using each first party provider's existing DVA allows the second party device provider to communicate with its DVA platform or DVA server as well as each second party device. It may be necessary to maintain a cloud presence (eg, via a cloud server) for servicing two-party devices. Also, using each first-party provider's existing DVA would give second-party device providers a differentiated voice-based interaction with their devices, or a more differentiated experience than their competitors. It gives little, if any, customization flexibility to offer customers. For example, the range and range of vocabulary used in voice-based interactions with a given second party device (e.g., compared to the range and range of vocabulary used in voice-based interactions with other devices) It can be relatively narrow and specific. In particular, each device (eg, of a given type or model) may support a corresponding specific set of device actions that may differ from those supported by other devices. Since user interaction with a device usually involves triggering a corresponding device action, using a narrow vocabulary that defines the device actions supported by a given type or model of device is a DVA system. can help serve a given type or model of device better. DAV systems can improve their accuracy in interpreting voice-based queries and providing perceptible responses to such queries. As used herein, a DVA system refers to a data processing system that provides server-side DVA functionality.
DVAベースのサービスまたは能力(たとえば、音声ベースまたはチャットベースの対話)の使用を第3当事者アプリケーションに拡張することに関しても、類似の限定および障壁が当てはまる。第3当事者アプリケーションは、第3当事者の開発者によって開発されたモバイルアプリケーション、クライアントアプリケーション、または他のアプリケーションを含むことができる。本明細書で使用するとき、第3当事者とは、DVAシステムを提供するエンティティ(本明細書では第1当事者とも呼ばれる)およびアプリケーションがその上で実行または動作し得るデバイスを提供するエンティティ(本明細書では第2当事者とも呼ばれる)とは異なるエンティティ(たとえば、アプリケーション開発者)である。第3当事者アプリケーションは、最初に製造段階または開発段階においてはデバイス上にインストールされないことがあり、むしろ市場においてデバイスが販売された後にダウンロードおよびインストール(または開発さえも)されることがある。デバイスがDVAクライアントをサポートしても、デバイス上で動作する第3当事者アプリケーションは、たとえば、第3当事者アプリケーションまたはそのコンテンツとの音声ベース対話を可能にするための、DVAの機能を採用できないことがある。 Similar limitations and barriers apply with respect to extending the use of DVA-based services or capabilities (eg, voice-based or chat-based interactions) to third-party applications. Third party applications can include mobile applications, client applications, or other applications developed by third party developers. As used herein, third party refers to the entity that provides the DVA system (also referred to herein as the first party) and the entity that provides the device on which applications may run or operate (herein (also referred to as a second party in the literature). Third party applications may not be installed on a device initially during the manufacturing or development stages, but rather may be downloaded and installed (or even developed) after the device has been sold on the market. Even if a device supports a DVA client, third party applications running on the device may not be able to adopt DVA's functionality, e.g., to enable voice-based interaction with the third party application or its content. be.
本開示では、セルフサービス手法により、第2当事者デバイスプロバイダまたは第3当事者アプリケーションプロバイダがそれぞれのカスタムアクションをトリガするために音声ベース(またはチャットベース)の対話を可能にすることが許容され得る。第2当事者デバイスプロバイダは、それぞれのグループのデバイス(たとえば、所与のタイプ、カテゴリー、またはモデルのデバイス)によってサポートされるカスタムデバイスアクションのバンドル(またはアクションパッケージ)を構築または定義することができ、そのバンドル(またはアクションパッケージ)をDVAシステムに提供することができる。カスタムデバイスアクションの各バンドルは、それぞれのグループのデバイスおよび1つまたは複数の対応するデバイス実行可能コマンドによってサポートされる1つまたは複数のデバイスアクションを含むことができる(または指定することができる)。カスタムデバイスアクションのバンドルにおける各デバイスアクションは、それぞれのグループのデバイスのうちの任意のデバイス上でそのデバイスアクションを実行するための(またはそれを遂行させるための)、対応するデバイス実行可能コマンドが関連付けられ得る。カスタムデバイスアクションのバンドルはまた、それぞれのデバイスアクションごとに、そのデバイスアクションの実行に関してそれぞれのグループのデバイスのうちの任意のデバイス上での提示のために提供されるべき、対応する応答(たとえば、オーディオ応答、ビジュアル応答、またはオーディオビジュアル応答)を含んでよい(または指定してよい)。 In the present disclosure, a self-service approach may allow second party device providers or third party application providers to enable voice-based (or chat-based) interactions to trigger their respective custom actions. Second party device providers may build or define bundles (or action packages) of custom device actions supported by their respective group of devices (e.g., devices of a given type, category, or model); That bundle (or action package) can be provided to the DVA system. Each bundle of custom device actions can include (or specify) one or more device actions supported by the respective group of devices and one or more corresponding device executable commands. Each device action in a bundle of custom device actions is associated with a corresponding device-executable command for executing that device action (or causing it to be accomplished) on any of the devices in the respective group. can be The bundle of custom device actions also includes, for each device action, a corresponding response (e.g., audio response, visual response, or audiovisual response) may be included (or specified).
DVAシステムは、それぞれの識別子に関連してカスタムデバイスアクションの各バンドルを保持することができる。識別子は、カスタムデバイスアクションのバンドルに関連付けられたデバイスのグループのデバイスモデルを示すデバイスモデル識別子(ID)、第2当事者デバイスプロバイダの識別子、バンドルID、カスタムデバイスアクションのバンドルがその下に保持されるディレクトリのディレクトリID、またはそれらの組合せであり得る。第2当事者デバイスプロバイダは、カスタムデバイスアクションのバンドルとともに、識別子をDVAシステムに提供することができる。カスタムデバイスアクションのバンドル、および識別子をDVAシステムに提供するプロセスは、対応するデバイスグループのデバイス(または対応するデバイスモデル)の、DVAシステムへの登録として見られ得る。デバイスモデル(またはデバイスのグループ)を登録することはまた、(たとえば、デバイスモデルに関連付けられた)デバイスのグループの性質、特性、機能、もしくは能力の表示、デバイスのグループまたはデバイスモデルに関連付けられた他のメタデータ、またはそれらの組合せを提供することを含んでよい。DVAシステム(またはその第1当事者プロバイダ)は、たとえば、ユーザインターフェース(UI)、ウェブインターフェース、またはRESTfulアプリケーションプログラミングインターフェース(API)を介して、第2当事者デバイスプロバイダがデバイスモデル(またはデバイスのグループ)をDVAシステムに登録することを可能にすることができる。第1当事者プロバイダまたはDVAシステムは、たとえば、カスタムデバイスアクションのバンドルの中で提供されるデバイス実行可能コマンドのテストに成功すると、デバイスモデル(またはデバイスのグループ)を有効化(または認証)してよい。 The DVA system can keep each bundle of custom device actions associated with their respective identifiers. The identifier is a device model identifier (ID) that indicates the device model of the group of devices associated with the custom device action's bundle, the second party device provider's identifier, the bundle ID, and the custom device action's bundle under which it is held. It can be the directory ID of the directory, or a combination thereof. A second party device provider can provide an identifier to the DVA system along with a bundle of custom device actions. The process of bundling custom device actions and providing identifiers to the DVA system can be viewed as registering devices of corresponding device groups (or corresponding device models) with the DVA system. Registering a device model (or group of devices) also means an indication of the nature, characteristics, capabilities, or capabilities of the group of devices (e.g., associated with the device model), the It may include providing other metadata, or a combination thereof. The DVA system (or its first-party provider) provides a device model (or group of devices) to a second-party device provider, for example, via a user interface (UI), web interface, or RESTful application programming interface (API). It can be enabled to register with the DVA system. A first party provider or DVA system may activate (or certify) a device model (or group of devices), for example, upon successfully testing a device executable command provided in a bundle of custom device actions. .
同様に、第3当事者アプリケーションプロバイダは、それぞれのアプリケーションによってサポートされるカスタムアプリケーションアクションのバンドル(またはパッケージ)を構築または定義することができ、そのバンドル(またはパッケージ)をDVAシステムに提供することができる。カスタムアプリケーションアクションのバンドルは、アプリケーションおよび1つまたは複数の対応するアプリケーション実行可能コマンドによってサポートされる1つまたは複数のアクションを含むことができる。各カスタムアプリケーションアクションは、そのカスタムアプリケーションアクションをアプリケーションに実行させるための、対応するアプリケーション実行可能コマンドが関連付けられ得る。カスタムデバイスアクションのバンドルと同様に、DVAシステムは、それぞれの識別子に関連してカスタムアプリケーションアクションの各バンドルを保持することができる。識別子は、アプリケーションID、第3当事者アプリケーションプロバイダID、バンドルID、またはカスタムアプリケーションアクションのバンドルがその下に保持されるディレクトリ(またはプロジェクト)を示すディレクトリIDであり得る。 Similarly, third-party application providers can build or define a bundle (or package) of custom application actions supported by their respective applications, and provide that bundle (or package) to the DVA system. . A bundle of custom application actions can include one or more actions supported by an application and one or more corresponding application executable commands. Each custom application action can be associated with a corresponding application executable command for causing the application to perform that custom application action. Similar to bundles of custom device actions, the DVA system can maintain each bundle of custom application actions in association with a respective identifier. The identifier can be an application ID, a third party application provider ID, a bundle ID, or a directory ID that indicates the directory (or project) under which the bundle of custom application actions is kept.
第1当事者プロバイダまたはDVAシステムは、音声ベースユーザ対話を可能にするために第2当事者デバイスまたは第3当事者アプリケーションの統合のための1つまたは複数のソフトウェア開発キット(SDK)を提供することができる。第1当事者プロバイダは、別個のSDKを第2当事者デバイスおよび第3当事者アプリケーションに提供することができる。SDKは、第2当事者デバイスまたは第3当事者アプリケーションの中に統合されたとき、オーディオレシーバ(たとえば、マイクロフォン)をアクティブ化すること、会話を起動すること、DVAシステムとの通信セッションを起動すること、要求を送るとともにDVAシステムから応答を受信すること、DVAシステムから受信された応答を構文解析すること、またはそれらの組合せのためのソフトウェアツールを提供することができる。また、第2当事者デバイスプロバイダまたは第3当事者アプリケーションプロバイダは、デバイス実行可能コマンドまたはアプリケーション実行可能コマンドのオンデバイス実行を実行するためのオンデバイスアクションハンドラを構築することができる。 A first party provider or DVA system may provide one or more software development kits (SDKs) for integration of second party devices or third party applications to enable voice-based user interaction. . A first party provider may provide separate SDKs for second party devices and third party applications. The SDK, when integrated into a second party device or third party application, activates an audio receiver (e.g., a microphone), initiates a conversation, initiates a communication session with a DVA system, Software tools can be provided for sending requests and receiving responses from the DVA system, parsing responses received from the DVA system, or a combination thereof. Second party device providers or third party application providers can also build on-device action handlers to perform on-device execution of device-executable commands or application-executable commands.
(たとえば、登録済みのデバイスグループまたはデバイスモデルに関連付けられた)第2当事者デバイスは、それぞれのユーザから音声ベース照会を受け取ることができ、音声ベース照会に対応するオーディオ信号を生成することができる。第2当事者デバイスは、それぞれのアクションパッケージに関連付けられた識別子(たとえば、デバイスモデルID)と一緒にオーディオ信号をDVAシステムへ送信することができる。DVAシステムは、オーディオ信号および識別子に基づいて、カスタムデバイスアクションのそれぞれのアクションパッケージの中で列挙されたデバイスアクションの間でデバイスアクションを識別することができる。デバイスアクションを識別する際に、DVAシステムは、それぞれのアクションパッケージの中で列挙されたアクションを示す表現または照会パターンに、異なる重みを割り当てることができる。DVAシステムは、デバイスモデルによってサポートされるデバイスアクションを示す照会パターンに対して、コンテキスト音声バイアスを用いたコンテキストデバイスアクション整合およびランク付けメカニズムを適用することができる。たとえば、複数の照会パターンのうちの照会パターンに受信オーディオ信号を整合させる際に、DVAシステムは、デバイスモデルによってサポートされるデバイスアクションに関連付けられた(またはそれを示す)照会パターンに、バイアスを適用することができる。 Second party devices (eg, associated with registered device groups or device models) can receive voice-based queries from their respective users and can generate audio signals corresponding to the voice-based queries. The second party device can send an audio signal to the DVA system along with an identifier (eg, device model ID) associated with each action package. The DVA system can identify device actions among device actions enumerated in respective action packages of custom device actions based on the audio signal and the identifier. In identifying device actions, the DVA system can assign different weights to expressions or query patterns that indicate actions listed in each action package. The DVA system can apply a contextual device action matching and ranking mechanism with contextual audio bias to query patterns that indicate device actions supported by the device model. For example, in matching a received audio signal to a query pattern of multiple query patterns, the DVA system applies a bias to the query pattern associated with (or indicative of) device actions supported by the device model. can do.
DVAシステムは、識別されたデバイスアクションに関連付けられたデバイス実行可能コマンドを取り出すことができ、そのデバイス実行可能コマンドを実行のために第2当事者デバイスへ送ることができる。DVAシステムはまた、識別されたデバイスアクションに関連付けられた応答を取り出すことができ、音声ベース照会の中で要求されたデバイスアクションの実行の前、実行中、または実行の後に、その応答のオーディオバージョンをユーザへの提示(または再生)のために第2当事者デバイスへ送ることができる。第2当事者デバイスがデバイス実行可能コマンドを受信すると、オンデバイスアクションハンドラは、DVAシステムから受信された通信からデバイス実行可能コマンドを抽出することまたは取り出すことができ、音声ベース照会の中で要求されたデバイスアクションを実行するためのデバイス実行可能コマンドを第2当事者デバイスに実行させることができる。第2当事者デバイスは、デバイスアクションの実行の前、実行中、または実行の後に、(DVAシステムから受信された)任意のオーディオ応答、ビジュアル応答、またはオーディオビジュアル応答を再生することができる。 The DVA system can retrieve the device-executable command associated with the identified device action and send the device-executable command to the second party device for execution. The DVA system can also retrieve the response associated with the identified device action and provide an audio version of that response before, during, or after performing the device action requested in the voice-based query. can be sent to the second party device for presentation (or playback) to the user. When the second party device receives the device executable command, the on-device action handler can extract or retrieve the device executable command from the communication received from the DVA system and request it in the voice-based query. A second party device can be caused to execute a device executable command for performing a device action. The second party device can play any audio, visual, or audiovisual response (received from the DVA system) before, during, or after execution of the device action.
(たとえば、その中に統合されデバイス上で動作するSDKを有する)第3当事者アプリケーションは、対話式ユーザインターフェース(UI)構成要素をデバイスのディスプレイ上での提示のために提供することができる。デバイスのユーザは、たとえば、第3当事者アプリケーションとの会話を始めるために、(たとえば、クリック、タッチ、またはスワイプすることによって)対話式UI構成要素と対話することができる。ユーザから音声ベース照会を受け取ると、アプリケーションは、音声ベース照会に対応するオーディオ信号を生成することができ、それぞれのアクションパッケージに関連付けられた識別子(たとえば、アプリケーションID、アクションパッケージID、ディレクトリID)と一緒にオーディオ信号をDVAシステムへ送信することができる。DVAシステムは、オーディオ信号および識別子に基づいて、それぞれのアクションパッケージの中で列挙されたカスタムアプリケーションアクションの間でアプリケーションアクションを識別することができる。デバイスアクションを識別する際に、DVAシステムは、それぞれのアクションパッケージの中で列挙されたアクションを示す表現または照会パターンに、異なる重みを割り当てることができる。DVAシステムは、第3当事者アプリケーションによってサポートされるアプリケーションアクションを示す照会パターンに対して、コンテキスト音声バイアスを用いたコンテキストデバイスアクション整合およびランク付けメカニズムを適用することができる。DVAシステムは、アプリケーションアクションに関連付けられたコマンドを識別することができ、そのコマンドを第3当事者アプリケーションによる実行のためにデバイスへ送信することができる。 A third party application (eg, having an SDK integrated therein and running on the device) can provide interactive user interface (UI) components for presentation on the device's display. A user of the device can interact with interactive UI components (eg, by clicking, touching, or swiping) to initiate a conversation with the third party application, for example. Upon receiving a voice-based query from a user, the application can generate an audio signal corresponding to the voice-based query, and an identifier (e.g., application ID, action package ID, directory ID) associated with each action package and Along with it, an audio signal can be sent to the DVA system. The DVA system can distinguish application actions among custom application actions enumerated in respective action packages based on audio signals and identifiers. In identifying device actions, the DVA system can assign different weights to expressions or query patterns that indicate actions listed in each action package. The DVA system can apply a contextual device action matching and ranking mechanism with contextual speech bias to query patterns that indicate application actions supported by third party applications. The DVA system can identify commands associated with application actions and can send the commands to the device for execution by the third party application.
DVAシステムはまた、識別子、識別されたデバイスもしくはアプリケーションアクション、デバイスの識別子、またはそれらの組合せを使用して、音声ベース照会のコンテキストを識別することができる。音声ベース照会のコンテキストを識別することは、音声ベース照会の背後のユーザ意図を識別することを含むことができる。DVAシステムは、第3当事者デジタルコンポーネント(たとえば、広告)などのデジタルコンポーネントを音声ベース照会のコンテキストに基づいて選択することができ、そのデジタルコンポーネントを提示のためにデバイスへ送ることができる。デジタルコンポーネントは、オーディオコンテンツまたはオーディオビジュアルコンテンツを含むことができる。デジタルコンポーネントは、サービスまたは製品をユーザに提案または提供するための販売促進コンテンツを含むことができる。デバイスは、音声ベース照会への自然応答の一部としてユーザに感じさせるか、そのように見えるように、デジタルコンポーネントをシームレスに提示することができる。 The DVA system can also use identifiers, identified device or application actions, device identifiers, or combinations thereof to identify the context of voice-based queries. Identifying the context of the speech-based query can include identifying user intent behind the speech-based query. The DVA system can select digital components, such as third party digital components (eg, advertisements), based on the context of the voice-based query, and send the digital components to the device for presentation. Digital components can include audio or audiovisual content. Digital components can include promotional content for offering or providing services or products to users. The device can seamlessly present the digital component in a manner that makes the user feel or appear to be part of a natural response to a voice-based inquiry.
本開示の例示的な実施形態によれば、本明細書で説明するシステム、方法、およびデバイスは、第2当事者デバイスプロバイダまたは第3当事者アプリケーションプロバイダが、第1当事者プロバイダに関連するDVAシステムと通信するためのクラウドポイントを保持することなく、デバイスアクションのオンデバイス実行モデルを採用することによって、第2当事者デバイスまたは第3当事者アプリケーションとの音声ベース対話を可能にする。DVAシステムは、第2当事者デバイスからオーディオ照会を受信することができ、要求されたデバイスまたはアプリケーションアクションを識別するために音声認識およびスマート自然言語処理を実行することができる。DVAシステムは、要求されたデバイスアクションを実行するように第2当事者デバイスをトリガするデバイス実行可能コマンドを示す応答、たとえば、JSON応答を、第2当事者デバイスに提供することができる。また、本開示の例示的な実施形態によれば、ユーザは、エージェントを呼び出すことまたはエージェントに話しかけることをデバイスに明示的に求めずに、特定のデバイスアクションまたは特定のアプリケーションアクションの遂行を要求するための音声ベース照会を行ってよい。 According to exemplary embodiments of the present disclosure, the systems, methods, and devices described herein enable a second party device provider or third party application provider to communicate with a DVA system associated with a first party provider. Enables voice-based interaction with second-party devices or third-party applications by adopting an on-device execution model for device actions without holding a cloud point to The DVA system can receive audio queries from second party devices and can perform speech recognition and smart natural language processing to identify the requested device or application action. The DVA system may provide a response, eg, a JSON response, to the second party device that indicates device executable commands that trigger the second party device to perform the requested device action. Also, according to exemplary embodiments of the present disclosure, a user requests performance of a particular device action or a particular application action without explicitly asking the device to call or speak to an agent. You may make a voice-based query for
以下において、デバイスアクションとは、カスタムデバイスアクションまたはカスタムアプリケーションアクションを指すことができる。事実上、カスタムデバイスアクションとカスタムアプリケーションアクションの両方が、電子(またはクライアント)デバイスによって実行される。また、電子(またはクライアント)デバイスまたはシステムとは、命令またはコマンドを実行するための電子(または処理)能力を有するデバイスまたはシステムを指すことができる。 In the following, device actions can refer to custom device actions or custom application actions. In effect, both custom device actions and custom application actions are performed by electronic (or client) devices. Also, an electronic (or client) device or system can refer to a device or system that has electronic (or processing) capabilities to execute instructions or commands.
図1は、音声ベース対話能力およびカスタマイズされたデジタル仮想アシスタント(DVA)機能を有する電子デバイスおよび第3当事者アプリケーションを可能にするための例示的なシステム100を示す。システム100は、データ処理システム102、および通信ネットワーク106を介してデータ処理システム102に通信可能に結合された複数のクライアントデバイス104を含むことができる。データ処理システム102およびクライアントデバイス104は、異なるかまたは別々のプロバイダに関連付けられ得る。システム100は、クライアントデバイス104のプロバイダ、またはクライアントデバイス104(たとえば、第2当事者デバイス)上で実行可能な第3当事者アプリケーションのプロバイダに関連する、1つまたは複数のコンピューティングデバイス108を含むことができる。本明細書で使用するとき、デバイスプロバイダは、クライアントデバイス104を顧客またはユーザに提供するデバイスメーカーまたは別のエンティティを含むことができる。第3当事者アプリケーションプロバイダは、アプリケーションを消費のために提供するアプリケーション開発者または別のエンティティを含むことができる。1つまたは複数のコンピューティングデバイス108は、通信ネットワーク106を通じてデータ処理システム102に通信可能に結合され得る。通信ネットワーク106は、インターネット、ワイヤレスセルラーネットワーク、有線ネットワーク、ローカルエリアネットワーク、ワイドエリアネットワーク、パブリックネットワーク、プライベートネットワーク、またはそれらの組合せを含むことができる。
FIG. 1 illustrates an
データ処理システム102は、データまたはコンピュータコード命令を記憶するためのメモリ110、コンピュータコード命令を実行するための1つまたは複数のプロセッサ112、およびクライアントデバイス104またはコンピューティングデバイス108などの他のシステムまたはデバイスと通信するための通信インターフェース114を含むことができる。データ処理システム102は、1つまたは複数のアクションパッケージ(またはバンドル)118を記憶するためのデータリポジトリ116を含むことができる。データ処理システム102は、アクションパッケージ118または対応するデータの記憶、アクセス、または処理を管理するためのアクションカスタマイゼーション構成要素120を含むことができる。データ処理システム102は、オーディオ信号をテキストに変換するための音声認識構成要素122、および音声認識構成要素122によって提供されるテキスト出力などのテキストの構造および意味を決定するための自然言語プロセッサ(NLP:natural language processor)構成要素124を含むことができる。データ処理システム102は、テキストを対応するオーディオ(または可聴)信号に変換するためのオーディオ信号発生器構成要素を含むことができる。データ処理システム102は、コンテンツまたはデジタルコンポーネント(本明細書ではコンテンツ項目とも呼ばれる)をクライアントデバイス104上での提示のために選択するためのコンテンツ選択器構成要素128を含むことができる。
The data processing system 102 includes a memory 110 for storing data or computer code instructions, one or
データ処理システム102は、1つまたは複数のコンピュータサーバ(図1に示さず)を含むことができる。たとえば、データ処理システム102は、分散コンピューティング技法を容易にする論理的にグループ化された複数のサーバ(図1に示さず)を含むことができる。サーバの論理グループは、データセンタ、サーバファーム、またはマシンファームと呼ばれることがある。サーバは地理的に分散させることができる。データセンタまたはマシンファームは単一のエンティティとして管理され得るか、またはマシンファームは複数のマシンファームを含むことができる。各マシンファーム内のサーバは異種であり得、サーバまたはマシンのうちの1つまたは複数が、1つまたは複数のタイプのオペレーティングシステムプラットフォームに従って動作することができる。データ処理システム102は、たとえば企業データセンタの中に配置された関連する記憶システムと一緒に、1つまたは複数の高密度ラックシステムの中に格納される、データセンタの中のサーバを含むことができる。統合されたサーバをこのようにして有するデータ処理システム102は、局所化された高性能ネットワークの中にサーバおよび高性能記憶システムを配置することによって、システム管理容易性、データセキュリティ、システムの物理的なセキュリティ、およびシステム性能を改善することができる。サーバおよび記憶システムを含み、かつ高度なシステム管理ツールを用いてそれらを結合する、データ処理システム102構成要素のうちの全部または一部の集中化により、サーバリソースのより効率的な使用が可能になり、そのことは、電力および処理要件を節約し、帯域幅使用量を低減する。 Data processing system 102 may include one or more computer servers (not shown in FIG. 1). For example, data processing system 102 may include multiple servers (not shown in FIG. 1) that are logically grouped to facilitate distributed computing techniques. A logical grouping of servers is sometimes called a data center, server farm, or machine farm. Servers can be geographically distributed. A data center or machine farm may be managed as a single entity, or a machine farm may contain multiple machine farms. The servers within each machine farm may be heterogeneous, and one or more of the servers or machines may operate according to one or more types of operating system platforms. The data processing system 102 may include servers in a data center housed in one or more high density rack systems with associated storage systems located, for example, in an enterprise data center. can. A data processing system 102 with integrated servers in this manner improves system manageability, data security, system physical security and improve system performance. Centralization of all or some of the data processing system 102 components, including servers and storage systems, and coupling them with advanced system management tools, allows for more efficient use of server resources. , which saves power and processing requirements and reduces bandwidth usage.
クライアントデバイス104は、たとえば第2当事者デバイスのセットのプロバイダによって定義されたデバイスモデルを有する(またはそれに関連付けられる)、第2当事者デバイスのセットを含むことができる。概して、データ処理システム102は、第2当事者デバイスの各セットがそれぞれのデバイスモデルまたはデバイスタイプを有して(またはそれに関連して)、第2当事者デバイスの複数のセットにサービスすることができる(または通信可能に結合され得る)。クライアントデバイス104は、第3当事者アプリケーションがその上にインストールされた第1当事者デバイスまたは第2当事者デバイスを含むことができる。クライアント(または電子)デバイス104は、ロボット、自動車もしくは他の車両、アプライアンス、ホームセキュリティシステム、照明制御システム、ケーブルボックス、スマートテレビジョン、メディアプレーヤ、ラジオデバイス、スマートアラームクロック、スマートウォッチ、モバイルデバイスもしくはハンドヘルドデバイス(たとえば、タブレット、スマートフォン、またはハンドヘルドメディアプレーヤ)、ビデオゲーム機、医療イメージングデバイス、フィットネスおよび運動デバイス、または命令もしくはコマンドを実行するための処理能力および、たとえばネットワーク106を介してデータ処理システム102と通信するための通信能力を有する、他のデバイスを含むことができる。プロバイダのデバイスのセットまたはグループが機能、性質、特性、または能力のそれぞれのセットを共有することを定義するために、そのデバイスプロバイダによってデバイスモデルが定義(または指定)され得る。デバイスモデルの例は、自動車(または、他の車両モデル)、アプライアンスモデル(冷蔵庫モデルまたはストーブモデル)、ホームセキュリティシステムモデル、照明制御システムモデル、ケーブルボックスモデル、スマートテレビジョンモデル、メディアプレーヤモデル、ラジオデバイスモデル、スマートアラームクロックモデル、スマートウォッチモデル、スマートフォンモデル、タブレットモデル、ラップトップモデル、ビデオゲーム機モデル、医療イメージングデバイスモデル、またはフィットネスおよび運動デバイスモデルを含むことができる。デバイスモデルは、デバイスモデル識別子(たとえば、デバイスモデル名、デバイスモデルシリアル番号、またはデバイスモデルコード)を含むことができる。所与のデバイスモデルを有する第2当事者デバイスは、共通部分を共有するデバイス識別子を有することができる。デバイス識別子の共通部分は、デバイスモデルの識別子またはインジケータとして働くことができる。デバイスプロバイダはデバイス104の複数のセット(またはグループ)を有することができ、各セットまたはグループは対応するデバイスモデルに関連付けられている。
The client device 104 can include a set of second party devices, eg, having (or associated with) a device model defined by the provider of the second party device set. Generally, data processing system 102 is capable of servicing multiple sets of second party devices, each set having (or associated with) a respective device model or device type ( or communicatively coupled). Client device 104 may include a first party device or a second party device with a third party application installed thereon. Client (or electronic) devices 104 may be robots, automobiles or other vehicles, appliances, home security systems, lighting control systems, cable boxes, smart televisions, media players, radio devices, smart alarm clocks, smart watches, mobile devices or handheld devices (e.g., tablets, smartphones, or handheld media players), video game consoles, medical imaging devices, fitness and exercise devices, or processing power to execute instructions or commands and data processing systems, e.g., via
所与のデバイスモデル(またはデバイスタイプもしくはデバイスカテゴリー)に関連付けられた第2当事者デバイスは、それぞれの複数のデバイスアクションをサポートすることができる。それぞれの複数のデバイスアクションは、所与のデバイスモデルを有する第2当事者デバイスによって実行され得るアクションを表すことができ、第2当事者デバイスのユーザによってトリガされ得る。たとえば、所与のロボットモデルのロボットに関連付けられたデバイスアクションは、たとえば、左移動、右移動、前方移動、後方移動、またはそれらの組合せを含むことができる。所与のセキュリティシステムモデルのホームセキュリティシステムによってサポートされるデバイスアクションは、たとえば、留守モードのアクティブ化、滞在モードのアクティブ化、(たとえば、特定のカメラ番号の)特定のカメラへの切替え、警報のアクティブ化、警報の非アクティブ化、またはそれらの組合せを含むことができる。所与のフィットネスおよび運動デバイスモデルのフィットネスおよび運動デバイス(たとえば、トレッドミル)によってサポートされるデバイスアクションは、たとえば、心臓モードのアクティブ化/切替え、脂肪燃焼モードのアクティブ化/切替え、特定の速度値への速度の設定、特定の仰角への高さの設定、またはそれらの組合せを含むことができる。所与のデバイスモデルの各デバイスアクションは、そのデバイスアクションを実行するように、所与のデバイスモデルを有する第2当事者デバイスをトリガする、対応するコマンド(すなわちデバイス実行可能コマンド)に関連付けられ得る。 A second party device associated with a given device model (or device type or device category) can support multiple device actions of each. Each multiple device action can represent an action that can be performed by a second party device having a given device model and can be triggered by a user of the second party device. For example, device actions associated with a robot of a given robot model may include, for example, left move, right move, forward move, backward move, or combinations thereof. The device actions supported by the home security system of a given security system model are e.g. activating away mode, activating stay mode, switching to a specific camera (e.g. with a specific camera number), setting an alarm It can include activation, deactivation of the alarm, or a combination thereof. The device actions supported by a given fitness and exercise device model fitness and exercise device (e.g. a treadmill) are e.g. cardio mode activation/switching, fat burning mode activation/switching, specific speed values , setting the height to a particular elevation, or a combination thereof. Each device action for a given device model may be associated with a corresponding command (ie, a device executable command) that triggers a second party device with the given device model to perform that device action.
また、第3当事者アプリケーションは、それぞれの複数のデバイスアクションをサポートすることができる。それぞれの複数のデバイスアクションは、第3当事者アプリケーションがその上にインストールされているクライアントデバイス104によって実行され得るアクションを表すことができ、第3当事者アプリケーションまたはクライアントデバイスのユーザによってトリガされ得る。たとえば、ドライバーを乗客と結びつけるためのアプリケーションに関連付けられたデバイス(またはアプリケーション)アクションは、第1のロケーションから第2のロケーションまでの乗り物を求めて検索すること、乗り物のリストから乗り物を選択すること、ドライバーの現在のロケーションをチェックすること、またはそれらの組合せを含むことができる。ソーシャルネットワークアプリケーションのデバイス(またはアプリケーション)アクションは、ページ(たとえば、友達のページ)をオープンすること、友達によって共有されるメディアファイルを再生すること、コンテンツ項目を共有すること、入力コンテンツを用いて友達の投稿に返答すること、またはそれらの組合せを含むことができる。ナビゲーションアプリケーションのデバイス(またはアプリケーション)アクションは、第1のロケーションから第2のロケーションまでの運転方角(または経路)を提供すること、経路に沿った交通情報を提供すること、経路に沿った施設(たとえば、ガソリンステーション、休憩地、またはレストラン)を求めて検索すること、代替経路に切り替えること、またはそれらの組合せを含むことができる。 Third party applications may also support multiple device actions of each. Each of the multiple device actions can represent an action that can be performed by a client device 104 having a third party application installed thereon, and can be triggered by the user of the third party application or client device. For example, the device (or application) actions associated with an application to connect a driver with a passenger are searching for a ride from a first location to a second location, selecting a ride from a list of rides. , checking the driver's current location, or a combination thereof. A device (or application) action of a social network application can be opening a page (e.g., a friend's page), playing a media file shared by a friend, sharing a content item, using the input content to posts, or a combination thereof. The device (or application) actions of the navigation application are to provide driving directions (or routes) from a first location to a second location, to provide traffic information along the route, to locate facilities ( For example, searching for gas stations, rest stops, or restaurants), switching to alternate routes, or a combination thereof.
第3当事者アプリケーションプロバイダまたは第2当事者デバイスプロバイダは、第3当事者アプリケーション(または、第3当事者アプリケーションをインストールするクライアントデバイス104)、または、それぞれ、デバイスモデルに関連付けられたクライアントデバイス104(たとえば、第2当事者デバイス)によってサポートされる、デバイスアクションを指定するアクションパッケージ118(たとえば、デバイスアクションファイルまたはデバイスアクションスクリプト)を生成することができる。アクションパッケージ118は、デバイスアクションごとに、クライアントデバイス104上でデバイスアクションをトリガするための1つまたは複数の照会パターンを列挙することができる。たとえば、所与のロボットモデルのロボットの場合、照会パターンは、左移動アクションに対して「左移動」および「左進行」、右移動アクションに対して「右移動」および「右進行」、前方移動アクションに対して「前方移動」および「前方進行」、後方移動アクションに対して「後方移動」および「後方進行」、またはそれらの組合せを含むことができる。所与のセキュリティシステムモデルのホームセキュリティシステムの場合、照会パターンは、留守セキュリティモードをアクティブ化するアクションに対して「留守モードのアクティブ化」および「留守モードへの切替え」、滞在セキュリティモードをアクティブ化するアクションに対して「滞在モードのアクティブ化」および「滞在モードへの切替え」、特定のカメラからのビデオコンテンツに切り替えるアクションに対して「カメラCAMERA_NUMBERへの切替え」、警報をアクティブ化するアクションに対して「警報のアクティブ化」、警報を非アクティブ化するアクションに対して「警報の非アクティブ化」、またはそれらの組合せを含むことができる。所与のフィットネスおよび運動デバイスモデルのフィットネスおよび運動デバイス(たとえば、トレッドミル)の場合、照会パターンは、たとえば、心臓血管モードをアクティブ化するアクションに対して「心臓モードのアクティブ化」および「心臓モードへの切替え」、脂肪燃焼モードをアクティブ化するアクションに対して「脂肪燃焼モードのアクティブ化」および「脂肪燃焼モードへの切替え」を含むことができる。モバイルデバイスの場合、例示的な照会パターンは、「設定をオープンする」、「電子メールをオープンする」、「私のリマインダを私に見せる」、またはそれらの組合せを含むことができる。ドライバーを乗客と結びつけるためのアプリケーションの場合、例示的な照会は、「LOCATION1からLOCATION2まで乗り物が必要」、「RIDEで行く」、または「ドライバーのロケーションを見せる」を含むことができる。ソーシャルネットワークアプリケーション用の例示的な照会は、「FRIENDページをオープンする」、「ビデオを再生する」、「ビデオを共有する」、または「CONTENTを用いてPOSTにコメントする」を含むことができる。ナビゲーションアプリケーションの場合、対応する照会は、「LOCATION1からLOCATION2までの運転方角を私に見せる」、「交通情報を私に見せる」、「FACILITIESを私に見せる」、または「新たな経路に切り替える」を含むことができる。 A third party application provider or a second party device provider may be a third party application (or a client device 104 installing a third party application) or, respectively, a client device 104 associated with a device model (e.g., a second An action package 118 (eg, a device action file or device action script) can be generated that specifies device actions supported by a party device). Action package 118 may list, for each device action, one or more query patterns for triggering the device action on client device 104 . For example, for a robot of a given robot model, the query patterns could be "move left" and "go left" for a move left action, "move right" and "go right" for a move right action, move forward It can include "move forward" and "go forward" for actions, "move backward" and "go backward" for move backward actions, or combinations thereof. For a home security system of a given security system model, the query pattern is "activate stay-away mode" and "switch to stay-away mode" for actions that activate stay-away security mode, activate stay-away security mode 'Activate stay mode' and 'Switch to stay mode' for actions to switch to video content from a specific camera, 'Switch to camera CAMERA_NUMBER' for actions to switch to video content from a specific camera, for actions to activate an alert can include "activate alert" for actions that deactivate alerts, "deactivate alert" for actions that deactivate alerts, or a combination thereof. For a given fitness and exercise device model fitness and exercise device (e.g., a treadmill), the query pattern could be, for example, "activate cardio mode" and "activate cardio mode" for an action that activates cardio mode. "Switch to", "Activate fat burn mode" and "Switch to fat burn mode" for actions that activate fat burn mode. For mobile devices, exemplary query patterns may include "open settings", "open email", "show me my reminders", or combinations thereof. For applications to connect drivers with passengers, exemplary queries may include "I need a ride from LOCATION1 to LOCATION2", "Take a RIDE", or "Show driver's location". Exemplary queries for social network applications may include "open FRIEND page", "play video", "share video", or "comment on POST using CONTENT". For navigation applications, the corresponding queries are "show me driving directions from LOCATION1 to LOCATION2", "show me traffic information", "show me FACILITIES", or "switch to new route". can contain.
アクションパッケージ118は、デバイスアクションごとにアクション名を含んでよい。アクションパッケージ118は、デバイスアクションごとに、デバイスアクションのオンデバイス実行をトリガするためのそれぞれのデバイス実行可能コマンド(またはアプリケーション実行可能コマンド)を指定してよい。アクションパッケージ118は、デバイスアクションごとに、デバイスアクションの実行に関してクライアントデバイス104によって提示されるべき応答を指定してよい。各応答は、クライアントデバイス104による提示のためにオーディオに変換され得るテキスト表現として記述され得る。下記のスクリプトは、スマート調理器具用のアクションパッケージを定義する例示的なスクリプトの例示を提供する。
{
"manifest":{...},
"actions":[
{
"intent":{
"name":"com.smart_cooker.COOK_CAKE",
"trigger":{
"queryPatterns":[
"bake a cake",
"cook a cake"
]
}
},
"availability":{
"deviceAction":true
},
"staticFulfillment":{
"textToSpeech":"Baking a cake",
"deviceExecution":{
"command":"com.smart_cooker.command.COOK_CAKE"
}
}
}
]
}
本スクリプトは、「COOK_CAKE」と名付けられている、ケーキを調理するための単一のデバイスアクションを定義する。本スクリプトはまた、デバイスアクションに関連付けられた照会パターン「bake a cake (ケーキを焼く)」および「cook a cake (ケーキを調理する)」を定義する。本スクリプトは、デバイスアクションを実行するためのデバイス実行可能コマンド「command.COOK_CAKE」を定義する。さらに、本スクリプトは、たとえば、音声照会「bake a cake」または「cook a cake」に応答してクライアントデバイス104によってオーディオフォーマットで再生されるべき応答、たとえば、「Baking a cake (ケーキを焼く)」を定義することができる。
Action package 118 may include an action name for each device action. Action package 118 may specify, for each device action, a respective device-executable command (or application-executable command) for triggering on-device execution of the device action. Action package 118 may specify, for each device action, a response to be presented by client device 104 regarding execution of the device action. Each response can be written as a textual representation that can be converted to audio for presentation by client device 104 . The script below provides an illustration of an exemplary script that defines an action package for smart cookware.
{
"manifest": {...},
"actions":[
{
"intent": {
"name":"com.smart_cooker.COOK_CAKE",
"trigger": {
"queryPatterns":[
"bake a cake",
"cook a cake"
]
}
},
"availability": {
"deviceAction": true
},
"staticFulfillment": {
"textToSpeech":"Baking a cake",
"deviceExecution": {
"command":"com.smart_cooker.command.COOK_CAKE"
}
}
}
]
}
This script defines a single device action for cooking a cake, named "COOK_CAKE". The script also defines query patterns "bake a cake" and "cook a cake" associated with device actions. This script defines a device executable command "command.COOK_CAKE" to perform device actions. Further, the script may, for example, specify a response to be played in audio format by the client device 104 in response to the voice query "bake a cake" or "cook a cake", e.g., "Baking a cake". can be defined.
第2当事者デバイスプロバイダまたは第3当事者アプリケーションプロバイダは、対応するアクションパッケージ、およびアクションパッケージに関連付けられた識別子(ID)を、データ処理システム102に提供するために、コンピューティングデバイス108を使用することができる。たとえば、第2当事者デバイスプロバイダは、コンピューティングデバイス108を介してデータ処理システム102にそれぞれのデバイスモデルを登録することができる。コンピューティングデバイス108は、デスクトップ、ラップトップ、スマートフォン、ハンドヘルドデバイス、または他のコンピューティングデバイスを含むことができる。コンピューティングデバイス108は、デバイスモデルの登録の一部として、アクションパッケージ118およびデバイスモデルデータをデータ処理システム102へ送信することができる。デバイスモデルデータは、たとえば、デバイスモデルのインジケータ(または表示)(たとえば、デバイスモデル識別子またはデバイスモデル名)、デバイスモデルに関連付けられたデバイスの性質、特性、機能、もしくは能力の表示、対応する第2当事者デバイスプロバイダの名称、デバイスモデルに関連付けられたデバイスの記述、およびデバイスタイプの表示、またはそれらの組合せを含むことができる。第3当事者アプリケーションプロバイダはまた、(たとえば、アプリケーションによってサポートされるデバイスアクションを定義する)それぞれのアクションパッケージおよびアクションパッケージに関連付けられたID(たとえば、アプリケーションID、パッケージID、ディレクトリID、またはプロジェクトID)をデータ処理システム102に提供するために、コンピューティングデバイス108を使用することができる。データ処理システム102は、アクションデータ、ID、または他の情報をデータ処理システム102へ送信するために、コンピューティングデバイス108による使用のためのRESTful APIまたはUIを提供することができる。たとえば、UIは、データ処理システム102または第1当事者プロバイダによって提供されるウェブページまたはアプリケーションに関連付けられ得る。コンピューティングデバイス108は、たとえば、UIの対応するテキスト入力スロットの中を、デバイスアクションデータ、デバイスモデルデータ、アプリケーション情報データ、またはそれらの組合せで埋めることを可能にするために、ウェブページまたはアプリケーションにアクセスすることができる。RESTful APIとは、データを要求、転送、または削除するためにHTTP要求(たとえば、GET、PUT、POST、またはDELETE)を使用するAPIである。
A second party device provider or third party application provider may use
下記のスクリプトは、第2当事者デバイスを登録することの一部として、コンピューティングデバイス108によってデータ処理システム102に提供され得るデータの例示的な例を提供する。本データは、上記で提供された例示的なアクションパッケージに関して説明したスマート調理器具に関係する。
{
"project_id":"my-smart-cooker",
"device_model_id":"smart-cooker-v1",
"manifest":{
"manufacturer":"Smart Cooker Inc",
"product_name":"Smart Cooker",
"device_description":"Smart device for cooking"
},
"device_type":"action.devices.types.OTHER",
"actionConfig":{
"supportedIntents":[
"com.smart_cooker.intent.COOK_CAKE"
]
}
}
上記のスクリプトの中のデータは、デバイスモデルID、製造業者名、製品名、デバイス記述、デバイスタイプ、およびアクションパッケージ(たとえば、上記の第1のスクリプトに関連付けられたアクションパッケージ)への参照(たとえば、「com.smart_cooker.intent.COOK_CAKE」)を指定する。コンピューティングデバイス108はまた、第2当事者デバイス(または第3当事者アプリケーション)に関連付けられたアクションパッケージ、識別子、および他の情報を、別々または一緒のいずれかでデータ処理システム102へ送信することができる。
The script below provides an illustrative example of data that may be provided to data processing system 102 by computing
{
"project_id":"my-smart-cooker",
"device_model_id":"smart-cooker-v1",
"manifest":{
"manufacturer":"Smart Cooker Inc",
"product_name":"Smart Cooker",
"device_description":"Smart device for cooking"
},
"device_type":"action.devices.types.OTHER",
"actionConfig": {
"supportedIntents":[
"com.smart_cooker.intent.COOK_CAKE"
]
}
}
The data in the script above is the device model id, manufacturer name, product name, device description, device type, and a reference to an action package (e.g. the action package associated with the first script above) (e.g. , "com.smart_cooker.intent.COOK_CAKE").
データ処理システム102の構成要素は、図2および図5に関して以下でさらに詳細に説明される。 The components of data processing system 102 are described in further detail below with respect to FIGS.
図2は、クライアント(または電子)デバイスとの音声ベース対話を可能にするための例示的な方法200のフロー図を示す。方法200は、デバイスアクションデータおよびそれぞれの識別子を受信すること(ACT202)を含むことができる。方法200は、デバイスアクションデータをメモリの中に記憶すること(ACT204)を含むことができる。方法200は、デバイスアクションデータに識別子をマッピングすること(ACT206)を含むことができる。方法200は、識別子およびオーディオ信号をクライアントデバイスから受信すること(ACT208)を含むことができる。方法200は、識別子およびオーディオ信号に基づいてデバイスアクションを識別すること(ACT210)を含むことができる。方法200は、デバイスアクションに対応するデバイス実行可能コマンドを識別すること(ACT212)を含むことができる。方法200は、デバイス実行可能コマンドをクライアントデバイスへ送信すること(ACT214)を含むことができる。
FIG. 2 shows a flow diagram of an
図1および図2を参照すると、方法200は、データ処理システム102がデバイスアクションデータおよび対応する識別子を対応するコンピューティングデバイス108から受信すること(ACT202)を含むことができる。コンピューティングデバイス108は、第2当事者デバイスプロバイダまたは第3当事者アプリケーションプロバイダに関連付けられ得る。識別子は、デバイスモデルID(たとえば、デバイスモデル名、デバイスモデルコード、またはそれらの組合せ)、デバイスタイプID、プロジェクトID、ディレクトリID、アプリケーションID、アクションパッケージID、プロバイダID、またはそれらの組合せを含むことができる。プロジェクトIDは、音声ベース対話を用いて第2当事者デバイスまたは第3当事者アプリケーションのセットを可能にするプロジェクトを識別することができる。プロジェクトは、第2当事者デバイスプロバイダまたは第3当事者アプリケーションプロバイダによってデータ処理システム102に提供されるソフトウェアツールおよび/またはデータの集合を指すことができる。ディレクトリIDは、アクションデータを記憶するためにデータ処理システム102によって使用されるディレクトリを識別することができる。デバイスアクションデータは、(たとえば、デバイスモデルIDまたはデバイスタイプIDに関連付けられた)第2当事者デバイスによって、または(たとえば、アプリケーションIDまたはプロジェクトIDに関連付けられた)第3当事者アプリケーションによってサポートされる、複数のデバイスアクションの表示を含むことができる。デバイスアクションデータはまた、複数のデバイス実行可能コマンドを含むことができる。複数のデバイス実行可能コマンドの各デバイス実行可能コマンドは、複数のデバイスアクションのうちの対応するデバイスアクションに関連付けられ得る。デバイスアクションごとに、対応するデバイス実行可能コマンドは、1つまたは複数のクライアントデバイス104上でデバイスアクションの実行をトリガすることができる。データ処理システム102はまた、デバイスタイプの表示、第2当事者デバイスプロバイダの識別子もしくは名称、第3当事者アプリケーションプロバイダの識別子もしくは名称、デバイスモデルもしくは対応する第2当事者デバイスの記述、第3当事者アプリケーションの記述、第3当事者アプリケーションのバージョン、またはそれらの組合せを含む情報を受信することができる。
1 and 2,
通信インターフェース114はまた、デバイスアクションの実行に関してクライアントデバイス104による提示のための複数の応答を受信することができる。複数の応答の各応答は、対応するデバイスアクションに関連付けられ得、対応するデバイスアクションの実行に関する提示のためにクライアントデバイス104に提供され得る。たとえば、応答は、対応するデバイスアクションの実行の開始、経過、または完了をユーザに告知するために、クライアントデバイス104によってオーディオ形式で再生され得る。
方法200は、デバイスアクションデータをメモリの中に記憶すること(ACT204)を含むことができる。メモリ110またはデバイスアクションカスタマイゼーション構成要素120は、様々なデバイスモデル、様々な第3当事者アプリケーション、またはそれらの組合せのためのデバイスアクションデータを記憶するための、データリポジトリ116を割り振ることができる。デバイスアクションカスタマイゼーション構成要素120は、別個のデバイスモデルまたは別個の第3当事者アプリケーションに関連付けられたデバイスアクションデータを別個に、たとえば、別個のアクションパッケージ118として記憶することができる。各アクションパッケージ118は、たとえばデバイスモデルまたは第3当事者アプリケーションに関連付けられた、複数のデバイスアクションおよび対応するデバイス実行可能コマンドを列挙する、1つまたは複数の対応するデータ構造、1つまたは複数の対応するデータファイル、またはそれらの組合せを含むことができる。
方法200は、デバイスアクションデータに識別子をマッピングすること(ACT206)を含むことができる。デバイスアクションカスタマイゼーション構成要素120は、対応するアクションパッケージ118の中の複数のデバイスアクションの各々に識別子がマッピングまたはリンクされるような、デバイスアクションデータを構成することができる。たとえば、データ処理システム102によって記憶されるようなアクションパッケージ118は、対応する識別子によって識別され得る。たとえば、デバイスアクションカスタマイゼーション構成要素120は、識別子を含む名称をアクションパッケージ118に割り当てることができるか、または識別子を含む名称を有するディレクトリの中にアクションパッケージ118を記憶することができる。デバイスアクションカスタマイゼーション構成要素120はまた、対応するデバイス実行可能コマンドに各デバイスアクションをマッピングまたはリンクしてよい。デバイスアクションカスタマイゼーション構成要素114はまた、もしあれば、対応する応答に各デバイスアクションをマッピングまたはリンクしてよい。たとえば、デバイスアクションカスタマイゼーション構成要素120は、対応するデバイス実行可能コマンドおよび対応する応答を有する同じ行(または同じ列)を共有する各デバイスアクションを有するテーブルの中に、デバイスアクション、デバイス実行可能コマンド、および応答を記憶してよい。
デバイスモデルに関連付けられた第2当事者デバイスに対して、デバイスアクションカスタマイゼーション構成要素120はまた、そのデバイスモデルに関連付けられた第2当事者デバイスにサービスする前にデバイスモデルを有効化または認証してよい。たとえば、(たとえば、試作または実際の第2当事者デバイスにおいて)デバイス実行可能コマンドのテストに成功すると、デバイスアクションカスタマイゼーション構成要素120は、アクションパッケージ118がアクティブであることを示すために、対応するアクションパッケージ118の中で設定(またはパラメータを作成)することによってデバイスモデルを有効化または認証してよい。アクティブでないアクションパッケージに関連付けられた第2当事者デバイスは、データ処理システム102によってサービスされなくてよい。 For second party devices associated with a device model, the device action customization component 120 may also validate or authenticate the device model before servicing the second party device associated with that device model. For example, upon successful testing of a device executable command (e.g., in a prototype or actual second party device), device action customization component 120 activates the corresponding action package 118 to indicate that action package 118 is active. A device model may be validated or validated by configuring (or creating parameters for) in 118 . Second party devices associated with inactive action packages may not be serviced by data processing system 102 .
方法200は、識別子およびオーディオ信号をクライアントデバイスから受信すること(ACT208)を含むことができる。通信インターフェース114は、クライアントデバイス104のユーザからの音声ベース照会に応答して、オーディオ信号および識別子を(たとえば、アクションパッケージ118に関連付けられた)クライアントデバイス104から受信することができる。たとえば、第2当事者デバイスに対して、それぞれのユーザは、第2当事者デバイスへの音声ベース照会を行ってよく、第2当事者デバイスは、照会に対応するオーディオ信号を記録することができ、それを識別子とともにデータ処理システム102へ送ることができる。第3当事者アプリケーションに対して、アプリケーションは、アプリケーションがその上にインストールされているクライアントデバイス104との会話を起動するための、対話式UI構成要素を提供することができる。対話式UI構成要素と対話すると、アプリケーションは、クライアントデバイス104に、たとえば、オーディオレシーバ(たとえば、マイクロフォン)をアクティブ化すること、データ処理システム102との通信セッションを確立すること、またはその両方を行わせることができる。ユーザが音声ベース照会を行うと、アプリケーションは、クライアントデバイス104に、照会を表すオーディオ信号を記録させることができ、そのオーディオ信号を識別子とともにデータ処理システム102へ送らせることができる。クライアントデバイス104は、データ処理システム102へ送るためのオーディオ入力をそこから受け取るための、オーディオレシーバとは異なる別のオーディオソースを指定することができる。
方法200は、識別子およびオーディオ信号に基づいてデバイスアクションを識別すること(ACT210)を含むことができる。デバイスアクションカスタマイゼーション構成要素120は、データ処理システム102によって保持される(またはそれにとってアクセス可能な)アクションパッケージ118の中から対応するアクションパッケージ118を識別するために、受信された識別子を使用することができる。デバイスアクションカスタマイゼーション構成要素120は、アクションパッケージ118の中で列挙されたデバイスアクションの各々関連付けられた照会パターンを取り出すことができる。音声認識構成要素122は、オーディオ信号を対応するテキストに変換することができる。NLP構成要素122は、音声認識構成要素122によって生成されたテキストおよび取り出された照会パターンを使用して、識別子に関連付けられたアクションパッケージの中で列挙された複数のデバイスアクションのうちのデバイスアクションを識別することができる。NLP構成要素124は、音声認識構成要素によって生成されたテキストを対応する意味に整合させるとき、取り出された照会パターンに対してバイアスを適用することができる。たとえば、受信オーディオ信号が、識別子または対応するアクションパッケージ118に関連付けられた第2当事者デバイスまたは第3当事者アプリケーションによって提供されるものと知られていることを仮定すれば、NLP構成要素124は、アクションパッケージ118の中で列挙された照会パターンに対応しない意味に、0の整合重みまたは(たとえば、アクションパッケージ118の中の照会パターンに対応する意味に対する整合重みと比較して)比較的小さい整合重みを割り当てることができる。NLP構成要素124は、NLP構成要素124の機械学習プロセスを使用して、デバイスアクション(または対応する照会パターン)ごとに(たとえば、整合重みに基づいて)整合スコアを決定することができる。NLP構成要素124は、受信オーディオ信号のコンテンツに整合するものとして、重みが最も大きいデバイスアクションを選択することができる。
方法200は、デバイスアクションに対応するデバイス実行可能コマンドを識別すること(ACT212)を含むことができる。デバイスアクションカスタマイゼーション構成要素120は、NLP構成要素124によって識別されたデバイスアクションに対応する、アクションパッケージ118の中の複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドを識別することができる(または取り出すことができる)。たとえば、デバイスアクションカスタマイゼーション構成要素120は、アクションパッケージ118の中の(NLP構成要素124によって識別された)デバイスアクションにマッピングまたはリンクされたデバイス実行可能アクションを取り出すことができる。デバイスアクションカスタマイゼーション構成要素120はまた、デバイス実行可能コマンドに関連付けられた1つまたは複数のパラメータを識別してよい。たとえば、デバイスアクション(または対応するデバイス実行可能コマンド)が、運転方角を求める要求または乗り物を求める要求に関係する場合、対応するパラメータは、出発ロケーションおよび行き先ロケーションの表示を含んでよい。デバイスアクションが、リソース情報(たとえば、ソーシャルネットワークページまたはウェブページ)をオープンすることに関係する場合、パラメータは、リソースの名称またはアドレスを含むことができる。デバイスアクションごとに、対応する照会パターンは、デバイスアクションが任意の入力パラメータに関連付けられ得るかどうかを示すことができる。たとえば、照会「need ride from LOCATION1 to LOCATION2 (第1のロケーションから第2のロケーションまでの乗り物を求める)」は、パラメータLOCATION1およびLOCATION2がクライアントデバイス104のユーザによって提供されるべきであることを示す。また、照会パターン「open FRIEND page (FRIENDページをオープンする)」、「go with RIDE (RIDEで行く)」、「show me FACILITIES (FACILITIESを私に見せる)」、および「comment to POST with CONTENT (CONTENTを用いてPOSTにコメントする)」の中で、パラメータFRIEND、RIDE、FACILITIES、POST、およびCONTENTは、ユーザによって提供されるべきである。NLP構成要素124は、受信オーディオ信号に対応するテキストを構文解析することができ、もしあれば、デバイスアクションパラメータの値を識別することができる。デバイスアクションカスタマイゼーション構成要素120は、デバイス実行可能コマンドをクライアントデバイス104へ送る前に、デバイスアクションに対応するデバイス実行可能コマンドに、識別されたパラメータを添付することができる。
デバイスアクションカスタマイゼーション構成要素120はまた、対応するアクションパッケージ118の中の(NLP構成要素124によって識別された)デバイスアクションにマッピングまたはリンクされた応答を取り出してよい。オーディオ信号発生器126は、応答が元はテキストフォーマットである場合、応答をオーディオフォーマット(たとえば、オーディオ信号)に変換することができる。デバイスアクションに関連する応答が、オーディオフォーマット、ビジュアルフォーマット、またはオーディオビジュアルフォーマットをなす場合、デバイスアクションカスタマイゼーション構成要素120は、第2当事者デバイス104へ送るために応答を通信インターフェース114に提供することができる。
Device action customization component 120 may also retrieve responses that are mapped or linked to device actions (identified by NLP component 124 ) in corresponding action packages 118 . Audio signal generator 126 can convert the response to an audio format (eg, an audio signal) if the response was originally in text format. If the response associated with the device action is in audio, visual, or audiovisual format, the device action customization component 120 can provide the response to the
方法200は、デバイス実行可能コマンドを第2当事者デバイスへ送信すること(ACT214)を含むことができる。通信インターフェース114は、音声ベース照会に応答した実行のために、もしあれば対応するパラメータとともに、デバイス実行可能コマンドをクライアントデバイス104へ送信することができる。実行可能コマンドは、実行されたとき、NLP構成要素124によって識別されたデバイスアクションをクライアントデバイス104に実行させることができる。通信インターフェース114はまた、もしあれば、(オーディオフォーマット、ビジュアルフォーマット、またはオーディオビジュアルフォーマットをなす)応答を、クライアントデバイス104へレンダリングのために送信してよい。
図3は、音声ベース対話をサポートするクライアント(または電子)デバイス104のブロック図を示す。クライアントデバイス104は、音声ベース照会を受信するためのオーディオレシーバ302、およびデータ処理システム102などの他のデバイスまたはシステムと通信するための通信インターフェース304を含むことができる。クライアントデバイス104は、デバイス実行可能コマンドを実行する(またはそれを実行させる)ためのコマンド実行構成要素306、およびオーディオ信号(たとえば、データ処理システム102から受信されるオーディオ信号)に基づいてオーディオ波を生成するためのスピーカー308を含むことができる。クライアントデバイス104は、データ処理システム102との通信を管理するためのコントローラ310を含むことができる。第2当事者デバイスのこれらの構成要素は、図4に関して以下でさらに説明される。
FIG. 3 shows a block diagram of a client (or electronic) device 104 that supports voice-based interaction. Client device 104 may include an
図4は、クライアントデバイスが音声ベース対話をサポートすることを可能にする例示的な方法400のフロー図を示す。方法400は、音声ベース照会に応答してオーディオ信号を生成すること(ACT402)を含むことができる。方法400は、オーディオ信号および識別子をリモートデータ処理システムへ送信すること(ACT404)を含むことができる。方法400は、デバイス実行可能コマンドを受信すること(ACT406)、およびデバイス実行可能コマンドを実行すること(ACT408)を含むことができる。
FIG. 4 shows a flow diagram of an
図3および図4を参照すると、方法400は、音声ベース照会に応答してオーディオ信号を生成すること(ACT402)を含むことができる。クライアントデバイス104のユーザは、クライアントデバイスまたはその上にインストールされた第3当事者アプリケーションとの会話を起動することができる。クライアントデバイス104または第3当事者アプリケーションは、会話を始めるというユーザの意図をクライアントデバイス104にシグナリングするために、対話式UI構成要素、ボタン、または他の入力メカニズムを提供してよい。対話式UI構成要素と対話すると(または他の入力時に)、クライアントデバイス104または第3当事者アプリケーションは、オーディオ入力の記録のためにオーディオレシーバ302(たとえばマイクロフォン)を作動させること、データ処理システム102との通信セッションを確立すること、またはその両方を行ってよい。オーディオレシーバ302は、クライアントデバイス104のユーザからの音声ベース照会に対応するオーディオ信号を生成することができる。オーディオレシーバ302は、たとえば、音声ベース照会に対応する音波を電気オーディオ信号に変換することができる。クライアントデバイス104はまた、クライアントデバイス104または第3当事者アプリケーションによってサポートされるデバイスアクションを定義するアクションパッケージに関連付けられた識別子(たとえば、デバイスモデルID、アプリケーションID、プロジェクトID、ディレクトリID、またはそれらの組合せ)を、(たとえば、対応するメモリの中に)記憶することができる。クライアントデバイス104(または第3当事者アプリケーション)は、データ処理システム102へ送るためのオーディオ入力をそこから受け取るための、オーディオレシーバとは異なる別のオーディオソースを指定することができる。クライアントデバイス104または第3当事者アプリケーションは、対話式UI構成要素と対話すると、指定されたオーディオソースを作動させてよい。
3 and 4,
方法400は、識別子およびオーディオ信号をリモートデータ処理システムへ送信すること(ACT404)を含むことができる。コントローラ310は、通信インターフェース304に、音声ベース照会に応答して識別子およびオーディオ信号をデータ処理システム102へ送信させることができる。コントローラ310は、オーディオ信号および識別子を含む、データ処理システム102へ送るための要求を生成することができる。その要求は、音声ベース照会のコンテンツを解釈するための要求として見られ得る。コントローラ310は、その要求をデータ処理システム102へ通信インターフェース304に送信させることができる。図1および図2に関して上記で説明したように、データ処理システム102は、識別子を使用して、データ処理システムによって保持される複数のアクションパッケージ118の中からアクションパッケージ118を識別することができ、オーディオ信号を使用して、アクションパッケージ118の中で列挙されたデバイスアクションまたは照会パターンの中から、音声ベース照会のコンテンツに対応するデバイスアクション(または対応する照会パターン)を決定することができる。データ処理システム102は、もしあれば、オーディオ信号のコンテンツに整合したデバイスアクションに対応するデバイス実行可能コマンドを決定することができる。
方法400は、デバイス実行可能コマンドを受信すること(ACT406)を含むことができる。通信インターフェース304は、オーディオ信号および識別子の送信に応答して、オーディオ信号のコンテンツに整合したデバイスアクションに対応するデバイス実行可能コマンドを含む応答メッセージを、データ処理システムから受信することができる。デバイス実行可能コマンドは、音声ベース照会(またはオーディオ信号)のコンテンツに対応するデバイスアクションを識別するとデータ処理システム102によって識別され得る。デバイス実行可能コマンドを受信することは、コマンドに関連付けられるとともに音声ベース照会の中でユーザによって提供された、1つまたは複数のパラメータを(たとえば、応答メッセージの中で)受信することを含むことができる。通信インターフェース304はまた、データ処理システム102からオーディオ応答を受信してよい。コントローラ310は、デバイス実行可能コマンド、コマンドに関連付けられた任意のパラメータ、クライアントデバイス104によってレンダリングされるべきメディア応答、またはそれらの組合せを識別するために、受信されたメッセージを構文解析することができる。
方法400は、デバイス実行可能コマンドを実行すること(ACT408)を含むことができる。コントローラ310は、デバイス実行可能コマンドおよびそれらの任意のパラメータを、実行のためにコマンド実行構成要素306に提供することができる。コマンド実行構成要素306は、受信されたデバイス実行可能コマンドに対応するデバイスアクションをクライアントデバイス104に実行させるために、デバイス実行可能コマンドを実行することができる。コマンドを実行することは、クライアントデバイス104(またはその上に記憶されたアプリケーション)が、検索照会(または検索要求)を生成すること、およびそれをオンラインサーバ(たとえば、第3当事者アプリケーションに関連付けられたサーバ)へ送ることを含むことができる。たとえば、アプリケーションまたはクライアントデバイス104は、受信された実行可能コマンドおよび対応するパラメータに基づいて、第1のロケーションから第2のロケーションまでの乗り物を求める要求を生成することができる。クライアントデバイス104は、検索照会または検索要求をオンラインサーバへ送信することができる。オンラインサーバから応答を受信すると、クライアントデバイス104は、ユーザへの応答の中で情報を提示することができる。
コントローラ310またはコマンド実行構成要素306は、データ処理システム102から受信された通信(またはメッセージ)からデバイス実行可能コマンドおよび対応する任意のパラメータを抽出し、かつ抽出されたコマンドを実行するための、デバイスアクションハンドラを含むことができる(または実装することができる)。下記のスクリプトは、デバイスアクションハンドラの例示的な例を表す。
.h
namespace assistant_client{
class SmartCookerHandler:public DeviceActionHandler{
public:
void Execute(const std::string&request_json)override;
};
}
.cc
namespace assistant_client{
void SmartCookerHandler::Execute(const std::string&device_request_json){
//コマンドを抽出
//cake cookingを開始
}
============================================================
namespace chromecast{
//static
assistant_client::DeviceActionHandler*
CastAssistantShlib::CreateDeviceActionHandler(const
std::string&action_type){
if(action_type=="device_control"){
return new assistant_client::SmartCookerHandler();
}
}}
//namespace chromecast
.h
namespace assistant_client{
class SmartCookerHandler: public DeviceActionHandler{
public:
void Execute(const std::string&request_json)override;
};
}
.cc
namespace assistant_client{
void SmartCookerHandler::Execute(const std::string&device_request_json){
// extract command
// start cake cooking
}
================================================== ==========
namespace chromecast{
// static
assistant_client::DeviceActionHandler*
CastAssistantShlib::CreateDeviceActionHandler(const
std::string&action_type){
if (action_type=="device_control"){
return new assistant_client::SmartCookerHandler();
}
}}
//namespace chromecast
コントローラ310は、クライアントデバイス104によるレンダリング用の任意のメディア応答を、対応するメディアプレーヤに提供することができる。たとえば、コントローラ310は、デバイス実行可能コマンドの実行に関してスピーカー308を通じてオーディオ応答を再生するために、データ処理システム102から受信されたオーディオ応答をオーディオプレーヤに提供することができる。コントローラ310は、デバイス実行可能コマンドの実行の前に、実行中に、または実行の後に、オーディオ応答をレンダリングさせることができる。オーディオプレーヤおよびスピーカーはまた、データ処理システム102から受信された任意の追加のオーディオコンテンツを再生してよい。ビジュアル応答またはオーディオビジュアル応答が受信される場合、コントローラは、オーディオビジュアルプレーヤ(たとえば、画像プレーヤ、アニメーションプレーヤ、またはビデオプレーヤ)に、クライアントデバイス104のディスプレイ上でビジュアル応答またはオーディオビジュアル応答をレンダリングさせることができる。
図3および図4に関して説明したアクションパッケージ、デバイスアクション、および対応するデバイス実行可能コマンドは、上記で図1および図2に関して説明したものと類似である。また、図3および図4の説明は、クライアントデバイス104によって実行されるプロセスおよび行為に焦点を当てるが、これらのプロセスおよび行為は、データ処理システム102によって実行されるとともに図1および図2に関して説明したプロセスおよび行為と相互に関係する。 The action packages, device actions, and corresponding device executable commands described with respect to FIGS. 3 and 4 are similar to those described with respect to FIGS. 1 and 2 above. Also, while the description of FIGS. 3 and 4 focuses on processes and acts performed by client device 104, these processes and acts are performed by data processing system 102 and described with respect to FIGS. interrelated with the processes and actions taken.
図5は、デバイスアクションをトリガするための音声ベース対話に応答してコンテンツを提供する例示的な方法500のフロー図を示す。方法500は、デバイスアクションデータをメモリの中に記憶すること(ACT502)を含むことができる。方法500は、デバイスアクションデータに識別子をマッピングすること(ACT504)を含むことができる。方法500は、識別子およびオーディオ信号をクライアントデバイスから受信すること(ACT506)を含むことができる。方法500は、識別子およびオーディオ信号に基づいてデバイスアクションコマンドペアを識別すること(ACT508)を含むことができる。方法500は、オーディオ信号に関連付けられた音声ベース照会のコンテキストを識別すること(ACT510)を含むことができる。方法500は、オーディオ信号に関連付けられた音声ベース照会のコンテキストに基づいてデジタルコンポーネントを選択すること(ACT512)を含むことができる。方法500は、デジタルコンポーネント、およびデバイスアクションコマンドペアに対応するデバイス実行可能コマンドを、クライアントデバイス104へ送信すること(ACT514)を含むことができる。
FIG. 5 shows a flow diagram of an
データ処理システム102(またはその構成要素)は、図1および図2に関して上記で説明したような類似の(図2のACT202～208と類似の)やり方で、方法500のACT502～508を実行することができる。デバイスアクションデータは、たとえば、デバイスモデルに関連付けられた第2当事者デバイスによって、または1つもしくは複数のクライアントデバイス104上にインストールされた(またはそれを動作させることが可能な)第3当事者アプリケーションによってサポートされる、カスタムデバイスアクションを定義する、デバイスアクションパッケージ118を含むことができる。
Data processing system 102 (or a component thereof) performs ACTs 502-508 of
方法500は、オーディオ信号に関連付けられた音声ベース照会のコンテキストを識別すること(ACT510)を含むことができる。アクションカスタマイゼーション構成要素120は、たとえば、オーディオ信号のコンテンツ、識別子に関連付けられたアクションパッケージ118(またはデバイスアクションデータ)のコンテンツ、またはその両方に関連付けられた要因に基づいて、受信オーディオ信号に対応する音声ベース照会のコンテキストを決定することができる。たとえば、識別子に関連付けられたアクションパッケージ118(またはデバイスアクションデータ)の中の各デバイスアクションは、(たとえば、第2当事者デバイスプロバイダもしくは第3当事者アプリケーションプロバイダによって提供されるか、または収集された履歴データに基づいてデータ処理システムによって生成される)1つまたは複数のキーワードに関連付けられ得る。キーワードは、そのデバイスアクションに整合した照会の共通コンテキストを示すことができる。アクションカスタマイゼーション構成要素120は、デバイスアクションのコンテキストを記述するとき、デバイスアクションに関連付けられたキーワードを使用することができる。
The
アクションカスタマイゼーション構成要素120は、たとえば、(たとえば、識別子がデバイスモデルIDである場合)デバイスモデルに関連付けられた第2当事者デバイスを記述するか、またはアクションパッケージに関連付けられた第3当事者アプリケーションを記述する、アクションパッケージに関連付けられた情報に基づいて、音声ベース照会のコンテキスト(またはその属性)を識別することができる。たとえば、アプリケーションがゲーミングアプリケーションである場合、音声ベース照会のコンテキスト(またはコンテキスト属性)はゲーミングであることになる。また、第2当事者デバイスがフィットネスデバイスである場合、音声ベース照会のコンテキスト(またはコンテキスト属性)はフィットネスおよび運動であることになる。 Action customization component 120, for example, describes a second party device associated with a device model (eg, where the identifier is a device model ID) or describes a third party application associated with an action package. , the context (or attributes thereof) of the speech-based query can be identified based on the information associated with the action package. For example, if the application is a gaming application, the context (or context attribute) of the voice-based query would be gaming. Also, if the second party device is a fitness device, the context (or context attribute) of the voice-based query would be fitness and exercise.
アクションカスタマイゼーション構成要素120は、たとえば、(たとえば、識別子がデバイスモデルIDである場合)デバイスモデルに関連付けられた第2当事者デバイスを記述するか、またはアクションパッケージに関連付けられた第3当事者アプリケーションを記述する、アクションパッケージに関連付けられた情報に基づいて、音声ベース照会のコンテキスト(またはその属性)を識別することができる。たとえば、アプリケーションがゲーミングアプリケーションである場合、音声ベース照会のコンテキスト(またはコンテキスト属性)はゲーミングであることになる。また、第2当事者デバイスがフィットネスデバイスである場合、音声ベース照会のコンテキスト(またはコンテキスト属性)はフィットネスおよび運動であることになる。 Action customization component 120, for example, describes a second party device associated with a device model (eg, where the identifier is a device model ID) or describes a third party application associated with an action package. , the context (or attributes thereof) of the speech-based query can be identified based on the information associated with the action package. For example, if the application is a gaming application, the context (or context attribute) of the voice-based query would be gaming. Also, if the second party device is a fitness device, the context (or context attribute) of the voice-based query would be fitness and exercise.
アクションカスタマイゼーション構成要素120は、音声ベース照会の中で提供されるとともにNLP構成要素124によって抽出される情報(またはパラメータ)に基づいて、音声ベース照会のコンテキスト(またはその属性)を識別することができる。たとえば、アクションカスタマイゼーション構成要素120は、音声ベース照会の地理的コンテキストを決定するために、地理的ロケーションを示す抽出されたパラメータを使用することができる。アクションカスタマイゼーション構成要素120は、ユーザ意図(たとえば、ガソリンを満たすこと、または食事をすること)を決定するために、ビジネスのタイプ(たとえば、ガソリンステーションまたはレストラン)を示す抽出されたパラメータを使用することができる。 The action customization component 120 can identify the context (or attributes thereof) of the speech-based query based on the information (or parameters) provided in the speech-based query and extracted by the NLP component 124. . For example, action customization component 120 can use extracted parameters indicative of geographic location to determine the geographic context of a voice-based query. The action customization component 120 uses extracted parameters that indicate the type of business (eg, gas station or restaurant) to determine user intent (eg, fill up with gas or eat). can be done.
デバイスアクションカスタマイゼーション構成要素120は、NLP構成要素124によって識別されたデバイスアクションを、デバイスアクションの1つまたは複数の対応する既定のシーケンスにマッピングすることができる。たとえば、デバイスアクションカスタマイゼーション構成要素120は、デバイスモデルに関連付けられた第2当事者デバイスのユーザまたは第3当事者アプリケーションのユーザによって要求されるデバイスアクションのシーケンスの統計データ(たとえば、反復または頻度)を収集することができる。識別されたデバイスアクションが与えられると、デバイスアクションカスタマイゼーション構成要素120は、識別されたデバイスアクションを含む、最も可能性が高い1つまたは複数のデバイスアクションシーケンスを決定することができる。デバイスアクションカスタマイゼーション構成要素120は、識別されたデバイスアクションに後続すべき1つまたは複数の他のデバイスアクションを識別(または予測)することができる。たとえば、スマートTVまたはケーブルボックスの場合、現在識別されるアクションが、オンデマンドチャネルに切り替えるためのアクションである場合、最も可能性が高く要求されることになる、後続するデバイスアクションは、動画一覧またはオンデマンドコンテンツ一覧を要求すること、ストリーミング用の動画またはメディアコンテンツを注文することを含む。コンテキストは、この場合、たとえば、「映画ストリーミング」または「エンターテインメントコンテンツストリーミング」であり得る。 Device action customization component 120 can map device actions identified by NLP component 124 to one or more corresponding predefined sequences of device actions. For example, the device action customization component 120 collects statistical data (eg, repetition or frequency) of sequences of device actions requested by users of second party devices or users of third party applications associated with the device model. be able to. Given the identified device actions, the device action customization component 120 can determine one or more most likely device action sequences that include the identified device actions. Device action customization component 120 can identify (or predict) one or more other device actions that should follow the identified device action. For example, for a smart TV or cable box, if the currently identified action is to switch to an on-demand channel, the most likely subsequent device action that would be requested would be a list of videos or Including requesting on-demand content listings and ordering video or media content for streaming. The context may in this case be, for example, "movie streaming" or "entertainment content streaming".
アクションカスタマイゼーション構成要素120は、音声ベース照会のコンテキストを識別するために、様々な要因の組合せを使用することができる。たとえば、アクションカスタマイゼーション構成要素120は、デバイス記述またはアプリケーション記述、音声ベースコンテンツから抽出されるパラメータ、アクションパッケージ118の中の照会パターンに関連付けられたキーワードの任意の組合せを使用することができる。アクションカスタマイゼーション構成要素120は、音声ベース照会のコンテキストを決定するために使用される要因(または情報)を拡張するために、経時的に収集されたデータおよび機械学習方法を採用することができる。 Action customization component 120 can use a combination of various factors to identify the context of voice-based queries. For example, action customization component 120 can use any combination of device or application descriptions, parameters extracted from speech-based content, keywords associated with query patterns in action package 118 . The action customization component 120 can employ data collected over time and machine learning methods to expand the factors (or information) used to determine the context of voice-based queries.
方法500は、オーディオ信号に関連付けられた音声ベース照会のコンテキストに基づいてデジタルコンポーネントを選択すること(ACT512)を含むことができる。コンテンツ選択器構成要素128は、1つまたは複数のデジタルコンポーネント(またはコンテンツ項目)を選択するために、音声ベース照会のコンテキストを記述するキーワード(または属性)を使用することができる。たとえば、コンテンツ選択器構成要素128は、コンテキストがメディアコンテンツストリーミングに関係することを決定すると、ストリーミング用の動画(または他のメディアコンテンツ)に関係するデジタルコンポーネント(たとえば、広告)を選択することができる。コンテンツ選択器構成要素128は、デジタルコンポーネントを選択する際に、オークションを行うことができるか、またはコンテキストに関連付けられたキーワードを含む要求をコンテンツ配信システムへ送ることができる。コンテンツ選択器構成要素128は、オーディオ信号発生器、またはデータ処理システム102の他の構成要素に、デジタルコンポーネントを第1のフォーマットから第2のフォーマットに(たとえば、テキストからオーディオに)変換させることができる。たとえば、コンテンツ選択器構成要素128またはデバイスアクションカスタマイゼーション構成要素120は、識別されたデバイスアクションに関連付けられたオーディオ応答へのオーディオ拡張として、デジタルコンポーネントをフォーマットすることができる。そのような場合、デジタルコンポーネントは、オーディオ応答の一部であるものとして(クライアントデバイス104のユーザによって)知覚され得る。
方法500は、デジタルコンポーネント、およびデバイスアクションコマンドペアに対応するデバイス実行可能コマンドを、クライアントデバイスへ送信すること(ACT512)を含むことができる。通信インターフェース114は、(対応する任意のパラメータとともに)デバイス実行可能コマンド、デジタルコンポーネント、および(存在する場合)応答を、第2当事者デバイス104へ送ることができる。クライアントデバイス104は、たとえば、上記の図4に関して説明したように、デバイス実行可能コマンドを実行することができ、応答および/またはデジタルコンポーネントをユーザに再生(または提示)することができる。
The
図1～図5の説明では、識別子は第2当事者デバイスプロバイダまたは第3当事者アプリケーションプロバイダによって提供されるものとして説明されるが、本開示によって企図される他の実施形態は、それぞれのデバイスアクションデータのアップロードに応答して、識別子を生成するとともにそれを第2当事者デバイスプロバイダまたは第3当事者アプリケーションプロバイダに提供する、データ処理システム102を含む。データ処理システムは、生成された識別子をデバイスアクションデータに割り当てることまたはマッピングすることができる。 1-5, the identifiers are described as being provided by the second party device provider or the third party application provider, but other embodiments contemplated by this disclosure include the respective device action data includes a data processing system 102 that generates an identifier and provides it to a second party device provider or a third party application provider in response to the upload of the . The data processing system can assign or map the generated identifier to the device action data.
図6は、例示的なコンピュータシステム600のブロック図である。コンピュータシステムまたはコンピューティングデバイス600は、システム100、またはデータ処理システム102(またはデバイスもしくはその構成要素)、クライアントデバイス104、もしくはデバイス・プロバイダ・コンピューティング・デバイス108などの、その構成要素を含むことができるか、またはそれらを実装するために使用され得る。コンピューティングシステム600は、情報を通信するためのバス605または他の通信構成要素、および情報を処理するためにバス605に結合されたプロセッサ610または処理回路を含む。コンピューティングシステム600はまた、情報を処理するためにバスに結合された1つまたは複数のプロセッサ610または処理回路を含むことができる。コンピューティングシステム600はまた、情報、およびプロセッサ610によって実行されるべき命令を記憶するためにバス605に結合された、ランダムアクセスメモリ(RAM)または他のダイナミック記憶デバイスなどの主記憶装置615を含む。主記憶装置615は、データリポジトリ116であり得るか、またはそれを含むことができる。主記憶装置615はまた、一時変数、またはプロセッサ610による命令の実行中の他の中間情報を記憶するために使用され得る。コンピューティングシステム600は、静的情報、およびプロセッサ610用の命令を記憶するためにバス605に結合された、読取り専用メモリ(ROM)620または他のスタティック記憶デバイスをさらに含んでよい。ソリッドステートデバイス、磁気ディスク、または光ディスクなどの記憶デバイス625は、情報および命令を持続的に記憶するためにバス605に結合され得る。記憶デバイス625は、データリポジトリ116を含むことができるか、またはその一部であり得る。
FIG. 6 is a block diagram of an
コンピューティングシステム600は、情報をユーザに表示するために、液晶ディスプレイまたはアクティブマトリックスディスプレイなどのディスプレイ635にバス605を介して結合されてよい。英数字キーおよび他のキーを含むキーボードなどの入力デバイス630が、情報およびコマンド選択をプロセッサ610に通信するためにバス605に結合されてよい。入力デバイス630は、タッチスクリーンディスプレイ635を含むことができる。入力デバイス630はまた、方向情報およびコマンド選択をプロセッサ610に通信するために、またディスプレイ635上でのカーソル移動を制御するために、マウス、トラックボール、またはカーソル方向キーなどのカーソル制御装置を含むことができる。ディスプレイ635は、たとえば、図1のデータ処理システム102、クライアントコンピューティングデバイス104、または他の構成要素の一部であり得る。
本明細書で説明するプロセス、システム、および方法は、プロセッサ610が主記憶装置615の中に収容される命令の構成を実行することに応答して、コンピューティングシステム600によって実施され得る。そのような命令は、記憶デバイス625などの別のコンピュータ可読媒体から主記憶装置615の中に読み取られ得る。主記憶装置615の中に収容される命令の構成の実行は、本明細書で説明する例示的なプロセスをコンピューティングシステム600に実行させる。主記憶装置615の中に収容される命令を実行するために、多重処理構成での1つまたは複数のプロセッサも採用されてよい。配線接続された回路構成が、ソフトウェア命令の代わりに、またはソフトウェア命令と組み合わせて、本明細書で説明するシステムおよび方法と一緒に使用され得る。本明細書で説明するシステムおよび方法は、ハードウェア回路構成とソフトウェアとのいかなる特定の組合せにも限定されない。
The processes, systems, and methods described herein may be implemented by computing
図6では例示的なコンピューティングシステムが説明されているが、本明細書で説明した動作を含む主題は、本明細書で開示する構造を含む他のタイプのデジタル電子回路構成、またはコンピュータソフトウェア、ファームウェア、もしくはハードウェア、およびそれらの構造的均等物で、あるいはそれらのうちの1つまたは複数の組合せで実施され得る。 Although an exemplary computing system is described in FIG. 6, the subject matter including the operations described herein may be implemented using other types of digital electronic circuitry, including the structures disclosed herein, or computer software, May be implemented in firmware or hardware, and structural equivalents thereof, or in any combination of one or more thereof.
本明細書で説明したシステムがユーザについての個人情報を収集するかまたは個人情報を利用し得る状況に対して、プログラムまたは機能が個人情報(たとえば、ユーザのソーシャルネットワーク、社会的な行動もしくは活動、ユーザの選好、またはユーザのロケーションについての情報)を収集し得るかどうかを制御するための、あるいはユーザにとってより重要であり得るコンテンツをコンテンツサーバもしくは他のデータ処理システムから受信するかどうか、またはどのように受信するのかを制御するための機会が、ユーザに提供され得る。加えて、いくつかのデータは、パラメータを生成するときに個人が特定可能な情報が除去されるように、記憶または使用される前に1つまたは複数のやり方で匿名化され得る。たとえば、ユーザの識別情報は、ユーザに対して個人が特定可能な情報が決定され得ないように匿名化され得るか、またはユーザの地理的ロケーションは、ユーザの特定のロケーションが決定され得ないように、ロケーション情報が取得される場所で(都市、郵便番号、または州レベルなどに)一般化され得る。したがって、ユーザは、彼または彼女について情報がどのように収集されコンテンツサーバによって使用されるのかを支配する、制御権を有してよい。 For situations where the systems described herein may collect or make use of personal information about a user, the program or function may include personal information (e.g., the user's social networks, social behavior or activities, user preferences, or information about the user's location), or whether content that may be more important to the user is received from a content server or other data processing system, or which The user may be provided with an opportunity to control how they receive. Additionally, some data may be anonymized in one or more ways before being stored or used such that personally identifiable information is removed when generating the parameters. For example, a user's identity may be anonymized so that personally identifiable information about the user cannot be determined, or the user's geographic location may be changed so that the user's specific location cannot be determined. In addition, it can be generalized (such as to the city, zip code, or state level) where the location information is obtained. Thus, a user may have control over how information about him or her is collected and used by the content server.
本明細書で説明した主題および動作は、本明細書で開示する構造を含むデジタル電子回路構成、またはコンピュータソフトウェア、ファームウェア、もしくはハードウェア、およびそれらの構造的均等物、あるいはそれらのうちの1つまたは複数の組合せで実施され得る。本明細書で説明した主題は、1つまたは複数のコンピュータプログラム、たとえば、データ処理装置による実行のための、またはデータ処理装置の動作を制御するための、1つまたは複数のコンピュータ記憶媒体上で符号化された、コンピュータプログラム命令の1つまたは複数の回路として実装され得る。代替または追加として、プログラム命令は、データ処理装置による実行のために、好適な受信機装置への送信のために情報を符号化するように生成される、人工的に生成された伝搬信号、たとえば、機械生成された電気信号、光信号、または電磁信号の上で符号化され得る。コンピュータ記憶媒体は、コンピュータ可読記憶デバイス、コンピュータ可読記憶基板、ランダムもしくはシリアルアクセスメモリアレイもしくはデバイス、またはそれらのうちの1つまたは複数の組合せであり得るか、またはその中に含まれ得る。コンピュータ記憶媒体は伝搬信号でないが、コンピュータ記憶媒体は、人工的に生成された伝搬信号の中で符号化されたコンピュータプログラム命令の送信元または送信先であり得る。コンピュータ記憶媒体はまた、1つまたは複数の別個の構成要素または媒体(たとえば、複数のCD、ディスク、または他の記憶デバイス)であり得るか、またはその中に含まれ得る。本明細書で説明した動作は、1つもしくは複数のコンピュータ可読記憶デバイス上に記憶されるかまたは他の送信元から受信されるデータに対して、データ処理装置によって実行される動作として実施され得る。 The subject matter and operations described herein may be directed to digital electronic circuitry, or computer software, firmware, or hardware, including structure disclosed herein, and structural equivalents thereof, or one of them. or multiple combinations. The subject matter described herein is one or more computer programs, e.g., stored on one or more computer storage media, for execution by a data processing apparatus or for controlling operation of a data processing apparatus. It may be implemented as one or more circuits of encoded computer program instructions. Alternatively or additionally, the program instructions are generated for execution by a data processing device to encode information for transmission to a suitable receiver device, such as an artificially generated propagated signal, e.g. , may be encoded on a machine-generated electrical, optical, or electromagnetic signal. A computer storage medium may be or be contained in a computer readable storage device, a computer readable storage substrate, a random or serial access memory array or device, or a combination of one or more thereof. Although a computer storage medium is not a propagated signal, a computer storage medium can be the source or destination of computer program instructions encoded in an artificially generated propagated signal. A computer storage medium can also be or be contained within one or more separate components or media (eg, multiple CDs, discs, or other storage devices). The operations described herein may be implemented as operations performed by a data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources. .
「データ処理システム」、「コンピューティングデバイス」、「構成要素」、または「データ処理装置」という用語は、例として、プログラマブルプロセッサ、コンピュータ、システムオンチップ、もしくは複数のそれら、または上記のものの組合せを含む、データを処理するための様々な装置、デバイス、および機械を包含する。装置は、専用論理回路構成、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)を含むことができる。装置はまた、ハードウェアに加えて、当該のコンピュータプログラム用の実行環境を作成するコード、たとえば、プロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、クロスプラットフォームランタイム環境、仮想マシン、またはそれらのうちの1つまたは複数の組合せを構成するコードを含むことができる。装置および実行環境は、ウェブサービス基盤、分散コンピューティング基盤、およびグリッドコンピューティング基盤などの、様々な異なるコンピューティングモデル基盤を実現することができる。データ処理システム102のデバイスアクションカスタマイゼーション構成要素120、音声認識構成要素122、NLP構成要素124、オーディオ信号発生器構成要素126、またはコンテンツ選択器構成要素128は、1つまたは複数のデータ処理装置、システム、コンピューティングデバイス、またはプロセッサを含むことまたは共有することができる。 The terms "data processing system", "computing device", "component", or "data processing apparatus" may be used to refer to, by way of example, a programmable processor, computer, system-on-chip, or any combination thereof, or any combination of the above. encompasses various apparatus, devices and machines for processing data, including The device may include dedicated logic circuitry, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). The apparatus also includes, in addition to hardware, code that creates an execution environment for the computer program in question, such as processor firmware, protocol stacks, database management systems, operating systems, cross-platform runtime environments, virtual machines, or among them. may include code that constitutes one or more combinations of The device and execution environment can implement a variety of different computing model infrastructures, such as web services infrastructure, distributed computing infrastructure, and grid computing infrastructure. The device action customization component 120, the speech recognition component 122, the NLP component 124, the audio signal generator component 126, or the content selector component 128 of the data processing system 102 may be implemented by one or more data processing devices, systems, or systems. , computing device, or processor.
コンピュータプログラム(プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、スクリプト、またはコードとも呼ばれる)は、コンパイラ型言語またはインタプリタ型言語、宣言型言語または手続き型言語を含む、任意の形式のプログラミング言語で書くことができ、スタンドアロンプログラム、もしくはモジュール、コンポーネント、サブルーチン、オブジェクト、またはコンピューティング環境において使用するのに適した他のユニットを含む、任意の形態で展開され得る。コンピュータプログラムは、ファイルシステムの中のファイルに対応することができる。コンピュータプログラムは、他のプログラムもしくはデータ(たとえば、マークアップ言語ドキュメントの中に記憶された1つまたは複数のスクリプト)を保持するファイルの一部分の中に、当該のプログラムに専用の単一のファイルの中に、または複数の協調ファイル(たとえば、1つまたは複数のモジュール、サブプログラム、またはコードの部分を記憶するファイル)の中に記憶され得る。コンピュータプログラムは、1つのコンピュータ上で、または1つの場所に配置されるか、もしくは複数の場所にわたって分散され通信ネットワークによって相互接続される複数のコンピュータ上で実行されるように、展開され得る。 Computer programs (also called programs, software, software applications, apps, scripts, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative languages, or procedural languages. It may be deployed in any form, including stand-alone programs, or modules, components, subroutines, objects, or other units suitable for use in a computing environment. A computer program can correspond to a file in a file system. A computer program may contain a single file dedicated to that program in parts of files that hold other programs or data (e.g., one or more scripts stored in a markup language document). or in multiple collaboration files (eg, files that store one or more modules, subprograms, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers located at one site or distributed across multiple sites and interconnected by a communication network.
本明細書で説明したプロセスおよび論理フローは、入力データに対して動作するとともに出力を生成することによってアクションを実行するために、1つまたは複数のプログラマブルプロセッサが1つまたは複数のコンピュータプログラム(たとえば、データ処理システム102の構成要素)を実行することによって実行され得る。プロセスおよび論理フローはまた、専用論理回路構成、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)によって実行することができ、そうした専用論理回路構成として装置も実装することができる。コンピュータプログラム命令およびデータを記憶するのに適したデバイスは、すべての形態の、例として、半導体メモリデバイス、たとえば、EPROM、EEPROM、およびフラッシュメモリデバイスを含む不揮発性メモリ、媒体およびメモリデバイス、磁気ディスク、たとえば、内部ハードディスクまたはリムーバルディスク、光磁気ディスク、ならびにCD ROMおよびDVD-ROMディスクを含む。プロセッサおよびメモリは、専用論理回路構成によって増補され得るか、または専用論理回路構成の中に組み込まれ得る。 The processes and logic flows described herein rely on one or more programmable processors executing one or more computer programs (e.g., , a component of data processing system 102). The processes and logic flows can also be performed by dedicated logic circuitry, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits), and the device can also be implemented as such dedicated logic circuitry. . Devices suitable for storing computer program instructions and data include all forms of nonvolatile memory, media and memory devices, including, by way of example, semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks; , including, for example, internal or removable disks, magneto-optical disks, and CD ROM and DVD-ROM disks. The processor and memory may be augmented by, or embedded within, dedicated logic circuitry.
本明細書で説明した主題は、たとえば、データサーバとしてのバックエンド構成要素を含むか、またはミドルウェア構成要素、たとえば、アプリケーションサーバを含むか、またはフロントエンド構成要素、たとえば、ユーザが本明細書で説明した主題の実装形態とそれを通じて対話できるグラフィカルユーザインターフェースもしくはウェブブラウザを有するクライアントコンピュータ、あるいは1つまたは複数のそのようなバックエンド構成要素、ミドルウェア構成要素、またはフロントエンド構成要素の組合せを含む、コンピューティングシステムの中で実施され得る。システムの構成要素は、任意の形態または媒体のデジタルデータ通信、たとえば、通信ネットワークによって、相互接続され得る。通信ネットワークの例は、ローカルエリアネットワーク(「LAN」)およびワイドエリアネットワーク(「WAN」)、インターネットワーク(たとえば、インターネット)、ならびにピアツーピアネットワーク(たとえば、アドホックピアツーピアネットワーク)を含む。 The subject matter described herein includes back-end components such as data servers, or middleware components such as application servers, or front-end components such as user including a client computer having a graphical user interface or web browser through which an implementation of the described subject matter can interact, or a combination of one or more such back-end, middleware, or front-end components; It can be implemented within a computing system. The components of the system can be interconnected by any form or medium of digital data communication, eg, a communication network. Examples of communication networks include local area networks (“LAN”) and wide area networks (“WAN”), internetworks (eg, the Internet), and peer-to-peer networks (eg, ad-hoc peer-to-peer networks).
本明細書でそのように説明したコンピューティングシステムは、クライアントおよびサーバを含むことができる。クライアントおよびサーバは、一般に互いに遠隔にあり、通常は通信ネットワーク(たとえば、ネットワーク106)を通じて対話する。コンピュータプログラムがそれぞれのコンピュータ上で動作するとともに互いにクライアントサーバ関係を有することによって、クライアントとサーバとの関係が現れる。いくつかの実装形態では、サーバは、(たとえば、クライアントコンピューティングデバイスと対話するユーザにデータを表示し、そうしたユーザからユーザ入力を受信するために)データ(たとえば、デジタルコンポーネントを表すデータパケット)をクライアントコンピューティングデバイスへ送信する。クライアントコンピューティングデバイスにおいて生成されたデータ(たとえば、ユーザ対話の結果)は、サーバにおいてクライアントコンピューティングデバイスから受信され得る(たとえば、データ処理システム102またはそのサーバによって受信され得る)。 The computing systems so described herein can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network (eg, network 106). The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some implementations, a server sends data (eg, data packets representing digital components) (eg, to display data to and receive user input from a user interacting with a client computing device). Send to client computing devices. Data generated at a client computing device (eg, results of user interactions) may be received from the client computing device at a server (eg, received by data processing system 102 or its server).
図面では特定の順序で動作が示されるが、そのような動作は、図示の特定の順序で、または順番に実行されることを必要とされず、図示したすべての動作は、実行されることが必須ではない。本明細書で説明したアクションは、異なる順序で実行され得る。 Although the figures show actions in a particular order, such actions are not required to be performed in the specific order or order shown, and all actions shown may be performed. Not required. Actions described herein may be performed in different orders.
様々なシステム構成要素の分離は、すべての実装形態において分離を必要とするとは限らず、説明したプログラム構成要素は、単一のハードウェアまたはソフトウェア製品の中に含まれ得る。たとえば、デバイスアクションカスタマイゼーション構成要素120、音声認識構成要素122、NLP構成要素124、オーディオ信号発生器構成要素126、およびコンテンツ選択器構成要素128の任意の組合せは、単一の構成要素、アプリケーション、プログラム、または1つまたは複数の処理回路を有する論理デバイス、あるいはデータ処理システム102の1つまたは複数のサーバの一部であり得る。 Separation of various system components may not require separation in all implementations, and the described program components may be contained within a single hardware or software product. For example, any combination of device action customization component 120, speech recognition component 122, NLP component 124, audio signal generator component 126, and content selector component 128 may be combined into a single component, application, program. , or a logic device having one or more processing circuits, or part of one or more servers of data processing system 102 .
ここでいくつかの例示的な実装形態を説明しているが、上記が例であり限定的ではなく、例として提示されていることは明らかである。詳細には、本明細書で提示した例の多くが方法行為またはシステム要素の特定の組合せを伴うが、それらの行為およびそれらの要素は、同じ目的を達成するために他のやり方で組み合わせられてよい。1つの実装形態に関して説明した行為、要素、および機能は、他の実装形態における類似の役割または実装形態から除外されるものではない。 Although some example implementations are now described, it should be clear that the above are presented by way of example and not limitation. In particular, although many of the examples presented herein involve a particular combination of method acts or system elements, those acts and those elements could be combined in other ways to accomplish the same purpose. good. Acts, elements and functions described with respect to one implementation are not excluded from similar roles or implementations in other implementations.
本明細書で使用する語法および用語は説明の目的のためのものであり、限定的とみなされるべきでない。「含むこと」、「備えること」、「有すること」、「収容すること」、「伴うこと」、「によって特徴づけられる」、「という点で特徴づけられる」、および本明細書におけるそれらの変形の使用は、その後に列挙される項目、それらの均等物、および追加の項目、ならびにその後に排他的に列挙される項目からなる代替実装形態を包含することを意味する。一実装形態では、本明細書で説明したシステムおよび方法は、説明した要素、行為、または構成要素のうちの1つ、その2つ以上の各組合せ、またはそのすべてからなる。 The phraseology and terminology used herein is for the purpose of description and should not be regarded as limiting. "including", "comprising", "having", "accommodating", "accompanied by", "characterized by", "characterized by" and variations thereof herein Use of is meant to encompass the items listed thereafter, their equivalents, and additional items, as well as alternative implementations consisting of the items listed exclusively after. In one implementation, the systems and methods described herein consist of one, each combination of two or more, or all of the described elements, acts, or components.
単数形で参照される、本明細書におけるシステムおよび方法の実装形態または要素もしくは行為への任意の参照はまた、複数のこれらの要素を含む実装形態を包含してよく、本明細書における任意の実装形態、要素、または行為への複数形での任意の参照はまた、単一の要素しか含まない実装形態を包含してよい。単数形または複数形での参照は、本開示のシステムもしくは方法、それらの構成要素、行為、または要素を、単一または複数の構成に限定するものではない。任意の情報、行為、または要素に基づく、任意の行為または要素への参照は、その行為または要素が任意の情報、行為、または要素に少なくとも部分的に基づく実装形態を含んでよい。 Any reference to implementations or elements or acts of the systems and methods herein that are referred to in the singular may also encompass implementations that include a plurality of these elements, and any Any reference to an implementation, element, or act in the plural may also encompass implementations containing only a single element. References in singular or plural form are not intended to limit the disclosed systems or methods, components, acts, or elements thereof to single or multiple configurations. A reference to any act or element that is based on any information, act or element may include implementations in which that act or element is based at least in part on any information, act or element.
本明細書で開示する任意の実装形態は、任意の他の実装形態または実施形態と組み合わせられてよく、「実装形態」、「いくつかの実装形態」、「1つの実装形態」などへの参照は、必ずしも互いに排他的であるとは限らず、実装形態に関して説明した特定の機能、構造、または特性が、少なくとも1つの実装形態または実施形態の中に含まれ得ることを示すことを意図する。本明細書で使用するような用語は、必ずしもすべてが同じ実装形態を参照しているとは限らない。任意の実装形態は、本明細書で開示する態様および実装形態と矛盾しない任意の方法で、任意の他の実装形態と包含的または排他的に組み合わせられてよい。 Any implementation disclosed herein may be combined with any other implementation or embodiment, and references to "implementation," "some implementations," "one implementation," etc. are not necessarily mutually exclusive, but are intended to indicate that a particular feature, structure, or characteristic described with respect to an implementation can be included in at least one implementation or embodiment. Terms such as those used herein are not necessarily all referring to the same implementation. Any implementation may be combined inclusively or exclusively with any other implementation in any manner consistent with the aspects and implementations disclosed herein.
「または」への参照は、「または」を使用して説明した任意の用語が、説明した用語のうちの1つ、2つ以上、および全部のうちのいずれかを示し得るように、包含的であるものと解釈されてよい。たとえば、「「A」および「B」のうちの少なくとも1つ」への参照は、「A」のみ、「B」のみ、および「A」と「B」の両方を含むことができる。「備えること」または他のオープンな用語とともに使用されるそのような参照は、追加の項目を含むことができる。 References to “or” are inclusive, such that any term described using “or” can refer to either one, more than one, and all of the described terms. may be interpreted as being For example, a reference to "at least one of 'A' and 'B'" can include only 'A', only 'B', and both 'A' and 'B'. Such references used with "comprising" or other open terminology may include additional items.
図面、発明を実施するための形態、または任意の請求項における技術的特徴に参照符号が後続する場合、その参照符号は、図面、発明を実施するための形態、および請求項の了解度を高めるために含められている。したがって、参照符号も、参照符号がないことも、任意の請求項要素の範囲においていかなる限定的効果も有しない。 When a reference sign follows a technical feature in the drawings, the detailed description, or any claim, the reference sign enhances the comprehension of the drawings, the detailed description, and the claims. included for Accordingly, neither the reference sign nor the absence of a reference sign shall have any limiting effect on the scope of any claim element.
本明細書で説明したシステムおよび方法は、それらの特性から逸脱することなく他の特定の形態で具現化され得る。上記の実装形態は、説明したシステムおよび方法の限定ではなく例示である。したがって、本明細書で説明したシステムおよび方法の範囲は、上記の説明ではなく添付の特許請求の範囲によって示され、特許請求の範囲の同等の意味および領域内に入る変更はそれらの中に包含される。 The systems and methods described herein may be embodied in other specific forms without departing from their attributes. The above implementations are illustrative rather than limiting of the systems and methods described. The scope of the systems and methods described herein is, therefore, indicated by the appended claims rather than by the foregoing description, and all changes that come within the meaning and range of equivalency of the claims are embraced therein. be done.
100 システム
102 データ処理システム
104 クライアントデバイス
106 通信ネットワーク
108 デバイス・プロバイダ・コンピューティング・デバイス
110 メモリ
112 プロセッサ
114 通信インターフェース
116 データリポジトリ
118 アクションパッケージ
120 デバイスアクションカスタマイゼーション構成要素
122 音声認識構成要素
124 自然言語プロセッサ構成要素
126 オーディオ信号発生器構成要素
128 コンテンツ選択器構成要素
302 オーディオレシーバ
304 通信インターフェース
306 コマンド実行構成要素
308 スピーカー
310 コントローラ
600 コンピュータシステム
605 バス
610 プロセッサ
615 主記憶装置
620 読取り専用メモリ
625 記憶デバイス
630 入力デバイス
635 ディスプレイ
100 systems
102 Data processing system
104 client devices
106 Communication Network
108 Device Provider Computing Device
110 memory
112 processors
114 communication interface
116 data repositories
118 Action Package
120 Device Action Customization Components
122 Speech Recognition Components
124 Natural Language Processor Components
126 Audio Signal Generator Components
128 Content Selector Components
302 audio receiver
304 communication interface
306 Command Execution Component
308 speakers
310 controller
600 computer system
605 bus
610 processor
615 main memory
620 read-only memory
625 storage device
630 input device
635 Display
Claims (60)
デバイスアクションデータおよび前記デバイスアクションデータに関連付けられた識別子をコンピューティングデバイスから受信するための通信インターフェースであって、前記デバイスアクションデータが、複数のクライアントデバイスによってサポートされる複数のデバイスアクション、および複数のデバイス実行可能コマンドを示し、前記複数のデバイス実行可能コマンドの各デバイス実行可能コマンドが、前記複数のデバイスアクションのうちの対応するデバイスアクションの実行をトリガする、通信インターフェースと、
前記デバイスアクションデータを記憶するためのメモリと、
前記デバイスアクションデータを前記識別子にマッピングするためのデバイスアクションカスタマイゼーション構成要素と、
オーディオ信号および前記識別子を前記複数のクライアントデバイスのうちのクライアントデバイスから受信するための前記通信インターフェースであって、前記オーディオ信号が、音声ベース照会に応答して前記クライアントデバイスによって取得される、前記通信インターフェースと、
前記複数のクライアントデバイスによってサポートされる前記複数のデバイスアクションのうちのデバイスアクションを、前記識別子、および前記オーディオ信号に関連付けられたコンテンツを使用して識別するための自然言語プロセッサ構成要素と、
前記デバイスアクションに対応する、前記複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドを識別するための前記デバイスアクションカスタマイゼーション構成要素と、
前記デバイスアクションを遂行させるために、前記音声ベース照会に応答した実行のための前記デバイス実行可能コマンドを前記クライアントデバイスへ送信するための前記通信インターフェースと
を備えるデータ処理システム。 A data processing system for enabling voice-based interaction with a client device, comprising:
1. A communication interface for receiving device action data and identifiers associated with the device action data from a computing device, wherein the device action data is a plurality of device actions supported by a plurality of client devices and a plurality of device actions supported by a plurality of client devices. a communication interface indicative of device-executable commands, each device-executable command of the plurality of device-executable commands triggering execution of a corresponding one of the plurality of device actions;
a memory for storing the device action data;
a device action customization component for mapping the device action data to the identifier;
the communication interface for receiving an audio signal and the identifier from a client device of the plurality of client devices, wherein the audio signal is obtained by the client device in response to a voice-based inquiry; an interface;
a natural language processor component for identifying a device action of the plurality of device actions supported by the plurality of client devices using the identifier and content associated with the audio signal;
the device action customization component for identifying a device executable command of the plurality of device executable commands corresponding to the device action;
and said communication interface for transmitting said device-executable commands for execution in response to said voice-based inquiry to said client device to effect said device action.
前記デバイスアクションの遂行に関する提示のために前記クライアントデバイスへ送るための応答を識別するための前記デバイスアクションカスタマイゼーション構成要素と
を備える、請求項1に記載のデータ処理システム。 the communication interface for receiving a plurality of responses for presentation by the plurality of client devices, each response of the plurality of responses for presentation supported by the plurality of client devices; the communication interface for performing a corresponding one of the device actions;
2. The data processing system of claim 1, comprising: said device action customization component for identifying a response to send to said client device for presentation regarding performance of said device action.
前記重み値に基づいて前記デバイスアクションを識別するための
前記自然言語プロセッサ構成要素を備える、請求項1に記載のデータ処理システム。 determining, for each first device action of the plurality of device actions, a corresponding weight value for matching the content of the received audio signal with the first device action;
2. The data processing system of claim 1, comprising said natural language processor component for identifying said device action based on said weight value.
前記1つまたは複数のパラメータを前記クライアントデバイスへ送信するための前記通信インターフェースと
を備える、請求項9に記載のデータ処理システム。 said device action customization component for identifying one or more parameters associated with said device executable command;
10. The data processing system of claim 9, comprising: said communication interface for transmitting said one or more parameters to said client device.
デバイスアクションデータおよび前記デバイスアクションデータに関連付けられた識別子をコンピューティングデバイスから受信するステップであって、前記デバイスアクションデータが、複数のクライアントデバイスによってサポートされる複数のデバイスアクション、および複数のデバイス実行可能コマンドを示し、前記複数のデバイス実行可能コマンドの各デバイス実行可能コマンドが、前記複数のデバイスアクションのうちの対応するデバイスアクションの実行をトリガする、ステップと、
前記デバイスアクションデータを記憶するステップと、
前記デバイスアクションデータを前記識別子にマッピングするステップと、
オーディオ信号および前記識別子を前記複数のクライアントデバイスのうちのクライアントデバイスから受信するステップであって、前記オーディオ信号が、音声ベース照会に応答して前記クライアントデバイスによって取得される、ステップと、
前記複数のクライアントデバイスによってサポートされる前記複数のデバイスアクションのうちのデバイスアクションを、前記識別子、および前記オーディオ信号に関連付けられたコンテンツを使用して識別するステップと、
前記デバイスアクションに対応する、前記複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドを識別するステップと、
前記デバイスアクションを遂行させるために、前記音声ベース照会に応答した実行のための前記デバイス実行可能コマンドを前記クライアントデバイスへ送信するステップと
を備える方法。 A method of enabling voice-based interaction with a client device, comprising:
receiving from a computing device device action data and an identifier associated with said device action data, said device action data being capable of performing multiple device actions supported by multiple client devices; indicating a command, each device-executable command of the plurality of device-executable commands triggering execution of a corresponding one of the plurality of device-actions;
storing the device action data;
mapping the device action data to the identifier;
receiving an audio signal and the identifier from a client device of the plurality of client devices, wherein the audio signal is obtained by the client device in response to a voice-based inquiry;
identifying a device action of the plurality of device actions supported by the plurality of client devices using the identifier and content associated with the audio signal;
identifying a device-executable command of the plurality of device-executable commands that corresponds to the device action;
sending the device-executable command for execution in response to the voice-based query to the client device to cause the device action to be performed.
前記デバイスアクションの遂行に関する提示のために前記クライアントデバイスへ送るための応答を識別するステップと
を備える、請求項11に記載の方法。 receiving a plurality of responses for presentation by the plurality of client devices, each response of the plurality of responses for presentation being one of the plurality of device actions supported by the plurality of client devices; a step relating to performing the corresponding device action of
12. The method of claim 11, comprising identifying a response to send to the client device for presentation regarding performance of the device action.
前記重み値に基づいて前記デバイスアクションを識別するステップと
を備える、請求項11に記載の方法。 determining, for each first device action of the plurality of device actions, a corresponding weight value for matching the content of the received audio signal with the first device action;
12. The method of claim 11, comprising identifying the device action based on the weight value.
前記1つまたは複数のパラメータを前記クライアントデバイスへ送信するステップと
を備える、請求項19に記載の方法。 identifying one or more parameters associated with the device executable command;
20. The method of claim 19, comprising: sending said one or more parameters to said client device.
入力音声ベース照会に対応するオーディオ信号を生成するためのオーディオレシーバであって、前記電子デバイスが、リモートデータ処理システムによって保持されるデバイスアクションデータ、および前記デバイスアクションデータの識別子に関連付けられており、前記デバイスアクションデータが、前記デバイスアクションデータに関連付けられた電子デバイスによってサポートされる、複数のデバイスアクションおよび複数のデバイス実行可能コマンドを含み、各デバイス実行可能コマンドが、前記複数のデバイスアクションのうちの対応するデバイスアクションの実行をトリガする、オーディオレシーバと、
前記音声ベース照会に応答して前記識別子および前記オーディオ信号を前記リモートデータ処理システムへ送信するための通信インターフェースであって、前記リモートデータ処理システムが、前記複数のデバイスアクションおよび前記複数のデバイス実行可能コマンドに前記識別子をマッピングする1つまたは複数のデータ構造を保持する、通信インターフェースと、
前記オーディオ信号の送信に応答して前記複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドを前記リモートデータ処理システムから受信するための前記通信インターフェースであって、前記デバイス実行可能コマンドが、前記識別子、前記オーディオ信号、および前記1つまたは複数のデータ構造に基づいて前記データ処理システムによって識別される、前記通信インターフェースと、
前記デバイスアクションを実行するための前記デバイス実行可能コマンドを実行するためのコマンド実行構成要素と
を備える電子デバイス。 an electronic device,
1. An audio receiver for generating an audio signal corresponding to an input speech-based query, wherein the electronic device is associated with device action data maintained by a remote data processing system and an identifier for the device action data; wherein the device action data includes a plurality of device actions and a plurality of device executable commands supported by an electronic device associated with the device action data, each device executable command representing one of the plurality of device actions; an audio receiver that triggers execution of corresponding device actions;
a communications interface for transmitting said identifier and said audio signal to said remote data processing system in response to said voice-based query, wherein said remote data processing system is capable of performing said plurality of device actions and said plurality of devices a communication interface holding one or more data structures mapping said identifiers to commands;
said communication interface for receiving from said remote data processing system a device-executable command of said plurality of device-executable commands in response to said transmission of said audio signal, said device-executable command being associated with said identifier; , the communication interface identified by the data processing system based on the audio signal and the one or more data structures;
and a command execution component for executing the device executable command for executing the device action.
前記デバイスアクションを実行することに関して前記オーディオ応答を再生するためのスピーカーと
を備える、請求項21に記載の電子デバイス。 the communication interface for receiving an audio response for display by the device in response to the transmission of the audio signal;
22. The electronic device of claim 21, comprising: a speaker for playing said audio response in connection with performing said device action.
前記デバイス実行可能コマンドに対応する前記デバイスアクションの実行中に前記オーディオ応答を前記スピーカーに再生させるための前記通信インターフェース、または
前記デバイス実行可能コマンドに対応する前記デバイスアクションの実行の後に前記オーディオ応答を前記スピーカーに再生させるための前記通信インターフェース
を備える、請求項22に記載の電子デバイス。 the command execution component for causing the speaker to play the audio response prior to execution of the device action corresponding to the device executable command;
the communication interface for causing the speaker to play the audio response during execution of the device action corresponding to the device executable command; or playing the audio response after execution of the device action corresponding to the device executable command. 23. The electronic device of claim 22, comprising the communication interface for playing on the speaker.
モバイルデバイス、
ロボットデバイス、
自動車、
アプライアンスデバイス、
スマートテレビジョン、
照明制御システム、または
ホームセキュリティシステムを含む、
請求項21に記載の電子デバイス。 the device is
mobile devices,
robotic device,
Automobile,
appliance device,
smart tv,
including lighting control systems, or home security systems,
22. Electronic device according to claim 21.
前記デバイス実行可能コマンドを実行するために前記1つまたは複数のパラメータを使用するための前記コマンド実行構成要素と
を備える、請求項27に記載の電子デバイス。 said communication interface for receiving from said remote data processing system one or more parameters associated with said device executable command;
28. The electronic device of claim 27, comprising: the command execution component for using the one or more parameters to execute the device executable command.
入力音声ベース照会に対応するオーディオ信号を電子デバイスによって生成するステップであって、前記電子デバイスが、リモートデータ処理システムによって保持されるデバイスアクションデータ、および前記デバイスアクションデータの識別子に関連付けられており、前記デバイスアクションデータが、前記デバイスアクションデータに関連付けられた電子デバイスによってサポートされる、複数のデバイスアクションおよび複数のデバイス実行可能コマンドを含み、各デバイス実行可能コマンドが、前記複数のデバイスアクションのうちの対応するデバイスアクションの実行をトリガする、ステップと、
前記電子デバイスによって、前記音声ベース照会に応答して前記識別子および前記オーディオ信号を前記リモートデータ処理システムへ送信するステップであって、前記リモートデータ処理システムが、前記複数のデバイスアクションおよび前記複数のデバイス実行可能コマンドに前記識別子をマッピングする1つまたは複数のデータ構造を保持する、ステップと、
前記電子デバイスによって、前記オーディオ信号の送信に応答して前記複数のデバイス実行可能コマンドのうちのデバイス実行可能コマンドを前記リモートデータ処理システムから受信するステップであって、前記デバイス実行可能コマンドが、前記識別子、前記オーディオ信号、および前記1つまたは複数のデータ構造に基づいて前記データ処理システムによって識別される、ステップと、
前記デバイスアクションを実行するための前記デバイス実行可能コマンドを前記電子デバイスによって実行するステップと
を備える方法。 A method of enabling support for voice-based interaction, comprising:
generating, by an electronic device, an audio signal corresponding to an input speech-based query, said electronic device being associated with device action data maintained by a remote data processing system and an identifier for said device action data; wherein the device action data includes a plurality of device actions and a plurality of device executable commands supported by an electronic device associated with the device action data, each device executable command representing one of the plurality of device actions; a step that triggers execution of a corresponding device action;
transmitting, by said electronic device, said identifier and said audio signal to said remote data processing system in response to said voice-based query, said remote data processing system performing said plurality of device actions and said plurality of devices; holding one or more data structures mapping said identifiers to executable commands;
receiving, by the electronic device, a device-executable command of the plurality of device-executable commands from the remote data processing system in response to transmission of the audio signal, the device-executable command identified by the data processing system based on an identifier, the audio signal, and the one or more data structures;
and executing, by the electronic device, the device-executable command for performing the device action.
前記デバイスアクションを実行することに関して前記オーディオ応答を再生するステップと
を備える、請求項31に記載の方法。 receiving an audio response for display by the device in response to the transmission of the audio signal;
32. The method of claim 31, comprising playing the audio response in relation to performing the device action.
前記デバイス実行可能コマンドに対応する前記デバイスアクションの実行中に前記オーディオ応答を前記スピーカーに再生させるステップ、または
前記デバイス実行可能コマンドに対応する前記デバイスアクションの実行の後に前記オーディオ応答を前記スピーカーに再生させるステップ
を備える、請求項32に記載の方法。 causing a speaker to play the audio response prior to execution of the device action corresponding to the device executable command;
playing the audio response to the speaker during execution of the device action corresponding to the device executable command; or playing the audio response to the speaker after execution of the device action corresponding to the device executable command. 33. The method of claim 32, comprising the step of causing.
モバイルデバイス、
ロボットデバイス、
自動車、
アプライアンスデバイス、
スマートテレビジョン、
照明制御システム、または
ホームセキュリティシステムを含む、
請求項31に記載の方法。 The electronic device
mobile devices,
robotic device,
Automobile,
appliance device,
smart tv,
including lighting control systems, or home security systems,
32. The method of claim 31.
前記デバイス実行可能コマンドを実行するために前記1つまたは複数のパラメータを使用するステップと
を備える、請求項37に記載の方法。 receiving from the remote data processing system one or more parameters associated with the device executable command;
and using the one or more parameters to execute the device executable command.
複数の電子デバイスによってサポートされる複数のデバイスアクションコマンドペアを含むデバイスアクションデータを記憶するためのメモリであって、各デバイスアクションコマンドペアが、複数のデバイスアクションのそれぞれのデバイスアクション、および前記それぞれのデバイスアクションの遂行をトリガするための複数のデバイス実行可能コマンドのそれぞれのデバイス実行可能コマンドを含む、メモリと、
前記複数の電子デバイスによってサポートされる前記複数のデバイスアクションコマンドペアの各々に識別子をマッピングするためのデバイスアクションカスタマイゼーション構成要素と、
オーディオ信号および前記識別子を電子デバイスから受信するための通信インターフェースであって、前記オーディオ信号が、音声ベース照会に応答して前記電子デバイスによって取得される、通信インターフェースと、
前記オーディオ信号に関連付けられたコンテンツ、および前記識別子を使用して、前記複数のデバイスアクションコマンドペアのうちのデバイスアクションコマンドペアを識別するための、自然言語プロセッサ構成要素と、
前記デバイスアクションデータまたは前記デバイスアクションコマンドペアに基づいて前記音声ベース照会のコンテキストを識別するための前記デバイスアクションカスタマイゼーション構成要素と、
前記音声ベース照会の前記コンテキストに基づいてデジタルコンポーネントを選択するためのコンテンツ選択器構成要素と、
前記デジタルコンポーネント、および前記デバイスアクションコマンドペアに関連付けられたデバイス実行可能コマンドを、前記電子デバイスへ送信するための前記通信インターフェースであって、前記デバイス実行可能コマンドが、前記デバイスアクションコマンドペアに関連付けられた前記デバイスアクションを遂行させ、前記デジタルコンポーネントが、前記電子デバイスによって提示されるものである、前記通信インターフェースと
を備えるデータ処理システム。 A data processing system for providing content in response to voice-based interaction, comprising:
A memory for storing device action data including a plurality of device action command pairs supported by a plurality of electronic devices, each device action command pair representing a respective device action of the plurality of device actions and a respective a memory including a device-executable command for each of a plurality of device-executable commands for triggering performance of a device action;
a device action customization component for mapping an identifier to each of the plurality of device action command pairs supported by the plurality of electronic devices;
a communication interface for receiving an audio signal and the identifier from an electronic device, wherein the audio signal is obtained by the electronic device in response to a voice-based inquiry;
a natural language processor component for identifying a device action command pair of said plurality of device action command pairs using content associated with said audio signal and said identifier;
the device action customization component for identifying a context for the voice-based query based on the device action data or the device action command pair;
a content selector component for selecting digital components based on the context of the speech-based query;
the communication interface for transmitting the digital component and device-executable commands associated with the device-action command pairs to the electronic device, wherein the device-executable commands are associated with the device-action command pairs; and said communication interface causing said device action to be performed, said digital component being presented by said electronic device.
前記デバイスアクションコマンドペアに関連付けられた前記第1のデバイスアクションを使用して、前記音声ベース照会に関連付けられたデバイスアクションの既定のシーケンスを識別し、
デバイスアクションの前記既定のシーケンスの中の、前記デバイスアクションコマンドペアに関連付けられた前記第1のデバイスアクションに後続する、1つまたは複数の第2のデバイスアクションを識別し、
前記デバイスアクションに後続する前記1つまたは複数の第2のデバイスアクションに基づいて、前記音声ベース照会の前記コンテキストの属性を識別するための
前記デバイスアクションカスタマイゼーション構成要素を備える、
請求項41に記載のデータ処理システム。 wherein the device action is a first device action, and the data processing system is configured to:
identifying a default sequence of device actions associated with the voice-based query using the first device action associated with the device action command pair;
identifying one or more second device actions in the predetermined sequence of device actions that follow the first device action associated with the device action command pair;
a device action customization component for identifying attributes of the context of the speech-based query based on the one or more second device actions that follow the device action;
42. A data processing system as claimed in claim 41.
前記デバイスアクションコマンドペアに対応する、前記複数の応答のうちの応答を識別するための、前記デバイスアクションカスタマイゼーション構成要素と、
前記応答を前記電子デバイスへ提示のために送信するための前記通信インターフェースと
を備える、請求項41に記載のデータ処理システム。 said memory for holding a plurality of responses for servicing said plurality of electronic devices, each response of said plurality of responses being one of said plurality of device action command pairs supported by said plurality of electronic devices; said memory mapped to corresponding device action command pairs of;
the device action customization component for identifying a response of the plurality of responses corresponding to the device action command pair;
42. The data processing system of claim 41, comprising: said communication interface for transmitting said response to said electronic device for presentation.
前記自然言語プロセッサ構成要素によって識別される前記デバイスアクションコマンドペアに関連付けられた前記1つまたは複数のキーワードに基づいて、前記音声ベース照会の前記コンテキストを識別するための、前記デバイスアクションカスタマイゼーション構成要素と
を備える、請求項41に記載のデータ処理システム。 said memory for retaining one or more corresponding keywords for each device action command pair of said plurality of device action command pairs;
the device action customization component for identifying the context of the speech-based query based on the one or more keywords associated with the device action command pairs identified by the natural language processor component; 42. The data processing system of claim 41, comprising:
デバイスモデルに関連付けられた前記複数の電子デバイスの前記記述に基づいて、前記音声ベース照会の前記コンテキストの属性を識別するための、前記デバイスアクションカスタマイゼーション構成要素と
を備える、請求項46に記載のデータ処理システム。 the memory for holding descriptions of the plurality of electronic devices associated with device models;
47. The data of claim 46, comprising: the device action customization component for identifying attributes of the context of the speech-based query based on the description of the plurality of electronic devices associated with device models. processing system.
前記複数の電子デバイス上にインストールされた前記アプリケーションの前記記述に基づいて、前記音声ベース照会の前記コンテキストの属性を識別するための、前記デバイスアクションカスタマイゼーション構成要素と
を備える、請求項48に記載のデータ処理システム。 the memory for holding descriptions of the applications installed on the plurality of electronic devices;
49. The device action customization component of claim 48, for identifying attributes of the context of the speech-based query based on the description of the application installed on the plurality of electronic devices. data processing system.
前記デバイスアクションコマンドペアに関連付けられた前記デバイス実行可能コマンドの前記1つまたは複数のパラメータ値に基づいて、前記音声ベース照会の前記コンテキストの属性を識別するための、前記デバイスアクションカスタマイゼーション構成要素と
を備える、請求項48に記載のデータ処理システム。 said device action customization component for identifying one or more parameter values of said device executable command associated with said device action command pair;
and a device action customization component for identifying attributes of the context of the voice-based query based on the one or more parameter values of the device executable command associated with the device action command pair. 49. The data processing system of claim 48, comprising:
複数の電子デバイスによってサポートされる複数のデバイスアクションコマンドペアを含むデバイスアクションデータをメモリの中に記憶するステップであって、各デバイスアクションコマンドペアが、複数のデバイスアクションのそれぞれのデバイスアクション、および前記それぞれのデバイスアクションの遂行をトリガするための複数のデバイス実行可能コマンドのそれぞれのデバイス実行可能コマンドを含む、ステップと、
前記複数の電子デバイスによってサポートされる前記複数のデバイスアクションコマンドペアの各々に識別子をマッピングするステップと、
オーディオ信号および前記識別子を電子デバイスから受信するステップであって、前記オーディオ信号が、音声ベース照会に応答して前記電子デバイスによって取得される、ステップと、
前記オーディオ信号に関連付けられたコンテンツ、および前記識別子を使用して、前記複数のデバイスアクションコマンドペアのうちのデバイスアクションコマンドペアを識別するステップと、
前記デバイスアクションデータまたは前記デバイスアクションコマンドペアに基づいて前記音声ベース照会のコンテキストを識別するステップと、
前記音声ベース照会の前記コンテキストに基づいてデジタルコンポーネントを選択するステップと、
前記デジタルコンポーネント、および前記デバイスアクションコマンドペアに関連付けられたデバイス実行可能コマンドを、前記電子デバイスへ送信するステップであって、前記デバイス実行可能コマンドが、前記デバイスアクションコマンドペアに関連付けられた前記デバイスアクションを遂行させ、前記デジタルコンポーネントが、前記電子デバイスによって提示されるものである、ステップと
を備える方法。 A method of providing content in response to a voice-based interaction, comprising:
storing in memory device action data including a plurality of device action command pairs supported by a plurality of electronic devices, each device action command pair corresponding to a respective device action of the plurality of device actions and said comprising a respective device-executable command of a plurality of device-executable commands for triggering performance of respective device actions;
mapping an identifier to each of the plurality of device action command pairs supported by the plurality of electronic devices;
receiving an audio signal and the identifier from an electronic device, wherein the audio signal is obtained by the electronic device in response to a voice-based inquiry;
identifying a device action command pair of the plurality of device action command pairs using content associated with the audio signal and the identifier;
identifying a context for the voice-based query based on the device action data or the device action command pair;
selecting a digital component based on the context of the speech-based query;
sending the digital component and a device-executable command associated with the device-action command pair to the electronic device, wherein the device-executable command is the device action associated with the device-action command pair. and wherein said digital component is presented by said electronic device.
デバイスアクションの前記既定のシーケンスの中の、前記デバイスアクションコマンドペアに関連付けられた前記第1のデバイスアクションに後続する、1つまたは複数の第2のデバイスアクションを識別するステップと、
前記デバイスアクションに後続する前記1つまたは複数の第2のデバイスアクションに基づいて、前記音声ベース照会の前記コンテキストの属性を識別するステップと
を備える、請求項53に記載の方法。 identifying a default sequence of device actions associated with said voice-based query using a first device action associated with said device action command pair;
identifying one or more second device actions that follow the first device action associated with the device action command pair in the predetermined sequence of device actions;
54. The method of claim 53, comprising identifying attributes of the context of the speech-based query based on the one or more second device actions that follow the device action.
自然言語プロセッサ構成要素によって識別される前記デバイスアクションコマンドペアに関連付けられた前記1つまたは複数のキーワードに基づいて、前記音声ベース照会の前記コンテキストを識別するステップと
を備える、請求項53に記載の方法。 retaining one or more corresponding keywords for each device action command pair of the plurality of device action command pairs;
54. The method of claim 53, comprising identifying the context of the speech-based query based on the one or more keywords associated with the device action command pairs identified by a natural language processor component. Method.
デバイスモデルに関連付けられた前記複数の電子デバイスの前記記述に基づいて、前記音声ベース照会の前記コンテキストの属性を識別するステップと
を備える、請求項56に記載の方法。 maintaining descriptions of the plurality of electronic devices associated with device models;
57. The method of claim 56, comprising identifying attributes of the context of the speech-based query based on the descriptions of the plurality of electronic devices associated with device models.
前記複数の電子デバイス上にインストールされた前記アプリケーションの前記記述に基づいて、前記音声ベース照会の前記コンテキストの属性を識別するステップと
を備える、請求項58に記載の方法。 maintaining a description of the application installed on the plurality of electronic devices;
59. The method of claim 58, comprising identifying attributes of the context of the speech-based query based on the description of the application installed on the plurality of electronic devices.
前記デバイスアクションコマンドペアに関連付けられた前記デバイス実行可能コマンドの前記1つまたは複数のパラメータ値に基づいて、前記音声ベース照会の前記コンテキストの属性を識別するステップと
を備える、請求項58に記載の方法。 identifying one or more parameter values for the device executable command associated with the device action command pair;
59. The method of claim 58, comprising identifying attributes of the context of the voice-based query based on the one or more parameter values of the device executable command associated with the device action command pair. Method.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
JP2022133277A JP2022164744A (en) | 2018-03-07 | 2022-08-24 | System and method for voice-based initiation of custom device action |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862640007P | 2018-03-07 | 2018-03-07 | |
US62/640,007 | 2018-03-07 | ||
PCT/US2018/031454 WO2019172948A1 (en) | 2018-03-07 | 2018-05-07 | Systems and methods for voice-based initiation of custom device actions |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022133277A Division JP2022164744A (en) | 2018-03-07 | 2022-08-24 | System and method for voice-based initiation of custom device action |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2021515911A JP2021515911A (en) | 2021-06-24 |
JP7130761B2 true JP7130761B2 (en) | 2022-09-05 |
Family
ID=62386969
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2020546986A Active JP7130761B2 (en) | 2018-03-07 | 2018-05-07 | System and method for voice-based activation of custom device actions |
JP2022133277A Pending JP2022164744A (en) | 2018-03-07 | 2022-08-24 | System and method for voice-based initiation of custom device action |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022133277A Pending JP2022164744A (en) | 2018-03-07 | 2022-08-24 | System and method for voice-based initiation of custom device action |
Country Status (6)
Country | Link |
---|---|
US (2) | US11314481B2 (en) |
EP (1) | EP3596729A1 (en) |
JP (2) | JP7130761B2 (en) |
KR (2) | KR102520068B1 (en) |
CN (2) | CN110574105B (en) |
WO (1) | WO2019172948A1 (en) |
Families Citing this family (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN112020707A (en) * | 2018-01-05 | 2020-12-01 | 国立大学法人九州工业大学 | Tag adding device, tag adding method, and program |
US11127395B1 (en) * | 2018-05-23 | 2021-09-21 | Amazon Technologies, Inc. | Device-specific skill processing |
KR20200055819A (en) * | 2018-11-08 | 2020-05-22 | 현대자동차주식회사 | Service robot and method for operating thereof |
KR20200098025A (en) * | 2019-02-11 | 2020-08-20 | 삼성전자주식회사 | Electronic apparatus and control method thereof |
KR20200109140A (en) * | 2019-03-12 | 2020-09-22 | 삼성전자주식회사 | Electronic apparatus and controlling method thereof |
CN112164400A (en) * | 2020-09-18 | 2021-01-01 | 广州小鹏汽车科技有限公司 | Voice interaction method, server and computer-readable storage medium |
KR20220118766A (en) * | 2021-02-19 | 2022-08-26 | 삼성전자주식회사 | Method and mobile device for processing command based on utterance input |
CN112540545B (en) * | 2021-02-22 | 2021-04-30 | 武汉世聪智能科技有限公司 | Intelligent equipment control method and system based on multiple intelligent systems |
US11915708B2 (en) * | 2021-03-18 | 2024-02-27 | Samsung Electronics Co., Ltd. | Methods and systems for invoking a user-intended internet of things (IoT) device from a plurality of IoT devices |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2001014134A (en) | 1999-05-21 | 2001-01-19 | Canon Inc | Network system, and server and device for network system |
Family Cites Families (52)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DE69712485T2 (en) | 1997-10-23 | 2002-12-12 | Sony Int Europe Gmbh | Voice interface for a home network |
US8498871B2 (en) * | 2001-11-27 | 2013-07-30 | Advanced Voice Recognition Systems, Inc. | Dynamic speech recognition and transcription among users having heterogeneous protocols |
US20050234779A1 (en) * | 2003-11-17 | 2005-10-20 | Leo Chiu | System for dynamic AD selection and placement within a voice application accessed through an electronic information pace |
EP1922717A4 (en) * | 2005-08-09 | 2011-03-23 | Mobile Voice Control Llc | Use of multiple speech recognition software instances |
US7818176B2 (en) * | 2007-02-06 | 2010-10-19 | Voicebox Technologies, Inc. | System and method for selecting and presenting advertisements based on natural language processing of voice-based input |
US8538757B2 (en) * | 2007-05-17 | 2013-09-17 | Redstart Systems, Inc. | System and method of a list commands utility for a speech recognition command system |
US8745213B2 (en) | 2008-12-19 | 2014-06-03 | Openpeak Inc. | Managed services platform and method of operation of same |
US10264138B2 (en) * | 2009-01-28 | 2019-04-16 | Headwater Research Llc | Mobile device and service management |
US20110067059A1 (en) * | 2009-09-15 | 2011-03-17 | At&T Intellectual Property I, L.P. | Media control |
US20110271210A1 (en) * | 2010-04-30 | 2011-11-03 | American Teleconferncing Services Ltd. | Conferencing Application Store |
US8805683B1 (en) * | 2012-02-24 | 2014-08-12 | Google Inc. | Real-time audio recognition protocol |
TWI453603B (en) | 2010-06-30 | 2014-09-21 | Ibm | Platform independent information handling system, communication method, and computer program product thereof |
US8787987B2 (en) * | 2010-10-19 | 2014-07-22 | General Motors Llc | Configuring of vehicle communications modules |
US10069781B2 (en) | 2015-09-29 | 2018-09-04 | Theatro Labs, Inc. | Observation platform using structured communications with external devices and systems |
US9847083B2 (en) * | 2011-11-17 | 2017-12-19 | Universal Electronics Inc. | System and method for voice actuated configuration of a controlling device |
KR101972955B1 (en) * | 2012-07-03 | 2019-04-26 | 삼성전자 주식회사 | Method and apparatus for connecting service between user devices using voice |
US20140025230A1 (en) | 2012-07-17 | 2014-01-23 | Elwha LLC, a limited liability company of the State of Delaware | Unmanned device interaction methods and systems |
US20140024999A1 (en) | 2012-07-17 | 2014-01-23 | Elwha LLC, a limited liability company of the State of Delaware | Unmanned device utilization methods and systems |
US8953757B2 (en) * | 2012-08-06 | 2015-02-10 | Angel.Com Incorporated | Preloading contextual information for applications using a conversation assistant |
US9196250B2 (en) | 2012-11-16 | 2015-11-24 | 2236008 Ontario Inc. | Application services interface to ASR |
US9172747B2 (en) * | 2013-02-25 | 2015-10-27 | Artificial Solutions Iberia SL | System and methods for virtual assistant networks |
US9397836B2 (en) * | 2014-08-11 | 2016-07-19 | Fisher-Rosemount Systems, Inc. | Securing devices to process control systems |
US9189196B2 (en) * | 2013-03-14 | 2015-11-17 | Google Inc. | Compartmentalized self registration of external devices |
US9462663B2 (en) * | 2013-05-28 | 2016-10-04 | Abl Ip Holding Llc | Interactive user interface functionality for lighting devices or system |
US9443527B1 (en) * | 2013-09-27 | 2016-09-13 | Amazon Technologies, Inc. | Speech recognition capability generation and control |
US9698999B2 (en) * | 2013-12-02 | 2017-07-04 | Amazon Technologies, Inc. | Natural language control of secondary device |
JP6543460B2 (en) * | 2013-12-18 | 2019-07-10 | ハーマン インターナショナル インダストリーズ インコーポレイテッド | Voice recognition inquiry response system |
US9823811B2 (en) | 2013-12-31 | 2017-11-21 | Next It Corporation | Virtual assistant team identification |
US9966065B2 (en) * | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US10448307B2 (en) * | 2014-07-15 | 2019-10-15 | Comcast Cable Communications, Llc | Systems and methods for managing network devices |
US9318107B1 (en) | 2014-10-09 | 2016-04-19 | Google Inc. | Hotword detection on multiple devices |
US9741344B2 (en) * | 2014-10-20 | 2017-08-22 | Vocalzoom Systems Ltd. | System and method for operating devices using voice commands |
KR102277259B1 (en) * | 2014-11-26 | 2021-07-14 | 엘지전자 주식회사 | Device control system, digital device and method of controlling the same |
US10147421B2 (en) | 2014-12-16 | 2018-12-04 | Microcoft Technology Licensing, Llc | Digital assistant voice input integration |
US9552816B2 (en) * | 2014-12-19 | 2017-01-24 | Amazon Technologies, Inc. | Application focus in speech-based systems |
US9811312B2 (en) | 2014-12-22 | 2017-11-07 | Intel Corporation | Connected device voice command support |
US10509829B2 (en) * | 2015-01-21 | 2019-12-17 | Microsoft Technology Licensing, Llc | Contextual search using natural language |
US9947364B2 (en) | 2015-09-16 | 2018-04-17 | Google Llc | Enhancing audio using multiple recording devices |
US20170092278A1 (en) | 2015-09-30 | 2017-03-30 | Apple Inc. | Speaker recognition |
US9747926B2 (en) | 2015-10-16 | 2017-08-29 | Google Inc. | Hotword recognition |
US9928840B2 (en) | 2015-10-16 | 2018-03-27 | Google Llc | Hotword recognition |
US9653075B1 (en) | 2015-11-06 | 2017-05-16 | Google Inc. | Voice commands across devices |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10743101B2 (en) | 2016-02-22 | 2020-08-11 | Sonos, Inc. | Content mixing |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
US10958695B2 (en) | 2016-06-21 | 2021-03-23 | Google Llc | Methods, systems, and media for recommending content based on network conditions |
US9972320B2 (en) | 2016-08-24 | 2018-05-15 | Google Llc | Hotword detection on multiple devices |
US10528977B1 (en) * | 2016-09-22 | 2020-01-07 | Amazon Technologies, Inc. | Generating dynamic audio content for delivery to audio devices |
US10096319B1 (en) * | 2017-03-13 | 2018-10-09 | Amazon Technologies, Inc. | Voice-based determination of physical and emotional characteristics of users |
CN107507614B (en) * | 2017-07-28 | 2018-12-21 | 北京小蓦机器人技术有限公司 | Method, equipment, system and the storage medium of natural language instructions are executed in conjunction with UI |
US11450314B2 (en) * | 2017-10-03 | 2022-09-20 | Google Llc | Voice user interface shortcuts for an assistant application |
CN107919129A (en) * | 2017-11-15 | 2018-04-17 | 百度在线网络技术（北京）有限公司 | Method and apparatus for controlling the page |
-
2018
- 2018-05-07 KR KR1020207028683A patent/KR102520068B1/en active IP Right Grant
- 2018-05-07 EP EP18727937.7A patent/EP3596729A1/en not_active Ceased
- 2018-05-07 CN CN201880028784.5A patent/CN110574105B/en active Active
- 2018-05-07 WO PCT/US2018/031454 patent/WO2019172948A1/en unknown
- 2018-05-07 US US15/781,787 patent/US11314481B2/en active Active
- 2018-05-07 KR KR1020237011704A patent/KR20230051619A/en not_active Application Discontinuation
- 2018-05-07 CN CN202410003320.6A patent/CN117877477A/en active Pending
- 2018-05-07 JP JP2020546986A patent/JP7130761B2/en active Active
-
2022
- 2022-04-25 US US17/728,614 patent/US20220244910A1/en active Pending
- 2022-08-24 JP JP2022133277A patent/JP2022164744A/en active Pending
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2001014134A (en) | 1999-05-21 | 2001-01-19 | Canon Inc | Network system, and server and device for network system |
Also Published As
Publication number | Publication date |
---|---|
JP2022164744A (en) | 2022-10-27 |
CN110574105A (en) | 2019-12-13 |
JP2021515911A (en) | 2021-06-24 |
US11314481B2 (en) | 2022-04-26 |
EP3596729A1 (en) | 2020-01-22 |
KR20230051619A (en) | 2023-04-18 |
KR20200128725A (en) | 2020-11-16 |
US20220244910A1 (en) | 2022-08-04 |
US20210026593A1 (en) | 2021-01-28 |
KR102520068B1 (en) | 2023-04-10 |
WO2019172948A1 (en) | 2019-09-12 |
CN117877477A (en) | 2024-04-12 |
CN110574105B (en) | 2024-01-23 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7130761B2 (en) | System and method for voice-based activation of custom device actions | |
US11183182B2 (en) | Systems and methods for voice-based initiation of custom device actions | |
KR102389331B1 (en) | Synchronize access control between computing devices | |
US20150242420A1 (en) | Location-Based Searching | |
RU2620999C2 (en) | Compressed spatial contextual information audio presentation | |
EP3610378B1 (en) | Immersive web-based simulator for digital assistant-based applications | |
CN112351350B (en) | Content display method, device, system, equipment and storage medium | |
CN107924403B (en) | Query composition system | |
CN109964457B (en) | Uniform resource identifier and image sharing for contextual information display | |
US11785094B2 (en) | Secure content delivery computer system | |
AU2021329831A1 (en) | Secure content delivery computer system | |
JP2019175290A (en) | Information processing system, information processing device, server, information processing method, and program |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20201106 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20211130 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20211213 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20220309 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20220725 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20220824 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7130761Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |