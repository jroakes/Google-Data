US9866955B2 - Enhancement of intelligibility in noisy environment - Google Patents
Enhancement of intelligibility in noisy environment Download PDFInfo
- Publication number
- US9866955B2 US9866955B2 US14/466,565 US201414466565A US9866955B2 US 9866955 B2 US9866955 B2 US 9866955B2 US 201414466565 A US201414466565 A US 201414466565A US 9866955 B2 US9866955 B2 US 9866955B2
- Authority
- US
- United States
- Prior art keywords
- features
- signal
- sequence
- noise
- rendered
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04R—LOUDSPEAKERS, MICROPHONES, GRAMOPHONE PICK-UPS OR LIKE ACOUSTIC ELECTROMECHANICAL TRANSDUCERS; DEAF-AID SETS; PUBLIC ADDRESS SYSTEMS
- H04R3/00—Circuits for transducers, loudspeakers or microphones
- H04R3/002—Damping circuit arrangements for transducers, e.g. motional feedback circuits
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/14—Speech classification or search using statistical models, e.g. Hidden Markov Models [HMMs]
- G10L15/142—Hidden Markov Models [HMMs]
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/20—Speech recognition techniques specially adapted for robustness in adverse environments, e.g. in noise, of stress induced speech
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0316—Speech enhancement, e.g. noise reduction or echo cancellation by changing the amplitude
- G10L21/0364—Speech enhancement, e.g. noise reduction or echo cancellation by changing the amplitude for improving intelligibility
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/226—Procedures used during a speech recognition process, e.g. man-machine dialogue using non-speech characteristics
- G10L2015/227—Procedures used during a speech recognition process, e.g. man-machine dialogue using non-speech characteristics of the speaker; Human-factor methodology
Definitions
- a user may receive a call with a mobile phone in a train station, a cafe, a car, a bus, or in a busy street and not understand a word the other person is saying.
- a user may be in an airport or train station and not understand the announcements, or the television may be on in a noisy environment such as a cafe and or an airport and the user is unable to understand what is being said.
- a user in a conference room may be trying to use the speaker phone but the room is noisy and it is difficult to understand what the other party is saying.
- the problem is particularly severe when the speaking party is only vaguely aware of the noisy environment that the listener is in.
- the present disclosure generally relates to methods and systems for processing audio signals. More specifically, aspects of the present disclosure relate to enhancing the intelligibility of speech in noisy environments.
- One embodiment of the present disclosure relates to a method for enhancing intelligibility of a speech signal rendered in a noisy environment, the method comprising: adapting a sequence of features for a signal rendered in a noisy environment to approximate the sequence of features for the signal rendered in a noise-free environment; and imposing a constraint on each of the features for the signal rendered in the noisy environment, wherein a spectrum of the signal rendered in the noisy environment is a compressed version of the signal rendered in the noise-free environment.
- the sequence of features for the signal rendered in the noise-free environment is a sequence of spectral features
- the method for enhancing intelligibility of a speech signal further comprises using the sequence of spectral features for the signal rendered in the noise-free environment as a target for spectral features for the signal rendered in the noisy environment.
- the method for enhancing intelligibility of a speech signal further comprises adjusting a fixed gain of each frequency band of the signal to maximize intelligibility given the environmental noise, subject to a power constraint.
- the method for enhancing intelligibility of a speech signal further comprises defining a fidelity measure to approximate the sequence of features for the signal rendered in the noisy environment to correspond with the sequence of features for the signal rendered in the noise-free environment.
- Another embodiment of the present disclosure relates to a system for enhancing intelligibility of a speech signal rendered in a noisy environment, the system comprising one or more processors, and a non-transitory computer-readable medium coupled to the one or more processors having instructions stored thereon that, when executed by the one or more processors, cause the one or more processors to perform operations comprising: adapting a sequence of features for a signal rendered in a noisy environment to approximate the sequence of features for the signal rendered in a noise-free environment; and imposing a constraint on each of the features for the signal rendered in the noisy environment, wherein a spectrum of the signal rendered in the noisy environment is a compressed version of the signal rendered in the noise-free environment.
- the sequence of features for the signal rendered in the noise-free environment is a sequence of spectral features
- the one or more processors in the system for enhancing intelligibility of a speech signal are caused to perform further operations comprising: using the sequence of spectral features for the signal rendered in the noise-free environment as a target for spectral features for the signal rendered in the noisy environment.
- the one or more processors in the system for enhancing intelligibility of a speech signal are caused to perform further operations comprising: adjusting a fixed gain of each frequency band of the signal to maximize intelligibility given the environmental noise, subject to a power constraint.
- the one or more processors in the system for enhancing intelligibility of a speech signal are caused to perform further operations comprising: defining a fidelity measure to approximate the sequence of features for the signal rendered in the noisy environment to correspond with the sequence of features for the signal rendered in the noise-free environment.
- Still another embodiment of the present disclosure relates to a method for enhancing intelligibility of a speech signal rendered in a noisy environment, the method comprising: adapting a sequence of features for a signal rendered in a noisy environment to approximate the sequence of features for the signal rendered in a noise-free environment; and imposing a constraint on each of the features for the signal rendered in the noisy environment, wherein the sequence of features for the signal rendered in the noisy environment is adapted by adjusting a fixed gain of each frequency band of the signal to maximize intelligibility.
- the methods and systems described herein may optionally include one or more of the following additional features: a spectrum of the signal rendered in the noisy environment is a compressed version of the signal rendered in the noise-free environment; the compression is optimized for each frequency band of the signal over time; the sequence of features are discrete log spectra or discrete linear spectra; a change in the sequence of features for the signal rendered in the noise-free environment corresponds to a change in the sequence of features for the signal rendered in the noisy environment; and/or the fixed gain of each frequency band of the signal rendered in the noisy environment is adjusted based on detected background noise in the noisy environment.
- Embodiments of some or all of the processor and memory systems disclosed herein may also be configured to perform some or all of the method embodiments disclosed above.
- Embodiments of some or all of the methods disclosed above may also be represented as instructions embodied on transitory or non-transitory processor-readable storage media such as optical or magnetic memory or represented as a propagated signal provided to a processor or data processing device via a communication network such as an Internet or telephone connection.
- FIG. 1 is a graphical representation illustrating example behavior between a feature of an audio signal for no-noise rendering and an observed feature of the signal in a frequency bin of a discrete log spectrum according to one or more embodiments described herein.
- FIG. 2 is a graphical representation illustrating an example mapping of a probability distribution of spectral amplitude onto a uniform distribution using a compander according to one or more embodiments described herein.
- FIG. 3 is a graphical representation illustrating an example of a single channel solution for an intelligibility enhancement method according to one or more embodiments described herein.
- FIG. 4 is a graphical representation illustrating another example of a single channel solution for an intelligibility enhancement method according to one or more embodiments described herein.
- FIG. 5 is a flowchart illustrating an example method for enhancing the intelligibility of an audio signal rendered in a noisy environment according to one or more embodiments described herein.
- FIG. 6 is a block diagram illustrating an example computing device arranged for enhancing the intelligibility of an audio signal rendered in a noisy environment according to one or more embodiments described herein.
- Embodiments of the present disclosure relate to enhancing the intelligibility of an audio (e.g., speech) signal rendered (e.g., played out) in a noisy environment, subject to a constraint on the power of the rendered signal.
- a quantitative measure of intelligibility is the mean probability of decoding of the message correctly.
- the methods and systems presented simplify the procedure by approximating the maximization of the decoding probability with the maximization of the similarity of the spectral dynamics of the noisy speech to the spectral dynamics of the corresponding noise-free speech.
- One or more embodiments relates to intelligibility enhancement procedures based on this principle, all of which have low computational cost and require little delay, thus facilitating real-time implementation. Preliminary experimental results confirm the effectiveness of the approach described herein.
- dX represent a change in the spectrum of speech spoken in the clean signal.
- dY be the change in the spectrum of the noisy signal as observed by the listener.
- the methods and systems described in the present disclosure aim to modify the rendered speech such that the resulting noisy observed speech minimizes this measure. Further, in accordance with at least one embodiment, the approach described herein aims to do this under a constraint on the energy or gain (since otherwise the solution would be to play out the signal very loud). For any enhancement strategy (e.g., adaptively changing the signal coloring, rewording the message, etc.) this leads to a mathematical problem, as further presented below.
- the spectrum of the signal rendered in noise may be a compressed version of the signal rendered in a noise-free environment, with the compressor being optimized continuously for each frequency band over time.
- a fixed gain of each frequency band may be optimally adjusted to maximize the intelligibility given the environmental noise, subject to an overall power constraint.
- the methods provided adapt to the noise spectrum and do so instantly. Additionally, the methods may be implemented with very low complexity and very low time delay. As such, the methods and systems described herein may be implemented, for example, in a mobile phone.
- Human-to-human communication conveys a message from the brain of one person to that of another person.
- the message is considered to be a real-valued random variable t and the conveyance of the message is modeled as a Markov chain (it should be noted, however, that similar results can be obtained if the message is considered to be a discrete-valued random variable).
- the message t (note that random variables are denoted herein by bold symbols) may be converted to a sequence of words and associated prosody, and this sequence in turn may be converted to a sequence of spectra which, in turn, may be converted to an acoustic signal.
- the acoustic signal is contaminated by acoustic noise, and is then interpreted by the human auditory system as a sequence of spectra, a sequence of words and, finally a received message ⁇ .
- this viewpoint naturally leads to practical methods for the enhancement of speech.
- the signal features e.g., a sequence of spectra or cepstra
- the signal features may be described as a real-valued random vector X, the default speech production rules by P, and the adjustment of these rules by R (the rules are deterministic).
- the conditional density of the sequence of spectra can then be written as p(X
- a probabilistic decoding model can be defined similarly to the encoding model. Let V denote the decoding rules and let Y denote a random vector of noisy-speech features. The distribution of decoding the message as ⁇ can then be written as p( ⁇
- the decoded message depends on the original message, the encoding and decoding rules, and the environmental noise. Exploiting the Markov model of the communication process, the following may be written: p ( ⁇
- t,N,P,R,V ) ⁇ p ( ⁇
- Equation (3) and (4) show that, for the hit-or-miss criterion, the message fidelity now correspond to the mean probability of accurate message decoding.
- the integration in equation (4) may be approximated by a time-average over messages. It should be noted that ergodicity is reasonable for both single-talker and multi-talker scenarios.
- equation (4) may be rewritten for the case that adaptations to the noisy environment are made on a signal ⁇ hacek over (X) ⁇ rendered under noise-free assumptions.
- Y is a deterministic function of X and N may be made.
- equation (5) can be narrowed down so that it applies to modifications to a rendering (e.g., a signal) intended for noise-free conditions:
- ⁇ hacek over (X) ⁇ , R) is generally a deterministic mapping, eliminating the integral over X and replacing (with abuse of notation) Y(X, N) with Y( ⁇ hacek over (X) ⁇ , N, R).
- the noisy-speech features Y for the message are a sequence of cepstra, and so-called delta-cepstra, and delta-delta cepstra (although so-called mel cepstra are generally used to reflect the frequency resolution of the auditory system, this level of specificity is omitted for purposes of brevity).
- the delta cepstra are the differences between successive updates of the cepstra in time
- the delta delta cepstra are the differences of the differences between successive updates.
- the emission probability of the HMMs e.g., the distribution of the observations given the state
- the state sequence is held fixed when the rules R are adapted to maximize equation (6).
- one objective of the method described herein is to adjust the features X such that the noisy features Y maximize the product of the emission probabilities for the sequence of samples. It should be noted that the optimization can be performed even for signals rendered in a noise-free environment, leading to an optimized signal that differs from the basic noise-free rendering by either a human or a machine.
- the feature vector sequence ⁇ hacek over (X) ⁇ of the noise-free rendering provides good intelligibility in a noise-free environment.
- a simplified approach to intelligibility enhancement can use the features of the noise-free rendering ⁇ hacek over (X) ⁇ as a target for the noisy features Y obtained with the modified features X.
- a homoscedastic HMM it is natural to use a squared error criterion weight for the feature vector with the inverse of the covariance matrix. While such a simplified approach may be more restrictive than the method based directly on equation (6), as it cannot exploit the shape of the emission probability, this simplified method does account for the choice of the features used (e.g., generally cepstra, delta cepstra, and delta delta cepstra).
- any adjustment to the signal modification process should be subject to a constraint on the gain or on the signal power.
- a practical objective then is to adapt the sequence of absolute, delta, and delta-delta cepstra vectors for the noisy signal, Y, to approximate the same sequence for the signal rendered in a noise-free environment, ⁇ hacek over (X) ⁇ , by modifying X, subject to a power or gain constraint on X.
- the cepstra may be subjected to cepstral mean normalization.
- dY d ⁇ hacek over (X) ⁇ (7)
- Y are the noisy-speech features
- ⁇ hacek over (X) ⁇ are the features of speech rendered for a noise-free condition.
- Equation (7) implies that any change in the features as rendered in a noise free environment corresponds to a similar change in the noisy-speech features if enhancement is present.
- the delta (and delta-delta) cepstra of the adapted noisy-speech features are identical to the noise-free-rendered-speech features. Since discrete log spectra are a unitary transform of the cepstra, this also means that changes in the log spectra are also identical in the adapted noisy-speech features and the noise-free-rendered-speech features.
- the algorithms described below perform nonlinear mappings on the features: they map a set of features produced under noise-free conditions into a set of features that are effective under noisy conditions. Because of the nonlinearity of these mappings, it is particular importance that the features used reflect the operation of the human auditory system properly.
- the human auditory system can be modeled as a filter bank (e.g., a resolution that decreases with increasing frequency followed by half-wave rectification and an adaptive gain). If any of the algorithms described herein affect the individual filters of the auditory filter bank separately, then their effect on the auditory system is straightforward to evaluate. For this reason, one or more embodiments consider a discrete mel scale or ERB (equivalent rectangular bandwidth) scale log power spectrum as the basic feature set (as with cepstra in the above description, in the present description omits mel and ERB for brevity).
- a discrete mel scale or ERB (equivalent rectangular bandwidth) scale log power spectrum as the basic feature set (as with cepstra in the above description, in the present description omits mel and ERB for brevity).
- cepstra are commonly used in automatic speech recognition.
- the cepstra and the log spectrum form unitary transforms of each other.
- the cepstra are the coefficients of a cosine-basis expansion of the log spectrum. Omitting the higher-order cepstras is equivalent to smoothing the log spectra, and this motivates the use of cepstra for automatic speech recognition.
- a nonlinear mapping on a single cepstrum coefficient affects all filters of the filter bank of the human auditory system. This makes it difficult to evaluate the impact of such a mapping. This reconfirms the choice of discrete log spectra (or discrete linear spectra) for the feature representation, in accordance with the methods and systems described herein.
- FIG. 1 illustrates example relations between the feature for no-noise rendering, ⁇ hacek over (X) ⁇ •,i and the observed feature Y •,i in frequency bin i of a discrete log spectrum.
- the horizontal axis of the graphical representation 100 shows the value of ⁇ hacek over (X) ⁇ •,i and the vertical axis shows Y •,i .
- the dashed curve ( 120 ) shows the case of a noisy environment without any enhancement for a noise level N •,i in the band i.
- the dynamics of the signal are inaudible in channel i for ⁇ hacek over (X) ⁇ •,i ⁇ hacek over (X) ⁇ (0),i .
- a straightforward technique to make the signal more intelligible is to multiply the signal by a gain ⁇ i .
- the features then become audible for ⁇ hacek over (X) ⁇ •,i ⁇ hacek over (X) ⁇ (0),i ⁇ log( ⁇ i ), which is illustrated by the dash-dotted curve ( 130 ).
- a natural constraint is to bound the overall rendered signal power.
- the need for increased loudness is strongest for frequency bins where speech has a low power level relative to the noise level.
- biases may be applied to the individual frequency bins. Such an approach is described in greater detail below.
- the calculus of variations may be used to find the optimal rules R in Y( ⁇ hacek over (X) ⁇ , N, R). It may be assumed that the channels can be treated independently, which means that for a channel i the noisy features Y •,i depend only on the variables in that channel and it can be written Y •,i ( ⁇ hacek over (X) ⁇ •,i , N •,i , R). The actual discrete log power spectrum rendered can be computed from the results as X •,i ⁇ log( e Y •,i ⁇ e N •,i ) (10) since the environmental noise and the rendered signal are independent at a signal level. In accordance with at least one embodiment, the case where the environmental noise is stationary may be considered, which means that the discrete noise spectrum n can be treated as a deterministic parameter in the present context (in contrast the random variable x varies across signal blocks).
- mapping is introduced: f: ⁇ .
- ⁇ hacek over (x) ⁇ •,i f( ⁇ hacek over (X) ⁇ •,i ).
- R and P the rule symbols R and P where this is obvious from the context.
- Y •,i ( ⁇ hacek over (X) ⁇ •,i ,N •,i ,R) may be reduced to y( ⁇ hacek over (x) ⁇ , n) after the mapping.
- the mapping is not compensated for. Instead, it is assumed that the measure is appropriate for the mapped domain.
- mapping f a set of single-channel solutions obtained under different boundary conditions and constraints.
- mapping f is performed to facilitate analytic solutions.
- the mapping f is injective so that it can be inverted and selected so that the fidelity criterion (equation (9)), when specified in the mapped domain, is still meaningful.
- Laplacian distributions of the spectral amplitude are often reasonable. Such a distribution can be mapped onto a uniform distribution using the compander
- FIG. 2 is a graphical representation 200 illustrating an example of the mapping.
- mapping (equation (15)) progressively down-weights the importance of the criterion for high and low values of ⁇ hacek over (X) ⁇ , which is desirable.
- errors will tend to be concentrated at high and low values of ⁇ hacek over (X) ⁇ .
- mapping themes described above lead to the following additional example solutions.
- Example Solutions The following provides a number of example analytic solutions.
- the first four example solutions described below are based on the assumption of a uniform distribution, which can be combined with the compander (equation (15)).
- the fifth example solution is found in the absolute spectrum domain.
- the problem may be defined as: find the solution for equation (37) (presented below) on [0, 1] with
- b is an adjustable parameter that determines the severity of the low-power enhancement. It can be used to bias the individual channels.
- FIG. 3 is a graphical representation 300 illustrating an example of the relation of equation (22) in the log spectral domain ⁇ hacek over (X) ⁇ : the solution is a noise-adaptive compander.
- the features of the rendered features X can be computed with equation (10).
- the problem may be defined as: find the solution for equation (37) (presented below) on [0, a], 0 ⁇ a ⁇ 1 with
- b 0 and b 1 are adjustable parameters that determine the strength of the low-power enhancement and the desired gain, respectively.
- the final solution may be determined as
- y ( x ⁇ ) x ⁇ - b 1 + d + b 1 - a - ( n + b 0 + b 1 ) ⁇ e ⁇ ⁇ ⁇ a e - ⁇ ⁇ ⁇ a - e ⁇ ⁇ ⁇ a ⁇ e - ⁇ ⁇ ⁇ x ⁇ + ( n + b 1 - d + b 1 - a - ( n + b 0 + b 1 ) ⁇ e ⁇ ⁇ a e - ⁇ ⁇ ⁇ a - e ⁇ ⁇ ⁇ a ) ⁇ e ⁇ ⁇ ⁇ x ⁇ ( 32 )
- FIG. 4 is a graphical representation illustrating an example of the relation of equation (32) in the log spectral domain (e.g., after applying the inverse mapping f ⁇ 1 to y and ⁇ hacek over (x) ⁇ ).
- the features of the rendered features X may be computed with equation (10).
- a speech intelligibility enhancement method and system based on the notion that for any channel the condition
- the signal power can be minimized subject to a constraint on the fidelity (e.g., the sum of the probabilities that the condition holds):
- the probability distribution p( ⁇ hacek over (X) ⁇ •,i ) is estimated for each frequency bin i.
- the probability distribution can be estimated by approximating the probability distribution over either an utterance or over a database.
- the distribution may be described, for example, using a histogram or by fitting a particular distribution (e.g., the mean absolute value may be determined and used to specify a Laplacian distribution).
- a desired fidelity (r desired ) is defined together with an error threshold ( ⁇ r threshold ).
- step V d and a step ⁇ are defined.
- step V d and step ⁇ should be defined to be sufficiently small for precision and sufficiently large for quick convergence.
- V •,i are set equal to V 0 , where V 0 is a sufficiently small value.
- the Lagrangian increase is computed.
- a fidelity measure is computed.
- the fidelity measure r may be computed from equation (63), which is described above.
- a setup with 32 bands linearly-spaced on a Mel scale in the range [100, 7500] Hz is used, corresponding to the spectral range of the signals in the development database.
- the sampling frequency is set to 16 kHz.
- An analysis frame length of 12 milliseconds (ms) and an update length of 10 ms are used.
- the analysis window is tapered in the overlap regions with a Harming window. Zero-padding to 2048 samples is performed.
- SSN speech-shaped
- BBL multi-speaker babble
- PSD noise power spectral density
- the reference method (PD) is set to operate at a system delay of one frame, where the frame length is 32 ms and the update length is 16 ms.
- the SDP method modifies the SNR, the power of the natural speech signal is equalized to the output power of the (SDP) modified signal to ensure fair comparison.
- the reference system output is obtained from processing the re-scaled natural speech signal.
- the subjective recognition scores are compared in a per-set basis in Table II, below.
- the scores are normalized for each subject by their best per-set recognition score.
- the significance analysis of the normalized scores is shown in Table III, using the conservative Wilcoxon signed rank test. The results indicate a significant improvement in intelligibility over natural speech (Nat.) and the speech processed by the reference method (SSN condition only) despite the low number of subjects.
- the methods and systems of the present disclosure demonstrate that speech intelligibility can be interpreted as the probability of being able to decode the original message correctly.
- the techniques provided herein approximate this probability by a distance from features describing the dynamics of the features for a rendering in a noise-free environment.
- the resulting methods and systems can be fine-tuned by overstating or understating the noise in a particular frequency bin.
- the resulting system provides significant enhancement of speech intelligibility.
- FIG. 6 is a block diagram illustrating an example computing device 600 that is arranged for enhancing the intelligibility of an audio (e.g., speech) signal rendered in a noisy environment in accordance with one or more embodiments of the present disclosure.
- computing device 600 may be configured to iteratively run an intelligibility enhancement algorithm performs nonlinear mappings on features of the noisy signal and the signal under noise-free conditions, as described above.
- computing device 600 typically includes one or more processors 610 and system memory 620 .
- a memory bus 630 may be used for communicating between the processor 610 and the system memory 620 .
- processor 610 can be of any type including but not limited to a microprocessor ( ⁇ P), a microcontroller ( ⁇ C), a digital signal processor (DSP), or any combination thereof.
- Processor 610 may include one or more levels of caching, such as a level one cache 611 and a level two cache 612 , a processor core 613 , and registers 614 .
- the processor core 613 may include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof.
- a memory controller 615 can also be used with the processor 610 , or in some embodiments the memory controller 615 can be an internal part of the processor 610 .
- system memory 620 can be of any type including but not limited to volatile memory (e.g., RAM), non-volatile memory (e.g., ROM, flash memory, etc.) or any combination thereof.
- System memory 620 typically includes an operating system 621 , one or more applications 622 , and program data 624 .
- application 622 includes an intelligibility enhancement algorithm 623 that is configured to map a set of signal (spectral) features produced under noise-free conditions into a set of signal (spectral) features that are effective under noisy conditions.
- the intelligibility enhancement algorithm 623 may be configured to utilize features that reflect the operation of the human auditory system. A range of constraints may also be imposed on the feature sets, either individually or globally.
- Program Data 624 may include audio data 625 that is useful for enhancing the intelligibility of a speech signal rendered in a noisy environment.
- application 622 can be arranged to operate with program data 624 on an operating system 621 such that the intelligibility enhancement algorithm 623 uses the audio data 625 to approximate the maximization of the decoding probability with the maximization of the similarity of the spectral dynamics of the noisy speech to the spectral dynamics of the corresponding noise free speech, as described above.
- Computing device 600 can have additional features and/or functionality, and additional interfaces to facilitate communications between the basic configuration 601 and any required devices and interfaces.
- a bus/interface controller 640 can be used to facilitate communications between the basic configuration 601 and one or more data storage devices 650 via a storage interface bus 641 .
- the data storage devices 650 can be removable storage devices 651 , non-removable storage devices 652 , or any combination thereof. Examples of removable storage and non-removable storage devices include magnetic disk devices such as flexible disk drives and hard-disk drives (HDD), optical disk drives such as compact disk (CD) drives or digital versatile disk (DVD) drives, solid state drives (SSD), tape drives and the like.
- Example computer storage media can include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, and/or other data.
- Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 600 . Any such computer storage media can be part of computing device 600 .
- Computing device 600 can also include an interface bus 642 for facilitating communication from various interface devices (e.g., output interfaces, peripheral interfaces, communication interfaces, etc.) to the basic configuration 601 via the bus/interface controller 640 .
- Example output devices 660 include a graphics processing unit 661 and an audio processing unit 662 , either or both of which can be configured to communicate to various external devices such as a display or speakers via one or more A/V ports 663 .
- Example peripheral interfaces 670 include a serial interface controller 671 or a parallel interface controller 672 , which can be configured to communicate with external devices such as input devices (e.g., keyboard, mouse, pen, voice input device, touch input device, etc.) or other peripheral devices (e.g., printer, scanner, etc.) via one or more I/O ports 673 .
- input devices e.g., keyboard, mouse, pen, voice input device, touch input device, etc.
- other peripheral devices e.g., printer, scanner, etc.
- An example communication device 680 includes a network controller 681 , which can be arranged to facilitate communications with one or more other computing devices 690 over a network communication (not shown) via one or more communication ports 682 .
- the communication connection is one example of a communication media.
- Communication media may typically be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media.
- a “modulated data signal” can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.
- communication media can include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared (IR) and other wireless media.
- RF radio frequency
- IR infrared
- computer readable media can include both storage media and communication media.
- Computing device 600 can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
- a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
- PDA personal data assistant
- Computing device 600 can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.
- ASICs Application Specific Integrated Circuits
- FPGAs Field Programmable Gate Arrays
- DSPs digital signal processors
- ASICs Application Specific Integrated Circuits
- FPGAs Field Programmable Gate Arrays
- DSPs digital signal processors
- some aspects of the embodiments described herein, in whole or in part, can be equivalently implemented in integrated circuits, as one or more computer programs running on one or more computers (e.g., as one or more programs running on one or more computer systems), as one or more programs running on one or more processors (e.g., as one or more programs running on one or more microprocessors), as firmware, or as virtually any combination thereof.
- processors e.g., as one or more programs running on one or more microprocessors
- firmware e.g., as one or more programs running on one or more microprocessors
- designing the circuitry and/or writing the code for the software and/or firmware would be well within the skill of one of skilled in the art in light of the present disclosure.
- Examples of a signal-bearing medium include, but are not limited to, the following: a recordable-type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission-type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).
- a recordable-type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.
- a transmission-type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).
- a typical data processing system generally includes one or more of a system unit housing, a video display device, a memory such as volatile and non-volatile memory, processors such as microprocessors and digital signal processors, computational entities such as operating systems, drivers, graphical user interfaces, and applications programs, one or more interaction devices, such as a touch pad or screen, and/or control systems including feedback loops and control motors (e.g., feedback for sensing position and/or velocity; control motors for moving and/or adjusting components and/or quantities).
- a typical data processing system may be implemented utilizing any suitable commercially available components, such as those typically found in data computing/communication and/or network computing/communication systems.
- the users may be provided with an opportunity to control whether programs or features associated with the systems and/or methods collect user information (e.g., information about a user's preferences).
- user information e.g., information about a user's preferences
- certain data may be treated in one or more ways before it is stored or used, so that personally identifiable information is removed.
- a user's identity may be treated so that no personally identifiable information can be determined for the user.
- the user may have control over how information is collected about the user and used by a server.
Abstract
Description
p(τ|t,N,P,R,V)=∫p(τ|Y,V)p(Y|X,N)p(N)p(X|t,P,R)dXdYdN (1)
F(τ,t)=−∫d(t,τ)p(τ|t,N,P,R,V)p(N)p(t)dτdtdN (2)
F HM(τ,t)=∫p(τ=t|t,N,P,R,V)p(t)p(N)dtdN. (3)
If the environment N density is sufficiently narrow, or if N is modeled as deterministic, then equation (3) may be written as
F HM(τ,t)=∫p(τ=t|t,N,P,R,V)p(t)dt. (4)
F HM(τ,t)=∫p(τ=t|Y,V)p(X|t,P,R)p(t)dXdt, (5)
where {hacek over (X)} describes the features of the signal produced using the noise-free condition with the basic production rules P. It is important to note that similar, but different, specialized versions of equation (5) can be written down for other signal modification strategies, such as, for example, choosing from a set of rephrasings in text-to-speech, or for modifying the pronunciation of particular vowels. Modifications of renderings aimed at noise-free conditions are particularly natural for the modification of live speech.
dY=d{hacek over (X)} (7)
where Y are the noisy-speech features and {hacek over (X)} are the features of speech rendered for a noise-free condition. Equation (7) implies that any change in the features as rendered in a noise free environment corresponds to a similar change in the noisy-speech features if enhancement is present. This means the delta (and delta-delta) cepstra of the adapted noisy-speech features are identical to the noise-free-rendered-speech features. Since discrete log spectra are a unitary transform of the cepstra, this also means that changes in the log spectra are also identical in the adapted noisy-speech features and the noise-free-rendered-speech features.
where j sums over the feature vectors in the sequence J and i sums over the vector elements of the individual vectors. The minus sign in equation (8) means that the measure is a fidelity measure.
where the subscript “•” indicates an arbitrary j. The hit-or-miss based fidelity criterion (e.g., equation (6)) has now been approximated with a fidelity measure that has a simple and straightforward dependency on the features.
X •,i≦log(e Y
since the environmental noise and the rendered signal are independent at a signal level. In accordance with at least one embodiment, the case where the environmental noise is stationary may be considered, which means that the discrete noise spectrum n can be treated as a deterministic parameter in the present context (in contrast the random variable x varies across signal blocks).
∫g(y)p({hacek over (x)})d{hacek over (x)}=0, (11)
where g:
Λ(y,{hacek over (x)})=∫(λg(y)−({dot over (y)}−1)2)p({hacek over (x)})d{hacek over (x)}, (12)
where
and λ is the Lagrange multiplier. The Euler-Lagrange equation is
or, equivalently
λp({hacek over (x)})ġ(y({hacek over (x)}))+2{dot over (p)}({hacek over (x)}){dot over (y)}({hacek over (x)})+2p({hacek over (x)}){umlaut over (y)}({hacek over (x)})−2{dot over (p)}({hacek over (x)})=0 (14)
the uniform density on [0, a] for {hacek over (x)} corresponds to a density of shape
for the spectral amplitude {hacek over (s)}. This density p({hacek over (s)}) has an infinite variance, which makes it physically unreasonable.
The range of this mapping is [0, 1]. A uniform density of {hacek over (x)} on [0, a], with 0≦a≦1 corresponds to an exponentially decaying density p({hacek over (s)})=e−μ
where b is an adjustable parameter that determines the severity of the low-power enhancement. It can be used to bias the individual channels.
ÿ=0 (20)
and the general solution is of the form
y=c 0 +c 1 {hacek over (x)} (21)
which, with the boundary conditions imposed becomes
The error in the slope
is uniform across the range of {hacek over (x)} and depends only the boundary values.
where b0 and b1 are adjustable parameters that determine the strength of the low-power enhancement and the desired gain, respectively.
2λ(y−{hacek over (x)}+b 1)−2ÿ≦0 (27)
or
λy−ÿ=λ({hacek over (x)}−b 1). (28)
The general solution to the homogeneous solution is
y (h)({hacek over (x)})=c 0 e −λ{hacek over (x)} +c 1 e λ{hacek over (x)} (29)
and a particular solution is
y (p)({hacek over (x)})={hacek over (x)}−b 1 (30)
The complete solution is of the form
y({hacek over (x)})={hacek over (x)}−b 1 +c 0 e −λ{hacek over (x)} +c 1 e −λ{hacek over (x)}. (31)
In view of the above, the final solution may be determined as
where b0 and b1 are again adjustable parameters that determine the strength of the low-power enhancement and the desired gain, respectively.
λ(−2+4λ{hacek over (x)} 2)y−2ÿ=λ(−2+4{hacek over (x)} 2){hacek over (x)}. (37)
A solution to the homogeneous equation is
y (h)({hacek over (x)})=c 0 e −λx
A particular solution is
y (p)({hacek over (x)})={hacek over (x)}. (39)
With the boundary conditions, the solution becomes
y({hacek over (x)})={hacek over (x)}−b 1+(n+b 0)e −λ{hacek over (x)}
The noisy signal features converge to y={hacek over (x)}. Again, the features of the rendered signal may be computed with equation (10).
For most features, as y>0 the bound (equation (44)) is always positive and limits the mean absolute feature value in the mapped domain.
λ2{hacek over (x)} 2 y−2ÿ({hacek over (x)})=0. (45)
The general solution of this equation is of the form
y({hacek over (x)})=c 1(x 2−2)e √{square root over (λ)}x +c 2(x 2+2)e −√{square root over (λ)}x, (46)
where c1 and c2 are found using the boundary conditions.
The weighting of the present solution emphasizes high values of {hacek over (x)}, compensating for the implicit down-weighting obtained by using the logarithm. As such, the Lagrangian (equation (12), described above) is replaced by
The remaining definition of the problem is
where A=(α−1)x0 α-1 with x0 the smallest value possible for x.
2n{hacek over (x)} 2 ÿ+2n(1−α){hacek over (x)}{dot over (y)}+2(n(α−1)−λ{hacek over (x)})(y−n)+2(n(α−1)−λ{hacek over (x)})n=0. (55)
The homogeneous solution for y−n is
It is clear that a particular solution is y−n=n. Thus, the general solution is then of the form
The boundary conditions show that c1+c2=b, and
or, for small λ,
can be satisfied precisely for sufficiently large {hacek over (X)}•,i.
Y •,i ={hacek over (X)} •,i +V •,i (59)
where V•,i is a constant that can be both positive and negative. Independence of the noise and speech signals implies that
X •,i=log(e Y
A condition for the (log power of the) rendered signal X•,i for satisfying equation (58) on the interval {hacek over (X)}•,i+V•,i≧N•,i is then
X •,i=log(e {hacek over (X)}
The condition of equation (58) is not satisfied for 0≦{hacek over (X)}•,i+V•,i<N•,i. To make a clear improvement in intelligibility, the value V•,i needs to be selected sufficiently large such that the impact of the range where equation (58) cannot be satisfied is small.
Equivalently, the signal power can be minimized subject to a constraint on the fidelity (e.g., the sum of the probabilities that the condition holds):
ΔΛi=−∫0 ∞ {hacek over (s)} •,i 2exp(V •,i +V d)p({hacek over (s)} •,i)d{hacek over (s)} •,i+∫0 ∞ {hacek over (s)} •,i 2exp(V •,i)p({hacek over (s)} •,i)d{hacek over (s)} •,i +λP({hacek over (X)} •,i +V •,i +V d ≧N •,i)−λP({hacek over (X)} •,i +V •,i ≧N •,i) (64)
TABLE I |
RAW INTELLIGIBILITY SCORES (SENTENCE |
SET NUMBER AS INDEX) |
noise | SSN | BBL |
sbj | Nat. | PD | SDP | Nat. | | SDP | |
1 | 0.5255 | 0.5456 | 0.6457 | 0.4258 | 0.5559 | 0.5960 | |
2 | 0.2557 | 0.5555 | 0.5956 | 0.2760 | 0.5658 | 0.6259 | |
3 | 0.4756 | 0.6657 | 0.8455 | 0.4459 | 0.6760 | 0.5458 | |
4 | 0.7058 | 0.7759 | 0.9160 | 0.5455 | 0.6456 | 0.6757 | |
5 | 0.3860 | 0.4858 | 0.6859 | 0.1457 | 0.4655 | 0.3856 | |
6 | 0.5459 | 0.6160 | 0.6158 | 0.1156 | 0.2557 | 0.5555 | |
TABLE II |
INTELLIGIBILITY SCORES AFTER |
PROFICIENCY NORMALIZATION |
noise | SSN | BBL |
sentence set | Nat. | PD | SDP | Nat. | PD | SDP |
55 | 0.81 | 0.89 | 1 | 0.59 | 0.68 | 0.90 |
56 | 0.56 | 0.84 | 0.95 | 0.18 | 0.70 | 0.56 |
57 | 0.40 | 0.79 | 1 | 0.21 | 0.41 | 0.74 |
58 | 0.77 | 0.71 | 1 | 0.66 | 0.9 | 0.64 |
59 | 0.89 | 0.85 | 1 | 0.52 | 0.86 | 1 |
60 | 0.56 | 1 | 1 | 0.44 | 0.8 | 0.92 |
mean | 0.66 | 0.84 | 0.99 | 0.43 | 0.72 | 0.79 |
std | 0.17 | 0.09 | 0.02 | 0.18 | 0.16 | 0.16 |
TABLE III |
SIGNIFICANCE ANALYSIS (WILCOXON'S |
SIGNED RANK TEST) |
SSN | Nat. | PD | SDP | BBL | Nat. | PD | SDP |
Nat. | 1 | 0.16 | 0.03 | Nat. | 1 | 0.03 | 0.06 |
PD | — | 1 | 0.06 | PD | — | 1 | 0.69 |
SDP | — | — | 1 | SDP | — | — | 1 |
Claims (10)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/466,565 US9866955B2 (en) | 2013-08-23 | 2014-08-22 | Enhancement of intelligibility in noisy environment |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201361869332P | 2013-08-23 | 2013-08-23 | |
US14/466,565 US9866955B2 (en) | 2013-08-23 | 2014-08-22 | Enhancement of intelligibility in noisy environment |
Publications (2)
Publication Number | Publication Date |
---|---|
US20150055800A1 US20150055800A1 (en) | 2015-02-26 |
US9866955B2 true US9866955B2 (en) | 2018-01-09 |
Family
ID=51535523
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/466,565 Active 2035-05-05 US9866955B2 (en) | 2013-08-23 | 2014-08-22 | Enhancement of intelligibility in noisy environment |
Country Status (2)
Country | Link |
---|---|
US (1) | US9866955B2 (en) |
WO (1) | WO2015027168A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10992273B2 (en) | 2018-09-03 | 2021-04-27 | Samsung Electronics Co., Ltd. | Electronic device and operation method thereof |
US11418877B2 (en) | 2019-11-21 | 2022-08-16 | Samsung Electronics Co., Ltd. | Electronic apparatus and controlling method thereof |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11152015B2 (en) | 2017-03-22 | 2021-10-19 | Samsung Electronics Co., Ltd. | Method and apparatus for processing speech signal adaptive to noise environment |
CN111696567B (en) * | 2020-06-12 | 2022-04-01 | 思必驰科技股份有限公司 | Noise estimation method and system for far-field call |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US3008013A (en) * | 1954-07-20 | 1961-11-07 | Ferranti Ltd | Electrostatic loudspeakers |
US3022471A (en) * | 1961-07-28 | 1962-02-20 | Raytheon Co | Self-tuning filter circuits for increasing ratio of narrow band variable frequency signal to broad band noise |
US3106609A (en) * | 1960-06-16 | 1963-10-08 | Motorola Inc | Automobile speaker system |
US3497637A (en) * | 1967-11-13 | 1970-02-24 | Intelectron Corp | Transducer for stimulation of facial nerve system with r-f energy |
US8180064B1 (en) * | 2007-12-21 | 2012-05-15 | Audience, Inc. | System and method for providing voice equalization |
US9208766B2 (en) * | 2012-09-02 | 2015-12-08 | QoSound, Inc. | Computer program product for adaptive audio signal shaping for improved playback in a noisy environment |
-
2014
- 2014-08-22 WO PCT/US2014/052316 patent/WO2015027168A1/en active Application Filing
- 2014-08-22 US US14/466,565 patent/US9866955B2/en active Active
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US3008013A (en) * | 1954-07-20 | 1961-11-07 | Ferranti Ltd | Electrostatic loudspeakers |
US3106609A (en) * | 1960-06-16 | 1963-10-08 | Motorola Inc | Automobile speaker system |
US3022471A (en) * | 1961-07-28 | 1962-02-20 | Raytheon Co | Self-tuning filter circuits for increasing ratio of narrow band variable frequency signal to broad band noise |
US3497637A (en) * | 1967-11-13 | 1970-02-24 | Intelectron Corp | Transducer for stimulation of facial nerve system with r-f energy |
US8180064B1 (en) * | 2007-12-21 | 2012-05-15 | Audience, Inc. | System and method for providing voice equalization |
US9208766B2 (en) * | 2012-09-02 | 2015-12-08 | QoSound, Inc. | Computer program product for adaptive audio signal shaping for improved playback in a noisy environment |
Non-Patent Citations (4)
Title |
---|
C. H. Taal et al., "A Speech PreProcessing Strategy for Intelligibility Improvement in Noise Based on a Perceptual Distortion Measure", IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing, Mar. 25-30, 2012, pp. 4061-4064, Kyoto, Japan. |
Petko N. Petkov et al., "Maximizing Phoneme Recognition Accuracy for Enhanced Speech Intelligibility in Noise", IEEE Transactions on Audio, Speech and Language Processing, vol. 21, No. 5, May 1, 2013, pp. 1035-1045. |
R. J. Niederjohn et al., "The Enhancement of Speech Intelligibility in High Noise Levels by High-Pass Filtering Followed by Rapid Amplitude Compression", IEEE Trans. on Acoustics, Speech and Signal Processing, vol. ASSP-24, No. 4, Aug. 1976, pp. 277-282. |
T.C. Zorila et al., "Speech-in-noise intelligibilty improvement based on spectral shaping and dynamic range compression", InterSpeech, Sep. 9-13, 2012, Portland, Oregon. |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10992273B2 (en) | 2018-09-03 | 2021-04-27 | Samsung Electronics Co., Ltd. | Electronic device and operation method thereof |
US11418877B2 (en) | 2019-11-21 | 2022-08-16 | Samsung Electronics Co., Ltd. | Electronic apparatus and controlling method thereof |
Also Published As
Publication number | Publication date |
---|---|
US20150055800A1 (en) | 2015-02-26 |
WO2015027168A1 (en) | 2015-02-26 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
Ma et al. | Objective measures for predicting speech intelligibility in noisy conditions based on new band-importance functions | |
US8855322B2 (en) | Loudness maximization with constrained loudspeaker excursion | |
US8063809B2 (en) | Transient signal encoding method and device, decoding method and device, and processing system | |
US9779721B2 (en) | Speech processing using identified phoneme clases and ambient noise | |
US7676362B2 (en) | Method and apparatus for enhancing loudness of a speech signal | |
US9542937B2 (en) | Sound processing device and sound processing method | |
EP3107097B1 (en) | Improved speech intelligilibility | |
US20120245927A1 (en) | System and method for monaural audio processing based preserving speech information | |
KR102464300B1 (en) | Method for encoding multi-channel signal and encoder | |
US10636433B2 (en) | Speech processing system for enhancing speech to be outputted in a noisy environment | |
US11222651B2 (en) | Automatic speech recognition system addressing perceptual-based adversarial audio attacks | |
US9866955B2 (en) | Enhancement of intelligibility in noisy environment | |
KR20090127625A (en) | Audio signal quality enhancement apparatus and method | |
CN112786064A (en) | End-to-end bone-qi-conduction speech joint enhancement method | |
Siam et al. | A novel speech enhancement method using Fourier series decomposition and spectral subtraction for robust speaker identification | |
EP2151820B1 (en) | Method for bias compensation for cepstro-temporal smoothing of spectral filter gains | |
CN101322183B (en) | Signal distortion elimination apparatus and method | |
Alam et al. | Robust feature extraction for speech recognition by enhancing auditory spectrum | |
US10396906B2 (en) | Mutual information based intelligibility enhancement | |
US10438604B2 (en) | Speech processing system and speech processing method | |
Li et al. | The application of nonlinear spectral subtraction method on millimeter wave conducted speech enhancement | |
De Wet et al. | Additive background noise as a source of non-linear mismatch in the cepstral and log-energy domain | |
EP2063420A1 (en) | Method and assembly to enhance the intelligibility of speech | |
Choi | Noise robust front-end for ASR using spectral subtraction, spectral flooring and cumulative distribution mapping | |
Chen et al. | Robust speech recognition using spatial–temporal feature distribution characteristics |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:KLEIJN, WILLEM BASTIAAN;PETKOV, PETKO N.;SIGNING DATES FROM 20140825 TO 20140901;REEL/FRAME:033690/0275 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044129/0001Effective date: 20170929 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |