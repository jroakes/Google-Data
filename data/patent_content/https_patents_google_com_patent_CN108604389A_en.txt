CN108604389A - continuous depth ordering image synthesis - Google Patents
continuous depth ordering image synthesis Download PDFInfo
- Publication number
- CN108604389A CN108604389A CN201680081768.3A CN201680081768A CN108604389A CN 108604389 A CN108604389 A CN 108604389A CN 201680081768 A CN201680081768 A CN 201680081768A CN 108604389 A CN108604389 A CN 108604389A
- Authority
- CN
- China
- Prior art keywords
- segments
- color
- pixel
- span
- body span
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/10—Processing, recording or transmission of stereoscopic or multi-view image signals
- H04N13/106—Processing image signals
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T15/00—3D [Three Dimensional] image rendering
- G06T15/10—Geometric effects
- G06T15/20—Perspective computation
- G06T15/205—Image-based rendering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T15/00—3D [Three Dimensional] image rendering
- G06T15/10—Geometric effects
- G06T15/40—Hidden part removal
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T15/00—3D [Three Dimensional] image rendering
- G06T15/50—Lighting effects
- G06T15/503—Blending, e.g. for anti-aliasing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/20—Image signal generators
- H04N13/204—Image signal generators using stereoscopic image cameras
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/20—Image signal generators
- H04N13/257—Colour aspects
Abstract
The output image of two dimension (2D) image creation scene of system usage scenario.For the pixel in output image, 2D segments corresponding with pixel are identified in the output image.2D segments are converted to three-dimensional (3D) segment by system, the body span for pixel is created based on 3D segments, it is contributed based on the corresponding one or more 3D fragment colors in the 3D segments for the integrated span in multiple body spans to determine the color of the integrated span, and determines the color of the pixel of output image according to the identified color of body span.
Description
Technical field
The scheme and embodiment of the disclosure are related to image synthesis, are more particularly to continuous depth ordering image synthesis.
Background technology
Three-dimensional (3D) rendering is to be write on computers by 3D photo-realistics (photorealistic) effect or non-photograph
It is real to render the computer graphical processing that 3D wire-frame models are automatically converted to two-dimentional (2D) image.Wire-frame model is 3D computer graphics
The vision of the 3D or physical object that are used in shape are presented.Scene description language can be rendered into 2D for describing by 3D renderers
The scene of image.During the 2D images of render scenes from 3D scene descriptions, each pixel of 2D images can be from field
Multiple objects in scape receive contribution (such as image segments).In order to generate single color value for each pixel, generally usual
These image segments are combined during referred to as " synthesizing ".(such as hidden object) is blocked in order to correctly investigate,
Foreground segment should generally block background segment completely.If foreground segment is translucent, should use based on physics
Hybrid technology (such as " over " operation) synthesizes foreground segment on background segment.According to the sequence synthesized to segment,
The Different Results of pixel color can be obtained.3D scene descriptions can be inaccurate, and because scene is movable, surface
Minor error in position may lead to fragment order suddenly change.Such suddenly change may lead to the final face of resulting pixel
The big discontinuous variation of color, shows as spacial aliasing in the 3 d image or flicker in video.
Invention content
The simple general introduction of disclosure various aspects is given below, to provide the basic comprehension to these schemes.This is summarized simultaneously
The extensive overview of the not all aspect being susceptible to, and it had both been not intended to mark key or important element, it is also not intended to describe these
The range of scheme.The purpose is to provide some concepts of the disclosure in simplified form, as more detailed description given later
Preamble.
In the scheme of the disclosure, a kind of method includes the output figure of two dimension (2D) image creation scene of usage scenario
Picture.For the pixel in output image, 2D segments corresponding with pixel are identified in the output image, 2D segments are converted to three
(3D) segment is tieed up, the body span (volume span) for pixel is created based on 3D segments, based on the 3D segments for body span
In the colors of corresponding one or more 3D segments contribute and determine the color of body span, and according to determined by body span
Color come determine output image pixel color.In one embodiment, 2D images are captured by multiple cameras.
In one embodiment, 2D segments, which are converted to 3D segments, includes：It is added to each 2D segments and predefines thickness.This method can lead to
Cross processing equipment execution.
In one embodiment, predefined thickness limits in disparity space.Predefined thickness can also be in depth
Degree limits in space.In one embodiment, determine that the color of body span includes：Identify being contributed to body span in 3D segments
One or more 3D segments of color, and determine the color contribution of identified 3D segments.In some embodiments, it identifies
One or more 3D segments of color are contributed to may include to body span in multiple 3D segments：Identify having in multiple 3D segments
One or more 3D segments of the part Chong Die with body span.In one embodiment, determine that color contribution includes：Determine body
The length of span, determines the overall thickness of each 3D segments in one or more 3D segments for being identified, and by body span
Length divided by overall thickness.In one embodiment, the one or more 3D segments identified in multiple 3D segments are determined
Color is contributed：It determines the summation of the color of identified 3D segments, and the summation of identified color is multiplied by and is known
The contribution of other 3D segments.In one embodiment, it is created based on 3D segments and includes for the body span of pixel：Mark 3D pieces
The beginning event and End Event of section, sort beginning event and End Event successively, and the beginning event based on 3D segments and
End Event is sorted successively come the beginning event and End Event of the body span for limiting pixel.
There is also described herein a kind of equipments, include the device of the output image of the 2D creation of image scenes of usage scenario.
For the pixel in output image, the device for identifying 2D segments corresponding with pixel in the output image is used for 2D
Segment is converted to the device of 3D segments, the device for creating body span for pixel based on 3D segments, for being based on 3D segments
In corresponding one or more 3D segments the color of body span contributed determine the integrated span in multiple body spans
Color device, and for according to the identified color of body span come determine output image pixel color dress
It sets.In one embodiment, 2D images are captured by multiple cameras.In one embodiment, it is used for 2D segments
The device for being converted to 3D segments includes for adding the device for predefining thickness to each 2D segments.
In one embodiment, predefined thickness limits in disparity space.In one embodiment, it is used for
Determine that the device of the color of body span includes one or more 3D pieces that color is contributed to body span in 3D segments for identification
The device of section, and determine the device of the color contribution of identified 3D segments.In one embodiment, for determining color
The device of contribution includes the device of the length for determining body span, for determining in the one or more 3D segments identified
The device of the overall thickness of each 3D segments, and for by the device of the length of body span divided by overall thickness.In an embodiment party
In formula, the device for creating the body span for pixel based on 3D segments includes：For mark 3D segments beginning event and
The device of End Event, for the device of the beginning event and End Event of sequence 3D segments successively, and for being based on 3D pieces
The beginning event of section and being sorted successively to limit the beginning event and End Event of body span for pixel for End Event
Device.
In Additional embodiments, the computing device of the operation for executing the above embodiment is also achieved.In addition exist
In embodiment of the present disclosure, computer readable storage medium can store the operation for executing embodiment as described herein
Instruction.
It should be appreciated that embodiment can be combined so that the spy described under the context (context) of an embodiment
Sign can be combined with the feature of other embodiment.Although specifically, described above is each embodiment, should manage
Features described above can be combined into one or more combinations of the feature of embodiment, to provide other embodiment by solution.
Description of the drawings
It can be more complete according to specific implementation mode given below and the attached drawing of disclosure various aspects and embodiment
Understand to face the aspect and embodiment of the disclosure, still, attached drawing is not construed as the disclosure being limited to specific aspect
Or embodiment, it is only used for illustrating and understand.
Fig. 1 shows the example of the system architecture for consecutive image synthesis according to one embodiment of the disclosure.
Fig. 2 shows the methods of the color according to the disclosure one embodiment for determining pixel using three-dimensional segment
The flow chart of aspect.
Fig. 3 shows that the identification according to one embodiment of the disclosure is used for the example of two dimension (2D) segment of pixel.
Fig. 4 shows the example that 2D segments are converted to three-dimensional (3D) segment according to one embodiment of the disclosure.
Fig. 5 shows that the establishment according to one embodiment of the disclosure is used for the example of the body span of pixel.
Fig. 6 shows to be synthesized for continuous image on room and time according to one embodiment of the disclosure improved
The example of the system architecture of pixel color.
Fig. 7 shows the block diagram of the Example Computing Device operated according to disclosure one or more scheme.
Specific implementation mode
The aspect and embodiment of the disclosure are related to continuous depth ordering image synthesis.Camera can capture a system of video
Row image.Video frame is one in many static images for constitute motion diagram (hereinafter referred to as " video ").Video flashes refer to
Result caused by big discontinuous variation by pixel color in image.Two of the render scenes from three-dimensional (3D) scene description
During tieing up (2D) image, each pixels of 2D images can receive contribution (such as image sheet from multiple objects in scene
Section).In order to generate single color value for each pixel, generally by these image segments groups during commonly referred to as " synthesizing "
It is combined.In general, synthesis is related to synthesizing segment in sequence.According to the sequence synthesized to segment, can obtain
The Different Results of pixel color.Conventional synthetic techniques may by segment inaccurately cluster together, and when scene activity,
The segment of cluster may lead to fragment order suddenly change.Such suddenly change may lead to the final color of resulting pixel
Big discontinuous variation, and generate in 2D images spatially incoherent as a result, discontinuous in generation time in video
Result.The scheme of the disclosure can remove and/or prevent the suddenly change of fragment order, continuous on room and time to provide
Image synthesis.In the following, continuous and/or continuity refer to the little change in depth should only be generated in composite result it is minimum
Variation.
The aspect of the disclosure collects the segment of each pixel during rendering 2D output images.Not with conventional synthetic schemes
Together, the scheme of the disclosure is that each segment assigns limited thickness, which is converted to 3D segments.Make in terms of the disclosure
It is determined how fragment packet together with the limited thickness of 3D segments.Limited thickness based on 3D segments divides segment
Group can prevent the suddenly change of fragment order.The aspect of the disclosure can be contributed based on the color of fragment packet to determine pixel
Color.The aspect of the disclosure generates more accurate pixel color, is synthesized with providing continuous image on room and time, this has
Help prevent video flashes.
Fig. 1 shows the example of the system architecture 100 for consecutive image synthesis according to one embodiment of the disclosure,
Help to prevent the time flicker in undesirable pseudomorphism and video in 2D images.System architecture 100 includes one or more phases
Machine (such as camera 105A-105P), one or more server (such as server 120), one or more data storages (such as
Data store 106), one or more user equipment (such as user equipment 150) and one or more platforms (such as platform
140), they are coupled via one or more networks (such as network 110).
In one embodiment, network 110 may include common network (such as internet), dedicated network (such as local
Net (LAN) or wide area network (WAN)), cable network (such as ethernet network), wireless network (such as 802.11 networks or Wi-Fi
Network), cellular network (such as long term evolution (LTE) network), router, hub, interchanger, server computer and/or
Combination thereof.In one embodiment, network 110 can be cloud.
Camera 105A-105P for example can be ODS (omnidirectional is three-dimensional) cameras and/or depth perception camera.ODS cameras be
The camera of visual field in horizontal plane with 360 degree of visual fields or with the entire spherical surface of (substantially) covering.Depth perception camera can be with
For the one or more Object Creation depth datas captured in the range of depth perception camera.In one embodiment, it is
Framework 100 of uniting includes a depth perception camera.In another embodiment, system architecture 100 includes multiple cameras, such as
ODS cameras and/or depth perception camera.
Camera can be arranged in camera array 160.Multiple cameras in camera array 160 can share setting and frame
Grade is synchronous, so that multiple camera serves as a camera.For example, what system architecture 100 may include being arranged in camera array 160
16 ODS cameras.Camera array 160 can be ring-shaped.Annular array 160 may include that the stereoscopic vision for accommodating camera is empty
Quasi- reality (VR) equipment.Camera array 160 can be multiple views camera system, can link together the movement of camera, with
The image of scene is captured from different perspectives.Scene may include one or more objects.
Camera can use RGB (red, green, blue) color space.In one embodiment, camera can generate output number
According to such as color data.Color data may include the RGB vectors of each pixel in the image of cameras capture.In another reality
It applies in mode, camera can generate the output data that can be converted to color data (such as RGB vectors).Herein, will make
Use the camera of RGB color as example.
Camera 105A-P can capture scene in the range of camera 105A-P, to create the content of such as video flowing.
Content can be the RGB image sequence of scene.Each camera 105A-P can be with outputting video streams, which is caught by respective camera
The RGB image sequence composition caught.RGB image in video flowing is made of pixel.RGB image can for example be encoded to binary word
Symbol string array, wherein per 4 bytes of pixel.
Video flowing and color data can be stored in data storage (such as data storage 180).Data storage 180 can be with
It is data-storable persistent storage.Persistent storage can be local storage unit or remote storage unit.Persistence
Storage can be magnetic cell, optical storage unit, solid state storage elements, electronic memory module (main memory) or similar deposit
Storage unit.Persistent storage can be single-chip device or distributed set.As it is used herein, " set " reference is any
Positive integer project.
One or more servers (such as server 120) can handle the video flowing that camera 105A-P is generated, to generate
Image (such as output image 130) is exported, to generate outputting video streams 170.Server can be by following trustship：One or more
A computing device (such as rack-mount server, router computer, server computer, personal computer, mainframe, knee
Laptop computer, tablet computer, desktop computer etc.), it is data storage (such as hard disk, memory, database), network, soft
Part component, and/or the hardware component that can be used for providing a user content.
In one embodiment, output image is panoramic scene (or " panorama "), and outputting video streams can be immersed
Formula video.In other embodiments, output image is non-panoramic view.Panorama is the wide-angle view or wide-angle table of physical space
Show.Immersion video --- also known as " 360 video ", " 360 degree of videos " or " spherical video " --- is real world panorama
Video flowing, wherein record the view in each direction simultaneously, and for example using omnidirectional's stereoscopic camera (such as camera 105A-105P) or
Camera set (such as camera array 160) is shot.During playback, user can control view direction, this is virtual reality
A kind of form.Virtual reality (VR) is a kind of computer technology of copying surroundings (true or the imagination environment), and can be with
Come in a manner of allowing user to interact analog subscriber be physically present and environment.Virtual reality can artificially create sense organ
Experience, including vision, tactile, the sense of hearing and/or smell.
Server 120 can be carried out the RGB image that alignment cameras 105A-P is generated using computer vision and 3D alignments and will
RGB image is spliced into seamless photo and inlays, to create outputting video streams 170.Computer vision refer to for obtaining, handling,
Analysis and understanding image and high dimensional data from real world, the method to generate number or symbolic information.Export image
(such as output image 130) and outputting video streams 170 can be stored in data storage 180.
Server 120 may include synthesizer 125, to determine that the output image of outputting video streams 170 (such as exports image
130) color of pixel.Splash (splatting) technology can be applied to the input figure that camera 105A-P is generated by synthesizer 125
Picture, to generate the splash (splat) for exporting image (such as output image 130), to generate RGBA vectors comprising every
Four channels (for example, red channel, green channel, blue channel, the channels Alpha) of a pixel." Alpha " is also used below
" α " is indicated.Opacity information is indicated by the channels alpha (Alpha).Opacity is a lack of transparency or translucence (no
Transparency) situation.The combination for the RGB image that camera 105A-P is generated is known as below together with the alpha channel informations of pixel
RGBA images.RGBA images can be 2D images.The output image (such as output image 130) generated from RGBA images 185 can
To be 2D images.Synthesizer 125 can analyze the scene in 2D RGBA images 185 in 3D.Server 120 can be based on closing
Grow up to be a useful person 125 analysis come adjust splicing.
In order to analyze the scene in 2D RGBA images 185 in 3D modeling, synthesizer 125 can identify output image 130
In pixel, and identify output image 130 in 2D segments associated with the pixel.Synthesizer 125 can be converted to 2D segments
It is that pixel creates body span (volume span) for the 3D segments of pixel, and based on 3D segments.Synthesizer 125 can be based on
The colors of 3D segments contributes to determine the color of body span, and determines the face of the pixel of output image based on the color of body span
Color.It is described in more detail in 3D modeling with reference to Fig. 2 to Fig. 5 and analyzes the scene in 2D RGBA images 185 to determine pixel
More acurrate color.Synthesizer 125 can determine the color of each pixel in output image 130.Synthesizer 125 can determine use
The color of pixel in the output image for generate outputting video streams 170.
Outputting video streams 170 can be single video flowing, can (such as content is shared flat by one or more platforms
Platform) it accesses.Outputting video streams 170 can be supplied to one or more user equipmenies by one or more platforms, and (such as VR wears dress
It sets, smart phone etc.).For example, outputting video streams 170 can be in any kind of systems of 360 viewing of VR head-wearing devices or support
It is played back in system.It is more fully described in figure 6 below defeated to the offer of one or more user equipmenies by one or more platforms
Go out video flowing 170.
Fig. 2 shows according to one embodiment of the disclosure, the method 200 of the color of pixel is determined using three-dimensional segment
The flow chart of aspect.Method 200 is performed by handling logic, may include hardware (circuit, special logic etc.), software
(such as being run in general-purpose computing system or special purpose machinery) or combination.In one embodiment, pass through Fig. 1
Synthesizer 125 execute the method, and in some other implementations, can be executed by another machine one of Fig. 2 or
Multiple frames.
In frame 210, the output image of two-dimentional (2D) creation of image scene of one or more of processing equipment usage scenario
(such as output image 130 of Fig. 1).One or more 2D images can be by one or more cameras (such as camera of Fig. 1
105A-P) the 2D RGBA images (such as RGBA images 185 of Fig. 1) generated.Processing equipment can use computer vision technique
The 2D RGBA images for carrying out alignment cameras generation with 3D technique of alignment, to create output image.
In frame 220, for the pixel in output image, processing equipment identifies 2D corresponding with pixel in the output image
Segment.Processing equipment can identify one to four segments of pixel.It, can be with about high-resolution texture in 2D RGBA images
There is the point of very big figure.In one embodiment, in a large amount of points of processing, processing equipment renders skill using surface splash point
Art tolerates the intrinsic loss of geometric accuracy and texture fidelity.In one embodiment, processing equipment uses surface splash
Splash is generated in the output image for each pixel in 2D RGBA images.Splash is the point in pixel.Processing equipment can be with
Splash is generated to splash algorithm using preceding.In one embodiment, processing equipment is applied to input by preceding to splash algorithm
Pixel in image (such as image of camera generation) and one splash of generation in the output image.Processing equipment can be by splash skill
Art is applied to each pixel in input picture, each input image pixels is converted to splash, which falls in output figure
A position as in.There can be multiple splashes to fall within each output pixel (exporting the pixel in image).Processing equipment can
The segment of the pixel of the output image is generated using the splash of the pixel in output image.
Processing equipment can calculate the color of each pixel by following：Mix the segment for the image for example nearby drawn
Contribution and the contribution of each segment is weighted by the degree that the segment covers according to the pixel.This technology is referred to as
" anti-aliasing (anti-aliasing) ", because it reduces " aliasing " effect for the lack sampling for leading to the suddenly change in image.
The exemplary scenario generated for realizing anti-aliasing image is A buffering schemes (A-buffer scheme).A bufferings can be used for generating
Institute contributive open list of the segment to pixel.Fragment list is safeguarded for each rendered object be overlapped with pixel.Place
Splash can be applied to by A buffer algorithms by managing equipment, to create the segment of pixel.
Fig. 3 shows the example of the 2D segments of the identification pixel according to one embodiment of the disclosure.Output image 300 can wrap
Include the set of pixel.Pixel can be square.Processing equipment can generate one in each pixel for falling within output image
Or multiple splashes.For example, splash 320 is in pixel 330.
A can be buffered the set for being applied to pixel in image 300 by processing equipment, to generate set (such as the segment of segment
1-4).Segment is rabbeted to the polygon of pixel boundary.For example, there are four segment 1-4 for the tool of pixel 330, it is polygon.A
Buffering can by the way that polygon is rabbeted each square pixel covered to them come according to scan line sequential processes polygon, with
Output fragment list corresponding with each square pixel.A bufferings can across the pixel Sliding mesh 310 in image 300, with
The segment (such as segment 1-4) of pixel is defined for the splash (such as splash 320) of pixel (such as pixel 330).Processing equipment
Can be that each segment generates color data (such as RGBA vectors) and stores.
Referring again to Fig. 2, in frame 230,2D segments are converted to three-dimensional (3D) segment by processing equipment.2D segments, which have, uses x
The x-y traces (footprint) of axis and y-axis.For each 2D segments, processing equipment is along the axis of third dimension by predefined thickness
Degree is added to front side and the rear side of 2D segments.Third dimension may be in parallax (d) space or depth (z) space.Parallax d is
It is inversely proportional instead of the flow vector length of depth, and with depth z so that parallax d=1/z.Herein, parallax d is used as the
The example of three dimensionality.
Fig. 4 shows the example that 2D segments are converted to 3D segments according to one embodiment of the disclosure.Processing equipment is known
One or more 2D segments of other pixel.In order to illustrate simplicity, Fig. 4 describe pixel a 2D segment 400.Processing equipment edge
D axis (such as axis of parallax) predefined thickness (" n ") 420 is added to the front side of 2D segments 400 and is added to 2D segments 400
2D segments 400 are converted to 3D segments 410 by rear side.It in another embodiment, can be along z-axis (such as depth axis)
It is limited in deep space and predefines thickness.Predefined thickness n 420 can be configurable and/or user-defined.
With reference to figure 2, in frame 240, it is that pixel creates body span that processing equipment, which is based on 3D segments,.Processing equipment can be along
Three dimensionality axis (such as d axis) is ranked up 3D segments.Processing equipment can position 3D according to the parallax of 3D segments along d axis
Segment.
Fig. 5 describes according to the example that one embodiment of the disclosure is pixel establishment body span.In the example of hgure 5, d
Axis 500A-C indicates the parallax relative to camera origin 510.For pixel there are four 2D segments (such as segment 501,503,
505、507).D axis 500A indicates the third dimension in disparity space.Parallax is inversely proportional with depth, and can be relative to phase
The origin 510 of machine.D axis 500A-500C indicates parallax d=1/z and can have the reference point for indicating camera origin 510.D axis
500A shows the viewgraph of cross-section of four 2D segments 501,503,505,507, and each 2D segments are along x-axis (such as the x in Fig. 4
Axis) and y-axis (such as y-axis in Fig. 4) have x-y coordinate.To simplify the explanation, x-axis and y-axis is not shown in Fig. 5.
D axis 500B shows the viewgraph of cross-section of four 3D segments 502,504,506,508.Processing equipment can be in d axis
Predefined limited thickness n is added in the both sides of each 2D segments in 2D segments 501,503,505,507 in 500A, thus will
2D segments 501,503,505,507 are converted to 3D segments 502,504,506,508 shown in d axis 500B.
Processing equipment can identify in d axis 500B and mark each 3D segments in 3D segments 502,504,506,508
Beginning event and End Event.Beginning event is the beginning of 3D segments, and can be by measurement (such as parallax) table of d axis 500B
Show.End Event is the end of 3D segments, and can be indicated by the measurement (such as parallax) of d axis 500B.For example, processing equipment mark
Remember the beginning event d of 3D segments 5020With End Event d3, the beginning event d of 3D segments 5041With End Event d4, 3D segments
506 beginning event d2With End Event d5And the beginning event d of 3D segments 5086With End Event d7.It can be by event flag
It is stored in data storage (such as data storage 180 of Fig. 1).
Processing equipment can be based on 3D segments 502,504,506,508 beginning event and End Event be pixel create body
Span.Processing equipment for example can sort event flag successively to limit body span by the value of the parallax d based on event.Processing is set
The standby beginning event and End Event that the body span of pixel can be limited using the sequence of event flag.Body span is selected for it
Select (such as a d in event flagv) as it start event, and by the next thing of sequential selection successively of event flag
Part label (such as dv+1) 3D segments as its End Event.For example, processing equipment can be by the way that body span 513 to be limited to have
There are beginning event d0 and End Event d1 to create body span 513.In another example, processing equipment can be by by body span
515 are defined with beginning event d1 and End Event d2 to create another individual span 515.In other examples, processing is set
It is standby to use event flag d0、d1、d2、d3、d4、d5、d6And d7To limit and create the body span 513-523 of pixel.
With reference to figure 2, in frame 250, processing equipment is contributed to determine body based on the color for the corresponding 3D segments for constituting body span
The color of span (such as body span 513-523 of Fig. 5).In order to determine that color is contributed, which 3D segments tool is processing equipment identify
There is the part Chong Die with body span, and is thus that body span contributes color.Such as in Figure 5, for body span 513,3D segments
502 have the part 556 Chong Die with body span 513.The color of part 556 is that the color of body span 513 is made contributions.Another
In a example, for body span 515, processing equipment can determine that 3D segments 502 have the part 557 Chong Die with body span 515,
And 3D segments 504 have the part 551 Chong Die with body span 515.The color of part 557 and the color of part 551 be body across
The color of section 515 is made contributions.
Processing equipment can determine the color contribution of identified 3D segments.It can be by the color of the 3D segments of particular volume span
Contribution is determined as the length of body span divided by the overall thickness k of 3D segments.For each 3D segments, overall thickness k is identical.
Processing equipment, which can contribute the color of the 3D segments identified, to be determined as：
(di+1-di)/k (equation 1)
In equation 1, parameter i refers to body span.The length of body span is (di+1-di).Parameter k refers to 3D segments
Overall thickness.Color contribution can be expressed as value or percentage.For example, for body span 523, single 3D segments (such as 3D
Segment 508) it is at least part of Chong Die with body span 523.In this case, the entirety of 3D segments 508 and 523 weight of body span
It is folded.The length 563 of body span 523 divided by the overall thickness 561 of 3D segments 508 can be 1 or 100%.3D segments 508 are to body span
The contribution of 523 color is 100%.
In another example, for body span 513, single 3D segments (such as 3D segments 502) at least one
Divide Chong Die with body span 513.In this case, the overall thickness 554 of the length 558 of body span 513 divided by 3D segments 502 can be with
It is 0.6 or 60%.3D segments 502 are 60% to the contribution of the color of body span 513.
In another example, for body span 515, two 3D segments (such as 3D segments 502,3D segments 504)
It is at least part of Chong Die with body span 515.In this case, the length 559 of body span 515 divided by 3D segments (such as 3D
Segment 502,3D segments 504) overall thickness (such as overall thickness 553 or overall thickness 554, they are identical) can be 0.2 or
20%.3D segments (such as 3D segments 502,3D segments 504) are 20% to the contribution of the color of body span 515.
Processing equipment can be Chong Die with body span according to some identified the colors of 3D segments contribute and determine
The color of body span.Processing equipment can determine the color of identified 3D segments, and determine the summation of color.Processing equipment can
The summation of the color of the 3D segments identified is multiplied with the contribution of the 3D segments identified.For example, 3D segments (such as 3D segments
502,3D segments 504) it is 20% to the contribution of the color of body span 515.Processing equipment can be by the color of the 3D segments identified
Summation be multiplied by 20%, as follows combine equation 2 described in detail by.
Processing equipment can use contribution (such as [(di+1-di)/k]) by the color of body span (such as body span 515)
(c ') is determined as：
c’i=[(di+1-di)/k]Σj∈θiMfj(equation 2)
In equation 2, parameter i refers to body span (such as body span 515).Parameter j is referred to
Such as body span 515) overlapping part (such as part 551, part 557) 3D segments (such as 3D segments 504,3D segments 502).
Parameter k refers to the overall thickness (such as overall thickness 553, overall thickness 554) of 3D segments j (such as 3D segments 504,3D segments 502).θi
Refer to the group of the part (such as part 551, part 557) Chong Die with body span i.
In equation 2, fjRefer to the RGBA color of 3D segments j.Color can be indicated with RGBA color value.RGBA color
Value can be appointed as three Color Channels, such as RGB (red, green, blue), and indicated by the channels alpha (Alpha)
Opacity information.Opacity is a lack of the situation of transparency or translucence (opacity).Specify 3D pieces in the channels alpha
The opacity for the object that section j is indicated.
RGBA color value can be appointed as to vector, such as RGBA (red, green, blue, α).In the Color Channel of vector
Each color parameter (for example, red, green and blue) define the intensity of color, and can be the integer between 0 to 255
Or percent value (from 0% to 100%).For example, for RGB color value, RGB (0,0,255) values or RGB (0%, 0%,
100%) it can be rendered into blue, because blue parameters are arranged to its peak (255 or 100%), and other parameters value
It is arranged to 0 or 0%.
The alpha parameters that A or α is expressed as in the channels α of vector for example can be that 0.0 (fully transparent) and 1.0 are (complete
It is opaque) between number.In another example, the alpha parameters for being expressed as A or α can be with 8 Color schemes come table
Show, wherein 255 be completely opaque, and 0 is fully transparent.Processing equipment can be according to camera (such as the camera 105A- of Fig. 1
P) output data (such as color data) generated determines the RGBA color value of 3D segments j.Processing equipment can be deposited from data
Storage (such as data storage 180 of Fig. 1) accesses color data.
The four-tuple (R, G, B, A) of pixel can indicate that pixel is covered with certain percentage by panchromatic object.For example, RGBA
Vectorial (0.5,0,0 .5) indicates a complete red object half mulching pixel.Four-tuple (R, G, B, A) indicates that pixel is by color (R/
A, G/A, B/A) covering A.
In above equation 2, M is configurable and/or user-defined weight multiplier.In one embodiment, by M
It is set as 0.5.MfjRefer to the weighting RGBA color of 3D segments j.In one embodiment, M is only applied in RGBA vectors
A channel, to determine alpha value.
Processing equipment can determine the color (c ') of body span using equation 2.The color (c ') of body span can be by
RGBA vectors indicate.In one embodiment, if the gained alpha value exceedance 1 or 8 of the body span in RGBA vectors
Position Color scheme in 255, then processing equipment the RGBA vectors of body span can be normalized.
Processing equipment can be that body span checks RGBA color c 'iThe value α of alpha in vector in A channel, and determine α
Value whether more than 1 or in 8 Color schemes more than 255.If α values be more than threshold value, processing equipment can by by body across
All channels divided by α values in the RGBA vectors of section normalize α values.
With reference to Fig. 2, in frame 260, processing equipment determines the color of the pixel of output image according to the color of body span.Place
Equation 2 can be applied to per individual span by managing equipment.Such as in Figure 5, processing equipment can determine the color of body span 513
(c0), the color (c of body span 5151), the color (c of body span 5172), the color (c of body span 5193), the face of body span 521
Color (c4) and body span 523 color (c5)。
Processing equipment can execute over operations to determine that the synthesis color of pixel is as follows by the color to body span：
ccomposite=c0over c1over......cn(equation 3)
Over operation definitions are as follows：
A over b=a+ (1-a_alpha) * b (equation 4)
Wherein a and b is rgba vectors, and a_alpha is the 4th component of a, i.e. alpha value.Processing equipment can scheme output
As the color of the pixel of (such as output image 130 of Fig. 1) is stored in data storage (such as data storage 180 of Fig. 1).Place
Managing equipment can be to other pixel repeat block 220 to 260 in output image (such as output image 130 of Fig. 1).It is set by processing
The standby pixel color determined is more more acurrate than traditional synthetic schemes, and help to prevent for create outputting video streams (such as
The outputting video streams 170 of Fig. 1) image in unexpected pixel color change.It is provided by the pixel color that processing equipment determines empty
Between and synthesis continuous in time, to reduce the video flashes in the spatial artifacts and outputting video streams in 2D images.
Fig. 6 is shown according to one embodiment of the disclosure, for the improvement that continuous image synthesizes on room and time
Pixel color system architecture 600 example.System architecture 600 includes user equipment 610A to 610Z, one or more nets
(such as content is total for network 605, one or more data storage 606, one or more servers 630 and one or more platforms
Platform 620 is enjoyed, recommends platform 657, is advertising platform 665, mobile platform 650, social network-i i-platform 660, search platform 645, interior
Hold supplier's platform 697 and cooperation platform 655).User equipment 610A to 610Z can be client device.
One or more networks 605 may include that one or more common networks (such as internet), one or more are special
Network (such as LAN (LAN) or one or more wide area network (WAN)), one or more cable networks (such as Ethernet),
One or more wireless networks (such as 802.11 networks or Wi-Fi network), one or more cellular network (such as long term evolution
(LTE) network), router, hub, interchanger, server computer and/or combination thereof.In one embodiment,
Some components of framework 600 are not directly connected to each other.In one embodiment, framework 600 includes separated network 605.
One or more data storages 606 can be memory (such as random access memory), cache, driver
(such as hard disk drive), flash drive, Database Systems or data-storable other kinds of component or equipment.
One or more data storages 606 may include multiple storage assemblies (such as multiple drivers or multiple databases), they also may be used
With across multiple computing devices (such as multiple server computers).Data storage 606 can be data-storable persistence
Storage.Persistent storage can be local storage unit or remote storage unit.Persistent storage can be magnetic cell, light
Storage unit, solid state storage elements, electronic memory module (main memory) or similar storage unit.Persistent storage can be with
It is single-chip device or distributed apparatus collection.As it is used herein, " set " refers to any positive integer project.
Content item 621 can be stored in one or more data storages 606.Data storage 606 can be one or
A part for multiple platforms.The example of content item 621 may include but be not limited to outputting video streams (such as the output video of Fig. 1
Stream 170), digital video, digital movie, live image, digital photos, digital music, digital audio, web site contents, social matchmaker
Body update, e-book (ebook), e-magazine, digital newspaper, digital audio books, electronic journal, web blogs, Simple Syndication
(RSS), electronics comic books, software application etc..Content item 621 is also referred to as media item.It for brevity, herein will be defeated
Go out the example that video flowing (hereinafter also referred to as video) (such as outputting video streams 170 of Fig. 1) is used as content item 621.
Content item 621 can be provided by server 630, for being stored in one or more data storages 606.Content item
Mesh 621 can be immersion video, also known as " 360 video ", " 360 degree of videos " or " spherical video ", be real world panorama
Video flowing, wherein recording the view in each direction simultaneously.During playback, user can control view direction.Server 230
It may include synthesizer 240, for providing a user outputting video streams (such as immersion video) via communications applications 215.Service
Device 230 can be one or more computing devices (such as rack-mount server, server computer etc.).In an embodiment
In, server 230 is included in one or more of platform.In another embodiment, server 230 and platform point
From, but can be with one or more Platform communications (such as exchanging data).
Content item 621 can be provided by content provider, for being stored in one or more data storages 606.
In one embodiment, content provider by RGBA images (such as RGBA images 185 of Fig. 1) be supplied to server 630 (such as
The server 120 of Fig. 1), and server 640 handles RGBA images to generate output image (such as output image 130) and use
The output creation of image content item 621 (such as outputting video streams 170 of Fig. 1).Content provider can be user, public affairs
Department, tissue etc..
ISP (such as content shared platform 620, recommendation platform 657, advertising platform 665, mobile platform 650, society
Hand over the network platform 660, search platform 645, content provider's platform 697 or cooperation platform 655) it can be in user equipment 610A-
Immersion video is provided on 610Z, so that user watches.
User equipment 610A-610Z may include such as virtual reality head-wearing device, smart mobile phone, cellular phone, a number
It is word assistant (PDA), portable media player, net book, laptop computer, E-book reader, tablet computer, desk-top
Computer, set-top box, game console, the equipment of television set or any kind of equipment for supporting 360 viewings.
Each user equipment 610A-610Z may include communications applications 615.It can disappear via communications applications 615, internet etc.
Take content item 621.As it is used herein, " media ", " media item ", " online Media project ", " Digital Media ", " number
Word media item ", " content " and " content item " may include such electronic document：It can use be configured as presentation content
Software, firmware or the hardware of project is executed or is loaded.In one embodiment, communications applications 615 can be such answer
With：The application allows user (such as content shared platform 620, to recommend platform 657, advertising platform 665, mobile flat by platform
Platform 650, social network-i i-platform 660, search platform 645, cooperation platform 655 and content provider's platform 697) and/or platform and/
Or content item 621 (such as immersion video) is created, is sent and received in the combination of network.
For example, communications applications 615 can be social networking applications, video sharing application, photo be shared application, chat and answer
With, the mobile application of content provider or any combinations of such application.Communications applications 615 in user equipment can be to
One or more users render, show and/or present one or more content items 621 (such as immersion video).For example, logical
Letter can provide one or more user interfaces (such as the graphical user to be rendered in the display of user equipment using 615
Interface), for transmission, reception and/or play immersion video.
In one embodiment, each user equipment 610A-610Z includes (such as the media play of content viewer 613
Device) with to one or more users render, display and/or presentation content project 621 (such as immersion video).Implement at one
In mode, content viewer 613 is embedded in application (such as communications applications 615).Such as mobile device, communication is answered
Can be such mobile application with 615：It can be (such as content shared platform 620, social network-i i-platform 660, interior from platform
Hold supplier's platform 697 etc.) it downloads, and may include content viewer 613 (such as media player).In another example
In, communications applications 615 can be desktop application, such as the Web service by platform that can access, retrieves, presents and/or navigate
Device is come the web-browsing of the content (such as webpage, Digital Media as hypertext markup language (HTML) page etc.) distributed
Device.Content viewer 613 can be web browser plug-in unit or individually application.In one embodiment, content viewer
613 are embedded in webpage.For example, the embedded media that content viewer 613 can be built-in in document (such as webpage) is broadcast
Put device (such asPlayer or HTML5 players).
Content provider's platform 697 can provide service, and content provider can be ISP.For example, interior
It can be stream ISP to hold supplier, it provides media stream service via communications applications 615, so that user is via content
Supplier's platform 697 plays TV programme, editing and film on user equipment 610A-210Z.Content provider's platform 697 can
To be one or more computing devices (such as rack-mount server, router computer, the clothes that can be used for providing a user content
Business device computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer etc.), data deposit
Store up (such as hard disk, memory, database), network, component software, and/or hardware component.
Social network-i i-platform 660 can be provided in line social networking service.Social network-i i-platform 660 can provide communication and answer
With 615, so that user creates profile and utilizes the carry out activity of their profile.Activity may include updating profile setting, with other
User exchanges message, and with shared with other users, assessment (such as is liked, comments on, dividing for issued state update, photo, video etc.
Enjoy, recommend) state update, photo, video etc., and receive the movable notice of other users.Social network-i i-platform 660 can be
It can be used for providing one or more computing devices (such as rack-mount server, router computer, the clothes of communication between users
Business device computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer etc.), data deposit
Store up (such as hard disk, memory, database), network, component software, and/or hardware component.
Mobile platform 650 can be and/or including one or more computing devices (such as server), data storage, net
Network (such as combination of telephone network, cellular network, LAN, internet, and/or network), component software, and/or hardware group
Part, they can be used for allowing user using one or more mobile devices (such as phone, tablet computer, laptop computer,
Wearable device etc.) and/or any other suitable equipment interconnection, shared information and/or interaction.For example, mobile platform
250 may be implemented telephone communication, short message service (SMS) information receiving and transmitting, multimedia messaging service (MMS) information receiving and transmitting, text
Any other communication between chat, and/or user.Mobile platform 650 can via video messaging receive and dispatch, Video chat, and/or
Video conference supports the user to communicate.
Such as use stream video or ip voice (VoIP) technology, cellular technology, LAN and/or WAN technologies, cooperation platform 655
It may be implemented collaboration services, such as transmitting-receiving of Video chat, video messaging and audio and/or video conference (such as in equipment
Between the user of 610A-610Z), and can be used for towards personal, amusement, business, education or the interaction of science.Cooperation platform 655
Can be one or more computing devices (such as rack-mount server, router meter that can be used for providing communication between users
Calculation machine, server computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer
Deng), data storage (such as hard disk, memory, database), network, component software, and/or hardware component.
It can be used for generating and provide commending contents (such as article, video, model, news, trip to recommend platform 657
Play etc.) one or more computing devices (such as rack-mount server, router computer, server computer, individual calculus
Machine, mainframe computer, notebook computer, tablet computer, desktop computer etc.), data storage (such as hard disk, memory,
Database), network, component software, and/or hardware component.
Search platform 645 can be used for allowing user to inquire one or more data to store 606 and/or one or more
A platform and one or more computing devices (such as rack-mount server, router computer, the server for receiving query result
Computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer etc.), data storage
(such as hard disk, memory, database), network, component software and/or hardware component.
Advertising platform 665 can provide video ads.Advertising platform 265 can be can be used for providing video ads one
Or multiple computing devices (such as rack-mount server, router computer, server computer, personal computer, mass computing
Machine, laptop computer, tablet computer, desktop computer etc.), data storage (such as hard disk, memory, database), net
Network, component software, and/or hardware component.Content item 621 (such as immersion video) can be used as video ads.
Content shared platform 620 can be can be used for one or more users provide to the access of content item 621 and/
Or one or more computing devices (such as rack-mount server, the router of content item 621 are provided to one or more users
Computer, server computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer,
Data store (such as hard disk, memory, database), network, component software, and/or hardware component.For example, content is shared flat
Platform 220 can allow customer consumption, upload, download and/or search content item 621.In another example, content is shared flat
Platform 620 can allow user to assess content item 621, such as approve of (liking), do not like, recommend, share, grade and/or comment
By content item 621.In another example, content shared platform 620 can allow user's content of edit project 621.Content
Shared platform 620 may also include website (such as one or more webpage) and/or one or more application (such as communications applications
615), they can be used for for example providing the visit to content item 621 to one or more users via user equipment 610A-610Z
It asks.Content shared platform 620 may include any kind of content transmission network for providing the access to content item 621.Content
Shared platform 620 may include content feeds component 690, the content feeds 695 for listing feed item, such as communications applications are presented
Content item 621 in 615 user interface.
Content shared platform 620 may include multiple channels (such as channel A 625).Channel can be obtained from common source
Data content or data content with common title or theme.Data content can be the digital content of user's selection, make
The digital content of digital content, content provider's selection that digital content obtained by user, user upload, broadcaster's selection
Digital content etc..For example, channel A 625 may include immersion video Y and Z.Channel can be associated with the owner, this is all
Person is the user that can be acted on channel.Data content can be one or more content items 621.
Can the action based on channel owners different activities are associated with channel, such as channel owners make number
Content can be used on channel, channel owners select (such as liking) digital content associated with another channel, channel institute
The person of having comments on digital content associated with another channel etc. etc..User in addition to channel owners can subscribe to them
Interested one or more channel.Once user subscribes to channel, so that it may be presented so that the activity from the channel is presented to the user
The information sent.Although channel to be described as to an embodiment of content shared platform, embodiment of the present disclosure is unlimited
In the content shared platform for providing content item 621 via channel model.
To simplify the explanation, disclosed method is shown and described as a series of actions.But according to the dynamic of the disclosure
Work can occur according to various sequences and/or simultaneously, and occur together with other actions not presented and described herein.This
Outside, it may not be necessary to which all of the illustrated actions realizes the method according to disclosed theme.In addition, those skilled in the art answer
Work as understanding, via state diagram or event the method can be expressed as to a series of associated states as an alternative.In addition it should manage
Solution, method disclosed in this specification can be stored on product, to transport and send to computing device by these methods.This
The term " product " that text uses is intended to cover the computer program that can be accessed from any computer readable device or storage medium.
Fig. 7 shows showing for the machine of the exemplary forms using computer system 700 according to one embodiment of the disclosure
It is intended to, collection can be executed instruction in computer system 700 for making the machine carry out one or more as described herein
A method.Computer system 700 can be with the server 120 of trustship Fig. 1.In alternative embodiment, machine can connect (such as
Networking) to the other machines in LAN, Intranet, extranet or internet.Machine can be in client-server network environment
In with the feature operation of server or client machine, or transported as peer machines in equity (or distributed) network environment
Row.Machine can be personal computer (PC), tablet computer, set-top box (STB), personal digital assistant (PDA), honeycomb electricity
Words, the network equipment, server, network router, interchanger or bridge or it is any be able to carry out one group of instruction (successively or its
His mode) any machine, described instruction specifies the action to be taken of the machine.Although in addition, only show individual machine,
Be term " machine " also should be considered as include execute alone or in combination one group (or multigroup) instruction with execute one described herein or
Any one any collection of machines of multiple methods.
Example computer system 700 includes processing equipment (processor) 702, ((such as the read-only memory of main memory 704
(ROM), flash memory, dynamic random access memory (DRAM) (such as synchronous dram (SDRAM), Double Data Rate (DDR
SDRAM) or DRAM (RDRAM)), static memory 706 (such as flash memory, static RAM (SRAM) etc.), with
And data storage device 718, they are in communication with each other via bus 730.
Processor (processing equipment) 702 indicates one or more general purpose processing devices, such as microprocessor, central processing list
Member etc..More specifically, processor 702 can be complex instruction set calculation (CISC) microprocessor, reduced instruction set computing
(RISC) microprocessor, very long instruction word (VLIW) microprocessor or processor or the realization instruction of realizing other instruction set
Collect multiple processors of combination.Processor 702 can also be one or more dedicated treatment facilities, such as application-specific integrated circuit
(ASIC), field programmable gate array (FPGA), digital signal processor (DSP), network processing unit etc..Processor 702 by with
It is set to and executes instruction 722, for carrying out operations described herein and step.
Computer system 700 may also include network interface device 708.It is single that computer system 700 may also include video display
First 710 (such as liquid crystal display (LCD) or cathode-ray tubes (CRT)), input equipment 712 (such as keyboard, alphanumeric key
Disk, motion sensing input equipment, touch screen), cursor control device 714 (such as mouse) and signal generate 716 (example of equipment
Such as loud speaker).Computer system 700 may also include camera 717, with record can directly store, be transferred to another position or
Both persons and can image.These images can be still photo or dynamic image, such as video or film.Camera 717 can be with
It is depth perception camera, RGB image can be captured and per pixel depth information.
Data storage device 718 may include non-transitory computer-readable storage media 728, be stored thereon with specific implementation
One or more instruction set 722 (such as software) of any one or more of method described herein or function.By
Computer system 700, main memory 704 and the processor 702 for constituting computer readable storage medium refer to during its execution
Enabling 722 can also completely or at least partially reside in main memory 704 and/or in processor 702.In addition, instruction 722 can
To transmit or receive on network 720 via network interface device 708.
In one embodiment, instruction 722 include be used for synthesizer (such as synthesizer 125 of Fig. 1) instruction and/or
Including calling the software library of the method for synthesizer.Although in the exemplary embodiment by 728 (machine of computer readable storage medium
Device readable storage medium storing program for executing) it is shown as single medium, but term " computer readable storage medium " should be considered as including storage one
A or multiple instruction collection single medium or multiple media (such as centralized or distributed database, and/or associated high speed
Caching and server).Term " computer readable storage medium " is it should also be understood that it includes that can store, encode or carry instructions to be
Collect so that machine executes and machine is made to carry out any medium of any one or more of disclosed method.Therefore, art
Language " computer readable storage medium " should be understood as including but not limited to solid-state memory, optical medium and magnetic medium.
Many details are given in description in front.But for those skilled in the art in benefit of this disclosure
Obviously, the disclosure can also be put into practice without these details.In some cases, well known knot is shown according to the form of block diagram
Structure and equipment rather than be shown specifically, in order to avoid the fuzzy disclosure.
Specific embodiment party is provided according to the algorithm of the operation to data bit in computer storage and symbolic indication
The some parts of formula.These algorithm descriptions and expression are that data processing field technical staff is used for most having the essence that they work
Effect it is communicated to the means of others skilled in the art.Here algorithm is typically considered being in harmony certainly of causing expected result
Sequence of steps.These steps need the physical manipulation to physical quantity.In general, although not necessarily, this tittle uses can
The form of the electric signal or magnetic signal that store, transmit, combine, compare and otherwise manipulate.For the reason of the usual purposes,
Verified is sometimes convenient these signals are known as bit, value, element, symbol, character, lexical item, number etc..
It should be borne in mind that all these and similar terms are all associated with appropriate physical quantity, and it is only to apply
In the facilitate label of this tittle.Unless separately specified according to following discussion is clear, it should be understood that throughout the specification,
Computer system is referred to using the discussion of the terms such as " reception ", " rendering ", " determination ", " selection " or similar electronics calculating is set
Standby action and processing, computer system or similar electronic computing device will be indicated as the register and memory of computer system
The data manipulation of interior physics (such as electronics) amount and being converted into be similarly represented as computer system memory or register or
Other data of physical quantity in other such information storages, transmission or display equipment.
To simplify the explanation, disclosed method is shown and described as a series of actions.But according to the dynamic of the disclosure
Work can occur according to various sequences and/or simultaneously, and occur together with other actions not presented and described herein.This
Outside, it may not be necessary to which all of the illustrated actions realizes the method according to disclosed theme.In addition, those skilled in the art answer
Work as understanding, via state diagram or event the method can be expressed as to a series of associated states as an alternative.In addition it should manage
Solution, method disclosed in this specification can be stored on product, and transporting and send to calculating by such method with promotion sets
It is standby.Terms used herein product is intended to cover the computer journey that can be accessed from any computer readable device or storage medium
Sequence.
The certain embodiments of the disclosure further relate to the device for being operated herein.The device can be configured to pre-
Phase purpose or it may include selectively be activated or reconfigured by by the computer program stored in computer it is general
Computer.Such computer program can store in a computer-readable storage medium, such as, but not limited to any kind of
Disk, including floppy disk, CD, CD-ROM and magneto-optic disk, read-only memory (ROM), random access memory (RAM), EPROM,
EEPROM, magnetic or optical card or any kind of medium suitable for storing e-command.
This specification means the reference of " embodiment " or " embodiment " to combine embodiment description
A particular feature, structure, or characteristic includes at least one embodiment.Therefore, the phrase throughout occurred in this specification
" in one embodiment " or " in embodiments " it is not necessarily all referring to identical embodiment.In addition, term "or" purport
Indicating the "or" of inclusive rather than exclusive "or".It is understood that described in the context of an embodiment
Feature can be combined with the feature described in the context in other embodiment.In addition, using word " example " herein or " showing
Example property " come indicate be used as example, example or explanation.Any scheme or design here depicted as " exemplary " are not necessarily explained
For or more advantage more advantageous than other schemes or design.On the contrary, being intended to specific side using word " example " or " exemplary "
Concept is presented in formula.
It should be appreciated that purpose described above be illustrative rather than it is restrictive.After reading and understanding above description, very
It will be obvious to those skilled in the art for more other embodiments.Therefore, the scope of the present disclosure should refer to appended
The full scope of the equivalent that claims and such claims are assigned determines.
It, can be in the case of system described herein collects the personal information about user or can utilize personal information
Chance is provided a user to control program or whether feature collects user information (such as the social networks, social dynamic about user
The information of the current location of work or activity, professional, user preference or user), or control whether and/or how to be taken from content
Business device receives content that may be more relevant with user.In addition, certain data can be before storage or use with one or more
Mode is handled, to remove personal recognizable information.For example, the identity of user can be handled so that can not be determined to user a
People can recognize that information, or can be extensive by the geographical location of user (such as to city, postal service in the case where obtaining location information
Coding or state rank) so that it can not determine the specific location of user.Therefore, user can be for controlling how collect about user's
Information and how to pass through content server use information.
It, can be in the case where system described herein collects the personal information about user or can utilize personal information
Chance is provided a user to control program or whether feature collects user information (such as the social networks, social dynamic about user
The information of the current location of work or activity, professional, user preference or user), or control whether and/or how to be taken from content
Business device receives content that may be more relevant with user.In addition, certain data can be before storage or use with one or more
Mode is handled so that the personal recognizable information of removal.For example, the identity of user can be handled so that can not be determined to user a
People can recognize that information, or can be extensive by the geographical location of user (such as to city, postal service in the case where obtaining location information
Coding or state rank) so that it can not determine the specific location of user.Therefore, user can be for controlling how collect about user's
Information and how to pass through content server use information.
Claims (12)
1. a kind of method, including：
The output image of scene described in multiple two-dimentional (2D) image creations of usage scenario；
For the pixel in the output image, multiple 2D pieces corresponding with the pixel are identified in the output image
Section；
The multiple 2D segments are converted into multiple three-dimensional (3D) segments by processing equipment；
The multiple body spans for being used for the pixel are created based on the multiple 3D segments by the processing equipment；
Based on the corresponding one or more 3D pieces in the multiple 3D segments for the integrated span in the multiple body span
The color contribution of section determines the color of the integrated span；And
The color of the pixel of the output image is determined from the identified color of the multiple body span.
2. according to the method described in claim 1, wherein, the multiple 2D images are captured by multiple cameras.
3. method according to claim 1 or 2, wherein the multiple 2D segments are converted to the multiple 3D segments packet
It includes：
It is added to each 2D segments and predefines thickness.
4. according to the method described in claim 3, wherein, the predefined thickness limits in disparity space.
5. according to the method described in claim 3, wherein, the predefined thickness limits in deep space.
6. method according to any preceding claims, wherein determine that the color of the body span includes：
Identify one or more 3D segments that color is contributed to the body span in the multiple 3D segments；And
Determine the color contribution of the one or more 3D segments identified in the multiple 3D segments.
7. according to the method described in claim 6, wherein, identifying in the multiple 3D segments and contributing color to the body span
One or more 3D segments include：Identify one with the part Chong Die with the body span in the multiple 3D segments
Or multiple 3D segments.
8. according to the method described in claim 6, wherein it is determined that one or more 3D identified in the multiple 3D segments
The color of segment is contributed：
Determine the length of the body span；
Determine the overall thickness of each 3D segments for the one or more 3D segments of the multiple 3D segments identified；And
By the length of the body span divided by the overall thickness.
9. according to the method described in claim 6,7 or 8, wherein determine one identified in the multiple 3D segments or
The color of multiple 3D segments is contributed：
Determine the summation of the color of identified 3D segments；
The summation of identified color is multiplied by the contribution of identified 3D segments.
10. method according to any preceding claims, wherein created based on the multiple 3D segments and be used for the pixel
The multiple body span include：
Mark the beginning event and End Event of the 3D segments；
The beginning event and End Event for the 3D segments that sort successively；And
It is limited for the multiple of the pixel based on the sequence successively of the beginning event of the 3D segments and End Event
The beginning event and End Event of body span.
11. a kind of system, including：
At least one processor；And
At least one processing equipment, is coupled to the memory, and at least one processing equipment is arranged to execute any
Method described in preceding claims.
12. a kind of nonvolatile computer-readable medium has the instruction stored on it, when described instruction is by user equipment
Processing equipment when executing so that the processing equipment perform claim requires the method described in any one of 1 to 10.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/156,192 US10681325B2 (en) | 2016-05-16 | 2016-05-16 | Continuous depth-ordered image compositing |
US15/156,192 | 2016-05-16 | ||
PCT/US2016/069168 WO2017200594A1 (en) | 2016-05-16 | 2016-12-29 | Continuous depth-ordered image compositing |
Publications (2)
Publication Number | Publication Date |
---|---|
CN108604389A true CN108604389A (en) | 2018-09-28 |
CN108604389B CN108604389B (en) | 2022-11-04 |
Family
ID=57851356
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680081768.3A Active CN108604389B (en) | 2016-05-16 | 2016-12-29 | Continuous depth-ordered image synthesis |
Country Status (4)
Country | Link |
---|---|
US (1) | US10681325B2 (en) |
EP (1) | EP3403241A1 (en) |
CN (1) | CN108604389B (en) |
WO (1) | WO2017200594A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN109800516A (en) * | 2019-01-24 | 2019-05-24 | 电子科技大学 | A kind of porous material flow field model building method based on DCGAN |
CN112767518A (en) * | 2020-12-22 | 2021-05-07 | 北京淳中科技股份有限公司 | Virtual animation special effect making method and device and electronic equipment |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10222958B2 (en) * | 2016-07-22 | 2019-03-05 | Zeality Inc. | Customizing immersive media content with embedded discoverable elements |
US10770113B2 (en) | 2016-07-22 | 2020-09-08 | Zeality Inc. | Methods and system for customizing immersive media content |
US11328437B2 (en) * | 2020-09-08 | 2022-05-10 | Weta Digital Limited | Method for emulating defocus of sharp rendered images |
US11308586B2 (en) | 2020-09-08 | 2022-04-19 | Unity Technologies Sf | Method for applying a vignette effect to rendered images |
Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20080074420A1 (en) * | 2006-09-27 | 2008-03-27 | Kuesel Jamie R | Pixel color accumulation in a ray tracing image processing system |
CN101243472A (en) * | 2005-08-09 | 2008-08-13 | 皇家飞利浦电子股份有限公司 | System and method for selective blending of 2D x-ray images and 3D ultrasound images |
CN101276479A (en) * | 2007-03-29 | 2008-10-01 | 国际商业机器公司 | Image process method and system |
US20130127895A1 (en) * | 2009-01-20 | 2013-05-23 | Gavin S. P. Miller | Method and Apparatus for Rendering Graphics using Soft Occlusion |
CN103632337A (en) * | 2012-05-07 | 2014-03-12 | 英特尔公司 | Real-time order-independent transparent rendering |
CN104052979A (en) * | 2013-03-12 | 2014-09-17 | 英特尔公司 | Apparatus and techniques for image processing |
CN104952100A (en) * | 2014-03-27 | 2015-09-30 | 英特尔公司 | Streaming compression anti-aliasing approach to deferred shading |
CN105283904A (en) * | 2013-06-03 | 2016-01-27 | 文塔纳医疗系统公司 | Image adaptive physiologically plausible color separation |
Family Cites Families (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5854631A (en) | 1995-11-22 | 1998-12-29 | Silicon Graphics, Inc. | System and method for merging pixel fragments based on depth range values |
KR100507780B1 (en) * | 2002-12-20 | 2005-08-17 | 한국전자통신연구원 | Apparatus and method for high-speed marker-free motion capture |
US20080158345A1 (en) * | 2006-09-11 | 2008-07-03 | 3Ality Digital Systems, Llc | 3d augmentation of traditional photography |
US8345956B2 (en) * | 2008-11-03 | 2013-01-01 | Microsoft Corporation | Converting 2D video into stereo video |
US8723789B1 (en) * | 2011-02-11 | 2014-05-13 | Imimtek, Inc. | Two-dimensional method and system enabling three-dimensional user interaction with a device |
KR101946019B1 (en) * | 2014-08-18 | 2019-04-22 | 삼성전자주식회사 | Video processing apparatus for generating paranomic video and method thereof |
US9699380B2 (en) * | 2015-11-03 | 2017-07-04 | Intel Corporation | Fusion of panoramic background images using color and depth data |
US9961283B2 (en) * | 2016-09-07 | 2018-05-01 | Essential Products, Inc. | Color reconstruction |
-
2016
- 2016-05-16 US US15/156,192 patent/US10681325B2/en active Active
- 2016-12-29 WO PCT/US2016/069168 patent/WO2017200594A1/en active Application Filing
- 2016-12-29 EP EP16829047.6A patent/EP3403241A1/en active Pending
- 2016-12-29 CN CN201680081768.3A patent/CN108604389B/en active Active
Patent Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101243472A (en) * | 2005-08-09 | 2008-08-13 | 皇家飞利浦电子股份有限公司 | System and method for selective blending of 2D x-ray images and 3D ultrasound images |
US20080074420A1 (en) * | 2006-09-27 | 2008-03-27 | Kuesel Jamie R | Pixel color accumulation in a ray tracing image processing system |
CN101276479A (en) * | 2007-03-29 | 2008-10-01 | 国际商业机器公司 | Image process method and system |
US20130127895A1 (en) * | 2009-01-20 | 2013-05-23 | Gavin S. P. Miller | Method and Apparatus for Rendering Graphics using Soft Occlusion |
CN103632337A (en) * | 2012-05-07 | 2014-03-12 | 英特尔公司 | Real-time order-independent transparent rendering |
CN104052979A (en) * | 2013-03-12 | 2014-09-17 | 英特尔公司 | Apparatus and techniques for image processing |
CN105283904A (en) * | 2013-06-03 | 2016-01-27 | 文塔纳医疗系统公司 | Image adaptive physiologically plausible color separation |
CN104952100A (en) * | 2014-03-27 | 2015-09-30 | 英特尔公司 | Streaming compression anti-aliasing approach to deferred shading |
Non-Patent Citations (1)
Title |
---|
LARS SCHNYDER，ET AL.: "2D TO 3D conversion of sports content using panoramas", 《IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING》 * |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN109800516A (en) * | 2019-01-24 | 2019-05-24 | 电子科技大学 | A kind of porous material flow field model building method based on DCGAN |
CN112767518A (en) * | 2020-12-22 | 2021-05-07 | 北京淳中科技股份有限公司 | Virtual animation special effect making method and device and electronic equipment |
CN112767518B (en) * | 2020-12-22 | 2023-06-06 | 北京淳中科技股份有限公司 | Virtual animation special effect manufacturing method and device and electronic equipment |
Also Published As
Publication number | Publication date |
---|---|
WO2017200594A1 (en) | 2017-11-23 |
EP3403241A1 (en) | 2018-11-21 |
CN108604389B (en) | 2022-11-04 |
US20170332063A1 (en) | 2017-11-16 |
US10681325B2 (en) | 2020-06-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11488355B2 (en) | Virtual world generation engine | |
JP6742474B2 (en) | User interaction analysis module | |
CN108604389A (en) | continuous depth ordering image synthesis | |
US10867416B2 (en) | Harmonizing composite images using deep learning | |
US11069094B1 (en) | Generating realistic makeup in a digital video stream | |
US11363329B2 (en) | Object discovery and exploration in video content | |
US11222479B2 (en) | Object customization and accessorization in video content | |
US11288867B2 (en) | Real-time exploration of video content | |
CN109803180A (en) | Video preview drawing generating method, device, computer equipment and storage medium | |
US10115149B1 (en) | Virtual world electronic commerce platform | |
Deng et al. | The design of tourism product CAD three-dimensional modeling system using VR technology | |
US20140082209A1 (en) | Personalized streaming internet video | |
US20230300292A1 (en) | Providing shared augmented reality environments within video calls | |
US20230164298A1 (en) | Generating and modifying video calling and extended-reality environment applications | |
O’Dwyer et al. | Jonathan Swift: augmented reality application for Trinity library’s long room | |
Zara | Virtual Reality course—A natural enrichment of Computer Graphics classes | |
CN107451196A (en) | Information recommendation method, device, equipment and system | |
Barszcz et al. | 3D scanning digital models for virtual museums | |
US20150264441A1 (en) | Generating new video content from pre-recorded video | |
Rebollo et al. | Three-dimensional trees for virtual globes | |
US20230368444A1 (en) | Rendering customized video call interfaces during a video call | |
US20240078745A1 (en) | Generation of a virtual viewpoint image of a person from a single captured image | |
US20240031519A1 (en) | Virtual field of view adjustment in live volumetric video | |
KR101908523B1 (en) | Method and system for generating and providing three-dimensional virtual reality contents from real objects and apparatus using the same | |
Hidayat et al. | The Augmented and Virtual Reality of Tourism and Creative Industry: Communicating Indonesia's New Way to the Digital Economy |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |