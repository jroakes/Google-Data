US10999578B2 - Transcoding media content using an aggregated quality score - Google Patents
Transcoding media content using an aggregated quality score Download PDFInfo
- Publication number
- US10999578B2 US10999578B2 US16/612,889 US201716612889A US10999578B2 US 10999578 B2 US10999578 B2 US 10999578B2 US 201716612889 A US201716612889 A US 201716612889A US 10999578 B2 US10999578 B2 US 10999578B2
- Authority
- US
- United States
- Prior art keywords
- media content
- score
- calibrated
- transcoded
- degradation
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/2343—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements
- H04N21/234309—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements by transcoding between formats or standards, e.g. from MPEG-2 to MPEG-4 or from Quicktime to Realvideo
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/124—Quantisation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/14—Coding unit complexity, e.g. amount of activity or edge presence estimation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/154—Measured or subjectively estimated visual quality after decoding, e.g. measurement of distortion
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/172—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a picture, frame or field
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/179—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being a scene or a shot
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/40—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video transcoding, i.e. partial or full decoding of a coded input stream followed by re-encoding of the decoded output stream
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/60—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding
- H04N19/61—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding in combination with predictive coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/23418—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving operations for analysing video streams, e.g. detecting features or characteristics
Definitions
- the quality of an encoded media content is a very important metric. Because of the amount of content being handled by these systems, it is necessary to automate the processes that monitor, verify, and even improve media content quality.
- At the heart of this challenge is the task of defining appropriate quantitative metrics that give meaningful indications about the quality of video and audio processing. In practice, however, these metrics may provide limited ways to meaningfully interpret their numerical values. Furthermore, these metrics are usually only meaningful when compared to values assigned to other media contents to determine which is better. It is difficult, however, to determine the magnitude of how much better a particular media content is.
- quality metrics usually make tradeoffs about how much “coverage” they provide within the domain of all possible audio and video content. Some metrics only do well on a subset of the domain (e.g., focusing on speech quality instead of general audio quality), while other metrics may generalize better to any media content but provide only a very specific measurement that cannot be interpreted as an overall quality measurement. Good coverage of a metric matters because different compressed videos may have different types of errors that are attributed to different root causes and that manifest in different manners. Metrics that focus only on one such root cause cannot characterize all these different aspects of “quality.” Furthermore, most metrics for audio and video quality are defined by modeling what makes audio and video be considered “good” or high quality.
- a method includes receiving, by one or more processors, an uploaded media content and obtaining, by the one or more processors, a transcoded media content.
- the transcoded media content is transcoded from the uploaded media content.
- the method further includes determining, by the one or more processors, a plurality of degradation metric values corresponding to the transcoded media content based on the uploaded media content and the transcoded media content. Each degradation metric value corresponds to a different degradation metric type.
- the method also includes mapping, by the one or more processors, each degradation metric value of the plurality of degradation metric values to a respective calibrated score to obtain a plurality of calibrated scores.
- the plurality of calibrated scores are all numerical values on a common interval.
- the method also includes determining, by the one or more processors, an aggregated quality score of the transcoded media content based on the plurality of calibrated scores and an exponential weighting function.
- the exponential weighting function exponentiates each of the calibrated scores by a respective weighting exponent and aggregates the exponentiated calibrated scores.
- the method further includes selectively reencoding, by the one or more processors, the transcoded media content based on the aggregated quality score.
- each of the respective weighting exponents is equal to a same constant value.
- each respective weighting exponent is specific to the respective calibrated score that the respective weighting exponent exponentiates.
- mapping each degradation metric value of the plurality of degradation metric values to a respective calibrated score includes, for each degradation metric value, obtaining a mapping mechanism corresponding to the degradation metric type of the degradation metric value and inputting the degradation metric value to the mapping mechanism to obtain the respective calibrated score.
- selectively reencoding the transcoded media content based on the aggregated quality score includes determining a predicted demand for the transcoded media content, determining a bitrate of the transcoded media content, determining a maximum score threshold and a lower score threshold based on the predicted demand. Furthermore, when the aggregated quality score is less than the maximum score threshold and greater than the lower score threshold, the method includes storing the transcoded media content. When the aggregated quality score is greater than the maximum score threshold, the method includes reencoding the uploaded media content at an increased bitrate that is greater than the bitrate of the transcoded media content. When the aggregated quality score is less than the lower score threshold, the method includes reencoding the uploaded media content at a decreased bitrate that is less than the bitrate of the transcoded media content.
- reencoding the transcoded media content based on the aggregated quality score includes comparing the aggregated quality score to a maximum score threshold. When the aggregated quality score is less than the maximum score threshold, the method includes storing the transcoded media content. When the aggregated quality score is greater than the maximum score threshold, the method includes adjusting one or more encoding parameters to decrease the aggregated quality score and reencoding the uploaded media content based on the adjusted encoding parameters.
- obtaining the transcoded media content includes receiving one or more encoding parameters and encoding the uploaded media content into the transcoded media content using the one or more encoding parameters.
- the transcoded media content includes video content and/or audio content.
- a media content delivery system includes a non-transitory storage that stores computer-readable data, a network interface, and one or more processors that execute computer-executable instructions.
- the instructions when executed, cause the one or more processors to receive an uploaded media content via the network interface and obtain a transcoded media content.
- the transcoded media content is transcoded from the uploaded media content.
- the instructions further cause the one or more processors to determine a plurality of degradation metric values corresponding to the transcoded media content based on the uploaded media content and the transcoded media content. Each degradation metric value corresponds to a different degradation metric type.
- the instructions further cause the one or more processors to map each degradation metric value of the plurality of degradation metric values to a respective calibrated score to obtain a plurality of calibrated scores.
- the plurality of calibrated scores are all numerical values on a common interval.
- the instructions further cause the one or more processors to determine an aggregated quality score of the transcoded media content based on the plurality of calibrated scores and an exponential weighting function.
- the exponential weighting function exponentiates each of the calibrated scores by a respective weighting exponent and aggregates the exponentiated calibrated scores.
- the instructions further cause the one or more processors to selectively reencode the transcoded media content based on the aggregated quality score.
- each of the respective weighting exponents is equal to a same constant value.
- each respective weighting exponent is specific to the respective calibrated score that the respective weighting exponent exponentiates.
- mapping each degradation metric value of the plurality of degradation metric values to a respective calibrated score includes, for each degradation metric value, obtaining a mapping mechanism corresponding to the degradation metric type of the degradation metric value, and inputting the degradation metric value to the mapping mechanism to obtain the respective calibrated score.
- selectively reencoding the transcoded media content based on the aggregated quality score includes determining a predicted demand for the transcoded media content, determining a bitrate of the transcoded media content and determining a maximum score threshold and a lower score threshold based on the predicted demand. Furthermore, when the aggregated quality score is less than the maximum score threshold and greater than the lower score threshold, the instructions cause the one or more processor to store the transcoded media content. When the aggregated quality score is greater than the maximum score threshold, the instructions cause the one or more processor to reencode the uploaded media content at an increased bitrate that is greater than the bitrate of the transcoded media content. When the aggregated quality score is less than the lower score threshold, the instructions cause the one or more processor to reencode the uploaded media content at a decreased bitrate that is less than the bitrate of the transcoded media content.
- reencoding the transcoded media content based on the aggregated quality score includes comparing the aggregated quality score to a maximum score threshold. When the aggregated quality score is less than the maximum score threshold, the instructions cause the one or more processor to store the transcoded media content. When the aggregated quality score is greater than the maximum score threshold, the instructions cause the one or more processor to adjust one or more encoding parameters to decrease the aggregated quality score and reencode the uploaded media content based on the adjusted encoding parameters.
- obtaining the transcoded media content includes receiving one or more encoding parameters and encoding the uploaded media content into the transcoded media content using the one or more encoding parameters.
- the transcoded media content includes video content and/or audio content.
- FIG. 1 is a schematic of a video encoding and decoding system.
- FIG. 2 is a block diagram of an example of a computing device that can implement a transmitting station or a receiving station.
- FIG. 3 is a diagram of a typical video stream to be encoded and subsequently decoded.
- FIG. 4 is a block diagram of an example of a media content delivery system.
- FIG. 5 is a flowchart illustrating a set of operations of a method for efficiently encoding a media content.
- bandwidth when streaming or otherwise delivering media content.
- media contents that are encoded at higher bitrates result in higher quality media contents
- media contents that are encoded at relatively lower bitrates result in lower quality media contents.
- Media contents that are encoded at these higher bitrates may consume increased storage space to store and increased bandwidth to deliver (e.g., stream or download).
- the quality gains that are realized by encoding the media content at a higher bitrate may not be discernable or of consequence to a consumer of the media content.
- the bandwidth consumed by a very popular media content that is streamed or otherwise delivered millions of times may be decreased by encoding the media content at a lower bitrate without substantially decreasing the overall quality of the media content.
- the present disclosure is directed to optimizing media encodings by determining an aggregated quality score of a transcoded media content.
- the aggregated quality score is an aggregation of a set of two or more calibrated scores.
- Each calibrated score is determined from a respective degradation metric value, where each degradation metric value corresponds to a different type of degradation metric.
- a first degradation metric value may be indicative of a degree of blockiness detected in the transcoded media content
- a second degradation metric may be indicative of a degree of blurriness detected in the transcoded media content.
- a first calibrated score may be determined from the blockiness degradation metric
- a second calibrated score may be determined from the blurriness degradation metric.
- the first and second calibrated scores reside on the same scale (e.g., between zero and one).
- the system may aggregate exponentiated (and potentially weighted) calibrated scores to obtain an aggregated quality score.
- the aggregated quality score may be used to determine whether to reencode the media content using new encoded parameters selected to improve or reduce the overall quality of the media content. According to some implementations, only degradation metrics are used to determine the calibrated scores
- a communication network 104 can connect the transmitting station 102 and a receiving station 106 for encoding and decoding of a media stream, such as a video stream or a media stream.
- the media stream can be encoded at the transmitting station 102
- the encoded media stream can be decoded at the receiving station 106 .
- the communication network 104 can be, for example, the Internet.
- the communication network 104 can also be a local area network (LAN), wide area network (WAN), virtual private network (VPN), cellular telephone network, or any other means of transferring the video stream from the transmitting station 102 to, in this example, the receiving station 106 .
- the receiving station 106 in one example, can be a computer having an internal configuration of hardware such as that described in FIG. 2 . However, other suitable implementations of the receiving station 106 are possible. For example, the processing of the receiving station 106 can be distributed among multiple devices.
- an implementation can omit the communication network 104 .
- a video stream can be encoded and then stored for transmission at a later time to the receiving station 106 or any other device having memory.
- the receiving station 106 receives (e.g., via the communication network 104 , a computer bus, and/or some communication pathway) the encoded video stream and stores the video stream for later decoding.
- a real-time transport protocol RTP
- a transport protocol other than RTP may be used, e.g., a Hypertext Transfer Protocol-based (HTTP-based) video streaming protocol.
- FIG. 2 is a block diagram of an example of a computing device 200 that can implement a transmitting station or a receiving station.
- the computing device 200 can implement one or both of the transmitting station 102 and the receiving station 106 of FIG. 1 .
- the computing device 200 can be in the form of a computing system including multiple computing devices, or in the form of one computing device, for example, a mobile phone, a tablet computer, a laptop computer, a notebook computer, a desktop computer, a server computer, and the like.
- a CPU 202 in the computing device 200 can be a conventional central processing unit.
- the CPU 202 can be any other type of device, or multiple devices, now existing or hereafter developed, capable of manipulating or processing information.
- the disclosed implementations can be practiced with one processor as shown, e.g., the CPU 202 , advantages in speed and efficiency can be achieved using more than one processor.
- a memory 204 in the computing device 200 can be a read-only memory (ROM) device or a random-access memory (RAM) device in an implementation. Any other suitable type of storage device can be used as the memory 204 .
- the memory 204 can include code and data 206 that is accessed by the CPU 202 using a bus 212 .
- the memory 204 can further include an operating system 208 and application programs 210 , the application programs 210 including at least one program that causes the CPU 202 to perform the methods described herein.
- the application programs 210 can include applications 1 through N, which further include a video coding application that performs the methods described herein.
- the computing device 200 can also include a secondary storage 214 , which can, for example, be a memory card used with a mobile computing device. Because the video communication sessions may contain a significant amount of information, they can be stored in whole or in part in the secondary storage 214 and loaded into the memory 204 as needed for processing.
- the computing device 200 can also include one or more output devices, such as a display 218 .
- the display 218 may be, in one example, a touch sensitive display that combines a display with a touch sensitive element that is operable to sense touch inputs.
- the display 218 can be coupled to the CPU 202 via the bus 212 .
- Other output devices that permit a user to program or otherwise use the computing device 200 can be provided in addition to or as an alternative to the display 218 .
- the output device is or includes a display
- the display can be implemented in various ways, including by a liquid crystal display (LCD), a cathode-ray tube (CRT) display or light emitting diode (LED) display, such as an organic LED (OLED) display.
- LCD liquid crystal display
- CRT cathode-ray tube
- LED light emitting diode
- OLED organic LED
- the computing device 200 can also include or be in communication with an image-sensing device 220 , for example, a camera, or any other image-sensing device 220 , now existing or hereafter developed, that can sense an image such as the image of a user operating the computing device 200 .
- the image-sensing device 220 can be positioned such that it is directed toward the user operating the computing device 200 .
- the position and optical axis of the image-sensing device 220 can be configured such that the field of vision includes an area that is directly adjacent to the display 218 and from which the display 218 is visible.
- FIG. 2 depicts the CPU 202 and the memory 204 of the computing device 200 as being integrated into one unit, other configurations can be utilized.
- the operations of the CPU 202 can be distributed across multiple machines (wherein individual machines can have one or more processors) that can be coupled directly or across a local area or other network.
- the memory 204 can be distributed across multiple machines, such as a network-based memory or memory in multiple machines performing the operations of the computing device 200 .
- the frame 306 may be further subdivided into frame blocks 310 , which can contain data corresponding to, for example, 16 ⁇ 16 pixels in the frame 306 .
- the frame blocks 310 can also be arranged to include data from one or more segments 308 of pixel data.
- the frame blocks 310 can also be of any other suitable size, such as 4 ⁇ 4 pixels, 8 ⁇ 8 pixels, 16 ⁇ 8 pixels, 8 ⁇ 16 pixels, 16 ⁇ 16 pixels, or larger. Unless otherwise noted, the terms block and macroblock are used interchangeably herein.
- FIG. 4 is a block diagram of an example of a media content delivery system 400 .
- the media content delivery system 400 may be configured to stream or otherwise deliver media, such as video content and/or audio content, to a receiving station 106 .
- the media content delivery system 400 includes a media content generator 402 ; a media content uploader 404 ; a transmitting station, such as the transmitting station 102 , described above; a communication network, such as the communication network 104 , described above; and a receiving station, such as the receiving station 106 , described above.
- the media content uploader 404 is configured to upload media content generated by the media content generator 402 to the transmitting station 102 .
- the media content uploader 404 may include any suitable media content uploader, such as a software application running on a computing device, such as the computing device 200 described above.
- a user may select one or more media contents to upload to the transmitting station 102 .
- the media content uploader 404 may upload the selected media contents to the transmitting station.
- the media content uploader 404 may encode the media content using any suitable video and/or audio codec before uploading the media content to the transmitting station 102 .
- the media content encoder 408 is configured to encode the intermediate media content according to a media content coding scheme.
- the media content encoder 408 may implement one or more video and/or audio codecs to encode the media content.
- the media content encoder 408 may encode the intermediate media content (or the chunks that make up the intermediate media content) into one or more transcoded media contents.
- the media content encoder 408 may encode each transcoded media content into a respective format (e.g., at different spatial resolutions such as 4 k, 1080p, 720p, 480p, 360p, 240p, etc.). In this way, the transcoded media contents can be played on different types of receiving stations.
- the media content encoder 408 may receive a set of encoding parameters.
- the encoding parameters may define the settings with which the transcoded media content is encoded.
- the encoding parameters may include a bitrate at which the transcoded media content is encoded, the motion parameters that are used to encode the transcoded media content, the quantization parameters used to encode the transcoded media content, deblocking filter parameters, and/or any other suitable parameters.
- Each of the encoding parameters may be adjusted to improve the quality of the media content. The improved quality, however, may come at the expense of storage, bandwidth consumption, and/or decoding times.
- the media content encoder 408 outputs the one or more transcoded media contents.
- the media content preprocessor 406 does not generate an intermediate media content.
- the media content encoder 408 may be configured to transcode the uploaded media content directly into the transcoded media content.
- the media content encoder 408 may receive a set of encoding parameters.
- the encoding parameters may define the settings with which the transcoded media content is encoded.
- the encoding parameters may include a bitrate at which the transcoded media content is encoded, the motion parameters that are used to encode the transcoded media content, the quantization parameters used to encode the transcoded media content, deblocking filter parameters, and/or any other suitable parameters. Each of the encoding parameters may be adjusted to improve the quality of the media content.
- the media content encoder 408 may receive the uploaded media content and may encode the uploaded media content into the transcoded media content based on the encoding parameters.
- the degradation metrics may include, but are not limited to, a blocking metric, a blurring metric, a ringing metric, a noise metric, a banding metric, a jitter metric, a flicker metric, a saliency metric, a temporal consistency metric, a local motion saliency metric, a sharpness or modulation transfer function metric, a peak-signal-to-noise metric, a structural similarity (SSIM) metric, a self-reference based learning-free evaluation of quality (SLEEQ) metric, an interlacing or staircase metric, a distortion metric, and/or a warping metric.
- a blocking metric e.g., a blurring metric
- a ringing metric e.g., a blurringing metric
- noise metric e.g., a blurringing metric
- a banding metric e.g., a jitter metric,
- the blocking metric may be a measure of blockiness detected in the transcoded media content. Blockiness can be observed at the pixels around the borders of a block edge.
- the blocking metric may be a numerical value that is determined by comparing the pixels of the uploaded media content and the pixels of the transcoded media content at the borders of each block edge.
- the noise metric may be a measurement of noise artifacts that are detected in the media content.
- Noise may be spatial and/or temporal.
- the noise metric may be a numerical value that is determined from the transcoded media content.
- Spatial noise may be determined in high frequencies fit to a noise model.
- Temporal noise may be determined by performing a multi-frame transformation (e.g., 3d-FFT) to estimate the power spectral density (PSD), and a noise-to-signal ratio may be measured.
- a multi-frame transformation e.g., 3d-FFT
- the blurring metric may be a measurement of blurriness artifacts that are detected in the transcoded media content.
- the blurring metric may be a numerical value that is determined from the transcoded media content and the uploaded media content.
- the blurring metric may be determined by comparing the pixel values around a region in a frame compared relative to one another and then comparing the pixel values in a corresponding frame of the uploaded media content.
- the jitter metric may be a measurement of jitter artifacts that are detected in the transcoded media content.
- the jitter metric may be a numerical value that is determined from the transcoded media content and the uploaded media content.
- the jitter metric may be determined by comparing irregular motion patterns in a frame sampling in the transcoded media content to a corresponding frame sampling in the uploaded media content.
- the saliency metric is a measurement of saliency that is observed in the transcoded media content.
- Saliency describes the uniqueness of qualities of a pixel relative to other pixels in an image or frame.
- the saliency metric may be a feature of the transcoded media content that is expressed as a numerical ratio that is determined from the transcoded media content.
- the saliency metric may be determined by segmenting pixels based on the intensity of each pixel and then measuring the contrast between the segments of pixels.
- the temporal consistency metric is a measurement of temporal consistency in the transcoded media content.
- the temporal consistency metric may be a feature of the transcoded media content that is expressed as a numerical ratio that is determined from the transcoded media content.
- the temporal consistency metric may be measured by determining the magnitude of significant jumps in a first derivative of frame level pixel intensity across the transcoded media content.
- the local motion saliency metric is a measurement of local motion saliency artifacts that are detected in the transcoded media content.
- the local motion saliency metric may be a numerical value that is determined based on the transcoded media content and the uploaded media content.
- the local motion saliency metric may be determined by comparing the texture variation between the most significant saliency segments (both spatial and temporal) in the frames of the transcoded media content with the most significant saliency segments (both spatial and temporal) in the frames of the uploaded media content.
- the sharpness metric (or modulation transfer function metric) is a quality measurement of the sharpness (e.g., the clarity of detail) of the transcoded media content.
- the sharpness metric is a quality measurement that can be determined from the transcoded media content.
- the sharpness metric may be determined by performing a point spread function on various rows of pixels that are used for power-spectral density calculation.
- the peak-signal-to-noise ratio metric is a quality measurement of the ratio between the power of a media signal and the power of the corrupting noise that affects the fidelity of the signal's representation.
- the peak-signal-to-noise metric may be a numerical ratio that is expressed in decibels and may be determined from the transcoded media content and the uploaded media content.
- the peak-signal-to-noise metric may be determined by determining a mean square error based on the differences in pixel values from the transcoded media content and the uploaded media content.
- the peak-signal-to-noise metric may be determined from the entropy in the mean square error.
- the SLEEQ metric is a quality measurement.
- the SLEEQ metric is a numerical value that can be determined from the transcoded media content and the uploaded media content.
- the SLEEQ metric may be determined by calculating, for both the transcoded media content and the uploaded media content, a deviation of the generalized pixel distribution from a normal distribution.
- the interlacing metric (or staircase metric) is a measurement of motion artifacts that are detected in the transcoded media content due to interlacing of frames.
- the interlacing metric may be a numerical value that can be determined from the transcoded media content and the uploaded media content.
- the interlacing metric may be determined by measuring edge pixels in a frame against each other with a differential operator and comparing the result with the same measurement performed on the uploaded media content.
- the distortion metric is a measurement of distortion artifacts that are detected in the transcoded media content.
- the distortion metric may be a numerical ratio that is determined based on the transcoded media content and the uploaded content.
- the distortion metric may be determined by measuring pixel differences radially for the transcoded media content and the uploaded media content and determining ratios of first and second derivatives that are matched separately for the transcoded media content and the uploaded media content.
- the warping metric is a measurement of warping artifacts that are detected in the transcoded media content.
- the warping metric may be a numerical ratio that is determined based on the transcoded media content and the uploaded media content.
- the warping metric may be determined by measuring, for both the transcoded media content and the uploaded media content, the horizontal, vertical, and diagonal edges within a region of pixels and comparing the measurements corresponding to the transcoded media content with those of the uploaded media content.
- the quality scoring module 410 maps the degradation metric to a respective calibrated score.
- Calibrated scores are values on a common interval (e.g., between 0 and 1, or between 1 and 5).
- the calibrated scores may be mapped to one of 0, 0.25, 0.5, 0.75, and 1.0, where 0 corresponds to “excellent quality,” 0.25 corresponds to “quality degradation is just noticeable for this aspect,” 0.5 corresponds to “quality degradation is obvious but tolerable,” 0.75 corresponds to “quality degradation is obvious and not tolerable,” and 1.0 corresponds to “quality is extremely poor for this aspect.”
- the quality scoring module 410 may utilize a mapping mechanism that is trained to map a particular degradation metric value to a corresponding calibrated score.
- a mapping mechanism can be any suitable mechanism that maps a particular metric to an opinion score.
- a mapping mechanism may be a mapping function or a lookup table.
- Each mapping mechanism can be determined empirically.
- the mapping mechanisms are learned in a supervised manner. For example, a group of test users (e.g., 100 or 1000 users) may be presented with media contents that have only one observable degradation quality.
- the users may be presented with various media contents (e.g., videos and/or audio) that contain various amounts of blocking artifacts, but that otherwise do not include any observable degradation artifacts or errors.
- Users can rate the media contents as being one of: “excellent quality;” “quality degradation is just noticeable for this aspect;” “quality degradation is obvious but tolerable;” “quality degradation is obvious and not tolerable;” and “quality is extremely poor for this aspect.”
- the training module (not shown) can learn which degrees of blockiness correspond to which ratings or calibrated scores. In this way, when a transcoded media content has a particular degree of blockiness, the mapping mechanism can map the degree of blockiness to one of the calibrated scores.
- the mapping mechanisms for each other monitored degradation metrics can be determined in a similar manner.
- the value of a relatively poor degradation metric value may be magnified relative to otherwise tolerable degradation metric values. In this way, even if only one type of degradation artifact or error is observed in a media content, the presence of such degradation artifacts may be sufficient to trigger a reencoding of the media content, as will be discussed below.
- the quality scoring module 410 may determine the aggregated quality score by exponentiating each calibrated score with a respective weighting exponent that corresponds to the type of degradation metric from which the calibrated score was determined. In these implementations, the quality scoring module 410 may penalize some types of degradation metrics more heavily than other degradation metrics. For instance, if the calibrated scores are scored on the interval of [0, 1], calibrated scores exponentiated by weighting exponents much greater than one (e.g., three, four, or five) correspond to degradation metrics that are relatively less important than degradation metrics whose calibrated scores are exponentiated by weighting exponents that are closer in value to one (e.g., two).
- calibrated scores exponentiated by weighting exponents much greater than one correspond to degradation metrics that are relatively more important than degradation metrics whose calibrated scores are exponentiated by weighting exponents that are closer in value to one (e.g., two).
- the optimization module 412 receives the aggregated quality score and determines whether the encoding of the transcoded media content is optimized based on the aggregated quality score. In some implementations, the optimization module 412 may determine a transcoded media content to be optimized if the aggregated quality score is less than a maximum score threshold. In these implementations, the maximum score threshold may be empirically determined to ensure that no transcoded media content is streamed or transmitted if it does not meet a minimum standard. For example, a group of test users may consume media contents (e.g., watch videos) of varying quality, with each media content having an aggregated quality score associated therewith.
- media contents e.g., watch videos
- the test users may rate the media contents on a scale, such as: “excellent,” “good,” “OK, but watchable/audible,” “not good, barely watchable/audible,” and “very poor.”
- the maximum score threshold may be based on the aggregated quality scores of media contents where a substantial number of the test users deemed the quality to be just good enough to consume and the aggregated quality scores of media contents where a substantial number of the test users deemed the quality too poor to consume. Put another way, the maximum score threshold may be indicative of video/audio quality that is the border between consumable and non-consumable media content.
- the optimization module 412 can determine whether the media content needs to be reencoded based on the comparison. When the aggregated quality score is greater than the maximum score threshold, the optimization module 412 determines that the media content needs to be reencoded. In response to this determination, the optimization module 412 may determine one or more updated encoding parameters with which the media content will be reencoded. For example, the optimization module 412 may determine an increased bitrate that is greater than the bitrate of the transcoded media content. The optimization module 412 may additionally or alternatively determine updated motion parameters, quantizing parameters, and/or deblocking filter parameters. The updated encoding parameters may be selected to improve the quality of the subsequent encoding.
- the optimization module 412 may determine whether a transcoded media content needs to be optimized based on the aggregated quality score, a maximum threshold, and a lower threshold. In these implementations, the optimization module 412 determines that the transcoded media content needs to be optimized if the aggregated quality score is greater than a maximum score threshold or less than a lower score threshold. In these implementations, the optimization module 412 is configured to balance the need for consumable media contents and the need to reduce the amount of storage to store the media contents and/or the bandwidth used to deliver the media contents to a receiving station 106 , both of which are significant costs to a large-scale media processing infrastructure. In these implementations, the maximum score threshold may be determined empirically, as was described above.
- the lower score threshold may be determined empirically. For example, a group of test users may consume media contents that have relatively low aggregated quality scores (which tend to denote high quality encodings). The test users may rate the overall quality of the media contents on a scale, such as “excellent,” “good,” “OK, but watchable/audible,” “not good, barely watchable/audible,” and “very poor.”
- the lower score threshold may be determined based on the ratings that are collected from the test users for the various media contents.
- the lower score threshold may be indicative of aggregated quality scores where a substantial number of users begin to notice artifacts in the media content.
- the lower score threshold may correspond to the aggregated quality scores where users begin to discern degradation artifacts in media contents.
- the optimization module 412 can determine whether the quality of the encoding is too good, such that the transcoded media content is likely using too much storage space and/or bandwidth.
- the optimization module 412 compares the aggregated quality score of the transcoded media content with the maximum score threshold and the lower score threshold. If the aggregated quality score is less than the maximum score threshold and greater than the lower score threshold, the optimization module 412 determines that the encoding of the transcoded media content is optimized, and stores or transmits the transcoded media content. If the aggregated quality score is greater than the maximum score threshold or less than the lower score threshold, the optimization module 412 determines updated encoding parameters and instructs the media content encoder 408 to reencode the media content using the updated encoding parameters.
- the optimization module 412 instructs the media content encoder 408 to reencode the media content using the updated encoding parameters.
- the media content encoder 408 may retrieve the intermediate media content from storage and may encode the intermediate media content using the updated encoding parameters to obtain the transcoded media content, which is encoded using the updated encoding parameters.
- the media content encoder 408 may retrieve the uploaded media content and may encode the uploaded media content using the updated encoding parameters.
- the optimization module 412 may utilize different lower score thresholds depending on a predicted popularity of the media content. For example, media contents that are likely to be popular (e.g., predicted to have more than a million views or downloads) will inherently require more bandwidth than media contents predicted to be less popular. Furthermore, more popular media contents may be cached at various network nodes to decrease download times. Thus, media contents that are more likely to be popular are likely to require more storage space across a network. Thus, to reduce the storage and bandwidth requirements associated with delivering more popular media contents, the lower score threshold for more popular media contents may be relatively higher than lower score thresholds for less popular media contents. In this way, a large-scale media processing infrastructure may improve its operational efficiency by using different lower score thresholds for media contents of varying popularity or predicted popularity.
- the media content transmitter 414 is configured to transmit or communicate the encoded media content over the communication network 104 .
- the media content transmitter 414 may transmit the transcoded media content to the receiving station 106 via the communication network 104 .
- the media content transmitter 414 may transmit or communicate the encoded media content using any suitable transmission or communications protocol.
- the media content transmitter 414 may be implemented to support distributed transmission of the transcoded media content.
- the receiving station 106 is configured to receive the transcoded media content, as described above.
- the media content decoder 416 is configured to decode the transcoded media content according to the media content scheme used to encode the transcoded media content, as described above.
- the media content display 418 may include any suitable display, such as the display 218 of the computing device 200 , as described above.
- the media content display 418 is configured to display the decoded media content, for example, for viewing by a consumer of the media content using a media content viewing application (e.g., a media content viewing application installed on the computing device 200 , a web-based media content viewing application, or other suitable media content viewing application).
- a media content viewing application e.g., a media content viewing application installed on the computing device 200 , a web-based media content viewing application, or other suitable media content viewing application.
- FIG. 5 is a flowchart illustrating an example set of operations of a method 500 for efficiently encoding a media content.
- the method 500 is described with respect to the transmitting station of FIG. 4 .
- the method 500 may be performed, however, by any other suitable computing system.
- the transmitting station 102 receives the uploaded media content from a media content uploader 404 .
- the media content uploader 404 is configured to upload media content generated by the media content generator 402 to the transmitting station 102 .
- the media content uploader 404 may encode the media content using any suitable video and/or audio codec before uploading the media content to the transmitting station 102 .
- the transmitting station 102 transcodes the uploaded media content to a transcoded media content.
- the media content preprocessor 406 is configured to receive the uploaded media content and to preprocess the uploaded media content. For example, the media content preprocessor 406 may decode the uploaded media content into an intermediate media content. The media content preprocessor 406 may utilize the appropriate codec to decode the uploaded media content into the intermediate media content. The media content preprocessor 406 may perform other suitable processes to improve the quality of the media content. In some implementations, the media content preprocessor 406 may chunk the intermediate media content into a series of chunks. In doing so, the media content encoder 408 may encode the chunks of the intermediate media content in a parallel and/or distributed manner.
- the media content preprocessor 406 may be configured to chunk the uploaded media content into a series of chunks, such that the chunks of the uploaded media content may be encoded in a parallel and/or distributed manner.
- the media content encoder 408 obtains the intermediate media content or the uploaded media content and encodes the intermediate media content or the uploaded media content according to a media content coding scheme. In some implementations, the media content encoder 408 receives the intermediate media content or the uploaded media content from the media content preprocessor 406 . Additionally or alternatively, the media content preprocessor 406 stores the intermediate media content or the uploaded media content in storage, and the media content encoder 408 may retrieve the intermediate media content or the uploaded media content from storage at a later time. The media content encoder 408 may implement one or more video and/or audio codecs to encode the media content.
- the media content encoder 408 may encode the intermediate media content (or the chunks that make up the intermediate media content) or the uploaded media content (or the chunks that make up the uploaded media contents) into one or more transcoded media contents.
- the media content encoder 408 may transcode each transcoded media content into a respective format (e.g., 4 k, 1080p, 720p, 480p, 360p, 240p, etc.). In this way, the transmitting station 102 can support a number of different requests and provide transcoded media content to different types of devices.
- the media content encoder 408 is described as encoding one transcoded media content. Operations 504 - 514 may be performed multiple times to support the transcoding of more than one transcoded media content.
- the media content encoder 408 may receive a set of encoding parameters.
- the encoding parameters may define the settings with which the transcoded media content is encoded.
- the encoding parameters may include a bitrate at which the transcoded media content is encoded, the motion parameters that are used to encode the transcoded media content, the quantization parameters used to encode the transcoded media content, deblocking filter parameters, and/or any other suitable parameters.
- Each of the encoding parameters may be adjusted to improve or reduce the video quality and/or the size of the transcoded media content.
- the media content encoder 408 receives the encoding parameters and encodes the intermediate media content or the uploaded media content into a transcoded media content. Upon completing the encoding, the media content encoder 408 outputs the transcoded media content.
- the media content encoder 408 may output the transcoded media content to storage, to the quality scoring module 410 , or to the media content transmitter 414 .
- the transmitting station 102 determines degradation metric values corresponding to the transcoded media content based on the uploaded media content and the transcoded media content.
- the quality scoring module 410 determines two or more degradation metric values corresponding to the transcoded media content in view of the uploaded media content.
- the degradation metrics may be metrics associated with artifacts, features, and errors that contribute to reducing the quality of the video.
- the degradation metrics may include, but are not limited to, a blocking metric, a blurring metric, a ringing metric, a noise metric, a banding metric, a jitter metric, a flicker metric, a saliency metric, a temporal consistency metric, a local motion saliency metric, a sharpness or modulation transfer function metric, a peak-signal-to-noise metric, a structural similarity (SSIM) metric, a self-reference based learning-free evaluation of quality (SLEEQ) metric, an interlacing or staircase metric, a distortion metric, and/or a warping metric.
- the foregoing listed degradation metrics are provided for example only.
- the quality scoring module 410 may collect/monitor/determine any other additional or alternative degradation metrics. Each of these degradation metric values may be measured on different scales. The quality scoring module 410 may determine the degradation metric values in any suitable manner.
- the transmitting station 102 maps each degradation metric value to a respective calibrated score.
- the quality scoring module 410 maps the degradation metric to a respective calibrated score.
- Calibrated scores are values on a common interval (e.g., between 0 and 1, or between 1 and 5).
- the quality scoring module 410 may utilize a mapping mechanism that is trained to map a particular degradation metric value to a corresponding calibrated score.
- a mapping mechanism can be any suitable mechanism that maps a particular metric to an opinion score.
- a mapping mechanism may be a mapping function or a lookup table. Each mapping mechanism can be determined empirically. In some implementations, the mapping mechanisms are learned in a supervised manner, as was described above.
- the quality scoring module 410 obtains a mapping mechanism corresponding to the degradation metric type of the metric value, and determines a calibrated score based on the degradation metric value and the mapping mechanism.
- ⁇ is a constant value, such that each calibrated score is exponentiated by the same value. By exponentiating each calibrated score, the value of a relatively poor degradation metric value may be magnified relative to otherwise tolerable degradation metric values.
- the quality scoring module 410 may determine the aggregated quality score by exponentiating each calibrated score with a respective weighting exponent that corresponds to the type of degradation metric from which the calibrated score was determined. In these implementations, the quality scoring module 410 may penalize some types of degradation metrics more heavily than other degradation metrics. For instance, if the calibrated scores are scored on the interval of [0, 1] (with zero being the best and one being the worst), calibrated scores exponentiated by weighting exponents much greater than one (e.g., three, four, or five) correspond to degradation metrics that are relatively less important than degradation metrics whose calibrated scores are exponentiated by weighting exponents that are closer in value to one (e.g., two).
- calibrated scores exponentiated by weighting exponents much greater than one correspond to degradation metrics that are relatively more important than degradation metrics whose calibrated scores are exponentiated by weighting exponents that are closer in value to one (e.g., two).
- each weighting exponent ( ⁇ i ) may be selected based on the relative importance of the calibrated score (m i ) being exponentiated. In these implementations, the weighting exponents may be determined empirically based on feedback provided from test users.
- the transmitting station 102 determines whether the encoding of the transcoded media content is optimized based on the aggregated quality score.
- the optimization module 412 receives the aggregated quality score and determines whether the encoding of the transcoded media content is optimized based on the aggregated quality score.
- the optimization module 412 may determine a transcoded media content to be optimized if the aggregated quality score is greater than a maximum score threshold.
- the maximum score threshold may be empirically determined to ensure that no media content is streamed or transmitted if it does not meet a minimum quality standard.
- the optimization module 412 can determine whether the media content is optimized (e.g., needs to be reencoded) based on the comparison.
- the optimization module 412 may determine whether a transcoded media content needs to be optimized based on the aggregated quality score, a maximum threshold, and a lower threshold. In these implementations, the optimization module 412 determines that the transcoded media content needs to be optimized (e.g., either needs to be reencoded or needs a reduction in quality) if the aggregated quality score is greater than a maximum score threshold or less than a lower score threshold. In these implementations, the optimization module 412 is configured to balance the need for consumable media contents and the need to reduce the amount of storage to store the media contents and/or the bandwidth used to deliver the media contents to a receiving station 106 , both of which are significant costs to a large-scale media processing infrastructure.
- the maximum score threshold and the lower score threshold may be determined empirically.
- the lower score threshold may be indicative of aggregated quality scores where a substantial number of users begin to notice artifacts in the media content.
- the optimization module 412 compares the aggregated quality score of the transcoded media content with the maximum score threshold and the lower score threshold to determine whether the transcoded media content needs to be optimized.
- the transmitting station 102 selectively reencodes the media content when the transcoded media content is not optimized.
- the transmitting station 102 may determine to reencode when the aggregated quality score is too high (i.e., the quality is poor). In other implementations, the transmitting station 102 may determine to reencode when the aggregated quality score is too high or too low (i.e., the quality is poor or the quality is too good).
- the optimization module 412 determines whether to reencode the media content by comparing the aggregated content score to the maximum score threshold. When the aggregated quality score is greater than the maximum score threshold, the optimization module 412 determines that the media content needs to be reencoded. In response to this determination, the optimization module 412 may determine one or more updated encoding parameters with which the media content will be reencoded. For example, the optimization module 412 may determine an increased bitrate that is greater than the bitrate of the transcoded media content. The optimization module 412 may additionally or alternatively determine updated motion parameters, quantizing parameters, and/or deblocking filter parameters. The updated encoding parameters may be selected to improve the quality of the subsequent encoding.
- the optimization module 412 instructs the media content encoder 408 to reencode the media content using the updated encoding parameters.
- the media content encoder 408 may retrieve the intermediate media content or the uploaded content and may encode the intermediate media content or the uploaded media content using the updated encoding parameters. It is noted that upon reencoding the media content, operations 504 , 506 , 508 , 510 , 512 , and 514 may be performed again.
- the optimization module 412 determines the updated encoding parameters to improve the overall quality of the media content. For example, the optimization module 412 may determine an increased bitrate that is greater than the bitrate of the transcoded media content. The optimization module 412 may additionally or alternatively determine updated motion parameters, quantizing parameters, and/or deblocking filter parameters that would improve the overall quality of the transcoded media content.
- the optimization module 412 determines the updated encoding parameters to decrease the overall quality of the media content in order to reduce the size of the transcoded media content. For example, the optimization module 412 may determine a decreased bitrate that is less than the bitrate of the transcoded media content. The optimization module 412 may additionally or alternatively determine updated motion parameters, quantizing parameters, and/or deblocking filter parameters that would decrease the overall size of the transcoded media content.
- the optimization module 412 instructs the media content encoder 408 to reencode the media content using the updated encoding parameters.
- the media content encoder 408 may retrieve the intermediate media content or the uploaded media content and may encode the intermediate media content or the uploaded media content using the updated encoding parameters.
- example is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as “example” is not necessarily to be construed as being preferred or advantageous over other aspects or designs. Rather, use of the word “example” is intended to present concepts in a concrete fashion.
- the term “or” is intended to mean an inclusive “or” rather than an exclusive “or”. That is, unless specified otherwise or clearly indicated otherwise by the context, the statement “X includes A or B” is intended to mean any of the natural inclusive permutations thereof. That is, if X includes A; X includes B; or X includes both A and B, then “X includes A or B” is satisfied under any of the foregoing instances.
- Implementations of the transmitting station 102 and/or the receiving station 106 can be realized in hardware, software, or any combination thereof.
- the hardware can include, for example, computers, intellectual property (IP) cores, application-specific integrated circuits (ASICs), programmable logic arrays, optical processors, programmable logic controllers, microcode, microcontrollers, servers, microprocessors, digital signal processors, or any other suitable circuit.
- IP intellectual property
- ASICs application-specific integrated circuits
- programmable logic arrays optical processors
- programmable logic controllers microcode, microcontrollers, servers, microprocessors, digital signal processors, or any other suitable circuit.
- signal processors should be understood as encompassing any of the foregoing hardware, either singly or in combination.
- signals and “data” are used interchangeably. Further, portions of the transmitting station 102 and the receiving station 106 do not necessarily have to be implemented in the same manner.
- implementations of the present disclosure can take the form of a computer program product accessible from, for example, a computer-usable or computer-readable medium.
- a computer-usable or computer-readable medium can be any device that can, for example, tangibly contain, store, communicate, or transport the program for use by or in connection with any processor.
- the medium can be, for example, an electronic, magnetic, optical, electromagnetic, or semiconductor device. Other suitable mediums are also available.
Abstract
Description
M=Σi=0 Nαimi γ
where M is the aggregated quality score, N is a total number of different degradation metrics represented in the plurality of degradation metric values, mi is an ith calibrated score of the plurality of calibrated scores, αi is a weighting factor corresponding to the ith calibrated score, and γ is the weighting exponent.
M=Σi=0 Nαimi γ
\where M is the aggregated quality score, N is a total number of different degradation metrics represented in the plurality of degradation metric values, mi is an ith calibrated score of the plurality of calibrated scores, αi is a weighting factor corresponding to the ith calibrated score, and γ is the respective weighting exponent that exponentiates the ith calibrated score.
M=Σi=0 Nαimi γ
where M is the aggregated quality score, N is a total number of different degradation metrics represented in the plurality of degradation metric values, mi is an ith calibrated score of the plurality of calibrated scores, αi is a weighting factor corresponding to the ith calibrated score, and γ is the weighting exponent.
M=Σi=0 Nαimi γ
\where M is the aggregated quality score, N is a total number of different degradation metrics represented in the plurality of degradation metric values, mi is an ith calibrated score of the plurality of calibrated scores, αi is a weighting factor corresponding to the ith calibrated score, and γ is the respective weighting exponent that exponentiates the ith calibrated score.
M=Σi=0 Nαimi γ
where M is the aggregated quality score, N is a total number of different degradation metrics represented in the plurality of degradation metric values, mi is the ith calibrated score of the plurality of calibrated scores, αi is a weighting factor corresponding to the ith calibrated score, and γ is the weighting exponent. In these implementations, γ is a constant value, such that each calibrated score is exponentiated by the same value. By exponentiating each calibrated score, the value of a relatively poor degradation metric value may be magnified relative to otherwise tolerable degradation metric values. In this way, even if only one type of degradation artifact or error is observed in a media content, the presence of such degradation artifacts may be sufficient to trigger a reencoding of the media content, as will be discussed below.
M=Σi=0 Nαimi γ
where M is the aggregated quality score, N is a total number of different degradation metrics represented in the plurality of degradation metric values, mi is the ith calibrated score of the plurality of calibrated scores, αi is a weighting factor corresponding to the ith calibrated score, and γi is the respective weighting exponent that exponentiates the ith calibrated score. In these implementations, each weighting exponent (γi) may be selected based on the relative importance of the calibrated score (mi) being exponentiated. In these implementations, the weighting exponents may be determined empirically.
M=Σi=0 Nαimi γ
where M is the aggregated quality score, N is a total number of different degradation metrics represented in the plurality of degradation metric values, mi is the ith calibrated score of the plurality of calibrated scores, αi is a weighting factor corresponding to the ith calibrated score, and γ is the weighting exponent. In these implementations, γ is a constant value, such that each calibrated score is exponentiated by the same value. By exponentiating each calibrated score, the value of a relatively poor degradation metric value may be magnified relative to otherwise tolerable degradation metric values.
M=Σi=0 Nαimi γ
where M is the aggregated quality score, N is a total number of different degradation metrics represented in the plurality of degradation metric values, mi is the ith calibrated score of the plurality of calibrated scores, αi is a weighting factor corresponding to the ith calibrated score, and γi is the respective weighting exponent that exponentiates the ith calibrated score. In these implementations, each weighting exponent (γi) may be selected based on the relative importance of the calibrated score (mi) being exponentiated. In these implementations, the weighting exponents may be determined empirically based on feedback provided from test users.
Claims (20)
M=Σi=0 Nαimi γ
M=Σi=0 Nαimi γ
M=Σi=0 Nαimi γ
M=Σi=0 Nαimi γ
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2017/065781 WO2019117864A1 (en) | 2017-12-12 | 2017-12-12 | Transcoding media content using an aggregated quality score |
Publications (2)
Publication Number | Publication Date |
---|---|
US20200204804A1 US20200204804A1 (en) | 2020-06-25 |
US10999578B2 true US10999578B2 (en) | 2021-05-04 |
Family
ID=60937891
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/612,889 Active US10999578B2 (en) | 2017-12-12 | 2017-12-12 | Transcoding media content using an aggregated quality score |
Country Status (2)
Country | Link |
---|---|
US (1) | US10999578B2 (en) |
WO (1) | WO2019117864A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20220201317A1 (en) * | 2020-12-22 | 2022-06-23 | Ssimwave Inc. | Video asset quality assessment and encoding optimization to achieve target quality requirement |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11165862B2 (en) * | 2017-10-24 | 2021-11-02 | 0Chain, LLC | Systems and methods of blockchain platform for distributed applications |
CA3088790C (en) * | 2018-02-15 | 2024-04-09 | Vitec, Inc. | Distribution and playback of media content |
US11259040B1 (en) * | 2019-04-25 | 2022-02-22 | Amazon Technologies, Inc. | Adaptive multi-pass risk-based video encoding |
WO2021137856A1 (en) * | 2019-12-31 | 2021-07-08 | Google Llc | Optimal format selection for video players based on predicted visual quality using machine learning |
CN115349263A (en) * | 2020-05-19 | 2022-11-15 | 谷歌有限责任公司 | Dynamic parameter selection for quality-normalized video transcoding |
EP4289134A1 (en) * | 2021-02-08 | 2023-12-13 | Tencent Cloud Europe (France) SAS | Methods and systems for updating an objective quality score of a video flow and for processing a video flow |
US11445252B1 (en) * | 2021-07-08 | 2022-09-13 | Meta Platforms, Inc. | Prioritizing encoding of video data received by an online system to maximize visual quality while accounting for fixed computing capacity |
CN113643584B (en) * | 2021-08-16 | 2023-05-23 | 中国人民解放军陆军特色医学中心 | Robot for training communication ability of doctors and patients and working method thereof |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110060792A1 (en) | 2009-09-08 | 2011-03-10 | Swarmcast, Inc. (Bvi) | Dynamic Selection of Parameter Sets for Transcoding Media Data |
US20110069138A1 (en) * | 2009-09-24 | 2011-03-24 | Microsoft Corporation | Mimicking human visual system in detecting blockiness artifacts in compressed video streams |
US20140067898A1 (en) | 2012-09-06 | 2014-03-06 | Moritz M. Steiner | Cost-aware cloud-based content delivery |
US9049420B1 (en) | 2009-08-24 | 2015-06-02 | Google Inc. | Relative quality score for video transcoding |
EP3022936A1 (en) | 2013-07-16 | 2016-05-25 | Microsoft Technology Licensing, LLC | Game clip popularity based control |
US20160212432A1 (en) * | 2013-09-06 | 2016-07-21 | Zhou Wang | Method and system for objective perceptual video quality assessment |
US9445110B2 (en) * | 2007-09-28 | 2016-09-13 | Dolby Laboratories Licensing Corporation | Video compression and transmission techniques |
-
2017
- 2017-12-12 WO PCT/US2017/065781 patent/WO2019117864A1/en active Application Filing
- 2017-12-12 US US16/612,889 patent/US10999578B2/en active Active
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9445110B2 (en) * | 2007-09-28 | 2016-09-13 | Dolby Laboratories Licensing Corporation | Video compression and transmission techniques |
US9049420B1 (en) | 2009-08-24 | 2015-06-02 | Google Inc. | Relative quality score for video transcoding |
US20110060792A1 (en) | 2009-09-08 | 2011-03-10 | Swarmcast, Inc. (Bvi) | Dynamic Selection of Parameter Sets for Transcoding Media Data |
US20110069138A1 (en) * | 2009-09-24 | 2011-03-24 | Microsoft Corporation | Mimicking human visual system in detecting blockiness artifacts in compressed video streams |
US20140067898A1 (en) | 2012-09-06 | 2014-03-06 | Moritz M. Steiner | Cost-aware cloud-based content delivery |
EP3022936A1 (en) | 2013-07-16 | 2016-05-25 | Microsoft Technology Licensing, LLC | Game clip popularity based control |
US20160212432A1 (en) * | 2013-09-06 | 2016-07-21 | Zhou Wang | Method and system for objective perceptual video quality assessment |
Non-Patent Citations (3)
Title |
---|
International Search Report and the Written Opinion of the ISA for International Application No. PCT/US2017/065781 dated May 4, 2018, 15 pgs. |
Moldovan Arghir-Nicolae et al: "QoE-aware video resolution thresholds computation for adaptive multimedia", 2017 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB), IEEE, Jun. 2017, pp. 1-6. |
Written Opinion of the International Preliminary Examining Authority for International Application No. PCT/US2017/065781 dated Sep. 12, 2019, 8 pgs. |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20220201317A1 (en) * | 2020-12-22 | 2022-06-23 | Ssimwave Inc. | Video asset quality assessment and encoding optimization to achieve target quality requirement |
Also Published As
Publication number | Publication date |
---|---|
US20200204804A1 (en) | 2020-06-25 |
WO2019117864A1 (en) | 2019-06-20 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10999578B2 (en) | Transcoding media content using an aggregated quality score | |
He et al. | Rubiks: Practical 360-degree streaming for smartphones | |
US9282330B1 (en) | Method and apparatus for data compression using content-based features | |
AU2017368324A1 (en) | Optimization of encoding profiles for media streaming | |
Moldovan et al. | Subjective assessment of bitdetect—a mechanism for energy-aware multimedia content adaptation | |
US11475539B2 (en) | Electronic apparatus, system and controlling method thereof | |
US10541894B2 (en) | Method for assessing the perceived quality of adaptive video streaming | |
JP2023524000A (en) | Dynamic Parameter Selection for Quality Normalized Video Transcoding | |
KR20200026759A (en) | Apparatus, method and computer program for processing video contents | |
US20220237749A1 (en) | Noise Reduction Method for High Dynamic Range Videos | |
US10609383B2 (en) | Video compression using down-sampling patterns in two phases | |
Göring et al. | Cencro-speedup of video quality calculation using center cropping | |
WO2015085873A1 (en) | Video code stream obtaining method and apparatus | |
Barkowsky et al. | Hybrid video quality prediction: reviewing video quality measurement for widening application scope | |
CN113596467A (en) | Transcoding service detection method and device, electronic equipment and storage medium | |
Micó-Enguídanos et al. | Per-title and per-segment CRF estimation using DNNs for quality-based video coding | |
US9749638B1 (en) | Method and apparatus for encoding video with dynamic quality improvement | |
Zhang et al. | A QOE-driven approach to rate adaptation for dynamic adaptive streaming over http | |
EP4068779A1 (en) | Cross-validation of video encoding | |
US20220232275A1 (en) | Adaptive bitrate video testing from screen recording | |
Reiter et al. | Comparing apples and oranges: assessment of the relative video quality in the presence of different types of distortions | |
Saha et al. | Perceptual Video Quality Assessment: The Journey Continues! | |
Wilk et al. | A content-aware video adaptation service to support mobile video | |
Lebreton et al. | Quitting ratio-based bitrate ladder selection mechanism for adaptive bitrate video streaming | |
Zhou et al. | Content-adaptive parameters estimation for multi-dimensional rate control |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SINGH, SHAWN;ADSUMILLI, BALINEEDU;WANG, YILIN;AND OTHERS;SIGNING DATES FROM 20180227 TO 20190228;REEL/FRAME:051046/0001 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |