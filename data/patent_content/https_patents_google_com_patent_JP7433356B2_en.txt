JP7433356B2 - Accessing data in multidimensional tensors using adders - Google Patents
Accessing data in multidimensional tensors using adders Download PDFInfo
- Publication number
- JP7433356B2 JP7433356B2 JP2022056584A JP2022056584A JP7433356B2 JP 7433356 B2 JP7433356 B2 JP 7433356B2 JP 2022056584 A JP2022056584 A JP 2022056584A JP 2022056584 A JP2022056584 A JP 2022056584A JP 7433356 B2 JP7433356 B2 JP 7433356B2
- Authority
- JP
- Japan
- Prior art keywords
- dimension
- value
- address offset
- partial address
- offset value
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000000034 method Methods 0.000 claims description 26
- 230000004044 response Effects 0.000 claims description 12
- 230000008569 process Effects 0.000 description 13
- 238000004590 computer program Methods 0.000 description 7
- 230000000717 retained effect Effects 0.000 description 7
- 239000011159 matrix material Substances 0.000 description 6
- 238000013528 artificial neural network Methods 0.000 description 5
- 238000010586 diagram Methods 0.000 description 4
- 238000004364 calculation method Methods 0.000 description 3
- 238000004519 manufacturing process Methods 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 238000013527 convolutional neural network Methods 0.000 description 2
- 238000010801 machine learning Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 238000003491 array Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000000593 degrading effect Effects 0.000 description 1
- 230000006870 function Effects 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/34—Addressing or accessing the instruction operand or the result ; Formation of operand address; Addressing modes
- G06F9/345—Addressing or accessing the instruction operand or the result ; Formation of operand address; Addressing modes of multiple operands or results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/3001—Arithmetic instructions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/10—Complex mathematical operations
- G06F17/16—Matrix or vector computation, e.g. matrix-matrix or matrix-vector multiplication, matrix factorization
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/30021—Compare instructions, e.g. Greater-Than, Equal-To, MINMAX
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/3005—Arrangements for executing specific machine instructions to perform operations for flow control
- G06F9/30065—Loop control instructions; iterative instructions, e.g. LOOP, REPEAT
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30072—Arrangements for executing specific machine instructions to perform conditional operations, e.g. using predicates or guards
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30098—Register arrangements
- G06F9/30101—Special purpose registers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/32—Address formation of the next instruction, e.g. by incrementing the instruction counter
- G06F9/322—Address formation of the next instruction, e.g. by incrementing the instruction counter for non-sequential address
- G06F9/325—Address formation of the next instruction, e.g. by incrementing the instruction counter for non-sequential address for loops, e.g. loop detection or loop counter
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/34—Addressing or accessing the instruction operand or the result ; Formation of operand address; Addressing modes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/34—Addressing or accessing the instruction operand or the result ; Formation of operand address; Addressing modes
- G06F9/345—Addressing or accessing the instruction operand or the result ; Formation of operand address; Addressing modes of multiple operands or results
- G06F9/3455—Addressing or accessing the instruction operand or the result ; Formation of operand address; Addressing modes of multiple operands or results using stride
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2212/00—Indexing scheme relating to accessing, addressing or allocation within memory systems or architectures
- G06F2212/45—Caching of specific data in cache memory
- G06F2212/454—Vector or matrix data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/30036—Instructions to perform operations on packed data, e.g. vector, tile or matrix operations
Description
背景
本明細書は、一般に、ハードウェア加算器を有する特殊目的計算ユニットを使用して機械学習計算を実行することに関する。
Background This specification generally relates to performing machine learning computations using special purpose computing units with hardware adders.
ニューラルネットワークは、モデルの１つ以上のレイヤを利用して、受信した入力に対する出力、たとえば分類、を生成する機械学習モデルである。ニューラルネットワークの中には、出力レイヤに加えて１つ以上の隠れレイヤを含んでいるものもある。各隠れレイヤの出力は、ネットワーク内の次のレイヤ、すなわちネットワークの次の隠れレイヤまたは出力レイヤ、への入力として使用される。ネットワークの各レイヤは、それぞれのパラメータセットの現在の値に従って、受信した入力から出力を生成する。 A neural network is a machine learning model that utilizes one or more layers of the model to generate an output, such as a classification, for received input. Some neural networks include one or more hidden layers in addition to the output layer. The output of each hidden layer is used as an input to the next layer in the network, ie the next hidden layer or output layer of the network. Each layer of the network generates an output from the input it receives according to the current values of its respective parameter set.
ニューラルネットワークの中には、１つ以上の畳み込みニューラルネットワークレイヤを含んでいるものもある。各畳み込みニューラルネットワークレイヤは、関連付けられたカーネルセットを有する。カーネルは、重み入力のマトリクス構造として表すことができる。各畳み込みレイヤは、カーネルを使用してレイヤへの入力を処理する。レイヤへの入力セットも、マトリクス構造として表すことができる。 Some neural networks include one or more convolutional neural network layers. Each convolutional neural network layer has an associated set of kernels. A kernel can be represented as a matrix structure of weight inputs. Each convolutional layer uses a kernel to process the input to the layer. The set of inputs to a layer can also be represented as a matrix structure.
概要
本明細書には、テンソル要素のメモリアドレスを求めるために１つ以上のハードウェア加算器を使用してＮ次元テンソルにアクセスすることに関連する技術が記載されている。
Overview Techniques are described herein that relate to accessing N-dimensional tensors using one or more hardware adders to determine memory addresses of tensor elements.
概して、本明細書に記載されている主題の１つの革新的局面は、Ｎ次元テンソルにアクセスするための装置で具体化することができる。上記装置は、上記Ｎ次元テンソルの各次元について、部分アドレスオフセット値要素を含んでもよく、上記部分アドレスオフセット値要素は、上記次元の初期値、上記次元のステップ値および上記次元のループの繰り返し回数に少なくとも基づいて上記次元の部分アドレスオフセット値を格納する。また、上記装置は、１つ以上のハードウェア加算器と、１つ以上のプロセッサとを含んでもよい。上記１つ以上のプロセッサは、上記Ｎ次元テンソルの特定の要素にアクセスするための命令を取得するように構成されてもよい。上記Ｎ次元テンソルは、上記Ｎ個の次元の各々にわたって配置された複数の要素を有してもよい。Ｎは、１以上の整数であってもよい。上記プロセッサは、上記部分アドレスオフセット値要素および上記１つ以上のハードウェア加算器のうちの１つ以上を使用して、上記特定の要素のアドレスを求め、上記Ｎ次元テンソルの上記特定の要素にアクセスするための上記求められたアドレスを示すデータを出力してもよい。 In general, one innovative aspect of the subject matter described herein can be embodied in an apparatus for accessing N-dimensional tensors. The apparatus may include a partial address offset value element for each dimension of the N-dimensional tensor, and the partial address offset value element includes an initial value of the dimension, a step value of the dimension, and a loop repetition number of the dimension. A partial address offset value of the dimension is stored based at least on . The apparatus may also include one or more hardware adders and one or more processors. The one or more processors may be configured to obtain instructions for accessing particular elements of the N-dimensional tensor. The N-dimensional tensor may have a plurality of elements arranged across each of the N dimensions. N may be an integer of 1 or more. The processor uses one or more of the partial address offset value element and the one or more hardware adders to determine the address of the particular element and add the address to the particular element of the N-dimensional tensor. Data indicating the obtained address for access may be output.
これらのおよび他の実現例の各々は、任意に、以下の特徴のうちの１つ以上を含んでもよい。いくつかの局面では、上記装置は、各次元について、上記次元の上記初期値を格納する初期値要素と、上記次元の上記ステップ値を格納するステップ値要素とを含んでもよい。各部分アドレスオフセット値要素、各初期値要素および各ステップ値要素は、レジスタを含んでもよい。 Each of these and other implementations may optionally include one or more of the following features. In some aspects, the apparatus may include, for each dimension, an initial value element that stores the initial value of the dimension, and a step value element that stores the step value of the dimension. Each partial address offset value element, each initial value element and each step value element may include a register.
いくつかの局面では、上記特定の要素の上記アドレスを求めることは、上記１つ以上のハードウェア加算器を使用して各次元について上記部分アドレスオフセット値の合計を求めることを含んでもよい。上記１つ以上のプロセッサは、各次元について、上記ステップ値を上記次元の以前のアドレスオフセット値に加算することによって、上記次元のネステ
ッドループの各繰り返し後に上記次元の上記部分アドレスオフセット値を求めるように構成されてもよい。
In some aspects, determining the address of the particular element may include summing the partial address offset values for each dimension using the one or more hardware adders. The one or more processors are configured to determine, for each dimension, the partial address offset value of the dimension after each iteration of the nested loop of the dimension by adding the step value to the previous address offset value of the dimension. may be configured.
上記装置は、各次元について、上記次元の限界値を格納する限界値要素を含んでもよい。上記１つ以上のプロセッサは、各次元について、次元の上記求められた部分アドレスオフセット値が上記次元の上記限界値に等しいか否かを判断してもよい。第１のネステッドループに対応する第１の次元の上記求められた部分アドレスオフセット値が上記第１の次元の上記限界値に等しいと判断したことに応答して、上記１つ以上のプロセッサは、上記第１の次元の上記部分アドレスオフセット値を上記第１の次元の上記初期値にリセットし、上記第１のネステッドループがネストされる第２のネステッドループに対応する第２の次元について、上記１つ以上のハードウェア加算器を使用して、上記第２の次元の上記ステップ値と上記第２の次元の上記部分アドレスオフセット値との合計に等しくなるように上記第２の次元の上記部分アドレスオフセット値を更新してもよい。いくつかの局面では、各次元の上記ステップ値は、１つ以上の上記次元における要素の個数に基づく予め定められた値である。 The apparatus may include, for each dimension, a limit value element storing a limit value for said dimension. The one or more processors may determine, for each dimension, whether the determined partial address offset value for the dimension is equal to the limit value for the dimension. In response to determining that the determined partial address offset value of the first dimension corresponding to the first nested loop is equal to the limit value of the first dimension, the one or more processors: resetting the partial address offset value of the first dimension to the initial value of the first dimension; and resetting the partial address offset value of the first dimension to the initial value of the first dimension; using one or more hardware adders to equal the sum of the step value of the second dimension and the partial address offset value of the second dimension; The address offset value may be updated. In some aspects, the step value for each dimension is a predetermined value based on the number of elements in one or more of the dimensions.
本明細書に記載されている主題は、以下の利点のうちの１つ以上を実現するように特定の実施形態において実現することができる。レジスタを使用してメモリアドレス値を追跡することによって、プログラムは、１つの命令で、深くネストされたループを繰り返すことができるようになる。メモリアドレス値は、レジスタに格納された値に基づいて単純な加算を適用することによって速やかに求めることができる。特殊目的計算ユニットは、アドレスを計算する加算器を含み得る。算術論理演算ユニット（ＡＬＵ）、乗算器または他の複雑な回路ではなく加算器を使用することによって、回路のサイズおよび回路の製造コストを下げることができる。ハードウェア加算器を使用してメモリアドレス値を求めることによって、プロセッサにおける計算サイクル数を減らすことができ、他の計算タスクのためのプロセッサ帯域幅が増加する。命令数を減らした状態でテンソルをトラバースすることができる。二次元レジスタアーキテクチャは、同時に追跡される異なる次元を各々が有する多次元テンソルを可能にする。 The subject matter described herein can be implemented in particular embodiments to achieve one or more of the following advantages. Using registers to track memory address values allows a program to iterate through deeply nested loops with a single instruction. Memory address values can be quickly determined by applying simple addition based on the values stored in the registers. The special purpose computing unit may include an adder that computes the address. By using adders rather than arithmetic logic units (ALUs), multipliers, or other complex circuits, the size of the circuit and the cost of manufacturing the circuit can be reduced. Using a hardware adder to determine memory address values reduces the number of computational cycles in the processor and increases processor bandwidth for other computational tasks. It is possible to traverse a tensor with a reduced number of instructions. The two-dimensional register architecture allows for multidimensional tensors, each having different dimensions tracked simultaneously.
これおよび他の局面の他の実現例は、コンピュータ記憶装置上に符号化された方法のアクションを実行するように構成された対応するシステム、方法およびコンピュータプログラムを含む。１つ以上のコンピュータからなるシステムは、動作時にシステムにアクションを実行させる、システムにインストールされたソフトウェア、ファームウェア、ハードウェアまたはそれらの組み合わせによってそのように構成することができる。１つ以上のコンピュータプログラムは、データ処理装置によって実行されたときに装置にアクションを実行させる命令を有することによってそのように構成することができる。 Other implementations of this and other aspects include corresponding systems, methods, and computer program products configured to perform the actions of the methods encoded on computer storage devices. A system of one or more computers may be so configured by software, firmware, hardware, or a combination thereof installed on the system that causes the system to perform actions during operation. One or more computer programs may be so configured to have instructions that, when executed by a data processing device, cause the device to perform actions.
本明細書に記載されている主題の１つ以上の実現例の詳細については、添付の図面および以下の説明に記載されている。主題の他の考えられる特徴、局面および利点は、明細書、図面および特許請求の範囲から明らかになるであろう。 The details of one or more implementations of the subject matter described herein are set forth in the accompanying drawings and the description below. Other possible features, aspects, and advantages of the subject matter will be apparent from the specification, drawings, and claims.
さまざまな図面中の同様の参照番号および名称は、同様の要素を示す。
詳細な説明
一般に、ソフトウェアアルゴリズムがＮ次元テンソルを処理する際にネステッドループが使用されてもよい。各ループは、Ｎ次元テンソルのそれぞれの次元をトラバースすることに関与し得る。多次元テンソルは、マトリクスまたは多次元マトリクスであってもよい。たとえば、二次元テンソルは、マトリクスであり、三次元テンソルは、複数の二次元マトリクスで構成される三次元マトリクスである。Ｎ次元テンソルの各次元は、１つ以上の要素を含んでもよく、各要素は、それぞれのデータ値を格納してもよい。たとえば、テンソルは、プログラムにおける変数であってもよく、この変数は、３つの次元を有してもよい。第１の次元は、３００個の要素の長さを有してもよく、第２の次元は、１０００個の要素の長さを有してもよく、第３の次元は、２０個の要素の長さを有してもよい。当然のことながら、各次元において他の個数の要素も可能である。
Like reference numbers and designations in the various drawings indicate similar elements.
DETAILED DESCRIPTION In general, nested loops may be used when software algorithms process N-dimensional tensors. Each loop may be involved in traversing a respective dimension of the N-dimensional tensor. A multidimensional tensor may be a matrix or a multidimensional matrix. For example, a two-dimensional tensor is a matrix, and a three-dimensional tensor is a three-dimensional matrix composed of a plurality of two-dimensional matrices. Each dimension of the N-dimensional tensor may include one or more elements, and each element may store a respective data value. For example, a tensor may be a variable in a program, and this variable may have three dimensions. The first dimension may have a length of 300 elements, the second dimension may have a length of 1000 elements, and the third dimension may have a length of 20 elements. It may have a length of Of course, other numbers of elements in each dimension are also possible.
ネステッドループにおいてテンソルをトラバースすることは、要素のメモリアドレス値を計算して、この要素の対応するデータ値をロードまたは格納することを含み得る。ｆｏｒループは、３つのループインデックス変数（たとえば、ｉ、ｊおよびｋ）によって追跡される３つのループを、三次元テンソルをトラバースするようにネストすることができるネステッドループの一例である。ニューラルネットワークでは、テンソルに関連付けられた１つ以上のドット積計算に要素の値が使用されてもよい。たとえば、要素の値は、対応するパラメータまたは重みを乗算されてもよい。要素にアクセスして要素の値を用いて１つ以上の計算を実行するために、テンソルの要素は、ネステッドｆｏｒループを使用して順番にトラバースされてもよい。引き続き三次元テンソルの例を参照して、外側ｆｏｒループを使用して、変数ｉによって追跡されるループをトラバースしてもよく、中間ｆｏｒループループを使用して、変数ｊによって追跡されるループをトラバースしてもよく、内側ｆｏｒループを使用して、変数ｋによって追跡されるループをトラバースしてもよい。この例では、アクセスされる第１の要素は（ｉ＝０，ｊ＝０，ｋ＝０）であってもよく、第２の要素は（ｉ＝０，ｊ＝０，ｋ＝１）であってもよい、などである。以下で説明するように、テンソルトラバーサルユニットを使用する目的は、ネステッドループを使用して順番に各要素のメモリアドレスを求めることによって、処理ユニットが要素の値にアクセスして、この要素の値を使用して１つ以上の計算を実行することができるようにすることである。重みまたはパラメータの値にも、ネステッドｆｏｒループを使用して同様にアクセスすることができる。また、テンソルトラバーサルユニットは、計算に使用される重みもしくはパラメータのアドレス、および／または、計算の出力のアドレスを求める目的でも使用することができ、計算の出力は、ニューラルネットワークの隠れレイヤへの入力として使用されてもよい。 Traversing a tensor in a nested loop may include computing a memory address value for an element and loading or storing a corresponding data value for this element. A for loop is an example of a nested loop in which three loops tracked by three loop index variables (eg, i, j, and k) can be nested to traverse a three-dimensional tensor. In the neural network, the values of the elements may be used in one or more dot product calculations associated with the tensor. For example, the value of an element may be multiplied by a corresponding parameter or weight. The elements of the tensor may be traversed in order using nested for loops to access the elements and perform one or more computations with the values of the elements. Continuing with the three-dimensional tensor example, an outer for loop may be used to traverse the loop tracked by variable i, and an intermediate for loop may be used to traverse the loop tracked by variable j. An inner for loop may be used to traverse the loop tracked by the variable k. In this example, the first element accessed may be (i=0, j=0, k=0) and the second element may be (i=0, j=0, k=1). It may be possible, etc. As explained below, the purpose of using a tensor traversal unit is to use a nested loop to determine the memory address of each element in turn, so that the processing unit can access the value of an element and set the value of this element to to be able to perform one or more calculations using Weights or parameter values can be similarly accessed using nested for loops. The tensor traversal unit can also be used to determine the address of the weights or parameters used in the computation and/or the address of the output of the computation, where the output of the computation is the input to the hidden layer of the neural network. may be used as
場合によっては、プロセッサは、外側ループインデックス変数を用いて内側ループのループ境界を設定するなど、ループ境界条件を実行する必要があるかもしれない。たとえば、ネステッドループの最も内側のループを出るか否かを判断する際に、プログラムは、最も内側のループのループインデックス変数の現在の値とネステッドループの最も外側のループのループインデックス変数の現在の値とを比較してもよい。 In some cases, the processor may need to perform loop boundary conditions, such as using an outer loop index variable to set the loop bounds of an inner loop. For example, when determining whether to exit the innermost loop of a nested loop, the program uses the current value of the loop index variable of the innermost loop and the current value of the loop index variable of the outermost loop of the nested loop. You can also compare the values.
これらのタスクは、分岐命令および整数演算命令などの相当数の命令を必要とする可能性がある。各ループ境界が小さく、ループの数が多い場合には、計算が全実行時間のうちのかなりの部分を占めて、全体的性能を非常に劣化させるおそれがある。プロセッサのた
めのハードウェアテンソルトラバーサルユニットは、テンソルをトラバースする際にプロセッサが処理しなければならない次元の個数を減少させることによってプロセッサの計算帯域幅を増加させることができる。
These tasks can require a significant number of instructions, such as branch instructions and integer arithmetic instructions. If each loop boundary is small and the number of loops is large, the computation can take up a significant portion of the total execution time, severely degrading the overall performance. A hardware tensor traversal unit for a processor can increase the processor's computational bandwidth by reducing the number of dimensions that the processor must process when traversing a tensor.
図１は、テンソルをトラバースするためのコンピューティングシステムの一例１００のブロック図を示す。一般に、コンピューティングシステム１００は、入力１０４を処理して出力１１６を生成する。コンピューティングシステム１００は、線形代数計算を実行するように構成されてもよい。入力１０４は、コンピューティングシステム１００が処理することができる任意の好適なデータであってもよい。コンピューティングシステム１００は、処理ユニット１０２と、記憶媒体１０４と、テンソルトラバーサルユニット１０６とを含む。
FIG. 1 shows a block diagram of an
一般に、処理ユニット１０２が、テンソルの特定の要素にアクセスするための命令を実行すると、テンソルトラバーサルユニット１０６は、このテンソルの特定の要素のアドレスを求め、それにより、処理ユニット１０２が記憶媒体１０４にアクセスして特定の要素の値を表すデータ１１４を読み出すことができる。たとえば、プログラムは、ネステッドループを含んでもよく、処理ユニット１０２は、ネステッドループに関連付けられた現在のインデックス変数値に従って、ネステッドループ内の二次元配列変数の要素にアクセスするための命令を実行してもよい。ネステッドループに関連付けられた現在のインデックス変数値に基づいて、テンソルトラバーサルユニット１０６は、二次元配列変数の第１の要素のメモリアドレスからのオフセットを表すアドレスオフセット値を求めてもよい。次いで、処理ユニット１０２は、このアドレスオフセット値を使用して、記憶媒体から二次元配列変数の特定の要素にアクセスしてもよい。
Generally, when processing
処理ユニット１０２は、記憶媒体１０４に格納された命令１１２または別の記憶装置に格納された他の命令を含む、コンピューティングシステム１００内で実行される命令を処理するように構成される。処理ユニット１０２は、１つ以上のプロセッサを含んでもよい。記憶媒体１０４は、コンピューティングシステム１００内の情報を格納する。いくつかの実現例では、記憶媒体１０４は、１つまたは複数の揮発性メモリユニットである。いくつかの他の実現例では、記憶媒体１０４は、１つまたは複数の不揮発性メモリユニットである。また、記憶媒体１０４は、フロッピー（登録商標）ディスクデバイス、ハードディスクデバイス、光ディスクデバイスもしくはテープデバイス、フラッシュメモリもしくは他の同様のソリッドステートメモリデバイス、または一連のデバイス（ストレージエリアネットワークもしくは他の構成のデバイスを含む）などの、別の形態のコンピュータ読取可能媒体であってもよい。命令は、処理ユニット１０２によって実行されると、処理ユニット１０２に１つ以上のタスクを実行させる。
テンソルトラバーサルユニット１０６は、特定用途向け集積回路として実現されてもよい。テンソルトラバーサルユニット１０６は、１つ以上のテンソルに関連付けられた状態を判断するように構成されてもよい。この状態は、ループ境界値、現在のループインデックス変数値、メモリアドレス値を求めるための部分アドレスオフセット値、および／または、分岐ループ境界を処理するためのプログラムカウンタ値を含んでもよい。 Tensor traversal unit 106 may be implemented as an application-specific integrated circuit. Tensor traversal unit 106 may be configured to determine state associated with one or more tensors. This state may include loop boundary values, current loop index variable values, partial address offset values for determining memory address values, and/or program counter values for processing branch loop boundaries.
テンソルトラバーサルユニット１０６は、テンソルインデックスをメモリアドレスに変換する。たとえば、テンソルトラバーサルユニット１０６は、一組のＮ次元テンソルインデックスを一次元アドレス空間に変換してもよい。テンソルトラバーサルユニットは、テンソル要素のメモリアドレスを要素の次元インデックスの組み合わせ（たとえば、線形組み合わせ）にすることによってこのような変換を実行することができる。 Tensor traversal unit 106 converts tensor indices into memory addresses. For example, tensor traversal unit 106 may transform a set of N-dimensional tensor indices into a one-dimensional address space. A tensor traversal unit can perform such a transformation by making the memory addresses of tensor elements a combination (e.g., a linear combination) of the element's dimension indices.
テンソルトラバーサルユニット１０６は、テンソル要素のシーケンスを参照するアドレ
スのシーケンスを効率的にプログラムに従って生成することができる。このアドレスのシーケンスは、ソフトウェアトラバーサルルーチンにおけるループネストによってアクセスされるであろうテンソル要素のシーケンスに対応する。トラバーサル中にアクセスされる要素のシーケンスは、メモリ内で物理的に連続している場合もあれば、そうでない場合もある。図２Ｂ～図２Ｈに示され、以下で説明する例は、要素のシーケンスがどのようにしてメモリ内で物理的に連続していないかの一例を示す。
Tensor traversal unit 106 can efficiently programmatically generate a sequence of addresses that refer to a sequence of tensor elements. This sequence of addresses corresponds to the sequence of tensor elements that would be accessed by the loop nest in the software traversal routine. The sequence of elements accessed during traversal may or may not be physically contiguous in memory. The examples shown in FIGS. 2B-2H and described below illustrate one example of how a sequence of elements may not be physically contiguous in memory.
テンソルトラバーサルユニット１０６は、テンソルアドレス値要素１２２と、ハードウェア加算器ユニット１２４とを含む。テンソルアドレス値要素１２２の各々は、記憶要素、たとえばレジスタまたはその他の好適な記憶回路であってもよい。いくつかの実現例では、図２Ａ～図２Ｈを参照して以下でより詳細に説明するように、テンソルアドレス値要素１２２は、異なるグループに物理的または論理的に分類されてもよい。いくつかの実現例では、テンソルアドレス値要素１２２のグループは、多次元配列に物理的または論理的に配置されてもよい。たとえば、テンソルアドレス値要素１２２の各グループは、二次元配列に物理的または論理的に配置されてもよい。
Tensor traversal unit 106 includes a tensor
ハードウェア加算器ユニット１２４は、１つ以上のハードウェア加算器を含み得る。各加算器は、加算演算を実行するように構成されたデジタル回路を含んでもよい。たとえば、以下で説明するように、１つ以上の加算器は、部分アドレスオフセット値を加算して、テンソルの要素の合計アドレスオフセット値を求めてもよい。ハードウェア加算器は、算術論理演算ユニット（ＡＬＵ）およびハードウェア乗算器よりも必要な回路部品が少ないので、ハードウェア加算器ユニット１２４の回路のサイズ（したがって、テンソルトラバーサルユニット１０６のサイズ）は、ＡＬＵおよび／または乗算器を含むテンソルトラバーサルユニットよりも小さくすることができる。また、ハードウェア加算器を有するテンソルトラバーサルユニットの製造コストは、ＡＬＵおよび／または乗算器を有するテンソルトラバーサルユニットの製造コストよりも少ないであろう。いくつかの実現例では、ハードウェア加算器ユニット１２４は、加算器のみを含み、他の数学回路または論理回路は含まない。
図２Ａは、テンソルトラバーサルユニットの一組のテンソルアドレス値要素２００の一例を示す。テンソルアドレス値要素２００は、テンソルトラバーサルユニット１０６のテンソルアドレス値要素１２２に対応してもよい。テンソルトラバーサルユニット２００は、一群の初期値要素２０２と、一群のステップ値要素２０４と、一群の終了値要素２０６と、一群の部分アドレスオフセット値要素２０８とを含む。
FIG. 2A shows an example of a set of tensor
初期値要素２０２は、Ｍ個の行とＮ個の列とを有する２Ｄ配列として物理的または論理的に配置されてもよく、ＭおよびＮは、１以上の整数である。初期値要素２０２は、テンソル要素のメモリアドレスを求めるために使用される部分アドレスオフセットの初期値を格納してもよい。いくつかの実現例では、初期値要素２０２の各行は、テンソルの初期値を表してもよい。たとえば、プログラムが２つの配列変数Ｖ１およびＶ２を定義する場合、テンソルトラバーサルユニットは、行２０２ａおよび２０２ｂを割り当てて、配列変数Ｖ１およびＶ２の初期値をそれぞれ格納してもよい。いくつかの実現例では、初期値要素２０２の各列は、テンソルに関連付けられたネステッドループインデックス変数値の初期値を表してもよい。たとえば、プログラムが、変数Ｖ１にアクセスするための３つのループを有するネステッドループを定義し、このネステッドループの各ループが、ネステッドループインデックス変数ｉ，ｊおよびｋによって索引付けされる場合、テンソルトラバーサルユニットは、初期値要素Ｖ１，１、Ｖ１，２およびＶ１，３を割り当てて、ネステッドループインデックス変数ｉ，ｊおよびｋの初期値をそれぞれ格納してもよい。初期値要素２０２については、図２Ｂ～図２Ｈを参照して以下でより詳細に説明する。
ステップ値要素２０４は、初期値要素２０２と同一の次元を有する２Ｄ配列として物理的または論理的に配置されてもよく、ステップ値要素２０４の各要素は、初期値要素２０２の中に対応する要素を有する。ステップ値要素２０４は、テンソル要素のメモリアドレスを求めるために使用される部分アドレスオフセットのステップ値を格納してもよい。いくつかの実現例では、ステップ値要素２０４の各行は、テンソルのステップ値を表してもよい。たとえば、プログラムが２つの配列変数Ｖ１およびＶ２を定義する場合、テンソルトラバーサルユニットは、行２０４ａおよび２０４ｂを割り当てて、配列変数Ｖ１およびＶ２のステップ値をそれぞれ格納してもよい。いくつかの実現例では、ステップ値要素２０４の各列は、テンソルに関連付けられたネステッドループインデックス変数値のステップ値を表してもよい。たとえば、プログラムが、変数Ｖ１にアクセスするための３つのループを有するネステッドループを定義し、このネステッドループの各ループが、ネステッドループインデックス変数ｉ，ｊおよびｋによって索引付けされる場合、テンソルトラバーサルユニットは、ステップ値要素Ｘ１，１、Ｘ１，２およびＸ１，３を割り当てて、ネステッドループインデックス変数ｉ，ｊおよびｋのステップ値をそれぞれ格納してもよい。ステップ値要素２０４については、図２Ｂ～図２Ｈを参照して以下でより詳細に説明する。
The
終了値要素２０６は、初期値要素２０２と同一の次元を有する２Ｄ配列として物理的または論理的に配置されてもよく、終了値要素２０６の各要素は、初期値要素２０２の中に対応する要素を有する。終了値要素２０６は、テンソル要素のメモリアドレスを求めるために使用される部分アドレスオフセットの終了値を格納してもよい。いくつかの実現例では、終了値要素２０６の各行は、テンソルの終了値を表してもよい。たとえば、プログラムが２つの配列変数Ｖ１およびＶ２を定義する場合、テンソルトラバーサルユニットは、行２０６ａおよび２０６ｂを割り当てて、配列変数Ｖ１およびＶ２の終了値をそれぞれ格納してもよい。いくつかの実現例では、終了値要素２０６の各列は、テンソルに関連付けられたネステッドループインデックス変数値の終了値を表してもよい。たとえば、プログラムが、変数Ｖ１にアクセスするための３つのループを有するネステッドループを定義し、このネステッドループの各ループが、ネステッドループインデックス変数ｉ，ｊおよびｋによって索引付けされる場合、テンソルトラバーサルユニットは、終了値要素Ｙ１，１、Ｙ１，２およびＹ１，３を割り当てて、ネステッドループインデックス変数ｉ，ｊおよびｋの終了値をそれぞれ格納してもよい。終了値要素２０６については、図２Ｂ～図２Ｈを参照して以下でより詳細に説明する。
The
部分アドレスオフセット値要素２０８は、初期値要素２０２と同一の次元を有する２Ｄ配列として物理的または論理的に配置されてもよく、部分アドレスオフセット値要素２０８の各要素は、初期値要素２０２の中に対応する要素を有する。部分アドレスオフセット値要素２０６は、テンソル要素のメモリアドレスを求めるために使用される部分アドレスオフセット値を格納してもよい。いくつかの実現例では、部分アドレスオフセット値要素２０８の各行は、テンソルの部分アドレスオフセット値を表してもよい。たとえば、プログラムが２つの配列変数Ｖ１およびＶ２を定義する場合、テンソルトラバーサルユニットは、行２０８ａおよび２０８ｂを割り当てて、配列変数Ｖ１およびＶ２の部分アドレスオフセット値をそれぞれ格納してもよい。いくつかの実現例では、部分アドレスオフセット値要素２０８の各列は、テンソルに関連付けられたネステッドループインデックス変数値の部分アドレスオフセット値を表してもよい。たとえば、プログラムが、変数Ｖ１にアクセスするための３つのループを有するネステッドループを定義し、このネステッドループの各ループが、ネステッドループインデックス変数ｉ，ｊおよびｋによって索引付けされる場合、テンソルトラバーサルユニットは、部分アドレスオフセット値要素Ｚ１，１、Ｚ１，２およびＺ１，３を割り当てて、ネステッドループインデックス変数ｉ，ｊおよびｋの部分アドレスオフセット値をそれぞれ格納してもよい。部分アドレスオフセット値要素２０８については、図２Ｂ～図２Ｈを参照して以下でより詳細に説明する。
Partial address offset
図２Ｂ～図２Ｈは、テンソルアドレス値要素２００がどのようにしてテンソルトラバーサルユニットによって使用されてテンソルを処理し得るかの一例を示し、テンソルのテンソル要素のメモリアドレス値を求めることを含む。図２Ｂを参照して、プログラム２１２は、記憶媒体１０４または別の記憶媒体に格納されてもよく、処理ユニット１０２によって実行可能である。プログラム２１２は、第１の次元が３であり、第２の次元が２であり、第３の次元が２である文字配列変数Ｖ１を指定する。プログラム２１２は、変数Ｖ１をトラバースするためのネステッドｆｏｒループを指定し、このｆｏｒループは、ネステッドループインデックス変数ｉによって追跡される外側ループにおいてＶ１の第１の次元をトラバースし、ネステッドループインデックス変数ｊによって追跡される中間ループにおいてＶ１の第２の次元をトラバースし、ネステッドループインデックス変数ｋによって追跡される内側ループにおいてＶ１の第３の次元をトラバースする。本明細書に記載されている図２Ｂ～図２Ｈの示されている例は、３つの次元を含んでいるが、異なる個数の次元（たとえば、２つ、５つ、８つ、または他の個数の次元）を有するテンソルのメモリアドレス値を同様の態様で求めることができる。たとえば、８つの次元を有するテンソルがトラバースされてもよく、テンソル要素のメモリアドレスは、８重のループネストを使用して求めることができる。
2B-2H illustrate an example of how tensor
いくつかの実現例では、テンソルアドレス値要素２００は、プログラムの開始時に初期化されてもよい。たとえば、プロセッサは、テンソルアドレス値要素２００を初期化する命令「InitializeElements」を実行してもよい。この命令は、プロセッサによって実行可能な命令セットのハードウェア命令であってもよい。いくつかの実現例では、初期化後、テンソルアドレス値要素２００の各要素は、予め定められた値に設定される。いくつかの実現例では、プロセッサは、たとえば初期値要素２０２のためにある命令を実行し、ステップ値要素のためにある命令を実行するなど、テンソルアドレス値要素の各グループについて別々の命令を実行してもよい。各々の別々の命令は、そのグループの各要素を当該要素のための予め定められた値に設定してもよい。
In some implementations, tensor
この例では、各初期値要素２０２は、ゼロという値に設定される。次元の初期値は、この次元をトラバースするｆｏｒループの１回目の繰り返しの間、この次元の部分アドレスオフセット値が設定される値である。したがって、この例では、各次元の部分アドレスオフセット値は、この次元のｆｏｒループの１回目の繰り返しの間はゼロという値に設定されることになる。
In this example, each
ステップ値要素は、テンソル要素のメモリアドレスを求めるために使用される部分アドレスオフセットのステップ値を格納してもよい。次元のステップ値は、この次元をトラバースするｆｏｒループの各繰り返しの後にこの次元の部分アドレスオフセット値に加算される値である。この例では、内側ネステッドループインデックス変数ｋは、１というステップ値を有し、中間ネステッドループインデックス変数ｊは、６というステップ値を有し、外側ネステッドループインデックス変数ｉは、２というステップ値を有する。 The step value element may store the step value of the partial address offset used to determine the memory address of the tensor element. The step value for a dimension is the value that is added to the partial address offset value for this dimension after each iteration of a for loop that traverses this dimension. In this example, the inner nested loop index variable k has a step value of 1, the intermediate nested loop index variable j has a step value of 6, and the outer nested loop index variable i has a step value of 2. .
いくつかの実現例では、プロセッサ、ユーザ、またはテンソルをトラバースするためのプログラムをコンパイルするコンパイラは、テンソルの１つ以上の次元における要素の個数に基づいて各次元のステップ値および／または終了値を求める。一例では、各次元のステップ値および／または終了値は、テンソルのメモリレイアウトによって決まる。二次元テンソルの場合、メモリレイアウトは、たとえば行優先または列優先の順序に従ってもよい。このように、各テンソル要素について計算されるメモリアドレスは、各々の他のテンソル要素のメモリアドレスとは異なっている。いくつかの実現例では、メモリアドレスは、トラバーサル中にアクセスされる要素のシーケンスがメモリ内で物理的に連続しているように求められる。この例では、第１のテンソル要素は、第１のアドレスを有する第１の
メモリ場所に格納されてもよく、第２のテンソル要素は、第１のメモリ場所のすぐ隣に位置する第２のメモリ場所に格納されてもよく、第３のテンソル要素は、第２のメモリ場所のすぐ隣に位置する第３のメモリ場所に格納されてもよい、などである。いくつかの実現例では、メモリアドレスは、トラバーサル中にアクセスされる要素のシーケンスがメモリ内で物理的に連続していないように求められる。この例では、第２のテンソル要素は、第１のテンソル要素のすぐ隣に格納されなくてもよい。
In some implementations, a processor, a user, or a compiler compiling a program for traversing a tensor determines the step and/or end values for each dimension based on the number of elements in one or more dimensions of the tensor. demand. In one example, the step value and/or end value for each dimension is determined by the memory layout of the tensor. For two-dimensional tensors, the memory layout may follow a row-major or column-major order, for example. Thus, the memory address computed for each tensor element is different from the memory address of each other tensor element. In some implementations, memory addresses are determined such that the sequence of elements accessed during traversal is physically contiguous in memory. In this example, a first tensor element may be stored in a first memory location having a first address, and a second tensor element may be stored in a second memory location located immediately adjacent to the first memory location. A third tensor element may be stored in a third memory location immediately adjacent to the second memory location, and so on. In some implementations, memory addresses are determined such that the sequence of elements accessed during traversal is not physically contiguous in memory. In this example, the second tensor element may not be stored immediately next to the first tensor element.
終了値要素は、次元の終了値を格納してもよい。次元の終了値は、部分アドレスオフセット値がこの次元の初期値にリセットされる値を表す。また、第１のループの部分アドレスオフセット値が第１のループの終了値に等しい場合には、第１のループがネストされる第２のループのステップ値が第２のループの部分アドレスオフセット値に加算される。この例では、内側ネステッドループインデックス変数ｉは、２という終了値を有し、中間ネステッドループインデックス変数ｉは、１２というステップ値を有し、外側ネステッドループインデックス変数ｋは、６という終了値を有する。したがって、内側ネステッドループインデックス変数ｉの部分アドレスオフセット値が２という値に達すると、プロセッサは、内側ネステッドループインデックス変数ｉの部分アドレスオフセット値をゼロにリセットして、中間ネステッドループインデックス変数ｊのステップ値（６）を中間ネステッドループインデックス変数ｊの部分アドレスオフセット値に加算してもよい。これが中間ネステッドループインデックス変数ｊによって追跡されるループの１回目の繰り返しであれば、中間ネステッドループインデックス変数ｊの部分アドレスオフセット値は、６（０＋６）になるであろう。 The end value element may store the end value of the dimension. The end value of a dimension represents the value at which the partial address offset value is reset to the initial value of this dimension. Furthermore, if the partial address offset value of the first loop is equal to the end value of the first loop, the step value of the second loop in which the first loop is nested is equal to the partial address offset value of the second loop. will be added to. In this example, the inner nested loop index variable i has an ending value of 2, the intermediate nested loop index variable i has a step value of 12, and the outer nested loop index variable k has an ending value of 6. . Therefore, when the partial address offset value of the inner nested loop index variable i reaches a value of 2, the processor resets the partial address offset value of the inner nested loop index variable i to zero, and the step of the intermediate nested loop index variable j The value (6) may be added to the partial address offset value of intermediate nested loop index variable j. If this is the first iteration of the loop tracked by intermediate nested loop index variable j, the partial address offset value of intermediate nested loop index variable j would be 6 (0+6).
部分アドレスオフセット値要素２０８は、次元の部分アドレスオフセット値を格納する。この例では、プロセッサは、部分アドレスオフセット値をゼロに設定する。部分アドレスオフセット値は、テンソル要素のメモリアドレスオフセットを求めるために使用される。いくつかの実現例では、特定の変数についての特定のテンソル要素のメモリアドレスは、式２２５に示されるように、テンソル要素の予め指定されたベースアドレスとテンソル要素の次元の部分アドレスオフセット値との合計に基づく。変数Ｖ１では、特定のテンソル要素のメモリアドレスは、テンソル要素のベースアドレスと行２０８ａ（一番上の行）における部分アドレスオフセット値との合計に等しい。したがって、変数Ｖ１（ｉ＝０，ｊ＝０，ｋ＝０）の各次元の第１の要素に対応するテンソル要素では、部分アドレスオフセット値が全てゼロであるので、メモリアドレスは、ベースアドレス＋ゼロに等しい。
Partial address offset
テンソル要素のメモリアドレスは、図１のハードウェア加算器ユニット１２４を使用して求めることができる。たとえば、特定の変数（たとえば、変数Ｖ１）についての加算器への入力は、ベースアドレスおよびこの変数の特定の行（たとえば、変数Ｖ１の行２０８ａ）における各部分アドレスオフセット値要素の値であってもよい。出力は、この変数のメモリアドレスである。
The memory address of the tensor element can be determined using the
図２Ｃは、プログラム２１２に従って要素Ｖ１［０］［０］［０］にアクセスすることを示す。たとえば、プロセッサは、アクセスされる要素に対応するメモリアドレスを突き止める命令「LocateTensor」を実行してもよい。いくつかの実現例では、この命令は、ベースメモリアドレスを含んでもよい。たとえば、命令「LocateTensor」は、変数Ｖ１の第１の要素である要素Ｖ１［０］［０］［０］のメモリアドレスを含んでもよい。いくつかの実現例では、この命令は、アクセス対象のテンソルに対応する行番号を含んでもよい。たとえば、命令「LocateTensor」は、変数Ｖ１に対応する行番号を含んでもよい。ここでは、行番号は１である。
FIG. 2C shows accessing element V1[0][0][0] according to
いくつかの実現例では、テンソルトラバーサルユニットを含むコンピューティングシステムは、テンソルトラバーサルユニットからメモリアドレス値を照会する有限状態機械（
ＦＳＭ）を含んでもよい。たとえば、ＦＳＭは、図２Ｂ～図２Ｈに関連して説明した「LocateTensor」および「IterateTensor」命令などの命令を実行するプロセッサではないプ
ロセッサのメモリアドレス値を照会してもよい。ＦＳＭは、プロセッサを参照して以下で説明するように、ネステッドループを繰り返しトラバースし、ループをトラバースしながら部分アドレス値を繰り返してもよい。次いで、プロセッサは、求められたメモリアドレス値を、それらが求められた通りにハードウェアカウンタまたはＦＳＭから受信することができる。
In some implementations, a computing system that includes a tensor traversal unit uses a finite state machine (
FSM). For example, the FSM may query the memory address value of a processor that is not the processor that executes instructions such as the "LocateTensor" and "IterateTensor" instructions described in connection with FIGS. 2B-2H. The FSM may repeatedly traverse nested loops and repeat partial address values while traversing the loops, as described below with reference to the processor. The processor may then receive the determined memory address values from the hardware counter or FSM as they were determined.
いくつかの実現例では、この命令を受信したことに応答して、ハードウェア加算器ユニット（たとえば、図１のハードウェア加算器ユニット１２４）は、部分アドレス値要素２０８の行１（行２０８ａ）における部分アドレスオフセット値要素２０８の各々に格納された値の合計を計算することによってメモリアドレスオフセットを求める。ここで、ハードウェア加算器ユニットは、要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値の合計を求める。次いで、プロセッサは、ベースメモリアドレスを求められたメモリアドレスオフセット（すなわち、この例では０）に加算してメモリアドレスを求め、求められたメモリアドレスに基づいて、記憶媒体に格納されたデータにアクセスすることによって、要素Ｖ１［０］［０］［０］にアクセスすることができる。別の例では、ハードウェア加算器は、ベースメモリアドレスと要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値との合計を求めることによって要素Ｖ１［０］［０］［０］のメモリアドレスを求めてもよい。次いで、プロセッサは、求められたメモリアドレスに基づいて、記憶媒体に格納されたにアクセスすることができる。
In some implementations, in response to receiving this instruction, a hardware adder unit (e.g.,
図２Ｄは、プログラム２１２に従って要素Ｖ１［０］［０］［１］にアクセスすることを示す。たとえば、プログラムが内側ループの１回目の繰り返しを完了した後、プロセッサは、プログラムが内側ループの２回目の繰り返し（すなわち、ｉ＝０，ｊ＝０，ｋ＝１）に入ったときに部分アドレスオフセット値を更新する命令「IterateTensor」を実行し
てもよい。いくつかの実現例では、テンソルトラバーサルユニットは、内側ループ（内側ネステッドループインデックス変数ｉによって追跡されるループ）に対応する次元の部分アドレスオフセット値要素２０８を、内側ループに対応する次元のステップ値だけインクリメントすることによって、部分アドレスオフセット値を更新する。この例では、部分アドレスオフセット値要素Ｚ１，１に格納された部分アドレスオフセット値は、ハードウェア加算器ユニットを使用して、ステップ値要素Ｘ１，１に格納されたステップ値だけインクリメントされる。内側ループのために格納された、結果として生じる更新後の部分アドレスオフセット値は、Ｚ１，１に格納された以前の値とＸ１，１に格納された値との合計、すなわち０＋１＝１である。
FIG. 2D shows accessing element V1[0][0][1] according to
いくつかの実現例では、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された更新後の部分オフセットアドレス値と要素Ｙ１，１に格納された内側ループの終了値とを比較する。Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値に等しい場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された部分オフセットアドレス値の値を、要素Ｖ１，１に格納された内側ループの初期値にリセットしてもよい。また、以下でより詳細に説明するように、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループに対応する次元の部分アドレスオフセット値を、Ｘ１，２に格納された中間ループのステップ値だけインクリメントしてもよい。 In some implementations, the tensor traversal unit compares the updated partial offset address value stored in element Z 1,1 with the inner loop exit value stored in element Y 1,1 . If the updated partial offset address value stored in Z 1,1 is equal to the end value of the inner loop stored in element Y 1,1 , then the tensor traversal unit returns the partial offset address value stored in element Z 1,1 . The value of the offset address value may be reset to the initial value of the inner loop stored in element V1,1 . As will be explained in more detail below, the tensor traversal unit also assigns the partial address offset value of the dimension corresponding to the intermediate loop stored in elements Z 1,2 to the partial address offset value of the intermediate loop stored in X 1,2 . It may be incremented by the step value.
要素Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値未満である場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された内側ループの更新後の部分アドレス値を保持してもよい。この例では、内側ループの更新後の部分アドレスオフセット値（１）は、内側ループの終了値（２）未
満である。したがって、テンソルトラバーサルユニットは、中間ループの部分アドレスオフセット値をインクリメントすることなく、内側ループの部分アドレスオフセット要素Ｚ１，１に格納された更新後の部分アドレスオフセット値を保持する。
If the updated partial offset address value stored in element Z 1,1 is less than the end value of the inner loop stored in element Y 1,1 , the tensor traversal unit is stored in element Z 1,1 . The updated partial address value of the inner loop may be retained. In this example, the updated partial address offset value (1) of the inner loop is less than the end value (2) of the inner loop. Therefore, the tensor traversal unit retains the updated partial address offset value stored in the partial address offset element Z 1,1 of the inner loop without incrementing the partial address offset value of the intermediate loop.
次いで、プロセッサは、Ｖ１［０］［０］［１］に対応するメモリアドレスを突き止めるための命令「LocateTensor」を実行することによって、要素Ｖ１［０］［０］［１］にアクセスすることができる。この命令を受信したことに応答して、ハードウェア加算器ユニットは、部分アドレス値要素２０８の行１（行２０８ａ）における部分アドレスオフセット値要素２０８の各々に格納された値の合計を計算することによって、メモリアドレスオフセットを求める。ここで、ハードウェア加算器ユニットは、要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値の合計を求める。次いで、プロセッサは、ベースメモリアドレスを求められたメモリアドレスオフセット（すなわち、この例では１）に加算してメモリアドレスを求め、求められたメモリアドレスに基づいて、記憶媒体に格納されたデータにアクセスすることによって、要素Ｖ１［０］［０］［１］にアクセスすることができる。別の例では、ハードウェア加算器は、ベースメモリアドレスと要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値との合計を求めることによって、要素Ｖ１［０］［０］［１］のメモリアドレスを求めてもよい。次いで、プロセッサは、求められたメモリアドレスに基づいて、記憶媒体に格納されたにアクセスすることができる。
The processor can then access element V1[0][0][1] by executing the instruction "LocateTensor" to locate the memory address corresponding to V1[0][0][1]. can. In response to receiving this instruction, the hardware adder unit calculates the sum of the values stored in each of the partial address offset
図２Ｅは、プログラム２１２に従って要素Ｖ１［０］［１］［０］にアクセスすることを示す。たとえば、プログラムが内側ループの２回目の繰り返しを完了した後、プロセッサは、プログラムが中間ループの２回目の繰り返し（すなわち、ｉ＝０，ｊ＝１，ｋ＝０）に入ったときに部分アドレスオフセット値を更新する命令「IterateTensor」を実行し
てもよい。いくつかの実現例では、テンソルトラバーサルユニットは、内側ループ（内側ネステッドループインデックス変数ｉによって追跡されるループ）に対応する次元の部分アドレスオフセット値要素２０８を、内側ループに対応する次元のステップ値だけインクリメントすることによって、部分アドレスオフセット値を更新する。この例では、部分アドレスオフセット値要素Ｚ１，１に格納された部分アドレスオフセット値は、ハードウェア加算器ユニットを使用して、ステップ値要素Ｘ１，１に格納されたステップ値だけインクリメントされる。内側ループのために格納された、結果として生じる更新後の部分アドレスオフセット値は、Ｚ１，１に格納された以前の値とＸ１，１に格納された値との合計、すなわち１＋１＝２である。
FIG. 2E shows accessing element V1[0][1][0] according to
いくつかの実現例では、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された更新後の部分オフセットアドレス値と要素Ｙ１，１に格納された内側ループの終了値とを比較する。Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値に等しい場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された部分オフセットアドレス値の値を、要素Ｖ１，１に格納された内側ループの初期値にリセットしてもよい。また、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループに対応する次元の部分アドレスオフセット値を、Ｘ１，２に格納された中間ループのステップ値だけインクリメントしてもよい。 In some implementations, the tensor traversal unit compares the updated partial offset address value stored in element Z 1,1 with the inner loop exit value stored in element Y 1,1 . If the updated partial offset address value stored in Z 1,1 is equal to the end value of the inner loop stored in element Y 1,1 , then the tensor traversal unit returns the partial offset address value stored in element Z 1,1 . The value of the offset address value may be reset to the initial value of the inner loop stored in element V1,1 . The tensor traversal unit may also increment the partial address offset value of the dimension corresponding to the intermediate loop stored in elements Z 1,2 by the step value of the intermediate loop stored in X 1,2 .
要素Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値未満である場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された内側ループの更新後の部分アドレス値を保持してもよい。この例では、内側ループの更新後の部分アドレスオフセット値（２）は、内側ループの終了値（２）に等しい。したがって、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された部分オフセットアドレス値を、要素Ｖ１，１に格納された初期値にリセットする。また、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループの部分アドレスオフセット値を、Ｘ１，２に格納された中間ループのステップ値だけインクリメントする。こ
の例では、中間ループの更新後の部分アドレスオフセット値は、６（０＋６）である。
If the updated partial offset address value stored in element Z 1,1 is less than the end value of the inner loop stored in element Y 1,1 , the tensor traversal unit is stored in element Z 1,1 . The updated partial address value of the inner loop may be retained. In this example, the inner loop's updated partial address offset value (2) is equal to the inner loop's end value (2). Therefore, the tensor traversal unit resets the partial offset address value stored in element Z 1,1 to the initial value stored in element V 1,1 . The tensor traversal unit also increments the partial address offset value of the intermediate loop stored in elements Z 1,2 by the step value of the intermediate loop stored in X 1,2 . In this example, the updated partial address offset value of the intermediate loop is 6 (0+6).
いくつかの実現例では、テンソルトラバーサルユニットは、中間ループの部分オフセットアドレス値を更新すると判断したことに応答して、要素Ｚ１，２に格納された中間ループの更新後の部分オフセットアドレス値と、要素Ｙ１，２に格納された中間ループの終了値とを比較する。Ｚ１，２に格納された中間ループ値の更新後の部分オフセットアドレスが、要素Ｙ１，２に格納された中間ループの終了値に等しい場合、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された部分オフセットアドレス値の値を、要素Ｖ１，２に格納された中間ループの初期値にリセットしてもよい。また、以下で説明するように、テンソルトラバーサルユニットは、要素Ｚ１，３に格納された外側ループに対応する次元の部分アドレスオフセット値を、Ｘ１，３に格納された外側ループのステップ値だけインクリメントしてもよい。
In some implementations, the tensor traversal unit, in response to determining to update the intermediate loop's partial offset address value, updates the intermediate loop's updated partial offset address value stored in element Z1,2 . , and the end value of the intermediate loop stored in elements Y1 and Y2 . If the updated partial offset address of the intermediate loop value stored in Z 1 , 2 is equal to the end value of the intermediate loop stored in element Y 1, 2 , the tensor traversal unit stores the intermediate loop value in element Z 1, 2 . The value of the partial offset address value may be reset to the initial value of the intermediate loop stored in elements V1 and 2 . Also, as explained below, the tensor traversal unit replaces the partial address offset value of the dimension corresponding to the outer loop stored in
要素Ｚ１，２に格納された中間ループの更新後の部分オフセットアドレス値が、要素Ｙ１，２に格納された中間ループの終了値未満である場合、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループの更新後の部分アドレス値を保持してもよい。この例では、中間ループの更新後の部分アドレスオフセット値（６）は、内側ループの終了値（１２）未満である。したがって、テンソルトラバーサルユニットは、外側ループの部分アドレスオフセット値をインクリメントすることなく、中間ループの部分アドレスオフセット要素Ｚ１，２に格納された更新後の部分アドレスオフセット値を保持する。 If the updated partial offset address value of the intermediate loop stored in elements Z 1 , 2 is less than the end value of the intermediate loop stored in elements Y 1, 2 , the tensor traversal unit The updated partial address value of the intermediate loop stored in the intermediate loop may be retained. In this example, the updated partial address offset value (6) of the middle loop is less than the end value (12) of the inner loop. Therefore, the tensor traversal unit retains the updated partial address offset value stored in the partial address offset element Z1,2 of the middle loop without incrementing the partial address offset value of the outer loop.
次いで、プロセッサは、Ｖ１［０］［１］［０］に対応するメモリアドレスを突き止めるための命令「LocateTensor」を実行することによって、要素Ｖ１［０］［１］［０］にアクセスすることができる。この命令を受信したことに応答して、ハードウェア加算器ユニットは、部分アドレス値要素２０８の行１（行２０８ａ）における部分アドレスオフセット値要素２０８の各々に格納された値の合計を計算することによって、メモリアドレスオフセットを求める。ここで、ハードウェア加算器ユニットは、要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値の合計を求める。次いで、プロセッサは、ベースメモリアドレスを求められたメモリアドレスオフセット（すなわち、この例では６）に加算してメモリアドレスを求め、求められたメモリアドレスに基づいて、記憶媒体に格納されたデータにアクセスすることによって、要素Ｖ１［０］［１］［０］にアクセスすることができる。別の例では、ハードウェア加算器は、ベースメモリアドレスと要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値との合計を求めることによって、要素Ｖ１［０］［１］［０］のメモリアドレスを求めてもよい。次いで、プロセッサは、求められたメモリアドレスに基づいて、記憶媒体に格納されたにアクセスすることができる。
The processor can then access element V1[0][1][0] by executing the instruction "LocateTensor" to locate the memory address corresponding to V1[0][1][0]. can. In response to receiving this instruction, the hardware adder unit calculates the sum of the values stored in each of the partial address offset
図２Ｆは、プログラム２１２に従って要素Ｖ１［０］［１］［１］にアクセスすることを示す。たとえば、プログラムが中間ループの２回目の繰り返しのための内側ループの１回目の繰り返しを完了した後、プロセッサは、プログラムが中間ループの２回目の繰り返しのための内側ループの２回目の繰り返し（すなわち、ｉ＝０，ｊ＝１，ｋ＝１）に入ったときに部分アドレスオフセット値を更新する命令「IterateTensor」を実行してもよい
。いくつかの実現例では、テンソルトラバーサルユニットは、内側ループ（内側ネステッドループインデックス変数ｉによって追跡されるループ）に対応する次元の部分アドレスオフセット値要素２０８を、内側ループに対応する次元のステップ値だけインクリメントすることによって、部分アドレスオフセット値を更新する。この例では、部分アドレスオフセット値要素Ｚ１，１に格納された部分アドレスオフセット値は、ハードウェア加算器ユニットを使用して、ステップ値要素Ｘ１，１に格納されたステップ値だけインクリメントされる。内側ループのために格納される、結果として生じる更新後の部分アドレスオフセット値は、Ｚ１，１に格納された以前の値とＸ１，１に格納された値との合計、すなわち０＋１＝２である。
FIG. 2F shows accessing element V1[0][1][1] according to
いくつかの実現例では、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された更新後の部分オフセットアドレス値と、要素Ｙ１，１に格納された内側ループの終了値とを比較する。Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値に等しい場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された部分オフセットアドレス値の値を、要素Ｖ１，１に格納された内側ループの初期値にリセットしてもよい。また、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループに対応する次元の部分アドレスオフセット値を、Ｘ１，２に格納された中間ループのステップ値だけインクリメントしてもよい。 In some implementations, the tensor traversal unit compares the updated partial offset address value stored in element Z 1,1 with the inner loop exit value stored in element Y 1,1 . If the updated partial offset address value stored in Z 1,1 is equal to the end value of the inner loop stored in element Y 1,1 , then the tensor traversal unit returns the partial offset address value stored in element Z 1,1 . The value of the offset address value may be reset to the initial value of the inner loop stored in element V1,1 . The tensor traversal unit may also increment the partial address offset value of the dimension corresponding to the intermediate loop stored in elements Z 1,2 by the step value of the intermediate loop stored in X 1,2 .
要素Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値未満である場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された内側ループの更新後の部分アドレス値を保持してもよい。この例では、内側ループの更新後の部分アドレスオフセット値（１）は、内側ループの終了値（２）未満である。したがって、テンソルトラバーサルユニットは、中間ループの部分アドレスオフセット値をインクリメントすることなく、内側ループの部分アドレスオフセット要素Ｚ１，１に格納された更新後の部分アドレスオフセット値を保持する。 If the updated partial offset address value stored in element Z 1,1 is less than the end value of the inner loop stored in element Y 1,1 , the tensor traversal unit is stored in element Z 1,1 . The updated partial address value of the inner loop may be retained. In this example, the updated partial address offset value (1) of the inner loop is less than the end value (2) of the inner loop. Therefore, the tensor traversal unit retains the updated partial address offset value stored in the partial address offset element Z 1,1 of the inner loop without incrementing the partial address offset value of the intermediate loop.
次いで、プロセッサは、Ｖ１［０］［１］［１］に対応するメモリアドレスを突き止めるための命令「LocateTensor」を実行することによって、要素Ｖ１［０］［１］［１］にアクセスすることができる。この命令を受信したことに応答して、ハードウェア加算器ユニットは、部分アドレス値要素２０８の行１（行２０８ａ）における部分アドレスオフセット値要素２０８の各々に格納された値の合計を計算することによって、メモリアドレスオフセットを求める。ここで、ハードウェア加算器ユニットは、要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値の合計を求める。次いで、プロセッサは、ベースメモリアドレスを求められたメモリアドレスオフセット（すなわち、この例では７）を加算してメモリアドレスを求め、求められたメモリアドレスに基づいて、記憶媒体に格納されたデータにアクセスすることによって、要素Ｖ１［０］［１］［１］にアクセスすることができる。別の例では、ハードウェア加算器は、ベースメモリアドレスと要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値との合計を求めることによって、要素Ｖ１［０］［１］［１］のメモリアドレスを求めてもよい。次いで、プロセッサは、求められたメモリアドレスに基づいて、記憶媒体に格納されたにアクセスすることができる。
The processor can then access element V1[0][1][1] by executing the instruction "LocateTensor" to locate the memory address corresponding to V1[0][1][1]. can. In response to receiving this instruction, the hardware adder unit calculates the sum of the values stored in each of the partial address offset
図２Ｇは、プログラム２１２に従って要素Ｖ１［１］［０］［０］にアクセスすることを示す。たとえば、プログラムが中間ループの２回目の繰り返しのための内側ループの２回目の繰り返しを完了した後、プロセッサは、プログラムが外側ループの２回目の繰り返し（すなわち、ｉ＝１，ｊ＝０，ｋ＝０）に入ったときに部分アドレスオフセット値を更新する命令「IterateTensor」を実行してもよい。いくつかの実現例では、テンソルトラ
バーサルユニットは、内側ループ（内側ネステッドループインデックス変数ｉによって追跡されるループ）に対応する次元の部分アドレスオフセット値要素２０８を、内側ループに対応する次元のステップ値だけインクリメントすることによって、部分アドレスオフセット値を更新する。この例では、部分アドレスオフセット値要素Ｚ１，１に格納された部分アドレスオフセット値は、ハードウェア加算器ユニットを使用して、ステップ値要素Ｘ１，１に格納されたステップ値だけインクリメントされる。内側ループのために格納される、結果として生じる更新後の部分アドレスオフセット値は、Ｚ１，１に格納された以前の値とＸ１，１に格納された値との合計、すなわち１＋１＝２である。
FIG. 2G shows accessing element V1[1][0][0] according to
いくつかの実現例では、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された更新後の部分オフセットアドレス値と、要素Ｙ１，１に格納された内側ループの終了値とを比較する。Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１
に格納された内側ループの終了値に等しい場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された部分オフセットアドレス値の値を、要素Ｖ１，１に格納された内側ループの初期値にリセットしてもよい。また、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループに対応する次元の部分アドレスオフセット値を、Ｘ１，２に格納された中間ループのステップ値だけインクリメントしてもよい。
In some implementations, the tensor traversal unit compares the updated partial offset address value stored in element Z 1,1 with the inner loop exit value stored in element Y 1,1 . The updated partial offset address value stored in Z 1,1 is the element Y 1,1
, the tensor traversal unit sets the value of the partial offset address value stored in element Z 1,1 to the initial value of the inner loop stored in element V 1,1 . You can reset it. The tensor traversal unit may also increment the partial address offset value of the dimension corresponding to the intermediate loop stored in elements Z 1,2 by the step value of the intermediate loop stored in X 1,2 .
要素Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値未満である場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された内側ループの更新後の部分アドレス値を保持してもよい。この例では、内側ループの更新後の部分アドレスオフセット値（２）は、内側ループの終了値（２）に等しい。したがって、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された部分オフセットアドレス値を、要素Ｖ１，１に格納された初期値にリセットする。また、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループの部分アドレスオフセット値を、Ｘ１，２に格納された中間ループのステップ値だけインクリメントする。この例では、中間ループの更新後の部分アドレスオフセット値は、１２（６＋６）である。 If the updated partial offset address value stored in element Z 1,1 is less than the end value of the inner loop stored in element Y 1,1 , the tensor traversal unit is stored in element Z 1,1 . The updated partial address value of the inner loop may be retained. In this example, the inner loop's updated partial address offset value (2) is equal to the inner loop's end value (2). Therefore, the tensor traversal unit resets the partial offset address value stored in element Z 1,1 to the initial value stored in element V 1,1 . The tensor traversal unit also increments the partial address offset value of the intermediate loop stored in elements Z 1,2 by the step value of the intermediate loop stored in X 1,2 . In this example, the updated partial address offset value of the intermediate loop is 12 (6+6).
いくつかの実現例では、テンソルトラバーサルユニットは、中間ループの部分オフセットアドレス値を更新すると判断したことに応答して、要素Ｚ１，２に格納された中間ループの更新後の部分オフセットアドレス値と、要素Ｙ１，２に格納された中間ループの終了値とを比較する。Ｚ１，２に格納された中間ループの更新後の部分オフセットアドレスが、要素Ｙ１，２に格納された中間ループの終了値に等しい場合、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された部分オフセットアドレス値の値を、要素Ｖ１，２に格納された中間ループの初期値にリセットしてもよい。また、テンソルトラバーサルユニットは、要素Ｚ１，３に格納された外側ループに対応する次元の部分アドレスオフセット値を、Ｘ１，３に格納された外側ループのステップ値だけインクリメントしてもよい。
In some implementations, the tensor traversal unit, in response to determining to update the intermediate loop's partial offset address value, updates the intermediate loop's updated partial offset address value stored in element Z1,2 . , and the end value of the intermediate loop stored in elements Y1 and Y2 . If the updated partial offset address of the intermediate loop stored in
要素Ｚ１，２に格納された中間ループの更新後の部分オフセットアドレス値が、要素Ｙ１，２に格納された中間ループの終了値未満である場合、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループの更新後の部分アドレス値を保持してもよい。この例では、中間ループの更新後の部分アドレスオフセット値（１２）は、中間ループの終了値（１２）に等しい。したがって、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された部分オフセットアドレス値を、要素Ｖ１，２に格納された初期値にリセットする。また、テンソルトラバーサルユニットは、要素Ｚ１，３に格納された外側ループの部分アドレスオフセット値を、Ｘ１，３に格納された外側ループのステップ値だけインクリメントする。この例では、外側ループの更新後の部分アドレスオフセット値は、２（０＋２）である。 If the updated partial offset address value of the intermediate loop stored in elements Z 1 , 2 is less than the end value of the intermediate loop stored in elements Y 1, 2 , the tensor traversal unit The updated partial address value of the intermediate loop stored in the intermediate loop may be retained. In this example, the intermediate loop's updated partial address offset value (12) is equal to the intermediate loop's end value (12). Therefore, the tensor traversal unit resets the partial offset address values stored in elements Z 1,2 to the initial values stored in elements V 1,2 . The tensor traversal unit also increments the outer loop partial address offset value stored in element Z 1,3 by the outer loop step value stored in X 1,3 . In this example, the updated partial address offset value of the outer loop is 2(0+2).
次いで、プロセッサは、Ｖ１［１］［０］［０］に対応するメモリアドレスを突き止めるための命令「LocateTensor」を実行することによって、要素Ｖ１［１］［０］［０］にアクセスすることができる。この命令を受信したことに応答して、ハードウェア加算器ユニットは、部分アドレス値要素２０８の行１（行２０８ａ）における部分アドレスオフセット値要素２０８の各々に格納された値の合計を計算することによって、メモリアドレスオフセットを求める。ここで、ハードウェア加算器ユニットは、要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値の合計を求める。次いで、プロセッサは、ベースメモリアドレスを求められたメモリアドレスオフセット（すなわち、この例では２）に加算してメモリアドレスを求め、求められたメモリアドレスに基づいて、記憶媒体に格納されたデータにアクセスすることによって、要素Ｖ１［１］［０］［０］にアクセスすることができる。別の例では、ハードウェア加算器は、ベースメモリアドレスと要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値との合計を求めることによって、要素Ｖ１［１］［０］［０］のメモリアドレスを求めてもよい。次いで、プロセッサは、求められたメモリアド
レスに基づいて、記憶媒体に格納されたにアクセスすることができる。
The processor can then access element V1[1][0][0] by executing the instruction "LocateTensor" to locate the memory address corresponding to V1[1][0][0]. can. In response to receiving this instruction, the hardware adder unit calculates the sum of the values stored in each of the partial address offset
図２Ｈは、プログラム２１２に従って要素Ｖ１［１］［０］［１］にアクセスすることを示す。たとえば、プログラムが外側ループの２回目の繰り返しのための内側ループの１回目の繰り返しを完了した後、プロセッサは、プログラムが外側ループの２回目の繰り返しのための内側ループの２回目の繰り返し（すなわち、ｉ＝１，ｊ＝０，ｋ＝１）に入ったときに部分アドレスオフセット値を更新する命令「IterateTensor」を実行してもよい
。いくつかの実現例では、テンソルトラバーサルユニットは、内側ループ（内側ネステッドループインデックス変数ｉによって追跡されるループ）に対応する次元の部分アドレスオフセット値要素２０８を、内側ループに対応する次元のステップ値だけインクリメントすることによって、部分アドレスオフセット値を更新する。この例では、部分アドレスオフセット値要素Ｚ１，１に格納された部分アドレスオフセット値は、ハードウェア加算器ユニットを使用して、ステップ値要素Ｘ１，１に格納されたステップ値だけインクリメントされる。内側ループのために格納される、結果として生じる更新後の部分アドレスオフセット値は、Ｚ１，１に格納された以前の値と、Ｘ１，１に格納された値との合計、すなわち０＋１＝２である。
FIG. 2H shows accessing element V1[1][0][1] according to
いくつかの実現例では、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された更新後の部分オフセットアドレス値と、要素Ｙ１，１に格納された内側ループの終了値とを比較する。Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値に等しい場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された部分オフセットアドレス値の値を、要素Ｖ１，１に格納された内側ループの初期値にリセットしてもよい。また、テンソルトラバーサルユニットは、要素Ｚ１，２に格納された中間ループに対応する次元の部分アドレスオフセット値を、Ｘ１，２に格納された中間ループのステップ値だけインクリメントしてもよい。 In some implementations, the tensor traversal unit compares the updated partial offset address value stored in element Z 1,1 with the inner loop exit value stored in element Y 1,1 . If the updated partial offset address value stored in Z 1,1 is equal to the end value of the inner loop stored in element Y 1,1 , then the tensor traversal unit returns the partial offset address value stored in element Z 1,1 . The value of the offset address value may be reset to the initial value of the inner loop stored in element V1,1 . The tensor traversal unit may also increment the partial address offset value of the dimension corresponding to the intermediate loop stored in elements Z 1,2 by the step value of the intermediate loop stored in X 1,2 .
要素Ｚ１，１に格納された更新後の部分オフセットアドレス値が、要素Ｙ１，１に格納された内側ループの終了値未満である場合、テンソルトラバーサルユニットは、要素Ｚ１，１に格納された内側ループの更新後の部分アドレス値を保持してもよい。この例では、内側ループの更新後の部分アドレスオフセット値（１）は、内側ループの終了値（２）未満である。したがって、テンソルトラバーサルユニットは、中間ループの部分アドレスオフセット値をインクリメントすることなく、内側ループの部分アドレスオフセット要素Ｚ１，１に格納された更新後の部分アドレスオフセット値を保持する。 If the updated partial offset address value stored in element Z 1,1 is less than the end value of the inner loop stored in element Y 1,1 , the tensor traversal unit is stored in element Z 1,1 . The updated partial address value of the inner loop may be retained. In this example, the updated partial address offset value (1) of the inner loop is less than the end value (2) of the inner loop. Therefore, the tensor traversal unit retains the updated partial address offset value stored in the partial address offset element Z 1,1 of the inner loop without incrementing the partial address offset value of the intermediate loop.
次いで、プロセッサは、Ｖ１［１］［０］［１］に対応するメモリアドレスを突き止めるための命令「LocateTensor」を実行することによって、要素Ｖ１［１］［０］［１］にアクセスすることができる。この命令を受信したことに応答して、ハードウェア加算器ユニットは、部分アドレス値要素２０８の行１（行２０８ａ）における部分アドレスオフセット値要素２０８の各々に格納された値の合計を計算することによって、メモリアドレスオフセットを求める。ここで、ハードウェア加算器ユニットは、要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値の合計を求める。次いで、プロセッサは、ベースメモリアドレスを求められたメモリアドレスオフセット（すなわち、この例では３）に加算してメモリアドレスを求め、求められたメモリアドレスに基づいて、記憶媒体に格納されたデータにアクセスすることによって、要素Ｖ１［１］［０］［１］にアクセスすることができる。別の例では、ハードウェア加算器は、ベースメモリアドレスと要素Ｚ１，１、Ｚ１，２およびＺ１，３に格納された値との合計を求めることによって、要素Ｖ１［１］［０］［１］のメモリアドレスを求めてもよい。次いで、プロセッサは、求められたメモリアドレスに基づいて、記憶媒体に格納されたにアクセスすることができる。
The processor can then access element V1[1][0][1] by executing the instruction "LocateTensor" to locate the memory address corresponding to V1[1][0][1]. can. In response to receiving this instruction, the hardware adder unit calculates the sum of the values stored in each of the partial address offset
テンソルトラバーサルユニットは、ネステッドループの残りの繰り返しについてメモリ
アドレスを求めて、同様の態様で残りのテンソル要素にアクセスし続けることができる。以下の表１は、図２Ａ～図２Ｈに示されるステップ値を使用したテンソル要素のメモリアドレスオフセット値を示す。
The tensor traversal unit can continue to access the remaining tensor elements in a similar manner, seeking memory addresses for the remaining iterations of the nested loop. Table 1 below shows memory address offset values for tensor elements using the step values shown in FIGS. 2A-2H.
図３は、多次元テンソル変数のアドレスを求めるためのプロセスの一例３００を示すフロー図である。プロセス３００は、１つ以上のコンピュータのシステム、たとえば図１のコンピューティングシステム１００によって実行されてもよい。このシステムは、初期値要素とステップ値要素と終了値要素と部分アドレスオフセット要素とを含むテンソルアドレス値要素を有するテンソルトラバーサルユニットを含む。テンソルトラバーサルユニットは、１つ以上のハードウェア加算器を有するハードウェア加算器ユニットも含む。
FIG. 3 is a flow diagram illustrating an
このシステムは、Ｎ次元テンソルの特定の要素にアクセスするための命令を取得する（３０２）。Ｎ次元テンソルは、Ｎ個の次元の各々にわたって配置された複数の要素を含み得て、Ｎは、１以上の整数である。たとえば、このシステムは、テンソルの特定の要素にアクセスするための命令を実行する処理ユニット（たとえば、処理ユニット１０２）を含んでもよい。 The system obtains instructions to access specific elements of the N-dimensional tensor (302). An N-dimensional tensor may include multiple elements arranged across each of N dimensions, where N is an integer greater than or equal to 1. For example, the system may include a processing unit (eg, processing unit 102) that executes instructions to access particular elements of the tensor.
いくつかの実現例では、命令は、第１のループと第２のループと第３のループとを含むネステッドループを処理するための命令を表してもよい。第１のループは、第２のループ内にネストされた内側ループであってもよく、第２のループは、第３のループ内にネストされた中間ループであってもよい。第１のループは、第１のインデックス変数を使用して繰り返されてもよい。同様に、第２のループは、第２のインデックス変数を使用して繰り
返されてもよく、第３のループは、第３のインデックス変数を使用して繰り返されてもよい。たとえば、プログラムは、記憶媒体に格納されてもよく、処理ユニットによって実行可能である。プログラムは、文字配列変数Ｖ１（または、別のタイプの配列）、２という第１の次元、２という第２の次元および３という第３の次元を指定してもよい。プログラムは、変数Ｖ１をトラバースするためのネステッドｆｏｒループを指定してもよい。このｆｏｒループは、ネステッドループインデックス変数ｉによって追跡される外側ループにおいてＶ１の第３の次元をトラバースしてもよい。また、このｆｏｒループは、ネステッドループインデックス変数ｊによって追跡される中間ループにおいてＶ１の第２の次元をトラバースしてもよく、ネステッドループインデックス変数ｋによって追跡される内側ループにおいて第１の次元をトラバースしてもよい。
In some implementations, the instructions may represent instructions for processing a nested loop that includes a first loop, a second loop, and a third loop. The first loop may be an inner loop nested within a second loop, and the second loop may be an intermediate loop nested within a third loop. The first loop may be repeated using the first index variable. Similarly, a second loop may be repeated using a second index variable, and a third loop may be repeated using a third index variable. For example, the program may be stored on a storage medium and executable by a processing unit. The program may specify a character array variable V1 (or another type of array), a first dimension of 2, a second dimension of 2, and a third dimension of 3. The program may specify a nested for loop to traverse variable V1. This for loop may traverse the third dimension of V1 in the outer loop tracked by the nested loop index variable i. This for loop may also traverse the second dimension of V1 in an intermediate loop tracked by nested loop index variable j, and the first dimension in an inner loop tracked by nested loop index variable k. You may.
このシステムは、１つ以上のハードウェア加算器および部分アドレスオフセット要素を使用して、特定の要素のアドレスを求める（３０４）。いくつかの実現例では、特定の要素のアドレスは、Ｎ次元テンソルの別の要素からオフセットされたアドレスであってもよい。たとえば、特定の要素のアドレスは、Ｎ次元テンソルの別の要素のベースメモリアドレスからオフセットされたアドレスであってもよい。１つ以上のテンソルインデックス要素の各テンソルインデックス要素について、このシステムは、ハードウェア加算器を使用してベースメモリアドレスとともに部分アドレスオフセット要素の現在の値を加算することによって、メモリアドレスを求めてもよい。部分アドレスオフセット要素の現在の値は、ループの現在の繰り返しに基づく。 The system uses one or more hardware adders and partial address offset elements to determine the address of a particular element (304). In some implementations, the address of a particular element may be an address offset from another element of the N-dimensional tensor. For example, the address of a particular element may be an address offset from the base memory address of another element of the N-dimensional tensor. For each tensor index element of one or more tensor index elements, the system also determines the memory address by adding the current value of the partial address offset element along with the base memory address using a hardware adder. good. The current value of the partial address offset element is based on the current iteration of the loop.
いくつかの実現例では、テンソルの要素のうちのいずれかの要素のアドレスオフセットを求める前に、このシステムは、テンソルアドレス値要素に格納された値を設定してもよい。たとえば、プロセッサは、テンソルアドレス値要素を初期化する命令「InitializeElements」を実行してもよい。 In some implementations, before determining the address offset of any of the elements of the tensor, the system may set the value stored in the tensor address value element. For example, a processor may execute an instruction "InitializeElements" that initializes tensor address value elements.
内側ループの各繰り返しについて、このシステムは、内側ループのステップ値を使用して内側ループの部分アドレスオフセット値を更新してもよい。中間および外側ループの１回目の繰り返しのための内側ループの１回目の繰り返しの前（すなわち、ｉ＝０，ｊ＝０，ｋ＝０）に、内側ループの部分アドレスオフセット値は、内側ループの初期値に設定されてもよい。 For each iteration of the inner loop, the system may update the inner loop partial address offset value using the inner loop step value. Before the first iteration of the inner loop for the first iteration of the middle and outer loops (i.e., i=0, j=0, k=0), the partial address offset value of the inner loop is It may be set to the initial value.
内側ループの各繰り返し後、このシステムは、内側ループの部分アドレスオフセット値を、内側ループの以前の部分アドレスオフセット値と内側ループのステップ値との合計に更新してもよい。次いで、このシステムは、内側ループの更新後の部分アドレスオフセット値と内側ループの終了値とを比較してもよい。内側ループの更新後の部分アドレスオフセット値が内側ループの終了値未満である場合、このシステムは、少なくとも内側ループの次の繰り返しまでは、他の部分アドレスオフセット値のいずれも修正することなく、部分アドレスオフセット値要素における内側ループの更新後の部分アドレスオフセット値を維持してもよい。 After each iteration of the inner loop, the system may update the inner loop partial address offset value to the sum of the inner loop's previous partial address offset value and the inner loop step value. The system may then compare the inner loop's updated partial address offset value and the inner loop's end value. If the inner loop's updated partial address offset value is less than the inner loop's exit value, the system updates the partial address offset value without modifying any of the other partial address offset values, at least until the next iteration of the inner loop. The updated partial address offset value of the inner loop in the address offset value element may be maintained.
この更新後の部分アドレスオフセット値が内側ループの終了値に等しい場合、このシステムは、部分アドレスオフセット値を内側ループの初期値にリセットし、内側ループのステップ値を使用して中間ループの部分アドレスオフセット値をインクリメントしてもよい。たとえば、このシステムは、中間ループの部分アドレスオフセット値を、中間ループの以前の部分アドレスオフセット値と中間ループのステップ値との合計に更新してもよい。次いで、このシステムは、中間ループの更新後の部分アドレスオフセット値と中間ループの終了値とを比較してもよい。中間ループの更新後の部分アドレスオフセット値が、内側ループの終了値未満である場合、このシステムは、少なくとも中間ループの次の繰り返しまでは、他の部分アドレスオフセット値のいずれも修正することなく、部分アドレスオフ
セット値要素における中間ループの更新後の部分アドレスオフセット値を維持してもよい。
If this updated partial address offset value is equal to the end value of the inner loop, the system resets the partial address offset value to the initial value of the inner loop and uses the step value of the inner loop to address the partial address of the intermediate loop. The offset value may be incremented. For example, the system may update the intermediate loop partial address offset value to the sum of the intermediate loop's previous partial address offset value and the intermediate loop step value. The system may then compare the intermediate loop's updated partial address offset value to the intermediate loop's end value. If the updated partial address offset value of the intermediate loop is less than the ending value of the inner loop, the system will update the partial address offset value without modifying any of the other partial address offset values, at least until the next iteration of the intermediate loop. The updated partial address offset value of the intermediate loop in the partial address offset value element may be maintained.
この更新後の部分アドレスオフセット値が中間ループの終了値に等しい場合、このシステムは、部分アドレスオフセット値を中間ループの初期値にリセットし、外側ループのステップ値を使用して外側ループの部分アドレスオフセット値をインクリメントしてもよい。たとえば、このシステムは、外側ループの部分アドレスオフセット値を、外側ループの以前の部分アドレスオフセット値と外側ループのステップ値との合計に更新してもよい。次いで、このシステムは、外側ループの更新後の部分アドレスオフセット値と外側ループの終了値とを比較してもよい。 If this updated partial address offset value is equal to the intermediate loop's exit value, the system resets the partial address offset value to the intermediate loop's initial value and uses the outer loop's step value to The offset value may be incremented. For example, the system may update the outer loop partial address offset value to the sum of the outer loop's previous partial address offset value and the outer loop step value. The system may then compare the outer loop's updated partial address offset value and the outer loop's end value.
外側ループの更新後の部分アドレスオフセット値が外側ループの終了値未満である場合、このシステムは、部分アドレスオフセット値要素における外側ループの更新後の部分アドレスオフセット値を維持してもよい。この更新後の部分アドレスオフセット値が外側ループの終了値に等しい場合、このシステムは、テンソルの各要素がアクセスされたときに各ループの部分アドレスオフセット値をそれらのそれぞれの初期値にリセットしてもよい。 If the outer loop's updated partial address offset value is less than the outer loop's ending value, the system may maintain the outer loop's updated partial address offset value in the partial address offset value element. If this updated partial address offset value is equal to the outer loop's exit value, the system resets each loop's partial address offset value to their respective initial value as each element of the tensor is accessed. Good too.
このシステムは、Ｎ次元テンソルの特定の要素にアクセスするための求められたアドレスを示すデータを出力する（３０６）。たとえば、テンソルトラバーサルユニットは、現在の部分アドレスオフセット値とベースメモリアドレスとの合計に基づいて、求められたアドレスを出力してもよい。システムの処理ユニットは、メモリアドレスオフセット値を使用して、記憶媒体におけるＮ次元配列変数の特定の要素にアクセスしてもよい。 The system outputs data indicating the determined address for accessing a particular element of the N-dimensional tensor (306). For example, the tensor traversal unit may output the determined address based on the sum of the current partial address offset value and the base memory address. A processing unit of the system may use the memory address offset value to access a particular element of the N-dimensional array variable on the storage medium.
本明細書に記載されている主題および機能動作の実施形態は、デジタル電子回路、有形に具体化されたコンピュータソフトウェアもしくはファームウェア、本明細書に開示されている構造およびそれらの構造的等価物を含むコンピュータハードウェア、またはそれらのうちの１つ以上の組み合わせで実現することができる。本明細書に記載されている主題の実施形態は、１つ以上のコンピュータプログラムとして、すなわちデータ処理装置によって実行されるようにまたはデータ処理装置の動作を制御するように有形の非一時的なプログラムキャリア上に符号化されたコンピュータプログラム命令の１つ以上のモジュールとして、実現することができる。代替的にまたは加えて、プログラム命令は、人為的に生成された伝搬信号、たとえば情報を符号化して好適な受信機装置に送信してデータ処理装置によって実行するように生成される、機械によって生成される電気信号、光信号または電磁信号、上に符号化することができる。コンピュータ記憶媒体は、機械読取可能な記憶装置、機械読取可能な記憶基板、ランダムもしくはシリアルアクセスメモリデバイス、またはそれらのうちの１つ以上の組み合わせであってもよい。 Embodiments of the subject matter and functional operations described herein include digital electronic circuits, tangibly embodied computer software or firmware, structures disclosed herein and structural equivalents thereof. It can be implemented in computer hardware, or a combination of one or more thereof. Embodiments of the subject matter described herein may be implemented as one or more computer programs, i.e., tangible, non-transitory programs configured to be executed by or to control the operation of a data processing device. It can be implemented as one or more modules of computer program instructions encoded on a carrier. Alternatively or additionally, the program instructions may be machine-generated, such as an artificially generated propagated signal, such as a machine-generated signal that encodes information for transmission to a suitable receiver device for execution by a data processing device. can be encoded onto electrical, optical or electromagnetic signals. A computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more thereof.
本明細書に記載されているプロセスおよび論理フローは、１つ以上のプログラム可能なコンピュータが入力データ上で動作して出力を生成することによって機能を実行するように１つ以上のコンピュータプログラムを実行することによって実行することができる。プロセスおよび論理フローは、特殊目的論理回路、たとえばＦＰＧＡ（フィールドプログラマブルゲートアレイ）、ＡＳＩＣ（特定用途向け集積回路）またはＧＰＧＰＵ（汎用グラフィックス処理ユニット）、によっても実行することができ、装置は、特殊目的論理回路としても実現することができる。 The processes and logic flows described herein enable one or more programmable computers to execute one or more computer programs to perform functions by operating on input data and producing output. It can be executed by The processes and logic flows can also be performed by special purpose logic circuits, such as FPGAs (Field Programmable Gate Arrays), ASICs (Application Specific Integrated Circuits) or GPGPUs (General Purpose Graphics Processing Units); It can also be realized as a purpose logic circuit.
コンピュータプログラムの実行に適したコンピュータは、一例として、汎用マイクロプロセッサもしくは特殊目的マイクロプロセッサもしくはそれら両方、またはその他の種類の中央処理装置を含み、それらに基づいてもよい。一般に、中央処理装置は、リードオンリメモリまたはランダムアクセスメモリまたはそれら両方から命令およびデータを受信す
る。コンピュータの必須の要素は、命令を実施または実行するための中央処理装置と、命令およびデータを格納するための１つ以上のメモリデバイスである。一般に、コンピュータは、データを格納するための１つ以上の大容量記憶装置（たとえば、磁気ディスク、光磁気ディスクまたは光ディスク）も含み、１つ以上の大容量記憶装置からデータを受信したり１つ以上の大容量記憶装置にデータを送信したり１つ以上の大容量記憶装置との間でデータを送受信したりするように動作可能に結合される。しかし、コンピュータは、このような装置を有していなくてもよい。さらに、コンピュータは、別のデバイス、たとえばほんの数例を挙げると、携帯電話、パーソナルデジタルアシスタント（ＰＤＡ）、携帯オーディオもしくはビデオプレーヤ、ゲーム機、グローバルポジショニングシステム（ＧＰＳ）受信機、またはポータブルストレージデバイス（たとえば、ユニバーサルシリアルバス（ＵＳＢ）フラッシュドライブ）、に組み込まれてもよい。
A computer suitable for the execution of a computer program may include or be based, by way of example, on a general-purpose and/or special-purpose microprocessor, or on other types of central processing units. Generally, a central processing unit receives instructions and data from read-only memory and/or random access memory. The essential elements of a computer are a central processing unit for implementing or executing instructions and one or more memory devices for storing instructions and data. Generally, a computer also includes one or more mass storage devices (e.g., magnetic disks, magneto-optical disks, or optical disks) for storing data, and receives data from or receives data from one or more mass storage devices. The device is operably coupled to transmit data to and receive data from and to the one or more mass storage devices. However, a computer may not have such a device. In addition, the computer may be connected to another device, such as a mobile phone, personal digital assistant (PDA), portable audio or video player, game console, Global Positioning System (GPS) receiver, or portable storage device, to name just a few. For example, it may be incorporated into a Universal Serial Bus (USB) flash drive).
コンピュータプログラム命令およびデータの格納に適したコンピュータ読取可能媒体は、全ての形態の不揮発性メモリ、メディアおよびメモリデバイスを含み、メモリデバイスは、一例として、半導体メモリデバイス（たとえば、ＥＰＲＯＭ、ＥＥＰＲＯＭおよびフラッシュメモリデバイス）、磁気ディスク（たとえば、内蔵ハードディスクまたはリムーバブルディスク）、光磁気ディスク、ならびにＣＤ ＲＯＭおよびＤＶＤ－ＲＯＭディスクを含む。プロセッサおよびメモリは、特殊目的論理回路によって補完されてもよく、または特殊目的論理回路に組み入れられてもよい。 Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including, by way of example, semiconductor memory devices (e.g., EPROM, EEPROM and flash memory). devices), magnetic disks (eg, internal hard disks or removable disks), magneto-optical disks, and CD ROM and DVD-ROM disks. The processor and memory may be supplemented by or incorporated into special purpose logic circuits.
本明細書は、多くの具体的な実現例の詳細を含んでいるが、これらは、いずれの発明または請求の範囲を限定するものとして解釈されるべきではなく、特定の発明の特定の実施形態に特有の特徴を説明するものとして解釈されるべきである。別々の実施形態の文脈で本明細書に記載されている特定の特徴は、単一の実施形態において組み合わせて実現することも可能である。逆に、単一の実施形態の文脈で記載されているさまざまな特徴は、複数の実施形態において別々にまたは任意の好適な部分的な組み合わせで実現することも可能である。さらに、特徴は、特定の組み合わせで動作するものとして上記され、最初にそのように記載されているかもしれないが、記載されている組み合わせの中の１つ以上の特徴は、場合によってはこの組み合わせから除外されてもよく、記載されている組み合わせは、部分的な組み合わせまたは部分的な組み合わせの変形例を対象としてもよい。 Although this specification contains details of many specific implementations, these should not be construed as limiting the scope of any invention or the claims, but rather the specific embodiments of the particular invention. should be interpreted as describing characteristics specific to Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Further, although features may be described above as operating in a particular combination, and may be initially described as such, one or more features in the described combination may The combinations described may also cover subcombinations or variations of subcombinations.
同様に、動作は、特定の順序で図面に示されているが、これは、望ましい結果を達成するために、示されている特定の順序またはシーケンシャルな順序でこのような動作を実行しなければならないものとして理解されるべきではなく、示されている動作を全て実行しなければならないものとして理解されるべきでもない。特定の状況では、マルチタスクおよび並列処理が有利である場合もある。さらに、上記の実施形態におけるさまざまなシステムモジュールおよびコンポーネントの分離は、このような分離が全ての実施形態で必要であるものとして理解されるべきではなく、記載されているプログラムコンポーネントおよびシステムは、一般に、単一のソフトウェア製品に一体化されるかまたは複数のソフトウェア製品にパッケージングされてもよいということが理解されるべきである。 Similarly, although operations are shown in the drawings in a particular order, this does not mean that such operations must be performed in the particular order shown or in the sequential order to achieve the desired results. It should not be understood as requiring that all actions indicated be performed. Multitasking and parallel processing may be advantageous in certain situations. Furthermore, the separation of various system modules and components in the embodiments described above is not to be understood as requiring such separation in all embodiments, and that the program components and systems described are generally , may be integrated into a single software product or packaged into multiple software products.
主題の特定の実施形態について説明してきた。他の実施形態は、以下の特許請求の範囲の範囲内である。たとえば、特許請求の範囲に記載されている動作は、異なる順序で実行されても、依然として望ましい結果を達成することができる。一例として、添付の図面に示されているプロセスは、望ましい結果を達成するために、示されている特定の順序またはシーケンシャルな順序を必ずしも必要としない。特定の実現例では、マルチタスクおよび並列処理が有利である場合もある。 Certain embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the acts recited in the claims may be performed in a different order and still achieve desirable results. By way of example, the processes illustrated in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. Multitasking and parallel processing may be advantageous in certain implementations.
Claims (20)
前記Ｎ次元テンソルの各次元について、部分アドレスオフセット値格納部を備え、前記部分アドレスオフセット値格納部は、前記次元の部分アドレスオフセット値を格納するように構成され、各次元の前記部分アドレスオフセット値は、前記次元の初期値、前記次元のステップ値および前記次元における要素の個数に少なくとも基づき、各部分アドレスオフセット値格納部は、ハードウェア記憶回路を備え、前記Ｎ次元テンソルは、前記Ｎ個の次元の各々にわたって配置された複数の要素を有し、Ｎは、２以上の整数であり、前記装置はさらに、
１つまたは複数のハードウェア加算器を備え、前記１つまたは複数のハードウェア加算器は、
前記Ｎ次元テンソルのデータ要素のシーケンスのデータ値を格納するためのメモリ内の場所のメモリアドレスを求めるように構成され、前記メモリアドレスを求めることは、各特定のデータ要素について、
前記Ｎ次元テンソルの各次元について、前記次元の前記部分アドレスオフセット値格納部から前記次元の現在の部分アドレスオフセット値を受信することと、
前記現在の部分アドレスオフセット値の合計を前記特定のデータ要素のメモリアドレスとして求めることとを含み、前記特定のデータ要素の前記求められたメモリアドレスは、前記特定のデータ要素の前記求められたメモリアドレスに格納された前記特定のデータ要素の値とは異なっており、前記１つまたは複数のハードウェア加算器はさらに、
前記Ｎ次元テンソルの各特定のデータ要素の前記求められたメモリアドレスを示すデータを出力するように構成される、装置。 An apparatus for determining a memory address of a data element of an N-dimensional tensor, the apparatus comprising:
A partial address offset value storage unit is provided for each dimension of the N-dimensional tensor, and the partial address offset value storage unit is configured to store the partial address offset value of the dimension, and the partial address offset value of each dimension is configured to store the partial address offset value of the dimension. is based on at least the initial value of the dimension, the step value of the dimension, and the number of elements in the dimension, each partial address offset value storage includes a hardware storage circuit, and the N-dimensional tensor is having a plurality of elements arranged across each of the dimensions, N being an integer greater than or equal to 2, the device further comprising:
one or more hardware adders, the one or more hardware adders comprising:
configured to determine a memory address of a location in memory for storing data values of a sequence of data elements of said N-dimensional tensor, determining the memory address comprising: for each particular data element;
For each dimension of the N-dimensional tensor, receiving a current partial address offset value for the dimension from the partial address offset value storage for the dimension;
determining the sum of the current partial address offset values as a memory address of the particular data element, the determined memory address of the particular data element being the determined memory address of the particular data element. the value of the particular data element stored at the address, and the one or more hardware adders further:
Apparatus configured to output data indicative of the determined memory address of each particular data element of the N-dimensional tensor.
各次元について、前記次元の前記求められた部分アドレスオフセット値が前記次元の前記限界値に等しいか否かを判断するように構成され、
第１のループに対応する第１の次元の前記求められた部分アドレスオフセット値が前記第１の次元の前記限界値に等しいと判断したことに応答して、
前記第１の次元の前記部分アドレスオフセット値を前記第１の次元の前記初期値にリセットするように構成され、
前記第１のループがネストされる第２のループに対応する第２の次元について、前記１つまたは複数のハードウェア加算器を使用して、前記第２の次元の前記ステップ値と前記第２の次元の前記部分アドレスオフセット値との合計に等しくなるように前記第２の次元の前記部分アドレスオフセット値を更新するように構成される、請求項４に記載の装置。 For each dimension, the one or more hardware processors further include: a limit value storage unit that stores a limit value for the dimension;
configured to determine, for each dimension, whether the determined partial address offset value of the dimension is equal to the limit value of the dimension;
in response to determining that the determined partial address offset value of a first dimension corresponding to a first loop is equal to the limit value of the first dimension;
configured to reset the partial address offset value of the first dimension to the initial value of the first dimension;
For a second dimension corresponding to a second loop in which the first loop is nested, the step value of the second dimension and the second 5. The apparatus of claim 4, configured to update the partial address offset value of the second dimension to be equal to the sum of the partial address offset values of the dimension.
前記次元の前記初期値を格納する初期値格納部と、
前記次元の前記ステップ値を格納するステップ値格納部とをさらに備え、
各部分アドレスオフセット値格納部、各初期値格納部および各ステップ値格納部は、ハードウェアレジスタを含む、請求項１～６のいずれかに記載の装置。 For each dimension,
an initial value storage unit that stores the initial value of the dimension;
further comprising a step value storage unit that stores the step value of the dimension,
7. The apparatus according to claim 1, wherein each partial address offset value storage , each initial value storage and each step value storage includes a hardware register.
Ｎ次元テンソルに対して線形代数演算を実行するように構成された１つまたは複数の処理ユニットを備え、前記Ｎ次元テンソルは、前記Ｎ個の次元の各々にわたって配置された複数の要素を有し、Ｎは、２以上の整数であり、前記システムはさらに、
前記Ｎ個の次元の各次元について、部分アドレスオフセット値格納部を備え、前記部分アドレスオフセット値格納部は、前記次元の部分アドレスオフセット値を格納するように構成され、各次元の前記部分アドレスオフセット値は、前記次元の初期値、前記次元のステップ値および前記次元における要素の個数に少なくとも基づき、各部分アドレスオフセット値格納部は、ハードウェア記憶回路を備え、前記システムはさらに、
１つまたは複数のハードウェア加算器を備え、前記１つまたは複数のハードウェア加算器は、
前記Ｎ次元テンソルのデータ要素のシーケンスのデータ値を格納するためのメモリ内の場所のメモリアドレスを求めるように構成され、前記メモリアドレスを求めることは、各特定のデータ要素について、
前記Ｎ次元テンソルの各次元について、前記次元の前記部分アドレスオフセット値格納部から前記次元の現在の部分アドレスオフセット値を受信することと、
前記現在の部分アドレスオフセット値の合計を前記特定のデータ要素のメモリアドレスとして求めることとを含み、前記特定のデータ要素の前記求められたメモリアドレスは、前記特定のデータ要素の前記求められたメモリアドレスに格納された前記特定のデータ要素の値とは異なっており、前記１つまたは複数のハードウェア加算器はさらに、
前記Ｎ次元テンソルの各特定のデータ要素の前記求められたメモリアドレスを示すデータを出力するように構成される、システム。 A system,
one or more processing units configured to perform linear algebra operations on an N-dimensional tensor, the N-dimensional tensor having a plurality of elements arranged across each of the N dimensions; , N is an integer greater than or equal to 2, and the system further includes:
A partial address offset value storage unit is provided for each of the N dimensions, and the partial address offset value storage unit is configured to store a partial address offset value of the dimension, and the partial address offset value of each dimension is configured to store a partial address offset value of the dimension. the value is based on at least an initial value of the dimension, a step value of the dimension, and a number of elements in the dimension, each partial address offset value store comprises a hardware storage circuit, and the system further comprises:
one or more hardware adders, the one or more hardware adders comprising:
configured to determine a memory address of a location in memory for storing data values of a sequence of data elements of said N-dimensional tensor, determining the memory address comprising: for each particular data element;
For each dimension of the N-dimensional tensor, receiving a current partial address offset value for the dimension from the partial address offset value storage for the dimension;
determining the sum of the current partial address offset values as a memory address of the particular data element, the determined memory address of the particular data element being the determined memory address of the particular data element. the value of the particular data element stored at the address, and the one or more hardware adders further:
A system configured to output data indicative of the determined memory address of each particular data element of the N-dimensional tensor.
各次元について、前記次元の前記求められた部分アドレスオフセット値が前記次元の前記限界値に等しいか否かを判断するように構成され、
第１のループに対応する第１の次元の前記求められた部分アドレスオフセット値が前記第１の次元の前記限界値に等しいと判断したことに応答して、
前記第１の次元の前記部分アドレスオフセット値を前記第１の次元の前記初期値にリセットするように構成され、
前記第１のループがネストされる第２のループに対応する第２の次元について、前記１つまたは複数のハードウェア加算器を使用して、前記第２の次元の前記ステップ値と前記第２の次元の前記部分アドレスオフセット値との合計に等しくなるように前記第２の次元の前記部分アドレスオフセット値を更新するように構成される、請求項１１に記載のシステム。 For each dimension, the one or more hardware processors further include: a limit value storage unit that stores a limit value for the dimension;
configured to determine, for each dimension, whether the determined partial address offset value of the dimension is equal to the limit value of the dimension;
in response to determining that the determined partial address offset value of a first dimension corresponding to a first loop is equal to the limit value of the first dimension;
configured to reset the partial address offset value of the first dimension to the initial value of the first dimension;
For a second dimension corresponding to a second loop in which the first loop is nested, the step value of the second dimension and the second 12. The system of claim 11, configured to update the partial address offset value in the second dimension to be equal to the sum of the partial address offset values in the dimension.
前記次元の前記初期値を格納する初期値格納部と、
前記次元の前記ステップ値を格納するステップ値格納部とをさらに備え、
各部分アドレスオフセット値格納部、各初期値格納部および各ステップ値格納部は、ハードウェアレジスタを備える、請求項８～１３のいずれかに記載のシステム。 For each dimension,
an initial value storage unit that stores the initial value of the dimension;
further comprising a step value storage unit that stores the step value of the dimension,
The system according to any of claims 8 to 13, wherein each partial address offset value store , each initial value store and each step value store comprises a hardware register.
１つまたは複数のハードウェア加算器を含むハードウェア回路が、前記Ｎ次元テンソルのデータ要素のシーケンスのデータ値を格納するためのメモリ内の場所のメモリアドレスを求めるステップを備え、前記メモリアドレスを求めるステップは、各特定のデータ要素について、
前記１つまたは複数のハードウェア加算器が、前記Ｎ次元テンソルの各次元について、前記次元の部分アドレスオフセット値格納部から前記次元の現在の部分アドレスオフセット値を受信するステップを含み、
各次元の前記部分アドレスオフセット値は、前記次元の初期値、前記次元のステップ値および前記次元における要素の個数に少なくとも基づき、
各部分アドレスオフセット値格納部は、ハードウェア記憶回路を含み、
前記Ｎ次元テンソルは、前記Ｎ個の次元の各々にわたって配置された複数の要素を有し、
Ｎは、２以上の整数であり、前記メモリアドレスを求めるステップはさらに、各特定のデータ要素について、
前記現在の部分アドレスオフセット値の合計を前記特定のデータ要素のメモリアドレスとして求めるステップを含み、前記特定のデータ要素の前記求められたメモリアドレスは、前記特定のデータ要素の前記求められたメモリアドレスに格納された前記特定のデータ要素の値とは異なっており、前記方法はさらに、
前記ハードウェア回路が、前記Ｎ次元テンソルの各特定のデータ要素の前記求められたメモリアドレスを示すデータを出力するステップを備える、方法。 A computer-implemented method for determining memory addresses of data elements of an N-dimensional tensor, the method comprising:
a hardware circuit including one or more hardware adders, determining a memory address of a location in memory for storing data values of the sequence of data elements of the N-dimensional tensor; For each particular data element, the steps to find are:
the one or more hardware adders receiving, for each dimension of the N-dimensional tensor, a current partial address offset value for the dimension from a partial address offset value store for the dimension;
The partial address offset value of each dimension is based at least on an initial value of the dimension, a step value of the dimension, and a number of elements in the dimension;
Each partial address offset value storage includes a hardware storage circuit,
The N-dimensional tensor has a plurality of elements arranged across each of the N dimensions,
N is an integer greater than or equal to 2, and the step of determining the memory address further includes, for each particular data element,
determining the sum of the current partial address offset values as the memory address of the particular data element, the determined memory address of the particular data element being the determined memory address of the particular data element; the value of said particular data element stored in said method further comprises:
The method comprises the step of the hardware circuit outputting data indicative of the determined memory address of each particular data element of the N-dimensional tensor.
第１のループに対応する第１の次元の前記求められた部分アドレスオフセット値が前記第１の次元の前記限界値に等しいと判断したことに応答して、
前記第１の次元の前記部分アドレスオフセット値を前記第１の次元の前記初期値にリセットするステップと、
前記第１のループがネストされる第２のループに対応する第２の次元について、前記１つまたは複数のハードウェア加算器を使用して、前記第２の次元の前記ステップ値と前記第２の次元の前記部分アドレスオフセット値との合計に等しくなるように前記第２の次元の前記部分アドレスオフセット値を更新するステップとをさらに備える、請求項１７に記載の方法。 determining, for each dimension, whether the determined partial address offset value of the dimension is equal to a limit value of the dimension;
in response to determining that the determined partial address offset value of a first dimension corresponding to a first loop is equal to the limit value of the first dimension;
resetting the partial address offset value of the first dimension to the initial value of the first dimension;
For a second dimension corresponding to a second loop in which the first loop is nested, the step value of the second dimension and the second 18. The method of claim 17, further comprising: updating the partial address offset value of the second dimension to be equal to the sum of the partial address offset values of the dimension.
前記次元の前記ステップ値は、前記次元のステップ値格納部に格納され、
各部分アドレスオフセット値格納部、各初期値格納部および各ステップ値格納部は、ハードウェアレジスタを含む、請求項１５～１９のいずれかに記載の方法。 The initial value of each dimension is stored in the initial value storage section of the dimension,
the step value of the dimension is stored in a step value storage of the dimension;
20. A method according to any of claims 15 to 19, wherein each partial address offset value store , each initial value store and each step value store includes a hardware register.
Applications Claiming Priority (6)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/603,061 | 2017-05-23 | ||
US15/603,061 US9946539B1 (en) | 2017-05-23 | 2017-05-23 | Accessing data in multi-dimensional tensors using adders |
US15/903,991 US10534607B2 (en) | 2017-05-23 | 2018-02-23 | Accessing data in multi-dimensional tensors using adders |
US15/903,991 | 2018-02-23 | ||
JP2019553901A JP7051895B2 (en) | 2017-05-23 | 2018-02-26 | Accessing data in a multidimensional tensor using an adder |
PCT/US2018/019691 WO2018217258A1 (en) | 2017-05-23 | 2018-02-26 | Accessing data in multi-dimensional tensors using adders |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019553901A Division JP7051895B2 (en) | 2017-05-23 | 2018-02-26 | Accessing data in a multidimensional tensor using an adder |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2022095773A JP2022095773A (en) | 2022-06-28 |
JP7433356B2 true JP7433356B2 (en) | 2024-02-19 |
Family
ID=61617155
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019553901A Active JP7051895B2 (en) | 2017-05-23 | 2018-02-26 | Accessing data in a multidimensional tensor using an adder |
JP2022056584A Active JP7433356B2 (en) | 2017-05-23 | 2022-03-30 | Accessing data in multidimensional tensors using adders |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019553901A Active JP7051895B2 (en) | 2017-05-23 | 2018-02-26 | Accessing data in a multidimensional tensor using an adder |
Country Status (6)
Country | Link |
---|---|
US (1) | US10534607B2 (en) |
EP (1) | EP3631625A1 (en) |
JP (2) | JP7051895B2 (en) |
KR (2) | KR102243036B1 (en) |
CN (1) | CN110462586A (en) |
WO (1) | WO2018217258A1 (en) |
Families Citing this family (23)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10108538B1 (en) | 2017-07-31 | 2018-10-23 | Google Llc | Accessing prologue and epilogue data |
GB2567038B (en) * | 2017-07-31 | 2019-09-25 | Google Llc | Accessing prologue and epilogue data |
US10936942B2 (en) * | 2017-11-21 | 2021-03-02 | Google Llc | Apparatus and mechanism for processing neural network tasks using a single chip package with multiple identical dies |
US10599583B2 (en) * | 2018-08-20 | 2020-03-24 | Macronix International Co., Ltd. | Pre-match system and pre-match method |
US11263011B2 (en) * | 2018-11-28 | 2022-03-01 | International Business Machines Corporation | Compound instruction set architecture for a neural inference chip |
KR102611169B1 (en) * | 2019-04-04 | 2023-12-06 | 캠브리콘 테크놀로지스 코퍼레이션 리미티드 | Data processing apparatus and related product |
US11620358B2 (en) | 2019-05-14 | 2023-04-04 | Intel Corporation | Technologies for performing macro operations in memory |
JP7062617B2 (en) * | 2019-06-26 | 2022-05-06 | 株式会社東芝 | Arithmetic logic unit and arithmetic method |
US11354564B2 (en) * | 2019-06-27 | 2022-06-07 | Intel Corporation | Tuning of loop orders in blocked dense basic linear algebra subroutines |
KR102658003B1 (en) * | 2019-11-27 | 2024-04-17 | 한양대학교 에리카산학협력단 | Quantum adder and method of adding with improved efficiency |
CN113391842A (en) * | 2020-03-13 | 2021-09-14 | 华为技术有限公司 | Single instruction multiple data SIMD instruction generation and processing method and related equipment |
EP3896565B1 (en) * | 2020-04-16 | 2024-03-06 | NXP USA, Inc. | Memory address generator |
US11954580B2 (en) | 2020-09-16 | 2024-04-09 | Meta Platforms, Inc. | Spatial tiling of compute arrays with shared control |
US11704562B1 (en) | 2020-11-04 | 2023-07-18 | Meta Platforms, Inc. | Architecture for virtual instructions |
US11709783B1 (en) | 2020-11-11 | 2023-07-25 | Meta Platforms, Inc. | Tensor data distribution using grid direct-memory access (DMA) controller |
US11972349B1 (en) | 2020-11-12 | 2024-04-30 | Meta Platforms, Inc. | Flexible compute array utilization in a tensor processor |
US11922306B2 (en) | 2020-12-28 | 2024-03-05 | Meta Platforms, Inc. | Tensor controller architecture |
US11790611B2 (en) | 2020-12-30 | 2023-10-17 | Meta Platforms, Inc. | Visual editor for designing augmented-reality effects that utilize voice recognition |
CN113836049B (en) * | 2021-09-17 | 2023-08-08 | 海飞科(南京)信息技术有限公司 | Memory access method and electronic device |
KR20230099190A (en) | 2021-12-27 | 2023-07-04 | 서울대학교산학협력단 | Apparatus and method for address generation of multi-dimensional tensor |
CN114489798B (en) * | 2022-01-25 | 2024-04-05 | 海飞科(南京)信息技术有限公司 | Method and electronic device for determining out-of-range state of tensor element |
CN117435547A (en) * | 2022-07-15 | 2024-01-23 | 北京有竹居网络技术有限公司 | Artificial intelligent chip, method, equipment and medium for flexibly accessing data |
CN115658146B (en) * | 2022-12-14 | 2023-03-31 | 成都登临科技有限公司 | AI chip, tensor processing method and electronic equipment |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2001090888A1 (en) | 2000-05-23 | 2001-11-29 | Theis Jean Paul | A data processing system having an address generation unit with hardwired multidimensional memory indexing support |
US20040034754A1 (en) | 2002-08-19 | 2004-02-19 | Schreiber Robert S. | Method and system for memory management optimization |
US20040093479A1 (en) | 2002-10-28 | 2004-05-13 | Quicksilver Technology, Inc. | Cache for instruction set architecture using indexes to achieve compression |
US20100145992A1 (en) | 2008-12-09 | 2010-06-10 | Novafora, Inc. | Address Generation Unit Using Nested Loops To Scan Multi-Dimensional Data Structures |
US20170075691A1 (en) | 2011-12-23 | 2017-03-16 | Intel Corporation | Instruction for element offset calculation in a multi-dimensional array |
Family Cites Families (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2854420B2 (en) * | 1990-02-21 | 1999-02-03 | 松下電器産業株式会社 | Multidimensional address generator and its control method |
WO1991018351A1 (en) | 1990-05-22 | 1991-11-28 | International Business Machines Corporation | Pyramid learning architecture neurocomputer |
CA2086229A1 (en) * | 1990-06-27 | 1991-12-28 | Warren Marwood | Number theory mapping generator for addressing matrix structures |
JPH06324935A (en) * | 1993-05-11 | 1994-11-25 | Matsushita Electric Ind Co Ltd | Address generator and address generation system |
US5958048A (en) * | 1996-08-07 | 1999-09-28 | Elbrus International Ltd. | Architectural support for software pipelining of nested loops |
US6219784B1 (en) | 1997-11-17 | 2001-04-17 | Advanced Micro Devices, Inc. | Processor with N adders for parallel target addresses calculation |
US6694311B1 (en) | 1999-01-25 | 2004-02-17 | International Business Machines Corporation | Method and apparatus for fast query approximation using adaptive query vector projection |
US6507835B1 (en) | 2000-02-17 | 2003-01-14 | International Business Machines Corporation | Generating grouping queries using tensor representations |
US7225439B2 (en) * | 2003-03-21 | 2007-05-29 | Sun Microsystems, Inc. | Combining write-barriers within an inner loop with fixed step |
JP2005209060A (en) * | 2004-01-26 | 2005-08-04 | Hitachi Ltd | System including address generation apparatus and address generation apparatus |
US8443169B2 (en) | 2005-03-28 | 2013-05-14 | Gerald George Pechanek | Interconnection network connecting operation-configurable nodes according to one or more levels of adjacency in multiple dimensions of communication in a multi-processor and a neural processor |
US20080250227A1 (en) | 2007-04-04 | 2008-10-09 | Linderman Michael D | General Purpose Multiprocessor Programming Apparatus And Method |
US20100153100A1 (en) * | 2008-12-11 | 2010-06-17 | Electronics And Telecommunications Research Institute | Address generator for searching algebraic codebook |
US9141916B1 (en) | 2012-06-29 | 2015-09-22 | Google Inc. | Using embedding functions with a deep network |
US9946539B1 (en) * | 2017-05-23 | 2018-04-17 | Google Llc | Accessing data in multi-dimensional tensors using adders |
-
2018
- 2018-02-23 US US15/903,991 patent/US10534607B2/en active Active
- 2018-02-26 CN CN201880021083.9A patent/CN110462586A/en active Pending
- 2018-02-26 EP EP18710248.8A patent/EP3631625A1/en active Pending
- 2018-02-26 KR KR1020197026962A patent/KR102243036B1/en active IP Right Grant
- 2018-02-26 KR KR1020217011131A patent/KR102347119B1/en active IP Right Grant
- 2018-02-26 WO PCT/US2018/019691 patent/WO2018217258A1/en active Application Filing
- 2018-02-26 JP JP2019553901A patent/JP7051895B2/en active Active
-
2022
- 2022-03-30 JP JP2022056584A patent/JP7433356B2/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2001090888A1 (en) | 2000-05-23 | 2001-11-29 | Theis Jean Paul | A data processing system having an address generation unit with hardwired multidimensional memory indexing support |
US20040034754A1 (en) | 2002-08-19 | 2004-02-19 | Schreiber Robert S. | Method and system for memory management optimization |
US20040093479A1 (en) | 2002-10-28 | 2004-05-13 | Quicksilver Technology, Inc. | Cache for instruction set architecture using indexes to achieve compression |
US20100145992A1 (en) | 2008-12-09 | 2010-06-10 | Novafora, Inc. | Address Generation Unit Using Nested Loops To Scan Multi-Dimensional Data Structures |
US20170075691A1 (en) | 2011-12-23 | 2017-03-16 | Intel Corporation | Instruction for element offset calculation in a multi-dimensional array |
Also Published As
Publication number | Publication date |
---|---|
CN110462586A (en) | 2019-11-15 |
KR20190113973A (en) | 2019-10-08 |
US20180341479A1 (en) | 2018-11-29 |
KR102347119B1 (en) | 2022-01-05 |
JP7051895B2 (en) | 2022-04-11 |
JP2022095773A (en) | 2022-06-28 |
KR20210045509A (en) | 2021-04-26 |
JP2020521198A (en) | 2020-07-16 |
EP3631625A1 (en) | 2020-04-08 |
KR102243036B1 (en) | 2021-04-21 |
US10534607B2 (en) | 2020-01-14 |
WO2018217258A1 (en) | 2018-11-29 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7433356B2 (en) | Accessing data in multidimensional tensors using adders | |
CN109324827B (en) | Apparatus, method and system for processing instructions for accessing data | |
JP7279226B2 (en) | Alternate loop limit | |
US9946539B1 (en) | Accessing data in multi-dimensional tensors using adders | |
KR102596365B1 (en) | Accessing data in multi-dimensional tensors | |
GB2567038B (en) | Accessing prologue and epilogue data |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20220427 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20220427 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20230613 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20230912 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20240109 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20240206 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7433356Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |