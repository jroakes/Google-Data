US6728752B1 - System and method for information browsing using multi-modal features - Google Patents
System and method for information browsing using multi-modal features Download PDFInfo
- Publication number
- US6728752B1 US6728752B1 US09/421,770 US42177099A US6728752B1 US 6728752 B1 US6728752 B1 US 6728752B1 US 42177099 A US42177099 A US 42177099A US 6728752 B1 US6728752 B1 US 6728752B1
- Authority
- US
- United States
- Prior art keywords
- feature
- modal
- document
- documents
- features
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
- 238000000034 method Methods 0.000 title claims abstract description 108
- 239000013598 vector Substances 0.000 claims abstract description 134
- 238000011524 similarity measure Methods 0.000 claims description 9
- 238000004891 communication Methods 0.000 claims description 6
- 238000004458 analytical method Methods 0.000 abstract description 14
- 230000008569 process Effects 0.000 description 25
- 230000000875 corresponding effect Effects 0.000 description 22
- 238000004422 calculation algorithm Methods 0.000 description 17
- 230000000007 visual effect Effects 0.000 description 17
- 230000006870 function Effects 0.000 description 16
- 238000013507 mapping Methods 0.000 description 16
- 238000013459 approach Methods 0.000 description 15
- 238000012800 visualization Methods 0.000 description 12
- 239000003086 colorant Substances 0.000 description 9
- 230000008901 benefit Effects 0.000 description 7
- 238000003064 k means clustering Methods 0.000 description 7
- 239000011159 matrix material Substances 0.000 description 7
- 238000012512 characterization method Methods 0.000 description 5
- 238000004040 coloring Methods 0.000 description 5
- 238000012986 modification Methods 0.000 description 5
- 230000004048 modification Effects 0.000 description 5
- 230000009471 action Effects 0.000 description 4
- 230000008520 organization Effects 0.000 description 4
- 238000011160 research Methods 0.000 description 4
- 230000004044 response Effects 0.000 description 4
- 238000007418 data mining Methods 0.000 description 3
- 238000003066 decision tree Methods 0.000 description 3
- 238000013461 design Methods 0.000 description 3
- 230000001965 increasing effect Effects 0.000 description 3
- 230000003993 interaction Effects 0.000 description 3
- 230000002452 interceptive effect Effects 0.000 description 3
- 230000001404 mediated effect Effects 0.000 description 3
- 238000012549 training Methods 0.000 description 3
- 241000282412 Homo Species 0.000 description 2
- 238000007792 addition Methods 0.000 description 2
- 230000006399 behavior Effects 0.000 description 2
- 230000009286 beneficial effect Effects 0.000 description 2
- 230000000881 depressing effect Effects 0.000 description 2
- 238000010586 diagram Methods 0.000 description 2
- 230000000694 effects Effects 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 238000011985 exploratory data analysis Methods 0.000 description 2
- 239000000463 material Substances 0.000 description 2
- 230000008450 motivation Effects 0.000 description 2
- 238000007781 pre-processing Methods 0.000 description 2
- 238000007670 refining Methods 0.000 description 2
- 238000000638 solvent extraction Methods 0.000 description 2
- 238000001228 spectrum Methods 0.000 description 2
- 238000012360 testing method Methods 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- 241000254158 Lampyridae Species 0.000 description 1
- 241001124569 Lycaenidae Species 0.000 description 1
- 230000004913 activation Effects 0.000 description 1
- 230000002776 aggregation Effects 0.000 description 1
- 238000004220 aggregation Methods 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 235000014510 cooky Nutrition 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 238000013079 data visualisation Methods 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 238000009795 derivation Methods 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 230000018109 developmental process Effects 0.000 description 1
- 238000009826 distribution Methods 0.000 description 1
- 238000004880 explosion Methods 0.000 description 1
- 238000013213 extrapolation Methods 0.000 description 1
- 238000003709 image segmentation Methods 0.000 description 1
- 230000001939 inductive effect Effects 0.000 description 1
- 238000012804 iterative process Methods 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000012544 monitoring process Methods 0.000 description 1
- 238000010606 normalization Methods 0.000 description 1
- 238000005192 partition Methods 0.000 description 1
- 238000009304 pastoral farming Methods 0.000 description 1
- 238000003825 pressing Methods 0.000 description 1
- 238000004445 quantitative analysis Methods 0.000 description 1
- 238000012216 screening Methods 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000007480 spreading Effects 0.000 description 1
- 238000003892 spreading Methods 0.000 description 1
- 239000004575 stone Substances 0.000 description 1
- 238000007794 visualization technique Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/34—Browsing; Visualisation therefor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/35—Clustering; Classification
- G06F16/353—Clustering; Classification into predefined classes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5838—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using colour
Definitions
- the invention relates to information browsing and retrieval, and more particularly to a system and method for using different document features to facilitate the identification of documents sharing one or more machine-identifiable characteristics.
- the World Wide Web is a loosely interlinked collection of documents (mostly text and images) located on servers distributed over the Internet.
- each document has an address, or Uniform Resource Locator (URL), in the exemplary form “http://www.server.net/directory/file.html”.
- URL Uniform Resource Locator
- the “www.server.net” specifies the name of a computer, or server, on which the document resides; “directory” refers to a directory or folder on the server in which the document resides; and “file.html” specifies the name of the file.
- HTML HyperText Markup Language
- external content such as images and other multimedia data types
- hotlinks or “links” to other documents to be placed within the document, among other things.
- Hotlinking allows a user to navigate between documents on the Web simply by selecting an item of interest within a page. For example, a Web page about reprographic technology might have a hotlink to the Xerox corporate web site.
- the hotlink By selecting the hotlink (often by clicking a marked word, image, or area with a pointing device, such as a mouse), the user's Web browser is instructed to follow the hotlink (usually via a URL, frequently invisible to the user, associated with the hotlink) and read a different document.
- search engine serves as an index into the content stored on the Internet.
- search engines There are two primary categories of search engines: those that include documents and Web sites that are analyzed and used to populate a hierarchy of subject-matter categories (e.g., Yahoo), and those that “crawl” the Web or document collections to build a searchable database of terms, allowing keyword searches on page content (such as AltaVista, Excite, and Infoseek, among many others).
- subject-matter categories e.g., Yahoo
- keyword searches on page content such as AltaVista, Excite, and Infoseek, among many others.
- recommendation systems which are capable of providing Web site recommendations based on criteria provided by a user or by comparison to a single preferred document (e.g., Firefly, Excite's “more like this” feature).
- Google is an example of a search engine that incorporates several recommendation-system-like features. It operates in a similar manner to traditional keyword-based search engines, in that a search begins by the user's entry of one or more search terms used in a pattern-matching analysis of documents on the Web. It differs from traditional keyword-based search engines (such as AltaVista), in that search results are ranked based on a metric of page “importance,” which differs from the number of occurrences of the desired search terms (and simple variations upon that theme).
- traditional keyword-based search engines such as AltaVista
- Google's metric of importance is based upon two primary factors: the number of pages (elsewhere on the Web) that link to a page (i.e., “inlinks,” defining the retrieved page as an “authority”), and the number of pages that the retrieved page links to (i.e., “outlinks,” defining the retrieved page as a “hub”).
- a page's inlinks and outlinks are weighted, based on the Google-determined importance of the linked pages, resulting in an importance score for each retrieved page.
- the search results are presented in order of decreasing score, with the most important pages presented first.
- Google's page importance metric is based on the pattern of links on the Web as a whole, and is not limited (and at this time cannot be limited) to the preferences of a single user or group of users.
- CLEVER CLient-side EigenVector Enhanced Retrieval
- Google operates like a traditional search engine, and uses inlinks/authorities and outlinks/hubs as metrics of page importance. Again, importance (based on links/throughout the Web) is used to rank search results.
- page content e.g., the words surrounding inlinks and outlinks
- CLEVER does not use its own database of Web content; rather, it uses an external hub, such as an index built by another search engine, to define initial communities of documents on the Web. From hubs on the Web that frequently represent people's interests, CLEVER is able to identify communities, and from those communities, identify related or important pages.
- Direct Hit is a service that cooperates with traditional search engines (such as HotBot), attempting to determine which pages returned in a batch of results are interesting or important, as perceived by users who have previously performed similar searches.
- Direct Hit tracks which pages in a list of search results are accessed most frequently; it is also able to track the amount of time users spend at the linked sites before returning to the search results. The most popular sites are promoted (i.e., given higher scores) for future searches.
- Alexa is a system that is capable of tracking a user's actions while browsing. By doing so, Alexa maintains a database of users' browsing histories. Page importance is derived from other users' browsing histories. Accordingly, at any point (not just in the context of a search), Alexa can provide a user with information on related pages, derived from overall traffic patterns, link structures, page content, and editorial suggestions.
- Knowledge Pump a Xerox system, provides community-based recommendations by initially allowing users to identify their interests and “experts” in the areas of those interests. Knowledge Pump is then able to “push” relevant information to the users based on those preferences; this is accomplished by monitoring network traffic to create profiles of users, including their interests and “communities of practice,” thereby refining the community specifications.
- Knowledge Pump does not presently perform any enhanced search and retrieval actions like the search-engine-based systems described above.
- HTML HyperText Markup Language
- each image in a collection ideally should be labeled with descriptive information including the objects in the image and a general description of the image.
- identification of the objects in an unrestricted collection of images, such as those on the web is a difficult task.
- Methods for automatically identifying objects are usually restricted to a particular domain, such as machine parts. And having humans identify each image is an onerous undertaking, and in some cases impossible, as on the web.
- Metadata may take on various forms, such as language, dates, location of the site, or whether other modalities such as images, video or audio are present.
- Multi-modal clustering hence is the grouping of objects that have data from several modalities associated with them.
- the text surrounding or associated with an image often provides an indication of its context.
- the method proposed herein permits the use of multi-modal information, such as text and image features, for performing browsing and retrieval (of images, in the exemplary case described herein). This method is applicable more generally to other applications in which the elements (e.g., documents, phrases, or images) of a collection can be described by multiple characteristics, or features.
- search engines In contrast to those image-based retrieval systems, there are text-based search engines that provide the ability to group results or identify more documents that are similar to a specific document. Entire topics or specific words in a topic can be required or excluded. A new search is then performed with the new query, or a narrowing search is performed on the previously returned set of results.
- the Excite search engine has a “more like this” functionality that performs a search using one particular document as the example for a new search; it refines the query by basing it on the selected document and performing a new search. This approach is unlike the method set forth herein, as it does not allow for searching based on multiple features in multiple modalities.
- Decision trees such as CART or ID3, perform iterative splitting of data.
- a tree is created by selecting a feature for splitting at each node.
- a different feature may be selected each time, or a combination of features may be used to define an aggregate similarity measure.
- the selection of features in creating a decision tree is usually performed automatically from a set of data, based on some criteria such as minimizing classification error or maximizing mutual information.
- This disclosure sets forth a framework for multi-modal browsing and clustering, and describes a system advantageously employing that framework to enhance browsing, searching, retrieving and recommending content in a collection of documents.
- Clustering of large data sets is important for exploratory data analysis, visualization, statistical generalization, and recommendation systems. Most clustering algorithms rely on a similarity measure between objects.
- This proposal sets forth a data representation model and an associated similarity measure for multi-modal data. This approach is relevant to data sets where each object has several disparate types of information associated with it, which are called modalities. Examples of such data sets include the pages of a World Wide Web site (modalities here could be text, inlinks, outlinks, image characteristics, text genre, etc.).
- a primary feature of the present invention resides in its novel data representation model.
- Each modality within each document is described herein by an n-dimensional vector, thereby facilitating quantitative analysis of the relationships among the documents in the collection.
- a method for serially using document features in different spaces (i.e., different modalities) to browse and retrieve information.
- One embodiment of the method uses image and text features for browsing and retrieval of images, although the method applies generally to any set of distinct features.
- the method takes advantage of multiple ways in which a user can specify items of interest. For example, in images, features from the text and image modalities can be used to describe the images.
- the method is similar to the method set forth in U.S. Pat. No. 5,442,778 and in D. Cutting, D. R. Karger, J. O. Pedersen, and J. W. Tukey, “Scatter/Gather: A cluster-based approach to browsing large document collections,” Proc. 15 th Ann.
- Scatter/Gather in that selection of clusters, followed by reclustering of the selected clusters is performed iteratively. It extends the Scatter/Gather paradigm in at least two respects: each clustering may be performed on a different feature (e.g., surrounding text, image URL, image color histogram, genre of the surrounding text); and a “map” function identifies the most similar clusters with respect to a specified feature. The latter function permits identification of additional similar images that may have been ruled out due to missing feature values for these images.
- the image clusters are represented by selecting a small number of representative images from each cluster.
- Various alternative embodiments of the invention also enable clustering users and documents according to one or more features, recommending documents based on user clusters' prior browsing behaviors, and visually representing clusters of either documents or users, graphically and textually.
- a system for representing users and documents in vector space and for performing browsing and retrieval on a collection of web images and associated text on an HTML page is described. Browsing is combined with retrieval to help a user locate interesting portions of the corpus or collection of information, without the need to formulate a query well matched to the corpus. Multi-modal information, in the form of text surrounding an image and some simple image features, is used in this process. Using the system, a user progressively narrows a collection to a small number of elements of interest, similar to the Scatter/Gather system developed for text browsing, except the Scatter/Gather method is extended hereby to use multi-modal features.
- some collection elements may have unknown or undefined values for some features; a method is presented for incorporating these elements into the result set. This method also provides a way to handle the case when a search is narrowed to a part of the space near a boundary between two clusters. A number of examples are provided.
- the documents in the present collection are characterized by many different features, or (probably non-orthogonal) “dimensions,” many of which are derived from the contents of the unstructured documents.
- Multi-modal features may take on many forms, such as user information, text genre, or analysis of images.
- the features used in the present invention can be considered a form of metadata, derived from the data (text and images, for example) and its context, and assigned automatically or semi-automatically, rather than current image search systems, in which metadata is typically assigned manually.
- Table 1 lists several possible features (all of which will be described in greater detail below); it will be recognized that various other features and modalities are also usable in the invention, and that the features of Table 1 are exemplary only.
- this specification presents methods of information access to a collection of web images and associated text on an HTML page.
- the method permits the use of multi-modal information, such as text and image features, for performing browsing and retrieval of images and their associated documents or document regions.
- text features derived from the text surrounding or associated with an image which often provide an indication of its content, are used together with image features.
- image features are used together with image features.
- the novelty of this approach lies in the way it makes text and image features transparent to users, enabling them to successively narrow down their search to the images of interest. This is particularly useful when a user has difficulty in formulating a query well matched to the corpus, especially when working with an unfamiliar or heterogeneous corpus, such as the web, where the vocabulary used in the corpus or the image descriptors are unknown.
- the methods presented herein are premised on an advantageous data representation model in which document (and user) features are embedded into multi-dimensional vector spaces.
- This data representation model facilitates the use of a consistent and symmetric similarity measure, which will be described in detail below.
- it is possible to represent users and clusters of users based on the contents and features of the documents accessed by those users (i.e., collection use data), thereby improving the ability to cluster users according to their similarities.
- a recommendation system based on multi-modal user clusters is possible with the collection of multi-modal collection use data as described below.
- a set of clusters is induced from a training set of users.
- a user desiring a recommendation is assigned to the nearest cluster, and that cluster's preferred documents are recommended to the user.
- this disclosure sets forth improved methods of visually representing clusters of documents and clusters of users. While documents are frequently stored hierarchically, enabling a hierarchical visual representation, the same is not usually true for users. Accordingly, the present invention allows for a view of user data by way of the a hierarchical view of the documents accessed or likely to be accessed by the appropriate users. Documents and clusters of documents can be visualized similarly, and also textually by way of clusters' “salient dimensions.”
- clustering in image retrieval is not new, it has usually been used for preprocessing, either to aid a human during the database population stage, or to cluster the images offline so that distance searches during queries are performed within clusters.
- iterative clustering and selection of cluster subsets can help a user identify images of interest.
- Clustering is used for interactive searching and presentation, and relevance feedback is implicit in the user's choice of clusters. Because the user is dealing with clusters, not individual images, the feedback step is also easier to perform.
- the various forms of multi-modal clustering set forth herein can be used for information access: for browsing a collection in order to find a document; for understanding a collection that is new to the user; and for dealing with cases of “nothing found” (in which clustering can help the user reformulate his or her query by formulating it in the vocabulary that is appropriate for the collection).
- a method for information browsing is performed by isolating multi-modal features from documents in a collection, searching the collection, and clustering and mapping as needed to refine the search and identify useful documents.
- FIG. 1 is a block diagram illustrating a network-connected document collection suitable for use with a system according to the invention
- FIG. 2 is a flow chart illustrating the process used by an embodiment of the invention to handle new documents added to a collection
- FIG. 3 is a flow chart illustrating the process used by an embodiment of the invention to calculate feature vectors representative of various documents and users;
- FIG. 4 is a flow chart illustrating the process used to calculate text-based feature vectors in an embodiment of the invention
- FIG. 5 is a flow chart illustrating the process used to calculate a text genre feature vector in an embodiment of the invention
- FIG. 6 is a flow chart illustrating the process used to calculate a color histogram feature vector in an embodiment of the invention
- FIG. 7 is a flow chart illustrating the process used to calculate a corresponding pair of color complexity feature vectors in an embodiment of the invention.
- FIG. 8 is a flow chart illustrating the process used to calculate a page usage vector in an embodiment of the invention.
- FIG. 9 is a flow chart illustrating the process used in wavefront clustering to identify initial cluster centers in an embodiment of the invention.
- FIG. 10 is a flow chart illustrating the process used in k-means clustering to assign related objects to clusters
- FIG. 11 is a diagram illustrating a hypothetical session of scattering and gathering collection objects in different modalities
- FIG. 12 is an exemplary visual display of text clusters returned in response to the query “ ancient cathedral”;
- FIG. 13 is an exemplary visual display of text clusters returned after scattering the first text cluster of FIG. 12;
- FIG. 14 is an exemplary visual display of image clusters returned after clustering based on the complexity feature
- FIG. 15 is an exemplary visual display of text clusters returned in response to the query “paper money”;
- FIG. 16 is an exemplary visual display of image clusters returned after clustering the first text cluster of FIG. 15 based on the complexity feature
- FIG. 17 is an exemplary visual display of image clusters returned after clustering the third and fifth image clusters of FIG. 16 based on the color histogram feature;
- FIG. 18 is an exemplary visual display of image clusters returned after clustering the second image cluster of FIG. 17 based on the color histogram feature;
- FIG. 19 is an exemplary visual display of text clusters returned in response to the query “pyramid egypt”;
- FIG. 20 is an exemplary visual display of image clusters returned after clustering based on the complexity feature
- FIG. 21 is an exemplary visual display of image clusters returned after clustering based on the color histogram feature
- FIG. 22 is an exemplary visual display of text clusters returned after expanding the set of images of FIG. 21 and clustering the result based on the color histogram feature;
- FIG. 23 is an exemplary indirect visualization of clusters according to the invention.
- one user cluster is illustrated by coloring in red (and indicated herein by arrows) all pages that have a high probability of being chosen by a member of the cluster;
- FIG. 24 is an exemplary visual display illustrating the interface used to browse and show the contents of clusters and documents in an embodiment of the invention.
- FIG. 25 is a flow chart illustrating the process used to recommend popular pages to a user in an exemplary recommendation system according to the invention.
- FIG. 26 is a flow chart illustrating the process used to recalculate recommendations in an exemplary recommendation system according to the invention.
- each document for example, an HTML document 110
- a collection 120 maps to a set of feature vectors 112 , one for each modality (for example, a text vector 114 and a URL vector 116 ).
- the feature vectors 112 are calculated by a processor 122 having access to both the document collection 120 and a communication network 124 (such as the Internet or a corporate intranet).
- the collection 120 is hosted by one or more servers also coupled to the network 124 .
- the feature vectors 112 for each document are stored in a database 126 , where they are correlated with the documents they correspond to.
- a plurality of user terminals 128 , 130 , and 132 coupled to the network 124 are used to access the system.
- the collection 120 comprises all known documents that will ever by processed by a system according to the invention.
- a new document is located (step 210 ).
- the document is processed (step 212 ) to calculate the feature vectors 112 , and the document can then be added to the corpus (step 214 ) or collection available to the invention. If there are no more documents (step 216 ), then the process is finished (step 218 ). Otherwise, another document is located (step 210 ) and the process is repeated.
- a presently preferred and operational version of the system is capable of employing eight possible document features: text content, document link, inlinks, outlinks, text genre, image color histogram, and image complexity.
- the first two of the listed features are text based, inlinks and outlinks are hyperlink based, text genre is probability based, and the final two features (image color histogram and image complexity) are image-based.
- these feature vectors are derived as described in FIG. 3 .
- a new document which can be a text document, image, or other type of information
- the disclosed method uses various information sources to derive the feature vectors. Text is extracted from the document (step 312 ) and used to create a corresponding text vector (step 314 ) and a corresponding URL vector (step 316 ).
- outlinks hypertext links within the document that point elsewhere
- Inlinks documents within the collection that point to the subject document
- Text genre is identified (step 326 ) and used to create a corresponding genre vector (step 328 ).
- the colors are extracted from the image (step 330 ) and used to create a corresponding color histogram vector (step 332 ).
- Horizontal and vertical runs of a single color (or set of similar colors) are also extracted from the image (step 334 ) and used to create a color complexity vector (step 336 ).
- references to the document are extracted from usage logs (step 338 ) and used to update users' page access vectors (step 340 ).
- All of the content vectors are then stored in the database 126 (step 342 ).
- adding documents having certain features to an existing collection may require revising the entire set of feature vectors for all documents in the collection. For example, adding a document that contains a unique word will impact the text vectors for all documents in the collection, as that word will require adding an extra term to each document's text vector. Accordingly, it may be computationally more efficient to update the collection in substantially large groups of documents, rather than incrementally each time a new document becomes available. Such considerations, as well as methods for computationally optimizing the set of vectors, is an implementation detail not considered to be important to the invention.
- each feature is used separately, and the most suitable distance metric can be applied to each feature.
- the features are combined into a single content vector representative of the document, and a single distance metric is used to cluster and compare the documents.
- the text feature is calculated as illustrated in FIG. 4 .
- the text feature is a term vector, where the elements of the vector represent terms used in the document itself.
- the text vector is based on the document's entire text content.
- the text used to formulate the text vector is derived from text surrounding an image in a “host” HTML page.
- the scope of the surrounding text is limited to 800 characters preceding or following the image location. If a horizontal rule, heading or another image occurs prior to the limit being reached, the scope ends at the rule, heading or image.
- a “stop list” is used to prevent indexing of common terms with little content, such as articles, prepositions, and conjunctions.
- text documents, image documents, and multimedia documents are all special cases of the generic term “documents,” and for each of those special cases, some or all of the modalities described herein may be applicable.
- images do not necessarily contain text, but are described by text in the hypertext links and URLs that point to them.
- Images containing text can have their text extracted via known document image decoding techniques.
- audio files may also be referenced by text in hyperlinks and URLs, and may also contain text extractable via known speech recognition algorithms.
- each text document d (or any kind of document containing extractable text) is embedded by the present invention into R n r (a vector space having n t dimensions, wherein each dimension is represented by a real number), where n t is the total number of unique words in the collection (n t stands for “number of text elements”).
- R n r a vector space having n t dimensions, wherein each dimension is represented by a real number
- n t is the total number of unique words in the collection (n t stands for “number of text elements”).
- N ci is the number of occurrences of element i in context c
- N i is the number of contexts in which i occurs
- N is the total number of contexts.
- elements correspond to words
- contexts corresponds to documents; this definition is consistent with the standard definitions for term frequency weight and inverse document frequency weight in the information-retrieval field.
- the text vector is calculated by first calculating the token frequency weight as above (step 410 ), then calculating the inverse context frequency weight as above (step 412 ), then multiplying the two to calculate the text content vector (step 414 ).
- token frequency weight and inverse context frequency weight for the embedding employed by the invention is consistent with the following intuitive description.
- a context e.g., a document
- Logarithms conventionally used as a dampening function and have been found to be satisfactory for this application.
- the inverse context frequency weight ranges from 0 for an element that occurs in every context (an example might be the word “the” in text documents) and reaches its maximum for an element that occurs in only one context (log N).
- log N/N i can be interpreted as a measure of how much information is gained when learning about the occurrence of element i in a context.
- the word “the” occurs in a document, no significant information is gained (assuming it occurs in every document).
- the phrase “Harry Truman” occurs in a document, much information is present (assuming that the phrase occurs in only a few documents).
- token frequency weight multiplied by the inverse context frequency weight has been found to be an advantageous way to scale the vectors.
- other weighting schemes are also possible and may provide other advantages.
- sim t ⁇ ( d 1 , d 2 ) ⁇ i ⁇ ⁇ t ⁇ ( d 1 ) i ⁇ ⁇ t ⁇ ( d 2 ) i ( ⁇ i ⁇ ⁇ t ⁇ ( d 1 ) i 2 ) ⁇ ( ⁇ i ⁇ ⁇ t ⁇ ( d 2 ) i 2 )
- d 1 and d 2 represent two different documents
- ⁇ t (d 1 ) i represents the i-th term of the vector representing document d 1 .
- the cosine distances between pairs of documents can be used to cluster documents based on text features alone, or can be used in combination with other features.
- the text feature described above can be calculated in a different way, or as a separate and independent feature.
- the text from titles, headings, and captions is isolated from a document to define a “subject” modality in R n s (where n s is the total number of unique words in the titles, headers, and captions of documents in the collection).
- vectors can be calculated for a document's URL.
- the exemplary URL “http://www.server.net/directory/file.html” includes seven terms: “http,” “www,” “server,” “net,” “directory,” “file,” and “html.” As with the text feature, some of those terms contain little or no informational value (“http,” “www,” “net,” and “html” in this example). Accordingly, the token frequency weight and inverse context frequency weight embedding is appropriate here, as well. Again see FIG. 4 .
- each document d is embedded into R n u (a vector space having n u dimensions, wherein each dimension is represented by a real number), where n u is the total number of unique URL terms identifying all documents in the collection (n u stands for “number of URL elements”).
- the embedding into the vector space is defined as follows:
- N ci is the number of occurrences of element i in context c
- N i is the number of contexts in which i occurs
- N is the total number of contexts.
- elements correspond to URL terms
- contexts corresponds to documents.
- Inlink vectors exist in R n i , where n f is the total number of distinct inlinks embodied in the collection (i.e., the total number of documents in the collection referring to other documents in the collection).
- Outlink vectors exist in R n o , where n o is the total number of distinct outlinks embodied in the collection (i.e., the total number of documents, in the collection or out, referred to by a document in the collection).
- a document's text genre is embedded into R n g , where n g is the number of known text genres.
- a document genre is a culturally defined document category that guides a document's interpretation. Genres are signaled by the greater document environment (such as the physical media, pictures, titles, etc. that serve to distinguish at a glance, for example, the National Enquirer from the New York Times) rather than the document text. The same information presented in two different genres may lead to two different interpretations. For example, a document starting with the line “At dawn the street was peaceful . . . ” would be interpreted differently by a reader of Time Magazine than by a reader of a novel.
- Each document type has an easily recognized and culturally defined genre structure which guides our understanding and interpretation of the information it contains. For example, news reports, newspaper editorials, calendars, press releases, and short stories are all examples of possible genres.
- a document's structure and genre can frequently be determined (at least in part) by an automated analysis of the document or text (step 510 ).
- color histogram To embed images into vector space, two modalities have been successfully used: color histogram and complexity.
- image documents are embedded into R n h , where n h is the number of “bins” in the histogram (twelve, in a presently preferred embodiment of the invention).
- n h is the number of “bins” in the histogram (twelve, in a presently preferred embodiment of the invention).
- a single color histogram is used as the color feature.
- the feature space is converted to HSV (the Hue, Saturation, and Value color model), and two bits are assigned to each dimension (step 610 ). Accordingly, there are three dimensions to the color space, and two bits (four values) for each color dimension, resulting in twelve total dimensions in the preferred vector space.
- HSV the Hue, Saturation, and Value color model
- Each pixel in the image being processed is then categorized (step 612 ): its hue, saturation, and value will fall into one of the four bins for each dimension, so the corresponding vector element is incremented (step 614 ).
- the color histogram for each document is normalized (step 616 ) so that all of the bin values sum to one—the result is then stored as the histogram vector (step 618 ). It should be noted that it is not appropriate to use the token frequency weight and inverse context frequency weight embedding as is preferably done for text (and certain other) modalities, as it is not meaningful in this context.
- sim h ⁇ ( d 1 , d 2 ) ⁇ i ⁇ ⁇ h ⁇ ( d 1 ) i ⁇ ⁇ h ⁇ ( d 2 ) i ( ⁇ i ⁇ ⁇ h ⁇ ( d 1 ) i 2 ) ⁇ ( ⁇ i ⁇ ⁇ h ⁇ ( d 2 ) i 2 )
- multiple color histograms are determined for multiple regions of each image, resulting in multiple color histogram feature vectors.
- color histograms in the four quadrants (top left, top right, bottom left, and bottom right) and center of an image can be computed separately, resulting in five separate color histogram vectors, which can then be weighted and combined as desired by a user or left as separate vectors.
- partially or completely overlapping regions can also be used, such as the top half, bottom half, left half, right half, and center rectangle.
- an image can be subdivided into tiles, with histograms being computed separately for each tile, and then combined as appropriate into regions.
- a symmetric distance is needed in this framework because distances between an image and another image or a centroid are needed for clustering purposes, rather than simple retrieval purposes.
- the complexity feature attempts to capture a coarse semantic distinction that humans might make between images: that between simple logos and cartoons at the one extreme, which are composed of a relatively small number of colors with regions of high color homogeneity, and photographs on the other, which are composed of a relatively large number of colors with fine shading.
- This feature is derived from horizontal and vertical run lengths of each color within an image.
- runs of the same color (which in a preferred embodiment is coarsely quantized into two-bit HSV values, step 710 , as above) are identified in the x (step 712 ) and y (step 714 ) directions.
- a histogram is computed for each direction (step 716 ), wherein each bin represents the number of pixels (or in an alternative embodiment, a quantized percentage of the total height or width) a run spans in the x or y direction, respectively.
- the count in each bin is the number of pixels in the image belonging to that particular run-length.
- the value added to a bin for each run can be weighted by the length of the run, giving greater weight to longer runs.
- the total number of elements in a histogram is the number of pixels in the image's horizontal and vertical dimensions, respectively.
- run-length complexity information is quantized into a smaller number of bins (and hence a smaller number of dimensions for each vector). This is performed to reduce the sparseness of the vectors, enabling more efficient and more robust comparisons between images.
- N bins and a maximum horizontal dimension of n x
- any horizontal run r x longer than n x /4 is placed into the N th (or last) bin.
- Shorter runs r x are placed into the bin indexed by floor(r x (N ⁇ 1)/(n x /4))+1 (where the “floor” function rounds its argument down to the nearest integer).
- run lengths are linearly quantized into N bins, with all runs of length greater than n x /4 going into the last bin. Similar operations are performed on vertical runs, resulting in a horizontal complexity vector having N dimensions and a vertical complexity vector also having N dimensions.
- sim c ⁇ ( d 1 , d 2 ) 0.5 ⁇ ⁇ i ⁇ ⁇ x ⁇ ( d 1 ) i ⁇ ⁇ x ⁇ ( d 2 ) i ( ⁇ i ⁇ ⁇ x ⁇ ( d 1 ) i 2 ) ⁇ ( ⁇ i ⁇ ⁇ x ⁇ ( d 2 ) i 2 ) + 0.5 ⁇ ⁇ i ⁇ ⁇ y ⁇ ( d 1 ) i ⁇ ⁇ y ⁇ ( d 2 ) i ( ⁇ i ⁇ ⁇ y ⁇ ( d 1 ) i 2 ) ⁇ ( ⁇ i ⁇ ⁇ y ⁇ ( d 2 ) i 2 ) ⁇ ( ⁇ i ⁇ ⁇ y ⁇ ( d 2 ) i 2 )
- ⁇ x and ⁇ y represent the horizontal complexity vector and the vertical complexity vector, respectively.
- subsampling can be performed to reduce the computational expense incurred in calculating the vector embeddings. For example, it has been found that it is possible to select a fraction (such as ⁇ fraction (1/10) ⁇ ) or a limited number (such as 1000) of the total number of pixels in the image an still achieve useful results. Those subsampled pixels are preferably uniformly spaced throughout the image, but in an alternative embodiment can be randomly selected. For the histogram feature, it is sufficient to calculate the proper histogram bin for only the subsampled pixels. For the complexity feature, it is also necessary to determine the lengths of runs, both horizontal and vertical that subsampled pixels belong to.
- this is accomplished by subsampling rows and columns.
- a maximum of fifty approximately evenly-distributed rows of pixels are selected (less than fifty if the image is shorter than fifty pixels in height), and runs in only those rows are counted.
- a similar process is followed for columns in the vertical complexity vector. The vector embeddings otherwise remain the same.
- page usage has been found to be indicative of users' information-seeking preferences.
- page accesses are first identified (step 810 ).
- the token frequency weight (step 812 ) and inverse context frequency weight (step 814 ) are again preferably used, the context being each user and a token being a user's page accesses.
- each user's page accesses may be regarded as binary: either the user has accessed a page, in which case the corresponding user's vector has a “1” in the appropriate element; or the user has not accessed a page, in which case the appropriate element is a “0.”
- modalities can also be derived from users.
- user-specified demographic information such as names, ages, hobbies, telephone numbers, home addresses, selected group memberships, and the like
- other kinds of tracked information including but not limited to on-line purchasing habits, software usage, and time spent viewing documents
- a user's group memberships can be embedded into a vector space having a number of dimensions equal to the number of known groups, with the terms of a user's group membership vector having boolean (“0” or “1”) values representative of whether the user is a member of the corresponding group.
- each text vector has a number of dimensions equal to the number of unique words in the collection; for the image complexity modality, each vector has a number of dimensions equal to the maximum horizontal or vertical pixel dimension of images in the collection; and for the page usage modality, each vector has a number of dimensions equal to the number of documents in the collection. Accordingly, as documents are added to the collection (and as users are added to the user population), it may become necessary to recalculate many of the feature vectors, to ensure that all of the vectors for the same feature have the same dimensions, thereby enabling use of the similarity metrics described above.
- sim ⁇ ( d 1 , d 2 ) ⁇ j ⁇ w j ⁇ sim j ⁇ ( d 1 , d 2 )
- the aggregate similarity metric may be suboptimal in certain circumstances, and it may be desirable to have the capability to “fall back” upon the individual similarity metrics when needed.
- the similarity metrics set forth above define the basis for clustering documents and users (collectively “objects”).
- objects A standard clustering algorithm is used.
- k-means clustering is used to assign objects to k different clusters.
- k-means clustering is a partitioning method that usually begins with k randomly selected objects as cluster centers. Objects are assigned to the closest cluster center (the center they have the highest similarity with). Then cluster centers are recomputed as the mean of their members. The process of (re)assignment of objects and re-computation of means is repeated several times until it converges.
- hierarchical multi-modal clustering can also be used, but k-means clustering has been found to provide satisfactory results.
- the classical form of k-means clustering selects initial clusters by way of random selection from the objects that are to be clustered.
- An alternative method for selecting the initial clusters uses the Buckshot algorithm, which computes initial centers by applying a hierarchical (but computationally expensive) clustering algorithm to a subset of the objects. The initial centers for k-means clustering are then the centers of the clusters found by clustering the subset.
- m (a number much smaller than the total number N of objects to be clustered) objects are randomly selected (step 910 ). This number is independent of the number k (which will be the number of clusters eventually calculated). By way of experimentation, it has been found that a suitable value for m is ten.
- centroid ⁇ right arrow over (c) ⁇ of the m objects (step 912 ).
- the centroid is calculated by methods well known in the art, namely by averaging the corresponding terms of the subject vectors.
- a total of k objects ⁇ right arrow over (x) ⁇ i are selected randomly from the N objects to be clustered (step 914 ). As stated above, k is the desired number of final clusters. Finally for each of the k initial objects ⁇ right arrow over (x) ⁇ i , calculate k cluster centers ⁇ right arrow over (x) ⁇ ′ i around the centroid ⁇ right arrow over (c) ⁇ on the way to each of the k initial objects. These cluster centers are calculated as follows (step 916 ):
- This technique has been given the name “wavefront clustering” because, in simplified terms, a “wave” is sent from the centroid ⁇ right arrow over (c) ⁇ , and the objects that are hit by the wave on its way to the second set of randomly picked objects are selected as initial cluster centers. These initial centers are appropriate for the case of a large number of objects being bunched up in one point because the centroid ⁇ right arrow over (c) ⁇ tends to be close to that point. The initial centers are well suited to efficiently partition the concentrated region.
- Standard k-means clustering then proceeds, as shown in FIG. 10, by assigning each object to its nearest cluster.
- an unassigned object is chosen (step 1012 ). Its similarity is calculated with respect to each cluster center (step 1014 ), using one of the similarity metrics set forth above.
- the object is then assigned to the nearest cluster center (step 1016 ). If there are more objects to assign, the process repeats (step 1018 ).
- the cluster centers are then recomputed (step 1020 ) as the centroid (or mean) of each cluster corresponding to each cluster center.
- step 1022 If the cluster centers have converged sufficiently (step 1022 ), for example by determining whether a sufficiently small number of objects have switched clusters, then the clustering process is finished (step 1024 ). Otherwise, all objects are de-assigned from all clusters (step 1026 ), and the process begins again with the newly determined cluster centers.
- multi-modal browsing and retrieval two applications of multi-modal features are considered herein: (1) helping a user to identify documents of interest in a system called multi-modal browsing and retrieval; and (2) the multi-modal analysis of users' interactions with a collection (collection use analysis, or CUA).
- CUA selection use analysis
- clusters of documents created as described above are used in a system for searching, recommending, and browsing documents.
- one feature is considered at a time, as specified by a user; in a second embodiment, multiple features are considered simultaneously.
- user clusters created as described above are applied to two separate functions.
- First, user clusters are made suitable for visualization through mediation, which will be described in further detail below.
- Second, multi-modal user clusters are used to generate recommendations.
- Multi-modal searching and browsing using one type of feature at a time, is best illustrated in connection with FIGS. 11-22.
- Each feature is used to either refine the set of images or to map to a related set of images of interest.
- image features are used independently of text features to create multiple clusterings which the human user can navigate between, using text (e.g., section headings, abstract title, “ALT” tags in image anchors) when it is perceived to be more appropriate, and image features when they are more so.
- One potential problem with progressively narrowing a search based on different features is that images with missing feature values may be inadvertently eliminated from consideration. For example, some documents contain images with no associated text, or text unrelated to the contents of the image. In particular, some images exist on pages that have no text. In other cases, the text surrounding the image has no relevance to the semantic content of the image.
- Another problem with progressively narrowing a search is that the search may be narrowed to a part of the space near a boundary between two clusters.
- features herein permits quick initial focusing of the set of elements of interest, and then organization and expansion to include similar elements, some of which may have incomplete features sets or may occur in another cluster.
- An ideal image browsing system would allow a user to browse documents, including images, that may or may not have descriptive annotative text and use both text or image features. Users may wish to browse through image collections based either on their semantic content (“what does the image show?”) or their visual content (“what does the image look like?”). Image retrieval systems are often based on manual keyword annotation or on matching of image features, since automatically annotating images with semantic information is currently an impossible task. Even so, a manually labeled image collection cannot include all the possible semantic significances that an image might have.
- Scatter/Gather was originally designed for use with text features derived from documents. Scatter/Gather iteratively refines a search by “scattering” a collection into a small number of clusters, and then a user “gathers” clusters of interest for scattering again.
- the Scatter/Gather method is extended by the invention to extend to a multi-modal multi-feature method, using both text and image features to navigate a collection of documents with text and images; there is also an “expand” (i.e., mapping) function so that elements from outside the working set can be incorporated into the working set.
- an “expand” i.e., mapping
- the correct answer to a query depends on the user. Accordingly, in the aspect of the invention related to browsing, the user selects the feature used at each step. The user only sees the current working set. If the map function is not used, and only one cluster is selected after each operation, this is equivalent to the user expanding only one node of the tree in a depth-first search. By selecting clusters to combine, a lattice is formed. And by using the map function, elements from outside the working set may become part of the working set, so neither a tree nor a lattice is created. Accordingly, the present method is quite different from a decision tree.
- an initial text query can be used to find candidate images of interest. Some of the returned clusters containing images of interest are then identified by the user for further consideration. By expanding based on similarity of one image feature, the system then finds and presents image clusters that are similar to those represented by the initially selected clusters, but without associated text or with text not similar enough to the user-specified query.
- the expand function permits relevant images that are absent in the original set as a result of the text query to be identified and included.
- the expand function can also identify for consideration elements that are near the feature space of interest, but that are—due to the partitioning at an earlier step—in another cluster.
- a preprocessing step is used to precompute information needed during browsing and to provide the initial organization of the data
- a set of distinct features is precomputed for each document and stored as vectors.
- features of images in web pages are computed in the manner described below.
- the text features include the words of text surrounding and associated with each image, the URL of the image, ALT tags, hyperlink text, and text genre (described below).
- the image features include a color histogram and a measure of color complexity. See Table 1, above.
- the documents are clustered into groups based on each of the features.
- a user begins by entering a text query.
- a hypothetical session is illustrated in FIG. 11, in which a circular node represents the data in a cluster; the solid arrows represent the scattering or gathering of data in a node; and the dashed lines represent movement of a subset of data in a node to another node, as in the expand (or map) function.
- the precomputed text clusters are ranked in terms of relevance (i.e., similarity) to the query terms using the cosine distance, and the highest ranking clusters are returned. These may be displayed as representative text or images in a first set of results 1110 .
- the user selects the clusters that are most similar to their interest. This may include all or a subset of clusters 1112 .
- One of two operations is then typically performed: the images in the selected clusters are re-clustered based on a selected feature to result in another set of results 1114 , or the selected clusters are mapped (or expanded) to new similar clusters 1116 based on a selected feature.
- the user is free to start a new search, or to operate on an existing results set by performing a new query (like the initial text query).
- the results of the later query can then be used to either refine or add to the existing results set, at the user's option.
- the new clusters are displayed as representative text or images, depending on whether the selected feature is derived from text or image data.
- the selected feature may be any of the precomputed features.
- the user can refine the set of images.
- mapping or expanding i.e., identifying other similar documents in the same or similar clusters regardless of prior refinement
- images similar in the specified feature, possibly with missing values in other features can be brought into the set of images for consideration.
- the clustering is performed using a standard k-means clustering algorithm with a preset number of clusters.
- the number of clusters is larger than the number of clusters presented to the user. This is because only a subset of clusters will be presented in response to the initial text string query.
- twenty clusters are initially used, but only the five most similar clusters are returned based on the query.
- the clusters selected by the user for gathering are then re-clustered, where the number of clusters is equal to the number of clusters to be displayed, again five in the disclosed embodiment.
- Each further gather and clustering operation results in five clusters. As each operation is performed, cluster results are stored. This permits “backing up” the chain of operations, and is also needed by the mapping or expanding operation.
- the initial clustering could alternatively be based on another feature, such as the color histogram feature.
- the appropriate number of initial clusters may be smaller, depending on the feature.
- the initial clustering is based on text, but at any time, the scatter and further clustering can be based on either a text feature or an image feature. It should also be noted that in alternative embodiments of the invention, initial clustering based on non-text features is possible and may be useful in certain circumstances.
- the expand/map function addresses a problem with progressively narrowing a search based on different features, in that images with missing values will be eliminated from consideration. For example, some documents contain images with no associated text, or text unrelated to the contents of the image. In other cases, the text surrounding the image has no relevance to the semantic content of the image.
- Another problem with progressively narrowing a search is that the search may be narrowed to a part of the space near a boundary between two clusters.
- the mapping or expanding operation adds images or clusters to the current set based on similarity in one feature dimension. Because only one feature is considered at a time, it should be noted that the distance metric used to establish similarity can be different for each feature. For example, as discussed above, the cosine distance can be used for text feature similarity, while Euclidean distance or the normalized histogram intersection is used for histogram similarity.
- the expand operation can be performed in several ways.
- One method ensures that the elements of the current clusters remain in the mapped set and the set size is increased. This is accomplished by adding to the current working set some elements that are close (via the appropriate distance metric) to the working set based on the selected feature.
- the mean of the selected feature for the current working set is computed, and then those elements (represented as vectors) selected from the entire database that are closest to this mean are added. This is most appropriate for text features.
- elements that are close to each displayed representative in the working set are selected and added. This alternative mapping procedure is more applicable to image features, in which the clusters are represented by selected images instead of a compilation of the elements used to represent text. However, if the text is represented by selected documents, the latter method of mapping would also be appropriate.
- Mapping can be sped up by considering only those elements that are present further up the chain of working sets saved for backup, as discussed above. That is, look up the backup chain of operations until the feature chosen for mapping was used for clustering.
- clustering was performed based on the color histogram feature, followed by further clustering based on the URL feature. If a map operation based on color complexity is requested, elements from the selected clusters based on the color histogram (another image feature) can be used, rather than all clusters.
- a final extension involves creating a special cluster for each feature containing all of the elements with no data for the feature. When mapping is to be performed, only those elements in the special clusters associated with a feature already used are considered as candidates to be added to the current working set.
- Another (simpler) method for mapping involves identifying the most similar clusters based on the color histogram feature. In this way, images with no relevant text are identified if they are similar to images with relevant associated text. For example, some URLs are not informative (e.g., “http:/www.company.com/products/special/image.jpg”, which contains only the common terms “www,” “company,” “com,” “products,” “special” “image,” and “jpg”). By first identifying images with the URL feature and then mapping to images similar in another feature, a larger number of images can be identified without restarting the search or requiring the use of feature weights.
- URLs are not informative (e.g., “http:/www.company.com/products/special/image.jpg”, which contains only the common terms “www,” “company,” “com,” “products,” “special” “image,” and “jpg”).
- a text cluster can be represented in a number of ways, the most common being the selection and display of a set of words that are in some way most representative of the cluster.
- image clusters need to be represented, it is less meaningful to choose image features that are common to the cluster members and display them, since these will not, in general, have semantic meaning to the user.
- Previous clustering image browsers have represented image clusters by mapping the images into a lower (two) dimensional space and displaying the map.
- a preferred embodiment of the invention calls for a further clustering of the cluster, followed by representing the cluster by (a) the three images closest to the centroid of the cluster, and (b) three images representative of subregions of the cluster.
- the three subregion representatives are computed by removing the three most central images from (a) above, computing three subclusters, and using the image closest to the centroid of each subcluster (as measured via the appropriate distance metric).
- This representation provides a sense of the cluster centroid and the range of images in the cluster.
- the representative images could also have been placed on a 2-D display using multi-dimensional scaling, but for the examples in this disclosure, the representatives are displayed in a row of three “centroid” images or three “subcluster” images (see, e.g., FIG. 14 ). This permits very similar images, such as thumbnails and multiple copies of originals, to be more readily identified.
- Web documents contain many of the same types of “meta-information” that can be found in scanned images of documents and can be used to infer the content of a document or the components in a document.
- An image was also required to pass some color-content-based tests: that no more than 90% of the image be composed of as few as 8 colors, no more than 95% of the image be composed of as few as 16 colors, and that the RGB colorspace covariance matrix of the image's pixels be non-singular.
- these criteria ensure that the images are not simple line drawings, and contain enough variety of color content to be well-differentiable by the color features described in detail above. No screening was performed for multiple versions of the same image, so the corpus does contain identical images, as well as an image and a thumbnail of the image.
- the first example illustrates the use of the text feature to first narrow the collection and then use of an image feature to organize the results.
- the user starts by typing in the text query “ ancient cathedrar” 1210 and by pressing a “submit” button 1212 .
- a user's interaction with a system as disclosed herein can take place in any known manner—for example, by interacting with actual physical buttons, by manipulating on-screen representations of buttons with a pointing device such as a mouse, by voice commands, to name but a few possibilities.
- the user interacts with a multi-modal image browser presented as a window 1214 by a software program implementing the invention.
- a snapshot of the screen displaying five returned text clusters 1216 , 1218 , 1220 , 1222 , and 1224 is shown in the left half of FIG. 12 .
- These clusters are the clusters closest to the query terms.
- the most frequent content terms in each cluster are displayed to represent each cluster.
- the user can scroll each text window to view additional representative terms for a text cluster.
- the user decides to scatter the first text cluster containing the terms “ancient” and “cathedral” again based on text. To do so, the user selects a checkbox 1226 next to the desired cluster and subsequently depresses a “text cluster” button 1228 . As described above, this causes the system to refine the existing selected cluster into smaller separate clusters.
- a snapshot of the screen displaying the five resulting text clusters 1310 , 1312 , 1314 , 1316 , and 1318 is shown on the left half of FIG. 13 .
- the user selects the three clusters that contain the terms “ancient,” “cathedral” and “church” to gather (by way of corresponding checkboxes 1320 , 1322 , and 1324 ) and selects complexity as the feature for scattering (by depressing a “complexity cluster” button 1326 ).
- FIG. 14 A snapshot of the screen after clustering based on the image complexity is shown in FIG. 14 .
- the representative images closest to the centroid are displayed.
- the user can move between the centroid and subcluster representative views.
- Image clusters 1414 , 1416 and 1420 contain images primarily of “ ancient” buildings and monuments, including old churches and cathedrals.
- Image cluster 1418 contains a logo and image cluster 1422 appears to contain miscellaneous items.
- the second example our hypothetical user is trying to find a number of images of paper money in our corpus.
- an initial query of “paper money” is given and the resulting text clusters 1510 , 1512 , 1514 , 1516 , and 1518 are displayed.
- the first text cluster 1510 contains the word “money” as well as the word “note”. This cluster looks promising so the user selects it.
- the second text cluster 1512 contains the word “paper,” but the surrounding words do not indicate that the desired sense of the word paper is being used, so this cluster is not selected. Since money is printed in many colors, the color complexity measure is appropriate to use initially as an image feature. Accordingly, the first text cluster 1510 is scattered based on the color complexity feature and the resulting clusters are shown in FIG.
- Image clusters 1614 and 1618 contain images of paper money, so they are gathered (by selecting both clusters) and then scattered based on the color histogram feature this time.
- the other image clusters 1610 , 1612 , and 1616 do not appear to contain images of interest, so the user would not select those.
- Image cluster 1712 contains 14 images, and the central representatives are all images of paper money. This cluster is scattered again based on the histogram feature; it can be observed that it contains many images of paper money, as shown in FIG. 18 . Some of the images appear to be duplicates, but in this case they are actually a thumbnail and the full-size image. Examination of the sub-cluster representatives reveals some images in the subclusters that do not contain money, but which have similar colors to the money images.
- This example illustrates the use of different features in serial combination to selectively narrow the set of images to a set of interest. Scattering is used to help organize a larger collection into smaller subsets. Gathering permits different collections to be combined and reorganized together.
- the user is searching for pyramids and types in the query “pyramid egypt.”
- the returned text clusters 1910 , 1912 , 1914 , 1916 , and 1918 are displayed.
- the user selects the first text cluster 1910 to be scattered based on the complexity feature, and representative images from the resulting image clusters are shown in FIG. 20 .
- the user notes that there are outdoor scenes with stone in the second and fourth image clusters 2012 and 2016 and selects those for further clustering based on the color histogram feature.
- the resulting image clusters are shown in FIG. 21 .
- the first image cluster 2110 contains four images, and the first image is of pyramids.
- the first image cluster 2110 When the first image cluster 2110 is expanded to include similar images based on the color histogram feature (by selecting the first image cluster 2110 and depressing the “histogram expand” button 2120 ), another image of a pyramid 2210 is identified, as shown in FIG. 22 . This image occurs on a web page without any text and with a non-informative URL, and so it was retrieved on the basis of the color histogram feature.
- the text query was used to reduce the size of the image collection, and the reduced collection was organized for presentation based on the image complexity feature. Additional images were obtained that were similar in the color histogram feature dimension.
- features in different modalities are used serially to help a user browse a set of images with associated text, using techniques of “scattering” and “gathering” subsets of elements in the corpus.
- a session begins with a text query to start with a more focussed initial set than the entire corpus. Clusters which are observed to contain one or more interesting elements can then be scattered to examine their content, or expanded to retrieve similar results from the entire collection.
- FIGS. 12-22 employed only three feature types, text, image histogram, and image complexity, the methods disclosed are equally applicable to all eight modalities discussed herein, as well as others.
- an aspect of the present invention includes a system for browsing a collection utilizing multiple modalities. Through an iterative process of “gathering” clusters and “scattering” the elements to examine the clusters, a user can find groups of images of interest.
- An “expand” or “map” function permits identification of elements in a collection that may be missing a value in one or more dimensions but are similar to other elements in some dimension of interest.
- the aggregate similarity sim(d 1 ,d 2 ) between two documents or objects can be used in the gathering, scattering, and expanding operations described in the foregoing section. Minor modifications to the user interface illustrated in FIGS. 12-22 will accommodate this additional feature.
- “Aggregate Cluster” and “Aggregate Expand” buttons can be added to facilitate operating on all possible modalities simultaneously, or alternatively, a listing of the possible modalities (text, color complexity, color histogram, etc.) can be provided with checkboxes (and optionally user-adjustable weights) to allow a user to indicate whether one modality or multiple modalities at once should be used when a “Cluster Selected Modalities” or “Expand Selected Modalities” button is activated. The aggregate similarity sim(d 1 ,d 2 ) over the selected modalities is then used in the scattering and mapping functions.
- the only direct information available for clustering users of a web site is which pages they accessed, and how often.
- mediated multi-modal representations are calculated by way of matrix multiplication.
- P the matrix of page accesses, with n p rows (the total number of pages) and n u columns (the number of users).
- Each column corresponds to a vector generated by the function ⁇ p , the derivation of which is described in detail above.
- the fifth column corresponding to user number five, is ⁇ p (u 5 ).
- T the text matrix with n p columns (the number of pages) and n t rows (the number of words).
- each column corresponds to a vector generated by the function ⁇ 1 .
- the seventh column corresponding to document number seven, is ⁇ t (d 7 ).
- the text representation of users is calculated as follows:
- This matrix inner product which is a matrix having n t rows and n u columns, can be interpreted as the weighted average of the text content of pages that each user has accessed. Or stated another way, P T can also be interpreted as an extrapolation of page accesses to the contents of the pages accessed.
- the inlink, outlink, and URL modalities are also representable by mediation, calculated analogously.
- the matrix multiplications here are L ⁇ P (inlinks), O ⁇ P (outlinks), and U ⁇ P (URLs), where L, O, and U are the matrices for inlinks, outlinks and urls respectively.
- This concept can also be extended to the other modalities, such as text genre, color histogram, and color complexity, as well as any other desired modality or feature calculated on a per-document basis.
- CUA collection use analysis
- the main technique used for CUA as described herein is multi-modal clustering of users; however, there remains the issue of trying to interpret those clusters.
- the objects of a cluster are characterized by similarities among the objects on features of text, usage, collection topology (inlinks and outlinks), and URL.
- similarities among objects are characterized by similarities among the objects on features of text, usage, collection topology (inlinks and outlinks), and URL.
- Disk Trees can be used to visualize the page and hyperlink topology of a Web site, and have been found advantageous to identify the parts of a site that typically interest various clusters of users. Also, techniques for summarizing the text and URLs that typify the interests of a cluster of users are employed by the invention. By combining such techniques, an analyst can be presented with an identification of the text, topology, and URLs that characterize the interests of an automatically identified cluster.
- testbed used in performing the examples set forth below consisted of a complete snapshot of the Xerox Web site (http:/lwww.xerox.com) during a 24-hour period over May 17 and 18, 1998. The entire day's usage information for about 6,400 users was collected. Users were identified on the basis of browser cookies. Additionally, the entire text and hyperlink topology was extracted. At the time of the snapshot, the site consisted of over 6,000 HTML pages and 8,000 non-HTML documents.
- the testbed system consisted of three primary components: a mapping program, which mapped modal information into real-valued vectors (embedded into R n ); a clustering program, which clustered sets of users; and a visualization system, which handled interactive data visualization of Web sites.
- the visualization program was capable of analyzing the directory structure of a Web site and constructing a Disk Tree as shown in FIG. 23 . As illustrated, each directory in the Web site corresponds to one node in the tree with all subdirectories and files in the directory being represented as children of the node. Preferably, layout of the tree is performed on a breadth-first basis.
- a visualization system used in an embodiment of the invention constructs a Disk Tree to represent the basic topology of a Web site, as shown in FIG. 23 .
- Each directory corresponds to one node in the tree with all subdirectories and files in the directory being represented as children of the node.
- Layout of the tree is performed on a Breadth-First basis.
- the Disk Tree 2310 in FIG. 23 shows the Xerox Web site, starting from the Xerox “splash page” (http://www.xerox.com/), with subsequent directories being depicted as concentric rings extending from the center of the disk. This produces an asymmetric disk.
- Disk Tree provides the analyst-user with a way to assess topology information about clusters.
- U.S. patent application Ser. No. 09/062,540 to Pirolli et al. entitled “Methods for Interactive Visualization of Spreading Activation Using Time Tubes and Disk Trees,”, now U.S. Pat. No. 6,151,595, the disclosure of which is hereby incorporated by reference as though set forth in full.
- clusters are visualized by coloring all segments that correspond to members of the cluster in one color.
- membership in a cluster can be indicated by coloring in red (indicated by bold lines in the Figure) the segments 2312 , 2314 , and 2316 that correspond to documents in the cluster.
- the preferred system allows for the visualization of multiple membership. For these cases, multiple membership is simply indicated by mixing the colors of all clusters that the page belongs to, for example by coloring one group 2320 of segments in stripes of red and blue to indicate simultaneous membership in a “red cluster” and a “blue cluster.”
- a dialog box interface (FIG. 24 ) the user of a preferred embodiment of the invention can interactively specify which clusters to display (currently limited to one or two clusters simultaneously).
- the dialog box displays a textual representation of the members of each cluster. For each cluster member, the weights of each modality are listed. The inlink outlink, text, and usage modalities are equally weighted (25% each).
- the “Clustering Report” 2410 contains the most characteristic keywords 2412 across all documents for the user cluster. This enables quick access to a high level abstraction of this modality while simultaneously viewing other properties.
- the “Document Report” 2416 in the cluster is the most characteristic keywords 2412 across all documents for the user cluster. This enables quick access to a high level abstraction of this modality while simultaneously viewing other properties.
- the Clustering Report is the best characterization of the cluster and in other cases, the Document Report provides the best characterization. It has been found that interaction with the system is greatly facilitated by being able to readily access a summary of both the entire cluster or of its most representative document.
- the result of multi-modal clustering is a textual listing of the dimensions that are most characteristic of a cluster for each modality. For example, if the cluster is “about” the Xerox HomeCentre product, then a salient dimension for the text modality is the word “HomeCentre.” Given that for the testbed Xerox Web site, twenty to fifty clusters were produced each containing hundreds of users, the task of identifying, comparing, and evaluating the cluster results in textual form can be daunting. In that case, the Disk Tree (described above) can be helpful.
- the Cluster Report window 2410 contains the characteristic keywords 2412 across all documents for the user cluster. These are computed by selecting the most highly weighted words in the text centroid (a text vector representing the centroid) of the cluster. Such summaries have been found to provide users with reliable assessments of the text of large clusters.
- the Document Report window 2414 provides the URL 2416 and a text summary 2418 of the most characteristic document (the document closest to the text centroid in the cluster). Together, the Cluster Report and Document Report windows 2410 and 2414 provide the analyst-user with a high level assessment of the text modality and the URL while simultaneously viewing other modalities.
- the dialog box interface in FIG. 24 is used to specify which clusters to display.
- the dialog box uses text to represent the members of each cluster.
- the weights of each modality 2420 are listed (the clustering shown in the figure was done for four of the five modalities), and in a preferred embodiment of the invention can be adjusted by the user.
- /investor/pr/ir980512.html is shown a member of cluster zero.
- the inlink, outlink, text, and usage modalities are equally weighted (25% each).
- the first method consists of a visual presentation of all members of the cluster. Building on the Disk Tree described above, this is straightforward if there is a hierarchical structure that members are embedded in. For example, a cluster of pages is shown by coloring all nodes in the Disk Tree that correspond to members of the cluster.
- a technical problem then is how to show user clusters in a web page-based visualization. This problem is solved by computing the probability that a particular page will be accessed if a random user is selected from a desired cluster.
- u) is calculated as the relative frequency with which a page p is accessed by a user u. For example, if a user accesses three pages, then each of them will have a probability P(p
- c), the relative frequency with which a page p is accessed by any user within a cluster c is then computed as the average of the probabilities P(p
- c ) ⁇ u ⁇ c ⁇ 1 ⁇ c ⁇ ⁇ P ⁇ ( p
- text-based cluster summaries are generated by presenting the most salient dimensions for each modality.
- Table 2 For a cluster of users interested in the Xerox HomeCentre.
- the ten most salient dimensions are listed: the ten most salient words, the ten most salient pages pointing to pages accessed by this cluster, the ten most salient outlinks occurring on accessed pages, the ten most salient pages accessed and the ten most salient url elements. It would be a daunting task to interpret and compare clusters based only on the objects that are in the cluster (the users in this case).
- the textual summary by means of salient dimensions makes it easier to understand clusters and why users were put in the same cluster.
- the salient dimensions for a given modality are calculated by using the probabilities expressed in P(p
- the largest terms in the aggregate feature vector then represent the salient dimensions. For example, referring to Table 2 above, the largest term in the aggregate text feature vector for the illustrated cluster corresponds to the word “homecentre”; likewise, the second-largest term corresponds to the word “detachable.”
- the most-important word is “products,” followed by “dhc.”
- Such a detailed characterization of the parts of the collection that are accessed can be used to add appropriate material or to improve existing material. For example, it was surprising to determine that there is only one small investor cluster. This can be interpreted as evidence that there is either not enough investment information on the site or that its layout should be improved to make it more attractive.
- clusters essentially consist of users that access only one page.
- An example is the cluster that only accesses the page for requesting a trial version of TextBridge Pro 98 (an optical character recognition program).
- These users have a clearly defined information need and are probably following a link from outside. Once they have the information they need (for example, Xerox' stock price on the Xerox home page), they leave immediately.
- clusters are characterized by grazing behavior, a much more amorphous information need that is gradually satisfied as the user browses through a large number of pages.
- One example is the cluster of users browsing the subhierarchy called the Document HomeCentre which has information on smaller devices, appropriate for small office and home office.
- Document HomeCentre which has information on smaller devices, appropriate for small office and home office.
- users from this cluster generally look at several pages of the subhierarchy, corresponding to several different Document HomeCentre products.
- these users come to the Xerox Web site to educate themselves about the range of products available, a process that requires looking at a relatively wide spectrum of information.
- the Disk Tree 2310 of FIG. 23 shows a cluster of investors from the 50-cluster clustering. There are two areas of strong activity in the upper half of the figure indicated by bold areas 2312 and 2314 . One area 2312 corresponds to the sub-hierarchy “annualreport”; the other area 2314 corresponds to the sub-hierarchy “factbook”. The fact that many investors look at both suggests that the collection should be reorganized so that these two sub-hierarchies are located together.
- the system is an example of using multi-modal clustering for exploratory data analysis.
- the system was used to characterize the user population on May 17, 1998. All 6400 users were assigned to 20 clusters.
- Nine clusters correspond to product categories: Pagis scanning, copiers, XSoft software, Xerox software library (for downloading pages), home and desktop products, TextBridge for Windows.
- Seven clusters correspond to users that mainly access a single page, for example the index of drivers or the Xerox home page.
- One cluster contains visitors who access employment information.
- One cluster contains investors and other visitors who are interested in press releases and other news about Xerox.
- Two clusters are mixed, containing users that do not fit well into any of the other categories. Multi-modal clustering thus enables analysts to get a quick characterization of the user population.
- Multi-modal clustering can be used for node aggregation the grouping of nodes into meta-nodes. For example, if there is not enough screen real estate to display the 1000 subnodes of a node on the edge of a screen, then these 1000 subnodes can be aggregated into 5 meta-nodes using multi-modal clustering. Displaying these 5 meta-nodes then takes up less space than displaying all 1000 subnodes.
- Multi-modal clustering can also be used for data mining. Once a cluster of users has been created by the multi-modal algorithm, one can automatically find salient features. For example, based on the textual representation of the HomeCentre cluster in Table 2 which shows “homecentre” as a salient word, one can test how well it is characterized by “homecentre” alone.
- Another data mining application is the discovery of unusual objects. For example, in the discovery phase of a lawsuit, a law firm may only be interested in outlier documents, not in the large groups of similar documents that mostly contain boilerplate. Multi-modal clustering would identify the large groups of similar documents (e.g., because of shared boilerplate). Interesting document would then be among those that are most distant from the centroids of large clusters.
- a data mining technique compares two groups of objects by doing a multi-modal clustering for the first and then assigning the second group to the clusters of the first.
- This analysis technique has been successfully used to compare Xerox-base and non-Xerox-based users of the Web site and found surprisingly few differences mainly because Xerox employees are users of Xerox products and that is one of the main reasons to go to the external Xerox web site (to download drivers, look up product information, etc).
- One difference was that a higher proportion of Xerox users visited only one page, the Xerox home page.
- Hierarchical clustering An increasingly important technique for organizing large collections, including intranets, is hierarchical clustering.
- the purpose is to automatically generate a hierarchy as it can be found on yahoo (and on many intranets).
- Hierarchical multi-modal clustering can be used to generate such a hierarchy automatically or to give human categorizers a first cut which they can then hand-edit.
- a recommendation system based on multi-modal user clusters is possible with the collection of multi-modal collection use data as described above.
- a set of clusters is induced from a training set of users.
- a new user is assigned to one of the clusters based on a few initial page accesses. Pages that were accessed by the users in the assigned cluster are then recommended to the user. Since the clustering is done based on multi-modal information it is robust enough to make useful recommendations.
- a multi-modal recommendation system is illustrated in FIG. 25 .
- a training set of users is identified (step 2510 ). Any type of information that is available about users is collected. In the disclosed embodiment, it has been found to be useful to collect information on the pages users access, as well as the text content, inlinks, outlinks, and URLs of these pages. It should also be noted that real-time document access data need not be used for this; the data can come from a usage log or even a user's set of browser “bookmarks,” when available. Also, as noted above, there are other modalities (beyond page usage) applicable to users that may be useful in this application, such as demographic information and other kinds of tracked information.
- the users are then clustered via multi-modal information (step 2512 ), as described above in the section related to multi-modal clustering.
- page usage is the primary information collected about users, as in the preferred embodiment of the invention, then it is appropriate to cluster users via the mediated representation of users by way of various document features, as described above. It should be recognized that other strategies are also possible. For example, if demographic information is collected, it may be more appropriate to cluster users simply on the demographic information.
- the selection of a basis on which to cluster is an implementation detail left to the judgment of a designer of a system according to the invention. Or alternatively, the selection may be left to the user.
- step 2514 If there are no new users (step 2514 ), then the process is finished (step 2516 ). Otherwise, the new user is identified (step 2518 ), browsing information is collected from the new user (step 2520 ), and the user is assigned to the nearest existing cluster (step 2522 ). In a preferred embodiment of the invention, the user is assigned based on the aggregate cosine similarity calculated over text content, inlinks, outlinks, and URLs, as described above.
- the most popular pages in the nearest cluster can then be identified (step 2524 ) and recommended to the new user (step 2526 ).
- the names, e-mail addresses, or other identifying data for the users in the nearest cluster can be provided to the new user, thereby allowing the new user to identify “experts” in a desired area.
- the algorithm has several advantages over other recommendation algorithms.
- the algorithm is fast. Since the clustering is a compile-time operation, the only run-time operation is the mapping of multi-modal information into the vector spaces of each modality and the computation of the aggregate cosine similarity with each cluster. This is efficient. Another way to gain the same advantage is to regard clustering as a way of summarizing the user population. This is important if the user population is large. For example, instead of having to keep track of one million users, recommendations can be made based on only, say, 1000 users; those that are representative of 1000 clusters derived from the complete user population.
- a subset of users is first identified (step 2610 ). As stated above, with a large population, a subset of users can represent very well the characteristics of the entire population. The subset of users is then re-clustered (step 2612 ). The most popular pages for each cluster are then determined (step 2614 ), and the pages recommended to new users are adjusted accordingly (step 2616 ).
- the algorithm set forth herein for providing multi-modal recommendations based on collection use analysis has been found to be very accurate and robust.
- Other recommendation algorithms rely on comparisons of the new user with previous users. When recommendations are based on one or two users who happen to be the nearest neighbors, then a bad page may be recommended because outliers can influence the recommended pages. Cluster-based generalization reduces the influence of outliers. Furthermore, since all available information is used and combined, the algorithm is more robust than recommendation algorithms that rely on a single source of information.
- testbed users i.e., users of the Xerox Web site on May 17-18, 1998) were logged. Based on their browsing habits, those users were placed into 200 clusters.
- Table 3 shows the most popular pages for user cluster 35 , based on the computation of the probability P(p
- This table includes the most salient pages for user cluster 127 . Based on the contents of this cluster, the system can recommend the employment pages of various subdivisions to users who are ready to apply for jobs.
- the listed documents include several employment pages on the Xerox web site that are not directly accessible from the central employment page (the second page in the table, with numerical identifier 37057). Two such not directly accessible pages are “research/xrcc/jobopps.htm” and “XBS/employmt.htm”. This type of recommendation enables users to find something that they may not find at all otherwise (as opposed to just saving them time). The same algorithm as described above is used to accomplish this: assign a new user to a user cluster (after some initial page accesses), and recommend pages characteristic of the cluster that the user has not accessed.
Abstract
Description
TABLE 1 | |||
Feature | Modality | ||
Text Vector | text | ||
Subject | text | ||
URLs | text | ||
Inlinks | hyperlink | ||
Outlinks | hyperlink | ||
Genre | genre | ||
Page Usage | user info | ||
Color Histogram | image | ||
Complexity | image | ||
TABLE 2 | ||||
text | ||||
0.504 | 8332 | homecentre | ||
0.221 | 14789 | detachable | ||
0.171 | 15270 | artist | ||
0.162 | 5372 | slot | ||
0.155 | 12010 | mono | ||
0.142 | 21335 | photoenhancer | ||
0.122 | 237 | foot | ||
0.121 | 4605 | creative | ||
0.113 | 3533 | projects | ||
0.109 | 21336 | pictureworks | ||
inlink | ||||
0.343 | 23856 | products/dhc/index.htm | ||
0.265 | 24144 | products/dhc/06does.htm | ||
0.259 | 17045 | soho/whatsnew.html | ||
0.257 | 24155 | products/dhc/13inclu.htm | ||
0.240 | 24151 | products/dhc/07buser.htm | ||
0.240 | 24152 | products/dhc/07cuser.htm | ||
0.235 | 24143 | products/dhc/12more.htm | ||
0.235 | 24157 | products/dhc/15supp.htm | ||
0.235 | 24156 | products/dhc/14req.htm | ||
outlink | ||||
0.527 | 24143 | products/dhc/12more.htm | ||
0.272 | 24156 | products/dhc/14req.htm | ||
0.272 | 24155 | products/dhc/13inclu.htm | ||
0.272 | 24157 | products/dhc/15supp.htm | ||
0.255 | 24149 | products/dhc/11pagis.htm | ||
0.248 | 31814 | http://www.teamxrx.com/retailers.html | ||
0.216 | 24145 | products/dhc/07user.htm | ||
0.216 | 24144 | products/dhc/06does.htm | ||
0.192 | 23856 | products/dhc/index.htm | ||
0.137 | 23857 | products/dwc450c/index.htm | ||
pages | ||||
0.557 | 37067 | products/dhc | ||
0.330 | 24143 | products/dhc/12more.htm | ||
0.303 | 19452 | products/multiprd.htm | ||
0.287 | 24144 | products/dhc/06does.htm | ||
0.274 | 24739 | soho/dhc.html | ||
0.233 | 24155 | products/dhc/13inclu.htm | ||
0.208 | 24156 | products/dhc/14req.htm | ||
0.191 | 24148 | products/dhc/09scan.htm | ||
0.184 | 24157 | products/dhc/15supp.htm | ||
0.176 | 24145 | products/dhc/07user.htm | ||
url | ||||
0.791 | 15 | products | ||
0.583 | 2036 | dhc | ||
0.141 | 646 | soho | ||
0.057 | 2037 | dwc450c | ||
0.054 | 895 | |||
0.044 | 31 | cgi-bin | ||
0.042 | 603 | supplies | ||
0.036 | 1768 | usa | ||
0.027 | 91 | xps | ||
0.020 | 844 | wwwwais | ||
TABLE 3 |
Cluster 35 |
0.976277 probsum |
16406 | 0.088639 | products/copiers.htm | ||
37005 | 0.085385 | http://www.xerox.com | ||
19453 | 0.059099 | products/cop_soho.htm | ||
33739 | 0.051071 | soho/xc0355.html | ||
21231 | 0.040836 | soho/xc1044.html | ||
17033 | 0.039741 | soho/xc0830.html | ||
37025 | 0.036496 | cgi-bin/wwwwais | ||
19451 | 0.035938 | products/cop_pers.htm | ||
17029 | 0.034706 | soho/xc0540.html | ||
17010 | 0.028586 | soho/5306.html | ||
21232 | 0.026014 | soho/xc1045.html | ||
TABLE 4 |
Cluster 127 |
1.000000 probsum |
24663 | 0.297222 | employment/ressend.htm | ||
37057 | 0.268162 | employment | ||
24666 | 0.079701 | employment/resascii.htm | ||
21384 | 0.076923 | research/xrcc/jobopps.htm | ||
37005 | 0.054701 | htp://www.xerox.com | ||
37087 | 0.050000 | cgi-bin/employment/xrxresume.cgi | ||
24675 | 0.047436 | employment/restip.htm | ||
24664 | 0.023077 | employment/college.htm | ||
15355 | 0.012821 | XBS/employmt.htm | ||
24665 | 0.012821 | employment/recruit.htm | ||
34418 | 0.012821 | employment/overview.htm | ||
37025 | 0.012821 | cgi-bin/wwwwais | ||
TABLE 5 |
Cluster 25 |
0.998387 probsum |
37057 | 0.661425 | employment | ||
37005 | 0.300403 | http://www.xerox.com | ||
34418 | 0.022581 | employment/overview.htm | ||
12839 | 0.004435 | searchform.html | ||
24675 | 0.004032 | employment/restip.htm | ||
37155 | 0.002688 | scansoft/tbapi | ||
37113 | 0.002016 | factbook/1997 | ||
23465 | 0.000806 | xbs | ||
Claims (26)
Priority Applications (14)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/421,770 US6728752B1 (en) | 1999-01-26 | 1999-10-19 | System and method for information browsing using multi-modal features |
EP00101367A EP1024437B1 (en) | 1999-01-26 | 2000-01-24 | Multi-modal information access |
EP10150975A EP2178008A3 (en) | 1999-01-26 | 2000-01-24 | Multi-modal information access |
DE60044220T DE60044220D1 (en) | 1999-01-26 | 2000-01-24 | Multimodal information access |
EP10183652A EP2284733A3 (en) | 1999-01-26 | 2000-01-24 | Multi-modal information access |
EP10150972A EP2178006A3 (en) | 1999-01-26 | 2000-01-24 | Multi-modal information access |
EP10150973A EP2178007A3 (en) | 1999-01-26 | 2000-01-24 | Multi-modal information access |
JP2000016705A JP4587512B2 (en) | 1999-01-26 | 2000-01-26 | Document data inquiry device |
JP2010140221A JP2010205306A (en) | 1999-01-26 | 2010-06-21 | Method for quantitatively representing object |
JP2010140220A JP4854799B2 (en) | 1999-01-26 | 2010-06-21 | How to make document recommendations |
JP2010140222A JP4874413B2 (en) | 1999-01-26 | 2010-06-21 | Inter-object similarity calculation method |
JP2010140223A JP4768073B2 (en) | 1999-01-26 | 2010-06-21 | Initial cluster center set selection method, wavefront clustering method |
JP2010140224A JP4768074B2 (en) | 1999-01-26 | 2010-06-21 | User cluster visibility method |
JP2011204358A JP5576842B2 (en) | 1999-01-26 | 2011-09-20 | Similarity calculation method between user characteristics |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11746299P | 1999-01-26 | 1999-01-26 | |
US09/421,770 US6728752B1 (en) | 1999-01-26 | 1999-10-19 | System and method for information browsing using multi-modal features |
Publications (1)
Publication Number | Publication Date |
---|---|
US6728752B1 true US6728752B1 (en) | 2004-04-27 |
Family
ID=32109670
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/421,770 Expired - Lifetime US6728752B1 (en) | 1999-01-26 | 1999-10-19 | System and method for information browsing using multi-modal features |
Country Status (1)
Country | Link |
---|---|
US (1) | US6728752B1 (en) |
Cited By (112)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020059215A1 (en) * | 2000-11-02 | 2002-05-16 | Takuya Kotani | Data search apparatus and method |
US20020065892A1 (en) * | 2000-11-30 | 2002-05-30 | Malik Dale W. | Method and apparatus for minimizing storage of common attachment files in an e-mail communications server |
US20020087532A1 (en) * | 2000-12-29 | 2002-07-04 | Steven Barritz | Cooperative, interactive, heuristic system for the creation and ongoing modification of categorization systems |
US20020129014A1 (en) * | 2001-01-10 | 2002-09-12 | Kim Brian S. | Systems and methods of retrieving relevant information |
US20030018617A1 (en) * | 2001-07-18 | 2003-01-23 | Holger Schwedes | Information retrieval using enhanced document vectors |
US20030074369A1 (en) * | 1999-01-26 | 2003-04-17 | Hinrich Schuetze | System and method for identifying similarities among objects in a collection |
US20030074368A1 (en) * | 1999-01-26 | 2003-04-17 | Hinrich Schuetze | System and method for quantitatively representing data objects in vector space |
US20030182310A1 (en) * | 2002-02-04 | 2003-09-25 | Elizabeth Charnock | Method and apparatus for sociological data mining |
US20040128391A1 (en) * | 2002-12-31 | 2004-07-01 | Robert Patzer | Method and system for managing a validity period in association with a presence attribute |
US20040139064A1 (en) * | 2001-03-16 | 2004-07-15 | Louis Chevallier | Method for navigation by computation of groups, receiver for carrying out said method and graphical interface for presenting said method |
US20040153456A1 (en) * | 2003-02-04 | 2004-08-05 | Elizabeth Charnock | Method and apparatus to visually present discussions for data mining purposes |
US20040249787A1 (en) * | 2000-03-22 | 2004-12-09 | Parvathi Chundi | Document clustering method and system |
US20060026152A1 (en) * | 2004-07-13 | 2006-02-02 | Microsoft Corporation | Query-based snippet clustering for search result grouping |
US6996577B1 (en) * | 2002-02-25 | 2006-02-07 | Novell, Inc. | Method and system for automatically grouping objects in a directory system based on their access patterns |
US20060095416A1 (en) * | 2004-10-28 | 2006-05-04 | Yahoo! Inc. | Link-based spam detection |
US20060184574A1 (en) * | 2005-02-15 | 2006-08-17 | Peng Wu | Digital image search and retrieval system |
US20060200769A1 (en) * | 2003-08-07 | 2006-09-07 | Louis Chevallier | Method for reproducing audio documents with the aid of an interface comprising document groups and associated reproducing device |
US7117198B1 (en) * | 2000-11-28 | 2006-10-03 | Ip Capital Group, Inc. | Method of researching and analyzing information contained in a database |
US20060253421A1 (en) * | 2005-05-06 | 2006-11-09 | Fang Chen | Method and product for searching title metadata based on user preferences |
US7213198B1 (en) * | 1999-08-12 | 2007-05-01 | Google Inc. | Link based clustering of hyperlinked documents |
WO2007056287A2 (en) * | 2005-11-04 | 2007-05-18 | Eye Tracking, Inc. | Generation of test stimuli in visual media |
US20070168856A1 (en) * | 2006-01-13 | 2007-07-19 | Kathrin Berkner | Tree pruning of icon trees via subtree selection using tree functionals |
US20070174872A1 (en) * | 2006-01-25 | 2007-07-26 | Microsoft Corporation | Ranking content based on relevance and quality |
US20070174790A1 (en) * | 2006-01-23 | 2007-07-26 | Microsoft Corporation | User interface for viewing clusters of images |
US20070174269A1 (en) * | 2006-01-23 | 2007-07-26 | Microsoft Corporation | Generating clusters of images for search results |
US20070198603A1 (en) * | 2006-02-08 | 2007-08-23 | Konstantinos Tsioutsiouliklis | Using exceptional changes in webgraph snapshots over time for internet entity marking |
US20070214140A1 (en) * | 2006-03-10 | 2007-09-13 | Dom Byron E | Assigning into one set of categories information that has been assigned to other sets of categories |
US20070219954A1 (en) * | 2006-03-15 | 2007-09-20 | Microsoft Corporation | Refined Search User Interface |
US20070219964A1 (en) * | 2006-03-20 | 2007-09-20 | Cannon John S | Query system using iterative grouping and narrowing of query results |
US20070226340A1 (en) * | 2006-03-22 | 2007-09-27 | Cellco Partnership (D/B/A Verizon Wireless) | Electronic communication work flow manager system, method and computer program product |
US7287214B1 (en) * | 1999-12-10 | 2007-10-23 | Books24X7.Com, Inc. | System and method for providing a searchable library of electronic documents to a user |
US20070276854A1 (en) * | 2006-05-23 | 2007-11-29 | Gold David P | System and method for organizing, processing and presenting information |
US20070294084A1 (en) * | 2006-06-13 | 2007-12-20 | Cross Charles W | Context-based grammars for automated speech recognition |
US7346604B1 (en) * | 1999-10-15 | 2008-03-18 | Hewlett-Packard Development Company, L.P. | Method for ranking hypertext search results by analysis of hyperlinks from expert documents and keyword scope |
US20080077569A1 (en) * | 2006-09-27 | 2008-03-27 | Yahoo! Inc., A Delaware Corporation | Integrated Search Service System and Method |
US20080082559A1 (en) * | 2006-09-28 | 2008-04-03 | Gm Global Technology Operations, Inc. | Method of linking information to an electronically enabled manufactured part archive |
US20080086686A1 (en) * | 2006-10-10 | 2008-04-10 | Microsoft Corporation | User interface for displaying images of sights |
US20080086468A1 (en) * | 2006-10-10 | 2008-04-10 | Microsoft Corporation | Identifying sight for a location |
US7386439B1 (en) | 2002-02-04 | 2008-06-10 | Cataphora, Inc. | Data mining by retrieving causally-related documents not individually satisfying search criteria used |
US20080144952A1 (en) * | 2006-11-30 | 2008-06-19 | Canon Kabushiki Kaisha | Method and Apparatus For Hybrid Image Compression |
US7398271B1 (en) * | 2001-04-16 | 2008-07-08 | Yahoo! Inc. | Using network traffic logs for search enhancement |
US7421432B1 (en) * | 1999-12-15 | 2008-09-02 | Google Inc. | Hypertext browser assistant |
US20080306935A1 (en) * | 2007-06-11 | 2008-12-11 | Microsoft Corporation | Using joint communication and search data |
US20090006357A1 (en) * | 2007-06-27 | 2009-01-01 | Alexandrin Popescul | Determining quality measures for web objects based on searcher behavior |
US20090013033A1 (en) * | 2007-07-06 | 2009-01-08 | Yahoo! Inc. | Identifying excessively reciprocal links among web entities |
US20090019026A1 (en) * | 2007-07-09 | 2009-01-15 | Vivisimo, Inc. | Clustering System and Method |
US20090019036A1 (en) * | 2007-07-10 | 2009-01-15 | Asim Roy | Systems and Related Methods of User-Guided Searching |
US20090112830A1 (en) * | 2007-10-25 | 2009-04-30 | Fuji Xerox Co., Ltd. | System and methods for searching images in presentations |
US20090193099A1 (en) * | 2008-01-29 | 2009-07-30 | Palo Alto Research Center Incorporated | Method and apparatus for automatically incorporating hypothetical context information into recommendation queries |
US20100017290A1 (en) * | 2008-01-10 | 2010-01-21 | Fujifilm Corporation | Apparatus, method and program for attaching advertisement |
US7672877B1 (en) * | 2004-02-26 | 2010-03-02 | Yahoo! Inc. | Product data classification |
US20100053408A1 (en) * | 2008-08-28 | 2010-03-04 | Sony Corporation | Information processing apparatus and method and computer program |
US20100070554A1 (en) * | 2008-09-16 | 2010-03-18 | Microsoft Corporation | Balanced Routing of Questions to Experts |
US20100082615A1 (en) * | 2008-09-19 | 2010-04-01 | Xerox Corporation | Cross-media similarity measures through trans-media pseudo-relevance feedback and document reranking |
US20100228777A1 (en) * | 2009-02-20 | 2010-09-09 | Microsoft Corporation | Identifying a Discussion Topic Based on User Interest Information |
US7870039B1 (en) | 2004-02-27 | 2011-01-11 | Yahoo! Inc. | Automatic product categorization |
US20110029511A1 (en) * | 2009-07-30 | 2011-02-03 | Muralidharan Sampath Kodialam | Keyword assignment to a web page |
US20110072012A1 (en) * | 2009-09-18 | 2011-03-24 | Xerox Corporation | System and method for information seeking in a multimedia collection |
US8005823B1 (en) | 2007-03-28 | 2011-08-23 | Amazon Technologies, Inc. | Community search optimization |
US20120036446A1 (en) * | 2010-08-06 | 2012-02-09 | Avaya Inc. | System and method for optimizing access to a resource based on social synchrony and homophily |
US20120054177A1 (en) * | 2010-08-31 | 2012-03-01 | Microsoft Corporation | Sketch-based image search |
US8234168B1 (en) | 2012-04-19 | 2012-07-31 | Luminate, Inc. | Image content and quality assurance system and method |
US8255495B1 (en) | 2012-03-22 | 2012-08-28 | Luminate, Inc. | Digital image and content display systems and methods |
US20120254162A1 (en) * | 2011-03-31 | 2012-10-04 | Infosys Technologies Ltd. | Facet support, clustering for code query results |
US20120288841A1 (en) * | 2011-05-13 | 2012-11-15 | Xerox Corporation | Methods and systems for clustering students based on their performance |
US20120290980A1 (en) * | 2010-01-11 | 2012-11-15 | Joel Sirot | Method for navigating identifiers placed in areas and receiver implementing the method |
US20130132190A1 (en) * | 2011-11-17 | 2013-05-23 | Kristen Lagle Ruiz | Image tagging system and method for contextually relevant advertising |
US8495489B1 (en) | 2012-05-16 | 2013-07-23 | Luminate, Inc. | System and method for creating and displaying image annotations |
US8521735B1 (en) * | 2012-02-27 | 2013-08-27 | Google Inc. | Anonymous personalized recommendation method |
US20130325600A1 (en) * | 2012-06-01 | 2013-12-05 | Luminate, Inc. | Image-Content Matching Based on Image Context and Referrer Data |
US8635519B2 (en) | 2011-08-26 | 2014-01-21 | Luminate, Inc. | System and method for sharing content based on positional tagging |
CN103797509A (en) * | 2011-09-16 | 2014-05-14 | 乐天株式会社 | Image search apparatus, image search method, program, and computer-readable recording medium |
US8737678B2 (en) | 2011-10-05 | 2014-05-27 | Luminate, Inc. | Platform for providing interactive applications on a digital content platform |
US8869097B2 (en) | 2011-03-23 | 2014-10-21 | Infosys Limited | Online integrated development environment with code assist |
US8868554B1 (en) | 2004-02-26 | 2014-10-21 | Yahoo! Inc. | Associating product offerings with product abstractions |
US8903752B1 (en) * | 2012-02-09 | 2014-12-02 | Google Inc. | Classifying documents based on automatically detected rules |
US8953857B2 (en) | 2011-06-30 | 2015-02-10 | Panasonic Corporation | Similar case searching apparatus and similar case searching method |
US8972393B1 (en) | 2010-06-30 | 2015-03-03 | Amazon Technologies, Inc. | Disambiguation of term meaning |
US20150100587A1 (en) * | 2013-10-08 | 2015-04-09 | Flipboard, Inc. | Identifying Similar Content on a Digital Magazine Server |
US9009664B2 (en) | 2011-03-31 | 2015-04-14 | Infosys Limited | Structural search of source code |
EP2869213A1 (en) * | 2013-10-31 | 2015-05-06 | Alcatel Lucent | Media content ordering system and method for ordering media content |
US9053115B1 (en) | 2009-04-20 | 2015-06-09 | Google Inc. | Query image search |
USD736224S1 (en) | 2011-10-10 | 2015-08-11 | Yahoo! Inc. | Portion of a display screen with a graphical user interface |
USD737290S1 (en) | 2011-10-10 | 2015-08-25 | Yahoo! Inc. | Portion of a display screen with a graphical user interface |
USD737289S1 (en) | 2011-10-03 | 2015-08-25 | Yahoo! Inc. | Portion of a display screen with a graphical user interface |
US9147125B2 (en) | 2013-05-03 | 2015-09-29 | Microsoft Technology Licensing, Llc | Hand-drawn sketch recognition |
US9183510B1 (en) * | 2011-10-03 | 2015-11-10 | Tastebud Technologies, Inc. | Method and system for personalized recommendation of lifestyle items |
US9245051B2 (en) | 2011-09-20 | 2016-01-26 | Nokia Technologies Oy | Method and apparatus for conducting a search based on available data modes |
US20160048512A1 (en) * | 2014-08-15 | 2016-02-18 | Freedom Solutions Group, LLC d/b/a/ Microsystems | User Interface Operation Based on Token Frequency of Use in Text |
US9268733B1 (en) | 2011-03-07 | 2016-02-23 | Amazon Technologies, Inc. | Dynamically selecting example passages |
US20160098613A1 (en) * | 2005-09-30 | 2016-04-07 | Facebook, Inc. | Apparatus, method and program for image search |
US9384408B2 (en) | 2011-01-12 | 2016-07-05 | Yahoo! Inc. | Image analysis system and method using image recognition and text search |
US20160314182A1 (en) * | 2014-09-18 | 2016-10-27 | Google, Inc. | Clustering communications based on classification |
US9665650B1 (en) * | 1999-12-15 | 2017-05-30 | Google Inc. | In-context searching |
US9679047B1 (en) | 2010-03-29 | 2017-06-13 | Amazon Technologies, Inc. | Context-sensitive reference works |
US9734167B2 (en) | 2011-09-21 | 2017-08-15 | Horsetooth Ventures, LLC | Interactive image display and selection system |
US9747305B2 (en) | 2012-03-29 | 2017-08-29 | Rakuten, Inc. | Image search device, image search method, program, and computer-readable storage medium |
US9760369B2 (en) | 2013-12-13 | 2017-09-12 | Infosys Limited | Assessing modularity of a program written in object oriented language |
US9940366B2 (en) | 2012-03-29 | 2018-04-10 | Rakuten, Inc. | Image search device, image search method, program, and computer-readable storage medium |
US9990433B2 (en) | 2014-05-23 | 2018-06-05 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US10013436B1 (en) | 2014-06-17 | 2018-07-03 | Google Llc | Image annotation based on label consensus |
US10061765B2 (en) | 2014-08-15 | 2018-08-28 | Freedom Solutions Group, Llc | User interface operation based on similar spelling of tokens in text |
US10332007B2 (en) | 2009-08-24 | 2019-06-25 | Nuix North America Inc. | Computer-implemented system and method for generating document training sets |
US10430450B2 (en) * | 2016-08-22 | 2019-10-01 | International Business Machines Corporation | Creation of a summary for a plurality of texts |
US10614366B1 (en) | 2006-01-31 | 2020-04-07 | The Research Foundation for the State University o | System and method for multimedia ranking and multi-modal image retrieval using probabilistic semantic models and expectation-maximization (EM) learning |
CN111783808A (en) * | 2019-07-23 | 2020-10-16 | 北京沃东天骏信息技术有限公司 | Method and apparatus for generating information |
CN112861944A (en) * | 2021-01-28 | 2021-05-28 | 中山大学 | Image retrieval method and device based on mixed modal input |
US11068546B2 (en) | 2016-06-02 | 2021-07-20 | Nuix North America Inc. | Computer-implemented system and method for analyzing clusters of coded documents |
US11068532B2 (en) | 2011-09-21 | 2021-07-20 | Horsetooth Ventures, LLC | Interactive image display and selection system |
US11256395B2 (en) * | 2019-10-31 | 2022-02-22 | Tweddle Group | Systems and methods for transforming user interfaces based on database interactions |
US11314826B2 (en) | 2014-05-23 | 2022-04-26 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US20220382424A1 (en) * | 2021-05-26 | 2022-12-01 | Intuit Inc. | Smart navigation |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5412774A (en) * | 1990-08-29 | 1995-05-02 | At&T Corp. | Apparatus for and method of displaying a data item of a database using the display function of a selected data item |
US5442778A (en) | 1991-11-12 | 1995-08-15 | Xerox Corporation | Scatter-gather: a cluster-based method and apparatus for browsing large document collections |
US5794178A (en) * | 1993-09-20 | 1998-08-11 | Hnc Software, Inc. | Visualization of information using graphical representations of context vector based relationships and attributes |
US5893095A (en) * | 1996-03-29 | 1999-04-06 | Virage, Inc. | Similarity engine for content-based retrieval of images |
US5926185A (en) * | 1996-05-03 | 1999-07-20 | Barco Graphics N.V. | Method for processing a set of page description language commands to reduce complexity |
US5999927A (en) * | 1996-01-11 | 1999-12-07 | Xerox Corporation | Method and apparatus for information access employing overlapping clusters |
US6415282B1 (en) * | 1998-04-22 | 2002-07-02 | Nec Usa, Inc. | Method and apparatus for query refinement |
-
1999
- 1999-10-19 US US09/421,770 patent/US6728752B1/en not_active Expired - Lifetime
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5412774A (en) * | 1990-08-29 | 1995-05-02 | At&T Corp. | Apparatus for and method of displaying a data item of a database using the display function of a selected data item |
US5442778A (en) | 1991-11-12 | 1995-08-15 | Xerox Corporation | Scatter-gather: a cluster-based method and apparatus for browsing large document collections |
US5794178A (en) * | 1993-09-20 | 1998-08-11 | Hnc Software, Inc. | Visualization of information using graphical representations of context vector based relationships and attributes |
US5999927A (en) * | 1996-01-11 | 1999-12-07 | Xerox Corporation | Method and apparatus for information access employing overlapping clusters |
US5893095A (en) * | 1996-03-29 | 1999-04-06 | Virage, Inc. | Similarity engine for content-based retrieval of images |
US5926185A (en) * | 1996-05-03 | 1999-07-20 | Barco Graphics N.V. | Method for processing a set of page description language commands to reduce complexity |
US6415282B1 (en) * | 1998-04-22 | 2002-07-02 | Nec Usa, Inc. | Method and apparatus for query refinement |
Cited By (207)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6922699B2 (en) * | 1999-01-26 | 2005-07-26 | Xerox Corporation | System and method for quantitatively representing data objects in vector space |
US20030074368A1 (en) * | 1999-01-26 | 2003-04-17 | Hinrich Schuetze | System and method for quantitatively representing data objects in vector space |
US20030074369A1 (en) * | 1999-01-26 | 2003-04-17 | Hinrich Schuetze | System and method for identifying similarities among objects in a collection |
US6941321B2 (en) * | 1999-01-26 | 2005-09-06 | Xerox Corporation | System and method for identifying similarities among objects in a collection |
US8516357B1 (en) | 1999-08-12 | 2013-08-20 | Google Inc. | Link based clustering of hyperlinked documents |
US7213198B1 (en) * | 1999-08-12 | 2007-05-01 | Google Inc. | Link based clustering of hyperlinked documents |
US7346604B1 (en) * | 1999-10-15 | 2008-03-18 | Hewlett-Packard Development Company, L.P. | Method for ranking hypertext search results by analysis of hyperlinks from expert documents and keyword scope |
US20080065609A1 (en) * | 1999-12-10 | 2008-03-13 | Books24X7.Com, Inc. | System and method for providing a searchable library of electronic documents to a user |
US7287214B1 (en) * | 1999-12-10 | 2007-10-23 | Books24X7.Com, Inc. | System and method for providing a searchable library of electronic documents to a user |
US8316016B1 (en) | 1999-12-15 | 2012-11-20 | Google Inc. | Hypertext browser assistant |
US8688687B1 (en) | 1999-12-15 | 2014-04-01 | Google Inc. | Hypertext browser assistant |
US9665650B1 (en) * | 1999-12-15 | 2017-05-30 | Google Inc. | In-context searching |
US8560564B1 (en) | 1999-12-15 | 2013-10-15 | Google Inc. | Hypertext browser assistant |
US7421432B1 (en) * | 1999-12-15 | 2008-09-02 | Google Inc. | Hypertext browser assistant |
US20040249787A1 (en) * | 2000-03-22 | 2004-12-09 | Parvathi Chundi | Document clustering method and system |
US7181678B2 (en) * | 2000-03-22 | 2007-02-20 | Hewlett-Packard Development Company, L.P. | Document clustering method and system |
US20020059215A1 (en) * | 2000-11-02 | 2002-05-16 | Takuya Kotani | Data search apparatus and method |
US7117198B1 (en) * | 2000-11-28 | 2006-10-03 | Ip Capital Group, Inc. | Method of researching and analyzing information contained in a database |
US7908332B2 (en) | 2000-11-30 | 2011-03-15 | At&T Intellectual Property I, L.P. | Method and apparatus for minimizing storage of common attachment files in an e-mail communications server |
US7003551B2 (en) * | 2000-11-30 | 2006-02-21 | Bellsouth Intellectual Property Corp. | Method and apparatus for minimizing storage of common attachment files in an e-mail communications server |
US7444382B2 (en) | 2000-11-30 | 2008-10-28 | At&T Intellectual Property I, L.P. | Method and apparatus for minimizing storage of common attachment files in an e-mail communications server |
US20060095527A1 (en) * | 2000-11-30 | 2006-05-04 | Malik Dale W | Method and apparatus for minimzing storage of common attachment files in an e-mail communications server |
US20020065892A1 (en) * | 2000-11-30 | 2002-05-30 | Malik Dale W. | Method and apparatus for minimizing storage of common attachment files in an e-mail communications server |
US20020087532A1 (en) * | 2000-12-29 | 2002-07-04 | Steven Barritz | Cooperative, interactive, heuristic system for the creation and ongoing modification of categorization systems |
US20020129014A1 (en) * | 2001-01-10 | 2002-09-12 | Kim Brian S. | Systems and methods of retrieving relevant information |
US7356530B2 (en) * | 2001-01-10 | 2008-04-08 | Looksmart, Ltd. | Systems and methods of retrieving relevant information |
US8086601B2 (en) | 2001-01-10 | 2011-12-27 | Looksmart, Ltd. | Systems and methods of retrieving relevant information |
US20080147649A1 (en) * | 2001-01-10 | 2008-06-19 | Looksmart, Ltd. | Systems and methods of retrieving relevant information |
US20040139064A1 (en) * | 2001-03-16 | 2004-07-15 | Louis Chevallier | Method for navigation by computation of groups, receiver for carrying out said method and graphical interface for presenting said method |
US7398271B1 (en) * | 2001-04-16 | 2008-07-08 | Yahoo! Inc. | Using network traffic logs for search enhancement |
US20080270404A1 (en) * | 2001-04-16 | 2008-10-30 | Arkady Borkovsky | Using Network Traffic Logs for Search Enhancement |
US20080270484A1 (en) * | 2001-04-16 | 2008-10-30 | Arkady Borkovsky | Using Network Traffic Logs for Search Enhancement |
US7996397B2 (en) | 2001-04-16 | 2011-08-09 | Yahoo! Inc. | Using network traffic logs for search enhancement |
US8203952B2 (en) | 2001-04-16 | 2012-06-19 | Yahoo! Inc. | Using network traffic logs for search enhancement |
US20030018617A1 (en) * | 2001-07-18 | 2003-01-23 | Holger Schwedes | Information retrieval using enhanced document vectors |
US7143091B2 (en) * | 2002-02-04 | 2006-11-28 | Cataphorn, Inc. | Method and apparatus for sociological data mining |
US7386439B1 (en) | 2002-02-04 | 2008-06-10 | Cataphora, Inc. | Data mining by retrieving causally-related documents not individually satisfying search criteria used |
US20030182310A1 (en) * | 2002-02-04 | 2003-09-25 | Elizabeth Charnock | Method and apparatus for sociological data mining |
US6996577B1 (en) * | 2002-02-25 | 2006-02-07 | Novell, Inc. | Method and system for automatically grouping objects in a directory system based on their access patterns |
US20040128391A1 (en) * | 2002-12-31 | 2004-07-01 | Robert Patzer | Method and system for managing a validity period in association with a presence attribute |
US20040153456A1 (en) * | 2003-02-04 | 2004-08-05 | Elizabeth Charnock | Method and apparatus to visually present discussions for data mining purposes |
US7421660B2 (en) | 2003-02-04 | 2008-09-02 | Cataphora, Inc. | Method and apparatus to visually present discussions for data mining purposes |
US20060200769A1 (en) * | 2003-08-07 | 2006-09-07 | Louis Chevallier | Method for reproducing audio documents with the aid of an interface comprising document groups and associated reproducing device |
US7546242B2 (en) * | 2003-08-07 | 2009-06-09 | Thomson Licensing | Method for reproducing audio documents with the aid of an interface comprising document groups and associated reproducing device |
US7672877B1 (en) * | 2004-02-26 | 2010-03-02 | Yahoo! Inc. | Product data classification |
US8868554B1 (en) | 2004-02-26 | 2014-10-21 | Yahoo! Inc. | Associating product offerings with product abstractions |
US7870039B1 (en) | 2004-02-27 | 2011-01-11 | Yahoo! Inc. | Automatic product categorization |
US20060026152A1 (en) * | 2004-07-13 | 2006-02-02 | Microsoft Corporation | Query-based snippet clustering for search result grouping |
US7617176B2 (en) * | 2004-07-13 | 2009-11-10 | Microsoft Corporation | Query-based snippet clustering for search result grouping |
US7533092B2 (en) | 2004-10-28 | 2009-05-12 | Yahoo! Inc. | Link-based spam detection |
US20060095416A1 (en) * | 2004-10-28 | 2006-05-04 | Yahoo! Inc. | Link-based spam detection |
CN101180624B (en) * | 2004-10-28 | 2012-05-09 | 雅虎公司 | Link-based spam detection |
US20060184574A1 (en) * | 2005-02-15 | 2006-08-17 | Peng Wu | Digital image search and retrieval system |
US8407201B2 (en) * | 2005-02-15 | 2013-03-26 | Hewlett-Packard Development Company, L.P. | Digital image search and retrieval system |
WO2006121576A2 (en) * | 2005-05-06 | 2006-11-16 | Motorola, Inc. | Method and product for searching metadata based on user preferences |
WO2006121576A3 (en) * | 2005-05-06 | 2007-05-31 | Motorola Inc | Method and product for searching metadata based on user preferences |
US20060253421A1 (en) * | 2005-05-06 | 2006-11-09 | Fang Chen | Method and product for searching title metadata based on user preferences |
US9881229B2 (en) * | 2005-09-30 | 2018-01-30 | Facebook, Inc. | Apparatus, method and program for image search |
US10810454B2 (en) | 2005-09-30 | 2020-10-20 | Facebook, Inc. | Apparatus, method and program for image search |
US20160098613A1 (en) * | 2005-09-30 | 2016-04-07 | Facebook, Inc. | Apparatus, method and program for image search |
WO2007056287A2 (en) * | 2005-11-04 | 2007-05-18 | Eye Tracking, Inc. | Generation of test stimuli in visual media |
WO2007056287A3 (en) * | 2005-11-04 | 2007-12-06 | Eye Tracking Inc | Generation of test stimuli in visual media |
US8602791B2 (en) | 2005-11-04 | 2013-12-10 | Eye Tracking, Inc. | Generation of test stimuli in visual media |
US20070168856A1 (en) * | 2006-01-13 | 2007-07-19 | Kathrin Berkner | Tree pruning of icon trees via subtree selection using tree functionals |
US8683314B2 (en) * | 2006-01-13 | 2014-03-25 | Ricoh Co., Ltd. | Tree pruning of icon trees via subtree selection using tree functionals |
US10120883B2 (en) | 2006-01-23 | 2018-11-06 | Microsoft Technology Licensing, Llc | User interface for viewing clusters of images |
US20070174269A1 (en) * | 2006-01-23 | 2007-07-26 | Microsoft Corporation | Generating clusters of images for search results |
US7644373B2 (en) | 2006-01-23 | 2010-01-05 | Microsoft Corporation | User interface for viewing clusters of images |
US20070174790A1 (en) * | 2006-01-23 | 2007-07-26 | Microsoft Corporation | User interface for viewing clusters of images |
US7725451B2 (en) * | 2006-01-23 | 2010-05-25 | Microsoft Corporation | Generating clusters of images for search results |
US9396214B2 (en) | 2006-01-23 | 2016-07-19 | Microsoft Technology Licensing, Llc | User interface for viewing clusters of images |
US20070174872A1 (en) * | 2006-01-25 | 2007-07-26 | Microsoft Corporation | Ranking content based on relevance and quality |
US7836050B2 (en) | 2006-01-25 | 2010-11-16 | Microsoft Corporation | Ranking content based on relevance and quality |
US10614366B1 (en) | 2006-01-31 | 2020-04-07 | The Research Foundation for the State University o | System and method for multimedia ranking and multi-modal image retrieval using probabilistic semantic models and expectation-maximization (EM) learning |
US20070198603A1 (en) * | 2006-02-08 | 2007-08-23 | Konstantinos Tsioutsiouliklis | Using exceptional changes in webgraph snapshots over time for internet entity marking |
US8429177B2 (en) | 2006-02-08 | 2013-04-23 | Yahoo! Inc. | Using exceptional changes in webgraph snapshots over time for internet entity marking |
US20070214140A1 (en) * | 2006-03-10 | 2007-09-13 | Dom Byron E | Assigning into one set of categories information that has been assigned to other sets of categories |
US20110137908A1 (en) * | 2006-03-10 | 2011-06-09 | Byron Edward Dom | Assigning into one set of categories information that has been assigned to other sets of categories |
US7885859B2 (en) | 2006-03-10 | 2011-02-08 | Yahoo! Inc. | Assigning into one set of categories information that has been assigned to other sets of categories |
WO2007106322A1 (en) * | 2006-03-15 | 2007-09-20 | Microsoft Corporation | Refined search user interface |
US20070219954A1 (en) * | 2006-03-15 | 2007-09-20 | Microsoft Corporation | Refined Search User Interface |
US7917511B2 (en) * | 2006-03-20 | 2011-03-29 | Cannon Structures, Inc. | Query system using iterative grouping and narrowing of query results |
US20070219964A1 (en) * | 2006-03-20 | 2007-09-20 | Cannon John S | Query system using iterative grouping and narrowing of query results |
US8868660B2 (en) * | 2006-03-22 | 2014-10-21 | Cellco Partnership | Electronic communication work flow manager system, method and computer program product |
US20070226340A1 (en) * | 2006-03-22 | 2007-09-27 | Cellco Partnership (D/B/A Verizon Wireless) | Electronic communication work flow manager system, method and computer program product |
US20070276854A1 (en) * | 2006-05-23 | 2007-11-29 | Gold David P | System and method for organizing, processing and presenting information |
US8392417B2 (en) | 2006-05-23 | 2013-03-05 | David P. Gold | System and method for organizing, processing and presenting information |
US8566087B2 (en) | 2006-06-13 | 2013-10-22 | Nuance Communications, Inc. | Context-based grammars for automated speech recognition |
US8332218B2 (en) * | 2006-06-13 | 2012-12-11 | Nuance Communications, Inc. | Context-based grammars for automated speech recognition |
US20070294084A1 (en) * | 2006-06-13 | 2007-12-20 | Cross Charles W | Context-based grammars for automated speech recognition |
US20080077569A1 (en) * | 2006-09-27 | 2008-03-27 | Yahoo! Inc., A Delaware Corporation | Integrated Search Service System and Method |
US20080082559A1 (en) * | 2006-09-28 | 2008-04-03 | Gm Global Technology Operations, Inc. | Method of linking information to an electronically enabled manufactured part archive |
US20100138435A1 (en) * | 2006-09-28 | 2010-06-03 | Lesperance Ronald M | Method of linking information to an electronically enabled manufactured part archive |
US20080086686A1 (en) * | 2006-10-10 | 2008-04-10 | Microsoft Corporation | User interface for displaying images of sights |
US20080086468A1 (en) * | 2006-10-10 | 2008-04-10 | Microsoft Corporation | Identifying sight for a location |
US7657504B2 (en) | 2006-10-10 | 2010-02-02 | Microsoft Corporation | User interface for displaying images of sights |
US7707208B2 (en) | 2006-10-10 | 2010-04-27 | Microsoft Corporation | Identifying sight for a location |
US8411942B2 (en) * | 2006-11-30 | 2013-04-02 | Canon Kabushiki Kaisha | Method and apparatus for hybrid image compression |
US20080144952A1 (en) * | 2006-11-30 | 2008-06-19 | Canon Kabushiki Kaisha | Method and Apparatus For Hybrid Image Compression |
US8005823B1 (en) | 2007-03-28 | 2011-08-23 | Amazon Technologies, Inc. | Community search optimization |
US20080306935A1 (en) * | 2007-06-11 | 2008-12-11 | Microsoft Corporation | Using joint communication and search data |
US8150868B2 (en) | 2007-06-11 | 2012-04-03 | Microsoft Corporation | Using joint communication and search data |
US8290986B2 (en) * | 2007-06-27 | 2012-10-16 | Yahoo! Inc. | Determining quality measures for web objects based on searcher behavior |
US20090006357A1 (en) * | 2007-06-27 | 2009-01-01 | Alexandrin Popescul | Determining quality measures for web objects based on searcher behavior |
US20090013033A1 (en) * | 2007-07-06 | 2009-01-08 | Yahoo! Inc. | Identifying excessively reciprocal links among web entities |
US8019760B2 (en) | 2007-07-09 | 2011-09-13 | Vivisimo, Inc. | Clustering system and method |
US20090019026A1 (en) * | 2007-07-09 | 2009-01-15 | Vivisimo, Inc. | Clustering System and Method |
US8402029B2 (en) | 2007-07-09 | 2013-03-19 | International Business Machines Corporation | Clustering system and method |
US8713001B2 (en) * | 2007-07-10 | 2014-04-29 | Asim Roy | Systems and related methods of user-guided searching |
US20090019036A1 (en) * | 2007-07-10 | 2009-01-15 | Asim Roy | Systems and Related Methods of User-Guided Searching |
US20090112830A1 (en) * | 2007-10-25 | 2009-04-30 | Fuji Xerox Co., Ltd. | System and methods for searching images in presentations |
US20100017290A1 (en) * | 2008-01-10 | 2010-01-21 | Fujifilm Corporation | Apparatus, method and program for attaching advertisement |
US20090193099A1 (en) * | 2008-01-29 | 2009-07-30 | Palo Alto Research Center Incorporated | Method and apparatus for automatically incorporating hypothetical context information into recommendation queries |
US7904530B2 (en) * | 2008-01-29 | 2011-03-08 | Palo Alto Research Center Incorporated | Method and apparatus for automatically incorporating hypothetical context information into recommendation queries |
US20100053408A1 (en) * | 2008-08-28 | 2010-03-04 | Sony Corporation | Information processing apparatus and method and computer program |
US8312374B2 (en) * | 2008-08-28 | 2012-11-13 | Sony Corporation | Information processing apparatus and method and computer program |
US20100070554A1 (en) * | 2008-09-16 | 2010-03-18 | Microsoft Corporation | Balanced Routing of Questions to Experts |
US8751559B2 (en) | 2008-09-16 | 2014-06-10 | Microsoft Corporation | Balanced routing of questions to experts |
US9183227B2 (en) * | 2008-09-19 | 2015-11-10 | Xerox Corporation | Cross-media similarity measures through trans-media pseudo-relevance feedback and document reranking |
US20100082615A1 (en) * | 2008-09-19 | 2010-04-01 | Xerox Corporation | Cross-media similarity measures through trans-media pseudo-relevance feedback and document reranking |
US20100228777A1 (en) * | 2009-02-20 | 2010-09-09 | Microsoft Corporation | Identifying a Discussion Topic Based on User Interest Information |
US9195739B2 (en) | 2009-02-20 | 2015-11-24 | Microsoft Technology Licensing, Llc | Identifying a discussion topic based on user interest information |
US9053115B1 (en) | 2009-04-20 | 2015-06-09 | Google Inc. | Query image search |
US20110029511A1 (en) * | 2009-07-30 | 2011-02-03 | Muralidharan Sampath Kodialam | Keyword assignment to a web page |
US8959091B2 (en) * | 2009-07-30 | 2015-02-17 | Alcatel Lucent | Keyword assignment to a web page |
US10332007B2 (en) | 2009-08-24 | 2019-06-25 | Nuix North America Inc. | Computer-implemented system and method for generating document training sets |
US20110072012A1 (en) * | 2009-09-18 | 2011-03-24 | Xerox Corporation | System and method for information seeking in a multimedia collection |
US8171049B2 (en) * | 2009-09-18 | 2012-05-01 | Xerox Corporation | System and method for information seeking in a multimedia collection |
US20120290980A1 (en) * | 2010-01-11 | 2012-11-15 | Joel Sirot | Method for navigating identifiers placed in areas and receiver implementing the method |
US9715509B2 (en) * | 2010-01-11 | 2017-07-25 | Thomson Licensing Dtv | Method for navigating identifiers placed in areas and receiver implementing the method |
US9679047B1 (en) | 2010-03-29 | 2017-06-13 | Amazon Technologies, Inc. | Context-sensitive reference works |
US8972393B1 (en) | 2010-06-30 | 2015-03-03 | Amazon Technologies, Inc. | Disambiguation of term meaning |
US9972022B2 (en) * | 2010-08-06 | 2018-05-15 | Avaya Inc. | System and method for optimizing access to a resource based on social synchrony and homophily |
US20120036446A1 (en) * | 2010-08-06 | 2012-02-09 | Avaya Inc. | System and method for optimizing access to a resource based on social synchrony and homophily |
US9449026B2 (en) * | 2010-08-31 | 2016-09-20 | Microsoft Technology Licensing, Llc | Sketch-based image search |
US20120054177A1 (en) * | 2010-08-31 | 2012-03-01 | Microsoft Corporation | Sketch-based image search |
US9384408B2 (en) | 2011-01-12 | 2016-07-05 | Yahoo! Inc. | Image analysis system and method using image recognition and text search |
US9268733B1 (en) | 2011-03-07 | 2016-02-23 | Amazon Technologies, Inc. | Dynamically selecting example passages |
US8869097B2 (en) | 2011-03-23 | 2014-10-21 | Infosys Limited | Online integrated development environment with code assist |
US20120254162A1 (en) * | 2011-03-31 | 2012-10-04 | Infosys Technologies Ltd. | Facet support, clustering for code query results |
US9348894B2 (en) * | 2011-03-31 | 2016-05-24 | Infosys Limited | Facet support, clustering for code query results |
US9009664B2 (en) | 2011-03-31 | 2015-04-14 | Infosys Limited | Structural search of source code |
US20120288841A1 (en) * | 2011-05-13 | 2012-11-15 | Xerox Corporation | Methods and systems for clustering students based on their performance |
US8768239B2 (en) * | 2011-05-13 | 2014-07-01 | Xerox Corporation | Methods and systems for clustering students based on their performance |
US8953857B2 (en) | 2011-06-30 | 2015-02-10 | Panasonic Corporation | Similar case searching apparatus and similar case searching method |
US8635519B2 (en) | 2011-08-26 | 2014-01-21 | Luminate, Inc. | System and method for sharing content based on positional tagging |
CN103797509B (en) * | 2011-09-16 | 2017-07-07 | 乐天株式会社 | Image retrieving apparatus and image search method |
US9588991B2 (en) * | 2011-09-16 | 2017-03-07 | Rakuten, Inc. | Image search device, image search method, program, and computer-readable storage medium |
US20150052139A1 (en) * | 2011-09-16 | 2015-02-19 | Rakuten, Inc. | Image search device, image search method, program, and computer-readable storage medium |
CN103797509A (en) * | 2011-09-16 | 2014-05-14 | 乐天株式会社 | Image search apparatus, image search method, program, and computer-readable recording medium |
US9245051B2 (en) | 2011-09-20 | 2016-01-26 | Nokia Technologies Oy | Method and apparatus for conducting a search based on available data modes |
US11068532B2 (en) | 2011-09-21 | 2021-07-20 | Horsetooth Ventures, LLC | Interactive image display and selection system |
US10459967B2 (en) | 2011-09-21 | 2019-10-29 | Horsetooth Ventures, LLC | Interactive image display and selection system |
US9734167B2 (en) | 2011-09-21 | 2017-08-15 | Horsetooth Ventures, LLC | Interactive image display and selection system |
US9183510B1 (en) * | 2011-10-03 | 2015-11-10 | Tastebud Technologies, Inc. | Method and system for personalized recommendation of lifestyle items |
USD737289S1 (en) | 2011-10-03 | 2015-08-25 | Yahoo! Inc. | Portion of a display screen with a graphical user interface |
USD738391S1 (en) | 2011-10-03 | 2015-09-08 | Yahoo! Inc. | Portion of a display screen with a graphical user interface |
US8737678B2 (en) | 2011-10-05 | 2014-05-27 | Luminate, Inc. | Platform for providing interactive applications on a digital content platform |
USD737290S1 (en) | 2011-10-10 | 2015-08-25 | Yahoo! Inc. | Portion of a display screen with a graphical user interface |
USD736224S1 (en) | 2011-10-10 | 2015-08-11 | Yahoo! Inc. | Portion of a display screen with a graphical user interface |
US20130132190A1 (en) * | 2011-11-17 | 2013-05-23 | Kristen Lagle Ruiz | Image tagging system and method for contextually relevant advertising |
US8903752B1 (en) * | 2012-02-09 | 2014-12-02 | Google Inc. | Classifying documents based on automatically detected rules |
US8745049B2 (en) | 2012-02-27 | 2014-06-03 | Google Inc. | Anonymous personalized recommendation method |
WO2013130616A1 (en) * | 2012-02-27 | 2013-09-06 | Google Inc. | Anonymous personalized recommendation method |
US20130226946A1 (en) * | 2012-02-27 | 2013-08-29 | Google Inc. | Anonymous personalized recommendation method |
US8521735B1 (en) * | 2012-02-27 | 2013-08-27 | Google Inc. | Anonymous personalized recommendation method |
US10078707B2 (en) | 2012-03-22 | 2018-09-18 | Oath Inc. | Digital image and content display systems and methods |
US9158747B2 (en) | 2012-03-22 | 2015-10-13 | Yahoo! Inc. | Digital image and content display systems and methods |
US8392538B1 (en) | 2012-03-22 | 2013-03-05 | Luminate, Inc. | Digital image and content display systems and methods |
US8255495B1 (en) | 2012-03-22 | 2012-08-28 | Luminate, Inc. | Digital image and content display systems and methods |
US9747305B2 (en) | 2012-03-29 | 2017-08-29 | Rakuten, Inc. | Image search device, image search method, program, and computer-readable storage medium |
US9940366B2 (en) | 2012-03-29 | 2018-04-10 | Rakuten, Inc. | Image search device, image search method, program, and computer-readable storage medium |
US8234168B1 (en) | 2012-04-19 | 2012-07-31 | Luminate, Inc. | Image content and quality assurance system and method |
US8311889B1 (en) | 2012-04-19 | 2012-11-13 | Luminate, Inc. | Image content and quality assurance system and method |
US8495489B1 (en) | 2012-05-16 | 2013-07-23 | Luminate, Inc. | System and method for creating and displaying image annotations |
US20130325600A1 (en) * | 2012-06-01 | 2013-12-05 | Luminate, Inc. | Image-Content Matching Based on Image Context and Referrer Data |
US9870516B2 (en) | 2013-05-03 | 2018-01-16 | Microsoft Technology Licensing, Llc | Hand-drawn sketch recognition |
US9147125B2 (en) | 2013-05-03 | 2015-09-29 | Microsoft Technology Licensing, Llc | Hand-drawn sketch recognition |
US20150100587A1 (en) * | 2013-10-08 | 2015-04-09 | Flipboard, Inc. | Identifying Similar Content on a Digital Magazine Server |
US10437901B2 (en) * | 2013-10-08 | 2019-10-08 | Flipboard, Inc. | Identifying similar content on a digital magazine server |
JP2016535341A (en) * | 2013-10-31 | 2016-11-10 | アルカテル−ルーセント | Media content ordering system and method for ordering media content |
EP2869213A1 (en) * | 2013-10-31 | 2015-05-06 | Alcatel Lucent | Media content ordering system and method for ordering media content |
WO2015063056A1 (en) * | 2013-10-31 | 2015-05-07 | Alcatel Lucent | Media content ordering system and method for ordering media content |
US9760369B2 (en) | 2013-12-13 | 2017-09-12 | Infosys Limited | Assessing modularity of a program written in object oriented language |
US11157577B2 (en) | 2014-05-23 | 2021-10-26 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US11080350B2 (en) | 2014-05-23 | 2021-08-03 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US11734370B2 (en) | 2014-05-23 | 2023-08-22 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US11314826B2 (en) | 2014-05-23 | 2022-04-26 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US10223466B2 (en) | 2014-05-23 | 2019-03-05 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US9990433B2 (en) | 2014-05-23 | 2018-06-05 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US10185725B1 (en) | 2014-06-17 | 2019-01-22 | Google Llc | Image annotation based on label consensus |
US10013436B1 (en) | 2014-06-17 | 2018-07-03 | Google Llc | Image annotation based on label consensus |
US10318590B2 (en) * | 2014-08-15 | 2019-06-11 | Feeedom Solutions Group, Llc | User interface operation based on token frequency of use in text |
US20160048512A1 (en) * | 2014-08-15 | 2016-02-18 | Freedom Solutions Group, LLC d/b/a/ Microsystems | User Interface Operation Based on Token Frequency of Use in Text |
US10061765B2 (en) | 2014-08-15 | 2018-08-28 | Freedom Solutions Group, Llc | User interface operation based on similar spelling of tokens in text |
US10007717B2 (en) * | 2014-09-18 | 2018-06-26 | Google Llc | Clustering communications based on classification |
US20160314182A1 (en) * | 2014-09-18 | 2016-10-27 | Google, Inc. | Clustering communications based on classification |
US11068546B2 (en) | 2016-06-02 | 2021-07-20 | Nuix North America Inc. | Computer-implemented system and method for analyzing clusters of coded documents |
US11238078B2 (en) * | 2016-08-22 | 2022-02-01 | International Business Machines Corporation | Creation of a summary for a plurality of texts |
US20220100787A1 (en) * | 2016-08-22 | 2022-03-31 | International Business Machines Corporation | Creation of a summary for a plurality of texts |
US10430450B2 (en) * | 2016-08-22 | 2019-10-01 | International Business Machines Corporation | Creation of a summary for a plurality of texts |
US11762893B2 (en) * | 2016-08-22 | 2023-09-19 | International Business Machines Corporation | Creation of a summary for a plurality of texts |
CN111783808A (en) * | 2019-07-23 | 2020-10-16 | 北京沃东天骏信息技术有限公司 | Method and apparatus for generating information |
US11256395B2 (en) * | 2019-10-31 | 2022-02-22 | Tweddle Group | Systems and methods for transforming user interfaces based on database interactions |
CN112861944A (en) * | 2021-01-28 | 2021-05-28 | 中山大学 | Image retrieval method and device based on mixed modal input |
CN112861944B (en) * | 2021-01-28 | 2022-09-23 | 中山大学 | Image retrieval method and device based on mixed modal input |
US20220382424A1 (en) * | 2021-05-26 | 2022-12-01 | Intuit Inc. | Smart navigation |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6728752B1 (en) | System and method for information browsing using multi-modal features | |
US6567797B1 (en) | System and method for providing recommendations based on multi-modal user clusters | |
US6941321B2 (en) | System and method for identifying similarities among objects in a collection | |
US6922699B2 (en) | System and method for quantitatively representing data objects in vector space | |
US6564202B1 (en) | System and method for visually representing the contents of a multiple data object cluster | |
US6598054B2 (en) | System and method for clustering data objects in a collection | |
EP1024437B1 (en) | Multi-modal information access | |
EP1202187B1 (en) | Image retrieval system and methods with semantic and feature based relevance feedback | |
US7502785B2 (en) | Extracting semantic attributes | |
US7624130B2 (en) | System and method for exploring a semantic file network | |
US7634471B2 (en) | Adaptive grouping in a file network | |
US9008446B2 (en) | Interactive concept learning in image search | |
US7523095B2 (en) | System and method for generating refinement categories for a set of search results | |
Tekli | An overview of cluster-based image search result organization: background, techniques, and ongoing challenges | |
Chen et al. | Multimodal browsing of images in web documents | |
Zhang et al. | An integrated system for building enterprise taxonomies | |
Liu et al. | Clustering-based navigation of image search results on mobile devices | |
Wen et al. | A search engine for images | |
Wulfekuhler | Personalized information discovery from unstructured text |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: XEROX CORPORATION, CONNECTICUTFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:CHEN, FRANCINE R.;SCHUETZE, HINRICH;GARGI, ULLAS;REEL/FRAME:010587/0860;SIGNING DATES FROM 20000112 TO 20000115 |
|
AS | Assignment |
Owner name: BANK ONE, NA, AS ADMINISTRATIVE AGENT, ILLINOISFree format text: SECURITY AGREEMENT;ASSIGNOR:XEROX CORPORATION;REEL/FRAME:013111/0001Effective date: 20020621Owner name: BANK ONE, NA, AS ADMINISTRATIVE AGENT,ILLINOISFree format text: SECURITY AGREEMENT;ASSIGNOR:XEROX CORPORATION;REEL/FRAME:013111/0001Effective date: 20020621 |
|
AS | Assignment |
Owner name: JPMORGAN CHASE BANK, AS COLLATERAL AGENT, TEXASFree format text: SECURITY AGREEMENT;ASSIGNOR:XEROX CORPORATION;REEL/FRAME:015134/0476Effective date: 20030625Owner name: JPMORGAN CHASE BANK, AS COLLATERAL AGENT,TEXASFree format text: SECURITY AGREEMENT;ASSIGNOR:XEROX CORPORATION;REEL/FRAME:015134/0476Effective date: 20030625 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: XEROX CORPORATION, NEW YORKFree format text: RELEASE BY SECURED PARTY;ASSIGNOR:BANK ONE, NA;REEL/FRAME:026957/0914Effective date: 20030625Owner name: XEROX CORPORATION, NEW YORKFree format text: RELEASE BY SECURED PARTY;ASSIGNOR:JPMORGAN CHASE BANK, N.A.;REEL/FRAME:026958/0463Effective date: 20061204 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:XEROX CORPORATION;REEL/FRAME:027728/0811Effective date: 20111110 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044127/0735Effective date: 20170929 |
|
AS | Assignment |
Owner name: XEROX CORPORATION, CONNECTICUTFree format text: RELEASE BY SECURED PARTY;ASSIGNOR:JPMORGAN CHASE BANK, N.A. AS SUCCESSOR-IN-INTEREST ADMINISTRATIVE AGENT AND COLLATERAL AGENT TO BANK ONE, N.A.;REEL/FRAME:061388/0388Effective date: 20220822Owner name: XEROX CORPORATION, CONNECTICUTFree format text: RELEASE BY SECURED PARTY;ASSIGNOR:JPMORGAN CHASE BANK, N.A. AS SUCCESSOR-IN-INTEREST ADMINISTRATIVE AGENT AND COLLATERAL AGENT TO JPMORGAN CHASE BANK;REEL/FRAME:066728/0193Effective date: 20220822 |