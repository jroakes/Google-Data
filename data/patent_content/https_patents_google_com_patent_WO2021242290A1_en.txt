WO2021242290A1 - Methods for aggregating credit across interactions - Google Patents
Methods for aggregating credit across interactions Download PDFInfo
- Publication number
- WO2021242290A1 WO2021242290A1 PCT/US2020/047643 US2020047643W WO2021242290A1 WO 2021242290 A1 WO2021242290 A1 WO 2021242290A1 US 2020047643 W US2020047643 W US 2020047643W WO 2021242290 A1 WO2021242290 A1 WO 2021242290A1
- Authority
- WO
- WIPO (PCT)
- Prior art keywords
- encrypted
- identifiers
- computing system
- encryption
- data
- Prior art date
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
- G06F21/6254—Protecting personal data, e.g. for financial or medical purposes by anonymising data, e.g. decorrelating personal data from the owner's identification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/10—Office automation; Time management
- G06Q10/101—Collaborative creation, e.g. joint development of products or services
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0201—Market modelling; Market analysis; Collecting market data
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/008—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols involving homomorphic encryption
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/06—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols the encryption apparatus using shift registers or memories for block-wise or stream coding, e.g. DES systems or RC4; Hash functions; Pseudorandom sequence generators
- H04L9/0643—Hash functions, e.g. MD5, SHA, HMAC or f9 MAC
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/06—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols the encryption apparatus using shift registers or memories for block-wise or stream coding, e.g. DES systems or RC4; Hash functions; Pseudorandom sequence generators
- H04L9/065—Encryption by serially and continuously modifying data stream elements, e.g. stream cipher systems, RC4, SEAL or A5/3
- H04L9/0656—Pseudorandom key sequence combined element-for-element with data sequence, e.g. one-time-pad [OTP] or Vernam's cipher
- H04L9/0662—Pseudorandom key sequence combined element-for-element with data sequence, e.g. one-time-pad [OTP] or Vernam's cipher with particular pseudorandom sequence generator
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/30—Public key, i.e. encryption algorithm being computationally infeasible to invert or user's encryption keys not requiring secrecy
- H04L9/3066—Public key, i.e. encryption algorithm being computationally infeasible to invert or user's encryption keys not requiring secrecy involving algebraic varieties, e.g. elliptic or hyper-elliptic curves
Definitions
- One implementation of the disclosure relates to a method including receiving, at a first computing system, encrypted identifiers and encrypted values, performing, by the first computing system, a concealing operation on the encrypted identifiers to produce concealed encrypted identifiers, wherein the concealing operation conceals the encrypted identifiers from the first computing system and a second computing system but enables matching between the concealed encrypted identifiers, decrypting, by the second computing system, the concealed encrypted identifiers to produce concealed identifiers, and performing, by the second computing system, an aggregation operation using the concealed identifiers and the encrypted values to produce an encrypted aggregate value without accessing personal information associated with the encrypted values.
- performing the concealing operation includes removing a first portion of first encryption from the encrypted identifiers to produce partially encrypted identifiers, and deterministically encrypting the partially encrypted identifiers with second encryption to produce the concealed encrypted identifiers.
- decrypting the concealed encrypted identifiers includes removing a second portion of the first encryption from the concealed encrypted identifiers to produce concealed identifiers.
- the method further includes decrypting, by a third computing system, the encrypted aggregate value to produce an aggregate value.
- the method further includes cooperatively generating by the first computing system and the second computing system a first encryption key, generating by the first computing system a second encryption key associated with the first encryption key and a third encryption key, generating by the second computing system a fourth encryption key associated with the first encryption key, and generating by the third computing system a fifth and sixth encryption key.
- the encrypted identifiers are encrypted using the first encryption key and the encrypted values are encrypted using the fifth encryption key, wherein the concealing operation uses the second and third encryption keys, wherein the concealed encrypted identifiers are decrypted using the fourth encryption key, and wherein the encrypted aggregate value is decrypted using the sixth encryption key.
- the concealing operation includes shuffling the encrypted identifiers and rerandomizing the encrypted values by generating a ciphertext using a hash function.
- the third computing system is part of the first computing system. In some implementations, at least one of the first computing system or the third computing system is a distributed computing system.
- the method further includes generating, by the second computing system, a random value, performing, by the second computing system, an operation using the random value and the encrypted aggregate value to produce a result, and sending, by the second computing system, the random value to a content publisher associated with the encrypted identifiers.
- the aggregation operation includes performing a weighting function using the concealed identifiers and time values associated with the concealed identifiers to produce the encrypted aggregate value.
- Another implementation of the disclosure relates to an outcome measurement system including a first computing system configured to receive encrypted identifiers and encrypted values, and perform a concealing operation on the encrypted identifiers to produce concealed encrypted identifiers, wherein the concealing operation conceals the encrypted identifiers from the first computing system and a second computing system but enables matching between the concealed encrypted identifiers, and the second computing system configured to decrypt the concealed encrypted identifiers to produce concealed identifiers, and perform an aggregation operation using the concealed identifiers and the encrypted values to produce an encrypted aggregate value without accessing personally identifiable information associated with the encrypted values.
- performing the concealing operation includes removing a first portion of first encryption from the encrypted identifiers to produce partially encrypted identifiers, and deterministically encrypting the partially encrypted identifiers with second encryption to produce the concealed encrypted identifiers.
- decrypting the concealed encrypted identifiers includes removing a second portion of the first encryption from the concealed encrypted identifiers to produce concealed identifiers.
- the outcome measurement system further includes a third computing system configured to decrypt the encrypted aggregate value to produce an aggregate value.
- the first and second computing systems are further configured to cooperatively generate a first encryption key, wherein the first computing system is further configured to generate a second encryption key associated with the first encryption key and a third encryption key, wherein the second computing system is further configured to generate a fourth encryption key associated with the first encryption key, and wherein the third computing system is further configured to generate a fifth and sixth encryption key.
- the encrypted identifiers are encrypted using the first encryption key and the encrypted values are encrypted using the fifth encryption key, wherein the concealing operation uses the second and third encryption keys, wherein the concealed encrypted identifiers are decrypted using the fourth encryption key, and wherein the encrypted aggregate value is decrypted using the sixth encryption key.
- the third computing system is part of the first computing system. In some implementations, at least one of the first computing system or the third computing system is a distributed computing system.
- the aggregation operation includes performing a weighting function using the concealed identifiers and time values associated with the concealed identifiers to produce the encrypted aggregate value.
- Another implementation of the disclosure relates to one or more computer-readable storage media having instructions stored thereon that, upon execution by one or more processors of at least one of a first computing system and a second computing system cause the first computing system to receive encrypted identifiers and encrypted values, and perform a concealing operation on the encrypted identifiers to produce concealed encrypted identifiers, wherein the concealing operation conceals the encrypted identifiers from the first computing system and a second computing system but enables matching between the concealed encrypted identifiers, and cause the second computing system to decrypt the concealed encrypted identifiers to produce concealed identifiers, and perform an aggregation operation using the concealed identifiers and the encrypted values to produce an encrypted aggregate value without accessing personally identifiable information associated with the encrypted values.
- performing the concealing operation includes removing a first portion of first encryption from the encrypted identifiers to produce partially encrypted identifiers, and deterministically encrypting the partially encrypted identifiers with second encryption to produce the concealed encrypted identifiers.
- decrypting the concealed encrypted identifiers includes removing a second portion of the first encryption from the concealed encrypted identifiers to produce concealed identifiers.
- the instructions are further configured to, upon execution by one or more processors of a third computing system, cause the third computing system to decrypt the encrypted aggregate value to produce an aggregate value.
- the instructions are configured to cause the first and second computing systems to cooperatively generate a first encryption key, wherein the instructions are configured to cause the first computing system to generate a second encryption key associated with the first encryption key and a third encryption key, wherein the instructions are configured to cause the second computing system to generate a fourth encryption key associated with the first encryption key, and wherein the instructions are configured to cause the third computing system to generate a fifth and sixth encryption key.
- the encrypted identifiers are encrypted using the first encryption key and the encrypted values are encrypted using the fifth encryption key, wherein the concealing operation uses the second and third encryption keys, wherein the concealed encrypted identifiers are decrypted using the fourth encryption key, and wherein the encrypted aggregate value is decrypted using the sixth encryption key.
- the third computing system is part of the first computing system.
- At least one of the first computing system or the third computing system is a distributed computing system.
- the aggregation operation includes performing a weighting function using the concealed identifiers and time values associated with the concealed identifiers to produce the encrypted aggregate value.
- FIGS. 1A-1B are a diagram illustrating various entities interacting over a network, according to an illustrative implementation.
- FIG. 2 is a diagram illustrating data transfer and aggregation using the outcome measurement system of FIG. 1 A, according to an implementation.
- FIG. 3 A is a flow diagram illustrating a method of key generation for the first data processing system of FIG. 1A, according to an illustrative implementation.
- FIG. 3B is a flow diagram illustrating a method of key generation for the second data processing system of FIG. 1 A, according to an illustrative implementation.
- FIG. 3C is a flow diagram illustrating a method of key generation for the third data processing system of FIG. 1A, according to an illustrative implementation.
- FIG. 3D is a flow diagram illustrating a method of key generation for the publisher computing system of FIG. IB, according to an illustrative implementation.
- FIGS. 4A-4B is a flow diagram illustrating a method of secure transfer and aggregation of credit for interactions according to the system of FIGS. 1 A-1B, according to an illustrative implementation.
- FIG. 5 is a flow diagram illustrating a method of performing the aggregation operation of FIG. 4B, according to an illustrative implementation.
- FIG. 6 is a diagram illustrating data set manipulation according to the aggregation operation of FIG. 5, according to an illustrative implementation.
- FIG. 7 is another diagram illustrating data set manipulation according to the aggregation operation of FIG. 5, according to an illustrative implementation.
- FIG. 8 is another diagram illustrating data set manipulation according to the aggregation operation of FIG. 5, according to an illustrative implementation.
- FIG. 9 is a diagram illustrating generation of Shapley values according to the aggregation operation of FIG. 5, according to an illustrative implementation.
- FIG. 10 is a diagram illustrating generation of a Markov Model according to the aggregation operation of FIG. 5, according to an illustrative implementation.
- FIG. 11 is a flow diagram illustrating a method of performing the masking operation of FIG. 4B, according to an illustrative implementation.
- FIG. 12 is a block diagram of a computing system, according to an illustrative implementation.
- a number of content publishers may display a number of content items that a user views before performing an online interaction, and it may be desirable to determine the number of online interactions associated with each content publisher’s content items (e.g., how many users viewed a particular content item before performing the online interaction).
- System and methods of the present disclosure relate generally to aggregating a number of interactions associated with a content item and distributing credit between a number of content publishers and/or interaction pathways associated with the content item. More specifically, systems and methods of the present disclosure relate to unique cryptography and computer architecture methodologies to aggregate data from different entities and distribute credit between the entities in a more secure way.
- aggregating data from different entities requires a computing system to have access to user specific data. For example, a system may determine an aggregate count by summing values having matching user identifiers. To avoid revealing personal information, the identity of the user must be hidden and suitably protected when generating and reporting the data.
- the encryption methods and architectures may be used to correlate online interactions with data from content publishers in a secure way, while providing increased security and also conserving user privacy.
- a second data processing system may produce a first public key for asymmetric encryption.
- a publisher computing system may encrypt first user identifiers using the first public key.
- a third data processing system may produce a second public key for homomorphic encryption.
- An interaction data provider computing system may encrypt second user identifiers using the first public key and associated values with the second public key.
- a first data processing system may receive, from a number of content publishers (e.g., publisher computing system, etc.), a number of encrypted first user identifiers.
- the first data processing system may receive, from one or more interaction data providers (e.g., interaction data provider computing system, etc.), a number of encrypted second user identifiers and associated encrypted values.
- the first data processing system may generate a secret key for elliptic curve encryption and may encrypt the encrypted first and second user identifiers with the secret key to produce double-encrypted first and second user identifiers.
- the first data processing system may send the double-encrypted first and second user identifiers and the associated encrypted values to the second data processing system which may decrypt the double-encrypted first and second user identifiers to produce elliptic curve (EC) encrypted first and second user identifiers.
- EC elliptic curve
- the second data processing system may join the EC encrypted first and second user identifiers and compute an encrypted aggregate value associated with each content publisher based on the joined EC encrypted first and second user identifiers.
- the second data processing system may send the encrypted aggregate value to the third data processing system which may decrypt the encrypted aggregate value to recover an aggregate value associated with each content publisher. Therefore, the outcome measurement system (e.g., first, second, and third data processing systems, etc.) may facilitate aggregation of interaction data without revealing personal information.
- a user may be provided with controls allowing the user to make an election as to both if and when systems, programs, or features described herein may enable collection of user information (e.g., information about a user’s social network, social actions, or activities, profession, a user’s preferences, or a user’s current location), and if the user is sent content or communications from a server.
- user information e.g., information about a user’s social network, social actions, or activities, profession, a user’s preferences, or a user’s current location
- certain data may be treated in one or more ways before it is stored or used, so that personally identifiable information is removed.
- a user’s identity may be treated so that no personal information, or only certain personal information, can be determined for the user, or a user’s geographic location may be generalized where location information is obtained (such as to a city, ZIP code, or state level), so that a particular location of a user cannot be determined.
- location information such as to a city, ZIP code, or state level
- the user may have control over what information is collected about the user, how that information is used, and what information is provided to the user.
- System 100 for securely aggregating data from different entities is shown, according to an illustrative implementation.
- System 100 includes outcome measurement service 102, publisher computing system 10, and interaction data provider computing system 30.
- outcome measurement service 102 includes first data processing system 200, second data processing system 300, and third data processing system 400.
- components of system 100 communicate over network 60.
- Network 60 may include computer networks such as the Internet, local, wide, metro or other area networks, intranets, satellite networks, other computer networks such as voice or data mobile phone communication networks, combinations thereof, or any other type of electronic communications network.
- Network 60 may include or constitute a display network (e.g., a subset of information resources available on the Internet that are associated with a content placement or search engine results system, or that are eligible to include third party content items as part of a content item placement campaign).
- network 60 facilitates secure communication between components of system 100.
- network 60 may implement transport layer security (TLS), secure sockets layer (SSL), hypertext transfer protocol secure (HTTPS), and/or any other secure communication protocol.
- Publisher computing system 10 may host publisher data such as user identifiers.
- publisher computing system 10 is associated with a publisher (e.g., an online publisher, etc.).
- the publisher data is associated with user interactions with publisher content.
- the publisher data may include user identifiers and timestamps associated with users that interacted with publisher content.
- the publisher data includes a count of user interactions.
- the publisher data includes an interaction classification.
- the publisher data may include an interaction classification indicating whether a user viewed a content item or interacted with a content item (e.g., clicked on a content item, etc.).
- the publisher content may be marketing items (e.g., advertisements) associated with a third party.
- Publisher computing system 10 may include database 12 and processing circuit 14.
- Database 12 may store publisher data. For example, upon serving a publisher content item to a client device, publisher computing system 10 may store a user identifier associated with a user in database 12. The user identifier may be used later for correlation of anonymous interaction data.
- Database 12 may include one or more storage mediums. The storage mediums may include but are not limited to magnetic storage, optical storage, flash storage, and/or RAM.
- Publisher computing system 10 may implement or facilitate various APIs to perform database functions (i.e., managing data stored in database 12). The APIs can be but are not limited to SQL, ODBC, JDBC, and/or any other data storage and manipulation API.
- Processing circuit 14 includes processor 16 and memory 18.
- Memory 18 may have instructions stored thereon that, when executed by processor 16, cause processing circuit 14 to perform the various operations described herein. The operations described herein may be implemented using software, hardware, or a combination thereof.
- Processor 16 may include a microprocessor, ASIC, FPGA, etc., or combinations thereof. In many implementations, processor 16 may be a multi-core processor or an array of processors.
- Processor 16 may implement or facilitate secure environments. For example, processor 16 may implement software guard extensions (SGX) to define private regions (e.g., enclaves) in memory 18.
- Memory 18 may include, but is not limited to, electronic, optical, magnetic, or any other storage devices capable of providing processor 16 with program instructions.
- Memory 18 may include a floppy disk, CD-ROM, DVD, magnetic disk, memory chip, ROM, RAM, EEPROM, EPROM, flash memory, optical media, or any other suitable memory from which processor 16 can read instructions.
- the instructions may include code from any suitable computer programming language such as, but not limited to, C, C++, C#, Java, JavaScript, Perl, HTML, XML, Python and Visual Basic.
- Memory 18 may include first encryption circuit 20, second encryption circuit 22, and decryption circuit 24.
- circuits 20, 22, and 24 may be implemented using computer or machine-readable instructions stored within memory 18.
- circuits 20, 22, and 24 may be discrete hardware circuits or may be implemented using a combination of hardware and software.
- First encryption circuit 20 may implement one or more encryption functions on input data to produce encrypted data.
- first encryption circuit 20 implements an asymmetric encryption function.
- first encryption circuit 20 implements an ElGamal (EG) encryption protocol.
- first encryption circuit 20 may encrypt user identifiers with an EG public key received from second data processing system 300.
- first encryption circuit 20 implements commutative encryption.
- first encryption circuit 20 may implement EG encryption that facilitates double- encrypted values (e.g., a single value encrypted with two different encryption schemes).
- first encryption circuit facilitates randomized encryption.
- first encryption circuit 20 may encrypt a first value using a first key to produce a first encrypted result and may encrypt the first value again using the first key to produce a second encrypted result that is different than the first encrypted result (e.g., produces different ciphertexts).
- first encryption circuit 20 facilitates rerandomization.
- Second encryption circuit 22 may implement one or more encryption functions on input data to produce encrypted data.
- second encryption circuit 22 implements an asymmetric encryption function.
- second encryption circuit 22 generates encryption keys.
- second encryption circuit 22 may generate a public key and a secret key.
- second encryption circuit 22 shares the encryption keys with other components of system 100 (e.g., second data processing system 300, etc.).
- second encryption circuit 22 may generate a public key and send the public key to second data processing system 300.
- second encryption circuit 22 implements commutative encryption as described above in reference to first encryption circuit 20.
- Decryption circuit 24 may receive encrypted data and decrypt it to produce unencrypted data.
- decryption circuit 24 receives encrypted data from third data processing system 400. Decryption circuit 24 may decrypt asymmetrically encrypted data. Additionally or alternatively, decryption circuit 24 may decrypt symmetric and/or threshold encrypted data. In various implementations, decryption circuit 24 receives one or more secrets (e.g., secret keys, etc.) from second encryption circuit 22. For example, decryption circuit 24 may receive a secret key from second encryption circuit 22 and use the secret key to decrypt encrypted data received from third data processing system 400.
- secrets e.g., secret keys, etc.
- Interaction data provider computing system 30 may host interaction data such as user identifiers and/or values.
- interaction data provider computing system 30 is associated with an interaction data provider (e.g., a merchant, an interaction data clearinghouse, etc.).
- the interaction data is associated with user commercial activity (e.g., purchases, etc.).
- the interaction data may include user identifiers of users that performed an online transaction.
- the interaction data may include a timestamp and/or value associated with the interaction.
- the interaction data includes an interaction classification.
- the interaction data may include an interaction classification indicating a type of interaction (e.g., a website visit, a purchase, etc.).
- the interaction data may be associated with the publisher data described in reference to publisher computing system 10.
- the interaction data may include user identifiers that overlap with a portion of the user identifiers in the publisher data.
- Interaction data provider computing system 30 may include database 32 and processing circuit 34.
- Database 32 may store interaction data. For example, upon detecting a user interaction, interaction data provider computing system 30 may store a user identifier associated with a user in database 32. The user identifier may be used later for correlation of anonymous interaction data.
- Database 32 may include one or more storage mediums. The storage mediums may include but are not limited to magnetic storage, optical storage, flash storage, and/or RAM.
- Interaction data provider computing system 30 may implement or facilitate various APIs to perform database functions (i.e., managing data stored in database 32). The APIs can be but are not limited to SQL, ODBC, JDBC, and/or any other data storage and manipulation API.
- Processing circuit 34 includes processor 36 and memory 38.
- Memory 38 may have instructions stored thereon that, when executed by processor 36, cause processing circuit 34 to perform the various operations described herein.
- the operations described herein may be implemented using software, hardware, or a combination thereof.
- Processor 36 may include a microprocessor, ASIC, FPGA, etc., or combinations thereof.
- processor 16 may be a multi-core processor or an array of processors.
- Processor 36 may implement or facilitate secure environments as described above.
- Memory 38 may include, but is not limited to, electronic, optical, magnetic, or any other storage devices capable of providing processor 36 with program instructions.
- Memory 38 may include a floppy disk, CD-ROM, DVD, magnetic disk, memory chip, ROM, RAM, EEPROM, EPROM, flash memory, optical media, or any other suitable memory from which processor 16 can read instructions.
- the instructions may include code from any suitable computer programming language such as, but not limited to, C, C++, C#, Java, JavaScript, Perl, HTML, XML,
- Memory 38 may include first encryption circuit 40 and second encryption circuit 42.
- First encryption circuit 40 may implement one or more encryption functions on input data to produce encrypted data.
- first encryption circuit 40 implements an asymmetric encryption function.
- first encryption circuit 40 implements (EG) encryption.
- first encryption circuit 40 may encrypt user identifiers with an EG public key received from second data processing system 300.
- first encryption circuit 40 facilitates various cryptographic functions (e.g., commutativity, rerandomization, etc.) as described in reference to first encryption circuit 20.
- Second encryption circuit 42 may implement one or more encryption functions on input data to produce encrypted data.
- second encryption circuit 42 implements an asymmetric encryption function.
- second encryption circuit 42 may implement a homomorphic cryptosystem.
- second encryption circuit 42 implements an additive encryption function.
- second encryption circuit 42 may implement Additive Homomorphic Encryption (AHE).
- AHE Additive Homomorphic Encryption
- second encryption circuit 42 implements an Exponential ElGamal (EEG) protocol.
- second encryption circuit 42 may implement a Paillier cryptosystem and/or Ring-LWE based encryption.
- second encryption circuit 42 implements a symmetric encryption function.
- second encryption circuit 42 encrypts values with an AHE public key received from third data processing system 400.
- second encryption circuit 42 facilitates homomorphic scalar multiplication.
- second encryption circuit 42 facilitates various cryptographic functions (e.g., commutativity, rerandomization, etc.) as described in reference to first encryption circuit 20.
- first data processing system 200 may facilitate processing of publisher data and/or interaction data.
- first data processing system 200 receives data and processes the data to produce processed data (e.g., data without or with less personal information, etc.).
- first data processing system 200 produces differentially-private data.
- first data processing system 200 generates encryption keys.
- first data processing system 200 may collaboratively generate an EG public key with second data processing system 300.
- First data processing system 200 may be a server, distributed processing cluster, cloud processing system, or any other computing device.
- First data processing system 200 may include or execute at least one computer program or at least one script.
- first data processing system 200 includes combinations of software and hardware, such as one or more processors configured to execute one or more scripts.
- First data processing system 200 is shown to include database 210 and processing circuit 220.
- Database 210 may store data received from publisher computing system 10 and/or interaction data provider computing system 30.
- database 210 may store encrypted first identifiers from publisher computing system 10 and/or encrypted second identifiers and/or encrypted values from interaction data provider computing system 30.
- Database 210 may include various storage mediums as described with reference to database 12 and 32.
- Processing circuit 220 includes processor 230 and memory 240.
- Memory 240 may have instructions stored thereon that, when executed by processor 230, cause processing circuit 220 to perform the various operations described herein.
- Processing circuit 220, processor 230, and/or memory 240 may be similar to processing circuit 14 and 34, processor 16 and 36, and/or memory 18 and 38 as described above.
- Memory 240 may include first encryption circuit 242, second encryption circuit 244, decryption circuit 246, and randomization circuit 248.
- First encryption circuit 242 may implement one or more encryption functions on input data to produce encrypted data.
- first encryption circuit 242 implements an asymmetric encryption function (e.g., EG, etc.).
- first encryption circuit 242 implements EG encryption over an elliptic curve.
- first encryption circuit 242 may implement EG encryption over an elliptic curve used by second encryption circuit 244 to implement EC encryption.
- first encryption circuit 242 generates encryption keys.
- first encryption circuit 242 may generate a public key and a secret key.
- first encryption circuit 242 collaboratively generates an EG public key with second data processing system 300.
- first encryption circuit 242 shares the encryption keys (or a portion thereof) with other components of system 100 (e.g., publisher computing system 10, interaction data provider computing system 30, etc.). For example, first encryption circuit 242 may collaboratively generate an EG public key with second data processing system 300 and send the EG public key to publisher computing system 10 and/or interaction data provider computing system 30. In various implementations, first encryption circuit 242 facilitates various cryptographic functions (e.g., commutativity, rerandomization, etc.) as described in reference to first encryption circuit 20.
- various cryptographic functions e.g., commutativity, rerandomization, etc.
- Second encryption circuit 244 may implement one or more encryption functions on input data to produce encrypted data.
- second encryption circuit 244 implements a symmetric encryption function.
- second encryption circuit 244 may implement Elliptic Curve (EC) encryption.
- second encryption circuit 244 may implement any cryptosystem where the Decisional Diffie- Hellman (DDH) problem is presumed to be computationally intractable, such that the multiplicative group of quadratic residues modulo a safe prime number.
- DDH Decisional Diffie- Hellman
- second encryption circuit 244 implements an asymmetric encryption function.
- second encryption circuit 244 generates an encryption key.
- second encryption circuit 244 may generate an EC secret key.
- second encryption circuit 244 collaboratively generates a number of EC secret keys with other second encryption circuits 244 (e.g., for collaborative encryption, etc.). In various implementations, second encryption circuit 244 encrypts identifiers with an EC secret key. In various implementations, second encryption circuit 244 implements deterministic encryption. For example, second encryption circuit 244 may encrypt a first value with a first key to produce a first encrypted result and may encrypt the first value again with the first key to produce a second encrypted result that is the same as the first encrypted result. In various implementations, second encryption circuit 244 facilitates generating encrypted data that may be compared for equality (e.g., compare two values encrypted with the same key, etc.).
- second encryption circuit 244 facilitates various cryptographic functions (e.g., commutativity, rerandomization, etc.) as described in reference to first encryption circuit 20.
- second encryption circuit 244 facilitates collaborative encryption. For example, a number of second encryption circuits 244 may work together to encrypt a data item (e.g., each adding a portion of encryption, etc.).
- Decryption circuit 246 may receive encrypted data and decrypt it to produce unencrypted data.
- decryption circuit 246 receives encrypted data from publisher computing system 10 and/or interaction data provider computing system 30.
- decryption circuit 246 may receive encrypted first identifiers from publisher computing system 10 and/or encrypted second identifiers from interaction data provider computing system 30.
- Decryption circuit 246 may decrypt asymmetrically encrypted data. Additionally or alternatively, decryption circuit 246 may decrypt symmetric and/or threshold encrypted data.
- decryption circuit 246 receives one or more secrets (e.g., secret keys, etc.) from first encryption circuit 242.
- secrets e.g., secret keys, etc.
- decryption circuit 246 may receive a secret key (e.g., an EG secret key, etc.) from first encryption circuit 242 and use the secret key to at least partially decrypt encrypted data received from publisher computing system 10 and/or interaction data provider computing system 30.
- a secret key e.g., an EG secret key, etc.
- Randomization circuit 248 may receive data and perform various randomization functions to produce randomized data.
- randomization circuit 248 may facilitate removing implicit/indirect identifiers (e.g., arrival time, order, originating IP address, etc.), performing batching operations, introducing noise, and/or performing any other anonymizing operation.
- randomization circuit 248 shuffles (e.g., rearranges, changes an order of, etc.) received data to produce shuffled data.
- randomization circuit 248 implements one or more hashing functions on input data to produce hashed data. For example, randomization circuit 248 may implement SHA-2, Scrypt, Balloon, and/or Argon2 hashing functions.
- randomization circuit 248 facilitates rerandomizing ciphertexts by applying subsequent rounds of encryption. For example, randomization circuit 248 may rerandomize an EG encrypted value by encrypting the EG encrypted value a second time with the same key used to encrypt the EG encrypted value the first time.
- Second data processing system 300 may facilitate securely correlating data from different entities.
- second data processing system 300 receives encrypted publisher data and/or encrypted interaction data and processes the received data to generate aggregate interaction data (e.g., aggregate values, etc.).
- aggregate interaction data e.g., aggregate values, etc.
- second data processing system 300 may perform an aggregation operation to join user identifiers, determine an aggregate value associated with an interaction, and distribute credit among various publishers.
- Second data processing system 300 may include or execute at least one computer program or at least one script.
- second data processing system 300 includes combinations of software and hardware, such as one or more processors configured to execute one or more scripts.
- Second data processing system 300 is shown to include processing circuit 310 having processor 320 and memory 330.
- Memory 330 may have instructions stored thereon that, when executed by processor 320, cause processing circuit 310 to perform the various operations described herein.
- Processing circuit 310, processor 320, and/or memory 330 may be similar to processing circuit 14 and 34, processor 16 and 36, and/or memory 18 and 38 as described above.
- Memory 330 may include first encryption circuit 332, second encryption circuit 334, decryption circuit 336, and analysis circuit 338.
- First encryption circuit 332 may implement one or more encryption functions on input data to produce encrypted data.
- first encryption circuit 332 implements an asymmetric encryption function (e.g., EG, etc.).
- first encryption circuit 332 implements EG encryption over an elliptic curve.
- first encryption circuit 332 may implement EG encryption over an elliptic curve used by second encryption circuit 244 to implement EC encryption.
- first encryption circuit 332 is similar to first encryption circuit 242.
- first encryption circuit 332 generates encryption keys.
- first encryption circuit 332 may generate a public key (e.g., an EG public key) and a secret key (e.g., an EG secret key).
- first encryption circuit 332 collaboratively generates an EG public key with first data processing system 200. In some implementations, first encryption circuit 332 shares the encryption keys (or a portion thereof) with other components of system 100 (e.g., publisher computing system 10, interaction data provider computing system 30, etc.). In various implementations, first encryption circuit 332 facilitates various cryptographic functions (e.g., commutativity, rerandomization, etc.) as described in reference to first encryption circuit 20
- Second encryption circuit 334 may implement one or more encryption functions on input data to produce encrypted data.
- second encryption circuit 334 implements an asymmetric encryption function.
- second encryption circuit 334 may implement a Rivest-Shamir-Adleman (RSA) cryptosystem.
- RSA Rivest-Shamir-Adleman
- second encryption circuit 334 may encrypt a random value with a public key received from publisher computing system 10.
- second encryption circuit 334 implements a masking operation.
- second encryption circuit 334 may mask an encrypted aggregate value to produce an encrypted masked aggregate value. The masking operation is described in more detail with reference to FIG.
- Decryption circuit 336 may receive encrypted data and decrypt it to produce unencrypted data.
- decryption circuit 336 receives encrypted data from first data processing system 200.
- decryption circuit 336 may receive encrypted first and second identifiers from first data processing system 200.
- Decryption circuit 336 may decrypt asymmetrically encrypted data. Additionally or alternatively, decryption circuit 336 may decrypt symmetric and/or threshold encrypted data.
- decryption circuit 336 receives one or more secrets (e.g., secret keys, etc.) from first encryption circuit 332.
- decryption circuit 336 may receive a secret key (e.g., an EG secret key, etc.) from first encryption circuit 332 and use the secret key to at least partially decrypt encrypted data received from first data processing system 200.
- secret key e.g., an EG secret key, etc.
- Analysis circuit 338 may receive anonymous (e.g., encrypted, etc.) publisher data and/or interaction data and produce aggregate interaction data (e.g., aggregate values, etc.).
- anonymous e.g., encrypted, etc.
- interaction data e.g., aggregate values, etc.
- analysis circuit 338 performs statistical operations on received data to produce statistical measurements describing the received data. For example, analysis circuit 338 may determine an aggregate value associated with online interactions with a publisher. In various implementations, analysis circuit 338 facilitates joining user identifiers. For example, analysis circuit 338 may join first user identifiers from publisher data with second user identifiers from interaction data. In various implementations, analysis circuit 338 facilitates joining encrypted identifiers, thereby preserving user privacy. In some implementations, analysis circuit 338 facilitates distributing credit between publishers associated with an online interaction.
- Third data processing system 400 may facilitate securely distributing aggregate interaction data (e.g., aggregate values, etc.) generated by second data processing system 300.
- third data processing system 400 may receive encrypted masked aggregate values from second data processing system 300, decrypt the encrypted masked aggregate values to produce masked aggregate values, and send the masked aggregate values to one or more publishers.
- Third data processing system 400 may include or execute at least one computer program or at least one script.
- third data processing system 400 includes combinations of software and hardware, such as one or more processors configured to execute one or more scripts.
- Third data processing system 400 is shown to include processing circuit 410 having processor 420 and memory 430.
- Memory 430 may have instructions stored thereon that, when executed by processor 420, cause processing circuit 410 to perform the various operations described herein.
- Processing circuit 410, processor 420, and/or memory 430 may be similar to processing circuit 14 and 34, processor 16 and 36, and/or memory 18 and 38 as described above.
- Memory 430 may include encryption circuit 432, randomization circuit 434, and decryption circuit 436.
- Encryption circuit 432 may implement one or more encryption functions on input data to produce encrypted data.
- encryption circuit 432 implements an asymmetric encryption function (e.g., EG, AHE, etc.).
- encryption circuit 432 is similar to second encryption circuit 42.
- encryption circuit 432 generates encryption keys. For example, encryption circuit 432 may generate a public key (e.g., an AHE public key) and a secret key (e.g., an AHE secret key).
- encryption circuit 432 shares the encryption keys with other components of system 100 (e.g., interaction data provider computing system 30, etc.). In various implementations, encryption circuit 432 facilitates various cryptographic functions (e.g., additivity, scalar multiplication, etc.) as described in reference to second encryption circuit 42. [0061] Randomization circuit 434 may receive data and perform various randomization functions to produce randomized data. In various implementations, randomization circuit 434 is similar to randomization circuit 248. In some implementations, randomization circuit 434 facilitates rerandomizing ciphertexts by applying subsequent rounds of encryption. For example, randomization circuit 434 may rerandomize an AHE encrypted value by encrypting the AHE encrypted value a second time with the same key used to encrypt the AHE encrypted value the first time.
- Decryption circuit 436 may receive encrypted data and decrypt it to produce unencrypted data.
- decryption circuit 436 receives encrypted data from second data processing system 300.
- decryption circuit 436 may receive encrypted aggregate values and/or encrypted masked aggregate values from second data processing system 300.
- Decryption circuit 436 may decrypt asymmetrically encrypted data. Additionally or alternatively, decryption circuit 436 may decrypt symmetric and/or threshold encrypted data.
- decryption circuit 436 receives one or more secrets (e.g., secret keys, etc.) from encryption circuit 432.
- decryption circuit 436 may receive a secret key (e.g., an AHE secret key, etc.) from encryption circuit 432 and use the secret key to at least partially decrypt encrypted data received from second data processing system 300.
- decryption circuit 436 facilitates collaborative decryption. For example, a number of decryption circuits 436 may work together to decrypt an encrypted data item (e.g., each removing a portion of encryption, etc.).
- publishers associated with publisher computing system 10 may provide content items to users using client devices (e.g., smartphones, computers, etc.).
- the content items are specific to specific users.
- Interaction data providers associated with interaction data provider computing system 30 may detect when users interact with the content items. For example, a user shown a video may click on the video. It is desirable to measure user interaction with the content items. For example, a publisher providing a video may wish to know how many users clicked on the video. Additionally or alternatively, users may interact with other content provided by a publisher as a result of their interaction with the content items.
- a user shown a video may later visit a website maintained by the publisher to purchase an item featured in the video.
- the interaction is or is associated with an online conversion.
- measuring user interaction with the content items requires comparing information from the publishers (e.g., publisher data, etc.) with information from the interaction data providers (e.g., interaction data, etc.). Therefore, there is a need for a system to securely and anonymously measure user interaction with online content without revealing personal information.
- a novel cryptography and computer architecture as described herein facilitates secure and anonymous measurement of user interactions with online content without revealing personal information.
- first data processing system 200 and second data processing system 300 collaboratively generate an EG public key.
- second data processing system 300 generates the EG public key alone.
- multiple first data processing systems 200 collaboratively generate the EG public key with second data processing system 300.
- the EG public key is an EG public key generated by implementing EG encryption over an elliptic curve.
- first data processing system 200 transmits the EG public key to publisher computing system 10 and interaction data provider computing system 30.
- second data processing system 300 may transmit the EG public key to publisher computing system 10 and/or interaction data provider computing system 30.
- first data processing system 200 and second data processing system 300 may each send the EG public key to publisher computing system 10 and interaction data provider computing system 30 which may verify that the keys received from first data processing system 200 and second data processing system 300 are the same.
- third data processing system 400 transmits an AHE public key to publisher computing system 10 and interaction data provider computing system 30.
- publisher computing system 10 and interaction data provider computing system 30 transmit data to first data processing system 200.
- the data is encrypted.
- a portion of the data may be encrypted with the EG public key and a portion of the data may be encrypted with the AHE public key.
- publisher computing system 10 transmits encrypted publisher data and interaction data provider computing system 30 transmits encrypted interaction data.
- the encrypted publisher data includes first encrypted identifiers.
- the publisher data includes timestamps and/or a count of interactions.
- the encrypted interaction data includes second encrypted identifiers and encrypted values.
- the interaction data includes timestamps and/or propensity data.
- the first and second encrypted identifiers may be encrypted with the EG public key and the encrypted values may be encrypted with the AHE public key.
- first data processing system 200 transmits data to second data processing system 300.
- the data is encrypted.
- a portion of the data may have a first layer of encryption with an EC secret key and a second layer of partial encryption with the EG public key and a portion of the data may have a layer of encryption with the AHE public key.
- the data includes encrypted publisher data and encrypted interaction data.
- second data processing system 300 transmits data to third data processing system 400.
- the data is encrypted.
- the data may be encrypted with the AHE public key.
- the data is masked.
- the data may have a random integer appended.
- the data includes an encrypted aggregate value.
- the data includes encrypted publisher credit associated with one or more publishers.
- third data processing system 400 may transmit the publisher credit to one or more publishers (e.g., publisher computing system 10, etc.).
- key generation process 600 is shown, according to an illustrative implementation.
- key generation process 600 (or elements thereof) occurs continuously.
- system 100 may perform key generation process 600 for each new set of data processed.
- key generation process 600 occurs periodically.
- system 100 may perform key generation process 600 every hour, day, week, and/or the like.
- key generation process 600 for first data processing system 200 is shown, according to an illustrative implementation.
- first data processing system 200 collaboratively generates a first public key with second data processing system 300. Additionally or alternatively, a number of first data processing systems 200 may collaboratively generate the first public key with second data processing system 300.
- first data processing system 200 may be a distributed processing system and a number of the distributed components of first data processing system 200 may collaboratively generate the first public key with second data processing system 300.
- first public key is an EG public key.
- the first public key may be a public key generated by implementing EG encryption over an elliptic curve.
- step 602 is omitted and second data processing system 300 generates the first public key alone.
- first data processing system 200 generates a first secret key associated with the first public key.
- the first secret key is an EG secret key.
- first data processing system 200 generates a number of first secret keys.
- first data processing system 200 may be a distributed processing system that collaboratively generates the first public key with second data processing system 300 and a number of the distributed components of first data processing system 200 may each generate their own first secret key.
- the first secret key and the first public key are a key pair.
- step 604 is omitted and second data processing system 300 generates the first public key alone.
- first data processing system 200 generates a second secret key.
- the second secret key is an EC secret key.
- the second secret key may be a secret key generated by implementing EC encryption over an elliptic curve.
- the elliptic curve used to generate the second secret key is the same as or similar to the elliptic curve used to generate the first public key in step 602 above.
- first data processing system 200 generates a number of second secret keys.
- first data processing system 200 may be a distributed processing system and a number of the distributed components of first data processing system 200 may each generate their own second secret key.
- second data processing system 300 collaboratively generates a first public key with first data processing system 200.
- the first public key is an EG public key.
- the first public key is generated by implementing EG encryption over the same elliptic curve used to generate the second secret key described in step 606 above.
- second data processing system 300 collaboratively generates the first public key with a number of first data processing systems 200.
- second data processing system 300 may generate the first public key alone.
- second data processing system 300 generates a third secret key associated with the first public key.
- the third secret key is an EG secret key.
- the third secret key and the first public key are a key pair.
- third data processing system 400 generates a second public key.
- the second public key is an AHE public key.
- third data processing system 400 generates a number of second public keys.
- third data processing system 400 may be a distributed processing system and a number of the distributed components of third data processing system 400 may each generate their own second public key.
- third data processing system 400 generates a fourth secret key associated with the second public key.
- the fourth secret key is an AHE secret key.
- third data processing system 400 generates a number of fourth secret keys.
- third data processing system 400 may be a distributed processing system and a number of the distributed components of third data processing system 400 may each generate their own fourth secret key.
- the fourth secret key and the second public key are a key pair.
- step 616 publisher computing system 10 generates a third public key.
- the third public key is an asymmetric encryption public key.
- a number of publishers may generate a number of third public keys, each of the third public keys corresponding to one of the number of publishers.
- step 616 includes generating a number of third public keys each for a different interaction stream (e.g., mobile, web, etc.).
- step 618 publisher computing system 10 generates a fifth secret key associated with the third public key.
- the fifth secret key is an asymmetric encryption secret key.
- the fifth secret key and the third public key are a key pair.
- system 100 performs a key generation process.
- the key generation process may be performed as described in detail above with reference to FIGS. 3A-3D.
- publisher computing system 10 encrypts first identifiers using a first public key.
- the first public key is an EG public key received from second data processing system 300.
- the first identifiers are user identifiers of users who interacted with publisher content (e.g., viewed an ad, clicked on a link, etc.).
- publisher computing system 10 transmits data to first data processing system 200.
- the data includes encrypted first identifiers.
- the data may include the first identifiers encrypted using the EG public key from second data processing system 300.
- the data includes timestamps and/or quantities.
- interaction data provider computing system 30 encrypts second identifiers using the first public key.
- the first public key is an EG public key.
- the second identifiers are user identifiers of users who completed an online interaction (e.g., a purchase, etc.).
- interaction data provider computing system 30 encrypts values using a second public key.
- the second public key is an AHE public key received from third data processing system 400.
- the values are value quantities associated with the online interaction completed by the users (e.g., a purchase amount, etc.).
- interaction data provider computing system 30 transmits data to first data processing system 200.
- the data includes encrypted second identifiers and encrypted values.
- the data may include second identifiers encrypted using the EG public key from second data processing system 300 and values encrypted using the AHE public key from third data processing system 400.
- the data includes timestamps and/or propensity data.
- first data processing system 200 receives encrypted first identifiers from publisher computing system 10 and encrypted second identifiers and encrypted values from interaction data provider computing system 30.
- first data processing system 200 receives additional information (e.g., timestamps, quantities, propensity data, etc.).
- first data processing system 200 removes a first portion of encryption from encrypted first and second identifiers using a first secret key to produce partially encrypted first and second identifiers.
- the first secret key is an EG secret key generated by first data processing system 200.
- first data processing system 200 and second data processing system 300 may collaboratively generate an EG public key that requires a first EG secret key from first data processing system 200 and a second EG secret key from second data processing system 300 to decrypt.
- step 732 is omitted and second data processing system 300 removes the EG encryption alone.
- a number of first data processing systems 200 may collaboratively remove the first portion of encryption from the first and second identifiers.
- a number of first data processing system 200 and second data processing system 300 may collaboratively generate an EG public key that requires a first number of EG secret keys from each of the number of first data processing systems 200 and a second EG secret key from second data processing system 300 to decrypt.
- the first portion of encryption is the portion of EG encryption that can be removed by the first EG secret key.
- first data processing system 200 encrypts the partially encrypted first and second identifiers using a second secret key to produce obscured encrypted first and second identifiers.
- the second secret key is an EC secret key generated by first data processing system 200.
- the obscured encrypted first and second identifiers have a first partial layer of EG encryption and a second layer of EC encryption.
- first data processing system 200 performs randomization operations on at least some of the obscured encrypted first identifiers and/or obscured encrypted second identifiers. For example, the randomization operations may include rerandomizing an encryption ciphertext.
- first data processing system 200 transmits data to second data processing system 300.
- the data includes the obscured encrypted first and second identifiers and encrypted values. In some implementations, the data includes additional information (e.g., timestamps, quantities, propensity data, etc.). [0082] At step 740, second data processing system 300 receives obscured encrypted first and second identifiers and encrypted values from first data processing system 200. In some implementations, second data processing system 300 receives additional information (e.g., timestamps, quantities, propensity data, etc.). At step 742, second data processing system 300 decrypts the obscured encrypted first and second identifiers using a third secret key to produce obscured first and second identifiers.
- additional information e.g., timestamps, quantities, propensity data, etc.
- step 742 includes removing a second portion of EG encryption corresponding to an EG secret key held by second data processing system 300.
- second data processing system 300 removes the entire EG encryption by itself (e.g., without first data processing system 200).
- the obscured first and second identifiers are EC encrypted first and second identifiers.
- second data processing system 300 performs an aggregation operation using the obscured first and second identifiers and the encrypted values to produce an encrypted aggregate value.
- the aggregation operation includes joining the obscured first and second identifiers and distributing credit associated with the encrypted values. The aggregation operation is described in greater detail with reference to FIGS. 5-10 below.
- the encrypted aggregate value is a value quantity associated with a specific publisher and/or interaction pathway.
- the encrypted aggregate value includes multiple value quantities (e.g., each associated with a different publisher and/or interaction pathway, etc.).
- the encrypted aggregate value is encrypted with AHE encryption.
- second data processing system 300 performs a masking operation on the encrypted aggregate value to produce an encrypted masked aggregate value.
- the masking operation includes appending random integer. The masking operation is described in greater detail with reference to FIG. 11 below.
- step 760 is omitted.
- second data processing system 300 transmits the encrypted masked aggregate value to third data processing system 400.
- the encrypted masked aggregate value may include multiple values (e.g., each associated with a different publisher and/or interaction pathway, etc.).
- third data processing system 400 receives an encrypted masked aggregate value from second data processing system 300.
- the encrypted masked aggregate value includes multiple values as described above.
- third data processing system 400 decrypts the encrypted masked aggregate value using a fourth secret key to produce a masked aggregate value.
- the fourth secret key is an AHE secret key generated by third data processing system 400.
- the masked aggregate value is an aggregate value having an appended random integer.
- third data processing system 400 transmits the masked aggregate value to publisher computing system 10. In some implementations, step 774 includes transmitting a number of masked aggregate values. For example, third data processing system 400 may transmit a number of masked aggregate values, each associated with a different interaction pathway and/or a different publisher.
- step 750 is shown in greater detail, according to an illustrative implementation.
- second data processing system 300 performs step 750.
- second data processing system 300 joins obscured first and second identifiers.
- joining obscured first and second identifiers includes comparing ciphertexts of the obscured first and second identifiers.
- step 752 includes grouping the data into rows by obscured identifiers.
- second data processing system 300 distributes credit among publishers. Additionally or alternatively, second data processing system 300 may distribute credit among interaction pathways.
- step 754 includes computing a function across rows to distribute credit. Step 754 is described in greater detail with reference to FIGS. 6-10 below.
- credit is distributed according to rule based attribution.
- second data processing system 300 may distribute credit based on a first-impression scheme (e.g., the first interaction receives all the credit), a last- impression scheme (e.g., the last interaction receives all the credit), a linear/equal weight scheme (e.g., each interaction and/or publisher receives an equal portion of the credit), a positional scheme (e.g., a first and/or last interaction receives a first portion of the credit and the remaining interactions receive an equal portion of the remaining credit), a time decay scheme (e.g., similar to the linear/equal weight but including a penalty associated with older interactions), a custom scheme, and/or the like.
- credit is distributed based on Shapley values.
- step 756 second data processing system 300 performs a summation to produce an encrypted aggregate value.
- step 756 produces a number of value quantities.
- step 756 includes aggregating along each column.
- second data processing system 300 may include publisher data 810 and interaction data 820.
- publisher data 810 includes first identifiers 814.
- First identifiers 814 may be EC encrypted.
- first identifiers 814 are device identifiers. Additionally or alternatively, first identifiers 814 may be or include another identifier such as an identifier associated with a user account. First identifiers 814 are shown as numbers, however it should be understood that first identifiers 814 may be alphanumeric ciphertexts. In various implementations, first identifiers 814 are associated with publisher identifier 812. Publisher identifier 812 may identify a source of an associated first identifier 814. In some implementations, publisher data includes an interaction pathway identifier. In various implementations, interaction data 820 includes second identifiers 822 and values 824.
- Second identifiers 822 may be EC encrypted. Values 824 may be AHE encrypted. As described above, second identifiers 822 and values 824 are shown as names and dollar amounts respectively, however it should be understood that second identifiers 822 and values 824 are alphanumeric ciphertexts. In various implementations, values 824 are associated with second identifiers 822. In various implementations, second identifiers 822 are associated with first identifiers 814. In various implementations, publisher data 810 and/or interaction data 820 is unstructured data (e.g., unsorted, etc.) when received by second data processing system 300.
- second data processing system 300 joins obscured first and second identifier (e.g., first identifiers 814 and second identifiers 822).
- Step 752 may include grouping the data into rows by matching first and second identifiers 814 and 822.
- second data processing system 300 determines whether a publisher recorded an interaction 830 with a user or did not record an interaction 832 with a user based on the joined first and second identifiers 814 and 822. For example, second data processing system 300 may determine that publisher 1 and 3 displayed publisher content to “ID 3” and publisher 2 did not.
- second data processing system 300 determines a specific value (e.g., of values 824) that corresponds to a row based on matching first and second identifiers 814 and 822. It should be understood that although the data is shown as corresponding to different publishers, the data may additionally or alternatively correspond to different interaction pathways.
- second data processing system 300 distributes credit 840 among publishers.
- credit 840 is part or all of values 824.
- second data processing system 300 evenly distributes credit 840 among publishers. For example, second data processing system 300 may determine that publisher 1 and 3 displayed publisher content to “ID 3” and publisher 2 did not and may evenly distribute “$9” of value associated with “ID 3” between publisher 1 and 3 (e.g., “$4.50” to each, etc.). Additionally or alternatively, second data processing system 300 may distribute value using a custom process (e.g., tailored rules, etc.). For example, second data processing system 300 may distribute a majority percentage of value to a first publisher that displayed content to the user first and may distribute a minority percentage of value amongst various other publishers that displayed content to the user after the first publisher.
- a custom process e.g., tailored rules, etc.
- second data processing system 300 performs a summation to produce aggregate value 850.
- Step 756 may include aggregating along each column.
- second data processing system 300 may sum a collection of credit 840 associated with publisher 1 to determine aggregate value 850.
- second data processing system 300 determines an aggregate value 850 for each publisher. Additionally or alternatively, second data processing system 300 may determine an aggregate value for each interaction pathway.
- Publisher data 810 may include time 816.
- Time 816 may be associated with a time that a user associated with first identifier 814 interacted with publisher content.
- time 816 includes a timestamp.
- time 816 is truncated (e.g., to the hour, day, etc.) and/or batched, thereby preserving personal information.
- step 752 is performed as described above.
- second data processing system 300 determines an interaction time 834 associated with each publisher interaction. For example, second data processing system 300 may determine that publisher 1 displayed publisher content to “ID 3” on “5/11,” publisher 3 displayed publisher content to “ID 3” on “5/14,” and publisher 2 did not record an interaction 832.
- second data processing system 300 may distribute credit 840 among publishers according to a last-clicked attribution scheme. For example, second data processing system 300 may distribute an entire value quantity associated with “ID 3” to publisher 3 because publisher 3 was the last publisher to display publisher content to “ID 3.” Additionally or alternatively, second data processing system 300 may distribute credit 840 among publishers according to a first-clicked attribution scheme.
- step 756 is performed as described above.
- Publisher data 810 may include quantity 818.
- Quantity 818 may be associated with a number of times that a publisher recorded an interaction with a user (e.g., displayed publisher content to a user, etc.).
- step 752 is performed as described above.
- second data processing system 300 determines an interaction quantity 836 associated with each publisher interaction. For example, second data processing system 300 may determine that publisher 1 displayed publisher content to “ID 3” once, publisher 3 displayed publisher content to “ID 3” four times, and publisher 2 did not record an interaction 832.
- second data processing system 300 may distribute credit 840 among publishers based on interaction quantity 836. For example, second data processing system 300 may weight credit 840 based on interaction quantity 836.
- second data processing system 300 may distribute four-fifths of a value quantity associated with “ID 3” to publisher 3 and one-fifth of the value quantity associated with “ID 3” to publisher 1 because publisher 3 recorded four-fifths of the total user interactions associated with “ID 3” and publisher 1 recorded one-fifth of the total user interaction associated with “ID 3.”
- step 756 is performed as described above.
- Interaction data 820 may include time 826.
- Time 826 may be associated with a time that a user associated with second identifier 822 performed an online interaction (e.g., a purchase, etc.).
- time 826 includes a timestamp.
- time 826 is truncated (e.g., to the hour, day, etc.) and/or batched, thereby preserving personal information (e.g., maintaining privacy and security, etc.).
- step 752 is performed as described above to determine interaction time 834.
- second data processing system 300 determines a number of interactions 862 and a total value 864 associated with each pathway 860.
- a first pathway 860 may include interactions for which a user interacted with publisher content from publisher 1, 2, and 3 while a second pathway 860 may include interactions for which a user interacted with publisher content only from publisher 1.
- pathways 860 describe a type of interaction.
- a first pathway 860 may include mobile and web interactions and a second pathway may include link-referrals.
- number of interactions 862 is a sum of a number of users that were recorded as interacting with the elements defined in the specific pathway 860.
- pathways 860 are unordered (e.g., non-sequential, etc.).
- second data processing system 300 determines a Shapley value 852.
- Shapley value 852 may describe an average marginal contribution of a publisher across all possible pathways 860.
- second data processing system 300 computes Shapley value 852 as: where ⁇ p ; - is the Shapley value 852 for x ; ⁇ , where X j is a user interaction (e.g., a first identifier 814 associated with a publisher identifier 812), where j is an index of the total number of publishers p, where P is the set of all user interactions, where S £ P ⁇ xj) is one subset of user interactions which must include interaction x ; ⁇ , and where i?(SU ⁇ x/ ⁇ ) is the credit distributed to the specific pathway 860.
- the Shapley value 852 may be computed as an aggregate value 850.
- the aggregate value 850 may be computed as:
- step 754B includes step 756.
- aggregate value 850 may be calculated based on propensity scores.
- second data processing system 300 may group the data based on propensity scores and may determine aggregate value 850 based on the groupings of data.
- step 752 is performed as described above.
- second data processing system 300 determines a number of interactions 862 and a total value 864 associated with a number of pathways 870.
- a first pathway 870 may include interactions for which a user interacted with publisher content from publisher 1, followed by publisher content from publisher 2, and followed by publisher content from publisher 3 while a second pathway 870 may include interactions for which a user interacted with publisher content only from publisher 1.
- pathways 870 are ordered (e.g., sequential, etc.).
- step 754C second data processing system 300 generates Markov Model 880.
- Markov Model 880 may model pathways 870 as a journey through a sequence of states.
- Markov Model 880 may include nodes 882 and connections 884.
- Nodes 882 may represent interactions. For example, a user may interact with publisher content from publisher 1 followed by publisher 3 before performing an online interaction (e.g., a purchase, etc.).
- Markov Model 880 includes a start, end, and null node 882.
- the start node 882 may represent a starting place (e.g., before a user has interacted with publisher content, etc.).
- the end node 882 may represent a user that has performed an online interaction.
- the null node 882 may represent a user that has not performed an online interaction.
- Connections 884 may represent a probability of transitioning from a first node 882 to a second node 882.
- second data processing system 300 determines the probabilities of connections 884 empirically (e.g., based on publisher data 810 and interaction data 820).
- second data processing system 300 generates removal effects 854.
- Removal effects 854 may model the contribution of a publisher by comparing a number of online interactions that occur with a specific publisher present to a number of online interactions that occur without the specific publisher present.
- step 754D includes step 756.
- second data processing system 300 generates removal effect 854 as a percentage of the sum of removal effects 854.
- removal effect 854 may be computed as: [0106] Referring now to FIG. 11, step 760 of performing a masking operation is shown, according to an illustrative implementation.
- second data processing system 300 performs step 760.
- second data processing system 300 generates a random value.
- the random value is a large random value (e.g., 128-bits or longer, etc.).
- step 762 includes generating multiple random values.
- second data processing system 300 may generate a random value for each destination of the masked aggregate values (e.g., for each publisher, etc.).
- second data processing system 300 performs an operation with the random value and an encrypted aggregate value to produce an encrypted masked aggregate value.
- the operation includes appending the random value to the encrypted aggregate value.
- second data processing system 300 encrypts the random value using a third public key to produce an encrypted random value.
- the third public key is an asymmetric encryption public key from publisher computing system 10.
- second data processing system 300 transmits the encrypted random value to publisher computing system 10.
- steps 766 and 768 may be repeated for each of the random values and/or destinations (e.g., for each publisher, etc.).
- FIG. 12 illustrates a depiction of a computing system 1000 that can be used, for example, to implement any of the illustrative systems (e.g., system 100, etc.) described in the present disclosure.
- the computing system 1000 includes a bus 1005 or other communication component for communicating information and a processor 1010 coupled to the bus 1005 for processing information.
- the computing system 1000 also includes main memory 1015, such as a random access memory (“RAM”) or other dynamic storage device, coupled to the bus 1005 for storing information, and instructions to be executed by the processor 1010.
- Main memory 1015 can also be used for storing position information, temporary variables, or other intermediate information during execution of instructions by the processor 1010.
- the computing system 1000 may further include a read only memory (“ROM”) 1020 or other static storage device coupled to the bus 1005 for storing static information and instructions for the processor 1010.
- a storage device 1025 such as a solid state device, magnetic disk or optical disk, is coupled to the bus 1005 for persistently storing information and instructions.
- the computing system 1000 may be coupled via the bus 1005 to a display 1035, such as a liquid crystal display, or active matrix display, for displaying information to a user.
- An input device 1030 such as a keyboard including alphanumeric and other keys, may be coupled to the bus 1005 for communicating information, and command selections to the processor 1010.
- the input device 1030 has a touch screen display 1035.
- the input device 1030 can include a cursor control, such as a mouse, a trackball, or cursor direction keys, for communicating direction information and command selections to the processor 1010 and for controlling cursor movement on the display 1035.
- the computing system 1000 may include a communications adapter 1040, such as a networking adapter.
- Communications adapter 1040 may be coupled to bus 1005 and may be configured to enable communications with a computing or communications network 1045 and/or other computing systems.
- any type of networking configuration may be achieved using communications adapter 1040, such as wired (e.g., via Ethernet), wireless (e.g., via Wi-Fi, Bluetooth, etc.), pre-configured, ad-hoc, LAN, WAN, etc.
- the processes that effectuate illustrative implementations that are described herein can be achieved by the computing system 1000 in response to the processor 1010 executing an arrangement of instructions contained in main memory 1015. Such instructions can be read into main memory 1015 from another computer-readable medium, such as the storage device 1025. Execution of the arrangement of instructions contained in main memory 1015 causes the computing system 1000 to perform the illustrative processes described herein. One or more processors in a multi processing arrangement may also be employed to execute the instructions contained in main memory 1015. In alternative implementations, hard-wired circuitry may be used in place of or in combination with software instructions to implement illustrative implementations.
- implementations are not limited to any specific combination of hardware circuitry and software.
- a user may be provided with controls allowing the user to make an election as to both if and when systems, programs, or features described herein may enable collection of user information (e.g., information about a user’s social network, social actions, or activities, profession, a user’s preferences, or a user’s current location), and if the user is sent content or communications from a server.
- user information e.g., information about a user’s social network, social actions, or activities, profession, a user’s preferences, or a user’s current location
- certain data may be treated in one or more ways before it is stored or used, so that personally identifiable information is removed.
- a user’s identity may be treated so that no personally identifiable information can be determined for the user, or a user’s geographic location may be generalized where location information is obtained (such as to a city, ZIP code, or state level), so that a particular location of a user cannot be determined.
- location information such as to a city, ZIP code, or state level
- the systems described herein collect personal information about users or applications installed on a user device, or make use of personal information
- the users are provided with an opportunity to control whether programs or features collect user information (e.g., information about a user’s social network, social actions, or activities, profession, a user’s preferences, or a user’s current location).
- user information e.g., information about a user’s social network, social actions, or activities, profession, a user’s preferences, or a user’s current location.
- certain data may be treated in one or more ways before it is stored or used, so that personal information is removed.
- the outcome measurement service may join publisher data and interaction data to determine an aggregate credit associated with an online interaction. Moreover, the outcome measurement service may securely distribute credit associated with the online interaction between the publishers using a unique cryptography and computer-architecture methodology as described herein. In various implementations, the outcome measurement service described herein improves the field of interaction measurements. Moreover, the outcome measurement service may securely determine aggregate measurements more quickly and with greater security than traditional systems, thereby improving the functioning of existing computer systems.
- Implementations of the subject matter and the operations described in this specification can be carried out using digital electronic circuitry, or in computer software embodied on a tangible medium, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Implementations of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on one or more computer storage medium for execution by, or to control the operation of, data processing apparatus.
- the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
- a computer-readable storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them.
- a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially-generated propagated signal.
- the computer storage medium can also be, or be included in, one or more separate components or media (e.g., multiple CDs, disks, or other storage devices). Accordingly, the computer storage medium is both tangible and non-transitory.
- the term “data processing apparatus” or “computing device” encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example, a programmable processor, a computer, a system on a chip, or multiple ones, or combinations of the foregoing.
- the apparatus can include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- the apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross- platform runtime environment, a virtual machine, or a combination of one or more of them.
- the apparatus and execution environment can realize various different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
- a computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code).
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- the processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output.
- the processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- Circuit as utilized herein may be implemented using hardware circuitry (e.g., FPGAs, ASICs, etc.), software (instructions stored on one or more computer readable storage media and executable by one or more processors), or any combination thereof.
- processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer.
- a processor will receive instructions and data from a read-only memory or a random access memory or both.
- the essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- a computer need not have such devices.
- a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (“PDA”), a mobile audio or video player, a game console, a Global Positioning System (“GPS”) receiver, or a portable storage device (e.g., a universal serial bus (“USB”) flash drive), to name just a few.
- Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example, semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD- ROM and DVD-ROM disks.
- the processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- implementations of the subject matter described in this specification can be carried out using a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- a computer can interact with a user by sending documents to and receiving documents from a device
- Implementations of the subject matter described in this specification can be carried out using a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such backend, middleware, or frontend components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network.
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- a server transmits data (e.g., an HTML page) to a client device (e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device).
- client device e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device.
- Data generated at the client device e.g., a result of the user interaction
- the features disclosed herein may be implemented on a smart television module (or connected television module, hybrid television module, etc.), which may include a processing circuit configured to integrate internet connectivity with more traditional television programming sources (e.g., received via cable, satellite, over-the-air, or other signals).
- the smart television module may be physically incorporated into a television set or may include a separate device such as a set-top box, Blu- ray or other digital media player, game console, hotel television system, and other companion device.
- a smart television module may be configured to allow viewers to search and find videos, movies, photos and other content on the web, on a local cable television channel, on a satellite television channel, or stored on a local hard drive.
- a set-top box (“STB”) or set-top unit (“STU”) may include an information appliance device that may contain a tuner and connect to a television set and an external source of signal, turning the signal into content which is then displayed on the television screen or other display device.
- a smart television module may be configured to provide a home screen or top level screen including icons for a plurality of different applications, such as a web browser and a plurality of streaming media services, a connected cable or satellite media source, other web “channels”, etc.
- the smart television module may further be configured to provide an electronic programming guide to the user.
- a companion application to the smart television module may be operable on a mobile computing device to provide additional information about available programs to a user, to allow the user to control the smart television module, etc.
- the features may be implemented on a laptop computer or other personal computer, a smartphone, other mobile phone, handheld computer, a tablet PC, or other computing device.
Abstract
Description
Claims
Priority Applications (6)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
GB2106166.8A GB2604190A (en) | 2020-05-26 | 2020-08-24 | Methods for aggregating credit across interactions |
CN202080005943.7A CN113994333A (en) | 2020-05-26 | 2020-08-24 | Method for aggregating points between interactions |
KR1020227040678A KR20230002933A (en) | 2020-05-26 | 2020-08-24 | How credit is aggregated across interactions |
US17/285,831 US11841973B2 (en) | 2020-05-26 | 2020-08-24 | Methods for aggregating credit across interactions |
DE112020000117.2T DE112020000117T5 (en) | 2020-05-26 | 2020-08-24 | PROCEDURE FOR CREDIT AGGREGATION ACROSS INTERACTIONS |
JP2022571291A JP7461513B2 (en) | 2020-05-26 | 2020-08-24 | A method for aggregating credits across interactions |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202063029835P | 2020-05-26 | 2020-05-26 | |
US63/029,835 | 2020-05-26 |
Publications (1)
Publication Number | Publication Date |
---|---|
WO2021242290A1 true WO2021242290A1 (en) | 2021-12-02 |
Family
ID=72433000
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
PCT/US2020/047643 WO2021242290A1 (en) | 2020-05-26 | 2020-08-24 | Methods for aggregating credit across interactions |
Country Status (1)
Country | Link |
---|---|
WO (1) | WO2021242290A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN116629871A (en) * | 2023-07-21 | 2023-08-22 | 济南正浩软件科技有限公司 | Order online payment system and payment method |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150186403A1 (en) * | 2013-12-30 | 2015-07-02 | The Nielsen Company (Us), Llc | Methods and apparatus to de-duplicate impression information |
US20160078431A1 (en) * | 2014-09-11 | 2016-03-17 | Google Inc. | Encrypted aggregated transaction data exchange with transaction data provider |
-
2020
- 2020-08-24 WO PCT/US2020/047643 patent/WO2021242290A1/en active Application Filing
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150186403A1 (en) * | 2013-12-30 | 2015-07-02 | The Nielsen Company (Us), Llc | Methods and apparatus to de-duplicate impression information |
US20160078431A1 (en) * | 2014-09-11 | 2016-03-17 | Google Inc. | Encrypted aggregated transaction data exchange with transaction data provider |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN116629871A (en) * | 2023-07-21 | 2023-08-22 | 济南正浩软件科技有限公司 | Order online payment system and payment method |
CN116629871B (en) * | 2023-07-21 | 2023-10-17 | 济南正浩软件科技有限公司 | Order online payment system and payment method |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11962687B2 (en) | Methods for protecting privacy | |
US11841973B2 (en) | Methods for aggregating credit across interactions | |
US11017099B2 (en) | Systems and methods for entropy balanced population measurement | |
US11757619B2 (en) | Generating sequences of network data while preventing acquisition or manipulation of time data | |
US20220376900A1 (en) | Aggregating encrypted network values | |
WO2021242290A1 (en) | Methods for aggregating credit across interactions | |
AU2021376160B2 (en) | Systems and methods for secure universal measurement identifier construction | |
WO2023196016A1 (en) | Secure computation using multi-party computation and a trusted execution environment | |
US11917078B2 (en) | Preventing data manipulation using multiple aggregation servers | |
US11356428B2 (en) | Data security method for privacy protection |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
ENP | Entry into the national phase |
Ref document number: 202106166Country of ref document: GBKind code of ref document: AFree format text: PCT FILING DATE = 20200824 |
|
121 | Ep: the epo has been informed by wipo that ep was designated in this application |
Ref document number: 20768745Country of ref document: EPKind code of ref document: A1 |
|
ENP | Entry into the national phase |
Ref document number: 2022571291Country of ref document: JPKind code of ref document: ARef document number: 20227040678Country of ref document: KRKind code of ref document: A |
|
122 | Ep: pct application non-entry in european phase |
Ref document number: 20768745Country of ref document: EPKind code of ref document: A1 |