WO2017136532A1 - Globally optimized least-squares post-filtering for speech enhancement - Google Patents
Globally optimized least-squares post-filtering for speech enhancement Download PDFInfo
- Publication number
- WO2017136532A1 WO2017136532A1 PCT/US2017/016187 US2017016187W WO2017136532A1 WO 2017136532 A1 WO2017136532 A1 WO 2017136532A1 US 2017016187 W US2017016187 W US 2017016187W WO 2017136532 A1 WO2017136532 A1 WO 2017136532A1
- Authority
- WO
- WIPO (PCT)
- Prior art keywords
- covariance matrix
- audio signals
- post
- sound field
- noise
- Prior art date
Links
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
- G10L21/0216—Noise filtering characterised by the method used for estimating noise
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
- G10L21/0216—Noise filtering characterised by the method used for estimating noise
- G10L21/0232—Processing in the frequency domain
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
- G10L21/0264—Noise filtering characterised by the type of parameter measurement, e.g. correlation techniques, zero crossing techniques or predictive techniques
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0272—Voice signal separating
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0272—Voice signal separating
- G10L21/0308—Voice signal separating characterised by the type of parameter measurement, e.g. correlation techniques, zero crossing techniques or predictive techniques
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0316—Speech enhancement, e.g. noise reduction or echo cancellation by changing the amplitude
- G10L21/0364—Speech enhancement, e.g. noise reduction or echo cancellation by changing the amplitude for improving intelligibility
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/03—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 characterised by the type of extracted parameters
- G10L25/21—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 characterised by the type of extracted parameters the extracted parameters being power information
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04R—LOUDSPEAKERS, MICROPHONES, GRAMOPHONE PICK-UPS OR LIKE ACOUSTIC ELECTROMECHANICAL TRANSDUCERS; DEAF-AID SETS; PUBLIC ADDRESS SYSTEMS
- H04R3/00—Circuits for transducers, loudspeakers or microphones
- H04R3/005—Circuits for transducers, loudspeakers or microphones for combining the signals of two or more microphones
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
- G10L21/0216—Noise filtering characterised by the method used for estimating noise
- G10L2021/02161—Number of inputs available containing the signal or the noise to be suppressed
- G10L2021/02166—Microphone arrays; Beamforming
Definitions
- Microphone arrays are increasingly being recognized as an effective tool to combat noise, interference, and reverberation for speech acquisition in adverse acoustic environments.
- Applications include robust speech recognition, hands-free voice communication and teleconferencing, hearing aids, to name just a few.
- Beamforming is a traditional microphone array processing technique that provides a form of spatial filtering: receiving signals coming from specific directions while attenuating signals from other directions. While spatial filtering is possible, it is not optimal in the minimum mean square error (MMSE) sense from a signal reconstruction perspective.
- MMSE minimum mean square error
- MCWF multichannel Wiener filter
- MVDR minimum variance distortionless response
- MVDR minimum variance distortionless response
- An example apparatus includes one or more processing devices and one or more storage devices storing instructions that, when executed by the one or more processing devices, cause the one or more processing devices to implement an example method.
- An example computer-readable medium includes sets of instructions to implement an example method.
- One embodiment of the present disclosure relates to a method for estimating coefficient values to reduce noise for a post- filter, the method comprising: receiving audio signals via a microphone array from sound sources in an environment; hypothesizing a sound field scenario based on the received audio signals; calculating fixed beamformer coefficients based on the received audio signals; determining covariance matrix models based on the hypothesized sound field scenario; calculating a covariance matrix based on the received audio signals; estimating power of the sound sources to find solution that minimizes the difference between the determined covariance matrix models and the calculated covariance matrix; calculating and applying post-filter coefficients based on the estimated power; and generating an output audio signal based on the received audio signals and the post-filter coefficients.
- the methods described herein may optionally include one or more of the following additional features: hypothesizing multiple sound field scenarios to generate multiple output signals, wherein the multiple generated output signals are compared and the output signal with the highest signal-to-noise ratio among the multiple output generated signals; the estimating of the power is based on the Frobenius norm, wherein the Frobenius norm is computed using the Hermitian symmetry of the covariance matrices; determining the location of at least one of the sound sources using sound-source location methods to hypothesize the sound field scenario, determine the covariance matrix models, and calculate the covariance matrix; the covariance matrix models are generated based on a plurality of hypothesized sound field scenarios, wherein a covariance matrix model is selected to maximize an objective function that reduces noise, and wherein an objective function is the sample variance of the final output audio signal.
- FIG. 1 is a functional block diagram illustrating an example system for generating a post-filtered output signal based on a hypothesized sound field scenario in accordance with one or more embodiments described herein.
- FIG. 2 is a functional block diagram illustrating a beamformed single-channel output generated from a noise environment in an example system.
- FIG. 3 is a functional block diagram illustrating the determination of covariance matrix models based on a hypothesized sound field scenario in an example system.
- FIG. 4 is a functional block diagram illustrating the post-filter estimation for a frequency bin.
- FIG. 5 is a flowchart illustrating example steps for calculating the post-filter coefficients for a frequency bin, in accordance with an embodiment of this disclosure.
- FIG. 6 illustrates the spatial arrangement of the microphone array and the sound sources related to the experimental results.
- FIG. 7 is a block diagram illustrating an exemplary computing device.
- the headings provided herein are for convenience only and do not necessarily affect the scope or meaning of the claims.
- the present disclosure generally relates to systems and methods for audio signal processing. More specifically, aspects of the present disclosure relate to post-filtering techniques for microphone array speech enhancement.
- Certain embodiments and features of the present disclosure relate to methods and systems for post-filtering audio signals that utilizes a signal model that accounts for not only diffuse and white noise, but also point interfering sources.
- the methods and systems are designed to achieve a globally optimized least- squares (LS) solution of microphones in a microphone array.
- LS least- squares
- the performance of the disclosed method is evaluated using real recorded impulse responses for the desired and interfering sources, including synthesized diffuse and white noise.
- the impulse response is the output or reaction of a dynamic system to a brief input signal called an impulse.
- FIG. 1 illustrates an example system for generating a post-filtered output signal (175) based on a hypothesized sound field scenario (111).
- a hypothesized sound field scenario (111) is a determination of the makeup of the noise components (106-108) in a noise environment (105).
- a precise knowledge of the actual sound field composition is inaccessible, several different hypotheses about the possible composition can be made. Each of these hypotheses are then processed independently, and the best results are output. According to this strategy, each hypothesized sound field composition can be called a hypothesized sound field scenario.
- a plurality of composite scenarios is used, each composite scenario being composed from sets of scenarios that are physical locations and/or physical types for each of the sound sources, where one composite scenario is selected based on maximizing an objective function over the set of scenarios for the desired sound source and minimizing said objective function over the set of scenarios for at least one of the interfering sound sources.
- this disclosed approach can be seen as a more generalized form of other multi -scenario approaches.
- one hypothesized sound field scenario (111) is inputted into the various frequency bins Fl to Fn (165a-c) to generate an output/desired signal (175).
- signals are transformed to a frequency domain. Beamforming and post-filtering are carried out independently from frequency to frequency.
- a hypothesized sound field scenario includes one interfering source.
- hypothesized sound field scenarios may be more complex, including numerous interfering scenarios.
- a simpler hypothesized sound field scenario may be used.
- a more complicated hypothesized sound field scenario with a higher number of acoustic components is used.
- multiple hypothesized sound field scenarios may be determined to generate multiple output signals.
- multiple sound field scenarios may be hypothesized based on various factors, such as information that may be known or determined about the environment.
- the quality of the output signals may be determined using various factors, such as measuring the signal-to-noise ratio (as measured, for example, in the experiments discussed below).
- a person skilled in the art may apply other methods to hypothesize sound field scenarios and determine the quality of the output signals.
- FIG. 1 illustrates a noise environment (105) which may include one or more noise components (106-108).
- the noise components (106-108) in an environment (105) may include, for example, diffuse noise, white noise, and/or point interfering noise sources.
- the noise components (106-108) or noise sources in an environment (105) may be positioned in various locations, projecting noise in various directions, and at various power/strength levels.
- Each noise component (106-108) generates audio signals that may be received by a plurality of microphones ML.Mn (115, 120, 125) in a microphone array (130).
- the audio signals that are generated by the noise components (106-108) in an environment (105) and received by each of the microphones (115, 120, 125) in a microphone array (130) are depicted as 109, a single arrow, in the example illustration for clarity.
- the microphone array (130) includes a plurality of individual omnidirectional microphones (115, 120, 125). This embodiment assumes omnidirectional microphones. Other example embodiments may implement other types of microphones which may alter the covariance matrix models.
- the audio signals (109) received by each of the microphones Ml to Mn (where "n" is an arbitrary integer) (115, 120, 125) may be converted to the frequency domain via a transformation method, such as, for example, Discrete-time Fourier Transformation (DTFT) (116, 121, 126).
- DTFT Discrete-time Fourier Transformation
- Other example transformation methods may include, but are not limited to, FFT (Fast Fourier Transformation), or STFT (Short-time Fourier Transformation).
- the output signals generated via each of the DTFT's (116, 121, 126) corresponding to one frequency are represented by a single arrow.
- the DTFT audio signal at the first frequency bin, Fl (165a), generated by audio received by microphone Ml (115) is represented as a single arrow 117a.
- FIG. 1 also illustrates multiple frequency bins (165a-c), which contain various components, and where each frequency bin's post-filter component generates a post-filter output signal.
- frequency bin Fl 's (165a) post-filter component (160a) generates a post-filter output signal of the first frequency bin (161a).
- the output signals for each frequency bin (165a-c) are inputted into an inverse DTFT component (170) to generate the final time-domain output / desired signal (175) with reduced unwanted noise.
- the details and steps of the various components in the frequency bins (165a-c) in this example system (100) are described in further detail below.
- FIG. 2 illustrates a beamformed single-channel output (136a) generated from a noise environment (105).
- a noise environment (105) contains various noise components (106-108) that generate output as sound.
- noise component 106 outputs desired sound
- noise components 107 and 108 output undesired sound, which may be in the form of white noise, diffuse noise, or point interfering noise.
- Each of the noise components (106-108) generates sound; however, for simplicity, the combined output of the noise components (106-108) is depicted as a single arrow 109.
- the microphones (115, 120, 125) in the array (130) receive the environment noise (109) at various time intervals based on the microphone's physical locations and the directions and strength of of the incoming audio signals within the environment noise (109).
- the received audio signals at each of the microphones (115, 120, 125) is transformed (116, 121, 126) and beamformed (135a) to generate a single-channel output (137a) for one single frequency.
- the fixed beamformer's (135a) single channel -output (137a) is passed to the post- filter (160a).
- the beamforming coefficients (138a), represented as h(ja>), associated with Equation (6) below, are generating the beamforming filters (136a) are passed to calculate post-filter coefficients (155a).
- g S;m denotes the impulse response from the desired component (106) to the mth microphone (e.g. 125), * denotes linear convolution, and m ( is the unwanted additive noise (i.e., sound generated by noise components 107 and 108).
- the disclosed method is capable of dealing with multiple point interfering sources; however, for clarity, one point interferer is described in the examples provided herein.
- the additive noise commonly consists of three different types of sound components: 1) coherent noise from a point interfering source, v(t), 2) diffuse noise, u m (t), and 3) white noise, w m (t). Also,
- g v,m is the impulse response from the point noise source to the mth microphone.
- the desired signal and these noise components (106-108) are presumed short-time stationary and mutually uncorrelated.
- the noise components may be comprised differently. For example, a noise environment which contains multiple desired sound sources moving around and the target desired sound source may alternate over a time period. In other words, a crowded room where two people are walking while having a conversation.
- Equation (3) in a vector/matrix form is as follows
- E j, ( ⁇ ) , and ( ⁇ )* denote the mathematical expectation, the Hermitian transpose of a vector or matrix, and the conjugate of a complex variable, respectively.
- FIR finite impulse response
- Equation (6) the covariance matrix of the desired sound source is also modeled. Its model is similar to that of the interfering source since both the desired and the interfering sources are point source. They differ in their directions with respect to the microphone array.
- FIG. 3 illustrates the steps for determining covariance matrix models based on a hypothesized sound field scenario (111).
- a hypothesized sound field scenario (111) is determined based on the makeup of the noise components (106-108) in the noise environment (105) and inputted into the covariance models (140a-c) for each frequency bin (165a-c) respectively.
- Equation (2) above represents a scenario with one point interfering source, diffuse noise, and white noise, resulting in four unknowns. If the scenario hypothesizes or assumes no point interfering source, only white and diffuse noise, the above Equation (5) can then be simplified resulting in only three unknowns.
- Equation (5) three interference/noise-related components (106-108) are modeled as follows:
- Point Interferer The covariance matrix Pgy (jco) due to the point interfering source v ⁇ t) has rank 1.
- Pgy jco
- the complex elements of the impulse response vector g v may have different magnitudes. But if only the direct path is taken into account or if the point source is in the far field, then
- a diffuse noise field is considered spherically or cylindrically isotropic, in that it is characterized by uncorrected noise signals of equal power propagating in multiple directions simultaneously. Its covariance matrix is given by
- MCWF Multichannel Wiener Filter
- MVDR Beamforming MVDR Beamforming
- a microphone array When a microphone array is used to capture a desired wideband sound signal (e.g., speech and/or music), the intention is to minimize the distance between Y (jco) in Equation (6) and S(jco) for a>'s.
- the MCWF that is optimal in the MMSE sense can be decomposed into a MVDR beamformer followed by a single-channel Wiener filter (SCWF): where
- the SCWF is regarded as a post-filter after the MVDR beamformer.
- FIG. 4 illustrates the post-filter estimation steps in a frequency bin.
- the signal and noise covariance matrices from the calculated covariance matrix of the microphone signals are estimated.
- the multichannel microphone signals are first windowed (e.g., by a weighted overlap-add analysis window) in frames and then transformed by a FFT to determine ⁇ (/ ⁇ , /), where i is the frame index.
- the estimate of the microphone signals' covariance matrix (145a) is recursively updated, dynamically or using a memory component, by
- T SIIN is the desired signal's time difference of arrival for the mt microphone with respect to the common reference point.
- Equation (14) LS estimator for ⁇ ( ⁇ , k), ⁇ ( ⁇ , k), ⁇ ( ⁇ , k), ⁇ ( ⁇ , k) ⁇ may be deduced. Note that the matrices in Equation (14) are Hermitian. Redundant information in this formulation has been omitted for clarity.
- a plurality of N Hermitian matrices of the same size may be defined as
- Equation (14) is reorganized to get where parameter jco is omitted for clarit .
- the LS (least-squares) solution given in Equation (21) is optimal in the MMSE sense. Substituting this estimate into Equation (11) leads to, as referred to in this disclosure, a LS post-filter (LSPF) (160a).
- the deduced LS solution assumes that > 3. This is due to the use of a more generalized acoustic-field model that consists of four types of sound signals.
- additional information regarding the acoustic field such that some types of interfering signals can be ignored (e.g., no point interferer and/or merely white noise)
- FIG. 5 is a flowchart illustrating example steps for calculating the post-filter coefficients for a frequency bin (165a), in accordance with an embodiment of this disclosure.
- the following illustration in FIG. 5 reflects an example implementation of the above disclosed details and mathematical concepts described above.
- the disclosed steps are given by way of illustration only. As would be apparent to one skilled in the art, some steps may be done in parallel or in an alternate sequence within the spirit and scope of this Detailed Description.
- step 502 audio signals are received via microphone array (130) from noise generated (109) by sound sources (106- 108) in an environment (105).
- step 503 a sound field scenario (111) is hypothesized.
- step 504 fixed beamformer coefficients (138a) are calculated based on the received audio signals (117a, 122a, 127a) for a frequency bin (165a).
- step 505 covariance matrix models (140a) based on the hypothesized sound field scenario (111) are determined.
- step 506 a covariance matrix (145a) based on the received audio signals (117a, 122a, 127a) is calculated.
- step 507 the power of the sound sources (150a), based on the determined covariance matrix models (140a) and the calculated covariance matrix (145a), are estimated.
- step 508 post-filter coefficients (155a), based on the estimated power of the sound sources (150a) and the calculated fixed beamformer coefficients (138a), are calculated.
- the example steps may proceed to the end step 509.
- the aforementioned steps may be implemented per frequency bin (165a-c) to generate the post-filtered output signals (161a-c) respectively.
- the post-filtered signals (161a-c) may then be transformed (170) to generate the final output/desired signal (175).
- Equation (19) is simplified as follows Instead of calculating the optimal LS solution for ⁇ (k) using Equation (21), the ZPF uses only the bottom odhv-part of Equation (22) to et
- Equation (19) becomes
- Equation (25) is an overdetermined system. Again, instead of finding a global LS solution by following Equation (21), the MPF applies three equations from Equation (25) that correspond to the pair of the pth and qth microphones to form a subsystem like the following
- the diffuse noise model is more common in practice than the white noise model.
- the MPF's approach to solving Equation (25) is heuristic and is also not optimal.
- FIG. 6 illustrates the spatial arrangement of the microphone array (610) and the sound sources (620, 630) of the experiments.
- the positions of the elements within the figures are not intended to convey exact scale or distance, which are provided in the following description.
- Provided are a set of experiments that consider the first four microphones M1-M4 (601-604) of a microphone array (610), where the spacing between each of the microphones is 3 cm.
- the 60 dB reverberation time is 360 ms.
- the desired source (620) is at the broadside (0 ° ) of the array while the interfering source (630) is at the 45° direction. Both are 2m from the array.
- Clean, continuous, 16 kHz/16-bit speech signals are used for these point sound sources.
- the desired source (620) is a female speaker and the interfering source (630) is a male speaker.
- the voiced parts of the two signals have many overlaps. Accordingly, the impulse responses are resampled at 16 kHz and are truncated to 4096 samples and spherically isotropic diffuse noise is generated.
- 72 x 36 2592 point sources distributed on a large sphere are used. The signals are truncated to 20 s.
- SINR signal -to- interference-and-noise ratio
- PESQ perceptual evaluation speech quality
- the processed desired speech and clean speech is passed to the PESQ estimator.
- the output PESQ indicates the quality of the enhanced signal while the dPESQ value quantifies the amount of speech distortion introduced.
- the Hu & Loizou's Matlab codes for PESQ are used in this study.
- the delay-and-sum (D&S) beamformer is implemented for front-end processing and compared to the following four different post-filtering algorithms: none, ZPF, MPF, and LSPF.
- the D&S-only implementation is used as a benchmark.
- ZPF and MPF Leukimmiatis's correction has been employed.
- the third sound field is apparently the most challenging case to tackle due to the presence of a time-varying interfering speech source.
- the LSPF outperforms the other conventional methods in all metrics.
- the present disclosure describes methods and systems for a LS post-filtering method for microphone array applications. Unlike conventional post-filtering techniques, the method described considers not only diffuse and white noise but also point interferers.
- FIG. 7 is a high-level block diagram to show an application on a computing device (700).
- the computing device (700) typically includes one or more processors (710), system memory (720), and a memory bus (730).
- the memory bus is used to do communication between processors and system memory.
- the configuration may also include a standalone post-filtering component (726) which implements the method described above, or may be integrated into an application (722, 723).
- the processor (710) can be a microprocessor ( ⁇ ), a microcontroller ⁇ C), a digital signal processor (DSP), or any combination thereof.
- the processor (710) can include one or more levels of caching, such as a LI cache (711) and a L2 cache (712), a processor core (713), and registers (714).
- the processor core (713) can include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof.
- a memory controller (716) can either be an independent part or an internal part of the processor (710).
- system memory (720) can be of any type including but not limited to volatile memory (such as RAM), non-volatile memory (such as ROM, flash memory, etc.) or any combination thereof.
- System memory (720) typically includes an operating system (721), one or more applications (722), and program data (724).
- the application (722) may include a post-filtering component (726) or a system and method to apply globally optimized least-squares post-filtering (723) for speech enhancement.
- Program Data (724) includes storing instructions that, when executed by the one or more processing devices, implement a system and method for the described method and component. (723). Or instructions and implementation of the method may be executed via post-filtering component (726).
- the application (722) can be arranged to operate with program data (724) on an operating system (721).
- the computing device (700) can have additional features or functionality, and additional interfaces to facilitate communications between the basic configuration (701) and any required devices and interfaces.
- System memory (720) is an example of computer storage media.
- Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 700. Any such computer storage media can be part of the device (700).
- the computing device (700) can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a smart phone, a personal data assistant (PDA), a personal media player device, a tablet computer (tablet), a wireless web-watch device, a personal headset device, an application-specific device, or a hybrid device that includes any of the above functions.
- the computing device (700) can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.
- non-transitory signal bearing medium examples include, but are not limited to, the following: a recordable type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission type medium such as a digital and/or an analog communication medium, (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.)
- a first example of a computer-implemented method comprises receiving audio signals via a microphone array from sound sources in an environment, hypothesizing a sound field scenario based on the received audio signals, calculating fixed beamformer coefficients based on the received audio signals, determining covariance matrix models based on the hypothesized sound field scenario, calculating a covariance matrix based on the received audio signals, estimating power of the sound sources to find solution that minimizes the difference between the determined covariance matrix models and the calculated covariance matrix, calculating and applying post-filter coefficients based on the estimated power, and generating an output audio signal based on the received audio signals and the post-filter coefficients.
- a second example the method of the first example , further comprising hypothesizing multiple sound field scenarios to generate multiple output signals.
- a third example the method of the second example, wherein the multiple generated output signals are compared and the output signal with the highest signal-to-noise ratio among the multiple output generated signals is selected as the final output signal.
- a fourth example the method of one of examples one to three, wherein the estimating of the power is based on the Frobenius norm.
- a fifth example The method of one of examples one to four, wherein the
- Frobenius norm is computed using the Hermitian symmetry of the covariance matrices.
- a sixth example The method of one of examples one to five, further comprising: determining the location of at least one of the sound sources using sound-source location methods to hypothesize the sound field scenario, determine the covariance matrix models, and calculate the covariance matrix.
- a seventh example The method of one of examples one to six, wherein the covariance matrix models are generated based on a plurality of hypothesized sound field scenarios.
- An eighth example The method of example seven, wherein a covariance matrix model is selected to maximize an objective function that reduces noise.
- a ninth example The method of example eight, wherein an objective function is the sample variance of the final output audio signal.
- a tenth example an apparatus, comprising one or more processing devices and one or more storage devices storing instructions that, when executed by the one or more processing devices, cause the one or processing devices to: receive audio signals via a microphone array from sound sources in an environment, hypothesize a sound field scenario based on the received audio signals, calculate fixed beamformer coefficients based on the received audio signals, determine covariance matrix models based on the hypothesized sound field scenario, calculate a covariance matrix based on the received audio signals, estimate power of the sound sources to find solution that minimizes the difference between the determined covariance matrix models and the calculated covariance matrix, calculate and applying post-filter coefficients based on the estimated power, and generate an output audio signal based on the received audio signals and the post-filter coefficients.
- An eleventh example the apparatus of example ten, further comprising of hypothesizing multiple sound field scenarios to generate multiple output signals.
- a twelfth example the apparatus of example eleven, wherein the multiple generated output signals are compared and the output signal with the highest signal-to-noise ratio among the multiple output generated signals.
- a thirteenth example the apparatus of one of example ten to twelf, wherein the estimating of the power is based on the Frobenius norm.
- a fourteenth example the apparatus of one of examples ten to thirteen, wherein the Frobenius norm is computed using the Hermitian symmetry of the covariance matrices.
- a fifteenth example the apparatus of one of examples ten to fourteen, further comprising determining the location of at least one of the sound sources using sound-source location methods to hypothesize the sound field scenario, determine the covariance matrix models, and calculate the covariance matrix.
- a sixteenth example a computer-readable medium, comprising sets of instructions for: receiving audio signals via a microphone array from sound sources in an environment, hypothesizing a sound field scenario based on the received audio signals, calculating fixed beamformer coefficients based on the received audio signals, determining covariance matrix models based on hypothesized sound field scenario, calculating a covariance matrix based on the received audio signals, estimating power of the sound sources to find solution that minimizes the difference between the determined covariance matrix models and the calculated covariance matrix, calculating and applying post-filter coefficients based on the estimated power, and
- a seventeenth example the computer-readable medium of example sixteen, wherein multiple hypothesized sound field scenarios to generate multiple output signals.
- An eighteenth example the computer-readable medium of example seventeen, wherein the multiple generated output signals are compared and the output signal with the highest signal-to-noise ratio among the multiple output generated signals.
- a nineteenth example the computer-readable medium of one of examples sixteen to eighteen, wherein the estimating of the power is based on the Frobenius norm.
- a twentieth example the computer-readable medium of one of examples sixteen to nineteen, wherein the Frobenius norm is computed using the Hermitian symmetry of the covariance matrices.
- a twenty-first example the computer program comprising sets of instructions which when being executed by a computer carry out the method of one of examples one to nine.
Abstract
Description
Claims
Priority Applications (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CA3005463A CA3005463C (en) | 2016-02-03 | 2017-02-02 | Globally optimized least-squares post-filtering for speech enhancement |
AU2017213807A AU2017213807B2 (en) | 2016-02-03 | 2017-02-02 | Globally optimized least-squares post-filtering for speech enhancement |
KR1020187013790A KR102064902B1 (en) | 2016-02-03 | 2017-02-02 | Globally optimized least squares post filtering for speech enhancement |
JP2018524733A JP6663009B2 (en) | 2016-02-03 | 2017-02-02 | Globally optimized least-squares post-filtering for speech enhancement |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/014,481 | 2016-02-03 | ||
US15/014,481 US9721582B1 (en) | 2016-02-03 | 2016-02-03 | Globally optimized least-squares post-filtering for speech enhancement |
Publications (1)
Publication Number | Publication Date |
---|---|
WO2017136532A1 true WO2017136532A1 (en) | 2017-08-10 |
Family
ID=58044200
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
PCT/US2017/016187 WO2017136532A1 (en) | 2016-02-03 | 2017-02-02 | Globally optimized least-squares post-filtering for speech enhancement |
Country Status (9)
Country | Link |
---|---|
US (1) | US9721582B1 (en) |
JP (1) | JP6663009B2 (en) |
KR (1) | KR102064902B1 (en) |
CN (1) | CN107039045B (en) |
AU (1) | AU2017213807B2 (en) |
CA (1) | CA3005463C (en) |
DE (2) | DE202017102564U1 (en) |
GB (1) | GB2550455A (en) |
WO (1) | WO2017136532A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110838307A (en) * | 2019-11-18 | 2020-02-25 | 苏州思必驰信息科技有限公司 | Voice message processing method and device |
Families Citing this family (30)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9565493B2 (en) | 2015-04-30 | 2017-02-07 | Shure Acquisition Holdings, Inc. | Array microphone system and method of assembling the same |
US9554207B2 (en) | 2015-04-30 | 2017-01-24 | Shure Acquisition Holdings, Inc. | Offset cartridge microphones |
EP3223279B1 (en) * | 2016-03-21 | 2019-01-09 | Nxp B.V. | A speech signal processing circuit |
US10367948B2 (en) | 2017-01-13 | 2019-07-30 | Shure Acquisition Holdings, Inc. | Post-mixing acoustic echo cancellation systems and methods |
US10182290B2 (en) * | 2017-02-23 | 2019-01-15 | Microsoft Technology Licensing, Llc | Covariance matrix estimation with acoustic imaging |
DE102018117557B4 (en) * | 2017-07-27 | 2024-03-21 | Harman Becker Automotive Systems Gmbh | ADAPTIVE FILTERING |
US10110994B1 (en) * | 2017-11-21 | 2018-10-23 | Nokia Technologies Oy | Method and apparatus for providing voice communication with spatial audio |
CN108172235B (en) * | 2017-12-26 | 2021-05-14 | 南京信息工程大学 | LS wave beam forming reverberation suppression method based on wiener post filtering |
WO2019231632A1 (en) | 2018-06-01 | 2019-12-05 | Shure Acquisition Holdings, Inc. | Pattern-forming microphone array |
US11297423B2 (en) | 2018-06-15 | 2022-04-05 | Shure Acquisition Holdings, Inc. | Endfire linear array microphone |
US10986437B1 (en) * | 2018-06-21 | 2021-04-20 | Amazon Technologies, Inc. | Multi-plane microphone array |
CN109194422B (en) * | 2018-09-04 | 2021-06-22 | 南京航空航天大学 | SNR estimation method based on subspace |
CN115514974A (en) * | 2018-09-05 | 2022-12-23 | Lg电子株式会社 | Method and medium for decoding/encoding video signal and transmitting data |
EP3854108A1 (en) | 2018-09-20 | 2021-07-28 | Shure Acquisition Holdings, Inc. | Adjustable lobe shape for array microphones |
US11902758B2 (en) | 2018-12-21 | 2024-02-13 | Gn Audio A/S | Method of compensating a processed audio signal |
CN109932689A (en) * | 2019-02-24 | 2019-06-25 | 华东交通大学 | A kind of General Cell optimization method suitable for certain position scene |
US11558693B2 (en) | 2019-03-21 | 2023-01-17 | Shure Acquisition Holdings, Inc. | Auto focus, auto focus within regions, and auto placement of beamformed microphone lobes with inhibition and voice activity detection functionality |
JP2022526761A (en) | 2019-03-21 | 2022-05-26 | シュアー アクイジッション ホールディングス インコーポレイテッド | Beam forming with blocking function Automatic focusing, intra-regional focusing, and automatic placement of microphone lobes |
CN113841419A (en) | 2019-03-21 | 2021-12-24 | 舒尔获得控股公司 | Housing and associated design features for ceiling array microphone |
CN114051738A (en) | 2019-05-23 | 2022-02-15 | 舒尔获得控股公司 | Steerable speaker array, system and method thereof |
CN113892265A (en) * | 2019-05-30 | 2022-01-04 | 夏普株式会社 | Image decoding device |
EP3977449A1 (en) | 2019-05-31 | 2022-04-06 | Shure Acquisition Holdings, Inc. | Low latency automixer integrated with voice and noise activity detection |
CN110277087B (en) * | 2019-07-03 | 2021-04-23 | 四川大学 | Pre-judging preprocessing method for broadcast signals |
JP2022545113A (en) | 2019-08-23 | 2022-10-25 | シュアー アクイジッション ホールディングス インコーポレイテッド | One-dimensional array microphone with improved directivity |
CN113035216B (en) * | 2019-12-24 | 2023-10-13 | 深圳市三诺数字科技有限公司 | Microphone array voice enhancement method and related equipment |
US11552611B2 (en) | 2020-02-07 | 2023-01-10 | Shure Acquisition Holdings, Inc. | System and method for automatic adjustment of reference gain |
WO2021243368A2 (en) | 2020-05-29 | 2021-12-02 | Shure Acquisition Holdings, Inc. | Transducer steering and configuration systems and methods using a local positioning system |
WO2022165007A1 (en) | 2021-01-28 | 2022-08-04 | Shure Acquisition Holdings, Inc. | Hybrid audio beamforming system |
CN113506556B (en) * | 2021-06-07 | 2023-08-08 | 哈尔滨工业大学（深圳） | Active noise control method, device, storage medium and computer equipment |
CN114205708A (en) * | 2021-12-17 | 2022-03-18 | 深圳市鑫正宇科技有限公司 | Intelligent voice touch control system and method of bone conduction Bluetooth headset |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2738762A1 (en) * | 2012-11-30 | 2014-06-04 | Aalto-Korkeakoulusäätiö | Method for spatial filtering of at least one first sound signal, computer readable storage medium and spatial filtering system based on cross-pattern coherence |
Family Cites Families (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5729613A (en) * | 1993-10-15 | 1998-03-17 | Industrial Research Limited | Reverberators for use in wide band assisted reverberation systems |
US7218741B2 (en) * | 2002-06-05 | 2007-05-15 | Siemens Medical Solutions Usa, Inc | System and method for adaptive multi-sensor arrays |
EP1473964A3 (en) * | 2003-05-02 | 2006-08-09 | Samsung Electronics Co., Ltd. | Microphone array, method to process signals from this microphone array and speech recognition method and system using the same |
US7872583B1 (en) * | 2005-12-15 | 2011-01-18 | Invisitrack, Inc. | Methods and system for multi-path mitigation in tracking objects using reduced attenuation RF technology |
DE602007003220D1 (en) | 2007-08-13 | 2009-12-24 | Harman Becker Automotive Sys | Noise reduction by combining beamforming and postfiltering |
EP2081189B1 (en) | 2008-01-17 | 2010-09-22 | Harman Becker Automotive Systems GmbH | Post-filter for beamforming means |
JP5267982B2 (en) * | 2008-09-02 | 2013-08-21 | Ｎｅｃカシオモバイルコミュニケーションズ株式会社 | Voice input device, noise removal method, and computer program |
EP2394270A1 (en) * | 2009-02-03 | 2011-12-14 | University Of Ottawa | Method and system for a multi-microphone noise reduction |
US20100217590A1 (en) * | 2009-02-24 | 2010-08-26 | Broadcom Corporation | Speaker localization system and method |
JP2010210728A (en) * | 2009-03-09 | 2010-09-24 | Univ Of Tokyo | Method and device for processing acoustic signal |
CN103125104B (en) * | 2010-07-22 | 2015-10-21 | 伊卡诺斯通讯公司 | For the method for operating vector VDSL sets of lines |
DK2701145T3 (en) * | 2012-08-24 | 2017-01-16 | Retune DSP ApS | Noise cancellation for use with noise reduction and echo cancellation in personal communication |
CN105230044A (en) * | 2013-03-20 | 2016-01-06 | 诺基亚技术有限公司 | Space audio device |
EP2916321B1 (en) * | 2014-03-07 | 2017-10-25 | Oticon A/s | Processing of a noisy audio signal to estimate target and noise spectral variances |
-
2016
- 2016-02-03 US US15/014,481 patent/US9721582B1/en not_active Expired - Fee Related
-
2017
- 2017-02-02 CA CA3005463A patent/CA3005463C/en not_active Expired - Fee Related
- 2017-02-02 WO PCT/US2017/016187 patent/WO2017136532A1/en active Application Filing
- 2017-02-02 AU AU2017213807A patent/AU2017213807B2/en active Active
- 2017-02-02 KR KR1020187013790A patent/KR102064902B1/en active IP Right Grant
- 2017-02-02 GB GB1701727.8A patent/GB2550455A/en not_active Withdrawn
- 2017-02-02 JP JP2018524733A patent/JP6663009B2/en active Active
- 2017-02-03 DE DE202017102564.0U patent/DE202017102564U1/en active Active
- 2017-02-03 DE DE102017102134.5A patent/DE102017102134B4/en active Active
- 2017-02-03 CN CN201710063534.2A patent/CN107039045B/en active Active
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2738762A1 (en) * | 2012-11-30 | 2014-06-04 | Aalto-Korkeakoulusäätiö | Method for spatial filtering of at least one first sound signal, computer readable storage medium and spatial filtering system based on cross-pattern coherence |
Non-Patent Citations (2)
Title |
---|
PAN CHAO ET AL: "On the noise reduction performance of the MVDR beamformer in noisy and reverberant environments", 2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), IEEE, 4 May 2014 (2014-05-04), pages 815 - 819, XP032618230, DOI: 10.1109/ICASSP.2014.6853710 * |
YOTAM PELED ET AL: "Linearly constrained minimum variance method for spherical microphone arrays in a coherent environment", HANDS-FREE SPEECH COMMUNICATION AND MICROPHONE ARRAYS (HSCMA), 2011 JOINT WORKSHOP ON, IEEE, 30 May 2011 (2011-05-30), pages 86 - 91, XP031957316, ISBN: 978-1-4577-0997-5, DOI: 10.1109/HSCMA.2011.5942416 * |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110838307A (en) * | 2019-11-18 | 2020-02-25 | 苏州思必驰信息科技有限公司 | Voice message processing method and device |
CN110838307B (en) * | 2019-11-18 | 2022-02-25 | 思必驰科技股份有限公司 | Voice message processing method and device |
Also Published As
Publication number | Publication date |
---|---|
CA3005463A1 (en) | 2017-08-10 |
DE102017102134B4 (en) | 2022-12-15 |
DE102017102134A1 (en) | 2017-08-03 |
CA3005463C (en) | 2020-07-28 |
JP6663009B2 (en) | 2020-03-11 |
KR20180069879A (en) | 2018-06-25 |
KR102064902B1 (en) | 2020-01-10 |
JP2019508719A (en) | 2019-03-28 |
US20170221502A1 (en) | 2017-08-03 |
AU2017213807B2 (en) | 2019-06-06 |
DE202017102564U1 (en) | 2017-07-31 |
CN107039045B (en) | 2020-10-23 |
GB201701727D0 (en) | 2017-03-22 |
CN107039045A (en) | 2017-08-11 |
GB2550455A (en) | 2017-11-22 |
AU2017213807A1 (en) | 2018-04-19 |
US9721582B1 (en) | 2017-08-01 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
AU2017213807B2 (en) | Globally optimized least-squares post-filtering for speech enhancement | |
Wang et al. | Deep learning based target cancellation for speech dereverberation | |
Kinoshita et al. | A summary of the REVERB challenge: state-of-the-art and remaining challenges in reverberant speech processing research | |
Gannot et al. | A consolidated perspective on multimicrophone speech enhancement and source separation | |
Benesty et al. | Speech enhancement | |
Benesty et al. | Speech enhancement in the STFT domain | |
Schwartz et al. | Multi-microphone speech dereverberation and noise reduction using relative early transfer functions | |
Kinoshita et al. | Suppression of late reverberation effect on speech signal using long-term multiple-step linear prediction | |
Krueger et al. | Speech enhancement with a GSC-like structure employing eigenvector-based transfer function ratios estimation | |
Tan et al. | Neural spectrospatial filtering | |
Schmid et al. | Variational Bayesian inference for multichannel dereverberation and noise reduction | |
Huang et al. | Globally optimized least-squares post-filtering for microphone array speech enhancement | |
Habets et al. | Dereverberation | |
Song et al. | An integrated multi-channel approach for joint noise reduction and dereverberation | |
Li et al. | A noise reduction system based on hybrid noise estimation technique and post-filtering in arbitrary noise environments | |
Tammen et al. | Joint estimation of RETF vector and power spectral densities for speech enhancement based on alternating least squares | |
EP3847645A1 (en) | Determining a room response of a desired source in a reverberant environment | |
Zohourian et al. | GSC-based binaural speaker separation preserving spatial cues | |
Lefkimmiatis et al. | An optimum microphone array post-filter for speech applications. | |
Bai et al. | Speech Enhancement by Denoising and Dereverberation Using a Generalized Sidelobe Canceller-Based Multichannel Wiener Filter | |
Mustière et al. | Design of multichannel frequency domain statistical-based enhancement systems preserving spatial cues via spectral distances minimization | |
Pfeifenberger et al. | Blind source extraction based on a direction-dependent a-priori SNR. | |
Ji et al. | Coherence-Based Dual-Channel Noise Reduction Algorithm in a Complex Noisy Environment. | |
Adcock | Optimal filtering and speech recognition with microphone arrays | |
CN117037836B (en) | Real-time sound source separation method and device based on signal covariance matrix reconstruction |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
121 | Ep: the epo has been informed by wipo that ep was designated in this application |
Ref document number: 17705258Country of ref document: EPKind code of ref document: A1 |
|
ENP | Entry into the national phase |
Ref document number: 2017213807Country of ref document: AUDate of ref document: 20170202Kind code of ref document: A |
|
ENP | Entry into the national phase |
Ref document number: 2018524733Country of ref document: JPKind code of ref document: A |
|
ENP | Entry into the national phase |
Ref document number: 3005463Country of ref document: CARef document number: 20187013790Country of ref document: KRKind code of ref document: A |
|
NENP | Non-entry into the national phase |
Ref country code: DE |
|
122 | Ep: pct application non-entry in european phase |
Ref document number: 17705258Country of ref document: EPKind code of ref document: A1 |