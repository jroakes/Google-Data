CN113873237B - Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction - Google Patents
Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction Download PDFInfo
- Publication number
- CN113873237B CN113873237B CN202111143037.6A CN202111143037A CN113873237B CN 113873237 B CN113873237 B CN 113873237B CN 202111143037 A CN202111143037 A CN 202111143037A CN 113873237 B CN113873237 B CN 113873237B
- Authority
- CN
- China
- Prior art keywords
- filtering
- degraded
- tile
- row
- scale factor
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000000034 method Methods 0.000 title claims abstract description 140
- 238000001914 filtration Methods 0.000 claims abstract description 131
- 230000001131 transforming effect Effects 0.000 claims description 4
- 238000004590 computer program Methods 0.000 claims description 3
- 230000015654 memory Effects 0.000 abstract description 29
- 230000008569 process Effects 0.000 description 99
- 230000015556 catabolic process Effects 0.000 description 26
- 238000006731 degradation reaction Methods 0.000 description 26
- 238000011084 recovery Methods 0.000 description 25
- 238000010586 diagram Methods 0.000 description 12
- 238000004891 communication Methods 0.000 description 11
- 238000012545 processing Methods 0.000 description 11
- 230000006870 function Effects 0.000 description 8
- 238000012360 testing method Methods 0.000 description 8
- 238000013139 quantization Methods 0.000 description 7
- 238000007906 compression Methods 0.000 description 5
- 230000006835 compression Effects 0.000 description 4
- 238000012546 transfer Methods 0.000 description 4
- 208000037170 Delayed Emergence from Anesthesia Diseases 0.000 description 3
- 230000002146 bilateral effect Effects 0.000 description 3
- 238000013461 design Methods 0.000 description 3
- 230000000694 effects Effects 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 229920002430 Fibre-reinforced plastic Polymers 0.000 description 2
- 230000008901 benefit Effects 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 2
- 230000000903 blocking effect Effects 0.000 description 2
- 239000002131 composite material Substances 0.000 description 2
- 239000011151 fibre-reinforced plastic Substances 0.000 description 2
- 238000009499 grossing Methods 0.000 description 2
- 238000004519 manufacturing process Methods 0.000 description 2
- 239000011159 matrix material Substances 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 230000009466 transformation Effects 0.000 description 2
- 239000013598 vector Substances 0.000 description 2
- 230000001413 cellular effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 239000003086 colorant Substances 0.000 description 1
- 230000006837 decompression Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000005259 measurement Methods 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 230000004044 response Effects 0.000 description 1
- 230000011218 segmentation Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 238000000638 solvent extraction Methods 0.000 description 1
- 230000009897 systematic effect Effects 0.000 description 1
- 230000002123 temporal effect Effects 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/117—Filters, e.g. for pre-processing or post-processing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/14—Coding unit complexity, e.g. amount of activity or edge presence estimation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/154—Measured or subjectively estimated visual quality after decoding, e.g. measurement of distortion
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/174—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a slice, e.g. a line of blocks or a group of blocks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/189—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding
- H04N19/192—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding the adaptation method, adaptation tool or adaptation type being iterative or recursive
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/46—Embedding additional information in the video signal during the compression process
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/80—Details of filtering operations specially adapted for video compression, e.g. for pixel interpolation
- H04N19/82—Details of filtering operations specially adapted for video compression, e.g. for pixel interpolation involving filtering within a prediction loop
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/85—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression
- H04N19/86—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression involving reduction of coding artifacts, e.g. of blockiness
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/85—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression
- H04N19/86—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression involving reduction of coding artifacts, e.g. of blockiness
- H04N19/865—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression involving reduction of coding artifacts, e.g. of blockiness with detection of the former encoding block subdivision in decompressed video
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/85—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression
- H04N19/89—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression involving methods or arrangements for detection of transmission errors at the decoder
- H04N19/895—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression involving methods or arrangements for detection of transmission errors at the decoder in combination with error concealment
Abstract
The present disclosure relates to methods and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction. A method includes, for scale factors of at least some scale factors, recursively filtering deteriorated tiles using scale factors to generate respective recovered tiles, and determining respective errors of the respective recovered tiles relative to the source tile. The method further includes selecting an optimal scale factor from at least some of the scale factors that corresponds to the smallest respective error, and encoding the scale parameter in the encoded bitstream based on the optimal scale factor. An apparatus includes a processor and a non-transitory memory storing instructions, wherein the instructions cause the processor to determine a scale factor from an encoded bitstream, the scale factor determining how strongly edges in a degraded tile affect a filtering operation, and recursively filter the degraded tile using the scale factor, resulting in a restored tile.
Description
Description of the division
The present application belongs to the divisional application of the Chinese patent application 201780067335.7 with the application date of 2017, 9 and 29.
Technical Field
The present disclosure relates to methods and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction.
Cross Reference to Related Applications
The present application claims priority and benefit from U.S. provisional patent application Ser. No. 62/428,718 filed on 1/12/2016, the entire disclosure of which is incorporated herein by reference.
Background
Digital video streams may use a sequence of frames or still images to represent video. Digital video may be used in a variety of applications including, for example, video conferencing, high definition video entertainment, video advertising, or sharing of user-generated video. Digital video streams may contain large amounts of data and consume large amounts of computing or communication resources of a computing device for processing, transmitting, or storing video data. Various methods have been proposed to reduce the amount of data in video streams, including compression and other encoding techniques.
Encoding using compression may be performed by dividing a frame or image into blocks or tiles that are then compressed, typically using encoding techniques that result in some data loss. The decoder may apply one or more filters to the reconstructed frame to remove or smooth artifacts caused by (e.g., lossy) encoding.
Disclosure of Invention
The present disclosure relates generally to video coding, and more particularly to loop recovery using domain transform recursive filters.
One aspect of the disclosed embodiments is a method for recovering a degraded tile of a degraded frame resulting from reconstruction of a source tile. The method includes, for a scale factor of at least some scale factors: recursively filtering the deteriorated tiles using the scale factors to generate corresponding recovered tiles; and determining respective errors of the respective recovered tiles relative to the source tile. The method further includes selecting an optimal scale factor from at least some of the scale factors, and encoding the scale parameters in the encoded bitstream based on the optimal scale factor. The optimal scale factor corresponds to the smallest corresponding error. Accordingly, the quality of the encoded frame may be improved (or reduced losses may be provided) without reducing the efficiency of the encoding or compression process.
For example, degraded frames may be caused by a reduction in fidelity or quality that occurs during encoding and decoding.
A tile may be at least a portion of a frame.
Alternatively, the scaling factors may be a function of the filter variance over the spatial domain of the degraded tile and the filter variance over the range of pixel values of the degraded tile, and wherein at least some of the scaling factors are selected by fixing one of the filter variance over the spatial domain and the filter variance over the range of pixel values of the degraded tile and changing the other.
Optionally, recursively filtering the degradation tiles may include: for a predetermined number of iterations: determining row weights using the scaling factor and the number of iterations; performing a row filtering operation on rows of the degraded tile; determining column weights using the scaling factor and the number of iterations; and performing a column filtering operation on the columns of the degraded tiles.
Optionally, the predetermined number of iterations is 3. Other numbers may be used.
Optionally, determining the row weight may include: the scaling factor, gradient of the pixel and the number of iterations are used to look up the row weight of the pixel in a look-up table.
Optionally, performing the row filtering operation may include: performing left-to-right filtering using row weights; and performing right-to-left filtering using the row weights, and wherein performing the column filtering operation comprises: performing top-down filtering using column weights; and performing bottom-up filtering using the column weights.
Alternatively, the recursive filtering may be filtering in the gradient domain.
Alternatively, the degradation tiles may be coextensive with the degradation frames.
Another aspect is an apparatus for recovering a degraded tile of a degraded frame resulting from reconstruction of a source tile. The apparatus includes a processor and a non-transitory memory storing instructions. The instructions cause the processor to determine a first error relative to the source tile, the first error corresponding to applying a domain transform recursive filter using a first scale factor to the degraded tile; determining a second error relative to the source tile, the second error corresponding to applying a domain transform recursive filter using a second scale factor to the degraded tile; and encoding one of a first scale factor and a second scale factor corresponding to the smaller of the first error and the second error in the encoded bitstream.
Alternatively, a domain transform recursive filter may be applied to be performed for a predetermined number of iterations.
Optionally, the predetermined number of iterations is 3.
Optionally, applying a domain transform recursive filter using a first scale factor to the degradation tile includes instructions for: determining weights including row weights and column weights using a first scale factor; performing left-to-right filtering using row weights; performing right-to-left filtering using row weights; performing top-down filtering using column weights; and performing bottom-up filtering using the column weights.
Optionally, determining the weights including the row weights and the column weights using the first scale factor includes: look up the row weight of the pixel in a look up table using the first scale factor and the horizontal gradient at the pixel; and looking up the column weight of the pixel in a look-up table using the first scale factor and the vertical gradient at the pixel.
Optionally, the instructions further comprise instructions for: the first size is selected for the degraded tile based on the second size of the degraded frame.
Optionally, selecting the first size of the degradation tile based on the second size of the degradation frame comprises: if the second size is greater than 256x256 pixels, the first size is set to 256x256 pixels; and if the second size is less than or equal to 256x256 pixels, setting the first size to 120x120 pixels.
Optionally, the domain transform is a gradient domain.
Another aspect is an apparatus for recovering a degraded tile of a degraded frame produced by a decoder reconstruction. The apparatus includes a processor and a non-transitory memory storing instructions. The instructions cause the processor to determine scale factors from the encoded bitstream and recursively filter the degraded tiles using the scale factors to obtain recovered tiles. The scale factor determines how strongly edges in the degraded tile affect the filtering operation.
Optionally, determining the scaling factor may include: decoding a range filter variance from the encoded bitstream; and calculating a scale factor using the range filter variance and the spatial domain filter variance.
Optionally, the spatial domain filter variance is
Optionally, recursively filtering the degradation tiles using the scale factors includes: determining weights including row weights and column weights using scale factors; performing left-to-right filtering using row weights; performing right-to-left filtering using row weights; performing top-down filtering using column weights; and performing bottom-up filtering using the column weights.
It should be noted that any of the features described above may be used with any particular aspect or embodiment of the present invention.
These and other aspects of the disclosure are disclosed in the following detailed description of the embodiments, the appended claims and the accompanying drawings.
Drawings
The description herein makes reference to the accompanying drawings wherein like reference numerals refer to like parts throughout the several views unless otherwise specified.
Fig. 1 is a schematic diagram of a video encoding and decoding system.
Fig. 2 is a block diagram of an example of a computing device that may implement a transmitting station or a receiving station.
Fig. 3 is a diagram of a video stream to be encoded and subsequently decoded.
Fig. 4 is a block diagram of an encoder according to an embodiment of the present disclosure.
Fig. 5 is a block diagram of a decoder according to an embodiment of the present disclosure.
Fig. 6 is a flowchart of a process for recovering a degraded tile of a degraded frame at an encoder according to an embodiment of the present disclosure.
Fig. 7 is a flowchart of a process for recursively filtering a degradation tile according to an embodiment of the present disclosure.
Fig. 8 is a diagram of recursive filtering of a 3 x 3 pixel tile according to an embodiment of the present invention.
Fig. 9 is a flowchart of a process for recovering a degraded frame at a decoder according to an embodiment of the present disclosure.
Detailed Description
As described above, compression schemes associated with compiling video streams may include dividing an image into blocks and generating a digital video output bitstream using one or more techniques to limit the information included in the output. The received bitstream may be decoded to recreate the block and source images from the limited information. Encoding a video stream or a portion thereof, such as a frame or block, may include using temporal and spatial similarities in the video stream to improve coding efficiency. For example, a current block of a video stream may be encoded based on identifying differences (residuals) between previously compiled pixel values and pixel values in the current block. In this way, only the residual and parameters used to generate it need be added to the bitstream, rather than including the entire current block. The residual may be encoded using a lossy quantization step. Decoding (i.e., reconstructing) a coded block from such a residual typically results in distortion between the original block and the reconstructed block.
The post-reconstruction loop filter may be used in various ways to improve the reconstructed frame that may be distorted or distorted by the encoding and decoding process. For example, an in-loop deblocking filter may be used to modify pixel values near boundaries between blocks to limit the visibility of those boundaries within a reconstructed frame. For example, other loop filters may be used to bring the reconstructed image closer to the source image by adding an offset, e.g., determined at the encoder, to the pixel values of the reconstructed frame. Such loop filters may operate in a blind setting (i.e., without accessing the source frame and its associated reconstructed frame).
According to the teachings herein, access to the source and reconstructed frames at the encoder allows the encoder to send information that can direct the decoder to achieve superior recovery. Therein, restoration using a domain transform recursive filter is described. The domain transform recursive filter transforms the reconstructed frame from the pixel domain to a different domain (e.g., gradient domain) and applies the edge preserving smoothing filter continuously in the different domain. The domain transform recursive filter may result in edge-preserving denoised frames (i.e., recovery frames) that are closer to the source frame than the reconstructed frames. That is, the difference between the recovery frame and the source frame may be smaller than the difference between the source frame and the reconstructed frame. The recovery frame is smoothed without edges and the edges are preserved (i.e., the edges are not smoothed to any significant extent). The recovery parameters of the frame difference based filter formula may be encoded and signaled to the decoder. The recovery described herein may be implemented in a switchable recovery framework that refers to the ability to switch between different recovery techniques or types for different portions of a reconstructed frame. Using the techniques described herein, various systematic errors (such as DC offset in flat areas of the frame) or color deviations may be removed or at least partially compensated for so that the restored image may be closer to the source image.
Restoration using a domain transform recursive filter is described herein first with reference to a system that may incorporate the present teachings. As described above, in the recovery herein, frames may be recovered in one or more portions. Each of these portions is referred to herein as a "tile," respectively, wherein tiles may or may not overlap each other. Tiles may or may not correspond to boundaries of blocks described herein, but the encoding and decoding of blocks described herein also applies to tiles.
Fig. 1 is a schematic diagram of a video encoding and decoding system 100. The transfer station 102 may be, for example, a computer having an internal configuration such as the hardware depicted in fig. 2. However, other suitable implementations of the transfer station 102 are possible. For example, the processing of the transfer station 102 may be distributed among multiple devices.
The network 104 may connect a transmitting station 102 and a receiving station 106 for encoding and decoding of video streams. In particular, the video stream may be encoded in the transmitting station 102 and the encoded video stream may be decoded in the receiving station 106. The network 104 may be, for example, the internet. The network 104 may also be a Local Area Network (LAN), wide Area Network (WAN), virtual Private Network (VPN), cellular telephone network, or any other means of delivering video streams from the transmitting station 102 to the receiving station 106 in this example.
In one example, the receiving station 106 may be a computer having an internal configuration such as the hardware depicted in fig. 2. However, other suitable implementations of the receiving station 106 are possible. For example, the processing of the receiving station 106 may be distributed among multiple devices.
Other implementations of the video encoding and decoding system 100 are possible. For example, embodiments may omit network 104. In another embodiment, the video stream may be encoded and then stored for transmission to the receiving station 106 or any other device having memory at a later time. In one embodiment, the receiving station 106 receives the encoded video stream (e.g., via the network 104, a computer bus, and/or some communication paths) and stores the video stream for later decoding. In an example embodiment, real-time transport protocol (RTP) is used to transport encoded video over network 104. In another embodiment, a transport protocol other than RTP may be used, such as a hypertext transfer protocol (HTTP) based video streaming protocol.
For example, when used in a video conferencing system, the transmitting station 102 and/or the receiving station 106 may include the capability to encode and decode video streams as described below. For example, the receiving station 106 may be a video conference participant that receives the encoded video bitstream from a video conference server (e.g., the transmitting station 102) to decode and view, and further encodes and transmits its own video bitstream to the video conference server for decoding and viewing by other participants.
Fig. 2 is a block diagram of a computing device 200 in which a transmitting station or a receiving station may be implemented. For example, computing device 200 may implement one or both of transmitting station 102 and receiving station 106 of fig. 1. Computing device 200 may be in the form of a computing system including multiple computing devices, or may be in the form of a single computing device, such as a mobile phone, tablet, laptop, notebook, desktop, and the like.
Processor 202 in computing device 200 may be a central processing unit. In the alternative, processor 202 may be any other type of device or devices capable of manipulating or processing information that is present or developed in the future. Although the disclosed embodiments may be implemented with a single processor, such as processor 202, as shown, multiple processors may be used to achieve speed and efficiency advantages.
In an implementation, the memory 204 in the computing device 200 may be a Read Only Memory (ROM) device or a Random Access Memory (RAM) device. Any other suitable type of storage device may be used as memory 204. Memory 204 may include code and data 206 that is accessed by processor 202 using bus 212. Memory 204 may further include an operating system 208 and application programs 210, with application programs 210 including at least one program that allows processor 202 to perform the methods described herein. For example, application 210 may include applications 1 through N, which further include a video compilation application that performs the methods described herein. Computing device 200 may also include secondary storage 214, which secondary storage 214 may be, for example, a memory card for use with mobile computing device 200. Because video communication sessions may contain a large amount of information, they may be stored in whole or in part in secondary storage 214 and loaded into memory 204 for processing as needed.
Computing device 200 may also include one or more output devices, such as a display 218. The display 218 may be, in one example, a touch sensitive display that combines the display with touch sensitive elements operable to sense touch inputs. A display 218 may be coupled to the processor 202 via the bus 212. In addition to or as an alternative to display 218, other output devices may be provided that allow a user to program or otherwise use computing device 200. When the output device is or includes a display, the display may be implemented in a variety of ways, including by a Liquid Crystal Display (LCD), a Cathode Ray Tube (CRT) display, or a Light Emitting Diode (LED) display, such as an Organic LED (OLED) display.
Computing device 200 may also include or be in communication with an image sensing device 220, image sensing device 220 being, for example, a camera, or any other image sensing device 220 now present or developed in the future that may sense images such as images of a user operating computing device 200. The image sensing device 220 may be positioned such that it is directed to a user operating the computing device 200. In an example, the position and optical axis of the image sensing device 220 may be configured such that the field of view includes an area directly adjacent to the display 218 and from which the display 218 is visible.
Computing device 200 may also include or be in communication with a sound sensing device 222, sound sensing device 222 being, for example, a microphone or any other sound sensing device now existing or developed in the future that may sense sound in the vicinity of computing device 200. The sound sensing device 222 can be positioned such that it is directed to a user operating the computing device 200 and can be configured to receive sound, such as speech or other utterances, emitted by the user while the user is operating the computing device 200.
Although fig. 2 illustrates the processor 202 and memory 204 of the computing device 200 as being integrated as a single unit, other configurations may be utilized. The operations of processor 202 may be distributed across multiple machines (each machine having one or more processors) that may be coupled directly or across a local or other network. The memory 204 may be distributed across multiple machines, such as network-based memory or memory in multiple machines performing the operations of the computing device 200. Although depicted as a single bus, the bus 212 of the computing device 200 may be comprised of multiple buses. Further, secondary storage 214 may be directly coupled to other components of computing device 200 or may be accessible via a network and may include a single integrated unit such as a memory card or multiple units such as multiple memory cards. Computing device 200 may thus be implemented in a variety of configurations.
Fig. 3 is a diagram of an example of a video stream 300 to be encoded and subsequently decoded. Video stream 300 includes video sequence 302. At the next level, the video sequence 302 includes a plurality of adjacent frames 304. Although three frames are depicted as adjacent frames 304, video sequence 302 may include any number of adjacent frames. Adjacent frames 304 may then be further subdivided into individual frames, such as frame 306. At the next level, the frame 306 may be subdivided into a series of segments 308 or planes. For example, segment 308 may be a subset of frames that allow parallel processing. Segment 308 may also be a subset of frames that may separate video data into separate colors. For example, a frame 306 of color video data may include a luminance plane and two chrominance planes. The segment 308 may be sampled at different resolutions.
Whether or not frame 306 is divided into segments 308, frame 306 may be further subdivided into blocks 310, and blocks 310 may contain data corresponding to, for example, 16 x 16 pixels in frame 306. Block 310 may also be configured to include data from one or more segments 308 of pixel data. The block 310 may also be any other suitable size, such as 4 x 4 pixels, 8 x 8 pixels, 16 x 8 pixels, 8 x 16 pixels, 16 x 16 pixels, or larger.
Fig. 4 is a block diagram of an encoder 400 according to an embodiment of the present disclosure. As described above, the encoder 400 may be implemented in the transmitting station 102, such as by providing a computer software program stored in a memory, e.g., the memory 204. The computer software program may include machine instructions that, when executed by a processor, such as processor 202, cause the transmitting station 102 to encode video data in the manner described herein. Encoder 400 may also be implemented as dedicated hardware included in, for example, transmission station 102. The encoder 400 has the following stages to perform various functions in the forward path (shown by the real connection) to produce an encoded or compressed bitstream 420 using the video stream 300 as input: an intra/inter prediction stage 402, a transform stage 404, a quantization stage 406, and an entropy coding stage 408. Encoder 400 may also include a reconstruction path (shown by dashed connection lines) to reconstruct the encoded frames for future blocks. In fig. 4, the encoder 400 has the following stages performing various functions in the reconstruction path: a dequantization stage 410, an inverse transformation stage 412, a reconstruction stage 414, and a loop filtering stage 416. Other structural variations of encoder 400 may be used to encode video stream 300.
When video stream 300 is presented for encoding, frames 306 may be processed in units of blocks. In the intra/inter prediction stage 402, blocks may be encoded using intra (intra) prediction (also referred to as intra (intra) prediction) or inter (inter-frame) prediction (also referred to as inter (inter) prediction) or a combination of both. In any case, a prediction block may be formed. In the case of intra prediction, all or a portion of the prediction block may be formed of samples in the current frame that have been previously encoded and reconstructed. In the case of inter prediction, all or part of the prediction block may be formed from samples in one or more previously constructed reference frames determined using motion vectors.
Next, still referring to fig. 4, a prediction block may be subtracted from the current block at an intra/inter prediction stage 402 to produce a residual block (also referred to as a residual). The transform stage 404 transforms the residual into transform coefficients in, for example, the frequency domain using a block-based transform. Such block-based transforms include, for example, discrete Cosine Transforms (DCTs) and Asymmetric Discrete Sine Transforms (ADSTs). Other block-based transforms are also possible. Furthermore, a combination of different transforms may be applied to a single residual. In one example of applying the transform, the DCT transforms the residual block into the frequency domain where the transform coefficient values are based on spatial frequencies. The lowest frequency (DC) coefficient is at the upper left corner of the matrix and the highest frequency coefficient may be at the lower right corner of the matrix. It is noted that the size of the prediction block and thus the residual block may be different from the size of the transform block. For example, the prediction block may be divided into smaller blocks to which separate transforms are applied.
The quantization stage 406 converts the transform coefficients into discrete quantization values, referred to as quantized transform coefficients, using a quantizer value or quantization level. For example, the transform coefficients may be divided by the quantizer values and truncated. The quantized transform coefficients are then entropy encoded by an entropy encoding stage 408. Entropy coding may be performed using any of a variety of techniques, including tokens and binary trees. The entropy encoded coefficients are then output to the compressed bitstream 420 along with other information for decoding the block including, for example, the type of prediction used, the transform type, the motion vector, and the quantizer values. The information used to decode the blocks may be entropy compiled into blocks, frames, slices, and/or segment headers within the compressed bitstream 420. The compressed bitstream 420 may also be referred to as an encoded video stream or an encoded video bitstream, and these terms are used interchangeably herein.
The reconstruction path (shown by the dashed connection) in fig. 4 may be used to ensure that the encoder 400 and decoder 500 (described below) use the same reference frames and blocks to decode the compressed bitstream 420. The reconstruction path performs functions similar to those that occur during the decoding process described in more detail below, including dequantizing the quantized transform coefficients at dequantization stage 410 and inverse transforming the dequantized transform coefficients at inverse transform stage 412 to produce a block of derived residuals (also referred to as a derived residual). At the reconstruction stage 414, the prediction block predicted at the intra/inter prediction stage 402 may be added to the derived residual to create a reconstructed block. Loop filtering stage 416 may be applied to the reconstructed block to reduce distortion such as blocking artifacts.
Other variations of encoder 400 may be used to encode compressed bit stream 420. For example, the non-transform based encoder 400 may directly quantize the residual signal without the transform stage 404 for some blocks or frames. In another embodiment, encoder 400 may combine quantization stage 406 and dequantization stage 410 into a single stage. Additionally or alternatively, encoder 400 includes deblocking filter stages in addition to loop filter stage 416, or the functions of these filter stages may be combined.
Fig. 5 is a block diagram of a decoder 500 according to an embodiment of the present disclosure. Decoder 500 may be implemented in receiving station 106, for example, by providing a computer software program stored in memory 204. The computer software program may include machine instructions that, when executed by a processor, such as processor 202, cause receiving station 106 to decode video data in a manner described below. Decoder 500 may also be implemented in hardware included in, for example, transmitting station 102 or receiving station 106.
Similar to the reconstruction path of encoder 400 discussed above, decoder 500 includes the following stages in one example to perform various functions to produce output video stream 516 from compressed bitstream 420: an entropy decoding stage 502, a dequantization stage 504, an inverse transform stage 506, an intra/inter prediction stage 508, a reconstruction stage 510, a loop filter stage 512, and a deblocking filter stage 514. Other structural variations of decoder 500 may be used to decode compressed bit stream 420.
When the compressed bit stream 420 is presented for decoding, data elements within the compressed bit stream 420 may be decoded by the entropy decoding stage 502 to produce a set of quantized transform coefficients. Dequantization stage 504 dequantizes the quantized transform coefficients (e.g., by multiplying the quantized transform coefficients by a quantizer value), and inverse transform stage 506 inverse transforms the dequantized transform coefficients using the selected transform type to produce a derivative residual, which may be the same as the derivative residual created by inverse transform stage 412 in encoder 400. Using header information decoded from compressed bitstream 420, decoder 500 may use intra/inter prediction stage 508 to create the same prediction block as created in encoder 400, for example, at intra/inter prediction stage 402. At the reconstruction stage 510, the prediction block may be added to the derived residual to create a reconstructed block. The loop filter stage 512 may be applied to the reconstruction block to reduce distortion as described below. Other filtering may be applied to the reconstructed block. In this example, deblocking filter stage 514 is applied to reconstructed blocks to reduce blocking artifacts, and the results are output as output video stream 516. The output video stream 516 may also be referred to as a decoded video stream, and the terms are used interchangeably herein.
Other variations of decoder 500 may be used to decode compressed bit stream 420. For example, decoder 500 may generate output video stream 516 without deblocking filter stage 514. In some implementations of decoder 500, deblocking filter stage 514 is applied prior to loop filter stage 512 and, therefore, prior to filtering as described herein. The functions of the filtering stages may be combined in a single stage.
Fig. 6 is a flowchart of a process 600 for recovering a degraded tile of a degraded frame at an encoder according to an embodiment of the present disclosure. Process 600 may be implemented in an encoder, such as encoder 400, and may be implemented as, for example, a software program that may be executed by a computing device, such as transmitting station 102. The software program may include machine readable instructions that may be stored in a memory, such as memory 204 or secondary storage 214, and that may be executed by a processor, such as processor 202, to cause the computing device to perform process 600. In at least some implementations, the process 600 may be performed in whole or in part by the loop filtering stage 416 of the encoder 400. Process 600 may be performed in whole or in part after loop filtering stage 416 of encoder 400.
Process 600 may be implemented using dedicated hardware or firmware. Some computing devices may have multiple memories, multiple processors, or both. Different processors, memories, or both may be used to distribute the steps or operations of process 600. The term "processor" or "memory" in the singular encompasses a computing device having one processor or one memory and a device having multiple processors or multiple memories that may be used in performing some or all of the described steps.
Although not explicitly shown, the process 600 first receives degraded tiles of the corresponding source tiles of the source frame. The degradation tiles may be all or part of a reconstructed frame, e.g., from a reconstruction loop of an encoder. That is, the degraded tile may be co-extensive (co-extensive) with the reconstructed frame, or may be smaller than the reconstructed frame. In some examples, a degradation tile may include a plurality of blocks. The degradation tile may be a segment 308. The reconstructed frame is referred to herein as a degraded frame in order to distinguish it from the final reconstructed (i.e., recovered) frame after filtering. For example, all or a portion of the degraded frame may be received from the reconstruction stage 414 at the loop filtering stage 416 of the encoder 400. The degraded frames from the reconstruction stage 414 may be deblocked before the process 600 occurs.
The process 600 may receive an entire degraded frame and divide the frame into one or more degraded tiles, or may receive degraded tiles divided at a previous stage of the encoder. That is, the process 600 may divide the degraded frame into blocks. Alternatively, the process 600 processes any unit of a received frame (whether a tile or the frame itself).
The size of each tile may be selected based on a tradeoff between the location of the degraded frame's statistical properties and the number of bits to be used in the encoded bitstream. For example, if a smaller tile size is selected, better positioning may be achieved; however, a degraded frame may be encoded using a higher number of bits. Alternatively, the tile size may be selected independently of the statistical properties of the frame, such as by referencing a degraded frame size. For example, if the frame size is greater than 256x256 pixels, the tile size may be set to 256x256 pixels; otherwise, the tile size is set to 120x120 pixels. The tile size may be selected based on the frame size exceeding a threshold. The tile size may be set to the size of the frame such that the frame includes only one tile. Other ways of selecting tile sizes may be used with embodiments of the present disclosure. Thus, for example, the process 600 may receive the reconstructed frame and divide it into tiles. The process 600 may select the size (i.e., the first size) of the degraded tile based on the size (i.e., the second size) of the degraded frame. As described above, if the second size is greater than 256×256 pixels, the process 600 may set the first size to 256×256 pixels. If the second size is less than or equal to 256×256 pixels, the process 600 may set the first size to 120×120 pixels. Setting the tile size may refer to dividing the reconstructed (i.e., degraded) frame into tiles such that at least one tile has a tile size.
The process 600 determines an optimal scale factor s for domain transform recursive filtering of the degraded tile. The optimal scaling factor is determined by testing several scaling factors. The optimal scale factor is the scale factor of the recovered tile that is closest to the source tile among several scale factors. The scaling factor s may be a function of two parameters: the desired filter variance over the spatial domain (i.e., pixel locations of pixels of the degraded tile) and the desired filter variance over the signal range (i.e., the range of pixel values and/or color component values of the degraded tile). The desired filter variance in the spatial domain can be determined by the spatial domain standard deviation sigma s Indicating that it controls the spatial size of the filter kernel. The desired filter variance in this range is determined by the signal range standard deviation sigma r Indicating how strongly the edges affect the filtering operation. The scale factor s is given by equation (1):
S＝σ s /σ r (1)
while the value of each of these variables may be altered, fixing one variable to a particular value may enable simpler computation. That is, the scale factor may be selected by fixing one of the filter of the spatial domain and the filter variance over the range of pixel values of the degradation tile and changing the other. In the examples herein, the spatial domain standard deviation σ s Is fixed and the standard deviation sigma of the test signal range r To determine which signal range standard deviation sigma r And obtaining the optimal recovery block. For example, the spatial domain standard deviation sigma s Can be set equal toThe standard deviation sigma of the signal range to be tested can be selected from a limited number of values r Is a value of (2). Due to the standard deviation sigma of the signal range r May fall along a continuum that includes non-integers and may therefore be quantized to any number of values, such as 32, 128, 64 or more or less. The quantization level may depend on the encodingStandard deviation sigma of signal range in coded bit stream where the code is to be received by decoder r Available number of bits of the value of (c). For example, if 6 bits are available, the signal range standard deviation σ can be tested r Is a constant value of 64. Alternatively, different scaling factors s may be selected such that the signal range standard deviation σ r And (3) a change.
At 602, the process 600 determines if more scale factors are available to test the current degradation tile from the plurality of scale factors. If more values are available, process 600 selects a value and control passes to 604; otherwise control passes to 608. The selection ratio value may refer to the selection signal range standard deviation sigma r Is a value of (2). Process 600 may exhaustively test the signal range standard deviation sigma r Is included in the set of possible quantized values. That is, if 64 values are available, each of the 64 values is tested. Alternatively, the process 600 may test some of the possible quantized scale factors. For example, process 600 may perform a segmentation (i.e., coarse search) algorithm. In some implementations, the process 600 can test each eighth value. From the test values, the process 600 selects the value of the optimal restoration tile and continues searching around the selected value. Alternatively, instead of the search range standard deviation sigma r The process 600 may select the scale factor s from a defined plurality of values.
At 604, the process 600 recursively filters the degraded tiles, resulting in recovered tiles. In the examples herein, recursive filtering is performed using techniques described in part in Edurado S.L, gastal, and Manuel Oliveira, "Domain transform for Edge-Aware Image and Video Processing," at ACM Transactions on Graphics, volume 30 (2011), stage 4, proceedings of SIGGRAPH 2011, article 69, the entire contents of which are incorporated herein by reference.
Fig. 7 is a flowchart of a process 700 for recursively filtering a degradation tile according to an embodiment of the present disclosure. The process 700 illustrates an embodiment of recursively filtering a degradation tile at 604 of the process 600 of fig. 6. The inputs to process 700 may include a scale factor, a range standard deviation sigma r Standard deviation sigma of space domain s Or a combination thereof.The process 700 transforms tiles from the pixel domain to the gradient domain, performs recursive operations on the transformed tiles, and converts tiles back to the pixel domain. Process 700 repeats for T iterations (i.e., a predetermined number of iterations). Each iteration consists of two parts as follows: a row filtering operation section and a column filtering operation section. For the number of iterations in the predetermined number of iterations, the process 700 may determine row weights using the scaling factor and the number of iterations, perform row filtering operations on the rows of the degraded tile, determine column weights using the scaling factor and the number of iterations, and perform column filtering operations on the columns of the degraded tile.
Process 700 applies a one-dimensional (1D) filter along each dimension of the image block. One row of horizontal sizes is processed at a time. One column of vertical dimensions is processed at a time. It is desirable to use several passes (i.e., iterations) in order to eliminate visual effects, such as streak effects, in the restored tile. Processing in alternating dimensions. For example, the horizontal dimension of a pass or iteration is processed before the vertical dimension. While the passes may be more or less than three times, three passes have been observed to produce acceptable results.
In each iteration, the process 700 processes tiles row by row. For each row, process 700 applies a left-to-right filtering operation, followed by a right-to-left filtering operation. The process 700 then processes the tiles column by column. For each column, process 700 applies a top-to-bottom filtering operation, followed by a bottom-to-top filtering operation. The result of the filtering operation is applied for use in applying the next filtering operation. Process 700 is described with reference to fig. 8.
Fig. 8 is a diagram 800 of recursive filtering of a 3 x 3 pixel tile according to an embodiment of the present invention. Fig. 8 shows a degradation tile 802. The process 700, when complete, generates a resume tile 828. As described above, the recovery block 828 may replace the degraded block 802 with a reconstructed block.
At 702, process 700 determines if more iterations are available. If all iterations have been performed, process 700 ends at 718; otherwise, the process 700 proceeds to 706 to determine if there are any rows in the current degraded tile to be filtered in the current iteration. As described above, process 700 may be performed for a defined (e.g., predetermined) number T of iterations. Although process 700 is described below as first performing filtering in a certain direction (i.e., horizontally and row-by-row), this is not necessarily the case. For example, process 700 may first perform column-wise filtering before performing row-wise filtering.
For each row in the degradation tile, the process 700 performs 708-710. While the degradation tile 802 in FIG. 8 is shown as having three (3) rows, in this example, the process 700 is performed 708-710 three (3) times.
At 708, process 700 determines row weights for rows that are the object of the current iteration. The row weight is defined by weight a n，i Given, where n corresponds to the pixel location and i corresponds to the number of iterations of the current iteration. The filtering operation described herein depends on the weight a n，i . In some filtering techniques, the filter coefficients (i.e., weights) may be constant for each pixel. However, as described below, the filtering weights a herein n，i According to the gradient d at pixel position n n And the number of iterations i.
The filtering operation is performed in the gradient domain as described below. Design a n，i So that even if the filtering operation is performed in the gradient domain, the values of the restoration tiles remain in the pixel domain at the end of the process 700. Row weight a n，i Using equation (2) to determine:
in equation (2), s is the scale factor selected at 602 of FIG. 6, gradient d n Is an estimate of the local gradient at the nth pixel position of the 1D signal to be filtered, i is the number of iterations of 702, and a i Is the iterative filter standard deviation. Standard deviation a of iterative filter i Given by equation (4). In the examples described herein, gradient d, although other metrics and/or values of gradient may be used n Is I [ n ]](i.e., the pixel value of the pixel at the nth position of the row) and I [ n-1 ] in the filtering direction]The absolute pixel difference (i.e., the pixel value of the pixel at the (n-1) th position of the same row) is given as equation (3).
d n ＝|I[n]-I[n-1]| (3)
In another example, the distance L between pixels may be used when determining the gradient. For example, gradient d n It may be an absolute pixel difference of the pixel at the nth position of the row and the (n-L) th position of the same row in the filtering direction.
Now the calculated gradient d is given n Is an example of (a). For the pixel at pixel location 804 of FIG. 8, and when a left-to-right filter is applied, gradient d n (e.g., horizontal gradient) given by equation 806 as d n ＝|X 0,1 –X 0,0 | a. The invention relates to a method for producing a fibre-reinforced plastic composite. Equation 806 uses the pixel value of the pixel at pixel location 804 and the value of the pixel immediately to the left of pixel location 804. The result of applying the left to right filter operation is block 808. A right-to-left filtering operation is then applied using block 808. For a pixel at pixel location 810 (i.e., the same pixel location as pixel location 804), gradient d is given by equation 812 n (e.g., horizontal gradient) of d n ＝|Y 0,1 –Y 0,2 | a. The invention relates to a method for producing a fibre-reinforced plastic composite. Equation 812 uses the value of the pixel at pixel location 810 and the value of the pixel immediately to the right of pixel location 810. Block 814 is the result of applying the right-to-left filtering operation. Equation 820d n ＝|X 1,1 –X 0,1 I shows the gradient d determined for the pixel at pixel location 818 of tile 816 when performing the top-down filtering operation n (e.g., vertical gradient). Equation 820 uses the value of the pixel at pixel location 818 and the value of the pixel directly above pixel location 818. Block 822 is the result of applying the top-to-bottom filtering operation. Equation 826d n ＝|Y 1,1 –Y 2,1 I shows that when performing a bottom-up filtering operation, a gradient d is determined for the pixel at pixel location 824 of tile 822 n (e.g., vertical gradient). Equation 826 uses the value of the pixel at pixel location 824 and the value of the pixel directly below pixel location 824.
Gradient d as described above n Is a measure of the gradient at the pixel position relative to the previous pixel position in the filtering direction. A high gradient value may indicate that there is a tile at the pixel locationAt the edges. Thus, the weight a at the pixel position n，i May be designed to have edge preserving effects (i.e., less filtering). When the gradient value is small, more filtering (i.e., smoothing) can be performed.
As described above, the iterative filter standard deviation a of the ith iteration (e.g., for the iteration coefficient) i Given by equation (4):
in equation (4), T is the number of iterations, i is the number of iterations, and σ s Is the spatial domain standard deviation.
Weight a n，i May be included in the lookup table such that the determination of row weights is determined at 708 from the lookup table, rather than being calculated. By pre-calculating the weights a n，i And they are compared with the standard deviation sigma for the range r Index of possible values, number of iterations, and gradient d n Stored together with possible values to generate a look-up table. Assume, but not limited to, that the pixel values of the degradation tile (e.g., degradation tile 802) are at [0, 255]In range (i.e., for 8-bit content), then gradient d n The value is also 0, 255]In the range. That is, gradient d n There are also 256 possible values. As described above, the range standard deviation sigma r In an example there may be 64 values. Furthermore, in the above example, there is a defined number T of iterations, where three (3) passes or 3 iterations are sufficient. In this case, the lookup table may include a table for weight a n，i Of 49, 152 (range standard deviation sigma r The 64 possible values multiplied by 3 iterations times the gradient d n 256 possible values of (c). This is a relatively small table in a codec application that can be shared with both the encoder and the decoder.
At 708, process 700 may obtain a range standard deviation σ r And the number of iterations. To find the weight a n，i Process 700 determines (i.e., calculates) gradient d n Values. Process 700 then uses the calculated gradient d n Value, iteration number i and range standard deviation sigma r Looking up the weight a in the lookup table n，i Is a value of (2). Weight a n，i May be mapped to an integer domain and stored as an integer in a lookup table.
After determining the row weights at 708, process 700 performs row filtering at 710. The row filtering operation includes a left-to-right filtering operation followed by a right-to-left filtering operation applied to each pixel of the row. The left to right filtering operation applies equation (5) to the pixels of the row of the degraded tile 802 of FIG. 8, resulting in the intermediate y [ n ] value of the tile 808 of FIG. 8.
y[0]＝x[0]；y[n]＝(1-a n，i )x[n]+a n，i y[n-1]，n＝1，2，...，N-1(5)
In equation (5), the row index is omitted. For example, when processing the second row, Y [0] corresponds to Y [1,0] in block 808 of FIG. 8, X [0] corresponds to X [1,0] in the degraded block 802, X [ n ] corresponds to X [1, n ], and so on. The first intermediate value y [0] is set to be the same as the first value x [0] of the degraded frame. The subsequent y n value is a recursively filtered version of the x n value and the previously calculated filtered y n-1 value.
The right-to-left filtering operation is performed using the results of the left-to-right filtering operation. That is, the right-to-left filtering operation uses block 808 of fig. 8. The right-to-left operation applies equation (6) to the pixels of the row of block 808.
z[N-1]＝y[N-1]；z[7n]＝(1-a n，i )y[n]-a n，i z[n+1]，n＝N-2，...，0(6)
It can be observed from equations (2) - (6) that when the gradient d at pixel n n When high, the weight a of the pixel n，i The value of (2) is also high. In this case, the filters of equations (5) and (6) produce a filter that selects more pixels themselves and fewer previously filtered pixels to include in the resulting filtered pixel values (i.e., pixel values weighted higher than the previously filtered pixels). Thus, a higher gradient d n Has edge retaining effect. On the other hand, when the gradient value d n For an hour, then more values of the previously filtered pixel are included in the resulting filtered pixel. That is, smoothingThe resulting pixel values.
When the line filtering at 710 is complete, process 700 returns to 706 to determine if there are remaining lines to filter in the current iteration. When all rows of the degraded tile are processed in response to the query at 706, the process 700 proceeds to 712 to determine if there are more columns left to filter in the current iteration. In 712-716, process 700 performs operations similar to those described with respect to 706-710. That is, in a similar manner to determining the row weights at 708, the column weights are determined at 714, and the top-to-bottom and bottom-to-top column filtering is performed in a similar manner to the row filtering at 710.
While the degraded tile 802 is used as the starting tile for the initial row at 708, the tile 814 is used as the starting tile for the initial column at 714. This is indicated by dashed line 830 in fig. 8. That is, tile 814 and tile 816 are identical. While tiles 802, 814, 816, and 828 of fig. 8 are illustrated as separate tiles, the same memory may be used for the X and Z values. That is, the calculated z [ n ] value replaces the corresponding x [ n ] value. Upon completion of the process 700, block 828 constitutes a recovery block of the degraded block 802 of FIG. 8.
Block 828 of fig. 8 is the result of completing a single iteration of process 700. Block 828 of fig. 8 is used as the degraded block 802 of fig. 8 in the next iteration of the process 700. And upon completion of all iterations of the process 700, the resulting tiles constitute a recovery tile.
Other filtering techniques, such as filtering techniques using bilateral filters, may require windows for the pixels being processed. This can lead to complex and expensive processes. In contrast, each of the left-to-right, right-to-left, top-to-bottom, and bottom-to-top filtering operations described herein is a simple operation that does not require more values than the previous pixel. In this way, embodiments according to the present disclosure result in a simple and inexpensive process.
Returning to the process 600 in FIG. 6, at 606, an error to recover the tile is determined. An error between the source tile and the recovered tile is determined. The error may be a mean square error between co-located pixel values of the corresponding tiles. The error may be the sum of absolute difference errors between co-located pixel values of the corresponding tiles. Any other suitable error measurement may be used. Process 600 then returns to 602 to determine if any other scale factors are available for testing. If so, the recursive filtering at 604 and the determining error at 606 are repeated until there are no additional scale factors to be tested.
Once all scale factors have been tested in the filtering process, process 600 proceeds to 608. At 608, the process 600 selects a scale factor from among the available scale factors for loop filtering. For example, the process 600 may select the scale factor of the plurality of scale factors that results in the smallest error. Another value of the optimal scaling factor of the plurality of scaling factors tested may be selected as long as it yields a relatively small error compared to the other values of error.
At 610, the process 600 encodes the scale parameters in the encoded bitstream based on the optimal scale factor. For example, process 600 may quantize and encode the signal range standard deviation σ corresponding to the optimal scaling factor r (i.e., an unfixed one of the parameters). Alternatively, the process 600 may quantize and encode the scale factor s.
When the process 600 is performed in whole or in part by the loop filtering stage 416 of the encoder 400, the reconstructed image formed by the reconstructed blocks (in the case of multiple tiles for a degraded image) may be used to predict a subsequent frame.
When the degradation frame is formed of a plurality of degradation tiles, each degradation tile of the plurality of degradation tiles may be restored based on a different restoration type. For example, other possible recovery types besides the above-described domain transform recursive filtering may include filters based on filtering and subspace projection bootstrap filters, wiener filters, or bilateral filters. For example, multiple recovery types may be tested and the results compared to determine which yields the smallest error between the source tile and the recovery tile. When multiple recovery types are available, the recovery type of the current tile may also be encoded into the bitstream at 610.
Parameters and optionally recovery types may be encoded into a frame header, slice header, segment header, block header, tile header, or a combination of these headers. The identification of the tiles used in the reconstruction process may also be transmitted within the bitstream. Alternatively, parameters for partitioning may be transmitted within the bitstream so that a decoder, such as decoder 500, may recreate tiles during the decoding process.
The decoder uses the recovery parameters (and recovery type, when available) to obtain the reconstructed tile described with reference to fig. 9.
Fig. 9 is a flowchart of a process 900 for recovering a degraded frame at a decoder according to an embodiment of the present disclosure. Process 900 may be performed by a decoder, such as decoder 500. For example, process 900 may be performed in whole or in part by loop filter stage 512 of decoder 500. Embodiments of process 900 may be performed by storing instructions to be executed by a processor, such as processor 202, in a memory 204, such as receiving station 106.
Process 900 may be implemented using dedicated hardware or firmware. Some computing devices may have multiple memories, multiple processors, or both. Different processors, memories, or both may be used to distribute the steps or operations of process 900. For simplicity of explanation, the process 900 is shown and described as a series of steps or operations. However, various sequences and/or concurrences may be made in accordance with the teachings of the present disclosure. Additionally, steps according to the present disclosure may occur with other steps not presented and described herein. Moreover, not all illustrated steps or operations may be employed to implement a method in accordance with the disclosed subject matter.
The process 900 occurs in whole or in part after the decoder generates a degraded tile of the source frame. The degradation tiles may be all or part of a reconstructed frame, e.g., generated by a reconstruction loop of a decoder. That is, the degraded frame may be a frame reconstructed by the decoder. Also, this frame is called a degraded frame in order to distinguish it from the final reconstructed frame after filtering. For example, all or a portion of the degraded frame may be received from the reconstruction stage 510 at the deblocking filter stage 514 of the decoder 500. Decoder 500 may be arranged such that deblocking filter stage 514 precedes loop filter stage 512. Alternatively, another filter stage may be located after the deblocking filter stage 514. In either case, the degraded frames from the reconstruction stage 414 may be deblocked before the process 900 occurs.
At 902, the process 900 determines scale parameters for a degraded tile from an encoded bitstream. The scale parameters may determine how strongly edges in the degraded tile affect the filtering operation as described above. In an example, the scale parameter may be determined by decoding and dequantizing the quantized scale factor from the header into which it is inserted. The scaling parameter may be a scaling factor s as described above. The scale parameter may be the signal range standard deviation sigma r From which the scaling factor can be determined as described above. In an example, determining the scale factor may include decoding a range filter variance from the encoded bitstream and calculating the scale factor using the range filter variance and the spatial domain filter variance. The range filter variance may be or may correspond to an optimal range standard deviation σ determined by the encoder at 608 of process 600 r . In an example, the spatial domain filter variance may be set to a predetermined value, such as
At 904, the degraded tiles are recursively filtered to generate restored tiles. Recursive filtering may be performed according to the process of fig. 7 using the current degradation tile. In an embodiment, process 900 looks up row and column weights in a lookup table similar to that described with reference to 708 of FIG. 7. In an example, recursively filtering the degraded tile using the scale factors may include determining weights including row weights and column weights using the scale factors, performing left-to-right filtering using the row weights, performing right-to-left filtering using the row weights, performing top-to-bottom filtering using the column weights, and performing bottom-to-top filtering using the column weights.
The process 900 of fig. 9 may be repeated as needed, for example, if the degraded frame constitutes more than one tile, until the reconstructed frame is completed to include as part of the output video stream, such as the output video stream 516 of fig. 5.
If a different recovery type is used for the frame, the recovery type of the tile may be decoded from the header that encoded it. If a domain transform recursive filter type is indicated, process 900 occurs. If another recovery type is used, an appropriate filter (e.g., wiener filter or bilateral filter) may be used in the reconstruction process.
The encoding and decoding aspects described above illustrate some encoding and decoding techniques. However, it should be understood that encoding and decoding as those terms are used in the claims may refer to compression, decompression, transformation, or any other processing or variation of data.
The word "example" or "embodiment" is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as "example" or "embodiment" is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the word "example" or "embodiment" is intended to present concepts in a concrete fashion. As used in this application, the term "or" is intended to mean an inclusive "or" rather than an exclusive "or". That is, unless specified otherwise or clear from the context, "X includes A or B" is intended to mean any natural inclusive permutation. That is, if X includes A; x comprises B; or X includes both A and B, then "X includes A or B" is satisfied in any of the foregoing cases. Furthermore, the articles "a" and "an" as used in this application and the appended claims should generally be construed to mean "one or more" unless specified otherwise or clear from context to be directed to a singular form. Furthermore, the use of the terms "embodiment" or "one embodiment" throughout are not intended to denote the same example or embodiment unless so described.
Embodiments of the transmitting station 102 and/or the receiving station 106 (and algorithms, methods, instructions, etc., stored thereon and/or executed by the encoder 400 and decoder 500, among others) may be implemented in hardware, software, or any combination thereof. The hardware may include, for example, a computer, an Intellectual Property (IP) core, an Application Specific Integrated Circuit (ASIC), a programmable logic array, an optical processor, a programmable logic controller, microcode, a microcontroller, a server, a microprocessor, a digital signal processor, or any other suitable circuit. In the claims, the term "processor" should be understood to include any of the foregoing hardware, alone or in combination. The terms "signal" and "data" are used interchangeably. Furthermore, portions of the transmitting station 102 and the receiving station 106 do not necessarily have to be implemented in the same manner.
Furthermore, in one aspect, for example, the transmitting station 102 or the receiving station 106 may be implemented using a general-purpose computer or general-purpose processor with a computer program that, when executed, implements any of the respective methods, algorithms, and/or instructions described herein. Additionally or alternatively, for example, a special purpose computer/processor may be used that may contain other hardware for performing any of the methods, algorithms, or instructions described herein.
The transmitting station 102 and the receiving station 106 may be implemented, for example, on computers in a video conferencing system. Alternatively, the transmitting station 102 may be implemented on a server and the receiving station 106 may be implemented on a device separate from the server, such as a handheld communication device. In this case, the transmitting station 102 may encode the content into an encoded video signal using the encoder 400 and transmit the encoded video signal to the communication device. The communication device may then decode the encoded video signal using decoder 500. Alternatively, the communication device may decode content stored locally on the communication device, such as content that is not transmitted by the transmitting station 102. Other transmit station 102 and receive station 106 implementations are available. For example, the receiving station 106 may be a generally stationary personal computer rather than a portable communication device, and/or a device including the encoder 400 may also include the decoder 500.
Furthermore, all or a portion of the embodiments of the present disclosure may take the form of a computer program product accessible from a tangible computer-usable or computer-readable medium, for example. A computer-usable or computer-readable medium may be any apparatus that can, for example, tangibly contain, store, communicate, or transport the program for use by or in connection with any processor. The medium may be, for example, an electronic, magnetic, optical, electromagnetic or semiconductor device. Other suitable media may also be used.
The foregoing examples, embodiments and aspects have been described in order to facilitate an easy understanding of the present disclosure, and are not limiting of the present disclosure. On the contrary, the disclosure is intended to cover various modifications and equivalent arrangements included within the scope of the appended claims, which scope is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures as is permitted under the law.
Claims (15)
1. A method for recovering a degraded tile of a degraded frame resulting from reconstruction, the method comprising:
for a scale factor of at least some scale factors:
using the scale factor to domain transform recursively filter the degraded tiles to generate corresponding recovered tiles, wherein domain transform recursively filtering the degraded tiles comprises: transforming the degraded tile from a pixel domain to a gradient domain prior to filtering, the gradient domain comprising gradients of pixel values; and
determining a respective error of the respective recovered tile relative to the source tile,
wherein the scale factor is a ratio of a filter variance over a spatial domain of the degraded tile and a filter variance over a range of pixel values of the degraded tile, wherein the filter variance over the spatial domain controls a filter kernel size and the filter variance over the range of pixel values determines how strongly an edge affects a filtering operation; and
Selecting an optimal scale factor from the at least some scale factors, the optimal scale factor corresponding to a minimum corresponding error,
wherein the domain transform recursively filtering the degraded tiles comprises:
for a predetermined number of iterations:
determining row weights using the scale factors and the number of iterations;
performing a recursive row filtering operation on rows of the degraded tile;
determining column weights using the scale factors and the number of iterations; and
a recursive column filtering operation is performed on columns of the degraded tile.
2. The method of claim 1, wherein the predetermined number of iterations is 3.
3. The method of claim 1 or 2, wherein determining the row weight comprises:
the scaling factor, the gradient of pixel values and the number of iterations are used to look up the row weight of a pixel in a look-up table.
4. The method according to claim 1 or 2,
wherein performing the recursive row filtering operation comprises:
performing left-to-right filtering using the row weights; and
performing right-to-left filtering using the row weights, and
wherein performing the recursive column filtering operation comprises:
performing top-to-bottom filtering using the column weights; and
Bottom-up filtering is performed using the column weights.
5. The method of claim 1 or 2, wherein the degraded tile is coextensive with the degraded frame.
6. A method for recovering a degraded tile of a degraded frame resulting from reconstruction, the method comprising:
determining a scale factor from the encoded bitstream, the scale factor comprising a ratio of a spatial domain filter variance and a range filter variance, wherein the spatial domain filter variance controls a filter kernel size and the range filter variance determines how strongly an edge affects a filtering operation; and
recursively filtering the degraded tiles using the scale factor sub-domain transform to obtain restored tiles, wherein applying a domain transform recursive filter using the scale factor comprises: transforming the degraded tile from a pixel domain to a gradient domain prior to filtering, the gradient domain comprising gradients of pixel values, and performing the steps of:
for a predetermined number of iterations:
determining row weights using the scale factors and the number of iterations;
performing a recursive row filtering operation on rows of the degraded tile;
determining column weights using the scale factors and the number of iterations; and
A recursive column filtering operation is performed on columns of the degraded tile.
7. The method of claim 6, wherein the spatial domain filter variance is
8. The method of claim 6, wherein the predetermined number of iterations is 3.
9. The method according to claim 6 to 8,
wherein performing the recursive row filtering operation comprises:
performing left-to-right filtering using the row weights; and
performing right-to-left filtering using the row weights; and
wherein performing the recursive column filtering operation comprises:
performing top-to-bottom filtering using the column weights; and
bottom-up filtering is performed using the column weights.
10. The method of claim 9, wherein determining the row weight comprises looking up the row weight of the pixel in a lookup table using the scale factor and a horizontal gradient at the pixel, and wherein determining the column weight comprises looking up the column weight of the pixel in the lookup table using the scale factor and a vertical gradient at the pixel.
11. The method of any of claims 6 to 8, wherein the degraded tile is coextensive with the degraded frame.
12. An apparatus for recovering a degraded tile of a degraded frame resulting from reconstruction, the apparatus comprising a processor configured to perform operations comprising:
determining a scale factor from the encoded bitstream, the scale factor comprising a ratio of a spatial domain filter variance and a range filter variance, wherein the spatial domain filter variance controls a filter kernel size and the range filter variance determines how strongly an edge affects a filtering operation; and
recursively filtering the degraded tiles using the scale factor sub-domain transform to obtain restored tiles, wherein applying a domain transform recursive filter using the scale factor comprises: transforming the degraded tile from a pixel domain to a gradient domain prior to filtering, the gradient domain comprising gradients of pixel values, and performing the steps of:
for a predetermined number of iterations:
determining row weights using the scale factors and the number of iterations;
performing a recursive row filtering operation on rows of the degraded tile;
determining column weights using the scale factors and the number of iterations; and
a recursive column filtering operation is performed on columns of the degraded tile.
13. The apparatus of claim 12, wherein the spatial domain filter variance is
14. The apparatus of claim 12 or 13,
wherein performing the recursive row filtering operation comprises:
performing left-to-right filtering using the row weights; and
performing right-to-left filtering using the row weights; and
wherein performing the recursive column filtering operation comprises:
performing top-to-bottom filtering using the column weights; and
bottom-up filtering is performed using the column weights.
15. A non-transitory computer readable storage medium storing computer program instructions which, when executed by a computer, cause the computer to perform the method of any one of claims 1 to 11.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202111143037.6A CN113873237B (en) | 2016-12-01 | 2017-09-29 | Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction |
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201662428718P | 2016-12-01 | 2016-12-01 | |
US62/428,718 | 2016-12-01 | ||
PCT/US2017/054331 WO2018102017A1 (en) | 2016-12-01 | 2017-09-29 | Restoration in video coding using domain transform recursive filters |
CN201780067335.7A CN109891894B (en) | 2016-12-01 | 2017-09-29 | Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction |
CN202111143037.6A CN113873237B (en) | 2016-12-01 | 2017-09-29 | Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780067335.7A Division CN109891894B (en) | 2016-12-01 | 2017-09-29 | Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction |
Publications (2)
Publication Number | Publication Date |
---|---|
CN113873237A CN113873237A (en) | 2021-12-31 |
CN113873237B true CN113873237B (en) | 2023-12-29 |
Family
ID=60043399
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780067335.7A Active CN109891894B (en) | 2016-12-01 | 2017-09-29 | Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction |
CN202111143037.6A Active CN113873237B (en) | 2016-12-01 | 2017-09-29 | Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780067335.7A Active CN109891894B (en) | 2016-12-01 | 2017-09-29 | Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction |
Country Status (4)
Country | Link |
---|---|
US (1) | US10757408B2 (en) |
EP (1) | EP3516877B1 (en) |
CN (2) | CN109891894B (en) |
WO (1) | WO2018102017A1 (en) |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20200060589A (en) | 2018-11-21 | 2020-06-01 | 삼성전자주식회사 | System-on-chip having merged frc and video codec and frame rate converting method thereof |
US11044473B2 (en) * | 2018-12-21 | 2021-06-22 | Qualcomm Incorporated | Adaptive loop filtering classification in video coding |
WO2021026361A1 (en) * | 2019-08-06 | 2021-02-11 | Op Solutions, Llc | Adaptive resolution management using sub-frames |
JP2022544164A (en) | 2019-08-06 | 2022-10-17 | オーピー ソリューションズ， エルエルシー | Implicit Signaling of Adaptive Resolution Management Based on Frame Type |
BR112022002204A2 (en) | 2019-08-06 | 2022-10-18 | Op Solutions Llc | ADAPTIVE RESOLUTION MANAGEMENT FORECAST SIZING |
KR20220090493A (en) | 2019-08-06 | 2022-06-29 | 오피 솔루션즈, 엘엘씨 | Block-based adaptive resolution management |
BR112022008918A2 (en) | 2019-11-08 | 2022-08-02 | Op Solutions Llc | METHODS AND SYSTEMS FOR ADAPTABLE CUTTING |
US11743459B2 (en) | 2020-09-29 | 2023-08-29 | Qualcomm Incorporated | Filtering process for video coding |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2249572A1 (en) * | 2008-03-07 | 2010-11-10 | Kabushiki Kaisha Toshiba | Dynamic image encoding/decoding method and device |
WO2011081637A1 (en) * | 2009-12-31 | 2011-07-07 | Thomson Licensing | Methods and apparatus for adaptive coupled pre-processing and post-processing filters for video encoding and decoding |
CN102710936A (en) * | 2011-01-04 | 2012-10-03 | 香港中文大学 | High performance loop filters in video compression |
WO2013047335A1 (en) * | 2011-09-28 | 2013-04-04 | ソニー株式会社 | Image processing device and method |
CN105684448A (en) * | 2012-06-15 | 2016-06-15 | 谷歌技术控股有限责任公司 | Method and apparatus for efficient slice header processing |
Family Cites Families (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DE3116266A1 (en) * | 1981-04-24 | 1982-11-11 | TE KA DE Felten & Guilleaume Fernmeldeanlagen GmbH, 8500 Nürnberg | METHOD FOR EQUALIZING A DATA SIGNAL |
US4652907A (en) * | 1985-03-25 | 1987-03-24 | Rca Corporation | Apparatus for adaptively controlling a video signal recursive filter |
US4698672A (en) * | 1986-10-27 | 1987-10-06 | Compression Labs, Inc. | Coding system for reducing redundancy |
US5150432A (en) * | 1990-03-26 | 1992-09-22 | Kabushiki Kaisha Toshiba | Apparatus for encoding/decoding video signals to improve quality of a specific region |
US5610657A (en) * | 1993-09-14 | 1997-03-11 | Envistech Inc. | Video compression using an iterative error data coding method |
FR2841424A1 (en) * | 2002-06-25 | 2003-12-26 | Koninkl Philips Electronics Nv | METHOD FOR DETECTING BLOCK ARTEFACTS |
US7778480B2 (en) * | 2004-11-23 | 2010-08-17 | Stmicroelectronics Asia Pacific Pte. Ltd. | Block filtering system for reducing artifacts and method |
US8218655B2 (en) * | 2005-09-19 | 2012-07-10 | Maxim Integrated Products, Inc. | Method, system and device for improving video quality through in-loop temporal pre-filtering |
US7885341B2 (en) * | 2005-10-21 | 2011-02-08 | Cisco Technology, Inc. | Spatial filtering for improving compression efficiency of motion compensated interframe coding |
JP4945532B2 (en) * | 2008-09-05 | 2012-06-06 | 株式会社東芝 | Degraded image restoration method, degraded image restoration device, and program |
US20100091127A1 (en) * | 2008-09-30 | 2010-04-15 | University Of Victoria Innovation And Development Corporation | Image reconstruction method for a gradient camera |
BRPI0921986A2 (en) * | 2008-11-25 | 2018-06-05 | Thomson Licensing | methods and apparatus for filtering out sparse matrix artifacts for video encoding and decoding |
US8538114B2 (en) * | 2011-06-06 | 2013-09-17 | Kabushiki Kaisha Toshiba | Method and system utilizing parameter-less filter for substantially reducing streak and or noise in computer tomography (CT) images |
KR101462052B1 (en) * | 2011-11-09 | 2014-11-20 | 에스케이 텔레콤주식회사 | Video Coding Method and Apparatus using Transform Based Fraquency Domain Adaptive Loop Filter |
US20130235931A1 (en) * | 2012-03-06 | 2013-09-12 | Apple Inc. | Masking video artifacts with comfort noise |
US9641729B2 (en) * | 2012-04-26 | 2017-05-02 | Futurewei Technologies, Inc. | System and method for encoder-integrated media denoising |
WO2015104963A1 (en) * | 2014-01-09 | 2015-07-16 | 株式会社日立国際電気 | Image processing device and moving image transmission method |
-
2017
- 2017-09-29 CN CN201780067335.7A patent/CN109891894B/en active Active
- 2017-09-29 EP EP17781350.8A patent/EP3516877B1/en active Active
- 2017-09-29 WO PCT/US2017/054331 patent/WO2018102017A1/en unknown
- 2017-09-29 CN CN202111143037.6A patent/CN113873237B/en active Active
- 2017-10-20 US US15/789,400 patent/US10757408B2/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2249572A1 (en) * | 2008-03-07 | 2010-11-10 | Kabushiki Kaisha Toshiba | Dynamic image encoding/decoding method and device |
WO2011081637A1 (en) * | 2009-12-31 | 2011-07-07 | Thomson Licensing | Methods and apparatus for adaptive coupled pre-processing and post-processing filters for video encoding and decoding |
CN102710936A (en) * | 2011-01-04 | 2012-10-03 | 香港中文大学 | High performance loop filters in video compression |
WO2013047335A1 (en) * | 2011-09-28 | 2013-04-04 | ソニー株式会社 | Image processing device and method |
CN105684448A (en) * | 2012-06-15 | 2016-06-15 | 谷歌技术控股有限责任公司 | Method and apparatus for efficient slice header processing |
Non-Patent Citations (4)
Title |
---|
A Post Deblocking Filter for H.264 Video;Yao-Min Huang et al.;《2007 16th International Conference on Computer Communications and Networks》;全文 * |
Domain transform for Edge-Aware Image and Video Processing;Eduardo S.L、Gastal、Manuel Oliveira;《ACM Transactions on Graphics ，Proceedings of SIGGRAPH 2011》;第30卷(第4期);全文 * |
统一环路的滤波器研究与改进;王迪;《 电脑编程技巧与维护》;全文 * |
高效视频编码的环路去块效应滤波技术研究;郭颖;《中国优秀硕士学位论文全文数据库（电子期刊）》;全文 * |
Also Published As
Publication number | Publication date |
---|---|
CN113873237A (en) | 2021-12-31 |
EP3516877A1 (en) | 2019-07-31 |
US10757408B2 (en) | 2020-08-25 |
US20180160117A1 (en) | 2018-06-07 |
CN109891894A (en) | 2019-06-14 |
CN109891894B (en) | 2021-10-08 |
EP3516877B1 (en) | 2020-03-11 |
WO2018102017A1 (en) | 2018-06-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN113873237B (en) | Method and apparatus for recovering degraded tiles of degraded frames resulting from reconstruction | |
JP7110370B2 (en) | Using Nonlinear Functions Applied to Quantization Parameters of Machine Learning Models for Video Coding | |
JP6858277B2 (en) | Directional intra-predictive coding | |
CN112203088B (en) | Transform selection for non-baseband signal coding | |
CN110169059B (en) | Composite Prediction for Video Coding | |
KR102598789B1 (en) | Apparatus and method for filtering in video coding | |
US11212527B2 (en) | Entropy-inspired directional filtering for image coding | |
CN109891885B (en) | Guided offset correction for loop recovery in video coding | |
CN110692245A (en) | Image processing for compression | |
CN107018416B (en) | Adaptive tile data size coding for video and image compression | |
US11924476B2 (en) | Restoration in video coding using filtering and subspace projection | |
CN110710208B (en) | Embedding information about EOB location | |
CN113170121A (en) | Adaptive filtering of video streams for bit rate reduction | |
CN115280772A (en) | Dual standard block partitioning heuristic for lossy compression | |
US9049432B1 (en) | Motion differential set partition coding for color image sequence compression | |
CN110710219B (en) | Method and apparatus for context derivation for coefficient coding | |
CN117957839A (en) | Filtering side information using context designed filters | |
WO2022229495A1 (en) | A method, an apparatus and a computer program product for video encoding and video decoding |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |