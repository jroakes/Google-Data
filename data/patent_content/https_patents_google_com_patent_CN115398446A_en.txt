CN115398446A - Machine learning algorithm search using symbolic programming - Google Patents
Machine learning algorithm search using symbolic programming Download PDFInfo
- Publication number
- CN115398446A CN115398446A CN202180026970.7A CN202180026970A CN115398446A CN 115398446 A CN115398446 A CN 115398446A CN 202180026970 A CN202180026970 A CN 202180026970A CN 115398446 A CN115398446 A CN 115398446A
- Authority
- CN
- China
- Prior art keywords
- machine learning
- algorithm
- search
- candidate
- tree
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/004—Artificial life, i.e. computing arrangements simulating life
- G06N3/006—Artificial life, i.e. computing arrangements simulating life based on simulated virtual individual or collective life forms, e.g. social simulations or particle swarm optimisation [PSO]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/086—Learning methods using evolutionary algorithms, e.g. genetic algorithms or genetic programming
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/01—Dynamic search techniques; Heuristics; Dynamic trees; Branch-and-bound
Abstract
A method for searching output Machine Learning (ML) algorithms to perform ML tasks is described. The method comprises the following steps: receiving data specifying an input ML algorithm; receiving data specifying a search algorithm to search for the candidate ML algorithm and an evaluation function to evaluate performance of the candidate ML algorithm; generating data representing a symbol tree from an input ML algorithm; generating data representing a supersymbol tree from the symbol tree; searching an algorithm search space defining a set of possible specific symbol trees from the supersymbol tree for the candidate ML algorithms and training the candidate ML algorithms to determine a respective performance metric for each of the candidate ML algorithms; and, based on the determined performance metrics, select one or more of the trained candidate ML algorithms.
Description
Cross Reference to Related Applications
This application is a non-provisional application and claims priority to U.S. provisional patent application No.63/035,551, filed 5/2020, the entire contents of which are incorporated herein by reference.
Technical Field
The present description relates to determining a machine learning algorithm to perform a machine learning task.
Background
The machine learning algorithm may be, for example, a neural network. Neural networks are machine learning models that use one or more layers of nonlinear units to predict output for received inputs. In addition to the output layer, some neural networks include one or more hidden layers. The output of each hidden layer serves as an input to the next layer in the network, i.e. the next hidden layer or output layer. Each layer of the network generates an output from the received input in accordance with the current values of the respective parameter set.
Disclosure of Invention
This specification describes a system implemented as a computer program on one or more computers at one or more locations that determines output machine learning algorithms to perform a particular machine learning task.
The subject matter described in this specification can be implemented in particular embodiments to realize one or more of the following advantages. By manipulating the symbols in the symbol tree that defines the search space using a search through the search space (i.e., a neural architecture search) as a control flow primitive, the described system can efficiently identify high performance machine learning algorithms for any of a variety of machine learning tasks. In particular, by formulating key elements of a machine learning algorithm in a symbolic paradigm using symbolic programming, the described techniques allow all portions of a target machine learning algorithm (or target program) to be universally searchable and make the search space simple, expressive, and easily modifiable. Thus, search algorithms can be reused and switched at almost zero cost, enabling them to cooperate with each other in complex search streams in a computationally efficient manner. Furthermore, the search process can be greatly simplified as a for loop with feedback operations, allowing the basic control flow pattern to express arbitrarily complex search flows. Thus, by using the described approach, complex search streams can be easily deployed to identify high performance algorithms, new search spaces can be easily explored, and new search algorithms can be introduced at lower cost. Thus, the techniques described herein can effectively extend automated machine learning (AutoML) in depth and breadth based on different profiles of projects, the proportion of shared code, and development costs to guide new searches and to introduce complex search methods and algorithms.
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 illustrates an example machine learning algorithm search system.
Fig. 2A shows an example of an input machine learning algorithm.
FIG. 2B illustrates an example symbol tree.
FIG. 2C illustrates an example of a superscript tree.
Fig. 3 illustrates an example process for searching a search space for a candidate ML algorithm.
FIG. 4 is a flow diagram of an example process for searching output machine learning algorithms to perform machine learning tasks.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
This specification describes a system implemented as a computer program on one or more computers at one or more locations that determines output machine learning algorithms to perform a particular machine learning task.
The machine learning algorithm defines one or more of: a model architecture for a machine learning model (neural network) for performing a task; hyper-parameters for training the model to perform a task; or pre-processing techniques (e.g., data enhancement strategies) applied to the input during training, after training, or both.
The machine learning model may be configured to perform any type of machine learning task, i.e., may be configured to receive any type of digital data input and generate any type of score, classification, or regression output based on the input.
In some cases, the machine learning model is a neural network configured to perform image processing tasks, i.e., receive an input image and process intensity or color values of pixels in the input image to generate a network output for the input image. For example, the task may be image classification, and the output generated by the neural network for a given image may be a score for each of a set of object classes, each score representing an estimated likelihood that the image contains an image of an object belonging to a certain class. As another example, the task may be image embedding generation and the output generated by the neural network may be digital embedding of the input image. As yet another example, the task may be object detection, and the output generated by the neural network may identify a location in the input image depicting a particular type of object. As yet another example, the task may be image segmentation, and the output generated by the neural network may assign each pixel of the input image to a class from a set of classes.
As another example, if the input to the neural network is an internet resource (e.g., a web page), a document or portion of a document or a feature extracted from an internet resource, document or portion of a document, the task may be to classify the resource or document, i.e., the output generated by the neural network for a given internet resource, document or portion of a document may be a score for each topic in a set of topics, each score representing an estimated likelihood that the internet resource, document or portion of a document is about that topic.
As another example, if the input to the neural network is a feature of the impression context of a particular advertisement, the output generated by the neural network may be a score representing an estimated likelihood that the particular advertisement will be clicked.
As another example, if the input to the neural network is a feature of a personalized recommendation for the user, such as a feature characterizing the context of the recommendation, such as a feature characterizing an action previously taken by the user, the output generated by the neural network may be a score for each of a set of content items, each score representing an estimated likelihood that the user will respond positively to the recommended content item.
As another example, if the input to the neural network is a sequence of text in one language, the output generated by the neural network may be a score for each of a set of text segments in another language, each score representing an estimated likelihood that a text segment in the other language is correctly translated into the other language.
As another example, the task may be an audio processing task. For example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network may be a score for each of a set of text segments, each score representing an estimated likelihood that the text segment is a correct transcript of the utterance. As another example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network may indicate whether a particular word or phrase ("hotword") was spoken in the utterance. As another example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network may recognize a natural language in which the utterance was spoken.
As another example, a task may be a natural language processing or understanding task, such as an implication task, a paraphrase task, a text similarity task, an emotion task, a sentence completion task, a grammar task, and the like, that runs on some sequence of text in natural language.
As another example, the task may be a text-to-speech task, where the input is text in natural language or a feature of text in natural language, and the network output is an audio spectrogram or other data defining text being spoken in natural language.
As another example, the task may be a health prediction task, where the input is electronic health record data for the patient and the output is a prediction related to the patient's future health, e.g., a predicted treatment that should be prescribed for the patient, a likelihood of an adverse health event for the patient, or a predicted diagnosis for the patient. Such electronic health record data may include physiological data related to the patient, such as blood glucose, blood pressure, body temperature, or heart rate, among others. Examples of adverse health events include hypoglycemic and/or hyperglycemic events, heart attacks or strokes, and the like.
As another example, the task may be an agent control task, where the input is an observation characterizing a state of the environment and the output defines an action to be performed by the agent in response to the observation. For example, the agent may be a real world or simulated robot, a control system of an industrial facility, or a control system controlling different types of agents. Examples of observations or other data characterizing environmental conditions include sensor data related to agents, such as visual data, LIDAR readings, sonar readings, or the like. Outputting data defining an action to be performed by an agent may include control signals for controlling the agent to perform the action, or may be converted into such signals.
Fig. 1 illustrates an example machine learning algorithm search system 100. System 100 is an example of a system implemented as a computer program on one or more computers at one or more locations, in which the systems, components, and techniques described below may be implemented.
To determine an output machine learning algorithm (e.g., output machine learning algorithm 150) to perform a particular machine learning task, system 100 includes an algorithm search subsystem 120, the algorithm search subsystem 120 configured to receive: (i) Specifying data input to the machine learning algorithm 102, the input machine learning algorithm 102 performing a particular machine learning task; (ii) Data specifying a search algorithm 104 that searches for candidate machine learning algorithms; and (iii) data specifying an evaluation function 105 that evaluates the performance of the candidate machine learning algorithm.
The search algorithm 104 employs a search strategy to search candidate machine learning algorithms from a search space. The search strategy may be one of the following: (ii) a brute force search strategy, (ii) a random search strategy, (iii) an evolutionary search strategy, (iv) a multi-stage search strategy, (v) a nested search strategy, (vi) a hybrid search strategy, (vii) a weight-sharing search strategy, (viii) a Reinforcement Learning (RL) based approach, (ix) a gradient based approach, or (x) a neural predictor. For example, the search algorithm 104 may be a stochastic search, a bayesian optimization, a reinforcement learning based search that learns a controller strategy that uses near-end strategy optimization (PPO), regularized evolution, or a high-efficiency neural architecture search (tuneas) to guide the search.
The subsystem 120 also receives a training data set 126 and a validation data set 128 for training a neural network defined by a candidate machine learning algorithm (hereinafter referred to as a "candidate ML algorithm"). The training data set 126 includes a set of training examples. Each training example of the set of training examples includes an example input for a particular machine learning task and a corresponding example output for the particular machine learning task. The verification data set 128 includes a set of verification examples. Each validation example of the set of validation examples includes a validation input for a particular machine learning task and a corresponding validation output for the particular machine learning task. For example, a larger training data set may have been randomly partitioned to generate a training data set and a validation data set.
Fig. 2A shows an example of an input ML algorithm. Input ML algorithm 202 is used to train a machine learning model (e.g., resNetLike) using an optimizer (e.g., adam optimizer). Input ML algorithm 202 specifies the structure of a machine learning model that includes a plurality of blocks, each block including a sequence of Conv (4, (3,3)), batchnormation (), and ReLU (), and the number of blocks is 12.
The subsystem 120 generates data representing the symbol tree 106 from the input machine learning algorithm 102. The symbol tree is a tree of nodes, where each node represents a component in the input machine learning algorithm and is associated with a specific value.
Fig. 2B shows an example of a symbol tree generated from an input ML algorithm. Symbol tree 204 is a node tree generated from input ML algorithm 202. The symbol tree 204 has a node 203 representing the machine learning model (the respective specific value in this example is ResNetLike), a node 205 representing the architecture of the blocks in the machine learning model (the respective specific value in this example is Sequential (Conv (4, (3,3), batchNormalization ()), reLU ()), a node 214 representing the number of blocks in the machine learning model (the respective specific value in this example is 12), and a node 216 representing an optimizer for training the machine learning model (the respective specific value in this example is Adam (2 e-4)).
Referring to FIG. 1, subsystem 120 generates data representing superscript tree 108 from symbol tree 106 by changing each node in a subset of the plurality of nodes in symbol tree 106 to a respective new node having a respective placeholder value. The respective new node is associated with a corresponding set of possible specific values that the respective placeholder value may assume.
The node's placeholder value is a super value. There are various categories of overrides: 1) Continuous values (e.g., values declared by floatv); 2) Discrete values (e.g., values declared by intv); 3) Classification values (values declared by oneof, manyof, or permatate). Table 1 summarizes the different over-value classes and their semantics.
Table 1: supervalue class and semantics thereof
FIG. 2C illustrates an example of a supersymbol tree generated from a symbol tree. The system generates a superscript tree 206 from the symbol tree 204 by changing node 205 to a new node 208 having a placeholder value with a set of possible concrete values. A possible specific set of values for node 208 includes a set of neural network layers (in this example, [ Conv, batchNormalization, reLU)]) A set of possible block architectures defined by the arrangement of (1), wherein the Conv layer has a searchable filter size (in this example, ([ 4,8)]) One of them). Node 214 in the symbol tree 204 is changed to a new node 210 where the number of blocks can be selected from a set of possible specific values (6 or 12 in this example). Node 216 in the symbol tree 204 is changed to a new node 212, where the fixed Adam optimizer in node 216 is compared to the Adam optimizer in node 212 and has a value of 10 -6 To 10 -3 In real number range (i.e., learning rate ∈ flowv (1 e-6, 1e-3)), the RMSProp optimizer.
Referring to fig. 1, subsystem 120 searches algorithm search space 110, which algorithm search space 110 defines a set of possible specific symbol trees from superscript tree 108. Each node in the possible concrete symbol tree corresponds to a respective node in the supersignal tree and takes a particular concrete value from a corresponding set of possible concrete values associated with the respective node in the supersignal tree. Each possible specific symbol tree corresponds to a candidate machine learning algorithm.
The subsystem 120 searches the algorithm search space 110 for the candidate ML algorithms by performing the following operations. Subsystem 120 generates data representing the candidate specific symbol tree by using search algorithm 104 to search the algorithm search space 110 for the candidate specific symbol tree. In particular, subsystem 120 generates an abstract search space from search space 110 and samples abstract candidate algorithms from the abstract search space using a search algorithm. The subsystem 120 generates a candidate concrete symbol tree using an abstract candidate algorithm 306. The subsystem 120 then generates candidate machine learning algorithms 112 from the candidate concrete symbol trees.
An example process for searching the space 110 for the candidate ML algorithm search algorithm using the search algorithm 104 is described in more detail below with reference to FIG. 3.
The subsystem 120 trains the candidate machine learning algorithm 112 with respect to the particular machine learning task using the received training data set 126 and validation data set 128. The subsystem 120 uses the evaluation function 105 to determine performance metrics 118 that specify the performance of the candidate machine learning algorithms 112 trained with respect to a particular machine learning task.
For example, the performance metric may be a validation loss, a training loss, a weighted combination of validation loss and training loss, or any metric suitable for a particular machine learning task.
In some implementations, the subsystem 120 can evaluate the performance of the trained candidate machine learning algorithm by performing the evaluation function 105 on a validation instance of a single validation dataset (e.g., validation dataset 104) with respect to the trained candidate ML algorithm.
In some other implementations, the subsystem 120 may evaluate the performance of the trained candidate machine learning algorithm by performing the evaluation function 105 on the validation examples of the plurality of validation data sets with respect to the trained candidate ML algorithm. This would allow the output machine learning algorithm 150 to be better generalized to new data sets (or new machine learning tasks).
The subsystem 120 may repeat the above operations multiple times to generate other candidate ML algorithms and their corresponding performance metrics, such as candidate ML algorithm 114 and its performance metrics 122 and candidate ML algorithm 116 and its performance metrics 124.
After each candidate ML algorithm or batch of multiple candidates is generated and evaluated, performance metrics of the candidate ML algorithm or batch are fed back to the search algorithm to improve future sampling of abstract candidate algorithms from the abstract search space.
To determine the output ML algorithm 150, the subsystem 120 selects one or more of the trained candidate machine learning algorithms based on the determined performance metrics. In some implementations, the subsystem 120 may select the K trained candidate machine learning algorithms with the best performance metrics among the trained candidate machine learning algorithms. The subsystem 120 may further train or further fine tune the K trained candidate machine learning algorithms and then select the best trained candidate machine learning algorithm as the output machine learning algorithm 150 for the machine learning task. In some other implementations, the subsystem 120 may select the trained candidate machine learning algorithm with the highest performance metric among the trained candidate machine learning algorithms as the output machine learning algorithm 150 for the machine learning task.
In some implementations, the system 100 can process the machine learning input using the output machine learning algorithm 150 to generate machine learning output to perform a particular machine learning task. Alternatively or additionally, the system 100 may provide the output machine learning algorithm 150 to another system that processes new inputs using the output machine learning algorithm to generate new outputs.
Fig. 3 illustrates an example process for generating candidate ML algorithms from a search space using a search algorithm (e.g., search algorithm 104 of fig. 1). For convenience, process 300 will be described as being performed by a system of one or more computers located at one or more locations. For example, a machine learning algorithm search system suitably programmed in accordance with the present description, such as machine learning algorithm search system 100 of fig. 1, may perform process 300.
The system generates an abstract search space 304 from the search space defined by the superscript tree 302 to prevent the search algorithm from seeing the full search space specification. Using the abstract search space 304, the search algorithm can only see what it needs to see for search purposes. The abstract search space 304 is a view of the algorithm of the search space 302. In contrast, a complete specification may be referred to as a specific search space (or simply "search space"). The difference between the concrete search space and the abstract search space is: the concrete search space serves as a template for generating a concrete symbol tree of candidates (defining corresponding ML algorithms of candidates) that contains all algorithm details (e.g. fixed parts). However, the abstract search space only sees the parts that require decision making and their possible concrete values (e.g., numeric ranges). Based on the abstract search space 304, the system generates abstract candidate algorithms 306 using a search algorithm. In particular, the search algorithm samples the abstract candidate algorithms 306 from the abstract search space 304 based on performance metrics generated for previous candidate machine learning algorithms. For each placeholder value in the superscript tree 302, the abstract candidate algorithm 306 may include a respective concrete value (i.e., a number selection) that the placeholder value takes.
The system recursively combines the placeholder values (i.e., the hyper-values) from the hyper-symbol tree 302 and the number selections from the abstract candidate algorithm 306 to generate a candidate concrete symbol tree 308. For continuous or discrete excess values, the selected value is the final value to be assigned to its target node in tree 302, and for categorical excess values, the selected value is the index of the selected candidate. For example, as shown in FIG. 3, numeral 2 in the abstract algorithm 306 specifies the index of the Conv layer (in the three layers Identity (), maxPool, and Conv) in the superscript tree 302, numeral 0 specifies the first of the two choices for the Conv layer filter (i.e., [4,8 ]) (i.e., 4), numeral 1 specifies the second of the two choices for the optimizer (i.e., adam and RMSProp) (i.e., RMSProp optimizer), and 3e-4 specifies the learning rate of the RMSProp optimizer. Given the data in the candidate concrete symbol tree 308, the system generates a candidate ML algorithm 310.
Fig. 4 is a flow diagram of an example process for searching output machine learning algorithms to perform a machine learning task. For convenience, process 400 will be described as being performed by a system of one or more computers located at one or more locations. For example, a machine learning algorithm search system suitably programmed in accordance with the present description, such as machine learning algorithm search system 100 of fig. 1, may perform process 400.
The system receives data specifying an input machine learning algorithm to perform a particular machine learning task (step 402). The specific machine learning task may be one of the following tasks: a classification task, a regression task, or an image recognition task.
The system receives data specifying a search algorithm to search for the candidate machine learning algorithm and an evaluation function to evaluate performance of the candidate machine learning algorithm (step 404).
The search algorithm searches candidate machine learning algorithms from a search space using a search strategy. The search strategy may be one of the following: (ii) a brute force search strategy, (ii) a random search strategy, (iii) an evolutionary search strategy, (iv) a multi-stage search strategy, (v) a nested search strategy, (vi) a hybrid search strategy, (vii) a weight-sharing search strategy, (viii) a Reinforcement Learning (RL) based approach, (ix) a gradient based approach, or (x) a neural predictor. For example, the search algorithm 104 may be: random searching; bayesian optimization; learning a reinforcement learning-based search of a controller policy that uses near-end policy optimization (PPO) to guide the search; regularized evolution; or a high efficiency neural architecture search (TuNAS). In some implementations, the search algorithm includes multiple search operations performed in a distributed manner.
The system also receives a training dataset and a validation dataset for training the candidate machine learning algorithm with respect to the particular machine learning task.
The system generates data representing a symbol tree from the input machine learning algorithm (step 406). The symbol tree is a tree of nodes, where each node represents a component in the input machine learning algorithm and is associated with a specific value. In some implementations, nodes in the symbol tree can be associated with symbol operations. The symbol operation associated with at least one node in the symbol tree is one of: a transformation operation that transforms a node, (ii) an inference operation that provides information about node attributes, (iii) a query operation that provides information about neighboring nodes of the node, or (iv) a replication operation that provides a copy of the node. The symbolic operations may be applied to components of the input machine learning algorithm represented by the nodes.
The system generates data representing a supersymbol tree from the symbol tree by changing each node in a subset of the plurality of nodes in the symbol tree to a respective new node having a respective placeholder value with a corresponding set of possible specific values (step 408). The node's placeholder value is a super value. The excess value is one of a continuous value, a discrete value, or a classification value.
The system searches an algorithmic search space defining a set of possible specific symbolic trees from the superscript tree by performing steps 410-416 at least once. Each node in the possible concrete symbol trees corresponds to a respective node in the supersignal tree and takes a particular concrete value from a corresponding set of possible concrete values associated with the respective node in the supersignal tree. Each possible specific symbol tree corresponds to a candidate machine learning algorithm.
The system generates data representing the candidate concrete symbol tree by searching the candidate concrete symbol tree in an algorithmic search space using a search algorithm (step 410).
In particular, the system generates an abstract search space from a search space. The abstract search space is a tree of decision nodes, each of which is mapped to a respective placeholder value in the superscript tree.
The system samples abstract candidate algorithms from an abstract search space using a search algorithm. In particular, the search algorithm samples the abstract candidate algorithm from an abstract search space based on performance metrics generated for previous candidate machine learning algorithms. For each placeholder value in the superscript tree, the abstract candidate algorithm may include a respective concrete value (i.e., a number selection) to be taken by the placeholder value.
The system recursively combines placeholder values (i.e., hypervalues) from the superscript tree and number selections from the abstract candidate algorithm to generate a candidate concrete symbol tree. For example, the following is a simplified example of an abstract search space:
the abstract search space above is a tree of depth 2 (i.e., the tree has two levels of depth). The first child node has a subtree of 3 nodes ('a', 'b', 'c'), while the other two child nodes of the root are leaves ('x', 'y'). The decision to reach 'b' can be described by the abstract candidate algorithm [0,1], which means that the first node at level 1 is selected, and then the second node at level 2 is selected. Since the depth of the tree is determined by the search space, the process of generating the candidate specific symbol tree is performed recursively.
The system generates candidate machine learning algorithms from the candidate concrete symbol tree (step 412).
The system trains candidate machine learning algorithms for a particular machine learning task using the received training data set (step 414).
The system determines performance metrics that specify the performance of trained candidate machine learning algorithms with respect to a particular machine learning task using an evaluation function (step 416).
For example, the performance metric may be a validation loss, a training loss, a weighted combination of validation loss and training loss, or any metric suitable for a particular machine learning task.
In some implementations, the system can evaluate the performance of the trained candidate machine learning algorithm by performing an evaluation function on validation examples of a single validation dataset (e.g., the received validation dataset) with respect to the trained candidate ML algorithm.
In some other implementations, the system may evaluate the performance of the trained candidate machine learning algorithm by performing an evaluation function on the validation examples of the plurality of validation data sets with respect to the trained candidate ML algorithm. This would allow the output machine learning algorithm to be better generalized to new data sets (or new machine learning tasks).
The system selects one or more of the trained candidate machine learning algorithms based on the determined performance metrics (step 418).
In some implementations, the system may select the K trained candidate machine learning algorithms with the best performance metrics among the trained candidate machine learning algorithms. The system may further train or further fine tune the K trained candidate machine learning algorithms, and then select the best trained candidate machine learning algorithm as the output machine learning algorithm for the machine learning task. In some other implementations, the system may select one of the trained candidate machine learning algorithms having the highest performance metric as the output machine learning algorithm for the machine learning task.
In some implementations, the system can process the machine learning input using an output machine learning algorithm to generate a machine learning output to perform a particular machine learning task. For example, the output machine learning algorithm may be configured to process the digital data input to generate a score, classification, or regression output based on the digital data input to perform a machine learning task. Alternatively or additionally, the system may provide the output machine learning algorithm to another system that processes the new input using the output machine learning algorithm to generate a new output.
The term "configured" is used herein in connection with system and computer program components. By a system of one or more computers configured to perform particular operations or actions, it is meant that the system has installed thereon software, firmware, hardware, or a combination thereof that, in operation, causes the system to perform the operations or actions. By one or more computer programs configured to perform certain operations or actions, it is meant that the one or more programs include instructions that, when executed by data processing apparatus, cause the apparatus to perform the operations or actions.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly embodied computer software or firmware, in computer hardware (including the structures disclosed in this specification and their structural equivalents), or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them. Alternatively or additionally, the program instructions may be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can also be, or include, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can optionally include, in addition to hardware, code that creates an execution environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program (also known as or described as a program, software application, app, module, software module, script, or code) can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
In this specification, the term "database" is used broadly to refer to any collection of data: the data need not be structured in any particular way, or at all, and it may be stored on a storage device in one or more locations. Thus, for example, an index database may include multiple data sets, each of which may be organized and accessed differently.
Similarly, in this specification, the term "engine" is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more particular functions. Typically, the engine will be implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers will be dedicated to a particular engine; in other cases, multiple engines may be installed and run on the same computer or multiple computers.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and in particular by, special purpose logic circuitry, e.g., an FPGA or an ASIC, or by a combination of special purpose logic circuitry and one or more programmed computers.
A computer suitable for executing a computer program may be based on a general purpose or special purpose microprocessor or both, or any other kind of central processing unit. Generally, a central processing unit will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or performing instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer may be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), to name a few.
Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example: semiconductor memory devices such as EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; a magneto-optical disk; and CD ROM and DVD-ROM disks.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having: a display device, for example, a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to a user; and a keyboard and a pointing device, such as a mouse or a trackball, by which a user can provide input to the computer. Other types of devices may also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. Additionally, the computer may interact with the user by: sending and receiving documents to and from a device used by a user; for example, a web page is sent to a web browser on a user device in response to a request received from the web browser. Further, the computer may interact with the user by sending a text message or other form of message to a personal device (e.g., a smartphone running a messaging application) and then receiving a response message from the user.
The data processing apparatus for implementing the machine learning model may also comprise, for example, a dedicated hardware accelerator unit for handling common and computationally intensive parts of the machine learning training or production, i.e. inferences, workloads.
The machine learning model may be implemented and deployed using a machine learning framework (e.g., a TensorFlow framework, a Microsoft cognitive toolkit framework, an Apache Singa framework, or an Apache MXNet framework).
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, such as a data server, or that includes a middleware component, such as an application server, or that includes a front-end component, such as a client computer having a graphical user interface, a Web browser, or an app, through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a Local Area Network (LAN) and a Wide Area Network (WAN) (e.g., the internet).
The computing system may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server sends data (e.g., HTML pages) to the user device, for example, for the purpose of displaying data to and receiving user input from a user interacting with the device as a client. Data generated at the user device, e.g., results of user interactions, may be received at the server from the user device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings and are recited in the claims in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (18)
1. A method of searching an output machine learning algorithm to perform a particular machine learning task given an input machine learning algorithm, the method comprising:
receiving data specifying an input machine learning algorithm to perform the particular machine learning task;
receiving data specifying a search algorithm to search for the candidate machine learning algorithm and an evaluation function to evaluate performance of the candidate machine learning algorithm;
generating data representing a symbol tree from the input machine learning algorithm, wherein the symbol tree is a tree of a plurality of nodes, wherein each node represents a component in the input machine learning algorithm and is associated with a particular value;
generating data representing a superscript tree from the symbol tree by changing each node in a subset of the plurality of nodes in the symbol tree to a respective new node having a respective placeholder value with a corresponding set of possible concrete values;
searching an algorithm search space defining a set of possible concrete symbol trees from the superscript tree, wherein each node in a possible concrete symbol tree corresponds to a respective node in the superscript tree, and obtaining a particular concrete value from the corresponding set of possible concrete values associated with the respective node in the superscript tree, wherein each possible concrete symbol tree corresponds to a candidate machine learning algorithm, and wherein searching the algorithm search space comprises performing at least one of the following:
generating data representing candidate concrete symbol trees by searching the candidate concrete symbol trees in the algorithm search space using the search algorithm;
generating candidate machine learning algorithms from the candidate concrete symbol trees,
training the candidate machine learning algorithm with respect to the particular machine learning task,
determining, using the evaluation function, a performance metric that specifies performance of the trained candidate machine learning algorithm with respect to the particular machine learning task; and
one or more trained candidate machine learning algorithms are selected among the trained candidate machine learning algorithms based on the determined performance metrics.
2. The method of claim 1, wherein the particular machine learning task is one of: a classification task, a regression task, or an image recognition task.
3. The method of claim 1 or 2, wherein the placeholder value of a node is a hyper-value.
4. The method of claim 3, wherein the excess value is one of a continuous value, a discrete value, or a classification value.
5. The method of any preceding claim, wherein at least one node in the symbol tree is associated with a symbol operation.
6. The method of claim 5, wherein the symbolic operation associated with at least one node in the symbolic tree is one of: (ii) a transformation operation to transform the node, (ii) an inference operation to provide information about attributes of the node, (iii) a query operation to provide information about neighboring nodes to the node, or (iv) a replication operation to provide a copy of the node, and wherein the method comprises applying the symbolic operation to a component of an input machine learning algorithm represented by the at least one node.
7. The method of any preceding claim, further comprising generating an abstract search space from the algorithmic search space, wherein the abstract search space is a tree of decision nodes, wherein each decision node is mapped to a respective placeholder value in the superscript tree.
8. The method of claim 7, wherein generating data representing the candidate specific symbol tree by searching in the algorithmic search space using the search algorithm further comprises:
generating data representing the candidate concrete symbol tree by applying the search algorithm over the abstract search space using previous performance metrics of previous candidate machine learning algorithms.
9. The method of claim 8, wherein the search algorithm uses a search strategy to generate data representing candidate specific symbol trees.
10. The method of claim 9, wherein the search policy is one of: (ii) a brute force search strategy, (ii) a random search strategy, (iii) an evolutionary search strategy, (iv) a multi-stage search strategy, (v) a nested search strategy, (vi) a hybrid search strategy, (vii) a weight-sharing search strategy, (viii) a Reinforcement Learning (RL) based approach, (ix) a gradient based approach, or (x) a neural predictor.
11. The method of any preceding claim, wherein the search algorithm comprises a plurality of search operations performed in a distributed manner.
12. The method of any preceding claim, wherein the output machine learning algorithm is configured to process a digital data input to generate a score, classification, or regression output based on the digital data input to perform the machine learning task.
13. The method of any of the preceding claims, wherein selecting the one or more trained candidate machine learning algorithms comprises: selecting a plurality of trained candidate machine learning algorithms having a best performance metric among the trained candidate machine learning algorithms.
14. The method of claim 13, further comprising:
further training the plurality of trained candidate machine learning algorithms with respect to the particular machine learning task, an
Selecting an optimal candidate machine learning algorithm among the further trained candidate machine learning algorithms as an output machine learning algorithm for the machine learning task.
15. The method of any of the preceding claims, wherein selecting the one or more trained candidate machine learning algorithms comprises: selecting the trained candidate machine learning algorithm with the highest performance metric among the trained candidate machine learning algorithms as an output machine learning algorithm for the machine learning task.
16. A system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform operations of the respective methods of any of claims 1-15.
17. One or more computer storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform operations of the respective methods of any of claims 1-15.
18. A method, comprising:
providing data specifying an input machine learning algorithm to an algorithm search system;
causing the algorithm search system to search for an output machine learning algorithm using the respective operations of any of claims 1-19; and
performing a particular machine learning task using the output machine learning algorithm.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202063035551P | 2020-06-05 | 2020-06-05 | |
US63/035,551 | 2020-06-05 | ||
PCT/US2021/036002 WO2021248068A1 (en) | 2020-06-05 | 2021-06-04 | Machine learning algorithm search with symbolic programming |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115398446A true CN115398446A (en) | 2022-11-25 |
Family
ID=76662555
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180026970.7A Pending CN115398446A (en) | 2020-06-05 | 2021-06-04 | Machine learning algorithm search using symbolic programming |
Country Status (3)
Country | Link |
---|---|
US (1) | US20230144138A1 (en) |
CN (1) | CN115398446A (en) |
WO (1) | WO2021248068A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN116416492B (en) * | 2023-03-20 | 2023-12-01 | 湖南大学 | Automatic data augmentation method based on characteristic self-adaption |
-
2021
- 2021-06-04 CN CN202180026970.7A patent/CN115398446A/en active Pending
- 2021-06-04 US US17/905,196 patent/US20230144138A1/en active Pending
- 2021-06-04 WO PCT/US2021/036002 patent/WO2021248068A1/en active Application Filing
Also Published As
Publication number | Publication date |
---|---|
US20230144138A1 (en) | 2023-05-11 |
WO2021248068A1 (en) | 2021-12-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20210334624A1 (en) | Neural architecture search using a performance prediction neural network | |
CN111602148B (en) | Regularized neural network architecture search | |
AU2018214675B2 (en) | Systems and methods for automatic semantic token tagging | |
US11568207B2 (en) | Learning observation representations by predicting the future in latent space | |
US20200104687A1 (en) | Hybrid neural architecture search | |
EP3732631A1 (en) | Neural architecture search for dense image prediction tasks | |
US11803731B2 (en) | Neural architecture search with weight sharing | |
CN113826125A (en) | Training machine learning models using unsupervised data enhancement | |
US20220108171A1 (en) | Training neural networks using transfer learning | |
US20190228297A1 (en) | Artificial Intelligence Modelling Engine | |
US20220253680A1 (en) | Sparse and differentiable mixture of experts neural networks | |
CN117121016A (en) | Granular neural network architecture search on low-level primitives | |
CN115398446A (en) | Machine learning algorithm search using symbolic programming | |
US20230063686A1 (en) | Fine-grained stochastic neural architecture search | |
CN115066690A (en) | Search normalization-activation layer architecture | |
CN115485694A (en) | Machine learning algorithm search | |
US20240152809A1 (en) | Efficient machine learning model architecture selection | |
JP7483751B2 (en) | Training machine learning models using unsupervised data augmentation | |
Wang et al. | A Knowledge-Enhanced Inferential Network for Cross-Modality Multi-hop VQA |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |