CN105573436A - Predictive pre-recording of audio for voice input - Google Patents
Predictive pre-recording of audio for voice input Download PDFInfo
- Publication number
- CN105573436A CN105573436A CN201511032215.2A CN201511032215A CN105573436A CN 105573436 A CN105573436 A CN 105573436A CN 201511032215 A CN201511032215 A CN 201511032215A CN 105573436 A CN105573436 A CN 105573436A
- Authority
- CN
- China
- Prior art keywords
- data
- mobile device
- user
- probability model
- speech input
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F1/00—Details not covered by groups G06F3/00 - G06F13/00 and G06F21/00
- G06F1/16—Constructional details or arrangements
- G06F1/1613—Constructional details or arrangements for portable computers
- G06F1/1626—Constructional details or arrangements for portable computers with a single-body enclosure integrating a flat display, e.g. Personal Digital Assistants [PDAs]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F1/00—Details not covered by groups G06F3/00 - G06F13/00 and G06F21/00
- G06F1/16—Constructional details or arrangements
- G06F1/1613—Constructional details or arrangements for portable computers
- G06F1/1633—Constructional details or arrangements of portable computers not specific to the type of enclosures covered by groups G06F1/1615 - G06F1/1626
- G06F1/1684—Constructional details or arrangements related to integrated I/O peripherals not covered by groups G06F1/1635 - G06F1/1675
- G06F1/1694—Constructional details or arrangements related to integrated I/O peripherals not covered by groups G06F1/1635 - G06F1/1675 the I/O peripheral being a single or a set of motion sensors for pointer control or gesture input obtained by sensing movements of the portable computer
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for providing predictive pre-recording of audio for voice input. In one aspect, a method includes establishing, as input data, state data that references a state of a mobile device and sensor data that is sensed by one or more sensors of the mobile device, applying a rule or a probabilistic model to the input data, inferring, based on applying the rule or the probabilistic model to the input data, that a user of the mobile device is likely to initiate voice input, and invoking one or more functionalities of the mobile device in response to inferring that the user is likely to initiate voice input.
Description
cross-reference to related applications
The divisional application that the application is international application no is PCT/US2011/029009, international filing date is on 03 18th, 2011, thenational phase application number is the application for a patent for invention of 201180016100.8.
This application claims the right of priority of the Application U.S. Serial No 12/732,827 of " PREDICTIVEPRE-RECORDINGOFAUDIOFORVOICEINPUT " by name that submit on March 26th, 2010, be incorporated to its disclosure by reference at this.
Technical field
This instructions relates generally to search engine.
Background technology
Due to quantity of information obtainable on the Internet sharp increase, user is difficult to form effective search inquiry to locate specific relevant information many times.In recent years, the competition between search engine provider has caused search engine algorithms and the acceleration evolution of user interface for receiving inquiry and display of search results.
Various mechanism can be used to provide inquiry to search engine.Such as, user can use the keyboard on computing equipment to key in query term to search box, and subsequently this query term can be submitted to search engine.User can implicitly define inquiry, to obtain the note of the point of interest that the display section of map exists by dragging map.And when use has mobile device (such as, smart phone, music player or tablet computer) of keypad or dummy keyboard, user can say query term to microphone.
Summary of the invention
Generally, a novel aspects of the theme described in this instructions can be implemented as a kind of method, comprise action: when predicting that user initiates background audio on the mobile apparatus when may initiate speech input and records, even if this mobile device is locked or be in park mode.Recorded by initiation background audio when predicting that user may initiate speech input instead of when user's actual initiation speech inputs by the time, the front portion avoiding speech input is blocked, and improves precision of identifying speech.In addition, prediction audio frequency prerecording saves the battery life of mobile device, and allows catch when inapplicable continuous recording buffering and input audio frequency.
Generally, another novel aspects of the theme described in this instructions can be implemented as a kind of method, comprises action: set up the status data of instruction mobile device status and the sensing data that sensed by one or more sensors of mobile device using as input data; To input market demand rule or probability model; Infer that the user of mobile device may initiate speech input based on to input market demand rule or probability model; And one or more functions of mobile device are called in response to inferring user may initiate speech input.
Other embodiments in this respect comprise corresponding system, equipment and are coded in computer program computer memory device being configured to the action performing the method.
These and other embodiment is each can comprise following one or more feature alternatively.Such as, the one or more functions calling mobile device may further include: start background audio and record, the display that status data can comprise instruction mobile device is opened or the data of closing, instruction mobile device are in locking mode or the data of non-locking mode operation, indicate the data of the one or more application performed on the mobile apparatus, instruction voice search is applied the data, the field selected by indicating user that whether perform just on the mobile apparatus and whether is allowed to the data whether data of speech Text Input or indicating user are operating the input mechanism of mobile device, status data can comprise: the instruction current state of mobile device or the data of recent state, sensing data can comprise the data sensed by the keypad sensor of mobile device, the data that sensor senses are determined by the position of mobile device, the data sensed by the accelerometer of mobile device, the data sensed by the magnetometer of mobile device, by mobile device photosensor senses to data, the data sensed by the Proximity Sensor of mobile device, the data sensed by the capacitive transducer of mobile device or the data sensed by the touch sensor of mobile device, action can comprise sets up sensing data as input data, this can comprise: set up the data that sensed by the first sensor of mobile device as input data, and the one or more functions calling mobile device can comprise: the second sensor activating mobile device in response to inferring user may initiate speech input, action can also comprise: set up data that status data, the data sensed by the first sensor of mobile device and the second sensor by mobile device sense as additional input data, to additional input market demand ancillary rules or additional probability model, based on inferring that to additional input market demand ancillary rules or additional probability model user still may initiate speech input, and deduction user starts background audio recording in response to still may initiate speech input, can comprise to input market demand rule or probability model: determine and the score that input data are associated, and infer that user may initiate speech input and can comprise: determine that the score be associated with input data meets predetermined threshold, can comprise to input market demand rule or probability model: to input market demand rule, can comprise to input market demand rule or probability model: to input market demand probability model, action can comprise: do not know whether user may initiate speech input based on inferring to input market demand rule or probability model, do not know whether user may initiate speech input and indicate mobile device to collect additivity data or additional sensor data in response to deduction, and to input data and additivity data or additional sensor data application rule or probability model, wherein infer that user may initiate speech input further based on to input data and additivity data or additional sensor data application rule or probability model, action can comprise: use historical state data or historical sensor data to come create-rule or training probability model, infer that user may initiate speech input and can comprise further: infer that user may initiate speech input by mobile device, infer that user may initiate speech input and can comprise: infer that user may initiate speech input by server, and/or action can comprise: transmit audio signals and duration data between mobile device and server, the background audio of encoding in the sound signal that wherein duration data instruction was recorded before user loquiturs is recorded.
The one or more embodiments of the detail of the theme described in this instructions are recorded at accompanying drawing with in hereafter describing.By specification, drawings and the claims, other potential feature, aspect and advantages of theme will become obvious.
Accompanying drawing explanation
Fig. 1 and Fig. 3 is the block diagram of the audio frequency prerecording for speech input.
Fig. 2 is the process flow diagram of an instantiation procedure.
Similar numbering represents corresponding part all the time.
Embodiment
Fig. 1 is the block diagram of the prediction audio frequency prerecording illustrated for speech input.Particularly, Fig. 1 shows a system 100, comprises the mobile client communication facilities 101 belonging to user 102 (" Jim "), the mobile client communication facilities 104 belonging to user 105 (" Bob ") and server 106.Mobile device 101 and 104 is connected to server 106 by one or more network 107 (showing for network 107a and 107b).Network 107 is public network or its some combination of dedicated network, the such as the Internet of such as Intranet or cellular phone network.It is mutual that Fig. 1 also show the first example between equipment 101 and server 106 in time sequence status " a " and " b " the second example that is mutual and that arrive in " v " at time sequence status " i " between equipment 104 and server 106.
Originally, " item " (or " query term ") used in instructions comprises one or more word that is complete or part, character or character string; " query search " comprises the one or more query terms submitting to search engine when user asks search engine to perform search.Item can use keypad to key in by user, or when voice queries, user says or otherwise provide speech to input, and speech input was transcribed by speech recognition engine before being submitted to search engine.
Except other things, " result " (or " Search Results ") of search comprises same resource identifier (" URI "), its resource indicating searched engine to be defined as in response to search inquiry.Search Results can comprise other guide, the title of such as respective resources, preview image, user's rank, map or direction, description, or from corresponding resource, be automatically or manually the text chunk extracting or otherwise associate with it.
In the example described, mobile client communication facilities 101 and 104 is mobile phones, and it comprises the function allowing respective user to initiate speech input.Such as, mobile device 101 and 104 can perform such application, this application display search box, and detecting that user is recorded by microphone after selecting " voice search " button of physics or user interface " voice search " control, generate sound signal, and sound signal is submitted to speech recognition engine or search engine.In other examples, mobile client communication facilities 101 and 104 is tablet computers, laptop computer, personal digital aid (PDA) (PDA), Mobile audio player, GPS (GPS) receiver or comprise other equipment of one or more processor and one or more microphones etc.
Server 106 can be implemented as one or more computing equipment, and it comprises: one or more processor 109; Speech recognition engine 110, for the treatment of the voice queries for search engine 111; Rule or probability model engine 112 are (such as, regulation engine, probability model engine or its combination in any), for input market demand rule or probability model to infer whether (or otherwise determining) should call one or more functions of mobile client communication facilities.Infer such as can the indicating user probability that will loquitur higher than predetermined threshold.
Server 106 also stores the historical data 114 relevant with equipment 101 and 104 and/or other mobile client communication facilitiess.Such as, historical data 114 can store previously by user (such as, user 102 or 105, or other users) the input data in past submitted to, and whether the input data in this past cause user may initiate the instruction of the deduction of speech input.
Select to provide in the realization to this type of information access user, the record in historical data 114 can be indicated by the user ID of user 102 or 105, such as name, telephone number or Internet protocol (IP) address.Such as, the behavior of specific user can be followed the tracks of to determine when this user may initiate speech input.In some implementations, historical data 114 comprises the record of the action following the tracks of groups of users or group, in order to determine the typical user's situation indicating speech input to initiate.Rule or model can be developed according to these situations, and can determine individual consumer whether may initiate speech input time be applied to input data.
Although speech recognition engine 110, search engine 111 and rule or probability model engine 112 are illustrated as the parts of server 106, but in other example implementation, these engines can be overall or be partly implemented on another equipment, such as, on mobile device 101 or mobile device 104.Such as, rule or probability model engine 112 can run, to reduce battery consumption by minimizing network service on mobile device 101 or mobile device 104.Mobile device 101 or mobile device 104 can comprise the static probability model set up in advance, or can sometimes be upgraded by server and upload to the probability model of mobile device 101 or mobile device 104.Mobile device 101 or mobile device 104 can also store training data, and it are regularly sent to server to allow server update probability model.
It is mutual that Fig. 1 shows with time sequence status " a " and " b " the first example occurred between equipment 101 and server 106.In this first example is mutual, mobile device 101 is placed in its pocket by user 102 (" Jim "), and is using the music player application run on mobile device 101 to listen to music.In this first example is mutual, user 102 does not intend to initiate speech input.
At state " a ", the data 105 (be in this description called as " input data ") relevant with mobile device 101 are acquired, generate, select, upgrade, receive or otherwise set up.Such as, input data 115 can be the status datas of instruction mobile device 101 state, and/or the untreated or processed sensing data sensed by one or more sensors of mobile device 101.In FIG, input data 115 comprise: device status data, and its instruction mobile device 101 just to run in " locking " application state and to run music player application; And sensing data, its instruction mobile device 101 moves (such as, being sensed by accelerometer) and be not touched (such as, being sensed by capacitive transducer or touch sensor).
Input data can be obtained or are upgraded constantly, or it can be acquired based on the reception of signal (such as, from the signal starting foundation input data of server 105) or upgrade.In another example, input data can based on the generation of event (such as, the process of time, or detect mobile device 101 started shooting or started mobile after) and to be acquired.
The input data 115 set up for mobile device 101 in state " a " can be included in the obtainable all devices status data of special time and sensing data, or certain subset of obtainable device status data and sensing data.If equipment is included in particular moment and is not activated or does not have at the sensor (such as in order to economize on electricity) generating data, acquisition sensing data can comprise collects data from the sensor activated or its certain subset, and/or activates by the sensor of solution activation and collect data from it.Once be acquired, input data 115 are transmitted to server 106 by network 107a.
Service regeulations or probability model 112, server 106 distinguishes application rule or probability model to input data 115, to infer whether user may initiate speech input.Result to input data 115 application rule or probability model can may initiate speech input (such as by indicating user, possibility meets threshold value that is predetermined or Dynamic Definition), user can not initiate speech input (such as, possibility score does not meet threshold value that is predetermined or Dynamic Definition), or do not know whether user may initiate speech input (such as, cannot based on given input set determination possibility score, or possibility score falls between upper limit threshold and lower threshold).
In this first example is mutual, because user 102 does not touch mobile device 101, music player performs, mobile device 101 moves, mobile device 101 is in the lock state or gives device status data and any weighting of sensing data or non-weighted array, rule or probability model 112 determine that user can not initiate speech input.Input data are stored on a server 106 as historical data 114 with the data of instruction inferred results, for generating or changing rule or train the model that will be used by rule or probability model engine 112.
Infer based on this, server 106 transmits message 116 in state " b " to mobile device 101, can not initiate speech input, and/or do not carry out predictability audio frequency prerecording to mobile device 101 indicating user.In some implementations, message 116 can comprise the data validation to being received from mobile device 101, if or server determined user can not initiate speech input, then server 106 can respond never in any form.To inputting the collection of data and whether wanting the deduction initiating speech input can occur once to user, specific number of times can be repeated or repeat with specific interval, or can repeat until there is scheduled event (such as, until running down of battery or mobile device stop mobile).
If user 102 does not want to initiate speech input (namely after state " b ", if infer it is " negative "), the additional movement of mobile device 101, touch or state can be detected change, and indicate that these are additional mobile, to touch or data that state changes can be used for inferring that in fact user 102 wants to initiate speech input by rule or probability model engine 112, or rules of conciliation or training pattern are to mate with user view better.But although may have to manually initiate speech input because have predictability prescoring ability user, user interface can comprise for the explicit button or the control that call speech input.But once predictability prescoring starts, this button or control can be removed or become ash temporarily to forbid manual initiating capacity.Alternatively, prescoring can be caused to stop the selection of control, or predictability prescoring function can be forbidden.
The second example that Fig. 1 also shows between the equipment of occurring in 104 and server 106 with time sequence status " i " to " v " is mutual.In this second example is mutual, user 105 (" Bob ") his mobile device 104 is being lifted he in one's ear or mouth to initiate speech input.
At state " i ", the input data 117 relevant with mobile device 104 are established.Such as, input data 117 and comprise the data indicating browser application to run and indicate mobile device 104 to run in " non-locking " application state just on the mobile devices 104.Input data 117 comprise the sensing data (such as, being sensed by accelerometer) of instruction mobile device 104 movement further.Input data 117 can obtain constantly, can be acquired, or can be acquired based on the generation of event based on the reception of signal.Input data 117 are transmitted to server 106 by network 107b.
Service regeulations or probability model engine 112, server 106 distinguishes application rule or probability model to input data 117, to infer whether user may initiate speech input.In this second example is mutual, because mobile device 104 moves, mobile device 104 runs with unlocked state or based on any weighting of device status data and sensing data or non-weighted array, rule or probability model can be determined not know whether user may initiate speech input.
In some implementations, except input data 117, server 106 also considers external data when determining whether user may initiate speech input.Such as, the typical behaviour (such as, tracked in historical data 114) of time or date and user 105 can compare by server 106.
In order to more clearly set up possibility, rule or probability model engine 112 then can identify mobile device 104 and use or non-using function, and can transmit a message to call the specific function of mobile device 104, this function may contribute to rule or probability model engine 112 infers whether user may initiate speech input.Such as, rule or probability model engine 112 can determine that mobile device 104 comprises capacitive transducer, and determine that capacitive transducer is not activated or capacitive transducer data are not acquired as input data based on there are not capacitive transducer data in input data 117.If rule or probability model engine 112 determine do not have the additional function of mobile device 104 to be available, rule or probability model engine 112 can utilize any can input data generate " best-guess " infer.
Based on not knowing whether user 105 has the ability to generate the capacitive transducer data that may contribute to the accuracy of this deduction by the deduction and mobile device 104 of initiating speech input, server 106 transmits message 119 to mobile device 104, to activate capacitive transducer.At state " iii ", based on receiving message 119, mobile device 104 activates capacitive transducer, sets up capacitive transducer data (" touch being detected ") as upgrading input data, and transmits the message 120 comprising capacitive transducer data to server 106.Message 120 can also comprise other data, comprises device status data or the sensing data of input data 117 or renewal.
When receiving message 120, server 106 is identical or different or probability model to input market demand, to infer whether whether user or still may may initiate speech input.Such as, based on the reception of capacitive transducer data, rule or probability model engine 112 can utilize capacitor sensor data as the rule or the probability model that input data by choice and operation.
Because capacitive transducer data just detect touch, or based on device status data with comprise any weighting of sensing data of capacitive transducer data or non-weighted array, rule or probability model 112 determine that user may initiate speech input.The data that input data and instruction deduction export are stored on a server 106 as historical data 114, for generating or changing rule or train the model used by rule or probability model engine 112.
At state " iv ", infer based on this, server 106 transmits message 121 to mobile device 104, may initiate speech input, and/or should start to record the predictability of audio frequency to mobile device 104 indicating user.To inputting the collection of data and whether wanting the deduction initiating speech input can occur once to user, specific number of times can be repeated or repeat with specific interval, can repeat until there is scheduled event, or can repeat until determine that user may initiate user's input for the N time.
Mobile device 104 processing messages 121, and responsively initiate predictability recording, this is such as by initiating the sound-recording function of mobile device 104, this sound-recording function record words that user 105 says and before speaking, period or the background audio that occurs afterwards.In this example, predictability recording make mobile device 104 record user as speech input the words 122 " direction " said, and of short duration (such as, two seconds) part of the background audio occurred before user says language 122.
The part of language 122 and background audio is converted to sound signal 124 by mobile device 104, and it is transmitted to server 106 from mobile device 104.Except sound signal 124, other information can be transmitted to server 106, the candidate transcription of the sound signal 124 such as generated by mobile device 104, or instruction before user loquiturs by the data of duration of background audio recording recorded.
In some implementations, mobile device 104 also transmits can provide for speech recognition engine 110 the contextual information be associated with sound signal 124.Such as, mobile device 104 can provide the URI of the content of browser or browser content (such as, for determining modal item, main title or other guide information), the position of user (such as, use built-in navigation sensor to be determined) or estimate user velocity (such as, user rides or walking, etc.).
Server uses speech recognition engine 110 to generate the one or more of sound signal 124 and transcribes, and uses search engine 111 mark to transcribe relevant resource to this.In other realize, speech recognition engine 110, search engine 111 or all or part of function that is regular or probability model engine 112 can be performed by mobile device 104.
As example above, and such as need to initiate speech and input by pressing button and require that compared with the system that the explicit initiation speech of user inputs, system 100 at least can realize three advantages.For first advantage, speech recognition be used to transcribe such as various have in noise circumstance input, such as when in the room (such as, coffee-house) of user in noise and excitement, walk in the street or there is broadcast or TV when the words that input.In order to filter this noise, some noise reduction algorithm require from this environment, the audio sample that do not have user speech.Predictably record in advance by initiating (such as, before user presses button) before speech inputs user, this background recording becomes and can be used for noise reduction algorithm, thus improves accuracy of identification.
For second advantage, when user such as by after loquituring, press button or before they terminate to speak release-push and initiate speech input time normally coarse.Predictability recording guarantees that the beginning that speech inputs is not lost better, and all words of record and transcribing user, this improves accuracy of identification again.
For the 3rd advantage, some mobile device initiates to have obvious delay between the moment of speech input and the moment that sound subsystem is activated and reality is recorded to start at user's explicitly.By predictably recording in advance, accuracy of identification will be enhanced, because the impact of this delay can be solved and overcome.
With lasting recording so as before user to start to input capturing audio system compared with, system 100 also provides additional advantage.Especially, system does not need mobile device 101 and 104 to run consuming cells constantly and shortens the microphone prime amplifier of mobile device battery life, analog to digital converter (ADC) and processor circuit.Therefore, except the accuracy of identification improved, system 10 provides the prolongation battery life of mobile device 101 and 104 and the overall user experience of enhancing.
Fig. 2 shows an example process 200.In brief, process 200 comprises: set up the status data of instruction mobile device status and the sensing data that sensed by one or more sensors of mobile device using as input data; To input market demand rule or probability model; Infer that the user of mobile device may initiate speech input based on to input market demand rule or probability model; And one or more functions of mobile device are called in response to inferring user may initiate speech input.
More specifically, when process 200 starts (201), set up the data of instruction mobile device status and the data that sensed by one or more sensors of mobile device using as input data (202).Input data can be obtained (such as, receive or generate) constantly, or can be acquired based on obtaining the signal of input data receiving from server.In another example, input data can be acquired based on the generation of event (such as, the process of time), or detect mobile device started shooting or start mobile after be acquired.
The data indicating mobile device status and the data sensed by the sensor of mobile device can comprise untreatment data and/or reduced data.Such as, data can comprise sensor reading (such as, the numerical value exported by accelerometer), or the significant explanation of numerical value (such as, to this numerical value instruction or represent what Practical computer teaching text describe).In addition, the data of instruction mobile device status can comprise the data of instruction current state and/or recent state, and the data sensed by sensor can comprise current or Recent data.
Short reference Fig. 3, the data of instruction mobile device status (namely, data 301) data 302 indicating the display of mobile device to open or close can be comprised, or instruction mobile device is the data 304 run in locking mode or non-locking pattern.Additionally or alternatively, data can comprise the data 305 of one or more application that instruction performs on the mobile apparatus, instruction voice search apply whether perform just on the mobile apparatus data 306, indicate the field selected by the user of mobile device whether to support the data 307 of speech Text Input and/or indicate the user of mobile device whether operating the input mechanism of mobile device (such as, to key on a keypad, or operating mouse or trace ball) data 309.In some implementations, if data 305 indicate two or more application to perform just on the mobile apparatus, it is active instruction at present that these data can comprise that application, or which is applied in the instruction of the top layer of the viewing area of mobile device.Device status data can comprise any other data 310 of one or more states of instruction mobile device.Service regeulations or model 324, whether device status data 301 can have been activated or activate for determining user the software indicating the input of coming speech by regulation engine or probability model engine, and determines to provide deduction 325 based on this.
China bowl, the data sensed by one or more sensors of mobile device (namely, data 311) data 312 that sense of the keypad sensor that can include mobile device are (namely, whether physics " voice search " button is pressed), determine that data 314 that sensor senses (such as by the position of mobile device, by GPS, inertial navigation, whether the user that boat position is inferred or cellular network or Wi-Fi triangulation module are determined leaves home, mobile or on the way), the data 315 sensed by the accelerometer of mobile device, the data 316 sensed by the magnetometer of mobile device (namely, equipment relative to ground towards), by mobile device photosensor senses to data 317 (namely, whether equipment is in the pocket of user), the data 319 sensed by the Proximity Sensor of mobile device, the data 320 sensed by the capacitive transducer of mobile device, the data 321 sensed by the touch sensor of mobile device (namely, whether user just holds mobile device) and/or the data 322 that obtain from any other sensor.Service regeulations or model 324, sensing data can by regulation engine or probability model engine be used for determining equipment be in physical location that the coming speech of instruction inputs or towards, and determine to provide deduction 325 based on this.
Return Fig. 2, rule or probability model are applied to input data (204), to generate the deduction whether user may initiate speech input.In rule-based method, can to input market demand rule to export the instruction whether user may initiate speech input, wherein the various combination of sensing data and device status data will provide different results.Such as, mobile device can have physics search button, and it needs pressing in two seconds to initiate voice search usually.Rule can specify: when capacitive transducer instruction mobile device is just being held and equipment is in unlocked state, as long as physics search button is pressed, predictability prescoring just can start, and without the need to waiting for the time through two seconds.
In another example, rule can specify: when screen be open and mobile device be in a button press or attitude can be utilized to carry out the state of triggering voice search time, such as when voice search frame is visible on screen or when speech input " input method editing machine (IME) " is visible on screen, the prescoring of predictability can start.If touch sensor can be used, touch sensor data can be used to detect that user just holds equipment, rolling audio buffer can be started in this case.
Equally or as an alternative, above-described any and all data types can be used as the input to probability model.But, replace each may the combination for input data and define specific result, probability model can generate the score of each for input data, and uses these scores to initiate predictability prescoring when the condition can recorded in formula (1) is met:
P (speech inputs | device status data, sensing data) and > threshold value (1)
Probability model can use Nae Bayesianmethod, logistic regression, support vector machine (SVM), gauss hybrid models or Bayesian network.These models are trained in the input data can collected based on the mobile device used from a large number of users and corresponding deduction (such as, inferring 325).And, input data and corresponding infer and can collect from the equipment of individual consumer, and can by the software on equipment for adjusting the weight in probability model, to reflect the agenda of user.
In one example, when observe user more likely with specific towards when initiating speech input when holding equipment, can improve in model for this towards weight.In this way, false the moon can be used (such as, infer that user may initiate speech input, but user does not speak and speech recognition engine returns sky recognition result) and vacation sun is (such as, infer that user can not initiate speech input, but user loquiturs and mobile device does not start to record the audio frequency pre-entered) the two carrys out classification device as training sample.
Based on to input market demand rule or probability model, infer whether user may initiate speech input (206).Infer that user may initiate speech input and can comprise and determine to meet predetermined threshold with the score that is associated of input data.
Speech input may be initiated in response to deduction user, one or more functions (208) of mobile device can be called, thus terminal procedure 200 (210).Such as, the function calling mobile device can comprise: before user presses button, start the recording to background audio.Background audio can be used as the input of speech recognition engine, in order to estimate be used for the noise model of squelch and/or estimate to be used for noise model and/or the level of speech terminals detection.
Replace the prescoring that starts predictability or in addition, the function calling mobile device can comprise: in response to inferring that user may initiate speech input or not know whether user may initiate speech input and activate the sensor of mobile device in response to inferring.Such as, rule or probability model engine can be determined that mobile device comprises and may contribute to definitely inferring whether user may initiate the sensor of speech input, and if the sensing data of this sensor is not included as a part for input data, then can send signal to activate this sensor to mobile device.
Describe multiple realization.But will be understood that and can carry out various amendment and not depart from spirit and scope of the present disclosure.Such as, can resequence to step, add step or delete step but with the various forms of streams illustrated above.Correspondingly, other realize also within the scope of the appended claims.
The theme described in this instructions and the embodiment of functional performance can realize in Fundamental Digital Circuit, or realize in computer software, firmware or hardware, this computer software, firmware or hardware comprise structure disclosed in this instructions and equivalent structure thereof or their one or more combination.The embodiment of the theme described in this instructions can be implemented as one or more computer program, also namely, encode on a computer-readable medium to be performed by data processing equipment or one or more computer program instructions modules that control data treating apparatus operates.Computer-readable medium can be machine-readable memory device, machine-readable storage substrate, memory device, realize the combination of the combination of computer-readable transmitting signal or one or more in them.Term " data processing equipment " comprises for the treatment of all devices of data, equipment and machine, such as, comprise programmable processor, computing machine, or multiple processor or computing machine.In addition to hardware, this device can comprise the code for the computer program establishment execution environment in consideration, such as, form processor firmware, protocol stack, data base management system (DBMS), operating system, cross-platform runtime environment, or the code of combinations one or more in them.Transmitting signal is the artificial signal produced, and such as, the electric signal that machine produces, light signal or electromagnetic signal, generate this signal to encode to information, to be transferred to suitable acceptor device.
Computer program (also referred to as program, software, software application, script or code) can be write by the programming language of arbitrary form, comprise compiler language or interpretative code, declarative language or procedural language, and this computer program can be disposed by arbitrary form, comprise and be deployed as independent program or module, assembly, subroutine, or be suitable for other unit of using in a computing environment.Computer program is without the need to corresponding to the file in file system.Program can be stored in preserves other programs or data (such as, be stored in the one or more scripts in marking language document) file a part in, can be stored in the Single document of the program be specifically designed in consideration, or to be stored in multiple coordinated files (such as, store one or more module, subroutine, or the file of code section).Computer program can be deployed as and perform on a computer, or be deployed as on the multiple computing machines being positioned at the three unities perform or stride across multiple place distribution and by multiple computing machines of interconnection of telecommunication network perform.
The process described in this instructions and logic flow can be performed by the one or more programmable processors performing one or more computer program, for carrying out n-back test by operating and produce output to input data.This process and logic flow can also be performed by the dedicated logic circuit of such as FPGA (field programmable gate array) or ASIC (special IC), and also device can be embodied as described dedicated logic circuit.
Be suitable for any one or more processors that processor that computer program performs such as comprises the digital machine of general and application specific processor and any type.Usually, processor will receive instruction and data from ROM (read-only memory) or random access storage device or both.The primary element of computing machine is the processor for performing instruction and the one or more memory devices for storing instruction and data.Usually, computing machine also will comprise the one or more mass memory units for storing data, or be operatively coupled as receiving data from described one or more mass memory units for storing data, transmitting data to it or carrying out both, this mass memory unit is disk, magneto-optic disk or CD such as.But computing machine does not necessarily have such equipment.And, computing machine can be embedded in other equipment, such as mobile phone, personal digital assistant (PDA), Mobile audio frequency or video player, GPS (GPS) receiver or portable memory apparatus are (such as, USB (universal serial bus) (USB) flash drive), this is only a few example.The computer-readable medium being suitable for storing computer program instructions and data comprises the nonvolatile memory of form of ownership, medium and memory device, such as, comprise: semiconductor memory apparatus, as EPROM, EEPROM and flash memory device; Disk, as internal hard drive or mobile hard disk; Magneto-optic disk; And CD-ROM and DVD-ROM dish.Processor and storer by supplemented or can be included in dedicated logic circuit.
Mutual in order to what provide with user, the embodiment of the theme described in this instructions can be provided on the computing machine of the keyboard of input and the equipment of indication to computing machine by it the display device had for showing information to user and user and realize, wherein display device such as CRT (cathode-ray tube (CRT)) or LCD (liquid crystal display) monitor, gives directions equipment such as mouse or trace ball.What also can use the equipment of other types to provide with user is mutual; Such as, the feedback being supplied to user can be any type of sensory feedback, such as visual feedback, auditory feedback or tactile feedback; And the input of the arbitrary form from user can be received, comprise sound, voice or sense of touch input.
The embodiment of the theme described in this instructions can be implemented in and comprises in the computing system of aft-end assembly, such as data server; Or realize in the computing system comprising middleware component, such as application server; Or realize in the computing system comprising front end assemblies, such as have the client computer of graphic user interface or Web browser, user can carry out alternately with the realization of theme that describes in this instructions by this graphic user interface or Web browser; Or realize in any combination of one or more such rear end, middleware or front end assemblies.System component can interconnect with the digital data communication (such as, communication network) of arbitrary form or medium.The example of communication network comprises LAN (Local Area Network) (" LAN "), wide area network (" WAN "), Internet (such as, internet) and ad-hoc network (such as, adhoc ad-hoc network).
Computing system can comprise client and server.Client and server generally mutual away from, and usually to be undertaken alternately by communication network.The relation of client and server obtains by means of the computer program running, have each other client-server relation on the respective computers.
Although this instructions comprises a lot of detail, should not be understood as is restriction to scope of the present invention or claimed content, and should be understood to the description of the special characteristic being the specific embodiment of the invention.Some feature in the context of each embodiment described in this instructions also can combine realization in single embodiment.On the contrary, the various features described in single embodiment context also can be separately implemented in multiple embodiment or in sub-portfolio suitable arbitrarily.And; although operation in specific combination may be described feature as above; also be even initially claimed like this; but can remove from this combination in some cases from one or more features of combination required for protection, and combination required for protection can for the distortion of sub-portfolio or combination.
Similarly, although describe operation with specific order in the accompanying drawings, should not be understood as and require to operate to perform these according to shown particular order or serial order, or the operation shown in requiring to perform all is to obtain the result of expectation.In specific environment, multitask and parallel processing may be favourable.And, the separation of multiple system component should not be understood to need these to operate in all embodiments in the above-described embodiment, described program assembly should be understood as and system can integrate usually in single software product, or be packaged in multiple software product.
In each example mentioning html file, can substitute with alternative document type or form.Such as, html file can be replaced with the file of XML, JSON, general text or other types.And, when mentioning table or Hash table, other data structures (such as list, relational database or structured document) can be used.
Thus, specific embodiment has been described.Other embodiments also within the scope of the appended claims.Such as, the action recorded in the claims can perform according to different order and still realize the result of expectation.
Claims (19)
1. a system, comprising:
One or more computing machine; And
Be coupled to the computer-readable medium of described one or more computing machine, there is the instruction be stored thereon, make described one or more computing machine executable operations when described execution is performed by described one or more computing machine, comprising:
To status data and sensing data application rule or probability model, the state of described status data instruction mobile device, described sensing data is sensed by one or more sensors of described mobile device;
Apply described rule or described probability model based on to described status data and described sensing data, infer that the user of described mobile device may initiate speech input;
Background recording is started in response to the described user of deduction may initiate speech input; And
Transmit (i) to encode the recording of described background and the sound signal that what is said or talked about, and (ii) indicates the duration data of the duration of the described background recording of encoding in described sound signal.
2. system according to claim 1, wherein said status data comprises: indicate the data that the display of described mobile device is opened or closed, indicate described mobile device just in locking mode or the data of non-locking mode operation, the data of one or more application that instruction described mobile device is performing, the data whether application of instruction voice search described mobile device performs, described user-selected field is indicated whether to be allowed to the data of speech Text Input or to indicate described user whether operating the data of the input mechanism of described mobile device.
3. system according to claim 1, wherein said status data comprises: indicate the current state of described mobile device or the data of recent state.
4. system according to claim 1, wherein said sensing data comprises: the data sensed by the keypad sensor of described mobile device, the data that sensor senses are determined by the position of described mobile device, the data sensed by the accelerometer of described mobile device, the data sensed by the magnetometer of described mobile device, by described mobile device photosensor senses to data, the data sensed by the Proximity Sensor of described mobile device, the data sensed by the capacitive transducer of described mobile device or the data sensed by the touch sensor of described mobile device.
5. system according to claim 1, wherein:
Described rule is applied or described probability model comprises further: to rule or described probability model described in the market demand that the first sensor by described mobile device senses to described sensing data;
Start the recording of described background to comprise further: the second sensor activating described mobile device in response to inferring described user may initiate speech input.
6. system according to claim 5, wherein said operation comprises further:
The described data sensed to the described first sensor by described mobile device and the additional data applications ancillary rules sensed by described second sensor of described mobile device or additional probability model;
Based on to ancillary rules described in described data and described additional data applications or described additional probability model, infer that described user still may initiate speech input; And
The recording of described background is started in response to the described user of deduction still may initiate speech input.
7. system according to claim 1, wherein:
Described rule is applied or described probability model comprises further: determine and the score that described status data and described sensing data are associated to described status data and described sensing data; And
Infer that described user may initiate speech input and comprise further: determine that the described score be associated with described status data and described sensing data meets predetermined threshold.
8. system according to claim 1, wherein applies described rule to described status data and described sensing data or described probability model comprises further: to described status data and described sensing data application rule.
9. system according to claim 1, wherein applies described rule to described status data and described sensing data or described probability model comprises further: to described status data and described sensing data applied probability model.
10. system according to claim 1, wherein said operation comprises further:
Apply described rule or described probability model based on to described status data and described sensing data, infer and do not know whether user may initiate speech input;
In response to deduction, whether unclear described user may initiate speech input, indicates described mobile device to collect additivity data or additional sensor data; And
Described rule or described probability model is applied to described status data, described sensing data and described additivity data or described additional sensor data,
Wherein infer that described user may initiate speech input and apply described rule or described probability model based on to described status data, described sensing data and described additivity data or described additional sensor data further.
11. systems according to claim 1, wherein said operation comprises further: use historical state data or historical sensor data generate described rule or train described probability model.
12. systems according to claim 1, wherein infer that described user may initiate speech input and comprise further: infer that described user may initiate speech input by described mobile device.
13. systems according to claim 1, wherein infer that described user may initiate speech input and comprise further: infer that described user may initiate speech input by server.
14. systems according to claim 1, wherein said operation comprises further:
Between described mobile device and server, transmit described sound signal and described duration data, wherein said duration data indicates the described background recording of recording before described user loquiturs of encoding in described sound signal.
15. 1 kinds of computer implemented methods, comprising:
By mobile device to status data and sensing data application rule or probability model, described status data indicates the state of described mobile device, and described sensing data is sensed by one or more sensors of described mobile device;
Apply described rule or described probability model based on to described status data and described sensing data, infer that the user of described mobile device may initiate speech input;
Start background by described mobile device in response to the described user of deduction may initiate speech input to record; And
Recorded and the sound signal that what is said or talked about by described mobile device transmission (i) described background of encoding, and (ii) indicates the duration data of the duration of the described background recording of encoding in described sound signal.
16. methods according to claim 15, wherein:
Described rule is applied or described probability model comprises further: to rule or described probability model described in the market demand that the first sensor by described mobile device senses to described sensing data, and
Start the recording of described background to comprise further: the second sensor activating described mobile device in response to inferring described user may initiate speech input.
17. methods according to claim 16, comprise further:
The described data sensed to the described first sensor by described mobile device and the additional data applications ancillary rules sensed by described second sensor of described mobile device or additional probability model;
Based on to ancillary rules described in described data and described additional data applications or described additional probability model, infer that described user still may initiate speech input; And
The recording of described background is started in response to the described user of deduction still may initiate speech input.
18. methods according to claim 15, wherein:
Described rule is applied or described probability model comprises further: determine and the score that described status data and described sensing data are associated to described status data and described sensing data; And
Infer that described user may initiate speech input and comprise further: determine that the described score be associated with described status data and described sensing data meets predetermined threshold.
19. 1 kinds of codings have the computer-readable storage medium of computer program, and described program comprises instruction, and make described one or more computing machine executable operations when described instruction is performed by one or more computing machine, described operation comprises:
To status data and sensing data application rule or probability model, described status data indicates the state of described mobile device, and described sensing data is sensed by one or more sensors of described mobile device;
Apply described rule or described probability model based on to described status data and described sensing data, infer that the user of described mobile device may initiate speech input;
Background recording is started in response to the described user of deduction may initiate speech input; And
Transmit (i) to encode the recording of described background and the sound signal that what is said or talked about, and (ii) indicates the duration data of the duration of the described background recording of encoding in described sound signal.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/732,827 | 2010-03-26 | ||
US12/732,827 US8428759B2 (en) | 2010-03-26 | 2010-03-26 | Predictive pre-recording of audio for voice input |
CN201180016100.8A CN102918493B (en) | 2010-03-26 | 2011-03-18 | The predictability audio frequency prerecording of speech input |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201180016100.8A Division CN102918493B (en) | 2010-03-26 | 2011-03-18 | The predictability audio frequency prerecording of speech input |
Publications (2)
Publication Number | Publication Date |
---|---|
CN105573436A true CN105573436A (en) | 2016-05-11 |
CN105573436B CN105573436B (en) | 2019-07-26 |
Family
ID=44148755
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201180016100.8A Active CN102918493B (en) | 2010-03-26 | 2011-03-18 | The predictability audio frequency prerecording of speech input |
CN201511032215.2A Active CN105573436B (en) | 2010-03-26 | 2011-03-18 | The predictive audio prerecording of speech input |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201180016100.8A Active CN102918493B (en) | 2010-03-26 | 2011-03-18 | The predictability audio frequency prerecording of speech input |
Country Status (5)
Country | Link |
---|---|
US (3) | US8428759B2 (en) |
EP (1) | EP2553563B1 (en) |
CN (2) | CN102918493B (en) |
AU (1) | AU2011229784B2 (en) |
WO (1) | WO2011119431A1 (en) |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108090568A (en) * | 2016-11-23 | 2018-05-29 | 埃森哲环球解决方案有限公司 | Recognize robot credit parser |
CN110047484A (en) * | 2019-04-28 | 2019-07-23 | 合肥马道信息科技有限公司 | A kind of speech recognition exchange method, system, equipment and storage medium |
CN110415698A (en) * | 2018-11-15 | 2019-11-05 | 腾讯科技（深圳）有限公司 | Artificial intelligence data detection method and device and storage medium |
CN110832477A (en) * | 2017-10-24 | 2020-02-21 | 谷歌有限责任公司 | Sensor-based semantic object generation |
CN112967716A (en) * | 2016-12-30 | 2021-06-15 | 谷歌有限责任公司 | Feedback controller for data transmission |
Families Citing this family (147)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8677377B2 (en) | 2005-09-08 | 2014-03-18 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US10002189B2 (en) | 2007-12-20 | 2018-06-19 | Apple Inc. | Method and apparatus for searching using an active ontology |
US9330720B2 (en) | 2008-01-03 | 2016-05-03 | Apple Inc. | Methods and apparatus for altering audio output signals |
US20100030549A1 (en) | 2008-07-31 | 2010-02-04 | Lee Michael M | Mobile device having human language translation capability with positional feedback |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US9009053B2 (en) | 2008-11-10 | 2015-04-14 | Google Inc. | Multisensory speech detection |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US11416214B2 (en) * | 2009-12-23 | 2022-08-16 | Google Llc | Multi-modal input on an electronic device |
EP2339576B1 (en) * | 2009-12-23 | 2019-08-07 | Google LLC | Multi-modal input on an electronic device |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US8682667B2 (en) | 2010-02-25 | 2014-03-25 | Apple Inc. | User profiling for selecting user specific voice input processing information |
US8359020B2 (en) * | 2010-08-06 | 2013-01-22 | Google Inc. | Automatically monitoring for voice input based on context |
US9262612B2 (en) | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
CA2831678A1 (en) * | 2011-03-28 | 2012-10-04 | Ambientz | Methods and systems for searching utilizing acoustical context |
US20120296458A1 (en) * | 2011-05-18 | 2012-11-22 | Microsoft Corporation | Background Audio Listening for Content Recognition |
US10057736B2 (en) | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
US8762151B2 (en) * | 2011-06-16 | 2014-06-24 | General Motors Llc | Speech recognition for premature enunciation |
US20130038895A1 (en) * | 2011-08-08 | 2013-02-14 | Alexander Govyadinov | Mobile communication device and printer having a particulate sensor for air quality monitoring |
GB201122206D0 (en) * | 2011-12-22 | 2012-02-01 | Vodafone Ip Licensing Ltd | Sampling and identifying user contact |
US10134385B2 (en) | 2012-03-02 | 2018-11-20 | Apple Inc. | Systems and methods for name pronunciation |
CN102681784A (en) * | 2012-05-09 | 2012-09-19 | 中兴通讯股份有限公司 | Method and device for operating mobile terminal on basis of sensor, and mobile terminal |
US10417037B2 (en) | 2012-05-15 | 2019-09-17 | Apple Inc. | Systems and methods for integrating third party services with a digital assistant |
US9704484B2 (en) * | 2012-08-10 | 2017-07-11 | Honda Access Corp. | Speech recognition method and speech recognition device |
KR101987255B1 (en) * | 2012-08-20 | 2019-06-11 | 엘지이노텍 주식회사 | Speech recognition device and speech recognition method |
CN102801846A (en) * | 2012-08-24 | 2012-11-28 | 成都思珩网络科技有限公司 | Mobile terminal for black screen recording and method for realizing black screen recording on mobile terminal |
US9805721B1 (en) * | 2012-09-21 | 2017-10-31 | Amazon Technologies, Inc. | Signaling voice-controlled devices |
US8543397B1 (en) * | 2012-10-11 | 2013-09-24 | Google Inc. | Mobile device voice activation |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US9268399B2 (en) | 2013-03-01 | 2016-02-23 | Qualcomm Incorporated | Adaptive sensor sampling for power efficient context aware inferences |
CN104053132B (en) * | 2013-03-14 | 2018-08-28 | 腾讯科技（深圳）有限公司 | A kind of method and device of information number identification |
US10652394B2 (en) | 2013-03-14 | 2020-05-12 | Apple Inc. | System and method for processing voicemail |
US10748529B1 (en) | 2013-03-15 | 2020-08-18 | Apple Inc. | Voice activated device for use with a voice-based digital assistant |
US9769305B2 (en) * | 2013-04-01 | 2017-09-19 | Tata Consultancy Services Limited | System and method for power effective participatory sensing |
US9293138B2 (en) * | 2013-05-14 | 2016-03-22 | Amazon Technologies, Inc. | Storing state information from network-based user devices |
WO2014197335A1 (en) | 2013-06-08 | 2014-12-11 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
KR101959188B1 (en) | 2013-06-09 | 2019-07-02 | 애플 인크. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
CN103312597B (en) * | 2013-06-27 | 2016-04-13 | 小米科技有限责任公司 | A kind of speech message generation method and device |
CN103455623B (en) * | 2013-09-12 | 2017-02-15 | 广东电子工业研究院有限公司 | Clustering mechanism capable of fusing multilingual literature |
CN103596007B (en) * | 2013-11-06 | 2016-09-07 | 华中科技大学 | A kind of method adjusting video encoding quality according to viewing environment change |
US10296160B2 (en) | 2013-12-06 | 2019-05-21 | Apple Inc. | Method for extracting salient dialog usage from live data |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US9633004B2 (en) | 2014-05-30 | 2017-04-25 | Apple Inc. | Better resolution when referencing to concepts |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US11190400B2 (en) | 2014-08-06 | 2021-11-30 | Belkin International, Inc. | Identifying and automating a device type using image data |
US9111221B1 (en) * | 2014-08-06 | 2015-08-18 | Belkin International, Inc. | Detector devices for presenting notifications and supporting context inferences |
US9514296B2 (en) | 2014-09-08 | 2016-12-06 | Qualcomm Incorporated | Automatic authorization for access to electronic device |
US9818400B2 (en) | 2014-09-11 | 2017-11-14 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US10074360B2 (en) | 2014-09-30 | 2018-09-11 | Apple Inc. | Providing an indication of the suitability of speech recognition |
US20160092159A1 (en) * | 2014-09-30 | 2016-03-31 | Google Inc. | Conversational music agent |
CN105869631B (en) * | 2015-01-21 | 2019-08-23 | 上海羽扇智信息科技有限公司 | The method and apparatus of voice prediction |
US20160224104A1 (en) * | 2015-02-02 | 2016-08-04 | Telenav, Inc. | Electronic system with capture mechanism and method of operation thereof |
US10152299B2 (en) | 2015-03-06 | 2018-12-11 | Apple Inc. | Reducing response latency of intelligent automated assistants |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US20160266871A1 (en) * | 2015-03-11 | 2016-09-15 | Adapx, Inc. | Speech recognizer for multimodal systems and signing in/out with and /or for a digital pen |
US10460227B2 (en) | 2015-05-15 | 2019-10-29 | Apple Inc. | Virtual assistant in a communication session |
US10200824B2 (en) | 2015-05-27 | 2019-02-05 | Apple Inc. | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US9578173B2 (en) | 2015-06-05 | 2017-02-21 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US20160378747A1 (en) | 2015-06-29 | 2016-12-29 | Apple Inc. | Virtual assistant for media playback |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US10740384B2 (en) | 2015-09-08 | 2020-08-11 | Apple Inc. | Intelligent automated assistant for media search and playback |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10956666B2 (en) | 2015-11-09 | 2021-03-23 | Apple Inc. | Unconventional virtual assistant interactions |
US10049668B2 (en) | 2015-12-02 | 2018-08-14 | Apple Inc. | Applying neural network language models to weighted finite state transducers for automatic speech recognition |
EP3179472B1 (en) * | 2015-12-11 | 2020-03-18 | Sony Mobile Communications, Inc. | Method and device for recording and analyzing data from a microphone |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
US10880833B2 (en) * | 2016-04-25 | 2020-12-29 | Sensory, Incorporated | Smart listening modes supporting quasi always-on listening |
US11227589B2 (en) | 2016-06-06 | 2022-01-18 | Apple Inc. | Intelligent list reading |
US10049663B2 (en) | 2016-06-08 | 2018-08-14 | Apple, Inc. | Intelligent automated assistant for media exploration |
US10586535B2 (en) | 2016-06-10 | 2020-03-10 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
DK179415B1 (en) | 2016-06-11 | 2018-06-14 | Apple Inc | Intelligent device arbitration and control |
DK201670540A1 (en) | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
US10341309B1 (en) * | 2016-06-13 | 2019-07-02 | Allstate Insurance Company | Cryptographically protecting data transferred between spatially distributed computing devices using an intermediary database |
US10474753B2 (en) | 2016-09-07 | 2019-11-12 | Apple Inc. | Language identification using recurrent neural networks |
US10043516B2 (en) | 2016-09-23 | 2018-08-07 | Apple Inc. | Intelligent automated assistant |
US10777201B2 (en) * | 2016-11-04 | 2020-09-15 | Microsoft Technology Licensing, Llc | Voice enabled bot platform |
US11204787B2 (en) | 2017-01-09 | 2021-12-21 | Apple Inc. | Application integration with a digital assistant |
DK201770383A1 (en) | 2017-05-09 | 2018-12-14 | Apple Inc. | User interface for correcting recognition errors |
US10417266B2 (en) | 2017-05-09 | 2019-09-17 | Apple Inc. | Context-aware ranking of intelligent response suggestions |
US10726832B2 (en) | 2017-05-11 | 2020-07-28 | Apple Inc. | Maintaining privacy of personal information |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
US10395654B2 (en) | 2017-05-11 | 2019-08-27 | Apple Inc. | Text normalization based on a data-driven learning network |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
US11301477B2 (en) | 2017-05-12 | 2022-04-12 | Apple Inc. | Feedback analysis of a digital assistant |
DK179496B1 (en) | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
DK179745B1 (en) | 2017-05-12 | 2019-05-01 | Apple Inc. | SYNCHRONIZATION AND TASK DELEGATION OF A DIGITAL ASSISTANT |
DK179560B1 (en) | 2017-05-16 | 2019-02-18 | Apple Inc. | Far-field extension for digital assistant services |
US20180336892A1 (en) | 2017-05-16 | 2018-11-22 | Apple Inc. | Detecting a trigger of a digital assistant |
US10311144B2 (en) | 2017-05-16 | 2019-06-04 | Apple Inc. | Emoji word sense disambiguation |
US10403278B2 (en) | 2017-05-16 | 2019-09-03 | Apple Inc. | Methods and systems for phonetic matching in digital assistant services |
US10303715B2 (en) | 2017-05-16 | 2019-05-28 | Apple Inc. | Intelligent automated assistant for media exploration |
US10755051B2 (en) | 2017-09-29 | 2020-08-25 | Apple Inc. | Rule-based natural language processing |
CN107833573B (en) * | 2017-10-23 | 2021-02-09 | 上海百芝龙网络科技有限公司 | Machine learning-based family scene semantic understanding auxiliary method |
US10636424B2 (en) | 2017-11-30 | 2020-04-28 | Apple Inc. | Multi-turn canned dialog |
CN108156326B (en) * | 2018-01-02 | 2021-02-02 | 京东方科技集团股份有限公司 | Method, system and device for automatically starting recording |
US10733982B2 (en) | 2018-01-08 | 2020-08-04 | Apple Inc. | Multi-directional dialog |
US10733375B2 (en) | 2018-01-31 | 2020-08-04 | Apple Inc. | Knowledge-based framework for improving natural language understanding |
US10789959B2 (en) | 2018-03-02 | 2020-09-29 | Apple Inc. | Training speaker recognition models for digital assistants |
US10592604B2 (en) | 2018-03-12 | 2020-03-17 | Apple Inc. | Inverse text normalization for automatic speech recognition |
US10818288B2 (en) | 2018-03-26 | 2020-10-27 | Apple Inc. | Natural assistant interaction |
US10909331B2 (en) | 2018-03-30 | 2021-02-02 | Apple Inc. | Implicit identification of translation payload with neural machine translation |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
US10984780B2 (en) | 2018-05-21 | 2021-04-20 | Apple Inc. | Global semantic word embeddings using bi-directional recurrent neural networks |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
DK179822B1 (en) | 2018-06-01 | 2019-07-12 | Apple Inc. | Voice interaction at a primary device to access call functionality of a companion device |
US10892996B2 (en) | 2018-06-01 | 2021-01-12 | Apple Inc. | Variable latency device coordination |
DK201870355A1 (en) | 2018-06-01 | 2019-12-16 | Apple Inc. | Virtual assistant operation in multi-device environments |
US11386266B2 (en) | 2018-06-01 | 2022-07-12 | Apple Inc. | Text correction |
US10496705B1 (en) | 2018-06-03 | 2019-12-03 | Apple Inc. | Accelerated task performance |
US11010561B2 (en) | 2018-09-27 | 2021-05-18 | Apple Inc. | Sentiment prediction from textual data |
US10839159B2 (en) | 2018-09-28 | 2020-11-17 | Apple Inc. | Named entity normalization in a spoken dialog system |
US11170166B2 (en) | 2018-09-28 | 2021-11-09 | Apple Inc. | Neural typographical error modeling via generative adversarial networks |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
US11475898B2 (en) | 2018-10-26 | 2022-10-18 | Apple Inc. | Low-latency multi-speaker speech recognition |
US11638059B2 (en) | 2019-01-04 | 2023-04-25 | Apple Inc. | Content playback on multiple devices |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
US11475884B2 (en) | 2019-05-06 | 2022-10-18 | Apple Inc. | Reducing digital assistant latency when a language is incorrectly determined |
US11423908B2 (en) | 2019-05-06 | 2022-08-23 | Apple Inc. | Interpreting spoken requests |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11140099B2 (en) | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
DK180129B1 (en) | 2019-05-31 | 2020-06-02 | Apple Inc. | User activity shortcut suggestions |
US11496600B2 (en) | 2019-05-31 | 2022-11-08 | Apple Inc. | Remote execution of machine-learned models |
DK201970510A1 (en) | 2019-05-31 | 2021-02-11 | Apple Inc | Voice identification in digital assistant systems |
US11289073B2 (en) | 2019-05-31 | 2022-03-29 | Apple Inc. | Device text to speech |
US11360641B2 (en) | 2019-06-01 | 2022-06-14 | Apple Inc. | Increasing the relevance of new available information |
US11227599B2 (en) | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
US11488406B2 (en) | 2019-09-25 | 2022-11-01 | Apple Inc. | Text detection using global geometry estimators |
US11043220B1 (en) | 2020-05-11 | 2021-06-22 | Apple Inc. | Digital assistant hardware abstraction |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11755276B2 (en) | 2020-05-12 | 2023-09-12 | Apple Inc. | Reducing description length based on confidence |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
US11146602B1 (en) * | 2020-12-04 | 2021-10-12 | Plantronics, Inc. | User status detection and interface |
US11792614B2 (en) * | 2021-04-01 | 2023-10-17 | Qualcomm Incorporated | Adaptive sensor activation and configuration for positioning |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1218258A (en) * | 1997-11-24 | 1999-06-02 | 世韩情报系统株式会社 | MPEG portable sound reproducing system and reproducing method thereof |
CN1347547A (en) * | 1999-02-08 | 2002-05-01 | 高通股份有限公司 | Voice recognition rejection scheme |
CN1545693A (en) * | 2001-08-22 | 2004-11-10 | �Ҵ���˾ | Intonation generating method, speech synthesizing device by the method, and voice server |
CN101399569A (en) * | 2007-09-30 | 2009-04-01 | 联想(北京)有限公司 | Method and system for using mobile terminal as input device of computer |
US20100069123A1 (en) * | 2008-09-16 | 2010-03-18 | Yellowpages.Com Llc | Systems and Methods for Voice Based Search |
Family Cites Families (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5657422A (en) | 1994-01-28 | 1997-08-12 | Lucent Technologies Inc. | Voice activity detection driven noise remediator |
US6549792B1 (en) | 1999-06-25 | 2003-04-15 | Agere Systems Inc. | Accelerometer influenced communication device |
US6615170B1 (en) | 2000-03-07 | 2003-09-02 | International Business Machines Corporation | Model-based voice activity detection system and method using a log-likelihood ratio and pitch |
EP1256875A1 (en) | 2001-05-10 | 2002-11-13 | Nokia Corporation | Method and device for context dependent user input prediction |
US6813491B1 (en) | 2001-08-31 | 2004-11-02 | Openwave Systems Inc. | Method and apparatus for adapting settings of wireless communication devices in accordance with user proximity |
US7159194B2 (en) | 2001-11-30 | 2007-01-02 | Palm, Inc. | Orientation dependent functionality of an electronic device |
US20060052109A1 (en) | 2004-09-07 | 2006-03-09 | Ashman William C Jr | Motion-based user input for a wireless communication device |
KR100631608B1 (en) | 2004-11-25 | 2006-10-09 | 엘지전자 주식회사 | Voice discrimination method |
JP2007280219A (en) | 2006-04-10 | 2007-10-25 | Nippon Telegr & Teleph Corp <Ntt> | Motion pattern recognition device, motion pattern recognition method, and motion pattern recognition program |
US8594742B2 (en) | 2006-06-21 | 2013-11-26 | Symbol Technologies, Inc. | System and method for monitoring a mobile device |
US8571862B2 (en) | 2006-11-30 | 2013-10-29 | Ashwin P. Rao | Multimodal interface for input of text |
CN103561154B (en) | 2007-11-09 | 2015-11-18 | 谷歌公司 | The method and system of the application in automatic activation mobile computing device |
US9009053B2 (en) * | 2008-11-10 | 2015-04-14 | Google Inc. | Multisensory speech detection |
-
2010
- 2010-03-26 US US12/732,827 patent/US8428759B2/en active Active
-
2011
- 2011-03-18 CN CN201180016100.8A patent/CN102918493B/en active Active
- 2011-03-18 AU AU2011229784A patent/AU2011229784B2/en active Active
- 2011-03-18 WO PCT/US2011/029009 patent/WO2011119431A1/en active Application Filing
- 2011-03-18 EP EP11712103.8A patent/EP2553563B1/en active Active
- 2011-03-18 CN CN201511032215.2A patent/CN105573436B/en active Active
- 2011-09-30 US US13/250,533 patent/US8195319B2/en active Active
-
2012
- 2012-07-31 US US13/563,504 patent/US8504185B2/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1218258A (en) * | 1997-11-24 | 1999-06-02 | 世韩情报系统株式会社 | MPEG portable sound reproducing system and reproducing method thereof |
CN1347547A (en) * | 1999-02-08 | 2002-05-01 | 高通股份有限公司 | Voice recognition rejection scheme |
CN1545693A (en) * | 2001-08-22 | 2004-11-10 | �Ҵ���˾ | Intonation generating method, speech synthesizing device by the method, and voice server |
CN101399569A (en) * | 2007-09-30 | 2009-04-01 | 联想(北京)有限公司 | Method and system for using mobile terminal as input device of computer |
US20100069123A1 (en) * | 2008-09-16 | 2010-03-18 | Yellowpages.Com Llc | Systems and Methods for Voice Based Search |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108090568A (en) * | 2016-11-23 | 2018-05-29 | 埃森哲环球解决方案有限公司 | Recognize robot credit parser |
CN108090568B (en) * | 2016-11-23 | 2021-12-07 | 埃森哲环球解决方案有限公司 | Cognitive robotics analyzer |
CN112967716A (en) * | 2016-12-30 | 2021-06-15 | 谷歌有限责任公司 | Feedback controller for data transmission |
CN110832477A (en) * | 2017-10-24 | 2020-02-21 | 谷歌有限责任公司 | Sensor-based semantic object generation |
CN110415698A (en) * | 2018-11-15 | 2019-11-05 | 腾讯科技（深圳）有限公司 | Artificial intelligence data detection method and device and storage medium |
CN110047484A (en) * | 2019-04-28 | 2019-07-23 | 合肥马道信息科技有限公司 | A kind of speech recognition exchange method, system, equipment and storage medium |
Also Published As
Publication number | Publication date |
---|---|
US8504185B2 (en) | 2013-08-06 |
AU2011229784A1 (en) | 2012-09-27 |
US20120296655A1 (en) | 2012-11-22 |
CN102918493B (en) | 2016-01-20 |
CN105573436B (en) | 2019-07-26 |
US8428759B2 (en) | 2013-04-23 |
CN102918493A (en) | 2013-02-06 |
US20120022675A1 (en) | 2012-01-26 |
WO2011119431A1 (en) | 2011-09-29 |
AU2011229784B2 (en) | 2014-03-27 |
US20110238191A1 (en) | 2011-09-29 |
EP2553563A1 (en) | 2013-02-06 |
EP2553563B1 (en) | 2019-07-17 |
US8195319B2 (en) | 2012-06-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN102918493B (en) | The predictability audio frequency prerecording of speech input | |
JP6811758B2 (en) | Voice interaction methods, devices, devices and storage media | |
CN110288987B (en) | System for processing sound data and method of controlling the same | |
KR101667006B1 (en) | Multi-dimensional disambiguation of voice commands | |
KR102331049B1 (en) | Leveraging user signals for initiating communications | |
US20200089661A1 (en) | System and method for providing augmented reality challenges | |
US20160379105A1 (en) | Behavior recognition and automation using a mobile device | |
CN107111516A (en) | Task without a head in personal digital assistant is completed | |
WO2015106134A1 (en) | Audio triggers based on context | |
WO2014113347A2 (en) | Accumulation of real-time crowd sourced data for inferring metadata about entities | |
US20210248173A1 (en) | Systems and methods for providing media recommendations using contextual and sequential user embeddings | |
US20180357306A1 (en) | Increasing use and trust in intelligent systems | |
CN109992606A (en) | A kind of method for digging of target user, device, electronic equipment and storage medium | |
CN110544468A (en) | Application awakening method and device, storage medium and electronic equipment | |
CN111800445B (en) | Message pushing method and device, storage medium and electronic equipment | |
US10614626B2 (en) | System and method for providing augmented reality challenges | |
AU2014201001B2 (en) | Predictive pre-recording of audio for voice input | |
CN111800537B (en) | Terminal use state evaluation method and device, storage medium and electronic equipment | |
CN117370586A (en) | Information display method and device, electronic equipment and storage medium | |
CN115858922A (en) | Information pushing method and device, electronic equipment and storage medium | |
CN117235336A (en) | Search processing method, device, equipment and storage medium based on position |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
GR01 | Patent grant | ||
GR01 | Patent grant |