US8732187B1 - Link-based ranking of objects that do not include explicitly defined links - Google Patents
Link-based ranking of objects that do not include explicitly defined links Download PDFInfo
- Publication number
- US8732187B1 US8732187B1 US12/099,503 US9950308A US8732187B1 US 8732187 B1 US8732187 B1 US 8732187B1 US 9950308 A US9950308 A US 9950308A US 8732187 B1 US8732187 B1 US 8732187B1
- Authority
- US
- United States
- Prior art keywords
- objects
- transitional
- images
- image
- processors
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24578—Query processing with adaptation to user needs using ranking
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/248—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/53—Querying
- G06F16/538—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/55—Clustering; Classification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5838—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using colour
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9538—Presentation of query results
Definitions
- the World Wide Web (“web”) contains a vast amount of information. Search engines assist users in locating desired portions of this information by cataloging web pages. Typically, in response to a user's request, the search engine returns references to documents relevant to the request.
- An image search engine such as a web-based image search engine, catalogs images from the web.
- the image search engine may associate text, such as text that occurs near a particular image, with the image.
- the text associated with the images may then be searched using conventional key word-based search queries to locate images relevant for the search.
- the search engine may return hundreds of results (e.g., images or links to images). The large number of potentially relevant results can be daunting for the user. Additionally, because the relevancy of the results may be primarily determined based on text associated with the image, such as text near the image in a web page, the image itself may not match the search or may be of relatively low quality. For example, a search for “Eiffel Tower” may result in some images that include the Eiffel Tower while others may not.
- the Eiffel Tower may not be the main focus of the image (for example, the image may primarily be a picture of a person standing at the base of the Eiffel Tower, with the Eiffel Tower only minimally visible in the background).
- One aspect is directed to a method that may include receiving a set of images for which ranking scores are to be calculated and determining transitional probabilities between images in the set of images, the transitional probabilities each being an estimate of a likelihood that a user viewing a first image is likely to select a second image.
- the method may further include calculating link-based ranking scores that each define a measure of quality for the images, the link-based ranking scores being calculated using the transitional probabilities as links between images in the set of images; and providing the images to users in an order influenced by the calculated link-based ranking scores.
- Yet another aspect is directed to a method that may include receiving a set of objects and generating virtual links between pairs of objects in the set of objects.
- the method may further include calculating a link-based ranking score for a first object in the set of objects based on the generated virtual links and presenting the first object to a user based on the link-based ranking score of the first object.
- Yet another aspect is directed to a system that comprises a server connected to a network to receive a search query from a user via the network.
- the server includes a database to store descriptive text relating to objects and a processor.
- the processor may generate an initial set of objects relevant to the search query based on a matching of terms in the search query to the descriptive text stored in the database and obtains ranking scores for the objects in the generated set of objects, the ranking scores being based on transitional probabilities that each represent a likelihood that a user having accessed a first object in the set of objects is likely to access a second object in the set of objects.
- the processor may additionally return a result set of objects or links to the objects to the user, the order of the objects in the result set being determined based on the ranking scores for the objects.
- FIG. 1 is a diagram providing a conceptual overview of concepts described herein;
- FIG. 2 is a diagram of an exemplary network in which implementations described herein may be implemented
- FIG. 3 is a diagram of an exemplary client or server shown in FIG. 2 ;
- FIG. 4 is a functional block diagram that illustrates an implementation of an image search engine
- FIG. 5 is a flow chart illustrating exemplary operations that may be performed in generating ranking scores for images
- FIG. 6 is a flow chart illustrating exemplary operations that may be performed in generating transitional probabilities for an input set of images
- FIG. 7 is a graph illustrating an exemplary distribution that can be used to convert similarity metrics into transitional probabilities
- FIG. 8 is a flow chart illustrating exemplary operations for post-processing transitional probabilities
- FIG. 9 is a flow chart illustrating exemplary operations that may be performed generating transitional probabilities for an input set of objects using click-data.
- FIG. 10 is a flow chart illustrating exemplary operations for performing a query-dependent calculation of ranking scores.
- Implementations described herein relate to assigning ranking scores to objects, such as images.
- the ranking scores may define an objective measure of quality of the objects and may be calculated based on “virtual links” between different objects.
- the virtual links do not necessarily need to be explicitly defined by the objects. Instead, the virtual links may be generated using content-based similarity information determined for the objects.
- the objects will be particularly described herein as images, although other types of objects, such as audio or video objects, could also be used.
- FIG. 1 is a diagram providing a conceptual overview of concepts described herein.
- images 110 , 120 , 130 , and 140 are to be ranked. That is, a ranking score is to be generated for each of the images that defines an objective measurement of quality of the images. Images with higher ranking scores should correspond to higher quality or “better” images.
- a content based similarity metric may be calculated for the pair of images.
- This similarity metric may be based on features of the images themselves.
- a number of different possible image features may be used.
- the feature comparison may be based on intensity or color histograms of the images, edge based features of the images, or other features of the images.
- a content-based similarity metric is calculated for each pair of the images shown in FIG. 1 .
- the value of each similarity metric between pairs of images is shown next to a line between the image pairs.
- higher metric values indicate greater similarity between images.
- the value of the content-based similarity metric between image 110 and 140 is 0.8 while the value of the content-based similarity metric between image 120 and 130 is 0.3, which indicates a greater level of similarity between images 110 / 140 than between images 120 / 130 .
- the content-based similarity metrics may be used as, or used as the basis for, “virtual links” between pairs of images 110 , 120 , 130 , and 140 .
- the virtual links can be thought of as analogous to explicit links between objects such as web documents.
- the virtual links described herein are not explicitly defined and are instead estimated from information such as the content-based similarity metric values.
- the virtual links may be used to calculate a final ranking score in a manner similar to the way explicit links between web documents are used to calculate ranking scores for documents.
- PageRankTM for example, is link-based quality score generation technique and is described in “The Anatomy of a Large-Scale Hypertextual Search Engine” by S. Brin and L. Page, 7th International World Wide Web Conference, Brisbane, Australia and U.S. Pat. No. 6,285,999.
- a technique such as PageRankTM or another link-based technique may be used to generate the ranking scores for images 110 , 120 , 130 , and 140 .
- the ranking score for each of images 110 , 120 , 130 , and 140 are shown in FIG. 1 as values within boxes next to image 110 , 120 , 130 , and 140 .
- image 110 may be assigned the ranking score of 0.70
- image 120 may be assigned the ranking score of 0.66
- image 130 may be assigned the ranking score 0.40
- image 140 may be assigned the ranking score of 0.63.
- image 110 may thus be considered to be the highest quality image.
- image 110 may be preferentially displayed to a user.
- FIG. 2 is a diagram of an exemplary network 200 in which implementations described herein may be implemented.
- Network 200 may include multiple clients 210 connected to a server 220 via a network 240 .
- Network 240 may include a local area network (LAN), a wide area network (WAN), a telephone network, such as the Public Switched Telephone Network (PSTN) or a cellular network, an intranet, the Internet, or a combination of networks.
- PSTN Public Switched Telephone Network
- Two clients 210 and one server 220 have been illustrated as connected to network 240 for simplicity. In practice, there may be more clients and/or servers. Also, in some instances, a client may perform one or more functions of a server and a server may perform one or more functions of a client.
- a client 210 may include a device such as a wireless telephone, a personal computer, a personal digital assistant (PDA), a lap top, or another type of computation or communication device, a thread or process running on one of these devices, and/or an object executable by one of these devices.
- Server 220 may include a server device that processes, searches, and/or maintains documents and images. Clients 210 and server 220 may connect to network 240 via wired or wireless connections.
- Server 220 may include an image search engine 225 usable by clients 210 .
- image search engine 225 may return images to the client that are relevant to the client request.
- FIG. 3 is an diagram of an exemplary client 210 or server 220 .
- Client/server 210 / 220 may include a bus 310 , a processor 320 , a main memory 330 , a read only memory (ROM) 340 , a storage device 350 , an input device 360 , an output device 370 , and a communication interface 380 .
- Bus 310 may include conductors that permit communication among the components of client/server 210 / 220 .
- Processor 320 may include a processor(s), a microprocessor(s), or processing logic that interprets and executes instructions.
- Main memory 330 may include a random access memory (RAM) or another type of dynamic storage device that stores information and instructions for execution by processor 320 .
- ROM 340 may include a conventional ROM device or another type of static storage device that stores static information and instructions for use by processor 320 .
- Storage device 350 may include a magnetic and/or optical recording medium and its corresponding drive.
- Input device 360 may include one or more mechanisms that permit a user to input information to client/server 210 / 220 , such as a keyboard, a mouse, a pen, voice recognition and/or biometric mechanisms, etc.
- Output device 370 may include one or more mechanisms that output information to the user, including a display, a printer, a speaker, etc.
- Communication interface 380 may include any transceiver-like mechanism that enables client/server 210 / 220 to communicate with other devices and/or systems.
- communication interface 380 may include mechanisms for communicating with another device or system via a network, such as network 240 .
- server 220 may implement image search engine 225 .
- Image search engine 225 may be stored in a computer-readable medium, such as memory 330 .
- a computer-readable medium may be defined as one or more physical or logical memory devices.
- the software instructions defining image search engine 225 may be read into memory 330 from another computer-readable medium, such as data storage device 350 , or from another device via communication interface 380 .
- the software instructions contained in memory 330 may cause processor 320 to perform processes that will be described later.
- hardwired circuitry or other logic may be used in place of, or in combination with, software instructions to implement processes described herein.
- embodiments described are not limited to any specific combination of hardware circuitry and software.
- FIG. 4 is a functional block diagram that illustrates an implementation of image search engine 225 .
- Image search engine 225 may include a search component 410 , a ranking score generator 415 , an image indexing component 420 , and a database 430 .
- image indexing component 420 may receive input documents, such as HTML web pages retrieved from the web, and parse the input documents for text and images that are to be included in potential results of search engine 225 to a user.
- image indexing component 420 may store images, or links to images, and image descriptive text in database 430 .
- Database 430 generally stores a collection of data.
- Database 430 may be implemented as, for example, a relational or non-relational database capable of storing and accessing data.
- Database 430 may be implemented on a single computing device or distributed across many computing devices and/or storage devices.
- Search component 410 may receive user search queries, such as from clients 210 , search database 430 for results based on the search queries, and generate relevant results (i.e., images or links to images) based on a comparison of the search query to the descriptive text for the images that are stored in database 430 .
- relevant results i.e., images or links to images
- search component 410 may generally match terms in the search query to the descriptive text associated with the images.
- search component may take into account the image ranking score determined for the images that match the search query.
- the ranking scores may be generated by ranking score generator 415 .
- ranking score generator 415 may dynamically generate the ranking scores for images in a set of images that initially match the user's query.
- ranking score generator 415 may generate the ranking scores “offline” (i.e., not in response to a user search query) based on, for example, all of the indexed images or based on subsets of the indexed images.
- the generated ranking scores may be stored in database 430 . Although shown as a separate element in FIG. 4 , in some implementations, ranking score generator 415 may be considered as being part of search component 410 or image indexing component 420 .
- ranking score generator 415 The calculation of the ranking scores by ranking score generator 415 will be described in additional detail below.
- the ranking score for an image can be though as a probability distribution that represents the likelihood that a hypothetical user selects a particular image given the following:
- image A The user randomly selects an image, called image A, from a collection of images.
- image B Another image, called image B, based on a transitional probability of selecting image B given image A.
- Image A is set to image B and (1) through (3) are repeated.
- (1) through (4) if the user is not satisfied with the initial results, the user can select one image among the search results and browse through a new set of “similar” images. The user may then select another image and continue this process until the user finishes the current search session.
- the mechanism described in the preceding paragraph may create probabilistic hyperlinks between images, where the user jumps from one image to another following a certain probability distribution (called the transitional probability, P(A ⁇ B), herein).
- P(A ⁇ B) a probability distribution
- N images with interconnected probability hyperlinks a Markov network with images as nodes and similarity measurements as transitional links is essentially created.
- the image ranking score for each image may therefore be viewed as the stationary probabilistic distribution for the Markov network.
- the accuracy of the image ranking score for an image depends on the accurate estimation of the transitional probability, P(A ⁇ B), given two images A and B.
- FIG. 5 is a flow chart illustrating exemplary operations that may by performed by ranking score generator 415 in generating ranking scores for images.
- Ranking score generator 415 may begin by receiving a set of images for which the ranking scores are to be calculated (act 500 ).
- the set of images may be the entire set of images indexed by image indexing component 420 or a subset of these images.
- the ranking scores may be generated, for example, for a subset of images that correspond to a particular category of images or for the set of images identified in response to a search query.
- Ranking score generator 415 may calculate the transitional probabilities, P(A ⁇ B), between each image A and each other image B (act 510 ). As previously mentioned, this represents the estimated probability that a user viewing image A will select image B.
- the transitional probabilities may be estimated based on content-based similarity metric(s). Calculation of the transitional probabilities is described in more detail below with reference to FIGS. 6-9 .
- the transitional probabilities may be used to determine the ranking scores (act 520 ). Generation of the ranking scores from the transitional probabilities is described in more detail below.
- Results may be output or transmitted to users based on the ranking scores (act 530 ). For example, in an image search, images returned to the user may be sorted in an order determined by or influenced by the ranking scores.
- FIG. 6 is a flow chart illustrating exemplary operations that may by performed to generate the transitional probabilities for an input set of images.
- the transitional probabilities may be generated for images by comparing images in the set of images to one another on an image feature basis.
- Ranking score generator 415 may receive the selection of which features to use (act 601 ).
- image features include image features based on, for example, intensity, color, edges, texture, wavelet based techniques, or other aspects of the image. For example, regarding intensity, each image may be divided into small patches (e.g., rectangles, circles, etc.) and an intensity histogram computed for each patch. Each intensity histogram may be considered to be a feature for the image. Similarly, as an example of a color-based feature, a color histogram may be computed for each patch (or for different patches) within each image.
- a color histogram can be similarly computed to obtain a possible color-based histogram.
- the color histogram may be calculated using any known color space, such as the RGB (red, green, blue) color space, YIQ (luma (Y) and chrominance (IQ)), or another color space.
- Histograms can also be used to represent edge and texture information. For example, histograms can be computed based on patches of edge information or texture information in an image. For wavelet based techniques, a wavelet transform may be computed for each patch and used as an image feature.
- image features discussed above represent an exemplary list of possible image features that may be used.
- image features such as features identified using the known Scale-Invariant Feature Transform (SIFT) may be used.
- SIFT Scale-Invariant Feature Transform
- features may be computed only for certain areas within images.
- “objects of interest” within an image may be determined and image features may only be computed for the objects of interest.
- image features may only be computed for the objects of interest.
- the image feature being used is a color histogram
- a histogram may be computed for each patch in the image that includes an object of interest.
- Objects of interest within an image can be determined in a number of ways. For example, for color, objects of interest may be defined as points where there is high variation in color (i.e., areas where color changes significantly). In general, objects of interest can be determined mathematically in a variety of ways and are frequently based on determining discontinuities or differences from surrounding points.
- the SIFT algorithm is an example of one technique for locating objects of interest.
- the various features described above may be computed using different image scales. For example, an image can be examined and features computed in its original scale and then features may be successively examined at smaller scales. Additionally or alternatively, features may be selected as features that are scale invariant or invariant to affine transformations.
- the SIFT techniques for example, can be used to extract distinctive invariant objects from images. The extracted objects are invariant to image scale and rotation.
- a comparison function For each feature that is to be used, a comparison function may be selected. A number of different comparison functions may be used to compare images. The particular comparison function to use may be decided ahead of time or offline by an administrator.
- Ranking score generator 415 may receive the selection of the comparison functions (act 602 ).
- a comparison function may operate to generate a value defining a similarity between a particular feature computed for two images.
- a simple histogram comparer function which is described in pseudo-code in Table I, below. As shown in Table I, the histogram comparer function returns a value that is the sum of the absolute values of the differences between corresponding bins in the input histograms. Smaller values returned from this function indicate greater similarity between the input histograms.
- the histogram comparer function is exemplary. It can be appreciated that other comparison functions can be used to compare histograms. For example, squared differences may be used rather than absolute differences, bin correlations may be taken into account instead of absolute differences, or percent differences may be used instead of absolute differences. Additionally, for image features other than those based on histograms, different comparison functions may, of course, be used.
- the selection of the image features to use and the comparison functions to use may be performed offline or in non-runtime operation.
- an administrator may initially design or configure ranking score generator 415 to use one or more image features and one or more comparison functions. After these initial acts, ranking score generator 415 may function in a runtime mode (acts 604 - 610 ).
- the selection of image features to use and the comparison functions to use may define a set of possible image features and comparison functions.
- the set of possible image features and comparison functions may be dynamically narrowed. For example, the number of matches for a feature across the images for that feature may be used as a measure as to whether the feature is interesting. Assume, for instance, that the user query “black and white pictures of the london tower” initially generated a number of black and white images. With this set of images, using a color histogram as a feature is not likely to be very helpful. However, other features, such as edge-based features, may play a more important part as they may be more distinguishing.
- a number of techniques may be used to determine whether a feature is interesting for a set of images, such as techniques based on the variation, distribution, or entropy in the responses across images for a feature.
- Ranking score generator 415 may set the first received image as the active image (act 604 ).
- the active image may then be compared to each other image in the set of images (act 605 ).
- the comparison may be based on the image features from act 501 and may be performed using the comparison functions from act 502 .
- act 605 An exemplary implementation of act 605 is shown in pseudo-code in Table II, below.
- Table II the final feature similarity metric is tabulated in the variable “image_similarity_score.”
- each feature F i of the active image is compared with every feature F j of image j that is the same feature type.
- F i is a color histogram then the comparison is performed with the color histogram features of image j, if F i is an edge histogram then the edge histogram features of image j are compared, etc.
- Ranking score generator 415 may assign a similarity metric value to the active image based on the comparison of act 605 (act 606 ).
- the “image_similarity_score” variable indicates how well the features in image i appear in other images and, in this implementation, represents the similarity metric assigned to the active image.
- image_similarity_score is simply the sum of the feature similarity scores for an image.
- the similarity metric may be calculated in other ways, such as by only adding the value of the variable “feature_similarity_score” to “image_similarity_score” when “feature_similarity_score” is above some threshold.
- the similarity metric may be designed so that more similar image features will contribute more significantly to the similarity metric.
- Acts 605 and 606 may be repeated for each image in the set of images (acts 607 and 608 ) to thus obtain a similarity metric for each image in the set of images.
- Acts 605 - 608 can be relatively computationally expensive, as it requires N 2 comparisons among the N images, and for each comparison, M i *M j feature comparisons, for M i and M j local features in each image.
- Techniques are known that may potentially accelerate this type of operation. For example, one such technique is described in the publication “The Pyramid Match Kernel: Discriminative Classification with Sets of Image Features,” K. Grauman et al., Proceedings of the IEEE International Conference on Computer Vision, Beijing, China, October 2005.
- the features used for each of the images may be pre-computed ahead of time and stored, for instance, in database 430 .
- the similarity metrics generated in acts 605 through 608 may be converted to transitional probabilities (act 609 ).
- the transitional probability that a hypothetical user viewing an image A selects an image B, P(A ⁇ B), may be conceptualized based on the following two intuitions: (1) the user is more likely to select an image that is similar to image A than an image that is not; and (2) the user is likely to ignore images that are too similar to image A.
- Intuition (2) reflects the notion that images that are too similar to the currently selected image are essentially redundant to the user.
- FIG. 7 is a graph 700 illustrating one possible distribution, called a conversion function herein, that can be used to convert similarity metrics into transitional probabilities.
- the x-axis represents the similarity metric between image A and B and the y-axis is its corresponding transitional probability.
- P(A ⁇ B) increases monotonically as the value of the similarity metric increases, but drops off sharply when the similarity metric value is above a cutoff point (approximately 0.8 in this example). In this example, assume that the similarity metric value ranges between zero and one.
- the function may be an “editable” function.
- the user may be able to use a settable slider or other graphical tool to set the type of images the user is looking for (e.g., very similar images or less similar images).
- the transitional probabilities may optionally be post-processed to potentially improve the transitional probabilities (act 610 ). This can be useful to make the transitional probabilities more closely correspond to user behavior in the real world. For example, the user may prefer a colorful image over a black-and-white image although the two images may have the same similarity score.
- One possible way to enhance the effectiveness of the transitional probabilities is based on query independent metrics of images.
- FIG. 8 is a flow chart illustrating exemplary operations for enhancing the effectiveness of the transitional probabilities via post-processing of the transitional probabilities as performed in act 610 .
- the operations shown in FIG. 8 may be performed for each transitional probability, P(A ⁇ B), between a document A and a document B.
- Quality(A) may be determined for image A (act 801 ).
- Quality(A) may, for example, measure how much or how well an image is in focus, how many colors are in the image, or the saturation of the image.
- Techniques are known for measuring the “focus” of an image. Such techniques may be based on the sharpness of the image and will not be described further herein.
- techniques for determining the number of colors in an image and determining a measure of the saturation of an image are also known and will not be described further herein.
- Another possible factor for improving transitional probabilities is based on a URL (uniform resource locator) analysis.
- Two images may be considered to be related when the corresponding web pages the images are related. For example, the user may enjoy finding images that are from the same blog, same website, or from the same social network.
- Techniques are known for estimating “similarity” based on relations between objects, such as hyperlinks between web pages.
- One such technique is described in the publication “SimRank: A Measure of Structural-Context Similarity,” G. Jeh and J. Widom, Proceedings of the eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002.
- a value measuring similarity of image A to image B based on the URL analysis may be determined (act 802 ).
- This “hyperlink-induced” similarity between image A and image B will be referred to a LINKSIM(A, B) herein.
- LINKSIM(A, B) may be determined based on the web pages containing images A and B.
- the SimRank technique or another technique capable of estimating similarity based on relationships between objects, may be used to calculate LINKSIM(A,B).
- the initial transitional probability, P(A ⁇ B), determined in act 609 may be modified or calculated based on Quality(A) and LINKSIM(A,B) (act 803 ).
- P(A ⁇ B) may be recalculated as Quality( A ) ⁇ LINKSIM( A,B ) ⁇ SIMILARITY( A,B ), where SIMILARITY(A,B) may refer to a distribution defined over the raw similarity metric values.
- P(A ⁇ B), as determined in act 803 may also be normalized to obtain a desired distribution of the transitional probabilities (act 804 ).
- the normalization may be performed, for example, after a number of or after all of the transitional probabilities are calculated.
- the post processing performed in act 610 may include additional or fewer factors than those shown in FIG. 8 .
- the post processing performed in act 610 may include additional or fewer factors than those shown in FIG. 8 .
- Quality(A) and LINKSIM(A, B) instead of using Quality(A) and LINKSIM(A, B), only one of these factors may be used.
- the transitional probabilities calculated in act 510 may be used to generate ranking scores (act 510 ).
- the ranking score for a particular image may be a function of the ranking scores and transitional probabilities of other images that have a transitional probability of transitioning to the particular image.
- the ranking score for a given image, I(M) may be defined recursively as:
- RankingScores [ I ⁇ ( M 1 ) I ⁇ ( M 2 ) I ⁇ ( M 3 ) ... I ⁇ ( M 4 ) ] , where RankingScores is the solution for
- RankingScores [ P ⁇ ( M 1 -> M 1 ) P ⁇ ( M 2 -> M 1 ) P ⁇ ( M n -> M 1 ) P ⁇ ( M 1 -> M 2 ) ... P ⁇ ( M n -> M 2 ) ... ... P ⁇ ( M 1 -> M n ) ... P ⁇ ( M n -> M n ) ] ⁇ RankingScores , ( Eq . ⁇ 1 ) where each column sums to one.
- a damping factor may be used.
- the damping factor may model the idea that the user is likely to stop selecting images at some point.
- a damping factor d may be defined to have a value between zero and one. With the damping factor, equation (1) becomes:
- RankingScores [ 1 - d N 1 - d N ... 1 - d N ] + d ⁇ [ P ⁇ ( M 1 -> M 1 ) P ⁇ ( M 2 -> M 1 ) P ⁇ ( M n -> M 1 ) P ⁇ ( M 1 -> M 2 ) ... P ⁇ ( M n -> M 2 ) ... ... P ⁇ ( M 1 -> M n ) ... P ⁇ ( M n -> M n ) ] ⁇ RankingScores .
- the ranking scores described above provide a link-based measure of quality for objects (e.g., images) that do not necessarily include explicit links between objects.
- the ranking scores were instead calculated based on “virtual” links determined for the objects based on similarity information (i.e., the transitional probabilities) of the objects.
- the transitional probabilities instead of being based on similarity information, may be based on user click data.
- FIG. 9 is a flow chart illustrating exemplary operations that may be performed to generate the transitional probabilities (as calculated in FIG. 5 , act 510 ) for an input set of objects (e.g., images) using click-data.
- Click-data refers to data gathered from users selecting one or more objects from a larger set of objects. For example, multiple thumbnail images may be displayed to a user in response to the user submitting a search query to an image search engine. The image search engine may log the images eventually selected by the user from the result set of thumbnail images. This logged information may be considered click-data in this situation.
- click-data may be gathered from users (act 900 ).
- the click-data may describe, for example, the number of times or the portion of the time that a user viewing a first image then selects a second image.
- the click-data may be gathered from, for example, user interaction with a web site, such as a search engine, or through information gathered by a toolbar or other program installed at a computer of the user.
- a web site such as a search engine
- a toolbar or other program installed at a computer of the user As one example of useful click-data, consider the situation in which a user is viewing multiple images in a single viewing session.
- the images may be displayed by, for example, an on-line photograph storage site or an image search image. It may be assumed that when a user clicks on multiple images in such a session, that the images are similar.
- the transitional probabilities may be calculated based on the gathered click-data (act 910 ).
- the click data may be used to directly calculate the transitional probabilities. For example, assume that the click-data includes 1000 samples of users viewing a first image A and then selecting a second image B. Assume that of these 1000 samples, 100 times the second image selected by the users was image B.
- the transitional probability, P(A ⁇ B) may be directly calculated as 0.10.
- the click-data described above may be used by itself to generate the transitional probabilities.
- the click-data may be used in addition to the similarity metric values to generate the transitional probabilities.
- the click-data may be used to modify the similarity metric values or vice-versa.
- the ranking scores described above were generally described as being generated over a set of images (act 500 , FIG. 5 ).
- the set can be, for example, all of the images indexed by image indexing component 420 or a subset of these images.
- the set of images may be determined in a search query-independent manner.
- a query-dependent calculation of the ranking scores may also be performed.
- the initial set of images determined in act 500 may be the set of images returned by search engine 225 in response to the initial user search query. For example, if the user submits the search query “Lincoln Memorial,” search engine 225 may retrieve a number of result images (e.g., hundreds or thousands) that are associated with text that matches the search query.
- search engine 225 may retrieve a number of result images (e.g., hundreds or thousands) that are associated with text that matches the search query.
- FIG. 10 is a flow chart illustrating exemplary operations for performing a query-dependent calculation of ranking scores.
- the set of available images may be divided into a number of categories (act 1010 ).
- N categories may be defined.
- the categories may be defined relatively coarsely, such as, for example, “outdoor,” “indoor,” “cars,” “portraits,” “drawings,” etc.
- Images can be categorized in a number of ways, such as based on text associated with the images (e.g., text surrounding an image in a web page that includes the image) or by classification based on the features of the images.
- Each category of images defines a set of images. For each set, a ranking score may be calculated as previously discussed with respect to FIG. 5 (act 1020 ). In some implementations, an image may be categorized as belonging to multiple categories. In this situation, the image may be associated with multiple ranking scores.
- the ranking score used by search engine 225 when returning images to the user may be calculated as a query-dependent combination of ranking scores for the image in the categories (act 1030 ).
- I(A,Q) refers to the ranking score of image A under query Q
- I(A,Q,C i ) refers to the ranking score of image A when calculated over the set of images that match the Query, Q, and are in category C i
- W i refers to a weight value by which I (A,C i ) is multiplied.
- the weights, W i may be calculated based on the semantic distance between the query, Q, and the image category. For example, if Q equals “beach” then the category may be most likely to be “outdoor” and the corresponding weight should be significantly larger than the weight for a category such as “indoor.”
- image search engine 225 may generally operate to transmit images or links to images to a user in response to a user search query.
- the ranking scores may be used by image search engine 225 to assist in ordering the images returned to the user. For example, images may be presented to the user in an order sorted from maximum to lowest ranking score.
- the ranking score of an image may be combined with a relevance score that defines how well text associated with the image matches the user search query. In this situation, images may be presented to the user in an order sorted from maximum to lowest of this combined value. More generally, the ranking score can be used in isolation or in combination with other signals relating to image quality.
- the ranking scores may also be used by image search engine 225 to determine a subset of images to return to a user from a larger set of possible images.
- the ranking scores may be employed in contexts other than a general image search engine.
- any application in which images are to be ranked or in which a subset of an initial set of images are to be selected may be an application that is appropriate for application of ranking score generator 415 .
- Ranking score generator 415 may additionally be used in situations in which it is desirable to find a single most representative image from a set of images. For example, in a product search engine or a news search engine, it may be desirable to display a single image next to a product listing or next to a news article. For a product search engine, for instance, the name of the product may be used as a search query to return an initial set of possible product images. Ranking score generator 415 may be used as described above to rank the initial set of product images. The single highest ranking product image may be chosen to display next to the product listing. Similarly, for a news article search engine, selected text from the news article may be used as a search query to return an initial set of possible images. Ranking score generator 415 may be used as described above to rank the initial set of images. The single highest ranking image may be chosen to display next to the news listing.
- a ranking score calculated as described above may be generated for other sets of objects for which transitional probabilities can be generated.
- ranking scores can be calculated for audio media objects (e.g., songs, audio books, audio clips, etc.) or video media objects (e.g., movies, short video clips, etc.).
- Other domains in which ranking scores can be calculated include book search, stock search, product search, resume search, or other search tasks where the user may find a “see more items like this one” option useful.
- the above-described ranking scores can be calculated for any set of objects in which it is possible to create virtual links based on similarity of the objects or other information, such as user click behavior.
- a set of objects are processed to rank the objects using link-based ranking techniques even when the objects do not include explicit links between them.
- virtual links may be generated based on, for example, similarity between objects or click-data.
- components may be implemented as “components” or “models” that performs one or more functions. These components/models may be implemented as hardware, such as an application specific integrated circuit or a field programmable gate array, software, or a combination of hardware and software.
Abstract
Description
TABLE I | ||||
Compare_histogram_type_features(histogram1,histogram2) | ||||
Difference = 0; | ||||
For all bins, b, in histogram: | ||||
Difference = Difference + |histogram1[b] − | ||||
histogram2[b]| | ||||
Return(Difference). | ||||
TABLE II | ||||
image_similarity_score = 0 | ||||
For each feature Fi of active image i: | ||||
For each image j (where j is not i): | ||||
For each feature Fj of image j that is of type Fi | ||||
feature_similarity_score = compare_features(Fi, Fj) | ||||
image_similarity_score = image_similarity_score + | ||||
feature_similarity_score | ||||
Quality(A)·LINKSIM(A,B)·SIMILARITY(A,B),
where SIMILARITY(A,B) may refer to a distribution defined over the raw similarity metric values.
Alternatively, it is noted that the ranking scores are also the entries of the dominant eigenvector of the transitional probability matrix. Stated formally:
where RankingScores is the solution for
where each column sums to one.
I(A,Q)=I(A,Q,C 1)·W 1 +I(A,Q,C 2)·W 2 + . . . +I(A,Q,C N)·W N,
where I(A,Q) refers to the ranking score of image A under query Q, I(A,Q,Ci) refers to the ranking score of image A when calculated over the set of images that match the Query, Q, and are in category Ci and Wi refers to a weight value by which I (A,Ci) is multiplied. In one implementation, the weights, Wi, may be calculated based on the semantic distance between the query, Q, and the image category. For example, if Q equals “beach” then the category may be most likely to be “outdoor” and the corresponding weight should be significantly larger than the weight for a category such as “indoor.”
Claims (31)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/099,503 US8732187B1 (en) | 2007-04-09 | 2008-04-08 | Link-based ranking of objects that do not include explicitly defined links |
US14/964,697 US9977816B1 (en) | 2007-04-09 | 2015-12-10 | Link-based ranking of objects that do not include explicitly defined links |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US91075707P | 2007-04-09 | 2007-04-09 | |
US12/099,503 US8732187B1 (en) | 2007-04-09 | 2008-04-08 | Link-based ranking of objects that do not include explicitly defined links |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US201414279972A Continuation | 2007-04-09 | 2014-05-16 |
Publications (1)
Publication Number | Publication Date |
---|---|
US8732187B1 true US8732187B1 (en) | 2014-05-20 |
Family
ID=50692363
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/099,503 Active 2029-01-22 US8732187B1 (en) | 2007-04-09 | 2008-04-08 | Link-based ranking of objects that do not include explicitly defined links |
US14/964,697 Active US9977816B1 (en) | 2007-04-09 | 2015-12-10 | Link-based ranking of objects that do not include explicitly defined links |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/964,697 Active US9977816B1 (en) | 2007-04-09 | 2015-12-10 | Link-based ranking of objects that do not include explicitly defined links |
Country Status (1)
Country | Link |
---|---|
US (2) | US8732187B1 (en) |
Cited By (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140250109A1 (en) * | 2011-11-24 | 2014-09-04 | Microsoft Corporation | Reranking using confident image samples |
US9367756B2 (en) | 2010-08-31 | 2016-06-14 | Google Inc. | Selection of representative images |
US9977816B1 (en) | 2007-04-09 | 2018-05-22 | Google Llc | Link-based ranking of objects that do not include explicitly defined links |
US10089762B2 (en) | 2014-07-04 | 2018-10-02 | Mapillary Ab | Methods for navigating through a set of images |
US10282055B2 (en) | 2012-03-06 | 2019-05-07 | Apple Inc. | Ordered processing of edits for a media editing application |
US10552016B2 (en) | 2012-03-06 | 2020-02-04 | Apple Inc. | User interface tools for cropping and straightening image |
US10936173B2 (en) | 2012-03-06 | 2021-03-02 | Apple Inc. | Unified slider control for modifying multiple image properties |
US11030235B2 (en) | 2016-01-04 | 2021-06-08 | Facebook, Inc. | Method for navigating through a set of images |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6285999B1 (en) | 1997-01-10 | 2001-09-04 | The Board Of Trustees Of The Leland Stanford Junior University | Method for node ranking in a linked database |
US20020057343A1 (en) * | 2000-06-30 | 2002-05-16 | Ronk Lawrence J. | Image object ranking |
US20040162827A1 (en) * | 2003-02-19 | 2004-08-19 | Nahava Inc. | Method and apparatus for fundamental operations on token sequences: computing similarity, extracting term values, and searching efficiently |
US20040189691A1 (en) * | 2003-03-28 | 2004-09-30 | Nebojsa Jojic | User interface for adaptive video fast forward |
US20050223031A1 (en) * | 2004-03-30 | 2005-10-06 | Andrew Zisserman | Method and apparatus for retrieving visual object categories from a database containing images |
US7773800B2 (en) * | 2001-06-06 | 2010-08-10 | Ying Liu | Attrasoft image retrieval |
US8090222B1 (en) | 2006-11-15 | 2012-01-03 | Google Inc. | Selection of an image or images most representative of a set of images |
Family Cites Families (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6850252B1 (en) | 1999-10-05 | 2005-02-01 | Steven M. Hoffberg | Intelligent electronic appliance system and method |
US7170632B1 (en) | 1998-05-20 | 2007-01-30 | Fuji Photo Film Co., Ltd. | Image reproducing method and apparatus, image processing method and apparatus, and photographing support system |
FR2779848B1 (en) | 1998-06-15 | 2001-09-14 | Commissariat Energie Atomique | INVARIANT METHOD OF INDEXING AN IMAGE USING FRACTAL CHARACTERIZATIONS AND AT TIMES |
US6751354B2 (en) * | 1999-03-11 | 2004-06-15 | Fuji Xerox Co., Ltd | Methods and apparatuses for video segmentation, classification, and retrieval using image class statistical models |
US6636220B1 (en) * | 2000-01-05 | 2003-10-21 | Microsoft Corporation | Video-based rendering |
US20020038299A1 (en) | 2000-03-20 | 2002-03-28 | Uri Zernik | Interface for presenting information |
JP4287287B2 (en) * | 2002-02-13 | 2009-07-01 | レイファイ コーポレイション | Method and apparatus for acquisition, compression, and characterization of spatiotemporal signals |
US7043474B2 (en) | 2002-04-15 | 2006-05-09 | International Business Machines Corporation | System and method for measuring image similarity based on semantic meaning |
WO2004090752A1 (en) * | 2003-04-14 | 2004-10-21 | Koninklijke Philips Electronics N.V. | Method and apparatus for summarizing a music video using content analysis |
US8732187B1 (en) | 2007-04-09 | 2014-05-20 | Google Inc. | Link-based ranking of objects that do not include explicitly defined links |
-
2008
- 2008-04-08 US US12/099,503 patent/US8732187B1/en active Active
-
2015
- 2015-12-10 US US14/964,697 patent/US9977816B1/en active Active
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6285999B1 (en) | 1997-01-10 | 2001-09-04 | The Board Of Trustees Of The Leland Stanford Junior University | Method for node ranking in a linked database |
US20020057343A1 (en) * | 2000-06-30 | 2002-05-16 | Ronk Lawrence J. | Image object ranking |
US7773800B2 (en) * | 2001-06-06 | 2010-08-10 | Ying Liu | Attrasoft image retrieval |
US20040162827A1 (en) * | 2003-02-19 | 2004-08-19 | Nahava Inc. | Method and apparatus for fundamental operations on token sequences: computing similarity, extracting term values, and searching efficiently |
US20040189691A1 (en) * | 2003-03-28 | 2004-09-30 | Nebojsa Jojic | User interface for adaptive video fast forward |
US20050223031A1 (en) * | 2004-03-30 | 2005-10-06 | Andrew Zisserman | Method and apparatus for retrieving visual object categories from a database containing images |
US8090222B1 (en) | 2006-11-15 | 2012-01-03 | Google Inc. | Selection of an image or images most representative of a set of images |
Non-Patent Citations (12)
Title |
---|
Brin, Sergey et al., "The Anatomy of a Large-Scale Hypertextual Web Search Engine", 7th International World Wide Conference, Brisbane, Australia, 1998, 20 pages. |
Dalal, Navneet, et al., "Histograms of oriented Gradients for Human Detection", Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Jun. 2005, pp. 886-893. |
Gibson, David et al., "Inferring Web Communities from Link Topology", Proc. 9th ACM Conference on Hypertext and Hypermedia, 1998, 10 pages. |
Grauman, Kristen et al., "Pyramid Match Kernels: Discriminative Classification with Sets of Image Features", Massachusetts Institute of Technology, Cambridge, MA, Mar. 17, 2005, 13 pages. |
Haveliwala, T., "Topic-Sensitive PageRank: A Context-Sensitive Ranking Algorithm for Web Search", IEEE Trans. Knowl. Data Eng., 15(4), 2003, pp. 784-796. |
Jeh, G. et al., SimRank: A Measure of Structural-Context Similarity, Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. New York, NY, USA, ACM, (2002), 11 pages. |
Ke, Yan et al., "PCA-SIFT: A More Distinctive Representation for Local Image Descriptors", Proceedings of Computer Vision and Pattern Recognition, 2004, 8 pages. |
Lowe, David G., "Distinctive Image Features from Scale-Invariant Keypoints", International Journal of Computer Vision, 60, 2m 2004, pp. 91-110. |
Lowe, David G., "Local Feature View Clustering for 3D Object Recognition", Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Dec. 2001, 7 pages. |
Mikolajczk, Krystian et al., "A Performance Evaluation of Local Descriptors" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, No. 10, Oct. 2005, pp. 1615-1630. |
Nister, David et al., "Scalable Recognition with a Vocabulary Tree", Proceedings of IEEE Conference Computer Vision and Pattern Recognition, Jun. 2006, pp. 2161-2168. |
Rothganger, Fred et al., "3D Object Modeling and Recognition Using Local Affine-Invariant Image Descriptors and Multi-View Spatial Constraints", Conference on Computer Vision and Pattern Recognition, 2004, 47 pages. |
Cited By (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9977816B1 (en) | 2007-04-09 | 2018-05-22 | Google Llc | Link-based ranking of objects that do not include explicitly defined links |
US9367756B2 (en) | 2010-08-31 | 2016-06-14 | Google Inc. | Selection of representative images |
US20140250109A1 (en) * | 2011-11-24 | 2014-09-04 | Microsoft Corporation | Reranking using confident image samples |
US9384241B2 (en) * | 2011-11-24 | 2016-07-05 | Microsoft Technology Licensing, Llc | Reranking using confident image samples |
US10545631B2 (en) | 2012-03-06 | 2020-01-28 | Apple Inc. | Fanning user interface controls for a media editing application |
US10282055B2 (en) | 2012-03-06 | 2019-05-07 | Apple Inc. | Ordered processing of edits for a media editing application |
US10552016B2 (en) | 2012-03-06 | 2020-02-04 | Apple Inc. | User interface tools for cropping and straightening image |
US10936173B2 (en) | 2012-03-06 | 2021-03-02 | Apple Inc. | Unified slider control for modifying multiple image properties |
US10942634B2 (en) | 2012-03-06 | 2021-03-09 | Apple Inc. | User interface tools for cropping and straightening image |
US11119635B2 (en) | 2012-03-06 | 2021-09-14 | Apple Inc. | Fanning user interface controls for a media editing application |
US11481097B2 (en) | 2012-03-06 | 2022-10-25 | Apple Inc. | User interface tools for cropping and straightening image |
US10089762B2 (en) | 2014-07-04 | 2018-10-02 | Mapillary Ab | Methods for navigating through a set of images |
US11030235B2 (en) | 2016-01-04 | 2021-06-08 | Facebook, Inc. | Method for navigating through a set of images |
Also Published As
Publication number | Publication date |
---|---|
US9977816B1 (en) | 2018-05-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9977816B1 (en) | Link-based ranking of objects that do not include explicitly defined links | |
US11314822B2 (en) | Interface for a universal search | |
US7548936B2 (en) | Systems and methods to present web image search results for effective image browsing | |
US8744191B1 (en) | Selection of an image or images most representative of a set of images | |
US10528650B2 (en) | User interface for presentation of a document | |
US7961986B1 (en) | Ranking of images and image labels | |
US9053115B1 (en) | Query image search | |
JP4587512B2 (en) | Document data inquiry device | |
US8606778B1 (en) | Document ranking based on semantic distance between terms in a document | |
US9436707B2 (en) | Content-based image ranking | |
US7801893B2 (en) | Similarity detection and clustering of images | |
US7849104B2 (en) | Searching heterogeneous interrelated entities | |
US10210179B2 (en) | Dynamic feature weighting | |
US7765209B1 (en) | Indexing and retrieval of blogs | |
EP1435581A2 (en) | Retrieval of structured documents | |
US20030187844A1 (en) | Statistical bigram correlation model for image retrieval | |
US8732165B1 (en) | Automatic determination of whether a document includes an image gallery | |
US8645363B2 (en) | Spreading comments to other documents | |
EP2192503A1 (en) | Optimised tag based searching | |
US8538970B1 (en) | Personalizing search results | |
US8799107B1 (en) | Systems and methods for scoring documents |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:JING, YUSHI;ROWLEY, HENRY A.;BALUJA, SHUMEET;SIGNING DATES FROM 20080201 TO 20080205;REEL/FRAME:020782/0844 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044277/0001Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551)Year of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |