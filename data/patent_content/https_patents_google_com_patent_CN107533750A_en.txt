CN107533750A - Virtual Image Processor instruction set architecture（ISA）With memory model and the exemplary goal hardware with two-dimensional shift array structure - Google Patents
Virtual Image Processor instruction set architecture（ISA）With memory model and the exemplary goal hardware with two-dimensional shift array structure Download PDFInfo
- Publication number
- CN107533750A CN107533750A CN201680019972.2A CN201680019972A CN107533750A CN 107533750 A CN107533750 A CN 107533750A CN 201680019972 A CN201680019972 A CN 201680019972A CN 107533750 A CN107533750 A CN 107533750A
- Authority
- CN
- China
- Prior art keywords
- instruction
- data
- memory
- array
- set architecture
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F30/00—Computer-aided design [CAD]
- G06F30/20—Design optimisation, verification or simulation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/10—Requirements analysis; Specification techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/20—Software design
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/3004—Arrangements for executing specific machine instructions to perform operations on memory
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30098—Register arrangements
- G06F9/30101—Special purpose registers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2200/00—Indexing scheme for image data processing or generation, in general
- G06T2200/28—Indexing scheme for image data processing or generation, in general involving image processing hardware
Abstract
A kind of method is described, being included in instantiation virtual processor, the virtual processor in applied software development environment has instruction set architecture and memory model, and instruction set architecture and memory model have preset the first and second regions of reserved memory.First reserved area preserves the data of input picture array.Second reserved area preserves the data of output image array.Methods described also includes the execution of the memory loading instruction by following step dummy instruction collection framework：Automatically using the first reserved area as target, and the first and second coordinates of the position in the vertical coordinate system expressed in the instruction format using memory loading instruction relative to virtual processor identify desired input data.
Description
Technical field
The field of invention relates generally to image procossing, is more particularly to used in virtual image process instruction collection framework
(ISA) and memory model and with two-dimensional shift array structure exemplary goal hardware.
Background technology
Image procossing is usually directed to the processing of the pixel value to being organized into array.Here, the two-dimensional array of spatial organization is caught
Catch image two-dimensional nature (dimension in addition can include time (for example, sequence of two dimensional image) and data type (for example,
Color)).Under typical scene, the pixel value of array is provided by the camera of generation still image or frame sequence, to catch fortune
Dynamic image.Traditional image processor would generally fall into two kinds it is one of extreme.
The first it is extreme as in general processor or general class processor (for example, leading to vector instruction enhancing
With processor) on the software program that performs perform image processing tasks.Although the first extremely the commonly provided highly versatile is answered
With Software Development Platform, but it combines associated overhead (for example, data outer with piece in instruction fetch and decoding, processing piece, speculating and holding
OK) using more fine-grained data structure can ultimately result in energy that during configuration processor code per unit data consume compared with
It is more.
Second opposite extreme to be applied to very big data block fixing function hard-wired circuitry.Use bigger (phase
For fine granularity) data block directly applies to the circuit of custom design, substantially reduce the power consumption of per unit data.However, use
The fixing function circuit of custom design, which normally results in processor, can only perform one group of limited task.So, second of pole
Lack programmed environment general extensively in end (it is extreme associated with first).
The technology for the power efficiency that the applied software development chance for providing highly versatile combines improved per unit data is put down
Platform is still preferable but missing solution.
The content of the invention
A kind of method is described, is included in instantiation virtual processor, the virtual place in application software development environment
Reason utensil has instruction set architecture and memory model, and instruction set architecture and memory model have preset the first of reserved memory
And second area.First reserved area preserves the data of input picture array.Second reserved area preserves output image array
Data.This method also includes the execution of the memory loading instruction by following step dummy instruction collection framework：Automatically first
Reserved area is loaded in the vertical coordinate system expressed in the instruction format of instruction relatively as target, and using the memory
The first and second coordinates in the position of virtual processor identify desired input data.
Brief description of the drawings
The following description and drawings are used to illustrate embodiments of the invention.In figure：
Fig. 1 shows the various assemblies of technology platform；
Fig. 2 a show the embodiment of the application software built with kernel；
Fig. 2 b show the embodiment of the structure of kernel；
Fig. 3 shows the embodiment of the operation of kernel；
Fig. 4 a, Fig. 4 b and Fig. 4 c depict the virtual place for the developing kernel thread in advanced applied software development environment
Manage the various aspects of the memory model of device；
Fig. 5 a show to utilize the embodiment of the thread of the loading instruction write-in with position relative format；
Fig. 5 b show the image with different pixels density；
Fig. 6 shows the embodiment of applied software development and simulated environment；
Fig. 7 shows the embodiment of image processor hardware structure；
Fig. 8 a, Fig. 8 b, Fig. 8 c, Fig. 8 d and Fig. 8 e depict image data analyzing by overlapping template into line-group, by line
Group is parsed into data slice and performs operation to data slice；
Fig. 9 a show the embodiment of template processor；
Fig. 9 b show the embodiment of the coding line of template processor；
Figure 10 shows the embodiment of the Data Computation Unit in template processor；
Figure 11 a, Figure 11 b, Figure 11 c, Figure 11 d, Figure 11 e, Figure 11 f, Figure 11 g, Figure 11 h, Figure 11 i, Figure 11 j and Figure 11 k are retouched
Draw and the example of a pair of adjacent output pixel values is determined using two-dimensional shift array and execution channel array by overlapping template；
Figure 12 shows the embodiment for the integrated unit cell for performing channel array and two-dimensional shift array；
Figure 13 shows the embodiment of computing system.
Embodiment
I. brief introduction
Herein below describes some embodiments on new images treatment technology platform, and the platform provides and uses larger data
The applied software development ring that can implement to hardware structure of block (for example, line buffer and data slice for being discussed further below)
Border, to provide improved power efficiency.
1.0 applied software development environment
A. the application of kernel and structure
Fig. 1 shows the high-level view of image processor technology platform, and the platform includes virtual image processing environment 101, reality
Border image processing hardware 103 and for the high-level code write to virtual processing environment 101 to be translated into the thing of actual hardware 103
The compiler 102 of the object code performed in reason.As detailed below, virtual processing environment 101 is wide in the application aspect that can be developed
Simple visualization that is general general and being customized for applying anabolic process.Program code exploitation work is completed by developer 104
After work, compiler 102 is translated into the code write in virtual processing environment 101 object code for actual hardware 103.
The structure and the example of form that the application software that Fig. 2 a show to write in virtual environment can be taken.Such as Fig. 2 a institutes
Show, it is contemplated that program code handles one or more frames of input image data 201, so as to realize to input image data
201 certain integral transformation.Pass through the program generation to be operated by the chronological order that developer expresses to input image data
The operation of one or more kernels of code 202 converts to realize.
For example, as shown in Figure 2 a, by handling each input picture with the first kernel K1 first to realize integral transformation.So
Afterwards, the output image as caused by kernel K1 is operated by kernel K2.Then, by kernel K3_1 or K3_2 to by interior
Each being operated in output image caused by core K2.Then, by kernel K4 to the output as caused by kernel K3_1/K3_2
Image is operated.Kernel K3_1 and K3_2 can be identical kernels, it is intended to be added by implementing parallel processing in the K3 stages
Fast disposed of in its entirety, or they can be different kernels (for example, kernel K3_1 enters to the first certain types of input picture
Row operation, and kernel K3_2 operates to second of different types of input picture).
So, larger general image processing sequence can take image processing pipeline or directed acyclic graph (DAG)
Form, and development environment can be equipped to developer is actual and provide the expression of program code so developed
(representation).Kernel can individually be developed by developer and/or can be (all by providing the entity of any Floor layer Technology
As actual signal processor hardware and/or its design) and/or by third party (be, for example, development environment write kernel software
Supplier) provide.As a result, it is contemplated that nominal development environment will include kernel " storehouse ", developer by various modes freely
" interim connection " kernel library, to complete the overall procedure of large-scale development.It is expected that some as a this storehouse part are basic
Kernel can include providing kernel one or more in following primary image processing task：Convolution, denoising, color space turn
Change, edge and Corner Detection, sharpening, white balance, gamma correction, tone mapping, matrix multiple, image registration, pyramid construction,
Wavelet transformation, piecemeal discrete cosine and Fourier transformation.
Fig. 2 b show the example plot of the structure for the kernel 203 that developer is contemplated that.As shown in Figure 2 b, kernel 203
Some parallel threads (" thread ") 204 of program code can be counted as, each of which is in corresponding floor processor 205
Operation, wherein each processor 205 is directed to the ad-hoc location in output array 206 (such as just in the output image of generation kernel
Specific pixel location).For the sake of simplicity, three processors and corresponding thread are only shown in figure 2b.In various embodiments,
The output array position each described can have the application specific processor of its own and corresponding thread.That is, to exporting battle array
Each pixel in row, single processor and thread can be distributed.In alternative method, same thread can generate multiple outputs
The data of pixel, and/or two different threads (for example, under some limited cases) can cooperate with generation for identical
The data of output pixel.
As detailed below, in various embodiments, in the bottom hardware of reality, perform road (execution lane)
Array is consistent with corresponding thread to work (for example, in a manner of single-instruction multiple-data (SIMD) type), is used to currently be located with generation
Manage the output image data of the part of " line-group (the line group) " of frame.Line-group is the continuous size adjustable of picture frame
Part.In various embodiments, developer may realize that, hardware operates to line-group, or development environment can provide
One kind is abstract, single processor and thread be present in this is abstract, such as each pixel in output frame (for example, defeated
The each pixel gone out in frame is generated by the application specific processor and thread of its own).Anyway, in various embodiments, develop
Person understand, kernel include for each output pixel individual threads (whether the visualization of output array be whole output frame or
Person's a portion).
As detailed below, in one embodiment, the processor 205 provided in virtual environment to developer has instruction set
Framework (ISA), it not only supports standard (for example, RISC) command code, but also refers to including the data access with special format
Order, this allows for developer easily to visualize the processing pixel-by-pixel being carrying out.With reference to traditional mathematics and program control operations
The ability that the whole ISA of code easily defined/visualized any input array position allows highly versatile programmed environment, and its is basic
It is upper to allow application developer ideally to define any required function to be performed on the imaging surface of any size.Example
Such as, it is desirable that easily any mathematical operation can be programmed to suitable for any template size.
On data access command, in one embodiment, it is special that the ISA of virtual processor (" virtual ISA ") includes
Data load instruction and special instruction data storage.Data load instruction can be from any in the input array of view data
Read position.Any position that instruction data storage can be write in the output array of view data.Latter instruction is allowed easily
Multiple instance-specifics of same processor, in different output pixel positions, (each processor is write in output array not on ground
Same pixel).So, for example, template size in itself (for example, being expressed as the width of pixel and the height of pixel) can turn into be easy to
The feature of programming.The visualization of processing operation is further simplified, and each having in special loading and store instruction is special
Instruction format, Target Aerial Array position is simply thus appointed as X-coordinate and Y-coordinate.
Anyway, by each to instantiate single processor in multiple positions in output array, handling
Device can be performed in parallel their own thread so that for example produce the analog value of whole positions in output array simultaneously.Value
Obtain it is noted that many image procossing routines generally perform identical operation to the different pixels of identical output image.So, exist
In one embodiment of development environment, it is assumed that each processor is identical and performs identical multi-threaded program code.Therefore,
The environment of virtualization can be considered as a type of two-dimentional (2D) SIMD processor, its by such as same processor 2D arrays
Composition, each processor perform identical code with lock-step.
Fig. 3 shows the place of two virtual processors of the same code of two different pixels positions in positive processing output array
Manage the more detailed example of environment.Fig. 3 shows the output array 304 for corresponding to the output image just generated.Here, first is virtual
The code that processor is just handling thread 301 to generate output valve at the position X1 of output array 304, and the second virtual place
Reason device is just handling the code of thread 302 with the generation output valve 304 at the position X2 of output array.In addition, in various embodiments
In, developer should be understood that for each location of pixels (only showing two of which for concise Fig. 3) in output array 304, exist
Single processor and thread.However, in various embodiments, developer only needs generation of the exploitation for a processor and thread
Code (because SIMD classes property of machine).
As known in the art, output pixel value includes and surrounded to correspond to output pixel position frequently by those are handled
The pixel of input array determines.For example, as from figure 3, it can be seen that the position X1 of output array 304 corresponds to input array
303 position E.Therefore, the masterplate (stencil) for being processed to determine the output valve X1 pixel value of input array 303 corresponds to
Input value ABCDEFGHI.Similarly, the template for being processed to determine output valve X2 input array pixel corresponds to input value
DEFGHIJKL。
Fig. 3 illustrates the ability to be used for calculate virtual environment corresponding to output valve X1 and X2 a pair of threads 301,302 respectively
The example of program code.In the example of fig. 3, two pairs of codes are the templates of identical and average nine input array values, with
It is determined that corresponding output valve.Unique difference between two threads is the output battle array for the variable and write-in called from input array
The position of row.Specifically, the thread for writing outgoing position X1 is run on template ABCDEFGHI, and writes outgoing position X2's
Thread is run on template DEFGHIJKL.
Such as each virtual processor is can be seen that from the corresponding program code of a pair of threads 301,302 comprise at least inside
Register R1 and R2 and at least support to give an order：1) LOAD instruction from input array to R1；2) from input array to R2
LOAD instruction；3) content plus R1 and R2 and the ADD instruction that result is placed in R2；4) the value in R2 divided by immediately
The DIV instructions of operand 9；And 5) R2 content is stored in the store instruction of the special output array position of thread.In addition, to the greatest extent
Pipe depicts only two output array positions and only two threads and corresponding processor in figure 3, but it is contemplated that can
The virtual processor of these functions and corresponding thread are performed for each position distribution in output array.In various embodiments
In, according to the SIMD class properties of processing environment, multiple threads perform in isolation from each other.That is, do not have between virtual processor
There is the communication of thread to thread (a SIMD channel, which is hampered by, crosses into another SIMD channel).
B. the memory model of virtual processor
In various embodiments, the correlated characteristic of each virtual processor is their memory model.Such as institute in this area
Understand, processor is operated to the data from memory read data and new data are write back in memory.Storage
Device model is processor with the perspective view or view the mode in data tissue to memory.Fig. 4 a to Fig. 4 c are related to use
In the embodiment of the memory model of the virtual processor of development environment.For exemplary purposes, it is virtual using only relating to three
The simplification environment of processor and corresponding thread 401.As detailed below, the memory model of virtual processor pays attention to retaining SIMD languages
Justice, and provide scalar operation and special median memory space simultaneously for each virtual processor.
As shown in fig. 4 a, in one embodiment, the storage region that each virtual processor therefrom operates is according to storage
The type of information and be organized into six kinds of different subregions.Specifically have：1) special (private) staging area 402；2) it is global
Input data array region 403；3) global output data array region 404；4) global look-up table information area 405；5) it is global
Atom statistical regions 406；And 6) global constant table information area 407.
As subregion that Fig. 4 a are described attempt to make according to the SIMD classes property of disposed of in its entirety environment virtual processor it
Between share or " overall situation " memory those area visualizations.Similarly, Fig. 4 a also attempt to make not virtual processor it
Between share or be to specific virtual processor " special " memory other area visualizations.Specifically, as shown in fig. 4 a,
In addition to the special staging area 402 of each virtual processor, whole memory partitions are all global.As retouched further below
State, several different memory areas also have different memory addressing schemes.
On staging area 402, during complicated image processing algorithm is performed, interim storage average information is not
Rare (for example, then read back again information and use the information later).In addition, such information is to different threads and different
(there may be different medians for different input values) is also not uncommon for.Therefore, it is special to include each processor for memory model
Staging area 402, for storing such average information by the corresponding thread of each virtual processor.In a reality
Apply in example, the staging area of par-ticular processor by the processor by typical case's (for example, linear) random access memory address come
Access 409 and be memory read/write area (that is, virtual processor can from private memory read information and will letter
Breath write-in private memory).The formal virtual processor ISA for being used to access staging area is discussed in more detail further below to refer to
The embodiment of order.
Input array part 403 includes input data set, and it is transferred 408 sets of threads to produce output data.In typical case
In the case of, input array corresponds to each thread in the image (for example, frame) or image section either run thereon in it.It is defeated
It can truly input to enter image, the Pixel Information such as provided by camera, or some form of intermediate image, such as exist
The information provided in larger general image processing sequence by previous kernel.Virtual processor does not compete identical input generally
Data item, because they are operated during same period to the different pixels position of input image data.
In one embodiment, which calls from input array 403 to define using the memory addressing scheme of novelty
Specific input value.Specifically, " position is relative " addressing scheme, the unconventional linear memory address using X, Y-coordinate are used
To define required input data.So, virtual processor ISA loading is instructed using X-component and Y-component identified input
The instruction format of specific memory location in array.So, memory is addressed using two-dimensional coordinate system so that from input battle array
Input value is read in row 403.
The image-region for allowing virtual processor just operating using position facing memory addressing method is easier to be developed
Person identifies.As described above, with reference to traditional mathematics and program control operations code whole ISA easily define/visualize it is any defeated
The ability for entering array position allows highly versatile programmed environment, and it substantially allows application developer to be ideally easy to fixed
Any required function that justice will perform on the imaging surface of any size.It is more fully described further below for using position
Put the embodiment of the various instruction format embodiments of the instruction of relative addressing scheme and the ISA supported other features.
Output array 404 includes the output image data that thread is responsible for generation.The output image data can be such as after
The final image data of actual image data over the display are presented after whole image processing sequence, or can be overall
The follow-up kernel of image processing sequence is used as the intermediate image data of its input image data information.In addition, generally, virtual processing
Device will not compete identical output data item, because they write the different pixels position of output image data during same period
Put.
In one embodiment, relative addressing scheme in position also be used to write output array.So, each virtual processing
The ISA of device includes store instruction, and its instruction format is defined as the target writing position in memory the X of two dimension, Y-coordinate, and
It is not traditional random access memory address.The embodiment of the position relative instruction on virtual ISA is further provided below
More details.
Fig. 4 a also illustrate each virtual processor to being performed in the look-up table 411 that is maintained in look-up table storage region 405
Search 410.Look-up table is commonly used in image processing tasks, for example, to obtain the wave filter of different array positions or conversion
Coefficient, complicated function (for example, gamma curve, sine, cosine) is realized, wherein look-up table is that the offer function such as input index value is defeated
Go out.Herein, it is contemplated that SIMD image processing sequences are often performed into identical look-up table during the identical clock cycle and looked into
Look for.So, such as input and output array memory area 403,404, search table section 405 and be available for any virtual processor complete
Office accesses.Fig. 4 a equally show effectively to search information from the same look-up table 411 being stored in look-up table storage region 405
It is each in three virtual processors.
In one embodiment, because index value is commonly used for defining required lookup table entries, therefore using just
Normal linear access scheme accesses look-up table information area.In one embodiment, the lookup region of memory is read-only
(that is, processor can not be changed in look-up table information and be only allowed read information therefrom).For the sake of simplicity, Fig. 4 a are only shown
One look-up table, which resides on, to be searched in table section 405, but virtual environment allows multiple different look-up tables during dry run
Resident.The embodiment of the virtual ISA instruction formats for the instruction that lookup is performed in look-up table is further provided below.
Fig. 4 b show each into three virtual processors of the write-in of atom statistical regions 406 413.Output information is entered
Appropriateness change is gone " renewal " or does to be not uncommon for for image procossing.It is then possible to the information of renewal is used for profit again
With other downstream processes of the information of the renewal.It is inclined with fixing that such renewal or the example moderately changed include output data
The simple addition that moves, simple be multiplied of output data and multiplicand either make the minimum value or most of output data and some threshold value
Big value compares.
In these sequences, as shown in Figure 4 b, the output data just calculated by each thread can be operated,
And result is write atom statistical regions 406.Semantic according to realizing, the output data operated by atomic action can be by
Reason device is internally preserved or called from output array, and Fig. 4 b show the latter 412.In various embodiments, can be to output
The atomic action that data perform includes addition, multiplication, minimized and maximizing.In one embodiment, in view of to output
The renewal of data can logically be organized into output data identical two-dimensional array itself, use position relative addressing scheme
Atom statistical regions 406 are accessed (as input and output array access).It is more fully described further below for defeated
Go out data to perform atomic action and write the result into the embodiment of the virtual ISA instruction formats of statistical regions 406.
Fig. 4 c show to read the virtual processing of 414 constant values in the constant look-up table 424 out of constant storage region 407
It is each in device.Here, for example, it is contemplated that in different threads in the same clock cycle (for example, the spy for whole image application
Determine multiplier) on may need identical constant or other values.Therefore, as illustrated in fig. 4 c, to the access of constant look-up table 415
Each return identical scalar value into virtual processor.Because look-up table generally is accessed using index value, in a reality
Apply in example, access storage address using linear random to access constant look-up table memory block.In one embodiment, memory
Constant section be read-only (that is, processor can not be changed in constant table information and be only allowed read information therefrom).
For the sake of simplicity, Fig. 4 c only show the single constant look-up table 415 in constant area domain 407.Because thread can use one
More than as table memory area 407, it is configured to the constant table that capacity is enough to accommodate needs/use.
C. virtual processor ISA
As mentioned in above in multiple examples, virtual processor ISA can include some correlated characteristics.Below will be right
Some of them are described in detail.
In various embodiments, the ISA of each virtual processor instruction format using relative positioning method come to be following
Each definition X of items, Y-coordinate：1) LOAD instruction of input image data is read from input array storage region；2) output
The STORE instructions of view data write-in output array；And 3) to the atomic update of the statistical regions of memory.
Any input array is easily defined with reference to the whole ISA of traditional data access, mathematics and program control operations code
The ability of position allows highly versatile programmed environment, and it substantially allows application developer ideally to define will be any
Any required function performed on the imaging surface of size.For example, it is desirable that easily any mathematical operation can be programmed to
Suitable for any template size.
In one embodiment, the instruction for loading from input array/being stored to output array has following form：
[OPCODE]LINEGROUP_(name)[(((X*XS+X0)/XD)；((Y*YS+Y0)/YD)；Z]
Wherein, [OPCODE] is certain types of operation (LOAD from input array, the STORE to output array), and
And LINEGROUP_ (name) is the name for the specific part that specific image is distributed in input or output array storage region
Claim (for example, line-group of the frame of view data).Here, because being operated respectively to different line-groups, different line-groups is assigned
Different titles is given, so they can just be uniquely identified/access (for example, LINEGROUP_1, LINEGROUP_2 etc.).
Line-group of the same name is there may be in input array storage region and output array storage region.The origin of any line-group can example
The lower left corner in its appropriate storage region in this way.
In the case where performing the instruction of renewal to atomic summary table, in one embodiment, instruction format is taken following
Similar structures：
[OPCODE]STATS_(name)[(((X*XS+X0)/XD)；((Y*YS+Y0)/YD)；Z]
Significant difference is, the position in input operand information definition certain statistical table (STATS_ (name)), rather than
Specific line-group in input or output array.For line-group, different titles is assigned to different statistical forms, so as to thread
Different statistical forms can uniquely be operated in its operating process.[OPCODE] specifies the specific atoms to be performed to move
Make (for example, STAT_ADD, STAT_MUL, STAT_MIN, STAT_MAX).
Accessed for input/output array access or atomic summary table, the target that the Z operands of instruction define instruction is
The line-group of name or which passage of statistical form.Here, generally, single image has multiple passages (channel).For example,
For the same frame of video flowing, video image generally has red channel (R), green channel (G) and blue channel (B).At certain
In kind meaning, complete image can be considered as independent R, G and channel B image superposed on one another.Z operands define the target of instruction
It is which of these passages (such as Z=0 corresponds to red channel, and Z=1 corresponds to blue channel, and Z=2 corresponds to green channel).Often
Individual line-group and statistical form are thereby configured to the content for each passage for including the specific image for just handling.
(X*XS+X0)/XD operands are defined as the X position in the name line-group or statistical form of instruction target, and (Y*
YS+Y0)/YD operands are defined as the Y location in the name line-group or statistical form of instruction target.For X position XS and
XD items and YS and YD items for Y location be used to enter between the input picture with different pixels density and output image
Row scaling.Scaling is detailed further below.
In the simplest situations, between input picture and output image without scaling, and the X and Y-component of instruction format
X+X0 and Y+Y0 form are simply taken, wherein X0 and Y0 are the position offsets relative to thread slot.Thread is considered as
Distribute to the position in the output array line-group that output valve is written into.Corresponding same position is easy to can be in input array line-group
Identified with any statistical form.
If as an example, being assigned with output array LINEGROUP_1 specific X, Y location to thread, instruct
LOAD LINEGROUP_1[(X-1)；(Y-1)；Z]
Identical X, Y location will be loaded in input array from LINEGROUP_1 to the first from left location of pixels and to next
The value of location of pixels.
Therefore, as shown in Figure 5 a, the simple fuzzy control core taken the mean to X, Y location together with the pixel value of its left and right neighbours can
To be written to false code.As shown in Figure 5 a, position ((X)；(Y) position of the virtual processor of positive write-in output array) is corresponded to
Put.In above-mentioned false code, LOAD corresponds to the command code of the loading from input array, and STORE corresponds to storage to output
The command code of array.Pay attention to LINEGROUP_1 in input array being present, and LINEGROUP_1 in output array be present.
Fig. 5 b depict the zoomed image of the zoom feature for explaining relative positioning loading and store instruction form.Under adopt
Sample refers to, by providing in the output image less than whole pixels present in input picture, high-definition picture is converted into low
Image in different resolution.Up-sampling refers to by creating in the output image more than pixel present in input picture, by low resolution
Image is converted to high-definition picture.
For example, referring to Fig. 5 b, if image 501 represents input picture, and image 502 represents output image, then will hold
Row down-sampling, because the pixel in output image is less than the pixel in input picture.Here, to each picture in output image
Element, determine output pixel output valve input picture in related pixel progress " remote " output image in along any axle move
Dynamic output pixel position.For example, to 3:1 down-sampling ratio, correspond to input along the first pixel of any axle in output image
Along first, second, and third pixel of same axle in image, the second pixel in output image correspond in input picture the
4th, the 5th and the 6th pixel etc..Therefore, the first output pixel has related pixel in the 3rd position, and the second output pixel exists
6th position has related pixel.
So, XS the and YS multiplicand items in relative positioning instruction format be used to realize down-sampling.If Fig. 5 a mould
Paste false code is rewritten as 3 along two axles:1 down-sampling, then code will be rewritten as：
R1<=LOAD LINEGROUP_1 [((3X) -1)；3(Y)；0]
R2<=LOAD LINEGROUP_1 [3 (X)；3(Y)；0]
R3<=LOAD LINEGROUP_1 [((3X)+1)；3(Y)；0]
R2<=ADD R1, R2
R2<=ADD R2, R3
R2<=DIV R2,3
STORE LINEGROUP_1[(X)；(Y)；(0)]；R2.
And 1：In the case of 3 up-samplings (for example, image 502 is input picture, and image 501 is output image),
XD and YD factors will be used for create three output pixels along each input pixel of any axle.So, code obfuscation will be by
It is rewritten as：
R1<=LOAD LINEGROUP_1 [(X-1)/3；(Y)/3；0]
R2<=LOAD LINEGROUP_1 [(X)/3；(Y)/3；0]
R3<=LOAD LINEGROUP_1 [(X+1)/3；(Y)/3；0]
R2<=ADD R1, R2
R2<=ADD R2, R3
R2<=DIV R2,3
STORE LINEGROUP_1[(X)；(Y)；(0)]；R2
In various embodiments, accessing the instruction format of the instruction of the special of memory, constant and lookup part includes
The operand of a*b+c forms is taken, wherein a is home position, and b is scaling item, and c is offset.Linearly sought however, taking herein
Location method, wherein a*b+c items correspond essentially to the linear directory applied to object table.It is each also including behaviour in these instructions
The identifier of memory area made code and just accessed.Can be with table for example, performing the instruction searched to storage region from look-up table
It is shown as：
LOAD LKUP_(name)[(A*B+C)]。
Wherein, LOAD is the command code of mark loading operation, and LKUP_ (name) specifies the look-up table storage just accessed
The title of look-up table in region.In addition, thread can use multiple look-up tables, therefore look-up table is identified using nomenclature scheme
Appropriate one present in memory area in more than one look-up table.
It is constant and dedicated memory region that similar form with the similar command code being intended to, which can be used in target,
Instruction is (for example, LOAD CNST_ (name) [(A*B+C)], LOAD PRVT_ (name) [(A*B+C)].In one embodiment,
Look-up table and constant table access are read-only (processor can not change the data having been placed in herein).So, these storage regions
STORE is just not present to instruct.In one embodiment, the reserved area of memory is by read/write.So, the storage region is just deposited
At store instruction (for example, STORE PRVT [(A*B+C)]).
In various embodiments, each virtual processor includes that the general of integer, floating-point or fixed-point values can be contained
Register.In addition, general register can include the data value of configurable bit width, the place value of such as 8,16 or 32.Therefore, it is defeated
Entering array, either the view data of each pixel position can have the size of data of 8,16 or 32 in output array.
This, virtual processor can be configured as the position size of value established in general register and the execution pattern of numeric format.Refer to
Order can also specify immediate operand, and (input value of these input operands is directly in instruction middle expression in itself, rather than referring to
Searched in fixed register).Real time operation number can also have 8,16 or 32 configurable bit widths.
In the embodiment of extension, each virtual processor can also be with the scalar mode of itself inside or SIMD moulds
Formula is operated.That is, data in specific array position can be considered as scalar value or with multiple elements to
Amount.For example, the first configuration can establish the scalar operation of 8, wherein each pattern matrix position keeps 8 place values of scalar.
Conversely, another configuration can establish the parallel/SIMD computings of 32, wherein assuming that each pattern matrix position is kept for four 8
Place value, the total data size of 32 for each array position.
In various embodiments, each virtual processor also includes being used for the register for preserving predicate value.Single predicate value
In length generally only one and represent to available data perform it is true/false or more than/be less than test command code
Result.Using predicate value, for example, to be determined during execution by the branch direction of code (thus as conditional branching
Operand in instruction).Predicate value can also be expressed as the immediate operand in instruction.
In various embodiments, each virtual processor includes being used for the register for preserving scalar value.Here, scalar value quilt
Store in the partition space of the memory model retained by constant and read (being discussed above with reference to Fig. 4 c) therefrom.
This, each virtual processor handled in one group of virtual processor of identical image is used from the identical of constant storage space
Scalar value.In the embodiment of extension, scalar predicate also be present.These, which are stored in register space, meets predicate and scalar
Definition value.
In various embodiments, each virtual processor is designed to RISC class instruction set, its arithmetic instruction supported behaviour
Making code includes any feasible combination of code below：1) ADD (operand A is added with B)；2) SUB (operand A and B subtract each other)；3)
Operand (is moved to another register) by MOV from a register；4) MUL (multiplying operand A and B)；5) MAD (operand A
It is multiplied with B and C is added in result)；6) ABS (absolute value for returning to operand A)；7) DIV is (by operand B divided by operation
Number A)；8) SHL (shifted left operand A)；9) SHR (right shift operand A)；10) MIN/MAX (returns to operand A and B
In larger one)；11) SEL (selection operation number A specified bytes)；12) AND (logical AND for returning to operand A and B)；
13) OR (return operand A and B logic or)；14) XOR (the logic XOR for returning to operand A and B)；15) NOT (returns to behaviour
Count A logical inverse).
The instruction set also predicate including standard operates, such as：1) SEQ (1 is returned if A equals B)；2) SNE is (if A
Then returned 1) not equal to B；3) SLT (returning to 1 if A is less than B)；4) SLE (returning to 1 if A is less than or equal to B).Also wrap
Controlling stream instruction, such as JMP (redirecting) and BRANCH are included, wherein can each include nominal variable or predicate as operation
Number.
D. applied software development and simulated environment
Fig. 6 depicts applied software development and simulated environment 601.Discussed as discussed above concerning Fig. 2, developer can pass through
Kernel is arranged in the policy sequence being consistent with the conversion of overall goals image, develops comprehensive image processing function (for example, flowing water
Each level in line performs the image processing pipeline of proprietary image processing tasks, routine set as defined in some other DAG
Deng).Kernel, and/or developer can be called to develop one or more customization kernels from storehouse 602.
Kernel (kernel) in storehouse 602 can be by the third-party vendor of kernel and/or the offer of any basic technology
Person provides (e.g., including supplier of the hardware platform of target hardware image processor or target hardware image processor
Supplier (for example, as its design or as actual hardware provide)).
In the case of the kernel of customized development, in many cases, developer only needs to write program for single thread 603
Code.That is, developer only need to be by reference to the input pixel value relative to output pixel position (for example, using above-mentioned
Position facing memory access instruction form), write the program code for determining single output pixel value.Meeting single thread 603
Operation after, development environment can again on corresponding virtual processor automatically instantiation thread code multiple examples so that
Kernel is realized on the processor array operated to imaging surface region.Imaging surface region can be one section of picture frame
(such as line-group).
In various embodiments, the multi-threaded program code of customization be written into virtual processor ISA object code (or
It is compiled to the high-level language of virtual processor ISA object codes).Including accessing the memory according to memory model tissue
Virtual processor dry run when environment in, the execution of program code for customizing kernel can be simulated.It is here, empty
Intend the software model 604 of processor and the software model 605 (object-oriented or otherwise) of memory comprising model
It is instantiated.
Then, the execution of the simulation thread code 603 of virtual processor model 604.Meet thread, its larger kernel and
After the performance of any larger function belonging to the kernel, the realistic objective code of bottom hardware is integrally compiled into.Whole simulation
Environment 601 may be implemented as the software run in computer system (for example, work station) 606.
Sections below description is write in the applied software development environment with the various features in the environment being discussed above
Application software exemplary goal hardware structure embodiment.It is necessary to note that target hardware described below is only example
Hardware structure (architecture) that is property and well imagining many other replacements should be by aforementioned software development environment
The code write orients.
The embodiment of 2.0 hardware structures
A. image processor hardware structure and operation
Fig. 7 is shown for the embodiment of the framework 700 of hard-wired image processor.Image processor can be such as
As the target of compiler, the compiler will be the program code conversion that the virtual processor in simulated environment is write into by hardware
The actual program code performed of processor.As shown in fig. 7, framework 700 include by network 704 (for example, network-on-chip (NOC),
Including loop network or other kinds of network on exchange network on piece, piece) it is interconnected to multiple masterplate processor unit 702_1
To 702_N and corresponding data slice maker unit 703_1 to 703_N multiple line buffer memory unit 701_1 to 701_M.
In one embodiment, any line buffer memory unit can be connected to any data slice maker and correspondingly by network 704
Template processor.
In one embodiment, program code is compiled and is loaded into corresponding template processor 702 to perform by soft
(program code can also be loaded into the related data piece life of template processor to the image processing operations that part developer defines previously
Grow up to be a useful person on 703, for example, this depends on design and implemented).In at least some examples, image processing pipeline can pass through by
The first kernel program for the first pipeline stages is loaded into the first template processor 702_1, will be used for the second pipeline stages
The second kernel program be loaded into that the second template processor 702_2 is medium to be realized, wherein the of the first kernel execution pipeline
The function of one-level, the function of the second level of the second kernel execution pipeline etc., and additional controlling stream method is installed, will be defeated
Go out the next stage that view data is transformed into streamline from the one-level of streamline.
In other configurations, image processor may be implemented as two or two with operation same kernel program code
Individual template above processor 702_1,702_2 parallel machine.For example, the high density and high data rate stream of view data can lead to
The multiple template processor for crossing across each of which execution identical function extends frame to handle.
In other other configurations, any DAG of substantially kernel may be loaded onto on hardware processor, and this is
In being designed in DAG, corresponding template processor of the configuration with its respective corresponding program code kernel, and will be appropriate
Controlling stream hook is configured in hardware with by input of the output image from a boot kernel to next kernel.
As general flow, the frame of view data is received by grand I/O units 705 and is sent to line buffer memory unit frame by frame
One or more of 701.The frame of its view data is parsed into the smaller area of view data by specific line buffer memory unit,
Referred to as " line-group (line group) ", is then sent to specific data slice maker by network 704 by line-group.It is complete or
The single line group of " complete " for example can form (for simplicity, this theory by the data of multiple continuous whole row or column of a frame
Bright book is primarily referred to as continuous row).The line-group of view data is further parsed into the smaller of view data by data slice maker
Region, it is referred to as " data slice (sheet) ", and data slice is supplied to its corresponding template (stencil) processor.
In the case where the image processing pipeline with single input or DAG flow, generally, input frame is directed to phase
Same line buffer memory unit 701_1, the line buffer memory unit are directed to data by image data analyzing into line-group and by line-group
The code of the first kernel in piece maker 703_1, its corresponding positive execution pipeline/DAG of template processor 702_1.In mould
After the line-group that sheet processor 702_1 is handled it completes operation, output line mass-sending is sent in " downstream " by data slice maker 703_1
Line buffer memory unit 701_2 (in some use-cases, output line-group, which can be sent back to, previous has sent the identical of input line-group
Line buffer memory unit 701_1).
Then, one or more " consumer " kernels are received by the first template from the line buffer memory unit 701_2 in downstream
The view data of device 702_1 generations is managed, " consumer " is represented in other respective data slice makers and template processor (example
Such as, data slice maker 703_2 and template processor 702_2) on next stage/operation in streamline/DAG for performing.Pass through
This mode, " producer " kernel run in the first template processor output it data forwarding in the processing of the second template
" consumer " kernel run on device, wherein consumer's kernel perform next group task after producer's kernel, this and totality
Streamline or DAG design are consistent.
Template processor 702 is designed to simultaneously operate multiple overlapping templates (stencil) of view data.
The multiple overlapping templates and internal hardware disposal ability of template processor effectively determine the size of data slice.Here, in template
In processor 702, the array processing performed unanimously causes while handled by the view data surface of multiple overlapping template coverings
Region.
As detailed below, in various embodiments, the data slice of view data is loaded into the two dimension in template processor 702
In register array structure.It is considered as effectively providing power consumption improvement using data slice and two-dimentional register array structure, this is
By the way that mass data is moved into a large amount of register spaces, for example, as single loading operation, followed by, by execution channel array
Processing task directly is performed to data.It can be easy to program/match somebody with somebody in addition, providing using execution channel array and corresponding register array
The different templates size put.
The parsing activity of Fig. 8 a to Fig. 8 e diagram outlets buffer memory unit 701, the more particulate of data slice maker unit 703
The parsing activity of degree and coupled to data slice maker unit 703 template processor 702 template processing activity it is advanced
Embodiment.
Fig. 8 a depict the embodiment of the input frame of view data 801.Fig. 8 a also depict template processor and are designed to use
Come the overlapping template 802 of operate three (it is each with 3 pixels × 3 pixel size) skeleton diagram.Each template is respectively it
The output pixel for generating output image data is highlighted with filled black.For the sake of simplicity, three overlapping templates 802 are depicted
To be only overlapping in vertical direction.It is necessary to recognize, in fact, template processor can be designed in vertical direction and level
All there is overlapping masterplate on direction.
Due to the vertically superposed template 802 in template processor, as shown in Figure 8 a, can be operated in single template processor
Frame in the view data of wide scope be present.As detailed below, in one embodiment, template processor across view data with from a left side
To the right side mode in its overlapping template processing data (and then being repeated with order from top to bottom to next group of line).Cause
This, as template processor persistently carries out its operation, the number of filled black output pixel block can increase to the right in the horizontal direction
Add.As discussed above, line buffer memory unit 701 is responsible for the line-group of input image data of the parsing from input frame, and it is enough to make mould
Sheet processor is operated in more upcoming cycles.The example plot of line-group is illustrated as shadow region 803.
In one embodiment, further described below, line buffer memory unit 701, which can have, to be used to send out to/from data slice maker
Send/receive the Different Dynamic of line-group.For example, according to a kind of pattern for being referred to as " full group ", inline cache device unit and data slice
The complete overall with line of view data is transmitted between maker.According to the second mode for being referred to as " real high ", initially with the son of overall with row
Collect to transmit line-group.Then, remaining row is sequentially transmitted with smaller fragment (being less than overall with).
As the line-group 803 of input image data is defined by line buffer memory unit and is sent to data slice maker list
Line-group is further parsed into finer data slice by member, data slice maker unit, and its more accurate adaptation is in template processor
Hardware limitation.More specifically, as detailed below, in one embodiment, each template processor is by two-dimensional shift register battle array
Row composition.Two-dimensional shift register array, to the array " lower section " for performing road, shifts herein substantially by image data shift
Pattern causes each execution road to be operated to the data in its each self-template (that is, each performing road to their own
Information model is handled to generate the output for the template).In one embodiment, data slice is " filling " or with other
Mode is loaded into the surface region of the input image data in two-dimensional shift register array.
Therefore, as shown in Figure 8 b, data slice maker parses the primary data piece 804 from line-group 803 and carried
Supply template processor (here, the data slice of data corresponds to the shadow region generally indicated by reference 804).Such as Fig. 8 c
Shown in Fig. 8 d, template processor in a manner of from left to right in data slice effectively moving overlapping template 802 and right
The data slice of input image data is operated.As shown in figure 8d, the picture for the output valve that the data out of data slice can calculate
Prime number is exhausted (can be with output valve determined by the information out of data slice without other location of pixels).For the sake of simplicity,
Ignore the borderline region of image.
As figure 8 e shows, data slice maker provides next data slice 805 to continue to operate for template processor again.Note
Meaning, initial position when template starts to operate next data slice is from being exhausted a little to the right in first data slice
Next progress (as preceding shown in figure 8d).On new data slice 805, with template processor according to first data
The same treatment mode of piece operates to new data slice, and template will simply continue to move right.
Pay attention to, due to the borderline region of the template around output pixel position, in the data and second of the first data slice 804
It is overlapping to there are some between the data of data slice 805.It is overlapping can be resend simply by data slice maker it is overlapping
Data are handled twice.In the embodiment of alternative, for next data slice is fed into template processor, data slice generation
Device can only continue new data being sent to template processor, and template processor is reused from last data piece
Overlapped data.
B. the design and operation of template processor
Fig. 9 a show the embodiment of template processor framework 900.As illustrated in fig. 9, it is single to include data calculating for template processor
Member 901, scalar processor 902 and associated memory 903 and I/O units 904.Data Computation Unit 901 includes performing
Channel array 905, two-dimensional shift array structure 906 and the independent random access memory associated with the specific row or column of array
907。
I/O units 904 are responsible for " input " the Data Data piece received from data slice maker to be loaded into data calculating
Stored in unit 901 and " output " the Data Data piece from template processor into data slice maker.In a reality
Apply in example, data sheet data, which is loaded into Data Computation Unit 901, needs the data slice received to be parsed into view data
Row/column and the row/column of view data be loaded into perform channel array row/column two-dimensional shift register structure 906 or
(it is described in more detail below) in the corresponding random access memory 907 of person.If data slice is initially loaded into memory
In 907, then each execution road performed in channel array 905 can be in due course data sheet data from random access memory
907 are loaded into two-dimensional shift register structure 906 (for example, referring to as the loading before being operated to data sheet data
Make).Data Data piece is completed to be loaded into register architecture 906 (either directly from data slice maker still from storage
Device 907) after, the execution road performed in channel array 905 operates to data, and finally using the data of completion as data slice
Directly " write back " to data slice maker or into random access memory 907.If I/O units 904 from depositing at random later
Data are taken out in access to memory 907 to form output data piece, then transfer it to data slice maker.
Scalar processor 902 includes cyclelog 909, and it reads the program of template processor from scalar memory 903
Code instructs and is sent to these instructions the execution road performed in channel array 905.In one embodiment, it is single identical
Instruction be broadcast to all execution roads in array 905 so that realizing SIMD class behaviors from Data Computation Unit 901.At one
In embodiment, read from scalar memory 903 and be sent to the instruction format bag of the instruction in the execution road for performing channel array 905
Very long instruction word (VLIW) type form is included, it includes often instructing more than one command code.In another embodiment,
VLIW forms include instruction, and by the ALU operation code of the ALU in each execution road mathematical functions performed, (as described below, it is at one
More than one traditional ALU operation can be specified in embodiment) and storage operation code (its indicate be used for it is specific execution road or
The storage operation in one group of execution road of person).
Term " performing road (execution lane) " refers to the one or more execution units composition for being able to carry out instruction
Set (if logic circuit of execute instruction).However, in various embodiments, performing road can include removing execution unit
Outside more processing device class function.For example, in addition to one or more execution units, performing road can also be included to receiving
The logic circuit decoded is instructed, or in the case where more MIMD classes design, including obtain and conciliate patrolling for code instruction
Collect circuit.On MIMD class methods, although centralized program control method is largely described to herein, in various alternatives
More distributed method (program code and program e.g., including in each execution road of array 905 can be realized in embodiment
Controller).
Perform channel array 905, cyclelog 909 and two-dimensional shift register structure 906 are combined as on a large scale may be used
Programing function provides the hardware platform for being broadly applicable/configuring.For example, in view of each execution road is able to carry out various work(
The input image data of the neighbouring any output array position of access and can be readily able to, applied software development person can program tool
There are the kernel and size (for example, template size) of extensive difference in functionality ability.
In addition to the data storage area that the view data that channel array 905 operates is performed except serving as, random access memory 907
One or more look-up tables can also be preserved, the group such as in the look-up table of Section 1.0 above described virtual processing memory
Any look-up table retained in part.In various embodiments, can also be instantiated in scalar memory 903 one or more
Scalar look-up table.One or more scalar look-up tables can be that the scalar of Section 1.0 above described memory model is searched
Any scalar look-up table retained in table component.
Scalar, which is searched to be related to the identical data value from identical look-up table to be delivered to from same index, performs channel array 905
Interior performing is each in road.In various embodiments, above-mentioned VLIW instruction form is extended to also include scalar operations code, its
The search operation performed by scalar processor is guided into scalar look-up table.It can be vertical to specify the index same with command code
I.e. operand or from some other data storage location extract.Anyway, in one embodiment, out of scalar memory
Scalar look-up table in carry out lookup and essentially relate to that identical data value is broadcast to execution during the identical clock cycle
Whole execution roads in channel array 905.The other details for using and operating on look-up table are further provided below.
Fig. 9 b summarize the embodiment of VLIW instruction word as discussed above.As shown in figure 9b, VLIW instruction word format includes
For three fields individually instructed：1) scalar instruction 951 performed by scalar processor；2) by each in execution channel array
The ALU instruction 952 that ALU is broadcasted and performed in a manner of SIMD；And 3) memory broadcasted and performed in a manner of the SIMD of part refers to
953 are made (if sharing same random access memory along the execution road of same a line for example, performing in channel array, from difference
(form of memory instructions 953 can include identification from every row to one actual execute instruction in execution road of the often row in row
Which performs the operand of road execute instruction)).
Also include the field 954 for one or more immediate operands.Can be identified in instruction format instruction 951,
952nd, which of 953 which immediate operand information used.Each also include its each phase in instruction 951,952,953
The input operand and object information answered are (for example, for the local register of ALU operation and for memory access instruction
Local register and memory address).In one embodiment, perform channel array in execution road execute instruction other 952,
Before any one in 953, scalar instruction 951 is performed by scalar processor.That is, performing VLIW words includes first week
Phase, scalar instruction 951 is performed during this period, is followed by second round, can perform other (notes of instruction 952,953 during this period
Meaning, in various embodiments, instruction 952 and 953 can be executed in parallel).
In one embodiment, by scalar processor perform scalar instruction include be sent to data slice maker with from/
The order of memory or 2D shift register load/store data pieces to Data Computation Unit.Here, data slice generator
Operation can depend on line buffer memory unit operation or its dependent variable, these variables prevent periodicity from including prerun,
And this can make data slice maker complete any order sent by scalar processor.So, in one embodiment, scalar refers to
The 951 any VLIW words for corresponding to or be otherwise result in sending to data slice generator order are made also to refer to including two other
Make being instructed without operation (NOOP) in field 952,953.Then, the NOOP instructions of program code input instruction field 952,953
Circulation, until data slice generator completes its loading/storage to/from Data Computation Unit.Here, to data slice maker
After sending order, scalar processor can set the position of interlock register that data slice maker is reset after completing to order.
During NOOP is circulated, scalar processor monitors the position of mutual lock-bit.When scalar processor detects that data slice generator has been completed
When it is ordered, normal perform is restarted.
Figure 10 shows the embodiment of data computation module 1001.As shown in Figure 10, data computation module 1001 includes logic
On be positioned at the execution channel array 1005 of two-dimensional shift register array structure 1006 " top ".As described above, in various implementations
In example, the data slice of the view data provided by data slice generator is loaded into two-dimensional shift register 1006.Then, hold
Trade operates to the data sheet data from register architecture 1006.
Perform channel array 1005 and shift register structure 1006 is fixed relative to one another in position.However, shift LD
Data in device array 1006 are shifted with strategy and coordination mode, so as to perform in each execution road processing data in channel array
Different templates.So, the output image values of the different pixels in the output table that road determination is generating each are performed.From Figure 10
Framework from the point of view of, it should be clear that overlapping template is not only vertically disposed so, and is horizontally arranged because perform channel array 1005
Including vertically adjacent to perform road and horizontally adjacent execution road.
Some notable architectural features of Data Computation Unit 1001 are included with than performing 1005 wider size of channel array
Shift register structure 1006.That is, performing " haloing " 1009 that register outside channel array 1005 be present.It is although dizzy
Circle 1009 is expressed as being present in the both sides for performing channel array, but according to embodiment, haloing may reside in execution channel array
On 1005 less side (side) or more side (three sides or four sides).Haloing 1009 is used for when data are performing road 1005 " lower section "
During displacement, " spilling " space is provided to be spilled over to the data outside the border for performing channel array 1005.In simple cases, when
During the leftmost pixel of processing template, occupy 5 × 5 templates at the right hand edge center for performing channel array 1005 need again to the right four
Individual haloing register position.For ease of drawing, Figure 10 is shown, in standards Example, the register on the right side of haloing only has
Horizontal shift connects, and only there is the register of haloing bottom side vertical movement to connect, and posting in either side (right side, bottom side)
Storage has horizontal connection and vertical connection.
Extra overflow space is provided by random access memory 1007, and the random access memory is coupled in array
Every a line and/or it is each row or part thereof (for example, random access memory can be assigned to perform channel array " area
Domain ", the region is across 4 execution road rows and 2 execution road row.For the sake of simplicity, remaining content of the application is related generally to based on row
And/or the allocative decision of row).Here, if the kernel operation for performing road requires that it handles two-dimensional shift register array 1006
Outside pixel value (some image procossing routines may have required for), then the plane of view data can further overflow, example
Such as, spilt over from haloing region 1009 in random access memory 1007.Held for example, it is contemplated that 6 × 6 templates, wherein hardware are included in
The haloing region for performing only four storage elements on the right side of road on the array right hand edge of trade.In this case, data need by
The right side of the right hand edge of haloing 1009 is further displaced to, with intactly processing template.It is displaced to outside haloing region 1009
Data can then spill into random access memory 1007.Random access memory 1007 and Fig. 3 template is further provided below
The other application of processor.
Figure 11 a to Figure 11 k show view data as described above in two-dimensional shift register array internal shift to execution road
The Working Examples of the mode of array " lower section ".As shown in fig. 11a, the number of two-dimensional shift array is depicted in the first array 1107
Execution channel array is depicted according to content, and by frame 1105.In addition, it is adjacent simply to depict two performed in channel array
Perform road 1110.In this simple description 1110, each road that performs includes register R1, and it can receive to post from displacement
The data of storage, receive the data (for example, accumulator is shown as between the cycle) from ALU outputs, or by output data
Write-in output destination.
In local register R2, each road that performs also is may be used in two-dimensional shift array positioned at the interior of its " lower section "
Hold.Therefore, R1 is the physical register for performing road, and R2 is the physical register of two-dimensional shift register array.Perform road bag
Include the ALU that can be operated to the operand by R1 and/or R2 offers.As detailed below, in one embodiment, shift LD
Device is actually realized with multiple storage/register elements (" depth ") of each array position, but displacement activity is limited
In a storage element plane (for example, each cycle is only capable of shifting a storage element plane).Figure 11 a to Figure 11 k are depicted
One in these deeper register positions, for storing from the corresponding result X for performing road.For ease of diagram, deeper knot
Fruit register is plotted in its paring registers R2 side rather than below.
Figure 11 a to Figure 11 k concentrate on the calculating of two templates, and the center of the two templates is painted with performing in channel array
A pair gone out perform road position 1111 and alignd.For ease of diagram, this is drawn into horizontal neighbor to performing road 1110, and according to
Lower example, they are actually vertical neighbors.
As initially shown in fig. 11 a, execution road is centered on the template position at its center.Figure 11 b show to be held by two
The object code that trade performs.As shown in figure 11b, the program code in two execution roads causes the data in shift register array
Displacement one position in one position and right shift downwards.This just makes two execution roads be directed at the upper left corner of its each self-template.
Then, program code causes the data of (in R2) positioned at their relevant positions to be loaded into R1.
As shown in fig. 11c, next, program code cause this to perform road by the data in shift register array to the left
A unit is shifted, this value allowed on the right side of the relevant position in each execution road moves on to the position in each execution road.Then, will
Value (previous value) addition in R1 has shifted to the new value for the position for performing road (in R2).Write the result into R1.Such as Figure 11 d
It is shown, repeat with being handled above with reference to identical described in Figure 11 c, this R1 for allowing for gained includes the value in upper execution road at present
The A+B+C and descending F+G+H performed in road.At this point, two execution roads have all handled the upper of each of which masterplate
OK.Pay attention to, if haloing region is not present in the left side for performing channel array, the halo region performed on the left of channel array can be spilt into
In domain (if left side has a haloing region) or random access memory.
As illustrated in fig. 11e, next, program code causes one list of data upward displacement in shift register array
Position, this allows for right hand edge of two execution roads all with the center row of each of which template and is aligned.The register in two execution roads
R1 is currently included the top row of template and the most r value sum of center row.Figure 11 f and Figure 11 g shows the template across two execution roads
The continuous progress that center row is moved to the left.Continue to add up, so at the end of Figure 11 g processing, two execution roads include them
The top row of each self-template and the value sum of center row.
Figure 11 h are shown another displacement of the most descending alignment of the corresponding masterplate in each execution road.Figure 11 i and figure
11j shows to continue displacement in the process of the template in two execution roads to complete to handle.Figure 11 k show additional shift, so that often
The individual road that performs is aligned and write the result into wherein with its correct position in a data array.
In Figure 11 a to Figure 11 k example, it is noted that the object code for shifting function can include identification with (X, Y)
The direction for the displacement that coordinates table reaches and the instruction format of magnitude.For example, the object code for one position of upward displacement can be with
It is expressed as SHIFT0 in object code ,+1.As another example, one position of right shift can express in object code
For SHIFT+1,0.In various embodiments, the displacement of larger magnitude can also be specified in object code (for example, SHIFT 0,
+2).If here, 2D shift register hardwares only support each cycle shift a position, instruction can by machine interpretation into
Multiple cycles are needed to perform, or 2D shift register hardwares can be designed to support each cycle to shift more than one position.
The embodiment of latter case is described more fully.
Figure 12 shows that array performs another of the unit cell element (cell) of road and shift register structure and retouched in more detail
State (register in haloing region does not include corresponding execution road).In one embodiment, by performing the every of channel array
The circuit shown in Figure 12 is instantiated at individual node, the execution road associated with performing each position in channel array is realized and posts
Storage space.As shown in figure 12, unit cell element includes performing road 1201, and it is coupled to what is be made up of four register R2 to R5
Register file 1202.During any cycle, perform road 1201 can from register R1 to R5 in any one read or
It is written to.For need two input operands instruction, perform road can from R1 to R5 in any one obtain two
Operand.
In one embodiment, it is by allowing register R2 during signal period to realize two-dimensional shift register structure
The content of any (only) one into R4 by output multiplexer 1203 " removal " to one in the register file of its neighbour,
And by any (only) in register R2 to R4 if the content of one be substituted for its neighbour by inputoutput multiplexer 1204 from
The content of corresponding one " immigration " so that the displacement between neighbours is in identical direction (for example, all performing road to moving to left
Position, all perform road right shift etc.).Although its content may be removed and be substituted for identical by usual identical register
The content moved into cycle, but multiplexer apparatus 1203,1204 allows the different shiftings during same period in same register file
Potential source register and shifted target register.
As shown in figure 12, it is noted that during shift sequence, perform road and content is displaced to its left side from its register file 1202
It is each in adjacent, right adjacent, upper adjacent and lower neighbour.With reference to identical shift sequence, perform road also by content from its it is left it is adjacent, right it is adjacent, on
Specific one in adjacent and lower neighbour is displaced in its register file.It, for all performing road, removes target and immigration for again
Source should meet same direction of displacement (if for example, removal is neighbours to the right, immigration should be the neighbours from left).
Although in one embodiment, each cycle each performs the content for allowing to shift unique register, other
Embodiment can allow the content for being moved in and out multiple registers.If for example, by the multiplexer circuit shown in Figure 12
1203rd, 1,204 second example is incorporated in Figure 12 design, then two registers can be removed/moved into during same period
Content.Certainly, in the embodiment that the content of displacement unique register is allowed in each cycle, by consuming more clocks weeks
The displacement that phase is used between mathematical operation, can be carried out from multiple register shifts (for example, by number between mathematical operation
Student movement consumes two shifting functions between calculating, and the content of two registers can be shifted between mathematical operation).
If the content removed during shift sequence pays attention to, often less than the full content for the register file for performing road
The content of the individual register not moved out for performing road is held in place and (not shifted).So, any be not substituted for moves into content not
Shift content and still locally retain in execution road in whole shift cycle.The memory cell observed in each execution road
(" M ") be used to add from/to the associated RAM space of the row and/or row with performing the execution road in channel array
Load/data storage.Here, M units serve as the M units of standard because its be frequently used for loading/storage can not be from/to holding
The data of the register space loading/storage of trade in itself.In various embodiments, the primary operational of M units be by data from
Local register write-in memory and from memory read data and it is written into local register.
The ISA operation code that ALU units on performing road 1201 by hardware are supported, in various embodiments, by hardware ALU
The mathematical operations code of support and supported by virtual execution road mathematical operations code (for example, ADD, SUB, MOV, MUL, MAD, ABS,
DIV, SHL, SHR, MIN/MAX, SEL, AND, OR, XOR, NOT) it is identical (for example, substantially the same) on the whole.As described above,
Memory access instruction can be performed by execution road 1201 with extracted from/to its associated random access memory/store number
According to.Shifting function instruction (right, left, upper and lower) is supported to shift in two-dimensional shift register structure in addition, hardware performs road 1201
Data.As described above, program control instruction is mainly performed by the scalar processor of template processor.
D. the embodiment of embodiment
Hardware design embodiment can partly be led in semiconductor chip and/or as being used to finally target as discussed above
The description of the circuit design of body manufacturing process is realized.In the later case, such circuit description can take advanced/behavior
Level circuit explanation (for example, VHDL is described) or low level circuitry description are (for example, register transfer level (RTL) description, transistor level
Description or mask description) or its various combination.For example, it can include having the application described above in chapters and sections 1.0 soft
One or more examples of part development environment are retouched as such circuit of the target hardware for the software write in development environment
State.Circuit description is generally embodied on computer-readable recording medium (such as CD-ROM or other kinds of memory technologies).
3.0 summarize
It can be appreciated that from foregoing, the virtual environment described in Section 1.0 above can carry out example on the computer systems
Change.Similarly, the image processor as described in Section 2.0 above can be embodied in the hardware in computer system (for example,
A part as the on-chip system (SOC) of the handheld device of the data of camera of the processing from handheld device).
It is necessary to note that above-mentioned various image processor architecture features are not necessarily limited to traditional image procossing simultaneously
It is possible thereby to applied to may (or may not) other application for promoting image processor to be characterized again.It is if for example, above-mentioned
Any one in various image processor architecture features is used for creating and/or generates and/or present animation, rather than place
Actual camera image is managed, then image processor can be characterized as being graphics processing unit.In addition, above-mentioned image processor architecture
Feature can be applied to other technologies application, such as Video processing, visual processes, image recognition and/or machine learning.Pass through
This mode application, image processor can (for example, as coprocessor) and more general processor (for example, as calculating
The CPU or one part of system) it is integrated, or can be the independent processor in computing system.
Hardware design embodiment can partly be led in semiconductor chip and/or as being used to finally target as discussed above
The description of the circuit design of body manufacturing process is realized.In the later case, such circuit description can take advanced/behavior
Level circuit explanation (for example, VHDL is described) or low level circuitry description are (for example, register transfer level (RTL) description, transistor level
Description or mask description) or its various combination.Circuit description is generally embodied in computer-readable recording medium (such as CD-
ROM or other kinds of memory technologies) on.
For preceding sections, it is necessary to recognize, image processor as described above can be embodied in department of computer science
(for example, the on-chip system (SOC) of the handheld device as the data of camera of the processing from handheld device in hardware on system
A part).In the case where image processor is implemented as hardware circuit, it is noted that the view data handled by image processor
Directly it can be received from camera.Here, image processor can be a part for discrete camera, or with integrated camera
A part for computing system.In the later case, view data can store directly from camera or from the system of computing system
Device receives (for example, its view data is sent to system storage rather than image processor by camera).It shall yet further be noted that preceding sections
Described in many features go for graphics processor unit (its present in animation).
Figure 13 provides the illustrative plot of computing system.Many components of following computing systems can be applied to have integrated phase
The computing system (for example, handheld device, such as smart phone or Tablet PC) of machine and associated image processor.This
Field those of ordinary skill is understood that relation between the two.
As shown in figure 13, basic calculating system can (it can be for example including multiple logical including CPU 1301
With process cores 1315_1 to 1315_N and the main memory controller being arranged on polycaryon processor 1317 or application processing
Device), system storage 1302, display 1303 (for example, touch-screen, flat board), local wired point-to-point link (for example, USB)
Interface 1304, various network I/O functions 1305 (such as Ethernet interface and/or cellular modem subsystem), wireless office
Domain net (for example, WiFi) interface 1306, wireless point-to-point link (for example, bluetooth) interface 1307 and global positioning system interface
1308th, various sensor 1309_1 to 1309_N, one or more cameras 1310, battery 1311, power management control unit
1313rd, loudspeaker and microphone 1313 and audio encoder/decoder 1314.
Application processor or polycaryon processor 1350 can include one or more general procedure cores in its CPU 1301
1315th, one or more graphics processing units 1316, memory management functions 1317 (for example, Memory Controller), I/O controls
Function 1318 and graphics processing unit 1319.General procedure core 1315 generally performs the operating system of computing system and using soft
Part.Graphics processing unit 1316 generally performs figure sensitive function, for example, to generate the figure presented on display 1303
Information.Memory control function 1317 and the interface of system storage 1302, with write to/from system storage 1302/read number
According to.The power consumption of the usual control system 1300 of power management control unit 1313.
Graphics processing unit 1319 can be in the graphics processing unit embodiment according to the detailed description in preceding sections
Any one is realized.As an alternative or in combination, IPU 1319 can be coupled to one in GPU 1316 and CPU 1301
Or both, as its coprocessor.In addition, in various embodiments, GPU 1316 can pass through the image of above-detailed
Any one in processor feature is realized.
Touch-screen display 1303, communication interface 1304 to 1307, GPS interface 1308, sensor 1309, the and of camera 1310
It can each be considered as various forms of I/O (input and/or output) in speaker/microphone codec 1313,1314,
This is for whole computing system, and in the appropriate case, it also includes integrated ancillary equipment (for example, one or more
Individual camera 1310).According to embodiment, each in these I/O components can be integrated at application processor/multinuclear
Manage on device 1350, can either be located at outside the tube core of processor/polycaryon processor 1350 or outside its encapsulation.
In one embodiment, one or more cameras 1310 include to survey between the object in camera and its visual field
Measure the depth camera of depth.In the general-purpose CPU of application processor or other processors (or with for configuration processor code
Other functional blocks of instruction execution pipeline) on perform application software, operating system software, device driver software and/or
Firmware can perform any one in above-mentioned function.
Embodiments of the invention can include various processes as described above.These processes can be embodied in machine and can hold
In row instruction.These instructions, which can be used in, promotes some processes of universal or special computing device.As an alternative, these processes
Can by the specialized hardware components comprising the firmware hardwired logic for implementation procedure or by the computer module of programming and
Any combinations of the nextport hardware component NextPort of customization perform.
The element of the present invention is also used as providing for storing the machine readable media of machine-executable instruction.Machine
Computer-readable recording medium can include but is not limited to floppy disk, CD, CD-ROM and magneto-optic disk, flash memory, ROM, RAM, EPROM,
EEPROM, magnetic or optical card, propagation medium or the other kinds of medium/machine readable media for being applied to storage e-command.
For example, the present invention can be used as computer program to download, the computer program can be via communication link (for example, modulatedemodulate
Adjust device or network connection) by be embodied in the data-signal in carrier wave or other propagation mediums and from remote computer (for example, clothes
Business device) it is sent to requesting computer (for example, client).
In specification above, the present invention is described by with reference to its specific illustrative embodiment.It may be evident, however, that
It can be modified and changed, without departing from wider spirit and scope of the invention as described in the appended claims.Cause
This, specification and drawings are considered as illustrative and not restrictive meaning.
Claims (23)
- A kind of 1. machinable medium with program code, under causing when described program code is performed by computing system The method of stating is performed：Virtual processor is instantiated in applied software development environment, the virtual processor has instruction set architecture and memory mould Type, the instruction set architecture and memory model have preset first area and the second area of reserved memory, and this is first pre- Region is stayed to preserve the data of input picture array, second reserved area preserves the data of output image array；WithThe execution of the memory loading instruction of the instruction set architecture is simulated by following step：Automatically reserved described first Region is loaded in the vertical coordinate system expressed in the instruction format of instruction relative to institute as target, and using the memory The first coordinate and the second coordinate for stating the position of virtual processor identify desired input data.
- 2. machine readable media according to claim 1, wherein methods described also include：The execution of the memory store instruction of the instruction set architecture is simulated by following step：Automatically the second reserved area is made For target, and the first coordinate and in the vertical coordinate system expressed in instruction format using the memory store instruction Two coordinates identify desired output data position.
- 3. machine readable media according to claim 1, in addition to：Allow other positions for determining the output array The other instantiation virtual processors for the output valve put access first reserved area and second reserved area.
- 4. machine readable media according to claim 1, wherein the instruction set architecture and memory model are also default 3rd reserved area is to preserve look-up table data, and wherein methods described also includes：By automatically reading instruction using the 3rd reserved area as target to simulate the look-up table of the instruction set architecture Execution.
- 5. machine readable media according to claim 4, wherein methods described also include：Allow for determining the output Other instantiation virtual processors of the output valve of the other positions of array read the mould of instruction by the look-up table of their own Intend performing and accessing the 3rd reserved area.
- 6. machine readable media according to claim 1, wherein methods described also include：The execution of following instructions of the instruction set architecture is simulated, the instruction, which performs, reads in constant table, and reading value is broadcasted To multiple instantiation virtual processors, the plurality of instantiation virtual processor determines the corresponding of the diverse location of the output array Output valve, the constant table are stored in the 3rd reserved area of the memory model.
- 7. machine readable media according to claim 1, wherein methods described also include：Simulate the execution of following instructions of the instruction set architecture, the instruction is performed to the data of the output image array more Newly, and result the 3rd reserved area of the memory model is write.
- 8. machine readable media according to claim 1, wherein the instruction format of memory loading instruction is to described First coordinate and the second coordinate application scaling item, to realize any up-sampling and down-sampling.
- 9. machine readable media according to claim 1, wherein the instruction set architecture and memory model are also default 3rd reserved area is to preserve atomic update table data, and wherein methods described further comprises：Pass through automatically the 3rd reserved area is instructed as target to simulate the atomic update of the instruction set architecture Perform.
- 10. a kind of method, including：Virtual processor is instantiated in applied software development environment, the virtual processor has instruction set architecture and memory mould Type, the instruction set architecture and memory model have preset first area and the second area of reserved memory, and this is first pre- Region is stayed to preserve the data of input picture array, second reserved area preserves the data of output image array；WithThe execution of the memory loading instruction of the instruction set architecture is simulated by following step：Automatically reserved described first Region as target, and using in the vertical coordinate system expressed in the instruction format that instruction is loaded with the memory relative to First coordinate of the position of the virtual processor and the second coordinate identify desired input data.
- 11. the method according to claim 11, in addition to：The execution of the memory store instruction of the instruction set architecture is simulated by following step：Automatically the second reserved area As target, and the first coordinate in the vertical coordinate system expressed in instruction format using the memory store instruction and Second coordinate identifies desired output data position.
- 12. the method according to claim 11, in addition to：Allow the defeated of the other positions for determining the output array The other instantiation virtual processors for going out value access first reserved area and second reserved area.
- 13. according to the method for claim 10, wherein the instruction set architecture and memory model also to have preset the 3rd pre- Region is stayed to preserve look-up table data, and wherein methods described also includes：By automatically reading instruction using the 3rd reserved area as target to simulate the look-up table of the instruction set architecture Execution.
- 14. according to the method for claim 13, wherein methods described also includes：Allow for determining the output array The simulation that other instantiation virtual processors of the output valve of other positions read instruction by the look-up table of their own performs And access the 3rd reserved area.
- 15. according to the method for claim 10, wherein methods described also includes：The execution of following instructions of the instruction set architecture is simulated, the instruction, which performs, reads in constant table, and reading value is broadcasted To multiple instantiation virtual processors, the plurality of instantiation virtual processor determines the corresponding of the diverse location of the output array Output valve, the constant table are stored in the 3rd reserved area of the memory model.
- 16. according to the method for claim 10, wherein methods described also includes：Simulate the execution of following instructions of the instruction set architecture, the instruction is performed to the data of the output image array more Newly, and result the 3rd reserved area of the memory model is write.
- 17. according to the method for claim 10, wherein the instruction format of memory loading instruction is sat to described first Mark and the second coordinate application scaling item, to realize any up-sampling and down-sampling.
- 18. a kind of computing system including multiple process kernels and at least one storage device, at least one storage device Comprising program code, cause when described program code is handled by the process kernel and perform a kind of method, methods described includes：The application software development environment for supporting following behavior is provided：Virtual processor is instantiated in applied software development environment, the virtual processor has instruction set architecture and memory mould Type, the instruction set architecture and memory model have preset first area and the second area of reserved memory, and this is first pre- Region is stayed to preserve the data of input picture array, second reserved area preserves the data of output image array；WithThe execution of the memory loading instruction of the instruction set architecture is simulated by following step：Automatically reserved described first Region as target, and using in the vertical coordinate system expressed in the instruction format that instruction is loaded with the memory relative to First coordinate of the position of the virtual processor and the second coordinate identify desired input data.
- 19. computing system according to claim 18, wherein methods described also include：The execution of the memory store instruction of the instruction set architecture is simulated by following step：Automatically the second reserved area As target, and the first coordinate in the vertical coordinate system expressed in instruction format using the memory store instruction and Second coordinate identifies desired output data position.
- 20. computing system according to claim 18, wherein the instruction set architecture and memory model have also preset Three reserved areas are to preserve look-up table data, and wherein methods described also includes：By automatically reading instruction using the 3rd reserved area as target to simulate the look-up table of the instruction set architecture Execution.
- 21. computing system according to claim 18, wherein methods described also include：The execution of following instructions of the instruction set architecture is simulated, the instruction, which performs, reads in constant table, and reading value is broadcasted To multiple instantiation virtual processors, the plurality of instantiation virtual processor determines the corresponding of the diverse location of the output array Output valve, the constant table are stored in the 3rd reserved area of the memory model.
- 22. a kind of machinable medium with program code, causes when described program code is performed by computing system Perform following methods：Virtual processor is instantiated in applied software development environment, the virtual processor has instruction set architecture and memory mould Type, the instruction set architecture and memory model have preset first area and the second area of reserved memory, and this is first pre- Region is stayed to preserve the data of input picture array, second reserved area preserves the data of output image array；WithThe execution of the memory store instruction of the instruction set architecture is simulated by following step：Automatically reserved described second Region is as target, and relative to institute in the vertical coordinate system expressed in instruction format using the memory store instruction The first coordinate and the second coordinate for stating the position of virtual processor identify desired output data position.
- 23. a kind of machinable medium with program code, when described program code is performed by computing system, cause Perform following methods：Virtual processor is instantiated in applied software development environment, the virtual processor has instruction set architecture and memory mould Type, the instruction set architecture and memory model have preset first area and the second area of reserved memory, and this is first pre- Region is stayed to preserve the data of input picture array, second reserved area preserves the data of output image array, and default Instruction, the instruction utilize the first coordinate value and the second coordinate of the position in vertical coordinate system relative to the virtual processor Value limits the access site of the first area and second area；WithThe explanation of the target hardware framework of image processor is provided, to perform the program code from the software development environment, The target hardware framework includes processor array and two-dimensional shift array structure.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/694,890 US10095479B2 (en) | 2015-04-23 | 2015-04-23 | Virtual image processor instruction set architecture (ISA) and memory model and exemplary target hardware having a two-dimensional shift array structure |
US14/694,890 | 2015-04-23 | ||
PCT/US2016/026029 WO2016171893A1 (en) | 2015-04-23 | 2016-04-05 | Virtual image processor instruction set architecture (isa) and memory model and exemplary target hardware having a two-dimensional shift array structure |
Publications (2)
Publication Number | Publication Date |
---|---|
CN107533750A true CN107533750A (en) | 2018-01-02 |
CN107533750B CN107533750B (en) | 2021-06-01 |
Family
ID=55953367
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680019972.2A Active CN107533750B (en) | 2015-04-23 | 2016-04-05 | Virtual image processor, and method and system for processing image data thereon |
Country Status (5)
Country | Link |
---|---|
US (2) | US10095479B2 (en) |
EP (1) | EP3286721B1 (en) |
CN (1) | CN107533750B (en) |
GB (1) | GB2553934B (en) |
WO (1) | WO2016171893A1 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110058882A (en) * | 2019-03-14 | 2019-07-26 | 成都恒创新星科技有限公司 | It is a kind of for CNN accelerate OPU instruction set define method |
CN111930768A (en) * | 2020-09-10 | 2020-11-13 | 腾讯科技（深圳）有限公司 | Incremental data acquisition method, incremental data transmission method, incremental data acquisition device, incremental data transmission device and computer storage medium |
CN112184565A (en) * | 2020-08-27 | 2021-01-05 | 瑞芯微电子股份有限公司 | Multi-window serial image sharpening method |
Families Citing this family (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9830150B2 (en) | 2015-12-04 | 2017-11-28 | Google Llc | Multi-functional execution lane for image processor |
US10313641B2 (en) | 2015-12-04 | 2019-06-04 | Google Llc | Shift register with reduced wiring complexity |
US10204396B2 (en) | 2016-02-26 | 2019-02-12 | Google Llc | Compiler managed memory for image processor |
US10387988B2 (en) | 2016-02-26 | 2019-08-20 | Google Llc | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform |
US10380969B2 (en) | 2016-02-28 | 2019-08-13 | Google Llc | Macro I/O unit for image processor |
US10546411B2 (en) * | 2016-03-31 | 2020-01-28 | Intel Corporation | Directed acyclic graph path enumeration with application in multilevel instancing |
US20180005346A1 (en) | 2016-07-01 | 2018-01-04 | Google Inc. | Core Processes For Block Operations On An Image Processor Having A Two-Dimensional Execution Lane Array and A Two-Dimensional Shift Register |
US20180005059A1 (en) | 2016-07-01 | 2018-01-04 | Google Inc. | Statistics Operations On Two Dimensional Image Processor |
US10546211B2 (en) | 2016-07-01 | 2020-01-28 | Google Llc | Convolutional neural network on programmable two dimensional image processor |
US20180007302A1 (en) | 2016-07-01 | 2018-01-04 | Google Inc. | Block Operations For An Image Processor Having A Two-Dimensional Execution Lane Array and A Two-Dimensional Shift Register |
US10430919B2 (en) | 2017-05-12 | 2019-10-01 | Google Llc | Determination of per line buffer unit memory allocation |
US10489199B2 (en) * | 2017-05-12 | 2019-11-26 | Google Llc | Program code transformations to improve image processor runtime efficiency |
US10726605B2 (en) * | 2017-09-15 | 2020-07-28 | Intel Corporation | Method and apparatus for efficient processing of derived uniform values in a graphics processor |
JP7035751B2 (en) * | 2018-04-12 | 2022-03-15 | 富士通株式会社 | Code conversion device, code conversion method, and code conversion program |
US10831479B2 (en) * | 2019-02-20 | 2020-11-10 | International Business Machines Corporation | Instruction to move data in a right-to-left direction |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1925544A (en) * | 2005-08-31 | 2007-03-07 | 松下电器产业株式会社 | Image data processing device |
CN101231585A (en) * | 2007-01-26 | 2008-07-30 | 辉达公司 | Virtual architecture and instruction set for parallel thread computing |
CN101796821A (en) * | 2007-09-05 | 2010-08-04 | 国立大学法人东北大学 | Solid state imaging element and its drive method |
US20110087867A1 (en) * | 2005-06-23 | 2011-04-14 | Jacobson Quinn A | Primitives to enhance thread-level speculation |
TW201118568A (en) * | 2009-08-28 | 2011-06-01 | Qualcomm Inc | Memory controller page management devices, systems, and methods |
CN103339604A (en) * | 2011-01-31 | 2013-10-02 | 松下电器产业株式会社 | Program generation device, program generation method, processor device, and multiprocessor system |
Family Cites Families (76)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4445177A (en) | 1981-05-22 | 1984-04-24 | Data General Corporation | Digital data processing system utilizing a unique arithmetic logic unit for handling uniquely identifiable addresses for operands and instructions |
GB2150726B (en) | 1983-11-30 | 1988-01-20 | Standard Telephones Cables Ltd | Office terminals |
US4835712A (en) | 1986-04-14 | 1989-05-30 | Pixar | Methods and apparatus for imaging volume data with shading |
US4720871A (en) * | 1986-06-13 | 1988-01-19 | Hughes Aircraft Company | Digital image convolution processor method and apparatus |
JP2554255B2 (en) * | 1987-03-23 | 1996-11-13 | 旭光学工業株式会社 | Filtering device |
DE3851005T2 (en) | 1987-06-01 | 1995-04-20 | Applied Intelligent Syst Inc | Parallel neighboring processing system and method. |
US4935894A (en) | 1987-08-31 | 1990-06-19 | Motorola, Inc. | Multi-processor, multi-bus system with bus interface comprising FIFO register stocks for receiving and transmitting data and control information |
US5253308A (en) | 1989-06-21 | 1993-10-12 | Amber Engineering, Inc. | Massively parallel digital image data processor using pixel-mapped input/output and relative indexed addressing |
WO1994009595A1 (en) | 1991-09-20 | 1994-04-28 | Shaw Venson M | Method and apparatus including system architecture for multimedia communications |
JP3482660B2 (en) * | 1993-09-08 | 2003-12-22 | ソニー株式会社 | Image data processing apparatus and image data processing method |
US5612693A (en) | 1994-12-14 | 1997-03-18 | International Business Machines Corporation | Sliding window data compression using a toroidal bit shift register |
US5802219A (en) * | 1995-11-27 | 1998-09-01 | Sun Microsystems, Inc. | Methods and apparatus for table lookup transformation of digital images |
JP3573755B2 (en) | 1996-01-15 | 2004-10-06 | シーメンス アクチエンゲゼルシヤフト | Image processing processor |
FR2748974B1 (en) | 1996-05-21 | 1998-08-14 | Faure Bertrand Equipements Sa | ADJUSTABLE ARTICULATION FOR SEAT BACK |
US6031573A (en) | 1996-10-31 | 2000-02-29 | Sensormatic Electronics Corporation | Intelligent video information management system performing multiple functions in parallel |
US5892962A (en) | 1996-11-12 | 1999-04-06 | Lucent Technologies Inc. | FPGA-based processor |
US6366289B1 (en) | 1998-07-17 | 2002-04-02 | Microsoft Corporation | Method and system for managing a display image in compressed and uncompressed blocks |
US6587158B1 (en) | 1998-07-23 | 2003-07-01 | Dvdo, Inc. | Method and apparatus for reducing on-chip memory in vertical video processing |
US7010177B1 (en) | 1998-08-27 | 2006-03-07 | Intel Corporation | Portability of digital images |
EP1164544B1 (en) | 1999-03-16 | 2011-11-02 | Hamamatsu Photonics K.K. | High-speed vision sensor |
JP3922859B2 (en) | 1999-12-28 | 2007-05-30 | 株式会社リコー | Image processing apparatus, image processing method, and computer-readable recording medium storing program for causing computer to execute the method |
US6745319B1 (en) | 2000-02-18 | 2004-06-01 | Texas Instruments Incorporated | Microprocessor with instructions for shuffling and dealing data |
US6728862B1 (en) | 2000-05-22 | 2004-04-27 | Gazelle Technology Corporation | Processor array and parallel data processing methods |
US6728722B1 (en) | 2000-08-28 | 2004-04-27 | Sun Microsystems, Inc. | General data structure for describing logical data spaces |
US6986025B2 (en) | 2001-06-11 | 2006-01-10 | Broadcom Corporation | Conditional execution per lane |
US7286717B2 (en) | 2001-10-31 | 2007-10-23 | Ricoh Company, Ltd. | Image data processing device processing a plurality of series of data items simultaneously in parallel |
JP4146654B2 (en) | 2002-02-28 | 2008-09-10 | 株式会社リコー | Image processing circuit, composite image processing circuit, and image forming apparatus |
US9170812B2 (en) | 2002-03-21 | 2015-10-27 | Pact Xpp Technologies Ag | Data processing system having integrated pipelined array data processor |
WO2003088033A1 (en) | 2002-04-09 | 2003-10-23 | University Of Rochester | Multiplier-based processor-in-memory architectures for image and graphics processing |
AU2003286131A1 (en) | 2002-08-07 | 2004-03-19 | Pact Xpp Technologies Ag | Method and device for processing data |
GB2398446B (en) * | 2003-02-12 | 2006-06-07 | Snell & Wilcox Ltd | Image processing |
US20060044576A1 (en) * | 2004-07-30 | 2006-03-02 | Kabushiki Kaisha Toshiba | Apparatus for image processing |
US7667764B2 (en) * | 2004-06-04 | 2010-02-23 | Konica Minolta Holdings, Inc. | Image sensing apparatus |
JP4219887B2 (en) | 2004-12-28 | 2009-02-04 | 富士通マイクロエレクトロニクス株式会社 | Image processing apparatus and image processing method |
ATE504043T1 (en) | 2005-04-28 | 2011-04-15 | Univ Edinburgh | RECONFIGURABLE INSTRUCTION CELL ARRAY |
US7602974B2 (en) | 2005-10-21 | 2009-10-13 | Mobilic Technology (Cayman) Corp. | Universal fixed-pixel-size ISP scheme |
FR2895103B1 (en) | 2005-12-19 | 2008-02-22 | Dxo Labs Sa | METHOD AND SYSTEM FOR PROCESSING DIGITAL DATA |
US20070165042A1 (en) * | 2005-12-26 | 2007-07-19 | Seitaro Yagi | Rendering apparatus which parallel-processes a plurality of pixels, and data transfer method |
US7802073B1 (en) | 2006-03-29 | 2010-09-21 | Oracle America, Inc. | Virtual core management |
US20080111823A1 (en) | 2006-11-13 | 2008-05-15 | Faraday Technology Corp. | Graphics processing system |
EP1927949A1 (en) | 2006-12-01 | 2008-06-04 | Thomson Licensing | Array of processing elements with local registers |
US20080244222A1 (en) | 2007-03-30 | 2008-10-02 | Intel Corporation | Many-core processing using virtual processors |
US8068114B2 (en) | 2007-04-30 | 2011-11-29 | Advanced Micro Devices, Inc. | Mechanism for granting controlled access to a shared resource |
JP4389976B2 (en) * | 2007-06-29 | 2009-12-24 | ブラザー工業株式会社 | Image processing apparatus and image processing program |
JP2009021459A (en) * | 2007-07-13 | 2009-01-29 | Fuji Xerox Co Ltd | Method for driving surface emitting semiconductor laser and optical transmission module |
JP4917561B2 (en) * | 2008-03-18 | 2012-04-18 | 株式会社リコー | Image processing device |
CN102047241B (en) | 2008-05-30 | 2014-03-12 | 先进微装置公司 | Local and global data share |
JP4999791B2 (en) * | 2008-06-30 | 2012-08-15 | キヤノン株式会社 | Information processing apparatus, control method thereof, and program |
US8456480B2 (en) | 2009-01-14 | 2013-06-04 | Calos Fund Limited Liability Company | Method for chaining image-processing functions on a SIMD processor |
US8332794B2 (en) | 2009-01-22 | 2012-12-11 | Taiwan Semiconductor Manufacturing Company, Ltd. | Circuits and methods for programmable transistor array |
KR101572879B1 (en) * | 2009-04-29 | 2015-12-01 | 삼성전자주식회사 | Dynamic parallel system and method for parallel application program |
US8572016B2 (en) * | 2009-07-31 | 2013-10-29 | International Business Machines Corporation | Match engine for detection of multi-pattern rules |
US8976195B1 (en) | 2009-10-14 | 2015-03-10 | Nvidia Corporation | Generating clip state for a batch of vertices |
US8436857B2 (en) | 2009-10-20 | 2013-05-07 | Oracle America, Inc. | System and method for applying level of detail schemes |
US8595428B2 (en) | 2009-12-22 | 2013-11-26 | Intel Corporation | Memory controller functionalities to support data swizzling |
US8749667B2 (en) | 2010-08-02 | 2014-06-10 | Texas Instruments Incorporated | System and method for maintaining maximum input rate while up-scaling an image vertically |
US8508612B2 (en) | 2010-09-30 | 2013-08-13 | Apple Inc. | Image signal processor line buffer configuration for processing ram image data |
US9552206B2 (en) * | 2010-11-18 | 2017-01-24 | Texas Instruments Incorporated | Integrated circuit with control node circuitry and processing circuitry |
US8797323B2 (en) | 2011-01-18 | 2014-08-05 | Intel Corporation | Shadowing dynamic volumetric media |
US9092267B2 (en) | 2011-06-20 | 2015-07-28 | Qualcomm Incorporated | Memory sharing in graphics processing unit |
US20130027416A1 (en) | 2011-07-25 | 2013-01-31 | Karthikeyan Vaithianathan | Gather method and apparatus for media processing accelerators |
JP5742651B2 (en) | 2011-10-15 | 2015-07-01 | コニカミノルタ株式会社 | Image processing apparatus, linkage method, and linkage program |
JP5746100B2 (en) | 2011-12-27 | 2015-07-08 | 京セラドキュメントソリューションズ株式会社 | Image forming apparatus |
US8823736B2 (en) | 2012-01-20 | 2014-09-02 | Intel Corporation | Graphics tiling architecture with bounding volume hierarchies |
US10244246B2 (en) | 2012-02-02 | 2019-03-26 | Texas Instruments Incorporated | Sub-pictures for pixel rate balancing on multi-core platforms |
US9235769B2 (en) | 2012-03-15 | 2016-01-12 | Herta Security, S.L. | Parallel object detection method for heterogeneous multithreaded microarchitectures |
US9329877B2 (en) * | 2012-03-18 | 2016-05-03 | Microsoft Technology Licensing, Llc | Static verification of parallel program code |
TWI520598B (en) | 2012-05-23 | 2016-02-01 | 晨星半導體股份有限公司 | Image processing apparatus and image processing method |
US20140019486A1 (en) | 2012-07-13 | 2014-01-16 | Amitava Majumdar | Logic Content Processing for Hardware Acceleration of Multi-Pattern Search |
US9232139B2 (en) | 2012-07-24 | 2016-01-05 | Apple Inc. | Image stabilization using striped output transformation unit |
US9378181B2 (en) | 2012-11-09 | 2016-06-28 | Intel Corporation | Scalable computing array |
US9058673B2 (en) * | 2013-03-15 | 2015-06-16 | Oracle International Corporation | Image mosaicking using a virtual grid |
US8954992B2 (en) * | 2013-03-15 | 2015-02-10 | Lenovo Enterprise Solutions (Singapore) Pte. Ltd. | Distributed and scaled-out network switch and packet processing |
US10255547B2 (en) * | 2014-12-04 | 2019-04-09 | Nvidia Corporation | Indirectly accessing sample data to perform multi-convolution operations in a parallel processing system |
US9818166B2 (en) | 2015-01-16 | 2017-11-14 | Intel Corporation | Graph-based application programming interface architectures with producer/consumer nodes for enhanced image processing parallelism |
US9749548B2 (en) | 2015-01-22 | 2017-08-29 | Google Inc. | Virtual linebuffers for image signal processors |
-
2015
- 2015-04-23 US US14/694,890 patent/US10095479B2/en active Active
-
2016
- 2016-04-05 CN CN201680019972.2A patent/CN107533750B/en active Active
- 2016-04-05 EP EP16721534.2A patent/EP3286721B1/en active Active
- 2016-04-05 GB GB1715610.0A patent/GB2553934B/en active Active
- 2016-04-05 WO PCT/US2016/026029 patent/WO2016171893A1/en active Application Filing
-
2017
- 2017-05-10 US US15/591,984 patent/US10216487B2/en active Active
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110087867A1 (en) * | 2005-06-23 | 2011-04-14 | Jacobson Quinn A | Primitives to enhance thread-level speculation |
CN1925544A (en) * | 2005-08-31 | 2007-03-07 | 松下电器产业株式会社 | Image data processing device |
CN101231585A (en) * | 2007-01-26 | 2008-07-30 | 辉达公司 | Virtual architecture and instruction set for parallel thread computing |
CN101796821A (en) * | 2007-09-05 | 2010-08-04 | 国立大学法人东北大学 | Solid state imaging element and its drive method |
TW201118568A (en) * | 2009-08-28 | 2011-06-01 | Qualcomm Inc | Memory controller page management devices, systems, and methods |
CN103339604A (en) * | 2011-01-31 | 2013-10-02 | 松下电器产业株式会社 | Program generation device, program generation method, processor device, and multiprocessor system |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110058882A (en) * | 2019-03-14 | 2019-07-26 | 成都恒创新星科技有限公司 | It is a kind of for CNN accelerate OPU instruction set define method |
CN110058882B (en) * | 2019-03-14 | 2023-01-06 | 深圳市比昂芯科技有限公司 | OPU instruction set definition method for CNN acceleration |
CN112184565A (en) * | 2020-08-27 | 2021-01-05 | 瑞芯微电子股份有限公司 | Multi-window serial image sharpening method |
CN112184565B (en) * | 2020-08-27 | 2023-09-29 | 瑞芯微电子股份有限公司 | Multi-window serial image sharpening method |
CN111930768A (en) * | 2020-09-10 | 2020-11-13 | 腾讯科技（深圳）有限公司 | Incremental data acquisition method, incremental data transmission method, incremental data acquisition device, incremental data transmission device and computer storage medium |
CN111930768B (en) * | 2020-09-10 | 2021-01-01 | 腾讯科技（深圳）有限公司 | Incremental data acquisition method, incremental data transmission method, incremental data acquisition device, incremental data transmission device and computer storage medium |
Also Published As
Publication number | Publication date |
---|---|
GB2553934B (en) | 2021-06-09 |
US10216487B2 (en) | 2019-02-26 |
WO2016171893A1 (en) | 2016-10-27 |
EP3286721A1 (en) | 2018-02-28 |
US10095479B2 (en) | 2018-10-09 |
US20170242943A1 (en) | 2017-08-24 |
US20160313980A1 (en) | 2016-10-27 |
CN107533750B (en) | 2021-06-01 |
GB201715610D0 (en) | 2017-11-08 |
GB2553934A (en) | 2018-03-21 |
EP3286721B1 (en) | 2020-11-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107533750A (en) | Virtual Image Processor instruction set architecture（ISA）With memory model and the exemplary goal hardware with two-dimensional shift array structure | |
US11182138B2 (en) | Compiler for translating between a virtual image processor instruction set architecture (ISA) and target hardware having a two-dimensional shift array structure | |
US10531030B2 (en) | Block operations for an image processor having a two-dimensional execution lane array and a two-dimensional shift register | |
KR101973733B1 (en) | Architecture for high performance, power efficient, programmable image processing processing | |
KR102232723B1 (en) | Core processor for block operation on image processor with two-dimensional execution lane array and two-dimensional shift register | |
CN107438861A (en) | Data slice maker for image composer | |
CN107533751A (en) | Line buffer unit for image processor | |
TWI752343B (en) | Execution unit circuits, image processors, and methods for performing a sum of absolute difference computation | |
CN110300944A (en) | Image processor with configurable number of active core and support internal network |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
CB02 | Change of applicant information | ||
GR01 | Patent grant | ||
GR01 | Patent grant |