US10410504B2 - System and method for interactive security - Google Patents
System and method for interactive security Download PDFInfo
- Publication number
- US10410504B2 US10410504B2 US15/233,562 US201615233562A US10410504B2 US 10410504 B2 US10410504 B2 US 10410504B2 US 201615233562 A US201615233562 A US 201615233562A US 10410504 B2 US10410504 B2 US 10410504B2
- Authority
- US
- United States
- Prior art keywords
- controlled environment
- sensor
- human
- heartbeat
- emergency condition
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B21/00—Alarms responsive to a single specified undesired or abnormal condition and not otherwise provided for
- G08B21/18—Status alarms
- G08B21/22—Status alarms responsive to presence or absence of persons
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B13/00—Burglar, theft or intruder alarms
- G08B13/18—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength
- G08B13/189—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems
- G08B13/194—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems using image scanning and comparing systems
- G08B13/196—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems using image scanning and comparing systems using television cameras
- G08B13/19697—Arrangements wherein non-video detectors generate an alarm themselves
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B19/00—Alarms responsive to two or more different undesired or abnormal conditions, e.g. burglary and fire, abnormal temperature and abnormal rate of flow
- G08B19/005—Alarms responsive to two or more different undesired or abnormal conditions, e.g. burglary and fire, abnormal temperature and abnormal rate of flow combined burglary and fire alarm systems
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B25/00—Alarm systems in which the location of the alarm condition is signalled to a central station, e.g. fire or police telegraphic systems
- G08B25/01—Alarm systems in which the location of the alarm condition is signalled to a central station, e.g. fire or police telegraphic systems characterised by the transmission medium
- G08B25/08—Alarm systems in which the location of the alarm condition is signalled to a central station, e.g. fire or police telegraphic systems characterised by the transmission medium using communication transmission lines
- G08B25/085—Alarm systems in which the location of the alarm condition is signalled to a central station, e.g. fire or police telegraphic systems characterised by the transmission medium using communication transmission lines using central distribution transmission lines
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B25/00—Alarm systems in which the location of the alarm condition is signalled to a central station, e.g. fire or police telegraphic systems
- G08B25/14—Central alarm receiver or annunciator arrangements
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/21—Server components or server architectures
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/4104—Peripherals receiving signals from specially adapted client devices
- H04N21/4131—Peripherals receiving signals from specially adapted client devices home appliance, e.g. lighting, air conditioning system, metering devices
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/422—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS]
- H04N21/42201—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS] biosensors, e.g. heat sensor for presence detection, EEG sensors or any limb activity sensors worn by the user
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/422—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS]
- H04N21/42202—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS] environmental sensors, e.g. for detecting temperature, luminosity, pressure, earthquakes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/422—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS]
- H04N21/4223—Cameras
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/45—Management operations performed by the client for facilitating the reception of or the interaction with the content or administrating data related to the end-user or to the client device itself, e.g. learning user preferences for recommending movies, resolving scheduling conflicts
- H04N21/4508—Management of client data or end-user data
- H04N21/4524—Management of client data or end-user data involving the geographical location of the client
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/45—Management operations performed by the client for facilitating the reception of or the interaction with the content or administrating data related to the end-user or to the client device itself, e.g. learning user preferences for recommending movies, resolving scheduling conflicts
- H04N21/4508—Management of client data or end-user data
- H04N21/4532—Management of client data or end-user data involving end-user characteristics, e.g. viewer profile, preferences
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/478—Supplemental services, e.g. displaying phone caller identification, shopping application
- H04N21/4788—Supplemental services, e.g. displaying phone caller identification, shopping application communicating with other users, e.g. chatting
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/81—Monomedia components thereof
- H04N21/8126—Monomedia components thereof involving additional data, e.g. news, sports, stocks, weather forecasts
- H04N21/814—Monomedia components thereof involving additional data, e.g. news, sports, stocks, weather forecasts comprising emergency warnings
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N7/00—Television systems
- H04N7/18—Closed-circuit television [CCTV] systems, i.e. systems in which the video signal is not broadcast
- H04N7/181—Closed-circuit television [CCTV] systems, i.e. systems in which the video signal is not broadcast for receiving images from a plurality of remote sources
Definitions
- Embodiments of the present invention generally relate to a system and method for area surveillance, and particularly to a system and method for interactive monitoring and security of an area.
- Home television network in connection with a computing device means are gaining increased popularity.
- multiple personal televisions can be connected together in the home and/or used for office computing device to permit a user to share security data and other data without having to manually carry a camera from one room to another.
- the television network in connection with a computing device means also permits the user to receive detected data, share printers, fax machines, and other devices or reach other distant destination.
- Internet access facilities can also be provided to permit access to external networks and services.
- a user can operate an interactive high definition television through his cell phone in communication with a server to gain instant access to information source from anywhere in the world.
- a remote control unit can be trained to send signals to components of an entertainment center such as, a television, stereo, and VCR, there is no known central device that can communicate and control multiple personal televisions and other analog and/or digital devices, destination at offices and residence or office environment.
- Embodiments in accordance with the present invention provide an interactive security system, method, and device for monitoring a controlled environment, detecting an emergency condition in the controlled environment and generating an alarm based on existence of the emergency condition.
- the present invention provides an interactive security system for monitoring a controlled environment, detecting an emergency condition in the controlled environment and generating an alarm based on existence of the emergency condition.
- the interactive security system includes plurality of sensors positioned at one or more predetermined locations in the controlled environment.
- the plurality of sensors are associated with a sensor, the sensor being configured to collect sensor data in the controlled environment.
- the plurality of sensors include at least one human body sensor configured to detect a human body presence in the controlled environment.
- the plurality of sensors further include at least one emergency condition sensor configured to detect an emergency condition within the controlled environment.
- a control server communicatively coupled to the sensor is configured to receive, store, and process the sensor data and generate an alarm based on detection of at least one of, the human body, the emergency condition or a combination thereof.
- the present invention discloses a method for monitoring a controlled environment, detecting an emergency condition in the controlled environment and generating an alarm based on existence of the emergency condition.
- the method includes receiving sensor data for the controlled environment from a sensor associated with the controlled environment.
- the method further includes processing the sensor data to determine an emergency condition and presence of a human body in the controlled environment and generating an alarm based on detection of at least one of, the emergency condition, the human body or a combination thereof.
- the present invention provides an interactive security media device for monitoring a controlled environment, detecting an emergency condition in the controlled environment and generating an alarm based on existence of the emergency condition.
- the media device includes a command interface for receiving a command from a control module where the control module is communicatively coupled to the media device.
- the media device further includes a communication interface for receiving sensor data from a sensor via a communication network, the sensor comprising a plurality of sensors positioned at one or more predetermined locations in a controlled environment.
- the media device further includes a display for displaying media content and the sensor data.
- the media device further includes a network interface for communicating with a remote command center external to the controlled environment.
- the media device further includes a processor communicatively coupled to the command interface, the control module, the communication interface, the display, and the network interface.
- the processor is configured to receive, store, and process the sensor data and display the sensor data on the display.
- the processor is further configured to generate an alarm based on detection of at least one of, presence of a human body in the controlled environment, detection of an emergency condition in the controlled environment or a combination thereof and provide the alarm information to the remote command center.
- FIG. 1 illustrates a block diagram depicting a security system associated with a controlled environment, according to an embodiment of the present invention
- FIG. 2 illustrates a block diagram depicting a control server of the security system, according to an embodiment of the present invention
- FIG. 3 illustrates a block diagram depicting an archival and retrieval unit of the security system, according to an embodiment of the present invention
- FIG. 4 illustrates a block diagram depicting an extended controlled environment, according to an embodiment of the present invention
- FIG. 5 illustrates a block diagram depicting a media device associated with a controlled environment, according to an embodiment of the present invention
- FIG. 6 illustrates a block diagram depicting a computing device at which one of more processing devices may be based, according to an embodiment of the present invention
- FIG. 7 depicts a flowchart of a method for generating a profile of a controlled environment, according to an embodiment of the present invention
- FIG. 8 depicts a flowchart of a method for controlling one or more devices of the security system, according to an embodiment of the present invention
- FIG. 9 depicts a flowchart of a method for handling sensor data of the controlled environment, according to an embodiment of the present invention.
- FIG. 10 depicts a flowchart of a method for generating an alarm based on sensor data of the controlled environment, according to an embodiment of the present invention
- each of the expressions “at least one of A, B and C”, “at least one of A, B, or C”, “one or more of A, B, and C”, “one or more of A, B, or C” and “A, B, and/or C” means A alone, B alone, C alone, A and B together, A and C together, B and C together, or A, B and C together.
- a or “an” entity refers to one or more of that entity.
- the terms “a” (or “an”), “one or more” and “at least one” can be used interchangeably herein.
- the terms “comprising”, “including”, and “having” can be used interchangeably.
- the term “automatic” and variations thereof, as used herein, refers to any process or operation done without material human input when the process or operation is performed. However, a process or operation can be automatic, even though performance of the process or operation uses material or immaterial human input, if the input is received before performance of the process or operation. Human input is deemed to be material if such input influences how the process or operation will be performed. Human input that consents to the performance of the process or operation is not deemed to be “material”.
- Non-volatile media includes, for example, NVRAM, or magnetic or optical disks.
- Volatile media includes dynamic memory, such as main memory.
- computing device-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, or any other magnetic medium, magneto-optical medium, a CD-ROM, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, a solid state medium like a memory card, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computing device can read.
- a floppy disk a flexible disk, hard disk, magnetic tape, or any other magnetic medium, magneto-optical medium, a CD-ROM, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, a solid state medium like a memory card, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computing device can read.
- a digital file attachment to e-mail or other self-contained information archive or set of archives is considered a distribution medium equivalent to a tangible storage medium.
- the computing device-readable media is configured as a database
- the database may be any type of database, such as relational, hierarchical, object-oriented, and/or the like. Accordingly, embodiments may include a tangible storage medium or distribution medium and prior art-recognized equivalents and successor media, in which the software embodiments of the present invention are stored.
- module refers to any known or later developed hardware, software, firmware, artificial intelligence, fuzzy logic, or combination of hardware and software that is capable of performing the functionality associated with that element. Also, while the present invention is described in terms of exemplary embodiments, it should be appreciated those individual aspects of embodiments of the present invention can be separately claimed.
- FIG. 1 illustrates a block diagram depicting a security system 100 , according to an embodiment of the present invention.
- the security system 100 includes a control server 102 communicatively coupled to a positioning unit 106 , a display 108 , a sensor network 110 , a camera 112 , and an archival and retrieval unit (ARU) 114 through a communication network 104 .
- the security system 100 may be installed in a geographical region, hereinafter referred to as “the controlled environment 122 ”.
- the control server 102 governs addition or deletion of a system component to the security system 100 .
- the control server 102 generates an environment profile to track and monitor all devices, destinations and applications within the controlled environment 122 .
- a text-based or graphical interface enables a user to specify the location or dimensions of the controlled environment 122 for monitoring.
- the controlled environment 122 may include a home, an office, an educational institution, a medical institution, an industrial establishment, a residential building or any other commercial or residential space where monitoring and security of occupants is desired.
- the controlled environment 122 can be one or more rooms or designated areas within a room. Embodiments may also be used to control the operations and functions of system components located within the surrounding area of the controlled environment 122 .
- the user can specify the system components that will be governed in the controlled environment 122 and enable communication with the control server 102 .
- a system component announces its presence by broadcasting a detection control message on a continuous or periodically scheduled basis.
- the control server 102 receives the broadcast and adds the system component to the profile for that particular controlled environment 122 by extracting a detection type and properties for the system component from the detection message.
- the system component can be automatically interfaced with the environment profile. The user can expressly accept the profile change, or ignore it thereby allowing the profile change to be automatically approved.
- control server 102 may also explicitly enable a request through at least one of the broadcast mechanism that all system components in the controlled environment 122 identify themselves through.
- the security system 100 monitors positions of various objects, system components and human beings within the controlled environment 122 in real time.
- the security system 100 utilizes one or more positioning units 106 for monitoring and tracking the location.
- the positioning unit 106 includes an interactive detector as described in U.S. Pat. No. 6,762,686, which is incorporated in by reference herein in its entirety.
- the positioning unit 106 designates spatial locations within the controlled environment 122 for security system 100 .
- the positioning unit 106 is communicatively coupled to the other system components such as the control server 102 via a wired and/or wireless interface.
- the positioning unit 106 is operable to be designated by coded means, to a floor or room within the controlled environment 122 .
- the positioning unit 106 is also operable to designate a specific location within a floor or room. In an embodiment, the positioning unit 106 can be situated outside of the controlled environment 122 to thereby, designate external areas of protection for the controlled environment 122 .
- multiple positioning units 106 are distributed throughout the controlled environment 122 .
- the positioning units 106 may be located within, or mounted to, a wall, door, ceiling, floor, or the like of the controlled environment 122 .
- the positioning units 106 can be coupled to the control module 116 or located as a stand-alone device within the controlled environment 122 .
- the positioning unit 106 is part of a radio frequency (RF) communications system.
- a RF transponder interacts with a RF interrogator to communicate positioning information.
- the transponder is coupled to a system component and makes available identification information that uniquely identifies the system component.
- the transponder can make available other types of information, including an assigned location of the system component if the component is a stationary or infrequently moved device.
- the transponder can be coupled to either the control module 116 or the positioning unit 106 .
- the transponder is an active transponder.
- the active transponder transmits a continuous or periodic signal containing the identification information.
- the position of the system component is being tracked and/or monitored in real time or near real time.
- the transponder is a passive transponder.
- the passive transponder remains inactive or silent until it is activated by detection, an interrogator, or manually activated by the user.
- the current position of the system component is not known to the security system 100 with certainty until the transponder is activated.
- the interrogator is coupled to another system component and receives positioning information when it comes within the communications range of the transponder.
- the interrogator will automatically receive the positioning information from an active transponder, or will activate a passive transponder to receive the positioning information.
- the interaction between the transponder and the interrogator can be explained with following illustration.
- the transponder is coupled to the control module 116 and the interrogator is coupled to or embodied within the positioning unit 106 .
- the positioning unit 106 receives identification codes from the control module 116 .
- the identification codes may include an identifier for the control module 116 .
- the positioning unit 106 sends the identification codes to the control server 102 for further processing.
- the positioning unit 106 sends a vicinity identifier in response to detection of at least an object, wherein the object is responsible for the activation of devices in the controlled environment 122 where the positioning unit 106 is located.
- control server 102 determines the vicinity identifier from an identifier assigned to the positioning unit 120 . For example, when the control module 116 is determined to be located within a dining area and enabled, the control server 102 will then allow the control module 116 to control system components positioned in the dining area.
- the sensor network 110 is communicatively coupled to the control server 102 via the communication network 104 .
- the sensor network 110 includes a plurality of sensors distributed throughout the controlled environment 122 .
- the plurality of sensors may be configured to detect a variety of events or data in the controlled environment 122 .
- the plurality of sensors may further be configured to detect a severity level of an emergency condition.
- the plurality of sensors may determine severity of a fire accident in the controlled environment 122 and/or severity of burn injuries to a human being present in the controlled environment 122 .
- a high resolution image of the human body may be used to determine severity of the burn injuries.
- the plurality of sensors may include an interactive sensor.
- the interactive sensor may analyze a detection severity within at least a frequency threshold value, and for providing at least a time map based on at least a classification of the human body.
- the interactive sensor may further determine a human body temperature of a human being present in the controlled environment 122 .
- the plurality of sensors may be positioned at predetermined locations in the controlled environment 122 .
- the plurality of sensors may collect detection data in the controlled environment 122 .
- the detection data may correspond to one or more events in the controlled environment 122 .
- the plurality of sensors may include a human body sensor configured to detect a human body presence in the controlled environment 122 .
- the human body sensor may be a heat sensor, a heartbeat sensor, a voice sensor, a motion sensor or the camera 112 .
- the human body sensor may detect a position and a movement of a human being.
- the plurality of sensors may further include one or more emergency condition sensors configured to detect an emergency condition within the controlled environment.
- the emergency condition sensors may include a smoke sensor, a fire sensor, a temperature sensor, a break-through sensor, a pressure sensor, a sound sensor, a voice sensor, or the camera 112 .
- the smoke sensor serves as a detection platform for the control server 102 .
- the smoke sensor's ceiling-wall mounted base and direct connection to existing voltage AC power line of the controlled environment 122 provides an ideal platform for the control server 102 and enables information to be transported throughout the controlled environment 122 either through a wireless connection or through the power line.
- the control server 102 can be housed within a wired/wireless access point, which provides the control server 102 with “always-on” connectivity.
- the smoke sensor may include a network interface card which enables the smoke sensor to provide the control server 102 with Home-PNA and/or wireless (e.g., IEEE 802.11 or 49.11) network connectivity.
- the smoke sensor platform also provides means of connectivity for the control server 102 .
- Another advantage of using the smoke sensor as a detection platform for the control server 102 is that the smoke sensor can be ceiling/wall mounted to facilitate a greater communications range.
- electronic image sensors may be embedded in the sensor network 110 .
- the image sensors may have mega-pixel resolution with optical/digital zoom arrays of a large number of very small light sensors, together called “mega-pixel resolution with optical/digital zoom arrays”.
- the camera 112 comprises imaging components to produce an optical image of an emergency scene onto the mega-pixel resolution with optical/digital zoom array.
- the electronic image sensors convert the optical image detected into a set of electronic signals.
- the electronic image sensors may utilize arrays of CCD sensors for converting light into electrical signals.
- the camera 112 is communicatively connected to the control server 102 .
- the camera 112 may include a control unit that enables remote control of various camera functions, such as pan, tilt, zoom, focus, and iris control.
- the camera 112 includes one or more video cameras or camcorders and is installed in a media device 118 .
- the media device 118 may be an interactive high definition television.
- the plurality of sensors may provide detection data to the control server 102 for further processing.
- the control server 102 may provide processed detection data to the archival and retrieval unit (ARU) 114 which is configured to receive compressed data streams, filter the streams for metadata such as, date, time, and source and store the streams and metadata for future retrieval. Further details of the ARU 114 are explained with reference to FIG. 3 below.
- ARU archival and retrieval unit
- the control server 102 may provide processed detection data to the display 108 for playback of the detection data.
- the display 108 is a wired or wireless display that supports closed-circuit viewing.
- the display 108 is a flat liquid crystal display (LCD) positioned on a wall or standing on a desk, table, or counter top.
- the display 108 receives a streaming screen saver that displays static or dynamic images of a photograph, or a portrait when the display 108 is functioning in an inactive state.
- the display 108 receives feeds from the media device 118 .
- the data from the plurality of sensors is analyzed by the control server 102 for determining an emergency condition. If an emergency condition exists in the controlled environment 122 , the control server 102 may activate one or more alarms or response functions in the controlled environment 122 . In another embodiment, the control server 102 intimates a remote command center 122 of the emergency condition. For example, if the detection data indicates a fire in the controlled environment 122 , the control server 102 may activate water sprinklers and intimate the remote command center 120 about the fire incident. The control server 102 may transmit live data associated with the emergency condition to the remote command center 120 .
- control module 116 is a wired or wireless data processing device that enables a user to interact with the security system 100 and send control commands to the control server 102 and other devices.
- the control module 116 enables a user to remotely control the operations of various components of the security system 100 .
- a display of the control module 116 is capable of receiving video, text, and/or audio from other devices.
- the control module 116 includes a flash ROM that enables wireless downloads and uploads of detection data about sections of the controlled environment 122 .
- the communication network 104 of the security system 100 may include a wired and/or wireless local area network (LAN) or wide area network (WAN), such as an organization's intranet, a local internet, the global-based Internet including the World Wide Web, an extranet, a. virtual private network (VPN), licensed wireless telecommunications spectrum for digital cable and cell including CDMA, TDMA, GSM, EDGE, GPRS, CDMA2000, WCDMA FDD and/or TDD or TD-SCDMA technologies, or the like.
- LAN local area network
- WAN wide area network
- VPN virtual private network
- CDMA licensed wireless telecommunications spectrum for digital cable and cell including CDMA, TDMA, GSM, EDGE, GPRS, CDMA2000, WCDMA FDD and/or TDD or TD-SCDMA technologies, or the like.
- the communication network 104 includes wired, wireless, or both transmission media and includes satellite, terrestrial such as fiber optic, copper, UTP, STP, coaxial, hybrid fiber-coaxial “HFC”, or the like, radio, free-space optics, microwave, and/or any other form or method of transmission.
- satellite terrestrial such as fiber optic, copper, UTP, STP, coaxial, hybrid fiber-coaxial “HFC”, or the like, radio, free-space optics, microwave, and/or any other form or method of transmission.
- FIG. 2 illustrates a block diagram depicting a control server 102 of the security system 100 , according to an embodiment of the present invention.
- the control server 102 includes a security controller 202 , a messaging controller 204 , an audio controller 206 , a menu module 208 , a. file controller 210 , telephony controller 212 , a video controller 214 , a network interface controller 216 , a clock module 218 , a processor 220 , and a memory 222 .
- the control server 102 may further include application software and data for enabling the above controllers.
- the security controller 202 enables the control server 102 to interact with and/or manage various system component of the security system 100 .
- the security controller 202 controls and/or monitors feedback from the plurality of sensors that form a part of the security system 100 .
- the security controller 202 receives feedback from one or more motion sensors placed within the controlled environment 122 or in external locations surrounding the controlled environment 122 .
- the feedback activates the camera 112 and/or an audio means within the vicinity of the detected motion.
- such feedback activates a security alarm or signals the control module 116 .
- the control module 116 can vibrate, ring, flash a message, or the like.
- the camera 112 may be moved and/or focused in a particular direction and particular location within the controlled environment 122 .
- the security controller 202 is operable to lock or unlock doors, windows, or entryways in response to user's input at the control module 116 .
- the security controller 202 interfaces with a fire and safety control system within the controlled environment 122 .
- the plurality of sensors is feed into control server 102 and may enable a user to log in and monitor emergency situations.
- the user can be authorized via the security controller 202 to log into the control server 102 over the Internet from the remote command center 120 and receive live feeds from the camera 112 , archived feeds from the camera 112 , or broadcasts feed from the media device 118 .
- the messaging controller 204 enables centralized storage of telephone calls received via the telephony controller 212 . Voice messages are written to a memory of the ARU 114 .
- the messaging controller 204 enables messages including audio, video, and/or text to be created, stored, and/or retrieved within the security system 100 .
- the user can operate the control module 116 , a telephone (not shown), or an audio means to create a message for another user.
- the messaging controller 204 may also enable the control server 102 to interact with a computing device to communicate, search and/or retrieve data from the computing device.
- the audio controller 206 manages the exchange of audio signals within the security system 100 . Accordingly, the audio controller 206 receives and/or distributes audio signals for one or more audio components, such as, for example, a voice auditory/audio means, speakers coupled to the computing device, the media device 118 or the control module 116 . The audio controller 206 may receive audio signals from the ARU 114 and distribute the audio signal to the voice auditory/audio means and the control module 116 . Further, the audio controller 206 may store an audio stream in the ARU 114 for future recall. In an embodiment, the audio controller 206 reads and/or writes to an internal storage medium that is designated for audio, and hence distributes audio to and from its internal storage medium.
- the audio controller 206 reads and/or writes to an internal storage medium that is designated for audio, and hence distributes audio to and from its internal storage medium.
- the audio controller 206 may query a web site, for example, “MP3.com” to download a digital recording to be played at a media device or stored in the ARU 114 .
- the audio controller 206 encodes the audio stream to MPEG-3 format to produce compact disk (CD) quality in real time or near real time.
- the audio controller 206 encodes the audio stream to produce detection data on the CD quality audio in real time or near real time.
- the menu module 208 may manage one or more menus associated with one or more devices in the controlled environment 122 .
- the menu module 208 may direct storing and retrieval of menu items in the ARU 114 .
- the menu module 208 is configured to interact with the control module 116 to receive one or more commands and direct a corresponding device to execute a function based on the one or more commands.
- the control server 102 manages a clock associated with a device via the menu module. 208
- the clock module 218 can set or synchronize a clock for one or more system components including the components of the ARU 114 .
- the clock module 218 includes a real-time clock that can be set by the user through the control module 116 . Alternatively, the real-time clock can be set via the Internet through the communication network 104 .
- the clock module 218 uses its own real-time clock to set the clock of other system components by navigating a menu of the respective system component. Since the control server 102 tracks and monitors the state of the system components, the clock module 218 is programmable to navigate the menus of the system component to set the clock without interfering with the component's operations, such as when the media device 118 is on.
- instructions for navigating a system component are stored in the ARU 114 .
- the input numbers for navigating the menus of a VCR or DVD distributor to set or program its internal clock can be memorized.
- the memorized numbers are associated with a set of infrared (IR) codes, which are stored at the control server 102 .
- the IR codes are retrieved from an IR code database or library, and transmitted to the appropriate system component.
- the IR codes are executed to navigate the menus to set the clock or retrieve detection data content.
- the file controller 210 enables the control server 102 to function as a central file server for all personal devices in the controlled environment 122 .
- the file controller 210 enables data to be stored and accessed by system components located within the controlled environment 122 .
- a device located outside the controlled environment is able to store and/or retrieve data via the file controller 210 . For example, if a static internet protocol (IP) address is sustained by the internet service provider (ISP) of the security system 100 , then a remote user could log into the control server 102 to retrieve and/or store data via the file controller 210 .
- IP internet protocol
- ISP internet service provider
- the telephony controller 212 manages the distribution of telecommunications from conventional telephone paths and/or a television network.
- the telephone is coupled to a conventional wired or wireless telephone path, such as POTS or PSTN.
- the telephone can also be coupled to a cellular or satellite communications path.
- a dedicated interface is provided to enable the cellular/satellite telephone means to interact with the security system 100 .
- Calls or signals received or transmitted over the conventional path are also monitored and/or controlled by the control server 102 .
- the control server 102 is responsive to distributing detection and communication signals from the calls or the controlled environment 122 to other system components. For example, the user is able to directly operate the control module 116 to place and/or receive calls indirectly via the telephone when detection is enabled.
- the video controller 214 manages the exchange of video signals within the controlled environment 122 .
- the video controller 214 receives and/or distributes video signals for displays coupled, for example, to the computing device, the media device 118 , or the control module 116 .
- the video controller 214 also interacts with the components of the ARU 114 .
- the video controller 214 reads and/or writes to an internal storage medium that is designated for video in addition to or in lieu of the ARU 114 components. Accordingly, the video controller 214 receives video signals from the ARU 114 components and/or its internal storage medium and distributes the video signals to other system components such as the media device 118 and the control module 116 .
- the video controller 214 can also receive a video stream from a source such as the Internet or the media device 118 and store the video stream in the ARU 114 or its internal storage medium for future references and viewing.
- the video controller 214 can query a web site such as “www.bet.com” to download a music video to be played and/or stored to a system component while also checking for ongoing security at a current bet show.
- the video controller 214 provides MPEG encoding.
- the video controller 214 is configured to receive, encode, and distribute a media and detected data stream in real time or near real time.
- a network connection to the Internet enables the video controller 214 to implement broadband Internet access for audio/video distribution of security data associated with the controlled environment 122 .
- the network interface controller 216 enables the control server 102 to communicate with the devices within or outside the controlled environment 122 via the communication network 104 and the Internet.
- the processor 220 is configured to process data received, stored or transmitted by the control server 102 in coordination with the various controllers described above. Processing of data may include reformatting or scaling of data (e.g., from a range of 0-65,535 to a human-interpretable range or meaningful units such as degrees Fahrenheit), combining or dividing various data or data fields, performing calculations on the data, comparing or correlating data, buffering the data, and so forth.
- the memory 222 is configured to store and hold data received at the control server 102 . The memory 222 may be accessed by various controllers and the processor 220 for retrieving data stored therein.
- FIG. 3 illustrates a block diagram depicting components of the ARU 114 , according to an embodiment of the present invention.
- the ARU 114 includes a data analyzer 302 , a data recognizer 304 , a decision support system (DSS) 306 , a data archive 308 , a secondary control server 310 , and a menu 312 .
- DSS decision support system
- the aforementioned ARU 114 components are not intended to be an exhaustive listing. Other ARU 114 components can be implemented and are deemed to be within the scope of embodiments of the present invention.
- the ARU 114 is communicatively coupled to the control server.
- the ARU 114 is configured to receive compressed streams, filter the streams for metadata such as, date, time, and source and store the streams and metadata for future retrieval.
- the ARU 114 may be internal or external to the control server 102 .
- the ARU 114 components may be centrally located or distributed throughout the controlled environment 122 . In an embodiment, the ARU 114 components may be accessible from an external source such as, a web server device having communicating means over the global Internet via the communication network 104 .
- the data archive 308 provides one or more storage mediums for various data including video data, audio data, and metadata.
- the data archive 308 may include a removable storage unit such as a zip disk, a floppy disk, or a compact disc-read only memory (CD-ROM).
- a data warehouse system may be used to store the detection data and support the control server 102 .
- the data archive 308 may include a relational or object oriented (OO) component based database management system, or the like, that controls the analyzer, storing, retrieving, and updating of relevant data and metadata in the database records.
- OO object oriented
- the database management system also controls data integration, enforces integrity rules and constraints including detection data integrity and detection data referential integrity, and enforces security constraints.
- the data archive 308 is a scalable system that stores data on multiple disk arrays.
- the detection and communication data warehousing can be implemented with the SQL Server 2000 application, which is available from Microsoft® Corporation, the Oracle® 9i database system is available from Oracle® Corporation or other similar proprietary products and services.
- the data archive 308 may support Open Database Connectivity (ODBC) and/or Java Database Connectivity (JDBC) protocols.
- ODBC Open Database Connectivity
- JDBC Java Database Connectivity
- the data archive 308 may further include an index file database system and/or a planner file database system.
- Secondary control server 310 receives audio and video signals from the television 412 and the plurality of sensors.
- the secondary control server 310 may include radio or television tuners and programmers.
- the data analyzer 302 can be a VCR distributor, DVD distributor, PVR, video server, virtual recorder, audio server, stereo, CD distributor, record distributor, audio tape or cassette distributor, digital audio tape recorder, and/or any other device or application that stores, records, generates, or plays back via magnetic, optical, electronic, or any other storage media.
- the IR codes may also be used to program the data analyzer 302 to record selected programs.
- the data recognizer 304 records and plays back media and detected data and/or multimedia and detected data similar to the data analyzer 302 functions. However, the data recognizer 304 is further capable of loading multiple recordings such as CD or DVD to be played without having to be reloaded.
- the DSS 306 may include a human body heat sensor to detect presence of a human body in the controlled environment 122 .
- the DSS 306 may enable the security system 100 to determine presence and condition of a human body in the controlled environment 122 .
- the menu 312 may include one or more menus associated with one or more devices or components of the security system 100 .
- the menu 312 may be stored in the data archive 308 or it may be external to the data archive 308 and stored in another storage medium such as a read only memory.
- FIG. 4 illustrates a block diagram depicting an extended controlled environment 400 , according to an embodiment of the present invention.
- the extended control environment 400 may include the controlled environment 122 and surrounding areas up to a predetermined distance from the boundaries of the controlled environment 122 .
- the controlled environment 122 may include a home, an office, an educational institution, a medical institution, an industrial establishment, a residential building or any other commercial or residential space where monitoring and security of occupants is desired.
- the extended controlled environment 400 may include one or more sensor networks at one or more locations.
- the extended controlled environment 400 may include a location 1 402 having installed a sensor network 110 .
- the extended controlled environment 400 may further include a location N 404 having installed another sensor network 110 .
- the location 1 and the location N may be outside the controlled environment 122 but within the surrounding areas and included in the extended controlled environment 400 .
- the controlled environment 100 , the sensor networks 110 at locations 1 -N may be communicatively coupled to the remote command center 120 via the communication center 120 .
- Each sensor network 110 may include the plurality of sensors as described with reference to FIG. 1 .
- Each sensor network 110 may send sensor data to the control server 102 of the controlled environment 122 .
- sensor data may depend upon the type of sensor that supplies the sensor data.
- sensor data may include an analog measurement (e.g., a temperature measurement).
- Sensor data may also include images or streaming media (e.g., photos, videos, audio recording, etc.).
- Sensor data may also include a binary indication (e.g., whether something is present or not present, whether a measurement is above or below a threshold, etc.).
- the controlled environment 122 includes a plurality of sections at locations 1 -N, each section having at least one human body sensor and the at least one emergency condition sensor. Other characteristics and functions of the extended controlled environment 400 are similar to that of the controlled environment 122 and the security system 100 as described with reference to FIG. 1 .
- the extended controlled environment 400 may further include an audio means (not shown).
- the audio means may include a wired or wireless audio system, such as a cell phone, stereo or audio voice server.
- the audio means may include a microphone as part of the security system 100 .
- the audio means includes one or more speakers with audio outputs located throughout the controlled environment 122 .
- FIG. 5 illustrates a block diagram depicting a media device 118 associated with the controlled environment 122 , according to an embodiment of the present invention.
- the control server 102 the camera 112 , and a computing device 500 are included in the media device 118 .
- the media device 118 may be communicatively coupled to the sensor network 110 , the control module 116 , the positioning unit 106 , and the remote command center 120 via the communication network 104 .
- the media device 118 is configured for monitoring and security of the controlled environment.
- the media device 118 may include a command interface for receiving a command from the control module 116 .
- the control module 116 being communicatively coupled to the media device 118 .
- the media device 118 may further include a communication interface for receiving and transmitting data from the network of sensors via the communication network 104 .
- the media device 118 may include a display for displaying media content and the sensor data.
- the media device 118 may further include a network interface for communicating with the remote command center 120 external to the controlled environment 122 .
- the media device may further include the computing device 500 .
- the computing device may include a processor.
- the processor is communicatively coupled to the command interface, the control module 116 , the communication interface, the display, and the network interface.
- the processor is configured to receive detection data from the network of sensors.
- the processor is further configured to display the detection data on the display of the media device 118 .
- the processor is further configured to generate an alarm based on the sensor data and providing the alarm information to the remote command center 120 .
- Generation of an alarm may proceed in various ways. For example, sensor data or a sensor status may be received by the processor from a sensor. The processor may then compare sensor data to a threshold, and generate the alarm if the sensor data is above a threshold (if higher sensor data is bad), or generate the alarm if the sensor data is below a threshold (if lower sensor data is bad). An alarm may also be generated if the sensor exhibits insufficient activity over time (e.g., if the sensor is defective).
- a sensor status may be sufficient to generate an alarm without comparison to a threshold, e.g., if the sensor status indicates the presence of an unwanted object, or the lack of presence of a wanted object. Further details of the computing device 500 are explained with reference to FIG. 6 below.
- the media device 118 includes an interactive high definition television.
- the television may be a conventional television having embedded cameras with all features focused for enabling interactive detection and communication.
- the television is enhanced to support interactive and personal services.
- the personal services may include monitoring, virtual recording, programming, pausing/rewinding live broadcasts, or the like.
- the television can be a personal television with interactive means enhanced to support online communication and other radio frequencies transmission through web TV Networks or other conventional networks.
- the television may include means for enabling communication through cable or satellite receptions and in connection to a device having at least a PVR, VCR, or DVD distributor/recorder.
- FIG. 6 illustrates a block diagram depicting the computing device 500 at which one of more processing devices may be based, according to an embodiment of the present invention.
- the following discussion is intended to provide a brief, general description of a suitable computing environment in which one or more components or devices of embodiments of the present invention may be implemented.
- Those skilled in the art will appreciate that the embodiments may be practiced with other computing device system configurations, including hand-held devices, multiprocessor systems, microprocessor-based or programmable consumer electronics, minicomputer devices, mainframe computing devices, and the like.
- the embodiments of the present invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network.
- program modules may be located in both local and remote memory storage devices.
- the computing device architecture illustrates a conventional computing device, including a central processing unit (CPU) 602 , a system memory 612 , including a random access memory (RAM) 614 , a read only memory (ROM) 616 , firmware 618 , and a system bus 624 that couples the system memory 612 to the CPU 602 .
- the CPU 602 may comprise a general purpose microprocessor from INTEL® CORPORATION.
- the CPU 602 may comprise a PENTIUM 4® or XEON® microprocessor from INTEL® CORPORATION.
- the ROM 616 may store the firmware 618 for use in operating the computing device 500 , such as a BIOS or an extensible firmware interface (EFI), containing the basic routines that perform basic platform initialization and prepare the computing device 500 to launch an operating system 622 .
- the RAM 614 is a battery-backed memory device that may be used by the firmware 618 to store setting information for the computing device 500 .
- the ROM 616 may be utilized to store configuration information.
- the computing device 500 further includes a mass storage device 620 for storing the operating system 622 and application data 624 .
- the mass storage device 620 is connected to the CPU 602 through a mass storage controller (not shown) connected to the bus 626 .
- the mass storage device 620 and its associated computing device-readable media provide non-volatile storage for the computing device 500 .
- computing device-readable media can be any available media that can be accessed by the computing device 500 .
- computing device-readable media may comprise computing device storage media and communication media.
- Computing device storage media includes volatile and non-volatile, removable and non-removable media implemented in any method or technology for storage of information such as computing device-readable instructions, data structures, program modules or other data.
- Computing device storage media includes, but is not limited to, RAM, ROM, EPROM, EEPROM, flash memory or other solid state memory technology, CD-ROM, digital versatile disks (“DVD”), or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by the computing device 500 .
- the computing device 500 may operate in a networked environment using logical connections to remote computing devices through the communication network 104 , and the Internet.
- the computing device 500 may connect to the Internet through a network interface 604 connected to the bus 626 . It should be appreciated that the network interface 604 may also be utilized to connect to other types of networks and remote computing device systems.
- the computing device 500 may also include a keyboard controller 606 for receiving input from a keyboard and a video display adapter 608 for providing output to a display screen.
- FIG. 7 depicts a flowchart of a method 700 for generating a profile of the controlled environment 122 or the extended controlled environment 400 , according to an embodiment of the present invention.
- the method 700 starts at step 702 .
- position information of a device or a system component located in the controlled environment 122 is received.
- Embodiments may determine the current position of any of the aforementioned system components.
- the present invention includes various embodiments for accessing locator codes and/or a vicinity identifier. For instance, in the described embodiment, a user interacts with a text or graphical interface to manually enter the current location for an intelligent component.
- a voice command interface enables the user to enter voice commands for an intelligent component responsive for enabling verbally communicating through devices in current and distant location indicative of enabling communication to intruders from remote locations.
- an intelligent component interacts with positioning unit 106 to access locator codes.
- the intelligent component may be the control module 116 and is coupled to the interrogator.
- the interrogator polls positioning unit 106 for a vicinity identifier.
- the vicinity identifier includes an infrared sensor having locator codes responsive for identifying the current location of detection activities and for identifying the location of users when detection is enabled for both or all system components.
- the interrogator may be integrated with positioning unit 106 and connected to the control module 116 to enable interactive communication with an intelligent component.
- the intelligent component representing at least the control module 116 in communication with the interrogator and configured with a plurality of devices.
- the interrogator receives an identifier for communications with intelligent component to enable a locator code representing at least the vicinity where detection was enabled.
- the locator codes are then produced and transmitted by associating the identifier with the vicinity identifier for the interrogator.
- step 704 identification information of the device or the system component is received.
- step 706 the position information and the identification information is provided to the control server.
- the control server generates a profile for the controlled environment 122 based on the position and identification information of the devices or the system components.
- the profile of the controlled environment 122 may be stored by the control server 102 at the data archive 308 for future reference or retrieval and method 700 ends.
- FIG. 8 depicts a flowchart of a method 800 for controlling one or more devices of the security system 100 , according to an embodiment of the present invention.
- the method 800 starts at step 802 .
- detection data from a device in the controlled environment is received.
- the detection data may be received via the sensor network 110 .
- an environment profile for the controlled environment 122 is received.
- the environment profile for the controlled environment 122 may be retrieved from the ARV 114 .
- the environment profile includes a listing of devices having links with distant destination and/or other device applications representing system components that receive commands and/or controls from the control server 102 and/or the control module 116 .
- control options for the device are presented to a user based on the environment profile and the detection data.
- the control options include the listing of devices in communication with a device destination and/or other device applications corresponding to the environment profile.
- the positioning can be determined remotely at the control server 102 or locally at the intelligent components such as cell phones, telephones, computing devices, portable wireless devices, or the control module 116 .
- the control server 102 when detection is enabled and determined remotely, the control server 102 , for example, produces description of the detection through interactive communication with plurality of devices having camera means and in wired/wireless communication with the control server 102 .
- the control server 102 sends a user the detection data through an interface means with at least an intelligent component and enable displaying the detection and control options on the intelligent component such as the control module 116 or another system component that the user is operating. If transmitted data is determined locally, at least the intelligent component retrieves the environment profile data to enable the user to interface with the environments of the home to which detection was enabled and also with security agencies such as the fire department and the police department.
- the environment profile can be sent to the intelligent component on demand through wired/wireless means, or the intelligent component can be updated periodically with available environment data.
- a control command is sent to the device based on the presented control options.
- the user operates the intelligent component such as at least the control module 116 to send a request to control a system component such as the media device 118 that are identified in the environment profile.
- the user can send a request to control a function and/or an operation of a system component.
- the user can send a request to alter the configuration or security profile for the component.
- Other control request can be sent as would be suggested by one skilled in the relevant art.
- the control request can be transmitted directly to the designated component, or indirectly to the designated component via the control server 102 .
- step 810 the device executes the received control command and the method 800 ends.
- FIG. 9 depicts a flowchart of a method 900 for handling sensor data of the controlled environment 122 , according to an embodiment of the present invention.
- the method 900 starts at step 902 .
- a recording command is sent to a recording device located in the controlled environment.
- the recording can be a recorder coupled to the media device 118 .
- a profile of the controlled environment 122 is retrieved from the ARU 114 .
- a display device is selected for displaying of the recorded data based on processing of the profile.
- the selected display device may be the media device 118 .
- the recorded data is transmitted to the selected display device.
- an audio level is selected for the selected display device.
- the recorded data is played on the selected display device and the method 900 ends.
- FIG. 10 depicts a flowchart of a method 1000 for generating an alarm based on sensor data of the controlled environment 122 , according to an embodiment of the present invention.
- the method 1000 starts at step 1002 .
- detection data from the sensor network 110 associated with the controlled environment 122 is received at the control server 102 .
- detection data from the sensor network 110 for detecting presence of a human body in the controlled environment 122 is received at the control server 102 .
- the data received from the sensor network 110 is processed by the control server 102 .
- step 1008 a profile of the controlled environment 122 is retrieved from the ARU 114 by the control server 102 .
- an alarm is generated based on the emergency condition, the presence of human body, and the profile information.
- step 1012 alarm information is provided to the remote command center 120 external to the controlled environment 122 and the method 1000 ends.
- the embodiments in accordance with the present invention provide an interactive security system, method, and device for monitoring a controlled environment, detecting an emergency condition in the controlled environment and generating an alarm based on existence of the emergency condition
- exemplary embodiments of the present invention illustrated herein show the various components of the system collocated, certain components of the system can be located remotely, at distant portions of a distributed network, such as a LAN and/or the Internet, or within a dedicated system.
- a distributed network such as a LAN and/or the Internet
- the components of the system can be combined in to one or more devices, such as a switch, server, and/or adjunct, or collocated on a particular node of a distributed network, such as an analog and/or digital telecommunications network, a packet-switch network, or a circuit-switched network.
- the various links connecting the elements can be wired or wireless links, or any combination thereof, or any other known or later developed element(s) that is capable of supplying and/or communicating data to and from the connected elements.
- These wired or wireless links can also be secure links and may be capable of communicating encrypted information.
- Transmission media used as links can be any suitable carrier for electrical signals, including coaxial cables, copper wire and fiber optics, and may take the form of acoustic or light waves, such as those generated during radio-wave and infrared data communications.
- system and method embodiments of the present invention may be implemented in conjunction with a special purpose computing device, a programmed microprocessor or microcontroller and peripheral integrated circuit element(s), an ASIC or other integrated circuit, a digital signal processor, a hard-wired electronic or logic circuit such as discrete element circuit, a programmable logic device or gate array such as PLD, PLA, FPGA, PAL, special purpose computing device, any comparable means, or the like.
- a special purpose computing device a programmed microprocessor or microcontroller and peripheral integrated circuit element(s), an ASIC or other integrated circuit, a digital signal processor, a hard-wired electronic or logic circuit such as discrete element circuit, a programmable logic device or gate array such as PLD, PLA, FPGA, PAL, special purpose computing device, any comparable means, or the like.
- any device(s) or means capable of implementing the methodology illustrated herein can be used to implement the various aspects of this present invention.
- Exemplary hardware that can be used for embodiments includes computing devices, handheld devices, telephones (e.g., cellular, Internet enabled, digital, analog, hybrids, and others), and other hardware known in the art. Some of these devices include processors (e.g., a single or multiple microprocessors), memory, non-volatile storage, input devices, and output devices.
- processors e.g., a single or multiple microprocessors
- memory e.g., a single or multiple microprocessors
- non-volatile storage e.g., input devices, and output devices.
- alternative software implementations including, but not limited to, distributed processing or component/object distributed processing, parallel processing, or virtual machine processing can also be constructed to implement the methods described herein.
- the disclosed methods may be readily implemented in conjunction with software using object or object-oriented software development environments that provide portable source code that can be used on a variety of computing device or workstation platforms.
- the disclosed system may be implemented partially or fully in hardware using standard logic circuits or VLSI design. Whether software or hardware is used to implement the systems in accordance with embodiments of the present invention is dependent on the speed and/or efficiency requirements of the system, the particular function, and the particular software or hardware systems or microprocessor or microcomputing device systems being utilized.
- the disclosed methods may be partially implemented in software that can be stored on a storage medium, executed on programmed general-purpose computing device with the cooperation of a controller and memory, a special purpose computing device, a microprocessor, or the like.
- the system and method embodiments of the present invention can be implemented as program embedded on personal computing device such as an applet, JAVA® or CGI script, as a resource residing on a server or computing device workstation, as a routine embedded in a dedicated measurement system, system component, or the like.
- the system can also be implemented by physically incorporating the system and/or method into a software and/or hardware system.
- the present invention in various embodiments, configurations, and aspects, includes components, methods, processes, systems and/or apparatus substantially as depicted and described herein, including various embodiments, sub-combinations, and subsets thereof. Those of skill in the art will understand how to make and use embodiments of the present invention after understanding the present disclosure.
- the present invention in various embodiments, configurations, and aspects, includes providing devices and processes in the absence of items not depicted and/or described herein or in various embodiments, configurations, or aspects hereof, including in the absence of such items as may have been used in previous devices or processes, e.g., for improving performance, achieving ease and/or reducing cost of implementation.
- Home security detectors configured with the control components of the home comprising interactive detectors enhanced to support location-awareness and home occupant-awareness and functionality.
- the system includes at least one motion sensor configured with communication devices operatively arranged to transmit information about any motion of occupants in the various sections of the home as part of the information about the occupancy of the home during an emergency.
- At least one sensor is provided in various rooms of a home each sensing a state of the home.
- a central communication device is coupled, wired or wirelessly, directly or indirectly, to each home sensor configured to transmit the state of the home.
- the number of occupants in the home are determined by at least one body heat sensor and at least one heartbeat sensor each configured with the interactive detectors to detect the presence of emergency and home occupants and to know the present situations such as their heartbeats, such that the number of occupants and their locations are determinable from the number of detected body heat and their security and safety conditions are determinable by their heartbeats.
- the detection method includes the steps of sensing a state of the home and transmitting the state of the home to at least a server. Images of the home are captured by at least a camera means configured with at least a MOS and/or CMOS based active sensor array for producing real-time images and stored in the server for wireless retrieval. The images ideally include at least an intruder of the home.
- the server is configured with a central processor for enabling controlling security vigilance monitoring and for enabling rapid distribution of detection data, voice, and other detection signals within the monitoring environment.
- the system establishes a network which includes configuring home audio/visual devices, media destination means such as televisions, monitors, PDAs, notepads, notebooks, MP3, wireless stereo, cell phones etc. for the detection means.
- the control server supports video/audio servings, telephony, messaging, file sharing, internetworking, and security monitoring and allows home occupants to access and control the home network environment from any location within a controlled residential, commercial/industrial and/or non-residential, commercial/industrial environment with at least a computer means such as a cell phone.
- a method for monitoring and providing security assistance to a home and home occupants comprises the steps of: determining at least one fire-property or characteristics of occupancy of the home constituting information about the security and occupancy state of the home; automatically establishing a communication channel between the home and a remote facility without manual intervention to thereby enable the information about the security and the occupancy state of the home to be transmitted to the remote facility; at the remote facility, considering the information about the security and the occupancy state of the home received from the home and directing assistance to the home based on the transmitted information; the step of determining at least one fire-property or characteristic of emergency and the occupancy state of the home comprising the step of determining the number of occupants in the various sections, the number of occupants in the various sections being transmitted as part of the information about the occupancy state of the home; and wherein the step of determining the number of occupants in the home comprising the steps of receiving waves energy or radiation from all of the each locations in the various sections and determining the number of occupants in the various sections from the received waves,
- the step of determining the number of occupants in the home comprises the step of arranging at least one heartbeat sensor and at least one body heat sensor in the home to detect the presence of human heartbeats in the home such that the number of occupants is determinable from the number of detected body heat and the security is determinable from the number of detected heartbeats and or body heat.
- a method for enabling security vigilant monitoring and communication comprises: a control server comprising a communication means configured to transmit various detection applications and communicatively connected to a at least an entertainment device comprising at least an interactive television; said interactive television responsive for viewing contents and said communication means comprising a wireless/wired device configured with method for using in-house communication control device to set a wireless/wired electronic device to join a wireless/wired local area network (LAN); said communication means further comprising sending a setup request from the control server configured with in-house entertainment devices comprising interactive detection means via at least a limited access connection; said setup request comprising a request to be compiled on the control server to the wireless/wired LAN for receiving a data package from at least said in-house entertainment device, said data package including at least a detection by the interactive detection means to enable network data distribution necessary for wireless/wired device to join the wireless LAN for utilizing the network data at the control server to establish a full access connection to an access point of at least a home; said communication means configured with said interactive detectors in communications with said
- the method for enabling security vigilant monitoring and communication further comprises the steps of: said interactive detection sensing a state of the home, a state of occupancy of the home, and/or a state of a component of the home; transmitting the state of the home, the state of occupancy of the home, and/or the state of the component of the home to at least a control server; sensing a state of the environment around and exterior of the home; and transmitting information about the environment of the home.
- the method for enabling security vigilant monitoring and communication further comprises the steps of: monitoring and providing assistance to a home, comprising the steps of: determining at least one fire-property or characteristic of occupancy of the home constituting information about the security and occupancy state of the home; determining at least one state of the home or of a component of the home constituting information about the operation of the home; selectively and automatically establishing a communication channel between the home and a remote facility without manual intervention to thereby enable the information about the security and occupancy state of the home and the information about the operation of the home to be transmitted to the remote facility to enable assistance to be provided to the home based on the transmitted information; at the remote facility, considering the information about the security and occupancy state of the home and the information about the operation of the home received from the control server, said control server directing assistance to the home based on the transmitted information; and the step of selectively and establishing a communication channel between the home and a remote facility without manual intervention comprising the step of addressing a transmission of information about the security and occupancy state of the home differently
- the method for enabling security vigilant monitoring and communication further comprises the steps of: obtaining images of the various sections of the home; and transmitting the images of the various sections after an emergency and/or a break-through involving the home; determining when the home experiences a break-through, the step of obtaining images of the various sections of the home comprising the step of obtaining images including the image of an intruder of the home; and transmitting the images of the various sections just prior to the break-through once it has determined that the home has experienced a break-through.
- the step of determining at least one fire-property or characteristic of occupancy of the home comprises the step of determining any motion in the various sections of the home, whereby information about any motion of occupants in the various sections is transmitted as part of the information about the security and occupancy state of the home; and determining the number of occupants in the various sections, the number of occupants in the various sections being transmitted as part of the information about the security and occupancy state of the home.
- the step of determining the number of occupants in the home comprises the steps of receiving waves or radiation energy from all of the each locations in the various sections of the home and determining the number of occupants in the various sections from the received waves, energy or radiation, and arranging at least one heartbeat sensor and at least a body heat sensor in the various sections of the home to detect the presence of heartbeats and body heat in the home such that the number of occupants is determinable from the number of detected body heat and security is determinable by at least the heartbeats.
Abstract
Description
Claims (18)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/233,562 US10410504B2 (en) | 2005-12-08 | 2016-08-10 | System and method for interactive security |
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US72110305P | 2005-12-08 | 2005-12-08 | |
US11/634,535 US20070256105A1 (en) | 2005-12-08 | 2006-12-05 | Entertainment device configured for interactive detection and security vigilant monitoring in communication with a control server |
US14/645,448 US20150187192A1 (en) | 2005-12-08 | 2015-03-12 | System and method for interactive security |
US15/233,562 US10410504B2 (en) | 2005-12-08 | 2016-08-10 | System and method for interactive security |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/645,448 Continuation US20150187192A1 (en) | 2005-12-08 | 2015-03-12 | System and method for interactive security |
Publications (2)
Publication Number | Publication Date |
---|---|
US20160351043A1 US20160351043A1 (en) | 2016-12-01 |
US10410504B2 true US10410504B2 (en) | 2019-09-10 |
Family
ID=53482425
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/645,448 Abandoned US20150187192A1 (en) | 2005-12-08 | 2015-03-12 | System and method for interactive security |
US15/233,562 Active 2027-07-17 US10410504B2 (en) | 2005-12-08 | 2016-08-10 | System and method for interactive security |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/645,448 Abandoned US20150187192A1 (en) | 2005-12-08 | 2015-03-12 | System and method for interactive security |
Country Status (1)
Country | Link |
---|---|
US (2) | US20150187192A1 (en) |
Families Citing this family (30)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9467500B2 (en) | 2012-08-09 | 2016-10-11 | Rockwell Automation Technologies, Inc. | Remote industrial monitoring using a cloud infrastructure |
US9253054B2 (en) * | 2012-08-09 | 2016-02-02 | Rockwell Automation Technologies, Inc. | Remote industrial monitoring and analytics using a cloud infrastructure |
US10482759B2 (en) * | 2015-05-13 | 2019-11-19 | Tyco Safety Products Canada Ltd. | Identified presence detection in and around premises |
CN105551176A (en) * | 2015-07-29 | 2016-05-04 | 宇龙计算机通信科技(深圳)有限公司 | Environment monitor method and user terminal |
CN105607069A (en) * | 2015-09-11 | 2016-05-25 | 云南电网有限责任公司电力科学研究院 | Electric-power-equipment nondestructive testing platform based on ultrasonic wave and obstacle avoidance method thereof |
US9474042B1 (en) | 2015-09-16 | 2016-10-18 | Ivani, LLC | Detecting location within a network |
US10665284B2 (en) | 2015-09-16 | 2020-05-26 | Ivani, LLC | Detecting location within a network |
US10382893B1 (en) | 2015-09-16 | 2019-08-13 | Ivani, LLC | Building system control utilizing building occupancy |
US11533584B2 (en) * | 2015-09-16 | 2022-12-20 | Ivani, LLC | Blockchain systems and methods for confirming presence |
US10321270B2 (en) | 2015-09-16 | 2019-06-11 | Ivani, LLC | Reverse-beacon indoor positioning system using existing detection fields |
US11350238B2 (en) | 2015-09-16 | 2022-05-31 | Ivani, LLC | Systems and methods for detecting the presence of a user at a computer |
US10425702B2 (en) | 2015-09-30 | 2019-09-24 | Sensormatic Electronics, LLC | Sensor packs that are configured based on business application |
US10354332B2 (en) | 2015-09-30 | 2019-07-16 | Sensormatic Electronics, LLC | Sensor based system and method for drift analysis to predict equipment failure |
US11151654B2 (en) | 2015-09-30 | 2021-10-19 | Johnson Controls Tyco IP Holdings LLP | System and method for determining risk profile, adjusting insurance premiums and automatically collecting premiums based on sensor data |
US11436911B2 (en) | 2015-09-30 | 2022-09-06 | Johnson Controls Tyco IP Holdings LLP | Sensor based system and method for premises safety and operational profiling based on drift analysis |
US10902524B2 (en) | 2015-09-30 | 2021-01-26 | Sensormatic Electronics, LLC | Sensor based system and method for augmenting underwriting of insurance policies |
CN205263523U (en) * | 2015-11-27 | 2016-05-25 | 南宁富桂精密工业有限公司 | Intelligent home controller |
WO2017165166A1 (en) | 2016-03-21 | 2017-09-28 | Carrier Corporation | Intrusion security panel with remote assistance through simulated user interface |
US10552914B2 (en) | 2016-05-05 | 2020-02-04 | Sensormatic Electronics, LLC | Method and apparatus for evaluating risk based on sensor monitoring |
US10810676B2 (en) | 2016-06-06 | 2020-10-20 | Sensormatic Electronics, LLC | Method and apparatus for increasing the density of data surrounding an event |
US10019880B1 (en) | 2016-11-22 | 2018-07-10 | Brad Winters | Portable security system |
CN108241300B (en) * | 2016-12-26 | 2023-05-02 | 开利公司 | Device control for predetermined spatial regions |
US11037300B2 (en) | 2017-04-28 | 2021-06-15 | Cherry Labs, Inc. | Monitoring system |
US10802696B2 (en) * | 2019-01-10 | 2020-10-13 | Honeywell International Inc. | Controlling and monitoring a smoke control system |
US20210206492A1 (en) * | 2020-01-06 | 2021-07-08 | Qualcomm Incorporated | Techniques for identifying aerial vehicles in mobile networks |
US11882508B2 (en) * | 2020-03-23 | 2024-01-23 | Sap Se | Data processing system for smart devices |
CN111815895A (en) * | 2020-06-19 | 2020-10-23 | 安徽超清科技股份有限公司 | Campus safety wisdom linkage monitored control system |
NO346552B1 (en) * | 2020-10-16 | 2022-10-03 | Dimeq As | An Alarm Detection System |
CN113691556A (en) * | 2021-09-02 | 2021-11-23 | 朱刚 | Big data processing method and server applied to information protection detection |
US11863349B2 (en) * | 2021-09-02 | 2024-01-02 | Nile Global, Inc. | Methods and systems for network segmentation |
Citations (30)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4635124A (en) | 1985-11-26 | 1987-01-06 | Rca Corporation | Auxiliary focusing circuit for automatic focusing camera |
US5023901A (en) | 1988-08-22 | 1991-06-11 | Vorec Corporation | Surveillance system having a voice verification unit |
US6112103A (en) * | 1996-12-03 | 2000-08-29 | Puthuff; Steven H. | Personal communication device |
US20030048926A1 (en) | 2001-09-07 | 2003-03-13 | Takahiro Watanabe | Surveillance system, surveillance method and surveillance program |
US20030062997A1 (en) * | 1999-07-20 | 2003-04-03 | Naidoo Surendra N. | Distributed monitoring for a video security system |
US20030067542A1 (en) | 2000-10-13 | 2003-04-10 | Monroe David A. | Apparatus for and method of collecting and distributing event data to strategic security personnel and response vehicles |
US20030176798A1 (en) * | 2002-02-12 | 2003-09-18 | Simon Arnold Baruch | Method and device for detecting cardiac arrest and automatically alerting emergency personnel of wearer's location |
US20040113770A1 (en) * | 2002-07-11 | 2004-06-17 | Dietrich Falk | Monitoring system and monitoring method |
US6762686B1 (en) | 1999-05-21 | 2004-07-13 | Joseph A. Tabe | Interactive wireless home security detectors |
US20040143602A1 (en) * | 2002-10-18 | 2004-07-22 | Antonio Ruiz | Apparatus, system and method for automated and adaptive digital image/video surveillance for events and configurations using a rich multimedia relational database |
US20040233282A1 (en) * | 2003-05-22 | 2004-11-25 | Stavely Donald J. | Systems, apparatus, and methods for surveillance of an area |
US20050184870A1 (en) * | 2004-02-25 | 2005-08-25 | Dmatek, Ltd. | Method and apparatus for portable transmitting devices |
US20050225448A1 (en) * | 2003-06-19 | 2005-10-13 | Eran Schenker | Mobile health and life signs detector |
US6965294B1 (en) | 2002-02-28 | 2005-11-15 | Kimball International, Inc. | Workspace security system |
US6970183B1 (en) * | 2000-06-14 | 2005-11-29 | E-Watch, Inc. | Multimedia surveillance and monitoring system including network configuration |
US20050275528A1 (en) * | 2004-05-27 | 2005-12-15 | Lawrence Kates | Wireless sensor unit |
US20060022816A1 (en) * | 2004-07-30 | 2006-02-02 | Mitsuhiko Yukawa | Home security system |
US20060049940A1 (en) * | 2002-11-29 | 2006-03-09 | Kabushiki Kaisha Toshiba | Security system and moving robot |
US20060109341A1 (en) | 2002-08-15 | 2006-05-25 | Roke Manor Research Limited | Video motion anomaly detector |
US20060171453A1 (en) | 2005-01-04 | 2006-08-03 | Rohlfing Thomas R | Video surveillance system |
US20060214785A1 (en) * | 2004-03-21 | 2006-09-28 | Devaul Richard W | Distributed multi-nodal voice/data communication |
US20070103542A1 (en) | 2002-10-15 | 2007-05-10 | Revolutionary Concepts, Inc. | Video communication method for receiving person at entrance |
US20070256105A1 (en) | 2005-12-08 | 2007-11-01 | Tabe Joseph A | Entertainment device configured for interactive detection and security vigilant monitoring in communication with a control server |
US20070298772A1 (en) * | 2004-08-27 | 2007-12-27 | Owens Steve B | System and method for an interactive security system for a home |
US20080001734A1 (en) | 2003-02-03 | 2008-01-03 | Stilp Louis A | Portable telephone in a security network |
US20080117299A1 (en) | 2002-10-15 | 2008-05-22 | Revolutionary Concepts, Inc. | Communication and monitoring system |
US20080216765A1 (en) | 2004-07-15 | 2008-09-11 | Lawrence Kates | System and method for computer-controlled animal toy |
US7544941B2 (en) | 2004-11-26 | 2009-06-09 | Protectconnect, Inc. | Motion detector module |
US20110001812A1 (en) * | 2005-03-15 | 2011-01-06 | Chub International Holdings Limited | Context-Aware Alarm System |
US20120092156A1 (en) * | 2005-10-16 | 2012-04-19 | Bao Tran | Personal emergency response (per) system |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050027552A1 (en) * | 2003-04-11 | 2005-02-03 | Massanelli Joseph A. | Systems and methods for claim processing in a recovery audit |
-
2015
- 2015-03-12 US US14/645,448 patent/US20150187192A1/en not_active Abandoned
-
2016
- 2016-08-10 US US15/233,562 patent/US10410504B2/en active Active
Patent Citations (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4635124A (en) | 1985-11-26 | 1987-01-06 | Rca Corporation | Auxiliary focusing circuit for automatic focusing camera |
US5023901A (en) | 1988-08-22 | 1991-06-11 | Vorec Corporation | Surveillance system having a voice verification unit |
US6112103A (en) * | 1996-12-03 | 2000-08-29 | Puthuff; Steven H. | Personal communication device |
US6762686B1 (en) | 1999-05-21 | 2004-07-13 | Joseph A. Tabe | Interactive wireless home security detectors |
US20030062997A1 (en) * | 1999-07-20 | 2003-04-03 | Naidoo Surendra N. | Distributed monitoring for a video security system |
US6970183B1 (en) * | 2000-06-14 | 2005-11-29 | E-Watch, Inc. | Multimedia surveillance and monitoring system including network configuration |
US20030067542A1 (en) | 2000-10-13 | 2003-04-10 | Monroe David A. | Apparatus for and method of collecting and distributing event data to strategic security personnel and response vehicles |
US20030048926A1 (en) | 2001-09-07 | 2003-03-13 | Takahiro Watanabe | Surveillance system, surveillance method and surveillance program |
US20030176798A1 (en) * | 2002-02-12 | 2003-09-18 | Simon Arnold Baruch | Method and device for detecting cardiac arrest and automatically alerting emergency personnel of wearer's location |
US6965294B1 (en) | 2002-02-28 | 2005-11-15 | Kimball International, Inc. | Workspace security system |
US20040113770A1 (en) * | 2002-07-11 | 2004-06-17 | Dietrich Falk | Monitoring system and monitoring method |
US7864980B2 (en) | 2002-08-15 | 2011-01-04 | Roke Manor Research Limited | Video motion anomaly detector |
US20060109341A1 (en) | 2002-08-15 | 2006-05-25 | Roke Manor Research Limited | Video motion anomaly detector |
US20070103542A1 (en) | 2002-10-15 | 2007-05-10 | Revolutionary Concepts, Inc. | Video communication method for receiving person at entrance |
US20080117299A1 (en) | 2002-10-15 | 2008-05-22 | Revolutionary Concepts, Inc. | Communication and monitoring system |
US20040143602A1 (en) * | 2002-10-18 | 2004-07-22 | Antonio Ruiz | Apparatus, system and method for automated and adaptive digital image/video surveillance for events and configurations using a rich multimedia relational database |
US20060049940A1 (en) * | 2002-11-29 | 2006-03-09 | Kabushiki Kaisha Toshiba | Security system and moving robot |
US20080001734A1 (en) | 2003-02-03 | 2008-01-03 | Stilp Louis A | Portable telephone in a security network |
US20040233282A1 (en) * | 2003-05-22 | 2004-11-25 | Stavely Donald J. | Systems, apparatus, and methods for surveillance of an area |
US20050225448A1 (en) * | 2003-06-19 | 2005-10-13 | Eran Schenker | Mobile health and life signs detector |
US20050184870A1 (en) * | 2004-02-25 | 2005-08-25 | Dmatek, Ltd. | Method and apparatus for portable transmitting devices |
US20060214785A1 (en) * | 2004-03-21 | 2006-09-28 | Devaul Richard W | Distributed multi-nodal voice/data communication |
US20050275528A1 (en) * | 2004-05-27 | 2005-12-15 | Lawrence Kates | Wireless sensor unit |
US20080216765A1 (en) | 2004-07-15 | 2008-09-11 | Lawrence Kates | System and method for computer-controlled animal toy |
US20060022816A1 (en) * | 2004-07-30 | 2006-02-02 | Mitsuhiko Yukawa | Home security system |
US20070298772A1 (en) * | 2004-08-27 | 2007-12-27 | Owens Steve B | System and method for an interactive security system for a home |
US7544941B2 (en) | 2004-11-26 | 2009-06-09 | Protectconnect, Inc. | Motion detector module |
US20060171453A1 (en) | 2005-01-04 | 2006-08-03 | Rohlfing Thomas R | Video surveillance system |
US20110001812A1 (en) * | 2005-03-15 | 2011-01-06 | Chub International Holdings Limited | Context-Aware Alarm System |
US20120092156A1 (en) * | 2005-10-16 | 2012-04-19 | Bao Tran | Personal emergency response (per) system |
US20070256105A1 (en) | 2005-12-08 | 2007-11-01 | Tabe Joseph A | Entertainment device configured for interactive detection and security vigilant monitoring in communication with a control server |
Also Published As
Publication number | Publication date |
---|---|
US20150187192A1 (en) | 2015-07-02 |
US20160351043A1 (en) | 2016-12-01 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10410504B2 (en) | System and method for interactive security | |
US8417090B2 (en) | System and method for management of surveillance devices and surveillance footage | |
US20180040241A1 (en) | Automated camera response in a surveillance architecture | |
US9628286B1 (en) | Television receiver and home automation system and methods to associate data with nearby people | |
US9208665B2 (en) | Automated, remotely-verified alarm system with intrusion and video surveillance and digital video recording | |
JP5873031B2 (en) | Method, system, and computer program product for managing a controlled residential or non-residential environment | |
US9661276B2 (en) | Peer to peer surveillance architecture | |
CA2643610C (en) | System and method for remote data acquisition and distribution | |
US20070256105A1 (en) | Entertainment device configured for interactive detection and security vigilant monitoring in communication with a control server | |
US11335097B1 (en) | Sharing video footage from audio/video recording and communication devices | |
KR101220884B1 (en) | Multi-conrol system using smart phone | |
US10448086B2 (en) | Sharing video footage from audio/video recording and communication devices to smart TV devices | |
KR20040106964A (en) | Real time moving picture remote guard controling system | |
US20040008257A1 (en) | Monitoring service process using communication network | |
EP3629146A1 (en) | Monitoring of one or more audio/video collection devices | |
US11984006B2 (en) | Methods for monitoring security |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:COSTA VERDI, SERIES 63 OF ALLIED SECURITY TRUST I;REEL/FRAME:043736/0996Effective date: 20150324Owner name: COSTA VERDI, SERIES 63 OF ALLIED SECURITY TRUST I,Free format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:TABE, JOSEPH;REEL/FRAME:043736/0975Effective date: 20141208 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044695/0115Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |