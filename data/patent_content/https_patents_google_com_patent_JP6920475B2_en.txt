JP6920475B2 - Modify digital video content - Google Patents
Modify digital video content Download PDFInfo
- Publication number
- JP6920475B2 JP6920475B2 JP2019565935A JP2019565935A JP6920475B2 JP 6920475 B2 JP6920475 B2 JP 6920475B2 JP 2019565935 A JP2019565935 A JP 2019565935A JP 2019565935 A JP2019565935 A JP 2019565935A JP 6920475 B2 JP6920475 B2 JP 6920475B2
- Authority
- JP
- Japan
- Prior art keywords
- content
- digital video
- data processing
- processing system
- frames
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000012545 processing Methods 0.000 claims description 292
- 230000003068 static effect Effects 0.000 claims description 190
- 238000000034 method Methods 0.000 claims description 76
- 230000004044 response Effects 0.000 claims description 23
- 238000013475 authorization Methods 0.000 claims description 11
- 238000007477 logistic regression Methods 0.000 claims description 5
- 230000008569 process Effects 0.000 description 29
- 238000010801 machine learning Methods 0.000 description 26
- 238000004422 calculation algorithm Methods 0.000 description 22
- 230000000153 supplemental effect Effects 0.000 description 18
- 238000004891 communication Methods 0.000 description 17
- 238000001514 detection method Methods 0.000 description 15
- 230000009471 action Effects 0.000 description 14
- 238000004590 computer program Methods 0.000 description 11
- 238000009877 rendering Methods 0.000 description 9
- 230000008859 change Effects 0.000 description 6
- 230000003993 interaction Effects 0.000 description 6
- 230000005540 biological transmission Effects 0.000 description 5
- 238000010586 diagram Methods 0.000 description 5
- 230000000694 effects Effects 0.000 description 5
- 230000033001 locomotion Effects 0.000 description 5
- 238000011143 downstream manufacturing Methods 0.000 description 4
- 230000000670 limiting effect Effects 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000001902 propagating effect Effects 0.000 description 3
- 230000002829 reductive effect Effects 0.000 description 3
- 239000013589 supplement Substances 0.000 description 3
- 238000012360 testing method Methods 0.000 description 3
- 238000012546 transfer Methods 0.000 description 3
- 238000004458 analytical method Methods 0.000 description 2
- 238000003491 array Methods 0.000 description 2
- 238000013528 artificial neural network Methods 0.000 description 2
- 239000000872 buffer Substances 0.000 description 2
- 230000003139 buffering effect Effects 0.000 description 2
- 239000003086 colorant Substances 0.000 description 2
- 230000007717 exclusion Effects 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 238000003780 insertion Methods 0.000 description 2
- 230000037431 insertion Effects 0.000 description 2
- 230000002452 interceptive effect Effects 0.000 description 2
- 238000012417 linear regression Methods 0.000 description 2
- 238000007726 management method Methods 0.000 description 2
- 238000010295 mobile communication Methods 0.000 description 2
- 238000007781 pre-processing Methods 0.000 description 2
- 230000009467 reduction Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 230000001360 synchronised effect Effects 0.000 description 2
- 230000002123 temporal effect Effects 0.000 description 2
- IRLPACMLTUPBCL-KQYNXXCUSA-N 5'-adenylyl sulfate Chemical compound C1=NC=2C(N)=NC=NC=2N1[C@@H]1O[C@H](COP(O)(=O)OS(O)(=O)=O)[C@@H](O)[C@H]1O IRLPACMLTUPBCL-KQYNXXCUSA-N 0.000 description 1
- 230000002411 adverse Effects 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 238000006243 chemical reaction Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000001934 delay Effects 0.000 description 1
- 230000014509 gene expression Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000004807 localization Effects 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 238000012015 optical character recognition Methods 0.000 description 1
- 238000003909 pattern recognition Methods 0.000 description 1
- 230000002688 persistence Effects 0.000 description 1
- 230000002250 progressing effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000011273 social behavior Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000001502 supplementing effect Effects 0.000 description 1
- 238000012549 training Methods 0.000 description 1
- 239000002699 waste material Substances 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/23418—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving operations for analysing video streams, e.g. detecting features or characteristics
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11B—INFORMATION STORAGE BASED ON RELATIVE MOVEMENT BETWEEN RECORD CARRIER AND TRANSDUCER
- G11B27/00—Editing; Indexing; Addressing; Timing or synchronising; Monitoring; Measuring tape travel
- G11B27/10—Indexing; Addressing; Timing or synchronising; Measuring tape travel
- G11B27/34—Indicating arrangements
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/435—Processing of additional data, e.g. decrypting of additional data, reconstructing software from modules extracted from the transport stream
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/437—Interfacing the upstream path of the transmission network, e.g. for transmitting client requests to a VOD server
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/44016—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving splicing one content stream with another content stream, e.g. for substituting a video clip
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/47205—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for manipulating displayed content, e.g. interacting with MPEG-4 objects, editing locally
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/4722—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting additional data associated with the content
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/81—Monomedia components thereof
- H04N21/8126—Monomedia components thereof involving additional data, e.g. news, sports, stocks, weather forecasts
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/845—Structuring of content, e.g. decomposing content into time segments
- H04N21/8455—Structuring of content, e.g. decomposing content into time segments involving pointers to the content, e.g. pointers to the I-frames of the video stream
Description
本開示は、デジタルビデオコンテンツの修正に関する。 The present disclosure relates to modifications of digital video content.
たとえば、バナーコンテンツアイテムまたはインストリームコンテンツアイテム(プレロール要素、ポストロール要素、またはインタースティシャル要素と呼ばれることもある)を使用して、デジタルビデオコンテンツとともに補足コンテンツを表示することができる。バナーコンテンツアイテムは、限られた時間の間、補助コンテンツアイテムを(たとえば、多くの実装形態では不透明または部分的に不透明の背景とともに)デジタルビデオに重畳することを指し得る。インタースティシャルインストリームコンテンツアイテムは、限られた時間の間、デジタルビデオを中断し、この時間の間、補足コンテンツアイテムを表示することを指し得るし、同様に、プレロールコンテンツアイテムおよびポストロールコンテンツアイテムはそれぞれ、デジタルビデオの前および後に出現し得る。しかし、バナーコンテンツアイテムとインストリームコンテンツアイテムはどちらも、限られた時間の間、出現し、元のデジタルビデオを中断するかまたは少なくとも部分的に覆い隠す。さらに、バナーコンテンツアイテムとインストリームコンテンツアイテムを使用すると、サーバがデジタルビデオを送信し、次いで補足コンテンツアイテムを別個に送信するか、またはデジタルビデオを中断することによってレンダリング全体の持続時間を延ばし得るので、帯域幅利用度、メモリ利用度、およびプロセッサ利用度が高くなる場合がある。したがって、デジタルビデオコンテンツに対して補足コンテンツをより長い持続時間にわたってデジタルビデオを中断せずに提供し、同時に、計算リソース利用度を管理することは困難である場合がある。 For example, banner content items or in-stream content items (sometimes called pre-roll elements, post-roll elements, or interstitial elements) can be used to display supplemental content along with digital video content. Banner content items can refer to superimposing ancillary content items on a digital video (for example, with an opaque or partially opaque background in many implementations) for a limited amount of time. Interstitial in-stream content items can refer to interrupting a digital video for a limited time and displaying supplemental content items during this time, as well as pre-roll and post-roll content. Items can appear before and after the digital video, respectively. However, both banner content items and in-stream content items appear for a limited amount of time, interrupting or at least partially obscuring the original digital video. In addition, banner content items and in-stream content items allow the server to send the digital video and then send the supplemental content items separately, or interrupt the digital video to extend the overall duration of the rendering. , Bandwidth utilization, memory utilization, and processor utilization may be high. Therefore, it can be difficult to provide supplemental content to digital video content over a longer duration without interruption of the digital video, while at the same time managing computational resource utilization.
本開示は、デジタルマルチメディアコンテンツを組み合わせるシステムおよび方法を対象とする。デジタルビデオ処理では、視聴者に提供すべき単一のビデオストリーム内にデジタルビデオコンテンツの2つ以上のソースを組み合わせることが望ましい場合がある。たとえば、元のデジタルビデオコンテンツを補足デジタルビデオコンテンツによって修正することが望ましい場合がある。補足デジタルデータコンテンツは、動的に選択されることがあり、経時的に変化し、ならびに/または最終的なデジタルビデオコンテンツの様々な視聴者に対して異なることがある。このようにして、たとえば、元のデジタルビデオコンテンツを全体的に置き換える必要なしに最終的なデジタルビデオコンテンツを(たとえば、新鮮さ、ローカライゼーション、個人化などについて)修正することができる。 The present disclosure is directed to systems and methods that combine digital multimedia content. In digital video processing, it may be desirable to combine two or more sources of digital video content within a single video stream that should be provided to the viewer. For example, it may be desirable to modify the original digital video content with supplemental digital video content. Supplement Digital data content may be dynamically selected, change over time, and / or differ for different viewers of the final digital video content. In this way, for example, the final digital video content can be modified (eg, for freshness, localization, personalization, etc.) without having to replace the original digital video content entirely.
本明細書で説明する技法は、ビデオコンテンツをより滑らかに組み合わせることを可能にする。このことはさらに、補足コンテンツをより長い持続時間の間、ほとんどまたはまったく中断されずに提供し、一方コンピューティングリソース利用度を低減させるのを可能にする。たとえば、本解決策は、デジタルビデオを(内部メモリまたは外部ソースから)受信し、ビデオにおける静的部分を特定するようにビデオを前処理するシステムを含むことができる。静的部分は、デジタルビデオ内の複数のフレームにわたって同様なピクセルまたは一致するピクセルを有するデジタルビデオ内の空間領域によって画定することができる。このシステムは、特定された静的部分の特性に基づいてデジタルビデオ内に空間スロットおよび/または時間スロットを自動的に作成することができる。たとえば、システムは、特定された静的部分が所定の持続時間しきい値、サイズ、色、位置、またはその他の特性を満たす場合にスロットを作成することができる。システムは、デジタルビデオ再生にさらなるレイテンシまたは遅延を生じさせずに補足コンテンツアイテムについてのリアルタイムコンテンツ選択プロセスを実行するために、リアルタイムコンテンツ選択とレイテンシ低減との間で最適化するスロットに先立った再生中に時間オフセットを算出し、補足コンテンツアイテムを選択し選択された補足コンテンツアイテムを提供することができ、それによって、遅延またはラグを生じさせずに作成されたスロットにおいて補足コンテンツアイテムをマージまたはレンダリングすることができる。 The techniques described herein allow for a smoother combination of video content. This also makes it possible to provide supplemental content for longer durations with little or no interruption, while reducing computing resource utilization. For example, the solution can include a system that receives digital video (from internal memory or an external source) and preprocesses the video to identify static parts of the video. The static part can be defined by a spatial area in the digital video that has similar or matching pixels across multiple frames in the digital video. The system can automatically create spatial and / or time slots in digital video based on the characteristics of the identified static parts. For example, the system can create a slot if the identified static part meets a given duration threshold, size, color, position, or other characteristic. The system is playing prior to a slot that optimizes between real-time content selection and latency reduction to perform a real-time content selection process for supplemental content items without causing additional latency or delay in digital video playback. You can calculate the time offset to and select the supplementary content item to serve the selected supplementary content item, thereby merging or rendering the supplementary content item in the slot created without delay or lag. be able to.
システムは、空間スロットおよび/または時間スロットを特定し、時間オフセットを算出すると、デジタルビデオをタグ付けすることができる。たとえば、システムは、空間スロットおよび/または時間スロットならびに時間オフセットを指示するデジタルビデオのメタデータにタグを挿入することができる。タグは、クライアントデバイスに時間オフセットにおいてコンテンツについての要求を生成させる(たとえば、レンダリング時間または表示時間の前にコンテンツをプレフェッチする)命令をさらに与えることができる。コンテンツについての要求は、空間スロットおよび/または時間スロットのサイズまたは位置、またはリアルタイムコンテンツ選択を容易にする特性(たとえば、背景色、前景色、デジタルビデオまたはスロットに関連するキーワード)などの、タグ内に与えられるパラメータを含むことができる。 The system can tag the digital video by identifying the spatial and / or time slots and calculating the time offset. For example, the system can insert tags into digital video metadata that indicate spatial slots and / or time slots as well as time offsets. The tag can further give the client device an instruction to generate a request for the content at a time offset (eg, prefetch the content before the render or display time). Content requests are within tags, such as the size or location of spatial and / or time slots, or characteristics that facilitate real-time content selection (for example, background color, foreground color, digital video, or slot-related keywords). Can include the parameters given to.
システムは、デジタルビデオにタグ付けし、デジタルビデオをクライアントデバイスに提供することができる。クライアントデバイスはデジタルビデオを再生またはレンダリングすることができる。たとえば、クライアントデバイスによって実行されるアプリケーション(たとえば、ビデオプレーヤ、マルチメディアプレーヤ、アプリケーションプログラミングインターフェース、またはウェブブラウザ)はデジタルビデオを再生、表示、またはレンダリングすることができる。クライアントデバイスは、システムによって生成され挿入されるタグを含むメタデータを解析することができる。クライアントデバイスは、デジタルビデオのメタデータに埋め込まれたタグまたはトリガに応答して要求を生成し送信することができる。クライアントデバイスは要求をシステムに送信することができる。したがって、システムは、メタデータ内の時間オフセットに基づいてクライアントデバイスからコンテンツについての要求を受信することができる。システムは、コンテンツについての要求を受信したことに応答して、要求またはクライアントデバイスに関連するパラメータを使用してコンテンツ選択プロセスを実行することができる。システムは、コンテンツアイテムを選択すると、そのコンテンツアイテムをクライアントデバイスに提供し、クライアントデバイスにそのコンテンツアイテムをデジタルビデオ内のスロットにおいてレンダリングさせる。場合によっては、システムは、選択されたコンテンツアイテムを、コンテンツスロットを形成する静的部分に対応するフレームとマージすることができ、デジタルビデオのマージされたフレームをクライアントデバイスにストリーミング送出することができる。したがって、システムは、デジタルビデオ内の適切な静的部分を特定しそのビデオにタグ付けすることによってスロットを自動的に生成し、クライアントデバイスにそのスロットを再生する前の時間オフセットにおいてコンテンツについてのリアルタイム要求を送信させることによって、デジタルビデオを中断することも、ビデオ再生の持続時間を延長することも、またはデジタルビデオのアクティブな部分を妨害することもなしに没入型補足コンテンツを提供し、同時に補足コンテンツアイテムを提供しレンダリングする際の遅延またはレイテンシを低減させることができる。 The system can tag the digital video and deliver the digital video to the client device. The client device can play or render digital video. For example, an application run by a client device (eg, a video player, multimedia player, application programming interface, or web browser) can play, view, or render digital video. The client device can parse the metadata containing the tags generated and inserted by the system. Client devices can generate and send requests in response to tags or triggers embedded in digital video metadata. The client device can send the request to the system. Therefore, the system can receive requests for content from client devices based on the time offset in the metadata. In response to receiving a request for content, the system can perform a content selection process using parameters related to the request or client device. When the system selects a content item, it provides the content item to the client device and causes the client device to render the content item in a slot in the digital video. In some cases, the system can merge the selected content item with the frame corresponding to the static part that forms the content slot, and can stream the merged frame of the digital video to the client device. .. Therefore, the system automatically creates a slot by identifying the appropriate static part of the digital video and tagging the video, and real-time about the content at a time offset before playing the slot on the client device. By sending a request, it provides immersive supplemental content without interrupting the digital video, extending the duration of the video playback, or interfering with the active part of the digital video, and at the same time supplementing. Delays or latencies in serving and rendering content items can be reduced.
これらの態様および実装形態ならびに他の態様および実装形態について以下に詳しく説明する。上記の情報および以下の詳細な説明は、様々な態様および実装形態の説明例を含み、請求される態様および実装形態の性質および特徴を理解するための概要または枠組みを提供する。図面は、様々な態様および実装形態の例示およびさらなる理解を可能にし、本明細書に組み込まれ、本明細書の一部を構成する。 These aspects and implementation forms as well as other aspects and implementation forms will be described in detail below. The above information and the following detailed description will include explanatory examples of various aspects and implementations and will provide an overview or framework for understanding the nature and characteristics of the claimed aspects and implementations. The drawings allow for illustration and further understanding of various aspects and implementations, which are incorporated herein and constitute a portion of this specification.
本明細書で説明する主題の1つもしくは複数の実装形態についての詳細は添付の図面および以下の説明に記載される。この主題の他の特徴、態様、および利点は、説明、図面、および特許請求の範囲から明らかになろう。 Details of one or more implementations of the subject matter described herein are given in the accompanying drawings and in the following description. Other features, aspects, and advantages of this subject will become apparent from the description, drawings, and claims.
様々な図面における同じ参照番号および符号は同じ要素を示す。 The same reference numbers and symbols in different drawings indicate the same elements.
以下に、ネットワークを介したコンピューティングデバイスとコンテンツ選択インフラストラクチャとの間のデータ要求のバランスを取るための方法、装置、およびシステムに関する様々な概念、ならびにこの方法、装置、およびシステムの実装形態についてより詳細に説明する。上記で紹介され以下により詳しく説明する様々な概念は多数の方法のうちの任意の方法で実現されてもよい。 Below are various concepts about methods, devices, and systems for balancing data requirements between computing devices over networks and content selection infrastructure, as well as implementations of these methods, devices, and systems. This will be described in more detail. The various concepts introduced above and described in more detail below may be implemented in any of a number of methods.
本開示は、デジタルビデオの中断を低減または防止しながら、デジタルビデオコンテンツを組み合わせてより長い持続時間の間、補足コンテンツを提供し、同時にコンピューティングリソース利用度を低減させるシステムおよび方法を対象とする。たとえば、元のビデオコンテンツにはかかわらず限定された固定位置に重畳バナーとして設けられる補足ビデオコンテンツアイテムは、デジタルビデオのアクティブな部分もしくは重要な部分を妨害するかもしくは隠し、サーバにこのバナーコンテンツアイテム用の余分なデータを提供もしくは送信させることによって余分な帯域幅を使用させ、またはデジタルビデオの再生に遅延もしくはラグを生じさせることがある。この理由は、このバナーコンテンツアイテムに対応するデータパケットがデジタルビデオ用のデータパケットに優先されることがあるからである。さらに、インストリームに設けられるインタースティシャル補足コンテンツアイテムは、補足コンテンツアイテムに対応する持続時間の間、デジタルビデオの再生を停止し、それによってデジタルビデオの再生を中断し、デジタルビデオ全体の持続時間を延長し得る(したがって、追加のサーバリソースおよび帯域幅が必要となること、接続ソケットと対応するネットワークソケットが関連付けられることなどが生じる)。さらに、バナーコンテンツアイテムとインタースティシャルコンテンツアイテムはどちらも、全体的なユーザエクスペリエンスおよびデジタル再生グラフィカルユーザインターフェースに悪影響を与えることがある。 The present disclosure relates to systems and methods that combine digital video content to provide supplemental content for a longer duration while reducing or preventing digital video interruptions while reducing computing resource utilization. .. For example, a supplemental video content item that is provided as a superimposed banner in a limited fixed position regardless of the original video content interferes with or hides the active or important part of the digital video and causes this banner content item on the server. It may cause extra bandwidth to be used by providing or transmitting extra data for, or delay or lag the playback of digital video. The reason for this is that the data packet corresponding to this banner content item may take precedence over the data packet for digital video. In addition, the in-stream interstitial supplemental content item stops playing the digital video for the duration corresponding to the supplementary content item, thereby interrupting the playback of the digital video and the duration of the entire digital video. (Therefore, additional server resources and bandwidth may be required, connection sockets may be associated with corresponding network sockets, etc.). In addition, both banner and interstitial content items can adversely affect the overall user experience and digital playback graphical user interface.
本解決策のシステムおよび方法は、デジタルビデオの中断を低減または防止しながら、デジタルビデオを組み合わせてより長い持続時間の間、補足コンテンツを提供し、同時にコンピューティングリソース利用度を低減させることができる。本解決策のシステムおよび方法は、補足コンテンツをデジタルビデオに没入的に埋め込むことによってユーザの注目度を高めることができる。たとえば、本解決策のデータ処理システムは、デジタルビデオアップローダユーザインターフェースを介してデジタルビデオコンテンツアイテムを受信することができる。デジタルビデオコンテンツアイテムは複数のフレームを含むことができる。データ処理システムは、ビデオアップローダインターフェースをコンテンツパブリッシャデバイスに提供することができる。コンテンツパブリッシャデバイスは、デジタルビデオコンテンツアイテムをアップローダインターフェースを介してデータ処理システムに送信することができる。デジタルビデオコンテンツアイテムは、複数の連続するフレームで形成することができ、各フレームは画像を含むことができる。データ処理では、デジタルビデオを前処理して、デジタルビデオコンテンツアイテムがさらなるダウンストリーム処理のために所定の最小基準を満たすかどうかを決定する(たとえば、最低フレームレート、最低解像度、主題、またはビデオ符号化プロトコル)ことができる。データ処理システムは、デジタルビデオコンテンツアイテムのフレームを分析して、静的部分を有するフレームのサブセットを特定することができる。静的部分は、時間領域または時間窓(たとえば、ビデオの2つ以上のフレーム)にわたって一致するピクセルまたは同様のピクセルを有し、したがって、空間次元と時間次元の両方を有する空間領域によって画定することができる。データ処理システムは、特定された静的部分が、リアルタイムコンテンツ選択プロセスを介して補足コンテンツアイテムを挿入することのできるスロットとなる候補であると決定することができる。 The systems and methods of this solution can combine digital video to provide supplemental content for a longer duration while reducing or preventing interruptions in digital video, while reducing computing resource utilization. .. The systems and methods of this solution can increase user attention by immersively embedding supplemental content in digital video. For example, the data processing system of this solution can receive digital video content items via the digital video uploader user interface. Digital video content items can contain multiple frames. The data processing system can provide a video uploader interface to the content publisher device. The content publisher device can send digital video content items to the data processing system via the uploader interface. A digital video content item can be formed by a plurality of consecutive frames, each frame containing an image. Data processing preprocesses digital video to determine if a digital video content item meets certain minimum criteria for further downstream processing (eg, minimum frame rate, minimum resolution, subject matter, or video code). The conversion protocol) can be. The data processing system can analyze the frames of a digital video content item to identify a subset of frames that have static parts. The static part has matching pixels or similar pixels over a time domain or time window (eg, two or more frames of video), and is therefore defined by a spatial domain that has both spatial and temporal dimensions. Can be done. The data processing system can determine that the identified static part is a candidate for a slot into which a supplementary content item can be inserted via the real-time content selection process.
場合によっては、データ処理システムは、デジタルビデオにおける複数の候補スロットを特定することができる。データ処理システムは、機械学習モデルまたはアルゴリズムを利用して複数の候補スロットのうちの1つもしくは複数を選択することができる。たとえば、データ処理システムは、ロジスティック回帰、線形回帰、人工ニューラルネットワーク、または他の機械学習モデルもしくはアルゴリズムを使用して候補スロットを特定することができる。データ処理システムは、デジタルビデオをアップロードしたコンテンツパブリッシャデバイスに複数の候補スロットのうちの1つもしくは複数を選択させることができる。場合によっては、コンテンツパブリッシャデバイスは、1つもしくは複数の候補コンテンツスロットを放棄またはロックして、コンテンツアイテムがコンテンツスロットに挿入されるのを阻止することができる。 In some cases, the data processing system can identify multiple candidate slots in digital video. The data processing system can use a machine learning model or algorithm to select one or more of a plurality of candidate slots. For example, a data processing system can use logistic regression, linear regression, artificial neural networks, or other machine learning models or algorithms to identify candidate slots. The data processing system allows the content publisher device that uploaded the digital video to select one or more of the multiple candidate slots. In some cases, the content publisher device may abandon or lock one or more candidate content slots to prevent content items from being inserted into the content slots.
データ処理システムは、デジタルビデオコンテンツ用のコンテンツスロットを選択すると、デジタルビデオコンテンツアイテムのメタデータに挿入されるタグを生成することができる。タグは、スロットのサイズおよび位置などの、自動的に生成されたコンテンツスロットに関する情報を示すことができる。タグは、コンテンツについての要求を生成するために使用するか、または要求に応答してデータ処理システムによって実行されるリアルタイムコンテンツ選択プロセスを容易にするために使用することができるコンテンツスロットに関する追加の情報を含むことができる。たとえば、データ処理システムは、スロットに対応するフレームのサブセットに先立った再生中に時間オフセットを算出することができる。時間オフセットは、データ処理システムにコンテンツ選択プロセスを実行させコンテンツアイテムを選択させてデジタルビデオコンテンツアイテム内のコンテンツスロットに挿入するのを可能にするために、クライアントデバイスがコンテンツについての要求をいつ送信すべきかを示すことができる。 The data processing system can generate tags that are inserted into the metadata of digital video content items by selecting a content slot for digital video content. Tags can indicate information about automatically generated content slots, such as slot size and location. Tags are additional information about content slots that can be used to generate requests for content or to facilitate the real-time content selection process performed by the data processing system in response to requests. Can be included. For example, a data processing system can calculate a time offset during playback prior to a subset of frames corresponding to a slot. The time offset should allow the client device to send a request for content to allow the data processing system to perform the content selection process, select the content item, and insert it into the content slot within the digital video content item. Can show the content.
データ処理システムは、タグ付けされたデジタルビデオコンテンツをクライアントデバイスに提供してクライアントデバイスにデジタルビデオコンテンツを再生させることができる。クライアントデバイスは、デジタルビデオコンテンツをレンダリングし、メタデータを解析してタグおよび時間オフセットを特定し、次いでタグに応答してコンテンツについての要求を送信することができる。データ処理システムは、要求を受信したことに応答して、コンテンツアイテムを選択してクライアントデバイスに提供し、クライアントデバイスに、デジタルビデオ内の自動的に生成されたスロットにおいて選択されたコンテンツアイテムをレンダリングさせることができる。場合によっては、データ処理システムは、選択された補足コンテンツアイテムをデジタルビデオコンテンツとマージして対応するフレームをクライアントデバイスに提供するか、またはストリーミング送出して、クライアントデバイスに、デジタルビデオを補足コンテンツアイテムとともにレンダリングまたは再生させることができる。場合によっては、データ処理システムは、クライアントデバイスに、デジタルビデオコンテンツのメタデータ内の特定されたコンテンツスロットにおいて補足コンテンツアイテムをレンダリングさせるための命令とともに補足コンテンツアイテムを与えることができる。 The data processing system can provide the tagged digital video content to the client device so that the client device can play the digital video content. The client device can render the digital video content, analyze the metadata to identify the tag and time offset, and then send a request for the content in response to the tag. In response to receiving the request, the data processing system selects the content item and provides it to the client device, which renders the selected content item in the automatically generated slot in the digital video. Can be made to. In some cases, the data processing system may merge the selected supplemental content item with the digital video content and provide the corresponding frame to the client device, or stream it to the client device to supplement the digital video. Can be rendered or played with. In some cases, the data processing system may provide the client device with a supplementary content item with instructions for rendering the supplementary content item in the identified content slot in the metadata of the digital video content.
次に図1Aを参照すると、デジタルビデオを組み合わせるかまたは修正するシステム用のディスプレイインターフェースの実装形態が示されている。図1Aは、デジタルビデオコンテンツアイテム102を再生し、レンダリングし、表示するビデオプレーヤアプリケーション100を示す。ビデオプレーヤアプリケーション100は、クライアントコンピューティングデバイス(たとえば、図2に示すクライアントコンピューティングデバイス228)によって実行することができる。ビデオプレーヤアプリケーション100は、いくつかの実装形態では再生時に停止ボタンに切り替えることができる再生ボタン108、早送りボタン110、音量制御インターフェース112、クローズキャプショントグル116、および全画面ボタン118などの1つまたは複数のビデオコントロールを含むことができる。様々な実装形態にはこれよりも多いかまたは少ない数のコントロールを含めることができる。ビデオプレーヤアプリケーション100は進捗バー106を備えることができ、進捗バー106は、デジタルビデオコンテンツアイテムの進捗を視覚化するように構成されたグラフィカル制御要素とすることができる。ビデオプレーヤアプリケーション100は、ビデオの現在の進捗の指示114をビデオの全持続時間にわたって与えることができる(たとえば、現在の進捗時間は0.56秒であってもよく、全持続時間は6:23であってもよい)。
Next, with reference to Figure 1A, an implementation of a display interface for a system that combines or modifies digital video is shown. FIG. 1A shows a
ビデオプレーヤアプリケーション100は、デジタルビデオコンテンツ102に空間的に重畳されたバナーコンテンツスロット120を備えることができる。しかし、図示の例では、バナーコンテンツスロット120は、デジタルビデオコンテンツ102の一部を覆い隠すので、指定された部分において指定されたサイズ(たとえば、480x70)で限られた時間の間、ビデオの上部に重畳される。バナーコンテンツスロット120は、ビデオの一部を覆い隠してユーザを困惑させいらいらさせ、下方の覆い隠されたビデオの対応する部分をレンダリングする処理リソースを無駄にし得る。ビデオのアクティブな部分は、たとえば、復号のためにより微細なマクロブロックを必要とする頻繁に変化する画像または詳細な画像(たとえば、テキストまたは動き)に起因して、復号および/またはレンダリングにより多くの処理を必要とすることが多く、したがって、これらの部分をレンダリングし、その後オーバーレイバナーによって覆い隠すには、ユーザに視認可能な効果をもたらさないにもかかわらず処理リソースを使用する必要がある。
The
本解決策では、コンテンツパブリッシャがデジタルビデオコンテンツ102をデータ処理システム(たとえば、図2に示すデータ処理システム202)にアップロードすることができる。データ処理システム202は、デジタルビデオコンテンツを分析してブランクまたは静的スペース122を特定することができる。ブランクスペースまたは静的スペース122は、ピクセルが所定の持続時間またはいくつかのフレームにわたって実質的に変化しない場合があるデジタルビデオコンテンツの静的部分に対応することができる。たとえば、ピクセルは、前のフレーム内のピクセルまたは領域内のピクセルと比較して同じである場合もあり、またはある割合(たとえば、1%、2%、3%、4%、5%、10%など)未満変化する場合もある。ブランクスペースまたは静的スペース122は背景または他の領域を表すことができる。
The solution allows the content publisher to upload the
たとえば、デジタルビデオコンテンツはニュースプログラムとすることができる。ニュースプログラムは、デジタルビデオ102における概ね一定の領域内に位置するニュースキャスター104を表示することができる。ニュースキャスター104は、静的な色の周囲の境界、静止した家具またはニュースセットなどの、ブランクスペースまたは静的スペース122によって周りを囲むことができる。したがって、デジタルビデオコンテンツ102を作成したか、またはデジタルビデオコンテンツ102を表示するコンテンツパブリッシャは、デジタルビデオコンテンツ102をデータ処理システム202にアップロードすることができ、データ処理システム202はデジタルビデオコンテンツアイテム102を分析することができる。データ処理システム202は、デジタルビデオコンテンツ102を受信すると、前処理を実行することができ、この前処理は、ビデオを複数のフォーマットに変換すること、解像度を変更すること、またはフレームレートを変更することを含むことができる。
For example, digital video content can be a news program. The news program can display the
次に、図1Bを参照すると、デジタルビデオを組み合わせるかまたは修正するためのディスプレイインターフェースおよびシステムの実装形態の別の図が示されている。図1Bは、システム101の動作を示し、この動作の間に、コンテンツパブリッシャ232は、ステップ140においてデジタルビデオコンテンツ102をデータ処理システム202にアップロードする。データ処理システム202はデジタルビデオコンテンツ102を分析することができる。データ処理システム202は、デジタルビデオコンテンツ102を分析して、図1Aに示すブランクスペース122に位置する候補コンテンツスロット124、126、128、130、132、および134を特定する。データ処理システム202は、候補コンテンツスロットの自動検出を実行することができる。
Then, with reference to FIG. 1B, another diagram of the display interface and system implementation for combining or modifying digital video is shown. FIG. 1B shows the operation of the
データ処理システム202は、画像解釈、画像処理、機械学習、またはその他の技法を利用して候補コンテンツスロット124、126、128、130、132、および134を特定することができる。たとえば、データ処理システム202は、デジタルビデオコンテンツ102内の連続するフレームを比較してしきい値よりも小さいピクセルの変化を特定し、1つまたは複数の候補コンテンツスロットを特定することができる。データ処理システム202は、機械学習を使用して、履歴性能または予測モデルに基づいて複数の候補コンテンツスロットのうちの1つまたは複数を選択することができる。たとえば、データ処理システム202は、ロジスティック回帰を使用して複数のフレームを分析し、2つ以上のフレームにわたって一致するピクセルを有する空間領域によって画定される第1の静的部分を特定することができる。データ処理システム202は、機械学習モデルまたはアルゴリズムを利用して複数の候補スロットのうちの1つまたは複数を選択することができる。データ処理システムは、ロジスティック回帰、線形回帰、人工ニューラルネットワーク、または他の機械学習モデルもしくはアルゴリズムを使用して候補スロットを特定することができる。たとえば、データ処理システム202は、すでに選択されたコンテンツスロットに基づく性能フィードバックを受信し、正のフィードバックに関連する特徴および負のフィードバックに関連する特徴を特定することができる。データ処理システム202は、正のフィードバック、負のフィードバック、および関連する特徴を使用して機械学習モデルを生成または構築することができ、データ処理システム202はこの機械学習モデルを使用して、正のフィードバックをもたらすためにコンテンツスロットを配置することができるビデオ内の静的領域を予測することができる。データ処理システム202は、機械学習モデルをさらに使用して、予測される負の性能に基づいてコンテンツスロットを配置すべきではないビデオ内の静的領域を予測することができる。
The data processing system 202 can utilize image interpretation, image processing, machine learning, or other techniques to identify
データ処理システム202は、人(たとえば、人104)、モニュメント、移動体、または他の所定のオブジェクトを含むデジタルビデオ102の1つまたは複数の部分を削除することを含む自動スロット検出技法を利用することができる。この自動スロット検出技法は、隣接するフレームについてピクセルごとに比較して、デジタルビデオ102が静的な背景を有する共通部分を特定することを含むことができる。自動スロット検出アルゴリズムの出力によって、図1Bに示すように複数の候補スロット(たとえば、静的な背景を有するデジタルビデオ102の複数の時間および位置)を得ることができる。たとえば、コンテンツスロット126、130、および134は持続時間142において静的な背景を有することができ、一方、コンテンツスロット124、128、および132は持続時間144において静的な背景を有することができる。
The data processing system 202 utilizes an automatic slot detection technique that involves deleting one or more parts of a
データ処理システム202は、複数の候補コンテンツスロット124、126、128、132、および134を特定すると、自動スロット検出技法を使用して、人(たとえば、人104)の近くの候補コンテンツスロットまたは興味をひく他の部分もしくは他の詳細な部分(たとえば、テキスト、動きなど)のうちの1つまたは複数をフィルタ処理してディストラクションを低減させることができる。データ処理システム202は、最大/最小規則を適用し複数の候補スロットをより少ない候補コンテンツスロットに統合して下流側処理を単純化し、それによってダウンストリーム処理の効率を向上させる。たとえば、候補コンテンツスロット124、128、および132は、最大コンテンツスロット136に統合することができ、候補コンテンツスロット126、130、および134は最大コンテンツスロット138に統合することができる。
When the data processing system 202 identifies multiple
データ処理システム202は、自動スロット検出プロセスを使用して、統合されたコンテンツスロット(または領域)136および138を機械学習アルゴリズムに転送して最良のコンテンツスロットを選択することができる。機械学習アルゴリズムは、以下の信号を利用して最良のコンテンツスロットを選択することができる。i)ビデオを見るエンドユーザ-エンドユーザは、これらの種類のビデオコンテンツアイテムを拒否するオプションを有し、ビデオの特定のセットを拒否する場合、利用されたスロットが不良または非最適であると見なされることがあり、対応する信号は、拒否するユーザに基づいて不良スロット位置を示すことができる。ii)ビデオアップローダ-ビデオを提供するビデオアップローダまたはユーザは、あるスロットの示唆を拒絶するまた受け入れることができ、したがって、この信号は、コンテンツパブリッシャがスロット位置を受け入れるかどうかに基づく統計的により優れたスロット位置およびパブリッシャがスロット位置を拒絶したかどうかに基づく不良なスロット位置を示すことができる。iii)クラウドソーシング情報-機械学習アルゴリズムに対してグランドトゥルースデータを提供して、(正の信号および負の信号を介して)スロットにおけるコンテンツの良好な配置および不良な配置を明示的に特定することについて訓練するクラウドソーシング評価システム、iv)ビデオ補足コンテンツアイテムの効果-コンテンツスロットにおけるレンダリングされたコンテンツアイテムに関連する様々なメトリクス(たとえば、性能、選択、ユーザ注視時間短縮)を観測し、A/Bテスト、バケットテスト、またはスプリットランテストに基づいてスロット選択を向上させる。 The data processing system 202 can use an automatic slot detection process to transfer the integrated content slots (or regions) 136 and 138 to a machine learning algorithm to select the best content slot. The machine learning algorithm can select the best content slot using the following signals. i) End-users watching video-End-users have the option to reject these types of video content items, and if they reject a particular set of video, the slots utilized are considered bad or non-optimal. The corresponding signal can indicate a bad slot location based on the rejecting user. ii) Video Uploader-The video uploader or user providing the video can reject and accept the suggestion of a slot, so this signal is statistically better based on whether the content publisher accepts the slot location. It can indicate a bad slot position based on the slot position and whether the publisher rejected the slot position. iii) Crowdsourcing Information-Providing ground truth data to machine learning algorithms to explicitly identify good and bad placement of content in slots (via positive and negative signals). Crowdsourcing Rating System to Train About, iv) Video Supplement Content Item Effects-Observe and A / B various metrics related to rendered content items in content slots (eg performance, selection, reduced user gaze time) Improve slot selection based on testing, bucket testing, or split run testing.
したがって、データ処理システム202は、自動スロット検出技法、自動スロット検出プロセス、機械学習アルゴリズムを含むことができる自動スロット検出アルゴリズムを利用して、デジタルビデオ内の静的部分に対応するコンテンツスロットをデジタルビデオ内に自動的に作成することができる。データ処理システム202は、コンテンツスロットのフレーム(持続時間142または144の開始時点に対応するコンテンツスロットについてのデジタルビデオ内の開始時間、コンテンツスロットについての座標、周囲の色、背景色、またはコンテンツスロットの持続時間)を決定することができる。たとえば、データ処理システム202は、候補コンテンツスロットの各々についての持続時間を決定することができる。データ処理システム202は、候補コンテンツスロットの各々が同じ持続時間を有するか、または候補コンテンツスロットのうちの1つまたは複数がそれぞれに異なる持続時間(たとえば、持続時間142および146)を有すると決定することができる。データ処理システム202は、所定の持続時間値に基づくか、または候補コンテンツスロットの位置に対応するピクセルが静的なままである持続時間に基づいて候補コンテンツスロットの各々についての持続時間を設定することができる。データ処理システム202は、フレームごとに調べて、デジタルビデオ内の領域が静的であるかまたは同じコンテンツに対応する(たとえば、同じピクセル、動きなしなど)のはどこかを特定することができる。データ処理システムは、さらなる処理を適用していくつかの領域を、その領域が変化しないにもかかわらず除外することができ、たとえば、領域がすでにテキストを含む(または放送局のコールサインなどの少量のテキストを有する領域を除外するのを阻止するために所定のしきい値よりも多いテキストを含む)か、補足コンテンツアイテムの提供に寄与しない色を有するか、顔もしくは補足コンテンツアイテムによって重畳されない他の特定可能なオブジェクトを含む場合などにこの除外を行うことができる。
Therefore, the data processing system 202 utilizes an automatic slot detection algorithm that can include an automatic slot detection technique, an automatic slot detection process, and a machine learning algorithm to digitally video the content slot corresponding to the static part in the digital video. Can be created automatically within. The data processing system 202 describes the frame of the content slot (the start time in the digital video for the content slot corresponding to the start point of
場合によっては、データ処理システム202は、候補コンテンツスロットのコンテンツパブリッシャに指示を与えることができる。データ処理システム202は、コンテンツパブリッシャに候補コンテンツスロットのうちの1つまたは複数を受け入れるかまたは拒絶するように促すことができる。場合によっては、コンテンツパブリッシャは、デジタルビデオコンテンツアイテム上の追加の領域を候補コンテンツスロットとしてマーク付けすることができる。たとえば、コンテンツパブリッシャは、グラフィカルユーザインターフェースまたはその他の入力機構(たとえば、マウス、タッチインターフェース、または入力座標)を使用してボックス132を候補コンテンツスロットとしてマーク付けすることができる。
In some cases, the data processing system 202 can give instructions to the content publisher of the candidate content slot. The data processing system 202 can urge the content publisher to accept or reject one or more of the candidate content slots. In some cases, content publishers may mark additional areas on digital video content items as candidate content slots. For example, content publishers can use a graphical user interface or other input mechanism (eg, mouse, touch interface, or input coordinates) to
データ処理システム202は、候補コンテンツスロットのうちの1つまたは複数を選択することができる。データ処理システム202は、選択されたコンテンツスロットに関する情報をデジタルビデオにタグ付けすることができる。データ処理システム202は、デジタルビデオコンテンツ102のメタデータ内に情報を含めることができる。たとえば、データ処理システム202は、コンテンツスロットについての位置、背景色、サイズ、キーワード、または時間オフセットを含むことができる。この情報は以後のコンテンツ選択を容易にすることができる。たとえば、背景色は、コンテンツアイテムを選択するうえで有用である場合がある。その理由は、コンテンツアイテムは、所定の背景色上に表示されるアイテムとして選択されるか、または一方では、所定の背景色上に表示されるアイテムとして選択されない選好を示し得るコンテンツ選択基準を含むことができるからである。
The data processing system 202 can select one or more of the candidate content slots. The data processing system 202 can tag the digital video with information about the selected content slot. The data processing system 202 can include information in the metadata of the
図1Cを参照すると、デジタルビデオを組み合わせるかまたは修正するためのディスプレイインターフェースおよびシステムの実装形態の別の図が示されている。図1Cは、データ処理システム202がステップ150においてクライアントコンピューティングデバイス230にタグ付きデジタルビデオ102'を提供するシステム102の動作を示す。タグ付きデジタルビデオ102'は、選択されたコンテンツスロットに関する情報(たとえば、サイズ、位置、背景色など)および時間オフセットを含むことができる。時間オフセット160は、コンテンツスロットを含むフレームのサブセットに先立った再生中における時間を指すことができる。時間オフセット160は、所定の値とすることができ、またはデジタルビデオコンテンツ102'、クライアントコンピューティングデバイス230、またはクライアントコンピューティングデバイス230およびデータ処理システム202が通信するためのネットワーク(たとえば、図2に示すネットワーク205)に関連する特性に基づいて動的に決定することができる。この特性は、バッファリング量を含むことができる。たとえば、クライアントコンピューティングデバイス230上にバッファまたはプレロードされるビデオコンテンツが多いほど、時間オフセット160を大きくすることができ、それによって、補足コンテンツアイテムが確実に、データ処理システム202によって選択され、クライアントコンピューティングデバイス230上にプレロードまたはバッファされるデジタルビデオコンテンツとともにクライアントコンピューティングデバイス230に提供される。
Referencing Figure 1C shows another diagram of the display interface and system implementation for combining or modifying digital video. FIG. 1C shows the operation of
いくつかの実装形態では、クライアントコンピューティングデバイス230がタグ付きデジタルビデオ102'の再生を開始するとき、タグは、クライアントコンピューティングデバイス230に、デジタルビデオコンテンツアイテム102'またはクライアントコンピューティングデバイス230に関連する情報とともに要求152をデータ処理システム202に送らせるための命令を含むことができる。要求152は、タグ付きデジタルビデオ102'の識別子を含むことができる。要求152は、タグ付きデジタルビデオコンテンツアイテム102'に関連するメタデータを含むことができる。データ処理システム202は、クライアントコンピューティングデバイス230がタグ付きデジタルビデオコンテンツ102'の再生を開始したことに応じてクライアントコンピューティングデバイス230から要求152を受信する。データ処理システム202は、要求152に応じて、要求152を介して受信されたメタデータに基づくか、または要求152を介して受信された識別子を使用してデータベースにおいて検索を実行することに基づいて、デジタルビデオコンテンツアイテム102'が没入型コンテンツスロットに適しているかどうかを特定することができる。
In some embodiments, when the client computing device 230 begins playing the tagged digital video 102', the tag is associated with the client computing device 230, the digital video content item 102'or the client computing device 230. It can include instructions to send
いくつかの実装形態では、クライアントコンピューティングデバイス230は、タグ付きデジタルビデオ102'の再生を開始すると、タグ付きデジタルビデオ102'、デバイスコンテキスト、およびデバイスプロファイル情報とともに要求152を送信する。データ処理システム202は、タグ付きデジタルビデオ102'に関する前処理済みメタデータを取り込み、タグ付きデジタルビデオ102'が埋め込みコンテンツスロットエクスペリエンスに適していると決定することができる。前処理済みメタデータはまた、埋め込みコンテンツスロット164のタイミングおよび位置付けに関する情報を含むことができる。たとえば、データ処理システム202は、データ処理システム202に関連するメタデータをデータベース内に記憶することができる。メタデータには、タグ付きデジタルビデオ102'の識別子を割り当てることができる。クライアントコンピューティングデバイス230は、タグ付きデジタルビデオ102'の再生時に、データ処理システム202に識別子を提供することができ、データ処理システム202は、受信された識別子を使用して検索を実行し、タグ付きデジタルビデオ102'についてのメタデータを取り出すことができる。クライアントコンピューティングデバイス230は、データ処理システム202にメタデータを記憶することによって、タグ付きデジタルビデオコンテンツ102'についての識別子を送信するだけでよく、それによって帯域幅使用量が削減されレイテンシが低減される。
In some implementations, when the client computing device 230 begins playing the tagged digital video 102', it sends a
いくつかの実装形態では、データ処理システム202は、没入型コンテンツスロットをいつどこでデジタルビデオコンテンツアイテム102'に表示すべきかに関する情報を含む応答154をクライアントコンピューティングデバイス230に送信することができる。クライアントコンピューティングデバイス230またはクライアントコンピューティングデバイス230上で実行されるビデオアプリケーションプレーヤは、受信された情報を記憶することができる。
In some implementations, the data processing system 202 can send a
いくつかの実装形態では、ステップ150において提供されたタグ付きデジタルビデオコンテンツアイテム102'は、この情報をデジタルビデオ102'のメタデータに含めることができ、要求ステップ152および応答ステップ154を不要にすることができ、それによってリモートプロシージャコールの数、ネットワーク使用量、およびレイテンシが低減される。
In some embodiments, the tagged digital video content item 102'provided in step 150 can include this information in the metadata of the digital video 102', eliminating the need for
再生時にタグ付きデジタルビデオ102'が進行すると、ビデオは時間オフセット160の開始時点まで進むことができる。時間オフセット160まで進行すると、コンテンツについての要求156をトリガすることができる。時間オフセット160まで進行すると、ビデオアプリケーションプレーヤを実行するクライアントコンピューティングデバイス230に、コンテンツについての要求156をデータ処理システム202に送信させることができる。コンテンツについての要求156は、時間オフセット160に基づいて送信することができ、時間オフセット160は、コンテンツスロット持続時間162に先立った再生中に生じる。
If the tagged digital video 102'progresses during playback, the video can advance to the start of the time offset 160. Proceeding to the time offset 160 can trigger
データ処理システム202は、コンテンツについての要求156を受信し、コンテンツ選択プロセスを実行することができる。データ処理システム202は、要求に関連する情報を使用してコンテンツアイテム(たとえば、コンテンツスロットの背景色、タグ付きデジタルビデオ102'に関連するキーワード、コンテンツスロットの位置、コンテンツスロットのサイズ、クライアントコンピューティングデバイス230に関連するプロファイル情報など)を選択することができる。データ処理システム202は、選択されたコンテンツアイテムを送信158を介してクライアントコンピューティングデバイス230に提供することができる。データ処理システム202は、クライアントコンピューティングデバイス230に選択されたコンテンツアイテムのコンテンツスロット164への挿入、埋め込み、マージ、重畳、またはその他のレンダリングもしくは表示を行わせるための命令を、送信158時にさらに提供することができる。選択されたコンテンツアイテムは、コンテンツスロット持続時間162(たとえば、30秒、1分、2分、3分、またはそれよりも長い時間)についてのコンテンツスロット164においてレンダリングすることができる。
The data processing system 202 can receive the
選択されたコンテンツアイテムは、静的画像などの画像とすることができる。データ処理システム202は、選択されたコンテンツアイテムに対応する静的画像を含むデータファイルをクライアントコンピューティングデバイス230に提供することができる。クライアントコンピューティングデバイス230またはクライアントコンピューティングデバイス230上で実行されるビデオプレーヤアプリケーションは、デジタルビデオコンテンツのフレームをレンダリングする。クライアントコンピューティングデバイス上で実行されるビデオプレーヤアプリケーションがデジタルビデオコンテンツのフレームをレンダリングすると、ビデオアプリケーションプレーヤは、データファイルにおいて受信された選択されたコンテンツアイテムに対応する画像を、(たとえば、コンテンツスロット164における)指定された位置において指定された持続時間162の間ビデオフレームとマージすることができる。したがって、システムは、選択されたコンテンツアイテムを単一の送信158において静的画像として提供し、クライアントコンピューティングデバイス230に、デジタルビデオのそれぞれのフレームにおける特定の位置において指定された持続時間の間、コンテンツアイテムをレンダリングするよう命令することによって、ネットワーク利用度を低減させることができる。
The selected content item can be an image, such as a static image. The data processing system 202 can provide the client computing device 230 with a data file containing a static image corresponding to the selected content item. A video player application running on a client computing device 230 or client computing device 230 renders a frame of digital video content. When a video player application running on a client computing device renders a frame of digital video content, the video application player displays an image corresponding to the selected content item received in the data file (for example, content slot 164). Can be merged with a video frame at a specified position (in) for a specified duration of 162. Therefore, the system provides the selected content item as a static image in a
持続時間162が完了した後、クライアントコンピューティングデバイス230によって実行されるビデオプレーヤアプリケーションは、コンテンツスロット164なしでデジタルビデオ102'をレンダリングすることができる。ビデオプレーヤアプリケーションは、ビデオが進行するにつれてコンテンツアイテムを示すことができる次のコンテンツスロットを待機することができる。
After the duration 162 is complete, the video player application run by the client computing device 230 can render the digital video
次に図1Dを参照すると、デジタルビデオを組み合わせるかまたは修正するためのディスプレイインターフェースおよびシステムの実装形態の別の図が示されている。図1Dは、タグ付きデジタルビデオ120''が第2のコンテンツスロット174を含むシステム102の動作を示す。第2のコンテンツスロット174は、第2の時間オフセット176および第2のコンテンツスロット持続時間178に関連付けることができる。第2の時間オフセット176および第2のコンテンツスロット持続時間178は、時間オフセット160およびコンテンツスロット持続時間162に後続することができる。第2のコンテンツスロット174の位置およびサイズは、コンテンツスロット164の位置およびサイズと異ならせることができる。たとえば、コンテンツスロット164は、デジタルビデオコンテンツ102'の右上隅に位置させることができ、一方、第2のコンテンツスロット174は、タグ付きデジタルビデオコンテンツ120''の左下隅に位置させることができる。タグ付きデジタルビデオ102'および120''は、異なる表示時間における同じビデオとすることも、またはそれぞれに異なるビデオとすることもできる。タグ付きデジタルビデオ120''は、コンテンツスロット164とコンテンツスロット174の両方をそれぞれに異なる表示時間に含むことができる。場合によっては、コンテンツスロット164とコンテンツスロット174の両方が同じ時間または重複する時間に存在することができる。たとえば、第2の時間オフセット176はコンテンツスロット持続時間162の間に生じて、コンテンツスロット174において表示される第2のコンテンツアイテムを待ち行列に入れることができ、一方、レイテンシが最小限になるようにコンテンツスロット持続時間162の間にコンテンツアイテムが表示される。
Then, with reference to Figure 1D, another diagram of the display interface and system implementation for combining or modifying digital video is shown. FIG. 1D shows the operation of
クライアントコンピューティングデバイス230は、タグ付きデジタルビデオ120''が第2の時間オフセット176まで進行するかまたは再生が第2の時間オフセット176に達したことに応答して、コンテンツについての要求170を送信することができる。データ処理システム202は、第2のコンテンツアイテムを選択し、送信172の間に第2のコンテンツアイテムをクライアントコンピューティングデバイス230に提供することができる。データ処理システム202は、コンテンツ要求170に関連する情報を使用して第2のコンテンツアイテムを選択することができる。情報は、第2のコンテンツスロット174または周囲のピクセルに関連する情報(たとえば、サイズ、位置、背景色)を含むことができる。データ処理システム202は、コンテンツスロットに関連する特性をコンテンツアイテムに関連するコンテンツ選択基準と照合して、一致するコンテンツアイテムを選択することができる。
The client computing device 230 sends a request 170 for content in response to the tagged digital video 120'' progressing to the second time offset 176 or the playback reaching the second time offset 176. can do. The data processing system 202 can select a second content item and provide the second content item to the client computing device 230 during transmission 172. The data processing system 202 can select a second content item using the information associated with content request 170. The information can include information related to the
図2は、デジタルビデオを組み合わせるかまたは修正するための例示的なシステム200を示す。システム200は、コンテンツ選択インフラストラクチャを含むことができる。システム200は、コンテンツプロバイダコンピューティングデバイス234、コンテンツパブリッシャコンピューティングデバイス232、またはクライアントコンピューティングデバイス230のうちの1つまたは複数とネットワーク205を介して通信するデータ処理システム202を含むことができる。ネットワーク205は、インターネット、ローカルエリアネットワーク、ワイドエリアネットワーク、メトロエリアネットワーク、またはその他のエリアネットワークなどのコンピュータネットワーク、イントラネット、衛星ネットワーク、および音声もしくはデータモバイル電話網などの他の通信ネットワークを含むことができる。ネットワーク205は、ラップトップ、デスクトップ、タブレット、携帯情報端末、スマートフォン、ポータブルコンピュータ、またはモバイル通信デバイスなどの少なくとも1つのコンピューティングデバイス230上に表示することができる、ウェブページ、ウェブサイト、ドメイン名、またはユニフォームリソースロケータなどの情報リソースにアクセスするために使用することができる。たとえば、コンピューティングデバイス230のユーザは、少なくとも1つのウェブサイトオペレータまたはコンテンツパブリッシャ232によって提供されるウェブページにネットワーク205を介してアクセスすることができる。クライアントコンピューティングデバイス230のウェブブラウザ(たとえば、アプリケーション104)は、ウェブサイトオペレータまたはコンテンツパブリッシャ232のウェブサーバにアクセスしてウェブページをコンピューティングデバイス230のモニタ上に表示するために取り出すことができる。コンテンツパブリッシャデバイス232は、コンピューティングデバイス230上で実行されるアプリケーション104にコンテンツをレンダリングするよう命令することができる。ウェブサイトオペレータまたはコンテンツパブリッシャ232は一般に、ウェブページを運営するエンティティを含む。ウェブサイトオペレータまたはコンテンツパブリッシャ232は、ネットワーク205と通信してコンピューティングデバイス230がウェブページを利用できるようにする少なくとも1つのウェブページサーバを含む。データ処理システム202は、コンピューティングデバイス230上で実行されるアプリケーション104にコンテンツをレンダリングするよう命令することができる。
FIG. 2 shows an
ネットワーク205は、任意の種類または形態のネットワークであってもよく、ポイントツーポイントネットワーク、ブロードキャストネットワーク、ワイドエリアネットワーク、ローカルエリアネットワーク、電気通信網、データ通信ネットワーク、コンピュータネットワーク、ATM(非同期転送モード)ネットワーク、SONET(同期型光ネットワーク)ネットワーク、SDH(同期デジタルハイアラーキ)ネットワーク、ワイヤレスネットワーク、および回線ネットワークのうちのいずれかを含んでもよい。ネットワーク205は、赤外線チャネルまたは衛星帯域などのワイヤレスリンクを含んでもよい。ネットワーク205のトポロジーは、バスネットワークトポロジー、スターネットワークトポロジー、またはリングネットワークトポロジーを含んでもよい。ネットワークは、アドバンストモバイルフォンプロトコル(“AMPS”)、時分割多元接続(“TDMA”)、符号分割多元接続(“CDMA”)、グローバルシステムフォーモバイルコミュニケーションズ(“GSM(登録商標)”)、汎用パケット無線サービス(“GPRS”)、またはユニバーサルモバイルテレコミュニケ-ションズシステム(“UMTS”)を含む、モバイルデバイス間で通信するために使用される任意のプロトコルを使用するモバイル電話網を含んでもよい。様々な種類のデータがそれぞれに異なるプロトコルを介して送信されてもよく、または同じ種類のデータがそれぞれに異なるプロトコルを介して送信されてもよい。 The network 205 may be any type or form of network, including point-to-point networks, broadcast networks, wide area networks, local area networks, telecommunications networks, data communication networks, computer networks, and ATMs (asynchronous transfer modes). It may include any of a network, a SONET (synchronous optical network) network, an SDH (synchronous digital hierarchy) network, a wireless network, and a line network. Network 205 may include wireless links such as infrared channels or satellite bands. The topology of network 205 may include a bus network topology, a star network topology, or a ring network topology. The network includes Advanced Mobile Phone Protocol (“AMPS”), Time Division Multiple Access (“TDMA”), Code Division Multiple Access (“CDMA”), Global System for Mobile Communications (“GSM®”), General Packet Radio Service. It may include a mobile telephone network that uses any protocol used to communicate between mobile devices, including wireless services (“GPRS”), or Universal Mobile Telecommunication Systems (“UMTS”). Different types of data may be transmitted via different protocols, or the same type of data may be transmitted via different protocols.
システム200は、少なくとも1つのデータ処理システム202を含むことができる。データ処理システム202は、ネットワーク205を介して、たとえばコンピューティングデバイス230、ウェブサイトオペレータまたはコンテンツパブリッシャデバイス232(もしくはコンテンツパブリッシャ232)、および少なくとも1つのコンテンツプロバイダコンピューティングデバイス234(もしくはプロバイダデバイス234もしくはコンテンツプロバイダ234)と通信するためにプロセッサを有するコンピティングデバイスなどの少なくとも1つの論理デバイスを含むことができる。データ処理システム202は、少なくとも1つの計算リソース、サーバ、プロセッサ、またはメモリを含むことができる。たとえば、データ処理システム202は、少なくとも1つのデータセンター内に位置する複数の計算リソースまたはサーバを含むことができる。データ処理システム202は、論理的にグループ分けされた複数のサーバを含み、分散コンピューティング技法を容易にすることができる。サーバの論理グループは、データセンター、サーバファーム、またはマシンファームと呼ばれることもある。サーバはまた、地理的に分散させることができる。データセンターまたはマシンファームは、単一のエンティティとして管理されてもよく、またはマシンファームは複数のマシンファームを含むことができる。各マシンファーム内のサーバは、互いに異種とすることができ、サーバまたはマシンのうちの1つまたは複数は、1つもしくは複数の種類のオペレーティングシステムプラットフォームに従って動作することができる。
マシンファーム内のサーバは、関連する記憶システムとともに高密度ラックシステムに格納し、エンタープライズデータセンター内に配置することができる。たとえば、サーバをこのように統合すると、ローカライズされた高性能ネットワーク上にサーバおよび高性能記憶システムを位置させることによって、システム管理性、データセキュリティ、システムの物理的セキュリティ、およびシステム性能が向上する場合がある。サーバおよび記憶システムを集中させ高度システム管理ツールと結合することによって、サーバリソースをより効率的に使用することができる。 Servers in a machine farm can be stored in a high-density rack system with associated storage systems and placed in an enterprise data center. For example, if servers are integrated in this way to improve system manageability, data security, system physical security, and system performance by locating servers and high-performance storage systems on a localized, high-performance network. There is. By centralizing servers and storage systems and combining them with advanced system management tools, server resources can be used more efficiently.
データ処理システム202は、少なくとも1つの計算リソースまたはサーバを有するコンテンツ配置システムを含むことができる。データ処理システム202は、少なくとも1つのコンテンツセレクタ226を含むか、または少なくとも1つのコンテンツセレクタ226と通信することができる。コンテンツプロバイダデバイス234は、画像、電子ドキュメント、オンラインドキュメント、ウェブページ、またはテキストを含むことができる補足コンテンツアイテムなどのコンテンツを提供することができ、データ処理システム202は、コンテンツアイテムをクライアントコンピューティングデバイス230に提供することができる。 The data processing system 202 can include a content placement system having at least one computational resource or server. The data processing system 202 may include at least one content selector 226 or communicate with at least one content selector 226. The content provider device 234 can provide content such as a supplementary content item that can contain images, electronic documents, online documents, web pages, or text, and the data processing system 202 allows the content item to be a client computing device. Can be provided to 230.
データ処理システム202は、少なくとも1つのコンテンツセレクタ構成要素226、少なくとも1つのインターフェース228、少なくとも1つのビデオ信号プロセッサ204、少なくとも1つのデータリポジトリ216を含むか、それらにアクセスするか、それらと相互作用するか、または場合によってはそれらと通信することができる。少なくとも1つのビデオ信号プロセッサは、少なくとも1つのビデオプレプロセッサ206、スロット検出器208、オフセット計算器210、メタデータタグ付け器212、またはビデオエディタ214を含むか、それらにアクセスするか、それらと相互作用するか、または場合によってはそれらと通信することができる。少なくとも1つのデータリポジトリ216は、1つもしくは複数のデータ構造またはデータベース内に、しきい値218、メタデータ220、時間オフセット222、コンテンツデータ224、またはデジタルビデオ238を含めるかまたは記憶することができる。コンテンツデータ224は、たとえば、コンテンツキャンペーン情報、コンテンツグループ、コンテンツ選択基準、コンテンツアイテムオブジェクト、あるいはコンテンツ選択を容易にするためにコンテンツプロバイダ234によって提供されるかまたはデータ処理システム202によって取得もしくは決定されるその他の情報を含むことができる。
The data processing system 202 includes, accesses, or interacts with at least one content selector component 226, at least one interface 228, at least one video signal processor 204, and at least one data repository 216. Or, in some cases, you can communicate with them. At least one video signal processor includes, accesses, or interacts with at least one video preprocessor 206, slot detector 208, offset
ビデオ信号プロセッサ204、ビデオプレプロセッサ206、スロット検出器208、オフセット計算器210、メタデータタグ付け器212、ビデオエディタ214、インターフェース228、またはコンテンツセレクタ226の各々は、少なくとも1つの処理ユニット、またはデータリポジトリ216と通信するように構成されたプログラム可能な論理アレイエンジンもしくはモジュールなどの他の論理デバイスを含むことができる。ビデオ信号プロセッサ204、ビデオプレプロセッサ206、スロット検出器208、オフセット計算器210、メタデータタグ付け器212、ビデオエディタ214、インターフェース228、またはコンテンツセレクタ226は、別個の構成要素とすることも、単一の構成要素とすることも、またはデータ処理システム202の一部とすることもできる。データ処理システム202およびその構成要素は、1つもしくは複数のプロセッサ、論理デバイス、または回路などのハードウェア要素を含むことができる。
Each of the video signal processor 204, the video preprocessor 206, the slot detector 208, the offset
データ処理システム202は、複数のコンピューティングデバイス230に関連する匿名コンピュータネットワークアクティビティ情報を取得することができる。コンピューティングデバイス230のユーザは、データ処理システム202がユーザのコンピューティングデバイス230に対応するネットワークアクティビティ情報を取得するのを肯定的に認可することができる。たとえば、データ処理システム202は、1つまたは複数の種類のネットワークアクティビティ情報を取得するための同意をコンピューティングデバイス230のユーザに促すことができる。コンピューティングデバイス230のユーザのIDは匿名のままとすることができ、コンピューティングデバイス230は、一意の識別子(たとえば、データ処理システムまたはコンピューティングデバイスのユーザによって提供されるユーザまたはコンピューティングデバイスについての一意の識別子)に関連付けられてもよい。データ処理システムは、各観測を対応する一意の識別子に関連付けることができる。 The data processing system 202 can acquire anonymous computer network activity information related to the plurality of computing devices 230. The user of the computing device 230 can positively authorize the data processing system 202 to acquire the network activity information corresponding to the user's computing device 230. For example, the data processing system 202 may prompt the user of the computing device 230 to consent to obtain one or more types of network activity information. The identity of the user of the computing device 230 can remain anonymous, and the computing device 230 has a unique identifier (for example, for a user or computing device provided by a user of a data processing system or computing device. It may be associated with a unique identifier). The data processing system can associate each observation with a corresponding unique identifier.
データ処理システム202は、ネットワーキングインターフェース、通信ポート、入出力ポート、または1つまたは複数の入力テキストボックス、ボタン、ドロップダウンメニュー、ウィジェット、またはその他のユーザインターフェース要素を含むグラフィカルユーザインターフェースなどのインターフェースを含むか、そのようなインターフェースを実行するか、またはそのようなインターフェース228と通信することができる。データ処理システム202は、コンテンツプロバイダデバイス234上のレンダリングのためのグラフィカルユーザインターフェースを構成することができる。データ処理システム202は、コンテンツ選択プロセスを容易にするかまたはコンテンツ選択プロセスを確立するパラメータまたはその他の情報をグラフィカルユーザインターフェースを介して受信することができる。 The data processing system 202 includes a networking interface, a communication port, an input / output port, or an interface such as a graphical user interface that includes one or more input text boxes, buttons, drop-down menus, widgets, or other user interface elements. Or you can perform such an interface or communicate with such an interface 228. The data processing system 202 can configure a graphical user interface for rendering on the content provider device 234. The data processing system 202 can receive parameters or other information via a graphical user interface that facilitates the content selection process or establishes the content selection process.
データ処理システムのインターフェース228は、グラフィカルユーザインターフェースを含むことができる。インターフェース228は、コンテンツパブリッシャ232がデジタルビデオをアップロードするのを可能にすることができる。インターフェース228は、コンテンツパブリッシャが、デジタルビデオ用の候補コンテンツスロット(たとえば、図1Bに示す候補コンテンツスロット)としてのマークボックスなどの追加の入力を提供するのを可能にすることができる。データ処理システム202のインターフェース228は、コンテンツパブリッシャデバイス232から受信されたデータパケットを、ビデオ信号プロセッサ204またはデータリポジトリ216などのデータ処理システム202の1つまたは複数の構成要素に転送またはルーティングすることができる。
Interface 228 of the data processing system can include a graphical user interface. Interface 228 can allow
インターフェース228は、クライアントコンピューティングデバイス230に通信可能に結合された1つもしくは複数の入出力デバイスを介して入力された情報もしくは命令を受信するか、ネットワーク205を介してデータパケットを受信するか、またはネットワーク205を介してデータを送信するためのネットワークインターフェース、ユーザインターフェース、入出力インターフェース、通信ポート、バス、またはその他のソフトウェアもしくはハードウェアを含むことができる。インターフェース228は、グラフィカルユーザインターフェース、マルチタッチインターフェース、ジェスチャーベースインターフェース、オーディオベースインターフェース、または音声ベースインターフェースを含むことができる。 Interface 228 receives information or instructions entered through one or more I / O devices communicatively coupled to client computing device 230, or receives data packets over network 205. Alternatively, it may include a network interface, user interface, input / output interface, communication port, bus, or other software or hardware for transmitting data over network 205. Interface 228 can include a graphical user interface, a multi-touch interface, a gesture-based interface, an audio-based interface, or a voice-based interface.
インターフェース228は、コンテンツプロバイダデバイス234、コンテンツパブリッシャデバイス232、またはデータ処理システム202にデータパケットまたは情報を提供し、コンテンツプロバイダデバイス234、コンテンツパブリッシャデバイス232、またはデータ処理システム202からデータパケットまたは情報を受信することができる。
Interface 228 provides data packets or information to content provider device 234,
インターフェース228は、1つまたは複数の入力テキストボックス、ボタン、ドロップダウンメニュー、ウィジェット、またはその他のユーザインターフェース要素を含むグラフィカルユーザインターフェースを含むか、グラフィカルユーザインターフェースを実行するか、またはグラフィカルユーザインターフェースと通信することができる。データ処理システム202は、グラフィカルユーザインターフェースをコンテンツプロバイダデバイス234、コンテンツパブリッシャデバイス232、またはクライアントコンピューティングデバイス230上でのレンダリング向けに構成することができる。データ処理システム202は、コンピューティングデバイス230のインターフェース228を介して、コンテンツ選択プロセスを容易にするパラメータまたはその他の情報を受信することができる。インターフェース228は、クライアントコンピューティングデバイス230の1つまたは複数の構成要素から受信されたデータパケットをデータ処理システム202、コンテンツパブリッシャデバイス234、またはコンテンツパブリッシャ232の構成要素に転送またはルーティングすることができる。
Interface 228 includes a graphical user interface that includes one or more input text boxes, buttons, drop-down menus, widgets, or other user interface elements, performs a graphical user interface, or communicates with the graphical user interface. can do. The data processing system 202 can configure the graphical user interface for rendering on the content provider device 234, the
コンテンツパブリッシャ232はデジタルビデオを提供することができる。コンテンツパブリッシャ232はデジタルビデオを作成することができる。コンテンツパブリッシャ232は、マルチメディアコンテンツを作成または提供することができる。たとえば、コンテンツパブリッシャは、ニュースプログラム、ドキュメンタリー、ショー、映画、ビデオクリップ、またはその他のコンテンツを作成することができる。コンテンツパブリッシャ232は、デジタルビデオをデータ処理システム202に送信またはアップロードすることができ、それによってデータ処理システム202は、デジタルビデオをクライアントコンピューティングデバイス230上で再生できるようにクライアントコンピューティングデバイス230にストリーミング送出または提供することができる。
データ処理システム202はまた、インターフェース228を介してコンテンツプロバイダデバイス234と通信することができる。たとえば、データ処理システム202のインターフェース228は、コンテンツプロバイダデバイス234から受信されたデータパケットを、コンテンツセレクタ構成要素226またはデータリポジトリ216などのデータ処理システム202の1つまたは複数の構成要素に転送またはルーティングすることができる。データ処理システム202は、コンテンツプロバイダデバイス234、コンテンツパブリッシャデバイス216、またはコンピューティングデバイス230にデータパケットまたは情報を提供し、コンテンツプロバイダデバイス234、コンテンツパブリッシャデバイス216、またはコンピューティングデバイス230からデータパケットまたは情報を受信するためのネットワークインターフェース、ユーザインターフェース、入出力インターフェース、通信ポート、バス、またはその他のソフトウェアもしくはハードウェアを含むことができる。 The data processing system 202 can also communicate with the content provider device 234 via interface 228. For example, interface 228 of data processing system 202 forwards or routes data packets received from content provider device 234 to one or more components of data processing system 202, such as content selector component 226 or data repository 216. can do. The data processing system 202 provides the data packet or information to the content provider device 234, the content publisher device 216, or the computing device 230, and the data packet or information from the content provider device 234, the content publisher device 216, or the computing device 230. Can include network interfaces, user interfaces, input / output interfaces, communication ports, buses, or other software or hardware for receiving data.
コンテンツプロバイダデバイス234は、データ処理システム202によって選択される1つまたは複数のコンテンツアイテムオブジェクトを提供することができる。データ処理システム202は、コンテンツグループについて指定されたバジェット、コンテンツスケジュール、最大ビッド、キーワード、およびその他の選択基準と一致するコンテンツ配置機会(たとえば、自動的に作成されるコンテンツスロット164または174)が利用可能になったときにコンテンツアイテムオブジェクトを選択することができる。テキストコンテンツアイテム、画像コンテンツアイテム、ビデオコンテンツアイテム、オーディオコンテンツアイテム、マルチメディアコンテンツアイテム、コールコンテンツアイテム、コンテンツアイテムリンク、インタースティシャルコンテンツアイテム、またはバナーコンテンツアイテムなどの様々な種類のコンテンツアイテムオブジェクトをコンテンツグループに含めることができる。
Content provider device 234 may provide one or more content item objects selected by the data processing system 202. Data processing system 202 utilizes content placement opportunities (eg, automatically created
クライアントコンピューティングデバイス230は、ビデオプレーヤアプリケーション236を含むか、ビデオプレーヤアプリケーション236を実行するか、またはビデオプレーヤアプリケーション236と通信することができる。ビデオプレーヤアプリケーション236は、ハードウェアまたはソフトウェア構成要素を含むかまたは利用することができる。ビデオプレーヤアプリケーション236は、たとえば、ウェブブラウザ、モバイルアプリケーション、またはメディアプレーヤを含むことができる。ビデオプレーヤアプリケーション236は、デジタルビデオ、映画、または音楽などのマルチメディアファイルを再生するコンピュータプログラムを含むことができる。ビデオプレーヤアプリケーション236は、デジタルビデオを圧縮または展開することができる1つまたは複数のビデオコーデックを含むように構成することができる。ビデオコーデックは、圧縮フォーマットのビデオを、クライアントコンピューティングデバイス230に通信可能に結合された表示デバイスを介してレンダリングまたは表示できるように生フォーマットに変換することができる。ビデオコーデックは、たとえばMPEG-2を含むことができ、MPEG-2は、ピクチャおよび関連するオーディオ情報を動かすコーディングについての規格を指す。 The client computing device 230 can include the video player application 236, run the video player application 236, or communicate with the video player application 236. Video player application 236 may include or utilize hardware or software components. The video player application 236 can include, for example, a web browser, a mobile application, or a media player. The video player application 236 can include a computer program that plays multimedia files such as digital video, movies, or music. The video player application 236 can be configured to include one or more video codecs capable of compressing or decompressing digital video. The video codec can convert compressed format video to raw format so that it can be rendered or displayed via a display device communicatively coupled to the client computing device 230. Video codecs can include, for example, MPEG-2, which refers to a standard for coding that drives pictures and related audio information.
クライアントコンピューティングデバイス230は、1つもしくは複数のインターフェースを含むことができ、これらのインターフェースは同じ種類であってもよく、またはそれぞれに異なる種類であってもよい。インターフェースは、クライアントコンピューティングデバイス230に通信可能に結合された1つもしくは複数の入出力デバイスを介して入力された情報もしくは命令を受信するか、ネットワーク205を介してデータパケットを受信するか、またはネットワーク205を介してデータを送信するためのネットワークインターフェース、ユーザインターフェース、入出力インターフェース、通信ポート、バス、またはその他のソフトウェアもしくはハードウェアを含むことができる。インターフェース202は、グラフィカルユーザインターフェース、マルチタッチインターフェース、ジェスチャーベースインターフェース、オーディオベースインターフェース、または音声ベースインターフェースを含むことができる。インターフェースは、位置センサー(たとえば、地球測位システム、ワイヤレス送信、短距離ワイヤレス通信、近距離通信など)、加速度計、ジャイロスコープ、周囲光センサー、動き検出器、周囲音センサー、周囲温度センサーなどのセンサーを含むか、これらのセンサーと相互作用することができる。インターフェース202は、クライアントコンピューティングデバイス230の1つまたは複数の構成要素が互いに相互作用するのを可能にすることができる。 The client computing device 230 may include one or more interfaces, which may be of the same type or of different types. The interface either receives information or instructions entered through one or more I / O devices communicatively coupled to the client computing device 230, receives data packets over network 205, or receives data packets. It can include network interfaces, user interfaces, input / output interfaces, communication ports, buses, or other software or hardware for transmitting data over network 205. Interface 202 can include a graphical user interface, a multi-touch interface, a gesture-based interface, an audio-based interface, or a voice-based interface. Interfaces include position sensors (eg, earth positioning systems, wireless transmission, short-range wireless communication, short-range communication, etc.), accelerometers, gyroscopes, ambient light sensors, motion detectors, ambient sound sensors, ambient temperature sensors, etc. Can include or interact with these sensors. Interface 202 can allow one or more components of the client computing device 230 to interact with each other.
クライアントコンピューティングデバイス230は、クライアントデバイス上で実行されるアプリケーション236を介して表示されるコンテンツについての要求を送信することができる。この要求は、データ処理システム202による(たとえば、コンテンツセレクタ構成要素226による)コンテンツ選択を容易にするための情報を含むことができる。コンピューティングデバイス230上で動作するアプリケーション236は、要求を生成し、クライアントコンピューティングデバイス230に、要求をデータ処理システム202に送信するよう命令することができる。アプリケーション236は、指示イベント、相互作用イベント、またはトリガイベントに応答して要求を生成することができる。たとえば、アプリケーション236は、デジタルビデオ内のトリガまたはタグがアプリケーション236によって再生またはレンダリングされたことに応答して要求を生成することができる。要求は、コンテンツ選択基準、選好、コンテンツスロットのサイズ、コンテンツスロットの幅、コンテンツスロットの位置、ディスプレイのサイズ、クライアントコンピューティングデバイス230の種類(たとえば、モバイルデバイス、デスクトップ、タブレットコンピューティングデバイス)、デジタルコンテンツの種類(たとえば、静的、動的、画像、テキスト、ビデオ、オーディオ)、背景色、前景色などのデジタルコンテンツの選択を容易にする情報を含むことができるか、またはそのような情報に関連付けることができる。 The client computing device 230 can send a request for the content displayed through the application 236 running on the client device. This request can include information to facilitate content selection by the data processing system 202 (eg, by content selector component 226). The application 236 running on the computing device 230 can generate a request and instruct the client computing device 230 to send the request to the data processing system 202. Application 236 can generate a request in response to an instruction event, interaction event, or trigger event. For example, application 236 can generate a request in response to a trigger or tag in a digital video being played or rendered by application 236. The requirements are content selection criteria, preferences, content slot size, content slot width, content slot location, display size, client computing device 230 types (eg mobile devices, desktops, tablet computing devices), digital. Can include or include information that facilitates the selection of digital content such as content type (eg static, dynamic, image, text, video, audio), background color, foreground color, etc. Can be associated.
データ処理システム202は、キーワードに基づいて、リアルタイムコンテンツ選択プロセスを介してコンテンツアイテムを受信し選択するためにコンテンツセレクタ構成要素226を含むか、コンテンツセレクタ構成要素226を実行するか、または場合によってはコンテンツセレクタ構成要素226と通信することができる。コンテンツ選択プロセスは、サードパーティコンテンツプロバイダ214によって提供されるスポンサー付きコンテンツアイテムオブジェクトを選択することを指すか、そのようなスポンサー付きコンテンツアイテムオブジェクトを選択することを含むことができる。リアルタイムコンテンツ選択プロセスは、複数のコンテンツプロバイダによって提供されるコンテンツアイテムが、1つまたは複数のコンテンツアイテムを選択してコンピューティングデバイス230に提供するために解析、処理、加重、または照合されるサービスを含むことができる。コンテンツセレクタ構成要素226は、コンテンツ選択プロセスをリアルタイムに実行することができる。コンテンツ選択プロセスをリアルタイムに実行することは、コンテンツについての要求がクライアントコンピューティングデバイス230を介して受信されたことに応答してコンテンツ選択プロセスを実行することを指すことができる。リアルタイムコンテンツ選択プロセスは、要求を受信する時間間隔(たとえば、5秒、10秒、20秒、30秒、1分、2分、3分、5分、10分、または20分)内に実行する(たとえば、開始または完了する)ことができる。リアルタイムコンテンツ選択プロセスは、クライアントコンピューティングデバイス230との通信セッションの間に実行するか、または通信セッションが終了した後の時間間隔内に実行することができる。
Data processing system 202 includes content selector component 226, executes content selector component 226, or in some cases, to receive and select content items through a real-time content selection process based on keywords. It can communicate with the content selector component 226. The content selection process may refer to selecting sponsored content item objects provided by the third
たとえば、データ処理システム202は、コンテンツアイテムオブジェクトを選択するように設計、構築、もしくは構成されるか、または選択するように動作可能なコンテンツセレクタ構成要素226を含むことができる。データ処理システム202は、表示されるコンテンツアイテムを選択するために、キーワードを使用して照合技法に基づいて一致するコンテンツアイテムを選択することができる。候補コンテンツアイテムは、候補コンテンツアイテムの主題を示すメタデータを含んでもよく、その場合、コンテンツセレクタ構成要素226は、メタデータを処理して、候補コンテンツアイテムの主題が入力されたキーワードに対応するかどうかを決定してもよい。 For example, the data processing system 202 may include a content selector component 226 that is designed, constructed, or configured to select a content item object, or can be operated to select it. The data processing system 202 can use keywords to select matching content items based on matching techniques in order to select the displayed content items. The Candidate Content Item may include metadata indicating the subject of the Candidate Content Item, in which case the Content Selector Component 226 processes the metadata to accommodate the keywords entered in the Subject of the Candidate Content Item. You may decide whether or not.
コンテンツセレクタ構成要素226は、デジタルビデオ内のコンテンツスロットに関連する特性またはメタデータに基づいてコンテンツアイテムを選択することができる。データ処理システム202(たとえば、ビデオ信号プロセッサ204)は、デジタルビデオを分析して、コンテンツスロット、ならびにコンテンツセレクタ構成要素226がコンテンツスロット用のコンテンツアイテムを選択するのを容易にすることのできるコンテンツスロットに関連する特性を自動的に検出することができる。コンテンツスロットの特性は、たとえば、コンテンツスロットのサイズ、コンテンツスロットの位置、コンテンツスロットの持続時間、コンテンツスロットの背景色、コンテンツスロットの周囲のオブジェクトタイプ、コンテンツスロットに近接する人、デジタルビデオの主題、デジタルビデオに関連するキーワード、デジタルビデオ上に表示されるテキストなどを含むことができる。 Content selector component 226 can select content items based on the characteristics or metadata associated with the content slot in the digital video. A data processing system 202 (eg, a video signal processor 204) can analyze digital video to facilitate content slots, as well as content selector component 226 to select content items for content slots. The characteristics related to can be detected automatically. Content slot characteristics include, for example, content slot size, content slot location, content slot duration, content slot background color, object types around the content slot, people close to the content slot, digital video themes, etc. It can include keywords related to digital video, text displayed on digital video, and so on.
たとえば、データ処理システム202は、コンテンツスロットにおいてレンダリングされるコンテンツについての要求を含む1つまたは複数のデータパケットをコンピューティングデバイス230から受信することができる。コンテンツスロットは、コンピューティングデバイス230によって実行されるビデオプレーヤアプリケーション236を介して電子ディスプレイハードウェアによって表示することができる。データ処理システム202は(たとえば、コンテンツセレクタ構成要素226を介して)、要求を受信したことに応じて、リアルタイムコンテンツ選択プロセスを実行し、1つまたは複数のデータパケットに基づいて複数のコンテンツを特定することができる。コンテンツセレクタ構成要素226は、1つまたは複数のデータパケットによって搬送または指示される一致する1つまたは複数の基準をコンテンツプロバイダ234によって提供される1つまたは複数のコンテンツ選択基準と照合することに基づいて複数のコンテンツアイテムを特定することができる。1つまたは複数のデータパケットによって指示される基準は、コンテンツアイテムをレンダリングさせるコンテンツスロットに関する情報、アプリケーション104に関連する情報、ウェブページに関する情報、またはコンピューティングデバイス230に関連する情報を含むことができる。
For example, the data processing system 202 may receive one or more data packets from the computing device 230 containing requests for content rendered in the content slot. Content slots can be viewed by electronic display hardware via video player application 236 run by computing device 230. The data processing system 202 (for example, via the content selector component 226) performs a real-time content selection process in response to a request to identify multiple contents based on one or more data packets. can do. Content selector component 226 is based on matching one or more matching criteria carried or directed by one or more data packets against one or more content selection criteria provided by content provider 234. Can identify multiple content items. Criteria dictated by one or more data packets can include information about the content slot that renders the content item, information about the
データ処理システム202は、コンテンツパブリッシャ232によって提供されるデジタルビデオを分析し、デジタルビデオ内のスロットを検出し、デジタルビデオにメタデータをタグ付けするように設計され構築されたビデオ信号プロセッサ204を含むことができる。ビデオ信号プロセッサ204は、1つまたは複数のハードウェアもしくはソフトウェア構成要素、モジュール、または要素を含むことができる。ビデオ信号プロセッサ204はビデオプレプロセッサ206を含むことができる。ビデオプレプロセッサ206は、コンテンツパブリッシャ232によってアップロードされるデジタルビデオを受信し、デジタルビデオの初期分析を実行することができる。ビデオプレプロセッサ206は、アップロードされたデジタルビデオのフォーマットを特定することができる。ビデオプレプロセッサ206は、アップロードされたデジタルビデオを1つまたは複数の追加のビデオフォーマットに変換することができる。たとえば、ビデオプレプロセッサ206は、アップロードされたデジタルビデオを第1のフォーマットから、様々な種類のクライアントコンピューティングデバイス230上で再生するのに適した1つまたは複数の追加のフォーマットに変換することができる。ビデオプレプロセッサ206は、クライアントコンピューティングデバイス230によるレンダリングまたは再生効率を向上させるためのフォーマットを選択することができる。ビデオプレプロセッサ206は、帯域幅利用度を低減させるためにデジタルビデオのデータファイルサイズを縮小するフォーマットを選択することができる。ビデオプレプロセッサ206は、解像度(たとえば、互いに積層された480本のラインで構成され、各ラインが852ピクセル幅である480p、各々が1280ピクセル幅である720本のラインで構成される720pなど)またはフレームレート(たとえば、毎秒フレーム数“fps”は、動画表示において連続する画像またはフレームが表示される頻度を指すことができる)を変更することによって、アップロードされたデジタルビデオを変換または修正することができる。
The data processing system 202 includes a video signal processor 204 designed and built to analyze the digital video provided by the
ビデオプレプロセッサ206は、アップロードされたデジタルビデオがデータリポジトリ216内にすでに存在するかどうかを決定し、重複排除プロセスを実行してデータリポジトリ216内のストレージ消費量を削減することができる。ビデオプレプロセッサ206は、アップロードされたデジタルビデオの識別子をデジタルビデオデータ構造238にすでに記憶されたデジタルビデオの識別子と比較することができる。ビデオプレプロセッサ206は、アップロードされたデジタルビデオの識別子を使用してデジタルビデオデータ構造238における検索を実行することができる。ビデオプレプロセッサ206は、検索を介して一致を特定したことに応じて、識別子に対応するすでに記憶されたデジタルビデオのうちの1つを維持するか、それともすでに記憶されたデジタルビデオを新たにアップロードされたデジタルビデオで置き換えることを決定することができる。ビデオプレプロセッサ206は、元のデジタルビデオを維持するか、それともデジタルビデオの品質(たとえば、フレームレートもしくは解像度)、ファイルサイズ、またはコンテンツパブリッシャ232の証明書などのデジタルビデオに関連する特性に基づいて元のデジタルビデオを置き換えることを決定することができる。たとえば、ビデオプレプロセッサ206は、より高い品質のデジタルビデオ(たとえば、より高い解像度またはより高いフレームレート)を維持することを決定することができる。別の例では、ビデオプレプロセッサ206は、デジタルビデオをコピーした可能性があるコンテンツパブリッシャ232ではなく、デジタルビデオを作成したコンテンツパブリッシャ232などの、認可されたコンテンツパブリッシャ232によって提供されるデジタルビデオを維持することを決定することができる。
The video preprocessor 206 can determine if the uploaded digital video already exists in the data repository 216 and perform a deduplication process to reduce the storage consumption in the data repository 216. The video preprocessor 206 can compare the uploaded digital video identifier with the digital video identifier already stored in the digital
ビデオプレプロセッサ206は、アップロードされたデジタルビデオの特性を決定して、アップロードされたデジタルビデオが没入型コンテンツスロット検出に適しているかどうかを決定することができる。特性は、たとえば、フレームレート、解像度、データファイルサイズ、トピック、デジタルビデオの種類、ジャンル、またはビデオ作成日付を含むことができる。たとえば、ビデオプレプロセッサ206は、アップロードされたデジタルビデオのフレームを最小フレームレートしきい値と比較することができる。フレームレートが最小フレームレートしきい値以上である場合、ビデオプレプロセッサ206は、アップロードされたデジタルビデオが十分なフレームレートを有すると決定することができる。しかし、フレームレートが最小フレームレートしきい値未満である場合、ビデオプレプロセッサ206はデジタルビデオをロックして没入型コンテンツスロットの挿入を阻止することができる。 The video preprocessor 206 can determine the characteristics of the uploaded digital video to determine if the uploaded digital video is suitable for immersive content slot detection. Characteristics can include, for example, frame rate, resolution, data file size, topic, digital video type, genre, or video creation date. For example, the video preprocessor 206 can compare the frames of the uploaded digital video with the minimum frame rate threshold. If the frame rate is greater than or equal to the minimum frame rate threshold, the video preprocessor 206 can determine that the uploaded digital video has a sufficient frame rate. However, if the frame rate is less than the minimum frame rate threshold, the video preprocessor 206 can lock the digital video to prevent the insertion of immersive content slots.
場合によっては、ビデオプレプロセッサ206は、アップロードされたデジタルビデオが自動的に検出されたコンテンツスロットによってタグ付けされていると決定することができる。ビデオプレプロセッサ206は、アップロードされたデジタルビデオのメタデータを解析してタグ付けされたコンテンツスロットまたはトリガを検出することができる。ビデオプレプロセッサは、アップロードされたデジタルビデオがコンテンツスロットによってタグ付けされていないと決定した場合、ビデオプレプロセッサ206はアップロードされたデジタルビデオをスロット検出器208に提供することができる。ビデオプレプロセッサ206は、アップロードされたデジタルビデオに、コンテンツスロットを示すタグまたはメタデータがないと決定したことに応じて、スロット検出器208に、アップロードされたデジタルビデオを自動的に分析し、スロット検出技法を使用して1つまたは複数のコンテンツスロットを特定または検出するよう命令することができる。場合によっては、ビデオプレプロセッサ206は、アップロードされたデジタルビデオがコンテンツスロットおよびトリガによってすでにタグ付けされていることを検出し得るが、デジタルビデオを再分析してコンテンツスロットを検出することを決定してもよい。 In some cases, the video preprocessor 206 can determine that the uploaded digital video is tagged with an automatically detected content slot. The video preprocessor 206 can analyze the uploaded digital video metadata to detect tagged content slots or triggers. If the video preprocessor determines that the uploaded digital video is not tagged by the content slot, the video preprocessor 206 may provide the uploaded digital video to the slot detector 208. When the video preprocessor 206 determines that the uploaded digital video does not have a tag or metadata indicating the content slot, the slot detector 208 automatically analyzes the uploaded digital video and slots. Discovery techniques can be used to instruct one or more content slots to be identified or discovered. In some cases, the video preprocessor 206 may detect that the uploaded digital video is already tagged with the content slot and trigger, but decides to reanalyze the digital video to detect the content slot. You may.
ビデオ信号プロセッサ204は、デジタルビデオを分析してコンテンツスロットを検出するように設計され構築されたスロット検出器208を含むことができる。スロット検出器208は、上述のようなスロット検出プロセス、技法、またはアルゴリズムを含むように構成することができる。たとえば、スロット検出器208は、1つもしくは複数のフレーム内のテキストを特定するための光学文字認識エンジン、1つもしくは複数のフレーム内の顔の有無を特定するための顔認識システム、1つもしくは複数のフレーム内または1つもしくは複数のフレーム間の同一のピクセルの領域を特定するためのピクセル比較器、あるいは潜在的なコンテンツスロットを検出するための任意の他の種類または形態のシステムを備えてもよい。スロット検出器208は、スロット検出プロセスを使用して1つまたは複数のコンテンツスロットを検出すると、機械学習モデルを使用して、検出された1つまたは複数のコンテンツスロットから少なくとも1つのコンテンツスロットを選択することができる。 The video signal processor 204 can include a slot detector 208 designed and constructed to analyze digital video to detect content slots. The slot detector 208 can be configured to include the slot detection process, technique, or algorithm as described above. For example, slot detector 208 is an optical character recognition engine for identifying text in one or more frames, a face recognition system for identifying the presence or absence of faces in one or more frames, one or more. Equipped with a pixel comparator to identify areas of the same pixel within multiple frames or between one or more frames, or any other type or form of system for detecting potential content slots. May be good. When slot detector 208 detects one or more content slots using the slot detection process, it uses a machine learning model to select at least one content slot from the detected content slots. can do.
アップロードされたデジタルビデオは複数のフレームを含むことができる。たとえば、アップロードされたデジタルビデオの持続時間が6分23秒であり、フレームレートが24fpsである場合、アップロードされたデジタルビデオ内のフレームの総数は9192フレームとすることができる。スロット検出器208は、9192個のフレームを分析して静的部分を有する連続するフレームの第1のサブセットを特定することができる。静的部分は、連続するフレームのサブセットにわたって一致するピクセルを含む空間領域によって画定することができる。たとえば、図1Bに示すように、スロット検出器208は、デジタルビデオ102内の9192個のフレームを分析して静的領域124、126、128、130、132、および134を特定することができる。
The uploaded digital video can contain multiple frames. For example, if the uploaded digital video has a duration of 6 minutes and 23 seconds and the frame rate is 24 fps, the total number of frames in the uploaded digital video can be 9192 frames. Slot detector 208 can analyze 9192 frames to identify the first subset of contiguous frames with static parts. The static part can be defined by a spatial area containing matching pixels over a subset of consecutive frames. For example, as shown in FIG. 1B, slot detector 208 can analyze 9192 frames in
場合によっては、スロット検出器208は、必ずしも9192個のフレームのすべてを分析しないことを決定することができる。その代わりに、スロット検出器208は、コンピューティングリソース利用度を低減させ効率を向上させるために、デジタルビデオの開始時点またはデジタルビデオの終了時点などの、ビデオ内のある時間間隔ではコンテンツスロットを生成しないように構成することができる。たとえば、スロット検出器208は、デジタルビデオの最初の30秒およびデジタルビデオの最後の30秒に没入型コンテンツスロットを配置することを阻止することができる。したがって、スロット検出器は、最初の30秒におけるフレーム(たとえば、最初の720個のフレーム)または最後の30秒におけるフレーム(たとえば、最後の720個のフレーム)を分析しないことを決定し、それによって合計で9192個のフレームのうちの1440個のフレームの分析を阻止し、コンピューティングリソース消費量を15%削減することができる。 In some cases, slot detector 208 may decide not to analyze all of the 9192 frames. Instead, slot detector 208 generates content slots at certain time intervals in the video, such as at the start of the digital video or at the end of the digital video, in order to reduce computing resource utilization and improve efficiency. It can be configured not to. For example, slot detector 208 can prevent the placement of immersive content slots in the first 30 seconds of digital video and the last 30 seconds of digital video. Therefore, the slot detector decides not to analyze the frames in the first 30 seconds (eg, the first 720 frames) or the frames in the last 30 seconds (eg, the last 720 frames), thereby. It can block the analysis of 1440 frames out of a total of 9192 frames and reduce computing resource consumption by 15%.
スロット検出器208はまず、様々なスロット位置を検出することができる。それを行うために、スロット検出器208は、ビデオにおける、コンテンツスロットによって上書きされることもまたは置き換えられることもない人、モニュメント、またはその他のオブジェクトを有する部分を削除することができる。スロット検出器208は、画像解釈アルゴリズムを使用して、ビデオ内の人、モニュメント、または他の変更不能なオブジェクトなどの所定の形状またはオブジェクトに対応するピクセルを特定することができる。画像解釈アルゴリズムは、画像内に人がいることを特定するか、または画像内のあるオブジェクトを特定することができるデジタル画像処理技法を含むことができる。画像解釈アルゴリズムは、パターン認識、デジタルジオメトリ、信号処理を使用して画像内に人がいることを特定するか、または画像内のあるオブジェクトがあることを特定することができる。 The slot detector 208 can first detect various slot positions. To do so, slot detector 208 can remove parts of the video that have people, monuments, or other objects that are neither overwritten nor replaced by content slots. Slot detector 208 can use image interpretation algorithms to identify pixels in a video that correspond to a given shape or object, such as a person, monument, or other immutable object. Image interpretation algorithms can include digital image processing techniques that can identify a person in an image or identify an object in an image. Image interpretation algorithms can use pattern recognition, digital geometry, and signal processing to identify a person in an image, or to identify an object in an image.
スロット検出器208は、人またはオブジェクトを特定すると、画像における人またはオブジェクトの位置を決定することができる。スロット検出器208は、人またはオブジェクトを含むフレームをさらに特定することができる。スロット検出器208は次いで、フレームにおける人またはオブジェクトを含む領域をコンテンツスロットの候補から除外することができる。場合によっては、上書きされることもまたは置き換えられることもない人またはオブジェクトは、フレームの比較的大きい(たとえば、70%、80%、90%、95%、またはそれらを超える大きさの)領域を包含してもよい。フレームから人またはオブジェクトを削除した後、残りの利用可能な領域が最小スロットサイズ未満である場合、スロット検出器208は、そのフレームを検討対象から除外することができ、それによってダウンストリーム処理におけるコンピューティングリソース利用度を低減させる。図1Aに示すように、スロット検出器208は、人104を特定し、次いでデジタルビデオ102における人104を含まないブランクスペース122を特定することができる。
When the slot detector 208 identifies a person or object, it can determine the position of the person or object in the image. Slot detector 208 can further identify frames containing people or objects. The slot detector 208 can then exclude the area of the frame containing the person or object from the candidate content slots. In some cases, a person or object that is neither overwritten nor replaced may cover a relatively large area of the frame (eg, 70%, 80%, 90%, 95%, or larger). It may be included. After removing a person or object from a frame, if the remaining available space is less than the minimum slot size, slot detector 208 can exclude the frame from consideration, thereby computing in downstream processing. Reduce the utilization of computing resources. As shown in FIG. 1A, the slot detector 208 can identify the
スロット検出器208は、上書きされない人またはオブジェクトを削除し、コンテンツスロット用の十分な残り領域を含むフレームを特定した後、フレームを分析して、第1の静的部分を有する複数のフレームから連続するフレームの第1のサブセットを特定することができる。第1の静的部分は、2つ以上のフレームにわたって一致するピクセルを有する空間領域によって画定することができる。たとえば、スロット検出器208は、互いに隣接するフレームについてピクセルごとに比較して、デジタルビデオが静的な背景を有する共通部分または静的領域を特定することができる。スロット検出器208は、この技法を使用して、ビデオにおける静的な背景または領域を含むそれぞれに異なる時間および位置に対応する複数の静的領域を特定することができる。たとえば、このアルゴリズムを使用するスロット検出器208は、図1Bに示す候補コンテンツスロット124、126、128、130、132、および134を特定することができる。別の例では、スロット検出器208は領域136および138を静的領域として特定することができる。
The slot detector 208 removes the non-overwritten person or object, identifies the frame that contains enough space for the content slot, and then analyzes the frame to contiguously from multiple frames with the first static part. You can identify the first subset of frames you want to play. The first static part can be defined by a spatial region with matching pixels over two or more frames. For example, slot detector 208 can compare adjacent frames pixel by pixel to identify intersections or areas where digital video has a static background. Slot detector 208 can use this technique to identify multiple static regions, each corresponding to a different time and position, including a static background or region in the video. For example, slot detector 208 using this algorithm can identify
場合によっては、スロット検出器208は、候補コンテンツスロットを削除するか、または特定された候補スロットのサイズを調整してデジタルビデオ内の人104またはその他のオブジェクトに対するディストラクションまたは干渉を低減させることができる。たとえば、スロット検出器208は、人104の近くのエッジまたはその他の変化する部分を平滑化することができ、それによって図1Bに示すようにより小さい候補コンテンツスロット132および134が得られる。
In some cases, slot detector 208 may remove candidate content slots or adjust the size of identified candidate slots to reduce distortion or interference with
スロット検出器208は、候補コンテンツスロットまたは静的領域(たとえば、136および138または124、126、128、130、132、および134)を特定すると、静的領域を機械学習アルゴリズムに入力して、静的領域をソートまたはランク付けしてコンテンツスロットを選択することができる。機械学習アルゴリズムは、様々な信号を使用して静的領域をソートすることができる。たとえば、第1の信号は、デジタルビデオの履歴ビューからのフィードバックに基づくことができる。大部分のユーザが候補コンテンツスロット124についての補足コンテンツアイテムを受信することを拒否したが、大部分のユーザが候補コンテンツスロット126についての補足コンテンツアイテムを受信することを許可した場合、機械学習モデルは、コンテンツスロット126をコンテンツスロット124よりも上位にスコアリングまたはランク付けすべきであると決定することができる。
When slot detector 208 identifies a candidate content slot or static region (eg, 136 and 138 or 124, 126, 128, 130, 132, and 134), it inputs the static region into the machine learning algorithm and statically Content slots can be selected by sorting or ranking the target area. Machine learning algorithms can use various signals to sort static regions. For example, the first signal can be based on feedback from a digital video history view. If most users refuse to receive supplementary content items for
第2の信号は、コンテンツパブリッシャデバイス232からのフィードバックに基づくことができる。コンテンツパブリッシャデバイス232がデジタルビデオをアップロードすると、データ処理システム202は、候補コンテンツスロットの初期指示(たとえば、図1Bに示す候補コンテンツスロット124、126、128、130、132、または134)を与えることができる。コンテンツパブリッシャ232は次いで、候補コンテンツスロットのうちの1つまたは複数を許容するかそれとも拒絶するかを決定することができる。データ処理システム202は、許容または拒絶された候補スロットを追跡し、フィードバックを使用して候補コンテンツスロットをスコアリングまたはランク付けすることができる。たとえば、大部分のコンテンツパブリッシャデバイス232が候補コンテンツスロット124を拒絶したが、候補コンテンツスロット126を許容した場合、データ処理システム202は、候補コンテンツスロット126を候補コンテンツスロット124よりも上位にランク付けすることを決定することができる。
The second signal can be based on feedback from the
機械学習アルゴリズムによって使用される第3の信号は、クラウドソーシングフィードバックを含むことができる。たとえば、データ処理システム202は、様々な候補コンテンツスロットに関するいくつかのコンテンツパブリッシャデバイス232またはクライアントコンピューティングデバイス230からのフィードバックを取得することができる。このフィードバックは、機械学習アルゴリズムを訓練するためのグランドトゥルースデータを形成することができる。
The third signal used by the machine learning algorithm can include crowdsourcing feedback. For example, the data processing system 202 can get feedback from some
第4の信号は、様々なコンテンツスロットに配置された補足コンテンツアイテムの性能に基づくことができる。データ処理システム202、コンテンツパブリッシャ232、またはコンテンツプロバイダ234は、サービスされる補足コンテンツアイテムに関連する様々なメトリクスを観測することができる。メトリクスは、ユーザが特定の候補コンテンツスロットとともにデジタルビデオを注視する時間の長さと、ユーザが候補コンテンツスロットなしでまたは異なる候補コンテンツスロットとともにデジタルビデオを注視する時間の長さとの比較を含むことができる。データ処理システム202は、コンテンツスロットに起因する閲覧持続時間の短縮を追跡することができる。たとえば、コンテンツスロット126よりもコンテンツスロット124の方が、デジタルビデオの平均閲覧持続時間が短縮された場合、データ処理システム202は、コンテンツスロット126をコンテンツスロット124よりも上位にスコアリングまたはランク付けすることを決定することができる。
The fourth signal can be based on the performance of supplemental content items placed in various content slots. The data processing system 202,
機械学習モデルは、これらの信号または追加の信号のうちの1つまたは複数を経時的に組み込むことができる。機械学習モデルが組み込むデータセットが大きくなるにつれて、機械学習アルゴリズムが経時的に発展して様々な候補コンテンツスロットをよりうまくスコアリングまたはランク付けできるようになる。スロット検出器208は、上位N個のコンテンツスロットをデジタルビデオに含めるコンテンツスロットとして選択することができる。 Machine learning models can incorporate one or more of these or additional signals over time. As the data sets built into machine learning models grow, machine learning algorithms evolve over time to better score or rank various candidate content slots. Slot detector 208 can select the top N content slots as content slots to include in the digital video.
スロット検出器208は、コンテンツスロットの持続時間(たとえば、第1の静的部分の持続時間)を決定することができる。スロット検出器208は、様々な技法を使用して第1の静的部分の持続時間を決定することができる。スロット検出器208は、静的部分についての開始タイムスタンプおよび静的部分についての終了タイムスタンプに基づいて持続時間を決定することができる。スロット検出器208は、静的部分を含む連続するフレームの第1のサブセット内のフレームの数にフレームレートを乗じた値に基づいて静的部分の持続時間を決定することができる。スロット検出器208は、静的部分の第1の持続時間としきい値を比較して、第1の持続時間がデジタルビデオに挿入するのに適しているかどうかを決定することができる。 The slot detector 208 can determine the duration of the content slot (eg, the duration of the first static portion). Slot detector 208 can use a variety of techniques to determine the duration of the first static portion. Slot detector 208 can determine the duration based on the start time stamp for the static part and the end time stamp for the static part. The slot detector 208 can determine the duration of the static part based on the number of frames in the first subset of consecutive frames containing the static part multiplied by the frame rate. The slot detector 208 can compare the first duration of the static part with the threshold to determine if the first duration is suitable for insertion into a digital video.
第1の持続時間がしきい値未満である場合、スロット検出器208は第1のコンテンツスロットを無視し、第2の最上位のコンテンツスロットの選択に進むことができる。スロット検出器208は次いで、第2の最上位のコンテンツスロットの持続時間を決定し、持続時間がしきい値を満たすことに応じて、デジタルビデオに第2のコンテンツスロットをタグ付けすることができる。 If the first duration is less than the threshold, slot detector 208 can ignore the first content slot and proceed to select the second topmost content slot. Slot detector 208 can then determine the duration of the second top-level content slot and tag the digital video with the second content slot depending on the duration satisfying the threshold. ..
データ処理システム202は(インターフェース228を介して)、コンテンツパブリッシャデバイス232に、特定された静的部分に上書きするための認可を要求することができる。コンテンツパブリッシャデバイス232は、要求を許容または拒絶することができ、それによって静的部分の上書きを認可または不認可とする。場合によっては、データ処理システム202は、静的部分についてコンテンツパブリッシャデバイス232から負の認可を受信する。負の認可は、データ処理システム202に静的部分をロックさせて、サードパーティコンテンツプロバイダデバイス234によって提供される補足コンテンツによる静的部分の上書きを阻止することができる。
Data processing system 202 (via interface 228) can request
ビデオ信号プロセッサ208は、静的部分またはコンテンツスロットについての時間オフセットを決定するように設計され構築されたオフセット計算器を含むことができる。時間オフセットは、クライアントコンピューティングデバイス230(またはそのビデオプレーヤアプリケーション236)がコンテンツスロットのためにコンテンツについての要求を送信するコンテンツスロットを含む連続するフレームの第1のサブセットに先立った再生中における時間を示すことができる。時間オフセットは、数秒から数分までの範囲とすることができる。たとえば、時間オフセットは、1秒、2秒、3秒、4秒、5秒、10秒、15秒、30秒、45秒、60秒、90秒、2分、3分、またはそれ以上とすることができる。 The video signal processor 208 can include an offset calculator designed and built to determine the time offset for a static part or content slot. The time offset is the time during playback prior to the first subset of consecutive frames containing the content slot in which the client computing device 230 (or its video player application 236) sends a request for content for the content slot. Can be shown. The time offset can range from a few seconds to a few minutes. For example, the time offset may be 1 second, 2 seconds, 3 seconds, 4 seconds, 5 seconds, 10 seconds, 15 seconds, 30 seconds, 45 seconds, 60 seconds, 90 seconds, 2 minutes, 3 minutes, or more. be able to.
時間オフセットは、オフセットデータ構造222から取り出される所定のオフセットとすることができる。オフセットデータ構造222はいくつかのオフセットを記憶することができる。オフセットは、クライアントコンピューティングデバイス230、デジタルビデオ、またはネットワーク205の特性にマップすることができる。たとえば、第1のオフセットはモバイルデバイスにマップすることができ、第2のオフセットはタブレットデバイスにマップすることができ、第3のオフセットは高解像度ビデオにマップすることができ、第4のオフセットはセルネットワーク205にマップすることができる。場合によっては、時間オフセットは、ネットワーク205の速度、クライアントコンピューティングデバイス230上で実行されるビデオアプリケーションプレーヤ236によって維持されるデジタルビデオバッファ、データ処理システム202の現在のプロセッサ利用度(たとえば、ピーク使用量である場合、時間オフセットを大きくして処理待ち行列における時間を延ばしレイテンシを低減させることができる)、またはデジタルビデオの持続時間に基づいて動的に決定することができる。 The time offset can be a predetermined offset taken from the offset data structure 222. The offset data structure 222 can store several offsets. The offset can be mapped to the characteristics of the client computing device 230, digital video, or network 205. For example, the first offset can be mapped to a mobile device, the second offset can be mapped to a tablet device, the third offset can be mapped to high resolution video, and the fourth offset can be It can be mapped to cell network 205. In some cases, the time offset is the speed of network 205, the digital video buffer maintained by the video application player 236 running on the client computing device 230, and the current processor utilization of the data processing system 202 (eg peak usage). If it is a quantity, it can be increased in time offset to increase time in the processing queue and reduce latency), or it can be dynamically determined based on the duration of the digital video.
オフセット計算器210は、ビデオアプリケーションプレーヤ236によってバッファされるデジタルビデオデータの量に基づいて時間オフセットを決定することができる。オフセット計算器210は、ビデオアプリケーションプレーヤ236によってメモリにプレロードされるフレームの数に基づいて時間オフセットを決定することができる。時間オフセットは、コンテンツについての要求が送信され、コンテンツセレクタ226がコンテンツアイテムを選択して返し、その後、選択されたコンテンツアイテムが挿入されるフレームがビデオアプリケーションプレーヤ236によってバッファされるように計算されうる。たとえば、ビデオアプリケーションプレーヤ236が30秒分のデジタルビデオをバッファする(たとえば、24fpsにおける720フレーム)場合、時間オフセットを35秒とし、ビデオアプリケーションプレーヤがコンテンツについての要求を送信し、データ処理システム202がコンテンツスロットに挿入されるコンテンツアイテムを選択して返すのに5秒確保することができる。たとえば、コンテンツスロットがデジタルビデオ内の56秒の時点で出現し、時間オフセットが35秒である場合、コンテンツについての要求は、デジタルビデオ内の21秒の時点でクライアントコンピューティングデバイス230から送信することができる(たとえば、図1Cに示す時間オフセット160)。
The offset
ビデオ信号プロセッサ204は、自動的に検出されるコンテンツスロットに関する情報およびコンテンツスロットのためにコンテンツについての要求をトリガするために使用される時間オフセットをデジタルビデオにタグ付けするように設計され構築されたメタデータタグ付け器212を含むことができる。メタデータタグ付け器212は、デジタルビデオに関連するメタデータファイルを更新することができる。メタデータタグ付け器212は、キーワード、色、背景色、色のグラデーション、またはフォントなどの、デジタルビデオまたはコンテンツスロットに関連する追加の情報を含むことができる。 The video signal processor 204 was designed and built to tag digital video with information about automatically detected content slots and the time offset used to trigger requests for content for the content slots. A metadata tagging device 212 can be included. The metadata tagger 212 can update the metadata files associated with digital video. The metadata tagger 212 can include additional information related to the digital video or content slot, such as keywords, colors, background colors, color gradients, or fonts.
メタデータタグ付け器212は、デジタルビデオのメタデータにコンテンツスロットに関する情報をタグ付けすることができる。メタデータタグ付け器212は、コンテンツスロットごとのコンテンツスロットデータ構造を生成することができる。たとえば、コンテンツスロットデータ構造は、content_slot_1{begin_timestamp, end_timestamp, temporal_offset, height, width, x-coordinate, y-coordinate, background color}を含むことができる。別の例では、コンテンツスロットデータ構造は、content_slot_1{begin_timestamp, duration, temporal_offset, height, width, x-coordinate, y-coordinate}を含むことができる。時間オフセットは、MPEGトランスポートストリームまたはMPEGプログラムストリームにおけるタイムスタンプメタデータフィールドに表示タイムスタンプ(“PTS”)として記憶することができる。 The metadata tagger 212 can tag digital video metadata with information about content slots. The metadata tagger 212 can generate a content slot data structure for each content slot. For example, the content slot data structure can include content_slot_1 {begin_timestamp, end_timestamp, temporal_offset, height, width, x-coordinate, y-coordinate, background color}. In another example, the content slot data structure can include content_slot_1 {begin_timestamp, duration, temporal_offset, height, width, x-coordinate, y-coordinate}. The time offset can be stored as a display time stamp (“PTS”) in the time stamp metadata field in the MPEG transport stream or MPEG program stream.
メタデータタグ付け器212は、デジタルビデオの既存のメタデータに情報を挿入することができる。メタデータタグ付け器212はデジタルビデオの既存のメタデータに情報を付加することができる。メタデータタグ付け器212は、デジタルビデオの既存のメタデータの少なくとも一部を置き換えることができる。メタデータタグ付け器212は、デジタルビデオのメタデータに1つまたは複数のフィールドを追加することができる。メタデータタグ付け器212は、ビデオプレーヤアプリケーション236に、時間オフセットに基づいてコンテンツについての要求を送信させるための命令を含むことができる。 The metadata tagger 212 can insert information into the existing metadata of digital video. The metadata tagger 212 can add information to the existing metadata of digital video. The metadata tagger 212 can replace at least some of the existing metadata in digital video. The metadata tagger 212 can add one or more fields to the metadata of digital video. The metadata tagger 212 may include instructions for causing the video player application 236 to send a request for content based on a time offset.
いくつかの実装形態では、ビデオ信号プロセッサ204は、デジタルビデオをタグ付けされたメタデータとともにクライアントコンピューティングデバイス230にストリーミング送出することができる。クライアントコンピューティングデバイス230はデジタルビデオを再生することができる。クライアントコンピューティングデバイス230は、時間オフセットに基づいてコンテンツについての要求をデータ処理システム202に送信し、補足コンテンツアイテムを受信し、次いでデジタルビデオのメタデータ内に指示されたコンテンツスロットにおいて受信されたコンテンツアイテムをレンダリングすることができる。 In some implementations, the video signal processor 204 can stream the digital video to the client computing device 230 along with the tagged metadata. The client computing device 230 can play digital video. The client computing device 230 sends a request for content to the data processing system 202 based on a time offset, receives a supplementary content item, and then the content received in the content slot indicated in the digital video metadata. Items can be rendered.
いくつかの実装形態では、ビデオ信号プロセッサ204はビデオエディタ214を含む。ビデオエディタ214は、選択されたコンテンツアイテムをコンテンツスロットにマージし、次いで修正されたフレームをクライアントコンピューティングデバイス230に送信して、ビデオプレーヤアプリケーション236に、すでにコンテンツスロットに挿入された選択されたコンテンツアイテムによってフレーム全体をレンダリングさせることができる。ビデオエディタ214は、引き続き、コンテンツスロットの持続時間の間、選択されたコンテンツアイテムを各フレームにマージすることができる。修正されたフレームをクライアントコンピューティングデバイス230に送信する前に、選択されたコンテンツアイテムをデータ処理システム202によってマージすると、クライアントコンピューティングデバイス230によるコンピューティングリソース消費量を低減させ、ならびにクライアントコンピューティングデバイス230(またはクライアントコンピューティングデバイス230上で実行されるソフトウェアプログラム)が選択されたコンテンツアイテムを妨害するのを防ぎ、選択されたコンテンツアイテムがコンテンツスロットにおいてレンダリングされるのを阻止することができる。
In some implementations, the video signal processor 204 includes a
システム200、またはたとえばデータ処理システム202、ビデオ信号プロセッサ204、コンテンツセレクタ226、インターフェース228、クライアントコンピューティングデバイス230、コンテンツパブリッシャデバイス232、もしくはコンテンツプロバイダデバイス234を含む、システム200の1つもしくは複数の構成要素もしくは要素は、図1A〜図1Dに示す1つまたは複数の機能または態様を実行することができる。
One or more configurations of
図3は、デジタルビデオを組み合わせるかまたは修正する方法の実装形態のフローチャートである。この方法300は、デジタルビデオを組み合わせるかまたは修正するコンピュータによって実施される方法を含むことができる。方法300は、システム、またはたとえばデータ処理システム202、ビデオ信号プロセッサ204、コンテンツセレクタ226、インターフェース228、クライアントコンピューティングデバイス230、コンテンツパブリッシャデバイス232、もしくはコンテンツプロバイダデバイス234を含む、図1A〜図1D、図2、もしくは図4に示す1つもしくは複数の構成要素を介して実行することができる。概略的には、方法300は、ステップ302においてデータ処理システムがビデオを受信することを含むことができる。ステップ304において、データ処理システムは、ビデオのフレームレートを決定することができる。ステップ306において、データ処理システムは、フレームレートがしきい値を満たすかどうかを決定することができる。フレームレートがしきい値を満たさない場合、データ処理システムはステップ308に進むことができる。ステップ308において、データ処理システムは、ビデオをロックして編集を阻止し、次いでステップ310において、パブリッシャにビデオがロックされたことを通知することができる。ステップ306において、フレームレートがしきい値を満たすと決定された場合、データ処理システムはステップ312に進み、第1の静的部分を特定し、第1の静的部分の持続時間を決定することができる。データ処理システムは次いで、決定ステップ314において、持続時間がしきい値を満たすかどうかを決定することができる。データ処理システムが、ステップ314において、持続時間がしきい値を満たさないと決定した場合、データ処理システムはステップ316に進み、第1の静的部分をロックして編集を阻止することができる。データ処理システムは次いで、ステップ318に進み、特定された第2の静的部分がしきい値を満たすかどうかを決定することができる。特定された第2の静的部分が持続時間しきい値を満たさない場合、データ処理システムはステップ308に進み、次いでステップ310に進むことができる。特定された第2の静的部分が持続時間しきい値を満たす場合、データ処理システムはステップ320に進み、第2の静的部分をコンテンツスロットとして使用することを決定することができる。データ処理システムは、ステップ322において、第2の静的部分についての時間オフセットを算出することができる。さらに、データ処理システムは、ステップ314において、第1の静的部分の持続時間が持続時間しきい値を満たすと決定した場合、直接ステップ322に進み、第1の静的部分についての時間オフセットを算出することができる。データ処理システムは、ステップ324においてビデオをタグ付けすることができる。データ処理システムは、ステップ326においてビデオを送信することができる。データ処理システムは、ステップ328において要求を受信することができる。データ処理システムは、ステップ330においてコンテンツアイテムを選択することができる。データ処理システムは、ステップ332においてコンテンツアイテムを提供することができる。
FIG. 3 is a flow chart of an implementation of how to combine or modify digital video. The
引き続き図3を参照して詳細に説明すると、方法300は、ステップ302において、データ処理システムがビデオを受信するステップを含むことができる。ビデオはデジタルビデオとすることができる。データ処理システムは、デジタルビデオをコンテンツパブリッシャデバイスから受信することができる。データ処理システムは、ビデオアップローダインターフェースを提供することができる。コンテンツパブリッシャデバイスは、インターフェースを介してデジタルビデオを転送し、アップロードし、または場合によっては提供することができる。デジタルビデオは複数のフレームを含むことができ、各フレームは画像データを含むことができる。デジタルビデオは、タイトルなどのデジタルビデオに関するメタデータまたは情報を含むことができる。デジタルビデオは、プロトコルを使用して符号化することができる。デジタルビデオは、カラーまたは単色の2次元デジタルビデオ、3次元デジタルビデオ、動画、実写版デジタルビデオ、漫画とすることができる。デジタルビデオは、様々な実装形態において、オーディオを含むことができ、または無声であってもよい。いくつかの実装形態では、デジタルビデオは、(たとえば、それぞれに異なる言語の)複数のオーディオトラックを含んでもよい。
Subsequently described in detail with reference to FIG. 3, the
ステップ304において、データ処理システムは、ビデオのフレームレートを決定することができる。いくつかの実装形態では、データ処理システムは、デジタルビデオ内のフレームの数およびデジタルビデオの持続時間に基づいてフレームレートを決定することができる。たとえば、フレームレートは、デジタルビデオ内のフレームの数を秒単位のデジタルビデオの持続時間で除すことによって得られる、毎秒フレーム数としての割合とすることができる。いくつかの実装形態では、データ処理システムは、デジタルビデオを符号化するのに使用される符号化プロトコルまたは媒体プロトコルの種類に基づいてフレームレートを決定することができる。いくつかの実装形態では、データ処理システムは、デジタルビデオに関連するメタデータ情報に基づいてフレームレートを決定することができる(たとえば、フレームレートの明示的な特定)。いくつかの実装形態では、データ処理システムは、デジタルビデオの解像度、デジタルビデオの種類、デジタルビデオを再生のために構成する場合の対象となるデバイスの種類、デジタルビデオのトピック、またはデジタルビデオの持続時間などの、デジタルビデオに関連する追加の情報を決定することができる。
In
ステップ306において、データ処理システムは、フレームレートがしきい値を満たすかどうかを決定することができる。データ処理システムは、データリポジトリからフレームレートしきい値を取り出すことができる。フレームレートしきい値は毎秒24フレーム(fps)、12fps、または任意の他のそのようなフレームレートとすることができる。フレームレートしきい値は、デジタルビデオが再生されるフレームレートよりも低くすることができる。たとえば、デジタルビデオが動画を含む場合、ビデオは、毎秒12個のフレームを含むことができるが、2つの連続するフレームが同じ画像を含む場合には24fpsで再生することができる。他の実装形態では、媒体は、毎秒フレーム数が再生時よりも少なくてもよく、クライアントデバイスが、補間を実行して削除されたフレームを再生成する。これによってデータ記憶要件および帯域幅要件が低減し得る。
In
フレームレートがしきい値を満たさない場合、データ処理システムはステップ308に進み、ビデオをロックして編集を阻止することができる。データ処理システムは、フレームレートが補足コンテンツスロットに対して不十分であり、コンテンツスロットがデジタルビデオの再生に干渉する場合があることに起因して、ビデオをロックすることを決定することができる。デジタルビデオをロックすることは、デジタルビデオのメタデータにタグ付けして、デジタルビデオが自動コンテンツスロット検出および没入型コンテンツスロットに適していないことを示すことを含むことができる。デジタルビデオをロックすることは、デジタルビデオの識別子をデータ処理システムのデータリポジトリに記憶し、デジタルビデオが自動コンテンツスロット検出に適していないことの指示を含むことができる。 If the frame rate does not meet the threshold, the data processing system can proceed to step 308 to lock the video and prevent editing. The data processing system can decide to lock the video because the frame rate is insufficient for the supplementary content slot and the content slot may interfere with the playback of the digital video. Locking a digital video can include tagging the metadata of the digital video to indicate that the digital video is not suitable for automatic content slot detection and immersive content slots. Locking the digital video can include storing the digital video identifier in the data repository of the data processing system and indicating that the digital video is not suitable for automatic content slot detection.
データ処理システムは、ステップ308においてビデオを編集に対してロックすると、ステップ310において、パブリッシャに、ビデオがロックされたことを通知することができる。データ処理システムは、ビデオがロックされたことを示すプロンプトをコンテンツパブリッシャに与えることができる。データ処理システムは、フレームレートのチェックに失敗したことなど、デジタルビデオがロックされたことの理由を示す指示をコンテンツパブリッシャに与えることができる。コンテンツパブリッシャは、フレームレートのチェックに失敗したことの指示を受信したことに応じて、十分なフレームレートを有する第2のデジタルビデオをアップロードしてもよい。第2のデジタルビデオは、同じデジタルビデオであるが適切なフレームレートでサンプリングされたデジタルビデオまたは異なるデジタルビデオとすることができる。
The data processing system may lock the video for editing in
ステップ306において、データ処理システムは、デジタルビデオがフレームレートチェックを満たすと決定した場合、ステップ312に進むことができる。ステップ312において、データ処理システムは、第1の静的部分を特定し、第1の静的部分の持続時間を決定することができる。データ処理システムは、スロット検出アルゴリズムまたは機械学習アルゴリズムのうちの1つまたは複数を使用することに基づいて第1の静的部分を特定することができる。データ処理システムは、デジタルビデオのフレームにおける没入型コンテンツスロットに適した領域を特定し、次いで特定された領域をスコアリングして1つまたは複数のコンテンツスロットを選択することができる。
In
たとえば、データ処理システムは、デジタルビデオのフレームにおける画素を比較し、フレーム全体にわたってピクセルの変化がないことに基づいて静的部分を特定し、次いで静的領域をコンテンツスロットとしてマーク付けすることができる。複数のコンテンツスロットがある場合、データ処理システムは、機械学習モデルを使用して複数のコンテンツスロットをスコアリングすることができる。データ処理システムは、スコアに基づいてコンテンツスロットをランク付けすることができる(たとえば、第1のコンテンツスロット、第2のコンテンツスロット、および第3のコンテンツスロット)。データ処理システムは次いで、デジタルビデオに挿入する最上位コンテンツスロット(たとえば、第1のコンテンツスロット)を選択することができる。 For example, a data processing system can compare pixels in a digital video frame, identify static parts based on the absence of pixel changes throughout the frame, and then mark static areas as content slots. .. If there are multiple content slots, the data processing system can use a machine learning model to score multiple content slots. The data processing system can rank content slots based on their scores (for example, first content slot, second content slot, and third content slot). The data processing system can then select the top-level content slot (eg, the first content slot) to insert into the digital video.
データ処理システムは、決定ステップ314において、第1のコンテンツスロットの持続時間が持続時間しきい値を満たすかどうかを決定することができる。第1のコンテンツスロットは、開始タイムスタンプおよび終了タイムスタンプ(または持続時間)を含むことができる。持続時間は、第1のコンテンツスロットに対応する静的領域を含むフレームの数に対応することができる。たとえば、第1のコンテンツスロットに対応する静的領域がデジタルビデオの720個の連続するフレームに存在し、フレームレートが24fpsである場合、第1のコンテンツスロットの持続時間は30秒である(たとえば、720個のフレーム数を24bpsで除した結果は30秒に等しい)。
In
データ処理システムは、データリポジトリから持続時間しきい値を取り出すことができる。データ処理システムは、所定の持続時間しきい値を使用することができる。データ処理システムは、デジタルビデオに関連する特性(たとえば、持続時間、フレームレート、品質、解像度、トピック、色など)に基づいて変化することができる動的な持続時間しきい値を使用することができる。持続時間しきい値は、デジタルビデオの持続時間に対する割合または比率とすることができる。たとえば、持続時間しきい値は、デジタルビデオの持続時間の5%、10%、15%、20%、25%、30%以上とすることができる。持続時間しきい値は、最小持続時間および最大持続時間を含むことができる。最大持続時間は、60秒、90秒、12秒とすることができる。コンテンツスロットの持続時間が最大持続時間を超える場合、データ処理システムはコンテンツスロットの持続時間を短縮または削減することができる。 The data processing system can retrieve the duration threshold from the data repository. The data processing system can use a predetermined duration threshold. Data processing systems can use dynamic duration thresholds that can change based on the characteristics associated with digital video (eg, duration, frame rate, quality, resolution, topic, color, etc.) can. The duration threshold can be a percentage or ratio of the duration of the digital video. For example, the duration threshold can be 5%, 10%, 15%, 20%, 25%, 30% or more of the duration of a digital video. The duration threshold can include a minimum duration and a maximum duration. The maximum duration can be 60 seconds, 90 seconds, 12 seconds. If the duration of the content slot exceeds the maximum duration, the data processing system can reduce or reduce the duration of the content slot.
データ処理システムは、第1のコンテンツスロットが持続時間しきい値を満たすと決定した場合、ステップ322において時間オフセットを算出することができる。しかし、データ処理システムは、ステップ314において、持続時間がしきい値を満たさないと決定した場合、ステップ316に進み、第1の静的部分をロックして編集を阻止することができる。データ処理システムは次いで、ステップ318に進み、特定されたコンテンツスロットがしきい値を満たすかどうかを決定することができる。第2のコンテンツスロットは、機械学習モデルに基づいて決定されたスコアに基づく第2位のコンテンツスロットとすることができる。特定された第2の静的部分が持続時間しきい値を満たさない場合、いくつかの実装形態では、データ処理システムはステップ308に進み、次いでステップ310に進むことができる。特定された第2の静的部分が持続時間しきい値を満たす場合、データ処理システムは、ステップ320に進み、第1のコンテンツスロットではなく第2のコンテンツスロットを使用することを決定することができる。2つの静的部分を試験することのみが示されているが、多くの実装形態では、ステップ312〜320は、必要なしきい値を超える静的部分が特定されるか、または特定される静的部分がなくなるまで、複数の追加の特定された静的部分の各々について反復的に繰り返されてもよい。
The data processing system can calculate the time offset in
ステップ322において、データ処理システムは、コンテンツスロット(たとえば、ステップ314において持続時間しきい値を満たす結果に基づく第1のコンテンツスロットまたは第2のコンテンツスロットの一方)についての時間オフセットを算出することができる。データ処理システムは、コンテンツスロットの開始タイムスタンプに先立ったデジタルビデオの再生中における時間オフセットを算出することができる。時間オフセットとしては、コンテンツスロットにおいてレンダリングされるコンテンツスロットを選択し提供する際にレイテンシを低減させるかまたはなくす時間オフセットを算出することができる。時間オフセットは、デジタルビデオについてのバッファリングメトリクス、デジタルビデオの解像度、ネットワーク特性、デジタルビデオの持続時間などに基づいて算出することができる。
In
データ処理システムは、ステップ324においてビデオにタグ付けすることができる。データ処理システムは、デジタルビデオにコンテンツスロットの指示をタグ付けすることができる。データ処理システムは、デジタルビデオにコンテンツスロットデータ構造をタグ付けすることができ、コンテンツスロットデータ構造は、コンテンツスロットに対応する静的部分を有する連続するフレームのサブセットの指示を含むことができる。データ処理システムは、算出された時間オフセットにおいてコンテンツについての要求を送信させるトリガをデジタルビデオにタグ付けすることができる。コンテンツスロットデータ構造は、たとえば、{start timestamp, duration, temporal offset, size, position}を含むことができる。
The data processing system can tag the video in
データ処理システムは、ステップ326においてビデオを送信することができる。データ処理システムは、デジタルビデオをクライアントデバイスに提供することができる。クライアントデバイスは、データ処理システムにデジタルビデオを要求することができる。クライアントデバイスは、デジタルビデオへのリンクまたはポインタを含むウェブページにアクセスしていてもよい。デジタルビデオは、クライアントデバイスによってアクセスされるウェブページに埋め込むことができる。データ処理システムは、コンテンツスロットおよびトリガの指示をデジタルビデオコンテンツに与えることができる。デジタルビデオコンテンツアイテムを受信すると、クライアントデバイスは、デジタルビデオコンテンツアイテムをレンダリングし、指示を解析して連続するフレームの第1のサブセットを特定し、トリガの実行に応じて、連続するフレームの第1のサブセットに先立った再生中における時間オフセットにおいて、コンテンツについての要求を送信することができる。
The data processing system can transmit the video in
データ処理システムは、ステップ328において要求を受信することができる。データ処理システムは、クライアントデバイスから要求を受信することができる。クライアントデバイスは、概ね(たとえば、10%)時間オフセットにおいて要求を送信することができる。データ処理システムは、コンテンツについての要求を受信したことに応じて、ステップ330においてコンテンツアイテムを選択することができる。データ処理システムは、ステップ332においてクライアントデバイスにコンテンツアイテムを提供することができる。クライアントデバイスは、コンテンツスロットについての持続時間の間、コンテンツスロットにおいてコンテンツアイテムをレンダリングすることができる。クライアントデバイスは、コンテンツスロットの持続時間の間、コンテンツアイテムを1度だけ受信すればよく、それによってネットワーク帯域幅使用量およびリモートプロシージャコールが低減する。たとえば、コンテンツアイテムは、720個の連続するフレームに対応してコンテンツスロットにおいて720回レンダリングすることができるが、コンテンツアイテムは、データ処理システムからクライアントコンピューティングデバイスに1度だけ送信されればよく、それによって改善が図られる。
The data processing system can receive the request in
コンテンツスロットの持続時間が終了した後、クライアントデバイスは、コンテンツスロットを終了し、コンテンツアイテムを削除または消去することができる。クライアントデバイスは、第2のコンテンツスロットが開始するまで待機し、第2のコンテンツスロットに対応する第2の時間オフセットにおいてコンテンツについての第2の要求を送信することができる。 After the content slot has expired, the client device can exit the content slot and delete or erase the content item. The client device can wait for the second content slot to start and send a second request for content at the second time offset corresponding to the second content slot.
図4は、例示的なコンピュータシステム400のブロック図である。コンピュータシステムまたはコンピューティングデバイス400は、システム200、またはデータ処理システム202などのシステム200の構成要素を含むか、またはシステム200またはその構成要素を実装するために使用することができる。コンピューティングシステム400は、情報を通信するためのバス405またはその他の通信構成要素と、情報を処理するためにバス405に結合されたプロセッサ410または処理回路とを含む。コンピューティングシステム400はまた、情報を処理するためにバスに結合された1つまたは複数のプロセッサ410または処理回路を含むことができる。コンピューティングシステム400はまた、情報、およびプロセッサ410によって実行すべき命令を記憶するためにバス405に結合された、ランダムアクセスメモリ(RAM)またはその他の動的記憶デバイスなどのメインメモリ415を含む。メインメモリ415は、データリポジトリ104とすることができ、またはデータリポジトリ104を含むことができる。メインメモリ415はまた、プロセッサ410による命令の実行時に位置情報、一時変数、またはその他の中間情報を記憶するために使用することができる。コンピューティングシステム400は、プロセッサ410用の静的情報および命令を記憶するためにバス405に結合された、読取り専用メモリ(ROM)420またはその他の静的記憶デバイスをさらに含んでもよい。固体状態デバイス、磁気ディスク、または光ディスクなどの記憶デバイス425を、情報および命令を永久的に記憶するためにバス405に結合することができる。記憶デバイス425は、データリポジトリ104を含むことができ、またはデータリポジトリ104の一部とすることができる。
FIG. 4 is a block diagram of an
コンピューティングシステム400は、情報をユーザに表示するために、液晶ディスプレイまたはアクティブマトリクスディスプレイなどのディスプレイ435にバス405に介して結合されてもよい。英数字キーおよびその他のキーを含むキーボードなどの入力デバイス430は、選択された情報およびコマンドをプロセッサ410に通信するためにバス405に結合されてもよい。入力デバイス430は、タッチスクリーンディスプレイ435を含むことができる。入力デバイス430はまた、方向情報およびコマンド選択をプロセッサ410に通信し、ディスプレイ435上のカーソルの移動を制御するための、マウス、トラックボール、またはカーソル方向キーなどのカーソル制御装置を含むことができる。ディスプレイ435は、たとえば、データ処理システム202、クライアントコンピューティングデバイス150、または図2の他の構成要素の一部とすることができる。
The
本明細書で説明するプロセス、システム、および方法は、プロセッサ410がメインメモリ415に含まれる一連の命令を実行したことに応答してコンピューティングシステム400によって実現することができる。そのような命令は、記憶デバイス425などの別のコンピュータ可読媒体からメインメモリ415に読み込むことができる。メインメモリ415に含まれる一連の命令を実行すると、コンピューティングシステム400は、本明細書で説明する例示的なプロセスを実行する。メインメモリ415に含まれる命令を実行するためにマルチプロセシング構成における1つまたは複数のプロセッサが使用されてもよい。ソフトウェア命令の代わりにまたはソフトウェア命令と組み合わせて、ハード配線された回路を、本明細書で説明するシステムおよび方法とともに使用することができる。本明細書で説明するシステムおよび方法は、ハードウェア回路とソフトウェアの任意の特定の組合せに限定されない。
The processes, systems, and methods described herein can be implemented by the
図4において例示的なコンピューティングシステムについて説明したが、本明細書で説明する動作を含む主題は、他の種類のデジタル電子回路、または本明細書で開示される構造およびその構造均等物を含むコンピュータソフトウェア、ファームウェア、もしくはハードウェア、またはそれらのうちの1つもしくは複数の組合せにおいて実現することができる。 Although exemplary computing systems have been described in FIG. 4, the subject matter including the operations described herein includes other types of digital electronic circuits, or the structures disclosed herein and their structural equivalents. It can be implemented in computer software, firmware, or hardware, or a combination of one or more of them.
本明細書で説明するシステムがユーザに関する個人情報を収集するか、または個人情報を利用し得る状況では、個人情報(たとえば、ユーザのソーシャルネットワーク、社会行動もしくは活動、ユーザの選好、またはユーザの位置に関する情報)を収集し得るプログラムもしくは機能を制御するか、あるいはコンテンツサーバもしくはユーザとの関連性がより高い場合がある他のデータ処理システムからコンテンツを受信するかどうかまたはどのように受信するかを制御する機会がユーザに与えられてもよい。さらに、いくつかのデータは、記憶または使用される前に1つまたは複数の方法で匿名化されてもよく、それによって、個人を特定可能な情報は、パラメータを生成する際に削除される。たとえば、ユーザの識別情報は、ユーザについて個人を特定可能な情報を決定することができないように匿名化されてもよく、または位置情報が得られる場合にユーザの地理的位置が(市、郵便番号、または州などのレベルに)一般化されてもよく、それによってユーザの特定の位置を決定することはできなくなる。したがって、ユーザは自分に関する情報がどのように収集されコンテンツサーバによって使用されるかについての制御が可能であってもよい。 In situations where the systems described herein collect or use personal information about you, personal information (eg, your social network, social behavior or activity, your preferences, or your location). Whether or how to receive content from a program or function that may collect information about it, or from a content server or other data processing system that may be more relevant to you. The user may be given the opportunity to control. In addition, some data may be anonymized in one or more ways before being stored or used, whereby personally identifiable information is removed when generating the parameters. For example, a user's identity may be anonymized so that no personally identifiable information about the user can be determined, or if location information is available, the user's geographic location (city, zip code). , Or to a level such as state), which makes it impossible to determine a particular location for the user. Therefore, the user may be able to control how information about him is collected and used by the content server.
本明細書で説明する主題および動作は、デジタル電子回路、または本明細書で開示される構造およびその構造均等物を含むコンピュータソフトウェア、ファームウェア、もしくはハードウェア、またはそれらのうちの1つもしくは複数の組合せにおいて実現することができる。本明細書で説明する主題は、データ処理装置によって実行されるようにまたはデータ処理装置の動作を制御するために1つまたは複数のコンピュータ記憶媒体上に符号化された1つまたは複数のコンピュータプログラム、たとえば、コンピュータプログラム命令の1つまたは複数の回路として実現することができる。代替または追加として、プログラム命令は、人工的に生成された伝搬信号、たとえば、データ処理装置による実行を目的として適切なレシーバ装置に送信されるように情報を符号化するために生成された機械生成電気信号、光信号、または電磁信号上に符号化することができる。コンピュータ記憶媒体は、コンピュータ可読記憶デバイス、コンピュータ可読記憶基板、ランダムもしくはシリアルアクセスメモリアレイもしくはデバイス、またはそれらのうちの1つもしくは複数の組合せとすることができ、あるいはそれらに含めることができる。コンピュータ記憶媒体は伝搬信号ではないが、コンピュータ記憶媒体は、人工的に生成された伝搬信号内に符号化されたコンピュータプログラム命令の送信元または送信先とすることができる。コンピュータ記憶媒体は、1つもしくは複数の別個の構成要素もしくは媒体(たとえば、複数のCD、ディスク、もしくはその他の記憶デバイス)とすることもでき、またはそれらに含めることができる。本明細書で説明する動作は、1つもしくは複数のコンピュータ可読記憶デバイス上に記憶されるかまたは他の送信元から受信されるデータに対してデータ処理装置によって実行される動作として実現することができる。 The subject matter and operation described herein is a digital electronic circuit, or computer software, firmware, or hardware, including the structures and structural equivalents thereof disclosed herein, or one or more of them. It can be realized in combination. The subject matter described herein is one or more computer programs encoded on one or more computer storage media to be performed by a data processor or to control the operation of the data processor. , For example, it can be implemented as one or more circuits of computer program instructions. Alternatively or additionally, the program instruction is a machine-generated signal generated to encode an artificially generated propagating signal, eg, information to be sent to a suitable receiver device for execution by a data processing device. It can be encoded on an electrical, optical, or electromagnetic signal. The computer storage medium can be, or include, a computer-readable storage device, a computer-readable storage board, a random or serial access memory array or device, or a combination thereof. Although the computer storage medium is not a propagating signal, the computer storage medium can be the source or destination of computer program instructions encoded in the artificially generated propagating signal. The computer storage medium can be, or can be included in, one or more separate components or media (eg, multiple CDs, discs, or other storage devices). The operations described herein can be implemented as operations performed by a data processor on data stored on one or more computer-readable storage devices or received from other sources. can.
「データ処理システム」、「コンピューティングデバイス」、「構成要素」、または「データ処理装置」という用語は、データを処理するための様々な装置、デバイス、および機械を包含し、一例としてプログラム可能なプロセッサ、コンピュータ、システムオンチップ、またはそれらのうちの複数もしくは組合せを含む。装置は、専用論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)を含むことができる。装置はまた、ハードウェアに加えて、対象のコンピュータプログラム用の実行環境を作成するためのコード、たとえば、プロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、クロスプラットフォーム実行時環境、仮想マシン、またはそれらのうちの1つもしくは複数の組合せを構成するコードを含むことができる。装置および実行環境は、ウェブサービス、分散コンピューティングインフラストラクチャ、およびグリッドコンピューティングインフラストラクチャなどの様々な異なるコンピューティングモデルインフラストラクチャを実現することができる。コンテンツセレクタ構成要素226、動的コンテンツサーバ130、静的コンテンツサーバ132、およびその他のデータ処理システム202構成要素は、1つもしくは複数のデータ処理装置、システム、コンピューティングデバイス、またはプロセッサを含むかあるいは共有することができる。さらに、インターフェース228、ビデオ信号プロセッサ204、コンテンツセレクタ226、ビデオプレプロセッサ206、スロット検出器208、オフセット計算器210、メタデータタグ付け器212、ビデオエディタ214、およびデータリポジトリ216、またはその他のクライアントコンピューティングデバイス230構成要素は、1つもしくは複数のデータ処理装置、システム、コンピューティングデバイス、またはプロセッサを含むかあるいは共有することができる。
The terms "data processing system," "computing device," "component," or "data processing device" include, as an example, programmable devices, devices, and machines for processing data. Includes processors, computers, system-on-chips, or multiples or combinations thereof. The device can include dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). In addition to the hardware, the device also has code to create an execution environment for the target computer program, such as processor firmware, protocol stack, database management system, operating system, cross-platform run-time environment, virtual machine, or It can contain code that constitutes one or more combinations of them. Equipment and execution environments can implement a variety of different computing model infrastructures such as web services, distributed computing infrastructure, and grid computing infrastructure. The content selector component 226,
コンピュータプロセッサ(プログラム、ソフトウェア、ソフトウェアアプリケーション、app、スクリプト、またはコードとも呼ばれる)は、コンパイル型言語またはインタプリト型言語、宣言型言語または手続き型言語を含む任意の形態のプログラミング言語で書くことができ、スタンドアロンプログラム、またはモジュール、構成要素、サブルーチン、オブジェクト、もしくはコンピューティング環境において使用するのに適した他のユニット任意の形態を含む任意の形態で装備することができる。コンピュータプログラムは、ファイルシステム内のファイルに対応することができる。コンピュータプログラムは、ファイルにおける他のプログラムまたはデータ(たとえば、マークアップ言語ドキュメントに記憶された1つもしくは複数のスクリプト)を保持する部分、対象のプログラム専用の単一のファイル、あるいは複数の組織的ファイル(たとえば、1つもしくは複数のモジュール、サブプログラム、またはコードの一部を記憶するファイル)に記憶することができる。コンピュータプログラムは、1つのコンピュータ上で実行するか、または1つの場所に位置するかもしくは複数の場所にわたって分散され通信ネットワークによって相互接続された複数のコンピュータ上で実行されるように装備することができる。 Computer processors (also called programs, software, software applications, apps, scripts, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages. It can be equipped in any form, including a stand-alone program, or any form of module, component, subroutine, object, or other unit suitable for use in a computing environment. Computer programs can accommodate files in the file system. A computer program is a portion of a file that holds other programs or data (for example, one or more scripts stored in a markup language document), a single file dedicated to the program of interest, or multiple organizational files. It can be stored in (for example, a file that stores one or more modules, subprograms, or parts of code). Computer programs can be equipped to run on one computer, or on multiple computers located in one location or distributed across multiple locations and interconnected by communication networks. ..
本明細書で説明するプロセスおよび論理フローは、1つまたは複数のプログラム可能なプロセッサが1つまたは複数のコンピュータプログラム(たとえば、データ処理システム202の構成要素)を実行して、入力データに作用し出力を生成することによって動作を行うことによって実施することができる。プロセスおよび論理フローは、専用論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)によって実行することもでき、装置をこのような専用論理回路として実現することもできる。コンピュータプログラム命令およびデータを記憶するのに適したデバイスは、一例として半導体メモリデバイス、たとえば、EPROM、EEPROM、およびフラッシュメモリデバイス、磁気ディスク、たとえば、内部ハードディスクまたは取外し可能ディスク、光磁気ディスク、ならびにCD ROMディスクおよびDVD-ROMディスクを含む、すべての形態の非揮発性メモリ、媒体およびメモリデバイスを含む。プロセッサおよびメモリは、専用論理回路によって補足することができ、または専用論理回路に組み込むことができる。 The processes and logical flows described herein are such that one or more programmable processors execute one or more computer programs (eg, components of data processing system 202) to act on input data. It can be done by performing an action by generating an output. Processes and logic flows can also be executed by dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits), and devices can be implemented as such dedicated logic circuits. Suitable devices for storing computer program instructions and data include, for example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices, magnetic disks, such as internal hard disks or removable disks, magneto-optical disks, and CDs. Includes all forms of non-volatile memory, media and memory devices, including ROM disks and DVD-ROM disks. The processor and memory can be supplemented by dedicated logic or can be incorporated into dedicated logic.
本明細書で説明する主題は、バックエンド構成要素を、たとえばデータサーバとして含むか、あるいはミドルウェア構成要素、たとえばアプリケーションサーバを含むか、あるいはフロントエンド構成要素、たとえば、ユーザが本明細書で説明する主題と相互作用するのを可能にするグラフィカルユーザインターフェースもしくはウェブブラウザを有するクライアントコンピュータ、あるいは1つもしくは複数のそのようなバックエンド構成要素、ミドルウェア構成要素、またはフロントエンド構成要素の組合せを含むコンピューティングシステムにおいて実現することができる。システムの構成要素は、任意の形態のデジタルデータ通信、たとえば、通信ネットワークによって相互接続することができ、またはデジタルデータ通信を媒介として相互接続することができる。通信ネットワークの例は、ローカルエリアネットワーク(“LAN”)およびワイドエリアネットワーク(“WAN”)、インターネットワーク(たとえば、インターネット)、およびピアツーピアネットワーク(たとえば、アドホックピアツーピアネットワーク)を含む。 The subject matter described herein includes a back-end component, eg, as a data server, or a middleware component, such as an application server, or a front-end component, eg, a user. A client computer with a graphical user interface or web browser that allows it to interact with the subject, or computing that includes one or more such back-end components, middleware components, or a combination of front-end components. It can be realized in the system. The components of the system can be interconnected by any form of digital data communication, such as a communication network, or can be interconnected via digital data communication. Examples of communication networks include local area networks (“LAN”) and wide area networks (“WAN”), internetworks (eg, the Internet), and peer-to-peer networks (eg, ad hoc peer-to-peer networks).
システム200またはシステム400などのコンピューティングシステムはクライアントとサーバとを含むことができる。クライアントとサーバは一般に、互いに離れており、通常、通信ネットワーク(たとえば、ネットワーク205)を通じて相互作用する。クライアントとサーバとの関係は、それぞれのコンピュータ上で動作し、互いにクライアント-サーバ関係を有するコンピュータプログラムによって生じる。サーバは、データ(たとえば、コンテンツアイテムを表すデータパケット)を(たとえば、クライアントデバイスと相互作用するユーザに対してデータを表示し、ユーザからユーザ入力を受信するために)クライアントデバイスに送信することができる。(たとえば、ユーザ相互作用の結果として)クライアントデバイスにおいて生成されたデータは、クライアントデバイスからサーバにおいて受信する(たとえば、コンピューティングデバイス230またはコンテンツプロバイダコンピューティングデバイス234またはコンテンツパブリッシャデバイス232からデータ処理システム202によって受信する)ことができる。
A computing system such as
本開示の態様は、デジタルビデオコンテンツを修正するシステムおよび方法を対象とする。たとえば、システムおよび方法は、ビデオコンテンツを組み合わせてもよい。たとえば、この方法は、ビデオ信号プロセッサおよびコンテンツセレクタを含むかまたは実行するデータ処理システムによって実行することができる。この方法は、複数のフレームを含むデジタルビデオコンテンツアイテムをパブリッシャデバイスから受信するデータ処理システムを含むことができる。ビデオ信号プロセッサは、デジタルビデオコンテンツアイテムのフレームレートを決定することができる。ビデオ信号プロセッサは、複数のフレームを分析して、第1静的部分を有する複数のフレームから連続するフレームの第1のサブセットを特定することができる。第1の静的部分は、2つ以上のフレームにわたって一致するピクセルを含む空間領域によって画定することができる。ビデオ信号プロセッサは、連続するフレームの第1のサブセットにおけるフレームの数およびフレームレートに基づいて第1の静的部分の第1の持続時間を決定することができる。ビデオ信号プロセッサは、第1の静的部分の第1の持続時間をしきい値と比較することができる。ビデオ信号プロセッサは、デジタルビデオコンテンツアイテムに、連続するフレームの第1のサブセットの指示およびトリガをタグ付けすることができる。ビデオ信号プロセッサは、第1の静的部分の持続時間がしきい値以上であることに応じてデジタルビデオコンテンツアイテムにタグ付けすることができる。トリガは、第1の静的部分を上書きするために使用されるコンテンツについての要求を送信させることができる。トリガは、連続するフレームの第1のサブセットに先立った再生中における時間オフセットにおいて要求を送信させることができる。ビデオ信号プロセッサは、指示およびトリガとともにデジタルビデオコンテンツアイテムをクライアントデバイスに提供することができる。クライアントデバイスによってデジタルビデオコンテンツアイテムを受信すると、クライアントデバイスは、デジタルビデオコンテンツアイテムをレンダリングし、指示を解析して連続するフレームの第1のサブセットを特定し、トリガの実行に応じて、連続するフレームの第1のサブセットに先立った再生中における時間オフセットにおいて、コンテンツについての要求を送信することができる。ビデオ信号プロセッサは、要求を受信することができ、この要求は、連続するフレームの第1のサブセットに先立った再生中における時間オフセットに基づいてクライアントデバイスによって送信されたものである。データ処理システムによって実行されるコンテンツセレクタは、コンテンツについての要求がクライアントデバイスから受信されたことに応じてコンテンツアイテムを選択することができる。データ処理システムは、コンテンツアイテムをクライアントデバイスに送信することができ、このコンテンツアイテムを受信すると、クライアントデバイスは、連続するフレームの第1のサブセットの第1の静的部分においてコンテンツアイテムをレンダリングする。 Aspects of the present disclosure are directed to systems and methods of modifying digital video content. For example, systems and methods may combine video content. For example, this method can be performed by a data processing system that includes or runs a video signal processor and content selector. The method can include a data processing system that receives digital video content items containing multiple frames from the publisher device. The video signal processor can determine the frame rate of the digital video content item. The video signal processor can analyze a plurality of frames to identify a first subset of consecutive frames from a plurality of frames having a first static portion. The first static part can be defined by a spatial area containing matching pixels over two or more frames. The video signal processor can determine the first duration of the first static part based on the number of frames and the frame rate in the first subset of consecutive frames. The video signal processor can compare the first duration of the first static part with the threshold. Video-signal processors can tag digital video content items with instructions and triggers for the first subset of consecutive frames. The video signal processor can tag the digital video content item according to the duration of the first static part being greater than or equal to the threshold. The trigger can send a request for the content used to overwrite the first static part. The trigger can cause the request to be sent at a time offset during playback prior to the first subset of consecutive frames. The video signal processor can provide digital video content items to client devices along with instructions and triggers. Upon receiving the digital video content item by the client device, the client device renders the digital video content item, parses the instructions to identify the first subset of the contiguous frames, and responds to the execution of the trigger by the contiguous frames. Requests for content can be sent at a time offset during playback prior to the first subset of. The video signal processor can receive the request, which is transmitted by the client device based on the time offset during playback prior to the first subset of consecutive frames. The content selector executed by the data processing system can select the content item according to the request for the content received from the client device. The data processing system can send the content item to the client device, and upon receiving this content item, the client device renders the content item in the first static part of the first subset of contiguous frames.
いくつかの実装形態では、パブリッシャデバイスおよびデータ処理システムは様々なデバイスを備えてもよい。他の実装形態では、パブリッシャデバイスはデータ処理システムの一部であってもよい。たとえば、いくつかの実装形態では、パブリッシャデバイスとデータ処理システムは同じデバイス上で実行されてもよい。デジタルビデオコンテンツアイテムを受信することは、デジタルビデオコンテンツアイテムをメモリまたはストレージからロードすることを含んでもよい。 In some implementations, the publisher device and data processing system may include a variety of devices. In other implementations, the publisher device may be part of a data processing system. For example, in some implementations, the publisher device and the data processing system may run on the same device. Receiving a digital video content item may include loading the digital video content item from memory or storage.
いくつかの実装形態では、データ処理システムは、フレームを分析して、連続するフレームの第1のサブセットにおける第2の静的部分を特定する。データ処理システムは、第1の静的部分に関連する第1のパラメータおよび第2の静的部分に関連する第2のパラメータを特定することができる。データ処理システムは、第1のパラメータと第2のパラメータとの比較に基づいて、タグ付けのために第1の静的部分を選択することができる。いくつかの実装形態では、第1のパラメータは、背景色、色のグラデーション、サイズ、または位置のうちの少なくとも1つを含む。第2のパラメータは、背景色、色のグラデーション、サイズ、または位置のうちの少なくとも1つを含むことができる。 In some implementations, the data processing system analyzes the frames to identify the second static part in the first subset of successive frames. The data processing system can identify the first parameter associated with the first static part and the second parameter associated with the second static part. The data processing system can select the first static part for tagging based on the comparison of the first and second parameters. In some implementations, the first parameter includes at least one of background color, color gradient, size, or position. The second parameter can include at least one of background color, color gradient, size, or position.
いくつかの実装形態では、データ処理システムは複数のフレームを分析して、連続するフレームの第1のサブセットにおける第2の静的部分を特定することができる。データ処理システムは、第2の静的部分の第2の持続時間を特定することができる。データ処理システムは、第1の持続時間が第2の持続時間を超えることに基づいて、タグ付けのために第1の静的部分を選択することができる。 In some implementations, the data processing system can analyze multiple frames to identify the second static part in the first subset of consecutive frames. The data processing system can identify the second duration of the second static part. The data processing system can select the first static part for tagging based on the first duration exceeding the second duration.
いくつかの実装形態では、データ処理システムは、デジタルビデオコンテンツアイテムにおける第2の静的部分を特定することができる。データ処理システムは、第2の静的部分を上書きするための認可をパブリッシャデバイスに要求することができる。データ処理システムは、第2の静的部分についてパブリッシャデバイスから負の認可を受信することができる。データ処理システムは、第2の静的部分をロックして、データ処理システムによって選択されたコンテンツで第2の静的部分を上書きするのを阻止することができる。 In some implementations, the data processing system can identify a second static part of the digital video content item. The data processing system can request the publisher device for authorization to overwrite the second static part. The data processing system can receive negative authorization from the publisher device for the second static part. The data processing system can lock the second static part to prevent the content selected by the data processing system from overwriting the second static part.
いくつかの実装形態では、データ処理システムは、複数のフレームにおける連続するフレームにわたるピクセルの変化に基づいて第1の静的部分を特定することができる。いくつかの実装形態では、データ処理システムは、パブリッシャデバイスから背景色の指示を受信して第1の静的部分の特定を制御することができる。データ処理システムは、背景色の指示を使用して、複数のフレームにおける連続するフレームにわたるピクセル特性に基づいて第1の静的部分を特定することができる。 In some implementations, the data processing system can identify the first static part based on pixel changes over successive frames in multiple frames. In some implementations, the data processing system can receive background color instructions from the publisher device to control the identification of the first static part. The data processing system can use the background color indication to identify the first static portion based on the pixel characteristics over successive frames in multiple frames.
いくつかの実装形態では、データ処理システムは、第1の静的部分に関連する1つもしくは複数の特性を特定することができる。1つもしくは複数の特性は、テキスト、フォント、顔、オブジェクトタイプ、または色のうちの少なくとも1つを含むことができる。データ処理システムは、第1の静的部分に関連する1つもしくは複数の特性に基づいてコンテンツアイテムを選択することができる。 In some implementations, the data processing system can identify one or more characteristics associated with the first static part. One or more properties can include at least one of text, font, face, object type, or color. The data processing system can select content items based on one or more characteristics associated with the first static part.
いくつかの実装形態では、データ処理システムは、クライアントデバイスのメモリにプレロードされるデジタルビデオコンテンツアイテムの量を特定することができる。データ処理システムは、この量に基づいて時間オフセットを設定し、クライアントデバイスに、この量がクライアントデバイスのメモリにプレロードされることに先立ってコンテンツについての要求を送信させることができる。 In some implementations, the data processing system can determine the amount of digital video content items that are preloaded into the memory of the client device. The data processing system can set a time offset based on this amount and have the client device send a request for content prior to this amount being preloaded into the client device's memory.
いくつかの実装形態では、データ処理システムは、デジタルビデオコンテンツアイテムの連続するフレームの第1のサブセットの第1の静的部分においてコンテンツアイテムをマージすることができる。データ処理システムは、コンテンツアイテムとマージされたデジタルビデオコンテンツアイテムの連続するフレームの第1のサブセットをクライアントデバイスに送信して、クライアントデバイスにコンテンツアイテムをレンダリングさせることができる。 In some implementations, the data processing system can merge content items in the first static part of the first subset of consecutive frames of digital video content items. The data processing system can send the first subset of contiguous frames of the digital video content item merged with the content item to the client device to have the client device render the content item.
少なくとも1つの態様は、デジタルビデオコンテンツを修正するためのシステムを対象とする。システムはデータ処理システムを含むことができる。データ処理システムは、少なくとも1つのプロセッサとメモリとを含むことができる。データ処理システムは、ビデオ信号プロセッサおよびコンテンツセレクタを実行することができる。ビデオ信号プロセッサは、複数のフレームを含むデジタルビデオコンテンツアイテムをパブリッシャデバイスから受信することができる。ビデオ信号プロセッサは、デジタルビデオコンテンツアイテムのフレームレートを決定することができる。ビデオ信号プロセッサは、複数のフレームを分析して、第1の静的部分を有する複数のフレームから連続するフレームの第1のサブセットを特定することができる。第1の静的部分は、2つ以上のフレームにわたって一致するピクセルを含む空間領域によって画定することができる。ビデオ信号プロセッサは、連続するフレームの第1のサブセットにおけるフレームの数およびフレームレートに基づいて、第1の静的部分の第1の持続時間を決定することができる。ビデオ信号プロセッサは、第1の静的部分の第1の持続時間をしきい値と比較することができる。ビデオ信号プロセッサは、デジタルビデオコンテンツアイテムに、連続するフレームの第1のサブセットの指示およびトリガをタグ付けすることができる。ビデオ信号プロセッサは、第1の静的部分の第1の持続時間がしきい値以上であることに応じて、このタグ付けを実行することができる。トリガは、第1の静的部分を上書きするために使用されるコンテンツについての要求を送信させることができる。この要求は、連続するフレームの第1のサブセットに先立った再生中における時間オフセットにおいて送信することができる。ビデオ信号プロセッサは、指示およびトリガとともにデジタルビデオコンテンツアイテムをクライアントデバイスに提供することができる。クライアントデバイスによってデジタルビデオコンテンツアイテムを受信すると、クライアントデバイスは、デジタルビデオコンテンツアイテムをレンダリングし、指示を解析して連続するフレームの第1のサブセットを特定し、トリガの実行に応じて、連続するフレームの第1のサブセットに先立った再生中における時間オフセットにおいて、コンテンツについての要求を送信することができる。コンテンツセレクタ構成要素は、コンテンツについての要求をクライアントデバイスから受信することができる。クライアントデバイスは、連続するフレームの第1のサブセットに先立った再生中における時間オフセットに基づいて要求を送信する。コンテンツセレクタ構成要素は、クライアントデバイスから受信されたコンテンツについての要求に応じてコンテンツアイテムを選択することができる。dpsは、コンテンツアイテムをクライアントデバイスに送信することができる。クライアントデバイスは、コンテンツアイテムを受信することができる。クライアントデバイスによってコンテンツアイテムを受信すると、クライアントデバイスは、連続するフレームの第1のサブセットの第1の静的部分においてコンテンツアイテムをレンダリングすることができる。 At least one aspect is intended for a system for modifying digital video content. The system can include a data processing system. The data processing system can include at least one processor and memory. The data processing system can run video signal processors and content selectors. The video signal processor can receive digital video content items containing multiple frames from the publisher device. The video signal processor can determine the frame rate of the digital video content item. The video signal processor can analyze a plurality of frames to identify a first subset of consecutive frames from a plurality of frames having a first static portion. The first static part can be defined by a spatial area containing matching pixels over two or more frames. The video-signal processor can determine the first duration of the first static part based on the number of frames and the frame rate in the first subset of consecutive frames. The video signal processor can compare the first duration of the first static part with the threshold. Video-signal processors can tag digital video content items with instructions and triggers for the first subset of consecutive frames. The video signal processor can perform this tagging depending on whether the first duration of the first static part is greater than or equal to the threshold. The trigger can send a request for the content used to overwrite the first static part. This request can be transmitted at a time offset during playback prior to the first subset of consecutive frames. The video signal processor can provide digital video content items to client devices along with instructions and triggers. Upon receiving the digital video content item by the client device, the client device renders the digital video content item, parses the instructions to identify the first subset of the contiguous frames, and responds to the execution of the trigger by the contiguous frames. Requests for content can be sent at a time offset during playback prior to the first subset of. The content selector component can receive requests for content from client devices. The client device sends a request based on the time offset during playback prior to the first subset of consecutive frames. The content selector component can select content items in response to requests for content received from client devices. dps can send content items to client devices. The client device can receive content items. Upon receiving the content item by the client device, the client device can render the content item in the first static part of the first subset of successive frames.
いくつかの実装形態では、ビデオ信号プロセッサは、複数のフレームを分析して、連続するフレームの第1のサブセットにおける第2の静的部分を特定する。ビデオ信号プロセッサは、第1の静的部分に関連する第1のパラメータおよび第2の静的部分に関連する第2のパラメータを特定することができる。ビデオ信号プロセッサは、第1のパラメータと第2のパラメータとの比較に基づいて、タグ付けのために第1の静的部分を選択することができる。いくつかの実装形態では、第1のパラメータは、背景色、色のグラデーション、サイズ、または位置のうちの少なくとも1つを含む。第2のパラメータは、背景色、色のグラデーション、サイズ、または位置のうちの少なくとも1つを含むことができる。 In some implementations, the video signal processor analyzes multiple frames to identify a second static part in the first subset of consecutive frames. The video signal processor can identify a first parameter related to the first static part and a second parameter related to the second static part. The video signal processor can select the first static part for tagging based on the comparison of the first parameter and the second parameter. In some implementations, the first parameter includes at least one of background color, color gradient, size, or position. The second parameter can include at least one of background color, color gradient, size, or position.
いくつかの実装形態では、ビデオ信号プロセッサは、複数のフレームを分析して、連続するフレームの第1のサブセットにおける第2の静的部分を特定することができる。ビデオ信号プロセッサは、第2の静的部分の第2の持続時間を特定することができる。ビデオ信号プロセッサは、第1の持続時間が第2の持続時間を超えることに基づいて、タグ付けのために第1の静的部分を選択することができる。 In some implementations, the video signal processor can analyze multiple frames to identify the second static part in the first subset of consecutive frames. The video signal processor can identify the second duration of the second static part. The video signal processor can select the first static part for tagging based on the first duration exceeding the second duration.
いくつかの実装形態では、ビデオ信号プロセッサは、デジタルビデオコンテンツアイテムにおける第2の静的部分を特定することができる。ビデオ信号プロセッサは、第2の静的部分を上書きするための認可をパブリッシャデバイスに要求することができる。ビデオ信号プロセッサは、第2の静的部分についてパブリッシャデバイスから負の認可を受信することができる。ビデオ信号プロセッサは、第2の静的部分をロックして、データ処理システムによって選択されたコンテンツで第2の静的部分を上書きするのを阻止することができる。 In some implementations, the video signal processor can identify a second static part of the digital video content item. The video-signal processor can request the publisher device for authorization to overwrite the second static part. The video signal processor can receive a negative authorization from the publisher device for the second static part. The video signal processor can lock the second static part to prevent the content selected by the data processing system from overwriting the second static part.
いくつかの実装形態では、ビデオ信号プロセッサは、複数のフレームにおける連続するフレームにわたるピクセルの変化に基づいて第1の静的部分を特定することができる。いくつかの実装形態では、ビデオ信号プロセッサは、パブリッシャデバイスから背景色の指示を受信して第1の静的部分の特定を制御することができる。ビデオ信号プロセッサは、背景色の指示を使用して、複数のフレームにおける連続するフレームにわたるピクセル特性に基づいて第1の静的部分を特定することができる。 In some implementations, the video signal processor can identify the first static portion based on pixel changes over successive frames in multiple frames. In some implementations, the video-signal processor can receive background color instructions from the publisher device to control the identification of the first static part. The video signal processor can use the background color indication to identify the first static part based on the pixel characteristics over consecutive frames in multiple frames.
いくつかの実装形態では、コンテンツセレクタは、第1の静的部分に関連する1つもしくは複数の特性を特定する。1つもしくは複数の特性は、テキスト、フォント、顔、オブジェクトタイプ、または色のうちの少なくとも1つを含むことができる。コンテンツセレクタは、第1の静的部分に関連する1つもしくは複数の特性に基づいてコンテンツアイテムを選択することができる。 In some implementations, the content selector identifies one or more characteristics associated with the first static part. One or more properties can include at least one of text, font, face, object type, or color. The content selector can select content items based on one or more characteristics associated with the first static part.
いくつかの実装形態では、ビデオ信号プロセッサは、クライアントデバイスのメモリにプレロードされるデジタルビデオコンテンツアイテムの量を特定することができる。ビデオ信号プロセッサは、この量に基づいて時間オフセットを設定し、クライアントデバイスに、この量がクライアントデバイスのメモリにプレロードされることに先立ってコンテンツについての要求を送信させることができる。 In some implementations, the video-signal processor can determine the amount of digital video content items that are preloaded into the memory of the client device. The video-signal processor can set a time offset based on this amount, causing the client device to send a request for content prior to preloading this amount into the client device's memory.
いくつかの実装形態では、ビデオ信号プロセッサは、デジタルビデオコンテンツアイテムの連続するフレームの第1のサブセットの第1の静的部分においてコンテンツアイテムをマージすることができる。ビデオ信号プロセッサは、コンテンツアイテムとマージされたデジタルビデオコンテンツアイテムの連続するフレームの第1のサブセットをクライアントデバイスに送信して、クライアントデバイスにコンテンツアイテムをレンダリングさせることができる。 In some implementations, the video signal processor can merge content items in the first static part of the first subset of consecutive frames of digital video content items. The video-signal processor can send the first subset of consecutive frames of the digital video content item merged with the content item to the client device to render the content item on the client device.
いくつかの実装形態では、ビデオ信号プロセッサは、ロジスティック回帰を使用して複数のフレームを分析し、2つ以上のフレームにわたって一致するピクセルを有する空間領域によって画定される第1の静的部分を特定することができる。 In some implementations, the video-signal processor uses logistic regression to analyze multiple frames and identify a first static part defined by a spatial region with matching pixels over two or more frames. can do.
動作は図面において特定の順序で示されているが、そのような動作を図示の特定の順序で実行することもまたは連続的に実行することも必要とされず、必ずしも図示の動作のすべてを実行する必要はない。本明細書で説明する動作は異なる順序で実行することができる。 Although the actions are shown in the drawings in a particular order, it is not necessary to perform such actions in the particular order shown or in sequence, and not necessarily to perform all of the actions shown. do not have to. The operations described herein can be performed in a different order.
様々な別々のシステム構成要素は、必ずしもすべての実装形態において分離する必要はなく、前述のプログラム構成要素は単一のハードウェアまたはソフトウェア製品に含めることができる。たとえば、ビデオプレプロセッサ206、コンテンツセレクタ226、またはビデオエディタ214は、単一の構成要素、app、もしくはプログラム、または1つもしくは複数の処理回路を有する論理デバイス、またはデータ処理システム202の1つもしくは複数のサーバの一部とすることができる。
The various separate system components do not necessarily have to be separated in all implementations, and the program components described above can be included in a single hardware or software product. For example, the video preprocessor 206, content selector 226, or
いくつかの例示的な実装形態について説明したが、上記のことは例示的であり制限ではなく、一例として提示されていることは明らかである。特に、本明細書で提示された例の多くは方法のための行為またはシステム要素の特定の組合せを伴うが、それらの行為およびそれらの要素を他の方法で組み合わせて同じ目的を実現してもよい。一実装形態に関連して説明した行為、要素、および特徴は、他の実装形態における同様な役割から除外されるものではない。 Although some exemplary implementations have been described, it is clear that the above is exemplary, not limiting, and is presented as an example. In particular, many of the examples presented herein involve specific combinations of actions or system elements for a method, but those actions and those elements can be combined in other ways to achieve the same purpose. good. The actions, elements, and features described in relation to one implementation are not excluded from similar roles in other implementations.
本明細書で使用される表現および用語は、説明のためのものであり、限定と見なされるべきではない。「含む」、「備える」、「有する」、「含有する」、「伴う」、「を特徴とする」、「ということを特徴とする」、およびそれらの変形例の使用は、その後に列挙される項目、その均等物、追加の項目、ならびにその後に列挙される項目から排他的に構成される代替実装形態を包含することを意味する。一実装形態では、本明細書で説明するシステムおよび方法は、前述の要素、行為、または構成要素のうちの複数またはすべての要素、行為、または構成要素の各々の1つの組合せからなる。 The expressions and terms used herein are for illustration purposes only and should not be considered limiting. The use of "contains", "provides", "has", "contains", "accompanied", "features", "features", and variants thereof are listed thereafter. It means to include an alternative implementation exclusively composed of items, their equivalents, additional items, and the items listed thereafter. In one implementation, the systems and methods described herein consist of a combination of each one of a plurality or all of the above-mentioned elements, actions, or components, actions, or components.
単数形で参照されるシステムおよび方法の実装形態または要素または行為のあらゆる参照はまた、複数のこれらの要素を含む実装形態を包含してもよく、本明細書の任意の実装形態または要素または行為の複数形でのあらゆる参照は、単一の要素のみを含む実装形態を包含してもよい。単数形または複数形での参照は、現在開示されているシステムもしくは方法、その構成要素、行為、または要素を単一または複数の構成に限定するものではない。任意の情報、行為、または要素に基づく任意の行為または要素の参照は、その行為または要素が任意の情報、行為、または要素に部分的に基づく実装形態を含んでもよい。 Any reference to an implementation or element or act of a system and method referenced in the plural may also include an implementation that includes more than one of these elements, and any implementation or element or act herein. Any reference in the plural of may include an implementation containing only a single element. References in the singular or plural form do not limit the currently disclosed system or method, its components, actions, or elements to a single or multiple components. References to any action or element based on any information, action, or element may include an implementation in which the action or element is partially based on any information, action, or element.
本明細書で開示する任意の実装形態は、任意の他の実装形態または実施形態と組み合わされてもよく、「実装形態」、「いくつかの実装形態」、「一実装形態」などの参照は、必ずしも相互に排他的であるとは限らず、実装形態に関連して説明した特定の特徴、構造、または特性は、少なくとも1つの実装形態または実施形態に含まれてもよい。本明細書で使用するそのような用語は、必ずしもすべてが同じ実装形態を指すとは限らない。任意の実装形態が、本明細書で開示する態様および実装形態に整合する任意の方法で包括的または排他的に任意の他の実装形態と組み合わされてもよい。 Any of the embodiments disclosed herein may be combined with any other implementation or embodiment, and references such as "implementation", "some implementations", "one implementation" etc. , Not necessarily mutually exclusive, and the particular features, structures, or properties described in relation to an implementation may be included in at least one implementation or embodiment. As used herein, not all such terms refer to the same implementation. Any implementation may be comprehensively or exclusively combined with any other implementation in any manner consistent with the aspects and implementations disclosed herein.
「または」の参照は、「または」を使用して説明したあらゆる用語が、それらの用語のうちの1つ、複数、またはすべてのいずれも指し得るように包括的なものと解釈されてもよい。たとえば、「'A'および'B'の少なくとも1つ」の参照は、'A'のみ、'B'のみ、ならびに'A'と'B'の両方を含むことができる。「備える」または他のオープンな用語とともに使用されるそのような参照は、追加の項目を含むことができる。 The "or" reference may be construed as comprehensive so that any term described using "or" can refer to one, more, or all of those terms. .. For example, a reference to "at least one of'A'and'B'" can include only'A', only'B', and both'A'and'B'. Such references used in conjunction with "provide" or other open terms may include additional items.
図面、詳細な説明、または任意のクレームにおける技術的要素の後に参照符号が示されている場合、その参照符号は、図面、詳細な説明、およびクレームの明瞭さを増すために含められている。したがって、参照符号があってもなくてもクレーム要素の範囲に限定的な効果を有さない。 Where a reference code is given after the drawing, detailed description, or technical element in any claim, the reference code is included to increase the clarity of the drawing, detailed description, and claim. Therefore, it has no limiting effect on the range of claim elements with or without a reference code.
本明細書で説明するシステムおよび方法は、その特徴から逸脱せずに他の特定の形態で具体化されてもよい。上記の実装形態は例示的であり、前述のシステムおよび方法を限定しない。したがって、本明細書で説明するシステムおよび方法の範囲は、上記の説明ではなく、添付の特許請求の範囲によって示され、クレームの均等の意味および範囲内の変更はその範囲内に含まれる。 The systems and methods described herein may be embodied in other particular forms without departing from their characteristics. The above implementation is exemplary and does not limit the systems and methods described above. Accordingly, the scope of the systems and methods described herein is set forth by the appended claims rather than by the description above, and the equal meaning of the claims and changes within the scope are included within that scope.
100 ビデオプレーヤアプリケーション
102 デジタルビデオコンテンツアイテム
102'、120'' タグ付きデジタルビデ
104 ニュースキャスター
106 進捗バー
108 再生ボタン
110 先送りボタン
112 音量制御インターフェース
114 指示
116 クローズドキャプショントグル
118 全画面ボタン
120 バナーコンテンツスロット
122 ブランクスペース
124、126、128、130、132、134 候補コンテンツスロット
136 最大コンテンツスロット
138 最大コンテンツスロット
142、144、146 持続時間
152 要求
154 応答
156 コンテンツについての要求
158 送信
160 時間オフセット
162 コンテンツスロット持続時間
164 埋め込みコンテンツスロット
170 コンテンツ要求
172 送信
174 第2のコンテンツスロット
176 第2の時間オフセット
200 システム
202 データ処理システム
204 ビデオ信号プロセッサ
205 ネットワーク
206 ビデオプレプロセッサ
208 スロット検出器
210 オフセット計算器
212 メタデータタグ付け器
214 ビデオエディタ
216 データリポジトリ
218 しきい値
220 メタデータ
222 時間オフセット
224 コンテンツデータ
226 コンテンツセレクタ
228 クライアントコンピューティングデバイス
230 クライアントコンピューティングデバイス
232 コンテンツパブリッシャ
234 コンテンツプロバイダコンピューティングデバイス
236 ビデオプレーヤアプリケーション
238 デジタルビデオ
400 コンピュータシステム
405 バス
410 プロセッサ
415 メインメモリ
420 読取り専用メモリ(ROM)
425 記憶デバイス
430 入力デバイス
435 ディスプレイ
100 video player application
102 Digital Video Content Items
102', 120'' Tagged Digital Bidet
104 Newscaster
106 progress bar
108 Play button
110 forward button
112 Volume control interface
114 instructions
116 Closed caption toggle
118 Full screen button
120 banner content slot
122 blank space
124, 126, 128, 130, 132, 134 Candidate content slots
136 Maximum Content Slots
138 Maximum content slots
142, 144, 146 Duration
152 Request
154 Response
156 Content Requests
158 Send
160 hours offset
162 Content slot duration
164 Embedded Content Slots
170 Content Request
172 Send
174 Second content slot
176 Second time offset
200 system
202 Data processing system
204 Video Signal Processor
205 network
206 video preprocessor
208 slot detector
210 offset calculator
212 Metadata tagging device
214 Video Editor
216 Data repository
218 threshold
220 metadata
222 time offset
224 Content data
226 Content Selector
228 Client computing device
230 client computing device
232 Content Publisher
234 Content Provider Computing Device
236 Video player application
238 Digital Video
400 computer system
405 bus
410 processor
415 main memory
420 Read-only memory (ROM)
425 Storage device
430 input device
435 display
Claims (21)
データ処理システムによって、複数のフレームを含むデジタルビデオコンテンツアイテムをパブリッシャデバイスから受信するステップと、
前記データ処理システムによって実行されるビデオ信号プロセッサによって、前記デジタルビデオコンテンツアイテムのフレームレートを決定するステップと、
前記ビデオ信号プロセッサによって、前記複数のフレームを分析して、第1の静的部分を有する連続するフレームの第1のサブセットを前記複数のフレームから特定するステップであって、前記第1の静的部分が、2つ以上のフレームにわたって一致するピクセルを含む空間領域によって画定される、ステップと、
前記ビデオ信号プロセッサによって、前記連続するフレームの第1のサブセットにおけるフレームの数および前記フレームレートに基づいて、前記第1の静的部分の第1の持続時間を決定するステップと、
前記ビデオ信号プロセッサによって、前記第1の静的部分の前記第1の持続時間をしきい値と比較するステップと、
前記ビデオ信号プロセッサによって、前記第1の静的部分の前記第1の持続時間が前記しきい値以上であることに応じて、前記デジタルビデオコンテンツアイテムに、前記連続するフレームの第1のサブセットの指示と、前記連続するフレームの第1のサブセットに先立った再生中における時間オフセットにおいて前記第1の静的部分を上書きするために使用されるコンテンツについての要求を送信させるトリガとをタグ付けするステップと、
前記ビデオ信号プロセッサによって、前記指示および前記トリガとともに前記デジタルビデオコンテンツアイテムをクライアントデバイスに提供するステップであって、前記デジタルビデオコンテンツアイテムを受信すると、前記クライアントデバイスに、前記デジタルビデオコンテンツアイテムをレンダリングし、前記指示を解析して前記連続するフレームの第1のサブセットを特定し、前記トリガの実行に応じて、前記連続するフレームの第1のサブセットに先立った再生中における前記時間オフセットにおいて、前記コンテンツについての要求を送信することをさせる、ステップと、
前記ビデオ信号プロセッサによって、前記コンテンツについての要求を前記クライアントデバイスから受信するステップであって、前記要求が、前記連続するフレームの第1のサブセットに先立った再生中における前記時間オフセットに基づいて前記クライアントデバイスによって送信される、ステップと、
前記データ処理システムによって実行されるコンテンツセレクタによって、前記クライアントデバイスから受信された前記コンテンツについての要求に応じてコンテンツアイテムを選択するステップと、
前記データ処理システムによって、前記コンテンツアイテムを前記クライアントデバイスに送信するステップであって、前記コンテンツアイテムを受信すると、前記クライアントデバイスに、前記連続するフレームの第1のサブセットの前記第1の静的部分において前記コンテンツアイテムをレンダリングすることをさせる、ステップとを含む方法。 A way to combine digital video content
The step of receiving a digital video content item containing multiple frames from the publisher device by the data processing system,
The step of determining the frame rate of the digital video content item by the video signal processor executed by the data processing system, and
A step of analyzing the plurality of frames by the video signal processor to identify a first subset of consecutive frames having a first static portion from the plurality of frames, wherein the first static. With steps, the parts are defined by a spatial area containing matching pixels over two or more frames.
A step of determining the first duration of the first static portion by the video signal processor based on the number of frames in the first subset of the contiguous frames and the frame rate.
A step of comparing the first duration of the first static portion with a threshold by the video signal processor.
Depending on the video signal processor that the first duration of the first static portion is greater than or equal to the threshold value, the digital video content item is confined to a first subset of the contiguous frames. A step of tagging instructions with a trigger that causes a request for content to be used to overwrite the first static portion at a time offset during playback prior to the first subset of the contiguous frames. When,
It is a step of providing the digital video content item to the client device together with the instruction and the trigger by the video signal processor, and when the digital video content item is received, the digital video content item is rendered on the client device. , The instructions are analyzed to identify the first subset of the contiguous frames, and in response to the execution of the trigger, the content at the time offset during playback prior to the first subset of the contiguous frames. Let me send you a request about, step and
The step of receiving a request for the content from the client device by the video signal processor, the client based on the time offset during playback prior to the first subset of the contiguous frames. Steps and steps sent by the device,
A step of selecting a content item in response to a request for the content received from the client device by a content selector executed by the data processing system.
The step of transmitting the content item to the client device by the data processing system, upon receipt of the content item, to the client device, said first static portion of the first subset of the contiguous frames. A method including a step that causes the content item to be rendered in.
データ処理システムによって、前記第1の静的部分に関連する第1のパラメータおよび前記第2の静的部分に関連する第2のパラメータを特定するステップと、
前記第1のパラメータと前記第2のパラメータとの比較に基づいて、タグ付けのために前記第1の静的部分を選択するステップとを含む、請求項1に記載の方法。 A step of analyzing the plurality of frames by the data processing system to identify a second static part in the first subset of the contiguous frames.
A step of identifying a first parameter related to the first static part and a second parameter related to the second static part by the data processing system.
The method of claim 1, comprising the step of selecting the first static portion for tagging based on a comparison of the first parameter with the second parameter.
前記データ処理システムによって、前記第2の静的部分の第2の持続時間を特定するステップと、
前記データ処理システムによって、前記第1の持続時間が前記第2の持続時間を超えることに基づいて、タグ付けのために前記第1の静的部分を選択するステップとを含む、請求項1に記載の方法。 A step of analyzing the plurality of frames by the data processing system to identify a second static part in the first subset of the contiguous frames.
The step of identifying the second duration of the second static part by the data processing system, and
Claim 1 comprises the step of selecting the first static portion for tagging based on the first duration exceeding the second duration by the data processing system. The method described.
前記データ処理システムによって、前記パブリッシャデバイスから、前記第2の静的部分を上書きするための認可を前記パブリッシャデバイスに要求するステップと、
前記データ処理システムによって、前記第2の静的部分についての負の認可を前記パブリッシャデバイスから受信するステップと、
前記データ処理システムによって、前記第2の静的部分をロックして、前記データ処理システムによって選択されたコンテンツで前記第2の静的部分を上書きするのを阻止するステップとを含む、請求項1に記載の方法。 A step of identifying a second static part of the digital video content item by the data processing system.
A step of requesting the publisher device for authorization to overwrite the second static portion from the publisher device by the data processing system.
A step of receiving a negative authorization for the second static portion from the publisher device by the data processing system.
1. The data processing system includes a step of locking the second static portion and preventing the content selected by the data processing system from overwriting the second static portion. The method described in.
前記データ処理システムによって、前記背景色の前記指示を使用して、前記複数のフレームにおける連続するフレームにわたるピクセル特性に基づいて前記第1の静的部分を特定するステップとを含む、請求項1から6のいずれか一項に記載の方法。 A step of receiving a background color instruction from the publisher device by the data processing system to control the identification of the first static portion.
From claim 1, the data processing system comprises the step of identifying the first static portion based on pixel characteristics over successive frames in the plurality of frames using the indication of the background color. The method according to any one of 6.
前記データ処理システムによって、前記量に少なくとも部分的に基づいて前記時間オフセットを設定し、前記クライアントデバイスに、前記量が前記クライアントデバイスの前記メモリにプレロードされることに先立って前記コンテンツについての要求を送信させるステップとを含む、請求項1から8のいずれか一項に記載の方法。 A step of determining the amount of the digital video content item preloaded into the memory of the client device by the data processing system.
The data processing system sets the time offset based at least in part on the quantity and makes a request to the client device for the content prior to preloading the quantity into the memory of the client device. The method according to any one of claims 1 to 8, including the step of transmitting.
前記データ処理システムによって、前記コンテンツアイテムとマージされた前記デジタルビデオコンテンツアイテムの前記連続するフレームの第1のサブセットを前記クライアントデバイスに送信して前記クライアントデバイスに前記コンテンツアイテムをレンダリングさせるステップとを含む、請求項1から9のいずれか一項に記載の方法。 A step of merging the content items in the first static portion of the first subset of the contiguous frames of the digital video content item by the data processing system.
The data processing system includes sending a first subset of the contiguous frames of the digital video content item merged with the content item to the client device to cause the client device to render the content item. , The method according to any one of claims 1 to 9.
少なくとも1つのプロセッサとメモリとを備えるデータ処理システムであって、ビデオ信号プロセッサおよびコンテンツセレクタを実行する、データ処理システムを備え、
前記ビデオ信号プロセッサは、
複数のフレームを含むデジタルビデオコンテンツアイテムをパブリッシャデバイスから受信することと、
前記デジタルビデオコンテンツアイテムのフレームレートを決定することと、
前記複数のフレームを分析して、第1の静的部分を有する連続するフレームの第1のサブセットを前記複数のフレームから特定することであって、前記第1の静的部分が、2つ以上のフレームにわたって一致するピクセルを含む空間領域によって画定される、ことと、
前記連続するフレームの第1のサブセットにおけるフレームの数および前記フレームレートに基づいて、前記第1の静的部分の第1の持続時間を決定することと、
前記第1の静的部分の前記第1の持続時間をしきい値と比較することと、
前記第1の静的部分の前記第1の持続時間が前記しきい値以上であることに応じて、前記デジタルビデオコンテンツアイテムに、前記連続するフレームの第1のサブセットの指示と、前記連続するフレームの第1のサブセットに先立った再生中における時間オフセットにおいて前記第1の静的部分を上書きするために使用されるコンテンツについての要求を送信させるトリガとをタグ付けすることと、
前記指示および前記トリガとともに前記デジタルビデオコンテンツアイテムをクライアントデバイスに提供することであって、前記デジタルビデオコンテンツアイテムを受信すると、前記クライアントデバイスに、前記デジタルビデオコンテンツアイテムをレンダリングし、前記指示を解析して前記連続するフレームの第1のサブセットを特定し、前記トリガの実行に応じて、前記連続するフレームの第1のサブセットに先立った再生中における前記時間オフセットにおいて、前記コンテンツについての要求を送信することをさせる、こととを行うように構成され、
前記コンテンツセレクタは、
前記コンテンツについての要求を前記クライアントデバイスから受信することであって、前記要求が、前記連続するフレームの第1のサブセットに先立った再生中における前記時間オフセットに基づいて前記クライアントデバイスによって送信される、ことと、
前記クライアントデバイスから受信された前記コンテンツについての要求に応じてコンテンツアイテムを選択することとを行うように構成され、
前記データ処理システムは、
前記コンテンツアイテムを前記クライアントデバイスに送信することであって、前記コンテンツアイテムを受信すると、前記クライアントデバイスに、前記連続するフレームの第1のサブセットの前記第1の静的部分において前記コンテンツアイテムをレンダリングすることをさせる、こととを行うようにさらに構成されるシステム。 A system for combining digital video content
A data processing system with at least one processor and memory, including a data processing system that executes a video signal processor and content selector.
The video signal processor
Receiving digital video content items containing multiple frames from publisher devices,
Determining the frame rate of the digital video content item
Analyzing the plurality of frames to identify a first subset of consecutive frames having a first static part from the plurality of frames, wherein the first static part is two or more. Is defined by a spatial area containing matching pixels over the frame of
Determining the first duration of the first static portion based on the number of frames in the first subset of the contiguous frames and the frame rate.
Comparing the first duration of the first static part with the threshold,
Depending on whether the first duration of the first static portion is greater than or equal to the threshold, the digital video content item is instructed by the first subset of the contiguous frames and the contiguous. Tagging with a trigger that causes a request for content to be used to overwrite the first static part at a time offset during playback prior to the first subset of frames.
Providing the digital video content item to the client device together with the instruction and the trigger, upon receiving the digital video content item, the client device renders the digital video content item and analyzes the instruction. Identify a first subset of the contiguous frames and, in response to execution of the trigger, transmit a request for the content at the time offset during playback prior to the first subset of the contiguous frames. Configured to do things, do things,
The content selector is
Receiving a request for the content from the client device, the request being transmitted by the client device based on the time offset during playback prior to the first subset of the contiguous frames. That and
It is configured to select a content item in response to a request for the content received from the client device.
The data processing system
Sending the content item to the client device, upon receiving the content item, renders the content item to the client device in the first static portion of the first subset of the contiguous frames. A system that is further configured to do and do things.
前記複数のフレームを分析して、前記連続するフレームの第1のサブセットにおける第2の静的部分を特定することと、
前記第1の静的部分に関連する第1のパラメータおよび前記第2の静的部分に関連する第2のパラメータを特定することと、
前記第1のパラメータと前記第2のパラメータとの比較に基づいて、タグ付けのために前記第1の静的部分を選択することとを行うようにさらに構成される、請求項11に記載のシステム。 The video signal processor
Analyzing the plurality of frames to identify a second static part in the first subset of the contiguous frames.
Identifying the first parameter related to the first static part and the second parameter related to the second static part,
11. system.
前記複数のフレームを分析して、前記連続するフレームの第1のサブセットにおける第2の静的部分を特定することと、
前記第2の静的部分の第2の持続時間を特定することと、
前記第1の持続時間が前記第2の持続時間を超えることに基づいて、タグ付けのために前記第1の静的部分を選択することとを行うようにさらに構成される、請求項11に記載のシステム。 The video signal processor
Analyzing the plurality of frames to identify a second static part in the first subset of the contiguous frames.
Identifying the second duration of the second static part,
11. The first duration is further configured to select the first static portion for tagging based on the first duration exceeding the second duration. Described system.
前記デジタルビデオコンテンツアイテムにおける第2の静的部分を特定することと、
前記パブリッシャデバイスから、前記第2の静的部分を上書きするための認可を前記パブリッシャデバイスに要求することと、
前記第2の静的部分についての負の認可を前記パブリッシャデバイスから受信することと、
前記第2の静的部分をロックして、前記データ処理システムによって選択されたコンテンツで前記第2の静的部分を上書きするのを阻止することとを行うようにさらに構成される、請求項11に記載のシステム。 The video signal processor
Identifying the second static part of the digital video content item
Requesting authorization from the publisher device to overwrite the second static part and
Receiving a negative authorization for the second static part from the publisher device,
11. The second static portion is further configured to lock the second static portion and prevent the content selected by the data processing system from overwriting the second static portion. The system described in.
前記複数のフレームにおける連続するフレームにわたるピクセルの変化に基づいて前記第1の静的部分を特定するようにさらに構成される、請求項11から15のいずれか一項に記載のシステム。 The video signal processor
The system according to any one of claims 11 to 15, further configured to identify the first static portion based on pixel changes over successive frames in the plurality of frames.
前記パブリッシャデバイスから背景色の指示を受信して、前記第1の静的部分の特定を制御することと、
前記背景色の前記指示を使用して、前記複数のフレームにおける連続するフレームにわたるピクセル特性に基づいて前記第1の静的部分を特定することとを行うようにさらに構成される、請求項11から16のいずれか一項に記載のシステム。 The video signal processor
To control the identification of the first static part by receiving the background color instruction from the publisher device,
From claim 11, wherein the indication of the background color is further configured to identify the first static portion based on pixel characteristics over successive frames in the plurality of frames. The system according to any one of 16.
前記第1の静的部分のサイズ、前記第1の静的部分の位置、前記第1の静的部分の持続時間、前記第1の静的部分の背景色、前記第1の静的部分に近接する人、前記デジタルビデオコンテンツの主題、前記デジタルビデオコンテンツに関連するキーワード、前記デジタルビデオコンテンツ上に表示されるテキストのうちの少なくとも1つに基づいて前記コンテンツアイテムを選択することとを行うようにさらに構成される、請求項11から17のいずれか一項に記載のシステム。 The content selector is
To the size of the first static part, the position of the first static part, the duration of the first static part, the background color of the first static part, and the first static part. To select the content item based on a person in close proximity, the subject of the digital video content, keywords related to the digital video content, and at least one of the text displayed on the digital video content. The system according to any one of claims 11 to 17, further comprising.
前記クライアントデバイスのメモリにプレロードされる前記デジタルビデオコンテンツアイテムの量を特定することと、
前記量に少なくとも部分的に基づいて前記時間オフセットを設定し、前記クライアントデバイスに、前記量が前記クライアントデバイスの前記メモリにプレロードされることに先立って前記コンテンツについての要求を送信させることとを行うようにさらに構成される、請求項11から18のいずれか一項に記載のシステム。 The video signal processor
Identifying the amount of the digital video content item preloaded into the memory of the client device and
The time offset is set at least in part based on the quantity to cause the client device to send a request for the content prior to the quantity being preloaded into the memory of the client device. The system according to any one of claims 11 to 18, further configured as such.
前記デジタルビデオコンテンツアイテムの前記連続するフレームの第1のサブセットの前記第1の静的部分において前記コンテンツアイテムをマージすることと、
前記コンテンツアイテムとマージされた前記デジタルビデオコンテンツアイテムの前記連続するフレームの第1のサブセットを前記クライアントデバイスに送信して前記クライアントデバイスに前記コンテンツアイテムをレンダリングさせることとを行うようにさらに構成される、請求項11から19のいずれか一項に記載のシステム。 The video signal processor
Merging the content item in the first static portion of the first subset of the contiguous frames of the digital video content item.
It is further configured to send a first subset of the contiguous frames of the digital video content item merged with the content item to the client device to cause the client device to render the content item. , The system according to any one of claims 11 to 19.
ロジスティック回帰を使用して前記複数のフレームを分析し、2つ以上のフレームにわたって一致するピクセルを含む空間領域によって画定される前記第1の静的部分を特定するようにさらに構成される、請求項11から20のいずれか一項に記載のシステム。 The video signal processor
Claims that use logistic regression to analyze the plurality of frames and further configure to identify the first static portion defined by a spatial region containing matching pixels over two or more frames. The system according to any one of 11 to 20.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2017/065381 WO2019112616A1 (en) | 2017-12-08 | 2017-12-08 | Modifying digital video content |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2020528680A JP2020528680A (en) | 2020-09-24 |
JP6920475B2 true JP6920475B2 (en) | 2021-08-18 |
Family
ID=60937881
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019565935A Active JP6920475B2 (en) | 2017-12-08 | 2017-12-08 | Modify digital video content |
Country Status (6)
Country | Link |
---|---|
US (3) | US11044521B2 (en) |
EP (1) | EP3616407A1 (en) |
JP (1) | JP6920475B2 (en) |
KR (1) | KR102200317B1 (en) |
CN (2) | CN113965777A (en) |
WO (1) | WO2019112616A1 (en) |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR102200317B1 (en) | 2017-12-08 | 2021-01-08 | 구글 엘엘씨 | Digital video content modification |
US10986402B2 (en) | 2018-07-11 | 2021-04-20 | Qualcomm Incorporated | Time signaling for media streaming |
US11823421B2 (en) * | 2019-03-14 | 2023-11-21 | Nokia Technologies Oy | Signalling of metadata for volumetric video |
US10951563B2 (en) * | 2019-06-27 | 2021-03-16 | Rovi Guides, Inc. | Enhancing a social media post with content that is relevant to the audience of the post |
JP7441735B2 (en) | 2020-06-08 | 2024-03-01 | 株式会社ソニー・インタラクティブエンタテインメント | Distribution server and image distribution method |
US11582502B2 (en) * | 2020-07-22 | 2023-02-14 | Yandex Europe Ag | Method and system for uploading media objects unto a web platform |
CN115668179A (en) | 2021-01-07 | 2023-01-31 | 谷歌有限责任公司 | Selecting and providing digital components during content display |
Family Cites Families (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
SG119229A1 (en) * | 2004-07-30 | 2006-02-28 | Agency Science Tech & Res | Method and apparatus for insertion of additional content into video |
KR100610690B1 (en) | 2005-06-29 | 2006-08-09 | 엔에이치엔(주) | Method for inserting flash moving picture into 3 dimensional screen and record medium for the same |
US20080066107A1 (en) * | 2006-09-12 | 2008-03-13 | Google Inc. | Using Viewing Signals in Targeted Video Advertising |
US8170396B2 (en) * | 2007-04-16 | 2012-05-01 | Adobe Systems Incorporated | Changing video playback rate |
GB0809631D0 (en) | 2008-05-28 | 2008-07-02 | Mirriad Ltd | Zonesense |
US20090327346A1 (en) | 2008-06-30 | 2009-12-31 | Nokia Corporation | Specifying media content placement criteria |
US20100043046A1 (en) | 2008-07-07 | 2010-02-18 | Shondip Sen | Internet video receiver |
US20100154007A1 (en) | 2008-12-17 | 2010-06-17 | Jean Touboul | Embedded video advertising method and system |
US9009066B2 (en) * | 2009-02-12 | 2015-04-14 | Echostar Technologies L.L.C. | Advertisement management for live internet multimedia content |
US20110080521A1 (en) * | 2009-10-05 | 2011-04-07 | Sony Corporation | On-screen display to highlight what a demo video is meant to illustrate |
KR101737084B1 (en) * | 2009-12-07 | 2017-05-17 | 삼성전자주식회사 | Method and apparatus for streaming by inserting another content to main content |
US20110292992A1 (en) * | 2010-05-28 | 2011-12-01 | Microsoft Corporation | Automating dynamic information insertion into video |
JP5465620B2 (en) * | 2010-06-25 | 2014-04-09 | Ｋｄｄｉ株式会社 | Video output apparatus, program and method for determining additional information area to be superimposed on video content |
US20120072957A1 (en) * | 2010-09-20 | 2012-03-22 | Google Inc. | Providing Dynamic Content with an Electronic Video |
KR101105467B1 (en) | 2011-03-30 | 2012-01-17 | 주식회사 엑스디웍스 | A advertisement providing method using composite video |
CN102254160B (en) * | 2011-07-12 | 2013-06-12 | 央视国际网络有限公司 | Video score detecting and recognizing method and device |
CN102339625B (en) * | 2011-09-20 | 2014-07-30 | 清华大学 | Video object level time domain editing method and system |
US20130268621A1 (en) * | 2012-04-08 | 2013-10-10 | Broadcom Corporation | Transmission of video utilizing static content information from video source |
CN105103566B (en) * | 2013-03-15 | 2019-05-21 | 构造数据有限责任公司 | Video clip is for identification so as to the system and method that show contextual content |
US9467750B2 (en) * | 2013-05-31 | 2016-10-11 | Adobe Systems Incorporated | Placing unobtrusive overlays in video content |
KR101610007B1 (en) * | 2014-11-13 | 2016-04-08 | 주식회사 그로브소프트 | Method for generating video data |
US9432703B2 (en) * | 2014-11-17 | 2016-08-30 | TCL Research America Inc. | Method and system for inserting contents into video presentations |
EP3262523B1 (en) * | 2015-02-27 | 2019-12-04 | DivX, LLC | System and method for frame duplication and frame extension in live video encoding and streaming |
US10430664B2 (en) * | 2015-03-16 | 2019-10-01 | Rohan Sanil | System for automatically editing video |
KR101741747B1 (en) | 2016-06-09 | 2017-05-31 | (주)매직비젼 | Apparatus and method for processing real time advertisement insertion on broadcast |
KR102200317B1 (en) | 2017-12-08 | 2021-01-08 | 구글 엘엘씨 | Digital video content modification |
-
2017
- 2017-12-08 KR KR1020197034916A patent/KR102200317B1/en active IP Right Grant
- 2017-12-08 CN CN202111107479.5A patent/CN113965777A/en active Pending
- 2017-12-08 CN CN201780091424.5A patent/CN110692251B/en active Active
- 2017-12-08 WO PCT/US2017/065381 patent/WO2019112616A1/en unknown
- 2017-12-08 EP EP17826024.6A patent/EP3616407A1/en not_active Withdrawn
- 2017-12-08 JP JP2019565935A patent/JP6920475B2/en active Active
- 2017-12-08 US US16/625,576 patent/US11044521B2/en active Active
-
2021
- 2021-05-19 US US17/325,065 patent/US11412293B2/en active Active
-
2022
- 2022-08-04 US US17/881,262 patent/US11974013B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
JP2020528680A (en) | 2020-09-24 |
US20220377412A1 (en) | 2022-11-24 |
WO2019112616A1 (en) | 2019-06-13 |
KR102200317B1 (en) | 2021-01-08 |
CN110692251A (en) | 2020-01-14 |
US11412293B2 (en) | 2022-08-09 |
CN110692251B (en) | 2021-10-12 |
US11044521B2 (en) | 2021-06-22 |
KR20190137924A (en) | 2019-12-11 |
US20210297736A1 (en) | 2021-09-23 |
EP3616407A1 (en) | 2020-03-04 |
US11974013B2 (en) | 2024-04-30 |
US20210084368A1 (en) | 2021-03-18 |
CN113965777A (en) | 2022-01-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6920475B2 (en) | Modify digital video content | |
US11902633B2 (en) | Dynamic overlay video advertisement insertion | |
US10650861B2 (en) | Video summarization and collaboration systems and methods | |
US10681391B2 (en) | Computerized system and method for automatic highlight detection from live streaming media and rendering within a specialized media player | |
US20190289359A1 (en) | Intelligent video interaction method | |
US9218101B2 (en) | Displaying estimated social interest in time-based media | |
US9002175B1 (en) | Automated video trailer creation | |
US20160014482A1 (en) | Systems and Methods for Generating Video Summary Sequences From One or More Video Segments | |
US10334300B2 (en) | Systems and methods to present content | |
US20150293928A1 (en) | Systems and Methods for Generating Personalized Video Playlists | |
US11140451B2 (en) | Representation of content based on content-level features | |
US20150195626A1 (en) | Augmented media service providing method, apparatus thereof, and system thereof | |
US9524278B2 (en) | Systems and methods to present content | |
US20200021872A1 (en) | Method and system for switching to dynamically assembled video during streaming of live video | |
US20230362460A1 (en) | Dynamically generated interactive video content | |
CN109729425B (en) | Method and system for predicting key segments | |
US20200159835A1 (en) | Methods and systems for managing content storage | |
Yang et al. | Serving a video into an image carousel: system design and implementation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20200127 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20200127 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20210303 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20210322 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210617 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20210705 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20210726 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6920475Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |