EP2638701A2 - Vector transformation for indexing, similarity search and classification - Google Patents
Vector transformation for indexing, similarity search and classificationInfo
- Publication number
- EP2638701A2 EP2638701A2 EP11839722.3A EP11839722A EP2638701A2 EP 2638701 A2 EP2638701 A2 EP 2638701A2 EP 11839722 A EP11839722 A EP 11839722A EP 2638701 A2 EP2638701 A2 EP 2638701A2
- Authority
- EP
- European Patent Office
- Prior art keywords
- vector
- vectors
- feature vector
- sparse binary
- feature
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 239000013598 vector Substances 0.000 title claims abstract description 463
- 230000009466 transformation Effects 0.000 title description 23
- 238000000034 method Methods 0.000 claims description 40
- 238000004590 computer program Methods 0.000 claims description 6
- 230000009471 action Effects 0.000 claims description 2
- 230000008569 process Effects 0.000 description 13
- 230000006870 function Effects 0.000 description 12
- 238000012545 processing Methods 0.000 description 8
- 230000008859 change Effects 0.000 description 4
- 230000000694 effects Effects 0.000 description 3
- 230000015654 memory Effects 0.000 description 3
- 230000008901 benefit Effects 0.000 description 2
- 238000013329 compounding Methods 0.000 description 2
- 238000010586 diagram Methods 0.000 description 2
- 238000007726 management method Methods 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 230000004044 response Effects 0.000 description 2
- PXFBZOLANLWPMH-UHFFFAOYSA-N 16-Epiaffinine Natural products C1C(C2=CC=CC=C2N2)=C2C(=O)CC2C(=CC)CN(C)C1C2CO PXFBZOLANLWPMH-UHFFFAOYSA-N 0.000 description 1
- 240000006829 Ficus sundaica Species 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 230000009286 beneficial effect Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 150000001875 compounds Chemical class 0.000 description 1
- 238000013480 data collection Methods 0.000 description 1
- 238000013479 data entry Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 238000009826 distribution Methods 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 238000005259 measurement Methods 0.000 description 1
- 239000000126 substance Substances 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/41—Indexing; Data structures therefor; Storage structures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
- G06V10/513—Sparse representations
Definitions
- the present disclosure generally relates to the fields of data indexing, similarity search and classifications, and more specifically to the manipulation of high- dimensional vector space data.
- Vectors are commonly used to represent the feature space of various phenomena.
- vectors are used to represent the features of images, videos, audio clips, and other media.
- the utility of vector space operations is not limited to digital media, but may additionally be applied to other data, to physical objects, or to any other entity capable of feature representation.
- features include color distributions (using, for example, 4x4 pixel hue and saturation histograms), the mean and variance of color intensities across color channels, color intensity difference inside and outside of pixel rectangles, edges, mean edge energy, texture, video motion, audio volume, audio spectrogram features, the presence of words or faces in images, or any other suitable media property.
- Vector space representations are particularly useful in the classification, indexing, and determination of similarity in digital media; determining the distance between digital media feature vectors is fundamental to these operations.
- the manual classification and indexing of digital media requires a human operator, and results in, for large media collections, prohibitively expensive and expansive operations.
- similarity search within a large media library requires analysis of all entries in the library, and even automated library analysis requires processing resource-intensive capabilities.
- high-dimensional feature vectors of digital media are also prone to noise, reducing the effectiveness of vector distance determinations on such vectors, and reducing the ability to detect vector distance differences resulting from changes to a small number of vector features.
- Many data classification tasks rely on vector space representations to represent the particular data of interest.
- One common data classification operation involves determining the similarity between two data objects.
- Using a vector space representation of the data objects allows a determination of similarity to be made based on the distance, such as the Euclidean distance, between the two vectors, such as coordinate vectors, representing the data objects.
- a change in the value of single vector component has an effect on the distance between the vectors that is inversely proportional to the number of dimensions of the vectors.
- the larger the number of dimension in a vector the smaller the effect changes in a single vector component has on the distance between the vectors.
- the elements of vectors in vector space operations are susceptible to noise, whether naturally occurring or otherwise.
- the determination of the distance between two vectors is increasingly affected by the compounding of noise affecting individual elements of the vectors.
- the magnitude of the compounded noise in distance determinations may exceed the magnitude of the change in distance determinations as a result of changes to a single vector dimension at high dimensional vector spaces. This is problematic in instances where it is desirable to measure the change in distance between vectors caused by the change of a small number of elements in the vectors.
- a feature vector representing a media object or other data object is encoded.
- the feature vector may be retrieved from a storage module, or may be generated by a feature vector generator.
- the media object or other data object may be, for example, an image, a video, an audio clip, a database, a spreadsheet, or a document.
- One or more permutations are generated, each permutation including a vector of ordinals of the same dimensionality as the feature vector.
- the one or more permutations can be generated randomly, resulting in a random ordering of each permutation's ordinals.
- the feature vector is permuted with the one or more permutations by re -ordering the entries of the feature vector according to the ordinals of the permutations, creating one or more permuted feature vectors.
- a window size is selected, for instance randomly.
- the window size can vary from 2 to the dimensionality of the feature vector.
- the window size can be selected such that the encoded feature vectors are biased towards the beginning of the permuted feature vectors.
- the permuted feature vectors are truncated according to the selected window size, such that a number of beginning vector values equivalent to the selected window size are maintained and the remaining vector values are discarded.
- the index of the maximum value of each truncated permuted feature vector is identified and encoded using, for instance, one-hot encoding.
- the encoded indexes may be concatenated into a single sparse binary vector, which may be stored for subsequent retrieval.
- One or more sparse binary vectors (each associated with one or more particular features of a media object) can be produced for each media object in a media library.
- the sparse binary vectors can be stored in conjunction with the media objects in the media library.
- a similarity search between a target media object and the media library can be performed on the stored sparse binary vectors and a sparse binary vector associated with a target media object by computing the dot product between the sparse binary vector associated with the target media object and the one or more sparse binary vector associated with each stored media object.
- the media object associated with the largest dot product may be selected as the stored media object most similar to the target media object with regards to the feature or features associated with the sparse binary vectors.
- a feature vector can be encoded over a polynomial space.
- a set of permutations is generated, the number of permutations in the set equal to the degree of the polynomial space.
- the feature vector is then permutated with the set of permutations, and the resulting permuted feature vectors are truncated according to a selected window size.
- a product vector the same dimensionality as the truncated permuted vectors is created, and the value at each index of the product vector is the product of the values at the particular index of each truncated permuted vector.
- the index of the maximum value of the product vector is then identified and encoded using, for example, one-hot encoding to produce a sparse binary vector representing the feature vector over the polynomial space.
- a data processing system can encode feature vectors representing stored media objects into sparse binary vectors, and can stored the sparse binary vectors in conjunction with the stored media objects.
- the data processing system can use the stored sparse binary vectors to perform similarity searches on media objects.
- the sparse binary vectors may also be used to categorize or tag the media objects, to index the media objects, and to otherwise process feature information related to the media objects.
- FIG. 1 is a block diagram of a media hosting service according to one embodiment.
- Fig. 2 illustrates the various components of the vector transformation module of Fig. 1, according to one embodiment.
- FIG. 3 illustrates a simple example embodiment of the transformation of a feature vector by the vector transformation module of Fig. 1, according to one
- FIG. 4 is a flowchart of a process for encoding a feature vector into a sparse vector, according to one embodiment.
- FIG. 5 is a flowchart of a process for encoding a polynomial space of a feature vector into a sparse vector, according to one embodiment.
- Fig. 6 is a flowchart of a process for performing a similarity search between a sparse binary feature vector for target media and sparse binary feature vectors for searchable media, according to one embodiment.
- FIG. 1 is a block diagram of a media hosting service in which data processing operations on vector data representing media objects are performed, according to one embodiment.
- the media hosting service 100 represents a system such as that of
- YOUTUBETM that stores and provides videos and other media (such as images, audio, and the like) to clients such as the client 135.
- the media hosting service 100
- the media hosting service 100 may be implemented in a cloud computing network, accessible by the content providers 130 and the clients 135 over the network 140.
- Fig. 1 depicts only one instance of content provider 130 and client 135, though in practice there will large numbers of each. It should be noted that the vector transformation discussed herein is equally applicable to non-media data objects (such as documents, spreadsheets, data collections, and the like), though the description herein is primarily directed to media objects solely for the purpose of simplicity.
- the media hosting service 100 additionally includes a front end interface 102, a media serving module 104, a media search module 106, an upload server 108, a feature module 110, a vector transformation module 112, a comparison module 114, a media storage module 116, and a vector storage module 118.
- Other conventional features such as firewalls, load balancers, authentication servers, application servers, failover servers, site management tools, and so forth, are not shown so as to more clearly illustrate the features of the media hosting service 100. While an example of a suitable service 100 is the YOUTUBE website, found at www.youtube.com, other media hosting sites can be adapted to operate according to the teachings disclosed herein. The illustrated
- components of the media hosting service 100 can be implemented as single or multiple components of software or hardware. In general, functions described in one embodiment as being performed by one component can also be performed by other components in other embodiments, or by a combination of components. Furthermore, functions described in one embodiment as being performed by components of the media hosting service 100 can also be performed by one or more clients 135 in other embodiments if appropriate.
- Clients 135 are computing devices that execute client software, e.g., a web browser or built-in client application, to connect to the front end interface 102 of the media hosting service 100 via a network 140 and to display or otherwise interact with media.
- the client 135 might be, for example, a personal computer, a personal digital assistant, a cellular, mobile, or smart phone, a tablet, or a laptop computer.
- the network 140 is typically the Internet, but may be any network, including but not limited to a LAN, a MAN, a WAN, a mobile wired or wireless network, a private network, or a virtual private network. In some embodiments, the network is a cloud computing network.
- the content provider 130 provides media content to the media hosting service 100 and the client 135 interacts with that content.
- content providers may also be clients 135. Additionally, the content provider 130 may be the same entity that operates the media hosting service 100.
- the content provider 130 operates a client to perform various content provider functions. Content provider functions may include, for example, uploading a media file to the media hosting service 100, editing a media file stored by the media hosting service 100, indexing media stored by the media hosting service 100, requesting the categorization and/or tagging of media stored by the media hosting servicer 100, and performing similarity searches on media stored by the media hosting service 100.
- the client 135 may also be used to configure viewer preferences related to media content.
- the client 135 includes an embedded media player such as, for example, the FLASH player from Adobe Systems, Inc. or any other player adapted for the media file formats used in the media hosting service 100.
- the client 135 may be adapted to request that the media hosting service perform similarity searches on stored media, index or tag stored media, fingerprint media, classify media, or any other data-processing functions.
- the upload server 108 of the media hosting service 100 receives media content from a content provider 130. Received content is stored in the media storage module 1 16. In response to requests from a client 135, a media serving module 104 provides media data from the media storage module 1 16 to the client 135. Clients 135 may also search for media of interest stored in the media storage module 1 16 using a media search module 106, such as by entering textual queries containing keywords of interest.
- the front end interface 102 provides the interface between the clients 135 and the various components of the media hosting service 100.
- the feature module 1 10 is configured to derive a set of features for a media object or other data object i, collectively referred to as a feature vector F L .
- a feature vector F L a set of features for a media object or other data object i.
- Each feature vector Fi is derived from one or more properties or characteristics ("features") of a media object.
- the features can be derived from the video, audio, textual, image, metadata, or other content of the media object.
- a feature vector Fi may include features describing the motion, color, texture, gradients, edges, interest points, corners, or other visual characteristics of a video or images.
- Other features include SIFT, SURF, GLOH, LESH and HoG, as well as space scale and affine representations.
- Features can also include audio features, such as spectrogram features, and Mel-frequency cepstral coefficients, and the like.
- Textual features can include bag of words representations, along with TF/IDF values and the like, as derived from the media content as well as from metadata (e.g., a description or summary of the media, tags, keywords, etc.).
- Features can also include data representing user interactions with the media data, such as view counts, downloads, co-watches, likes, and so forth.
- Features can also include category and tag information.
- the feature module 1 10 may produce feature vectors Fj based on features described in co-pending U.S. Application No. 12/881 ,078, filed September 13, 2010, and co-pending U.S. Application No. 12/950,955, filed November 19, 2010, the contents of each of which are hereby incorporated by reference.
- the feature module 1 10 stores generated feature vectors F in the vector storage module 1 18.
- the media storage module 1 16 and the vector storage module 1 18 can be any non-transitory computer readable data storage apparatus, using any type of data retrieval mechanism, e.g., database, file system, etc.
- the entries (components) of the feature vectors F are numeric and typically real valued, and each feature vector entry is associated with an ordinal or index. For example, for the feature vector [3, 17, 9, 1], the "3" is referred to as the first entry and is said to be at index "0", the "17” is referred to as the second entry and is said to be at index "1", and so forth.
- Each feature vector entry represents a measurement or value associated with the particular feature or features of a media object represented by the feature vector Fj for the media object. For example, if the above feature vector represented the brightness of various pixels in an image, each of the entries "3", “17”, “9", and “1” might represent the luminance levels of corresponding pixels.
- the dimensionality (or cardinality) is the number of components in the feature vector; in this example the dimensionality is 4. In practice, the feature vectors F have high
- the feature module 1 10 may produce a feature vector Fj for a media object stored in the media object storage module 1 16, for a media object uploaded by a content provider 130 or requested by a client 135, or for any other media objects.
- the feature module 1 10 may produce one or more feature vectors for media objects as they are received from content providers 130, or may produce one or more feature vectors for media objects when queried, for instance by the vector transformation module 1 12.
- Feature vectors F generated for media objects and stored in the vector storage module 1 18 may be stored in conjunction with the media objects stored in the media storage module 1 16 for subsequent retrieval.
- the vector transformation module 1 12 retrieves a media object feature vector F from the vector storage module 1 18 and transforms the retrieved vector F into a sparse binary feature vector S.
- Fig. 2 illustrates the various components of the vector
- the vector transformation module 1 12 includes a permutation module 200, a window module 202, a max index module 204, and an encoder 206. In other embodiments, the modules of the vector transformation 1 12 perform different functions than those described herein.
- the permutation module 200 After retrieving a feature vector from the vector storage module 1 18, the permutation module 200 permutes the retrieved feature vector Fj with one or more permutations (3 ⁇ 4.
- the permutation module 200 may generate the one or more permutations ⁇ or may retrieve the permutations (3 ⁇ 4 from, for example, the vector storage module 1 18.
- a permutation (9,, is a sequence of ordinals that describe a reordering of the components a feature vector Fj by the permutation module 200 producing a set of permuted feature vectors P, j .
- Fig. 3 illustrates a simple example embodiment of the transformation of a feature vector by the vector transformation module 200, according to one embodiment.
- a feature vector Fj is retrieved from the feature module 1 10 for a target media object Tj.
- the feature vector Fj is the vector [3, 9, 17, 4, 1 1 , 6], which represents some feature of the target media object T h
- ⁇ 2 [4, 2,5,3, 1,0]
- ⁇ 3 [0,3, 2, 5, 4, 1]
- ⁇ 4 [1,0, 3, 5, 2, 4]
- each permutation 9 j is the same as the dimensionality of the feature vector F h Permuting the feature vector F t with each permutation 9 j results in 5 permutations vectors, Pio to Pi .
- the permutation vector P i0 includes the 6 entries:
- the permutations 9 j can be generated randomly (e.g., random selection without replacement from the set of integers ⁇ 0, N ⁇ where N is the dimensionality of the feature vectors) or formulaically.
- the generated permutations can be stored in, for instance, the vector storage module 118 for subsequent use.
- the permutation module 200 may retrieve previously generated permutations from the vector storage module 118 in order to permute the retrieved feature vector F h Storing the generated permutations allows the permutations to be used in many contexts which require the application to a feature vector F 2 representing media object T 2 of the same permutations applied to a feature vector F] representing media object Tj.
- the same set of permutations 9 j is used to permute feature vectors F t and F z representing a target media object T t and a plurality of searchable media objects M z in order to identify one of the searchable media objects M z most similar to the target media object Tj.
- the set of permutations (9, is applied to the feature vectors F z and stored in the vector storage module 118 for subsequent retrieval and application to the feature vector F h
- the window module 202 generates a magnitude K, 2 ⁇ K ⁇ N, where N is the number of dimensions of the feature vector Fj. K is called the "window size" of the permuted vectors P .
- the window module 202 truncates the permuted vectors P to a dimensionality of K, producing truncated permuted vectors P . k by keeping the first K entries of Pj j and discarding the remaining entries.
- the magnitude K may be determined randomly or by other means.
- the same magnitude K is used to truncate the permuted vectors Pj j of each media object.
- K may vary by permuted vector Pj j , though the remainder of the description herein assumes K is constant for a set of permuted vectors P .
- the window module 202 determines the magnitude K to be 4. The window module 202 then truncates the permuted vectors P to a window size of 4, producing the truncated permuted vectors ⁇ .
- the max index module 204 identifies the index of the truncated permuted vector entry representing the maximum value of a truncated permuted vector Pi j,k , for each truncated permuted vector Pi j,k . In one embodiment, the max index module 204 identifies the index of the maximum value of a truncated permuted vector by comparing the value of ⁇ at index 0 to the value of ⁇ at index 1 , and selecting the index representing the greater of the two values. The max index module 204 next compares the value represented by the selected index with the value of P i:j:k at index 2, and selects the index representing the greater of the two values.
- the max index module 204 identifies the index of the maximum value which appears first in Pi j ,k- [0039] In the example of Fig. 3, the max index module 204 selects the index representing the maximum value of each truncated permuted vector. For the vector Pi , o,4, the max index module 204 identifies the maximum value of "1 1" to be located at index 0.
- the max index module 204 identifies the maximum values of "1 1", “17”, “17” and “9” to be located at index 2, 1 , 2, 0, respectively (the left-most entry in a vector described herein appears at index 0).
- the encoder 206 retrieves the identified indexes representing the maximum value of each truncated permuted vector Pi ,k , and encodes the identified indexes of the truncated permuted vectors P ⁇ , producing encoded vectors ⁇ .
- the encoder 206 encodes the identified indexes using a one-hot binary encoding scheme, producing encoded vectors Ey ; * of the same dimensionality as the truncated permuted vectors Pi j ,k, with each entry of the vectors set to 0 except for the entries at the identified indexes, which are set to 1.
- the encoder 206 encodes the values of the vectors y ⁇ at the identified indexes (and not just the identified indexes), or utilizes an encoding scheme other than the one-hot binary encoding scheme described herein.
- the encoder 206 may encode the identified indexes using maximum entropy encoding.
- encoding the identified indexes using maximum entropy encoding requires only log 2 (y) bits to represent the encoded indexes, where y is the dimensionality of of the encoded vectors E y ⁇ (compared to y bits for one-hot encoding), though it should be noted that maximum entropy encodings are not vector space representations.
- the encoder 206 concatenates the encoded vectors E y; * into a binary vector which is stored in the vector storage module 1 18 for subsequent retrieval.
- the window size K By limiting the selection of the window size K to natural numbers greater than or equal to 2, the dimensionality of the truncated permuted vectors y ⁇ is guaranteed to be greater than or equal to 2.
- the selection of one index within each vector ⁇ results in the selection of 50% or less of the total entries across the vectors ⁇ .
- encoding the selected indexes with a one-hot binary encoding scheme and concatenating the encoded indexes results in less than 50% of the entries of S irk being set to 1 , guaranteeing that S irk is a sparse binary vector.
- performing vector operations on sparse binary vectors S typically requires less computing and storage resources than performing the same operations on the original vectors associated with the sparse binary vectors S.
- the encoding performed by the vector transformation module 1 12 may be extended to a polynomial expansion of a feature space.
- a set of permutations 9 P is generated, and a feature vector Fj is permuted with the set of permutations 9 P , producing a set of permuted vectors P i:P .
- this encoding may be performed for multiple sets of permutations 9 pj , resulting in multiple sparse binary vectors S p , which may be concatenated together to form a longer sparse binary vector S.
- Encoding a polynomial expansion of a feature space in this way produces equivalent results to computing the expanded polynomial feature space first and then subsequently encoding the expanded feature space, but can be performed much more efficiently as the encoding occurs over a smaller feature space.
- the MinHash may be computed over a combinatorial space of binary hypercubes in logarithmic time.
- the MinHash may be computed in 0(p) time, compared to 0(v ) time for first expanding the polynomial feature space and then computing the MinHash.
- the sparse binary vectors S described herein are based on the relative rank ordering of the feature vectors F, allowing the sparse binary vectors S to be resilient to noise that does not affect the implicit ordering of the elements of F.
- noise compounds proportional to the dimensionality of the vector, resulting in small changes to distance determinations as a result of changes in a small number of vector entries being dwarfed in magnitude by the compounded noise.
- the sparse binary vectors S herein are largely immune to such compounding of noise as the exact values of each dimension become secondary in importance to the ranking of the elements, restricting the effect of noise associated with a single dimension to the values of the dimension and the nearest neighbor ranked dimensions. Noise only becomes relevant to the vector operations described herein when it is great enough to affect the ordering of the feature vectors F. Thus, the degree of invariance to noise is equivalent to the variance of the values of the feature vectors F.
- the sparse binary vectors S herein are also resistant to variations that do not affect the implicit ordering of the elements of the feature vectors F by the feature module 1 10, the vector transformation module 1 12, or any other component.
- the vectors F can be multiplied by scalar values without altering the ordering of the elements of the vectors F, and thus without affecting the produced sparse binary vectors S.
- a constant value can be added to all elements of the vectors F without affecting the ordering of the elements of the vectors F and thus the vectors S.
- the selection of K by the window module 202 determines the amount of information encoded by the encoder 206.
- the one-hot encoding discussed above encodes the index of the maximum value of a truncated permuted vector P ⁇ as 1 in an encoded vector Ej j:k , and encodes the remaining indexes of y - * as 0 in
- the vector transformation module 1 12 may produce a sparse binary feature vector S for a media object in real-time when requested, or may produce sparse binary feature vectors S in advance.
- the vector transformation module 1 12 may produce one or more sparse binary feature vectors S for each media object stored in the media storage module 1 16. Sparse binary feature vectors S produced in advance may be stored in the vector storage module 1 18 in conjunction with the stored media objects.
- the other parameters used to produce the vectors S may be stored in the vector storage module 1 18, such as the permutations (3 ⁇ 4, the magnitudes K, the features used by the feature module 1 10 to produce the feature vectors F for the media objects, the type of encodings used by the encoder 206, or any other parameter related to the creation of the sparse binary feature vectors S.
- the media hosting service 100 via, for example, the comparison module 1 14
- the media hosting service 100 can perform a variety of functions related to media features on stored media without having to produce sparse binary feature vectors S for stored media in real-time.
- the comparison module 1 14 compares sparse binary feature vectors S representing two or more media objects to perform a variety of comparison functions between the two or more media objects.
- One example comparison function includes a similarity search between a target media object 7 and a plurality of searchable media objects M z .
- the vector transformation module 1 12 retrieves a feature vector Fj for the target media object T, and produces a sparse binary feature vector Si for the object Tj.
- the comparison module 1 14 then scans a plurality of sparse binary feature vectors S z
- the comparison module 1 14 To identify a sparse binary feature vector S z most similar to the sparse binary feature vectors Si, the comparison module 1 14 performs a vector dot product between the Si and each S z .
- the comparison module 1 14 is configured to identify the sparse binary feature vector S z that results in the greatest dot product with Si, and selects the media object M z associated with the identified vector S z as the media object most similar to the target media object Ti.
- the selected media object M z determined to be most similar to the target media object based on the similarity of the sparse binary vectors associated with each is only determined to be the most similar to the target media object 7 ⁇ with regards to the feature or features used to produce the sparse binary vectors.
- Similarity searches may be performed by combining the sparse media vectors S z associated with the media objects M z into a table, beneficially allowing the comparison module 1 14 to efficiently query the table and perform dot products on the entire set of sparse media vectors S z simultaneously. Searches for a media object M z similar to a target media object 7 ⁇ may be made more accurate or may be otherwise enhanced by
- concatenating multiple sets of sparse binary vectors S z for media objects M z can be queried by concatenating together a sparse binary vector Sj for the tartget media object T t associated with each of the multiple sets of vectors S z and performing a dot product between the concatenated sparse binary vectors representing the media objects M z and the target media object Ti.
- Each of the multiple sets of sparse binary vectors represents a different feature, and thus performing a similarity search on concatenated sparse binary vectors representing multiple features will enhance the accuracy of the similarity search as the comparison module 1 14 will identify the media object M z most similar to Ti with regards to multiple features and not just a single feature.
- Similarity searches as described herein may be performed by the comparison module 1 14 in a variety of contexts.
- a similarity search may be performed on a library of images to identify an image to be used as a reference image for video encoding.
- a similarity search may be performed in conjunction with the image retrieval system described in U.S. Patent Application 13/083,423, filed April 8, 201 1 , the contents of which are hereby incorporated by reference.
- a similarity search may also be performed on media and other data in the context of identifying duplicate media and data in a data set, allowing the duplicate data to be discarded, reducing the footprint of the data set.
- the comparison module 1 14 may also perform other comparison functions. For example, the comparison module 1 14 indexes media objects M z stored in the media storage module 1 16 using sparse binary vectors S z produced by the vector transformation module 1 12. The indexes may be stored in conjunction with the media objects M z in the media storage module 1 16. Given a high enough dimensionality, the stored indexes may be used to uniquely identify the media objects M z . The stored indexes may be used by the comparison module 1 14 in performing nearest neighbor searches among the media objects M z for a target media object Tj. Similarly, the sparse binary vectors S z may be stored and used to fingerprint the media objects M z .
- the comparison module 1 14 may use sparse binary vectors S z produced by the vector transformation module 1 12 to tag or categorize the media objects M z .
- the comparison module 1 14 may associate sparse binary vectors S z with particular media subject matters or categories. Accordingly, the comparison module 1 14 may categorize or tag media objects M z based on the sparse binary vectors S z of the media objects M z and the categories and subject matters associated with the sparse binary vectors S z .
- the categorization and tagging of media objects using sparse binary vectors S z beneficially allows a massive library of media objects to be efficiently categorized and tagged, and allows media objects related to a target media object by category and tag to be displayed to a user of the media hosting service 100 currently interacting with the target media object.
- Fig. 4 is a flowchart of a process for encoding a feature vector into a sparse vector, according to one embodiment.
- a feature vector is retrieved 400.
- the retrieved feature vector includes feature information representing a media object (such as an image, video, or audio clip) or other data object (such as a collection of data, a data entry, a spreadsheet, or a document).
- the feature information may include information representing the motion rigidity of a video sequence, a color histogram computed using hue and saturation in HSV color space, audio spectrogram features, data variance, and any other properties of media or other data.
- a set of permutations is generated 410, for instance randomly or
- Each permutation includes a vector of the same dimensionality as the retrieved vector, and each permutation vector entry includes an ordinal representing a vector index.
- the set of permutations may include one permutation or many, for instance hundreds.
- the feature vector is permuted 420 with each permutation, producing a set of permuted vectors.
- the set of permuted vectors are truncated 430 to a magnitude determined by a selected window size.
- the selected window size may be randomly determined, or may be selected to bias the encodings towards the beginning of the permuted vectors. Truncating the permuted vectors involves retaining (in order) a number of the first permuted vector entries equal to the selected window size and discarding the remaining permuted vector entries.
- the index of the maximum value of each truncated permuted vectors is identified 440.
- the maximum value of each truncated permuted vectors may be identified by performing vector entry comparisons between truncated permuted vector entry pairs to identify the greater of the two entries, comparing the greater of the two entries to the next truncated permuted vector entry, and repeating the process for the remainder of the entries.
- the identified index of the maximum value of each truncated permuted vectors is encoded 450 into a sparse binary sub-vector, for instance using a one-hot binary encoding scheme or any other suitable encoding scheme.
- the sparse binary sub-vectors are concatenated 460 into a sparse binary vector representing the retrieved feature vector.
- the sparse binary vector may be stored in conjunction with the feature vector for subsequent retrieval and processing.
- Fig. 5 is a flowchart of a process for encoding a polynomial space of degree p of a feature vector into a sparse vector, according to one embodiment.
- a feature vector is retrieved 500, and a set p of permutations is generated 510.
- the feature vector is permuted 520 with each generated permutation, producing p permuted vectors.
- the p permuted vectors are truncated 530 to a selected window size.
- each index of the truncated vectors the values of each truncated vector at the index are multiplied 540 together to form a product vector entry.
- the product vector entries collectively form a product vector, with each product vector entry located at the product vector index associated with the multiplied values of the truncated vectors.
- the index of the maximum value in the product vector is identified 550 and encoded 560 into a sparse binary vector. Similarly to the process of Fig. 4, this process may be applied to many sets of p permutations, producing sparse binary sub-vectors which may be concatenated into a sparse binary vector.
- Fig. 6 is a flowchart of a process for performing a similarity search between a sparse binary feature vector for target media and sparse binary feature vectors for searchable media, according to one embodiment.
- a sparse binary feature vector associated with target media is retrieved 600.
- Sparse binary feature vectors associated with searchable media are similarly retrieved 610.
- the sparse binary feature vectors may be previously computed using the process of Fig. 4 and stored for subsequent retrieval. Alternatively, the sparse binary feature vectors may be computed in response to receiving a request for a similarity search from a user of a media system or a client.
- a dot product is computed 620 between the sparse binary vector associated with the target media and each sparse binary vector associated with the searchable media.
- the sparse binary vector associated with the searchable media that results in the largest dot product is selected 630 as the sparse binary vector most similar to the sparse binary vector associated with the target media.
- the searchable media associated with the selected sparse binary vector may be selected as the searchable media most similar to the target media with regards to the feature or features associated with the sparse binary vectors.
- the present invention also relates to an apparatus for performing the operations herein.
- This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored on a computer readable medium that can be accessed by the computer.
- a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, application specific integrated circuits (ASICs), or any type of computer-readable storage medium suitable for storing electronic instructions, and each coupled to a computer system bus.
- the computers referred to in the specification may include a single processor or may be architectures employing multiple processor designs for increased computing capability.
- the present invention is well suited to a wide variety of computer network systems over numerous topologies.
- the configuration and management of large networks comprise storage devices and computers that are communicatively coupled to dissimilar computers and storage devices over a network, such as the Internet.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US41271110P | 2010-11-11 | 2010-11-11 | |
PCT/US2011/059183 WO2012064587A2 (en) | 2010-11-11 | 2011-11-03 | Vector transformation for indexing, similarity search and classification |
Publications (3)
Publication Number | Publication Date |
---|---|
EP2638701A2 true EP2638701A2 (en) | 2013-09-18 |
EP2638701A4 EP2638701A4 (en) | 2015-10-07 |
EP2638701B1 EP2638701B1 (en) | 2020-09-09 |
Family
ID=45953565
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP11839722.3A Active EP2638701B1 (en) | 2010-11-11 | 2011-11-03 | Vector transformation for indexing, similarity search and classification |
Country Status (6)
Country | Link |
---|---|
US (1) | US8165414B1 (en) |
EP (1) | EP2638701B1 (en) |
CN (1) | CN103283247B (en) |
AU (1) | AU2011326269B2 (en) |
CA (1) | CA2814401C (en) |
WO (1) | WO2012064587A2 (en) |
Families Citing this family (41)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9569771B2 (en) | 2011-04-29 | 2017-02-14 | Stephen Lesavich | Method and system for storage and retrieval of blockchain blocks using galois fields |
US9137250B2 (en) | 2011-04-29 | 2015-09-15 | Stephen Lesavich | Method and system for electronic content storage and retrieval using galois fields and information entropy on cloud computing networks |
US9037564B2 (en) | 2011-04-29 | 2015-05-19 | Stephen Lesavich | Method and system for electronic content storage and retrieval with galois fields on cloud computing networks |
US9361479B2 (en) | 2011-04-29 | 2016-06-07 | Stephen Lesavich | Method and system for electronic content storage and retrieval using Galois fields and geometric shapes on cloud computing networks |
US9135712B2 (en) * | 2012-08-01 | 2015-09-15 | Augmented Reality Lab LLC | Image recognition system in a cloud environment |
WO2014023338A1 (en) * | 2012-08-07 | 2014-02-13 | Metaio Gmbh | A method of providing a feature descriptor for describing at least one feature of an object representation |
TWI498845B (en) * | 2012-12-14 | 2015-09-01 | Ind Tech Res Inst | Method and system for diet management |
US9659085B2 (en) * | 2012-12-28 | 2017-05-23 | Microsoft Technology Licensing, Llc | Detecting anomalies in behavioral network with contextual side information |
US10649970B1 (en) * | 2013-03-14 | 2020-05-12 | Invincea, Inc. | Methods and apparatus for detection of functionality |
CN104090882B (en) * | 2013-11-14 | 2016-06-01 | 深圳市腾讯计算机系统有限公司 | A kind of quick clustering method of advertisement order and system, server |
US9286902B2 (en) * | 2013-12-16 | 2016-03-15 | Gracenote, Inc. | Audio fingerprinting |
US10394828B1 (en) | 2014-04-25 | 2019-08-27 | Emory University | Methods, systems and computer readable storage media for generating quantifiable genomic information and results |
JP6260442B2 (en) * | 2014-05-02 | 2018-01-17 | 富士通株式会社 | Information processing method and program |
KR102172321B1 (en) | 2014-05-20 | 2020-10-30 | 삼성전자주식회사 | Method for data deduplication |
US10115146B1 (en) | 2015-01-08 | 2018-10-30 | Google Llc | Scoring candidates for set recommendation problems |
JP6952679B2 (en) * | 2015-07-15 | 2021-10-20 | サイランス・インコーポレイテッドＣｙｌａｎｃｅ Ｉｎｃ． | Malware detection |
US9690938B1 (en) | 2015-08-05 | 2017-06-27 | Invincea, Inc. | Methods and apparatus for machine learning based malware detection |
US9672358B1 (en) * | 2015-11-04 | 2017-06-06 | Invincea, Inc. | Methods and apparatus for detecting malware samples with similar image sets |
WO2017082875A1 (en) | 2015-11-10 | 2017-05-18 | Hewlett Packard Enterprise Development Lp | Data allocation based on secure information retrieval |
US9805269B2 (en) * | 2015-11-20 | 2017-10-31 | Adobe Systems Incorporated | Techniques for enhancing content memorability of user generated video content |
US10606879B1 (en) | 2016-02-29 | 2020-03-31 | Gracenote, Inc. | Indexing fingerprints |
US10326585B2 (en) | 2016-06-17 | 2019-06-18 | Hewlett Packard Enterprise Development Lp | Hash value generation through projection vector split |
US9531989B1 (en) * | 2016-06-17 | 2016-12-27 | Spotify Ab | Devices, methods and computer program products for playback of digital media objects using a single control input |
EP3475822B1 (en) | 2016-06-22 | 2020-07-22 | Invincea, Inc. | Methods and apparatus for detecting whether a string of characters represents malicious activity using machine learning |
US11080301B2 (en) * | 2016-09-28 | 2021-08-03 | Hewlett Packard Enterprise Development Lp | Storage allocation based on secure data comparisons via multiple intermediaries |
US10754948B2 (en) | 2017-04-18 | 2020-08-25 | Cylance Inc. | Protecting devices from malicious files based on n-gram processing of sequential data |
US10984045B2 (en) * | 2017-05-24 | 2021-04-20 | International Business Machines Corporation | Neural bit embeddings for graphs |
US20190102463A1 (en) * | 2017-09-29 | 2019-04-04 | Facebook, Inc. | Systems and methods for providing location-based subscriptions and notifications |
WO2019079490A1 (en) * | 2017-10-18 | 2019-04-25 | Memorial Sloan Kettering Cancer Center | Probabilistic modeling to match patients to clinical trials |
US10311913B1 (en) | 2018-02-22 | 2019-06-04 | Adobe Inc. | Summarizing video content based on memorability of the video content |
US11106708B2 (en) * | 2018-03-01 | 2021-08-31 | Huawei Technologies Canada Co., Ltd. | Layered locality sensitive hashing (LSH) partition indexing for big data applications |
CN108984747B (en) * | 2018-07-17 | 2020-06-02 | 厦门美图之家科技有限公司 | Audio retrieval index generation method and device |
US11561942B1 (en) | 2019-07-05 | 2023-01-24 | The Nielsen Company (Us), Llc | Methods and apparatus to estimate audience sizes of media using deduplication based on vector of counts sketch data |
US11416461B1 (en) | 2019-07-05 | 2022-08-16 | The Nielsen Company (Us), Llc | Methods and apparatus to estimate audience sizes of media using deduplication based on binomial sketch data |
US11361362B2 (en) * | 2019-08-16 | 2022-06-14 | Salesforce, Inc. | Method and system utilizing ontological machine learning for labeling products in an electronic product catalog |
US11238103B2 (en) * | 2019-09-13 | 2022-02-01 | Ebay Inc. | Binary coding for improved semantic search |
US11423304B2 (en) * | 2020-01-15 | 2022-08-23 | Beijing Jingdong Shangke Information Technology Co., Ltd. | System and method for semantic analysis of multimedia data using attention-based fusion network |
CN112434722B (en) * | 2020-10-23 | 2024-03-19 | 浙江智慧视频安防创新中心有限公司 | Label smooth calculation method and device based on category similarity, electronic equipment and medium |
US20220207050A1 (en) * | 2020-12-29 | 2022-06-30 | Atlassian Pty Ltd. | Systems and methods for identifying similar electronic content items |
WO2024005784A1 (en) * | 2022-06-28 | 2024-01-04 | Innopeak Technology, Inc. | Text-to-video retrieval using shifted self-attention windows |
CN117454015B (en) * | 2023-12-19 | 2024-04-12 | 深圳须弥云图空间科技有限公司 | Information recommendation method and device |
Family Cites Families (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6850252B1 (en) * | 1999-10-05 | 2005-02-01 | Steven M. Hoffberg | Intelligent electronic appliance system and method |
US6910035B2 (en) * | 2000-07-06 | 2005-06-21 | Microsoft Corporation | System and methods for providing automatic classification of media entities according to consonance properties |
US7065416B2 (en) * | 2001-08-29 | 2006-06-20 | Microsoft Corporation | System and methods for providing automatic classification of media entities according to melodic movement properties |
JP2002117037A (en) * | 2000-10-06 | 2002-04-19 | Nec Corp | Device and method for image retrieval and recording medium where the same method is written |
US6892193B2 (en) * | 2001-05-10 | 2005-05-10 | International Business Machines Corporation | Method and apparatus for inducing classifiers for multimedia based on unified representation of features reflecting disparate modalities |
US8059815B2 (en) * | 2001-12-13 | 2011-11-15 | Digimarc Corporation | Transforming data files into logical storage units for auxiliary data through reversible watermarks |
JP3744464B2 (en) * | 2002-05-20 | 2006-02-08 | ソニー株式会社 | Signal recording / reproducing apparatus and method, signal reproducing apparatus and method, program, and recording medium |
US8312031B2 (en) * | 2005-10-26 | 2012-11-13 | Cortica Ltd. | System and method for generation of complex signatures for multimedia data content |
US7765192B2 (en) * | 2006-03-29 | 2010-07-27 | Abo Enterprises, Llc | System and method for archiving a media collection |
US7756338B2 (en) * | 2007-02-14 | 2010-07-13 | Mitsubishi Electric Research Laboratories, Inc. | Method for detecting scene boundaries in genre independent videos |
US7941516B2 (en) * | 2007-06-15 | 2011-05-10 | Microsoft Corporation | Redundant pile of inexpensive drivers (RPID) |
WO2009141759A1 (en) * | 2008-05-19 | 2009-11-26 | Koninklijke Philips Electronics N.V. | Noise robust helper data system (hds) |
US8429216B2 (en) * | 2008-09-23 | 2013-04-23 | Hewlett-Packard Development Company, L.P. | Generating a hash value from a vector representing a data object |
-
2011
- 2011-11-03 CA CA2814401A patent/CA2814401C/en active Active
- 2011-11-03 CN CN201180061086.3A patent/CN103283247B/en active Active
- 2011-11-03 AU AU2011326269A patent/AU2011326269B2/en active Active
- 2011-11-03 US US13/288,706 patent/US8165414B1/en active Active
- 2011-11-03 WO PCT/US2011/059183 patent/WO2012064587A2/en active Application Filing
- 2011-11-03 EP EP11839722.3A patent/EP2638701B1/en active Active
Also Published As
Publication number | Publication date |
---|---|
AU2011326269B2 (en) | 2013-08-22 |
CA2814401A1 (en) | 2012-05-18 |
CA2814401C (en) | 2013-12-31 |
EP2638701B1 (en) | 2020-09-09 |
WO2012064587A2 (en) | 2012-05-18 |
CN103283247B (en) | 2014-11-12 |
AU2011326269A1 (en) | 2013-05-23 |
CN103283247A (en) | 2013-09-04 |
US20120121194A1 (en) | 2012-05-17 |
WO2012064587A3 (en) | 2012-07-05 |
EP2638701A4 (en) | 2015-10-07 |
US8165414B1 (en) | 2012-04-24 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8165414B1 (en) | Vector transformation for indexing, similarity search and classification | |
Matsui et al. | Sketch-based manga retrieval using manga109 dataset | |
Liu et al. | Collaborative hashing | |
TWI506459B (en) | Content-based image search | |
US20090282025A1 (en) | Method for generating a representation of image content using image search and retrieval criteria | |
JP2014505313A (en) | Method and apparatus for identifying similar images | |
Valsesia et al. | Large-scale image retrieval based on compressed camera identification | |
Zhou et al. | Online video recommendation in sharing community | |
Mukherjee et al. | A survey on image retrieval performance of different bag of visual words indexing techniques | |
Zhou et al. | Structure tensor series-based large scale near-duplicate video retrieval | |
Majhi et al. | An image retrieval scheme based on block level hybrid dct-svd fused features | |
Ghose et al. | Fractional local neighborhood intensity pattern for image retrieval using genetic algorithm | |
Amato et al. | Large scale image retrieval using vector of locally aggregated descriptors | |
Besiris et al. | Dictionary-based color image retrieval using multiset theory | |
Zhao et al. | Fast covariant vlad for image search | |
Kordopatis-Zilos et al. | Finding near-duplicate videos in large-scale collections | |
Yadav et al. | Texture-based medical image retrieval in compressed domain using compressive sensing | |
Gallas et al. | Locality‐sensitive hashing for region‐based large‐scale image indexing | |
Cirakman et al. | Content-based copy detection by a subspace learning based video fingerprinting scheme | |
Chan et al. | The Power of Bounds: Answering Approximate Earth Mover's Distance with Parametric Bounds | |
Zhao et al. | Image descriptor based on local color directional quaternionic pattern | |
Chiu et al. | Efficient histogram-based indexing for video copy detection | |
Zhao et al. | MapReduce-based clustering for near-duplicate image identification | |
Amato et al. | Indexing vectors of locally aggregated descriptors using inverted files | |
Yan et al. | Iterated local search optimized hashing for image copy detection |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20130611 |
|
AK | Designated contracting states |
Kind code of ref document: A2Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
DAX | Request for extension of the european patent (deleted) | ||
A4 | Supplementary search report drawn up and despatched |
Effective date: 20150902 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 17/30 20060101ALI20150828BHEPIpc: H04N 21/234 20110101AFI20150828BHEPIpc: G06F 17/00 20060101ALI20150828BHEP |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20180607 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R079Ref document number: 602011068565Country of ref document: DEFree format text: PREVIOUS MAIN CLASS: H04N0021234000Ipc: G06F0016410000 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 16/41 20190101AFI20191202BHEP |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
INTG | Intention to grant announced |
Effective date: 20200325 |
|
RIN1 | Information on inventor provided before grant (corrected) |
Inventor name: YAGNIK, JAY |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE PATENT HAS BEEN GRANTED |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: REFRef document number: 1312464Country of ref document: ATKind code of ref document: TEffective date: 20200915Ref country code: CHRef legal event code: EP |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602011068565Country of ref document: DE |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201209Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201210Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201209 |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 1312464Country of ref document: ATKind code of ref document: TEffective date: 20200909 |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: MPEffective date: 20200909 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: RSFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: NLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20210111Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: SMFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: ALFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20210109 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602011068565Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201103 |
|
REG | Reference to a national code |
Ref country code: BERef legal event code: MMEffective date: 20201130 |
|
26N | No opposition filed |
Effective date: 20210610 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201130Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201130 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: IEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201103 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: TRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: MTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200909 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201130 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230506 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: GBPayment date: 20231127Year of fee payment: 13 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: FRPayment date: 20231127Year of fee payment: 13Ref country code: DEPayment date: 20231129Year of fee payment: 13 |