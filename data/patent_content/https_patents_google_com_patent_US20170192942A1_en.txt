US20170192942A1 - Hierarchical positioned event dispatch - Google Patents
Hierarchical positioned event dispatch Download PDFInfo
- Publication number
- US20170192942A1 US20170192942A1 US14/989,087 US201614989087A US2017192942A1 US 20170192942 A1 US20170192942 A1 US 20170192942A1 US 201614989087 A US201614989087 A US 201614989087A US 2017192942 A1 US2017192942 A1 US 2017192942A1
- Authority
- US
- United States
- Prior art keywords
- view
- views
- event
- layout
- positioned event
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
Images
Classifications
-
- G06F17/2241—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/12—Use of codes for handling textual entities
- G06F40/137—Hierarchical processing, e.g. outlines
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/54—Interprogram communication
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2209/00—Indexing scheme relating to G06F9/00
- G06F2209/54—Indexing scheme relating to G06F9/54
- G06F2209/545—Gui
Definitions
- the present disclosure relates generally to graphical user interfaces and, more particularly, to receiving and processing touch events and other positioned events in a graphical user interface.
- GUIs Graphical user interfaces
- GUIs enable the use of multiple windows, or views, by which information may be displayed to a user or by which input may be received from a user.
- this input is provided through the use of a touchscreen, trackpad, mouse, or other positional input component.
- the user's interaction with the GUI via a positional input component takes the form of one or more positioned events, each having a two-dimensional location relative to the display space of the system.
- the underlying GUI framework operates to dispatch the input event to the intended view for processing.
- the GUI implements a view hierarchy (also often referred to as a “view tree”) of views presently displayed, and representing the parent-child relationships between these views.
- the dispatch of an input event thus typically involves dispatching the input event down the view hierarchy.
- the positioned event may be intercepted or modified by a parent view of the intended view, such as to account for touch “slop” or to differentiate between different types of gesture inputs, as the input event traverses the view hierarchy.
- each parent view receives a positioned event based on the location of the positioned event overlapping the bounding box, or being within the bounds, of the parent view object, and the parent view need only pass an input event to whichever child view object overlaps the positioned event location.
- Conventional spatial-based hierarchical event dispatch processes which constrain a view object to accept only positioned events within the bounding box of the view object, are unable to accurately dispatch and process positioned events in such instances.
- FIG. 1 is a diagram illustrating a process for dispatch of positioned events in an electronic device utilizing an unconstrained GUI in accordance with at least one embodiment of the present disclosure.
- FIG. 2 is a block diagram illustrating an example hardware configuration of the electronic device of FIG. 1 in accordance with at least one embodiment of the present disclosure.
- FIG. 3 is a flow diagram illustrating a method for positioned event dispatch for an unconstrained GUI in accordance with at least one embodiment of the present disclosure.
- FIG. 4 is a diagram illustrating a method for determining a quadtree data structure representing positioning of views of a layout in accordance with at least one embodiment of the present disclosure.
- FIG. 5 is a diagram illustrating a method for determining a view map data structure representing positioning of views of a layout in accordance with at least one embodiment of the present disclosure.
- FIG. 6 is a diagram illustrating a method for determining a list data structure representing views of a layout in accordance with at least one embodiment of the present disclosure.
- FIGS. 1-6 illustrate example devices and techniques for the processing of positioned input events in an “unconstrained” GUI—that is, a GUI that does not constrain the position of a child view to the bounding box or other boundary of the parent view.
- An electronic device provides for display of a GUI having a layout of views.
- a user may utilize a touchscreen, trackpad, mouse, or other positional input component to provide input via the GUI in the form of positioned input events (hereinafter, “positioned events” for brevity) relative to the views in the current layout.
- the electronic device maintains a view display-space registry in the form of a data structure representative of the views in the current layout and their positions relative to the layout or display space of the display of the electronic device.
- the electronic device uses the view display-space registry to identify the view for which the positioned event is likely intended—this view being identified herein as the “terminal view.”
- the electronic device identifies the location of the terminal view in a view hierarchy for the current layout and works up the view hierarchy from the terminal view to build an ancestor chain representing the chain of views from the top parent view down to the terminal view from the view hierarchy.
- the electronic device then may sequentially dispatch the positioned event in the ancestor chain until a view in the ancestor chain consumes or modifies the positioned event or the positioned event is ultimately rejected by the terminal view.
- filtering of positioned events based on the locations of the positioned events may be disabled or bypassed, thereby allowing each view in the ancestor chain to consider the positioned event regardless of the relationship between the location of the positioned event and a bounding box or other bounds of a non-terminal view.
- an ancestor view may consider the positioned input without having to identify the child view to which the positioned input is to be dispatched.
- the relationship between the position of the child view and the boundary of the parent view is not germane to the dispatch of the positioned event, which allows a child view to be positioned partially or fully outside the bounds of the parent view while still permitting the expected hierarchical processing of positioned events. That is, as each ancestor view is provided the opportunity to consume, delay, or otherwise modify a positioned event, processing of larger-context user input, such as scrolling, swipe gestures, multi-touch gestures, and the like, continues to be handled appropriately.
- OS operating system
- UI user interface
- FIG. 1 illustrates an example process 100 for dispatching positioned events for GUI that does not constrain the position of a child view to the bounding box or other boundary of the parent view (hereinafter, a “constrained GUI”) in accordance with at least one embodiment.
- the process 100 is performed by an electronic device 102 having a display 104 and one or more positional user input components (not shown in FIG. 1 ), such as a touch screen, trackpad, mouse, and the like.
- the electronic device 102 may include, for example, a compute-enabled cellular phone, a tablet computer, a compute-enabled watch or other compute-enabled wearable device, a notebook computer, a desktop computer, a game console, a remote controller, a network appliance, a server computer, a home automation controller, an automotive display interface, a compute-enabled medical device, and the like.
- the electronic device 102 provides a GUI 106 to a user via the display 104 .
- the GUI 106 includes a layout 108 of views currently displayed in the GUI, such as views 110 , 112 , 114 .
- views 110 , 112 are window views and view 114 is a button view.
- view 114 is a child view of view 112 , which in turn is a child view of view 110 , and thus view 110 is parent to view 112 , which in turn is parent to view 114 .
- the GUI 106 is an unconstrained GUI in that the views of the GUI 106 may be at least partially or fully positioned outside of the boundaries of their parent views.
- view 114 is located entirely outside of the boundary of view 112
- view 112 likewise is located entirely outside of the boundary of view 110 . Because of this unconstrained relationship between parent view and child view, a conventional bounding-box-based hierarchical dispatch process would likely fail to appropriately process a positioned event.
- the view 110 would reject the positioned event because the location of the positioned event is outside of the boundary of the view 110 .
- the electronic device 102 employs an unconstrained hierarchical dispatch technique (process 100 ) that operates to dispatch positioned events in a manner that does not rely on bounding-box-based filtering while continuing to enable hierarchical event dispatch for processing of larger-context user input events.
- the electronic device 102 maintains a view display-space registry 116 that stores information representing some or all of the views of the current view layout 108 and their positions relative to the layout 108 or to the display space.
- the view display-space registry 116 may include any of a variety of data structures or combinations of data structures. To illustrate, as described in greater detail below with reference to FIGS.
- the view display-space registry 116 may include a quadtree data structure, a list of views, or an array-based data structure that map or otherwise reference the positions of the associated views to the display space of the display 104 .
- the view display-space registry 116 represents all views in the layout 108 .
- the electronic device 102 may filter out such views so that only views configured to receive user input, or more specifically, position-based input, are represented in the view display-space registry 116 .
- the GUI 106 In response to the user manipulating a positional input component, the GUI 106 signals an initial positioned event 118 , which includes a two-dimensional (2D) location identifier (denoted “(X,Y)”) corresponding to the 2D location in the display space of the display 104 at which the positioned event 118 occurred.
- this location identifier can identify the position in display space where a user first contacted a touchscreen, the position in display space of a cursor when a mouse button or trackpad button is engaged, and so on.
- this positioned event occurred at a location (denoted in FIG. 1 with the concentric rings of contact point 120 ) in the display space that overlaps with the location of the button widget of view 114 .
- the positioned event 118 triggers the electronic device 102 to perform a lookup into, or otherwise access, the view display-space registry 116 to identify the view likely intended by the user to be the target or recipient of the positional event 118 .
- This view is identified herein as the “terminal” view 122 for the positioned event 118 .
- the process of identifying the terminal view 122 generally entails identification of those views of the current layout 108 that have a bounding box overlapping the location (X,Y) of the positioned event 118 . It will be appreciated that there may be multiple views that overlap in the layout 108 , and thus there may be multiple views that overlap at the location (X,Y).
- the electronic device 102 selects the terminal view 122 from the multiple views based on one or more selection criteria. For example, because the view “on top” in the layout 108 is likely the view intended to receive the user input, the electronic device 102 may utilize the Z number or draw order of each view to select the appropriate view. As another example, if one of the overlapping views is the current “in focus” view, this is a strong hint that the user intended the “in focus” view as the intended view for the user input. For the example of FIG. 1 , the positioned event 118 occurs at location (X,Y), which overlaps with a button widget of view 114 , and thus view 114 is postulated as the terminal view 122 .
- the electronic device 102 identifies the terminal view 122 using the view display-space registry 116 and thus could dispatch the positioned event 118 directly to the terminal view 122 , this would bypass hierarchical dispatch of the positioned event to the ancestor views of the terminal view 122 and thus prevent any larger-context processing of the positioned event 118 , including detection of multi-touch gestures, compensation for touch slop, discernment between similar types of gestures (e.g., touch-to-drag vs. touch-to-press gestures). Accordingly, to enable this hierarchical dispatch in the unconstrained GUI 106 , the electronic device 102 also identifies those views that are ancestors to the terminal view 122 .
- the underlying operating system (OS) framework or user interface (UI) framework supporting the GUI 106 typically maintains a view tree 124 (or view hierarchy) that both identifies the views present in the current layout 108 and identifies the parent-child relationships between these views.
- OS operating system
- UI user interface
- the electronic device 102 identifies the terminal view 122 within the view tree 124 and then sequences up the view tree 124 to identify each ancestor view of the terminal view 122 (assuming the terminal view 122 has at least one ancestor view).
- the electronic device 102 constructs an ancestor chain 126 that represents the one or more ancestor views of the terminal view 122 and their hierarchical arrangement as determined by the sequencing up the view tree 124 by the electronic device 102 .
- view 112 is the parent of view 114 (as terminal view 122 ) and view 110 is the parent of view 112 , and thus the resulting ancestor chain 126 would be: view 110 ⁇ view 112 ⁇ view 114 .
- the electronic device 102 With the ancestor chain 126 so constructed or otherwise identified, the electronic device 102 then hierarchically dispatches the positioned event 118 sequentially to the views in the ancestor chain 126 . Each view may then reject, consume, or modify the dispatched positioned event 118 based on the configuration or programming of the view. In the event that the view has rejected or modified the positioned event 118 , the electronic device 102 then may dispatch the rejected/modified positioned event 118 to the next view in the ancestor chain 126 . Thus, in the example of FIG. 1 , the positioned event 118 is dispatched first to the view 110 (dispatch event 128 ).
- the positioned event 118 (or a version thereof as modified by the view 110 ) may be dispatched next to the view 112 (dispatch event 130 ).
- the positioned event 118 (or a version thereof as modified by the view 112 ) may be dispatched next to the view 114 (dispatch event 132 ).
- the view 114 being the terminal view 122 , then may elect to consume or reject the positioned event 118 based on the configuration or programming of the view 114 .
- the UI framework supporting the GUI 106 may by default configure a view to reject any positioned event that occurs at a location outside of the bounds of the view.
- the view 110 would otherwise operate to automatically reject the positioned event 118 . This could prevent the larger-context positioned event processing, such as slop compensation or scrolling, that otherwise might be provided by the view 110 .
- the electronic device 102 may operate to bypass or disable this filtering so that parent views in the ancestor chain 126 consider the positioned event 118 even though it may have occurred at a location outside of the bounding box of the parent view.
- This bypass/disabling of spatial filtering may be achieved in any of a variety of ways.
- the dispatch of the positioned event 118 may occur through a framework that is separate from the default hierarchical dispatch process employed by the GUI 106 .
- the filtering may be overridden through the setting of a parameter when instantiating a view, the parameter controlling whether bounding-box filtering is to be to be applied for the instance of the view, through a function call that temporarily overrides all bounding box filtering, through use of a special view class that does not use bounding-box filtering, and the like.
- FIG. 2 illustrates an example hardware configuration 200 of the electronic device 102 in accordance with at least one embodiment of the present disclosure.
- the electronic device 102 includes one or more processors, such as central processing unit (CPU) 202 and graphics processing unit (GPU) 204 , one or more storage components, such as system memory 206 or a storage drive (not shown), a set 208 of user input components, and the display 104 interconnected via one or more busses 210 or other component interconnects.
- the hardware configuration 200 may further include various other components, such as one or more wireless interfaces, sensors, and the like, which have been omitted from FIG. 2 for purposes of clarity.
- the set 208 of user input components includes one or more user input components that may be manipulated by a user to perform a UI action, such as a touchscreen 212 , a mouse 214 , a trackpad 218 , a keyboard 218 , a microphone 220 , and the like.
- Certain user input components such as the touchscreen 212 , mouse 214 , and trackpad 218 , may receive input that has a positional aspect relative to the display space of the display 104 , and thus are positional input components.
- one or both of the processors 202 , 204 execute a software application 222 accessed from the system memory 206 or other storage component.
- the software application 222 manipulates the processors 202 , 204 and other components of the electronic device 102 to display the GUI 106 ( FIG. 1 ) via the display 104 , to receive user input relative to the GUI 106 via one or more of the set 208 of user input components, and to respond to the user input accordingly.
- the electronic device 102 may provide a user interface (UI) framework 224 that provides the lower-level processing and handling framework for the software application 222 and the GUI 106 .
- UI user interface
- the UI framework 224 may include, for example, a positioned event handler component 226 , a view tree management component 228 , a registry management component 230 , and a view rendering component 232 .
- the UI framework 224 is part of the operating system (OS) of the electronic device 102 , and thus the UI framework 224 , as well as the components 226 , 228 , 230 , 232 , are implemented as one or both of the processors 202 , 204 and one or more sets of executable instructions that are executed by one or both of the processors 202 , 204 to provide the functionality described herein.
- OS operating system
- some or all of the components 226 , 228 , 230 , 232 may be implemented in hardcoded logic, such as in an application specific integrated circuit (ASIC), in programmable logic, such as in a field programmable gate array (FPGA) or programmable logic device (PLD), or a combination thereof.
- ASIC application specific integrated circuit
- FPGA field programmable gate array
- PLD programmable logic device
- the view rendering component 232 operates to render the display frames representing the GUI 106 in the current layout 108 , and these display frames are then output to the display 104 for display.
- the view rendering component 232 references layout information 234 from the software application 222 , with the layout information 234 specifying the current views in the layout 108 as well as their relevant display parameters.
- the view rendering component 232 identifies the Z number or draw order of the views in the current layout and uses the Z numbers/draw order to render the views in accordance with their specified depths, which may result in partial or full occlusion of one or more views in the resulting display frame depending on the depths of the views and degree of overlap with other views.
- the view tree management component 228 operates to construct and update the view tree 124 (stored, for example, as one or more data structures in the system memory 206 ) for the current layout 108 .
- the Android framework provides two classes relating to views: a “View” object that occupies a (typically rectangular) area on the display 104 and is responsible for drawing and event handling; and a “ViewGroup” object which is a special view that can contain other views.
- a UI may designate leaf child views as “View” objects (e.g., view 114 with a “Button” widget”), and parent views as “ViewGroup” objects (e.g., views 110 , 110 ).
- the underlying Android OS may process the current layout 108 on display, identify the instantiated View objects and ViewGroup objects in the current layout 108 and their parent/child relationship, and build the view tree 124 based on this identified information.
- the registry management component 230 operates to construct and maintain the view display-space registry 116 , which may be stored as one or more data structures in the system memory 206 or other storage component of the electronic device 102 .
- the registry management component 230 may utilize the view tree 124 to identify the views in the current layout 108 , and in some implementations the positions of the views, and update the view display-space registry 116 accordingly.
- the view rendering component 232 may utilize a rendering tree to identify the views to be rendered, and thus the registry management component 230 alternatively may use this rendering tree in identifying the views in the current layout 108 , as well as their positions relative to display space.
- the representation of a particular view in the view display-space registry 116 may be based on information pertaining to that view as provided by the software application 222 (this information being identified herein as “view behavior/parameter information 236 ”).
- view behavior/parameter information 236 may identify size and position parameters for the view, and thus indicating the position of the view in the display space coordinates, which in turn may be reflected in some form in the view display-space registry 116 .
- the view behavior/parameter information 236 may indicate the class or type of the view, and from this the registry management component 230 may determine whether the view is configured to accept position-based user input. If not, the registry management component 230 may then filter out the view so as to prevent its unnecessary inclusion in the view display-space registry 116 .
- the positioned event handler component 226 operates to detect positioned events from user manipulation of the positional user input components and then hierarchically dispatch these positioned events among the views of the current layout 108 using the techniques described herein. To this end, the positioned event handler component 226 coordinates with the other components 228 , 230 , 232 of the UI framework 224 in identifying the terminal view intended for a positioned event, traversing the view tree 124 to construct the ancestor chain 126 , and sequentially dispatching the positioned event through one or more views of the ancestor chain 126 .
- FIG. 3 illustrates a method 300 for hierarchical dispatch in an unconstrained GUI in accordance with at least one embodiment.
- method 300 is described in the example context of the hardware configuration 200 of FIG. 2 , it should be appreciated that the method 300 may be similarly employed in other hardware configurations of an electronic device using the guidelines provided herein.
- method 300 illustrates events in a particular sequence, it should be appreciated that these events may be performed in another order as appropriate, or that some events may be omitted.
- the method 300 reflects two processes operating in parallel: a process of updating the layout 108 of the GUI 106 , as represented by flow 302 ; and a process of hierarchical dispatch of a positioned event based on the current layout 108 , as represented by flow 304 .
- the UI framework 224 monitors for user input or other stimuli that triggers an update to the layout 108 of the GUI 106 .
- the user may utilize a user input component to “drag” a view to a new location, to close a view, to open a view, or otherwise provide input that modifies the appearance or existence of a view.
- underlying processes occurring during execution of the software application 222 or during execution of the OS may trigger a change in the position, existence, or appearance of one or more views.
- the UI framework 224 reconstructs or otherwise modifies the layout 108 accordingly, and the view rendering component 232 renders display frames representative of the current layout 108 .
- the view tree management component 228 updates the view tree 124 as appropriate to reflect the view hierarchy of the views in the current layout 108 . Further in response to this change in the layout 108 , at block 308 the registry management component 230 updates the view display-space registry 116 to reflect views in the currently layout 108 and, in some implementations, the current positions of these views with respect to the display space coordinate frame.
- Flow 304 initiates at block 310 , whereby the positioned event handler component 226 monitors for user manipulation of a positional user input component that signals the start of a gesture or other positional user input.
- a positional user input component that signals the start of a gesture or other positional user input.
- an Android-based implementation of the UI framework 224 would instantiate a touch event of the class “MotionEvent” and assign this initial touch event the action code ACTION_DOWN and a set of axis values that include the X and Y coordinates of the touch event relative to the touchscreen 212 , along with a base pointer value (e.g., 0).
- the UI framework 224 For each subsequent touch event until the user has completed or canceled the touch gesture, the UI framework 224 would instantiate another touch event, assign the appropriate action code (e.g., ACTION_MOVE) and corresponding set of axis values, and an incremented pointer value. The last touch event for the gesture would be assigned an action code ACTION_UP (or ACTION_CANCELED if the user cancels the gesture action). Similar actions may be taken for mouse-based gestures or trackpad-based gestures.
- the appropriate action code e.g., ACTION_MOVE
- ACTION_UP or ACTION_CANCELED if the user cancels the gesture action.
- the registry management component 230 queries the view display-space registry 116 to identify the terminal view (e.g., terminal view 122 ) likely intended for receipt of the positional user input.
- the view display-space registry 116 registers views on the basis of their positions relative to the display space or otherwise includes reference to the positions of the views, and thus the registry management component 230 may identify the terminal view through application of a hit testing using the X,Y coordinates of the initial positioned event detected at block 310 . To illustrate, as described below with reference to FIG.
- the views of the current layout 108 may be maintained in the view display-space registry 116 based on a quadtree representation of the display space and the positions of the views therein, and thus the hit test may take the form of a traversal of the quadtree based on the X,Y coordinates.
- the view display-space registry 116 may take the form of a view map built as a 2D array of entries, each entry associated with a corresponding pixel block of one or more pixels of the display space and storing an indication of any view(s) positioned in the corresponding pixel block.
- the hit testing may take the form of indexing the appropriate entry based on the X,Y coordinates of the input positioned event, identifying the views (if any) represented in the entry, and if there are more than one view so represented, selecting the terminal view from the multiple represented views based on, for example, the Z numbers or draw order of the views.
- the view display-space registry 116 may take the form of a list of views and a representation of their positions relative to the display space, the hit testing make take the form of some form of search through the list based on comparisons of the representations of the listed view's positions and the X,Y coordinates.
- the view tree management component 228 locates the terminal view within the view tree 124 and then traverses up the view tree 124 to identify the ancestor chain (e.g., ancestor chain 126 ) of the terminal view.
- the parent view of a given view may be invoked by calling the function View#getParent( ) for that view.
- the view tree management component 228 may traverse up the view tree 124 by calling getParent( ) for the terminal view to identify the immediate parent view for the terminal view, then calling getParent( ) for this parent view to identify the parent view at the next higher level, and so on until the call to getParent( ) returns a null value, thereby indicating that the current view is the root parent view for the terminal view.
- the view tree management component 228 adds an identifier of the view (e.g., the identifier assigned to the view in the Android framework) to the ancestor chain.
- the ancestor chain thus may be constructed as, for example, a linked list with both forward and backward pointers, thereby allowing the positioned event handler component 226 to traverse from root view (with reference to the current view layout) to the terminal view.
- the positioned event handler component 226 initiates the hierarchical dispatch of the initial positioned event through the ancestor chain.
- the positioned event handler component 226 initially sets the current view to the identifier of the root view in the ancestor chain.
- the positioned event handler component 226 dispatches the initial positioned event to the current view, which in the first iteration of block 318 is the root view of the ancestor chain.
- the UI framework 224 may, by default, employ bounding-box-based filtering for dispatch events whereby a view may be configured to automatically reject any positioned event having a location that is outside of the bounding box of the view.
- the UI framework 224 may take action to disable or bypass this filtering.
- the function call View#isTransformedTouchPointInView( ) returns a Boolean value indicating whether a location (x,y) supplied with the function call is within the bounding box or other bounds of the corresponding view, and the basis of the default filtering of positioned events is based on whether this function call returns a True or False value.
- the library for this function call, or the compilation of this function call may be configured for such views to either be disabled or to always return a value of True, thereby overriding the default operation of this function call.
- the spatial check using the function call View#isTransformedTouchPointInView( ) may be replaced manually during development of the software application 222 or during build/compilation to include a directed dispatch to a single child view known at that time.
- the current view to which the initial positioned event has been dispatched processes the initial positioned event to determine whether the positioned event should be rejected, consumed, or modified by the current view.
- this processing can include evaluation of the initial positioned event for higher-level gesture context, such as for purposes of handling touch event slop or scrolling events.
- the current view elects to consume or modify the initial positioned event
- the initial positioned event is consumed or modified by the current view. Further, in the event that the positioned event is modified, the modified positioned event is then dispatched down the ancestor chain in the same manner as the unmodified initial positioned event would otherwise be dispatched down the ancestor chain.
- all subsequent positioned events in that sequence are by default intercepted by, or dispatched directly to, that view.
- the current view consumes or modifies the initial positioned event
- all subsequent positioned events are dispatched or intercepted by the current view until the gesture is completed or canceled.
- the positioned event handler component 226 checks whether the current view is the terminal view of the ancestor chain. If not, at block 328 the positioned event handler component 226 sets the current view to the next view of the ancestor chain, and the process of blocks 318 , 320 , 322 , 324 , and 326 is repeated for this next view as the current view. Otherwise, if the current view that rejected the initial positioned event is the terminal view, then the UI framework 224 may conclude that the user input was spurious or in error, and thus terminate any further processing of the initial positioned event at block 330 .
- the view display-space registry 116 is implemented as one or more data structures used to store information identifying the views of the current layout 108 , and this information is used to identify the terminal view associated with the position of a positioned event.
- the view display-space registry 116 may take any of a variety of forms in accordance with the guidelines provided herein, FIGS. 4-6 illustrate methods for constructing and maintaining certain example data structures for the view display-space registry 116 .
- FIG. 4 depicts an example method 400 for constructing and maintaining the view display-space registry 116 in the form of a quadtree data structure.
- the method 400 initiates at block 402 , whereby the registry management component 230 utilizes the information from the current layout 108 to identify the views in the current layout and uses positional information obtained for the identified views to determine the positions within the display space.
- the registry management component 230 constructs a quadtree data structure 406 that represents the views and their identified positions.
- the top node 408 of the quadtree data structure 406 represents the display space.
- the display space is spatially separated into four quadrants, which are represented by the four nodes immediately under node 408 . Any quadrant having a view positioned therein is then itself partitioned into four sub-quadrants, each represented by a corresponding node. This process is recursively repeated for a specified number of levels of the quad tree, or until no further divisions of a sub-quadrant are necessary.
- all terminal leaf nodes either contain entries for one or more views that overlap the corresponding sub-quadrant of the display space, or are null, or empty leaf nodes.
- the layout 108 may accommodate views of different depths, and thus some views may partially or fully occlude other views in the layout 108 , there may be multiple views that overlap a given sub-quadrant, and thus the terminal leaf node for that sub-quadrant may have multiple entries, one for each view present in that sub-quadrant.
- These entries may store an identifier (ID) of the corresponding view, as well as an identifier of the depth of the view, such as the view's Z value or draw order (e.g., as represented by the numbers “0”, “1”, and “2” in the quadtree data structure 406 ).
- ID an identifier
- draw order e.g., as represented by the numbers “0”, “1”, and “2” in the quadtree data structure 406 ).
- the registry management component 230 traverses the quadtree to find the terminal leaf node that represents the sub-quadrant containing the (X,Y) location of the positioned event. In the event that this terminal leaf node is a null node, the hit test fails and the UI framework 224 ceases processing of the positioned event. In the event that there is a single entry at the terminal leaf node, the registry management component 230 returns the view ID stored at this single entry as the terminal view overlapping the location of the positioned event.
- the registry management component 230 may select, for example, the view having the highest Z value (that is, the least-deep view) as the terminal view, and thus return the view ID of this view as the terminal view.
- FIG. 5 depicts a method 500 for constructing and maintaining the view display-space registry 116 as a pixel-block-based array of entries in accordance with some embodiments.
- the view rendering component 232 may generate one or more display frames representative of the display view of the current layout 108 , where the display frames represent the display-space view of the current layout 108 , including occlusion of deeper (higher-Z) views that are overlapped by shallower (lower-Z) views.
- the view rendering component 232 may utilize a rendering tree that identifies each view that is to be visible in the display frame to be rendered, as well as its layout within the display space.
- this rendering tree may serve as an efficient representation of the views of interest, and their positions, for the current layout 108 . Accordingly, the method 500 initiates at block 502 with the view rendering component 232 determining or accessing a render tree for the current layout 108 . At block 504 , the view rendering component 232 renders a display frame based on the rendering tree.
- the rendered display frame includes a 2D array of pixels, which the registry management component 230 may logically partition into a set of pixel blocks, with each pixel block including one or more pixels of this 2D array of pixels.
- the display frame may be logically partitioned into an array of pixel blocks of 4 ⁇ 4, 8 ⁇ 8, or 16 ⁇ 16 pixels.
- the registry management component 230 also constructs a view map 510 including a 2D array of entries 512 , with each entry 512 associated with a corresponding pixel block. With this, at block 506 , the registry management component 230 uses the rendering tree to identify, for each pixel block, whether any of the views of the current layout overlap the location of the pixel block.
- the registry management component 230 fills the entry associated with each pixel block with information identifying any views determined to overlap the corresponding pixel block.
- the entry 512 corresponding to that pixel block may be subdivided into multiple sub-entries, with each sub-entry storing the ID of a corresponding view.
- Each subentry may also include the Z-number or draw order of the view, or the sub-entries may be organized according to Z-number or draw order.
- the method 500 may be advantageously implemented by the GPU 204 . Moreover, in view of the tight correlation between the rendering of the pixel blocks of the display frame and the construction of view map 510 based on these pixel blocks, in some embodiments the method 500 may be performed as part of the display frame rendering process, with each vector unit of the GPU 204 performing both the rendering process for the corresponding pixel block as well as the overlapping view identification process for the same pixel block.
- the registry management component 230 may perform a hit test using the view map 510 to identify the terminal view associated with a positioned event at location (X,Y) relative to the display space by identifying the pixel block located at the coordinates (X,Y), identifying the entry 512 associated with that pixel block.
- the registry management component 230 returns a null value, and the dispatch process terminates.
- the view ID of this single view is returned by the registry management component 230 as the terminal view.
- the view ID of the view having the lowest Z value/draw order may be returned as the terminal view.
- FIG. 6 illustrates a method 600 for constructing an implementation of the view display-space registry 116 as a list-based data structure in accordance with at least one embodiment.
- the method 600 initiates at block 602 , wherein the registry management component 230 utilizes the information from the current layout 108 to identify the views in the current layout and their corresponding positional information.
- the registry management component 230 generates a view list 605 based on the identified views.
- the view list 605 contains a list of entries 607 , each entry 607 representing a corresponding view and having one or more fields, such as an index field storing an index value for the entry, a view ID field storing a view ID of the view represented by the entry 607 , and a depth field storing the Z value or draw order value for the view.
- the registry management component 230 may identify those views of the current layout 108 that are not configured to receive positional user input and filter out such views so that the view list 605 contains entries 607 only for views identified as capable of receiving positional user input or as having an indeterminate capability with regard to receiving positional user input, as represented by block 606 .
- this filtering process may be omitted.
- the registry management component 230 may perform a hit test to identify the terminal view for a positioned event by searching through the view list 605 to identify a listed view that has a position that overlaps with the location of the positioned event.
- the position of each view may be determined at the point of generation of the corresponding entry 607 and included in a corresponding position field (not shown) of the entry 607 .
- the position of a view under consideration may be determined by utilizing one or more function calls that return dimensional or positional information for the view.
- the search of the view list 605 utilize any of a variety of search methodologies.
- the search may include a straightforward sequential search starting at the first entry in the list, then on to the second entry in the list, and so forth.
- the view list 605 may be at least rudimentarily sorted by some parameter, such as by Z-number, overall view size, etc., and the search may leverage this sorting, such as by sorting the entries based on corresponding Z-number and then performing a prioritized search based on Z-number order.
- certain aspects of the techniques described above may implemented by one or more processors of a processing system executing software.
- the software includes one or more sets of executable instructions stored or otherwise tangibly embodied on a non-transitory computer readable storage medium.
- the software can include the instructions and certain data that, when executed by the one or more processors, manipulate the one or more processors to perform one or more aspects of the techniques described above.
- the non-transitory computer readable storage medium can include, for example, a magnetic or optical disk storage device, solid state storage devices such as Flash memory, a cache, random access memory (RAM) or other non-volatile memory device or devices, and the like.
- the executable instructions stored on the non-transitory computer readable storage medium may be in source code, assembly language code, object code, or other instruction format that is interpreted or otherwise executable by one or more processors.
- a computer readable storage medium may include any storage medium, or combination of storage media, accessible by a computer system during use to provide instructions and/or data to the computer system.
- Such storage media can include, but is not limited to, optical media (e.g., compact disc (CD), digital versatile disc (DVD), Blu-Ray disc), magnetic media (e.g., floppy disc, magnetic tape, or magnetic hard drive), volatile memory (e.g., random access memory (RAM) or cache), non-volatile memory (e.g., read-only memory (ROM) or Flash memory), or microelectromechanical systems (MEMS)-based storage media.
- optical media e.g., compact disc (CD), digital versatile disc (DVD), Blu-Ray disc
- magnetic media e.g., floppy disc, magnetic tape, or magnetic hard drive
- volatile memory e.g., random access memory (RAM) or cache
- non-volatile memory e.g., read-only memory (ROM) or Flash memory
- MEMS microelectro
- the computer readable storage medium may be embedded in the computing system (e.g., system RAM or ROM), fixedly attached to the computing system (e.g., a magnetic hard drive), removably attached to the computing system (e.g., an optical disc or Universal Serial Bus (USB)-based Flash memory), or coupled to the computer system via a wired or wireless network (e.g., network accessible storage (NAS)).
- system RAM or ROM system RAM or ROM
- USB Universal Serial Bus
- NAS network accessible storage
Abstract
Description
- Field of the Disclosure
- The present disclosure relates generally to graphical user interfaces and, more particularly, to receiving and processing touch events and other positioned events in a graphical user interface.
- Description of the Related Art
- Graphical user interfaces (GUIs) enable the use of multiple windows, or views, by which information may be displayed to a user or by which input may be received from a user. Often, this input is provided through the use of a touchscreen, trackpad, mouse, or other positional input component. In a conventional system, the user's interaction with the GUI via a positional input component takes the form of one or more positioned events, each having a two-dimensional location relative to the display space of the system. For each of these positioned events, the underlying GUI framework operates to dispatch the input event to the intended view for processing. Typically, the GUI implements a view hierarchy (also often referred to as a “view tree”) of views presently displayed, and representing the parent-child relationships between these views. The dispatch of an input event thus typically involves dispatching the input event down the view hierarchy. In many instances, the positioned event may be intercepted or modified by a parent view of the intended view, such as to account for touch “slop” or to differentiate between different types of gesture inputs, as the input event traverses the view hierarchy.
- In a GUI configuration whereby each child view is required to be completely contained within the bounding box of the parent view, the dispatch of view events down a view hierarchy is relatively straightforward in that each parent view receives a positioned event based on the location of the positioned event overlapping the bounding box, or being within the bounds, of the parent view object, and the parent view need only pass an input event to whichever child view object overlaps the positioned event location. However, it may be desirable for aesthetic reasons or other design reasons to provide a view layout in which the positioning of child view objects are not limited by the bounding boxes of their parent view objects. In such instances, the location of the input event intended for a particular view may not fall within the boundary of the parent view object of that particular view. Conventional spatial-based hierarchical event dispatch processes, which constrain a view object to accept only positioned events within the bounding box of the view object, are unable to accurately dispatch and process positioned events in such instances.
- The present disclosure may be better understood, and its numerous features and advantages made apparent to those skilled in the art by referencing the accompanying drawings. The use of the same reference symbols in different drawings indicates similar or identical items.
-
FIG. 1 is a diagram illustrating a process for dispatch of positioned events in an electronic device utilizing an unconstrained GUI in accordance with at least one embodiment of the present disclosure. -
FIG. 2 is a block diagram illustrating an example hardware configuration of the electronic device ofFIG. 1 in accordance with at least one embodiment of the present disclosure. -
FIG. 3 is a flow diagram illustrating a method for positioned event dispatch for an unconstrained GUI in accordance with at least one embodiment of the present disclosure. -
FIG. 4 is a diagram illustrating a method for determining a quadtree data structure representing positioning of views of a layout in accordance with at least one embodiment of the present disclosure. -
FIG. 5 is a diagram illustrating a method for determining a view map data structure representing positioning of views of a layout in accordance with at least one embodiment of the present disclosure. -
FIG. 6 is a diagram illustrating a method for determining a list data structure representing views of a layout in accordance with at least one embodiment of the present disclosure. -
FIGS. 1-6 illustrate example devices and techniques for the processing of positioned input events in an “unconstrained” GUI—that is, a GUI that does not constrain the position of a child view to the bounding box or other boundary of the parent view. An electronic device provides for display of a GUI having a layout of views. A user may utilize a touchscreen, trackpad, mouse, or other positional input component to provide input via the GUI in the form of positioned input events (hereinafter, “positioned events” for brevity) relative to the views in the current layout. The electronic device maintains a view display-space registry in the form of a data structure representative of the views in the current layout and their positions relative to the layout or display space of the display of the electronic device. In response to a positioned event, the electronic device uses the view display-space registry to identify the view for which the positioned event is likely intended—this view being identified herein as the “terminal view.” The electronic device then identifies the location of the terminal view in a view hierarchy for the current layout and works up the view hierarchy from the terminal view to build an ancestor chain representing the chain of views from the top parent view down to the terminal view from the view hierarchy. The electronic device then may sequentially dispatch the positioned event in the ancestor chain until a view in the ancestor chain consumes or modifies the positioned event or the positioned event is ultimately rejected by the terminal view. As part of this dispatch process, filtering of positioned events based on the locations of the positioned events may be disabled or bypassed, thereby allowing each view in the ancestor chain to consider the positioned event regardless of the relationship between the location of the positioned event and a bounding box or other bounds of a non-terminal view. - Through utilization of the view display-space registry to identify a terminal view independent of any parent view, construction of the ancestor chain up from the terminal view, and sequential dispatch of a positioned event down this ancestor chain, an ancestor view may consider the positioned input without having to identify the child view to which the positioned input is to be dispatched. As such, the relationship between the position of the child view and the boundary of the parent view is not germane to the dispatch of the positioned event, which allows a child view to be positioned partially or fully outside the bounds of the parent view while still permitting the expected hierarchical processing of positioned events. That is, as each ancestor view is provided the opportunity to consume, delay, or otherwise modify a positioned event, processing of larger-context user input, such as scrolling, swipe gestures, multi-touch gestures, and the like, continues to be handled appropriately.
- For ease of reference, examples and implementations of various aspects are described below with reference to, or in the context of, the Android operating system (OS) framework (hereinafter, “Android framework”) and its corresponding terminology as promulgated by Google Inc. However, these references are exemplary only and are not intended to be limiting. The identified aspects may be similarly implemented in other OS frameworks or user interface (UI) frameworks using the guidelines provided herein.
-
FIG. 1 illustrates anexample process 100 for dispatching positioned events for GUI that does not constrain the position of a child view to the bounding box or other boundary of the parent view (hereinafter, a “constrained GUI”) in accordance with at least one embodiment. Theprocess 100 is performed by anelectronic device 102 having adisplay 104 and one or more positional user input components (not shown inFIG. 1 ), such as a touch screen, trackpad, mouse, and the like. Theelectronic device 102 may include, for example, a compute-enabled cellular phone, a tablet computer, a compute-enabled watch or other compute-enabled wearable device, a notebook computer, a desktop computer, a game console, a remote controller, a network appliance, a server computer, a home automation controller, an automotive display interface, a compute-enabled medical device, and the like. - As depicted, the
electronic device 102 provides aGUI 106 to a user via thedisplay 104. TheGUI 106 includes alayout 108 of views currently displayed in the GUI, such asviews views view 114 is a button view. Further,view 114 is a child view ofview 112, which in turn is a child view ofview 110, and thus view 110 is parent to view 112, which in turn is parent to view 114. As also shown byFIG. 1 , theGUI 106 is an unconstrained GUI in that the views of theGUI 106 may be at least partially or fully positioned outside of the boundaries of their parent views. To illustrate,view 114 is located entirely outside of the boundary ofview 112, andview 112 likewise is located entirely outside of the boundary ofview 110. Because of this unconstrained relationship between parent view and child view, a conventional bounding-box-based hierarchical dispatch process would likely fail to appropriately process a positioned event. To illustrate, if the user were to initiate a touch gesture by initiating contact with a touchscreen (not shown) at a location that overlaps the position of theview 112, this location is outside of the boundary of theview 110, and thus when the positioned event corresponding to the initial touchscreen contact is dispatched down a view hierarchy in a conventional spatial-based hierarchical dispatch process, theview 110 would reject the positioned event because the location of the positioned event is outside of the boundary of theview 110. - To prevent such boundary-based rejection of positioned events and thus enable the
GUI 106 to operate effectively as an unconstrained GUI, theelectronic device 102 employs an unconstrained hierarchical dispatch technique (process 100) that operates to dispatch positioned events in a manner that does not rely on bounding-box-based filtering while continuing to enable hierarchical event dispatch for processing of larger-context user input events. To this end, theelectronic device 102 maintains a view display-space registry 116 that stores information representing some or all of the views of thecurrent view layout 108 and their positions relative to thelayout 108 or to the display space. The view display-space registry 116 may include any of a variety of data structures or combinations of data structures. To illustrate, as described in greater detail below with reference toFIGS. 4-6 , the view display-space registry 116 may include a quadtree data structure, a list of views, or an array-based data structure that map or otherwise reference the positions of the associated views to the display space of thedisplay 104. In some embodiments, the view display-space registry 116 represents all views in thelayout 108. However, as some views may not be configured to receive user input, or may more particularly, may not be configured to receive position-based input, theelectronic device 102 may filter out such views so that only views configured to receive user input, or more specifically, position-based input, are represented in the view display-space registry 116. - In response to the user manipulating a positional input component, the
GUI 106 signals an initial positionedevent 118, which includes a two-dimensional (2D) location identifier (denoted “(X,Y)”) corresponding to the 2D location in the display space of thedisplay 104 at which the positionedevent 118 occurred. For example, this location identifier can identify the position in display space where a user first contacted a touchscreen, the position in display space of a cursor when a mouse button or trackpad button is engaged, and so on. For the following example, it is assumed that this positioned event occurred at a location (denoted inFIG. 1 with the concentric rings of contact point 120) in the display space that overlaps with the location of the button widget ofview 114. - The positioned
event 118 triggers theelectronic device 102 to perform a lookup into, or otherwise access, the view display-space registry 116 to identify the view likely intended by the user to be the target or recipient of thepositional event 118. This view is identified herein as the “terminal”view 122 for the positionedevent 118. As described in greater detail below, the process of identifying theterminal view 122 generally entails identification of those views of thecurrent layout 108 that have a bounding box overlapping the location (X,Y) of the positionedevent 118. It will be appreciated that there may be multiple views that overlap in thelayout 108, and thus there may be multiple views that overlap at the location (X,Y). In such instances, theelectronic device 102 selects theterminal view 122 from the multiple views based on one or more selection criteria. For example, because the view “on top” in thelayout 108 is likely the view intended to receive the user input, theelectronic device 102 may utilize the Z number or draw order of each view to select the appropriate view. As another example, if one of the overlapping views is the current “in focus” view, this is a strong hint that the user intended the “in focus” view as the intended view for the user input. For the example ofFIG. 1 , the positionedevent 118 occurs at location (X,Y), which overlaps with a button widget ofview 114, and thus view 114 is postulated as theterminal view 122. - Although the
electronic device 102 identifies theterminal view 122 using the view display-space registry 116 and thus could dispatch the positionedevent 118 directly to theterminal view 122, this would bypass hierarchical dispatch of the positioned event to the ancestor views of theterminal view 122 and thus prevent any larger-context processing of the positionedevent 118, including detection of multi-touch gestures, compensation for touch slop, discernment between similar types of gestures (e.g., touch-to-drag vs. touch-to-press gestures). Accordingly, to enable this hierarchical dispatch in theunconstrained GUI 106, theelectronic device 102 also identifies those views that are ancestors to theterminal view 122. The underlying operating system (OS) framework or user interface (UI) framework supporting theGUI 106 typically maintains a view tree 124 (or view hierarchy) that both identifies the views present in thecurrent layout 108 and identifies the parent-child relationships between these views. - Accordingly, to identify those views that should have the opportunity to consider the positioned
event 118 before it is provided to theterminal view 122, theelectronic device 102 identifies theterminal view 122 within theview tree 124 and then sequences up theview tree 124 to identify each ancestor view of the terminal view 122 (assuming theterminal view 122 has at least one ancestor view). Theelectronic device 102 constructs anancestor chain 126 that represents the one or more ancestor views of theterminal view 122 and their hierarchical arrangement as determined by the sequencing up theview tree 124 by theelectronic device 102. In the example ofFIG. 1 ,view 112 is the parent of view 114 (as terminal view 122) andview 110 is the parent ofview 112, and thus the resultingancestor chain 126 would be: view 110→view 112→view 114. - With the
ancestor chain 126 so constructed or otherwise identified, theelectronic device 102 then hierarchically dispatches the positionedevent 118 sequentially to the views in theancestor chain 126. Each view may then reject, consume, or modify the dispatched positionedevent 118 based on the configuration or programming of the view. In the event that the view has rejected or modified the positionedevent 118, theelectronic device 102 then may dispatch the rejected/modified positionedevent 118 to the next view in theancestor chain 126. Thus, in the example ofFIG. 1 , the positionedevent 118 is dispatched first to the view 110 (dispatch event 128). In the event that theview 110 does not consume the positionedevent 118, the positioned event 118 (or a version thereof as modified by the view 110) may be dispatched next to the view 112 (dispatch event 130). In the event that theview 112 does not consume the positionedevent 118, the positioned event 118 (or a version thereof as modified by the view 112) may be dispatched next to the view 114 (dispatch event 132). Theview 114, being theterminal view 122, then may elect to consume or reject the positionedevent 118 based on the configuration or programming of theview 114. - As noted above, the UI framework supporting the
GUI 106 may by default configure a view to reject any positioned event that occurs at a location outside of the bounds of the view. Under this constraint, in the example ofFIG. 1 whereby the positionedevent 118 occurs at location (X,Y) outside of the bounds of theview 110, theview 110 would otherwise operate to automatically reject the positionedevent 118. This could prevent the larger-context positioned event processing, such as slop compensation or scrolling, that otherwise might be provided by theview 110. Accordingly, in implementations with this default bounding-box filtering of positioned events, theelectronic device 102 may operate to bypass or disable this filtering so that parent views in theancestor chain 126 consider the positionedevent 118 even though it may have occurred at a location outside of the bounding box of the parent view. This bypass/disabling of spatial filtering may be achieved in any of a variety of ways. For example, the dispatch of the positionedevent 118 may occur through a framework that is separate from the default hierarchical dispatch process employed by theGUI 106. As another example, the filtering may be overridden through the setting of a parameter when instantiating a view, the parameter controlling whether bounding-box filtering is to be to be applied for the instance of the view, through a function call that temporarily overrides all bounding box filtering, through use of a special view class that does not use bounding-box filtering, and the like. -
FIG. 2 illustrates anexample hardware configuration 200 of theelectronic device 102 in accordance with at least one embodiment of the present disclosure. In the depicted example, theelectronic device 102 includes one or more processors, such as central processing unit (CPU) 202 and graphics processing unit (GPU) 204, one or more storage components, such assystem memory 206 or a storage drive (not shown), a set 208 of user input components, and thedisplay 104 interconnected via one ormore busses 210 or other component interconnects. Thehardware configuration 200 may further include various other components, such as one or more wireless interfaces, sensors, and the like, which have been omitted fromFIG. 2 for purposes of clarity. The set 208 of user input components includes one or more user input components that may be manipulated by a user to perform a UI action, such as atouchscreen 212, a mouse 214, atrackpad 218, akeyboard 218, amicrophone 220, and the like. Certain user input components, such as thetouchscreen 212, mouse 214, andtrackpad 218, may receive input that has a positional aspect relative to the display space of thedisplay 104, and thus are positional input components. - In operation, one or both of the
processors 202, 204 execute asoftware application 222 accessed from thesystem memory 206 or other storage component. During execution, thesoftware application 222 manipulates theprocessors 202, 204 and other components of theelectronic device 102 to display the GUI 106 (FIG. 1 ) via thedisplay 104, to receive user input relative to theGUI 106 via one or more of the set 208 of user input components, and to respond to the user input accordingly. To facilitate the operation of theGUI 106 in this manner, theelectronic device 102 may provide a user interface (UI)framework 224 that provides the lower-level processing and handling framework for thesoftware application 222 and theGUI 106. To this end, theUI framework 224 may include, for example, a positionedevent handler component 226, a viewtree management component 228, aregistry management component 230, and aview rendering component 232. In some embodiments, theUI framework 224 is part of the operating system (OS) of theelectronic device 102, and thus theUI framework 224, as well as thecomponents processors 202, 204 and one or more sets of executable instructions that are executed by one or both of theprocessors 202, 204 to provide the functionality described herein. In other embodiments, some or all of thecomponents - The
view rendering component 232 operates to render the display frames representing theGUI 106 in thecurrent layout 108, and these display frames are then output to thedisplay 104 for display. For this rendering process, theview rendering component 232references layout information 234 from thesoftware application 222, with thelayout information 234 specifying the current views in thelayout 108 as well as their relevant display parameters. As part of this rendering process, theview rendering component 232 identifies the Z number or draw order of the views in the current layout and uses the Z numbers/draw order to render the views in accordance with their specified depths, which may result in partial or full occlusion of one or more views in the resulting display frame depending on the depths of the views and degree of overlap with other views. - The view
tree management component 228 operates to construct and update the view tree 124 (stored, for example, as one or more data structures in the system memory 206) for thecurrent layout 108. To illustrate, the Android framework provides two classes relating to views: a “View” object that occupies a (typically rectangular) area on thedisplay 104 and is responsible for drawing and event handling; and a “ViewGroup” object which is a special view that can contain other views. Using this classification scheme, a UI may designate leaf child views as “View” objects (e.g., view 114 with a “Button” widget”), and parent views as “ViewGroup” objects (e.g., views 110, 110). Thus, while thesoftware application 222 is executing, the underlying Android OS (one embodiment of the UI framework 224) may process thecurrent layout 108 on display, identify the instantiated View objects and ViewGroup objects in thecurrent layout 108 and their parent/child relationship, and build theview tree 124 based on this identified information. - The
registry management component 230 operates to construct and maintain the view display-space registry 116, which may be stored as one or more data structures in thesystem memory 206 or other storage component of theelectronic device 102. Theregistry management component 230 may utilize theview tree 124 to identify the views in thecurrent layout 108, and in some implementations the positions of the views, and update the view display-space registry 116 accordingly. Theview rendering component 232 may utilize a rendering tree to identify the views to be rendered, and thus theregistry management component 230 alternatively may use this rendering tree in identifying the views in thecurrent layout 108, as well as their positions relative to display space. The representation of a particular view in the view display-space registry 116 may be based on information pertaining to that view as provided by the software application 222 (this information being identified herein as “view behavior/parameter information 236”). To illustrate, the view behavior/parameter information 236 may identify size and position parameters for the view, and thus indicating the position of the view in the display space coordinates, which in turn may be reflected in some form in the view display-space registry 116. As another example, the view behavior/parameter information 236 may indicate the class or type of the view, and from this theregistry management component 230 may determine whether the view is configured to accept position-based user input. If not, theregistry management component 230 may then filter out the view so as to prevent its unnecessary inclusion in the view display-space registry 116. - The positioned
event handler component 226 operates to detect positioned events from user manipulation of the positional user input components and then hierarchically dispatch these positioned events among the views of thecurrent layout 108 using the techniques described herein. To this end, the positionedevent handler component 226 coordinates with theother components UI framework 224 in identifying the terminal view intended for a positioned event, traversing theview tree 124 to construct theancestor chain 126, and sequentially dispatching the positioned event through one or more views of theancestor chain 126. - The operations of the
components hardware configuration 200 of theelectronic device 102 may be more fully understood with reference toFIG. 3 , which illustrates amethod 300 for hierarchical dispatch in an unconstrained GUI in accordance with at least one embodiment. Althoughmethod 300 is described in the example context of thehardware configuration 200 ofFIG. 2 , it should be appreciated that themethod 300 may be similarly employed in other hardware configurations of an electronic device using the guidelines provided herein. Further, whilemethod 300 illustrates events in a particular sequence, it should be appreciated that these events may be performed in another order as appropriate, or that some events may be omitted. Themethod 300 reflects two processes operating in parallel: a process of updating thelayout 108 of theGUI 106, as represented byflow 302; and a process of hierarchical dispatch of a positioned event based on thecurrent layout 108, as represented byflow 304. - Turning first to flow 302, at
block 306 theUI framework 224 monitors for user input or other stimuli that triggers an update to thelayout 108 of theGUI 106. For example, the user may utilize a user input component to “drag” a view to a new location, to close a view, to open a view, or otherwise provide input that modifies the appearance or existence of a view. Alternatively, underlying processes occurring during execution of thesoftware application 222 or during execution of the OS may trigger a change in the position, existence, or appearance of one or more views. In such an event, theUI framework 224 reconstructs or otherwise modifies thelayout 108 accordingly, and theview rendering component 232 renders display frames representative of thecurrent layout 108. Further, the viewtree management component 228 updates theview tree 124 as appropriate to reflect the view hierarchy of the views in thecurrent layout 108. Further in response to this change in thelayout 108, atblock 308 theregistry management component 230 updates the view display-space registry 116 to reflect views in the currentlylayout 108 and, in some implementations, the current positions of these views with respect to the display space coordinate frame. -
Flow 304 initiates atblock 310, whereby the positionedevent handler component 226 monitors for user manipulation of a positional user input component that signals the start of a gesture or other positional user input. To illustrate, upon detection of an initial touch event to thetouchscreen 212 indicating the start of a touch gesture, an Android-based implementation of theUI framework 224 would instantiate a touch event of the class “MotionEvent” and assign this initial touch event the action code ACTION_DOWN and a set of axis values that include the X and Y coordinates of the touch event relative to thetouchscreen 212, along with a base pointer value (e.g., 0). For each subsequent touch event until the user has completed or canceled the touch gesture, theUI framework 224 would instantiate another touch event, assign the appropriate action code (e.g., ACTION_MOVE) and corresponding set of axis values, and an incremented pointer value. The last touch event for the gesture would be assigned an action code ACTION_UP (or ACTION_CANCELED if the user cancels the gesture action). Similar actions may be taken for mouse-based gestures or trackpad-based gestures. - In the event that the
UI framework 224 signals an initial positioned event (e.g., a MotionEvent with action code=ACTION_DOWN), atblock 312 theregistry management component 230 queries the view display-space registry 116 to identify the terminal view (e.g., terminal view 122) likely intended for receipt of the positional user input. In some embodiments, the view display-space registry 116 registers views on the basis of their positions relative to the display space or otherwise includes reference to the positions of the views, and thus theregistry management component 230 may identify the terminal view through application of a hit testing using the X,Y coordinates of the initial positioned event detected atblock 310. To illustrate, as described below with reference toFIG. 4 , the views of thecurrent layout 108 may be maintained in the view display-space registry 116 based on a quadtree representation of the display space and the positions of the views therein, and thus the hit test may take the form of a traversal of the quadtree based on the X,Y coordinates. As described below with reference toFIG. 5 , the view display-space registry 116 may take the form of a view map built as a 2D array of entries, each entry associated with a corresponding pixel block of one or more pixels of the display space and storing an indication of any view(s) positioned in the corresponding pixel block. In this case, the hit testing may take the form of indexing the appropriate entry based on the X,Y coordinates of the input positioned event, identifying the views (if any) represented in the entry, and if there are more than one view so represented, selecting the terminal view from the multiple represented views based on, for example, the Z numbers or draw order of the views. Alternatively, as described below with reference toFIG. 6 , the view display-space registry 116 may take the form of a list of views and a representation of their positions relative to the display space, the hit testing make take the form of some form of search through the list based on comparisons of the representations of the listed view's positions and the X,Y coordinates. - With the terminal view identified, at
block 314 the viewtree management component 228 locates the terminal view within theview tree 124 and then traverses up theview tree 124 to identify the ancestor chain (e.g., ancestor chain 126) of the terminal view. In the Android framework, the parent view of a given view may be invoked by calling the function View#getParent( ) for that view. Thus, the viewtree management component 228 may traverse up theview tree 124 by calling getParent( ) for the terminal view to identify the immediate parent view for the terminal view, then calling getParent( ) for this parent view to identify the parent view at the next higher level, and so on until the call to getParent( ) returns a null value, thereby indicating that the current view is the root parent view for the terminal view. As each view is identified as an ancestor, the viewtree management component 228 adds an identifier of the view (e.g., the identifier assigned to the view in the Android framework) to the ancestor chain. The ancestor chain thus may be constructed as, for example, a linked list with both forward and backward pointers, thereby allowing the positionedevent handler component 226 to traverse from root view (with reference to the current view layout) to the terminal view. - With the ancestor chain constructed, the positioned
event handler component 226 initiates the hierarchical dispatch of the initial positioned event through the ancestor chain. Atblock 316, the positionedevent handler component 226 initially sets the current view to the identifier of the root view in the ancestor chain. Atblock 318, the positionedevent handler component 226 dispatches the initial positioned event to the current view, which in the first iteration ofblock 318 is the root view of the ancestor chain. As explained above, theUI framework 224 may, by default, employ bounding-box-based filtering for dispatch events whereby a view may be configured to automatically reject any positioned event having a location that is outside of the bounding box of the view. Accordingly, atblock 320 theUI framework 224 may take action to disable or bypass this filtering. For example, in the Android framework, the function call View#isTransformedTouchPointInView( ) returns a Boolean value indicating whether a location (x,y) supplied with the function call is within the bounding box or other bounds of the corresponding view, and the basis of the default filtering of positioned events is based on whether this function call returns a True or False value. Accordingly, for views identified at build time or compile time to be views that do not spatially constrain their child views, the library for this function call, or the compilation of this function call, may be configured for such views to either be disabled or to always return a value of True, thereby overriding the default operation of this function call. Alternatively, for such views, the spatial check using the function call View#isTransformedTouchPointInView( ) may be replaced manually during development of thesoftware application 222 or during build/compilation to include a directed dispatch to a single child view known at that time. - At
block 322, the current view to which the initial positioned event has been dispatched processes the initial positioned event to determine whether the positioned event should be rejected, consumed, or modified by the current view. In the event that the current view is an ancestor of the terminal view, this processing can include evaluation of the initial positioned event for higher-level gesture context, such as for purposes of handling touch event slop or scrolling events. In the event that the current view elects to consume or modify the initial positioned event, atblock 324 the initial positioned event is consumed or modified by the current view. Further, in the event that the positioned event is modified, the modified positioned event is then dispatched down the ancestor chain in the same manner as the unmodified initial positioned event would otherwise be dispatched down the ancestor chain. Further, in the Android framework and other UI frameworks, after a view has elected to consume or modify a positioned event in a sequence of positioned events representing a user input gesture, all subsequent positioned events in that sequence are by default intercepted by, or dispatched directly to, that view. In keeping with this configuration, in at least one embodiment, if the current view consumes or modifies the initial positioned event, then all subsequent positioned events are dispatched or intercepted by the current view until the gesture is completed or canceled. - Returning to block 322, in the event that the current view rejects the initial positioned event, the hierarchical dispatch process moves on to the next view in the ancestor chain. Accordingly, to verify that there is a next view in the ancestor chain, at
block 326 the positionedevent handler component 226 checks whether the current view is the terminal view of the ancestor chain. If not, atblock 328 the positionedevent handler component 226 sets the current view to the next view of the ancestor chain, and the process ofblocks UI framework 224 may conclude that the user input was spurious or in error, and thus terminate any further processing of the initial positioned event atblock 330. - As explained above, the view display-
space registry 116 is implemented as one or more data structures used to store information identifying the views of thecurrent layout 108, and this information is used to identify the terminal view associated with the position of a positioned event. Although the view display-space registry 116 may take any of a variety of forms in accordance with the guidelines provided herein,FIGS. 4-6 illustrate methods for constructing and maintaining certain example data structures for the view display-space registry 116. -
FIG. 4 depicts anexample method 400 for constructing and maintaining the view display-space registry 116 in the form of a quadtree data structure. Themethod 400 initiates atblock 402, whereby theregistry management component 230 utilizes the information from thecurrent layout 108 to identify the views in the current layout and uses positional information obtained for the identified views to determine the positions within the display space. - With the views and their positions relative to the display space so identified, at
block 404 theregistry management component 230 constructs aquadtree data structure 406 that represents the views and their identified positions. In this process, the top node 408 of thequadtree data structure 406 represents the display space. The display space is spatially separated into four quadrants, which are represented by the four nodes immediately under node 408. Any quadrant having a view positioned therein is then itself partitioned into four sub-quadrants, each represented by a corresponding node. This process is recursively repeated for a specified number of levels of the quad tree, or until no further divisions of a sub-quadrant are necessary. In thequadtree data structure 406, all terminal leaf nodes either contain entries for one or more views that overlap the corresponding sub-quadrant of the display space, or are null, or empty leaf nodes. As thelayout 108 may accommodate views of different depths, and thus some views may partially or fully occlude other views in thelayout 108, there may be multiple views that overlap a given sub-quadrant, and thus the terminal leaf node for that sub-quadrant may have multiple entries, one for each view present in that sub-quadrant. These entries may store an identifier (ID) of the corresponding view, as well as an identifier of the depth of the view, such as the view's Z value or draw order (e.g., as represented by the numbers “0”, “1”, and “2” in the quadtree data structure 406). - Thus, to perform a hit test on the
quadtree data structure 406, theregistry management component 230 traverses the quadtree to find the terminal leaf node that represents the sub-quadrant containing the (X,Y) location of the positioned event. In the event that this terminal leaf node is a null node, the hit test fails and theUI framework 224 ceases processing of the positioned event. In the event that there is a single entry at the terminal leaf node, theregistry management component 230 returns the view ID stored at this single entry as the terminal view overlapping the location of the positioned event. In the event that there are multiple entries representing multiple overlapping views at the positioned event location, theregistry management component 230 may select, for example, the view having the highest Z value (that is, the least-deep view) as the terminal view, and thus return the view ID of this view as the terminal view. -
FIG. 5 depicts amethod 500 for constructing and maintaining the view display-space registry 116 as a pixel-block-based array of entries in accordance with some embodiments. As noted above, theview rendering component 232 may generate one or more display frames representative of the display view of thecurrent layout 108, where the display frames represent the display-space view of thecurrent layout 108, including occlusion of deeper (higher-Z) views that are overlapped by shallower (lower-Z) views. Theview rendering component 232 may utilize a rendering tree that identifies each view that is to be visible in the display frame to be rendered, as well as its layout within the display space. As a user input is less likely to be directed to a view that is not visible or largely occluded, this rendering tree may serve as an efficient representation of the views of interest, and their positions, for thecurrent layout 108. Accordingly, themethod 500 initiates atblock 502 with theview rendering component 232 determining or accessing a render tree for thecurrent layout 108. Atblock 504, theview rendering component 232 renders a display frame based on the rendering tree. - The rendered display frame includes a 2D array of pixels, which the
registry management component 230 may logically partition into a set of pixel blocks, with each pixel block including one or more pixels of this 2D array of pixels. To illustrate, the display frame may be logically partitioned into an array of pixel blocks of 4×4, 8×8, or 16×16 pixels. Theregistry management component 230 also constructs aview map 510 including a 2D array ofentries 512, with eachentry 512 associated with a corresponding pixel block. With this, atblock 506, theregistry management component 230 uses the rendering tree to identify, for each pixel block, whether any of the views of the current layout overlap the location of the pixel block. At block 508, theregistry management component 230 fills the entry associated with each pixel block with information identifying any views determined to overlap the corresponding pixel block. In the event that there are multiple views overlapping a given pixel block, theentry 512 corresponding to that pixel block may be subdivided into multiple sub-entries, with each sub-entry storing the ID of a corresponding view. Each subentry may also include the Z-number or draw order of the view, or the sub-entries may be organized according to Z-number or draw order. - Due to the highly parallelized nature of the determination of the views overlapping each pixel block, the
method 500 may be advantageously implemented by the GPU 204. Moreover, in view of the tight correlation between the rendering of the pixel blocks of the display frame and the construction ofview map 510 based on these pixel blocks, in some embodiments themethod 500 may be performed as part of the display frame rendering process, with each vector unit of the GPU 204 performing both the rendering process for the corresponding pixel block as well as the overlapping view identification process for the same pixel block. - As the
view map 510 maps views to each and every pixel block overlapped by the view in the display space, theregistry management component 230 may perform a hit test using theview map 510 to identify the terminal view associated with a positioned event at location (X,Y) relative to the display space by identifying the pixel block located at the coordinates (X,Y), identifying theentry 512 associated with that pixel block. In the event that the identifiedentry 512 is empty, then theregistry management component 230 returns a null value, and the dispatch process terminates. In the event that theentry 512 identifies a single view, the view ID of this single view is returned by theregistry management component 230 as the terminal view. In the event that theentry 512 identifies multiple views, the view ID of the view having the lowest Z value/draw order may be returned as the terminal view. - The implementation of the view display-
space registry 116 as a quadtree data structure as shown inFIG. 4 , a 2D pixel-block-based view map as shown inFIG. 5 , or other spatial-based organization of views may be impracticable from due to performance, storage, or power limitations. Accordingly,FIG. 6 illustrates amethod 600 for constructing an implementation of the view display-space registry 116 as a list-based data structure in accordance with at least one embodiment. Themethod 600 initiates atblock 602, wherein theregistry management component 230 utilizes the information from thecurrent layout 108 to identify the views in the current layout and their corresponding positional information. Atblock 604, theregistry management component 230 generates aview list 605 based on the identified views. As shown, theview list 605 contains a list ofentries 607, eachentry 607 representing a corresponding view and having one or more fields, such as an index field storing an index value for the entry, a view ID field storing a view ID of the view represented by theentry 607, and a depth field storing the Z value or draw order value for the view. - Depending on the particular configuration of the
GUI 106, some of the views in thecurrent layout 108 may not be configured to receive positional user input, and thus cannot consume or modify a positioned event triggered by positional user input. As such, during the construction of theview list 605 atblock 604, theregistry management component 230 may identify those views of thecurrent layout 108 that are not configured to receive positional user input and filter out such views so that theview list 605 containsentries 607 only for views identified as capable of receiving positional user input or as having an indeterminate capability with regard to receiving positional user input, as represented byblock 606. However, in implementations where only a relatively small number of views in any given layout are anticipated, this filtering process may be omitted. - As illustrated by block 608, the
registry management component 230 may perform a hit test to identify the terminal view for a positioned event by searching through theview list 605 to identify a listed view that has a position that overlaps with the location of the positioned event. To this end, the position of each view may be determined at the point of generation of thecorresponding entry 607 and included in a corresponding position field (not shown) of theentry 607. Alternatively, the position of a view under consideration may be determined by utilizing one or more function calls that return dimensional or positional information for the view. The search of theview list 605 utilize any of a variety of search methodologies. For example, the search may include a straightforward sequential search starting at the first entry in the list, then on to the second entry in the list, and so forth. Alternatively, theview list 605 may be at least rudimentarily sorted by some parameter, such as by Z-number, overall view size, etc., and the search may leverage this sorting, such as by sorting the entries based on corresponding Z-number and then performing a prioritized search based on Z-number order. - In some embodiments, certain aspects of the techniques described above may implemented by one or more processors of a processing system executing software. The software includes one or more sets of executable instructions stored or otherwise tangibly embodied on a non-transitory computer readable storage medium. The software can include the instructions and certain data that, when executed by the one or more processors, manipulate the one or more processors to perform one or more aspects of the techniques described above. The non-transitory computer readable storage medium can include, for example, a magnetic or optical disk storage device, solid state storage devices such as Flash memory, a cache, random access memory (RAM) or other non-volatile memory device or devices, and the like. The executable instructions stored on the non-transitory computer readable storage medium may be in source code, assembly language code, object code, or other instruction format that is interpreted or otherwise executable by one or more processors.
- A computer readable storage medium may include any storage medium, or combination of storage media, accessible by a computer system during use to provide instructions and/or data to the computer system. Such storage media can include, but is not limited to, optical media (e.g., compact disc (CD), digital versatile disc (DVD), Blu-Ray disc), magnetic media (e.g., floppy disc, magnetic tape, or magnetic hard drive), volatile memory (e.g., random access memory (RAM) or cache), non-volatile memory (e.g., read-only memory (ROM) or Flash memory), or microelectromechanical systems (MEMS)-based storage media. The computer readable storage medium may be embedded in the computing system (e.g., system RAM or ROM), fixedly attached to the computing system (e.g., a magnetic hard drive), removably attached to the computing system (e.g., an optical disc or Universal Serial Bus (USB)-based Flash memory), or coupled to the computer system via a wired or wireless network (e.g., network accessible storage (NAS)).
- Note that not all of the activities or elements described above in the general description are required, that a portion of a specific activity or device may not be required, and that one or more further activities may be performed, or elements included, in addition to those described. Still further, the order in which activities are listed are not necessarily the order in which they are performed. Also, the concepts have been described with reference to specific embodiments. However, one of ordinary skill in the art appreciates that various modifications and changes can be made without departing from the scope of the present disclosure as set forth in the claims below. Accordingly, the specification and figures are to be regarded in an illustrative rather than a restrictive sense, and all such modifications are intended to be included within the scope of the present disclosure.
- Benefits, other advantages, and solutions to problems have been described above with regard to specific embodiments. However, the benefits, advantages, solutions to problems, and any property(s) that may cause any benefit, advantage, or solution to occur or become more pronounced are not to be construed as a critical, required, or essential property of any or all the claims. Moreover, the particular embodiments disclosed above are illustrative only, as the disclosed subject matter may be modified and practiced in different but equivalent manners apparent to those skilled in the art having the benefit of the teachings herein. No limitations are intended to the details of construction or design herein shown, other than as described in the claims below. It is therefore evident that the particular embodiments disclosed above may be altered or modified and all such variations are considered within the scope of the disclosed subject matter. Accordingly, the protection sought herein is as set forth in the claims below.
Claims (20)
Priority Applications (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/989,087 US20170192942A1 (en) | 2016-01-06 | 2016-01-06 | Hierarchical positioned event dispatch |
PCT/US2016/068802 WO2017120077A1 (en) | 2016-01-06 | 2016-12-28 | Hierarchical positioned event dispatch |
EP16826861.3A EP3374869A1 (en) | 2016-01-06 | 2016-12-28 | Hierarchical positioned event dispatch |
CN201680074739.4A CN108475219A (en) | 2016-01-06 | 2016-12-28 | Hierarchical Location events dispatcher |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/989,087 US20170192942A1 (en) | 2016-01-06 | 2016-01-06 | Hierarchical positioned event dispatch |
Publications (1)
Publication Number | Publication Date |
---|---|
US20170192942A1 true US20170192942A1 (en) | 2017-07-06 |
Family
ID=57822092
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/989,087 Abandoned US20170192942A1 (en) | 2016-01-06 | 2016-01-06 | Hierarchical positioned event dispatch |
Country Status (4)
Country | Link |
---|---|
US (1) | US20170192942A1 (en) |
EP (1) | EP3374869A1 (en) |
CN (1) | CN108475219A (en) |
WO (1) | WO2017120077A1 (en) |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10606448B2 (en) | 2017-01-04 | 2020-03-31 | International Business Machines Corporation | Searching and displaying child objects of a parent object |
US20200159332A1 (en) * | 2017-05-18 | 2020-05-21 | Atmel Corporation | Techniques for identifying user interface elements and systems and devices using the same |
US10693745B2 (en) * | 2018-02-27 | 2020-06-23 | Servicenow, Inc. | Defining and enforcing operational associations between configuration item classes in managed networks |
CN111522548A (en) * | 2020-03-24 | 2020-08-11 | 北京三快在线科技有限公司 | Project function expansion method and device, electronic equipment and computer readable medium |
US11151995B2 (en) * | 2018-03-27 | 2021-10-19 | Samsung Electronics Co., Ltd. | Electronic device for mapping an invoke word to a sequence of inputs for generating a personalized command |
EP3761165A4 (en) * | 2018-03-02 | 2021-12-01 | Huizhou TCL Mobile Communication Co., Ltd | Graphical user interface redrawing method, terminal device and computer readable storage medium |
AU2021200444B2 (en) * | 2018-02-27 | 2022-01-27 | Servicenow, Inc. | Defining and enforcing operational associations between configuration item classes in managed networks |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050086666A1 (en) * | 2001-06-08 | 2005-04-21 | Xsides Corporation | Method and system for maintaining secure data input and output |
US20080086497A1 (en) * | 2006-10-05 | 2008-04-10 | Daniel John Wallace | Enabling notifications pertaining to an asset |
US20080086349A1 (en) * | 2006-10-05 | 2008-04-10 | Rob Petrie | Unreported event status change determination and alerting |
US20080086391A1 (en) * | 2006-10-05 | 2008-04-10 | Kurt Maynard | Impromptu asset tracking |
US20080086508A1 (en) * | 2006-10-05 | 2008-04-10 | Paul Ballew | System and method for providing asset management information to a customer |
US20080086685A1 (en) * | 2006-10-05 | 2008-04-10 | James Janky | Method for delivering tailored asset information to a device |
US20080103955A1 (en) * | 2006-10-25 | 2008-05-01 | Microsoft Corporation | Accounting for trusted participants in an online advertising exchange |
Family Cites Families (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7933929B1 (en) * | 2005-06-27 | 2011-04-26 | Google Inc. | Network link for providing dynamic data layer in a geographic information system |
US8645458B2 (en) * | 2007-11-20 | 2014-02-04 | General Electric Company | Systems and methods for delivering media content and improving diagnostic reading efficiency |
JP2010120231A (en) * | 2008-11-19 | 2010-06-03 | Oki Data Corp | Print device and print control program |
US9177298B2 (en) * | 2009-12-15 | 2015-11-03 | International Business Machines Corporation | Abbreviated user interface for instant messaging to minimize active window focus changes |
EP2508972B1 (en) * | 2011-04-05 | 2017-10-18 | 2236008 Ontario Inc. | Portable electronic device and method of controlling same |
US20120320073A1 (en) * | 2011-06-14 | 2012-12-20 | Obscura Digital, Inc. | Multiple Spatial Partitioning Algorithm Rendering Engine |
US8600921B2 (en) * | 2011-09-15 | 2013-12-03 | Google Inc. | Predicting user navigation events in a browser using directed graphs |
CN102707958B (en) * | 2012-06-08 | 2017-07-14 | 北京奇虎科技有限公司 | A kind of interface generation method of calibration and equipment based on open platform |
EP2763041A1 (en) * | 2013-01-31 | 2014-08-06 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Apparatus, method and computer program for processing out-of-order events |
-
2016
- 2016-01-06 US US14/989,087 patent/US20170192942A1/en not_active Abandoned
- 2016-12-28 CN CN201680074739.4A patent/CN108475219A/en active Pending
- 2016-12-28 WO PCT/US2016/068802 patent/WO2017120077A1/en unknown
- 2016-12-28 EP EP16826861.3A patent/EP3374869A1/en not_active Withdrawn
Patent Citations (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050086666A1 (en) * | 2001-06-08 | 2005-04-21 | Xsides Corporation | Method and system for maintaining secure data input and output |
US7007025B1 (en) * | 2001-06-08 | 2006-02-28 | Xsides Corporation | Method and system for maintaining secure data input and output |
US20080086497A1 (en) * | 2006-10-05 | 2008-04-10 | Daniel John Wallace | Enabling notifications pertaining to an asset |
US20080086349A1 (en) * | 2006-10-05 | 2008-04-10 | Rob Petrie | Unreported event status change determination and alerting |
US20080086391A1 (en) * | 2006-10-05 | 2008-04-10 | Kurt Maynard | Impromptu asset tracking |
US20080086508A1 (en) * | 2006-10-05 | 2008-04-10 | Paul Ballew | System and method for providing asset management information to a customer |
US20080086685A1 (en) * | 2006-10-05 | 2008-04-10 | James Janky | Method for delivering tailored asset information to a device |
US8255358B2 (en) * | 2006-10-05 | 2012-08-28 | Trimble Navigation Limited | System and method for providing asset management information to a customer |
US9111234B2 (en) * | 2006-10-05 | 2015-08-18 | Trimble Navigation Limited | Enabling notifications pertaining to an asset |
US9536405B2 (en) * | 2006-10-05 | 2017-01-03 | Trimble Inc. | Unreported event status change determination and alerting |
US20080103955A1 (en) * | 2006-10-25 | 2008-05-01 | Microsoft Corporation | Accounting for trusted participants in an online advertising exchange |
Non-Patent Citations (1)
Title |
---|
Gamma et al., "Design PAtterns - Elements of Reusable Object-Oriented Software", Pearson Education, 1994, pages 220-245 * |
Cited By (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10606448B2 (en) | 2017-01-04 | 2020-03-31 | International Business Machines Corporation | Searching and displaying child objects of a parent object |
US20200159332A1 (en) * | 2017-05-18 | 2020-05-21 | Atmel Corporation | Techniques for identifying user interface elements and systems and devices using the same |
US11809626B2 (en) * | 2017-05-18 | 2023-11-07 | Atmel Corporation | Techniques for identifying user interface elements and systems and devices using the same |
US10693745B2 (en) * | 2018-02-27 | 2020-06-23 | Servicenow, Inc. | Defining and enforcing operational associations between configuration item classes in managed networks |
AU2021200444B2 (en) * | 2018-02-27 | 2022-01-27 | Servicenow, Inc. | Defining and enforcing operational associations between configuration item classes in managed networks |
EP3761165A4 (en) * | 2018-03-02 | 2021-12-01 | Huizhou TCL Mobile Communication Co., Ltd | Graphical user interface redrawing method, terminal device and computer readable storage medium |
US11461116B2 (en) | 2018-03-02 | 2022-10-04 | Huizhou Tcl Mobile Communication Co., Ltd. | Graphical user interface redrawing method. Terminal device and computer readable storage medium |
US11151995B2 (en) * | 2018-03-27 | 2021-10-19 | Samsung Electronics Co., Ltd. | Electronic device for mapping an invoke word to a sequence of inputs for generating a personalized command |
CN111522548A (en) * | 2020-03-24 | 2020-08-11 | 北京三快在线科技有限公司 | Project function expansion method and device, electronic equipment and computer readable medium |
Also Published As
Publication number | Publication date |
---|---|
WO2017120077A1 (en) | 2017-07-13 |
EP3374869A1 (en) | 2018-09-19 |
CN108475219A (en) | 2018-08-31 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20170192942A1 (en) | Hierarchical positioned event dispatch | |
US10579205B2 (en) | Edge-based hooking gestures for invoking user interfaces | |
CN106575196B (en) | Electronic device and method for displaying user interface thereof | |
US9250788B2 (en) | Gesture handlers of a gesture engine | |
US8881047B2 (en) | Systems and methods for dynamic background user interface(s) | |
US7523409B2 (en) | Methods and systems for operating multiple web pages in a single window | |
US8890808B2 (en) | Repositioning gestures for chromeless regions | |
US9383913B2 (en) | Touch screen device data filtering | |
US20150370427A1 (en) | Event response method for user interface of mobile device, and mobile device | |
US9886190B2 (en) | Gesture discernment and processing system | |
JP2013156992A (en) | One-click tagging user interface | |
US11429272B2 (en) | Multi-factor probabilistic model for evaluating user input | |
US20140082559A1 (en) | Control area for facilitating user input | |
US20140033129A1 (en) | Computing device and method for controlling desktop applications | |
KR20150024246A (en) | A method and system to implement a quasi-user interface for applications on an electronic device | |
US20130117711A1 (en) | Resize handle activation for resizable portions of a user interface | |
CN110471700A (en) | Graphic processing method, device, storage medium and electronic equipment | |
WO2017201655A1 (en) | Background application display method and apparatus, electronic device and computer program product | |
RU2656988C2 (en) | Text selection paragraph snapping | |
CN112578961B (en) | Application identifier display method and device | |
US11714538B2 (en) | Electronic device, method, and computer-readable medium for switchable bar region of user interface | |
US11320962B2 (en) | Method for handling on a mobile terminal a list of contents each associated to a sub-content | |
CN113139542A (en) | Target detection method, device, equipment and computer readable storage medium | |
US11366571B2 (en) | Visualization components including sliding bars | |
KR101363082B1 (en) | Terminal unit with graphic user interface and method for processing input event thereof |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:CRAIK, CHRISTOPHER;POWELL, ADAM WILLIAM;REEL/FRAME:037427/0498Effective date: 20160105 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044129/0001Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |