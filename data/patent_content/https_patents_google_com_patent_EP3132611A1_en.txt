EP3132611A1 - System and method for using closed captions for television viewership measurement - Google Patents
System and method for using closed captions for television viewership measurementInfo
- Publication number
- EP3132611A1 EP3132611A1 EP15719346.7A EP15719346A EP3132611A1 EP 3132611 A1 EP3132611 A1 EP 3132611A1 EP 15719346 A EP15719346 A EP 15719346A EP 3132611 A1 EP3132611 A1 EP 3132611A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- closed captioning
- identification
- content
- captioning data
- item
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000005259 measurement Methods 0.000 title claims abstract description 269
- 238000000034 method Methods 0.000 title claims description 45
- 238000003860 storage Methods 0.000 claims description 36
- 230000003247 decreasing effect Effects 0.000 claims description 8
- 230000001965 increasing effect Effects 0.000 claims description 7
- 238000010586 diagram Methods 0.000 description 18
- 230000005540 biological transmission Effects 0.000 description 16
- 238000012546 transfer Methods 0.000 description 14
- 238000012545 processing Methods 0.000 description 11
- 238000004422 calculation algorithm Methods 0.000 description 10
- 238000004590 computer program Methods 0.000 description 10
- 230000008569 process Effects 0.000 description 10
- 238000004891 communication Methods 0.000 description 9
- 230000006870 function Effects 0.000 description 6
- 230000003287 optical effect Effects 0.000 description 6
- 238000003491 array Methods 0.000 description 5
- 238000004364 calculation method Methods 0.000 description 5
- 230000001413 cellular effect Effects 0.000 description 4
- 235000014510 cooky Nutrition 0.000 description 4
- 238000012544 monitoring process Methods 0.000 description 4
- 230000008901 benefit Effects 0.000 description 3
- 238000009434 installation Methods 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 239000002131 composite material Substances 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 230000004044 response Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000005236 sound signal Effects 0.000 description 2
- 230000001360 synchronised effect Effects 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 230000003442 weekly effect Effects 0.000 description 2
- 230000002776 aggregation Effects 0.000 description 1
- 238000004220 aggregation Methods 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 230000033228 biological regulation Effects 0.000 description 1
- 230000008867 communication pathway Effects 0.000 description 1
- 238000012790 confirmation Methods 0.000 description 1
- 230000001186 cumulative effect Effects 0.000 description 1
- 238000013480 data collection Methods 0.000 description 1
- 238000013144 data compression Methods 0.000 description 1
- 230000001667 episodic effect Effects 0.000 description 1
- 239000000835 fiber Substances 0.000 description 1
- 230000001939 inductive effect Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 230000000737 periodic effect Effects 0.000 description 1
- 238000013439 planning Methods 0.000 description 1
- 238000010845 search algorithm Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 239000010409 thin film Substances 0.000 description 1
- 238000012384 transportation and delivery Methods 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/231—Content storage operation, e.g. caching movies for short term storage, replicating data over plural servers, prioritizing data for deletion
- H04N21/23109—Content storage operation, e.g. caching movies for short term storage, replicating data over plural servers, prioritizing data for deletion by placing content in organized collections, e.g. EPG data repository
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/442—Monitoring of processes or resources, e.g. detecting the failure of a recording device, monitoring the downstream bandwidth, the number of times a movie has been viewed, the storage space available from the internal hard disk
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/35—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users
- H04H60/37—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users for identifying segments of broadcast information, e.g. scenes or extracting programme ID
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/23418—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving operations for analysing video streams, e.g. detecting features or characteristics
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/251—Learning process for intelligent management, e.g. learning user preferences for recommending movies
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/258—Client or end-user data management, e.g. managing client capabilities, user preferences or demographics, processing of multiple end-users preferences to derive collaborative data
- H04N21/25866—Management of end-user data
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/258—Client or end-user data management, e.g. managing client capabilities, user preferences or demographics, processing of multiple end-users preferences to derive collaborative data
- H04N21/25866—Management of end-user data
- H04N21/25883—Management of end-user data being end-user demographical data, e.g. age, family status or address
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/258—Client or end-user data management, e.g. managing client capabilities, user preferences or demographics, processing of multiple end-users preferences to derive collaborative data
- H04N21/25866—Management of end-user data
- H04N21/25891—Management of end-user data being end-user preferences
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/442—Monitoring of processes or resources, e.g. detecting the failure of a recording device, monitoring the downstream bandwidth, the number of times a movie has been viewed, the storage space available from the internal hard disk
- H04N21/44213—Monitoring of end-user related data
- H04N21/44222—Analytics of user selections, e.g. selection of programs or purchase activity
- H04N21/44224—Monitoring of user activity on external systems, e.g. Internet browsing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/45—Management operations performed by the client for facilitating the reception of or the interaction with the content or administrating data related to the end-user or to the client device itself, e.g. learning user preferences for recommending movies, resolving scheduling conflicts
- H04N21/466—Learning process for intelligent management, e.g. learning user preferences for recommending movies
- H04N21/4667—Processing of monitored end-user data, e.g. trend analysis based on the log file of viewer selections
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/488—Data services, e.g. news ticker
- H04N21/4884—Data services, e.g. news ticker for displaying subtitles
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/488—Data services, e.g. news ticker
- H04N21/4888—Data services, e.g. news ticker for displaying teletext characters
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/63—Control signaling related to video distribution between client, server and network components; Network processes for video distribution between server and clients or between remote clients, e.g. transmitting basic layer and enhancement layers over different transmission paths, setting up a peer-to-peer communication via Internet between remote STB's; Communication protocols; Addressing
- H04N21/637—Control signals issued by the client directed to the server or network components
- H04N21/6377—Control signals issued by the client directed to the server or network components directed to server
Definitions
- Audiences for content blocks are typically measured via single-source data panels consisting of individuals or households recording content exposure over time.
- panel members carry a portable pager-sized device with a microphone that listens for embedded subaudible codes or watermarks in audio of media programs.
- the device records the codes it hears, indicating that the panel member was present while the program was being shown or played.
- the device periodically transmits its logs to a measurement server, which aggregates logs from a plurality of the devices to determine a total viewership for the program.
- the encoded text may be used to identify specific programs being watched by a viewer, and accordingly may be used for audience measurement via the systems and methods disclosed herein. Because each broadcaster already is generating and embedding the captioning, these systems and methods do not require any additional encoders to be installed at stations or cable providers.
- a small monitor or capture device may be installed at a participating panel member's home or other viewing location, and may receive the NTSC and/or ATSC video signal from a cable or HDTV decoder, set top box, digital video recorder (DVR), receiver, television output, or other such source.
- the capture device may decode the closed captioning signal (e.g. the encoded line 21 signal and/or embedded EIA-708 streams), and may transmit the decoded text or a hash of the decoded text to an audience measurement server.
- the measurement server may receive the text or hash from the capture device and compare the received data to a database of closed captioning text to identify matches.
- the database may be populated via one or more additional capture devices receiving local or national broadcast signals, or with data separately provided by broadcasters.
- the measurement server may determine that the panel member is watching a program having the corresponding closed captioning. Matching may be performed using very short windows, as small as 8 words or less, allowing quick identification of
- One implementation disclosed herein is a method for audience measurement.
- the method includes receiving, by an audience measurement engine executed by a processor of a first device, from a remote device, a first identification of closed captioning data received by the remote device during playback of an item of content.
- the method also includes matching, by the audience measurement engine, the first identification of closed captioning data received by the remote device to a second identification of closed captioning data stored in a database in a storage device of the first device.
- the method further includes retrieving, by the audience measurement engine, an identification of the item of content associated in the database with the second identification of closed captioning data, responsive to the match.
- the method also includes adding, by the audience measurement engine, a device identifier of the remote device to an audience list of the identified item of content stored in the storage device.
- the first identification of closed captioning data comprises closed captioning text. In other implementations of the method, the first identification of closed captioning data comprises a hash of closed captioning text. In one implementation, the method includes receiving, by the audience measurement engine, a second identification of closed captioning data received by a second device; and adding the second identification of closed captioning data to the database. In a further implementation, the second device is operated on behalf of the audience measurement engine. In another further implementation, the method includes receiving an identification of the item of content, associated with the second identification of closed captioning data; and adding the identification of the item of content to the database with the second identification of closed captioning data.
- the method includes calculating a hash of the first identification of closed captioning data; and identifying, within the database, an entry identifying an item of content at an index corresponding to the calculated hash, the index equal to a result of a hash of the second identification of closed captioning data.
- the method includes receiving, by the audience measurement engine from the remote device, a second identification of closed captioning data received by the remote device during playback of the item of content. The method also includes matching, by the audience measurement engine, the second identification of closed captioning data received by the remote device to a third identification of closed captioning data stored in the database.
- the method also includes retrieving, by the audience measurement engine, the identification of the item of content associated in the database with the third identification of closed captioning data, responsive to the match.
- the method further includes determining, by the audience measurement engine, that the device identifier of the remote device is included in the audience list of the identified item of content; and increasing, by the audience measurement engine, a confidence score associated with the device identifier of the remote device in the audience list of the identified item of content.
- the method includes decreasing, by the audience measurement engine, the confidence score associated with the device identifier of the remote device in the audience list of the identified item of content, responsive to not matching an identification of closed captioning data received by the remote device to a corresponding identification of closed captioning data associated with the item of content stored in the database within a predetermined time period.
- the method includes incrementing, by the audience measurement engine, an audience measurement counter for the item of content for each device identifier included in the audience list of the identified item of content having a confidence score greater than a threshold.
- a system for audience measurement including a capture device, comprising a video input, a closed captioning decoder connected to the video input, and a first network interface for transmitting a first identification of closed captioning data received by the capture device during playback of an item of content to an audience measurement server.
- the system also includes an audience measurement server comprising a processor executing a measurement engine, and a second network interface for receiving the identification of closed captioning data.
- the measurement engine is configured for matching the first identification of closed captioning data received by the capture device to a second identification of closed captioning data stored in a database in a storage device of the audience measurement server.
- the measurement engine is also configured for retrieving an identification of the item of content associated in the database with the second
- the first identification of closed captioning data comprises closed captioning text. In other implementations of the system, the first identification of closed captioning data comprises a hash of closed captioning text.
- the measurement engine is further configured for receiving a second identification of closed captioning data received by a second capture device; and adding the second identification of closed captioning data to the database. In a further implementation, the second capture device is operated on behalf of the audience measurement engine. In another further implementation, the measurement engine is further configured for receiving an identification of the item of content, associated with the second identification of closed captioning data, and adding the identification of the item of content to the database with the second identification of closed captioning data.
- the measurement engine is further configured for calculating a hash of the first identification of closed captioning data, and identifying, within the database, an entry identifying an item of content at an index corresponding to the calculated hash, the index equal to a result of a hash of the second identification of closed captioning data.
- the measurement engine is further configured for receiving, from the capture device, a second identification of closed captioning data received by the remote device during playback of the item of content; and matching the second identification of closed captioning data received by the capture device to a third identification of closed captioning data stored in the database.
- the measurement engine is also configured for retrieving the identification of the item of content associated in the database with the third identification of closed captioning data, responsive to the match.
- the measurement engine is further configured for determining that the device identifier of the capture device is included in the audience list of the identified item of content; and increasing a confidence score associated with the device identifier of the capture device in the audience list of the identified item of content.
- the measurement engine is further configured for decreasing the confidence score associated with the device identifier of the capture device in the audience list of the identified item of content, responsive to not matching an identification of closed captioning data received by the capture device to a corresponding identification of closed captioning data associated with the item of content stored in the database within a predetermined time period.
- the measurement engine is further configured for incrementing, by the audience measurement engine, an audience measurement counter for the item of content for each device identifier included in the audience list of the identified item of content having a confidence score greater than a threshold.
- Also disclosed herein is an implementation of a computer-readable storage medium storing instructions that when executed by one or more data processors, cause the one or more data processors to perform operations including receiving, from a remote device, a first identification of closed captioning data received by the remote device during playback of an item of content.
- the operations also include matching the first identification of closed captioning data received by the remote device to a second identification of closed captioning data stored in a database in a storage device.
- the operations further include retrieving an identification of the item of content associated in the database with the second identification of closed captioning data, responsive to the match; and adding a device identifier of the remote device to an audience list of the identified item of content stored in the storage device.
- FIG. 1A is a diagram of a system for using closed captions for audience
- FIG. IB is a diagram of a another system using closed captions for audience measurement, according to one implementation.
- FIG. 2A is a block diagram of a broadcast provider system, according to one implementation
- FIG. 2B is a block diagram of a closed captioning capture device, according to one implementation.
- FIG. 2C is a block diagram of an audience measurement server, according to one implementation;
- FIG. 3 is a diagram illustrating comparison of captured closed captioning data and generation of a confidence measurement for inclusion of a device in an audience measurement, according to one implementation
- FIG. 4A is a flow diagram of the steps taken in one implementation of a process for capturing closed captioning data by a client device, according to one implementation
- FIG. 4B is a flow diagram of the steps taken in one implementation of a process for matching received closed captioning data by an audience measurement server, according to one implementation.
- FIG. 4C is a flow diagram of the steps taken in one implementation of a process for measuring an audience of an item of content by an audience measurement server, according to one implementation.
- Measurement of an audience of content may be useful for measuring audience size or popularity of content for pricing and selling advertisement placements, planning content delivery schedules, or other such purposes.
- a provider may not have direct knowledge of the number of receivers tuned in at any time, due to the lack of a back channel or communication pathway from the receiver to the provider.
- some audience measurement systems have used panels of participating individuals who agree to fill out surveys or diaries of content they've seen or listened to. However, this system relies on self-reporting, which may have decreased accuracy.
- Another system requires panel participants to wear or carry a portable device that detects content played back in the vicinity via subaudible audio watermarks or codes, and records a log for subsequent transmission to the panel provider.
- this system requires watermarking encoders to be installed at every broadcast source to be measured as part of the signal chain, increasing expense and failure rates.
- embedded codes may be distorted or corrupted when data compression is applied, such as in digital video recorders or other systems.
- closed captioning data encoded in EIA- 608 and/or EIA-708 formats within the video signal, format.
- the closed captioning data is content-specific, and accordingly may be used to identify specific programs being watched by a viewer for audience measurement.
- FIG. 1A is a diagram of a system for using closed captions for audience
- a broadcaster 100 may deliver content to client systems via satellite or terrestrial radio frequency (RF) broadcasts, cable systems, or via Internet protocols (IP) such as streamed or downloaded content, VOD systems, or other such systems.
- RF radio frequency
- IP Internet protocols
- a broadcaster 100 may comprise a broadcast source such as a national broadcast network source, a regional or local network affiliate that receives and redistributes the network source (sometimes with additional local or regional-specific content), a cable broadcast provider, an Internet service provider (ISP), or other various affiliated and non-affiliated entities.
- Content may be received by a client system at a receiver 102a, which may comprise an antenna or satellite dish and demodulator or decoder, a cable receiver, a digital television (DTV) decoder, a set top box, a DVR, a computing device, or any other type and form of device for receiving content with closed captioning data.
- the receiver 102a may be connected to a multimedia system 106, such as a television, home theater system, or any other type and form of device for displaying audio and/or video content received and decoded by a receiver 102a.
- the receiver 102a and multimedia system 106 may be combined, as in many televisions with attached antennas or included cable demodulators, "smart" or Internet-attached televisions, or other such devices.
- a small monitoring or capture device 104 may be installed or deployed at a participating panel member's home or other viewing location, and may receive a video signal including closed captioning data (e.g. an ATSC or NTSC video signal with embedded closed captioning) from a receiver 102a and/or multimedia system 106 (e.g. cable or HDTV decoder, set top box, DVR, television output, multimedia receiver or switcher output, or other such source).
- closed captioning data e.g. an ATSC or NTSC video signal with embedded closed captioning
- multimedia system 106 e.g. cable or HDTV decoder, set top box, DVR, television output, multimedia receiver or switcher output, or other such source.
- the capture device 104 may be physically wired to the receiver 102a or multimedia system 106, while in other implementations, the capture device 104 may wirelessly receive the video signal including closed captioning data.
- the receiver 102a and/or multimedia system 106 may include a wireless transmitter streaming video content to a display (such as a Bluetooth connection to a projector, or other such system).
- the capture device 104 may also receive the transmitted video signal.
- the capture device 104 may comprise a receiver 102a and may receive transmissions directly such as terrestrial broadcast television signals.
- the capture device 104 may be portable, and may be carried by the participating panel member. Accordingly, "installation” or “deployment” of the capture device 104 may refer to physical installation, or may refer to the capture device 104 being in a location to receive a video signal with closed captioning data. In any of these
- the capture device 104 may decode the closed captioning signal (e.g. the encoded line 21 signal and/or embedded EIA-708 streams), and in some implementations, may transmit the decoded text or a hash of the decoded text to an audience measurement server 1 12 (discussed in more detail below) via a network 108.
- the closed captioning signal e.g. the encoded line 21 signal and/or embedded EIA-708 streams
- the capture device 104 may decode the closed captioning signal (e.g. the encoded line 21 signal and/or embedded EIA-708 streams), and in some implementations, may transmit the decoded text or a hash of the decoded text to an audience measurement server 1 12 (discussed in more detail below) via a network 108.
- Network 108 may be any form of computer network or combinations of networks that relay information between one or more client capture devices 104, and one or more audience measurement servers 112, as well as other devices not illustrated.
- network 108 may include the Internet and/or other types of data networks, such as a local area network (LAN), a wide area network (WAN), a cellular network, satellite network, or other types of data networks.
- Network 108 may also include any number of computing devices (e.g., computer, servers, routers, network switches, etc.) that are configured to receive and/or transmit data within network 108.
- Network 108 may further include any number of hardwired and/or wireless connections.
- a client device 104 may communicate wirelessly (e.g., via WiFi, cellular, radio, etc.) with a transceiver that is hardwired (e.g., via a fiber optic cable, a CAT5 cable, etc.) to other computing devices in network 108.
- a network 108 may be a virtual network, such as a virtual network between a plurality of virtual machines executed by a single physical machine, or a abstract network such as an offline transfer of data via physically movable media (e.g. a Sneakernet, transferring data via tape media, CD-ROM, flash media, external hard drives, floppy disks, etc.).
- a client device 104 may capture and store closed captioning information for subsequent transfer to a computing device via a universal serial bus (USB) or similar interface to be transmitted by said computing device via a network 108.
- USB universal serial bus
- a measurement system may also include a receiver 102b, which may be similar to a receiver 102a at a client system.
- Receiver 102b may receive content from a broadcaster 100 via terrestrial or satellite broadcast, cable system, Internet, or any other such means, and may output video to a measurement service capture device 110.
- a receiver 102b may be in the same geographical region as a receiver 102a.
- at least one receiver 102b may be deployed in each city including one or more panel members to capture the same broadcast from a local broadcaster 100.
- a receiver 102b may be deployed elsewhere, and may receive a similar, but different broadcast.
- a receiver 102b may receive a national network broadcast via a cable system, while a receiver 102a may receive a terrestrial broadcast from a local affiliate of the national network broadcaster.
- Such local affiliate broadcasts may include similar content, but may have different interstitial advertising, local newscasts, or other inserted or modified content.
- a plurality of receivers 102b may be deployed at a location; e.g. one per broadcaster to be measured.
- a receiver 102b may have a plurality of tuners, demodulators, or sub-receivers and may be able to receive and output a plurality of broadcasts simultaneously to a corresponding plurality of measurement service capture devices 1 10.
- the measurement system may include one or more measurement service capture devices 1 10, similar to a client capture device 104.
- the capture device 1 10 may decode the closed captioning signal (e.g. the encoded line 21 signal and/or embedded EIA-708 streams), and in some implementations, may transmit the decoded text or a hash of the decoded text to an audience measurement server 112.
- the transmission may be via a network 108, an internal or local network, or via another interface.
- the measurement service capture device 1 10 may include a USB, Bluetooth, or serial output for connection to a corresponding input device of an audience measurement server 1 12.
- a receiver 102b need not be located in geographic proximity to a measurement service capture device 110 and/or an audience measurement server 112.
- a receiver 102b may communicate with a measurement service capture device 110 via a network 108, such as the Internet; and/or a measurement service capture device 110 may communicate via a network 108 with an audience measurement server 112.
- a receiver 102b and/or measurement service capture device 110 may be deployed at a broadcast transmission site or studio and receive a pre-transmitter video feed or a feed from a monitoring receiver at the site or studio, and may transmit decoded closed captioning data to the audience measurement server 1 12 via a network 108.
- An audience measurement server 112 may comprise one or more computing devices, servers, desktop computers, rack mount computers, workstations, or other devices for receiving closed captioning data from client capture devices 104 and measurement service capture devices 1 10 and for correlating or matching the received data to determine if devices 104, 110 received the same content at a particular time.
- an audience measurement server 1 12 may be a virtual machine or machines executed by one or more physical machines, such as in a cloud service or server farm. Audience measurement servers 112 may be located in proximity to measurement service capture devices 1 10, or may be remote from one or more measurement service capture devices 1 10 and may communicate with the devices over a network 108.
- FIG. IB is a diagram of a another system using closed captions for audience measurement, according to one implementation.
- a client system or receiver 102a may receive content from a broadcaster via satellite or terrestrial broadcast, cable system, or streamed or downloaded via a network.
- the receiver 102a may include or connect to a digital video recorder (DVR), which may allow time-shifting and/or replay of received content.
- DVR digital video recorder
- the receiver 102a may also receive video-on-demand (VOD) comment, or content selected by a user for streaming or asynchronous transfer to the receiver 102a from the broadcaster 100 for playback via a multimedia system 106.
- VOD video-on-demand
- Client capture device 104 may receive the time- shifted content or replayed content from the DVR or on-demand, streamed, or downloaded content, and may decode closed captioning data and transmit the decoded data to an audience measurement server, provided line 21 or EIA-708 captioning is implemented. Accordingly, in such implementations, audiences for non-real-time broadcasts may be measured via the same systems as measurements of live broadcasts.
- a measurement system may include a database or storage device 1 14 storing closed captioning data, referred to generally as a closed captioning database 1 14.
- Closed captioning data for the database 1 14 may be received from the measurement service capture device 1 10, or may be received directly from a broadcaster 100.
- closed captioning data may be intercepted before encoding in the video signal and/or decoded via a monitoring output at a broadcast site or studio, and may be transmitted via a network 108 for storage in a closed captioning database 114.
- closed captioning data may be provided in non-real-time from the broadcaster 100 for inclusion in a closed captioning database 1 14.
- the broadcaster 100 may separately provide text or data files of closed captioning data to be embedded in a video signal during broadcast of a movie or television program, sometimes hours, days, or weeks in advance of broadcast.
- the broadcaster 100 may provide text or data files of closed captioning data for one or more items of content in a VOD library.
- the received data may be matched to the text or data files previously received from the broadcaster and stored in database 114.
- closed captioning data 114 may be part of the audience measurement server 112 or maintained by the audience measurement server 112. Accordingly, in such implementations, the audience measurement server 1 12 may receive closed captioning data from broadcaster(s) 100 and/or measurement service capture device(s) 1 10 and may store the data in the closed captioning database 1 14.
- Closed captioning database 114 may comprise a relational database, flat file, data file, or any other type and form of database.
- closed captioning text may be stored in the database 1 14 as text.
- a portion of closed captioning text e.g.
- Closed captioning database 114 may also include an identification of an item of content associated with the closed captioning data or portion of the closed captioning data.
- the data may be explicitly identified as associated with an item of content.
- the data may be associated with an item of content based on a broadcast schedule, embedded metadata, or other such information.
- the data may be associated with a channel and broadcast time that the content was received by a receiver 102b, and may be subsequently associated with the item of content based on a broadcast schedule, such as during a subsequent step of audience measurement.
- the measurement server 112 may receive closed captioning data or a hash of the data from a client capture device 104 and compare the received data to the database 114 of closed captioning data to identify matches.
- the measurement server 1 12 may use a search algorithm for a text string including the received text.
- the measurement server 112 may determine if an entry exists in the database at an index identified by the hash calculation value, such that existence of such entry (with an associated identification of a content) indicates that the received data from client capture device 104 matches data received from a measurement service capture device 110 or from a broadcaster 100.
- the measurement server 112 may determine that the item of content was received and played by receiver 102a to a multimedia system 106, and presumably was watched by the panel participant; accordingly, the measurement server 1 12 may identify the participant as an audience member of the item of content.
- a sliding window may be used to calculate hashes of closed captioning data for inclusion in the database or for comparison of closed captioning data received from a client capture device 104. For example, if the database is populated via hashes of strings of closed captioning data twenty words in length, then in some implementations, a comparison of a hash of received data from word number five to word number twenty-five may not match a hash of data from word one to word twenty. Accordingly, in such implementations, a sliding window (e.g. 1-20, 2-21, 3-22, etc.) may be used either for comparing hashes of received data from client capture device 104 or for populating the database 114.
- a sliding window e.g. 1-20, 2-21, 3-22, etc.
- Window length may be chosen to reliably identify an item of content, with larger windows having greater uniqueness, but requiring more data to create a match.
- older content or closed captioning data may be removed from the database. For example, many broadcast programs are presented daily or weekly (e.g. nightly newscasts or episodic sitcoms with identical introductions, etc.). Closed captioning data from these programs may be removed from the database 1 14 after a corresponding time period of a day or week, eliminating the possibility of data received from a client capture device 104 matching both a current presentation and a previous presentation of the same program.
- closed captioning data received from a client capture device 104 may be compared to closed captioning data in a database 114 for a "best", but not perfect match.
- strings of closed captioning data may be compared to find strings that match above a predetermined threshold, such as 50%, 75%, 90% or any other value.
- a predetermined threshold such as 50%, 75%, 90% or any other value.
- this may eliminate the need for a sliding window comparison or allow for a large slide in a window (e.g. windows that overlap by 50%, such as strings of words 1-20, 1 1-31, 21-41, etc.), as matching closed captioning strings will always match at a rate above the threshold, even if they do not start with the same word or character.
- matches may be detected if a program is the same, even if interstitial or local advertising received by the client capture device 104 is different.
- FIG. 2A is a block diagram of a broadcast provider system, according to one implementation.
- a broadcaster 100 may include one or more media sources 200. Although only one media source is illustrated, it may be readily appreciated that typical broadcasters 100 may include multiple studios, media play out sources, satellite downlinks, or other equipment, which may be mixed or selected via a mixer, router, switch, or other interface and provided to a closed captioning encoder or embedder 206, referred to generally as an encoder 206.
- encoders 206 may receive closed captioning data from one or more sources, such as a caption input interface 202 and/or a closed captioning data file 204, and may encode or embed the data in EIA-608 and/or EIA-708 format or other similar formats. Closed captioning may be inserted for live programming, such as live sports or news broadcast events via input interfaces 202 (e.g. computing devices, keyboards, text-to- speech converters, etc.); or may be provided by program producers or third-party services for pre-recorded content, such as movies or television programs. Closed captioning data files 204 may be sent to an encoder 206 via automation or other systems for synchronized embedding during playback for on-air broadcasting.
- sources such as a caption input interface 202 and/or a closed captioning data file 204
- Closed captioning may be inserted for live programming, such as live sports or news broadcast events via input interfaces 202 (e.g. computing devices, keyboards, text-to- speech converters, etc.
- output of an encoder 206 may be provided to a transmitter 208, such as a satellite transmitter, terrestrial transmitter, microwave transmitter, or cable modulator; may be provided to a web server 210 for streamed broadcasting; and/or may be provided to a VOD server 212 for transfer to a client responsive to a request.
- media content from a source 200 and closed captioning data 204 may be provided separately to a VOD server 212, without embedding, or for embedding via a client- side interface.
- FIG. 2B is a block diagram of a closed captioning capture device, such as a client capture device 104 or measurement service capture device 1 10, according to one
- a capture device 104, 1 10 may include a video input 220.
- Video input 220 may be any type and form of video input, including an analog composite or component video input, a baseband or RF video input, a digital video input, or any other type of input.
- a client capture device 104, 110 may include a video splitter 222 and a video output 224.
- a client capture device 104 may be configured for installation as an intermediary device between a video output of a receiver and a video input of a television.
- the client capture device 104 may include a video input 220 for connection to the receiver, video splitter 222 for splitting the input signal for processing by a closed captioning decoder 226, and video output 224 for connection to the television.
- the capture device may not include a video splitter 222 and video output 224.
- Decoder 226 may comprise hardware, software, or a combination of hardware and software.
- decoder 226 may comprise a CMOS integrated circuit (IC), such as a MCI 44144 series IC manufactured by Motorola Inc. of Schaumburg, Illinois or an equivalent IC; a programmable IC or field-programmable gate array (FPGA); or any other type and form of circuit or combination of circuits.
- the capture device 104, 110 may include a processor 234 and memory device 236, and may execute a software decoder 226, which may read a digital input or output of an analog-to-digital converter connected to video input 220.
- Decoder 226 may output one or more strings of closed captioning data.
- EIA-608 allows for four channels of information.
- decoder 226 may output a plurality of these channels, while in other implementations, decoder 226 may output a single channel or be selectively set to output a single channel.
- EIA-708 allows for 63 channels plus two backwards-compatible EIA-608 channels, and decoder 226 may be set to output one or more of the embedded channels.
- Hash calculator 228 may comprise hardware, software, or a combination of hardware and software for performing a hashing calculation on a string of output data from closed captioning decoder 226.
- hash calculator 228 may comprise an IC, PIC, FPGA, or other hardware programmed to perform a cryptographic or non-cryptographic hashing function, such as a message-digest algorithm (MD) hash (e.g. MD2, MD4, MD5, MD6, etc.), secure hash algorithm (SHA) hash, or any other type and form of hashing function.
- MD message-digest algorithm
- MD4 MD2, MD4, MD5, MD6, etc.
- SHA secure hash algorithm
- a hash calculator 228 may comprise a software algorithm, stored in memory 236 and executed by a processor 234 on an output of a decoder 226. As discussed above, a hash calculator 228 may perform a hashing calculation on any number of characters or words, and may utilize a sliding window to perform hashing calculations on overlapping data sets output from a decoder 226.
- an output of decoder 226 and/or hash calculator 228 may be buffered in a buffer 230, such as a First-in/First-out (FIFO) buffer, ring buffer, or similar memory structure.
- a buffer 230 such as a First-in/First-out (FIFO) buffer, ring buffer, or similar memory structure.
- FIFO First-in/First-out
- ring buffer or similar memory structure.
- data may be buffered in buffer 230 for a predetermined period of time or a predetermined amount of data may be buffered for subsequent transmission.
- an output of a buffer 230, and/or decoder 226 or hash calculator 228, may be transmitted or streamed via a network interface 232 to an audience measurement server.
- a network interface 232 may comprise any type and form of network interface, including a wired interface (e.g. Ethernet, including 10 Base T, 100 Base T, or 1000 Base T ("Gigabit")), a wireless interface (e.g. 802.11a, 802.1 lb, 802.1 lg, 802.1 In, 802.11.ac, Bluetooth, Bluetooth Low Energy, Near- field Communication (NFC)), a cellular interface, or any other type of interface for transmitting data over a network.
- a wired interface e.g. Ethernet, including 10 Base T, 100 Base T, or 1000 Base T (“Gigabit")
- a wireless interface e.g. 802.11a, 802.1 lb, 802.1 lg, 802.1 In, 802.11.ac, Bluetooth, Bluetooth Low Energy, Near- field Communication (NFC)
- NFC Near-
- network interface 232 may comprise a parallel or serial interface, such as a USB interface, an IEEE 1394 (Firewire) interface, an RS-232 interface, an RS-485 interface, or any other type and form of interface to another computing device.
- a parallel or serial interface such as a USB interface, an IEEE 1394 (Firewire) interface, an RS-232 interface, an RS-485 interface, or any other type and form of interface to another computing device.
- a second computing device may serve as an intermediary for
- a capture device may communicate via a USB interface with a desktop computer, which may transmit captured closed captioning data via an Ethernet interface to a network gateway or switch connected to the Internet for transmission to an audience measurement server.
- network interface 232 may be referred to as a communications interface.
- the capture device 104, 110 may store decoded and/or hashed data in a memory 236, for subsequent synchronization or transfer via a computing device connected to a network 108.
- a capture device 104, 110 may include a processor 234.
- Processor 234 may comprise any type and form of processing unit, including a microprocessor, application-specific integrated circuit (ASIC), FPGA, etc., or combinations of these or other processing units.
- processor 234 may be a multi-core processor or an array of processors.
- a capture device 104, 1 10 may also include memory 236, which may include, but is not limited to, electronic, optical, magnetic, or any other storage devices capable of providing processor 234 with program instructions.
- Memory 236 may include a floppy disk, CD-ROM, DVD, magnetic disk, memory chip, ROM, RAM, EEPROM, EPROM, flash memory, optical media, or any other suitable memory from which processor 234 can read instructions and, in some implementations, to which processor 234 can write decoded or hashed closed captioning data for subsequent transmission via network interface 232.
- the instructions may include code from any suitable computer programming language such as, but not limited to, C, C++, C#, Java, JavaScript, Perl, HTML, XML, Python and Visual Basic.
- a capture device 104, 1 10 may include a device identifier 238.
- Device identifier 238 may be an alphanumeric string, data string, serial number, media access control (MAC) address, internet protocol (IP) address, username or account name, globally unique identifier (GUID), cookie, random or pseudorandom number, or any other type and form of identifier, including combinations of these or other identifiers, to identify the capture device 104, 110.
- the device identifier 238 may be fixed to the device or preconfigured in the device, such as a manufacturer serial number or MAC address, while in other implementations, the device identifier 238 may be dynamically set by a panel provider, by the audience measurement server, or other entity, such as via a cookie or username.
- a unique or new device identifier 238 may be set for each communication to the audience measurement server, while in other implementations, the device identifier 238 may not be changed, or may be changed periodically (e.g. hourly, daily, weekly, etc.) or at other intervals (e.g. on restart of the capture device, login to an internet service, etc.).
- Device identifier 238 may be transmitted to the audience measurement server before, with, or subsequent to a transfer of decoded and/or hashed closed captioning data, such that the data may be identified as having been captured by the device 104, 110.
- a capture device 104, 110 may log in or establish an authenticated session with an audience measurement server using the device identifier 238.
- the capture device 104 may transmit closed captioning data in the body of a packet, with the device identifier included in the header of the packet.
- closed captioning data may be transmitted via a representational state transfer (REST) protocol, hypertext transfer protocol (HTTP) request (e.g. a POST or GET request with captioning data as a parameter-value pair), or via any other such application, session, or presentation layer protocol.
- REST representational state transfer
- HTTP hypertext transfer protocol
- closed captioning data may be transmitted via an options field of a transport layer protocol packet header, such as a transport control protocol (TCP) or user datagram protocol (UDP) packet.
- TCP transport control protocol
- UDP user datagram protocol
- closed captioning data may be provided as a serial bit stream.
- a capture device 104, 1 10 may include a power supply 240.
- Power supply 240 may comprise a battery, AC power supply, DC power supply, USB power supply, Power-over-Ethernet (PoE) power supply, inductive power supply, or any other type and form of power supply.
- a power supply 238 may be external from device 104, 110, such as an external AC-to-DC converter.
- a capture device 104, 110 may be very small, such as only a few cubic inches in size or less. As many of the features of a capture device 104, 110 may be implemented with small integrated circuits, the capture device 104, 110 may be inexpensive to manufacture, and may be unobtrusive when installed in a panel participant's home or other viewing location.
- FIG. 2C is a block diagram of an audience measurement server 112, according to one implementation.
- audience measurement server 112 may comprise a plurality of devices connected via a network, such as a server farm or cluster or a cloud of devices.
- one or more audience measurement servers 1 12 may comprise a virtual machine executed by a physical machine. Accordingly, in such implementations, audience measurement server 1 12 may comprise one or more of each of interfaces, memory, and processors 260-266.
- An audience measurement server 1 12 may include one or more storage device or capture device interfaces 260, and one or more network interfaces 262. As discussed above, in many implementations, a capture device 104, 1 10 may communicate with an audience measurement server 1 12 via a network 108 to a network interface 262.
- Network interface 262 may comprise any type and form of network interface, such as a wired interface (e.g. Ethernet), a wireless interface (e.g. 802.11a, 802.1 1b, 802. l lg, 802.1 1 ⁇ , 802.11.ac,
- Bluetooth Bluetooth Low Energy, NFC interface, etc.
- a cellular interface or any other type of interface for receiving data from capture devices 104, 1 10.
- an audience measurement server 1 12 may be deployed locally to an audience measurement capture device 110.
- the capture device may connect via a network interface 262, or via a capture device interface 260, including a parallel or serial interface, such as a USB interface, an IEEE 1394 (Firewire) interface, an RS-232 interface, an RS-485 interface, or any other type and form of interface.
- an audience measurement server 112 may connect to one or more storage devices, such as hard drives, flash drives, redundant arrays of independent disks (RAID arrays), network attached storage (NAS) devices, storage area network (SAN) devices, or any other type and form of storage.
- Such storage devices may store closed captioning data 114, as discussed above, received from one or more broadcasters 100, one or more audience measurement capture devices 1 10, or other data.
- a storage device may store audience measurement data 272, discussed in more detail below.
- An audience measurement server 112 may include one or more processors 266, including one or more microprocessors, ASIC circuits, FPGAs, etc., or combinations of these or other processing units.
- processor 266 may be a multi-core processor or an array of processors.
- a processor 266 may comprise a virtual processor executed by a physical processor.
- Processor 266 may be configured for executing a measurement engine 268 and/or hash calculator 270, as well as for
- An audience measurement server 1 12 may also include memory 264, which may include, but is not limited to, electronic, optical, magnetic, or any other storage devices capable of providing processor 266 with program instructions.
- Memory 264 may include a floppy disk, CD-ROM, DVD, magnetic disk, memory chip, ROM, RAM, EEPROM, EPROM, flash memory, optical media, or any other suitable memory from which processor 266 can read instructions and to which processor 266 can write data.
- a closed captioning database 1 14' may be stored in memory 264 rather than an external storage device.
- Memory 264 may include a measurement engine 268.
- Measurement engine 268 may comprise an application, service, server, daemon, routine, subroutine, or other executable logic for comparing closed captioning data or an identifier of closed captioning data such as a hash result received from one or more client capture devices with closed captioning data received by a measurement capture device and/or stored in a closed captioning database 1 14, 114'.
- Measurement engine 268 may execute one or more matching or comparison functions, such as a search function, a lookup function, or any other such function.
- a measurement engine 268 may maintain an audience measurement database 272.
- Audience measurement database 272 may comprise any type and form of database, including a data file, flat file, relational database, structured database, etc.
- a measurement engine 268 may count unique device identifiers associated in the database 272 with an item of content to determine an audience measurement for the content.
- an audience measurement database 272 may store confidence scores of matches of each device identifier to an item of content. In such implementations, device identifiers having low confidence scores may be removed or excluded from the audience measurement count.
- FIG. 3 is a diagram illustrating comparison of captured closed captioning data and generation of a confidence measurement for inclusion of a device in an audience measurement, according to one implementation.
- a measurement service capture device 110 may capture closed captioning data embedded in a television program, such as a program 300 having segments 300a and 300b. The capture device 110 may also capture closed captioning data embedded in interstitial alternative content 302a, such as advertising, program promotions, breaking newscasts, or other such content. This closed captioning data may be associated by an audience measurement server with program 300 and content 302a based on a broadcast schedule or metadata received from a broadcaster 100.
- a client capture device 104 may also receive video for the broadcast program 300, but may receive different alternative content.
- the measurement service capture device 110 may receive a national network feed from the broadcaster, while the client capture device 104 may receive a local affiliate feed with local advertising, weather, news, etc.
- Closed captioning data captured by the client capture device 104 may be identical or highly similar to captioning data captured by the measurement service capture device 1 10 during program segments A 300a and B 300b, but may be different during alternative content segments 302b-302c.
- captured data may be filtered using a confidence measure 304.
- the confidence measure 304 may increase for each matched segment of closed captioning data during a program and may decrease for unmatched segments.
- the audience measurement server may increase confidence measure 304 throughout time ti, during which closed captioning data captured by capture device 104 matches that captured by capture device 110 (or received from a broadcaster 100 for the program 300).
- the audience measurement server may decrease confidence measure 304 due to matching closed captioning data not being identified.
- the audience measurement server may again increase the confidence measure 304 as matches are identified.
- the audience measurement server may increment an audience counter for the program and/or add a device identifier of the client capture device 104 to a confirmed audience list for the program.
- times ti-4 may be of any duration.
- a program segment may refer to a two minute news segment during a broadcast, or an act of a movie.
- Rates of confidence measure 604 increase and decrease, and threshold « 306 may be configured to confirm audience membership based on any desired cumulative viewing time.
- an audience measurement server may apply hysteresis or pause for a predetermined time period before decreasing a confidence measure 304, e.g. at time This may allow for temporary differences in closed captioning content that do not indicate that the panel participant is viewing a different program (e.g. emergency alert system (EAS) alerts or tests broadcast by a local affiliate during a national feed of a program, short station identifiers, etc.). If no matches are identified by expiration of the predetermined time period (e.g. expiration of a timer set to the time period, etc.), then the audience measurement server may begin decrementing the confidence measure 304.
- EAS emergency alert system
- FIG. 4A is a flow diagram of the steps taken in one implementation of a process 400 for capturing closed captioning data by a capture device, according to one
- a capture device may receive a video signal at step 402.
- the capture device may decode closed captioning data embedded in the video signal.
- the capture device may transmit the closed captioning data to an audience measurement server.
- the capture device may calculate a hash of the closed captioning data or a portion of the data, and at step 410, may transmit the hash result to the audience measurement server.
- a capture device such as a client capture device or a measurement service capture device, may receive a video signal.
- the capture device may receive a signal from a receiver, such as a receiver connected at a panel participant's home or other viewing location or at a measurement service data center or office, or may receive a video signal from a switcher, monitoring output, or other source at a broadcast studio, transmitter site, or other such location.
- the video signal may comprise an analog ( TSC) or digital (ATSC) signal, a phase alternating line (PAL) video signal, a sequential color with memory (SECAM) signal, a digital video broadcasting (DVB) signal, or any other type and form of signal having one or more channels of embedded closed captioning data, such as data in an EIA-608 and/or EIA-708 format.
- the capture device may receive the signal via an input port, such as a composite, component, RF baseband, HDMI, or other video input interface, and, in some implementations, may split the signal to a closed captioning decoder and simultaneous output interface for connection to a recorder, television, or other device.
- the capture device may decode the closed captioning data in the video signal.
- the capture device may decode a plurality of channels or strings of data, such as a first channel for a first language and second channel for a second language, while in other implementations, the capture device may decode only a first, default or predetermined channel.
- the capture device may decode only text data, while in other implementations, the capture device may decode command data (e.g. font, style, or color options, placement options, etc.). Such command data may further provide unique data to improve matching.
- the capture device may transmit the decoded closed captioning data to an audience measurement server.
- the capture device may collect a predetermined amount of closed captioning data and may transmit the data periodically, such as via a FIFO buffer or ring buffer or any other type of buffer, as discussed above. Periodic transmissions may be based on a time period, such as five seconds, ten seconds, one minute, or any other such period; or may be based on collection of a set amount of data, such as 1 kilobyte, 5 kilobytes, 30 kilobytes, etc. In some implementations, transmission frequency may be dynamically set responsive to network conditions.
- Transmission of the data may be via any suitable protocol, such as a RESTful application layer protocol such as via HTTP parameter-value messages, a simple mail transfer protocol (SMTP), a file transfer protocol, or any other such protocol; via raw data encapsulated in a transport layer protocol such as TCP or UDP packet or network layer protocol such as IP; or via any other such protocol.
- the protocol may be a lossless protocol; however, in other implementations, particularly utilizing dynamic confidence measurements discussed above, a lossy protocol may be used to reduce overhead.
- hysteresis time periods may be configured to allow at least one subsequent transmission to be received before a measurement is decreased.
- transmission of decoded data at step 406 may include transmission of a device identifier of the capture device.
- the device identifier may be provided with the decoded data, such as in an options field of a packet header, as a cookie, in a session identifier, as a parameter-value pair, or any other such means.
- the device identifier may log in or authenticate itself to the audience measurement server before transmitting decoded data.
- the capture device may establish an authenticated session with an audience measurement server, and identify itself with its device identifier, before sending decoded data; or may connect to an audience measurement server or authentication server with its device identifier and may receive a cookie for use in subsequent data transfers.
- log in and/or authentication may be provided by another device, such as an Internet gateway deployed as an intermediary between the capture device and audience measurement server.
- decoded closed captioning data may be hashed at step 408.
- the capture device may perform any type and form of hashing algorithm on the closed captioning data, including a cryptographic or non-cryptographic hashing algorithm, or one substantially free of hash collisions. In other implementations, particularly with dynamic confidence measures as discussed above, a hashing algorithm with some collisions may be acceptable, provided collisions result in a low level of false positive matches.
- Hash results may be transmitted to the audience measurement server at step 410, using any of the methods discussed above in connection with step 406. As discussed above, in many implementations, the hash results may be buffered for a predetermined time period or size of data collected prior to transmission.
- FIG. 4B is a flow diagram of the steps taken in one implementation of a process 420 for matching received closed captioning data by an audience measurement server, according to one implementation.
- the audience measurement server or a measurement engine of an audience measurement server may receive closed captioning data, or, in some implementations, a hash of such data.
- the audience measurement server may receive data via an application layer protocol such as a RESTful protocol, or any other protocol.
- the audience measurement server may receive closed captioning data from a broadcaster or other data provider as data file, such as a single data file for a television program or movie.
- the audience measurement server may receive the data from a capture device, in smaller amounts such as around a few kilobytes of data or data representing a few minutes of a program.
- the audience measurement engine may determine if the data was received from a broadcaster or service provider, such as via a file transfer. If so, then the data may include a content identification in metadata, such as a file header, file name, or other data field. The content identification may identify the source of the content, the content type, a name of the content, a day or time of day of broadcast of the content, or any combination of these or other information.
- the audience measurement engine may receive the content identification and/or extract the content identification from the received data. The audience measurement engine may determine that the data was received from the broadcaster or service provider responsive to the inclusion or presence of the metadata, responsive to a method of receipt (e.g. file transfer via a network, attachment via email, etc.), or responsive to other such indicators (e.g. data file size being above a threshold equivalent to a maximum buffer size in a capture device, etc.).
- the audience measurement engine may calculate a hash of the received closed captioning data or a portion of the data. For example, the measurement engine may select a window of data, such as 20 words, 120 characters, 150 bytes, 500 bytes, or any other size window of closed captioning data, and may calculate a hash value of the data. The hash result may be used as an index to a closed captioning database and the content identifier may be stored at the corresponding database entry at step 430. In some implementations, a sliding window algorithm may be used and overlapping portions of closed captioning data may be hashed. For example, the measurement engine may receive a large closed captioning data set from the broadcaster or service provider.
- the measurement engine may break the received set up into a plurality of portions or windows for separate hashing and indexing, such as windows of 10 words, 20 words, 100 bytes, etc.
- steps 428-430 may be repeated iteratively for each successive window or portion until all of the received data is hashed and indexed.
- the closed captioning data may be used as the index value directly; in such implementations, step 428 may be skipped.
- the closed captioning data may still be broken up or apportioned into a plurality of shorter windows for subsequent comparison.
- the closed captioning data may be stored as a data file or array associated with the content identification, and may be searched directly for data matching received phrases in subsequent matching steps. Accordingly, in such implementations, step 430 may be skipped.
- the measurement engine may determine if the data is received from an audience measurement service capture device.
- the measurement engine may determine that the measurement service capture device is the source responsive to a device identifier received with the closed captioning data corresponding to a known device identifier of the capture device, via the connection type (e.g. a serial connection over USB rather than a TCP connection via the Internet), or any other such means.
- the measurement engine may retrieve a corresponding content identification at step 434.
- the content identification may be retrieved from a broadcast schedule, such as published television listings for a channel monitored by the capture device.
- the measurement engine may transmit a request to a broadcaster for an identification of currently playing content, and may receive a corresponding content identification.
- the received closed captioning data may, in some implementations, be hashed at step 428 and/or may be added to a closed captioning database.
- the measurement engine may confirm that the content identification associated with each set of data is identical. If the content identifications are identical, the measurement engine may discard the latter set of data. If the identifications are not identical, the measurement engine may replace an earlier-received content identification with a later-received content identification to update the closed captioning database with new information.
- the measurement engine may receive a large closed captioning data set from the measurement capture device.
- the measurement engine may break the received set up into a plurality of portions or windows for separate hashing and indexing, such as windows of 10 words, 20 words, 100 bytes, etc.
- steps 428-430 may be repeated iteratively for each successive window or portion until all of the received data is hashed and indexed.
- the measurement engine may receive a device identifier of the client device at step 438. As discussed above, the device identifier may be received with the closed captioning data, prior to receipt of the closed captioning data (e.g. during an authentication, session establishment, or login process), or subsequent to receipt of the closed captioning data.
- the measurement engine may calculate a hash of the received closed captioning data or a portion of the data.
- the measurement engine may determine if a content identifier exists at a corresponding hash index value entry in the closed captioning database. If no entry exists, then an identical set of closed captioning data or a portion of the data has not been previously received by the measurement engine (at least within a time period before removal of old entries from the closed captioning database, as discussed above), and the hash result may be discarded.
- a sliding window algorithm may be used and steps 440- 442 may be iteratively repeated for each new position of the window until a match is identified.
- the sliding window algorithm may only need to be performed in a first round of iterations for received closed captioning data. For example, if a set of closed captioning data from a client capture device is identical to a set of data received from a measurement device, but starting five words later, then steps 440-442 may need to be repeated only five times, advancing the window one word at a time, until a match is identified.
- windows may be compared of words 1-20, 2-21, 3-22, 4-23, 5-24, and 6-25, at which point a match may be identified.
- the window may be advanced by its full length: e.g. matching words 6-25, then 26-45, 46-65, etc.
- closed captioning data may be used as the index of the closed captioning database directly, and accordingly, may not need to be hashed.
- step 440 may be skipped.
- Step 442 may still be repeated, as discussed above, for iterations of a sliding window algorithm on subsequent portions of the closed captioning data without hashing.
- the measurement engine may identify an associated item of content and determine if the device identifier of the client device is in an audience database entry for the item of content.
- each entry in the closed captioning database may include a corresponding identification of content added at step 430. Accordingly, when the measurement engine looks up an index entry corresponding to a hash or portion of the data, if an entry exists and a match is found, then the measurement engine may simply retrieve the associated content identifier.
- Each content identifier may also be associated with an audience database or array of device identifiers of devices identified as having received the corresponding content.
- the measurement engine may determine if the device identifier of the client device exists within the array or database for the associated content identifier. If the device identifier does not exist within the array, then at step 446, the measurement engine may add the device identifier to the array or database. In a further implementation, the measurement engine may add a default or starting confidence score for the device identifier being part of the audience to the array. If the device identifier does exist within the array, then the device has previously been identified as having received the content; accordingly, in some
- the measurement engine may increase a confidence score for the device identifier in the array associated with the content.
- the measurement engine may maintain a database or array of content associated with a device identifier, in addition to or instead of a database or array of device identifiers associated with an item of content. For example, rather than maintaining a list or array of devices identified as being part of the audience for a particular show, the measurement engine may maintain a list or array of shows identified as having been received by a particular device. In some such implementations, the measurement engine may subsequently search through a plurality of arrays associated with devices for a content identifier of an item of content, to determine how many devices were part of the audience. In a similar implementation, the arrays may be provided to a third party, such as a panel provider, for analysis and/or audience measurement.
- a third party such as a panel provider
- steps 440-448 may be repeated iteratively for each successive window or portion until all of the received data is hashed and indexed.
- the measurement engine may decrease a confidence score for a client device identifier and previously matched item of content if a match is not identified at step 442 in a subsequent iteration.
- the measurement engine may retain an identification of a device identifier and a previously matched item of content.
- the measurement engine may retain the identification for a predetermined period of time, such as a minute, five minutes, an hour, or any other such period. Responsive to determining that a portion of closed captioning data received from the client does not match any entries in the closed captioning database, the measurement engine may decrement a confidence score associated with the client device identifier in an audience array for the item of content.
- the confidence score may be decreased at a slower rate than it was increased at step 448 (e.g. the confidence score may be incremented by two points per match but decremented by one point per non-match, or any other such values).
- the measurement engine may not decrease the confidence score until a predetermined period of time has passed since the last matched closed captioning data, such as 15 seconds, 30 seconds, 1 minute, or any other such value. This may provide hysteresis for short local content in an otherwise identical broadcast program.
- audience measurement may be performed in real time, incrementing a counter for each device identifier added to an audience array for an item of content and decrementing the counter (and possibly removing a device identifier) responsive to a confidence measure for the device identifier falling below a threshold.
- audience measurement may be performed responsive to a request for an audience measurement, or responsive to the end of an item of content being broadcast.
- FIG. 4C is a flow diagram of the steps taken in one implementation of a process 480 for measuring an audience of an item of content by an audience measurement server, according to one implementation.
- the measurement engine may receive a request for an audience measurement for an item of content.
- the request may be received from a broadcaster, advertiser, producer, panel provider, marketer, analyst, or other entity.
- the request may identify one or more items of content, and, in some implementations, may include a confidence measure threshold to utilize for the measurement.
- the measurement engine may determine if the item of content is still be broadcast or is over. If the content is still being broadcast, then in some implementations, the measurement engine may wait and repeat step 484 until the item of content is over. The measurement engine may determine that the item of content is still being broadcast based on a published broadcast schedule, responsive to metadata received from a broadcaster including program start and end times, or based on other similar information. In other implementations, step 484 may be skipped, for example, for live audience measurements during a program.
- the measurement engine may retrieve a first device identifier, and, in some implementations, a confidence score or measure associated with the device identifier, from an audience array or database for the item of content.
- a confidence score or measure associated with the device identifier may be retrieve from an audience array or database for the item of content.
- the measurement engine may determine if the confidence score is above a threshold n, such as a predetermined threshold or a threshold received at step 482. If the confidence score is greater than the threshold n, then at step 490, an audience counter for the item of content may be incremented. If the confidence score is less than the threshold, then step 490 may be skipped. At step 492, the audience measurement engine may repeat steps 486-492 for each additional device identifier in the audience array, until a total audience measurement for the item of content is generated. In implementations not utilizing a confidence score, step 488 may be skipped and the audience counter may be a direct count of the number of device identifiers in the audience array. At step 494, the audience
- the measurement may be output or provided as a response to the request for audience measurement.
- Closed captioning databases, and audience measurement databases or arrays may be periodically purged.
- device identifiers and confidence scores may be removed from an audience array after a program is complete and a measurement is generated.
- the device identifiers and confidence scores may be removed from the array after an hour, a day, a week, or any other amount of time. This may allow for aggregation of audience measurements including live audiences as well as audience members who record and time-shift the program for later watching.
- Closed captioning databases may also be purged with entries removed after a predetermined amount of time, such as prior to a next episode of a program, or simply periodically.
- the systems and methods discussed herein utilize a capture device installed in series or parallel with a panel participant's television, such panel participants must typically sign up or agree to participate in data collection.
- device identifiers and closed captioning data are transmitted from client capture devices, privacy and anonymity of panel participants may be protected.
- the device identifiers and/or closed captioning data may be encrypted for transmission to the audience measurement server.
- Panel participants may also stop transmitting measurement data by removing a video input, network connection, and/or power connection from the capture device, and may resume at any time by reattaching said connection or connections.
- the panel participant may be provided with an opportunity to control whether or how to transmit measurement data to the audience measurement server.
- the client capture device may be configured to be disabled during certain times of day or with certain program material (e.g. specified channels, or responsive to the presence of specified V-chip parental rating codes embedded within the video).
- the panel participant may have control over how information is collected about him or her and used by the audience measurement servers, panel providers, and content providers.
- Implementations of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Implementations of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on one or more computer storage medium for execution by, or to control the operation of, data processing apparatus.
- the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
- a computer storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them.
- a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially-generated propagated signal.
- the computer storage medium can also be, or be included in, one or more separate components or media (e.g., multiple CDs, disks, or other storage devices). Accordingly, the computer storage medium may be tangible.
- client or “server” include all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple ones, or combinations, of the foregoing.
- the apparatus can include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- the apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them.
- the apparatus and execution environment can realize various different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
- a computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code).
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- the processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output.
- the processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit).
- processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer.
- a processor will receive instructions and data from a read-only memory or a random access memory or both.
- the essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- a computer need not have such devices.
- a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a universal serial bus (USB) flash drive), to name just a few.
- PDA personal digital assistant
- GPS Global Positioning System
- USB universal serial bus
- Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example
- semiconductor memory devices e.g., EPROM, EEPROM, and flash memory devices
- magnetic disks e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
- the processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- implementations of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube), LCD (liquid crystal display), OLED (organic light emitting diode), TFT (thin-film transistor), plasma, other flexible configuration, or any other monitor for displaying information to the user and a keyboard, a pointing device, e.g., a mouse, trackball, etc., or a touch screen, touch pad, etc., by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube), LCD (liquid crystal display), OLED (organic light emitting diode), TFT (thin-film transistor), plasma, other flexible configuration, or any other monitor for displaying information to the user and a keyboard, a pointing device, e.g., a mouse, trackball, etc., or a touch screen, touch pad, etc., by which the user can provide input to the computer
- a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending webpages to a web browser on a user's client device in response to requests received from the web browser.
- Implementations of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network.
- Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
- LAN local area network
- WAN wide area network
- inter-network e.g., the Internet
- peer-to-peer networks e.g., ad hoc peer-to-peer networks.
- the features disclosed herein may be implemented on a smart television module (or connected television module, hybrid television module, etc.), which may include a processing circuit configured to integrate Internet connectivity with more traditional television programming sources (e.g., received via cable, satellite, over-the-air, or other signals).
- the smart television module may be physically incorporated into a television set or may include a separate device such as a set-top box, Blu-ray or other digital media player, game console, hotel television system, and other companion device.
- a smart television module may be configured to allow viewers to search and find videos, movies, photos and other content on the web, on a local cable TV channel, on a satellite TV channel, or stored on a local hard drive.
- a set-top box (STB) or set-top unit (STU) may include an information
- a smart television module may be configured to provide a home screen or top level screen including icons for a plurality of different applications, such as a web browser and a plurality of streaming media services, a connected cable or satellite media source, other web "channels", etc.
- the smart television module may further be configured to provide an electronic programming guide to the user.
- a companion application to the smart television module may be operable on a mobile computing device to provide additional information about available programs to a user, to allow the user to control the smart television module, etc.
- the features may be implemented on a laptop computer or other personal computer, a smartphone, other mobile phone, handheld computer, a tablet PC, or other computing device.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/253,028 US9485525B1 (en) | 2014-04-15 | 2014-04-15 | Systems and methods for using closed captions for television viewership measurement |
PCT/US2015/025185 WO2015160630A1 (en) | 2014-04-15 | 2015-04-09 | System and method for using closed captions for television viewership measurement |
Publications (2)
Publication Number | Publication Date |
---|---|
EP3132611A1 true EP3132611A1 (en) | 2017-02-22 |
EP3132611B1 EP3132611B1 (en) | 2020-06-03 |
Family
ID=53015919
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP15719346.7A Active EP3132611B1 (en) | 2014-04-15 | 2015-04-09 | System and method for using closed captions for television viewership measurement |
Country Status (4)
Country | Link |
---|---|
US (2) | US9485525B1 (en) |
EP (1) | EP3132611B1 (en) |
CN (1) | CN106233733B (en) |
WO (1) | WO2015160630A1 (en) |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
GB2556612B (en) | 2016-04-18 | 2022-03-09 | Grass Valley Ltd | Monitoring audio-visual content with captions |
JP6752124B2 (en) * | 2016-11-22 | 2020-09-09 | 株式会社ビデオリサーチ | Channel determination device, channel determination method, and its program |
US10735808B2 (en) | 2017-08-10 | 2020-08-04 | The Nielsen Company (Us), Llc | Methods and apparatus of media device detection for minimally invasive media meters |
CN107484035B (en) * | 2017-08-17 | 2020-09-22 | 深圳Tcl数字技术有限公司 | Closed caption display method, apparatus and computer readable storage medium |
US20230247188A1 (en) * | 2022-02-01 | 2023-08-03 | Comcast Cable Communications, Llc | Caption Anomaly Detection |
Family Cites Families (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4857999A (en) | 1988-12-20 | 1989-08-15 | Peac Media Research, Inc. | Video monitoring system |
CA2036205C (en) | 1990-06-01 | 1996-11-19 | Russell J. Welsh | Program monitoring unit |
US6295092B1 (en) * | 1998-07-30 | 2001-09-25 | Cbs Corporation | System for analyzing television programs |
US8006268B2 (en) * | 2002-05-21 | 2011-08-23 | Microsoft Corporation | Interest messaging entertainment system |
CN101077014B (en) * | 2004-08-09 | 2013-09-25 | 尼尔森（美国）有限公司 | Methods and apparatus to monitor audio/visual content from various sources |
EP2030439B1 (en) * | 2006-06-15 | 2018-09-19 | The Nielsen Company (US), LLC | Methods and apparatus to meter content exposure using closed caption information |
US20090150951A1 (en) * | 2007-12-06 | 2009-06-11 | At&T Knowledge Ventures, L.P. | Enhanced captioning data for use with multimedia content |
US8245249B2 (en) | 2009-10-09 | 2012-08-14 | The Nielson Company (Us), Llc | Methods and apparatus to adjust signature matching results for audience measurement |
US20110234900A1 (en) | 2010-03-29 | 2011-09-29 | Rovi Technologies Corporation | Method and apparatus for identifying video program material or content via closed caption data |
-
2014
- 2014-04-15 US US14/253,028 patent/US9485525B1/en active Active
-
2015
- 2015-04-09 CN CN201580019837.3A patent/CN106233733B/en active Active
- 2015-04-09 WO PCT/US2015/025185 patent/WO2015160630A1/en active Application Filing
- 2015-04-09 EP EP15719346.7A patent/EP3132611B1/en active Active
- 2015-10-05 US US14/874,921 patent/US10009648B1/en active Active
Also Published As
Publication number | Publication date |
---|---|
US10009648B1 (en) | 2018-06-26 |
CN106233733A (en) | 2016-12-14 |
EP3132611B1 (en) | 2020-06-03 |
WO2015160630A1 (en) | 2015-10-22 |
US9485525B1 (en) | 2016-11-01 |
CN106233733B (en) | 2019-08-02 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11546659B2 (en) | System and method for associating search queries with remote content display | |
US10296645B2 (en) | Systems and methods for content selection based on search query correlation with broadcast media | |
US9854315B1 (en) | Systems and methods for broadcast audience interaction and participation | |
KR102332953B1 (en) | Media content matching and indexing | |
US11805288B2 (en) | Crowdsourced playback control of media content | |
JP6438628B2 (en) | Automatic content recognition fingerprint sequence verification | |
US10009648B1 (en) | Systems and methods for using closed captions for television viewership measurement | |
US8806544B1 (en) | Content synchronization | |
US20140373036A1 (en) | Hybrid video recognition system based on audio and subtitle data | |
US8726314B2 (en) | System and method for extending recording time for a digital video record (DVR) | |
US20090222853A1 (en) | Advertisement Replacement System | |
US8358909B2 (en) | Coordinated output of messages and content | |
KR20150042195A (en) | A method and an apparatus for processing a broadcast signal including an interactive broadcast service | |
US11234026B2 (en) | Methods and apparatus for responding to inoperative commands | |
US11606626B2 (en) | Inserting advertisements in ATSC content | |
KR101615930B1 (en) | Using multimedia search to identify what viewers are watching on television | |
US20180206004A1 (en) | Enhanced restart tv |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE INTERNATIONAL PUBLICATION HAS BEEN MADE |
|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: REQUEST FOR EXAMINATION WAS MADE |
|
17P | Request for examination filed |
Effective date: 20161011 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAV | Request for validation of the european patent (deleted) | ||
DAX | Request for extension of the european patent (deleted) | ||
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
17Q | First examination report despatched |
Effective date: 20171017 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: H04N 21/488 20110101ALI20180416BHEPIpc: H04H 60/31 20080101ALI20180416BHEPIpc: H04N 21/442 20110101AFI20180416BHEP |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
INTG | Intention to grant announced |
Effective date: 20180531 |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
INTC | Intention to grant announced (deleted) | ||
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
INTG | Intention to grant announced |
Effective date: 20200220 |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
GRAL | Information related to payment of fee for publishing/printing deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR3 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
GRAL | Information related to payment of fee for publishing/printing deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR3 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
GRAL | Information related to payment of fee for publishing/printing deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR3 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
GRAL | Information related to payment of fee for publishing/printing deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR3 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAR | Information related to intention to grant a patent recorded |
Free format text: ORIGINAL CODE: EPIDOSNIGR71 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE PATENT HAS BEEN GRANTED |
|
INTC | Intention to grant announced (deleted) | ||
INTC | Intention to grant announced (deleted) | ||
INTC | Intention to grant announced (deleted) | ||
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
INTG | Intention to grant announced |
Effective date: 20200428 |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EPRef country code: ATRef legal event code: REFRef document number: 1278314Country of ref document: ATKind code of ref document: TEffective date: 20200615 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602015053714Country of ref document: DE |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200904Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200903Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603 |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: MPEffective date: 20200603 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200903Ref country code: RSFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603 |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 1278314Country of ref document: ATKind code of ref document: TEffective date: 20200603 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ALFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: NLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: SMFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201006 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201003 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602015053714Country of ref document: DE |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603 |
|
26N | No opposition filed |
Effective date: 20210304 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20210409 |
|
REG | Reference to a national code |
Ref country code: BERef legal event code: MMEffective date: 20210430 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20210430Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20210430 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: IEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20210409 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201003 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20210430 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: HUFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMIT; INVALID AB INITIOEffective date: 20150409 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230508 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: FRPayment date: 20230425Year of fee payment: 9Ref country code: DEPayment date: 20230427Year of fee payment: 9 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: GBPayment date: 20230427Year of fee payment: 9 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200603 |