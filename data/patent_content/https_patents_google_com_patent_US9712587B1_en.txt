US9712587B1 - Identifying and rendering content relevant to a user's current mental state and context - Google Patents
Identifying and rendering content relevant to a user's current mental state and context Download PDFInfo
- Publication number
- US9712587B1 US9712587B1 US14/556,802 US201414556802A US9712587B1 US 9712587 B1 US9712587 B1 US 9712587B1 US 201414556802 A US201414556802 A US 201414556802A US 9712587 B1 US9712587 B1 US 9712587B1
- Authority
- US
- United States
- Prior art keywords
- user
- media
- context
- state
- current session
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/103—Detecting, measuring or recording devices for testing the shape, pattern, colour, size or movement of the body or parts thereof, for diagnostic purposes
- A61B5/11—Measuring movement of the entire body or parts thereof, e.g. head or hand tremor, mobility of a limb
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/16—Devices for psychotechnics; Testing reaction times ; Devices for evaluating the psychological state
- A61B5/165—Evaluating the state of mind, e.g. depression, anxiety
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0241—Advertisements
- G06Q30/0251—Targeted advertisements
- G06Q30/0269—Targeted advertisements based on user profile or attribute
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/1066—Session management
- H04L65/1083—In-session procedures
- H04L65/1089—In-session procedures by adding media; by removing media
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/61—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio
- H04L65/612—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio for unicast
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/61—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio
- H04L65/613—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio for the control of the source by the destination
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/75—Media network packet handling
- H04L65/762—Media network packet handling at the source
Definitions
- This application generally relates to systems and methods for identifying and rendering content relevant to a user's current mental state and context.
- Various content providers and advertisers often determine content to suggest to a user or advertisements to show to the user during a current session with the content provider based on historical analysis of the user's previous history with the content provider and/or other content providers. For example, when browsing the Internet, some advertisement systems will present the user with advertisements for content the user viewed/accessed in a previous browsing session or content similar to what they viewed or accessed in a previous session. These advertisement systems generally analyze various signals from the user's previous browsing sessions before the user begins a future browsing session to determine advertisement content to show the user in the user's future browsing session. However this advertisement content may not be relevant to the when the user begins the future browsing session for a variety of reasons.
- FIG. 1 illustrates an example system for identifying content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 2 presents an example system for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 3 presents another example system for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 4 presents another example system for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 5 presents another example system for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 6 illustrates an example flow diagram of an example method for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 7 illustrates another example flow diagram of an example method for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 8 illustrates another example flow diagram of an example method for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 9 is a schematic block diagram illustrating a suitable operating environment in accordance with various aspects and embodiments.
- FIG. 10 is a schematic block diagram of a sample-computing environment in accordance with various aspects and embodiments.
- the subject disclosure relates to dynamically determining or inferring content, provided by a content provider (e.g., via a network based platform such as a website or mobile application), that a user will be most receptive to at any given point during a current interaction session with the content provider based on the context and state of the user during the current session.
- a content provider e.g., via a network based platform such as a website or mobile application
- Various content providers and advertisers often determine content to suggest to a user or advertisements to show to the user during a current session with the content provider based on historical analysis of the user's previous history with the content provider and/or other content providers. For example, when browsing the Internet, some advertisement systems will present the user with advertisements for content they viewed/accessed in a previous session or content similar to what they viewed or accessed in a previous session.
- this content may not be relevant to the user during the current session for a variety of reasons. For example, during a current session, a user may not be shopping online as the user was in a prior session but researching a technical subject for a work project. Accordingly, showing content to the user during the current session that includes advertisements for products previously viewed by the user will most likely disturb and distract the user. Similarly, where the user previously accessed content related to a technical subject for a work assignment and the user is now relaxing in the evening and browsing the Internet for entertainment and leisure based content, suggesting content to the user related to the technical work subject at this time will likely annoy the user and the user will likely discard the content.
- the subject disclosure employs a variety to signals received or extracted during a user's current session with a content provider to determine or infer a context of the current session and the user's mental state during the current session. These signals are then used to identify content that the user will be most receptive to at any given point during the current session.
- user research has shown that users are in different ‘modes’ according to various dynamic factors such as time of day, what device they are on, what brought them to a particular a particular content provider's website/application, where the user is located (e.g., home vs.
- the user's state of mind can also influence characteristics of content that the user will be most receptive to during a current session. For example, media content (e.g., images, video, music, etc.) can evict various user emotions. When a user's current frame of mind or mood can be discerned, media content can be identified and provided to the user the reflects or effects the user's mood. Accordingly, systems and mechanisms are provided that will take into account various factors related to a user's mental state and context during a current session of the user with a content provider to determine or infer a particular content item to render to the user during the current session.
- media content e.g., images, video, music, etc.
- the disclosed techniques are specifically tailored to determine or infer media content that a user will be most receptive to engage with during a current session with a streaming media provider that offers a wide array of different media content of various types and durations for access by the user.
- the specific media items that a user selects to view or listen to and the manner in which the user engages with media items selected by the user or pushed to the user can provide a strong indication of a user's mental state. For example, when a user is accessing and/or searching for short clips of funny videos, it can be inferred that the user is in a joyful, leisurely state of mind. This information coupled with information related to the context of the current session can provide even greater insight into the user's state of mind.
- the determination that the user is in a joyful and leisurely state of mind can be held with greater confidence when it is also determined that the user is at a party sharing the videos with friends.
- the specific content of the funny videos e.g., the plot, the characters, the script, the setting, etc.
- a user when a user is searching for videos related to information on a specific technical subject, it can be determined that the user's frame mind is focused, diligent, serious, etc.
- the user's frame of mind can further be discerned depending on the time of day, location of the user, the user's profession and the specific technical subject searched. For example, the user's intentions and concerns may vary if the technical subject is related to work aspects or personal aspects. Further, the user's navigational tactics can indicate the user's intention of the current session and the user's state of mind regarding fulfilling the intention.
- media content provided by the streaming media can be identified and rendered to the user that is relevant to the current user's mental state and context.
- this media content can include advertisements (e.g., video advertisements or static advertisements).
- a video advertisement having a specific content type and duration can be identified based on characteristics of the user's mental state and context during a current session of the user with the media provider and rendered to the user during the current session at a point during the current session when the user will be most receptive to it.
- the media content identified for provision to the user can include a trailer for another video or channel offered by the media provider.
- the media content can include other videos, playlists and channels provided by the media provider and suggested to the user in a recommendation list for viewing during the current session.
- a system in one or more aspects, includes a state component configured to determine a state of a user during a current session of the user with the media system based on at least one of: navigation of the media system by the user during the current session, media items provided by the media system that are played for watching by the user during the current session, or a manner via which the user interacts with or reacts to the played media items, wherein the state of the user includes a mood of the user.
- the system further includes a selection component configured to select a media item provided by the media provider based on the state of the user, and a rendering component configured to effectuate rendering of the media item to the user during the current session.
- a method includes using a processor to execute computer executable instructions stored in a memory to perform various acts. These acts can include: determining user state attributes associated with a user's current state of mind during a current session of the user with a streaming media provider based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or a manner via which the user interacts with or reacts to the played media items, wherein the state of the user includes a mood of the user; selecting a media item provided by the streaming media provider based on the user state attributes; and rendering the media item to the user during the current session
- a tangible computer-readable storage medium comprising computer-readable instructions that, in response to execution, cause a computing system to perform various operations. These operations include determining mood attributes associated with a user's current mood during a session of the user with a streaming media provider and determining context attributes associated with a current context of the session based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or an environment of the user. The operations further include, selecting a media item provided by the streaming media provider based on the mood attributes and the context attributes, and rendering the media item to the user during the session.
- FIG. 1 presented is diagram of an example system 100 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- Aspects of systems, apparatuses or processes explained in this disclosure can constitute machine-executable components embodied within machine(s), e.g., embodied in one or more computer readable ediums (or media) associated with one or more machines. Such components, when executed by the one or more machines, e.g., computer(s), computing device(s), virtual machine(s), etc. can cause the machine(s) to perform the operations described.
- System 100 includes at least a content provider 102 and a client device 122 wherein the content provider is configured to provide content to a user of the client device 122 via one or more networks 120 using a network based platform (e.g., a website or mobile application).
- the content provider 102 can include dynamic content selection platform 104 to determine or infer characteristics of a user's current mental state and context during a session of the user with the content provider and to identify other content (e.g., an advertisement, a suggested content item, etc.) that is relevant to the user's current mental state and context.
- the dynamic content selection platform 104 can then facilitate rendering of the identified other content to the user by the content provider 102 during the current session. For example, when the other content is an advertisement, dynamic content selection platform 104 can direct content provider 102 to provide the advertisement to the user during the user's current session.
- system 100 can also include external sources 128 , other client devices 130 and auxiliary input devices 132 .
- Dynamic content selection platform 104 and/or content provider 102 can include memory 116 for storing computer executable components and instructions and processor 114 to facilitate operation of the instructions (e.g., computer executable components and instructions) by the dynamic content selection platform 104 .
- client device 122 can include memory for storing computer executable components and instructions and a processor to facilitate operation of the instructions (not shown).
- the various components and devices of system 100 can be connected either directly or via one or more networks 120 .
- networks can include wired and wireless networks, including but not limited to, a cellular network, a wide area network (WAD, e.g., the Internet), a local area network (LAN), or a personal area network (PAN).
- client device 122 can communicate with content provider 102 (and vice versa) using virtually any desired wired or wireless technology, including, for example, cellular, WAN, wireless fidelity (Wi-Fi), Wi-Max, WLAN, and etc.
- one or more components of system 100 are configured to interact via disparate networks.
- dynamic content selection platform 104 is depicted as being internal to content provider 102 , one or more aspects of dynamic content selection platform 104 can be provided locally at client device 122 .
- content provider 102 can include an application service provider and client device 122 can employ a thin client application to interact with and receive various content and services provided by the content provider.
- the thin client application provided on the client device 122 can include one or more components (e.g., reception component 106 , state component 108 , context component 112 , etc.) of dynamic content selection platform 104 .
- Content provider 102 can include an entity configured to provide content and/or services to a user at a client device (e.g., client device 120 ) via a network (e.g., the Internet).
- content provider 102 can include a website or application service provider configured to provide videos, pictures, articles, blogs, messages, services, etc. or other types of content items to client devices via a network.
- the content provided by the website or application can be configured for downloading, streaming or merely viewing at a client device 122 via the network.
- content provider 102 can include a information store that provides access to data included in the information store via a network.
- content provider 102 can include an online merchant that provides goods and services.
- the term content item refers to any suitable data object that can be accessed or otherwise shared via a network and includes but is not limited to: documents, articles, messages, webpages, programs, applications, data object and media items.
- the term media item or media content can include but is not limited to: video, live video, animations, video advertisements, music, music videos, sound files, pictures, and thumbnails.
- an owner of a media item is referred to herein as a content creator to indicate that the media item was created by the content creator (i.e., the content creator holds copyright authority to the media item).
- the term media item or media content refers to a collection of media items, such as a playlist or channel including several videos or songs.
- a channel can include data content available from a common source or data content having a common topic or theme.
- a channel can be associated with a curator who can perform management actions on the channel. Management actions can include, for example, adding media items to the channel, removing media items from the channel, defining subscription requirements for the channel, defining presentation attributes for channel content, defining access attributes for channel content, etc.
- this curator constitutes the channel owner or channel creator and the channel itself can be considered a content or media item owned or created by the channel owner.
- channel content can include digital content uploaded to an Internet-based content platform that hosts the channel (e.g., content provider 102 ) by the channel curator and/or digital content selected by the channel curator from other content available on the Internet-based content platform.
- a channel curator can include a professional content provider (e.g., a professional content creator, a professional content distributor, a content rental service, a television (TV) service, etc.) or an amateur individual.
- Channel content can include professional content (e.g., movie clips, TV clips, music videos, educational videos) and/or amateur content (e.g., video blogging, short original videos, etc.).
- Users, other than the curator of the channel can subscribe to one or more channels in which they are interested. Users in addition to the channel curator can access content provided by a channel.
- content provider 102 includes a streaming media provider configured to provide streaming media and related services to client devices over a network.
- content provider 102 can include a media provider that has access to a voluminous quantity (and potentially an inexhaustible number) of shared media (e.g., video and/or audio) files.
- the media provider can further stream these media files to one or more users at respective client devices (e.g., clients 122 ) of the one or more users over a network.
- the media can be stored in memory associated with the media provider (e.g., memory 116 ) and/or at various servers and caches employed by media provider and accessed by client devices using a networked platform (e.g., a website platform, a mobile application) employed by the media provider.
- a networked platform e.g., a website platform, a mobile application
- the media provider can provide and present media content to a user via a website that can be accessed by a client device using a browser.
- the media provider can provide and present media to a user via a mobile/cellular application provided on a client device (e.g., where the client device is a smartphone or the like).
- Client device 122 can include presentation component 124 to generate a user interface (e.g., a graphical user interface or virtual interface) that displays media content provided by the media provider to a user of the client device.
- presentation component 124 can include an application (e.g., a web browser) for retrieving, presenting and traversing information resources on the World Wide Web.
- the media provider can provide and/or present media content to a client device 122 via a website that can be accessed using a browser of the client device 122 .
- the media provider can provide and/or present media content to a client device 122 via a mobile application platform.
- presentation component 124 can employ a client application version of the media provider that that can access the cellular application platform of the media provider.
- the media content can be presented and/or played at client device 122 using a video player associated with the media provider and/or the client device 122 .
- Client device 122 can include any suitable computing device associated with a user and configured to interact with content provider 102 via a network.
- client device 122 can include a desktop computer, a laptop computer, a television, an Internet enabled television, a mobile phone, a smartphone, a tablet personal computer (PC), a personal digital assistant PDA, or a wearable device.
- content consumer or “user” refer to a person, entity, system, or combination thereof that employs system 100 (or additional systems described in this disclosure) using a client device 122 .
- dynamic content selection platform 104 includes a streaming media provider (as described herein). Accordingly, dynamic contribution platform 104 is discussed in association with determining or inferring, in real-time or substantially real time, media content (e.g., media advertisement, video trailers, channel trailers, other videos provided by the media provider etc.) that is relevant to a user during the user's current session with the media provider.
- media content e.g., media advertisement, video trailers, channel trailers, other videos provided by the media provider etc.
- dynamic content selection platform 104 can be employed by a variety of content providers and systems to determine or infer content for provision to a user (e.g., advertisements, recommended content) that is relevant to the user's context and mental state at the time of rendering of the content.
- dynamic content selection platform 104 can include reception component 106 , state component 108 , context component 110 and selection component 112 .
- Reception component 106 is configured to receive and/or extract information in association with a user's current session with content provider 102 that can be employed to determine or infer attributes of the user's current mental state and context. For example, when a user conducts a session with a streaming media provider that includes navigating and consuming media content provided by the streaming media provider, reception component 106 can receive or extract information about the user's current session that relates to the user's state of mind and context. Based on this information, state component 108 is configured to determine a state of the user and context component 110 is configured to determine a context of the user and/or the current session. Selection component 112 can then determine or infer advertisements, video trailers, channel trailers, and/or other media that the user is likely to be most receptive to during the current session based on the user's state and context.
- reception component 106 can receive information regarding the manner in which the user navigates the media provider's content (e.g., searching via key word search, searching within a specific media category or channel, browsing, following recommendations, etc.,), the specific content accessed and viewed by the user, and the manner in which the user interacts with the content selected by the user for viewing or pushed upon the user (e.g., watching or dismissing a video, controlling the playing of the video, commenting about the video, liking or disliking the video, sharing the video, having the video visible, having the volume of the video audible, interaction with the interface via which the video is included as based on cursor movement or touch screen interaction, etc.).
- Reception component 106 can also receive information regarding the watch history of the user during the current session, including durations of media items selected for watching or listening to by the user and respective amounts of the media items actually watched or listened to by the user.
- information regarding a user's navigation of a media provider, content accessed and viewed/watched, and the manner in which the user interacts with the content can be extracted in real-time as it is generated at the media provider during the user's session.
- signals regarding user interaction and engagement with the media provider during a current session can be collected at client device 122 via a signal collection component 126 and provided to reception component 106 during the course of the user's session (e.g., in real-time, in substantially real-time, or periodically).
- signal collection component 126 can receive signals regarding cursor movement, interaction by the user with a graphical user interface via which the media provider's content is accessed, interaction and control of a media player via which video and/or audio content provided by the media provider is played, visibility of media played during a current session at the client device 122 (e.g., whether the media player is minimized/maximized, whether the media player is behind another tab or window, etc.), and volume of media played during the current session.
- reception component 106 can also receive information regarding a user's facial expressions, posture, and words or sounds provided by the user during the current session. For example, reception component 106 can receive information indicating when a user is smiling, laughing, crying, etc.
- signal collection component 126 can receive signals from a camera facing the user and a microphone provided at client device 122 and/or an auxiliary input device 132 , and relay these signals to reception component 106 .
- reception component 106 can receive information regarding a mechanism via which the current session was initiated (e.g., in response to a general request by the user to open the network based platform of the streaming media provider, or in response to selection of a link to media content, provided by the streaming media provider, at an external source 128 or received by the user in an electronic message).
- reception component 106 can receive information identifying the specific media item represented by a selected link, the referral source at which the link was located (e.g., an external source 128 ), and information about the referral source. This information can be provided by the referring source, the client device 122 and/or identified by reception component 106 via metadata associated with the selected link and/or the referral source.
- reception component 106 can receive information about the content of a website or webpage at which the link was located. This information can provide insight into what mood the user was in at the time of selection of the link. For instance, where the selected link corresponded to a video providing information about coping with a terminal illness and the link was located at a webpage providing medical information about the terminal illness, it can be inferred that the user's mental state is one of concern, sadness, despair, curiosity, etc. In another example, where the user selected a link to a music video for a love song from a message provided by her boyfriend, it can be assumed that the user is in a state of happiness, joy and feeling loved.
- Reception component 106 can also receive information related to the user's environment during a current session (e.g., including location, other people and things at the location, activities or events occurring at the location, etc.), what the user is doing in the environment in association with the current session, time of day of the current session, the type of device the user is employing to conduct the current session (e.g., mobile, stationary, tablet, phone, desktop, etc.).
- client device 122 and other clients 130 as well
- can determine its location e.g., via a global positioning system method, triangulation, or any other suitable locating technique) and provide this location information to reception component 106 over the course of the current session.
- an external source e.g., a cellular carrier system
- reception component 106 can look up information about the location (e.g., places and things associated with the location, events associated with the location, other clients 130 /users at the location, weather at the location, traffic at the location etc.).
- information regarding a user's environment can be captured and provided to reception component 106 via a camera and/or microphone located at client device 122 and/or an auxiliary input device 132 .
- information regarding what a user is doing in association with a current session can be received by reception component 106 from a user's schedule (e.g., provided on client device 122 or at an external source 128 ).
- information regarding a user's movement and motion can be captured by various motion sensors employed by the user (e.g., worn by the user) and/or provided at client device (e.g., an accelerometer, gyroscope). This motion/movement information can facilitate determining (e.g., by reception component, dynamic content selection platform 104 and/or another system), what the user is doing (e.g., walking, running, sitting, driving a car, etc.) and where the user is going.
- dynamic content selection platform 104 and/or another system can learn user patterns and behaviors over time based on where the user goes, what the user does, who the user is with, the user's schedule, etc. to determine or infer what the user is doing at a particular point in time in association with a current session.
- reception component 106 can also receive information related to what the user was doing before initiation of a current session (e.g., where the user was, an activity the user was performing, etc.), an amount of time the user has for conducting the current session (e.g., the user has a one hour lunch break during after which the user must return to work and end the current session), and what the user is likely to do or scheduled to do after the current session (e.g., return to work, go to bed, attend an event, etc.), based on the user's schedule and/or learned user behaviors/patterns.
- information related to what the user was doing before initiation of a current session e.g., where the user was, an activity the user was performing, etc.
- an amount of time the user has for conducting the current session e.g., the user has a one hour lunch break during after which the user must return to work and end the current session
- what the user is likely to do or scheduled to do after the current session e.g., return to work, go to bed,
- reception component 106 can receive information about a user's physiological state. For example, reception component 106 can receive information about a user's heart rate, blood pressure, blood sugar, blood oxygenation level, cortisol level, blood alcohol level, or information regarding pupil dilation.
- physiological information about a user can be captured via various biometric/motion sensing devices employed by the user (e.g., worn by the user and/or provided at client device 122 ).
- Reception component 106 can also receive information about other users activity with content provider 102 during a user's current session with the content provider, wherein the other users have some connection with the user (e.g., a social connection, a shared preference, a shared demographic feature, etc.). For example, media content that is being watched, liked, shared, etc., by a user's friends at a streaming media provider while the user is conducting a current session with the streaming media provider can influence what content the user may also be interested in during the user's current session. According to this example, when a bunch of the user's friends are conducting sessions with the streaming media provider at the same time as the user and watching a particular live sports video, it can be assumed that the user would likely be interested in watching the sports video as well. Accordingly the live sports video can be recommended to the user during the user's current session.
- a bunch of the user's friends are conducting sessions with the streaming media provider at the same time as the user and watching a particular live sports video, it can be assumed that the user would likely be interested
- State component 108 is configured to determine or infer state of mind attributes associated with a user's current state of mind during a session with a content provider 102 (e.g., a streaming media provider) based on information received by reception component 106 .
- a user's state of mind can include aspects related to what the user is thinking and/or feeling during a current session.
- state of mind attributes can correspond to aspects of a user's mood or attitude during a current session.
- a person's mood is a conscious and temporary state of mind or predominant emotion.
- possible values/attributes of a user's mood can include happy, inspired, indignant, optimistic, pessimistic, excited, say, depressed, etc.
- a user's mood can also reflect whether the user is feeling rushed or not, whether the user is exhibiting patience, whether the user anxious, or whether the user is passive.
- Mood is a generalized, internal state of feeling. It is closely related to the concepts of affect and emotion. Emotions are intense feelings that are directed at specific objects or situations, while mood is a state of feeling that is less intense than emotions and more generalized. For example, when a person is mad (emotion), they are usually mad at specific things; however, when a person is in an anxious mood, they may be anxious throughout the day no matter what the circumstances.
- a user's state of mind can also reflect a user's conscious or subconscious intention for performing or conducting a session with a streaming media provider.
- a user's mood can indicate whether the user wants to be entertained, whether the user is in an educational frame of mind, or whether the user is in a work frame of mind.
- a user's state of mind can include a level of engagement a user has with a particular content item such as a video or song (e.g., whether the user is actively attentive towards the content item or passively engaged with the content item).
- state component 108 can determine state attributes representative of a user's current state of mind during a session with a content provider 102 based on how the user navigates about content provided by the content provider 102 . For example, state component 108 can determine attributes about a user's state of mind based on how the user navigates about a media provider's website (e.g., what categories the user's selects, how the user moves from one interface to another, how the user influence what media items are presented on a particular interface, whether the user is searching or browsing, etc.).
- State component 108 can also determine state attributes based on media items, provided by the media provider, that are played for watching by the user during the current session (e.g., either in response to selection by the user or automatically played/pushed to the user), and a manner via which the user interacts with or reacts to the played media items.
- state attributes for the user could include ‘happy,’ ‘joyful,’ ‘entertainment mode,’ ‘humorous content,’ and ‘light hearted.’
- state component 108 can determine the user is in a relaxed mood.
- state component 108 can determine whether the user is looking to be entertained and how or whether the user is looking for informational/instructional content. For instance, when a user is selecting videos that are short movies of a thriller genre, state component 108 can determine the user is looking to be entertained with media content that has a thriller theme. According state attributes for the user could include ‘entertainment mode,’ ‘movie,’ and ‘thriller.’ In another example, if a user is selecting exercise videos, state component 108 can determine that the user is in a mindset of working out.
- respective media items provided by a media provider at which a user conducts a current session can be associated with one or more different mood or state of mind attribute values.
- these mood or state of mind attributes can be associated with the respective media items as metadata associated with the respective media items.
- these mood or state attributes can be associated with the respective media items on a database correlating the respective media items to mood/state of mind attributes. For example, a funny video about puppies can be associated with mood values of corresponding to happy, joyful, sappy, sensitive, and humorous.
- workout videos can be associated with moods reflective of exercise, motivation, health and energy.
- classical music based content can be associated with relaxation mood values.
- attributes of media items provided by the media provider can be associated with respective mood values.
- state component 108 can analyze the various state or mood values associated with media items viewed (e.g., watched and/or listened to) by a user over the course of a current session to determine or infer one or more cumulative state attributes of the user's mood.
- information regarding a level of user interaction and engagement with the respective media items can further facilitate determining a user's mood. For example, where a user engages with and interacts more with media items having mood values of a, b, and c and less with media items having mood values x, y and z, state component 108 can place a greater weight on mood values a, b and c when determining the user's mood attributes.
- state component 108 can determine or infer a user's mood based on the manner in which a user navigates content provided by a media provider during the user's session with the media provider. For example, based on the user's navigational mechanisms, state component 108 can whether the user is in a state of haste or whether the user is not in a state of haste.
- state component 108 can determine or infer that a user is in a state of haste or not based on how quickly and frequently a user selects new media items for viewing and the durations of the media items selected for viewing being relatively short or long (e.g., with respect to a threshold duration) as well as the amounts of the durations watched/listened to by the user (e.g., watching more than X % of a video can indicate the user is not in a state of haste while watching less than X % of a video can indicate the user is in a state of haste).
- state component 108 can determining whether the user is in a leisurely mindset or has is focused on a specific agenda or task. According to this example, when a user's navigation mechanisms indicate the user is browsing the various media content provided by a media provider (e.g., via selecting recommended media items or items associated with different media item categories), state component 108 can consider the user in a leisurely mindset. On the other hand, when a user is performing a specific keywords search and looking for videos of a particular subject matter or title, the user can be considered to be in focused and structured mindset.
- state component 108 can determine or infer state attributes to associated with a user during a current session that include ‘state of haste or hurry,’ ‘browsing mindset,’ ‘focused searching mindset,’ ‘structure searching mindset,’ and similar attributes.
- state component 108 can determine or infer attributes associated with a user's state of mind based on the manner via which a user interacts with or reacts to the media items played during the user's current session. For example, if a user stops playing a certain media item or disengages from the media item as it plays, state component 108 can determine that mood values associated with the media item do not reflect the user's current mood. Similarly, where a user engages with a particular media item during a current session, shares the media item, comments on the item etc., state component 108 can determine or infer that mood values associated with the media item are more reflective of the user's current mood. Thus in an aspect, state component 108 can weight mood values associated with media items accessed/watched/listened to by a user based on the manner and level of engagement the user has with the respective media items.
- state component 108 can determine or infer attributes corresponding to a user's current state of mind based on a user's physical reaction to a particular media item during a current session (e.g., laughing, crying, smiling, dancing, leaning in to watch intently, expression of excitement, acceleration of heart rate, etc.), and comments provided by the user about the media item (“I love this song,” “this was so scary,” “this video made be bawl,” etc).
- state component 108 can not only determine that a user is sad but why the user is sad. The state component 108 can then determine other attributes associated with the user's mood based on a determination as to what type of content characteristics arouse the user's sadness. For instance, a sad music video for a love song about a passed significant other can be associated with feelings of loneliness, longing, and grief.
- Signals regarding a user's physical state can also be employed by state component 108 to determine or infer attributes related to a user's mental state. For example, information regarding a user's heart rate levels received as the user is presented different types of content during a current session can provide information regarding whether the user finds the content type exciting or boring. In another example, when it can be discerned that the user is stressed during a current session (e.g., based on cortisol levels), content associated with alleviating the user's stress can be identified for presenting to the user during the current session.
- a user's state of mind can include a level of engagement of a user during a current session with a media provider and/or particular content played during the session.
- state component 108 can determine or infer state attributes that indicate whether the user is actively engaged, passively engaged or disengaged.
- state component 108 can discern a user's level of engagement during a current session based on explicit engagement signals (e.g., like/dislike, comment, subscribe, seek, etc.) and implicit engagement signals (e.g., continued playback, mouse/keyboard movement, device movement, touchscreen activity, etc.) received by reception component 106 .
- explicit engagement signals e.g., like/dislike, comment, subscribe, seek, etc.
- implicit engagement signals e.g., continued playback, mouse/keyboard movement, device movement, touchscreen activity, etc.
- state component 108 can determine a user's level of engagement during a current session based on visibility of the played media items via an interface presented to the user during the current session and volume of the played media items. For example, when a user has video content playing with the volume turned off or low, state component 108 can determine that the user is passively engaged in a ‘watching no volume mode.’ In another example, when a user has a video content playing with the volume turned up yet the video player minimized or provided behind another open window or tab, state component 108 can determine that the user is passively engaged in a ‘listening only mode.’ However where both the video player is not visible and the volume is turned off or down, state component 108 can determine that the user is disengaged.
- state component 108 can employ information regarding a user's movement/motion to determine or infer a user's state of mind. For example, if a user is moving or headed somewhere, state component 108 can determine that the user is in a state of ‘haste’ or ‘on the go.’ Similarly, if the user is stationary, state component 108 can determine that the user is relaxed and has time on his hands.
- Context component 110 is configured to determine context characteristics related to the context of a current session between a user and content provider 102 .
- Context refers to the circumstances that form the setting for an event, statement, or idea, and in terms of which it can be fully understood and assessed.
- context can include the circumstances that form the setting of the current session.
- context component 110 is configured to determine context characteristics associated with a current session between a user and a media provider based on information received by reception component 106 .
- these context characteristics can include but are not limited to: where the user is located or going during the current session (e.g., as determined by context component 110 based on received or determined location information for client device 122 during the current session and/or received user movement/motion information), when (e.g., time of day) the current session is occurring, and who the user is with (e.g., alone, with a group other users, with a friend etc.) during the current session (e.g., as determined by context component 110 based on received location information for other clients 130 when authorized by the other clients and/or based on video/image and/or audio information capture of the user's environment).
- content component 110 can further employ various external sources to look up current context characteristics about the location (e.g., persons, places, things, events, weather, traffic, etc. associated with the location). For example, context component 110 can determine that a user is located at a restaurant at a time when the restaurant that is throwing special event for alumni of a local college.
- context component 110 can determine that a user is located at a restaurant at a time when the restaurant that is throwing special event for alumni of a local college.
- context component 110 can determine or infer content characteristics that relate to what a user is doing aside from or in association with a current session with a content provider (e.g., walking, exercising, riding a train/bus, working, conducting a work meeting, attending a class, cleaning the house, waiting at the doctor's office, laying at the beach, attending a party with friends, etc.). Context component can also determine characteristics regarding what the user was doing before and/or will do after the current session. For example, context component 110 can determine or infer an activity performed by the user preceding initiation of the current session, a duration of time the user has available for the current session, or an activity for performance by the user at a known point in time after initiation of the current session.
- a content provider e.g., walking, exercising, riding a train/bus, working, conducting a work meeting, attending a class, cleaning the house, waiting at the doctor's office, laying at the beach, attending a party with friends, etc.
- Context component can also determine characteristics regarding what the
- Context component 110 can determine these content characteristics related two what a user is doing, was doing and will do in the near future based on analysis of a various received signals related to where the user is located, time of day, who the user is with, what device the user is on, and movement data for the user in view of the user's schedule and/or learned behavior for the user. For example, based on information indicating the user is located at her home around 6 am on a weekday morning, information indicating the user is moving about the house, information indicating the user is conducting a current media session on her Internet enabled television, and the user's work schedule, context component 110 can determine that the user is getting ready to go to work and will be leaving the house at about 7 am.
- Context component 110 can also determine content characteristics related to a user's purpose for a current session. For example, context component 110 can determine whether a current session with a media provider is for an entertainment purpose, an educational purpose, or a work related purpose. In an aspect, context component 110 can determine or infer a purpose of a current session with a media provider based on the media items provided by the media system that are played for watching by the user during the current session, and the manner via which the user interacts with or reacts to the played media items.
- context component 110 can determine whether a user is performing the current session to get information about a specific subject, to find a playlist for a party, to watch videos about a particular subject, to get the recent local news, to find a movie to watch, to browse for something entertaining to watch, to get instruction for performing a task, to find a yoga instruction video, etc.
- context component 110 can determine a purpose for a current session with a media provider based on how the current session was initiated.
- the purpose of a session could initially include a user's desire to view a media item represented by a selected link at another source.
- context component can determine 110 whether the user was directed to the media system from a referral source, a media item provided by the media provider represented by a link selected by the user at the referral source, and/or information about the referral source.
- context component 110 can determine or infer information related to sessions of other users, related to the user (e.g., friends of the user, users sharing similar preferences or demographics of the user, etc.), with the content provider that are being conducted during the current session of the user. For example, context information regarding content the user's friends are accessing and sharing while the user is also accessing the content provider can influence what the user may find interesting during the user's current session, such as what videos and channels the user's friends are watching during the user's current session with a media provider.
- state component 108 can determine or infer various attributes about a user's state of mind based on characteristics of a user's context as determined by context component 110 .
- a user's context can greatly influence the user's state of mind.
- a user's mood can vary depending on the time of day, the user's environment (e.g., where the user is located and current aspects associated with the location at the time of day and day of week, including other persons, things and events or activities), what the user is doing in association with the current session (e.g., driving, relaxing, at a party, etc.), what the user just did before the session and/or has to do after the session (e.g., came from school, going to a doctor's appointment, etc.), what device the user is employing, or how the user initiated the session (e.g., in response to selection of a link to a specific video, to conduct a search, or to browse).
- state component 110 can analyze characteristics about a user's context to facilitate determining or inferring a user's current state of mind (e.g., mood, attitude, emotional state, energy level, etc.).
- state component 108 can employ various rule based classification schemes and/or machine learning techniques that relate different context attributes associated with a user's current context particular to state of mind attributes (e.g., mood values).
- Selection component 112 is configured to select a content item for provision to a user during the user's current session with a content provider 102 based on the various state attributes and context characteristics determined or inferred by state component 108 and context component 110 , respectively, during the user's current session.
- content provider 102 is a streaming media provider
- selection component 112 is configured to select a media item based on the user's state attributes and context characteristic.
- the media item can include a media advertisement or video trailer for another media item or channel provided by the media provider.
- the media advertisement or video trailer can be provided to the user (e.g., as an in-stream advertisement/trailer, as a banner advertisement, as an in-video advertisement, etc.) to the user in association with other media content accessed by the user during the current session.
- the media item can include another media item provided by the media provider.
- the media item can be provided to the user in a recommendation section or list of media items recommended to the user during the user's current session.
- selection component 112 can employ a media index 118 that associates a plurality of media items and media advertisements, provided by the media provider, with state attributes and context attributes.
- the state and context attributes associated with a particular media item can be selected based on a particular user a state of mind and user context under which the media item is considered to be well received.
- a video advertisement for a fast food breakfast restaurant could be associated with state attributes such as ‘hungry,’ ‘state of haste,’ ‘tired,’ or ‘on the go.’
- Context attributes associated with the advertisement could include ‘morning,’ ‘driving,’ and ‘location N’ (wherein location N can vary and include different locations where the fast food breakfast restaurant is located).
- media items in media index 118 can be associated with various mood attributes indicative of modes the media items evoke or compliment, such as mood attributes indicating whether the media item is suited for users in an entertainment related or a work related mode.
- media items that are relatively short in length can be associated with attributes that indicate they are suited for users who are in a state of haste/hurry or in distracted/passive state while media items that are longer in duration can be associated with attributes that indicate they are suited for users who are in leisurely, calm, time on their hands, attentive, etc., kind of state.
- a media advertisement can be associated with attributes that indicate whether it has audible branding or not (wherein a media advertisement without audible branding will be ineffective for a user who is passively engaged with a media content session based on failure to have a media player or interface visible to the user).
- a media advertisement can be associated with an attribute indicating it has no or low visible branding (wherein the media advertisement will be ineffective when the user is passively engaged do to no or low volume).
- selection component 112 can match or relate user state attributes and user context characteristics with state attributes and context characteristics associated with different media items provided in media index 118 to identify one or more media items that match or relate the user's current state of mind and context. For example, when a user is relaxing in the evening at home and selecting and watching relatively short videos with funny and light hearted content, selection component 112 can select a media item for provision to the user that is also relatively short and has an entertaining, funny and light hearted nature.
- a determination that a media item matches a user's current state and context can be based on a correspondence threshold (e.g., a percentage match threshold) between the user's current state and context attributes and the state and context attributes associated with the media item.
- a correspondence threshold e.g., a percentage match threshold
- the degree of contribution of certain state attributes and context characteristics to a match determination can also vary. For example, a location based context characteristic can provide a greater influence on a match determination over a context characteristic related to why a user's current session was initiated.
- selection component 112 can be configured to select media items that do not necessarily share the same state/context attributes as a user, but which are associated with state/context attributes that compliment those of the user.
- selection component can identify a media advertisement that is associated with attributes designed to lift the user's spirits. For example, a suitable advertisement could include one for a warm weather vacation.
- selection component 112 can employ various rule based classification schemes or machine based learning techniques to facilitate selecting a media item that a user will likely be receptive to and engage with during the user's current session with a media provider based on the user's current state of mind and context.
- selection component 112 can infer that although a user's state and context characteristics indicate the user is a relatively good match for the fast food breakfast restaurant advertisement, based on a single context characteristic that indicates the user has X amount of time before she has to be at work, the user will not be able to stop at the fast food breakfast restaurant on the way to work. Accordingly, selection component 112 can determine that provision of the fast food breakfast restaurant advertisement to the user during the user's current session would not cause the user to act on the advertisement, and thus select a different media advertisement for provision to the user.
- System 200 includes same or similar features and functionalities as system 100 with the additions of scoring component 202 and rendering component 204 to dynamic content selection platform 104 . Repetitive description of like elements employed in respective embodiments of systems described herein is omitted for sake of brevity.
- Scoring component 202 is configured to score and rank content items (e.g., media items) provided by content provider 102 (e.g., a streaming media provider based on relevance or suitability to a user in association with a current session between the user and the content provider 102 , wherein the determination of relevance or suitability is based at least in part on the user's current state of mind and context.
- content provider 102 e.g., a streaming media provider based on relevance or suitability to a user in association with a current session between the user and the content provider 102 , wherein the determination of relevance or suitability is based at least in part on the user's current state of mind and context.
- scoring component 202 can score media advertisements provided by a media provider based on relevance and suitability of the media advertisements for a user during the user's current session with the media provider based on the user's current state of mind and context.
- scoring component 202 can analyze a plurality of media advertisements based on correspondence and fixed relationships between the user's current user state and context attributes and state and context attributes respectively associated with the media advertisements to determine a score for the respective media advertisements representative of relevance and suitability of the respective media advertisements to the user.
- relevance and suitability can reflect a probability that the user will view the advertisement and/or the advertisement will have an impression upon the user.
- Selection component 112 can then select the media advertisement having the highest score (and/or a subset of the media advertisement having the highest scores) for provision to the user during the user's current media session.
- the weight vector W can be designed to account for a probability that the media advertisement will be viewed past a billable point and/or a probability that the media advertisement will have a lasting impression upon the user.
- W can be generated using historical data using a machine learning algorithm.
- scoring component 202 can re-score the respective media advertisements based on the new user attribute values. Accordingly, over the course of the user's session, selection component 112 can dynamically select the most relevant and suitable media advertisement for provision to the user at a current point in the user's session based on the user's current mental state and context at that point.
- scoring component 202 can score and rank trailers for channels provided by a media provider or trailers for other videos provided by the media provider based on relevance and suitability for a user during the user's current session with the media provider in view of the user's current state of mind and context.
- relevance and suitability can reflect a probability that the user will view the trailer and choose to select the channel or video represented by the trailer for watching, subscribing to, or otherwise showing an affinity for.
- selection component 112 can then select the trailer having the highest score (and/or a subset of the media advertisement having the highest scores) for provision to the user during the user's current media session.
- respective scores associated with trailers can change over the course of a user's media session based on changes to the user's mood or context. Accordingly, at any given time in a user's media session, selection component 112 can select the trailer having the highest score at that time.
- scoring component 202 can score other media items (e.g., videos, channels or playlists) provided by a media provider based on relevance and suitability for a user during the user's current session with the media provider based on the user's current state of mind and context. According to this example, relevance and suitability can reflect a probability that the user will view/play the media item or subscribe to the media item. Selection component 112 can then select a subset of media items having the highest scores for provision to the user in a recommendation section/list during the user's current media session.
- media items e.g., videos, channels or playlists
- Rendering component 204 is configured to effectuate the rendering of a content item (e.g., a media item) identified be selection component 112 to the user during the user's current session. For example, when the session includes a session with a streaming media provider, rendering component 204 can direct the streaming media provider to stream a selected video advertisement or trailer (e.g., an in-stream video advertisement) to the user in association with another media item accessed by the user. In another example, rendering component 204 can direct the streaming media provider to include a subset of media items identified by selection component 112 in a recommendation menu or list included in a portion of a user interface employed by the streaming media provider.
- a content item e.g., a media item identified be selection component 112
- rendering component 204 can direct the streaming media provider to stream a selected video advertisement or trailer (e.g., an in-stream video advertisement) to the user in association with another media item accessed by the user.
- rendering component 204 can direct the streaming media provider to include a subset of
- FIG. 3 presents another example system 300 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- System 300 includes same or similar features and functionalities as system 200 with the addition of inference component 302 to dynamic content selection platform 104 . Repetitive description of like elements employed in respective embodiments of systems described herein is omitted for sake of brevity.
- Inference component 302 is configured to provide for or aid in various inferences or determinations associated with aspects of dynamic content selection platform 104 .
- inference component 302 can aid state component 108 and context component 110 with inferring attributes about a user's current state of mind and context based on the various information received by reception component 106 discussed herein.
- inference component 302 can aid selection component 112 with identifying a content item (e.g., a media item) that is likely to be well received by a user during the user's current session based on the user's current state of mind and context.
- inference component 302 can facilitate scoring component 202 with inferring scores of suitability and relevance for content items based on a user's current state of mind and context and state and context attributes respectively associated with the content items.
- inference component 302 can examine the entirety or a subset of the data to which it is granted access and can provide for reasoning about or infer states of the system, environment, etc. from a set of observations as captured via events and/or data.
- An inference can be employed to identify a specific context or action, or can generate a probability distribution over states, for example.
- the inference can be probabilistic—that is, the computation of a probability distribution over states of interest based on a consideration of data and events.
- An inference can also refer to techniques employed for composing higher-level events from a set of events and/or data.
- Such an inference can result in the construction of new events or actions from a set of observed events and/or stored event data, whether or not the events are correlated in close temporal proximity, and whether the events and data come from one or several event and data sources.
- Various classification (explicitly and/or implicitly trained) schemes and/or systems e.g., support vector machines, neural networks, expert systems, Bayesian belief networks, fuzzy logic, data fusion engines, etc.
- support vector machines, neural networks, expert systems, Bayesian belief networks, fuzzy logic, data fusion engines, etc. can be employed in connection with performing automatic and/or inferred action in connection with the claimed subject matter.
- Such classification can employ a probabilistic and/or statistical-based analysis (e.g., factoring into the analysis utilities and costs) to prognose or infer an action that a user desires to be automatically performed.
- a support vector machine (SVM) is an example of a classifier that can be employed. The SVM operates by finding a hyper-surface in the space of possible inputs, where the hyper-surface attempts to split the triggering criteria from the non-triggering events. Intuitively, this makes the classification correct for testing data that is near, but not identical to training data.
- directed and undirected model classification approaches include, e.g., na ⁇ ve Bayes, Bayesian networks, decision trees, neural networks, fuzzy logic models, and probabilistic classification models providing different patterns of independence can be employed. Classification as used herein also is inclusive of statistical regression that is utilized to develop models of priority.
- FIG. 4 presents another example system 400 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- System 400 includes same or similar features and functionalities as system 300 with the additions of trailer component 402 and recommendation component 404 to dynamic content selection platform 104 . Repetitive description of like elements employed in respective embodiments of systems described herein is omitted for sake of brevity.
- selection component 112 is configured to select a content item for provision to a user during the user's current session with a content provider 102 based on the user's current state of mind and context.
- the type of the content item selected can vary depending on the content provider 102 .
- the content item can include a trailer for another media item provided by the streaming media provider.
- a trailer is a series of short edited clips of selected scenes of a video that are put together into one montage. Trailers are often used as a way to advertise a video or film.
- Trailer for channels provided by the streaming media provider can include video content associated with the channel configured to provide a video advertisement for the channel.
- Trailer component 402 is specifically configured to identify video and/or channel trailers for videos and channels provided by a media provider based on a user's current state of mind and/or context during a current session with the media provider.
- a trailer identified by trailer component 402 can be streamed to a user during the user's current session as an in-stream video in association with another video selected for watching by the user.
- a trailer identified by trailer component 402 can be streamed to a user during the user's current session when the user is not playing another video (e.g., while the user is searching or browsing for media items provided by the media provider.
- Recommendation component 404 is configured to generate a list of recommended media items, provided by a streaming media provider, for suggesting or recommending to a user during a user's current session with a streaming media provider based on the user's current state of mind and/or context.
- recommendation component 404 can identify videos, channels, and/or playlists that include media content that is reflective of or complementary to a user's current mood and context.
- FIG. 5 presents another example system 500 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- System 500 includes same or similar features and functionalities as system 400 with the additions of advertisement component 502 and advertisement charging component 504 to dynamic content selection platform 104 . Repetitive description of like elements employed in respective embodiments of systems described herein is omitted for sake of brevity.
- Advertisement component 502 is configured to facilitate targeted advertising based on a user's current state of mind and context during a session with a content provider 102 .
- advertisement component 502 can identify video advertisements, banner advertisements, image advertisements, audio advertisements, etc. that are relevant to a user and likely to provide an impression upon the user based on the user's current state of mind and context as determined or inferred by state component 108 and context component 110 , respectively.
- advertisement component 502 can target users with tailored advertisements at the right time, increasing user happiness and advertiser return on investment.
- Advertisement charging component 504 can facilitate dynamically charging an advertiser for provision of an advertisement based on a degree to which the advertisement capitalizes on a user's current state of mind and context.
- scoring component is configured to dynamically score advertisements based on relevance and suitability of the advertisements for a user given various attributes associated with the user's state of mind and context, wherein relevance and suitability can reflect a probability that the user will view the advertisement and/or the advertisement will have an impression upon the user.
- Advertisement charging component 504 can factor in an advertisements score in association with charging provision of the advertisement.
- example methods that can be implemented in accordance with the disclosed subject matter can be further appreciated with reference to flowcharts in FIGS. 6-8 .
- example methods disclosed herein are presented and described as a series of acts; however, it is to be understood and appreciated that the disclosed subject matter is not limited by the order of acts, as some acts may occur in different orders and/or concurrently with other acts from that shown and described herein.
- a method disclosed herein could alternatively be represented as a series of interrelated states or events, such as in a state diagram.
- interaction diagram(s) may represent methods in accordance with the disclosed subject matter when disparate entities enact disparate portions of the methods.
- FIG. 6 illustrates a flow chart of an example method 600 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- user state attributes associated with a user's current state of mind during a current session of the user with a streaming media provider are determined based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or a manner via which the user interacts with or reacts to the played media items, wherein the state of the user includes a mood of the user (e.g., via state component 108 ).
- state component 108 can determine that the user is probably frustrated, annoyed, focused on finding a solution to a specific problem as opposed to looking for entertainment content and attentive to the current session.
- a media item provided by the streaming media provider is selected based on the user state attributes (e.g., via selection component 112 ). For example, selection component 112 can select a video trailer for a channel provided on by the streaming media provider that includes several short do it yourself repairs for different cell phone types and issues. In another example, selection component 112 can select a media advertisement for a service that repairs broken cell phones.
- the selected media item is then rendered to the user during the current session.
- FIG. 7 illustrates a flow chart of another example method 700 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- mood attributes associated with a user's current mood during a session of the user with a streaming media provider and context attributes associated with a current context of the session based are determined on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or an environment of the user (e.g., via state component 108 and context component 110 ).
- selecting a media item provided by the streaming media provider based on the mood attributes and the context attributes e.g., via selection component 112 ).
- the media item is rendered to the user during the current session (e.g., via rendering component 204 ).
- FIG. 8 illustrates a flow chart of another example method 700 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- current mood attributes associated with a user's current mood during a session of the user with a streaming media provider and current context attributes associated with a current context of the session are determined based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or an environment of the user (e.g., via state component 108 and context component 110 ).
- a plurality of media advertisements provided by the streaming media provider are scored based on relevance and suitability for the user during the user's session, wherein the relevance and suitability is based on a correspondence between the current mood and current context attributes, and state and context attributes respectively associated with the plurality of media advertisements (e.g., via scoring component 202 ).
- one of the plurality of media advertisements associated with a score exceeding a threshold score is selected, wherein scores above the threshold score indicate a high degree of relevance and suitability for the user based on the user's current mood and the current context of the session (e.g., via selection component 112 ).
- streaming of the media advertisement to the user is effectuated during the user's current session (e.g., via rendering component 204 ).
- a suitable environment 1000 for implementing various aspects of the claimed subject matter includes a computer 1002 .
- the computer 1002 includes a processing unit 1004 , a system memory 1006 , a codec 1005 , and a system bus 1008 .
- the system bus 1008 couples system components including, but not limited to, the system memory 1006 to the processing unit 1004 .
- the processing unit 1004 can be any of various available processors. Dual microprocessors and other multiprocessor architectures also can be employed as the processing unit 1004 .
- the system bus 1008 can be any of several types of bus structure(s) including the memory bus or memory controller, a peripheral bus or external bus, and/or a local bus using any variety of available bus architectures including, but not limited to, Industrial Standard Architecture (ISA), Micro-Channel Architecture (MSA), Extended ISA (EISA), Intelligent Drive Electronics (IDE), VESA Local Bus (VLB), Peripheral Component Interconnect (PCI), Card Bus, Universal Serial Bus (USB), Advanced Graphics Port (AGP), Personal Computer Memory Card International Association bus (PCMCIA), Firewire (IEEE 13104), and Small Computer Systems Interface (SCSI).
- ISA Industrial Standard Architecture
- MSA Micro-Channel Architecture
- EISA Extended ISA
- IDE Intelligent Drive Electronics
- VLB VESA Local Bus
- PCI Peripheral Component Interconnect
- Card Bus Universal Serial Bus
- USB Universal Serial Bus
- AGP Advanced Graphics Port
- PCMCIA Personal Computer Memory Card International Association bus
- Firewire IEEE 13104
- SCSI Small Computer Systems Interface
- the system memory 1006 includes volatile memory 1010 and non-volatile memory 1012 .
- the basic input/output system (BIOS) containing the basic routines to transfer information between elements within the computer 1002 , such as during start-up, is stored in non-volatile memory 1012 .
- codec 1005 may include at least one of an encoder or decoder, wherein the at least one of an encoder or decoder may consist of hardware, a combination of hardware and software, or software. Although, codec 1005 is depicted as a separate component, codec 1005 may be contained within non-volatile memory 1012 .
- non-volatile memory 1012 can include read only memory (ROM), programmable ROM (PROM), electrically programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), or flash memory.
- Volatile memory 1010 includes random access memory (RAM), which acts as external cache memory. According to present aspects, the volatile memory may store the write operation retry logic (not shown in FIG. 10 ) and the like.
- RAM is available in many forms such as static RAM (SRAM), dynamic RAM (DRAM), synchronous DRAM (SDRAM), double data rate SDRAM (DDR SDRAM), and enhanced SDRAM (ESDRAM.
- Disk storage 1014 includes, but is not limited to, devices like a magnetic disk drive, solid state disk (SSD) floppy disk drive, tape drive, Jaz drive, Zip drive, LS-70 drive, flash memory card, or memory stick.
- disk storage 1014 can include storage medium separately or in combination with other storage medium including, but not limited to, an optical disk drive such as a compact disk ROM device (CD-ROM), CD recordable drive (CD-R Drive), CD rewritable drive (CD-RW Drive) or a digital versatile disk ROM drive (DVD-ROM).
- CD-ROM compact disk ROM
- CD-R Drive CD recordable drive
- CD-RW Drive CD rewritable drive
- DVD-ROM digital versatile disk ROM drive
- a removable or non-removable interface is typically used, such as interface 1016 .
- FIG. 10 describes software that acts as an intermediary between users and the basic computer resources described in the suitable operating environment 1000 .
- Such software includes an operating system 1018 .
- Operating system 1018 which can be stored on disk storage 1014 , acts to control and allocate resources of the computer system 1002 .
- Applications 1020 take advantage of the management of resources by operating system 1018 through program modules 1024 , and program data 1026 , such as the boot/shutdown transaction table and the like, stored either in system memory 1006 or on disk storage 1014 . It is to be appreciated that the claimed subject matter can be implemented with various operating systems or combinations of operating systems.
- Input devices 1028 include, but are not limited to, a pointing device such as a mouse, trackball, stylus, touch pad, keyboard, microphone, joystick, game pad, satellite dish, scanner, TV tuner card, digital camera, digital video camera, web camera, and the like.
- These and other input devices connect to the processing unit 1004 through the system bus 1008 via interface port(s) 1030 .
- Interface port(s) 1030 include, for example, a serial port, a parallel port, a game port, and a universal serial bus (USB).
- Output device(s) 1036 use some of the same type of ports as input device(s).
- a USB port may be used to provide input to computer 1002 , and to output information from computer 1002 to an output device 1036 .
- Output adapter 1034 is provided to illustrate that there are some output devices 1036 like monitors, speakers, and printers, among other output devices 1036 , which require special adapters.
- the output adapters 1034 include, by way of illustration and not limitation, video and sound cards that provide a means of connection between the output device 1036 and the system bus 1008 . It should be noted that other devices and/or systems of devices provide both input and output capabilities such as remote computer(s) 1038 .
- Computer 1002 can operate in a networked environment using logical connections to one or more remote computers, such as remote computer(s) 1038 .
- the remote computer(s) 1038 can be a personal computer, a server, a router, a network PC, a workstation, a microprocessor based appliance, a peer device, a smart phone, a tablet, or other network node, and typically includes many of the elements described relative to computer 1002 .
- only a memory storage device 1040 is illustrated with remote computer(s) 1038 .
- Remote computer(s) 1038 is logically connected to computer 1002 through a network interface 1042 and then connected via communication connection(s) 1044 .
- Network interface 1042 encompasses wire and/or wireless communication networks such as local-area networks (LAN) and wide-area networks (WAN) and cellular networks.
- LAN technologies include Fiber Distributed Data Interface (FDDI), Copper Distributed Data Interface (CDDI), Ethernet, Token Ring and the like.
- WAN technologies include, but are not limited to, point-to-point links, circuit switching networks like Integrated Services Digital Networks (ISDN) and variations thereon, packet switching networks, and Digital Subscriber Lines (DSL).
- ISDN Integrated Services Digital Networks
- DSL Digital Subscriber Lines
- Communication connection(s) 1044 refers to the hardware/software employed to connect the network interface 1042 to the bus 1008 . While communication connection 1044 is shown for illustrative clarity inside computer 1002 , it can also be external to computer 1002 .
- the hardware/software necessary for connection to the network interface 1042 includes, for exemplary purposes only, internal and external technologies such as, modems including regular telephone grade modems, cable modems and DSL modems, ISDN adapters, and wired and wireless Ethernet cards, hubs, and routers.
- the system 1100 includes one or more client(s) 1102 (e.g., laptops, smart phones, PDAs, media players, computers, portable electronic devices, tablets, and the like).
- the client(s) 1102 can be hardware and/or software (e.g., threads, processes, computing devices).
- the system 1100 also includes one or more server(s) 1104 .
- the server(s) 1104 can also be hardware or hardware in combination with software (e.g., threads, processes, computing devices).
- the servers 1104 can house threads to perform transformations by employing aspects of this disclosure, for example.
- One possible communication between a client 1102 and a server 1104 can be in the form of a data packet transmitted between two or more computer processes wherein the data packet may include video data.
- the data packet can include a metadata, e.g., associated contextual information, for example.
- the system 1100 includes a communication framework 1106 (e.g., a global communication network such as the Internet, or mobile network(s)) that can be employed to facilitate communications between the client(s) 1102 and the server(s) 1104 .
- a communication framework 1106 e.g., a global communication network such as the Internet, or mobile network(s)
- the client(s) 1102 include or are operatively connected to one or more client data store(s) 1108 that can be employed to store information local to the client(s) 1102 (e.g., associated contextual information).
- the server(s) 1104 are operatively include or are operatively connected to one or more server data store(s) 1110 that can be employed to store information local to the servers 1104 .
- a client 1102 can transfer an encoded file, in accordance with the disclosed subject matter, to server 1104 .
- Server 1104 can store the file, decode the file, or transmit the file to another client 1102 .
- a client 1102 can also transfer uncompressed file to a server 1104 and server 1104 can compress the file in accordance with the disclosed subject matter.
- server 1104 can encode video information and transmit the information via communication framework 1106 to one or more clients 1102 .
- the illustrated aspects of the disclosure may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network.
- program modules can be located in both local and remote memory storage devices.
- various components described in this description can include electrical circuit(s) that can include components and circuitry elements of suitable value in order to implement the embodiments of the subject innovation(s).
- many of the various components can be implemented on one or more integrated circuit (IC) chips.
- IC integrated circuit
- a set of components can be implemented in a single IC chip.
- one or more of respective components are fabricated or implemented on separate IC chips.
- the terms used to describe such components are intended to correspond, unless otherwise indicated, to any component which performs the specified function of the described component (e.g., a functional equivalent), even though not structurally equivalent to the disclosed structure, which performs the function in the disclosure illustrated exemplary aspects of the claimed subject matter.
- the innovation includes a system as well as a computer-readable storage medium having computer-executable instructions for performing the acts and/or events of the various methods of the claimed subject matter.
- a component may be, but is not limited to being, a process running on a processor (e.g., digital signal processor), a processor, an object, an executable, a thread of execution, a program, and/or a computer.
- a processor e.g., digital signal processor
- an application running on a controller and the controller can be a component.
- One or more components may reside within a process and/or thread of execution and a component may be localized on one computer and/or distributed between two or more computers.
- a “device” can come in the form of specially designed hardware; generalized hardware made specialized by the execution of software thereon that enables the hardware to perform specific function; software stored on a computer readable storage medium; software transmitted on a computer readable transmission medium; or a combination thereof.
- example or “exemplary” are used in this disclosure to mean serving as an example, instance, or illustration. Any aspect or design described in this disclosure as “exemplary” is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the words “example” or “exemplary” is intended to present concepts in a concrete fashion.
- the term “or” is intended to mean an inclusive “or” rather than an exclusive “or”. That is, unless specified otherwise, or clear from context, “X employs A or B” is intended to mean any of the natural inclusive permutations.
- Computer-readable storage media can be any available storage media that can be accessed by the computer, is typically of a non-transitory nature, and can include both volatile and nonvolatile media, removable and non-removable media.
- Computer-readable storage media can be implemented in connection with any method or technology for storage of information such as computer-readable instructions, program modules, structured data, or unstructured data.
- Computer-readable storage media can include, but are not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disk (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or other tangible and/or non-transitory media which can be used to store desired information.
- Computer-readable storage media can be accessed by one or more local or remote computing devices, e.g., via access requests, queries or other data retrieval protocols, for a variety of operations with respect to the information stored by the medium.
- communications media typically embody computer-readable instructions, data structures, program modules or other structured or unstructured data in a data signal that can be transitory such as a modulated data signal, e.g., a carrier wave or other transport mechanism, and includes any information delivery or transport media.
- modulated data signal or signals refers to a signal that has one or more of its characteristics set or changed in such a manner as to encode information in one or more signals.
- communication media include wired media, such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media.
Abstract
Description
F=<f 1 ,f 2 , . . . ,f N>
wherein each attribute or feature (e.g., user is active, user is A, user is B . . . , advertisement is X, advertisement is Y, . . . , user has mood X, advertisement has mood Y, etc.) is assigned a fixed position. Then scoring
F·W=S
where S is the score. The weight vector W can be designed to account for a probability that the media advertisement will be viewed past a billable point and/or a probability that the media advertisement will have a lasting impression upon the user. In an aspect, W can be generated using historical data using a machine learning algorithm.
Claims (22)
Priority Applications (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/556,802 US9712587B1 (en) | 2014-12-01 | 2014-12-01 | Identifying and rendering content relevant to a user's current mental state and context |
US15/651,232 US10481749B1 (en) | 2014-12-01 | 2017-07-17 | Identifying and rendering content relevant to a user's current mental state and context |
US16/597,307 US10963119B1 (en) | 2014-12-01 | 2019-10-09 | Identifying and rendering content relevant to a user's current mental state and context |
US17/118,068 US11372514B1 (en) | 2014-12-01 | 2020-12-10 | Identifying and rendering content relevant to a user's current mental state and context |
US17/833,061 US11861132B1 (en) | 2014-12-01 | 2022-06-06 | Identifying and rendering content relevant to a user's current mental state and context |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/556,802 US9712587B1 (en) | 2014-12-01 | 2014-12-01 | Identifying and rendering content relevant to a user's current mental state and context |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/651,232 Continuation-In-Part US10481749B1 (en) | 2014-12-01 | 2017-07-17 | Identifying and rendering content relevant to a user's current mental state and context |
Publications (1)
Publication Number | Publication Date |
---|---|
US9712587B1 true US9712587B1 (en) | 2017-07-18 |
Family
ID=59296460
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/556,802 Active 2035-08-04 US9712587B1 (en) | 2014-12-01 | 2014-12-01 | Identifying and rendering content relevant to a user's current mental state and context |
Country Status (1)
Country | Link |
---|---|
US (1) | US9712587B1 (en) |
Cited By (37)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160292158A1 (en) * | 2015-04-06 | 2016-10-06 | Netflix, Inc. | Global recommendation systems for overlapping media catalogs |
US20160357864A1 (en) * | 2015-06-05 | 2016-12-08 | Apple Inc. | Personalized music presentation templates |
US20170169531A1 (en) * | 2001-08-08 | 2017-06-15 | Geoffrey S. Lycas | Method and Apparatus for Personal Awareness and Growth |
US20170223092A1 (en) * | 2016-01-28 | 2017-08-03 | Echostar Technologies L.L.C. | Providing media content based on user state detection |
US20170228512A1 (en) * | 2016-02-05 | 2017-08-10 | Kerry Michael Albert Driscoll | Triggered responses based on real-time electroencephalography |
US20180027090A1 (en) * | 2015-02-23 | 2018-01-25 | Sony Corporation | Information processing device, information processing method, and program |
US20180069817A1 (en) * | 2015-06-22 | 2018-03-08 | Stephen Constantinides | Real time geo-social visualization platform |
US20180088752A1 (en) * | 2016-09-28 | 2018-03-29 | Button Inc. | Mobile web browser providing contextual actions based on web page content |
US20180232641A1 (en) * | 2017-02-16 | 2018-08-16 | International Business Machines Corporation | Cognitive content filtering |
US20180270283A1 (en) * | 2017-03-15 | 2018-09-20 | International Business Machines Corporation | Personalized video playback |
US20190095956A1 (en) * | 2017-09-22 | 2019-03-28 | Fujitsu Limited | Information control apparatus, information control system and information control method |
US10390084B2 (en) | 2016-12-23 | 2019-08-20 | DISH Technologies L.L.C. | Communications channels in media systems |
WO2019211220A1 (en) * | 2018-04-30 | 2019-11-07 | Koninklijke Philips N.V. | Flagging a portion of a recording for review |
US10616727B2 (en) | 2017-10-18 | 2020-04-07 | YouMap, Inc. | System and method for location-based content delivery and visualization |
US10679151B2 (en) | 2014-04-28 | 2020-06-09 | Altair Engineering, Inc. | Unit-based licensing for third party access of digital content |
US10685055B2 (en) | 2015-09-23 | 2020-06-16 | Altair Engineering, Inc. | Hashtag-playlist content sequence management |
US10764381B2 (en) | 2016-12-23 | 2020-09-01 | Echostar Technologies L.L.C. | Communications channels in media systems |
US10779016B2 (en) | 2015-05-06 | 2020-09-15 | Dish Broadcasting Corporation | Apparatus, systems and methods for a content commentary community |
US10796491B2 (en) | 2015-01-23 | 2020-10-06 | YouMap, Inc. | Virtual work of expression within a virtual environment |
US10984036B2 (en) | 2016-05-03 | 2021-04-20 | DISH Technologies L.L.C. | Providing media content based on media element preferences |
US11004117B2 (en) | 2016-06-13 | 2021-05-11 | International Business Machines Corporation | Distributing and updating advertisement |
US11037550B2 (en) | 2018-11-30 | 2021-06-15 | Dish Network L.L.C. | Audio-based link generation |
US11055294B2 (en) * | 2018-07-04 | 2021-07-06 | Sharp Kabushiki Kaisha | Communication terminal, content server, content recommendation system, control device, and control method |
US11138217B2 (en) | 2015-06-22 | 2021-10-05 | YouMap, Inc. | System and method for aggregation and graduated visualization of user generated social post on a social mapping network |
CN113518979A (en) * | 2018-12-29 | 2021-10-19 | 爱贝克思技术股份有限公司 | Video distribution system |
US11182447B2 (en) * | 2018-11-06 | 2021-11-23 | International Business Machines Corporation | Customized display of emotionally filtered social media content |
US11196826B2 (en) | 2016-12-23 | 2021-12-07 | DISH Technologies L.L.C. | Communications channels in media systems |
US11218525B2 (en) * | 2020-01-21 | 2022-01-04 | Dish Network L.L.C. | Systems and methods for adapting content delivery based on endpoint communications |
US20220020061A1 (en) * | 2020-07-14 | 2022-01-20 | At&T Intellectual Property I, L.P. | Apparatuses and methods for populating inventory associated with content items in accordance with emotionally guided placements and adaptations |
US11265687B2 (en) | 2015-06-22 | 2022-03-01 | YouMap, Inc. | Creating and utilizing map channels |
US11321328B2 (en) | 2019-07-23 | 2022-05-03 | Immersyve Holdings, LLC | System and method for customized user content |
US11341540B2 (en) | 2018-03-30 | 2022-05-24 | At&T Intellectual Property I, L.P. | Methods, systems and devices for selecting advertisements based on media profiles and advertisement profiles |
US11356817B2 (en) | 2015-06-22 | 2022-06-07 | YouMap, Inc. | System and method for location-based content delivery and visualization |
US20220215436A1 (en) * | 2021-01-07 | 2022-07-07 | Interwise Ltd. | Apparatuses and methods for managing content in accordance with sentiments |
US11707216B2 (en) * | 2016-07-21 | 2023-07-25 | Comcast Cable Communications, Llc | Recommendations based on biometric feedback from wearable device |
US11782968B2 (en) * | 2020-02-12 | 2023-10-10 | Spotify Ab | Systems and methods for providing media recommendations using contextual and sequential user embeddings |
US11799864B2 (en) | 2019-02-07 | 2023-10-24 | Altair Engineering, Inc. | Computer systems for regulating access to electronic content using usage telemetry data |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150153910A1 (en) * | 2013-12-03 | 2015-06-04 | Google Inc. | Dyanmic thumbnail representation for a video playlist |
-
2014
- 2014-12-01 US US14/556,802 patent/US9712587B1/en active Active
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150153910A1 (en) * | 2013-12-03 | 2015-06-04 | Google Inc. | Dyanmic thumbnail representation for a video playlist |
US9454289B2 (en) * | 2013-12-03 | 2016-09-27 | Google Inc. | Dyanmic thumbnail representation for a video playlist |
Cited By (64)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20170169531A1 (en) * | 2001-08-08 | 2017-06-15 | Geoffrey S. Lycas | Method and Apparatus for Personal Awareness and Growth |
US10055802B2 (en) * | 2001-08-08 | 2018-08-21 | Geoffrey S. Lycas | Method and apparatus for personal awareness and growth |
US10679151B2 (en) | 2014-04-28 | 2020-06-09 | Altair Engineering, Inc. | Unit-based licensing for third party access of digital content |
US11651575B2 (en) | 2015-01-23 | 2023-05-16 | You Map Inc. | Virtual work of expression within a virtual environment |
US10796491B2 (en) | 2015-01-23 | 2020-10-06 | YouMap, Inc. | Virtual work of expression within a virtual environment |
US11302084B2 (en) | 2015-01-23 | 2022-04-12 | Stephen Constantinides | Virtual work of expression within a virtual environment |
US20180027090A1 (en) * | 2015-02-23 | 2018-01-25 | Sony Corporation | Information processing device, information processing method, and program |
US20160292158A1 (en) * | 2015-04-06 | 2016-10-06 | Netflix, Inc. | Global recommendation systems for overlapping media catalogs |
US10885093B2 (en) | 2015-04-06 | 2021-01-05 | Netflix, Inc. | Global recommendation systems for overlapping media catalogs |
KR20180021677A (en) * | 2015-04-06 | 2018-03-05 | 넷플릭스, 인크. | Global Recommendation System for Overlapping Media Catalogs |
US10552470B2 (en) * | 2015-04-06 | 2020-02-04 | Netflix, Inc. | Global recommendation systems for overlapping media catalogs |
US11743514B2 (en) | 2015-05-06 | 2023-08-29 | Dish Broadcasting Corporation | Apparatus, systems and methods for a content commentary community |
US11356714B2 (en) | 2015-05-06 | 2022-06-07 | Dish Broadcasting Corporation | Apparatus, systems and methods for a content commentary community |
US10779016B2 (en) | 2015-05-06 | 2020-09-15 | Dish Broadcasting Corporation | Apparatus, systems and methods for a content commentary community |
US20160357864A1 (en) * | 2015-06-05 | 2016-12-08 | Apple Inc. | Personalized music presentation templates |
US10664520B2 (en) * | 2015-06-05 | 2020-05-26 | Apple Inc. | Personalized media presentation templates |
US20180069817A1 (en) * | 2015-06-22 | 2018-03-08 | Stephen Constantinides | Real time geo-social visualization platform |
US11265687B2 (en) | 2015-06-22 | 2022-03-01 | YouMap, Inc. | Creating and utilizing map channels |
US11589193B2 (en) | 2015-06-22 | 2023-02-21 | You Map Inc. | Creating and utilizing services associated with maps |
US11436619B2 (en) * | 2015-06-22 | 2022-09-06 | You Map Inc. | Real time geo-social visualization platform |
US11704329B2 (en) | 2015-06-22 | 2023-07-18 | You Map Inc. | System and method for aggregation and graduated visualization of user generated social post on a social mapping network |
US11356817B2 (en) | 2015-06-22 | 2022-06-07 | YouMap, Inc. | System and method for location-based content delivery and visualization |
US11138217B2 (en) | 2015-06-22 | 2021-10-05 | YouMap, Inc. | System and method for aggregation and graduated visualization of user generated social post on a social mapping network |
US11696097B2 (en) | 2015-06-22 | 2023-07-04 | You Map Inc. | System and method for location-based content delivery and visualization |
US10685055B2 (en) | 2015-09-23 | 2020-06-16 | Altair Engineering, Inc. | Hashtag-playlist content sequence management |
US10719544B2 (en) * | 2016-01-28 | 2020-07-21 | DISH Technologies L.L.C. | Providing media content based on user state detection |
US20170223092A1 (en) * | 2016-01-28 | 2017-08-03 | Echostar Technologies L.L.C. | Providing media content based on user state detection |
US20190205329A1 (en) * | 2016-01-28 | 2019-07-04 | DISH Technologies L.L.C. | Providing media content based on user state detection |
US10268689B2 (en) * | 2016-01-28 | 2019-04-23 | DISH Technologies L.L.C. | Providing media content based on user state detection |
US20170228512A1 (en) * | 2016-02-05 | 2017-08-10 | Kerry Michael Albert Driscoll | Triggered responses based on real-time electroencephalography |
US10803145B2 (en) * | 2016-02-05 | 2020-10-13 | The Intellectual Property Network, Inc. | Triggered responses based on real-time electroencephalography |
US20200402667A1 (en) * | 2016-02-05 | 2020-12-24 | The Intellectual Property Network, Inc. | Triggered responses to real-time electroencephalography |
US10984036B2 (en) | 2016-05-03 | 2021-04-20 | DISH Technologies L.L.C. | Providing media content based on media element preferences |
US11004117B2 (en) | 2016-06-13 | 2021-05-11 | International Business Machines Corporation | Distributing and updating advertisement |
US11100541B2 (en) * | 2016-06-13 | 2021-08-24 | International Business Machines Corporation | Distributing and updating advertisement |
US11707216B2 (en) * | 2016-07-21 | 2023-07-25 | Comcast Cable Communications, Llc | Recommendations based on biometric feedback from wearable device |
US20180088752A1 (en) * | 2016-09-28 | 2018-03-29 | Button Inc. | Mobile web browser providing contextual actions based on web page content |
US10764381B2 (en) | 2016-12-23 | 2020-09-01 | Echostar Technologies L.L.C. | Communications channels in media systems |
US11483409B2 (en) | 2016-12-23 | 2022-10-25 | DISH Technologies L.LC. | Communications channels in media systems |
US11196826B2 (en) | 2016-12-23 | 2021-12-07 | DISH Technologies L.L.C. | Communications channels in media systems |
US11659055B2 (en) | 2016-12-23 | 2023-05-23 | DISH Technologies L.L.C. | Communications channels in media systems |
US10390084B2 (en) | 2016-12-23 | 2019-08-20 | DISH Technologies L.L.C. | Communications channels in media systems |
US10958742B2 (en) * | 2017-02-16 | 2021-03-23 | International Business Machines Corporation | Cognitive content filtering |
US20180232641A1 (en) * | 2017-02-16 | 2018-08-16 | International Business Machines Corporation | Cognitive content filtering |
US20180270283A1 (en) * | 2017-03-15 | 2018-09-20 | International Business Machines Corporation | Personalized video playback |
US11012486B2 (en) * | 2017-03-15 | 2021-05-18 | International Business Machines Corporation | Personalized video playback |
US10560508B2 (en) * | 2017-03-15 | 2020-02-11 | International Business Machines Corporation | Personalized video playback |
US20190095956A1 (en) * | 2017-09-22 | 2019-03-28 | Fujitsu Limited | Information control apparatus, information control system and information control method |
US10616727B2 (en) | 2017-10-18 | 2020-04-07 | YouMap, Inc. | System and method for location-based content delivery and visualization |
US11341540B2 (en) | 2018-03-30 | 2022-05-24 | At&T Intellectual Property I, L.P. | Methods, systems and devices for selecting advertisements based on media profiles and advertisement profiles |
WO2019211220A1 (en) * | 2018-04-30 | 2019-11-07 | Koninklijke Philips N.V. | Flagging a portion of a recording for review |
US11055294B2 (en) * | 2018-07-04 | 2021-07-06 | Sharp Kabushiki Kaisha | Communication terminal, content server, content recommendation system, control device, and control method |
US11182447B2 (en) * | 2018-11-06 | 2021-11-23 | International Business Machines Corporation | Customized display of emotionally filtered social media content |
US11037550B2 (en) | 2018-11-30 | 2021-06-15 | Dish Network L.L.C. | Audio-based link generation |
CN113518979A (en) * | 2018-12-29 | 2021-10-19 | 爱贝克思技术股份有限公司 | Video distribution system |
US11843809B2 (en) * | 2018-12-29 | 2023-12-12 | Avex Technologies Inc. | Movie distribution system |
US11799864B2 (en) | 2019-02-07 | 2023-10-24 | Altair Engineering, Inc. | Computer systems for regulating access to electronic content using usage telemetry data |
US11675798B2 (en) | 2019-07-23 | 2023-06-13 | Immersyve Holdings, LLC | System and method for customized user content |
US11321328B2 (en) | 2019-07-23 | 2022-05-03 | Immersyve Holdings, LLC | System and method for customized user content |
US11799932B2 (en) | 2020-01-21 | 2023-10-24 | Dish Network L.L.C. | Systems and methods for adapting content delivery based on endpoint communications |
US11218525B2 (en) * | 2020-01-21 | 2022-01-04 | Dish Network L.L.C. | Systems and methods for adapting content delivery based on endpoint communications |
US11782968B2 (en) * | 2020-02-12 | 2023-10-10 | Spotify Ab | Systems and methods for providing media recommendations using contextual and sequential user embeddings |
US20220020061A1 (en) * | 2020-07-14 | 2022-01-20 | At&T Intellectual Property I, L.P. | Apparatuses and methods for populating inventory associated with content items in accordance with emotionally guided placements and adaptations |
US20220215436A1 (en) * | 2021-01-07 | 2022-07-07 | Interwise Ltd. | Apparatuses and methods for managing content in accordance with sentiments |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9712587B1 (en) | Identifying and rendering content relevant to a user's current mental state and context | |
US11861132B1 (en) | Identifying and rendering content relevant to a user's current mental state and context | |
US11936610B2 (en) | Privacy aligned and personalized social media content sharing recommendations | |
US11974019B2 (en) | Identifying related videos based on relatedness of elements tagged in the videos | |
US9055343B1 (en) | Recommending content based on probability that a user has interest in viewing the content again | |
US11055340B2 (en) | System and method for creating synopsis for multimedia content | |
US20180167692A1 (en) | Enhancing live video streams using themed experiences | |
US8296660B2 (en) | Content recommendation using third party profiles | |
US8255293B1 (en) | Product catalog dynamically tailored to user-selected media content | |
US9820004B1 (en) | Optimizing timing of display of a video overlay | |
US11979465B2 (en) | Recommending media content to a user based on information associated with a referral source | |
US10783157B1 (en) | Delivering a continuous feed of content items to a client device | |
US11531925B2 (en) | Optimizing content distribution using a model | |
US10620801B1 (en) | Generation and presentation of interactive information cards for a video | |
KOÇ | THE ROLE OF USER INTERACTIONS IN SOCIAL MEDIA ON RECOMMENDATION ALGORITHMS: EVALUATION OF TIKTOK'S PERSONALIZATION PRACTICES FROM USER'S PERSPECTIVE | |
US20230283849A1 (en) | Content navigation and personalization | |
Haugen | Mobile News: Design, User Experience and Recommendation | |
Lagger | User intent classification for video retrieval | |
Ngan | Nudge and persuasive design on Video on Demand Platforms: a digital enforcement effect in streaming services using design principles to influence users’ attitude and behavior as a cue for social navigation. |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ALFISHAWI, THABET;MITTAL, SAGAR;STEVENS, MARK;SIGNING DATES FROM 20141125 TO 20141201;REEL/FRAME:034289/0864 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044097/0658Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |