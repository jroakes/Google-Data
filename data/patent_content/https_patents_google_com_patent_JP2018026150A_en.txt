JP2018026150A - Detection of lane marking - Google Patents
Detection of lane marking Download PDFInfo
- Publication number
- JP2018026150A JP2018026150A JP2017187738A JP2017187738A JP2018026150A JP 2018026150 A JP2018026150 A JP 2018026150A JP 2017187738 A JP2017187738 A JP 2017187738A JP 2017187738 A JP2017187738 A JP 2017187738A JP 2018026150 A JP2018026150 A JP 2018026150A
- Authority
- JP
- Japan
- Prior art keywords
- data points
- intensity
- lane marker
- data
- section
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000001514 detection method Methods 0.000 title description 5
- 239000003550 marker Substances 0.000 claims abstract description 105
- 238000000034 method Methods 0.000 claims abstract description 40
- 238000012545 processing Methods 0.000 claims abstract description 22
- 230000015654 memory Effects 0.000 claims description 24
- 238000001914 filtration Methods 0.000 claims description 5
- 238000010586 diagram Methods 0.000 description 11
- 239000007787 solid Substances 0.000 description 7
- 230000006870 function Effects 0.000 description 6
- 238000011156 evaluation Methods 0.000 description 3
- 239000000446 fuel Substances 0.000 description 3
- 239000000463 material Substances 0.000 description 3
- 230000005540 biological transmission Effects 0.000 description 2
- 238000004891 communication Methods 0.000 description 2
- 239000003973 paint Substances 0.000 description 2
- 238000002310 reflectometry Methods 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- 230000001133 acceleration Effects 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000007423 decrease Effects 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 230000007613 environmental effect Effects 0.000 description 1
- 230000005484 gravity Effects 0.000 description 1
- 238000010606 normalization Methods 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 230000008054 signal transmission Effects 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G05—CONTROLLING; REGULATING
- G05D—SYSTEMS FOR CONTROLLING OR REGULATING NON-ELECTRIC VARIABLES
- G05D1/00—Control of position, course or altitude of land, water, air, or space vehicles, e.g. automatic pilot
- G05D1/02—Control of position or course in two dimensions
- G05D1/021—Control of position or course in two dimensions specially adapted to land vehicles
- G05D1/0231—Control of position or course in two dimensions specially adapted to land vehicles using optical position detecting means
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B60—VEHICLES IN GENERAL
- B60W—CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT
- B60W30/00—Purposes of road vehicle drive control systems not related to the control of a particular sub-unit, e.g. of systems using conjoint control of vehicle sub-units, or advanced driver assistance systems for ensuring comfort, stability and safety or drive control systems for propelling or retarding the vehicle
- B60W30/10—Path keeping
- B60W30/12—Lane keeping
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B60—VEHICLES IN GENERAL
- B60W—CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT
- B60W40/00—Estimation or calculation of non-directly measurable driving parameters for road vehicle drive control systems not related to the control of a particular sub unit, e.g. by using mathematical models
- B60W40/02—Estimation or calculation of non-directly measurable driving parameters for road vehicle drive control systems not related to the control of a particular sub unit, e.g. by using mathematical models related to ambient conditions
- B60W40/06—Road conditions
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B60—VEHICLES IN GENERAL
- B60W—CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT
- B60W60/00—Drive control systems specially adapted for autonomous road vehicles
- B60W60/001—Planning or execution of driving tasks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/10—Image acquisition
- G06V10/12—Details of acquisition arrangements; Constructional details thereof
- G06V10/14—Optical characteristics of the device performing the acquisition or on the illumination arrangements
- G06V10/145—Illumination specially adapted for pattern recognition, e.g. using gratings
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/50—Context or environment of the image
- G06V20/56—Context or environment of the image exterior to a vehicle by using sensors mounted on the vehicle
- G06V20/588—Recognition of the road, e.g. of lane markings; Recognition of the vehicle driving pattern in relation to the road
-
- B60W2420/408—
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B60—VEHICLES IN GENERAL
- B60Y—INDEXING SCHEME RELATING TO ASPECTS CROSS-CUTTING VEHICLE TECHNOLOGY
- B60Y2300/00—Purposes or special features of road vehicle drive control systems
- B60Y2300/10—Path keeping
- B60Y2300/12—Lane keeping
Abstract
Description
関連出願の相互参照
本出願は、２０１２年３月２３日に出願された米国特許出願第１３／４２７，９６４号の継続出願であり、その開示は参照により本明細書に組み込まれる。
CROSS REFERENCE TO RELATED APPLICATIONS This application is a continuation of US Patent Application No. 13 / 427,964, filed March 23, 2012, the disclosure of which is incorporated herein by reference.
自律車両は、ある場所から別の場所への搭乗者の輸送を補助するために、さまざまなコンピューティング・システムを使用している。いくつかの自律車両では、パイロット、運転手、または搭乗者等の操作者からの初期入力又は連続入力が必要な場合がある。他の自律システムでは、例えば自動操縦システムの場合、そのようなシステムが操作可能状態にある場合のみ使用することができ、それにより操作者は手動モード（操作者が車両の動きを密にコントロールする場合）から自律モード（本質的には車両が自身で運転する）、その間の中間的なモードに移ることが許される。 Autonomous vehicles use a variety of computing systems to assist passengers in transporting from one location to another. Some autonomous vehicles may require initial or continuous input from an operator such as a pilot, driver, or passenger. In other autonomous systems, for example in the case of an autopilot system, it can only be used when such a system is in an operable state, so that the operator can control the movement of the vehicle in manual mode. ) To autonomous mode (essentially the vehicle is driving by itself) and to an intermediate mode in between.
このような車両は、周囲の物体を検出するために通常様々な種類のセンサーを備えている。例えば、自律車両は、車両の周囲からのデータをスキャンし記録するレーザー、音波探知機、レーダー、カメラ、及び他のデバイスを含み得る。１つ又は複数のこれらのデバイスからのセンサーデータは、複数の物体及びこれらのそれぞれの特性（位置、形状、方位、速度等）を検出するために使用され得る。この検出及び識別は、自律車両の安全運転のための重要な機能である。 Such vehicles are usually equipped with various types of sensors to detect surrounding objects. For example, autonomous vehicles may include lasers, sound detectors, radars, cameras, and other devices that scan and record data from around the vehicle. Sensor data from one or more of these devices can be used to detect multiple objects and their respective characteristics (position, shape, orientation, velocity, etc.). This detection and identification is an important function for safe driving of autonomous vehicles.
いくつかの自律走行システムにおいては、レーンマーカ等の機能は、自律走行システムによって無視されている。このレーンマーカが無視されると、自律車両は、地図情報と地理的位置の推定に一層深く依存して自身を操縦するようになり得る。これは、地図情報が利用できないか、不完全か、又は不正確であるような地域では、有用でないこともあり得る。 In some autonomous traveling systems, functions such as lane markers are ignored by the autonomous traveling system. If this lane marker is ignored, the autonomous vehicle may steer itself depending more deeply on the map information and the geographical location estimation. This may not be useful in areas where map information is not available, incomplete, or inaccurate.
リアルタイムでそのような情報を処理し運転の意思決定を行う必要のないシステムのようないくつかの非リアルタイムのシステムでは、レーンマーカを識別するのにカメラを使用し得る。例えば、地図作成者は、車線境界線を識別するのにカメラ画像を使用し得る。これは、１つ又は複数のカメラ画像に描かれた車線の境界等の視覚的な路面表示を検出するために画像を処理することを伴い得る。しかし、カメラ画像の品質は、画像がキャプチャされるときの照明状態に依存する。加えて、カメラ画像は、画像にある物体の地理的位置を決定するために、地面に投影するか又は他の画像と比較されなければならない。 In some non-real-time systems, such as systems that do not need to process such information and make driving decisions in real time, a camera may be used to identify lane markers. For example, a cartographer may use camera images to identify lane boundaries. This may involve processing the image to detect visual road surface indications, such as lane boundaries drawn in one or more camera images. However, the quality of the camera image depends on the lighting conditions when the image is captured. In addition, the camera image must be projected onto the ground or compared with other images to determine the geographical location of the object in the image.
１つの本開示の態様は方法を提供する。前記方法は、道路に対して収集されたスキャンデータにアクセスするステップを含む。前記スキャンデータは、物体の位置情報と強度情報を有する複数のデータポイントを含む。前記方法は、前記複数のデータポイントを複数のセクションに分割するステップと、各セクションに対して、閾値強度を特定するステップと、前記特定のデータポイントの前記強度値を前記特定のデータポイントの前記セクションの閾値強度の値と比較することにより、前記複数のデータポイントの特定のデータポイントのそれぞれを評価することにより、プロセッサーが前記複数のデータポイントからレーンマーカのデータポイントの集合を生成するステップと、後に使用するために前記レーンマーカのデータポイントの集合を記憶するステップと、をも含む。 One aspect of the present disclosure provides a method. The method includes accessing scan data collected for a road. The scan data includes a plurality of data points having object position information and intensity information. The method includes dividing the plurality of data points into a plurality of sections, identifying a threshold intensity for each section, and determining the intensity value of the particular data point from the particular data point. Generating a set of lane marker data points from the plurality of data points by evaluating each particular data point of the plurality of data points by comparing to a threshold intensity value of the section; and Storing a set of data points of the lane marker for later use.
一例では、前記レーンマーカのデータポイントの集合を生成するステップは、前記道路の閾値標高の範囲内にある位置を有する前記複数のデータポイントから成るデータポイントを選択することをさらに含む。さらに他の例では、前記複数のデータポイントを複数のセクションに分割するステップは、固定数のデータポイントを処理することを含む。さらなる例では、前記複数のデータポイントを複数のセクションに分割するステップは、レーザーによりスキャンされる領域をセクションに分割することを含む。さらなる例では、前記方法は、前記レーンマーカのデータポイントの集合を記憶する前に、前記レーンマーカのデータポイントの集合とレーンマーカのモデルとの比較に基づいて、前記レーンマーカのデータポイントの集合にフィルタをかけることをさらに備える。他の例では、前記方法は、前記レーンマーカのデータポイントの集合を記憶する前に、前記レーンマーカのデータポイントの集合に含まれるデータポイントの集団を識別することに基づいて前記レーンマーカのデータポイントの集合にフィルタをかけることをさらに備える。さらに他の例では、前記方法は、前記レーンマーカのデータポイントの集合を記憶する前に、前記レーザースキャンデータを受け取ったときのレーザーの位置に基づいて前記レーンマーカのデータポイントの集合にフィルタをかけることをさらに備える。さらなる例では、前記方法は、前記レーンマーカのデータポイントの集合を使用して自律車両をリアルタイムに動作させるステップをさらに備える。さらなる例では、前記方法は、前記レーンマーカのデータポイントの集合を使用して地図情報を生成するステップをさらに備える。 In one example, generating the set of data points for the lane marker further includes selecting a data point comprised of the plurality of data points having a position that is within a threshold elevation of the road. In yet another example, dividing the plurality of data points into a plurality of sections includes processing a fixed number of data points. In a further example, dividing the plurality of data points into sections includes dividing an area scanned by the laser into sections. In a further example, the method filters the set of lane marker data points based on a comparison of the set of lane marker data points and a lane marker model before storing the set of lane marker data points. It is further provided. In another example, the method is configured to identify a set of data points for the lane marker based on identifying a set of data points included in the set of lane marker data points before storing the set of data points for the lane marker. Further comprising filtering. In yet another example, the method filters the set of lane marker data points based on the position of the laser when receiving the laser scan data before storing the set of lane marker data points. Is further provided. In a further example, the method further comprises operating an autonomous vehicle in real time using the set of lane marker data points. In a further example, the method further comprises generating map information using the set of data points of the lane marker.
他の例では、前記スキャンデータは複数のビームを有するレーザーを使用して収集され、アクセスされたスキャンデータは前記複数のビームの第１のビームに関係付けられる。この例の方法は、さらに前記複数のビームの第２のビームに関係付けられる第２のスキャンデータにアクセスするステップであって、第２のスキャンデータは物体における位置及び強度情報を有する第２の複数のデータポイントを含む、ステップと、第２の複数のデータポイントを第２の複数のセクションに分割するステップと、各第２のセクションについて、そのセクションについて前記データポイントを評価してそれぞれの平均強度とそれぞれの強度の標準偏差を決定するステップと、各第２のセクションについて、それぞれの平均強度及び前記それぞれの強度の標準偏差に基づいて閾値強度を決定するステップと、前記特定のデータポイントの前記強度値をその特定のデータポイントの前記第２のセクションの閾値強度の値と比較することにより、第２の複数のデータポイントの特定のデータポイントのそれぞれを評価することにより、その複数のデータポイントからレーンマーカのデータポイントの第２の集合を生成するステップと、後の使用のためにレーンマーカのデータポイントの前記第２の集合を記憶するステップとをさらに備える。 In another example, the scan data is collected using a laser having a plurality of beams, and the accessed scan data is related to a first beam of the plurality of beams. The example method further includes accessing second scan data associated with a second beam of the plurality of beams, wherein the second scan data includes position and intensity information on the object. Including a plurality of data points; dividing a second plurality of data points into a second plurality of sections; and for each second section, evaluating the data points for that section and averaging each Determining an intensity and a standard deviation of each intensity; determining, for each second section, a threshold intensity based on the respective average intensity and the standard deviation of the respective intensity; and Compare the intensity value with the threshold intensity value of the second section of that particular data point Generating a second set of lane marker data points from the plurality of data points by evaluating each particular data point of the second plurality of data points; and for later use Storing the second set of lane marker data points.
他の例では、前記方法は、各セクションについて、前記セクションの前記データポイントを評価して、それぞれの平均強度とそれぞれの強度の標準偏差を決定するステップをさらに含む。この例では、前記所与のセクションに対して閾値強度を特定するステップは、所与のセクションについてのそれぞれの平均強度と前記それぞれの強度の標準偏差に基づく。この例では、所与のセクションについて閾値強度を特定するステップは、それぞれの標準偏差に所定の値を乗算し、前記それぞれの平均強度値を加算することを含む。他の例では、前記セクションについての前記閾値強度を特定するステップは、単一の閾値標準偏差の値にアクセスすることを含む。 In another example, the method further includes, for each section, evaluating the data points of the section to determine a respective mean intensity and a standard deviation of each intensity. In this example, the step of identifying a threshold intensity for the given section is based on the respective average intensity for the given section and the standard deviation of the respective intensity. In this example, identifying the threshold intensity for a given section includes multiplying each standard deviation by a predetermined value and adding the respective average intensity values. In another example, identifying the threshold strength for the section includes accessing a single threshold standard deviation value.
他の本開示の態様は、デバイスを提供する。このデバイスは、レーンマーカのデータポイントの集合を記憶するメモリを含む。このデバイスは、前記メモリに接続されたプロセッサーをも含む。このプロセッサーは、道路について収集されたスキャンデータにアクセスし、該スキャンデータは、物体の位置情報と強度情報を有する複数のデータポイントを含み、この複数のデータポイントを複数のセクションに分割し、各セクションについて、閾値強度を特定し、前記特定のデータポイントの強度値をこの特定のデータポイントの前記セクションの閾値強度の値と比較して、前記複数のデータポイントの特定のデータポイントのそれぞれを評価することにより、前記複数のデータポイントからレーンマーカのデータポイントの集合を生成し、後の使用のために前記レーンマーカのデータポイントの集合をメモリに記憶するように構成される。 Another aspect of the present disclosure provides a device. The device includes a memory that stores a set of lane marker data points. The device also includes a processor connected to the memory. The processor accesses scan data collected for a road, the scan data including a plurality of data points having object location information and intensity information, dividing the plurality of data points into sections, For a section, identify a threshold strength and compare the strength value of the particular data point with the threshold strength value of the section for the particular data point to evaluate each particular data point of the plurality of data points By doing so, a set of lane marker data points is generated from the plurality of data points, and the set of lane marker data points is stored in a memory for later use.
一例では、前記プロセッサーは、道路の閾値標高の範囲内に位置する前記複数のデータポイントから成るデータポイントを選択することにより、前記レーンマーカのデータポイントの集合を生成するようにさらに構成される。さらに別の例では、前記プロセッサーは、固定数のデータポイントを処理することにより前記複数のデータポイントを複数のセクションに分割する。さらなる例では、前記プロセッサーが前記複数のデータポイントを複数のセクションに分割することは、スキャンされる領域を複数のセクションに分割することを含む。さらに別の例では、前記プロセッサーは、前記レーンマーカのデータポイントの集合を記憶する前に、前記レーンマーカのデータポイントの集合とレーンマーカのモデルとの比較に基づいて前記レーンマーカのデータポイントの集合にフィルタをかける。別な例では、前記プロセッサーは、前記レーンマーカのデータポイントの集合を記憶する前に、前記レーンマーカのデータポイントの集合におけるデータポイントの集団を特定することに基づいて、前記レーンマーカのデータポイントの集合にフィルタをかける。さらなる例では、前記プロセッサーは、前記レーンマーカのデータポイントの集合を記憶する前に、前記レーザースキャンデータを受け取ったときの前記レーザーの前記位置に基づいて前記レーンマーカのデータポイントの集合にフィルタをかける。さらなる例では、前記プロセッサーは、前記レーンマーカのデータポイントの集合を使用して自律車両をリアルタイムに動作させる。別な例では、前記プロセッサーは、前記レーンマーカのデータポイントの集合を使用して地図情報を生成する。さらに別の例では、前記プロセッサーは、各セクションについて、前記セクションの前記データポイントを評価して、それぞれの平均強度とそれぞれの強度の標準偏差を決定するよう構成される。この例では、前記プロセッサーは、前記所与のセクションについてそれぞれの平均強度とそれぞれの強度の標準偏差に基づいて、前記所与のセクションについて前記閾値強度を特定するようにさらに構成される。この例では、前記プロセッサーは、前記それぞれの標準偏差に所定の値を乗算し前記それぞれの平均強度値を加算することによって、所与のセクションについて前記閾値強度を特定するようにさらに構成される。他の例では、前記プロセッサーは、単一の閾値標準偏差の値にアクセスすることにより、前記セクションについての前記閾値強度を特定するようにさらに構成される。 In one example, the processor is further configured to generate a set of data points for the lane marker by selecting a data point consisting of the plurality of data points located within a road threshold elevation. In yet another example, the processor divides the plurality of data points into sections by processing a fixed number of data points. In a further example, dividing the plurality of data points into a plurality of sections includes dividing a region to be scanned into a plurality of sections. In yet another example, the processor filters the set of lane marker data points based on a comparison of the set of lane marker data points and a lane marker model before storing the set of lane marker data points. Call. In another example, the processor may store the set of data points of the lane marker based on identifying a set of data points in the set of data points of the lane marker before storing the set of data points of the lane marker. Apply a filter. In a further example, the processor filters the set of lane marker data points based on the position of the laser when the laser scan data is received before storing the set of lane marker data points. In a further example, the processor operates the autonomous vehicle in real time using the set of data points of the lane marker. In another example, the processor generates map information using a set of data points for the lane marker. In yet another example, the processor is configured to, for each section, evaluate the data points of the section to determine a respective average intensity and a standard deviation of each intensity. In this example, the processor is further configured to identify the threshold intensity for the given section based on the respective average intensity and the standard deviation of each intensity for the given section. In this example, the processor is further configured to identify the threshold intensity for a given section by multiplying the respective standard deviation by a predetermined value and adding the respective average intensity values. In another example, the processor is further configured to identify the threshold strength for the section by accessing a single threshold standard deviation value.
さらに本開示の態様は、コンピュータが読み取り可能なプログラムの命令が記憶される有形のコンピュータ可読媒体を提供する。前記命令がプロセッサーにより実行されるときに、前記命令に起因して前記プロセッサーは方法を実行する。前記方法は、道路について収集されたスキャンデータにアクセスするステップであって、前記スキャンデータは物体の位置情報と強度情報を有する複数のデータポイントを含む前記ステップと、前記複数のデータポイントを複数のセクションに分割するステップと、各セクションについて、前記セクションの前記データポイントを評価して、それぞれの平均強度とそれぞれの強度の標準偏差を決定するステップと、各セクションについて、前記それぞれの平均強度と前記それぞれの強度の標準偏差に基づいて閾値強度を決定するステップと、前記特定のデータポイントの前記強度値を前記特定のデータポイントの前記セクションの前記閾値強度値と比較することにより、前記複数のデータポイントの特定のデータポイントのそれぞれを評価し、それにより前記複数のデータポイントからレーンマーカのデータポイントの集合を生成するステップと、後に使用するために前記レーンマーカのデータポイントの集合を前記メモリに記憶するステップと、を含む。 Furthermore, aspects of the present disclosure provide a tangible computer readable medium having stored thereon computer readable program instructions. When the instruction is executed by the processor, the processor executes the method due to the instruction. The method includes accessing scan data collected for a road, the scan data including a plurality of data points having position information and intensity information of an object, and the plurality of data points to a plurality of data points. Dividing into sections; for each section, evaluating the data points of the section to determine a respective mean intensity and a standard deviation of each intensity; for each section, the respective mean intensity and the Determining a threshold intensity based on a standard deviation of each intensity; and comparing the intensity value of the specific data point with the threshold intensity value of the section of the specific data point. Evaluate each specific data point of the point Thereby comprising the steps of: storing a set of data points of the lane marker in the memory for use in step and, after generating a set of data points of lane markers from the plurality of data points.
本開示の一態様では、複数のレーザービームからの複数のデータポイントを含むレーザースキャンデータは、道路に沿ってレーザーを動かすことにより収集することができる。このデータポイントは、レーザー光が反射する物体についての強度と位置情報を表わし得る。各レーザーのビームは、複数のデータポイントのうちのデータポイントの部分集合のそれぞれに関連付けられ得る。 In one aspect of the present disclosure, laser scan data including multiple data points from multiple laser beams can be collected by moving the laser along a road. This data point may represent intensity and position information about the object that the laser light reflects. Each laser beam may be associated with a respective subset of the data points of the plurality of data points.
単一のビームに対して、データポイントの各部分集合は、複数のセクションに分割し得る。各セクションについて、それぞれの平均強度とそれぞれの強度の標準偏差が決定され得る。各セクションについて、閾値強度がそれぞれの平均強度とそれぞれの強度の標準偏差に基づいて決定され得る。これは、そのレーザーの他のビームに対しても繰り返され得る。 For a single beam, each subset of data points may be divided into multiple sections. For each section, the respective average intensity and the standard deviation of each intensity can be determined. For each section, a threshold intensity may be determined based on the respective average intensity and the standard deviation of each intensity. This can be repeated for other beams of the laser.
複数のデータポイントからレーンマーカのデータポイントの集合が生じ得る。このことは、複数のデータポイントのそれぞれが道路の閾値標高内にあるかどうかを決定するためにデータポイントのそれぞれを評価し、及びデータポイントのそれぞれのセクションについてデータポイントの強度値を閾値強度値と比較することにより行うことを含み得る。レーンマーカのデータポイントの集合は後の使用のためにメモリに記憶することができ、または別の方法でさらなる処理のために、例えば、自律車両に利用可能になり得る。 A set of lane marker data points may result from a plurality of data points. This evaluates each of the data points to determine whether each of the plurality of data points is within the threshold elevation of the road, and the intensity value of the data points for each section of the data points Can be done by comparing to. The set of lane marker data points can be stored in a memory for later use, or otherwise made available to an autonomous vehicle, for example, for further processing.
図１に示されるように、本開示の一態様における自律走行システム１００は、様々なコンポーネントを有する車両１０１を含む。本開示のある態様は特定の種類の車両に関して特に有用である一方、この車両は、自動車、トラック、オートバイ、バス、ボート、飛行機、ヘリコプター、芝刈り機、レクリエーショナル・ビークル（ＲＶ車）、遊園地の乗り物、路面電車、ゴルフカート、電車、トロリーなどを含む任意のタイプの車両であってもよく、しかもこれらに限られない。この車両は、プロセッサー１２０、メモリ１３０及び汎用コンピュータに通常存在する他のコンポーネントを含むコンピュータ１１０等の１つ又は複数のコンピュータを有し得る。 As shown in FIG. 1, an autonomous traveling system 100 according to an aspect of the present disclosure includes a vehicle 101 having various components. While certain aspects of the present disclosure are particularly useful with certain types of vehicles, such vehicles may be automobiles, trucks, motorcycles, buses, boats, airplanes, helicopters, lawn mowers, recreational vehicles (RV vehicles), amusement parks It may be any type of vehicle including, but not limited to, vehicles, trams, golf carts, trains, trolleys, and the like. The vehicle may have one or more computers, such as computer 110, including processor 120, memory 130, and other components typically present in general purpose computers.
メモリ１３０は、プロセッサー１２０により実行されまたは別の方法で使用され得る命令１３２及びデータ１３４を含め、プロセッサー１２０によりアクセス可能な情報を記憶する。メモリ１３０は、コンピュータ−可読媒体、又はハードディスクドライブ、メモリカード、ＲＯＭ、ＲＡＭ、ＤＶＤもしくは他の光ディスク、同様に他の書き込み可能もしくは読取可能メモリ等の電子デバイスを用いて読取可能なデータを記憶する他の媒体を含め、プロセッサーによりアクセス可能な情報を記憶する能力のあるどのような種類のものでもよい。システム及び方法は、上述のものと異なる組み合わせを含み得る。そして命令及びデータの異なる部分が異なる種類の媒体に記憶され得る。 Memory 130 stores information accessible by processor 120, including instructions 132 and data 134 that may be executed by processor 120 or otherwise used. Memory 130 stores data readable using a computer-readable medium or electronic device such as a hard disk drive, memory card, ROM, RAM, DVD or other optical disk, as well as other writable or readable memory. Any type capable of storing information accessible by the processor, including other media. The system and method may include different combinations than those described above. Different portions of instructions and data can then be stored on different types of media.
命令１３２は、プロセッサーにより直接的に（機械コード等）又は間接的に（スクリプト等）実行されるべき命令の任意の集合であり得る。例えば、命令は、コンピュータ−可読媒体にコンピュータコードとして記憶され得る。その点に関して、用語「命令」と用語「プログラム」とはここでは同じ意味で使われ得る。命令は、プロセッサーにより直接処理するためにオブジェクトコード形式で、又は要求に応じて解釈されもしくは前もってコンパイルされる独立したソースコードモジュールの集まりもしくはスクリプトを含む他の任意のコンピュータ言語により記憶され得る。命令の機能、方法及び動作は、以下により詳細に説明される。 The instructions 132 may be any set of instructions that are to be executed directly (such as machine code) or indirectly (such as a script) by the processor. For example, the instructions may be stored as computer code on a computer-readable medium. In that regard, the term “instruction” and the term “program” may be used interchangeably herein. The instructions may be stored in object code form for direct processing by the processor or in any other computer language including a collection of independent source code modules or scripts that are interpreted or pre-compiled on demand. The function, method and operation of the instructions are described in more detail below.
データ１３４は、命令１３２にしたがってプロセッサー１２０により、読み出され、書き込まれ、又は修正され得る。例えば、システム及び方法は、どのような特定のデータ構造にも限定されるものではないが、このデータは、コンピュータ・レジスタに、複数の異なるフィールド及びレコードを有するテーブル、ＸＭＬドキュメント又はフラットファイルとしてリレーショナル・データベースに記憶され得る。このデータは、任意のコンピュータ可読フォーマットでもフォーマットされ得る。さらなるほんの一例として、画像データは、圧縮されたもしくは圧縮されない、無損失の（例えば、ＢＭＰ）もしくは損失を伴う（例えば、ＪＰＥＧ）、及びビットマップもしくはベクターベースの（例えば、ＳＶＧ）、及びグラフィックスを描くためのコンピュータ命令のフォーマットにより保存される画素の格子からなるビットマップとして記憶され得る。このデータは、数、説明文、専用コード、同じメモリの他の領域もしくは異なるメモリ（他のネットワークの場所を含む）に記憶されたデータの参照、又は関連のあるデータを算出する機能により使用される情報等の関連のある情報を識別するのに十分などのような情報をも備え得る。 Data 134 may be read, written, or modified by processor 120 according to instructions 132. For example, the system and method are not limited to any particular data structure, but this data can be relational as a table, XML document or flat file with multiple different fields and records in a computer register. Can be stored in a database This data may be formatted in any computer readable format. By way of further example, image data may be compressed or uncompressed, lossless (eg, BMP) or lossy (eg, JPEG), and bitmap or vector-based (eg, SVG), and graphics Can be stored as a bitmap consisting of a grid of pixels stored in a format of computer instructions for drawing. This data is used by numbers, descriptions, dedicated codes, references to data stored in other areas of the same memory or in different memories (including other network locations), or functions that calculate relevant data Information such as sufficient to identify relevant information such as
プロセッサー１２０は、市販のＣＰＵ等の任意の従来のプロセッサーであり得る。あるいは、プロセッサーは、ＡＳＩＣ等の専用デバイスでもよい。図１は、プロセッサー、メモリ、及び同じブロック内にあるコンピュータ１１０の他の要素を機能的に示しているが、このプロセッサー及びメモリは、同じ物理的ハウジング内に格納されてもよく格納されなくてもよい複数のプロセッサー及びメモリを実際に備え得ることが理解されたい。例えば、メモリは、コンピュータ１１０のハウジングとは異なるハウジングに位置するハードディスクドライブ又は他の記憶媒体でもよい。したがって、プロセッサー又はコンピュータの言及は、並列に動作し得る又は並列に動作しないプロセッサー又はコンピュータ又はメモリの集合体の言及を含むと理解されたい。ここで説明するステップを実行するために単一のプロセッサーを使用するのではなく、操舵装置や減速装置等のコンポーネントのいくつかは、それぞれそのコンポーネントの特定の機能に関係する計算を実行するのみの独自のプロセッサーを有し得る。 The processor 120 can be any conventional processor such as a commercially available CPU. Alternatively, the processor may be a dedicated device such as an ASIC. Although FIG. 1 functionally illustrates the processor, memory, and other elements of the computer 110 that are in the same block, the processor and memory may or may not be stored in the same physical housing. It should be understood that multiple processors and memories may actually be provided. For example, the memory may be a hard disk drive or other storage medium located in a different housing than the computer 110 housing. Thus, reference to a processor or computer should be understood to include a reference to a collection of processors or computers or memory that may or may not operate in parallel. Rather than using a single processor to perform the steps described here, some of the components, such as steering and reduction gears, only perform calculations related to the particular function of that component. You can have your own processor.
ここに説明する様々な態様では、プロセッサーは、その車両から離れた場所に位置することができ、車両と無線で通信し得る。他の態様では、ここで説明する処理のいくつかは、車両内に配置されるプロセッサーで実行され得る一方、他の処理は、単一の手順を実行するのに必要なステップを取ることを含め、遠隔プロセッサーにより実行される。 In various aspects described herein, the processor can be located remotely from the vehicle and can communicate wirelessly with the vehicle. In other aspects, some of the processes described herein may be performed by a processor located in the vehicle, while other processes include taking the steps necessary to perform a single procedure. Executed by the remote processor.
コンピュータ１１０は、中央処理装置（ＣＰＵ）、ウェブブラウザ等のデータ１３４及び命令を記憶するメモリ（例えば、ＲＡＭ及び内蔵ハードディスクドライブ）、電子的ディスプレイ１４２（例えば、画面を有するモニター、小型ＬＣＤタッチスクリーン又は情報を表示するように動作する他の任意の電子デバイス）、ユーザ入力１４０（例えば、マウス、キーボード、タッチスクリーン及び／またはマイクロフォン）、及び人の状態や願望についての明示的な（例えば、身ぶり手ぶり）又は暗黙的な（例えば、「その人は眠っている」）情報を集める様々なセンサー（例えば、ビデオカメラ）等のコンピュータに関して通常使用されるコンポーネントの全てを含み得る。 The computer 110 may be a central processing unit (CPU), data 134 such as a web browser and memory for storing instructions (eg, RAM and internal hard disk drive), an electronic display 142 (eg, a monitor with a screen, a small LCD touch screen, or Any other electronic device that operates to display information), user input 140 (eg, mouse, keyboard, touch screen and / or microphone), and explicit (eg, gesturing hands) about a person's condition or desire It may include all of the components commonly used for computers, such as various sensors (eg, video cameras) that collect information (eg, “bright”) or implicit (eg, “the person is asleep”).
一例では、コンピュータ１１０は、車両１０１に組み込まれた自律走行コンピューティングシステムであり得る。図２は、自律車両の内部の例示的なデザインを示している。自律車両は、例えば、ハンドル２１０等の操舵装置、ナビゲーションディスプレイ２１５等のナビゲーションディスプレイ装置、及び変速装置２２０等のギアセレクタ装置、等の非自律車両の全ての特徴を含み得る。車両は、１つ又は複数の自律走行モードをアクティブ化又は非アクティブ化し、運転者又は搭乗者２９０にナビゲーションの目的地等の情報を自律走行コンピュータ１１０に提供させることを可能とする変速装置２２０、タッチスクリーン２１７、又はボタン入力２１９等の様々なユーザ入力デバイスを有し得る。 In one example, the computer 110 may be an autonomous running computing system incorporated in the vehicle 101. FIG. 2 shows an exemplary design inside the autonomous vehicle. An autonomous vehicle can include all the features of a non-autonomous vehicle, such as a steering device such as a handle 210, a navigation display device such as a navigation display 215, and a gear selector device such as a transmission 220. A vehicle 220 that activates or deactivates one or more autonomous travel modes and allows the driver or passenger 290 to provide information such as a navigation destination to the autonomous travel computer 110, Various user input devices such as touch screen 217 or button input 219 may be included.
車両１０１は、１つ又は複数の追加のディスプレイをも含み得る。例えば、車両は、自律車両又はそのコンピュータの状態に関する情報を表示するディスプレイ２２５を含み得る。他の例においては、車両は、車両１０１の現在の状態を示すためにステータス・バー２３０等のステータス表示装置を含み得る。図２の例では、ステータス・バー２３０は、「この車両は現在ドライブモードにあり毎時２マイルで走行中である」ことを示す「Ｄ」及び「２ｍｐｈ」を表示する。この点に関して、車両は、電子ディスプレイにテキストを表示し、ハンドル２１０等の車両１０１の一部を発光させ、又は他の様々な種類の表示を提供し得る。 The vehicle 101 may also include one or more additional displays. For example, the vehicle may include a display 225 that displays information regarding the state of the autonomous vehicle or its computer. In other examples, the vehicle may include a status display device such as a status bar 230 to indicate the current state of the vehicle 101. In the example of FIG. 2, the status bar 230 displays “D” and “2 mph” indicating that “this vehicle is currently in drive mode and is traveling at 2 mph”. In this regard, the vehicle may display text on an electronic display, cause a portion of the vehicle 101, such as the handle 210, to illuminate, or provide various other types of displays.
自律走行コンピューティングシステムは、車両の様々なコンポーネントと通信する能力を有し得る。例えば、図１に戻ると、コンピュータ１１０は、車両１０１の動き、速度等を制御するために、車両の標準的な中央処理装置１６０と通信することができ、車両１０１の様々なシステム（例えばブレーキシステム１８０、加速システム１８２、信号伝達システム１８４、及びナビゲーションシステム１８６）と情報の送受信ができる。加えて、コンピュータ１１０は、それが操作可能状態にあるとき、車両１０１のこれらの機能のいくつか又は全てを制御し得るので、したがって全てが又は単に部分的に自律的であり得る。様々なシステム及びコンピュータ１１０が車両１０１の中で示されているが、これらの要素は、車両１０１の外部にあってもよく、又は物理的に長い距離を離れていても良いと理解される。 An autonomous running computing system may have the ability to communicate with various components of the vehicle. For example, returning to FIG. 1, the computer 110 can communicate with the vehicle's standard central processing unit 160 to control the movement, speed, etc. of the vehicle 101 and various systems (eg, brakes) of the vehicle 101. System 180, acceleration system 182, signal transmission system 184, and navigation system 186) can send and receive information. In addition, the computer 110 may control some or all of these functions of the vehicle 101 when it is in an operable state, and thus all or may be only partially autonomous. Although various systems and computers 110 are shown in the vehicle 101, it is understood that these elements may be external to the vehicle 101 or may be physically separated by long distances.
車両は、デバイスの地理的位置を決定するためにコンピュータ１１０と通信する地理的位置コンポーネント１４４をも含み得る。例えば、位置コンポーネントは、デバイスの緯度、経度及び／または高度の位置を決定するためにＧＰＳ受信機を含み得る。レーザーベースの位置推定システム、慣性支援ＧＰＳ、又はカメラベースの位置推定等の他の位置システムも、車両の位置を識別するのに使用され得る。車両の位置には、緯度、経度、高度等の絶対的な地理的位置、及び絶対的な地理的位置よりも少ないノイズで決定できることが多いその車両の周囲直近の他の車に対する位置等の相対的な位置情報が含まれ得る。 The vehicle may also include a geographic location component 144 that communicates with the computer 110 to determine the geographic location of the device. For example, the location component may include a GPS receiver to determine the latitude, longitude, and / or altitude location of the device. Other position systems such as laser-based position estimation systems, inertial assistance GPS, or camera-based position estimation can also be used to identify the position of the vehicle. The position of the vehicle is relative to the absolute geographical position such as latitude, longitude, altitude, etc., and relative to other vehicles in the immediate vicinity of the vehicle, which can often be determined with less noise than the absolute geographical position. Location information may be included.
車両は、車両の方向及び速度又はそれに対する変化を決定するためにコンピュータ１１０と通信する加速度計、ジャイロスコープ又は他の方向／速度検出デバイス１４６等の他の構成も含み得る。ほんの一例として、デバイス１４６は、重力方向又はそれに垂直な平面方向に対するそのピッチ、ヨー又はロール（又はこれらの変化）を決定し得る。このデバイスは、速度の増加または減少及びこのような変化の方向を追跡もし得る。このデバイスによるここに記載された位置及び方向のデータの提供は、ユーザ、コンピュータ１１０、他のコンピュータ及び上述の組み合わせに対して自動的になされ得る。 The vehicle may also include other configurations such as an accelerometer, gyroscope or other direction / speed detection device 146 that communicates with the computer 110 to determine the direction and speed of the vehicle or changes thereto. By way of example only, device 146 may determine its pitch, yaw or roll (or variations thereof) relative to the direction of gravity or a plane direction perpendicular thereto. The device may also track speed increases or decreases and the direction of such changes. The provision of the position and orientation data described herein by this device can be made automatically to the user, computer 110, other computers, and combinations of the above.
コンピュータは、様々なコンポーネントを制御することにより、車両の方向及び速度を制御し得る。一例として、もし、車両が完全な自律モードで動作しているなら、コンピュータ１１０は、車両を加速させ（例えば、エンジンに供給される燃料又は他のエネルギーを増加させることにより）、減速させ（例えば、エンジンに供給される燃料を減少させること又はブレーキをかけることにより）、及び方向を変化させ得る（例えば、前２輪の向きを変えることにより）。 The computer can control the direction and speed of the vehicle by controlling various components. As an example, if the vehicle is operating in a fully autonomous mode, the computer 110 may accelerate the vehicle (eg, by increasing fuel or other energy supplied to the engine) and decelerate (eg, by , By reducing the fuel supplied to the engine or by applying a brake), and changing the direction (eg by changing the direction of the front two wheels).
車両は、他の車両、道路にある障害物、交通信号、標識、樹木等の車両の外部の物体を検出するコンポーネントを含み得る。検出システムは、レーザー、音波探知機、レーダー、カメラ又はコンピュータ１１０により処理され得るデータを記録する他の任意の検出デバイスを含み得る。例えば、もし車両が小型乗用車であれば、この乗用車は、屋根又は他の便利な位置に取り付けられるレーザーを含み得る。図３Ａに示されるように、車両１０１は、小型乗用車であり得る。この例では、車両１０１のセンサーは、車両の前部と屋根にそれぞれ取り付けられるレーザー３１０、３１１を含み得る。レーザーは、ＶｅｌｏｄｙｎｅＨＤＬ−６４、又は他のモデル等の市販のレーザーを含み得る。レーザーは、１つ以上のレーザービームを含み得る。例えば、ＶｅｌｏｄｙｎｅＨＤＬ−６４レーザーは、６４ビームを含み得る。一例では、レーザー３１０のビームは、１５０メートルの距離、３０度の垂直視野角、及び３０度の水平視野角を有し得る。レーザー３１１のビームは、５０−８０メートルの距離、３０度の垂直視野角、及び３６０度の水平視野角を有し得る。異なる距離及び構成を有する他のレーザーも使用し得ると理解されるであろう。このレーザーは、コンピュータが車両の周囲にある様々な物体の位置及び距離を特定するのに使用し得る距離及び強度情報を車両に提供し得る。１つの態様では、レーザーは、その軸を回転させ及びそのピッチを変更することにより、その車両とその車両と向き合う物体表面との間の距離を測定し得る。 The vehicle may include components that detect objects outside the vehicle, such as other vehicles, obstacles on the road, traffic signals, signs, trees and the like. The detection system may include a laser, sound detector, radar, camera, or any other detection device that records data that can be processed by the computer 110. For example, if the vehicle is a small passenger car, the passenger car may include a laser that is attached to the roof or other convenient location. As shown in FIG. 3A, the vehicle 101 may be a small passenger car. In this example, the sensor of the vehicle 101 may include lasers 310, 311 that are attached to the front and roof of the vehicle, respectively. The laser may include a commercially available laser such as Velodyne HDL-64, or other models. The laser can include one or more laser beams. For example, a Velodyne HDL-64 laser can include 64 beams. In one example, the beam of laser 310 may have a distance of 150 meters, a vertical viewing angle of 30 degrees, and a horizontal viewing angle of 30 degrees. The laser 311 beam may have a distance of 50-80 meters, a vertical viewing angle of 30 degrees, and a horizontal viewing angle of 360 degrees. It will be appreciated that other lasers having different distances and configurations may be used. The laser may provide the vehicle with distance and intensity information that a computer can use to determine the position and distance of various objects around the vehicle. In one aspect, the laser can measure the distance between the vehicle and the object surface facing the vehicle by rotating its axis and changing its pitch.
上述のセンサーにより、搭乗者の安全のみならず周囲の物体や人々の安全も最大化するために、車両がその環境を理解し潜在的にその環境に対応することが可能となり得る。その車両の種類、数及びセンサーの種類、センサーの位置、センサーの視野、及びセンサーの視界は単に例示的なものであるにすぎない。様々な他の構成も利用され得ることが理解されるだろう。 The sensors described above may allow the vehicle to understand and potentially respond to its environment to maximize not only the safety of the passengers but also the surrounding objects and people. The vehicle type, number and sensor type, sensor location, sensor field of view, and sensor field of view are merely exemplary. It will be appreciated that various other configurations may be utilized.
上記のセンサーに加えて、コンピュータは、典型的な非自律車両のセンサーからの入力をも使用し得る。例えば、これらのセンサーは、タイヤ圧力センサー、エンジン温度センサー、ブレーキ熱センサー、ブレーキパッド状態センサー、タイヤ・トレッドセンサー、燃料センサー、オイルレベル及び品質センサー、エアクオリティセンサー（空気中の温度、湿度又は微粒子を検出するための）等を含み得る。 In addition to the sensors described above, the computer may also use input from typical non-autonomous vehicle sensors. For example, these sensors include tire pressure sensors, engine temperature sensors, brake heat sensors, brake pad condition sensors, tire tread sensors, fuel sensors, oil level and quality sensors, air quality sensors (temperature in air, humidity or particulates For detecting) and the like.
これらのセンサーの多くは、リアルタイムでコンピュータにより処理されるデータを提供する。すなわち、センサーは、その時に又は時間範囲に亘り検出された環境を反映させるためにこれらの出力を連続的に更新し得る。そして、コンピュータが車両のその時の方向又は速度を検出された環境に応じて修正するべきであるかどうかを決定できるように、連続的に又は要求に応じて更新された出力をコンピュータに提供する。 Many of these sensors provide data that is processed by a computer in real time. That is, the sensor may continuously update these outputs to reflect the environment detected at that time or over a time range. It then provides the computer with updated output continuously or on demand so that the computer can determine whether the current direction or speed of the vehicle should be modified according to the detected environment.
様々なセンサーにより提供されるデータを処理することに加え、コンピュータは、過去のある時点で取得され、その環境に車両が存在するかしないかに関わらず持続することが期待される環境のデータを頼りにし得る。例えば、図１に戻ると、データ１３４は、道路の形状および標高、交差点、横断歩道、速度制限、交通信号、ビルディング、標識、リアルタイムのトラフィック情報、又は他のこのような物体及び情報を特定する詳細な地図情報１３６、例えば、非常に細かい地図を含み得る。 In addition to processing the data provided by the various sensors, the computer captures environmental data that is acquired at some point in the past and is expected to persist regardless of the presence or absence of vehicles in the environment. You can count on it. For example, returning to FIG. 1, data 134 identifies road shape and elevation, intersections, pedestrian crossings, speed limits, traffic signals, buildings, signs, real-time traffic information, or other such objects and information. Detailed map information 136 may be included, for example, a very fine map.
詳細な地図情報１３６は、レーンマーカの位置、標高、及び形状を特定するレーンマーカ情報をも含み得る。レーンマーカは、実線又は破線、二重線又は一重線の車線境界線、実線又は破線の車線境界線、反射体等の特徴を含み得る。所与の車線は、車線の境界を規定する、左側車線境界線、右側車線境界線又は他のレーンマーカに対応付けられ得る。 Detailed map information 136 may also include lane marker information that identifies the position, elevation, and shape of the lane marker. Lane markers may include features such as solid or broken lines, double or single lane boundaries, solid or dashed lane boundaries, reflectors, and the like. A given lane may be associated with a left lane boundary, a right lane boundary, or other lane marker that defines a lane boundary.
図４は、道路（レーザーの距離範囲の外側の情報と同様）の同じセクションの例を含む詳細な地図４００を説明する。道路のセクションの詳細な地図は、実線の車線境界線４１０、破線の車線境界線４２０、４４０、及び二重線の実線の車線境界線４３０等の情報を含む。これらの車線境界線は、車線４５０及び車線４６０を定義している。各車線は、車両が殆どの場合それぞれの車線内で走行すべき方向を示すレール４５５、４６５に対応付けられる。例えば、車両は、車線４６０に沿って走行するときにレール４６５をたどって進み得る。 FIG. 4 illustrates a detailed map 400 that includes an example of the same section of a road (similar to information outside the laser distance range). The detailed map of the road section includes information such as solid lane boundaries 410, dashed lane boundaries 420, 440, and double solid lane boundaries 430. These lane boundaries define a lane 450 and a lane 460. Each lane is associated with rails 455 and 465 that indicate the direction in which the vehicle should travel in the respective lane in most cases. For example, the vehicle may follow the rail 465 when traveling along the lane 460.
さらに、この詳細な地図情報は画像ベースの地図として説明されているが、この地図情報は、完全に画像ベース（例えば、ラスター）である必要はない。例えば、この詳細な地図情報は、道路、車線、交差点、及びこれらの要素の接続等の情報の１つ又は複数の道路グラフ又はグラフネットワークを含み得る。各要素は、グラフデータとして記憶され得るし、地理的位置とその要素が他の関連する要素とリンクしているかどうか（例えば、一時停止の標識が道路や交差点とリンクし得る等）等の情報と関連付けられ得る。いくつかの例においては、関連付けられたデータは、ある道路グラフの要素の効率的な検索を可能とするために道路グラフの格子状のインデックスを含み得る。 Furthermore, although the detailed map information has been described as an image-based map, the map information need not be completely image-based (eg, raster). For example, this detailed map information may include one or more road graphs or graph networks of information such as roads, lanes, intersections, and connections of these elements. Each element can be stored as graph data, and information such as geographic location and whether the element is linked to other related elements (for example, a stop sign can be linked to a road or intersection) Can be associated with In some examples, the associated data may include a grid-like index of the road graph to allow efficient search for certain road graph elements.
コンピュータ１１０は、他のコンピュータとの間で情報の送受信も行い得る。例えば、コンピュータ１１０により記憶される地図情報は、他のコンピュータとの間で送信又は受信され得る、及び／または、車両１０１のセンサーから収集されたセンサーデータは、ここで説明されるように処理するために他のコンピュータに送信され得る。図３Ｂ及び図３Ｃに示されるように、コンピュータ１１０からのデータは、さらなる処理のためにネットワークを介してコンピュータ３２０に送信され得る。ネットワーク、及び介在するノードは、インタネット、ワールドワイドウェブ、イントラネット、仮想プライベート・ネットワーク、広域領域ネットワーク、ローカルネットワーク、１つ又は複数の会社専用の通信プロトコルを用いるプライベート・ネットワーク、イーサネット（登録商標）、ＷｉＦｉ並びにＨＴＴＰ、及び上述の様々な組み合わせを含む様々な構成及びプロトコルを備える。このような通信は、モデム及び無線インタフェース等の他のコンピュータとの間で送信データをやり取りする能力がある任意のデバイスにより促進され得る。他の例では、データは、コンピュータ１１０、３２０によってアクセスされ得る又は接続され得るメモリに記憶させることにより、伝達され得る。 The computer 110 can also send and receive information to and from other computers. For example, map information stored by computer 110 may be transmitted to or received from other computers and / or sensor data collected from sensors in vehicle 101 is processed as described herein. Can be sent to other computers. As shown in FIGS. 3B and 3C, data from the computer 110 may be transmitted over the network to the computer 320 for further processing. The network and intervening nodes include the Internet, the World Wide Web, an intranet, a virtual private network, a wide area network, a local network, a private network using one or more company-specific communication protocols, Ethernet, With various configurations and protocols including WiFi and HTTP, and various combinations of the above. Such communication can be facilitated by any device capable of exchanging transmission data with other computers, such as modems and wireless interfaces. In other examples, the data can be communicated by storing it in a memory that can be accessed or connected by the computers 110, 320.
一例では、コンピュータ３２０は、複数のコンピュータを有するサーバー、例えばコンピュータ１１０からのデータを受信し、処理し、送信する目的でネットワークの異なるノードと情報を交換する複数のコンピュータ、例えば、負荷分散サーバーファームを備え得る。サーバーは、コンピュータ１１０と同様に、プロセッサー３３０、メモリ３５０、命令３６０、及びデータ３７０により構成され得る。 In one example, computer 320 is a plurality of computers that exchange information with different nodes of the network for the purpose of receiving, processing, and transmitting data from a server having a plurality of computers, such as computer 110, for example, a load balancing server farm. Can be provided. The server may be configured with a processor 330, a memory 350, instructions 360, and data 370, similar to the computer 110.
図１に戻ると、データ１３４は、レーンマーカモデル１３８をも含み得る。レーンマーカモデルは、幅、寸法、他の車線境界線等に対する相対的位置等の典型的な車線境界線の形状を規定し得る。レーンマーカモデル１３８は地図情報１３６の一部として、又は別個に記憶され得る。レーンマーカモデルは、さらに車両１０１、コンピュータ３２０のいずれか、又はその両方に記憶され得る。 Returning to FIG. 1, the data 134 may also include a lane marker model 138. The lane marker model may define a typical lane boundary shape, such as width, size, relative position to other lane boundary lines, and the like. The lane marker model 138 may be stored as part of the map information 136 or separately. The lane marker model can be further stored in either the vehicle 101, the computer 320, or both.
上に述べられた又は図面に示された動作に加えて、様々な動作がここで説明される。以下の動作は、下記の通りの順序で実行されなくてもよく、むしろ、様々なステップが、異なる順序で、又は同時に処理され得るし、またステップのいくつかが追加又は省略されてもよいと理解すべきである。 In addition to the operations described above or shown in the drawings, various operations will now be described. The following operations may not be performed in the following order, rather, the various steps may be processed in a different order or simultaneously, and some of the steps may be added or omitted: Should be understood.
１つ又は複数のレーザーを含む車両は、道路に沿って運転され得る。例えば、レーザーは、車両１０１等の自律走行システムの構成要素又は典型的な車両に取り付けられたボード外センサーであり得る。図５は、図４の詳細な地図情報に対応する道路５００のセクション上の車両１０１を説明する。この例では、道路は、実線の車線境界線５１０、破線の車線境界線５２０、５４０、二重線の車線境界線５３０、及び車線５５０、５６０を含む。 A vehicle including one or more lasers can be driven along the road. For example, the laser may be a component of an autonomous driving system such as the vehicle 101 or an off-board sensor attached to a typical vehicle. FIG. 5 illustrates the vehicle 101 on the section of the road 500 corresponding to the detailed map information of FIG. In this example, the road includes a solid lane boundary 510, a dashed lane boundary 520, 540, a double lane boundary 530, and lanes 550, 560.
車両の１つまたは複数のレーザーが動かされるにつれて、レーザーはレーザースキャンデータを収集し得る。レーザースキャンデータは、同じ位置（点又は領域）に対していくつかの方向からの及び／または異なる時刻における距離及び強度情報を有するデータポイントを含み得る。例えば、レーザースキャンデータは、データが提供される特定のビームに関連付けられ得る。したがって、単一の３６０度のスキャンに対して、ビームのそれぞれはデータポイントの集合を提供し得る。 As the vehicle's laser or lasers are moved, the laser may collect laser scan data. Laser scan data may include data points with distance and intensity information from several directions and / or at different times for the same location (point or region). For example, laser scan data can be associated with a particular beam for which data is provided. Thus, for a single 360 degree scan, each of the beams can provide a collection of data points.
単一のレーザーに複数のビームが存在し得るので、単一ビームに関連付けられるデータポイントは共に処理され得る。例えば、レーザー３１１のビームの各ビームに対するデータポイントは、地理的位置座標を生成するようにコンピュータ１１０（又はコンピュータ３２０）により処理され得る。これらの地理的位置座標は、ＧＰＳの緯度と経度の座標及び第３の標高の座標（ｘ，ｙ，ｚ）を含み、又は他の座標システムと関連付けられ得る。この処理の結果が、データポイントの集合である。この集合のデータポイントのそれぞれは、レーザーが物体から光を受ける際の物体の反射率を示す強度値及び位置並びに標高の成分（ｘ，ｙ，ｚ）を含み得る。 Since there can be multiple beams in a single laser, data points associated with a single beam can be processed together. For example, the data points for each of the beams of laser 311 may be processed by computer 110 (or computer 320) to generate geographic location coordinates. These geographic location coordinates may include GPS latitude and longitude coordinates and third elevation coordinates (x, y, z), or may be associated with other coordinate systems. The result of this processing is a set of data points. Each of the data points in this set may include an intensity value and position indicating the reflectivity of the object as the laser receives light from the object, and an elevation component (x, y, z).
図６は、交差点に接近しつつある車両１０１の例示的な画像６００を説明する。この画像は、例えば、収集する（複数の）レーザーのビームの全てのデータポイントを用いて、車両の周囲の単一３６０度スキャンを行い、車両のレーザーにより収集されたレーザースキャンデータから生成された。白い線はレーザーがその周囲をどのように「見ている」かを表している。複数のビームのデータポイントが共に考慮されたとき、データポイントは、車両の周囲にある他の物の形状及び３次元の（３Ｄ）位置（ｘ，ｙ，ｚ）を示し得る。例えば、レーザースキャンデータは、人々６１０、車両６２０、及び縁石６３０等の様々な物体の輪郭、形状及び車両１０１からの距離を示し得る。 FIG. 6 illustrates an exemplary image 600 of the vehicle 101 approaching the intersection. This image was generated from laser scan data collected by the vehicle laser, for example, a single 360 degree scan around the vehicle using all data points of the laser beam (s) to be collected. . The white line represents how the laser “sees” its surroundings. When multiple beam data points are considered together, the data points may indicate the shape of other objects around the vehicle and the three-dimensional (3D) position (x, y, z). For example, the laser scan data may indicate the contours, shapes, and distances from the vehicle 101 of various objects such as people 610, vehicles 620, and curb 630.
図７は、車両が図５の道路５００に沿って走行するときに単一スキャンで収集されたレーザースキャンデータの他の例７００を説明する（図４の地図情報４００でも説明されている）。図７の例では、車両１０１は、レーザー線７３０に囲まれて描かれている。各レーザー線は、単一ビームからの一連の離散データポイントを表し得る。複数のビームのデータポイントは互いにつながっているようにみなされ、このデータポイントは、車両の周囲にある他の物の形状及び３次元の（３Ｄ）位置（ｘ，ｙ，ｚ）を示し得る。車線境界線、白色材料（塗料等）、反射体、又は再帰反射の性質を有する反射体等のより大きく反射する物からのデータポイントは、小さい反射率の物よりも大きな強度を有する。この例では、参照線７２０は、実線の車線境界線と関連付けられるデータポイント７１０を結んだ線であり、レーザーデータの一部ではない。 FIG. 7 illustrates another example 700 of laser scan data collected in a single scan as the vehicle travels along the road 500 of FIG. 5 (also described in the map information 400 of FIG. 4). In the example of FIG. 7, the vehicle 101 is drawn surrounded by a laser line 730. Each laser line may represent a series of discrete data points from a single beam. Multiple beam data points are considered to be connected to one another, which may indicate the shape of other objects around the vehicle and the three-dimensional (3D) position (x, y, z). Data points from more reflective objects, such as lane boundaries, white materials (such as paint), reflectors, or reflectors with retroreflective properties, have greater intensity than objects with lower reflectivity. In this example, reference line 720 is a line connecting data points 710 associated with a solid lane boundary, and is not part of the laser data.
図７は、実線の二重線の車線境界線で反射する光から生成されたデータポイント７４０と同様に破線の車線境界線で反射する光から生成されたデータポイント７５０をも含む。道路の特徴に加え、レーザースキャンデータは、車両７６０のように道路にある他の物体から発生するデータであり得る。 FIG. 7 also includes data points 750 generated from light reflected at the dashed lane boundary as well as data points 740 generated from light reflected at the solid double-lane lane boundary. In addition to road features, the laser scan data may be data originating from other objects on the road, such as a vehicle 760.
コンピュータ１１０（又はコンピュータ３２０）は、単一ビームの統計値を計算し得る。例えば、図８は、単一ビームに対するレーザースキャンデータの例８００である。この例では、データポイントは、二重線の車線境界線５３０（図５で示される）で反射する光から生成されたデータポイント７４０と、破線の車線境界線５２０（図５で示される）で反射する光から生成されたデータポイント７５０と、車両等の道路における他の物体から生成されるデータポイント７６０とを含む。 Computer 110 (or computer 320) may calculate single beam statistics. For example, FIG. 8 is an example laser scan data 800 for a single beam. In this example, the data points are a data point 740 generated from light reflected at a double lane boundary 530 (shown in FIG. 5) and a dashed lane boundary 520 (shown in FIG. 5). It includes data points 750 generated from the reflected light and data points 760 generated from other objects on the road such as a vehicle.
ビームのデータポイントは、評価のために等間隔のセクションの集合に分割され得る。図９は、セクション９１０、９２０、及び９３０を含む１６個の物理的セクションに分割された、図８のレーザースキャンデータの例９００である。１６個のセクションのみが使用されているが、より多い又はより少ない個数のセクションが多く使用され得る。このセクション分けは回転方式で実行され得る。例えば、３６０度スキャンが実行された後にデータポイントを物理的にセクション分けすることにより又はコンピュータにより受信されるＮ個のデータポイントの集合を評価する。 The beam data points may be divided into a set of equally spaced sections for evaluation. FIG. 9 is an example 900 of the laser scan data of FIG. 8 divided into 16 physical sections including sections 910, 920, and 930. Only 16 sections are used, but more or fewer sections can be used more often. This sectioning can be performed in a rotating manner. For example, evaluate the set of N data points received by physically sectioning the data points after a 360 degree scan has been performed or by a computer.
各セクションにおける平均強度値及び標準偏差が算出され得る。いくつかの例では、強度値及び標準偏差が隣接するセクション間であまり大きく相違しないことを確認するために、データポイントが、セクションの間で又はセクション内で正規化され得る。この正規化により、近隣データを考慮することにより推定におけるノイズを低減し得る。 Average intensity values and standard deviations in each section can be calculated. In some examples, data points can be normalized between sections or within sections to ensure that intensity values and standard deviations do not differ significantly between adjacent sections. This normalization can reduce the noise in the estimation by considering neighboring data.
レーンマーカのデータポイント又はレーンマーカに対応する可能性が高いデータポイントの集合を識別するためにビームに対する全てのデータポイントを評価することができる。例えば、コンピュータは、各データポイントがレーンマーカであるか（又は無いか）のいくつかの基準をみたしているかどうかを判定し得る。この基準を満たしているデータポイントは、レーンマーカに関連するとみなされ得るし、あり得るレーンマーカのデータポイントの集合に含められ得る。この点に関し、コンピュータは異なる車線境界線を区別する必要がない。言い換えれば、あり得るレーンマーカのデータポイントの集合には、複数の異なる車線境界線データポイントが含まれ得る。 All data points for the beam can be evaluated to identify a lane marker data point or a set of data points likely to correspond to a lane marker. For example, the computer may determine whether each data point meets some criteria of whether or not it is a lane marker. Data points that meet this criterion may be considered related to the lane marker and may be included in a set of possible lane marker data points. In this regard, the computer need not distinguish between different lane boundaries. In other words, a set of possible lane marker data points may include a plurality of different lane boundary data points.
一例では、基準はデータポイントの標高に基づき得る。この例では、地面（又は道路表面）に非常に近い標高成分（ｚ）を有するデータポイントは、道路表面から閾値距離より高い位置にあるデータポイントより、レーンマーカ（又は少なくとも道路に関連するもの）と関連付けられる可能性が高い。道路表面情報は、地図情報に含まれ得る、又はレーザースキャンデータから推定され得る。例えば、コンピュータは、表面モデルをレーザーデータに適用して、地面を識別し、そしてこの判定をレーンマーカのデータポイントの解析に使用し得る。したがって、コンピュータは、閾値距離より高い位置にあるデータポイントにフィルターをかけ又は無視し得る。言い換えれば、閾値標高かそれより低いデータポイントが考慮され又はレーンマーカのデータポイントの集合の中に含められ得る。 In one example, the criteria may be based on the elevation of the data points. In this example, a data point having an elevation component (z) very close to the ground (or road surface) is a lane marker (or at least related to the road) rather than a data point that is higher than the threshold distance from the road surface. Likely to be associated. Road surface information may be included in the map information or estimated from laser scan data. For example, the computer may apply a surface model to the laser data to identify the ground and use this determination to analyze the lane marker data points. Thus, the computer may filter or ignore data points that are higher than the threshold distance. In other words, data points at or below the threshold elevation can be considered or included in the set of lane marker data points.
例えば、図１０Ａは、セクション９１０からのデータポイントの部分のｘ及びｙ座標（緯度と経度）の略図である。上記の例のように、データポイント７５０は、破線の車線境界線６２０（図６に示される）に関連付けられるデータポイントである。図１０Ｂは、これと同じデータの標高（ｚ）の略図である。この例における全てのデータポイントは、道路表面線１０２０に近く、全てのデータポイントは閾値標高線（ｚＴＨ）１０３０よりも低い。したがって、この全てのデータがレーンマーカのデータポイントの集合に含まれ得るか又は考慮され得る。 For example, FIG. 10A is a schematic diagram of the x and y coordinates (latitude and longitude) of the portion of the data point from section 910. As in the example above, data point 750 is a data point associated with a dashed lane boundary 620 (shown in FIG. 6). FIG. 10B is a schematic diagram of the altitude (z) of the same data. All data points in this example are close to the road surface line 1020 and all data points are below the threshold elevation line (z TH ) 1030. Thus, all this data can be included or considered in the set of lane marker data points.
他の基準は、閾値強度値を基準とし得る。閾値強度値は、デフォルトの値又は１つの値であり得るし、又は特定のセクションに固有のものであり得る。例えば、閾値強度値は、所与のセクションにおける平均強度であり得る。この例では、所与のセクションにおける特定のデータポイントそれぞれの強度値は、所与のセクションにおける平均強度と比較され得る。もし、所与のセクションのデータポイントの強度値が所与のセクション内での平均強度より大きいならば、これらのデータポイントは、レーンマーカに関連付けられるとみなされ得る。他の例では、所与のセクションにおける閾値強度値が、所与のセクションに対して平均強度よりも標準偏差の何倍か（２倍、３倍、４倍等）だけ大きいことがあり得る。したがって、コンピュータは、閾値強度値より低いデータポイントにフィルタをかけるか又は無視し得る。言い換えれば、閾値強度値かそれより大きいデータポイントは、考慮され又は集合の中に含められ得る。 Other criteria may be based on threshold intensity values. The threshold intensity value can be a default value, a single value, or can be specific to a particular section. For example, the threshold intensity value can be the average intensity in a given section. In this example, the intensity value for each particular data point in a given section can be compared to the average intensity in a given section. If the intensity values of data points in a given section are greater than the average intensity within a given section, these data points can be considered associated with lane markers. In other examples, the threshold intensity value in a given section can be several times the standard deviation (2x, 3x, 4x, etc.) greater than the average intensity for a given section. Thus, the computer can filter or ignore data points below the threshold intensity value. In other words, data points at or above the threshold intensity value can be considered or included in the set.
例えば、図１０Ａのように、図１１Ａは、セクション９１０からのデータポイントの部分のｘとｙ（緯度と経度）座標の略図である。上記の例のように、データポイント７５０は、破線の車線境界線６２０（図６に示される）に関連付けられるデータポイントである。図１１Ｂは、この同じデータの強度（Ｉ）の略図である。この例は、及び標準偏差閾値数線（ＮσＩ）１１２０をも含む。この例では、データポイント７５０は、線１１２０より高く（そして、線１１１０よりも相当高いことがある）、一方データポイント１０１０は、１１２０より低い（そして、線１１１０より相当に高くはないことがある）。したがって、この例ではデータポイント７５０は、この集合に含められ又は考慮され得る一方、データポイント１０１０はフィルタをかけられ又は無視され得る。 For example, as in FIG. 10A, FIG. 11A is a schematic representation of the x and y (latitude and longitude) coordinates of the portion of the data point from section 910. As in the example above, data point 750 is a data point associated with a dashed lane boundary 620 (shown in FIG. 6). FIG. 11B is a schematic diagram of the intensity (I) of this same data. This example also includes a standard deviation threshold number line (Nσ I ) 1120. In this example, data point 750 is higher than line 1120 (and may be significantly higher than line 1110), while data point 1010 may be lower than 1120 (and not significantly higher than line 1110). ). Thus, in this example, data points 750 can be included or considered in this set, while data points 1010 can be filtered or ignored.
したがって、図１０Ｂ及び図１１Ｂの両方の例を考慮すると、データポイント７５０は、データポイント１０１０よりもレーンマーカに関連付けられる可能性が高い。したがって、データポイント７５０は、レーンマーカのデータポイントの識別された集合に含められ得る一方、データポイント１０１０は含められない。 Thus, considering both the examples of FIGS. 10B and 11B, the data point 750 is more likely to be associated with a lane marker than the data point 1010. Thus, data points 750 can be included in the identified set of lane marker data points, while data points 1010 are not included.
レーンマーカと識別されたデータポイントの集合は、さらにレーンマーカのデータポイントである可能性が低いデータポイントを除くためにフィルタをかけられ得る。例えば、各データポイントは、レーンマーカと識別されたデータポイントの集合の残りのデータポイントと整合が取れるかどうか判定するために評価され得る。コンピュータ１１０（又はコンピュータ３２０）は、集合の中のデータポイント間の間隔が典型的なレーンマーカの場合と整合しているかどうかを判定し得る。この点に関し、レーンマーカのデータポイントは、レーンマーカモデル１３８と比較され得る。整合していないデータポイントは、ノイズを減少させるためにフィルタをかけられるかまたは取り除かれ得る。 The set of data points identified as lane markers may be further filtered to exclude data points that are less likely to be lane marker data points. For example, each data point can be evaluated to determine if it matches the remaining data points in the set of data points identified as lane markers. Computer 110 (or computer 320) may determine whether the spacing between data points in the set is consistent with a typical lane marker case. In this regard, the lane marker data points can be compared to the lane marker model 138. Unmatched data points can be filtered or removed to reduce noise.
このフィルタリングは、さらに、強度データポイントが高い集団を調べることを含み得る。例えば、３６０度スキャンの場合、レーザースキャンデータにおける隣接するポイントは、現実世界における近隣位置に対応し得る。もし、互いに近くに位置する（例えば、互いに隣接する）比較的高い強度を有する２つ以上のデータポイントの一群が存在するなら、これらのデータポイントは、同じレーンマーカに対応する可能性が高い。同様に、他の強度が高いデータポイントの近隣ではない、又は１つの集団と関連付けられない、強度が高いデータポイントは、フィルタをかけられるか、レーンマーカのデータポイントであると識別された集合には含めないようにされ得る。 This filtering may further include examining a population with high intensity data points. For example, in the case of a 360 degree scan, adjacent points in the laser scan data can correspond to neighboring locations in the real world. If there is a group of two or more data points with relatively high intensity that are located close to each other (eg, adjacent to each other), these data points are likely to correspond to the same lane marker. Similarly, high-intensity data points that are not neighbors of other high-intensity data points or are not associated with one population are filtered or are identified as being lane marker data points. Can be excluded.
識別されるレーンマーカのデータポイントの集合は、レーザースキャンデータが取り込まれるときのレーザー（又は車両）の位置に基づいてフィルターをかけられる。例えば、もし、コンピュータが車両は車線の境界から（ある方向で）一定の距離内に存在することを知るならば、車両からの距離（ある方向における）が近くない高い強度のデータポイントは、フィルタをかけられるか、又は識別されたレーンマーカのデータポイントの集合に含まれないことにし得る。同様に、レーザー（又は車両）から比較的遠くに（例えば、所定のヤード数より遠くに、等）位置するレーザーデータポイントは、もし、レーザースキャンデータがさらにレーザー（又は車両）から離れてノイズが大きいなら、無視されるか又は識別されたレーンマーカのデータポイントの集合からフィルタをかけられ得る。 The set of identified lane marker data points is filtered based on the position of the laser (or vehicle) when the laser scan data is captured. For example, if the computer knows that the vehicle is within a certain distance (in a certain direction) from the lane boundary, a high-intensity data point that is not near the distance (in a certain direction) from the vehicle can be filtered Or may not be included in the set of identified lane marker data points. Similarly, a laser data point that is located relatively far from the laser (or vehicle) (eg, beyond a predetermined number of yards, etc.) will cause noise if the laser scan data is further away from the laser (or vehicle). If so, it can be ignored or filtered from the set of identified lane marker data points.
上述のステップは、レーザーのビームそれぞれに対して繰り返され得る。例えば、もし、特定のレーザーに６４個のビームが存在するなら、６４個のフィルタをかけられる車線作成データポイントの集合が存在する。 The above steps can be repeated for each of the laser beams. For example, if there are 64 beams for a particular laser, there is a set of lane creation data points that can be filtered.
結果として生じるレーンマーカのデータポイントのフィルタをかけられた集合は、後の使用のために記憶されるか又は単に他の使用のために利用可能とされる。例えば、データは、リアルタイムに車両１０１等の自律車両を動かすためにコンピュータ１１０等のコンピュータにより使用され得る。例えば、コンピュータ１１０は、車線境界線を識別し車両１０１を車線内に保つために、レーンマーカデータのフィルタをかけられた集合を使用し得る。車両が車線に沿って動くとき、コンピュータ１１０は、上記のステップの全て又はいくつかを繰り返してレーザーデータの処理を継続し得る。 The resulting filtered set of lane marker data points is stored for later use or simply made available for other uses. For example, the data can be used by a computer such as computer 110 to move an autonomous vehicle such as vehicle 101 in real time. For example, the computer 110 may use a filtered set of lane marker data to identify lane boundaries and keep the vehicle 101 in the lane. As the vehicle moves along the lane, the computer 110 may continue processing the laser data by repeating all or some of the above steps.
いくつかの例では、レーンマーカデータのフィルタをかけられた集合は、後でコンピュータ３２０等の他のコンピュータによって、決定され得る。例えば、レーザースキャンデータは、処理のためにアップロードされるか又はコンピュータ３２０に送信され得る。レーザースキャンデータは上記のように処理され得るし、結果としてのフィルタをかけられたレーンマーカデータの集合は、自律車両を運転するのに使用される地図情報を生成し、更新し、補足するのに使用され得る。同様に、この情報は、ナビゲーション（例えば、ＧＰＳナビゲーション）及び他の目的のために使用される地図を準備するのに使用され得る。 In some examples, the filtered set of lane marker data can be determined later by other computers, such as computer 320. For example, laser scan data can be uploaded for processing or transmitted to computer 320. Laser scan data can be processed as described above, and the resulting filtered set of lane marker data generates, updates, and supplements map information used to drive autonomous vehicles. Can be used. Similarly, this information can be used to prepare maps used for navigation (eg, GPS navigation) and other purposes.
図１２のフローチャート１２００は、上記のいくつかの態様の例である。次のステップのそれぞれが、コンピュータ１１０、コンピュータ３２０、またはこの両方の組み合わせにより実行され得る。この例では、１２０２において、複数のレーザービームからの複数のデータポイントを含むレーザースキャンデータが、道路に沿ってレーザーを動かすことにより収集される。上で説明したように、データポイントは、レーザー光が反射された物体の強度及び位置情報を表わし得る。レーザーの各ビームは、複数のデータポイントの部分集合のそれぞれに関連付けられ得る。 Flowchart 1200 in FIG. 12 is an example of some of the above aspects. Each of the following steps may be performed by computer 110, computer 320, or a combination of both. In this example, at 1202, laser scan data including a plurality of data points from a plurality of laser beams is collected by moving the laser along a road. As explained above, the data points may represent the intensity and position information of the object from which the laser light is reflected. Each beam of the laser may be associated with a respective subset of the plurality of data points.
ブロック１２０４において、単一のビームに対して、データポイントの部分集合のそれぞれが、セクションに分割され得る。ブロック１２０６で各セクションについて、それぞれの平均強度とそれぞれの強度の標準偏差が、決定される。各セクションの閾値強度は、ブロック１２０８においてそれぞれの平均強度とそれぞれの強度の標準偏差とに基づいて決定され得る。もし、ブロック１２１０において評価のための他のビームが存在するなら、プロセスは、ブロック１２０４に戻り、次のビームのデータポイントの部分集合が上述のように評価される。 At block 1204, for a single beam, each of the subsets of data points may be divided into sections. At block 1206, for each section, a respective average intensity and a standard deviation of each intensity are determined. The threshold intensity for each section may be determined at block 1208 based on the respective average intensity and the standard deviation of each intensity. If there are other beams for evaluation in block 1210, the process returns to block 1204 and a subset of data points for the next beam is evaluated as described above.
ブロック１２１０に戻ると、評価のための他のビームが存在しないなら、ブロック１２１２で複数のデータポイントからのレーンマーカのデータポイントの集合が、生成される。これは、データポイントの強度値をそのデータポイントのそれぞれのセクションの閾値強度値とを比較することにより、複数のデータポイントのそれぞれを評価してデータポイントが道路の閾値標高内であるかどうかを決定することを含む。レーンマーカのデータポイントの集合は、ブロック１２１４において後の使用のためにメモリに記憶され得るし、または別の方法でさらなる処理のために利用可能となるようにさせ得る。 Returning to block 1210, if there are no other beams for evaluation, at block 1212 a set of lane marker data points from a plurality of data points is generated. This evaluates each of the data points by comparing the intensity value of the data point with the threshold intensity value of each section of that data point to determine whether the data point is within the road threshold elevation. Including deciding. The set of lane marker data points may be stored in memory for later use at block 1214, or may otherwise be made available for further processing.
上記の例は連続する各ビームからのデータポイントの処理を含む一方、同じステップが強度値を含むレーザーデータの任意の集合にも適用し得る。例えば、もし複数のビームが存在するなら、ビーム毎の処理ではなく単一の３６０度スキャンのレーザーデータが一度にそろって処理され得る。他の例では、レーザーデータが単一ビームのみを含むことができ、あるいはレーザースキャンデータはコンピュータ１１０、又はコンピュータ３２０によりビームの指示無しに受信され得る。 While the above example involves processing data points from each successive beam, the same steps can be applied to any set of laser data that includes intensity values. For example, if there are multiple beams, laser data for a single 360 degree scan can be processed all at once rather than processing for each beam. In other examples, the laser data may include only a single beam, or the laser scan data may be received by the computer 110 or computer 320 without the instruction of the beam.
この点に関し、統計値（強度の平均、標準偏差）は、様々な異なる方法で計算され得る。例えば、レーザースキャンデータは、ビーム毎にではなくて複数のビームからのデータを有するセクションに分割され得る。あるいは、１つ以上の又は全てのビームについてのレーザースキャンデータの全てが、データポイントをセクションに分割することなしに一度にそろって処理され得る。加えて、道路の特定のセクションのスキャンに対する統計値データは、記憶され、将来同じ位置で取られる新しいレーザースキャンデータと（後になって）オフラインで比較され得る。 In this regard, statistics (intensity average, standard deviation) can be calculated in a variety of different ways. For example, the laser scan data may be divided into sections with data from multiple beams rather than per beam. Alternatively, all of the laser scan data for one or more or all beams can be processed together at one time without dividing the data points into sections. In addition, statistical data for scans of specific sections of the road can be stored and compared (later) offline with new laser scan data taken at the same location in the future.
加えて、位置、標高、及び強度値を含むレーザースキャンデータの使用は、再帰反射型材料及び／または白色材料（塗料等）に基づいて増加する値を戻す任意のセンサーにより置き換えられ得る。 In addition, the use of laser scan data including position, elevation, and intensity values can be replaced by any sensor that returns an increasing value based on retroreflective material and / or white material (such as paint).
上記の態様により、さらなる利点が得られる。例えば、レーンマーカに関連付けられる可能性が非常に高いデータポイントを識別することにより、他の処理ステップを実行するのに必要な時間及び処理能力を減少させ得る。このことは、自律車両を動かすためにレーザースキャンデータがリアルタイムで処理される場合に特に重要であり得る。したがって、時間及び処理能力コストの点で非常に大きな節約となり得る。 Further advantages are gained by the above aspects. For example, identifying data points that are very likely to be associated with a lane marker may reduce the time and processing power required to perform other processing steps. This can be particularly important when laser scan data is processed in real time to move an autonomous vehicle. Thus, it can be a huge saving in terms of time and processing cost.
上記の特徴のこれらの並びに他の変形例及びその組み合わせは、特許請求範囲に定義された発明の主題から逸脱することなく利用可能であるので、上述の例示的な実施例の説明は、特許請求範囲に定義された発明の主題を限定することではなく、実例として解釈されるべきものである。ここで説明される例の提供は、（「等の」、「例えば」、「含む」等の文言も同様に）請求項の発明の主題を限定するものとして解釈されるべきではなく、むしろ多くの可能な態様の中からいくつかだけを例として示すことを意図していることも理解されるであろう。 Since these and other variations and combinations of the features set forth above can be utilized without departing from the subject matter of the invention as defined in the claims, the description of the exemplary embodiments described above is It should be construed as illustrative rather than limiting on the subject matter of the invention as defined in scope. The provision of examples described herein should not be construed as limiting the subject matter of the claimed invention (as well as the words “such as”, “for example”, “including”, etc.) It will also be understood that only some of the possible embodiments are intended to be shown by way of example.
本開示は道路上のレーンマーカに関連付けられる可能性が非常に高いレーザースキャンデータからデータポイントを特定するのに使用され得る。 The present disclosure can be used to identify data points from laser scan data that are very likely to be associated with lane markers on the road.
Claims (26)
道路について収集されたスキャンデータにアクセスするステップであって、前記スキャンデータは、物体の位置情報と強度情報を有する複数のデータポイントを含む前記ステップと、
前記複数のデータポイントを複数のセクションに分割するステップと、
各セクションについて、閾値強度を特定するステップと、前記特定のデータポイントの前記強度値を前記特定のデータポイントの前記セクションの前記閾値強度の値と比較することにより、前記複数のデータポイントの特定のデータポイントのそれぞれを評価することにより、プロセッサーが前記複数のデータポイントからレーンマーカのデータポイントの集合を生成するステップと、
後に使用するために前記レーンマーカのデータポイントの集合を記憶するステップと、を備える方法。 A method,
Accessing scan data collected for a road, wherein the scan data includes a plurality of data points having object location information and intensity information;
Dividing the plurality of data points into a plurality of sections;
For each section, identifying a threshold intensity and comparing the intensity value of the specific data point with the threshold intensity value of the section of the specific data point Generating a set of lane marker data points from the plurality of data points by evaluating each of the data points;
Storing the set of data points of the lane marker for later use.
前記複数のビームの第２のビームに関係付けられる第２のスキャンデータにアクセスするステップであって、前記第２のスキャンデータは物体に対する位置及び強度情報を有する第２の複数のデータポイントを含む、前記ステップと、
前記第２の複数のデータポイントを第２の複数のセクションに分割するステップと、
各第２のセクションについて、前記第２のセクションの前記データポイントを評価してそれぞれの平均強度とそれぞれの強度の標準偏差を決定するステップと、
各第２のセクションについて、前記それぞれの平均強度及び前記それぞれの強度の標準偏差に基づいて閾値強度を決定するステップと、
前記特定のデータポイントの前記強度値を前記特定のデータポイントの前記第２のセクションの前記閾値強度の値と比較することにより、前記第２の複数のデータポイントの特定のデータポイントのそれぞれを評価することにより、前記第２の複数のデータポイントからレーンマーカのデータポイントの第２の集合を生成するステップと、
後の使用のためにレーンマーカのデータポイントの前記第２の集合を記憶するステップと、をさらに備える、請求項１に記載の方法。 The scan data is collected using a laser having a plurality of beams, the accessed scan data is related to a first beam of the plurality of beams, and the method includes:
Accessing second scan data associated with a second beam of the plurality of beams, wherein the second scan data includes a second plurality of data points having position and intensity information relative to an object. Said step;
Dividing the second plurality of data points into a second plurality of sections;
For each second section, evaluating the data points of the second section to determine a respective mean intensity and a standard deviation of each intensity;
Determining a threshold intensity for each second section based on the respective average intensity and the standard deviation of the respective intensity;
Evaluating each of the specific data points of the second plurality of data points by comparing the intensity value of the specific data points with the threshold intensity value of the second section of the specific data points Generating a second set of lane marker data points from the second plurality of data points;
2. The method of claim 1, further comprising storing the second set of lane marker data points for later use.
前記セクションの所与のセクションについて前記閾値強度を特定するステップは、前記所与のセクションの前記平均強度と前記強度の標準偏差に基づいて行われる、請求項１に記載の方法。 For each section, further comprising evaluating the data points of that section to determine a respective mean intensity and a standard deviation of each intensity;
The method of claim 1, wherein identifying the threshold intensity for a given section of the section is performed based on the average intensity of the given section and a standard deviation of the intensity.
レーンマーカのデータポイントの集合を記憶するメモリと、
前記メモリに接続されたプロセッサーとを備え、前記プロセッサーは、
道路について収集されたスキャンデータにアクセスし、前記スキャンデータは、物体の位置情報と強度情報を有する複数のデータポイントを含み、
前記複数のデータポイントを複数のセクションに分割し、
各セクションについて、そのセクションの前記データポイントを評価して、それぞれの平均強度とそれぞれの強度の標準偏差を決定し、
各セクションについて、それぞれの平均強度とそれぞれの強度の標準偏差に基づいて閾値強度を決定し、
前記特定のデータポイントの前記強度値を前記特定のデータポイントの前記セクションの前記閾値強度の値と比較して、前記複数のデータポイントの特定のデータポイントのそれぞれを評価することにより、前記複数のデータポイントからレーンマーカのデータポイントの集合を生成し、
後の使用のために前記レーンマーカのデータポイントの集合を前記メモリに記憶する、ように構成されるデバイス。 A device,
A memory for storing a set of lane marker data points;
A processor connected to the memory, the processor comprising:
Accessing scan data collected for a road, wherein the scan data includes a plurality of data points having object location information and intensity information;
Dividing the plurality of data points into sections;
For each section, evaluate the data points for that section to determine the respective mean intensity and the standard deviation of each intensity,
For each section, determine the threshold intensity based on the respective average intensity and the standard deviation of each intensity,
Comparing the intensity value of the specific data point with the threshold intensity value of the section of the specific data point to evaluate each of the specific data points of the plurality of data points; Generate a set of lane marker data points from the data points,
A device configured to store a set of data points of the lane marker in the memory for later use.
各セクションについて、そのセクションの前記データポイントを評価して、それぞれの平均強度とそれぞれの強度の標準偏差を決定し、
前記所与のセクションについて前記それぞれの平均強度と前記それぞれの強度の標準偏差に基づいて、前記閾値強度を特定するようにさらに構成される、請求項１２に記載のデバイス。 The processor is
For each section, evaluate the data points for that section to determine the mean intensity and standard deviation of each intensity,
The device of claim 12, further configured to identify the threshold intensity based on the respective average intensity and a standard deviation of the respective intensity for the given section.
道路について収集されたスキャンデータにアクセスするステップであって、前記スキャンデータは物体の位置情報と強度情報を有する複数のデータポイントを含む前記ステップと、
前記複数のデータポイントを複数のセクションに分割するステップと、
各セクションについて、そのセクションの前記データポイントを評価して、それぞれの平均強度とそれぞれの強度の標準偏差を決定するステップと、
各セクションについて、前記それぞれの平均強度と前記それぞれの強度の標準偏差に基づいて閾値強度を決定するステップと、
前記特定のデータポイントの前記強度値を前記特定のデータポイントの前記セクションの前記閾値強度値と比較することにより、前記複数のデータポイントの特定のデータポイントのそれぞれを評価することにより、前記複数のデータポイントからレーンマーカのデータポイントの集合を生成するステップと、
後に使用するために前記レーンマーカのデータポイントの集合を前記メモリに記憶するステップと、を備える、コンピュータ可読媒体。 A tangible computer readable medium storing instructions of a computer readable program, wherein when the instructions are executed by a processor, the processor performs a method due to the instructions, the method comprising:
Accessing scan data collected for a road, wherein the scan data includes a plurality of data points having object position information and intensity information;
Dividing the plurality of data points into a plurality of sections;
For each section, evaluating the data points of that section to determine a respective mean intensity and a standard deviation of each intensity;
For each section, determining a threshold intensity based on the respective average intensity and the standard deviation of the respective intensity;
By evaluating each of the plurality of data points by comparing the intensity value of the specific data point with the threshold intensity value of the section of the specific data point. Generating a set of lane marker data points from the data points;
Storing the set of data points of the lane marker in the memory for later use.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/427,964 | 2012-03-23 | ||
US13/427,964 US20130253753A1 (en) | 2012-03-23 | 2012-03-23 | Detecting lane markings |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2015501915A Division JP6453209B2 (en) | 2012-03-23 | 2013-03-21 | Lane marking detection |
Publications (1)
Publication Number | Publication Date |
---|---|
JP2018026150A true JP2018026150A (en) | 2018-02-15 |
Family
ID=49212734
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2015501915A Active JP6453209B2 (en) | 2012-03-23 | 2013-03-21 | Lane marking detection |
JP2017187738A Pending JP2018026150A (en) | 2012-03-23 | 2017-09-28 | Detection of lane marking |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2015501915A Active JP6453209B2 (en) | 2012-03-23 | 2013-03-21 | Lane marking detection |
Country Status (6)
Country | Link |
---|---|
US (1) | US20130253753A1 (en) |
EP (1) | EP2812222A4 (en) |
JP (2) | JP6453209B2 (en) |
KR (1) | KR20140138762A (en) |
CN (2) | CN107798305B (en) |
WO (1) | WO2014003860A2 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20200054373A (en) * | 2018-11-06 | 2020-05-20 | 현대자동차주식회사 | Method and apparatus for recognizing driving vehicle position |
WO2022102114A1 (en) * | 2020-11-16 | 2022-05-19 | 三菱電機株式会社 | Vehicle control system |
WO2022130896A1 (en) * | 2020-12-15 | 2022-06-23 | 株式会社豊田自動織機 | Forklift |
Families Citing this family (33)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DE102011081397A1 (en) * | 2011-08-23 | 2013-02-28 | Robert Bosch Gmbh | Method for estimating a road course and method for controlling a light emission of at least one headlight of a vehicle |
US8880273B1 (en) | 2013-01-16 | 2014-11-04 | Google Inc. | System and method for determining position and distance of objects using road fiducials |
US9062979B1 (en) | 2013-07-08 | 2015-06-23 | Google Inc. | Pose estimation using long range features |
US20150120244A1 (en) * | 2013-10-31 | 2015-04-30 | Here Global B.V. | Method and apparatus for road width estimation |
JP5858446B2 (en) * | 2014-05-15 | 2016-02-10 | ニチユ三菱フォークリフト株式会社 | Cargo handling vehicle |
EP3154835A1 (en) | 2014-06-10 | 2017-04-19 | Mobileye Vision Technologies Ltd. | Top-down refinement in lane marking navigation |
EP3183688B1 (en) | 2014-08-18 | 2023-08-23 | Mobileye Vision Technologies Ltd. | Recognition and prediction of lane constraints |
DE102015201555A1 (en) * | 2015-01-29 | 2016-08-04 | Robert Bosch Gmbh | Method and device for operating a vehicle |
KR101694347B1 (en) | 2015-08-31 | 2017-01-09 | 현대자동차주식회사 | Vehicle and lane detection method for the vehicle |
DE102015218890A1 (en) * | 2015-09-30 | 2017-03-30 | Robert Bosch Gmbh | Method and apparatus for generating an output data stream |
KR20170054186A (en) | 2015-11-09 | 2017-05-17 | 현대자동차주식회사 | Apparatus for controlling autonomous vehicle and method thereof |
JP2017161363A (en) * | 2016-03-09 | 2017-09-14 | 株式会社デンソー | Division line recognition device |
US10121367B2 (en) * | 2016-04-29 | 2018-11-06 | Ford Global Technologies, Llc | Vehicle lane map estimation |
JP2017200786A (en) * | 2016-05-02 | 2017-11-09 | 本田技研工業株式会社 | Vehicle control system, vehicle control method and vehicle control program |
DE102016214027A1 (en) | 2016-07-29 | 2018-02-01 | Volkswagen Aktiengesellschaft | Method and system for detecting landmarks in a traffic environment of a mobile unit |
JP6407447B1 (en) * | 2017-01-10 | 2018-10-17 | 三菱電機株式会社 | Traveling path recognition device and traveling path recognition method |
JP6871782B2 (en) * | 2017-03-31 | 2021-05-12 | 株式会社パスコ | Road marking detector, road marking detection method, program, and road surface detector |
US11288959B2 (en) | 2017-10-31 | 2022-03-29 | Bosch Automotive Service Solutions Inc. | Active lane markers having driver assistance feedback |
KR102464586B1 (en) * | 2017-11-30 | 2022-11-07 | 현대오토에버 주식회사 | Traffic light location storage apparatus and method |
CN108319262B (en) * | 2017-12-21 | 2021-05-14 | 合肥中导机器人科技有限公司 | Filtering method for reflection points of laser reflector and laser navigation method |
US10684131B2 (en) | 2018-01-04 | 2020-06-16 | Wipro Limited | Method and system for generating and updating vehicle navigation maps with features of navigation paths |
DE102018203440A1 (en) * | 2018-03-07 | 2019-09-12 | Robert Bosch Gmbh | Method and localization system for creating or updating an environment map |
DE102018112202A1 (en) * | 2018-05-22 | 2019-11-28 | Knorr-Bremse Systeme für Nutzfahrzeuge GmbH | Method and device for recognizing a lane change by a vehicle |
US10598791B2 (en) * | 2018-07-31 | 2020-03-24 | Uatc, Llc | Object detection based on Lidar intensity |
DK180774B1 (en) | 2018-10-29 | 2022-03-04 | Motional Ad Llc | Automatic annotation of environmental features in a map during navigation of a vehicle |
US10976747B2 (en) * | 2018-10-29 | 2021-04-13 | Here Global B.V. | Method and apparatus for generating a representation of an environment |
US11693423B2 (en) * | 2018-12-19 | 2023-07-04 | Waymo Llc | Model for excluding vehicle from sensor field of view |
WO2020133369A1 (en) * | 2018-12-29 | 2020-07-02 | Beijing Didi Infinity Technology And Development Co., Ltd. | Identifying a curb based on 3-d sensor data |
US20200393265A1 (en) * | 2019-06-11 | 2020-12-17 | DeepMap Inc. | Lane line determination for high definition maps |
US11209824B1 (en) * | 2019-06-12 | 2021-12-28 | Kingman Ag, Llc | Navigation system and method for guiding an autonomous vehicle through rows of plants or markers |
KR102355914B1 (en) * | 2020-08-31 | 2022-02-07 | (주)오토노머스에이투지 | Method and device for controlling velocity of moving body based on reflectivity of driving road using lidar sensor |
US11776282B2 (en) | 2021-03-26 | 2023-10-03 | Here Global B.V. | Method, apparatus, and system for removing outliers from road lane marking data |
CN113758501A (en) * | 2021-09-08 | 2021-12-07 | 广州小鹏自动驾驶科技有限公司 | Method for detecting abnormal lane line in map and readable storage medium |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH09319872A (en) * | 1996-05-28 | 1997-12-12 | Matsushita Electric Ind Co Ltd | Road white line detector, curvature radium calculator, and navigation device |
JPH117534A (en) * | 1997-06-17 | 1999-01-12 | Nissan Motor Co Ltd | Road white line detection device |
JP2003030792A (en) * | 2001-07-12 | 2003-01-31 | Nissan Motor Co Ltd | Device and method for discriminating type of object |
JP2011210165A (en) * | 2010-03-30 | 2011-10-20 | Denso Corp | Detection device |
JP2011221005A (en) * | 2010-03-26 | 2011-11-04 | Denso Corp | Division line detector and method for detecting division line |
Family Cites Families (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP3997885B2 (en) * | 2002-10-17 | 2007-10-24 | 日産自動車株式会社 | Lane marker recognition device |
FR2864932B1 (en) * | 2004-01-09 | 2007-03-16 | Valeo Vision | SYSTEM AND METHOD FOR DETECTING CIRCULATION CONDITIONS FOR A MOTOR VEHICLE |
JP2006208223A (en) * | 2005-01-28 | 2006-08-10 | Aisin Aw Co Ltd | Vehicle position recognition device and vehicle position recognition method |
US7561032B2 (en) * | 2005-09-26 | 2009-07-14 | Gm Global Technology Operations, Inc. | Selectable lane-departure warning system and method |
US7640122B2 (en) * | 2007-11-07 | 2009-12-29 | Institut National D'optique | Digital signal processing in optical systems used for ranging applications |
US8332134B2 (en) * | 2008-04-24 | 2012-12-11 | GM Global Technology Operations LLC | Three-dimensional LIDAR-based clear path detection |
US8194927B2 (en) * | 2008-07-18 | 2012-06-05 | GM Global Technology Operations LLC | Road-lane marker detection using light-based sensing technology |
US8699755B2 (en) | 2009-02-20 | 2014-04-15 | Navteq B.V. | Determining travel path features based on retroreflectivity |
JP5188452B2 (en) * | 2009-05-22 | 2013-04-24 | 富士重工業株式会社 | Road shape recognition device |
JP5441549B2 (en) * | 2009-07-29 | 2014-03-12 | 日立オートモティブシステムズ株式会社 | Road shape recognition device |
JP5016073B2 (en) * | 2010-02-12 | 2012-09-05 | 株式会社デンソー | White line recognition device |
CN101914890B (en) * | 2010-08-31 | 2011-11-16 | 中交第二公路勘察设计研究院有限公司 | Airborne laser measurement-based highway reconstruction and expansion investigation method |
CN102508255A (en) * | 2011-11-03 | 2012-06-20 | 广东好帮手电子科技股份有限公司 | Vehicle-mounted four-wire laser radar system and circuit and method thereof |
CN106127113A (en) * | 2016-06-15 | 2016-11-16 | 北京联合大学 | A kind of road track line detecting method based on three-dimensional laser radar |
-
2012
- 2012-03-23 US US13/427,964 patent/US20130253753A1/en not_active Abandoned
-
2013
- 2013-03-21 CN CN201710991251.4A patent/CN107798305B/en not_active Expired - Fee Related
- 2013-03-21 KR KR1020147026504A patent/KR20140138762A/en not_active Application Discontinuation
- 2013-03-21 WO PCT/US2013/033315 patent/WO2014003860A2/en active Application Filing
- 2013-03-21 CN CN201380015689.9A patent/CN104203702B/en active Active
- 2013-03-21 JP JP2015501915A patent/JP6453209B2/en active Active
- 2013-03-21 EP EP13810454.2A patent/EP2812222A4/en not_active Withdrawn
-
2017
- 2017-09-28 JP JP2017187738A patent/JP2018026150A/en active Pending
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH09319872A (en) * | 1996-05-28 | 1997-12-12 | Matsushita Electric Ind Co Ltd | Road white line detector, curvature radium calculator, and navigation device |
JPH117534A (en) * | 1997-06-17 | 1999-01-12 | Nissan Motor Co Ltd | Road white line detection device |
JP2003030792A (en) * | 2001-07-12 | 2003-01-31 | Nissan Motor Co Ltd | Device and method for discriminating type of object |
JP2011221005A (en) * | 2010-03-26 | 2011-11-04 | Denso Corp | Division line detector and method for detecting division line |
JP2011210165A (en) * | 2010-03-30 | 2011-10-20 | Denso Corp | Detection device |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20200054373A (en) * | 2018-11-06 | 2020-05-20 | 현대자동차주식회사 | Method and apparatus for recognizing driving vehicle position |
KR102602224B1 (en) | 2018-11-06 | 2023-11-14 | 현대자동차주식회사 | Method and apparatus for recognizing driving vehicle position |
WO2022102114A1 (en) * | 2020-11-16 | 2022-05-19 | 三菱電機株式会社 | Vehicle control system |
JP7399313B2 (en) | 2020-11-16 | 2023-12-15 | 三菱電機株式会社 | vehicle control system |
WO2022130896A1 (en) * | 2020-12-15 | 2022-06-23 | 株式会社豊田自動織機 | Forklift |
Also Published As
Publication number | Publication date |
---|---|
WO2014003860A2 (en) | 2014-01-03 |
WO2014003860A3 (en) | 2014-03-06 |
CN107798305B (en) | 2021-12-07 |
CN104203702B (en) | 2017-11-24 |
JP6453209B2 (en) | 2019-01-16 |
CN104203702A (en) | 2014-12-10 |
KR20140138762A (en) | 2014-12-04 |
EP2812222A4 (en) | 2015-05-06 |
EP2812222A2 (en) | 2014-12-17 |
JP2015514034A (en) | 2015-05-18 |
CN107798305A (en) | 2018-03-13 |
US20130253753A1 (en) | 2013-09-26 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6453209B2 (en) | Lane marking detection | |
JP6677765B2 (en) | Map creation of working and non-working construction areas for autonomous driving | |
US11726493B2 (en) | Modifying behavior of autonomous vehicles based on sensor blind spots and limitations | |
US11807235B1 (en) | Modifying speed of an autonomous vehicle based on traffic conditions | |
US10037039B1 (en) | Object bounding box estimation | |
US8948958B1 (en) | Estimating road lane geometry using lane marker observations | |
US9709679B1 (en) | Building elevation maps from laser data | |
US8949016B1 (en) | Systems and methods for determining whether a driving environment has changed | |
US9261379B1 (en) | Intersection completer | |
US8874372B1 (en) | Object detection and classification for autonomous vehicles | |
US8565958B1 (en) | Removing extraneous objects from maps | |
US10094670B1 (en) | Condensing sensor data for transmission and processing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20170929 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20170929 |
|
A711 | Notification of change in applicant |
Free format text: JAPANESE INTERMEDIATE CODE: A711Effective date: 20180629 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20180910 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20180918 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20181127 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20190418 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20190703 |
|
A02 | Decision of refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A02Effective date: 20190718 |