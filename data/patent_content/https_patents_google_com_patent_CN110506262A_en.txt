CN110506262A - It is assisted using the context aware chat history of machine learning model - Google Patents
It is assisted using the context aware chat history of machine learning model Download PDFInfo
- Publication number
- CN110506262A CN110506262A CN201780089569.1A CN201780089569A CN110506262A CN 110506262 A CN110506262 A CN 110506262A CN 201780089569 A CN201780089569 A CN 201780089569A CN 110506262 A CN110506262 A CN 110506262A
- Authority
- CN
- China
- Prior art keywords
- text
- situation
- computing device
- mobile computing
- user
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2453—Query optimisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/335—Filtering based on additional data, e.g. user or group profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/335—Filtering based on additional data, e.g. user or group profiles
- G06F16/337—Profile generation, learning or modification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/38—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/387—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using geographical or spatial information, e.g. location
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L51/00—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail
- H04L51/42—Mailbox-related aspects, e.g. synchronisation of mailboxes
Abstract
System and method present disclose provides situation determination and/or Text Feature Extraction is realized in calculating equipment application using machine learning.Specific embodiment may include and use the Text Feature Extraction model of machine learning, has been trained to receive one or more message comprising text and has determined one or more parts of the text extracted from one or more message and the relative users situation of each of one or more parts of text for distributing to extraction.Additionally or alternatively, specific embodiment may include and determine model using the situation of machine learning, its one or more part for being trained to the available one or more input source receiving device data from mobile computing device, and determine the movable current user context of one or more that the user of instruction mobile computing device is currently participating in.
Description
Technical field
The present disclosure relates generally to machine learning.More specifically, this disclosure relates to realizing situation sense using machine learning model
Know the system and method that (context aware) chat history is assisted.
Background technique
Calculating equipment has many applications, and text information or other data are transmitted between different on-line customers.Example
Such as, text message transmitting or chat messages transmitting application transmit text data in a manner of unstructured between networked devices.This
The text data of sample can have the identifier including sender and/or recipient information and date and/or timestamp.So
And such application is not usually with essence and/or the text data different themes or class that are attributable to based on text data itself
Do not identify that the mode of the relevant portion of text data carrys out tissue text data.Therefore, it is necessary to facilitate with significant and useful
Mode by the portion of tissue of text data, classify and send to calculate equipment user solution.
The Present solutions of interested information can be related to through a large amount of text datas or other data for identification
Manual search.This is usually directed to the long list that user rolls or otherwise searches for chat recipient and/or chat messages
The plenty of time spent.Some chat messages transmitting or text message transmitting application include for by including in these applications
Text realize keyword search tool.However, even keyword search tool also lacks with significant relevant way
It polymerize the ability of the information from different messages and/or recipient.Specifically, there is identification related text in such application simultaneously
By its demand relevant to particular event or activity.
Summary of the invention
The aspect and advantage of embodiment of the disclosure will illustrate partly in the following description, or can be from description middle school
It practises, or can be learnt by the practice of embodiment.
One exemplary aspect of the disclosure is related to a kind of mobile computing device.The mobile computing device includes: at least one
A processor, display screen, machine learning situation determine model and at least one tangible non-transitory computer readable medium
Matter, store instruction, described instruction make the mobile computing device execute behaviour when being executed by least one described processor
Make.Situation determines that model has been trained to from the addressable one or more input source receiving device data of mobile computing device
One or more parts, and the one or more for determining that the user of instruction mobile computing device is currently participating in movable is worked as
Preceding user context.The operation that the mobile computing device executes includes: defeated from the addressable one or more of mobile computing device
Enter the first set that source obtains one or more parts of device data.The operation that the mobile computing device executes further include:
The situation that the first set of one or more parts of device data is input to machine learning is determined in model.The mobile meter
Calculate the operation that equipment executes further include: receive determining user context, the situation as machine learning determines the output of model.Institute
State the operation of mobile computing device execution further include: determine the user context having with the matched distribution of identified user context
, one or more parts of the text of one or more application from mobile computing device.The mobile computing device is held
Capable operation further include: one or more parts of text are provided, for the display screen display in mobile computing device.
User context determined by can determining from scheduled user context set, each user context indicate the movement
Calculate the difference activity that the user of equipment can participate in.The scheduled user context set may include for including shopping or
The different movable corresponding situations of the one or more of participation event.With being contextually relevant to the user in predesignated subscriber's situation set
The different activities of each of connection can correspond to main situation, and wherein also determine that the user context includes movable with description
The associated auxiliary situation of the classification of particular aspects.Mobile computing device can also include: one or more input sources, be configured
To provide the device data, the input source includes position sensor, motion sensor, audio sensor, imaging sensor
One or more of with calendar application.It can periodically determine with matched distributed with identified user context
One or more parts of user context, one or more application from mobile computing device text.The use
One or more of applications that family calculates equipment may include text message transmitting application, chat messages transmitting application, electronics
One or more of mail applications and voice mail application.One or more of parts of the text can be from two
Or more obtain in message threads between side.The operation can also include: to receive signal instruction from the user, the letter
Number instruction description about be provided for the display screen display of mobile computing device text it is one or more of
Partial feedback；And the data of one or more of parts of the text shown on a display screen are provided for description
Signal instruction from the user is provided in combination, and the situation as machine learning determines the training data of model.Determination has
With matched the distributed user context of identified user context, from the one or more of the mobile computing device
The step of one or more parts of the text of a application, may include: by the text input from one or more application to machine
In the Text Feature Extraction model of device study, the Text Feature Extraction model of machine learning has been trained to receive one or more comprising text
A message, and determine one or more parts of the text extracted from one or more of message and distribute to and mentioned
The relative users situation of each of one or more of parts of the text taken；And text of the reception as machine learning
One or more parts of the extracted text of the output of this extraction model, wherein distributing to described the one of extracted text
User context in each of a or multiple portions corresponds to identified current user context.
Another exemplary aspect of the disclosure is related to a kind of mobile computing device, comprising: at least one processor, machine learning
Text Feature Extraction model and at least one tangible non-transitory computer-readable medium, store instruction, described instruction exist
The mobile computing device is set to execute operation when being executed by least one described processor.Text Feature Extraction model can be instructed
Practice to receive the one or more message for including text, and determines the one of extracted text from one or more of message
The relative users situation of each of a or multiple portions and the one or more of parts for distributing to extracted text.
The operation that the mobile computing device executes includes: to obtain disappearing comprising text from the one or more application of mobile computing device
The first set of breath.The operation that the mobile computing device executes further include: input the first set of the message comprising text
Into the Text Feature Extraction model of machine learning.The operation that the mobile computing device executes further include: receive the from message
One or more parts of the extracted text of one set and the one or more of portions for distributing to extracted text
Point each of relative users situation, the output of the Text Feature Extraction model as machine learning.The mobile computing device
The operation of execution further include: provide at least part for distributing to the text of extraction of at least one relative users situation as defeated
Out.
The operation can also include the signal instruction that instruction specific user's situation is received from user, and wherein provides and divide
It includes: that specific use is distributed in offer that at least one at least part for corresponding to the text of the extraction of user context of dispensing, which is used as output,
At least part of the text of the extraction of family situation, for the display screen display in mobile computing device.The operation may be used also
To comprise determining that the movable current user contexts of one or more for indicating that the user of mobile computing device is currently participating in,
And wherein providing at least part for distributing to the text for the extraction that at least one corresponds to class of subscriber as output includes: to mention
At least one portion for corresponding to the text of the extraction of current user context is used to show on a display screen.Determine active user
Situation may include: that one or more portions of device data are obtained from the addressable one or more input sources of mobile computing device
The first set divided；The situation that the first set of one or more parts of device data is input to machine learning is determined into model
In, wherein situation determines that model has been trained to one or more portions from one or more of input source receiving device data
Point, and determine the movable current user context of one or more that the user of instruction mobile computing device is currently participating in；With
And receive the output that determining current user context determines model as the situation of machine learning.The current user context can be with
It is determined from scheduled user context set, the difference that the user of each user context instruction mobile computing device can participate in is living
It is dynamic, and optionally, wherein scheduled user context set includes for including shopping or participating in the one or more of event not
With movable corresponding situation.From in predesignated subscriber's situation set be contextually relevant to the user the different activities of each of connection can be right
It should also determine that the user context includes associated with the classification for describing movable particular aspects in main situation, and wherein
Auxiliary situation.The equipment can also include: one or more input sources, be configured to supply device data, the input
Source includes one or more of position sensor, motion sensor, audio sensor, imaging sensor and calendar application, and
And current user context is wherein at least determined in part with device data, and wherein it is possible to periodically described in realization
It obtains, input and reception operate.One or more of applications of the user calculating equipment may include text message transmitting
Using one or more of, chat messages transmitting application, e-mail applications and voice mail application.The operation can be with
It include: to receive signal instruction from the user, described in text of the signal instruction description about the extraction provided as output
At least part of feedback；And it provides in combination at least part of data of the description text provided as output
From the signal instruction of user, the training data of the Text Feature Extraction model as machine learning.
Another exemplary aspect of the disclosure is related to the tangible non-transitory meter of one or more storage computer-readable instructions
Calculation machine readable medium, the computer-readable instruction make one or more of processing when executed by one or more processors
Device executes operation.The operation includes: to obtain the of the message comprising text from the one or more application of mobile computing device
One collection.The operation further include: the first set of the message comprising text is input in the Text Feature Extraction model of machine learning,
Wherein Text Feature Extraction model can be trained to receive include text one or more message, and from one or more of
One or more of parts of the one or more parts and the text for distributing to extraction of extracted text are determined in message
Each of relative users situation.The operation further include: receive the extracted text of the first set from message
One or more parts and each of one or more of parts for distributing to extracted text mutually apply
Family situation, the output of the Text Feature Extraction model as machine learning.The operation further include: it is corresponding that offer distributes at least one
At least part of the text of the extraction of user context is as output.
There is provided at least one at least part for corresponding to the text of the extraction of user context described in distributing to is used as output can
To include: to provide described at least part of extracted text for showing.Described instruction can also include: to receive description to close
In the signal instruction of at least part of feedback of the text of the extraction provided as output；And with description as output
At least part of data of the text of the extraction of offer provide signal instruction from the user in combination, as machine learning
Text Feature Extraction model training data.
Another exemplary aspect of the disclosure is related to the tangible non-transitory meter of one or more storage computer-readable instructions
Calculation machine readable medium, the computer-readable instruction make one or more of processing when executed by one or more processors
Device executes operation.The operation includes: to obtain device data from the addressable one or more input sources of mobile computing device
The first set of one or more parts.The operation further include: by the first set of one or more parts of device data
The situation for being input to machine learning determines in model that wherein situation determines that model has been trained to from one or more of inputs
One or more parts of source receiving device data, and determine one that the user of instruction mobile computing device is currently participating in
Or multiple movable current user contexts.The operation further include: receive determining current user context as machine learning
Situation determines the output of model.The operation further include: it is determining with it is identified it is being contextually relevant to the user, set from mobile computing
One or more parts of the text of standby one or more application.The operation further include: provide the one of text or
Multiple portions are for the display screen display in mobile computing device.The one or more of storage computer-readable instruction have
The non-transitory computer-readable medium of shape, wherein it is determining with it is identified it is being contextually relevant to the user, come from mobile computing device
One or more parts of text of one or more application may include: by the text from one or more of applications
It is input in the Text Feature Extraction model of machine learning, the Text Feature Extraction model of the machine learning is trained to receive comprising text
One or more message, and from one or more of message determine extracted text one or more parts, with
And the relative users situation of each of one or more parts for distributing to extracted text；And it receives and is used as machine
One or more parts of the extracted text of the output of the Text Feature Extraction model of study, wherein distributing to extracted text
One or more of parts in each part user context correspond to identified current user context.Described instruction
It can also include: reception signal instruction, signal instruction description is mentioned about for the display screen display in mobile computing device
The feedback of one or more of parts of the text of confession；And the text shown on a display screen is provided for description
The data of one or more of parts provide signal instruction from the user in combination, and the situation as machine learning determines
The training data of model.
It should be appreciated that feature described in context in one aspect can it is described above it is otherwise up and down
It is realized in text.With reference to the following description and the appended claims, be better understood with the various embodiments of the disclosure these and its
His features, aspects and advantages.Comprising in the present specification and constitute part thereof of attached drawing show the disclosure example implement
Example, and be used to explain relative theory together with specification.
Detailed description of the invention
Elaborate being discussed in detail for the embodiment for being directed to those of ordinary skill in the art in the description with reference to attached drawing,
In:
Fig. 1 depicts the block diagram of example mobile computing device according to an example embodiment of the present disclosure；
Fig. 2 depicts the block diagram of the exemplary computing system of execution machine learning according to an example embodiment of the present disclosure；
Fig. 3 depicts the frame of the first Example Computing Device of execution machine learning according to an example embodiment of the present disclosure
Figure；
Fig. 4 depicts the frame of the second Example Computing Device of execution machine learning according to an example embodiment of the present disclosure
Figure；
Fig. 5 depicts sample text according to an example embodiment of the present disclosure and extracts model arrangement；
Fig. 6 depicts example scenarios according to an example embodiment of the present disclosure and determines that model is arranged；
Fig. 7 depict according to an example embodiment of the present disclosure with chat messages transmit apply associated example user circle
Face；
Fig. 8 depicts the illustrative data base record of the specified text for extraction according to an example embodiment of the present disclosure；
Fig. 9 depict according to an example embodiment of the present disclosure with determining example user circle for being contextually relevant to the user connection
Face；
Figure 10 depicts example user interface associated with the text of extraction according to an example embodiment of the present disclosure；
Figure 11 depict according to an example embodiment of the present disclosure for executing the of the machine learning for situation determination
The flow chart of one exemplary method；
Figure 12 depict according to an example embodiment of the present disclosure for executing the of the machine learning for being used for Text Feature Extraction
The flow chart of two exemplary methods；
Figure 13 depicts the example that model is extracted for training machine learning text according to an example embodiment of the present disclosure
The flow chart of method；And
Figure 14 depicts the situation for training machine study according to an example embodiment of the present disclosure and determines showing for model
The flow chart of example method.
Specific embodiment
In general, the disclosure is directed to using machine learning realizes that situation is determining and/or text mentions in calculating equipment application
The system and method taken.Specifically, the system and method for the disclosure may include and use the Text Feature Extraction model of machine learning,
The model is trained to receive one or more message comprising text and determine from one or more message extracted
Each of one or more parts of text and the one or more parts for distributing to extracted text are mutually applied
Family situation.Additionally or alternatively, the system and method for the disclosure may include and determine model using the situation of machine learning, should
Model is trained to one or more portions of the available one or more input source receiving device data from mobile computing device
Point, and determine the movable current user context of one or more that the user of instruction mobile computing device is currently participating in.
The user context that is distributed by Text Feature Extraction model and/or by situation determine current user context that model determines can from it is various
Activity and the associated scheduled different user situation set of corresponding classification (for example, doing shopping, taking exercise, participating in meeting, participate in social
Party etc.) in determine.When determining that user is in particular context, the text data of the extraction of particular context can will be distributed to
It is supplied to user.In this way, can notify user or user that can more easily search for automatically when operating mobile computing device
To obtain related text or other data.For example, mobile device (for example, smart phone) or use text based apply (example
Such as, chat messages transmitting application) other calculate equipment can provide for summarizing text data and with structuring and automation
Mode provides it to the integration tool of user.
In an example embodiment, consider to operate chat messages transmitting just on its mobile computing device in the first user
Using when two users between ongoing dialogue.Ongoing dialogue includes discussing that they still need for that will lift
The message of certain food items of capable activity purchase.For example, message may include such as " he S！Sunday breakfast we still need
Want bread and butter " text.Talk may not continue about that topic, and between two users there may be with evening
It fetes unrelated intervention message.However, next time when determining that the first user or second user are in particular context (for example, in quotient
Shop or online shopping), they will desire access to and/or be automatically presented with the video all related text datas (for example, bread, butter,
On May 7th, 2017 (wherein May 7 was the Sunday mentioned in message)) or from related to particular context (for example, shopping)
Its chat messages history other information.For example, mobile computing device, which can be configured as to actively generate, has " bread, Huang
The notice of oil, on May 7th, 2017 " reminds the when mobile computing device detects that the first user comes into shopping situation
One user buys anything.
In some implementations, mobile computing device is (for example, the mobile meter of such as smart phone or other mobile devices
Calculate equipment) may include at least one processor He at least one tangible non-transitory computer-readable medium, store
Instruction, when executed by least one processor, makes mobile computing device execute operation.Mobile computing device can also include text
This extraction model.In some implementations, Text Feature Extraction model is the Text Feature Extraction model of machine learning.For example, engineering
Practising Text Feature Extraction model may include one or more neural networks (for example, deep neural network), support vector machines, decision
Tree, aggregation model, k- nearest neighbor model, Bayesian network or the other types including linear model and/or nonlinear model
Model.Exemplary neural network may include feedforward neural network, convolutional neural networks, recurrent neural network (for example, shot and long term
Remember (LSTM) recurrent neural network, gate recurrence unit (GRU) neural network) or other forms neural network.
In some implementations, mobile computing device can be accessed additionally or alternatively and be stored remotely from mobile computing
The Text Feature Extraction model of the remote location (for example, in remote server location of supervisor's Text Feature Extraction application) of equipment.
Mobile computing device can calculate equipment application (for example, text message transmitting application, chat disappear from one or more
One or more of breath transmitting application, e-mail applications and/or voice mail application) to obtain include the first of text data
Massage set.In some implementations, text data can be continuously obtained and further analyze, so that in real time or close in fact
When obtain text data, and when sending and/or receive in text based application, is analyzed.In some implementations
In, it can periodically such as be obtained with the interval of regulation arrangement (for example, every five minutes) and further analyze text data.In
It, can be when one or more trigger events occur (for example, ought open or make on a mobile computing device in some implementations
Time, the time when mobile computing device determines new situation etc. when being applied with specific text based) it obtains and goes forward side by side one
Step analysis text data.The user of mobile computing device can be offered the opportunity to control whether can with and/or which message and/
Or text data be Text Feature Extraction model and/or mobile device other assemblies and it is relevant application or model it is addressable.
Mobile computing device can be additionally configured to for the first message set comprising text data being fed as input to
Machine learning Text Feature Extraction model.Then, mobile computing device can receive the output as Text Feature Extraction model from the
It one or more parts of the extraction text of one massage set and distributes in one or more parts of extracted text
The relative users situation of each.
In some implementations, it can be determined from scheduled different user situation set and distribute to extracted text
Each of one or more parts user context.Each user context can indicate that the user of mobile computing device can
With the difference activity of participation.In this way, scheduled user context set may include for one or more different movable corresponding
Situation, including do shopping or participate in event.In some implementations, scheduled user context set may include one or more
Main situation and one or more auxiliary situations.For example, one or more main situations can correspond to different activity (examples
Such as, do shopping or participate in event), and one or more auxiliary situations can correspond to different movable particular aspects.
For example, auxiliary situation can describe classification associated with activity.One example user situation can have shopping
Main situation and auxiliary situation associated with the categories class of shopping (for example, furniture shopping, grocery store shopping, clothes purchase
Object etc.).Another example user situation can have the main situation of participation event and associated with the categories class of event
Auxiliary situation (for example, meeting of working, participate in together with friend social event, the fitness class for participating in gymnasium etc.).
Mobile computing device can be additionally configured to distribute to the text for the extraction that at least one corresponds to user context
At least part is provided as exporting.In some implementations, such text extracted can be provided based in movement
Calculate the display screen display of equipment.In some implementations, the text of this extraction can store the text in the distribution of extraction
In database.The text database of the distribution of extraction may include multiple data notes for example corresponding with the text of extraction
Record.Each data record may include a part of the text of such as extraction, one or more associated with the text extracted
Identifier is (for example, message identifier, date identifier, time identifier, sender's identifier, one or more recipient's marks
Know symbol) and one or more situations distributed.The user context of distribution can include when available multiple user contexts (for example,
Main users situation, auxiliary user context, third user context etc.) or with other descriptors or class for being contextually relevant to the user connection
Not.
In some implementations, user can request information associated with particular context.It can be with for example, calculating equipment
The signal instruction of instruction specific user's situation is received from user.In response to receiving such signal instruction, distribution can be provided
To at least part of the text of the extraction of specific user's situation (extracted text is provided extremely for example, passing through as output
Few a part is for the display screen display in mobile computing device).
In some implementations, the distribution including extraction can be initiatively provided based on determining current user context
The notice of text data is as output.For example, calculating equipment can be configured as the use for automatically determining instruction mobile computing device
The movable current user context of one or more that family is currently participating in.It is then possible to provide using Text Feature Extraction model point
At least part of the text of the extraction of dispensing current user context is as output (for example, by providing extracted text
At least part is for the display screen display in mobile computing device).
In some implementations, mobile computing device can also include that situation determines model.In some implementations,
Situation determines that model is that the situation of machine learning determines model.For example, the situation of machine learning determines that model may include one
Or multiple neural networks (for example, deep neural network), support vector machines, decision tree, aggregation model, k- nearest neighbor model,
Bayesian network or other kinds of model including linear model and/or nonlinear model.Exemplary neural network may include
Feedforward neural network, convolutional neural networks, recurrent neural network are (for example, shot and long term remembers (LSTM) recurrent neural network, gate
Recurrence unit (GRU) neural network) or other forms neural network.
In some implementations, mobile computing device can be accessed additionally or alternatively and be stored remotely from mobile computing
The situation of the remote location (for example, determining the remote server location of application in supervisor's situation) of equipment determines model.
Mobile computing device can obtain the first of one or more parts of device data from one or more input sources
Set.It can provide that chance control whether and/or which device data by situation determines model to the user of mobile computing device
And/or the other assemblies and related application or model of mobile computing device are obtained and be may have access to.
In some implementations, one or more input sources can be locally available in mobile computing device.Some
In implementation, one or more input sources can be additionally or alternatively via the electricity of the user to network with mobile computing device
Sub- equipment is available (for example, the input source in the wearable computing devices of the user of electronic communication is carried out with mobile computing device).
Example input source may include one or more sensors, for example, one or more position sensors are (for example, the whole world
Alignment sensor (GPS), wireless beacon etc.), one or more motion sensor (for example, accelerometer, magnetometer, gyroscope,
Compass etc.), one or more audio sensor (for example, microphone), one or more imaging sensors (for example, camera) or its
His sensor.Example input source can also include one or more application, for example, calendar application, map or other navigation applications,
Communications applications, document creation application etc..In this way, may include being based on sensing from the device data that one or more input sources obtain
The data of device and/or data based on application.Sensor-based data may include original sensor data and/or can wrap
Include summary and/or the classification of original sensor data.Similarly, the data based on application may include original application data and/
It or may include summary and/or the classification of original application data.
Mobile computing device can be additionally configured to using the first set of one or more parts of device data as defeated
The situation for entering to be supplied to machine learning determines model.Then, mobile computing device can receive determining current user context and make
The output of model is determined for situation.Current user context can determine from scheduled user context set, the scheduled use
The Text Feature Extraction model of various pieces of the family situation set for example, from that can distribute extracted text to it uses identical
Predesignated subscriber's situation set.
Mobile computing device can be additionally configured to determine from the one or more application of mobile computing device and by situation
Determine the one or more parts for the relevant text of current user context that model determines.For example, also being wrapped in mobile computing device
In the case where including Text Feature Extraction model as described herein, calculating equipment can be configured as access and be used by Text Feature Extraction model
Extracted distribution text database.It can analyze one or more in the text database for being stored in extracted distribution
The text or other information of extraction in a record determine current user context that model determines with by situation to determine to have
The record of the user context for the distribution matched.In some instances, the text database of extraction can additionally or alternatively be analyzed
Interior record has the record of date identifier and/or time identifier within a predetermined range to determine.In one example,
It can identify the record with nearest date identifier and/or time identifier.In another example, can identify has and spy
Surely the date identifier of connection and/or the record of time identifier are contextually relevant to the user (for example, participating in the conventional fitness class of gymnasium
Journey).One or more parts that text relevant to current user context can be provided (provide institute for example, passing through as output
At least part of the text of extraction is for the display screen display in mobile computing device).
According to another aspect of the present disclosure, in some implementations, Text Feature Extraction model and/or situation determine model or
Its at least part can be obtained via the Application Programming Interface (API) of the one or more application for providing on the computing device
.In some instances, first Text Feature Extraction model is requested access to using API, situation determines model and/or its portion
Point.Text Feature Extraction model, situation determine that model and/or its part can be responsible for for a part of the second application or with first
Using in identical calculating equipment or the individual special layer calculated in equipment, application or component.
According to another aspect of the present disclosure, novel loss function can be used and determining true (ground-truth) number
Model is determined according to upper training Text Feature Extraction model described herein and/or situation.More specifically, training computing system can be used
Training dataset including multiple determining truthful data set carrys out training text extraction model and/or situation determines model.
In some implementations, when training text extracts model to determine the text or other knots of related news, extraction
When structure information and the user context of distribution, Text Feature Extraction training dataset may include structured message (for example, comprising text
The message of notebook data etc.) and the respective labels of a large amount of previously observed message are described.
In one implementation, Text Feature Extraction training dataset includes first of the data corresponding to the message of record
Point, the message of the record includes the text data via the text based application relaying on mobile computing device.For example, working as
User operates one on mobile computing device and/or Networked electronic devices (for example, by wearable computing devices of user's operation)
When a or multiple text based applications (for example, chat messages, text message or e-mail applications), it can recorde and recorded
Message.Text Feature Extraction training dataset may also include second of the data for corresponding to the label of specific part of identification text
Divide or should be extracted as relevant other structures data (for example, image, video etc.).The second part of data can add
Ground or alternatively include equipment distribute to extracted text relevant portion different user situation label.In some cases
Under, it can be used and be applied to explain that the conventional heuristics of text data marks the message including text data automatically.For example, inspiring
Method may include being configured as detecting the rule or mode of predetermined phrase, such as " I needs to buy ", " you can bring ", " ...
Meeting " etc..It in some cases, can include the message of text data with hand labeled.In some cases, it can be used automatic
The combination of label and hand labeled carrys out retrtieval data.
In some implementations, in order to which training text extracts model, training computing system can will determine truthful data
The first part (for example, first part of the first exemplary training dataset) of set is input to the Text Feature Extraction model to be trained
In.In response to receiving such first part, Text Feature Extraction model exports one or more parts of the text extracted, each
Part has the user context distributed accordingly.The output of Text Feature Extraction model is predicted to determine the remainder of truthful data set
Divide (for example, second part of data).After such prediction, training computing system can be applied or otherwise be determined
Loss function, the function is by one or more parts of the text of the extraction exported by Text Feature Extraction model and corresponding distribution
User context is compared with the remainder that Text Feature Extraction model attempts the determination truthful data predicted.Then, training calculates
System can extract model (for example, by modification and text with training text by Text Feature Extraction model backpropagation loss function
The associated one or more weights of this extraction model).A part of model is extracted as training text, this input determines true
Real data determines that loss function and the processing by Text Feature Extraction model backpropagation loss function can be repeated as many times.
In some implementations, when training situation determines model to determine current user context, situation determines training
Data set may include device data from one or more input sources and describe a large amount of previously observed number of devices factually
The corresponding label of example.
In one implementation, situation determines that training dataset includes and the number of devices from one or more input sources
According to the first part of corresponding data.Device data may include for example passing from one or more position sensors, movement
Sensor, audio sensor, imaging sensor and/or other sensors sensor-based data and/or come from one or more
A calendar application, map or navigation application, communications applications, the data based on application of document creation application and/or other application.
For example, can be in user's operation mobile computing device and/or Networked electronic devices (for example, by the wearable computing of user's operation
Equipment) while recording equipment data.Situation determines that training dataset can also include corresponding to identification specific user at one section
Second of the data of the movable label of difference participated in time (for example, more days etc. in one day repeatedly, in one week/mono- month)
Point.It in some cases, can be by giving including the label in the second part that situation determines the data in training dataset
User's manual annotations of mobile computing device, while operation training application on a mobile computing device, the training application are designed
It include determining the label that training data is concentrated in situation to collect.In some cases, it can mark automatically or using automatic
The combination of label and hand labeled is to mark the device data including user context label.
In some implementations, in order to train situation to determine model, training computing system can will determine truthful data
The first part (for example, first part of the second exemplary training dataset) of set is input to the situation to be trained and determines model
In.In response to receiving such first part, situation determines the user of model output instruction mobile computing device currently
The movable user context of one or more of participation.Situation determines that the output of model is predicted to determine the residue of truthful data set
Partially (for example, second part of the second exemplary training dataset).After such prediction, training computing system can be applied
Or otherwise determine loss function, which will determine that the user context of model output and situation determine mould by situation
The remainder that type attempts the determination truthful data predicted is compared.Then, training computing system can be determined by situation
Model backpropagation loss function is to train situation to determine model (for example, determining model associated one with situation by modifying
A or multiple weights).A part that model is determined as training situation can be repeated several times input and determine truthful data, determination
Loss function and the processing that model backpropagation loss function is determined by situation.
According to another aspect of the present disclosure, in some implementations, it can use user feedback system to help to collect
Model is extracted for training text and/or situation determines the additional training data of model.For example, mobile computing device can be matched
The one or more user interfaces of offer are set to be used to prompt user in display screen display associated with mobile computing device
One or more portions of the description about determining user context and/or the text for the extraction for distributing to determining user context are provided
The signal instruction for the feedback divided.Signal instruction from the user can with describe determined by user context and/or distribute to really
The data of one or more parts of the text of the extraction of fixed user context provide together, as the text for machine learning
Extraction model and the situation of machine learning determine one or more training datas of model.
In some cases, user interface can be configured to user request information relevant to specific user's situation when or
When automatically determining of current operation (for example, determining model using described situation) in specific user's situation shows description
The information of the associated extraction text of specific user's situation.The interaction of user and user interface is (for example, by selection user interface
One or more icons, button or other interface elements of offer) it can star the anti-of the text for describing the distribution about extraction
The relaying of the signal instruction of feedback.For example, feedback can indicate that the text for the distribution extracted is useful or useless.Can provide option with
Feedback to the part of extracted text is provided, or the score of useful degree is provided.Then, which can be used for generating one
A or multiple labels, to include together with corresponding text data.Then the data of label can be added to Text Feature Extraction instruction
Practice in data set.
In some instances, user interface can be configured as the information that display describes identified user context.User
Interaction with user interface is (for example, pass through one or more icons, button or other Interface Elements for providing in selection user interface
Element) it can star relaying of the description about the signal instruction of the feedback of identified user context.For example, feedback can be confirmed,
Refusal and/or the user context of modification determination.Then, which can be used for generating label, for for determining user context
Relevant device data include together.Then the data of label can be added to situation and determines training dataset.
System and method described herein can provide many technical effects and benefit.For example, disclosed technology can be with
It advantageously solves to handle a large amount of texts or other data associated time and money in text based calculating equipment application
Source problem, to give calculating equipment user with the part of significant and useful mode tissue, classification and transmission text data.Institute
Disclosed technology provides automation solutions, can help to reduce user's manual search mass data the time it takes；
For example, user may not necessarily arduously scroll up and down in long chat history or e-mail thread, to find and specific feelings
The relevant comment in border or information.Therefore, system and method discussed here can help to reduce in traditional manual search method
The middle power of battery and computing resource that may be exhausted.In addition, being disappeared by only collecting and providing from relevant to specific user's situation
The text data extracted in breath can be minimized the data retrieval rank of mobile computing device as output.Because disclosed
System and method do not retrieve the exquisite detail of complete chat messages history, it is possible to realize that more simplified and effective technology solves
Scheme.The text of extraction can be distributed to different user contexts by disclosed system and method, are allowed and to be supplied to shifting
The dynamic particular event for calculating equipment user and/or the more timely and significant presentation of the relevant text data of activity.
Another example technique effect and benefit of the disclosure are to predict extracted text by the accuracy with raising
Relevant portion, the specified situation of related text and/or current user context determine output to improve Text Feature Extraction and/or situation.
For example, since the situation of machine learning determines model on a mobile computing device across one or more text based application operatings
The ability for considering the text data from multiple users, can be improved the level of accuracy that situation determines model.Similarly, due to
The Text Feature Extraction model of machine learning understand Message-text which is partially related to user and should be assigned to specifically
The ability of situation or classification, therefore the level of accuracy of Text Feature Extraction model can also be improved.
Another example technique effect and benefit of the disclosure are the Text Feature Extraction and/or situation definitive result of enhancing, can
It is customized by the specific user of one or more mobile computing devices.By using including from mobile meter associated with specific user
The training data for calculating the marking arrangement data that equipment obtains carrys out training machine Studying Situntion and determines model and/or machine learning text
Extract model, can be customized and be exported with user, thus provide for specialized text messages content associated with specific user and/or
The customization result of user context.Therefore, it is possible to use disclosed machine learning techniques are determining and/or use to provide Text Feature Extraction
More complicated and customization nuance during family situation is determining.When machine learning model includes described deep neural network
When, compared with multinomial, this model more preferably simulation complex text abstraction function and/or user context can determine function.
In this way, it is quasi- that the Text Feature Extraction model and/or situation of the disclosure determine that model can provide superior prediction if suitably trained
Exactness.
Another example technique benefit of the disclosure is improved scalability.Specifically, pass through neural network or other machines
Device learning model greatly reduces relative to hand-made the text data and/or user context data modeling of the distribution of extraction
Text Feature Extraction and/or situation determine the exploitation of algorithm needed for search time.For example, being calculated for hand-made Text Feature Extraction
Method, algorithm routine person needs to derive different messages exhaustively and/or how related message text portion is or uncorrelated, Yi Jiying
How the different piece of text is applied to the Heuristic Model of the different user situation of different scenes and/or different user by this.
Similarly, algorithm is determined for hand-made situation, algorithm routine person needs to derive how to determine difference exhaustively
Device data set (for example, sensing data and/or apply data) as corresponding to different scenes and/or different users
In different user situation Heuristic Model.In contrast, in order to use neural network as described herein or other machines
Learning art, can on training data appropriate training machine learn Text Feature Extraction model and/or machine learning situation
It determines model, if training system allows, can complete on a large scale.In addition, as new training data is available, machine
Device learning model can easily modify.
Referring now to the drawings, the example embodiment of the disclosure will be discussed in more detail.
Example apparatus and system
Fig. 1 depicts the block diagram of example mobile computing device 102 according to an example embodiment of the present disclosure.Mobile computing is set
Standby 102 can be configured or can operate to execute all aspects of this disclosure, including Text Feature Extraction model 112 and/or situation determine
The creation and/or use of model 114.
Mobile computing device 102 can be desk-top calculating equipment, lap-top computing devices, tablet computing device, mobile meter
Calculate equipment (for example, smart phone calculating equipment), the calculating equipment of vehicle (for example, Vehicular communication system, vehicle entertainment system,
Onboard navigation system) or including calculate equipment wearable device (for example, have calculate equipment wrist-watch, have calculating equipment
Glasses, virtual or augmented reality calculate equipment).Additional and/or substitution calculating equipment can be provided.
Mobile computing device 102 may include one or more processors 104 and memory 106.One or more processing
Device 104 can be any suitable processing equipment (for example, processor core, microprocessor, ASIC, FPGA, GPU, controller, micro-
Controller etc.), and the multiple processors that can be a processor or be operably connected.Memory 106 may include one
A or multiple non-transitory computer-readable storage medias, RAM, ROM, EEPROM, EPROM, flash memory device, disk etc.,
And their combination.Memory 106, which can store, to be executed by one or more processors 104 so that mobile computing device 102
Execute the data 108 and instruction 110 of operation.
Mobile computing device 102 can store or otherwise include Text Feature Extraction model 112.For example, Text Feature Extraction
Model 112 can be or can otherwise include the Text Feature Extraction model of machine learning.For example, machine learning Text Feature Extraction
Model may include one or more neural networks (for example, deep neural network), support vector machines, decision tree, aggregation model,
K- nearest neighbor model, Bayesian network or the other kinds of multilayered model including linear model and/or nonlinear model.Show
Example neural network may include feedforward neural network, convolutional neural networks, recurrent neural network (for example, shot and long term is remembered
(LSTM) recurrent neural network, gate recurrence unit (GRU) neural network) or other forms neural network.In some realizations
In mode, mobile computing device 102 can additionally or alternatively access the long-range position for being stored remotely from mobile computing device 102
The Text Feature Extraction model for setting (for example, in remote server location of supervisor's Text Feature Extraction application), such as described in Fig. 2
's.Fig. 5 includes some additional aspects associated with Text Feature Extraction model 112.
In some implementations, mobile computing device 102 can also include that situation determines model 114.In some realizations
In mode, situation determines that model 114 is that the situation of machine learning determines model.For example, the situation of machine learning determines that model can
To include one or more neural networks (for example, deep neural network), support vector machines, decision tree, aggregation model, k- nearest
Neighbor model, Bayesian network or the other kinds of multilayered model including linear model and/or nonlinear model.Exemplary neural
Network may include feedforward neural network, convolutional neural networks, recurrent neural network (for example, shot and long term remembers (LSTM) recurrence
Neural network, gate recurrence unit (GRU) neural network) or other forms neural network.In some implementations, mobile
The remote location for being stored remotely from mobile computing device can additionally or alternatively be accessed (for example, being responsible for by calculating equipment 102
Situation determine application remote server location) situation determine model, as depicted in Figure 2.Fig. 6 includes true with situation
The associated some additional aspects of cover half type 114.
Mobile computing device 102 can also include model trainer 116, use for example one or more loss functions
The various training of backpropagation or learning art training text extract model 112.For example, model trainer 116 can train text
This extraction model 112 determines the text extracted from one or more message to receive one or more message comprising text
One or more parts and each of one or more parts of text for distributing to extraction relative users situation.
Model trainer 116 can be used loss function and carry out training text extraction model 112, and loss function description is really counted with determining
According to gathering associated comment tag and from the difference between the received output data of Text Feature Extraction model 112.Specifically, one
In a little implementations, when modifying Text Feature Extraction model 112 (for example, at least one power for passing through modification Text Feature Extraction model 112
Weight), loss function as 112 backpropagation of Text Feature Extraction model can be passed through.
Model trainer 116 can be additionally configured to using the various of such as backpropagation of one or more loss functions
Trained or learning art training situation determines model 114.Situation can be trained to determine model 114 can visit from mobile computing device
The one or more parts for the one or more input source receiving device data asked, and determine the user of instruction mobile computing device
The movable current user context of one or more currently participated in.In some instances, loss can be used in model trainer 116
Function trains situation to determine model 114, loss function description comment tag associated with truthful data set is determined and
The difference between the received output data of model 114 is determined from situation.Specifically, in some implementations, in modification situation
It determines (for example, at least one weight for determining model 114 by modifying situation) when model 114, mould can be determined by situation
Loss function as 114 backpropagation of type.
Model trainer 116 may include for providing the computer logic of desired function.Model trainer 116 can be with
It is realized with hardware, firmware and/or the software of control general processor.For example, in some implementations, model trainer
116 include storage on a storage device, the program file that is loaded into memory and is performed by one or more processors.At it
In his implementation, model trainer 116 includes that one or more set of computer-executable instructions are closed, and is stored in such as RAM
In the tangible computer readable storage medium of hard disk or optically or magnetically medium.
Mobile computing device 102 can also include one or more input sources 120.In some implementations, one or
Multiple input sources 120 can be additionally or alternatively available via the electronic equipment of the user to network with mobile computing device 102
(for example, the input source in wearable computing devices associated with the user of electronic communication can be carried out with mobile computing device 102
Also associated with user).
Example input source 120 may include one or more sensors, for example, 121 (example of one or more position sensors
Such as, GPS sensor (GPS), wireless beacon etc.), one or more motion sensor 122 is (for example, accelerometer, magnetic force
Meter, gyroscope, compass etc.), one or more audio sensor 123 (for example, microphone), one or more imaging sensors
124 (for example, cameras) or other sensors.Example input source 120 can also include one or more application, for example, calendar is answered
It is answered with 125, chat application 126 (for example, the application of text application, message transmission, e-mail applications etc.), map or other navigation
With, communications applications, document creation application etc..In this way, may include from the device data that one or more input sources 120 obtain
Sensor-based data and/or data based on application.Sensor-based data may include original sensor data and/
It or may include summary and/or the classification of original sensor data.Similarly, the data based on application may include original application
Data and/or may include original application data summary and/or classification.
In some implementations, it can be used as a part storage of data 108 from the device data that input source 120 obtains
In mobile computing device 102.It should be appreciated that can be provided for the user of mobile computing device 102 chance control whether and/or
Which device data of person is determined the other assemblies of model 114 and/or mobile computing device 102 by Text Feature Extraction model 112, situation
And related application or model are obtained and be may have access to.
Mobile computing device 102 can also include one or more output precisions 128.In some implementations, one
Or multiple output precisions 128 may include display screen 129, can provide thereon the text of extraction one or more parts and/
Or one or more situations determined and/or include information that or one or more user interfaces of other relevant informations,
For being shown to the user of mobile computing device 102.In some implementations, display screen 129 is configured with mobile computing device
The touch sensitive surface that 102 user can interact with the graphic user interface provided on display screen 129, to provide for from movement
The user for calculating equipment 102 receives the component of signal instruction.
Fig. 2 depicts the block diagram of exemplary computing system 130 according to an example embodiment of the present disclosure.Computing system 130 is wrapped
Include the first client computing device 102a, the second client computing device 102b, machine learning communicated to connect by network 166
Computing system 132 and training computing system 150.It is any although illustrating only two client computing device 102a/102b
The client computing device 102a/102b of quantity can be connected to machine learning computing system 132 and/or instruction by network 166
Practice computing system 150.
First client computing device 102a and the second client computing device 102b can correspond to all describe as shown in figure 1
Mobile computing device 102 different instances or including Text Feature Extraction model 112 and/or situation determine model 114 and/or its
Other of associated component calculate equipment, as shown in Fig. 1 and described in referred to.In some implementations, the first client
End calculates equipment 102a and the second client computing device 102b and is communicatedly connected by network 166.The calculating of first client is set
Standby 102a and the second client communication device 102b can be additionally or alternatively directly connected to by communication channel 164.
In some instances, the first client computing device 102a and the second client computing device 102b all with given use
Family is associated, and can work together to realize the various aspects of disclosed technology.For example, the calculating of the first client is set
Standby 102a can correspond to smart phone, and the second client computing device can correspond to smartwatch, both can be with
It is configured as collecting data for being input to Text Feature Extraction model 112 and/or situation determines model 114 and/or will be with these
The associated output of model is supplied to the use of the first client computing device 102a and/or the second client computing device 102b
Family.
In some instances, the first client computing device 102a is associated with the first user, and the second client calculates
Equipment 102b is associated with second user.For example, the first client computing device 102a and the second client computing device 102b
It can include calculating associated first user of equipment 102a with first and calculating equipment 102b associated second with second
The specific application that user is used to communicate with one another is (for example, chat messages transmitting is applied, text message transmitting is applied, Email is answered
With, voice mail application).Use this executed by the first client computing device 102a and the second client computing device 102b
The message threads of kind of application creation can be when operating in the particular context that the textual portions of extraction are assigned to as user, quilt
Identify the source for extracting and being shown to one or more parts of the text of user.
Machine learning computing system 132 may include one or more processors 134 and memory 136.At one or more
Reason device 134 can be any suitable processing equipment (for example, processor core, microprocessor, ASIC, FPGA, GPU, controller,
Microcontroller etc.), and the multiple processors that can be a processor or be operably connected.Memory 136 may include
One or more non-transitory computer-readable storage medias, RAM, ROM, EEPROM, EPROM, flash memory device, disk etc.
And their combination.Memory 136, which can store, to be executed by one or more processors 134 so that machine learning computing system
132 execute the data 138 of operation and instruction 140.
In some implementations, machine learning computing system 132 include one or more server computing devices or with
Other modes are realized by one or more server computing devices.It include multiple server meters in machine learning computing system 132
In the case where calculating equipment, such server computing device can be according to sequence counting system structure, parallel computation architecture
Or some combinations are to operate.
Machine learning computing system 132 can store or otherwise include one or more machine learning models, packet
The situation of the Text Feature Extraction model 142 and/or machine learning that include machine learning determines model 146.For example, the text of machine learning
The situation for extracting model 142 and/or machine learning determines that model 146 can be or can otherwise include various engineerings
The model of habit, such as neural network (for example, depth recurrent neural network) or other multilayered nonlinear models, the mould based on recurrence
Type etc..Machine learning computing system 132 can be via the friendship with the training computing system 150 being communicatively coupled by network 166
The situation of the Text Feature Extraction model 142 and/or machine learning that mutually carry out training machine study determines model 146.Training computing system
150 can separate or can be a part of machine learning computing system 132 with machine learning computing system 132.Once machine
The Text Feature Extraction model 142 of device study and/or the Text Feature Extraction model 146 of machine learning are trained to, they can be provided to
Client computing device 102a and/or 102b is otherwise accessed by client computing device 102a and/or 102b.
Training computing system 150 may include one or more processors 152 and memory 154.One or more processors
152 can be any suitable processing equipment (for example, processor core, microprocessor, ASIC, FPGA, GPU, controller, micro-control
Device processed etc.), and the multiple processors that can be a processor or be operably connected.Memory 154 may include one
Or multiple non-transitory computer-readable storage medias, RAM, ROM, EEPROM, EPROM, flash memory device, disk etc. and
Their combination.Memory 154, which can store, to be executed by one or more processors 152 so that training computing system 150 executes
The data 156 and instruction 158 of operation.In some implementations, training computing system 150 includes one or more server meters
It calculates equipment or is otherwise realized by one or more server computing devices.
Training computing system 150 may include model trainer 160, the text learnt using 162 training machine of training data
This extraction model 142 and/or the situation of machine learning determine that model 146, training data 162 may include being stored in machine learning meter
The identical training data (for example, Text Feature Extraction training data 144 and/or situation determine training data 148) of calculation system 130.Instruction
The various training of such as backpropagation can be used in white silk computing system 150 or learning art carrys out implementation model training.It then can be with
Backpropagation is iterated through according to one or more algorithms and adjusts weight in the model of machine learning, and the algorithm includes but not
It is limited to gradient decline, stochastic gradient descent (SGD), self-adaption gradient decline (AdaGrad) and/or adaptive moments estimation (ADAM)
Algorithm.Model trainer 160 can execute what many general technology (for example, weight decaying, loss etc.) was being trained with improvement
The generalization ability of model.
Specifically, model trainer 160 can be learnt based on the set of Text Feature Extraction training data 144 come training machine
Text Feature Extraction model 142.The training data 144 of Text Feature Extraction may include for using novel loss function training machine
The determination truthful data of the Text Feature Extraction model 142 of habit.More specifically, training computing system 150 can be used including multiple true
The Text Feature Extraction training data 144 for determining truthful data set carrys out training machine learning text and extracts model 142.
In some implementations, when training machine study Text Feature Extraction model 142 with determine related news, extract
When text or other structures information and the user context of distribution, Text Feature Extraction training data 144 may include structured message
(for example, message comprising text data etc.) and the respective labels for describing a large amount of previously observed message.It is realized at one
In mode, Text Feature Extraction training data 144 includes the first part corresponding to the data of the message of record comprising via being based on
The application (for example, via chat application 126 on the mobile computing device 102 of Fig. 1) of text relays on a mobile computing device
Text data.For example, when user is in the visitor of the first client computing device 102a (for example, mobile computing device) and/or second
Family end calculates and operates one or more text based applications on equipment 102b (for example, having the wearable device for calculating equipment)
When (for example, chat messages transmitting, text message transmitting or e-mail applications), recorded message can recorde.Text mentions
Take training data 144 that can also include the specific part corresponding to identification text or relevant other structures should be extracted as
Change the second part of the data of the label of data (for example, image, video etc.).Data in Text Feature Extraction training data 144
Second part can additionally or alternatively include the different user situation that the relevant portion of extracted text is distributed in identification
Label.In some cases, it can be used and be applied to explain that the conventional heuristics of text data is marked automatically including textual data
According to message.For example, heuristics may include be configured as detection such as " I needs to buy ", " you can bring ", " ... see
The rule or mode of the predetermined phrase in face " etc..It in some cases, can include the message of text data with hand labeled.One
In a little situations, the combination that automatic label and hand labeled can be used carrys out retrtieval data.
In some implementations, for the Text Feature Extraction model 142 of training machine study, training computing system 150 can
The first part (for example, first part of Text Feature Extraction training data 144) for determining truthful data set to be input to and to instruct
The Text Feature Extraction model 142 of experienced machine learning.In response to receiving such first part, the Text Feature Extraction mould of machine learning
Type 142 exports one or more parts of the text of each extraction with the user context distributed accordingly.Machine learning
The output of Text Feature Extraction model 142 predicts the remainder for determining truthful data set (for example, Text Feature Extraction training data
144 second part).After such prediction, loss letter can be applied or otherwise be determined to training computing system 150
Number, the loss function by one or more parts of the text of the extraction exported by the Text Feature Extraction model 142 of machine learning and
The user context of corresponding distribution attempts the remainder for the determination truthful data predicted (for example, text with Text Feature Extraction model
Extract the second part of training data 144) it is compared.Then, training computing system 150 can pass through the text of machine learning
142 backpropagation loss function of model is extracted, with the Text Feature Extraction model 142 of training machine study (for example, passing through modification and machine
The associated one or more weights of the Text Feature Extraction model 142 of device study).In some implementations, such as
The Machine learning tools of TensorFlow and/or Theano can be used for executing damage by the Text Feature Extraction model 142 of machine learning
Lose the backpropagation of function.
In addition, model trainer 160 can determine the feelings that the set of training data 148 learns come training machine based on situation
Border determines model 146.Situation determines that training data 148 may include for using novel loss function training machine to learn
Situation determines the determination truthful data of model 146.More specifically, it is true including multiple determinations to train computing system 150 can be used
The situation of real data set determines that training data 148 carrys out the situation that training machine learns and determines model 146.
In some implementations, when the situation of training machine study determines model 146 to determine current user context,
Situation determines that training data 148 may include the device data from one or more input sources (for example, input source 120 of Fig. 1)
With the respective labels for describing a large amount of previously observed device data examples.In one implementation, the situation of machine learning
Determine that training data 148 includes the first part of data corresponding with the device data from one or more input sources.If
Standby data may include for example from one or more position sensors 121, motion sensor 122, audio sensor 123, figure
As sensor-based data of sensor 124 and/or other sensors and/or from one or more calendar applications 125, chat
It using 126 (for example, the application of text application, message transmission, e-mail applications etc.), map or navigation application, communications applications,
The data based on application of document creation application and/or other application.It is set for example, can be calculated in the first client of user's operation
Standby 102a (for example, mobile computing device) and/or the second client computing device 102b (calculate wearing for equipment for example, having
Wear equipment) while recording equipment data.Situation determines that training data 148 may further include and corresponds to identification at one section
Between specific user participates in (for example, secondary more than a day, more days of one week/moon etc.) movable labels of difference data second part.
It in some cases, can be by the user of given mobile computing device while operation training is applied on a mobile computing device
The label that manual annotations include in the second part that situation determines the data in training data 148, the training application are designed
To collect for including determining the label in training data 148 in situation.In some cases, it can mark automatically including user
The device data of situation label, or carry out marking arrangement data using the combination of automatic label and hand labeled.
In some implementations, in order to which the situation of training machine study determines model 146, training computing system 150 can
It to be trained so that the first part (for example, first part that situation determines training data) for determining truthful data set to be input to
The situation of machine learning determines model 146.In response to receiving such first part, the situation of machine learning determines model
The movable user context of one or more that the user of 146 output instruction mobile computing devices is currently participating in.Machine learning
Situation determine model 146 the output predict determine truthful data set remainder (for example, situation determines training data
148 second part).After such prediction, loss letter can be applied or otherwise be determined to training computing system 150
The situation of machine learning is determined that the user context that model 146 exports determines that model attempts to predict with situation by number, the loss function
The remainder (for example, second part that situation determines training data 148) of determination truthful data be compared.Then, it instructs
146 backpropagation loss function of model can be determined by the situation of machine learning by practicing computing system 150, be learnt with training machine
Situation determine model 146 (for example, determining the associated one or more of model 146 with the situation of machine learning by modification
Weight).In some implementations, the Machine learning tools of such as TensorFlow and/or Theano can be used for executing and pass through
The situation of machine learning determines the backpropagation of the loss function of model 146.
In some implementations, if user has agreed to provide, Text Feature Extraction training data 144 and/or situation
Determine that training data 148 can be by client computing device 102a and/or 102b (for example, based on extracted text and/or by visitor
Family end calculates the text of the determination of equipment 102a and/or 102b identification) and provide.Therefore, in this implementation, Ke Yiyou
Training computing system 150 is providing to train to visitor from the received user's specific data of client computing device 102a/102b
Family end calculates the Text Feature Extraction model 142 of machine learning of equipment 102a/102b and/or the situation of machine learning determines model
146.In some cases, which is properly termed as personalized model.
According to another aspect of the present disclosure, in some implementations, it can use user feedback system to help to collect
The additional training data of model 146 is determined for the Text Feature Extraction model 142 of training machine study and/or the situation of machine learning
(for example, Text Feature Extraction training data 144 and/or situation determine training data 148).For example, mobile computing device is (for example, Fig. 1
Mobile computing device 102) can be configured as on display screen 129 associated with mobile computing device 102 provide one
Or multiple user interfaces are with for showing, the user interface prompt user provide description about determining user context and/or
Distribute to the signal instruction of the feedback of one or more parts of the text of the extraction of determining user context.For example, in Figure 10
In depict example user interface.Can with describe determined by user context and/or distribute to mentioning for determining user context
The data of one or more parts of the text taken provide signal instruction from the user together, as the text for machine learning
This extraction model 142 and machine learning situation determine the training data of one or more of model 146.
Model trainer 160 may include for providing desired functional computer logic.Model trainer 160 can
To be realized with hardware, firmware and/or the software of control general processor.For example, in some implementations, model trainer
160 include storage on a storage device, the program file that is loaded into memory and is performed by one or more processors.At it
In his implementation, model trainer 160 includes that one or more set of computer-executable instructions are closed, be stored in such as RAM,
In the tangible computer readable storage medium of hard disk or optically or magnetically medium.
Network 166 can be any kind of communication network, such as local area network (for example, Intranet), wide area network (for example,
Internet) or some combinations, and may include any amount of wired or wireless link.In general, passing through the logical of network 166
Various communication protocols (for example, TCP/IP, HTTP, SMTP, FTP), coding or format (such as HTML, XML) can be used in letter
And/or protection scheme (for example, VPN, secure HTTP, SSL) is carried via any kind of wiredly and/or wirelessly connection.
Fig. 2 shows the exemplary computing systems 130 that can be used for realizing the disclosure.Also other can be used and calculates system
System.For example, in some implementations, client computing device 102a/102b may include model trainer 160 and training number
According to 162.In such implementation, Text Feature Extraction model and/or situation determine that model can be in client computing device sheet
Ground training and use.
Fig. 3 depicts the block diagram of the Example Computing Device 170 of execution communication auxiliary according to an example embodiment of the present disclosure.
Calculating equipment 170 can be user calculating equipment or server computing device.
Calculating equipment 170 includes multiple applications (for example, arriving J using 1).Each application include oneself machine learning library and
The model of machine learning.For example, each application may include the communication submodel of machine learning.Sample application includes that text disappears
Breath transmitting application, e-mail applications, dictation application, dummy keyboard application, browser application, virtual reality (VR) application etc..
As shown in Figure 3, each application can be communicated with the multiple other assemblies for calculating equipment, and the component such as one
Or multiple sensors, context management device, equipment state component and/or add-on assemble.In some implementations, each application can
To use API (for example, public API) to communicate with each apparatus assembly.In some implementations, each using API
It can be specific to the application.
Fig. 4 depicts the block diagram of the Example Computing Device 180 of execution communication auxiliary according to an example embodiment of the present disclosure.
Calculating equipment 180 can be user calculating equipment or server computing device.
Calculating equipment 180 includes multiple applications (for example, arriving J using 1).Each application can be led to central intelligent layer
Letter.Sample application includes text message transmitting application, e-mail applications, dictation application, dummy keyboard is applied, browser is answered
With, virtual reality (VR) application etc..In some implementations, API can be used (for example, across all applications in each application
General API) it is communicated with central intelligent layer (and the model being stored therein).
Central intelligent layer includes the model of many machine learning.For example, as shown in figure 4, can be provided simultaneously for each application
By the model (for example, communication submodel) of the corresponding machine learning of central intelligent layer-management.In other implementations, two
Or more application can share individual machine study model.For example, in some implementations, central intelligent layer can be
All applications provide single model (for example, individually communicating submodel).In some implementations, central intelligent layer can wrap
It includes and is realized in the operating system for calculating equipment 180 or otherwise by the operating system of calculating equipment 180.
Central intelligent layer can be communicated with central equipment data Layer.Central equipment data Layer, which can be, calculates equipment 180
The centrally stored library of data.As shown in figure 4, central equipment data Layer can be communicated with the multiple other assemblies for calculating equipment, institute
State other assemblies such as one or more sensors, context management device, equipment state component and/or add-on assemble.In some realities
In existing mode, central equipment data Layer can be used API (for example, privately owned API) and communicate with each apparatus assembly.
Example model arrangement
Fig. 5 depicts sample text according to an example embodiment of the present disclosure and extracts model arrangement.More specifically, Fig. 5
Text Feature Extraction model 200 can correspond to the machine learning of the Text Feature Extraction model 112 of Fig. 1, Fig. 2 Text Feature Extraction model 142,
Or other Text Feature Extraction model embodiments according to the disclosure.
Text Feature Extraction model 200 can be the model of machine learning.In some implementations, Text Feature Extraction model 200
It can be or can include otherwise various machine learning models, such as neural network is (for example, depth recurrent neural net
Network) or other multilayered nonlinear models, the model based on recurrence etc..When Text Feature Extraction model 200 includes recurrent neural network,
This can be multilayer shot and long term memory (LSTM) neural network, multilayer gate recurrence unit (GRU) neural network or other forms
Recurrent neural network.
Text Feature Extraction model 200, which can be configured as, receives text data 202.In one example, text data 202 can
With from one or more calculate equipment applications (for example, text message transmitting, chat messages transmitting application, e-mail applications and/
Or one or more of voice mail application) obtain.In this way, text data 202 may include via such calculating sometimes
The message or message threads of equipment application transmission, wherein message and/or message threads respectively include text data 202.Some
In implementation, text data 202 can be obtained and further continuously analyze, so that text data 202 is being based on text
Application program in obtained and analyzed by real-time or near real-time when transmission and/or reception.In some implementations,
Text data 202 can be iteratively updated, refreshes or generated when sending and/or receiving additional text data.In some realizations
In mode, periodically such as with the interval of regulation arrangement (for example, every five minutes), it can obtain and further analyze text
Data 202.It in some implementations, can be when one or more trigger events occur (for example, on a mobile computing device
Opening or the time applied using specific text based determine time when new situation etc. by mobile computing device) it obtains
It obtains and further analyzes text data 202.It can be controlled whether to the user of mobile computing device offer chance and/or which disappears
Breath and/or text data 202 can by the other assemblies and related application of Text Feature Extraction model 200 and/or mobile computing device or
Model access.
Referring still to Fig. 5, text data 202 can be used as input and provide into Text Feature Extraction model 200.In some realizations
In mode, the Text Feature Extraction model 200 of machine learning may include neural network and input text data 202 includes by text
Data are input in the neural network of Text Feature Extraction model 200.In some implementations, the Text Feature Extraction model of machine learning
200 may include that many different sizes, the number of plies and connection are horizontal.For the neural network trained by large data sets, Ke Yitong
It crosses using pressure difference and increases the number of plies and layer size, to solve the potential problems of overfitting.In some cases, mind can be designed
Through network to abandon at the top of network using the upper layer being fully connected.By forcing network to undergo dimension reduction in the intermediate layer,
Very deep neural network model can be designed, while substantially reducing the quantity of learning parameter.In some implementations, machine
The Text Feature Extraction model 200 of study may include the neural network that there is word to be embedded in, will be as the defeated of Text Feature Extraction model 200
The word or phrase for entering offer are mapped to one or more real vectors.The other configuration text of one or more technologies can be used to mention
Modulus type 200, including but not limited to batch standardization, gradient clipping, attention mechanism, add linear unit again at layer standardization
(RELUS), RELUS etc. is leaked.
In some implementations, Text Feature Extraction model 200 may include one or more message correlation characterization layers
204, one or more structured message extract layers 206, and/or one or more situation Distribution Layers 208.Although message correlation
Characterization layer 204, the information extraction layer 206 of structuring and/or situation Distribution Layer 208 are depicted as in Text Feature Extraction model 200
Individual course, but it is to be understood that these layers can be inclusion layer, so that message correlation, structured message extract and situation point
It is united with can be, and can be learnt and be determined simultaneously by Text Feature Extraction model 200.When text data 202 includes coming from
When calculating the message threads or multiple message of equipment application, message correlation characterization layer 204 can determine message threads or multiple
Which message correlation in message by structured message extract layer 206 and/or situation Distribution Layer 208 for further being analyzed.
Structured message extract layer 206 can determine related news or by the structure in the received all message of Text Feature Extraction model 200
Change information (for example, text etc.) which partially to extract.Situation Distribution Layer 208 can determination to distribute to by structured message
The particular context of each part for the structured message that extract layer 206 extracts.In this way, the output of Text Feature Extraction model 200 can be with
The text data 210 of distribution corresponding to extraction.The text data 210 of the distribution of extraction may include from text data 202
One or more of one or more parts of the text 212 for the extraction selectively extracted and the text 212 for distributing to extraction
The relative users situation 214 of each of a part.
Referring still to Fig. 5, in some implementations, distribution can be determined from scheduled different user context set
The user context 214 of each of one or more parts of text 212 to extraction.Each user context 214 can refer to
Show the difference activity that the user of mobile computing device can participate in.In this way, scheduled user context set may include for wrapping
It includes shopping or participates in the different movable corresponding situations of one or more of event.In some implementations, scheduled user's feelings
Border set may include one or more main situations and one or more auxiliary situations.For example, one or more main situations
It can correspond to different activities (for example, shopping or participation event), and one or more auxiliary situations can correspond to not
With movable particular aspects.
For example, auxiliary situation can describe classification associated with activity.One example user situation can have shopping
Main situation and auxiliary situation associated with the categories class of shopping (for example, furniture shopping, grocery store shopping, clothes purchase
Object etc.).Another example user situation can have the main situation of participation event and associated with the categories class of event
Auxiliary situation (for example, meeting of working, participate in together with friend social activity, the fitness class for participating in gymnasium etc.)
Fig. 6 depicts example scenarios according to an example embodiment of the present disclosure and determines that model is arranged.More specifically, Fig. 6
Situation determine model 240 can correspond to Fig. 1 situation determine the situation of the machine learning of model 114, Fig. 2 determine model 146,
Or model embodiment is determined according to other situations of the disclosure.
Situation determines that model 240 can be the model of machine learning.In some implementations, situation determines model 240
It can be or can otherwise include the model of various machine learning, such as neural network is (for example, depth recurrent neural net
Network) or other multilayered nonlinear models, the model based on recurrence etc..When situation determines that model 240 includes recurrent neural network,
It can be multilayer shot and long term memory (LSTM) neural network, multilayer gate recurrence unit (GRU) neural network or other forms
Recurrent neural network.
Situation determines that model 240 can be configured as from one or more and calculates equipment (for example, the mobile computing of Fig. 1 is set
The second client computing device 102b of the first client computing device 102a and/or Fig. 2 of standby 102, Fig. 2) receiving device number
According to 250.Device data 250 may include for example sensor-based data and/or the data based on application.In some realization sides
In formula, device data 250 may include one of the following or multiple: position sensor data 251 is (for example, such as from Fig. 1's
Position sensor 121 obtain), motion sensor data 252 (for example, such as being obtained from the motion sensor of Fig. 1 122), audio
Sensing data 253 (for example, such as obtaining from the audio sensor of Fig. 1 123), vision sensor data 254 are (for example, such as
Obtained from the imaging sensor 124 of Fig. 1) and/or calendar data 255 (for example, for example being obtained from the calendar application of Fig. 1 125).In
In some implementations, further analytical equipment data 250 can be continuously obtained simultaneously, so that sending out in text based application
When sending and/or receiving in real time or near real-time obtain and analytical equipment data 250.In some implementations, it can change
Generation ground update, refreshing or generating device data 250.It in some implementations, can periodically, such as with regulation arrangement
It is spaced (for example, every five minutes), obtains simultaneously further analytical equipment data 250.In some implementations, can at one or
(for example, when calculating equipment change position, capture new audio or image data, determining calendar thing when multiple trigger events occur
When generation of part etc.) obtain simultaneously further analytical equipment data 250.Chance control can be provided to the user of mobile computing device
System whether and/or which device data 250 can be determined by situation model 240 and/or mobile computing device other assemblies and
Related application or model access.
Referring still to Fig. 6, the situation that device data 250 is fed as input to machine learning can be determined into model 240.
In some implementations, the situation of machine learning determines that model 240 may include neural network, and input equipment data
250 include that device data is input to the situation of machine learning to determine in the neural network of model 240.In some implementations
In, the situation of machine learning determines that model 240 may include many different sizes, the rank of the quantity of layer and connection.For
The neural network trained by large data sets can increase the number of plies and layer size, by using pressure difference to solve overfitting
Potential problems.In some cases, neural network can be designed to abandon at the top of network using the upper layer being fully connected.Pass through
It forces network to undergo dimension reduction in the intermediate layer, very deep neural network model can be designed, while substantially reducing study
The quantity of parameter.
In some implementations, situation determines that model 240 may include that one or more main situations determine layer 260
And/or auxiliary situation determines layer 262.It also may include that the situation of additional level determines layer (example although not shown in FIG. 6
Such as, third situation determines layer etc.).Although situation, which determines in model 240, determines that layer 260 and/or auxiliary situation are true for main situation
Given layer 262 is portrayed as individual layer, but it is to be understood that such layer can be inclusion layer, so that main situation is determining and auxiliary
It helps situation to determine that (and the situation of any other rank determines) can be united, and model 240 is determined simultaneously by situation
Ground learns and determines.Situation determines that the output of model 240 can correspond to one or more current contexts 270 determined.Each
Determining current context may include one or more situation layers, such as main situation (for example, shopping) and auxiliary situation (example
Such as, groceries, furniture, clothes etc.)
Referring still to Fig. 6, in some implementations, can determine from scheduled different user context set by situation
Determine the current context 270 that model 240 determines.In some implementations, the scheduled difference of current context 270 is determined from it
User context set corresponds to the identical scheduled different use for the text that extraction can be distributed to by Text Feature Extraction model 200
The set of family situation 214.Each user context can indicate the difference activity that the user of mobile computing device can participate in.This
Sample, scheduled user context set may include for including that the one or more of shopping or participation event is different movable corresponding
Situation.In some implementations, scheduled user context set may include one or more main situations and one or more
A auxiliary situation.For example, one or more main situations can correspond to different activities (for example, shopping or participation event),
And one or more auxiliary situation can correspond to different movable particular aspects.For example, auxiliary situation can describe and live
Move associated classification.One example user situation can have the main situation of shopping and associated with the categories class of shopping
Auxiliary situation (for example, furniture shopping, grocery store shopping, clothes shopping etc.).Another example user situation can have participation
The main situation of event and auxiliary situation associated with the categories class of event are (for example, work meeting and friend
Social activity, the fitness class for participating in gymnasium etc. are participated in together)
Example user interface
Fig. 7 and 8 provides exemplary aspect relevant to all Text Feature Extraction models 200 as shown in Figure 5.
Fig. 7 depict according to an example embodiment of the present disclosure with chat messages transmit apply associated example user circle
Face.More specifically, user interface 300 depicts the example message thread 302 communicated between two sides or more.Specifically,
Message threads 302 are between the first user and the second user described by second user profile image 303 of mobile computing device
Transmission.Message threads 302 include multiple message 304-320.It can will be some in message 304-320 according to disclosed technology
Or all it is provided as the input of Text Feature Extraction model.For example, message 304-320 can correspond to the Text Feature Extraction mould as Fig. 5
The input of type 200 and the text data 202 provided.
Fig. 8 depicts the illustrative data base note of the text of the distribution for extraction according to an example embodiment of the present disclosure
Record.More specifically, Fig. 8 depicts the text database 330 of the distribution of extraction comprising with the input as Text Feature Extraction model
The associated data of the message of offer and the information determined from Text Feature Extraction model for such message.The distribution of extraction
Text database record can be configured as storage from Text Feature Extraction model as the received information of output.For example, disappearing as Fig. 7
When breath 304-320 is supplied to Text Feature Extraction model 200 as input (for example, text data 202), the textual data of the distribution of extraction
It can be configured as the text data 210 for the distribution that storage is extracted according to library 330, such as shown graphically in fig 5.The text of the distribution of extraction
Database 330 includes multiple numbers for example corresponding to one or more parts of the text 212 of the extraction from message 304-320
According to record 332-344.Each data record 332-344 may include a part of the text of such as extraction, the text with extraction
It is associated one or more identifier (for example, message identifier, date identifier, time identifier, sender's identifier,
One or more recipient's identifiers) and one or more situations distributed.The user context of distribution can include when available
Multiple user contexts (for example, main users situation, auxiliary user context, third user context etc.) join with being contextually relevant to the user
Other descriptors or classification.For example, the distribution that the message 306 that the first data record 332 of Fig. 8 corresponds to from Fig. 7 is extracted
Text.A part (for example, " bread ") including message identifier " ABC306 " of text of the data record 332 including extraction,
What date identifier " 5/04/2017 ", one or more identifiers of time identifier " 2:32pm " and one or more were distributed
Situation (for example, main situation " shopping " and auxiliary situation " groceries ").
Fig. 9 depicts the letter for being configured as display and describing identified user context according to an example embodiment of the present disclosure
The example user interface of breath.More specifically, Fig. 9 depicts the example for example shown on the display screen of mobile computing device 402
User interface 400.In some implementations, mobile computing device 402 can correspond to include Fig. 1 of display screen 129 shifting
It is dynamic to calculate equipment 102.User interface 400 respectively includes situation display portion 404 and multiple optional user interface button 406-
412.Situation display portion 404 in user interface 400 can be configured as display current user context, for example, such as according to this
The situation of disclosed example embodiment determines determined by model.In some implementations, user circle can be continuously provided
Face 400 or one or more part, to be shown on mobile computing device 402 as output.In some implementations, In
There are one or more trigger events (for example, when determining that model determines new active user's feelings by situation as described herein
When border) when, user interface 400 or one or more part can be provided for showing.
Referring still to Fig. 9, the interaction of user and user interface is (for example, by selecting one or more user interface buttons
406,408,410 and/or 412) can star description about identified user context feedback signal instruction relaying.Example
Such as, if the current context for determining and showing in situation display portion 404 is correctly, from user interface button 406
Such current context can be confirmed in the received feedback of user's selection.If determining and showing in situation display portion 404
User context is incorrect, then selects received feedback that can modify determining user context from the user of user interface button 408.
For example, the selection of user interface button 408 can star the display of selectable alternative context list.From user interface button
410 user selects the received feedback setting related with the device data that mobile computing device 402 accesses that can star display
And/or for determining that model determines that the factor of current user context and/or display associated with user interface 400 are set by situation
The display set.It is then possible to select received feedback next life using from user interface button 406,408,410 or other users
At the label for including together with relevant device data, for determining the user context indicated in situation display portion 404.
Then the situation that the data of label are added to Fig. 2 can be determined to training data 148 or be used to that situation to be trained to determine model its
His training dataset.
In some implementations, the user interface 400 of Fig. 9 can also comprise user interface button 412, and starting is
The display of the allocated related text data to the current user context for determining and showing in situation display portion 404.Continue
With the example of Fig. 7 and 8, if situation display portion 404 indicates that situation determines that model has determined that current user context has purchase
The auxiliary situation of main situation and the groceries shopping of object, then situation display portion 404 may include the determining active user of description
Situation is (for example, " you are in grocery store.") text.Then, the selection of user interface button 412 can star distribute to it is specific miscellaneous
Shop do shopping situation extraction text display (for example, " bread, butter, 5/10/2017 ").It can be additionally or alternatively
The source (for example, " from chat with user B ") for providing the text of this extraction is display together with the text with extraction.It is such
The text of extraction can provide in display window 414, which is provided at individually uses with user interface 400
In the interface of family, in the window being covered in user interface 400 or with any other suitable display configuration.
Figure 10 depicts example user interface associated with the text of extraction according to an example embodiment of the present disclosure.More
Specifically, Figure 10 depicts the example user interface 450 for example shown on the display screen of mobile computing device 452.Some
In implementation, mobile computing device 452 can correspond to the calculating equipment 102 of Fig. 1, including display screen 129.User interface
450 include current context display portion 454, related chat data display portion 456 and optional user interface button 458 and 460.
User interface 450 provides the text data (for example, providing in related chat data display portion 456) of the distribution including extracting
Notice, can be based on determining current user context (for example, being provided in current context display portion 454) come initiatively
It provides as output.For example, mobile computing device 452, which can be configured as to automatically determine, indicates that the user of mobile computing device works as
The preceding movable current user context of one or more participated in, current context display portion 454 is shown in when determining
It is interior.The situation of machine learning as described herein determines that model can be used for determining that is shown in current context display portion 454 works as
Preceding user context.The Text Feature Extraction model of machine learning can also determine that model is used simultaneously to identify and come from and can distribute with situation
To the part of the extraction text of the chat messages of specific user's situation.Therefore, it determines and shows in current context display portion 454
At least part that shows distribute to the text of the extraction of current user context can be used as output and provide in user interface 450
In related chat data display portion 456.Continue with the sample data from Fig. 7 and 8, the user interface 450 of Figure 10 is by " parent
Teachers association parliament is talked " it is identified as the current context in current context display portion 454, and by " teacher's name: Audrey；It is geographical
Test is identified as with the part with the extraction of the text of the user context of " parent teachers association parliament what is said or talked about " matched distribution.
Referring still to Figure 10, interacted with the user of user interface (for example, by selecting one or more user interface buttons
458 and/or 460) can star description about extraction distribution text feedback signal instruction relaying.For example, feedback
It can indicate that the text for the distribution extracted is helpful in user's selection of user interface button 458, or the distribution extracted
Text is not helped in user's selection of user interface element 460.It may include option to provide the portion to the text of extraction
Point feedback or provide for serviceability rank score.Then the feedback can be used generate for corresponding text
One or more labels that data include together.Then the data of label can be added to the Text Feature Extraction training data of Fig. 2
144 or other training datasets, model is extracted for training text.
Exemplary method
Figure 11-14 is elaborated and the computer implemented method of one or more according to an example embodiment of the present disclosure respectively
Associated aspect.In some embodiments, the computer implemented method of Figure 11-14 may include other features disclosed herein
Or step.In some embodiments, equipment, computing system or other example systems are calculated as described with reference to Figures 1 and 2 or are set
The some or all of methods described in Figure 11-14 may be implemented in standby or other example systems or equipment.In some embodiments,
The tangible non-transitory computer-readable mediums of one or more for storing computer-readable instruction, when described instruction by one or
When multiple processors execute, so that one or more processors execute operation, which includes one as described in Figure 11-14
Or the step of described in multiple methods.
Figure 11 depicts the first exemplary method 500 for executing machine learning according to an example embodiment of the present disclosure
Flow chart.Similarly describe and describe some aspects of method 500 with reference to Fig. 6.
At 502, the situation that one or more calculating equipment can obtain description machine learning determines model (for example, Fig. 1
Situation determine that the situation of the machine learning of model 114, Fig. 2 determines that the situation of model 146, and/or Fig. 6 determine model 240)
Data.The situation that data are obtained at 502 determines that model can be trained to from one or more input source receiving device data
One or more parts, and the one or more for determining that instruction mobile computing device user is currently participating in is movable current
User context.
At 504, one or more calculates equipment can be from the addressable one or more input sources of mobile computing device
Obtain the first set of one or more parts of device data.The device data obtained at 504 can correspond to such as Fig. 6
Device data 250 or from one or more input sources 120 (for example, sensor and/or application) of Fig. 1 obtain data.
For example, in some implementations, calculating equipment may include the one or more input sources for being configured to supply device data,
Input source includes one or more in position sensor, motion sensor, audio sensor, imaging sensor and calendar application
It is a.
At 506, one or more calculates equipment can be by one or more parts of the device data obtained 504
The situation that first set is input to the machine learning for obtaining its data 502 determines in model.
At 508, it is true as the situation of machine learning that one or more calculating equipment can receive determining user context
The output of cover half type.In some implementations, received identified user context can be from scheduled user's feelings at 508
It is determined in the set of border, the difference activity that the user of each user context instruction mobile computing device can participate in.For example, scheduled
User context set may include for including the different movable corresponding situations of one or more for doing shopping or participating in event.One
In a little implementations, the different activities of each of connection are contextually relevant to the user corresponding to main feelings from scheduled user context set
Border.The associated auxiliary situation of the classification that user context be may further determine that include with describe movable particular aspects.
At 510, one or more calculates equipment can be from the one or more application of mobile computing device (for example, text
One or more of the application of this message transmission, chat messages transmitting application, e-mail applications and voice mail application) it determines
One or more parts of text have the user context with the matched distribution of identified user context.In some realizations
In mode, one or more parts of text are periodically determined at 510.In some implementations, one of text or
Multiple portions are obtained from the message threads between two sides or more, are answered as calculated the networking in equipment using relative users
With transmission.
In some implementations, determine have and identified user from the one or more application of mobile computing device
One or more parts of the text of the user context of the matched distribution of situation may include the Text Feature Extraction using machine learning
Model.For example, one or more calculating equipment can be by the text of the text input from one or more application to machine learning
In this extraction model.The Text Feature Extraction model of machine learning can be trained to receive one or more message comprising text,
And one or more parts of the text extracted are determined from one or more message and the text of distributing to extraction one
The relative users situation of each of a or multiple portions.The output of Text Feature Extraction model as machine learning, one or
Multiple calculating equipment can receive one or more parts of extracted text, wherein distributing to one of extracted text
Or the user context of each of multiple portions corresponds to identified user context.
At 512, one or more calculate equipment can provide one or more parts of text as output (for example,
By providing in the display screen display for calculating equipment).
In some implementations, method 500 may include additional step.For example, method 500 can also comprise from
Family receives signal instruction, which describes about the text provided for the display screen display in mobile computing device
The feedback of one or more parts.Signal instruction from the user can provide the text for showing on a display screen with description
The data of one or more parts provide together, the situation as the machine learning in 502 acquisition its data determines model
Training data.Such training data, which can be saved, determines training data 148 as the training data 118 of Fig. 1, the situation of Fig. 2
And/or a part of the training data 162 of Fig. 2.
Figure 12 depicts the second exemplary method 600 for executing machine learning according to an example embodiment of the present disclosure
Flow chart.Similarly describe and describe some aspects of method 600 with reference to Fig. 5.
At 602, one or more calculates the data (example that equipment can obtain the Text Feature Extraction model of description machine learning
Such as, the Text Feature Extraction model of the Text Feature Extraction model 142, and/or Fig. 5 of the machine learning of the Text Feature Extraction model 112, Fig. 2 of Fig. 1
200).The Text Feature Extraction model that its data is obtained at 602 can be trained to receive one or more message comprising text,
And determine one or more parts of extracted text from one or more message and the text of distributing to extraction one
Each a or multiple portions relative users situation.
At 604, one or more calculates equipment can be from the one or more application of mobile computing device (for example, Fig. 1
Mobile computing device 102 chat application 126 or another text message transmitting application, chat messages transmitting application, electronics postal
Part application or voice mail application) obtain comprising text one or more message first set.
At 606, one or more calculates equipment can be defeated by the first set of one or more message comprising text
Enter into the Text Feature Extraction model for the machine learning for obtaining its data at 602.
At 608, one or more calculating equipment can receive the output of the Text Feature Extraction model as machine learning
One or more of one or more parts of the text of the extraction of first set from message and the text for distributing to extraction
The relative users situation of each of a part.
In some implementations, obtaining at 604 is realized periodically or when one or more trigger events occur
It obtains, the reception at the input and 608 at 606.
At 610, one or more, which calculates equipment, can will distribute to the text for the extraction that at least one corresponds to user context
At least one of this one or more parts provide (for example, by providing for showing on a display screen) as output.
In some implementations, method 600 may include additional step.For example, method 600 may include connecing from user
Receive the signal instruction of instruction specific user's situation.In some implementations, method 600 can include determining that instruction mobile computing
The movable current user context of one or more that the user of equipment is currently participating in.In such implementation, 610
It may include providing that place, which provides and distributes at least part for the text that at least one corresponds to extraction of the class of subscriber as output,
At least part of the text of extraction corresponding with current user context is as output (for example, by providing for showing
Screen display).
In some implementations, determine that current user context can more specifically include from can be visited by mobile computing device
The one or more input sources asked are (for example, position sensor, motion sensor, audio sensor, imaging sensor and/or day
Go through using etc.) obtain device data one or more parts first set.It can be by the one or more of device data
The situation that partial first set is fed as input to machine learning determines model, the model can be trained to from one or
One or more parts of multiple input source receiving device data, and determine that the user of instruction mobile computing device is currently joining
With the movable current user contexts of one or more.It can receive situation of the determining current user context as machine learning
Determine the output of model.
In some implementations, current user context can be determined from scheduled user context set.Each user
Situation can indicate the difference activity that the user of mobile computing device can participate in, and optionally, wherein scheduled user's feelings
Border set includes for including the different movable corresponding situations of one or more for doing shopping or participating in event.In some implementations
In, correspond to main situation from the different activities of each of connection that are contextually relevant to the user in scheduled user context set, and it can
With the associated auxiliary situation of the classification for further determining that user context to include with describe movable particular aspects.
In some implementations, method 600 can also comprise from user and receive signal instruction, signal instruction description
At least part of feedback of text about the extraction provided at 610 as output.It then can be in conjunction with description as defeated
At least part of data of the text provided out provide signal instruction from the user, as the machine for obtaining its data 602
The training data of the Text Feature Extraction model of device study.Such training data can save as the training data 118 of Fig. 1, Fig. 2
A part of the training data 162 of Text Feature Extraction training data 144 and/or Fig. 2.
Figure 13 depicts the example side of the Text Feature Extraction model of the study of training machine according to an example embodiment of the present disclosure
The flow chart of method.More specifically, method 700 includes aspect associated with training text extraction model.It is similarly retouched with reference to Fig. 2
Draw and describe some aspects of method 700.
At 702, one or more, which calculates equipment, can obtain Text Feature Extraction training dataset (for example, the text of Fig. 2 mentions
Take a part of a part of training data 144 and/or the training data 118 of Fig. 1 and/or the training data 162 of Fig. 2), packet
Include multiple determining truthful data set.At 704, it is true that one or more calculating equipment can be provided in the determination obtained at 704
Input of the first part of the Text Feature Extraction training dataset of real data as Text Feature Extraction model.It is one or more at 706
One or more parts of the text of extraction can be received in response to receiving the first part of determining truthful data by calculating equipment
The user context that the distribution of the remainder of the Text Feature Extraction training dataset of truthful data is determined with prediction, as Text Feature Extraction
The output of model.At 708, one or more, which calculates equipment, can determine loss function, which will mention with by text
The part of the prediction of the text for the extraction that modulus type generates and the user context of distribution and Text Feature Extraction model attempt to predict really
The second part (for example, remainder) for determining truthful data is compared.At 710, one or more, which calculates equipment, to lead to
It crosses Text Feature Extraction model backpropagation loss function and model is extracted (for example, by modification and Text Feature Extraction model with training text
Associated one or more weight).As a part of the training text extraction model in method 700, respectively in 704-710
The step of place is described can be repeated as many times.
The situation that Figure 14 depicts the study of training machine according to an example embodiment of the present disclosure determines the example side of model
The flow chart of method.More specifically, method 800 includes determining the associated aspect of model with training situation.It is similarly retouched with reference to Fig. 2
Draw and describe some aspects of method 800.
At 802, one or more calculating equipment can obtain situation and determine training dataset (for example, the situation of Fig. 2 is true
Determine a part of a part of training data 148 and/or the training data 118 of Fig. 1 and/or the training data 162 of Fig. 2), packet
Include multiple determining truthful data set.At 804, it is true that one or more calculating equipment can be provided in the determination obtained at 704
The situation of real data determines that the first part of training dataset determines the input of model as situation.At 806, in response to receiving
To the first part for determining truthful data, one or more, which calculates equipment, can receive the one of the output that model is determined as situation
The user context of a or multiple determinations is predicted to determine the remainder that the situation of truthful data determines training dataset.808
Place, one or more, which calculates equipment, can determine loss function, which will determine being determined for model generation by situation
User context and situation determine that model attempts the second part (for example, remainder) of the determination truthful data predicted and compared
Compared with.At 810, one or more calculates equipment can determine model backpropagation loss function to train situation true by situation
Cover half type (for example, by modification with situation determine model it is associated one or more weights).Describe at 804-810 respectively
The step of can be repeated as many times, as in method 800 training situation determine a part of model.
Additional disclosure
Technical Reference server discussed here, database, software application and other computer based systems, Yi Jisuo
The movement taken and the information for being sent to these systems and being sent from these systems.Computer based system it is intrinsic flexibly
Property allow component between task and it is functional it is various it is possible configuration, combination and divide.For example, processing discussed here
Multiple equipment or the component of individual equipment or component or work in combination can be used to realize.Database and application can be single
It realizes in system or is distributed across multiple systems.Distributed component can sequence or parallel work-flow.
Although this theme is described in detail about the various specific example embodiments of the disclosure, each example is
By explaining rather than limit the disclosure to provide.After obtaining to the understanding of foregoing teachings, those skilled in the art can be with
Easily generate change, variation and the equivalent to these embodiments.Therefore, the disclosure is not precluded including this to this theme
A little modifications, variation and/or addition, this will be apparent to practitioners skilled in this.For example, as a reality
The feature that a part for applying example shows or describes can be used together with another embodiment, to generate another embodiment.Cause
This, the disclosure is intended to cover these changes, variation and equivalent.
Specifically, although respectively depicting the step of executing with particular order for explanation and the purpose Figure 11-14 discussed,
But disclosed method is not limited to specifically shown sequence or arrangement.It without departing from the scope of the disclosure, can be with
It omits, rearrange in various ways, combining and/or each step of method of adjustment 500,600,700 and 800.
Claims (26)
1. a kind of mobile computing device, comprising:
At least one processor；
Display screen；
The situation of machine learning determines model, wherein the situation determines that model has been trained to from the mobile computing device
One or more parts of addressable one or more input source receiving device data, and determine and indicate that the mobile computing is set
The movable current user context of one or more that standby user is currently participating in；
At least one tangible non-transitory computer-readable medium, store instruction, described instruction by it is described at least one
When processor executes, the mobile computing device is set to execute operation, the operation includes:
One or more parts of device data are obtained from the addressable one or more input sources of the mobile computing device
First set；
The situation that the first set of one or more parts of the device data is input to the machine learning is determined into model
In；
User context determined by receiving, the situation as the machine learning determine the output of model；
Determine have with the user context of the identified matched distribution of user context, come from the mobile computing device
One or more application text one or more parts；And
One or more parts of the text are provided, for the display screen display in the mobile computing device.
2. mobile computing device according to claim 1, wherein user situation determined by described is from scheduled user
What situation set determined, each user context indicates the difference activity that the user of the mobile computing device can participate in.
3. mobile computing device according to claim 2, wherein the scheduled user context set includes for including
Shopping or the different movable corresponding situations of the one or more for participating in event.
4. mobile computing device according to claim 2 or 3, wherein with the user in predesignated subscriber's situation set
The associated each different activities of situation correspond to main situation, and wherein the user context be also determined include and description
The associated auxiliary situation of the classification of movable particular aspects.
5. mobile computing device according to any one of claim 1 to 4, further includes: one or more input sources are matched
It is set to and the device data is provided, the input source includes position sensor, motion sensor, audio sensor, image sensing
One or more of device and calendar application.
6. mobile computing device according to any one of the preceding claims, wherein determining has and identified user
One of matched the distributed user context of situation, one or more application from mobile computing device text
Or multiple portions are periodically determining.
7. mobile computing device according to any one of the preceding claims, wherein the user calculating equipment it is described
One or more application includes that text message transmitting application, chat messages transmitting application, e-mail applications and voice mail are answered
One or more of with.
8. mobile computing device according to claim 7, wherein one or more of parts of text be from two or
It is obtained in message threads between more multi-party.
9. mobile computing device according to any one of the preceding claims, the operation further include:
Signal instruction from the user is received, which describes about being provided in the mobile computing device
The feedback of one or more of parts of the text of the display screen display；And
It is combined with the data that description is provided for one or more of parts of the text shown on the display screen
Ground provides the signal instruction from the user, and the situation as the machine learning determines the training data of model.
10. mobile computing device according to any one of the preceding claims, wherein determining has and identified user
Matched the distributed user context of situation, one or more of applications from mobile computing device text
The step of one or more parts, includes:
By in the Text Feature Extraction model of the text input from one or more of applications to machine learning, the machine learning
Text Feature Extraction model be trained to receive include text one or more message, and from one or more of message
It determines one or more parts of the text extracted and distributes in one or more of parts of extracted text
The relative users situation of each；And
One or more parts of the extracted text of the output of the Text Feature Extraction model as the machine learning are received,
In distribute to user context in each of one or more of parts of extracted text correspond to it is identified current
User context.
11. a kind of mobile computing device, comprising:
At least one processor；
The Text Feature Extraction model of machine learning, wherein the Text Feature Extraction model has been trained to receive one comprising text
Or multiple message, and determine the one or more of extracted text partially from one or more of message and distribute
The relative users situation of each of one or more of parts to extracted text；
At least one tangible non-transitory computer-readable medium, store instruction, described instruction by it is described at least one
Processor makes the mobile computing device execute operation when executing, and the operation includes:
The first set of the message comprising text is obtained from the one or more application of the mobile computing device；
The first set of message comprising text is input in the Text Feature Extraction model of the machine learning；
It receives one or more parts of the extracted text of the first set from message and distributes to and extracted
Each of one or more of parts of text relative users situation, the Text Feature Extraction as the machine learning
The output of model；And
At least part for distributing to the text of extraction of at least one relative users situation is provided as output.
12. mobile computing device according to claim 11, wherein the operation further includes specific from user's reception instruction
The signal instruction of user context, and wherein at least the one of the text of the extraction of at least one relative users situation is distributed in offer
Part includes: to provide at least part of the text for the extraction for distributing to specific user's situation as output, in the shifting
The dynamic display screen display for calculating equipment.
13. mobile computing device according to claim 11 or 12, wherein the operation further include: determine instruction movement
Calculate the movable current user contexts of one or more that the user of equipment is currently participating in, and wherein provide distribute to
At least part of the text of the extraction of a few corresponding class of subscriber includes: to provide to correspond to the active user as output
At least one portion of the text of the extraction of situation for showing on a display screen.
14. mobile computing device according to claim 13, wherein determining that the current user context includes:
One or more parts of device data are obtained from the addressable one or more input sources of the mobile computing device
First set；
The situation that the first set of one or more parts of device data is input to machine learning is determined in model,
Described in situation determine that model has been trained to one or more portions from one or more of input source receiving device data
Point, and determine the movable current user context of one or more that the user of instruction mobile computing device is currently participating in；With
And
Receive the output that determining current user context determines model as the situation of the machine learning.
15. mobile computing device described in 3 or 14 according to claim 1, wherein the current user context is from scheduled use
What family situation set determined, the difference activity that the user of each user context instruction mobile computing device can participate in, and can
Selection of land, wherein scheduled user context set includes different movable right for including the one or more of shopping or participation event
Answer situation.
16. mobile computing device according to claim 15, wherein with the user in the scheduled user context set
The associated each different activities of situation correspond to main situation, and wherein, and the user context is also determined including and retouching
State the associated auxiliary situation of classification of movable particular aspects.
17. mobile computing device described in any one of 3 to 16 according to claim 1, further includes: one or more input sources,
It is configured to supply device data, the input source includes position sensor, motion sensor, audio sensor, image sensing
One or more of device and calendar application, and active user's feelings are wherein at least determined in part with device data
Border.
18. mobile computing device described in any one of 1 to 17 according to claim 1, wherein described to obtain, input and receive
Operation is periodically realized.
19. mobile computing device described in any one of 1 to 18 according to claim 1, wherein the institute of the user calculating equipment
Stating one or more application includes text message transmitting application, chat messages transmitting application, e-mail applications and voice mail
One or more of using.
20. mobile computing device described in any one of 1 to 19 according to claim 1, the operation further include:
Signal instruction from the user is received, described in text of the signal instruction description about the extraction provided as output extremely
At least part of feedback；And
Signal instruction from the user is provided in combination at least part of data of the description text provided as output,
The training data of Text Feature Extraction model as machine learning.
21. the tangible non-transitory computer-readable medium of one or more storage computer-readable instruction, the computer can
Reading instruction makes one or more of processors execute operation when executed by one or more processors, and the operation includes:
The first set of the message comprising text is obtained from the one or more application of mobile computing device；
The first set of message comprising text is input in the Text Feature Extraction model of machine learning, wherein the text
It extracts model to be trained to receive one or more message comprising text, and determines institute from one or more of message
One or more parts of the text of extraction and distribute to each of one or more of parts of text of extraction
Relative users situation；
It receives one or more parts of the extracted text of the first set from message and distributes to and extracted
Each of one or more of parts of text relative users situation, the Text Feature Extraction as the machine learning
The output of model；And
At least part for distributing to the text of extraction of at least one relative users situation is provided as output.
22. the tangible non-transitory computer of one or more storage computer-readable instructions according to claim 21 can
Medium is read, wherein providing at least part for distributing to the text of extraction of at least one relative users situation as output
It include: to provide described at least part of extracted text for showing.
23. the tangible non-transitory that the one or more according to claim 21 or 22 stores computer-readable instruction calculates
Machine readable medium, wherein described instruction further include:
Receive signal instruction of the description about at least part of feedback of the text of the extraction provided as output；And
Letter from the user is provided in combination at least part of data of the text for the extraction for describing to provide as output
Number instruction, the training data of the Text Feature Extraction model as the machine learning.
24. the tangible non-transitory computer-readable medium of one or more storage computer-readable instruction, the computer can
Reading instruction makes one or more of processors execute operation when executed by one or more processors, and the operation includes:
The first of one or more parts of device data is obtained from the addressable one or more input sources of mobile computing device
Set；
The situation that the first set of one or more parts of device data is input to machine learning is determined in model,
Described in situation determine that model has been trained to one or more portions from one or more of input source receiving device data
Point, and determine the movable active user's feelings of one or more for indicating that the user of the mobile computing device is currently participating in
Border；
Receive the output that determining current user context determines model as the situation of the machine learning；
Determining and identified one or more application being contextually relevant to the user, from the mobile computing device text
One or more parts；And
One or more of parts of text are provided for the display screen display in the mobile computing device.
25. the tangible non-transitory computer of one or more storage computer-readable instructions according to claim 24 can
Medium is read, wherein determining and identified one or more application being contextually relevant to the user, from the mobile computing device
One or more parts of text include:
By in the Text Feature Extraction model of the text input from one or more of applications to machine learning, the machine learning
Text Feature Extraction model be trained to receive include text one or more message, and it is true from one or more of message
It one or more parts of fixed extracted text and distributes to each in one or more parts of extracted text
A relative users situation；And
One or more parts of the extracted text of the output of the Text Feature Extraction model as the machine learning are received,
In distribute to each part in one or more of parts of extracted text user context correspond to it is identified
Current user context.
26. the tangible non-transitory meter of the storage computer-readable instruction of the one or more according to claim 24 or 25
Calculation machine readable medium, wherein described instruction further include:
Signal instruction is received, which describes about the display screen being provided in the mobile computing device
The feedback of one or more of parts of the text of upper display；And
The data for being provided for one or more of parts of the text shown on the display screen with description are mutually tied
It closes ground and signal instruction from the user is provided, the situation as the machine learning determines the training data of model.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2017/036967 WO2018231187A1 (en) | 2017-06-12 | 2017-06-12 | Context aware chat history assistance using machine-learned models |
Publications (1)
Publication Number | Publication Date |
---|---|
CN110506262A true CN110506262A (en) | 2019-11-26 |
Family
ID=59093629
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780089569.1A Pending CN110506262A (en) | 2017-06-12 | 2017-06-12 | It is assisted using the context aware chat history of machine learning model |
Country Status (4)
Country | Link |
---|---|
US (1) | US10642830B2 (en) |
EP (1) | EP3571602A1 (en) |
CN (1) | CN110506262A (en) |
WO (1) | WO2018231187A1 (en) |
Families Citing this family (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10638482B2 (en) * | 2017-12-15 | 2020-04-28 | Qualcomm Incorporated | Methods and apparatuses for dynamic beam pair determination |
CN108346107B (en) * | 2017-12-28 | 2020-11-10 | 创新先进技术有限公司 | Social content risk identification method, device and equipment |
CN108737872A (en) * | 2018-06-08 | 2018-11-02 | 百度在线网络技术（北京）有限公司 | Method and apparatus for output information |
US11205045B2 (en) * | 2018-07-06 | 2021-12-21 | International Business Machines Corporation | Context-based autocompletion suggestion |
KR102035796B1 (en) * | 2018-07-26 | 2019-10-24 | 주식회사 딥핑소스 | Method, system and non-transitory computer-readable recording medium for processing data to be anonymized |
US11593433B2 (en) * | 2018-08-07 | 2023-02-28 | Marlabs Incorporated | System and method to analyse and predict impact of textual data |
US20200288204A1 (en) * | 2019-03-05 | 2020-09-10 | Adobe Inc. | Generating and providing personalized digital content in real time based on live user context |
US11678031B2 (en) | 2019-04-19 | 2023-06-13 | Microsoft Technology Licensing, Llc | Authoring comments including typed hyperlinks that reference video content |
US10904631B2 (en) * | 2019-04-19 | 2021-01-26 | Microsoft Technology Licensing, Llc | Auto-completion for content expressed in video data |
US11785194B2 (en) | 2019-04-19 | 2023-10-10 | Microsoft Technology Licensing, Llc | Contextually-aware control of a user interface displaying a video and related user text |
KR20220028098A (en) * | 2019-07-04 | 2022-03-08 | 넥스트나브, 엘엘씨 | Systems and methods for using a pressure sensor of a mobile device to improve the reliability of a determined context |
US11954602B1 (en) * | 2019-07-10 | 2024-04-09 | Optum, Inc. | Hybrid-input predictive data analysis |
US11322235B2 (en) * | 2019-10-15 | 2022-05-03 | Bhargav Sri Prakash | Systems and methods for digital vaccine |
EP3809279A1 (en) * | 2019-10-18 | 2021-04-21 | Amadeus S.A.S. | Device, system and method for training machine learning models using messages associated with provider objects |
FR3102278A1 (en) * | 2019-10-18 | 2021-04-23 | Amadeus | DEVICE, SYSTEM AND METHOD FOR TRAINING AUTOMATIC LEARNING MODELS USING MESSAGES ASSOCIATED WITH PROVIDER OBJECTS |
US11367017B2 (en) * | 2019-10-18 | 2022-06-21 | Amadeus S.A.S., Sophia Antipolis | Device, system and method for training machine learning models using messages associated with provider objects |
US11544886B2 (en) * | 2019-12-17 | 2023-01-03 | Samsung Electronics Co., Ltd. | Generating digital avatar |
US11321587B2 (en) * | 2020-01-30 | 2022-05-03 | Ford Global Technologies, Llc | Domain generation via learned partial domain translations |
US11349800B2 (en) | 2020-07-27 | 2022-05-31 | Bytedance Inc. | Integration of an email, service and a messaging service |
US11645466B2 (en) | 2020-07-27 | 2023-05-09 | Bytedance Inc. | Categorizing conversations for a messaging service |
US11539648B2 (en) | 2020-07-27 | 2022-12-27 | Bytedance Inc. | Data model of a messaging service |
US11290409B2 (en) | 2020-07-27 | 2022-03-29 | Bytedance Inc. | User device messaging application for interacting with a messaging service |
US11694116B2 (en) * | 2020-07-27 | 2023-07-04 | BlueOwl, LLC | Vehicle resiliency, driving feedback and risk assessment using machine learning-based vehicle wear scoring |
US11922345B2 (en) * | 2020-07-27 | 2024-03-05 | Bytedance Inc. | Task management via a messaging service |
US11343114B2 (en) | 2020-07-27 | 2022-05-24 | Bytedance Inc. | Group management in a messaging service |
US11610054B1 (en) * | 2021-10-07 | 2023-03-21 | Adobe Inc. | Semantically-guided template generation from image content |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040254998A1 (en) * | 2000-06-17 | 2004-12-16 | Microsoft Corporation | When-free messaging |
US20130297551A1 (en) * | 2012-05-07 | 2013-11-07 | Runway 20, Inc. | System and method for providing intelligent location information |
US20150057035A1 (en) * | 2013-08-22 | 2015-02-26 | Yahoo! Inc. | System and method for contextual social messaging |
US20160357761A1 (en) * | 2015-06-05 | 2016-12-08 | Apple Inc. | Techniques for suggesting recipients based on a context of a device |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8634788B2 (en) * | 2007-03-02 | 2014-01-21 | Aegis Mobility, Inc. | System and methods for monitoring the context associated with a mobile communication device |
JP2017097585A (en) | 2015-11-24 | 2017-06-01 | 株式会社リコー | Learning device, program, and learning method |
-
2017
- 2017-06-12 WO PCT/US2017/036967 patent/WO2018231187A1/en unknown
- 2017-06-12 CN CN201780089569.1A patent/CN110506262A/en active Pending
- 2017-06-12 EP EP17731987.8A patent/EP3571602A1/en not_active Withdrawn
- 2017-06-12 US US15/758,363 patent/US10642830B2/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040254998A1 (en) * | 2000-06-17 | 2004-12-16 | Microsoft Corporation | When-free messaging |
US20130297551A1 (en) * | 2012-05-07 | 2013-11-07 | Runway 20, Inc. | System and method for providing intelligent location information |
US20150057035A1 (en) * | 2013-08-22 | 2015-02-26 | Yahoo! Inc. | System and method for contextual social messaging |
US20160357761A1 (en) * | 2015-06-05 | 2016-12-08 | Apple Inc. | Techniques for suggesting recipients based on a context of a device |
Also Published As
Publication number | Publication date |
---|---|
US20190034483A1 (en) | 2019-01-31 |
WO2018231187A1 (en) | 2018-12-20 |
EP3571602A1 (en) | 2019-11-27 |
US10642830B2 (en) | 2020-05-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN110506262A (en) | It is assisted using the context aware chat history of machine learning model | |
AU2019204800B2 (en) | Intent engines systems and method | |
CN109241440A (en) | It is a kind of based on deep learning towards implicit feedback recommended method | |
CN108781175A (en) | The automatic suggestion of thread is inscribed for message exchange | |
CN108023927A (en) | Suggestion of taking action for activity | |
CN103488994B (en) | Symbiotic helper | |
CN110321429A (en) | Entity for improving digital content recommending indicates study | |
US11475218B2 (en) | Apparatus and method for providing sentence based on user input | |
CN115917535A (en) | Recommendation model training method, recommendation device and computer readable medium | |
CN111512617B (en) | Device and method for recommending contact information | |
US20230152951A1 (en) | Analyzing augmented reality content item usage data | |
US20190079946A1 (en) | Intelligent file recommendation | |
CN106383882A (en) | Information recommendation method and device and server | |
CN110521213A (en) | Story making video method and system | |
CN113010702A (en) | Interactive processing method and device for multimedia information, electronic equipment and storage medium | |
CN109978175A (en) | Parallelization coordinate descent for machine learning model | |
KR20190053481A (en) | Apparatus and method for user interest information generation | |
Gips et al. | Mapping human networks | |
US20230325944A1 (en) | Adaptive wellness collaborative media system | |
CN110147464A (en) | Video recommendation method, device, electronic equipment and readable storage medium storing program for executing | |
CN113139133B (en) | Cloud exhibition content recommendation method, system and equipment based on generation countermeasure network | |
Nguyen | Millennial travellers' expectations for smart hotels | |
Scerri et al. | A semantic infrastructure for personalisable context-aware environments | |
CN108255985A (en) | Data directory construction method, search method and device, medium and electronic equipment | |
Palma | WOK–User Interaction in a Crowdsourcing Application |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |