US20140059033A1 - Machine translation using information retrieval - Google Patents
Machine translation using information retrieval Download PDFInfo
- Publication number
- US20140059033A1 US20140059033A1 US12/108,415 US10841508A US2014059033A1 US 20140059033 A1 US20140059033 A1 US 20140059033A1 US 10841508 A US10841508 A US 10841508A US 2014059033 A1 US2014059033 A1 US 2014059033A1
- Authority
- US
- United States
- Prior art keywords
- segment
- candidate
- subsegments
- target
- similarity
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/40—Processing or translation of natural language
- G06F40/42—Data-driven translation
- G06F40/45—Example-based machine translation; Alignment
Definitions
- the present disclosure relates to machine translation.
- Machine translation systems are used to automatically translate text, speech, or other content from a source language to a target language.
- Conventional machine translation systems include dictionary-based machine translation, model-based machine translation, and instance-based machine translation.
- Instance-based machine translation systems typically include a repository of source data and corresponding repository of target data. For example, a collection of documents in the source language and corresponding translated documents in the target language.
- An input segment for example a sentence, is translated from the source language to the target language by identifying a matching segment in the example source data.
- a matching segment in the source data is found by testing the input segment one at a time against each segment in the source data to identify an exact match.
- the target language segment corresponding to the matching source segment is then provided as the translation of the input segment.
- Systems, methods, and apparatuses, including computer program products, are provided for machine translation using information retrieval techniques.
- one aspect of the subject matter described in this specification can be embodied in methods that include the actions of providing a received input segment as a query to a search engine, the search engine searching an index of one or more collections of documents, receiving one or more candidate segments in response to the query, determining a similarity of each candidate segment to the received input segment, and for one or more candidate segments having a determined similarity that exceeds a threshold similarity, providing a translated target segment corresponding to the respective candidate segment.
- Other embodiments of this aspect include corresponding systems, apparatus, and computer program products.
- the aspect can further include, for a candidate segment having a determined similarity that does not exceed the threshold similarity, identifying one or more subsegments of the input segment and providing one or more candidate subsegments corresponding to each of the one or more subsegments of the input segment.
- the aspect can further include identifying a non-matching subsegment of the candidate segment that does not match the corresponding subsegment of the input segment, identifying a matching candidate subsegment, and substituting the matching candidate subsegment for the non-matching candidate subsegment.
- Identifying a matching candidate subsegment can further include providing the identified subsegments as queries to the search engine, receiving the one or more candidate subsegments for each identified subsegment, and determining similarity of the candidate subsegments to the corresponding identified subsegment.
- the aspect can further include, for candidate subsegments having a similarity that does not exceed the threshold similarity, using a model-based statistical machine translation to identify target subsegments corresponding to the input subsegments.
- the aspect can further include receiving an input adjusting the similarity threshold, where adjusting the similarity threshold results in different sized candidate subsegments.
- the aspect can further include, providing target subsegments for each candidate subsegments having a determined similarity to the corresponding subsegment of the input segment that exceeds a threshold similarity.
- Providing target subsegments can include using alignment data for the candidate subsegment to identify a location of the target subsegment in a repository.
- Providing the target segment corresponding to the candidate segment can include using alignment data for the candidate segment to identify a location of the corresponding target segment.
- one aspect of the subject matter described in this specification can be embodied in methods that include the actions of generating a hierarchical aligned repository of documents, the hierarchical aligned repository of documents including a plurality of segments, each segment being part of a pair that includes a source segment and a translated target segment, each source segment being aligned to a corresponding target segment, the plurality of segment including a hierarchy of segments having multiple segment levels, indexing each source segment of the repository, the indexing identifying each location of the respective source segment in the repository, and using information retrieval to search the index to identify one or more translated target segments for a given input segment.
- Other embodiments of this aspect include corresponding systems, apparatus, and computer program products.
- the aspect can further include generating a target index of the target segments from the repository of paired segments, where the index and target index are symmetric.
- the index can further include alignment data for each segment, the alignment data identifying a location of the corresponding target segment.
- the aspect can further include generating one or more alignment tables, the alignment tables identifying alignment information for each segment in the repository. Indexing can include generating an inverted index.
- the multiple segment levels can include paragraphs, sentences, and words.
- Information retrieval techniques can be used to provide quick retrieval in large data sets.
- Recursive techniques can be used to decompose segments into subsegments to provide greater translation accuracy.
- a user can ask the system to produce translations composed of retrieved target language segments at different levels of granularity.
- FIG. 1 is a block diagram illustrating an example machine translation system.
- FIG. 2 is a block diagram illustrating an example of a hierarchically aligned bilingual repository.
- FIG. 3 is a flow chart illustrating an example method for generating a hierarchically aligned bilingual repository.
- FIG. 4 is a flow chart illustrating an example method for searching an aligned bilingual repository.
- FIG. 5 is a schematic diagram of an example computer system.
- FIG. 1 is a block diagram illustrating an example machine translation system 100 .
- Machine translation system 100 includes a parallel repository 102 , an alignment engine 104 , an indexing engine 106 , a subsegment engine 108 , a similarity engine 110 , and a translation engine 114 .
- the machine translation system can include, or be coupled to, a search system 112 .
- the components of the machine translation system 100 and the search system 112 can communicate across one or more networks.
- the parallel repository 102 includes a collection of documents in a source language (e.g., French) and corresponding translation collections of documents in one or more target languages (e.g., English).
- the parallel repository 102 can include a number of different document types, including, e.g., web page and news article pairs where each pair includes text in the source language and the corresponding translated text in the target language.
- the parallel repository 102 can include multi-lingual data. For example, United Nations proceedings are available which provide parallel translations in six languages.
- the parallel repository 102 includes one or more collections of documents where each collection is associated with a different language.
- one collection of documents is designated a source collection and each other collection is designated as a target collection (e.g., the language to which an input in the source language is translated).
- target collection e.g., the language to which an input in the source language is translated.
- any two collections of documents can be designated as a respective pair of source and target document collections depending on the translation to be performed.
- Source language documents in the collection are hierarchically aligned with corresponding documents in one or more target language collections.
- the parallel repository 102 can be a hierarchically aligned bilingual repository (e.g., a single source language hierarchically aligned with a single target language).
- each collection of documents is hierarchically aligned with each other collection of documents such that any combination of collections of documents to provide multiple hierarchically aligned collections of documents.
- the hierarchical aligned documents in the parallel repository 102 provide paired segments associating content in one collection of documents with corresponding content in another collection of documents.
- each paired segment includes a source language segment and its corresponding translation into a target language segment. Paired segments can be identified according to the alignment of the collections in the repository.
- a segment can be an entire document or a portion of a document including a paragraph, a sentence, a phrase, or other portion.
- segments are paired at more than one segment level (e.g., at both paragraph and sentence levels to form hierarchical aligned pairs).
- the repository 102 can include pairs of more than one segment size for the same collection of source and target documents. Paired segments can be decomposed into paired subsegments (e.g., smaller included segments of a larger segment), for example, using subsegment engine 108 , which is described below.
- the alignment engine 104 hierarchically aligns segments from the collection of source language documents to segments from the collection of target documents.
- the term “alignment” will be used to refer to a data structure that represents a segment-for-segment connection between source and target segments in a pair of documents.
- the alignment is simply a vector identifying positions of source segments that various target segments connect to. For example, a particular word in a source document can be aligned with a corresponding translated word or words in a target document (e.g., that a word segment “hello” in one source sentence aligns with the word segment “bonjour” of a target sentence).
- Hierarchical alignment aligns documents from one collection to documents of another collection at multiple segment levels (e.g., document segments, paragraph segments, sentence segments). Alignment can be performed using a number of techniques. For example, some alignments can be manually generated, e.g., by one or more individuals. Alternatively, statistical techniques can be used to generate an alignment between segments.
- the source and target collections include parallel documents (e.g., each document in the source collection has a corresponding translated document in the target collection)
- documents in the source and target collections can be analyzed using, for example, an iterative process, e.g., expectation-maximization algorithm, to find likely connections between source and target segments.
- the subsegment engine 108 identifies subsegments from segments. Subsegments are smaller segments formed from a given segment. For example, a document segment can be divided into paragraphs segments, which are referred to in some implementations as subsegments of the document segment. Subsegments are formed from one or more of the segments and represent segments of a lesser level. For example, a document segment can be separated into paragraph subsegments. In some implementations, the subsegments can be further divided into sentence subsegments, word subsegments, character subsegments, etc.
- the indexing engine 106 indexes the repository 102 .
- the indexing engine 106 only indexes the source collection of documents.
- the indexing engine 106 generates an index for both the source collection and the target collections in the parallel repository 102 .
- the generated index can be, for example, an inverted index identifying a location for each source segment in the parallel repository 102 .
- a word segment can be indexed to identify each document of the collection in which the word occurs along with the specific position within the respective document (e.g., document 52 , position 3 ).
- the index also includes alignment information identifying a location of one or more corresponding target segments (e.g., identifying a target document and position).
- the search system 112 identifies one or more source segments associated with an input segment using one or more information retrieval techniques.
- the input e.g., a segment to be translated
- the search system 112 can be implemented as, for example, computer programs running on one or more computers in one or more locations that are coupled to each other through a network.
- the search system 112 can include a search engine.
- the search system 112 responds to the query by generating search results, for example, results identifying the locations in the repository corresponding to the query.
- the search engine uses information retrieval techniques to identify relevant resources (e.g., documents in a source collection).
- the search engine will generally use an index (e.g., provided in an index database by indexing engine 106 ) that actively searches the parallel repository 102 .
- an index e.g., provided in an index database by indexing engine 106
- the inverted index for a particular collection of documents can be searched.
- the similarity engine 110 determines a similarity measure between input segments and candidate source language segments.
- the similarity engine uses one or more criteria to determine whether the similarity between an input segment and a candidate source language segment exceeds a specified threshold level.
- the similarity measure can be an edit-distance measure that computes a minimum number of edits applied to the input segment to yield the candidate source language segment.
- the search engine will generally include a ranking engine (or other software) to rank the resources related to the query.
- the ranking of the resources can be performed using conventional techniques for determining an information retrieval score for indexed resources in view of a given query.
- the relevance of a particular resource with respect to a particular query term or to other provided information may be determined by any appropriate technique.
- the translation engine 114 identifies one or more target segments corresponding to a source segment. For example, the translation engine 114 can use alignment information associated with the source segment to identify one or more corresponding target segments.
- FIG. 2 is a block diagram illustrating an example of a hierarchically aligned bilingual repository 200 .
- documents of the repository are aligned for segments of multiple levels.
- source document 202 can be aligned with target document 204 .
- having aligned documents does not mean that the sentences of the two documents are aligned.
- two news stories that are translations of each other can be aligned as documents about the same news story.
- Hierarchically aligned documents allow for the identification of corresponding portions of the documents at several segment levels.
- the levels of alignment are illustrated for a particular source document 202 and target document 204 .
- Source document 202 includes three source paragraphs 206 .
- the target document 204 includes three target paragraphs 208 .
- the source paragraphs 206 and the target paragraphs 208 are also aligned.
- each source paragraph 206 includes source sentences 210 and each target paragraph 208 includes target sentence 212 .
- the source sentences 210 and target sentences 212 can also be aligned.
- a given sentence of the source document 202 is aligned with a corresponding translated sentence in the target document 204 .
- alignments between the source document 202 and target document 204 can also be performed. For example, alignments can be identified according to phrases or words in the documents. Additionally, in some implementations, alignments are identified at the character level. For example, in some ideographic languages (e.g., Chinese, Japanese, Korean), individual characters can be aligned.
- ideographic languages e.g., Chinese, Japanese, Korean
- FIG. 3 is a flowchart illustrating an example method 300 for generating a hierarchically aligned bilingual repository. For convenience, the method 300 will be described with respect to a system that performs the method 300 .
- the system receives 302 a collection of source documents and a corresponding collection of target documents (e.g., to be included in repository 102 of FIG. 1 ).
- the source and target documents can be a web corpus of news articles where the target documents represent translated news articles of source documents into a particular language.
- the collection of source and target documents are received from an external parallel corpus. For example, the United Nations proceedings providing parallel translations in six languages or a parallel corpus of news stories translated for different countries (e.g., a news organization can provide a web page including stories in multiple languages for readers in various countries).
- the collection of source documents and target documents are retrieved from the web, for example, as news stories.
- multiple collections of documents can be received, each having documents corresponding to translations of documents of other collections into another language.
- Each of the collections of documents can be a source collection or a target collection depending on the translation to be performed. For example, for translations of a French input into English, the source collection of documents can be French while the target collection of documents can include corresponding English translations of the source collection of documents.
- the system generates 304 a hierarchically aligned repository (e.g., using alignment engine 104 ).
- the repository can include multiple collections of documents.
- the hierarchically aligned repository includes one or more hierarchically aligned pairs of source and target collections of documents.
- the system can generate the hierarchical alignment for a given source and target collection of documents manually or using statistical techniques.
- the statistical techniques can include using, for example, an iterative process, e.g., an expectation-maximization algorithm, to find likely connections between source and target segments.
- the system receives a repository that includes one or more collections of documents that have already been hierarchically aligned with respect to each other.
- the system can receive multiple collections of documents and alignment data that identifies one or more hierarchical alignments between paired collections of documents, for example, identifying the alignments between particular source and target document segments.
- the resulting hierarchical aligned repository provides alignment information at multiple segment levels for a given source collection of documents and target collection of documents. For example, for a given source segment (e.g., a sentence), the alignment information identifies a location in the target collection of documents for a particular location in a target document that is a translation of the source segment. Similar alignment data is provided at different hierarchical levels, for example, document, paragraph, phrase, and word levels. In some implementations, the alignments between source and target collections of documents are bi-directional such that the alignment data also identifies locations in source documents corresponding to segments in the target documents.
- the system indexes 306 the hierarchical aligned repository (e.g., using indexing engine 106 ).
- a single source collection of documents in the repository is indexed.
- each collection of documents is similarly indexed such that any collection of documents can be used as the source collection of documents.
- the indexing identifies locations in the corresponding collection of documents for each segment of the collection of documents. For example, if the segment is a particular word, the indexing identifies each location of the word within the collection of documents. For example, by document number and position within the document.
- the index includes segments of each level, e.g., paragraphs, sentences, phrases, and words.
- the index is an inverted index.
- An inverted index is an index that stores a mapping from segments to their positions in a collection of documents. The index can be used for searching the collection of documents, for example, using information retrieval techniques to identify locations of segments in the collection of documents. An example of searching the index is described below.
- the index for each collection of documents can include the corresponding alignment information for one or more other collections of documents.
- the index not only identifies positions of the segment within the source collection of documents, but also identifies corresponding translations of the segment in one or more target collections of documents.
- alignment information can be stored in the parallel repository (e.g., parallel repository 102 ).
- the parallel repository can include one or more tables including alignment information at each hierarchal segment level.
- the tables include nested alignment information.
- a table can include the alignment information for a pair of documents.
- the paragraph entry can include nested alignment information for smaller segments (e.g., sentences).
- Each sentence can include further alignment information for the table, for example, between words.
- FIG. 4 is a flowchart illustrating an example method 400 for searching an aligned repository (e.g., parallel repository 102 ). For convenience, the method 400 will be described with respect to a system that performs the method 400 .
- the system receives 402 an input segment.
- the input segment can be received, for example, from a user.
- the input segment can be an entire document, a paragraph, sentence, or phrase.
- the input segment can be received, for example, as part of a request for a translation of the input segment. Additionally, in some implementations, the input segment is part of a sequence of input segments to be translated into a particular target language.
- the system provides 404 the input segment as a query to a search system (e.g., search system 112 of FIG. 1 ).
- the search system uses the input segment to search the source collection of documents.
- the search system uses an index for the source collection of documents and searches using conventional information retrieval techniques.
- the search system breaks the input segment into lower level segments. For example, if the input segment is a sentence, the search system can break the sentence into word segments and then perform the searching for each word, e.g., using an inverted index.
- the search system searches for the lower level segments as an OR query.
- the OR query can be conditioned to discard results that do not include a threshold number of the lower level segments.
- common segments e.g., stop words
- words can be weighted, for example, using inverse document frequency.
- the search system uses the index for the source collection of documents to search for the query terms (e.g., words in an input sentence) while requiring the terms to be within a specified edit distance of each other.
- a document identified as including a match to the input segment can include the query terms grouped together within some specified amount.
- the query terms are limited to the exact order with possible intervening words. For example, for each word the index is searched to identify one or more locations (e.g., document and position) for the word in the source collection to documents. For a sentence to match, the system can require that the identified locations for each word be within a threshold distance of each other.
- the search system can identify one or more candidate results for the input segment.
- the system receives 406 the one or more candidate results from the search system. For example, if the input segment is a document, the search system can return one or more candidate documents from the source collection. In some implementations, the search system returns the candidate results in a ranked order, for example, based on how similar the candidate results are to the input segment. In other implementations, the search system provides all candidate results that satisfy some baseline criteria without ranking.
- the machine translation system can then rank the candidate segments using one or more criteria (e.g., based on a similarity between each candidate segment and the input segment).
- the system determines 408 the similarity of each candidate segment to the input segment. For example, the system can determine similarity of each candidate segment to the input segment according to how closely the candidate segment matches the input segment. For example, the more words of the input segment that are found in the candidate segment, the more similar the two segments are. In another example, the smaller the edit distance of the candidate segment to the input segment, the more similar the candidate segment is taken to be to the input segment.
- the edit distance refers to the number of operations necessary (e.g., insertion, deletion, and substitution) to match a candidate segment to the input segment.
- the similarity can be determined by the search system or by another system component (e.g., similarity engine 110 ). In some implementations, the system assigns a similarity score to each candidate segment quantifying the degree of similarity between the candidate segment and the input segment.
- the system determines 410 whether one or more of the candidate segments exceed a threshold similarity amount.
- the system presents 412 one or more corresponding target segments (e.g., to a user). For example, for each candidate segment that exceeds the threshold, the corresponding target language segment can be identified, e.g., using the alignment information associated with the input segment.
- the search system can receive alignment information with the candidate segments as part of the index information for the candidate segments (e.g., when alignment is included along with the inverted index data).
- the search system can identify alignment information for a given candidate segment using alignment data stored, for example, as one or more alignment tables in the parallel repository.
- more than one target language segment is presented to the user for selection.
- a user interface can present the target language segments to the user. The user can then identify a particular target language segment to use as the translation of the input segment. Alternatively, the system can identify a single candidate segment that has a highest similarity level and then present the corresponding target language segment.
- the system identifies 414 one or more non-matching subsegments of the candidate input segment. For example, if the input segment is the sentence “ACME Corporation made an offer of 100 million dollars for the shares of ABC Corporation,” the identified candidate sentences may include all of the words except those specific to this deal e.g., the name of the companies and the amount. For example, one candidate segment identified can be “Widget Corporation made and offer of 50 million dollars for the shares of XYZ Corporation.”
- the differences between the input segment and the candidate sentence can result in a similarity that does not exceed the specified threshold.
- the system would not use the candidate sentence as a whole in translating the input segment.
- several subsegments (e.g., words) in the candidate segment can have a high confidence of matching the input segment, leaving only a few subsegments as non-matching.
- the system identifies “ACME” “100” and “ABC” as subsegments of the input segment that are non-matching with the candidate segment.
- the system separately searches 416 each of these subsegments, which are simply lower level segments (e.g., words of the sentence), using the search system to identify candidate subsegments.
- the system searches for each of the subsegments in a similar manner as the system searched for the entire sentence segment. For example, a search system can use the index for the collection of documents to identify the location of subsegments.
- the system replaces 418 the non-matching subsegments of the candidate segment with substitute subsegments.
- the subsegments “ACME” and “ABC” can replace the non-matching subsegments “Widget” and “XYZ” of the candidate segment, if found in the collection of documents. Consequently, a substitute candidate segment can be formed that includes subsegments that initially matched and substitute subsegments for non-matching portions of the candidate segment.
- the system determines 420 whether the substitute candidate segment exceeds the similarity threshold. Similarity of the substitute candidate segment can be based on the same criteria as determining the similarity of the candidate segment (e.g., matching words, edit distance).
- the system When the substitute candidate segment exceeds the similarity threshold, the system the system presents 422 one or more corresponding target segments (e.g., to a user). For example, for each substitute candidate segment that exceeds the threshold, the corresponding target language segment can be identified, e.g., using the alignment information associated with the input segment. For example, the search system can receive alignment information with the candidate segments as part of the index information for the candidate segments (e.g., when alignment is included along with the inverted index data). Alternatively, the search system can identify alignment information for a given candidate segment using alignment data stored, for example, as one or more alignment tables in the parallel repository.
- the system performs 424 further processing.
- the further processing includes one or more recursive searches for substitute subsegments at increasingly lower segment levels.
- a substitute candidate segment can include a document having substitute paragraph level subsegments for one or more non-matching paragraphs.
- the system can then search for non-matching sentence subsegments of the non-matching paragraphs to form another substitute candidate segment using substitute sentence subsegments.
- additional recursions can include phrase and word substitutions until the similarity threshold is met.
- the system can present an imperfect match to the user either with or without recursive attempts to provide a higher similarity match.
- the system can provide a target language segment that had the highest similarity to the input segment.
- the system can identify (e.g., using highlighting or other visual cues) non-matching portions (e.g., particular word or sentence subsegments) in the provided target language segment.
- the system provides additional information when presenting one or more target language segments. For example, when providing target language segments that are documents, the system can identify the source of the document. Thus, if the input document is a news article, the user can identify the organization responsible for the target language documents. The user can then make a selection of a target language document based on a source that the user considers more reliable or reputable.
- FIG. 5 is a schematic diagram of an example computer system 500 .
- the system 500 can be used for the operations described in association with the method 300 shown in FIG. 3 , according to one implementation or the method 400 shown in FIG. 4 , according to another implementation.
- the storage device 530 is capable of providing mass storage for the system 500 .
- the storage device 530 is a computer-readable medium.
- the storage device 530 can include, for example, a hard disk device, an optical disk device, or some other large capacity storage device.
- the input/output device 540 provides input/output operations for the system 500 .
- the input/output device 540 includes a keyboard and/or pointing device.
- the input/output device 540 includes a display unit for displaying graphical user interfaces.
- data processing apparatus encompasses all apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers.
- the apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
- a propagated signal is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus.
- the processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output.
- the processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer.
- a processor will receive instructions and data from a read-only memory or a random access memory or both.
- the essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- a computer need not have such devices.
- a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio player, a Global Positioning System (GPS) receiver, to name just a few.
- Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
- the processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described is this specification, or any combination of one or more such back-end, middleware, or front-end components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), e.g., the Internet.
- LAN local area network
- WAN wide area network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
Abstract
Description
- The present disclosure relates to machine translation.
- Machine translation systems are used to automatically translate text, speech, or other content from a source language to a target language. Conventional machine translation systems include dictionary-based machine translation, model-based machine translation, and instance-based machine translation.
- Instance-based machine translation systems typically include a repository of source data and corresponding repository of target data. For example, a collection of documents in the source language and corresponding translated documents in the target language. An input segment, for example a sentence, is translated from the source language to the target language by identifying a matching segment in the example source data. Typically, a matching segment in the source data is found by testing the input segment one at a time against each segment in the source data to identify an exact match. The target language segment corresponding to the matching source segment is then provided as the translation of the input segment.
- Systems, methods, and apparatuses, including computer program products, are provided for machine translation using information retrieval techniques. In general, one aspect of the subject matter described in this specification can be embodied in methods that include the actions of providing a received input segment as a query to a search engine, the search engine searching an index of one or more collections of documents, receiving one or more candidate segments in response to the query, determining a similarity of each candidate segment to the received input segment, and for one or more candidate segments having a determined similarity that exceeds a threshold similarity, providing a translated target segment corresponding to the respective candidate segment. Other embodiments of this aspect include corresponding systems, apparatus, and computer program products.
- These and other embodiments can optionally include one or more of the following features. The aspect can further include, for a candidate segment having a determined similarity that does not exceed the threshold similarity, identifying one or more subsegments of the input segment and providing one or more candidate subsegments corresponding to each of the one or more subsegments of the input segment. The aspect can further include identifying a non-matching subsegment of the candidate segment that does not match the corresponding subsegment of the input segment, identifying a matching candidate subsegment, and substituting the matching candidate subsegment for the non-matching candidate subsegment.
- Identifying a matching candidate subsegment can further include providing the identified subsegments as queries to the search engine, receiving the one or more candidate subsegments for each identified subsegment, and determining similarity of the candidate subsegments to the corresponding identified subsegment. The aspect can further include, for candidate subsegments having a similarity that does not exceed the threshold similarity, using a model-based statistical machine translation to identify target subsegments corresponding to the input subsegments.
- The aspect can further include receiving an input adjusting the similarity threshold, where adjusting the similarity threshold results in different sized candidate subsegments. The aspect can further include, providing target subsegments for each candidate subsegments having a determined similarity to the corresponding subsegment of the input segment that exceeds a threshold similarity. Providing target subsegments can include using alignment data for the candidate subsegment to identify a location of the target subsegment in a repository. Providing the target segment corresponding to the candidate segment can include using alignment data for the candidate segment to identify a location of the corresponding target segment.
- In general, one aspect of the subject matter described in this specification can be embodied in methods that include the actions of generating a hierarchical aligned repository of documents, the hierarchical aligned repository of documents including a plurality of segments, each segment being part of a pair that includes a source segment and a translated target segment, each source segment being aligned to a corresponding target segment, the plurality of segment including a hierarchy of segments having multiple segment levels, indexing each source segment of the repository, the indexing identifying each location of the respective source segment in the repository, and using information retrieval to search the index to identify one or more translated target segments for a given input segment. Other embodiments of this aspect include corresponding systems, apparatus, and computer program products.
- These and other embodiments can optionally include one or more of the following features. The aspect can further include generating a target index of the target segments from the repository of paired segments, where the index and target index are symmetric. The index can further include alignment data for each segment, the alignment data identifying a location of the corresponding target segment. The aspect can further include generating one or more alignment tables, the alignment tables identifying alignment information for each segment in the repository. Indexing can include generating an inverted index. The multiple segment levels can include paragraphs, sentences, and words.
- Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages. Information retrieval techniques can be used to provide quick retrieval in large data sets. Recursive techniques can be used to decompose segments into subsegments to provide greater translation accuracy. A user can ask the system to produce translations composed of retrieved target language segments at different levels of granularity.
- The details of one or more embodiments of the invention are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the invention will become apparent from the description, the drawings, and the claims.
-
FIG. 1 is a block diagram illustrating an example machine translation system. -
FIG. 2 is a block diagram illustrating an example of a hierarchically aligned bilingual repository. -
FIG. 3 is a flow chart illustrating an example method for generating a hierarchically aligned bilingual repository. -
FIG. 4 is a flow chart illustrating an example method for searching an aligned bilingual repository. -
FIG. 5 is a schematic diagram of an example computer system. - Like reference numbers and designations in the various drawings indicate like elements.
-
FIG. 1 is a block diagram illustrating an examplemachine translation system 100.Machine translation system 100 includes aparallel repository 102, analignment engine 104, anindexing engine 106, asubsegment engine 108, asimilarity engine 110, and atranslation engine 114. The machine translation system can include, or be coupled to, asearch system 112. For example, the components of themachine translation system 100 and thesearch system 112 can communicate across one or more networks. - The
parallel repository 102 includes a collection of documents in a source language (e.g., French) and corresponding translation collections of documents in one or more target languages (e.g., English). Theparallel repository 102 can include a number of different document types, including, e.g., web page and news article pairs where each pair includes text in the source language and the corresponding translated text in the target language. In another example, theparallel repository 102 can include multi-lingual data. For example, United Nations proceedings are available which provide parallel translations in six languages. - In some implementations, the
parallel repository 102 includes one or more collections of documents where each collection is associated with a different language. In some implementations, one collection of documents is designated a source collection and each other collection is designated as a target collection (e.g., the language to which an input in the source language is translated). Alternatively, any two collections of documents can be designated as a respective pair of source and target document collections depending on the translation to be performed. - Source language documents in the collection are hierarchically aligned with corresponding documents in one or more target language collections. For example, the
parallel repository 102 can be a hierarchically aligned bilingual repository (e.g., a single source language hierarchically aligned with a single target language). Alternatively, in some implementations, each collection of documents is hierarchically aligned with each other collection of documents such that any combination of collections of documents to provide multiple hierarchically aligned collections of documents. - The hierarchical aligned documents in the
parallel repository 102 provide paired segments associating content in one collection of documents with corresponding content in another collection of documents. For example, for particular source and target collections, each paired segment includes a source language segment and its corresponding translation into a target language segment. Paired segments can be identified according to the alignment of the collections in the repository. - A segment can be an entire document or a portion of a document including a paragraph, a sentence, a phrase, or other portion. In some implementations, segments are paired at more than one segment level (e.g., at both paragraph and sentence levels to form hierarchical aligned pairs). Thus, the
repository 102 can include pairs of more than one segment size for the same collection of source and target documents. Paired segments can be decomposed into paired subsegments (e.g., smaller included segments of a larger segment), for example, usingsubsegment engine 108, which is described below. - The
alignment engine 104 hierarchically aligns segments from the collection of source language documents to segments from the collection of target documents. The term “alignment” will be used to refer to a data structure that represents a segment-for-segment connection between source and target segments in a pair of documents. In some implementations, the alignment is simply a vector identifying positions of source segments that various target segments connect to. For example, a particular word in a source document can be aligned with a corresponding translated word or words in a target document (e.g., that a word segment “hello” in one source sentence aligns with the word segment “bonjour” of a target sentence). Hierarchical alignment aligns documents from one collection to documents of another collection at multiple segment levels (e.g., document segments, paragraph segments, sentence segments). Alignment can be performed using a number of techniques. For example, some alignments can be manually generated, e.g., by one or more individuals. Alternatively, statistical techniques can be used to generate an alignment between segments. - For example, if the source and target collections include parallel documents (e.g., each document in the source collection has a corresponding translated document in the target collection), documents in the source and target collections can be analyzed using, for example, an iterative process, e.g., expectation-maximization algorithm, to find likely connections between source and target segments.
- Additional details on alignment can be found, for example, in Franz Joseph Och and Hermann Ney, A Systematic Comparison of Various Statistical Alignment Models, Computational Linguistics, 29(1): 9-51, March 2003.
- The
subsegment engine 108 identifies subsegments from segments. Subsegments are smaller segments formed from a given segment. For example, a document segment can be divided into paragraphs segments, which are referred to in some implementations as subsegments of the document segment. Subsegments are formed from one or more of the segments and represent segments of a lesser level. For example, a document segment can be separated into paragraph subsegments. In some implementations, the subsegments can be further divided into sentence subsegments, word subsegments, character subsegments, etc. - The
indexing engine 106 indexes therepository 102. In some implementations, theindexing engine 106 only indexes the source collection of documents. Alternatively, theindexing engine 106 generates an index for both the source collection and the target collections in theparallel repository 102. The generated index can be, for example, an inverted index identifying a location for each source segment in theparallel repository 102. For example, a word segment can be indexed to identify each document of the collection in which the word occurs along with the specific position within the respective document (e.g., document 52, position 3). In some implementations, the index also includes alignment information identifying a location of one or more corresponding target segments (e.g., identifying a target document and position). - The
search system 112 identifies one or more source segments associated with an input segment using one or more information retrieval techniques. When an input is received at themachine translation system 100, the input (e.g., a segment to be translated) can be provided as a query to thesearch system 112. For example, when the input is received, the input is transmitted as a query through one or more wired or wireless networks to thesearch system 112. Thesearch system 112 can be implemented as, for example, computer programs running on one or more computers in one or more locations that are coupled to each other through a network. Thesearch system 112 can include a search engine. Thesearch system 112 responds to the query by generating search results, for example, results identifying the locations in the repository corresponding to the query. - When the query is received by the search engine, the search engine uses information retrieval techniques to identify relevant resources (e.g., documents in a source collection). The search engine will generally use an index (e.g., provided in an index database by indexing engine 106) that actively searches the
parallel repository 102. For example, the inverted index for a particular collection of documents can be searched. - The
similarity engine 110 determines a similarity measure between input segments and candidate source language segments. The similarity engine uses one or more criteria to determine whether the similarity between an input segment and a candidate source language segment exceeds a specified threshold level. For example, the similarity measure can be an edit-distance measure that computes a minimum number of edits applied to the input segment to yield the candidate source language segment. - The search engine will generally include a ranking engine (or other software) to rank the resources related to the query. The ranking of the resources can be performed using conventional techniques for determining an information retrieval score for indexed resources in view of a given query. The relevance of a particular resource with respect to a particular query term or to other provided information may be determined by any appropriate technique.
- The
translation engine 114 identifies one or more target segments corresponding to a source segment. For example, thetranslation engine 114 can use alignment information associated with the source segment to identify one or more corresponding target segments. -
FIG. 2 is a block diagram illustrating an example of a hierarchically alignedbilingual repository 200. In the hierarchically alignedbilingual repository 200, documents of the repository are aligned for segments of multiple levels. For example, at a high level,source document 202 can be aligned withtarget document 204. However, having aligned documents does not mean that the sentences of the two documents are aligned. For example, two news stories that are translations of each other can be aligned as documents about the same news story. However, without aligning the content of the stories at a more refined level, it is not known which particular sentences of the source news story correspond to particular sentences of the target news story. - Hierarchically aligned documents allow for the identification of corresponding portions of the documents at several segment levels. For example, in the hierarchical aligned
bilingual repository 200, the levels of alignment are illustrated for aparticular source document 202 andtarget document 204.Source document 202 includes threesource paragraphs 206. Thetarget document 204 includes threetarget paragraphs 208. Thesource paragraphs 206 and thetarget paragraphs 208 are also aligned. Additionally, eachsource paragraph 206 includessource sentences 210 and eachtarget paragraph 208 includestarget sentence 212. Thesource sentences 210 andtarget sentences 212 can also be aligned. Thus for example, a given sentence of thesource document 202 is aligned with a corresponding translated sentence in thetarget document 204. - Further alignments between the
source document 202 andtarget document 204 can also be performed. For example, alignments can be identified according to phrases or words in the documents. Additionally, in some implementations, alignments are identified at the character level. For example, in some ideographic languages (e.g., Chinese, Japanese, Korean), individual characters can be aligned. -
FIG. 3 is a flowchart illustrating anexample method 300 for generating a hierarchically aligned bilingual repository. For convenience, themethod 300 will be described with respect to a system that performs themethod 300. - The system receives 302 a collection of source documents and a corresponding collection of target documents (e.g., to be included in
repository 102 ofFIG. 1 ). For example, the source and target documents can be a web corpus of news articles where the target documents represent translated news articles of source documents into a particular language. In some implementations, the collection of source and target documents are received from an external parallel corpus. For example, the United Nations proceedings providing parallel translations in six languages or a parallel corpus of news stories translated for different countries (e.g., a news organization can provide a web page including stories in multiple languages for readers in various countries). Alternatively, in other implementations, the collection of source documents and target documents are retrieved from the web, for example, as news stories. - In some implementations, multiple collections of documents can be received, each having documents corresponding to translations of documents of other collections into another language. Each of the collections of documents can be a source collection or a target collection depending on the translation to be performed. For example, for translations of a French input into English, the source collection of documents can be French while the target collection of documents can include corresponding English translations of the source collection of documents.
- The system generates 304 a hierarchically aligned repository (e.g., using alignment engine 104). The repository can include multiple collections of documents. The hierarchically aligned repository includes one or more hierarchically aligned pairs of source and target collections of documents. The system can generate the hierarchical alignment for a given source and target collection of documents manually or using statistical techniques. The statistical techniques can include using, for example, an iterative process, e.g., an expectation-maximization algorithm, to find likely connections between source and target segments.
- Alternatively, in some implementations, the system receives a repository that includes one or more collections of documents that have already been hierarchically aligned with respect to each other. Thus, for example, the system can receive multiple collections of documents and alignment data that identifies one or more hierarchical alignments between paired collections of documents, for example, identifying the alignments between particular source and target document segments.
- The resulting hierarchical aligned repository provides alignment information at multiple segment levels for a given source collection of documents and target collection of documents. For example, for a given source segment (e.g., a sentence), the alignment information identifies a location in the target collection of documents for a particular location in a target document that is a translation of the source segment. Similar alignment data is provided at different hierarchical levels, for example, document, paragraph, phrase, and word levels. In some implementations, the alignments between source and target collections of documents are bi-directional such that the alignment data also identifies locations in source documents corresponding to segments in the target documents.
- The
system indexes 306 the hierarchical aligned repository (e.g., using indexing engine 106). In some implementations, a single source collection of documents in the repository is indexed. Alternatively, in some other implementations, each collection of documents is similarly indexed such that any collection of documents can be used as the source collection of documents. - The indexing identifies locations in the corresponding collection of documents for each segment of the collection of documents. For example, if the segment is a particular word, the indexing identifies each location of the word within the collection of documents. For example, by document number and position within the document. In some implementations, the index includes segments of each level, e.g., paragraphs, sentences, phrases, and words. In some implementations, the index is an inverted index. An inverted index is an index that stores a mapping from segments to their positions in a collection of documents. The index can be used for searching the collection of documents, for example, using information retrieval techniques to identify locations of segments in the collection of documents. An example of searching the index is described below.
- Additionally, the index for each collection of documents can include the corresponding alignment information for one or more other collections of documents. Thus, the index not only identifies positions of the segment within the source collection of documents, but also identifies corresponding translations of the segment in one or more target collections of documents.
- Alternatively, alignment information can be stored in the parallel repository (e.g., parallel repository 102). For example, the parallel repository can include one or more tables including alignment information at each hierarchal segment level. In some implementations, the tables include nested alignment information. For example, a table can include the alignment information for a pair of documents. For each aligned paragraph in the table, the paragraph entry can include nested alignment information for smaller segments (e.g., sentences). Each sentence can include further alignment information for the table, for example, between words.
-
FIG. 4 is a flowchart illustrating anexample method 400 for searching an aligned repository (e.g., parallel repository 102). For convenience, themethod 400 will be described with respect to a system that performs themethod 400. - The system receives 402 an input segment. The input segment can be received, for example, from a user. The input segment can be an entire document, a paragraph, sentence, or phrase. The input segment can be received, for example, as part of a request for a translation of the input segment. Additionally, in some implementations, the input segment is part of a sequence of input segments to be translated into a particular target language.
- The system provides 404 the input segment as a query to a search system (e.g.,
search system 112 ofFIG. 1 ). The search system uses the input segment to search the source collection of documents. In some implementations, the search system uses an index for the source collection of documents and searches using conventional information retrieval techniques. - In some implementations, the search system breaks the input segment into lower level segments. For example, if the input segment is a sentence, the search system can break the sentence into word segments and then perform the searching for each word, e.g., using an inverted index. In some implementation, the search system searches for the lower level segments as an OR query. However, the OR query can be conditioned to discard results that do not include a threshold number of the lower level segments. In some implementations, common segments (e.g., stop words) are discounted or removed from the search, for example, “a” and “the”. In some implementations, words can be weighted, for example, using inverse document frequency.
- In some other implementations, the search system uses the index for the source collection of documents to search for the query terms (e.g., words in an input sentence) while requiring the terms to be within a specified edit distance of each other. Thus, for example, a document identified as including a match to the input segment can include the query terms grouped together within some specified amount. In some implementations, the query terms are limited to the exact order with possible intervening words. For example, for each word the index is searched to identify one or more locations (e.g., document and position) for the word in the source collection to documents. For a sentence to match, the system can require that the identified locations for each word be within a threshold distance of each other.
- The search system can identify one or more candidate results for the input segment. The system receives 406 the one or more candidate results from the search system. For example, if the input segment is a document, the search system can return one or more candidate documents from the source collection. In some implementations, the search system returns the candidate results in a ranked order, for example, based on how similar the candidate results are to the input segment. In other implementations, the search system provides all candidate results that satisfy some baseline criteria without ranking. The machine translation system can then rank the candidate segments using one or more criteria (e.g., based on a similarity between each candidate segment and the input segment).
- The system determines 408 the similarity of each candidate segment to the input segment. For example, the system can determine similarity of each candidate segment to the input segment according to how closely the candidate segment matches the input segment. For example, the more words of the input segment that are found in the candidate segment, the more similar the two segments are. In another example, the smaller the edit distance of the candidate segment to the input segment, the more similar the candidate segment is taken to be to the input segment. The edit distance refers to the number of operations necessary (e.g., insertion, deletion, and substitution) to match a candidate segment to the input segment. The similarity can be determined by the search system or by another system component (e.g., similarity engine 110). In some implementations, the system assigns a similarity score to each candidate segment quantifying the degree of similarity between the candidate segment and the input segment.
- Whether the similarity of the candidate segments is identified by the search system or by the system separately, the system determines 410 whether one or more of the candidate segments exceed a threshold similarity amount.
- When the threshold is exceeded for one or more candidate segments, the system presents 412 one or more corresponding target segments (e.g., to a user). For example, for each candidate segment that exceeds the threshold, the corresponding target language segment can be identified, e.g., using the alignment information associated with the input segment. For example, the search system can receive alignment information with the candidate segments as part of the index information for the candidate segments (e.g., when alignment is included along with the inverted index data). Alternatively, the search system can identify alignment information for a given candidate segment using alignment data stored, for example, as one or more alignment tables in the parallel repository.
- In some implementations, more than one target language segment is presented to the user for selection. For example, a user interface can present the target language segments to the user. The user can then identify a particular target language segment to use as the translation of the input segment. Alternatively, the system can identify a single candidate segment that has a highest similarity level and then present the corresponding target language segment.
- When the threshold is not exceeded, the system identifies 414 one or more non-matching subsegments of the candidate input segment. For example, if the input segment is the sentence “ACME Corporation made an offer of 100 million dollars for the shares of ABC Corporation,” the identified candidate sentences may include all of the words except those specific to this deal e.g., the name of the companies and the amount. For example, one candidate segment identified can be “Widget Corporation made and offer of 50 million dollars for the shares of XYZ Corporation.”
- The differences between the input segment and the candidate sentence can result in a similarity that does not exceed the specified threshold. Thus, the system would not use the candidate sentence as a whole in translating the input segment. However, several subsegments (e.g., words) in the candidate segment can have a high confidence of matching the input segment, leaving only a few subsegments as non-matching.
- The system identifies “ACME” “100” and “ABC” as subsegments of the input segment that are non-matching with the candidate segment. The system separately searches 416 each of these subsegments, which are simply lower level segments (e.g., words of the sentence), using the search system to identify candidate subsegments. The system searches for each of the subsegments in a similar manner as the system searched for the entire sentence segment. For example, a search system can use the index for the collection of documents to identify the location of subsegments.
- The system replaces 418 the non-matching subsegments of the candidate segment with substitute subsegments. For example, the subsegments “ACME” and “ABC” can replace the non-matching subsegments “Widget” and “XYZ” of the candidate segment, if found in the collection of documents. Consequently, a substitute candidate segment can be formed that includes subsegments that initially matched and substitute subsegments for non-matching portions of the candidate segment.
- The system determines 420 whether the substitute candidate segment exceeds the similarity threshold. Similarity of the substitute candidate segment can be based on the same criteria as determining the similarity of the candidate segment (e.g., matching words, edit distance).
- When the substitute candidate segment exceeds the similarity threshold, the system the system presents 422 one or more corresponding target segments (e.g., to a user). For example, for each substitute candidate segment that exceeds the threshold, the corresponding target language segment can be identified, e.g., using the alignment information associated with the input segment. For example, the search system can receive alignment information with the candidate segments as part of the index information for the candidate segments (e.g., when alignment is included along with the inverted index data). Alternatively, the search system can identify alignment information for a given candidate segment using alignment data stored, for example, as one or more alignment tables in the parallel repository.
- When the substitute candidate segment does not exceed the similarity threshold, the system performs 424 further processing. In some implementations, the further processing includes one or more recursive searches for substitute subsegments at increasingly lower segment levels. For example, for an input segment that is a document, a substitute candidate segment can include a document having substitute paragraph level subsegments for one or more non-matching paragraphs. However, if the similarity threshold is not exceeded for the substitute candidate segment, the system can then search for non-matching sentence subsegments of the non-matching paragraphs to form another substitute candidate segment using substitute sentence subsegments. Similarly, additional recursions can include phrase and word substitutions until the similarity threshold is met.
- In some implementations, the system allows the user to increase or decrease the similarity threshold, resulting in translations with smaller or larger segments. In some other implementations, if the similarity threshold is not met, with or without recursive substitutions, the system can fail over to a model-based translation. For example, a model-based system using a language model and translation model can be used to predict a translated target segment based on probabilistic data derived from a corpus of text in the source and target languages.
- Alternatively, in some other implementations, the system can present an imperfect match to the user either with or without recursive attempts to provide a higher similarity match. For example, the system can provide a target language segment that had the highest similarity to the input segment. In some implementations, the system can identify (e.g., using highlighting or other visual cues) non-matching portions (e.g., particular word or sentence subsegments) in the provided target language segment.
- In some implementations, the system provides additional information when presenting one or more target language segments. For example, when providing target language segments that are documents, the system can identify the source of the document. Thus, if the input document is a news article, the user can identify the organization responsible for the target language documents. The user can then make a selection of a target language document based on a source that the user considers more reliable or reputable.
- The system can be used to provide instance based translations for various applications including language translation, speech recognition, and query correction/expansion.
-
FIG. 5 is a schematic diagram of anexample computer system 500. Thesystem 500 can be used for the operations described in association with themethod 300 shown inFIG. 3 , according to one implementation or themethod 400 shown inFIG. 4 , according to another implementation. - The
system 500 includes aprocessor 510, amemory 520, astorage device 530, and an input/output device 540. Each of thecomponents system bus 550. Theprocessor 510 is capable of processing instructions for execution within thesystem 500. In one implementation, theprocessor 510 is a single-threaded processor. In another implementation, theprocessor 510 is a multi-threaded processor. Theprocessor 510 is capable of processing instructions stored in thememory 520 or on thestorage device 530 to display graphical information for a user interface on the input/output device 540. In some embodiments, a parallel processing set ofsystems 500 connected over a network may be employed, clustered into one or more server centers. - The
memory 520 stores information within thesystem 500. In one implementation, thememory 520 is a computer-readable medium. In one implementation, thememory 520 is a volatile memory unit. In another implementation, thememory 520 is a non-volatile memory unit. - The
storage device 530 is capable of providing mass storage for thesystem 500. In one implementation, thestorage device 530 is a computer-readable medium. In various different implementations, thestorage device 530 can include, for example, a hard disk device, an optical disk device, or some other large capacity storage device. - The input/
output device 540 provides input/output operations for thesystem 500. In one implementation, the input/output device 540 includes a keyboard and/or pointing device. In another implementation, the input/output device 540 includes a display unit for displaying graphical user interfaces. - Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer program products, i.e., one or more modules of computer program instructions encoded on a computer-readable medium for execution by, or to control the operation of, data processing apparatus. The computer-readable medium can be a machine-readable storage device, a machine-readable storage substrate, a memory device, a composition of matter effecting a machine-readable propagated signal, or a combination of one or more of them. The term “data processing apparatus” encompasses all apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them. A propagated signal is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus.
- A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio player, a Global Positioning System (GPS) receiver, to name just a few. Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described is this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), e.g., the Internet.
- The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- While this specification contains many specifics, these should not be construed as limitations on the scope of the invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of the invention. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
- Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
- Thus, particular embodiments of the invention have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results.
Claims (47)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/108,415 US8972432B2 (en) | 2008-04-23 | 2008-04-23 | Machine translation using information retrieval |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/108,415 US8972432B2 (en) | 2008-04-23 | 2008-04-23 | Machine translation using information retrieval |
Publications (2)
Publication Number | Publication Date |
---|---|
US20140059033A1 true US20140059033A1 (en) | 2014-02-27 |
US8972432B2 US8972432B2 (en) | 2015-03-03 |
Family
ID=50148952
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/108,415 Active 2031-11-23 US8972432B2 (en) | 2008-04-23 | 2008-04-23 | Machine translation using information retrieval |
Country Status (1)
Country | Link |
---|---|
US (1) | US8972432B2 (en) |
Cited By (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140052436A1 (en) * | 2012-08-03 | 2014-02-20 | Oracle International Corporation | System and method for utilizing multiple encodings to identify similar language characters |
US20150066624A1 (en) * | 2013-08-27 | 2015-03-05 | Jon Anthony ASTORE | Method and system for providing a social media ecosystem cooperative marketplace |
US20150066689A1 (en) * | 2013-08-27 | 2015-03-05 | Jon Anthony ASTORE | Method and system for providing social media ecosystem compensation |
US9292886B2 (en) | 2013-08-27 | 2016-03-22 | Unittus, Inc. | Method and system for providing social media ecosystem classified listings |
US9348916B2 (en) | 2013-08-27 | 2016-05-24 | Unittus, Inc. | Method and system for providing search services for a social media ecosystem |
US20190197117A1 (en) * | 2017-02-07 | 2019-06-27 | Panasonic Intellectual Property Management Co., Ltd. | Translation device and translation method |
CN110765244A (en) * | 2019-09-18 | 2020-02-07 | 平安科技（深圳）有限公司 | Method and device for acquiring answering, computer equipment and storage medium |
CN110866407A (en) * | 2018-08-17 | 2020-03-06 | 阿里巴巴集团控股有限公司 | Analysis method, device and equipment for determining inter-translation text and similarity between texts |
US10997373B2 (en) * | 2019-04-09 | 2021-05-04 | Walmart Apollo, Llc | Document-based response generation system |
WO2022110428A1 (en) * | 2020-11-27 | 2022-06-02 | 江苏省舜禹信息技术有限公司 | Pre-translation editing method and system for machine translation of patent text |
Families Citing this family (120)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8677377B2 (en) | 2005-09-08 | 2014-03-18 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US10002189B2 (en) | 2007-12-20 | 2018-06-19 | Apple Inc. | Method and apparatus for searching using an active ontology |
US9330720B2 (en) | 2008-01-03 | 2016-05-03 | Apple Inc. | Methods and apparatus for altering audio output signals |
US20100030549A1 (en) | 2008-07-31 | 2010-02-04 | Lee Michael M | Mobile device having human language translation capability with positional feedback |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US8682667B2 (en) | 2010-02-25 | 2014-03-25 | Apple Inc. | User profiling for selecting user specific voice input processing information |
US9262612B2 (en) | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
US10057736B2 (en) | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
US10134385B2 (en) | 2012-03-02 | 2018-11-20 | Apple Inc. | Systems and methods for name pronunciation |
US10417037B2 (en) | 2012-05-15 | 2019-09-17 | Apple Inc. | Systems and methods for integrating third party services with a digital assistant |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US10652394B2 (en) | 2013-03-14 | 2020-05-12 | Apple Inc. | System and method for processing voicemail |
US10748529B1 (en) | 2013-03-15 | 2020-08-18 | Apple Inc. | Voice activated device for use with a voice-based digital assistant |
WO2014197335A1 (en) | 2013-06-08 | 2014-12-11 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
KR101959188B1 (en) | 2013-06-09 | 2019-07-02 | 애플 인크. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
US10296160B2 (en) | 2013-12-06 | 2019-05-21 | Apple Inc. | Method for extracting salient dialog usage from live data |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9842101B2 (en) * | 2014-05-30 | 2017-12-12 | Apple Inc. | Predictive conversion of language input |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US9633004B2 (en) | 2014-05-30 | 2017-04-25 | Apple Inc. | Better resolution when referencing to concepts |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US9818400B2 (en) | 2014-09-11 | 2017-11-14 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US10074360B2 (en) | 2014-09-30 | 2018-09-11 | Apple Inc. | Providing an indication of the suitability of speech recognition |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US10152299B2 (en) | 2015-03-06 | 2018-12-11 | Apple Inc. | Reducing response latency of intelligent automated assistants |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US10567477B2 (en) | 2015-03-08 | 2020-02-18 | Apple Inc. | Virtual assistant continuity |
US10460227B2 (en) | 2015-05-15 | 2019-10-29 | Apple Inc. | Virtual assistant in a communication session |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US10200824B2 (en) | 2015-05-27 | 2019-02-05 | Apple Inc. | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device |
US9578173B2 (en) | 2015-06-05 | 2017-02-21 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US11025565B2 (en) | 2015-06-07 | 2021-06-01 | Apple Inc. | Personalized prediction of responses for instant messaging |
US20160378747A1 (en) | 2015-06-29 | 2016-12-29 | Apple Inc. | Virtual assistant for media playback |
US10740384B2 (en) | 2015-09-08 | 2020-08-11 | Apple Inc. | Intelligent automated assistant for media search and playback |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10956666B2 (en) | 2015-11-09 | 2021-03-23 | Apple Inc. | Unconventional virtual assistant interactions |
US10049668B2 (en) | 2015-12-02 | 2018-08-14 | Apple Inc. | Applying neural network language models to weighted finite state transducers for automatic speech recognition |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
US20170185587A1 (en) * | 2015-12-25 | 2017-06-29 | Panasonic Intellectual Property Management Co., Ltd. | Machine translation method and machine translation system |
US11227589B2 (en) | 2016-06-06 | 2022-01-18 | Apple Inc. | Intelligent list reading |
US10049663B2 (en) | 2016-06-08 | 2018-08-14 | Apple, Inc. | Intelligent automated assistant for media exploration |
US10586535B2 (en) | 2016-06-10 | 2020-03-10 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
DK179415B1 (en) | 2016-06-11 | 2018-06-14 | Apple Inc | Intelligent device arbitration and control |
DK201670540A1 (en) | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
US10474753B2 (en) | 2016-09-07 | 2019-11-12 | Apple Inc. | Language identification using recurrent neural networks |
US10043516B2 (en) | 2016-09-23 | 2018-08-07 | Apple Inc. | Intelligent automated assistant |
US11281993B2 (en) | 2016-12-05 | 2022-03-22 | Apple Inc. | Model and ensemble compression for metric learning |
US11204787B2 (en) | 2017-01-09 | 2021-12-21 | Apple Inc. | Application integration with a digital assistant |
US10417266B2 (en) | 2017-05-09 | 2019-09-17 | Apple Inc. | Context-aware ranking of intelligent response suggestions |
DK201770383A1 (en) | 2017-05-09 | 2018-12-14 | Apple Inc. | User interface for correcting recognition errors |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
DK201770439A1 (en) | 2017-05-11 | 2018-12-13 | Apple Inc. | Offline personal assistant |
US10395654B2 (en) | 2017-05-11 | 2019-08-27 | Apple Inc. | Text normalization based on a data-driven learning network |
US10726832B2 (en) | 2017-05-11 | 2020-07-28 | Apple Inc. | Maintaining privacy of personal information |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
DK179496B1 (en) | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
US11301477B2 (en) | 2017-05-12 | 2022-04-12 | Apple Inc. | Feedback analysis of a digital assistant |
DK179745B1 (en) | 2017-05-12 | 2019-05-01 | Apple Inc. | SYNCHRONIZATION AND TASK DELEGATION OF A DIGITAL ASSISTANT |
DK201770432A1 (en) | 2017-05-15 | 2018-12-21 | Apple Inc. | Hierarchical belief states for digital assistants |
US10303715B2 (en) | 2017-05-16 | 2019-05-28 | Apple Inc. | Intelligent automated assistant for media exploration |
US20180336892A1 (en) | 2017-05-16 | 2018-11-22 | Apple Inc. | Detecting a trigger of a digital assistant |
US10403278B2 (en) | 2017-05-16 | 2019-09-03 | Apple Inc. | Methods and systems for phonetic matching in digital assistant services |
US10311144B2 (en) | 2017-05-16 | 2019-06-04 | Apple Inc. | Emoji word sense disambiguation |
DK179560B1 (en) | 2017-05-16 | 2019-02-18 | Apple Inc. | Far-field extension for digital assistant services |
US10657328B2 (en) | 2017-06-02 | 2020-05-19 | Apple Inc. | Multi-task recurrent neural network architecture for efficient morphology handling in neural language modeling |
US10445429B2 (en) | 2017-09-21 | 2019-10-15 | Apple Inc. | Natural language understanding using vocabularies with compressed serialized tries |
US10755051B2 (en) | 2017-09-29 | 2020-08-25 | Apple Inc. | Rule-based natural language processing |
US10552547B2 (en) | 2017-10-10 | 2020-02-04 | International Business Machines Corporation | Real-time translation evaluation services for integrated development environments |
US10636424B2 (en) | 2017-11-30 | 2020-04-28 | Apple Inc. | Multi-turn canned dialog |
US10733982B2 (en) | 2018-01-08 | 2020-08-04 | Apple Inc. | Multi-directional dialog |
US10733375B2 (en) | 2018-01-31 | 2020-08-04 | Apple Inc. | Knowledge-based framework for improving natural language understanding |
US10789959B2 (en) | 2018-03-02 | 2020-09-29 | Apple Inc. | Training speaker recognition models for digital assistants |
US10592604B2 (en) | 2018-03-12 | 2020-03-17 | Apple Inc. | Inverse text normalization for automatic speech recognition |
US10818288B2 (en) | 2018-03-26 | 2020-10-27 | Apple Inc. | Natural assistant interaction |
US10909331B2 (en) | 2018-03-30 | 2021-02-02 | Apple Inc. | Implicit identification of translation payload with neural machine translation |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
US10984780B2 (en) | 2018-05-21 | 2021-04-20 | Apple Inc. | Global semantic word embeddings using bi-directional recurrent neural networks |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
US10892996B2 (en) | 2018-06-01 | 2021-01-12 | Apple Inc. | Variable latency device coordination |
US11386266B2 (en) | 2018-06-01 | 2022-07-12 | Apple Inc. | Text correction |
DK201870355A1 (en) | 2018-06-01 | 2019-12-16 | Apple Inc. | Virtual assistant operation in multi-device environments |
DK179822B1 (en) | 2018-06-01 | 2019-07-12 | Apple Inc. | Voice interaction at a primary device to access call functionality of a companion device |
US10496705B1 (en) | 2018-06-03 | 2019-12-03 | Apple Inc. | Accelerated task performance |
CN109241238B (en) * | 2018-06-27 | 2022-02-08 | 阿里巴巴（中国）有限公司 | Article searching method and device and electronic equipment |
US11010561B2 (en) | 2018-09-27 | 2021-05-18 | Apple Inc. | Sentiment prediction from textual data |
US10839159B2 (en) | 2018-09-28 | 2020-11-17 | Apple Inc. | Named entity normalization in a spoken dialog system |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
US11170166B2 (en) | 2018-09-28 | 2021-11-09 | Apple Inc. | Neural typographical error modeling via generative adversarial networks |
US11475898B2 (en) | 2018-10-26 | 2022-10-18 | Apple Inc. | Low-latency multi-speaker speech recognition |
US11638059B2 (en) | 2019-01-04 | 2023-04-25 | Apple Inc. | Content playback on multiple devices |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
US11423908B2 (en) | 2019-05-06 | 2022-08-23 | Apple Inc. | Interpreting spoken requests |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
US11475884B2 (en) | 2019-05-06 | 2022-10-18 | Apple Inc. | Reducing digital assistant latency when a language is incorrectly determined |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11140099B2 (en) | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
DK180129B1 (en) | 2019-05-31 | 2020-06-02 | Apple Inc. | User activity shortcut suggestions |
US11289073B2 (en) | 2019-05-31 | 2022-03-29 | Apple Inc. | Device text to speech |
US11496600B2 (en) | 2019-05-31 | 2022-11-08 | Apple Inc. | Remote execution of machine-learned models |
DK201970510A1 (en) | 2019-05-31 | 2021-02-11 | Apple Inc | Voice identification in digital assistant systems |
US11360641B2 (en) | 2019-06-01 | 2022-06-14 | Apple Inc. | Increasing the relevance of new available information |
US11227599B2 (en) | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
US11488406B2 (en) | 2019-09-25 | 2022-11-01 | Apple Inc. | Text detection using global geometry estimators |
US11043220B1 (en) | 2020-05-11 | 2021-06-22 | Apple Inc. | Digital assistant hardware abstraction |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6356865B1 (en) * | 1999-01-29 | 2002-03-12 | Sony Corporation | Method and apparatus for performing spoken language translation |
US20020152081A1 (en) * | 2001-04-16 | 2002-10-17 | Mihoko Kitamura | Apparatus and method for adding information to a machine translation dictionary |
US20050197827A1 (en) * | 2004-03-05 | 2005-09-08 | Russ Ross | In-context exact (ICE) matching |
US20050228643A1 (en) * | 2004-03-23 | 2005-10-13 | Munteanu Dragos S | Discovery of parallel text portions in comparable collections of corpora and training using comparable texts |
US20060004560A1 (en) * | 2004-06-24 | 2006-01-05 | Sharp Kabushiki Kaisha | Method and apparatus for translation based on a repository of existing translations |
US20060116866A1 (en) * | 2004-11-02 | 2006-06-01 | Hirokazu Suzuki | Machine translation system, method and program |
US20060167675A1 (en) * | 2002-01-29 | 2006-07-27 | International Business Machines Corporation | TranslatinG method, translated sentence outputting method, recording medium, program, and computer device |
US20070094006A1 (en) * | 2005-10-24 | 2007-04-26 | James Todhunter | System and method for cross-language knowledge searching |
US7275029B1 (en) * | 1999-11-05 | 2007-09-25 | Microsoft Corporation | System and method for joint optimization of language model performance and size |
US20080300857A1 (en) * | 2006-05-10 | 2008-12-04 | Xerox Corporation | Method for aligning sentences at the word level enforcing selective contiguity constraints |
US20090240487A1 (en) * | 2008-03-20 | 2009-09-24 | Libin Shen | Machine translation |
US7949514B2 (en) * | 2007-04-20 | 2011-05-24 | Xerox Corporation | Method for building parallel corpora |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP0834139A4 (en) * | 1995-06-07 | 1998-08-05 | Int Language Engineering Corp | Machine assisted translation tools |
US8744835B2 (en) * | 2001-03-16 | 2014-06-03 | Meaningful Machines Llc | Content conversion method and apparatus |
WO2005033909A2 (en) * | 2003-10-08 | 2005-04-14 | Any Language Communications Inc. | Relationship analysis system and method for semantic disambiguation of natural language |
US7672830B2 (en) * | 2005-02-22 | 2010-03-02 | Xerox Corporation | Apparatus and methods for aligning words in bilingual sentences |
-
2008
- 2008-04-23 US US12/108,415 patent/US8972432B2/en active Active
Patent Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6356865B1 (en) * | 1999-01-29 | 2002-03-12 | Sony Corporation | Method and apparatus for performing spoken language translation |
US7275029B1 (en) * | 1999-11-05 | 2007-09-25 | Microsoft Corporation | System and method for joint optimization of language model performance and size |
US20020152081A1 (en) * | 2001-04-16 | 2002-10-17 | Mihoko Kitamura | Apparatus and method for adding information to a machine translation dictionary |
US20060167675A1 (en) * | 2002-01-29 | 2006-07-27 | International Business Machines Corporation | TranslatinG method, translated sentence outputting method, recording medium, program, and computer device |
US20050197827A1 (en) * | 2004-03-05 | 2005-09-08 | Russ Ross | In-context exact (ICE) matching |
US20050228643A1 (en) * | 2004-03-23 | 2005-10-13 | Munteanu Dragos S | Discovery of parallel text portions in comparable collections of corpora and training using comparable texts |
US20060004560A1 (en) * | 2004-06-24 | 2006-01-05 | Sharp Kabushiki Kaisha | Method and apparatus for translation based on a repository of existing translations |
US20060116866A1 (en) * | 2004-11-02 | 2006-06-01 | Hirokazu Suzuki | Machine translation system, method and program |
US20070094006A1 (en) * | 2005-10-24 | 2007-04-26 | James Todhunter | System and method for cross-language knowledge searching |
US20080300857A1 (en) * | 2006-05-10 | 2008-12-04 | Xerox Corporation | Method for aligning sentences at the word level enforcing selective contiguity constraints |
US7949514B2 (en) * | 2007-04-20 | 2011-05-24 | Xerox Corporation | Method for building parallel corpora |
US20090240487A1 (en) * | 2008-03-20 | 2009-09-24 | Libin Shen | Machine translation |
Cited By (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9128915B2 (en) * | 2012-08-03 | 2015-09-08 | Oracle International Corporation | System and method for utilizing multiple encodings to identify similar language characters |
US20140052436A1 (en) * | 2012-08-03 | 2014-02-20 | Oracle International Corporation | System and method for utilizing multiple encodings to identify similar language characters |
US9348916B2 (en) | 2013-08-27 | 2016-05-24 | Unittus, Inc. | Method and system for providing search services for a social media ecosystem |
US20150066689A1 (en) * | 2013-08-27 | 2015-03-05 | Jon Anthony ASTORE | Method and system for providing social media ecosystem compensation |
US9292885B2 (en) | 2013-08-27 | 2016-03-22 | Unittus, Inc. | Method and system for providing social search and connection services with a social media ecosystem |
US9292886B2 (en) | 2013-08-27 | 2016-03-22 | Unittus, Inc. | Method and system for providing social media ecosystem classified listings |
US20150066624A1 (en) * | 2013-08-27 | 2015-03-05 | Jon Anthony ASTORE | Method and system for providing a social media ecosystem cooperative marketplace |
US9824404B2 (en) * | 2013-08-27 | 2017-11-21 | Unittus, Inc. | Method and system for providing a social media ecosystem cooperative marketplace |
US20190197117A1 (en) * | 2017-02-07 | 2019-06-27 | Panasonic Intellectual Property Management Co., Ltd. | Translation device and translation method |
US11048886B2 (en) * | 2017-02-07 | 2021-06-29 | Panasonic Intellectual Property Management Co., Ltd. | Language translation by dividing character strings by fixed phases with maximum similarity |
CN110866407A (en) * | 2018-08-17 | 2020-03-06 | 阿里巴巴集团控股有限公司 | Analysis method, device and equipment for determining inter-translation text and similarity between texts |
US10997373B2 (en) * | 2019-04-09 | 2021-05-04 | Walmart Apollo, Llc | Document-based response generation system |
CN110765244A (en) * | 2019-09-18 | 2020-02-07 | 平安科技（深圳）有限公司 | Method and device for acquiring answering, computer equipment and storage medium |
WO2022110428A1 (en) * | 2020-11-27 | 2022-06-02 | 江苏省舜禹信息技术有限公司 | Pre-translation editing method and system for machine translation of patent text |
Also Published As
Publication number | Publication date |
---|---|
US8972432B2 (en) | 2015-03-03 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8972432B2 (en) | Machine translation using information retrieval | |
Liu et al. | Opinion target extraction using word-based translation model | |
US20120047172A1 (en) | Parallel document mining | |
US8521516B2 (en) | Linguistic key normalization | |
US8706474B2 (en) | Translation of entity names based on source document publication date, and frequency and co-occurrence of the entity names | |
US20130060769A1 (en) | System and method for identifying social media interactions | |
US20070021956A1 (en) | Method and apparatus for generating ideographic representations of letter based names | |
KR101500617B1 (en) | Method and system for Context-sensitive Spelling Correction Rules using Korean WordNet | |
US8280721B2 (en) | Efficiently representing word sense probabilities | |
US8423350B1 (en) | Segmenting text for searching | |
US20100153396A1 (en) | Name indexing for name matching systems | |
JP2006012168A (en) | Method for improving coverage and quality in translation memory system | |
US8204736B2 (en) | Access to multilingual textual resources | |
RU2579873C2 (en) | Resolution of semantic ambiguity using semantic classifier | |
Zitouni et al. | Mention detection crossing the language barrier | |
US7593844B1 (en) | Document translation systems and methods employing translation memories | |
Paramita et al. | Methods for collection and evaluation of comparable documents | |
US9189475B2 (en) | Indexing mechanism (nth phrasal index) for advanced leveraging for translation | |
Dietz et al. | Across-Document Neighborhood Expansion: UMass at TAC KBP 2012 Entity Linking. | |
Ling et al. | Named entity translation using anchor texts | |
Hakkani-Tür et al. | Translating natural language utterances to search queries for slu domain detection using query click logs | |
Dadashkarimi et al. | A probabilistic translation method for dictionary-based cross-lingual information retrieval in agglutinative languages | |
Mei et al. | Post-processing OCR text using web-scale corpora | |
Kwok et al. | CHINET: a Chinese name finder system for document triage | |
Abdelali et al. | Uclir: a multilingual information retrieval tool |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ALSHAWI, HIYAN;BRANTS, THORSTEN;REEL/FRAME:021095/0272Effective date: 20080422 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044334/0466Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |