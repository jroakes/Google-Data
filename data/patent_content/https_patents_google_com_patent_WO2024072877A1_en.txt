WO2024072877A1 - Learning the joint distribution of two sequences using little or no paired data - Google Patents
Learning the joint distribution of two sequences using little or no paired data Download PDFInfo
- Publication number
- WO2024072877A1 WO2024072877A1 PCT/US2023/033841 US2023033841W WO2024072877A1 WO 2024072877 A1 WO2024072877 A1 WO 2024072877A1 US 2023033841 W US2023033841 W US 2023033841W WO 2024072877 A1 WO2024072877 A1 WO 2024072877A1
- Authority
- WO
- WIPO (PCT)
- Prior art keywords
- model
- sequence domain
- data
- computing system
- training
- Prior art date
Links
- 238000009826 distribution Methods 0.000 title claims description 20
- 238000012549 training Methods 0.000 claims description 100
- 238000000034 method Methods 0.000 claims description 75
- 238000012545 processing Methods 0.000 claims description 15
- 238000013528 artificial neural network Methods 0.000 claims description 13
- 230000001143 conditioned effect Effects 0.000 claims description 11
- 230000006870 function Effects 0.000 claims description 8
- 230000000306 recurrent effect Effects 0.000 claims description 5
- 238000013459 approach Methods 0.000 abstract description 34
- 230000008569 process Effects 0.000 description 49
- 230000015654 memory Effects 0.000 description 12
- 230000008901 benefit Effects 0.000 description 6
- 238000010586 diagram Methods 0.000 description 6
- 238000003860 storage Methods 0.000 description 6
- 238000013519 translation Methods 0.000 description 5
- 230000000007 visual effect Effects 0.000 description 5
- 238000004891 communication Methods 0.000 description 4
- 238000012015 optical character recognition Methods 0.000 description 4
- 230000004075 alteration Effects 0.000 description 3
- 238000010801 machine learning Methods 0.000 description 3
- 239000011159 matrix material Substances 0.000 description 3
- 230000011218 segmentation Effects 0.000 description 3
- 238000007476 Maximum Likelihood Methods 0.000 description 2
- 230000015572 biosynthetic process Effects 0.000 description 2
- 238000013527 convolutional neural network Methods 0.000 description 2
- 238000001514 detection method Methods 0.000 description 2
- 230000000694 effects Effects 0.000 description 2
- 238000003709 image segmentation Methods 0.000 description 2
- 238000013507 mapping Methods 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 239000000203 mixture Substances 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 238000005070 sampling Methods 0.000 description 2
- 238000003786 synthesis reaction Methods 0.000 description 2
- 238000012800 visualization Methods 0.000 description 2
- 241000282326 Felis catus Species 0.000 description 1
- AYFVYJQAPQTCCC-GBXIJSLDSA-N L-threonine Chemical compound C[C@@H](O)[C@H](N)C(O)=O AYFVYJQAPQTCCC-GBXIJSLDSA-N 0.000 description 1
- 230000009471 action Effects 0.000 description 1
- 238000007792 addition Methods 0.000 description 1
- 239000000654 additive Substances 0.000 description 1
- 230000000996 additive effect Effects 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000006243 chemical reaction Methods 0.000 description 1
- 238000013329 compounding Methods 0.000 description 1
- 238000007906 compression Methods 0.000 description 1
- 230000006835 compression Effects 0.000 description 1
- 230000003750 conditioning effect Effects 0.000 description 1
- 238000013144 data compression Methods 0.000 description 1
- 238000000354 decomposition reaction Methods 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 238000009472 formulation Methods 0.000 description 1
- 230000002068 genetic effect Effects 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 238000002372 labelling Methods 0.000 description 1
- 230000003121 nonmonotonic effect Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 102000004169 proteins and genes Human genes 0.000 description 1
- 108090000623 proteins and genes Proteins 0.000 description 1
- 230000004044 response Effects 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 230000035945 sensitivity Effects 0.000 description 1
- 230000006403 short-term memory Effects 0.000 description 1
- 238000006467 substitution reaction Methods 0.000 description 1
- 230000026676 system process Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0475—Generative networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
- G06N3/0455—Auto-encoder networks; Encoder-decoder networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/047—Probabilistic or stochastic networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/088—Non-supervised learning, e.g. competitive learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/092—Reinforcement learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/094—Adversarial learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L13/00—Speech synthesis; Text to speech systems
- G10L13/08—Text analysis or generation of parameters for speech synthesis out of text, e.g. grapheme to phoneme translation, prosody generation or stress or intonation determination
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/16—Speech classification or search using artificial neural networks
Definitions
- the present disclosure relates generally to machine learning. More particularly, the present disclosure relates to a noisy channel generative model of two sequences, for example text and speech, which enables uncovering the associations between the two modalities when limited paired data is available.
- a classical approach to speech recognition is to treat the process of generating speech audio as a noisy channel, where text is drawn from some distribution and then statistically transformed into speech audio, and the task of speech recognition is to invert this generative model to infer the text most likely to have given rise to a given speech waveform.
- This generative model of speech audio was historically successful but has been superseded in all modern discriminative systems by directly modeling the conditional distribution of text given speech. [0005]
- the direct approach has the advantage of allowing limited modeling power to be solely devoted to the task of interest, whereas the generative approach can be extremely sensitive to faulty assumptions in the speech audio model despite the fact that this is not the primary object of interest.
- One example aspect of the present disclosure is directed to a computer- implemented method to learn a noisy channel generative model for a first sequence domain and a second sequence domain.
- the method includes, for one or more generative training iterations: obtaining, by the computing system from the training dataset, an unpaired training example from the second sequence domain; processing, by the computing system, the unpaired training example from the second sequence domain with an encoder model to generate a sample from the first sequence domain; determining, by the computing system, a first likelihood that the unpaired training example from the second sequence domain is output from a decoder model when conditioned on the sample from the first sequence domain generated by the encoder model; and updating, by the computing system, one or more parameter values of the decoder model based at least in part on the first likelihood.
- the method includes, for one or more variational training iterations: generating, by the computing system, a sample from the second sequence domain using the decoder model when conditioned on data from the first sequence domain; determining, by the computing system, a second likelihood that the data from the first sequence domain is output by the encoder model when conditioned on the sample from the second sequence domain; and updating, by the computing system, one or more parameter values of the encoder model based at least in part on the second likelihood.
- Another example aspect of the present disclosure is directed to a computer system that includes one or more processors and one or more non-transitory computer- readable media that collectively store: a noisy channel generative model of two sequences, wherein the noisy channel generative model has been learned using a variational posterior model; and instructions that, when executed by the one or more processors, cause the computer system to implement the noisy channel generative model to convert data from a second sequence domain to a first sequence domain.
- Another example aspect of the present disclosure is directed to a computer system that includes one or more processors and one or more non-transitory computer- readable media that collectively store: a noisy channel generative model of two sequences, wherein the noisy channel generative model has been learned using a KL encoder loss function; and instructions that, when executed by the one or more processors, cause the computer system to implement the noisy channel generative model to convert data from a second sequence domain to a first sequence domain.
- Other aspects of the present disclosure are directed to various systems, apparatuses, non-transitory computer-readable media, user interfaces, and electronic devices.
- Figure 1B depicts an example generative training approach applied when an paired training example from both the first sequence domain and a second sequence domain is retrieved from the training dataset according to example embodiments of the present disclosure.
- Figure 1C depicts an example generative training approach applied when an unpaired training example from the second sequence domain is retrieved from the training dataset according to example embodiments of the present disclosure.
- Figure 1D depicts an example variational training approach for training an encoder model according to example embodiments of the present disclosure.
- Figure 1E depicts an example inference approach according to example embodiments of the present disclosure.
- Figure 2A depicts a block diagram of an example computing system according to example embodiments of the present disclosure.
- Figure 2B depicts a block diagram of an example computing device according to example embodiments of the present disclosure.
- Figure 2C depicts a block diagram of an example computing device according to example embodiments of the present disclosure.
- Reference numerals that are repeated across plural figures are intended to identify the same features in various implementations.
- DETAILED DESCRIPTION Overview [0022] Generally, the present disclosure is directed to a noisy channel generative model of two sequences, for example text and speech, which enables uncovering the associations between the two modalities when limited paired data is available. To address the intractability of the exact model under a realistic data set-up, example aspects of the present disclosure include a variational inference approximation.
- the present disclosure provides a noisy channel joint model of text and speech for learning from a corpus consisting of relatively large amounts of text-only data and speech-only data, but little or no parallel (text, speech) data.
- Example implementations cope with the sensitivity of generative modeling to faulty modeling assumptions by trying to make the generative model as accurate as possible, and cope with the resulting intractable inference problem using a variational approximate posterior of text given speech.
- An analogous formulation in the other direction can be adopted for text to speech models.
- Similar to discrete latent variable models when the proposed variational approach infers a discrete quantity (e.g., text or phoneme), the typical stochastic gradient variational Bayes approach is not applicable and requires a different optimization procedure. In response, the present disclosure proposed a method that can be referred to as KL encoder loss.
- one aspect of the present disclosure is directed to a noisy channel joint model of text and speech distribution.
- the noisy channel joint model can be developed through the use of a variational noisy channel model or encoder.
- Another aspect of the present disclosure is directed to a KL encoder loss to train the discrete latent variable models.
- the systems and methods of the present disclosure provide a number of technical effects.
- the proposed approaches enable improved learning of joint distributions even in settings with little to no paired training data. This enables application of the proposed techniques to many domains that previously were not explored using joint probabilities due to the lack of paired training data for such domains.
- generation e.g., labeling
- the proposed approaches reduce the computational cost of learning of joint distributions.
- the proposed approaches enable the more principled generative approach to be extended to additional domains (e.g., as opposed to discriminative approaches).
- Figures 1A-D show example approaches to learn a noisy channel generative model for a first sequence domain and a second sequence domain according to example aspects of the present disclosure.
- the first sequence domain comprises textual sequences and the second sequence domain comprises sequences of speech data.
- the speech data can be expressed as a raw waveform or using Mel spectrograms.
- the second sequence domain comprises textual sequences and the first sequence domain comprises sequences of speech data.
- the first sequence domain comprises textual sequences and the second sequence domain comprises sequences of image data corresponding to rendered characters.
- the first sequence domain comprises sequences expressed in a first language (e.g., English) and the second sequence domain comprises sequences expressed in a second language (e.g., French).
- Other sequential domains are possible as well such as genetic sequences, protein sequences, sequences of sensor data, and/or other forms of sequential data.
- Figure 1A depicts an example generative training approach applied when an unpaired training example from a first sequence domain is retrieved from a training dataset according to example embodiments of the present disclosure.
- a computing system obtains, from a training dataset, an unpaired training example 12 from the first sequence domain.
- the computing system determines a likelihood 16 that the unpaired training example 12 from the first sequence domain is output from a prior model 14.
- Figure 1B depicts an example generative training approach applied when an paired training example from both the first sequence domain and a second sequence domain is retrieved from the training dataset according to example embodiments of the present disclosure.
- a computing system obtains, from the training dataset, a paired training example 20 comprising paired training data from the first sequence domain 22 and paired training data from the second sequence domain.
- the computing system determines a likelihood 30 that the paired training data from the first sequence domain is output from the prior model 14 and updates one or more parameter values of the prior model 14 based at least in part on the likelihood 30.
- FIG. 1C depicts an example generative training approach applied when an unpaired training example from the second sequence domain is retrieved from the training dataset according to example embodiments of the present disclosure.
- a computing system obtains, from the training dataset, an unpaired training example from the second sequence domain 32.
- the computing system processes the unpaired training example from the second sequence domain 32 with an encoder model 34 to generate a sample from the first sequence domain 36.
- the computing system determines a likelihood 40 that the unpaired training example from the second sequence domain 32 is output from a decoder model 24 when conditioned on the sample from the first sequence domain 36 generated by the encoder model 34.
- the computing system updates one or more parameter values of the decoder model 24 based at least in part on the likelihood 40.
- the computing system can additionally determine a likelihood 38 that the sample from the first sequence domain 36 is output by the prior model 14 and can update one or more parameters of the prior model 14 based on the likelihood 38.
- Figure 1D depicts an example variational training approach for training an encoder model according to example embodiments of the present disclosure.
- a computing system generates a sample from the second sequence domain 62 using the decoder model 24 when conditioned on data from the first sequence domain 60.
- the computing system determines a likelihood 64 that the data from the first sequence domain 60 is output by the encoder model 34 when conditioned on the sample from the second sequence domain 62.
- the computing system updates one or more parameter values of the encoder model 34 based at least in part on the likelihood 64.
- the data from the first sequence domain 60 can be or include a sample from the first sequence domain generated by the prior model 14.
- Figure 1E depicts an example inference approach according to example embodiments of the present disclosure.
- a computing system can invert the decoder model 24 to generate data from the first sequential domain (e.g., text 72) when provided with data from the second sequential domain (e.g., speech data 70).
- Example Models [0037] This section describes an example proposed joint model of two sequences and how to train it.
- the two sequences ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ and ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ may be different lengths ( ⁇ ⁇ ⁇ ) and may each have discrete or continuous values.
- For the first sequence ⁇ might be text consisting of a sequence of graphemes and the ⁇ a sequence of mel spectrogram frames in an application related to speech recognition and synthesis, or ⁇ might be text and ⁇ a sequence of image patches corresponding to printed characters in an application related to optical character recognition.
- Some example implementations assume that there is a mix of paired and unpaired data. Specifically some example implementations assume the corpus is generated by repeatedly and independently sampling a sequence pair ⁇ , ⁇ from the true distribution (or data distribution) ⁇ ⁇ ⁇ , ⁇ and then keeping only ⁇ with probability ⁇ , only ⁇ with probability ⁇ , or both ⁇ and ⁇ with probability ⁇ , where ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ 1. Some example implementations refer to ⁇ as the paired fraction. Some example implementations are applied in the regime ⁇ ⁇ 1, including the extreme case ⁇ ⁇ 0 where there is no paired data. [0039] One advantage of generative modeling is that it provides a principled way to use unpaired data during parameter estimation.
- the model ⁇ ⁇ ⁇ , ⁇ defines a joint distribution over the two sequences ⁇ and ⁇ with parameters ⁇ , which in turn defines marginals ⁇ ⁇ ⁇ and ⁇ ⁇ ⁇ . If the marginals are tractable then some example implementations may estimate ⁇ by minimizing the cross-entropy ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ log ⁇ ⁇ ⁇ ⁇ ⁇ 1 ⁇ where ⁇ is “whatever is observed” for a given example, be that ⁇ or ⁇ or ⁇ , ⁇ . In practice the expectation over ⁇ ⁇ ⁇ is replaced with samples from the training corpus yielding a form of maximum likelihood estimation.
- Equation (1) can be written concisely as the KL divergence ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ with the understanding that the unknown but irrelevant additive constant ⁇ ⁇ ⁇ ⁇ ⁇ log ⁇ ⁇ ⁇ is not computed in practice.
- This KL divergence can in turn be written as ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ 2 ⁇ ⁇ ⁇ , ⁇ ⁇ ⁇ ⁇ , ⁇ [0040]
- This loss incentivizes the model to match both the marginal and joint distributions of the data.
- the generative model used in some example implementations is a form of noisy channel model.
- Some example implementations factorize ⁇ ⁇ ⁇ , ⁇ in terms of a prior ⁇ ⁇ ⁇ and decoder ⁇ ⁇ ⁇
- Some example implementations can use recurrent autoregressive models with step-by-step end-of-sequence decisions for both the prior and decoder, using attention to incorporate the conditioning information ⁇ for the decoder.
- the noisy channel model allows directly computing ⁇ ⁇ ⁇ and ⁇ ⁇ ⁇ , ⁇ .
- the marginal ⁇ ⁇ ⁇ is tractable for simple models such as a Markovian prior and decoder.
- some example implementations introduce a variational posterior (or encoder) ⁇ ⁇ ⁇
- This is the objective (ELBO) up to a constant.
- variational latent variable models such as variational autoencoders (VAEs)
- VAEs variational autoencoders
- VAEs variational autoencoders
- Example KL Encoder Loss [0044] To cope with discrete-valued ⁇ , some example implementations can perform a novel variant of the wake-sleep algorithm. This section describes this approach. [0045] First, this section reviews why discrete ⁇ is more challenging than continuous ⁇ . The expression (3) involves an expectation over ⁇ ⁇ ⁇
- this challenge applies even if ⁇ has continuous values, since the length of ⁇ is unknown and discrete.
- Some example implementations solve this problem by modifying the loss used to train the variational posterior. Instead of minimizing ⁇ ⁇ ⁇ ⁇ ⁇
- Some example implementations continue to train the generative model parameters ⁇ as before. This training procedure is similar to the wake-sleep algorithm, where the ⁇ updates and ⁇ updates correspond to the wake phase and sleep phase respectively.
- This approach can be referred to as KL encoder loss training since the variational posterior appears in the right “KL” argument to the KL divergence, as opposed to the conventional ELBO for which the variational posterior appears in the left “reverse KL” argument to the KL divergence.
- the conventional ELBO and KL encoder loss have the same non- parametric optimal variational posterior, namely ⁇
- the two approaches place different computational demands on ⁇ ⁇ and ⁇ ⁇ .
- the approach requires tractable reparameterized samples and log prob computations for tractable log prob computations for ⁇ ⁇ ⁇ , ⁇ .
- the KL encoder loss approach requires tractable log prob computations for ⁇ ⁇ ⁇
- ⁇ are ⁇ ⁇ ⁇ ; ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ log ⁇ ⁇ ⁇ ⁇ [0051]
- ⁇ ⁇ ⁇ ⁇ ; ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ log ⁇ ⁇ ⁇ ⁇ ⁇ [0051] In can a approximation based on the training corpus in the natural way, using the ⁇ term for examples where only ⁇ is observed, the ⁇ term for examples where only ⁇ is observed, and the ⁇ term for examples where both ⁇ and ⁇ are observed.
- Some example implementations perform simultaneous gradient descent on ⁇ , ⁇ based on the gradients ⁇ ⁇ ⁇ ⁇ ; ⁇ / ⁇ , ⁇ ⁇ ; ⁇ / ⁇ . [0052] Some example implementations perform some or all of the variations for training. Firstly, samples from autoregressive models can suffer from small errors compounding over time, particularly when trained with maximum likelihood estimation / KL. This only weakly penalizes unrealistic next-step samples because KL is a “covering” rather than “mode-seeking” divergence. Another approach is to adjust the temperature of the distribution. The prior, decoder and variational posterior are all trained with KL, and some example implementations apply temperature adjustment when sampling from these models during both training and decoding.
- some example implementations recursively sample from 1 ⁇ instead of ⁇ ⁇ ⁇ ⁇
- the generative model and variational posterior are both very suboptimal, and the noisy gradients from the ⁇ term of ⁇ ⁇ may swamp the small but consistent signal from the paired data ⁇ term when training the decoder.
- some example implementations pre-train with the ⁇ term omitted from ⁇ ⁇ , effectively ignoring the ⁇ - only data.
- some example implementations optionally ignore the ELBO term throughout training when updating the prior ⁇ ⁇ ⁇ .
- identifiability given no paired data say a generative model ⁇ ⁇ ⁇ , ⁇ is identifiable given no paired data if matching the marginals implies matching the joint, that is if ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ for all sequences ⁇ and ⁇ ⁇ ⁇ ⁇ ⁇ for all sequences ⁇ implies ⁇ ⁇ ⁇ , ⁇ ⁇ ⁇ and ⁇ .
- Some example implementations do not require ⁇ ⁇ ⁇ ⁇ . It may be thought of as follows: ⁇ ⁇ as the true parameters and ⁇ as the model parameters being learned. [0057] Even in the case where the model is identifiable, local optima may be a substantial impediment to learning.
- a decoder has strict time locality if the overall probability can be written as a product of time-local factors ⁇ ⁇ ⁇ ⁇ ⁇
- the decoder ⁇ ⁇ ⁇
- Some example implementations refer to a decoder as time local if (6) holds approximately. If it is assumed that the true marginal ⁇ ⁇ ⁇ has long-range correlations which mean it is either not time local, or is time local with time constant much greater than ⁇ , then the way for the model as a whole to capture these correlations across time in its marginal ⁇ ⁇ ⁇ is to induce them from corresponding correlations across time in ⁇ . This provides the generative model with an incentive to uncover how ⁇ maps to ⁇ . [0061] Time locality is an intuitively reasonable assumption in many seq2seq problems such as speech recognition and synthesis, optical character recognition and machine translation (with non-monotonic ⁇ ).
- ⁇ is a permutation matrix, corresponding to a substitution cipher.
- ⁇ is English text represented as a series of graphemes.
- the ciphertext ⁇ might be wi jtvwjpvwjbhjwi jgvw, corresponding to some English plaintext ⁇ . It is known that this simple cipher can be broken by frequency analysis, by tabulating the frequency of grapheme n-grams in the ciphertext and looking for grapheme n-grams with similar frequencies in conventional English text.
- Some example implementations may codify this by considering the singular value decompositions of ⁇ and ⁇ . As long as the singular values of ⁇ are distinct and non-zero then we can completely recover ⁇ and have identifiability given no paired data.
- the plaintext above is the cat sat on the mat. [0065] Secondly consider the case where ⁇ is not restricted to be a permutation matrix but where the ⁇ and ⁇ alphabets both have size two, say ⁇ ⁇ , ⁇ ⁇ ⁇ ⁇ 0,1 ⁇ .
- FIG. 2A depicts a block diagram of an example computing system 100 according to example embodiments of the present disclosure.
- the system 100 includes a user computing device 102, a server computing system 130, and a training computing system 150 that are communicatively coupled over a network 180.
- the user computing device 102 can be any type of computing device, such as, for example, a personal computing device (e.g., laptop or desktop), a mobile computing device (e.g., smartphone or tablet), a gaming console or controller, a wearable computing device, an embedded computing device, or any other type of computing device.
- the user computing device 102 includes one or more processors 112 and a memory 114.
- the one or more processors 112 can be any suitable processing device (e.g., a processor core, a microprocessor, an ASIC, an FPGA, a controller, a microcontroller, etc.) and can be one processor or a plurality of processors that are operatively connected.
- the memory 114 can include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof.
- the memory 114 can store data 116 and instructions 118 which are executed by the processor 112 to cause the user computing device 102 to perform operations.
- the user computing device 102 can store or include one or more machine-learned models 120.
- the machine-learned models 120 can be or can otherwise include various machine-learned models such as neural networks (e.g., deep neural networks) or other types of machine-learned models, including non-linear models and/or linear models.
- Neural networks can include feed-forward neural networks, recurrent neural networks (e.g., long short-term memory recurrent neural networks), convolutional neural networks or other forms of neural networks.
- Some example machine-learned models can leverage an attention mechanism such as self-attention.
- some example machine-learned models can include multi-headed self-attention models (e.g., transformer models).
- Example machine-learned models 120 are discussed with reference to Figures 1A-E.
- the one or more machine-learned models 120 can be received from the server computing system 130 over network 180, stored in the user computing device memory 114, and then used or otherwise implemented by the one or more processors 112.
- the user computing device 102 can implement multiple parallel instances of a single machine-learned model 120 (e.g., to perform parallel conversion across multiple instances of sequential data).
- one or more machine-learned models 140 can be included in or otherwise stored and implemented by the server computing system 130 that communicates with the user computing device 102 according to a client-server relationship.
- the machine-learned models 140 can be implemented by the server computing system 140 as a portion of a web service.
- the user computing device 102 can also include one or more user input components 122 that receives user input.
- the user input component 122 can be a touch-sensitive component (e.g., a touch-sensitive display screen or a touch pad) that is sensitive to the touch of a user input object (e.g., a finger or a stylus).
- the touch-sensitive component can serve to implement a virtual keyboard.
- Other example user input components include a microphone, a traditional keyboard, or other means by which a user can provide user input.
- the server computing system 130 includes one or more processors 132 and a memory 134.
- the one or more processors 132 can be any suitable processing device (e.g., a processor core, a microprocessor, an ASIC, an FPGA, a controller, a microcontroller, etc.) and can be one processor or a plurality of processors that are operatively connected.
- the memory 134 can include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof.
- the memory 134 can store data 136 and instructions 138 which are executed by the processor 132 to cause the server computing system 130 to perform operations.
- the server computing system 130 includes or is otherwise implemented by one or more server computing devices. In instances in which the server computing system 130 includes plural server computing devices, such server computing devices can operate according to sequential computing architectures, parallel computing architectures, or some combination thereof.
- the server computing system 130 can store or otherwise include one or more machine-learned models 140.
- the models 140 can be or can otherwise include various machine-learned models.
- Example machine-learned models include neural networks or other multi-layer non-linear models.
- Example neural networks include feed forward neural networks, deep neural networks, recurrent neural networks, and convolutional neural networks.
- Some example machine-learned models can leverage an attention mechanism such as self-attention.
- some example machine-learned models can include multi-headed self-attention models (e.g., transformer models).
- Example models 140 are discussed with reference to Figures 1A-E.
- the user computing device 102 and/or the server computing system 130 can train the models 120 and/or 140 via interaction with the training computing system 150 that is communicatively coupled over the network 180.
- the training computing system 150 can be separate from the server computing system 130 or can be a portion of the server computing system 130.
- the training computing system 150 includes one or more processors 152 and a memory 154.
- the one or more processors 152 can be any suitable processing device (e.g., a processor core, a microprocessor, an ASIC, an FPGA, a controller, a microcontroller, etc.) and can be one processor or a plurality of processors that are operatively connected.
- the memory 154 can include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof.
- the memory 154 can store data 156 and instructions 158 which are executed by the processor 152 to cause the training computing system 150 to perform operations.
- the training computing system 150 includes or is otherwise implemented by one or more server computing devices.
- the training computing system 150 can include a model trainer 160 that trains the machine-learned models 120 and/or 140 stored at the user computing device 102 and/or the server computing system 130 using various training or learning techniques, such as, for example, backwards propagation of errors.
- a loss function can be backpropagated through the model(s) to update one or more parameters of the model(s) (e.g., based on a gradient of the loss function).
- Various loss functions can be used such as mean squared error, likelihood loss, cross entropy loss, hinge loss, and/or various other loss functions.
- Gradient descent techniques can be used to iteratively update the parameters over a number of training iterations.
- performing backwards propagation of errors can include performing truncated backpropagation through time.
- the model trainer 160 can perform a number of generalization techniques (e.g., weight decays, dropouts, etc.) to improve the generalization capability of the models being trained.
- the model trainer 160 can train the machine-learned models 120 and/or 140 based on a set of training data 162.
- the training data 162 can include, for example, unpaired training examples from a first sequence domain, unpaired training examples from a second sequence domain, and paired training examples from both the first sequence domain and the second sequence domain. In some implementations, there may be a very small number of paired training examples relative to the number of unpaired training examples.
- the training examples can be provided by the user computing device 102.
- the model 120 provided to the user computing device 102 can be trained by the training computing system 150 on user-specific data received from the user computing device 102. In some instances, this process can be referred to as personalizing the model.
- the model trainer 160 includes computer logic utilized to provide desired functionality.
- the model trainer 160 can be implemented in hardware, firmware, and/or software controlling a general purpose processor.
- the model trainer 160 includes program files stored on a storage device, loaded into a memory and executed by one or more processors.
- the model trainer 160 includes one or more sets of computer-executable instructions that are stored in a tangible computer-readable storage medium such as RAM, hard disk, or optical or magnetic media.
- the network 180 can be any type of communications network, such as a local area network (e.g., intranet), wide area network (e.g., Internet), or some combination thereof and can include any number of wired or wireless links.
- communication over the network 180 can be carried via any type of wired and/or wireless connection, using a wide variety of communication protocols (e.g., TCP/IP, HTTP, SMTP, FTP), encodings or formats (e.g., HTML, XML), and/or protection schemes (e.g., VPN, secure HTTP, SSL).
- the input to the machine-learned model(s) of the present disclosure can be image data.
- the machine-learned model(s) can process the image data to generate an output.
- the machine-learned model(s) can process the image data to generate an image recognition output (e.g., a recognition of the image data, a latent embedding of the image data, an encoded representation of the image data, a hash of the image data, etc.).
- the machine-learned model(s) can process the image data to generate an image segmentation output.
- the machine- learned model(s) can process the image data to generate an image classification output.
- the machine-learned model(s) can process the image data to generate an image data modification output (e.g., an alteration of the image data, etc.).
- the machine-learned model(s) can process the image data to generate an encoded image data output (e.g., an encoded and/or compressed representation of the image data, etc.).
- the machine-learned model(s) can process the image data to generate an upscaled image data output.
- the machine-learned model(s) can process the image data to generate a prediction output.
- the input to the machine-learned model(s) of the present disclosure can be text or natural language data.
- the machine-learned model(s) can process the text or natural language data to generate an output.
- the machine- learned model(s) can process the natural language data to generate a language encoding output.
- the machine-learned model(s) can process the text or natural language data to generate a latent text embedding output.
- the machine- learned model(s) can process the text or natural language data to generate a translation output.
- the machine-learned model(s) can process the text or natural language data to generate a classification output.
- the machine-learned model(s) can process the text or natural language data to generate a textual segmentation output.
- the machine-learned model(s) can process the text or natural language data to generate a semantic intent output.
- the machine-learned model(s) can process the text or natural language data to generate an upscaled text or natural language output (e.g., text or natural language data that is higher quality than the input text or natural language, etc.).
- the machine-learned model(s) can process the text or natural language data to generate a prediction output.
- the input to the machine-learned model(s) of the present disclosure can be speech data.
- the machine-learned model(s) can process the speech data to generate an output.
- the machine-learned model(s) can process the speech data to generate a speech recognition output.
- the machine- learned model(s) can process the speech data to generate a speech translation output.
- the machine-learned model(s) can process the speech data to generate a latent embedding output.
- the machine-learned model(s) can process the speech data to generate an encoded speech output (e.g., an encoded and/or compressed representation of the speech data, etc.).
- the machine-learned model(s) can process the speech data to generate an upscaled speech output (e.g., speech data that is higher quality than the input speech data, etc.).
- the machine-learned model(s) can process the speech data to generate a textual representation output (e.g., a textual representation of the input speech data, etc.).
- the machine- learned model(s) can process the speech data to generate a prediction output.
- the input to the machine-learned model(s) of the present disclosure can be latent encoding data (e.g., a latent space representation of an input, etc.).
- the machine-learned model(s) can process the latent encoding data to generate an output.
- the machine-learned model(s) can process the latent encoding data to generate a recognition output.
- the machine-learned model(s) can process the latent encoding data to generate a reconstruction output.
- the machine-learned model(s) can process the latent encoding data to generate a search output.
- the machine-learned model(s) can process the latent encoding data to generate a reclustering output.
- the machine-learned model(s) can process the latent encoding data to generate a prediction output.
- the input to the machine-learned model(s) of the present disclosure can be statistical data.
- Statistical data can be, represent, or otherwise include data computed and/or calculated from some other data source.
- the machine-learned model(s) can process the statistical data to generate an output.
- the machine- learned model(s) can process the statistical data to generate a recognition output.
- the machine-learned model(s) can process the statistical data to generate a prediction output.
- the machine-learned model(s) can process the statistical data to generate a classification output.
- the machine-learned model(s) can process the statistical data to generate a segmentation output.
- the machine-learned model(s) can process the statistical data to generate a visualization output.
- the machine-learned model(s) can process the statistical data to generate a diagnostic output.
- the input to the machine-learned model(s) of the present disclosure can be sensor data.
- the machine-learned model(s) can process the sensor data to generate an output.
- the machine-learned model(s) can process the sensor data to generate a recognition output.
- the machine-learned model(s) can process the sensor data to generate a prediction output.
- the machine-learned model(s) can process the sensor data to generate a classification output.
- the machine-learned model(s) can process the sensor data to generate a segmentation output.
- the machine-learned model(s) can process the sensor data to generate a visualization output.
- the machine-learned model(s) can process the sensor data to generate a diagnostic output.
- the machine-learned model(s) can process the sensor data to generate a detection output.
- the machine-learned model(s) can be configured to perform a task that includes encoding input data for reliable and/or efficient transmission or storage (and/or corresponding decoding).
- the task may be an audio compression task.
- the input may include audio data and the output may comprise compressed audio data.
- the input includes visual data (e.g. one or more images or videos), the output comprises compressed visual data, and the task is a visual data compression task.
- the task may comprise generating an embedding for input data (e.g. input audio or visual data).
- the input includes visual data and the task is a computer vision task.
- the input includes pixel data for one or more images and the task is an image processing task.
- the image processing task can be image classification, where the output is a set of scores, each score corresponding to a different object class and representing the likelihood that the one or more images depict an object belonging to the object class.
- the image processing task may be object detection, where the image processing output identifies one or more regions in the one or more images and, for each region, a likelihood that region depicts an object of interest.
- the image processing task can be image segmentation, where the image processing output defines, for each pixel in the one or more images, a respective likelihood for each category in a predetermined set of categories.
- the set of categories can be foreground and background.
- the set of categories can be object classes.
- the image processing task can be depth estimation, where the image processing output defines, for each pixel in the one or more images, a respective depth value.
- the image processing task can be motion estimation, where the network input includes multiple images, and the image processing output defines, for each pixel of one of the input images, a motion of the scene depicted at the pixel between the images in the network input.
- the input includes audio data representing a spoken utterance and the task is a speech recognition task.
- the output may comprise a text output which is mapped to the spoken utterance.
- the task comprises encrypting or decrypting input data.
- the task comprises a microprocessor performance task, such as branch prediction or memory address translation.
- Figure 2A illustrates one example computing system that can be used to implement the present disclosure. Other computing systems can be used as well.
- the user computing device 102 can include the model trainer 160 and the training dataset 162.
- the models 120 can be both trained and used locally at the user computing device 102.
- FIG. 2B depicts a block diagram of an example computing device 10 that performs according to example embodiments of the present disclosure.
- the computing device 10 can be a user computing device or a server computing device.
- the computing device 10 includes a number of applications (e.g., applications 1 through N). Each application contains its own machine learning library and machine-learned model(s). For example, each application can include a machine-learned model.
- Example applications include a text messaging application, an email application, a dictation application, a virtual keyboard application, a browser application, etc.
- each application can communicate with a number of other components of the computing device, such as, for example, one or more sensors, a context manager, a device state component, and/or additional components.
- each application can communicate with each device component using an API (e.g., a public API).
- the API used by each application is specific to that application.
- Figure 2C depicts a block diagram of an example computing device 50 that performs according to example embodiments of the present disclosure.
- the computing device 50 can be a user computing device or a server computing device.
- the computing device 50 includes a number of applications (e.g., applications 1 through N). Each application is in communication with a central intelligence layer.
- Example applications include a text messaging application, an email application, a dictation application, a virtual keyboard application, a browser application, etc.
- each application can communicate with the central intelligence layer (and model(s) stored therein) using an API (e.g., a common API across all applications).
- the central intelligence layer includes a number of machine-learned models. For example, as illustrated in Figure 2C, a respective machine-learned model can be provided for each application and managed by the central intelligence layer. In other implementations, two or more applications can share a single machine-learned model. For example, in some implementations, the central intelligence layer can provide a single model for all of the applications.
- the central intelligence layer is included within or otherwise implemented by an operating system of the computing device 50.
- the central intelligence layer can communicate with a central device data layer.
- the central device data layer can be a centralized repository of data for the computing device 50.
- the central device data layer can communicate with a number of other components of the computing device, such as, for example, one or more sensors, a context manager, a device state component, and/or additional components.
- the central device data layer can communicate with each device component using an API (e.g., a private API).
- API e.g., a private API
Abstract
Provided is a noisy channel generative model of two sequences, for example text and speech, which enables uncovering the associations between the two modalities when limited paired data is available. To address the intractability of the exact model under a realistic data set-up, example aspects of the present disclosure include a variational inference approximation. To train this variational model with categorical data, a KL encoder loss approach is proposed which has connections to the wake-sleep algorithm.
Description
LEARNING THE JOINT DISTRIBUTION OF TWO SEQUENCES USING LITTLE OR NO PAIRED DATA RELATED APPLICATIONS [0001] This application claims priority to and the benefit of United States Provisional Patent Application Number 63/410,445, filed September 27, 2022. United States Provisional Patent Application Number 63/410,445 is hereby incorporated by reference in its entirety. FIELD [0002] The present disclosure relates generally to machine learning. More particularly, the present disclosure relates to a noisy channel generative model of two sequences, for example text and speech, which enables uncovering the associations between the two modalities when limited paired data is available. BACKGROUND [0003] Learning the joint or conditional distribution of two sequences appears in many machine learning applications, e.g., automatic speech recognition (ASR), text to speech (TTS), machine translation (MT), optical character recognition (OCR), text summarization and others. Being able to learn these distributions with limited or no paired data when large amounts of unpaired data is available is desirable. Thus, the task of learning the joint or conditional distribution of two sequences is generally applicable to many seq2seq problems. [0004] One specific setting in which this task is relevant is for text and speech for ASR and TTS models. A classical approach to speech recognition is to treat the process of generating speech audio as a noisy channel, where text is drawn from some distribution and then statistically transformed into speech audio, and the task of speech recognition is to invert this generative model to infer the text most likely to have given rise to a given speech waveform. This generative model of speech audio was historically successful but has been superseded in all modern discriminative systems by directly modeling the conditional distribution of text given speech. [0005] The direct approach has the advantage of allowing limited modeling power to be solely devoted to the task of interest, whereas the generative approach can be extremely sensitive to faulty assumptions in the speech audio model despite the fact that this is not the primary object of interest. However the generative approach allows learning in a principled way from untranscribed speech audio, something fundamentally impossible in the direct
approach. Thus, improved techniques for a generative approach to learning the joint or conditional distribution of two sequences are desired in the art. SUMMARY [0006] Aspects and advantages of embodiments of the present disclosure will be set forth in part in the following description, or can be learned from the description, or can be learned through practice of the embodiments. [0007] One example aspect of the present disclosure is directed to a computer- implemented method to learn a noisy channel generative model for a first sequence domain and a second sequence domain. The method includes, for one or more generative training iterations: obtaining, by the computing system from the training dataset, an unpaired training example from the second sequence domain; processing, by the computing system, the unpaired training example from the second sequence domain with an encoder model to generate a sample from the first sequence domain; determining, by the computing system, a first likelihood that the unpaired training example from the second sequence domain is output from a decoder model when conditioned on the sample from the first sequence domain generated by the encoder model; and updating, by the computing system, one or more parameter values of the decoder model based at least in part on the first likelihood. The method includes, for one or more variational training iterations: generating, by the computing system, a sample from the second sequence domain using the decoder model when conditioned on data from the first sequence domain; determining, by the computing system, a second likelihood that the data from the first sequence domain is output by the encoder model when conditioned on the sample from the second sequence domain; and updating, by the computing system, one or more parameter values of the encoder model based at least in part on the second likelihood. [0008] Another example aspect of the present disclosure is directed to a computer system that includes one or more processors and one or more non-transitory computer- readable media that collectively store: a noisy channel generative model of two sequences, wherein the noisy channel generative model has been learned using a variational posterior model; and instructions that, when executed by the one or more processors, cause the computer system to implement the noisy channel generative model to convert data from a second sequence domain to a first sequence domain. [0009] Another example aspect of the present disclosure is directed to a computer system that includes one or more processors and one or more non-transitory computer-
readable media that collectively store: a noisy channel generative model of two sequences, wherein the noisy channel generative model has been learned using a KL encoder loss function; and instructions that, when executed by the one or more processors, cause the computer system to implement the noisy channel generative model to convert data from a second sequence domain to a first sequence domain. [0010] Other aspects of the present disclosure are directed to various systems, apparatuses, non-transitory computer-readable media, user interfaces, and electronic devices. [0011] These and other features, aspects, and advantages of various embodiments of the present disclosure will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate example embodiments of the present disclosure and, together with the description, serve to explain the related principles. BRIEF DESCRIPTION OF THE DRAWINGS [0012] Detailed discussion of embodiments directed to one of ordinary skill in the art is set forth in the specification, which makes reference to the appended figures, in which: [0013] Figure 1A depicts an example generative training approach applied when an unpaired training example from a first sequence domain is retrieved from a training dataset according to example embodiments of the present disclosure. [0014] Figure 1B depicts an example generative training approach applied when an paired training example from both the first sequence domain and a second sequence domain is retrieved from the training dataset according to example embodiments of the present disclosure. [0015] Figure 1C depicts an example generative training approach applied when an unpaired training example from the second sequence domain is retrieved from the training dataset according to example embodiments of the present disclosure. [0016] Figure 1D depicts an example variational training approach for training an encoder model according to example embodiments of the present disclosure. [0017] Figure 1E depicts an example inference approach according to example embodiments of the present disclosure. [0018] Figure 2A depicts a block diagram of an example computing system according to example embodiments of the present disclosure. [0019] Figure 2B depicts a block diagram of an example computing device according to example embodiments of the present disclosure.
[0020] Figure 2C depicts a block diagram of an example computing device according to example embodiments of the present disclosure. [0021] Reference numerals that are repeated across plural figures are intended to identify the same features in various implementations. DETAILED DESCRIPTION Overview [0022] Generally, the present disclosure is directed to a noisy channel generative model of two sequences, for example text and speech, which enables uncovering the associations between the two modalities when limited paired data is available. To address the intractability of the exact model under a realistic data set-up, example aspects of the present disclosure include a variational inference approximation. To train this variational model with categorical data, a KL encoder loss approach is proposed which has connections to the wake-sleep algorithm. Experimental results show that even tiny amount of paired data is sufficient to learn to relate the two modalities (e.g., graphemes and phonemes) when large amounts of unpaired data is available, paving the path to adopting this principled approach for ASR and TTS models in low resource data regimes. [0023] More particularly, the present disclosure provides a noisy channel joint model of text and speech for learning from a corpus consisting of relatively large amounts of text-only data and speech-only data, but little or no parallel (text, speech) data. Example implementations cope with the sensitivity of generative modeling to faulty modeling assumptions by trying to make the generative model as accurate as possible, and cope with the resulting intractable inference problem using a variational approximate posterior of text given speech. An analogous formulation in the other direction can be adopted for text to speech models. [0024] Similar to discrete latent variable models, when the proposed variational approach infers a discrete quantity (e.g., text or phoneme), the typical stochastic gradient variational Bayes approach is not applicable and requires a different optimization procedure. In response, the present disclosure proposed a method that can be referred to as KL encoder loss. [0025] The large body of work on leveraging speech-only and text-only data resources to build and also to refine automatic speech recognition (ASR) and text to speech (TTS) systems rely on the close connection between the two modalities. However, the feasibility and necessary conditions to doing so is not well understood theoretically. The present disclosure
formalizes the problem as identifying the joint text and speech distribution by only observing its marginal samples and provides solutions to this problem. [0026] Thus, one aspect of the present disclosure is directed to a noisy channel joint model of text and speech distribution. Specifically, the noisy channel joint model can be developed through the use of a variational noisy channel model or encoder. Another aspect of the present disclosure is directed to a KL encoder loss to train the discrete latent variable models. [0027] The systems and methods of the present disclosure provide a number of technical effects. As one example, the proposed approaches enable improved learning of joint distributions even in settings with little to no paired training data. This enables application of the proposed techniques to many domains that previously were not explored using joint probabilities due to the lack of paired training data for such domains. In addition, because generation (e.g., labeling) of paired training data consumes resources such as computational resources, the proposed approaches reduce the computational cost of learning of joint distributions. As another example technical effect and benefit, the proposed approaches enable the more principled generative approach to be extended to additional domains (e.g., as opposed to discriminative approaches). [0028] With reference now to the Figures, example embodiments of the present disclosure will be discussed in further detail. Example Training and Inference Approaches [0029] Figures 1A-D show example approaches to learn a noisy channel generative model for a first sequence domain and a second sequence domain according to example aspects of the present disclosure. For ease of explication and to provide one example, in Figures 1A-D the first sequence domain comprises textual sequences and the second sequence domain comprises sequences of speech data. For example, the speech data can be expressed as a raw waveform or using Mel spectrograms. However, this is provided as one example application only. In another example the second sequence domain comprises textual sequences and the first sequence domain comprises sequences of speech data. In another example, the first sequence domain comprises textual sequences and the second sequence domain comprises sequences of image data corresponding to rendered characters. In another example, the first sequence domain comprises sequences expressed in a first language (e.g., English) and the second sequence domain comprises sequences expressed in a second
language (e.g., French). Other sequential domains are possible as well such as genetic sequences, protein sequences, sequences of sensor data, and/or other forms of sequential data. [0030] Figure 1A depicts an example generative training approach applied when an unpaired training example from a first sequence domain is retrieved from a training dataset according to example embodiments of the present disclosure. As illustrated in Figure 1A, a computing system obtains, from a training dataset, an unpaired training example 12 from the first sequence domain. The computing system determines a likelihood 16 that the unpaired training example 12 from the first sequence domain is output from a prior model 14. The computing system updates one or more parameter values of the prior model 14 based at least in part on the likelihood 16. [0031] Figure 1B depicts an example generative training approach applied when an paired training example from both the first sequence domain and a second sequence domain is retrieved from the training dataset according to example embodiments of the present disclosure. As illustrated in Figure 1B, a computing system obtains, from the training dataset, a paired training example 20 comprising paired training data from the first sequence domain 22 and paired training data from the second sequence domain. The computing system determines a likelihood 30 that the paired training data from the first sequence domain is output from the prior model 14 and updates one or more parameter values of the prior model 14 based at least in part on the likelihood 30. The computing system also determines an additional likelihood 26 that the paired training data from the second sequence domain is output from a decoder model 24 when conditioned on the paired training data from the first sequence domain 22. The computing system updates one or more parameter values of the decoder model 24 based at least in part on the additional likelihood 26. [0032] Figure 1C depicts an example generative training approach applied when an unpaired training example from the second sequence domain is retrieved from the training dataset according to example embodiments of the present disclosure. As illustrated in Figure 1C, a computing system obtains, from the training dataset, an unpaired training example from the second sequence domain 32. The computing system processes the unpaired training example from the second sequence domain 32 with an encoder model 34 to generate a sample from the first sequence domain 36. The computing system determines a likelihood 40 that the unpaired training example from the second sequence domain 32 is output from a decoder model 24 when conditioned on the sample from the first sequence domain 36 generated by the encoder model 34. The computing system updates one or more parameter values of the decoder model 24 based at least in part on the likelihood 40.
[0033] In some implementations, the computing system can additionally determine a likelihood 38 that the sample from the first sequence domain 36 is output by the prior model 14 and can update one or more parameters of the prior model 14 based on the likelihood 38. [0034] Figure 1D depicts an example variational training approach for training an encoder model according to example embodiments of the present disclosure. As illustrated in Figure 1D, a computing system generates a sample from the second sequence domain 62 using the decoder model 24 when conditioned on data from the first sequence domain 60. The computing system determines a likelihood 64 that the data from the first sequence domain 60 is output by the encoder model 34 when conditioned on the sample from the second sequence domain 62. The computing system updates one or more parameter values of the encoder model 34 based at least in part on the likelihood 64. [0035] As one example, as illustrated in Figure 1D, the data from the first sequence domain 60 can be or include a sample from the first sequence domain generated by the prior model 14. [0036] Figure 1E depicts an example inference approach according to example embodiments of the present disclosure. As illustrated in Figure 1E, a computing system can invert the decoder model 24 to generate data from the first sequential domain (e.g., text 72) when provided with data from the second sequential domain (e.g., speech data 70).
Example Models [0037] This section describes an example proposed joint model of two sequences and how to train it. The two sequences ^ ൌ ^^^^^ ௌ ୀି ^^ and ^ ൌ ^^௧^் ௧ୀ ି ^^ may be different lengths (^ ് ^) and may each have discrete or continuous values. For the first sequence ^ might be text consisting of a sequence of graphemes and the
Claims
WHAT IS CLAIMED IS: 1. A computer-implemented method to learn a noisy channel generative model for a first sequence domain and a second sequence domain, the method comprising: for one or more generative training iterations: obtaining, by the computing system from the training dataset, an unpaired training example from the second sequence domain; processing, by the computing system, the unpaired training example from the second sequence domain with an encoder model to generate a sample from the first sequence domain; determining, by the computing system, a first likelihood that the unpaired training example from the second sequence domain is output from a decoder model when conditioned on the sample from the first sequence domain generated by the encoder model; and updating, by the computing system, one or more parameter values of the decoder model based at least in part on the first likelihood; and for one or more variational training iterations: generating, by the computing system, a sample from the second sequence domain using the decoder model when conditioned on data from the first sequence domain; determining, by the computing system, a second likelihood that the data from the first sequence domain is output by the encoder model when conditioned on the sample from the second sequence domain; and updating, by the computing system, one or more parameter values of the encoder model based at least in part on the second likelihood.
2. The computer-implemented method of claim 1, wherein the first sequence domain comprises textual sequences and the second sequence domain comprises sequences of speech data.
3. The computer-implemented method of claim 1, wherein the second sequence domain comprises textual sequences and the first sequence domain comprises sequences of speech data.
4. The computer-implemented method of claim 1, wherein the first sequence domain comprises textual sequences and the second sequence domain comprises sequences of image data corresponding to rendered characters.
5. The computer-implemented method of claim 1, wherein the first sequence domain comprises sequences expressed in a first language and the second sequence domain comprises sequences expressed in a second language.
6. The computer-implemented method of any preceding claim, wherein the data from the first sequence domain comprises a sample from the first sequence domain generated by a prior model.
7. The computer-implemented method of claim 6, further comprising, for one or more of the generative training iterations: obtaining, by the computing system from the training dataset, an unpaired training example from the first sequence domain; determining, by the computing system, a third likelihood that the unpaired training example from the first sequence domain is output from the prior model; and updating, by the computing system, one or more parameter values of the prior model based at least in part on the third likelihood.
8. The computer-implemented method of any preceding claim, further comprising, for one or more of the generative training iterations: obtaining, by the computing system from the training dataset, a paired training example comprising paired training data from the first sequence domain and paired training data from the second sequence domain; determining, by the computing system, a fourth likelihood that the paired training data from the first sequence domain is output from the prior model; updating, by the computing system, one or more parameter values of the prior model based at least in part on the fourth likelihood;
determining, by the computing system, a fifth likelihood that the paired training data from the second sequence domain is output from the decoder model when conditioned on the paired training data from the first sequence domain; and updating, by the computing system, one or more parameter values of the decoder model based at least in part on the fifth likelihood.
9. The computer-implemented method of any preceding claim, wherein the decoder model is expressed as a product of time-local factors.
10. The computer-implemented method of any preceding claim, further comprising: inverting, by the computing system, the decoder model to generate data from the first sequential domain when provided with data from the second sequential domain.
11. The computer-implemented method of any preceding claim, wherein one or both of the encoder model and decoder model comprise autoregressive recurrent neural networks.
12. A computer system, comprising: one or more processors; and one or more non-transitory computer-readable media that collectively store: a noisy channel generative model of two sequences, wherein the noisy channel generative model has been learned using a variational posterior model; and instructions that, when executed by the one or more processors, cause the computer system to implement the noisy channel generative model to convert data from a second sequence domain to a first sequence domain.
13. The computer system of claim 12, wherein the variational posterior model has been trained with a KL encoder loss function.
14. The computer system of claim 13, wherein the KL encoder loss comprises a KL divergence to a generative distribution of the noisy channel generative model.
15. A computer system, comprising: one or more processors; and one or more non-transitory computer-readable media that collectively store: a noisy channel generative model of two sequences, wherein the noisy channel generative model has been learned using a KL encoder loss function; and instructions that, when executed by the one or more processors, cause the computer system to implement the noisy channel generative model to convert data from a second sequence domain to a first sequence domain.
16. The computer system of claim 15, wherein the KL encoder loss comprises a KL divergence to a generative distribution of the noisy channel generative model.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202263410445P | 2022-09-27 | 2022-09-27 | |
US63/410,445 | 2022-09-27 |
Publications (1)
Publication Number | Publication Date |
---|---|
WO2024072877A1 true WO2024072877A1 (en) | 2024-04-04 |
Family
ID=88506945
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
PCT/US2023/033841 WO2024072877A1 (en) | 2022-09-27 | 2023-09-27 | Learning the joint distribution of two sequences using little or no paired data |
Country Status (1)
Country | Link |
---|---|
WO (1) | WO2024072877A1 (en) |
-
2023
- 2023-09-27 WO PCT/US2023/033841 patent/WO2024072877A1/en unknown
Non-Patent Citations (3)
Title |
---|
LIU LU ET AL: "Multimodal face aging framework via learning disentangled representation", JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION, ACADEMIC PRESS, INC, US, vol. 83, 1 February 2022 (2022-02-01), XP086971691, ISSN: 1047-3203, [retrieved on 20220211], DOI: 10.1016/J.JVCIR.2022.103452 * |
SOROOSH MARIOORYAD ET AL: "Learning the joint distribution of two sequences using little or no paired data", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 6 December 2022 (2022-12-06), XP091388026 * |
WENXUE CHEN ET AL: "Multimodal Adversarially Learned Inference with Factorized Discriminators", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 20 December 2021 (2021-12-20), XP091119306 * |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11487954B2 (en) | Multi-turn dialogue response generation via mutual information maximization | |
CN114514540A (en) | Contrast pre-training of language tasks | |
CN116468070A (en) | Training neural networks using normalized target outputs | |
CN110929114A (en) | Tracking digital dialog states and generating responses using dynamic memory networks | |
US20220383206A1 (en) | Task Augmentation and Self-Training for Improved Few-Shot Learning | |
US11533495B2 (en) | Hierarchical video encoders | |
US20230237993A1 (en) | Systems and Methods for Training Dual-Mode Machine-Learned Speech Recognition Models | |
US20230267315A1 (en) | Diffusion Models Having Improved Accuracy and Reduced Consumption of Computational Resources | |
US20230401382A1 (en) | Dynamic Language Models for Continuously Evolving Content | |
CN113673235A (en) | Energy-based language model | |
US20240104352A1 (en) | Contrastive Learning and Masked Modeling for End-To-End Self-Supervised Pre-Training | |
WO2024072877A1 (en) | Learning the joint distribution of two sequences using little or no paired data | |
US20220245917A1 (en) | Systems and methods for nearest-neighbor prediction based machine learned models | |
US11922550B1 (en) | Systems and methods for hierarchical text-conditional image generation | |
US20240087196A1 (en) | Compositional image generation and manipulation | |
US20220245428A1 (en) | Machine-Learned Attention Models Featuring Omnidirectional Processing | |
US20240070456A1 (en) | Corrective Reward Optimization for Sequential Labeling | |
US11755883B2 (en) | Systems and methods for machine-learned models having convolution and attention | |
US20220245432A1 (en) | Machine-Learned Attention Models Featuring Echo-Attention Layers | |
US20230112862A1 (en) | Leveraging Redundancy in Attention with Reuse Transformers | |
US20240135187A1 (en) | Method for Training Large Language Models to Perform Query Intent Classification | |
WO2024020107A1 (en) | Task-specific prompt recycling for machine-learned models that perform multiple tasks | |
WO2023192632A1 (en) | Zero-shot multi-modal data processing via structured inter-model communication | |
WO2023172692A1 (en) | Maximizing generalizable performance by extraction of deep learned features while controlling for known variables | |
WO2023114141A1 (en) | Knowledge distillation via learning to predict principal components coefficients |