JP7394265B2 - Synchronous replication of high-throughput streaming data - Google Patents
Synchronous replication of high-throughput streaming data Download PDFInfo
- Publication number
- JP7394265B2 JP7394265B2 JP2023528455A JP2023528455A JP7394265B2 JP 7394265 B2 JP7394265 B2 JP 7394265B2 JP 2023528455 A JP2023528455 A JP 2023528455A JP 2023528455 A JP2023528455 A JP 2023528455A JP 7394265 B2 JP7394265 B2 JP 7394265B2
- Authority
- JP
- Japan
- Prior art keywords
- log
- storage location
- data blocks
- data
- replicated
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000010076 replication Effects 0.000 title claims description 132
- 230000001360 synchronised effect Effects 0.000 title description 7
- 230000015654 memory Effects 0.000 claims description 117
- 238000012545 processing Methods 0.000 claims description 48
- 238000000034 method Methods 0.000 claims description 47
- 238000004891 communication Methods 0.000 claims description 8
- 230000004044 response Effects 0.000 claims description 7
- 230000003362 replicative effect Effects 0.000 description 13
- 230000008569 process Effects 0.000 description 12
- 238000010586 diagram Methods 0.000 description 11
- 238000004590 computer program Methods 0.000 description 8
- 238000012546 transfer Methods 0.000 description 5
- 230000003287 optical effect Effects 0.000 description 4
- 230000002776 aggregation Effects 0.000 description 2
- 238000004220 aggregation Methods 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 238000011084 recovery Methods 0.000 description 2
- 230000003044 adaptive effect Effects 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000012790 confirmation Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000012795 verification Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
- 230000001755 vocal effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/14—Error detection or correction of the data by redundancy in operation
- G06F11/1402—Saving, restoring, recovering or retrying
- G06F11/1446—Point-in-time backing up or restoration of persistent data
- G06F11/1458—Management of the backup or restore process
- G06F11/1466—Management of the backup or restore process to make the backup process non-disruptive
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0602—Interfaces specially adapted for storage systems specifically adapted to achieve a particular effect
- G06F3/0614—Improving the reliability of storage systems
- G06F3/0619—Improving the reliability of storage systems in relation to data integrity, e.g. data losses, bit errors
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/16—Error detection or correction of the data by redundancy in hardware
- G06F11/20—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements
- G06F11/2053—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant
- G06F11/2056—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring
- G06F11/2071—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring using a plurality of controllers
- G06F11/2076—Synchronous techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/14—Error detection or correction of the data by redundancy in operation
- G06F11/1402—Saving, restoring, recovering or retrying
- G06F11/1446—Point-in-time backing up or restoration of persistent data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/14—Error detection or correction of the data by redundancy in operation
- G06F11/1402—Saving, restoring, recovering or retrying
- G06F11/1471—Saving, restoring, recovering or retrying involving logging of persistent data for recovery
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/16—Error detection or correction of the data by redundancy in hardware
- G06F11/20—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements
- G06F11/2053—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant
- G06F11/2056—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/16—Error detection or correction of the data by redundancy in hardware
- G06F11/20—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements
- G06F11/2053—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant
- G06F11/2056—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring
- G06F11/2058—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring using more than 2 mirrored copies
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/16—Error detection or correction of the data by redundancy in hardware
- G06F11/20—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements
- G06F11/2053—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant
- G06F11/2056—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring
- G06F11/2064—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring while ensuring consistency
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/16—Error detection or correction of the data by redundancy in hardware
- G06F11/20—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements
- G06F11/2053—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant
- G06F11/2056—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring
- G06F11/2071—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring using a plurality of controllers
- G06F11/2074—Asynchronous techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/16—Error detection or correction of the data by redundancy in hardware
- G06F11/20—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements
- G06F11/2053—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant
- G06F11/2056—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where persistent mass storage functionality or persistent mass storage control functionality is redundant by mirroring
- G06F11/2082—Data synchronisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/30—Monitoring
- G06F11/3003—Monitoring arrangements specially adapted to the computing system or computing system component being monitored
- G06F11/3034—Monitoring arrangements specially adapted to the computing system or computing system component being monitored where the computing system component is a storage system, e.g. DASD based or network based
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0629—Configuration or reconfiguration of storage systems
- G06F3/0635—Configuration or reconfiguration of storage systems by changing the path, e.g. traffic rerouting, path reconfiguration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0638—Organizing or formatting or addressing of data
- G06F3/064—Management of blocks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0646—Horizontal data movement in storage systems, i.e. moving data in between storage devices or systems
- G06F3/065—Replication mechanisms
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0653—Monitoring storage devices or systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0655—Vertical data movement, i.e. input-output transfer; data movement between one or more hosts and one or more storage devices
- G06F3/0659—Command handling arrangements, e.g. command buffers, queues, command scheduling
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0668—Interfaces specially adapted for storage systems adopting a particular infrastructure
- G06F3/067—Distributed or networked storage systems, e.g. storage area networks [SAN], network attached storage [NAS]
Description
技術分野
本開示は、ハイスループットストリーミングデータの同期複製に関する。
TECHNICAL FIELD This disclosure relates to synchronous replication of high-throughput streaming data.
背景
大量のデータをクラウドに記憶することが一般的になるにつれて、クラウドコンピューティングの人気が高まっている。クラウドに記憶された大量のデータを保護するために、データのロバストな記憶の必要性も高まっている。一部のクラウドサービスプロバイダは、異なる地理的ゾーンに跨る複数の記憶場所にデータを非同期的に記憶することによって、クラウドデータ記憶のロバスト性を増加する。例えば、第１のゾーン内の第１または一次記憶場所にデータを書き込んだ後、データは、第２のゾーン内の第２の記憶場所に書き込まれる。データを異なる記憶場所に記憶することによって、ユーザは、記憶場所のうちの１つがアクセス不能になった場合に、データを回復することができる。一部のデータ、例えばミッションクリティカルなアプリケーションのデータの場合、データの損失は、許容できない。
Background Cloud computing is growing in popularity as it becomes common to store large amounts of data in the cloud. The need for robust storage of data is also increasing to protect the large amount of data stored in the cloud. Some cloud service providers increase the robustness of cloud data storage by storing data asynchronously in multiple storage locations across different geographic zones. For example, after writing data to a first or primary storage location in a first zone, the data is written to a second storage location in a second zone. By storing data in different storage locations, a user can recover the data if one of the storage locations becomes inaccessible. For some data, such as mission-critical application data, data loss is unacceptable.
概要
本開示の一態様は、ハイスループットストリーミングデータを同期複製するための方法を提供する。この方法は、データ処理ハードウェアが、分散記憶システムの第１の記憶場所および分散記憶システムの第２の記憶場所に記憶するための一組のデータブロックを受信することを含む。第１の記憶場所は、第１の地理的領域に関連付けられ、第２の記憶場所は、第１の地理的領域とは異なる第２の地理的領域に関連付けられる。また、この方法は、データ処理ハードウェアが、一組のデータブロックを第１の記憶場所および第２の記憶場所に同期的に書き込むことを含む。この方法は、データ処理ハードウェアが、一組のデータブロックを第１の記憶場所および第２の記憶場所に同期的に書き込んでいる間に、第２の記憶場所への一組のデータブロックのさらなる書き込みを妨害する第２の記憶場所の回復不能失敗を判断することを含む。また、この方法は、データ処理ハードウェアが、一組のデータブロックを書き込むときの失敗点を判断することを含む。失敗点は、第２の記憶場所に正常に書き込まれたデータブロックと、第２の記憶場所に正常に書き込まれなかったデータブロックとの境界を示す。また、この方法は、データ処理ハードウェアが、失敗点から開始して、分散記憶システムの第１の記憶場所および第３の記憶場所に一組のデータブロックを同期的に書き込むことを含む。第３の記憶システムは、第１の地理的領域および第２の地理的領域とは異なる第３の地理的領域に関連付けられる。
Overview One aspect of the present disclosure provides a method for synchronously replicating high-throughput streaming data. The method includes data processing hardware receiving a set of data blocks for storage in a first storage location of the distributed storage system and a second storage location of the distributed storage system. The first storage location is associated with a first geographic area and the second storage location is associated with a second geographic area that is different from the first geographic area. The method also includes the data processing hardware synchronously writing a set of data blocks to the first storage location and the second storage location. The method includes data processing hardware writing a set of data blocks to a second memory location while synchronously writing a set of data blocks to a first memory location and a second memory location. including determining an irrecoverable failure of the second storage location that prevents further writes. The method also includes determining a point of failure when the data processing hardware writes the set of data blocks. The failure point marks the boundary between a data block that was successfully written to the second storage location and a data block that was not successfully written to the second storage location. The method also includes the data processing hardware synchronously writing a set of data blocks to the first storage location and the third storage location of the distributed storage system starting from the point of failure. The third storage system is associated with a third geographic area that is different from the first geographic area and the second geographic area.
本開示の実装形態は、以下の任意選択の特徴のうちの１つ以上を含むことができる。いくつかの実装形態において、この方法は、データ処理ハードウェアが、一組のデータブロックの始点から失敗点までの一組のデータブロックを第３の記憶場所に非同期的に書き込むことをさらに含む。いくつかの例において、第２の記憶場所への一組のデータブロックのさらなる書き込みを妨害する第２の記憶場所の回復不能失敗を判断することは、一組のデータブロックを第２の記憶場所に書き込む失敗を判断することと、一組のデータブロックを第２の記憶場所に書き込む失敗の判断に応答して、一組のデータブロックを第２の記憶場所に書き込むことを再試行することと、一組のデータブロックを第２の記憶場所に書き込むことを再試行することが失敗した場合、この失敗が回復不能失敗であると判断することとを含む。 Implementations of this disclosure may include one or more of the following optional features. In some implementations, the method further includes the data processing hardware asynchronously writing the set of data blocks from a start point of the set of data blocks to a point of failure to a third storage location. In some examples, determining an irrecoverable failure of the second memory location that prevents further writing of the set of data blocks to the second memory location may include writing the set of data blocks to the second memory location. determining a failure to write the set of data blocks to the second memory location; and, in response to determining a failure to write the set of data blocks to the second memory location, retrying to write the set of data blocks to the second memory location. , determining that if retrying to write the set of data blocks to the second storage location fails, the failure is an irrecoverable failure.
必要に応じて、一組のデータブロックを書き込むときの失敗点を判断することは、第１の記憶場所に正常にコミットされたデータブロックを示す第１の複製ログが利用可能であるか否かを判断することと、第２の記憶場所に正常にコミットされたデータブロックを示す第２の複製ログが利用可能であるか否かを判断することと、第１の複製ログおよび第２の複製ログが利用可能である場合、第１の複製ログの長さおよび第２の複製ログの長さに基づいて、第１の複製ログと第２の複製ログとを照合することとを含む。いくつかの例において、第１の複製ログと第２の複製ログとを照合することは、回復不能失敗に関連する第２の複製ログのインデックスを決定することと、第２の複製ログのインデックスを、データ処理ハードウェアと通信するメモリハードウェアに記憶することと、第２の記憶場所へのさらなる書き込みを禁止するように第２の複製ログを終了させることと、照合する必要性を示すセンチネルファイルを生成することとを含む。他の例において、この方法は、第１の複製ログが利用可能であり、第２の複製ログが利用できない場合、データ処理ハードウェアが、第１の複製ログの長さに基づいて、第１の複製ログと第２の複製ログとを照合することをさらに含む。この方法は、第１の複製ログが利用できず、第２の複製ログが利用可能である場合、データ処理ハードウェアが、第２の複製ログの長さに基づいて、第１の複製ログと第２の複製ログとを照合することをさらに含むことができる。 Optionally, determining the point of failure when writing a set of data blocks includes determining whether a first replication log is available that indicates data blocks that were successfully committed to the first storage location. determining whether a second replication log is available indicating data blocks successfully committed to the second storage location; If the logs are available, matching the first replicated log and the second replicated log based on the length of the first replicated log and the length of the second replicated log. In some examples, matching the first replicated log and the second replicated log includes determining an index of the second replicated log associated with the unrecoverable failure; and terminating the second replication log to prevent further writes to the second storage location. and generating a file. In other examples, the method includes, if the first replicated log is available and the second replicated log is not available, the data processing hardware determines the first replicated log based on the length of the first replicated log. and a second replication log. This method provides that if a first replicated log is unavailable and a second replicated log is available, the data processing hardware determines whether the first replicated log is the same as the first replicated log based on the length of the second replicated log. The method may further include matching a second replication log.
いくつかの実装形態において、方法は、データ処理ハードウェアが、各データブロックを第１の記憶場所に書き込む時間を示すタイムスタンプを含む第１の複製ログを生成することと、データ処理ハードウェアが、各データブロックを第２の記憶場所に書き込む時間を示すタイムスタンプを含む第２の複製ログを生成することとをさらに含む。これらの実装形態において、この方法は、データ処理ハードウェアが、第１の記憶場所に記憶された複数のデータブロックの返却を要求するクエリ要求を受信することと、データ処理ハードウェアが、第１の複製ログの長さおよび第２の複製ログの長さに基づいて、第１の複製ログと第２の複製ログとを照合することと、データ処理ハードウェアが、第１の複製ログおよび第２の複製ログの照合に基づいて、要求された複数のデータブロックを返すこととを含む。必要に応じて、第１の複製ログと第２の複製ログとを照合することは、第２の複製ログの長さが利用できないことを判断することと、後続の書き込みが閾値期間内に第１の複製ログに追加されると判断することとを含む。 In some implementations, the method includes: the data processing hardware generating a first replication log that includes a timestamp indicating the time to write each data block to the first storage location; , and generating a second replication log including a timestamp indicating a time to write each data block to the second storage location. In these implementations, the method includes: the data processing hardware receiving a query request requesting a return of a plurality of data blocks stored in the first storage location; matching the first replicated log and the second replicated log based on the length of the first replicated log and the length of the second replicated log; and returning the requested plurality of data blocks based on matching the replication logs of No. 2. Optionally, matching the first replicated log with the second replicated log includes determining that the length of the second replicated log is not available and that subsequent writes are completed within a threshold period. This includes determining that the information is added to the replication log of No. 1.
本開示の別の態様は、ハイスループットストリーミングデータを同期複製するためのシステムを提供する。このシステムは、データ処理ハードウェアと、データ処理ハードウェアと通信するメモリハードウェアとを備える。メモリハードウェアは、データ処理ハードウェア上で実行されると、データ処理ハードウェアに以下の動作を実行させる命令を記憶する。動作は、分散記憶システムの第１の記憶場所および分散記憶システムの第２の記憶場所に記憶するための一組のデータブロックを受信することを含む。第１の記憶場所は、第１の地理的領域に関連付けられ、第２の記憶場所は、第１の地理的領域とは異なる第２の地理的領域に関連付けられる。また、動作は、一組のデータブロックを第１の記憶場所および第２の記憶場所に同期的に書き込むことを含む。動作は、一組のデータブロックを第１の記憶場所および第２の記憶場所に同期的に書き込んでいる間に、第２の記憶場所への一組のデータブロックのさらなる書き込みを妨害する第２の記憶場所の回復不能失敗を判断することを含む。また、動作は、一組のデータブロックを書き込むときの失敗点を判断することを含む。失敗点は、第２の記憶場所に正常に書き込まれたデータブロックと、第２の記憶場所に正常に書き込まれなかったデータブロックとの境界を示す。さらに、動作は、失敗点から開始して、一組のデータブロックを分散記憶システムの第１の記憶場所および第３の記憶場所に同期的に書き込むことを含む。第３の記憶システムは、第１の地理的領域および第２の地理的領域とは異なる第３の地理的領域に関連付けられる。 Another aspect of the disclosure provides a system for synchronously replicating high-throughput streaming data. The system includes data processing hardware and memory hardware in communication with the data processing hardware. The memory hardware stores instructions that, when executed on the data processing hardware, cause the data processing hardware to perform the following operations. The operations include receiving a set of data blocks for storage in a first storage location of the distributed storage system and a second storage location of the distributed storage system. The first storage location is associated with a first geographic area and the second storage location is associated with a second geographic area that is different from the first geographic area. The operations also include synchronously writing a set of data blocks to the first memory location and the second memory location. The operations include, while synchronously writing the set of data blocks to the first memory location and the second memory location, a second block of data that prevents further writing of the set of data blocks to the second memory location. including determining irrecoverable failure of the storage location. The operations also include determining a point of failure when writing the set of data blocks. The failure point marks the boundary between a data block that was successfully written to the second storage location and a data block that was not successfully written to the second storage location. Further, the operations include synchronously writing a set of data blocks to a first storage location and a third storage location of the distributed storage system starting from the point of failure. The third storage system is associated with a third geographic area that is different from the first geographic area and the second geographic area.
本開示の実装形態は、以下の任意選択の特徴のうちの１つ以上を含むことができる。いくつかの実装形態において、動作は、一組のデータブロックの始点から失敗点までの一組のデータブロックを第３の記憶場所に非同期的に書き込むことをさらに含む。いくつかの例において、第２の記憶場所への一組のデータブロックのさらなる書き込みを妨害する第２の記憶場所の回復不能失敗を判断することは、一組のデータブロックを第２の記憶場所に書き込む失敗を判断することと、一組のデータブロックを第２の記憶場所に書き込む失敗の判断に応答して、一組のデータブロックを第２の記憶場所に書き込むことを再試行することと、一組のデータブロックを第２の記憶場所に書き込むことを再試行することが失敗した場合、この失敗が回復不能失敗であると判断することとを含む。 Implementations of this disclosure may include one or more of the following optional features. In some implementations, the operations further include asynchronously writing the set of data blocks from a start point of the set of data blocks to a point of failure to a third storage location. In some examples, determining an irrecoverable failure of the second memory location that prevents further writing of the set of data blocks to the second memory location may include writing the set of data blocks to the second memory location. determining a failure to write the set of data blocks to the second memory location; and, in response to determining a failure to write the set of data blocks to the second memory location, retrying to write the set of data blocks to the second memory location. , determining that if retrying to write the set of data blocks to the second storage location fails, the failure is an irrecoverable failure.
必要に応じて、一組のデータブロックを書き込むときの失敗点を判断することは、第１の記憶場所に正常にコミットされたデータブロックを示す第１の複製ログが利用可能であるか否かを判断することと、第２の記憶場所に正常にコミットされたデータブロックを示す第２の複製ログが利用可能であるか否かを判断することと、第１の複製ログおよび第２の複製ログが利用可能である場合、第１の複製ログの長さおよび第２の複製ログの長さに基づいて、第１の複製ログと第２の複製ログとを照合することとを含む。いくつかの例において、第１の複製ログと第２の複製ログとを照合することは、回復不能失敗に関連する第２の複製ログのインデックスを決定することと、第２の複製ログのインデックスを、データ処理ハードウェアと通信するメモリハードウェアに記憶することと、第２の記憶場所へのさらなる書き込みを禁止するように第２の複製ログを終了させることと、照合する必要性を示すセンチネルファイルを生成することとを含む。他の例において、動作は、第１の複製ログが利用可能であり、第２の複製ログが利用できない場合、データ処理ハードウェアが、第１の複製ログの長さに基づいて、第１の複製ログと第２の複製ログとを照合することをさらに含む。動作は、第１の複製ログが利用できず、第２の複製ログが利用可能である場合、データ処理ハードウェアが、第２の複製ログの長さに基づいて、第１の複製ログと第２の複製ログとを照合することをさらに含むことができる。 Optionally, determining the point of failure when writing a set of data blocks includes determining whether a first replication log is available that indicates data blocks that were successfully committed to the first storage location. determining whether a second replication log is available indicating data blocks successfully committed to the second storage location; If the logs are available, matching the first replicated log and the second replicated log based on the length of the first replicated log and the length of the second replicated log. In some examples, matching the first replicated log and the second replicated log includes determining an index of the second replicated log associated with the unrecoverable failure; and terminating the second replication log to prevent further writes to the second storage location. and generating a file. In other examples, the operation is such that if the first replicated log is available and the second replicated log is not available, the data processing hardware determines the first replicated log based on the length of the first replicated log. The method further includes matching the replication log with the second replication log. The operation is such that if the first replicated log is unavailable and the second replicated log is available, the data processing hardware merges the first replicated log and the second replicated log based on the length of the second replicated log. The method may further include comparing the replication logs of the second replication log with the second replication log.
いくつかの実装形態において、動作は、各データブロックを第１の記憶場所に書き込む時間を示すタイムスタンプを含む第１の複製ログを生成することと、データ処理ハードウェアが、各データブロックを第２の記憶場所に書き込む時間を示すタイムスタンプを含む第２の複製ログを生成することとをさらに含む。これらの実装形態において、動作は、第１の記憶場所に記憶された複数のデータブロックの返却を要求するクエリ要求を受信することと、第１の複製ログの長さおよび第２の複製ログの長さに基づいて、第１の複製ログと第２の複製ログとを照合することと、第１の複製ログおよび第２の複製ログの照合に基づいて、要求された複数のデータブロックを返すこととを含む。必要に応じて、第１の複製ログと第２の複製ログとを照合することは、第２の複製ログの長さが利用できないことを判断することと、後続の書き込みが閾値期間内に第１の複製ログに追加されると判断することとを含む。 In some implementations, the operations include generating a first replication log that includes a timestamp indicating the time to write each data block to the first storage location; and data processing hardware writing each data block to the first memory location. and generating a second replication log including a timestamp indicating a time to write to the second storage location. In these implementations, the operations include receiving a query request requesting the return of a plurality of data blocks stored in a first storage location, and determining the length of the first replication log and the length of the second replication log. matching the first replicated log to the second replicated log based on length; and returning the requested plurality of data blocks based on matching the first replicated log and the second replicated log. Including things. Optionally, matching the first replicated log with the second replicated log includes determining that the length of the second replicated log is not available and that subsequent writes are completed within a threshold period. This includes determining that the information is added to the replication log of No. 1.
１つ以上の実装形態の詳細は、添付の図面および以下の詳細な説明に記載されている。他の特徴および利点は、詳細な説明および図面ならびに特許請求の範囲から明白になるであろう。 The details of one or more implementations are set forth in the accompanying drawings and the detailed description below. Other features and advantages will be apparent from the detailed description and drawings, and from the claims.
様々な図面において、同様の参照符号は、同様の要素を示す。
詳細な説明
クラウドデータウェアハウスの規模および人気が増加するにつれて、クラウドデータウェアハウスが取り込むデータの量は、飛躍的に増加している。例えば、いくつかのシステムは、１秒間に少なくとも数百ギガバイトを取り込む（すなわち、受信する）。取り込まれたデータは、通常、異なる地理的領域（すなわち、「ゾーン」）に配置された複数の記憶場所、例えば一次記憶場所および二次記憶場所に記憶され、データのバックアップを提供する。データの二次記憶場所は、一次記憶場所が破損したり、アクセス不能になったりした場合に、データに対する追加の保護を提供するフェールセーフ（failsafe）として機能する。例えば、第１の記憶場所の地理的領域に自然災害が発生した場合、第１の記憶場所ではデータにアクセスできなくなる。この例において、データは、第１の記憶場所とは異なる地理的領域に位置する第２の記憶場所ではアクセス可能である。
Like reference numbers indicate similar elements in the various drawings.
DETAILED DESCRIPTION As cloud data warehouses increase in size and popularity, the amount of data they ingest is increasing exponentially. For example, some systems capture (ie, receive) at least several hundred gigabytes per second. Captured data is typically stored in multiple storage locations, such as a primary storage location and a secondary storage location, located in different geographic areas (i.e., "zones") to provide backup of the data. A secondary storage location for data acts as a failsafe, providing additional protection for the data if the primary storage location becomes corrupted or becomes inaccessible. For example, if a natural disaster occurs in the geographic area of the first storage location, the data becomes inaccessible at the first storage location. In this example, the data is accessible at a second storage location located in a different geographic area than the first storage location.
従来のシステムは、データを取り込む時にデータを一次記憶場所に書き込み、データの受信をユーザに知らせる。その後、非同期バックグラウンドプロセスは、データを一次記憶場所から二次記憶場所に複製する。例えば、第１の記憶場所に一定期間非アクティブであった（例えば、１５分間新しいデータを受信していない）後、または十分な量のデータ（例えば、１００ＭＢ）が一次記憶場所に書き込まれた場合、非同期バックグラウンドプロセスは、同じデータを一次記憶場所から二次記憶場所に複製して記憶する。 As conventional systems capture data, they write the data to a temporary storage location and notify the user of the receipt of the data. An asynchronous background process then replicates the data from the primary storage location to the secondary storage location. For example, after a period of inactivity in the primary storage location (e.g., no new data has been received for 15 minutes), or if a sufficient amount of data (e.g., 100MB) is written to the primary storage location. , an asynchronous background process replicates and stores the same data from a primary storage location to a secondary storage location.
この非同期複製プロセスは、第１の記憶場所で発生する永久的な失敗がデータの回復不能なデータ損失につながるという脆弱性を残している。具体的には、システムが非同期複製プロセスを介してデータを第２の記憶場所に書き込む前に第１の記憶場所に失敗が発生する場合、データは、第２の記憶場所にまだ記憶されていないため、永久的に失われる可能性がある。 This asynchronous replication process leaves a vulnerability in that a permanent failure occurring at the first storage location can lead to irrecoverable data loss. Specifically, if a failure occurs in the first storage location before the system writes the data to the second storage location via the asynchronous replication process, the data is not yet stored in the second storage location. Therefore, it may be permanently lost.
対照的に、同期複製プロセスは、ユーザから受信したストリーミングデータを一次記憶場所および二次記憶場所に同時に記憶する。したがって、データを一次記憶場所または二次記憶場所のいずれかに書き込んでいる間またはその後に失敗が発生した場合、データは、他の記憶場所で依然としてアクセス可能である。しかしながら、データを一次記憶場所または二次記憶場所に同期複製する間に失敗が発生した場合、同期複製プロセスの失敗処理は、データが依然として利用可能であり、依然として適切に複製されていることを保証しなければならない。例えば、データを一次記憶場所および二次記憶場所に同時に同期複製している間に二次記憶場所がアクセス不能になると、データは、完全にバックアップされていない。 In contrast, a synchronous replication process stores streaming data received from a user in primary and secondary storage locations simultaneously. Therefore, if a failure occurs during or after writing data to either the primary or secondary storage location, the data is still accessible at the other storage location. However, if a failure occurs while synchronously replicating data to a primary or secondary storage location, the failure handling of the synchronous replication process ensures that the data is still available and is still properly replicated. Must. For example, if a secondary storage location becomes inaccessible while simultaneously replicating data to a primary storage location and a secondary storage location, the data is not completely backed up.
本明細書の実装形態は、ストリーミングデータを第１の記憶場所および第２の記憶場所に同時に同期複製するためのシステムに関する。このシステムは、一次記憶場所および／または二次記憶場所におけるストリーミングデータの利用可能性を常に維持するように、同期複製プロセス中に発生する失敗を管理する。例えば、システムは、データブロックを第１の記憶場所および第２の記憶場所に同期的に書き込んでいる間に、追加のデータブロックを第２の記憶場所に書き込むことを妨害する回復不能失敗を判断する。失敗に応答して、システムは、回復不能失敗の失敗点から開始して、一組のデータブロックを第１の記憶場所および第３の記憶場所に同期的に書き込む。 Implementations herein relate to a system for synchronously replicating streaming data to a first storage location and a second storage location simultaneously. The system manages failures that occur during the synchronous replication process so as to maintain the availability of streaming data at the primary and/or secondary storage locations at all times. For example, while writing data blocks to a first storage location and a second storage location synchronously, the system determines an unrecoverable failure that prevents writing additional data blocks to the second storage location. do. In response to the failure, the system synchronously writes a set of data blocks to the first storage location and the third storage location, starting from the point of failure of the irrecoverable failure.
図１を参照して、いくつかの実装形態において、例示的システム１００は、各ユーザ１２に関連付けられ、ネットワーク１１２を介してリモートシステム１４０と通信しているユーザ装置１０２を含む。ユーザ装置１０２は、任意のコンピューティング装置、例えば、デスクトップワークステーション、ラップトップワークステーション、またはモバイル装置（すなわち、スマートフォン）であってもよい。ユーザ装置１０２は、計算リソース１８（例えば、データ処理ハードウェア）および／または記憶リソース１６（例えば、メモリハードウェア）を含む。
Referring to FIG. 1, in some implementations, an
リモートシステム１４０は、計算リソース１４４（例えば、データ処理ハードウェア）および／または記憶リソース１４６（例えば、メモリハードウェア）を含む、拡張可能な／順応性のあるリソース１４２を有する単一のコンピュータ、複数のコンピュータ、または分散システム（例えば、クラウド環境）であってもよい。複数のデータブロックデータストア１５０、１５０ａ～ｃ（すなわち、リモート記憶装置１５０）が記憶リソース１４２上にオーバーレイされ、ユーザ１０および計算リソース１４４の一方または両方による記憶リソース１４２の拡張可能な使用を可能にする。各データブロックデータストア１５０は、複数のデータブロック２２、２２ａ～ｎをデータ構造（例えば、テーブル）に記憶するように構成されてもよい。各データブロックデータストア１５０は、記憶場所２１０、２１０ａ～ｃに関連付けられ、各記憶場所２１０は、異なる地理的領域に関連付けられる。
The
ユーザ１０は、ユーザ装置１０２を用いて、ネットワーク１１２を介して、リモートシステム１４０に記憶するための一組のデータブロック２２をリモートシステム１４０に送信する。一組のデータブロック２２は、任意の数のデータブロック２２を含むことができる。リモートシステム１４０は、リモートシステム１４０の第１の記憶場所２１０ａ（例えば、一次記憶場所２１０）およびリモートシステム１４０の第２の記憶場所２１０ｂ（例えば、二次記憶場所２１０）に記憶するための一組のデータブロック２２を受信する。第１の記憶場所２１０ａは、第１の地理的領域に関連付けられ、第２の記憶場所２１０ｂは、第１の地理的領域とは異なる第２の地理的領域に関連付けられる。例えば、第１の記憶場所２１０ａは、ニューヨーク市に位置し、第２の記憶場所２１０ｂは、ロサンゼルスに位置する。リモートシステム１４０の各記憶場所２１０は、一組のデータブロック２２を記憶するように構成された１つ以上のデータブロックデータストア１５０を含む。
リモートシステム１４０は、ユーザ装置１０２から受信した一組のデータブロック２２を複製するように構成されたデータブロック複製器２４０を実行する。すなわち、データブロック複製器２４０は、一組のデータブロック２２の各データブロック２２を２つの別個の組のデータブロック２２に複製する。一組のデータブロック２２を２組のデータブロック２２に複製することによって、データブロック複製器２４０は、一組のデータブロック２２を第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂに同期的に（すなわち、同時に）書き込むことができる。例えば、一組のデータブロック２２は、リモートシステム１４０によって第１の記憶場所２１０ａ（例えば、ロサンゼルス）のデータブロックデータストア１５０ａおよび第２の記憶場所２１０ｂ（例えば、ニューヨーク市）のデータブロックデータストア１５０ｂに記憶されるテーブルの一部または全てを表す。データブロック複製器２４０は、一組のデータブロック２２の各データブロック２２を、同時にまたは実質的に同時に第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂの両方に書き込む。同期書き込みを保証するために、データブロック複製器２４０は、各対の複製データブロック２２を、同時またはほぼ同時に一次記憶場所２１０ａおよび二次記憶場所２１０ｂに送信し、その後、両方のデータブロックデータストア１５０（例えば、データブロックデータストア１５０ａおよびデータブロックデータストア１５０ｂ）が前のデータブロック２２を受信したことを確認するまで、次のデータブロック２２の送信を待機させることができる。すなわち、各対の複製データブロック２２は、同時に送信され、データブロック複製器２４０は、一組のデータブロック２２を書き込む間に、同期性を維持する。
いくつかの例において、ユーザ１０は、一次記憶場所２１０（すなわち、第１の記憶場所２１０ａ）を選択する。例えば、ユーザ１０は、ロサンゼルスをデータの一次記憶場所として選択する。この例において、ユーザ１０またはリモートシステム１４０のいずれかは、二次記憶場所２１０（すなわち、第２の記憶場所２１０ｂ）を選択する。例えば、リモートシステム１４０は、一次記憶場所２１０とは異なる二次記憶場所２１０を選択するようにユーザ１０に指示する。代替的には、リモートシステム１４０は、様々な要因（例えば、場所、一次記憶場所２１０からの距離、混雑、コスト、遅延など）に基づいて、一次記憶場所２１０とは異なる二次記憶場所２１０を自動的に選択する。他の例において、リモートシステム１４０は、上述した要因のいずれかに基づいて、一次記憶場所２１０と二次記憶場所２１０の両方を自動的に選択する。
In some examples,
いくつかの実装形態において、リモートシステム１４０は、一組のデータブロック２２を第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂに同期的に書き込んでいる間に、第２の記憶場所２１０ｂへの一組のデータブロック２２のさらなる書き込みを妨害する第２の記憶場所２１０ｂの回復不能失敗を判断する。例えば、第２の記憶場所２１０ｂは、第２の記憶場所２１０ｂのデータブロックデータストア１５０ｂを物理的に損傷する自然災害を受ける可能性がある。別の例において、第２の記憶場所２１０ｂのデータブロックデータストア１５０ｂは、第２の記憶場所２１０ｂおよび／またはデータブロックデータストア１５０ｂとの通信を妨げるネットワーク接続問題に遭遇する。回復不能エラーは、閾値期間に持続するエラーおよび／または閾値数の再試行後に持続するエラーとして定義される。
In some implementations, the
回復不能失敗が発生すると、データブロック複製器２４０は、一組のデータブロック２２のうちの一部のデータブロック２２のみを第２の記憶場所２１０ｂに書き込む可能性がある。すなわち、回復不能失敗が第２の記憶場所２１０ｂおよび／またはデータブロックデータストア１５０ｂとのさらなる通信を妨害する前に、データブロック複製器２４０は、一組のデータブロック２２のうちの一部のみを書き込む。リモートシステム１４０は、一組のデータブロック２２を書き込むときの失敗点２２０（図２Ａおよび２Ｂ）を判断する。具体的には、失敗点２２０は、回復不能失敗が一組のデータブロック２２のうち、どのデータブロック２２に発生したかを示す。すなわち、失敗点２２０は、リモートシステム１４０が第２の記憶場所２１０ｂに正常に書き込んだデータブロック２２と、リモートシステム１４０が第２の記憶場所２１０ｂに正常に書き込まなかったデータブロック２２との境界を示す。なお、本明細書の例は、回復不能失敗が第２の記憶場所２１０ｂへのさらなる書き込みを妨害すると説明しているが、回復不能失敗は、一次記憶場所２１０（例えば、第１の記憶場所２１０ａ）または二次記憶場所２１０（例えば、第２の記憶場所２１０ｂ）のいずれかに発生しても、本明細書の実装形態の範囲に含まれる。
If an irrecoverable failure occurs,
第２の記憶場所２１０ｂの失敗点２２０を判断した後、データブロック複製器２４０は、失敗点２２０から開始して、一組のデータブロック２２を第１の記憶場所２１０ａおよび第３の記憶場所２１０ｃのデータブロックデータストア１５０ｃに同期的に書き込む。第３の記憶場所２１０ｃは、第１の地理的領域（例えば、ロサンゼルス）および第２の地理的領域（例えば、ニューヨーク市）とは異なる第３の地理的領域（例えば、マイアミ）に関連付けられる。
After determining the
図２Ａを参照して、いくつかの実装形態において、データブロック複製器２４０は、データブロック２２ａ～ｊを含む一組のデータブロック２２を受信する。データブロック複製器２４０は、一組のデータブロック２２（例えば、データブロック２２ａ～ｊ）を複製して、第１の記憶場所２１０ａと第２の記憶場所２１０ｂの両方に同時に書き込む。すなわち、データブロック複製器２４０は、一組のデータブロック２２を２組のデータブロック２２（例えば、２組のデータブロック２２ａ～ｊ）に複製することにより、一組のデータブロック２２を第１の記憶場所２１０ａと第２の記憶場所２１０ｂの両方に同期的に書き込むことができる。すなわち、データブロック２２を非同期的に書き込む代わりに、例えば、第１の記憶場所２１０ａへの書き込みを開始してから一定の期間で第２の記憶場所２１０ｂへの書き込みを開始する代わりに、データブロック複製器２４０は、各対の複製データブロック２２を第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂに同期的に書き込む。
Referring to FIG. 2A, in some implementations,
一組のデータブロック２２を複製した後、データブロック複製器２４０は、一組のデータブロック２２のうちの各データブロック２２を、第１の記憶場所２１０ａのデータブロックデータストア１５０ａおよび第２の記憶場所２１０ｂのデータブロックデータストア１５０ｂに書き込む。リモートシステム１４０は、一組のデータブロック２２を第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂに同期的に書き込んでいる間に、第２の記憶場所２１０ｂの回復不能失敗を判断する。この回復不能失敗は、第２の記憶場所２１０ｂへの一組のデータブロック２２のさらなる書き込みを妨害する。いくつかの実装形態において、リモートシステム１４０は、データブロック２２のうちの１つの書き込みが失敗したことを判断する。例えば、第２の記憶場所２１０ｂは、閾値期間で、各データブロック２２の書き込みの確認を待つ。図示の例において、データブロック２２ｆを第２の記憶場所２１０ｂに書き込むことが失敗したが、データブロック２２ｆを第１の記憶場所に書き込むことが成功した。データブロック複製器２４０が、各対の複製データブロック２２（すなわち、第１の記憶場所２１０ａのデータブロック２２および第２の記憶場所２１０ｂのデータブロック２２）の各々の書き込みが閾値期間中に発生したことを判断できない場合、リモートシステム１４０は、データブロック２２の書き込みが失敗したと判断する。
After replicating the set of data blocks 22, the
１つのデータブロック２２を第２の記憶場所２１０ｂ（他の例において、第１の記憶場所２１０ａ）に書き込む失敗の判断に応答して、リモートシステム１４０は、一組のデータブロック２２を第２の記憶場所２１０ｂに書き込むことを再試行することができる。例えば、第２の記憶場所２１０ｂは、リモートシステム１４０とのネットワーク接続を一時的に失い、閾値期間内にネットワーク接続を回復することがある。したがって、データブロック複製器２４０は、失敗が回復不能失敗であると判断する前に、任意の回数で失敗したデータブロック２２を送信しようと試みることができる。データブロック複製器２４０は、データブロック２２を第１の記憶場所２１０ａと第２の記憶場所２１０ｂの両方に同期的に書き込むため、第２の記憶場所２１０ｂへの失敗した書き込みを再試行する間に、任意の追加のデータブロック２２を第１の記憶場所２１０ａに書き込むことを控えることができる。
In response to determining a failure to write one
失敗したデータブロック２２を書き込むための再試行のうちの１つが成功した場合、リモートシステム１４０は、失敗が回復不能失敗ではないと判断し、一組のデータブロック２２を第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂの両方に書き込み続けることができる。リモートシステム１４０は、失敗した書き込みの１つ以上の再試行が失敗したと判断した場合、この失敗が第２の記憶場所２１０ｂへの一組のデータブロック２２のさらなる書き込みを妨害する回復不能失敗であると判断する。データブロック複製器２４０は、例えば、書き込みが失敗したデータブロック２２に基づいてまたは最後に書き込みが成功したデータブロック２２に基づいて、失敗点２２０を判断する。図２Ａの例において、データブロック複製器２４０は、（データブロック複製器２４０が第２の記憶場所２１０ｂに正常に書き込んだ）データブロック２２ｅと（データブロック複製器２４０が第２の記憶場所２１０ｂに正常に書き込まなかった）データブロック２２ｆとの間に、失敗点が発生したと判断する。
If one of the retries to write the failed
いくつかの例において、リモートシステム１４０は、第２の記憶場所２１０ｂの回復不能失敗を判断した後、エラーまたは失敗を示す指示をユーザ１０に返す。この指示は、失敗の前に正常に書き込まれたデータブロック２２の数、失敗点２２０、書き込みが失敗した記憶場所２１０などの詳細を含むことができる。
In some examples, after
図２Ｂを参照して、いくつかの例において、リモートシステム１４０が第２の記憶場所２１０ｂの回復不能失敗および失敗点２２０を判断した後、データブロック複製器２４０は、失敗点２２０から開始して、一組のデータブロック２２を第１の記憶場所２１０ａおよび第３の記憶場所２１０ｃに同期的に書き込む。具体的には、第２の記憶場所２１０ｂの回復不能失敗を判断した後、データブロック複製器２４０は、データブロック２２を第２の記憶場所２１０ｂに書き込むことの試みを停止し、代わりに、第１の記憶場所２１０ａと同期してデータブロック２２を第３の記憶場所２１０ｃに書き込むことを開始する。この例において、失敗点２２０が一組のデータブロック２２ａ～ｊのうちのデータブロック２２ｅとデータブロック２２ｆとの間にあると判断した後、データブロック複製器２４０は、データブロック２２ｆを第２の記憶場所２１０ｂに書き込むことの試みを停止する。データブロック複製器２４０は、失敗点２２０（すなわち、データブロック２２ｆ）から始まる一組のデータブロック２２を、一組のデータブロック２２（すなわち、データブロック２２ｊ）の終わりまで、第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂに同期的に書き込むことを開始する。したがって、データブロック複製器２４０は、一組のデータブロック２２の全体を書き込んでいる間に、一組のデータブロック２２の同期書き込みを維持する。
Referring to FIG. 2B, in some examples, after the
図２Ｃを参照して、いくつかの実装形態において、データブロック複製器２４０は、一組のデータブロック２２の開始点（すなわち、一組のデータブロック２２内の第１のデータブロック２２）から失敗点２２０までの一組のデータブロック２２を第３の記憶場所２１０ｃに非同期的に書き込む。例えば、データブロック複製器２４０が一組のデータブロック２２を第１の記憶場所２１０ａおよび第３の記憶場所２１０ｃに同期的に書き込むことを完了した後（すなわち、データブロック２２ｊの後）、第１の記憶場所２１０ａは、データブロック２２ａ～ｊを含み、第３の記憶場所は、データブロック２２ｆ～ｊを含む。一組のデータブロック２２を第３の記憶場所２１０ｃに完全に複製するために、データブロック複製器２４０は、残りのデータブロック２２ａ～ｅ（すなわち、データブロック複製器２４０が第２の記憶場所２１０ｂに正常に書き込んだデータブロック２２）を第３の記憶場所２１０ｃに非同期的に書き込む。データブロック複製器２４０がストリームデータブロック２２を第３の記憶場所２１０ｃに非同期的に書き込んだ後、第１の記憶場所２１０ａと第３の記憶場所２１０ｃの両方は、一組のデータブロック２２の全体（例えば、データブロック２２ａ～ｊ）を含む。
Referring to FIG. 2C, in some implementations, the
いくつかの例において、データブロック複製器２４０は、一組のデータブロック２２を第３の記憶場所２１０ｃに同期的に書き込んだ後、一組のデータブロック２２を第３の記憶場所２１０ｃに非同期的に書き込む。他の例において、データブロック複製器２４０は、一組のデータブロック２２を第１の記憶場所２１０ａおよび第３の記憶場所２１０ｃに同期的に書き込むと共に、一組のデータブロック２２を第３の記憶場所２１０ｃに非同期的に書き込む。
In some examples,
図３Ａの概略図３００ａを参照して、いくつかの実装形態において、リモートシステム１４０は、各記憶場所２１０および／または各データブロックデータストア１５０の複製ログ３１０、３１０ａ、および３１０ｂを生成する。複製ログ３１０は、データブロック２２を記憶する物理ファイルであってもよい。代替的には、複製ログ３１０は、別個のファイルであってもよい。この例において、リモートシステム１４０は、各データブロック２２を第１の記憶場所２１０ａおよび／またはデータブロックデータストア１５０ａに正常に書き込んだ時間を示すタイムスタンプを含む第１の複製ログ３１０ａを生成する。すなわち、データブロック複製器２４０がデータブロック２２を記憶場所２１０に正常に書き込む（すなわち、コミットする）と、リモートシステム１４０は、この書き込みを反映するように、（例えば、対応するタイムスタンプを用いて）対応する複製ログ３１０を更新する。一方、データブロック複製器２４０がデータブロック２２を記憶場所２１０に正常に書き込むことに失敗した場合、リモートシステム１４０は、この書き込みを反映するように、対応する複製ログを更新しない。各記憶場所２１０が対応する複製ログ３１０を含むため、リモートシステム１４０は、複製ログ３１０を用いて、複製間のコヒーレンシを保証することができる。
Referring to schematic diagram 300a of FIG. 3A, in some implementations,
いくつかの例において、リモートシステム１４０は、照合器３３０を実行する。照合器３３０は、第１の記憶場所２１０ａに正常にコミットされたデータブロック２２を示す第１の複製ログ３１０ａが利用可能であるか否かを判断することによって、および第２の記憶場所２１０ｂに正常にコミットされたデータブロック２２を示す第２の複製ログ３１０ｂが利用可能であるか否かを判断することによって、一組のデータブロック２２内の失敗点２２０を判断することができる。すなわち、リモートシステム１４０（または、いくつかの例において、ユーザ１０）は、エラーを照合器３３０に通知し、照合器３３０は、第１の記憶場所２１０ａからの第１の複製ログ３１０ａと、第２の記憶場所２１０ｂからの第２の複製ログ３１０ｂとの両方を取得することを試みる。図３Ａの例において、照合器３３０は、第１の複製ログ３１０ａと第２の複製ログ３１０ｂの両方が利用可能であると判断する。
In some examples,
第１の複製ログ３１０ａと第２の複製ログ３１０ｂの両方が利用可能である場合、照合器３３０は、第１の複製ログ３１０ａの長さおよび第２の複製ログ３１０ｂの長さに基づいて、第１の複製ログ３１０ａと第２の複製ログ３１０ｂとを照合する。いくつかの例において、照合器３３０は、複製ログ３１０が同じ長さ（すなわち、同じサイズ）を有し、複製ログ３１０の各々が失敗点２２０の後のデータブロック２２のレコードを含むと判断する。これは、リモートシステム１４０が失敗から回復し、一組のデータブロック２２が第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂの両方に正常にコミットされたことを意味する。このシナリオにおいて、照合器３３０は、複製が成功したことをユーザ１０に通知する。
If both the first replicated
他の例において、照合器３３０は、第２の複製ログ３１０ｂの長さが第１の複製ログ３１０ａの長さよりも小さい（すなわち、第２の複製ログ３１０ｂのサイズが第１の複製ログ３１０ａのサイズよりも小さい）と判断する。このシナリオは、現在ではデータブロック複製器２４０と第２の記憶場所２１０ｂとの間に「インフライト」書き込みがあり、複製ログ３１０ａ、３１０ｂの異なる長さを引き起こすことを示す、またはインフライト書き込みがなく、第２の記憶場所２１０ｂが失敗したことを示す。すなわち、データブロック複製器２４０は、データブロック２２を第１の記憶場所２１０ａに正常に書き込むことに成功し、対応する複製データブロック２２を第２の記憶場所２１０ｂに書き込むことに失敗した。一般的には、リモートシステム１４０および／またはユーザ１０が閾値期間を待ってから失敗を照合器３３０に通知するため、照合器３３０は、インフライト書き込みがないと仮定する。図２Ａ～２Ｃの例を続けると、照合器３３０は、（データブロック２２ａ～ｆの書き込みに対応するエントリを含む）第１の複製ログ３１０ａの長さが（データブロック２２ａ～ｅの書き込みに対応するエントリを含む）第２の複製ログ３１０ｂの長さよりも長いと判断する。
In other examples, the matcher 330 determines that the length of the second replicated
照合器３３０は、第１の複製ログ３１０ａの長さが第２の複製ログ３１０ｂの長さと異なると判断した後、照合プロセス（例えば、強制終了）を実行する。照合器３３０は、回復不能失敗に関連する第２の複製ログ３１０ｂのインデックス（例えば、回復不能失敗の位置または失敗点２２０）を決定することによって、第１の複製ログ３１０ａと第２の複製ログ３１０ｂとを照合することができる。照合器３３０は、第２の複製ログ３１０ｂのインデックスを決定した後、第２の複製ログ３１０ｂのインデックスをメモリハードウェア１４６に記憶することができる。すなわち、リモートシステム１４０は、将来の参照のために、複製ログの長さを記憶することができる。いくつかの実装形態において、照合器３３０は、第２の記憶場所２１０ｂへのさらなる書き込みを禁止するように第２の複製ログ３１０ｂを終了させ、照合する必要性を示すセンチネルファイル３４０を生成する。
After the matcher 330 determines that the length of the
いくつかの例において、データブロック複製器２４０は、データブロック２２を記憶場所２１０に書き込むように構成された別個のストリームサーバまたはワーカ（すなわち、処理タスクまたは処理スレッド）と連携する。ワーカがデータブロック２２の書き込みに一時的に失敗したが、アクティブなままである（すなわち、「ゾンビ」ワーカである）場合、このワーカは、データブロック複製器２４０が回復不能失敗を判断し、一組のデータブロック２２を第３の記憶場所２１０ｃに書き込み始めた後でも、データブロック２２を第２の記憶場所２１０ｂに書き込み続けることを試みることができる。このゾンビワーカは、最終化された複製ログ３１０に遭遇すると、複製ログ３１０に追加の書き込みを事実上コミットすることができない。さらに、センチネルファイル３４０は、ログファイルの所有権を中止するようにワーカに通知する役割を果たす。
In some examples,
図３Ｂを参照して、いくつかの例において、第１の複製ログ３１０ａが利用可能であり、第２の複製ログ３１０ｂが利用できない（またはその逆）場合、照合器３３０は、第１の複製ログ３１０ａの長さに基づいて、第１の複製ログ３１０ａおよび第２の複製ログ３１０ｂを再び照合する。例えば、回復不能失敗によって第２の記憶場所２１０ｂがアクセス不能である場合、第２の複製ログ３１０ｂも同様にアクセス不能である。この場合、照合器３３０は、第１の複製ログ３１０ａおよび第２の複製ログ３１０ｂの長さを比較することができないため、第１の複製ログ３１０ａの長さのみに依存する。同様に、第１の複製ログ３１０ａが利用できず、第２の複製ログが利用可能である場合、照合器３３０は、第２の複製ログ３１０ｂの長さに基づいて、第１の複製ログ３１０ａと第２の複製ログ３１０ｂとを照合することができる。
3B, in some examples, if the
照合器３３０は、利用可能な複製ログ３１０が利用不可能な複製ログ３１０よりも長くても短くてもうまく照合できるため、利用可能な複製ログ３１０の長さのみに依存することができる。利用可能な複製ログ３１０が利用不可能な複製ログ３１０よりも短い場合、これは、データブロック２２を記憶場所２１０に書き込んだ後、データブロック２２を記憶場所にコミットする前に失敗が発生した場合にのみ起こり得る。したがって、照合器３３０は、利用不可能な複製ログ３１０の長さを増加させた「余分な」データブロック２２がコミットされていないと安全に仮定することができる。
The matcher 330 can rely only on the length of the available replication logs 310 because it can successfully match whether the available replication logs 310 are longer or shorter than the unavailable replication logs 310. If the
一方、利用可能な複製ログ３１０が利用不可能な複製ログ３１０よりも長い場合、利用可能な記憶場所２１０に書き込まれた追加のデータブロック２２は、失敗した書き込み（例えば、ハイパーテキスト転送プロトコル（ＨＴＴＰ）５００エラーなどの内部エラーによる失敗した書き込み）に対応する。照合器３３０は、リモートシステム１４０が全ての読み取りに対してデータブロック２２を常に提供している限り、このデータがコミットされていると安全に仮定することができる。
On the other hand, if the
図４を参照して、いくつかの実施例において、リモートシステム１４０は、第１の記憶場所２１０ａ（すなわち、一次記憶場所２１０）に記憶された複数のデータブロック５２の返却を要求するクエリ要求４１０を受信する。クエリ要求４１０は、返却されるデータブロック２２を定義する１つ以上のパラメータ、例えば１つ以上のキーワードを含むことができる。パラメータは、スナップショット読み取りタイムスタンプ４１２を含む。このスナップショット読み取りタイムスタンプ４１２は、リモートシステム１４０がデータブロックデータストア１５０を読み取る時刻を指定する。複製ログ３１０内のタイムスタンプがデータブロック２２をデータブロックデータストア１５０にコミットする時刻を示すため、リモートシステム１４０は、スナップショット読み取りタイムスタンプ４１２を複製ログ３１０内の各データブロック２２に関連付けられたタイムスタンプと相関させる。例えば、リモートシステム１４０は、スナップショット読み取りタイムスタンプ４１２の後、データブロック複製器２４０がデータブロックデータストア１５０に書き込んだデータブロック２２を返す。クエリ要求４１０がスナップショット読み取りタイムスタンプ４１２を含まない場合、リモートシステム１４０は、スナップショット読み取りタイムスタンプ４１２を現在の時間に初期設定する。
Referring to FIG. 4, in some embodiments, the
データブロック２２をデータブロックデータストア１５０にコミットするときに複製ログ３１０に追加されるタイムスタンプが単調に増加するため、リモートシステム１４０が複製ログ３１０を読み取るときに、リモートシステム１４０がスナップショット読み取りタイムスタンプ４１２よりも大きいコミットタイムスタンプを有するデータブロック２２に遭遇すると、リモートシステム１４０は、複製ログ３１０内の全てのさらなるレコードもスナップショット読み取りタイムスタンプ４１２よりも大きいタイムスタンプを有すると安全に仮定することができ、したがって、リモートシステム１４０は、複製ログ３１０の読み取りを停止することができる。しかしながら、複製ログ３１０内の最後のレコードがスナップショット読み取りタイムスタンプ４１２より大きくないタイムスタンプを有するデータブロック２２に関連付けられた場合、リモートシステム１４０は、最後のデータブロック２２に対していかなる仮定を行わない可能性がある。その理由は、最後のデータブロック２２が、失敗した書き込みの結果である可能性があり、他の記憶場所２１０に正常に複製されていなかったからである。したがって、リモートシステム１４０は、最後のデータブロック２２を提供する前に、現在のスナップショット読み取りタイムスタンプ４１２と同じまたはそれよりも大きいスナップショット読み取りタイムスタンプ４１２を有する任意の他の後続の読み取りも、最後のデータブロック２２を常に提供することを保証しなければならない。この目的のために、照合器３３０は、クエリ要求４１０からの読み取りを照合することができる。
Because the timestamp added to the
いくつかの実装形態において、照合器３３０は、第１の複製ログ３１０ａの長さおよび第２の複製ログ３１０ｂの長さに基づいて、第１の複製ログ３１０ａと第２の複製ログ３１０ｂとを照合する。いくつかの例において、照合器３３０は、まず、第２の複製ログ３１０ｂの長さが利用できないと判断し、その後、後続の書き込みが閾値期間内に第１の複製ログ３１０ａに追加されると判断する。すなわち、状態を照合するために、照合器３３０は、複製ログ３１０ａ、３１０ｂの長さを判断し、両方が同じである場合、照合器３３０は、第１の複製ログ３１０ａの最後のデータブロックがコミットされ、完了していると判断する。しかしながら、複製ログ３１０ａ、３１０ｂのいずれかが利用不可能であるかまたはアクセス不可能である場合、照合器３３０は、後続の書き込みが利用可能な複製ログ３１０に現れるまで、少量の時間（例えば、５５ミリ秒）で待機する。この例において、リモートシステム（例えば、データブロック複製器２４０のストリームサーバ）は、非アクティブな複製ログ３１０に対して「キープアライブ」書き込みを定期的に（例えば、１５ミリ秒毎に）実行する。
In some implementations, the matcher 330 matches the first replicated
後続の書き込みが複製ログ３１０に現れると、照合器３３０は、複製された書き込みが発生しており、したがって、前のデータブロック２２の書き込みが成功したと仮定することができる。この書き込みは、クエリ要求４１０のスナップショット読み取りタイムスタンプよりも大きいタイムスタンプに関連付けられているため、照合器３３０は、全てのデータブロック２２（すなわち、複製ログ３１０中の最後のデータブロック２２）を安全に提供できると仮定することができる。後続の書き込みが少量の時間で待機しても現れない場合、照合器３３０は、以前の照合で記憶された任意の複製ログ長を検索して、最後のデータブロック２２を提供すべきか否かを判断する。すなわち、データブロック２２が以前の照合で記憶された長さよりも大きいインデックスを有する場合、リモートシステム１４０は、最後のデータブロック２２を提供しない。しかしながら、最後のデータブロック２２が、以前の照合で記憶された長さと同じまたはそれより小さいインデックスを有する場合、リモートシステム１４０は、最後のデータブロック２２を提供する。必要な照合をした後、リモートシステム１４０は、第１の複製ログ３１０ａと第２の複製ログ３１０ｂの照合に基づいて、要求された複数のデータブロック２２を返す。
When a subsequent write appears in
いくつかの実装形態において、リモートシステム１４０は、各々が最後のデータブロック２２の照合を要求する複数のクエリ要求４１０を受信する。このシナリオにおいて、クエリ要求４１０のうちの１つのみが、複製ログ３１０の最終コミット長を決定し、リモートシステム１４０が、同じ最終コミット長を用いて他の全てのクエリ要求４１０を処理する。したがって、リモートシステム１４０は、一致した複製を提供する。
In some implementations,
図５は、ハイスループットストリーミングデータを同期複製するための方法５００の動作の例示的な構成を示す流れ図である。方法５００は、ステップ５０２において、データ処理ハードウェア１４４が、分散記憶システム１４０の第１の記憶場所２１０ａおよび分散記憶システム１４０の第２の記憶場所２１０ｂに記憶するための一組のデータブロック２２を受信することを含む。第１の記憶場所２１０ａは、第１の地理的領域に関連付けられ、第２の記憶場所は、第１の地理的領域とは異なる第２の地理的領域に関連付けられる。方法５００は、ステップ５０４において、データ処理ハードウェア１４４が、一組のデータブロック２２を第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂに同期的に書き込むことを含む。方法５００は、ステップ５０６において、データ処理ハードウェア１４４が、一組のデータブロック２２を第１の記憶場所２１０ａおよび第２の記憶場所２１０ｂに同期的に書き込んでいる間に、第２の記憶場所２１０ｂへの一組のデータブロック２２のさらなる書き込みを妨害する第２の記憶場所２１０ｂの回復不能失敗を判断することを含む。
FIG. 5 is a flow diagram illustrating an example configuration of the operation of a
方法５００は、ステップ５０８において、データ処理ハードウェア１４４が、一組のデータブロック２２を書き込むときの失敗点２２０を判断することを含む。失敗点２２０は、第２の記憶場所２１０ｂに正常に書き込まれたデータブロック２２と、第２の記憶場所２１０ｂに正常に書き込まれなかったデータブロック２２との境界を示す。方法５００は、ステップ５１０において、データ処理ハードウェア１４４が、失敗点２２０から開始して、一組のデータブロック２２を分散記憶システムの第１の記憶場所２１０ａおよび第３の記憶場所２１０ｃに同期的に書き込むことを含む。第３の記憶場所２１０ｃは、第１の地理的領域および第２の地理的領域とは異なる第３の地理的領域に関連付けられる。
図６は、本明細書に記載のシステムおよび方法を実装するために使用され得る例示的なコンピューティング装置６００を示す概略図である。コンピューティング装置６００は、ラップトップ、デスクトップ、ワークステーション、ＰＤＡ（Personal Digital Assistant）、サーバ、ブレードサーバ、メインフレームおよび他の適切なコンピュータなどの様々な形態のデジタルコンピュータを表すように意図されている。図示された要素、それらの接続および関係並びにそれらの機能は、例示的なものに過ぎず、本明細書に記載および／または請求される発明の実施を限定するものではない。
FIG. 6 is a schematic diagram illustrating an
コンピューティング装置６００は、プロセッサ６１０と、メモリ６２０と、記憶装置６３０と、メモリ６２０および高速拡張ポート６５０に接続する高速インターフェイス／コントローラ６４０と、低速バス６７０および記憶装置６３０に接続する低速インターフェイス／コントローラ６６０とを含む。要素６１０、６２０、６３０、６４０、６５０および６６０は、様々なバスを使用して相互に接続され、共通のマザーボード上に実装されてもよく、または適切な他の方法で実装されてもよい。プロセッサ６１０は、メモリ６２０または記憶装置６３０に記憶された命令を含むコンピューティング装置６００内に実行される命令を処理することによって、外部入力／出力装置のグラフィカルユーザインターフェイス（ＧＵＩ）に、例えば高速インターフェイス６４０に接続されたディスプレイ６８０にグラフィック情報を表示することができる。他の実施態様において、複数のプロセッサおよび／または複数のバスは、複数のメモリおよび複数種類のメモリと共に、適切に使用されることができる。また、各装置が（例えば、サーババンク、一群のブレードサーバ、またはマルチプロセッサシステムとして）必要な動作の一部を実行するように、複数のコンピューティング装置６００を接続することができる。
メモリ６２０は、情報をコンピューティング装置６００に非一時的に格納する。メモリ６２０は、コンピュータ可読媒体、揮発性メモリユニット、または不揮発性メモリユニットであってもよい。非一時的なメモリ６２０は、コンピューティング装置６００によって使用されるように、プログラム（例えば、一組の命令）またはデータ（例えば、プログラム状態情報）を一時的または永続的に格納するための物理装置であってもよい。不揮発性メモリの例として、フラッシュメモリおよび読み取り専用メモリ（ＲＯＭ）／プログラマブル読み取り専用メモリ（ＰＲＯＭ）／消去可能なプログラマブル読み取り専用メモリ（ＥＰＲＯＭ）／（通常ブートプログラムなどのファームウェアに使用される）電子的に消去可能なプログラマブル読み取り専用メモリ（ＥＥＰＲＯＭ）を含むが、これらに限定されない。揮発性メモリの例として、ランダムアクセスメモリ（ＲＡＭ）、ダイナミックランダムアクセスメモリ（ＤＲＡＭ）、スタティックランダムアクセスメモリ（ＳＲＡＭ）、相変化メモリ（ＰＣＭ）およびディスクまたはテープを含むが、これらに限定されない。
記憶装置６３０は、コンピューティング装置６００に大容量の記憶を提供することができる。いくつかの実現形態において、記憶装置６３０は、コンピュータ可読媒体である。様々な異なる実現例において、記憶装置６３０は、例えば、フロッピー（登録商標）ディスク装置、ハードディスク装置、光学ディスク装置、テープディスク装置、フラッシュメモリまたは他の同様の固体メモリ装置、または記憶エリアネットワークまたは他の構成内の装置を含むアレイ記憶装置などのコンピュータ可読媒体を含むことができる。追加の実現例において、コンピュータプログラム製品は、情報担体に有形的に具体化される。また、コンピュータプログラム製品は、命令を含むことができる。これらの命令は、実行されると、上述したような１つ以上の方法を実行することができる。情報担体は、例えば、メモリ６２０、記憶装置６３０、またはプロセッサ６１０上のメモリなどのコンピュータ可読媒体または機械可読媒体である。
高速コントローラ６４０は、コンピューティング装置６００の高速の帯域幅集約動作を管理し、低速コントローラ６６０は、低速の帯域幅集約動作を管理する。このような機能の割り当ては、例示に過ぎない。いくつかの実現例において、高速コントローラ６４０は、メモリ６２０に、（例えば、グラフィックプロセッサまたはアクセラレータを介して）ディスプレイ６８０に、および様々な拡張カード（図示せず）を挿入できる高速拡張ポート６１０に連結される。いくつかの実現例において、低速コントローラ６６０は、記憶装置６３０および低速拡張ポート６９０に連結される。様々な通信ポート（例えば、ＵＳＢ、ブルートゥース（登録商標）、イーサネット（登録商標）、無線イーサネット）を含み得る低速拡張ポート６９０は、例えば、キーボード、ポインティング装置、スキャナなどの１つ以上の入出力装置に連結されてもよく、またはネットワークアダプタを介して、スイッチまたはルータなどのネットワーキング装置に連結されてもよい。
図示のように、コンピューティング装置６００は、いくつかの異なる形態で実装されてもよい。例えば、コンピューティング装置６００は、標準サーバ６００ａとして実装されてもよく、またはラップトップコンピュータ６００ｂとしてまたはラックサーバシステム６００ｃの一部として一群の標準サーバ６００ａに複数回実装されてもよい。
As illustrated,
本明細書に記載のシステムおよび技術の様々な実装は、デジタル電子および／または光回路、集積回路、特別に設計されたＡＳＩＣ（特定用途向け集積回路）、コンピュータハードウェア、ファームウェア、ソフトウェアおよび／またはそれらの組み合わせで実現することができる。これらの様々な実装は、プログラム可能なシステム上で実行可能および／または解釈可能な１つ以上のコンピュータプログラムにおける実装を含むことができる。このプログラム可能なシステムは、記憶システムからデータおよび命令を受信し、データおよび命令を記憶システムに送信するように記憶システムに連結された少なくとも１つのプログラム可能な専用または汎用のプロセッサ、少なくとも１つの入力要素、および少なくとも１つの出力装置を含む。 Various implementations of the systems and techniques described herein may include digital electronic and/or optical circuits, integrated circuits, specially designed ASICs (Application Specific Integrated Circuits), computer hardware, firmware, software and/or This can be achieved by combining them. These various implementations may include implementation in one or more computer programs executable and/or interpretable on a programmable system. The programmable system includes at least one programmable special purpose or general purpose processor coupled to the storage system to receive data and instructions from the storage system and transmit data and instructions to the storage system; at least one input; and at least one output device.
（プログラム、ソフトウェア、ソフトウェアアプリケーションまたはコードとしても知られている）これらのコンピュータプログラムは、プログラム可能なプロセッサ用の機械命令を含み、高度な手続き型プログラミング言語および／または高度な目標物指向プログラミング言語で実装することができ、および／またはアセンブリ言語／機械言語で実装することができる。「機械可読媒体」および「コンピュータ可読媒体」という用語は、本明細書に使用された場合、プログラム可能なプロセッサに機械命令および／またはデータを提供するために使用された機械可読信号としての機械命令を受け取る機械可読媒体を含む任意のコンピュータプログラム製品、非一時的コンピュータ可読媒体、機械および／または装置（例えば、磁気ディスク、光学ディスク、メモリ、プログラム可能な論理装置（ＰＬＤ））を指す。「機械可読信号」という用語は、機械命令および／またはデータをプログラム可能なプロセッサに提供するために使用された任意の信号を指す。 These computer programs (also known as programs, software, software applications, or code) contain machine instructions for a programmable processor and are written in a high-level procedural programming language and/or a high-level goal-oriented programming language. and/or in assembly/machine language. The terms "machine-readable medium" and "computer-readable medium" as used herein refer to machine instructions as machine-readable signals used to provide machine instructions and/or data to a programmable processor. Refers to any computer program product, non-transitory computer-readable medium, machine and/or device (e.g., magnetic disk, optical disk, memory, programmable logic device (PLD)) that receives machine-readable media. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
本明細書に記載のプロセスおよびロジックフローは、データ処理ハードウェアとも呼ばれる１つ以上のコンピュータプログラムを実行する１つ以上のプログラム可能なプロセッサによって、入力データを処理して出力を生成する機能を実行することによって実行されてもよい。プロセスおよびロジックフローは、専用ロジック回路、例えば、ＦＰＧＡ（フィールドプログラマブルゲートアレイ）またはＡＳＩＣ（特定用途向け集積回路）によって実行されてもよい。コンピュータプログラムの実行に適したプロセッサは、例として、汎用マイクロプロセッサ、専用マイクロプロセッサ、およびあらゆる種類のデジタルコンピュータの１つ以上のプロセッサを含む。一般的に、プロセッサは、読み取り専用メモリまたはランダムアクセスメモリもしくはその両方から、命令およびデータを受け取る。コンピュータの重要な要素は、命令を実行するためのプロセッサと、命令およびデータを格納するための１つ以上のメモリ装置である。一般的に、コンピュータは、データを格納するための１つ以上の大容量記憶装置、例えば磁気ディスク、光磁気ディスクまたは光ディスクを含むまたはデータを受信または転送するように動作可能に結合される。しかしながら、コンピュータは、このような装置を備えなくてもよい。コンピュータプログラム命令およびデータの格納に適したコンピュータ可読媒体は、例として、例えばＥＰＲＯＭ、ＥＥＰＲＯＭおよびフラッシュメモリ装置などの半導体メモリ装置、内蔵ハードディスクまたはリムーバブルディスクなどの磁気ディスク、光磁気ディスク、ＣＤ ＲＯＭおよびＤＶＤ－ＲＯＭディスクを包括する全ての不揮発性メモリ、媒体およびメモリ装置を含む。プロセッサおよびメモリは、専用ロジック回路によって補足されてもよく、または専用ロジック回路に組み込まれてもよい。 The processes and logic flows described herein perform the functions of processing input data and producing output by one or more programmable processors executing one or more computer programs, also referred to as data processing hardware. It may be performed by The processes and logic flows may be performed by dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). Processors suitable for the execution of a computer program include, by way of example, general purpose microprocessors, special purpose microprocessors, and one or more processors of any type of digital computer. Generally, a processor receives instructions and data from read-only memory and/or random access memory. The essential elements of a computer are a processor for executing instructions and one or more memory devices for storing instructions and data. Generally, a computer is operably coupled to include one or more mass storage devices for storing data, such as magnetic, magneto-optical or optical disks, or for receiving or transferring data. However, a computer may not include such a device. Computer readable media suitable for storing computer program instructions and data include, by way of example, semiconductor memory devices such as EPROMs, EEPROMs and flash memory devices, magnetic disks such as internal hard disks or removable disks, magneto-optical disks, CD ROMs and DVDs. - Includes all non-volatile memory, media and memory devices including ROM disks. The processor and memory may be supplemented by or incorporated into dedicated logic circuits.
ユーザとの情報交換を行うために、本開示の１つ以上の態様は、例えばＣＲＴ（ブラウン管）モニタ、ＬＣＤ（液晶ディスプレイ）モニタ、またはタッチ画面などの、ユーザに情報を表示するためのディスプレイ素子、および必要に応じて、ユーザがコンピュータに入力を提供することができるキーボードおよびポインティング装置（例えば、マウスまたはトラックボール）を含むコンピュータ上で実装することができる。他の種類の装置を使用して、ユーザと情報交換を行うこともできる。例えば、ユーザに与えるフィードバックは、任意の形の感覚フィードバック（例えば、視覚フィードバック、聴覚フィードバック、または触覚フィードバック）であってもよく、ユーザから受け入れる入力は、音響入力、音声入力、または触覚入力を含む任意の形態であってもよい。さらに、コンピュータは、ユーザが使用している装置との間で文書を送受信することによって、例えば、Ｗｅｂブラウザから受信した要求に応答して、ユーザのクライアント装置上のＷｅｂブラウザにＷｅｂページを送信することによって、ユーザと情報交換することができる。 To exchange information with a user, one or more aspects of the present disclosure may include a display element, such as a CRT (cathode ray tube) monitor, an LCD (liquid crystal display) monitor, or a touch screen, for displaying information to the user. , and, optionally, a keyboard and pointing device (e.g., a mouse or trackball) that allow a user to provide input to the computer. Other types of devices may also be used to exchange information with users. For example, the feedback provided to the user may be any form of sensory feedback (e.g., visual, auditory, or haptic feedback), and the input accepted from the user includes acoustic, vocal, or tactile input. It may be in any form. Additionally, the computer sends and receives documents to and from the device that the user is using, e.g., in response to requests received from the web browser, transmitting web pages to the web browser on the user's client device. This allows information to be exchanged with users.
いくつかの実装形態を説明した。これにもかかわらず、本開示の精神および範囲から逸脱することなく、様々な修正を行うことができることが理解されるであろう。したがって、他の実装形態は、以下の特許請求の範囲に含まれる。 Several implementation forms were explained. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly, other implementations are within the scope of the following claims.
Claims (19)
データ処理ハードウェアが、分散記憶システムの第１の記憶場所および前記分散記憶システムの第２の記憶場所に記憶するための一組のデータブロックを受信することを含み、前記第１の記憶場所は、第１の地理的領域に関連付けられ、前記第２の記憶場所は、前記第１の地理的領域とは異なる第２の地理的領域に関連付けられ、
前記データ処理ハードウェアが、前記一組のデータブロックを前記第１の記憶場所および前記第２の記憶場所に同期的に書き込むことと、
前記データ処理ハードウェアが、前記一組のデータブロックを前記第１の記憶場所および前記第２の記憶場所に同期的に書き込んでいる間に、前記第２の記憶場所への前記一組のデータブロックのさらなる書き込みを妨害する前記第２の記憶場所の回復不能失敗を判断することと、
前記データ処理ハードウェアが、前記一組のデータブロックを書き込むときの失敗点を判断することとを含み、前記失敗点は、前記第２の記憶場所に正常に書き込まれたデータブロックと前記第２の記憶場所に正常に書き込まれなかったデータブロックとの境界を示し、
前記データ処理ハードウェアが、前記失敗点から開始して、前記一組のデータブロックを前記分散記憶システムの前記第１の記憶場所および第３の記憶場所に同期的に書き込むことを含み、前記第３の記憶場所は、前記第１の地理的領域および前記第２の地理的領域とは異なる第３の地理的領域に関連付けられ、
前記データ処理ハードウェアが、前記一組のデータブロックの開始点から前記失敗点までの前記一組のデータブロックを前記第３の記憶場所に非同期的に書き込むことを含む、方法。 A method,
data processing hardware receiving a set of data blocks for storage in a first memory location of a distributed storage system and a second memory location of the distributed storage system, the first memory location being , associated with a first geographic area, the second storage location being associated with a second geographic area different from the first geographic area,
the data processing hardware synchronously writes the set of data blocks to the first storage location and the second storage location;
the set of data to the second memory location while the data processing hardware is synchronously writing the set of data blocks to the first memory location and the second memory location; determining an irrecoverable failure of the second memory location that prevents further writing of the block;
the data processing hardware determining a failure point when writing the set of data blocks, the failure point being a data block successfully written to the second storage location and a failure point when writing the set of data blocks; indicates a boundary with a data block that was not successfully written to the storage location of
the data processing hardware synchronously writes the set of data blocks to the first and third storage locations of the distributed storage system starting from the point of failure; three storage locations are associated with a third geographic area different from the first geographic area and the second geographic area ;
The method includes: the data processing hardware asynchronously writing the set of data blocks from a starting point of the set of data blocks to the point of failure to the third storage location.
前記一組のデータブロックを前記第２の記憶場所に書き込む失敗を判断することと、
前記一組のデータブロックを前記第２の記憶場所に書き込む失敗の判断に応答して、前記一組のデータブロックを前記第２の記憶場所に書き込むことを再試行することと、
前記一組のデータブロックを前記第２の記憶場所に書き込むことを再試行することが失敗した場合、前記失敗が回復不能失敗であると判断することとを含む、請求項１に記載の方法。 determining the irrecoverable failure of the second storage location that prevents further writing of the set of data blocks to the second storage location;
determining a failure to write the set of data blocks to the second memory location;
retrying writing the set of data blocks to the second memory location in response to a determination of failure to write the set of data blocks to the second memory location;
2. The method of claim 1 , comprising: if retrying writing the set of data blocks to the second storage location fails, determining the failure is an irrecoverable failure.
前記第１の記憶場所に正常にコミットされた前記データブロックを示す第１の複製ログが利用可能であるか否かを判断することと、
前記第２の記憶場所に正常にコミットされた前記データブロックを示す第２の複製ログが利用可能であるか否かを判断することと、
前記第１の複製ログおよび前記第２の複製ログが利用可能である場合、前記第１の複製ログの長さおよび前記第２の複製ログの長さに基づいて、前記第１の複製ログと前記第２の複製ログとを照合することとを含む、請求項１または２に記載の方法。 Determining the point of failure when writing the set of data blocks comprises:
determining whether a first replication log indicating the data blocks successfully committed to the first storage location is available;
determining whether a second replication log is available indicating the data blocks successfully committed to the second storage location;
If the first replicated log and the second replicated log are available, the length of the first replicated log and the second replicated log are determined based on the length of the first replicated log and the length of the second replicated log. 3. The method according to claim 1 , comprising comparing the second replication log with the second replication log.
前記回復不能失敗に関連する前記第２の複製ログのインデックスを決定することと、
前記第２の複製ログの前記インデックスを、前記データ処理ハードウェアと通信するメモリハードウェアに記憶することと、
前記第２の記憶場所へのさらなる書き込みを禁止するように前記第２の複製ログを終了させることと、
照合する必要性を示すセンチネルファイルを生成することとを含む、請求項３に記載の方法。 Collating the first replication log and the second replication log includes:
determining an index of the second replication log associated with the unrecoverable failure;
storing the index of the second replication log in memory hardware in communication with the data processing hardware;
terminating the second replication log to inhibit further writes to the second storage location;
4. The method of claim 3 , comprising: generating a sentinel file indicating the need for matching.
前記データ処理ハードウェアが、各データブロックを前記第２の記憶場所に書き込む時間を示すタイムスタンプを含む第２の複製ログを生成することををさらに含む、請求項１から６のいずれか一項に記載の方法。 the data processing hardware generating a first replication log including a timestamp indicating the time at which each data block was written to the first storage location;
7. Any one of claims 1 to 6 , wherein the data processing hardware further comprises generating a second replication log including a timestamp indicating the time to write each data block to the second storage location. The method described in.
前記データ処理ハードウェアが、前記第１の複製ログの長さおよび前記第２の複製ログの長さに基づいて、前記第１の複製ログと前記第２の複製ログとを照合することと、
前記データ処理ハードウェアが、前記第１の複製ログおよび前記第２の複製ログの前記照合に基づいて、要求された前記複数のデータブロックを返すこととをさらに含む、請求項７に記載の方法。 the data processing hardware receiving a query request requesting return of a plurality of data blocks stored in the first storage location;
the data processing hardware collating the first replication log and the second replication log based on the length of the first replication log and the length of the second replication log;
8. The method of claim 7 , further comprising: the data processing hardware returning the requested plurality of data blocks based on the matching of the first replication log and the second replication log. .
前記第２の複製ログの前記長さが利用できないと判断することと、
後続の書き込みが閾値期間内に前記第１の複製ログに追加されると判断することとを含む、請求項８に記載の方法。 Collating the first replication log and the second replication log includes:
determining that the length of the second replication log is unavailable;
and determining that subsequent writes are added to the first replication log within a threshold period.
データ処理ハードウェアと、
前記データ処理ハードウェアと通信するメモリハードウェアとを備え、前記メモリハードウェアは、前記データ処理ハードウェア上で実行されると、前記データ処理ハードウェアに以下の動作を実行させる命令を記憶し、
前記動作は、
分散記憶システムの第１の記憶場所および前記分散記憶システムの第２の記憶場所に記憶するための一組のデータブロックを受信することを含み、前記第１の記憶場所は、第１の地理的領域に関連付けられ、前記第２の記憶場所は、前記第１の地理的領域とは異なる第２の地理的領域に関連付けられ、
前記一組のデータブロックを前記第１の記憶場所および前記第２の記憶場所に同期的に書き込むことと、
前記一組のデータブロックを前記第１の記憶場所および前記第２の記憶場所に同期的に書き込んでいる間に、前記第２の記憶場所への前記一組のデータブロックのさらなる書き込みを妨害する前記第２の記憶場所の回復不能失敗を判断することと、
前記一組のデータブロックを書き込むときの失敗点を判断することとを含み、前記失敗点は、前記第２の記憶場所に正常に書き込まれたデータブロックと前記第２の記憶場所に正常に書き込まれなかったデータブロックとの境界を示し、
前記失敗点から開始して、前記一組のデータブロックを前記分散記憶システムの前記第１の記憶場所および第３の記憶場所に同期的に書き込むことを含み、前記第３の記憶場所は、前記第１の地理的領域および前記第２の地理的領域とは異なる第３の地理的領域に関連付けられ、
前記一組のデータブロックの開始点から前記失敗点までの前記一組のデータブロックを前記第３の記憶場所に非同期的に書き込むことを含む、システム。 A system,
data processing hardware;
memory hardware in communication with the data processing hardware, the memory hardware storing instructions that, when executed on the data processing hardware, cause the data processing hardware to perform the following operations;
The said operation is
receiving a set of data blocks for storage in a first storage location of a distributed storage system and a second storage location of the distributed storage system, the first storage location being located in a first geographic location; associated with a region, the second storage location being associated with a second geographical region different from the first geographical region;
synchronously writing the set of data blocks to the first memory location and the second memory location;
Preventing further writing of the set of data blocks to the second memory location while synchronously writing the set of data blocks to the first memory location and the second memory location. determining an irrecoverable failure of the second storage location;
determining a failure point when writing the set of data blocks, the failure point being a data block successfully written to the second storage location and a data block successfully written to the second storage location. indicates the boundary with the data block that was not
starting from the point of failure, synchronously writing the set of data blocks to the first storage location and a third storage location of the distributed storage system, the third storage location being associated with a third geographical region different from the first geographical region and the second geographical region ;
The system includes asynchronously writing the set of data blocks from a starting point of the set of data blocks to the point of failure to the third storage location .
前記一組のデータブロックを前記第２の記憶場所に書き込む失敗を判断することと、
前記一組のデータブロックを前記第２の記憶場所に書き込む失敗の判断に応答して、前記一組のデータブロックを前記第２の記憶場所に書き込むことを再試行することと、
前記一組のデータブロックを前記第２の記憶場所に書き込むことを再試行することが失敗した場合、前記失敗が回復不能失敗であると判断することとを含む、請求項１０に記載のシステム。 determining the irrecoverable failure of the second storage location that prevents further writing of the set of data blocks to the second storage location;
determining a failure to write the set of data blocks to the second memory location;
retrying writing the set of data blocks to the second memory location in response to a determination of failure to write the set of data blocks to the second memory location;
and determining that the failure is an irrecoverable failure if retrying writing the set of data blocks to the second storage location fails.
前記第１の記憶場所に正常にコミットされた前記データブロックを示す第１の複製ログが利用可能であるか否かを判断することと、
前記第２の記憶場所に正常にコミットされた前記データブロックを示す第２の複製ログが利用可能であるか否かを判断することと、
前記第１の複製ログおよび前記第２の複製ログが利用可能である場合、前記第１の複製ログの長さおよび前記第２の複製ログの長さに基づいて、前記第１の複製ログと前記第２の複製ログとを照合することとを含む、請求項１０または１１に記載のシステム。 Determining the point of failure when writing the set of data blocks comprises:
determining whether a first replication log indicating the data blocks successfully committed to the first storage location is available;
determining whether a second replication log is available indicating the data blocks successfully committed to the second storage location;
If the first replicated log and the second replicated log are available, the length of the first replicated log and the second replicated log are determined based on the length of the first replicated log and the length of the second replicated log. The system according to claim 10 or 11 , comprising comparing the second replication log with the second replication log.
前記回復不能失敗に関連する前記第２の複製ログのインデックスを決定することと、
前記第２の複製ログの前記インデックスを、前記データ処理ハードウェアと通信するメモリハードウェアに記憶することと、
前記第２の記憶場所へのさらなる書き込みを禁止するように前記第２の複製ログを終了させることと、
照合する必要性を示すセンチネルファイルを生成することとを含む、請求項１２に記載のシステム。 Collating the first replication log and the second replication log includes:
determining an index of the second replication log associated with the unrecoverable failure;
storing the index of the second replication log in memory hardware in communication with the data processing hardware;
terminating the second replication log to inhibit further writes to the second storage location;
and generating a sentinel file indicating a need for matching.
各データブロックを前記第１の記憶場所に書き込む時間を示すタイムスタンプを含む第１の複製ログを生成することと、
各データブロックを前記第２の記憶場所に書き込む時間を示すタイムスタンプを含む第２の複製ログを生成することををさらに含む、請求項１０から１５のいずれか一項に記載のシステム。 The said operation is
generating a first replication log including a timestamp indicating the time to write each data block to the first storage location;
16. The system of any one of claims 10 to 15 , further comprising generating a second replication log including a timestamp indicating the time to write each data block to the second storage location.
前記第１の記憶場所に記憶された複数のデータブロックの返却を要求するクエリ要求を受信することと、
前記第１の複製ログの長さおよび前記第２の複製ログの長さに基づいて、前記第１の複製ログと前記第２の複製ログとを照合することと、
前記第１の複製ログおよび前記第２の複製ログの前記照合に基づいて、要求された前記複数のデータブロックを返すこととをさらに含む、請求項１６に記載のシステム。 The said operation is
receiving a query request requesting return of a plurality of data blocks stored in the first storage location;
collating the first replication log and the second replication log based on the length of the first replication log and the length of the second replication log;
17. The system of claim 16 , further comprising: returning the requested plurality of data blocks based on the matching of the first replication log and the second replication log.
前記第２の複製ログの前記長さが利用できないと判断することと、
後続の書き込みが閾値期間内に前記第１の複製ログに追加されると判断することとを含む、請求項１７に記載のシステム。 Collating the first replication log and the second replication log includes:
determining that the length of the second replication log is unavailable;
and determining that subsequent writes are added to the first replication log within a threshold period.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US17/098,306 US11579778B2 (en) | 2020-11-13 | 2020-11-13 | Synchronous replication of high throughput streaming data |
US17/098,306 | 2020-11-13 | ||
PCT/US2021/058841 WO2022103880A1 (en) | 2020-11-13 | 2021-11-10 | Synchronous replication of high throughput streaming data |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2023547949A JP2023547949A (en) | 2023-11-14 |
JP7394265B2 true JP7394265B2 (en) | 2023-12-07 |
Family
ID=78827931
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2023528455A Active JP7394265B2 (en) | 2020-11-13 | 2021-11-10 | Synchronous replication of high-throughput streaming data |
Country Status (6)
Country | Link |
---|---|
US (2) | US11579778B2 (en) |
EP (1) | EP4244723A1 (en) |
JP (1) | JP7394265B2 (en) |
KR (1) | KR20230098348A (en) |
CN (1) | CN116529714A (en) |
WO (1) | WO2022103880A1 (en) |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2014130475A (en) | 2012-12-28 | 2014-07-10 | Fujitsu Ltd | Library device, control method and program |
US10452680B1 (en) | 2015-09-25 | 2019-10-22 | Amazon Technologies, Inc. | Catch-up replication with log peer |
US20200389546A1 (en) | 2019-06-05 | 2020-12-10 | Microsoft Technology Licensing, Llc | State replication, allocation and failover in stream processing |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7467168B2 (en) * | 2003-06-18 | 2008-12-16 | International Business Machines Corporation | Method for mirroring data at storage locations |
US7617369B1 (en) | 2003-06-30 | 2009-11-10 | Symantec Operating Corporation | Fast failover with multiple secondary nodes |
US8185663B2 (en) | 2004-05-11 | 2012-05-22 | Hewlett-Packard Development Company, L.P. | Mirroring storage interface |
US20060182050A1 (en) | 2005-01-28 | 2006-08-17 | Hewlett-Packard Development Company, L.P. | Storage replication system with data tracking |
US7818522B2 (en) * | 2007-09-07 | 2010-10-19 | International Business Machines Corporation | Apparatus, system, and method for incremental resynchronization in a data storage system |
US11409711B2 (en) * | 2019-12-03 | 2022-08-09 | Western Digital Technologies, Inc. | Barriers for dependent operations among sharded data stores |
US11221785B2 (en) * | 2019-12-03 | 2022-01-11 | Western Digital Technologies, Inc. | Managing replication state for deleted objects |
-
2020
- 2020-11-13 US US17/098,306 patent/US11579778B2/en active Active
-
2021
- 2021-11-10 WO PCT/US2021/058841 patent/WO2022103880A1/en active Application Filing
- 2021-11-10 JP JP2023528455A patent/JP7394265B2/en active Active
- 2021-11-10 EP EP21823416.9A patent/EP4244723A1/en active Pending
- 2021-11-10 CN CN202180080718.4A patent/CN116529714A/en active Pending
- 2021-11-10 KR KR1020237019450A patent/KR20230098348A/en unknown
-
2023
- 2023-02-09 US US18/166,834 patent/US20230195331A1/en active Pending
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2014130475A (en) | 2012-12-28 | 2014-07-10 | Fujitsu Ltd | Library device, control method and program |
US10452680B1 (en) | 2015-09-25 | 2019-10-22 | Amazon Technologies, Inc. | Catch-up replication with log peer |
US20200389546A1 (en) | 2019-06-05 | 2020-12-10 | Microsoft Technology Licensing, Llc | State replication, allocation and failover in stream processing |
Also Published As
Publication number | Publication date |
---|---|
US20220155972A1 (en) | 2022-05-19 |
CN116529714A (en) | 2023-08-01 |
EP4244723A1 (en) | 2023-09-20 |
US11579778B2 (en) | 2023-02-14 |
WO2022103880A1 (en) | 2022-05-19 |
US20230195331A1 (en) | 2023-06-22 |
KR20230098348A (en) | 2023-07-03 |
JP2023547949A (en) | 2023-11-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11836155B2 (en) | File system operation handling during cutover and steady state | |
US9582382B1 (en) | Snapshot hardening | |
US10191677B1 (en) | Asynchronous splitting | |
US9557925B1 (en) | Thin replication | |
US9563684B1 (en) | Replication cookie | |
US10067694B1 (en) | Replication ordering | |
US9256605B1 (en) | Reading and writing to an unexposed device | |
US9740572B1 (en) | Replication of xcopy command | |
US8769336B1 (en) | Method and apparatus for preventing journal loss on failover in symmetric continuous data protection replication | |
US9003138B1 (en) | Read signature command | |
US8600945B1 (en) | Continuous data replication | |
US10083093B1 (en) | Consistent replication in a geographically disperse active environment | |
US10042579B1 (en) | Crash consistent snapshot | |
US8060714B1 (en) | Initializing volumes in a replication system | |
US8898112B1 (en) | Write signature command | |
US9740573B1 (en) | Dynamic LUN resizing in a replication environment | |
US8464101B1 (en) | CAS command network replication | |
US9535801B1 (en) | Xcopy in journal based replication | |
US8738813B1 (en) | Method and apparatus for round trip synchronous replication using SCSI reads | |
US8271441B1 (en) | Virtualized CG | |
US8806161B1 (en) | Mirroring splitter meta data | |
US8028192B1 (en) | Method and system for rapid failback of a computer system in a disaster recovery environment | |
US10223007B1 (en) | Predicting IO | |
US7610318B2 (en) | Autonomic infrastructure enablement for point in time copy consistency | |
US9639295B1 (en) | Method and apparatus for reducing splitter latency using parallel splitting |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20230807 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20230807 |
|
A871 | Explanation of circumstances concerning accelerated examination |
Free format text: JAPANESE INTERMEDIATE CODE: A871Effective date: 20230807 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20231031 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20231127 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7394265Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |