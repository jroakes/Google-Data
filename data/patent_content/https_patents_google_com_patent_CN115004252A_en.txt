CN115004252A - Image authenticity verification using decoding neural networks - Google Patents
Image authenticity verification using decoding neural networks Download PDFInfo
- Publication number
- CN115004252A CN115004252A CN202080094561.6A CN202080094561A CN115004252A CN 115004252 A CN115004252 A CN 115004252A CN 202080094561 A CN202080094561 A CN 202080094561A CN 115004252 A CN115004252 A CN 115004252A
- Authority
- CN
- China
- Prior art keywords
- image
- neural network
- output
- loss
- training
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/95—Pattern authentication; Markers therefor; Forgery detection
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/80—Recognising image objects characterised by unique random patterns
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/24—Classification techniques
- G06F18/241—Classification techniques relating to the classification model, e.g. parametric or non-parametric approaches
- G06F18/2413—Classification techniques relating to the classification model, e.g. parametric or non-parametric approaches based on distances to training or reference patterns
- G06F18/24133—Distances to prototypes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/764—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using classification, e.g. of video objects
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/77—Processing image or video features in feature spaces; using data integration or data reduction, e.g. principal component analysis [PCA] or independent component analysis [ICA] or self-organising maps [SOM]; Blind source separation
- G06V10/771—Feature selection, e.g. selecting representative features from a multi-dimensional feature space
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/77—Processing image or video features in feature spaces; using data integration or data reduction, e.g. principal component analysis [PCA] or independent component analysis [ICA] or self-organising maps [SOM]; Blind source separation
- G06V10/774—Generating sets of training patterns; Bootstrap methods, e.g. bagging or boosting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/82—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using neural networks
Abstract
This document describes techniques and apparatuses for verifying image authenticity. In various aspects, a method comprises: receiving, by a decoder system (220), an image (210) to be authenticated; performing feature recognition on the received image to determine determined features of the received image (238); generating a first output (236) defining a value representative of the determined characteristic; decoding the received image through a message decoding neural network (252) to extract a signature (254) embedded in the received image, the embedded signature representing recovered features (258) of the received image; generating a second output (256) defining values representative of the recovered features; providing a first output and a second output to a steering detection neural network (272); and generating an estimate of the authenticity of the received image using at least the first output and the second output by manipulating the detection neural network.
Description
Background
With artificial neural networks and computational processes, images can be fraudulently altered to contain information that was not present when the image was originally created, thereby creating a manipulated or "false" image. For example, deep learning forgery ("deep forgery") can be created by using an artificial neural network, wherein a video of a person making a first statement is modified to show that the person made a second, different statement. In another example, a "face exchange" application may be used to exchange a first person's face with a second person's face on a still image.
Various methods of detecting a pseudo image have been created. For example, algorithms may be used to detect subtle inconsistencies (e.g., illumination patterns) in the image that indicate tampering. Although these methods have been created, reliable detection of the pseudo-image has proven to be a challenging and difficult problem. A new framework is needed to verify the authenticity of images to address the limitations of the prior art.
Disclosure of Invention
Techniques and apparatus for verifying authenticity of an image are described. In particular, the techniques and apparatus may include or otherwise utilize one or more machine learning models to verify the authenticity of received images to detect manipulation of the images. The verification is based on comparing the detected image features with the restored image features to determine whether the image is counterfeit or manipulated. A comparison of the detected features and the recovered features may be used to identify features indicative of an unrealistic image that may not be detected by a human observer.
In some embodiments, a feature extraction process is used to extract determined features from the input image, and a message embedding process is used to embed a signature including the determined features into the input image to generate the output image. The feature extraction process is used to extract an embedded signature containing features from the received image and to recover the features from the signature. The authenticity of the image is then verified using an authenticity process, for example, by comparing the determined features with the recovered features.
Aspects described below include a method performed by a system that includes an encoder system and a decoder system. In the method, a system (e.g., a decoder system) receives an image to be authenticated. The system performs feature recognition on the received image to determine a plurality of determined features of the received image. The system generates a first output defining values representative of the determined characteristics of the received image. The system includes a message decoding neural network that decodes a received image to extract a signature embedded in the received image. The embedded signature represents a recovered characteristic of the received image. The system generates a second output that defines a value representing the recovered feature. The system provides a first output and a second output to a steering detection neural network. The steering detection neural network generates an estimate of the authenticity of the received image using at least the first output and the second output.
Aspects described below also include a computing device having a processor and a computer-readable storage medium having stored thereon instructions that, in response to execution by the processor, cause the processor to perform a process for verifying authenticity of an image. Aspects described below include methods of generating images and methods of verifying authenticity of images. Optional features of one aspect (such as the method described above) may be combined with other aspects.
Drawings
Techniques and apparatus for verifying image authenticity using a machine learning model are described with reference to the following figures. The same numbers are used throughout the drawings to reference like features and components:
FIG. 1 illustrates an environment in which techniques and apparatus for verifying image authenticity using machine learning models may be implemented;
FIG. 2 illustrates another environment in which techniques and apparatus for verifying image authenticity using machine learning models may be implemented;
FIG. 3 depicts a block diagram of an example user computing system, an example server computing system, and an example training computing system, according to some embodiments of the present disclosure;
FIG. 4 illustrates an example system for training a feature extraction neural network to extract features from an image;
FIG. 5 illustrates an example system for training a message codec neural network to encode/decode images;
FIG. 6 illustrates a method of generating an image to be authenticated;
FIG. 7 illustrates a method of verifying authenticity of an image; and
fig. 8 illustrates a block diagram of an example machine learning model, according to an example embodiment of the present disclosure.
Detailed Description
SUMMARY
As described above, the present disclosure relates to techniques and apparatuses for verifying authenticity of an image. In particular, the systems and methods of the present disclosure may include or utilize one or more machine learning models to verify the authenticity of an image.
As used herein, the phrase "image" includes, but is not limited to, still images, moving images (e.g., video), moving images associated with audio, moving images associated with text, and the like. As used herein, the phrase "video" refers to a series or time-series of moving images, which may or may not be associated with other types of information, such as audio or text. For example, a video may comprise a time series of moving images containing streams of audio information. As used herein, the phrase "pseudo-image" refers to an image that is presented as an original image, but is a manipulated copy of the original image, or is a pseudo-copy of the original image. As used herein, the phrase "image features" includes, but is not limited to, image-independent measurement matrices, facial expressions, landmarks, facial landmarks of a person in the image, landmarks, key points, user-provided features, edges, corners, blogs, ridges, motions, optical flow, raw pixels of the image, and the like, of the entire image.
As used herein, a phrase referring to "at least one of" a series of items refers to any combination of those items, including a single member. For example, "at least one of a, b, or c" is intended to encompass a, b, c, a-b, a-c, b-c, and a-b-c, as well as any combination of multiple identical elements (e.g., a-a-a, a-a-b, a-a-c, a-b-b, a-c-c, b-b-b, b-b-c, c-c, and c-c-c, or any other order of a, b, and c).
Fig. 1 shows an example system 100 that uses a feature recognition engine 120 (e.g., a feature extraction neural network 122) configured to extract image features from an input image 102 and a message encoder 140 (e.g., a message encoding neural network 142) configured to generate an output image 150 from the input image 102.
Fig. 2 illustrates an example system 200 that uses a feature recognition engine 230 (e.g., a feature extraction neural network 232) configured to extract features 238 from a received image 210, a message decoder 250 configured to extract a signature 254 (hidden message) including features 258 from the received image 210, and/or an authenticity engine 270 (e.g., a manipulation detection neural network 272) configured to verify the authenticity of the received image 210 based on processing of the received image 210. In aspects, the system may include one or both of the encoder system 110 of fig. 1 configured to generate an output image and the decoder system 220 of fig. 2 configured to decode a received image and determine the authenticity of the received image. At least one of system 100, components of system 100, system 200, or components of system 200 may be implemented on one or more of a user computing device, an embedded computing device, a server computing device, a model processing device, a training device, a virtual computing device, other computing devices, or a computing infrastructure, or a combination thereof, such as described below with reference to fig. 3.
As shown in fig. 1, in the system 100, an encoder system 110 receives an input image 102 as input for processing. For example, a user may submit an image (e.g., a photograph) to the system 100 as the input image 102. In another example, the user may capture the input image 102 on an imaging device (e.g., a digital camera, a camera of a computing device), and the encoder system 110 is implemented in an image pipeline of the imaging device. In another example, the input images 102 may be stored in the image library 104 and provided to the encoder system 110. The image repository 104 may be included in the system 100 (e.g., via one or more local wired or wireless connections), or may be remote from the system 100 and in communication with the system 100 via one or more wired or wireless connections (e.g., a Local Area Network (LAN) or Wide Area Network (WAN) connection). The image library 104 may be, for example, a database stored locally on the system 100, a database located at a server remote from the system 100, or a memory device implemented on a computing device.
The system 100 (e.g., the encoder system 110) receives an input image 102, selects one or more features 128 of the input image 102, generates one or more signatures 144 based on the selected features 128, and embeds the signatures 144 in the input image 102 to create an output image 150. In some aspects, the output image 150 may be stored on a memory device.
The system 100 (e.g., encoder system 110) includes a feature recognition engine 120. The feature recognition engine 120 is configured to perform a feature extraction process on the input image 102 to determine a plurality of determined features 128 of the input image 102. For example, the feature recognition engine 120 may be configured to select a plurality of features from the input image 102 and process the selected image features 128 to generate an output 126 (e.g., data), the output 126 defining values representative of the determined features of the input image. In some aspects, the feature recognition engine 120 selects a plurality of features from the input image 102 and processes the selected image features 128 to generate outputs 126, each output 126 representing a selected feature 128 of the input image 102. For example, the features 128 of the input image 102 may include image-independent measurement matrices, facial expressions, facial landmarks of people in the image, landmarks, keypoints, user-provided features, edges, corners, blogs, ridges, motions, optical flow, original pixels of the image, and so forth.
The feature recognition engine 120 may include a feature extraction neural network 122. The feature extraction neural network 122 may be configured to receive the input image 102 and process the input image 102 to generate an output 126, the output 126 defining values of a selected feature 128 representing the input image 102. In some aspects, the values each represent a selected feature 128 of the input image 102. For example, the feature extraction neural network 122 may receive the input image 102 and process the input image 102 or a portion thereof to generate an output 126, the output 126 defining values representing one or more image features corresponding to facial expressions, landmarks, keypoints, edges, corners, blogs, ridges, and the like. In some aspects, the output 126 defines values, each value representing one or more image features corresponding to a facial expression, landmark, keypoint, edge, corner, blog, ridge, or the like. In other embodiments, the feature recognition engine 120 may generate image features by using other feature extraction techniques and algorithms that do not rely on neural networks, such as principal component analysis, edge detection, hough transform, or other algorithms.
The feature recognition engine 120 may receive one or more user-provided features 124 provided by one or more user input components configured to receive input (selected image features) from a user. The user-provided features 124 may include facial expressions, facial markers of a person in the image, original pixels of the image, and so forth. The feature recognition engine 120 may include a feature extraction neural network 122 and user-provided features 124.
The system 100 (e.g., encoder system 110) also performs a message embedding process on the input image 102. The system 100 sends an output 126 specifying image features 128 derived from the input image 102 to a message encoder 140. The message encoder 140 may include a message encoding neural network 142. The message encoding neural network 142 may be configured as a message encoding/decoding neural network (e.g., a message encoding/decoding neural network) for encoding and decoding messages. The message encoding neural network 142 of fig. 1 and the message decoding neural network 252 of fig. 2 are message encoding/decoding neural networks.
A message encoder 140 (e.g., a message encoding neural network 142) receives an output 126 specifying image features 128 derived from an input image 102 from the system 100 and generates a signature 144 (e.g., including the output 126) representative of the image features 128 of the input image 102. A message encoder 140 (e.g., a message encoding neural network 142) processes the input image 102 by embedding a signature 144 (message) as a digital message (e.g., steganographic signal) into the input image 102 to generate an output image 150. In some aspects, the signature 144 is a perceptually invisible watermark.
The weights may be shared between the feature recognition engine 120 (e.g., the first feature extraction neural network 122, the user-provided features 124) shown in fig. 1 and the second feature recognition engine 230 (e.g., the second feature extraction neural network 232, the user-provided features 234) shown in fig. 2.
Fig. 2 shows a system 200 that includes a decoder system 220, the decoder system 220 being configured to decode a received image 210 and verify the authenticity of the received image 210. The received image 210 is an image to be authenticated. In some aspects, the received image 210 is a copy of the output image 150. In some aspects, the received image 210 is a pseudo-copy of the input image 102 or the output image 150. In some aspects, the received image 210 is a manipulated copy of the input image 102 or the output image 150. The decoder system 220 determines the authenticity of the received image 210, e.g., whether the received image 210 is an output image 150 or whether the received image 210 is a counterfeit version of the input image 102.
The system 100 may send the output image 150 generated by the encoder system 110 to the decoder system 220 as a received image 210. In some embodiments, the received image 210 is provided to a decoder system 220 of the system 200; for example, a user may submit a photograph to the system 200 as the received image 210.
In another example, the received image 210 may be provided to the decoder system 220 by an image library (such as the image library 104 of fig. 1).
In one example, a user utilizes system 100 and/or system 200 to verify the authenticity of an image. In another example, an online service provider utilizes system 100 and/or system 200 to verify the authenticity of an image. In another example, a third party utilizes system 100 and/or system 200 to verify the authenticity of an image.
The system 200 provides the received image 210 as input to a decoder system 220, and the decoder system 220 determines whether the received image 210 is a reliable copy (e.g., a true copy, an unaltered copy) or whether the received image 210 is an unreliable copy, such as a dummy image or altered copy of the output image 150 or the input image 102. As shown in fig. 2, system 200 (e.g., decoder system 220) includes a feature recognition engine 230, a message decoder 250, and an authenticity engine 270.
The system 200 may provide the received image 210 as input to a feature recognition engine 230. The feature recognition engine 230 is configured to perform a feature extraction process (feature recognition) on the received image 210 to determine a plurality of determined features 238 of the received image 210. For example, the determined features 238 of the received image 210 may include image-independent measurement matrices, facial expressions, landmarks, keypoints, user-provided features, edges, corners, blogs, ridges, motion, optical flow, pixels, and so forth.
The feature recognition engine 230 selects a plurality of determined features 238 from the received image 210 and processes the determined features 238 to generate an output 236 (data), the output 236 defining values representative of the determined features of the received image 210. In aspects, the feature recognition engine 230 selects a plurality of determined features 238 from the received image 210 and processes the determined features 238 to generate an output 236 (data), the output 236 defining values representing the determined features of the received image, each determined feature representing a selected feature of the received image 210. The system 200 sends the output 236 of the determined characteristic 238 to the veracity engine 270.
The feature recognition engine 230 may include a second feature extraction neural network 232. Feature extraction neural network 232 performs a feature extraction process on received image 210. The feature extraction neural network 232 may be configured to receive the received image 210 and process the received image 210 to generate an output 236 (data), the output 236 defining values representative of the determined features 238 of the received image 210. For example, the feature extraction neural network 232 may be configured to receive the received image 210 and process the received image 210 to generate an output 236, the output 236 defining values that each represent a determined feature 238 of the received image 210. In some embodiments, the feature extraction neural network 232 is the same neural network as the feature extraction neural network 122 of fig. 1. In some embodiments, the feature extraction neural network 232 is a different feature extraction neural network than the feature extraction neural network 122 of fig. 1.
The feature recognition engine 230 may receive input including one or more user-provided features 234 provided by one or more user input components (e.g., the user input component 322 of fig. 3) configured to receive input (selected image features) from a user. The user-provided features 234 may include, for example, facial expressions, facial markers of a person in an image, original pixels of an image, and so forth. In some implementations, the feature recognition engine 230 can include a second feature extraction neural network 232 and user-provided features 234.
The received image 210 may be provided as input to a message decoder 250 of the decoder system 220. Message decoder 250 (e.g., message decoding neural network 252) decodes received image 210. For example, the message decoder 250 decodes the received image 210 by performing a message extraction process on the received image 210. In the message extraction process, the message decoder 250 processes the received image 210 to extract the signature 254 embedded in the received image 210. The signature 254 represents a recovered feature 258 embedded in the received image 210 by a message encoder (e.g., the message encoder 140 of fig. 1). In some aspects, the system 200 detects whether a signature is present in the received image 210.
The message extraction process includes the generation of a second output 256 (data), the second output 256 defining values of a recovered feature 258 representing the received image 210. In aspects, the message extraction process includes generating a second output 256, the second output 256 defining values of recovered features 258 each representing a received image 210 recovered from the signature 254. The system 200 sends the output 256 of the recovered features 258 to the veracity engine 270.
The output 236 (first output) from the feature recognition engine 230 and the output 256 (second output) of the message decoder 250 are provided to the veracity engine 270 and used by the veracity engine 270 to generate a prediction (e.g., estimate) of the veracity of the received image 210. For example, the authenticity engine 270 of the decoder system 220 determines whether the received image 210 is a reliable copy (e.g., a true copy, an unaltered copy), or whether the received image 210 is an unreliable copy, e.g., a dummy image or an altered copy.
The veracity engine 270 may include a steering detection neural network 272 that receives outputs (e.g., output 236, output 256). For example, by comparing output 236 and output 256, steering detection neural network 272 uses at least output 236 and output 256 to generate an estimate (prediction) of the authenticity of received image 210. Based on the estimates generated by the authenticity engine 270, the system 100 determines whether the received image 210 is a reliable copy (e.g., a true copy, an unaltered copy), or whether the received image 210 is an unreliable copy, e.g., a dummy image or an altered copy.
Example embodiments
The systems and methods of the present disclosure may be implemented by or executed on one or more computing systems. Example ones of computing systems 300 include one or more user computing devices (e.g., laptops, desktops, mobile computing devices such as tablets, smartphones, wearable computing devices, cameras, etc.); embedded computing devices (e.g., devices embedded within vehicles, cameras, image sensors, industrial machines, satellites, game consoles or controllers, or household appliances such as refrigerators, thermostats, electricity meters, home energy managers, smart home assistants, etc.); server computing devices (e.g., database servers, parameter servers, file servers, mail servers, print servers, web servers, game servers, application servers, etc.); dedicated, specialized model processing or training equipment; a virtual computing device; other computing devices or computing infrastructures; or a combination thereof.
For example, fig. 3 depicts a block diagram of an example computing system 300 that may verify image authenticity in accordance with an example embodiment of the present disclosure. Computing system 300 includes one or more user computing systems 302, server computing system 330, or training computing system 350 communicatively coupled via network 380.
The server computing system 330 may include, or be implemented by, one or more server computing devices. Where server computing system 330 includes multiple server computing devices, such server computing devices may operate according to a sequential computing architecture, a parallel computing architecture, or some combination thereof. In some embodiments, training computing system 350 includes, or is implemented by, one or more server computing devices.
The user computing system 302 includes one or more processors 312 and one or more memory devices 314. The server computing system 330 includes one or more processors 332 and memory devices 334. Training computing system 350 includes one or more processors 352 and memory device 354. The processors 312, 332, 352 may be any suitable processing device (e.g., a Central Processing Unit (CPU), a Visual Processing Unit (VPU), a Graphics Processing Unit (GPU), a Tensor Processing Unit (TPU), a Neural Processing Unit (NPU), a neural processing engine, a core of a CPU, VPU, GPU, TPU, NPU, or other processing device, an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), a coprocessor, a controller, or a combination of the above) and may be one processor or a plurality of processors operatively connected. The processors 312, 332, 352 may be embedded in other hardware components, such as, for example, image sensors, accelerometers, and so forth.
The memory devices 314, 334, 354 may include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, a disk, and the like, as well as combinations thereof. The memory device 314 may store data 316 and instructions 318 that are executed by the processor 312 to cause the user computing system 302 to perform operations. The memory device 334 may store data 336 and instructions 338 that are executed by the processor 332 to cause the server computing system 330 to perform operations. Memory device 354 may store data 356 and instructions 358 that are executed by processor 352 to cause training computing system 350 to perform operations.
One or more of the user computing system 302, the server computing system 330, or the training computing system 350 may include an encoder system (e.g., the encoder system 110 of fig. 1). An example encoder system may include a feature recognition engine (e.g., feature recognition engine 120 of fig. 1) and a message encoder (e.g., message encoder 140 of fig. 1). In some implementations, one or more of the user computing system 302, the server computing system 330, or the training computing system 350 can include a decoder system (e.g., the decoder system 220 of fig. 2). The example decoder system may include at least one of a feature recognition engine (e.g., feature recognition engine 230 of fig. 2), a message decoder (e.g., message decoder 250 of fig. 2), or an authenticity engine (e.g., authenticity engine 270 of fig. 2).
The user computing system 302 may store or include one or more machine learning models 320. For example, the machine learning model 320 may be or may otherwise include various machine learning models, such as a neural network (e.g., a deep neural network) or other types of machine learning models, including non-linear models and/or linear models. The neural network may include a feed-forward neural network, a recurrent neural network (e.g., a long-short term memory recurrent neural network), a convolutional neural network, or other form of neural network. More specifically, the machine learning model 320 may include one or more feature extraction networks (such as the feature extraction neural network 122 of fig. 1 and/or the second feature extraction neural network 232 of fig. 2), message encoding neural networks (such as the message encoding neural network 142 of fig. 1), message decoding neural networks (such as the message decoding neural network 252 of fig. 2), or manipulation detection neural networks (such as the manipulation detection neural network 272 of fig. 2).
Additionally or alternatively, one or more machine learning models 340 may be included in server computing system 330 in communication with user computing system 302 according to a client-server relationship, or stored and implemented by server computing system 330. For example, the machine learning model 340 may be implemented by the server computing system 340 as part of a web service (e.g., an extreme multi-class or multi-label classification service, a language modeling service, a metric learning service). Thus, one or more models 320 can be stored and implemented at the user computing system 302, and/or one or more models 340 can be stored and implemented at the server computing system 330. In an embodiment, the machine learning model 340 may include one or more feature extraction networks (such as the feature extraction neural network 122 of fig. 1 and/or the feature extraction neural network 232 of fig. 2), message encoding neural networks (such as the message encoding neural network 142 of fig. 1), message decoding neural networks (such as the message decoding neural network 252 of fig. 2), or manipulation detection neural networks (such as the manipulation detection neural network 272 of fig. 2).
The user computing system 302 may also include one or more user input components 322 that receive user input. For example, the user input component 322 may be a touch-sensitive component (e.g., a touch-sensitive display screen, a touchpad) that is sensitive to touch by a user input object (e.g., a finger, a stylus). The touch sensitive component may be used to implement a virtual keyboard. Other example user input components include a microphone, a conventional keyboard, or other components that a user may use to provide user input.
As described above, the server computing system 330 may store or otherwise include one or more machine learning models 340. For example, the model 340 may be or may include various machine learning models. Example machine learning models include neural networks or other multi-layered nonlinear models. Examples of neural networks include feed-forward neural networks, deep neural networks, recurrent neural networks, and convolutional neural networks.
The computing system 300 may include an image library 104. For example, the image library 104 may be included in the system 300 via one or more local wired or wireless connections, or may be remote from the system 300 and in communication with the system 300 via one or more wired or wireless connections, such as a Local Area Network (LAN) or Wide Area Network (WAN) connection. For example, the image library 104 may be a database stored locally on the user computing system 302, or a database located on a server remote from the system 300 (e.g., server computing system 330, training computing system 350).
The user computing system 302 and/or the server computing system 330 may train the models 320 and/or 340 via interaction with a training computing system 350 communicatively coupled via a network 380. The training computing system 350 may be separate from the server computing system 330 or may be part of the server computing system 330.
The model trainer 360 may train the machine learning models 320 and/or 340 based on a set of training data 362. Training data 362 may include, for example, examples of input data that has been assigned labels corresponding to output data.
If the user has provided consent, training examples may be provided by the user computing system 302. Thus, in such implementations, the model 320 provided to the user computing system 302 may be trained by the training computing system 350 based on user-specific data received from the user computing system 302. In some cases, this process may be referred to as a personalization model.
Model trainer 360 includes computer logic for providing the desired functionality. Model trainer 360 may be implemented in hardware, firmware, and/or software that controls a general purpose processor. For example, in some embodiments, model trainer 360 includes program files stored on a memory device, loaded into memory, and executed by one or more processors. In other embodiments, model trainer 360 includes one or more sets of computer-executable instructions stored in a tangible computer-readable storage medium, such as a RAM hard disk or an optical or magnetic medium.
FIG. 3 illustrates one example of a computing system 300 that may be used to implement the present disclosure. Other computing systems may also be used. For example, in some embodiments, user computing system 302 may include model trainer 360 and training data 362. In such an implementation, the model 320 may be trained and used locally at the user computing system 302. In some such implementations, user computing system 302 may implement model trainer 360 to personalize model 320 based on user-specific data.
Training
The framework described herein may be trained in a variety of ways, for example, depending on how the feature extraction neural network is trained, the message codec neural network (e.g., message encoding neural network, message decoding neural network, message encoding/decoding neural network), and/or the steering detection neural network. In some embodiments, one or more neural networks may be trained separately. In some embodiments, one or more neural networks are trained together. In other embodiments, all neural networks are trained together.
Fig. 4 depicts an example system 400 configured to train a first feature extraction neural network 422 (such as the first feature extraction neural network 122 of fig. 1 and/or the second feature extraction neural network 232 of fig. 2) to extract features from an image (e.g., input image 416) with improved accuracy. In some aspects, the feature extraction neural network 422 is used in a system configured to verify image authenticity (e.g., the system 100 of fig. 1, the system 200 of fig. 2).
The feature extraction neural network 422 may be trained separately from one or more message encoding neural networks, message decoding neural networks, or steering detection neural networks. For example, at operation 412, the input image 416 is provided to an encoder system 410 that includes a feature recognition engine 420 for processing. For example, a user may submit an image (e.g., a photograph) to the system 400 as the input image 416. In another example, the feature recognition engine 420 is a feature extraction neural network 422, and the image library 104 (as described with respect to fig. 2) provides the input images 416 to the feature recognition engine 420. In an embodiment, the feature recognition engine 462 may generate the determined features 418 by using other feature extraction techniques and algorithms that do not rely on neural networks, such as principal component analysis, edge detection, hough transform, or other algorithms.
The feature recognition engine 420 (e.g., feature extraction neural network 422) is configured to estimate (determine) features of the input image 416 and generate an output of the determined features 418 (such as features 128 of fig. 1). In some aspects, the feature extraction neural network 422 estimates the determined features 418, the determined features 418 having characteristics that can be identified as learned features through image recognition. The learned features should be sensitive to the detection of false images; for example, if the image is manipulated or is false, the learned features will be very different.
Alternatively or additionally, the determined features 418 may be extracted from the input image 416 by using user input, such as user-provided features 424 (e.g., user-provided features 124 described herein). In an embodiment, the second feature recognition engine 462 may generate the recovered features 466 by using other feature extraction techniques and algorithms that do not rely on neural networks, such as principal component analysis, edge detection, hough transform, or other algorithms.
After the determined features 418 are evaluated, the feature recognition engine 420 sends an output 430 of the determined features 418 to a discriminant feature loss computation engine 470. The determined features 418 are provided to a discriminative feature loss computation engine 470 to enable the discriminative feature loss computation engine 470 to compute feature losses 472 for training the feature extraction neural network 422. This process may be repeated until the calculated loss is equal to or below a predetermined threshold, or until other convergence criteria are met.
The feature recognition engine 420 may also send the output 426 with the determined features 418 to a message encoder 440, including a message encoding neural network 442 (e.g., the message encoding neural network 142 of fig. 1), to generate an output image 450. In some aspects, one or more signatures are generated based on the determined features 428 and embedded as a digital message (e.g., Steganographic signal) into the input image 416 to generate the output image 450. In an embodiment, the feature recognition engine 420 may generate the determined features 418 by using other feature extraction techniques and algorithms that do not rely on neural networks, such as principal component analysis, edge detection, hough transform, or other algorithms.
The feature extraction process is performed on the image (e.g., input image 416, received image 452) by a feature recognition engine (e.g., by a first feature extraction neural network 420 (e.g., first feature extraction neural network 422 (such as first feature extraction neural network 122 of fig. 1)) and/or by a second feature recognition engine 462 (e.g., second feature extraction neural network 464 (such as feature extraction neural network 232 of fig. 2)). For example, as shown in fig. 4, the decoder system 460 includes a second feature recognition engine 462 (e.g., a feature extraction neural network 464). The second feature recognition engine 462 decodes the received image 452 to extract a signature from the received image 452 (e.g., as described above with reference to fig. 2). The signature represents a recovered feature 466 of the received image 452.
The feature recognition engine (e.g., the second feature recognition engine 462) sends the output 468 with the recovered features 466 to the authenticated feature loss computation engine 470. The recovered features 466 are provided to enable the discriminative feature loss computation engine 470 to compute feature losses 472, which feature losses 472 may be used to train the feature extraction neural network 422.
The system may execute a message codec neural network training procedure in which the discriminative feature loss computation engine 470 applies a discriminative feature loss function to the recovered features 466 and the determined features 418 to determine an image feature loss 472 resulting from the estimation performed by the feature extraction neural network 422. The discriminative feature loss function compares the determined features 418 of the input image 416 (such as the selected features 128 of the input image 102 of fig. 1) with the restored features 466 of the received image 452 (such as the restored features 258 of the received image 210 of fig. 2). If the test image (e.g., received image 210 of fig. 2) is authentic (e.g., not a false copy of output image 450, not a manipulated copy of output image 450), then the discriminant feature loss function should be small. However, if the test image (e.g., received image 452) is not authentic (e.g., is a false copy of output image 450, is a manipulated copy of output image 450), then the discriminant feature loss function should be large.
The discriminative feature loss computation engine 470 sends the feature losses 472 as output to the feature recognition engine 420 for training the feature extraction neural network 422. The loss function determines the deviation between the determined features 418 estimated by the feature recognition engine 420 and the recovered features 466 generated by the second feature recognition engine 462. In some implementations, the loss function can represent the deviation as a loss in accuracy of the recovered feature 466 in the received image 452 due to the received image 452 being a dummy image.
After the losses are calculated, the feature losses 472 are used to further optimize the feature extraction neural network 422. For example, the feature loss 472 may be used to perform parameter optimization on the layers of the feature extraction neural network 422.
Such a training loop may be repeated for a plurality of images from the image library 104 to iteratively optimize the feature extraction neural network 422. Parameter optimization enables the feature extraction neural network 422 to more accurately estimate features depicted in the image. Over time, with sufficient training through iterations of the training loop, the feature extraction neural network 422 may refine to minimize the loss function such that the recovered features 466 provided by the second feature recognition engine 462 to the discriminative feature loss computation engine 470 converge to the determined features 418 provided by the first feature recognition engine 420 to the discriminative feature loss computation engine 470. The process shown in fig. 4 may be repeated until the feature loss is at or below a predetermined threshold, or until other convergence criteria are met.
Fig. 5 depicts an example system 500 configured to train a message codec neural network (e.g., a message encoding/decoding neural network). For example, a message encoding neural network (e.g., message encoding neural network 542 of fig. 5, message encoding neural network 142 of fig. 1) of message encoder 540 and/or a message decoding neural network (e.g., message decoding neural network 562 of fig. 5, message decoding neural network 252 of fig. 2) of message decoder 561 of decoder system 560 encodes output images and/or decodes received images with improved accuracy. In some aspects, at least one of the message encoding neural network or the message decoding neural network is trained separately from the feature extraction neural network and/or the steering detection neural network. In some aspects, a message codec neural network is trained with one or more feature extraction neural networks or steering detection neural networks.
At operation 504, the input image 502 is provided to a feature recognition engine 520 for processing. For example, as described above with reference to fig. 4, a user may submit an image (e.g., a photograph) to system 500 as input image 502. In an embodiment, the input image 502 is modified in order to train at least one message encoding neural network 542 to be robust to this type of distortion. For example, the input image 502 may be modified (e.g., edited, resized, cropped) or may be a pseudo image.
In another example, the feature recognition engine 520 includes a first feature extraction neural network 522 of the encoder system 510. The image library 104 (e.g., as described with respect to the image library 104 of fig. 4) provides the input image 502 to the feature recognition engine 520, as described with respect to fig. 4. The input image 502 is also provided to the image loss calculation engine 580 for processing at operation 506.
The feature recognition engine 520 (e.g., the feature extraction neural network 522) estimates (determines) features of the input image 502 and generates an output of the determined features 528. In some aspects, the feature extraction neural network 522 estimates determined features 528, the determined features 528 having characteristics that can be identified as learned features through image recognition. The learned features should be sensitive to the detection of false images; for example, if the image is manipulated or is false, the learned features will be very different. In some aspects, the user-provided features (such as the user-provided features 124 of fig. 1 and/or the user-provided features 234 of fig. 2) may be provided by the user to include the determined features 528.
Alternatively or additionally, the determined features 528 may be extracted from the input image 502 by using user-provided features, as described above with reference to fig. 4. In an embodiment, the feature recognition engine 520 may generate the determined features 528 by using other feature extraction techniques and algorithms that do not rely on neural networks, such as principal component analysis, edge detection, hough transform, or other algorithms.
After evaluating the determined features 528, the feature recognition engine 520 sends an output 530 (third output) of the determined features 528 to the feature loss computation engine 570. The determined features 528 are provided to a feature loss calculation engine 570 to enable the feature loss calculation engine 570 to calculate feature losses 572, which feature losses 572 are provided as inputs to an overall loss calculation engine 590.
The feature recognition engine 520 also sends the output 526 with the determined features 528 to a message encoding neural network 542 of a message encoder 540 (e.g., the message encoding neural network 142 of fig. 1) to generate an output image 550. In some aspects, one or more signatures 528 are generated based on the determined characteristics and embedded as a digital message (e.g., steganographic signal) into the output image 550 to generate the output image 550.
At operation 554, the received image 552 is sent to the image loss calculation engine 580 for processing. At operation 556, the received image 552 is sent to the decoder system 560. In some aspects, decoder system 560 includes a message decoder 561. In some aspects, the message decoder 561 includes a message decoding neural network 562. Message decoding neural network 562 (such as message decoding neural network 252 of fig. 2) decodes received image 552 to extract a signature from received image 552. The signature represents the recovered features 564 of the received image 552. In an embodiment, message decoding neural network 252 is a message encoding/decoding neural network configured to encode and decode images.
The message decoding neural network 562 is configured to send an output 563 (a second output) including the recovered features 564 to the feature loss computation engine 570. The recovered features 564 are provided to a feature loss calculation engine 570 to enable the feature loss calculation engine 570 to calculate feature losses 572 that are provided as inputs to an overall loss calculation engine 590.
The system 500 determines the feature loss 572. In an embodiment, the system 500 includes a characteristic loss calculation engine 570 that applies a loss function to determine a characteristic loss 572. The loss function determines the deviation between the determined features 528 estimated by the feature recognition engine 520 relative to the features in the input image 502 and the recovered features 564 extracted by the message decoding neural network 562 relative to the features in the received image 552. In some implementations, the loss function can represent the deviation as a loss in accuracy of the recovered features 564 in the received image 552 due to the received image 552 being a pseudo-image. After the penalty is computed, the characteristic penalty 572 is sent as an output (first penalty) to the total penalty computation engine 590. The feature losses 572 are provided to an overall loss calculation engine 590 to further optimize one or more of the feature extraction neural network 522, the message encoding neural network 542, the message decoding neural network 562, or the message encoding/decoding neural network (e.g., message encoding/decoding neural network).
The system 500 determines an image loss 582. In an embodiment, the system 500 includes an image loss calculation engine 580 that receives the input image 502 and the received image 552 and applies a loss function to determine image losses 582. The loss function determines the deviation between the input image 502 and the received image 552. In some implementations, the loss function can represent a deviation in the received image 552 that is the result of a dummy image or a manipulated image. After calculating the image loss 582, the image loss 582 is sent to the total loss calculation engine 590 and may be used to further optimize one or more of the feature extraction neural network 522, the message encoding neural network 542, or the message decoding neural network 562.
The system 500 determines an overall penalty 592 based on the image penalty 582 and the feature penalty 572. In some aspects, the system 500 includes an overall loss calculation engine 590 that applies a loss function to the feature loss 572 and the image loss 582 to determine an overall loss 592. The total loss 592 may be caused by an estimation performed by at least one of the first feature extraction neural network 522 or the message decoding neural network 562. The loss function determines the deviation between the feature loss 572 computed by the feature loss computation engine 570 and the image loss 582 computed by the image loss computation engine 580.
The total loss function to be optimized can be represented by the following equation:
L＝L il (I i ,I o )+L fl (f,f ii ) (1)
where the total loss is equal to the image loss function (input image, output image) plus the feature loss function (feature, feature recovered from the input image). In the equation, the total loss is L and the image loss function is L il The characteristic loss function is L fl The input image is I i The output image is I o The feature is f, and the feature recovered from the input image is f ii 。
After calculating the total loss, the calculated total loss 592 is used to further optimize at least one of the feature extraction neural network 522, the message decoding neural network 562, or the message codec neural network (e.g., message encoding/decoding neural network). For example, the calculated total loss 592 may be used for parameter optimization of one or more layers of the feature extraction neural network 522 or the message decoding neural network 562. The process illustrated in fig. 5 may be repeated until the calculated total loss is equal to or below the predetermined threshold, or until other convergence criteria are met. Such a training loop may be repeated for a plurality of images from the image library 104 to iteratively optimize one or more of the feature extraction neural network 522, the message encoding neural network 542, or the message decoding neural network 562. In an embodiment, parameter optimization enables feature extraction neural network 522 to more accurately estimate features depicted in an image. Over time, with sufficient training through iterations of the training loop, the feature extraction neural network 522 may improve such that the recovered features 536 provided to the feature loss computation engine 570 by the message decoding neural network 562 converge to the determined features 528 provided to the feature loss computation engine 570 by the feature extraction neural network 522.
In an embodiment, a manipulation detection neural network (e.g., the manipulation detection neural network 272 shown in fig. 2) is trained separately from one or more of a message encoding neural network (e.g., the message encoding neural network 142 of fig. 1), a message decoding neural network (e.g., the message decoding neural network 252 of fig. 2, the message decoding neural network 562 of fig. 5), or a feature extraction neural network (e.g., the feature extraction neural network 122 of fig. 1, the feature extraction neural network 232 of fig. 2, the feature extraction neural network 422 of fig. 4, the second feature extraction neural network 464 of fig. 4, the first feature extraction neural network 522 of fig. 5).
To train the steering detection neural network, values of at least one of the feature extraction neural network, the message encoding neural network, the feature extraction neural network, or the message decoding neural network are fixed, and a training image is generated. The training image may include at least one image manipulation. In some aspects, the input image may be a training image. In some aspects, the received image may be a training image.
The system sends the training image to the steering detection neural network. The manipulation detection neural network determines an image manipulation that is applied to the training image. The processing detects that the neural network calculates normal loss based on a normal loss function using image manipulation applied to the training images. In an embodiment, the normal penalty is a cross-entropy penalty. The steering detection neural network is trained based at least on the calculated normal loss. In some aspects, the applied loss function is a normal loss function for classification.
The feature extraction neural network may be co-trained with a message codec neural network (e.g., a message encoding/decoding neural network, one or more message encoding neural networks, or a message encoding/decoding neural network) to extract features from the image and/or to encode/decode messages in the image with improved accuracy. For example, by a combination of the above-described individual feature extraction neural network training and the above-described individual message encoding/decoding neural network training. The total loss function to be optimized can be represented by the following equation:
L＝L il (I i ,I o )+L fl (f,f ii )+L dfl (f,f ri ) (2)
where the total loss is equal to the image loss function (input image, output image) plus the feature loss function (feature, feature recovered from the input image) plus the discriminating feature loss function (feature, feature recovered from the received image). In this equation, the total loss is L and the image loss function is L il The characteristic loss function is L fl The input image is I i The output image is I o With the feature f, recovering from the input imageIs characterized in that ii The discriminant feature loss function is L dfl And the feature from the received image is f ri 。
The input image may be perceptually the same as the output image, and the features recovered from the input image are as close as possible to the features extracted (recovered) from the input image, even if there is some image manipulation (or forgery). In this case, the learned features may be features that are more easily hidden and extracted by the message-encoded neural network. Furthermore, the learned features may be sensitive to image manipulation (or forgery), and thus, if the image is changed (e.g., manipulated, forged), the extracted features will be completely different from the features extracted from the input image. In such an aspect, the steering detection neural network may be trained separately, as described above.
The feature extraction neural network may be co-trained with the manipulation detection neural network to extract features from the image and/or to determine with improved accuracy whether the received image is a counterfeit or manipulated version of the input image. In such an aspect, the message codec neural network (e.g., message codec neural network 142 of fig. 1 and message codec neural network 252 of fig. 2) may be trained first. To train a message codec neural network, image manipulation (or forgery) desired to be detected may be applied to random input images having random features.
The total loss function to be optimized can be represented by the following equation:
L＝L il (I i ,I o )+L fl (f ra ,f rr ) (3)
where the total loss is equal to the image loss function (input image, output image) plus the feature loss function (random feature, recovered random feature). In the equation, the total loss is L, and the image loss function is L il The characteristic loss function is L fl Random feature is F ra And the recovered random feature is f rr 。
The input image may be perceptually identical to the output image and the random features are recovered from the input image. The weights in the message codec neural network are then fixed and the feature extraction network and the steering detection neural network are trained together. Then, image manipulation or forgery desired to be detected may be randomly applied or not applied.
The total loss function to be optimized can be represented by the following equation:
L＝L dfl (f,f ri )+L ce (4)
where the total loss is equal to the discriminating characteristic loss function (characteristic, characteristic from the received image) plus the cross-entropy loss (false or true). In the equation, the total loss is L and the discriminant feature loss function is L dfl The feature from the received image is f ri The cross-entropy penalty (false or true) is L ce . With such a training procedure, the feature extraction neural network will learn the best features for detecting counterfeit or authentic images.
The message codec neural networks (e.g., message codec neural network 142 of fig. 1 and message codec neural network 252 of fig. 2) may be trained in conjunction with the manipulation detection neural network to encode/decode messages in images and/or to determine with improved accuracy whether a received image is a counterfeit or manipulated version of an input image. In this regard, as described above, the feature extraction neural networks are trained separately. After the feature extraction neural network is trained, the weights are fixed. To co-train the message codec neural network and the manipulation detection neural network, image manipulation or forgery desired to be detected is randomly applied or not applied. The total loss function to be optimized can be represented by the following equation:
L＝L il (I i ,I o )+L fl (f,f ii )+L ce (5)
where the total loss is equal to the image loss function (input image, output image) plus the feature loss function (feature, feature recovered from the input image) plus the cross-entropy loss (false or true). In the equation, the total loss is L and the image loss function is L il The characteristic loss function is L fl The input image is I i The output image is I o The feature is f, and the feature recovered from the input image is f ii The cross-entropy loss (spurious or true) is L ce . In all aspects, the inputThe incoming image may be perceptually the same as the output image, and the features recovered from the input image are as close as possible to the features extracted (recovered) from the input image, even if there is some image manipulation (or forgery).
The feature extraction neural network may be co-trained with a message codec neural network (e.g., a message encoding/decoding neural network, a message encoding neural network, and a message decoding neural network) and a manipulation detection neural network to extract features from an image with improved accuracy, encode/decode messages in the image, and/or determine whether a received image is a forged or manipulated version of an input image with improved accuracy.
Manipulations or falsifications that are desired to be detected may be applied randomly or not. The total loss function to be optimized can be represented by the following equation:
L＝L il (I i ,I o )+L fl (f,f ii )+L dfl (f,f ri )+L ce (6)
where the total loss is equal to the image loss function (input image, output image) plus the feature loss function (random feature, recovered random feature) plus the discriminating feature loss function (feature, feature from the received image) plus the cross-entropy loss (false or true). In the equation, the total loss is L and the image loss function is L il The characteristic loss function is L fl The random feature is F ra The recovered random feature is f rr The discriminant feature loss function is L dfl The feature from the received image is f ri The cross-entropy penalty (false or true) is L ce 。
In the case where the received image is a pseudo image, the discriminating feature loss function will penalize (penalize) case features, and features from the received image are close. In the case where the received image is true, the discriminating feature loss function will penalize the case feature, and the feature from the received image is far. It is desirable that the input image is perceptually identical to the output image. It is desirable that the message codec neural network be robust to image manipulation or forgery. It is desirable that the extracted features be sensitive to image manipulation or forgery.
While features and concepts of the described techniques and apparatus for verifying image authenticity may be implemented in any number of different environments, systems, devices, and/or various configurations, aspects of verifying image authenticity are described in the context of the following example devices, systems, and configurations.
For the cases where the techniques and/or apparatus discussed herein may collect personal information about a user or may make use of personal information, the user may be provided with an opportunity to control whether programs or features collect personal information, such as information about the user's social network, social actions or activities, profession, preferences, or current location, or whether and/or how the systems and/or methods may perform operations more relevant to the user. In addition, certain data may be anonymized in one or more ways before it is stored or used, thereby deleting the personal identity information. For example, the identity of the user may be anonymized so that personally identifiable information of the user cannot be determined, or the geographic location of the user may be generalized to a location from which location information is obtained, such as at a city, zip code, or state level, so that a particular location of the user cannot be determined. Thus, users can control how information about them is collected and used.
Method
FIG. 6 illustrates an example method 600 of generating an image to be verified. Method 600 may be performed by system 100 as described above with reference to fig. 1, using one or more components described with reference to fig. 1. At 602, an encoder system receives an input image. At 604, the encoder system performs feature recognition on the input image to determine a plurality of determined features of the input image. At 606, the encoder system generates a third output defining values representing the determined features of the input image. At 608, the encoder system provides a third output to the message encoding neural network. At 610, the message encoding neural network generates a signature from a third output that defines values representing the determined features of the input image. At 612, the encoder system embeds the second signature in the input image to generate an output image. In some aspects, the method 600 includes verifying authenticity of the image. The method 600 may be performed, include more or fewer operations than illustrated, or performed in a different order.
In an example use case of the method 600, a user of a user computing device takes an input image (photograph) with a camera module of the user computing device. An encoder system implemented on a user computing device receives an input image. The encoder system performs feature recognition on the input image to determine a plurality of determined features of the input image. The encoder system generates an output defining values representing the determined features of the input image. The encoder system provides an output to a message encoding neural network implemented on a memory device of the user computing device. The message-encoding neural network generates a signature from an output that defines values representing determined features of the input image. The encoder system embeds the signature in the input image to generate an output image that is stored on a memory device of the user computing device.
In another example use case of the method 600, the image is stored in an image library. An encoder system implemented on a server computing device receives an input image from an image library. For example, an operator of a server computing device may utilize an image repository to store images uploaded by users of services provided by the operator. The encoder system performs feature recognition on the input image to determine a plurality of determined features of the input image. The encoder system generates an output defining values representing the determined features of the input image. The encoder system provides an output to a message encoding neural network implemented on a memory device of the server computing device. The message-encoding neural network generates a signature from an output that defines values representing determined features of the input image. The encoder system embeds the signature in the input image to generate an output image that is stored on a memory device of the server computing device. The embedded signature may be used later to verify the image.
Fig. 7 illustrates an example method 700 of verifying image authenticity. Method 700 may be performed by system 200 as described above with reference to fig. 2, using one or more components described with reference to fig. 2. At 702, a decoder system receives an image to be authenticated. At 704, the decoder system performs feature recognition on the received image to determine a plurality of determined features of the received image. At 706, the decoder system generates a first output defining values representing the determined characteristics of the received image. At 708, the decoder system decodes the received image using the message decoding neural network to extract the signature embedded in the received image. The embedded signature represents a recovered characteristic of the received image. At 710, the decoder system generates a second output defining values of features representing the restoration of the received image. At 712, the decoder system provides a first output and a second output to the steering detection neural network. At 714, the steering detection neural network generates an estimate of the authenticity of the received image using at least the first output and the second output. In some aspects, method 700 includes verifying authenticity of an image. The method 700 may be performed, include more or fewer operations than shown, or performed in a different order.
In an example use case of the method 700, a decoder system implemented on a user computing device receives an image to be verified from a memory device implemented on the user computing device. The decoder system performs feature recognition on the received image to determine a plurality of determined features of the received image. The decoder system generates a first output defining values representative of the determined characteristics of the received image. The decoder system decodes the received image using a message decoding neural network implemented on the user computing device to extract the signature embedded in the received image. The embedded signature represents a recovered characteristic of the received image. The decoder system generates a second output defining values representative of the restored features of the received image. The decoder system provides the first output and the second output to a steering detection neural network implemented on a user computing device. The steering detection neural network generates an estimate of the authenticity of the received image using at least the first output and the second output.
In another example use case of the method 700, a decoder system implemented on a server computing device receives an image to be verified from an image library. For example, an operator of a server computing device may utilize an image repository to store images uploaded by users of services provided by the operator. The decoder system performs feature recognition on the received image to determine a plurality of determined features of the received image. The decoder system generates a first output defining values representative of the determined characteristics of the received image. The decoder system decodes the received image using a message decoding neural network implemented on the server computing device to extract the signature embedded in the received image. The embedded signature represents a recovered characteristic of the received image. The decoder system generates a second output defining values representative of the restored features of the received image. The decoder system provides the first output and the second output to a steering detection neural network implemented on a server computing device. The steering detection neural network generates an estimate of the authenticity of the received image using at least the first output and the second output.
Machine learning model
Fig. 8 depicts a block diagram of an example machine learning model 800, according to an example embodiment of the present disclosure. As shown in fig. 8, machine learning model 800 is trained to receive one or more types of input data and, in response, provide one or more types of output data. Thus, fig. 8 illustrates a machine learning model 800 that performs inference.
The input data may include one or more characteristics associated with the instance or example. In some implementations, one or more features associated with an instance or example may be organized into a feature vector. In some embodiments, the output data may include one or more predictions. Prediction may also be referred to as inference. Thus, given the features associated with a particular instance, the machine learning model may output a prediction for such instance based on these features.
The machine learning model may be or include one or more of a variety of different types of machine learning models. In particular, in some embodiments, the machine learning model may perform classification, regression, clustering, association, anomaly detection, recommendation generation, and/or other tasks.
The machine learning model may perform various types of classification based on the input data. For example, the machine learning model may perform a binary classification or a multi-class classification. In binary classification, the output data may include a classification of the input data into one of two different classes. In a multi-class classification, the output data may include one (or more) of the input data in more than two classes. The classification may be single-label or multi-label.
The machine learning model may perform discrete classification, where the input data is simply classified into one or more categories or classes.
The machine learning model may perform the classification, wherein the machine learning model provides a numerical value for each of the one or more classes that describes a degree to which the input data is deemed to be classified into the respective class. In some cases, the numerical values provided by the machine learning model may be referred to as "confidence scores," which indicate respective confidences associated with the classifications input to the respective categories. In some implementations, the confidence score can be compared to one or more thresholds to provide a discrete classification prediction. In some implementations, only a certain number of categories (e.g., one) having relatively largest confidence scores may be selected to present discrete classification predictions.
The machine learning model may provide probabilistic classification. For example, given sample input, a machine learning model can predict a probability distribution for a set of classes. Thus, the machine learning model may output, for each class, the probability that the sample input belongs to the class, rather than just the most likely class to which the sample input should belong. In some embodiments, the sum of the probability distributions for all possible classes may be 1. In some implementations, the softmax function or layer can be used to squeeze a set of real values respectively associated with possible categories into a set of real values in a range (0, 1) that sums to 1.
The probabilities provided by the probability distributions may be compared to one or more thresholds to provide discrete classification predictions. In some implementations, only a certain number of categories (e.g., one) having a relatively maximum prediction probability may be selected to present discrete classification predictions.
In implementations where the machine learning model performs classification, supervised learning techniques may be used to train the machine learning model. For example, a machine learning model may be trained on a training data set that includes training examples labeled as belonging to (or not belonging to) one or more classes. Further details regarding supervised training techniques are provided below.
The machine learning model may perform a regression that provides output data in the form of continuous values. Consecutive numerical values may correspond to any number of different metrics or numerical representations, including, for example, a monetary value, a score, or other numerical representation. For example, the machine learning model may perform a linear regression, a polynomial regression, or a nonlinear regression. For example, the machine learning model may perform a simple regression or a multiple regression. As described above, in some embodiments, the softmax function or layer may be used to squeeze a set of real values respectively associated with two or more possible categories into a set of real values in a range (0, 1) that sums to 1.
The machine learning model may perform various types of clustering. For example, the machine learning model may identify one or more previously defined clusters to which the input data most likely corresponds. As another example, the machine learning model may identify one or more clusters in the input data. That is, where the input data includes multiple objects, documents, or other entities, the machine learning model may classify the multiple entities included in the input data into multiple clusters. In some embodiments where the machine learning model performs clustering, the machine learning model may be trained using unsupervised learning techniques.
The machine learning model may perform anomaly detection or outlier detection. For example, the machine learning model may identify input data that does not conform to an expected pattern or other feature (e.g., as previously observed from previous input data). For example, anomaly detection may be used for fraud detection or system failure detection.
The machine learning model may provide output data in the form of one or more recommendations. For example, the machine learning model may be included in a recommendation system or engine. As an example, given input data describing previous results of certain entities (e.g., scores, rankings, or ratings indicative of success or enjoyment), the machine learning model may output suggestions or recommendations of one or more additional entities that are expected to have a desired result based on the previous results (e.g., elicited scores, rankings, or ratings indicative of success or enjoyment). As one example, given input data describing the number of products purchased or highly rated by a user, the recommendation system may output suggestions or recommendations for additional products that the user may like or wish to purchase.
The machine learning model may act as a proxy in the environment. For example, reinforcement learning may be used to train a machine learning model, which will be discussed in further detail below.
The machine learning model may be a parametric model, while in other embodiments the machine learning model may be a non-parametric model. In some embodiments, the machine learning model may be a linear model, while in other embodiments, the machine learning model may be a non-linear model.
As described above, the machine learning model may be or include one or more of a variety of different types of machine learning models. Examples of such different types of machine learning models are provided below for illustration. One or more of the example models described below may be used to (e.g., combine) provide output data in response to input data. Other models may be used in addition to the example models provided below.
The machine learning model may be or include one or more classifier models, such as, for example, a linear classification model, a quadratic classification model, and so forth.
The machine learning model may be or include one or more regression models such as, for example, a simple linear regression model, a multiple linear regression model, a logistic regression model, a stepwise regression model, a multiple adaptive regression spline; locally estimated scatter diagram smoothing models; and so on.
The machine learning model may be or include one or more decision tree based models, such as, for example, classification and/or regression trees; ID3 (iterative dichotomy 3) decision tree; c4.5 decision tree; a chi-square automatic interaction detection decision tree; a decision-making disorder; a conditional decision tree; and so on.
The machine learning model may be or include one or more core machines. In some implementations, the machine learning model can be or include one or more support vector machines.
The machine learning model may be or include one or more instance-based learning models, such as, for example, a learning vector quantization model, a self-organizing map model, a locally weighted learning model, and so forth.
The machine learning model may be or include one or more nearest neighbor models, such as, for example, a k-nearest neighbor classification model; k is a nearest neighbor regression model; and so on.
The machine learning model may be or include one or more bayesian models, such as, for example, a na iotave bayes model, a gaussian na iotave bayes model, a polynomial na iotave bayes model; averaging the single-phase-dependent estimates; a Bayesian network; a Bayesian belief network; a hidden Markov model; and so on.
The machine learning model may be or include one or more artificial neural networks (also referred to simply as neural networks). A neural network may include a set of connected nodes, which may also be referred to as neurons or perceptrons. The neural network may be organized into one or more layers. Neural networks comprising multiple layers may be referred to as "deep" networks. The deep network may include an input layer, an output layer, and one or more hidden layers positioned between the input layer and the output layer. The nodes of the neural network may be connected or not fully connected.
The machine learning model may be or include one or more feed-forward neural networks. In a feed forward network, the connections between nodes do not form loops. For example, each connection may connect a node of an earlier layer to a node of a later layer.
The machine learning model may be or include one or more recurrent neural networks. In some cases, at least some nodes of the recurrent neural network may form a loop. Recurrent neural networks are particularly useful for processing input data that is continuous in nature. In particular, in some cases, a recurrent neural network may pass or retain information from a previous portion of the input data sequence to a subsequent portion of the input data sequence by using recurrent or directed cyclic node connections.
As one example, the sequential input data may include time series data (e.g., sensor data versus time or images captured at different times). For example, the recurrent neural network may analyze sensor data versus time to detect or predict swipe directions, perform handwriting recognition, and the like. As another example, the sequential input data may include words in a sentence (e.g., for natural language processing, speech detection or processing, etc.); musical notes in musical compositions; sequential actions taken by the user (e.g., detecting or predicting sequential application usage); a sequential object state; and so on.
Example recurrent neural networks include Long Short Term (LSTM) recurrent neural networks; a gated loop unit; a bidirectional recurrent neural network; a continuous-time recurrent neural network; a neural history compressor; an echo state network; an Elman network; a Jordan network; a recurrent neural network; a Hopfield network; a fully-cycled network; configuring between sequences; and so on.
The machine learning model may be or include one or more convolutional neural networks. In some cases, a convolutional neural network may include one or more convolutional layers that perform convolution on input data using a learning filter. Filters may also be referred to as kernels. Convolutional neural networks are particularly useful for visual problems, such as when the input data comprises images, such as still images or video. However, convolutional neural networks may also be applied to natural language processing.
The machine learning model may be or include one or more generating networks, such as, for example, generating a countering network. The generation network may be used to generate new data, such as new images or other content.
The machine learning model may be or include an auto-encoder. In some cases, the purpose of an auto-encoder is to learn a representation of a set of data (e.g., low-dimensional encoding), typically for the purpose of dimension reduction. For example, in some cases, an auto-encoder may attempt to encode input data and then provide output data that reconstructs the input data from the encoding. Recently, the concept of an auto-encoder has been more widely used for learning a generative model of data. In some cases, the auto-encoder may include additional losses in addition to reconstructing the input data.
The machine learning model may be or include one or more other forms of artificial neural networks, such as, for example, a deep boltzmann machine, a deep belief network, a stacked autoencoder, and so forth. Any of the neural networks described herein may be combined (e.g., stacked) to form a more complex network.
One or more neural networks may be used to provide the embedding based on the input data. For example, embedding can be a representation of knowledge abstracted from input data into one or more learning dimensions. In some cases, embedding may be a useful source to identify related entities. In some cases, the embedding may be extracted from the output of the network, while in other cases, the embedding may be extracted from any hidden node or layer of the network (e.g., near the final layer but not the final layer of the network). Embedding may be used to perform auto-suggest next videos, product suggestions, entity or object recognition, and the like. In some cases, embedding is a useful input to the downstream model. For example, embedding may be used to summarize input data (e.g., search queries) for a downstream model or processing system.
The machine learning model may include one or more clustering models, such as, for example, a k-means clustering model, an expectation maximization model, a hierarchical clustering model; and so on.
The machine learning model may perform one or more dimension reduction techniques, such as, for example, principal component analysis; analyzing a core principal component; graph-based core principal component analysis; regression of principal components; partial least squares regression; sammon mapping; a multi-dimensional scale; projection pursuit; linear discriminant analysis; carrying out mixed differential analysis; performing secondary identification analysis; generalized discriminant analysis; flexible differential analysis; automatic coding; and so on.
The machine learning model may perform or be subject to one or more reinforcement learning techniques such as, for example, markov decision processes, dynamic programming; q function or Q learning; a cost function method; a deep Q-network; a differentiable neural computer; asynchronous dominant actor-critic; a deterministic policy gradient; and so on.
The machine learning model may be an autoregressive model. In some cases, the autoregressive model may specify that the output data is linearly dependent on its own previous values and random terms. In some cases, the autoregressive model may take the form of a random difference equation. One example autoregressive model is WaveNet, which is a generative model of the original audio.
The machine learning model may comprise or form part of a multi-model set. As one example, bootstrap aggregation may be performed, which may also be referred to as "packing" in bootstrap aggregation, the training data set is divided into a plurality of subsets (e.g., by random sampling with alternates), and a plurality of models are trained on the plurality of subsets, respectively. When inferred, the respective outputs of the multiple models can be combined (e.g., by averaging, voting, or other techniques) and used as an integrated output.
One example model integration is a random forest, which may also be referred to as a random decision forest. Random forests are an integrated learning method for classification, regression, and other tasks. A random forest is generated by generating a plurality of decision trees when training. In some cases, classes that are a pattern of classes (classification) or average predictions (regression) of individual trees may be used as the output of the forest at the time of inference. The random decision tree may correct the tendency of the decision tree to over-adapt to the training set.
Another example integration technique is stacking, which may be referred to as stacking generalization in some cases. Stacking includes training the combiner model to mix or otherwise combine predictions of several other machine learning models. Accordingly, multiple machine learning models (e.g., of the same or different types) may be trained based on training data. Further, the combiner model may be trained to take predictions from other machine learning models as input, and in response, generate final inferences or predictions. In some cases, a single-layer logistic regression model may be used as the combined model.
Another example integration technology is boosting. Boosting can include incrementally building the ensemble by iteratively training weak models and then adding to the final strong model. For example, in some cases, each new model may be trained to emphasize training examples of previous model misinterpretations (e.g., misclassifications). For example, the weight associated with each such misinterpreted example may be increased. One common implementation of Boosting is AdaBoost, which may also be referred to as adaptive Boosting. Other example Boosting techniques include linear programming Boosting (lpboost); TotalBoost; brownboost; XGboost; MadaBoost, LogitBoost, gradient boosting; and so on.
Further, any of the models described above (e.g., regression models and artificial neural networks) may be combined to form a set. For example, the integration may include a top-level machine learning model or heuristic functions to combine and/or weight the outputs forming the integrated model.
Multiple machine learning models (e.g., models forming an ensemble) may be linked and trained together (e.g., by sequential error back-propagation in model ensemble). However, in some embodiments, only a subset (e.g., one) of the co-trained models is used for the inference.
The machine learning model may be used to pre-process input data for subsequent input into another model. For example, the machine learning model may perform dimension reduction techniques and embedding (e.g., matrix decomposition, principal component analysis, singular value decomposition, Word2vec/GloVe, and/or correlation methods); clustering; even classification regression on downstream consumption. Many of these techniques have been discussed above and will be discussed further below.
Referring again to fig. 8, and as described above, the machine learning model may be trained or otherwise configured to receive input data and, in response, provide output data. The input data may include different types, forms, or variations of input data. As an example, in various embodiments, the input data may include determined image features and/or user-provided image features.
The machine learning model may receive and use input data in raw form. In some embodiments, the raw input data may be pre-processed. Thus, the machine learning model may receive and use preprocessed input data in addition to or instead of raw input data.
Preprocessing the input data may include extracting one or more additional features from the raw input data. For example, feature extraction techniques may be applied to the input data to generate one or more new additional features. Example feature extraction techniques include edge detection; detecting an angular point; detecting spots; ridge line detection; transforming the scale-invariant features; detecting motion; an optical flow; hough transform; and so on.
The extracted features may include or be derived from transformations of the input data into other domains and/or dimensions. For example, the extracted features may comprise or be derived from a transformation of the input data into the frequency domain. For example, a wavelet transform and/or a fast fourier transform may be performed on the input data to generate additional features.
The extracted features may include statistics computed from the input data or certain portions or dimensions of the input data. Example statistics include patterns, averages, maxima, minima, or other metrics of the input data or portions thereof.
As described above, the input data may be sequential in nature. In some cases, the sequential input data may be generated by sampling or dividing the input data stream. As one example, frames may be extracted from a video. In some embodiments, the sequential data may be made non-sequential by aggregation.
As another example of a preprocessing technique, portions of the input data may be evaluated. For example, additional synthesized input data may be generated by interpolation and/or extrapolation.
As another example pre-processing technique, some or all of the input data may be scaled, normalized, generalized, and/or regularized. Example regularization techniques include ridge regression; a minimum absolute shrinkage and selection operator (LASSO); an elastic net; regression of the minimum angle; performing cross validation; l1 regularization; l2 normalized; and so on. As one example, some or all of the input data may be normalized by subtracting the mean of the feature values for a given dimension from each individual feature value, and then dividing by the standard deviation or another metric.
As another example preprocessing technique, some or all of the input data may be quantized or discretized. As yet another example, qualitative features or variables included in the input data may be converted into quantitative features or variables. For example, one hot encoding may be performed.
Dimension reduction techniques may be applied to the input data prior to input to the machine learning model. Examples of several dimension reduction techniques are provided above, including, for example, principal component analysis; analyzing a core principal component; graph-based core principal component analysis; regression of principal components; partial least squares regression; sammon mapping; a multi-dimensional scale; projection pursuit; linear discriminant analysis; carrying out mixed differential analysis; performing secondary identification analysis; generalized discriminant analysis; flexible differential analysis; automatic coding; and so on.
During training, the input data may be intentionally deformed in a number of ways to improve the robustness, generalization ability, or other quality of the model. Example techniques to distort input data include adding noise; changing color, shade, or hue; a magnification factor; segmenting; amplifying; and so on.
Referring again to fig. 8, in response to receipt of input data, the machine learning model 800 may provide output data. The output data may include different types, forms, or variations of output data. As an example, in various implementations, the output data may include values representing features of an image (e.g., input image, output image, received image), values representing image features embedded in the received image, and/or a prediction (e.g., estimate) of image authenticity.
As described above, the output data may include various types of classification data (e.g., binary classification, multi-class classification, single label, multi-label, discrete classification, regression classification, probabilistic classification, etc.) or may include various types of regression data (e.g., linear regression, polynomial regression, non-linear regression, simple regression, multiple regression, etc.). In other cases, the output data may include clustered data, anomaly detection data, recommendation data, or any other form of output data described above.
The output data may affect downstream processes or decisions. As one example, in some embodiments, the output data may be interpreted and/or acted upon by a rule-based regulator.
In aspects, when the machine learning model is stored on a computing system (e.g., user computing system 302), software encryption rules (e.g., a secure hash algorithm) may be used to protect the integrity of the model and prevent third parties from tampering with the model (e.g., replacing a portion of the machine learning model with another model). In some aspects, an alert signal may be generated in response to detecting an attempted tampering.
Accordingly, the present disclosure provides systems and methods that include or otherwise utilize one or more machine learning models to generate a prediction (e.g., estimate) of image authenticity based on determined features and/or restored image features embedded in an image. Any of the different types or forms of input data described above may be combined with any of the different types or forms of machine learning models described above to provide any of the different types or forms of output data described above.
The machine learning model 800 may be stored in a computing system (e.g., computing system 300 of fig. 3) and/or implemented locally by the computing system. For example, the machine learning model 800 may be stored on and/or implemented locally by the user computing device or embedded computing device. Output data obtained by locally implementing the machine learning model at the computing system may be used to improve performance of the computing system (e.g., an application implemented by the computing system). As one example, fig. 3 illustrates a block diagram of a user computing system 302 (e.g., a mobile computing device) that locally stores and implements a machine learning model 320.
The machine learning model may be stored on and/or implemented by a server computing device (such as server computing system 330 of fig. 3). In some cases, output data obtained by implementing the machine learning model at the server computing device may be used to improve other server tasks, or may be used by other non-user devices to improve services performed by or for such other non-user devices. For example, the output data may improve other downstream processes performed by the server computing device for the user computing device or the embedded computing device. In other cases, the output data obtained by implementing the machine learning model at the server computing device may be sent to and used by the user computing device, the embedded computing device, or some other client device. For example, the server computing device may be said to perform machine learning as a service. As one example, fig. 3 illustrates a block diagram of an example user computing system 302 that may communicate over a network 380 with an example server computing system 330 that includes a machine learning model 340.
Different respective portions of the machine learning model may be stored in and/or implemented by some combination of user computing devices, embedded computing devices, server computing devices, and the like.
The computing device may use one or more machine learning platforms, frameworks, and/or libraries to perform graphics processing techniques or other machine learning techniques, such as, for example, TensorFlow, Caffe/Caffe2, Theano, Torch/PyTorch, MXNet, cognitive toolkit (CNTK), and so forth.
The computing devices may be distributed over different physical locations and connected via one or more networks. The distributed computing devices may operate according to a sequential computing architecture, a parallel computing architecture, or a combination thereof. In one example, the distributed computing device may be controlled or booted through the use of a parameter server.
Multiple instances of the machine learning model may be parallelized to provide increased processing throughput. For example, multiple instances of a machine learning model may be parallelized on a single processing device or computing device, or across multiple processing devices or computing devices.
As described above, the machine learning models described herein may be trained at a training computing system and then provided for storage and/or implementation at one or more computing devices. For example, the model trainer 360 may be located at the training computing system 350, as shown in FIG. 3. The training computing system 350 may be included in or separate from one or more computing devices that implement the machine learning model. As one example, FIG. 3 illustrates a block diagram of an example user computing system 302 in communication with an example training computing system 350 that includes a model trainer 360.
The machine learning model may be trained in an offline manner or in an online manner. In offline training (also known as batch learning), a model is trained on the entirety of a set of static training data. In online learning, a model is continuously trained (or retrained) as new training data becomes available (e.g., when the model is used to perform inferences).
The model trainer may perform centralized training of the machine learning model (e.g., based on a centrally stored data set). In other embodiments, decentralized training techniques, such as distributed training, joint learning, and the like, may be used to train, update, or personalize the machine learning model.
The machine learning models described herein may be trained according to one or more of a variety of different training types or techniques. For example, in some implementations, a machine learning model can be trained using supervised learning, where the machine learning model is trained on a training dataset that includes instances or examples with labels. The tags may be applied manually by an expert, generated by crowd sourcing, or provided by other techniques (e.g., by physical-based or complex mathematical models). In some embodiments, the training examples may be provided by the user computing device if the user has provided consent. In some embodiments, this process may be referred to as a personalization model.
The machine learning model may be trained by optimizing an objective function. For example, in some embodiments, the objective function may be or include a loss function that compares (e.g., determines differences between) output data generated by the model from the training data and a label (e.g., ground truth label) associated with the training data. For example, the loss function may compute the sum or mean of the squared differences between the output data and the labels. As another example, the objective function may be or include a cost function that describes the cost of a particular result or output data. Other objective functions may include margin-based techniques such as triple loss or maximum margin training.
One or more of a variety of optimization techniques may be performed to optimize the objective function. For example, the optimization technique may minimize or maximize an objective function. Example optimization techniques include Hessian-based techniques and gradient-based techniques such as, for example, coordinate descent, gradient descent (e.g., random gradient descent), sub-gradient methods, and the like. Other optimization techniques include black box optimization techniques and heuristics.
Back propagation of errors may be used in conjunction with optimization techniques (e.g., gradient-based techniques) to train a model (e.g., a multi-layer model such as an artificial neural network). For example, an iterative loop of propagation and model parameter (e.g., weight) updates may be performed to train the model. Example backpropagation techniques include time-truncated backpropagation, Levenberg-Marquardt backpropagation, and the like.
The machine learning models described herein may be trained using unsupervised learning techniques. Unsupervised learning may include inferring functions that describe hidden structures from unlabeled data. For example, the classification or categorization may not be included in the data. Unsupervised learning techniques may be used to generate machine learning models that can perform clustering, anomaly detection, learning latent variable models, or other tasks.
The machine learning model described herein may be trained using semi-supervised techniques that combine supervised learning and unsupervised learning.
The machine learning models described herein may be trained or generated by evolutionary techniques or genetic algorithms.
The machine learning models described herein may be trained using reinforcement learning. In reinforcement learning, an agent (e.g., a model) may take actions in the environment and learn to maximize rewards and/or minimize penalties resulting from such actions. Reinforcement learning differs from the supervised learning problem in that neither correct input/output pairs occur nor suboptimal actions are explicitly corrected.
One or more generalization techniques may be performed during training to improve the generalization of the machine learning model. Generalization techniques can help reduce overfitting of machine learning models to training data. Example generalization techniques include drop techniques, weight decay techniques, batch normalization, early stop, subset selection, step-by-step selection, and the like.
The machine learning model described herein may include or be affected by a plurality of hyper-parameters, such as, for example, learning rate, number of layers, number of nodes in each layer, number of leaves in a tree, number of clusters; and so on. The hyper-parameters may affect the model performance. The hyper-parameters may be selected manually or may be selected automatically by applying techniques such as grid searching; black-box optimization techniques (e.g., bayesian optimization, random search, etc.); a gradient-based optimization; and so on. Example techniques and/or tools for performing automated hyper-parameter optimization include Hyperopt; Auto-WEKA; spearmint; a Metric Optimization Engine (MOE); and so on.
Various techniques may be used to optimize and/or adjust the learning rate when training the model. Example techniques and/or tools for performing learning rate optimization or adaptation include AdaGrad, adaptive moment estimation (ADAM), ADADELTA, RMSprop, and the like.
The migration learning technique may be used to provide an initial model from which to train the machine learning model described herein.
The machine learning models described herein may be included in different portions of computer readable code on a computing device. In one example, the machine learning model may be included in and used (e.g., exclusively) by a particular application or program. Thus, in one example, a computing device may include multiple applications, and one or more of such applications may contain its own respective machine learning libraries and machine learning models.
The machine learning model described herein may be included in an operating system of a computing device (e.g., in a central intelligence layer of the operating system) and may be invoked or otherwise used by one or more applications interacting with the operating system. In some implementations, each application can communicate with the central smart tier (and the models stored therein) using an Application Programming Interface (API) (e.g., a common API across all applications).
The central smart inlay may communicate with a central device data plane. The central device data layer may be a centralized data repository of computing devices. The central device data layer may communicate with a plurality of other components of the computing device, such as, for example, one or more sensors, a context manager, a device state component, and/or an additional component. In some embodiments, the central device data layer may communicate with each device component using an API (e.g., a private API).
The techniques discussed herein refer to servers, databases, software applications, and other computer-based systems, as well as actions taken and information sent to and received from such systems. The inherent flexibility of computer-based systems allows for a variety of possible configurations, combinations, and divisions of tasks and functions between components. For example, the processes discussed herein may be implemented using a single device or component or a plurality of devices or components operating in combination. The database and applications may be implemented on a single system or may be distributed across multiple systems. The distributed components may operate sequentially or in parallel.
Moreover, the machine learning techniques described herein are easily interchangeable and combinable. While certain example techniques have been described, many others exist and may be used in conjunction with aspects of the present disclosure.
Thus, while the present subject matter has been described in detail with respect to various specific example embodiments, each example is provided by way of explanation, not limitation of the disclosure. One of ordinary skill in the art may readily modify, adapt and equivalents such embodiments. Accordingly, the subject disclosure does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art. For instance, features illustrated or described as part of one embodiment, can be used with another embodiment to yield a still further embodiment.
Examples of the invention
In the next section, some examples are described:
example 1: a method, comprising: receiving, by a decoder system (220), an image (210) to be authenticated; performing feature recognition on the received image (210) to determine a plurality of determined features (238) of the received image (210); generating a first output (236) defining values representative of the determined features (238) of the received image (210); decoding the received image (210) by a message decoding neural network (252) of the decoder system (220) to extract a signature (254) embedded in the received image (210), the signature (254) representing recovered features (258) of the received image (210); generating a second output (256), the second output (256) defining values of a feature (258) representing a restoration of the received image (210); providing a first output (236) and a second output (256) to a steering detection neural network (272) of a decoder system (220); and generating, by the steering detection neural network (272), an estimate of the authenticity of the received image (210) using at least the first output (236) and the second output (256).
Example 2: the method of example 1, wherein performing feature recognition on the received image further comprises at least one of: processing the received image using a first feature extraction neural network to select a plurality of features of the received image; or receiving a first user input to select a plurality of features of the received image.
Example 3: the method of example 1 or example 2, further comprising: receiving, by an encoder system, an input image; performing feature recognition on the input image to determine a plurality of determined features of the input image; and generating a third output defining values representing the determined features of the input image.
Example 4: the method of example 3, wherein performing feature recognition on the received image comprises processing the received image using a first feature extraction neural network to select a plurality of features of the received image; wherein performing feature recognition on the input image comprises processing the input image using a second feature extraction neural network to select a plurality of features of the input image; the method further comprises the following steps: providing the second output and the third output to a discriminant feature loss computation engine; calculating, by the discriminant feature loss calculation engine, a first loss based on at least the second output and the third output based on a first loss function; calculating a second loss based on a second loss function based on at least the input image and the received image; calculating a total loss based on a total loss function based on at least the first loss and the second loss; and co-training at least one of the first or second feature extraction neural networks with the message decoding neural network based at least on the calculated total loss.
Example 5: the method of example 3 or example 4, further comprising: providing a third output to a message encoding neural network; generating a second signature from the third output; and embedding the second signature into the input image to generate an output image.
Example 6: the method of example 3, wherein performing feature recognition on the input image further comprises at least one of: processing the input image using a second feature extraction neural network to select a plurality of features of the input image; or receiving a second user input to select a plurality of features of the input image.
Example 7: the method of any of examples 4-6, further comprising: performing a feature extraction neural network training procedure comprising: calculating a third loss based on a third loss function based on at least the second output and the third output; and training at least one of the first or second feature extraction neural networks based at least on the calculated third loss.
Example 8: the method of any of examples 3-7, wherein receiving the input image comprises at least one of: receiving an input image from an image library; or receiving an input image in response to a user selection; and wherein receiving the received image to be verified comprises at least one of: receiving a received image from an image library; or receive a received image in response to a user selection.
Example 9: the method of any one of example 3, example 5, or example 8, wherein performing feature recognition on the received image comprises processing the received image using a first feature extraction neural network to select a plurality of features of the received image; wherein performing feature recognition on the input image comprises processing the input image using a second feature extraction neural network to select a plurality of features of the input image; the method further comprises the following steps: fixing a value of at least one of a first feature extraction neural network, a second feature extraction neural network, a message encoding neural network, or a message decoding neural network; generating a training image comprising at least one image manipulation; sending the training image to a steering detection neural network; determining an image manipulation to apply to the training image; calculating a normal loss based on a normal loss function using image manipulation applied to the training image; and training the steering detection neural network based at least on the calculated normal loss.
Example 10: the method of any one of example 3, example 5, or example 8, wherein performing feature recognition on the received image comprises processing the received image using a first feature extraction neural network to select a plurality of features of the received image; wherein performing feature recognition on the input image comprises processing the input image using a second feature extraction neural network to select a plurality of features of the input image; the method further comprises the following steps: calculating an image loss based on an image loss function based on the input image; calculating a feature loss based on a feature loss function based on the input image; calculating a total loss based on the image loss and the feature loss; and training at least one of the message encoding neural network or the message decoding neural network based at least on the calculated total loss.
Example 11: the method of any of examples 3-8 or 10, further comprising: at least one image manipulation is applied to the input image.
Example 12: the method of example 10, further comprising: fixing a value of at least one of a first feature extraction neural network, a second feature extraction neural network, a message encoding neural network, or a message decoding neural network; generating a training image comprising at least one image manipulation; sending the training image to a steering detection neural network; determining an image manipulation to apply to the training image; calculating a normal loss based on a normal loss function using image manipulation applied to the training image; and training the steering detection neural network based at least on the calculated normal loss.
Example 13: the method of example 5 or example 8, further comprising: performing a feature extraction neural network training procedure, comprising: calculating a third loss based on a third loss function based on at least the second output and the third output; training at least one of the first feature extraction neural network or the second feature extraction neural network based at least on the calculated third loss; and executing a steering detection neural network training program comprising: fixing a value of at least one of a first feature extraction neural network, a second feature extraction neural network, a message encoding neural network, or a message decoding neural network; generating a training image comprising at least one image manipulation; sending the training image to a steering detection neural network; determining an image manipulation to apply to the training image; calculating a normal loss based on a normal loss function using image manipulation applied to the training image; training a steering detection neural network based at least on the calculated normal loss; and co-training the feature extraction neural network and the manipulation detection neural network.
Example 14: the method of example 3 or example 8, wherein performing feature recognition on the received image comprises processing the received image using a first feature extraction neural network; wherein performing feature recognition on the input image comprises processing the input image using a second feature extraction neural network; the method further comprises the following steps: providing a third output to a message encoding neural network; generating a second signature from the third output; embedding the second signature into the input image to generate an output image; providing the second output and the third output to a discriminant feature loss computation engine; executing a message codec neural network training procedure, comprising: calculating, by the discriminant feature loss calculation engine, a first loss based on at least the second output and the third output based on a first loss function; calculating a second loss based on a second loss function based on at least the input image and the received image; calculating a total loss based on a total loss function based on at least the first loss and the second loss; training at least one of a first feature extraction neural network, a second feature extraction neural network, or a message decoding neural network based at least on the calculated total loss; performing a steering detection neural network training procedure comprising: fixing a value of at least one of a first feature extraction neural network, a second feature extraction neural network, a message encoding neural network, or a message decoding neural network; generating a training image comprising at least one image manipulation; sending the training image to a steering detection neural network; calculating a normal loss of image manipulation applied to the training image based on a normal loss function, wherein the normal loss is a cross-entropy loss; and training a steering detection neural network based at least on the calculated normal loss; and co-training the message encoding neural network and the steering detection neural network.
Example 15: the method of example 3 or example 8, wherein performing feature recognition on the received image comprises processing the received image using a first feature extraction neural network; wherein performing feature recognition on the input image comprises processing the input image using a second feature extraction neural network; the method further comprises the following steps: providing a third output to a message encoding neural network; generating a second signature from the third output; embedding the second signature into the input image to generate an output image; providing the second output and the third output to a discriminant feature loss computation engine; executing a message codec neural network training procedure, comprising: calculating, by the discriminant feature loss calculation engine, a first loss based on at least the second output and the third output based on a first loss function; calculating a second loss based on a second loss function based on at least the input image and the received image; calculating a total loss based on a total loss function based on at least the first loss and the second loss; and training at least one of the first feature extraction neural network, the second feature extraction neural network, or the message decoding neural network based at least on the calculated total loss; performing a feature extraction neural network training procedure comprising: calculating a third loss based on a third loss function based on at least the second output and the third output; training at least one of the first feature extraction neural network or the second feature extraction neural network based at least on the calculated third loss; and executing a steering detection neural network training program comprising: fixing a value of at least one of a first feature extraction neural network, a second feature extraction neural network, a message encoding neural network, or a message decoding neural network; generating a training image comprising at least one image manipulation; sending the training image to a steering detection neural network; determining an image manipulation to apply to the training image; calculating a normal loss based on a normal loss function using image manipulation applied to the training image; and training a steering detection neural network based at least on the calculated normal loss; and co-training the feature extraction neural network, the message encoding neural network and the manipulation detection neural network.
Example 16: the method of any of examples 4-15, wherein the first feature extraction neural network and the second feature extraction neural network are the same feature extraction neural network.
Example 17: the method of any one of embodiments 9, 12, or 13-15, wherein the normal loss is a cross-entropy loss.
Example 18: a computing device, comprising: a processor; and a computer-readable storage medium having instructions stored thereon that, in response to execution by a processor, cause the processor to perform the method of any of examples 1 to 17.
Example 19: a system comprising one or more computers and one or more memory devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform operations comprising the method of any of examples 1-17.
Example 20: one or more non-transitory computer storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform operations comprising the method of any one of examples 1-19.
Conclusion
Although the techniques and apparatus for verifying the authenticity of images have been described in language specific to features and/or methods, it is to be understood that the subject of the appended claims is not necessarily limited to the specific features or methods described. Rather, the specific features and methods are disclosed as example embodiments of techniques and apparatus for verifying the authenticity of images.
Claims (16)
1. A method, comprising:
receiving, by a decoder system (220), an image (210) to be authenticated;
performing feature recognition on a received image (210) to determine a plurality of determined features (238) of the received image (210);
generating a first output (236), the first output (236) defining a value representative of the determined feature (238) of the received image (210);
decoding the received image (210) by a message decoding neural network (252) of the decoder system (220) to extract a signature (254) embedded in the received image (210), the signature (254) representing recovered features (258) of the received image (210);
generating a second output (256), the second output (256) defining values representative of the restored features (258) of the received image (210);
providing the first output (236) and the second output (256) to a steering detection neural network (272) of the decoder system (220); and
generating, by the steering detection neural network (272), an estimate of authenticity of the received image (210) using at least the first output (236) and the second output (256).
2. The method of claim 1, wherein performing feature recognition on the received image further comprises at least one of:
processing the received image using a first feature extraction neural network to select the plurality of features of the received image; or
A first user input is received to select the plurality of features of the received image.
3. The method of claim 1 or 2, further comprising:
receiving, by an encoder system, an input image;
performing feature recognition on the input image to determine a plurality of determined features of the input image; and
generating a third output defining values representing the determined features of the input image.
4. The method of claim 3, wherein the first and second light sources are selected from the group consisting of,
wherein performing feature recognition on the received image comprises processing the received image using a first feature extraction neural network to select the plurality of features of the received image;
wherein performing feature recognition on the input image comprises processing the input image using a second feature extraction neural network to select the plurality of features of the input image;
the method further comprises the following steps:
providing the second output and the third output to a discriminant feature loss computation engine;
calculating, by the discriminative feature loss calculation engine, a first loss based on a first loss function based on at least the second output and the third output;
calculating a second loss based on a second loss function based on at least the input image and the received image;
calculating a total loss based on a total loss function based on at least the first loss and the second loss; and
at least one of the first or second feature-extracting neural networks is co-trained with the message-decoding neural network based at least on the calculated total loss.
5. The method of claim 3 or 4, further comprising:
providing the third output to a message encoding neural network;
generating a second signature from the third output; and
embedding the second signature in the input image to generate an output image.
6. The method of claim 3, wherein performing feature recognition on the input image further comprises at least one of:
processing the input image using a second feature extraction neural network to select the plurality of features of the input image; or
Receiving a second user input to select the plurality of features of the input image.
7. The method of any of claims 4-6, further comprising:
performing a feature extraction neural network training procedure comprising:
calculating a third loss based on a third loss function based on at least the second output and the third output; and
training at least one of the first or second feature extraction neural networks based at least on the calculated third loss.
8. The method according to any one of claims 3-7,
wherein receiving the input image comprises at least one of:
receiving the input image from an image library; or alternatively
Receiving the input image in response to a user selection; and
wherein receiving the received image to be verified comprises at least one of:
receiving the received image from an image repository; or
Receiving the received image in response to a user selection.
9. The method of any one of claims 3, 5 or 8,
wherein performing feature recognition on the received image comprises processing the received image using a first feature extraction neural network to select the plurality of features of the received image;
wherein performing feature recognition on the input image comprises processing the input image using a second feature extraction neural network to select the plurality of features of the input image;
the method further comprises the following steps:
fixing a value of at least one of the first feature extraction neural network, the second feature extraction neural network, a message encoding neural network, or the message decoding neural network;
generating a training image comprising at least one image manipulation;
sending the training image to the manipulation detection neural network;
determining the image manipulation to apply to the training image;
calculating a normal loss based on a normal loss function using the image manipulation applied to the training image; and
training the steering detection neural network based at least on the calculated normal loss.
10. The method of any one of claims 3, 5, or 8,
wherein performing feature recognition on the received image comprises processing the received image using a first feature extraction neural network to select the plurality of features of the received image;
wherein performing feature recognition on the input image comprises processing the input image using a second feature extraction neural network to select the plurality of features of the input image;
the method further comprises the following steps:
calculating an image loss based on an image loss function based on the input image;
calculating a feature loss based on a feature loss function based on the input image;
calculating a total loss based on the image loss and the feature loss; and
training at least one of a message encoding neural network or a message decoding neural network based at least on the calculated total loss.
11. The method of any of claims 3-8 or 10, further comprising:
applying at least one image manipulation to the input image.
12. The method of claim 10, further comprising:
fixing a value of at least one of the first feature extraction neural network, the second feature extraction neural network, the message encoding neural network, or the message decoding neural network;
generating a training image comprising at least one image manipulation;
sending the training image to the maneuver detection neural network;
determining the image manipulation applied to the training image;
calculating a normal loss based on a normal loss function using the image manipulation applied to the training image; and
training the steering detection neural network based at least on the calculated normal loss.
13. The method of claim 5 or 8, further comprising:
performing a feature extraction neural network training procedure, comprising:
calculating a third loss based on a third loss function based on at least the second output and the third output;
training at least one of the first or second feature extraction neural networks based at least on the calculated third loss; and
performing a steering detection neural network training procedure comprising:
fixing a value of at least one of the first feature extraction neural network, the second feature extraction neural network, the message encoding neural network, or the message decoding neural network;
generating a training image comprising at least one image manipulation;
sending the training image to the manipulation detection neural network;
determining the image manipulation applied to the training image;
calculating a normal loss based on a normal loss function using the image manipulation applied to the training image;
training the maneuver detection neural network based at least on the calculated normal loss; and
co-training the feature extraction neural network and the manipulation detection neural network.
14. The method according to claim 3 or 8,
wherein performing the feature recognition on the received image comprises processing the received image using a first feature extraction neural network;
wherein performing the feature recognition on the input image comprises processing the input image using a second feature extraction neural network;
the method further comprises the following steps:
providing the third output to a message encoding neural network;
generating a second signature from the third output;
embedding the second signature in the input image to generate an output image;
providing the second output and the third output to a discriminant feature loss computation engine;
executing a message codec neural network training procedure, comprising:
calculating, by the discriminative feature loss calculation engine, a first loss based on a first loss function based on at least the second output and the third output;
calculating a second loss based on a second loss function based on at least the input image and the received image;
calculating a total loss based on a total loss function based on at least the first loss and the second loss;
training at least one of the first feature extraction neural network, the second feature extraction neural network, or the message decoding neural network based at least on the calculated total loss;
performing a steering detection neural network training procedure comprising:
fixing a value of at least one of the first feature extraction neural network, the second feature extraction neural network, the message encoding neural network, or the message decoding neural network;
generating a training image comprising at least one image manipulation;
sending the training image to the manipulation detection neural network;
calculating a normal loss based on a normal loss function using the image manipulation applied to the training image; and
training the maneuver detection neural network based at least on the calculated normal loss; and
co-training the message codec neural network and the steering detection neural network.
15. The method according to claim 3 or 8,
wherein performing the feature recognition on the received image comprises processing the received image using a first feature extraction neural network;
wherein performing the feature recognition on the input image comprises processing the input image using a second feature extraction neural network;
the method further comprises the following steps:
providing the third output to a message encoding neural network;
generating a second signature from the third output;
embedding the second signature in the input image to generate an output image;
providing the second output and the third output to a discriminant feature loss computation engine;
executing a message codec neural network training procedure, comprising:
calculating, by the discriminative feature loss calculation engine, a first loss based on a first loss function based on at least the second output and the third output;
calculating a second loss based on a second loss function based on at least the input image and the received image;
calculating a total loss based on a total loss function based on at least the first loss and the second loss; and
training at least one of the first feature extraction neural network, the second feature extraction neural network, or the message decoding neural network based at least on the calculated total loss;
performing a feature extraction neural network training procedure, comprising:
calculating a third loss based on a third loss function based on at least the second output and the third output;
training at least one of the first or second feature extraction neural networks based at least on the calculated third loss; and
performing a steering detection neural network training procedure comprising:
fixing a value of at least one of the first feature extraction neural network, the second feature extraction neural network, the message encoding neural network, or the message decoding neural network;
generating a training image comprising at least one image manipulation;
sending the training image to the manipulation detection neural network;
determining the image manipulation to apply to the training image;
calculating a normal loss based on a normal loss function using the image manipulation applied to the training image; and
training the maneuver detection neural network based at least on the calculated normal loss; and
co-training the feature extraction neural network, the message codec neural network, and the manipulation detection neural network.
16. A computing device, comprising:
a processor; and
a computer-readable storage medium having instructions stored thereon that, in response to execution by the processor, cause the processor to perform the method of any of claims 1-15.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/016384 WO2021158205A1 (en) | 2020-02-03 | 2020-02-03 | Verification of the authenticity of images using a decoding neural network |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115004252A true CN115004252A (en) | 2022-09-02 |
Family
ID=69771067
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080094561.6A Pending CN115004252A (en) | 2020-02-03 | 2020-02-03 | Image authenticity verification using decoding neural networks |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230061517A1 (en) |
EP (1) | EP4055514A1 (en) |
JP (1) | JP7461485B2 (en) |
KR (1) | KR20220122741A (en) |
CN (1) | CN115004252A (en) |
WO (1) | WO2021158205A1 (en) |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20210374462A1 (en) * | 2020-05-28 | 2021-12-02 | Canon Kabushiki Kaisha | Image processing apparatus, neural network training method, and image processing method |
US20210383187A1 (en) * | 2020-06-05 | 2021-12-09 | Suman Kalyan | Decentralized machine learning system and a method to operate the same |
US20220092406A1 (en) * | 2020-09-22 | 2022-03-24 | Ford Global Technologies, Llc | Meta-feature training models for machine learning algorithms |
CN113673631B (en) * | 2021-10-22 | 2022-03-29 | 广东众聚人工智能科技有限公司 | Abnormal image detection method and device |
CN114360034A (en) * | 2022-03-18 | 2022-04-15 | 武汉大学 | Method, system and equipment for detecting deeply forged human face based on triplet network |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP1678677A4 (en) * | 2003-09-26 | 2008-02-20 | Agency Science Tech & Res | Method and system for protecting and authenticating a digital image |
JP4958868B2 (en) * | 2008-09-25 | 2012-06-20 | 株式会社日立製作所 | Document feature extraction apparatus and method |
US11263478B2 (en) * | 2016-04-07 | 2022-03-01 | Hewlett-Packard Development Company, L.P. | Signature authentications based on features |
US10515296B2 (en) * | 2017-11-14 | 2019-12-24 | Adobe Inc. | Font recognition by dynamically weighting multiple deep learning neural networks |
JP6401411B1 (en) * | 2018-02-13 | 2018-10-10 | 株式会社Ａｉハヤブサ | Artificial intelligence catch identification system, management system and logistics system |
JP7020312B2 (en) * | 2018-06-15 | 2022-02-16 | 日本電信電話株式会社 | Image feature learning device, image feature learning method, image feature extraction device, image feature extraction method, and program |
-
2020
- 2020-02-03 US US17/789,323 patent/US20230061517A1/en active Pending
- 2020-02-03 KR KR1020227026535A patent/KR20220122741A/en unknown
- 2020-02-03 CN CN202080094561.6A patent/CN115004252A/en active Pending
- 2020-02-03 JP JP2022547126A patent/JP7461485B2/en active Active
- 2020-02-03 WO PCT/US2020/016384 patent/WO2021158205A1/en unknown
- 2020-02-03 EP EP20709826.0A patent/EP4055514A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20230061517A1 (en) | 2023-03-02 |
JP2023514120A (en) | 2023-04-05 |
JP7461485B2 (en) | 2024-04-03 |
EP4055514A1 (en) | 2022-09-14 |
KR20220122741A (en) | 2022-09-02 |
WO2021158205A1 (en) | 2021-08-12 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
Kwon et al. | Backpropagated gradient representations for anomaly detection | |
JP7461485B2 (en) | Verifying image authenticity using decoding neural networks | |
Benchaji et al. | Enhanced credit card fraud detection based on attention mechanism and LSTM deep model | |
CN115760127A (en) | Transaction fraud detection method and system based on rule attention mechanism | |
Price | Predictive Cryptocurrency Mining and Staking | |
Raman et al. | Predicting Delivery Time of Components in a Supply Chain | |
Marco et al. | Conditional Variational Autoencoder with Inverse Normalization Transformation on Synthetic Data Augmentation in Software Effort Estimation. | |
US20240152440A1 (en) | Game performance prediction across a device ecosystem | |
Luo et al. | Training High Quality Spam-detection Models Using Weak Labels | |
Price et al. | Machine Learning to Automatically Lock Device Screen at Opportune Time | |
Lupi | Compressed Sensing for Monitoring of an Application | |
Salazar | Legal Precedent Mining with Machine Learning | |
Donny-Clark et al. | Determining Validity of a Point of Interest Based on Existing Data | |
Felker | Correcting Image Anomalies Using Machine Learning | |
Chai et al. | Item recommendations for cache and synchronization of application stores | |
Lai et al. | Suggesting Deletion of Blurry Photos | |
Loveless | Identifying Sources of a Change in Metrics of a Stack of Servers | |
Price et al. | Configuring Alarm Setting Using Machine Learning | |
Dhillon et al. | Reinforcement Learning for Fuzzing Testing Techniques | |
Oberdiek | Assessing the reliability of deep neural networks | |
Feltenberger | Semi-Supervised Classification Using Object Metadata | |
Price | Predicting Computing Prices Dynamically Using Machine Learning | |
Noy et al. | Using object detection to extract structured content from documents | |
Price et al. | Machine Learning to Select Screen Brightness Level | |
Feltenberger et al. | Image Moderation Using Machine Learning |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |