CN111344694B - Interface for distributed network system - Google Patents
Interface for distributed network system Download PDFInfo
- Publication number
- CN111344694B CN111344694B CN201880069402.3A CN201880069402A CN111344694B CN 111344694 B CN111344694 B CN 111344694B CN 201880069402 A CN201880069402 A CN 201880069402A CN 111344694 B CN111344694 B CN 111344694B
- Authority
- CN
- China
- Prior art keywords
- search results
- attributes
- attribute
- search
- data processing
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3325—Reformulation based on results of preceding query
- G06F16/3326—Reformulation based on results of preceding query using relevance feedback from the user, e.g. relevance feedback on documents, documents sets, document terms or passages
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24578—Query processing with adaptation to user needs using ranking
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
- G06F16/638—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1822—Parsing for meaning understanding
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/03—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 characterised by the type of extracted parameters
Abstract
The present disclosure is generally directed to data processing systems for customizing content in a voice-activated computer network environment. The data processing system may provide an improved speech-based interface by selecting response attributes based on response weighting. By providing a more compact audio-based response, selection of predetermined attributes may reduce the size of the response data and reduce network transmissions.
Description
Cross Reference to Related Applications
The present application claims the benefit and priority of U.S. patent application Ser. No.15/914,949, entitled "INTERFACE FOR A DISTRIBUTED NETWORK SYSTEM," filed on 7 and 3 at 2018, the entire contents of which are incorporated herein by reference.
Background
The voice-based interface may sequentially provide options, data, and other information to the user. The limited ability of a user to remember each item in the ordered list can lead to excessive network transmissions because the user requests repeated information or requests follow-up questions. Packet-based or otherwise excessive network transmission of network traffic data between computing devices can prevent the computing devices from properly processing the network traffic data, completing operations related to the network traffic data, or responding to the network traffic data in a timely manner. Excessive transmission of network traffic data can also complicate data routing or reduce response quality if the responding computing device meets or exceeds its processing capabilities, which can lead to inefficient bandwidth utilization.
Disclosure of Invention
In accordance with at least one aspect of the present disclosure, a system for providing digital components in a voice activated system can include a natural language processor component, a content selector component, an audio signal generation component, which are executed by a data processing system. The data processing system is capable of receiving a first input audio signal via the interface. The data processing system may parse the first input audio signal to identify a first search request in the first input audio signal. The data processing system can select a plurality of search results based on the first search request. The data processing system can determine a search context for the first search request. The data processing system is capable of selecting a plurality of attributes for each of a plurality of search results. The data processing system can determine a first weighting of a plurality of attributes for each of a plurality of search results based on the search context. The data processing system can determine a second weighting of the plurality of attributes for each of the plurality of search results based on the client device context. The data processing system can select an attribute from the plurality of attributes for each of the plurality of search results based on a first weighting of the plurality of attributes for each of the plurality of search results and a second weighting of the plurality of attributes for each of the plurality of search results. The data processing system may generate a digital component comprising a data structure having a selection of an attribute from each of the plurality of attributes for each of the plurality of search results based on a first weighting of the plurality of attributes for each of the plurality of search results and a second weighting of the plurality of attributes for each of the plurality of search results. The data processing system may transmit the digital component to the client device via the interface in response to the input audio signal.
According to at least one aspect of the present disclosure, a method of providing a digital component in a voice activated system can include: the first input audio signal is received by a natural language processor component executed by the data processing system and via an interface of the data processing system. The method may include parsing, by a natural language processor component, the first input audio signal to identify a first search request in the first input audio signal. The method can include: a content selector component executed by the data processing system selects a plurality of search results based on the first search request. The method may include determining, by an attribute selector component executed by the data processing system, a search context for a first search request. The method can include selecting, by an attribute selector component, a plurality of attributes for each of a plurality of search results. The method may include determining, by an attribute selector component, a first weighting of a plurality of attributes for each of a plurality of search results based on a search context. The method may include: a second weighting of the plurality of attributes for each of the plurality of search results is determined by the attribute selector component based on the client device context. The method may include: an attribute is selected from the plurality of attributes based on, for each of the plurality of search results, a first weighting of the plurality of attributes for each of the plurality of search results and a second weighting of the plurality of attributes for each of the plurality of search results by an attribute selector component. The method can include generating, by an audio signal generator component executed by a data processing system, a digital component comprising a data structure having, for each of a plurality of search results, a first weighting based on a plurality of attributes for each of the plurality of search results and a second weighting based on the plurality of attributes for each of the plurality of search results, an attribute selected from each of the plurality of attributes. The method can include: the digital component is transmitted by the audio signal generator to the client device via the interface in response to the input audio signal.
These and other aspects and embodiments are discussed in detail below. The foregoing information and the following detailed description include illustrative examples of various aspects and embodiments, and provide an overview or framework for understanding the nature and character of the claimed aspects and embodiments. The accompanying drawings provide a description and a further understanding of various aspects and embodiments, and are incorporated in and constitute a part of this specification.
Drawings
The drawings are not intended to be drawn to scale. Like reference numbers and designations in the various drawings indicate like elements. In the interest of clarity, not every component may be labeled in every drawing.
In the drawings:
FIG. 1 illustrates an example system for customizing content in a computer network environment based on voice activated data packets (or other protocols);
FIG. 2 illustrates a flow chart of an example method of selecting attributes for search results in the system illustrated in FIG. 1;
FIG. 3 illustrates a block diagram of converting a plurality of ranked search results into a data structure; and
FIG. 4 is a block diagram illustrating the general architecture of a computer system for elements that may be employed to implement the systems and methods described and illustrated herein.
Detailed Description
The following are more detailed descriptions of various concepts and embodiments thereof related to methods, apparatuses and systems for attribute selection for data structures in a packetized audio signal. The various concepts introduced above and discussed in more detail below may be implemented in any of a number of ways.
The present disclosure is generally directed to customization of responses in a voice-activated computer network environment. The voice interface of the device in the voice activated computer network can sequentially present the results as a list. Sequentially providing results to the user can require the user to remember each result in the list, as the voice interface provides a complete list of results and each result associated with an attribute. It may be difficult for a user to remember a complete list of results because the list of results is repeatedly provided to the user, which can lead to increased network and computer usage.
The systems and methods of the present disclosure may select one or more attributes related to the client device context or search context for each result in the list instead of sending all attributes associated with each result. The inclusion of specific attributes (as opposed to a complete list of attributes) can reduce network utilization as less data is sent to the client device. Providing the user with selected, relevant attributes and search results also enables the user to distinguish and remember the results of the results list, which may reduce the number of times the results list is repeated to the user. Reducing the number of times the results are rendered to the user may also save network and computing resources.
Fig. 1 illustrates an example system 100, which example system 100 customizes content in response to packetized audio signals in a computer network environment based on voice activated data packets (or other protocols). System 100 may include at least one data processing system 102. Data processing system 102 may include at least one server having at least one processor. For example, data processing system 102 may include multiple servers located in at least one data center or server farm. The data processing system 102 may determine a request and a trigger key associated with the request from the input audio signal. The response of the data processing system to the request or trigger may depend on the user. For example, the data processing system 102 may select a different response based on which user provided the input audio signal. The data processing system 102 may use speech recognition to determine which user provided the input audio signal. Data processing system 102 may respond to requests with one or more digital components that may include a data structure with response data. The data structures may be incorporated into one or more audio files that, when rendered, provide audio output or sound waves. In addition to audio-based content, the digital components may also include other content formats (e.g., content in text, video, or image formats).
The data processing system 102 can include at least one Natural Language Processor (NLP) component 112, at least one interface 110, at least one attribute selector component 113, at least one content selector component 118, at least one audio signal generator component 120, at least one direct action Application Programming Interface (API) 116, and at least one data store 122. The NLP component 112, interface 110, attribute selector component 113, content selector component 118, audio signal generator component 120, and direct action API 116 configured to communicate with a data store 122 and other computing devices (e.g., client computing device 104 or content provider computing device 106) via at least one computer network 105 may each comprise at least one processing unit, server, virtual server, circuit, engine, agent, appliance, or other logic device, such as a programmable logic array. The network 105 may include a computer network such as the internet, a local area network, a wide area network, a metropolitan area network or other area network, an intranet, a satellite network, other computer networks such as a voice or data mobile phone communication network, and combinations thereof.
Network 105 may include a display network, for example, a subset of information resources available on the internet associated with a content placement or search engine results system, or otherwise eligible to include a third-party digital component as part of a digital component placement activity. The data processing system 102 may use the network 105 to access information resources, such as web pages, websites, domain names, or uniform resource locators that may be presented, output, rendered, or displayed by the client computing device 104. For example, via network 105, a user of client computing device 104 may access information or data provided by content provider computing device 106.
The network 105 may include, for example, a point-to-point network, a broadcast network, a wide area network, a local area network, a telecommunications network, a data communications network, a computer network, an Asynchronous Transfer Mode (ATM) network, a Synchronous Optical Network (SONET) network, a Synchronous Digital Hierarchy (SDH) network, a wireless network, or a wired network, and combinations thereof. The network 105 may include wireless links such as infrared channels or satellite bands. The topology of the network 105 may include a bus, star, or ring network topology. Network 105 may include a mobile telephone network that uses any one or more protocols for communicating between mobile devices, including advanced mobile phone protocol ("AMPS"), time division multiple access ("TDMA"), code division multiple access ("CDMA"), global system for mobile communications ("GSM"), general packet radio service ("GPRS"), or universal mobile telecommunications system ("UMTS"). Different types of data may be transmitted via different protocols or the same type of data may be transmitted via different protocols.
The client computing device 104 and the content provider computing device 106 may each include at least one logic device, such as a computing device with a processor, to communicate with each other or with the data processing system 102 via the network 105. The client computing device 104 and the content provider computing device 106 can each include at least one server, processor, or memory, or multiple computing resources or servers located at least one data center. The client computing device 104 and the content provider computing device 106 may each include at least one computing device, such as a desktop computer, a laptop computer, a tablet computer, a personal digital assistant, a smartphone, a portable computer, a thin client computer, a virtual server, a speaker-based assistant device, or other computing device.
The client computing device 104 may include at least one sensor 140, at least one transducer 142, at least one audio driver 144, at least one speaker 146, and at least one pre-processor 148. The sensor 140 may include a microphone or an audio input sensor. The sensor 140 may also include at least one of a GPS sensor, a proximity sensor, an ambient light sensor, a temperature sensor, a motion sensor, an accelerometer, or a gyroscope. The transducer 142 may convert the audio input into an electronic signal. The audio driver 144 may include scripts or programs that are executed by one or more processors of the client computing device 104 to control the sensor 140, transducer 142, or audio driver 144, as well as other components of the client computing device 104, to process audio inputs or to provide audio outputs. The speaker 146 may transmit (or render) audio output signals.
The preprocessor assembly 148 may be coupled with the audio driver 144, the transducer 142, and the sensor 140. The preprocessor component 148 may be or include one or more processors that perform functions on received signals prior to transmission to the data processing system 102 or processing by other components of the client computing device 104. For example, the preprocessor component 148 may filter the input audio signal detected by the transducer 142 (or otherwise received by the client computing device 104) to create a filtered input audio signal. The filtering of the preprocessor 148 may include filtering (or reducing) noise in the input audio signal, amplifying a predetermined frequency in the input audio signal, reducing a predetermined frequency in the input audio signal, or upsampling or downsampling the input audio signal. The pre-processor component 148 may convert the filtered input audio signal into data packets and transmit the data packets to the data processing system 102 via the network 105.
The client computing device 104 may be associated with an end user that inputs a voice-based search request into the client computing device 104 as audio input (via the sensor 140 or the transducer 142) and receives audio output in the form of computer-generated voice that may be provided from the data processing system 102 (or the content provider computing device 106). The client computing device 104 may output audio output from the speaker 146. The computer-generated speech may include a record from a real person or a computer-generated language. The audio output may be generated from an audio file generated and provided by the data processing system 102. The audio output may be generated from text or other data provided by the data processing system 102. For example, the client computing device 104 may include a text-to-speech processor that converts text provided by the data processing system 102 into audio output. The client computing device 104 may include a display and the response to the voice-based search request may include a visual-based response, which may include images, graphics, movies, animations, displayed text, and the like. The visual-based response may supplement or replace the audio-based response.
The content provider computing device 106 may provide audio-based digital components or other data for rendering by the client computing device 104 as audio output digital components. The data may include bids for goods or services. The data may include information about the content provider computing device 106. For example, the data may include a business hours of the business associated with the content provider computing device 106, a location of the business, a qualification list, a offered services list, a promotional list, a ranking or ranking, or any combination thereof. Data processing system 102 may store data provided by content provider device 106 as content data 128 in data store 122. The data processing system 102 may retrieve the data and transmit the data to the client computing device 104. The data processing system 102 may select the digital audio component and provide the digital audio component (or instruct the content provider computing device 106 to provide the digital audio component) to the client computing device 104.
The data repository 122 may include one or more local or distributed databases and may include a database management system. Data store 122 may include a computer data store or memory and may store one or more policies 123, profiles 126, content data 128 or templates 130, and other data. Content data 128 may include digital components or associated metadata and input audio messages that may be part of one or more communication sessions with client computing device 104. The templates 130 may include data structures that may be used to communicate with the client computing device 104. Template 130 may include one or more placeholders that data processing system 102 may populate with, for example, content data 128, digital components, or other data. The profile 126 may include preference data provided by a user of the client computing device 104.
The data processing system 102 may include an application, script, or program installed at the client computing device 104, such as an app for communicating input audio signals to the interface 110 of the data processing system 102 and driving components of the client computing device 104 to render output audio signals. The data processing system 102 may receive data packets or other signals that include or identify an input audio signal. For example, data processing system 102 can execute or run NLP component 112 to receive and process input audio signals received from client computing device 104.
By comparing the input signal to a stored set of representative audio waveforms and selecting the closest match, the NLP component 112 can convert or parse the input audio signal into recognized text. A representative waveform may be generated across a large set of input signals. The user may provide some of the input signals. Once the audio signal is converted to recognized text, the NLP component 112 can match the text with words associated with actions that the system 100 can make, for example, via a learning phase. Via transducer 142, audio driver 144, or other components, client computing device 104 can provide input audio signals to data processing system 102 (e.g., via network 105), where the input audio signals can be received (e.g., through interface 110) and provided as content data 128 to NLP component 112 or stored in data store 122.
The NLP component 112 may obtain an input audio signal. From the input audio signal, the NLP component 112 can identify at least one search request. The search request may include a trigger word (or phrase) and a request. The request may indicate an intention or topic of the input audio signal. The trigger key may indicate the type of action that may be taken. For the example input audio signal "I need a plumber," the NLP component 112 may parse the input audio signal to identify the trigger phrase as "I need" and identify the request as "plumber. The NLP component 112 can determine that the user wants to perform a search for "thumb" based on the trigger phrase "I ned," requesting.
The content selector component 118 can select a plurality of responses based on the search request identified in the input audio signal. Content selector component 118 can select a response from data store 122, wherein the response can be stored as part of content data 128. Continuing with the example above, content selector component 118 can select a plurality of search results based on the search request identified by NLP component 112. For example, data processing system 102 may periodically perform web crawling to index and cache websites and other web-based content. Data processing system 102 may store the results of the indexing and caching as content data 128 in data store 122. Content selector component 118 can perform a search for content data 128 using the request (in the example above, "resume") as a key. Based on the search, the content selector component 118 can select a plurality of search results.
The content selector component 118 can select a search context for the search request. The content selector component 118 can assign a rank to each of the search results based on the search context. The search context may be a geographic area or location, a search preference, a search history, a usage history, or any combination thereof. For example, the content selector component 118 may use the geographic search context to select a plumber that is within a predetermined distance of the client computing device 104. The search context may be determined by information included in the audio input. For example, the packetized audio input, when transmitted to the data processing system 102, may include an IP address or other information that enables the data processing system 102 to determine the general area in which the client computing device 104 is located. The search context may be determined by information stored in profile 126. For example, a user of client computing device 104 may have established a profile 126 with data processing system 102 that provides search preferences to data processing system 102. The search context may be determined by information in the input audio signal that is identified by the NLP component 112. For example, if the input audio signal is "Find me a plumber in New York City (help me find plumber in New York City)", the NLP component 112 can identify "in New York City" as a search context and limit the search results to plumbers in New York City.
The search for possible response data may be performed by different data processing systems 102. For example, the content selector component 118 can interface with a separate data processing system 102 that performs the search via the direct action API 116. The direct action API 116 may convert the search request and search context into a file format that may be transmitted to the search data processing system 102. For example, the search request and search context may be converted to a URL in JSON format or encoded with data that is identified as requested by the search data processing system 102.
The attribute may be a characteristic, quality, metadata, or other information associated with the search results. For example, the attributes may include store or other address, bid, business hours, downtime, license, certificate, service, expertise, capability, or rank associated with the search results. For example and continuing with the above example of a search for a plumber, the attributes may include the plumber's address, an indication of whether the plumber provided a promotion, an identification of a plumber's license or professional certification, and an indication of whether the plumber is insured.
The attribute selector component 113 can collect attributes for each of the search results during an indexing and caching process performed by a web crawler of the data processing system. For each potential search result processed by the web crawler, the web crawler may identify HTML tags or other meta tags. For example, the owner of a web page crawled as a possible search result may indicate business and outage times to data processing system 102 by appending the business and outage times to predetermined tags in the web page's HTML. The attribute selector component 113 can process text and other content of possible search results using machine learning algorithms to identify attributes. The data processing system 102 may also have an interface that enables an owner of a web page (e.g., the content provider device 106) to input attributes that the owner wants to be associated with the web page or search results.
The attribute selector component 113 can select one or more attributes for each of the search results for inclusion in a data structure that is transmitted to the client computing device 104 for rendering to an end user. The data structure may be included in a digital component that may be rendered to an end user at the client computing device 104 as an audio output signal. The attributes may become mental anchors (mental anchors) for the end user because each of the search results are presented to the user in an audible and sequential manner. To select a search result from the audio-based list, the user may provide a voice-based response indicating a particular search result (e.g., "Ok, select Bob's scrolling, inc. (good, select Bob's Plumbing limited)"), a location in the search result list (e.g., "Ok, select the third plumber (good, select third plumber)") or an attribute (e.g., "Ok, select the plumber that is open all hours a day (good, select 24hours a plumber)"). For example, attribute selector component 113 may select "open 24hours a day" as an attribute of a first search result and "located 2 mils away" as an attribute of a second search result. In this example, the digital component rendered at the client computing device 104 in response to the user's input audio signal "I need a resume" may be "I found Plumber A, whish is open 24hours a day and Plumber B,which is located 2miles away" (I find plumber a and plumber B located 2miles away for 24hours a day). The user may select to be one of the search results of PLUMBER A by providing a voice-based input such as "Ok, select PLUMBER A (good, select Water Confucius A)" or "Ok, select the one open hours a day (good, select 24hours of business one day)".
The attribute selector component 113 can select which one or more attributes to include in a data structure that includes one or more selected attributes for each search result. The data structure may be incorporated into the digital component. The selection of the attributes by the attribute selector component may be based on the weighting of each of the different attributes. The attribute selector component 113 can select a first weight based on the search context and can select a second weight based on the client device context. For each attribute, the attribute selector component 113 can use the weighting to generate a score for each of the respective attributes. The attribute selector component 113 can rank the attributes based on the score and can select the attributes to include in the data structure based on the ranking. The search context weighting of the search results may be based on the relevance of the attribute to the search request, the uniqueness of the attribute (e.g., how many other search results have the same attribute), the similarity of the attribute to other attributes, or the ranking of the search results. The weighting based on the client device context may be based on preferences of a user providing the input audio signal to the client computing device 104 or based on actions of a community of users. For example, the weighting based on the user search context may be based on defined user preferences, implicit user preferences, past user selections, or client computing device 104 location information.
If one or more attributes correspond to an attribute of another search result, attribute selector component 113 can remove the attribute from association with the search result. When the values of the attributes substantially match each other (for example, two attributes have values of "Open 24hours a day"), have values that have similar meanings but do not completely match each other (for example, "Open 24hours a day" and "Open all day), or are of the same type (for example," Open 24hours a day "and" Open 9to 5 (9 to 5 place business) "are both of the" business time "type), the attributes may correspond to each other. The content selector component 118 can rank the search results. Based on the search result ranking, attribute selector component 113 can select an attribute for each search result. When removing attributes, the attribute selector component 113 can first select one or more attributes for the highest ranked search result before selecting the attribute for the next highest ranked search result. Once the attribute selector component 113 selects an attribute for a search result, the attribute selector component 113 may not select the attribute selected for a higher ranked search result for a lower ranked search result. For example, assume that both the search results of Plumber A and Plumber B have the attribute "Open 24hours a day" as their respective highest ranked attributes, and that the search results of Plumber A have a higher search ranking than the search results of Plumber B. In this example, the attribute selector component 113 can select "Open 24hours a day" as an attribute for Plumber A, and a different attribute for Plumber B, even if the selected attribute is a lower ranked attribute for Plumber B's search results.
When the attribute selector component 113 then selects an attribute for each of the search results after ranking the search results, the attribute selector component 113 can apply a penalty to the attribute (e.g., by applying a low or negative weight or adjusting an existing weight) if an attribute is selected for a higher ranked search result, rather than removing the selected attribute. For example, if a business hours attribute is selected for the highest ranked search result, a penalty may be given to the business hours attribute of the lower ranked search result to reduce the likelihood that the attribute will also be selected for the lower ranked search result. Because each attribute may have multiple weights, the attribute selector component 113 can select an attribute with a penalty if the other weights of the attributes are relatively high enough to compensate for the penalty.
For each search result, attribute selector component 113 can combine the weights to generate a score. Weighting may positively or negatively affect the score of an attribute. For example, to rank and select attributes for each of the search results that are important to the user, the uniqueness of the attributes may positively impact the score of the attributes. The attributes of the search results may be unique when the attributes of other search results do not have the same attributes or have different values for a given attribute. For example, the location attributes of each of the plumber's search results in a given city may not be unique (or similar to each other) because each of the plumber's returned search results may be located in the same city or geographic area. The time attribute of the plumber's search results may be unique, for example, if the attribute indicates that the plumber is operating 24 hours a day, and the time attribute of the other returned search results indicates that the corresponding plumber's operating hours are between 9 am and 5 pm.
The data processing system 102 can include an audio signal generator component 120. The audio signal generator component 120 can generate or otherwise obtain an output signal that includes or incorporates the data structure generated by the attribute selector component 113. The audio signal generator component 120 can incorporate data structures into the digital components. The digital component may include a data structure indicating search results and attributes selected for each of the respective search results. The interface 110 of the data processing system 102 may provide or transmit one or more data packets comprising digital components as output signals to the client computing device 104 via the computer network 105. In some implementations, the data processing system 102 can transmit the data structure to the client computing device 104, which client computing device 104 incorporates the data structure in the digital component.
The data processing system 102 can provide output signals from the data store 122 or from the audio signal generator component 120 to the client computing device 104. Interface 110 may be a hardware interface, such as a network port data port or a radio station, that enables data processing system 102 to receive and transmit data. The interface 110 may be graphics-based. For example, interface 110 may be a graphical user interface that enables a user to input data or otherwise interact with data processing system 102. The data processing system 102 may also instruct the content provider computing device 106 to provide the output signal to the client computing device 104 via data packet transmission. The output signals may be obtained, generated, converted, or transmitted as one or more data packets (or other communication protocols) from the data processing system 102 (or other computing device) to the client computing device 104.
The output signals corresponding to the digital components, e.g., output signals obtained or generated by the audio signal generator component 120 for transmission to the client computing device 104 via the interface 110 and the computer network 105, may cause the client computing device 104 to execute the audio driver 144 to drive the speaker 146 to generate sound waves corresponding to the output signals. The sound waves may include words corresponding to the digital components. When the digital component includes an image or text, the client computing device 104 may display the image or text on a display of the client computing device 104.
FIG. 2 illustrates a flow chart of an example method 200 of selecting attributes for search results. The method 200 may include receiving an input signal (ACT 202). The method 200 may include parsing an input signal (ACT 204). The method 200 may include selecting search results (ACT 206). The method 200 may include selecting an attribute (ACT 208). The method 200 may include determining weights (ACT 210). The method 200 may include generating a data structure (ACT 212). The method 200 may include transmitting the digital component (ACT 214).
As described above, the method 200 may include receiving an input signal (ACT 202). Additionally, referring to fig. 1, etc., the input signal may be an audio-based input signal received from the client computing device 104 at the interface 110 of the data processing system 102. For example, a user of the client computing device 104 may ask questions as audio input to the client computing device 104. The transducer 142 (e.g., microphone) of the client computing device 104 may detect the audio input and convert the audio input into a digitized signal. The pre-processor 148 may perform initial audio filtering of the digitized signal. Client computing device 104 may group the digitized signals and transmit the signals as input signals to interface 110 of data processing system 102.
The method 200 may include parsing an input signal (ACT 204). The NLP component 112 executed by the data processing system 102 can parse the input signal to identify a search request in the input signal. The NLP component 112 can identify a trigger key in the input signal that can indicate an action associated with the search request.
The method 200 may include selecting search results (ACT 206). Content selector component 118 can select one or more search results based on the search request identified by NLP component 112. For example, the search request "I need a web," the content selector component 118 can perform a search of web pages stored as an index of content data 128 to identify web pages for a plurality of different plumbers. The content selector component 118 can rank the search results. For example, search results may be ranked based on an identification of the importance of each web page. The importance of a web page may be based on the number of times other web pages include links to the web page. The content selector component 118 can select search results from among search results returned from the search data processing system via the direct action API 116.
The method 200 may include selecting an attribute (ACT 208). The attribute selector component 113 can select one or more attributes for each of the search results identified by the content selector component 118. The attribute may be a characteristic, quality, metadata, or other information associated with the search results. For example, the attributes may include store or other address, bid, business hours, downtime, license, certificate, service, expertise, capability, or rank associated with the search results.
The method 200 may include determining a weighting of the attributes (ACT 210). The attribute selector component 113 can determine a plurality of weights for each of the attributes. For example, the attribute selector component 113 can determine a first weight associated with the search context and a second weight associated with the client device context. The attribute selector component 113 can determine a score based on each of a plurality of weights.
For example, and with reference to FIG. 3, etc., the content selector component 118 can determine a plurality of search results 301. Fig. 3 illustrates a block diagram of a ranking of search results 301 converted to a data structure. The content selector component 118 can rank the search results 301 and generate a ranked list of search results from search result (1) to search result (2) and to search result (n), where n is the number of search results. For each attribute 302, the attribute selector component 113 can determine a first weight 304 (1) and a second weight 304 (2), which can be generally referred to as weights 304. The attribute selector component 113 can determine more than 2 weights 304. For example, for each of a plurality of user preferences, the attribute selector component 113 can determine a different weighting 304 that maps the attribute to each of the user preferences.
The attribute selector component 113 can select one or more attributes for each of the search results to include in the data structure. To select the attributes, the attribute selector component 113 can generate a score 303 for each of the attributes. The score 303 for a given attribute 302 may be based on a weighting 304. For example, the attribute selector component 113 can sum, average, or otherwise combine each of the weights 304 for a given attribute 302 to calculate a score 303 for that attribute 302. For each search result, the attribute selector component 113 can select a predetermined number of attributes with the highest score. For example, the attribute selector component 113 can select the two attributes 302 with the highest scores to incorporate into the data structure 305.
The weighting 304 may be a ranking based on the search results 301. Once the search results 301 are ranked, the attribute selector component 113 can adjust or assign weights based on the search rankings. For example, for each subsequent search result 301 lower in the search ranking list, the attribute selector component 113 can assign a smaller weight to the attribute 302 of that search result than for the attribute 302 of the higher ranked search result 301.
In some implementations, the weighting based on the search result ranking is applied based on both the value of the attribute 302 and the search result ranking. For example, an attribute may be penalized or weighted lower for a lower ranked search result only when that attribute is selected for the higher ranked search result. For example, if the plumber's highest ranked search result has an "open 24hrs a day" business hours attribute and the plumber's second highest ranked search result has an "open on weekends" business hours attribute, then the attribute selector component 113 may not penalize the lower ranked search result's business hours attribute because the value of the attribute is different from the value of the higher ranked search result's business hours attribute.
The method 200 may include generating a data structure (ACT 212). In addition, referring to FIG. 3, etc., the data structure 305 may include each of the search results 301. The data structure 305 may include one or more attributes 302 for each of the search results 301. The attribute selector component 113 can determine which attributes are associated with a given search result 301 for inclusion in a data structure. For example, selection of a respective attribute 302 may be based on a ranking of the attribute 302 by the associated score 303 and a ranking of the search result 301 by the content selector component 118.
The attribute selector component 113 can also select a number of attributes 302 to include for each of the search results 301. The attribute selector component 113 can select the same number for each of the search results 301. For example, the attribute selector component 113 can select a single attribute 302 for each of the search results 301. The attribute selector component 113 can select a different number for each of the attributes 302. For example, the attribute selector component 113 can select a greater number of attributes 302 for higher ranked ones 301 of the search results to include in the data structure 305. The determination of the number of attributes to include in the data structure 305 by the attribute selector component 113 can be based on a client device context or a search context. The data processing system 102 can determine a client device context based on the device type of the client computing device 104. For example, when the device type is a mobile device, the attribute selector component 113 can select fewer attributes, and when the device type is a home-based speaker system, can select more attributes.
In some implementations, the attribute selector component 113 can include a rendering format for each attribute 302 in the data structure 305. The rendering format may indicate whether the attribute 302 should be included in an audio-based output, an image-based output, or a combination thereof. For example, if the client computing device 104 includes speakers and a screen. The attribute selector component 113 can indicate in the data structure that the highest scoring attribute for each search result should be included in the audio-based output, while other attributes should be displayed on the screen of the client computing device.
The audio signal generator component 120 can incorporate the data structure 305 into the digital component. The digital component may be a search results page, web page, audio-based file, or other type of content item. The digital component may include instructions for how the client computing device 104 should render the data structure. For example, the digital components may include templates that include the order, layout, language, voice, or other information that the client computing device 104 should use to render the data structure.
The method 200 may include transmitting a data structure (ACT 214). Data processing system 102 may transmit the data structure to client computing device 104 via network 105. Data processing system 102 may transmit the data structure in digital components to client computing device 104. In response to receiving the data structure, the client computing device 104 may render the data structure (or a digital component comprising the data structure) to a user of the client computing device 104. Rendering the data structure may include visually displaying an image and/or generating an output audio signal based on the content of the data structure.
Fig. 4 is a block diagram of an example computer system 400. Computer system or computing device 400 may include or be used to implement system 100 or components thereof, such as data processing system 102. Computing system 400 includes a bus 405 or other communication component for communicating information, and a processor 410 or processing circuit coupled to bus 405 for processing information. Computing system 400 may also include one or more processors 410 or processing circuits coupled to a bus to process information. Computing system 400 also includes a main memory 415, such as a Random Access Memory (RAM) or other dynamic storage device, coupled to bus 405 for storing information and instructions to be executed by processor 410. Main memory 415 may be or include data store 122. Main memory 415 also may be used for storing location information, temporary variables, or other intermediate information during execution of instructions by processor 410. Computing system 400 may also include Read Only Memory (ROM) 420 or a static storage device coupled to bus 405 for storing static information and instructions for processor 410. A storage device 425, such as a solid state device, magnetic disk, or optical disk, may be coupled to bus 405 for storing information and instructions continuously. Storage 425 may include or be part of data store 122.
The computing system 400 may be coupled via bus 405 to a display 435, such as a liquid crystal display or an active matrix display, to display information to a user. An input device 430, such as a keyboard including alphanumeric and other keys, may be coupled to bus 405 for communicating information and command selections to processor 410. The input device 430 may include a touch screen display 435. The input device 430 may also include a cursor control, such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to the processor 410 and for controlling cursor movement on the display 435. For example, display 435 may be part of data processing system 102, client computing device 104, or other component of fig. 1.
The processes, systems, and methods described herein may be implemented by computing system 400 in response to processor 410 executing an arrangement of instructions contained in main memory 415. Such instructions may be read into main memory 415 from another computer-readable medium, such as storage device 425. Execution of the arrangement of instructions contained in main memory 415 causes computing system 400 to perform the illustrative processes described herein. One or more processors in a multi-processing arrangement may also be employed to execute the instructions contained in main memory 415. Hardwired circuitry may be used in place of or in combination with software instructions to implement the systems and methods described herein. The systems and methods described herein are not limited to any specific combination of hardware circuitry and software.
Although an example computing system has been described in FIG. 4, the subject matter comprising the operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures and structural equivalents disclosed in this specification, or in combinations of one or more of them.
For the case where the system discussed herein gathers personal information about a user or may use personal information, the user may be provided with the following opportunities: whether or not the control program or feature can collect personal information (e.g., information about the person's social network, social behavior or activity, the user's preferences, or the user's location), or whether or how to receive content from a content server or other data processing system that may be more relevant to the user. In addition, certain data may be anonymized in one or more ways prior to storage or use to remove personally identifiable information when generating parameters. For example, the identity of the user may be anonymized so that no personally identifiable information can be determined for the user, or the geographic location of the user may be generalized (such as to a city, zip code, or state level) where location information is obtained so that a particular location of the user cannot be determined. Thus, the user can control how information is collected about him or her and how the information is used by the content server.
The subject matter and operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. The subject matter described in this specification can be implemented as one or more computer programs, e.g., one or more circuits of computer program instructions, encoded on one or more computer storage media for execution by, or to control the operation of, data processing apparatus. Alternatively or additionally, the program instructions may be encoded on a manually generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus. The computer storage medium may be or be included in a computer readable storage device, a computer readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Although the computer storage medium is not a propagated signal, the computer storage medium may be a source or destination of computer program instructions encoded with an artificially generated propagated signal. The computer storage media may also be or be included in one or more separate components or media (e.g., multiple CDs, disks, or other storage devices). The operations described in this specification may be implemented as operations performed by a data processing apparatus on data stored on one or more computer readable storage devices or received from other sources.
The terms "data processing system," "computing device," "component," or "data processing apparatus" encompass a variety of devices, apparatuses, and machines for processing data, including, for example, a programmable processor, a computer, a system on a chip, or a combination of more or the foregoing. The apparatus may comprise a dedicated logic circuit, for example an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit). In addition to hardware, the apparatus may include code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment may implement a variety of different computing model infrastructures, such as web services, distributed computing, and grid computing infrastructures. The direct action API 116, content selector component 118, attribute selector component 113, or NLP component 112, as well as other data processing system 102 components, can include or share one or more data processing apparatuses, systems, computing devices, or processors.
A computer program (also known as a program, software application, app, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. The computer program may correspond to a file in a file system. A computer program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store portions of one or more modules, sub-programs, or code). A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs (e.g., components of data processing system 102) to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
The subject matter described herein may be implemented in a computing system including: a back-end component, e.g., as a data server; or middleware components, such as application servers; or a front-end component, e.g., a client computer having a graphical user interface or web browser through which a user may interact with embodiments of the subject matter described in this specification; or a combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include local area networks ("LANs") and wide area networks ("WANs"), internets (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing systems described herein may include clients and servers. The client and server are typically remote from each other and typically interact through a communication network (e.g., network 105). The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some implementations, the server transmits data (e.g., data packets representing the data components) to the client computing device (e.g., for the purpose of displaying data to and receiving user input from a user interacting with the client computing device). Data generated at the client computing device (e.g., results of the user interaction) may be received from the client computing device at the server (e.g., received by the data processing system 102 from the client computing device 104 or the content provider computing device 106).
Although operations are depicted in the drawings in a particular order, such operations need not be performed in the particular order shown or in sequential order, and not all illustrated operations need be performed. The acts described herein may be performed in a different order.
The separation of individual system components does not require separation in all embodiments, and the described program components can be included in a single hardware or software product. For example, NLP component 112, content selector component 118, or attribute selector component 113 can be a single component, app or program, or part of one or more servers having one or more processing circuit logic devices, or data processing system 102.
Having now described some illustrative embodiments, it should be apparent that the foregoing has been presented by way of example and not limitation. In particular, although many of the examples presented herein involve specific combinations of method acts or system elements, those acts and those elements may be combined in other ways to achieve the same objectives. Acts, elements and features discussed in connection with one embodiment are not intended to be excluded from a similar role in other embodiments or embodiments.
The phraseology and terminology used herein is for the purpose of description and should not be regarded as limiting. The use of "including," "comprising," "having," "containing," "involving," "characterized by" and variations thereof herein is meant to encompass the items listed thereafter and equivalents thereof as well as additional items and alternative embodiments consisting solely of the items listed thereafter. In one embodiment, the systems and methods described herein consist of one, more than one, each, or all of the elements, acts, or components described.
Any reference to an embodiment or element or act of a system and method recited in the singular and proceeded with the word "a" or "an" may also encompass embodiments comprising plural of such elements, and any reference to any embodiment, or element or act, herein plural, may also encompass embodiments comprising only a single element. Singular or plural references are not intended to limit the presently disclosed systems or methods, their components, acts, or elements to a single or multiple configurations. References to any action or element based on any information, action or element may include embodiments in which the action or element is based at least in part on any information, action or element.
Any embodiment disclosed herein may be combined with any other embodiment or example, and references to "an embodiment," "some embodiments," "one embodiment," etc., are not necessarily mutually exclusive, and are intended to indicate that a particular feature, structure, or characteristic described in connection with the embodiment may be included in at least one embodiment or example. Such terms as used herein do not necessarily all refer to the same embodiment. Any embodiment may be combined with any other embodiment, either inclusive or exclusive, in any manner consistent with aspects and embodiments disclosed herein.
Reference to "or" may be construed as inclusive such that any term described using "or" may indicate any one of a single, more than one, and all of the described terms. For example, references to "at least one of a 'and B' may include" a "only," B "only, and both" a "and" B ". Such references, used in conjunction with "comprising" or other open terms, may include additional items.
Where technical features in the drawings, detailed description, or any claim are followed by reference signs, the reference signs have been included to increase the intelligibility of the drawings, detailed description, and claims. Accordingly, neither the reference signs nor the absence thereof have any limiting effect on the scope of any claim elements.
The systems and methods described herein may be embodied in other specific forms without departing from the characteristics thereof. The foregoing embodiments are illustrative and not limiting of the systems and methods described. The scope of the systems and methods described herein are, therefore, indicated by the appended claims rather than by the foregoing description, and all changes which come within the meaning and range of equivalency of the claims are therefore intended to be embraced therein.
Claims (20)
1. A system for providing digital components in a voice activated system, comprising:
a natural language processor component, the natural language processor component being executed by a data processing system to:
receiving an input audio signal via an interface; and
parsing the input audio signal to identify a first search request in the input audio signal;
a content selector component that is executed by the data processing system to select a plurality of search results based on the first search request;
an attribute selector component, the attribute selector component being executable by the data processing system to:
determining a search context for the first search request;
determining a plurality of attributes including information associated with each of the plurality of search results;
Determining a first weight for each of the plurality of attributes of each of the plurality of search results based on the search context;
determining a second weight for each of the plurality of attributes of each of the plurality of search results based on the client device context; and
selecting, for each of the plurality of search results, a subset of attributes from the plurality of attributes based on the first weighting for each of the plurality of attributes of each of the plurality of search results and the second weighting for each of the plurality of attributes of each of the plurality of search results; and
an audio signal generation component, the audio signal generation component being executed by the data processing system to:
generating a digital component comprising a data structure having, for each of the plurality of search results, a selected subset of attributes from each of the plurality of attributes based on the first weighting for each of the plurality of attributes for each of the plurality of search results and the second weighting for each of the plurality of attributes for each of the plurality of search results; and
The digital component is transmitted to a client device via the interface in response to the input audio signal.
2. The system of claim 1, comprising the data processing system:
ranking the plurality of search results; and
a third weighting for the plurality of attributes is generated based on the ranking of the plurality of search results.
3. The system of claim 1, comprising the data processing system:
assigning a first rank to a first search result of the plurality of search results;
assigning a second rank to a second search result of the plurality of search results;
determining that the first one of the plurality of search results has a first attribute corresponding to a first attribute of the second one of the plurality of search results; and
a penalty weighting is applied to the first attribute of the second one of the plurality of search results based on the first attribute of the plurality of search results corresponding to the first attribute of the second one of the plurality of search results.
4. The system of claim 1, comprising the data processing system:
Assigning a first rank to a first search result of the plurality of search results;
assigning a second rank to a second search result of the plurality of search results;
determining that the first one of the plurality of search results has a first attribute corresponding to a first attribute of the second one of the plurality of search results; and
the first attribute of the second one of the plurality of search results is removed from the data structure based on the first attribute of the plurality of search results corresponding to the first attribute of the second one of the plurality of search results.
5. The system of claim 1, comprising the data processing system:
ranking the plurality of attributes for each of the plurality of search results;
ranking the plurality of search results; and
a score for the plurality of attributes for each of the plurality of search results is generated based on the ranking of the plurality of attributes for each of the plurality of search results and the ranking of the plurality of search results.
6. The system of claim 1, comprising the data processing system:
determining a number of attributes based on the client device context; and
the number of attributes for each of the plurality of search results is selected.
7. The system of claim 1, comprising the data processing system:
determining a number of attributes for each of the plurality of search results; and
the number of attributes for the plurality of search results is selected.
8. The system of claim 7, wherein the number of attributes for each of the plurality of search results is different.
9. The system of claim 1, wherein the plurality of properties can include an indication of an address, bid, business hours, downtime, license, certificate, service, expertise, capability, or level.
10. The system of claim 1, comprising the data processing system:
selecting a first rendering format for a selected attribute from the plurality of attributes; and
a second rendering format for a second selected attribute is selected, wherein the second rendering format is different from the first rendering format.
11. A method of providing digital components in a voice activated system, comprising:
receiving, by a natural language processor component executed by a data processing system, an input audio signal via an interface of the data processing system;
parsing, by the natural language processor component, the input audio signal to identify a first search request in the input audio signal;
selecting, by a content selector component executed by the data processing system, a plurality of search results based on the first search request;
determining, by an attribute selector component executed by the data processing system, a search context for the first search request;
determining, by the attribute selector component, a plurality of attributes including information associated with each of the plurality of search results;
determining, by the attribute selector component, a first weight for each of the plurality of attributes of each of the plurality of search results based on the search context;
determining, by the attribute selector component, a second weight for each of the plurality of attributes of each of the plurality of search results based on a client device context;
Selecting, by the attribute selector component, for each of the plurality of search results, an attribute subset from the plurality of attributes based on the first weighting for each of the plurality of attributes of each of the plurality of search results and the second weighting for each of the plurality of attributes of each of the plurality of search results;
generating, by an audio signal generator executed by the data processing system, a digital component comprising a data structure having, for each of the plurality of search results, a subset of attributes selected from each of the plurality of attributes based on the first weighting for each of the plurality of attributes for each of the plurality of search results and the second weighting for each of the plurality of attributes for each of the plurality of search results; and
transmitting, by the audio signal generator component, the digital component to a client device via the interface in response to the input audio signal.
12. The method of claim 11, comprising:
ranking the plurality of search results; and
a third weighting for the plurality of attributes is generated based on the ranking of the plurality of search results.
13. The method of claim 11, comprising:
assigning a first rank to a first search result of the plurality of search results;
assigning a second rank to a second search result of the plurality of search results;
determining that the first one of the plurality of search results has a first attribute corresponding to a first attribute of the second one of the plurality of search results; and
based on the first attribute of the plurality of search results corresponding to the first attribute of the second search result of the plurality of search results, a weighting of the first attribute of the second search result of the plurality of search results is adjusted.
14. The method of claim 11, comprising:
assigning a first rank to a first search result of the plurality of search results;
assigning a second rank to a second search result of the plurality of search results;
determining that the first one of the plurality of search results has a first attribute corresponding to a first attribute of the second one of the plurality of search results; and
The first attribute of the second one of the plurality of search results is removed from the data structure based on the first attribute of the plurality of search results corresponding to the first attribute of the second one of the plurality of search results.
15. The method of claim 11, comprising:
ranking the plurality of attributes for each of the plurality of search results;
ranking the plurality of search results; and
a score for the plurality of attributes for each of the plurality of search results is generated based on the ranking of the plurality of attributes for each of the plurality of search results and the ranking of the plurality of search results.
16. The method of claim 11, comprising:
determining a number of attributes based on the client device context; and
the number of attributes for each of the plurality of search results is selected.
17. The method of claim 11, comprising:
determining a number of attributes for each of the plurality of search results; and
The number of attributes for the plurality of search results is selected.
18. The method of claim 17, wherein the number of attributes for each of the plurality of search results is different.
19. The method of claim 11, wherein the plurality of properties may include an indication of an address, bid, business hours, downtime, license, certificate, service, expertise, capability, or level.
20. The method of claim 11, comprising:
selecting a first rendering format for a selected attribute from the plurality of attributes; and
a second rendering format for a second selected attribute is selected, wherein the second rendering format is different from the first rendering format.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/914,949 US10896213B2 (en) | 2018-03-07 | 2018-03-07 | Interface for a distributed network system |
US15/914,949 | 2018-03-07 | ||
PCT/US2018/049782 WO2019172954A1 (en) | 2018-03-07 | 2018-09-06 | Interface for a distributed network system |
Publications (2)
Publication Number | Publication Date |
---|---|
CN111344694A CN111344694A (en) | 2020-06-26 |
CN111344694B true CN111344694B (en) | 2023-06-06 |
Family
ID=63794603
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201880069402.3A Active CN111344694B (en) | 2018-03-07 | 2018-09-06 | Interface for distributed network system |
Country Status (4)
Country | Link |
---|---|
US (1) | US10896213B2 (en) |
EP (1) | EP3685277A1 (en) |
CN (1) | CN111344694B (en) |
WO (1) | WO2019172954A1 (en) |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20200394351A1 (en) * | 2018-02-07 | 2020-12-17 | Incucomm, Inc. | Operations and maintenance systems and methods employing sensor-less digital twins |
US20190243933A1 (en) * | 2018-02-07 | 2019-08-08 | Incucomm, Inc. | System and method that characterizes an object employing virtual representations thereof |
US11347756B2 (en) * | 2019-08-26 | 2022-05-31 | Microsoft Technology Licensing, Llc | Deep command search within and across applications |
US11900046B2 (en) | 2020-08-07 | 2024-02-13 | Microsoft Technology Licensing, Llc | Intelligent feature identification and presentation |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN104795067A (en) * | 2014-01-20 | 2015-07-22 | 华为技术有限公司 | Voice interaction method and device |
Family Cites Families (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6999932B1 (en) | 2000-10-10 | 2006-02-14 | Intel Corporation | Language independent voice-based search system |
US20170237801A1 (en) * | 2004-06-30 | 2017-08-17 | Google Inc. | Device configuration-based function delivery |
US20080005068A1 (en) | 2006-06-28 | 2008-01-03 | Microsoft Corporation | Context-based search, retrieval, and awareness |
US20080071544A1 (en) | 2006-09-14 | 2008-03-20 | Google Inc. | Integrating Voice-Enabled Local Search and Contact Lists |
US9183312B2 (en) * | 2012-03-20 | 2015-11-10 | Google Inc. | Image display within web search results |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US10055462B2 (en) * | 2013-03-15 | 2018-08-21 | Google Llc | Providing search results using augmented search queries |
US9760608B2 (en) * | 2013-11-01 | 2017-09-12 | Microsoft Technology Licensing, Llc | Real-time search tuning |
US20170092278A1 (en) | 2015-09-30 | 2017-03-30 | Apple Inc. | Speaker recognition |
US9747926B2 (en) | 2015-10-16 | 2017-08-29 | Google Inc. | Hotword recognition |
US9928840B2 (en) | 2015-10-16 | 2018-03-27 | Google Llc | Hotword recognition |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
-
2018
- 2018-03-07 US US15/914,949 patent/US10896213B2/en active Active
- 2018-09-06 EP EP18783170.6A patent/EP3685277A1/en not_active Withdrawn
- 2018-09-06 WO PCT/US2018/049782 patent/WO2019172954A1/en unknown
- 2018-09-06 CN CN201880069402.3A patent/CN111344694B/en active Active
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN104795067A (en) * | 2014-01-20 | 2015-07-22 | 华为技术有限公司 | Voice interaction method and device |
Also Published As
Publication number | Publication date |
---|---|
CN111344694A (en) | 2020-06-26 |
WO2019172954A1 (en) | 2019-09-12 |
US10896213B2 (en) | 2021-01-19 |
EP3685277A1 (en) | 2020-07-29 |
US20190347356A1 (en) | 2019-11-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10535348B2 (en) | Multimodal transmission of packetized data | |
CN111344694B (en) | Interface for distributed network system | |
KR102603717B1 (en) | Generation of domain-specific models in networked systems | |
JP2020129145A (en) | Modulation of packetized audio signal | |
US11848009B2 (en) | Adaptive interface in a voice-activated network | |
CN115210692A (en) | Interface and mode selection for digital motion execution | |
CN110692040A (en) | Activating remote devices in a network system | |
CN110149810B (en) | Transmission system and method for limiting manipulation of content in a network environment and digital assistant device | |
US11798555B2 (en) | Detection of duplicate packetized data for selective transmission into one of a plurality of a user's devices | |
CN111213136B (en) | Generation of domain-specific models in networked systems |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |