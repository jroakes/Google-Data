EP2780834A1 - Data processing service - Google Patents
Data processing serviceInfo
- Publication number
- EP2780834A1 EP2780834A1 EP12795212.5A EP12795212A EP2780834A1 EP 2780834 A1 EP2780834 A1 EP 2780834A1 EP 12795212 A EP12795212 A EP 12795212A EP 2780834 A1 EP2780834 A1 EP 2780834A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- data
- data center
- logical
- stored
- computing system
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000012545 processing Methods 0.000 title description 105
- 238000000034 method Methods 0.000 claims abstract description 235
- 238000005192 partition Methods 0.000 claims abstract description 159
- 230000010076 replication Effects 0.000 claims abstract description 35
- 230000004044 response Effects 0.000 claims description 59
- 230000003362 replicative effect Effects 0.000 claims description 25
- 238000003780 insertion Methods 0.000 claims description 4
- 230000037431 insertion Effects 0.000 claims description 4
- 238000003860 storage Methods 0.000 description 151
- 238000013500 data storage Methods 0.000 description 46
- 230000008569 process Effects 0.000 description 46
- 230000015654 memory Effects 0.000 description 45
- 230000008676 import Effects 0.000 description 33
- 238000010586 diagram Methods 0.000 description 20
- 230000002776 aggregation Effects 0.000 description 18
- 238000004220 aggregation Methods 0.000 description 18
- 238000004891 communication Methods 0.000 description 18
- 230000006870 function Effects 0.000 description 17
- 238000004458 analytical method Methods 0.000 description 15
- 230000007246 mechanism Effects 0.000 description 14
- 238000013499 data model Methods 0.000 description 11
- 238000002474 experimental method Methods 0.000 description 11
- 238000012546 transfer Methods 0.000 description 11
- 230000014509 gene expression Effects 0.000 description 10
- 238000007726 management method Methods 0.000 description 10
- 230000008901 benefit Effects 0.000 description 9
- 230000002452 interceptive effect Effects 0.000 description 9
- 238000004590 computer program Methods 0.000 description 8
- 230000008859 change Effects 0.000 description 7
- 238000011065 in-situ storage Methods 0.000 description 7
- 230000007704 transition Effects 0.000 description 7
- 230000009471 action Effects 0.000 description 5
- 230000004888 barrier function Effects 0.000 description 5
- 238000013523 data management Methods 0.000 description 5
- 230000008520 organization Effects 0.000 description 5
- 230000006837 decompression Effects 0.000 description 4
- 230000002829 reductive effect Effects 0.000 description 4
- 230000009286 beneficial effect Effects 0.000 description 3
- 239000000872 buffer Substances 0.000 description 3
- 230000006835 compression Effects 0.000 description 3
- 238000007906 compression Methods 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000036961 partial effect Effects 0.000 description 3
- 239000000047 product Substances 0.000 description 3
- 230000004931 aggregating effect Effects 0.000 description 2
- 230000001413 cellular effect Effects 0.000 description 2
- 238000006243 chemical reaction Methods 0.000 description 2
- 238000007405 data analysis Methods 0.000 description 2
- 238000012217 deletion Methods 0.000 description 2
- 230000037430 deletion Effects 0.000 description 2
- 230000001419 dependent effect Effects 0.000 description 2
- 238000011156 evaluation Methods 0.000 description 2
- 239000004615 ingredient Substances 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 238000005259 measurement Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000002085 persistent effect Effects 0.000 description 2
- 230000000717 retained effect Effects 0.000 description 2
- 239000007787 solid Substances 0.000 description 2
- 230000001360 synchronised effect Effects 0.000 description 2
- 230000009466 transformation Effects 0.000 description 2
- 238000000844 transformation Methods 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- 244000141353 Prunus domestica Species 0.000 description 1
- 239000008186 active pharmaceutical agent Substances 0.000 description 1
- 230000027455 binding Effects 0.000 description 1
- 238000009739 binding Methods 0.000 description 1
- 230000015556 catabolic process Effects 0.000 description 1
- 230000000295 complement effect Effects 0.000 description 1
- 238000010205 computational analysis Methods 0.000 description 1
- 230000001186 cumulative effect Effects 0.000 description 1
- 230000007423 decrease Effects 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 239000012634 fragment Substances 0.000 description 1
- 238000007373 indentation Methods 0.000 description 1
- 230000000670 limiting effect Effects 0.000 description 1
- 230000005012 migration Effects 0.000 description 1
- 238000013508 migration Methods 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000012544 monitoring process Methods 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 230000001902 propagating effect Effects 0.000 description 1
- 230000001172 regenerating effect Effects 0.000 description 1
- 238000013468 resource allocation Methods 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 238000001228 spectrum Methods 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 239000004753 textile Substances 0.000 description 1
- 238000010200 validation analysis Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/23—Updating
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/22—Indexing; Data structures therefor; Storage structures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/22—Indexing; Data structures therefor; Storage structures
- G06F16/2282—Tablespace storage structures; Management thereof
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/23—Updating
- G06F16/235—Update request formulation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2455—Query execution
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/248—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/27—Replication, distribution or synchronisation of data between databases or within a distributed database system; Distributed database system architectures therefor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/27—Replication, distribution or synchronisation of data between databases or within a distributed database system; Distributed database system architectures therefor
- G06F16/275—Synchronous replication
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/90335—Query processing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/41—Compilation
- G06F8/45—Exploiting coarse grain parallelism in compilation, i.e. parallelism between groups of instructions
- G06F8/453—Data distribution
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F7/00—Methods or arrangements for processing data by operating upon the order or content of the data handled
Definitions
- the present disclosure generally relates to replication of data among computing devices and large-scale analytical data processing.
- data processing has become widespread in web companies and across industries, not least due to low-cost storage that enabled collecting vast amounts of business- critical data.
- Putting this data at the fingertips of analysts and engineers has grown increasingly important; interactive response times often make a qualitative difference in data exploration, monitoring, online customer support, rapid prototyping, debugging of data pipelines, and other tasks.
- Performing interactive data analysis at scale demands a high degree of parallelism. For example, reading one terabyte of compressed data in one second using today's commodity disks may require tens of thousands of disks. Similarly, CPU-intensive queries may need to run on thousands of cores to complete within seconds.
- a data processing service is herein disclosed.
- the described service provides a scalable, interactive ad-hoc query system for analysis of nested data.
- the described system and methods is capable of running rapid and efficient queries such as aggregation queries.
- a columnar storage representation for nested records a prevalent data model that may be used in many web-scale and scientific datasets, is described.
- a record is decomposed into column stripes, each column encoded as a set of blocks, each block containing field values and repetition and definition level information.
- Level information is generated using a tree of field writers, whose structure matches the field hierarchy in the record schema.
- the record can be assembled from the columnar data efficiently using a finite state machine that reads the field values and level information for each field and appends the values sequentially to the output records.
- a finite state machine can be constructed that accesses a limited amount of data fields in all or a portion of the records (e.g., a single data field in all of the records).
- additional metadata such as constraint information with the columnar storage representation, additional types of queries can be supported.
- a multi-level serving tree is used to execute queries.
- a root server receives an incoming query, reads metadata from the tables, and routes the queries to a next level in the serving tree.
- Leaf servers communicate with a storage layer or access the data on local storage, where the stored data can be replicated, and read stripes of nested data in the columnar representation.
- Each server can have an internal execution tree corresponding to a physical query execution plan, comprising a set of iterators that scan input columns and emit results of aggregates and scalar functions annotated with level information.
- a query dispatcher is provided which schedules queries based on their priorities and balances the load.
- the query dispatcher also provides fault tolerance when one server becomes much slower than others or as a replica becomes unreachable.
- the query dispatcher can compute a histogram of processing times for execution threads on the leaf servers and reschedule to another server when processing time takes a disproportionate amount of time.
- a web service may provide users remote access to the query system and a supporting data storage system. Users of the web service may upload data to the data storage system for hosted storage. A portion of uploaded data may include collections of nested records and may be stored as an object.
- the web service may provide remote data hosting for multiple users, allowing the multiple users to stream data to the web service and aggregate the data in a single location. Users may create tables on which to perform queries, and may import the data in one or more objects stored in the data storage system into the tables. The import process can include converting nested records in an object into columnar data, and storing the columnar data in a different data layer than the objects. Thus, from a user's perspective, a table may be filled with data from objects, but actually may instead reference underlying sets of columnar data. In this case, queries of the tables by web service users may cause the query system to query particular columns of data that underlie the tables.
- the columnar data may be queried in situ. Maintaining the columnar data on a common storage layer and providing mechanisms to assemble records from the columnar data enables operability with data management tools that analyze data in a record structure.
- the system may scale to numerous CPUs and be capable of rapidly reading large amounts of data.
- Particular embodiments can be implemented, in certain instances, to realize one or more of the following advantages.
- Nested data may be operated on in situ, such that the data may be accessed without loading the data with a database management system. Queries of nested data may be performed in a reduced execution time than required by other analysis programs.
- a columnar storage data structure that is implemented on a common storage layer enables multiple different analysis programs to access the columnar storage data structure.
- Figure 1 illustrates record-wise v. columnar representation of nested data.
- Figure 2 illustrates two sample nested records and their schema.
- Figure 3 illustrates column-striped representations of the sample nested records.
- Figure 4 is an algorithm for dissecting a record into columns.
- Figure 5 illustrates an automaton for performing complete record assembly.
- Figure 6 illustrates an automaton for assembly records from two fields, and the records that the automaton produces.
- Figure 7 is an algorithm for constructing a record assembly automaton.
- Figure 8 is an algorithm for assembling a record from columnar data.
- Figure 9 depicts a sample query that performs projection, selection, and within-record aggregation.
- Figure 10 illustrates a system architecture and execution inside a server node.
- Figure 1 1 is a table illustrating the datasets used in the experimental study.
- Figure 12 is a graph that illustrates the performance breakdown that may occur when reading from a local disk.
- Figure 13 is a graph that illustrates execution of both MapReduce and the described system on columnar v. record-oriented storage.
- Figure 14 is a graph that illustrates the execution time as a function of serving tree levels for two aggregation queries.
- Figure 15 is a graph that illustrates histograms of processing times.
- Figure 16 is a graph that illustrates execution time when the system is scaled from 1000 to 4000 nodes using a top-k query.
- Figure 17 is a graph that illustrates a percentage of processed tables as a function of processing time per tablet.
- Figure 18 is a graph that illustrates query response time distribution in a monthly workload.
- Figure 19 is a block diagram of a system for generating and processing columnar storage representations of nested records.
- Figure 20 is a flow chart of an example process for generating columnar data.
- Figure 21 is a block diagram illustrating an example of a system that implements a web service for data storage and processing.
- Figure 22 is a flowchart showing an example of a process for performing data storage and processing.
- Figure 23 shows a schematic diagram of an example computing system infrastructure.
- Figure 24 shows a schematic diagram of an example of data naming structure that may be used to support data replication.
- Figure 25 shows a schematic diagram of components that may be used to provide the data processing service.
- Figure 26 shows a schematic diagram of an example of the components stored within the global table and how these components relate to a user-generated table.
- Figure 27 is a schematic diagram showing examples of locally stored tables.
- Figure 28 is a flowchart showing an example of a process for reading data from a table with a query.
- Figure 29 is a flowchart showing an example of a process for inbound replication of data.
- FIGS. 30A-C show a swim-lane diagram illustrating an example of a process for writing and replicating data.
- Figure 31 is a block diagram of computing devices that may be used to implement the systems and methods described in this document, as either a client or as a server or plurality of servers.
- This document describes techniques, methods, systems, and mechanisms for a data storage and processing service.
- the described system may generate and process columnar storage representations of nested records.
- an organization may store data from web pages in records of nested information.
- the nested information may be compiled in a columnar data storage format that enables efficient queries of the data using a multi-level execution tree.
- the columnar data may be re-assembled into records for input into analysis programs that operate on record-oriented data.
- each record may be an instantiation of a schema that defines a formatting of records, where the records are created in accordance with the schema.
- a schema may identify various fields for storing information about a web page and a structure for organizing fields in a record and their corresponding values.
- the record may include for each field a data element and a corresponding value.
- the data element may define the semantics of the value in accordance with a definition in the schema.
- the term data element and field may be used interchangeably in this document. Field may also refer to a combination of a data element and a corresponding value.
- a particular record may need not include all of the fields that are defined by a schema.
- the schema may serve as a 'template' from which fields may be selected for the particular record.
- the schema may include a field for defining information about video content in a web page. If a web page does not include video content, then the record corresponding to the web page may not include the field from the schema that defines information about videos on the web page. Thus, some of the fields may be Optional.'
- a 'required' field in the schema may be a Uniform Resource Locator (URL) of a source location for the document that served the web page.
- the field may be required because every web page document may be retrieved from a source location (i.e., there is a URL available for every document) and because the field may be required to further process information on the web page (e.g., to determine if the content has changed).
- URL Uniform Resource Locator
- a field may also be 'repeatable.
- a field that is in the schema and that is defined as repeatable may be replicated at the location defined by the schema repeatedly in a instantiation of the schema (i.e., in a record).
- a schema may include a field that is for defining documents that link to the web page. The schema may only specify the field a single time, but may indicate that the field is repeatable (e.g., because several documents may link to a particular web page).
- a record for the web page may include multiple fields that identify a value for a linking web page. The repeated fields may be located at a same level and nested beneath a parent field in the record (as discussed in more detail below).
- the fields of the schema may be nested.
- some fields may be children of other fields, which may be referenced as the parent fields, grandparent fields, etc.
- children nodes are those nodes in the schema that are found within a pair of opening and closing curly brackets immediately following the parent node.
- Other implementations for nesting may be utilized (e.g., the use of a start tag for the field and an end tag for the field).
- each field may have a parent field.
- the schema may include a 'Video' field.
- the 'Video' field may include several children fields that may identify the characteristics of the video (e.g., how long the video is, the format of the video, and the resolution of the video).
- children nodes may not be placed in the record if their parent nodes are not present.
- a record for a web page that does not include a video may not include a 'VideoLength' field because the record does not include a 'Video' field (i.e., the parent of the 'VideoLength' field).
- Application programs that enable viewing and editing a record may visually nest the dependent children off of the parent children (e.g., indent the children to the right of the parent field).
- Analyzing millions of records may be time consuming.
- a user is interested in a data from a single field, but each of the records must be accessed in its entirety.
- a user may request that an analysis program check each of millions of records to identify those records that are associated with web pages that include videos that are longer than ten minutes and that have a 'High' resolution.
- each record may be stored as a separate data structure, each entire record may need to be loaded into a database management system in order to query the record to determine if the record includes the particular combination of video length and resolution.
- a field in a record may be identified by its path, which may include a listing of the field and the parent fields (e.g., GrandParent.Parent.Child). Because one or more of the fields in the path may be repeating, there may be several instances of a field with the same path name. Thus, when looking at a
- a mechanism is needed to identify which values belong to which records, and for those records that include multiple values for a particular path, what is the respective location of the value in the record. In other words, given a sequence of values in a columnar structure, a mechanism is needed to reconstruct the structure of the record from the values.
- the mechanism for reconstructing the structure of a record from columnar data includes storing, for each value in the columnar data, a 'repetition' level and a 'definition' level.
- Each 'level' is a sequence of bits that represents a number. For example, a 'level' of 3 may be represented by two bits (e.g., '1 1 '). In another example, a 'level' of 5 may be represented by three bits (e.g., ⁇ 01 ').
- the 'repetition' level that is stored for a particular value indicates the field in the value's path that has most recently repeated.
- a column of values may be stored for a field with the path "Video. Resolution. Width.'
- a repetition level of '1 ' may indicate that the 'Video' field most recently repeated, while a repetition level of '2' may indicate that the 'Resolution' field most recently repeated.
- Recently repeating can indicate, from the position of the value in the record from which the value was selected and working upwards towards the beginning of the document, which field in the path 'Video. Resolution.
- Width' is the first to reach a count of two (e.g., which field is encountered for the second time first).
- each field is encountered a single time. Finding a second instance of each field requires traversing to the depths of the next, adjacent nested field (and possibly to further nestings). Thus, a 'Video' field may be encountered that does not include any 'Resolution' children (e.g., because the 'Resolution' field is optional or a repeating field). Thus, the 'Video' field has been encountered a second time and is thus the most recently repeated field. A repetition level of ⁇ ' is assigned to the value.
- a repetition level of '0' may indicate that the field does not include a most recently repeated value (e.g., it has been encountered for the first time in the record during a top-down scan).
- a 'required' field in a path does not have a repetition level.
- the range of resolution levels may be either ⁇ ' or ⁇ .' 'Resolution' may not have a level because it is always present in the record when the 'Video' field is present.
- 'Resolution' was assigned a level of '2,' it may always be encountered before 'Video' and thus a level of may not ever be assigned.
- not including a repetition level for required fields may enable a number of different resolution levels to be reduced, and a number of bits to represent the resolution level may be reduced.
- Width' path may use a mechanism to designate when a 'Video' or a 'Video. Resolution' path is found in the record but the 'Width' field has not been instantiated in the record. This mechanism may include storing, in the 'Video. Resolution. Width' column of data, a 'Definition' level for each 'Video' or 'Video. Resolution' field in the record regardless whether the 'Width' field is instantiated. The 'Definition' level may indicate how many of the fields in the 'Video. Resolution. Width' path that could be missing (e.g., because the field is optional or repeatable) are actually present.
- a definition level of '1 ' may be recorded in the 'Video. Resolution. Width' column. If the field 'Video. Resolution' is present in the record, but no corresponding 'Width' child is instantiated, a definition level of '2' may be recorded. If the field 'Video. Resolution. Width' is present in the record, a definition level of '3' may be recorded.
- the 'Definition' level (which represents the number of fields that could be undefined but are actually defined) is less than the number of fields that could be defined, a missing occurrence of the 'Width' field may be identified.
- the combination of the 'Repetition' level and the 'Definition' level may enable the structure of the record to be reconstructed.
- a column of data for a particular field (e.g., the
- Video. Resolution. Width' field may include the values for the field from multiple records, corresponding repetition and definition levels (acknowledging that some 'missing' values may have a repetition and a definition level), and header information.
- the values are stored consecutively and adjacent. In other words, if a value for one "Video. Resolution. Width' field was 700' and the value for a next 'Video. Resolution. Width' field was '800,' a portion of the column as stored in memory may read 700800.' In this example, a header in the column may identify that the each value has a fixed width (e.g., a fixed binary
- the stored values are represented by strings.
- instances of the 'Width' field may include the values 'Small' and
- the various string values may be a fixed length (e.g., a null value may be added to the beginning or end of the 'Small' value to make the string the same length as the 'Medium' value).
- each stored string may include an identifier in a beginning portion of the string that identifies a length of the string.
- the 'small' value may include an identifier that indicates that the string is five digits long (or a
- the 'repetition' and 'definition' levels may be stored at the beginning of the columnar stripe.
- the 'repetition' and 'definition' levels are stored in pairs for a particular value (whether instantiated or missing).
- a repetition level of 3 may be stored in the first four bits of a byte and a definition level of 1 may be stored in the last four bits of the byte.
- a next byte in the header may include a repetition level and a definition level for the next instance of the field in the record (or the first instance in the subsequent record).
- the number of bits used to represent the repetition and definition levels may be based on a maximum level value. For example, if the maximum repetition level is 3, the repetition level may be represented with two bits. If the maximum repetition level is 4 the repetition level may be represented with three bits.
- the header may include information that identifies the length of the repetition and definition levels.
- the repetition levels may be stored
- the definition levels may be stored consecutively in memory (e.g., not in pairs).
- the repetition and definition levels may be stored in a group with their corresponding value (if the value is instantiated). In other words, a sequence of information in the columnar stripe may read
- the columnar stripes may be compressed into blocks of information.
- each columnar stripe may be split into a set of blocks, with each block including its own respective header.
- a first block may include the first 800,000 values and a second block may include a second 800,000 values from a stripe of 1 .6 million values.
- a block header may include the repetition and definition levels along with additional information that may be used to help analyze the portion of the columnar stripe that is represented by the block, and to reconstruct the columnar stripe.
- the block header includes an 'Assertion' value that defines a type of data that is found in the block's values. For example, a block for the "Video. Resolution. Width' field may not include any values that list 'Large' width resolution. Thus, the 'Assertion' value may indicate that the values only include 'Small' and 'Medium' values. If a query is performed for records that include 'High' width resolution videos, then the described block may be avoided by the querying system.
- the system described in this document may perform queries on columnar stripes without reconstructing the information in the columnar stripes into records, and without loading information from the columnar stripes into a database (e.g., without using 'Insert' clause).
- the data may be accessed in situ, which may provide computational analysis time savings on the order of magnitudes.
- the querying system may employ many of the clauses employed for querying relational databases. Additional clauses that are specific to nonrelational data, however, may be employed. For example, a WITHIN clause may allow for operations to be performed on multiple instances of a field within a single record or a portion of a record. A relational database, however, may be unable to store more than a single instance of a field in a row (e.g., a
- a query on a relational database may be fundamentally unable to perform queries 'within' a record.
- values for a particular field may be multiplied. Supposing that the query instructions request that all values for 'MutualFund.lnterestRate' be multiplied together for a particular record (where each record may be for a particular account holder). The querying system may find all of the 'MutualFund.lnterestRate' values within the single record and multiply them together.
- OMIT IF clause Another example of a clause that may be specific to non-relational nested data is the OMIT IF clause.
- This clause may enable a record to be filtered to remove instances of fields if a particular condition is met (e.g., a new columnar stripe or record may be created with specified fields removed).
- a stripe of values that list employee salaries may be queried and a new stripe that removes employee's with salaries above $90,000 may be generated using the OMIT IF clause.
- the querying system may be hosted by a server system and provided over the internet to remote computing devices through application programming interfaces (API).
- API application programming interfaces
- the columnar data may be represented to external users of the remote computing devices as stored within tables of information.
- the users may generate the tables using API calls and may fill the tables with data from a repository of objects.
- the users may use separate API calls to load objects into the repository.
- the server system may also implement an internet- accessible storage system that enables users to push data to the server system for remote hosting.
- the data storage service may serve as a repository for data aggregated from many geographically dispersed computing devices.
- internet website logs may be streamed by hundreds of computers to the storage system and be stored as individual objects in one or more "buckets" at the repository.
- a given bucket may have an access control list that determines which computing devices or user accounts are authorized to upload objects to the bucket or to access objects in a bucket.
- individual objects may have associated access control lists that control which devices or user accounts are able to access or manipulate the object.
- a user may explicitly request that the data in objects in a bucket be transferred to a table, or may establish a service that monitors the bucket and transfers the data in newly placed objects into the table.
- the transfer of data in the objects to the table may include converting the data format of the objects to a different format, generating columnar stripes for the data in the records, and placing the columnar stripes in a different repository.
- Metadata for the table may be updated to reference the columnar stripes that include the converted data for the imported objects.
- the querying service when the querying service receives a request to query a table, the metadata for the table is located and a query is performed on the columnar data that underlies the table.
- the output of the query may be placed in a different table, provided to the remote device requesting the query, or may be stored in the repository of objects as an object (e.g., an object that includes a collection of records).
- a cluster may host a multitude of distributed applications that share resources, have widely varying workloads, and run on machines with different hardware parameters.
- An individual computing machine in a distributed application may take much longer to execute a given task than others, or may never complete due to failures or preemption by a cluster management system.
- stragglers e.g., computing tasks with significant latency
- failures may achieve fast execution and fault tolerance. See G. Czajkowski. Sorting 1 PB with MapReduce. Official Google Blog, Nov. 2008. At http://googleblog.blogspot.com/2008/1 1 /sorting-1 pb-with- mapreduce.html.
- a nested representation of data may include a multiple fields that each include several levels of children fields. Some of the children fields may include corresponding data. Normalizing and recombining such data at web scale may be computationally expensive.
- a nested data model underlies some of the structured data processing at major web companies.
- This document describes a system that supports interactive analysis of very large datasets over shared clusters of commodity machines. Unlike traditional databases, it is capable of operating on in situ nested data. In situ refers to the ability to access data 'in place', for example, in a distributed file system like Google File System (see S. Ghemawat, H. Gobioff, and S.-T. Leung. The Google File System. In SOSP, 2003) or another storage layer like Bigtable (see F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wallach, M. Burrows, T. Chandra, A. Fikes, and R. Gruber. Bigtable: A Distributed Storage System for Structured Data. In OSDI, 2006).
- Google File System see S. Ghemawat, H. Gobioff, and S.-T. Leung. The Google File System. In SOSP, 2003
- Bigtable see F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D.
- the system can execute many queries over such data that may ordinarily require a sequence of MapReduce jobs, but at a fraction of the execution time. See J. Dean and S. Ghemawat. MapReduce: Simplified Data Processing on Large Clusters. In OSDI, 2004.
- the described system may be used in conjunction with MapReduce to analyze outputs of MapReduce pipelines or rapidly prototype larger computations. Examples of using the system include:
- the described system builds on ideas from web search and parallel database management systems.
- a query gets pushed down the tree and rewritten at each step. The result of the query is assembled by aggregating the replies received from lower levels of the tree.
- Second, the described system provides a high-level, SQL-like language to express ad hoc queries. In contrast to layers such as Pig (see C. Olston, B. Reed, U. Srivastava, R. Kumar, and A. Tomkins.
- Section 4 describes a columnar storage format for nested data. Algorithms are presented for dissecting nested records into columns and reassembling them.
- Section 5 a query language for processing data in that is stored in the columnar storage format is described.
- the query language and execution of the language are designed to operate efficiently on column-striped nested data and do not require restructuring of nested records.
- Section 6 an illustration of applying execution trees that are used in web search serving systems to database processing is provided. The benefits for answering aggregation queries efficiently is explained.
- Alice's commands execute in seconds. She runs a few other queries to convince herself that her algorithm works. She finds an irregularity in signaM and digs deeper by writing a FlumeJava program that performs a more complex analytical computation over her output dataset. Once the issue is fixed, she sets up a pipeline which processes the incoming input data continuously. She formulates a few canned SQL queries that aggregate the results of her pipeline across various dimensions, and adds them to an interactive dashboard (e.g., a web page about a service that explains the service and details statistics on the service). Finally, she registers her new dataset in a catalog so other engineers can locate and query the dataset quickly.
- an interactive dashboard e.g., a web page about a service that explains the service and details statistics on the service.
- the above scenario may require interoperation between the query processor and other data management tools.
- the first ingredient for such interoperation is a common storage layer.
- the Google File System is one such distributed storage layer that may be used.
- the Google File System manages very large replicated datasets across thousands of machines and tens of thousands of disks.
- Replication helps preserve the data despite faulty hardware and achieve fast response times in presence of stragglers.
- a high-performance shared storage layer is a key enabling factor for in situ data management. It allows accessing the data without a time-consuming loading phase, which is a major impedance to database usage in analytical data processing (where it is often possible to run dozens of MapReduce analyses before a database management system is able to load the data and execute a single query). For example, when a database management system is used to analyze data, the database may need to be loaded with data using 'Insert' commands. Such loading may not be required by the described system. As an added benefit, data in a file system can be conveniently manipulated using standard tools, e.g., to transfer to another cluster, change access privileges, or identify a subset of data for analysis based on file names.
- a second ingredient for building interoperable data management components is a shared storage format.
- Columnar storage is used for flat relational data but adapting columnar storage to a nested data model allows the technique to be applied to web data.
- Figure 1 illustrates the idea that all values of a nested field in a data structure are stored contiguously.
- all values for a particular nested field within a data structure e.g., the field A.B.C
- values for the field A.B.C can be retrieved from memory without reading values from the field A.E and values from the field A.B.D.
- values for the same particular field in different instances of a data structure may be stored contiguously.
- the values for field A.B.C for the record 'r1 ' are stored adjacent to the values for the same field for the record 'r2.'
- the values for field A.B.C for the record 'r1 ' are stored adjacent to the values for the same field for the record 'r2.'
- Protocol Buffers originated in the context of distributed systems, and is available as an open source implementation. See (Protocol Buffers: Developer Guide. Available at http://code.google.com/apis/protocolbuffers/docs/overview.html).
- ⁇ is an atomic type or a record type.
- Atomic types in dom comprise integers, floating-point numbers, strings, etc. Records consist of one or multiple fields.
- Field / ' in a record has a name A and an optional multiplicity label.
- Repeated fields (*) may occur multiple times in a record. They are interpreted as lists of values, i.e., the order of field occurrences in a record is significant.
- Optional fields may be missing from the record. Otherwise, a field is required (e.g., must appear exactly once).
- Figure 2 depicts a schema that defines a record type 'Document,' which represents a web document.
- the schema definition uses the Protocol Buffers syntax.
- a 'Document' has a required integer 'Docld' and optional 'Links,' containing a list of 'Forward' and 'Backward' entries holding 'Doclds' of other web pages.
- a 'Document' can have multiple 'Names,' which are different URLs by which the document can be referenced.
- a 'Name' contains a sequence of 'Code' and (optional) 'Country' pairs.
- Figure 2 also shows two sample records, r1 and r2, that conform to the schema.
- the record structure is outlined using indentation.
- the sample records r1 and R2 in Figure 2 are used explain the algorithms throughout this document.
- the fields defined in the schema form a tree hierarchy.
- the full path of a nested field is denoted using a dotted notation, e.g., Name. Language.
- Code is the full path name for the 'Code' field depicted in Figure 2.
- the nested data model backs a platform-neutral, extensible mechanism for serializing structured data. Code generation tools produce bindings for different programming languages such as C++ or Java.
- Cross- language interoperability is achieved using a standard binary on-the-wire representation of records, in which field values are laid out sequentially as they occur in the record. This way, a MapReduce program written in Java can consume records from a data source exposed via a C++ library. Thus, if records are stored in a columnar representation, assembling them fast may assist interoperation with MapReduce and other data processing tools.
- the repetition level of Code ranges between 0 and 2.
- Level 0 denotes the start of a new record
- level 1 denotes a recent repetition at the 'Name' field
- level 2 denotes a recent repetition at the 'Language' field.
- record 'r1 ' may be scanned from the top down.
- the value 'en-us' is first encountered and a check may be performed to identify the field in the Name.
- Language Code path that has most recently repeated in the record. In this example, none of the fields have been repeated and thus, the repetition level is 0.
- the value 'en' is next encountered for the Name.
- Language Code path and the field 'Language' is identified as the field that has most recently repeated. For example, scanning upwards from the value 'en,' the first field in the Name. Language.
- the repetition level is 2 (e.g., because '2' corresponds to the 'Language' field because 'Language' is the second field in the Name. Language. Code path that repeats).
- the repetition level is 1 .
- the repetition level for a value may be a number that represents a most recently repeated field.
- the repetition levels of Code values in record 'r1 ' are 0, 2, 1 .
- a 'definition level' specifies how many fields in the path 'p' that could be undefined (e.g., because the fields are optional or repeated) are actually present in the record.
- the field 'Links' is defined (at a level of 1 ).
- a NULL value with definition level of 1 is added to the 'Links. Backward' column.
- each column that corresponds to a particular field may be stored with a header that includes a contiguous listing of repetition and definition values, followed by a contiguous listing of the substantive values.
- Each repletion and definition value may be stored as bit sequences (e.g., in a single byte). For example, the first four bits of a byte may be used to represent the repetition level for a particular value and the last four bits may be used to represent the definition level.
- the header may include definitions of lengths of the number of bits so that delimiters may not be used. Thus, bits may only be used as necessary. For example, if the maximum definition level is 3, two bits per definition level may be used.
- a representation of columnar data for a single field may be stored in memory with a sequence of bytes representing the repetition and definition levels for a corresponding sequence of values, followed by a sequence of values.
- NULL values may not be stored explicitly as they may be determined by analyzing the definition levels. For instance, any definition level that is smaller than the number of repeated and optional fields in a field's path can denote a NULL. Thus, a system may be able to determine where in the listing of consecutive values a NULL value should be inserted or inferred.
- definition levels are not stored for values that are always defined. Similarly, repetition levels may only be stored if required.
- a representation of columnar data in memory may be broken up into a set of blocks.
- Each block may include a header that includes the repetition and definition level information, and a subsequent listing of the values for the field.
- Each header may include a 'constraint' value that indicates an allowable range of values in the block.
- the constraint can also indicate other properties of the values, e.g., whether the values have been sorted. In general, the 'constraint' may be thought of as an 'assertion' about what kind of values are found in the block.
- Each block may be compressed.
- Procedure 'DissectRecord' is passed an instance of a 'RecordDecoder,' which is used to traverse binary-encoded records.
- the primary job of the 'DissectRecord' procedure is to maintain the current 'repetitionLevel.
- the current 'definitionLevel' is uniquely determined by the tree position of the current writer, as the sum of the number of optional and repeated fields in the field's path.
- non-atomic fields such as Name. Language in Figure 2
- column stripes of their own containing only levels but no non-NULL values.
- Assembling records (e.g., records 'r1 ' and 'r2') from columnar data efficiently is critical for record-oriented data processing tools (e.g., Map Reduce). Given a subset of fields, a goal is to reconstruct the original records as if they contained just the selected fields, with all other fields stripped away.
- the key idea is to create a finite state machine (FSM) that reads the field values and levels for each field, and appends the values sequentially to the output records.
- An FSM state corresponds to a field reader for each selected field. State transitions are labeled with repetition levels. Once a reader fetches a value, the next repetition level is looked at to decide what next reader to use. The FSM is traversed from the start to end state once for each record.
- FSM finite state machine
- Figure 5 shows an FSM that reconstructs the complete records in our running example using as input the blocks described in Section 4.1 .
- the nodes are labeled with fields and the edges are labeled with repetition levels.
- the start state is 'Docld.' Once a 'Docld' value is read, the FSM transitions to the 'Links. Backward' state. After all repeated 'Backward' values have been drained, the FSM jumps to 'Links. Forward,' etc.
- T the next repetition level returned by the current field reader for field 'f.'
- 'f the schema tree
- its ancestor is found that repeats at level T and select the first leaf field 'n' inside that ancestor.
- This provides an FSM transition (T; T) ⁇ n.
- Figure 6 depicts an FSM for reading the fields 'Docld' and 'Name. Language. Country.' The figure shows the output records 's1 ' and 's2' produced by the automaton. Notice that the encoding and the assembly algorithm preserve the enclosing structure of the field 'Country.' This may be important for applications that need to access, e.g., the Country appearing in the first Language of the second Name. In XPath, this may correspond to the ability to evaluate expressions like
- FIG. 7 shows an algorithm for constructing a finite-state machine that performs record assembly.
- the algorithm takes as input the fields that should be populated in the records, in the order in which they appear in the schema.
- the algorithm uses a concept of a 'common repetition level' of two fields, which is the repetition level of their lowest common ancestor. For example, the common repetition level of 'Links. Backward' and 'Links. Forward' equals 1 .
- the second concept is that of a 'barrier', which is the next field in the sequence after the current one. The intuition is that each field is attempted to be processed one by one until the barrier is hit and requires a jump to a previously seen field.
- Step 1 the common repetition levels are processed backwards. These are guaranteed to be non-increasing. For each repetition level encountered, the left-most field in the sequence is picked—that is the field that is to be transitioned to when that repetition level is returned by a 'FieldReader.'
- Step 2 the gaps are filled (Lines 1 1 -14). The gaps arise because not all repetition levels are present in the common repetition levels computed at Line 8.
- Step 3 transitions for all levels are set that are equal to or below the barrier level to jump to the barrier field. If a 'FieldReader' produces such a level, the nested record may continue to be constructed and there may be no need to bounce off the barrier.
- An Assemble Record procedure (illustrated in Figure 8) takes as input a set of 'FieldReaders' and (implicitly) the FSM with state transitions between the readers. In other words, the algorithm operates on an FSM and columnar data and outputs constructed records.
- Variable reader holds the current 'FieldReader' in the main routine (Line 4).
- Variable Reader holds the last reader whose value is appended to the record and is available to all three procedures shown in Figure 7.
- the main while-loop is at Line 5.
- the next value is fetched from the current reader. If the value is not NULL, which is determined by looking at its definition level, the record being assembled is synchronized to the record structure of the current reader in the method 'MoveToLevel,' and the field value is appended to the record. Otherwise, the record structure may be adjusted without appending any value—which may be done if empty records are present.
- a 'full definition level' is used. Recall that the definition level factors out required fields (only repeated and optional fields are counted). Full definition level takes all fields into account.
- Procedure 'MoveToLevel' transitions the record from the state of the 'lastReader' to that of the 'nextReader' (see Line 22). For example, suppose the 'lastReader' corresponds to 'Links. Backward' in Figure 2 and 'nextReader' is 'Name. Language. Code.' The method ends the nested record Links and starts new records Name and Language, in that order.
- Procedure 'ReturnsToLevel' (Line 30) is a counterpart of 'MoveToLevel' that only ends current records without starting any new ones.
- the described system may employ a query language that is based on SQL and is designed to be efficiently implementable on columnar nested storage. Aspects of the query language are described herein.
- Each SQL-like statement (and algebraic operators it translates to) takes as input one or multiple nested tables (e.g., a set of compressed blocks of columnar data that represents a table, as described in Section 4.1 ) and their schemas, and produces a nested table (e.g., a modified instance of the columnar data) and its output schema.
- the COUNT expression illustrates within-record aggregation.
- the aggregation is done WITHIN each 'Name' subrecord, and emits the number of occurrences of 'Name. Language. Code' for each 'Name' as a non-negative 64-bit integer (uint64).
- uint64 64-bit integer
- the language supports nested subqueries, inter and intra-record aggregation, top-k, joins, user-defined functions, etc. Some of these features are discussed in the experimental data section.
- the described query language includes an OM IT IF statement that can filter an intra- row group of values. For example, each of thousands of records may include several repeated 'Cost' fields that each include a numerical value. An user of the query language may want to throw out all records where a sum of the values in the fields exceeds the number '20.' Thus, the user may employ an OM IT IF statement to generate a list of the records where the summed 'Cost' in each record is twenty or less.
- Tree Architecture The described system uses a multi-level serving tree to execute queries (see Figure 10).
- a root server receives incoming queries, reads metadata from the tables, and routes the queries to the next level in the serving tree.
- the leaf servers communicate with the storage layer or access the data on local disk.
- Many of the queries that operate in the described system are single-scan aggregations; therefore, this document focuses on explaining those and uses them for experiments in the next section.
- the root server When the root server receives the above query, it determines all tablets, i.e., horizontal partitions of the table, that comprise the table T and rewrites the query as follows:
- Tables R j UN ION ALL ... R [ are the results of queries sent to the nodes 1 , . . . , n at level 1 of the serving tree:
- J) is a disjoint partition of tablets in T processed by server T at level ⁇ .
- Each serving level performs a similar rewriting.
- the queries reach the leaves, which scan the tablets in T in parallel.
- intermediate servers perform a parallel aggregation of partial results.
- the execution model presented above is well suited for aggregation queries returning small and medium-sized results, which are a very common class of interactive queries.
- Query Dispatcher The described system is a multi-user system, e.g., several queries may be executed simultaneously.
- a query dispatcher schedules queries based on their priorities and balances the load. Another role is to provide fault tolerance when one server becomes much slower than others or a tablet replica becomes unreachable.
- the amount of data processed in each query is often larger than the number of processing units available for execution, which are called slots.
- a slot corresponds to an execution thread on a leaf server. For example, a system of 3,000 leaf servers each using 8 threads has 24,000 slots. So, a table spanning 100,000 tablets can be processed by assigning about 5 tablets to each slot.
- the query dispatcher computes a histogram of tablet processing times. If a tablet takes a disproportionately long time to process, the system reschedules the tablet on another server. Some tablets may need to be redispatched multiple times.
- the blocks in each stripe are prefetched asynchronously; the read-ahead cache typically achieves hit rates of 95%. Tablets are usually three- way replicated. When a leaf server cannot access one tablet replica, it falls over to another replica.
- the query dispatcher honors a parameter that specifies the minimum percentage of tablets that must be scanned before returning a result. As described below, setting such parameter to a lower value (e.g., 98% instead of 100%) can often speed up execution significantly, especially when using smaller replication factors.
- Each server may have an internal execution tree, as depicted on the right-hand side of Figure 7.
- the internal tree corresponds to a physical query execution plan, including evaluation of scalar expressions. Optimized, type- specific code is generated for most scalar functions.
- a basic execution plan consists of a set of iterators that scan input columns in lockstep and emit results of aggregates and scalar functions annotated with the correct repetition and definition levels, bypassing record assembly entirely during query execution.
- Figure 12 shows five graphs, illustrating the time it takes to read and uncompress the data, and assemble and parse the records, for a subset of the fields.
- Graphs (a)-(c) outline the results for columnar storage. Each data point in these graphs was obtained by averaging the measurements over 30 runs, in each of which a set of columns of a given cardinality was chosen at random.
- Graph (a) shows reading and decompression time.
- Graph (b) adds the time needed to assemble nested records from the columns.
- Graph (c) shows how long it takes to parse the records into strongly typed C++ data structures.
- Graphs (d)-(e) depict the time for accessing the data on record- oriented storage.
- Graph (d) shows reading and decompression time. A bulk of the time is spent in decompression; in fact, the compressed data can be read from the disk in about half the time.
- Graph (e) indicates, parsing adds another 50% on top of reading and decompression time. These costs are paid for all fields, including the ones that are not needed.
- the gains of columnar representation may be about an order of magnitude. Retrieval time for columnar nested data may grow linearly with the number of fields. Record assembly and parsing may be expensive, each potentially doubling the execution time. Similar trends were observed on other datasets.
- a natural question to ask is where the top and bottom graphs cross, i.e., record-wise storage starts outperforming columnar storage. In experience, the crossover point may lie at dozens of fields but varies across datasets and depends on whether or not record assembly is required.
- Map Reduce and the Described System Next an execution of MapReduce and the described system are illustrated on columnar vs. record- oriented data. In this case, a single field is accessed and the performance gains are the most pronounced. Execution times for multiple columns can be extrapolated using the results of Figure 12. In this experiment, the average number of terms in a field 'txtField' of table TV is counted. MapReduce execution is done using the following Sawzall program:
- FIG. 13 shows the execution times of two MapReduce jobs and the described system on a logarithmic scale. Both MapReduce jobs are run on 3000 workers (e.g., servers). Similarly, a 3000-node instance of the present system is used to execute Query Q-i .
- the described system and MapReduce-on- columns read about 0.5TB of compressed columnar data vs. 87TB read by MapReduce-on-records.
- MapReduce gains an order of magnitude in efficiency by switching from record-oriented to columnar storage (from hours to minutes). Another order of magnitude is achieved by using the described system (going from minutes to seconds).
- Figure 14 shows the execution times for each query as a function of the server topology.
- the number of leaf servers is kept constant at 2900 so that the same cumulative scan speed may be assumed.
- the 2-level topology (1 :2900)
- a single root server communicates directly with the leaf servers.
- a 1 :100:2900 setup is used, i.e., an extra level of 100 intermediate servers.
- the 4-level topology is 1 :10:100:2900.
- Query Q 2 runs in 3 seconds when 3 levels are used in the serving tree and does not benefit much from an extra level. In contrast, the execution time of Q3 is halved due to increased parallelism. At 2 levels, Q3 is off the chart, as the root server needed to aggregate near-sequentially the results received from thousands of nodes. This experiment illustrates how aggregations returning many groups may benefit from multi-level serving trees.
- FIG. 15 shows how fast tablets get processed by the leaf servers for a specific run of Q 2 and Q 3 .
- the time is measured starting at the point when a tablet got scheduled for execution in an available slot, i.e., excludes the time spent waiting in the job queue. This measurement methodology factors out the effects of other queries that are executing simultaneously.
- the area under each histogram corresponds to 100%.
- 99% of Q 2 (or Q 3 ) tablets are processed under one second (or two seconds).
- the query was executed using four configurations of the system, ranging from 1000 to 4000 nodes.
- the execution times are in Figure 16.
- the total expended CPU time is nearly identical, at about 300K seconds, whereas the user-perceived time decreases near-linearly with the growing size of the system. This result suggests that a larger system can be just as effective in terms of resource usage as a smaller one, yet allows faster execution.
- Stragglers may be tasks (e.g., processing a tablet) that are not performed, for example, because the machine performing the task has an operational problem or the machine is not being aggressive enough in handling the task given higher-priority tasks.
- Query Q 6 below is run on a trillion-row table T5. In contrast to the other datasets, T5 is two-way replicated. Hence, the likelihood of stragglers slowing the execution is higher since there are fewer opportunities to reschedule the work.
- Figure 18 shows the query response time distribution in a typical monthly workload of the described system, on a logarithmic scale. As Figure 18 indicates, most queries are processed under 10 seconds, well within the interactive range. Some queries have achieved a scan throughput close to 100 billion records per second in a busy cluster, and even higher on dedicated machines. The experimental data presented above suggests the following observations:
- MapReduce and query processing can be used in a complementary
- Figure 19 is a block diagram of a system for generating and processing columnar storage representations of nested records.
- the record generator 1904 generates records of nested data from data sources 1920 and a schema 1902.
- the column generator 1908 receives as input the records 1906 and the schema 1902 and outputs column stripes that represent the data in the records 1906, but in a columnar format.
- the columnar data 1910 may be queried in situ by the querying system 1912 in order to produce different sets of output columns 1914.
- the columnar data 1910 may also be assembled back into record form by the record assembler 1916.
- the records 1918 that are output by the record assembler may each include a sub-set of fields from the original records in the collection 1906.
- the output records 1918 may be operated on by a record- based data analysis program (e.g., MapReduce).
- MapReduce MapReduce
- the data sources 1920 may include substantially unstructured data. Substantially unstructured indicates that the data may include elements that denote structure, but the entire spectrum of information may not be similarly structured. As an illustration, the data sources 1920 may include the source code for each of millions of websites. Although each website includes some degree of structure, the content of each website is not generated based on a common schema. Standards may generally govern a format of the site, but content and placement of fields is not specified among each and every website by a single schema. In some examples, the information in data sources 1920 is not stored in the common storage layer 1922, but is pulled directly from external sources on the internet.
- the schema 1902 defines a common structuring for information that may be contained in the data sources. As described earlier in this document, the schema 1902 can require certain fields of information and may permit other fields of information to be stored as optional.
- the record generator 1904 receives as input the schema 1902 and information from the data sources 1920.
- the record generator 1904 takes the information from the data sources 1920 and structures all or portions of the information into individual instances of records that comply with the schema 1902. For example, while the data sources 1920 may include substantially unstructured data from web pages, the record generator 1904 may select pieces of information from each web page to include for particular records 1906.
- each of the records 1906 may include data that is structured according to the schema 1902.
- the structured data may include fields, which may denote a semantics of data values and a structural relationship of the data values. Accordingly, the schema may be referenced to obtain additional definition information for the data value (e.g., what the digitally stored data value represents in the real world or on a web page and relationships to other values).
- Each record 1906 may include nested fields and data values.
- a nested record may include more than one field of the same name or path.
- the fields with the same name or path can be structurally located in different locations in a particular record. For example, a single field that is defined by the schema may be able to repeat multiple times. Further, fields may have children fields (i.e., nested fields). Thus, at a top level of a record a particular field may repeat, and each repetition of the field may or may not include a particular child field. In other words, the record may include instances of the child field in some portions of the record, but not in other portions of the records.
- the collection of records 1906 may be translated into columnar data 1910 to speed up processing of information in the records. For example, if the amount of records in the collection 1906 numbers in the billions, and each record could include hundreds of different fields, an analysis of the records may be time- intensive where information on a small number of fields is desired. This is because each record in the collection 1906 is stored with other information from the record. That is, each record is grouped together in a consecutive portion of memory (e.g., as illustrated in the 'record-oriented' depiction of nested data in Figure 1 ).
- columnar data 1910 includes columns that each store information for a single field in the schema 1902 (e.g., as illustrated in the 'column-oriented' depiction of nested data in Figure 1 ).
- the column for the field may be on the order of billions of bytes (e.g., one byte for each record) as opposed to billions of records (e.g., where each record may be a megabyte in size).
- the operations of the column generator 1908 are described in more detail in Section 4.2 "Splitting Records into Columns.”
- the storage format for the columnar data 1910 is described in more detail in Section 4.1 "Repetition and Definition Levels.”
- the columnar data 1910 may be queried directly using the querying system 1912. In other words, the columnar data 1910 may be queried without loading the data into a database.
- the querying system when executing a query, may receive as an input a table of columnar data. In some examples, the querying system also receives as input the schema 1902.
- the columnar stripes may be stored together with the schema to make the data self-describing.
- the querying system allows operations to be performed on the columnar data in order to generate columns of output information 1914.
- the output columns 1914 may include a subset of the values represented in the columnar data 1910, as determined by a particular query. In some examples, the querying system outputs records 1918 instead of, or in addition to, the columns 1914.
- the querying system 1912 may receive a first query and, in response, may parse through select columns of data and generate a set of output columns that provides a title of all web pages that have one or more videos and a number of the videos for each web page.
- the querying system may receive a second query and in response output a second set of output columns that provides a URL of every web page that was generated within the last fifteen minutes.
- Other information from the columns 1910 may not be included in a set of output columns that corresponds to a particular query 1914.
- the record assembler 1916 may receive as input the columnar data and assemble records from the columnar data. The process of assembling records is described in more detail in Section 4.3 "Record Assembly.”
- the record assembler 1916 enables generating a set of records that includes a subset of the fields of the records in the collection 1906. For example, the records in the collection may include thousands of different fields. A user may want to run a record-oriented analysis program that only requires knowledge from two of the fields, but for all of the records.
- the record assembler 1916 may generate a set of records that only includes information on the requested fields. This way, multiple sets of output records 1918 can be developed for different analysis or for different analysis programs. An analysis on smaller records may be faster than an analysis that must traverse the larger records that may be found in collection 1906.
- FIG. 19 is a flow chart of an example process for generating columnar data. The process may be performed by components of the system 1900.
- a set of records is generated.
- the generation of the records may be performed by the record generator 1904.
- Unstructured data e.g., from data sources 1920
- the records may be stored in the collection 1906.
- the records in the collection 1906 are accessed.
- the column generator 1908 receives as input the data from the collection of records 1906.
- a list of values for the particular is generated. For example, each of the records may be traversed and a list of values for the particular field is generated.
- repetition levels for the particular field are generated.
- the column generator 1908 may determine a repetition level for each of the values in the list by determining a most recently repeated field in the path for the field.
- definition levels for the particular field are generated.
- the column generator 1908 may determine a definition level for each value (including values that are 'missing,' as described in more detail above).
- a columnar stripe is assembled for the particular field.
- the repetition and definition levels are placed in paired groupings in the header of the stripe.
- the list of values may be placed in the body of the stripe.
- the columnar stripe is broken into blocks that may be compressed. Each block may include a set of values and their corresponding repetition and definition levels. Subsequently, a determination in box 2006 of whether columnar stripes are to be generated for additional fields is performed. If no additional columnar stripes are to be generated, the process ends.
- the process depicted in Figure 20 is an example process for generating columnar stripes. Variations on the process are contemplated. For example, the operations of the boxes may not be performed sequentially as depicted in the flowchart. Stripes for multiple fields may be generated at a single time. The repetition level and definition level may be generated as each value is obtained from a record. The columnar stripe may not be generated as a whole. Instead, each block may be generated from the stripe and independently compressed. Thus, the flowchart may represent a conceptual mechanism for understanding the generation of stripes, but is not intended to be limiting. A process for generating columnar data is depicted in the algorithm of Figure 4, which may not correspond to the operations described in relation to Figure 20.
- Figure 21 is a block diagram illustrating an example of a system 2100 that implements a web service for data storage and processing.
- the columnar data processing system 2130 in the lower-right side of Figure 21 represents components of the system illustrated in Figure 19 (which illustrates a block diagram of a system for generating and processing columnar storage representations of nested records).
- the columnar data processing system 2130 may execute efficient queries on columnar data that is stored in repository 2132.
- the remaining components of the data storage and processing service 2102 support a web service that stores data, allows external users (e.g., individuals accessing the service 2102 over the internet) to import that data into tables, and, from the user's perspective, perform queries over those tables.
- the data underlying those tables may be stored as columnar data and the queries over the tables may be implemented by the querying capabilities of the columnar data processing system 2130.
- These external users use Application Programming Interfaces (API) 2104, 2134, and 2124 to upload data to the data storage and processing service 2102, import select portions of the uploaded data into tables, and perform queries on the tables.
- API Application Programming Interfaces
- the data that is stored in the tables may be replicated among multiple data centers.
- External users may use the Objects API 2104 to upload data into the object storage 2106, potentially aggregating in a single service data that streams regularly from many computing devices.
- External users may define tables and transfer the data that is located in the object storage 2106 to the tables. The transfer can be performed upon user request or automatically by the service 2102 as new data is uploaded to the object storage 2106.
- the bulk data that is referenced in tables may be stored as columnar data in storage 2132, while the metadata for the tables may be stored separately in the table metadata storage 2120.
- the external users may run efficient queries on the tables using the Query API 2124.
- the queries on the tables may be implemented as queries on the underlying columnar data in storage 2132, and the processing of the queries on the columnar data in storage 2132 may be performed by the columnar data processing system 2130, as described throughout this document.
- the object storage 2106 that is provided to external users through the Objects API 2104 is described in detail first.
- the object storage 2106 hosts data that may be accessible through the Objects API 2104 to numerous external users.
- data may be accessible through the Objects API 2104 to numerous external users.
- more and more log data that is generated by websites is being hosted in the cloud by remote services that specialize in data hosting, as opposed to the websites themselves storing the log files on their own networks.
- cloud-based storage may be particularly beneficial when data that is continuously generated by many geographically dispersed computers needs to be aggregated in one place, available to multiple different users, and occasionally analyzed.
- the object storage 2106 may include objects from a variety of users that are grouped into buckets.
- Each bucket may be a flat container that groups objects and provides a unique namespace for the group of objects.
- An external user may own a collection of buckets and assign access settings to each bucket.
- objects in one bucket may be private to a few users while objects in another bucket may be publicly accessible on the internet.
- the buckets may have a universally unique name among all buckets owned by external users.
- the buckets exist in a flat namespace such that the buckets are not nestable.
- Each object may be stored as an opaque collection of bytes.
- the object storage 2106 may receive through the Objects API 2104 different types of data, but may treat the received data as a chunk of data without regard to the format of the data.
- Each object may have corresponding metadata that is stored in a separate table or database.
- Each object may be assigned to one bucket, and each object in a bucket may have a name that is unique to the bucket. Thus each object may have a globally unique name when addressed with reference to the object's parent bucket.
- each object may have its own access control list, enabling sharing data over a network (e.g., the internet) between a variety of users with different permissions.
- the interface provided by the Objects API 2104 to exchange data may be a RESTful (REpresentational State Transfer) HTTP interface that employs industry standard, or proprietary, protocols.
- RESTful REpresentational State Transfer
- external users may employ GET, PUT, POST, HEAD, and DELETE actions to interact with objects that are stored in the object storage 2106.
- the Objects API 2104 provides a sequential interface for writing and reading data to objects in the object storage 2106.
- the Objects API 2104 provides readonly access to some of the objects. Thus, a user may delete and replace objects, but may not incrementally modify objects.
- the data storage and processing service 2102 may not be configured for external customers to perform SQL-like queries on the objects directly. The data in the objects may be first placed into structured tables before such queries are performed.
- HTTP API requests may be received at the frontend server 2126 from a remote computerized device that is associated with an external user.
- the frontend server 2126 forwards the request to an API collection implementor 2126.
- the API collection implementor stores API libraries, processes the request based on the stored libraries, and generates
- API requests for the objects API 2104 pertain to object storage 2106
- the API collection implementor 21 16 forwards a request to the object storage 2106.
- the data storage and processing service 2102 provides the ability to transfer data that is stored in objects into tables and run efficient queries on the tables using the columnar data processing system 2130. For example, users can append data to tables, create new tables, and manage sharing permissions for tables.
- the data in the tables may be stored as columnar data in the columnar data storage 2132. Accordingly, when data is placed in a table, the data storage and processing service 2102 transfers data from the object storage 2106 to the columnar data storage 2132.
- the import job manager 2108 manages the process of transferring the data and performs conversion operations on the data.
- Each table represents a structured data set that a user may query through the Query API 2124. Users can create tables, import data into tables, share tables, run queries over the tables, and use the tables in data analysis pipelines.
- the external user exposure to a table may be an object that is stored in the object storage 2106 as a delegate object.
- a delegate object may be an object that provides an interface to a set of data and operations that are not stored in the object storage 2106. In other words, delegate objects may allow tables to be mapped into the namespace for the object storage 2106. Thus, each table's name may reside in the global object namespace and may be unique.
- a delegate object for a table may hold metadata that identifies the owner of the table, the access control list for the table, and the table identifier (which links the delegate object to additional table metadata, and is described in more detail below).
- an external user sees tables as objects residing within buckets.
- the user may view a list of all tables in a bucket and may delete a table by deleting the corresponding delegate object, much in the same way that the user may view a list of objects and delete objects.
- a reference to underlying table data is extracted from the delegate object and is used to service the request.
- a delete operation on a table may trigger cleanup operations on the corresponding metadata in the table metadata storage 2120 and underlying columnar data in the columnar data storage 2132.
- a table is created in response to a request through the Table API 2134.
- the table management system 21 18 may create a table at a key of a database in the table metadata storage 2120, and then create a delegate object in the object storage 2106 to reference the key.
- the table metadata storage 2120 may hold metadata for the tables that are referenced by delegate objects. For example, a table identifier in a delegate object references a key in a row of the table metadata storage 2120.
- the table metadata storage 2120 stores, for the table and under the key, any combination of: (1 ) the table identifier, (2) a table revision number, (3) a table name, (4) a data reference set, (5) a schema description, and (6) data statistics.
- the table name may be a back pointer to one or more buckets and objects that the table is associated with. Storing the table name may facilitate garbage collection and help avoid conflicts if the table is deleted and a new table with the same external (object) name is later created.
- the data reference set may include path references to the columnar data 2132 that backs the table (e.g., that stores the bulk data for the tables).
- the schema description may allow for efficient schema validation during data management operations.
- the data statistics may identify information about the table, for example, a number of rows, a size of data referenced by the table, and a last updated timestamp.
- a table is filled with data from objects in the object storage 2106 in response to a demand by a user (e.g., a Table API call).
- the import job manager 2108 may receive an ad-hoc request from a data owner to import the data from a set of objects from the data storage 2106 into a table.
- a data owner may generate a job that is executed by the import job manager 2108, and that establishes a continuous import service that takes objects that are newly placed in a bucket and "auto- imports" the data in the objects into a table. After the data from the objects is imported into the table, the objects may be automatically deleted without user input.
- the import job manager 2108 receives requests to import data from an object into a table, and in response performs several operations to transfer data to the columnar data storage 2132.
- the job manager 2108 creates job metadata to track the import and launches a coordinator 21 10.
- the job metadata is stored in the import job metadata storage 2122.
- the import job manager 21 18 may aggregate the content of objects, perform data format transformations, shard the data into appropriately sized chunks, move the data into a different storage layer, and place the chucks of data in the columnar data storage 2132 for access by the columnar data processing system 2130.
- the import job manager 2108 transforms the object data into columnar data.
- the import job manager 2108 places non-columnar chunks of data in the columnar data storage 2132, and the columnar data processing system 2130 converts the non-columnar chunks of data to a columnar format.
- the coordinator 21 10 is invoked by the import job manager 2108 to analyze an import job and launch an appropriate number of workers to process the data in a reasonable amount of time.
- the coordinator 21 10 analyzes the input data objects and decides how to assign the data objects among individual workers 21 12 that process the input data objects.
- the coordinator 21 10 spawns individual worker instances and observes worker progress.
- the coordinator 21 10 ensures that the data handled by each worker is not too small or large.
- each worker instance 21 12 may sequentially read input data objects, perform appropriate format conversions, and store the data in sharded bundles of columnar data 2132.
- worker instances are assigned to run in the same clusters where the input data is located (because cross-datacenter traffic can be inefficient and expensive).
- Input data may be any schematized data format that the system understands.
- Input data may be text or binary form, and the schema may be incorporated in the data format or specified along with the data.
- Example input data may be: (1 ) a record data type (a self-contained and self-describing structure for record- stored data), (2) a column data type (a self-contained and self-describing structure for column-stored data), (3) text based formats for which the data storage and processing service 2102 knows the schema (field separated or fixed field length formats such as Apache, AppEngine, or W3C logs), or (4) text based formats that can be described by name/type value pairs (field separated or fixed field length, and the user specifies the name/type pairs and separators or field sizes).
- the coalescer and garbage collector 21 14 may periodically scan tables for issues to fix.
- the coalescer may monitor contents of the columnar data storage 2132 and detect columnar data bundles that are too small and may be coalesced into larger bundles.
- the garbage collector detects columnar data bundles that are not referenced by any tables and may be deleted.
- dangling table metadata may be cleaned up, for example, when a table is generated but the table creation process fails before a corresponding delegate object is generated in the object storage 2106.
- user queries may be run on the tables.
- the queries may be SQL-like and may be received from external users through the Query API 2124.
- the frontend server 2126 receives the Query API requests and forwards the requests to the API collection implementor 21 16, which passes the queries to the query manager 2128.
- the query manager 2128 takes SQL-like queries and an
- the columnar data processing system 2130 may query columnar data 2132 and output result data (e.g., columns of result data).
- the result data may be placed in a table defined by the query, returned to the external user in a format defined by data format templates, or placed in an object defined in the API call.
- the API collection implementor 21 16 handles API calls through the Objects API 2104, Table API 2134, and the Query API 2124.
- Example API functions are detailed later in this disclosure.
- the collection of APIs may enable SQL-like summaries to be performed on large quantities of data that is imported into tables from the object storage 2106.
- the source objects in object storage 2106 may be aggregated from numerous web sources, each source having permission to place data in the same bucket of object storage 2106.
- the illustrated data storage and processing service 2102 can provide an aggregation and data import pipeline for the columnar data processing system 2130 described earlier in this document.
- the columnar data processing system 2130 can provide fast queries and aggregations of large datasets.
- Figure 22 is a flowchart showing an example of a process 2200 for performing data storage and processing.
- the process 2200 may be performed by the system illustrated in Figure 21 , and more particularly the data storage and processing service 2102.
- a request to store data is received at a server system.
- a server system that provides the data storage and processing service 2102 may implement an API that enables remote computing devices to upload data to the server system, for example, over the internet.
- the server system may receive a function call to upload data through the API and from a remote computing device.
- the function call may identify data to upload and a name for the data.
- the name for the data may identify a storage location for data (e.g., a bucket).
- the request may be received from a computing device that does not access the data storage and processing service 2102 over the internet.
- a third party may physically ship one or more physical storage devices (e.g., CDs, DVDs, hard discs, or RAID enclosures) to a business entity that operates the data storage and processing service 2102.
- Employees of the business entity may load the data that is included in the physical storage device into the object storage 2106 using a computing device that is connected to the data storage and processing service 2102 over a local network.
- the local transfer of data to the object storage 2106 may not use the API.
- the identified data is stored as an object in a repository at the server system.
- the repository may include a collection of "buckets" that are each configured to include one or more objects.
- Each bucket may have a name that is unique among the collection of buckets, and the objects in each bucket may have names that are unique to the bucket.
- each object may be addressable by a unique name path (e.g., bucketName.objectName).
- Each bucket may be owned by one or more external customers.
- Storing the data may include determining that the remote device that is uploading the data is authorized to place objects in the identified bucket. For example, an external customer may create a bucket and assign specific user accounts as authorized to place data in the bucket and view the contents of the bucket. If a remote device logged in under one of the specific accounts requests to place data in the bucket, the request may be granted. Similar requests by non- authorized user accounts may be rejected.
- a request is received to create a table.
- the data storage and processing service 2102 may receive from a remote computing device an API function call requesting to create a table.
- a table may be a structured data set that a user may query.
- the request may define a name for the table, and define the fields for the table.
- the request may include a schema that defines a structure for a type of record, and the table may be generated to store data for records of the type.
- the table is created. For example, metadata for the table may be added under a row in a database.
- a delegate object that references the table row may be placed in the object repository. For example, if the API call requests to generate a table named bucketName.TableName, a delegate object that is named TableName may be placed in the bucket bucketName.
- the TableName delegate object may include an access control list for the table and a table identifier (e.g., an identifier of the database row that stores metadata for the table).
- a request to import data in the object into the table is received.
- the data storage and processing service 2102 may receive from a remote computing device an API function call requesting that data in the object be loaded into the table or appended to the end of a table that already includes data.
- the request is received from a continuous import service.
- the continuous import service may periodically monitor a bucket and when the bucket includes new objects (e.g., when external customers place new objects in the bucket) the continuous import service requests that data in the new objects be appended to the table.
- an API function call that establishes the continuous import service was received earlier.
- the customer-facing view of the continuous import service may be a delegate object.
- the data in the object is converted into columnar format.
- the object may include a set of records, and the records may be converted into a set of columnar stripes, where each stripe (or set of blocks of a stripe) describes a single attribute field of the records.
- the columnar stripes may include the repetition and definition levels described throughout this document.
- the columnar data is stored in a repository.
- the repository for the columnar data is different than the repository for the objects.
- the repositories may be different storage layers implemented at a server system implementing the data storage and processing service 2102. Metadata that references the columnar data may be stored in the table database.
- a query of the table may include referencing the metadata in the table database to identify columnar data that corresponds to particular attribute fields for the data in the table.
- the request identifies several objects for which data is to be loaded into the table.
- the data content of the objects may be aggregated, data format transformations may be performed, the data may be sharded into appropriately sized chunks of columnar data, and the chucks of columnar data may be placed in the repository for columnar data.
- a request is received to perform a query on the table.
- the data storage and processing service 2102 may receive an API function call from a remote computing device requesting that a SQL-like query be run on the table.
- the query operates on the table and one or more other tables.
- the query may collect data having particular characteristics from each of two tables and place the aggregated data in a third table.
- the delegate object for each table may have an access control list that identifies user accounts that may run queries on the table corresponding to the delegate object, delete the table, and add data to the table. If a remote computing device associated with a user account attempts to run a query on several tables, the data storage and processing service 2102 determines if the user account is authorized to query each of the tables.
- a query is performed on columnar data. For example, queries are performed on the columnar data underlying the tables specified in the query request.
- a query manager 2128 may generate, based on the query received from the remote computing device, component queries that are performed on particular columns of data for the tables specified by the query. For example, the query may request data within a particular range for a single attribute in a table.
- the query manager 2128 may generate a component query on a collection of blocks of a columnar stripe that is associated with the single attribute, and may run other component queries on columnar stripes for other of the attributes in the query.
- data is output based on the query.
- the query may identify a table that the results of the query are to be placed in.
- the query manager 2128, table management system 21 18, and columnar data processing system 2130 may place the result data in a table.
- the query may identify one or more objects in which to place the results of the query.
- the results of the query may be placed in one or more objects in the object storage 2106.
- the API call requesting that the data be placed in the object may specify a data format for storage of the data in the object.
- outputting the data as one or more objects may include converting output columns of columnar data stored in the columnar data storage 2132 into a different type of data format for storage in the object storage 2106 (e.g., a record- based type of data format).
- the schema may be extensible.
- a third party may request minor changes to the schema (e.g., by editing the schema through an API or uploading a new schema that includes minor changes).
- the minor changes can include adding new optional fields to the schema.
- the user may not be able to add new required fields or remove existing required fields from the schema.
- the schema may be updated without rebuilding or regenerating the entire data set. As such, a new columnar stripe may be added for a newly added optional field without modification of the existing columnar stripes.
- a third party user may be able to change field names and add aliases for field names.
- a schema may include a field that is named "Time.”
- a third party user may decide to change the name of the field to "LocalTime.”
- newly submitted data records may include "LocalTime” fields
- data records that are already stored by the data storage and processing service 2102 may include "Time” fields.
- the data storage and processing service 2102 may recognize the fields "Time” and "Local Time” as aliases of each other.
- the data storage and processing service 2102 may store an index that matches field names to a unique identifier for a data element.
- the index may associate both the "Time” and "Local Time” aliases to a unique identifier for a field (e.g., the identifier "1 A452BC").
- the unique identifier may be associated with and designate a single columnar stripe that all the data values for the "Time” and "Local Time” fields.
- the data records stored in the object storage 2106 also identify fields with unique identifiers and do not identify fields with names that can change.
- the data may be directly output to the remote computing device, additionally or instead of placing the data in a table or an object.
- a remote computing device requesting the query may in response receive the results of the query.
- the results of the query may be in various formats (e.g., CSV or data for reconstructing a display of the output table).
- the data that is stored by the data storage and processing service 2102 is replicated among geographically dispersed server devices.
- an object that is stored in object storage 2106 may be replicated among server devices in data centers that are hundreds of kilometers apart from each other. Thus, a localized server failure, power outage, or natural disaster may not influence the availability of the object.
- the columnar stripes that underlie the table and that reside in the columnar data storage 2132 may be replicated among geographically dispersed server devices.
- the table metadata that is stored in the table metadata storage 2120 may also be replicated among geographically dispersed server devices. This replication of columnar data and table metadata is described hereinafter.
- FIG. 23 shows a schematic diagram of an example computing system infrastructure.
- an organization operates multiple data centers, although only two data centers 2310 and 2350 are shown in the figure for illustrative purposes.
- Each data center may be separated by a geographical distance of, for example, at least fifty kilometers or at two hundred kilometers.
- Each data center includes numerous computing devices (e.g., servers, groups of servers, or individual CPUs).
- the computing devices are logically grouped into cells.
- Cell A 2312 is shown as including three computing devices 2314, 2316, and 2318, although the cell may include additional computing devices.
- Each computing device in a data center may belong to a single cell (e.g., no computing device may be assigned to more than one cell and service more than one cell at particular times).
- the devices that are assigned to a specific cell may dynamically change so as to balance resource allocation among the cells of a data center.
- An individual or group of individuals (e.g., a project team) at the organization may reserve one or more cells at one or more data centers, for example, to support data processing that the team requires to offer a web service.
- a reserved cell may exclusively support the reserving team and may not be available to other teams while reserved.
- a team may reserve a collection of cells from different data centers, and may implement a data replication process among the cells.
- the data that is replicated among the cells may be the columnar data that is described with respect to columnar data storage 2132.
- the system may replicate the columnar data in order to ensure that the columnar data is persistent in the event that a particular device or data center crashes, in order to support load balancing among the data centers, and/or in order to reduce latency in providing a customer with a result to a query by processing data at a data center that is geographically near to the customer.
- FIG. 24 shows a schematic diagram of an example of a data naming structure that may be used to support replication of data.
- a block of columnar data may be assigned a logical address.
- the logical address may be distinct from physical addresses of the replicated copies of the columnar data, and may not reference specific machines or locations at which the columnar data is replicated.
- the logical address may take the form Cohort:lnstance:Shard:File, where each portion of the "Cohort: lnstance:Shard:File" logical address indicates a logical set of data that can be replicated among multiple cells.
- a cohort may be a rather sizable logical collection of data that is replicated among multiple cells.
- the "file” portion of the address may represent a logical name for a single block of columnar data.
- logical herein indicates a naming structure that is abstracted from the physical address of the data, and that can reference data that is replicated among multiple physical locations. As such, a logical set of data may be associated with multiple actual copies of the set of data at multiple respective cells.
- the logical collection of data denoted a cohort may include multiple "instances" that represent logical portions of the sizable collection of data. Each of the instances in the cohort may be replicated among the multiple cells that replicate the data in the cohort.
- cohort 2400 is assigned instances 2410, 2420, and 2430. Each instance represents a partition of the data that is stored by the cohort and that is replicated among the different cells that store the data in the cohort.
- each cell that stores data in a cohort may store a copy of all instances that, put together, comprise the cohort
- each instance may be assigned one of the cells as its writing cell.
- cell 2440 is assigned as the writing cell for instance 2410
- cell 2450 is assigned as the writing cell for instance 2420
- cell 2460 is assigned as the writing cell for instance 2430.
- a writing cell may be the initial cell that writes to its corresponding instance. Once the instance has been written to by its respectively assigned writing cell, however, the writing cell updates the other cells with the instance of the cell. Along the same line, the writing cell receives updates to its non-writing instances from the other cells in the cohort.
- Cell 2440 may be the writing cell for Instance 2410
- cell 2440 may store replicated data from instances 2420 and 2430.
- the writing cell for an instance may be the cell that first updates information for that instance of data.
- the cell that first writes an update to a file in the cohort may be determined by which instance that file is logically stored within.
- This process is illustrated in Figure 24 by the narrow, solid arrows (e.g., arrow 2470) and the large, hollow arrows (e.g., arrow 2480).
- the small arrows represent the writing of data from the cell to its assigned instance.
- the large arrows represent the replication of updates from the other cells and of other instances back to that particular cell.
- cell A 2440 writes to cell 2410 but receives replicated data from cells 2420 and 2430.
- Each instance may be written to as a direct result of a querying operation by only its assigned writing cell. All other cells that store the instance may copy the information that resulted from the querying operation from the assigned writing cell. These other cells may not copy the information that resulted from the querying operation until that information has been written to the appropriate data structures of the assigned writing cell. As such, even though all cells that replicate data in a cohort may store a copy of an instance from that cohort, a single one of the cells that is assigned to the instance may be designated as a first cell to write to its locally-stored copy of the instance. As described in greater detail below, the other cells may thereafter update their versions of the instance.
- Each instance includes multiple shards.
- a shard represents a logical portion of the logical files that are stored in the instance. The use of shards permits the system to scale its replication process by assigning multiple replication jobs to multiple respective shards at a given moment.
- the cohort:instance:shard:file naming structure provides a logical address for data that is distinct from a physical address for the data.
- a cohort may be serviced by three cells: a first cell in North America, a second cell in Europe, and a third cell in China.
- the development team that has reserved the cells assigned to the cohort may determine that customers would be better served if a cell in India were used to support the cohort instead of the cell in China.
- the cell in India may be brought online and the cell in China may be brought offline. Aside from the period in which data is transitioned from the cell in China to the cell in India, the overall number of cells that support the cohort may not change. Further, the
- cohort:instance:shard file name for data that was initially written by the China cell may remain the same even after writing responsibilities have been transferred to the Indian cell. Indeed a particular file named according to the
- cohort:instance:shard:file protocol may be stored at the three cells that back the Cohort.
- FIG. 25 shows a schematic diagram of components that may be used to provide the data processing service. The figure shows system
- each cell can include its own data cache, which may be provided by local storage systems of the individual cells, and the data cache can store the replicating data.
- each cell may execute an instance of the local storage system.
- the local storage system may be a scalable distributed file system, such as the Google File System.
- the files or columnar data described throughout this document may be replicated among data caches 2534, 2544, and 2554 of cells 2440, 2450, and 2460, respectively.
- each cell's data cache can store all instances that are assigned to the cohort. Each cell, however, may be designated to write to one instance (or more than one instance when, for example, another one of the cells is brought off line for servicing).
- the writing cell that is designed to write to a particular instance is identified by the underline of the label for each particular instance. For example, cell A 2440 writes to instance 2410, cell D 2450 writes to instance 2420, and cell G 2460 writes to instance 2430.
- the designation "writing cell" for a particular instance indicates that the cell has been established, at least temporarily, by the overall storage system as a first cell in the cohort to write to the particular instance.
- a particular period of time e.g., one minute, one hour, or one day
- all initial writing operations to a particular instance may be performed by the writing cell, and the updated data may thereafter be replicated to the other cells.
- Writing operations during the same period of time to other instances may be performed by their other writing cells.
- the writing and replication operations are distributed among the cells of the cohort.
- the cell that writes to a particular instance may not write to other instances in the cohort, even though the cell may store the other instances.
- the cell updates the data in the stored instances with data from the writing cells for the respective instances.
- Cell D 2450 updates instance 2410 from Cell A 2440 and updates instance 2430 from Cell G 2430.
- all cells in a cohort except for the writing cell may receive updates to the particular instance from the writing cell.
- a single instance of a querying subsystem can execute at each cell in the cohort.
- the different cells or data centers may execute different manifestations of the querying subsystem.
- each occurrence of the querying subsystem e.g., occurrence 2532
- can perform data processing operations on a single data cache e.g., data cache 2530.
- all columnar data that is accessed during a data processing procedure may be stored within a single data cache at the same data center at which the data processing procedure executes.
- querying subsystem 2532 represents a manifestation of the columnar data processing system 2130 (FIG. 21 ) and the data cache 2534 represents a copy of the columnar data storage 2132 (FIG. 21 ).
- the system also may include a global storage system 2510.
- the global storage system may be a storage system that includes its own internal mechanisms for replicating data across data centers and cells.
- the cells that support the global storage system may be different than the cells in which the columnar data processing operations are supported.
- the data centers that store the columnar data and the data backing the global storage system 2510 may be at least partly in common.
- the described data processing system may not use the global storage system 2510 for all storage and data processing operations because the columnar data processing service may be optimized to operate on data that is stored within a single data center, for example, by a single data cache 2534.
- the columnar data processing service may use greater internal data processing throughput (e.g., data processing and communication among computing devices of a storage system) than external throughput (e.g., communication throughput between a storage system and a device of an external user through an application program interface).
- Storage systems that are localized to cells may provide better operational characteristics for a processing system that uses greater internal throughput than external throughput.
- the global storage system 2510 can include global file storage 2512 (e.g., for providing persistent storage for data).
- the global storage system 2510 can also include a global table 2514.
- the global table 2514 is used to store customer projects, datasets, and tables, for example. The information that is stored in the global table 2514 is described in greater detail below.
- Each cell also may include a cache state (e.g., cache state 2536).
- Each cache state may identify the state of the data that is stored by the user- generated tables (e.g., in the columnar data) in all of the data caches of a cohort.
- each cell may have, in its respective cache state, information that identifies the present state of each instance in the cohort for each cell assigned to the cohort.
- the information may also identify the present state of each file in the cohort (e.g., each block of columnar data), and may identify whether the file is up to date (e.g., whether the cell still needs to receive an update from the writing cell for the instance that stores the file).
- the cache state information may replicate quickly between cells.
- each cell may query the information in its cache state to identify whether to replicate data from another cell. In other instances, each cell distributes updates for its assigned writing instance to other cells.
- Each cell can include a writing subsystem (e.g., writing subsystem 3540).
- the writing subsystem handles writing operations to the instance that is assigned to the cell at which the writing subsystem executes.
- the writing subsystem can either parse the received query to identify values that are to be added to the instance that is assigned to the cell, or can receive such values from the querying subsystem 2532 and write the values to the local copy of the instance.
- the writing subsystem modifies portions of the instance by appending values specified by the query into certain blocks stored by the instance. In some examples, the writing subsystem modifies portions of the instance by replacing certain blocks in the instance with newly-formed blocks that include the values specified by the query.
- Each cell can include a replicating subsystem (e.g., replicating subsystem 2538) that handles the replication processes for the cell.
- the replicating system can either (i) compare copies of instances stored by the cell to copies of the instances stored by other cells to determine if the other cells have stored more up-to-date copies of the instances (as described with respect to FIG. 29), or (ii) can, after the local manifestation of the writing subsystem 3540 updates an instance, distribute the updates to copies of the instance at other cells (as described with respect to FIGS. 30A-C).
- a query distributor 2542 can receive a query that is structured to select data from a table, and can distribute the query to one of the cells (e.g., one of cells 2440, 2450, and 2460) based on the replication state of the data stored by the cells and various other criteria, such as distances between a remote computing device that submitted the query and the cells.
- FIG. 26 shows a schematic diagram of an example of the components stored within the global table and how these components relate to a user-generated table.
- User-generated table 2635 conceptually illustrates a table as the table may be understood and perceived, at least in part, by external users of the web service.
- the user-generated table 2635 represents tables described throughout this disclosure, for example, the tables described with reference to FIG. 21 and the table API 2134, the table management system 21 18, and the table metadata storage 2120.
- the user-generated table 2635 may be backed by columnar data.
- the user-generated table 2635 may be created by the data processing system in response to a method call received through an API.
- the method may be called in response to the external user providing user input for calling the method on a remote device, or may be called by an automated system that the external user had set up to access the data processing service through the external user's account.
- User-generated table 2635 includes multiple rows 2612 and multiple columns 2614.
- each row may represent a product that is sold by an online retailer and each column may represent a feature of the products (e.g., price, quantity available, and description).
- each column of data that backs the table may be segmented into blocks.
- the blocks for different columns may represent the same collections of rows.
- the data in the table may be broken into subsets of the rows (e.g., rows 1 -3, 4-6, and 7-9), but with multiple attributes for each subset of rows (e.g., each subset of rows includes data for columns A, B, and C).
- Each subset of rows may be separated into blocks that each represents data for a single attribute. Accordingly, each block can represent values for a subset of rows for a single attribute.
- each block may be stored within a particular instance in a cohort as a logical file. As such, a block may be replicated among the multiple cells of a cohort that store that instance.
- FIG. 26 illustrates that Block A 2616 is stored by Cell A 2440, Cell D 2450, and Cell G 2460, as described in greater detail with respect to FIG. 25.
- the global table 2514 stores data that identifies the nested structure of user data.
- the user data may be stored in the nested relationship
- Each level of the naming structure may provide a unique namespace.
- a customer may have one or more projects (not shown in FIG. 26).
- Each project can group many different datasets and provide a separate billing unit for each dataset.
- different departments at a customer organization may use different projects so that the provider of the data processing service can bill the departments separately for data processing usage.
- Each project can include one or more datasets.
- a dataset is a collection of tables to which an access control list can be attached.
- an external user may group multiple tables under a dataset so that the user can provide other users access to the entire set of tables without having to grant the other users access to each table individually.
- Each table includes multiple storage sets (e.g., storage set 2640).
- a storage set can be a container for multiple storage entries.
- a storage entry may be a representation in the global table 2514 of a block.
- storage entry 2650 is a representation of Block A 2616.
- Each storage entry can include an identification of its respective block (e.g., a logical address of the block in the form Cohort:lnstance:Shard:Block), an identification of each cell that is storing the block, and an identification of the cell that is designated as a writing cell for the block.
- FIG. 27 is a schematic diagram showing examples of locally stored tables.
- Each such local table may be stored at a data center, or alternatively at a cell.
- each data center may have a single table, or each cell in the data center that is used for the data processing service may have its own table.
- Each local table can identify the state of data that is stored at the respective cell.
- Each local table can further identify the state of data that is stored at the other cells in the cohort.
- local table A 2710 stores the cache state information (e.g., the cache state 2536) for cell A 2440.
- the cache state information may include status information for each table that is stored by the data cache of cell A 2440 (e.g., "User Table A (Cell A) Status” 2720 and "User Table B (Cell A) Status”).
- the cache state information may also include information for each table that is stored by the data cache of the other cells in the cohort (e.g., "User Table A (Cell D) Status” and "User Table B (Cell D) 2730").
- the status information for each user table may include the date that the columnar blocks supporting the table were cached, a most-recent date that the columnar blocks supporting the table were accessed, and a date that the table was deleted.
- the data identifies the date cached, accessed, and deleted for individual blocks in a table.
- the status information may indicate whether each columnar block is up to date, for example, as a result of a determination whether the date that a particular block was cached is more recent than a date that the particular block was cached at the writing cell (assuming that such a determination is taking place for a cell that is not the writing cell).
- the system does not permit updating a block once created. Rather, in order to effectively update a block, the system may have to delete the existing block and add a new block that includes the updated data.
- the above-described information is stored by the global table 2514.
- FIG. 28 is a flowchart showing an example of a process for reading data from a table with a query.
- a computing system receives a query that is structured to select data from a database table.
- the query may be received as part of an API call, as discussed in greater detail throughout this disclosure.
- the computing system may be a frontend computing system that receives the API calls.
- the computing system may include computing devices at a datacenter at which one or more of the cells that store the columnar data are physically located.
- the query may be a request to insert one or more data values into a database table.
- the computing system identifies that the data that is to be selected from the database table is stored by one or more blocks.
- the computing system may identify an instance in which the one or more blocks are stored, for example, by obtaining from the global table a list of blocks that back a table identified by the query and identifying the instance that stores the blocks.
- the computing system can access the global table 2514, identify the query-identified table from a list of tables, can identify a list of the storage entries that support the user-identified table, and can obtain a list of the blocks for each storage entry.
- the obtained list of blocks may include the logical address of each block (e.g., cohort:instance:shard:file) and/or the physical address of each block (e.g., celhfilename).
- the identified instance may be one of multiple partitions of data that comprise a cohort.
- the terms cohort and instance are not intended to limit the scope or type of data storage structure, and may alternatively be referred to within this disclosure as a logical collection of data (e.g., a cohort) and a logical partition of the logical collection of data (e.g., an instance).
- the computing system identifies multiple cells among which the blocks are replicated. For example, the computing system may identify, in the storage entry for each of the blocks, the cells of computing devices at which each of the blocks are replicated. Because all blocks in a table may be replicated among the same cells, the computing system may only have to identify this information from one of the storage entries.
- the replication process may be structured so that each data center has a single cell that supports the replication process, this disclosure at times may refer to the replication on a data center-by-data center basis, rather than a cell-by-cell basis, even though the replication may be among cells of the data center rather than all computing devices that comprise the data center.
- the computing system identifies whether any cells have fully replicated the one or more blocks. In other words, the computing system identifies whether any of the cells have copies of the one or more blocks in their most up-to-date form (e.g., so that no other cell more-recently stored a copy of any of the cells in a different form).
- the storage entry for each block may include, for each cell that stores the corresponding block, a flag or other indication of whether the cell stores a copy of the block that is fully up-to- date.
- the computing system analyzes data stored by the storage entry for each block to determine which of the blocks may be fully up- to-date. For example, the computing system may compare a date cached timestamp for the copy of the block that is stored by the writing cell for that block to the date cached timestamps for each of the other cells that replicate the block. If a block at one of the other cells has a date cached timestamp that is more recent than the date cached timestamp for the copy of the block at the writing cell, then the computing system may indicate that such the block at the one of the other cells is up-to-date. If all of the one or more blocks for a cell are identified as being up-to-date, the computing system may indicate that the one or more blocks are fully replicated.
- the writing cell may not be identified as being fully up-to-date, for example, when the writing cell is being taken offline and replaced by another writing cell. Data may be transferred from the old writing cell to the new writing cell, and, during the transfer, updates to the instance that is assigned to the writing cell may be written to the new writing cell. Thus, neither of these cells may be fully up to date and an indication of such a status may be stored with reference to one or both of these cells.
- the computing system can access the metadata for each of the blocks in the list and determine whether each block is a most-recent version of the block.
- the metadata for locally-stored blocks have flags that identify if the blocks are up to date.
- the computing system can compare metadata for each locally-stored block. The creation date of each locally-stored block can be compared to the creation date that is stored in the global table.
- the computing system in response to identifying that at least two cells have fully replicated the blocks, identifies a cell to handle the query based on a criterion.
- the computing system may determine which of the at least two cells is geographically closest to an estimated geographical position of the remote computing device (e.g., as determined using an IP address of the remote computing device or a GPS determination by the remote computing device). In other words, if the blocks at a local data center are up to date, the computing system requests that that the query be performed on the table at the local data center.
- the computing system may determine which of the at least two cells is temporally closest to remote computing device based on a shortest trip time for a message transmitted between the remote computing device and each of the at least two cells.
- the remote computing device may PING each of the at least two cells, and the cell associated with the shortest PING may be selected as the cell to which the query is sent.
- the computing system may determine which of the at least two cells has been determined to have the most-available computing capacity. For instance, the computing system may implement a load balancing procedure to identify which of the cells is underutilized. The computing system may select the local cell by requesting that an external process identify, based on various metrics, a cell from a collection of cells. The metrics can include load balancing and estimated latency in providing the computing system of the external user with a response.
- the computing system sends the query to the identified data center, and, in box 2824, a local copy of the querying system (e.g., querying subsystem 2532) executes the query on locally stored data (e.g., data cache 2534).
- a local copy of the querying system e.g., querying subsystem 2532
- executes the query on locally stored data e.g., data cache 2534.
- the computing system in response to identifying that none of the cells have fully replicated the blocks, identifies a cell that most- recently updated the blocks. As discussed, above, the computing system may determine that the storage entries for the blocks from which data is to be selected indicate that none of the cells are fully up-to-date. This may be the result, for example, when the blocks are stored by an instance, and the writing cell for that instance is being transitioned to another writing cell. In this case, some of the one or more blocks may be stored by the old writing cell and some of the one or more blocks may be stored by the new writing cell. In such a circumstance, the computing system may send the query to the cell that most-recently updated the one or more blocks. The computing system may determine such a cell by identifying which of the cells has a most recent date cached timestamp for any of the one or more blocks.
- querying the most-recent writing cell can ensure that the system is querying the most-recent version of the table.
- the cell that most-recently wrote to the table may be the writing cell for the instance that stores the table.
- the writing cell for such an instance may have the most up to date information for the table.
- the most-recently updated cell may perform the query.
- Performing the query at the most-recently updated cell may include requesting that the most-recently updated cell copy any necessary blocks from the old writing cell so that the most-recently updated cell has a fully updated set of blocks.
- Performing the query at the most-recently updated cell may include requesting that the most-recently updated cell request partial performance of the query at the most-recently updated cell (on the blocks stored at the most-recently updated cell), and partial performance of the query at the old writing cell (on the blocks stored at the old writing cell).
- the computing system in response to identifying that one of the cells has fully replicated the blocks, the computing system sends the query to the one cell. The one cell may then perform the query on locally-stored data.
- a writing query operation may determine the cell that is assigned as the writing cell for the instance that includes the table data, and may request that the writing cell perform the query, as described with respect to Figures 30A-C.
- FIG. 29 is a flowchart showing an example of a process for inbound replication of data.
- the process of FIG. 29 may be performed by each of multiple cells identified in a cohort to ensure that that the data in the each of the cells remains up to date.
- each of the instances in a cohort may be assigned to a cell.
- all cells may store all four instances, while one of the cells is the writing cell to four instances and two of writing cells write to only a single instance.
- each cell may include a local table that identifies the state of the data that is stored by all cells in a given cohort. This state information may replicate quickly among the cells, but the underlying data that backs the user-generated tables may not be able to replicate so quickly.
- a single cell may handle the writing operations for its assigned instance. That cell, however, also may store multiple other instances for which it is not the writing cell. The replication process for these other instances is described below. This replication process may be handled by a cache manager (e.g., cache manager 2538).
- the cache manager at a particular cell identifies a list of instances in a cohort to which the particular cell is assigned.
- the cache manager of Cell A 2440 may identify that instances 2410, 2420, and 2430 are assigned to cohort 2400 and thus are stored by Cell A 2440.
- the cache manager may identify a writing cell for each instance.
- the cache manager of Cell A 2440 may identify that Cell A is the writing cell for instance 2410, that Cell D is the writing cell for instance 2420, and that cell G is the writing cell for instance 2430.
- the cache manager may select a remote instance.
- the cache manager may select one of the instances for which the cell that includes the cache manager is not a writing cell.
- the cache manager 2538 is executed by Cell A 2440 which is the writing cell for instance 2410. As such, the cache manager 2538 may select one of instances 2420 or 2430.
- the cache manager determines if the selected instance, at its writing cell, is more up to date than the selected instance at the local cell.
- the cache manager 2538 may determine if the instance 2420 that is stored at Cell D is more up to date than the instance 2420 that is stored at Cell A 2440.
- the cache manager 2538 may perform this determination by comparing the "date cached" identifier stored for each file in the local table of Cell D 2450 (e.g., Local Table D 2760) to the "date cached" identifier stored for each file in the local table of Cell A 2440 (e.g., Local Table A 2710).
- Cell D 2450 may be the only writing cell for instance 2420, if the time cached between the two files is different and the most-recent time is for the writing cell, the cache manager 2538 can determine that instance 2420 in Cell A may have to be updated with the information from Cell D 2450. If the writing cell for the selected instance is more up to date than the local instance, the operations of box 2910 are performed.
- the cache manager copies one or more files from the selected instance at the writing cell to the selected instance at the local cell.
- each file that has a newer "date cached" identifier at the writing cell may be copied to the local cell.
- the system may not update files, but may delete old files and upload new files that include the updated information in order to update information.
- the local cell may delete files that are no longer stored at the writing cell and may add files that were newly added to the writing cell.
- the cache manager determines if all remote instances have been processed. If not, the cache manager selects (in box 2914) the next remote instance from the identified list of instances and performs the operations of box 2908. If all remote instances have been processed, the cache manager repeats the process by performing the operations of box 2902.
- FIGS. 30A-C show a swim-lane diagram illustrating an example of a process for writing and replicating data.
- a computing system receives a first writing query.
- the computing may receive from a remote computing device, a first request to insert one or more first data values into a first database table.
- the frontend server 2126 (FIG. 21 ) may receive a query through the query API 2124 as having been sent from a remote computing device of a third- party organization.
- the receipt of the query "from" the remote computing device may indicate that the query was received as having been sent from the remote computing device.
- the query may be transmitted through intervening computing systems.
- the computing system identifies that data that is responsive to the first query is stored by a first instance.
- the frontend server 2126 may analyze the query to identify a database table to which the query is structured to write.
- the frontend server 2126 may access the global table 2514 to retrieve information that indicates an instance in which the table is stored.
- the computing system identifies that a first cell is a writing cell for the first instance.
- the frontend server 2126 may access the global table 2514 in order to identify which of the multiple cells, among which the instance is replicated, serves as the writing cell for the instance.
- a logical collection of data (referred to herein as a cohort) may be replicated among multiple cells, but the writing responsibilities for portions of the logical collection of data may be divided among the multiple cells. For example, one cell may initially write to a first partition of the logical collection of data (referred to herein as an instance) and another cell may initially write to a second partition of the logical collection of data.
- the computing system may dispatch all queries that the computing system receives during a time period (e.g., 1 hour or 1 day), and that are structured to write to the first instance, to the cell that is assigned to write to the first instance.
- the system may not dispatch such queries to any other of the cells and any other of the cells may not be designated to write to the first instance during the time period.
- At least fifty queries, and maybe hundreds or thousands of queries, that are structured to write to the first instance may be received during the timer period from a variety of remote computing devices.
- the computing system sends the query to the writing cell.
- the computing system may send the first request to insert the one or more first data values into the first database table for receipt by computing devices at a particular data center that are assigned to the first cell.
- the sending of the query or the first request may include sending a query or first request that has changed in form, but that includes instructions that are similar or identical to the original query or the first request that was received from the remote computing device.
- the sending of the query "to" the writing cell may indicate that the query was sent for receipt by the writing cell.
- the query may be transmitted through intervening computing systems.
- the first cell of computing devices receives the first query.
- the first datacenter may receive, from the computing system, the first query or the first request.
- the first cell of computing devices inserts the data identified by the first writing query into the first database table.
- the first cell may insert the one or more first data values into a copy of the first database table that is stored by the first data center.
- multiple computing devices included in the first cell may generate new blocks of columnar data that add to the old blocks of columnar data the values identified by the query.
- the multiple computing devices included in the first cell may replace old blocks of columnar data with the newly-generated blocks of columnar data.
- the data values identified by the query may be included in the query or may be included in another database table that was identified by the query, for example.
- the first cell of computing devices replicates data identified by the first writing query to other cells.
- the cache manager at the cell e.g., cache manager 2538
- the first cell sends the query for receipt by each of the other cells, and each of the other cells executes the query.
- a second cell of computing devices receives the data identified by the first writing query.
- the second cell may receive the updated one or more blocks of columnar data, or may receive the query.
- the second cell of computing devices inserts the data identified by the first writing query into the first database table.
- the second cell of computing devices may insert the one or more first data values into a copy of the first database table that is stored by the second data center.
- the second cell of computing devices may do this by replacing certain blocks of columnar data with the updated blocks of columnar data that the second cell received from the first cell.
- the second cell of computing devices does not generate the updated blocks of columnar data and instead just receives such updated blocks of columnar data from the first cell.
- the second cell may execute the query that the second cell received from the first cell, and insert values identified by the query into the copy of the first database table that is stored by the second cell.
- Boxes 3026 through 3044 illustrate a process of receiving a second writing query and writing data initially to the second cell of computing devices, whereby the second cell of computing devices replicates the data to the first cell of computing devices.
- the operations of boxes 3026 through 3044 are similar to those of boxes 3002 through 3024, except that the second writing query is structured to write to a second instance that is assigned the second cell as a writing cell.
- Boxes 3026-3044 have been included in the diagram of FIGS. 30A-C to illustrate that different queries are dispatched to different cells of computing devices based on the logical storage location of the data to which the queries are structured to write.
- each of the data centers may eventually end up with an up-to-date set of data, such that all cells among which an instance and its parent cohort are replicated may eventually store the same versions of one or more blocks of data.
- each of the cells among which the data is replicated may be capable of executing reading queries on the data. This is process is illustrated by boxes 3050 through 3058, which illustrate that a remote computing device's submission of a query that is structured to write to either a first database table or a second database table may be received by either the first cell or the second cell, and the local querying subsystem (e.g., querying subsystem 2532) may execute the query.
- the cell that executes a reading query may be selected as described by Figure 28.
- all data that is stored by the first database table is stored within the first instance, and all data that is stored by the second database table is stored within the second instance.
- all columnar data blocks that back a table may be stored within a same instance. Blocks that back a same table may not be split between different instances, in some implementations.
- the first cell is designated as an only cell of the multiple cells to write to a first instance of data concurrently as a second cell is designated as an only cell of the multiple cells to write to a second instance of data.
- all queries that write to the first instance may be designated for routing to the first cell and all queries that write to the second instance may be designated for routing to the second cell.
- a dataset can contain zero or more tables. There may not be an identified limit to the number of tables or the total data size of a dataset.
- Dataset access control lists can apply to datasets, tables, and table data. Jobs may be dependent on a mix of dataset and project ACLs.
- the project owner may have delete rights to any dataset within the project, but may not be guaranteed any other rights to any dataset in that project.
- the property "kind” can have a value “processingservice #dataset” and may not be mutable. This property can be the resource type.
- the property "id” can have a value "string” and may not be mutable.
- the fully-qualified unique name of this dataset may be in the format
- the dataset name without the project name may be given in the datasetld field.
- the dataset name may be given in the datasetld field.
- one may leave this field blank, and instead specify the datasetld field.
- the property "selfLink” can have a value "string” and may not be mutable. It may reference a URL that can be used to access this resource again. This URL can be used in Get or Update requests to this resource.
- the property "project ID can have a value "string” and may be mutable on creation.
- the property can be the ID of the container project. The default may be the current project.
- the property "datasetld” can have a value "string” and may be mutable on creation.
- the property can be a unique ID for this dataset, without the project name. This may be an optional field. If this is not specified when a dataset is created, an ID may be assigned for the dataset.
- the dataset ID may be unique within the project.
- the dataset ID may be a string of 1 -1024 characters satisfying the regular expression [A-Za-zO-9J
- the property "friendlyName” can have a value "string” and may be mutable, but requires owner rights. This property can be an optional descriptive name for this dataset, which may be shown in any data processing service user interfaces for browsing the dataset.
- the property datasetld may be used for making API calls. The default is an empty string.
- the property "description” can have a value "string” and may be mutable, but requires owner rights. This property can be an optional arbitrary string description for the dataset. This might be shown in the data processing service user interface for browsing the dataset. The default is an empty string.
- the property "access” can have a value "list” and may be mutable, but requires owner rights. This property can be optional and may describe users' rights on the dataset.
- the same role can be assigned to multiple users, and multiple roles can be assigned to the same user.
- Default values assigned to a new dataset may be as follows: OWNER - Project owners, dataset creator;
- the property "access. role” can have a value "string” and may be mutable, but requires owner rights. This property describes the rights granted to the user specified by the other member of the access object. The following string values are supported: READ - User can call any list() or get() method on any collection or resource. WRITE - User can call any method on any collection except for datasets, on which they can call list() and get(). OWNER - User can call any method. The dataset creator is granted this role by default. [00310]
- the property "access. userByEmail” can have a value "string” and may be mutable, but requires owner rights. This property describes a fully qualified email address of a user to grant access to. For example: fred@example.com.
- the property name "access. groupByEmail” can have a value "string” and may be mutable, but requires owner rights. This property describes a fully- qualified email address of a mailing list to grant access to.
- the property "access. domain” can have a value "string” and may be mutable, but requires owner rights. This property describes a domain to grant access to. Any users signed in with the domain specified may be granted the specified access. Example: “example.com”.
- the property “creationTime” can have a value “long” and may not be mutable. This property describes the date when this dataset was created, in milliseconds since the epoch.
- the property "last ModifiedTime” can have a value “long” and may not be mutable. This property describes the date when this dataset or any of its tables was last modified, in milliseconds since the epoch.
- processinqservice.datasets.list [00317] This method can list all the datasets in the specified project to which the caller has read access; however, a project owner can list (but not necessarily get) all datasets in his project.
- required ACLs To call this method, the user may have to have one of the following rights: project.READ/WRITE/OWNER may enable the user to list all datasets in the project, dataset. access. READ/WRITE/OWNER may return any datasets that the user has explicit access to.
- the parameter "pageToken” can have the type "integer.”
- a page token can be used when requesting a specific page in a set of paged results.
- the parameter "maxResults” can have the type "integer.” This parameter can be the maximum number of rows to return. If not specified, it may return up to the maximum amount of data that may fit in a reply.
- processingservice#datasetl_ist The property can be the resource type.
- the property "etag” can have the value "string.”
- the property can be a hash of the page of results.
- the property "nextPageToken" can have the value "string.”
- the property can be a token to request the next page of results. It may be present only when there is more than one page of results.
- the property "datasets” can have the value "list.”
- the property can be an array of one or more summarized dataset resources. The property may be absent when there are no datasets in the specified project.
- the property "datasets. id" can have the value "string.”
- the property can be the fully-qualified unique name of this dataset in the format
- the property "datasets. projectld” can have the value "string.”
- the property can be the ID of the container project.
- the property "datasets. datasetld” can have the value "string.”
- the property can be the unique ID for this dataset. This can be the ID value without the project name.
- the property "datasets.friendlyName” can have the value "string.”
- the property can be a descriptive name for this dataset.
- This method can return the dataset specified by datasetlD.
- the user may specify the unqualified datasetid value and not the fully-qualified id value of the dataset.
- Response The response returns a dataset resource or an error message. If the requested dataset does not exist, it returns an HTTP 404 error.
- This method may create a new empty dataset.
- Required ACLs To call this method, the user may have one of the following rights: Write or Owner rights on the containing project.
- the response may return a copy of the new dataset resource if successful, or an error message if not successful.
- This method can update information in an existing dataset, specified by datasetld. Properties not included in the submitted resource may not be changed. If a user includes a member without a value, it may be reset to null. Note that if a user includes the access property without any values assigned, the request may fail as the user may have to specify at least one owner for a dataset.
- WRITE access on the dataset to may be required to modify any member except access.
- OWNER access on the dataset may be required to modify the access member.
- the specified access list may completely overwrite the existing access list. If a user specifies an empty access list, access may be revoked to everyone except the user; the user cannot remove all owners from a dataset.
- Request data The user can pass in the following data object with any values that the user wishes to modify. The user can omit any properties that the user wishes do not wish to change.
- domain string
- allAuthenticatedUsers boolean
- This method deletes the dataset specified by datasetld value. Before a user can delete a dataset, the user may have to delete all its tables, either manually or by specifying deleteContents. Immediately after deletion, the user can create another dataset with the same name.
- the parameter "deleteContents” can have the type "Boolean.”
- the parameter is optional and, if true, deletes all the tables in the dataset. If False and the dataset contains tables, the request may fail. The default is False.
- Response The method returns an HTTP 202 (not found) response if successful, or an error message.
- JOB RESOURCE [00357]
- a job is an operation performed at the request of a user on a dataset. Jobs include SQL queries, table import requests, and table export requests, for example.
- the resource contains a different configuration member depending on what kind of job this is.
- the JSON data structure for a job follows:
- the property "kind” can have a value "processingservice#job” and may not be mutable.
- the property can be the resource type.
- the property "id” can have a value "string” and may not be mutable.
- the property can be the fully-qualified job name, in the format projectl&.jobld. When creating a new job, the user may not specify this value, and may instead specify the
- the unqualified job ID can be retrieved from the jobld field.
- the property "selfLink” can have a value "string” and may not be mutable.
- the property can be an URL that can be used to access this resource again. The user can use this URL in get() requests for this resource.
- the property "projectld” may have a value "string” and may not be mutable.
- the property is the ID of the project that contains this job. This is the project that may be billed for the job.
- the property "jobld” may have a value "object” and may be mutable at creation.
- the property may reference a unique ID for this job within the project. This value may be optional when the user creates a new job. If the user does not specify a value here, a random ID may be chosen.
- the property may have to be a string of 1 -1024 characters satisfying the regular expression [A-Za- z0-9_ ⁇ -].
- the property "configuration” may have a value "object” and may be mutable at creation. The property may reference an object that specifies the details of this job. When inserting a new job, the user may include only one of the following child objects, depending on what type of job it is. load - Create and populate a new table from a CSV file, query - Run a query, extract - Export a Processingservice table to Company Storage as a CSV file.
- the property "configuration. query” may have a value "object” and may be mutable at creation.
- the property can be an object that must be present only when sending a query. If the query returns one or more result rows, results may be stored in the table specified by the destinationTable property.
- the property "configuration. query.query” may have a value "string” and may be mutable at creation.
- the property can be a query string, following the Processingservice query syntax of the query to execute.
- Table names may have to be qualified by dataset name in the format projectld:datasetld.tableld unless the user specifies the defaultDataset value. If the table is in the same project as the job, the user can omit the project ID.
- the property "configuration. query.destinationTable” may have a value "object” and may be mutable at creation.
- the property can be an optional object describing a destination table where results may be saved. The user may specify whether to create a new or overwrite an existing table by specifying createDispensation and writeDispensation.
- the property "configuration. query.destinationTable. projectld” may have a value "string” and may be mutable at creation.
- the property can be the project ID of the dataset where the table should be created.
- the property "configuration. query.destinationTable.datasetld” may have a value "string” and may be mutable at creation.
- the property can be the datasetld of the dataset in which to create the result table. This may not be qualified by the project ID. The user may have to have write access on this dataset. If the specified dataset does not exist, the method may return an error.
- the property "configuration. query.destinationTable. tableld” may have a value "string” and may be mutable at creation.
- the property may reference the tableld of the table to hold the results. This can be an existing table or not, depending on the query. createDisposition value.
- the property "configuration. query.createDisposition” may have a value "string” and may be mutable at creation. This property may be optional and can be whether to create a results table if no table by that ID already exists.
- the following string values may be supported: CREATE_NEVER - [Default] Do not create a new table to hold results. CREATE_IF_NEEDED - Create a new table if one does not exist and the query result set has more than zero records.
- the property "configuration. query.writeDisposition” may have a value "string” and may be mutable at creation.
- the property may be optional and may reference whether or not to overwrite an existing results table with the specified name.
- the following string values are supported: WRITE_EMPTY - [Default] Only write to a table with no data, otherwise fail.
- WRITE_TRUNCATE - Clear the data from the existing table and append the output data.
- the table schema must match the schema of the new data.
- the table schema may have to match the schema of the new data.
- the property "configuration. query.defaultDataset” may have a value "object” and may be mutable at creation.
- the property may specify the default datasetid and projectid to assume for any unqualified table names in the query. If not set, all table names in the query string may be fully-qualified in the format projectld:datasetld.tableid. The user may have to specify either both datasetid and projectid, or neither (omit this object).
- the property "configuration. query.defaultDataset.datasetld” may have a value "string” and may be mutable at creation.
- the property may reference the assumed dataset ID of any tables that are not qualified by dataset.
- the property "configuration. query.defaultDataset.projectld” may have a value "string” and may be mutable at creation.
- the property may reference the assumed project ID of any tables not qualified by project.
- the property "configuration. load” may have a value "object” and may be mutable at creation.
- the property may reference an object that must be present only when importing data into a new or existing table from a CSV data file.
- the property "configuration. load. sourceUris” may have a value "list” and may be mutable at creation.
- the property may reference a list of one or more Company Storage objects containing table data.
- the device for the user calling jobs. insert may have to have read access to all objects referenced. All objects may have to be CSV files in the proper format, with the same table schema. These may have to be be fully-qualified names, for example:
- the property "configuration. load. schema” may have a value “object” and may be mutable at creation.
- the property may reference a schema descriptor that describes all imported tables. All tables may follow the schema described in this object.
- the property "configuration. load. schema.fields” may have a value "list” and may be mutable at creation.
- the property may reference a list of one or more objects, each describing a column in the imported table(s) schema. These values may be applied to the table created, if a new table is created rather than appended to.
- the property "configuration. load. schema.fields. name” may have a value "string” and may be mutable at creation.
- the property may reference a friendly name for this column. This name may be assigned to the column in the newly created table.
- the property "configuration. load. schema.fields. type” may have a value "string” and may be mutable at creation.
- the property may reference the field type.
- the property "configuration. load. schema.fields. mode” may have a value "string” and may be mutable at creation.
- the property may reference the field mode.
- the property "configuration. load. schema.fields.fields” may have a value "list of schema objects" and may be mutable at creation. The property may be present only in a column that holds nested fields. This object may describe any nested fields.
- the property "configuration. load. destinationTable” may have a value "object” and may be mutable at creation. This object may be the tablelD of the destination table to hold the query results, if more than zero result rows are returned. The user may specify whether to create a new table or overwrite or append to an existing one by setting createDispostion and writeDispostion.
- the property "configuration. load. destinationTable.projectld” may have a value "string” and may be mutable at creation.
- the property may reference the assumed project ID of any tables not qualified by project.
- the property may reference the ID of the project that contains the dataset to write the result table to. If not specified, the system may write to the project containing the job.
- the property "configuration. load. destinationTable.datasetld” may have a value "string” and may be mutable at creation.
- the property may reference the unqualified ID of the dataset to write the result table to. The user may have to have write access in this dataset.
- the property "configuration. load. destinationTable.tableld” may have a value "string” and may be mutable at creation.
- the property may reference the unqualified table ID of the table to create or append to.
- the property "configuration. load. createDisposition” may have a value "string” and may be mutable at creation. The property may reference whether or not to create a new table, if none exists. The following string values may be supported: CREATE_NEVER [Default] - Do not create a new table.
- the property "configuration. load.writeDisposition” may have a value "string” and may be mutable at creation. The property may reference whether or not to overwrite an existing table. The following string values may be supported: WRITE_EMPTY - [Default] Only write to a table with no data, otherwise fail. WRITE_TRUNCATE - If a table exists, replace existing data with new data.
- the property "configuration. extract” may have a value "object” and may be mutable at creation.
- the property may reference an object that may be present only when exporting a table to Company storage.
- the property "configuration. extract.sourceTable” may have a value
- object and may be mutable at creation.
- the property may reference an object describing the Processingservice table to be exported.
- the property "configuration. extract.source Table. projectld” may have a value "string” and may be mutable at creation.
- the property may reference the ID of the project containing the source table.
- the property "configuration. extract.source Table. datasetld” may have a value "string” and may be mutable at creation.
- the property may reference the datasetld of the dataset containing the source table. The user must have read access on this dataset.
- the property "configuration. extract.source Table. tableld” may have a value "string” and may be mutable at creation.
- the property may reference the tableld of the table to export, in the specified dataset.
- the property "configuration. extract.destinationUri” may have a value "string” and may be mutable at creation.
- the property may reference the fully- qualified Company Storage URI of the object where the user has requested that the table is saved. This is in the format bucket/object with the gs:// prefix. The user may have write access on this bucket.
- the property "status” may have a value "object” and may be mutable at creation.
- the property may reference the status of this job. The user can examine this value when polling an asynchronous job to see if the job is complete.
- the property "status. state” may have a value "string” and may be mutable at creation.
- the property may reference the current state of this job.
- the property supports the following string values: PENDING - Queued. RUNNING - Running. DONE - Completed, either successfully or not. If unsuccessful, the errorResult field should contain additional information.
- the property "status. errorResult” may have a value "object” and may not be mutable at creation.
- the property may reference an object that may only be present if the job has failed.
- the property "status. errorResult.domain” may have a value "string” and may not be mutable at creation.
- the property may reference a scoping mechanism that, when combined with status.errors. reason, defines a unique string.
- the property "status. errorResult.code” may have a value "string” and may not be mutable at creation.
- the property may reference a
- the property "status. errorResult.errorMessage” may have a value "string” and may not be mutable at creation. The property may reference a user- friendly description of the error. Status. errors. code may be used to trap specific errors.
- the property "status.errors” may have a value "list” and may not be mutable at creation.
- the property may reference a list of non-fatal errors that occurred during job processing. It is possible that a job can complete successfully even if there are some errors. In import or export requests, it is possible that some rows were unable to be imported or exported due to errors.
- the property "status. errors. domain” may have a value "string” and may not be mutable at creation.
- a scoping mechanism that, when combined with status.errors. reason, defines a unique string.
- the property "status. errors. code” may have a value "string” and may not be mutable at creation.
- the property may reference a Processingservice error code appropriate for this error.
- the property "status. errors. debuglnfo" may have a value "string” and may not be mutable at creation. The property may reference additional information about the error.
- the property "status. errors. errorMessage” may have a value "string” and may not be mutable at creation.
- the property may reference a user-friendly description of the error. Use status.errors. code to trap specific errors.
- the property "statistics" may have a value "object” and may not be mutable at creation.
- the property may reference information about this job.
- the property "statistics. startTime” may have a value “long” and may not be mutable at creation.
- the property may reference the start time of this job, in milliseconds since the epoch. This starts ticking when the job status changes to RUNNING, not when the request is sent by the user or received by
- the property "statistics. endTime” may have a value “long” and may not be mutable at creation. This may be end time of the job, in milliseconds since the epoch. This may be when the status changed to DONE, successfully or not. If the job has not finished, this member may not be present. [00409] processinqservice.jobs.list
- This method may list all the Jobs in the current project that the user has READ access to. Jobs may be retained indefinitely unless the user calls processingservice.jobs. delete on a job. Authentication may be required. To call the method, a user may need to have one of the following rights: project.READ;
- the parameter "page Token” can have a type of "Integer.”
- the parameter is optional and may reference a page token used when requesting a specif page in a set of paged results.
- the parameter "maxResults" can have a type of "Integer.”
- the parameter is optional and may reference the maximum number of rows to return. If not specified, the method may return up to the maximum amount of data that may fit in a reply.
- the property "kind” can have a value "processingservice#jobl_ist.”
- the property can reference the resource type of the response.
- the property "etag” can have a value "string.”
- the property can reference a hash of this page of results.
- the property "nextPageToken" can have a value "string.”
- the property can reference a token to request the next page of results.
- the property may be present only when there is more than one page of results.
- the property "jobs" can have a value "list.”
- the property may reference an array of one or more Job descriptions.
- the property may be absent when there are no jobs in the specified project.
- the property "jobs. id" can have a value "string.”
- the property may reference the fully-qualified job ID, in the format projectld:jobld.
- the property "jobs. projectld” can have a value "string.”
- the property may reference the id of the project that contains this job.
- the property "jobs.jobld” can have a value "string.”
- the property may reference the jobld of the job.
- the property "jobs. state” can have a value "string.”
- the property may reference the current state of this job.
- jobs.startTime can have a value "long.”
- the property may reference the start time of this job, in milliseconds since the epoch.
- the clock starts ticking when the job status changes to RUNNING, not when the request is sent by the user or received by the processing service.
- the property "jobs.endTime” can have a value "long.”
- the property reference the end time of this job, in milliseconds since the epoch.
- the property is when the status changed to DONE, successfully or not. If the job has not finished, this may be null.
- jobs.errorResult can have a value "object.” An object that may be present only if a job has failed.
- This method retrieves the specified job by ID.
- the user may specify the unqualified jobld value, not the fully-qualified id value of the job.
- the user may have to have one of the following rights:
- dataset.access.READ dataset.access. WRITE; dataset.access. OWNER;
- the response can be a job resource or an error message. If the requested job does not exist, the system may return an HTTP 404 error. [00430] processinqservice.jobs.insert
- This method starts a new asynchronous job.
- the user may have to have write access to a project in order to run a job.
- This method returns immediately.
- the user may have to call jobs.get() and examine the job status to learn when the job is complete.
- the user may have to include one and only one of the following child members in the job resource. The child member that that the user includes defines the type of job that this is.
- the child member "load” may load data from a CSV file into a table.
- the job can create a new table, overwrite an existing table, or append data to an existing table with a matching schema, as the user specifies in the job
- the caller may need to have read rights on any objects holding the data to import.
- the child member "query" may query.
- the child member "extract" may export a data processing service table to Company Storage as a CSV file, using the data processing service CSV syntax.
- Request Data The user can pass in the following object with appropriate values.
- the job resource documentation can provide additional information.
- the method deletes a completed job specified by jobld.
- the job may have to be completed, either successfully or not, to call this method.
- the method runs a synchronous SQL query.
- the user may call Jobs.insert(). This method creates a result table, or deposits data in the specified table, if there are any results, and returns the
- Request data An object with the following syntax. ⁇
- the property "maxResults" can have a value "long.”
- the property is optional and can reference the maximum number of results to return per page of results. If the response list exceeds the maximum response size for a particular response, the user may have to page through the results. The default may be to return the maximum response size.
- configuration ⁇ job. configuration. query object ⁇
- status ⁇ job.status object ⁇
- status ⁇ job.status object ⁇
- status ⁇ job. statistics object ⁇
- the property name "kind” can have a value of
- processingservice#queryResults The property can reference the resource type of the response.
- the property name "id" can have a value of "string.”
- the property can reference the fully-qualified job name, in the format projectld:jobld.
- the property name "selfLink” can have a value of "string.”
- the property can reference an URL that can be used to access this resource again. The user can use this URL in Get() requests for this resource.
- the property name "projectld” can have a value of "string.”
- the user can use the ID of the project that contains this job.
- the property name "jobld” can have a value of "string.”
- the property can reference a unique ID for this job within the project.
- the property name "configuration” can have a value of "object.”
- the property can reference information about the query.
- the property name "status” can have a value of "object.”
- the property can reference the status of this job. The user can examine this value when polling an asynchronous job to see if the job is complete.
- the property name "statistics” can have a value of "object.” The property can reference statistics about this job.
- the property name "schema” can have a value of "object.”
- the property can reference an object describing the schema of the result set.
- the property name "job” can have a value of "object.”
- the property can reference a job resource describing the query job.
- totalRows can have a value of "integer.”
- the property can reference the total number of rows in the complete query result set, which can be more than the number of rows in this single page of results.
- the property name "rows" can have a value of "list.”
- the property can reference an object with as many results as can be contained within the maximum permitted reply size. To get any additional rows, the user may call processingservice.tabledata.list().
- the property name "rows.f can have a value of "list.”
- the property may represent a single row in the result set, consisting of one or more fields.
- the property name "rows.f. v" can have any value.
- the property may contains the field value in this row.
- a user can list projects to which the user has read access using the processingservice. projects.list method; however, to create or manage projects, the user may have to use a separate system.
- the project name and the project ID are not the same thing: a project name may be a human-readable string, and may not be required to be unique.
- a project ID may be a unique
- GUID string across all projects registered by the system.
- a project can hold zero or more datasets.
- the user may have to assign it to an existing project.
- the user may have at least have read access to a project to be able to see any of the datasets that it contains.
- the parameter "pageToken” can have the type "Integer.”
- the parameter may be optional and may reference a page token used when requesting a specific page in a set of paged results.
- the parameter "maxResults" can have the type "Integer.”
- the parameter may be optional and may reference the maximum number of rows to return. If not specified, the method may return up to the maximum amount of data that may fit in a reply.
- processingservice#datasetl_ist The property can reference the resource type.
- the property "etag” can have the value "string.”
- the property can reference a hash of this page of results.
- the property "nextPageToken" can have the value "string.”
- the property can reference a token to request the next page of results.
- the property may be present only when there is more than one page of results.
- the property "projects” can have the value "list.”
- the property can reference an array of zero or more projects to which the user has read/write access.
- the property "proejcts.id” can have the value "string.”
- the property can reference the ID of this project.
- the property "projects.friendlyName” can have the value "string.”
- the property can reference a descriptive name for this project.
- Tabledata is used to return a slice of rows from a specified table. All columns may be returned. Each row is actually a Tabledata resource. To get a slice of rows, the user may call processingservice. tabledata. Iist(). The user may specify a zero-based start row and a number of rows to retrieve in the list() request. Results may be paged if the number of rows exceeds the maximum for a single page of data. The column order may be the order specified by the table schema.
- a JSON representation of a single row of table data may be retrieved. See tabledata. Iist() for details about how the returned data is structured.
- This method may be used to retrieve table data from a specified set of rows.
- the user may specify a zero-based starting row. If the user requests a row index greater than the number of available rows, the method may return successfully, but without a "rows" member. Column labels, table schema, and other metadata are may not be part of the response. Note that the response also may
- Data may be returned in a JSON object that can be accessed in JavaScript, where the cell data is stored in the V member of a two dimensional array, accessible like this:
- the parameter "startlndex” can have the type “Integer.”
- the parameter is optional and may reference the zero-based index of the starting row.
- the parameter "maxResults" can have the type "Integer.”
- the parameter is optional and may reference the maximum number of rows to return. If not specified, the method may return up to the maximum amount of data that may fit in a reply.
- the property "kind” can have a value
- processingservice#tableDatal_ist The property can reference the resource type of the response.
- totalRows can have a value "integer.”
- the property can reference the total number of rows in the complete table, which can be more than the number of rows in this single page of results.
- the property "rows" can have a value "list.”
- the property can reference an array of one or more table rows. If the user requests a table with no data, or with a start index beyond the table length, this member may be absent.
- the property "rows.f can have a value "list.”
- the property can reference an array of cells in the row.
- the property "rows.f.v” can have any value.
- the property can reference the value of a single cell in the row.
- a table's schema is specified when the table is crated. ⁇ "kind”: “processingservice#table”,
- the property "kind” can have the value "processingservice#table, and may not be mutable.
- the property can reference the resource type ID.
- the property "id” can have the value "string,” and may not be mutable.
- the property can represent the fully-qualified name of this table in the format proejctld:datasetld:tableld.
- the property "selfLink” can have the value "string,” and may not be mutable.
- the property can reference a URL that can be used to access this resource. This URL can be used in the get() or update() requests to this resource.
- the property "projectid” can have the value "string,” and may be mutable on creation.
- the property can reference the projectid of the project that contains this table.
- the property "datasetid” can have the value "string,” and may be mutable on creation.
- the property can reference the datasetid of the dataset that contains this table.
- the property "tableld” can have the value "string,” and may mutable on creation.
- the property can reference a unique ID for this table. Use this to refer to the table in code. The user may have to specify this value when creating a new table.
- This property may have to be a string of 1 -1024 characters satisfying the regular expression [A-Za-z0-9 ⁇ -].
- the property "friendlyName” can have the value "string,” and may be mutable on creation.
- the property can reference an optional user-friendly name for this table.
- the property "description” can have the value "string,” and may be mutable.
- the property can reference a user-friendly description of this table.
- the property “schema” can have the value "object,” and may be mutable on creation.
- the property can reference an object describing the schema of this table.
- the property "schema.fields" can have the value "list,” and may be mutable on creation.
- the property can reference an array of items describing this field.
- the property "schema.fields. name” can have the value "string,” and may be mutable on creation. The property can reference the name of this field.
- the property "schema.fields. type” can have the value "string,” and may be mutable on creation. The property can reference the data type of this field.
- the property "schema.fields. mode” can have the value "string,” and may be mutable on creation. The property can reference the mode of this field (whether it can be null or not).
- the property "schema.fields.fields” can have the value "list,” and may be mutable on creation.
- the property can be used for describing nested fields in a table.
- the property "creationTime” can have the value “long,” and may not be mutable.
- the property can reference the time when this table was created, in milliseconds since the epoch.
- the property "lastModifiedTime” can have the value “long,” and may not be mutable.
- the property can reference the time when either the table schema or table data was last modified, in seconds since the epoch.
- processinqservice.tables.list [00518] This method lists all tables in the specified dataset.
- the parameter "pageToken” can have the type "Integer.”
- the parameter may be optional and may reference a page token used when requesting a specific page in a set of paged results.
- the parameter "maxResults" can have the type "Integer.”
- the parameter may be optional and may reference the maximum number of rows to return. If not specified, the method may return up to the maximum amount of data that may fit in a reply.
- the property "kind” can have the value "string.”
- the property references the resource type of the response.
- the property "etag” can have the value "string.”
- the property references a hash of this page of results.
- the property "nextPageToken" can have the value "string.”
- the property references a token to request the next page of results.
- the property may be present only when there is more than one page of results.
- the property "tables" can have the value "list.”
- the property references an array of descriptions of one or more tables. The property may be absent when there are no tables in the specified dataset.
- the property "tables. projectld” can have the value "string.”
- the property references the projectld of the project that contains this table.
- the property "tables. datasetid” can have the value "string.”
- the property references the datasetid of the dataset that contains this table.
- the property "tables. tableld” can have the value "string.”
- the property references the unique ID for this table.
- the property "tables.friendlyName” can have the value "string.”
- the property references the user-friendly name of this table.
- the property "totalltems" can have the value "integer.”
- the property references the total number of tables in the dataset.
- This method gets the specified table resource by tableld. This method may not return the data in the table, only the table resource, which describes the structure of this table.
- tabledata.list() The user should specify the unqualified tableld value, not the fully-qualified id value of the table.
- the method creates a new, empty table in the dataset, with the schema provided. Once a table is created using this method, the user may not be able to modify the schema, even if the table does not yet hold data. To populate a table with data, a user can create an appropriate job. [00541] Required ACLs. To call this method, the user may have to have one of the following rights: dataset.access. WRITE; dataset.access. OWNER.
- Request data Submit with an object of the following syntax.
- processinqservice.tables.update [00546] The method updates information in an existing table, specified by tableld.
- Request data submit an object with the following properties as desired. Properties not included in the submitted resource may not be changed.
- FIG 31 is a block diagram of computing devices 3100, 3150 that may be used to implement the systems and methods described in this document, as either a client or as a server or plurality of servers.
- Computing device 3100 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.
- Computing device 3150 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices.
- Additionally computing device 3100 or 3150 can include Universal Serial Bus (USB) flash drives.
- the USB flash drives may store operating systems and other applications.
- the USB flash drives can include input/output components, such as a wireless transmitter or USB connector that may be inserted into a USB port of another computing device. The components shown here, their
- Computing device 3100 includes a processor 3102, memory 3104, a storage device 3106, a high-speed interface 3108 connecting to memory 3104 and high-speed expansion ports 31 10, and a low speed interface 31 12 connecting to low speed bus 31 14 and storage device 3106.
- Each of the components 3102, 3104, 3106, 3108, 31 10, and 31 12, are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 3102 can process instructions for execution within the computing device 3100, including instructions stored in the memory 3104 or on the storage device 3106 to display graphical information for a GUI on an external input/output device, such as display 31 16 coupled to high speed interface 3108.
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 3100 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 3104 stores information within the computing device 3100.
- the memory 3104 is a volatile memory unit or units.
- the memory 3104 is a non-volatile memory unit or units.
- the memory 3104 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 3106 is capable of providing mass storage for the computing device 3100.
- the storage device 3106 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 3104, the storage device 3106, or memory on processor 3102.
- the high speed controller 3108 manages bandwidth-intensive operations for the computing device 3100, while the low speed controller 31 12 manages lower bandwidth-intensive operations. Such allocation of functions is exemplary only.
- the high-speed controller 3108 is coupled to memory 3104, display 31 16 (e.g., through a graphics processor or
- low-speed controller 31 12 is coupled to storage device 3106 and low-speed expansion port 31 14.
- the low- speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 3100 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 3120, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 3124. In addition, it may be implemented in a personal computer such as a laptop computer 3122.
- components from computing device 3100 may be combined with other components in a mobile device (not shown), such as device 3150.
- a mobile device not shown
- Each of such devices may contain one or more of computing device 3100, 3150, and an entire system may be made up of multiple computing devices 3100, 3150 communicating with each other.
- Computing device 3150 includes a processor 3152, memory 3164, an input/output device such as a display 3154, a communication interface 3166, and a transceiver 3168, among other components.
- the device 3150 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 3150, 3152, 3164, 3154, 3166, and 3168, are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 3152 can execute instructions within the computing device 3150, including instructions stored in the memory 3164.
- the processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. Additionally, the processor may be implemented using any of a number of architectures.
- the processor 410 may be a CISC (Complex Instruction Set Computers) processor, a RISC (Reduced
- MISC Minimum Instruction Set
- the processor may provide, for example, for coordination of the other components of the device 3150, such as control of user interfaces, applications run by device 3150, and wireless communication by device 3150.
- Processor 3152 may communicate with a user through control interface 3158 and display interface 3156 coupled to a display 3154.
- the display 3154 may be, for example, a TFT (Thin-Film-Transistor Liquid Crystal Display) display or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology.
- the display interface 3156 may comprise appropriate circuitry for driving the display 3154 to present graphical and other information to a user.
- the control interface 3158 may receive commands from a user and convert them for submission to the processor 3152.
- an external interface 3162 may be provide in communication with processor 3152, so as to enable near area communication of device 3150 with other devices.
- External interface 3162 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
- the memory 3164 stores information within the computing device 3150.
- the memory 3164 can be implemented as one or more of a computer- readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.
- Expansion memory 3174 may also be provided and connected to device 3150 through expansion interface 3172, which may include, for example, a SIMM (Single In Line Memory Module) card interface. Such expansion memory 3174 may provide extra storage space for device 3150, or may also store applications or other information for device 3150.
- SIMM Single In Line Memory Module
- expansion memory 3174 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 3174 may be provide as a security module for device 3150, and may be programmed with instructions that permit secure use of device 3150.
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include, for example, flash memory and/or NVRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 3164, expansion memory 3174, or memory on processor 3152 that may be received, for example, over transceiver 3168 or external interface 3162..
- Device 3150 may communicate wirelessly through communication interface 3166, which may include digital signal processing circuitry where necessary.
- Communication interface 3166 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency
- transceiver 3168 In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown).
- GPS (Global Positioning System) receiver module 3170 may provide additional navigation- and location-related wireless data to device 3150, which may be used as appropriate by applications running on device 3150.
- Device 3150 may also communicate audibly using audio codec 3160, which may receive spoken information from a user and convert it to usable digital information. Audio codec 3160 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 3150. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 3150.
- Audio codec 3160 may receive spoken information from a user and convert it to usable digital information. Audio codec 3160 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 3150. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 3150.
- the computing device 3150 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 3180. It may also be implemented as part of a smartphone 3182, personal digital assistant, or other similar mobile device.
- Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network).
- a communication network examples include a local area network (“LAN”), a wide area network (“WAN”), peer-to-peer networks (having ad-hoc or static members), grid computing infrastructures, and the Internet.
- LAN local area network
- WAN wide area network
- peer-to-peer networks having ad-hoc or static members
- grid computing infrastructures and the Internet.
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client- server relationship to each other.
- Implementation 1 is a computer-implemented method.
- the method comprises receiving, by a computing system and from a remote computing device, a first request to insert one or more first data values into a first database table.
- the method comprises identifying, by the computing system, that first data stored by the first database table is stored in a first logical partition of a logical collection of data, wherein: (i) the logical collection of data is designated for replication among multiple data centers such that a copy of the logical collection of data is designated to be stored by each of the multiple data centers, (ii) the logical collection of data is logically partitioned into multiple logical partitions which together comprise the logical collection of data, and (iii) the first logical partition is one of the multiple logical partitions of data.
- the method comprises identifying, by the computing system, that a first data center of the multiple data centers is designated as one data center, of the multiple data centers, that initially writes to the first logical partition of data.
- the method comprises sending, by the computing system and to the first data center, the first request to insert the one or more first data values into the first database table.
- the method comprises receiving, by the computing system and from the remote device, a second request to insert one or more second data values into a second database table.
- the method comprises identifying, by the computing system, that second data stored by the second database table is stored in a second logical partition of the logical collection of data, wherein the second logical partition is one of the multiple logical partitions of data.
- the method comprises identifying, by the computing system, that a second data center of the multiple data centers is designated as one data center, of the multiple data centers, that initially writes to the second logical partition of data.
- the method comprises sending, by the computing system and to the second data center, the second request to insert the one or more second data values into the second database table.
- Implementation 2 is the method of implementation 1 , wherein the first data center comprises over fifty computer processors; and the second data center comprises over fifty computer processors.
- Implementation 3 is the method of implementation 1 , where the method further comprises receiving, by the computing system and from the remote device, a third request to insert one or more third data values into a third database table.
- the method further comprises identifying, by the computing system, that third data stored by the third database table is stored in a third logical partition of the logical collection of data, wherein the third logical partition is one of the multiple logical partitions of data.
- the method further comprises identifying, by the computing system, that a third data center of the multiple data centers is designated as a data center that initially writes to the third logical partition of data.
- the method further comprises sending, by the computing system and to the third data center, the third request to insert one or more third data values into the third record of the third database table.
- Implementation 4 is the method of implementation 1 , wherein the method further comprises inserting, by the first data center, the one or more first data values into the first database table. The method further comprises replicating the one or more first data values from the first data center to each of the multiple data centers other than the first data center, including the second data center. The method further comprises inserting, by the second data center, the one or more second data values into the second database table. The method further comprises replicating the one or more second data values from the second data center to each of the multiple data centers other than the second data center, including the first data center.
- Implementation 5 is the method of implementation 4, wherein the one or more first data values are replicated after the first data center has inserted the one or more first data values into the first database table.
- the one or more second data values are replicated after the second data center has inserted the one or more second data values into the second database table.
- Implementation 6 is the method of implementation 4, wherein the first request is received by the computing system before the replicating of the one or more first data values.
- the second request is received by the computing system before the replicating of the one or more second data values.
- Implementation 7 is the method of implementation 4, wherein the method further comprises receiving, by the first data center, the one or more second data values as having been replicated from the second data center. The method further comprises inserting, by the first data center, the one or more second data values into the second database table. The method further comprises receiving, by the second data center, the one or more first data values as having been replicated from the first data center. The method further comprises inserting, by the second data center, the one or more first data values into the first database table.
- Implementation 8 is the method of implementation 4, wherein:
- inserting, by the first data center, the one or more first data values into the first database table includes inserting the one or more first data values into a copy of the first database table stored by the first data center; inserting, by the second data center, the one or more second data values into the second database table includes inserting the one or more second data values into a copy of the second database table stored by the second data center; inserting, by the first data center, the one or more second data values into the second database table includes inserting the one or more second data values into a copy of the second database table stored by the first data center; and inserting, by the second data center, the one or more first data values into the first database table includes inserting the one or more first data values into a copy of the first database table stored by the second data center.
- Implementation 9 is the method of implementation 1 , wherein: the first data stored by the first database table is columnar data arranged for querying by a columnar database querying system; and the second data stored by the second database table is columnar data arranged for querying by the columnar database querying system.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201161559707P | 2011-11-14 | 2011-11-14 | |
PCT/US2012/065068 WO2013074665A1 (en) | 2011-11-14 | 2012-11-14 | Data processing service |
Publications (2)
Publication Number | Publication Date |
---|---|
EP2780834A1 true EP2780834A1 (en) | 2014-09-24 |
EP2780834B1 EP2780834B1 (en) | 2020-07-08 |
Family
ID=47279070
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP12795212.5A Active EP2780834B1 (en) | 2011-11-14 | 2012-11-14 | Processing changes to distributed replicated databases |
Country Status (4)
Country | Link |
---|---|
US (3) | US8918363B2 (en) |
EP (1) | EP2780834B1 (en) |
DE (1) | DE202012013469U1 (en) |
WO (1) | WO2013074665A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20240095248A1 (en) * | 2022-09-15 | 2024-03-21 | Sap Se | Data transfer in a computer-implemented database from a database extension layer |
Families Citing this family (151)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8752042B2 (en) * | 2008-08-27 | 2014-06-10 | Cardinalcommerce Corporation | Intelligent server routing |
US8332365B2 (en) | 2009-03-31 | 2012-12-11 | Amazon Technologies, Inc. | Cloning and recovery of data volumes |
EP2740055A4 (en) * | 2011-08-01 | 2015-09-09 | Tagged Inc | Systems and methods for asynchronous distributed database management |
TWI471802B (en) * | 2011-12-06 | 2015-02-01 | Inst Information Industry | Conversion methods of applications of mobile devices and mobile devices and systems capable of converting applications of mobile devices |
US8812564B2 (en) * | 2011-12-20 | 2014-08-19 | Sap Ag | Parallel uniqueness checks for partitioned tables |
US9465844B2 (en) | 2012-04-30 | 2016-10-11 | Sap Se | Unified table query processing |
US9171020B2 (en) | 2012-04-30 | 2015-10-27 | Sap Se | Deleting records in a multi-level storage architecture |
US9465829B2 (en) * | 2012-04-30 | 2016-10-11 | Sap Se | Partial merge |
US20130297624A1 (en) * | 2012-05-07 | 2013-11-07 | Microsoft Corporation | Interoperability between Map-Reduce and Distributed Array Runtimes |
US9218573B1 (en) * | 2012-05-22 | 2015-12-22 | Google Inc. | Training a model using parameter server shards |
GB2505183A (en) * | 2012-08-21 | 2014-02-26 | Ibm | Discovering composite keys |
US9383982B2 (en) * | 2012-09-12 | 2016-07-05 | Microsoft Technology Licensing, Llc | Data-parallel computation management |
US9501483B2 (en) | 2012-09-18 | 2016-11-22 | Mapr Technologies, Inc. | Table format for map reduce system |
US9514208B2 (en) * | 2012-10-30 | 2016-12-06 | Vekatachary Srinivasan | Method and system of stateless data replication in a distributed database system |
US9286336B2 (en) * | 2013-03-12 | 2016-03-15 | Sap Se | Unified architecture for hybrid database storage using fragments |
US9342557B2 (en) * | 2013-03-13 | 2016-05-17 | Cloudera, Inc. | Low latency query engine for Apache Hadoop |
US9576012B2 (en) | 2013-03-14 | 2017-02-21 | Oracle International Corporation | Hierarchical tablespace space management |
US9336058B2 (en) * | 2013-03-14 | 2016-05-10 | International Business Machines Corporation | Automated scheduling management of MapReduce flow-graph applications |
US10430894B2 (en) | 2013-03-21 | 2019-10-01 | Khoros, Llc | Gamification for online social communities |
US9798783B2 (en) * | 2013-06-14 | 2017-10-24 | Actuate Corporation | Performing data mining operations within a columnar database management system |
WO2014201402A1 (en) * | 2013-06-14 | 2014-12-18 | American Chemical Society | Systems and methods for searching chemical structures |
US9679000B2 (en) | 2013-06-20 | 2017-06-13 | Actuate Corporation | Generating a venn diagram using a columnar database management system |
US9600539B2 (en) | 2013-06-21 | 2017-03-21 | Actuate Corporation | Performing cross-tabulation using a columnar database management system |
US9158472B2 (en) | 2013-06-25 | 2015-10-13 | Google Inc. | Hierarchical chunking of objects in a distributed storage system |
US9600558B2 (en) | 2013-06-25 | 2017-03-21 | Google Inc. | Grouping of objects in a distributed storage system based on journals and placement policies |
US9607020B1 (en) * | 2013-09-17 | 2017-03-28 | Amazon Technologies, Inc. | Data migration system |
US9569486B2 (en) * | 2013-09-27 | 2017-02-14 | International Business Machines Corporation | System and a method for hierarchical data column storage and efficient query processing |
US9477731B2 (en) | 2013-10-01 | 2016-10-25 | Cloudera, Inc. | Background format optimization for enhanced SQL-like queries in Hadoop |
US9639544B1 (en) * | 2013-10-28 | 2017-05-02 | Pivotal Software, Inc. | Table data persistence |
US9794135B2 (en) | 2013-11-11 | 2017-10-17 | Amazon Technologies, Inc. | Managed service for acquisition, storage and consumption of large-scale data streams |
US9465820B2 (en) * | 2013-11-13 | 2016-10-11 | Cellco Partnership | Method and system for unified technological stack management for relational databases |
US9639589B1 (en) | 2013-12-20 | 2017-05-02 | Amazon Technologies, Inc. | Chained replication techniques for large-scale data streams |
US9396202B1 (en) * | 2013-12-27 | 2016-07-19 | Google Inc. | Weakly synchronized garbage collection and compaction for aggregated, replicated object stores |
US9608664B2 (en) | 2013-12-30 | 2017-03-28 | International Business Machines Corporation | Compression of integer data using a common divisor |
US9678998B2 (en) * | 2014-02-28 | 2017-06-13 | Cisco Technology, Inc. | Content name resolution for information centric networking |
US9268597B2 (en) * | 2014-04-01 | 2016-02-23 | Google Inc. | Incremental parallel processing of data |
US9628107B2 (en) | 2014-04-07 | 2017-04-18 | International Business Machines Corporation | Compression of floating-point data by identifying a previous loss of precision |
CA2855136C (en) * | 2014-04-07 | 2019-01-29 | Marin Litoiu | Systems and methods of precision sharing of big data |
US9785510B1 (en) | 2014-05-09 | 2017-10-10 | Amazon Technologies, Inc. | Variable data replication for storage implementing data backup |
US10572488B2 (en) * | 2014-06-13 | 2020-02-25 | Koverse, Inc. | System and method for data organization, optimization and analytics |
US9218407B1 (en) | 2014-06-25 | 2015-12-22 | Pure Storage, Inc. | Replication and intermediate read-write state for mediums |
US9298590B2 (en) * | 2014-06-26 | 2016-03-29 | Google Inc. | Methods and apparatuses for automated testing of streaming applications using mapreduce-like middleware |
US9734021B1 (en) | 2014-08-18 | 2017-08-15 | Amazon Technologies, Inc. | Visualizing restoration operation granularity for a database |
CN104182506A (en) * | 2014-08-19 | 2014-12-03 | 浪潮(北京)电子信息产业有限公司 | Log management method |
US9984110B2 (en) | 2014-08-21 | 2018-05-29 | Dropbox, Inc. | Multi-user search system with methodology for personalized search query autocomplete |
US9350384B2 (en) | 2014-09-30 | 2016-05-24 | International Business Machines Corporation | Hierarchical data compression and computation |
US9959178B2 (en) | 2014-11-25 | 2018-05-01 | Sap Se | Transactional and parallel log replay for asynchronous table replication |
US9959299B2 (en) * | 2014-12-02 | 2018-05-01 | International Business Machines Corporation | Compression-aware partial sort of streaming columnar data |
US10198185B2 (en) * | 2014-12-31 | 2019-02-05 | Samsung Electronics Co., Ltd. | Computing system with processing and method of operation thereof |
US9384226B1 (en) | 2015-01-30 | 2016-07-05 | Dropbox, Inc. | Personal content item searching system and method |
US9183303B1 (en) | 2015-01-30 | 2015-11-10 | Dropbox, Inc. | Personal content item searching system and method |
US10909078B2 (en) | 2015-02-25 | 2021-02-02 | International Business Machines Corporation | Query predicate evaluation and computation for hierarchically compressed data |
WO2016149552A1 (en) | 2015-03-17 | 2016-09-22 | Cloudera, Inc. | Compaction policy |
US9996563B2 (en) * | 2015-03-23 | 2018-06-12 | International Business Machines Corporation | Efficient full delete operations |
US11016946B1 (en) | 2015-03-31 | 2021-05-25 | EMC IP Holding Company LLC | Method and apparatus for processing object metadata |
US10318491B1 (en) * | 2015-03-31 | 2019-06-11 | EMC IP Holding Company LLC | Object metadata query with distributed processing systems |
EP3271840B1 (en) | 2015-05-07 | 2019-02-27 | Cloudera, Inc. | Mutations in a column store |
US10733198B1 (en) * | 2015-06-29 | 2020-08-04 | Trifacta Inc. | Visual interactions for transforming datasets with nested data structures |
US10241979B2 (en) * | 2015-07-21 | 2019-03-26 | Oracle International Corporation | Accelerated detection of matching patterns |
US10929419B2 (en) | 2015-09-25 | 2021-02-23 | Netapp, Inc. | Object storage backed file system |
US11334540B2 (en) * | 2015-09-25 | 2022-05-17 | Netapp, Inc. | Namespace hierarchy preservation with multiple object storage objects |
US9842183B1 (en) * | 2015-09-29 | 2017-12-12 | Cadence Design Systems, Inc. | Methods and systems for enabling concurrent editing of electronic circuit layouts |
US10423493B1 (en) | 2015-12-21 | 2019-09-24 | Amazon Technologies, Inc. | Scalable log-based continuous data protection for distributed databases |
US10567500B1 (en) | 2015-12-21 | 2020-02-18 | Amazon Technologies, Inc. | Continuous backup of data in a distributed data store |
US10853182B1 (en) | 2015-12-21 | 2020-12-01 | Amazon Technologies, Inc. | Scalable log-based secondary indexes for non-relational databases |
US10866940B2 (en) * | 2015-12-31 | 2020-12-15 | Fireeye, Inc. | Method, apparatus, and computer-readable medium for ingesting semi-structured data in a columnar format |
CN107085570B (en) * | 2016-02-14 | 2020-08-14 | 华为技术有限公司 | Data processing method, application server and router |
US10509803B2 (en) * | 2016-02-17 | 2019-12-17 | Talentica Software (India) Private Limited | System and method of using replication for additional semantically defined partitioning |
US10762037B2 (en) * | 2016-03-25 | 2020-09-01 | Hitachi, Ltd | Data processing system |
US10896178B2 (en) * | 2016-03-30 | 2021-01-19 | Microsoft Technology Licensing, Llc | High performance query processing and data analytics |
US20170337232A1 (en) * | 2016-05-19 | 2017-11-23 | Fifth Dimension Holdings Ltd. | Methods of storing and querying data, and systems thereof |
CN109791538B (en) | 2016-06-09 | 2023-04-21 | 霍利斯特克信息公司 | Data storage system and execution method thereof |
US10922278B2 (en) * | 2016-07-22 | 2021-02-16 | Albert Haag | Systems and methods for database compression and evaluation |
US10216782B2 (en) * | 2016-08-12 | 2019-02-26 | Sap Se | Processing of updates in a database system using different scenarios |
US11074342B1 (en) * | 2016-08-16 | 2021-07-27 | State Farm Mutual Automobile Insurance Company | Si data scanning process |
US11269888B1 (en) * | 2016-11-28 | 2022-03-08 | Amazon Technologies, Inc. | Archival data storage for structured data |
CN106817406B (en) * | 2016-12-22 | 2020-05-26 | 南京邮电大学 | Pre-distribution self-adaptive compression method applied to RCFile storage model |
US10489366B2 (en) * | 2017-01-27 | 2019-11-26 | Salesforce.Com, Inc. | Change data capture using nested buckets |
US11113244B1 (en) * | 2017-01-30 | 2021-09-07 | A9.Com, Inc. | Integrated data pipeline |
US10902462B2 (en) | 2017-04-28 | 2021-01-26 | Khoros, Llc | System and method of providing a platform for managing data content campaign on social networks |
KR102600366B1 (en) * | 2017-08-15 | 2023-11-08 | 누오디비 인코포레이티드 | Index partitioning in distributed databases |
US10922303B1 (en) * | 2017-08-17 | 2021-02-16 | Amazon Technologies, Inc. | Early detection of corrupt data partition exports |
US10761734B2 (en) * | 2017-08-30 | 2020-09-01 | General Electric Company | Systems and methods for data frame representation |
US10990581B1 (en) | 2017-09-27 | 2021-04-27 | Amazon Technologies, Inc. | Tracking a size of a database change log |
US10754844B1 (en) | 2017-09-27 | 2020-08-25 | Amazon Technologies, Inc. | Efficient database snapshot generation |
US10785222B2 (en) | 2018-10-11 | 2020-09-22 | Spredfast, Inc. | Credential and authentication management in scalable data networks |
US10346449B2 (en) | 2017-10-12 | 2019-07-09 | Spredfast, Inc. | Predicting performance of content and electronic messages among a system of networked computing devices |
US11050704B2 (en) | 2017-10-12 | 2021-06-29 | Spredfast, Inc. | Computerized tools to enhance speed and propagation of content in electronic messages among a system of networked computing devices |
US10999278B2 (en) | 2018-10-11 | 2021-05-04 | Spredfast, Inc. | Proxied multi-factor authentication using credential and authentication management in scalable data networks |
US11470161B2 (en) | 2018-10-11 | 2022-10-11 | Spredfast, Inc. | Native activity tracking using credential and authentication management in scalable data networks |
US11570128B2 (en) | 2017-10-12 | 2023-01-31 | Spredfast, Inc. | Optimizing effectiveness of content in electronic messages among a system of networked computing device |
US11182372B1 (en) | 2017-11-08 | 2021-11-23 | Amazon Technologies, Inc. | Tracking database partition change log dependencies |
US11042503B1 (en) | 2017-11-22 | 2021-06-22 | Amazon Technologies, Inc. | Continuous data protection and restoration |
US11269731B1 (en) | 2017-11-22 | 2022-03-08 | Amazon Technologies, Inc. | Continuous data protection |
US10601937B2 (en) | 2017-11-22 | 2020-03-24 | Spredfast, Inc. | Responsive action prediction based on electronic messages among a system of networked computing devices |
WO2019104338A1 (en) | 2017-11-27 | 2019-05-31 | Snowflake Computing Inc | Batch data ingestion in database systems |
US10594773B2 (en) | 2018-01-22 | 2020-03-17 | Spredfast, Inc. | Temporal optimization of data operations using distributed search and server management |
US11061900B2 (en) | 2018-01-22 | 2021-07-13 | Spredfast, Inc. | Temporal optimization of data operations using distributed search and server management |
AU2019209542B2 (en) * | 2018-01-22 | 2021-10-21 | Eric Manuel FALCAO | Temporal optimization of data operations using distributed search and server management |
US10621049B1 (en) | 2018-03-12 | 2020-04-14 | Amazon Technologies, Inc. | Consistent backups based on local node clock |
US20190294713A1 (en) * | 2018-03-22 | 2019-09-26 | Accenture Global Solutions Limited | Database impact analysis |
US10365964B1 (en) | 2018-05-31 | 2019-07-30 | Capital One Services, Llc | Data processing platform monitoring |
CN110581823B (en) * | 2018-06-07 | 2020-12-22 | 中国科学院声学研究所 | Method for analyzing non-public database protocol request data packet |
US11126505B1 (en) | 2018-08-10 | 2021-09-21 | Amazon Technologies, Inc. | Past-state backup generator and interface for database systems |
CA3055993C (en) * | 2018-09-20 | 2024-01-02 | Idera, Inc. | Database access, monitoring, and control system and method for reacting to suspicious database activities |
US10936640B2 (en) * | 2018-10-09 | 2021-03-02 | International Business Machines Corporation | Intelligent visualization of unstructured data in column-oriented data tables |
US10855657B2 (en) | 2018-10-11 | 2020-12-01 | Spredfast, Inc. | Multiplexed data exchange portal interface in scalable data networks |
CN109542896B (en) * | 2018-10-26 | 2020-12-01 | 深圳点猫科技有限公司 | Data processing method and device for education operating system |
US11042454B1 (en) | 2018-11-20 | 2021-06-22 | Amazon Technologies, Inc. | Restoration of a data source |
EP3678033A1 (en) * | 2019-01-07 | 2020-07-08 | QlikTech International AB | A computer implemented method for indexlet based aggregation |
US11809382B2 (en) | 2019-04-01 | 2023-11-07 | Nutanix, Inc. | System and method for supporting versioned objects |
US10931540B2 (en) | 2019-05-15 | 2021-02-23 | Khoros, Llc | Continuous data sensing of functional states of networked computing devices to determine efficiency metrics for servicing electronic messages asynchronously |
US11023311B2 (en) | 2019-09-27 | 2021-06-01 | Amazon Technologies, Inc. | On-demand code execution in input path of data uploaded to storage service in multiple data portions |
US11394761B1 (en) | 2019-09-27 | 2022-07-19 | Amazon Technologies, Inc. | Execution of user-submitted code on a stream of data |
US10996961B2 (en) | 2019-09-27 | 2021-05-04 | Amazon Technologies, Inc. | On-demand indexing of data in input path of object storage service |
US11263220B2 (en) | 2019-09-27 | 2022-03-01 | Amazon Technologies, Inc. | On-demand execution of object transformation code in output path of object storage service |
US11416628B2 (en) | 2019-09-27 | 2022-08-16 | Amazon Technologies, Inc. | User-specific data manipulation system for object storage service based on user-submitted code |
US10908927B1 (en) | 2019-09-27 | 2021-02-02 | Amazon Technologies, Inc. | On-demand execution of object filter code in output path of object storage service |
US11360948B2 (en) | 2019-09-27 | 2022-06-14 | Amazon Technologies, Inc. | Inserting owner-specified data processing pipelines into input/output path of object storage service |
US11550944B2 (en) | 2019-09-27 | 2023-01-10 | Amazon Technologies, Inc. | Code execution environment customization system for object storage service |
US11106477B2 (en) * | 2019-09-27 | 2021-08-31 | Amazon Technologies, Inc. | Execution of owner-specified code during input/output path to object storage service |
US11055112B2 (en) | 2019-09-27 | 2021-07-06 | Amazon Technologies, Inc. | Inserting executions of owner-specified code into input/output path of object storage service |
US11250007B1 (en) | 2019-09-27 | 2022-02-15 | Amazon Technologies, Inc. | On-demand execution of object combination code in output path of object storage service |
US11386230B2 (en) | 2019-09-27 | 2022-07-12 | Amazon Technologies, Inc. | On-demand code obfuscation of data in input path of object storage service |
US11656892B1 (en) | 2019-09-27 | 2023-05-23 | Amazon Technologies, Inc. | Sequential execution of user-submitted code and native functions |
US11514066B2 (en) * | 2019-11-08 | 2022-11-29 | Servicenow, Inc. | System and methods for querying and updating databases |
US11609777B2 (en) * | 2020-02-19 | 2023-03-21 | Nutanix, Inc. | System and method for multi-cluster storage |
US11386062B2 (en) * | 2020-04-23 | 2022-07-12 | Sap Se | Container storage management system |
US20210334284A1 (en) | 2020-04-28 | 2021-10-28 | Nutanix, Inc. | System and method of querying objects on demand |
US11263051B2 (en) * | 2020-05-05 | 2022-03-01 | Nvidia Corporation | Techniques for scaling dictionary-based compression |
US11487787B2 (en) | 2020-05-29 | 2022-11-01 | Nutanix, Inc. | System and method for near-synchronous replication for object store |
US10922469B1 (en) | 2020-06-30 | 2021-02-16 | Cadence Design Systems, Inc. | Methods and systems of enabling concurrent editing of hierarchical electronic circuit layouts |
US11128589B1 (en) | 2020-09-18 | 2021-09-21 | Khoros, Llc | Gesture-based community moderation |
US11438289B2 (en) | 2020-09-18 | 2022-09-06 | Khoros, Llc | Gesture-based community moderation |
US11436211B1 (en) * | 2020-09-29 | 2022-09-06 | Amazon Technologies, Inc. | Renaming a database table with minimized application downtime |
US11734291B2 (en) | 2020-10-21 | 2023-08-22 | Ebay Inc. | Parallel execution of API calls using local memory of distributed computing devices |
US20220121640A1 (en) * | 2020-10-21 | 2022-04-21 | Western Digital Technologies, Inc. | Emulation of relational data table relationships using a schema |
US11627100B1 (en) | 2021-10-27 | 2023-04-11 | Khoros, Llc | Automated response engine implementing a universal data space based on communication interactions via an omnichannel electronic data channel |
US11438282B2 (en) | 2020-11-06 | 2022-09-06 | Khoros, Llc | Synchronicity of electronic messages via a transferred secure messaging channel among a system of various networked computing devices |
US11924375B2 (en) | 2021-10-27 | 2024-03-05 | Khoros, Llc | Automated response engine and flow configured to exchange responsive communication data via an omnichannel electronic communication channel independent of data source |
US11775487B2 (en) * | 2020-11-12 | 2023-10-03 | Western Digital Technologies, Inc. | Automatic flexible schema detection and migration |
US11714629B2 (en) | 2020-11-19 | 2023-08-01 | Khoros, Llc | Software dependency management |
US11900164B2 (en) | 2020-11-24 | 2024-02-13 | Nutanix, Inc. | Intelligent query planning for metric gateway |
US20220164478A1 (en) * | 2020-11-25 | 2022-05-26 | Anonomatic, Inc. | Processing personally identifiable information from a schema |
US11822370B2 (en) | 2020-11-26 | 2023-11-21 | Nutanix, Inc. | Concurrent multiprotocol access to an object storage system |
US11797523B2 (en) | 2020-12-18 | 2023-10-24 | Microsoft Technology Licensing, Llc | Schema and data modification concurrency in query processing pushdown |
US11487766B2 (en) * | 2020-12-18 | 2022-11-01 | Microsoft Technology Licensing, Llc | Operation fragmentation with metadata serialization in query processing pushdowns |
US11552904B2 (en) | 2021-01-19 | 2023-01-10 | Reliance Jio Infocomm Usa, Inc. | Architecture for high performing data plane applications with smart network interface on compute servers |
US20220269702A1 (en) * | 2021-02-19 | 2022-08-25 | Sap Se | Intelligent annotation of entity-relationship data models |
US11899572B2 (en) | 2021-09-09 | 2024-02-13 | Nutanix, Inc. | Systems and methods for transparent swap-space virtualization |
US20230161795A1 (en) * | 2021-11-19 | 2023-05-25 | Intertrust Technologies Corporation | Time series data management systems and methods |
Family Cites Families (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1262481A (en) | 1999-01-27 | 2000-08-09 | 电话通有限公司 | Method and device for synchronizing multiple data base |
US6751618B1 (en) | 1999-11-24 | 2004-06-15 | Unisys Corporation | Method and apparatus for a web application server to upload multiple files and invoke a script to use the files in a single browser request |
US7213017B2 (en) | 2000-03-17 | 2007-05-01 | Microsoft Corporation | Systems and methods for transforming query results into hierarchical information |
US6675264B2 (en) * | 2001-05-07 | 2004-01-06 | International Business Machines Corporation | Method and apparatus for improving write performance in a cluster-based file system |
US7024414B2 (en) | 2001-08-06 | 2006-04-04 | Sensage, Inc. | Storage of row-column data |
US7149733B2 (en) | 2002-07-20 | 2006-12-12 | Microsoft Corporation | Translation of object queries involving inheritence |
US6973654B1 (en) | 2003-05-27 | 2005-12-06 | Microsoft Corporation | Systems and methods for the repartitioning of data |
US8250058B2 (en) | 2005-10-18 | 2012-08-21 | Fish Robert D | Table for storing parameterized product/services information using variable field columns |
US7716180B2 (en) | 2005-12-29 | 2010-05-11 | Amazon Technologies, Inc. | Distributed storage system with web services client interface |
US7877370B2 (en) | 2006-05-15 | 2011-01-25 | Algebraix Data Corporation | Systems and methods for data storage and retrieval using algebraic relations composed from query language statements |
US20090006399A1 (en) | 2007-06-29 | 2009-01-01 | International Business Machines Corporation | Compression method for relational tables based on combined column and row coding |
US7970903B2 (en) | 2007-08-20 | 2011-06-28 | Hitachi, Ltd. | Storage and server provisioning for virtualized and geographically dispersed data centers |
US8271357B2 (en) | 2007-12-11 | 2012-09-18 | Ebay Inc. | Presenting items based on activity rates |
US8229980B2 (en) | 2008-04-30 | 2012-07-24 | Microsoft Corporation | State buckets |
US7925782B2 (en) * | 2008-06-30 | 2011-04-12 | Amazon Technologies, Inc. | Request routing using network computing components |
CN101727465B (en) | 2008-11-03 | 2011-12-21 | 中国移动通信集团公司 | Methods for establishing and inquiring index of distributed column storage database, device and system thereof |
US20100235394A1 (en) | 2009-03-10 | 2010-09-16 | Nokia Corporation | Method and apparatus for accessing content based on user geolocation |
US8239337B2 (en) * | 2009-05-30 | 2012-08-07 | Cisco Technology, Inc. | Network device proximity data import based on weighting factor |
GB0920644D0 (en) | 2009-11-25 | 2010-01-13 | Geniedb | System for improved record consistency and availability |
US8352495B2 (en) | 2009-12-15 | 2013-01-08 | Chalklabs, Llc | Distributed platform for network analysis |
US9195657B2 (en) | 2010-03-08 | 2015-11-24 | Microsoft Technology Licensing, Llc | Columnar storage of a database index |
US8504515B2 (en) | 2010-03-30 | 2013-08-06 | Commvault Systems, Inc. | Stubbing systems and methods in a data replication environment |
EP2556446B1 (en) | 2010-04-05 | 2018-12-12 | Google LLC | Columnar storage representations of records |
US20110264667A1 (en) | 2010-04-27 | 2011-10-27 | Stavros Harizopoulos | Column-oriented storage in a row-oriented database management system |
US20120016901A1 (en) | 2010-05-18 | 2012-01-19 | Google Inc. | Data Storage and Processing Service |
US8775625B2 (en) | 2010-06-16 | 2014-07-08 | Juniper Networks, Inc. | Virtual machine mobility in data centers |
WO2012031112A2 (en) * | 2010-09-03 | 2012-03-08 | Time Warner Cable, Inc. | Methods and systems for managing a virtual data center with embedded roles based access control |
US8392399B2 (en) * | 2010-09-16 | 2013-03-05 | Microsoft Corporation | Query processing algorithm for vertically partitioned federated database systems |
US8868512B2 (en) * | 2011-01-14 | 2014-10-21 | Sap Se | Logging scheme for column-oriented in-memory databases |
US9519673B2 (en) * | 2011-08-23 | 2016-12-13 | Sap Se | Management of I/O and log size for columnar database |
US9483512B2 (en) | 2011-11-07 | 2016-11-01 | Sap Se | Columnar database using virtual file data objects |
-
2012
- 2012-11-14 WO PCT/US2012/065068 patent/WO2013074665A1/en active Application Filing
- 2012-11-14 US US13/676,997 patent/US8918363B2/en active Active
- 2012-11-14 US US13/677,069 patent/US8996456B2/en active Active
- 2012-11-14 EP EP12795212.5A patent/EP2780834B1/en active Active
- 2012-11-14 DE DE202012013469.8U patent/DE202012013469U1/en not_active Expired - Lifetime
-
2015
- 2015-03-23 US US14/665,026 patent/US10176225B2/en active Active
Non-Patent Citations (1)
Title |
---|
See references of WO2013074665A1 * |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20240095248A1 (en) * | 2022-09-15 | 2024-03-21 | Sap Se | Data transfer in a computer-implemented database from a database extension layer |
Also Published As
Publication number | Publication date |
---|---|
DE202012013469U1 (en) | 2017-01-30 |
US8918363B2 (en) | 2014-12-23 |
EP2780834B1 (en) | 2020-07-08 |
US20130124466A1 (en) | 2013-05-16 |
US20130124467A1 (en) | 2013-05-16 |
WO2013074665A1 (en) | 2013-05-23 |
US20150193504A1 (en) | 2015-07-09 |
US10176225B2 (en) | 2019-01-08 |
US8996456B2 (en) | 2015-03-31 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10176225B2 (en) | Data processing service | |
EP2572289B1 (en) | Data storage and processing service | |
JP6617117B2 (en) | Scalable analysis platform for semi-structured data | |
CA2795525C (en) | Columnar storage representations of records | |
US10983967B2 (en) | Creation of a cumulative schema based on an inferred schema and statistics | |
Melnik et al. | Dremel: interactive analysis of web-scale datasets | |
US9805079B2 (en) | Executing constant time relational queries against structured and semi-structured data | |
US9639542B2 (en) | Dynamic mapping of extensible datasets to relational database schemas | |
US8200668B2 (en) | Scalar representation for a logical group of columns in relational databases | |
US20170322963A1 (en) | Apparatus and Method for Creating User Defined Variable Size Tags on Records in RDBMS | |
Dutta | Distributed computing technologies in big data analytics | |
Alla | Big Data Analytics with Hadoop 3: Build highly effective analytics solutions to gain valuable insight into your big data | |
US20230267102A1 (en) | On-demand virtual storage access method analytics | |
Johnson et al. | Big data processing using Hadoop MapReduce programming model | |
Lakhe et al. | Lambda architecture for real-time Hadoop applications | |
VA | A DISTRIBUTED APPROACH ON EARLY TRENDING TOPICS PREDICTION ON SOCIAL NETWORK SERVICES | |
Mostafa et al. | Investigation cloud data storage |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20140519 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
DAX | Request for extension of the european patent (deleted) | ||
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20181010 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R079Ref document number: 602012071162Country of ref document: DEFree format text: PREVIOUS MAIN CLASS: G06F0017300000Ipc: G06F0016000000 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 16/00 20190101AFI20190925BHEP |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
INTG | Intention to grant announced |
Effective date: 20200128 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE PATENT HAS BEEN GRANTED |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EPRef country code: ATRef legal event code: REFRef document number: 1289209Country of ref document: ATKind code of ref document: TEffective date: 20200715 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602012071162Country of ref document: DE |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: FP |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 1289209Country of ref document: ATKind code of ref document: TEffective date: 20200708 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201008Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201109Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201008Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201009 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: RSFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20201108 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602012071162Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SMFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708 |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ALFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708 |
|
26N | No opposition filed |
Effective date: 20210409 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201114 |
|
REG | Reference to a national code |
Ref country code: BERef legal event code: MMEffective date: 20201130 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201130Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201130 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: IEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201114Ref country code: FRFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201130 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: TRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: MTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200708 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20201130 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230505 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: NLPayment date: 20231126Year of fee payment: 12 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: GBPayment date: 20231127Year of fee payment: 12 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: DEPayment date: 20231129Year of fee payment: 12 |