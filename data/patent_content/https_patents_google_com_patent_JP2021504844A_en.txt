JP2021504844A - Neural architecture search using performance prediction neural network - Google Patents
Neural architecture search using performance prediction neural network Download PDFInfo
- Publication number
- JP2021504844A JP2021504844A JP2020529555A JP2020529555A JP2021504844A JP 2021504844 A JP2021504844 A JP 2021504844A JP 2020529555 A JP2020529555 A JP 2020529555A JP 2020529555 A JP2020529555 A JP 2020529555A JP 2021504844 A JP2021504844 A JP 2021504844A
- Authority
- JP
- Japan
- Prior art keywords
- neural network
- architecture
- candidate
- task
- performance
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/214—Generating training patterns; Bootstrap methods, e.g. bagging or boosting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
- G06F18/2178—Validation; Performance evaluation; Active pattern learning techniques based on feedback of a supervisor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
Abstract
特定の機械学習タスクを実行するように構成されたタスクニューラルネットワークのためのアーキテクチャを決定するための方法について説明する。この方法は、タスクニューラルネットワークに対する候補アーキテクチャの現在のセットを指定するデータを取得するステップと、現在のセット内の各候補アーキテクチャに対して、複数の性能予測パラメータを有する性能予測ニューラルネットワークを使用して、候補アーキテクチャを指定するデータを処理するステップであって、性能予測ニューラルネットワークは、候補アーキテクチャを有するニューラルネットワークが特定の機械学習タスクに対してトレーニングされた後で、どの程度良好に機能することになるかを特徴付ける性能予測を生成するために、性能予測パラメータの現在の値に従って、候補アーキテクチャを指定するデータを処理するように構成される、処理するステップと、現在のセット内の候補アーキテクチャに対する性能予測に基づいて、現在のセット内の候補アーキテクチャのうちの1つまたは複数を選択することによって、候補アーキテクチャの更新されたセットを生成するステップとを含む。Describes a method for determining the architecture for a task neural network that is configured to perform a particular machine learning task. This method uses a performance prediction neural network with multiple performance prediction parameters for each candidate architecture in the current set, with the step of retrieving data that specifies the current set of candidate architectures for the task neural network. The step of processing the data that specifies the candidate architecture, and how well the performance predictive neural network works after the neural network with the candidate architecture is trained for a particular machine learning task. To generate a performance prediction that characterizes what will be, the processing steps that are configured to process the data that specifies the candidate architecture according to the current value of the performance prediction parameter, and for the candidate architecture in the current set. Includes steps to generate an updated set of candidate architectures by selecting one or more of the candidate architectures in the current set based on performance predictions.
Description
関連出願の相互参照
本出願は、その内容全体が参照により本明細書に組み込まれている、2017年11月30日に出願した、米国仮特許出願第62/593,213号の非仮出願であり、それに対する優先権を主張するものである。
Cross-reference to related applications This application is a non-provisional application of US Provisional Patent Application No. 62 / 593,213 filed on November 30, 2017, the entire contents of which are incorporated herein by reference. It claims priority over it.
本明細書は、ニューラルネットワークのためのアーキテクチャを決定することに関する。 The present specification relates to determining an architecture for a neural network.
ニューラルネットワークは、非線形ユニットの1つまたは複数のレイヤを用いて、受信入力に対する出力を予測する機械学習モデルである。いくつかのニューラルネットワークは、出力レイヤに加えて、1つまたは複数の隠れレイヤを含む。各隠れレイヤの出力は、ネットワーク内の次のレイヤ、すなわち、次の隠れレイヤまたは出力レイヤに対する入力として使用される。ネットワークの各レイヤは、パラメータのそれぞれのセットの現在の値に従って、受信入力から出力を生成する。 A neural network is a machine learning model that uses one or more layers of nonlinear units to predict the output for a received input. Some neural networks include one or more hidden layers in addition to the output layer. The output of each hidden layer is used as input to the next layer in the network, the next hidden layer or output layer. Each layer of the network produces an output from the received input according to the current value of each set of parameters.
いくつかのニューラルネットワークは、回帰ニューラルネットワークである。回帰ニューラルネットワークは、入力シーケンスを受信し、その入力シーケンスから出力シーケンスを生成するニューラルネットワークである。具体的には、回帰ニューラルネットワークは、現在の時間ステップにおいて出力を計算する際に、前の時間ステップからのネットワークの内部状態のうちのいくつかまたはすべてを使用することができる。回帰ニューラルネットワークの一例は、1つまたは複数の長短期記憶(LSTM:long short-term memory)メモリブロックを含むLSTMニューラルネットワークである。各LSTMメモリブロックは、各々が、セルが、たとえば、現在のアクティブ化をもたらす際に使用するための、またはLSTMニューラルネットワークの他の構成要素に提供されるべき、そのセルに対する前の状態を記憶することを可能にする、入力ゲート、忘却ゲート、および出力ゲートを含む、1つまたは複数のセルを含み得る。 Some neural networks are recurrent neural networks. A recurrent neural network is a neural network that receives an input sequence and generates an output sequence from the input sequence. Specifically, the recurrent neural network can use some or all of the internal state of the network from the previous time step when calculating the output at the current time step. An example of a recurrent neural network is an LSTM neural network that contains one or more long short-term memory (LSTM) memory blocks. Each LSTM memory block stores the previous state for the cell, for example, to be used to bring about the current activation, or to be provided to other components of the LSTM neural network. It can contain one or more cells, including an input gate, an oblivion gate, and an output gate.
本明細書は、特定の機械学習タスクを実行するように構成されたタスクニューラルネットワークのためのネットワークアーキテクチャを決定する、1つまたは複数のロケーション内の1つまたは複数のコンピュータ上のコンピュータプログラムとして実装されるシステムについて説明する。 This specification is implemented as a computer program on one or more computers in one or more locations that determines the network architecture for a task neural network that is configured to perform a particular machine learning task. The system to be used will be described.
本明細書で説明する主題は、以下の利点のうちの1つまたは複数を実現するために、特定の実施形態で実装され得る。本明細書で説明する技法を使用してタスクニューラルネットワークのアーキテクチャを決定することによって、システムは、様々な機械学習タスクのうちのいずれか、たとえば、画像分類または別の画像処理タスクに対する最新性能を達成するかまたはそれをさらに超えるネットワークアーキテクチャを決定し得る。加えて、システムは、既存の技法よりも計算効率がはるかに高く、すなわち、消費する計算リソースが既存の技法よりもはるかに少ない特定の様式でタスクニューラルネットワークのアーキテクチャを決定し(たとえば、タスクニューラルネットワークのアーキテクチャにわたって繰り返される出力セルを決定し)得る。具体的には、多くの既存の技法は、候補アーキテクチャを有するネットワークをトレーニングすることによって、多数の候補アーキテクチャの性能を評価することに依拠する。このトレーニングは、時間がかかるとともに、計算集約的である。説明する技法は、代わりに、候補アーキテクチャを有する、トレーニングされたネットワークの性能を効果的に予測する性能予測ニューラルネットワークを用いることによって、すなわち、候補アーキテクチャを有するネットワークを実際にトレーニングする必要なしに、トレーニングされる必要があるタスクニューラルネットワークのインスタンス量を大きく削減する。いくつかの説明する実装形態では、この手法は、他のリソース節約手法、すなわち、さらに大きな計算効率を達成するために、出力アーキテクチャの複数のインスタンスを含む、生じるタスクニューラルネットワークの性能に悪影響を及ぼさずに最終的な出力アーキテクチャの考えられるアーキテクチャの探索空間を効果的に制限する、また場合によっては、その性能をさらに改善する、技法と組み合わせられる。たとえば、他のリソース節約手法は、畳み込みセル、または複数の動作ブロックを含む他のタイプのセルのアーキテクチャを学習し、次いで、事前決定されたテンプレートに従って、学習されたセルを繰り返して、タスクニューラルネットワークのアーキテクチャを生成することを含み得る。 The subject matter described herein may be implemented in a particular embodiment to achieve one or more of the following advantages: By determining the architecture of the task neural network using the techniques described herein, the system provides up-to-date performance for any of a variety of machine learning tasks, such as image classification or another image processing task. You can determine the network architecture to achieve or even exceed. In addition, the system determines the architecture of the task neural network in a particular fashion that is much more computationally efficient than existing techniques, that is, consumes far less computational resources than existing techniques (eg, task neurals). (Determine the output cell that repeats across the architecture of the network). Specifically, many existing techniques rely on assessing the performance of a large number of candidate architectures by training networks with candidate architectures. This training is time consuming and computationally intensive. The technique described is instead by using a performance predictive neural network that effectively predicts the performance of the trained network with the candidate architecture, i.e., without the need to actually train the network with the candidate architecture. Significantly reduce the amount of task neural network instances that need to be trained. In some described implementations, this technique adversely affects the performance of other resource-saving techniques, ie, task neural networks that involve multiple instances of the output architecture in order to achieve greater computational efficiency. Combined with techniques that effectively limit the exploration space of the possible architecture of the final output architecture and, in some cases, further improve its performance. For example, other resource-saving techniques learn the architecture of convolution cells, or other types of cells that contain multiple action blocks, and then iterate through the trained cells according to a pre-determined template to create a task neural network. Can include generating the architecture of.
本明細書で説明する主題の1つまたは複数の実施形態の詳細が、添付の図面および以下の明細書に記載される。本主題の他の特徴、態様、および利点は、明細書、図面、および特許請求の範囲から明らかになるであろう。 Details of one or more embodiments of the subject matter described herein are described in the accompanying drawings and the following specification. Other features, aspects, and advantages of this subject will become apparent from the specification, drawings, and claims.
様々な図面における同様の参照番号および表示は、同様の要素を示す。 Similar reference numbers and indications in various drawings indicate similar elements.
本明細書は、タスクニューラルネットワークのためのネットワークアーキテクチャを決定する、1つまたは複数のロケーション内の1つまたは複数のコンピュータ上でコンピュータプログラムとして実装されるニューラルアーキテクチャ探索システムについて説明する。タスクニューラルネットワークは、特定の機械学習タスクを実行するように構成される。 This specification describes a neural architecture search system implemented as a computer program on one or more computers in one or more locations that determines the network architecture for a task neural network. Task neural networks are configured to perform specific machine learning tasks.
概して、タスクニューラルネットワークは、ネットワーク入力を受信し、その入力に対するネットワーク出力を生成するために、そのネットワーク入力を処理するように構成される。 In general, a task neural network is configured to process a network input in order to receive the network input and generate a network output for that input.
場合によっては、タスクニューラルネットワークは、入力画像を受信し、その入力画像に対するネットワーク出力を生成するために、すなわち、何らかの種類の画像処理タスクを実行するために、その入力画像を処理するように構成された畳み込みニューラルネットワークである。 In some cases, a task neural network is configured to receive an input image and process the input image in order to generate network output for that input image, i.e., to perform some sort of image processing task. It is a convolutional neural network.
たとえば、タスクは画像分類であり得、所与の画像に対してニューラルネットワークによって生成される出力は、オブジェクトカテゴリーのセットの各々に対するスコアであり得、各スコアは、その画像がそのカテゴリーに属するオブジェクトの画像を含む推定尤度を表す。 For example, a task can be an image classification, the output generated by a neural network for a given image can be a score for each of a set of object categories, and each score is an object for which the image belongs to that category. Represents the estimated likelihood including the image of.
別の例として、タスクは、画像埋め込み生成であり得、ニューラルネットワークによって生成される出力は、入力画像の数値埋め込みであり得る。 As another example, the task can be an image embedding generation and the output generated by the neural network can be a numerical embedding of the input image.
さらに別の例として、タスクはオブジェクト検出であり得、ニューラルネットワークによって生成される出力は、特定のタイプのオブジェクトが示される入力画像内のロケーションを識別し得る。 As yet another example, the task can be object detection, and the output produced by the neural network can identify the location in the input image where a particular type of object is shown.
いくつかの他の場合には、タスクはビデオ分類であり得、タスクニューラルネットワークは、ビデオまたはビデオの一部分を入力として受信し、その入力ビデオまたはビデオ部分が何の1つまたは複数のトピックに関係するかを決定する出力を生成するように構成される。 In some other cases, the task can be a video classification, the task neural network receives the video or part of the video as input and the input video or video part is related to one or more topics. It is configured to produce output that determines what to do.
いくつかの他の場合には、タスクは音声認識であり得、タスクニューラルネットワークは、入力としてオーディオデータを受信し、発せられた所与の発話に対して、その発話が表す1つまたは複数の用語を決定する出力を生成するように構成される。 In some other cases, the task can be speech recognition, the task neural network receives audio data as input, and for a given utterance uttered, one or more utterances represent. It is configured to produce output that determines the term.
いくつかの他の場合には、タスクはテキスト分類であり得、タスクニューラルネットワークは、入力テキストセグメントを受信し、入力テキストセグメントが何の1つまたは複数のトピックに関係するかを決定する出力を生成するように構成される。 In some other cases, the task can be a text classification, and the task neural network receives the input text segment and outputs an output that determines what the input text segment is related to one or more topics. Configured to generate.
図1は、例示的なニューラルアーキテクチャ探索(NAS)システム100を示す。ニューラルアーキテクチャ探索システム100は、以下で説明するシステム、構成要素、および技法が実装され得る、1つまたは複数のロケーション内の1つまたは複数のコンピュータ上でコンピュータプログラムとして実装されるシステムの一例である。 Figure 1 shows an exemplary Neural Architecture Search (NAS) system 100. The Neural Architecture Search System 100 is an example of a system implemented as a computer program on one or more computers in one or more locations where the systems, components, and techniques described below may be implemented. ..
いくつかの実装形態では、NASシステム100は、ネットワークアーキテクチャにわたって繰り返される出力セル150のためのアーキテクチャを決定することによって、タスクニューラルネットワークのためのネットワークアーキテクチャを決定するように構成される。すなわち、タスクニューラルネットワークは、出力セル150の複数のインスタンスを含む。出力セル150のインスタンス内の畳み込み動作のフィルタの数は、タスクニューラルネットワーク内のインスタンスの位置に基づいて異なり得る。場合によっては、タスクニューラルネットワークは、出力セル150の複数のインスタンスのスタックを含む。場合によっては、出力セルのスタックに加えて、タスクニューラルネットワークは、1つまたは複数の他のニューラルネットワークレイヤ、たとえば、出力レイヤおよび/または1つまたは複数の他のタイプのレイヤを含む。たとえば、タスクニューラルネットワークは、畳み込みニューラルネットワークレイヤと、続いて出力セルの複数のインスタンスのスタックと、続いてグローバルプーリング(global pooling)ニューラルネットワークレイヤと、続いてsoftmax分類ニューラルネットワークレイヤとを含み得る。タスクニューラルネットワークの例示的なアーキテクチャについては、図3を参照しながら以下でより詳細に説明する。 In some implementations, the NAS system 100 is configured to determine the network architecture for the task neural network by determining the architecture for the output cells 150 that are repeated across the network architecture. That is, the task neural network contains multiple instances of the output cell 150. The number of filters for convolution behavior within an instance of output cell 150 can vary based on the location of the instance within the task neural network. In some cases, the task neural network contains a stack of multiple instances of output cell 150. In some cases, in addition to the stack of output cells, the task neural network includes one or more other neural network layers, such as the output layer and / or one or more other types of layers. For example, a task neural network may include a convolutional neural network layer, followed by a stack of multiple instances of output cells, followed by a global pooling neural network layer, followed by a softmax classification neural network layer. An exemplary architecture of a task neural network will be described in more detail below with reference to FIG.
概して、セルは、セル入力を受信し、セル出力を生成するように構成された全畳み込みニューラルネットワークである。いくつかの実装形態では、セル出力は、セル入力と同じ寸法、たとえば、同じ高さ(H)、幅(W)、および深さ(F)を有し得る。たとえば、セルは、特徴マップを入力として受信し、入力特徴マップと同じ寸法を有する出力特徴マップを生成し得る。いくつかの他の実装形態では、セル出力は、セル入力の寸法とは異なる寸法を有し得る。たとえば、セルが、ストライド2を有する全畳み込みニューラルネットワークであるとき、セル入力はH×W×Fテンソルであると考えると、セル出力は、H'×W'×F'テンソルであり得、ここで、H'=H/2、W'=W/2、およびF'=2Fである。 In general, a cell is a fully convolutional neural network configured to receive cell inputs and generate cell outputs. In some implementations, the cell output may have the same dimensions as the cell input, eg, the same height (H), width (W), and depth (F). For example, a cell may receive a feature map as input and generate an output feature map with the same dimensions as the input feature map. In some other implementations, the cell output may have dimensions that differ from the dimensions of the cell input. For example, if the cell is a fully convolutional neural network with stride 2, then given that the cell input is an H × W × F tensor, the cell output can be an H'× W'× F'tensor, where And H'= H / 2, W'= W / 2, and F'= 2F.
場合によっては、セルはB個の動作ブロックを含み、ここで、Bは、所定の正の整数である。たとえば、Bは、3、5、または10であり得る。セル内の各動作ブロックは、1つまたは複数のそれぞれの入力隠れ状態を受信し、1つまたは複数の動作を入力隠れ状態に適用して、それぞれの出力隠れ状態を生成する。 In some cases, the cell contains B blocks of motion, where B is a given positive integer. For example, B can be 3, 5, or 10. Each action block in the cell receives one or more of its respective input hidden states and applies one or more actions to the input hidden states to generate each output hidden state.
いくつかの実装形態では、B個の動作ブロックの各々は、動作ブロックに対する第1の入力隠れ状態に第1の動作を適用して、第1の出力を生成するように構成される。動作ブロックは、動作ブロックに対する第2の入力隠れ状態に第2の動作を適用して、第2の出力を生成するように構成される。動作ブロックは、次いで、第1および第2の出力に対して組合せ動作を適用して、動作ブロックに対する出力隠れ状態を生成するように構成される。第1の入力隠れ状態、第2の入力隠れ状態、第1の動作、第2の動作、および組合せ動作は、動作ブロックに関連するハイパーパラメータのセットによって定義され得る。たとえば、動作ブロックに対応するハイパーパラメータのセットは、以下のハイパーパラメータを含む、すなわち、どの隠れ状態が第1の入力隠れ状態として使用されるかを表す第1のハイパーパラメータ、どの隠れ状態が第2の入力隠れ状態として使用されるかを表す第2のハイパーパラメータ、どの動作が第1の動作として使用されるかを表す第3のハイパーパラメータ、どの動作が第2の動作として使用されるかを表す第4のハイパーパラメータ、およびどの動作が第1の動作と第2の動作の出力を組み合わせるための組合せ動作として使用されるかを表す第5のハイパーパラメータである。 In some implementations, each of the B motion blocks is configured to apply the first motion to the first input hidden state for the motion block to produce a first output. The motion block is configured to apply the second motion to the second input hidden state for the motion block to generate a second output. The motion block is then configured to apply a combinatorial action to the first and second outputs to create an output hidden state for the motion block. The first input hidden state, the second input hidden state, the first action, the second action, and the combination action can be defined by a set of hyperparameters associated with the action block. For example, the set of hyperparameters corresponding to the motion block contains the following hyperparameters, i.e., the first hyperparameters that represent which hidden state is used as the first input hidden state, which hidden state is the first. A second hyperparameter that indicates which action is used as the input hidden state of 2, a third hyperparameter that indicates which action is used as the first action, which action is used as the second action A fourth hyperparameter that represents, and a fifth hyperparameter that represents which action is used as a combined action to combine the outputs of the first action and the second action.
セルの例示的なアーキテクチャについては、図2を参照しながら以下でより詳細に説明する。 An exemplary architecture of the cell will be described in more detail below with reference to FIG.
出力セル150のアーキテクチャを決定するために、NASシステム100は、複数の性能予測パラメータ(本明細書において「予測パラメータ」とも呼ばれる)を有する性能予測ニューラルネットワーク110(「予測器110」とも呼ばれる)を含む。予測器110は、1つまたは複数の回帰ニューラルネットワークレイヤを含む回帰ニューラルネットワークである。たとえば、予測器110は、長短期メモリ(LSTM)ニューラルネットワークまたはゲート回帰ユニット(GRU:gated recurrent unit)ニューラルネットワークであり得る。 To determine the architecture of the output cell 150, the NAS system 100 uses a performance prediction neural network 110 (also referred to as the "predictor 110") with multiple performance prediction parameters (also referred to herein as "prediction parameters"). Including. Predictor 110 is a recurrent neural network that includes one or more recurrent neural network layers. For example, the predictor 110 can be a long short-term memory (LSTM) neural network or a gated recurrent unit (GRU) neural network.
概して、予測器110は、候補セルを指定するデータを受信し、予測パラメータに従ってそのデータを処理して、候補セルを有するニューラルネットワークが、特定の機械学習タスクに対してトレーニングされた後で、どの程度良好に機能することになるかを特徴付ける性能予測を生成するように構成される。候補セルを指定するデータは、候補セルを定義する埋め込み(たとえば、ハイパーパラメータの各セットが候補セル内に含まれるそれぞれの動作ブロックを定義する、ハイパーパラメータの複数のセットの埋め込み)のシーケンスである。本明細書で使用される埋め込みは、ハイパーパラメータの数値表現、たとえば、ベクトル、または数値の他の順序付けられた集合である。埋め込みは、事前決定されてよいか、または予測器をトレーニングする一環として学習されてもよい。 In general, the predictor 110 receives data specifying candidate cells, processes the data according to predictive parameters, and after a neural network with candidate cells has been trained for a particular machine learning task, which It is configured to generate performance predictions that characterize how well it will work. The data that specifies the candidate cells is a sequence of embeddings that define the candidate cells (for example, embedding multiple sets of hyperparameters, where each set of hyperparameters defines each action block contained within the candidate cell). .. The embeddings used herein are numerical representations of hyperparameters, such as vectors, or other ordered sets of numbers. Implantation may be pre-determined or learned as part of training the predictor.
性能予測は、たとえば、トレーニングされたニューラルネットワークの精度の予測であり得る。別の例として、性能予測は、予測平均精度と精度に対する予測標準偏差または差異の両方を含み得る。 The performance prediction can be, for example, a prediction of the accuracy of the trained neural network. As another example, performance prediction can include both predicted mean accuracy and predicted standard deviation or variance to accuracy.
具体的には、タスクニューラルネットワークのネットワークアーキテクチャにわたって繰り返される出力セル150のためのアーキテクチャを決定する一環として、NASシステム100は、出力セル150に対する候補セルの現在のセットを指定するデータ102を取得する。場合によっては、候補セルの現在のセットは、候補セルの初期セットである。いくつかの他の場合には、NASシステム100は、前の反復からセルを取得し、次いで、前のセルの各々を拡張することによって、たとえば、前のセルの各々にそれぞれの1つまたは複数の動作ブロックを追加することによって、候補セルの現在のセットを生成する。 Specifically, as part of determining the architecture for the output cell 150 that is repeated across the network architecture of the task neural network, the NAS system 100 acquires data 102 that specifies the current set of candidate cells for the output cell 150. .. In some cases, the current set of candidate cells is the initial set of candidate cells. In some other cases, the NAS system 100 retrieves cells from the previous iteration and then extends each of the previous cells, for example, one or more of each in each of the previous cells. Generate the current set of candidate cells by adding the motion block of.
現在のセット内の候補セルの各々に対して、予測器110は、候補セルを指定するデータを受信し、各候補セルに対する性能予測を生成するために、性能予測パラメータの現在の値に従って、性能予測ニューラルネットワーク110を使用してそのデータを処理する。 For each of the candidate cells in the current set, the predictor 110 receives data that specifies the candidate cells and performs according to the current value of the performance prediction parameters to generate a performance prediction for each candidate cell. The predictive neural network 110 is used to process the data.
NASシステム100は、次いで、現在のセット内の候補セルに対する性能予測に基づいて、現在のセット内の候補セルのうちの1つまたは複数を選択することによって、候補セルの更新されたセット112を生成する。すなわち、NASシステム100は、性能予測ニューラルネットワーク110によって生成された予測に基づいて、現在のセットをプルーニング(prune)して、更新されたセットを生成する。たとえば、NASシステム100は、更新されたセット112内に含まれるべき最良の性能予測を有するK個の候補セルを現在のセットから選択し、ここで、Kは、事前決定された整数である。 The NAS system 100 then selects an updated set of 112 candidate cells by selecting one or more of the candidate cells in the current set based on performance predictions for the candidate cells in the current set. Generate. That is, the NAS system 100 prunes the current set based on the predictions generated by the performance prediction neural network 110 to generate an updated set. For example, NAS system 100 selects from the current set K candidate cells with the best performance predictions to be included in the updated set 112, where K is a pre-determined integer.
予測器110の性能予測パラメータの値を更新するために、NASシステム100は、トレーニングエンジン120と予測パラメータ更新エンジン130とを含む。概して、トレーニングエンジン120および予測パラメータ更新エンジン130は、1つまたは複数のロケーション内の1つまたは複数のコンピュータ上にインストールされた、1つまたは複数のソフトウェアモジュールまたはソフトウェア構成要素として実装されることになる。場合によっては、1つまたは複数のコンピュータは、特定のエンジン専用になり、他の場合には、複数のエンジンがインストールされ、同じ1つまたは複数のコンピュータ上で実行してもよい。 To update the values of the performance prediction parameters of the predictor 110, the NAS system 100 includes a training engine 120 and a prediction parameter update engine 130. In general, the training engine 120 and the predictive parameter update engine 130 will be implemented as one or more software modules or software components installed on one or more computers in one or more locations. Become. In some cases, one or more computers may be dedicated to a particular engine, in other cases multiple engines may be installed and run on the same one or more computers.
更新されたセット内の各候補セルに対して、トレーニングエンジン120は、候補セルを有するタスクニューラルネットワークのインスタンスを生成し、特定の機械学習タスクを実行するためにそのインスタンスをトレーニングするように構成される。たとえば、トレーニングエンジン120は、タスクニューラルネットワークの所定のテンプレートアーキテクチャに従って、タスクニューラルネットワークのインスタンスを生成する。たとえば、タスクニューラルネットワークのテンプレートアーキテクチャは、第1のニューラルネットワークレイヤ(たとえば、畳み込みレイヤ)と、続いてセルのN個のインスタンスのスタックと、続いて出力サブネットワーク(たとえば、softmaxニューラルネットワークレイヤを含む出力サブネットワーク)とを含む。 For each candidate cell in the updated set, the training engine 120 is configured to instantiate a task neural network with candidate cells and train that instance to perform a particular machine learning task. To. For example, the training engine 120 creates an instance of the task neural network according to a predetermined template architecture of the task neural network. For example, a task neural network template architecture includes a first neural network layer (eg, a convolution layer), followed by a stack of N instances of cells, followed by an output subnetwork (eg, softmax neural network layer). Output subnetwork) and includes.
タスクニューラルネットワークのインスタンスをトレーニングするために、トレーニングエンジン120は、特定の機械学習タスクに対してインスタンスをトレーニングするためのトレーニングデータ、およびその特定の機械学習タスクに対して、タスクニューラルネットワークのトレーニングされたインスタンスの性能を評価するための検証セットを取得する。 To train an instance of a task neural network, the training engine 120 is trained on the task neural network for the training data for training the instance for a particular machine learning task, and for that particular machine learning task. Get a validation set to evaluate the performance of the instance.
トレーニングエンジン120は、様々な様式のうちのいずれかでインスタンスをトレーニングするためのデータを受信し得る。たとえば、いくつかの実装形態では、トレーニングエンジン120は、たとえば、NASシステム100によって利用可能にされたアプリケーションプログラミングインターフェース(API)を使用して、データ通信ネットワークを介してNASシステム100の遠隔ユーザからのアップロードとしてトレーニングデータを受信する。 The training engine 120 may receive data for training an instance in any of a variety of modes. For example, in some implementations, the training engine 120 uses an application programming interface (API) made available by the NAS system 100, for example, from a remote user of the NAS system 100 over a data communication network. Receive training data as an upload.
トレーニングエンジン120は、トレーニングされたインスタンスの実際の性能122を決定するために、特定の機械学習タスクに対してトレーニングされた各インスタンスの性能を評価する。たとえば、実際の性能は、適切な精度測定によって測定された検証セットに対するトレーニングされたインスタンスの精度であり得る。たとえば、この精度は、タスクが分類タスクであるときには分類誤り率であってよく、またはタスクが回帰タスクであるときにはIoU(Intersection over Union)差異尺度であってよい。別の例として、実際の性能はインスタンスのトレーニングの最後の2個、5個、または10個のエポックの各々に対するインスタンスの平均精度または最大精度であってよい。 The training engine 120 evaluates the performance of each trained instance for a particular machine learning task in order to determine the actual performance 122 of the trained instance. For example, the actual performance can be the accuracy of the trained instance against the validation set measured by appropriate accuracy measurements. For example, this accuracy may be a classification error rate when the task is a classification task, or an IoU (Intersection over Union) variance scale when the task is a regression task. As another example, the actual performance may be the average or maximum accuracy of the instance for each of the last 2, 5, or 10 epochs of instance training.
予測パラメータ更新エンジン130は、性能予測ニューラルネットワーク110の性能予測パラメータの値を調整するために、トレーニングされたインスタンスに対する実際の性能を使用する。具体的には、予測パラメータ更新エンジン130は、予測器110をトレーニングすることによって予測パラメータの値を調整して、従来の教師あり学習(supervised learning)技法、たとえば、確率的勾配降下(SGD:stochastic gradient descent)技法を使用して、候補セルの実際の性能を正確に予測する。 The predictive parameter update engine 130 uses the actual performance for the trained instance to adjust the value of the performance predictor parameter of the performance predictor neural network 110. Specifically, the predictive parameter update engine 130 adjusts the value of the predictor parameter by training the predictor 110 to a traditional supervised learning technique, such as stochastic gradient descent (SGD). Use the gradient descent) technique to accurately predict the actual performance of candidate cells.
予測器110を使用して、現在のセット内の候補セルの各々に対する性能予測を生成することによって、NASシステム100は、現在のセット内のすべての候補セルを考慮した。しかしながら、NASシステム100は、少数の候補セル、すなわち、更新されたセット内に含めるために予測器110によって生成された性能予測に基づいて選択された候補セルを実際にトレーニングすることのみが必要であった。したがって、NASシステム100は候補セルを有するネットワークを実際にトレーニングすることによって、多数の候補セルの性能の評価に依拠する既存のシステムよりも計算効率がはるかに高く、(すなわち、消費する計算リソースがはるかに少ない)特定の技術的実装形態を定義する。これは、タスクニューラルネットワークのインスタンスをトレーニングすることは、予測器110を使用してそれらの実際の性能を単に予測するよりも計算的にさらに一層費用がかかるためである。その上、いくつかの実装形態では、更新されたセット内に含めるために予測器によって選択された候補セルは、並行してトレーニングおよび評価されることが可能であり、それにより、NASシステム100が従来のシステムよりも高速で出力セルを決定することを可能にする。 By using the predictor 110 to generate performance predictions for each of the candidate cells in the current set, the NAS system 100 considered all candidate cells in the current set. However, the NAS system 100 only needs to actually train a small number of candidate cells, that is, candidate cells selected based on the performance predictions generated by the predictor 110 to be included in the updated set. there were. Therefore, the NAS system 100 is much more computationally efficient (ie, consumes computational resources) than existing systems that rely on evaluating the performance of a large number of candidate cells by actually training the network with the candidate cells. Define a specific technical implementation (much less). This is because training instances of task neural networks is computationally even more expensive than simply predicting their actual performance using the predictor 110. Moreover, in some implementations, candidate cells selected by the predictor for inclusion in the updated set can be trained and evaluated in parallel, thereby allowing the NAS system 100 to. Allows you to determine output cells faster than traditional systems.
予測器110の予測パラメータを更新した後、NASシステム100は、更新されたセット内の候補セルを拡張して、複数の新しい候補セルを含む新しいセットを生成する。具体的には、NASシステム100は、更新されたセット内の候補セルの各々に対して、ハイパーパラメータのそれぞれのセットを有するそれぞれの新しい動作ブロックを候補セルに追加することによって、更新されたセット内の候補セルを拡張する。 After updating the prediction parameters of the predictor 110, the NAS system 100 expands the candidate cells in the updated set to generate a new set containing a plurality of new candidate cells. Specifically, the NAS system 100 adds each new action block with each set of hyperparameters to the candidate cells for each of the candidate cells in the updated set. Expand the candidate cells in.
概して、更新されたセットが、各々がb個の動作ブロックを有する、N個の候補セルを有すると考えると、NASシステム100は、更新されたセット内のそれぞれの特定の候補セルに対して、(すなわち、新しい第(b+1)の動作ブロックを特定の候補セルに追加することによって)b+1個の動作ブロックを有するそれぞれの考えられるセルを有するすべての考えられるセルのサブセットを生成する。新しいセットは、b+1個の動作ブロックを有するすべての考えられるセルのサブセットの組合せである。 In general, given that the updated set has N candidate cells, each with b blocks of operation, the NAS system 100 will for each particular candidate cell in the updated set. Generates a subset of all possible cells with each possible cell with b + 1 operation blocks (ie, by adding a new (b + 1) th operation block to a particular candidate cell) .. The new set is a combination of a subset of all possible cells with b + 1 motion blocks.
いくつかの実装形態では、新しい第(b+1)の動作ブロックは、5個のハイパーパラメータ(I1,I2,O1,O2,C)によって指定され得、ここで、I1,I2∈Ib+1は、新しい動作ブロックに対する入力を指定し、Ib+1は、新しい動作ブロックに対する考えられる入力のセットであり、O1,O2∈Oは、それぞれ、入力I1およびI2に適用するための動作を指定し、ここで、Oは、所定の動作空間であり、C∈eは、新しい動作ブロックに対するブロック出力 In some implementations, the new (b + 1) action block can be specified by five hyperparameters (I 1 , I 2 , O 1 , O 2 , C), where I 1 , I 2 ∈I b + 1 specifies the input for the new operation block, I b + 1 is the set of possible inputs for a new operation block, O 1, O 2 ∈O are respectively input I 1 And I 2 specify the behavior to apply, where O is the given working space and C ∈ e is the block output for the new working block.
を生成するために、O1およびO2をどのように組み合わせるかを指定し、ここで、eは、考えられる組合せ演算子(combination operator)のセットである。 Specifies how to combine O 1 and O 2 to generate, where e is a set of possible combination operators.
これらの実装形態では、第(b+1)の動作ブロックに対して考えられる構造の探索空間は、サイズ|Bb+1|=|Ib+1|2×|O|2×|e|2を有するBb+1であり、ここで、|Ib+1|=2+(b+1)-1の場合、|O|は、動作空間内の動作の数であり、|e|は、セットe内の組合せ演算子の数である。したがって、新しいセット内の候補セルの数は、N×|Bb+1|個のセルである。 In these implementations, the search space for the possible structure for the (b + 1) th motion block is size | B b + 1 | = | I b + 1 | 2 × | O | 2 × | e | B b + 1 with 2 , where | I b + 1 | = 2 + (b + 1) -1, where | O | is the number of actions in the working space, | e | Is the number of combinatorial operators in set e. Therefore, the number of candidate cells in the new set is N × | B b + 1 | cells.
NASシステム100は、次いで、候補セルの新しいセットを候補セルの現在のセットとして設定し、候補セルが所定の最大数の動作ブロックを有するまで、上記のプロセスを繰り返す。 The NAS system 100 then sets a new set of candidate cells as the current set of candidate cells and repeats the above process until the candidate cells have a predetermined maximum number of operating blocks.
候補セルの各々の中の動作ブロック数が動作ブロックの所定の最大数と等しくなるとき、NASシステム100は、最良の実際の性能を有する、トレーニングされたインスタンスに対応する新しい候補セルをタスクニューラルネットワークのための出力セル150として選択する。 When the number of working blocks in each of the candidate cells is equal to a predetermined maximum number of working blocks, the NAS system 100 will task neural network with new candidate cells corresponding to the trained instances with the best actual performance. Select as output cell 150 for.
いくつかの実装形態では、システム100は、出力セル150が決定されると、出力セルのアーキテクチャを指定するデータを、たとえば、ネットワークを介してユーザデバイスに提供する。アーキテクチャを指定するデータを提供する代わりに、またはそれに加えて、システム100は、決定された出力セル150を有するニューラルネットワークを、たとえば、最初からトレーニングするか、またはより大きなニューラルネットワークをトレーニングする結果として生成されたパラメータ値を微調整するためにトレーニングし、次いで、トレーニングされたニューラルネットワークを使用して、たとえば、NASシステム100によって提供されたAPIを通して、ユーザが受信した要求を処理する。 In some implementations, the system 100, once the output cell 150 is determined, provides data specifying the architecture of the output cell to the user device, for example, over a network. Instead of providing data that specifies the architecture, or in addition, the system 100 trains a neural network with determined output cells 150, for example from scratch, or as a result of training a larger neural network. It trains to fine-tune the generated parameter values and then uses the trained neural network to process the requests received by the user, for example through the API provided by the NAS system 100.
本明細書は、タスクニューラルネットワークにわたって複数回繰り返されるセルに対して考えられるアーキテクチャの空間を探索することについて説明するが、いくつかの他の実装形態では、NASシステム100は、たとえば、1つまたは複数の所定の出力レイヤ、および、随意に、1つまたは複数の所定の入力レイヤ以外のタスクニューラルネットワーク全体に対して考えられるアーキテクチャを通して、繰り返されていないアーキテクチャの部分を探索する。 Although this specification describes exploring possible architectural spaces for cells that are repeated multiple times across a task neural network, in some other implementations the NAS system 100 may be, for example, one or more. Explore non-repeating parts of the architecture through possible architectures for multiple predetermined output layers and, optionally, for the entire task neural network other than one or more predetermined input layers.
図2は、タスクニューラルネットワークを構築するために使用され得る例示的なセル200のアーキテクチャを示す。 Figure 2 shows an exemplary cell 200 architecture that can be used to build a task neural network.
セル200は、セル入力(たとえば、H×W×Fテンソル)を処理して、セル出力(たとえば、H'×W'×F'テンソル)を生成するように構成された全畳み込みニューラルネットワークである。 Cell 200 is a fully convolutional neural network configured to process cell inputs (eg, HxWxF tensors) and generate cell outputs (eg, H'xW'xF' tensors). ..
いくつかの実装形態では、たとえば、セル200が、ストライド1を有する全畳み込みニューラルネットワークであるとき、セル出力は、セル入力と同じ寸法を有し得る(たとえば、H'=H、W'=W、およびF'=F)。いくつかの他の実装形態では、セル出力は、セル入力の寸法とは異なる寸法を有し得る。たとえば、セルが、ストライド2を有する全畳み込みニューラルネットワークであるとき、セル入力がH×W×Fテンソルであると考えると、セル出力は、H'×W'×F'テンソルであり得、式中、H'=H/2、W'=W/2、およびF'=2Fである。 In some implementations, for example, when cell 200 is a fully convolutional neural network with stride 1, the cell output can have the same dimensions as the cell input (eg H'= H, W'= W). , And F'= F). In some other implementations, the cell output may have dimensions that differ from the dimensions of the cell input. For example, if the cell is a fully convolutional neural network with stride 2, then given that the cell input is an H × W × F tensor, the cell output can be an H'× W'× F'tensor, the formula. Medium, H'= H / 2, W'= W / 2, and F'= 2F.
セル200は、複数の動作ブロック(B個のブロック)を含む。たとえば、図2に示すように、セル200は、5個のブロック、すなわち、ブロック202、204、206、208、および210を含む。 Cell 200 includes a plurality of operation blocks (B blocks). For example, as shown in FIG. 2, cell 200 includes five blocks, namely blocks 202, 204, 206, 208, and 210.
セル200内の各ブロックbは、5個のハイパーパラメータ(I1,I2,O1,O2,C)によって指定することができ、ここで、I1,I2∈Ibは、ブロックbに対する入力を指定し、O1,O2∈Oは、それぞれ、入力I1、I2に適用するための動作を指定し、ここで、Oは動作空間であり、C∈eは、ブロックbに対するブロック出力 Each block b in cell 200 can be specified by 5 hyperparameters (I 1 , I 2 , O 1 , O 2 , C), where I 1, I 2 ∈ I b is a block. Specifying the input to b, O 1, O 2 ∈ O specifies the behavior to apply to inputs I 1 and I 2 , respectively, where O is the working space and C ∈ e is the block. Block output for b
を生成するために、O1およびO2をどのように組み合わせるかを指定し、ここで、eは、考えられる組合せ演算子のセットである。 Specifies how to combine O 1 and O 2 to generate, where e is a set of possible combination operators.
考えられる入力のセットIbは、セル200内のすべての前のブロックのセット The set of possible inputs I b is the set of all previous blocks in cell 200.
に、前のセルの出力 To the output of the previous cell
を加え、それに前のセルに先行するセルの出力 And the output of the cell that precedes the previous cell
を加えたものである。 Is added.
動作空間Oは、限定はしないが、以下の動作を含み得る:すなわち、3×3深さ方向分離可能な畳み込み(depthwise-separable convolution)、5×5深さ方向分離可能畳み込み、7×7深さ方向分離可能畳み込み、1×7とその後に7×1が続く畳み込み(1x7 followed by 7x1 convolution)、恒等式、3×3平均プーリング、3×3最大プーリング、および3×3拡張畳み込み(dilated convolution)、である。 The operating space O can include, but is not limited to, the following actions: 3x3 depthwise-separable convolution, 5x5 depthwise separable convolution, 7x7 depth. Directionally separable convolution, 1x7 followed by 7x1 convolution, equality, 3x3 average pooling, 3x3 maximum pooling, and 3x3 extended convolution ,.
いくつかの実装形態では、考えられる組合せ演算子のセットeは、追加動作および連結動作を含む。 In some implementations, a set of possible combinatorial operators e includes additional and concatenated actions.
いくつかの実装形態では、考えられる組合せ演算子のセットeは、追加動作のみを含む。これらの実装形態では、セル200の各ブロックbは、4個のハイパーパラメータ(I1,I2,O1,O2)によって指定され得る。 In some implementations, the set of possible combinatorial operators e contains only additional behavior. In these implementations, each block b in cell 200 can be specified by four hyperparameters (I 1 , I 2 , O 1 , O 2 ).
各ブロックbがブロック出力を生成した後、すべてのブロックのブロック出力が組み合わされ、たとえば、連結されるか、加算されるか、または平均されて、セル200に対するセル出力Hcを生成する。 After each block b produces a block output, the block outputs of all blocks are combined, for example concatenated, added, or averaged to produce a cell output H c for cell 200.
図3は、例示的なタスクニューラルネットワーク300のアーキテクチャを示す。タスクニューラルネットワーク300は、ネットワーク入力302を受信し、入力302に対するネットワーク出力320を生成するように構成される。 Figure 3 shows the architecture of an exemplary task neural network 300. The task neural network 300 is configured to receive network input 302 and generate network output 320 for input 302.
タスクニューラルネットワーク300は、セルインスタンスのスタック306を含む。スタック306は、次々にスタックされるセルの複数のインスタンスを含む。スタック306内のセルインスタンスは、同じ構造を有し得るが、異なるパラメータ値を有する。スタック306内のセルインスタンスの中の畳み込み動作のフィルタ数は、そのスタック内のインスタンスの位置に基づいて異なり得る。たとえば、一実装形態では、セルインスタンス308は、ストライド2セルであり、セルインスタンス310は、ストライド1セルである。そのような実装形態では、セルインスタンス308は、セルインスタンス310が有する2倍のフィルタを有する。 The task neural network 300 includes a stack 306 of cell instances. Stack 306 contains multiple instances of cells that are stacked one after the other. The cell instances in stack 306 can have the same structure but different parameter values. The number of filters for convolution behavior within a cell instance in stack 306 can vary based on the location of the instance in that stack. For example, in one implementation, cell instance 308 is stride 2 cells and cell instance 310 is stride 1 cell. In such an implementation, cell instance 308 has twice the filter that cell instance 310 has.
スタック306内の第1のセルインスタンス308は、第1のセル入力を受信し、第1のセル出力を生成するために第1のセル入力を処理するように構成される。 The first cell instance 308 in stack 306 is configured to receive the first cell input and process the first cell input to produce the first cell output.
場合によっては、第1のセル入力は、タスクニューラルネットワークのネットワーク入力302である。 In some cases, the first cell input is the network input 302 of the task neural network.
いくつかの他の場合には、ネットワーク入力302は画像であり、タスクニューラルネットワーク300は、画像の処理に関連する計算コストを低減させるために、セルのスタック306に先行して、畳み込みニューラルネットワークレイヤ304を含み得る。たとえば、畳み込みニューラルネットワークレイヤ304は、ストライド2を有する3×3畳み込みフィルタレイヤである。これらの場合には、畳み込みニューラルネットワークレイヤ304は、第1のセル入力としてセルインスタンス308に提供されるべき中間出力を生成するために、ネットワーク入力302を処理するように構成される。 In some other cases, the network input 302 is an image, and the task neural network 300 precedes the cell stack 306 to reduce the computational costs associated with processing the image, the convolutional neural network layer. Can include 304. For example, the convolutional neural network layer 304 is a 3x3 convolutional filter layer with stride 2. In these cases, the convolutional neural network layer 304 is configured to process the network input 302 to generate an intermediate output that should be provided to the cell instance 308 as the first cell input.
第1のセルインスタンスに続く各セルインスタンス(たとえば、セルインスタンス310〜312)は、前のセルインスタンスのセル出力を入力として受信し、入力として次のセルインスタンスに供給されるそれぞれのセル出力を生成するように構成される。スタック306の出力は、最後のセルインスタンス314のセル出力である。 Each cell instance following the first cell instance (for example, cell instances 310-312) receives the cell output of the previous cell instance as input and produces each cell output supplied as input to the next cell instance. It is configured to. The output of stack 306 is the cell output of the last cell instance 314.
タスクニューラルネットワーク300は、サブネットワーク316と、続いてセルインスタンスのスタック306とを含む。サブネットワーク316は、入力としてセルインスタンスのスタック306の出力を受信し、ネットワーク出力320を生成するためにスタック306の出力を処理するように構成される。一例として、サブネットワーク316は、グローバルプーリングニューラルネットワークレイヤと、続いてsoftmax分類ニューラルネットワークレイヤとを含む。 The task neural network 300 includes a subnet 316 followed by a stack of cell instances 306. Subnetwork 316 is configured to receive the output of stack 306 for cell instances as input and process the output of stack 306 to generate network output 320. As an example, the subnet 316 includes a global pooling neural network layer followed by a softmax classification neural network layer.
図4は、タスクニューラルネットワークにわたって繰り返されるセルのアーキテクチャを決定するための例示的なプロセス400の流れ図である。便宜上、プロセス400は、1つまたは複数のロケーション内に位置する1つまたは複数のコンピュータのシステムによって実行されるとして説明される。たとえば、ニューラルアーキテクチャ探索システム、たとえば、本明細書に従って適切にプログラムされた、図1のニューラルアーキテクチャ探索システム100がプロセス400を実行し得る。 FIG. 4 is a flow diagram of an exemplary process 400 for determining the architecture of cells that are repeated across a task neural network. For convenience, process 400 is described as being performed by a system of one or more computers located in one or more locations. For example, a neural architecture search system, eg, a neural architecture search system 100 of FIG. 1, properly programmed according to the present specification, may perform process 400.
システムは、タスクニューラルネットワークを構築するために使用される出力セルに対する候補セルの現在のセットを指定するデータを取得する(ステップ402)。 The system gets data that specifies the current set of candidate cells for the output cells used to build the task neural network (step 402).
場合によっては、候補セルの現在のセットは、候補セルの初期セットである。いくつかの他の場合には、システムは、前の反復からセルを取得し、次いで、前のセルの各々を拡張することによって、たとえば、それぞれの1つまたは複数の動作ブロックを前のセルの各々に追加することによって、候補セルの現在のセットを生成する。 In some cases, the current set of candidate cells is the initial set of candidate cells. In some other cases, the system retrieves cells from the previous iteration and then extends each of the previous cells to, for example, one or more blocks of action for each of the previous cells. Generate the current set of candidate cells by adding to each.
システムは、複数の性能予測パラメータを有する性能予測ニューラルネットワークを使用して、候補セルを指定するデータを処理する(ステップ404)。性能予測ニューラルネットワークは、候補セルを有するニューラルネットワークが、特定の機械学習スタックに対してトレーニングされた後で、どの程度良好に機能することになるかを特徴付ける性能予測を生成するために、性能予測パラメータの現在の値に従って、候補セルを指定するデータを処理するように構成される。 The system uses a performance prediction neural network with multiple performance prediction parameters to process the data specifying candidate cells (step 404). Performance Prediction Neural Networks are used to generate performance predictions that characterize how well a neural network with candidate cells will perform after being trained against a particular machine learning stack. It is configured to process data that specifies candidate cells according to the current value of the parameter.
システムは、現在のセット内の候補セルに対する性能予測に基づいて、現在のセット内の候補セルのうちの1つまたは複数を選択することによって、候補セルの更新されたセットを生成する(ステップ406)。すなわち、システムは、性能予測ニューラルネットワークによって生成される予測に基づいて、現在のセットをプルーニングして、更新されたセットを生成する。たとえば、システムは、更新されたセット内に含まれるべき最良の性能予測を有するK個の候補セルを現在のセットから選択し、ここで、Kは、所定の整数である。 The system generates an updated set of candidate cells by selecting one or more of the candidate cells in the current set based on performance predictions for the candidate cells in the current set (step 406). ). That is, the system prunes the current set to generate an updated set based on the predictions generated by the performance prediction neural network. For example, the system selects from the current set K candidate cells with the best performance predictions to be included in the updated set, where K is a given integer.
システムは、以下のように、現在のセット内の候補セルの各々に対してステップ408〜412を反復的に実行する。 The system iteratively performs steps 408-412 for each of the candidate cells in the current set, as follows:
システムは、候補セルを有するタスクニューラルネットワークのインスタンスを生成する(ステップ408)。たとえば、システムは、タスクニューラルネットワークの所定のテンプレートアーキテクチャに従って、タスクニューラルネットワークのインスタンスを生成する。たとえば、タスクニューラルネットワークのテンプレートアーキテクチャは、第1のニューラルネットワークレイヤ(たとえば、畳み込みレイヤ)と、続いてセルのN個のインスタンスのスタックと、続いて出力サブネットワーク(たとえば、softmaxニューラルネットワークレイヤを含む出力サブネットワーク)とを含む。 The system instantiates a task neural network with candidate cells (step 408). For example, the system instantiates a task neural network according to a given template architecture of the task neural network. For example, a task neural network template architecture includes a first neural network layer (eg, a convolution layer), followed by a stack of N instances of cells, followed by an output subnetwork (eg, softmax neural network layer). Output subnetwork) and includes.
システムは、特定の機械学習タスクを実行するようにインスタンスをトレーニングする(ステップ410)。 The system trains the instance to perform a specific machine learning task (step 410).
タスクニューラルネットワークのインスタンスをトレーニングするために、システムは、特定の機械学習タスクに対してインスタンスをトレーニングするためのトレーニングデータ、および特定の機械学習タスクに対して、タスクニューラルネットワークのトレーニングされたインスタンスの性能を評価するための検証セットを取得する。システムは、次いで、従来の機械学習トレーニング技法を使用して、トレーニングデータに対してインスタンスをトレーニングする。 To train an instance of a task neural network, the system has training data for training the instance for a particular machine learning task, and for a particular machine learning task, a trained instance of the task neural network. Obtain a verification set to evaluate performance. The system then trains the instance against the training data using traditional machine learning training techniques.
システムは、次いで、たとえば、検証データセットに対してトレーニングされたインスタンスの精度を測定することによって、トレーニングされたインスタンスの実際の性能を決定するために、特定の機械学習タスクに対してトレーニングされた各インスタンスの性能を評価する(ステップ412)。 The system was then trained for a particular machine learning task to determine the actual performance of the trained instance, for example by measuring the accuracy of the trained instance against the validation dataset. Evaluate the performance of each instance (step 412).
システムが現在のセット内のすべての候補セルに対してステップ408〜412を繰り返すと、システムは、性能予測ニューラルネットワークの性能予測パラメータの値を調整するために、トレーニングされたインスタンスに対する実際の性能を使用する(ステップ414)。 When the system repeats steps 408-412 for all candidate cells in the current set, the system determines the actual performance for the trained instance in order to adjust the values of the performance prediction parameters of the performance prediction neural network. Use (step 414).
具体的には、システムは、性能予測ニューラルネットワークをトレーニングすることによって、予測パラメータの値を調整して、従来の教師あり学習技法、たとえば、確率的勾配降下(SGD)技法を使用して、候補セルの実際の性能を正確に予測する。 Specifically, the system adjusts the values of predictive parameters by training a performance predictive neural network and uses traditional supervised learning techniques, such as stochastic gradient descent (SGD) techniques, as candidates. Accurately predict the actual performance of the cell.
システムは、次いで、更新されたセット内の候補セルの各々の中の動作ブロック数がセル内で許可される所定の最大動作ブロック数未満であるかどうかを決定する(ステップ416)。 The system then determines whether the number of working blocks in each of the candidate cells in the updated set is less than the predetermined maximum number of working blocks allowed in the cell (step 416).
新しいセット内の新しい候補セルの各々の中の動作ブロック数がセル内で許可される所定の最大動作ブロック数未満であるとき、システムは、更新されたセット内の候補セルを拡張して、候補セルの新しいセットを生成する。具体的には、システムは、更新されたセット内の候補セルの各々に対して、ハイパーパラメータのそれぞれのセットを有するそれぞれの新しい動作ブロックをその候補セルに追加することによって、更新されたセット内の候補セルを拡張する。システムは、次いで、候補セルのこの新しいセットを候補セルの現在のセットとして設定し、各候補セル内の動作ブロック数が最大動作ブロック数に等しくなるまで、ステップ402〜416を繰り返す。 When the number of working blocks in each of the new candidate cells in the new set is less than the predetermined maximum number of working blocks allowed in the cell, the system expands the candidate cells in the updated set to make candidates. Generate a new set of cells. Specifically, for each of the candidate cells in the updated set, the system adds each new action block with each set of hyperparameters to the candidate cell in the updated set. Expand the candidate cells of. The system then sets this new set of candidate cells as the current set of candidate cells and repeats steps 402-416 until the number of working blocks in each candidate cell is equal to the maximum number of working blocks.
更新されたセット内の候補セルの各々の中の動作ブロック数が所定の最大動作ブロック数に等しいとき、システムは、タスクニューラルネットワークのアーキテクチャにわたって繰り返される出力セルとして、最良の実際の性能を有するトレーニングされたインスタンスに対応する新しい候補セルを選択する(ステップ418)。 When the number of working blocks in each of the candidate cells in the updated set is equal to a given maximum number of working blocks, the system trains with the best actual performance as output cells that are repeated across the architecture of the task neural network. Select a new candidate cell that corresponds to the instance (step 418).
この明細書は、システムおよびコンピュータプログラム構成要素に関して「構成された」という用語を使用する。特定の動作または活動を実行するように構成されるべき1つまたは複数のコンピュータのシステムは、そのシステムが、動作中、そのシステムにそれらの動作または活動を実行させるソフトウェア、ファームウェア、ハードウェア、またはそれらの組合せをその上にインストールしていることを意味する。特定の動作または活動を実行するように構成されるべき1つまたは複数のコンピュータプログラムは、その1つまたは複数のプログラムが、データ処理装置によって実行されると、その装置にそれらの動作または活動を実行させる命令を含むことを意味する。 This specification uses the term "configured" with respect to system and computer program components. A system of one or more computers that should be configured to perform a particular action or activity is software, firmware, hardware, or software, firmware, hardware, or that causes the system to perform those actions or activities while the system is running. It means that you have a combination of them installed on it. A computer program that should be configured to perform a particular action or activity, when the one or more programs are executed by a data processing device, causes that device to perform those actions or activities. It means to include an instruction to be executed.
本明細書で説明した主題および機能的動作の実施形態は、デジタル電子回路で、有形に具現化されたコンピュータソフトウェアまたはファームウェアで、本明細書で開示した構造およびそれらの構造的均等物を含めて、コンピュータハードウェアで、またはそれらのうちの1つまたは複数の組合せで実装され得る。本明細書で説明した主題の実施形態は、1つまたは複数のコンピュータプログラム、すなわち、データ処理装置によって実行するための、またはデータ処理装置の動作を制御するための、有形の非一時的記憶媒体上で符号化されたコンピュータプログラム命令の1つまたは複数のモジュールとして実装され得る。コンピュータ記憶媒体は、機械可読記憶デバイス、機械可読記憶基板、ランダムアクセスメモリデバイスもしくはシリアルアクセスメモリデバイス、またはそれらのうちの1つまたは複数の組合せであってよい。代替または追加として、プログラム命令は、データ処理装置による実行のために適切な受信機装置に送信するための情報を符号化するために生成された、人工的に生成された伝搬信号、たとえば、機械生成電気信号、光信号、または電磁信号上で符号化され得る。 Embodiments of the subject matter and functional operations described herein are computer software or firmware tangibly embodied in digital electronic circuits, including the structures disclosed herein and their structural equivalents. It can be implemented in computer hardware, or in one or more combinations of them. Embodiments of the subject matter described herein are tangible, non-temporary storage media for one or more computer programs, i.e., to be executed by a data processor or to control the operation of the data processor. It can be implemented as one or more modules of the computer program instructions encoded above. The computer storage medium may be a machine-readable storage device, a machine-readable storage board, a random access memory device or a serial access memory device, or a combination thereof. Alternatively or additionally, the program instruction is an artificially generated propagating signal, eg, a machine, generated to encode the information to be sent to the appropriate receiver device for execution by the data processor. It can be encoded on a generated electrical, optical, or electromagnetic signal.
「データ処理装置」という用語は、データ処理ハードウェアを指し、例として、プログラマブルプロセッサ、コンピュータ、または複数のプロセッサもしくはコンピュータを含めて、データを処理するためのすべての種類の装置、デバイス、および機械を包含する。これらの装置は、専用論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)であってもよいか、またはそれらをさらに含んでよい。これらの装置は、随意に、ハードウェアに加えて、コンピュータプログラムのための実行環境を作成するコード、たとえば、プロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、またはそれらのうちの1つまたは複数の組合せを構成するコードを含み得る。 The term "data processor" refers to data processing hardware, including programmable processors, computers, or multiple processors or computers, all types of devices, devices, and machines for processing data. Including. These devices may be dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits), or may further include them. These devices optionally, in addition to hardware, code that creates an execution environment for computer programs, such as processor firmware, protocol stacks, database management systems, operating systems, or one or more of them. Can include codes that make up the combination of.
プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、モジュール、ソフトウェアモジュール、スクリプト、またはコードと呼ばれることもあるか、またはそのように説明されてもよいコンピュータプログラムは、コンパイル型言語もしくはインタープリタ型言語、または宣言型言語もしくは手続き型言語を含めて、任意の形態のプログラミング言語で書き込まれてよく、スタンドアロンプログラムとして、またはモジュール、構成要素、サブルーチン、もしくはコンピューティング環境で使用するのに適した他のユニットとして、を含めて、任意の形態で展開され得る。プログラムは、必ずしもその必要はないが、ファイルシステム内のファイルに対応し得る。プログラムは、他のプログラムまたはデータ、たとえば、マークアップ言語文書内、当該プログラム専用の単一のファイル内、または複数の協調ファイル、たとえば、1つまたは複数のモジュール、サブプログラム、またはコードの部分を記憶するファイル内に記憶された1つまたは複数のスクリプトを保持するファイルの一部分の中に記憶され得る。コンピュータプログラムは、1つの場所に位置するか、または複数の場所にわたって分散され、データ通信ネットワークによって相互接続された、1つのコンピュータまたは複数のコンピュータ上で実行されるように展開され得る。 Computer programs that are sometimes referred to or may be referred to as programs, software, software applications, apps, modules, software modules, scripts, or code are compiled or interpreted languages, or declarative languages. Alternatively, it may be written in any form of programming language, including procedural languages, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. And can be deployed in any form. The program may correspond to files in the file system, but not necessarily. A program may contain other programs or data, such as within a markup language document, within a single file dedicated to that program, or multiple collaborative files, such as one or more modules, subprograms, or parts of code. It can be stored in a part of a file that holds one or more scripts stored in the file to be stored. Computer programs may be deployed to run on one or more computers located in one location or distributed across multiple locations and interconnected by data communication networks.
本明細書において、「データベース」という用語は、データの任意のコレクションを指すように広く使用され、データは、任意の特定の様式で構成される必要はなく、またはまったく構成されなくてもよく、データは、1つまたは複数のロケーション内の記憶デバイス上に記憶されてよい。したがって、たとえば、インデックスデータベースは、データの複数のコレクションを含んでよく、その各々は、異なって編成されアクセスされ得る。 As used herein, the term "database" is widely used to refer to any collection of data, which may or may not be constructed in any particular manner. Data may be stored on storage devices in one or more locations. Thus, for example, an index database may contain multiple collections of data, each of which can be organized and accessed differently.
同様に、本明細書において、「エンジン」という用語は、1つまたは複数の特定の機能を実行するようにプログラムされた、ソフトウェアベースのシステム、サブシステム、またはプロセスを指すように広く使用される。概して、エンジンは、1つまたは複数のロケーション内の1つまたは複数のコンピュータ上にインストールされた、1つまたは複数のソフトウェアモジュールまたはソフトウェア構成要素として実装されることになる。場合によっては、1つまたは複数のコンピュータは、特定のエンジン専用になり、他の場合には、複数のエンジンが同じ1つまたは複数のコンピュータ上にインストールされ実行され得る。 Similarly, as used herein, the term "engine" is widely used to refer to a software-based system, subsystem, or process programmed to perform one or more specific functions. .. Generally, the engine will be implemented as one or more software modules or software components installed on one or more computers in one or more locations. In some cases, one or more computers may be dedicated to a particular engine, in other cases multiple engines may be installed and run on the same one or more computers.
本明細書で説明したプロセスおよび論理フローは、入力データを動作させ、出力を生成することによって機能を実行するために1つまたは複数のコンピュータプログラムを実行する、1つまたは複数のプログラマブルコンピュータによって実行され得る。プロセスおよび論理フローは、専用論理回路、たとえば、FPGAもしくはASICによって、または専用論理回路と1つまたは複数のプログラムされたコンピュータの組合せによって実行されてもよい。 The processes and logical flows described herein are run by one or more programmable computers that run one or more computer programs to operate input data and perform functions by producing output. Can be done. Processes and logic flows may be performed by dedicated logic circuits, such as FPGAs or ASICs, or by a combination of dedicated logic circuits and one or more programmed computers.
コンピュータプログラムの実行に適したコンピュータは、汎用マイクロプロセッサもしくは専用マイクロプロセッサまたは両方、あるいは任意の他の種類の中央処理装置に基づき得る。概して、中央処理装置は、読取り専用メモリもしくはランダムアクセスメモリまたは両方から命令およびデータを受信することになる。コンピュータの必須要素は、命令を実行(perform)または実行(execute)するための中央処理装置、および命令およびデータを記憶するための1つまたは複数のメモリデバイスである。中央処理装置およびメモリは、専用論理回路によって補完されてよいか、またはその中に組み込まれてもよい。概して、コンピュータはまた、データを記憶するための1つまたは複数の大容量記憶デバイス、たとえば、磁気ディスク、光磁気ディスク、または光ディスクを含むことになるか、あるいはそこからデータを受信するか、もしくはそこにデータを転送するか、または両方を行うように動作可能に結合されることになる。しかしながら、コンピュータは、そのようなデバイスを有さなくてもよい。さらに、コンピュータは、別のデバイス、たとえば、ほんのいくつかを挙げれば、モバイル電話、携帯情報端末(PDA)、モバイルオーディオプレイヤーもしくはモバイルビデオプレイヤー、ゲームコンソール、全地球測位システム(GPS)受信機、またはポータブル記憶デバイス、たとえば、ユニバーサルシリアルバス(USB)フラッシュドライブ内に埋め込まれてもよい。 A suitable computer for executing a computer program may be based on a general purpose microprocessor, a dedicated microprocessor, or both, or any other type of central processing unit. In general, the central processing unit will receive instructions and data from read-only memory and / or random access memory. Essential elements of a computer are a central processing unit for performing or executing instructions, and one or more memory devices for storing instructions and data. The central processing unit and memory may be complemented by or incorporated into a dedicated logic circuit. In general, a computer will also include or receive data from one or more mass storage devices for storing data, such as magnetic disks, magneto-optical disks, or optical disks. It will be operably combined to transfer data there, or both. However, the computer does not have to have such a device. In addition, computers can be other devices, such as mobile phones, personal digital assistants (PDAs), mobile audio or mobile video players, game consoles, Global Positioning System (GPS) receivers, or, to name just a few. It may be embedded in a portable storage device, such as a universal serial bus (USB) flash drive.
コンピュータプログラム命令およびデータを記憶するのに適したコンピュータ可読媒体は、例として、半導体メモリデバイス、たとえば、EPROM、EEPROM、およびフラッシュメモリデバイス;磁気ディスク、たとえば、内部ハードディスクまたはリムーバブルディスク;光磁気ディスク;ならびにCD ROMディスクおよびDVD-ROMディスクを含めて、すべての形態の不揮発性のメモリ、媒体デバイスおよびメモリデバイスを含む。 Computer-readable media suitable for storing computer program instructions and data include, for example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices; magnetic disks such as internal hard disks or removable disks; magneto-optical disks; Includes all forms of non-volatile memory, media devices and memory devices, including CD ROM disks and DVD-ROM disks.
ユーザとの対話を提供するために、本明細書で説明した主題の実施形態は、情報をユーザに表示するためのディスプレイデバイス、たとえば、CRT(陰極線管)モニタまたはLCD(液晶ディスプレイ)モニタと、それによりユーザがコンピュータに入力を提供することができるキーボードおよびポインティングデバイス、たとえば、マウスまたはトラックボールとを有するコンピュータ上で実装され得る。他の種類のデバイスを使用して、ユーザとの対話を実現することもでき、たとえば、ユーザに提供されるフィードバックは、任意の形態の感覚フィードバック、たとえば、視覚フィードバック、聴覚フィードバック、または触覚フィードバックであってよく、ユーザからの入力は、音響入力、音声入力、または触覚入力を含めて、任意の形態で受信され得る。加えて、コンピュータは、ユーザによって使用されるデバイスに文書を送り、そこから文書を受信することによって、たとえば、ウェブブラウザから受信された要求に応じて、ウェブページをユーザのデバイス上のウェブブラウザに送ることによって、ユーザと対話することができる。また、コンピュータは、テキストメッセージまたは他の形態のメッセージをパーソナルデバイス、たとえば、メッセージングアプリケーションを実行しているスマートフォンに送り、返しに、ユーザから応答メッセージを受信することによって、ユーザと対話し得る。 To provide user interaction, embodiments of the subject matter described herein include a display device for displaying information to the user, such as a CRT (cathode tube) monitor or LCD (liquid crystal display) monitor. It can be implemented on a computer that has a keyboard and pointing device that allows the user to provide input to the computer, such as a mouse or trackball. Other types of devices can also be used to enable interaction with the user, for example, the feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback. The input from the user may be received in any form, including acoustic input, voice input, or tactile input. In addition, the computer sends a document to the device used by the user and receives the document from it, for example, in response to a request received from a web browser, to a web page on the user's device. You can interact with the user by sending. The computer may also interact with the user by sending a text message or other form of message to a personal device, such as a smartphone running a messaging application, and in return receiving a response message from the user.
機械学習モデルを実装するためのデータ処理装置は、たとえば、機械学習トレーニングまたは機械学習製造の共通のコンピュータ集約的な部分、すなわち、推論、作業負荷を処理するために、専用ハードウェア加速ユニットを含んでもよい。 Data processing equipment for implementing machine learning models includes, for example, a common computer-intensive part of machine learning training or machine learning manufacturing, namely a dedicated hardware acceleration unit to handle inference, workload. It may be.
機械学習モデルは、機械学習フレームワーク、たとえば、TensorFlowフレームワーク、Microsoft Cognitive Toolkitフレームワーク、Apache Singaフレームワーク、またはApache MXNetフレームワークを使用して、実装および展開され得る。 Machine learning models can be implemented and deployed using machine learning frameworks such as the TensorFlow framework, Microsoft Cognitive Toolkit framework, Apache Singa framework, or Apache MXNet framework.
本明細書で説明した主題の実施形態は、たとえば、データサーバなどのバックエンド構成要素を含むか、もしくはミドルウェア構成要素、たとえば、アプリケーションサーバを含むか、またはフロントエンド構成要素、たとえば、それを通してユーザが本明細書で説明した主題の実装形態と対話することができる、グラフィカルユーザインターフェース、ウェブブラウザ、またはアプリを有するクライアントコンピュータを含むコンピューティングシステムで、あるいは1つまたは複数のそのようなバックエンド構成要素、ミドルウェア構成要素、またはフロントエンド構成要素の任意組合せで実装され得る。システムの構成要素は、任意の形態または媒体のデジタルデータ通信、たとえば、通信ネットワークによって相互接続され得る。通信ネットワークの例は、ローカルエリアネットワーク(LAN)および広域ネットワーク(WAN)、たとえば、インターネットを含む。 Embodiments of the subject described herein include, for example, a back-end component such as a data server, or include a middleware component, such as an application server, or a front-end component, eg, a user through it. In a computing system including a client computer with a graphical user interface, web browser, or application that can interact with the implementations of the subject matter described herein, or in one or more such backend configurations. It can be implemented with any combination of elements, middleware components, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, such as a communication network. Examples of communication networks include local area networks (LANs) and wide area networks (WANs), such as the Internet.
コンピューティングシステムは、クライアントおよびサーバを含み得る。クライアントおよびサーバは、概して、互いから遠隔にあり、典型的には、通信ネットワークを通じて対話する。クライアントおよびサーバの関係は、それぞれのコンピュータ上で実行し、互いとクライアント/サーバ関係を有するコンピュータプログラムにより生じる。いくつかの実施形態では、サーバは、たとえば、クライアントとして働くデバイスと対話するユーザにデータを表示し、そこからユーザ入力を受信するために、データ、たとえば、HTMLページをユーザデバイスに送信する。ユーザデバイスにおいて生成されたデータ、たとえば、ユーザ対話の結果は、サーバにおいてデバイスから受信され得る。 The computing system can include clients and servers. Clients and servers are generally remote from each other and typically interact through communication networks. The client-server relationship arises from computer programs that run on their respective computers and have a client / server relationship with each other. In some embodiments, the server sends data, eg, an HTML page, to the user device, for example, to display the data to a user interacting with the device acting as a client and to receive user input from it. Data generated on the user device, such as the result of user interaction, can be received from the device on the server.
本明細書は多くの特定の実装形態詳細を含むが、これらは、本発明の範囲に対する、または特許請求され得る範囲に対する制限と解釈されるべきではなく、特定の発明の特定の実施形態に固有であり得る特徴の説明として解釈されるべきである。別個の実施形態の文脈で、本明細書で説明したいくつかの特徴は、単一の実施形態において組み合わせて実装されてもよい。逆に、単一の実施形態の文脈で説明した様々な特徴は、複数の実施形態で別々に、または任意の適切なサブコンビネーションで実装されてもよい。その上、特徴は上記でいくつかの組合せで動作するとして説明される場合があり、当初、そのようなものとして特許請求される場合すらあるが、特許請求される組合せからの1つまたは複数の特徴は、場合によっては、その組合せから削除されてよく、特許請求される組合せは、サブコンビネーションまたはサブコンビネーションの変種に関する場合がある。 Although the present specification contains many specific implementation details, these should not be construed as restrictions on the scope of the invention or claims, and are specific to a particular embodiment of a particular invention. Should be interpreted as an explanation of possible features. In the context of separate embodiments, some of the features described herein may be implemented in combination in a single embodiment. Conversely, the various features described in the context of a single embodiment may be implemented separately in multiple embodiments or in any suitable subcombination. Moreover, the features may be described above as working in several combinations, initially claimed as such, but one or more from the claimed combinations. Features may be removed from the combination in some cases, and the claimed combination may relate to a subcombination or a variant of the subcombination.
同様に、動作は、特定の順序で、図面において示され、請求項において列挙されるが、これは、そのような動作が、示される特定の順序で、または連続的な順序で実行されるべきであるとして、または所望の結果を達成するために、示したすべての動作が実行されるべきであるとして理解されるべきではない。状況によっては、マルチタスキングおよび並列処理が有利であり得る。その上、上記で説明した実施形態内の様々なシステムモジュールおよび構成要素の分離は、すべての実施形態においてそのような分離を必要とすると理解すべきではなく、説明したプログラム構成要素およびシステムは、概して、単一のソフトウェア製品内に一緒に統合されてよいか、または複数のソフトウェア製品内に梱包されてよいことを理解されたい。 Similarly, the operations are shown in the drawings and listed in the claims in a particular order, but this is because such actions should be performed in the specific order shown or in a continuous order. It should not be understood as being, or as all the actions shown should be performed in order to achieve the desired result. In some situations, multitasking and parallelism can be advantageous. Moreover, the separation of the various system modules and components within the embodiments described above should not be understood as requiring such separation in all embodiments, and the program components and systems described. It should be understood that, in general, they may be integrated together within a single software product or packaged within multiple software products.
本主題の特定の実施形態について説明されてきた。他の実施形態は、以下の特許請求の範囲内である。たとえば、特許請求の範囲において列挙する活動は、異なる順序で実行され、依然として所望の結果を達成し得る。一例として、添付の図面に示したプロセスは、所望の結果を達成するために、必ずしも示した特定の順序、または連続的な順序を必要とするとは限らない。場合によっては、マルチタスキングおよび並列処理が有利であり得る。 Specific embodiments of the subject have been described. Other embodiments are within the scope of the following claims. For example, the activities listed in the claims may be performed in a different order and still achieve the desired result. As an example, the process shown in the accompanying drawings does not necessarily require the particular order or sequential order shown to achieve the desired result. In some cases, multitasking and parallel processing can be advantageous.
100 ニューラルアーキテクチャ探索(NAS)システム
102 データ
110 性能予測ニューラルネットワーク、予測器
112 更新されたセット
120 トレーニングエンジン
122 実際の性能
130 予測パラメータ更新エンジン
150 出力セル
200 セル
202 ブロック
204 ブロック
206 ブロック
208 ブロック
210 ブロック
300 タスクニューラルネットワーク
302 ネットワーク入力、入力
304 畳み込みニューラルネットワークレイヤ
306 セルインスタンスのスタック、スタック
308 セルインスタンス、第1のセルインスタンス
310 セルインスタンス
312 セルインスタンス
314 最後のセルインスタンス
316 サブネットワーク
320 ネットワーク出力
400 プロセス
100 Neural Architecture Search (NAS) System
102 data
110 Performance Prediction Neural Network, Predictor
112 Updated set
120 training engine
122 Actual performance
130 Predictive Parameter Update Engine
150 output cells
200 cells
202 blocks
204 blocks
206 blocks
208 blocks
210 blocks
300 task neural network
302 network input, input
304 Convolutional Neural Network Layer
306 Cell instance stack, stack
308 cell instance, first cell instance
310 cell instance
312 cell instance
314 Last cell instance
316 Subnetwork
320 network output
400 processes
Claims (15)
特定の機械学習タスクを実行するように構成されたタスクニューラルネットワークのためのアーキテクチャを決定するステップを含み、前記決定するステップが、
前記タスクニューラルネットワークに対する候補アーキテクチャの現在のセットを指定するデータを取得するステップと、
前記現在のセット内の各候補アーキテクチャに対して、
複数の性能予測パラメータを有する性能予測ニューラルネットワークを使用して、前記候補アーキテクチャを指定する前記データを処理するステップであって、前記性能予測ニューラルネットワークは、前記候補アーキテクチャを有するニューラルネットワークが前記特定の機械学習タスクに対してトレーニングされた後で、どの程度良好に機能することになるかを特徴付ける性能予測を生成するために、前記性能予測パラメータの現在の値に従って、前記候補アーキテクチャを指定する前記データを処理するように構成される、処理するステップと、
前記現在のセット内の前記候補アーキテクチャに対する前記性能予測に基づいて、前記現在のセット内の前記候補アーキテクチャのうちの1つまたは複数を選択することによって、候補アーキテクチャの更新されたセットを生成するステップと
を含む、方法。 A method performed by one or more computers
The determining steps include determining the architecture for a task neural network configured to perform a particular machine learning task.
The step of retrieving data that specifies the current set of candidate architectures for the task neural network, and
For each candidate architecture in the current set
A step of processing the data that specifies the candidate architecture using a performance prediction neural network having a plurality of performance prediction parameters, wherein the performance prediction neural network is such that the neural network having the candidate architecture is the specific. The data specifying the candidate architecture according to the current value of the performance prediction parameter to generate a performance prediction that characterizes how well it will work after being trained for a machine learning task. And the steps to process, which are configured to process
A step of generating an updated set of candidate architectures by selecting one or more of the candidate architectures in the current set based on the performance predictions for the candidate architecture in the current set. And including methods.
受信されたネットワーク入力に対して前記特定の機械学習タスクを実行するために、前記決定されたアーキテクチャを有する前記トレーニングされたタスクニューラルネットワークを使用するステップと
をさらに含む、請求項1から4のいずれか一項に記載の方法。 Steps to train a task neural network with the determined architecture,
Any of claims 1 to 4, further comprising the step of using the trained task neural network having the determined architecture to perform the particular machine learning task on the received network input. The method described in item 1.
前記候補アーキテクチャを有する前記タスクニューラルネットワークのインスタンスを生成し、
前記特定の機械学習タスクを実行するために前記インスタンスをトレーニングし、
前記トレーニングされたインスタンスの実際の性能を決定するために、前記特定の機械学習タスクに対して前記トレーニングされたインスタンスの性能を評価するステップと、
前記性能予測ニューラルネットワークの前記性能予測パラメータの前記現在の値を調整するために、前記トレーニングされたインスタンスに関する前記実際の性能を使用するステップと
をさらに含む、請求項1から5のいずれか一項に記載の方法。 For each candidate architecture in the updated set
An instance of the task neural network having the candidate architecture is generated.
Train the instance to perform the particular machine learning task and
To determine the actual performance of the trained instance, a step of evaluating the performance of the trained instance for the particular machine learning task, and
Any one of claims 1-5, further comprising the step of using the actual performance of the trained instance to adjust the current value of the performance prediction parameter of the performance prediction neural network. The method described in.
各新しい候補アーキテクチャに対して、1つまたは複数の動作のそれぞれのセットを前記候補アーキテクチャに追加することによって、前記候補アーキテクチャから複数の新しい候補アーキテクチャを生成するステップと、
各新しい候補アーキテクチャに対して、
前記新しい候補アーキテクチャに対する性能予測を生成するために、前記性能予測ニューラルネットワークを使用して、前記性能予測パラメータの前記更新された値に従って、前記新しい候補アーキテクチャを指定するデータを処理するステップと、
前記新しい候補アーキテクチャに対する前記性能予測に基づいて、前記新しい候補アーキテクチャのうちの1つまたは複数を選択することによって、候補アーキテクチャの新しいセットを生成するステップと
をさらに含む、請求項6に記載の方法。 For each candidate architecture in the updated set
For each new candidate architecture, a step of generating multiple new candidate architectures from the candidate architecture by adding each set of one or more behaviors to the candidate architecture.
For each new candidate architecture
To generate performance predictions for the new candidate architecture, the steps of using the performance prediction neural network to process data specifying the new candidate architecture according to the updated values of the performance prediction parameters.
The method of claim 6, further comprising generating a new set of candidate architectures by selecting one or more of the new candidate architectures based on the performance predictions for the new candidate architecture. ..
をさらに含む、請求項7に記載の方法。 7. The method of claim 7, further comprising selecting one of the new candidate architectures in the new set as the architecture for the task neural network.
前記新しいセット内の各新しい候補アーキテクチャに対して、
前記新しい候補アーキテクチャを有する前記タスクニューラルネットワークのインスタンスを生成し、
前記特定の機械学習タスクを実行するために前記インスタンスをトレーニングし、
前記トレーニングされたインスタンスの実際の性能を決定するために、前記特定の機械学習タスクに対して前記トレーニングされたインスタンスの性能を評価するステップと、
前記タスクニューラルネットワークのための前記アーキテクチャとして、最良の実際の性能を有する前記トレーニングされたインスタンスに対応する新しい候補アーキテクチャを選択するステップと
を含む、請求項8に記載の方法。 The step to select is
For each new candidate architecture in the new set
An instance of the task neural network with the new candidate architecture is generated.
Train the instance to perform the particular machine learning task and
To determine the actual performance of the trained instance, a step of evaluating the performance of the trained instance for the particular machine learning task, and
8. The method of claim 8, wherein the architecture for the task neural network includes the step of selecting a new candidate architecture corresponding to the trained instance with the best actual performance.
各新しい候補セルに対して、それぞれのハイパーパラメータを有する新しい動作ブロックを前記候補アーキテクチャに追加するステップ
を含む、請求項10に記載の方法。 Each candidate architecture defines an architecture for a convolution cell with a first number of motion blocks, and for each new candidate architecture, each set of one or more behaviors is added to the candidate architecture. The step of generating multiple new candidate architectures from the candidate architecture
10. The method of claim 10, comprising adding a new operating block with its hyperparameters to the candidate architecture for each new candidate cell.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762593213P | 2017-11-30 | 2017-11-30 | |
US62/593,213 | 2017-11-30 | ||
PCT/US2018/063293 WO2019108923A1 (en) | 2017-11-30 | 2018-11-30 | Neural architecture search using a performance prediction neural network |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2021504844A true JP2021504844A (en) | 2021-02-15 |
JP7157154B2 JP7157154B2 (en) | 2022-10-19 |
Family
ID=64734190
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2020529555A Active JP7157154B2 (en) | 2017-11-30 | 2018-11-30 | Neural Architecture Search Using Performance Prediction Neural Networks |
Country Status (5)
Country | Link |
---|---|
US (2) | US11087201B2 (en) |
EP (1) | EP3718057A1 (en) |
JP (1) | JP7157154B2 (en) |
CN (1) | CN111406267A (en) |
WO (1) | WO2019108923A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP7376717B2 (en) | 2021-03-26 | 2023-11-08 | グーグル エルエルシー | Boosting and matrix factorization |
Families Citing this family (36)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2016061576A1 (en) | 2014-10-17 | 2016-04-21 | Zestfinance, Inc. | Api for implementing scoring functions |
US11941650B2 (en) | 2017-08-02 | 2024-03-26 | Zestfinance, Inc. | Explainable machine learning financial credit approval model for protected classes of borrowers |
US11960981B2 (en) | 2018-03-09 | 2024-04-16 | Zestfinance, Inc. | Systems and methods for providing machine learning model evaluation by using decomposition |
US11847574B2 (en) | 2018-05-04 | 2023-12-19 | Zestfinance, Inc. | Systems and methods for enriching modeling tools and infrastructure with semantics |
WO2020051776A1 (en) * | 2018-09-11 | 2020-03-19 | Intel Corporation | Method and system of deep supervision object detection for reducing resource usage |
US11816541B2 (en) | 2019-02-15 | 2023-11-14 | Zestfinance, Inc. | Systems and methods for decomposition of differentiable and non-differentiable models |
EP3871088A1 (en) * | 2019-02-26 | 2021-09-01 | Google LLC | Reinforcement learning techniques for selecting a software policy network and autonomously controlling a corresponding software client based on selected policy network |
JP7276757B2 (en) * | 2019-03-18 | 2023-05-18 | ゼストファイナンス，インコーポレーテッド | Systems and methods for model fairness |
US20210019599A1 (en) * | 2019-07-19 | 2021-01-21 | Google Llc | Adaptive neural architecture search |
KR20210045845A (en) * | 2019-10-17 | 2021-04-27 | 삼성전자주식회사 | Electronic device and operating method for the same |
CN111123232B (en) * | 2019-11-11 | 2022-03-18 | 浙江大学 | Radar individual identification system with task adaptability |
US11620487B2 (en) * | 2019-12-31 | 2023-04-04 | X Development Llc | Neural architecture search based on synaptic connectivity graphs |
US11568201B2 (en) | 2019-12-31 | 2023-01-31 | X Development Llc | Predicting neuron types based on synaptic connectivity graphs |
US11593617B2 (en) | 2019-12-31 | 2023-02-28 | X Development Llc | Reservoir computing neural networks based on synaptic connectivity graphs |
US11593627B2 (en) | 2019-12-31 | 2023-02-28 | X Development Llc | Artificial neural network architectures based on synaptic connectivity graphs |
US11625611B2 (en) | 2019-12-31 | 2023-04-11 | X Development Llc | Training artificial neural networks based on synaptic connectivity graphs |
US11631000B2 (en) | 2019-12-31 | 2023-04-18 | X Development Llc | Training artificial neural networks based on synaptic connectivity graphs |
CN111340221B (en) * | 2020-02-25 | 2023-09-12 | 北京百度网讯科技有限公司 | Neural network structure sampling method and device |
US11394799B2 (en) | 2020-05-07 | 2022-07-19 | Freeman Augustus Jackson | Methods, systems, apparatuses, and devices for facilitating for generation of an interactive story based on non-interactive data |
US11544561B2 (en) * | 2020-05-15 | 2023-01-03 | Microsoft Technology Licensing, Llc | Task-aware recommendation of hyperparameter configurations |
CN111797983A (en) * | 2020-05-25 | 2020-10-20 | 华为技术有限公司 | Neural network construction method and device |
CN111882042B (en) * | 2020-08-03 | 2024-04-05 | 中国人民解放军国防科技大学 | Neural network architecture automatic search method, system and medium for liquid state machine |
KR20220032861A (en) * | 2020-09-08 | 2022-03-15 | 삼성전자주식회사 | Neural architecture search method and attaratus considering performance in hardware |
CN116368493A (en) * | 2020-10-15 | 2023-06-30 | 罗伯特·博世有限公司 | Method and apparatus for weight sharing neural network with random architecture |
KR102535007B1 (en) * | 2020-11-13 | 2023-05-19 | 숭실대학교 산학협력단 | Neuromorphic architecture dynamic selection method for snn model parameter-based modeling, recording medium and device for performing the method |
US11720962B2 (en) | 2020-11-24 | 2023-08-08 | Zestfinance, Inc. | Systems and methods for generating gradient-boosted models with improved fairness |
CN112685623A (en) * | 2020-12-30 | 2021-04-20 | 京东数字科技控股股份有限公司 | Data processing method and device, electronic equipment and storage medium |
CN112819138A (en) * | 2021-01-26 | 2021-05-18 | 上海依图网络科技有限公司 | Optimization method and device of image neural network structure |
CN113033784A (en) * | 2021-04-18 | 2021-06-25 | 沈阳雅译网络技术有限公司 | Method for searching neural network structure for CPU and GPU equipment |
CN112949662B (en) * | 2021-05-13 | 2021-11-16 | 北京市商汤科技开发有限公司 | Image processing method and device, computer equipment and storage medium |
CN113255770B (en) * | 2021-05-26 | 2023-10-27 | 北京百度网讯科技有限公司 | Training method of compound attribute prediction model and compound attribute prediction method |
CN113705628B (en) * | 2021-08-06 | 2024-02-06 | 北京百度网讯科技有限公司 | Determination method and device of pre-training model, electronic equipment and storage medium |
CN116151319A (en) * | 2021-11-22 | 2023-05-23 | 华为技术有限公司 | Method and device for searching neural network integration model and electronic equipment |
US20230252292A1 (en) * | 2022-02-10 | 2023-08-10 | Nota, Inc. | Method of providing information on neural network model and electronic apparatus for performing the same |
KR102500341B1 (en) | 2022-02-10 | 2023-02-16 | 주식회사 노타 | Method for providing information about neural network model and electronic apparatus for performing the same |
KR20230135781A (en) * | 2022-03-17 | 2023-09-26 | 서울대학교산학협력단 | Method and apparatus for predicting performance of artificial neural network accorindg to data format |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2004192584A (en) * | 2002-12-13 | 2004-07-08 | Adoin Kenkyusho:Kk | Network type information processing system using genetic algorithm, learning device and learning method for the same, and recording medium with program of learning method recorded |
JP2018195314A (en) * | 2017-05-19 | 2018-12-06 | セールスフォース ドット コム インコーポレイティッド | Domain specific language for generation of recurrent neural network architectures |
Family Cites Families (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5904227A (en) | 1997-12-30 | 1999-05-18 | Otis Elevator Company | Method for continuously adjusting the architecture of a neural network used in elevator dispatching |
WO2002061679A2 (en) * | 2001-01-31 | 2002-08-08 | Prediction Dynamics Limited | Neural network training |
US9524450B2 (en) * | 2015-03-04 | 2016-12-20 | Accenture Global Services Limited | Digital image processing using convolutional neural networks |
US9336483B1 (en) * | 2015-04-03 | 2016-05-10 | Pearson Education, Inc. | Dynamically updated neural network structures for content distribution networks |
US10628733B2 (en) * | 2015-04-06 | 2020-04-21 | Deepmind Technologies Limited | Selecting reinforcement learning actions using goals and observations |
EP3360082B1 (en) * | 2015-11-12 | 2021-06-02 | Deepmind Technologies Limited | Neural programming |
US11263514B2 (en) * | 2016-01-13 | 2022-03-01 | Google Llc | Processing and generating sets using recurrent neural networks |
US11443169B2 (en) * | 2016-02-19 | 2022-09-13 | International Business Machines Corporation | Adaptation of model for recognition processing |
US10402740B2 (en) * | 2016-07-29 | 2019-09-03 | Sap Se | Natural interactive user interface using artificial intelligence and freeform input |
US20190138901A1 (en) * | 2017-11-06 | 2019-05-09 | The Royal Institution For The Advancement Of Learning/Mcgill University | Techniques for designing artificial neural networks |
-
2018
- 2018-11-30 JP JP2020529555A patent/JP7157154B2/en active Active
- 2018-11-30 CN CN201880076005.9A patent/CN111406267A/en active Pending
- 2018-11-30 EP EP18821860.6A patent/EP3718057A1/en active Pending
- 2018-11-30 WO PCT/US2018/063293 patent/WO2019108923A1/en unknown
-
2020
- 2020-04-29 US US16/861,491 patent/US11087201B2/en active Active
-
2021
- 2021-07-01 US US17/365,939 patent/US20210334624A1/en active Pending
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2004192584A (en) * | 2002-12-13 | 2004-07-08 | Adoin Kenkyusho:Kk | Network type information processing system using genetic algorithm, learning device and learning method for the same, and recording medium with program of learning method recorded |
JP2018195314A (en) * | 2017-05-19 | 2018-12-06 | セールスフォース ドット コム インコーポレイティッド | Domain specific language for generation of recurrent neural network architectures |
Non-Patent Citations (1)
Title |
---|
BROCK, ANDREW ほか: "SMASH: One-Shot Model Architecture Search through HyperNetworks", ARXIV[ONLINE], JPN6021023430, 17 August 2017 (2017-08-17), pages 1 - 21, ISSN: 0004705007 * |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP7376717B2 (en) | 2021-03-26 | 2023-11-08 | グーグル エルエルシー | Boosting and matrix factorization |
Also Published As
Publication number | Publication date |
---|---|
EP3718057A1 (en) | 2020-10-07 |
US20200257961A1 (en) | 2020-08-13 |
US11087201B2 (en) | 2021-08-10 |
US20210334624A1 (en) | 2021-10-28 |
JP7157154B2 (en) | 2022-10-19 |
WO2019108923A1 (en) | 2019-06-06 |
CN111406267A (en) | 2020-07-10 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP2021504844A (en) | Neural architecture search using performance prediction neural network | |
JP6889270B2 (en) | Neural network architecture optimization | |
EP3711000B1 (en) | Regularized neural network architecture search | |
US10748065B2 (en) | Multi-task neural networks with task-specific paths | |
JP6790286B2 (en) | Device placement optimization using reinforcement learning | |
JP6828121B2 (en) | Training neural networks with prioritized empirical memory | |
JP6963627B2 (en) | Neural architecture search for convolutional neural networks | |
US11544536B2 (en) | Hybrid neural architecture search | |
EP3446260B1 (en) | Memory-efficient backpropagation through time | |
JP7043596B2 (en) | Neural architecture search | |
JP2022511491A (en) | Generation of integrated circuit floor plans using neural networks | |
JP2022523666A (en) | Composite model scaling for neural networks | |
CN114072809A (en) | Small and fast video processing network via neural architectural search | |
US11893480B1 (en) | Reinforcement learning with scheduled auxiliary control | |
US20240152809A1 (en) | Efficient machine learning model architecture selection |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20200529 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20210608 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20210621 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210921 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20220214 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20220510 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20220912 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20221006 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7157154Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |