JP2023513652A - Direct memory access architecture with multi-level multi-stride - Google Patents
Direct memory access architecture with multi-level multi-stride Download PDFInfo
- Publication number
- JP2023513652A JP2023513652A JP2022522723A JP2022522723A JP2023513652A JP 2023513652 A JP2023513652 A JP 2023513652A JP 2022522723 A JP2022522723 A JP 2022522723A JP 2022522723 A JP2022522723 A JP 2022522723A JP 2023513652 A JP2023513652 A JP 2023513652A
- Authority
- JP
- Japan
- Prior art keywords
- memory
- memory address
- tensor
- request
- dimension
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 230000015654 memory Effects 0.000 title claims abstract description 388
- 230000004044 response Effects 0.000 claims description 106
- 238000004364 calculation method Methods 0.000 claims description 47
- 238000000034 method Methods 0.000 claims description 25
- 230000008707 rearrangement Effects 0.000 claims 1
- 239000013598 vector Substances 0.000 description 38
- 238000010586 diagram Methods 0.000 description 14
- 230000008569 process Effects 0.000 description 13
- 230000006870 function Effects 0.000 description 8
- 238000000926 separation method Methods 0.000 description 2
- 235000008694 Humulus lupulus Nutrition 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000010801 machine learning Methods 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 238000002360 preparation method Methods 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
- 230000001360 synchronised effect Effects 0.000 description 1
- 230000008685 targeting Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F12/00—Accessing, addressing or allocating within memory systems or architectures
- G06F12/02—Addressing or allocation; Relocation
- G06F12/08—Addressing or allocation; Relocation in hierarchically structured memory systems, e.g. virtual memory systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F13/00—Interconnection of, or transfer of information or other signals between, memories, input/output devices or central processing units
- G06F13/14—Handling requests for interconnection or transfer
- G06F13/20—Handling requests for interconnection or transfer for access to input/output bus
- G06F13/28—Handling requests for interconnection or transfer for access to input/output bus using burst mode transfer, e.g. direct memory access DMA, cycle steal
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F1/00—Details not covered by groups G06F3/00 - G06F13/00 and G06F21/00
- G06F1/04—Generating or distributing clock signals or signals derived directly therefrom
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F12/00—Accessing, addressing or allocating within memory systems or architectures
- G06F12/02—Addressing or allocation; Relocation
- G06F12/08—Addressing or allocation; Relocation in hierarchically structured memory systems, e.g. virtual memory systems
- G06F12/10—Address translation
- G06F12/1081—Address translation for peripheral access to main memory, e.g. direct memory access [DMA]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/34—Addressing or accessing the instruction operand or the result ; Formation of operand address; Addressing modes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/38—Concurrent instruction execution, e.g. pipeline, look ahead
- G06F9/3885—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units
Abstract
マルチレベルマルチストライドを実行することと、複数のメモリアドレスを並列して決定することとが可能なＤＭＡアーキテクチャについて説明する。１つの態様では、ＤＭＡシステムは、１つ以上のハードウェアＤＭＡスレッドを備える。各ＤＭＡスレッドは、並列メモリアドレス計算周期のたびに多次元テンソルのためにＭ個のメモリアドレスを並列して生成し、メモリアドレスごとにメモリ操作を行うようメモリシステムに求める要求を生成するように構成された要求生成部を含む。要求生成部は、Ｍ個のメモリアドレス部を含み、各メモリアドレス部は、テンソルの次元ごとに次元のステップインデックス値を生成し、ステップインデックス値に基づいて次元のストライドオフセット値を生成するように構成されるステップ追跡部を含む。各メモリアドレス部は、テンソル要素のメモリアドレスを生成し、メモリ操作を行うよう求める要求を送るように構成されるメモリアドレス計算要素を含む。A DMA architecture capable of performing multi-level multi-stride and determining multiple memory addresses in parallel is described. In one aspect, a DMA system comprises one or more hardware DMA threads. Each DMA thread generates M memory addresses in parallel for the multi-dimensional tensor for each parallel memory address computation cycle, and generates a request to the memory system to perform a memory operation for each memory address. Contains a configured request generator. The request generator includes M memory address units, each memory address unit generating a dimensional step index value for each dimension of the tensor and a dimensional stride offset value based on the step index value. Includes a configured step tracker. Each memory address unit includes a memory address computation element configured to generate memory addresses for tensor elements and to send requests to perform memory operations.
Description
背景
ＤＭＡ（ダイレクトメモリアクセス）とは、デバイスやサブシステムが、処理装置とは独立してメモリにアクセスすることを可能にする機能である。これにより、処理装置は、データ転送に関わることから解放され、処理装置は、その他の操作を実行できるよう、利用可能になる。ＤＭＡを利用して、大容量のメモリ転送操作およびスキャッター／ギャザー操作など、処理装置が抱えるコストの高いメモリ操作の負担を軽減させることができる。
Background DMA (direct memory access) is a feature that allows a device or subsystem to access memory independently of the processing unit. This frees the processing device from being involved in the data transfer and makes the processing device available to perform other operations. DMA can be used to offload costly memory operations from a processing unit, such as large memory transfer operations and scatter/gather operations.
概要
本明細書は、たとえば１つのクロック周期の間に、マルチレベルマルチストライドを行うことと、複数のメモリアドレスを並列して決定することとが可能なＤＭＡアーキテクチャに関する技術について説明する。
Overview This specification describes techniques for a DMA architecture capable of performing multi-level multi-stride and determining multiple memory addresses in parallel, eg, during a single clock cycle.
概して、本明細書において説明する主題の１つの革新的な態様は、１つ以上のハードウェアＤＭＡスレッドを備えるＤＭＡ（ダイレクトメモリアクセス）システムに含めることができる。各ＤＭＡスレッドは、並列メモリアドレス計算周期のたびに（１）多次元テンソルのためにＭ個のメモリアドレスを並列して生成し、メモリアドレスごとに（２）多次元テンソルに関するメモリ操作を行うようメモリシステムに求める要求を生成するように構成された要求生成部を含み、要求生成部は、Ｍ個のメモリアドレス部を含む。各メモリアドレス部は、多次元テンソルの次元ごとに（１）次元のステップインデックス値を生成し、ステップインデックス値に基づいて（２）次元のストライドオフセット値を生成するように構成されるステップ追跡部と、メモリアドレス計算要素とを含み、メモリアドレス計算要素は、並列メモリアドレス計算周期のたびに、ストライドオフセット値に基づいて、多次元テンソルのテンソル要素のメモリアドレスを生成し、メモリアドレスを用いてメモリ操作を行うよう求める要求を、メモリシステムに送るように構成され、Ｍは、１以上である。この態様のその他の実施態様は、対応する装置および方法を含む。 In general, one innovative aspect of the subject matter described herein can be included in a DMA (direct memory access) system with one or more hardware DMA threads. Each DMA thread (1) generates M memory addresses in parallel for a multi-dimensional tensor for each parallel memory address calculation cycle, and (2) performs memory operations on the multi-dimensional tensor for each memory address. A request generator configured to generate a request to the memory system, the request generator including M memory address portions. Each memory address unit is configured to generate a (1)-dimensional step index value for each dimension of the multi-dimensional tensor and to generate a (2)-dimensional stride offset value based on the step index value. and a memory address calculation element, wherein the memory address calculation element generates memory addresses for tensor elements of the multi-dimensional tensor based on the stride offset value for each parallel memory address calculation cycle, and uses the memory addresses to It is configured to send a request to perform a memory operation to the memory system, where M is 1 or greater. Other implementations of this aspect include corresponding apparatus and methods.
これらのおよびその他の実施態様は、各々、任意で下記の特徴のうち１つ以上を含み得る。いくつかの態様では、要求生成部は、１つのクロック周期の間にメモリアドレスを並列して生成するように構成され、各並列メモリ計算は、１つのクロック周期の間に行われる。クロック周期のたびに、各メモリアドレス部のメモリアドレス計算要素は、他のメモリアドレス部のメモリアドレス計算要素と同じまたは異なるテンソル要素のメモリアドレスを生成する。 These and other implementations can each optionally include one or more of the following features. In some aspects, the request generator is configured to generate memory addresses in parallel during one clock cycle, each parallel memory computation occurring during one clock cycle. On each clock cycle, the memory address calculation elements of each memory address portion generate memory addresses for tensor elements that are the same or different than the memory address calculation elements of other memory address portions.
いくつかの態様では、要求生成部は、多次元テンソルの記述子を受け取るように構成され、記述子は、次元ごとに、次元のストライド値のステップ数を規定する。要求生成部は、Ｍ個のレーンを含み得、Ｍ個のレーンは、各々、ステップ追跡部と、メモリアドレス計算要素とを含む。各レーンのステップ追跡部およびメモリアドレス計算要素は、対応するメモリアドレスを他のレーンと並列して計算する。ステップ追跡部は、ループネストに基づいて多次元テンソルのメモリアドレスを生成するように構成され得、ループネストは、多次元テンソルの次元ごとに、多次元テンソルの次元を横断するためのループを含む。各次元のストライド値当たりのステップ数は、次元のループのループ範囲を表し、各次元のステップインデックス値は、次元のループのループインデックスを表す。 In some aspects, the request generator is configured to receive a descriptor of a multi-dimensional tensor, the descriptor defining, for each dimension, the number of stride value steps for the dimension. The request generator may include M lanes, each including a step tracker and a memory address calculation element. Each lane's step tracker and memory address calculation element calculates the corresponding memory address in parallel with the other lanes. The step tracker may be configured to generate a memory address of the multi-dimensional tensor based on a loop nest, the loop nest including a loop for traversing the dimensions of the multi-dimensional tensor for each dimension of the multi-dimensional tensor. . The number of steps per stride value for each dimension represents the loop extent of the dimension's loop, and the step index value for each dimension represents the loop index for the dimension's loop.
いくつかの態様では、各ステップ追跡部は、クロック周期のたびに次元の各々のステップインデックス値を更新するように構成される。ステップ追跡部ごとのステップインデックス値の組合せは、他のステップ追跡部のステップインデックス値の組合せとは異なり得る。各ステップ追跡部は、複数のステップインクリメント部を含むステップインクリメントチェーンを含み得、複数のステップインクリメント部は、各々、次元の次元メモリアドレスオフセット値を決定するように構成される。ループネストの最も内側のループに対応するステップインクリメントチェーンの第１ステップインクリメント部は、予告量を受け取るように構成され得る。クロック周期のたびに次元のうち１つ以上の次元のステップインデックス値を更新することは、第１ステップインクリメント部が予告量に基づいて１つ以上の次元のステップインデックス値を更新することを含み得る。 In some aspects, each step tracker is configured to update the step index value for each of the dimensions every clock cycle. The combination of step index values for each step tracker may differ from the combination of step index values for other step trackers. Each step tracker may include a step increment chain including a plurality of step increments, each of the plurality of step increments configured to determine a dimensional memory address offset value for the dimension. A first step increment portion of the step increment chain corresponding to the innermost loop of the loop nest may be configured to receive a preview amount. Updating step index values for one or more of the dimensions at each clock cycle may include the first step increment unit updating step index values for one or more dimensions based on the advance notice amount. .
いくつかの態様では、最も内側のループが入れ子になっているループに対応するステップインクリメントチェーンの１つ以上の第２ステップインクリメント部は、ステップインクリメントチェーンにある前のステップ追跡部からラップ量を受け取るように構成される。クロック周期のたびに次元のうち１つ以上の次元のステップインデックス値を更新することは、第２ステップインクリメント部がラップ量に基づいて１つ以上の次元のステップインデックス値を更新することを含み得る。 In some aspects, one or more second step increments of the step increment chain corresponding to the loop in which the innermost loop is nested receives the wrap amount from the previous step tracker in the step increment chain. configured as Updating step index values in one or more of the dimensions each clock cycle may include the second step increment unit updating step index values in one or more dimensions based on the wrap amount. .
いくつかの態様は、応答並替え部と同期部とを含む進行状況追跡部を備え得る。応答並替え部は、テンソル要素のメモリ操作が行われたかどうかのステータスをテンソルごとに保持するように構成され得る。同期部は、複数の一部の最新情報をプロセッサコアに提供するように構成され得、複数の一部の最新情報は、各々、多次元テンソルのテンソル要素に対して行われたメモリ操作の全体的なステータスを明記する。 Some aspects may comprise a progress tracker that includes a response reorderer and a synchronizer. The response reorderer may be configured to maintain, for each tensor, a status of whether memory operations on tensor elements have been performed. The synchronizer may be configured to provide a plurality of partial updates to the processor core, each of the plurality of partial updates representing the totality of memory operations performed on tensor elements of the multi-dimensional tensor. status.
いくつかの態様では、各要求は、一意の識別子を含む。応答並替え部は、メモリシステムから応答を任意の順番に受け取るように構成され得る。各応答は、応答が提供される要求の一意の識別子を含み得る。応答並替え部は、少なくともしきい値数の連続した一意の識別子を応答で受け取った場合、一連の一意の識別子を、要求生成部が再利用できるよう、解放するように構成され得る。 In some aspects, each request includes a unique identifier. The response reorderer may be configured to receive responses from the memory system in any order. Each response may contain a unique identifier for the request for which the response is provided. The response reorderer may be configured to release the sequence of unique identifiers for reuse by the request generator if at least a threshold number of consecutive unique identifiers are received in the response.
概して、本明細書において説明する主題の別の革新的な態様は、１つ以上のプロセッサコアと、メモリシステムと、１つ以上のＤＭＡスレッドを含むＤＭＡエンジンとを備えるシステムに含めることができる。各ＤＭＡスレッドは、並列メモリアドレス計算周期のたびに（１）多次元テンソルのためにＭ個のメモリアドレスを並列して生成し、メモリアドレスごとに（２）多次元テンソルに関するメモリ操作を行うようメモリシステムに求める要求を生成するように構成された要求生成部を含み得、要求生成部は、Ｍ個のメモリアドレス部を含み、Ｍは、１以上である。各メモリアドレス部は、多次元テンソルの次元ごとに（１）次元のステップインデックス値を生成し、ステップインデックス値に基づいて（２）次元のストライドオフセット値を生成するように構成されるステップ追跡部と、メモリアドレス計算要素とを含み得、メモリアドレス計算要素は、並列メモリアドレス計算周期のたびに、ストライドオフセット値に基づいて、多次元テンソルのテンソル要素のメモリアドレスを生成し、メモリアドレスを用いてメモリ操作を行うよう求める要求を、メモリシステムに送るように構成される。各ＤＭＡスレッドは、応答並替え部と、同期更新部とを含む進行状況追跡部を備え得、同期更新部は、ＤＭＡエンジンが管理するメモリ操作についての同期に関する一部の最新情報を１つ以上のプロセッサコアに提供するように構成される。この態様のその他の実施態様は、対応する装置および方法を含む。 In general, another innovative aspect of the subject matter described herein can be included in a system with one or more processor cores, a memory system, and a DMA engine including one or more DMA threads. Each DMA thread (1) generates M memory addresses in parallel for a multi-dimensional tensor for each parallel memory address calculation cycle, and (2) performs memory operations on the multi-dimensional tensor for each memory address. A request generator configured to generate a request to the memory system may be included, the request generator including M memory address units, where M is one or more. Each memory address unit is configured to generate a (1)-dimensional step index value for each dimension of the multi-dimensional tensor and to generate a (2)-dimensional stride offset value based on the step index value. and a memory address calculation element, the memory address calculation element generating memory addresses for tensor elements of the multi-dimensional tensor based on the stride offset values for each parallel memory address calculation cycle, and using the memory addresses is configured to send a request to the memory system to perform a memory operation on the memory system. Each DMA thread may have a progress tracker that includes a response reorderer and a synchronization updater that updates one or more pieces of synchronization for memory operations managed by the DMA engine. of processor cores. Other implementations of this aspect include corresponding apparatus and methods.
これらのおよびその他の実施態様は、各々、任意で下記の特徴のうち１つ以上を含み得る。いくつかの態様では、要求生成部は、１つのクロック周期の間にメモリアドレスを並列して生成するように構成され、各並列メモリ計算は、１つのクロック周期の間に行われる。 These and other implementations can each optionally include one or more of the following features. In some aspects, the request generator is configured to generate memory addresses in parallel during one clock cycle, each parallel memory computation occurring during one clock cycle.
クロック周期のたびに、各メモリアドレス部のメモリアドレス計算要素は、他のメモリアドレス部のメモリアドレス計算要素と同じまたは異なるテンソル要素のメモリアドレスを生成し得る。要求生成部は、多次元テンソルの記述子を受け取るように構成され得、記述子は、次元ごとに、次元のストライド値のステップ数を規定する。要求生成部は、Ｍ個のレーンを含み得、Ｍ個のレーンは、各々、ステップ追跡部と、メモリアドレス計算要素とを含み、各レーンのステップ追跡部およびメモリアドレス計算要素は、対応するメモリアドレスを他のレーンと並列して計算する。 On each clock cycle, the memory address calculation elements of each memory address section may generate memory addresses for tensor elements that are the same or different than memory address calculation elements of other memory address sections. The request generator may be configured to receive a descriptor of the multidimensional tensor, the descriptor defining, for each dimension, the number of stride value steps for the dimension. The request generator may include M lanes, each including a step tracker and a memory address computation element, each lane's step tracker and memory address computation element being associated with a corresponding memory Addresses are calculated in parallel with other lanes.
概して、本明細書において説明する主題の別の革新的な態様は、ＤＭＡシステムによって実行される方法に含めることができる。この方法は、要求生成部が、並列メモリアドレス計算周期のたびに（１）多次元テンソルのためにＭ個のメモリアドレスを並列して生成し、メモリアドレスごとに（２）多次元テンソルに関するメモリ操作を行うようメモリシステムに求める要求を生成するステップを含み、要求生成部は、Ｍ個のメモリアドレス部を含み、Ｍは、１以上であり、各メモリアドレス部は、ステップ追跡部と、メモリアドレス計算部とを含み、方法は、さらに、ステップ追跡部が、多次元テンソルの次元ごとに（１）次元のステップインデックス値を生成し、ステップインデックス値に基づいて（２）次元のストライドオフセット値を生成するステップと、各メモリアドレス部のメモリアドレス計算要素が、並列メモリアドレス計算周期のたびに、ストライドオフセット値に基づいて、多次元テンソルのテンソル要素のメモリアドレスを生成するステップと、メモリアドレスを用いてメモリ操作を行うよう求める要求を、メモリシステムに送るステップとを含む。 In general, another innovative aspect of the subject matter described herein can be included in a method performed by a DMA system. In this method, the request generation unit (1) generates M memory addresses in parallel for the multidimensional tensor for each parallel memory address calculation cycle, and (2) memory addresses for the multidimensional tensor for each memory address. generating a request to the memory system to perform the operation, the request generator comprising M memory address units, M being 1 or greater, each memory address unit comprising: a step tracker; an address calculator, the method further comprising: the step tracker generating (1)-dimensional step index values for each dimension of the multi-dimensional tensor; and (2)-dimensional stride offset values based on the step index values. a memory address calculation element of each memory address portion generating a memory address for a tensor element of the multi-dimensional tensor based on the stride offset value for each parallel memory address calculation period; sending a request to the memory system to perform a memory operation using .
本明細書において説明する主題は、以下の利点のうち１つ以上を実現するように特定の実施の形態で実現され得る。本明細書において説明するＤＭＡアーキテクチャにより、たとえばクロック周期当たり、多次元テンソルのメモリアドレスを並列して複数（Ｍ個）生成することが可能になる。これにより、メモリアドレスをより高速に生成でき、メモリ処理能力が向上する。ＤＭＡアーキテクチャは、複数のレーンを含み得、各レーンは、ステップ追跡部を含み、ステップ追跡部は、マルチストライド技術を実行して、多次元テンソルのループネストに基づいて複数のテンソル要素の複数のメモリアドレスを並列して計算する。ＤＭＡアーキテクチャの要求生成部が用いるこの技術により、複数のステップ追跡部が、テンソルの複数の次元にそれぞれ異なるステップインデックス値を用いて、並列して動作し、互いに独立して、クロック周期の間にそれぞれ異なるテンソル要素のアドレスを並列して生成することが可能になる。各ステップ追跡部は、次のテンソル要素のメモリアドレスを決定することに備えて、クロック周期のたびにそのステップインデックス値を更新し得る。 The subject matter described herein can be implemented in particular embodiments to achieve one or more of the following advantages. The DMA architecture described herein allows parallel generation of multiple (M) memory addresses of a multi-dimensional tensor, eg, per clock cycle. This allows memory addresses to be generated faster and improves memory throughput. The DMA architecture may include multiple lanes, each lane including a step tracker that performs a multi-stride technique to generate multiple lanes of multiple tensor elements based on loop nests of the multi-dimensional tensor. Compute memory addresses in parallel. This technique, used by the request generator of the DMA architecture, allows multiple step trackers to operate in parallel, each with different step index values for the multiple dimensions of the tensor, independently of each other, during the clock period. It becomes possible to generate addresses of different tensor elements in parallel. Each step tracker may update its step index value every clock cycle in preparation for determining the memory address of the next tensor element.
また、ＤＭＡアーキテクチャは、同期に関する一部の最新情報をプロセッサコアに提供する進行状況追跡部を備え得、プロセッサコアは、メモリの決定したメモリアドレスに格納されたデータを消費する。これにより、ＤＭＡのメモリトランザクションのすべてが完了する前にプロセッサコアがデータの消費を開始することが可能になり、メモリ転送によってプロセッサコアにかかっていた待ち時間が減り、処理装置の計算の全体的な効率が向上する。進行状況追跡部は、応答並替え部を含み得、応答並替え部は、メモリから一度に複数の応答を任意の順番で受け取ることができ、メモリは、生成された要求に対して、順不同で対処および応答できる。応答並替え部のサイズが限られているので、少なくともしきい値数の要求に対する応答が受け付けられた場合、応答並替え部は、要求の識別子を解放できる。これにより、要求生成部は、最大数の要求のすべてに対する応答を待たずに、解放された識別子を利用してメモリ要求の発行を継続することが可能なり、メモリ転送の速度および効率が向上する。 The DMA architecture may also include a progress tracker that provides some up-to-date information regarding synchronization to the processor core, which consumes data stored in memory at determined memory addresses. This allows the processor cores to start consuming data before all of the DMA memory transactions are complete, reducing the latency that memory transfers incur on the processor cores and reducing the overall computational burden of the processing unit. efficiency. The progress tracker may include a response reorderer, which may receive multiple responses at once from the memory in any order, and the memory may respond to the generated requests out of order. Able to react and respond. Since the size of the response reorderer is limited, the response reorderer can free the request identifiers if at least a threshold number of responses to the request have been received. This allows the request generator to continue issuing memory requests using freed identifiers without waiting for responses to all of the maximum number of requests, improving the speed and efficiency of memory transfers. .
上述した主題様々な特徴および利点について、図面を参照にしながら以下に説明する。その他の特徴および利点は、本明細書で説明する主題、および添付の特許請求の範囲から明らかである。 Various features and advantages of the subject matter described above are described below with reference to the drawings. Other features and advantages are apparent from the subject matter described herein and from the claims that follow.
様々な図面における同じ参照番号および名称は、同じ要素を示す。
詳細な説明
概して、本明細書は、たとえば１つのクロック周期の間に、マルチレベルマルチストライドを行うことと、複数のメモリアドレスを並列して決定することとが可能なＤＭＡアーキテクチャについて説明する。チップは、チップのプロセッサコア（複数可）からのメモリ転送操作の負荷を軽減させる１つ以上のＤＭＡエンジンを含み得る。各ＤＭＡエンジンは、１つ以上のＤＭＡスレッドを含み得る。各ＤＭＡスレッドは、コア（複数可）に代わってＤＭＡトランザクションの実行を管理するハードウェアユニットである。クロック周期は、ＤＭＡエンジンまたはコアによる１つの操作の実行に必要な時間であり得る。
The same reference numbers and names in the various drawings identify the same elements.
DETAILED DESCRIPTION In general, this specification describes a DMA architecture capable of performing multi-level multi-stride and determining multiple memory addresses in parallel, eg, during one clock cycle. A chip may include one or more DMA engines that offload memory transfer operations from the chip's processor core(s). Each DMA engine may contain one or more DMA threads. Each DMA thread is a hardware unit that manages the execution of DMA transactions on behalf of core(s). A clock period may be the time required to perform one operation by a DMA engine or core.
図１～図６に示し、以下で説明する例示的なＤＭＡアーキテクチャは、クロック周期当たり、最大で４つのテンソル次元ならびに最大で４つの読出し元メモリアドレスおよび最大で４つの宛先メモリアドレスをサポートできる設計を提供する。しかしながら、ＤＭＡアーキテクチャは、厳密にぴったりと周期当たり４つの次元または４つのアドレスに当てはまらない。周期当たりその他の数の次元およびその他の数のアドレスにも、同様のアーキテクチャが使用できる。これに加えて、周期当たりのアドレスの数は、アドレスが決定されるテンソルの次元の数とは異なり得る。たとえば、ＤＭＡスレッドは、周期当たり５つのアドレスを生成するために５つのレーンを含み得るが、ハードウェアは、最大で４つの次元、最大で１０個の次元、または別の最大数の次元を有するテンソルのアドレスを計算するように構成される。すなわち、アーキテクチャは、パラメータ化可能であり、設計のための面積／周波数の目標によって設定の選択が異なる。 The exemplary DMA architecture shown in FIGS. 1-6 and described below is designed to support up to four tensor dimensions and up to four source memory addresses and four destination memory addresses per clock cycle. I will provide a. However, the DMA architecture does not fit exactly four dimensions or four addresses per cycle. A similar architecture can be used for other numbers of dimensions and other numbers of addresses per cycle. Additionally, the number of addresses per period may differ from the number of dimensions of the tensor over which the addresses are determined. For example, a DMA thread may include 5 lanes to generate 5 addresses per cycle, but the hardware may have up to 4 dimensions, up to 10 dimensions, or another maximum number of dimensions. Configured to compute the address of a tensor. That is, the architecture is parameterizable, with different setting choices depending on the area/frequency goals for the design.
図１は、ＤＭＡスレッド１２０がメモリ操作を生成してその進行状況を追跡する例示的な環境１００の図である。ＤＭＡスレッド１２０は、プロセッサコアに代わって要求されるトランザクションの一部としてメモリ操作を生成して、その進行状況を追跡し得る。ＤＭＡスレッド１２０は、ハードウェアユニットである。このハードウェアユニットは、ＤＭＡスレッド１２０と、１つ以上の他のＤＭＡスレッド（必須ではない）とを備えるＤＭＡエンジンの一部であり得る。ＤＭＡスレッド１２０は、スキャッター／ギャザー操作およびその他のメモリ転送操作など、コア１１０を含む１つ以上のプロセッサコアのＤＭＡトランザクションを管理し得る。たとえば、ＤＭＡスレッド１２０は、コア１１０とＤＭＡスレッド１２０とを備えるチップ上のメモリシステムの、異なるメモリ間での多次元テンソルの転送を指揮し得る。ＤＭＡスレッド１２０は、メモリシステムに要求（コマンド）を送ることによりデータの移動を指揮し、トランザクションを要求したコアに進行状況を同期できるよう、これらの要求の完了を追跡する。メモリシステムは、読出／書込の要求／コマンドがメモリシステムに入ると、要求の順番に関係なく独立して各要求を満たす。ＤＭＡスレッド１２０は、要求／応答の順番、およびコアとの同期に対処する。ＤＭＡスレッド１２０にこれらのメモリ操作の負荷を肩代わりさせることで、たとえば、機械学習計算を行ったり、テンソルの形を変更したりするなどのその他のタスクのために、コア１１０上の計算周期が解放される。
FIG. 1 is an illustration of an
コア１１０は、ＤＭＡスレッド１２０に記述子１１２を送ることによってＤＭＡトランザクションを要求し得る。各ＤＭＡトランザクションは、１つ以上のメモリ転送操作を含み得る。記述子１１２は、ＤＭＡトランザクションについての情報を含む。たとえば、記述子１１２は、データが読み出されるメモリシステム１５０の読出し元メモリ１５２（たとえば、読出し元メモリ１５２のメモリアドレス（複数可））を明記する情報、データが書き込まれる書出し先メモリ１５４（たとえば、書出し先メモリ１５４のメモリアドレス（複数可））を明記する情報、テンソル要素が読出し元メモリ１５２に格納されるソーステンソルのサイズおよび形（たとえば、次元）を明記する情報、ならびにテンソル要素が書出し先メモリ１５４に格納される宛先テンソルのサイズおよび形を明記する情報を含み得る。テンソル要素とは、テンソルにおける特定のインデックス化された位置に対応するテンソルが含むデータである。
Core 110 may request a DMA transaction by sending
ソーステンソルのサイズおよび形は、宛先テンソルのサイズおよび形と同じであってもよく、異なってもよい。たとえば、テンソルの形がコア１１０によって変更されている場合、サイズおよび形は、異なってもよい。記述子１１２は、テンソルの各次元のストライド当たりのステップ数の値を用いて、テンソルのサイズおよび形を規定し得る。ｆｏｒループでは、ステップサイズとは、ループのイテレーションごとのインクリメントの大きさであり、ストライド当たりのステップ数とは、ループがリセットされる前のステップの数、たとえばループのループ範囲である。
The size and shape of the source tensor may be the same as or different from the size and shape of the destination tensor. For example, if the shape of the tensor is modified by core 110, the size and shape may be different. The
たとえば、１つのテンソルの１つの次元のストライド当たりのステップ数は、その次元全体のテンソル要素の数に等しくてもよい。特に、８×６×４×２の４次元テンソルでは、１つ目の次元のストライド当たりのステップ数が８であり、２つ目の次元のストライド当たりのステップ数が６であり、３つ目の次元のストライド当たりのステップ数が４であり、４つ目の次元のストライド当たりのステップ数が２であり得る。詳細については後述するが、ストライド当たりのステップ数を用いて、テンソルの各次元を横断（ｔｒａｖｅｒｓｅ）し、テンソル要素のメモリアドレスを計算できる。 For example, the number of steps per stride in one dimension of a tensor may equal the number of tensor elements across that dimension. In particular, for an 8×6×4×2 4-dimensional tensor, the number of steps per stride in the first dimension is 8, the number of steps per stride in the second dimension is 6, and the number of steps per stride in the third dimension is 6. The number of steps per stride in the dimension may be four, and the number of steps per stride in the fourth dimension may be two. As detailed below, the number of steps per stride can be used to traverse each dimension of the tensor and compute the memory addresses of the tensor elements.
また、記述子１１２は、各次元のストライド次元オフセット値を含み得る。後述するが、これらのストライド次元オフセット値（次元オフセット値とも称する）を使用して、テンソル要素のメモリアドレスを決定する。次元オフセットとは、ストライドの距離である。テンソル次元に沿った処理の各ステップにおいて、ＤＭＡスレッド１２０は、ストライド次元オフセット値だけメモリアドレスを「飛び越す（ｈｏｐ）」。記述子１１２は、ソーステンソルについて、ソーステンソルの各次元のストライド次元オフセット値を含み得る。また、記述子１１２は、宛先テンソルについて、宛先テンソルの各次元のストライド次元オフセット値を含み得る。
ＤＭＡスレッド１２０は、記述子１１２を格納する記述子キュー１２２を備える。たとえば、ＤＭＡスレッド１２０は、受け取って記述子キュー１２２に格納した記述子１１２に基づいて、複数のＤＭＡスレッドを逐次実行し得る。いくつかの実施態様では、記述子キュー１２２は、ＦＩＦＯ（Ｆｉｒｓｔ－Ｉｎ，Ｆｉｒｓｔ－Ｏｕｔ）キューであり、ＤＭＡトランザクションの記述子１１２が受け取られる順番にＤＭＡスレッド１２０がＤＭＡトランザクションを実行できる。ＤＭＡトランザクションの実行は、完全にパイプライン化されており、順不同な操作を行うように実装され得るが、処理装置には、プログラム順に実行しているように見える。
また、ＤＭＡスレッド１２０は、記述子スプリッター１２４を含む。記述子スプリッター１２４は、ソースサブスレッド１３０が利用する情報および宛先サブスレッド１４０が利用する情報を記述子１１２から取り出して、各サブスレッド１３０および１４０に適切な情報を提供し得る。
一般に、ソースサブスレッド１３０は、読出し元メモリ１５２からデータを読み出すための読出要求を生成してメモリシステム１５０に送り、読出動作の進行状況を追跡して、読出動作の進行状況にコア１１０を同期させる。同様に、宛先スレッド１４０は、書出し先メモリ１５４にデータを書き込むための書込要求を生成してメモリシステム１５０に送り、書込動作の進行状況を追跡して、書込動作の進行状況にコア１１０を同期させる。メモリシステム１５０は、コア１１０またはコア１１０を備えるチップの主メモリ、たとえば、コア１１０またはチップのＲＡＭ（ランダムアクセスメモリ）であり得る。メモリシステムは、読出し元メモリ読出要求ごとに読み出されるデータが書出し先メモリへの書込要求と対になるよう、実際のメモリの配線を実装する。データがＤＭＡスレッドを通過することはない（要求アドレスは送り出され、応答は受け取られるが、これらの応答および要求は、メモリデータを保持しない）。
In general, source subthread 130 generates and sends read requests to memory system 150 to read data from
ソースサブスレッド１３０は、記述子１１２に基づいて読出要求を生成する要求生成部１３２を含む。詳細については後述するが、要求生成部１３２は、たとえばクロック周期当たり複数のメモリアドレスを並列して生成し、メモリアドレスごとに読出要求を生成し得る。たとえば、要求生成部１３２は、コア１１０の１つのクロック周期の間に、多次元テンソルを横断しながら複数のテンソル要素の各々のメモリアドレスを生成し得る。各読出要求は、要求識別子（「要求ＩＤ」）と、データが読み出されるメモリアドレスと、メモリオペコードとを含み得る。後述するが、応答は順不同に受け取られ得るので、要求ＩＤは、要求を応答と対応付けるために使われるシーケンス番号またはタグであり得る。メモリオペコードは、メモリ操作、たとえば、要求が読出操作であるのか、書込操作であるのか、ｍｅｍｓｅｔ操作であるのか、または要求のメモリアドレスをターゲットにした別の操作であるのかを示す。
Source subthread 130 includes a request generator 132 that generates read requests based on
また、ソースサブスレッド１３０は、読出要求が明記する読出動作の進行状況を追跡する進行状況追跡部１３４を含む。たとえば、メモリシステム１５０は、読出動作が完了したことを知らせる読出応答を進行状況追跡部１３４に送り得る。各読出応答は、応答が送られた読出要求の要求ＩＤを含み得る。こうすることで、進行状況追跡部１３４は、要求ＩＤを使用して、ＤＭＡトランザクションの進行状況を追跡できる。 Source subthread 130 also includes a progress tracker 134 that tracks the progress of the read operation specified by the read request. For example, memory system 150 may send a read response to progress tracker 134 indicating that the read operation has completed. Each read response may include the request ID of the read request to which the response was sent. This allows the progress tracker 134 to track the progress of the DMA transaction using the request ID.
宛先サブスレッド１４０は、記述子１１２に基づいて書込要求を生成する要求生成部１４２を含む。詳細については後述するが、要求生成部１４２は、たとえばクロック周期当たり複数のメモリアドレスを並列して生成し、メモリアドレスごとに書込要求を生成し得る。たとえば、要求生成部１４２は、コア１１０の１つのクロック周期の間に、多次元テンソルを横断しながら複数のテンソル要素の各々のメモリアドレスを生成し得る。各書込要求は、要求ＩＤを含み得、データが書き込まれるメモリアドレスを明記し得る。
Destination subthread 140 includes a request generator 142 that generates write requests based on
また、宛先サブスレッド１４０は、書込要求が明記する書込動作の進行状況を追跡する進行状況追跡部１３４を含む。たとえば、メモリシステム１５０は、書込動作が完了したことを知らせる書込応答を進行状況追跡部１４４に送り得る。各書込応答は、応答が送られた書込要求の要求ＩＤを含み得る。こうすることで、進行状況追跡部１４４は、要求ＩＤを使用して、ＤＭＡトランザクションの進行状況を追跡できる。 Destination subthread 140 also includes a progress tracker 134 that tracks the progress of the write operation specified by the write request. For example, memory system 150 may send a write response to progress tracker 144 indicating that the write operation has completed. Each write response may include the request ID of the write request to which the response was sent. This allows the progress tracker 144 to track the progress of the DMA transaction using the request ID.
進行状況追跡部１３４および１４４は、それぞれ同期メッセージ１１５および１１６をコア１１０に送り、記述子１１２に対応するＤＭＡトランザクションの進行状況についての最新情報をコア１１０に提供し得る。同期メッセージ１１５および１１６は、完了度合い（たとえば、完了したメモリ操作の割合もしくは数）および／または応答が受け取られた要求ＩＤを明記し得る。
Progress trackers 134 and 144 may send
後述するが、進行状況追跡部１３４および１４４は、ＤＭＡトランザクションの進行状況についての一部のまたは不完全な最新情報を提供する同期メッセージ１１５および１１６を送り得る。たとえば、各進行状況追跡部１３４および１４４は、ＤＭＡトランザクションに対する指定された数、たとえば、しきい値数の応答が受け取られるたびに同期メッセージ１１５および１１６を送るように構成され得る。特定の例では、各進行状況追跡部１３４および１４４は、連続した一続きの少なくともしきい値数の要求ＩＤに対する応答が受け取られるたびに同期メッセージ１１５および１１６を送るように構成され得る。メモリ操作が行われる順番（よって、テンソル要素が移動されている順番）をコア１１０は知り得るので、コア１１０は、すべての一連のＤＭＡトランザクションが完了するのを待たずに、これらの一部の最新情報に基づいて、転送済みのデータの処理を開始し得る。
As described below, progress trackers 134 and 144 may send
読出操作と書込動作に別個のサブスレッドを用いることで、処理能力を向上させることが可能になる。たとえば、各サブスレッド１３０および１４０が、クロック周期当たり特定の数の要求、たとえば、クロック周期当たり４つの要求を並列して生成できる場合、２つのサブスレッド１３０および１４０によって生成される要求の数は、当該特定の数の２倍、たとえば、８個の要求になる。 Using separate sub-threads for read and write operations allows for increased throughput. For example, if each subthread 130 and 140 can generate a certain number of requests per clock cycle in parallel, say 4 requests per clock cycle, then the number of requests generated by the two subthreads 130 and 140 is , resulting in twice that particular number, eg, 8 requests.
場合によっては、複数のＤＭＡスレッドを使用してＤＭＡトランザクションが行われ得る。たとえば、メモリのバンド幅が、１つのＤＭＡスレッドが生成し得る要求よりも多くの要求をクロック周期当たりに対処するのに十分である場合、複数のＤＭＡスレッドを使用して要求が生成され得る。多次元テンソルのデータを転送するために複数のＤＭＡスレッドが使用される場合、各ＤＭＡスレッドは、多次元テンソルの一部、たとえば、テンソルの１つのスライスの記述子を受け取り得る。この記述子は、フルテンソルの記述子と同様に、テンソルのスライスのサイズおよび形と、メモリアドレスとを明記し得る。 In some cases, DMA transactions may be performed using multiple DMA threads. For example, multiple DMA threads may be used to generate requests if the memory bandwidth is sufficient to handle more requests per clock cycle than one DMA thread can generate. When multiple DMA threads are used to transfer data of a multi-dimensional tensor, each DMA thread may receive a descriptor for a portion of the multi-dimensional tensor, eg, one slice of the tensor. This descriptor may specify the size and shape of the slice of the tensor and the memory address, similar to the full tensor descriptor.
図２Ａは、例示的な要求生成部２００の図である。要求生成部２００は、図１の要求生成部１３２および１４２の各々を実装するために用いられ得る。この例では、要求生成部２００は、最大で４つのテンソル次元があり、クロック周期当たり最大で４つのメモリアドレスが生成され得る実装向けに構成される。
FIG. 2A is a diagram of an
一般に、要求再生成部２００は、多次元テンソルまたはその他の多次元データ構造（本明細書では、説明が煩雑になるのを防ぐために、テンソルと称す）におけるテンソル要素のメモリアドレスを決定し得る。要求生成部２００は、テンソルのデータがメモリから読み出されるおよび／またはメモリに書き込めるよう、メモリアドレスを決定し得る。要求生成部２００は、テンソル内でのテンソル要素の位置を定める当該テンソル要素のステップインデックス値に基づいて、テンソル要素のメモリアドレスを計算し得る。例示的な要求生成部２００は、５段階設計を用いて、隣接する段階の間にパイプラインレジスタ２２０、２３０、２４０、２６０、および２７０を配置させた状態に実装される。
In general,
メモリアドレスを決定するために、要求生成部２００は、各次元の各ステップインデックス値を１つずつ進むことにより、各次元を横断し得る。たとえば、１つの次元が１０個の要素を含む場合、要求生成部２００は、ステップインデックス値を１から１０の順番に１つずつ進み得る。概念的に、これは、テンソルの次元ごとに１つのループを含んだループネストを使用して行われ得る。このような例では、そのループに含まれる要素の数にループ範囲が等しくなるまでループのイテレーションごとに当該ループのステップインデックス値をインクリメントすることによって、テンソルの１つ次元がループを用いて横断され得る。ループ範囲に達すると、次の外側のループがインクリメントされ、現在のループは、次元が含む最初の要素に対応する最初のステップインデックス値にリセットされる。最も内側のループは、ループネストに含まれる４つのループのステップインデックス値に対応するテンソル内の位置にあるテンソル要素のメモリアドレスを決定するためのメモリアドレス計算を含み得る。４つのループを使用してメモリアドレスを決定するための例示的な擬似コード２８０を図２Ｂに示す。
To determine the memory address,
図２Ｂを参照すると、擬似コード２８０は、１つのテンソルの４つの次元を横断するために使われる４つのループ２８１～２８４を含む。図示した擬似コード２８０には、トランザクションの半分が記述されている（ソース側が読み込むか、宛先側が書き出すかのいずれか）。完全なトランザクションにするために、同じまたは同様の擬似コードが別個に２回インスタンス化され得る。擬似コード２８０では、各次元のループ範囲（ｓｔｅｐｓ＿ｐｅｒ＿ｓｔｒｉｄｅ）は、転送のソース側と宛先側とで同じであるが、ストライドオフセット値（ｓｔｒｉｄｅ＿ｄｉｍｅｎｓｉｏｎ＿ｏｆｆｓｅｔ＿ｖａｌｕｅ＿ｉ）は異なり得る。すなわち、擬似コードにおけるｓｔｅｐｓ＿ｐｅｒ＿ｓｔｒｉｄｅ＿０はソース側と宛先側とで同じであるが、ソース側の擬似コードにおけるｓｔｒｉｄｅ＿ｄｉｍｅｎｓｉｏｎ＿ｏｆｆｓｅｔ＿ｖａｌｕｅ＿０は、宛先擬似コードにおけるｓｔｒｉｄｅ＿ｄｉｍｅｎｓｉｏｎ＿ｏｆｆｓｅｔ＿ｖａｌｕｅ＿０とは異なり得る。
Referring to FIG. 2B,
最も外側のループ２８１は、複数ある次元のうち１つに対応し、ステップインデックス値ｉ０と、ループ範囲ｓｔｅｐｓ＿ｐｅｒ＿ｓｔｒｉｄｅ＿０とを含む。ループ範囲ｓｔｅｐｓ＿ｐｅｒ＿ｓｔｒｉｄｅ＿０は、最も外側のループに対応する次元２８１に含まれる要素の数に等しくてもよい。同様に、ループ２８２は、複数ある次元のうち１つに対応し、ステップインデックス値ｉ１と、ループ範囲ｓｔｅｐｓ＿ｐｅｒ＿ｓｔｒｉｄｅ＿１（ループ２８２に対応する次元に含まれる要素の数に等しくてもよい）とを含み、ループ２８３は、複数ある次元のうち１つに対応し、ステップインデックス値ｉ２と、ループ範囲ｓｔｅｐｓ＿ｐｅｒ＿ｓｔｒｉｄｅ＿２（ループ２８３に対応する次元に含まれる要素の数に等しくてもよい）とを含む。
The
最も内側のループ２８４もまた、複数ある次元のうち１つに対応し、ステップインデックス値ｉ３と、ループ範囲ｓｔｅｐｓ＿ｐｅｒ＿ｓｔｒｉｄｅ＿３（最も内側のループ２８４に対応する次元に含まれる要素の数に等しくてもよい）とを含む。最も内側のループのイテレーションごとに、関数２８５を使用して、テンソルの各次元の次元メモリアドレスオフセット値が計算され、これらの次元メモリアドレスオフセット値を用いて、関数２８６を使用して、ステップインデックス値ｉ０～ｉ３に対応するテンソル要素のメモリアドレスが決定される。最も外側のループ２８１に対応する次元の次元メモリアドレスオフセット値（ｄｅｓｔｉｎａｔｉｏｎ＿ｍｅｍｏｒｙ＿ａｄｄｒｅｓｓ＿ｏｆｆｓｅｔ＿０）は、ループのステップインデックス値ｉ０と次元のストライド次元オフセット値（ｓｔｒｉｄｅ＿ｄｉｍｅｎｓｉｏｎ＿ｏｆｆｓｅｔ＿ｖａｌｕｅ＿０）との積に等しい。その他の次元ごとの次元メモリアドレスオフセット値も、図２Ｂに示すように、同様に決定される。上述したように、次元のストライド次元オフセット値は、記述子に含まれ得る。
The
その後、テンソル要素のメモリアドレスは、ベースメモリアドレス、およびテンソルの各次元の次元メモリアドレスオフセット値に基づいて計算され得る。たとえば、テンソル要素のメモリアドレスは、図２Ｂに示すように、ベースメモリアドレスと、それぞれの次元の次元メモリアドレスオフセット値との和に基づき得る、たとえば、ベースメモリアドレスと、それぞれの次元の次元メモリアドレスオフセット値との和に等しい。 The memory addresses of the tensor elements can then be calculated based on the base memory address and the dimensional memory address offset values for each dimension of the tensor. For example, the memory addresses of the tensor elements may be based on the sum of the base memory address and the dimensional memory address offset values for each dimension, as shown in FIG. Equal to the sum with the address offset value.
図２Ａに戻ると、要求生成部２００は、実際にループを繰り返さずに、類似したメモリアドレス計算を並列して行い得る。この例では、要求生成部２００は、たとえば１つのクロック周期内で４つのメモリアドレスを並列して計算するための４つのレーン２０１～２０４を含む。その他の例では、たとえば３つのメモリアドレスには３つのレーン、５つのメモリアドレスには５つのレーンなど、２つ以上のレーンを使用して２つ以上のメモリアドレスが並列して計算され得る。すなわち、要求生成部２００は、Ｍ個のメモリアドレスを並列して計算するためにＭ個のレーンを含み得る。ここで、Ｍは、１以上である。要求生成部２００は、並列メモリアドレス計算周期の間に、Ｍ個のメモリアドレスを計算し得る。並列メモリアドレス計算周期の長さは、１つのクロック周期以下の長さである。
Returning to FIG. 2A,
レーンの数は、テンソルの次元の数と同じであってもよく、異なってもよい。たとえば、要求生成部２００を用いて、記述子１１２に含まれる情報に基づいて、次元の数が異なるテンソルのメモリアドレスを計算し得る。たとえば、４つのレーンを有する要求生成部２００は、最大で４つのレーンのすべてを使用して、３次元テンソルのメモリアドレスを周期当たり最大で４つ計算し得る。また、同じ要求生成部２００は、最大で４つのレーンすべてを使用して、１次元テンソル、２次元テンソル、または４次元テンソルのアドレスを周期当たり最大で４つ計算し得る。
The number of lanes may or may not be the same as the number of dimensions of the tensor. For example,
各レーン２０１～２０４は、互いに異なるテンソル要素のメモリアドレスを計算しなければならず、各レーンが互いに独立して動作するので、マルチレベルマルチストライド（この例では、４レベルマルチストライド）に基づいてこのような計算を並列して行うことは、難しいであろう。各レーン２０１～２０４が並列して、たとえば同時にメモリアドレスを計算するので、一方のレーンが、他方のレーンが完了するのを待ってから、１つ以上のループを繰り返して次のテンソル要素のメモリアドレスを決定することはできない。その代わりに、各レーンが、別のレーンを待たずに、次のテンソル要素（たとえば、次のテンソル要素のステップインデックス値）を決定し、そのテンソル要素のメモリアドレスを決定できるようになければならない。 Because each lane 201-204 has to compute the memory addresses of different tensor elements from each other and each lane operates independently from each other, based on multi-level multi-stride (4-level multi-stride in this example) Performing such computations in parallel would be difficult. Since each lane 201-204 computes memory addresses in parallel, eg, simultaneously, one lane waits for the other lane to complete before repeating one or more loops to compute the next tensor element's memory address. address cannot be determined. Instead, each lane should be able to determine the next tensor element (e.g. the step index value of the next tensor element) and determine the memory address of that tensor element without waiting for another lane. .
要求生成部２００は、それぞれのレーン２０１～２０４に（よって、それぞれの並列メモリアドレス計算のために）メモリアドレス部２４２～２４８を含む。各メモリアドレス部２４２～２４８は、それぞれステップ追跡部２２２～２２８と、それぞれメモリアドレス計算要素２５２～２５８とを含む。一般に、ステップ追跡部２２２～２２８は、テンソルのテンソル要素を１つずつ進んで、テンソル要素の次元メモリアドレスオフセット値を決定するように構成される。メモリアドレス計算要素２５２～２５８は、ステップ追跡部２２２～２２８から受け取る次元メモリアドレスオフセット値を用いて、テンソル要素のメモリアドレスを決定するように構成される。
要求生成部２００は、ステップ追跡部２２２～２２８のために値を事前に計算する計算要素２１０を備える。たとえば、計算要素２１０は、メモリアドレスが決定される次のテンソル要素の次のステップインデックス値を決定するためにステップ追跡部２２２～２２８が使用できる様々なステップ比較値を事前に計算し得る。後述するが、現在のステップインデックス値とステップ比較値との比較は、次のステップインデックス値を決定するためのその他の条件とともに使用され得る。計算要素２１０は、テンソルの各次元のステップ比較値を事前に計算し得る。要求生成部２００がメモリアドレスを生成して要求を送っている現在の記述子１１２のテンソルの次元の数によっては、これらのステップ比較値は、たとえば、次元のストライド当たりのステップ数から１を減算した値、次元のストライド当たりのステップ数から２を減算した値、次元のストライド当たりのステップ数から３を減算した値などであり得る。計算要素２１０は、必須ではなく、事前に計算された値も必須ではない。値を事前に計算することは、次のクロック周期上でのクリティカルパスタイミングを改善するのに役立ち得る。
The
計算要素２１０は、ステップ比較値を事前に計算してレジスタ２２０（またはその他の適切なデータ記憶素子）に格納する一連のハードウェア加算器を備え得る。計算要素２１０は、記述子で受け取ったストライド当たりのステップ数の値に基づいて、比較オフセット値を計算し得る。この記述子は、次元のうち１つ以上の次元のストライド当たりのステップ数の値を含み得る。この例では、記述子は、次元１～３（ｓｐｓ＿１～ｓｐｓ＿３）のストライド当たりのステップ数の値を含み売るが、次元０（たとえば、最も外側のループに対応する次元）のストライド当たりのステップ数の値は含まない。たとえば、ストライド当たりのステップ変数が３２ビットの符号付き整数で表される場合、次元０のストライド当たりのステップ数の値は、最大整数値、たとえば、符号付き３２ビットの整数で格納できる最大整数値である、と暗に示され得る。別の例では、ストライド当たりのステップ数の値は、記述子に含まれ得るが、図２Ａには示していない。
ストライド当たりのステップ数の値がテンソルのサイズおよび形に基づいて異なり得るので、計算要素２１０は、記述子ごとにステップ比較値を事前に計算し、レジスタ２２０に格納し得る。また、記述子は、レジスタ２２０に格納され得る。
Since the number of steps per stride value may vary based on the size and shape of the tensor,
また、要求生成部２００は、ＦＳＭ（有限ステートマシン）２３２を備える。ＦＳＭ２３２は、記述子１１２からの情報に基づいてステップ追跡部２２２～２２８を初期化および制御し得る。たとえば、ＦＳＭ２３２は、レジスタ２３０から記述子情報を取得して、記述子情報に基づいて、記述子が規定するＤＭＡトランザクションを求めて送る要求の数を決定し得る。この数は、テンソルに含まれるテンソル要素の数であり得る。ＦＳＭ２３２は、送る残りの要求の数を追跡し、この残りの要求の数に基づく予告量（advance amount）を各ステップ追跡部２２２～２２４に送り得る。予告量は、メモリアドレス計算要素２５２～２５８が行うメモリアドレス計算の次の周期の間に計算されるメモリアドレスの数を定める。
The
たとえば、４つのレーン２０１～２０４のすべてを使用してＤＭＡトランザクションを実行する過程で、予告量は、４に等しくてもよい。しかしながら、このＤＭＡトランザクションについて計算されるメモリアドレスの数が４つ未満である場合、最後の周期の予告量は、４よりも小さい値になる。たとえば、メモリアドレスの数が１８である場合、ＦＳＭ２３２は、最初の４つの周期については４という予告量を各ステップ追跡部２２２～２２８に提供し、その後、最後の周期については２という予告量を提供する。
For example, in the course of performing a DMA transaction using all four lanes 201-204, the amount of advance notice may be equal to four. However, if the number of memory addresses calculated for this DMA transaction is less than four, then the last period notice amount will be less than four. For example, if the number of memory addresses is 18,
また、ＦＳＭ２３２は、ステップ追跡部２３２をストールし得る。たとえば、後述するが、進行状況追跡部１３４および１４４は、１度に特定の数の要求の進行状況を追跡すればよい。要求生成部２００は、割り当てられた要求ＩＤを使い切ると、要求生成部２００は、要求生成部２００自体、たとえば、ステップ追跡部２３２をストールし得る。要求ＩＤが解放されて再割り当てされ得る場合、たとえば、後述するが、少なくともしきい値数の連続した要求ＩＤに対する応答が受け取られると、進行状況追跡部１３４および１４４は、要求ＩＤクレジットを返し得る。
また、要求生成部１３２および１４２は、外部接続バックプレッシャー（external interconnect backpressure）により、ストールし得る（すなわち、メモリシステムは、新しい要求をまだ受け付けられない）。いくつかの実施態様では、各ＤＭＡスレッド１２０は、ソフトウェアによって構成可能なハードウェアＦＳＭを用いて、独立して速度が絞られ得る。ソフトウェアは、構成可能なサンプリング期間にわたる目標要求生成バンド幅をＤＭＡスレッド１２０ごとに設定し得、ＤＭＡスレッド１２０は、割り当てられたバンド幅に達すると自動的にそのパイプラインをストールする。よって、ＤＭＡスレッド１２０は、（１）メモリシステムネットワークバックプレッシャー、（２）要求バンド幅が絞られる、（３）要求ＩＤ割り当てを使い果たす（進行状況追跡部がクレジットを返すのを待つ）という３つの異なる状況でストールし得る。
Also, request generators 132 and 142 may stall (ie, the memory system cannot accept new requests yet) due to external interconnect backpressure. In some implementations, each
各ステップ追跡部２２２～２２８は、ＦＳＭ２３２から受け取った予告量と、テンソルの各次元の現在のステップインデックス値と、各次元のストライド当たりのステップ数の値とを用いて、各次元の次のステップインデックス値を決定する。また、各ステップ追跡部２２２～２２８は、各次元の次元メモリアドレスオフセット値を、当該次元の次のステップインデックス値と、当該次元のストライド次元オフセット値とに基づいて決定する。各ステップ追跡部２２２～２２８は、決定した次元メモリアドレスオフセット値を、それぞれの対応するメモリアドレス計算要素２５２～２５８にレジスタ２４０を介して出力する。後述するが、メモリアドレス計算要素２５２～２５８は、受け取った次元メモリアドレスオフセット値に基づいてテンソル要素のメモリアドレスを決定する。
Each step tracker 222-228 uses the advance notice received from
ステップ追跡部２２２～２２８は、互いに異なるテンソル要素の次元メモリアドレスオフセット値を決定する。たとえば、全部で１６個のテンソル要素を含む２×２×２×２のテンソル（またはその他の形のテンソル）について考える。４つのレーン２０１～２０４が周期ごとに４つの要求を生成するので、各ステップ追跡部２２２～２２８は、１６個のテンソル要素のうち、全部で４つのテンソル要素の次元メモリアドレスオフセット値を決定する。たとえば、ステップ追跡部２２２が最初のテンソル要素、５番目のテンソル要素、８番目のテンソル要素、および１３番目のテンソル要素の次元メモリアドレスオフセット値を決定し得、ステップ追跡部２２４が２番目のテンソル要素、６番目のテンソル要素、１０番目のテンソル要素、および１４番目のテンソル要素の次元メモリアドレスオフセット値を決定するなどである。
The step trackers 222-228 determine dimensional memory address offset values for different tensor elements. For example, consider a 2x2x2x2 tensor (or other form of tensor) containing a total of 16 tensor elements. Since the four lanes 201-204 generate four requests per cycle, each step tracker 222-228 determines the dimensional memory address offset values for a total of four tensor elements out of the 16 tensor elements. . For example,
ステップ追跡部２２２～２２８は、それぞれの次元メモリアドレスオフセット値を、互いに独立して、並列して決定し得る。すなわち、いくつかの実施態様では、ステップ追跡部２２２～２２８は、その他のステップ追跡部２２２～２２８とはデータを通信しない。その代わりに、詳細については後述するが、各ステップ追跡部２２２～２２８は、ステップ追跡部２２２～２２８の初期化およびＦＳＭ２３２から受け取った予告量に基づいて、次のテンソル要素（たとえば、次のテンソル要素のステップインデックス値）を決定するように構成され得る。このように、いずれのステップ追跡部２２２～２２８も他のステップ追跡部２２２～２２８を待たなくてよく、この並列計算は、すべてのステップ追跡部２２２～２２８によって１つのクロック周期で完了され得る。ステップ追跡部の例示的なアーキテクチャ、および次元メモリアドレスオフセット値を決定するための技術について、図３、図４、および図７に示し、以下に説明する。
The step trackers 222-228 may determine their respective dimensional memory address offset values independently of each other and in parallel. That is, in some implementations, step trackers 222-228 do not communicate data with other step trackers 222-228. Instead, each step tracker 222-228, based on the initialization of the step tracker 222-228 and the advance notice received from the
メモリアドレス計算要素２５２～２５８は、第１加算要素２６２Ａ～２６８Ａと、第２加算要素２６２Ｂ～２６８Ｂとをそれぞれ含む。第１加算要素２６２Ａ～２６８Ａは、並列メモリアドレス計算周期ごとにそれぞれのステップ追跡部２２２～２２８から受け取った次元メモリアドレスオフセット値の和を求め得る。たとえば、加算要素２６２Ａは、ステップ追跡部２２２が生成した特定のテンソル要素についての４つの次元メモリアドレスオフセット値の合計を求め得る。第１加算要素２６２Ａ～２６８Ａは、ハードウェア加算器として実現され得る。
Memory address calculation elements 252-258 include
第２加算要素２６２Ｂ～２６８Ｂ（これらもハードウェア加算器としても実現され得る）は、それぞれの対応する第１加算要素２６２Ａ～２６８Ａが計算した次元メモリアドレスオフセット値の和と、基底アドレスとに基づいて、テンソル要素のメモリアドレスを決定し得る。たとえば、加算要素２６２Ｂは、ステップ追跡部２２２が生成した特定のテンソル要素についての４つの次元メモリアドレスオフセット値の和に基底アドレスを加算することによって、当該特定のテンソル要素のメモリアドレスを決定し得る。
The
第２加算要素２６２Ｂ～２６８Ｂは、それぞれのメモリアドレスをレジスタ２７０に出力し得る。要求送信部２９０は、各メモリアドレスを求める要求を生成して、メモリシステム、たとえば、図１のメモリシステム１５０に送り得る。要求は、要求ＩＤと、メモリアドレスとを含み得る。要求ＩＤは、要求に順番に割り当てられ得る。たとえば、ＤＭＡスレッドが一度に５００個の未処理の要求を有するように構成された場合、要求ＩＤは、０または１から始まり、それぞれ最大で４９９または５００までになる。０～４９９が用いられた場合、最初の要求の要求ＩＤは０であり得、２番目の要求の要求ＩＤは１であり得るなどである。要求送信部２９９は、各要求の要求ＩＤを決定するカウンタを備え得る。
Second summing
４つのレーン２０１～２０４は、各々、１つのクロック周期の間に、テンソル要素のメモリアドレスを並列して生成し得る。ＦＳＭ２３２は、レーン２０１～２０４のステップ追跡部２２２～２２８を制御して、テンソルに含まれる各テンソル要素のメモリアドレスが計算されるまで、テンソルの各テンソル要素を反復処理する。記述子を求める要求を発行し終わると、ＦＳＭ２３２は、次の記述子に取り掛かり得る。しかしながら、ＦＳＭ２３２は、すべての要求に対する応答が受け取られるのを待つ必要はない。少なくともしきい値数の連続した（たとえば、応答が受け取られた）要求ＩＤが利用可能であれば、進行状況追跡部１３２または１３４は、要求生成部２００がこれらの利用可能な要求ＩＤを用いて次の記述子を求める要求を発行できるよう、要求生成部２００に通知を行い得る。これにより、ＤＭＡスレッドの処理能力および効率性がさらに向上する。
Each of the four lanes 201-204 may generate memory addresses for tensor elements in parallel during one clock cycle. The
上述したように、ＤＭＡサブスレッド１３２および１３４の要求生成部１３２および１３４は、要求生成部２００を用いて実装され得る。この例では、各サブスレッド１３２および１３４は、クロック周期当たり４つの要求を送ることが可能になる。
As noted above, request generators 132 and 134 of DMA subthreads 132 and 134 may be implemented using
図３は、例示的なステップ追跡部３００の図である。ステップ追跡部３００は、図２Ａのステップ追跡部２２２～２２８の各々を実装するために用いられ得る。この例では、ステップ追跡部３００は、２つのインクリメントチェーン３２２および３２４を備える。インクリメントチェーン３２２および３２４は、同じまたは同様の関数を実行して、テンソル要素のステップインデックス値および次元メモリアドレスオフセット値を生成し得る。これにより、ステップインクリメントチェーンのうち一方は、ＤＭＡスレッドが処理を開始する現在の記述子の次元メモリアドレスオフセット値を積極的に決定できるようになり、他方のステップインクリメントチェーンは、ＤＭＡスレッドが処理する次の記述子のために初期化される。
FIG. 3 is a diagram of an
たとえば、ステップインクリメントチェーン３２４が現在の記述子の次元メモリアドレスオフセット値を積極的に決定し得る。ステップインクリメントチェーン３２４は、ＦＳＭから受け取った予告量、たとえば、図２のＦＳＭ２３２、および（記述子が規定する）ストライドパラメータを用いて、現在の記述子の次元メモリアドレスオフセット値を決定し得る。図４を参照して後述するが、ステップインクリメントチェーン３２４がアクティブである間、ＦＳＭは、ステップインクリメントチェーン３２２を初期化し得る。
For example, step increment chain 324 may proactively determine the current descriptor's dimensional memory address offset value. The step increment chain 324 may use the advance amount received from the FSM, eg,
現在の記述子の最後の周期のメモリアドレスが要求されている間に、ＦＳＭは、初期化されたステップインクリメントチェーン３２２に切り替えて、ステップインクリメントチェーン３２２に初期化量を送り得る。ステップインクリメントチェーン３２４が次元メモリアドレスオフセット値の最後の一式を決定したクロック周期の直後のクロック周期に、ステップインクリメントチェーン３２２は、次元メモリアドレスオフセット値の最初の一式を生成し得る。２つのステップインクリメントチェーンをこのように利用することで、特に、テンソルが小さい場合にＤＭＡスレッドの処理能力および効率性が大幅に改善し得る。たとえば、このテンソルのメモリアドレスのすべてを決定するために要求生成部が３つのクロック周期しか必要としない場合、１つのクロック周期を用いてテンソル間の１つのステップインクリメントチェーンを再度初期化すると、処理能力（たとえば、単位時間当たりに行われるメモリ操作の数）が２５％低下してしまう。 While the memory address of the last period of the current descriptor is being requested, the FSM may switch to the initialized step increment chain 322 and send the initialization amount to the step increment chain 322 . In the clock cycle immediately following the clock cycle in which step increment chain 324 determined the last set of dimensional memory address offset values, step increment chain 322 may generate the first set of dimensional memory address offset values. Utilizing two step-increment chains in this way can greatly improve the throughput and efficiency of the DMA thread, especially when the tensors are small. For example, if the request generator requires only three clock cycles to determine all of the memory addresses for this tensor, then using one clock cycle to reinitialize the one step-increment chain between tensors would allow the process Performance (eg, number of memory operations performed per unit of time) is reduced by 25%.
ステップインクリメントチェーン３２２と３２４とを切り替えるとき、ＦＳＭは、マルチプレクサ３３２～３３８の一式を制御して、レジスタ３４２を介してどのステップインクリメントチェーンの出力をメモリアドレス計算部に送るかを選択し得る。たとえば、ＦＳＭは、インクリメントチェーン３２２がアクティブである場合、各マルチプレクサ３３２～３３８の上段のレーンを選択し得、インクリメントチェーン３２４がアクティブである場合、各マルチプレクサ３３２～３３８の下段のレーンを選択し得る。
When switching between step increment chains 322 and 324, the FSM may control a set of multiplexers 332-338 to select via
図２Ｂを参照して上述したが、各レーン２０１～２０４は、ステップ追跡部３００として実装され得るステップ追跡部を含む。この例では、ステップ追跡部３００は、レーン０のステップ追跡部であり、レーン０の４つの次元メモリアドレスオフセット値を出力する。
As described above with reference to FIG. 2B, each lane 201 - 204 includes a step tracker that may be implemented as
また、図示しないが、各ステップ追跡部３００は、次元メモリアドレスオフセット値を決定するために用いられる次のステップインデックス値を出力し得る。当該次のステップインデックス値は、後続のステップインデックス値および次元メモリアドレスオフセット値を決定する際に使用するために、ステップ追跡部３００に戻される。すなわち、ステップインクリメントチェーン３２４は、各次元のステップインデックス値を決定し得、各次元の次元メモリアドレスオフセット値を決定し得る。これらの値は、ステップインクリメントチェーン３２４に現在値として戻されて、次の値を決定する際に使用され得る。
Also, although not shown, each
また、ステップ追跡部３００は、ステップインデックス値用のマルチプレクサを備え得る。これらのマルチプレクサは、マルチプレクサ３２２～３３８がステップインクリメントチェーン３２２および３２４の両方から次元メモリアドレスオフセット値を受け取るのと同様に、ステップインクリメントチェーン３２２および３２４の両方から各次元のステップインデックス値を受け取る。これらのマルチプレクサの出力は、ステップインクリメントチェーン３２４に提供されて、後続のステップインデックス値を決定する際に使用される。
The
ステップインクリメントチェーン３２４が現在の記述子の次元メモリアドレスオフセット値を計算する一方、ステップインクリメントチェーン３２２は、初期化された状態を用いて、次の記述子のメモリアドレスの第１セットの次元メモリアドレスオフセット値を決定し得る。しかしながら、ＦＳＭは、マルチプレクサ３３２～３３８を制御して、ステップインクリメントチェーン３２４から受け取った次元メモリアドレスオフセット値を渡し得る。現在の記述子が完了すると、ＦＳＭは、マルチプレクサ３３２～３３８を制御して、１つ周期についてステップインクリメントチェーン３２２が計算した次元メモリアドレスオフセット値を渡し得る。次元メモリアドレスオフセット値は、次のテンソルの最初の４つのテンソル要素の値を含む。また、ＦＳＭは、ステップインデックス値に関してマルチプレクサを制御して、ステップインクリメント部３２２からステップインクリメントチェーン３２４にこの１つの周期のステップインデックス値を渡し得る。その後、ステップインクリメントチェーン３２４は、ステップインデックス値の現在の状態を有することとなり、この記述子に関連する残りの周期の次元メモリアドレスオフセット値を決定し得る。この記述子の最初の周期が完了した後、ＦＳＭは、マルチプレクサを制御して、ステップインクリメントチェーン３２４の出力を再び渡し得る。 While step increment chain 324 calculates the dimensional memory address offset value for the current descriptor, step increment chain 322 uses the initialized state to calculate the dimensional memory address of the first set of memory addresses for the next descriptor. An offset value can be determined. However, the FSM may control multiplexers 332 - 338 to pass the dimensional memory address offset values received from step increment chain 324 . When the current descriptor is complete, the FSM may control multiplexers 332-338 to pass the dimensional memory address offset values calculated by step increment chain 322 for one cycle. The dimensional memory address offset value contains the values of the first four tensor elements of the next tensor. The FSM may also control a multiplexer on the step index value to pass this one period step index value from the step increment unit 322 to the step increment chain 324 . The step increment chain 324 then has the current state of the step index value and can determine the remaining cycle dimensional memory address offset values associated with this descriptor. After the first cycle of this descriptor is completed, the FSM may control the multiplexer to pass the output of the step increment chain 324 again.
図４は、例示的なステップインクリメントチェーン４００の図である。ステップインクリメントチェーン４００は、ＤＭＡスレッドが処理するように構成された最大テンソルの次元ごとに、ステップインクリメント部を備え得る。この例では、ステップインクリメントチェーン４００は、最大で４つの次元テンソルに対して４つのステップインクリメント部４１０～４４０を含む。図４に示すこの例示的なステップインクリメントチェーンは、キャリーリップル方式の加算回路と同様の形式で組合せ関数として実装される。
FIG. 4 is a diagram of an exemplary
各ステップインクリメント部４１０～４４０は、パラメータのセットを受け取り得る。このステップインクリメント部４１０～４４０のパラメータのセットは、ステップインクリメント部４１０～４４０に対応する次元のストライド当たりのステップ数と、計算要素２１０が事前に計算した次元の各ステップ比較値とを含み得る。これらの値は、ＤＭＡトランザクションが行われているテンソルの含み得るサイズおよび形に基づいて変わり得るので、ステップインクリメント部４１０～４４０は、記述子ごとに初期化され得る。
Each step incrementer 410-440 may receive a set of parameters. This set of parameters for step increments 410 - 440 may include the number of steps per stride for the dimension corresponding to step increments 410 - 440 and a step comparison value for each dimension previously computed by
また、各ステップインクリメント部４１０～４４０は、その次元のステップインデックス値と、当該次元の次元オフセット値とを受け取り得る。この次元のステップインデックス値は、（ステップインクリメントチェーン３２２への入力値によっても図示されているように）最初の周期で０に初期化され得る。最初の周期の後、ステップインクリメント部４１０～４４０に入力されるステップインデックス値は、ステップインクリメント部４１０～４４０によって出力される次のステップインデックス値になる。上述したように、次元の次元オフセット値は、ステップインデックス値によって乗算される値であり、次元メモリアドレスオフセット値を決定する。図２Ｂの擬似コード２８０の４つのループを使用することと比較すると、ステップインクリメント部４１０は、ループネストの最も内側のループと同様に機能する。しかしながら、ループのイテレーションごとにステップインデックスを１つインクリメントするのではなく、ステップインクリメント部４１０は、ＦＳＭから受け取った予告量に基づいて、そのステップインデックス値をインクリメントする。たとえば、予告量が４であった場合、ステップインクリメント部４１０は、その次元のステップインデックス値を４つずつインクリメントするであろう。このインクリメント数が次元のストライド当たりのステップ数を超えた場合、ステップインクリメント部は、ステップインデックス値を０に再度初期化して、４回インクリメントされるまでインクリメントを続け得る。これは、２回以上の再度初期化することを含み得る。たとえば、ストライド当たりのステップ数が３で予告量が４である場合、ステップインクリメント部４１０は、０から３にインクリメントし、０に再度初期化し、４回インクリメントした後に、０から１にインクリメントするであろう。
Each step incrementer 410-440 may also receive a step index value for that dimension and a dimension offset value for that dimension. The step index value for this dimension may be initialized to 0 on the first cycle (as also illustrated by the input value to step increment chain 322). After the first period, the step index value input to step increments 410-440 becomes the next step index value output by step increments 410-440. As noted above, the dimensional offset value for a dimension is the value that is multiplied by the step index value to determine the dimensional memory address offset value. Compared to using four loops in the
ステップインクリメント部４１０は、ステートフルなイテレーションを利用するのではなく、最適化された加算器のペアと同様に挙動する組合せ関数を利用し得る。加算器のように、ステップインクリメント部の一部は、２つのオペランド（「ステップ３ インデックス」および「ａｄｖａｎｃｅ＿ａｍｏｕｎｔ」）をとり、和（「ステップ３ 次のインデックス」）と、桁上がり（「ラップ量」）とを出す。この関数は、次の次元オフセットを計算する関数がラップ量の出力を出さないこと以外は、次元オフセットに対して同様である。 Rather than using stateful iteration, the step increment unit 410 may use a combinatorial function that behaves like an optimized adder pair. Like an adder, part of the step increment part takes two operands ("step 3 index" and "advance_amount"), sums ("step 3 next index") and carries ("wrap amount" ). This function is similar for dimensional offsets, except that the function that computes the next dimensional offset does not output a wrap amount.
ステップインクリメント部４１０は、ステップインクリメント部４２０にラップ量を出力し得る。ラップ量は、受け取った予告量に基づいてステップインクリメント部４１０のステップインデックス値が現在の周期において再度初期化された回数に等しくてもよい。すなわち、ラップ量は、予告量に基づいて４つのループがラップアラウンドされる回数を反映している。 Step increment section 410 may output the wrap amount to step increment section 420 . The wrap amount may be equal to the number of times the step index value of the step incrementer 410 has been reinitialized in the current cycle based on the received advance notice amount. That is, the wrap amount reflects the number of times the four loops wrap around based on the advance amount.
ステップインクリメント部４１０～４４０がその次元メモリアドレスオフセット値を計算する周期ごとに、たとえば、１つのクロック周期の間に、ステップインクリメント部４１０は、その次元の次のステップインデックス値と、ステップインクリメント部４２０のラップ量と、次元メモリアドレスオフセット値（たとえば、次のステップインデックス値と、次元の次元オフセット値との積）とを計算し得る。 Each period that step incrementers 410-440 calculate the dimension memory address offset value, eg, during one clock period, step incrementer 410 calculates the dimension's next step index value and step incrementer 420 and a dimensional memory address offset value (eg, the product of the next step index value and the dimension's dimensional offset value).
ステップインクリメント部４２０がＦＳＭから受け取った予告量を利用した方法と同様の方法で、ステップインクリメント部４２０は、ステップインクリメント部４１０から受け取ったラップ量を利用する。すなわち、ラップ量は、ステップインクリメント部４２０に対応する次元のステップインデックス値がこの周期でインクリメントされる回数を表す。ステップインクリメント部４２０は、そのステップインデックス値を、ステップインクリメント部４１０から受け取ったラップ量を用いてインクリメントし、次のステップインデックス値を決定する。また、ステップインクリメント部４２０は、その次元メモリアドレスオフセット値を、次のステップインデックス値を用いて決定し得る（たとえば、次元の次のステップインデックス値とストライド次元オフセット値との積）。 Step incrementer 420 utilizes the wrap amount received from step incrementer 410 in a manner similar to the way step incrementer 420 utilized the advance amount received from the FSM. That is, the wrap amount represents the number of times the step index value of the dimension corresponding to the step increment unit 420 is incremented in this cycle. Step increment unit 420 increments the step index value using the wrap amount received from step increment unit 410 to determine the next step index value. Step increment unit 420 may also determine its dimension memory address offset value using the next step index value (eg, the product of the dimension's next step index value and the stride dimension offset value).
ステップインクリメント部４１０と同様に、ステップインクリメント部４２０も、ラップ量を計算してステップインクリメント部４３０に出力し得る。ラップ量は、ステップインクリメント部４１０から受け取ったラップ量に基づいてステップインクリメント部４２０のステップインデックス値が現在の周期で再度初期化された回数と等しくてもよい。すなわち、ラップ量は、受け取ったラップ量に基づいて４つのループがラップアラウンドされる回数を反映している。 Similar to step increment section 410 , step increment section 420 may also calculate a wrap amount and output it to step increment section 430 . The wrap amount may be equal to the number of times the step index value of the step increment unit 420 has been reinitialized in the current cycle based on the wrap amount received from the step increment unit 410 . That is, the wrap amount reflects the number of times the four loops are wrapped around based on the wrap amount received.
ステップインクリメント部４３０は、ステップインクリメント部４２０から受け取ったラップ量を同様に利用し得る。すなわち、ラップ量は、ステップインクリメント部４３０に対応する次元のステップインデックス値がこの周期でインクリメントされる回数を表す。ステップインクリメント部４３０は、そのステップインデックス値を、ステップインクリメント部４２０から受け取ったラップ量を用いてインクリメントし、次のステップインデックス値を決定し得る。また、ステップインクリメント部４３０は、その次元メモリアドレスオフセット値を、次のステップインデックス値を用いて決定し得る（たとえば、次元の次のステップインデックス値とストライド次元オフセット値との積）。 Step incrementer 430 may similarly utilize the wrap amount received from step incrementer 420 . That is, the wrap amount represents the number of times the step index value of the dimension corresponding to the step increment unit 430 is incremented in this cycle. Step incrementer 430 may increment the step index value using the wrap amount received from step incrementer 420 to determine the next step index value. Step increment unit 430 may also determine its dimension memory address offset value using the next step index value (eg, the product of the dimension's next step index value and the stride dimension offset value).
ステップインクリメント部４２０と同様に、ステップインクリメント部４３０もラップ量を計算してステップインクリメント部４４０に出力し得る。ラップ量は、ステップインクリメント部４３０のステップインデックス値が、ステップインクリメント部４２０から受け取ったラップ量に基づいて現在の周期で再度初期化された回数に等しくてもよい。すなわち、ラップ量は、受け取ったラップ量に基づいて４つのループがラップアラウンドされる回数を反映している。 Similar to step increment section 420 , step increment section 430 may also calculate a wrap amount and output it to step increment section 440 . The wrap amount may be equal to the number of times the step index value of the step incrementer 430 has been reinitialized in the current period based on the wrap amount received from the step incrementer 420 . That is, the wrap amount reflects the number of times the four loops are wrapped around based on the wrap amount received.
ステップインクリメント部４４０は、ステップインクリメント部４３０から受け取ったラップ量を同様に利用し得る。すなわち、ラップ量は、ステップインクリメント部４４０に対応する次元のステップインデックス値がこの周期でインクリメントされる回数を表す。ステップインクリメント部４４０は、そのステップインデックス値を、ステップインクリメント部４３０から受け取ったラップ量を用いてインクリメントし、次のステップインデックス値を決定し得る。また、ステップインクリメント部４４０は、その次元メモリアドレスオフセット値を、次のステップインデックス値を用いて決定し得る（たとえば、次元の次のステップインデックス値とストライド次元オフセット値との積）。 Step incrementer 440 may similarly utilize the wrap amount received from step incrementer 430 . That is, the wrap amount represents the number of times the step index value of the dimension corresponding to the step increment unit 440 is incremented in this cycle. Step incrementer 440 may increment the step index value using the wrap amount received from step incrementer 430 to determine the next step index value. Step increment unit 440 may also determine its dimension memory address offset value using the next step index value (eg, the product of the dimension's next step index value and the stride dimension offset value).
ステップインクリメント部４１０～４４０がその次元メモリアドレスオフセット値を計算する周期ごとに、たとえば、１つのクロック周期の間に、ステップインクリメント部４１０～４４０は、各々、その次元の次のステップインデックス値と、次のステップインクリメント部（該当する場合は）のラップ量と、次元メモリアドレスオフセット値（たとえば、次元の次のステップインデックス値とストライド次元オフセット値との積）とを計算し得る。 Each period in which the step increment units 410-440 calculate the dimension memory address offset value, eg, during one clock period, the step increment units 410-440 each calculate the next step index value for that dimension and A wrap amount for the next step increment (if applicable) and a dimensional memory address offset value (eg, the product of the dimension's next step index value and the stride dimension offset value) may be calculated.
いくつかの実施態様では、各インクリメント部４１０～４４０は、その次元の次のステップインデックス値および／またはその次元のラップ量を決定する際に、一連の条件を使用し得る。この条件は、インクリメント量（たとえば、インクリメント部４１０に対する予告量、またはインクリメント部４２０～４４０に対するラップ量）を含み得る。また、この条件は、次元のストライド当たりのステップ数、および現在のステップインデックス値とステップ比較値との比較も含み得る。 In some implementations, each incrementer 410-440 may use a set of conditions in determining its dimension's next step index value and/or its dimension's wrap amount. This condition may include an increment amount (eg, an advance amount for increment 410 or a wrap amount for increments 420-440). The condition may also include the number of steps per stride of the dimension and a comparison of the current step index value and the step comparison value.
たとえば、ルックアップテーブルが生成され得る。ルックアップテーブルは、たとえば、インクリメント量と、ストライド当たりのステップ数と、どのステップ比較値が現在のステップインデックス値と一致するのかとの特定の組合せごとに、次のステップインデックス値が何になるのか、およびラップ量が何になるのかを明記する。特定の組合せは、要求生成部がメモリアドレスを生成できるテンソルの次元の数に基づいて異なり得る。このように、各ステップインクリメント部４１０～４４０は、インクリメント量および現在のステップインデックス値をテーブルと単純に比較して、次のステップインデックス値とラップ量とが何になるかを判断し得る。 For example, a lookup table can be generated. A lookup table, for example, tells what the next step index value will be for each particular combination of increment amount, number of steps per stride, and which step comparison value matches the current step index value. , and specify what the wrap amount will be. The specific combination can differ based on the number of dimensions of the tensor for which the request generator can generate memory addresses. Thus, each step incrementer 410-440 may simply compare the increment amount and the current step index value to a table to determine what the next step index value and wrap amount will be.
図５は、例示的な進行状況追跡部５００の図である。進行状況追跡部５００は、図２Ａの進行状況追跡部１３４および１４４の各々を実装するために使われ得る。進行状況追跡部５００は、進行状況追跡部のキュー５１０と、応答並替え部５２０と、同期部５３０とを備える。
FIG. 5 is a diagram of an
進行状況追跡部のキュー５１０は、１つの記述子から複数の記述子（または、記述子のうち、応答と同期に対処するために必要な関連箇所）を受け取って格納し得る。後述するが、記述子により、同期部５３０は、記述子が規定するＤＭＡトランザクションの進行状況を特定することが可能になる。
The progress tracker's
応答並替え部５２０は、メモリシステム、たとえば、図１のメモリシステム１５０から応答を受け取り得る。各応答は、応答に対応する要求の要求ＩＤを明記し得る。すなわち、メモリシステムは、進行状況追跡部５００に対応する要求生成部から受け取った完了済みの各要求に対する応答を、進行状況追跡部５００に送り得る。
応答並替え部５２０は、任意の順序で応答を受け取って、それらの要求ＩＤに基づいて応答の順序を並び替え得る。メモリシステムは、要求が受け取られた順序とは異なる順序で要求を処理し得る。たとえば、メモリシステムは、バンド幅最適化技術を利用して、一部の要求をその他の要求よりも優先し得る。これに鑑みて、応答並替え部５２０は、応答を順不同に受け取って、その順序を並び替えて、メモリシステムによって完了されるメモリ操作の進行状況を追跡するように構成され得る。例示的な応答並替え部については図６に示し、詳細については後述する。
同期部５３０は、応答並替え部から進行状況データを受け取り、コア、たとえば、図１のコア１１０に同期メッセージを送り得る。たとえば、同期部５３０は、応答並替え部５２０から、受け取った順序要求ＩＤの数を明記するデータを受け取り得る。同期部５３０は、記述子が規定する少なくともしきい値量（またはしきい値割合）のメモリ操作が完了するたびに、同期メッセージを送るように構成され得る。たとえば、同期部５３０は、現在の記述子に関連して行われるメモリ操作の回数（たとえば、読出操作または書込操作であるかは、サブスレッドによって異なる）を決定し得る。同期更新部５３０は、メモリ操作の少なくとも１０％が完了するたびにコアに同期メッセージを送るように構成され得る。上述したように、記述子が規定するメモリ操作のすべてが完了するまで待たずに、コアは、これらの一部の最新情報を使って、転送されたデータを消費し始め得る。
応答並替え部５２０および／または同期部５３０は、要求生成部が再利用できる一連の要求ＩＤを要求生成部に通知するように構成され得る。たとえば、少なくともしきい値数の順序要求ＩＤをメモリシステムから応答で受け取るたびに、これらの要求ＩＤは、応答生成部に解放されて再利用され得る。これにより、要求生成部は、進行状況追跡部５００が処理できる最大数の要求を要求生成部が送った後、すべての要求が完了する前に、要求の生成を継続することが可能になる。
The
たとえば、進行状況追跡部５００が１度に５００個のメモリ操作しか追跡できない応答並替えバッファを含み、要求ＩＤが０～４９９であると想定する。５００個のメモリ操作のすべてが要求で使われて、いずれの要求に対しても応答がなかった場合、要求生成部は、進行状況追跡部５００から利用可能な要求ＩＤを明記する通知を受け取るまでストールしなければならない。進行状況追跡部５００が０～１５の要求ＩＤに対する応答を受け取り（しかし、識別子のすべての応答ではない）、しきい値が１５未満である場合、進行状況追跡部５００は、５００個すべてのメモリ操作が完了するまで待たずに、要求生成部が０～１５の要求ＩＤを用いた要求の送信を再開できることを明記する通知（たとえば、要求ＩＤクレジットリターンメッセージ）を送り得る。
For example, assume that
図６は、例示的な応答並替え部６００の図である。応答並替え部６００を用いて、図５応答並替え部５２０が実装され得る。応答並替え部６００は、応答ベクトル６１０と、並替えベクトル６３０とを含み、これらは各々、ビットベクトルレジスタを用いて実装され得る。応答ベクトル６１０および並替えベクトル６３０は、各々、要求生成部が発行できる要求ＩＤごとに１つのビットを含み得る。このビットは、要求ＩＤのステータスを示し得る。たとえば、ビットの値が０である場合、メモリ操作に対する応答は、未だ受け取っていない。ビットの値が１である場合、メモリ操作に対する応答はすでに受け取っている。応答ベクトル６１０、並替えベクトル６３０、およびポップベクトル（後述する）は、すべて同じサイズであってもよく、たとえば同じ数のビットを含み得る。
FIG. 6 is a diagram of an exemplary response reorderer 600. As shown in FIG. Response reorderer 600 may be used to implement
応答ベクトル６１０は、一度に複数の応答、たとえばこの例では最大で４つの応答を一度に受け取るように構成され得る。たとえば、応答ベクトル６１０は、対応する要求生成部のレーンの数に一致する数の応答を同時に受け取るように構成され得る。その他の例では、応答ベクトル６１０は、対応する要求生成部のレーンの数とは異なる数、たとえばレーンの数よりも多い数の応答を同時に受け取るように構成され得る。
並替えベクトル６３０に含まれるビットは、要求ＩＤの順番に配置され得る。並替えベクトル６３０の入力側には論理和ゲート６２４がある。論理和ゲート６２４は、並替えベクトル６３０のビットごとに論理和ゲートを備えるビットベクトル論理和ゲートであり得る。要求ＩＤごとに、要求ＩＤの応答ベクトルのビット、および論理積ゲート６２２（たとえば、ビットベクトル論理積ゲート）が出力する要求ＩＤのビットは、論理和ゲートへの入力となり得、並替えベクトル６３０に含まれる要求ＩＤのビットの値が決定される。
The bits contained in
論理積ゲート６２２には、要求ＩＤごとに、したがって並替えベクトル６３０のビットごとに１対の入力がある。特定の要求ＩＤの場合、並替えベクトル６３０に含まれるビットの値、およびポップベクトルロジック６４０が保持するポップベクトルにある要求ＩＤのポップビットの値が両方とも１である場合、当該要求ＩＤに関する論理積ゲートの出力は、１である。後述するが、メモリアドレスのポップビットを１に設定して、たとえば、要求生成部が使用するために要求ＩＤが解放された場合に、ビットの値をクリアして０にし得る。すなわち、要求ＩＤに対する応答が受け取られていて要求ＩＤがまだ解放されていない場合、要求ＩＤに対応するビットの論理積ゲート６２２の出力は、１である。要求ＩＤが解放された場合、このビットについての論理積ゲート６２２の出力は、ポップベクトルからの入力が１になるので、０である。
AND
また、応答並替え部６００は、先頭ポインタロジック６５０と、ポップベクトルロジック６４０と、内部ポップカウントロジック６６０とを備える。先頭ポインタロジック６５０は、並替えベクトル６３０に含まれる、応答が受け取られた最も数字が大きい順序要求ＩＤのビットの後ろの次のビットに、ポインタを維持し得る。順序要求ＩＤは、最初の要求ＩＤから応答がまだ受け取られていない要求ＩＤまでの、応答が受け取られた連続した要求ＩＤである。たとえば、要求ＩＤの値が０～４９９であり、０～８、１１、５６、および６１～７８に対する応答がすでに受け取られている場合、順序要求ＩＤの値は、０～８である。この例では、先頭ポインタは、要求ＩＤの値が９であるビットを指す。値が９および１０である要求ＩＤに対する応答が受け取られると、順序要求ＩＤの値は、０～１１となり、値が１２である要求ＩＤの応答はまだ受け取られていないと想定される。
Response rearranger 600 also includes
また、先頭ポインタロジック６５０は、先頭ポインタに１を足したポインタ（たとえば、先頭ポインタが指しているビットの次のビット）、先頭ポインタに２を足したポインタなど、別の先頭ポインタを事前に計算し得る。こうすることで、ポップカウントロジック６６０は、１つのクロック周期の間に並替えベクトル６３０において２つ以上のビットをポップし得る。この機能は、必須ではなく、これを使って、特定のクロック周波数のタイミングに合わせることができる。ロジックは、周期当たりの応答が多い大きな並替えベクトルの場合、かなり複雑になる。この事前計算は、目標周波数が比較的高速である場合、または周期当たりの応答が多い（たとえば、レーンが多い）場合に用いられ得る。
The
内部ポップカウントロジック６６０は、並替えベクトル６３０に含まれるビットを監視して、先頭ポインタが移動したときに並替えベクトルのいくつのビットがポップ（たとえば、クリア）され得るかを決定し得る。たとえば、内部ポップカウントロジック６６０は、値が１のビット列をルックアヘッドし得る。１という値は、ビットに対応するメモリ操作に対する応答が受け取られたことを示す。先頭ポインタロジック６５０が別のビットに移動すると、先頭ポインタロジック６３０は、先頭ポインタの移動先（たとえば、ｈｅａｄ＿ｐｌｕｓ＿ｉ＿ｎｅｘｔ）（たとえば、ビット）を提供し得る。先頭ポインタの新しい位置および監視されているビットに基づいて、内部ポップカウントロジック６６０は、クロック周期当たりの、ポップし得るビットの数、たとえば、最大ポップ数までを決定し得る。たとえば、先頭ポインタがビット１０個分だけ上に移動し得る場合、最大ポップ数は、クロック周期当たりビット４つであり、内部ポップカウントロジック６６０は、ポップベクトルロジック６４０に、最初の周期で４つのビットをポップし、２回目の周期で４つのビットをポップし、２回目の周期で２つのビットをポップするよう指示し得る。先頭ポインタは、その周期の間にポップするエントリの数と同じ数だけインクリメントされるので、この例では、周期当たり最大でビット４つ分だけ進み得る。
Internal
ポップベクトルロジック６４０は、ポップするビットのポップベクトルを保持し、このポップベクトルを論理積ゲート６２２に入力として提供し得る。先頭ポインタおよび別の先頭ポインタ、ならびに内部ポップカウントロジック６６０から受け取ったポップするビットの数に基づいて、ポップベクトルロジック６４０は、どのビットがポップするかを決定し得る。たとえば、ポップするビットが４つである場合、ポップベクトルロジック６４０は、現在の先頭ポインタから先頭ポインタに４を足した位置までのビットをポップし得る。先頭ポインタに４を足した値はすでに計算されているので、ポップベクトルロジック６４０は、ポップするビットの位置を、クロック周期を消費して決定する必要がない。
Pop vector logic 640 may hold the pop vector of the bit to pop and provide this pop vector as an input to AND
先頭ポインタロジック６５０も、ポップカウントロジックから、ポップするビットの数を受け取り得る。先頭ポインタロジック６５０は、先頭ポインタを更新し、ポップするビットの数に基づいて、別の先頭ポインタを事前に計算し得る。
The
また、応答並替え部６００は、順序アイテムレジスタ６７２と、計算要素６７０および６７４とを備える。順序アイテムレジスタ６７２は、要求生成部にまだ解放されていない、ポップした順序アイテムの数のカウントを保持し得る。そうするために、計算部６７０は、内部ポップカウントロジック６６０の出力に基づいて、ポップしたビットの数を集約する。
Response reordering unit 600 also includes an
レジスタ６７２にある順序アイテムの数は、同期部５３０にも送られる。同期部５３０は、ポップした順序アイテムの数に基づいて、要求ＩＤを要求生成部に解放するタイミングを決定し得る。たとえば、同期部は、要求生成部が利用できる要求ＩＤの数（たとえば、要求ＩＤクレジットリターン）を明記するデータを送り得る。計算部６７４は、この数を、レジスタ６７２に現在ある順序アイテムの数から減算し、その結果（および内部ポップカウントロジック６６０からの新たにポップしたアイテム）を用いてレジスタを更新し得る。たとえば、レジスタ６７２が１５個の順序アイテムがポップしたと示し、同期部５３０が１０個を要求生成部に解放した場合、計算要素６７４は、１５個の要求ＩＤからこの１０個の解放された要求ＩＤを減算し、５つの要求ＩＤの値を格納して更新し得る。こうすることで、レジスタ２７２は、要求生成部に解放できる要求ＩＤの数の累計を格納する。
The number of order items in
図７は、メモリ操作を求める要求を生成するための例示的な処理７００を説明するフロー図である。処理７００は、要求生成部、たとえば、図１の要求生成部１３２もしくは１４２、または図２の要求生成部２００によって実行され得る。
FIG. 7 is a flow diagram illustrating an
要求生成部は、１つ以上の記述子を受け取る（７０２）。各記述子は、ＤＭＡトランザクション、たとえば、一連のメモリ転送操作についての情報を含む。たとえば、記述子は、データが読み出される読出し元メモリを明記する情報と、データが書き込まれる書出し先メモリを明記する情報と、テンソル要素が読出し元メモリに格納されるソーステンソルのサイズおよび形（たとえば、次元）を明記する情報と、テンソル要素が書出し先メモリに格納される宛先テンソルのサイズおよび形を明記する情報と、各次元のストライド次元オフセット値を明記する情報とを含み得る。 The request generator receives (702) one or more descriptors. Each descriptor contains information about a DMA transaction, eg a series of memory transfer operations. For example, a descriptor contains information specifying the source memory from which data is read, the destination memory to which data is written, and the size and shape of the source tensor whose tensor elements are stored in the source memory (e.g. , dimensions), the size and shape of the destination tensor whose tensor elements are to be stored in the destination memory, and the stride dimension offset values for each dimension.
要求生成部は、ステップ追跡部を初期化する（７０４）。上述したように、要求生成部は、たとえばクロック周期当たりのメモリアドレスを各々が並列して計算する複数のレーンを備え得る。各レーンは、ステップ追跡部と、メモリアドレス計算部とを含み得る。各ステップ追跡部は、ステップインクリメントチェーンを含み得る。ステップ追跡部を初期化することは、各ステップインクリメント部にステップパラメータを提供することと、ステップインクリメント部ごとにステップインデックス値を初期化することとを含む。 The request generator initializes the step tracker (704). As mentioned above, the request generator may comprise multiple lanes each calculating in parallel, for example, a memory address per clock cycle. Each lane may include a step tracker and a memory address calculator. Each step tracker may include a step increment chain. Initializing the step tracker includes providing a step parameter to each step increment and initializing a step index value for each step increment.
要求生成部は、メモリアドレスを生成する（７０６）。たとえば、要求生成部は、複数のレーンを使用して、たとえば１つのクロック周期の間に複数のメモリアドレスを並列して計算し得る。特に、クロック周期の間、各ステップ追跡部は、（テンソルに含まれる特定のテンソル要素に対応する）テンソルの各次元の次のステップインデックス値を計算し、各次元の次元メモリアドレスオフセット値を、当該次元のストライド次元オフセット値と、次のステップインデックス値とを用いて計算し得る。そして、レーン上のステップ追跡部が出力した各次元の次元メモリアドレスオフセット値と、基底アドレスとに基づいて、各レーンのメモリアドレス計算部は、メモリアドレスを計算し得る。たとえば、レーンのメモリアドレス（よって、テンソル要素）は、基底アドレスと、次元メモリアドレスオフセット値との和であり得る。 The request generator generates a memory address (706). For example, the request generator may use multiple lanes to compute multiple memory addresses in parallel, eg, during one clock cycle. In particular, during a clock period, each step tracker calculates the next step index value for each dimension of the tensor (corresponding to a particular tensor element contained in the tensor), and the dimensional memory address offset value for each dimension by It can be calculated using the stride dimension offset value for that dimension and the next step index value. Then, the memory address calculator of each lane can calculate the memory address based on the dimensional memory address offset value of each dimension and the base address output by the step tracking unit on the lane. For example, a lane memory address (and thus a tensor element) can be the sum of a base address and a dimensional memory address offset value.
要求生成部は、要求を生成してメモリシステムに送る（７０８）。要求は、読出要求であってもよく、書込要求であってもよい。各要求は、要求ＩＤと、この周期中に計算されたメモリアドレスとを明記し得る。すなわち、要求生成部は、コンピュータメモリアドレスごとに各要求を生成して送り得る。要求生成部は、メモリシステムに要求を送り得、メモリシステムは、要求に含まれているメモリアドレスを用いて読出動作または書込動作を行う。 The request generator generates a request and sends it to the memory system (708). The request may be a read request or a write request. Each request may specify a request ID and a memory address computed during this cycle. That is, the request generator may generate and send each request for each computer memory address. A request generator may send a request to the memory system, which performs a read or write operation using the memory address included in the request.
要求生成部は、メモリアドレスを計算するテンソル要素がまだあるかどうかを判断する（７１０）。たとえば、上述したように、ＦＳＭは、記述子に関して生成する残りの要求の数を追跡し得る。テンソル要素がまだある場合、処理７００は、ステップ７０６に戻り、メモリアドレスをさらに生成する。
The request generator determines (710) whether there are more tensor elements to compute memory addresses for. For example, as described above, the FSM may track the number of remaining requests it generates for descriptors. If there are more tensor elements,
別のテンソル要素がない場合、要求生成部は、ＤＭＡトランザクションを行う別の記述子があるかどうかを判断する（７１４）。たとえば、要求生成部は、記述子キューを確認して、キューの中に別の記述子があるかどうかを判断し得る。別の記述子がない場合、処理は終了する。別の記述子がある場合、処理は、ステップ７０４に戻る。ステップ７０４では、次の記述子のためにステップ追跡部が初期化される。上述したように、ステップ追跡部は、前の記述子のＤＭＡトランザクションが完了する前に初期化され得る。
If there is not another tensor element, the request generator determines (714) whether there is another descriptor for DMA transactions. For example, the request generator may check the descriptor queue to determine if there is another descriptor in the queue. If there are no more descriptors, processing ends. If there is another descriptor, processing returns to step 704 . At
図８は、メモリ操作の進行状況を追跡するための例示的な処理８００を説明するフロー図である。処理８００は、進行状況追跡部、たとえば、図１の進行状況追跡部１３４もしくは１４４、または図５の進行状況追跡部５００によって行われ得る。
FIG. 8 is a flow diagram illustrating an
進行状況追跡部は、１つ以上の応答を受け取る（８０２）。たとえば、メモリシステムは、メモリ操作が完了したことに応答して追跡した進行状況に対する応答を送り得る。この応答は、完了したメモリ操作の要求ＩＤを明記し得る。 The progress tracker receives one or more responses (802). For example, a memory system may send a tracked progress response in response to a memory operation completing. This response may specify the request ID of the completed memory operation.
進行状況追跡部は、並替えベクトルを更新する（８０４）。進行状況追跡部は、並替えベクトルを更新して、要求ＩＤに対応するメモリ操作が完了したことを示し得る。たとえば、進行状況追跡部は、要求ＩＤのビットの値を０から１に更新して、要求ＩＤに対応するメモリ操作が完了したことを示し得る。
The
進行状況追跡部は、連続する要素（たとえば、要求ＩＤのビット）の数がしきい値以上であるかどうかを判断する（８０６）。しきい値以上である場合、進行状況追跡部は、要求ＩＤを解放して、要求生成部が再利用できるようにする（８０８）。しきい値以上でない場合、処理８００は、要求ＩＤを解放することなく、ステップ８１０に続く。
The progress tracker determines (806) whether the number of consecutive elements (eg, bits of the request ID) is greater than or equal to a threshold. If so, the Progress Tracker releases the Request ID for reuse by the Request Generator (808). If not,
ステップ８１０では、進行状況追跡部は、受け取った応答の数がしきい値以上であるかどうかを判断する。この数は、メモリ操作が行われているコアに前回の同期メッセージが送られてから受け取った応答の数であり得る。別の例では、進行状況追跡部は、受け取る応答の数のうち、少なくともしきい値割合の応答を受け取ったかどうかを判断し得る。 At step 810, the progress tracker determines whether the number of responses received is greater than or equal to a threshold. This number may be the number of responses received since the last sync message was sent to the core on which the memory operation is occurring. In another example, the progress tracker may determine whether it has received at least a threshold percentage of the number of responses it receives.
いずれの例においても、しきい値以上になった場合、進行状況追跡部は、コアと同期し得る（８１２）。たとえば、進行状況追跡部は、受け取った応答の数または割合を示す同期メッセージをコアに送り得る。別の例では、進行状況追跡部は、前回の同期メッセージがコアに送られてから受け取った応答の数を示す同期メッセージをコアに送り得る。 In either example, if the threshold is exceeded, the progress tracker may synchronize 812 with the core. For example, the progress tracker may send a synchronization message to the core indicating the number or percentage of responses received. In another example, the progress tracker may send a synchronization message to the core indicating the number of responses received since the last synchronization message was sent to the core.
しきい値に達していない場合、処理８００は、ステップ８１４に続く。ステップ８１４では、進行状況追跡部は、記述子の応答をすべて受け取ったどうかを判断する。記述子のすべての応答を受け取っていない場合、処理８００は、ステップ８０２に戻る。ステップ８０２では、さらに多くの応答を受け取る。記述子のすべての応答を受け取っている場合、進行状況追跡部は、たとえば、記述子のメモリ操作のすべてが完了したことを示す同期メッセージを送ることによって、コアと同期し得る（８１６）。
If the threshold has not been reached,
本明細書は、多くの具体的な実施態様の詳細を含むが、これらは発明または特許請求の範囲の限定として解釈されるべきではなく、むしろ、特定の発明の特定の実施の形態に特有な特徴の説明であると解釈されるべきである。本明細書おいて別々の実施の形態として説明された特定の特徴も、組み合わせて１つの実施の形態で実現することができる。その逆に、１つの実施の形態として説明された様々な特徴を、別々の複数の実施の形態または任意の適した部分的な組み合わせで実現することもできる。また、特徴は、いくつかの特定の組み合わせで動作するものとして上述され、そのように当初クレームされてもよいが、クレームされた組合せからの１つ以上の特徴は、場合によっては、組み合わせから削除することができ、クレームされた組合せは、部分的な組み合わせまたは部分的な組み合わせの変形例を対象としてもよい。 While this specification contains details of many specific embodiments, these should not be construed as limitations on the scope of the invention or claims, but rather are specific to specific embodiments of particular inventions. should be construed as a description of the features. Certain features that are described in this specification as separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in a single embodiment can also be implemented in separate embodiments or in any suitable subcombination. Also, while features are described above as operating in some particular combination, and may originally be claimed as such, one or more features from the claimed combination may, in some cases, be deleted from the combination. and a claimed combination may cover subcombinations or variations of subcombinations.
同様に、図面に動作を特定の順番で示しているが、所望の結果を実現するためにこのような動作を図示された特定の順番または順序で実行する必要がある、または、図示した動作のすべてを実行する必要がある、と理解されるべきではない。特定の状況では、多重タスク処理および並列処理が有利である場合がある。また、上述の実施の形態における様々なシステムおよび構成要素を分離することは、このような分離がすべての実施の形態において必要であると理解されるべきではなく、説明したプログラムコンポーネントおよびシステムは、一般に、１つのソフトウェアプロダクトに一体化したり、複数のソフトウェアプロダクトにパッケージ化したりすることができると理解されるべきである。 Similarly, although the figures show acts in a particular order, it is necessary that such acts be performed in the specific order or order shown to achieve desired results, or that the acts shown need to be performed in the particular order or order shown. It should not be understood that you have to do everything. Multitasking and parallel processing may be advantageous in certain situations. Also, the separation of various systems and components in the above-described embodiments should not be construed as requiring such separation in all embodiments; In general, it should be understood that they can be integrated into one software product or packaged into multiple software products.
よって、本発明の主題の特定の実施の形態を説明した。その他の実施の形態も、添付の特許請求の範囲に含まれる。場合によっては、請求項に記載された動作は、異なる順序で実行することができ、それでもなお所望の結果を実現することができる。これに加えて、添付の図面に示した処理は、所望の結果を実現するために必ずしも図示した特定の順番または一連の順序である必要はない。いくつかの実施態様において、多重タスク処理および並列処理が有利である場合がある。 Thus, specific embodiments of the inventive subject matter have been described. Other embodiments are within the scope of the appended claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Additionally, the operations illustrated in the accompanying drawings need not necessarily be in the particular order or sequence shown to achieve desired results. In some implementations, multitasking and parallel processing may be advantageous.
Claims (20)
１つ以上のハードウェアＤＭＡスレッドを備え、各ＤＭＡスレッドは、
並列メモリアドレス計算周期のたびに（１）多次元テンソルのためにＭ個のメモリアドレスを並列して生成し、メモリアドレスごとに（２）前記多次元テンソルに関するメモリ操作を行うようメモリシステムに求める要求を生成するように構成された要求生成部を含み、前記要求生成部は、Ｍ個のメモリアドレス部を含み、各メモリアドレス部は、
前記多次元テンソルの次元ごとに（１）前記次元のステップインデックス値を生成し、前記ステップインデックス値に基づいて（２）前記次元のストライドオフセット値を生成するように構成されるステップ追跡部と、
メモリアドレス計算要素とを含み、前記メモリアドレス計算要素は、
並列メモリアドレス計算周期のたびに、前記ストライドオフセット値に基づいて、前記多次元テンソルのテンソル要素のメモリアドレスを生成し、
前記メモリアドレスを用いて前記メモリ操作を行うよう求める前記要求を、前記メモリシステムに送るように構成され、
前記Ｍは、１以上である、ＤＭＡシステム。 A DMA (direct memory access) system,
one or more hardware DMA threads, each DMA thread comprising:
Each parallel memory address computation cycle asks the memory system to (1) generate M memory addresses in parallel for a multi-dimensional tensor, and for each memory address (2) perform memory operations on said multi-dimensional tensor. a request generator configured to generate a request, the request generator including M memory address units, each memory address unit comprising:
a step tracker configured for each dimension of the multi-dimensional tensor to (1) generate a step index value for the dimension and (2) generate a stride offset value for the dimension based on the step index value;
and a memory address calculation element, said memory address calculation element comprising:
generating memory addresses for tensor elements of the multi-dimensional tensor based on the stride offset value for each parallel memory address calculation cycle;
configured to send the request to the memory system to perform the memory operation using the memory address;
The DMA system, wherein the M is 1 or more.
各次元のストライド値当たりのステップ数は、前記次元のループのループ範囲を表し、各次元の前記ステップインデックス値は、前記次元のループのループインデックスを表す、請求項５に記載のＤＭＡシステム。 A step tracker is configured to generate the memory address of the multi-dimensional tensor based on a loop nest, wherein the loop nest traverses a dimension of the multi-dimensional tensor for each dimension of the multi-dimensional tensor. contains a loop of
6. The DMA system of claim 5, wherein the number of steps per stride value in each dimension represents a loop range for a loop in said dimension and said step index value in each dimension represents a loop index for a loop in said dimension.
前記ループネストの最も内側のループに対応する前記ステップインクリメントチェーンの第１ステップインクリメント部は、予告量を受け取るように構成され、
クロック周期のたびに前記次元のうち１つ以上の次元のステップインデックス値を更新することは、前記第１ステップインクリメント部が前記予告量に基づいて前記１つ以上の次元の前記ステップインデックス値を更新することを含む、請求項８に記載のＤＭＡシステム。 each step tracker includes a step increment chain including a plurality of step increments, each of the plurality of step increments configured to determine a dimensional memory address offset value of a dimension;
a first step increment portion of the step increment chain corresponding to the innermost loop of the loop nest configured to receive an advance notice amount;
Updating step index values of one or more of the dimensions at each clock cycle causes the first step increment unit to update the step index values of the one or more dimensions based on the advance notice amount. 9. The DMA system of claim 8, comprising:
クロック周期のたびに前記次元のうち１つ以上の次元のステップインデックス値を更新することは、前記第２ステップインクリメント部が前記ラップ量に基づいて前記１つ以上の次元の前記ステップインデックス値を更新することを含む、請求項９に記載のＤＭＡシステム。 The one or more second step increments of the step increment chain corresponding to the loop in which the innermost loop is nested are configured to receive a wrap amount from a previous step tracker in the step increment chain. is,
Updating the step index values of one or more of the dimensions each clock cycle means that the second step increment unit updates the step index values of the one or more dimensions based on the wrap amount. 10. The DMA system of claim 9, comprising:
前記応答並替え部は、
前記メモリシステムから応答を任意の順番に受け取るように構成され、各応答は、前記応答が提供される前記要求の一意の識別子を含み、前記応答並替え部は、さらに、
少なくともしきい値数の連続した一意の識別子を前記応答で受け取った場合、一連の一意の識別子を、前記要求生成部が再利用できるよう、解放するように構成される、請求項１１に記載のＤＭＡシステム。 Each request contains a unique identifier,
The response rearrangement unit
configured to receive responses from the memory system in any order, each response including a unique identifier of the request to which the response is provided, the response reordering unit further comprising:
12. The method of claim 11, configured to release a sequence of unique identifiers for reuse by the request generator if at least a threshold number of consecutive unique identifiers are received in the response. DMA system.
１つ以上のプロセッサコアと、
メモリシステムと、
１つ以上のＤＭＡスレッドを含むＤＭＡエンジンとを備え、各ＤＭＡスレッドは、
並列メモリアドレス計算周期のたびに（１）多次元テンソルのためにＭ個のメモリアドレスを並列して生成し、メモリアドレスごとに（２）前記多次元テンソルに関するメモリ操作を行うようメモリシステムに求める要求を生成するように構成された要求生成部を含み、前記要求生成部は、Ｍ個のメモリアドレス部を含み、前記Ｍは、１以上であり、各メモリアドレス部は、
前記多次元テンソルの次元ごとに（１）前記次元のステップインデックス値を生成し、前記ステップインデックス値に基づいて（２）前記次元のストライドオフセット値を生成するように構成されるステップ追跡部と、
メモリアドレス計算要素とを含み、前記メモリアドレス計算要素は、
並列メモリアドレス計算周期のたびに、前記ストライドオフセット値に基づいて、前記多次元テンソルのテンソル要素のメモリアドレスを生成し、
前記メモリアドレスを用いて前記メモリ操作を行うよう求める前記要求を、前記メモリシステムに送るように構成され、前記システムは、さらに、
応答並替え部と、同期更新部とを含む進行状況追跡部を備え、前記同期更新部は、前記ＤＭＡエンジンが管理するメモリ操作についての同期に関する一部の最新情報を前記１つ以上のプロセッサコアに提供するように構成される、システム。 a system,
one or more processor cores;
a memory system;
a DMA engine including one or more DMA threads, each DMA thread comprising:
Each parallel memory address computation cycle asks the memory system to (1) generate M memory addresses in parallel for a multi-dimensional tensor, and for each memory address (2) perform memory operations on said multi-dimensional tensor. a request generator configured to generate a request, the request generator including M memory address units, wherein M is equal to or greater than 1, each memory address unit comprising:
a step tracker configured for each dimension of the multi-dimensional tensor to (1) generate a step index value for the dimension and (2) generate a stride offset value for the dimension based on the step index value;
and a memory address calculation element, said memory address calculation element comprising:
generating memory addresses for tensor elements of the multi-dimensional tensor based on the stride offset value for each parallel memory address calculation cycle;
configured to send the request to the memory system to perform the memory operation using the memory address, the system further comprising:
a progress tracker including a response reorderer and a synchronization updater, wherein the synchronization updater updates to the one or more processor cores some current information about synchronization for memory operations managed by the DMA engine. A system configured to provide to
要求生成部が、並列メモリアドレス計算周期のたびに（１）多次元テンソルのためにＭ個のメモリアドレスを並列して生成し、メモリアドレスごとに（２）前記多次元テンソルに関するメモリ操作を行うようメモリシステムに求める要求を生成するステップを含み、前記要求生成部は、Ｍ個のメモリアドレス部を含み、前記Ｍは、１以上であり、各メモリアドレス部は、ステップ追跡部と、メモリアドレス計算部とを含み、前記方法は、さらに、
前記ステップ追跡部が、前記多次元テンソルの次元ごとに（１）前記次元のステップインデックス値を生成し、前記ステップインデックス値に基づいて（２）前記次元のストライドオフセット値を生成するステップと、
各メモリアドレス部の前記メモリアドレス計算要素が、並列メモリアドレス計算周期のたびに、前記ストライドオフセット値に基づいて、前記多次元テンソルのテンソル要素のメモリアドレスを生成するステップと、
前記メモリアドレスを用いて前記メモリ操作を行うよう求める前記要求を、前記メモリシステムに送るステップとを含む、方法。 A method performed by a DMA system, comprising:
A request generation unit (1) generates M memory addresses for a multidimensional tensor in parallel for each parallel memory address calculation cycle, and (2) performs a memory operation on the multidimensional tensor for each memory address. said request generator comprising M memory address units, said M being greater than or equal to 1, each memory address unit comprising: a step tracker; a computing unit, the method further comprising:
the step tracker for each dimension of the multidimensional tensor (1) generating a step index value for the dimension and (2) generating a stride offset value for the dimension based on the step index value;
the memory address calculation elements of each memory address section generating memory addresses for tensor elements of the multi-dimensional tensor based on the stride offset values for each parallel memory address calculation period;
sending said request to said memory system to perform said memory operation using said memory address.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202062977062P | 2020-02-14 | 2020-02-14 | |
US62/977,062 | 2020-02-14 | ||
US16/838,796 US11314674B2 (en) | 2020-02-14 | 2020-04-02 | Direct memory access architecture with multi-level multi-striding |
US16/838,796 | 2020-04-02 | ||
PCT/US2020/062605 WO2021162765A1 (en) | 2020-02-14 | 2020-11-30 | Direct memory access architecture with multi-level multi-striding |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2023513652A true JP2023513652A (en) | 2023-04-03 |
JP7472277B2 JP7472277B2 (en) | 2024-04-22 |
Family
ID=77272083
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022522723A Active JP7472277B2 (en) | 2020-02-14 | 2020-11-30 | Multi-level multi-stride direct memory access architecture |
Country Status (7)
Country | Link |
---|---|
US (3) | US11314674B2 (en) |
EP (1) | EP4022450A1 (en) |
JP (1) | JP7472277B2 (en) |
KR (1) | KR20220062068A (en) |
CN (1) | CN114556311A (en) |
TW (1) | TW202131195A (en) |
WO (1) | WO2021162765A1 (en) |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11314674B2 (en) * | 2020-02-14 | 2022-04-26 | Google Llc | Direct memory access architecture with multi-level multi-striding |
US11704130B2 (en) * | 2021-08-16 | 2023-07-18 | Micron Technology, Inc. | Indexing external memory in a reconfigurable compute fabric |
CN113836049B (en) * | 2021-09-17 | 2023-08-08 | 海飞科(南京)信息技术有限公司 | Memory access method and electronic device |
CN116821019B (en) * | 2023-08-30 | 2023-11-14 | 腾讯科技（深圳）有限公司 | Data processing method, computer equipment and chip |
Family Cites Families (43)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPS6057457A (en) * | 1983-09-07 | 1985-04-03 | Ricoh Co Ltd | Dma device |
US4855903A (en) * | 1984-12-20 | 1989-08-08 | State University Of New York | Topologically-distributed-memory multiprocessor computer |
JPS63216170A (en) * | 1987-03-05 | 1988-09-08 | Mitsubishi Electric Corp | Digital signal processor |
US5361363A (en) * | 1990-10-03 | 1994-11-01 | Thinking Machines Corporation | Input/output system for parallel computer for performing parallel file transfers between selected number of input/output devices and another selected number of processing nodes |
US5659797A (en) * | 1991-06-24 | 1997-08-19 | U.S. Philips Corporation | Sparc RISC based computer system including a single chip processor with memory management and DMA units coupled to a DRAM interface |
EP0562251A2 (en) * | 1992-03-24 | 1993-09-29 | Universities Research Association, Inc. | Parallel data transfer network controlled by a dynamically reconfigurable serial network |
JPH06243113A (en) * | 1993-02-19 | 1994-09-02 | Fujitsu Ltd | Calculation model mapping method for parallel computer |
US5526501A (en) * | 1993-08-12 | 1996-06-11 | Hughes Aircraft Company | Variable accuracy indirect addressing scheme for SIMD multi-processors and apparatus implementing same |
US5628026A (en) * | 1994-12-05 | 1997-05-06 | Motorola, Inc. | Multi-dimensional data transfer in a data processing system and method therefor |
US5809334A (en) | 1996-09-24 | 1998-09-15 | Allen-Bradley Company, Llc | Receive packet pre-parsing by a DMA controller |
US6185634B1 (en) * | 1996-09-27 | 2001-02-06 | Emc Corporation | Address triggered DMA controller with an indicative signal including circuitry for calculating a new trigger address value based on the sum of the current trigger address and the descriptor register data with a trigger address register |
EP1059588A1 (en) | 1999-06-09 | 2000-12-13 | Texas Instruments Incorporated | Multi-channel dma with request scheduling |
US7035958B2 (en) * | 2002-10-03 | 2006-04-25 | International Business Machines Corporation | Re-ordering a first request within a FIFO request queue to a different queue position when the first request receives a retry response from the target |
US6874054B2 (en) | 2002-12-19 | 2005-03-29 | Emulex Design & Manufacturing Corporation | Direct memory access controller system with message-based programming |
US7331013B2 (en) * | 2004-02-18 | 2008-02-12 | Nvidia Corporation | Viterbi decoder with survivor bits stored to support look-ahead addressing |
US7165722B2 (en) * | 2004-03-10 | 2007-01-23 | Microsoft Corporation | Method and system for communicating with identification tags |
US7363397B2 (en) * | 2004-08-26 | 2008-04-22 | International Business Machines Corporation | System and method for DMA controller with multi-dimensional line-walking functionality |
US7577772B2 (en) | 2004-09-08 | 2009-08-18 | Qlogic, Corporation | Method and system for optimizing DMA channel selection |
US8843727B2 (en) | 2004-09-30 | 2014-09-23 | Intel Corporation | Performance enhancement of address translation using translation tables covering large address spaces |
US7529245B1 (en) * | 2005-04-04 | 2009-05-05 | Sun Microsystems, Inc. | Reorder mechanism for use in a relaxed order input/output system |
US20060259658A1 (en) * | 2005-05-13 | 2006-11-16 | Connor Patrick L | DMA reordering for DCA |
US20090125647A1 (en) * | 2005-06-30 | 2009-05-14 | Citibank, N.A. | Device And Method For Executing A DMA Task |
US7926046B2 (en) * | 2005-12-13 | 2011-04-12 | Soorgoli Ashok Halambi | Compiler method for extracting and accelerator template program |
US7870544B2 (en) * | 2006-04-05 | 2011-01-11 | International Business Machines Corporation | Insuring maximum code motion of accesses to DMA buffers |
TWI346873B (en) * | 2007-03-27 | 2011-08-11 | Ind Tech Res Inst | A direct memory access controller with dynamic data width adjustment, method thereof, and computer accessible storage media to store program thereof |
US20090031001A1 (en) * | 2007-07-27 | 2009-01-29 | Archer Charles J | Repeating Direct Memory Access Data Transfer Operations for Compute Nodes in a Parallel Computer |
JP2010033188A (en) * | 2008-07-25 | 2010-02-12 | Fujitsu Ltd | Transmission path selection device, data transmission system, computer device, and transmission path selection method |
US20100180100A1 (en) * | 2009-01-13 | 2010-07-15 | Mavrix Technology, Inc. | Matrix microprocessor and method of operation |
US8255593B2 (en) * | 2009-09-29 | 2012-08-28 | Oracle America, Inc. | Direct memory access with striding across memory |
JP5706754B2 (en) * | 2011-05-13 | 2015-04-22 | キヤノン株式会社 | Data processing apparatus and data processing method |
US9996500B2 (en) * | 2011-09-27 | 2018-06-12 | Renesas Electronics Corporation | Apparatus and method of a concurrent data transfer of multiple regions of interest (ROI) in an SIMD processor system |
US9094039B2 (en) * | 2013-10-18 | 2015-07-28 | Advanced Micro Devices, Inc. | Efficient deflate decompression |
US10255547B2 (en) * | 2014-12-04 | 2019-04-09 | Nvidia Corporation | Indirectly accessing sample data to perform multi-convolution operations in a parallel processing system |
US20170192720A1 (en) * | 2015-12-31 | 2017-07-06 | Arteris, Inc. | Prioritization of order ids in dram scheduling |
US10061714B2 (en) | 2016-03-18 | 2018-08-28 | Oracle International Corporation | Tuple encoding aware direct memory access engine for scratchpad enabled multicore processors |
US11055063B2 (en) | 2016-05-02 | 2021-07-06 | Marvell Asia Pte, Ltd. | Systems and methods for deep learning processor |
US9959498B1 (en) | 2016-10-27 | 2018-05-01 | Google Llc | Neural network instruction set architecture |
US10896367B2 (en) * | 2017-03-07 | 2021-01-19 | Google Llc | Depth concatenation using a matrix computation unit |
US9946539B1 (en) * | 2017-05-23 | 2018-04-17 | Google Llc | Accessing data in multi-dimensional tensors using adders |
CN108388527B (en) | 2018-02-02 | 2021-01-26 | 上海兆芯集成电路有限公司 | Direct memory access engine and method thereof |
US11101804B2 (en) * | 2019-01-22 | 2021-08-24 | Intel Corporation | Fast memory for programmable devices |
US10997102B2 (en) * | 2019-04-01 | 2021-05-04 | Wave Computing, Inc. | Multidimensional address generation for direct memory access |
US11314674B2 (en) * | 2020-02-14 | 2022-04-26 | Google Llc | Direct memory access architecture with multi-level multi-striding |
-
2020
- 2020-04-02 US US16/838,796 patent/US11314674B2/en active Active
- 2020-11-30 JP JP2022522723A patent/JP7472277B2/en active Active
- 2020-11-30 CN CN202080071556.3A patent/CN114556311A/en active Pending
- 2020-11-30 EP EP20825377.3A patent/EP4022450A1/en active Pending
- 2020-11-30 KR KR1020227011989A patent/KR20220062068A/en unknown
- 2020-11-30 WO PCT/US2020/062605 patent/WO2021162765A1/en unknown
- 2020-12-07 TW TW109143079A patent/TW202131195A/en unknown
-
2022
- 2022-04-25 US US17/728,478 patent/US11762793B2/en active Active
-
2023
- 2023-08-02 US US18/229,616 patent/US20240070098A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20210255976A1 (en) | 2021-08-19 |
KR20220062068A (en) | 2022-05-13 |
EP4022450A1 (en) | 2022-07-06 |
US11314674B2 (en) | 2022-04-26 |
WO2021162765A1 (en) | 2021-08-19 |
US11762793B2 (en) | 2023-09-19 |
TW202131195A (en) | 2021-08-16 |
US20220327075A1 (en) | 2022-10-13 |
CN114556311A (en) | 2022-05-27 |
JP7472277B2 (en) | 2024-04-22 |
US20240070098A1 (en) | 2024-02-29 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP2023513652A (en) | Direct memory access architecture with multi-level multi-stride | |
TWI528279B (en) | Multiprocessor system and method for data processing | |
KR102201935B1 (en) | Load-store instruction | |
JP2005531848A (en) | Reconfigurable streaming vector processor | |
US11816485B2 (en) | Nested loop control | |
TWI417798B (en) | High - speed reverse transfer neural network system with elastic structure and learning function | |
US11972236B1 (en) | Nested loop control | |
US10303399B2 (en) | Data processing apparatus and method for controlling vector memory accesses | |
KR20210029725A (en) | Data through gateway | |
US20200319893A1 (en) | Booting Tiles of Processing Units | |
KR102349138B1 (en) | High-speed computer accelerators with pre-programmed functions | |
CN111475205B (en) | Coarse-grained reconfigurable array structure design method based on data flow decoupling | |
US6049839A (en) | Data processor with multiple register queues | |
US10956361B2 (en) | Processor core design optimized for machine learning applications | |
JP5544856B2 (en) | Arbitration device, arbitration method, and program | |
US11599363B2 (en) | Communication in a computer having multiple processors | |
WO2022063269A1 (en) | Method and apparatus for configurable hardware accelerator | |
US20230065512A1 (en) | Pseudo-First In, First Out (FIFO) Tag Line Replacement | |
CN117597673A (en) | Data processing apparatus and method for handling stalled data | |
JPS5899868A (en) | Parallel processing system | |
JPS61221966A (en) | Vector instruction processor | |
JPH01205269A (en) | Vector processor |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20220824 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20230823 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20230926 |
|
A601 | Written request for extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A601Effective date: 20231225 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20240222 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20240312 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20240410 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7472277Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |