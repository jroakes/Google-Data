EP3752945A1 - Automatic generation of patches for security violations - Google Patents
Automatic generation of patches for security violationsInfo
- Publication number
- EP3752945A1 EP3752945A1 EP18755966.1A EP18755966A EP3752945A1 EP 3752945 A1 EP3752945 A1 EP 3752945A1 EP 18755966 A EP18755966 A EP 18755966A EP 3752945 A1 EP3752945 A1 EP 3752945A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- patch
- code
- candidate
- security violation
- inputs
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 230000015654 memory Effects 0.000 claims description 46
- 238000000034 method Methods 0.000 claims description 41
- 238000010801 machine learning Methods 0.000 claims description 6
- 238000012549 training Methods 0.000 claims description 3
- 238000005304 joining Methods 0.000 claims description 2
- 239000000872 buffer Substances 0.000 description 30
- 230000006870 function Effects 0.000 description 21
- 238000010586 diagram Methods 0.000 description 17
- 230000000875 corresponding effect Effects 0.000 description 14
- 230000006399 behavior Effects 0.000 description 11
- 230000008901 benefit Effects 0.000 description 7
- 238000005516 engineering process Methods 0.000 description 7
- 230000003068 static effect Effects 0.000 description 7
- 238000003860 storage Methods 0.000 description 7
- 238000004458 analytical method Methods 0.000 description 5
- 238000012804 iterative process Methods 0.000 description 5
- 238000012360 testing method Methods 0.000 description 5
- 238000013459 approach Methods 0.000 description 4
- VLCQZHSMCYCDJL-UHFFFAOYSA-N tribenuron methyl Chemical compound COC(=O)C1=CC=CC=C1S(=O)(=O)NC(=O)N(C)C1=NC(C)=NC(OC)=N1 VLCQZHSMCYCDJL-UHFFFAOYSA-N 0.000 description 4
- 208000021769 Acute sensory ataxic neuropathy Diseases 0.000 description 3
- 230000000903 blocking effect Effects 0.000 description 3
- 238000012552 review Methods 0.000 description 3
- 238000011161 development Methods 0.000 description 2
- 230000014509 gene expression Effects 0.000 description 2
- 238000004519 manufacturing process Methods 0.000 description 2
- 238000012545 processing Methods 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- UPLPHRJJTCUQAY-WIRWPRASSA-N 2,3-thioepoxy madol Chemical compound C([C@@H]1CC2)[C@@H]3S[C@@H]3C[C@]1(C)[C@@H]1[C@@H]2[C@@H]2CC[C@](C)(O)[C@@]2(C)CC1 UPLPHRJJTCUQAY-WIRWPRASSA-N 0.000 description 1
- 235000005733 Raphanus sativus var niger Nutrition 0.000 description 1
- 244000155437 Raphanus sativus var. niger Species 0.000 description 1
- 230000009286 beneficial effect Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000004891 communication Methods 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 238000003066 decision tree Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 238000011156 evaluation Methods 0.000 description 1
- 238000005065 mining Methods 0.000 description 1
- 238000012544 monitoring process Methods 0.000 description 1
- 230000001131 transforming effect Effects 0.000 description 1
- 238000010200 validation analysis Methods 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/57—Certifying or maintaining trusted computer platforms, e.g. secure boots or power-downs, version controls, system software checks, secure updates or assessing vulnerabilities
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/57—Certifying or maintaining trusted computer platforms, e.g. secure boots or power-downs, version controls, system software checks, secure updates or assessing vulnerabilities
- G06F21/577—Assessing vulnerabilities and evaluating computer system security
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/36—Preventing errors by testing or debugging software
- G06F11/3668—Software testing
- G06F11/3672—Test management
- G06F11/3688—Test management for test execution, e.g. scheduling of test suites
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/60—Software deployment
- G06F8/65—Updates
- G06F8/658—Incremental updates; Differential updates
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2221/00—Indexing scheme relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/03—Indexing scheme relating to G06F21/50, monitoring users, programs or devices to maintain the integrity of platforms
- G06F2221/033—Test or assess software
Definitions
- Security bugs or violations in software or application code may take significant amounts of time, for instance many months or more, and resources to fix. Efforts to find security violations yield a steady stream of such issues, so that at any given time many security violations are open or unfixed. In practice, the process of creating, testing, and deploying a fix requires an unschedulable effort by a number of human operators. Fixing these issues quickly is not feasible as long as operators are in the critical path. During the time these security violations are open, these applications remain at risk.
- security violations may include memory safety violations (such as reading data beyond a size of the buffer used for that data as this could improperly allow access to data that the application should otherwise not be accessing in order to function), input validation errors, race conditions, undefined behaviors, and so on.
- the method includes generating, by one or more processors, a plurality of inputs for code; executing, by the one or more processors, the code using the plurality of inputs to obtain execution states at a plurality of code locations, the execution states including at least one security violation for at least one of the plurality of inputs; determining, by the one or more processors using the execution states, one or more patch conditions causing the security violation; determining, by the one or more processors, using the execution states, one or more corresponding patch locations based on a code location of the plurality of code locations where the at least one security violation conditions occurred; and automatically generating, by the one or more processors, at least one candidate patch for the at least one security violation, the at least one candidate patch includes one of the patch conditions and one of the one or more corresponding patch locations.
- the method also includes generating, by the one or more processors, patched code by inserting the at least one candidate patch into the code.
- the at least one candidate patch is configured to cause the at least some of the plurality of inputs associated with the at least one security violation to fail execution.
- the at least one candidate patch causes at least part of the code to abort execution before a security violation can occur.
- the at least one candidate patch is configured to generate a log of diagnostic information for a security violation.
- the method also includes generating, by the one or more processors, a set of candidate patched codes by inserting each of the one or more candidate patches into the code; executing, by the one or more processors, each of the candidate patched codes using the plurality of inputs to obtain patched execution states at the plurality of code locations; selecting, by the one or more processors, a candidate patch among the one or more candidate patches based on the patched execution states; and generating, by the one or more processors, second patched code by inserting the selected candidate patch into the code.
- the method also includes selecting, by the one or more processors, a candidate patch from the at least one candidate patches based on at least one of complexity, proximity to a site of the at least one security violation, or impact on execution of the code and generating, by the one or more processors, patched code by inserting the selected candidate patch into the code.
- the method also includes generating, by the one or more processors, a new plurality of inputs for the patched code; executing, by the one or more processors, the patched code using the new plurality of inputs to obtain new execution states at the plurality of code locations, the new execution states including a new security violation; computing, by the one or more processors using the new execution states, one or more new patch conditions causing the new security violation associated with one or more of the plurality of inputs; determining, by the one or more processors, using the new execution states, one or more new corresponding patch locations where each of the one or more new patch conditions occur; and generating, by the one or more processors, at least one new candidate patch for the new security violation, each of the at least one new candidate patch includes one of the new patch conditions and one of the new corresponding patch locations, wherein the at least one new candidate patch is configured to cause the new violating inputs associated with the new security violation to fail execution.
- training inputs for a learning-based model are clustered based on whether the input results in a security violation.
- the one or more patch conditions are generated using a machine learning model, and the method further comprises inputs for the model are clustered based on whether the input reaches a region of interest in the code.
- determining the one or more patch conditions further comprises determining at least one dynamic invariant related to the at least one security violation.
- the dynamic invariant includes a predicate template.
- the method also includes joining two or more of the dynamic invariants in order to determine the one or more patch conditions.
- generating the one or more patch conditions further comprises determining a weakest precondition related to the at least one security violation.
- generating the one or more patch conditions further comprises tracking data flow through memory states collected by logs. In this example, tracking data flow through memory states includes using selective memory tracking.
- the system includes one or more processors configured to generate a plurality of inputs for code; execute the code using the plurality of inputs to obtain execution states at a plurality of code locations, the execution states including a security violation for at least one of the plurality of inputs; determine, using the execution states, one or more patch conditions causing the security violation; determine, using the execution states, one or more corresponding patch locations based on a code location of the plurality of code locations where the at least one security violation each of the one or more patch conditions occurred; and automatically generate at least one candidate patch for the at least one security violation, the at least one candidate patch includes one of the patch conditions and one of the one or more corresponding patch locations.
- the one or more processors are further configured to generate patched code by inserting the at least one candidate patch into the code.
- the at least one candidate patch is configured to cause the at least some of the plurality of inputs associated with the at least security violation to fail execution and at least part of the code to abort execution before a security violation can occur.
- the at least one candidate patch is configured to generate a log of diagnostic information for a security violation.
- Such features are advantageous because they may be used to protect vulnerable code from attack via security violations even before a full fix is available. These feature provide for automatic generation of patches for security violations without having to wait for a full fix by operators. These patches, while not fixing the program’s logic entirely, may cause the code to abort before a security violation occurs, thereby hardening or protecting the code from exploitation. This has the advantage to bring the time to mitigate potential exploitation down from months to hours. Further, the patches may have alternative or additional functions such as collecting data for better forensic analyses and displaying security violations to warn developers and users.
- FIGURE 1 is a block diagram illustrating an example system according to aspects of the disclosure.
- FIGURE 2 is an example functional diagram in accordance with aspects of the disclosure.
- FIGURES 3A-3B are examples of code and patched code in accordance with aspects of the disclosure.
- FIGURES 4A-4B are examples of code and patched code in accordance with aspects of the disclosure.
- FIGURE 5 is an example of code in accordance with aspects of the disclosure.
- FIGURE 6 is an example of code in accordance with aspects of the disclosure.
- FIGURE 7 is an example of code in accordance with aspects of the disclosure.
- FIGURES 8A-8B are examples of code and patched code in accordance with aspects of the disclosure.
- FIGURE 9 is an example functional diagram in accordance with aspects of the disclosure.
- FIGURE 10 is an example of code in accordance with aspects of the disclosure.
- FIGURE 11 is an example functional diagram in accordance with aspects of the disclosure.
- FIGURE 12 is an example functional diagram in accordance with aspects of the disclosure.
- FIGURE 13 is an example functional diagram in accordance with aspects of the disclosure.
- FIGURE 14 is an example functional diagram in accordance with aspects of the disclosure.
- FIGURE 15 is a flow chart illustrating an example method according to aspects of the disclosure. DETAILED DESCRIPTION
- the technology generally relates to automatically generating patches for security vulnerabilities in computer code.
- Security violations may regularly be detected during development and after deployment of the code. While some system may implement automation for finding security violations at a large scale, these systems lack the ability to automatically mitigate the impact of known security violations. A lack of automation to fix the found issues may cause security violations to languish as operators manually address them. Moreover, the process of creating, testing, and deploying a full fix, which likely involves team effort, may take a significant amount of time. The process may therefore leave the code vulnerable to attack, potentially for days or even months.
- patches for security violations or vulnerabilities may be especially useful. These patches, while not fixing an application’s logic entirely, may be used to cause an application to abort before a security vulnerability occurs, thereby hardening the application from exploitation, in some cases indefinitely, but ideally until a full and complete fix is deployed. This has the potential to bring the time to mitigate potential exploitation down from months to hours or even less.
- a patch for the security violation may be automatically generated. For instance, inputs may be generated for the code using fuzzing techniques. The code may then be executed using each of the generated inputs. For each execution, states at various code locations may be monitored including whether or not security violations have occurred. The code, the generated inputs, and the execution states may be analyzed to determine conditions that likely caused the security violation associated with one or more of the inputs as well as to determine corresponding patch locations where the conditions are likely to occur. Based on these evaluations, at least one candidate patch may be generated for a security violation. The candidate patch may include a patch condition and one of the corresponding patch locations. The at least one candidate patch may cause the violating inputs associated with the security violation to fail execution and/or log the execution in order to allow operators to observe the issue in real-time and further investigate using the log.
- the technology described herein is advantageous because it protects vulnerable code from attack via security violations even before a full fix is available.
- the technology provides automatic generation of patches for security violations without having to wait for a full fix by operators. These patches, while not fixing the program’s logic entirely, may cause the code to abort before a security violation occurs, thereby hardening or protecting the code from exploitation. This has the advantage to bring the time to mitigate potential exploitation down from months to hours.
- heuristics and machine learning may be used to select automatically generated patches that block security violations, but still allow passing execution with non-violating inputs.
- the technology further provides iterative processes to validate the generated patch, analyze the impact of the patch, and produce more suitable patches for selection.
- a plurality of inputs may be generated for computer code.
- the code may be executed using the plurality of inputs to obtain execution states at a plurality of code locations.
- the execution states may include at least one security violation for at least one of the plurality of inputs.
- one or more patch conditions causing the at least one security violation may be determined.
- one or more corresponding patch locations may be determined based on a code location of the plurality of code locations where the at least one security violation each of the one or more patch conditions occurred.
- At least one candidate patch for the security violation may be automatically generated.
- the at least one candidate patch may include one of the patch conditions and one of the corresponding patch locations.
- FIGURE 1 includes an example system 100 in which the features described herein may be implemented. It should not be considered as limiting the scope of the disclosure or usefulness of the features described herein.
- system 100 can include computing devices 110, 120, 130 and storage system 140 connected via a network 150.
- Each computing device 110, 120, 130 can contain one or more processors 112, memory 114 and other components typically present in general purpose computing devices.
- system 100 Although only a few computing devices and a storage systems are depicted in the system 100, the system may be expanded to any number of additional devices. In addition to a system including a plurality of computing devices and storage systems connected via a network, the features described herein may be equally applicable to other types of devices such as individual chips, including those incorporating System on Chip (Soc) or other chips with memory.
- Soc System on Chip
- Memory 114 of each of computing devices 110, 120, 130 can store information accessible by the one or more processors 112, including instructions that can be executed by the one or more processors.
- the memory can also include data that can be retrieved, manipulated or stored by the processor.
- the memory can be of any non-transitory type capable of storing information accessible by the processor, such as a hard-drive, memory card, ROM, RAM, DVD, CD-ROM, write-capable, and read-only memories.
- the instructions can be any set of instructions to be executed directly, such as machine code, or indirectly, such as scripts, by the one or more processors.
- the terms "instructions,” “application,” “steps,” and “programs” can be used interchangeably herein.
- the instructions can be stored in object code format for direct processing by a processor, such as the one or more processors 112, or in any other computing device language including scripts or collections of independent source code modules that are interpreted on demand or compiled in advance. Functions, methods, and routines of the instructions are explained in more detail below.
- Data may be retrieved, stored or modified by the one or more processors 112 in accordance with the instructions.
- the data can be stored in computer registers, in a relational database as a table having many different fields and records, or XML documents.
- the data can also be formatted in any computing device-readable format such as, but not limited to, binary values, ASCII or Unicode.
- the data can comprise any information sufficient to identify the relevant information, such as numbers, descriptive text, proprietary codes, pointers, references to data stored in other memories such as at other network locations, or information that is used by a function to calculate the relevant data.
- the one or more processors 112 can be any conventional processors, such as a commercially available CPU. Alternatively, the processors can be dedicated components such as an application specific integrated circuit ("ASIC") or other hardware-based processor. Although not necessary, one or more of computing devices 110 may include specialized hardware components to perform specific computing processes, such as decoding video, matching video frames with images, distorting videos, encoding distorted videos, etc. faster or more efficiently.
- ASIC application specific integrated circuit
- Figure 1 functionally illustrates the processor, memory, and other elements of computing device 110 as being within the same block
- the processor, computer, computing device, or memory can actually comprise multiple processors, computers, computing devices, or memories that may or may not be stored within the same physical housing.
- the memory can be a hard drive or other storage media located in housings different from that of the computing devices 110.
- references to a processor, computer, computing device, or memory will be understood to include references to a collection of processors, computers, computing devices, or memories that may or may not operate in parallel.
- the computing devices 110 may include server computing devices operating as a load-balanced server farm, distributed system, etc.
- some functions described below are indicated as taking place on a single computing device having a single processor, various aspects of the subject matter described herein can be implemented by a plurality of computing devices, for example, communicating information over network 150.
- Each of the computing devices 110, 120, 130 can be at different nodes of a network 150 and capable of directly and indirectly communicating with other nodes of network 150. Although only a few computing devices are depicted in FIGURE 1 , it should be appreciated that a typical system can include a large number of connected computing devices, with each different computing device being at a different node of the network 150.
- each of computing devices 110, 120, 130 may be server computing devices that are part of a load-balanced server farm.
- the network 150 and intervening nodes described herein can be interconnected using various protocols and systems, such that the network can be part of the Internet, World Wide Web, specific intranets, wide area networks, or local networks.
- the network can utilize standard communications protocols, such as Ethernet, WiFi and F1TTP, protocols that are proprietary to one or more companies, and various combinations of the foregoing.
- the storage system 140 may also store information that can be accessed by any of the computing devices 110, 120, and/or 130. Flowever, in this case, the storage system 140 may store information that can be accessed over the network 150. As with the memory, the storage system can include any non-transitory type capable of storing information accessible by the processor, such as a hard-drive, memory card, ROM, RAM, DVD, CD-ROM, write-capable, and read only memories.
- each of computing devices 110, 120, 130 may include one or more applications. These applications may include code that can be run in order to perform various tasks. At least some of this code may be vulnerable to attacks from third parties looking to steal information, slow down processing speeds, or otherwise cause havoc.
- the applications may include a“patch generator” 280 (shown in FIGURE 2 as“program metadata” 270) configured to automatically generates patches based on any of a variety types of data (shown in FIGURE 2 as“program metadata” 270), a“code-miner” (shown in FIGURE 2 as“code-miner” 240) with generates at least some of the program metadata, a“candidate selector” (shown in FIGURE 11 as candidate selector 1110) which selects or determines a winning patch from the candidate patches, as well as various other instructions as discussed further below.
- a“patch generator” 280 shown in FIGURE 2 as“program metadata” 270
- a“code-miner” shown in FIGURE 2 as“code-miner” 240
- a“candidate selector” shown in FIGURE 11 as candidate selector 1110 which selects or determines a winning patch from the candidate patches, as well as various other instructions as discussed further below.
- FIGURE 2 is an example functional diagram 200 that identifies aspects of candidate patch generation for a set of code 210.
- test corpus 220 of FIGURE 2 may include the generated inputs discussed above.
- the code may then be executed using each of the generated inputs. For each execution, execution states at various code locations may be monitored. For instance, the code locations may involve transforming or moving data in various steps. Over the course of the program execution through these code locations, memory allocations and deallocations may be tracked in metadata and updated.
- This metadata may include information such as size of applicable memory regions as well as some content information (such as potential null-termination of strings).
- the metadata may be used to track for every pointer, which base pointer and thus which memory allocation, it is pointing to. Thus, for any memory access, the metadata may identify the size of the allocated memory region. As such, when executing the code, the metadata is essentially collection or print out of log of diagnostic information for every accessed memory region.
- this diagnostic information may include: identifying compiler infrastructure or LLVM debug information, such as program location, variable information, accessed memory byte address, starting address of the accessed memory region (or 0, if invalid access), ending address of the accessed memory region (or 0, if invalid access), next Null- terminating character of accessed memory byte (or -1, if not applicable), and other such information.
- identifying compiler infrastructure or LLVM debug information such as program location, variable information, accessed memory byte address, starting address of the accessed memory region (or 0, if invalid access), ending address of the accessed memory region (or 0, if invalid access), next Null- terminating character of accessed memory byte (or -1, if not applicable), and other such information.
- the states may indicate whether or not a security violation has occurred and also whether the execution is overall a“non-crashing execution” with no security violation or a“crashing execution” with a security violation.
- Examples of crashing executions may include heap buffer overflows, static memory overflows, use-after-frees, as well as other runtime issues leading to undefined behaviors.
- For each type of crashing execution there may be a set of commonly occurring patterns of patches to consider. These patterns may be encoded as template patches for which a proper instantiation to the code being patched needs to be discovered.
- the code, the generated inputs, and the execution states may be analyzed to determine conditions that likely caused the security violation associated with one or more of the inputs.
- a code miner such as code-miner 240 of FIGURE 2
- FIGURE 4 A is an example of a sample code with a C string bug which would result in a crashing execution.
- the code miner may be used to identify a plurality of conditions including: string length of result->content is the same as string length of content; String length of result->content is the same as result->length; string length of content is the same as result->length; allocation size of result->content is 1 more than string length of result->content; allocation size of result->content is 1 more than result->length; etc.
- string length of result->content is the same as string length of content
- string length of content is the same as result->length
- allocation size of result->content is 1 more than string length of result->content
- allocation size of result->content is 1 more than result->length
- the code-miner may also generate patch conditions or invariants for these conditions.
- the code-miner 240 may generate“crashing invariants” 250 and“non-crashing invariants” 260 which are then incorporated into the program metadata 270 as inputs to the patch generator 280.
- the crashing and non-crashing invariants generated by the code-miner may be dynamic invariants, as statically computing invariants may be too imprecise for features such as non-normalized loops or recursive functions.
- a dynamic invariant may be an abstract representation of a condition that apply to a set of executions of the code, while a static invariant may be computed statically over all paths of the program.
- Dynamic invariants from across multiple executions may be joined to create more complex dynamic invariants and therefore more complex patches. These crashing invariants and non-crashing invariants may be incorporated into the program metadata that is input into the patch generator.
- Dynamic invariants may be determined in various ways. For instance, dynamic invariants may be determined based on user input. In some instances, it is advantageous to employ one or more machine learning techniques to determine differences, correlations, and invariants between the non-crashing and crashing executions, such as Daikon, decision trees, classifiers, etc. For instance, the generated inputs and the metadata described above may be used to train a model. In some instances, as training inputs for a machine learning model, the generated inputs may be clustered based on whether they result in security violations at different code locations and/or failing executions. The generated inputs may be further clustered based on whether they reach a certain region of interest in the code.
- the patch generator such as patch generator 280 of FIGURE 2, may then automatically generate a patch, such as candidate patch 290, from the program metadata 270.
- the candidate patch may include a patch condition and a patch location.
- the at least one candidate patch may cause the violating inputs associated with the security violation to fail execution and/or log the execution in order to allow operators to observe the issue in real-time and to further investigate using the log as discussed further below.
- the patch generator 280 may generate a candidate patch by computing a difference between the crashing invariants and the non-crashing invariants. In other words, by analyzing the passing and failing executions, the differences in the values of the variables (i.e., the differences in the dynamic invariants) can be determined. This may allow the patch generator 280 generate a patch, for instance, if the size of the buffer is already being tracked within an existing variable which is in-scope at the point of the buffer-overflow.
- the patches may be generated using the computed differences, at least some of which will correspond to pre-defined templates. For instance, based on the differences between the execution states for the passing and failing executions, and the type of crash being observed, a template may be identified. These templates may include various conditions that may resemble “some_variable ⁇ some_other_variable”. In the foregoing examples, the all capitalized values represent “symbolic conditions” of a template for a patch that do not necessarily otherwise exist in the code. As one example, a template may be“BUFFER_INDEX ⁇ BUFFER_SIZE”. This template may be identified when there is a buffer overflow, or where the code attempts to read a buffer at a location beyond the length of the buffer. As noted above, both BUFFER_INDEX and BUFFER_SIZE may be“symbolic conditions,” that is, conditions that are not necessarily in the code that represent the buffer index and buffer size of a buffer used in the code.
- a template may be may be“ptr_arithmetic_expression ⁇ BASE_POINTER + BUFFER_SIZE”. This template may be identified in the case of a buffer overflow caused by a pointer- arithmetic error.
- "ptr_arithmetic_expression” may correspond to a computation the code performs in order to index into memory, and both BASE_POINTER and BUFFER_SIZE may be “symbolic conditions” that are not necessarily in the code that represent the base pointer and buffer size of a buffer used in the code.
- FIGURE 5 is an example of a simple code.
- a buffer overflow security violation occurs due to pointer arithmetic going out-of-bounds of the end of a buffer.
- the security violation occurs within DuplicateLastValue if the buffer pointed to by dest is the same size or smaller than the size parameter to the function the dest buffer will overflow.
- proper use of the function is in the function NonBuggyUser: the buffer str contains three elements, a new buffer duplicated is created to be of size four, and both ‘str’ and ‘duplicated’ are passed to DuplicateLastValue.
- size of ‘str’ and‘duplicated’ are the same.
- the template ptr_arithmetic_expression ⁇ BASE_POINTER + BUFFER_SIZE may be identified, and here, 'ptr_arithmetic_expression' is 'dest + size'.
- the BASE_POINTER and BUFFER_SIZE are from either BuggyUser() or NonBuggyUser().
- the generated patch (after adjusting for weakest precondition discussed further below) may be placed in NonBuggyUser.
- a template may be BUFFER_SIZE ⁇ STRLEN_SRC. This template may be identified when there is a string buffer overflow, where STRLEN_SRC refers to the length of a string being read from. Such security violations may occur when C string libraries expect string buffers to be null-terminated.
- FIGURE 6 is an example of a simple code.
- a buffer overflow occurs within the call to‘strcpy’ in the BuggyStrCpyO function.
- the C-standard strcpy function copies from‘src’ to‘dest’ until a null-terminator is read in‘src’.
- the template BUFFER_SIZE > STRLEN_SRC may be identified.
- BUFFER_SIZE is the size of the buffer passed as the dest argument to ‘strcpy’
- STRLEN_SRC is the string- length length of the‘src’ argument to‘strcpy’.
- strlen(src) for STRLEN_src.
- strlen function requires that src be null-terminated. This can be determined from the execution states of both passing and failing executions on the contents of‘src’. This type of template can be used to patch errors caused by a lack of null-terminator on a buffer.
- Aliasing relationships may be captured dynamically using symbolic conditions capturing that a specific pointer must point to certain memory iocation(s). For example, this may be useful in determining that a pointer within the code points only to a buffer which is used in a crash. This is useful since pointer variables may point-to multiple memory locations, e.g., within a function with a pointer argument which is passed multiple distinct memory locations.
- a template may not be required since the patch generate may simply lookup the type.
- FIGURE 7 provides an example of a simple code where an error occurs down a particular branch within a function.
- the code reads uninitialized memory when 'c' is false. Since the general concept of reading uninitialized memory would not fit a template, in this example, the patch generator may fall back on mining differences between the passing and failing executions. In this case, the error only occurs when 'buffer' is read and 'c' is false. Again certain heuristics will likely be useful in these cases, e.g., restricting the variables used within the crash to be defined“close” to where the crash occurs (e.g., within the same function, within the same library/compilation-unit, within N-callframes of the error stack trace). This may prevent spurious differences from being included in the patch, e.g., changes in global variables.
- any of the“symbolic conditions” of the template for the security violation may first be set. For instance, in many cases the variables required for a patch do not actually exist in the program, for example, the size of the buffer is not actually being tracked explicitly. As such, these symbolic conditions allow insert variables into the program (the symbolic ones) in order to use these symbolic conditions to simplify the generation of the patch. As such, the symbolic conditions represent conditions or values that result in occurrence (or absence) of the security violation and can be used as the basis for defining the actual code that constitutes the candidate patch.
- the patches may be generated by selecting template language or expressions that are then customized to trigger or avoid the security violation by causing (or preventing) the symbolic condition(s) from occurring or exiting execution if the symbolic conditions occur.
- an identified template may include BUFFER_INDEX ⁇ BUFFER_SIZE.
- a symbolic condition for buffer overflow may be set as 0 ⁇ BUFFER_INDEX ⁇ BUFFER_SIZE.
- FIGURE 3A provides an example code.
- ‘idx’ is BUFFER_INDEX.
- ‘length’ is BUFFER_SIZE.
- variable in the code contains BUFFER_INDEX or BUFFER_SIZE that was causing the security violation, in fact, the code itself may have no actual variable containing either BUFFER_INDEX or BUFFER_SIZE.
- the symbolic condition of 0 ⁇ BUFFER_INDEX ⁇ BUFFER_SIZE must be concretized by substituting in actual variables in the code or actual values during execution.
- non-crashing executions for the TrimTrailingCharacter function may all guarantee that str->length is bigger than 0 when the function is entered, whereas crashing executions at this line enter with str->length set to 0.
- a potential learned patch would be to add a crash before str->length is decremented to make sure it is not 0.
- Another interesting difference in the learned relationships would be at the point of the memory access. All non-crashing executions at that point guarantee that the string length of str->content is equal to the value of str->length. This is not true in the crashing executions.
- a patch may be generated by the patch generator for after the decrement operation, which checks this relationship.
- the patch generator 280 may generate candidate patches for different conditions in various ways. For instance, two competing patches are shown in the example patched code of FIGURE 4B (merged into a single example for simplicity though when in use, only a single patch is needed). By generating multiple patch conditions and different versions of the patched program, these can be compared them against one another. This may be useful to guard against bugs in the patch generation process which may otherwise cause bad patch proposals, for example.
- the code, the generated inputs, and the execution states may also be analyzed by the patch generator to determine corresponding patch locations where the patch conditions are likely to occur. For instance, patches may be inserted immediately before the code locations where the security violations or undesired behaviors are observed.
- FIGURE 8A is an example of a simple code.
- the function RoundedAngle returns a value within [0, 360) or fails with an error code if the parameter angle is negative.
- This function may be assumed to be used in some code or application, where the value of the parameter angle can be provided in some way by a programmer.
- an input is discovered that causes undefined behavior when executing this code.
- a floating-point value that is larger than the maximally representable integer (or a not-a-number value, also known as NaN) is passed in as parameter angle.
- UBSAN UndefinedBehaviorSanitizer
- UBSAN UndefinedBehaviorSanitizer
- this execution may identity that the undefined behavior occurs due to the fact that the value of the parameter angle was too large.
- a patch such as the patch of the example patched code of FIGURE 8B, may be generated.
- a program abort is introduced as a check before the code location where the bad cast occurred. The introduced check is very syntactic in such scenarios, and can easily be automated.
- Other typical cases may include handling of C strings, where a patch for a buffer overflow could be described as a missing null-terminating character or expected range checks. Checks could also contain regular expression matching for certain types of errors.
- Each of the candidate patches may be inserted into the code at the locations of the candidate patches to create a set of candidate patched codes. Then, each of the candidate patched codes may be executed using generated inputs to obtain patched execution states. This may allow for the identification of changes between the execution states and patched execution states for the same generated inputs.
- the patch of FIGURE 8B introduces a program abort at the point of failure. It checks that the upcoming cast from the floating-point variable angle is too large for the type int ( std::numeric_limits ⁇ int>::max() returning the largest representable number of type int ). If that conditions fails, the LOG_IF statement will log the error message“Auto generated path to avoid undefined behavior due to overflow.” As such, the execution will abort due to the use of the FATAL logging level.
- the candidate patch is especially beneficial in that it only patches the undesired behavior.
- Approaches that do not rely on actual executions may have also generated a check on underflow behavior. That is, such approaches would likely have tried to introduce a check that also makes sure that negative angles are too big in absolute terms. As the generated inputs did not result in, no such patch would be proposed. The reason the this would not occur, of course, is due to the fact that any negative angle value does not reach the cast due to the earlier check in the program.
- a candidate patch may be generated for a security violation by determining weakest preconditions based on the aforementioned templates as discussed above.
- FIGURE 9 is an example functional diagram 900 that identifies aspects of candidate patch generation for a set of code 210 utilizing weakest preconditions 940. As shown, the weakest preconditions may also be incorporated into the program metadata 270 which is input into the patch generator 280 in order to generate a candidate patch 990.
- a weakest precondition may be a formula that describes a set of program states or program inputs that exhibit a certain common behavior. As with invariants, weakest preconditions may also be computed statically or dynamically and at every execution stage of the code. A weakest precondition for a security violation at an execution stage may imply that if the weakest precondition is true, the execution will lead to the security violation assuming that all nondeterministic choices, such as thread schedules, are not altered in the re-execution.
- FIGURE 10 is an example of a simple program in order to further illustrate weakest condition.
- randl00() returns a random number between [0, 100).
- a crash, CRASFl() is assumed to occur when x2 was 95, and y2 was 80.
- the goal is to determine a condition on the return values of the calls to randl00() rather than at the location of an actual crash.
- condition x2>y2 can be expressed as x>l0*y-2.
- This generalized condition may be the weakest precondition and represents many more cases, such as for example, any value for x if and only if y is 0. Since a crash was observed, there is at least one input that causes the crash to occur; the weakest precondition will never be empty. At a minimum, the weakest precondition would contain at least the single crashing input used to generate the weakest condition though this is unlikely to occur as generalization from a single crashing input will often cover a variety of different possible conditions.
- Weakest preconditions can be computed along the whole execution trace or rather at every program execution stage in a crashing run. Such a weakest precondition at a execution stage may imply that if the condition is true, the execution will definitely run into the same exact crash again assuming that all nondeterministic choices, such as thread schedules, are not altered in the re-execution. That is, a weakest precondition of a crashing run at some program point can be used to effectively predict a security violation.
- the weakest preconditions provide advantages in this context as the weakest preconditions can be computed locally to the crash-site (i.e. the location in the code at which an execution crashed). The closer to the crash-site the condition can be expressed, the more likely the weakest precondition is to be less complex and thus more readable.
- a user that develops a library XYZ which depends on features of another library ABC.
- library ABC also depends on library DEF.
- library XYZ is being fuzzed, a security violation is observed in library DEF. In this situation, the security violation is now“two dependencies deep.” The user is most likely interested in identifying security violations in library XYZ, as the user is developing that code.
- the patch generator may generate candidate patches based on tracking data flow through memory states collected by sanitizer logs.
- FIGURE 11 is an example functional diagram 1100 that identifies aspects of candidate patch generation for a set of code 210 utilizing sanitizer logs 1140. As shown, the sanitizer logs may also be incorporated into the program metadata 270 which is input into the patch generator 280 in order to generate a candidate patch 1190.
- ASAN may be used to keep track of such memory data. Since ASAN is only used for patch generation and not during production, there may be very little or no impact on performance in production. Further, even during patch generation, selective memory tracking may be used. For instance, ASAN may be selectively turned on only for certain code locations or variables to minimize impact on performance. Other runtime monitoring techniques may also be used, such as Valgrind or other FFVM sanitizers.
- the patch generator may generate candidate patches based on static information.
- variable names and variable types may be used as additional information for generating the patch.
- the concretization of symbolic conditions with variables in the code may be based on such static information.
- some weakest preconditions may also be computed statically.
- some invariants may also be computed statically.
- FIGURE 12 is an example functional diagram 1200 that identifies aspects of candidate patch generation for a set of code 210 utilizing static information 1240.
- the static information may also be incorporated into the program metadata 270 which is input into the patch generator 280 in order to generate a candidate patch 1290.
- the patch generator may thus generate candidate patches using the program metadata.
- FIGURE 13 is an example functional diagram 1300 where the program metadata 270 includes a combination of crashing invariants 250, non-crashing invariants 260, sanitizer logs 1140, static information 1240 or any combination of these. Again, this program metadata is input into the patch generator 280 in order to generate a candidate patch 1390.
- the patch generation process may be an iterative process. For example, after the code is patched using one of the candidate patches, a new set of violating and non-violating inputs may be generated for the patched code using new generated inputs. As with the example above, these generated inputs may be generated using fuzzing techniques.
- the patched code may be executed using the new generated inputs. Again, for each execution, states at various code locations are monitored. For example, the states may show that some of the new inputs cause a new security violation.
- the new security violation may be the same security violation as before the patch, a different security violation that is correlated to the security violation before the patch, or a different unrelated security violation.
- the program metadata 270 which include the code, the patched code, the generated inputs for the code, the generated inputs for the patched code, the execution states using the code, and the execution states using the patched code.
- the program metadata 270 may then be analyzed to determine new patch conditions that likely caused the new security violation as well the corresponding patch locations where the new patch conditions likely occurred. Based on these analyses, at least one new candidate patch may be generated for the new security violation.
- an iterative process may be used to determine incremental impact of the candidate patch. For example, non-violating inputs for the code before the patch should still be non- violating when used in an execution of the patched code. This way it is ensured that the patch does not cause an otherwise passing execution to fail. If non- violating inputs for the code before the patch are now somehow causing violations when used in an execution of the patched code, this means that the candidate patch had introduced an execution failure to the code and is therefore not a good candidate patch.
- an iterative process may be used. The process may begin by generating a plurality of candidate patches using the same approach with different sets of inputs and/or using different approaches as described above. As shown in the example functional diagram 1400 of FIGURE 14,“Patch Generator 1” may generate a first candidate patch using template-based weakest preconditions,“Patch Generator 2” may generate a second candidate patch using template-based dynamic invariants,“Patch Generator N” may generate the“N h ” candidate patch using the same code-miner, but with a different set of generated inputs, etc.
- each of the patch generators of FIGURE 14 may correspond to the patch generator 280 in that it is an identical instance or the same instance.
- candidate patches 1 , 2, and N may correspond to any of candidate patches 290, 990, 1190, 1290, or 1390.
- the candidate patches as well as the test corpus 220 may be input into a candidate selector, such as candidate selector 1410, which selects or determines a winning patch from the candidate patches.
- a winning candidate patch 1490 may be determined based on the patched execution states, for example, a suitable candidate patch may be one that causes the violating inputs associated with the security violation to fail execution but still allows all of the non- violating inputs to pass execution. As an example, one candidate patch may slow down performance less than the other candidate patches and may therefore be a suitable candidate patch.
- a winning candidate patch may also be selected based on complexity of the candidate patch and/or the proximity of the candidate patch to site of the security violation. For instance, if a candidate patch has a very complex patch condition, operators may be reluctant to accept the candidate patch because it may be difficult to fully understand the effects of the candidate patch on the code. For another instance, although a security violation may occur due to a misuse of a very low- level library, a candidate patch having a patch location at such a low-level library may cause problems for many other codes sharing the same library, and therefore the candidate patch is not suitable and should not be a winning patch.
- the winning patch may be inserted into the code at the location of the patch in order to cause the code to produce any number of desired results for inputs which would have previously resulted in a security violation.
- the winning patch may be a blocking patch that causes at least part of the code to abort execution before the security violation occurs.
- the winning patch may be a diagnostic patch that causes data about the security violation to be collected or otherwise logged for immediate or later review.
- winning patch may cause a display of information on the security violation to be generated. Such a display may appear, for instance, as visual and/or audible warnings on a computing device of an operator or user to prompt appropriate actions.
- Such patches may also allow operators to observe the impact of the security violation in real-time and to decide whether to ignore the security violation, allow a blocking patch to be inserted, or to develop a full fix. For instance, instead of simply logging the security violation or displaying a notification in real time, a counter may be used to track how often a particular security violation has occurred. These counters for the different security violations may be viewed in real time, for instance, by providing a graphical user interface or other visual and/or audible representation of these numbers for review by an operator. This, in turn, may assist an operator in prioritizing security violations for review and/or fixing as well as to assist an operator in determining which security violations are or are likely to become emergent problems.
- FIGURE 12 is an example flow diagram 1200 for automatically generating patches for security violations in accordance with aspects of the disclosure.
- the blocks of the flow diagram may be performed by one or more processors, such as one or more processors 112.
- a plurality of inputs for a code is generated at block 1210.
- the code is executed using the plurality of inputs to obtain execution states at a plurality of code locations stages at block 1220.
- These execution states include at least one security violation for at least one of the plurality of inputs.
- one or more patch conditions causing the at least one security violation are determined.
- one or more corresponding patch locations where each of the one or more patch conditions occur are determined based on a code location of the plurality of code locations where the at least one security violation each of the one or more patch conditions occurred.
- At least one candidate patch for the security violation is automatically generated at block 1250.
- Each of the at least one candidate patch includes one of the patch conditions and one of the corresponding patch locations.
- the technology described herein is advantageous because it protects vulnerable code from attack via security violations even before a full fix is available.
- the technology provides automatic generation of patches for security violations without having to wait for a full fix by operators. These patches, while not fixing the program’s logic entirely, may cause the code to abort before a security violation occurs, thereby hardening or protecting the code from exploitation. This has the advantage to bring the time to mitigate potential exploitation down from months to hours.
- the technology further provides iterative processes to validate the generated patch, analyze the impact of the patch, and produce more suitable patches for selection. Further, the patches may have alternative or additional functions such as collecting data for better forensic analyses and displaying security violations to warn developers and users.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862674133P | 2018-05-21 | 2018-05-21 | |
PCT/US2018/042448 WO2019226188A1 (en) | 2018-05-21 | 2018-07-17 | Automatic generation of patches for security violations |
Publications (1)
Publication Number | Publication Date |
---|---|
EP3752945A1 true EP3752945A1 (en) | 2020-12-23 |
Family
ID=63244967
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP18755966.1A Pending EP3752945A1 (en) | 2018-05-21 | 2018-07-17 | Automatic generation of patches for security violations |
Country Status (4)
Country | Link |
---|---|
US (1) | US20210004470A1 (en) |
EP (1) | EP3752945A1 (en) |
CN (1) | CN111919214A (en) |
WO (1) | WO2019226188A1 (en) |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11580234B2 (en) | 2019-06-29 | 2023-02-14 | Intel Corporation | Implicit integrity for cryptographic computing |
US11575504B2 (en) | 2019-06-29 | 2023-02-07 | Intel Corporation | Cryptographic computing engine for memory load and store units of a microarchitecture pipeline |
US11669625B2 (en) * | 2020-12-26 | 2023-06-06 | Intel Corporation | Data type based cryptographic computing |
US11580035B2 (en) | 2020-12-26 | 2023-02-14 | Intel Corporation | Fine-grained stack protection using cryptographic computing |
Family Cites Families (25)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP1619572A1 (en) * | 2004-07-23 | 2006-01-25 | Texas Instruments Incorporated | System and method of identifying and preventing security violations within a computing system |
US8146072B2 (en) * | 2004-07-30 | 2012-03-27 | Hewlett-Packard Development Company, L.P. | System and method for updating software on a computer |
US7814473B2 (en) * | 2004-10-27 | 2010-10-12 | Oracle International Corporation | Feature usage based target patching |
US7765538B2 (en) * | 2004-10-29 | 2010-07-27 | Hewlett-Packard Development Company, L.P. | Method and apparatus for determining which program patches to recommend for installation |
US7512936B2 (en) * | 2004-12-17 | 2009-03-31 | Sap Aktiengesellschaft | Code diversification |
CN101154257A (en) * | 2007-08-14 | 2008-04-02 | 电子科技大学 | Dynamic mend performing method based on characteristics of loopholes |
US8613096B2 (en) * | 2007-11-30 | 2013-12-17 | Microsoft Corporation | Automatic data patch generation for unknown vulnerabilities |
US8037529B1 (en) * | 2008-03-19 | 2011-10-11 | Symantec Corporation | Buffer overflow vulnerability detection and patch generation system and method |
US8108931B1 (en) * | 2008-03-31 | 2012-01-31 | Symantec Corporation | Method and apparatus for identifying invariants to detect software tampering |
US8296756B1 (en) * | 2009-11-06 | 2012-10-23 | Southern Company Services, Inc. | Patch cycle master records management and server maintenance system |
US8726394B2 (en) * | 2009-12-15 | 2014-05-13 | Seeker Security Ltd. | Method and system of runtime analysis |
US9063818B1 (en) * | 2011-03-16 | 2015-06-23 | Google Inc. | Automated software updating based on prior activity |
US9135405B2 (en) * | 2011-05-26 | 2015-09-15 | Carnegie Mellon University | Automated exploit generation |
US9032530B2 (en) * | 2012-09-28 | 2015-05-12 | International Business Machines Corporation | Correcting workflow security vulnerabilities via static analysis and virtual patching |
US10587641B2 (en) * | 2014-05-20 | 2020-03-10 | Micro Focus Llc | Point-wise protection of application using runtime agent and dynamic security analysis |
US9971671B2 (en) * | 2014-09-26 | 2018-05-15 | Oracle International Corporation | System and method for dynamic debugging in a multitenant application server environment |
US9792443B1 (en) * | 2015-03-12 | 2017-10-17 | Whitehat Security, Inc. | Position analysis of source code vulnerabilities |
US10282550B1 (en) * | 2015-03-12 | 2019-05-07 | Whitehat Security, Inc. | Auto-remediation workflow for computer security testing |
US10628764B1 (en) * | 2015-09-15 | 2020-04-21 | Synack, Inc. | Method of automatically generating tasks using control computer |
US10783241B2 (en) * | 2015-10-28 | 2020-09-22 | Qomplx, Inc. | System and methods for sandboxed malware analysis and automated patch development, deployment and validation |
US10033534B2 (en) * | 2015-12-01 | 2018-07-24 | Intel Corporation | Methods and apparatus to provide for efficient and secure software updates |
CN105787367B (en) * | 2016-02-23 | 2018-09-21 | 华中科技大学 | A kind of the patch safety detecting method and system of software upgrading |
US20180129579A1 (en) * | 2016-11-10 | 2018-05-10 | Nec Laboratories America, Inc. | Systems and Methods with a Realtime Log Analysis Framework |
US20190102564A1 (en) * | 2017-10-02 | 2019-04-04 | Board Of Trustees Of The University Of Arkansas | Automated Security Patch and Vulnerability Remediation Tool for Electric Utilities |
US10708292B2 (en) * | 2017-11-28 | 2020-07-07 | Aetna Inc. | Vulnerability contextualization |
-
2018
- 2018-07-17 CN CN201880091955.9A patent/CN111919214A/en active Pending
- 2018-07-17 US US16/980,546 patent/US20210004470A1/en active Pending
- 2018-07-17 WO PCT/US2018/042448 patent/WO2019226188A1/en unknown
- 2018-07-17 EP EP18755966.1A patent/EP3752945A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20210004470A1 (en) | 2021-01-07 |
CN111919214A (en) | 2020-11-10 |
WO2019226188A1 (en) | 2019-11-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
Chen et al. | jPredictor: a predictive runtime analysis tool for Java | |
Ayewah et al. | Evaluating static analysis defect warnings on production software | |
JP7164017B2 (en) | Systems and methods for optimizing control flow graphs for functional safety using fault tree analysis | |
Whaley et al. | Automatic extraction of object-oriented component interfaces | |
Gabel et al. | Online inference and enforcement of temporal properties | |
Díaz et al. | Static analysis of source code security: Assessment of tools against SAMATE tests | |
Le Goues et al. | Specification mining with few false positives | |
US7882495B2 (en) | Bounded program failure analysis and correction | |
US20210004470A1 (en) | Automatic Generation Of Patches For Security Violations | |
Bian et al. | Detecting bugs by discovering expectations and their violations | |
Kobayashi et al. | Model-checking higher-order programs with recursive types | |
Reger | Automata based monitoring and mining of execution traces | |
Sözer | Integrated static code analysis and runtime verification | |
Olesen et al. | Coccinelle: tool support for automated cert c secure coding standard certification | |
Daian et al. | Runtime verification at work: A tutorial | |
Rocha et al. | Memory management test-case generation of C programs using bounded model checking | |
Foster et al. | Improving software quality with static analysis | |
Kim et al. | JRF-E: using model checking to give advice on eliminating memory model-related bugs | |
White | Secure Coding Assistant: enforcing secure coding practices using the Eclipse Development Environment | |
Liva et al. | Modeling time in Java programs for automatic error detection | |
Park | Effective fault localization techniques for concurrent software | |
White et al. | An early detection tool in Eclipse to support secure coding practices | |
Ersoy et al. | Extending static code analysis with application-specific rules by analyzing runtime execution traces | |
Johansson et al. | Concurrency defect localization in embedded systems using static code analysis: An evaluation | |
Back et al. | MJ-a system for constructing bug-finding analyses for Java |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: UNKNOWN |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE INTERNATIONAL PUBLICATION HAS BEEN MADE |
|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: REQUEST FOR EXAMINATION WAS MADE |
|
17P | Request for examination filed |
Effective date: 20200914 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAV | Request for validation of the european patent (deleted) | ||
DAX | Request for extension of the european patent (deleted) | ||
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20220621 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |