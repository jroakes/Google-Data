US9246923B1 - Developer risk classifier - Google Patents
Developer risk classifier Download PDFInfo
- Publication number
- US9246923B1 US9246923B1 US14/158,859 US201414158859A US9246923B1 US 9246923 B1 US9246923 B1 US 9246923B1 US 201414158859 A US201414158859 A US 201414158859A US 9246923 B1 US9246923 B1 US 9246923B1
- Authority
- US
- United States
- Prior art keywords
- signal
- developer
- account
- signals
- application
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/10—Network architectures or network communication protocols for network security for controlling access to devices or network resources
- H04L63/101—Access control lists [ACL]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q20/00—Payment architectures, schemes or protocols
- G06Q20/38—Payment protocols; Details thereof
- G06Q20/40—Authorisation, e.g. identification of payer or payee, verification of customer or shop credentials; Review and approval of payers, e.g. check credit lines or negative lists
- G06Q20/401—Transaction verification
- G06Q20/4016—Transaction verification involving fraud or risk level assessment in transaction processing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/55—Detecting local intrusion or implementing counter-measures
- G06F21/554—Detecting local intrusion or implementing counter-measures involving event detection and direct action
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/10—Network architectures or network communication protocols for network security for controlling access to devices or network resources
- H04L63/102—Entity profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/51—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems at application loading time, e.g. accepting, rejecting, starting or inhibiting executable software based on integrity or source reliability
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/57—Certifying or maintaining trusted computer platforms, e.g. secure boots or power-downs, version controls, system software checks, secure updates or assessing vulnerabilities
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/57—Certifying or maintaining trusted computer platforms, e.g. secure boots or power-downs, version controls, system software checks, secure updates or assessing vulnerabilities
- G06F21/577—Assessing vulnerabilities and evaluating computer system security
Definitions
- An application ecosystem may be open, allowing any party to develop and submit applications to the application ecosystem for distribution.
- Applications developers may have their developer accounts banned from submitting applications to the application ecosystem for a variety of reasons, such as the submission of applications containing viruses or malware, or applications that violate data gathering, advertising, hardware usage, or other policies of the application ecosystem. Because the application ecosystem is open, a developer who had their developer account banned from submitting applications may create a new developer account from which to submit applications.
- Application level signals such as an advertising identification given to the developer or a certificate used by the developer to sign applications, may be matched between applications that were submitted from a banned developer account and applications from a new developer account to help ascertain whether the same developer is responsible for both the banned and new developer account.
- these application signals may not help locate clusters of developer accounts that are related to one another despite belonging to multiple developers, which may occur when a developer uses multiple names to open developer accounts, and may not provide enough information for a person or automated system to be able to quickly decide whether to ban the new account.
- signals associated with a developer account for an application ecosystem may be received, where each of the signals may include one of an account signal, an application signal, and a financial signal, and each of the signals may be associated with a weight and a score.
- the signals may be combined using the weights and the scores associated with the signals to obtain a risk probability for the developer account.
- the risk probability may be stored.
- Combining the signals may include summing the result of multiplying the score for each of the at least signals by the weight for the signal to obtain a sum; and dividing the sum by the number of signals used to obtain the sum.
- the scores associated with one of the signals may be based on a banned prevalence percentage.
- the developer account may be banned from the application ecosystem based on the risk probability.
- the account signal may include one of a spam signal, an Internet Protocol address signal, and an umbrella account conversion time signal.
- the application signal may include one of an application flagging signal, an advertising identification signal, a certificate signal, an asset signal, and a combination application signal, and the financial signal may include a buyer signal.
- the spam signal may include a score based on a quantity of umbrella accounts and developer accounts associated with a user of the developer account.
- the score for the Internet Protocol address signal may be based on matching an Internet Protocol address associated with the developer account to Internet Protocol addresses associated with banned developer accounts in the application ecosystem.
- the score for the umbrella account conversion time signal may be based on the amount of elapsed time between the creation of an umbrella account and a conversion of the umbrella account into the developer account.
- the score for the application flagging signal may be based on a flag set for an application submitted from the developer account to the application ecosystem, wherein the flag indicates one of a security risk or policy violation in the application.
- the score for the advertising identification signal may be based on matching advertising identifications used by applications submitted from the developer account to advertising identifications used by applications submitted from banned developer accounts in the application ecosystem.
- the score for the asset signal may be based on matching assets used to build applications submitted from the developer account to assets used to build applications submitted from banned developer accounts in the application ecosystem.
- the score for the buyer signal may be based on matching at least one data item for a user associated with the developer account to a one data item for users of banned developer accounts in the application ecosystem.
- the score for the combination application signal may be based on the advertising identification signals, the certificate signal, and the asset signal.
- the data item may include one of a contact name, a company name, a phone number, a physical address, an email address domain, an email address, a payment instrument, an Internet Protocol address, and a unique identifier for a computing device.
- the banned prevalence percentage may be based on the number of banned developer accounts comprising a characteristic of a signal matching a characteristic of the signal in the developer account, and the total number of developer accounts in the application ecosystem comprising the characteristic of the signal.
- the characteristic of the signal may be one item selected from the group of: an advertising identification for an application, a certificate used to sign the application, an asset used to build the application, and an Internet Protocol address used to access the developer account.
- One of the weights for one of the signals may be a super-weight.
- a means for receiving signals associated with a developer account for an application ecosystem where each of the signals may include one of an account signal, an application signal, and a financial signal, and each of the signals may be associated with a weight and a score, a means for combining the signals using the weights and the scores associated with the signals to obtain a risk probability for the developer account, a means for storing the risk probability, a means for summing the result of multiplying the score for each of the signals by the weight for the signal to obtain a sum; and a means for dividing the sum by the number of signals used to obtain the sum, are included.
- FIG. 1 shows an example system suitable for a developer risk classifier according to an implementation of the disclosed subject matter.
- FIG. 2 shows an example arrangement for a developer risk classifier according to an implementation of the disclosed subject matter.
- FIG. 3 shows an example process for determining a risk probability according to an implementation of the disclosed subject matter.
- FIG. 4 shows an example visualization of a developer risk classifier according to an implementation of the disclosed subject matter.
- FIG. 5 shows a computer according to an embodiment of the disclosed subject matter.
- FIG. 6 shows a network configuration according to an embodiment of the disclosed subject matter.
- a developer risk classifier may use multiple signals from developer accounts to assist in determining whether a developer account is related to a banned developer account.
- a risk probability for a developer account in an application ecosystem may be determined using account signals, application signals, and financial signals associated with the developer account.
- a signal as disclosed herein includes any indicator, such as a binary yes/no or true/false indicator, a probability, a ranking, an occurrence count, a score, or the like, that provides information relating to a particular aspect of one or more accounts, users, identities, or the like.
- the risk probability may be an indicator, for example, a probability from 0% to 100% expressed in any suitable manner, of whether the developer account was opened by a bad developer, for example, a developer who has had previous developer accounts banned from the application ecosystem.
- the risk probability may be used to determine whether to ban the developer account as part of a manual or automated review of the developer account. A high risk probability may make it more likely that a developer account will be banned.
- the risk probability for a developer account may be determined using account signals, application signals, and financial signals associated with the developer account.
- the account signals may include, for example, a spam signal, an Internet Protocol (IP) address signal, and an umbrella account conversion time signal.
- IP Internet Protocol
- the application signals may include an application flagging signal, an advertising identification signal, a certificate signal, and an asset signal.
- the advertising identification signal, the certificate signal, and the asset signal may also be combined into a combination application signal.
- the financial signals may include a buyer signal. Each of the signals may be scored.
- the spam signal for a developer account may have a score based on the number of accounts, including developer accounts and umbrella accounts, created by the user who created the developer account.
- the umbrella account may be an account for a larger ecosystem that includes, for example, e-mail services, cloud storage, and other services, along with access to the application ecosystem. For example, a higher number of overall accounts created by the same user that created the developer account may result in a high score for the spam signal for the developer account.
- the IP address signal for a developer account may include the IP addresses used to log in to the developer account, and may be scored based on matching the IP addresses used to log in to the developer account with the IP addresses used to log in to other developer accounts, such as developer accounts that have been banned. For example, if the IP addresses used to log in to the developer account were also used to log in to developer accounts that have been banned, a score for IP addresses signal for the developer account may be high.
- the umbrella account conversion time signal for the developer account may be the amount of time between the creation of an umbrella account for the larger ecosystem of which the application system is a part and the conversion of the umbrella account into a developer account for the application ecosystem, and may be scored based on the amount of time. For example, an umbrella account that is quickly, for example, within 72 hours, converted into a developer account for the application ecosystem may have a high score for the umbrella account conversion time signal.
- the application flagging signal for the developer account may be based on whether an application submitted to the application ecosystem has been flagged as security risk or as being in violation of policies of the application ecosystem.
- the flagging of applications may be done by, for example, an application scorer, which may score applications based on the level of security risk they pose or level of violation of application ecosystem policies and flag applications with scores that reach a threshold. The presence of absence of a flag for an application may then be converted to an application flagging score. For example, the developer account that submitted an application that was flagged as a security risk may have a high score for the application flagging signal.
- the advertising identification signal for the developer account may include the advertising identifications used by the developer account.
- the advertising identifications may be unique identifiers issued by, for example, the application ecosystem, to allow developers to collect advertising revenue from their applications, and may be used by the developer account for both the developer account itself and the applications submitted through the developer account.
- the advertising identifications signal may be scored by matching the advertising identifications used by the developer account and applications submitted from the developer account to the advertising identifications used by banned developer accounts and the applications submitted from the banned developer accounts. For example, if the advertising identifications used in the applications submitted from the developer account match the advertising identifications used by applications submitted by a high number banned developer accounts, a score for the advertising identification signal for the developer account may be high.
- the certificate signal for the developer account may include the certificates used to sign applications submitted from the developer account.
- the certificates may be issued by, for example, the application ecosystem.
- the certificates signal may be scored by matching the certificates used to sign application submitted from the developer account to the certificates used to sign applications submitted from banned developer accounts. For example, if the developer account submits applications signed with certificates that have also been used to sign applications submitted from banned developer accounts, a score for the certificate signal for the developer account may be high.
- the asset signal for the developer account may include the assets used within applications submitted by the developer account.
- Assets such as libraries, may be used by developers to construct applications for the application ecosystem, and may be reused in different applications.
- the asset signal may be scored by matching the assets used in applications submitted from the developer account to assets used in applications submitted from banned developer accounts. For example, if the assets used by applications submitted by the developer account match assets used in applications submitted by banned developer accounts, a score for the asset signal for the developer account may be high.
- the combination application signal may be a combination of the advertising identification signal, the certificate signal, and the asset signal for the applications submitted from the developer account. For example, a certain number of total matches for the advertising identifications, assets, and certificates used by the applications submitted from the developer account with applications submitted from banned developer accounts may be correlated with a certain score for the combination application signal, with, for example, a higher number of matches resulting in a higher score.
- the buyer signal may include data items about the user who opened the developer account, and may be scored based on matching the data items about the user who opened the developer account with data items for users who opened developer accounts that were banned.
- Data items used for matching may include individual names, company names, e-mail addresses, physical addresses, phone numbers, IP addresses and payment information. For example, the more data items that are matched between the user who opened the developer account and the users who opened banned developer accounts, the higher the score for the buyer signal for the developer account may be.
- Each of the signals may be scored on the same scale, for example, between 0 and 100%, or 0 and 1.0, and may have an associated weight that determines that importance of the signal when determining the risk probability of the developer account.
- the weights associated with the signals may be configurable parameters, and may be preset or determined dynamically, for example, through machine learning.
- Certain signals may be scored based on a banned prevalence percentage.
- the banned prevalence percentage may be converted into a score for the signal in any suitable manner, for example, using a score table correlating banned prevalence percentages with scores. The same banned prevalence percentage may result in different scores for different signals.
- the various account signals, financial signals, and application signals for the developer account may be combined to determine the risk probability for the developer account. For example, the score for each of the signals for the developer account may be multiplied by the weight for the signal, with the result being summed across all of the signals. This sum may then be divided by the number of signals used to produce the risk probability for the developer account. Not all of the signals may be used when determining the risk probability for the developer account, as not all of the signals may be available for the developer account.
- the risk probability for the developer account may be used to determine whether the developer account should be banned from submitting applications to the application ecosystem. For example, the risk probability for the developer account may be presented to a user, such as an administrator for the application ecosystem, along with data about the signals used to determine the risk probability, and the user may determine whether to ban the developer account.
- the risk probability may also be used with an automated system that may, for example, automatically ban the developer account if the risk probability meets or exceeds a threshold.
- FIG. 1 shows an example system suitable for a developer risk classifier according to an implementation of the disclosed subject matter.
- a computer 100 may include a risk classifier 110 and storage 140 .
- the computer 100 may be any suitable device, such as, for example, a computer 20 as described in FIG. 5 , for implementing the risk classifier 110 and the storage 140 .
- the computer 100 may be a single computing device, or may include multiple connected computing devices.
- the risk classifier 110 may use account signals 142 , application signals 144 , and financial signals 146 , to determine risk probabilities 148 .
- the storage 140 may store the account signals 142 , the application signals 144 , the financial signals 146 , and the risk probabilities 148 in any suitable format.
- FIG. 2 shows an example arrangement for a developer risk classifier according to an implementation of the disclosed subject matter.
- Signals may be gathered for developer accounts in an application ecosystem.
- the developer accounts may be used by developers of applications to distribute the applications through the application ecosystem.
- the applications may be of any application type for any type of computing device, such as, for example, personal computers and mobile computing devices.
- the signals may include the account signals 142 , the applications signals 144 , and the financial signals 146 , and may gathered in any suitable manner, including through automated systems and manual data gathering and entry.
- the gathered account signals 142 , applications signals 144 , and financial signals 146 may be stored in the storage 140 .
- the account signals 142 , the applications signals 144 , and the financial signals 146 may be used to determine the risk probabilities 148 for the developer accounts in the application ecosystem.
- the risk classifier 110 may receive the account signals 142 , the applications signals 144 , and the financial signals 146 that were gathered for a specific developer account and use them to determine the risk probability 148 for that developer account. The determined risk probability 148 may then be stored in the storage 140 with any other risk probabilities 148 for other developer accounts.
- the account signals 142 , the applications signals 144 , and the financial signals 146 may have associated scores and weights. The scores may be stored with the account signals 142 , the applications signals 144 , and the financial signals 146 , and may be assigned the by the risk classifier 110 or determined when the signals are gathered by any other suitable system.
- the account signals 142 for the developer account used by the risk classifier 110 to determine the risk probability 148 may include the spam signal, the IP address signal, and the umbrella account conversion time signal.
- the score for the spam signal may have a weight of 1.0, and may be 1.0 when the number of accounts, including umbrella and developer accounts, opened by the user who opened the developer account reaches a certain threshold and 0 when the number of accounts does not reach the threshold. For example, if the threshold is 15, and the user has opened 18 umbrella accounts, the score for the spam signal for the user's developer account may be 1.0.
- the score for the IP address signal may have a weight of 0.7, and may be scored based on a table correlating a banned prevalence percentage for the matched IP addresses to a score between 0 and 1.0.
- a banned prevalence percentage of 0% may have a score of 0, a banned prevalence percentage greater than 0% and less than 50% may have a score of 0.5, a banned prevalence percentage greater than or equal to 50% and less than 60% may have a score of 0.8, a banned prevalence percentage greater than or equal to 60% and less than 70% may have a score of 0.9, and a banned prevalence percentage greater than or equal to 70% may have a score of 1.0.
- the banned prevalence percentage may be 0%, and the score for the IP address matches may be 0. If the IP addresses used to log in to the developer account match IP addresses used to log in to 10 total developer accounts, 7 of which are banned, the banned prevalence percentage may be 70%, and the score for IP address signal may be 1.0.
- the score for the umbrella account conversion signal time may have a weight of 0.6, and may be scored based on the amount of time elapsed between the creation of an umbrella account and the conversion of that umbrella account into a developer account. For example, a conversion time of greater than 72 hours may have a score of 0, a conversion time within 72 hours but after 48 hours may have a score of 0.7, a conversion time within 48 hours but after 24 hours may have a score of 0.85, and a conversion time within 24 hours may have a score of 1.0. For example, if the developer account was converted from an umbrella account 35 hours after the creation of the umbrella account, the score for the umbrella account conversion time signal may be 0.85.
- the application signals 144 for the developer account used by the risk classifier 110 to determine the risk probability 148 may include the application flagging signal, the advertising identification signal, the certificate signal, the asset signal, and the combination application signal.
- the score for the application flagging signal may have a weight of 1.0, and may be scored based on flagging done by an application scorer.
- the application scorer may score and flag applications based on security risks posed by the applications, or violations of policies of the application ecosystem by the applications.
- the score for the application flagging signal for the developer account may be 1.0 if any application submitted by the developer account has been flagged by the application scorer, and 0 if no applications submitted by the developer account have been flagged.
- the score for the advertising identification signal may have a weight of 0.9, and may be scored based on a table correlating a banned prevalence percentage for the matched advertising identifications to a score between 0 and 1.0.
- a banned prevalence percentage of 0% may have a score of 0, a banned prevalence percentage greater than 0% and less than 30% may have a score of 0.5, a banned prevalence percentage greater than or equal to 30% and less than 40% may have a score of 0.6, a banned prevalence percentage greater than or equal to 40% and less than 50% may have a score of 0.7, a banned prevalence percentage greater than or equal to 50% and less than 60% may have a score of 0.8, a banned prevalence percentage greater than or equal to 60% and less than 70% may have a score of 0.9, and a banned prevalence percentage greater than or equal to 70% may have a score of 1.0.
- the banned prevalence percentage may be 60%, and the score for the advertising identification signal may be 0.9.
- the score for the certificate signal may have a weight of 0.9, and may be scored based on a table correlating a banned prevalence percentage for the matched certificates to a score between 0 and 1.0.
- a banned prevalence percentage of 0% may have a score of 0, a banned prevalence percentage greater than 0% and less than 30% may have a score of 0.5, a banned prevalence percentage greater than or equal to 30% and less than 40% may have a score of 0.6, a banned prevalence percentage greater than or equal to 40% and less than 50% may have a score of 0.7, a banned prevalence percentage greater than or equal to 50% and less than 60% may have a score of 0.8, a banned prevalence percentage greater than or equal to 60% and less than 70% may have a score of 0.9, and a banned prevalence percentage greater than or equal to 70% may have a score of 1.0.
- the banned prevalence percentage may be 40%, and the score for certificate signal may be 40%, and the score for certificate signal may be 40%, and the score for certificate signal may be 40%, and the score for certificate signal may be 40%,
- the score for the asset signal may have a weight of 0.9, and may be scored and may be scored based on a table correlating a banned prevalence percentage for the matched assets to a score between 0 and 1.0.
- a banned prevalence percentage of 0% may have a score of 0, a banned prevalence percentage greater than 0% and less than 30% may have a score of 0.5, a banned prevalence percentage greater than or equal to 30% and less than 40% may have a score of 0.6, a banned prevalence percentage greater than or equal to 40% and less than 50% may have a score of 0.7, a banned prevalence percentage greater than or equal to 50% and less than 60% may have a score of 0.8, a banned prevalence percentage greater than or equal to 60% and less than 70% may have a score of 0.9, and a banned prevalence percentage greater than or equal to 70% may have a score of 1.0. For example, if assets used in applications submitted by the developer account match assets used in applications from 10 total developer accounts, 5 of which are banned, the banned prevalence percentage may be 50%, and the score for asset signal may
- the combination application signal may have a weight of 1.0, and may be scored based on the number of matches to banned developer accounts that were found for the signals for the advertising identification matches, the certificate matches, and the asset matches. For example, 3 or more matches for the advertising identifications, certificates, or assets from applications submitted by the developer account may result in a combination application signal score of 1.0, 2 matches may result in a score of 0.9, and fewer than 2 matches may result in a score of 0. For example, if there were 2 matches to banned developer accounts for the advertising identifications used in applications submitted from the developer account, 1 match for the certificates, and 1 match for the assets, the total of 4 matches may result in the score for the combination application signal being 1.0.
- the financial signals 146 for the developer account used by the risk classifier 110 to determine the risk probability 148 may include the buyer signal.
- the score for the buyer signal may have a weight of 1.0, and may be based on the number of data items the user who created the developer account has in common with the users who created banned developer accounts.
- matching phone number digits may result in a score of 0.5
- a matching login IP address, physical address, or email address domain may result in a score of 0.7
- a matching contact name, entire phone number, email address, or company name may result in a score of 0.9
- a matching payment instrument for example, credit card or bank account, or unique identifier for the computing device, or two matches from any of the data items that would result in lower scores on their own, may result in a score of 1.0.
- the score for the buyer signal for the developer account may be 1.0.
- the risk classifier 110 may determine the risk probability 148 from any available signals from the account signals 142 , the application signals 144 , and the financial signals 146 in any suitable manner.
- the scores for the available signals may be combined according to:
- RP the risk probability for the developer account
- n the number of signals available for the developer account, for example, from the account signals 142 , the application signals 144 , and the financial signals 146
- w i the weight for the signal i
- s i the score the signal i.
- the risk probability 148 may be the sum of each score for an available signal multiplied by the weight for the signal, and divided by the number of available signals.
- the developer account may have a score for a spam signal of 1.0, an IP address signal score of 0.8, an umbrella account conversion time signal score of 0.85, an application flagging signal score of 1.0, an advertising identification signal score of 0.9, a certificate signal score of 0.7, an asset signal score of 0.8, a combination application signal score of 1.0, and a score for a buyer signal of 0.9, for a total of 9 available signals.
- signals may have super weights.
- the weight for the signal may be 1.0, and if the score for the signal is also 1.0, then the risk probability 148 for the developer account will be set 1.0, by, for example, the risk classifier 110 , regardless of the weights and scores for the other available signals.
- the spam signal, the buyer signal, the application flagging signal, and the combination application signal may have super weights. If the application flagging signal score for the developer account is 1.0 because one of the applications submitted from the developer account has been flagged, then the risk probability 148 for the developer account may be 1.0 due to the super weight on the application flagging signal score.
- the risk probabilities 148 may be used determine a rank for a cluster of related developer accounts.
- the risk classifier 110 may determine that a number of developer accounts are related using the account signals 142 , the applications signals 144 , and the financial signals 146 or any other suitable data on the developer accounts.
- the rank of the cluster of related developer accounts may determined by averaging the risk probabilities 148 for all of the developer accounts in the cluster, and multiplying the result by the number of developer accounts in the cluster.
- the rank may provide an indication as to the concentration developer accounts that may need to be banned within the cluster of related developer accounts, and may be used, for example, to establish priority when deciding which developer accounts to review.
- Related developer accounts may be determined based on shared signals between developer accounts. For example, the sharing of advertising identifications, certificates, assets, login IP addresses, buyer data items between developer accounts, or the creation of the developer accounts by the same user, may be used to determine which developer accounts belong in a cluster, in any suitable manner.
- FIG. 3 shows an example process for determining a risk probability according to an implementation of the disclosed subject matter.
- the available signals for a developer account may be received.
- the risk classifier 110 may receive the signals that are available for the developer account being evaluated from the account signals 142 , the applications signals 144 , and the financial signals 146 .
- the signals may have been gathered in any suitable manner and stored in the storage 140 .
- the signals may be combined to determine a risk probability.
- the risk classifier 110 may combine the received signals from the account signals 142 , the applications signals 144 , and the financial signals 146 to determine the risk probability 148 for the developer account being evaluated.
- the risk classifier 110 may, for example, assign a score to each of the available signals using, for example, banned prevalence percentage or any other suitable scoring system, or may receive already assigned scores. Different signals may be scored with different scoring systems.
- the risk classifier 110 may combine the scores for the available signals with weights for the available signals to determine the risk probability 148 . For example, each score for an available signal may be multiplied by the weight for the signal, with the results summed across all of the available signals. The result of the summation may then be divided by the number of available signals to produce the risk probability 148 .
- the risk probability may be stored.
- the risk classifier 110 may store the risk probability 148 in the storage 140 with the risk probabilities 148 .
- the risk probabilities 148 may be stored in any suitable format.
- the risk probabilities 148 may be accessed by, for example, an automated system for determining whether to ban developer accounts, or users who are, for example, administrators of the application ecosystem who need to determine whether to ban developer accounts.
- FIG. 4 shows an example visualization of a developer risk classifier according to an implementation of the disclosed subject matter.
- the risk probabilities 148 may be displayed to a user of a tool 400 for banning developer accounts from the application ecosystem.
- the display of the tool 400 may include a ban check box 410 , a developer name 420 , a risk probability 430 , a status 440 , signals 450 , and prevalence 460 for each of the developer accounts being viewed.
- the ban check box 410 may be an interactive check box the user can check to ban the developer account.
- the user may be banning AppDev2.
- the developer name 420 may be the name given to the developer account by the user of the developer account.
- the risk probability 430 may be the risk probability 148 for the developer as determined by, for example, the risk classifier 110 , and may be received by the tool 400 from the risk probabilities 148 in the storage 140 .
- the status 440 may be the current status of the developer account, which may be, for example, banned or paid.
- AppDev1 may be a developer account that has been banned from submitting applications to the application ecosystem.
- AppDev4 may be a paid developer account, which may be a developer account that is not banned and is being paid based on advertising in or sales of its applications in the application ecosystem.
- Signals 450 may be a listing of the available signals from the account signals 142 , the applications signals 144 , and the financial signals 146 that were used to determine the risk probability 148 for the developer account by, for example, the risk classifier 110 .
- AppDev1 may have a spam signal of 1.0, two advertising identifications that were matched, and unique identifier for a computing device that was matched.
- the prevalence 460 may be the prevalence with which the signals were found in banned developer accounts among all developer accounts, or developer accounts in a cluster with the developer account, in which the signals were found.
- the prevalence 460 for the spam signal for AppDev1 may be 2 ⁇ 3, indicating that three developer accounts have spam signal scores of 1.0, and among those, 2 were banned.
- the prevalence 460 for signals that use banned prevalence percentage may be the banned prevalence percentage.
- FIG. 5 is an example computer system 20 suitable for implementing embodiments of the presently disclosed subject matter.
- the computer 20 includes a bus 21 which interconnects major components of the computer 20 , such as one or more processors 24 , memory 27 such as RAM, ROM, flash RAM, or the like, an input/output controller 28 , and fixed storage 23 such as a hard drive, flash storage, SAN device, or the like.
- a user display such as a display screen via a display adapter
- user input interfaces such as controllers and associated user input devices
- keyboard, mouse, touchscreen, or the like and other components known in the art to use in or in conjunction with general-purpose computing systems.
- the bus 21 allows data communication between the central processor 24 and the memory 27 .
- the RAM is generally the main memory into which the operating system and application programs are loaded.
- the ROM or flash memory can contain, among other code, the Basic Input-Output system (BIOS) which controls basic hardware operation such as the interaction with peripheral components.
- BIOS Basic Input-Output system
- Applications resident with the computer 20 are generally stored on and accessed via a computer readable medium, such as the fixed storage 23 and/or the memory 27 , an optical drive, external storage mechanism, or the like.
- Each component shown may be integral with the computer 20 or may be separate and accessed through other interfaces.
- Other interfaces such as a network interface 29 , may provide a connection to remote systems and devices via a telephone link, wired or wireless local- or wide-area network connection, proprietary network connections, or the like.
- the network interface 29 may allow the computer to communicate with other computers via one or more local, wide-area, or other networks, as shown in FIG. 6 .
- FIG. 5 Many other devices or components (not shown) may be connected in a similar manner, such as document scanners, digital cameras, auxiliary, supplemental, or backup systems, or the like. Conversely, all of the components shown in FIG. 5 need not be present to practice the present disclosure. The components can be interconnected in different ways from that shown. The operation of a computer such as that shown in FIG. 5 is readily known in the art and is not discussed in detail in this application. Code to implement the present disclosure can be stored in computer-readable storage media such as one or more of the memory 27 , fixed storage 23 , remote storage locations, or any other storage mechanism known in the art.
- FIG. 6 shows an example arrangement according to an embodiment of the disclosed subject matter.
- One or more clients 10 , 11 such as local computers, smart phones, tablet computing devices, remote services, and the like may connect to other devices via one or more networks 7 .
- the network may be a local network, wide-area network, the Internet, or any other suitable communication network or networks, and may be implemented on any suitable platform including wired and/or wireless networks.
- the clients 10 , 11 may communicate with one or more computer systems, such as processing units 14 , databases 15 , and user interface systems 13 .
- clients 10 , 11 may communicate with a user interface system 13 , which may provide access to one or more other systems such as a database 15 , a processing unit 14 , or the like.
- the user interface 13 may be a user-accessible web page that provides data from one or more other computer systems.
- the user interface 13 may provide different interfaces to different clients, such as where a human-readable web page is provided to web browser clients 10 , and a computer-readable API or other interface is provided to remote service clients 11 .
- the user interface 13 , database 15 , and processing units 14 may be part of an integral system, or may include multiple computer systems communicating via a private network, the Internet, or any other suitable network.
- Processing units 14 may be, for example, part of a distributed system such as a cloud-based computing system, search engine, content delivery system, or the like, which may also include or communicate with a database 15 and/or user interface 13 .
- an analysis system 5 may provide back-end processing, such as where stored or acquired data is pre-processed by the analysis system 5 before delivery to the processing unit 14 , database 15 , and/or user interface 13 .
- a machine learning system 5 may provide various prediction models, data analysis, or the like to one or more other systems 13 , 14 , 15 .
Abstract
Description
where RP is the risk probability for the developer account, n is the number of signals available for the developer account, for example, from the account signals 142, the application signals 144, and the
((1.0*1.0)+(0.7*0.8)+(0.6*0.85)+(1.0*1.0)+(0.9*0.9)+(0.9*0.7)+(0.9*0.8)+(1.0*1.0)+(1.0*0.9))/9=0.79.
Claims (17)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/158,859 US9246923B1 (en) | 2014-01-19 | 2014-01-19 | Developer risk classifier |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/158,859 US9246923B1 (en) | 2014-01-19 | 2014-01-19 | Developer risk classifier |
Publications (1)
Publication Number | Publication Date |
---|---|
US9246923B1 true US9246923B1 (en) | 2016-01-26 |
Family
ID=55086308
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/158,859 Active 2034-04-20 US9246923B1 (en) | 2014-01-19 | 2014-01-19 | Developer risk classifier |
Country Status (1)
Country | Link |
---|---|
US (1) | US9246923B1 (en) |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160021174A1 (en) * | 2014-07-17 | 2016-01-21 | Telefonica Digital Espana, S.L.U. | Computer implemented method for classifying mobile applications and computer programs thereof |
US10148643B2 (en) * | 2016-03-03 | 2018-12-04 | F-Secure Corporation | Authenticating or controlling software application on end user device |
US10185924B1 (en) * | 2014-07-01 | 2019-01-22 | Amazon Technologies, Inc. | Security risk response impact analysis |
CN110941818A (en) * | 2018-09-21 | 2020-03-31 | 武汉安天信息技术有限责任公司 | Reputation obtaining method and device for mobile application program developer |
US10905962B2 (en) * | 2018-09-07 | 2021-02-02 | Valve Corporation | Machine-learned trust scoring for player matchmaking |
US11052311B2 (en) | 2018-09-07 | 2021-07-06 | Valve Corporation | Machine-learned trust scoring based on sensor data |
US20230214822A1 (en) * | 2022-01-05 | 2023-07-06 | Mastercard International Incorporated | Computer-implemented methods and systems for authentic user-merchant association and services |
Citations (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040215977A1 (en) | 2003-03-03 | 2004-10-28 | Goodman Joshua T. | Intelligent quarantining for spam prevention |
US7725544B2 (en) | 2003-01-24 | 2010-05-25 | Aol Inc. | Group based spam classification |
US20110022406A1 (en) * | 2009-07-27 | 2011-01-27 | Barbara Ann Fox | Apparatus and method for providing security in an online gaming and/or digital environment |
US20110154439A1 (en) * | 2009-12-21 | 2011-06-23 | Amol Bhasker Patel | Secure application network |
US20120072991A1 (en) * | 2010-09-22 | 2012-03-22 | Rohyt Belani | Methods and systems for rating privacy risk of applications for smart phones and other mobile platforms |
US8151349B1 (en) * | 2008-07-21 | 2012-04-03 | Google Inc. | Masking mechanism that facilitates safely executing untrusted native code |
US20120096516A1 (en) | 2010-10-19 | 2012-04-19 | Symantec Corporation | Software Signing Certificate Reputation Model |
US20120210422A1 (en) | 2010-12-01 | 2012-08-16 | Oliver Friedrichs | Method and apparatus for detecting malicious software using generic signatures |
US20120222111A1 (en) | 2003-09-08 | 2012-08-30 | Jonathan Oliver | Classifying a message based on fraud indicators |
US20130054711A1 (en) | 2011-08-23 | 2013-02-28 | Martin Kessner | Method and apparatus for classifying the communication of an investigated user with at least one other user |
US20130191918A1 (en) | 2012-01-25 | 2013-07-25 | Carey Nachenberg | Identifying Trojanized Applications for Mobile Environments |
US20130318568A1 (en) | 2008-10-21 | 2013-11-28 | Lookout Inc. | Assessing a data object based on application data associated with the data object |
US20130326625A1 (en) | 2012-06-05 | 2013-12-05 | Los Alamos National Security, Llc | Integrating multiple data sources for malware classification |
US8763131B2 (en) * | 2012-05-22 | 2014-06-24 | Verizon Patent And Licensing Inc. | Mobile application security score calculation |
US20140214610A1 (en) * | 2013-01-31 | 2014-07-31 | Sean Moshir | Method and System to Intelligently Assess and Mitigate Security Risks on a Mobile Device |
US20150150137A1 (en) * | 2012-02-24 | 2015-05-28 | Appthority, Inc. | Quantifying the risks of applications for mobile devices |
US20150161672A1 (en) * | 2013-12-09 | 2015-06-11 | Microsoft Corporation | Preventing Display of Age Inappropriate Advertising |
-
2014
- 2014-01-19 US US14/158,859 patent/US9246923B1/en active Active
Patent Citations (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7725544B2 (en) | 2003-01-24 | 2010-05-25 | Aol Inc. | Group based spam classification |
US20040215977A1 (en) | 2003-03-03 | 2004-10-28 | Goodman Joshua T. | Intelligent quarantining for spam prevention |
US20120222111A1 (en) | 2003-09-08 | 2012-08-30 | Jonathan Oliver | Classifying a message based on fraud indicators |
US8151349B1 (en) * | 2008-07-21 | 2012-04-03 | Google Inc. | Masking mechanism that facilitates safely executing untrusted native code |
US20130318568A1 (en) | 2008-10-21 | 2013-11-28 | Lookout Inc. | Assessing a data object based on application data associated with the data object |
US20110022406A1 (en) * | 2009-07-27 | 2011-01-27 | Barbara Ann Fox | Apparatus and method for providing security in an online gaming and/or digital environment |
US20110154439A1 (en) * | 2009-12-21 | 2011-06-23 | Amol Bhasker Patel | Secure application network |
US20120072991A1 (en) * | 2010-09-22 | 2012-03-22 | Rohyt Belani | Methods and systems for rating privacy risk of applications for smart phones and other mobile platforms |
US20120096516A1 (en) | 2010-10-19 | 2012-04-19 | Symantec Corporation | Software Signing Certificate Reputation Model |
US20120210422A1 (en) | 2010-12-01 | 2012-08-16 | Oliver Friedrichs | Method and apparatus for detecting malicious software using generic signatures |
US20130054711A1 (en) | 2011-08-23 | 2013-02-28 | Martin Kessner | Method and apparatus for classifying the communication of an investigated user with at least one other user |
US20130191918A1 (en) | 2012-01-25 | 2013-07-25 | Carey Nachenberg | Identifying Trojanized Applications for Mobile Environments |
US20150150137A1 (en) * | 2012-02-24 | 2015-05-28 | Appthority, Inc. | Quantifying the risks of applications for mobile devices |
US8763131B2 (en) * | 2012-05-22 | 2014-06-24 | Verizon Patent And Licensing Inc. | Mobile application security score calculation |
US20130326625A1 (en) | 2012-06-05 | 2013-12-05 | Los Alamos National Security, Llc | Integrating multiple data sources for malware classification |
US20140214610A1 (en) * | 2013-01-31 | 2014-07-31 | Sean Moshir | Method and System to Intelligently Assess and Mitigate Security Risks on a Mobile Device |
US20150161672A1 (en) * | 2013-12-09 | 2015-06-11 | Microsoft Corporation | Preventing Display of Age Inappropriate Advertising |
Cited By (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10185924B1 (en) * | 2014-07-01 | 2019-01-22 | Amazon Technologies, Inc. | Security risk response impact analysis |
US20160021174A1 (en) * | 2014-07-17 | 2016-01-21 | Telefonica Digital Espana, S.L.U. | Computer implemented method for classifying mobile applications and computer programs thereof |
US10148643B2 (en) * | 2016-03-03 | 2018-12-04 | F-Secure Corporation | Authenticating or controlling software application on end user device |
US10905962B2 (en) * | 2018-09-07 | 2021-02-02 | Valve Corporation | Machine-learned trust scoring for player matchmaking |
US11052311B2 (en) | 2018-09-07 | 2021-07-06 | Valve Corporation | Machine-learned trust scoring based on sensor data |
US11504633B2 (en) | 2018-09-07 | 2022-11-22 | Valve Corporation | Machine-learned trust scoring for player matchmaking |
CN110941818A (en) * | 2018-09-21 | 2020-03-31 | 武汉安天信息技术有限责任公司 | Reputation obtaining method and device for mobile application program developer |
US20230214822A1 (en) * | 2022-01-05 | 2023-07-06 | Mastercard International Incorporated | Computer-implemented methods and systems for authentic user-merchant association and services |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9246923B1 (en) | Developer risk classifier | |
US11546223B2 (en) | Systems and methods for conducting more reliable assessments with connectivity statistics | |
US20230275817A1 (en) | Parallel computational framework and application server for determining path connectivity | |
US20210232608A1 (en) | Trust scores and/or competence ratings of any entity | |
KR102127039B1 (en) | Interactive data processing method and apparatus using same | |
US9922134B2 (en) | Assessing and scoring people, businesses, places, things, and brands | |
US9258340B2 (en) | Secure digital remediation systems and methods for managing an online reputation | |
MX2012003721A (en) | Systems and methods for social graph data analytics to determine connectivity within a community. | |
CN112348659B (en) | User identification policy distribution method and device and electronic equipment | |
US20160180282A1 (en) | Systems and methods for crowdfunding and crowdsourcing a project | |
US20230116362A1 (en) | Scoring trustworthiness, competence, and/or compatibility of any entity for activities including recruiting or hiring decisions, composing a team, insurance underwriting, credit decisions, or shortening or improving sales cycles | |
WO2022257731A1 (en) | Method, device and system for performing algorithm negotiation on privacy computation | |
CN114219604A (en) | House loan service processing method, device, equipment and storage medium | |
CN112634062B (en) | Hadoop-based data processing method, device, equipment and storage medium | |
CN115470512A (en) | Method, device and system for carrying out multi-party algorithm negotiation aiming at privacy calculation | |
CN109857748B (en) | Contract data processing method and device and electronic equipment | |
CN111210109A (en) | Method and device for predicting user risk based on associated user and electronic equipment | |
CN111858686A (en) | Data display method and device, terminal equipment and storage medium | |
CN113269179B (en) | Data processing method, device, equipment and storage medium | |
US9996691B1 (en) | Using signals from developer clusters | |
US20220148048A1 (en) | Leveraging structured data to rank unstructured data | |
CN110675136A (en) | Information processing method, device and equipment | |
CN111507787A (en) | Commodity transaction method, commodity transaction system, computer device and readable storage medium | |
US11985037B2 (en) | Systems and methods for conducting more reliable assessments with connectivity statistics | |
WO2022239128A1 (en) | Information processing device, analysis method, and program |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:TERRIBILINI, RYAN JAMES;GO, ALEC;SIGNING DATES FROM 20140116 TO 20140117;REEL/FRAME:032001/0887 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044566/0657Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |