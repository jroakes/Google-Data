KR20230160376A - Pre-activates automated assistant driving mode for variable movement detection reliability - Google Patents
Pre-activates automated assistant driving mode for variable movement detection reliability Download PDFInfo
- Publication number
- KR20230160376A KR20230160376A KR1020237036509A KR20237036509A KR20230160376A KR 20230160376 A KR20230160376 A KR 20230160376A KR 1020237036509 A KR1020237036509 A KR 1020237036509A KR 20237036509 A KR20237036509 A KR 20237036509A KR 20230160376 A KR20230160376 A KR 20230160376A
- Authority
- KR
- South Korea
- Prior art keywords
- assistant
- user
- computing device
- vehicle
- score
- Prior art date
Links
- 238000001514 detection method Methods 0.000 title description 3
- 238000000034 method Methods 0.000 claims description 94
- 230000004044 response Effects 0.000 claims description 26
- 238000004891 communication Methods 0.000 claims description 14
- 230000008569 process Effects 0.000 claims description 14
- 238000005457 optimization Methods 0.000 abstract description 21
- 230000009471 action Effects 0.000 description 16
- 238000012545 processing Methods 0.000 description 11
- 230000000875 corresponding effect Effects 0.000 description 9
- 230000006870 function Effects 0.000 description 7
- 238000010801 machine learning Methods 0.000 description 5
- 239000000463 material Substances 0.000 description 5
- 230000015654 memory Effects 0.000 description 5
- 230000001755 vocal effect Effects 0.000 description 5
- 239000003795 chemical substances by application Substances 0.000 description 4
- 230000003993 interaction Effects 0.000 description 4
- 238000012549 training Methods 0.000 description 4
- 230000002093 peripheral effect Effects 0.000 description 3
- 238000010276 construction Methods 0.000 description 2
- 238000010586 diagram Methods 0.000 description 2
- 230000000977 initiatory effect Effects 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 238000009877 rendering Methods 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 230000001133 acceleration Effects 0.000 description 1
- 238000013528 artificial neural network Methods 0.000 description 1
- 230000019771 cognition Effects 0.000 description 1
- 230000001276 controlling effect Effects 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 239000010779 crude oil Substances 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000000116 mitigating effect Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 230000001737 promoting effect Effects 0.000 description 1
- 238000010079 rubber tapping Methods 0.000 description 1
- 238000013179 statistical model Methods 0.000 description 1
Classifications
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/34—Route searching; Route guidance
- G01C21/36—Input/output arrangements for on-board computers
- G01C21/3605—Destination input or retrieval
- G01C21/3608—Destination input or retrieval using speech input, e.g. using speech recognition
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/34—Route searching; Route guidance
- G01C21/36—Input/output arrangements for on-board computers
- G01C21/3664—Details of the user input interface, e.g. buttons, knobs or sliders, including those provided on a touch screen; remote controllers; input using gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
Abstract
본 명세서에 설명된 구현은 사용자가 비히클을 타고 이동하는 것으로 예측되는 신뢰도에 따라 다양한 운전 최적화 모드에 따라 동작할 수 있는 자동화된 어시스턴트에 관한 것이다. 예를 들어, 사용자가 이동 중이라는 예측이 소정의 신뢰도에 해당하면 자동화된 어시스턴트는 운전 최적화 모드에 따라 자동으로 동작할 수 있다. 대안적으로, 사용자가 이동 중이라는 예측이 더 낮은 신뢰도에 대응할 때, 자동화된 어시스턴트는 사용자가 자동화된 어시스턴트를 운전 최적화 모드로 전환하도록 명시적으로 선택할 때까지 운전 최적화 모드에 따라 동작하지 않을 수 있다. 사용자가 운전 최적화 모드를 선택할 때, 운전 모드 GUI는 사용자의 예상 목적지로의 방향을 포함할 수 있는 내비게이션 인터페이스 및/또는 사용자를 위한 콘텐츠 제안이 있는 다른 인터페이스로 렌더링될 수 있다.Implementations described herein relate to an automated assistant that can operate according to various driving optimization modes depending on the predicted reliability of the user's movement in the vehicle. For example, if the prediction that the user is moving corresponds to a predetermined level of confidence, the automated assistant may automatically operate according to the driving optimization mode. Alternatively, when the prediction that the user is moving corresponds to a lower confidence level, the automated assistant may not operate in accordance with the driving optimization mode until the user explicitly selects to switch the automated assistant to the driving optimization mode. . When a user selects a driving optimization mode, the driving mode GUI may be rendered as a navigation interface that may include directions to the user's expected destination and/or other interface with content suggestions for the user.
Description
인간은 여기에서 "자동화된 어시스턴트"(또한 "디지털 에이전트", "챗봇", "대화형 개인 어시스턴트", "지능형 개인 어시스턴트", "어시스턴트 애플리케이션", "대화형 에이전트" 등으로 불림) 라고 하는 대화형 소프트웨어 애플리케이션을 사용하여 인간 대 컴퓨터 대화에 참여할 수 있다. 예를 들어, 인간(자동화된 어시스턴트와 상호 작용할 때 "사용자"라고 부를 수 있음)은 음성 자연어 입력(즉, 발화)을 사용하여 자동화된 어시스턴트에게 명령 및/또는 요청을 제공할 수 있으며, 이는 경우에 따라 텍스트로 변환된 다음 처리될 수 있고 및/또는 텍스트(타이핑됨) 자연어 입력을 제공함으로써 가능하다. Humans conduct conversations, herein referred to as “automated assistants” (also called “digital agents”, “chatbots”, “conversational personal assistants”, “intelligent personal assistants”, “assistant applications”, “conversational agents”, etc.). You can engage in human-to-computer conversations using similar software applications. For example, a human (who may be referred to as a “user” when interacting with an automated assistant) may use spoken natural language input (i.e., utterances) to provide commands and/or requests to the automated assistant, which may be may be converted to text and then processed, and/or by providing text (typed) natural language input.
자동화된 어시스턴트 및 기타 애플리케이션은 사용자가 차량을 타고 이동할 때와 같은 다양한 상황에서 휴대폰 및 태블릿 컴퓨터와 같은 휴대용 컴퓨팅 장치를 통해 액세스할 수 있다. 특정 애플리케이션(예: 자동화된 어시스턴트 애플리케이션)에 의해 운전 모드가 제공될 때, 사용자는 컴퓨팅 장치에 대한 입력을 통해 운전 모드를 직접 초기화해야 할 수 있다. 그러나 이는 사용자가 이미 차량을 운전하고 있는 경우 편리하거나 안전하지 않을 수 있다. 예를 들어, 차량을 운전하는 사용자는 내비게이션 애플리케이션으로부터 내비게이션 명령어를 받는 동시에 자동화된 어시스턴트에 액세스하기를 원할 수 있다. 불행하게도 많은 자동화된 어시스턴트는 내비게이션 명령어의 렌더링을 중단하지 않고 내비게이션 중에 요청에 응답하지 않을 수 있다. 이러한 방식으로 내비게이션을 중단하면 사용자가 자동화된 어시스턴트와의 추가 상호 작용을 시도하거나 사용자가 놓쳤을 수 있는 내비게이션 명령어를 식별하려고 시도하므로 사용자에게 위험할 수 있다. 더욱이, 운전 및/또는 내비게이션 중 어시스턴트 응답은 자동화된 어시스턴트가 사용자가 운전 중이라는 것을 인식하지 못할 때 주의를 산만하게 할 수 있다. Automated assistants and other applications can be accessed through portable computing devices such as mobile phones and tablet computers in a variety of situations, such as when users are traveling in a vehicle. When a driving mode is provided by a specific application (e.g., an automated assistant application), the user may need to initiate the driving mode directly through input to the computing device. However, this may not be convenient or safe if the user is already driving the vehicle. For example, a user driving a vehicle may wish to receive navigation commands from a navigation application while simultaneously accessing an automated assistant. Unfortunately, many automated assistants may not stop rendering navigation commands and may not respond to requests during navigation. Interrupting navigation in this way can be dangerous for the user as they attempt to further interact with the automated assistant or identify navigation commands the user may have missed. Moreover, assistant responses while driving and/or navigating can be distracting when the automated assistant is not aware that the user is driving.
본 명세서에 설명된 구현은 사용자가 차량으로 이동하고 있는지 사전에 결정한 후 그에 따라 운전에 최적화된 어시스턴트 응답을 제공하는 자동화된 어시스턴트에 관한 것이다. 일부 구현에서, 사용자는 자신의 차량을 운전하고 사용자의 휴대폰을 통해 액세스할 수 있는 자동화된 어시스턴트에 쿼리를 제출할 수 있다. 사용자가 쿼리를 제공하기 전에 자동화된 어시스턴트는 사용자가 차량을 타고 이동하고 있음을 사전에 검출할 수 있다. 따라서, 사용자로부터의 쿼리에 응답하여, 자동화된 어시스턴트는 자신의 차량을 운전하는 사용자의 결정된 컨텍스트에 따라 응답을 생성할 수 있다. 예를 들어, 쿼리가 "Assistant, Acme Consignment"와 같은 음성 발화인 경우, 자동화된 어시스턴트는 "Acme Consignment"라는 가장 가까운 매장에 대한 내비게이션 명령어로 응답할 수 있다. 따라서 자동화된 어시스턴트는 쿼리에 대한 응답을 생성할 때, 사용자가 차량을 타고 이동하고/있거나 운전 모드에 있을 가능성이 있다는 점을 고려할 수 있다. 예를 들어, 사용자가 매장 근처까지 이동했음에도 불구하고 "Acme Consignment"로 가는 정확한 경로를 알 수 없다는 것을 깨닫는 경우, 사용자는 앞서 언급한 쿼리를 제공하여 자동화된 어시스턴트가 길을 따라 자세한 내비게이션 명령어를 제공하도록 할 수 있다. 반면, 사용자가 더 이상 운전하지 않는 동안 사용자가 이 쿼리를 제공하면, 자동화된 어시스턴트는 "Acme Consignment"에 대한 웹사이트 링크를 포함할 수 있는 "Acme Consignment"에 대한 인터넷 검색 결과를 제공할 수 있다. Implementations described herein relate to automated assistants that proactively determine whether a user is moving in a vehicle and then provide driving-optimized assistant responses accordingly. In some implementations, a user can drive their own vehicle and submit queries to an automated assistant that can be accessed through the user's mobile phone. Before the user provides a query, the automated assistant can proactively detect that the user is traveling in a vehicle. Accordingly, in response to a query from a user, the automated assistant may generate a response according to the determined context of the user driving his or her vehicle. For example, if the query is a voice utterance such as “Assistant, Acme Consignment,” the automated assistant may respond with a navigation command for the nearest store, “Acme Consignment.” Accordingly, when generating a response to a query, the automated assistant may take into account that the user is likely traveling in a vehicle and/or in driving mode. For example, if a user realizes that they can't get the exact route to "Acme Consignment" even though they've moved close to the store, the user can provide the aforementioned query and have the automated assistant provide detailed navigation commands along the way. You can do it. On the other hand, if the user provides this query while the user is no longer driving, the automated assistant may provide Internet search results for "Acme Consignment", which may include a website link to "Acme Consignment" .
다른 방식으로, 본 명세서에 개시된 구현은, 사용자가 운전할 가능성이 있다고 결정하는 것에 응답하여 및/또는 사용자 장치가 운전 모드에 있는 것에 응답하여, 사용자 요청에 따라 수행되는 자연어 이해 및/또는 이행을 운전에 더 안전하고/또는하거나 더 도움이 되는 의도 및/또는 이행쪽으로 편향시킬 수 있다. 예를 들어, 운전 모드에 있을 때 "내비게이션" 의도에 대한 편향은 위의 "Assistant, Acme Consignment" 사용자 요청(요청에 따라 내비게이션 명령어가 제공됨)에 대해 내비게이션 의도가 결정될 수 있지만, 해당 내비게이션 의도에 편향되지 않으면(예: 운전 모드가 아닌 경우) 위의 "Assistant, Acme Consignment" 사용자 요청에 대해 일반 검색 의도(그리고 요청에 따라 제공되는 "Acme Consignment"에 대한 일반 정보)가 결정될 수 있다. 따라서, 이러한 방식 및 다른 방식으로, 요청에 대한 자동화된 어시스턴트 응답은 요청이 운전 모드에 있는 사용자 장치 및/또는 차량을 타고 이동 중인 것으로 검출된 사용자 장치로부터 시작되는지 여부에 따라 동적으로 적응될 수 있다. Alternatively, implementations disclosed herein may provide driving natural language understanding and/or performance performed upon user requests, in response to determining that the user is likely to drive and/or in response to the user device being in a driving mode. may bias it toward intentions and/or implementation that are safer and/or more helpful. For example, when in driving mode, a bias toward the "Navigation" intent may be determined for the "Assistant, Acme Consignment" user request above (navigation commands are provided upon request), but there is a bias toward that navigation intent. If not (e.g. not in driving mode), general search intent (and general information about "Acme Consignment" provided upon request) may be determined for the user request above for "Assistant, Acme Consignment". Accordingly, in these and other ways, an automated assistant response to a request may be dynamically adapted depending on whether the request originates from a user device in a driving mode and/or a user device detected to be traveling in a vehicle. .
일부 구현예에서, 자동화된 어시스턴트는 사용자가 자신의 컴퓨팅 장치를 가지고 차량으로 이동할 때를 검출하고, 이에 응답하여 컴퓨팅 장치의 디스플레이 인터페이스가 선택 가능한 어시스턴트 그래픽 사용자 인터페이스(GUI) 요소를 렌더링하게 할 수 있다. 일부 구현예에서, 사용자가 이동 중이라는 예측은 자동화된 어시스턴트에 의해 결정되는 신뢰도 점수에 의해 특성화(characterized)될 수 있다. 선택 가능한 어시스턴트 GUI 요소가 사용자에 의해 선택되면(예를 들어, 터치 입력 또는 음성 발화를 통해), 자동화된 어시스턴트는 어시스턴트 운전 모드 GUI가 디스플레이 인터페이스에서 렌더링되도록 할 수 있다. 신뢰도 점수가 특정 신뢰도 임계값을 만족하면, 자동화된 어시스턴트는 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택하지 않았더라도 운전에 최적화된 방식으로 입력을 처리하고/하거나 출력을 생성하기 위한 운전 모드에 따라 동작할 수 있다. 일부 구현에서, 신뢰도 점수가 특정 신뢰도 점수 임계값을 만족하고 사용자가 선택 가능한 어시스턴트 GUI 요소를 무시(dismisses)(예를 들어, swipes away)할 때, 자동화된 어시스턴트는 운전 모드에 따라 계속 동작할 수 있다. 그러나 신뢰도 점수가 특정 신뢰도 점수 임계값을 만족하지 못할 때, 자동화된 어시스턴트는 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택할 때까지 운전 모드에 따라 동작하지 않고 및/또는 어시스턴트 운전 모드 GUI를 제시하지 않을 수도 있다. In some implementations, an automated assistant may detect when a user moves to a vehicle with his/her computing device and, in response, cause the display interface of the computing device to render selectable assistant graphical user interface (GUI) elements. . In some implementations, the prediction that the user is moving may be characterized by a confidence score determined by an automated assistant. Once a selectable assistant GUI element is selected by the user (e.g., via touch input or voice utterance), the automated assistant may cause the assistant driving mode GUI to be rendered in the display interface. If the confidence score satisfies a certain confidence threshold, the automated assistant will act according to the driving mode to process input and/or generate output in a manner optimized for driving, even if the user has not selected any of the selectable assistant GUI elements. You can. In some implementations, when the confidence score meets a certain confidence score threshold and the user dismisses selectable assistant GUI elements (e.g., swipes away), the automated assistant may continue to operate according to the driving mode. there is. However, when the confidence score does not meet a certain confidence score threshold, the automated assistant may not act upon the driving mode and/or not present the assistant driving mode GUI until the user selects a selectable assistant GUI element. .
어시스턴트 운전 모드 GUI는 사용자의 여행(excursion)을 지원하고, 알림을 보고, 및/또는 컴퓨팅 장치의 하나 이상의 동작을 제어하기 위한 하나 이상의 옵션을 제공할 수 있다. 예를 들어, 어시스턴트 운전 모드 GUI는 사용자의 예상 목적지에 대한 표시를 제공할 수 있고, 사용자가 예상 목적지에 대한 내비게이션 명령을 제공하도록 선택할 수 있다. 대안적으로 또는 추가적으로, 어시스턴트 운전 모드 GUI는 사용자가 차량을 타고 이동하는 동안 보고 싶어할 수 있는 통신 알림(예: 수신 메시지) 및/또는 예측 미디어의 표시를 제공할 수 있다. 어시스턴트 운전 모드 GUI는 운전에 최적화될 수 있는 글꼴 크기 및 색상과 같은 특성을 갖도록 렌더링될 수 있으므로 운전 중 사용자의 주의가 산만해지는 것을 완화할 수 있다. 즉, 어시스턴트 운전 모드 GUI는 비운전 모드 GUI와 다른 특성(들)을 포함할 수 있고, 이러한 특성(들)은 운전 모드 GUI와 상호작용하는데 필요한 인지량(amount of cognition)을 줄이기 위해 활용될 수 있다. The assistant driving mode GUI may provide one or more options to assist the user in excursions, view notifications, and/or control one or more operations of the computing device. For example, an assisted driving mode GUI may provide an indication of the user's expected destination, and the user may choose to provide navigation commands to the expected destination. Alternatively or additionally, the assistant driving mode GUI may provide a display of communication alerts (e.g., incoming messages) and/or predictive media that the user may want to see while traveling in the vehicle. Assisted driving mode GUIs can be rendered with characteristics such as font size and color that can be optimized for driving, thereby mitigating user distraction while driving. That is, the assistant driving mode GUI may include characteristic(s) that are different from the non-driving mode GUI, and these characteristic(s) may be utilized to reduce the amount of cognition required to interact with the driving mode GUI. there is.
일부 구현에서, 사용자가 차량을 타고 이동하는 것으로 결정되면, 자동화된 어시스턴트는 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택하지 않을 때에도 컴퓨팅 장치의 다양한 인터페이스를 운전에 최적화되도록 사전에 조정할 수 있다. 예를 들어, 선택 가능한 어시스턴트 GUI 요소가 사용자가 차량을 운전하고 있다는 것을 검출한 것에 응답하여 렌더링될 때, 자동화된 어시스턴트는 운전에 최적화된 형식으로 특정 알림(통지)을 렌더링할 수도 있다. 예를 들어, "부재중 전화(missed call)" 알림(통지) 및/또는 "읽지 않은 텍스트" 알림(통지)은 사용자가 운전 중일 것으로 예측되지 않은 경우에 사용되는 것보다 더 큰 글꼴 크기 및/또는 더 큰 영역으로 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링될 수 있다. 대안으로 또는 추가적으로, 선택 가능한 제안은 상황에 따라 사용자가 액세스할 것으로 예상되는 콘텐츠 및/또는 애플리케이션에 대한 바로가기를 제공하기 위해 운전에 최적화된 형식으로 사전에 렌더링될 수도 있다. 예를 들어, 운전에 최적화된 선택 가능한 제안은 사용자가 운전 중에 듣고 싶어하는 팟캐스트(podcast)에 해당할 수 있다. 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택하지 않았더라도, 자동화된 어시스턴트는 그럼에도 불구하고 운전에 최적화된 형식으로 선택 가능한 제안을 렌더링할 수 있다. In some implementations, once the user determines to travel in a vehicle, the automated assistant may proactively adjust various interfaces of the computing device to optimize driving, even when the user does not select selectable assistant GUI elements. For example, when a selectable assistant GUI element is rendered in response to detecting that the user is driving a vehicle, the automated assistant may render specific notifications in a format optimized for driving. For example, “missed call” notifications (Notifications) and/or “unread text” notifications (Notifications) may use a larger font size and/or text size than would be used when the user is not expected to be driving. A larger area can be rendered on the display interface of the computing device. Alternatively or additionally, selectable suggestions may be pre-rendered in a format optimized for driving to provide shortcuts to content and/or applications the user is expected to access depending on the context. For example, optional suggestions optimized for driving may correspond to podcasts the user wants to listen to while driving. Even if the user does not select a selectable assistant GUI element, the automated assistant may nonetheless render selectable suggestions in a format optimized for driving.
일부 구현예에서, 사용자는 사용자가 차량을 타고 이동하는 것으로 결정되거나 예측되는 동안 컴퓨팅 장치의 디스플레이 인터페이스로부터 선택 가능한 어시스턴트 GUI 요소를 제거하기 위한 입력을 제공할 수 있다. 이에 응답하여, 자동화된 어시스턴트는 자동화된 어시스턴트 상호 작용이 운전에 최적화될 수 있는 경량 운전 최적화 모드에서 동작할 수 있지만 컴퓨팅 장치의 다른 기능은 원래 특성을 나타낼 수 있다. 예를 들어, 경량 운전 최적화 모드(light driving-optimized mode)에서 컴퓨팅 장치의 홈 화면은 운전에 최적화된 형식으로 렌더링되지 않을 수 있으며 선택 가능한 어시스턴트 GUI 요소를 포함하지 않을 수 있다. 대안적으로 또는 추가적으로, 경량 운전 최적화 모드에서는 자동화된 어시스턴트 이외의 다른 애플리케이션이 운전 최적화 모드에서 나타나는 다른 특성과 다른 특성을 나타낼 수 있다. 그러나 경량 운전 최적화 모드에서, 자동화된 어시스턴트는 차량을 타고 이동하는 동안 컴퓨팅 장치와 상호작용할 때 경험하는 위험을 완화하기 위해 운전에 최적화된 알림, 응답 및/또는 기타 콘텐츠를 사용자에게 제공할 수 있다. In some implementations, a user may provide input to remove a selectable assistant GUI element from the display interface of the computing device while the user is determined or predicted to be traveling in a vehicle. In response, the automated assistant may operate in a light driving optimization mode in which the automated assistant interaction may be optimized for driving while other functions of the computing device may exhibit native characteristics. For example, in a light driving-optimized mode, the computing device's home screen may not be rendered in a driving-optimized format and may not include selectable assistant GUI elements. Alternatively or additionally, in the light driving optimization mode, applications other than the automated assistant may exhibit characteristics that are different from other characteristics exhibited in the driving optimization mode. However, in a light driving optimization mode, the automated assistant may provide the user with driving-optimized notifications, responses, and/or other content to mitigate the risks experienced when interacting with a computing device while traveling in a vehicle.
일부 구현예에서, 사용자는 사용자가 운전하지 않을 때 - 심지어 자동화된 어시스턴트가 사용자가 운전하고 있다고 예측하더라도 운전 최적화 모드 및/또는 경량 운전 최적화 모드를 비활성화하도록 선택할 수 있다. 사용자가 명시적으로 제공한 대로 사용자가 운전 중이 아니라는 표시는 자동화된 어시스턴트를 추가로 훈련하는 데 사용될 수 있다. 예를 들어, 사용자가 차량을 타고 이동하고 있다는 예측을 하는 데 사용되는 하나 이상의 표시(예: 특정 애플리케이션, 캘린더 이벤트 등에 액세스하는 사용자)는 사용자가 이동 중이 아니라는 것을(예: 사용자가 "Assistant, cancel driving mode(어시스턴트, 운전 모드 취소해 줘)", "Assistant, I'm not driving(어시스턴트, 나 운전 안 해)" 등의 입력을 할 때) 명시적으로 나타내는 것에 응답하여 예측에 이어 더 낮은 우선순위가 할당될 수 있다. 더 낮은 우선순위 표시는 이후 사용자가 차량으로 이동하고 있는지 여부와 관련된 후속 예측에 대한 신뢰도 점수에 영향을 미칠 수 있다. 이러한 방식으로, 사용자는 그러한 표시가 발생할 때 운전 모드를 해제하기 위한 입력을 반복할 필요가 없으며, 이에 따라 자동화된 어시스턴트에 의해 처리되는 사용자 입력의 수를 줄이고 또한 자동화된 어시스턴트를 위한 계산 리소스를 보존할 수 있다. In some implementations, the user may choose to disable the Driving Optimization Mode and/or the Light Driving Optimization Mode when the user is not driving - even if the automated assistant predicts that the user is driving. An indication that the user is not driving, as explicitly provided by the user, can be used to further train the automated assistant. For example, one or more indications used to predict that a user is traveling in a vehicle (e.g., a user accessing a particular application, calendar event, etc.) may indicate that the user is not moving (e.g., that the user is "Assistant, cancel"). lower priority following prediction in response to explicit indications (when inputting "Assistant, I'm not driving", etc.) Rankings may be assigned. A lower priority indication may subsequently affect the confidence score for subsequent predictions regarding whether the user is traveling by vehicle. In this way, the user does not have to repeat inputs to disengage driving mode when such an indication occurs, thereby reducing the number of user inputs processed by the automated assistant and also conserving computational resources for the automated assistant. can do.
위의 설명은 본 개시의 일부 구현의 개요로서 제공된다. 이러한 구현 및 다른 구현에 대한 추가 설명은 아래에서 더 자세히 설명된다. The above description is provided as an overview of some implementations of the present disclosure. Additional descriptions of these and other implementations are described in greater detail below.
다른 구현은 하나 이상의 프로세서(예를 들어, 중앙 처리 장치(들)(CPU(들)), 그래픽 처리 장치(GPU) 및/또는 위에서 설명한 방법 및/또는 본 문서의 다른 곳에서 설명한 방법 중 하나 이상과 같은 방법을 수행하기 위한 텐서 처리 장치(TPU)에 의해 실행 가능한 명령어를 저장하는 비일시적 컴퓨터 판독 가능 저장 매체를 포함할 수 있다. 또 다른 구현은 위에서 및/또는 본 문서의 다른 곳에서 설명된 방법 중 하나 이상과 같은 방법을 수행하기 위해 저장된 명령어를 실행하도록 동작 가능한 하나 이상의 프로세서를 포함하는 하나 이상의 컴퓨터로 구성된 시스템을 포함할 수 있다. Other implementations may include one or more processors (e.g., a central processing unit(s) (CPU(s)), a graphics processing unit (GPU), and/or one or more of the methods described above and/or elsewhere herein. It may include a non-transitory computer-readable storage medium that stores instructions executable by a tensor processing unit (TPU) for performing a method such as. Another implementation is described above and/or elsewhere in this document. A system comprising one or more computers operable to execute stored instructions to perform one or more of the methods may include one or more of the methods.
전술한 개념과 본 명세서에 더 자세히 설명된 추가 개념의 모든 조합은 본 명세서에 개시된 주제의 일부인 것으로 고려된다는 것이 이해되어야 한다. 예를 들어, 본 개시의 마지막 부분에 나타나는 청구된 요지의 모든 조합은 본 명세서에 개시된 요지의 일부인 것으로 고려된다. It should be understood that all combinations of the foregoing concepts with additional concepts described in greater detail herein are considered to be part of the subject matter disclosed herein. For example, any combination of claimed subject matter that appears at the end of this disclosure is considered to be part of the subject matter disclosed herein.
도 1a, 도 1b, 도 1c 및 도 1d는 사용자가 차량을 타고 이동하는 것으로 예측되는지 여부에 따라 기능을 적응시킬 수 있는 자동화된 어시스턴트에 대한 액세스를 제공하는 개인 컴퓨팅 장치를 가지고 차량을 타고 이동하는 사용자의 모습을 예시한다.
도 2는 사용자가 차량을 타고 이동하는 것으로 예측되는 신뢰도에 따라 특정한 운전 최적화 기능을 촉진하는(용이하게 하는) 자동화된 어시스턴트를 제공하는 시스템을 도시한다.
도 3은 어시스턴트 운전 최적화 모드에서 자동화된 어시스턴트를 능동적으로 동작하고, 사용자가 운전 최적화 모드에서 동작하도록 명시적으로 선택한 경우 추가적인 운전 최적화 기능을 제공하는 방법을 예시한다.
도 4는 예시적인 컴퓨터 시스템의 블록도이다.1A, 1B, 1C, and 1D illustrate a user traveling in a vehicle with a personal computing device that provides access to an automated assistant that can adapt its functionality depending on whether the user is predicted to be traveling in a vehicle. Illustrates the user's appearance.
2 illustrates a system that provides an automated assistant that promotes (facilitates) specific driving optimization functions depending on the user's predicted confidence in traveling in the vehicle.
3 illustrates a method of actively operating an automated assistant in an assistant driving optimization mode and providing additional driving optimization functions when a user explicitly selects to operate in the driving optimization mode.
Figure 4 is a block diagram of an example computer system.
도 1a, 도 1b, 도 1c 및 도 1d는 사용자(102)가 비히클(vehicle)(이하, 차량으로 칭함)을 타고 이동할 것으로 예측되는지 여부에 따라 기능을 적응시키는 자동화된 어시스턴트에 대한 액세스를 제공하는 개인용 컴퓨팅 장치(104)를 가지고 차량(108)을 타고 이동하는 사용자(102)의 뷰(100), 뷰(120), 뷰(140) 및 뷰(160)를 예시한다. 예를 들어, 사용자(102)는 자동화된 어시스턴트에 대한 액세스를 제공할 수 있는 컴퓨팅 장치(104)를 사용하여 차량(108)에 진입할 수 있다. 컴퓨팅 장치(104)가 차량(비히클) 컴퓨팅 장치와 연결하기 위해 차량(108)의 차량 컴퓨팅 장치의 범위 내에 있을 때, 자동화된 어시스턴트는 사용자(102)가 차량(108)을 타고 이동하고 있다고 예측할 수 있다. 예를 들어, 컴퓨팅 장치(104)는 무선 또는 유선 통신 프로토콜을 통해 차량 컴퓨팅 장치에 연결할 수 있다. 자동화된 어시스턴트가 이 연결에 기초하여 사용자(102)가 차량(108)을 타고 이동 중이거나 이동할 것이라고 예측할 때, 자동화된 어시스턴트는 선택 가능한 어시스턴트 GUI 요소(110)가 차량(108)의 디스플레이 인터페이스(106)에서 렌더링되게 할 수 있다. 사용자(102)가 선택 가능한 어시스턴트 GUI 요소(110)를 선택할 때, 자동화된 어시스턴트는 어시스턴트 운전 모드 GUI가 컴퓨팅 장치(104)의 디스플레이 인터페이스 및/또는 차량 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되게 할 수 있다. 일부 구현에서, 자동화된 어시스턴트가 사용자(102)가 전술한 연결 및/또는 내비게이션 애플리케이션의 사용자 개시 액세스에 기초하여 이동 중이거나 이동할 것이라고 예측할 때, 자동화된 어시스턴트는 어시스턴트 운전 모드에 따라 자동으로 동작할 수 있다. 1A, 1B, 1C, and 1D provide access to an automated assistant that adapts functionality depending on whether the user 102 is expected to travel in a vehicle (hereinafter referred to as vehicle). Examples include views 100 , 120 , 140 , and 160 of a user 102 traveling in a vehicle 108 with a personal computing device 104 . For example, user 102 may enter vehicle 108 using computing device 104, which may provide access to an automated assistant. When computing device 104 is within range of a vehicle computing device of vehicle 108 to connect with the vehicle computing device, the automated assistant may predict that user 102 is traveling in vehicle 108. there is. For example, computing device 104 may connect to a vehicle computing device via wireless or wired communication protocols. When the automated assistant predicts, based on this connection, that the user 102 is or will be traveling in the vehicle 108, the automated assistant determines that the selectable assistant GUI element 110 will be displayed in the display interface 106 of the vehicle 108. ) can be rendered in . When user 102 selects selectable assistant GUI element 110 , the automated assistant may cause the assistant driving mode GUI to be rendered on the display interface of computing device 104 and/or the display interface of the vehicle computing device. In some implementations, when the automated assistant predicts that the user 102 is moving or will be moving based on user-initiated access to the connectivity and/or navigation application described above, the automated assistant may automatically operate in accordance with the assistant driving mode. there is.
예를 들어, 도 1b의 뷰(120)에 도시된 바와 같이, 컴퓨팅 장치의 자동화된 어시스턴트 및/또는 하나 이상의 다른 애플리케이션은 사용자(102)가 선택 가능한 어시스턴트 GUI 요소(110)를 선택하기 전에 어시스턴트 운전 모드에 따라 동작할 수 있다. 어시스턴트 운전 모드에 따라 자동화된 어시스턴트가 동작 중인 경우, 운전에 최적화된 방식으로 알림 및/또는 기타 동작의 렌더링이 수행될 수 있다. 예를 들어, 사용자(102)가 수신 메시지를 수신하고 컴퓨팅 장치(104)가 어시스턴트 운전 모드에 따라 동작하고 있을 때, 수신 메시지는 어시스턴트 제안(assistant suggestion)(124)을 생성하는 데 사용될 수 있다. 어시스턴트 제안(124)은 어시스턴트 제안(124)이 비운전 모드에서 렌더링될 때 달라질 수 있는 하나 이상의 특성으로 렌더링될 수 있다. 예를 들어, 특성 중 하나 이상은 어시스턴트 제안(124)의 텍스트 크기, 텍스트의 스타일, 어시스턴트 제안(124)에 대응하는 음성 특성이 있는지 여부(예: 자동화된 어시스턴트가 메시지 알림을 청각적으로 렌더링함), 어시스턴트 제안(124)에 의해 점유되는 디스플레이 인터페이스(106)의 영역, 및/또는 애플리케이션 알림과 연관될 수 있는 기타 특성을 포함할 수 있다. For example, as shown in view 120 of FIG. 1B , an automated assistant on a computing device and/or one or more other applications may perform assistant driving prior to user 102 selecting selectable assistant GUI element 110 . It can operate depending on the mode. When an automated assistant is operating according to the assistant driving mode, notifications and/or other actions may be rendered in a manner optimized for driving. For example, when user 102 receives an incoming message and computing device 104 is operating in accordance with an assistant driving mode, the incoming message may be used to generate an assistant suggestion 124. Assistant suggestions 124 may be rendered with one or more characteristics that may vary when assistant suggestions 124 are rendered in a non-driving mode. For example, one or more of the characteristics may include the size of the text in the assistant suggestion 124, the style of the text, whether there is a corresponding voice characteristic in the assistant suggestion 124 (e.g., whether the automated assistant renders the message notification audibly) ), the area of display interface 106 occupied by assistant suggestions 124, and/or other characteristics that may be associated with application notifications.
일부 구현에서, 선택 가능한 어시스턴트 GUI 요소(110)가 디스플레이 인터페이스(106)로부터 제거될 때를 나타내기 위해 카운트다운 타이머가 디스플레이 인터페이스(106)에서 렌더링될 수 있다. 일부 구현예에서, 카운트다운 타이머는 어시스턴트 운전 모드 GUI(144)가 디스플레이 인터페이스(106)에서 렌더링될 때를 나타내기 위해 디스플레이 인터페이스(106)에서 렌더링될 수 있다(사용자(102)가 카운트다운 타이머가 만료되기 전에 선택 가능한 어시스턴트 GUI 요소(110)를 해제하지 않는다고 가정한다.). 일부 구현예에서, 카운트다운 타이머의 기간이 만료될 때 수행되는 액션은 사용자가 이동하고 있다는 예측에 대한 신뢰도 점수에 기초할 수 있다. 예를 들어, 신뢰도 점수가 신뢰도 점수 임계값을 만족할 때, 타이머의 만료로 인해 어시스턴트 운전 모드 GUI(144)가 렌더링될 수 있다. 그러나, 신뢰도 점수가 신뢰도 점수 임계값을 만족하지 않을 때, 타이머의 만료로 인해 어시스턴트 운전 모드 GUI(144)가 렌더링되지 않을 수 있지만 자동화된 어시스턴트는 여전히 운전 최적화 모드에서 동작할 수 있다. In some implementations, a countdown timer may be rendered in display interface 106 to indicate when a selectable assistant GUI element 110 is removed from display interface 106. In some implementations, a countdown timer may be rendered in the display interface 106 to indicate when the assistant driving mode GUI 144 is rendered in the display interface 106 (if the user 102 determines that the countdown timer is Assume you do not release the selectable Assistant GUI element 110 before it expires.) In some implementations, the action performed when the countdown timer's period expires may be based on a confidence score for the prediction that the user is moving. For example, when the confidence score satisfies a confidence score threshold, the expiration of a timer may cause the assistant driving mode GUI 144 to be rendered. However, when the confidence score does not meet the confidence score threshold, the assistant driving mode GUI 144 may not be rendered due to expiration of the timer but the automated assistant may still operate in the driving optimization mode.
일부 구현예에서, 카운트다운 타이머의 기간(duration)은 사용자(102)가 차량을 타고 이동하고 있다는 예측과 상관되는 신뢰도 및/또는 신뢰도 점수에 기초할 수 있다. 예를 들어, 예측에 대한 신뢰도가 낮을 때와 비교하여 사용자(102)가 이동하고 있다는 예측에 더 큰 신뢰도가 있을 때 기간은 더 길어질 수 있다. 일부 구현예에서, 자동화된 어시스턴트는 카운트다운 타이머의 기간 내에 사용자(102)가 선택 가능한 어시스턴트 GUI 요소(110)를 선택하는지 여부에 관계없이 어시스턴트 운전 모드에 따라 동작할 수 있다. 그러나, 사용자(102)는 임계 기간 내에 선택 가능한 어시스턴트 GUI 요소(110)를 선택할 수 없으므로 어시스턴트 운전 모드 GUI(144)가 디스플레이 인터페이스(106)에서 렌더링되게 하지 않을 수 있다. 일부 구현예에서, 점수는 어시스턴트 운전 모드에서 자동으로 동작할지, 아니면 어시스턴트 운전 모드에서 동작하기 전에 사용자(102)가 선택 가능한 어시스턴트 GUI 요소(110)를 선택할 때까지 기다릴지를 결정하기 위한 점수 임계값과 비교될 수 있다. 예를 들어, 점수가 점수 임계값을 만족할 때, 자동화된 어시스턴트 및/또는 컴퓨팅 장치(104)는 어시스턴트 운전 모드에 따라 동작할 수 있다. 그렇지 않고, 점수가 점수 임계값을 만족하지 않을 때, 자동화된 어시스턴트는 선택 가능한 어시스턴트 GUI 요소(110)가 디스플레이 인터페이스(106)에서 렌더링되게 할 수 있다. 일부 구현에서, 점수 임계값은 사용자(102), 자동화된 어시스턴트, 및/또는 자동화된 어시스턴트와 연관될 수 있는 임의의 다른 애플리케이션에 의해 설정될 수 있다. In some implementations, the duration of the countdown timer may be based on confidence and/or a confidence score that is correlated with the prediction that user 102 is traveling in a vehicle. For example, the period may be longer when there is greater confidence in the prediction that user 102 is moving compared to when confidence in the prediction is low. In some implementations, the automated assistant may operate according to the assistant driving mode regardless of whether the user 102 selects the selectable assistant GUI element 110 within the period of the countdown timer. However, the user 102 may not be able to select a selectable assistant GUI element 110 within the threshold period, thereby causing the assistant driving mode GUI 144 to be rendered in the display interface 106 . In some implementations, the score may include a score threshold to determine whether to automatically operate in the assistant driving mode or wait until the user 102 selects a selectable assistant GUI element 110 before operating in the assistant driving mode. can be compared. For example, when a score meets a score threshold, automated assistant and/or computing device 104 may operate in accordance with an assistant driving mode. Otherwise, when the score does not meet the score threshold, the automated assistant may cause a selectable assistant GUI element 110 to be rendered in the display interface 106. In some implementations, the score threshold may be set by the user 102, the automated assistant, and/or any other application that may be associated with the automated assistant.
선택 가능한 어시스턴트 GUI 요소(110)의 선택이 도 1b에 도시된 바와 같이 사용자(102)로부터(예를 들어, 손(126) 및/또는 다른 입력을 통해) 수신될 때, 자동화된 어시스턴트는 어시스턴트 운전 모드 GUI(144)가 디스플레이 인터페이스(106)에서 렌더링되게 할 수 있다. 어시스턴트 운전 모드 GUI(144)의 하나 이상의 특성 및/또는 특징은 사용자(102)가 차량(108)을 타고 이동하고 있음을 예측하는 데 사용되는 데이터에 기초할 수 있다. 예를 들어, 컴퓨팅 장치(104)와 차량 컴퓨팅 장치 사이의 연결에 기초하여 사용자(102)가 이동 중일 것으로 예측될 때, 어시스턴트 운전 모드 GUI(144)는 내비게이션 인터페이스(146) 및 기타 제안된 콘텐츠로 렌더링될 수 있다. 다른 제안 콘텐츠는 미디어 스트리밍 애플리케이션을 열기 위한 어시스턴트 제안(148)(예: 제1 선택 가능한 요소) 및/또는 메시징 애플리케이션을 열기 위한 어시스턴트 제안(150)(예: 제2 선택 가능한 요소)일 수 있지만 이에 제한되지는 않는다. 내비게이션 인터페이스(146)는 사용자(102)가 이동할 것으로 예측되는 목적지까지의 경로에 관한 세부사항으로 렌더링될 수 있다. 예를 들어, 사용자(102)가 이동할 수 있는 목적지를 예측하기 위해 컴퓨팅 장치(104) 및/또는 자동화된 어시스턴트에 이용 가능한 컨텍스트 데이터 및/또는 다른 데이터가 처리될 수 있다. 특정 목적지가 식별되고 그리고 사용자(102)로부터 사전 허가를 받은 경우, 사용자(102)의 현재 위치에서 예측 목적지까지의 경로가 내비게이션 인터페이스(146)를 통해 사용자(102)에게 제공될 수 있다. 예를 들어, 도 1c에 도시된 바와 같이, 사용자(102)는 컨텍스트 데이터(예를 들어, 시간, 사용자(102)와 자동화된 어시스턴트 사이의 최근 상호작용, 자동화된 어시스턴트에 전달된 차량(비히클) 상태 데이터, 자동화된 어시스턴트에 의해 액세스되도록 허용된 애플리케이션 데이터 등)에 기초하여 "Ear-X-Y-Z"로 이동할 것으로 예측될 수 있다. When a selection of selectable assistant GUI element 110 is received from user 102 (e.g., via hand 126 and/or other input) as shown in FIG. 1B, the automated assistant performs assistant driving. Mode GUI 144 may be rendered in display interface 106 . One or more features and/or characteristics of the assistant driving mode GUI 144 may be based on data used to predict that the user 102 is traveling in the vehicle 108 . For example, when it is predicted that user 102 will be moving based on the connection between computing device 104 and the vehicle computing device, assistant driving mode GUI 144 may provide navigation interface 146 and other suggested content. can be rendered. Other suggested content may be an assistant suggestion 148 to open a media streaming application (e.g., a first selectable element) and/or an assistant suggestion 150 to open a messaging application (e.g., a second selectable element), but It is not limited. Navigation interface 146 may be rendered with details regarding the route to the destination where user 102 is expected to travel. For example, context data and/or other data available to computing device 104 and/or automated assistant may be processed to predict destinations to which user 102 may travel. If a specific destination has been identified and prior permission has been received from user 102, a route from user 102's current location to the predicted destination may be provided to user 102 via navigation interface 146. For example, as shown in Figure 1C, user 102 may collect context data (e.g., time, recent interaction between user 102 and the automated assistant, vehicle) communicated to the automated assistant. It can be predicted to go "Ear-X-Y-Z" based on status data, application data allowed to be accessed by automated assistants, etc.).
일부 구현에서, 자동화된 어시스턴트는 초기에 선택 가능한 어시스턴트 GUI 요소(110)가 디스플레이 인터페이스(106)에서 렌더링되게 하지 않고 내비게이션 인터페이스가 어시스턴트 운전 모드 GUI(144)로 렌더링되게 할 수 있다. 예를 들어, 이동 예측(travel prediction)에 대한 신뢰도 점수가 제1 점수 임계값을 만족할 때, 자동화된 어시스턴트는 선택 가능한 어시스턴트 GUI 요소(110)가 디스플레이 인터페이스(106)에서 렌더링되게 할 수 있다. 그러나 신뢰도 점수가 제2 점수 임계값을 만족하면, 자동화된 어시스턴트는 선택 가능한 어시스턴트 GUI 요소(110)를 초기에 렌더링하지 않고 도 1c의 어시스턴트 운전 모드 GUI(144)가 렌더링되도록 할 수 있다. 일부 구현에서, 제2 점수 임계값을 만족하는 신뢰도 점수는 내비게이션 애플리케이션이 컴퓨팅 장치(104)에서 액세스되고 있는 동안 컴퓨팅 장치(104)가 차량 컴퓨팅 장치에 연결되어 있다는 결정에 기초할 수 있다. 대안적으로, 내비게이션 애플리케이션이 컴퓨팅 장치(104)에서 액세스되고 있고 및/또는 컴퓨팅 장치(104)의 하나 이상의 센서가 사용자(102)가 차량을 타고 이동하고 있음을 나타낼 때(예: 속도, 가속도, 고도 등의 변화를 기준으로 함) 제1 점수 임계값이 만족될 수 있다. In some implementations, the automated assistant may cause the navigation interface to be rendered into the assistant driving mode GUI 144 without initially causing the selectable assistant GUI elements 110 to be rendered in the display interface 106 . For example, when the confidence score for a travel prediction satisfies a first score threshold, the automated assistant may cause a selectable assistant GUI element 110 to be rendered in display interface 106. However, if the confidence score satisfies the second score threshold, the automated assistant may cause the assistant driving mode GUI 144 of FIG. 1C to be rendered without initially rendering the selectable assistant GUI element 110. In some implementations, a confidence score that satisfies the second score threshold may be based on a determination that computing device 104 is connected to the vehicle computing device while a navigation application is being accessed at computing device 104 . Alternatively, when a navigation application is being accessed on computing device 104 and/or one or more sensors on computing device 104 indicate that user 102 is moving in a vehicle (e.g., speed, acceleration, A first score threshold (based on changes in altitude, etc.) may be satisfied.
자동화된 어시스턴트가 어시스턴트 운전 모드에 따라 동작할 때, 사용자(102)가 차량(108)을 타고 이동 중인 현재 컨텍스트에 따라 자동화된 어시스턴트에 대한 입력이 처리(프로세싱)될 수 있다. 예를 들어, 사용자(102)가 차량(108)을 타고 이동하지 않고 집 안에 있을 때, "Assistant, Doo-Wop Store"와 같은 자동화된 어시스턴트에 대한 음성 발화(142)는 웹사이트에 대한 인터넷 검색이나 사전적 의미(definition)로 처리(프로세싱)될 수 있다. 그러나, 사용자(102)가 차량(108)을 타고 이동하는 것으로 예측될 때, 음성 발화(142)는 차량(108)을 타고 이동하는 사용자(102)의 컨텍스트에 기초하여 처리(프로세싱)될 수 있다. 예를 들어, 사용자(102)가 음성 발화(142)을 제공할 때, 자동화된 어시스턴트는 음성 발화(142)의 콘텐츠에 지정된 특정 목적지로의 방향을 찾으라는 요청으로서 음성 발화(142)을 처리할 수 있다. 이 처리의 결과는 도 1d의 뷰(160)에 도시된 바와 같이, 어시스턴트 운전 모드 GUI(144)에서 렌더링될 수 있다.When the automated assistant operates according to the assistant driving mode, input to the automated assistant may be handled (processed) according to the current context in which the user 102 is traveling in the vehicle 108. For example, when user 102 is at home and not traveling in vehicle 108, voice utterance 142 to an automated assistant, such as “Assistant, Doo-Wop Store,” may be used to search the Internet for a website. Or it can be processed as a dictionary meaning (definition). However, when the user 102 is predicted to be traveling in the vehicle 108, the vocal utterance 142 may be processed based on the context of the user 102 traveling in the vehicle 108. . For example, when user 102 provides spoken utterance 142, the automated assistant may process spoken utterance 142 as a request to find directions to a specific destination specified in the content of spoken utterance 142. You can. The results of this processing may be rendered in the assistant driving mode GUI 144, as shown in view 160 in FIG. 1D.
일부 경우에, 사용자(102)는 어시스턴트 운전 모드 GUI(144)를 더 이상 보지 않기를 원할 수 있다. 어시스턴트 운전 모드 GUI(144)를 해제하기 위해, 사용자(102)는 자동화된 어시스턴트 및/또는 컴퓨팅 장치(104)에 입력을 제공하여(예를 들어, 디스플레이 인터페이스(106)를 스와이프(swip)하거나 "해제(dismiss)"라고 말함으로써) 어시스턴트 운전 모드 GUI(144)가 디스플레이 인터페이스(106)에서 제거되도록 할 수 있다. 이에 응답하여, 자동화된 어시스턴트는 디스플레이 인터페이스(106)가 도 1c에 표시된 콘텐츠로부터 도 1a에 표시된 콘텐츠로 되돌아가게 할 수 있다. 즉, 사용자(102)가 도 1c에서 렌더링된 어시스턴트 운전 모드 GUI(144)를 해제한 것에 응답하여, 자동화된 어시스턴트는 도 1a에 도시된 바와 같이 어시스턴트 운전 모드 GUI(144)를 선택 가능한 어시스턴트 GUI 요소(110)로 대체할 수 있다. In some cases, user 102 may wish to no longer view assistant driving mode GUI 144. To disengage the assistant driving mode GUI 144, the user 102 may provide input to the automated assistant and/or computing device 104 (e.g., swipe the display interface 106 or You can cause the assistant driving mode GUI 144 to be removed from the display interface 106 (by saying “dismiss”). In response, the automated assistant may cause display interface 106 to return from the content displayed in FIG. 1C to the content displayed in FIG. 1A. That is, in response to the user 102 disabling the assistant driving mode GUI 144 rendered in FIG. 1C, the automated assistant displays the assistant GUI element selectable with the assistant driving mode GUI 144 as shown in FIG. 1A. It can be replaced with (110).
일부 구현예에서, 사용자(102)는 도 1c의 뷰(140)에 예시된 바와 같이, 자동화된 어시스턴트가 어시스턴트 운전 모드에 따라 동작하는 동안 어시스턴트 제안(150)을 선택할 수도 있다. 이에 대응하여, 어시스턴트 제안(150)의 콘텐츠가 차지하는 디스플레이 인터페이스(106)의 영역은 더 큰 영역으로 확장될 수 있다. 대안적으로 또는 추가적으로, 어시스턴트 제안(150)과 연관된 추가 콘텐츠는 사용자(102)가 어시스턴트 제안(150)을 선택하는 것에 응답하여 렌더링될 수 있다. 예를 들어, 도 1d에 도시된 바와 같이, 어시스턴트 제안(150)은 다수의 다른 사람들로부터 수신된 다수의 메시지를 특성화하는(characterizing) 콘텐츠를 포함하도록 확장될 수 있다. 사용자(102)는 자동화된 어시스턴트가 보다 안전한 운전에 최적화된 방식으로 메시지의 콘텐츠를 렌더링하도록 하기 위해, 도 1d에 도시된 바와 같이 메시지 중 하나를 선택할 수 있다. 예를 들어, 사용자(102)가 "제인(Jane)"의 메시지에 해당하는 GUI 요소를 탭하는 것에 응답하여, 자동화된 어시스턴트는 "Jane says: 'Do I need to bring anything?(제인이 말하길: 뭐라도 가져가야 하나요?)'"와 같은 출력(162)을 청각적으로 렌더링할 수 있으므로, 사용자(102)는 디스플레이 인터페이스(106)로부터 메시지를 읽을 필요가 없다. In some implementations, user 102 may select assistant suggestions 150 while the automated assistant is operating according to an assistant driving mode, as illustrated in view 140 of FIG. 1C. Correspondingly, the area of the display interface 106 occupied by the content of the assistant suggestion 150 may be expanded to a larger area. Alternatively or additionally, additional content associated with assistant suggestion 150 may be rendered in response to user 102 selecting assistant suggestion 150 . For example, as shown in Figure 1D, assistant suggestions 150 may be expanded to include content characterizing multiple messages received from multiple different people. User 102 can select one of the messages, as shown in Figure 1D, to have the automated assistant render the content of the message in a manner optimized for safer driving. For example, in response to user 102 tapping a GUI element corresponding to the message “Jane,” the automated assistant may display “Jane says: 'Do I need to bring anything? Output 162 such as "Do I need to get anything?" can be rendered audibly, so that the user 102 does not have to read the message from the display interface 106.
도 2는 사용자가 차량을 타고 이동하는 것으로 예측되는 신뢰도(즉, 신뢰도 점수)에 따라 특정 운전 최적화 기능을 촉진하는 자동화된 어시스턴트를 제공하는 시스템(200)을 예시한다. 자동화된 어시스턴트(204)는 컴퓨팅 장치(202) 및/또는 서버 장치와 같은 하나 이상의 컴퓨팅 장치에서 제공되는 어시스턴트 애플리케이션의 일부로서 동작할 수 있다. 사용자는 어시스턴트 인터페이스(들)(220)를 통해 자동화된 어시스턴트(204)와 상호작용할 수 있으며, 이는 마이크로폰, 카메라, 터치 스크린 디스플레이, 사용자 인터페이스, 및/또는 사용자와 애플리케이션 간의 인터페이스를 제공할 수 있는 기타 장치일 수 있다. 예를 들어, 사용자는 어시스턴트 인터페이스(220)에 구두, 텍스트 및/또는 그래픽 입력을 제공하여 자동화된 어시스턴트(204)가 하나 이상의 동작(예: 데이터 제공, 주변 장치 제어, 에이전트 액세스, 입력 및/또는 출력 생성 등)을 초기화하게 함으로써 자동화된 어시스턴트(204)를 초기화할 수 있다.2 illustrates a system 200 that provides an automated assistant that promotes specific driving optimization functions based on the user's predicted confidence in traveling in the vehicle (i.e., confidence score). Automated assistant 204 may operate as part of an assistant application provided on one or more computing devices, such as computing device 202 and/or server devices. A user may interact with an automated assistant 204 through assistant interface(s) 220, which may include a microphone, camera, touch screen display, user interface, and/or other device that may provide an interface between the user and the application. It could be a device. For example, a user may provide verbal, textual, and/or graphical input to assistant interface 220 to enable automated assistant 204 to perform one or more actions, such as providing data, controlling a peripheral device, accessing an agent, typing, and/or The automated assistant 204 can be initialized by initializing output generation, etc.).
대안적으로, 자동화된 어시스턴트(204)는 하나 이상의 트레이닝된 기계 학습 모델을 사용하는 컨텍스트 데이터(236)의 처리(프로세싱)에 기초하여 초기화될 수 있다. 컨텍스트 데이터(236)는 자동화된 어시스턴트(204)가 액세스 가능한 환경의 하나 이상의 특징, 및/또는 자동화된 어시스턴트(204)와 상호 작용할 의도가 있는 것으로 예측되는 (사용자의 사전 허가를 받은 경우) 사용자의 하나 이상의 특징을 특성화할 수 있다. 컴퓨팅 장치(202)는 디스플레이 장치를 포함할 수 있으며, 이는 터치 입력을 수신하기 위한 터치 인터페이스 및/또는 사용자가 터치 인터페이스를 통해 컴퓨팅 장치(202)의 애플리케이션(234)을 제어할 수 있게 하는 제스처를 포함하는 디스플레이 패널일 수 있다. 일부 구현에서, 컴퓨팅 장치(202)는 디스플레이 장치가 없을 수 있고, 따라서 그래픽 사용자 인터페이스 출력을 제공하지 않고 가청 사용자 인터페이스 출력을 제공할 수 있다. 또한, 컴퓨팅 장치(202)는 사용자로부터 음성 자연어 입력을 수신하기 위한 마이크로폰과 같은 사용자 인터페이스를 제공할 수 있다. 일부 구현에서, 컴퓨팅 장치(202)는 터치 인터페이스를 포함할 수 있고 카메라가 없을 수 있지만 선택적으로 하나 이상의 다른 센서를 포함할 수 있다. Alternatively, automated assistant 204 may be initialized based on processing of context data 236 using one or more trained machine learning models. Contextual data 236 may include one or more features of the environment accessible to automated assistant 204, and/or information about the user (if the user's prior permission is obtained) with which automated assistant 204 predicts that the user intends to interact. One or more features can be characterized. Computing device 202 may include a display device, which may include a touch interface for receiving touch input and/or gestures to allow a user to control applications 234 on computing device 202 via the touch interface. It may be a display panel including. In some implementations, computing device 202 may not have a display device and therefore may provide audible user interface output without providing graphical user interface output. Additionally, computing device 202 may provide a user interface, such as a microphone, for receiving vocal natural language input from a user. In some implementations, computing device 202 may include a touch interface and no camera, but may optionally include one or more other sensors.
컴퓨팅 장치(202) 및/또는 다른 제3자 클라이언트 장치는 인터넷과 같은 네트워크를 통해 서버 장치와 통신할 수 있다. 추가로, 컴퓨팅 장치(202) 및 임의의 다른 컴퓨팅 장치는 Wi-Fi 네트워크와 같은 LAN(local area network)을 통해 서로 통신할 수 있다. 컴퓨팅 장치(202)는 컴퓨팅 장치(202)에서 컴퓨팅 자원을 보존하기 위해 컴퓨팅 작업을 서버 장치로 오프로드할 수 있다. 예를 들어, 서버 장치는 자동화된 어시스턴트(204)를 호스팅할 수 있고/있거나 컴퓨팅 장치(202)는 하나 이상의 어시스턴트 인터페이스(220)에서 수신된 입력을 서버 장치로 전송할 수 있다. 그러나, 일부 구현에서, 자동화된 어시스턴트(204)는 컴퓨팅 장치(202)에서 호스팅될 수 있고, 자동화된 어시스턴트 동작과 연관될 수 있는 다양한 프로세스가 컴퓨팅 장치(202)에서 수행될 수 있다. Computing device 202 and/or other third-party client devices may communicate with the server device over a network, such as the Internet. Additionally, computing device 202 and any other computing device may communicate with each other via a local area network (LAN), such as a Wi-Fi network. Computing device 202 may offload computing tasks to a server device to conserve computing resources at computing device 202. For example, a server device can host automated assistant 204 and/or computing device 202 can transmit input received at one or more assistant interfaces 220 to the server device. However, in some implementations, automated assistant 204 may be hosted on computing device 202 and various processes that may be associated with automated assistant operations may be performed on computing device 202.
다양한 구현에서, 자동화된 어시스턴트(204)의 모든 에스펙트(aspects) 또는 그보다 적은 에스펙트가 컴퓨팅 장치(202)에서 구현될 수 있다. 이러한 구현 중 일부에서, 자동화된 어시스턴트(204)의 에스펙트는 컴퓨팅 장치(202)를 통해 구현되고 서버 장치와 인터페이스할 수 있으며, 이는 자동화된 어시스턴트(204)의 다른 에스펙트를 구현할 수 있다. 서버 장치는 다중 스레드를 통해 복수의 사용자 및 관련 어시스턴트 애플리케이션을 선택적으로 제공할 수 있다. 자동화된 어시스턴트(204)의 모든 에스펙트 또는 그보다 적은 에스펙트가 컴퓨팅 장치(202)를 통해 구현되는 구현에서, 자동화된 어시스턴트(204)는 컴퓨팅 장치(202)의 운영 체제 (예: 운영 체제 "탑(on top)"에 설치됨)와 별개인 애플리케이션일 수 있거나 또는 대안적으로 컴퓨팅 장치(202)의 운영 체제에 의해 직접 구현될 수 있다(예: 운영 체제의 애플리케이션으로 간주되지만 운영 체제와 통합됨).In various implementations, all or fewer aspects of automated assistant 204 may be implemented in computing device 202. In some of these implementations, aspects of automated assistant 204 may be implemented via computing device 202 and interface with a server device, which may implement other aspects of automated assistant 204. The server device may optionally serve multiple users and associated assistant applications through multiple threads. In implementations where all or fewer aspects of the automated assistant 204 are implemented via the computing device 202, the automated assistant 204 may run the operating system (e.g., an operating system "top") of the computing device 202. may be a separate application (installed “on top”) or alternatively, may be implemented directly by the operating system of computing device 202 (e.g., considered an application of the operating system but integrated with the operating system).
일부 구현에서, 자동화된 어시스턴트(204)는 입력 처리 엔진(206)을 포함할 수 있으며, 이는 컴퓨팅 장치(202) 및/또는 서버 장치에 대한 입력 및/또는 출력을 처리하기 위해 복수의 상이한 모듈을 사용할 수 있다. 예를 들어, 입력 처리 엔진(206)은 어시스턴트 인터페이스(220)에서 수신된 오디오 데이터를 처리하여 오디오 데이터에 구현된 텍스트를 식별할 수 있는 음성 처리 엔진(208)을 포함할 수 있다. 오디오 데이터는 예를 들어 컴퓨팅 장치(202)에서 컴퓨팅 리소스를 보존하기 위해 컴퓨팅 장치(202)에서 서버 장치로 전송될 수 있다. 부가적으로 또는 대안적으로, 오디오 데이터는 컴퓨팅 장치(202)에서 배타적으로 처리될 수 있다. In some implementations, automated assistant 204 may include an input processing engine 206, which may use a plurality of different modules to process input and/or output to computing device 202 and/or server device. You can use it. For example, input processing engine 206 may include a speech processing engine 208 that can process audio data received at assistant interface 220 to identify text embodied in the audio data. Audio data may be transferred from computing device 202 to a server device, for example, to conserve computing resources at computing device 202. Additionally or alternatively, audio data may be processed exclusively at computing device 202.
오디오 데이터를 텍스트로 변환하기 위한 프로세스는 신경망을 채용할 수 있는 음성 인식 알고리즘 및/또는 단어 또는 구에 대응하는 오디오 데이터 그룹을 식별하기 위한 통계 모델을 포함할 수 있다. 오디오 데이터로부터 변환된 텍스트는 데이터 파싱 엔진(210)에 의해 파싱될 수 있고 명령 구문(들), 의도(intent)(들), 액션(들), 슬롯 값(들) 및/또는 사용자가 지정한 기타 콘텐츠를 생성 및/또는 식별하는 데 사용될 수 있는 텍스트 데이터로서 자동화된 어시스턴트(204)에 제공될 수 있다. 일부 구현에서, 데이터 파싱 엔진(210)에 의해 제공된 출력 데이터는 사용자가 특정 의도, 액션, 및/또는 자동화된 어시스턴트(204)에 의해 수행될 수 있는 루틴 및/또는 자동화된 어시스턴트(204)를 통해 액세스될 수 있는 애플리케이션 또는 에이전트에 대응하는 입력을 제공했는지 여부를 결정하기 위해 파라미터 엔진(212)에 제공될 수 있다. 예를 들어, 어시스턴트 데이터(238)는 서버 장치 및/또는 컴퓨팅 장치(202)에 저장될 수 있고, 자동화된 어시스턴트(204)에 의해 수행될 수 있는 하나 이상의 액션(동작)을 정의하는 데이터뿐만 아니라 액션(동작)을 수행하는 데 필요한 파라미터를 포함할 수 있다. 파라미터 엔진(212)은 의도, 액션 및/또는 슬롯 값에 대한 하나 이상의 파라미터를 생성하고 하나 이상의 파라미터를 출력 생성 엔진(214)에 제공할 수 있다. 출력 생성 엔진(214)은 하나 이상의 파라미터를 사용하여 사용자에게 출력을 제공하기 위해 어시스턴트 인터페이스(220)와 통신하고/하거나 하나 이상의 애플리케이션(234)에 출력을 제공하기 위해 하나 이상의 애플리케이션(234)과 통신할 수 있다. The process for converting audio data to text may include speech recognition algorithms, which may employ neural networks and/or statistical models to identify groups of audio data that correspond to words or phrases. Text converted from audio data may be parsed by the data parsing engine 210 and may contain command syntax(s), intent(s), action(s), slot value(s), and/or other user-specified information. It may be provided to automated assistant 204 as text data that can be used to create and/or identify content. In some implementations, the output data provided by the data parsing engine 210 can be processed by the user through specific intents, actions, and/or routines that can be performed by the automated assistant 204 and/or through the automated assistant 204. Parameter engine 212 may be provided to determine whether input has been provided that corresponds to an application or agent that can be accessed. For example, assistant data 238 may be stored on server device and/or computing device 202 and may include data defining one or more actions that may be performed by automated assistant 204. It can contain parameters necessary to perform an action. Parameter engine 212 may generate one or more parameters for intent, action, and/or slot values and provide one or more parameters to output generation engine 214. Output generation engine 214 communicates with assistant interface 220 to provide output to a user using one or more parameters and/or communicates with one or more applications 234 to provide output to one or more applications 234. can do.
일부 구현에서, 자동화된 어시스턴트(204)는 컴퓨팅 장치(202)의 운영 체제 "탑(on-top)" 설치될 수 있는 애플리케이션일 수 있고/있거나 그 자체가 컴퓨팅 장치(202)의 운영 체제의 일부(또는 전체)를 형성할 수 있다. 자동화된 어시스턴트 애플리케이션은 온-디바이스(on-device) 음성 인식, 온-디바이스 자연어 이해 및 온-디바이스 이행을 포함 및/또는 액세스한다. 예를 들어, 온-디바이스 음성 인식은 컴퓨팅 장치(202)에 로컬로 저장된 E2E(end-to-end) 음성 인식 기계 학습 모델을 사용하여 오디오 데이터(마이크로폰에 의해 검출됨)를 처리하는 온-디바이스 음성 인식 모듈을 사용하여 수행될 수 있다. 온-디바이스 음성 인식은 오디오 데이터에 있는 음성 발화(있는 경우)에 대해 인식된 텍스트를 생성한다. 또한, 예를 들어, 온-디바이스 자연어 이해(NLU)는 NLU 데이터를 생성하기 위해 온-디바이스 음성 인식을 사용하여 생성된 인식된 텍스트 및 선택적으로 컨텍스트 데이터를 처리하는 온-디바이스 NLU 모듈을 사용하여 수행될 수 있다. In some implementations, automated assistant 204 may be an application that can be installed “on-top” the operating system of computing device 202 and/or is itself part of the operating system of computing device 202. (or the whole) can be formed. Automated assistant applications include and/or access on-device speech recognition, on-device natural language understanding, and on-device fulfillment. For example, on-device speech recognition processes audio data (detected by a microphone) using an end-to-end speech recognition machine learning model stored locally on computing device 202. This can be performed using a voice recognition module. On-device speech recognition generates recognized text for speech utterances (if present) in the audio data. Additionally, for example, on-device natural language understanding (NLU) uses an on-device NLU module to process recognized text and optionally context data generated using on-device speech recognition to generate NLU data. It can be done.
NLU 데이터는 음성 발화에 해당하는 의도(intent)(들)와 선택적으로 의도(들)에 대한 파라미터(예: 슬롯 값)를 포함할 수 있다. 온-디바이스 이행은 NLU 데이터(온-디바이스 NLU에서) 및 선택적으로 다른 로컬 데이터를 활용하는 온-디바이스 이행 모듈을 사용하여 수행할 수 있다. 음성 발화의 의도(및 선택적으로 의도에 대한 파라미터)를 해결하기 위해 취할 액션(들)을 결정한다. 이는 음성 발화에 대한 로컬 및/또는 원격 응답(예: 답변), 음성 발화를 기반으로 수행할 로컬에 설치된 애플리케이션과의 상호 작용, 음성 발화를 기반으로 사물 인터넷(IoT) 장치(들)에 (직접 또는 해당 원격 시스템을 통해) 전송하라는 명령, 및/또는 음성 발화를 기반으로 수행할 다른 해결 액션을 결정하는 것을 포함할 수 있다. 그런 다음 온-디바이스 이행은 음성 발화를 해결하기 위해 결정된 액션의 로컬 및/또는 원격 수행/실행을 시작할 수 있다. NLU data may include intent(s) corresponding to the voice utterance and optionally parameters (e.g., slot value) for the intent(s). On-device fulfillment can be performed using an on-device fulfillment module that leverages NLU data (from the on-device NLU) and optionally other local data. Determine the action(s) to be taken to resolve the intent (and optionally the parameters for the intent) of the vocal utterance. This includes local and/or remote responses (e.g., replies) to the spoken utterance, interactions with locally installed applications to perform based on the spoken utterance, and (directly) communicated to the Internet of Things (IoT) device(s) based on the spoken utterance. or via a corresponding remote system), and/or determining other resolution actions to perform based on the vocal utterance. The on-device implementation may then begin local and/or remote performance/execution of the determined action to resolve the speech utterance.
다양한 구현에서, 원격 음성 처리, 원격 NLU 및/또는 원격 이행이 적어도 선택적으로 활용될 수 있다. 예를 들어, 인식된 텍스트는 원격 NLU 및/또는 원격 이행을 위해 원격 자동화된 어시스턴트 컴포넌트(들)에 적어도 선택적으로 전송될 수 있다. 예를 들어, 인식된 텍스트는 온-디바이스 성능(기능)과 병행하여 원격 성능을 위해 선택적으로 전송되거나 온-디바이스 NLU 및/또는 온-디바이스 이행 실패에 응답할 수 있다. 온-디바이스 음성 처리, 온-디바이스 NLU, 온-디바이스 이행 및/또는 온-디바이스 실행은 적어도 음성 발화를 해결할 때 제공하는 대기 시간 감소로 인해 우선 순위를 지정할 수 있다(발화를 해결하는 데 클라이언트-서버 왕복이 필요하지 않기 때문에). 또한 온-디바이스 기능은 네트워크 연결이 없거나 제한된 상황에서 사용할 수 있는 유일한 기능일 수 있다. In various implementations, remote speech processing, remote NLU, and/or remote implementation may at least optionally be utilized. For example, recognized text may at least optionally be transmitted to a remote NLU and/or remote automated assistant component(s) for remote implementation. For example, recognized text may be optionally transmitted for remote performance in parallel with on-device performance (function) or in response to on-device NLU and/or on-device performance failure. On-device speech processing, on-device NLU, on-device fulfillment, and/or on-device execution can be prioritized, at least due to the reduced latency they provide when resolving spoken utterances (client-to-device since it doesn't require a server round trip). Additionally, on-device features may be the only features available in situations where there is no or limited network connectivity.
일부 구현에서, 컴퓨팅 장치(202)는 컴퓨팅 장치(202) 및/또는 자동화된 어시스턴트(204)를 제공한 엔티티와 다른 제3자 엔티티에 의해 제공될 수 있는 하나 이상의 애플리케이션(234)을 포함할 수 있다. 자동화된 어시스턴트(204) 및/또는 컴퓨팅 장치(202)의 애플리케이션 상태 엔진은 하나 이상의 애플리케이션(234)의 각 애플리케이션의 상태 및/또는 컴퓨팅 장치(202)와 연관된 각각의 장치의 상태뿐만 아니라, 하나 이상의 애플리케이션(234)에 의해 수행될 수 있는 하나 이상의 동작을 결정하기 위해 애플리케이션 데이터(230)에 액세스할 수 있다. 자동화된 어시스턴트(204) 및/또는 컴퓨팅 장치(202)의 장치 상태 엔진은 컴퓨팅 장치(202) 및/또는 컴퓨팅 장치(202)와 연관된 하나 이상의 장치에 의해 수행될 수 있는 하나 이상의 동작을 결정하기 위해 장치 데이터(232)에 액세스할 수 있다. 애플리케이션 데이터(230) 및/또는 임의의 다른 데이터(예를 들어, 장치 데이터(232))는 컨텍스트 데이터(236)를 생성하기 위해 자동화된 어시스턴트(204)에 의해 액세스될 수 있으며, 이는 특정 애플리케이션(234) 및/또는 장치가 실행 중인 컨텍스트, 및/또는 특정 사용자가 컴퓨팅 장치(202)에 액세스하고, 애플리케이션(234) 및/또는 임의의 다른 장치 또는 모듈에 액세스하고 있는 컨텍스트를 특성화(characterize)할 수 있다.In some implementations, computing device 202 may include one or more applications 234 that may be provided by a third party entity different from the entity that provided computing device 202 and/or automated assistant 204. there is. The automated assistant 204 and/or the application state engine of the computing device 202 may monitor the state of each application of one or more applications 234 and/or the state of each device associated with the computing device 202 as well as one or more Application data 230 may be accessed to determine one or more operations that may be performed by application 234. Automated assistant 204 and/or the device state engine of computing device 202 may be configured to determine one or more actions that may be performed by computing device 202 and/or one or more devices associated with computing device 202. Device data 232 may be accessed. Application data 230 and/or any other data (e.g., device data 232) may be accessed by automated assistant 204 to generate context data 236, which may be specific to a specific application ( 234) and/or the context in which the device is running, and/or the context in which a particular user is accessing the computing device 202 and accessing the application 234 and/or any other device or module. You can.
하나 이상의 애플리케이션(234)이 컴퓨팅 장치(202)에서 실행되는 동안, 장치 데이터(232)는 컴퓨팅 장치(202)에서 실행되는 각각의 애플리케이션(234)의 현재 동작 상태를 특성화할 수 있다. 또한, 애플리케이션 데이터(230)는 하나 이상의 애플리케이션(234)의 지시에 따라 렌더링되는 하나 이상의 그래픽 사용자 인터페이스의 콘텐츠와 같은 실행 애플리케이션(234)의 하나 이상의 기능을 특성화할 수 있다. 대안적으로 또는 부가적으로, 애플리케이션 데이터(230)는 각각의 애플리케이션의 현재 동작 상태에 기초하여 각각의 애플리케이션 및/또는 자동화된 어시스턴트(204)에 의해 업데이트될 수 있는 액션 스키마(action schema)를 특성화할 수 있다. 대안적으로 또는 부가적으로, 하나 이상의 애플리케이션(234)에 대한 하나 이상의 액션 스키마는 정적으로 유지될 수 있지만, 자동화된 어시스턴트(204)를 통해 초기화하기에 적합한 액션(동작)을 결정하기 위해 애플리케이션 상태 엔진에 의해 액세스될 수 있다. While one or more applications 234 are executing on computing device 202 , device data 232 may characterize the current operating state of each application 234 executing on computing device 202 . Additionally, application data 230 may characterize one or more functions of executing applications 234 , such as the content of one or more graphical user interfaces rendered according to instructions of one or more applications 234 . Alternatively or additionally, application data 230 characterizes an action schema that can be updated by each application and/or automated assistant 204 based on the current operating state of each application. can do. Alternatively or additionally, one or more action schemas for one or more applications 234 may be maintained statically, but may be subject to application state to determine appropriate actions (operations) for initialization via automated assistant 204. Can be accessed by the engine.
컴퓨팅 장치(202)는 애플리케이션 데이터(230), 장치 데이터(232), 컨텍스트 데이터(236), 및/또는 컴퓨팅 장치(202)에 액세스 가능한 임의의 다른 데이터를 처리하기 위해 하나 이상의 훈련된 기계 학습 모델을 사용할 수 있는 어시스턴트 호출 엔진(222)을 더 포함할 수 있다. 어시스턴트 호출 엔진(222)은 자동화된 어시스턴트(204)를 호출하기 위해 사용자가 호출 문구를 명시적으로 말할 때까지 기다릴지 결정하기 위해 또는 사용자가 명시적으로 호출 문구를 말하도록 요구하는 대신에 데이터가 자동화된 어시스턴트를 호출하려는 사용자의 의도를 나타내는 것으로 간주하기 위해 이 데이터를 처리(프로세싱)할 수 있다. 예를 들어, 하나 이상의 훈련된 기계 학습 모델은 사용자가 여러 장치 및/또는 애플리케이션이 다양한 동작 상태를 나타내는 환경에 있는 시나리오에 기반한 훈련 데이터의 인스턴스를 사용하여 훈련될 수 있다. 사용자가 자동화된 어시스턴트를 호출하는 컨텍스트 및 사용자가 자동화된 어시스턴트를 호출하지 않는 다른 컨텍스트를 특징짓는 트레이닝 데이터를 캡처하기 위해 트레이닝 데이터의 인스턴스가 생성될 수 있다. 하나 이상의 훈련된 기계 학습 모델이 이러한 훈련 데이터 인스턴스에 따라 훈련될 때, 어시스턴트 호출 엔진(222)은 자동화된 어시스턴트(204)가 컨텍스트 및/또는 환경의 특징에 기초하여 사용자로부터 음성 호출 문구를 검출하거나 검출을 제한하게 할 수 있다. 부가적으로 또는 대안적으로, 어시스턴트 호출 엔진(222)은 자동화된 어시스턴트(204)가 컨텍스트 및/또는 환경의 특징에 기초하여 사용자로부터의 하나 이상의 어시스턴트 명령을 검출하거나 그 명령에 대한 검출을 제한하게 할 수 있다. Computing device 202 may train one or more machine learning models to process application data 230, device data 232, context data 236, and/or any other data accessible to computing device 202. It may further include an assistant call engine 222 that can use. The assistant invocation engine 222 may request data to determine whether to wait for the user to explicitly say an invocation phrase to invoke the automated assistant 204, or instead of requiring the user to explicitly say an invocation phrase. This data may be processed to indicate the user's intention to invoke an automated assistant. For example, one or more trained machine learning models may be trained using instances of training data based on a scenario in which a user is in an environment where multiple devices and/or applications exhibit various operational states. Instances of training data may be created to capture training data characterizing contexts in which a user invokes an automated assistant and other contexts in which a user does not invoke an automated assistant. When one or more trained machine learning models are trained according to these training data instances, assistant invocation engine 222 may cause automated assistant 204 to detect spoken invocation phrases from the user based on features of the context and/or environment. Detection may be limited. Additionally or alternatively, assistant invocation engine 222 may cause automated assistant 204 to detect or limit detection of one or more assistant commands from the user based on characteristics of the context and/or environment. can do.
일부 구현예에서, 시스템(200)은 사용자가 교통 수단(예를 들어, 차량(비히클(vehicle)))을 통해 이동하고 있는지에 관한 예측을 생성할 수 있는 이동 예측 엔진(216)을 포함할 수 있다. 이동 예측 엔진(216)은 애플리케이션 데이터(230), 장치 데이터(232), 컨텍스트 데이터(236), 및/또는 시스템(200)에 이용 가능한 임의의 다른 데이터에 기초하여 사용자가 이동하고 있는지에 관한 예측을 생성할 수 있다. 일부 구현에서, 이동 예측 엔진(216)은 컴퓨팅 장치(202)가 (예: 블루투스 또는 기타 프로토콜을 통해) 차량 컴퓨팅 장치와 통신하고 있는지, 사용자가 내비게이션 애플리케이션에 액세스하고 있는지, 및/또는 사용자 및/또는 컴퓨팅 장치의 움직임이 차량 이동을 나타내는 여부에 기초하여 예측을 생성할 수 있다. 예측을 특성화하는(characterizing) 테이터는 시스템(200)의 예측 점수 엔진(218)으로 전달될 수 있다. In some implementations, system 200 may include a travel prediction engine 216 that can generate predictions regarding whether the user is traveling via transportation (e.g., a vehicle). there is. Movement prediction engine 216 makes predictions about whether the user is moving based on application data 230, device data 232, context data 236, and/or any other data available to system 200. can be created. In some implementations, movement prediction engine 216 determines whether computing device 202 is communicating with a vehicle computing device (e.g., via Bluetooth or other protocol), whether a user is accessing a navigation application, and/or whether a user and/or Alternatively, a prediction may be generated based on whether the movement of the computing device is indicative of vehicle movement. Data characterizing the prediction may be passed to the prediction scoring engine 218 of system 200.
예측 점수 엔진(218)은 사용자가 차량을 통해 이동하고 있다는 예측에 대한 신뢰도를 나타내는 점수를 생성할 수 있다. 예를 들어, 점수는 컴퓨팅 장치(202)가 차량 컴퓨팅 장치와 통신할 때 그리고 사용자가 내비게이션 애플리케이션에 액세스할 때 더 많은 신뢰도를 나타낼 때이다. 더욱이, 점수는 컴퓨팅 장치가 차량 컴퓨팅 장치와 통신하지 않지만 사용자가 내비게이션 애플리케이션에 액세스하고 있는 경우 상대적으로 낮은 신뢰도를 나타낼 수 있다. 대안적으로 또는 추가적으로, 예측이 사용자의 움직임 및/또는 컴퓨팅 장치(202)의 하나 이상의 센서로부터의 데이터에 기초할 때 점수는 상대적으로 낮은 신뢰도를 나타낼 수 있다. Prediction score engine 218 may generate a score indicating confidence in the prediction that the user is moving by vehicle. For example, a score indicates more confidence when computing device 202 communicates with a vehicle computing device and when a user accesses a navigation application. Moreover, the score may indicate relatively low confidence if the computing device is not communicating with the vehicle computing device but the user is accessing a navigation application. Alternatively or additionally, the score may indicate relatively low confidence when the prediction is based on the user's movements and/or data from one or more sensors of computing device 202.
운전 모드 GUI 엔진(226)은 어시스턴트 운전 모드에서 컴퓨팅 장치(202) 및/또는 자동화된 어시스턴트(204)를 동작할지 여부를 결정하기 위해 예측 점수 엔진(218)으로부터의 점수를 처리(프로세싱)할 수 있다. 대안적으로 또는 추가적으로, 운전 모드 GUI 엔진(226)은 선택 가능한 어시스턴트 GUI 요소가 컴퓨팅 장치(202)의 인터페이스에서 렌더링되도록 할지 여부를 결정하기 위해 점수를 처리할 수 있다. 예를 들어, 어시스턴트 운전 모드를 자동으로 초기화하기 위한 점수 임계값과 점수를 비교할 수 있다. 점수 임계값이 만족되면, 운전 모드 GUI 엔진(226)은 자동화된 어시스턴트(204)가 어시스턴트 운전 모드에 따라 동작하게 하고 또한 선택 가능한 어시스턴트 GUI 요소가 컴퓨팅 장치(202)의 디스플레이 인터페이스에서 렌더링되게 할 수 있다. 점수 임계값이 만족되지 않을 때, 운전 모드 GUI 엔진(226)은 선택 가능한 어시스턴트 GUI 요소가 컴퓨팅 장치(202)의 디스플레이 인터페이스에서 렌더링되게 할 수 있다. 그 후, 운전 모드 GUI 엔진(226)은 자동화된 어시스턴트(204)가 어시스턴트 운전 모드에 따라 동작하게 하기 전에 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택하기를 기다릴 수 있다. Driving mode GUI engine 226 may process scores from predictive scoring engine 218 to determine whether to operate computing device 202 and/or automated assistant 204 in assisted driving mode. there is. Alternatively or additionally, driving mode GUI engine 226 may process the score to determine whether to cause the selectable assistant GUI element to be rendered in the interface of computing device 202. For example, the score can be compared to a score threshold for automatically initializing the assistant driving mode. If the score threshold is met, driving mode GUI engine 226 may cause automated assistant 204 to operate according to the assistant driving mode and also cause selectable assistant GUI elements to be rendered in a display interface of computing device 202. there is. When the score threshold is not met, driving mode GUI engine 226 may cause selectable assistant GUI elements to be rendered in the display interface of computing device 202. Driving mode GUI engine 226 may then wait for the user to select a selectable assistant GUI element before causing automated assistant 204 to operate according to the assistant driving mode.
일부 구현에서, 시스템(200)의 GUI 타이머 엔진(224)은 선택 가능한 어시스턴트 GUI 요소가 렌더링될 기간을 나타내기 위해 컴퓨팅 장치(202)의 디스플레이 인터페이스에서 시간이 렌더링되도록 할 수 있다. 사용자가 기간 내에 선택 가능한 어시스턴트 GUI 요소를 선택하지 않기로 선택한 경우, GUI 타이머 엔진(224)은 사용자가 기간 내에 선택 가능한 어시스턴트 GUI 요소를 선택하지 않았음을 운전 모드 GUI 엔진(226)에 표시할 수 있다. 이에 응답하여, 운전 모드 GUI 엔진(226)은 선택 가능한 어시스턴트 GUI 요소가 디스플레이 인터페이스에서 제거되도록 할 수 있다. 일부 구현에서, 기간은 예측 점수 엔진(218)에 의해 생성된 점수에 기초하여 GUI 타이머 엔진(224)에 의해 선택될 수 있다. 예를 들어, 타이머의 기간(duration)은 더 높은 신뢰도를 나타내는 점수에 대해 더 길 수 있고(예를 들어, 20초), 더 낮은 신뢰도를 나타내는 점수에 대해 더 짧을 수 있다(예를 들어, 5초).In some implementations, the GUI timer engine 224 of system 200 may cause time to be rendered in the display interface of computing device 202 to indicate the period for which selectable assistant GUI elements will be rendered. If the user chooses not to select a selectable assistant GUI element within a period of time, GUI timer engine 224 may indicate to the driving mode GUI engine 226 that the user did not select a selectable assistant GUI element within a period of time. . In response, driving mode GUI engine 226 may cause the selectable assistant GUI element to be removed from the display interface. In some implementations, the period may be selected by GUI timer engine 224 based on the score generated by prediction score engine 218. For example, the duration of the timer may be longer for scores indicating higher confidence (e.g., 20 seconds) and shorter for scores indicating lower confidence (e.g., 5 seconds). candle).
도 3은 어시스턴트 운전 최적화 모드에서 자동화된 어시스턴트를 능동적으로 동작하고, 사용자가 운전 최적화 모드에서 동작하도록 명시적으로 선택할 때 추가적인 운전 최적화 기능을 제공하기 위한 방법(300)을 예시한다. 방법(300)은 하나 이상의 컴퓨팅 장치, 애플리케이션, 및/또는 자동화된 어시스턴트와 연관될 수 있는 임의의 다른 장치 또는 모듈에 의해 수행될 수 있다. 방법(300)은 사용자가 예측된 경로를 따라 이동하는 것으로 예측되는지 여부를 결정하는 동작(302)을 포함할 수 있다. 일부 구현에서, 동작(302)에서의 결정은 하나 이상의 애플리케이션, 센서 및/또는 장치와 같으나 이에 제한되지 않는 하나 이상의 데이터 소스에 기초할 수 있다. 예를 들어, 사용자가 이동 중이라는 결정은 무선 통신 프로토콜을 통해 차량 컴퓨팅 장치에 연결하는 컴퓨팅 장치(예: 휴대폰) 및/또는 특정 목적지로 이동하기 위해 사용자가 내비게이션 애플리케이션을 초기화하는 것에 기초할 수 있다. 일부 구현에서, 동작(302)에서의 결정은 사용자가 차량에 탑승하고 있음을 나타내는 방식으로 사용자가 이동하고 있음을 나타내는 컴퓨팅 장치 및/또는 차량 컴퓨팅 장치의 하나 이상의 센서에 기초할 수 있다. 3 illustrates a method 300 for actively operating an automated assistant in an assistant driving optimization mode and providing additional driving optimization functionality when a user explicitly selects to operate in the driving optimization mode. Method 300 may be performed by one or more computing devices, applications, and/or any other device or module that may be associated with an automated assistant. The method 300 may include an act 302 of determining whether the user is predicted to travel along the predicted path. In some implementations, the decision in operation 302 may be based on one or more data sources, such as, but not limited to, one or more applications, sensors, and/or devices. For example, a determination that a user is moving may be based on a computing device (e.g., a cell phone) connecting to the vehicle computing device via a wireless communication protocol and/or the user initiating a navigation application to navigate to a specific destination. . In some implementations, the determination in operation 302 may be based on one or more sensors on the computing device and/or the vehicle computing device that indicate that the user is moving in a manner that indicates that the user is riding a vehicle.
사용자가 이동하는 것으로 예측되면, 방법(300)은 단계(302)에서 단계(304)로 진행될 수 있다. 그렇지 않으면, 방법(300)을 실행하는 애플리케이션 및/또는 장치는 사용자가 이동하는 것으로 예측되는지 및/또는 비운전 모드에서 자동화된 어시스턴트를 동작하는지를 계속해서 결정할 수 있다. 동작(304)은 사용자가 이동하고 있다는 예측에 대한 신뢰도를 특성화하는(characterize) 예측 점수를 생성하는 것을 포함할 수 있다. 예를 들어, 컴퓨팅 장치가 차량 컴퓨팅 장치와 통신하지 않을 때보다 사용자의 컴퓨팅 장치가 차량 컴퓨팅 장치와 통신할 때 신뢰도 점수가 더 높을 수 있다. 방법(300)은 동작(304)으로부터 예측 점수가 임계값을 만족하는지 여부를 결정하는 동작(306)으로 진행할 수 있다. 예측 점수가 임계값을 만족할 때, 방법(300)은 동작(306)에서 동작(310)으로 진행될 수 있다. 그렇지 않고, 예측 임계값이 만족되지 않는 경우, 방법(300)은 동작(306)에서 동작(308)으로 진행될 수 있다. If the user is predicted to move, method 300 may proceed from step 302 to step 304. Otherwise, the application and/or device executing method 300 may continue to determine whether the user is predicted to be moving and/or operating the automated assistant in a non-driving mode. Operation 304 may include generating a prediction score that characterizes the confidence in the prediction that the user is moving. For example, a trust score may be higher when the user's computing device is communicating with a vehicle computing device than when the computing device is not communicating with the vehicle computing device. Method 300 may proceed from operation 304 to operation 306, which determines whether the prediction score satisfies a threshold. When the prediction score satisfies the threshold, method 300 may proceed from operation 306 to operation 310. Otherwise, if the prediction threshold is not satisfied, method 300 may proceed from operation 306 to operation 308.
동작(308)은 선택 가능한 어시스턴트 GUI 요소가 컴퓨팅 장치(예를 들어, 차량 컴퓨팅 장치와 별개인 휴대용 컴퓨팅 장치)의 디스플레이 인터페이스에서 렌더링되게 하는 것을 포함할 수 있다. 선택 가능한 어시스턴트 GUI 요소는 예를 들어 선택 가능한 어시스턴트 GUI 요소를 선택하면 자동화된 어시스턴트가 운전 최적화 모드(즉, 어시스턴트 운전 모드)에서 동작하게 됨을 표시하는 자동차 그래픽(automobile graphic)을 포함하는 선택 가능한 아이콘일 수 있다. 일부 구현예에서, 선택 가능한 어시스턴트 GUI 요소는 예측 점수가 사용자가 이동하고 있다는 예측에 대한 더 큰 신뢰도를 나타낼 때 더 두드러지게(prominently) 렌더링될 수 있고, 예측 점수가 더 낮은 신뢰도를 나타낼 때 덜 두드러지게 렌더링될 수 있다. 방법(300)은 동작 308로부터 동작 312로 진행될 수 있다. Operation 308 may include causing a selectable assistant GUI element to be rendered in a display interface of a computing device (e.g., a portable computing device separate from a vehicle computing device). The selectable assistant GUI element may be a selectable icon, including, for example, an automobile graphic indicating that selecting the selectable assistant GUI element will cause the automated assistant to operate in a driving optimization mode (i.e., assistant driving mode). You can. In some implementations, selectable assistant GUI elements may be rendered more prominently when the prediction score indicates greater confidence in predicting that the user is moving, and less prominently when the prediction score indicates lower confidence in the prediction that the user is moving. may be rendered poorly. Method 300 may proceed from operation 308 to operation 312.
동작 312는 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택했는지 여부를 결정하는 것을 포함할 수 있다. 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택하지 않은 것으로 결정되면, 방법(300)은 단계(312)에서 단계(318)로 진행될 수 있다. 동작 318은 어시스턴트 운전 모드에 따라 자동화된 어시스턴트를 동작시키는 동작을 포함할 수 있다. 어시스턴트 운전 모드는 자동화된 어시스턴트가 운전 및/또는 안전 증진(promoting safety)에 최적화된 방식으로 특정 출력을 렌더링 및/또는 특정 입력을 처리하는 모드일 수 있다. 예를 들어, 수신 메시지에 대한 알림(통지)은 사용자가 이동하는 것으로 예상되지 않는 경우 알림에 활용되는 다른 글꼴 크기보다 더 큰 텍스트 크기로 디스플레이 인터페이스에서 렌더링될 수 있다. 대안적으로 또는 추가적으로, 수신 메시지에 대한 알림은 사용자가 이동하는 것으로 예측되지 않은 경우 알림에 활용될 다른 영역보다 더 큰 디스플레이 인터페이스 영역의 디스플레이 인터페이스에서 렌더링될 수 있다. Operation 312 may include determining whether the user has selected a selectable assistant GUI element. If it is determined that the user has not selected a selectable assistant GUI element, method 300 may proceed from step 312 to step 318. Operation 318 may include operating the automated assistant according to the assistant driving mode. An assistant driving mode may be a mode in which an automated assistant renders certain outputs and/or processes certain inputs in a manner optimized for driving and/or promoting safety. For example, a notification for an incoming message may be rendered on the display interface with a text size larger than other font sizes utilized in the notification if the user is not expected to move. Alternatively or additionally, notifications for incoming messages may be rendered on the display interface in an area of the display interface that is larger than other areas to be utilized for notifications when the user is not expected to be moving.
일부 구현에서, 자동화된 어시스턴트가 어시스턴트 운전 모드에 따라 동작할 때, 자동화된 어시스턴트에 대한 입력은 적어도 사용자의 지리적 위치를 특성화하는 로컬 데이터를 사용하여 처리될 수 있다. 예를 들어, 자동화된 어시스턴트가 어시스턴트 운전 모드로 동작 중일 때, 사용자가 “Assistant, how much is gas?(어시스턴트, 휘발유 얼마예요?)”와 같은 입력을 하면, 사용자의 위치에 대응되는 데이터를 이용하여 입력을 처리할 수 있다. 예를 들어, 자동화된 어시스턴트는 사용자의 현재 위치와 관련된 데이터를 사용하여 "Gas is $2.35 per gallon at the Station that is 0.25 miles from your location(현재 위치에서 0.25마일 떨어진 스테이션에서 휘발유 가격은 갤런당 2.35달러이다.)"와 같은 응답 출력을 생성할 수 있다. 그러나 자동화된 어시스턴트가 어시스턴트 운전 모드로 동작하지 않을 때 사용자가 이 입력을 제공하면 자동화된 어시스턴트는 "Crude oil is $70 per barrel today.(오늘 원유 가격은 배럴당 70달러이다.)"와 같은 다른 응답 출력을 제공할 수 있다. 이 다른 응답 출력은 로컬 데이터를 포함하거나 우선순위를 지정하지 않을 수 있는 하나 이상의 데이터 소스를 기반으로 할 수 있다. In some implementations, when the automated assistant operates in accordance with the assistant driving mode, input to the automated assistant may be processed using at least local data characterizing the user's geographic location. For example, when the automated assistant is operating in assistant driving mode and the user inputs something like “Assistant, how much is gas?”, data corresponding to the user’s location is used. You can process input by doing this. For example, an automated assistant could use data related to your current location to say "Gas is $2.35 per gallon at the Station that is 0.25 miles from your location." It is possible to generate response output such as "." However, if the user provides this input when the automated assistant is not operating in assistant driving mode, the automated assistant will output a different response, such as "Crude oil is $70 per barrel today." can be provided. These different response outputs may contain local data or be based on one or more data sources that may not be prioritized.
일부 구현예에서, 예측 점수가 어시스턴트 운전 모드의 시작을 우회하기 위한 다른 예측 임계값을 만족하지 않을 때 단계 318을 우회할 수 있다. 이러한 방식으로, 다른 예측 임계값이 만족되지 않는 경우, 자동화된 어시스턴트는 어시스턴트 운전 모드에 따라 동작하기 전에 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택할 때까지 선택적으로 기다릴 수 있다. 방법(300)은 동작(318)으로부터 임계 기간이 발생하기 전에 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택했는지 여부 및/또는 사용자가 선택 가능한 어시스턴트 GUI 요소를 해제했는지(dismissed) 여부를 결정하는 선택적 동작(320)으로 진행할 수 있다. 일부 구현에서, 임계 기간은 사용자가 차량을 타고 이동하고 있다는 예측에 대한 점수에 기초할 수 있다. 점수는 사용자가 차량을 타고 이동 중이거나 차량을 운전하고 있다는 예측에 대한 신뢰도를 나타낼 수 있다. 예를 들어, 임계 기간은 신뢰도 점수가 높을수록 길어지고 신뢰도 점수가 낮을수록 짧아질 수 있다. 이는 사용자가 차량을 타고 이동할 가능성이 더 높을 것으로 예측될 때 선택 가능한 어시스턴트 GUI 요소를 통해 어시스턴트 운전 모드를 활성화하는 데 더 많은 시간을 사용자에게 허용할 수 있다. 사용자가 선택 가능한 어시스턴트 GUI 요소를 선택하지 않고 임계 기간이 경과한 경우, 방법(300)은 선택적으로 동작 320에서 동작 310으로 진행하거나, 선택적으로 동작 320에서 동작 316으로 진행할 수 있다. 그렇지 않고, 사용자가 동작 312에서 선택 가능한 어시스턴트 GUI 요소를 선택하면, 방법(300)은 동작 310으로 진행할 수 있다. In some implementations, step 318 may be bypassed when the prediction score does not meet another prediction threshold to bypass initiation of the assistant driving mode. In this way, if other prediction thresholds are not met, the automated assistant can optionally wait for the user to select a selectable assistant GUI element before acting according to the assistant driving mode. Method 300 includes an optional operation (i.e., determining whether a user has selected a selectable assistant GUI element and/or whether a user has dismissed a selectable assistant GUI element before a threshold period occurs from operation 318). 320). In some implementations, the threshold period may be based on a score for predicting that the user is traveling in a vehicle. The score may indicate confidence in the prediction that the user is traveling in a vehicle or driving a vehicle. For example, the critical period can be longer for higher confidence scores and shorter for lower confidence scores. This may allow the user more time to activate the assistant driving mode through a selectable assistant GUI element when the user is predicted to be more likely to travel in the vehicle. If a threshold period of time elapses without the user selecting a selectable assistant GUI element, method 300 may optionally proceed from operation 320 to operation 310, or alternatively from operation 320 to operation 316. Otherwise, if the user selects a selectable assistant GUI element in operation 312, method 300 may proceed to operation 310.
동작(310)은 사용자가 이동 중이라는 예측에 대한 점수에 기초하여 어시스턴트 운전 모드 GUI가 디스플레이 인터페이스에서 렌더링되게 하는 것을 포함할 수 있다. 예를 들어, 점수가 임계 점수를 만족할 때, 어시스턴트 운전 모드 GUI는 내비게이션 인터페이스를 포함하는 제1 부분과 하나 이상의 선택 가능한 제안을 포함하는 제2 부분으로 렌더링될 수 있다. 대안적으로 또는 추가적으로, 점수가 임계 점수를 만족하지 않을 때, 어시스턴트 운전 모드 GUI는 내비게이션 인터페이스 또는 하나 이상의 선택 가능한 제안을 사용하여 초기에 렌더링될 수 있다. 일부 예에서, 컴퓨팅 장치의 안테나 또는 센서가 무선 통신 프로토콜을 통해 차량 컴퓨팅 장치와 통신할 때 점수는 임계 점수를 만족할 수 있다. 대안적으로 또는 추가적으로, 컴퓨팅 장치가 차량 컴퓨팅 장치와 통신하고 있고 사용자가 컴퓨팅 장치 및/또는 차량 컴퓨팅 장치를 통해 내비게이션 애플리케이션에 액세스하고 있을 때 점수는 임계 점수를 만족할 수 있다. 일부 경우에, 컴퓨팅 장치가 차량 컴퓨팅 장치와 통신하지 않지만 사용자가 컴퓨팅 장치를 통해 내비게이션 애플리케이션에 액세스하고 있는 경우 점수는 임계 점수를 만족하지 못할 수 있다. Operation 310 may include causing an assistant driving mode GUI to be rendered in the display interface based on the score for predicting that the user is moving. For example, when the score satisfies a threshold score, the assistant driving mode GUI may be rendered with a first portion comprising a navigation interface and a second portion comprising one or more selectable offers. Alternatively or additionally, when the score does not meet the threshold score, the assistant driving mode GUI may be initially rendered using a navigation interface or one or more selectable suggestions. In some examples, the score may meet a threshold score when the computing device's antenna or sensor communicates with the vehicle computing device via a wireless communication protocol. Alternatively or additionally, the score may satisfy a threshold score when the computing device is in communication with the vehicle computing device and the user is accessing the navigation application through the computing device and/or the vehicle computing device. In some cases, the score may not meet the threshold score if the computing device is not in communication with the vehicle computing device, but the user is accessing the navigation application through the computing device.
일부 구현들에서, 방법(300)은 동작(310)로부터 동작(314)으로 진행될 수 있으며, 이는 자동화된 어시스턴트가 어시스턴트 운전 모드에 따라 동작하게 하는 단계를 포함할 수 있다. 자동화된 어시스턴트의 특성 및/또는 컴퓨팅 장치에 의해 렌더링되는 콘텐츠는 사용자가 차량을 타고 이동하고 있다는 예측에 대한 점수에 따라 조정될 수 있다. 방법(300)은 동작(314)으로부터 선택 가능한 어시스턴트 GUI 요소가 디스플레이 인터페이스로부터 제거되게 하는 것을 포함할 수 있는 선택적 동작(316)으로 진행할 수 있다. 그 후, 방법(300)은 사용자가 차량을 타고 이동하는 것으로 예측되는지 여부를 결정하기 위해 동작(314) 또는 동작(316)으로부터 동작(302)으로 진행할 수 있다. 사용자가 더 이상 차량(비히클)(예: 자동차, 트럭, 비행기, 자전거, 오토바이, 보트 및/또는 기타 교통 수단)을 타고 이동하지 않을 것으로 예상되면 자동화된 어시스턴트는 어시스턴트 운전 모드에 따라 동작을 중단할 수 있다. 대안적으로, 방법(300)은 사용자가 어시스턴트 운전 모드 GUI를 해제하거나 스와이프할 때 동작 314 또는 동작 316에서 동작 308로 진행될 수 있다. 이러한 방식으로, 어시스턴트 운전 모드 GUI를 해제하고 선택 가능한 어시스턴트 GUI 요소가 다시 렌더링되도록 함으로써 사용자는 이동 중에 어시스턴트 운전 모드 GUI에 다시 액세스할 수 있는 "shortcut(바로가기)"를 갖게 된다. In some implementations, method 300 may proceed from operation 310 to operation 314, which may include causing the automated assistant to operate in accordance with an assistant driving mode. The characteristics of the automated assistant and/or content rendered by the computing device may be adjusted depending on the score for predicting that the user is traveling in a vehicle. Method 300 may proceed from operation 314 to optional operation 316, which may include causing the selectable assistant GUI element to be removed from the display interface. Method 300 may then proceed from operation 314 or 316 to operation 302 to determine whether the user is predicted to be traveling in a vehicle. When the user is no longer expected to be traveling in a vehicle (e.g., car, truck, airplane, bicycle, motorcycle, boat, and/or other mode of transportation), the automated assistant may suspend actions according to the assistant driving mode. You can. Alternatively, method 300 may proceed from operation 314 or 316 to operation 308 when the user dismisses or swipes the assistant driving mode GUI. In this way, by turning off the Assistant Driving Mode GUI and causing selectable Assistant GUI elements to be re-rendered, the user has a "shortcut" to re-access the Assistant Driving Mode GUI while on the go.
도 4은 예시적인 컴퓨팅 시스템(410)의 블록도이다. 컴퓨팅 시스템(410)은 전형적으로 버스 서브시스템(412)을 통해 복수의 주변 장치와 통신하는 적어도 하나의 프로세서(414)를 포함한다. 이러한 주변 장치는, 예를 들어, 메모리 서브시스템(425) 및 파일 저장(스토리지) 서브시스템(426), 사용자 인터페이스 출력 장치(420), 사용자 인터페이스 입력 장치(422) 및 네트워크 인터페이스 서브시스템(네트워크 인터페이스)(416)을 포함하는 저장(스토리지) 서브시스템(424)을 포함할 수 있다. 입력 및 출력 장치는 컴퓨팅 시스템(410)과의 사용자 상호작용을 허용한다. 네트워크 인터페이스 서브시스템(416)은 외부 네트워크에 인터페이스를 제공하고 다른 컴퓨팅 장치에서 대응하는 인터페이스 장치에 연결된다. Figure 4 is a block diagram of an example computing system 410. Computing system 410 typically includes at least one processor 414 that communicates with a plurality of peripheral devices via a bus subsystem 412. These peripheral devices include, for example, memory subsystem 425 and file storage (storage) subsystem 426, user interface output device 420, user interface input device 422, and network interface subsystem (network interface ) may include a storage (storage) subsystem 424 including 416. Input and output devices allow user interaction with computing system 410. Network interface subsystem 416 provides an interface to an external network and connects to corresponding interface devices on other computing devices.
사용자 인터페이스 입력 장치(422)는 키보드, 마우스, 트랙볼, 터치 패드 또는 그래픽 태블릿과 같은 포인팅 장치, 스캐너, 디스플레이에 통합된 터치스크린, 음성 인식 시스템과 같은 오디오 입력 장치, 마이크로폰 및/또는 다른 유형의 입력 장치를 포함할 수 있다. 일반적으로, "입력 장치"라는 용어의 사용은 모든 가능한 유형의 장치 및 정보를 컴퓨팅 시스템(410) 또는 통신 네트워크에 입력하는 방법을 포함하도록 의도된다. User interface input device 422 may include a pointing device such as a keyboard, mouse, trackball, touchpad, or graphics tablet, a scanner, a touchscreen integrated into a display, an audio input device such as a voice recognition system, a microphone, and/or other types of input. May include devices. In general, use of the term “input device” is intended to include all possible types of devices and methods of inputting information into computing system 410 or a communications network.
사용자 인터페이스 출력 장치(420)는 디스플레이 서브시스템, 프린터, 팩스기, 또는 오디오 출력 장치와 같은 비 시각적 디스플레이를 포함할 수 있다. 디스플레이 서브시스템은 음극선 관(CRT), 액정 디스플레이(LCD)와 같은 평판 장치, 투영 장치, 또는 가시 이미지를 생성하기 위한 다른 메커니즘을 포함할 수 있다. 디스플레이 서브시스템은 또한 오디오 출력 장치를 통한 것과 같은 비 시각적 디스플레이를 제공할 수 있다. 일반적으로, "출력 장치"라는 용어의 사용은 모든 가능한 유형의 장치 및 컴퓨팅 시스템(410)로부터 사용자 또는 다른 기계 또는 컴퓨팅 장치로 정보를 출력하는 방법을 포함하도록 의도된다.User interface output device 420 may include a non-visual display, such as a display subsystem, printer, fax machine, or audio output device. The display subsystem may include a flat panel device such as a cathode ray tube (CRT), liquid crystal display (LCD), a projection device, or other mechanism for producing a visible image. The display subsystem may also provide non-visual display, such as through an audio output device. Generally, the use of the term “output device” is intended to include all possible types of devices and methods of outputting information from computing system 410 to a user or other machine or computing device.
저장(스토리지) 서브시스템(424)은 본 명세서에 설명된 일부 또는 모든 모듈의 기능을 제공하는 프로그래밍 및 데이터 구성을 저장한다. 예를 들어, 저장 서브시스템(424)은 방법(300)의 선택된 양태를 수행하고/하거나 시스템(200), 컴퓨팅 장치(104) 및/또는 임의의 다른 애플리케이션, 디바이스, 장치 및/또는 여기에 설명된 모듈 중 하나 이상을 구현하는 로직을 포함할 수 있다. Storage subsystem 424 stores programming and data configurations that provide the functionality of some or all modules described herein. For example, storage subsystem 424 may perform selected aspects of method 300 and/or use system 200, computing device 104, and/or any other application, device, apparatus, and/or described herein. It may contain logic that implements one or more of the modules provided.
이들 소프트웨어 모듈은 일반적으로 프로세서(414)에 의해 단독으로 또는 다른 프로세서와의 조합으로 실행된다. 저장 서브시스템(424)에 사용되는 메모리(메모리 서브시스템)(425)는 프로그램 실행 동안 명령 및 데이터의 저장을 위한 메인 랜덤 액세스 메모리(RAM)(430) 및 고정 명령이 저장된 판독 전용 메모리(ROM)(432)를 포함하는 복수의 메모리를 포함할 수 있다. 파일 저장 서브시스템(426)은 프로그램 및 데이터 파일을 위한 영구 저장을 제공할 수 있으며, 하드 디스크 드라이브, 플로피 디스크 드라이브 및 관련 이동식 매체, CD-ROM 드라이브, 광학 드라이브 또는 이동식 매체 카트리지를 포함할 수 있다. 특정 구현의 기능을 구현하는 모듈은 파일 저장 서브시스템(426)에 의해 저장 서브시스템(424) 또는 프로세서(들)(414)에 의해 액세스 가능한 다른 머신에 저장될 수 있다. These software modules are generally executed by processor 414, either alone or in combination with other processors. The memory (memory subsystem) 425 used in the storage subsystem 424 includes a main random access memory (RAM) 430 for storage of instructions and data during program execution and a read-only memory (ROM) where fixed instructions are stored. It may include a plurality of memories including (432). File storage subsystem 426 may provide permanent storage for program and data files and may include hard disk drives, floppy disk drives and associated removable media, CD-ROM drives, optical drives, or removable media cartridges. . Modules implementing the functionality of a particular implementation may be stored by file storage subsystem 426 in storage subsystem 424 or on another machine accessible by processor(s) 414.
버스 서브시스템(412)은 컴퓨팅 시스템(410)의 다양한 컴포넌트 및 서브시스템이 의도된대로 서로 통신하도록 하는 메커니즘을 제공한다. 버스 서브시스템(412)이 단일 버스로서 개략적으로 도시되어 있지만, 버스 서브시스템의 대안적인 구현은 다중 버스를 사용할 수 있다. Bus subsystem 412 provides a mechanism to allow the various components and subsystems of computing system 410 to communicate with each other as intended. Although bus subsystem 412 is schematically depicted as a single bus, alternative implementations of the bus subsystem may use multiple buses.
컴퓨팅 시스템(410)는 워크스테이션, 서버, 컴퓨팅 클러스터, 블레이드 서버, 서버 팜, 또는 임의의 다른 데이터 처리 시스템 또는 컴퓨팅 장치를 포함하는 다양한 유형일 수 있다. 컴퓨터 및 네트워크의 끊임없이 변화하는 특성으로 인해, 도 4에 도시된 컴퓨팅 시스템(410)의 설명은 일부 구현 예를 설명하기 위한 특정 예로서 만 의도된다. 컴퓨팅 시스템(410)의 많은 다른 구성은 도 4에 도시된 컴퓨팅 장치보다 더 많거나 적은 컴포넌트를 가질 수 있다. Computing system 410 may be of various types, including workstations, servers, computing clusters, blade servers, server farms, or any other data processing system or computing device. Due to the ever-changing nature of computers and networks, the description of computing system 410 shown in Figure 4 is intended only as a specific example to illustrate some implementations. Many other configurations of computing system 410 may have more or fewer components than the computing device shown in FIG. 4 .
여기에 설명된 시스템이 사용자(또는 본 문서에서 종종 "참가자"라고 함)에 대한 개인 정보를 수집하거나 개인 정보를 사용할 수 있는 상황에서, 사용자는 프로그램 또는 기능이 사용자 정보(예: 사용자의 소셜 네트워크, 소셜 활동 또는 활동, 직업, 사용자의 선호도 또는 사용자의 현재 지리적 위치에 대한 정보)를 수집하는지 여부를 제어하거나 사용자와 더 관련이 있을 수 있는 콘텐츠 서버로부터 콘텐츠를 수신할지 여부 및/또는 수신 방법을 제어할 기회가 제공될 수 있다. 또한 특정 데이터는 저장 또는 사용되기 전에 하나 이상의 방식으로 프로세싱되어 개인 식별 정보가 제거될 수 있다. 예를 들어, 사용자의 신원이 프로세싱되어 사용자에 대한 개인 식별 정보가 결정될 수 없거나 지리적 위치 정보를 얻은 사용자의 지리적 위치가 일반화(예: 도시, 우편번호 또는 주 수준)되어 사용자의 특정 지리적 위치를 결정할 수 없게 될 수 있다. 따라서 사용자는 사용자에 대한 정보 수집 및/또는 사용 방법을 제어할 수 있다.In situations where the systems described herein may collect or use personal information about Users (or sometimes referred to herein as “Participants”), Users acknowledge that the Program or feature may collect or use Personal Information about Users (e.g., Users’ social networks). control whether and/or how you receive content from content servers that may be more relevant to you; Opportunities for control may be provided. Additionally, certain data may be processed in one or more ways to remove personally identifiable information before it is stored or used. For example, a user's identity may be processed so that no personally identifiable information about the user can be determined, or the user's geographic location from which geolocation information is obtained may be generalized (e.g., to the city, zip code, or state level) to determine the user's specific geographic location. It may become impossible. Accordingly, you can control how information about you is collected and/or used.
여러 구현이 여기에 설명되고 예시되었지만, 기능을 수행하고 및/또는 여기에 설명된 결과 및/또는 하나 이상의 이점을 얻기 위한 다양한 다른 수단 및/또는 구조가 활용될 수 있으며, 각각의 이러한 변형 및/또는 수정은 여기에 설명된 구현의 범위 내에 있는 것으로 간주된다. 보다 일반적으로, 본 명세서에 설명된 모든 파라미터, 치수, 재료 및 구성은 예시적인 것이며 실제 파라미터, 치수, 재료 및/또는 구성은 교시가 사용되는 특정 응용 또는 응용에 의존할 것이라는 것을 의미한다. 당업자는 단지 일상적인 실험을 사용하여 본 명세서에 설명된 특정 구현에 대한 많은 등가물을 인식하거나 확인할 수 있을 것이다. 따라서, 전술한 구현은 단지 예로서 제시된 것이며, 첨부된 청구 범위 및 그 균등물의 범위 내에서 구현이 구체적으로 설명되고 청구된 것과 달리 실행될 수 있다는 것을 이해해야 한다. 본 개시 내용의 구현은 본원에 기재된 각각의 개별적인 특징, 시스템, 물품, 재료, 키트 및/또는 방법에 관한 것이다. 둘 이상의 이러한 특징, 시스템, 물품, 재료, 키트 및/또는 방법의 임의의 조합(이러한 특징, 시스템, 물품, 재료, 키트 및/또는 방법이 서로 매칭하지 않는 경우)은 본 개시의 범위 내에 포함된다.Although several implementations are described and illustrated herein, various other means and/or structures may be utilized to perform the functions and/or achieve one or more of the results and/or advantages described herein, and variations of each of these and/or structures may be utilized. or modifications are deemed to be within the scope of the implementation described herein. More generally, all parameters, dimensions, materials and constructions described herein are meant to be exemplary and that the actual parameters, dimensions, materials and/or constructions will depend on the particular application or applications for which the teachings are used. Those skilled in the art will recognize, or be able to ascertain using no more than routine experimentation, many equivalents to the specific implementations described herein. Accordingly, it is to be understood that the foregoing implementations are presented by way of example only, and that within the scope of the appended claims and their equivalents, implementations may be practiced otherwise than as specifically described and claimed. Implementations of the present disclosure relate to each individual feature, system, article, material, kit, and/or method described herein. Any combination of two or more such features, systems, articles, materials, kits and/or methods (provided that such features, systems, articles, materials, kits and/or methods do not match each other) is included within the scope of this disclosure. .
일부 구현에서, 하나 이상의 프로세서에 의해 구현되는 방법은 컴퓨팅 장치에서 컴퓨팅 장치의 사용자가 비히클(vehicle)을 타고 이동하고 있다는 예측을 결정하는 것과 같은 동작을 포함하는 것으로 설명된다. 여기서 컴퓨팅 장치는 자동화된 어시스턴트에 대한 액세스를 제공하고 비히클의 비히클(차량) 컴퓨팅 장치와는 별개이다. 일부 구현예에서, 방법은 사용자가 비히클을 타고 이동하고 있다는 예측이 상기 컴퓨팅 장치 또는 상기 비히클 컴퓨팅 장치를 통한 내비게이션 인터페이스의 사용자 개시 액세스에 기초할 때 -상기 컴퓨팅 장치는 상기 비히클 컴퓨팅 장치와 통신함-: 어시스턴트 운전 모드 그래픽 사용자 인터페이스(GUI)가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 자동으로 렌더링되도록 하는 단계 -상기 어시스턴트 운전 모드 GUI는 상기 내비게이션 인터페이스 및 상기 사용자가 상기 비히클을 타고 이동하는 동안 상기 사용자에 의해 액세스될 것으로 예측되는 콘텐츠를 포함함-를 포함한다. 일부 구현예에서, 방법은 상기 사용자가 비히클을 타고 이동하고 있다는 예측이 상기 내비게이션 인터페이스가 상기 컴퓨팅 장치를 통해 액세스되지 않는 동안 상기 컴퓨팅 장치가 상기 비히클 컴퓨팅 장치와 통신하는 것에 기초할 때: 선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되도록 하는 단계를 포함하며, 상기 선택 가능한 어시스턴트 GUI 요소의 선택은 상기 내비게이션 인터페이스가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되게 한다. In some implementations, methods implemented by one or more processors are described to include operations at a computing device, such as determining a prediction that a user of the computing device is traveling in a vehicle. Here, the computing device provides access to the automated assistant and is separate from the vehicle's vehicle computing device. In some implementations, the method includes when the prediction that the user is traveling in a vehicle is based on user-initiated access to the computing device or a navigation interface through the vehicle computing device, wherein the computing device is in communication with the vehicle computing device. : causing an assistant driving mode graphical user interface (GUI) to be automatically rendered in a display interface of the computing device, wherein the assistant driving mode GUI is in the navigation interface and accessed by the user while the user is traveling in the vehicle. Contains content predicted to be - Includes. In some implementations, the method includes when the prediction that the user is traveling in a vehicle is based on the computing device communicating with the vehicle computing device while the navigation interface is not accessed through the computing device: a selectable assistant and causing a GUI element to be rendered in a display interface of the computing device, wherein selection of the selectable assistant GUI element causes the navigation interface to be rendered in a display interface of the computing device.
일부 구현예에서, 방법은 상기 컴퓨팅 장치가 상기 비히클 컴퓨팅 장치와 통신하지 않는 동안 상기 사용자가 상기 비히클을 타고 이동하고 있음을 나타내는 상기 컴퓨팅 장치의 하나 이상의 센서에 기초하여 상기 사용자가 상기 비히클을 타고 이동하는 것으로 예측될 때: 상기 자동화된 어시스턴트가 상기 자동화된 어시스턴트에 대한 특정 사용자 입력이 상기 사용자의 지리적 위치 또는 상기 비히클의 예측된 경로를 특성화하는 로컬 데이터를 사용하여 처리되는 어시스턴트 운전 모드에서 동작하게 하는 단계를 더 포함한다. 일부 구현에서, 상기 선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되게 하는 단계는, 카운트다운 타이머가 상기 컴퓨팅 장치를 통해 렌더링 및 초기화되도록 하는 단계를 포함하며, 상기 선택 가능한 어시스턴트 GUI 요소는 상기 카운트다운 타이머가 만료되기 전에 상기 사용자가 상기 선택 가능한 어시스턴트 GUI 요소를 선택하지 않은 것에 응답하여 상기 디스플레이 인터페이스에서 제거된다. 일부 구현에서, 상기 선택 가능한 어시스턴트 GUI 요소가 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되게 하는 단계는, 카운트다운 타이머가 상기 컴퓨팅 장치를 통해 렌더링 및 초기화되도록 하는 단계를 포함하며, 상기 카운트다운 타이머가 만료되기 전에 상기 사용자가 상기 선택 가능한 어시스턴트 GUI 요소를 선택하지 않을 때, 상기 자동화된 어시스턴트는 상기 자동화된 어시스턴트에 대한 특정 사용자 입력이 상기 사용자의 지리적 위치 또는 상기 비히클의 예측된 경로를 특성화하는 로컬 데이터를 사용하여 처리되는 어시스턴트 운전 모드에 따라 동작한다. 일부 구현예에서, 상기 어시스턴트 운전 모드 GUI의 콘텐츠는 메시징 애플리케이션에 대응하는 제1 선택 가능한 요소와 미디어 스트리밍 애플리케이션에 대응하는 제2 선택 가능한 요소를 포함한다. In some implementations, the method further comprises determining that the user is moving in the vehicle while the computing device is not in communication with the vehicle computing device based on one or more sensors in the computing device that indicate that the user is moving in the vehicle. When predicted to: cause the automated assistant to operate in an assisted driving mode in which certain user inputs to the automated assistant are processed using local data characterizing the user's geographic location or the predicted path of the vehicle. Includes more steps. In some implementations, causing the selectable assistant GUI element to be rendered in a display interface of the computing device includes causing a countdown timer to be rendered and initialized via the computing device, wherein the selectable assistant GUI element is: In response to the user not selecting the selectable assistant GUI element before the countdown timer expires, it is removed from the display interface. In some implementations, causing the selectable assistant GUI element to be rendered in a display interface of a computing device includes causing a countdown timer to be rendered and initialized via the computing device, before the countdown timer expires. When the user does not select the selectable assistant GUI element, the automated assistant determines that specific user input to the automated assistant may use local data characterizing the user's geographic location or the predicted path of the vehicle. It operates depending on the assistant driving mode being processed. In some implementations, the content of the assistant driving mode GUI includes a first selectable element corresponding to a messaging application and a second selectable element corresponding to a media streaming application.
다른 구현에서, 하나 이상의 프로세서에 의해 구현되는 방법은 사용자가 비히클(vehicle)을 타고 이동하고 있다는 예측에 대한 점수를 컴퓨팅 장치에서 결정하는 것과 같은 동작을 포함하는 것으로 설명된다. 여기서 컴퓨팅 장치는 자동화된 어시스턴트에 대한 액세스를 제공하고 그리고 상기 비히클의 비히클 컴퓨팅 장치와는 별개이다. 일부 구현에서, 방법은 예측에 대한 점수가 점수 임계값을 만족할 때: 어시스턴트 운전 모드 그래픽 사용자 인터페이스(GUI)가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 자동으로 렌더링되도록 하는 단계 -상기 어시스턴트 운전 모드 GUI는 내비게이션 인터페이스 및 상기 사용자가 비히클을 타고 이동하는 동안 상기 사용자에 의해 액세스될 것으로 예측되는 콘텐츠를 포함함- 를 포함한다. 일부 구현에서, 방법은 상기 예측에 대한 점수가 상기 점수 임계값을 만족하지 않을 때: 선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되도록 하는 단계를 포함하며, 상기 선택 가능한 어시스턴트 GUI 요소의 선택은 상기 내비게이션 인터페이스가 상기 디스플레이 인터페이스에서 렌더링되는 어시스턴트 운전 모드에 따라 상기 자동화된 어시스턴트가 동작하게 한다. In another implementation, a method implemented by one or more processors is described as including operations such as determining, at the computing device, a score for a prediction that the user is traveling in a vehicle. where the computing device provides access to an automated assistant and is separate from the vehicle computing device of the vehicle. In some implementations, the method includes when a score for a prediction satisfies a score threshold: causing an assistant driving mode graphical user interface (GUI) to be automatically rendered in a display interface of the computing device, wherein the assistant driving mode GUI is a navigation interface. and containing content expected to be accessed by the user while the user is traveling in the vehicle. In some implementations, the method includes when the score for the prediction does not meet the score threshold: causing a selectable assistant GUI element to be rendered in a display interface of the computing device, wherein the selectable assistant GUI element's The selection causes the automated assistant to operate according to the assistant driving mode in which the navigation interface is rendered in the display interface.
일부 구현에서, 상기 선택 가능한 어시스턴트 GUI 요소가 상기 디스플레이 인터페이스에서 렌더링되게 하는 단계는 상기 선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되는 홈 화면 또는 잠금 화면 위에 렌더링되도록 하는 단계를 포함한다. 일부 구현에서, 상기 사용자가 비히클을 타고 이동하고 있다는 예측에 대한 점수를 결정하는 단계는 상기 컴퓨팅 장치의 하나 이상의 센서를 사용하여 생성된 데이터 또는 상기 사용자와 연관된 다른 컴퓨팅 장치에서 이용 가능한 다른 데이터에 기초하여 상기 예측에 대한 점수를 생성하는 단계를 포함한다. 일부 구현에서, 상기 어시스턴트 운전 모드 GUI가 디스플레이 인터페이스에서 렌더링될 때, 상기 내비게이션 인터페이스는 상기 내비게이션 인터페이스가 렌더링되고 그리고 상기 점수가 상기 점수 임계값을 만족하지 않을 때에 비해 상기 점수가 상기 점수 임계값을 만족할 때 상기 디스플레이 인터페이스의 더 큰 영역에서 렌더링된다. In some implementations, causing the selectable assistant GUI element to be rendered in the display interface includes causing the selectable assistant GUI element to be rendered over a home screen or lock screen that is rendered in the display interface of the computing device. In some implementations, determining a score for a prediction that the user is traveling in a vehicle is based on data generated using one or more sensors on the computing device or other data available on another computing device associated with the user. This includes generating a score for the prediction. In some implementations, when the assistant driving mode GUI is rendered in a display interface, the navigation interface is configured to determine whether the score satisfies the score threshold compared to when the navigation interface is rendered and the score does not meet the score threshold. When the display interface is rendered in a larger area.
일부 구현에서, 상기 어시스턴트 운전 모드 GUI가 상기 디스플레이 인터페이스에서 렌더링될 때, 상기 어시스턴트 운전 모드 GUI의 텍스트 콘텐츠는 상기 텍스트 콘텐츠가 렌더링되고 그리고 상기 점수가 상기 점수 임계값을 만족하지 못할 때에 비해 상기 점수가 상기 점수 임계값을 만족할 때 더 크게(larger) 렌더링된다. 일부 구현에서, 방법은 상기 예측에 대한 점수가 점수 임계값을 만족하지 않을 때, 선택 가능한 어시스턴트 GUI 요소가 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되게 하는 단계는 상기 선택 가능한 어시스턴트 GUI 요소가 임계 기간 후에 상기 디스플레이 인터페이스에서 제거될 것이라는 표시를 상기 컴퓨팅 장치의 디스플레이 인터페이스 또는 다른 인터페이스가 렌더링하도록 하는 단계를 포함하며, 상기 임계 기간은 상기 사용자가 비히클을 타고 이동하고 있다는 예측에 대한 점수에 기초한다. 일부 구현에서, 상기 예측에 대한 점수는 상기 컴퓨팅 장치의 네트워크 안테나가 상기 컴퓨팅 장치와 상기 비히클 컴퓨팅 장치 사이의 무선 통신을 용이하게 하는지 여부에 기초한다.In some implementations, when the assistant driving mode GUI is rendered in the display interface, the textual content of the assistant driving mode GUI is adjusted to determine the score compared to when the textual content is rendered and the score does not meet the score threshold. When the score threshold is met, it is rendered larger. In some implementations, the method includes, when the score for the prediction does not satisfy a score threshold, causing a selectable assistant GUI element to be rendered in a display interface of a computing device, wherein the selectable assistant GUI element is displayed in the display interface after a threshold period of time. causing a display interface or other interface of the computing device to render an indication that the interface will be removed, wherein the threshold period is based on a score for predicting that the user is traveling in a vehicle. In some implementations, the score for the prediction is based on whether a network antenna of the computing device facilitates wireless communication between the computing device and the vehicle computing device.
또 다른 구현에서, 하나 이상의 프로세서에 의해 구현되는 방법은 컴퓨팅 장치에서, 상기 컴퓨팅 장치의 하나 이상의 센서를 사용하여 생성된 데이터에 기초하여 사용자가 비히클(vehicle)을 타고 이동하고 있다는 예측을 결정하는 단계를 포함하며, 상기 컴퓨팅 장치는 자동화된 어시스턴트에 대한 액세스를 제공하고 그리고 상기 비히클의 비히클 컴퓨팅 장치와는 별개이다. 방법은 상기 사용자가 상기 비히클을 타고 이동하는 것으로 예측된다는 결정에 기초하여, 선택 가능한 어시스턴트 그래픽 사용자 인터페이스(GUI) 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되도록 하는 단계를 더 포함할 수 있다. 방법은 상기 자동화된 어시스턴트에 대한 운전 모드를 활성화하기 위해 상기 선택 가능한 어시스턴트 GUI 요소의 선택이 수신될 때: 상기 선택 가능한 어시스턴트 GUI 요소의 선택을 수신하는 것에 응답하여, 어시스턴트 운전 모드 GUI가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되도록 하는 단계를 더 포함하며, 상기 어시스턴트 운전 모드 GUI에서 렌더링되는 하나 이상의 선택 가능한 GUI 요소의 특성은 상기 사용자가 비히클을 타고 이동하고 있다는 예측에 대한 점수에 기초하여 선택된다. In another implementation, a method implemented by one or more processors includes, at a computing device, determining a prediction that a user is traveling in a vehicle based on data generated using one or more sensors of the computing device. wherein the computing device provides access to an automated assistant and is separate from a vehicle computing device of the vehicle. The method may further include causing selectable assistant graphical user interface (GUI) elements to be rendered in a display interface of the computing device based on the determination that the user is predicted to be traveling in the vehicle. The method may further include, when a selection of the selectable assistant GUI element is received to activate a driving mode for the automated assistant: In response to receiving the selection of the selectable assistant GUI element, an assistant driving mode GUI is displayed on the computing device. causing the user to be rendered in a display interface, wherein characteristics of one or more selectable GUI elements rendered in the assistant driving mode GUI are selected based on a score for predicting that the user is traveling in a vehicle.
일부 구현에서, 상기 선택 가능한 어시스턴트 GUI 요소가 상기 디스플레이 인터페이스에서 렌더링되게 하는 단계는 상기 선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되는 홈 화면 또는 잠금 화면 위에 렌더링되도록 하는 단계를 포함한다. 일부 구현에서, 상기 사용자가 비히클을 타고 이동하고 있다는 예측을 결정하는 단계는 상기 사용자가 내비게이션 애플리케이션에 액세스하고 있는지 여부와 상기 컴퓨팅 장치가 상기 비히클 컴퓨팅 장치와 통신하고 있는지 여부에 기초하여 상기 예측에 대한 점수를 생성하는 단계를 포함한다. 일부 구현에서, 어시스턴트 운전 모드 GUI가 디스플레이 인터페이스에서 렌더링되게 하는 단계는 상기 어시스턴트 운전 모드 GUI가 차지할 디스플레이 인터페이스의 영역을 선택하기 위한 점수 임계값을 상기 점수가 만족하는지 여부를 결정하는 단계를 포함하며, 상기 점수가 상기 점수 임계값을 만족하지 않을 때에 비해 상기 점수가 점수 임계값을 만족할 때 상기 영역이 더 크다. In some implementations, causing the selectable assistant GUI element to be rendered in the display interface includes causing the selectable assistant GUI element to be rendered over a home screen or lock screen that is rendered in the display interface of the computing device. In some implementations, determining a prediction that the user is traveling in a vehicle includes determining the prediction based on whether the user is accessing a navigation application and whether the computing device is communicating with the vehicle computing device. It includes the step of generating a score. In some implementations, causing an assistant driving mode GUI to be rendered in a display interface includes determining whether the score satisfies a score threshold for selecting a region of the display interface to be occupied by the assistant driving mode GUI, The area is larger when the score satisfies the score threshold compared to when the score does not meet the score threshold.
일부 구현에서, 어시스턴트 운전 모드 GUI가 디스플레이 인터페이스에서 렌더링되게 하는 단계는 상기 점수가 상기 어시스턴트 운전 모드 GUI에 대응되는 텍스트에 대한 텍스트 크기를 선택하기 위한 점수 임계값을 만족하는지 여부를 결정하는 단계를 포함하며, 상기 텍스트 크기는, 상기 점수가 상기 점수 임계값을 만족하지 않을 때에 비해 상기 점수가 상기 점수 임계값을 만족할 때, 더 크다. 일부 구현에서, 방법은 상기 사용자가 비히클을 타고 이동한다는 예측을 결정하는 것에 기초하여, 자동화된 어시스턴트가 어시스턴트 운전 모드에 따라 동작하도록 하는 단계를 더 포함하며, 상기 자동화된 어시스턴트가 어시스턴트 운전 모드에 따라 동작할 때, 상기 자동화된 어시스턴트에 대한 특정 사용자 입력은 상기 사용자의 지리적 위치 또는 상기 사용자의 예측된 경로를 특성화하는 로컬 데이터를 사용하여 처리된다. 일부 구현들에서, 방법은 상기 자동화된 어시스턴트에 대한 운전 모드를 활성화하기 위해 상기 선택 가능한 어시스턴트 GUI 요소의 선택이 수신되지 않을 때: 상기 선택 가능한 어시스턴트 GUI 요소가 임계 기간 후에 상기 디스플레이 인터페이스에서 제거될 것이라는 표시를 상기 컴퓨팅 장치의 디스플레이 인터페이스 또는 다른 인터페이스가 렌더링하도록 하는 단계를 더 포함하며, 상기 임계 기간은 상기 사용자가 비히클을 타고 이동하고 있다는 예측에 대한 점수에 기초한다. 일부 구현에서, 상기 사용자가 비히클을 타고 이동하고 있다는 예측을 결정하는 단계는 상기 사용자가 비히클을 타고 이동하고 있음을 나타내는 비히클 상태 데이터를 상기 컴퓨팅 장치가 상기 비히클로부터 수신했는지 여부에 기초하여 상기 예측을 위한 점수를 생성하는 단계를 포함한다. In some implementations, causing an assistant driving mode GUI to be rendered in a display interface includes determining whether the score satisfies a score threshold for selecting a text size for text corresponding to the assistant driving mode GUI. and the text size is larger when the score satisfies the score threshold than when the score does not meet the score threshold. In some implementations, the method further includes causing an automated assistant to operate according to an assistant driving mode based on determining a prediction that the user is traveling in a vehicle, wherein the automated assistant operates according to an assistant driving mode: In operation, specific user input to the automated assistant is processed using local data characterizing the user's geographic location or the user's predicted route. In some implementations, the method is configured to: when a selection of the selectable assistant GUI element is not received to activate a driving mode for the automated assistant: the selectable assistant GUI element will be removed from the display interface after a threshold period of time; and causing a display interface or other interface of the computing device to render an indication, wherein the threshold period is based on a score for predicting that the user is traveling in a vehicle. In some implementations, determining a prediction that the user is traveling in a vehicle comprises determining the prediction based on whether the computing device has received vehicle state data from the vehicle indicating that the user is traveling in a vehicle. It includes the step of generating a score for.
Claims (20)
컴퓨팅 장치에서, 상기 컴퓨팅 장치의 사용자가 비히클(vehicle)을 타고 이동하고 있다는 예측을 결정하는 단계 -상기 컴퓨팅 장치는 자동화된 어시스턴트에 대한 액세스를 제공하고 그리고 상기 비히클의 비히클 컴퓨팅 장치와는 별개임-;
상기 사용자가 상기 비히클을 타고 이동하고 있다는 예측이 상기 컴퓨팅 장치 또는 상기 비히클 컴퓨팅 장치를 통한 내비게이션 인터페이스의 사용자 개시 액세스에 기초할 때 -상기 컴퓨팅 장치는 상기 비히클 컴퓨팅 장치와 통신함-:
어시스턴트 운전 모드 그래픽 사용자 인터페이스(GUI)가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 자동으로 렌더링되도록 하는 단계 -상기 어시스턴트 운전 모드 GUI는 상기 내비게이션 인터페이스 및 상기 사용자가 상기 비히클을 타고 이동하는 동안 상기 사용자에 의해 액세스될 것으로 예측되는 콘텐츠를 포함함-; 그리고
상기 사용자가 비히클을 타고 이동하고 있다는 예측이 상기 내비게이션 인터페이스가 상기 컴퓨팅 장치를 통해 액세스되지 않는 동안 상기 컴퓨팅 장치가 상기 비히클 컴퓨팅 장치와 통신하는 것에 기초할 때:
선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되도록 하는 단계를 포함하며,
상기 선택 가능한 어시스턴트 GUI 요소의 선택은 상기 내비게이션 인터페이스가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되게 하는, 하나 이상의 프로세서에 의해 구현되는 방법.A method implemented by one or more processors, comprising:
At a computing device, determining a prediction that a user of the computing device is traveling in a vehicle, wherein the computing device provides access to an automated assistant and is separate from the vehicle computing device of the vehicle. ;
When the prediction that the user is traveling in the vehicle is based on user-initiated access to the computing device or a navigation interface via the vehicle computing device, the computing device in communication with the vehicle computing device:
causing an assistant driving mode graphical user interface (GUI) to be automatically rendered in a display interface of the computing device, wherein the assistant driving mode GUI is configured to be connected to the navigation interface and to be accessed by the user while the user is traveling in the vehicle. Contains content predicted to be -; and
When the prediction that the user is traveling in a vehicle is based on the computing device communicating with the vehicle computing device while the navigation interface is not accessed through the computing device:
causing selectable assistant GUI elements to be rendered on a display interface of the computing device,
Wherein selection of the selectable assistant GUI element causes the navigation interface to be rendered in a display interface of the computing device.
상기 컴퓨팅 장치가 상기 비히클 컴퓨팅 장치와 통신하지 않는 동안 상기 사용자가 상기 비히클을 타고 이동하고 있음을 나타내는 상기 컴퓨팅 장치의 하나 이상의 센서에 기초하여 상기 사용자가 상기 비히클을 타고 이동하는 것으로 예측될 때:
상기 자동화된 어시스턴트가 상기 자동화된 어시스턴트에 대한 특정 사용자 입력이 상기 사용자의 지리적 위치 또는 상기 비히클의 예측된 경로를 특성화하는 로컬 데이터를 사용하여 처리되는 어시스턴트 운전 모드에서 동작하게 하는 단계를 더 포함하는, 하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 1, wherein
When the user is predicted to be traveling in the vehicle based on one or more sensors on the computing device that indicate that the user is traveling in the vehicle while the computing device is not in communication with the vehicle computing device:
further comprising causing the automated assistant to operate in an assisted driving mode in which specific user input to the automated assistant is processed using local data characterizing the user's geographic location or the predicted path of the vehicle. A method implemented by one or more processors.
카운트다운 타이머가 상기 컴퓨팅 장치를 통해 렌더링 및 초기화되도록 하는 단계를 포함하며, 상기 선택 가능한 어시스턴트 GUI 요소는 상기 카운트다운 타이머가 만료되기 전에 상기 사용자가 상기 선택 가능한 어시스턴트 GUI 요소를 선택하지 않은 것에 응답하여 상기 디스플레이 인터페이스에서 제거되는, 하나 이상의 프로세서에 의해 구현되는 방법.3. The method of claim 1 or 2, wherein causing the selectable assistant GUI element to be rendered in a display interface of the computing device comprises:
causing a countdown timer to be rendered and initialized via the computing device, wherein the selectable assistant GUI element is responsive to the user not selecting the selectable assistant GUI element before the countdown timer expires. A method implemented by one or more processors that is removed from the display interface.
카운트다운 타이머가 상기 컴퓨팅 장치를 통해 렌더링 및 초기화되도록 하는 단계를 포함하며,
상기 카운트다운 타이머가 만료되기 전에 상기 사용자가 상기 선택 가능한 어시스턴트 GUI 요소를 선택하지 않을 때, 상기 자동화된 어시스턴트는 상기 자동화된 어시스턴트에 대한 특정 사용자 입력이 상기 사용자의 지리적 위치 또는 상기 비히클의 예측된 경로를 특성화하는 로컬 데이터를 사용하여 처리되는 어시스턴트 운전 모드에 따라 동작하는, 하나 이상의 프로세서에 의해 구현되는 방법.3. The method of claim 1 or 2, wherein causing the selectable assistant GUI element to be rendered in a display interface of a computing device comprises:
causing a countdown timer to be rendered and initialized via the computing device,
When the user does not select the selectable assistant GUI element before the countdown timer expires, the automated assistant determines whether the specific user input to the automated assistant is related to the user's geographic location or the vehicle's predicted route. A method implemented by one or more processors, operating according to the assistant driving mode, which is processed using local data characterizing the process.
컴퓨팅 장치에서, 사용자가 비히클(vehicle)을 타고 이동하고 있다는 예측에 대한 점수를 결정하는 단계 -상기 컴퓨팅 장치는 자동화된 어시스턴트에 대한 액세스를 제공하고 그리고 상기 비히클의 비히클 컴퓨팅 장치와는 별개임-;
상기 예측에 대한 점수가 점수 임계값을 만족할 때:
어시스턴트 운전 모드 그래픽 사용자 인터페이스(GUI)가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 자동으로 렌더링되도록 하는 단계 -상기 어시스턴트 운전 모드 GUI는 내비게이션 인터페이스 및 상기 사용자가 비히클을 타고 이동하는 동안 상기 사용자에 의해 액세스될 것으로 예측되는 콘텐츠를 포함함-; 그리고
상기 예측에 대한 점수가 상기 점수 임계값을 만족하지 않을 때:
선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되도록 하는 단계를 포함하며,
상기 선택 가능한 어시스턴트 GUI 요소의 선택은 상기 내비게이션 인터페이스가 상기 디스플레이 인터페이스에서 렌더링되는 어시스턴트 운전 모드에 따라 상기 자동화된 어시스턴트가 동작하게 하는, 하나 이상의 프로세서에 의해 구현되는 방법.A method implemented by one or more processors, comprising:
At a computing device, determining a score for a prediction that a user is traveling in a vehicle, wherein the computing device provides access to an automated assistant and is separate from the vehicle's vehicle computing device;
When the score for the above prediction satisfies the score threshold:
causing an assistant driving mode graphical user interface (GUI) to be automatically rendered on a display interface of the computing device, wherein the assistant driving mode GUI is expected to be accessed by the user while the user is traveling in a vehicle and a navigation interface. Contains content that is -; and
When the score for the prediction does not meet the score threshold:
causing selectable assistant GUI elements to be rendered on a display interface of the computing device,
wherein selection of the selectable assistant GUI element causes the automated assistant to operate in accordance with an assistant driving mode in which the navigation interface is rendered in the display interface.
상기 선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되는 홈 화면 또는 잠금 화면 위에 렌더링되도록 하는 단계를 포함하는, 하나 이상의 프로세서에 의해 구현되는 방법.7. The method of claim 6, wherein causing the selectable assistant GUI element to be rendered in the display interface comprises:
A method implemented by one or more processors, comprising causing the selectable assistant GUI element to be rendered over a home screen or lock screen rendered on a display interface of the computing device.
상기 컴퓨팅 장치의 하나 이상의 센서를 사용하여 생성된 데이터 또는 상기 사용자와 연관된 다른 컴퓨팅 장치에서 이용 가능한 다른 데이터에 기초하여 상기 예측에 대한 점수를 생성하는 단계를 포함하는, 하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 6 or 7, wherein determining a score for predicting that the user is moving in a vehicle comprises:
A method implemented by one or more processors, comprising generating a score for the prediction based on data generated using one or more sensors of the computing device or other data available on another computing device associated with the user. .
상기 내비게이션 인터페이스가 렌더링되고 그리고 상기 점수가 상기 점수 임계값을 만족하지 않을 때에 비해 상기 점수가 상기 점수 임계값을 만족할 때 상기 디스플레이 인터페이스의 더 큰 영역에서 렌더링되는, 하나 이상의 프로세서에 의해 구현되는 방법.The method of any one of claims 6 to 8, wherein when the assistant driving mode GUI is rendered on a display interface, the navigation interface is:
The method implemented by one or more processors, wherein the navigation interface is rendered and rendered over a larger area of the display interface when the score meets the score threshold compared to when the score does not meet the score threshold.
상기 선택 가능한 어시스턴트 GUI 요소가 임계 기간 후에 상기 디스플레이 인터페이스에서 제거될 것이라는 표시를 상기 컴퓨팅 장치의 디스플레이 인터페이스 또는 다른 인터페이스가 렌더링하도록 하는 단계를 포함하며,
상기 임계 기간은 상기 사용자가 비히클을 타고 이동하고 있다는 예측에 대한 점수에 기초하는, 하나 이상의 프로세서에 의해 구현되는 방법.11. The method of any one of claims 6-10, wherein when the score for the prediction does not meet a score threshold, causing a selectable assistant GUI element to be rendered in a display interface of the computing device comprising:
causing a display interface or other interface of the computing device to render an indication that the selectable assistant GUI element will be removed from the display interface after a threshold period of time;
The method implemented by one or more processors, wherein the threshold period is based on a score for predicting that the user is traveling in a vehicle.
컴퓨팅 장치에서, 상기 컴퓨팅 장치의 하나 이상의 센서를 사용하여 생성된 데이터에 기초하여 사용자가 비히클(vehicle)을 타고 이동하고 있다는 예측을 결정하는 단계 -상기 컴퓨팅 장치는 자동화된 어시스턴트에 대한 액세스를 제공하고 그리고 상기 비히클의 비히클 컴퓨팅 장치와는 별개임-;
상기 사용자가 상기 비히클을 타고 이동하는 것으로 예측된다는 결정에 기초하여, 선택 가능한 어시스턴트 그래픽 사용자 인터페이스(GUI) 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되도록 하는 단계;
상기 자동화된 어시스턴트에 대한 운전 모드를 활성화하기 위해 상기 선택 가능한 어시스턴트 GUI 요소의 선택이 수신될 때:
상기 선택 가능한 어시스턴트 GUI 요소의 선택을 수신하는 것에 응답하여, 어시스턴트 운전 모드 GUI가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되도록 하는 단계를 포함하며,
상기 어시스턴트 운전 모드 GUI에서 렌더링되는 하나 이상의 선택 가능한 GUI 요소의 특성은 상기 사용자가 비히클을 타고 이동하고 있다는 예측에 대한 점수에 기초하여 선택되는, 하나 이상의 프로세서에 의해 구현되는 방법.A method implemented by one or more processors, comprising:
determining, at a computing device, a prediction that the user is traveling in a vehicle based on data generated using one or more sensors of the computing device, wherein the computing device provides access to an automated assistant; and is separate from the vehicle computing device of the vehicle;
based on a determination that the user is predicted to be traveling in the vehicle, causing selectable assistant graphical user interface (GUI) elements to be rendered in a display interface of the computing device;
When selection of the selectable assistant GUI element is received to activate a driving mode for the automated assistant:
In response to receiving a selection of the selectable assistant GUI element, causing an assistant driving mode GUI to be rendered in a display interface of the computing device,
A method implemented by one or more processors, wherein characteristics of one or more selectable GUI elements rendered in the assistant driving mode GUI are selected based on a score for predicting that the user is traveling in a vehicle.
상기 선택 가능한 어시스턴트 GUI 요소가 상기 컴퓨팅 장치의 디스플레이 인터페이스에서 렌더링되는 홈 화면 또는 잠금 화면 위에 렌더링되도록 하는 단계를 포함하는, 하나 이상의 프로세서에 의해 구현되는 방법.14. The method of claim 13, wherein causing the selectable assistant GUI element to be rendered in the display interface comprises:
A method implemented by one or more processors, comprising causing the selectable assistant GUI element to be rendered over a home screen or lock screen rendered on a display interface of the computing device.
상기 사용자가 내비게이션 애플리케이션에 액세스하고 있는지 여부와 상기 컴퓨팅 장치가 상기 비히클 컴퓨팅 장치와 통신하고 있는지 여부에 기초하여 상기 예측에 대한 점수를 생성하는 단계를 포함하는, 하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 13 or 14, wherein determining a prediction that the user is moving in a vehicle comprises:
A method implemented by one or more processors, including generating a score for the prediction based on whether the user is accessing a navigation application and whether the computing device is in communication with the vehicle computing device.
상기 어시스턴트 운전 모드 GUI가 차지할 디스플레이 인터페이스의 영역을 선택하기 위한 점수 임계값을 상기 점수가 만족하는지 여부를 결정하는 단계를 포함하며, 상기 점수가 상기 점수 임계값을 만족하지 않을 때에 비해 상기 점수가 점수 임계값을 만족할 때 상기 영역이 더 큰, 하나 이상의 프로세서에 의해 구현되는 방법.16. The method of any one of claims 13 to 15, wherein causing the assistant driving mode GUI to be rendered in the display interface comprises:
and determining whether the score satisfies a score threshold for selecting an area of the display interface to be occupied by the assistant driving mode GUI, wherein the score is greater than when the score does not satisfy the score threshold. A method implemented by one or more processors, wherein the area becomes larger when a threshold is met.
상기 점수가 상기 어시스턴트 운전 모드 GUI에 대응되는 텍스트에 대한 텍스트 크기를 선택하기 위한 점수 임계값을 만족하는지 여부를 결정하는 단계를 포함하며,
상기 텍스트 크기는, 상기 점수가 상기 점수 임계값을 만족하지 않을 때에 비해 상기 점수가 상기 점수 임계값을 만족할 때, 더 큰, 하나 이상의 프로세서에 의해 구현되는 방법.17. The method of any one of claims 13 to 16, wherein causing the assistant driving mode GUI to be rendered in the display interface comprises:
determining whether the score satisfies a score threshold for selecting a text size for text corresponding to the assistant driving mode GUI;
The method of claim 1, wherein the text size is larger when the score satisfies the score threshold compared to when the score does not meet the score threshold.
상기 사용자가 비히클을 타고 이동한다는 예측을 결정하는 것에 기초하여, 자동화된 어시스턴트가 어시스턴트 운전 모드에 따라 동작하도록 하는 단계를 더 포함하며,
상기 자동화된 어시스턴트가 어시스턴트 운전 모드에 따라 동작할 때, 상기 자동화된 어시스턴트에 대한 특정 사용자 입력은 상기 사용자의 지리적 위치 또는 상기 사용자의 예측된 경로를 특성화하는 로컬 데이터를 사용하여 처리되는, 하나 이상의 프로세서에 의해 구현되는 방법.The method of any one of claims 13 to 17, wherein the method comprises:
Based on determining the prediction that the user is traveling in the vehicle, causing the automated assistant to operate according to an assistant driving mode,
One or more processors, wherein when the automated assistant operates in accordance with an assistant driving mode, specific user input to the automated assistant is processed using local data characterizing the user's geographic location or the user's predicted route. The method implemented by .
상기 자동화된 어시스턴트에 대한 운전 모드를 활성화하기 위해 상기 선택 가능한 어시스턴트 GUI 요소의 선택이 수신되지 않을 때:
상기 선택 가능한 어시스턴트 GUI 요소가 임계 기간 후에 상기 디스플레이 인터페이스에서 제거될 것이라는 표시를 상기 컴퓨팅 장치의 디스플레이 인터페이스 또는 다른 인터페이스가 렌더링하도록 하는 단계를 더 포함하며,
상기 임계 기간은 상기 사용자가 비히클을 타고 이동하고 있다는 예측에 대한 점수에 기초하는, 하나 이상의 프로세서에 의해 구현되는 방법.The method of any one of claims 13 to 18, wherein the method comprises:
When no selection of the selectable assistant GUI element is received to activate a driving mode for the automated assistant:
further comprising causing a display interface or other interface of the computing device to render an indication that the selectable assistant GUI element will be removed from the display interface after a threshold period of time;
The method implemented by one or more processors, wherein the threshold period is based on a score for predicting that the user is traveling in a vehicle.
상기 사용자가 비히클을 타고 이동하고 있음을 나타내는 비히클 상태 데이터를 상기 컴퓨팅 장치가 상기 비히클로부터 수신했는지 여부에 기초하여 상기 예측을 위한 점수를 생성하는 단계를 포함하는, 하나 이상의 프로세서에 의해 구현되는 방법.20. The method of any one of claims 13 to 19, wherein determining a prediction that the user is traveling in a vehicle comprises:
A method implemented by one or more processors, comprising generating a score for the prediction based on whether the computing device has received vehicle state data from the vehicle indicating that the user is traveling in a vehicle.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163236584P | 2021-08-24 | 2021-08-24 | |
US63/236,584 | 2021-08-24 | ||
US17/533,380 US20230062489A1 (en) | 2021-08-24 | 2021-11-23 | Proactively activating automated assistant driving modes for varying degrees of travel detection confidence |
US17/533,380 | 2021-11-23 | ||
PCT/US2021/061237 WO2023027751A1 (en) | 2021-08-24 | 2021-11-30 | Proactively activating automated assistant driving modes for varying degrees of travel detection confidence |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20230160376A true KR20230160376A (en) | 2023-11-23 |
Family
ID=79170936
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020237036509A KR20230160376A (en) | 2021-08-24 | 2021-11-30 | Pre-activates automated assistant driving mode for variable movement detection reliability |
Country Status (3)
Country | Link |
---|---|
EP (1) | EP4162233A1 (en) |
KR (1) | KR20230160376A (en) |
WO (1) | WO2023027751A1 (en) |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10705794B2 (en) * | 2010-01-18 | 2020-07-07 | Apple Inc. | Automatically adapting user interfaces for hands-free interaction |
US8473289B2 (en) * | 2010-08-06 | 2013-06-25 | Google Inc. | Disambiguating input based on context |
KR102056177B1 (en) * | 2013-02-22 | 2020-01-22 | 삼성전자 주식회사 | Method for providing a voice-speech service and mobile terminal implementing the same |
US10116748B2 (en) * | 2014-11-20 | 2018-10-30 | Microsoft Technology Licensing, Llc | Vehicle-based multi-modal interface |
CN108804010B (en) * | 2018-05-31 | 2021-07-30 | 北京小米移动软件有限公司 | Terminal control method, device and computer readable storage medium |
US11157169B2 (en) * | 2018-10-08 | 2021-10-26 | Google Llc | Operating modes that designate an interface modality for interacting with an automated assistant |
-
2021
- 2021-11-30 WO PCT/US2021/061237 patent/WO2023027751A1/en active Application Filing
- 2021-11-30 KR KR1020237036509A patent/KR20230160376A/en unknown
- 2021-11-30 EP EP21835480.1A patent/EP4162233A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2023027751A1 (en) | 2023-03-02 |
EP4162233A1 (en) | 2023-04-12 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP3507718B1 (en) | Using textual input and user state information to generate reply content to present in response to the textual input | |
JP6827479B2 (en) | Non-deterministic task initiation with personal assistant module | |
EP3540729B1 (en) | Reducing latency caused by switching input modalities | |
US11749280B2 (en) | Dynamically delaying execution of automated assistant actions and/or background application requests | |
US20220005476A1 (en) | Systems, methods, and apparatuses for managing incomplete automated assistant actions | |
JP2023500048A (en) | Using Automated Assistant Feature Correction for Training On-Device Machine Learning Models | |
KR20230110788A (en) | Passive disambiguation of assistant commands | |
KR20200124298A (en) | Mitigate client device latency when rendering remotely generated automated assistant content | |
JP2023535250A (en) | Failure detection and handling in automated voice assistants | |
KR20230160376A (en) | Pre-activates automated assistant driving mode for variable movement detection reliability | |
US20230062489A1 (en) | Proactively activating automated assistant driving modes for varying degrees of travel detection confidence | |
US11853649B2 (en) | Voice-controlled entry of content into graphical user interfaces | |
US11801750B2 (en) | Adaptation(s) based on correlating hazardous vehicle events with application feature(s) | |
CN117157504A (en) | Actively activating an auto-assistant driving mode to obtain varying degrees of confidence in travel detection | |
CN116711004A (en) | Automatic assistant execution of non-assistant application operations in response to user input capable of limiting parameters | |
US20230335127A1 (en) | Multiple concurrent voice assistants | |
US11959764B2 (en) | Automated assistant that detects and supplements various vehicle computing device capabilities | |
US20240038246A1 (en) | Non-wake word invocation of an automated assistant from certain utterances related to display content | |
CN116802597A (en) | Selectively rendering keyboard interfaces in response to assistant calls in some cases | |
CN114675773A (en) | Conditional preparation of automated assistant input from a user in a vehicle |