US7055071B2 - Method and apparatus for reporting error logs in a logical environment - Google Patents
Method and apparatus for reporting error logs in a logical environment Download PDFInfo
- Publication number
- US7055071B2 US7055071B2 US10/339,770 US33977003A US7055071B2 US 7055071 B2 US7055071 B2 US 7055071B2 US 33977003 A US33977003 A US 33977003A US 7055071 B2 US7055071 B2 US 7055071B2
- Authority
- US
- United States
- Prior art keywords
- error
- error information
- buffer
- log
- time
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/0703—Error or fault processing not based on redundancy, i.e. by taking additional measures to deal with the error or fault not making use of redundancy in operation, in hardware, or in data representation
- G06F11/0766—Error or fault reporting or storing
- G06F11/0781—Error filtering or prioritizing based on a policy defined by the user or on a policy defined by a hardware/software module, e.g. according to a severity level
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/0703—Error or fault processing not based on redundancy, i.e. by taking additional measures to deal with the error or fault not making use of redundancy in operation, in hardware, or in data representation
- G06F11/0706—Error or fault processing not based on redundancy, i.e. by taking additional measures to deal with the error or fault not making use of redundancy in operation, in hardware, or in data representation the processing taking place on a specific hardware platform or in a specific software environment
- G06F11/0712—Error or fault processing not based on redundancy, i.e. by taking additional measures to deal with the error or fault not making use of redundancy in operation, in hardware, or in data representation the processing taking place on a specific hardware platform or in a specific software environment in a virtual computing platform, e.g. logically partitioned systems
Definitions
- the present invention relates generally to an improved data processing system, and in particular, to a method and apparatus for error analysis. Still more particularly, the present invention provides a method and apparatus for retrieving logs for a partition in a logical partitioned data processing system.
- a logical partitioned (LPAR) functionality within a data processing system allows multiple copies of a single operating system (OS) or multiple heterogeneous operating systems to be simultaneously run on a single data processing system platform.
- a partition, within which an operating system image runs, is assigned a non-overlapping subset of the platform's resources.
- These platform allocable resources include one or more architecturally distinct processors with their interrupt management area, regions of system memory, and input/output (I/O) adapter bus slots.
- the partition's resources are represented by the platform's firmware to the OS image.
- Each distinct OS or image of an OS running within the platform is protected from each other such that software errors on one logical partition cannot affect the correct operation of any of the other partitions. This is provided by allocating a disjoint set of platform resources to be directly managed by each OS image and by providing mechanisms for ensuring that the various images cannot control any resources that have not been allocated to it. Furthermore, software errors in the control of an operating system's allocated resources are prevented from affecting the resources of any other image. Thus, each image of the OS (or each different OS) directly controls a distinct set of allocable resources within the platform.
- An operating system within a LPAR data processing system may periodically call a routine to check states and report errors that are found.
- This routine is part of a run-time abstraction services (RTAS) component and is called an event scan.
- RTAS is designed to insulate an operating system from having to know about and manipulate platform functions that would require platform specific code.
- the RTAS is called as an interface to hardware, such as hardware registers.
- Each partition has a copy of RTAS in memory.
- RTAS is found in IBM eServer pSeries products, which are available from International Business Machines Corporation.
- the event scan function checks for error logs that may have been reported by various subsystems of the data processing system. These subsystems include, for example, the service processor, open firmware, and non-maskable machine interrupt code.
- Each of these subsystems places reported error logs for an operating system in a specific location.
- One location used by service processors to place reportable logs for a partition is a non-volatile random access memory (NVRAM).
- NVRAM non-volatile random access memory
- the event scan function searches the various locations used by these components to find for new non-reported error logs. When a new non-reported log is identified, this function reports the log to the operating system that the log is to be reported and marks the log so that it is no longer considered new and unreported. By marking the log in this manner, the event scan function will not report the log again at a later time. Additionally, this allows the space occupied by the log to be overlaid with a new non-reported log.
- a symmetric multiprocessor mode configuration the entire data processing system is owned by one operating system. As a result, only one instance of the event scan function is called. With only one instance of the event scan function, any error log reported to the operating system can be marked as old and reported. In a LPAR environment, a few problems become apparent. For example, with each LPAR partition, an instance of the event scan function may be called. Each event scan function is required to report the same error logs to their respective operating systems. It is important that the NVRAM locations in which the subsystems place new error logs do not become clogged. Otherwise, errors may be missed.
- a partition within a LPAR system booted days or months after the data processing system has been started has no reason to receive outdated error logs even if the error would be considered new to the partition.
- the event scan function called by one partition, is unable to mark an error log as old and reported because the error log may not be old or reported to another partition. Without this ability to mark error logs, logs cannot be removed, preventing the addition of new error logs when the memory space is used up.
- the present invention provides a method, apparatus, and computer instructions for managing error logs.
- a request is received from a partition within a plurality of partitions in the logical partitioned data processing system to access error information.
- a determination is made as to whether the error information is located in a buffer.
- the error information is retrieved from a non-volatile memory in response to the error information being absent in the buffer.
- the retrieved error information retrieved from the non-volatile memory is stored in the buffer. This error information is stored in the buffer only for a selected period of time. After that period of time, this error information is deleted or removed from the buffer. In this manner, outdated error information is not returned to the plurality of partitions.
- FIG. 1 is a block diagram of a data processing system in which the present invention may be implemented
- FIG. 2 is a block diagram of an exemplary logically partitioned platform in which the present invention may be implemented
- FIG. 3 is a diagram illustrating components used in managing error logs in accordance with a preferred embodiment of the present invention
- FIG. 4 is a diagram illustrating an example structure of a partition log buffer in accordance with a preferred embodiment of the present invention.
- FIG. 5 is a flowchart of a process used for managing error logs in a logical partitioned data processing system in accordance with a preferred embodiment of the present invention
- FIG. 6 is a flowchart of a process used for retrieving logs in accordance with a preferred embodiment of the present invention.
- FIG. 7 is a flowchart of a process used for copying logs into a partition log buffer in accordance with a preferred embodiment of the present invention.
- FIG. 8 is a flowchart of a process used for deleting a log in a partition log buffer in accordance with a preferred embodiment of the present invention.
- Data processing system 100 may be a symmetric multiprocessor (SMP) system including a plurality of processors 101 , 102 , 103 , and 104 connected to system bus 106 .
- SMP symmetric multiprocessor
- data processing system 100 may be an IBM RS/6000, a product of International Business Machines Corporation in Armonk, N.Y., implemented as a server within a network.
- a single processor system may be employed.
- memory controller/cache 108 Also connected to system bus 106 is memory controller/cache 108 , which provides an interface to a plurality of local memories 160 – 163 .
- I/O bus bridge 110 is connected to system bus 106 and provides an interface to I/O bus 112 . Memory controller/cache 108 and I/O bus bridge 110 may be integrated as depicted.
- Data processing system 100 is a logically partitioned data processing system.
- data processing system 100 may have multiple heterogeneous operating systems (or multiple instances of a single operating system) running simultaneously. Each of these multiple operating systems may have any number of software programs executing within it.
- Data processing system 100 is logically partitioned such that different PCI I/O adapters 120 – 121 , 128 – 129 , and 136 , graphics adapter 148 , and hard disk adapter 149 may be assigned to different logical partitions.
- graphics adapter 148 provides a connection for a display device (not shown)
- hard disk adapter 149 provides a connection to control hard disk 150 .
- data processing system 100 is divided into three logical partitions, P 1 , P 2 , and P 3 .
- Each of PCI I/O adapters 120 – 121 , 128 – 129 , 136 , graphics adapter 148 , hard disk adapter 149 , each of host processors 101 – 104 , and each of local memories 160 – 163 is assigned to one of the three partitions.
- processor 101 local memory 160 , and I/O adapters 120 , 128 , and 129 may be assigned to logical partition P 1 ; processors 102 – 103 , local memory 161 , and PCI I/O adapters 121 and 136 may be assigned to partition P 2 ; and processor 104 , local memories 162 – 163 , graphics adapter 148 and hard disk adapter 149 may be assigned to logical partition P 3 .
- Each operating system executing within data processing system 100 is assigned to a different logical partition. Thus, each operating system executing within data processing system 100 may access only those I/O units that are within its logical partition. Thus, for example, one instance of the Advanced Interactive Executive (AIX) operating system may be executing within partition P 1 , a second instance (image) of the AIX operating system may be executing within partition P 2 , and a Windows XP operating system may be operating within logical partition P 1 .
- AIX Advanced Interactive Executive
- a Windows XP operating system may be operating within logical partition P 1 .
- Windows XP is a product and trademark of Microsoft Corporation of Redmond, Wash.
- Peripheral component interconnect (PCI) host bridge 114 connected to I/O bus 112 provides an interface to PCI local bus 115 .
- a number of PCI input/output adapters 120 – 121 may be connected to PCI bus 115 through PCI-to-PCI bridge 116 , PCI bus 118 , PCI bus 119 , I/O slot 170 , and I/O slot 171 .
- PCI-to-PCI bridge 116 provides an interface to PCI bus 118 and PCI bus 119 .
- PCI I/O adapters 120 and 121 are placed into I/O slots 170 and 171 , respectively.
- Typical PCI bus implementations will support between four and eight I/O adapters (i.e. expansion slots for add-in connectors).
- Each PCI I/O adapter 120 – 121 provides an interface between data processing system 100 and input/output devices such as, for example, other network computers, which are clients to data processing system 100 .
- An additional PCI host bridge 122 provides an interface for an additional PCI bus 123 .
- PCT bus 123 is connected to a plurality of PCI I/O adapters 128 – 129 .
- PCI I/O adapters 128 – 129 may be connected to PCI bus 123 through PCI-to-PCI bridge 124 , PCI bus 126 , PCI bus 127 , I/O slot 172 , and I/O slot 173 .
- PCI-to-PCI bridge 124 provides an interface to PCI bus 126 and PCI bus 127 .
- PCI I/O adapters 128 and 129 are placed into I/O slots 172 and 173 , respectively.
- additional I/O devices such as, for example, modems or network adapters may be supported through each of PCI I/O adapters 128 – 129 .
- data processing system 100 allows connections to multiple network computers.
- a memory mapped graphics adapter 148 inserted into I/O slot 174 may be connected to I/O bus 112 through PCI bus 144 , PCI-to-PCI bridge 142 , PCI bus 141 and PCT host bridge 140 .
- Hard disk adapter 149 may be placed into I/O slot 175 , which is connected to PCI bus 145 . In turn, this bus is connected to PCI-to-PCI bridge 142 , which is connected to PCI host bridge 140 by PCI bus 141 .
- a PCI host bridge 130 provides an interface for a PCI bus 131 to connect to I/O bus 112 .
- PCI I/O adapter 136 is connected to I/O slot 176 , which is connected to PCI-to-PCI bridge 132 by PCI bus 133 .
- PCI-to-PCI bridge 132 is connected to PCI bus 131 .
- This PCI bus also connects PCI host bridge 130 to the service processor mailbox interface and ISA bus access pass–through logic 194 and PCI-to-PCI bridge 132 .
- Service processor mailbox interface and ISA bus access pass–through logic 194 forwards PCI accesses destined to the PCI/ISA bridge 193 .
- NVRAM storage 192 is connected to the ISA bus 196 .
- Service processor 135 is coupled to service processor mailbox interface and ISA bus access pass–through logic 194 through its local PCI bus 195 .
- Service processor 135 is also connected to processors 101 – 104 via a plurality of JTAG/I 2 C busses 134 .
- JTAG/I 2 C busses 134 are a combination of JTAG/scan busses (see IEEE 1149.1) and Phillips I 2 C busses. However, alternatively, JTAG/I 2 C busses 134 may be replaced by only Phillips I 2 C busses or only JTAG/scan busses. All SP-ATTN signals of the host processors 101 , 102 , 103 , and 104 are connected together to an interrupt input signal of the service processor.
- the service processor 135 has its own local memory 191 , and has access to the hardware OP–panel 190 .
- service processor 135 uses the JTAG/I 2 C busses 134 to interrogate the system (host) processors 101 – 104 , memory controller/cache 108 , and I/O bridge 110 .
- service processor 135 has an inventory and topology understanding of data processing system 100 .
- Service processor 135 also executes Built-In-Self-Tests (BISTs), Basic Assurance Tests (BATs), and memory tests on all elements found by interrogating the host processors 101 – 104 , memory controller/cache 108 , and I/O bridge 110 . Any error information for failures detected during the BISTs, BATs, and memory tests are gathered and reported by service processor 135 .
- BISTs Built-In-Self-Tests
- BATs Basic Assurance Tests
- data processing system 100 is allowed to proceed to load executable code into local (host) memories 160 – 163 .
- Service processor 135 then releases the host processors 101 – 104 for execution of the code loaded into local memory 160 – 163 . While the host processors 101 – 104 are executing code from respective operating systems within the data processing system 100 , service processor 135 enters a mode of monitoring and reporting errors.
- the type of items monitored by service processor 135 include, for example, the cooling fan speed and operation, thermal sensors, power supply regulators, and recoverable and non–recoverable errors reported by processors 101 – 104 , local memories 160 – 163 , and I/O bridge 110 .
- Service processor 135 is responsible for saving and reporting error information related to all the monitored items in data processing system 100 .
- Service processor 135 also takes action based on the type of errors and defined thresholds. For example, service processor 135 may take note of excessive recoverable errors on a processor's cache memory and decide that this is predictive of a hard failure. Based on this determination, service processor 135 may mark that resource for deconfiguration during the current running session and future Initial Program Loads (IPLs). IPLs are also sometimes referred to as a “boot” or “bootstrap”.
- IPLs are also sometimes referred to as a “boot” or “bootstrap”.
- Data processing system 100 may be implemented using various commercially available computer systems.
- data processing system 100 may be implemented using IBM eServer iSeries Model 840 system available from International Business Machines Corporation.
- Such a syst em may support logical partitioning using an OS/400 operating system, which is also available from International Business Machines Corporation.
- FIG. 1 may vary.
- other peripheral devices such as optical disk drives and the like, also may be used in addition to or in place of the hardware depicted.
- the depicted example is not meant to imply architectural limitations with respect to the present invention.
- Logically partitioned platform 200 includes partitioned hardware 230 , operating systems 202 , 204 , 206 , 208 , and hypervisor 210 .
- Operating systems 202 , 204 , 206 , and 208 may be multiple copies of a single operating system or multiple heterogeneous operating systems simultaneously run on platform 200 .
- These operating systems may be implemented using OS/400, which are designed to interface with a hypervisor.
- Operating systems 202 , 204 , 206 , and 208 are located in partitions 203 , 205 , 207 , and 209 . Additionally, these partitions also include firmware loaders 211 , 213 , 215 , and 217 . These firmware loaders may be implemented using RTAS.
- partitions 203 , 205 , 207 , and 209 are instantiated, a copy of the open firmware is loaded into each partition by the hypervisor's partition manager. The processors associated or assigned to the partitions are then dispatched to the partitions' memory to execute the partition firmware.
- Partitioned hardware 230 includes a plurality of processors 232 – 238 , a plurality of system memory units 240 – 246 , a plurality of input/output (I/O) adapters 248 – 262 , and a storage unit 270 .
- Partitioned hardware 230 also includes service processor 290 , which may be used to provide various services, such as processing of errors in the partitions.
- Each of the processors 232 – 238 , memory units 240 – 246 , NVRAM storage 298 , and I/O adapters 248 – 262 may be assigned to multiple partitions within logically partitioned platform 200 , each of which corresponds to one of operating systems 202 , 204 , 206 , and 208 . Most of NVRAM storage 298 is partitioned up for use by the different partitions, but this NVRAM also includes a common area, accessed by all of the partitions, in which the service processor places logs.
- Partition management firmware (hypervisor) 210 performs a number of functions and services for partitions 203 , 205 , 207 , and 209 to create and enforce the partitioning of logically partitioned platform 200 .
- Hypervisor 210 is a firmware implemented virtual machine identical to the underlying hardware. Hypervisor software is available from International Business Machines Corporation. Firmware is “software” stored in a memory chip that holds its content without electrical power, such as, for example, read-only memory (ROM), programmable ROM (PROM), erasable programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), and non-volatile random access memory (non-volatile RAM).
- ROM read-only memory
- PROM programmable ROM
- EPROM erasable programmable ROM
- EEPROM electrically erasable programmable ROM
- non-volatile random access memory non-volatile RAM
- the present invention provides a method, apparatus, and computer implemented instructions for managing the reporting of error information to different partitions in a logically partitioned data processing system.
- the mechanism of the present invention copies the error log into a buffer.
- the buffer is accessible by all instances of the event scan function that may be called by the different partitions.
- the information is copied from the location usually used to store error logs, such as NVRAM 298 in FIG. 2 .
- error log is copied into the buffer, this log is marked in the NVRAM as being old and reported.
- the log that is copied into the buffer is assigned or given an expiration time stamp. This time stamp is used to determine when a log may be deleted or removed from the buffer.
- This buffer is also referred to as a partition log buffer.
- the partition log buffer may be located in various places in the data processing system.
- the partition log buffer may be located in local memory, such as local memory 160 in FIG. 1 .
- This buffer also may be located in a storage device, such as a hard disk drive or a tape drive.
- an error log may be made available to any partition in a LPAR system within a selected period of time.
- partitions booted or started days or months after the machine has been started will not see error logs that are outdated even though these logs may be new to these particular partitions.
- partition management firmware 300 may be implemented using a hypervisor, such as partition management firmware 210 in FIG. 2 .
- This firmware includes a function similar to the event scan function. However, the function includes managing logs in partition log buffer 302 . This buffer is used to store the logs that are to be accessed by a partition, such as partition 304 .
- NVRAM 306 is the location in which different subsystems place error logs in these examples. Other locations may be used depending on the implementation.
- a non-volatile storage is typically used to retain these logs if the data processing system is powered off.
- Partition 304 may call an event scan function in partition management firmware 300 operating system 308 through firmware loader 310 to request error information.
- partition management firmware 300 will call a retrieve log function in which the call includes the requesting partition number and the memory area in which the log is to be placed. This memory area identifies the area in which the requesting partition expects to receive the error information. If this function indicates that a log, such as log 312 , is present in partition log buffer 302 , then this function copies the information to the memory area identified in the call for use by the partition.
- partition management firmware 300 will check NVRAM 306 to determine whether new and non-reported error logs are present.
- NVRAM 306 contains log 314 and log 316 . If neither of these logs is new and non-reported, partition management firmware 300 returns a message to the calling partition indicating that no error information is present. If one or more of these logs are new and unreported, the new and unreported error log is copied from NVRAM 306 into partition log buffer 302 . In these examples, only one log is copied into partition log buffer 302 . Of course, depending on the implementation more than one log may be copied into this buffer.
- the error log copied into partition log buffer 302 is associated with a time period or time stamp to indicate when the log will be removed from partition log buffer 302 . Further, the log copied into partition log buffer 302 is marked as being old and reported within NVRAM 306 . After a new log is copied into partition log buffer 302 , partition management firmware 300 will again call the retrieve log function now that a log is present in partition log buffer 302 .
- Data structure 400 is an example of a data structure used to implement a partition log buffer, such as partition log buffer 302 in FIG. 3 .
- line 402 is an index for the newest recorded log in the partition log buffer.
- Line 404 identifies an index, on a partition basis, as to what is the oldest log reported to a particular partition.
- Line 406 defines an area in the partition log buffer to record the expiration time of a log stored within the partition log buffer.
- Line 408 is used to identify whether a partition has started to report error logs.
- Line 410 is used to define the buffer used to hold the copy of the error log.
- each error log in the partition log buffer is stored in a 1K buffer.
- the expiration time for a log is selected to be two hours.
- the partition log buffer is designed to hold 64 logs. Of course, depending on the particular system and implementation, different sizes, times, and numbers of logs may be selected for the partition log buffer.
- FIG. 5 a flowchart of a process used for managing error logs in a logical partitioned data processing system is depicted in accordance with a preferred embodiment of the present invention.
- the process illustrated in FIG. 5 may be implemented in a partition management firmware component, such as partition management firmware 300 in FIG. 3 .
- the process begins by receiving a request for error information (step 500 ).
- This request is received from a partition, such as partition 304 in FIG. 3 .
- a retrieve log function is called (step 502 ). This function is described in more detail in FIG. 6 below.
- a determination is made as to whether an error log present in the partition log buffer has been copied or sent to the partition by the retrieve log function (step 504 ). If an error log has not been copied or sent by this function, the non-volatile storage is checked for new logs (step 506 ).
- the non-volatile storage is a NVRAM, such as NVRAM 306 in FIG. 3 .
- a header may be included in NVRAM 306 to facilitate managing of logs. The header describes the location and status of each log in the NVRAM. In these examples, the status is indicated using a single byte. A value of 0 indicates that the log is old and unreported, while a value of 1 indicates that the log is new and unreported.
- an add log function is called (step 510 ). This function is used to copy the log from the non-volatile storage to the partition log buffer. Thereafter, the error log copied from the non-volatile storage to the partition log buffer is marked as “old and reported” (step 512 ) and the process returns to step 502 as described above.
- step 508 if a “new and non-reported” error log is absent in the non-volatile storage, the process terminates.
- step 504 if the retrieve log function has copied or sent the error information, the error log, to the partition, the process also terminates.
- FIG. 6 a flowchart of a process used for retrieving logs is depicted in accordance with a preferred embodiment of the present invention.
- the process illustrated in FIG. 6 may be implemented in a partition management firmware component, such as partition management firmware 300 in FIG. 3 .
- the function illustrated in this flowchart is a more detailed description of a retrieve log function called in step 502 in FIG. 5 .
- the process begins by searching the partition buffer log for the oldest non-reported log for the partition (step 600 ). A determination is made as to whether a log is present in the partition log buffer (step 602 ). If a log is present, the expiration time for the log is checked (step 604 ). Next, a determination is made as to whether the log has expired (step 606 ). This determination may be made by checking a timer or time stamp assigned to the log. If the log has not expired, the log is returned to the partition (step 608 ) and the process terminates thereafter. In these examples, this log is returned or sent to a partition by copying the log to a memory location and using a partition number specified by the caller of this function.
- step 606 if a log has expired, a delete log function is called (step 610 ) and the process terminates thereafter.
- step 610 if the log is not present, the process reports no logs are present (step 612 ) and the process terminates thereafter.
- FIG. 7 a flowchart of a process used for copying logs into a partition log buffer is depicted in accordance with a preferred embodiment of the present invention.
- the process illustrated in FIG. 7 may be implemented in a partition management firmware component, such as partition management firmware 300 in FIG. 3 .
- This process is a more detailed description of an add log function called in step 510 in FIG. 5 .
- the process begins by copying the error log from the non-volatile storage into the partition log buffer (step 700 ).
- the current time is obtained (step 702 ).
- Two hours are added to the current time (step 704 ).
- This new time forms an expiration time stamp and is stored in association with the log (step 706 ) with the process terminating thereafter. This time stamp is used to determine whether a log has expired.
- FIG. 8 a flowchart of a process used for deleting a log in a partition log buffer is depicted in accordance with a preferred embodiment of the present invention.
- the process illustrated in FIG. 8 may be implemented in a partition management firmware component, such as partition management firmware 300 in FIG. 3 .
- the process illustrated in this figure is a more detailed description of a delete log function called in step 610 in FIG. 6 .
- the process begins by erasing a log from the partition log buffer (step 800 ).
- the expiration time associated with the log also is erased (step 802 ) and the process terminates thereafter.
- the present invention provides an improved method, apparatus, and computer instructions for managing error logs in a logical partitioned data processing system.
- the mechanism of the present invention places error logs in a separate location from those used by different subsystems to report errors.
- the error logs placed into separate locations are associated with expiration times such that these logs will be deleted from the buffer after some selected period of time has passed. In this manner, partitions that are booted at a later time from when the data processing system is started will not receive outdated error logs.
Abstract
Description
Claims (32)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/339,770 US7055071B2 (en) | 2003-01-09 | 2003-01-09 | Method and apparatus for reporting error logs in a logical environment |
JP2003421702A JP3943538B2 (en) | 2003-01-09 | 2003-12-18 | Method for managing error logs in a logically partitioned data processing system |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/339,770 US7055071B2 (en) | 2003-01-09 | 2003-01-09 | Method and apparatus for reporting error logs in a logical environment |
Publications (2)
Publication Number | Publication Date |
---|---|
US20040139368A1 US20040139368A1 (en) | 2004-07-15 |
US7055071B2 true US7055071B2 (en) | 2006-05-30 |
Family
ID=32711170
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US10/339,770 Active 2024-07-29 US7055071B2 (en) | 2003-01-09 | 2003-01-09 | Method and apparatus for reporting error logs in a logical environment |
Country Status (2)
Country | Link |
---|---|
US (1) | US7055071B2 (en) |
JP (1) | JP3943538B2 (en) |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20080086515A1 (en) * | 2006-10-06 | 2008-04-10 | International Business Machines Corporation | Method and System for a Soft Error Collection of Trace Files |
US20090141948A1 (en) * | 2005-07-22 | 2009-06-04 | Sharp Kabushiki Kaisha | Portable information terminal device |
US20110154091A1 (en) * | 2009-12-17 | 2011-06-23 | Walton Andrew C | Error log consolidation |
US20130339801A1 (en) * | 2012-06-14 | 2013-12-19 | Sap Ag | System and method for log and trace diagnostics and analytics |
US11556408B2 (en) | 2020-04-14 | 2023-01-17 | Paypal, Inc. | Classifying errors in a failure log |
Families Citing this family (43)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7673070B1 (en) * | 2003-03-17 | 2010-03-02 | Network Equipment Technologies, Inc. | Method of sharing telecommunications node equipment facilities |
US7707189B2 (en) * | 2004-10-05 | 2010-04-27 | Microsoft Corporation | Log management system and method |
US7321987B2 (en) * | 2005-01-04 | 2008-01-22 | International Business Machines Corporation | Error monitoring of partitions in a computer system using partition status indicators |
US20070077200A1 (en) * | 2005-09-30 | 2007-04-05 | Baker Clark R | Method and system for controlled maintenance of hypoxia for therapeutic or diagnostic purposes |
US20070083792A1 (en) * | 2005-10-11 | 2007-04-12 | Mcdermott Andrew | System and method for error detection and reporting |
US20070088987A1 (en) * | 2005-10-13 | 2007-04-19 | Hiroshi Kimizuka | System and method for handling information transfer errors between devices |
EP1860557A1 (en) * | 2006-05-24 | 2007-11-28 | Robert Bosch Gmbh | Method of handling fault codes in a memory |
WO2009047759A2 (en) * | 2007-10-11 | 2009-04-16 | N-Trig Ltd. | Method for palm touch identification in multi-touch digitizing systems |
US9135037B1 (en) | 2011-01-13 | 2015-09-15 | Google Inc. | Virtual network protocol |
US8874888B1 (en) | 2011-01-13 | 2014-10-28 | Google Inc. | Managed boot in a cloud system |
US8533343B1 (en) | 2011-01-13 | 2013-09-10 | Google Inc. | Virtual network pairs |
US9419921B1 (en) | 2011-01-13 | 2016-08-16 | Google Inc. | Network address translation for virtual machines |
US8862743B1 (en) | 2011-01-13 | 2014-10-14 | Google Inc. | Resource management |
US9619662B1 (en) | 2011-01-13 | 2017-04-11 | Google Inc. | Virtual network pairs |
US8745329B2 (en) | 2011-01-20 | 2014-06-03 | Google Inc. | Storing data across a plurality of storage nodes |
US9760216B2 (en) * | 2011-02-15 | 2017-09-12 | Microsoft Technology Licensing, Llc | Tracking input to a multi-touch digitizer system |
US8812586B1 (en) | 2011-02-15 | 2014-08-19 | Google Inc. | Correlating status information generated in a computer network |
WO2012114343A1 (en) * | 2011-02-24 | 2012-08-30 | Hewlett-Packard Development Company, L.P. | System and method for error reporting in a network |
US9237087B1 (en) | 2011-03-16 | 2016-01-12 | Google Inc. | Virtual machine name resolution |
US9176759B1 (en) | 2011-03-16 | 2015-11-03 | Google Inc. | Monitoring and automatically managing applications |
US8261295B1 (en) | 2011-03-16 | 2012-09-04 | Google Inc. | High-level language for specifying configurations of cloud-based deployments |
US8533796B1 (en) | 2011-03-16 | 2013-09-10 | Google Inc. | Providing application programs with access to secured resources |
US9063818B1 (en) | 2011-03-16 | 2015-06-23 | Google Inc. | Automated software updating based on prior activity |
US10228959B1 (en) | 2011-06-02 | 2019-03-12 | Google Llc | Virtual network for virtual machine communication and migration |
US9075979B1 (en) | 2011-08-11 | 2015-07-07 | Google Inc. | Authentication based on proximity to mobile device |
US8966198B1 (en) | 2011-09-01 | 2015-02-24 | Google Inc. | Providing snapshots of virtual storage devices |
US9069616B2 (en) | 2011-09-23 | 2015-06-30 | Google Inc. | Bandwidth throttling of virtual disks |
US8276140B1 (en) | 2011-11-14 | 2012-09-25 | Google Inc. | Adjustable virtual network performance |
US8958293B1 (en) | 2011-12-06 | 2015-02-17 | Google Inc. | Transparent load-balancing for cloud computing services |
US9178698B1 (en) | 2011-12-21 | 2015-11-03 | Google Inc. | Dynamic key management |
US8800009B1 (en) | 2011-12-30 | 2014-08-05 | Google Inc. | Virtual machine service access |
US8983860B1 (en) | 2012-01-30 | 2015-03-17 | Google Inc. | Advertising auction system |
US9672052B1 (en) | 2012-02-16 | 2017-06-06 | Google Inc. | Secure inter-process communication |
US8996887B2 (en) | 2012-02-24 | 2015-03-31 | Google Inc. | Log structured volume encryption for virtual machines |
US8677449B1 (en) | 2012-03-19 | 2014-03-18 | Google Inc. | Exposing data to virtual machines |
US9069806B2 (en) | 2012-03-27 | 2015-06-30 | Google Inc. | Virtual block devices |
US8909939B1 (en) | 2012-04-04 | 2014-12-09 | Google Inc. | Distribution of cryptographic host keys in a cloud computing environment |
JP2013222435A (en) * | 2012-04-19 | 2013-10-28 | Toshiba Corp | Semiconductor storage device and method of controlling the same |
US9430255B1 (en) | 2013-03-15 | 2016-08-30 | Google Inc. | Updating virtual machine generated metadata to a distribution service for sharing and backup |
CN105074653B (en) | 2013-03-28 | 2018-11-23 | 慧与发展有限责任合伙企业 | Make to calculate blade apparatus and extends the memory of blade apparatus for being used by operating system |
EP2979171A4 (en) | 2013-03-28 | 2016-11-23 | Hewlett Packard Entpr Dev Lp | Identifying memory of a blade device for use by an operating system of a partition including the blade device |
WO2014158161A1 (en) * | 2013-03-28 | 2014-10-02 | Hewlett-Packard Development Company, L.P. | Error coordination message for a blade device having a logical processor in another system firmware domain |
US9529661B1 (en) * | 2015-06-18 | 2016-12-27 | Rockwell Collins, Inc. | Optimal multi-core health monitor architecture |
Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4633467A (en) | 1984-07-26 | 1986-12-30 | At&T Bell Laboratories | Computer system fault recovery based on historical analysis |
US4780809A (en) | 1986-08-08 | 1988-10-25 | Amdahl Corporation | Apparatus for storing data with deferred uncorrectable error reporting |
US5128885A (en) | 1990-02-23 | 1992-07-07 | International Business Machines Corporation | Method for automatic generation of document history log exception reports in a data processing system |
JPH04242842A (en) * | 1990-12-29 | 1992-08-31 | Nec Corp | Data base buffer controller |
JPH07262054A (en) | 1994-03-17 | 1995-10-13 | Hitachi Ltd | Failure information management system |
US5553285A (en) * | 1988-04-22 | 1996-09-03 | Amdahl Corporation | File system for a plurality of storage classes |
US5590056A (en) | 1994-01-12 | 1996-12-31 | Isogon Corporation | Method and apparatus for computer program usage monitoring |
US5592638A (en) | 1992-07-14 | 1997-01-07 | Hitachi, Ltd. | Storage region assignment method in a logically partitioned environment |
US5790779A (en) | 1995-03-10 | 1998-08-04 | Microsoft Corporation | Method and system for consolidating related error reports in a computer system |
US5801948A (en) * | 1996-08-22 | 1998-09-01 | Dickey-John Corporation | Universal control system with alarm history tracking for mobile material distribution apparatus |
US5822513A (en) | 1996-09-27 | 1998-10-13 | Emc Corporation | Method and apparatus for detecting stale write data |
US5847972A (en) | 1993-09-24 | 1998-12-08 | Eick; Stephen Gregory | Method and apparatus for graphically analzying a log-file |
US5857190A (en) | 1996-06-27 | 1999-01-05 | Microsoft Corporation | Event logging system and method for logging events in a network system |
US5892917A (en) | 1995-09-27 | 1999-04-06 | Microsoft Corporation | System for log record and log expansion with inserted log records representing object request for specified object corresponding to cached object copies |
US5892898A (en) | 1996-10-04 | 1999-04-06 | Honeywell, Inc. | Error management system for supporting the identification and logging of error messages |
JP2001325165A (en) | 2000-05-16 | 2001-11-22 | Hitachi Electronics Service Co Ltd | Hardware fault monitoring system, fault monitoring computer, computer for monitoring center and recording medium |
US6493837B1 (en) * | 1999-07-16 | 2002-12-10 | Microsoft Corporation | Using log buffers to trace an event in a computer system |
US6823482B2 (en) * | 2001-03-08 | 2004-11-23 | International Business Machines Corporation | System and method for reporting platform errors in partitioned systems |
-
2003
- 2003-01-09 US US10/339,770 patent/US7055071B2/en active Active
- 2003-12-18 JP JP2003421702A patent/JP3943538B2/en not_active Expired - Lifetime
Patent Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4633467A (en) | 1984-07-26 | 1986-12-30 | At&T Bell Laboratories | Computer system fault recovery based on historical analysis |
US4780809A (en) | 1986-08-08 | 1988-10-25 | Amdahl Corporation | Apparatus for storing data with deferred uncorrectable error reporting |
US5553285A (en) * | 1988-04-22 | 1996-09-03 | Amdahl Corporation | File system for a plurality of storage classes |
US5128885A (en) | 1990-02-23 | 1992-07-07 | International Business Machines Corporation | Method for automatic generation of document history log exception reports in a data processing system |
JPH04242842A (en) * | 1990-12-29 | 1992-08-31 | Nec Corp | Data base buffer controller |
US5592638A (en) | 1992-07-14 | 1997-01-07 | Hitachi, Ltd. | Storage region assignment method in a logically partitioned environment |
US5847972A (en) | 1993-09-24 | 1998-12-08 | Eick; Stephen Gregory | Method and apparatus for graphically analzying a log-file |
US5590056A (en) | 1994-01-12 | 1996-12-31 | Isogon Corporation | Method and apparatus for computer program usage monitoring |
JPH07262054A (en) | 1994-03-17 | 1995-10-13 | Hitachi Ltd | Failure information management system |
US5790779A (en) | 1995-03-10 | 1998-08-04 | Microsoft Corporation | Method and system for consolidating related error reports in a computer system |
US5892917A (en) | 1995-09-27 | 1999-04-06 | Microsoft Corporation | System for log record and log expansion with inserted log records representing object request for specified object corresponding to cached object copies |
US5857190A (en) | 1996-06-27 | 1999-01-05 | Microsoft Corporation | Event logging system and method for logging events in a network system |
US5801948A (en) * | 1996-08-22 | 1998-09-01 | Dickey-John Corporation | Universal control system with alarm history tracking for mobile material distribution apparatus |
US5822513A (en) | 1996-09-27 | 1998-10-13 | Emc Corporation | Method and apparatus for detecting stale write data |
US5892898A (en) | 1996-10-04 | 1999-04-06 | Honeywell, Inc. | Error management system for supporting the identification and logging of error messages |
US6493837B1 (en) * | 1999-07-16 | 2002-12-10 | Microsoft Corporation | Using log buffers to trace an event in a computer system |
JP2001325165A (en) | 2000-05-16 | 2001-11-22 | Hitachi Electronics Service Co Ltd | Hardware fault monitoring system, fault monitoring computer, computer for monitoring center and recording medium |
US6823482B2 (en) * | 2001-03-08 | 2004-11-23 | International Business Machines Corporation | System and method for reporting platform errors in partitioned systems |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090141948A1 (en) * | 2005-07-22 | 2009-06-04 | Sharp Kabushiki Kaisha | Portable information terminal device |
US8224128B2 (en) * | 2005-07-22 | 2012-07-17 | Sharp Kabushiki Kaisha | Portable information terminal device |
US20080086515A1 (en) * | 2006-10-06 | 2008-04-10 | International Business Machines Corporation | Method and System for a Soft Error Collection of Trace Files |
US20110154091A1 (en) * | 2009-12-17 | 2011-06-23 | Walton Andrew C | Error log consolidation |
US8122290B2 (en) * | 2009-12-17 | 2012-02-21 | Hewlett-Packard Development Company, L.P. | Error log consolidation |
US20130339801A1 (en) * | 2012-06-14 | 2013-12-19 | Sap Ag | System and method for log and trace diagnostics and analytics |
US11556408B2 (en) | 2020-04-14 | 2023-01-17 | Paypal, Inc. | Classifying errors in a failure log |
Also Published As
Publication number | Publication date |
---|---|
JP2004220582A (en) | 2004-08-05 |
US20040139368A1 (en) | 2004-07-15 |
JP3943538B2 (en) | 2007-07-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US7055071B2 (en) | Method and apparatus for reporting error logs in a logical environment | |
US7930594B2 (en) | Apparatus to preserve trace data | |
US7139940B2 (en) | Method and apparatus for reporting global errors on heterogeneous partitioned systems | |
US6842870B2 (en) | Method and apparatus for filtering error logs in a logically partitioned data processing system | |
US8352940B2 (en) | Virtual cluster proxy to virtual I/O server manager interface | |
US7103808B2 (en) | Apparatus for reporting and isolating errors below a host bridge | |
US6920587B2 (en) | Handling multiple operating system capabilities in a logical partition data processing system | |
US6910160B2 (en) | System, method, and computer program product for preserving trace data after partition crash in logically partitioned systems | |
US7257734B2 (en) | Method and apparatus for managing processors in a multi-processor data processing system | |
US6971002B2 (en) | Method, system, and product for booting a partition using one of multiple, different firmware images without rebooting other partitions | |
US7877643B2 (en) | Method, system, and product for providing extended error handling capability in host bridges | |
JP4366336B2 (en) | Method for managing trace data in logical partition data processing system, logical partition data processing system for managing trace data, computer program for causing computer to manage trace data, logical partition data Processing system | |
US6976191B2 (en) | Method and apparatus for analyzing hardware errors in a logical partitioned data processing system | |
US20030212883A1 (en) | Method and apparatus for dynamically managing input/output slots in a logical partitioned data processing system | |
US8024544B2 (en) | Free resource error/event log for autonomic data processing system | |
US6898731B2 (en) | System, method, and computer program product for preventing machine crashes due to hard errors in logically partitioned systems | |
US6934888B2 (en) | Method and apparatus for enhancing input/output error analysis in hardware sub-systems | |
US7260752B2 (en) | Method and apparatus for responding to critical abstracted platform events in a data processing system | |
US7370240B2 (en) | Method and apparatus for preserving trace data in a logical partitioned data processing system | |
US7302690B2 (en) | Method and apparatus for transparently sharing an exception vector between firmware and an operating system | |
US7275185B2 (en) | Method and apparatus for device error log persistence in a logical partitioned data processing system | |
US20030191978A1 (en) | Multiple fault location in a series of devices |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: INTERNATIONAL BUSINESS MACHINES CORPORATION, NEW YFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:AUSTEN, CHRISTOPHER HARRY;KITAMORN, ALONGKORN;OLIVER, DOUGLAS WAYNE;AND OTHERS;REEL/FRAME:013654/0805;SIGNING DATES FROM 20021007 TO 20021009 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTERNATIONAL BUSINESS MACHINES CORPORATION;REEL/FRAME:027463/0594Effective date: 20111228 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044127/0735Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553)Year of fee payment: 12 |