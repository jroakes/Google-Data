US20130117252A1 - Large-scale real-time fetch service - Google Patents
Large-scale real-time fetch service Download PDFInfo
- Publication number
- US20130117252A1 US20130117252A1 US13/644,297 US201213644297A US2013117252A1 US 20130117252 A1 US20130117252 A1 US 20130117252A1 US 201213644297 A US201213644297 A US 201213644297A US 2013117252 A1 US2013117252 A1 US 2013117252A1
- Authority
- US
- United States
- Prior art keywords
- content
- request
- fetch
- storage device
- server
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
- 238000000034 method Methods 0.000 claims abstract description 39
- 230000005055 memory storage Effects 0.000 claims description 48
- 230000004044 response Effects 0.000 claims description 34
- 230000009193 crawling Effects 0.000 claims description 15
- 230000008569 process Effects 0.000 claims description 7
- 238000012545 processing Methods 0.000 claims description 2
- 238000009877 rendering Methods 0.000 description 9
- 238000004590 computer program Methods 0.000 description 8
- 101150060512 SPATA6 gene Proteins 0.000 description 4
- 238000004891 communication Methods 0.000 description 4
- 238000010586 diagram Methods 0.000 description 4
- 230000007246 mechanism Effects 0.000 description 3
- 230000000007 visual effect Effects 0.000 description 3
- 230000003993 interaction Effects 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 238000009825 accumulation Methods 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 230000001934 delay Effects 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 230000006870 function Effects 0.000 description 1
- 239000011521 glass Substances 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 230000002085 persistent effect Effects 0.000 description 1
- 238000012802 pre-warming Methods 0.000 description 1
- 230000000135 prohibitive effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 238000006467 substitution reaction Methods 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000001052 transient effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
Definitions
- This description relates to searching document repositories and, more specifically, to methods and systems for efficiently retrieving embedded objects for later rendering from a large document repository, such as the Internet.
- the world-wide-web is a rich source of information.
- Each document has a specific address, known as a uniform resource locator (URL).
- URL uniform resource locator
- Many of these documents are dynamically created, e.g., the home page of the New York Times, and have links to embedded content such as images, style sheets, and videos.
- a computer-implemented method for fetching content of an object embedded in a document includes identifying a fetch server from a plurality of fetch servers that is associated with a host of the document as part of a batch-crawl of a corpus of documents and sending a request to the fetch server for the content of the embedded object.
- the method may also include receiving the request at the fetch server on a request thread, determining, at the fetch server, whether a first memory storage device associated with the fetch server contains the content of the object, and returning the content from the first memory storage device when it is determined that the first storage device contains the content.
- the method may also include switching the request from the request thread to a worker thread, determining whether a second memory storage device contains the content of the object, wherein the second memory storage device has a slower access time that the first memory storage device, and returning the content from the second memory storage device when it is determined that the second storage device contains the content.
- the method may include scheduling a request with the batch crawler to have the content retrieved from a server hosting the embedded object.
- the method may also include determining whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled, inserting the request to have the content retrieved into the queue when it is determined that the queue has room, and returning a failure response when it is determined that the queue does not have room.
- the method may include receiving a second request for the content of the embedded object, the second request being a repeat of the first request. The second request may be sent to another fetch server from the plurality of fetch servers.
- scheduling the request may include determining whether a request to crawl the content has already been scheduled and returning a failure response when the request has already been scheduled.
- the method can include receiving a dummy fetch request for the content of the object prior to receiving the request to fetch the content.
- the method may also include determining whether a timestamp associated with the content is too old and, returning the content from the first memory device may include returning the content when it is determined that the timestamp not too old.
- the fetch server may include at least one processor, a first memory storage device, a second memory storage device that has a slower access time than the first memory storage device, and instructions embodied on a third storage device, the instructions causing the fetch server to perform operations.
- the operations may include receiving, on a request thread, a request to fetch content of an object embedded in a document, determining whether the first memory storage device contains the content of the object, and returning the content from the first memory storage device when it is determined that the first storage device contains the content.
- the operations may also include switching the request to a worker thread when the first storage device does not contain the content, determining whether the second memory storage device contains the content of the object, and returning the content from the second memory storage device when it is determined that the second storage device contains the content.
- the operations can also include scheduling a request to have the content retrieved from a server hosting the embedded object as part of a batch crawl when the second storage devices does not contain the content.
- the operations may also include determining whether a worker thread is available, performing the switching when a worker thread is available, and returning a response indicating that the request could not be processed when no worker thread is available.
- the operation of scheduling the request may include determining whether a request to crawl the content has already been scheduled; and returning a failure response when the request has already been scheduled.
- the operations may also include determining whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled, inserting the request to have the content retrieved into the queue when it is determined that the queue has room, and returning a failure response when it is determined that the queue does not have room.
- the system may include one or more fetch servers configured to process batch fetch requests, each fetch server being associated with a host of the document corpus. Each fetch server ma include a first memory storage device, and a second memory storage device that has a slower access time than the first memory storage device.
- the system may also include a fetch requestor configured to determine a particular fetch server of the one or more fetch servers, the particular fetch server being associated with a host of a particular document, and send a request to the particular fetch server for content of an object embedded in the particular document.
- the system may also include a web crawling engine, configured to schedule batch crawls of a document corpus to retrieve object contents from the corpus.
- the one or more fetch servers may be configured to receive a request for a particular embedded object, determine whether the first memory storage device contains the content of the particular embedded object and return the content from the first memory storage device when it is determined that the first storage device contains the content.
- the one or more fetch servers may also be configured to determine whether the second memory storage device contains the content of the particular embedded object and return the content from the second memory storage device when it is determined that the second storage device contains the content.
- the one or more fetch servers may be configured to send a request to the web crawling engine to retrieve the object content from the corpus.
- processing the request may include sending the object content to the fetch requestor, the fetch requestor being configured to store the object content in a memory.
- the fetch requestor may also be configured to render the document from the object content returned by the fetch server.
- the fetch requestor may be configured to send a dummy fetch request for the embedded object prior to requesting the content of the embedded object and, the one or more fetch servers may be configured to skip sending the object content to the fetch requestor for the dummy request.
- the one or more fetch servers may be further configured to determine whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled, insert the request to have the content retrieved into the queue when it is determined that the queue has room, and return a failure response to the fetch requestor when it is determined that the queue does not have room.
- the one or more fetch servers are further configured with a request thread and a working thread, wherein the request thread determines whether the first memory storage device contains the content of the object and the working thread determines whether the second memory storage deice contains the content of the object and sends the request to the web crawling engine.
- the fetch servers may be configured to switch the request from the request thread to the working thread when it is determined that the first memory device does not contain the content.
- Another aspect of the disclosure can be a tangible computer-readable storage device having recorded and embodied thereon instructions that, when executed by one or more processors of a computer system, cause the computer system to perform any of the methods or operations described herein.
- FIG. 1 is a block diagram of a document having embedded objects.
- FIG. 2 is a block diagram of a system for fetching embedded objects from document content.
- FIG. 3 is a flowchart illustrating a method by which a fetch server in a web page storage system can obtain target embedded objects.
- FIG. 4 is a flowchart illustrating a method by which a fetch server in a web page storage system can schedule a web crawl for a target embedded object.
- a rendering system To completely render a received document, a rendering system first obtains the content of all of the external resources that may be embedded in the web page.
- Such resources may include, but are not limited to, external images, JavaScript code, and style sheets.
- the same external resource is embedded in many different web pages.
- the New York Times logo may be located on many web pages available from the New York Times server.
- JavaScript code and/or style sheets may be embedded on each web page hosted by the New York Times server. Whenever any one of these web pages is rendered, the image, JavaScript, and style sheet objects are downloaded from the New York Times server.
- a render server of a web page storage process is designed to render and store a large number of documents at a time, and to continually render a large number of documents at a time in order to build a large index or repository of documents, such as web pages. If such a rendering engine attempted to render thousands or tens of thousands of web pages that embed the same external resource at the same time or close together in time, the server on which the external resource resides would be flooded with near simultaneous requests for the same object. To avoid such problems, the rendering engine of a web page storage process should ideally crawl each embedded resource exactly once, regardless of how many web pages embed the resource.
- a web page storage service can render web content with embedded objects at a large scale using a plurality of render server tasks.
- a render server task needs the contents of the document itself, e.g., http://www.cnn.com/, as well as the contents of the embedded objects, e.g., css, JavaScript, and images.
- the render servers may not directly crawl these URLs on-demand in order to honor robots.txt, host load limits, transient errors, duplicates, etc.
- an embedded object processor may be used to crawl the URLs efficiently and pass the results back to the requesting render server.
- iterative calls may be needed to obtain the various levels of embedded objects.
- a batch crawl mechanism may be employed to address these concerns. However, a batch crawl may incur long latency times, prohibiting the timely accumulation of web page content data and limiting the number of web pages that the system can render and store.
- Disclosed embodiments provide an improved distributed fetch service that provides efficient, near real-time access to URL contents.
- the service may cache crawled contents in main memory, such as RAM, cache, or flash memory, as well as in more persistent memory structures, such as disks.
- main memory such as RAM, cache, or flash memory
- the copies in main memory may become stale after a predetermined amount of time, but until they become stale, copies of embedded objects can be quickly fetched from the main memory store rather from the slower disk store.
- the use of such a system provides lower latency and greater efficiency in rendering snapshots of a large number of web pages, for example 300 million per day.
- FIG. 1 is a block diagram of a document, such as a web page, having embedded objects.
- a web page 100 can contain a plurality of embedded objects. These embedded objects can include, but are not limited to, other web pages or documents 110 , style sheets 120 , image files 130 , links to additional URLs 140 , and JavaScript code 150 . Additional and different types of embedded objects are, of course, possible.
- each of the objects embedded in web page 100 may also embed other objects.
- a web page 110 that is embedded in web page 100 may embed other web pages, image files, style sheets, and the like.
- a style sheet 120 embedded in web page 100 may embed other objects such as a background image file.
- each of the objects embedded in web page 110 or style sheet 120 may themselves embed even more objects.
- a rendering engine or an embedded object processor must request each of the embedded objects 110 - 150 , or primary embedded objects, all of the objects that are embedded in the primary embedded objects 110 - 150 , or secondary embedded objects, all of the objects that are embedded in the secondary embedded objects, or tertiary embedded objects, and so on.
- a web storage system may use a batch crawler to schedule crawls to reduce the number of multiple fetches of the same content.
- a web page fetching and storage system such as that disclosed in FIG. 2 , can be employed.
- FIG. 2 is a block diagram of a system for fetching embedded objects from web page content.
- the system includes one or more web crawling engines 210 .
- Web crawling engine 210 may be a batch crawler with an associated host queue (not shown). Web crawling engine 210 may have a queue for each host.
- the system may also include one or more fetch servers 220 with associated databases 215 and 225 , and a fetch requestor 230 with associated database 235 .
- Web-crawling engine 210 , fetch server 220 , and fetch requestor 230 may work together to safely and efficiently capture a large corpus of documents, such as web pages that can be found on the world wide web.
- Fetch server 220 offers a single service that may receive a list of embedded links (fetch targets) for a document from the fetch requestor 230 and respond with the contents of the embedded links.
- Fetch Server 220 may receive the contents of the embedded links from disk database 225 , cache 215 , or web crawling engine 210 .
- Cache 215 may include a sub-set of the information stored in disk database 225 .
- Information stored in cache 215 may become old or stale sooner than the information in disk database 225 . In other words, document contents may have a shorter life in cache 215 than in database 225 .
- Each fetch server 220 may service one or more hosts.
- Fetch requestor 230 may use a fetch client application programming interface to assist in choosing which fetch server 220 to send a request to.
- a fetch client of fetch requestor 230 may use an affinity mechanism to identify a particular fetch server 220 that is most likely to have the requested URLs in its cache, e.g., the fetch server 220 that owns the host of the main document. Fetch requestor 230 may then direct a request to that particular fetch server 220 .
- the affinity mechanism may enable the web page storage system to avoid having multiple queues for any host by using separate fetch service tasks for each host.
- the web storage system may include several fetch servers 220 , with each fetch server 220 associated with a host.
- the fetch requestor 230 makes a fetch request
- the fetch client may enable it to choose the fetch server 220 that “owns” that host. This allows the system to avoid sending requests directed to one host from multiple fetch servers 220 .
- the fetch requestor 230 may include a render server or an embedded object processor, may send a request to the fetch server 220 for known embedded links of a document, such as a web page. Once the fetch server 220 returns the content of the requested links, the fetch requestor 230 may discover a new set of embedded links in the returned content. Accordingly, the fetch requestor 230 may send a new fetch request for the newly discovered links. This loop terminates when the fetch requestor fails to discover new links in a peel.
- the fetch requestor 230 may pre-warm the cache 215 with the contents of currently known embedded links by making a dummy request for the links.
- the fetch server 220 may not send back a response for a dummy request, but will fetch the links from database 225 into cache 215 . This enables a subsequent request for these links by the fetch requestor 230 to be serviced by the fetch server 220 very quickly.
- Such pre-warming of the cache may be especially helpful when the fetch requestor 230 is a render server where data structures use more memory than the contents of embedded links and pausing rendering while waiting for a response from a fetch server affects the use of RAM.
- FIG. 3 is a flowchart illustrating a method by which a fetch server in a web page storage system can efficiently retrieve web page content, including embedded objects.
- a fetch server 220 receives a request for a fetch service task from a fetch requestor 230 ( 305 ).
- Fetch requestor 230 may be a render server or an embedded object processor and the fetch service task may be a request to fetch one or more embedded objects from a specific URL.
- the fetch server 220 may then check to see if the fetch target is located in cache 215 .
- Cache 215 may be RAM or flash storage, so retrieval occurs more quickly than with other types of storage.
- Cache 215 may be populated with embedded content that has recently been retrieved by web crawling engine 210 .
- the fetch requestor 230 may pre-warm the cache 215 to increase the number of requested fetch targets in the cache.
- the time that the embedded content was retrieved and last accessed may be stored in cache 215 to help determine staleness. If the fetch target is located in the cache and is not stale (i.e., the time that embedded content was last accessed and/or last retrieved is not too old) ( 310 , YES), then the fetch server 220 may generate a successful response and return the content associated with the fetch target ( 320 ).
- fetch server 220 may look in a disk database, for example disk database 225 , for the fetch target. If the fetch target is in the disk database and is not stale ( 315 , YES), then fetch server 220 may generate a successful response for the fetch target by, for example, returning the content associated with the target from the disk database ( 320 ). In one implementation, when the fetch server 220 locates a fetch target in the disk database, or in the cache, it may update a time last accessed associated with the content of the target.
- fetch server 220 may make a web crawl request to web crawling engine 210 ( 325 ).
- web crawling engine 210 may be a batch crawler that schedules crawl requests for specific content.
- the web crawling engine 210 may be a web crawler that processes the request as it is received.
- Fetch server 220 may receive the results of the web crawl request and, when the store the results in cache 215 and/or disk database 225 ( 330 ).
- a successful request may include a response that indicates the link could not be resolved. In such circumstances, a successful request indicates only that the crawl status of a link is known, not that the content of link has been successfully obtained.
- storing the results in cache 215 and/or disk database 225 may include setting a timestamp.
- fetch server 220 may return the result of the web crawl request, whether it is successful or not successful ( 335 ) to fetch requestor 230 .
- an unsuccessful fetch request may indicate that the crawl has not yet been completed. If fetch server 220 returns an unsuccessful response, in some embodiments fetch requestor 230 may attempt the fetch again at a later time by repeating the request. If fetch requestor 230 receives the content of the object, fetch requestor 230 may store the contents in database 235 so that the document can be rendered at a later time from database 235 .
- the fetch server 220 may send a response back for each fetch target it receives, or it may receive a request having several embedded links (fetch targets) and send a response to fetch requestor 230 only once a response is determined for each embedded link. For a request to fetch server 220 containing multiple embedded links, fetch server 220 may perform method 300 for each link before returning a response.
- the fetch server 220 may maintain two thread pools to do its work: a request thread pool and a worker thread pool.
- the threads in a request thread pool may manage the request, containing multiple URLs, as a whole.
- the threads in the request thread pool may also look for the content of a specific URL in cache 215 .
- fetch server 220 may not delegate these requests to the worker thread to avoid the overhead of a thread context switch.
- the cache 215 may be sharded or divided into multiple caches.
- the second thread pool may include a worker thread pool.
- the request thread pool may switch the request to the worker thread pool when a document is not found in the cache 215 .
- the threads in a worker thread pool may look for the contents of a URL in the disk database 225 or from a web crawl.
- Web crawl requests may be subject to a timeout, to avoid holding up the request from fetch requestor 230 indefinitely.
- a disk database request may not timeout because such requests have a much smaller latency time and prematurely timing out may result in an unnecessary web crawler request.
- the two thread-pool design allows fetch server 220 to more easily determine when to push back on client requests due to a lack of thread resources.
- the fetch requestor 230 may include a fetch client.
- the fetch client may perform two important duties. The first is routing fetch requests to the fetch server 220 that “owns” the host for the document.
- the fetch client may accomplish this by using an affinity based load balancing, using a hash based on the host of the document, such as a web page, having the embedded objects.
- routing may be based on domain instead of host. For large domains, the fetch client may smear the hash a little to spread around the load into more than one fetch server 220 .
- the second duty performed by the fetch client may include resending a fetch request in case of push back from fetch server 220 .
- Fetch server 220 may push back when it is heavily loaded and doesn't have any available threads in the request thread pool. The push back can be just a special reply status.
- the fetch client may then retry the fetch request with the next fetch server in the hash sequence of that document i.e., the hash obtained by appending the retry number to the URL string of the document. After a few retries, fetch client may add a delay or sleep between retries.
- FIG. 4 is a flowchart illustrating a method by which a fetch server 220 in a web page storage system can schedule a web crawl for a target embedded object.
- Fetch server 220 may use method 400 when a fetch target is not found in cache 215 or database 225 , as shown in step 325 of FIG. 3 .
- the fetch server 220 may check the batch crawl scheduler to determine whether the fetch target is already scheduled for a crawl ( 405 ). If a crawl of the object has already been scheduled ( 410 , YES), then a failure response is returned. The failure response indicates that the document cannot be rendered yet because the fetch target has not yet been retrieved. This is not a permanent failure status because the target is scheduled for batch crawl and, after it is successfully crawled, the web page storage system can attempt to fetch the target again.
- the fetch server 220 may determine whether there is room in the crawler queue for this target. In some embodiments such queues are per host, so the queue for load-bound hosts may be full. In some embodiments the queues may be maintained in the fetch server 220 itself. If no room is available ( 420 , NO), then fetch server 220 returns a failure response ( 425 ). As before, this response means only that the contents of the target have not yet been fetched and the fetch requestor 230 should repeat the request. Fetch server 220 may also schedule a batch crawl of the fetch target. This may include scheduling the crawl on another host or waiting until the queue has room. If, however, the queue has room ( 420 , YES), then fetch server 220 inserts the request into the queue and waits for a response ( 430 ).
- fetch server 220 determines whether the crawler 210 succeeded in reaching the web host for the target. If the web host was reached ( 435 , YES), then the target has been successfully fetched. Note that even if an error was encountered and the content of the target could not be crawled, this is still considered a success. Success means that the crawl status of the fetch target has been determined, not that the content of the target was successfully located. If the crawler 210 did not successfully reach the host ( 435 , NO), then fetch server 220 schedules a batch crawl and returns a failure response. As before, this indicates that the web storage system will reattempt to resolve the target.
- Process 400 then ends, with fetch server 220 supplying either a failure or a success response to fetch requestor 230 .
- a success response may include sending the contents of the target object to fetch requestor 230 .
- the contents may include an indication that the object is not available.
- Fetch requestor 230 may store the returned contents in database 235 .
- the data stored in web page storage database 235 may be used to generate a preview of a web page, for example, as part of a search result.
- a preview system may provide a graphic overview of a search result and may highlight the most relevant section of the preview image. This may enable a user viewing the preview to more easily locate the right page.
- a magnifying glass or some other icon may appear next to the title of a search result, indicating that a preview is available for the search result. Clicking on the icon may cause the system to read the data from storage database 235 and generate a visual overview of the web page.
- the visual overview may have search terms identified, for example with highlighting or different colored text, so that relevant content is quickly located.
- previews help a user determine if the search result contains a chart, map, picture, or some other embedded content. For users desiring to locate a previously visited web page, previews assist the user in determining whether the search result “looks familiar.” A preview may also assist users looking for “official websites” by displaying the trademarks and logos associated with each page.
- the methods and apparatus described herein may be implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in combinations of them. They may be implemented as a computer program product, i.e., as a computer program tangibly embodied in a machine-readable storage device for execution by, or to control the operation of, a processor, a computer, or multiple computers. Method steps may be performed by one or more programmable processors executing a computer program to perform functions by operating on input data and generating output. Method steps also may be performed by, and an apparatus may be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The method steps may be performed in the order shown or in alternative orders.
- FPGA field programmable gate array
- ASIC application-specific integrated circuit
- a computer program such as the computer program(s) described above, can be written in any form of programming language, including compiled or interpreted languages, and can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, plug-in or other unit suitable for use in a computing environment.
- a computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communications network.
- Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer, including digital signal processors.
- a processor will receive instructions and data from a read-only memory or a random access memory or both.
- Elements of a computer may include at least one processor for executing instructions and one or more memory devices for storing instructions and data.
- a computer may also include, or be operatively coupled to receive data from and/or transfer data to one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- Machine readable media suitable for embodying computer program instructions and data include all forms of non-volatile memory, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
- the processor and the memory may be supplemented by, or incorporated in special purpose logic circuitry.
- the methods and apparatus may be implemented on a computer having a display device, e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse, trackball or touch pad, by which the user can provide input to the computer.
- a display device e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor
- keyboard and a pointing device e.g., a mouse, trackball or touch pad
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the methods and apparatus described may be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation, or any combination of such back-end, middleware, or front-end components.
- Components may be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.
- LAN local area network
- WAN wide area network
Abstract
System and method for fetching embedded object content as part of a batch crawl. A fetch server receives a request on a request thread to retrieve content for objects embedded in a document, such as a web page. The fetch server attempts to locate the content of the object in cache first and in disk storage next. If the content is not located in the cache the fetch server may switch the request to a worker thread. If the content is not located in the disk storage, the fetch server may schedule a request to retrieve the content of the embedded object through a batch web crawl. Scheduling a request may include determining that a request to crawl the content of the object has already been scheduled or inserting a request into a scheduling queue.
Description
- This application claims the benefit of priority to U.S. Provisional Application No. 61/557,740, filed Nov. 9, 2011, the disclosure of which is incorporated herein by reference in its entirety.
- This description relates to searching document repositories and, more specifically, to methods and systems for efficiently retrieving embedded objects for later rendering from a large document repository, such as the Internet.
- The world-wide-web is a rich source of information. Today, there are estimated to be over one trillion unique documents such as web pages. Each document has a specific address, known as a uniform resource locator (URL). Many of these documents are dynamically created, e.g., the home page of the New York Times, and have links to embedded content such as images, style sheets, and videos. To fully recreate or store these documents, for example as a web page preview, the documents must be rendered as they exist when they are first created and served. While it is relatively straightforward for a web browser to render a single web page or a small number of web pages in real time, for example as they are created, it is much more difficult for a web page storage system to render and store a large number of documents, such as all of the pages on the world wide web (1 trillion pages) or even just the top 1% of pages on the world wide web (10 billion pages) in real time.
- According to one general aspect of the invention, a computer-implemented method for fetching content of an object embedded in a document includes identifying a fetch server from a plurality of fetch servers that is associated with a host of the document as part of a batch-crawl of a corpus of documents and sending a request to the fetch server for the content of the embedded object. The method may also include receiving the request at the fetch server on a request thread, determining, at the fetch server, whether a first memory storage device associated with the fetch server contains the content of the object, and returning the content from the first memory storage device when it is determined that the first storage device contains the content. When it is determined that the first storage device does not contain the content the method may also include switching the request from the request thread to a worker thread, determining whether a second memory storage device contains the content of the object, wherein the second memory storage device has a slower access time that the first memory storage device, and returning the content from the second memory storage device when it is determined that the second storage device contains the content. When the content is not in the second memory storage device the method may include scheduling a request with the batch crawler to have the content retrieved from a server hosting the embedded object.
- These and other aspects can include one or more of the following features. For example, the method may also include determining whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled, inserting the request to have the content retrieved into the queue when it is determined that the queue has room, and returning a failure response when it is determined that the queue does not have room. In some implementations, after returning a failure response, the method may include receiving a second request for the content of the embedded object, the second request being a repeat of the first request. The second request may be sent to another fetch server from the plurality of fetch servers. As another example, scheduling the request may include determining whether a request to crawl the content has already been scheduled and returning a failure response when the request has already been scheduled. In some implementations the method can include receiving a dummy fetch request for the content of the object prior to receiving the request to fetch the content. The method may also include determining whether a timestamp associated with the content is too old and, returning the content from the first memory device may include returning the content when it is determined that the timestamp not too old.
- Another aspect of the disclosure can be a system a fetch server for obtaining documents from a document corpus. The fetch server may include at least one processor, a first memory storage device, a second memory storage device that has a slower access time than the first memory storage device, and instructions embodied on a third storage device, the instructions causing the fetch server to perform operations. The operations may include receiving, on a request thread, a request to fetch content of an object embedded in a document, determining whether the first memory storage device contains the content of the object, and returning the content from the first memory storage device when it is determined that the first storage device contains the content. The operations may also include switching the request to a worker thread when the first storage device does not contain the content, determining whether the second memory storage device contains the content of the object, and returning the content from the second memory storage device when it is determined that the second storage device contains the content. The operations can also include scheduling a request to have the content retrieved from a server hosting the embedded object as part of a batch crawl when the second storage devices does not contain the content.
- These and other aspects can include one or more of the following features. For example, the operations may also include determining whether a worker thread is available, performing the switching when a worker thread is available, and returning a response indicating that the request could not be processed when no worker thread is available. In some implementations the operation of scheduling the request may include determining whether a request to crawl the content has already been scheduled; and returning a failure response when the request has already been scheduled. The operations may also include determining whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled, inserting the request to have the content retrieved into the queue when it is determined that the queue has room, and returning a failure response when it is determined that the queue does not have room.
- Another aspect of the disclosure can be a system for obtaining embedded objects from documents in a document corpus. The system may include one or more fetch servers configured to process batch fetch requests, each fetch server being associated with a host of the document corpus. Each fetch server ma include a first memory storage device, and a second memory storage device that has a slower access time than the first memory storage device. The system may also include a fetch requestor configured to determine a particular fetch server of the one or more fetch servers, the particular fetch server being associated with a host of a particular document, and send a request to the particular fetch server for content of an object embedded in the particular document. The system may also include a web crawling engine, configured to schedule batch crawls of a document corpus to retrieve object contents from the corpus. The one or more fetch servers may be configured to receive a request for a particular embedded object, determine whether the first memory storage device contains the content of the particular embedded object and return the content from the first memory storage device when it is determined that the first storage device contains the content. The one or more fetch servers may also be configured to determine whether the second memory storage device contains the content of the particular embedded object and return the content from the second memory storage device when it is determined that the second storage device contains the content. When it is determined that the second memory storage devices does not contain the content the one or more fetch servers may be configured to send a request to the web crawling engine to retrieve the object content from the corpus.
- In some implementations, processing the request may include sending the object content to the fetch requestor, the fetch requestor being configured to store the object content in a memory. The fetch requestor may also be configured to render the document from the object content returned by the fetch server. In some implementations, the fetch requestor may be configured to send a dummy fetch request for the embedded object prior to requesting the content of the embedded object and, the one or more fetch servers may be configured to skip sending the object content to the fetch requestor for the dummy request. The one or more fetch servers may be further configured to determine whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled, insert the request to have the content retrieved into the queue when it is determined that the queue has room, and return a failure response to the fetch requestor when it is determined that the queue does not have room. In some implementations, the one or more fetch servers are further configured with a request thread and a working thread, wherein the request thread determines whether the first memory storage device contains the content of the object and the working thread determines whether the second memory storage deice contains the content of the object and sends the request to the web crawling engine. The fetch servers may be configured to switch the request from the request thread to the working thread when it is determined that the first memory device does not contain the content.
- Another aspect of the disclosure can be a tangible computer-readable storage device having recorded and embodied thereon instructions that, when executed by one or more processors of a computer system, cause the computer system to perform any of the methods or operations described herein.
- The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features will be apparent from the description and drawings, and from the claims.
-
FIG. 1 is a block diagram of a document having embedded objects. -
FIG. 2 is a block diagram of a system for fetching embedded objects from document content. -
FIG. 3 is a flowchart illustrating a method by which a fetch server in a web page storage system can obtain target embedded objects. -
FIG. 4 is a flowchart illustrating a method by which a fetch server in a web page storage system can schedule a web crawl for a target embedded object. - To completely render a received document, a rendering system first obtains the content of all of the external resources that may be embedded in the web page. Such resources may include, but are not limited to, external images, JavaScript code, and style sheets. Often, the same external resource is embedded in many different web pages. For example, the New York Times logo may be located on many web pages available from the New York Times server. Additionally, JavaScript code and/or style sheets may be embedded on each web page hosted by the New York Times server. Whenever any one of these web pages is rendered, the image, JavaScript, and style sheet objects are downloaded from the New York Times server. While it is efficient for a single user's web browser to request an external web page resource, such as the logo or a style sheet, in real time, such as when the page in which the resource is embedded is rendered, it is neither feasible nor efficient for the rendering engine of a web page storage process to do so.
- A render server of a web page storage process is designed to render and store a large number of documents at a time, and to continually render a large number of documents at a time in order to build a large index or repository of documents, such as web pages. If such a rendering engine attempted to render thousands or tens of thousands of web pages that embed the same external resource at the same time or close together in time, the server on which the external resource resides would be flooded with near simultaneous requests for the same object. To avoid such problems, the rendering engine of a web page storage process should ideally crawl each embedded resource exactly once, regardless of how many web pages embed the resource.
- A web page storage service can render web content with embedded objects at a large scale using a plurality of render server tasks. In order to render a document, a render server task needs the contents of the document itself, e.g., http://www.cnn.com/, as well as the contents of the embedded objects, e.g., css, JavaScript, and images. At a large scale, the render servers may not directly crawl these URLs on-demand in order to honor robots.txt, host load limits, transient errors, duplicates, etc. Accordingly, an embedded object processor may be used to crawl the URLs efficiently and pass the results back to the requesting render server. In some instances, iterative calls may be needed to obtain the various levels of embedded objects. A batch crawl mechanism may be employed to address these concerns. However, a batch crawl may incur long latency times, prohibiting the timely accumulation of web page content data and limiting the number of web pages that the system can render and store.
- Disclosed embodiments provide an improved distributed fetch service that provides efficient, near real-time access to URL contents. The service may cache crawled contents in main memory, such as RAM, cache, or flash memory, as well as in more persistent memory structures, such as disks. The copies in main memory may become stale after a predetermined amount of time, but until they become stale, copies of embedded objects can be quickly fetched from the main memory store rather from the slower disk store. The use of such a system provides lower latency and greater efficiency in rendering snapshots of a large number of web pages, for example 300 million per day.
-
FIG. 1 is a block diagram of a document, such as a web page, having embedded objects. As shown in the figure, aweb page 100 can contain a plurality of embedded objects. These embedded objects can include, but are not limited to, other web pages ordocuments 110, style sheets 120, image files 130, links toadditional URLs 140, andJavaScript code 150. Additional and different types of embedded objects are, of course, possible. Moreover, each of the objects embedded inweb page 100 may also embed other objects. For example, aweb page 110 that is embedded inweb page 100 may embed other web pages, image files, style sheets, and the like. Likewise, a style sheet 120 embedded inweb page 100 may embed other objects such as a background image file. Further, each of the objects embedded inweb page 110 or style sheet 120 may themselves embed even more objects. To completely render such a web page to an image file, a rendering engine or an embedded object processor must request each of the embedded objects 110-150, or primary embedded objects, all of the objects that are embedded in the primary embedded objects 110-150, or secondary embedded objects, all of the objects that are embedded in the secondary embedded objects, or tertiary embedded objects, and so on. - As discussed above, while an individual user's web browser can efficiently request all of these embedded objects and use them to completely render and display
web page 100 in real time, the rendering engine or embedded object processor of a web page storage system cannot request all of these embedded objects in real time without the risk of flooding, and perhaps even crashing, web servers on which some of the more commonly embedded objects reside. Additionally, the time required to crawl the hundreds of millions of web pages on the world wide web is prohibitive and lag times resulting from requests to re-fetch commonly embedded objects may result in the inability to fetch and render additional web pages. A web storage system may use a batch crawler to schedule crawls to reduce the number of multiple fetches of the same content. However, objects embedded in web page content are often not fetched in the same batch as the web page content itself, causing more latency delays as the web storage system waits to fetch the embedded objects. Thus, to safely and efficiently fetch and store the data needed to render a large number of crawled web pages, a web page fetching and storage system, such as that disclosed inFIG. 2 , can be employed. -
FIG. 2 is a block diagram of a system for fetching embedded objects from web page content. As shown inFIG. 2 , the system includes one or moreweb crawling engines 210.Web crawling engine 210 may be a batch crawler with an associated host queue (not shown).Web crawling engine 210 may have a queue for each host. The system may also include one or more fetchservers 220 with associateddatabases database 235. Web-crawlingengine 210, fetchserver 220, and fetch requestor 230 may work together to safely and efficiently capture a large corpus of documents, such as web pages that can be found on the world wide web. Fetchserver 220 offers a single service that may receive a list of embedded links (fetch targets) for a document from the fetchrequestor 230 and respond with the contents of the embedded links. FetchServer 220 may receive the contents of the embedded links fromdisk database 225,cache 215, orweb crawling engine 210.Cache 215 may include a sub-set of the information stored indisk database 225. Information stored incache 215 may become old or stale sooner than the information indisk database 225. In other words, document contents may have a shorter life incache 215 than indatabase 225. Each fetchserver 220 may service one or more hosts. Fetch requestor 230 may use a fetch client application programming interface to assist in choosing which fetchserver 220 to send a request to. For example, a fetch client of fetch requestor 230 may use an affinity mechanism to identify a particular fetchserver 220 that is most likely to have the requested URLs in its cache, e.g., the fetchserver 220 that owns the host of the main document. Fetch requestor 230 may then direct a request to that particular fetchserver 220. - The affinity mechanism may enable the web page storage system to avoid having multiple queues for any host by using separate fetch service tasks for each host. Thus, in certain embodiments the web storage system may include several fetch
servers 220, with each fetchserver 220 associated with a host. When the fetchrequestor 230 makes a fetch request, the fetch client may enable it to choose the fetchserver 220 that “owns” that host. This allows the system to avoid sending requests directed to one host from multiple fetchservers 220. - Because a web page has layers of embedded links, the page must be rendered iteratively, i.e., in peels. In each peel the fetch
requestor 230, which may include a render server or an embedded object processor, may send a request to the fetchserver 220 for known embedded links of a document, such as a web page. Once the fetchserver 220 returns the content of the requested links, the fetchrequestor 230 may discover a new set of embedded links in the returned content. Accordingly, the fetchrequestor 230 may send a new fetch request for the newly discovered links. This loop terminates when the fetch requestor fails to discover new links in a peel. - In some embodiments, the fetch
requestor 230 may pre-warm thecache 215 with the contents of currently known embedded links by making a dummy request for the links. The fetchserver 220 may not send back a response for a dummy request, but will fetch the links fromdatabase 225 intocache 215. This enables a subsequent request for these links by the fetch requestor 230 to be serviced by the fetchserver 220 very quickly. Such pre-warming of the cache may be especially helpful when the fetchrequestor 230 is a render server where data structures use more memory than the contents of embedded links and pausing rendering while waiting for a response from a fetch server affects the use of RAM. -
FIG. 3 is a flowchart illustrating a method by which a fetch server in a web page storage system can efficiently retrieve web page content, including embedded objects. As shown inFIG. 3 , in one implementation, a fetchserver 220 receives a request for a fetch service task from a fetch requestor 230 (305). Fetch requestor 230 may be a render server or an embedded object processor and the fetch service task may be a request to fetch one or more embedded objects from a specific URL. The fetchserver 220 may then check to see if the fetch target is located incache 215.Cache 215 may be RAM or flash storage, so retrieval occurs more quickly than with other types of storage.Cache 215 may be populated with embedded content that has recently been retrieved byweb crawling engine 210. As explained above, in some embodiments the fetchrequestor 230 may pre-warm thecache 215 to increase the number of requested fetch targets in the cache. The time that the embedded content was retrieved and last accessed may be stored incache 215 to help determine staleness. If the fetch target is located in the cache and is not stale (i.e., the time that embedded content was last accessed and/or last retrieved is not too old) (310, YES), then the fetchserver 220 may generate a successful response and return the content associated with the fetch target (320). If the fetch target is not in cache, or if the version in the cache is stale (310, NO), then fetchserver 220 may look in a disk database, forexample disk database 225, for the fetch target. If the fetch target is in the disk database and is not stale (315, YES), then fetchserver 220 may generate a successful response for the fetch target by, for example, returning the content associated with the target from the disk database (320). In one implementation, when the fetchserver 220 locates a fetch target in the disk database, or in the cache, it may update a time last accessed associated with the content of the target. - If the fetch target is not in the disk database or is located in the database but is stale (i.e. too old) (315, NO), then fetch
server 220 may make a web crawl request to web crawling engine 210 (325). In some implementations,web crawling engine 210 may be a batch crawler that schedules crawl requests for specific content. In other implementations, theweb crawling engine 210 may be a web crawler that processes the request as it is received. Fetchserver 220 may receive the results of the web crawl request and, when the store the results incache 215 and/or disk database 225 (330). In some instances, a successful request may include a response that indicates the link could not be resolved. In such circumstances, a successful request indicates only that the crawl status of a link is known, not that the content of link has been successfully obtained. In some embodiments, storing the results incache 215 and/ordisk database 225 may include setting a timestamp. - Finally, fetch
server 220 may return the result of the web crawl request, whether it is successful or not successful (335) to fetchrequestor 230. As explained below with regard toFIG. 4 , an unsuccessful fetch request may indicate that the crawl has not yet been completed. If fetchserver 220 returns an unsuccessful response, in some embodiments fetchrequestor 230 may attempt the fetch again at a later time by repeating the request. If fetchrequestor 230 receives the content of the object, fetch requestor 230 may store the contents indatabase 235 so that the document can be rendered at a later time fromdatabase 235. - The fetch
server 220 may send a response back for each fetch target it receives, or it may receive a request having several embedded links (fetch targets) and send a response to fetch requestor 230 only once a response is determined for each embedded link. For a request to fetchserver 220 containing multiple embedded links, fetchserver 220 may performmethod 300 for each link before returning a response. - In some embodiments the fetch
server 220 may maintain two thread pools to do its work: a request thread pool and a worker thread pool. The threads in a request thread pool may manage the request, containing multiple URLs, as a whole. The threads in the request thread pool may also look for the content of a specific URL incache 215. As this is relatively lightweight work, fetchserver 220 may not delegate these requests to the worker thread to avoid the overhead of a thread context switch. In some embodiments, to minimize the possibility of a mutually exclusive contention accessing the in-memory cache 215, thecache 215 may be sharded or divided into multiple caches. - The second thread pool may include a worker thread pool. The request thread pool may switch the request to the worker thread pool when a document is not found in the
cache 215. The threads in a worker thread pool may look for the contents of a URL in thedisk database 225 or from a web crawl. Web crawl requests may be subject to a timeout, to avoid holding up the request from fetch requestor 230 indefinitely. However, a disk database request may not timeout because such requests have a much smaller latency time and prematurely timing out may result in an unnecessary web crawler request. The two thread-pool design allows fetchserver 220 to more easily determine when to push back on client requests due to a lack of thread resources. - As discussed above, the fetch
requestor 230 may include a fetch client. The fetch client may perform two important duties. The first is routing fetch requests to the fetchserver 220 that “owns” the host for the document. The fetch client may accomplish this by using an affinity based load balancing, using a hash based on the host of the document, such as a web page, having the embedded objects. In some implementations, routing may be based on domain instead of host. For large domains, the fetch client may smear the hash a little to spread around the load into more than one fetchserver 220. - The second duty performed by the fetch client may include resending a fetch request in case of push back from fetch
server 220. Fetchserver 220 may push back when it is heavily loaded and doesn't have any available threads in the request thread pool. The push back can be just a special reply status. The fetch client may then retry the fetch request with the next fetch server in the hash sequence of that document i.e., the hash obtained by appending the retry number to the URL string of the document. After a few retries, fetch client may add a delay or sleep between retries. -
FIG. 4 is a flowchart illustrating a method by which a fetchserver 220 in a web page storage system can schedule a web crawl for a target embedded object. Fetchserver 220 may usemethod 400 when a fetch target is not found incache 215 ordatabase 225, as shown instep 325 ofFIG. 3 . As shown inFIG. 4 , the fetchserver 220 may check the batch crawl scheduler to determine whether the fetch target is already scheduled for a crawl (405). If a crawl of the object has already been scheduled (410, YES), then a failure response is returned. The failure response indicates that the document cannot be rendered yet because the fetch target has not yet been retrieved. This is not a permanent failure status because the target is scheduled for batch crawl and, after it is successfully crawled, the web page storage system can attempt to fetch the target again. - If the fetch target is not already scheduled (410, NO), the fetch
server 220 may determine whether there is room in the crawler queue for this target. In some embodiments such queues are per host, so the queue for load-bound hosts may be full. In some embodiments the queues may be maintained in the fetchserver 220 itself. If no room is available (420, NO), then fetchserver 220 returns a failure response (425). As before, this response means only that the contents of the target have not yet been fetched and the fetch requestor 230 should repeat the request. Fetchserver 220 may also schedule a batch crawl of the fetch target. This may include scheduling the crawl on another host or waiting until the queue has room. If, however, the queue has room (420, YES), then fetchserver 220 inserts the request into the queue and waits for a response (430). - When a response is received, fetch
server 220 determines whether thecrawler 210 succeeded in reaching the web host for the target. If the web host was reached (435, YES), then the target has been successfully fetched. Note that even if an error was encountered and the content of the target could not be crawled, this is still considered a success. Success means that the crawl status of the fetch target has been determined, not that the content of the target was successfully located. If thecrawler 210 did not successfully reach the host (435, NO), then fetchserver 220 schedules a batch crawl and returns a failure response. As before, this indicates that the web storage system will reattempt to resolve the target.Process 400 then ends, with fetchserver 220 supplying either a failure or a success response to fetchrequestor 230. As indicated above, a success response may include sending the contents of the target object to fetchrequestor 230. In some embodiments, the contents may include an indication that the object is not available. Fetch requestor 230 may store the returned contents indatabase 235. - The data stored in web
page storage database 235 may be used to generate a preview of a web page, for example, as part of a search result. Such a preview system may provide a graphic overview of a search result and may highlight the most relevant section of the preview image. This may enable a user viewing the preview to more easily locate the right page. In some embodiments, a magnifying glass or some other icon may appear next to the title of a search result, indicating that a preview is available for the search result. Clicking on the icon may cause the system to read the data fromstorage database 235 and generate a visual overview of the web page. The visual overview may have search terms identified, for example with highlighting or different colored text, so that relevant content is quickly located. Because the terms are located in the context of the entire web page, a user may more easily evaluate whether the web page is relevant to the search. In addition, previews help a user determine if the search result contains a chart, map, picture, or some other embedded content. For users desiring to locate a previously visited web page, previews assist the user in determining whether the search result “looks familiar.” A preview may also assist users looking for “official websites” by displaying the trademarks and logos associated with each page. - The methods and apparatus described herein may be implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in combinations of them. They may be implemented as a computer program product, i.e., as a computer program tangibly embodied in a machine-readable storage device for execution by, or to control the operation of, a processor, a computer, or multiple computers. Method steps may be performed by one or more programmable processors executing a computer program to perform functions by operating on input data and generating output. Method steps also may be performed by, and an apparatus may be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The method steps may be performed in the order shown or in alternative orders.
- A computer program, such as the computer program(s) described above, can be written in any form of programming language, including compiled or interpreted languages, and can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, plug-in or other unit suitable for use in a computing environment. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communications network. Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer, including digital signal processors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both.
- Elements of a computer may include at least one processor for executing instructions and one or more memory devices for storing instructions and data. Generally, a computer may also include, or be operatively coupled to receive data from and/or transfer data to one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. Machine readable media suitable for embodying computer program instructions and data include all forms of non-volatile memory, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory may be supplemented by, or incorporated in special purpose logic circuitry.
- To provide for interaction with a user, the methods and apparatus may be implemented on a computer having a display device, e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse, trackball or touch pad, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- The methods and apparatus described may be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation, or any combination of such back-end, middleware, or front-end components. Components may be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.
- While certain features of the described implementations have been illustrated as described herein, many modifications, substitutions, changes and equivalents will now occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the scope of the embodiments.
Claims (20)
1. A computer-implemented method for fetching content of an object embedded in a document, the method comprising:
identifying a fetch server from a plurality of fetch servers that is associated with a host of the document as part of a batch-crawl of a corpus of documents;
sending a request to the fetch server for the content of the embedded object;
receiving the request at the fetch server on a request thread;
determining, at the fetch server, whether a first memory storage device associated with the fetch server contains the content of the object;
returning the content from the first memory storage device when it is determined that the first storage device contains the content;
switching the request from the request thread to a worker thread when it is determined that the first storage device does not contain the content;
determining whether a second memory storage device contains the content of the object, wherein the second memory storage device has a slower access time that the first memory storage device;
returning the content from the second memory storage device when it is determined that the second storage device contains the content; and
scheduling a request with the batch crawler to have the content retrieved from a server hosting the embedded object when the content is not in the second memory storage device.
2. The computer-implemented method of claim 1 , further comprising:
determining whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled;
inserting the request to have the content retrieved into the queue when it is determined that the queue has room; and
returning a failure response when it is determined that the queue does not have MOM.
3. The computer-implemented method of claim 2 , further comprising:
after returning a failure response, receiving a second request for the content of the embedded object, the second request being a repeat of the first request.
4. The computer-implemented method of claim 3 , wherein the second request is sent to another fetch server from the plurality of fetch servers.
5. The computer-implemented method of claim 1 , wherein scheduling the request comprises:
determining whether a request to crawl the content has already been scheduled; and
returning a failure response when the request has already been scheduled.
6. The computer-implemented method of claim 1 , further comprising:
receiving a dummy fetch request for the content of the object prior to receiving the request to fetch the content.
7. The computer-implemented method of claim 1 , further comprising determining whether a timestamp associated with the content is too old and, wherein the returning the content from the first memory device further comprises returning the content when it is determined that the timestamp not too old.
8. A computer-readable device storing instructions that, when executed by one or more processors, cause the one or more processors to perform the method of claim 1 .
9. A fetch server for obtaining documents from a document corpus, the fetch server comprising:
at least one processor;
a first memory storage device;
a second memory storage device that has a slower access time than the first memory storage device;
instructions embodied on a third storage device, the instructions causing the fetch server to perform operations comprising:
receiving, on a request thread, a request to fetch content of an object embedded in a document,
determining whether the first memory storage device contains the content of the object,
returning the content from the first memory storage device when it is determined that the first storage device contains the content,
switching the request to a worker thread when the first storage device does not contain the content;
determining whether the second memory storage device contains the content of the object,
returning the content from the second memory storage device when it is determined that the second storage device contains the content, and
scheduling a request to have the content retrieved from a server hosting the embedded object as part of a batch crawl when the second storage devices does not contain the content.
10. The fetch server of claim 9 , wherein the instructions cause the fetch server to further perform operations comprising:
determining whether a worker thread is available;
performing the switching when a worker thread is available; and
returning a response indicating that the request could not be processed when no worker thread is available.
11. The fetch server of claim 9 , wherein the operation of scheduling the request comprises:
determining whether a request to crawl the content has already been scheduled; and
returning a failure response when the request has already been scheduled.
12. The fetch server of claim 11 , the operations further comprising:
determining whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled;
inserting the request to have the content retrieved into the queue when it is determined that the queue has room; and
returning a failure response when it is determined that the queue does not have MOM.
13. A system for obtaining embedded objects from documents in a document corpus, the system comprising:
one or more fetch servers configured to process batch fetch requests, each fetch server being associated with a host of the document corpus and each fetch server comprising:
a first memory storage device, and
a second memory storage device that has a slower access time than the first memory storage device;
a fetch requestor configured to:
determine a particular fetch server of the one or more fetch servers, the particular fetch server being associated with a host of a particular document, and
send a request to the particular fetch server for content of an object embedded in the particular document; and
a web crawling engine, configured to schedule batch crawls of a document corpus to retrieve object contents from the corpus,
wherein the one or more fetch servers are configured to:
receive a request for a particular embedded object;
determine whether the first memory storage device contains the content of the particular embedded object,
return the content from the first memory storage device when it is determined that the first storage device contains the content,
determine whether the second memory storage device contains the content of the particular embedded object,
return the content from the second memory storage device when it is determined that the second storage device contains the content, and
send a request to the web crawling engine to retrieve the object content from the corpus when it is determined that the second memory storage devices does not contain the content.
14. The system of claim 13 , wherein processing the request further comprises sending the object content to the fetch requestor, and wherein the fetch requestor is further configured to store the object content in a memory.
15. The system of claim 14 , wherein the fetch requestor is further configured to render the document from the object content returned by the fetch server.
16. The system of claim 14 , wherein the fetch requestor is further configured to send a dummy fetch request for the embedded object prior to requesting the content of the embedded object and, wherein the one or more fetch servers are configured to skip sending the object content to the fetch requestor for the dummy request.
17. The system of claim 13 , wherein as part of sending a request to the web crawling engine, the one or more fetch servers are configured to:
determine whether a request to crawl the content has already been scheduled; and
return a failure response to the fetch requestor when the request has already been scheduled.
18. The system of claim 17 , wherein the one or more fetch servers are further configured to:
determine whether a queue storing scheduled requests has room for another request when it is determined that the request has not been scheduled;
insert the request to have the content retrieved into the queue when it is determined that the queue has room; and
return a failure response to the fetch requestor when it is determined that the queue does not have room.
19. The system of claim 13 , wherein the one or more fetch servers are further configured with a request thread and a working thread, wherein the request thread determines whether the first memory storage device contains the content of the object and the working thread determines whether the second memory storage deice contains the content of the object and sends the request to the web crawling engine.
20. The system of claim 19 , wherein the one or more fetch servers are further configured to switch the request from the request thread to the working thread when it is determined that the first memory device does not contain the content.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/644,297 US20130117252A1 (en) | 2011-11-09 | 2012-10-04 | Large-scale real-time fetch service |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201161557740P | 2011-11-09 | 2011-11-09 | |
US13/644,297 US20130117252A1 (en) | 2011-11-09 | 2012-10-04 | Large-scale real-time fetch service |
Publications (1)
Publication Number | Publication Date |
---|---|
US20130117252A1 true US20130117252A1 (en) | 2013-05-09 |
Family
ID=48224433
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/644,297 Abandoned US20130117252A1 (en) | 2011-11-09 | 2012-10-04 | Large-scale real-time fetch service |
Country Status (1)
Country | Link |
---|---|
US (1) | US20130117252A1 (en) |
Cited By (25)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN103544209A (en) * | 2013-08-26 | 2014-01-29 | 深圳市融创天下科技股份有限公司 | Method and system for web page access |
US20140033019A1 (en) * | 2010-04-05 | 2014-01-30 | Zixiao Zhang | Caching Pagelets of Structured Documents |
WO2015077140A1 (en) * | 2013-11-21 | 2015-05-28 | Google Inc. | Speeding up document loading |
WO2015196414A1 (en) | 2014-06-26 | 2015-12-30 | Google Inc. | Batch-optimized render and fetch architecture |
US9582482B1 (en) | 2014-07-11 | 2017-02-28 | Google Inc. | Providing an annotation linking related entities in onscreen content |
US9703541B2 (en) | 2015-04-28 | 2017-07-11 | Google Inc. | Entity action suggestion on a mobile device |
AU2014223495B2 (en) * | 2013-03-01 | 2017-07-13 | Facebook, Inc. | Caching pagelets of structured documents |
US9736212B2 (en) | 2014-06-26 | 2017-08-15 | Google Inc. | Optimized browser rendering process |
US9767199B2 (en) | 2012-10-05 | 2017-09-19 | Google Inc. | Transcoding and serving resources |
US9785720B2 (en) | 2014-06-26 | 2017-10-10 | Google Inc. | Script optimized browser rendering process |
US9965559B2 (en) | 2014-08-21 | 2018-05-08 | Google Llc | Providing automatic actions for mobile onscreen content |
CN108268498A (en) * | 2016-12-30 | 2018-07-10 | 北京国双科技有限公司 | The treating method and apparatus of batch reptile task |
US10037276B1 (en) * | 2015-11-04 | 2018-07-31 | Veritas Technologies Llc | Systems and methods for accelerating access to data by pre-warming the cache for virtual machines |
US10055390B2 (en) | 2015-11-18 | 2018-08-21 | Google Llc | Simulated hyperlinks on a mobile device based on user intent and a centered selection of text |
US10178527B2 (en) | 2015-10-22 | 2019-01-08 | Google Llc | Personalized entity repository |
US10353993B2 (en) | 2010-04-05 | 2019-07-16 | Facebook, Inc. | Phased generation and delivery of structured documents |
US10498812B1 (en) * | 2019-05-29 | 2019-12-03 | Cloudflare, Inc. | State management and object storage in a distributed cloud computing network |
US10535005B1 (en) | 2016-10-26 | 2020-01-14 | Google Llc | Providing contextual actions for mobile onscreen content |
US20200334315A1 (en) * | 2017-11-10 | 2020-10-22 | Yijun Du | Enhanced document searching system and method |
US10970646B2 (en) | 2015-10-01 | 2021-04-06 | Google Llc | Action suggestions for user-selected content |
US11237696B2 (en) | 2016-12-19 | 2022-02-01 | Google Llc | Smart assist for repeated actions |
US11240309B1 (en) | 2020-12-04 | 2022-02-01 | Cloudflare, Inc. | State management and storage with policy enforcement in a distributed cloud computing network |
US11271933B1 (en) * | 2020-01-15 | 2022-03-08 | Worldpay Limited | Systems and methods for hosted authentication service |
US20220292142A1 (en) * | 2019-11-08 | 2022-09-15 | GAP Intelligence | Automated web page accessing |
US20230004618A1 (en) * | 2019-02-25 | 2023-01-05 | Bright Data Ltd. | System and method for url fetching retry mechanism |
Citations (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6321265B1 (en) * | 1999-11-02 | 2001-11-20 | Altavista Company | System and method for enforcing politeness while scheduling downloads in a web crawler |
US20030041280A1 (en) * | 1997-06-09 | 2003-02-27 | Cacheflow, Inc. | Network object cache engine |
US6643641B1 (en) * | 2000-04-27 | 2003-11-04 | Russell Snyder | Web search engine with graphic snapshots |
US6865192B1 (en) * | 2000-12-22 | 2005-03-08 | Sprint Communications Company L.P. | Integrated services hub self configuration |
US20070104208A1 (en) * | 2005-11-04 | 2007-05-10 | Bea Systems, Inc. | System and method for shaping traffic |
US20080270659A1 (en) * | 2007-04-26 | 2008-10-30 | Microsoft Corporation | Governing access to a computing resource |
US20090077198A1 (en) * | 2006-12-19 | 2009-03-19 | Daniel Mattias Larsson | Dynamically constrained, forward scheduling over uncertain workloads |
US20100057802A1 (en) * | 2001-11-30 | 2010-03-04 | Micron Technology, Inc. | Method and system for updating a search engine |
US20110083037A1 (en) * | 2009-10-06 | 2011-04-07 | Microsoft Corporation | Reliable media streaming |
US20110119602A1 (en) * | 2009-11-19 | 2011-05-19 | Sony Corporation | Web server, web browser and web system |
-
2012
- 2012-10-04 US US13/644,297 patent/US20130117252A1/en not_active Abandoned
Patent Citations (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030041280A1 (en) * | 1997-06-09 | 2003-02-27 | Cacheflow, Inc. | Network object cache engine |
US6321265B1 (en) * | 1999-11-02 | 2001-11-20 | Altavista Company | System and method for enforcing politeness while scheduling downloads in a web crawler |
US6643641B1 (en) * | 2000-04-27 | 2003-11-04 | Russell Snyder | Web search engine with graphic snapshots |
US6865192B1 (en) * | 2000-12-22 | 2005-03-08 | Sprint Communications Company L.P. | Integrated services hub self configuration |
US20100057802A1 (en) * | 2001-11-30 | 2010-03-04 | Micron Technology, Inc. | Method and system for updating a search engine |
US20070104208A1 (en) * | 2005-11-04 | 2007-05-10 | Bea Systems, Inc. | System and method for shaping traffic |
US20090077198A1 (en) * | 2006-12-19 | 2009-03-19 | Daniel Mattias Larsson | Dynamically constrained, forward scheduling over uncertain workloads |
US20080270659A1 (en) * | 2007-04-26 | 2008-10-30 | Microsoft Corporation | Governing access to a computing resource |
US20110083037A1 (en) * | 2009-10-06 | 2011-04-07 | Microsoft Corporation | Reliable media streaming |
US20110119602A1 (en) * | 2009-11-19 | 2011-05-19 | Sony Corporation | Web server, web browser and web system |
Cited By (66)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140033019A1 (en) * | 2010-04-05 | 2014-01-30 | Zixiao Zhang | Caching Pagelets of Structured Documents |
US10353993B2 (en) | 2010-04-05 | 2019-07-16 | Facebook, Inc. | Phased generation and delivery of structured documents |
US9626343B2 (en) * | 2010-04-05 | 2017-04-18 | Facebook, Inc. | Caching pagelets of structured documents |
US10599727B2 (en) | 2012-10-05 | 2020-03-24 | Google Llc | Transcoding and serving resources |
US11580175B2 (en) | 2012-10-05 | 2023-02-14 | Google Llc | Transcoding and serving resources |
US9767199B2 (en) | 2012-10-05 | 2017-09-19 | Google Inc. | Transcoding and serving resources |
AU2014223495B2 (en) * | 2013-03-01 | 2017-07-13 | Facebook, Inc. | Caching pagelets of structured documents |
CN103544209A (en) * | 2013-08-26 | 2014-01-29 | 深圳市融创天下科技股份有限公司 | Method and system for web page access |
US11809511B2 (en) | 2013-11-21 | 2023-11-07 | Google Llc | Speeding up document loading |
US10909207B2 (en) | 2013-11-21 | 2021-02-02 | Google Llc | Speeding up document loading |
WO2015077140A1 (en) * | 2013-11-21 | 2015-05-28 | Google Inc. | Speeding up document loading |
US10296654B2 (en) | 2013-11-21 | 2019-05-21 | Google Llc | Speeding up document loading |
US9736212B2 (en) | 2014-06-26 | 2017-08-15 | Google Inc. | Optimized browser rendering process |
US10713330B2 (en) | 2014-06-26 | 2020-07-14 | Google Llc | Optimized browser render process |
US9785720B2 (en) | 2014-06-26 | 2017-10-10 | Google Inc. | Script optimized browser rendering process |
CN106462582A (en) * | 2014-06-26 | 2017-02-22 | 谷歌公司 | Batch-optimized render and fetch architecture |
WO2015196414A1 (en) | 2014-06-26 | 2015-12-30 | Google Inc. | Batch-optimized render and fetch architecture |
US11328114B2 (en) | 2014-06-26 | 2022-05-10 | Google Llc | Batch-optimized render and fetch architecture |
EP3161668A4 (en) * | 2014-06-26 | 2018-03-28 | Google LLC | Batch-optimized render and fetch architecture |
US10284623B2 (en) | 2014-06-26 | 2019-05-07 | Google Llc | Optimized browser rendering service |
US9984130B2 (en) | 2014-06-26 | 2018-05-29 | Google Llc | Batch-optimized render and fetch architecture utilizing a virtual clock |
US10080114B1 (en) | 2014-07-11 | 2018-09-18 | Google Llc | Detection and ranking of entities from mobile onscreen content |
US11704136B1 (en) | 2014-07-11 | 2023-07-18 | Google Llc | Automatic reminders in a mobile environment |
US11347385B1 (en) | 2014-07-11 | 2022-05-31 | Google Llc | Sharing screen content in a mobile environment |
US11907739B1 (en) | 2014-07-11 | 2024-02-20 | Google Llc | Annotating screen content in a mobile environment |
US11573810B1 (en) | 2014-07-11 | 2023-02-07 | Google Llc | Sharing screen content in a mobile environment |
US10244369B1 (en) | 2014-07-11 | 2019-03-26 | Google Llc | Screen capture image repository for a user |
US10248440B1 (en) | 2014-07-11 | 2019-04-02 | Google Llc | Providing a set of user input actions to a mobile device to cause performance of the set of user input actions |
US9582482B1 (en) | 2014-07-11 | 2017-02-28 | Google Inc. | Providing an annotation linking related entities in onscreen content |
US9916328B1 (en) | 2014-07-11 | 2018-03-13 | Google Llc | Providing user assistance from interaction understanding |
US9886461B1 (en) | 2014-07-11 | 2018-02-06 | Google Llc | Indexing mobile onscreen content |
US10491660B1 (en) | 2014-07-11 | 2019-11-26 | Google Llc | Sharing screen content in a mobile environment |
US9824079B1 (en) | 2014-07-11 | 2017-11-21 | Google Llc | Providing actions for mobile onscreen content |
US9811352B1 (en) | 2014-07-11 | 2017-11-07 | Google Inc. | Replaying user input actions using screen capture images |
US10592261B1 (en) | 2014-07-11 | 2020-03-17 | Google Llc | Automating user input from onscreen content |
US9788179B1 (en) | 2014-07-11 | 2017-10-10 | Google Inc. | Detection and ranking of entities from mobile onscreen content |
US10652706B1 (en) | 2014-07-11 | 2020-05-12 | Google Llc | Entity disambiguation in a mobile environment |
US9762651B1 (en) | 2014-07-11 | 2017-09-12 | Google Inc. | Redaction suggestion for sharing screen content |
US10963630B1 (en) | 2014-07-11 | 2021-03-30 | Google Llc | Sharing screen content in a mobile environment |
US9965559B2 (en) | 2014-08-21 | 2018-05-08 | Google Llc | Providing automatic actions for mobile onscreen content |
US9703541B2 (en) | 2015-04-28 | 2017-07-11 | Google Inc. | Entity action suggestion on a mobile device |
US10970646B2 (en) | 2015-10-01 | 2021-04-06 | Google Llc | Action suggestions for user-selected content |
US11716600B2 (en) | 2015-10-22 | 2023-08-01 | Google Llc | Personalized entity repository |
US11089457B2 (en) | 2015-10-22 | 2021-08-10 | Google Llc | Personalized entity repository |
US10178527B2 (en) | 2015-10-22 | 2019-01-08 | Google Llc | Personalized entity repository |
US10037276B1 (en) * | 2015-11-04 | 2018-07-31 | Veritas Technologies Llc | Systems and methods for accelerating access to data by pre-warming the cache for virtual machines |
US10733360B2 (en) | 2015-11-18 | 2020-08-04 | Google Llc | Simulated hyperlinks on a mobile device |
US10055390B2 (en) | 2015-11-18 | 2018-08-21 | Google Llc | Simulated hyperlinks on a mobile device based on user intent and a centered selection of text |
US10535005B1 (en) | 2016-10-26 | 2020-01-14 | Google Llc | Providing contextual actions for mobile onscreen content |
US11734581B1 (en) | 2016-10-26 | 2023-08-22 | Google Llc | Providing contextual actions for mobile onscreen content |
US11237696B2 (en) | 2016-12-19 | 2022-02-01 | Google Llc | Smart assist for repeated actions |
US11860668B2 (en) | 2016-12-19 | 2024-01-02 | Google Llc | Smart assist for repeated actions |
CN108268498A (en) * | 2016-12-30 | 2018-07-10 | 北京国双科技有限公司 | The treating method and apparatus of batch reptile task |
US20200334315A1 (en) * | 2017-11-10 | 2020-10-22 | Yijun Du | Enhanced document searching system and method |
US20230004618A1 (en) * | 2019-02-25 | 2023-01-05 | Bright Data Ltd. | System and method for url fetching retry mechanism |
WO2020242521A1 (en) * | 2019-05-29 | 2020-12-03 | Cloudflare, Inc. | State management and object storage in a distributed cloud computing network |
US11038959B2 (en) * | 2019-05-29 | 2021-06-15 | Cloudflare, Inc. | State management and object storage in a distributed cloud computing network |
US20230028120A1 (en) * | 2019-05-29 | 2023-01-26 | Cloudflare, Inc. | State management and object storage in a distributed cloud computing network |
US11489918B2 (en) * | 2019-05-29 | 2022-11-01 | Cloudflare, Inc. | State management and object storage in a distributed cloud computing network |
US10498812B1 (en) * | 2019-05-29 | 2019-12-03 | Cloudflare, Inc. | State management and object storage in a distributed cloud computing network |
US11818209B2 (en) * | 2019-05-29 | 2023-11-14 | Cloudflare, Inc. | State management and object storage in a distributed cloud computing network |
US11709900B2 (en) * | 2019-11-08 | 2023-07-25 | Gap Intelligence, Inc. | Automated web page accessing |
US20220292142A1 (en) * | 2019-11-08 | 2022-09-15 | GAP Intelligence | Automated web page accessing |
US11271933B1 (en) * | 2020-01-15 | 2022-03-08 | Worldpay Limited | Systems and methods for hosted authentication service |
US11909736B2 (en) | 2020-01-15 | 2024-02-20 | Worldpay Limited | Systems and methods for authenticating an electronic transaction using hosted authentication service |
US11240309B1 (en) | 2020-12-04 | 2022-02-01 | Cloudflare, Inc. | State management and storage with policy enforcement in a distributed cloud computing network |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20130117252A1 (en) | Large-scale real-time fetch service | |
KR102097300B1 (en) | File handling within a cloud-based file system | |
US8346755B1 (en) | Iterative off-line rendering process | |
RU2659481C1 (en) | Optimized architecture of visualization and sampling for batch processing | |
CN1192317C (en) | System and method for locating pages on the world wide web and for locating documents from network of computers | |
KR101678245B1 (en) | System and method for reducing startup cost of a software application | |
KR101647071B1 (en) | Architectural pattern for persistent web application design | |
US7630970B2 (en) | Wait timer for partially formed query | |
US9967309B2 (en) | Dynamic loading of routes in a single-page application | |
US10440140B2 (en) | Browser cache management | |
US8392576B1 (en) | Browser based redirection of broken links | |
US9064013B1 (en) | Application of resource limits to request processing | |
US8553259B2 (en) | Intelligent print options for search engine results | |
US9021087B1 (en) | Method to improve caching accuracy by using snapshot technology | |
US8504692B1 (en) | Browser based redirection of broken links | |
US20240086479A1 (en) | Identification and Issuance of Repeatable Queries | |
US8930946B1 (en) | Leasing prioritized tasks | |
US20160188717A1 (en) | Network crawling prioritization | |
US20140068005A1 (en) | Identification, caching, and distribution of revised files in a content delivery network | |
US10691750B1 (en) | Browser configured to efficiently store browsing session state | |
US8712992B2 (en) | Method and apparatus for web crawling | |
US20160182673A1 (en) | Dynamic cache injector | |
JP2018160264A (en) | Batch-optimized render and fetch architecture | |
US10331747B1 (en) | Method and system for creating and using persona in a content management system | |
US9798779B2 (en) | Obtaining desired web content for a mobile device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SAMADDAR, SUMITRO;KAPOOR, RUPESH;FEDORYNSKI, PAWEL ALEKSANDER;REEL/FRAME:029605/0975Effective date: 20120928 |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044144/0001Effective date: 20170929 |