EP1864502B1 - Dominant motion estimation for image sequence processing - Google Patents
Dominant motion estimation for image sequence processing Download PDFInfo
- Publication number
- EP1864502B1 EP1864502B1 EP05795066.9A EP05795066A EP1864502B1 EP 1864502 B1 EP1864502 B1 EP 1864502B1 EP 05795066 A EP05795066 A EP 05795066A EP 1864502 B1 EP1864502 B1 EP 1864502B1
- Authority
- EP
- European Patent Office
- Prior art keywords
- frame
- motion
- dominant motion
- integral projections
- current frame
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000033001 locomotion Effects 0.000 title claims description 132
- 238000012545 processing Methods 0.000 title claims description 5
- 238000000034 method Methods 0.000 claims description 43
- 230000000694 effects Effects 0.000 claims description 10
- PXFBZOLANLWPMH-UHFFFAOYSA-N 16-Epiaffinine Natural products C1C(C2=CC=CC=C2N2)=C2C(=O)CC2C(=CC)CN(C)C1C2CO PXFBZOLANLWPMH-UHFFFAOYSA-N 0.000 claims description 5
- 238000012360 testing method Methods 0.000 claims description 4
- 238000001914 filtration Methods 0.000 claims 1
- 230000003019 stabilising effect Effects 0.000 claims 1
- 230000006641 stabilisation Effects 0.000 description 11
- 239000013598 vector Substances 0.000 description 9
- 230000008569 process Effects 0.000 description 8
- 238000006073 displacement reaction Methods 0.000 description 7
- 230000006870 function Effects 0.000 description 4
- 238000005259 measurement Methods 0.000 description 4
- 230000009466 transformation Effects 0.000 description 4
- 208000012639 Balance disease Diseases 0.000 description 3
- 238000013459 approach Methods 0.000 description 3
- 238000003384 imaging method Methods 0.000 description 3
- 238000013507 mapping Methods 0.000 description 3
- 230000007246 mechanism Effects 0.000 description 3
- 230000003044 adaptive effect Effects 0.000 description 2
- 230000006399 behavior Effects 0.000 description 2
- 230000015556 catabolic process Effects 0.000 description 2
- 230000008859 change Effects 0.000 description 2
- 238000007906 compression Methods 0.000 description 2
- 230000006835 compression Effects 0.000 description 2
- 238000006731 degradation reaction Methods 0.000 description 2
- 238000011161 development Methods 0.000 description 2
- 230000018109 developmental process Effects 0.000 description 2
- 230000009467 reduction Effects 0.000 description 2
- 238000013519 translation Methods 0.000 description 2
- 230000014616 translation Effects 0.000 description 2
- 235000002566 Capsicum Nutrition 0.000 description 1
- 241000758706 Piperaceae Species 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 238000004891 communication Methods 0.000 description 1
- 239000012141 concentrate Substances 0.000 description 1
- 230000010485 coping Effects 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 230000000875 corresponding effect Effects 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 238000009472 formulation Methods 0.000 description 1
- 238000010237 hybrid technique Methods 0.000 description 1
- 230000007257 malfunction Effects 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 229920001690 polydopamine Polymers 0.000 description 1
- 229910052704 radon Inorganic materials 0.000 description 1
- SYUHGPGVQRZVTB-UHFFFAOYSA-N radon atom Chemical compound [Rn] SYUHGPGVQRZVTB-UHFFFAOYSA-N 0.000 description 1
- 230000009291 secondary effect Effects 0.000 description 1
- 238000011105 stabilization Methods 0.000 description 1
- 239000003381 stabilizer Substances 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000003786 synthesis reaction Methods 0.000 description 1
- 230000002123 temporal effect Effects 0.000 description 1
- 238000000844 transformation Methods 0.000 description 1
- PICXIOQBANWBIZ-UHFFFAOYSA-N zinc;1-oxidopyridine-2-thione Chemical class [Zn+2].[O-]N1C=CC=CC1=S.[O-]N1C=CC=CC1=S PICXIOQBANWBIZ-UHFFFAOYSA-N 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/14—Picture signal circuitry for video frequency region
- H04N5/144—Movement detection
- H04N5/145—Movement estimation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/20—Analysis of motion
- G06T7/269—Analysis of motion using gradient-based methods
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/527—Global motion vector estimation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/80—Details of filtering operations specially adapted for video compression, e.g. for pixel interpolation
Definitions
- This invention relates to image and video processing and is concerned with measuring the global, dominant or camera motion between any pair of frames in an image sequence.
- Prior art reveals work in this area for compensating random displacements due to unwanted camera motion, for improving MPEG4 coding and for detecting events in a video stream (e.g. scene cuts).
- the dominant motion in a scene is that motion component that can be ascribed to most of the picture material in an image.
- Terms like global motion and camera motion are used synonymously to mean the same thing, but they do not quite express the fact that the dominant motion in a scene can be a combination of both camera behaviour and apparent object behaviour.
- the movement of the head is likely to be the dominant motion in the scene as it is the largest moving object.
- any camera motion is the dominant motion since most of the scene content is background (the court) and that background will move relatively with the camera.
- the camera zooms in from a wide view of the court to a close up of the player.
- the dominant motion is initially the camera zoom, but as the player's body fills the field of view toward the end of the shot, the body motion becomes dominant later on.
- Dominant motion information has long been recognised as an important feature in many video processing tasks. This motion embodies information about the video event, hence it is a useful feature for content based retrieval [3]. Similarly, because of the large picture area that can be ascribed to dominant motion, it can (in general) be estimated more robustly than local motion, and is useful for compression as in MPEG4 [4].
- One embodiment of this invention involves image stabilisation.
- Image instability manifests as a random, unwanted fluctuation in the dominant motion of a scene.
- Shake is very common in footage from both hand-held cameras and fixed cameras (despite the image stabilisation technology on most cameras).
- Instability can be caused by external factors such as wind and unsteadiness in the camera's movement (any instability is magnified at high zoom).
- Archived video sequences also suffer from unsteadiness introduced during filming or during the digitization of film.
- most common compression systems utilise the similarity between consecutive frames, random dominant motion has a large effect on the compressibility of video data since more bandwidth is consumed unnecessarily representing motion locally. Removal of this fluctuation therefore has wide application in a number of different areas.
- Feature based methods typically employed in computer vision, attempt to locate and match important features, e.g. corners in image pairs, and hence extract the image geometry and eventually the perspective distortion [12].
- Image based methods rely on direct transformation of the image grid and minimize some image difference criterion. The technique discussed here is an image based method.
- Adaptive weights are generally a superior mechanism for coping with global motion, even though more computationally expensive.
- Image stabilisation, LEBBELL MARK (GB); TASKER DAVID (GB), 2002 mention is made about using global motion for video stabilisation but there is no claim regarding the mechanism used for making the global motion measurement.
- Direct matching techniques can be attempted for dominant motion estimation. This implies exhaustively searching for the best motion component that would exactly match two image frames. This is known as Block Matching. It is very simple to implement but computationally expensive because of the exhaustive nature of the search process. Since 1992 [5], ad-hoc developments in an alternative strategy for direct matching have emerged. Note that all of these developments have addressed only the problem of discovering the image translation between two images that are identical except for the relative displacement between them. The application domain was not realistic image sequences but instead targeted the image registration problem in satellite imagery. The idea is instead of matching the entire 2D images, it is sensible to match the vertical and horizontal summation of the image. Intuitively it makes sense. Consider that the vertical image projection is the sum of the image intensities along columns.
- This invention discloses a new means for estimating dominant motion that is more computationally efficient.
- One embodiment of the invention results in a system using general purpose hardware, that removes random, unwanted global motion at rates in excess of 25 frames per second operating on standard definition 720 ⁇ 576 digital television images.
- the input may be any sequence of image frames from an image source, such as a video camera, an IR or X-ray imagery, radar, or from a storage medium such as computer disk memory, video tape or a computer graphics generator.
- One component of this invention is a new perspective on Integral Projections which is much simpler to follow than the Transform domain exposition [8]. It is different in that it leads directly to a gradient based approach to matching integral projections. This is computationally cheaper.
- the gradient based aspect is another component of the invention, along with a refinement process for treating large displacement.
- the new result allows a measure to be derived that can check the validity of a projection before motion estimation begins.
- the invention also incorporates the use of weights in the image space to remove the effect of local motion on the integral projection.
- one embodiment of the invention is the use of the Graphics Hardware available in general purpose PCs, PDAs and game consoles (e.g. Sony Playstation) for implementing the projection and compensation unit for an image stabiliser.
- FIG. 1 An overview of the process is shown in Figure 1 .
- the figure shows the overall system invention, in an embodiment for translational motion.
- the frame buffer unit is an image delay that can manifest as a framestore holding one previous frame in memory.
- the frames input to the system need not be consecutive however.
- the Image Projections and Projection Shift units create and translate projections respectively. These units maybe implemented within the Graphics hardware of modern computers and games consoles.
- the Gradient Based matching unit calculates the shift between current and previous image frame projections using the method described in this invention.
- Dominant motion is estimated based on a single large N ⁇ N block centred on each frame.
- a value of N 512 pixels is used for a 720 ⁇ 576 image.
- This block size is arbitrary and depends on the size of the overall picture. It generally should occupy 90% of the area of the image. All methods described use one dimensional, Integral Projections of this block to estimate global motion.
- the directions of the projections need not be vertical and horizontal. They may be any set of directions, preferably two orthogonal directions.
- Each such equation at each row can be stacked into a vector to yield a set of equations as follows.
- z n x 0 z n x 0 z n x 0 ⁇ z n x ⁇ N - 1 u y ⁇ g y x 0 g y x 0 g y x 0 ⁇ g y x ⁇ N - 1 where there are N rows in the block being analysed.
- u y g y x ⁇ T ⁇ z n x g y x ⁇ T ⁇ g y x
- u y can be calculated using integral projections.
- u x can be calculated similarly, summing along rows k .
- Weights can be used to reduce the effect of objects undergoing local motion on the estimation of global motion. Weighting can be done either in the projections themselves or in the 2D image space. The idea of weighted estimation for this purpose can be found in [9]. This invention applies that idea for use with the projections based, gradient technique given here.
- a weight w ( h , k ) representing a confidence between 0 and 1 can be associated with each pixel site.
- ⁇ adjusts how fast the weights go to 0 as Z gets larger.
- Many other functions can be used, the essential idea being that large DFD probably indicates a poor image match, hence residual motion, hence local motion.
- These weights are then used to remove the effect of the corresponding pixels in the integral projections by premultiplying the image with the weights before summation. Each projection element must be scaled by the sum of the weights along the relevant row or column.
- weights can be applied directly in the projections space by applying them to modulate gradients and z.
- a weight is associated with each projection bin by using the same means as mentioned previously except the error measure (DFD) is the difference between current and previous projections (displaced by current motion estimates). Both the gradient and difference vector are multiplied by the weights before a solution is generated for the global motion. This results in a matching process robust to large deviations in the projections space presumably caused by local motion.
- DMD error measure
- each frame must be processed in less than 40ms.
- the table below compares the computational complexity of block matching with that of each of the methods proposed as embodiments of the invention.
- the first column gives the number of operations required based on a single N x N size block, with a range of (+/- w ) (where i is the number of iterations and t is the number of taps used in the low pass filter used by the multi resolution method). This does not include the number of computations required to calculate the projections (2 N 2 ).
- Global motion can be caused by: (1) intentional effects like a pan, and (2) the unsteadiness of the camera which is unintentional.
- the first effect is generally low frequency and exhibits slow temporal variations, whereas the secondary effect could be temporally impulsive.
- the measured motion is a combination of unwanted and wanted components. For instance, if a person is holding a camera and pans from left to right, a shaking hand will cause the deviation of the global motion away from the desired pan motion due to the (perhaps) random hand movements.
- the random hand motion component is unwanted while the pan is desired.
- the dominant motion estimator will yield a motion estimate that is the sum of these two motions. Thus removing all dominant motion in this case does stabilise the sequence but it also removes the desired pan.
- the dominant motion estimator can be coupled with a process for removing unwanted components of motion. It is possible to extract the low frequency (desired) signal by means of a low pass filter [6]. The motion estimate that is required for stabilisation can then be found by simple difference of the output of this filter and the measured motion.
- H z 0.0201 + 0.0402 ⁇ z - 1 + 0.2017 ⁇ z - 2 1 + 1.561 ⁇ z - 1 - 0.6414 ⁇ z - 2
- the unintentional motion could last for a single frame or be completely random. This is the case in film scanning when frames are displaced randomly from each other because of scanner malfunction or the degradation of the film guide holes.
- the filter above cannot reject the impulsive, random component on its own especially when that component is large.
- a solution is to use a median filter as a detector of large deviations in global motion.
- the motion estimates are first filtered with a median filter (having at least 3 taps, and preferably 5 taps). This will reject large deviations in the observed global motion.
- the difference between that median filtered output and the original motion signature will be large at the instances of large impulsive deviation, but small otherwise. By thresholding this difference signal, it is possible to switch between the IIR filter output and the median filter output.
- the desired component of motion can be estimated regardless of the size and randomness of the global motion.
- the ability to automatically spot an important event in a video sequence is useful for surveillance and summarisation applications.
- a rapid zoom in could indicate an important object is in view.
- a zoom in followed by a zoom out indicates a bowler run up and delivery sequence [1].
- large apparent translations could indicate people entering or leaving a room. For this reason the dominant motion estimation process described here can be used for event spotting since it yields a feature that could be correlated to important events in the video.
- each image must be shifted to compensate for the unwanted motion component estimated in previous sections.
- a sub-pixel accurate motion vector is typically required.
- Interpolation of the image signal is required to motion compensate a frame with a fractional motion vector.
- bilinear interpolation is sufficient.
- this interpolation is computationally very demanding and can be a bottleneck in a real-time shake reduction scheme.
- Modern graphics hardware contain very efficient interpolation units which are used in the texture mapping stage of the graphics pipeline.
- the graphics hardware can compensate each frame with bilinear interpolation accuracy. This can be done much faster than real-time with the motion compensated sequence displayed on screen.
- Each motion compensated frame can also be retrieved from the graphics hardware and saved to file if necessary. Because the graphics hardware can work in parallel with the CPU, using it for motion compensation also frees up valuable CPU cycles for other processes.
- the point to be made here is that it is one embodiment of this invention that the interpolation unit of the GPU can be used as part of the pipeline for dominant motion estimation and subsequent video stabilisation as required. GPUs produced by NVIDIA TM and ATI TM are good vehicles for this implementation.
- the Sony Playstation TM is also suitable.
- dedicated hardware can be built to perform these functions including a combination of FPGA and DSP blocks.
Description
- This invention relates to image and video processing and is concerned with measuring the global, dominant or camera motion between any pair of frames in an image sequence. Prior art reveals work in this area for compensating random displacements due to unwanted camera motion, for improving MPEG4 coding and for detecting events in a video stream (e.g. scene cuts). The dominant motion in a scene is that motion component that can be ascribed to most of the picture material in an image. Terms like global motion and camera motion are used synonymously to mean the same thing, but they do not quite express the fact that the dominant motion in a scene can be a combination of both camera behaviour and apparent object behaviour. Thus in an image sequence showing a head and shoulders shot of a person taken with a static camera, the movement of the head is likely to be the dominant motion in the scene as it is the largest moving object. In the recording of a tennis match, any camera motion is the dominant motion since most of the scene content is background (the court) and that background will move relatively with the camera. However, consider that the camera zooms in from a wide view of the court to a close up of the player. The dominant motion is initially the camera zoom, but as the player's body fills the field of view toward the end of the shot, the body motion becomes dominant later on.
- Dominant motion information has long been recognised as an important feature in many video processing tasks. This motion embodies information about the video event, hence it is a useful feature for content based retrieval [3]. Similarly, because of the large picture area that can be ascribed to dominant motion, it can (in general) be estimated more robustly than local motion, and is useful for compression as in MPEG4 [4].
- One embodiment of this invention involves image stabilisation. Image instability manifests as a random, unwanted fluctuation in the dominant motion of a scene. Shake is very common in footage from both hand-held cameras and fixed cameras (despite the image stabilisation technology on most cameras). Instability can be caused by external factors such as wind and unsteadiness in the camera's movement (any instability is magnified at high zoom). Archived video sequences also suffer from unsteadiness introduced during filming or during the digitization of film. As most common compression systems utilise the similarity between consecutive frames, random dominant motion has a large effect on the compressibility of video data since more bandwidth is consumed unnecessarily representing motion locally. Removal of this fluctuation therefore has wide application in a number of different areas.
- There are two issues in video stabilisation. Firstly, the dominant motion must be estimated. The unwanted component of this dominant motion must then be extracted and removed, while preserving intentional motion such as pan. To achieve this, it is assumed that the two components of motion have different statistics.
- There are many possibilities for estimating dominant motion. These can be split into two main categories:feature based and image based. Feature based methods, typically employed in computer vision, attempt to locate and match important features, e.g. corners in image pairs, and hence extract the image geometry and eventually the perspective distortion [12]. Image based methods rely on direct transformation of the image grid and minimize some image difference criterion. The technique discussed here is an image based method.
- Early image based methods include the work described by Dufaux et al [4] (2000) and Odobez et al [9] (1995). These are both very similar and rely on a gradient based approximation to image warping. [9] correctly points out that accurate estimation of dominant motion requires the design of a technique that can suppress the motion of the smaller objects in the scene i.e the Local Motion. Both [9] and [4] propose weighting schemes which are applied to the 2D image plane in order to remove the effect of image motion. These weights are derived from measurements made at single pixel sites only.
- As part of video stabilisation systems several prior art publications present mention of global motion estimation. In
GB2307133 EP0986252 , System and method for electronic image stabilization HANNA KEITH JAMES (US), BURT PETER JEFFREY (US), SARNOFF CORP (US), 2000 a generic claim is made for global motion estimation using a recursive refinement of an initial estimate which may be zero. This concept is well established in prior available literature, also for global motion [9] 1995. Even more generically it is known as an idea for generating motion information since 1987 [2]. The present invention presents a new means for creating updates and the updates themselves do not apply to the entire 2D image surface, but instead to extracted measurement vectors. InWO2004056089 , FRETWELL PAUL, FAULKNER DAVID ANDREW ALEXANDER (GB) et al, 2004 a claim is made for a method that uses a mask to remove the effect of local motion in estimating global motion. That idea is the same as the weights used by [9], 1995; for the same purpose. However, in [9], the weights are adaptive while inWO2004056089 the weights comprise a fixed, binary mask. Adaptive weights are generally a superior mechanism for coping with global motion, even though more computationally expensive. Finally, inGB2365244 - Direct matching techniques can be attempted for dominant motion estimation. This implies exhaustively searching for the best motion component that would exactly match two image frames. This is known as Block Matching. It is very simple to implement but computationally expensive because of the exhaustive nature of the search process. Since 1992 [5], ad-hoc developments in an alternative strategy for direct matching have emerged. Note that all of these developments have addressed only the problem of discovering the image translation between two images that are identical except for the relative displacement between them. The application domain was not realistic image sequences but instead targeted the image registration problem in satellite imagery. The idea is instead of matching the entire 2D images, it is sensible to match the vertical and horizontal summation of the image. Intuitively it makes sense. Consider that the vertical image projection is the sum of the image intensities along columns. Similarly the horizontal projection is the same along rows. If an image moves upwards, then its horizontal projection also moves upwards. Thus instead of matching an N × M image containing N rows of M columns of digital data, one could just match two vectors containing N and M entries respectively. This is a vast savings in computational cost.
- Since 1992, more schemes have emerged that properly recognise the relationship to motion estimation: 1996 [11], 2002 [7]. However these papers all deal with i) direct matching of integral projections using an exhaustive search and ii) no local motion in the blocks. In the former case, computational expense is lower than direct matching of 2D images, but it is still a cost especially for high resolution. In the latter case these papers do not consider the problem of dominant motion estimation. Integral projections have other applications and were also used by Kim1 et al (1996) for object based video coding.
- Milanfar et al [8, 10] have placed some structure on the previously ad-hoc work. They do so by showing that the integral projections approach can be derived from a Radon Transform of the image. Their work leads to unification of previous approaches and the introduction of the idea that projections along non-cartesian directions could be better in some cases. Again this work does not consider local motion as an issue.
1 Mapping parameter estimation using integral projections and segmented moving objects in object-oriented analysis-synthesis coding, Joon Seek Kim and Rae-Hong Park, Optical Engineering, Vol 35 . - This invention discloses a new means for estimating dominant motion that is more computationally efficient. One embodiment of the invention results in a system using general purpose hardware, that removes random, unwanted global motion at rates in excess of 25 frames per second operating on standard definition 720 × 576 digital television images. The input may be any sequence of image frames from an image source, such as a video camera, an IR or X-ray imagery, radar, or from a storage medium such as computer disk memory, video tape or a computer graphics generator.
- One component of this invention, is a new perspective on Integral Projections which is much simpler to follow than the Transform domain exposition [8]. It is different in that it leads directly to a gradient based approach to matching integral projections. This is computationally cheaper. The gradient based aspect is another component of the invention, along with a refinement process for treating large displacement. In addition, the new result allows a measure to be derived that can check the validity of a projection before motion estimation begins. The invention also incorporates the use of weights in the image space to remove the effect of local motion on the integral projection. Finally, one embodiment of the invention is the use of the Graphics Hardware available in general purpose PCs, PDAs and game consoles (e.g. Sony Playstation) for implementing the projection and compensation unit for an image stabiliser.
- An overview of the process is shown in
Figure 1 . The figure shows the overall system invention, in an embodiment for translational motion. The frame buffer unit is an image delay that can manifest as a framestore holding one previous frame in memory. The frames input to the system need not be consecutive however. The Image Projections and Projection Shift units create and translate projections respectively. These units maybe implemented within the Graphics hardware of modern computers and games consoles. The Gradient Based matching unit calculates the shift between current and previous image frame projections using the method described in this invention. - Dominant motion is estimated based on a single large N × N block centred on each frame. In one embodiment of the invention, a value of N = 512 pixels is used for a 720 × 576 image. This block size is arbitrary and depends on the size of the overall picture. It generally should occupy 90% of the area of the image. All methods described use one dimensional, Integral Projections of this block to estimate global motion. The directions of the projections need not be vertical and horizontal. They may be any set of directions, preferably two orthogonal directions. Consider an integral projection of the image In(h, k), where n is the frame index, h, k are pixel coordinates. The horizontal projection is calculated by summing along rows (horizontal direction) and given by
-
- Consider that an initial estimate of d exists. The initial estimate may be zero. Define this to be d0. Further, consider that it is required to update this estimate such that the result is the actual displacement: d = d0 + u, where u = [ux , uy ] is the update displacement vector. Therefore, the image sequence model can be written as
-
-
-
- The crucial step is to recognise that assuming the motion is the same for a large image area, summing in a particular direction can allow useful approximations. To simplify matters assume ∑ h ε(h, k) = 0 although it is possible to proceed without this assumption. Summing horizontally along rows with respect to h:
- A similar expression exists for summing in the vertical direction. If it were possible to ignore one of the two terms (ii) or (iii) each component of motion could be solved separately. The table below shows the ratio Σ h G y /Σ h Gx for a number of test images which are used as standard in the image processing industry.
Image Ratio Lena 7.1 Sailboat 24.2 Peppers 76.9 - The table shows that term (iii) is more significant than term (ii) in general. This makes sense since summing with respect to h followed by calculating the gradient also with respect to h is equivalent to applying a low-pass filter along the rows followed by a high-pass filter in the same direction. Such a cascade will produce a low energy output. It is sensible then to assume that (ii) =0, which yields the following simplification.
-
-
-
-
- Thus uy can be calculated using integral projections. ux can be calculated similarly, summing along rows k. Hence the connection between Integral projections and motion estimation.
-
-
- Again, the Taylor series expansion can be used to expand the expression above about an initial estimate. However the initial motion estimate is now A0, d0, since both affine motion and translational must be accounted for. Exactly the same steps as above can then be followed, including summing along particular directions to yield a solution for the parameters A, d. In this formulation however it is not possible to straightforwardly separate estimation of each parameter into separate equations even after summation along the projection directions. Nevertheless summation does yield simplification and again a projection based motion estimate results.
- It is possible to use projection directions which are not vertical or horizontal. In fact this is advantageous in order to increase the validity of the crucial assumption in equation 8. To validate a particular projection direction, the term ∑ h Gk /∑ h Gh can be measured. If this value is too low, another projection angle should be used. This ratio can also be used as a prior step before motion estimation to decide on suitable projection directions.
- The Taylor series expansion holds only for small values of dominant motion. This problem can be circumvented by using multiresolution techniques. Coarse to fine refinement of motion estimates on a pyramid of images is one mechanism for dealing with large displacement in the gradient estimation context. Here a 4 level pyramid is employed with a maximum of 10 iterations at each level. The method is called Multi-Res in subsequent sections. A further computational savings is had by noting that the pyramid can be generated in the ID projection space rather than in the 2D image space. Thus the pyramid is built by downsampling 1D projections rather than projecting downsampled images. The savings is on the order of N 2/3 multiply adds.
- Because the manipulation of integral projections requires so little computation, it is possible to propose another, Hybrid technique. Direct matching on the projections using for example cross correlation is performed, at the integer pixel resolution. This leads to an estimate do. The resulting estimate of motion is then used to initialise the gradient based estimator above. This method allows the gradient based method to concentrate on the relatively small motion adjustments required after the gross direct matching is achieved.
- Weights can be used to reduce the effect of objects undergoing local motion on the estimation of global motion. Weighting can be done either in the projections themselves or in the 2D image space. The idea of weighted estimation for this purpose can be found in [9]. This invention applies that idea for use with the projections based, gradient technique given here.
- Applied to the image space, a weight w(h, k) representing a confidence between 0 and 1 can be associated with each pixel site. Each weight can be derived as a function of the observed displaced frame difference (DFD) ∈(x) = In (x) - I n-1(x + d) at that site at each iteration. Note that the DFD is measured by warping the 2D image I n-1 with the current estimate of global motion and subtracting that from the current image In . Large DFD is mapped to low weights and vice versa. One possibility for mapping DFD to weights is the function w(h, k) = 2/(1 + exp(α∈(h, k))) where α adjusts how fast the weights go to 0 as Z gets larger. Many other functions can be used, the essential idea being that large DFD probably indicates a poor image match, hence residual motion, hence local motion. These weights are then used to remove the effect of the corresponding pixels in the integral projections by premultiplying the image with the weights before summation. Each projection element must be scaled by the sum of the weights along the relevant row or column.
- In a similar fashion, weights can be applied directly in the projections space by applying them to modulate gradients and z. Thus a weight is associated with each projection bin by using the same means as mentioned previously except the error measure (DFD) is the difference between current and previous projections (displaced by current motion estimates). Both the gradient and difference vector are multiplied by the weights before a solution is generated for the global motion. This results in a matching process robust to large deviations in the projections space presumably caused by local motion.
- The video frame-rate must be maintained for a real-time implementation. To achieve real-time implementation at this PAL frame rate (25 fps), each frame must be processed in less than 40ms.
- The table below compares the computational complexity of block matching with that of each of the methods proposed as embodiments of the invention. The first column gives the number of operations required based on a single N x N size block, with a range of (+/- w) (where i is the number of iterations and t is the number of taps used in the low pass filter used by the multi resolution method). This does not include the number of computations required to calculate the projections (2N 2). The ratio of computations w.r.t. block matching is also shown (including the calculation of the projections) given values of N = 512, w = 32, i = 20 and t = 15. A value of ratio less than 1 indicates that the algorithm contains proportionately less operations than BM. It is clear from these values the use of integral projections provides a huge reduction in computational complexity.
Method Operations Ratio to BM BM (2ω + 1)2 (N 2) 1 Gradient based 2i (7N) 0.00060 Hybrid 8ωN + 8N + 14iN 0.00073 Multi-Res 0.00074 - Global motion can be caused by: (1) intentional effects like a pan, and (2) the unsteadiness of the camera which is unintentional. The first effect is generally low frequency and exhibits slow temporal variations, whereas the secondary effect could be temporally impulsive. In the case of image sequence stabilisation, after the dominant motion estimation step the measured motion is a combination of unwanted and wanted components. For instance, if a person is holding a camera and pans from left to right, a shaking hand will cause the deviation of the global motion away from the desired pan motion due to the (perhaps) random hand movements. The random hand motion component is unwanted while the pan is desired. The dominant motion estimator will yield a motion estimate that is the sum of these two motions. Thus removing all dominant motion in this case does stabilise the sequence but it also removes the desired pan.
- In one embodiment of the invention, the dominant motion estimator can be coupled with a process for removing unwanted components of motion. It is possible to extract the low frequency (desired) signal by means of a low pass filter [6]. The motion estimate that is required for stabilisation can then be found by simple difference of the output of this filter and the measured motion.
-
- In another situation, the unintentional motion could last for a single frame or be completely random. This is the case in film scanning when frames are displaced randomly from each other because of scanner malfunction or the degradation of the film guide holes. In this situation the filter above cannot reject the impulsive, random component on its own especially when that component is large. A solution is to use a median filter as a detector of large deviations in global motion. Thus the motion estimates are first filtered with a median filter (having at least 3 taps, and preferably 5 taps). This will reject large deviations in the observed global motion. The difference between that median filtered output and the original motion signature will be large at the instances of large impulsive deviation, but small otherwise. By thresholding this difference signal, it is possible to switch between the IIR filter output and the median filter output. Thus the desired component of motion can be estimated regardless of the size and randomness of the global motion.
- Finally, it is noted that when there are changes in the average brightness of the image, the iterative refinement global motion estimate process described above may not converge well.This problem can occur during scene change effects like fades, or if there is degradation of the image leading to brightness fluctuations. This lack of convergence can occur because changes in brightness can cause a fixed offset in z which in turn ensures that the update motion u may not ever become zero. To alleviate this problem it is preferable to normalise the projections to have the same mean and variance before proceeding with the matching step.
- The ability to automatically spot an important event in a video sequence is useful for surveillance and summarisation applications. In sports for instance, a rapid zoom in could indicate an important object is in view. In cricket, a zoom in followed by a zoom out indicates a bowler run up and delivery sequence [1]. In addition, large apparent translations could indicate people entering or leaving a room. For this reason the dominant motion estimation process described here can be used for event spotting since it yields a feature that could be correlated to important events in the video.
- To create the final images for output, each image must be shifted to compensate for the unwanted motion component estimated in previous sections. In order to accurately represent the global motion of a frame, a sub-pixel accurate motion vector is typically required. Interpolation of the image signal is required to motion compensate a frame with a fractional motion vector. Typically bilinear interpolation is sufficient. However this interpolation is computationally very demanding and can be a bottleneck in a real-time shake reduction scheme.
- Modern graphics hardware contain very efficient interpolation units which are used in the texture mapping stage of the graphics pipeline. The graphics hardware can compensate each frame with bilinear interpolation accuracy. This can be done much faster than real-time with the motion compensated sequence displayed on screen. Each motion compensated frame can also be retrieved from the graphics hardware and saved to file if necessary. Because the graphics hardware can work in parallel with the CPU, using it for motion compensation also frees up valuable CPU cycles for other processes. We do not present here the details of the GPU code needed to achieve this. This code will change with generations of GPUs. The point to be made here is that it is one embodiment of this invention that the interpolation unit of the GPU can be used as part of the pipeline for dominant motion estimation and subsequent video stabilisation as required. GPUs produced by NVIDIA ™ and ATI ™ are good vehicles for this implementation. The Sony Playstation ™ is also suitable.
- In addition, dedicated hardware can be built to perform these functions including a combination of FPGA and DSP blocks.
-
- [1] A.Kokaram and P.Delacourt. A new global estimation algorithm and its application to retrieval in sport events. In IEEE International Workshop on Multimedia Signal Pr ocessing, MMSP'01, pages 3-5, October 2001.
- [2] J. Biemond, L. Looijenga, and D.E. Boekee. A pel-recursive Wiener-based displacement estimation algorithm. Signal Processing, 1987.
- [3] P. Bouthémy, M. Gelgon, and F. Ganansia. A unified approach to shot change detection and camera motion characterization. IEEE Transactions on Circuits and Systems for Video Technology, 9:1030-1044, 1999.
- [4] F. Dufaux and J. Konrad. Efficient, robust and fast global motion estimation for video coding. IEEE Transactions on Image Processing, 9:497-501, 2000.
- [5] J.-S. Kim and R.-H. Park. A fast feature-based block matching algorithm using integral projections. IEEE J. Selected Areas in Communications, 10(5):986-971, June 1992.
- [6] A. Kokaram, R. Dahyot, F. Pitié, and H. Denman. Simultaneous luminance and position stabilization for film and video. In Visual Communication and Image Processing,San Jose, California USA, January 2003.
- [7] J. H. Lee and J. B. Ra. Block motion estimation based on selective integral projections. In IEEE ICIP, volume I, pages 689-693, 2002.
- [8] P. Milanfar. A model of the effect of image motion in the radon transform domain. IEEE Trans. on Image Processing, 8(9):1276-1281, 1999.
- [9] J-M. Odobez and P. Bouthémy. Robust multiresolution estimation of parametric motion models. Journal of visual communication and image representation, 6:348-365, 1995.
- [10] Dirk Robinson and Peyman Milanfar. Fast local and global projection-based methods for affine motion estimation. Journal of Mathematical Imaging and Vision, 18:35-54, 2003.
- [11] K. Sauer and B. Schwartz. Efficent block motion estimation using integral projections. IEEE Trans. Circuits and Systems for Video Technology, 6(5):513-518, October 1996.
- [12] P.H.S. Torr. Geometric motion segmentation and model selection. Philosophical Transactions of the Royal Society A, pages 1321-1340, 1998.
Claims (18)
- A method of estimating dominant motion between a current frame n and another frame m of an image sequence having a plurality of frames, each of the frames having a plurality of pixels, the method comprising:generating integral projections of the current frame n and the other frame m; andestimating dominant motion by using gradients of the integral projections of the current frame n and the other frame m and differences between the integral projections of the current frame n and the other frame n to calculate shifts between the integral projections of the current frame n and the other frame m;wherein the dominant motion is a motion associated with most of the pixels of current frame n and is based on the calculated shifts.
- A method according to claim 1, wherein the dominant motion is estimated for a coarse version of the current frame n and other frame m and the dominant motion estimate is successively refined at successively higher frame resolutions of the current frame n and other frame m.
- A method according to any of claims 1-2, wherein the dominant motion is estimated by direct matching of the integral projections and the dominant motion estimate is then refined using gradients of the integral projections.
- A method according to any of claims 1-3, wherein the dominant motion being estimated is translational only.
- A method according to any of claims 1-3, wherein the dominant motion being estimated is translational and affine only.
- A method according to claim 3, wherein a test is applied to validate an effectiveness of one or more projection angles of the integral projections before starting the direct matching.
- A method according to claim 6, wherein different projection angles are used if the test fails at a particular angle.
- A method according to any of claims 1-7, further comprising:stabilising a video sequence using the dominant motion estimate.
- A method according to any of claims 1-7, further comprising:spotting an event in an image sequence using the dominant motion estimate.
- A method according to any of claims 1-7, further comprising:spotting an event in a sports broadcast or image sequence containing sport using the dominant motion estimate.
- A method according to any of claims 1-10, wherein the generation of the integral projections uses a Graphics Processing Unit.
- A method according to any of claims 1-11, further comprising:applying a weight to of at least one of pixels of the current frame n or the other frame n or to the integral projections to suppress an effect of local motion.
- A method according to any of claims 1-12, further comprising:removing unwanted motion components from the estimated dominant motion using an IIR filter.
- A method according to any of claims 1-13 in which the integral projections of each of the current frame n and other frame m are generated over a single sub-block that occupies a substantively large portion of each respective frame.
- A method according to any of claims 1-13 in which the integral projections of each of the current frame n and other frame m are generated over a single sub-block of each respective frame that occupies a region of 512 × 512 pixels, wherein each of the current frame n and other frame n have a frame resolution of 720 × 576 pixels.
- A method according to claim 4, wherein the dominant motion estimates for the coarse version of the current frame n and other frame m and successive refinements at successively higher frame resolutions of the current frame n and other frame m are estimated and refined using a coarse version of the generated integral projection and successively higher resolution versions of the generated integral projections, wherein the coarse version and successively higher resolution versions are created by filtering the generated integral projections.
- A method according to any of claims 1-16, further comprising:estimating desired components of the dominant motion estimate using a combination of an IIR filter and a median filter.
- A method according to any of claims 1-17, further comprising:normalizing the integral projections for mean and variance before estimating the dominant motion.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
GBGB0423578.4A GB0423578D0 (en) | 2004-10-22 | 2004-10-22 | Dominant motion estimation for image sequence processing |
PCT/IE2005/000117 WO2006043258A2 (en) | 2004-10-22 | 2005-10-20 | Dominant motion estimation for image sequence processing |
Publications (2)
Publication Number | Publication Date |
---|---|
EP1864502A2 EP1864502A2 (en) | 2007-12-12 |
EP1864502B1 true EP1864502B1 (en) | 2014-09-03 |
Family
ID=33485094
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP05795066.9A Active EP1864502B1 (en) | 2004-10-22 | 2005-10-20 | Dominant motion estimation for image sequence processing |
Country Status (4)
Country | Link |
---|---|
US (2) | US8385418B2 (en) |
EP (1) | EP1864502B1 (en) |
GB (1) | GB0423578D0 (en) |
WO (1) | WO2006043258A2 (en) |
Families Citing this family (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
SE531372C2 (en) * | 2006-04-25 | 2009-03-17 | Flir Systems Ab | Method for signal conditioning |
US8363919B2 (en) | 2009-11-25 | 2013-01-29 | Imaging Sciences International Llc | Marker identification and processing in x-ray images |
US9082177B2 (en) * | 2009-11-25 | 2015-07-14 | Dental Imaging Technologies Corporation | Method for tracking X-ray markers in serial CT projection images |
US8180130B2 (en) * | 2009-11-25 | 2012-05-15 | Imaging Sciences International Llc | Method for X-ray marker localization in 3D space in the presence of motion |
US9826942B2 (en) * | 2009-11-25 | 2017-11-28 | Dental Imaging Technologies Corporation | Correcting and reconstructing x-ray images using patient motion vectors extracted from marker positions in x-ray images |
US9082036B2 (en) * | 2009-11-25 | 2015-07-14 | Dental Imaging Technologies Corporation | Method for accurate sub-pixel localization of markers on X-ray images |
US9082182B2 (en) * | 2009-11-25 | 2015-07-14 | Dental Imaging Technologies Corporation | Extracting patient motion vectors from marker positions in x-ray images |
US8532197B2 (en) * | 2010-02-16 | 2013-09-10 | The Aerospace Corporation | Methods and systems for detecting temporally oscillating sources in video signals using a recursive infinite impulse response (IIR) filter technique |
CN102098440B (en) * | 2010-12-16 | 2013-01-23 | 北京交通大学 | Electronic image stabilizing method and electronic image stabilizing system aiming at moving object detection under camera shake |
US9224202B2 (en) | 2011-04-14 | 2015-12-29 | Koninklijke Philips N.V. | Device and method for extracting information from characteristic signals |
CN103620621B (en) * | 2011-06-30 | 2017-10-24 | 诺基亚技术有限公司 | For the method and apparatus using the feature tracking for integrating gradient projection |
WO2013095180A1 (en) * | 2011-12-22 | 2013-06-27 | Intel Corporation | Complexity scalable frame rate up-conversion |
US9338352B2 (en) | 2011-12-30 | 2016-05-10 | Flir Systems Ab | Image stabilization systems and methods |
US9326008B2 (en) | 2012-04-10 | 2016-04-26 | Google Inc. | Noise reduction for image sequences |
CA2870789C (en) * | 2012-04-26 | 2017-09-26 | Propagation Research Associates, Inc. | Method and system for using orthogonal space projections to mitigate interference |
US10554965B2 (en) | 2014-08-18 | 2020-02-04 | Google Llc | Motion-compensated partitioning |
US10571224B2 (en) | 2015-05-04 | 2020-02-25 | Propagation Research Associates, Inc. | Systems, methods and computer-readable media for improving platform guidance or navigation using uniquely coded signals |
US10397600B1 (en) | 2016-01-29 | 2019-08-27 | Google Llc | Dynamic reference motion vector coding mode |
US10462457B2 (en) | 2016-01-29 | 2019-10-29 | Google Llc | Dynamic reference motion vector coding mode |
US11018705B1 (en) | 2020-07-17 | 2021-05-25 | Propagation Research Associates, Inc. | Interference mitigation, target detection, location and measurement using separable waveforms transmitted from spatially separated antennas |
TWI809921B (en) * | 2022-06-07 | 2023-07-21 | 齊碩行銷有限公司 | Evaluating method for motion deviation and system thereof |
Family Cites Families (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5384865A (en) * | 1992-06-01 | 1995-01-24 | Eastman Kodak Company | Adaptive, hybrid median filter for temporal noise suppression |
KR100268311B1 (en) * | 1993-06-04 | 2000-10-16 | 윌리암 제이. 버크 | System and method for electronic image stabilization |
GB2307133A (en) * | 1995-11-13 | 1997-05-14 | Secr Defence | Video camera image stabilisation system |
IT1296807B1 (en) * | 1997-03-14 | 1999-08-02 | Alsthom Cge Alcatel | METHOD FOR ESTIMATING THE MOVEMENT IN SEQUENCES OF BLOCK-CODED IMAGES IN PARTICULAR FOR THE PROCESSING OF THE VIDEO SIGNAL |
US6741655B1 (en) * | 1997-05-05 | 2004-05-25 | The Trustees Of Columbia University In The City Of New York | Algorithms and system for object-oriented content-based video search |
GB2365244A (en) * | 2000-07-27 | 2002-02-13 | Snell & Wilcox Ltd | Image stabilisation |
EP1294194B8 (en) * | 2001-09-10 | 2010-08-04 | Texas Instruments Incorporated | Apparatus and method for motion vector estimation |
GB0229096D0 (en) * | 2002-12-13 | 2003-01-15 | Qinetiq Ltd | Image stabilisation system and method |
US7646437B1 (en) * | 2003-09-03 | 2010-01-12 | Apple Inc. | Look-ahead system and method for pan and zoom detection in video sequences |
-
2004
- 2004-10-22 GB GBGB0423578.4A patent/GB0423578D0/en not_active Ceased
-
2005
- 2005-10-20 US US11/577,779 patent/US8385418B2/en not_active Expired - Fee Related
- 2005-10-20 EP EP05795066.9A patent/EP1864502B1/en active Active
- 2005-10-20 WO PCT/IE2005/000117 patent/WO2006043258A2/en active Application Filing
-
2013
- 2013-02-25 US US13/775,301 patent/US20130271666A1/en not_active Abandoned
Also Published As
Publication number | Publication date |
---|---|
GB0423578D0 (en) | 2004-11-24 |
WO2006043258A3 (en) | 2006-06-08 |
US8385418B2 (en) | 2013-02-26 |
WO2006043258A2 (en) | 2006-04-27 |
EP1864502A2 (en) | 2007-12-12 |
US20090122866A1 (en) | 2009-05-14 |
WO2006043258A8 (en) | 2011-06-30 |
US20130271666A1 (en) | 2013-10-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP1864502B1 (en) | Dominant motion estimation for image sequence processing | |
US7221776B2 (en) | Video stabilizer | |
Morimoto et al. | Fast electronic digital image stabilization | |
EP0986252B1 (en) | System and method for electronic image stabilization | |
Matsushita et al. | Full-frame video stabilization with motion inpainting | |
US8718333B2 (en) | System, method and a computer readable medium for providing an output image | |
US7605845B2 (en) | Motion stabilization | |
EP0643539B1 (en) | Motion vector detection apparatus and method | |
KR100985805B1 (en) | Apparatus and method for image stabilization using adaptive Kalman filter | |
Liu et al. | Codingflow: Enable video coding for video stabilization | |
US20110188583A1 (en) | Picture signal conversion system | |
EP1078511A1 (en) | Motion estimation process and system using sparse search block-matching and integral projection | |
EP0792494A1 (en) | Mosaic based image processing system and method for processing images | |
Schallauer et al. | Automatic restoration algorithms for 35mm film | |
Gal et al. | Progress in the restoration of image sequences degraded by atmospheric turbulence | |
US6266371B1 (en) | Motion vector detecting apparatus and method | |
US20110187924A1 (en) | Frame rate conversion device, corresponding point estimation device, corresponding point estimation method and corresponding point estimation program | |
Crawford et al. | Gradient based dominant motion estimation with integral projections for real time video stabilisation | |
US7254279B2 (en) | Method for image stabilization by adaptive filtering | |
US7848541B2 (en) | Differential phase correlation | |
US20050129312A1 (en) | Unit for and method of segmentation | |
Neumann et al. | Adaptive multistage 2D image motion field estimation | |
Rawat et al. | Performance Evaluation of various Temporal Derivatives for Stabilization of Videos with Large Moving Objects | |
Hoshino et al. | Fast panoramic image mosaicing using one-dimensional flow estimation | |
Ferdjali et al. | TOWARDS A DIGITAL VIDEO STABILIZATION APPROACH USING OBJECTIVE IMAGE QUALITY ASSESSMENT METRICS |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20070521 |
|
AK | Designated contracting states |
Kind code of ref document: A2Designated state(s): AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HU IE IS IT LI LT LU LV MC NL PL PT RO SE SI SK TR |
|
DAX | Request for extension of the european patent (deleted) | ||
17Q | First examination report despatched |
Effective date: 20080211 |
|
R17C | First examination report despatched (corrected) |
Effective date: 20080403 |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE INC. |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R079Ref document number: 602005044665Country of ref document: DEFree format text: PREVIOUS MAIN CLASS: H04N0007360000Ipc: H04N0019503000 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: H04N 19/527 20140101ALI20140303BHEPIpc: H04N 19/503 20140101AFI20140303BHEPIpc: H04N 5/14 20060101ALI20140303BHEPIpc: H04N 19/80 20140101ALI20140303BHEPIpc: G06T 7/20 20060101ALI20140303BHEP |
|
INTG | Intention to grant announced |
Effective date: 20140327 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HU IE IS IT LI LT LU LV MC NL PL PT RO SE SI SK TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R081Ref document number: 602005044665Country of ref document: DEOwner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GREENPARROTPICTURES LTD., BRAY WICKLOW, IE |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: REFRef document number: 686137Country of ref document: ATKind code of ref document: TEffective date: 20140915Ref country code: CHRef legal event code: EP |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602005044665Country of ref document: DEEffective date: 20141016 |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 686137Country of ref document: ATKind code of ref document: TEffective date: 20140903 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20141204Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903 |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: VDEPEffective date: 20140903 |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: NLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150105Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150103 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602005044665Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20141031 |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: MM4A |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20141031Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20141031 |
|
26N | No opposition filed |
Effective date: 20150604 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903 |
|
REG | Reference to a national code |
Ref country code: FRRef legal event code: PLFPYear of fee payment: 11 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: IEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20141020 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: FRPayment date: 20151019Year of fee payment: 11 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: HUFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMIT; INVALID AB INITIOEffective date: 20051020Ref country code: TRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: BEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20140903Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20141020 |
|
REG | Reference to a national code |
Ref country code: FRRef legal event code: STEffective date: 20170630 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: FRFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20161102 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R082Ref document number: 602005044665Country of ref document: DERepresentative=s name: MARKS & CLERK (LUXEMBOURG) LLP, LURef country code: DERef legal event code: R081Ref document number: 602005044665Country of ref document: DEOwner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GOOGLE, INC., MOUNTAIN VIEW, CALIF., US |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230505 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: GBPayment date: 20231027Year of fee payment: 19 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: DEPayment date: 20231027Year of fee payment: 19 |