KR20230170975A - Wireless networks using neural networks for channel state feedback - Google Patents
Wireless networks using neural networks for channel state feedback Download PDFInfo
- Publication number
- KR20230170975A KR20230170975A KR1020237040314A KR20237040314A KR20230170975A KR 20230170975 A KR20230170975 A KR 20230170975A KR 1020237040314 A KR1020237040314 A KR 1020237040314A KR 20237040314 A KR20237040314 A KR 20237040314A KR 20230170975 A KR20230170975 A KR 20230170975A
- Authority
- KR
- South Korea
- Prior art keywords
- neural network
- csi
- receiving
- csf
- output
- Prior art date
Links
- 238000013528 artificial neural network Methods 0.000 title claims abstract description 267
- 238000000034 method Methods 0.000 claims abstract description 189
- 230000008569 process Effects 0.000 claims abstract description 120
- 238000012545 processing Methods 0.000 claims description 91
- 230000005540 biological transmission Effects 0.000 claims description 48
- 230000015654 memory Effects 0.000 claims description 26
- 230000004044 response Effects 0.000 claims description 11
- 230000011664 signaling Effects 0.000 abstract description 24
- 238000012549 training Methods 0.000 description 72
- 238000010801 machine learning Methods 0.000 description 43
- 238000012360 testing method Methods 0.000 description 38
- 238000004891 communication Methods 0.000 description 33
- 238000013459 approach Methods 0.000 description 21
- 238000010586 diagram Methods 0.000 description 17
- 238000011176 pooling Methods 0.000 description 12
- 230000006870 function Effects 0.000 description 11
- 238000003384 imaging method Methods 0.000 description 10
- 230000008901 benefit Effects 0.000 description 9
- 238000004422 calculation algorithm Methods 0.000 description 8
- 238000005516 engineering process Methods 0.000 description 8
- 230000003287 optical effect Effects 0.000 description 7
- 239000011159 matrix material Substances 0.000 description 6
- 238000013527 convolutional neural network Methods 0.000 description 5
- 238000013461 design Methods 0.000 description 5
- 230000000694 effects Effects 0.000 description 5
- 230000003044 adaptive effect Effects 0.000 description 4
- 238000004458 analytical method Methods 0.000 description 4
- 230000008859 change Effects 0.000 description 4
- 238000001514 detection method Methods 0.000 description 4
- 239000000284 extract Substances 0.000 description 4
- 238000012986 modification Methods 0.000 description 4
- 230000004048 modification Effects 0.000 description 4
- 238000013139 quantization Methods 0.000 description 4
- 230000001413 cellular effect Effects 0.000 description 3
- 210000002569 neuron Anatomy 0.000 description 3
- 230000000306 recurrent effect Effects 0.000 description 3
- 230000004913 activation Effects 0.000 description 2
- 238000003491 array Methods 0.000 description 2
- 238000004364 calculation method Methods 0.000 description 2
- 238000012512 characterization method Methods 0.000 description 2
- 230000000295 complement effect Effects 0.000 description 2
- 230000002452 interceptive effect Effects 0.000 description 2
- 238000012417 linear regression Methods 0.000 description 2
- 238000005259 measurement Methods 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 230000000737 periodic effect Effects 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 239000007787 solid Substances 0.000 description 2
- 238000011144 upstream manufacturing Methods 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 230000002730 additional effect Effects 0.000 description 1
- -1 and upon completion Substances 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000003542 behavioural effect Effects 0.000 description 1
- 210000004027 cell Anatomy 0.000 description 1
- 238000006243 chemical reaction Methods 0.000 description 1
- 230000006835 compression Effects 0.000 description 1
- 238000007906 compression Methods 0.000 description 1
- 238000012790 confirmation Methods 0.000 description 1
- 238000010276 construction Methods 0.000 description 1
- 238000010219 correlation analysis Methods 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 238000011156 evaluation Methods 0.000 description 1
- 238000009499 grossing Methods 0.000 description 1
- 238000007477 logistic regression Methods 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 238000010606 normalization Methods 0.000 description 1
- 230000035515 penetration Effects 0.000 description 1
- 230000001902 propagating effect Effects 0.000 description 1
- 238000011084 recovery Methods 0.000 description 1
- 238000000611 regression analysis Methods 0.000 description 1
- 230000003595 spectral effect Effects 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000007619 statistical method Methods 0.000 description 1
- 238000012706 support-vector machine Methods 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04B—TRANSMISSION
- H04B7/00—Radio transmission systems, i.e. using radiation field
- H04B7/02—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas
- H04B7/04—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas
- H04B7/06—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station
- H04B7/0613—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission
- H04B7/0615—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission of weighted versions of same signal
- H04B7/0619—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission of weighted versions of same signal using feedback from receiving side
- H04B7/0621—Feedback content
- H04B7/0626—Channel coefficients, e.g. channel state information [CSI]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04B—TRANSMISSION
- H04B17/00—Monitoring; Testing
- H04B17/30—Monitoring; Testing of propagation channels
- H04B17/373—Predicting channel quality or other radio frequency [RF] parameters
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04B—TRANSMISSION
- H04B7/00—Radio transmission systems, i.e. using radiation field
- H04B7/02—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas
- H04B7/04—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas
- H04B7/0413—MIMO systems
- H04B7/0452—Multi-user MIMO systems
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04B—TRANSMISSION
- H04B7/00—Radio transmission systems, i.e. using radiation field
- H04B7/02—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas
- H04B7/04—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas
- H04B7/06—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station
- H04B7/0613—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission
- H04B7/0615—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission of weighted versions of same signal
- H04B7/0617—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission of weighted versions of same signal for beam forming
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04B—TRANSMISSION
- H04B7/00—Radio transmission systems, i.e. using radiation field
- H04B7/02—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas
- H04B7/04—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas
- H04B7/06—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station
- H04B7/0613—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission
- H04B7/0615—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission of weighted versions of same signal
- H04B7/0619—Diversity systems; Multi-antenna system, i.e. transmission or reception using multiple antennas using two or more spaced independent antennas at the transmitting station using simultaneous transmission of weighted versions of same signal using feedback from receiving side
- H04B7/0658—Feedback reduction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L25/00—Baseband systems
- H04L25/02—Details ; arrangements for supplying electrical power along data transmission lines
- H04L25/0202—Channel estimation
- H04L25/024—Channel estimation channel estimation algorithms
- H04L25/0254—Channel estimation channel estimation algorithms using neural network algorithms
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W8/00—Network data management
- H04W8/22—Processing or transfer of terminal data, e.g. status or physical capabilities
- H04W8/24—Transfer of terminal data
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L1/00—Arrangements for detecting or preventing errors in the information received
- H04L1/0001—Systems modifying transmission characteristics according to link quality, e.g. power backoff
- H04L1/0023—Systems modifying transmission characteristics according to link quality, e.g. power backoff characterised by the signalling
- H04L1/0026—Transmission of channel quality indication
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L1/00—Arrangements for detecting or preventing errors in the information received
- H04L1/0001—Systems modifying transmission characteristics according to link quality, e.g. power backoff
- H04L1/0023—Systems modifying transmission characteristics according to link quality, e.g. power backoff characterised by the signalling
- H04L1/0028—Formatting
- H04L1/0029—Reduction of the amount of signalling, e.g. retention of useful signalling or differential signalling
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L25/00—Baseband systems
- H04L25/02—Details ; arrangements for supplying electrical power along data transmission lines
- H04L25/0202—Channel estimation
- H04L25/0224—Channel estimation using sounding signals
Abstract
무선 시스템(100)은 신경망(122, 128)을 사용하여 송신 장치(108)와 수신 장치(110) 사이의 CSI 추정 피드백을 제공한다. 관리 컴포넌트(140)는 성능 정보(146, 148)에 기초하여 송신 및 수신 장치에서 구현하기 위한 신경망 아키텍처 구성(144)을 선택한다. 수신 장치는 송신 장치로부터의 CSI 파일럿 시그널링으로부터 CSI 추정치(들)(134)를 결정한다. CSI 추정치(들)는 수신 장치에서 신경망(들)에 의해 처리되어 CSF 출력(136)을 생성하고, 이는 예를 들어 하나 이상의 예측된 미래 CSI 추정치를 나타낼 수 있으며 송신 장치에 무선으로 전송된다. 그러면 송신 장치의 하나 이상의 신경망은 수신된 CSF 출력을 처리하여 하나 이상의 복구된 예측된 미래 CSI 추정치를 생성하고(138), 이는 송신 장치에서 하나 이상의 MIMO 프로세스를 제어하는데 사용된다.Wireless system 100 uses neural networks 122 and 128 to provide CSI estimate feedback between transmitting device 108 and receiving device 110. The management component 140 selects a neural network architecture configuration 144 for implementation in the transmitting and receiving devices based on the performance information 146, 148. The receiving device determines CSI estimate(s) 134 from CSI pilot signaling from the transmitting device. The CSI estimate(s) are processed by the neural network(s) at the receiving device to generate a CSF output 136, which may represent, for example, one or more predicted future CSI estimates, and are transmitted wirelessly to the transmitting device. One or more neural networks at the transmitting device then process the received CSF output to generate one or more recovered predicted future CSI estimates (138), which are used to control one or more MIMO processes at the transmitting device.
Description
무선 통신 시스템은 종종 경로 손실, 산란, 신호 회절, 침투 손실 등과 같이 주파수에 따라 달라지는 여러 가지 신호 전파 문제에 직면한다. 3GPP(3세대 파트너십) LTE(Long Term Evolution) 및 5G NR(5세대 New Radio) 셀룰러 표준 또는 특정 IEEE 802.11 무선 근거리 통신망(WLAN) 표준을 준수하는 시스템과 같이 고주파수에 의존하는 많은 무선 전송 방식에서는 이러한 신호 전파 문제를 완화하기 위해 다양한 다중 입력 다중 출력(MIMO) 기술을 사용했다.Wireless communication systems often face several frequency-dependent signal propagation problems, such as path loss, scattering, signal diffraction, penetration loss, etc. Many wireless transmission methods rely on high frequencies, such as systems that comply with the Third Generation Partnership (3GPP) Long Term Evolution (LTE) and Fifth Generation New Radio (5G NR) cellular standards or certain IEEE 802.11 wireless local area network (WLAN) standards. Various multiple-input multiple-output (MIMO) techniques were used to alleviate signal propagation problems.
빔포밍 기술, 시공간 코딩 기술, 다중 사용자 MIMO(MU-MIMO) 기술과 같은 많은 MIMO 기술은 현재 신호 전파 환경에서 식별된 채널에 대해 하나 이상의 해당 반송파 주파수에서 무선 신호가 어떻게 전파되는지에 대한 이해 또는 특성화에 의존하거나 적어도 이점을 얻는다. 일반적으로, 이 채널 추정은 채널 상태 정보(CSI)로서 제공된다. CSI는 종종 하나 이상의 행렬 형태를 취하며, 각 행렬 항목은 해당 반송파 주파수에 대한 전달 함수, 보다 구체적으로는 채널 주파수 응답(CFR)을 나타내는 정보를 저장한다. 채널의 CSI를 확인하기 위해, 송신 장치는 IEEE 802.11 기반 시스템에 대한 긴 트레이닝 심볼(Long Training Symbol: LTE)와 같은 하나 이상의 CSI 파일럿 심볼을 수신 장치에 무선으로 전송하고, 수신 장치는 전송된 CSI 파일럿 심볼의 수신 형태를 사용하여 하나 이상의 CSI 파일럿 심볼을 전송하는데 사용된 해당 반송파 주파수에 대한 적어도 하나의 CSI 추정치를 계산한다. 수신 장치는 CSI 추정치를 이용하여 주어진 채널에 대한 MIMO 수신 프로세스를 관리할 수 있다. 이 CSI 추정치는 송신 장치가 그에 따라 자신의 MIMO 전송 프로세스 중 하나 이상을 관리할 수 있도록 송신 장치에 다시 무선으로 제공될 수 있다(이 피드백 프로세스는 일반적으로 "채널 상태 피드백"(CSF)으로 지칭됨).Many MIMO technologies, such as beamforming technology, space-time coding technology, and multi-user MIMO (MU-MIMO) technology, are used to understand or characterize how wireless signals propagate on one or more corresponding carrier frequencies for an identified channel in the current signal propagation environment. Depends on, or at least takes advantage of. Typically, this channel estimate is provided as channel state information (CSI). CSI often takes the form of one or more matrices, with each matrix entry storing information representing the transfer function for that carrier frequency, more specifically the channel frequency response (CFR). To determine the CSI of a channel, the transmitting device wirelessly transmits one or more CSI pilot symbols, such as the Long Training Symbol (LTE) for IEEE 802.11-based systems, to the receiving device, and the receiving device responds to the transmitted CSI pilot. The received form of the symbol is used to calculate at least one CSI estimate for the corresponding carrier frequency used to transmit one or more CSI pilot symbols. The receiving device can manage the MIMO reception process for a given channel using the CSI estimate. This CSI estimate may be provided wirelessly back to the transmitting device so that the transmitting device can manage one or more of its MIMO transmission processes accordingly (this feedback process is commonly referred to as "channel state feedback" (CSF)) ).
파일럿 심볼을 전송하고, 수신된 파일럿 심볼로부터 CSI 추정치를 계산하고, 이어서 CSI 추정치를 송신 장치로 다시 보고하는 전반적인 프로세스는 일반적으로 이 프로세스의 각 단계 또는 스테이지가 한 명 이상의 디자이너에 의해 개별적으로 "수작업"되는 알고리즘식, 모듈식 접근 방식을 통해 구현된다. 각 단계의 상대적 복잡성은 일반적으로 프로세스의 하드 코딩된 구현을 설계, 테스트 및 구현하는데 있어 그에 상응하는 복잡성을 의미한다. 게다가, 수신 장치에서 CSI 추정치의 복잡한 알고리즘 계산은 수신 장치의 상당한 자원을 소비할 수 있는 반면, 일반적인 형태의 CSI 추정치의 빈번한 무선 전송은 수신 장치를 송신 장치에 연결하는 채널에서 상당한 대역폭을 소비할 수 있다. 이와 같이, 변화하는 조건에 잘 적응하고 전송 지연시간(latency) 감소 및 자원 소비 감소에 매우 효율적인 강력한 채널 추정 프로세스를 설계하고 구현하는 것은 어려울 수 있다.The overall process of transmitting pilot symbols, calculating CSI estimates from the received pilot symbols, and subsequently reporting the CSI estimates back to the transmitting device is typically a process in which each step or stages of this process are individually "manufactured" by one or more designers. “It is implemented through an algorithmic, modular approach. The relative complexity of each step usually means the corresponding complexity in designing, testing, and implementing a hard-coded implementation of the process. Moreover, complex algorithmic computation of CSI estimates at the receiving device can consume significant resources of the receiving device, while frequent wireless transmission of CSI estimates in the form of a common form can consume significant bandwidth in the channel connecting the receiving device to the transmitting device. there is. As such, it can be difficult to design and implement a robust channel estimation process that adapts well to changing conditions and is highly efficient in reducing transmission latency and resource consumption.
일부 실시예에 따르면, 제1 장치의 컴퓨터로 구현되는 방법은 제1 장치의 적어도 하나의 성능을 나타내는 성능 정보를 인프라 컴포넌트(구성요소)에 제공하는 것에 응답하여 신경망 아키텍처 구성의 표시를 수신하는 단계와; 제1 장치의 송신 신경망에서 신경망 아키텍처 구성을 구현하는 단계와; 송신 신경망에 대한 입력으로서 채널 상태 정보(CSI) 추정치의 표현을 수신하는 단계와; 송신 신경망에서, CSI 추정치의 표현에 기초하여 제1 출력을 생성하는 단계와, 제1 출력은 미래 시점에 대한 CSI 추정치의 예측 표현의 압축된 버전을 나타내고; 그리고 제2 장치에 의한 수신을 위해 제1 출력을 나타내는 제1 RF 신호를 전송하도록 제1 장치의 무선 주파수(RF) 안테나 인터페이스를 제어하는 단계를 포함한다. According to some embodiments, a computer-implemented method of a first device includes receiving an indication of a neural network architecture configuration in response to providing performance information indicative of at least one performance of the first device to an infrastructure component. and; implementing a neural network architecture configuration in a transmit neural network of the first device; Receiving a representation of channel state information (CSI) estimates as input to a transmit neural network; In a transmit neural network, generating a first output based on the representation of the CSI estimate, the first output representing a compressed version of the predictive representation of the CSI estimate for a future point in time; and controlling a radio frequency (RF) antenna interface of the first device to transmit a first RF signal representative of the first output for reception by the second device.
다양한 실시예에서, 이 방법은 다음의 양태들 중 하나 이상을 추가로 포함할 수 있다. 방법은 제2 장치로부터 수신된 하나 이상의 RF 신호에 기초하여 CSI 추정치를 알고리즘적으로 결정하는 단계를 더 포함한다. 제1 출력은 미래 시점에 대한 CSI 추정치의 예측(즉, 예측된 미래 CSI 추정치)을 추가로 나타낸다. 제1 출력을 생성하는 단계는 송신 신경망에 대한 입력으로 제공된 제2 장치의 다중 입력 다중 출력(MIMO) 프로세스의 스케줄링 대기시간의 표현에 더 기초하여 송신 신경망에서 제1 출력을 생성하는 단계를 더 포함한다. 송신 신경망은 스케줄링 대기시간에 대한 표현을 입력으로 수신한다. 신경망 아키텍처 구성은 스케줄링 대기시간에 기초하여 복수의 후보 신경망 아키텍처 구성으로부터 송신 신경망에 대해 선택된다. 성능 정보에 의해 표현되는 적어도 하나의 성능은 안테나 성능; 처리 성능; 전원 성능; 또는 센서 성능 중 적어도 하나를 포함한다. 신경망 아키텍처 구성은 제1 장치의 적어도 하나의 성능, 제2 장치의 적어도 하나의 성능, CSI 추정치에 의해 표현된 채널의 주파수 또는 대역; 또는 제1 장치의 현재 신호 전파 환경 중 적어도 하나에 기초하여 복수의 신경망 아키텍처 구성으로부터 선택된다. 신경망 아키텍처 구성의 표시를 수신하는 단계는 제1 장치에 로컬로 저장된 복수의 후보 신경망 아키텍처 구성 중 하나와 연관된 식별자를 수신하는 단계; 또는 신경망 아키텍처 구성의 파라미터를 나타내는 하나 이상의 데이터 구조를 수신하는 단계 중 적어도 하나를 포함한다. 제1 출력을 생성하는 단계는 제1 장치의 하나 이상의 센서로부터 송신 신경망에 입력된 센서 데이터; 또는 RF 안테나 인터페이스의 적어도 하나의 동작 파라미터에 매개변수 중 적어도 하나에 더 기초하여 송신 신경망에서 제1 출력을 생성하는 단계를 포함한다. 방법은 제2 장치의 수신 신경망에 대한 수신 신경망 아키텍처 구성과 송신 신경망에 대한 전송 신경망 아키텍처 구성의 공동 트레이닝에 참여하는 단계를 더 포함한다. 방법은 또한 제1 장치의 수신 신경망의 입력으로서 CSI 파일럿 신호의 표현을 수신하는 단계와; 그리고 수신 신경망에서, CSI 파일럿 신호의 표현에 기초하여 제2 출력을 생성하는 단계를 포함하고, 제2 출력은 CSI 추정치의 표현을 포함한다. 제2 출력을 생성하는 단계는 제1 장치의 하나 이상의 센서로부터의 센서 데이터, CSI 추정치와 연관된 채널의 반송파 주파수, 또는 제1 장치의 안테나 인터페이스에 대한 동작 파라미터 중 적어도 하나에 기초하여 수신 신경망에서 제2 출력을 생성하는 단계를 더 포함한다. 송신 신경망은 심층 신경망(DNN)이다.In various embodiments, the method may further include one or more of the following aspects. The method further includes algorithmically determining a CSI estimate based on one or more RF signals received from the second device. The first output further represents a prediction of the CSI estimate for a future point in time (i.e., the predicted future CSI estimate). Generating the first output further includes generating a first output in the transmit neural network based further on a representation of the scheduling latency of a multiple-input multiple-output (MIMO) process of the second device provided as input to the transmit neural network. do. The transmission neural network receives an expression for scheduling latency as input. A neural network architecture configuration is selected for the transmit neural network from a plurality of candidate neural network architecture configurations based on scheduling latency. At least one performance expressed by the performance information includes antenna performance; processing performance; power performance; or at least one of sensor performance. The neural network architecture configuration includes at least one capability of the first device, at least one capability of the second device, frequency or band of the channel represented by the CSI estimate; or selected from a plurality of neural network architecture configurations based on at least one of the current signal propagation environment of the first device. Receiving an indication of a neural network architecture configuration may include receiving an identifier associated with one of a plurality of candidate neural network architecture configurations stored locally on the first device; or receiving one or more data structures representing parameters of a neural network architecture configuration. Generating the first output may include sensor data input to a transmission neural network from one or more sensors of the first device; or generating a first output in the transmit neural network further based on at least one of the parameters in at least one operating parameter of the RF antenna interface. The method further includes engaging in joint training of a receive neural network architecture configuration for the receive neural network of the second device and a transmit neural network architecture configuration for the transmit neural network. The method also includes receiving a representation of the CSI pilot signal as input to a receiving neural network of the first device; and, in the receiving neural network, generating a second output based on the representation of the CSI pilot signal, wherein the second output includes a representation of the CSI estimate. Generating a second output may include generating a second output in a receiving neural network based on at least one of sensor data from one or more sensors of the first device, a carrier frequency of a channel associated with the CSI estimate, or an operating parameter for an antenna interface of the first device. 2 It further includes the step of generating output. The transmitting neural network is a deep neural network (DNN).
일부 실시예에 따르면, 제1 장치의 컴퓨터 구현 방법은 제1 장치의 적어도 하나의 성능을 나타내는 성능 정보를 인프라 컴포넌트에 제공하는 것에 응답하여 신경망 아키텍처 구성의 표시를 수신하는 단계와; 제1 장치의 수신 신경망에서 신경망 아키텍처 구성을 구현하는 단계와; 제1 장치의 무선 주파수(RF) 안테나 인터페이스에서, 제2 장치로부터 제1 RF 신호를 수신하는 단계와, 상기 제1 RF 신호는 예측된 미래 채널 상태 정보(CSI) 추정치의 압축된 표현을 나타내고; 수신 신경망에 대한 입력으로서 제1 RF 신호의 표현을 제공하는 단계와; 수신 신경망에서, 수신 신경망에 대한 입력에 기초하여 예측된 미래 CSI 추정치를 생성하는 단계와; 그리고 예측된 미래 CSI 추정에 기초하여 제1 장치에서 적어도 하나의 다중 입력 다중 출력(MIMO) 프로세스를 관리하는 단계를 포함한다. According to some embodiments, a computer-implemented method of a first device includes receiving an indication of a neural network architecture configuration in response to providing performance information indicative of at least one performance of the first device to an infrastructure component; implementing a neural network architecture configuration in a receiving neural network of the first device; At a radio frequency (RF) antenna interface of the first device, receiving a first RF signal from a second device, the first RF signal representing a compressed representation of a predicted future channel state information (CSI) estimate; providing a representation of the first RF signal as input to a receiving neural network; generating, in the receiving neural network, a predicted future CSI estimate based on the input to the receiving neural network; and managing at least one multiple-input multiple-output (MIMO) process at the first device based on the predicted future CSI estimate.
다양한 실시예에서, 이 방법은 다음 양태들 중 하나 이상을 추가로 포함할 수 있다. 신경망 아키텍처 구성은 제1 장치의 적어도 하나의 성능, 제2 장치의 적어도 하나의 성능, 예측된 미래 CSI 추정치에 의해 표현되는 채널의 주파수 또는 대역, 또는 제1 장치의 현재 신호 전파 환경 중 적어도 하나에 기초하여 복수의 신경망 아키텍처 구성으로부터 선택된다. 신경망 아키텍처 구성의 표시를 수신하는 단계는 제1 장치에 로컬로 저장된 복수의 후보 신경망 아키텍처 구성 중 하나와 연관된 식별자를 수신하는 단계; 또는 신경망 아키텍처 구성의 파라미터를 나타내는 하나 이상의 데이터 구조를 수신하는 단계 중 적어도 하나를 포함한다. 예측된 미래 CSI 추정치를 생성하는 단계는 제1 디바이스의 하나 이상의 센서로부터 수신 신경망에 입력된 센서 데이터; 또는 RF 안테나 인터페이스의 현재 동작 파라미터 중 적어도 하나에 더 기초하여 수신 신경망에서 예측된 미래 CSI 추정치를 생성하는 단계를 포함한다. 방법은 제2 장치의 송신 신경망을 위한 신경망 아키텍처 구성과 수신 신경망을 위한 신경망 아키텍처 구성의 공동 트레이닝에 참여하는 단계를 더 포함한다. 방법은 또한 제1 장치의 송신 신경망에서 CSI 파일럿 신호를 생성하는 단계와; 그리고 제2 장치에 의한 수신을 위해 CSI 파일럿 신호를 나타내는 제2 RF 신호를 전송하도록 제1 장치의 RF 안테나 인터페이스를 제어하는 단계를 포함한다. CSI 파일럿 신호를 생성하는 단계는 예측된 미래 CSI 추정치와 연관된 채널의 반송파 주파수, 또는 제1 장치의 RF 안테나 인터페이스에 대한 적어도 하나의 동작 파라미터 중 적어도 하나에 더 기초하여 송신 신경망에서 CSI 파일럿 신호를 생성하는 단계를 포함한다. CSI 파일럿 신호를 생성하는 단계는 제1 장치의 하나 이상의 센서로부터의 센서 데이터, 예측된 미래 CSI 추정치와 연관된 채널의 반송파 주파수, 또는 제1 디바이스의 안테나 인터페이스에 대한 적어도 하나의 동작 파라미터 중 적어도 하나에 기초하여 송신 신경망에서 CSI 파일럿 신호를 생성하는 단계를 더 포함한다. 예측된 미래 CSI 추정치를 생성하는 단계는 제1 장치의 하나 이상의 센서로부터의 센서 데이터, 예측된 미래 CSI 추정치와 연관된 채널의 반송파 주파수, 또는 제1 장치의 RF 안테나 인터페이스에 대한 적어도 하나의 동작 파라미터 중 적어도 하나에 기초하여 송신 신경망에서 예측된 미래 CSI 추정값을 생성하는 단계를 더 포함한다. 적어도 하나의 MIMO 프로세스는 빔포밍 프로세스, 시공간 코딩 프로세스, 및 다중 사용자 MIMO 프로세스 중 적어도 하나를 포함한다. 적어도 하나의 성능은 안테나 성능, 처리 성능, 전원 성능, 또는 센서 성능 중 적어도 하나를 포함한다. 수신 신경망은 심층 신경망(DNN)을 포함한다.In various embodiments, the method may further include one or more of the following aspects. The neural network architecture configuration is based on at least one of the following: at least one performance of the first device, at least one performance of the second device, the frequency or band of the channel represented by the predicted future CSI estimate, or the current signal propagation environment of the first device. Based on the configuration, a plurality of neural network architectures are selected. Receiving an indication of a neural network architecture configuration may include receiving an identifier associated with one of a plurality of candidate neural network architecture configurations stored locally on the first device; or receiving one or more data structures representing parameters of a neural network architecture configuration. Generating a predicted future CSI estimate may include sensor data input to a receiving neural network from one or more sensors of the first device; or generating a predicted future CSI estimate in the receiving neural network further based on at least one of the current operating parameters of the RF antenna interface. The method further includes engaging in joint training of a neural network architecture configuration for a transmit neural network and a neural network architecture configuration for a receive neural network of the second device. The method also includes generating a CSI pilot signal in a transmit neural network of the first device; and controlling the RF antenna interface of the first device to transmit a second RF signal representing the CSI pilot signal for reception by the second device. Generating the CSI pilot signal further comprises generating the CSI pilot signal in the transmit neural network based further on at least one of the carrier frequency of the channel associated with the predicted future CSI estimate, or at least one operating parameter for the RF antenna interface of the first device. It includes steps to: Generating a CSI pilot signal may include at least one of sensor data from one or more sensors of the first device, a carrier frequency of a channel associated with a predicted future CSI estimate, or at least one operating parameter for an antenna interface of the first device. It further includes generating a CSI pilot signal in the transmission neural network based on the transmission neural network. Generating the predicted future CSI estimate may include sensor data from one or more sensors of the first device, a carrier frequency of a channel associated with the predicted future CSI estimate, or at least one operating parameter for an RF antenna interface of the first device. It further includes generating a predicted future CSI estimate in the transmission neural network based on at least one. The at least one MIMO process includes at least one of a beamforming process, a space-time coding process, and a multi-user MIMO process. The at least one performance includes at least one of antenna performance, processing performance, power performance, or sensor performance. Receiving neural networks include deep neural networks (DNNs).
일부 실시예에 따르면, 컴퓨터 구현 방법은 제1 장치 또는 제2 장치 중 적어도 하나로부터 성능 정보를 수신하는 단계와, 상기 성능 정보는 제1 장치 또는 제2 장치 중 대응하는 하나의 적어도 하나의 성능을 나타내고; 성능 정보에 기초하여 후보 신경망 아키텍처 구성 세트로부터 신경망 아키텍처 구성 쌍을 선택하는 단계와, 상기 신경망 아키텍처 구성 쌍은 제1 장치와 제2 장치 간의 채널 상태 정보(CSI) 추정 피드백 프로세스를 구현하기 위해 공동으로 트레이닝되고; 제1 장치의 송신 신경망에서의 구현을 위해 상기 쌍의 제1 신경망 아키텍처 구성의 제1 표시를 제1 장치로 전송하는 단계와; 그리고 제2 장치의 수신 신경망에서의 구현을 위해 상기 쌍의 제2 신경망 아키텍처 구성의 제2 표시를 제2 장치로 전송하는 단계를 포함한다. 적어도 하나의 성능은 안테나 성능, 처리 성능, 전원 성능, 또는 센서 성능 중 적어도 하나를 포함한다. 송신 신경망과 수신 신경망은 각각 심층 신경망(DNN)을 포함한다.According to some embodiments, a computer-implemented method includes receiving performance information from at least one of a first device or a second device, wherein the performance information indicates at least one performance of a corresponding one of the first device or the second device. represents; selecting a neural network architecture configuration pair from a set of candidate neural network architecture configurations based on the performance information, the neural network architecture configuration pairs jointly implementing a channel state information (CSI) estimation feedback process between the first device and the second device; trained; transmitting a first indication of a first neural network architecture configuration of the pair to a first device for implementation in a transmitting neural network of the first device; and transmitting a second indication of the pair of second neural network architecture configurations to a second device for implementation in a receiving neural network of the second device. The at least one performance includes at least one of antenna performance, processing performance, power performance, or sensor performance. The transmitting neural network and receiving neural network each include a deep neural network (DNN).
일부 실시예에서, 장치는 네트워크 인터페이스, 네트워크 인터페이스에 연결된 적어도 하나의 프로세서, 및 실행 가능한 명령들을 저장하는 메모리를 포함하고, 실행 가능한 명령들은 위에서 및 본 명세서에 기술된 방법 중 하나를 수행하기 위해 적어도 하나의 프로세서를 조작하도록 구성된다.In some embodiments, a device includes a network interface, at least one processor coupled to the network interface, and memory storing executable instructions, the executable instructions being configured to perform at least one of the methods described above and herein. It is configured to operate one processor.
본 개시 내용은 첨부된 도면을 참조함으로써 당업자에게 더 잘 이해되고 수많은 특징 및 이점이 명백해진다. 서로 다른 도면에서 동일한 참조 기호를 사용하는 것은 유사하거나 동일한 항목을 나타낸다.
도 1은 일부 실시예에 따른 무선 채널을 특성화하기 위해 채널 상태 피드백(CSF) 신경망 방식을 사용하는 예시적인 무선 시스템을 도시하는 도면이다.
도 2는 일부 실시예에 따른 도 1의 무선 시스템의 사용자 장비(UE)의 예시적인 하드웨어 구성을 도시하는 도면이다.
도 3은 일부 실시예에 따른 도 1의 무선 시스템의 기지국(BS)의 예시적인 하드웨어 구성을 도시하는 도면이다.
도 4는 일부 실시예에 따른 도 1의 무선 시스템의 관리 인프라 컴포넌트의 예시적인 하드웨어 구성을 도시하는 도면이다.
도 5는 일부 실시예에 따른 CSF 신경망 방식에 사용하기 위한 신경망을 사용하는 기계 학습(ML) 모듈을 도시하는 도면이다.
도 6은 일부 실시예에 따른 UE와 BS 사이의 CSI 추정치의 처리 및 전송을 위한 공동 트레이닝된 신경망 쌍을 도시하는 도면이다.
도 7은 일부 실시예에 따른 무선 시스템에서 CSF를 촉진하기 위한 신경망 세트의 공동 트레이닝을 위한 예시적인 방법을 도시하는 흐름도이다.
도 8은 일부 실시예에 따른 선택되고 공동으로 트레이닝된 신경망 세트를 사용하여 CSI 추정치의 피드백을 위한 예시적인 방법을 도시하는 흐름도이다.
도 9는 일부 실시예에 따른 도 8의 방법의 예시적인 동작을 도시하는 사다리 시그널링 도면이다.
도 10은 일부 실시예에 따른 CSI 파일럿 시그널링, CSI 추정 및 CSI 추정치의 피드백의 전송을 위한 공동 트레이닝된 신경망의 선택된 세트를 도시하는 도면이다.
도 11은 일부 실시예에 따른 신경망을 사용하여 CSI 추정치를 결정하고 CSI 추정치를 다시 피드백하는 예시적인 방법을 도시하는 흐름도이다.
도 12는 일부 실시예에 따른 도 11의 방법의 예시적인 동작을 도시하는 사다리 시그널링 도면이다.The present disclosure will be better understood and numerous features and advantages will become apparent to those skilled in the art by reference to the accompanying drawings. Use of the same reference symbol in different drawings indicates similar or identical items.
1 is a diagram illustrating an example wireless system using a channel state feedback (CSF) neural network approach to characterize a wireless channel in accordance with some embodiments.
FIG. 2 is a diagram illustrating an example hardware configuration of a user equipment (UE) of the wireless system of FIG. 1 according to some embodiments.
FIG. 3 is a diagram illustrating an example hardware configuration of a base station (BS) of the wireless system of FIG. 1 according to some embodiments.
FIG. 4 is a diagram illustrating an example hardware configuration of a management infrastructure component of the wireless system of FIG. 1 in accordance with some embodiments.
5 is a diagram illustrating a machine learning (ML) module using a neural network for use in a CSF neural network approach according to some embodiments.
FIG. 6 is a diagram illustrating a pair of jointly trained neural networks for processing and transmission of CSI estimates between a UE and a BS according to some embodiments.
FIG. 7 is a flow diagram illustrating an example method for joint training of a set of neural networks to facilitate CSF in a wireless system according to some embodiments.
8 is a flow diagram illustrating an example method for feedback of CSI estimates using a selected set of jointly trained neural networks, according to some embodiments.
FIG. 9 is a ladder signaling diagram illustrating example operation of the method of FIG. 8 in accordance with some embodiments.
10 is a diagram illustrating a selected set of jointly trained neural networks for transmission of CSI pilot signaling, CSI estimation, and feedback of the CSI estimate, according to some embodiments.
11 is a flow diagram illustrating an example method for determining a CSI estimate and feeding back the CSI estimate using a neural network, according to some embodiments.
FIG. 12 is a ladder signaling diagram illustrating example operation of the method of FIG. 11 in accordance with some embodiments.
채널 상태 피드백(CSF)은 빔포밍이나 시공간 코딩과 같은 다양한 MIMO 프로세스를 촉진한다. 수신 장치(device)에서 CSI를 효율적으로 추정하고, 그 CSI 추정치를 CSF로서 송신 장치에 제공하기 위해, 적어도 하나의 실시예에서 송신 장치와 수신 장치는 파일럿 전송 프로세스, CSI 추정 프로세스 또는 CSI 피드백 프로세스 중 하나 이상을 구현하기 위해 공동으로 트레이닝된 신경망을 사용한다. 이로 인해 해당 CSF 단계(stage) 시퀀스에 대해 특별히 설계 및 테스트할 필요 없이 실제로 CSF 단계의 기존 시퀀스와 동일한 처리를 제공하도록 트레이닝된 신경망 세트가 생성된다. 설명하자면, 일부 실시예에서 CSI 파일럿 전송 프로세스 및 CSI 추정 프로세스는 알고리즘 접근 방식을 사용하여 수행되지만, CSI 추정치를 송신 장치에 다시 제공하는 프로세스는, 실제로 현재 무선 환경을 고려하여 CSI 추정치를 효율적으로 양자화하거나 압축하는 방식으로 수신 장치로부터 송신 장치로의 무선 주파수(RF) 전송에 대한 CSI 추정치를 처리하도록 동작하는 수신 장치의 송신(TX) 신경망과, 송신 장치의 하나 이상의 MIMO 관리 프로세스에 의해 사용하기 위해 CSI 추정치 또는 그의 표현을 복구하기 위해 TX 신경망으로부터 무선으로 수신된 출력을 수신하고 처리하도록 동작하는 송신 장치의 수신(RX) 신경망을 포함하여, 공동으로 트레이닝된 신경망 세트의 사용에 의존한다.Channel state feedback (CSF) facilitates various MIMO processes such as beamforming and space-time coding. To efficiently estimate CSI at a receiving device and provide the CSI estimate as a CSF to a transmitting device, in at least one embodiment, the transmitting device and the receiving device perform one of a pilot transmission process, a CSI estimation process, or a CSI feedback process. It uses jointly trained neural networks to implement more than one. This results in a set of neural networks that are trained to actually provide the same processing as an existing sequence of CSF stages, without having to be designed and tested specifically for that CSF stage sequence. To illustrate, in some embodiments the CSI pilot transmission process and the CSI estimation process are performed using an algorithmic approach, but the process of providing the CSI estimate back to the transmitting device actually quantizes the CSI estimate efficiently, taking into account the current wireless environment. For use by a transmit (TX) neural network in the receiving device operative to process CSI estimates for radio frequency (RF) transmissions from the receiving device to the transmitting device in a manner that compresses or compresses them, and by one or more MIMO management processes in the transmitting device. It relies on the use of a set of jointly trained neural networks, including a receive (RX) neural network of the transmitting device that operates to receive and process the wirelessly received output from the TX neural network to recover the CSI estimate or representation thereof.
다른 실시예에서는, 신경망이 파일럿 전송, CSI 추정 및 피드백 단계 각각에 사용된다. 이 접근 방식에서, 송신 장치는 수신 장치에 무선으로 전송되는 CSI 파일럿 출력을 생성하도록 동작하는 TX 신경망을 사용하고, 수신 장치는 다시 RX 신경망을 사용하여 CSI 파일럿을 입력으로 수신하고 CSI 추정치를 나타내는 대응하는 CSI 출력을 생성한다. 수신 장치는 CSI 추정치를 수신하고 그 CSI 추정치의 양자화(된) 버전 또는 압축(된) 버전을 나타내는 CSF 출력을 생성하기 위해 TX 신경망을 더 사용한다. 수신 장치는 이 CSF 출력을 송신 장치로 전송하며, 여기서 RX 신경망은 CSF 출력을 수신 및 처리하여 송신 장치가 송신 장치에서 하나 이상의 MIMO 프로세스를 관리하는데 활용할 수 있는 대응하는 CSI 추정치를 생성한다.In another embodiment, a neural network is used for each of the pilot transmission, CSI estimation, and feedback steps. In this approach, the transmitting device uses a TX neural network that operates to generate a CSI pilot output that is transmitted wirelessly to the receiving device, and the receiving device in turn uses an RX neural network to receive the CSI pilot as input and generate a corresponding CSI estimate representing the CSI estimate. Generates CSI output that The receiving device further uses the TX neural network to receive the CSI estimate and generate a CSF output representing a quantized () or compressed () version of the CSI estimate. The receiving device transmits this CSF output to the transmitting device, where the RX neural network receives and processes the CSF output to generate a corresponding CSI estimate that the transmitting device can utilize to manage one or more MIMO processes at the transmitting device.
어느 접근 방식에서든, 무선 시스템은 사용되는 특정 반송파 주파수 또는 채널, 신호 형식 또는 프로토콜, 전파 환경(예를 들어 다양한 센서의 센서 데이터로 특징지어짐), 컴퓨팅 자원, 센서 자원, 전력 자원, 안테나 자원 및 기타 성능과 같은 임의의 다양한 파라미터에 기초하여 송신 장치와 수신 장치 사이에 사용된 다양한 신경망에 대한 다수의 후보 신경망 아키텍처 구성의 공동 트레이닝을 사용할 수 있다. 따라서, 송신 장치와 수신 장치 각각에 사용되는 특정 신경망 구성은 이들 장치의 특정 구성과 대응하는 신경망 아키텍처 구성을 트레이닝하는데 사용되는 파라미터 사이의 상관관계에 기초하여 선택될 수 있다.In either approach, the wireless system is characterized by the specific carrier frequencies or channels used, the signal format or protocol, the propagation environment (characterized for example by sensor data from various sensors), computing resources, sensor resources, power resources, antenna resources, and Joint training of multiple candidate neural network architecture configurations for the various neural networks used between the transmitting and receiving devices may be used based on any of a variety of parameters such as performance and other parameters. Accordingly, the specific neural network configuration used in each of the transmitting and receiving devices may be selected based on the correlation between the specific configuration of those devices and the parameters used to train the corresponding neural network architecture configuration.
이러한 기술 및 기타 기술은 "송신 장치" 및 "수신 장치"를 참조하여 아래에서 설명된다. 본 명세서에 사용된 바와 같이, "송신 장치"는 대응하는 채널 링크에 대한 주(primary) 송신기 역할을 하는 장치를 지칭하고, "수신 장치"는 대응하는 채널 링크에 대한 주 수신기 역할을 하는 장치를 지칭한다. 그러나, 이는 송신 장치가 채널을 통해 RF 신호를 수신할 수 없거나, 수신 장치가 채널을 통해 RF 신호를 송신할 수도 없다는 것을 의미하는 것은 아니다. 예를 들어, CSF 컨텍스트에서, 송신 장치는 일부 형태의 CSI 파일럿 시그널링을 전송하는 장치이고, 수신 장치는 CSI 파일럿 시그널링을 수신하고 채널에 대한 그 CSI 시그널링으로부터 일부 형태의 CSI 또는 CSI 추정치를 결정하는 장치이다. 하지만, 이후 이 동일한 수신 장치는 보통 결정된 CSI의 표현을 동일한 채널 또는 다른 채널의 송신 장치로 다시 전송하며, 이 경우, 수신 장치는 CSI 피드백의 송신을 위한 송신기로서 동작하고, 송신 장치는 송신된 CSI 피드백의 수신을 위한 수신기로서 동작한다. 더욱이, 장치는 하나의 채널에 대해서는 송신 장치로서 동작하면서 다른 채널에 대해서는 수신 장치로서 동작할 수도 있다는 점을 이해해야 한다. 예를 들어, 제1 장치는 송신 장치로서 동작할 수 있고, 제2 장치는 제1 장치와 제2 장치 사이의 제1 채널(예를 들어, 다운링크 채널)에 대한 채널 특성화를 위한 수신 장치로서 동작할 수 있으며, 동시에 또는 다른 시간에 제1 장치는 수신 장치로서 동작할 수 있고, 제2 장치는 제1 장치와 제2 장치 사이의 제2 채널(예를 들어, 업링크 채널) 또는 제2 장치와 제3 장치 사이의 제2 채널(예를 들어 사이드링크 채널) 또는 제2 장치와 제3 장치 사이의 제2 채널(예를 들어, 사이드링크 채널)에 대한 채널 특성화를 위한 송신 장치로서 동작할 수 있다.These and other technologies are described below with reference to “Transmitting Device” and “Receiving Device.” As used herein, “transmitting device” refers to a device that serves as the primary transmitter for a corresponding channel link, and “receiving device” refers to a device that serves as the primary receiver for a corresponding channel link. refers to However, this does not mean that the transmitting device cannot receive RF signals through the channel or that the receiving device cannot transmit RF signals through the channel. For example, in a CSF context, a transmitting device is a device that transmits some form of CSI pilot signaling, and a receiving device is a device that receives CSI pilot signaling and determines some form of CSI or CSI estimate from that CSI signaling for a channel. am. However, this same receiving device then usually transmits the determined representation of the CSI back to the transmitting device on the same or a different channel, in which case the receiving device acts as a transmitter for transmission of CSI feedback, and the transmitting device acts as a transmitter for the transmission of the CSI feedback. It operates as a receiver for receiving feedback. Moreover, it should be understood that a device may operate as a transmitting device on one channel while operating as a receiving device on another channel. For example, the first device may operate as a transmitting device and the second device may operate as a receiving device for channel characterization for a first channel (e.g., a downlink channel) between the first device and the second device. The first device may operate as a receiving device, and the second device may operate as a receiving device, and the second device may operate as a receiving device or a second channel (e.g., an uplink channel) between the first device and the second device. Operate as a transmitting device for channel characterization for a second channel between a device and a third device (e.g., a sidelink channel) or a second channel between a second device and a third device (e.g., a sidelink channel) can do.
도 1은 일부 실시예에 따른 신경망 촉진(facilitated) 채널 상태 피드백을 사용하는 무선 통신 시스템(100)을 도시한다. 도시된 바와 같이, 무선 통신 시스템(100)은 하나 이상의 광역 네트워크(WAN)(104) 또는 인터넷과 같은 다른 패킷 데이터 네트워크(PDN)에 연결된 코어 네트워크(102)를 포함하는 셀룰러 네트워크이다. 무선 통신 시스템(100)은 적어도 하나의 기지국(BS)(108)을 더 포함하고, 각각의 BS(108)는 하나 이상의 통신 프로토콜 또는 표준에 의해 지정된 하나 이상의 적용 가능한 무선 접속 기술(RAT)을 사용하여 RF 시그널링을 통해 UE(110)와 같은 하나 이상의 UE와의 무선 통신을 지원한다. 이와 같이, BS(108)는 UE(110)와 코어 네트워크(102) 및 다른 네트워크(예를 들어, 패킷 교환(PS) 데이터 서비스, 회선 교환(CS) 서비스)에 의해 제공되는 다양한 네트워크 및 서비스 간의 무선 인터페이스로서 동작한다. 일반적으로, BS(108)에서 UE(110)로의 데이터 또는 시그널링의 통신은 "다운링크" 또는 "DL"로 지칭되는 반면, UE(110)에서 BS(108)로의 데이터 또는 시그널링의 통신은 "업링크" 또는 "UL"로 지칭된다.1 illustrates a wireless communication system 100 using neural network facilitated channel state feedback in accordance with some embodiments. As shown, the wireless communication system 100 is a cellular network that includes a core network 102 connected to one or more wide area networks (WANs) 104 or other packet data networks (PDNs), such as the Internet. The wireless communication system 100 further includes at least one base station (BS) 108, each BS 108 using one or more applicable radio access technologies (RATs) specified by one or more communication protocols or standards. Thus, wireless communication with one or more UEs, such as UE 110, is supported through RF signaling. As such, BS 108 provides connectivity between UE 110 and various networks and services provided by core network 102 and other networks (e.g., packet switched (PS) data services, circuit switched (CS) services). It operates as a wireless interface. Generally, communication of data or signaling from BS 108 to UE 110 is referred to as “downlink” or “DL,” while communication of data or signaling from UE 110 to BS 108 is referred to as “uplink.” Referred to as “Link” or “UL”.
BS(108)는 UMTS(Universal Mobile Telecommunications System) RAT("3G"라고도 함)에 대해 NodeB(또는 BTS(base transceiver station))로 동작하고, 3GPP LTE RAT에 대해 eNodeB(enhanced NodeB)로 동작하고, 3GPP 5세대(5G) NR(New Radio) RAT에 대해 5G 노드 B("gNB")로 동작하는 것과 같은 다양한 RAT 중 임의의 것을 사용할 수 있다. UE(110)는 예를 들어, 모바일 휴대폰, 셀룰러 지원 태블릿 컴퓨터 또는 랩탑 컴퓨터, 데스크탑 컴퓨터, 셀룰러 지원 비디오 게임 시스템, 서버, 셀룰러 지원 기기, 셀룰러 지원 자동차 통신 시스템, 셀룰러 지원 스마트 워치 또는 기타 웨어러블 장치 등을 포함하여 적절한 RAT를 통해 BS(108)와 통신하도록 동작 가능한 다양한 전자 장치 중 임의의 것을 구현할 수 있다.The BS 108 operates as a NodeB (or base transceiver station (BTS)) for the Universal Mobile Telecommunications System (UMTS) RAT (also referred to as “3G”) and as an enhanced NodeB (eNodeB) for the 3GPP LTE RAT, Any of a variety of RATs can be used, such as operating as a 5G Node B (“gNB”) for a 3GPP 5th Generation (5G) New Radio (NR) RAT. UE 110 may be, for example, a mobile cell phone, cellular-enabled tablet or laptop computer, desktop computer, cellular-enabled video game system, server, cellular-enabled device, cellular-enabled automotive communication system, cellular-enabled smartwatch or other wearable device, etc. Any of a variety of electronic devices operable to communicate with BS 108 via an appropriate RAT may be implemented, including.
BS(108)와 UE(110) 사이에 형성된 무선 인터페이스를 통한 정보의 통신은 제어 평면 시그널링과 사용자 데이터 평면 시그널링 모두를 나타내는 RF 신호의 형태를 취한다. 그러나, 상대적으로 높은 주파수, 상대적으로 좁은 타이밍 마진, 송신 장치와 수신 장치 간의 상대적 이동, 건물, 신체 및 기타 간섭 객체의 존재 또는 이동뿐만 아니라 근접 송신 간섭자 중 하나 이상으로 인해, RF 시그널링을 포함하는 채널의 전파 환경은 자주 변경된다. 따라서, 적어도 하나의 실시예에서, BS(108)와 UE(110)는 CSI 추정 또는 수신 장치에서 송신 장치로의 CSI 추정 정보 피드백 중 하나 또는 둘 모두를 용이하게 하도록 트레이닝되거나 구성된 하나 이상의 신경망(NN)을 통합하는 송신기(TX) 및 수신기(RX) 처리 경로를 구현한다. 본 명세서에 설명된 바와 같이, 이러한 확인 및 관련 프로세스는 UE(110)에 의한 수신을 위해 BS(108)에 의해 전송된 RF 시그널링을 위한 다운링크 채널(112)에 대해, BS(108)에 의한 수신을 위해 UE(110)에 의해 전송된 RF 시그널링을 위한 업링크 채널(114)에 대해, 또는 각 채널(112, 114)에 대해 구현될 수 있다. 따라서, 다운링크 채널(112)에 대해, BS(108)는 송신 장치로 동작하고 UE(110)는 CSF 목적을 위해 수신 장치로 동작하는 반면, 업링크 채널(114)에 대해 UE(110)는 송신 장치로 동작하고 BS(108)는 CSF 목적을 위해 수신 장치로 동작한다.Communication of information over the air interface established between BS 108 and UE 110 takes the form of RF signals representing both control plane signaling and user data plane signaling. However, due to one or more of the relatively high frequencies, relatively narrow timing margins, relative movement between the transmitting and receiving devices, the presence or movement of buildings, bodies, and other interfering objects, as well as close transmitting interferers, the RF signaling involved The channel's propagation environment changes frequently. Accordingly, in at least one embodiment, the BS 108 and the UE 110 have one or more neural networks (NNs) trained or configured to facilitate either or both CSI estimation or feedback of CSI estimation information from the receiving device to the transmitting device. ) implements a transmitter (TX) and receiver (RX) processing path that integrates As described herein, this confirmation and related process may be performed by BS 108 on the downlink channel 112 for RF signaling transmitted by BS 108 for reception by UE 110. It may be implemented for uplink channel 114 for RF signaling transmitted by UE 110 for reception, or for each channel 112, 114. Thus, for downlink channel 112, BS 108 operates as a transmitting device and UE 110 operates as a receiving device for CSF purposes, while for uplink channel 114, UE 110 Acting as a transmitting device, BS 108 operates as a receiving device for CSF purposes.
다운링크 채널(112)에 대한 CSF 경로(116)에 관해 설명하기 위해, UE(110)는 CSI 추정 컴포넌트(120) 및 UE(110)의 RF 프런트 엔드(124)에 결합된 출력을 갖는 UE CSF TX DNN(122)(또는 다른 신경망)을 갖는 TX 처리 경로(118)를 이용한다. BS(108)는 BS(108)의 RF 프론트엔드(130)에 결합된 입력을 갖는 BS CSF RX DNN(128)(또는 다른 신경망) 및 BS CSF RX DNN(128)의 출력에 결합된 입력을 갖는 MIMO 관리 컴포넌트(132)를 갖는 RX 처리 경로(126)를 이용한다.To describe the CSF path 116 for the downlink channel 112, the UE 110 has a CSI estimation component 120 and a UE CSF with outputs coupled to the RF front end 124 of the UE 110. It uses the TX processing path 118 with the TX DNN 122 (or other neural network). BS 108 has a BS CSF RX DNN 128 (or other neural network) with an input coupled to the RF front end 130 of BS 108 and an input coupled to the output of BS CSF RX DNN 128. It utilizes RX processing path 126 with MIMO management component 132.
동작시, BS(108)는 RF 프런트 엔드(130)를 통해, CSI 파일럿 신호(일반적으로 "트레이닝 신호"라고도 함)를 나타내는 RF 신호(미도시)를 전송하며, 이는 UE(110)의 RF 프런트 엔드(124)에 의해 수신되고 CSI 추정 컴포넌트(120)에 의해 처리되어 그 수신된 CSI 파일럿 신호에 의해 표현되는 각각의 주파수 또는 부반송파에 대해 하나 이상의 CSI 추정치(134)를 생성한다. CSI 추정 컴포넌트(120)는 BS(108)에 의해 전송된 하나 이상의 CSI 파일럿 신호의 대응 세트로부터 적어도 하나의 CSI 추정치(134)를 생성하기 위해 잘 알려져 있거나 독점적인 다양한 기술 중 임의의 것을 사용할 수 있다. 예를 들어, 채널과 잡음 분포가 알려지지 않은 경우, CSI 추정 컴포넌트(120)는 예를 들어 임의의 다양한 최소 제곱 추정기를 사용하여 CSI 추정치(134)를 결정할 수 있는 반면, 채널 및 잡음 분포가 알려진 경우, CSI 추정 컴포넌트(120)는 예를 들어 임의의 다양한 베이지안 추정 기술을 사용하여 CSI 추정치(134)를 결정할 수 있다. CSI 추정치(134)는 당업계에 공지된 바와 같이 임의의 다양한 형태 또는 표현을 취할 수 있지만, 참조의 용이함을 위해, CSI 추정치(134)의 구현은 하나 이상의 행렬 세트로 구현되며, 각 행렬은 해당 반송파 주파수에 대한 대응하는 전송 형식을 나타낸다. 그러나, CSI 추정치(134)는 이러한 특정 구현에 제한되지 않으며 다양한 적합한 CSI 추정 형태 중 임의의 것을 나타낼 수 있다는 것이 이해될 것이다.In operation, BS 108 transmits, via RF front end 130, an RF signal (not shown) representing the CSI pilot signal (commonly referred to as a “training signal”), which is transmitted to the RF front end of UE 110. Received by end 124 and processed by CSI estimation component 120 to generate one or more CSI estimates 134 for each frequency or subcarrier represented by the received CSI pilot signal. CSI estimation component 120 may use any of a variety of well-known or proprietary techniques to generate at least one CSI estimate 134 from a corresponding set of one or more CSI pilot signals transmitted by BS 108. . For example, if the channel and noise distribution are unknown, CSI estimation component 120 may determine the CSI estimate 134 using, for example, any of a variety of least squares estimators, whereas if the channel and noise distribution are known. , CSI estimation component 120 may determine CSI estimate 134 using any of a variety of Bayesian estimation techniques, for example. CSI estimate 134 may take any of a variety of forms or representations as is known in the art, but for ease of reference, an implementation of CSI estimate 134 is implemented as a set of one or more matrices, each matrix corresponding to Indicates the corresponding transmission format for the carrier frequency. However, it will be understood that CSI estimate 134 is not limited to this particular implementation and may represent any of a variety of suitable CSI estimate forms.
CSI 추정치(134)는 UE(110)의 하나 이상의 센서에 의해 관찰되는(그리고 아래에 설명되는) 현재 전파 환경을 나타내는 센서 데이터 입력과 같은 임의의 다양한 선택적인 다른 입력들과 함께 UE CSF TX DNN(122)에 대한 입력으로 제공된다. 적어도 하나의 실시예에서, UE CSF TX DNN(122)은 BS(108)의 BS CSF RX DNN(128)과 함께 공동으로 트레이닝되므로 BS(108)로의 RF 전송과 BS CSF RX DNN(128)에 의한 처리에 적합한 CSI 추정치(134)(및 임의의 다른 입력)로부터 CSF 출력을 생성한다. 이러한 공동 트레이닝 또는 기타 구성의 일부로서, UE CSF TX DNN(122)은 적어도 하나의 실시예에서, 실제로 CSI 추정치(134)에 의해 표현된 데이터 또는 정보를 양자화하거나 압축하고 그리고 입력 센서 데이터 또는 다른 입력을 고려하여 결과적인 압축 정보를 처리하여 BS(108)로의 무선 전송을 위해 RF 프런트 엔드(124)에 제공되는 CSF 출력(136)을 생성하도록 트레이닝되거나 구성된다. CSI estimate 134 may be generated by the UE CSF TX DNN ( 122) is provided as input. In at least one embodiment, the UE CSF TX DNN 122 is jointly trained with the BS CSF RX DNN 128 of the BS 108 such that RF transmissions to the BS 108 and BS CSF RX DNN 128 Generates a CSF output from CSI estimate 134 (and any other inputs) suitable for processing. As part of this joint training or other configuration, UE CSF TX DNN 122, in at least one embodiment, actually quantizes or compresses the data or information represented by CSI estimate 134 and input sensor data or other input. is trained or configured to take into account and process the resulting compressed information to produce a CSF output 136 that is provided to the RF front end 124 for wireless transmission to BS 108.
BS(108)에서, RF 프론트 엔드(130)는 수신된 RF 시그널링으로부터 CSF 출력(136)을 추출하고 CSF 출력(136)을 BS CSF RX DNN(128)에 대한 입력으로 제공한다. BS의 센서로부터의 센서 데이터와 같은 선택적인 다른 입력이 BS CSF RX DNN(128)에 대한 입력으로 동시에 제공될 수도 있다. 이들 입력으로부터, 공동 트레이닝 또는 다른 구성에 기초하여, BS CSF RX DNN(128)은 본 명세서에서 복구된 CSI 추정치(138)로 지칭되는 CSI 추정치(134)의 복구된 표현을 제공하도록 동작한다. 그러면 복구된 CSI 추정치(138)는 MIMO 관리 컴포넌트(132)에 제공되며, 이는 복구된 CSI 추정치(138)를 사용하여 예를 들어 적어도 UE(110)로의 RF 전송을 위해 RF 프런트 엔드(130)에 의해 활용되는 빔형성 프로세스, 시공간 코딩 프로세스, 또는 다중 사용자 MIMO 프로세스 중 하나 이상을 제어함으로써, UE(110)와의 다운링크 채널(112)에 대해 BS(108)의 하나 이상의 MIMO 프로세스를 제어한다. 적어도 UE(110)로의 RF 전송을 위해 RF 프런트 엔드(130)에 의해 활용되는 빔포밍 프로세스, 시공간 코딩 프로세스, 또는 다중 사용자 MIMO 프로세스에 더 가깝다.At BS 108, RF front end 130 extracts CSF output 136 from the received RF signaling and provides CSF output 136 as input to BS CSF RX DNN 128. Optionally other inputs, such as sensor data from sensors in the BS, may also be provided simultaneously as inputs to the BS CSF RX DNN 128. From these inputs, based on joint training or other configuration, BS CSF RX DNN 128 operates to provide a recovered representation of CSI estimate 134, referred to herein as recovered CSI estimate 138. The recovered CSI estimate 138 is then provided to the MIMO management component 132, which uses the recovered CSI estimate 138 to, for example, at least provide RF front end 130 for RF transmission to UE 110. Control one or more MIMO processes of BS 108 for the downlink channel 112 with UE 110 by controlling one or more of a beamforming process, a space-time coding process, or a multi-user MIMO process utilized by the BS 108. It is at least closer to the beamforming process, space-time coding process, or multi-user MIMO process utilized by the RF front end 130 for RF transmission to UE 110.
도 1은 다운링크 채널(112)에 대한 CSF 경로(116)를 도시하지만, 도시된 것과 유사한 구성이 또한 업링크 채널(114)에 대한 CSF 경로를 제공하기 위해 활용될 수 있으며, BS(108)는 유사한 CSI 추정 컴포넌트 및 CSF TX DNN을 사용하고 UE(110)는 유사한 CSF RX DNN 및 MIMO 관리 컴포넌트를 사용한다는 것이 이해될 것이다. 그러나, 설명의 편의를 위해 본 개시의 신경망 기반 CSF 기술은 BS에서 UE로의 다운링크 채널의 예시적인 맥락에서 설명되지만, 이러한 동일한 기술은 UE에서 BS로의 업링크 채널에, 또는 송신 장치로 동작하는 임의의 RF 지원 장치와 CSF 목적을 위한 수신 장치로 동작하는 다른 RF 지원 장치 사이에 동일하게 적용 가능하다는 것이 이해될 것이다. 더욱이, 도 1은 송신 장치에 의한 CSI 파일럿 신호의 생성 및 송신과 수신 장치에서 수신된 CSI 파일럿 신호에 기초한 CSI의 알고리즘 추정이 종래의 접근법을 사용하여 수행될 수 있는 예시적인 구현을 도시하지만, 다른 실시예에서는, 이러한 프로세스 중 하나 이상은 도 10-12를 참조하여 이후에 설명되는 바와 같이 공동 트레이닝된 신경망을 사용하여 부분적으로 또는 완전히 구현될 수도 있다.1 shows a CSF path 116 for the downlink channel 112, a similar configuration as shown could also be utilized to provide a CSF path for the uplink channel 114 and BS 108. It will be understood that uses similar CSI estimation components and CSF TX DNN and UE 110 uses similar CSF RX DNN and MIMO management components. However, for ease of explanation, the neural network-based CSF technology of this disclosure is described in the example context of a downlink channel from BS to UE, but these same techniques may also be used in an uplink channel from UE to BS, or in any device operating as a transmitting device. It will be understood that the same is applicable between the RF-enabled device of and any other RF-enabled device operating as a receiving device for CSF purposes. Moreover, Figure 1 shows an example implementation in which the generation and transmission of a CSI pilot signal by a transmitting device and algorithmic estimation of CSI based on the CSI pilot signal received at a receiving device can be performed using conventional approaches, but other In embodiments, one or more of these processes may be partially or fully implemented using a co-trained neural network, as described later with reference to FIGS. 10-12.
위에서 언급하고 여기에 더 자세히 설명된 바와 같이, 송신 장치와 수신 장치(예를 들어, CSF 경로(116)에 대해 각각 BS(108)와 UE(110)) 모두는 하나 이상의 DNN 또는 전체 CSF 프로세스를 촉진하기 위해 상황별 파라미터에 기초하여 공동으로 트레이닝되고 선택되는 기타 신경망을 사용한다. 이러한 신경망의 공동 트레이닝, 선택 및 유지 관리를 관리하기 위해, 적어도 하나의 실시예에서 시스템(100)은 관리 인프라 컴포넌트(140)(또는 간결성을 위해 "관리 컴포넌트(140)")를 추가로 포함한다. 이 관리 컴포넌트(140)는 예를 들어 코어 네트워크(102) 또는 WAN(104) 내와 같은 무선 통신 시스템(100)의 네트워크 인프라(106) 내의 서버 또는 다른 컴포넌트를 포함할 수 있다. 또한, 도시된 예에서는 별도의 컴포넌트로 도시되어 있지만, 적어도 일부 실시예에서 BS(108)는 관리 컴포넌트(140)를 구현한다. 관리 컴포넌트(140)에 의해 제공되는 감독(oversight) 기능에는 예를 들어, 신경망의 공동 트레이닝을 감독하는 것, 특정 기능 또는 기타 컴포넌트별 파라미터에 기초하여 송신 장치 또는 수신 장치 중 하나 이상에 대한 특정 신경망 아키텍처 구성의 선택을 관리하는 것, 신경망 구성 선택을 위한 기능 업데이트 수신 및 처리, 신경망 트레이닝 또는 선택을 위한 피드백 수신 및 처리 등의 일부 또는 전부가 포함될 수 있다.As mentioned above and described in more detail herein, both the transmitting device and the receiving device (e.g., BS 108 and UE 110, respectively, for CSF path 116) may perform one or more DNNs or an entire CSF process. To facilitate this, we use other neural networks that are jointly trained and selected based on context-specific parameters. To manage the joint training, selection, and maintenance of these neural networks, in at least one embodiment, system 100 further includes a management infrastructure component 140 (or “management component 140” for brevity). . This management component 140 may include a server or other component within the network infrastructure 106 of the wireless communication system 100, such as within the core network 102 or WAN 104, for example. Additionally, although shown as a separate component in the illustrated example, BS 108 implements management component 140 in at least some embodiments. Oversight functions provided by management component 140 may include, for example, overseeing joint training of neural networks, specific neural networks for one or more of the transmitting or receiving devices based on specific functions or other component-specific parameters. It may include any or all of the following: managing the selection of architectural configurations, receiving and processing feature updates for neural network configuration selection, and receiving and processing feedback for neural network training or selection.
아래에서 좀 더 자세히 설명하자면, 일부 실시예에서 관리 컴포넌트(140)는 해당 신경망을 구현하는 컴포넌트의 현재 성능(capability), 전송 체인의 다른 컴포넌트의 현재 성능, 또는 이들의 조합에 적어도 부분적으로 기초하여 해당 CSF 경로의 특정 컴포넌트에 사용되도록 선택될 수 있는 후보 신경망 아키텍처 구성(144)의 세트(142)를 유지한다. 이러한 성능은 센서 성능, 처리 리소스 성능, 배터리/전원 성능, RF 안테나 성능, 컴포넌트의 하나 이상의 액세서리 성능, 해당 채널을 통해 전송될 데이터의 유형 또는 특성 등을 포함할 수 있다. BS(108) 및 UE(110)에 대한 이들 성능을 나타내는 정보는 관리 컴포넌트(140)에 의해 각각 BS 성능 정보(146) 및 UE 성능 정보(148)로서 획득되어 저장된다. 관리 컴포넌트(140)는 또한 채널의 반송파 주파수, 객체 또는 다른 간섭자의 알려진 존재 등과 같은 환경의 전파 채널 또는 해당 채널의 파라미터 또는 다른 측면을 고려할 수 있다. 채널 또는 전파 환경의 측면을 나타내는 정보는 관리 컴포넌트(140)에 의해 채널/전파 정보(150)로서 획득되어 저장된다.As described in more detail below, in some embodiments, management component 140 may perform a configurable process based at least in part on the current capabilities of the component implementing the neural network, the current capabilities of other components in the transport chain, or a combination thereof. Maintains a set 142 of candidate neural network architecture configurations 144 that can be selected to be used for specific components of the CSF path in question. These capabilities may include sensor performance, processing resource performance, battery/power performance, RF antenna performance, performance of one or more accessories of the component, type or nature of data to be transmitted over the channel, etc. Information representing these capabilities for BS 108 and UE 110 is obtained and stored by management component 140 as BS capability information 146 and UE capability information 148, respectively. Management component 140 may also consider parameters or other aspects of the propagation channel or the channel in the environment, such as the channel's carrier frequency, the known presence of objects or other interferers, etc. Information representing aspects of the channel or propagation environment is obtained and stored by the management component 140 as channel/propagation information 150.
이 접근 방식을 지원하여, 일부 실시예에서, 관리 컴포넌트(140)는 다양한 성능/컨텍스트 조합에 대한 후보 신경망 아키텍처 구성(144)의 다양한 조합의 공동 트레이닝을 관리할 수 있다. 그런 다음 관리 컴포넌트(140)는 BS(108)로부터 성능 정보(146), UE(110)로부터 성능 정보(148), 또는 둘 모두를 획득할 수 있으며, 이 성능 정보로부터 관리 컴포넌트(140)는 채널/전파 정보(150)에 반영된 RF 시그널링 환경 및 해당 표시된 성능에 적어도 부분적으로 기초하여 각 컴포넌트에 대한 후보 신경망 아키텍처 구성(144)의 세트(142)로부터 신경망 아키텍처 구성을 선택한다. 일부 실시예에서, 후보 신경망 아키텍처 구성은 BS(108)에 대한 특정 성능 세트의 각각의 후보 신경망 아키텍처 구성이 UE(110)에 대한 특정 성능 세트의 단일 대응 후보 신경망 아키텍처 구성과 공동으로 트레이닝되도록 페어링된(쌍을 이루는) 서브세트로 공동으로 트레이닝된다. 다른 실시예에서, 후보 신경망 아키텍처 구성은 BS(108)에 대한 각각의 후보 구성이 UE(110)에 대한 다수의 후보 구성과 일대다 대응을 갖고 그 반대의 경우도 가능하도록 트레이닝된다.Supporting this approach, in some embodiments, management component 140 may manage joint training of various combinations of candidate neural network architecture configurations 144 for various performance/context combinations. Management component 140 may then obtain performance information 146 from BS 108, performance information 148 from UE 110, or both, from which management component 140 can determine the channel /Select a neural network architecture configuration from the set 142 of candidate neural network architecture configurations 144 for each component based at least in part on the RF signaling environment reflected in the propagation information 150 and its indicated performance. In some embodiments, the candidate neural network architecture configurations are paired such that each candidate neural network architecture configuration in a specific performance set for BS 108 is jointly trained with a single corresponding candidate neural network architecture configuration in a specific performance set for UE 110. They are jointly trained on (paired) subsets. In another embodiment, candidate neural network architecture configurations are trained such that each candidate configuration for BS 108 has a one-to-many correspondence with multiple candidate configurations for UE 110 and vice versa.
따라서, 시스템(100)은 호환성을 위해 특별히 설계되지 않았을 수 있는 독립적으로 설계된 프로세스 블록버다는 CSI 피드백을 위한 송신 장치와 수신 장치 사이의 관리되고, 공동으로 트레이닝되고, 선택적으로 사용되는 신경망 세트에 의존하는 CSF 접근 방식을 활용한다. 이것은 향상된 유연성을 제공할 뿐만 아니라 일부 상황에서는 각 장치에서 더 빠른 처리와 더 효율적인 RF 전송을 제공하여 CSI 추정치 추정, 전달 및 구현 시 지연 시간을 줄일 수 있다. 이것은 결국 송신 장치와 수신 장치 간의 보다 효율적이고 효과적인 시그널링을 위해 MIMO 프로세스를 더욱 세밀하고 시기적절하게 제어할 수 있게 해준다.Accordingly, system 100 relies on a set of managed, jointly trained, and optionally used neural networks between transmitting and receiving devices for CSI feedback, rather than independently designed process blocks that may not have been specifically designed for compatibility. Utilize the CSF approach that Not only does this provide increased flexibility, but in some situations it can provide faster processing and more efficient RF transmission on each device, reducing latency in estimating, communicating, and implementing CSI estimates. This ultimately allows for more detailed and timely control of the MIMO process for more efficient and effective signaling between transmitting and receiving devices.
도 2는 일부 실시예에 따른 UE(110)(대표적인 수신 장치로서)에 대한 예시적인 하드웨어 구성을 도시한다. 도시된 하드웨어 구성은 본 명세서에 설명된 신경망 기반 프로세스와 가장 직접적으로 관련된 처리 컴포넌트 및 통신 컴포넌트를 나타내며, 디스플레이, 비-센서 주변 장치, 외부 전원 공급 장치 등과 같은 전자 장치에서 자주 구현되는 것으로 잘 이해되는 특정 컴포넌트를 생략한다. 2 shows an example hardware configuration for UE 110 (as a representative receiving device) according to some embodiments. The depicted hardware configuration represents the processing and communication components most directly related to the neural network-based process described herein, and is well understood as frequently implemented in electronic devices such as displays, non-sensor peripherals, external power supplies, etc. Omit certain components.
도시된 구성에서, UE(110)는 하나 이상의 안테나(202)를 갖는 RF 프런트 엔드(124) 및 하나 이상의 RAT를 지원하기 위한 하나 이상의 모뎀을 갖는 RF 안테나 인터페이스(204)를 포함한다. RF 프런트 엔드(124)는 다양한 유형의 무선 통신을 용이하게 하기 위해 UE(110)의 하나 이상의 프로세서(206)와 안테나(202) 사이의 시그널링을 수행하고 처리하는 물리적(PHY) 트랜시버 인터페이스로서 사실상 동작한다. 안테나(202)는 서로 유사하거나 다르게 구성되고 대응하는 RAT와 연관된 하나 이상의 주파수 대역에 동조될 수 있는 다중 안테나의 하나 이상의 어레이로 배열될 수 있다. 하나 이상의 프로세서(206)는 예를 들어, 하나 이상의 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 텐서 처리 장치(TPU) 또는 기타 주문형 집적 회로(ASIC) 등을 포함할 수 있다. 설명하자면, 프로세서(206)는 운영 체제 및 다양한 사용자 레벨 소프트웨어 애플리케이션을 실행하기 위해 UE(110)에 의해 이용되는 애플리케이션 프로세서(AP)뿐만 아니라 RF 프런트의 기저대역 프로세서 또는 모뎀에 의해 이용되는 하나 이상의 프로세서를 포함할 수 있다. UE(110)는 RAM, ROM, 캐시, 플래시 메모리, 솔리드 스테이트 드라이브(SSD) 또는 기타 대용량 저장 장치 등과 같이 데이터 및/또는 실행 가능한 명령을 저장하기 위해 전자 장치에 의해 사용되는 다양한 매체 중 임의의 것을 포함하는 하나 이상의 컴퓨터 판독 가능 매체(208)를 더 포함한다. 설명의 용이성과 간결함을 위해, 컴퓨터 판독 가능 매체(208)는 프로세서(206)에 의한 실행을 위한 데이터 및 명령을 저장하기 위해 시스템 메모리 또는 기타 메모리를 자주 사용한다는 점에서 본 명세서에서는 "메모리(208)"로 지칭되지만, 달리 명시하지 않는 한 "메모리(208)"에 대한 언급은 다른 유형의 저장 매체에도 동일하게 적용된다는 것이 이해될 것이다.In the depicted configuration, UE 110 includes an RF front end 124 with one or more antennas 202 and an RF antenna interface 204 with one or more modems to support one or more RATs. RF front end 124 operates in effect as a physical (PHY) transceiver interface that performs and processes signaling between one or more processors 206 of UE 110 and antennas 202 to facilitate various types of wireless communications. do. Antennas 202 may be arranged in one or more arrays of multiple antennas that may be similarly or differently configured and tuned to one or more frequency bands associated with a corresponding RAT. One or more processors 206 may include, for example, one or more central processing units (CPUs), graphics processing units (GPUs), tensor processing units (TPUs), or other application specific integrated circuits (ASICs). To illustrate, processor 206 may be one or more processors used by a baseband processor or modem on the RF front, as well as an application processor (AP) used by UE 110 to run an operating system and various user-level software applications. may include. UE 110 may use any of a variety of media used by electronic devices to store data and/or executable instructions, such as RAM, ROM, cache, flash memory, solid state drive (SSD), or other mass storage devices. It further includes one or more computer-readable media 208 that include: For ease of explanation and brevity, computer-readable medium 208 is referred to herein as “memory 208” in that it often uses system memory or other memory to store data and instructions for execution by processor 206. )", but it will be understood that, unless otherwise specified, reference to "memory 208" applies equally to other types of storage media.
적어도 일 실시예에서, UE(110)는 본 명세서에서 센서 세트(210)로 지칭되는 복수의 센서를 더 포함하며, 이들 중 적어도 일부는 본 명세서에 설명된 신경망 기반 방식에서 활용된다. 일반적으로, 센서 세트(210)의 센서들은 UE(110)의 환경 또는 사용자에 의한 UE(110)의 사용의 일부 측면을 감지하는 센서를 포함하며, 이 센서는 BS(108)에 대한 UE(110)의 RF 전파 경로 또는 RF 송신/수신 성능에 적어도 어느 정도 영향을 미치거나 이를 반영하는 파라미터를 감지할 가능성이 있다. 센서 세트(210)의 센서는 레이더 센서, 라이더 센서, 이미징 센서, 구조광 기반 깊이 센서 등과 같은 객체 감지를 위한 하나 이상의 센서를 포함할 수 있다. 센서 세트(210)는 또한 와 같은 위성 위치 확인 센서(예를 들어, GPS 센서, GNSS(Global Navigation Satellite System) 센서, IMU(Internal Measurement Unit) 센서), 시각 주행 센서, 자이로스코프, 기울기 센서 또는 기타 경사계, 초광대역(UWB) 기반 센서 등과 같이 UE(110)의 위치 또는 자세를 결정하기 위한 하나 이상의 센서를 포함할 수 있다. 센서 세트(210)의 센서 유형의 다른 예에는 사용자에 의한 이미지 캡처용 카메라, 얼굴 감지용 카메라, 입체 관찰 또는 시각적 주행 거리 측정용 카메라, 장치의 피처에 근접한 객체 검출용 광 센서 등과 같은 이미징 센서가 포함될 수 있다. UE(110)는 하나 이상의 배터리(212) 또는 다른 휴대용 전원뿐만 아니라 터치 스크린, 사용자 조작 가능한 입/출력 장치(예를 들어, "버튼" 또는 키보드), 기타 터치/접촉 센서, 마이크로폰, 또는 오디오 컨텐츠 캡처용 기타 음성 센서, 비디오 콘텐츠 캡처용 이미지 센서, (예를 들어, 사용자와의 근접성 감지용) 열 센서등을 더 포함할 수 있다.In at least one embodiment, UE 110 further includes a plurality of sensors, referred to herein as sensor sets 210, at least some of which are utilized in the neural network-based approach described herein. Generally, the sensors of sensor set 210 include a sensor that senses some aspect of the environment of UE 110 or the use of UE 110 by a user, which sensor detects UE 110 relative to BS 108. ), there is the possibility of detecting parameters that affect or reflect at least some degree of the RF propagation path or RF transmission/reception performance. Sensors of sensor set 210 may include one or more sensors for object detection, such as radar sensors, lidar sensors, imaging sensors, structured light-based depth sensors, etc. Sensor set 210 may also include a satellite positioning sensor (e.g., a GPS sensor, a Global Navigation Satellite System (GNSS) sensor, an Internal Measurement Unit (IMU) sensor), a visual odometry sensor, a gyroscope, a tilt sensor, or other It may include one or more sensors for determining the location or attitude of the UE 110, such as an inclinometer, ultra-wideband (UWB)-based sensor, etc. Other examples of sensor types in sensor set 210 include imaging sensors, such as cameras for capturing images by a user, cameras for face detection, cameras for stereoscopic viewing or visual odometry, optical sensors for detecting objects proximate to features of the device, etc. May be included. UE 110 may include one or more batteries 212 or other portable power sources, as well as a touch screen, user-operable input/output device (e.g., “buttons” or keyboard), other touch/contact sensors, microphone, or audio content. It may further include other voice sensors for capturing, image sensors for capturing video content, thermal sensors (e.g., for detecting proximity to a user), etc.
UE(110)의 하나 이상의 메모리(208)는 본 명세서에 설명되고 UE(110)에 귀속되는 다양한 기능을 수행하기 위해 UE(110)의 하나 이상의 프로세서(206) 및 다른 컴포넌트를 조작하는 실행 가능한 소프트웨어 명령 및 관련 데이터의 하나 이상의 세트를 저장하는데 사용된다. 실행 가능한 소프트웨어 명령(어) 세트는 예를 들어 운영 체제(OS), 다양한 드라이버(미도시), 다양한 소프트웨어 애플리케이션을 포함한다. 실행 가능한 소프트웨어 명령 세트는 신경망 관리 모듈(222), 성능 관리 모듈(224), 또는 CSI 추정 모듈(226)(도 1의 CSI 추정 컴포넌트(120)의 일 실시예) 중 하나 이상을 더 포함한다. 신경망 관리 모듈(222)은 아래에 상세히 설명되는 바와 같이 UE(110)에 대한 하나 이상의 신경망을 구현한다. 성능 관리 모듈(224)은 신경망 구성 또는 선택과 관련될 수 있는 UE(110)의 다양한 성능을 결정하고, 이 성능을 관리 컴포넌트(140)에 보고할 뿐만 아니라 RF 및 처리 성능의 변화, 액세서리 가용성 또는 성능의 변화 등을 포함하는 이러한 성능의 변화에 대해 UE(110)를 모니터링하고, 관리 컴포넌트(140)에 대한 이러한 성능 및 성능의 변화에 대한 보고를 관리한다. 위에서도 유사하게 설명한 바와 같이, CSI 추정 모듈(226)은 BS(108)와 같은 다른 장치에 의해 전송된 CSI 파일럿 신호의 수신된 표현에 기초하여 CSI 추정치를 생성하도록 동작한다. 적어도 하나의 실시예에서, CSI 추정 모듈(226)은 당업계에 공지된 바와 같은 다양한 최소 제곱(LS), 최소 평균 제곱(LMS), 또는 베이지안 CSI 추정 기술 중 임의의 것과 같은 CSI 추정치를 계산하기 위한 하나 이상의 알고리즘 기술을 구현한다.One or more memories 208 of UE 110 may include executable software that manipulates one or more processors 206 and other components of UE 110 to perform various functions described herein and attributed to UE 110. Used to store one or more sets of instructions and related data. The executable set of software instructions includes, for example, an operating system (OS), various drivers (not shown), and various software applications. The set of executable software instructions further includes one or more of a neural network management module 222, a performance management module 224, or a CSI estimation module 226 (an embodiment of CSI estimation component 120 of FIG. 1). Neural network management module 222 implements one or more neural networks for UE 110, as described in detail below. Performance management module 224 determines various performances of UE 110 that may be related to neural network configuration or selection and reports this performance to management component 140 as well as changes in RF and processing performance, accessory availability or The UE 110 is monitored for changes in performance, including changes in performance, and reports on such performance and changes in performance are managed to the management component 140. As similarly described above, CSI estimation module 226 operates to generate a CSI estimate based on a received representation of a CSI pilot signal transmitted by another device, such as BS 108. In at least one embodiment, CSI estimation module 226 is configured to calculate a CSI estimate, such as any of a variety of least squares (LS), least mean squares (LMS), or Bayesian CSI estimation techniques as known in the art. Implement one or more algorithmic techniques for
본 명세서에 설명된 바와 같이 UE(110)의 동작을 용이하게 하기 위해, UE(110)의 하나 이상의 메모리(208)는 이러한 동작과 연관된 데이터를 추가로 저장할 수 있다. 이 데이터는 예를 들어 장치 데이터(228) 및 하나 이상의 신경망 아키텍처 구성(230)을 포함할 수 있다. 장치 데이터(228)는 예를 들어 사용자 데이터, 멀티미디어 데이터, 빔포밍 코드북, 소프트웨어 애플리케이션 구성 정보 등을 나타낸다. 장치 데이터(228)는 특정 센서 또는 센서 유형의 존재 또는 부재를 포함하는 센서 세트(210)의 하나 이상의 센서에 관한 센서 성능 정보와 같은 UE(110)에 대한 성능 정보, 및 존재하는 센서에 대해, 라이더 또는 레이더 센서의 범위 및 해상도, 이미징 카메라의 이미지 해상도 및 색상 깊이 등과 같이 해당 성능에 대한 하나 이상의 표현을 더 포함할 수 있다. 성능 정보는 예를 들어 배터리(212)의 성능 또는 상태, UI(214)의 성능 또는 상태(예를 들어, 화면 해상도, 색역 또는 디스플레이의 프레임 속도) 등에 관한 정보를 더 포함할 수 있다.To facilitate operations of UE 110 as described herein, one or more memories 208 of UE 110 may additionally store data associated with such operations. This data may include, for example, device data 228 and one or more neural network architecture configurations 230. Device data 228 represents, for example, user data, multimedia data, beamforming codebook, software application configuration information, etc. Device data 228 may include performance information for the UE 110, such as sensor performance information regarding one or more sensors in the sensor set 210, including the presence or absence of a particular sensor or sensor type, and for sensors present; It may further include one or more representations of its capabilities, such as range and resolution of a lidar or radar sensor, image resolution and color depth of an imaging camera, etc. Performance information may further include information about, for example, the performance or status of the battery 212, the performance or status of the UI 214 (e.g., screen resolution, color gamut, or frame rate of the display), etc.
하나 이상의 신경망 아키텍처 구성(230)은 관리 컴포넌트(140)에 의해 유지괸리되는 후보 신경망 아키텍처 구성(144)의 세트(142)로부터 선택된 UE 구현 예를 나타낸다. 각각의 신경망 아키텍처 구성(230)은 UE(110)의 대응 신경망을 형성하기 위해 신경망 관리 모듈(222)에 의해 사용되는 파라미터 구성 및/또는 대응 아키텍처를 나타내는 데이터 및 기타 정보를 포함하는 하나 이상의 데이터 구조를 포함한다. 신경망 아키텍처 구성(230)에 포함된 정보는 예를 들어 완전 연결 계층 신경망 아키텍처, 컨볼루션 계층 신경망 아키텍처, 순환 신경망 계층, 여러 연결된 은닉 신경망 계층, 입력 계층 아키텍처, 출력 계층 아키텍처, 신경망에서 활용되는 노드 수, 신경망에서 활용되는 계수(예를 들어, 가중치 및 편향), 커널 파라미터, 신경망에서 활용되는 여러 필터, 신경망에서 활용되는 스트라이드/풀링 구성, 각 신경망 계층의 활성화 함수, 신경망 계층 간의 상호 연결, 건너뛸 신경망 계층 등을 지정하는 파라미터를 포함한다. 따라서, 신경망 아키텍처 구성(230)은 DNN을 정의 및/또는 형성하는 NN 형성 구성(예를 들어, 하나 이상의 NN 형성 컴포넌트의 조합)을 생성하는데 사용할 수 있는 NN 형성 컴포넌트(예를 들어, 아키텍처 및/또는 파라미터 구성)의 임의의 조합을 포함한다.One or more neural network architecture configurations 230 represent UE implementation examples selected from the set 142 of candidate neural network architecture configurations 144 maintained by management component 140. Each neural network architecture configuration 230 includes one or more data structures containing data representing the corresponding architecture and/or parameter configurations used by the neural network management module 222 to form a corresponding neural network of UE 110 and other information. Includes. Information included in the neural network architecture configuration 230 may include, for example, a fully connected layer neural network architecture, a convolutional layer neural network architecture, a recurrent neural network layer, multiple connected hidden neural network layers, an input layer architecture, an output layer architecture, and the number of nodes utilized in the neural network. , coefficients utilized in the neural network (e.g., weights and biases), kernel parameters, several filters utilized in the neural network, stride/pooling configurations utilized in the neural network, activation functions of each neural network layer, interconnections between neural network layers, skips, etc. Contains parameters that specify the neural network layer, etc. Accordingly, neural network architecture configuration 230 includes NN forming components (e.g., architectures and/or structures) that can be used to create a NN forming configuration (e.g., a combination of one or more NN forming components) that defines and/or forms a DNN. or parameter configuration).
도 3은 일부 실시예에 따른 BS(108)(대표적인 송신 장치로서)에 대한 예시적인 하드웨어 구성을 도시한다. 도시된 하드웨어 구성은 본 명세서에 설명된 신경망 기반 프로세스와 가장 직접적으로 관련된 처리 컴포넌트 및 통신 컴포넌트를 나타내고, 디스플레이, 비-센서 주변 장치, 외부 전원 공급 장치 등과 같은 전자 장치에서 자주 구현되는 것으로 잘 이해되는 특정 컴포넌트를 생략한다. 또한, 예시된 도면은 단일 네트워크 노드(예를 들어, 5G NR 노드 B 또는 "gNB")로서 BS(108)의 구현을 나타내지만, 대신에 BS(108)의 기능 및 하드웨어 컴포넌트는 다수의 네트워크 노드 또는 장치에 걸쳐 분산될 수 있고 본 명세서에 설명된 기능을 수행하는 방식으로 분산될 수 있다.3 shows an example hardware configuration for BS 108 (as a representative transmitting device) according to some embodiments. The depicted hardware configuration represents the processing components and communication components most directly associated with the neural network-based processes described herein, and is well understood as frequently implemented in electronic devices such as displays, non-sensor peripherals, external power supplies, etc. Omit certain components. Additionally, the illustrated diagram shows an implementation of BS 108 as a single network node (e.g., 5G NR Node B or “gNB”), but instead the functionality and hardware components of BS 108 can be deployed as a single network node. Or it may be distributed across the device and in a manner that performs the functions described herein.
도시된 구성에서, BS(108)는 하나 이상의 안테나(302)를 갖는 RF 프론트 엔드(130) 및 하나 이상의 RAT를 지원하기 위한 하나 이상의 모뎀을 갖는 RF 안테나 인터페이스(304)를 포함하고, 이는 다양한 유형의 무선 통신을 용이하게 하기 위해 BS(108)의 하나 이상의 프로세서(306)와 안테나(302) 사이의 시그널링을 수행하고 처리하는 PHY 트랜시버 인터페이스로 작동한다. 안테나(302)는 서로 유사하거나 다르게 구성되고 대응하는 RAT와 연관된 하나 이상의 주파수 대역에 동조될 수 있는 다중 안테나의 하나 이상의 어레이로 배열될 수 있다. 하나 이상의 프로세서(306)는 예를 들어 하나 이상의 CPU, GPU, TPU 또는 다른 ASIC 등을 포함할 수 있다. BS(108)는 RAM, ROM, 캐시, 플래시 메모리, SSD 또는 기타 대용량 저장 장치와 같은 데이터 및/또는 실행 가능한 명령을 저장하기 위해 전자 장치에 의해 사용되는 다양한 매체 중 임의의 것을 포함하는 하나 이상의 컴퓨터 판독 가능 매체(308)를 더 포함한다. UE(110)의 메모리(208)와 마찬가지로, 설명의 용이성과 간결함을 위해, 컴퓨터 판독 가능 매체(308)는 프로세서(306)에 의한 실행을 위한 데이터 및 명령을 저장하기 위해 시스템 메모리 또는 다른 메모리를 자주 사용한다는 점에서 본 명세서에서는 "메모리(308)"로 지칭되지만, 달리 명시하지 않는 한 "메모리 308"에 대한 언급은 다른 유형의 저장 매체에도 동일하게 적용된다는 것이 이해될 것이다.In the depicted configuration, BS 108 includes an RF front end 130 with one or more antennas 302 and an RF antenna interface 304 with one or more modems to support one or more RATs, which may be of various types. It operates as a PHY transceiver interface that performs and processes signaling between one or more processors 306 of the BS 108 and the antenna 302 to facilitate wireless communication. Antennas 302 may be arranged in one or more arrays of multiple antennas that may be similarly or differently configured and tuned to one or more frequency bands associated with a corresponding RAT. One or more processors 306 may include, for example, one or more CPUs, GPUs, TPUs, or other ASICs. BS 108 is one or more computers that include any of a variety of media used by electronic devices to store data and/or executable instructions, such as RAM, ROM, cache, flash memory, SSD, or other mass storage devices. It further includes a readable medium (308). Like memory 208 of UE 110, for ease of explanation and brevity, computer-readable medium 308 refers to system memory or other memory for storing data and instructions for execution by processor 306. Due to frequent usage, it is referred to herein as “memory 308,” but it will be understood that, unless otherwise specified, reference to “memory 308” applies equally to other types of storage media.
적어도 일 실시예에서, BS(108)는 본 명세서에서 센서 세트(310)로 지칭되는 복수의 센서를 더 포함하며, 이들 중 적어도 일부는 본 명세서에 설명된 신경망 기반 방식에서 활용된다. 일반적으로 센서세트(310)의 센서는 BS(108) 환경의 일부 측면을 감지하고 해당 UE(110)에 대한 BS(108)의 RF 전파 경로 또는 RF 송신/수신 성능에 적어도 어느 정도 영향을 미치거나 이를 반영하는 파라미터를 감지할 가능성이 있다. 센서 세트(310)의 센서는 레이더 센서, 라이더 센서, 이미징 센서, 구조광 기반 깊이 센서 등과 같은 객체 검출을 위한 하나 이상의 센서를 포함할 수 있다. BS(108)가 모바일 BS인 경우, 센서 세트(310)는 또한 BS(108)의 위치 또는 자세를 결정하기 위한 하나 이상의 센서를 포함할 수 있다. 센서 세트(310)의 센서 유형의 다른 예는 이미징 센서, BS(108)의 피처에 근접한 객체를 감지하기 위한 광 센서 등을 포함할 수 있다.In at least one embodiment, BS 108 further includes a plurality of sensors, referred to herein as sensor sets 310, at least some of which are utilized in the neural network-based approach described herein. Typically, the sensors of sensor set 310 detect some aspect of the BS 108 environment and have at least some influence on the RF propagation path or RF transmit/receive performance of the BS 108 for that UE 110. There is a possibility of detecting parameters that reflect this. The sensors of sensor set 310 may include one or more sensors for object detection, such as a radar sensor, a lidar sensor, an imaging sensor, a structured light-based depth sensor, etc. If BS 108 is a mobile BS, sensor set 310 may also include one or more sensors for determining the location or attitude of BS 108. Other examples of sensor types in sensor set 310 may include imaging sensors, optical sensors for detecting objects proximate to features of BS 108, etc.
BS(108)의 하나 이상의 메모리(308)는 본 명세서에 설명되고 BS(108)에 귀속되는 다양한 기능을 수행하기 위해 BS(108)의 하나 이상의 프로세서(306) 및 기타 컴포넌트를 조작하는 실행 가능한 소프트웨어 명령 및 관련 데이터의 하나 이상의 세트를 저장하는데 사용된다. 실행 가능한 소프트웨어 명령어 세트는 예를 들어 운영 체제(OS), 다양한 드라이버(미도시), 다양한 소프트웨어 애플리케이션을 포함한다. 실행 가능한 소프트웨어 명령어 세트는 신경망 관리 모듈(314), 성능 관리 모듈(316), CSF 관리 모듈(318) 또는 MIMO 관리 모듈(320) 중 하나 이상을 더 포함한다.One or more memories 308 of BS 108 may include executable software that manipulates one or more processors 306 and other components of BS 108 to perform various functions described herein and attributed to BS 108. Used to store one or more sets of instructions and related data. The executable software instruction set includes, for example, an operating system (OS), various drivers (not shown), and various software applications. The executable software instruction set further includes one or more of a neural network management module 314, a performance management module 316, a CSF management module 318, or a MIMO management module 320.
신경망 관리 모듈(314)은 아래에 상세히 설명되는 바와 같이 BS(108)에 대한 하나 이상의 신경망을 구현한다. 성능 관리 모듈(318)은 신경망 구성 또는 선택과 관련될 수 있는 BS(108)의 다양한 성능을 결정하고 이러한 성능을 관리 컴포넌트(140)에 보고할 뿐만 아니라 RF 및 처리 성능을 포함하여 이러한 성능의 변화에 대해 BS(108)를 모니터링하고, 관리 컴포넌트(140)에 대한 이러한 성능 및 성능의 변화에 대한 보고를 관리한다. CSF 관리 모듈(318)은 대응하는 UE(110)에 대한 CSI 파일럿 신호의 생성 및 전송을 관리하고, 전송된 CSI 파일럿 신호의 분석으로부터 UE(110)에 의해 보고된 결과적인 CSI 추정 정보를 획득 및 처리하고, 결과적인 CSI 추정치의 표현을 MIMO 관리 모듈(320)에 전달하는 것을 포함하여, BS(108)와 하나 이상의 대응하는 UE(110) 사이의 CSF 프로세스를 관리하도록 동작한다. MIMO 관리 모듈(320)은 제공된 CSI 추정치에 기초하여 RF 프런트 엔드(124)의 하나 이상의 MIMO 프로세스를 제어하도록 동작한다. 이러한 MIMO 프로세스에는 빔포밍 프로세스, 시공간 코딩 프로세스, MU-MIMO 프로세스 등이 포함될 수 있다.Neural network management module 314 implements one or more neural networks for BS 108, as described in detail below. Performance management module 318 determines various performances of BS 108, which may be related to neural network configuration or selection, and reports these performances to management component 140, as well as changes in such performance, including RF and processing performance. Monitors the BS 108 for and manages reporting of such performance and changes in performance to the management component 140. The CSF management module 318 manages the generation and transmission of CSI pilot signals for the corresponding UE 110, obtains the resulting CSI estimation information reported by the UE 110 from analysis of the transmitted CSI pilot signal, and Operates to manage the CSF process between the BS 108 and one or more corresponding UEs 110, including processing and communicating a representation of the resulting CSI estimate to the MIMO management module 320. MIMO management module 320 operates to control one or more MIMO processes of RF front end 124 based on the provided CSI estimates. This MIMO process may include a beamforming process, spatiotemporal coding process, MU-MIMO process, etc.
본 명세서에 설명된 바와 같이 BS(108)의 동작을 용이하게 하기 위해, BS(108)의 하나 이상의 메모리(308)는 이러한 동작과 연관된 데이터를 추가로 저장할 수 있다. 이 데이터는 예를 들어 BS 데이터(328) 및 하나 이상의 신경망 아키텍처 구성(330)을 포함할 수 있다. BS 데이터(328)는 예를 들어 빔포밍 코드북, 소프트웨어 애플리케이션 구성 정보 등을 나타낸다. BS 데이터(328)는 특정 센서 또는 센서 유형의 존재 또는 부재를 포함하는 센서 세트(310)의 하나 이상의 센서에 관한 센서 성능 정보와 같은 BS(108)에 대한 성능 정보와, 존재하는 센서에 대해, 라이다 또는 레이더 센서의 범위 및 해상도, 이미징 카메라의 이미지 해상도 및 색상 깊이 등과 같이 해당 성능에 대한 하나 이상의 표현을 더 포함할 수 있다. 하나 이상의 신경망 아키텍처 구성(330)은 관리 컴포넌트(140)에 의해 유지되는 후보 신경망 아키텍처 구성(144)의 세트(142)로부터 선택된 BS 구현 예를 나타낸다. 따라서, 도 2의 신경망 아키텍처 구성(230)과 마찬가지로. 각각의 신경망 아키텍처 구성(330)은 BS(108)의 대응하는 신경망을 형성하기 위해 신경망 관리 모듈(314)에 의해 사용되는 대응 아키텍처 및/또는 파리미터 구성을 나타내는 데이터 및 기타 정보를 포함하는 하나 이상의 데이터 구조를 포함한다.To facilitate operation of BS 108 as described herein, one or more memories 308 of BS 108 may additionally store data associated with such operations. This data may include, for example, BS data 328 and one or more neural network architecture configurations 330. BS data 328 represents, for example, a beamforming codebook, software application configuration information, etc. BS data 328 may include performance information for BS 108, such as sensor performance information about one or more sensors in sensor set 310, including the presence or absence of a particular sensor or sensor type, and for sensors present; It may further include one or more representations of its capabilities, such as range and resolution of a LiDAR or radar sensor, image resolution and color depth of an imaging camera, etc. One or more neural network architecture configurations 330 represent examples of BS implementations selected from a set 142 of candidate neural network architecture configurations 144 maintained by management component 140. Thus, similarly to the neural network architecture configuration 230 of FIG. 2 . Each neural network architecture configuration 330 includes one or more data representing the corresponding architecture and/or parameter configuration and other information used by the neural network management module 314 to form the corresponding neural network of BS 108. Includes structure.
도 4는 일부 실시예에 따른 관리 컴포넌트(140)에 대한 예시적인 하드웨어 구성을 도시한다. 도시된 하드웨어 구성은 본 명세서에 설명된 신경망 기반 프로세스에 가장 직접적으로 관련된 처리 컴포넌트 및 통신 컴포넌트를 나타내고 이러한 전자 장치에서 자주 구현되는 것으로 잘 이해되는 특정 컴포넌트를 생략한다는 점에 유의한다. 또한, 하드웨어 구성은 단일 컴포넌트에 위치하는 것으로 도시되어 있지만, 대신에 관리 컴포넌트(140)의 기능, 따라서 하드웨어 컴포넌트는 다수의 인프라 컴포넌트 또는 노드에 걸쳐 분산될 수 있고 본 명세서에 설명된 기능을 수행하는 방식으로 분산될 수 있다.4 shows an example hardware configuration for management component 140 according to some embodiments. Note that the depicted hardware configuration represents the processing and communication components most directly related to the neural network-based processes described herein and omits certain components that are well understood to be frequently implemented in such electronic devices. Additionally, although the hardware configuration is shown as being located in a single component, the functionality of the management component 140, and thus the hardware component, may be distributed across multiple infrastructure components or nodes and perform the functions described herein. It can be distributed in some way.
위에서 언급한 바와 같이, 관리 컴포넌트(140)는 네트워크 인프라(106) 내의 임의의 다양한 컴포넌트 또는 컴포넌트의 조합으로 구현될 수 있다. 설명의 편의를 위해, 관리 컴포넌트(140)는 코어 네트워크들(102) 중 하나의 서버 또는 다른 컴포넌트로서의 예시적인 구현을 참조하여 본 명세서에서 설명되지만, 다른 실시예에서 관리 컴포넌트(140)는 예를 들어 BS(108)의 일부로서 구현될 수 있다.As mentioned above, management component 140 may be implemented with any of a variety of components or combinations of components within network infrastructure 106. For ease of explanation, management component 140 is described herein with reference to an example implementation as a server or other component of one of the core networks 102, but in other embodiments management component 140 may be configured as, for example, For example, it may be implemented as part of BS 108.
도시된 바와 같이, 관리 컴포넌트(140)는 시스템(100)의 하나 이상의 네트워크에 연결된 하나 이상의 네트워크 인터페이스(402)(예를 들어, 이더넷 인터페이스), 하나 이상의 네트워크 인터페이스(402)에 연결된 하나 이상의 프로세서(404), 및 하나 이상의 프로세서(404)에 연결된 하나 이상의 비-일시적 컴퓨터 판독 가능 저장 매체(406)(본 명세서에서는 간략하게 "메모리(406)"로 지칭됨)를 포함한다. 하나 이상의 메모리(406)는 본 명세서에 설명되고 관리 컴포넌트(140)에 귀속되는 다양한 기능을 수행하기 위해 하나 이상의 프로세서(404) 및 관리 컴포넌트(140)의 다른 컴포넌트를 조작하는 실행 가능한 소프트웨어 명령 및 관련 데이터의 하나 이상의 세트를 저장한다. 실행 가능한 소프트웨어 명령 세트에는 예를 들어 OS 및 다양한 드라이버(미도시)가 포함된다. 하나 이상의 메모리(406)에 저장된 소프트웨어는 트레이닝 모듈(408) 또는 신경망 선택 모듈(410) 중 하나 이상을 더 포함할 수 있다. 트레이닝 모듈(408)은 하나 이상의 트레이닝 데이터 세트(416)를 사용하여 CSF 경로의 송신 및 수신 장치에서 사용될 수 있는 후보 신경망 세트(142)에 대한 후보 신경망 아키텍처 구성(144)의 공동 트레이닝을 관리하도록 작동한다. 트레이닝에는 오프라인(즉, 통신 처리에 적극적으로 참여하지 않는 동안) 및/또는 온라인(즉, 통신 처리에 적극적으로 참여하는 동안) 동안 신경망을 트레이닝하는 것이 포함될 수 있다. 더욱이, 트레이닝은 개별적이거나 별개일 수 있으므로, 각 신경망은 결과가 전송 경로의 반대쪽 끝의 DNN 트레이닝에 전달되거나 영향을 주지 않고 자체 트레이닝 데이터 세트에 대해 개별적으로 트레이닝되며, 트레이닝은 데이터 스트림 전송 경로의 신경망이 동일하거나 보완적인 데이터 세트에 대해 공동으로 트레이닝되도록 하는 공동 트레이닝일 수 있다.As shown, management component 140 includes one or more network interfaces 402 (e.g., Ethernet interfaces) connected to one or more networks of system 100, one or more processors (e.g., Ethernet interfaces) connected to one or more network interfaces 402 404), and one or more non-transitory computer-readable storage media 406 (simply referred to herein as “memory 406”) coupled to one or more processors 404. One or more memories 406 may store executable software instructions and related information that manipulate one or more processors 404 and other components of management component 140 to perform various functions described herein and attributed to management component 140. Stores one or more sets of data. The set of executable software instructions includes, for example, an OS and various drivers (not shown). Software stored in one or more memories 406 may further include one or more of a training module 408 or a neural network selection module 410 . The training module 408 operates to manage joint training of a candidate neural network architecture configuration 144 using one or more training data sets 416 to a set of candidate neural networks 142 that can be used in transmitting and receiving devices in the CSF path. do. Training may include training the neural network while offline (i.e., while not actively participating in communication processing) and/or online (i.e., while actively participating in communication processing). Moreover, training can be separate or distinct, so that each neural network is trained individually on its own training data set, without the results being passed on to or affecting the DNN training at the other end of the transmission path, and training is performed on the neural network on the data stream transmission path. This could be co-training, which allows them to be jointly trained on the same or complementary data sets.
신경망 선택 모듈(410)은 도 1의 예시적인 CSF 경로(116)에 대해, BS(108) 및 UE(110)와 같은 CSF 경로의 송신 장치 및 수신 장치 중 하나 또는 둘 모두로부터 선택 관련 정보(420)를 각각 획득하고, 필터링하고, 처리하고, 그리고 이 선택 관련 정보(420)를 사용하여 CSF 경로의 송신 장치 및 수신 장치에서의 구현을 위해 후보 세트(142)로부터 공동으로 트레이닝된 신경망 아키텍처 구성 쌍(144)을 선택하도록 동작한다. 위에서 언급한 바와 같이, 이 선택 관련 정보(420)는 예를 들어 UE(110) 및 BS(108) 중 하나 또는 둘 다로부터의 현재 성능 정보, 현재 전파 경로 정보, 채널 특정 파라미터 등을 포함할 수 있다. 선택이 이루어진 후, 신경망 선택 모듈(410)은 선택된 구성과 관련된 인덱스 번호의 전송, 신경망 아키텍처 구성 자체를 나타내는 하나 이상의 데이터 구조의 전송, 또는 이들의 조합을 통해 각 네트워크 컴포넌트에 대해 선택된 신경망 아키텍처 구성(144) 표시의 전송을 시작한다. The neural network selection module 410 may, for the example CSF path 116 of FIG. 1 , receive selection-related information 420 from one or both of the transmitting and receiving devices of the CSF path, such as BS 108 and UE 110. ), respectively, obtain, filter, process, and use this selection-related information 420 to jointly train neural network architecture pairs from the candidate set 142 for implementation in the transmitter and receiver of the CSF path. Operates to select (144). As mentioned above, this selection-related information 420 may include, for example, current performance information from one or both UE 110 and BS 108, current propagation path information, channel specific parameters, etc. there is. After the selection has been made, the neural network selection module 410 selects the selected neural network architecture configuration ( 144) Start transmitting the indication.
도 5는 일부 실시예에 따른 신경망을 구현하기 위한 예시적인 기계 학습(ML) 모듈(500)을 도시한다. 본 명세서에 설명된 바와 같이, CSF 경로(예를 들어, 도 1의 CSF 경로(116)에서 각각 BS(108) 및 UE(110))의 송신 장치와 수신 장치 중 하나 또는 둘 모두는 CSI 피드백과 관련된 들어오고 나가는 무선 통신을 처리하기 위해 하나 이상의 DNN 또는 기타 신경망을 구현한다. 따라서 ML 모듈(500)은 이러한 신경망 중 하나 이상을 구현하기 위한 예시적인 모듈을 예시한다.5 shows an example machine learning (ML) module 500 for implementing a neural network according to some embodiments. As described herein, one or both of the transmitting and receiving devices in the CSF path (e.g., BS 108 and UE 110, respectively, in CSF path 116 of FIG. 1) provide CSI feedback and Implement one or more DNNs or other neural networks to process the associated incoming and outgoing wireless communications. Accordingly, ML module 500 illustrates an example module for implementing one or more of these neural networks.
도시된 예에서, ML 모듈(500)은 3개 이상의 계층으로 구성되는 연결된 노드 그룹(예를 들어, 뉴런 및/또는 퍼셉트론)으로 적어도 하나의 심층 신경망(DNN)(502)을 구현한다. 계층들 간 노드는 예를 들어 제1 계층에 있는 노드의 제1 서브세트가 제2 계층에 있는 노드의 제2 서브세트와 연결되는 부분 연결 구성과, 제1 계층에 있는 각 노드가 제2 계층에 있는 각 노드에 연결되는 완전 연결 구성 등과 같이 다양한 방식으로 구성 가능하다. 뉴런은 입력 데이터를 처리하여 0과 1 사이의 실수와 같은 연속적인 출력 값을 생성한다. 일부 경우, 출력 값은 입력 데이터가 원하는 범주에 얼마나 가까운지를 나타낸다. 퍼셉트론은 입력 데이터에 대해 이진 분류와 같은 선형 분류를 수행한다. 뉴런이든 퍼셉트론이든 노드는 다양한 알고리즘을 사용하여 적응형 학습에 기초하여 출력 정보를 생성할 수 있다. DNN(502)을 사용하여, ML 모듈(500)은 단일 선형 회귀, 다중 선형 회귀, 로지스틱 회귀, 단계별 회귀, 이진 분류, 다중 클래스 분류, 다변량 적응형 회귀 스플라인, 국부적으로 추정된 산점도 평활화(scatterplot smoothing) 등을 포함하여 다양한 유형의 분석을 수행한다.In the example shown, the ML module 500 implements at least one deep neural network (DNN) 502 with a group of connected nodes (e.g., neurons and/or perceptrons) comprised of three or more layers. Nodes between layers can be configured, for example, in a partially connected configuration such that a first subset of nodes in a first layer are connected to a second subset of nodes in a second layer, and each node in the first layer is connected to a second subset of nodes in the second layer. It can be configured in various ways, such as a fully connected configuration connected to each node in . Neurons process input data to produce continuous output values, such as real numbers between 0 and 1. In some cases, the output value indicates how close the input data is to the desired category. Perceptron performs linear classification, such as binary classification, on input data. Nodes, whether neurons or perceptrons, can generate output information based on adaptive learning using various algorithms. Using DNN 502, ML module 500 performs single linear regression, multiple linear regression, logistic regression, stepwise regression, binary classification, multiclass classification, multivariate adaptive regression spline, locally estimated scatterplot smoothing. ) perform various types of analysis, including
일부 구현에서, ML 모듈(500)은 지도 학습에 기초하여 적응적으로 학습한다. 지도 학습에서, ML 모듈(500)은 다양한 유형의 입력 데이터를 트레이닝 데이터로서 수신한다. ML 모듈(500)은 입력을 원하는 출력에 매핑하는 방법을 학습하기 위해 트레이닝 데이터를 처리한다. 일 예로, ML 모듈(500)은 신호의 디지털 샘플을 입력 데이터로서 수신하고 그 신호 내에 포함된 정보를 반영하는 이진 데이터에 신호 샘플을 매핑하는 방법을 학습한다. 또 다른 예로서, ML 모듈(500)은 이진 데이터를 입력 데이터로서 수신하고 그 이진 데이터를 신호 내에 이진 데이터가 내장된 신호의 디지털 샘플에 매핑하는 방법을 학습한다. 또한, 또 다른 예로서 아래에서 더 자세히 설명되는 바와 같이, TX 모드에서 사용되는 경우, ML 모듈(500)은 발신(outgoing) 정보 블록을 수신하고, RF 안테나 인터페이스에 의한 무선 전송에 적합한 출력을 형성하기 위해 실제로 정보 블록에 표현된 인코딩된(예를 들어, 압축된) 데이터와 인코딩된 채널을 나타내는 출력을 생성하는 방법을 모두 학습한다. 반대로, ML 모듈(500)이 RX 모드로 구현되는 경우, 실제로 정보 블록의 데이터 인코딩 및 채널 인코딩 표현을 나타내는 입력을 수신하고 그 입력을 처리하여 실제로 입력의 데이터 디코딩 및 채널 디코딩 표현인 출력을 생성하여 정보 데이터의 복구된 표현을 나타내도록 트레이닝된다. 아래에 추가로 설명된 바와 같이, TX 모드 또는 RX 모드 중 하나 또는 둘 다에서의 트레이닝은 입력으로서 센서 데이터, 입력으로서 성능 정보, 입력으로서 액세서리 정보, RF 안테나 구성, 또는 입력으로서 다른 동작 파라미터 정보 등을 사용하는 트레이닝을 포함할 수 있다.In some implementations, ML module 500 learns adaptively based on supervised learning. In supervised learning, the ML module 500 receives various types of input data as training data. ML module 500 processes training data to learn how to map input to a desired output. As an example, the ML module 500 receives digital samples of a signal as input data and learns how to map the signal samples to binary data that reflects information contained within the signal. As another example, the ML module 500 receives binary data as input data and learns how to map the binary data to digital samples of the signal with the binary data embedded within the signal. Additionally, as another example and as described in more detail below, when used in TX mode, the ML module 500 receives outgoing information blocks and forms an output suitable for wireless transmission by the RF antenna interface. To do this, we learn how to generate both the encoded (e.g. compressed) data actually represented in the information block and an output representing the encoded channel. Conversely, when ML module 500 is implemented in RX mode, it receives input that actually represents a data-encoded and channel-encoded representation of a block of information and processes that input to produce an output that is actually a data-encoded and channel-encoded representation of the input. It is trained to represent a recovered representation of information data. As described further below, training in either TX mode or RX mode, or both, may use sensor data as input, performance information as input, accessory information as input, RF antenna configuration, or other operating parameter information as input, etc. May include training in the use of .
트레이닝 절차 동안, ML 모듈(500)은 레이블이 지정된 데이터 또는 알려진 데이터를 DNN(502)에 대한 입력으로 사용한다. DNN(502)은 노드를 사용하여 입력을 분석하고 해당 출력을 생성한다. ML 모듈(500)은 해당 출력을 실제 데이터와 비교하고 노드에 의해 구현된 알고리즘을 적용하여 출력 데이터의 정확성을 향상시킨다. 그 후, DNN(502)은 적응된 알고리즘을 레이블이 지정되지 않은 입력 데이터에 적용하여 해당 출력 데이터를 생성한다. ML 모듈(500)은 통계 분석 및 적응형 학습 중 하나 또는 둘 모두를 사용하여 입력을 출력에 매핑한다. 예를 들어, ML 모듈(500)은 트레이닝 데이터로부터 학습된 특성을 사용하여 임계값 범위 또는 값 내에서 통계적으로 가능성이 높은 출력과 알려지지 않은 입력을 연관시킨다. 이를 통해 ML 모듈(500)은 복잡한 입력을 수신하여 해당 출력을 식별할 수 있다. 언급한 바와 같이, 일부 구현은 무선 통신 시스템에서 사용되는 데이터 인코딩/디코딩 방식의 특성과 동시에 그 무선 통신 시스템을 통해 전송되는 통신의 특성(예를 들어, 시간/주파수 인터리빙, 시간/주파수 디인터리빙, 컨벌루션 인코딩, 컨벌루션 디코딩, 전력 레벨, 채널 등화, 심볼간 간섭, 직교 진폭 변조/복조, 주파수 분할 다중화/역다중화, 전송 채널 특성)에 대해 ML 모듈(500)을 트레이닝한다. 이를 통해 트레이닝된 ML 모듈(500)은 신호 샘플을 입력으로 수신하고 신호에 포함된 이진 데이터와 같은 신호로부터 정보를 복구할 수 있다.During the training procedure, ML module 500 uses labeled or known data as input to DNN 502. DNN 502 uses nodes to analyze input and generate corresponding output. The ML module 500 compares the output with actual data and applies the algorithm implemented by the node to improve the accuracy of the output data. DNN 502 then applies the adapted algorithm to the unlabeled input data to generate corresponding output data. ML module 500 maps input to output using one or both statistical analysis and adaptive learning. For example, ML module 500 uses features learned from training data to associate an unknown input with a statistically likely output within a threshold range or value. Through this, the ML module 500 can receive complex input and identify the corresponding output. As noted, some implementations may vary depending on the nature of the data encoding/decoding scheme used in a wireless communication system and, at the same time, the nature of the communications transmitted over that wireless communication system (e.g., time/frequency interleaving, time/frequency deinterleaving, Train the ML module 500 for convolutional encoding, convolutional decoding, power level, channel equalization, inter-symbol interference, orthogonal amplitude modulation/demodulation, frequency division multiplexing/demultiplexing, and transmission channel characteristics. The ML module 500 trained through this can receive signal samples as input and recover information from the signal, such as binary data included in the signal.
도시된 예에서, DNN(502)은 입력 계층(504), 출력 계층(506), 및 입력 계층(504)과 출력 계층(506) 사이에 위치한 하나 이상의 은닉 계층(508)을 포함한다. 각 계층에는 임의의 수의 노드가 있으며, 계층 간 노드 수는 같거나 다를 수 있다. 즉, 입력 계층(504)은 출력 계층(506)과 동일한 수 및/또는 다른 수의 노드를 가질 수 있고, 출력 계층(506)은 하나 이상의 은닉 계층(508)과 동일한 수 및/또는 다른 수의 노드를 가질 수 있다.In the example shown, DNN 502 includes an input layer 504, an output layer 506, and one or more hidden layers 508 located between the input layer 504 and the output layer 506. Each layer has an arbitrary number of nodes, and the number of nodes between layers can be the same or different. That is, the input layer 504 may have the same number and/or a different number of nodes as the output layer 506, and the output layer 506 may have the same number and/or a different number of nodes as the one or more hidden layers 508. Can have nodes.
노드(510)는 입력 계층(504)에 포함된 여러 노드 중 하나에 대응하며, 여기서 노드는 개별적이고 독립적인 계산을 수행한다. 추가로 설명되는 바와 같이, 노드는 입력 데이터를 수신하고 하나 이상의 알고리즘을 사용하여 입력 데이터를 처리하여 출력 데이터를 생성한다. 일반적으로, 알고리즘에는 적응형 학습에 기초하여 변경되는 가중치 및/또는 계수가 포함된다. 따라서, 가중치 및/또는 계수는 신경망에 의해 학습된 정보를 반영한다. 경우에 따라 각 노드는 처리된 입력 데이터를 하나 이상의 다음 노드에 전달할지 여부를 결정할 수 있다. 설명하자면, 입력 데이터를 처리한 후, 노드(510)는 처리된 입력 데이터를 은닉 계층(508)의 노드(512)와 노드(514) 중 하나 또는 둘 다에 전달할지 여부를 결정할 수 있다. 대안적으로 또는 추가적으로, 노드(510)는 처리된 입력 데이터를 계층 연결 아키텍처에 기초하여 노드에 전달한다. 이 프로세스는 DNN(502)이 출력 계층(506)의 노드(예를 들어, 노드(516))를 사용하여 출력을 생성할 때까지 다수의 계층에 걸쳐 반복될 수 있다.Node 510 corresponds to one of several nodes included in input layer 504, where nodes perform separate and independent calculations. As further described, a node receives input data and processes the input data using one or more algorithms to produce output data. Typically, the algorithm includes weights and/or coefficients that change based on adaptive learning. Accordingly, the weights and/or coefficients reflect information learned by the neural network. In some cases, each node may decide whether to forward processed input data to one or more next nodes. To illustrate, after processing the input data, node 510 may determine whether to forward the processed input data to one or both of node 512 and node 514 of hidden layer 508. Alternatively or additionally, node 510 forwards processed input data to nodes based on a hierarchical connectivity architecture. This process may be repeated across multiple layers until DNN 502 produces output using a node of output layer 506 (e.g., node 516).
신경망은 또한 신경망 내의 어떤 노드가 연결되어 있는지, 데이터가 신경망에서 어떻게 진행 및/또는 유지되는지, 어떤 가중치와 계수가 입력 데이터를 처리하는데 사용되는지, 데이터가 어떻게 처리되는지를 결정하는 다양한 아키텍처를 사용할 수 있다. 이러한 다양한 요소는 위에서 간략하게 설명한 신경망 아키텍처 구성과 같은 신경망 아키텍처 구성을 집합적으로 설명한다. 설명하자면, LSTM(장단기 기억) 신경망과 같은 순환 신경망은 입력 데이터 시퀀스의 이전 부분의 정보를 유지하기 위해 노드 연결 사이에 싸이클을 형성한다. 그런 다음 순환 신경망은 입력 데이터 시퀀스의 후속 부분에 대해 보유된 정보를 사용한다. 또 다른 예로서, 피드포워드 신경망은 정보를 유지하기 위한 사이클을 형성하지 않고 정보를 포워드 연결로 전달한다. 노드 연결의 맥락에서 설명되었지만, 신경망 아키텍처 구성은 DNN(502) 또는 다른 신경망이 입력 데이터를 처리하는 방법에 영향을 미치는 다양한 파라미터 구성을 포함할 수 있다는 것이 이해되어야 한다.Neural networks can also use a variety of architectures that determine which nodes within the network are connected, how data progresses and/or is maintained in the network, what weights and coefficients are used to process the input data, and how the data is processed. there is. These various elements collectively describe a neural network architecture configuration, such as the neural network architecture configuration outlined above. To explain, recurrent neural networks, such as long-short-term memory (LSTM) networks, form cycles between node connections to retain information from previous parts of the input data sequence. The recurrent neural network then uses the information held for subsequent parts of the input data sequence. As another example, a feedforward neural network passes information to forward connections without forming a cycle to retain the information. Although described in the context of node connections, it should be understood that neural network architecture configurations may include various parameter configurations that affect how the DNN 502 or another neural network processes input data.
신경망의 신경망 아키텍처 구성은 다양한 아키텍처 및/또는 파라미터 구성으로 특징지어질 수 있다. 설명을 위해, DNN(502)이 컨볼루션 신경망(CNN)을 구현하는 예를 고려한다. 일반적으로, 컨벌루션 신경망은 입력 데이터를 필터링하기 위해 계층들이 컨볼루션 연산을 사용하여 데이터를 처리하는 DNN 유형에 해당한다. 따라서, CNN 아키텍처 구성은 예를 들어 풀링 파라미터(들), 커널 파라미터(들), 가중치, 및/또는 계층 파라미터(들)로 특징지어질 수 있다.The neural network architecture configuration of a neural network may be characterized by various architectures and/or parameter configurations. To illustrate, consider an example where DNN 502 implements a convolutional neural network (CNN). In general, a convolutional neural network corresponds to a type of DNN in which layers process data using convolution operations to filter input data. Accordingly, the CNN architecture configuration may be characterized by, for example, pooling parameter(s), kernel parameter(s), weights, and/or layer parameter(s).
풀링 파라미터는 입력 데이터의 차원을 감소시키는 컨벌루션 신경망 내의 풀링 계층을 지정하는 파라미터에 해당한다. 설명하자면, 풀링 계층은 제1 계층의 노드 출력을 제2 계층의 노드 입력으로 결합할 수 있다. 대안적으로 또는 추가적으로, 풀링 파라미터는 신경망이 데이터를 풀링하는 데이터 계층의 방법과 위치를 지정한다. 예를 들어, "최대 풀링"을 나타내는 풀링 파라미터는 제1 계층의 노드에 의해 생성된 데이터 그룹으로부터 최대값을 선택함으로써 풀링하고, 최대값을 제2 계층의 단일 노드에 대한 입력으로 사용하도록 신경망을 구성한다. "평균 풀링"을 나타내는 풀링 파라미터는 제1 계층의 노드에 의해 생성된 데이터 그룹으로부터 평균값을 생성하고 해당 평균값을 제2 계층의 단일 노드에 대한 입력으로 사용하도록 신경망을 구성한다.The pooling parameter corresponds to a parameter that specifies a pooling layer within a convolutional neural network that reduces the dimensionality of the input data. To explain, a pooling layer may combine node outputs from a first layer with node inputs from a second layer. Alternatively or additionally, the pooling parameters specify how and where in the data layer the neural network pools data. For example, a pooling parameter that stands for "maximum pooling" pools by selecting the maximum value from a group of data generated by a node in the first layer, and sets up a neural network to use that maximum as input to a single node in the second layer. Compose. The pooling parameter, which stands for “average pooling,” configures the neural network to generate an average value from a group of data generated by a node in the first layer and use that average value as input to a single node in the second layer.
커널 파라미터는 입력 데이터 처리에 사용되는 필터 크기(예를 들어, 폭, 높이)를 나타낸다. 대안으로 또는 추가적으로, 커널 파라미터는 입력 데이터를 필터링하고 처리하는데 사용되는 커널 방법의 유형을 지정한다. 예를 들어, 지원 벡터 머신은 회귀 분석을 사용하여 데이터를 식별 및/또는 분류하는 커널 방법에 해당한다. 다른 유형의 커널 방법에는 가우스 프로세스, 표준 상관 분석, 스펙트럼 클러스터링 방법 등이 포함된다. 따라서, 커널 파라미터는 신경망에 적용할 필터 크기 및/또는 커널 방법의 종류를 나타낼 수 있다. 가중치 파라미터는 입력 데이터를 분류하기 위해 노드 내 알고리즘에서 사용되는 가중치와 편향을 지정한다. 일부 구현에서, 가중치와 편향은 트레이닝 데이터로부터 생성된 파라미터 구성과 같은 학습된 파라미터 구성이다. 계층 파라미터는 제1 계층(예를 들어, 출력 층(506))의 모든 노드를 제2 계층(예를 들어, 은닉 계층(508))의 모든 노드에 연결함을 나타내는 완전 연결 계층 유형, 제1 계층 어떤 노드가 제2 게층으부터 연결 해제되는지를 나타내는 부분 연결 계층 유형, 신경망 내에서 활성화할 필터 및/또는 계층을 나타내는 활성화 계층 유형과 같은 계층 연결 및/또는 계층 유형을 지정한다. 대안적으로 또는 추가적으로, 계층 파라미터는 정규화 계층 유형, 컨벌루션 계층 유형, 풀링 계층 유형 등과 같은 노드 계층의 유형을 지정한다.Kernel parameters indicate the filter size (e.g. width, height) used to process input data. Alternatively or additionally, the kernel parameter specifies the type of kernel method used to filter and process the input data. For example, support vector machines correspond to kernel methods that use regression analysis to identify and/or classify data. Other types of kernel methods include Gaussian processes, canonical correlation analysis, spectral clustering methods, etc. Accordingly, the kernel parameter may indicate the type of filter size and/or kernel method to be applied to the neural network. The weight parameter specifies the weight and bias used by the in-node algorithm to classify the input data. In some implementations, the weights and biases are learned parameter configurations, such as parameter configurations generated from training data. The layer parameter is a fully connected layer type, first layer indicating that it connects all nodes of a first layer (e.g., output layer 506) to all nodes of a second layer (e.g., hidden layer 508). Specifies layer connections and/or layer types, such as a partially connected layer type indicating which nodes are disconnected from the second layer, and an activation layer type indicating which filters and/or layers to activate within the neural network. Alternatively or additionally, the layer parameters specify the type of node layer, such as normalization layer type, convolutional layer type, pooling layer type, etc.
풀링 파라미터, 커널 파라미터, 가중치 파라미터, 및 계층 파라미터의 맥락에서 설명하였지만, 본 명세서에 제공된 명령과 일치하는 DNN을 형성하기 위해 다른 파라미터 구성이 사용될 수 있음을 이해할 것이다. 따라서, 신경망 아키텍처 구성에는 DNN이 입력 데이터를 처리하여 출력 데이터를 생성하는 방법에 영향을 주는 DNN에 적용할 수 있는 임의의 적합한 유형의 구성 파라미터가 포함될 수 있다.Although described in the context of pooling parameters, kernel parameters, weight parameters, and layer parameters, it will be understood that other parameter configurations may be used to form a DNN consistent with the instructions provided herein. Accordingly, the neural network architecture configuration may include any suitable type of configuration parameters applicable to the DNN that affect how the DNN processes input data to produce output data.
일부 실시예에서, ML 모듈(500)의 구성은 현재 동작 환경에 더 기초한다. 설명을 위해, 신호의 디지털 샘플로부터 이진 데이터를 생성하도록 트레이닝된 ML 모듈을 고려한다. RF 신호 전파 환경은 종종 물리적 환경을 통해 이동하는 신호의 특성을 수정한다. RF 신호 전파 환경은 종종 변경되며 이는 환경이 신호를 수정하는 방식에 영향을 미친다. 예를 들어, 제1 RF 신호 전파 환경은 첫 번째 방식으로 신호를 수정하는 반면, 제2 RF 신호 전파 환경은 첫 번째와 다른 방식으로 신호를 수정한다. 이러한 차이는 ML 모듈(500)에 의해 생성된 출력 결과의 정확성에 영향을 미친다. 예를 들어, 제1 RF 신호 전파 환경에서 전송된 통신을 처리하도록 구성된 DNN(502)은 제2 RF 신호 전파 환경에서 전송된 통신을 처리할 때 오류를 생성하거나 성능을 제한할 수 있다. DNN(502)을 구현하는 컴포넌트의 센서 세트의 특정 센서는 현재 RF 신호 전파 환경의 하나 이상의 양태를 나타내는 센서 데이터를 제공할 수 있다. 위에 언급된 예에는 LOS 전파 경로 내에서 간섭 객체의 존재 여부를 결정하기 위한 라이다, 레이더 또는 기타 객체 감지 센서, 컴포넌트에 대한 사용자 신체의 존재 및/또는 위치를 결정하기 위한 UI 센서가 포함될 수 있다. 그러나, 이용 가능한 특정 센서 능력은 센서를 구현하는 특정 컴포넌트에 따라 달라질 수 있다는 것이 이해될 것이다. 예를 들어, BS(108)는 라이다 또는 레이더 기능을 가질 수 있으므로 근접한 객체를 감지하는 능력을 가질 수 있는 반면, UE(110)는 라이다 및 레이더 기능이 없을 수 있다. 다른 예로서, 스마트폰(UE(110)의 일 실시예)에는 스마트폰이 사용자의 주머니나 가방에 있는지 여부를 감지하는데 사용할 수 있는 광 센서가 있을 수 있지만, 노트북 컴퓨터(UE(110)의 다른 실시예)에는 이러한 기능이 없을 수 있다. 이와 같이, 일부 실시예에서, ML 모듈(500)에 대해 구현된 특정 구성은 ML 모듈(500)을 구현하는 장치의 특정 센서 구성에 적어도 부분적으로 의존할 수 있다.In some embodiments, configuration of ML module 500 is further based on the current operating environment. To illustrate, consider a ML module trained to generate binary data from digital samples of a signal. The RF signal propagation environment often modifies the characteristics of the signal as it travels through the physical environment. The RF signal propagation environment often changes, which affects how the environment modifies the signal. For example, a first RF signal propagation environment modifies the signal in a first manner, while a second RF signal propagation environment modifies the signal in a different manner than the first. These differences affect the accuracy of the output results produced by ML module 500. For example, DNN 502 configured to process communications transmitted in a first RF signal propagation environment may generate errors or limit performance when processing communications transmitted in a second RF signal propagation environment. Certain sensors in the sensor set of components implementing DNN 502 may provide sensor data indicative of one or more aspects of the current RF signal propagation environment. Examples mentioned above may include lidar, radar, or other object detection sensors to determine the presence of interfering objects within the LOS propagation path, and UI sensors to determine the presence and/or position of the user's body relative to the component. . However, it will be appreciated that the specific sensor capabilities available may vary depending on the specific component implementing the sensor. For example, BS 108 may have lidar or radar capabilities and therefore the ability to detect nearby objects, while UE 110 may not have lidar or radar capabilities. As another example, a smartphone (one embodiment of the UE 110) may have an optical sensor that can be used to detect whether the smartphone is in the user's pocket or bag, while a laptop computer (an embodiment of the UE 110) may have an optical sensor that can be used to detect whether the smartphone is in the user's pocket or bag. Example) may not have this function. As such, in some embodiments, the particular configuration implemented for ML module 500 may depend, at least in part, on the particular sensor configuration of a device implementing ML module 500.
ML 모듈(500)의 구조적 구성은 또한 ML 모듈(500)을 구현하는 노드, ML 모듈(500)을 구현하는 노드의 업스트림 또는 다운스트림의 하나 이상의 노드, 또는 이들의 조합의 성능에 기초할 수 있다. 예를 들어, UE(110)는 배터리 전력이 제한될 수 있으므로, UE(110)와 BS(108) 모두에 대한 ML 모듈(500)은 예를 들어 양단의 ML 모듈(500)이 낮은 전력 소비에 더 적합한 CSI 추정 코딩 방식을 사용한다. 또한, 일부 실시예에서, ML 모듈(500)의 아키텍처 구성은 CSI 피드백을 위한 TX 처리 모듈에서 구현되는 경우, CSI가 하나 이상의 MIMO 프로세스의 제어를 위해 고려될 미래 기간의 CSI 예측(예상 미래 CSI 추정치)에 기초하거나 이를 위해 트레이닝될 수 있으며, 이에 따라 ML 모듈(500)은 이러한 예측을 사용하도록 트레이닝될 수 있다.The structural configuration of ML module 500 may also be based on the performance of a node implementing ML module 500, one or more nodes upstream or downstream of a node implementing ML module 500, or a combination thereof. . For example, the UE 110 may be limited in battery power, so the ML module 500 for both the UE 110 and the BS 108 may have low power consumption, for example. Use a more suitable CSI estimation coding method. Additionally, in some embodiments, the architectural configuration of the ML module 500, when implemented in the TX processing module for CSI feedback, is configured to provide a CSI prediction (estimated future CSI estimate) of a future period in which CSI will be considered for control of one or more MIMO processes. ), and the ML module 500 may be trained accordingly to use these predictions.
따라서, 일부 실시예에서, ML 모듈(500)을 구현하는 장치는 성능 파라미터, RF 환경 파라미터 등의 다양한 조합에 대해 다양한 신경망 아키텍처 구성을 구현하도록 구성될 수 있다. 예를 들어, 장치는 이미징 카메라가 장치에서 사용 가능하고 CSF 경로의 다른 장치가 라이다를 사용할 때 사용하기 위한 하나 이상의 신경망 아키텍처 구성, 및 이미징 카메라가 장치에서 사용 가능하지 않고 다른 장치가 레이더를 사용할 때 사용하기 위한 하나 이상의 신경망 아키텍처 구성의 다른 세트에 액세스할 수 있다.Accordingly, in some embodiments, a device implementing ML module 500 may be configured to implement various neural network architecture configurations for various combinations of performance parameters, RF environment parameters, etc. For example, the device may configure one or more neural network architectures for use when an imaging camera is available on the device and another device in the CSF path uses lidar, and when an imaging camera is not available on the device and another device uses lidar. When using one or more neural network architectures, you have access to a different set of configurations.
일부 실시예에서, ML 모듈(500)을 구현하는 장치는 ML 모듈(500)에 사용될 수 있는 후보 신경망 아키텍처 구성 세트의 일부 또는 전부를 로컬로 저장한다. 예를 들어, 후보 신경망 아키텍처 구성은 하나 이상의 성능 파라미터, 전파 환경 파라미터, 하나 이상의 채널 등과 같은 하나 이상의 파라미터를 입력으로 취하는 다른 데이터 구조 또는 룩업 테이블(LUT)에 의해 인덱싱될 수 있으며, 입력 파라미터(들)를 고려하여 동작에 적합한 해당 로컬로 저장된 후보 신경망 아키텍처 구성과 관련된 식별자를 출력할 수 있다. 그러나, 일부 실시예에서 송신 장치에 사용되는 신경망과 수신 장치에 사용되는 신경망은 공동으로 트레이닝되므로, 각 장치가 ML 모듈(500)에 대해 다른 장치가 상호 보완적인 ML 모듈(500)에 대해 선택한 신경망 아키텍처 구성과 공동으로 트레이닝되었거나 적어도 동작상 호환되는 신경망 아키텍처 구성을 선택하도록 돕기 위해 송신 장치와 수신 장치 사이에 메커니즘이 사용되어야 할 수도 있다. 이 메커니즘은 예를 들어 두 장치 사이에 직접적으로 또는 관리 컴포넌트(140)를 통해 전송되는 조정 시그널링을 포함할 수 있거나, 관리 컴포넌트(140)는 각 장치에 의해 제안된 서브세트로부터 호환 가능한 공동 트레이닝된 아키텍처 구성 쌍을 선택하는 심판 역할을 할 수 있다.In some embodiments, a device implementing ML module 500 locally stores some or all of a set of candidate neural network architecture configurations that may be used in ML module 500. For example, a candidate neural network architecture configuration may be indexed by a lookup table (LUT) or another data structure that takes as input one or more parameters, such as one or more performance parameters, propagation environment parameters, one or more channels, etc., and may be indexed by a lookup table (LUT) of the input parameter(s). ), an identifier associated with the corresponding locally stored candidate neural network architecture configuration suitable for operation can be output. However, in some embodiments, the neural network used in the transmitting device and the neural network used in the receiving device are trained jointly, so that each device uses the neural network selected by the other device for the complementary ML module 500. A mechanism may need to be used between the transmitting and receiving devices to help select a neural network architecture configuration that is jointly trained or at least operationally compatible with the architecture configuration. This mechanism may include, for example, coordinated signaling sent between the two devices directly or through the management component 140, or the management component 140 may provide compatible jointly trained signals from the subsets proposed by each device. It can act as a referee in selecting pairs of architectural configurations.
그러나, 다른 실시예에서는 송신 장치 및 수신 장치의 대응 ML 모듈(500)에 사용될 적절한 공동 트레이닝된 신경망 아키텍처 구성 쌍을 선택하도록 관리 컴포넌트(140)를 작동시키는 것이 더 효율적이거나 유리할 수 있다. 이 접근 방식에서, 관리 컴포넌트(140)는 송신 및 수신 장치로부터 선택 프로세스에 사용될 수 있는 파라미터 중 일부 또는 전부를 나타내는 정보를 획득하고, 이 정보로부터 관리 컴포넌트(140)에서 유지되는 이러한 구성 세트(142)로부터 공동 트레이닝된 신경망 아키텍처 구성 쌍(144)을 선택한다. 관리 컴포넌트(140)에서 유지된다. 이 선택 프로세스는 예를 들어 하나 이상의 알고리즘, LUT 등을 사용하여 구현될 수 있다. 그런 다음 관리 컴포넌트(140)는 해당 장치의 ML 모듈(500)에 대해 선택된 신경망 아키텍처 구성의 식별자 또는 기타 표시를 각 장치에 전송할 수 있거나(각 장치가 로컬로 저장된 사본을 갖는 경우), 관리 컴포넌트(140)는 해당 장치에 대해 선택된 신경망 아키텍처 구성을 나타내는 하나 이상의 데이터 구조를 전송할 수 있다.However, in other embodiments it may be more efficient or advantageous to operate the management component 140 to select an appropriate pair of co-trained neural network architecture configurations to be used in the corresponding ML modules 500 of the transmitting and receiving devices. In this approach, management component 140 obtains information from transmitting and receiving devices indicating some or all of the parameters that can be used in the selection process, and from this information creates a set of such configurations 142 maintained in management component 140. ) Select a jointly trained neural network architecture configuration pair 144 from . It is maintained in management component 140. This selection process may be implemented using, for example, one or more algorithms, LUTs, etc. The management component 140 may then transmit to each device an identifier or other indication of the neural network architecture configuration selected for that device's ML module 500 (if each device has a locally stored copy), or the management component ( 140) may transmit one or more data structures representing the neural network architecture configuration selected for the device.
송신 및 수신 장치에 대한 신경망 아키텍처 구성의 적절한 쌍을 선택하는 프로세스를 용이하게 하기 위해, 적어도 하나의 실시예에서 관리 컴포넌트(140)는 신경망 관리 모듈과 트레이닝 모듈의 적절한 조합을 사용하여 트레이닝 CSF 경로에서 ML 모듈(500)을 트레이닝시킨다. 트레이닝은 활성(active) 통신 교환이 발생하지 않는 경우 오프라인으로 수행되거나 활성 통신 교환 중에 온라인으로 수행될 수 있다. 예를 들어, 관리 컴포넌트(140)는 수학적으로 트레이닝 데이터를 생성하고, 트레이닝 데이터를 저장하는 파일에 액세스하고, 실제 통신 데이터를 획득할 수 있다. 그런 다음 관리 컴포넌트(140)는 후속 사용을 위해 다양한 학습된 신경망 아키텍처 구성을 추출하고 저장한다. 일부 구현에서는 각각의 신경망 아키텍처 구성에 입력 특성을 저장하며, 이에 따라 입력 특성은 개별 신경망 아키텍처 구성에 대응하는 RF 신호 전파 환경 및 성능(capability) 구성 중 하나 또는 둘 모두의 다양한 속성을 기술한다. 구현에서, 신경망 관리자는 현재 RF 신호 전파 환경 및 현재 동작 환경을 입력 특성에 매칭시켜 신경망 아키텍처 구성을 선택하고, 현재 동작 환경에는 센서 성능, RF 성능, 스트리밍 액세서리 성능, 처리 성능, 스케줄링 대기 시간 등과 같은 트레이닝 CSF 경로를 따라 하나 이상의 노드의 성능 표시가 포함된다. To facilitate the process of selecting an appropriate pair of neural network architecture configurations for the transmitting and receiving devices, in at least one embodiment the management component 140 may use an appropriate combination of a neural network management module and a training module to configure the training CSF path. Train the ML module 500. Training may be performed offline, when no active communication exchange is occurring, or online, during an active communication exchange. For example, management component 140 can mathematically generate training data, access files storing training data, and obtain actual communication data. Management component 140 then extracts and stores the various learned neural network architecture configurations for subsequent use. Some implementations store input characteristics in each neural network architecture configuration, whereby the input characteristics describe various properties of one or both of the RF signal propagation environment and the capability configuration that correspond to the individual neural network architecture configuration. In the implementation, the neural network manager selects the neural network architecture configuration by matching the current RF signal propagation environment and the current operating environment to the input characteristics, and the current operating environment includes factors such as sensor performance, RF performance, streaming accessory performance, processing performance, scheduling latency, etc. A performance representation of one or more nodes along the training CSF path is included.
언급한 바와 같이, BS(108) 및 UE(110)와 같이 무선 통신 중인 네트워크 장치는, 각 네트워크 장치에서 하나 이상의 DNN을 사용하여 무선 통신 교환을 처리하도록 구성할 수 있으며, 여기서 각 DNN은 CSI 추정 프로세스 또는 CSF 프로세스를 촉진하기 위해 하나 이상의 하드 코딩된 또는 고정된 설계 블록에 의해 기존에 구현된 하나 이상의 기능을 대체한다. 더욱이, 각각의 DNN은 네트워크 장치의 센서 세트 중 하나 이상의 센서로부터의 현재 센서 데이터 및/또는 체인(116)을 따른 일부 또는 모든 노드로부터의 성능 데이터를 추가로 통합하여 실제로 현재 동작 환경을 고려하여 동작을 수정하거나 적응할 수 있다.As mentioned, network devices in wireless communication, such as BS 108 and UE 110, may be configured to handle wireless communication exchanges using one or more DNNs in each network device, where each DNN performs CSI estimation. Replaces one or more previously implemented functions by one or more hard-coded or fixed design blocks to facilitate a process or CSF process. Moreover, each DNN may further integrate current sensor data from one or more sensors in the network device's sensor set and/or performance data from some or all nodes along the chain 116 to actually operate taking into account the current operating environment. can be modified or adapted.
이를 위해, 도 6은 도 1의 예시적인 CSF 경로(116)에서 DNN 구현을 위한 예시적인 동작 환경(600)을 도시하며, 여기서 BS(108)는 송신 장치로 동작하고 UE(110)는 수신 장치로 동작한다. 도시된 예에서, UE(110)의 신경망 관리 모듈(222)은 CSF 송신기(TX) 처리 모듈(602)을 구현하는 반면, BS(108)의 신경망 관리 모듈(314)은 CSF 수신기(RX) 처리 모듈(604)을 구현한다. 적어도 하나의 실시예에서, 이러한 처리 모듈 각각은 도 5의 ML 모듈(500)의 하나 이상의 DNN(502)을 참조하여 위에서 설명한 것과 같이 대응하는 ML 모듈의 구현을 통해 하나 이상의 DNN을 구현한다.To this end, Figure 6 illustrates an example operating environment 600 for a DNN implementation in the example CSF path 116 of Figure 1, where BS 108 operates as a transmitting device and UE 110 acts as a receiving device. It operates as In the example shown, neural network management module 222 of UE 110 implements CSF transmitter (TX) processing module 602, while neural network management module 314 of BS 108 implements CSF receiver (RX) processing. Implements module 604. In at least one embodiment, each of these processing modules implements one or more DNNs through implementation of corresponding ML modules, as described above with reference to one or more DNNs 502 of ML modules 500 of Figure 5.
도시된 접근 방식에서, 동작 환경(600)은 CSI 추정값을 생성하는 프로세스에 대해 기존 접근 방식을 사용하지만 CSI 추정값을 인코딩하고 BS(108)로 다시 전송하기 위해 신경망 기반 접근 방식을 사용한다. 따라서, CSF 관리 모듈(318)은 하나 이상의 CSI 파일럿 신호(608)의 시퀀스를 생성하며, 이들 각각은 하나 이상의 안테나(302)를 통해 UE(110)로 전송되는 대응하는 RF 신호(610)로 변환하기 위해 BS(108)의 RF 안테나 인터페이스(304)에 제공된다. RF 신호(610)는 하나 이상의 안테나(202) 및 RF 안테나 인터페이스(204)를 통해 UE(110)에서 수신되고 처리되며, 결과적으로 캡처된 신호(612)는 CSI 추정 모듈(226)에 의해 분석되어 전송된 CSI 파일럿 신호(608)에 대응하는 안테나/수신기/부반송파에 대한 하나 이상의 CSI 추정치를 생성한다. CSI 추정 모듈(226)은 CSI 추정을 위해 잘 알려진 다양한 독점 기술을 사용할 수 있다. 일반적으로, 이러한 CSI 추정 기술은 CSI 파일럿 신호(608)의 파라미터가 선험적으로 알려져 있다는 사실을 활용하므로 캡처된 신호(612)의 실제 수신 형태는 CSI 추정을 결정하기 위해 예상 수신 형태와 비교될 수 있다.In the depicted approach, operating environment 600 uses a conventional approach for the process of generating CSI estimates, but uses a neural network-based approach to encode and transmit the CSI estimates back to BS 108. Accordingly, the CSF management module 318 generates a sequence of one or more CSI pilot signals 608, each of which is converted into a corresponding RF signal 610 that is transmitted to the UE 110 via one or more antennas 302. To do this, it is provided to the RF antenna interface 304 of the BS 108. RF signal 610 is received and processed at UE 110 via one or more antennas 202 and RF antenna interface 204, and the resulting captured signal 612 is analyzed by CSI estimation module 226 to Generate one or more CSI estimates for the antenna/receiver/subcarrier corresponding to the transmitted CSI pilot signal 608. CSI estimation module 226 may use a variety of well-known proprietary techniques for CSI estimation. Typically, these CSI estimation techniques utilize the fact that the parameters of the CSI pilot signal 608 are known a priori so that the actual received shape of the captured signal 612 can be compared to the expected received shape to determine the CSI estimate. .
기존의 CSF 프로세스에서, 해당 안테나/수신기/부반송파 조합에 대한 CSI 추정치는 CSI 추정 행렬의 해당 인덱스 위치에 추가되며, 완료되면 CSI 추정 행렬에 대해 전송될 데이터의 총량을 줄이기 위해 벡터 양자화(VQ)와 같은 일부 고정되고 하드코딩된 압축 알고리즘을 사용하여 UE에서 BS로 다시 전송된다. 그러나, 대규모 MIMO 시스템 또는 MU-MIMO 시스템과 같은 복잡한 시스템에서는 안테나, 부반송파 및 사용자 수가 증가하면 결과 CSI 추정 행렬의 크기가 기하급수적으로 증가하며 이는 전송을 위해 CSI 추정 행렬을 양자화하거나 압축하는 기존의 하드코딩된 알고리즘 접근 방식을 실행 불가능하게 만들거나 적어도 지나치게 복잡하게 만들 수 있다.In a traditional CSF process, the CSI estimate for that antenna/receiver/subcarrier combination is added to the corresponding index position in the CSI estimate matrix, and upon completion, vector quantization (VQ) and It is transmitted back from the UE to the BS using some fixed, hard-coded compression algorithm of the same. However, in complex systems such as large-scale MIMO systems or MU-MIMO systems, as the number of antennas, subcarriers, and users increases, the size of the resulting CSI estimation matrix increases exponentially, which is beyond the traditional hard to quantize or compress the CSI estimation matrix for transmission. This can make coded algorithmic approaches unfeasible, or at least overly complex.
따라서, 하드코딩되거나 알고리즘적인 CSI 추정 양자화 프로세스를 사용하는 대신, UE(110)의 CSF TX 처리 모듈(602)과 BS(108)의 CSF RX 처리 모듈(604)은 BS(108)에 의해 전송된 CSI 파일럿 시그널링으로부터 UE(110)에 의해 결정된 CSI 추정치를 나타내는 데이터를 통신하기 위해 UE(110)와 BS(108) 사이의 신경망 기반 무선 피드백 경로를 지원하기 위해 상호 동작한다. 이를 위해, UE(110)의 CSF TX 처리 모듈(602)의 하나 이상의 DNN는 CSI 추정 모듈(226)에 의해 생성된 하나 이상의 CSI 추정치를 나타내는 발신 CSI 추정 데이터 블록(614)을 입력으로 수신하고, 이들 입력으로부터 대응하는 CSI 출력(620)을 생성하도록 트레이닝된다.Therefore, instead of using a hardcoded or algorithmic CSI estimation quantization process, the CSF TX processing module 602 of UE 110 and the CSF RX processing module 604 of BS 108 process the They interoperate to support a neural network-based wireless feedback path between UE 110 and BS 108 to communicate data representing CSI estimates determined by UE 110 from CSI pilot signaling. To this end, one or more DNNs of the CSF TX processing module 602 of the UE 110 receive as input an outgoing CSI estimate data block 614 representing one or more CSI estimates generated by the CSI estimation module 226; It is trained to generate the corresponding CSI output 620 from these inputs.
CSF TX 처리 모듈(602)에 제공되는 선택적인 다른 입력은 예를 들어 센서 세트(210)로부터의 센서 데이터(616) 및 RF 안테나 인터페이스(204)의 전송측에 대한 현재 동작 파라미터를 나타내는 네트워크 상태 정보(618)를 포함할 수 있고, 따라서 시그널링을 전송하기 위한 현재 RF 전파 환경의 표현 역할을 할 수 있다. 또한, 채널 상태는 시시각각 변할 수 있으며, 이에 따라 CSI 추정치가 UE(110)에서 생성되는 때와 MIMO 관리 모듈(320)이 하나 이상의 MIMO 프로세스를 제어하기 위해 CSI 추정치를 사용하는 때 사이의 대기시간(여기서는 "스케줄링 대기시간"으로 지칭됨)으로 인해 현재 기간의 MIMO 프로세스를 제어하는데 사용되는 이전 기간의 CSI 추정 정보가 최신이 아닐 수 있다는 것이 이해될 것이다. 이러한 스케줄링 대기시간을 보상하기 위해, CSF TX 처리 모듈(602)의 하나 이상의 DNN은 CSI 출력(620)에 표현된 예측된 미래 CSI 추정치(들)가 BS(108)의 MIMO 관리 모듈(320)에 의해 사용될 다음 기간(BS(108)의 스케줄링 대기시간에 의해 표시죔)에 대한 미래 CSI 추정치(들)의 예측인 CSI 출력을 제공하기 위해 다양한 스케줄링 대기시간에 대해 트레이닝될 수 있다. 따라서, 이를 위해, UE(110)는 또한 BS(108)에 대한 스케줄링 대기시간을 나타내는 스케줄링 대기시간 정보(619)를 입력으로서 CSF TX 처리 모듈(602)에 제공할 수 있으며 이는 BS(108)의 동작 분석을 통해 결정될 수 있고, BS(108)에 의한 스케줄링의 명시적인 광고에 기초하여 결정될 수 있고, 다른 UE에 의해 관찰되는 BS(108)의 스케줄링 대기시간에 기초하여 결정될 수 있다.Optional other inputs provided to CSF TX processing module 602 include, for example, sensor data 616 from sensor set 210 and network state information indicating current operating parameters for the transmitting side of RF antenna interface 204. 618, and thus may serve as a representation of the current RF propagation environment for transmitting signaling. Additionally, channel conditions may change from moment to moment, and accordingly, the latency between when the CSI estimate is generated at the UE 110 and when the MIMO management module 320 uses the CSI estimate to control one or more MIMO processes ( It will be appreciated that due to (referred to herein as “scheduling latency”) the CSI estimation information of a previous period used to control the MIMO process of the current period may be out of date. To compensate for this scheduling latency, one or more DNNs in the CSF TX processing module 602 send the predicted future CSI estimate(s) expressed in the CSI output 620 to the MIMO management module 320 of the BS 108. Can be trained for various scheduling latencies to provide a CSI output that is a prediction of the future CSI estimate(s) for the next period (as indicated by the scheduling latency of BS 108) to be used by the BS 108. Accordingly, for this purpose, the UE 110 may also provide scheduling latency information 619 indicating the scheduling latency for the BS 108 as input to the CSF TX processing module 602, which corresponds to the scheduling latency of the BS 108. It may be determined through behavioral analysis, may be determined based on explicit advertisement of scheduling by BS 108, and may be determined based on scheduling latency of BS 108 observed by other UEs.
RF 안테나 인터페이스(204) 및 하나 이상의 안테나(202)는 이 CSI 출력(620)을 BS(108)에 의한 수신을 위해 무선으로 전송되는 대응 RF 신호(622)로 변환한다. 특히, 일부 실시예에서 CSF TX 처리 모듈(602)의 하나 이상의 DNN은 실제로 입력 CSI 추정 데이터 블록(614)의 인코딩된(예를 들어, 압축된) 데이터 표현을 생성하는 처리를 제공하도록 트레이닝되며, 이러한 처리는 알고리즘 데이터 양자화 프로세스의 힘들고 비효율적인 하드코딩을 요구하는 대신 공동 훈련을 통해 하나 이상의 DNN으로 트레이닝된다. 또한, 일부 실시예에서, 하나 이상의 DNN은 디지털-아날로그 변환 및 RF 전송을 위해 준비된 CSI 추정 데이터 블록(614)의 채널 인코딩(변조 포함) 표현을 실제로 제공하도록 추가로 동작할 수 있다. 즉, 별도의 개별 처리 블록을 사용하여 데이터 인코딩 프로세스를 구현한 후 초기 RF 인코딩 프로세스를 수행하는 것이 아니라, CSF TX 처리 모듈(602)은 이러한 프로세스와 동등한 것을 동시에 제공하고, 센서 데이터(616), 네트워크 상태 정보(618) 및 스케줄링 대기시간 정보(619)와 같은 다른 현재 데이터에 적어도 부분적으로 기초하여 실제로 소스 인코딩 및 채널 인코딩되어 RF 전송 준비가 된 해당 신호를 생성하도록 트레이닝될 수 있으며, 스케줄링 대기시간이 고려되는 경우 예측된 미래 CSI 추정치를 반영하도록 수정된다.RF antenna interface 204 and one or more antennas 202 convert this CSI output 620 into a corresponding RF signal 622 that is transmitted wirelessly for reception by BS 108. In particular, in some embodiments, one or more DNNs of the CSF TX processing module 602 are trained to provide processing that actually produces an encoded (e.g., compressed) data representation of the input CSI estimate data block 614; This processing is trained by one or more DNNs through joint training, rather than requiring laborious and inefficient hardcoding of the algorithmic data quantization process. Additionally, in some embodiments, one or more DNNs may further operate to actually provide a channel-encoded (including modulated) representation of the CSI estimate data block 614 ready for digital-to-analog conversion and RF transmission. That is, rather than using separate individual processing blocks to implement the data encoding process and then performing the initial RF encoding process, the CSF TX processing module 602 simultaneously provides the equivalent of these processes, sensor data 616, Based at least in part on other current data, such as network state information 618 and scheduling latency information 619, the scheduling latency can be trained to produce corresponding signals that are actually source-encoded and channel-encoded and ready for RF transmission. If this is considered, it is adjusted to reflect the predicted future CSI estimate.
UE(110)로부터 전파되는 RF 신호(622)는 BS(108)의 안테나(302) 및 RF 안테나 인터페이스(304)에 의해 수신되고 초기에 처리된다. CSF RX 처리 모듈(604)의 하나 이상의 DNN은 선택적으로 센서 세트(310)로부터의 센서 데이터(626) 및 RF 안테나 인터페이스(304)의 수신측에 대한 현재 파라미터를 나타내는 네트워크 상태 정보(628) 등과 같은 하나 이상의 다른 입력과 함께 RF 안테나 인터페이스(304)의 결과 출력을 입력(624)으로 수신하고, 이들 입력으로부터, UE(110)의 CSI 추정 모듈(226)에 의해 제공되는 CSI 추정 데이터 블록(614)의 복구된 표현 또는 버전인 대응하는 CSI 추정 데이터 블록(630)을 생성하도록 트레이닝된다. CSF RX 처리 모듈(604)에 의해 수행되는 처리는 예를 들어 CSI 추정 데이터 블록(614)의 데이터 인코딩된 버전의 디지털 표현을 생성하기 위해 입력(624)의 채널 디코딩뿐만 아니라 실제로 CSI 추정 데이터 블록(614)의 디코딩된 표현을 생성하기 위해 데이터 자체의 디코딩(예를 들어, 압축 해제)을 포함할 수 있다. 그런 다음 복구된 CSI 추정 데이터 블록(630)은 BS(108)와 UE(110) 사이, 또는 BS(108)와 다수의 UE 사이에서 하나 이상의 MIMO 기반 프로세스를 제어하는데 사용하기 위해 MIMO 관리 모듈(320)에 제공될 수 있다. 전술한 바와 같이, 이러한 동작은 빔형성 동작, 공간 다이버시티 동작 등을 포함할 수 있다. RF signal 622 propagating from UE 110 is received and initially processed by antenna 302 and RF antenna interface 304 of BS 108. One or more DNNs in CSF RX processing module 604 may optionally store sensor data 626 from sensor set 310 and network state information 628 indicating current parameters for the receiving end of RF antenna interface 304, etc. Receives the resulting output of RF antenna interface 304 along with one or more other inputs as input 624, from which CSI estimation data block 614 is provided by CSI estimation module 226 of UE 110. is trained to generate a corresponding CSI estimate data block 630 that is a recovered representation or version of . The processing performed by the CSF RX processing module 604 may include, for example, channel decoding of the input 624 to produce a digital representation of a data-encoded version of the CSI estimate data block 614, as well as the actual CSI estimate data block ( 614) may include decoding (e.g., decompressing) the data itself to produce a decoded representation. The recovered CSI estimation data block 630 is then sent to the MIMO management module 320 for use in controlling one or more MIMO-based processes between the BS 108 and the UE 110, or between the BS 108 and multiple UEs. ) can be provided. As described above, these operations may include beamforming operations, spatial diversity operations, etc.
송신 장치와 수신 장치 사이의 CSF 경로를 구현하기 위해 공동 트레이닝된 DNN 또는 기타 신경망의 구현은 설계 유연성을 제공하고 기존 블록별 설계 및 테스트 접근 방식에 비해 효율적인 업데이트를 촉진하는 동시에 CSF 경로에 있는 장치들이 발신 및 수신 전송 처리를 현재 동작 파라미터에 신속하게 적응시킬 수 있도록 한다. 그러나, DNN들이 배포되고 작동하기 전에. 이들은 일반적으로 주어진 하나 이상의 입력 세트에 적합한 출력을 제공하도록 트레이닝되거나 구성된다. 이를 위해, 도 7은 일부 실시예에 따른 서로 다른 동작 환경에 대한 CSF 경로의 장치들에 대한 옵션으로서 하나 이상의 공동 트레이닝된 DNN 아키텍처 구성을 개발하기 위한 예시적인 방법(700)을 도시한다. 도 7을 참조하여 설명된 동작들의 순서는 단지 예시를 위한 것이며, 동작들의 다른 순서가 수행될 수 있으며, 또한 하나 이상의 동작이 생략될 수 있거나 예시된 방법에 하나 이상의 추가 동작이 포함될 수 있다는 점에 유의한다. 또한, 도 7은 하나 이상의 테스트 노드를 사용하는 오프라인 트레이닝 접근 방식을 도시하지만, 활성 동작 중인 하나 이상의 노드를 사용하는 온라인 트레이닝을 위해 유사한 접근 방식이 구현될 수 있다는 점에 유의한다.Implementation of a co-trained DNN or other neural network to implement the CSF path between transmitting and receiving devices provides design flexibility and promotes efficient updates compared to traditional block-by-block design and testing approaches, while also ensuring that devices in the CSF path are Allows outgoing and incoming transmission processing to be quickly adapted to current operating parameters. However, before DNNs are deployed and operational. They are typically trained or configured to provide an appropriate output given a set of one or more inputs. To this end, FIG. 7 illustrates an example method 700 for developing one or more co-trained DNN architecture configurations as an option for devices in the CSF path for different operating environments according to some embodiments. The order of operations described with reference to FIG. 7 is for illustrative purposes only, and other orders of operations may be performed, and also that one or more operations may be omitted or one or more additional operations may be included in the illustrated method. Be careful. Additionally, note that although Figure 7 illustrates an offline training approach using one or more test nodes, a similar approach could be implemented for online training using one or more nodes in active operation.
위에서 설명한 바와 같이, 해당 CSF 경로를 형성하는 DNN 체인의 하나 또는 두 장치에 사용되는 DNN의 동작은 일반적으로 RF 전파 환경뿐만 아니라 해당 DNN을 사용하는 장치의 동작 파라미터, 하나 이상의 업스트림 또는 다운스트림 장치의 동작 파라미터, 또는 이들의 조합의 동작 파라미터와 같은 CSF 경로의 특정 성능 및 현재 동작 파라미터에 기초할 수 있다. 이러한 성능 및 동작 파라미터에는 예를 들어 장치의 RF 전송 환경을 감지하는데 사용되는 센서 유형, 이러한 센서의 성능, 하나 이상의 장치의 전력 용량, 하나 이상의 장치의 처리 용량, 하나 이상의 장치의 RF 안테나 인터페이스 구성(예를 들어, 빔 수, 안테나 포트, 지원되는 주파수) 등이 포함될 수 있다. 설명되는 DNN은 이러한 정보를 활용하여 자신의 동작을 지시하기 때문에, 많은 경우에 노드들 중 하나에서 구현된 특정 DNN 구성은 해당 장치 또는 CSF 경로의 반대편에 있는 장치에서 현재 사용되는 특정 성능 및 동작 파라미터에 기초한다는 것이 이해될 것이다. 즉, 구현된 특정 DNN 구성은 송신 및 수신 장치에 의해 구현된 CSF 경로에 의해 현재 표시되는 성능 정보 및 동작 파라미터를 반영한다.As described above, the operation of a DNN used in one or two devices of the DNN chain forming a given CSF path will generally depend on the RF propagation environment as well as the operating parameters of the devices using that DNN, that of one or more upstream or downstream devices, and It may be based on the specific performance and current operating parameters of the CSF path, such as operating parameters, or a combination of operating parameters. These performance and operating parameters may include, for example, the types of sensors used to sense the RF transmitting environment of the device, the performance of such sensors, the power capabilities of one or more devices, the processing capacity of one or more devices, and the RF antenna interface configuration of one or more devices ( For example, number of beams, antenna ports, supported frequencies), etc. may be included. Because the DNN being described leverages this information to direct its own behavior, in many cases the specific DNN configuration implemented at one of the nodes will depend on the specific performance and operating parameters currently used by that device or devices on the other side of the CSF path. It will be understood that it is based on . That is, the specific DNN configuration implemented reflects the performance information and operating parameters currently displayed by the CSF path implemented by the transmitting and receiving devices.
따라서, 방법(700)은 테스트 송신 장치 및 테스트 수신 장치를 포함하는 테스트 CSF 경로의 하나 이상의 테스트 노드의 예상 성능(예상 동작 파라미터 또는 파라미터 범위 포함)의 식별로 블록(702)에서 시작한다. 다음의 경우, 관리 컴포넌트(140)의 트레이닝 모듈(408)이 공동 트레이닝을 관리하고 따라서 테스트 장치에 대한 성능 정보가 (예를 들어, 이 정보를 저장하는 데이터베이스 또는 다른 로컬로 저장된 데이터 구조를 통해) 트레이닝 모듈(408)에 알려지는 것으로 가정된다. 그러나, 관리 컴포넌트(140)는 임의의 주어진 UE의 성능에 대한 사전 지식을 갖고 있지 않을 가능성이 높기 때문에, 테스트 송신 및 수신 장치는 테스트 장치에서 사용 가능한 센서 유형의 표시, 이러한 센서에 대한 다양한 파라미터의 표시(예를 들어, 이미징 카메라의 이미징 해상도 및 사진 데이터 포멧), 위성 기반 위치 센서의 위성 위치 확인 유형 및 포멧, 장치에서 사용 가능한 액세서리 및 적용 가능한 파라미터(예를 들어, 오디오 채널 수) 등과 같은 개별 성능의 표시를 관리 컴포넌트(140)에 제공한다. 예를 들어, 테스트 장치는 적어도 4G LTE 및 5G NR 사양에 따라 BS에 의해 전송된 UECapabilityEnquiry RRC 메시지에 응답하여 UE에 의해 일반적으로 제공되는 UECapabilityInformation RRC(Radio Resource Control) 메시지의 일부로서 이러한 성능 표시를 제공할 수 있다. 대안적으로, 테스트 UE는 별도의 부채널(side-channel) 또는 제어 채널 통신으로 센서 성능의 표시를 제공할 수 있다. 또한, 일부 실시예에서, 테스트 장치의 성능은 관리 컴포넌트(140)가 사용할 수 있는 로컬 또는 원격 데이터베이스에 저장될 수 있으며, 따라서 관리 컴포넌트(140)는 테스트 장치와 관련된 IMSI(International Mobile Subscriber Identity) 값과 같은 테스트 장치의 식별자의 일부 형태에 기초하여 이 데이터베이스에 질의할 수 있다.Accordingly, method 700 begins at block 702 with identification of expected performance (including expected operating parameters or parameter ranges) of one or more test nodes in a test CSF path including a test transmitting device and a test receiving device. In the following cases, training module 408 of management component 140 manages joint training and thus performance information about the test device (e.g., via a database or other locally stored data structure that stores this information). It is assumed that training module 408 is known. However, since the management component 140 likely does not have prior knowledge of the performance of any given UE, the test transmitting and receiving device must provide an indication of the types of sensors available on the test device and the various parameters for these sensors. Individual features such as indications (e.g. imaging resolution and picture data format of imaging cameras), type and format of satellite positioning of satellite-based position sensors, accessories available on the device and applicable parameters (e.g. number of audio channels), etc. Provides an indication of performance to management component 140. For example, the test device provides this performance indication as part of a UECapabilityInformation Radio Resource Control (RRC) message that is typically provided by the UE in response to a UECapabilityEnquiry RRC message sent by the BS, at least according to the 4G LTE and 5G NR specifications. can do. Alternatively, the test UE may provide an indication of sensor performance with separate side-channel or control channel communication. Additionally, in some embodiments, the performance of the test device may be stored in a local or remote database that may be used by management component 140, so that management component 140 may store the International Mobile Subscriber Identity (IMSI) value associated with the test device. This database can be queried based on some form of the test device's identifier, such as
일부 실시예에서, 트레이닝 모듈(408)은 모든 CSF 구성 순열을 트레이닝하려고 시도할 수 있다. 그러나, 송신 및 수신 장치가 상대적으로 많고 다양한 성능과 기타 동작 파라미터를 가질 가능성이 있는 구현에서, 이러한 노력은 실행 불가능할 수 있다. 따라서, 블록(704)에서 트레이닝 모듈(408)은 지정된 후보 CSF 구성 세트로부터 테스트 장치의 DNN을 공동으로 트레이닝하기 위한 특정 CSF 구성을 선택할 수 있다. 따라서 각각의 후보 CSF 구성은 CSF 관련 파라미터, 파라미터 범위, 또는 이들의 조합의 특정 조합을 나타낼 수 있다. 이러한 파라미터 또는 파라미터 범위에는 센서 성능 파라미터, 처리 성능 파라미터, 배터리 전력 파라미터, RF 신호 파라미터(예를 들어, 안테나 수 및 유형, 서브채널 수 및 유형 등), 스케줄링 대기 시간 정보 등이 포함될 수 있다. 이러한 CSF 관련 파라미터는 송신 장치에 의해 사용될 특정 유형의 CSI 파일럿 신호, 수신 장치가 CSI 추정치를 계산하는 방식 및 CSI 추정치가 CSF로서 제공되는 포멧을 더 나타낼 수 있다. 트레이닝을 위해 후보 CSF 구성이 선택되면, 추가로 블록(704)에서 트레이닝 모듈(408)은 테스트 송신 장치 및 테스트 수신 장치 각각에 대한 초기 DNN 아키텍처 구성을 식별하고, 테스트 장치가 후보 초기 DNN 아키텍처 구성의 복사본을 저장하는 경우 초기 DNN 아키텍처 구성과 관련된 식별자를 테스트 장치에 제공하거나, 초기 DNN 아키텍처 구성 자체를 나타내는 데이터를 테스트 장치로 전송함으로써 테스트 장치에 이러한 각각의 초기 DNN 아키텍처 구성을 구현하도록 지시한다.In some embodiments, training module 408 may attempt to train all CSF configuration permutations. However, in implementations where the transmitting and receiving devices are relatively numerous and likely to have varying capabilities and other operating parameters, this effort may not be feasible. Accordingly, at block 704, training module 408 may select a particular CSF configuration from the specified set of candidate CSF configurations to jointly train the test device's DNN. Accordingly, each candidate CSF configuration may represent a specific combination of CSF-related parameters, parameter ranges, or combinations thereof. These parameters or ranges of parameters may include sensor performance parameters, processing performance parameters, battery power parameters, RF signal parameters (e.g., number and type of antennas, number and type of subchannels, etc.), scheduling latency information, etc. These CSF-related parameters may further indicate the specific type of CSI pilot signal to be used by the transmitting device, how the receiving device calculates the CSI estimate, and the format in which the CSI estimate is provided as the CSF. Once a candidate CSF configuration is selected for training, further at block 704, the training module 408 identifies an initial DNN architecture configuration for each of the test transmitting device and the test receiving device, and determines whether the test device has any of the candidate initial DNN architecture configurations. If you save a copy, you instruct the test device to implement each of these initial DNN architecture configurations by providing the test device with an identifier associated with the initial DNN architecture configuration, or by transmitting data representing the initial DNN architecture configuration itself to the test device.
CSF 구성이 선택되고 선택된 CSF 구성에 기초하는 DNN 아키텍처 구성으로 테스트 장치가 초기화되면, 블록(706)에서 트레이닝 모듈(408)은 선택된 CSF 구성 및 초기 DNN 아키텍처 구성에 기초하여 DNN 체인의 DNN을 공동으로 훈련하는데 사용할 하나 이상의 트레이닝 데이터 세트를 식별한다. 즉, 하나 이상의 트레이닝 데이터 세트는 온라인 동작에서 해당 DNN에 대한 입력으로 제공될 수 있고 따라서 DNN을 트레이닝하는데 적합한 데이터를 포함하거나 나타낸다. 설명을 위해, 이 트레이닝 데이터에는 테스트 CSI 파일럿 신호의 스트림, 테스트 CSI 파일럿 신호의 테스트 수신 표현, 테스트 중인 구성에 포함된 센서와 일치하는 테스트 센서 데이터, 테스트 중인 구성과 일치하는 테스트 네트워크 상태 정보가 포함될 수 있다.Once the CSF configuration is selected and the test device is initialized with a DNN architecture configuration based on the selected CSF configuration, at block 706 the training module 408 jointly trains the DNNs in the DNN chain based on the selected CSF configuration and the initial DNN architecture configuration. Identify one or more training data sets to use for training. That is, one or more training data sets may be provided as input to the corresponding DNN in online operation and thus contain or represent data suitable for training the DNN. For illustrative purposes, this training data will include a stream of test CSI pilot signals, a test receive representation of the test CSI pilot signal, test sensor data matching the sensors included in the configuration under test, and test network state information matching the configuration under test. You can.
하나 이상의 트레이닝 세트가 획득되면, 블록(708)에서 트레이닝 모듈(408)은 테스트 CSF 경로의 DNN의 공동 트레이닝을 시작한다. 이러한 공동 트레이닝에는 일반적으로 의사 무작위로 선택되는 초기 값으로 다양한 DNN의 편향 가중치 및 계수를 초기화하는 것, 이어서 테스트 수신 장치의 TX 처리 모듈(예를 들어, CSF TX 처리 모듈(602))에 트레이닝 데이터 세트를 입력하는 것, 테스트 수신 장치의 RX 처리 모듈(예를 들어, CSF RX 처리 모듈(604))에 대한 전송으로서 결과 출력을 무선으로 전송하는 것, 결과 출력을 분석하는 것 및 이어서 분석에 기초하여 DNN 아키텍처 구성을 업데이트하는 것이 포함된다. Once one or more training sets are obtained, at block 708 the training module 408 begins joint training of the DNN of the test CSF path. Such joint training typically involves initializing the bias weights and coefficients of the various DNNs with initial values that are pseudo-randomly chosen, followed by feeding the training data to a TX processing module of the test receiver (e.g., CSF TX processing module 602). inputting the set, wirelessly transmitting the result output as a transmission to an RX processing module (e.g., CSF RX processing module 604) of a test receiving device, analyzing the result output, and then based on the analysis. This includes updating the DNN architecture configuration.
DNN 트레이닝에 자주 사용되는 것처럼, CSF RX 처리 모듈(604)의 실제 결과 출력의 결과로서 획득된 피드백은 예를 들어 역전파 등을 통해 CSF 경로의 하나 이상의 DNN의 파라미터를 수정하거나 개선(refine)하는데 사용된다. 따라서, 블록(710)에서 관리 컴포넌트(140) 및/또는 DNN 체인 자체는 전송된 트레이닝 세트에 대한 피드백을 획득한다. 이 피드백은 다양한 형태나 형태의 조합으로 구현될 수 있다. 일부 실시예에서, 피드백에는 트레이닝 모듈(408) 또는 실제 결과 출력과 예상 결과 출력 사이의 오류를 결정하고 DNN 체인의 DNN 전체에 걸쳐 이 오류를 역전파하는 다른 트레이닝 모듈이 포함된다. 예를 들어, DNN 체인에 의한 처리는 양자화 또는 기타 인코딩의 형태를 효과적으로 제공하므로, 트레이닝 데이터 세트에 대한 객관적인 피드백은 DNN 체인에 입력으로서 제공된 원본 CSI 추정 데이터와 비교하여 DNN 체인의 출력으로서 획득된 복구된 CSI 추정 데이터의 정확성을 측정하는 일종의 측정 형태일 수 있다. 획득된 피드백에는 또한 신호가 DNN 체인의 하나 이상의 링크를 통과할 때 신호의 일부 측면에 대한 평가 메트릭이 포함될 수 있다. 예를 들어, 신호의 RF 측면과 관련하여, 피드백에는 블록 오류율(BER), 신호 대 잡음비(SNR), 신호 대 간섭 플러스 잡음 비(SINR) 등과 같은 메트릭이 포함될 수 있다.As is often used in DNN training, the feedback obtained as a result of the actual result output of the CSF RX processing module 604 is used to modify or refine parameters of one or more DNNs in the CSF path, for example, through backpropagation. It is used. Accordingly, at block 710 the management component 140 and/or the DNN chain itself obtains feedback about the transmitted training set. This feedback can be implemented in various forms or combinations of forms. In some embodiments, the feedback includes a training module 408 or another training module that determines the error between the actual and expected result outputs and backpropagates this error throughout the DNNs in the DNN chain. For example, processing by a DNN chain effectively provides some form of quantization or other encoding, so that objective feedback on the training data set can be compared to the original CSI estimate data provided as input to the DNN chain, and the recovery obtained as the output of the DNN chain. It may be a form of measurement that measures the accuracy of the estimated CSI data. The obtained feedback may also include evaluation metrics for some aspect of the signal as it passes through one or more links in the DNN chain. For example, with respect to the RF aspect of the signal, feedback may include metrics such as block error rate (BER), signal-to-noise ratio (SNR), signal-to-interference-plus-noise ratio (SINR), etc.
블록(712)에서, DNN 체인을 통한 테스트 데이터 세트의 전송 및 테스트 송신 장치에서의 결과 출력의 프리젠테이션 또는 기타 소비의 결과로 획득된 피드백은 이어서 예를 들어, 해당 DNN의 가중치, 연결 또는 계층을 변경하기 위한 오류의 역전파를 통해 또는 이러한 피드백에 응답하여 관리 컴포넌트(140)에 의한 관리된 수정을 통해, CSF 경로의 하나 이상의 DNN의 다양한 양태를 업데이트하는데 사용된다. 블록(706-712)의 트레이닝 프로세스는 블록(706)의 다음 반복에서 선택된 트레이닝 데이터의 다음 세트에 대해 수행되고, 특정 횟수의 트레이닝 반복이 수행될 때까지 또는 특정 최소 오류율이 달성될 때까지 반복된다.At block 712, the feedback obtained as a result of the transmission of the test data set through the DNN chain and the presentation or other consumption of the resulting output at the test transmitting device can then be used to modify, for example, the weights, connections, or layers of the corresponding DNN. It is used to update various aspects of one or more DNNs of the CSF path, either through backpropagation of errors to change or through managed modifications by management component 140 in response to such feedback. The training process of blocks 706-712 is performed on the next set of selected training data in the next iteration of block 706 and is repeated until a certain number of training iterations have been performed or a certain minimum error rate is achieved. .
테스트 송신 장치와 테스트 수신 장치 사이의 CSF 경로를 따라 신경망을 공동(또는 개별) 트레이닝한 결과, 각 신경망은 특정 신경망 아키텍처 구성을 갖거나, 구현된 신경망이 DNN인 경우 은닉 계층 수, 각 계층의 노드 수, 각 계층 간의 연결, 각 노드에서 구현되는 가중치, 계수 및 기타 편향 값 등과 같은 해당 DNN의 아키텍처와 파라미터를 특징짓는 DNN 아키텍처 구성을 가질 수 있다. 따라서, 선택된 CSF 구성에 대한 CSF 경로의 DNN의 공동 또는 개별 트레이닝이 완료되면, 블록(714)에서 트레이닝된 DNN 구성의 일부 또는 전부는 시스템(100)의 BS(108)와 UE(110)에 배포되고, 각 노드는 해당 DNN의 결과적인 DNN 구성을 DNN 아키텍처 구성으로서 저장한다. 적어도 하나의 실시예에서, DNN 아키텍처 구성은 은닉 계층 수, 노드 수, 연결, 계수, 가중치 및 기타 편향 값 등과 같은 해당 DNN의 아키텍처 및 파라미터를 추출함으로써 생성될 수 있다. 다른 실시예에서, 관리 컴포넌트(140)는 쌍을 이루는 DNN 아키텍처 구성의 복사본을 세트(142)의 후보 신경망 아키텍처 구성(144)으로서 저장하고, 이러한 DNN 아키텍처 구성은 필요에 따라 BS(108) 및 UE(110)에 배포된다.As a result of jointly (or separately) training neural networks along the CSF path between the test transmitter and the test receiver, each neural network has a specific neural network architecture configuration, or, if the implemented neural network is a DNN, the number of hidden layers, and the nodes in each layer. You can have a DNN architecture configuration that characterizes the architecture and parameters of that DNN, such as the number, connections between each layer, weights, coefficients and other bias values implemented at each node, etc. Accordingly, once joint or individual training of the DNNs of the CSF paths for the selected CSF configurations is complete, some or all of the trained DNN configurations at block 714 are distributed to the BSs 108 and UEs 110 of the system 100. And each node stores the resulting DNN configuration of the corresponding DNN as a DNN architecture configuration. In at least one embodiment, a DNN architecture configuration may be created by extracting the architecture and parameters of the corresponding DNN, such as the number of hidden layers, number of nodes, connections, coefficients, weights, and other bias values. In another embodiment, management component 140 stores copies of paired DNN architecture configurations as candidate neural network architecture configurations 144 in set 142, and these DNN architecture configurations can be sent to BS 108 and UE as needed. It is distributed at (110).
트레이닝될 하나 이상의 다른 후보 CSF 구성이 남아 있는 경우, 방법(700)은 공동으로 트레이닝될 다음 후보 CSF 구성을 선택하기 위해 블록(704)으로 돌아가서, 트레이닝 모듈(408)에 의해 선택된 다음 CSF 구성에 대해 블록(704-714)의 하위 프로세스의 또 다른 반복이 반복된다. 그렇지 않고. CSF 경로의 DNN이 의도된 모든 CSF 구성에 대해 공동으로 트레이닝된 경우 방법(700)은 완료되고 시스템(100)은 도 8-12를 참조하여 아래에 설명되는 바와 같이 신경망 지원 CSI 추정 피드백으로 전환할 수 있다.If one or more other candidate CSF configurations remain to be trained, method 700 returns to block 704 to select the next candidate CSF configuration to be jointly trained, for the next CSF configuration selected by training module 408. Another iteration of the subprocesses of blocks 704-714 is repeated. other. Once the DNNs of the CSF paths have been jointly trained for all intended CSF configurations, method 700 is complete and system 100 can transition to neural network assisted CSI estimation feedback, as described below with reference to FIGS. 8-12. You can.
위에서 언급한 바와 같이, 공동 트레이닝 프로세스는 오프라인 테스트 노드(즉, 제어 정보 또는 사용자 평면 데이터의 활성 통신이 발생하지 않는 동안)를 사용하거나 의도된 전송 경로의 실제 노드가 온라인인 동안(즉, 즉, 제어 정보 또는 사용자 평면 데이터의 활성 통신이 발생하는 동안) 수행될 수 있다. 또한, 일부 실시예에서는, 경우에 따라 모든 DNN을 공동으로 트레이닝하는 대신 다른 DNN을 정적으로 유지하면서 DNN의 서브세트가 트레이닝되거나 재트레이닝될 수 있다. 설명하자면, 관리 컴포넌트(140)는 예를 들어 DNN을 구현하는 장치 근처에 감지되지 않은 간섭자가 존재하거나 이전에 보고되지 않은 처리 용량 손실에 대한 응답으로 인해 특정 장치의 DNN이 비효율적으로 또는 부정확하게 동작하고 있음을 감지할 수 있으며, 따라서 관리 컴포넌트(140)는 다른 장치의 다른 DNN을 현재 구성으로 유지하면서 장치의 DNN(들)의 개별적인 재트레이닝을 스케줄링할 수 있다.As mentioned above, the co-training process uses offline test nodes (i.e., while no active communication of control information or user plane data is occurring) or while the actual nodes in the intended transmission path are online (i.e. (while active communication of control information or user plane data is occurring). Additionally, in some embodiments, a subset of DNNs may be trained or retrained while keeping other DNNs static instead of jointly training all DNNs, as the case may be. To illustrate, management component 140 may cause a DNN on a particular device to operate inefficiently or incorrectly, for example, due to the presence of an undetected interferer in the vicinity of the device implementing the DNN or in response to a previously unreported loss of processing capacity. management component 140 may then schedule individual retraining of the device's DNN(s) while maintaining other DNNs on other devices in their current configuration.
또한, 다수의 CSF 구성을 지원하는 매우 다양한 장치가 있을 수 있지만, 많은 다른 노드가 동일하거나 유사한 CSF 구성을 지원할 수 있다는 것이 인식될 것이다. 따라서, CSF 경로에 통합된 모든 장치에 대해 공동 트레이닝을 반복할 필요 없이, 대표 장치의 공동 훈련에 이어, 해당 장치는 CSF 구성에 대한 트레이닝된 DNN 아키텍처 구성의 표현을 관리 컴포넌트(140)로 전송할 수 있으며, 관리 컴포넌트(140)는 DNN 아키텍처 구성을 저장한 후 이를 CSF 경로의 DNN에서의 구현을 위해 동일하거나 유사한 CSF 구성을 지원하는 다른 장치로 전송할 수 있다.Additionally, while there may be a wide variety of devices supporting multiple CSF configurations, it will be appreciated that many different nodes may support the same or similar CSF configurations. Therefore, following joint training of a representative device, that device can transmit a representation of the trained DNN architecture configuration for the CSF configuration to the management component 140, without the need to repeat joint training for all devices integrated in the CSF path. The management component 140 may store the DNN architecture configuration and then transmit it to another device that supports the same or similar CSF configuration for implementation in the DNN of the CSF path.
더욱이, 해당 장치가 DNN을 사용하여 작동함에 따라 DNN 아키텍처 구성은 시간이 지남에 따라 변경되는 경우가 많다. 따라서, 동작이 진행됨에 따라, 주어진 장치의 신경망 관리 모듈(예를 들어, 신경망 관리 모듈(222, 314))은 예를 들어, 트리거에 응답하여 업데이트된 기울기 및 관련 정보를 관리 컴포넌트(140)에 제공함으로써 해당 노드에 사용된 하나 이상의 DNN의 업데이트된 아키텍처 구성의 표현을 전송하도록 구성될 수 있다. 이 트리거는 주기적 타이머의 만료, 관리 컴포넌트(140)로부터의 질의, 변경의 크기가 지정된 임계값을 초과했다는 결정 등일 수 있다. 그런 다음 관리 컴포넌트(140)는 이러한 수신된 DNN 업데이트를 해당 DNN 아키텍처 구성에 통합하고 따라서 전송 경로의 노드에 적절하게 배포할 수 있는 업데이트된 DNN 아키텍처 구성을 갖게 된다.Moreover, the DNN architecture configuration often changes over time as the device in question operates using a DNN. Accordingly, as the operation progresses, the neural network management module of a given device (e.g., neural network management modules 222, 314) provides updated slope and related information to management component 140, for example in response to a trigger. It may be configured to transmit a representation of an updated architectural configuration of one or more DNNs used for that node by providing. This trigger may be the expiration of a periodic timer, a query from management component 140, a determination that the size of the change has exceeded a specified threshold, etc. Management component 140 then integrates these received DNN updates into its DNN architecture configuration and thus has an updated DNN architecture configuration that can be appropriately distributed to the nodes in the transmission path.
도 8 및 도 9는 일부 실시예에 따른 무선 장치들 사이에서 공동으로 트레이닝된 DNN 기반 CSF 경로를 사용하여 채널 상태 피드백을 위한 예시적인 방법(800)을 함께 도시한다. 논의의 용이함을 위해, 도 8의 방법(800)은 도 1 및 도 6의 CSF 경로(116)의 예시적인 맥락에서 아래에 설명되며, 여기서 BS(108)는 송신 장치로서 동작하고 UE(110)는 수신 장치로서 동작한다. 또한, 방법(800)의 프로세스는 도 9의 예시적인 트랜잭션(사다리) 도면(900)을 참조하여 설명된다.Figures 8 and 9 together illustrate an example method 800 for channel state feedback using jointly trained DNN-based CSF paths between wireless devices in accordance with some embodiments. For ease of discussion, the method 800 of FIG. 8 is described below in the example context of the CSF path 116 of FIGS. 1 and 6, where the BS 108 operates as a transmitting device and the UE 110 operates as a receiving device. Additionally, the process of method 800 is described with reference to the exemplary transaction (ladder) diagram 900 of FIG. 9 .
방법(800)은 블록(802)에서 BS(108) 및 UE(110)가 셀룰러 컨텍스트에서 5G NR 독립형 등록/부착 프로세스를 통해 또는 WLAN 컨텍스트에서 IEEE 802.11 연결 프로세스를 통해 무선 연결을 설정하는 것으로 시작된다. 블록(804)에서, 관리 컴포넌트(140)는 BS(108)의 성능(capability) 관리 모듈(316)(도 3)에 의해 제공되는 성능 정보(902)(도 9) 및 UE(110)의 성능 관리 모듈(224)(도 2)에 의해 제공되는 성능 정보(904)(도 9)와 같은 성능 정보를 BS(108)와 UE(110) 각각으로부터 획득한다. 일부 실시예에서, 관리 컴포넌트(140)는 동일한 인프라 네트워크의 일부일 때 BS(108)의 성능에 대해 이미 통보받을 수 있으며, 이 경우 BS(108)에 대한 성능 정보(902)를 획득하는 것은 로컬 또는 원격 데이터베이스 또는 다른 데이터 저장소에 액세스하는 것을 포함할 수 있다. UE(110)의 경우, BS(108)는 UE(110)에 성능 요청을 전송할 수 있고, UE(110)는 성능 정보(904)로 이 요청에 응답하고, BS(108)는 이를 관리 컴포넌트(140)에 포워딩한다. 예를 들어, BS(108)는 UECapabilityEnquiry RRC 메시지를 전송할 수 있으며, UE(110)는 CSI-관련 성능 정보를 포함하는 UECapabilityInformation RRC 메시지로 응답한다.Method 800 begins at block 802 with BS 108 and UE 110 establishing a wireless connection via a 5G NR standalone registration/attachment process in a cellular context or via an IEEE 802.11 attach process in a WLAN context. . At block 804, the management component 140 manages the performance information 902 (FIG. 9) provided by the capability management module 316 (FIG. 3) of the BS 108 and the capabilities of the UE 110. Performance information, such as performance information 904 (FIG. 9) provided by the management module 224 (FIG. 2), is obtained from each of the BS 108 and the UE 110. In some embodiments, management component 140 may already be informed about the performance of BS 108 when it is part of the same infrastructure network, in which case obtaining performance information 902 for BS 108 may be performed locally or locally. This may include accessing remote databases or other data stores. For UE 110, BS 108 may send a performance request to UE 110, UE 110 responds to this request with performance information 904, and BS 108 sends it to the management component ( 140). For example, BS 108 may send a UECapabilityEnquiry RRC message, and UE 110 responds with a UECapabilityInformation RRC message containing CSI-related capability information.
블록(806)에서, 관리 컴포넌트(140)의 신경망 선택 모듈(410)은 BS(108)와 UE(110) 사이의 CSF 구성을 나타내는 성능 정보 및 기타 정보를 사용하여 CSF 경로(116)를 지원하기 위해 BS(108) 및 UE(110)에서 구현될 CSF DNN 아키텍처 구성 쌍을 선택한다(DNN 선택(906), 도 9). 일부 실시예에서, 신경망 선택 모듈(410)은 DNN 아키텍처 구성의 적합한 쌍을 식별하기 위해 BS(108) 및 UE(110)로부터 획득된 성능 정보와 CSF 경로(116)의 CSF 구성 파라미터를 세트(142) 내의 후보 신경망 아키텍처 구성 쌍(144)의 속성과 비교하는 알고리즘 선택 프로세스를 사용한다. 다른 실시예에서, 신경망 선택 모듈(410)은 하나 이상의 LUT에서 후보 DNN 아키텍처 구성을 구성할 수 있고, 그의 각 항목은 해당 DNN 아키텍처 구성 쌍을 저장하고 입력 파라미터 또는 파라미터 범위의 해당 조합에 의해 인덱싱되며, 신경망 선택 모듈(410)은 하나 이상의 LUT에 대한 입력으로서 블록(804)에서 식별된 성능 및 CSF 구성 파라미터의 제공을 통해 BS(108)와 UE(110)에 의해 채용될 DNN 아키텍처 구성의 적합한 쌍을 선택할 수 있다.At block 806, the neural network selection module 410 of management component 140 uses performance information and other information representative of the CSF configuration between BS 108 and UE 110 to support CSF path 116. To select a pair of CSF DNN architecture configurations to be implemented in BS 108 and UE 110 (DNN selection 906, FIG. 9). In some embodiments, the neural network selection module 410 sets 142 the CSF configuration parameters of the CSF path 116 and the performance information obtained from the BS 108 and the UE 110 to identify a suitable pair of DNN architecture configurations. ) uses an algorithmic selection process that compares the properties of candidate neural network architecture configuration pairs 144 within. In another embodiment, neural network selection module 410 may construct candidate DNN architecture configurations from one or more LUTs, each of which stores a pair of corresponding DNN architecture configurations and is indexed by a corresponding combination of input parameters or parameter ranges; , the neural network selection module 410 selects a suitable pair of DNN architecture configurations to be employed by the BS 108 and the UE 110 through providing the performance and CSF configuration parameters identified in block 804 as input to one or more LUTs. You can select .
또한 블록(806)에서, 관리 컴포넌트(140)는 선택된 공동 트레이닝된 DNN 아키텍처 구성 쌍으로부터 각자의 DNN 아키텍처 구성을 구현하도록 BS(108) 및 UE(110)에 지시한다. BS(108) 및 UE(110) 각각이 잠재적인 향후 사용을 위해 후보 DNN 아키텍처 구성을 저장하는 구현에서, 관리 컴포넌트(140)는 구현될 DNN 아키텍처 구성의 식별자와 함께 메시지를 전송할 수 있다. 그렇지 않으면, 관리 컴포넌트(140)는 예를 들어 계층 1 신호, 계층 2 제어 요소, 계층 3 RRC 메시지, 또는 이들의 조합으로서 DNN 아키텍처 구성을 나타내는 정보를 전송할 수 있다. 예를 들어, 도 9를 참조하면, 관리 컴포넌트(140)는 BS(108)에 대해 선택된 DNN 아키텍처 구성을 나타내는 데이터를 포함하는 DNN 구성 메시지(908)를 BS(108)로 전송한다. 이 메시지를 수신하는 것에 응답하여, BS(108)의 신경망 관리 모듈(314)은 DNN 구성 메시지(908)로부터 데이터를 추출하고 그 추출된 데이터에 표시된 DNN 아키텍처 구성을 갖는 하나 이상의 DNN을 구현하도록 CSF RX 처리 모듈(604)을 구성한다. 마찬가지로, 관리 컴포넌트(140)는 UE(110)에 대해 선택된 DNN 아키텍처 구성을 나타내는 데이터를 포함하는 DNN 구성 메시지(910)를 UE(110)로 전송한다. 이 메시지를 수신하는 것에 응답하여, UE(110)의 신경망 관리 모듈(222)은 DNN 구성 메시지(910)로부터 데이터를 추출하고 그 추출된 데이터에 표시된 DNN 아키텍처 구성을 갖는 하나 이상의 DNN을 구현하도록 CSF TX 처리 모듈(602)을 구성한다.Also at block 806, management component 140 instructs BS 108 and UE 110 to implement their respective DNN architecture configurations from the selected co-trained DNN architecture configuration pairs. In implementations where BS 108 and UE 110 each store candidate DNN architecture configurations for potential future use, management component 140 may send a message with an identifier of the DNN architecture configuration to be implemented. Otherwise, management component 140 may transmit information indicating the DNN architecture configuration, for example, as a layer 1 signal, a layer 2 control element, a layer 3 RRC message, or a combination thereof. For example, referring to FIG. 9 , management component 140 sends a DNN configuration message 908 to BS 108 containing data indicating the DNN architecture configuration selected for BS 108 . In response to receiving this message, the neural network management module 314 of BS 108 extracts data from the DNN configuration message 908 and configures the CSF to implement one or more DNNs having the DNN architecture configuration indicated in the extracted data. Configures the RX processing module 604. Likewise, management component 140 sends to UE 110 a DNN configuration message 910 containing data indicating the DNN architecture configuration selected for UE 110. In response to receiving this message, the neural network management module 222 of the UE 110 extracts data from the DNN configuration message 910 and configures the CSF to implement one or more DNNs having the DNN architecture configuration indicated in the extracted data. Configures the TX processing module 602.
CSF 경로(116)의 DNN이 초기에 구성되면, CSI 추정 및 피드백 프로세스가 시작될 수 있다. 따라서, 블록(808)에서 BS(108)의 CSF 관리 모듈(318)은 (예를 들어, 사용될 특정 빔, 안테나, 부반송파 등을 포함할 수 있는) CSF 경로(116)의 CSF 구성에 기초하여 CSI 파일럿 신호(912)(도 9)를 선택 또는 식별하고, UE(110)에 대한 CSI 파일럿 신호(912)의 무선 송신을 제공한다. 블록(810)에서, UE(110)는 전송된 CSI 파일럿 신호(912)를 나타내는 하나 이상의 RF 신호를 수신하고, 하나 이상의 RF 신호를 하나 이상의 대응하는 기저대역 신호로 변환하고, 이어서 CSI 추정 모듈(226)은 하나 이상의 기저대역 신호를 분석하여 CSI 추정치(914)(도 9)를 결정한다. 전술한 바와 같이, CSI 추정치를 결정하기 위해 CSI 추정 모듈(226)에 의해 다양한 CSI 추정 기술 중 임의의 것이 채용될 수 있다.Once the DNN of the CSF path 116 is initially configured, the CSI estimation and feedback process can begin. Accordingly, at block 808, the CSF management module 318 of the BS 108 configures the CSI Select or identify pilot signal 912 (FIG. 9) and provide wireless transmission of CSI pilot signal 912 to UE 110. At block 810, UE 110 receives one or more RF signals representing transmitted CSI pilot signals 912, converts the one or more RF signals to one or more corresponding baseband signals, and then operates a CSI estimation module ( 226) analyzes one or more baseband signals to determine a CSI estimate 914 (FIG. 9). As discussed above, any of a variety of CSI estimation techniques may be employed by CSI estimation module 226 to determine the CSI estimate.
블록(812)에서, CSF TX 처리 모듈(602)은 선택적으로 UE(110)의 센서로부터의 센서 데이터, BS(108)에서 CSI 추정치를 사용할 때의 스케줄링 대기시간을 나타내는 스케줄링 대기시간 정보, 및/또는 UE(110)의 RF 안테나 인터페이스(204)로부터의 현재 네트워크 상태 정보와 같은 하나 이상의 다른 입력과 함께 CSI 추정치(914)를 입력으로서 수신하고, 이들 입력으로부터 CSI 추정치(914)를 양자화된 형태 또는 인코딩된 형태로 나타내는 CSF 출력(916)(도 9)을 생성한다. 블록(814)에서, 결과적인 CSF 출력(916)은 UE(110)로부터 BS(108)로 무선으로 전송된다.At block 812, the CSF TX processing module 602 optionally processes sensor data from the sensors of the UE 110, scheduling latency information indicating scheduling latency when using the CSI estimate at the BS 108, and/ or receive the CSI estimate 914 as input along with one or more other inputs, such as current network state information from the RF antenna interface 204 of the UE 110, and generate the CSI estimate 914 from these inputs in quantized form or Generates CSF output 916 (FIG. 9), which represents it in encoded form. At block 814, the resulting CSF output 916 is transmitted wirelessly from UE 110 to BS 108.
블록(816)에서, CSF 출력(916)을 나타내는 하나 이상의 RF 신호는 BS(108)의 RF 프론트 엔드(304)에 의해 수신되어 처리되고, 결과 출력은 선택적으로 BS(108)의 센서 세트(310)로부터의 센서 데이터, BS(108)에 의해 획득된 현재 네트워크 상태 정보 등과 같은 하나 이상의 다른 입력과 함께 BS(108)의 CSF RX 처리 모듈(604)에 대한 입력으로서 제공된다. CSF RX 처리 모듈(604)의 하나 이상의 DNN은 이들 입력에 기초하여 CSI 추정치(914)(복구된 CSI 추정치(918), 도 9)의 복구된 표현을 생성한다. 블록(818)에서, 복구된 CSI 추정치(918)는 MIMO 관리 모듈(320)에 제공되며, 이는 CSI 추정치(918)를 사용하여 그에 따라 하나 이상의 MIMO 프로세스(920)를 수정하거나 제어한다. 위에서 언급한 바와 같이, UE(110)의 CSF TX 처리 모듈(602)은 CSI 추정치(914)가 CSI 추정치의 예측된 미래 버전을 반영하기 위해 CSF TX 처리 모듈(602)에 의한 처리 동안 수정되어, 복원된 CSI 추정치(918)가 MIMO 관리 모듈(320)이 MIMO 프로세스를 제어할 때 CSI 추정치를 사용하도록 스케줄링된 기간 동안일 것으로 예측되는 CSI 추정치를 나타내도록, CSI 출력을 생성할 때 BS(108)의 스케줄링 대기시간을 고려할 수 있다At block 816, one or more RF signals representing CSF outputs 916 are received and processed by the RF front end 304 of BS 108, and the resulting outputs are optionally transmitted to sensor set 310 of BS 108. ), sensor data from BS 108, current network state information obtained by BS 108, etc., as input to the CSF RX processing module 604 of BS 108. One or more DNNs in the CSF RX processing module 604 generate a recovered representation of the CSI estimate 914 (recovered CSI estimate 918, FIG. 9) based on these inputs. At block 818, the recovered CSI estimate 918 is provided to the MIMO management module 320, which uses the CSI estimate 918 to modify or control one or more MIMO processes 920 accordingly. As mentioned above, the CSF TX processing module 602 of the UE 110 modifies the CSI estimate 914 during processing by the CSF TX processing module 602 to reflect the predicted future version of the CSI estimate, BS 108 when generating the CSI output such that the restored CSI estimate 918 represents the CSI estimate expected to be during the period for which the MIMO management module 320 is scheduled to use the CSI estimate when controlling the MIMO process. You can consider the scheduling waiting time of
일반적으로, CSI 추정 프로세스는 특정 서브채널 또는 서브채널/반송파 주파수 세트의 반송파 주파수를 특징짓는데 사용하도록 구성된 각 CSI 파일럿 신호(또는 CSI 파일럿 신호의 서브세트)를 갖는 일련의 CSI 파일럿 신호를 전송하는 것을 포함한다. 따라서, 블록(808 내지 818)의 프로세스는 이러한 시퀀스의 각 CSI 파일럿 신호에 대해 반복될 수 있다. 예를 들어, 이 프로세스의 다음 반복에서는, 다른 부반송파의 채널 추정을 위해 CSI 파일럿 신호(922)(도 9)가 선택될 수 있고, BS(108)로부터 UE(110)로 전송될 수 있다. CSI 추정 모듈(225)은 해당 부반송파에 대한 CSI 추정(924)(도 9)을 결정하기 위해 CSI 파일럿 신호(922)의 수신된 버전을 처리하고, CSI 추정치(924)는 CSF 출력(926)(도 9)의 형태로 CSI 추정치(924)의 인코딩된 표현을 생성하기 위해 다른 입력들과 함께 CSF TX 처리 모듈(602)에 대한 입력으로서 제공된다. 그런 다음, CSF 출력(926)은 BS(108)에 무선으로 전송되고, 이에 따라 CSF 출력(926)의 복구된 표현은 CSF RX 처리 모듈(604)에 대한 입력으로서 제공되고, CSF RX 처리 모듈(604)은 이 입력과 선택적으로 하나 이상의 다른 입력을 사용하여 CSI 추정치(924)의 복구된 표현(복구된 CSI 추정치(928), 도 9)을 생성하고, 이는 차례로 BS(108)에서 하나 이상의 MIMO 프로세스(930)(도 9)를 수정하거나 제어하는데 사용될 수 있다.Generally, the CSI estimation process involves transmitting a series of CSI pilot signals, with each CSI pilot signal (or subset of CSI pilot signals) configured for use in characterizing the carrier frequency of a particular subchannel or set of subchannels/carrier frequencies. Includes. Accordingly, the process of blocks 808-818 may be repeated for each CSI pilot signal in this sequence. For example, in the next iteration of this process, CSI pilot signal 922 (FIG. 9) may be selected and transmitted from BS 108 to UE 110 for channel estimation of other subcarriers. The CSI estimation module 225 processes the received version of the CSI pilot signal 922 to determine a CSI estimate 924 (FIG. 9) for that subcarrier, and the CSI estimate 924 is output to the CSF output 926 ( It is provided as an input to the CSF TX processing module 602 along with other inputs to generate an encoded representation of the CSI estimate 924 in the form of Figure 9). CSF output 926 is then wirelessly transmitted to BS 108, whereby the recovered representation of CSF output 926 is provided as input to CSF RX processing module 604, which 604) uses this input and optionally one or more other inputs to generate a recovered representation of the CSI estimate 924 (recovered CSI estimate 928, FIG. 9), which in turn generates one or more MIMO It may be used to modify or control process 930 (FIG. 9).
또한, 도 8의 방법(800) 및 도 9의 사다리 도면(900)의 대응하는 예시적인 동작은 UE(110)에서 생성된 각각의 CSI 추정치가 대응하는 별도의 CSF 출력을 생성하는데 사용되는 구현을 도시하지만, 다른 실시예에서는 UE(110)에서 생성된 각각의 CSI 추정치에 대해 새로운 CSF 출력을 생성하는 대신, UE(110)는 주어진 CSF 반복에 대해 BS(108)에 의해 전송된 일련의 CSI 파일럿 신호의 전체 중 일부 또는 전부에 대한 CSI 추정치를 생성하고 임시 저장한 다음, CSI 추정치 세트를 나타내는 단일 CSF 출력의 생성을 위해 CSF TX 처리 모듈(602)에 대한 입력으로서. CSI 추정 행렬 또는 다른 데이터 구조 형태의 단일 데이터 블록(예를 들어, CSI 추정 데이터 블록(134), 도 1)으로 CSI 추정의 결과 세트를 제공하도록 구성될 수 있다. Additionally, the method 800 of FIG. 8 and the corresponding example operation of the ladder diagram 900 of FIG. 9 provide an implementation in which each CSI estimate generated at UE 110 is used to generate a corresponding separate CSF output. Although shown, in another embodiment, instead of generating a new CSF output for each CSI estimate generated at UE 110, UE 110 generates a series of CSI pilots transmitted by BS 108 for a given CSF repetition. Generate and temporarily store CSI estimates for some or all of the signals and then as input to the CSF TX processing module 602 for generation of a single CSF output representing the set of CSI estimates. It may be configured to provide a result set of CSI estimation as a single data block in the form of a CSI estimation matrix or other data structure (e.g., CSI estimation data block 134, FIG. 1).
지금까지, 시스템(100)은 결과적인 CSI 추정치를 송신 장치에 다시 제공하기 위해 신경망 기반 채널 상태 피드백 경로와 함께 기존의 CSI 파일럿 전송 및 CSI 추정 프로세스가 사용되는 실시예의 맥락에서 설명되었다. 그러나, 시스템(100)은 이 접근 방식에 제한되지 않고 대신 CSI 파일럿 전송, CSI 추정 및 CSI 피드백 프로세스 각각에 대해 공동으로 트레이닝된 DNN 또는 다른 신경망을 사용할 수 있다. 이를 위해, 도 10은 CSI 파일럿 전송, CSI 추정 및 CSI 피드백 프로세스가 송신 장치와 수신 장치에서 공동으로 트레이닝된 DNN 세트 또는 다른 신경망을 사용하여 구현되는 예시적인 동작 환경(1000)을 도시한다. 설명의 편의를 위해, 동작 환경은 송신 장치인 BS(108)와 수신 장치인 UE(110)의 예시적인 맥락에서 설명된다. 개시된 원리는 송신 장치로서 UE(110) 및 수신 장치로서 BS(108)를 갖는 예뿐만 아니라 사이드링크 예에도 동일하게 적용된다.So far, system 100 has been described in the context of an embodiment in which a conventional CSI pilot transmission and CSI estimation process is used along with a neural network-based channel state feedback path to provide the resulting CSI estimate back to the transmitting device. However, system 100 is not limited to this approach and may instead use jointly trained DNNs or other neural networks for each of the CSI pilot transmission, CSI estimation, and CSI feedback processes. To this end, FIG. 10 shows an example operating environment 1000 in which the CSI pilot transmission, CSI estimation, and CSI feedback processes are implemented using a set of DNNs or other neural networks jointly trained in the transmitting and receiving devices. For convenience of explanation, the operating environment is described in the example context of the BS 108, which is a transmitting device, and the UE 110, which is a receiving device. The principles disclosed apply equally to the sidelink example as well as to the example with UE 110 as the transmitting device and BS 108 as the receiving device.
도시된 예시적인 동작 환경(1000)에서, BS(108)의 신경망 관리 모듈(314)은 CSF TX 처리 모듈(1002) 및 CSF RX 처리 모듈(1008)을 사용하는 반면, UE(110)의 신경망 관리 모듈(222)은 CSF RX 처리 모듈(1004) 및 CSF TX 처리 모듈(1006)을 구현한다. 적어도 하나의 실시예에서, 이러한 처리 모듈 각각은 도 5의 ML 모듈(500)의 하나 이상의 DNN(502)을 참조하여 위에서 설명한 것과 같이 대응하는 ML 모듈의 구현을 통해 하나 이상의 DNN을 구현한다.In the example operating environment 1000 shown, the neural network management module 314 of the BS 108 uses the CSF TX processing module 1002 and the CSF RX processing module 1008, while the neural network management module 314 of the UE 110 Module 222 implements CSF RX processing module 1004 and CSF TX processing module 1006. In at least one embodiment, each of these processing modules implements one or more DNNs through implementation of corresponding ML modules, as described above with reference to one or more DNNs 502 of ML modules 500 of Figure 5.
처리 모듈(1002, 1004, 1006, 1008)은 BS(108) 및 UE(110)의 현재 동작 파라미터에 적응될 수 있을 뿐만 아니라 이러한 동작 파라미터의 변경에도 적응될 수 있는 트레이닝된 신경망 기반 접근 방식을 선호하여 복잡하고, 하드코딩된 CSF 프로세스의 사용을 줄이거나 제거하는 방식으로 CSF를 제공하도록 함께 동작한다. 이를 위해, 후보 신경망 아키텍처 구성은 도 7의 방법(700)을 참조하여 위에서 설명된 바와 같이 공동으로 트레이닝될 수 있으며, 관리 컴포넌트(140) 또는 시스템(100)의 다른 컴포넌트는 위에서 설명한 것과 유사하게 선택 프로세스를 사용하여 공동 트레이닝된 후보로부터 이러한 처리 모듈에 사용될 신경망 아키텍처 구성의 특정 세트를 선택할 수 있다.Processing modules 1002, 1004, 1006, 1008 prefer a trained neural network based approach that can be adapted to the current operating parameters of the BS 108 and UE 110 as well as changes in these operating parameters. They work together to provide CSF in a way that reduces or eliminates the use of complex, hard-coded CSF processes. To this end, candidate neural network architecture configurations may be jointly trained as described above with reference to method 700 of Figure 7, and management component 140 or other components of system 100 may be selected similarly as described above. The process can be used to select from co-trained candidates a specific set of neural network architecture configurations to be used for these processing modules.
도 11은 일부 실시예에 따른 도 10의 동작 환경(1000)의 동작 방법(1100)의 예를 도시한다. 이해를 돕기 위해, 방법(1100)은 도 12의 예시적인 드랜잭션(사다리) 도면(1200)을 참조하여 설명된다. 방법(1100)은 블록(802, 804)(도 8)을 참조하여 전술한 바와 같이, BS(108) 및 UE(110)가 초기 연결을 설정하고 관리 컴포넌트(140)가 BS(108) 및 UE(110)로부터 CSF 관련 성능 정보를 획득하는 블록(1102)에서 시작한다. 또한 블록(806)을 참조하여 위에서 유사하게 설명된 바와 같이, 관리 컴포넌트(140)는 획득된 성능 정보 및 제공된 임의의 CSF 구성 정보에 기초하여 처리 모듈(1002, 1004, 1006 및 1008)에 의해 사용될 DNN 아키텍처 구성 세트를 선택하고, 그 선택된 DNN 아키텍처 구성을 구현하도록 BS(108) 및 UE(110)에게 지시한다. 이 프로세스는 트랜잭션 도면(1200)에서 DNN 구성 프로세스(1202)로 표시된다.FIG. 11 illustrates an example of a method 1100 of operating the operating environment 1000 of FIG. 10 according to some embodiments. To facilitate understanding, method 1100 is described with reference to example transaction (ladder) diagram 1200 of FIG. 12 . Method 1100, as described above with reference to blocks 802 and 804 (FIG. 8), allows BS 108 and UE 110 to establish an initial connection and management component 140 to connect BS 108 and UE. It begins at block 1102 where CSF-related performance information is obtained from 110. Also, as similarly described above with reference to block 806, management component 140 determines the information to be used by processing modules 1002, 1004, 1006, and 1008 based on the performance information obtained and any CSF configuration information provided. Select a set of DNN architecture configurations and instruct BS 108 and UE 110 to implement the selected DNN architecture configurations. This process is denoted as DNN configuration process 1202 in transaction diagram 1200.
블록(1104)에서, CSF 관리 모듈(318)은 UE(110)와의 다운링크 통신에서 BS(108)에 의해 사용하기 위한 CSI를 제공하기 위해 BS(108)와 UE(110)가 공동으로 협력해야 하는 현재 CSF 구성을 나타내는 정보로 구성된 CSF 구성 입력(1010)(도 10, 12)을 생성한다. 이 정보에는 예를 들어 사용될 빔의 특정 서브세트, 사용될 반송파 주파수의 특정 서브세트, 사용될 안테나 포트의 특정 수, 지정된 전력 효율 목표, RF 시그널링이 LoS(Line of Sight)인지, 다중 경로인지, 또는 이들의 조합일 것으로 예상되는지 여부에 대한 표시가 포함될 수 있다.At block 1104, the CSF management module 318 requires the BS 108 and the UE 110 to jointly provide CSI for use by the BS 108 in downlink communications with the UE 110. generates a CSF configuration input 1010 (FIGS. 10, 12) consisting of information representing the current CSF configuration. This information may include, for example, the specific subset of beams to be used, the specific subset of carrier frequencies to be used, the specific number of antenna ports to be used, the specified power efficiency target, whether the RF signaling will be Line of Sight (LoS), multipath, or any of these. An indication of whether it is expected to be a combination of
블록(1106)에서, CSF 구성 입력(1010)은 선택적으로 센서 세트(310)로부터의 현재 센서 데이터 또는 BS(108)에 의해 관찰되는 현재 네트워크 상태 정보와 같은 하나 이상의 다른 입력과 함께 BS(108)의 CSF TX 처리 모듈(1002)에 대한 입력으로서 제공된다(이러한 입력은 설명의 편의를 위해 도 10에서 생략됨). CSF 구성 입력(1010)과 기타 입력(들)에 기초하여, CSF TX 처리 모듈(1002)은 CSF 구성 입력(1010)에 표현된 바와 같이 현재 CSF 구성을 반영하는 하나 이상의 CSI 파일럿 신호를 사실상 나타내는 CSI 파일럿 출력(1012)(도 10, 도 12)을 생성하도록 동작한다. 블록(1108)에서, CSI 파일럿 출력(1012)은 UE(110)에 무선으로 전송된다. 또한, CSI 파일럿 출력(1012)은 BS(108)의 CSF RX 처리 모듈(1008)에 대한 입력으로서 제공되며, CSF RX 처리 모듈(1008)은 아래에 설명된 바와 같이 UE(110)에서 DNN 생성(DNN-generated) 출력으로부터 CSI 추정 정보를 복구하기 위해 센서 데이터 또는 현재 네트워크 상태 정보와 같은 다른 입력과 함께 선택적으로 이 입력을 사용할 것이다.At block 1106, the CSF configuration input 1010 is connected to BS 108, optionally along with one or more other inputs, such as current sensor data from sensor set 310 or current network state information observed by BS 108. is provided as an input to the CSF TX processing module 1002 (this input is omitted from Figure 10 for convenience of description). Based on the CSF configuration input 1010 and other input(s), the CSF TX processing module 1002 generates a CSI signal that effectively represents one or more CSI pilot signals that reflect the current CSF configuration as expressed in the CSF configuration input 1010. Operates to produce pilot output 1012 (FIGS. 10 and 12). At block 1108, CSI pilot output 1012 is transmitted wirelessly to UE 110. Additionally, the CSI pilot output 1012 is provided as an input to the CSF RX processing module 1008 of the BS 108, which generates the DNN at the UE 110 (as described below). We will optionally use this input along with other inputs, such as sensor data or current network state information, to recover CSI estimation information from the DNN-generated (DNN-generated) output.
블록(1110)에서, UE(110)는 CSI 파일럿 출력(1012)을 나타내는 수신된 무선 신호를 처리하고, 선택적으로 UE(110)의 센서 세트(210)로부터의 센서 데이터 또는 UE(110)에 의해 관찰된 현재 네트워크 상태 정보(설명의 편의를 위해 도 10에서 생략)와 같은 하나 이상의 다른 입력과 함께 UE(110)의 CSF RX 처리 모듈(1006)에 대한 입력으로서 그 결과를 제공한다. 그런 다음 CSF RX 처리 모듈(1006)은 이들 입력을 사용하여 대응하는 CSI 출력(1014)(도 10, 도 12)을 생성하는데, 이는 사실상 CSF 구성 정보(1010)에 표시되고 수신된 CSI 파일럿 출력(1012)에 의해 표시되는 CSI 파일럿 정보로부터 생성된 서브채널/빔/안테나 포트 조합의 일부 또는 전부에 대한 하나 이상의 CSI 추정치를 나타낸다. 즉, CSF TX 처리 모듈(1002)과 CSF RX 처리 모듈(1006)은 사실상 기존의 알고리즘 CSI 파일럿 전송 및 CSI 추정 계산 프로세스와 동등한 것을 제공하도록 공동으로 트레이닝될 수 있지만, 여기서 처리 모듈(1002 및 1006)은 또한 현재 전송 환경에 더 잘 적응하기 위해 현재 센서 입력 및 현재 네트워크 상태의 형태로 현재 동작 파라미터를 통합할 수 있을 뿐만 아니라 BS(108)가 생성되는 CSI 추정 정보를 사용하는 기간 동안 CSI 추정 정보를 더 잘 예측하기 위해 대기 시간 정보를 스케줄링할 수 있다.At block 1110, the UE 110 processes the received wireless signal representing the CSI pilot output 1012, optionally using sensor data from the sensor set 210 of the UE 110 or by the UE 110. The results are provided as input to the CSF RX processing module 1006 of UE 110 along with one or more other inputs, such as observed current network state information (omitted from Figure 10 for ease of explanation). CSF RX processing module 1006 then uses these inputs to generate corresponding CSI outputs 1014 (FIGS. 10, 12), which in effect are displayed in CSF configuration information 1010 and receive CSI pilot outputs ( Indicates one or more CSI estimates for some or all of the subchannel/beam/antenna port combinations generated from CSI pilot information indicated by 1012). That is, the CSF TX processing module 1002 and the CSF RX processing module 1006 may be jointly trained to provide substantially the equivalent of a conventional algorithmic CSI pilot transmission and CSI estimate calculation process, but where processing modules 1002 and 1006 It can also integrate current operating parameters in the form of current sensor inputs and current network conditions to better adapt to the current transmission environment, as well as provide CSI estimate information for the period in which the BS 108 uses the generated CSI estimate information. You can schedule latency information to better predict.
블록(1112)에서, CSF TX 모듈(1006)은 선택적으로 센서 데이터, 네트워크 상태 데이터, 또는 하나 이상의 다른 입력으로서 다른 데이터와 함께 입력으로서 CSI 출력(1014)을 수신하고, 이들 입력으로부터 CSI 출력(1014)에 표시된 CSI 추정 정보의 압축 또는 인코딩된 표현을 사실상 표시하고, 센서 데이터, 네트워크 상태 정보, 스케줄링 대기 시간 및 기타 입력에 표시된 대로 현재 동작 컨텍스트에 적용되는 CSF 출력(1016)(도 10, 12)을 생성한다. 블록(1114)에서 UE(110)는 CSF 출력(1016)을 BS(108)에 무선으로 전송한다.At block 1112, the CSF TX module 1006 receives a CSI output 1014 as an input, optionally along with other data as sensor data, network state data, or one or more other inputs, and generates a CSI output 1014 from these inputs. CSF output 1016, which in effect represents a compressed or encoded representation of the CSI estimation information shown in ) and applied to the current operating context as shown in sensor data, network state information, scheduling latency, and other inputs (FIGS. 10, 12). creates . At block 1114, UE 110 wirelessly transmits CSF output 1016 to BS 108.
블록(1116)에서, BS(108)는 CSF 출력(1016)을 나타내는 무선 신호를 처리하고 CSF 출력(1016)의 복구된 CSI 표현을 나타내는 결과 출력을 CSF RX 처리 모듈(1008)에 제공한다. CSF RX 처리 모듈(1008)은 입력으로서 CSI 파일럿 출력(1012)과 함께 이 입력을 사용하고 선택적으로 BS(108)에서 관찰된 센서 데이터 및 현재 네트워크 상태 정보와 같은 하나 이상의 다른 입력과 함께 사용하여, BS(108)의 CSF TX 처리 모듈(1002)에 의해 생성된 CSI 파일럿 출력(1012)의 수신된 표현에 기초하여 UE(110)의 CSF RX 처리 모듈(1004)에 의해 생성된 CSI 출력(1014)에 표현된 CSI 추정 정보의 복구된 표현을 나타내는 CSI 추정 출력(1018)을 생성한다. 즉, 일 실시예에서 처리 모듈(1006 및 1008)의 DNN은 실제로 CSI 추정치가 전송을 위해 인코딩되지만 처리 모듈(1006 및 1008)이 현재 전송 환경에 더 잘 적응하기 위해 현재 센서 입력 및 현재 네트워크 상태의 형태로 현재 동작 파라미터를 추가로 통합할 수 있는 기존의 하드코딩된 CSI 피드백 프로세스와 동등한 기능을 제공하도록 공동으로 트레이닝된다. 블록(1118)에서, CSI 추정 출력(1018)에 표현된 CSI 추정 정보는 BS(108)에서 사용되는 하나 이상의 MIMO 프로세스를 제어하는데 사용하기 위해 MIMO 관리 모듈(320)에 제공된다.At block 1116, BS 108 processes the wireless signal representing CSF output 1016 and provides a resulting output representing a recovered CSI representation of CSF output 1016 to CSF RX processing module 1008. The CSF RX processing module 1008 uses this input with the CSI pilot output 1012 as an input, and optionally with one or more other inputs, such as observed sensor data and current network state information from the BS 108, to: CSI output 1014 generated by CSF RX processing module 1004 of UE 110 based on a received representation of CSI pilot output 1012 generated by CSF TX processing module 1002 of BS 108 Generates a CSI estimation output 1018 representing a recovered representation of the CSI estimation information expressed in . That is, in one embodiment, the DNNs in processing modules 1006 and 1008 actually encode the CSI estimates for transmission, but allow processing modules 1006 and 1008 to better adapt to the current transmission environment by providing information on current sensor inputs and current network conditions. They are jointly trained to provide equivalent functionality to existing hard-coded CSI feedback processes that can further incorporate current operating parameters in the form of At block 1118, the CSI estimate information represented in CSI estimate output 1018 is provided to MIMO management module 320 for use in controlling one or more MIMO processes used in BS 108.
일반적으로, 동작 환경의 변화는 블록(1104 내지 1118)의 프로세스의 가장 최근 반복 동안 제공되는 CSI 추정치의 재교정 또는 재계산을 필요로 할 수 있다. 예를 들어, UE(110)의 위치는 재계산을 필요로 할 정도로 충분히 변경되었을 수 있고, BS(108) 또는 UE(110) 중 하나 또는 둘 모두의 안테나 패턴은 실질적으로 변경되었을 수 있다. 따라서, 블록(1104 내지 1118)의 프로세스는 특정 MIMO 동작을 제어하기 위해 BS(108)에 의해 사용되는 CSI 추정치를 업데이트하기 위해 반복될 수 있다. 블록(1104 내지 1118)의 프로세스의 또 다른 반복의 트리거링은 타이머 또는 기타 주기적 기준에 기초할 수 있다. 예를 들어, BS(108) 또는 관리 컴포넌트(140)는 타이머의 경과에 기초하여 또 다른 반복을 트리거할 수 있다. 다른 실시예에서, 반복 트리거의 타이밍은 DNN 자체에 트레이닝될 수 있으므로, BS(108)의 CSF TX 처리 모듈(1002)은 특정 센서 데이터 입력 또는 네트워크 상태 입력 등에 기초하여, 타이머에 근거하여 또 다른 반복을 트리거하도록 트레이닝될 수 있다.In general, changes in operating environment may require recalibration or recalculation of the CSI estimate provided during the most recent iteration of the process of blocks 1104-1118. For example, the location of UE 110 may have changed sufficiently to require recalculation, and the antenna pattern of one or both BS 108 or UE 110 may have changed substantially. Accordingly, the process of blocks 1104-1118 may be repeated to update the CSI estimate used by BS 108 to control specific MIMO operations. Triggering of another repetition of the process of blocks 1104-1118 may be based on a timer or other periodic basis. For example, BS 108 or management component 140 may trigger another repetition based on the passage of a timer. In another embodiment, the timing of the repetition trigger may be trained in the DNN itself, such that the CSF TX processing module 1002 of the BS 108 may trigger another repetition based on a timer, based on a specific sensor data input or network state input, etc. Can be trained to trigger.
일부 실시예에서, 위에 설명된 기술의 특정 양태는 소프트웨어를 실행하는 처리 시스템의 하나 이상의 프로세서에 의해 구현될 수 있다. 소프트웨어는 비-일시적 컴퓨터 판독 가능 저장 매체에 저장되거나 유형적으로 구현되는 하나 이상의 실행 가능한 명령 세트를 포함한다. 소프트웨어는 하나 이상의 프로세서에 의해 실행될 때 전술한 기술의 하나 이상의 양태를 수행하기 위해 하나 이상의 프로세서를 조작하는 명령 및 특정 데이터를 포함할 수 있다. 비-일시적 컴퓨터 판독 가능 저장 매체는 예를 들어 자기 또는 광 디스크 저장 장치, 플래시 메모리, 캐시, RAM과 같은 고체 상태 저장 장치, 또는 기타 비-휘발성 메모리 장치 또는 장치들을 포함할 수 있다. 비-일시적 컴퓨터 판독 가능 저장 매체에 저장된 실행 가능 명령들은 소스 코드, 어셈블리 언어 코드, 목적 코드, 또는 하나 이상의 프로세서에 의해 해석되거나 실행 가능한 다른 명령 형식일 수 있다.In some embodiments, certain aspects of the technology described above may be implemented by one or more processors of a processing system executing software. Software includes one or more sets of executable instructions stored on or tangibly embodied in a non-transitory computer-readable storage medium. Software may include certain data and instructions that, when executed by one or more processors, manipulate one or more processors to perform one or more aspects of the techniques described above. Non-transitory computer readable storage media may include, for example, magnetic or optical disk storage, solid state storage such as flash memory, cache, RAM, or other non-volatile memory device or devices. Executable instructions stored on a non-transitory computer-readable storage medium may be in the form of source code, assembly language code, object code, or other instructions that can be interpreted or executed by one or more processors.
컴퓨터 판독 가능 저장 매체는 명령 및/또는 데이터를 컴퓨터 시스템에 제공하기 위해 사용하는 동안 컴퓨터 시스템에 의해 액세스 가능한 임의의 저장 매체 또는 저장 매체의 조합을 포함할 수 있다. 이러한 저장 매체는 광학 매체(예를 들어, CD, DVD, Blu-Ray 디스크), 자기 매체(예를 들어, 플로피 디스크, 자기 테이프 또는 자기 하드 드라이브), 휘발성 메모리(예를 들어, RAM 또는 캐시), 비-휘발성 메모리(예를 들어, ROM 또는 플래시 메모리) 또는 MEMS(Microelectromechanical Systems) 기반 저장 매체를 포함할 수 있지만 이에 한정되지 않는다. 컴퓨터 판독 가능 저장 매체는 컴퓨팅 시스템(예를 들어, 시스템 RAM 또는 ROM)에 내장되거나, 컴퓨팅 시스템(예를 들어, 자기 하드 드라이브)에 고정적으로 부착되거나, 컴퓨팅 시스템(예를 들어, 광 디스크 또는 USB(Universal Serial Bus) 기반 플래시 메모리)에 제거 가능하게 부착되거나, 유선 또는 무선 네트워크(예를 들어, NAS(Network Accessible Storage))를 통해 컴퓨터 시스템에 연결될 수 있다.A computer-readable storage medium may include any storage medium, or combination of storage media, that is accessible by a computer system during use to provide instructions and/or data to the computer system. Such storage media may include optical media (e.g., CDs, DVDs, Blu-Ray Discs), magnetic media (e.g., floppy disks, magnetic tape, or magnetic hard drives), and volatile memory (e.g., RAM or cache). , non-volatile memory (e.g., ROM or flash memory), or Microelectromechanical Systems (MEMS) based storage media. A computer-readable storage medium is embedded in the computing system (e.g., system RAM or ROM), fixedly attached to the computing system (e.g., a magnetic hard drive), or stored in the computing system (e.g., an optical disk or USB drive). (Universal Serial Bus) based flash memory) or connected to a computer system via a wired or wireless network (e.g., Network Accessible Storage (NAS)).
일반적인 설명으로 위에서 설명한 모든 활동 또는 요소가 필요한 것은 아니며, 특정 활동 또는 장치의 일부가 필요하지 않을 수도 있고, 설명된 것 외에 하나 이상의 추가 활동이 수행되거나 요소가 포함될 수 있다. 또한, 동작들이 나열되는 순서가 반드시 수행 순서는 아니다. 또한, 개념들이 구체적인 실시예를 참조하여 설명되었다. 그러나, 당업자라면 아래의 청구범위에 기재된 바와같이 본 발명의 범위를 벗어나지 않고 다양한 수정 및 변경이 이루어질 수 있음을 이해할 것이다. 따라서, 명세서 및 도면은 제한적인 의미가 아니라 예시적인 것으로 간주되어야 하며, 이러한 모든 변형은 본 개시의 범위 내에 포함되도록 의도된다.As a general note, not all activities or elements described above may be required, some specific activities or devices may not be required, and one or more additional activities or elements may be included in addition to those described. Additionally, the order in which operations are listed is not necessarily the order in which they are performed. Additionally, concepts have been explained with reference to specific embodiments. However, those skilled in the art will appreciate that various modifications and changes may be made without departing from the scope of the invention as set forth in the claims below. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense, and all such modifications are intended to be included within the scope of this disclosure.
이점, 다른 장점 및 문제에 대한 해결책은 특정 실시예와 관련하여 위에서 설명되었다. 그러나, 이점, 장점, 문제에 대한 해결책 및 그 이점, 장점 또는 솔루션이 발생하거나 더욱 두드러질 수 있는 기능은 청구범위의 일부 또는 전부의 중요하거나 필수이거나 필수적인 특징으로 해석되어서는 안 된다. 더욱이, 위에 개시된 특정 실시예는 단지 예시일 뿐이며, 개시된 주제는 본 명세서의 교시의 이점을 갖는 당업자에게 명백하지만 상이하지만 동등한 방식으로 수정되고 실시될 수 있다. 아래 청구범위에 설명된 것 외에 본 명세서에 표시된 구성 또는 설계의 세부 사항에는 제한이 없다. 따라서 위에 개시된 특정 실시예는 변경되거나 수정될 수 있으며 이러한 모든 변형은 개시된 주제의 범위 내에서 고려된다는 것이 명백하다. 따라서, 본 명세서에서 추구하는 보호는 아래 청구범위에 기술된 바와 같다.Advantages, other advantages and solutions to problems have been described above with respect to specific embodiments. However, any advantage, advantage, solution to a problem and any feature by which the advantage, advantage or solution may arise or be more pronounced shall not be construed as an important, essential or essential feature of any or all of the claims. Moreover, the specific embodiments disclosed above are by way of example only, and the disclosed subject matter may be modified and practiced in different but equivalent ways, as will be apparent to those skilled in the art having the benefit of the teachings herein. There are no limitations on the details of construction or design shown herein other than as set forth in the claims below. Accordingly, it is clear that certain embodiments disclosed above may be changed or modified and that all such modifications are considered within the scope of the disclosed subject matter. Accordingly, the protection sought herein is as set forth in the claims below.
Claims (19)
제1 장치의 적어도 하나의 성능(capability)을 나타내는 성능 정보를 인프라 컴포넌트에 제공하는 것에 응답하여 신경망 아키텍처 구성의 표시를 수신하는 단계와;
제1 장치의 송신 신경망에서 신경망 아키텍처 구성을 구현하는 단계와;
송신 신경망에 대한 입력으로서 채널 상태 정보(CSI) 추정치의 표현을 수신하는 단계와;
송신 신경망에서, CSI 추정치의 표현에 기초하여 제1 출력을 생성하는 단계와, 상기 제1 출력은 미래 시점에 대한 CSI 추정치의 예측 표현의 압축 버전을 나타내고; 그리고
제2 장치에 의한 수신을 위해 제1 출력을 나타내는 제1 RF 신호를 전송하도록 제1 장치의 무선 주파수(RF) 안테나 인터페이스를 제어하는 단계를 포함하는, 제1 장치의 컴퓨터 구현 방법.1. A computer-implemented method of a first device, comprising:
receiving an indication of a neural network architecture configuration in response to providing performance information representative of at least one capability of the first device to an infrastructure component;
implementing a neural network architecture configuration in a transmit neural network of the first device;
Receiving a representation of channel state information (CSI) estimates as input to a transmit neural network;
In a transmit neural network, generating a first output based on the representation of the CSI estimate, the first output representing a compressed version of the predictive representation of the CSI estimate for a future point in time; and
A computer-implemented method of a first device, comprising controlling a radio frequency (RF) antenna interface of the first device to transmit a first RF signal representative of a first output for reception by a second device.
제2 장치로부터 수신된 하나 이상의 RF 신호에 기초하여 CSI 추정치를 알고리즘적으로 결정하는 단계를 더 포함하는, 제1 장치의 컴퓨터 구현 방법.According to paragraph 1,
The computer-implemented method of a first device further comprising algorithmically determining a CSI estimate based on one or more RF signals received from the second device.
제1 출력을 생성하는 단계는,
송신 신경망에 대한 입력으로 제공된 제2 장치의 다중 입력 다중 출력(MIMO) 프로세스의 스케줄링 대기시간(latency)의 표현에 더 기초하여 송신 신경망에서 제1 출력을 생성하는 단계를 더 포함하는, 제1 장치의 컴퓨터 구현 방법.According to paragraph 1,
The step of generating the first output is:
The first device further comprising generating a first output from the transmit neural network based further on a representation of a scheduling latency of a multiple-input multiple-output (MIMO) process of the second device provided as input to the transmit neural network. A computer implementation method of.
신경망 아키텍처 구성은,
스케줄링 대기시간에 기초하여 복수의 후보 신경망 아키텍처 구성으로부터 송신 신경망에 대해 선택되는, 제1 장치의 컴퓨터 구현 방법. According to paragraph 3,
The neural network architecture is:
A computer-implemented method of a first apparatus, wherein a transmission neural network is selected from a plurality of candidate neural network architecture configurations based on scheduling latency.
제1 출력을 생성하는 단계는,
제1 장치의 하나 이상의 센서로부터 송신 신경망에 입력되는 센서 데이터에 더 기초하여 송신 신경망에서 제1 출력을 생성하는 단계를 포함하는, 제1 장치의 컴퓨터 구현 방법. According to any one of claims 1 to 4,
The step of generating the first output is:
A computer-implemented method of a first device, comprising generating a first output in a transmit neural network further based on sensor data input to the transmit neural network from one or more sensors of the first device.
제1 장치의 수신 신경망의 입력으로서 CSI 파일럿 신호의 표현을 수신하는 단계와; 그리고
수신 신경망에서, CSI 파일럿 신호의 표현에 기초하여, 제2 출력을 생성하는 단계를 더 포함하고, 상기 제2 출력은 CSI 추정치의 표현을 포함하는, 제1 장치의 컴퓨터 구현 방법. According to any one of claims 1 to 5,
Receiving a representation of the CSI pilot signal as input to a receiving neural network of the first device; and
The computer-implemented method of the first apparatus further comprising generating, in the receive neural network, a second output based on the representation of the CSI pilot signal, the second output comprising a representation of a CSI estimate.
제2 출력을 생성하는 단계는,
제1 장치의 하나 이상의 센서로부터의 센서 데이터 또는 CSI 추정치와 연관된 채널의 반송파 주파수 중 적어도 하나에 기초하여 수신 신경망에서 제2 출력을 생성하는 단계를 더 포함하는, 제1 장치의 컴퓨터 구현 방법.According to clause 6,
The step of generating the second output is,
The computer-implemented method of the first device further comprising generating a second output in the receive neural network based on at least one of sensor data from one or more sensors of the first device or a carrier frequency of a channel associated with the CSI estimate.
제1 장치의 적어도 하나의 성능을 나타내는 성능 정보를 인프라 컴포넌트에 제공하는 것에 응답하여 신경망 아키텍처 구성의 표시를 수신하는 단계와;
제1 장치의 수신 신경망에서 신경망 아키텍처 구성을 구현하는 단계와;
제1 장치의 무선 주파수(RF) 안테나 인터페이스에서, 제2 장치로부터 제1 RF 신호를 수신하는 단계와, 상기 제1 RF 신호는 예측된 미래 채널 상태 정보(CSI) 추정치의 압축된 표현을 나타내고;
수신 신경망에 대한 입력으로서 제1 RF 신호의 표현을 제공하는 단계와;
수신 신경망에서, 수신 신경망에 대한 입력에 기초하여 예측된 미래 CSI 추정치를 생성하는 단계와; 그리고
예측된 미래 CSI 추정에 기초하여 제1 장치에서 적어도 하나의 다중 입력 다중 출력(MIMO) 프로세스를 관리하는 단계를 포함하는, 제1 장치의 컴퓨터 구현 방법.1. A computer-implemented method of a first device, comprising:
receiving an indication of a neural network architecture configuration in response to providing performance information indicative of at least one performance of the first device to an infrastructure component;
implementing a neural network architecture configuration in a receiving neural network of a first device;
At a radio frequency (RF) antenna interface of the first device, receiving a first RF signal from a second device, the first RF signal representing a compressed representation of a predicted future channel state information (CSI) estimate;
providing a representation of the first RF signal as input to a receiving neural network;
generating, in the receiving neural network, a predicted future CSI estimate based on the input to the receiving neural network; and
A computer-implemented method of a first device, comprising managing at least one multiple-input multiple-output (MIMO) process at the first device based on predicted future CSI estimates.
예측된 미래 CSI 추정치를 생성하는 단계는,
수신 신경망에 대한 입력으로 제공된 제1 장치의 다중 입력 다중 출력(MIMO) 프로세스의 스케줄링 대기시간의 표현에 더 기초하여 수신 신경망에서 예측된 미래 CSI 추정치를 생성하는 단계를 더 포함하는, 제1 장치의 컴퓨터 구현 방법.According to clause 8,
The steps for generating predicted future CSI estimates are:
generating a predicted future CSI estimate in a receiving neural network based further on a representation of a scheduling latency of a multiple-input multiple-output (MIMO) process of the first device provided as input to the receiving neural network. Computer implementation method.
신경망 아키텍처 구성은,
스케줄링 대기시간에 기초하여 복수의 후보 신경망 아키텍처 구성으로부터 수신 신경망에 대해 선택되는, 제1 장치의 컴퓨터 구현 방법.According to clause 9,
The neural network architecture is:
A computer-implemented method of a first apparatus, wherein a receiving neural network is selected from a plurality of candidate neural network architecture configurations based on scheduling latency.
예측된 미래 CSI 추정치를 생성하는 단계는,
제1 장치의 하나 이상의 센서로부터 수신 신경망에 입력된 센서 데이터에 더 기초하여 수신 신경망에서 예측된 미래 CSI 추정치를 생성하는 단계를 포함하는, 제1 장치의 컴퓨터 구현 방법.According to any one of claims 8 to 10,
The steps for generating predicted future CSI estimates are:
A computer-implemented method of a first device, comprising generating a predicted future CSI estimate in a receiving neural network further based on sensor data input to the receiving neural network from one or more sensors of the first device.
신경망 아키텍처 구성은,
제1 장치의 적어도 하나의 성능 또는 제1 장치의 현재 신호 전파 환경 중 적어도 하나에 기초하여 복수의 신경망 아키텍처 구성으로부터 선택되는, 제1 장치의 컴퓨터 구현 방법.According to any one of claims 1 to 10,
The neural network architecture is:
A computer-implemented method of a first device, selected from a plurality of neural network architecture configurations based on at least one of at least one capability of the first device or a current signal propagation environment of the first device.
신경망 아키텍처 구성의 표시를 수신하는 단계는,
제1 장치에 로컬로 저장된 복수의 후보 신경망 아키텍처 구성 중 하나와 연관된 식별자를 수신하는 단계; 또는
신경망 아키텍처 구성의 파라미터를 나타내는 하나 이상의 데이터 구조를 수신하는 단계 중 적어도 하나를 포함하는, 제1 장치의 컴퓨터 구현 방법.According to any one of claims 1 to 10,
Receiving an indication of the neural network architecture configuration includes:
Receiving an identifier associated with one of a plurality of candidate neural network architecture configurations stored locally on the first device; or
A computer-implemented method of a first apparatus, comprising at least one of the following steps: receiving one or more data structures representing parameters of a neural network architecture configuration.
제1 장치의 송신 신경망에서 CSI 파일럿 신호를 생성하는 단계와; 그리고
제2 장치에 의한 수신을 위해 CSI 파일럿 신호를 나타내는 제2 RF 신호를 전송하도록 제1 장치의 RF 안테나 인터페이스를 제어하는 단계를 포함하는, 제1 장치의 컴퓨터 구현 방법.According to any one of claims 8 to 13,
generating a CSI pilot signal in a transmission neural network of the first device; and
A computer-implemented method of a first device, comprising controlling an RF antenna interface of the first device to transmit a second RF signal representing a CSI pilot signal for reception by the second device.
CSI 파일럿 신호를 생성하는 단계는,
CSI 추정치와 연관된 채널의 반송파 주파수, 제1 장치의 RF 안테나 인터페이스에 대한 적어도 하나의 동작 파라미터, 또는 제1 장치의 하나 이상의 센서로부터의 센서 데이터, 또는 CSI 추정치와 연관된 채널의 반송파 주파수 중 적어도 하나에 더 기초하여 송신 신경망에서 CSI 파일럿 신호 생성하는 단계를 포함하는, 제1 장치의 컴퓨터 구현 방법.According to clause 14,
The step of generating a CSI pilot signal is:
at least one of the carrier frequency of the channel associated with the CSI estimate, at least one operating parameter for an RF antenna interface of the first device, or sensor data from one or more sensors of the first device, or the carrier frequency of the channel associated with the CSI estimate. A computer-implemented method of a first apparatus further comprising generating a CSI pilot signal in a transmit neural network.
예측된 미래 CSI 추정치를 생성하는 단계는,
제1 장치의 하나 이상의 센서로부터의 센서 데이터 또는 예측된 미래 CSI 추정치와 연관된 채널의 반송파 주파수 중 적어도 하나에 기초하여 송신 신경망에서 예측된 미래 CSI 추정치를 생성하는 단계를 더 포함하는, 제1 장치의 컴퓨터 구현 방법.According to any one of claims 8 to 15,
The steps for generating predicted future CSI estimates are:
generating a predicted future CSI estimate in a transmit neural network based on at least one of sensor data from one or more sensors of the first device or a carrier frequency of a channel associated with the predicted future CSI estimate. Computer implementation method.
적어도 하나의 MIMO 프로세스는,
빔포밍 프로세스, 시공간 코딩 프로세스, 또는 다중 사용자 MIMO 프로세스 중 적어도 하나를 포함하는, 제1 장치의 컴퓨터 구현 방법. According to any one of claims 8 to 16,
At least one MIMO process is:
A computer-implemented method of a first apparatus, comprising at least one of a beamforming process, a space-time coding process, or a multi-user MIMO process.
적어도 하나의 성능은,
처리 성능, 전원 성능, 또는 센서 성능 중 적어도 하나를 포함하는, 제1 장치의 컴퓨터 구현 방법. According to any one of claims 1 to 17,
At least one performance is:
A computer-implemented method of a first device, comprising at least one of processing performance, power performance, or sensor performance.
무선 주파수(RF) 안테나 인터페이스;
RF 안테나 인터페이스에 연결된 적어도 하나의 프로세서; 및
실행 가능한 명령들을 저장하는 메모리를 포함하며, 상기 실행 가능한 명령들은 제1항 내지 제18항 중 어느 한 항의 방법을 수행하기 위해 적어도 하나의 프로세서를 조작하도록 구성되는 것을 특징으로 하는 장치.As a device,
radio frequency (RF) antenna interface;
at least one processor coupled to an RF antenna interface; and
An apparatus comprising a memory storing executable instructions, the executable instructions configured to operate at least one processor to perform the method of any one of claims 1 to 18.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163214931P | 2021-06-25 | 2021-06-25 | |
US63/214,931 | 2021-06-25 | ||
PCT/US2022/034060 WO2022271564A1 (en) | 2021-06-25 | 2022-06-17 | Wireless network employing neural networks for channel state feedback |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20230170975A true KR20230170975A (en) | 2023-12-19 |
Family
ID=82608192
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020237040314A KR20230170975A (en) | 2021-06-25 | 2022-06-17 | Wireless networks using neural networks for channel state feedback |
Country Status (4)
Country | Link |
---|---|
EP (1) | EP4327477A1 (en) |
KR (1) | KR20230170975A (en) |
CN (1) | CN117461266A (en) |
WO (1) | WO2022271564A1 (en) |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2020213964A1 (en) * | 2019-04-16 | 2020-10-22 | Samsung Electronics Co., Ltd. | Method and apparatus for reporting channel state information |
US10992331B2 (en) * | 2019-05-15 | 2021-04-27 | Huawei Technologies Co., Ltd. | Systems and methods for signaling for AI use by mobile stations in wireless networks |
US11928587B2 (en) * | 2019-08-14 | 2024-03-12 | Google Llc | Base station-user equipment messaging regarding deep neural networks |
-
2022
- 2022-06-17 CN CN202280040206.XA patent/CN117461266A/en active Pending
- 2022-06-17 KR KR1020237040314A patent/KR20230170975A/en unknown
- 2022-06-17 EP EP22743993.2A patent/EP4327477A1/en active Pending
- 2022-06-17 WO PCT/US2022/034060 patent/WO2022271564A1/en active Application Filing
Also Published As
Publication number | Publication date |
---|---|
EP4327477A1 (en) | 2024-02-28 |
WO2022271564A1 (en) | 2022-12-29 |
CN117461266A (en) | 2024-01-26 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11863258B2 (en) | Encoding and decoding of information for wireless transmission using multi-antenna transceivers | |
WO2023185978A1 (en) | Channel feature information reporting method, channel feature information recovery method, terminal and network side device | |
KR20230170975A (en) | Wireless networks using neural networks for channel state feedback | |
WO2022184010A1 (en) | Information reporting method and apparatus, first device, and second device | |
CN117318774A (en) | Channel matrix processing method, device, terminal and network side equipment | |
WO2022221388A1 (en) | Wireless system employing end-to-end neural network configuration for data streaming | |
US20240129004A1 (en) | Method and apparatus for transmitting channel state information | |
WO2023179474A1 (en) | Channel feature information assisted reporting and recovery method, terminal and network side device | |
JP2024519274A (en) | Wireless system employing end-to-end neural network configuration for data streaming - Patents.com | |
WO2023202514A1 (en) | Communication method and apparatus | |
EP4369620A1 (en) | Communication method and apparatus | |
WO2023179473A1 (en) | Channel feature information reporting method, channel feature information recovery method, terminal and network side device | |
WO2023179540A1 (en) | Channel prediction method and apparatus, and wireless communication device | |
KR20240038140A (en) | Cellular positioning using local sensors using neural networks | |
KR20230145196A (en) | Devices that use neural networks to combine cellular communications and sensor data | |
CN117614569A (en) | Method and apparatus for learning-based channel matrix prediction | |
TW202410654A (en) | Method and system for learning-based channel matrix prediction, and user equipment | |
CN117897931A (en) | Information processing method, apparatus, device, medium, chip, product, and program | |
WO2023220145A1 (en) | Conditional neural networks for cellular communication systems | |
CN117411527A (en) | Channel characteristic information reporting and recovering method, terminal and network equipment |