US8243988B1 - Clustering images using an image region graph - Google Patents
Clustering images using an image region graph Download PDFInfo
- Publication number
- US8243988B1 US8243988B1 US12/183,613 US18361308A US8243988B1 US 8243988 B1 US8243988 B1 US 8243988B1 US 18361308 A US18361308 A US 18361308A US 8243988 B1 US8243988 B1 US 8243988B1
- Authority
- US
- United States
- Prior art keywords
- images
- graph
- visual
- clusters
- computer
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 238000000034 method Methods 0.000 claims abstract description 38
- 238000004590 computer program Methods 0.000 claims abstract description 19
- 230000000007 visual effect Effects 0.000 claims description 19
- 241001417495 Serranidae Species 0.000 claims description 3
- 230000005484 gravity Effects 0.000 claims description 2
- 230000006870 function Effects 0.000 description 7
- 230000008569 process Effects 0.000 description 4
- 230000001965 increasing effect Effects 0.000 description 3
- 230000008520 organization Effects 0.000 description 3
- 239000000470 constituent Substances 0.000 description 2
- 230000010365 information processing Effects 0.000 description 2
- 238000007726 management method Methods 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 239000013598 vector Substances 0.000 description 2
- 230000006978 adaptation Effects 0.000 description 1
- 238000007792 addition Methods 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000015556 catabolic process Effects 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000002708 enhancing effect Effects 0.000 description 1
- 238000010191 image analysis Methods 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 230000002093 peripheral effect Effects 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/51—Indexing; Data structures therefor; Storage structures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2458—Special types of queries, e.g. statistical queries, fuzzy queries or distributed queries
- G06F16/2477—Temporal data queries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/5866—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using information manually generated, e.g. tags, keywords, comments, manually generated location and time information
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/23—Clustering techniques
- G06F18/231—Hierarchical techniques, i.e. dividing or merging pattern sets so as to obtain a dendrogram
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/23—Clustering techniques
- G06F18/232—Non-hierarchical techniques
- G06F18/2323—Non-hierarchical techniques based on graph theory, e.g. minimum spanning trees [MST] or graph cuts
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/762—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using clustering, e.g. of similar faces in social networks
- G06V10/7625—Hierarchical techniques, i.e. dividing or merging patterns to obtain a tree-like representation; Dendograms
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/762—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using clustering, e.g. of similar faces in social networks
- G06V10/7635—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using clustering, e.g. of similar faces in social networks based on graphs, e.g. graph cuts or spectral clustering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/30—Scenes; Scene-specific elements in albums, collections or shared content, e.g. social network photos or video
Definitions
- This invention relates generally to the grouping of digital images and more specifically to using image region graphs in clustering of images.
- a method for grouping images from image corpora using graph clustering is presented.
- a method is presented where grouping of images from a collection of digital images is done by: representing regions of images as vertices in a graph; connecting each pair of matching-vertices with a matching-edge; connecting each pair of overlap-vertices with an overlap-edge; assigning weights to each said matching-edge and to each said overlap-edge; clustering the graph, wherein clustering generates one or more vertex-clusters; and grouping the digital images into visual-clusters based on the vertex-clusters.
- a system for grouping images having: a processor; an interface, wherein the interface connects to a collection of digital images; and a visual clustering module that groups images from the collection of digital images.
- the visual clustering module includes: a graph generator module that generates a graph, where vertices represent regions in an image, where matching-edges connect regions to corresponding regions in different images, and where overlap-edges connect regions in the same image; an image clusterer module, that generates one or more vertex-clusters from the graph; and an image grouper module for grouping images into visual-clusters, wherein the grouping is based on said vertex-clusters.
- FIG. 1 is a system for automatically clustering images from image corpora, according to an embodiment of the present invention.
- FIG. 2 shows further details of the visual clustering module shown in FIG. 1 , according to an embodiment of the present invention.
- FIG. 3 is a flowchart illustrating the processing stages for grouping images based on graph clustering, according to an embodiment of the present invention.
- FIG. 4 shows further details of the graph generation stage of FIG. 3 , according to an embodiment of the present invention.
- FIG. 5 shows further details of the determine regions/vertices step of FIG. 4 , according to an embodiment of the present invention.
- FIG. 6 shows an example of a graph constructed according to an embodiment of the present invention.
- the methods disclosed may be used to rank images in similarity to each other, or to a specified image.
- the methods may also be used to facilitate the process of adding or maintaining user provided image descriptions and to organize images based on image contents.
- FIG. 1 illustrates a system according to an embodiment of the present invention that can automatically classify images from image corpora.
- a computer 101 that implements the classification methods according to teachings in this disclosure is connected to image corpora 110 , a database of grouped images 121 , and a system interface 130 .
- the image corpora 110 may be local to computer 101 , or may be coupled through a link 141 .
- Link 141 may be a device-internal connection such as peripheral component interchange (PCI) bus, a local area network, or a connection to a wide area network 140 .
- PCI peripheral component interchange
- Database of grouped images 121 is coupled to computer 101 using a link 142 .
- Link 142 may be a device-internal connection such as a PCI bus, a local area network, or a connection to a wide area network.
- Database 121 may include the results of the image classification processing from computer 101 .
- Database 121 may also include storage of images, resulting classification and search information, and any other data relevant to the classification of images according to the teachings in this disclosure.
- Database 121 may include functions to organize and manage images, for example and without limitation, a database management system.
- the term “database” is used in this disclosure broadly to mean a data storage entity with or without an associated data organization and retrieval system such as a database management system.
- System interface 130 is coupled to computer 101 through a link 131 .
- Interface 130 may connect computer 101 to another information processing system, or to a user.
- Link 131 may be a device-internal connection such as a PCI bus, a local area network, or a connection to a wide area network.
- System interface 130 may include a user input interface and display.
- System interface 130 may also include a web-based graphical user interface. User provided configuration information and feedback, as well as display of the image classification progress and/or results may be achieved using system interface 130 .
- Computer 101 includes a processor 102 , memory 103 , storage 104 , a visual clustering module 105 , an image collection interface 106 , and a database interface 107 .
- Processor 102 , memory 103 , storage 104 , and other components, including network or device interfaces (not shown), may be coupled with an internal bus (not shown).
- processor 102 includes the capability to execute the instructions of modules 105 , 106 , and 107 in implementing the teachings of this disclosure.
- the operating environment of computer 101 may include one or more operating systems, including, for example, any variant of Microsoft Windows or Linux operating systems.
- Memory 103 may include a random access temporary memory that provides temporary storage for data and instructions during the execution of the instructions in modules 105 , 106 , and 107 .
- Storage 104 may include a hard disk and/or removable storage that provide temporary or permanent storage for data and/or instructions forming the control logic in modules 105 , 106 , and 107 .
- Visual clustering module 105 includes instructions that enable the classification and grouping of images according to the teachings of this disclosure.
- Image collection interface 106 includes the instructions for maintaining the links to image corpora being used for processing in computer 101 , and may also include instructions for downloading and maintaining images from external sources for use in computer 101 .
- some or all of the images from image corpora 110 may be stored locally on storage 104 using image collection interface 106 , prior to processing by visual clustering module 105 .
- Database interface 107 includes instructions to enable the interaction between computer 101 and database 121 .
- the output of the visual clustering module 105 including visual clusters, may be written out to database 121 using database interface 107 .
- Visual clusters include the groups of images that are created based on the clustering done according to the teachings in this disclosure.
- database interface 107 may enable the modules of computer 101 , including visual clustering module 105 , to use information stored in database 121 in their processing.
- the instructions of modules 105 , 106 and 107 in their original form, may be written in any computer programming language including C, C++, Java or Assembly, or a combination thereof.
- modules 105 , 106 and 107 may include software, firmware, hardware or any combination thereof.
- FIG. 2 shows more detail of the composition of visual clustering module 105 in one embodiment of the present invention.
- Visual clustering module 105 includes a graph generator module 201 that generates a graph, for example, a region graph, based on the images from the image corpora; and an image organizer module 202 that generates visual-clusters of images based on the graph.
- Graph generator module 201 may, for example and without limitation, include logic instructions to: represent regions (see below for definition) in images as vertices in a graph; connect each pair of vertices that represent corresponding regions in two images; connect each pair of vertices that represent regions of the same image; and assign weights to each edge in the graph.
- Graph organizer module 202 may further include an image clusterer module 203 that clusters the images based on the graph constructed in stage 201 , and an image grouper module 205 that groups the clustered images into visual-clusters according to the clustering and user preferences.
- image clusterer module 203 that clusters the images based on the graph constructed in stage 201
- image grouper module 205 that groups the clustered images into visual-clusters according to the clustering and user preferences.
- FIG. 3 is a flowchart showing the processing stages of a method of grouping images according to an embodiment of the present invention.
- the first stage, stage 301 generates a graph, referred to herein as a region graph, based on the images to be processed.
- FIG. 4 is a more detailed breakdown of the components of stage 301 .
- the first activity in generating the graph is to determine the vertices of the region graph, as indicated in stage 401 .
- Stage 401 in one embodiment of the present invention, is further broken down to its constituent processing stages as shown in FIG. 5 .
- each image is processed to identify interest-points.
- An interest-point is a point in an image that has a well defined position and that can be detected readily, even in the presence of some image noise and differing scales.
- Interest-points can be corner points, points of lines, points of locally high curvature or other locally significant points.
- a number of interest-point detectors are known and may be used in stage 501 .
- the interest-point detector identifies interest-points by looking for locations on an image that are maxima or minima of a Laplacian-of-Gaussian function.
- stage 502 local descriptors are computed for each interest-point detected in stage 501 .
- a local descriptor corresponding to a particular interest-point describes a set of features in the area defined by the interest-point.
- the set of features included in a local descriptor may be predefined based on application requirements.
- local descriptors are generated by sampling the local region of the image relative to its scale-space coordinate frame using a set of Gabor wavelets. By generating local descriptors in this manner, the feature representation can be made invariant to many local variations. Local descriptors are also interchangeably referred to as feature vectors.
- image matching is performed using the local descriptors computed in stage 502 .
- the matching of two images may include comparison of features of the set of local descriptors of each image.
- the matching need not be absolute and may be based on a scoring that indicates the extent of matching features of each interest-point such that the scores can be aggregated over the set of interest-points for a pair of images that are compared.
- the scoring may also include predefined numerical weights assigned to each feature such that selected features may exert a higher impact on the matching process.
- an image index may be generated describing each image that was processed in stages 501 and 502 .
- the index may include a list of the images where, for each image, several data elements are included.
- the data elements may include the original image or a reference to the original image, an image derived from the original image (e.g., a low resolution thumbnail image), one or more image templates and local descriptors.
- the data elements may also include other information such as user information, geo-tagging information where available and user-provided or automatically assigned tag information.
- a region is a set of interest-points that contribute to a match between a pair of images. Therefore, a region is defined between a pair of images, and it is possible that a particular interest-point is included in more than one region. For example, if images A and B, and images A and C are matching pairs, then it is possible that a particular interest-point on image A contributes to the match between A and B as well as to the match between A and C, thereby becoming a part of the regions defined for both pairs.
- determining the regions based on interest-points yields the set of vertices for the graph, in stage 401 , as described with respect to FIG. 5 above.
- each region corresponds to a vertex in the graph being constructed, i.e., the region graph.
- stage 402 vertices are connected with matching-edges. Having already determined regions in stage 401 , the set of image pairs between which matching-edges should be drawn is already determined.
- a matching-edge is added between image A and image B (more specifically, between a region in image A and a region in image B), if they match, i.e., they exceed a threshold level of matching based on the set of feature vectors. For example, in the image index described above, if the entry for image A lists image B as a match with a score exceeding a predefined threshold, a matching-edge is added between the vertices that are considered a match.
- Each matching-edge is assigned a weight or cost as in formula (1):
- P FPij is the probability that the match between region i and region j is a false positive.
- Other embodiments of the present invention may assign costs based on a different measure of the strength of the match depicted by the edge, or match confidence.
- edges of a second type are added to the region graph.
- overlap-edges are created to inter-connect all regions within the image.
- the cost assigned to an overlap-edge is indicative of the level of overlap between the two regions connected by the overlap-edge. In one embodiment, the cost may be assigned as indicated in formula (2):
- d ij f d ⁇ ⁇ r _ i - r j _ ⁇ L ⁇ ⁇ 2 s i + s j ( 2 )
- f d is a factor to adjust the two different distance measures.
- ⁇ s is a scale multiple to account for the size of the image patch used to compute the descriptor relative to the interest-point scale s ik .
- K is the number of interest points in a region, and L2 denotes the L2-norm.
- Formula (2) effectively treats the interest-points as Gaussian blobs instead of points for the purpose of expansion computation.
- FIG. 6 illustrates an example graph 600 according to one embodiment of the present invention, using four images, Image 601 , Image 602 , Image 603 , and Image 604 .
- Graph 600 in FIG. 6 may be used to clarify the terminology used in this disclosure.
- the point 612 in Image 601 is the center of gravity of the set of interest-points that match with Image 603 .
- the center-of-gravity may be determined by a number of methods, including, by computing the average x and y coordinates of corresponding interest-points.
- the matching interest-points on Image 601 lie within the region 613 .
- the corresponding region in Image 603 is region 615 .
- Region 615 encompasses the set of interest-points on Image 603 that matched Image 601 , and has the center-of-gravity 614 .
- Edge 616 that connects region 613 in Image 601 and region 615 in Image 603 is a matching-edge.
- the cost, i.e., distance, of edge 616 is determined based on the points 612 and 614 .
- Region 611 is also in Image 601 , and the center-of-gravity of the interest-points in region 611 is point 610 .
- a region 617 encompasses interest-points in Image 602 that match with the interest-points of region 611 .
- Region 617 is centered on the center-of-gravity 634 of the corresponding interest-points.
- Edge 618 is a matching-edge. Also, because region 611 and region 613 are in the same Image 601 , the edge 619 that connects regions 611 and 613 is an overlap-edge.
- FIG. 6 also illustrates that regions, as defined in this disclosure, can overlap.
- regions 617 and 621 the interest-points of region 621 has the center-of-gravity at point 620
- regions 617 and 621 have common interest-points in the area in which they intersect.
- Regions 624 and 630 in Image 603 have their centers-of-gravity at points 623 and 629 , respectively.
- Region 633 in Image 604 the only area in Image 604 that matches another image, has its center-of-gravity in point 632 .
- the region graph corresponding to FIG. 6 has: vertices corresponding to regions 611 , 613 , 617 , 621 , 615 , 624 , 630 and 633 ; matching-edges 616 , 618 , 625 , and 631 ; and overlap-edges 619 , 622 , 626 , 627 and 628 .
- a shortest path graph may be generated from the region graph.
- the distance between any two regions n and m may be defined as in formula (3):
- P is the shortest path connecting n and m in the region graph.
- the density of the graph i.e., the ratio of edges to vertices two different algorithms can be used to find shortest paths: for dense graphs where the number of edges far exceeds the number of vertices, the Floyd-Warshall algorithm can be used; and, for sparse graphs, the Dijkstra shortest path algorithm can be used. Both these algorithms are known in the art.
- Clustering is implemented in stage 302 .
- hierarchical agglomerative clustering is used.
- pairs of vertices having the lowest cost e.g., shortest path in a shortest path graph
- the resulting graph is a collection of clusters connected by edges.
- the distance between the clusters may be defined in multiple ways. For example, formulas (4a), (4b), and (4c) show three possible approaches to computing the distance between two clusters n and m:
- Formula (4a) does not consider intra-cluster distances, and thus does not penalize very extensive clusters.
- Formula (4c), on the other hand, is directly dependent on cluster extension.
- Formula (4b) is in between (4a) and (4c) with regard to penalizing widely spread out clusters. All three distance measures (4a), (4b) and (4c), are commutative (since they only depend on the cluster constituents) and convex. This enables the application of nearest neighbor chains to solve the agglomerative clustering problem in O(N 2 ) time.
- an agglomerative clustering algorithm with nearest neighbor chains can be used with one of the measures (4a), (4b) or (4c) for inter-cluster distance, i.e., lowest cost.
- formula (4a) for inter-cluster distance enables the clustering result to be obtained using an equivalent algorithm. For example, instead of establishing a distance between any two vertices using a shortest path algorithm as in hierarchical agglomerative clustering, the same result can be obtained by deleting all edges with cost above the threshold. The groups of vertices still connected by edges (directly or indirectly) then comprise the clusters.
- the images are grouped using the clustering.
- the set of images containing all regions (vertices) of that cluster is the group of images corresponding to that vertex cluster.
- other aspects may be achieved. For example, within a given cluster, the image having the highest number of connecting edges may be selected as a representative image for that cluster or corresponding image group.
- the results of the processing may be stored and maintained in such a way that additions of new images to the image corpora can be incrementally integrated to the grouping.
- FIGS. 3-5 and the accompanying description can be implemented in software, firmware, hardware, or using any combination thereof. If programmable logic is used, such logic can execute on a commercially available processing platform or a special purpose processing platform.
- the programmable logic may be specified using any programming language.
- the software may be stored in a computer program product and loaded into a processing platform (for example, computer 101 ) for execution.
- the control logic also referred to as computer program logic or computer program
- the processor causes the processor (for example, processor 102 ) to perform the functions of FIGS. 3-5 and the accompanying description.
Abstract
Description
the center-of-gravity of region i,
the squared expansion of region i, and (rik,sik) the interest-points comprising region i. fd is a factor to adjust the two different distance measures. σs is a scale multiple to account for the size of the image patch used to compute the descriptor relative to the interest-point scale sik. K is the number of interest points in a region, and L2 denotes the L2-norm. Formula (2) effectively treats the interest-points as Gaussian blobs instead of points for the purpose of expansion computation.
Claims (23)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/183,613 US8243988B1 (en) | 2008-07-31 | 2008-07-31 | Clustering images using an image region graph |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/183,613 US8243988B1 (en) | 2008-07-31 | 2008-07-31 | Clustering images using an image region graph |
Publications (1)
Publication Number | Publication Date |
---|---|
US8243988B1 true US8243988B1 (en) | 2012-08-14 |
Family
ID=46613527
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/183,613 Active 2031-06-15 US8243988B1 (en) | 2008-07-31 | 2008-07-31 | Clustering images using an image region graph |
Country Status (1)
Country | Link |
---|---|
US (1) | US8243988B1 (en) |
Cited By (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140037227A1 (en) * | 2012-07-31 | 2014-02-06 | Bin Zhang | Hierarchical cluster determination based on subgraph density |
WO2014134150A1 (en) * | 2013-03-01 | 2014-09-04 | Facebook, Inc. | Photo clustering into moments |
US20140321761A1 (en) * | 2010-02-08 | 2014-10-30 | Microsoft Corporation | Intelligent Image Search Results Summarization and Browsing |
US20150154467A1 (en) * | 2013-12-04 | 2015-06-04 | Mitsubishi Electric Research Laboratories, Inc. | Method for Extracting Planes from 3D Point Cloud Sensor Data |
CN105678778A (en) * | 2016-01-13 | 2016-06-15 | 北京大学深圳研究生院 | Image matching method and device |
CN107844803A (en) * | 2017-10-30 | 2018-03-27 | 中国银联股份有限公司 | The method and apparatus that a kind of picture compares |
US20190179621A1 (en) * | 2017-12-12 | 2019-06-13 | Sap Se | Agglomerative Algorithm for Graph Clustering |
EP3417364A4 (en) * | 2016-02-15 | 2019-07-03 | eBay Inc. | Digital image presentation |
US10592539B1 (en) | 2014-07-11 | 2020-03-17 | Twitter, Inc. | Trends in a messaging platform |
US10601749B1 (en) * | 2014-07-11 | 2020-03-24 | Twitter, Inc. | Trends in a messaging platform |
US10650039B2 (en) * | 2016-02-25 | 2020-05-12 | Lionheart Legacy Uco | Customizable world map |
US11416121B2 (en) * | 2020-02-28 | 2022-08-16 | Fujifilm Corporation | Image processing apparatus, image processing method, and program |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6580811B2 (en) | 1998-04-13 | 2003-06-17 | Eyematic Interfaces, Inc. | Wavelet-based facial motion capture for avatar animation |
US20030219147A1 (en) * | 2002-05-23 | 2003-11-27 | Kabushiki Kaisha Toshiba | Object tracking apparatus and method |
US6711293B1 (en) | 1999-03-08 | 2004-03-23 | The University Of British Columbia | Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image |
US20060045325A1 (en) * | 2004-08-31 | 2006-03-02 | Semiconductor Insights Inc. | Method of design analysis of existing integrated circuits |
-
2008
- 2008-07-31 US US12/183,613 patent/US8243988B1/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6580811B2 (en) | 1998-04-13 | 2003-06-17 | Eyematic Interfaces, Inc. | Wavelet-based facial motion capture for avatar animation |
US6711293B1 (en) | 1999-03-08 | 2004-03-23 | The University Of British Columbia | Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image |
US20030219147A1 (en) * | 2002-05-23 | 2003-11-27 | Kabushiki Kaisha Toshiba | Object tracking apparatus and method |
US20060045325A1 (en) * | 2004-08-31 | 2006-03-02 | Semiconductor Insights Inc. | Method of design analysis of existing integrated circuits |
Non-Patent Citations (7)
Title |
---|
Brucher, F.A.., et al., U.S. Appl. No. 12/119,359, filed May 12, 2008, entitled "Automatic Discovery of Popular Landmarks". |
Buddemeier, U., et al., U.S. Appl. No. 12/049,841, filed Mar. 17, 2008, entitled "System and Methods for Descriptor Vector Computation". |
Gronau, I., et al., "Optimal Implementations of UPGMA and Other Common Clustering Algorithms", Information Processing Letters; Dec. 2007; 6 pages. |
Lindeberg, T., "On Scale Selection for Differential Operators", Proc. 8th Scandinavian Conference on Image Analysis; May 1993; pp. 857-866. |
Lowe, David G., "Distinctive Image Features from Scale-Invariant Keypoints", International Journal of Computer Vision; Jan. 5, 2004; 28 pages. |
Lowe, David G., "Object Recognition from Local Scale-Invariant Features", Proc. of the International Conference on Computer Vision; Sep. 1999; 8 pages. |
Maurer, T. et al. ,"Tracking and Learning Graphs on Image Sequences of Faces", Proceedings of International Conference on Artificial Neural Networks at Bochum; Jul. 16, 2006; 6 pages. |
Cited By (22)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10521692B2 (en) * | 2010-02-08 | 2019-12-31 | Microsoft Technology Licensing, Llc | Intelligent image search results summarization and browsing |
US20140321761A1 (en) * | 2010-02-08 | 2014-10-30 | Microsoft Corporation | Intelligent Image Search Results Summarization and Browsing |
US20140037227A1 (en) * | 2012-07-31 | 2014-02-06 | Bin Zhang | Hierarchical cluster determination based on subgraph density |
US8971665B2 (en) * | 2012-07-31 | 2015-03-03 | Hewlett-Packard Development Company, L.P. | Hierarchical cluster determination based on subgraph density |
US9411831B2 (en) | 2013-03-01 | 2016-08-09 | Facebook, Inc. | Photo clustering into moments |
AU2014223586B2 (en) * | 2013-03-01 | 2017-06-15 | Facebook, Inc. | Photo clustering into moments |
WO2014134150A1 (en) * | 2013-03-01 | 2014-09-04 | Facebook, Inc. | Photo clustering into moments |
US20150154467A1 (en) * | 2013-12-04 | 2015-06-04 | Mitsubishi Electric Research Laboratories, Inc. | Method for Extracting Planes from 3D Point Cloud Sensor Data |
US9412040B2 (en) * | 2013-12-04 | 2016-08-09 | Mitsubishi Electric Research Laboratories, Inc. | Method for extracting planes from 3D point cloud sensor data |
US10592539B1 (en) | 2014-07-11 | 2020-03-17 | Twitter, Inc. | Trends in a messaging platform |
US11500908B1 (en) | 2014-07-11 | 2022-11-15 | Twitter, Inc. | Trends in a messaging platform |
US11108717B1 (en) | 2014-07-11 | 2021-08-31 | Twitter, Inc. | Trends in a messaging platform |
US10601749B1 (en) * | 2014-07-11 | 2020-03-24 | Twitter, Inc. | Trends in a messaging platform |
CN105678778A (en) * | 2016-01-13 | 2016-06-15 | 北京大学深圳研究生院 | Image matching method and device |
EP3417364A4 (en) * | 2016-02-15 | 2019-07-03 | eBay Inc. | Digital image presentation |
US10796193B2 (en) | 2016-02-15 | 2020-10-06 | Ebay Inc. | Digital image presentation |
US11681745B2 (en) | 2016-02-15 | 2023-06-20 | Ebay Inc. | Digital image presentation |
US10650039B2 (en) * | 2016-02-25 | 2020-05-12 | Lionheart Legacy Uco | Customizable world map |
CN107844803A (en) * | 2017-10-30 | 2018-03-27 | 中国银联股份有限公司 | The method and apparatus that a kind of picture compares |
US10552129B2 (en) * | 2017-12-12 | 2020-02-04 | Sap Se | Agglomerative algorithm for graph clustering |
US20190179621A1 (en) * | 2017-12-12 | 2019-06-13 | Sap Se | Agglomerative Algorithm for Graph Clustering |
US11416121B2 (en) * | 2020-02-28 | 2022-08-16 | Fujifilm Corporation | Image processing apparatus, image processing method, and program |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8243988B1 (en) | Clustering images using an image region graph | |
US20230185844A1 (en) | Visually Guided Machine-learning Language Model | |
US20220075806A1 (en) | Natural language image search | |
US11816888B2 (en) | Accurate tag relevance prediction for image search | |
US11449767B2 (en) | Method of building a sorting model, and application method and apparatus based on the model | |
US20200380027A1 (en) | Multi-Modal Differential Search with Real-Time Focus Adaptation | |
KR102354716B1 (en) | Context-sensitive search using a deep learning model | |
US9087111B2 (en) | Personalized tag ranking | |
JP5749279B2 (en) | Join embedding for item association | |
US7548936B2 (en) | Systems and methods to present web image search results for effective image browsing | |
JP5346279B2 (en) | Annotation by search | |
EP2812883B1 (en) | System and method for semantically annotating images | |
JP2014534540A (en) | Interactive multi-mode image search | |
US20150178321A1 (en) | Image-based 3d model search and retrieval | |
KR20010053788A (en) | System for content-based image retrieval and method using for same | |
JP6167767B2 (en) | Index generation device and search device | |
CN113661487A (en) | Encoder for generating dense embedded vectors using machine-trained entry frequency weighting factors | |
CN103608826A (en) | In-video product annotation with web information mining | |
US20200272674A1 (en) | Method and apparatus for recommending entity, electronic device and computer readable medium | |
Choi et al. | Multimodal location estimation of consumer media: Dealing with sparse training data | |
US8001122B2 (en) | Relating similar terms for information retrieval | |
JP5890340B2 (en) | Image classification device and image classification program | |
CN110472058B (en) | Entity searching method, related equipment and computer storage medium | |
CN116628228A (en) | RPA flow recommendation method and computer readable storage medium | |
CN112883218A (en) | Image-text combined representation searching method, system, server and storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:BUDDEMEIER, ULRICH;REEL/FRAME:021324/0987Effective date: 20080730 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0405Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |