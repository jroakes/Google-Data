US8538886B1 - Watermarking system and methodology for digital multimedia content - Google Patents
Watermarking system and methodology for digital multimedia content Download PDFInfo
- Publication number
- US8538886B1 US8538886B1 US09/763,917 US76391799A US8538886B1 US 8538886 B1 US8538886 B1 US 8538886B1 US 76391799 A US76391799 A US 76391799A US 8538886 B1 US8538886 B1 US 8538886B1
- Authority
- US
- United States
- Prior art keywords
- video image
- video
- warping
- data stream
- viewer
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/0021—Image watermarking
- G06T1/005—Robust watermarking, e.g. average attack or collusion attack resistant
Definitions
- This invention relates generally to data protection, and more particularly to aspects of a novel digital watermark system and methodology for multimedia content, such as audio, video, text, still images, computer graphics, and software.
- a watermark is an imperceptible or at least difficult to perceive signal embedded into multimedia content such as audio, video, text, still images, computer graphics, or software.
- the watermark conveys some useful information without disturbing or degrading the presentation of the content in a way that is noticeable or objectionable.
- Watermarks have been used for the purpose of protecting the property rights of content providers, e.g., by helping to identify the rightful owner of the content. In this case, it should be possible reliably to retrieve the watermark even from content that has been significantly modified or degraded by various causes.
- the watermark should be resistant to intentional or unintentional removal, counterfeiting, or other tampering without substantial degradation to the content, significantly reducing its commercial value.
- a watermark should survive innocent processing like compression, decompression, analog to digital and digital to analog conversion, and format conversion (e.g., converting video from NTSC to PAL).
- the watermark should defy a deliberate attack by a pirate using common signal processing operations.
- it must be difficult to counterfeit a watermark; otherwise, watermarks might not be useful, for example, in resolving multiple claims of ownership.
- Watermarking technology is divided into three broad categories with different objectives, namely, tracing, copy protection and proof of ownership (copyright protection).
- Tracing identifies users that sell or give away illegal copies of protected content.
- Copy protection is implemented to prevent coping (at least, by compliant recorders) of content that contains a watermark denoting that the content should not be copied. Proof of ownership invalidates claims of ownership by anyone other than the legitimate owner of a copyrighted work.
- a watermark can be inserted into the content that contains information, which identifies the source of the copy.
- This watermark can include information such as the user identification number (e.g., from a smartcard), the serial number of the terminal, the serial number of the content, and the date and time the content was presented or copied. Since the watermark is different for every terminal and every user of the terminal, it must be inserted by the terminal and similar devices (at least, for broadcasted content such as pay-per-view and video on demand). This type of watermark may be recovered off-line by the content provider, service provider, or law enforcement officials.
- the content provider or service provider embeds a watermark into the multimedia content prior to public distribution.
- the watermark may be embedded into uncompressed or compressed versions of the content (or both).
- a properly constructed watermark unambiguously identifies the owner of the content. Later, if multiple claims of ownership need to be resolved, only the rightful owner of the content can recover the watermark from each copy of the content claimed to be an original.
- Standardization and openness are required because proprietary systems discourage the consumer due to a lack of interoperability. For example, deploying a video recorder that will only record content containing a “copying is allowed” watermark is worthwhile only if it can retrieve watermarks inserted by playback devices produced by many manufacturers.
- standardization and openness ensure that compliant devices have at least the minimum capabilities required to support the necessary functionalities (including watermarking). Expandability is needed because experience clearly indicates that technology advances rapidly and, in particular, security technology does not remain secure for very long whereas consumer electronics devices may remain in service for more than a decade. Also, new types of content and new technologies, not yet imagined, must be secure and protected.
- an unauthorized copyist may combine video outputs from a number of video players when a copy is made, so that the running mark information associated with any one player will not be easily read unambiguously.
- the copending application describes methodology using code division multiple access coding (CDMA) to detect the running marks associated with each single player among running marks associated with all the players used. Each player in this methodology encodes its running mark data using a different low correlation waveform.
- CDMA code division multiple access coding
- Each player in this methodology encodes its running mark data using a different low correlation waveform.
- the example described in the application implements a set of Hadmard-Walsh (HW) waveforms because they are mutually orthogonal and easily generated.
- bits are recovered by performing correlation (inner products) between the received waveform and reference waveforms to decode the running marks and provide source-of-copying information. Since correlation among these waveforms is low, inner product processing extracts the running mark bits correctly in a field of received waveforms from multiple players.
- the waveform adopted by a player is selected randomly at runtime from a finite set waveforms, to avoid the situation, although rare, where a pirate may use multiple players having the same waveform to make a copy.
- the described methodology includes waveform value scrambling and uses more than one waveform in a bitstream.
- the waveforms are permuted among different columns first and then among different rows.
- Storage of the CDMA waveform values (this may be incorporated in a separate security chip), even on a column basis, requires a considerable amount of memory. Placing the storage off chip is complicated, and security in that event is compromised.
- the above and other objectives and advantages are achieved, at least in part, by a novel system and methodology for processing a video bitstream where multiple (N) copies have been combined by a pirate from N players, for making it difficult to extract the running mark data for any player.
- the invention is performed, in accord with one aspect, by altering the video image slightly using any of a variety of different mapping functions during encoding to warp the video image by a small amount.
- the mapping function may change from time to time, such as periodically, using small changes of pixel position on the screen, or sharper changes upon significant scene changes.
- each time a video is played the player will select randomly among a finite number of mapping functions applied during encoding of the video bitstream.
- Pixels thus are shifted in position and must be realigned to the original pixel positions in the reproduced video upon decoding so that the image will not appear distorted.
- a pirate will be able to perform the necessary realignment of pixels only by doing so for each legitimate copy combined to make an unauthorized master copy of a video. This work on the part of the pirate is made more difficult by the fact that the pirate will not have possession of the original.
- the position shift furthermore prevents the pirate from being able to remove the watermarks by discerning the corresponding correlation function by well known video techniques, such as taking the average or multiplexing among the N copies.
- watermark data, other data or software may be downloaded from a service provider by embedding the data or software in the analog channel of the video supplied by the provider to the user.
- the software may comprise programming for changing the functionality of equipment in the hardware platform at the user terminal, e.g., encryption implemented in the encoder of a player.
- Preferably, local error correction is performed on the received software, where no handshaking with the provider is carried out.
- the data in practice will be downloaded at a rate sufficiently high such that the image may be disturbed. However, in general, downloading will be relatively brief or performed while the television or monitor is not being used and may be intentionally blanked.
- CDMA waveform values are carried, column by column, in the running mark pack within the video bitstream. Preferably, up to two columns of the CDMA waveform values are embedded in a running mark pack.
- the incoming encrypted bitstream contains the original video data and running mark packs.
- the CDMA table column values are added by to the running mark pack by vectoring to the bottom end of a pack and storing upward.
- a single column of values may be derived from bits of different columns of the CDMA table, for enhanced security. Flexibility is enhanced because the columns being carried by the running mark pack may be changed during play.
- the data structure implemented in the MPEG bitstream of running mark system is comprised of a header followed by successive data regions. Between the header and first data region, and between successive data regions is an unused portion. A pointer from the header or from any data region to the next data region, jumping over the unused portion, enables the unused portion to be filled by future program expansion such as watermark insertion, encryption, etc.
- the particular packet to which watermark data is to be added by message hole replacement is uniquely identified. This is done, either by packet counting that is inherently unreliable in the presence of noise, or by packet numbering that is complicated and adds to overhead, or by signature.
- the signature of a packet is derived from the stream identification (stream_id) and presentation time stamp (PTS) of a packet, defined in the MPEG-2 standard for packetized elemental streams (PES).
- the stream_id describing the type of packet, and PTS describing time interval within a packet for synchronization purposes, together form a signature that is usually capable of identifying the location of a particular bit within the bitstream. If a packet does not contain a PTS, the packet location in a bitstream is identified by offset from a previous packet having a PTS. Absolute location can be used to locate a packet when there is no available signature. To reduce ambiguities, and enhance robustness, more than one signature can be employed, or signature in combination with an absolute or relative address, may be implemented to identify a packet location.
- FIG. 1 is a high-level block diagram showing the hardware platform of a user terminal in which the invention is implemented.
- FIG. 2 shows the terminal interconnected with television and recorder appliances at a user facility.
- FIG. 3 shows the user terminal interconnected with a device in which there is no digital link, for describing an aspect of the invention.
- FIG. 4 shows a multiple player environment, in which image modification per another aspect of the invention is implemented.
- FIG. 5 depicts graphs depicting image mapping and re-alignment implementing an embodiment of image modification in accord with the invention
- FIGS. 6 and 7 are block diagrams of watermark inserter and extractor systems implementing image modification.
- FIG. 8 is a diagram of the data structure of a RMG_PCK used for carrying CDMA table data, in accord with another aspect of the invention.
- FIG. 9 is a diagram showing processing of column data carried by the RMG_PCK, in the invention.
- FIG. 10 shows an expandable MPEG-2 compatible bitstream packet, in accordance with a further aspect of the invention.
- FIG. 11 shows packet identification using packet signatures per another aspect of the invention.
- FIG. 13( a )-( d ) represent chain coding, wherein FIG. 13( a ) represents a sample coding scheme, FIG. 13( b ) represents a contour segment, FIG. 13( c ) is a chain-coded representation and FIG. 13( d ) shows a contour segment code.
- FIG. 14 shows different types of time warping functions applied to video.
- FIG. 15 represents a partition of an image frame, with each partition warped by a different function.
- FIG. 16 shows message holes in a video stream.
- FIG. 17 shows the use of reference packets and offset information to search for the target packet.
- FIG. 18 shows the use of group signatures (patterns) and string matching to search for a particular packet.
- FIG. 19 shows bits being extracted to be sent from B e [ ].
- Proposed image and video watermarking techniques can be divided into categories baed upon the domain in which they operate: spatial domain, or transform domain.
- Spatial domain techniques immerse the watermark into uncompressed video data, e.g., by directly modifying pixel values.
- the uncompressed video may be video that has not been compressed or video that has been obtained by decompressing a compressed video.
- Transform domain techniques compute a transformation (like the FFT, DCT, or wavelet transforms) of part of the video, insert the watermark by modifying the coefficient values, and compute the inverse transform to obtain the watermarked video.
- the complexity of spatial domain techniques can be moderate. For example, suppose the watermark is a noise-like pseudo-random sequence that is added to the luminance pixel values comprising a video. A hardware implementation of a pseudo-random generator requires only a few gates and a software implementation is not computationally complex. Spatial domain techniques are not constrained by the MPEG bitstream format. For instance, it is possible to spread the watermark throughout the entire video if every pixel in every frame is modified. Of course, it is convenient to use spatial domain techniques only when the uncompressed video is available (before compression or after decompression). Otherwise, it would be necessary to decode the compressed bitstream, insert the watermark, and reencode the video, which is costly and time-consuming.
- Transform domain watermarking techniques often have high complexity. Usually, a DCT, FFT, or wavelet transform of an entire image and its inverse is computed. The computational burden is substantial. If the watermark needs to be added to an MPEG bitstream, decoding and reencoding also are required. Despite the high complexity, transform domain techniques are the most common approach to watermarking (at least, when computational complexity is not an issue). The relevance of these transforms, especially the DCT and wavelet, to human perception is a major reason for this popularity. Another reason is that these transforms are natural operating domains for spread spectrum techniques. The MPEG bitstream format does not impose any constraints in the transform domain. It is possible, however, for some transform domain techniques to take advantage of the 8 ⁇ 8 DCTs in the MPEG bitstream.
- the method of Swanson, Zhu, and Tewfik is an interesting example of a transform domain technique.
- the (uncompressed) video to be watermarked is segmented into scenes.
- a 3D (x, y, and t) wavelet transform of each scene is computed.
- By computing the wavelet temporally as well as spatially it is possible to spread the watermarks across a greater portion of the video. For instance, the watermark embedded in the lowest frequency wavelet coefficient exists throughout all frames in the scene.
- a model of the human visual system is used to assess how much each wavelet coefficient can be modified without introducing a noticeable degradation of the video.
- the model takes into account frequency masking and spatial masking effects.
- the watermark is embedded into the video by modifying the wavelet coefficients to the extent indicated by the model and computing the inverse wavelet transform.
- the watermarking process is configured and controlled by a series of messages that are present in an auxiliary bit stream such as a private data stream.
- Message types that form the core functionality of a watermarking system are defined in this document.
- the messages have been designed according to object oriented principles. For example, many messages are a combination of a reference to an object (e.g., some data structure maintained by an OPIMA terminal), an action (method) to be performed on that object, and any other parameters needed to carry out the requested action.
- object e.g., some data structure maintained by an OPIMA terminal
- an action method
- the messages, objects, and methods have been designed to be as general as practicable. It should be possible to implement a wide variety of watermarking techniques by combining the various messages in different ways.
- Watermarking in the spatial domain has some interesting advantages. For instance, some digital video display devices have the ability to scale the video after it is decoded, e.g., to convert NTSC to a format suitable for display on a computer monitor. The detrimental effect that this scaling has on the watermark can be avoided if it is possible to insert the watermark into the video in the spatial domain after the video has been scaled. Also, if watermarks are inserted directly into an MPEG-2 video stream in an I or P frame, the watermark can affect the display of several frames, which may make the watermark more easily perceived. Of course, one disadvantage of placing watermarks in the spatial domain is that it is not possible to protect an MPEG-2 video stream without decoding and re-encoding at least part of the video.
- the spatial domain watermarking concepts presented in this section concentrate on the watermarking of each picture (frame) comprising the video.
- a picture might be obtained by decompressing an unwatermarked MPEG bitstream.
- Watermarking produces a picture, v′ i,j , with some bits hidden in it, e.g., some of the bits comprising the bit string denoted by B e .
- a bit or a group of bits are inserted into a picture by modifying a rectangular region of the picture:
- v i , j t ⁇ r l ⁇ ( v i , j , x i - i 0 , j - j 0 ) , if ⁇ ⁇ 0 ⁇ i - i 0 ⁇ M ⁇ ⁇ and ⁇ ⁇ 0 ⁇ j - j 0 ⁇ N , v i , j , otherwise ,
- (i 0 , j 0 ) is the location (coordinates) in the picture of the upper left corner of the modified rectangular region
- r l is some insertion (modulation) method, such as one of those listed in Table 1.
- ⁇ A , ⁇ p , and ⁇ E are parameters that control the strength of marks that are inserted by addition, multiplication, and exponentiation, respectively. This insertion process corresponds to watermark modulator 1 in FIG. 7 . Note that the insertion process may be repeated to insert as many watermarks as desired into a picture.
- b i is the bit (e.g., the ith bit of the bit string, B e ) and x m,n 0 and x m,n 1 are the versions of the watermark associated with a bit value of 0 and 1, respectively, and x m,n 0 are matrices of values. Each of these matrices are the same size (have the same dimension) as x m,n . For clarity, in the remainder of this section, matrices like x m,n 0 and x m,n 1 are referred to as marks, whereas the term watermark is reserved for matrices and collections of matrices like x m,n . Now suppose that a watermark represents 2 bits:
- the method of encoding multiple bits into a single watermark is analogous to a technique commonly used in digital communications where multiple bits can be represented with one set of modulations. For example, in QPSK, 2 bits are represented by four different phase shifts.
- class_id class identification number
- class_id class identification number
- the class_id values can be selected so that they also serve as start codes or resynchronization markers like those used in MPEG-2 sequence, GOP, picture, and slice headers, e.g., in the event of a loss of data due to a communication error.
- object identification number obj_id
- Objects are persistent; once created they continue to exist until they are explicitly destroyed or the content stream ends. If a message requests the construction of an object that already exists, the effect is the same as if the existing object has been destroyed and another object subsequently constructed. It is the responsibility of the designer of the messages to ensure that class_id, obj_id, and method values are correct.
- a mark object (one of the x m,n k matrices) is a matrix of values that can be used to modify a rectangular region of equal size in an uncompressed video frame.
- the mark can be either a pseudo-random pattern automatically generated by a pseudo-random number generator in the terminal or a given array of values.
- the syntax for a mark is listed in Table 2. There are four methods (actions) for a mark: construct a pseudo-random mark (constructRandom), construct a mark from the given matrix element values (constructMatrix), delete the mark (destroy), and insert the mark into a picture (insert).
- the insertion method type (r l ), the dimensions (size) of the mark (M and N), and the pseudo-random generator must be specified.
- the insertion method type is included in a mark object so that some intermediate values (such as ⁇ A ⁇ x) can be cached within the terminal, if desired.
- the pseudo-random generator object is created separately (by another message, described subsequently) and incorporated into a mark object by reference.
- the generator object provides a pseudo-random value for each element of the mark matrix.
- the insertion method type and the matrix element values are given. An example syntax is listed in Table 3. More efficient and more convenient representations of this data are sought.
- the insert method embeds a mark into the picture.
- This method is provided to allow the insertion of a static watermark, i.e., a watermark that does not depend on any bit values (b i ).
- the size of the mark and the insertion method type are given when the mark is constructed, so the only additional information required is a reference to the picture where the mark should go (v i,j ) and the location in that picture corresponding to the upper left corner of the mark, (i 0 , j 0 )
- obj_id A value which uniquely identifies an object in the SpatialVidMark( ) class.
- VidMarkinsertType( ) The insertion method type, which specifies how the mark should be inserted into the video (see Table 13).
- x_size The horizontal dimension of the mark (N).
- y_size The vertical dimension of the mark (M).
- PseudoRandomGeneratorRef( ) The pseudo-random number generator to be used to generate the mark (see Table 12).
- SpatialVidMarkPic( ) The mark, represented as a small rectangular matrix (image). See Table 3.
- PictureRef( ) Specifies which picture (video frame) the mark should be inserted into.
- x, y The x, y coordinates, in the picture, where the top left corner of the mark is inserted (i 0 , j 0 ).
- This object also contains a reference to the picture (frame) into which the marks are inserted (v i,j ) and the x, y coordinates in that picture where the mark should be placed (i 0 ,j 0 ).
- the construct method constructs a SpatialVidBitInserter( ) object from these constituent data structures.
- the destroy method deletes an object.
- the insert method extracts num_bits bits from the bit string source and inserts the corresponding mark into the picture at the coordinates that that were specified when the object was constructed.
- obj_id A value which uniquely identifies an object in the SpatialVidBitInserter( ) class.
- BitSourceRef( ) Specifies a bit string source (B e ) that controls which mark gets inserted.
- PictureRef( ) Specifies which picture (video frame) the mark should be inserted into (see Table 11).
- x, y The x, y coordinates, in the picture, where the top left corner of the mark is located (i 0 , j 0 ).
- SpatialVidMarkRef( ) A reference to a mark (see Table 2).
- a normally distributed pseudo-random number generator with a mean of 0 and a standard deviation of 4 is constructed and used to fill the elements of two mark matrices (image) that are 32 pixels wide and 12 pixels high. The mark will be inserted by adding it directly to the picture (video frame) pixel values without any scaling (since the amplitude is 1).
- a spatial video bit inserter is constructed that will, when requested, insert the second mark at coordinates (382, 186) in the referenced picture if the next bit extracted from the bit string is a 0 and will insert the first mark is it is a 1. Next, this bit is inserted into the picture. Finally, all the objects that were constructed (created) are destroyed.
- the transform could be the DCT, FFT, a wavelet, or some other transform.
- the elements of the matrix could be scalar values or complex numbers.
- the matrix is the transform of a rectangular region of a picture (frame) comprising the video. For example, it might be an 8 ⁇ 8 DCT (a block) or the 720 ⁇ 480 FFT of an entire NTSC frame.
- v s m ,t m are the modified transform coefficients
- r l is some insertion (modulation) method (see Table 1).
- the list of locations, (s m , t m ) allows any arbitrary subset of the transform coefficients to be modified and is easily implemented in software as illustrated in the following C code fragment:
- the list of locations generalizes the concept of the zigzag scan pattern used to access the DCT coefficient values in MPEG.
- Watermark insertion by this method corresponds to watermark modulator 1 in FIG. 6 .
- the insertion process can be repeated to insert as many bits as needed into the transform coefficients.
- x m 0 and x m 1 are vectors that are the same size as x m .
- a watermark represents 2 bits
- b i and b i+1 four marks x m,n 0 , x m,n 1 , x m,n 2 , and x m,n 3 are used to denote the four possible values of 2 bits: 00, 01, 10, and 11.
- the transform domain mark syntax is listed in Table 6.
- This mark is a vector (a 1-dimensional array) of transform coefficient values (x m k ).
- the values can be either a pseudo-random sequence or they can be provided in the message.
- the methods (actions) that can be performed on a mark are: construct a pseudo-random mark (constructRandom), construct a mark from the given array of coefficients (constructArray), delete the mark (destroy), and insert the mark (insert).
- construct a pseudo-random mark the transform type (DCT, FFT, wavelet, etc.), the insertion method type (r l ), the number of coefficients (M), and the pseudo-random generator are specified.
- Another message creates a pseudo-random number generator object and a reference to it provided when constructing a mark.
- the insertion method type is specified when the mark is constructed so that some of the intermediate values (such as ⁇ A ⁇ x in Table 1) can be cached within the terminal, if desired.
- To construct a mark from an array of coefficients the same data is needed except that an array (list) of transform coefficient values replaces the pseudo-random number generator.
- the coefficient values can be scalars or complex numbers. Destroying a mark releases the storage associated with it.
- the mark is inserted into the transform by the insert method. This method does not use any bit values (b i ); a static watermark is inserted.
- the insertion method type and the number of coefficients in the mark are given when the mark is constructed.
- TransformCoeff(transform_type) A transform coefficient value for the given type of transform (x m k ).
- VidTransformRef( ) Specifies which previously computed transform the mark should be inserted into.
- ScanPatternRef( ) A reference to the scanning pattern or list of locations, (s m ,t m ), as defined in Table 8, that determines which of the previously computed transform coefficients is modified by insertion.
- dct_coeff A DCT coefficient value.
- real_fft_coeff The real part of an FFT coefficient value.
- imag_fft_coeff The imaginary part of an FFT coefficient value.
- the syntax for inserting transform domain marks is listed in Table 7.
- the TransformVidBitInserter( ) class represents a list of marks, any one of which can be inserted into the transform depending on the value of a bit or bits from a bit string source (e.g., B e ).
- the mark is inserted into the set of coefficients obtained from a previously computed transform (v i,j ), incorporated by reference, VidTransformRef( ).
- a scanning pattern, (s m ,t m ) controls which coefficients are modified during insertion and which coefficients are left undisturbed.
- This scanning pattern is analogous to the zigzag or alternate scanning patterns for DCT coefficients in MPEG-2 except that any pattern can be specified and the pattern need not contain all the coefficients in the previously computed transform.
- an inverse transformation is computed and the resulting spatial (pixel) domain values are inserted into the specified picture (frame) at the given x, y coordinates. All these constituent data structures are given when the TransformVidBitInserter( ) object is constructed using the construct method. The object is deleted with the destroy method. The insert method get num_bits bits from the bit string source and inserts the appropriate mark.
- obj_id A value which uniquely identifies an object in the Spatial VidBitInserter( ) class.
- BitSourceRef( ) Specifies a bit string source to be used to control which mark gets inserted.
- PictureRef( ) Specifies which picture (video frame) the mark should be inserted into (see Table 11).
- x, y The x, y coordinates, in the picture, where the top left corner of the mark is located.
- 0 is represented by the absence of a mark.
- ScanPatternRef( ) A reference to the scanning pattern or list of locations, (s m ,t m ), as defined in Table 8, that determines which of the previously computed transform coefficients is modified by insertion.
- TransformVidMarkRef( ) A reference to a mark (see Table 6).
- the ScanPattern( ) class is used to select or specify a subset of the coefficient values comprising a 2-D transform such as the DCT, the FFT, or a wavelet transform.
- the syntax for the class is listed in Table 8.
- Four types of scanning patterns can be constructed: (1) zigzag, like the default DCT scanning pattern, (2) rectangular, like the order in which words are put on a page, (3) a list of locations (row and column coordinates), (4) a chain coded scan that is completely specified by data provided when the scanning pattern is constructed.
- the zigzag and rectangular scans both cover a rectangular area of the transform coefficients.
- the rectangular region that is covered must be specified by giving the row and column (corner1_u and corner1_v) of the first scanned coefficient in the matrix of transform coefficients and the row and column (corner2_u and corner2_v) of the last scanned coefficient. Also, for each of these scans, there are two different patterns that can fill the rectangle, depending on whether the first step is a horizontal or vertical one (which is specified by the horizontal bit flag). These scanning patterns are illustrated in FIG. 12 . The dot at the base of the arrows indicates the location given by corner1_u and corner1_v. The corner diagonally opposite is given by corner2_u and corner2_v.
- the chain coded scan is a continuous contour through the transform coefficients that is represented using a chain code. From any point in the matrix, a step to any one of the 8 adjacent points in the matrix can be specified by a value between 0 and 7 as illustrated in FIG. 13 .
- the contour is represented by the starting row and column (begin_u and begin_v) of the first scanned coefficient and a list of steps (step_dir) to take from there.
- obj_id A value which uniquely identifies an object in the ScanPattern( ) class.
- corner1_u, corner1_v For a zigzag or rectangular scan, the row and column of the first scanned coefficient in the matrix of transform coefficients.
- corner2_u, corner2_v The row and column of the last scanned coefficient.
- horizontal A bit flag that specifies if the first step in a zigzag or rectangular scan is horizontal or vertical.
- num_locs The number of locations in the list (M).
- u, v A row and column coordinate pair (s m , t m ).
- begin_u, begin_v The starting row and column of the first scanned coefficient of a chain coded scan.
- step_dir A value between 0 and 7 that specifies the direction to take when moving from one coefficient in the matrix of transform coefficients to any one of the 8 adjacent coefficients in the matrix.
- the VidTransform( ) class represents a transform of a rectangular region of a picture (frame) of the video.
- the type of transform to be computed, the picture to be used, and the rectangular region must be specified when constructing a VidTransform( ) object using the construct method.
- obj_id A value which uniquely identifies an object in the VidTransform( ) class.
- transform_type A bit string that indicates the type of transform (e.g., DCT, FFT, or wavelet).
- PictureRef( ) A rectangular region of pixels in this picture (video frame) is the data source (input) for the transform.
- begin_x, begin_y The x, y coordinates of the top left corner of the rectangular region.
- end x, end v The x, y coordinates of the bottom right corner of the rectangular region.
- method A code that indicates the action (method) to be performed.
- new_class_id The class_id value for the new class that is being registered.
- existing_class_id The class_id value of an existing class for which a new method is being registered.
- num_methods The number of new methods being registered.
- method_code The method value for each new method that is being registered.
- MethodRef( ) A reference to a method that has previously been downloaded to the terminal.
- the syntax for messages that manipulate common types of objects is described in this section.
- the types of objects are: a picture (frame) reference, a pseudo-random number generator, the type of video mark insertion method, a DCT of a section of video, and the scan pattern for scanning through transform coefficients, e.g., DCT coefficients.
- a pseudo-random number generator potentially can be used in several places in a watermarking technique.
- a pseudo-random number generator can be set-up and controlled using the syntax in Table 12.
- the algorithm used to create the pseudo-random numbers needs to be universally agreed upon since, in many watermarking techniques, the same pseudo-random sequence must be generated in both the watermark inserter and extractor. For this reason, it is also important that, if the construction (creation) of multiple pseudo-random number generator objects is requested, each object should have separate internal state variables. Numbers should generated only when requested by a message so that the internal state can be recreated if needed.
- a pseudo-random number generator is constructed (created) by specifying the seed value, the distribution, and the parameters of the distribution.
- a uniform distribution is specified by the upper and lower bounds of the pseudo-random numbers to be generated.
- a normal distribution is specified by the mean and standard deviation.
- a discrete distribution is specified a list of the discrete values the generator can return and the probability of occurrence associated with that value.
- One example of a discrete distribution is a binary random variable with an equal probability of occurrence for 0 and 1, which is listed in the following table:
- the terminal should compute and use a seed value such that the seed is different each time this option is invoked (e.g., by computing it from the system clock).
- lower bound The lower bound of the range of values that may be returned by the uniformly distributed pseudo-random number generator.
- upper_bound The upper bound of the range of values that may be returned by the generator.
- mean The mean of the normally distributed pseudo-random number generator.
- std_dev A value representing the standard deviation of the generator.
- num_values The number of discrete values that may be returned by the pseudo-random number generator discrete: One of the discrete values that may be returned by the generator.
- v′ i , v i , and x i can denote values in either the spatial or frequency (transform) domains.
- a user terminal 100 in a multimedia system that may be incorporated in, or provided with, a set top box in, for example, an OPIMA compliant terminal, is configured to receive scrambled and possibly encrypted multimedia content from a service or content provider.
- the multimedia content may comprise audio, video, still picture, software, etc., received by way of any suitable link, such as optical fiber, hard wire, RF, etc.
- the received content is applied to a descrambler 102 that produces descrambled, but still compressed, content in a form that conforms, for example, to MPEG standard.
- the compressed content when reproduced, is decoded to produce an analog output that is applied to a television or a monitor, in the case of video content, or to another reproduction device.
- Watermark data are inserted into the data stream and becomes part of the output of the terminal, such that any reproduction of the output signal developed by the terminal will bear the watermark.
- the watermark is a digital signal that identifies when and where playback has occurred.
- the watermark may be in the form of “running marks” of the type described in copending application Ser. No. 09/092,898, filed on Jun. 8, 1998 and incorporated herein by reference, that identify the source-of-copying (that is, the DVD, DVD player and time of play). This “source-of-copying” information can be used to trace to the copyist, to control copying, or both, as described in the copending application.
- the compressed content descrambled by unit 102 , can have watermark data inserted either before or after decoding, or can be performed both before and after decoding.
- the compressed multimedia content is applied to tracing watermark inserter 104 a to provide a digital output that is a bitstream containing both compressed digital content and watermark data, and then to decoder 108 a (such as an MPEG-2 decoder) to produce a corresponding first analog output.
- decoder 108 a such as an MPEG-2 decoder
- the compressed digital content can be routed first to decoder 108 b and then to tracing watermark inserter 104 b to produce a second analog output signal.
- the digital output from watermark inserter 104 a may be applied to a recorder 112 for recording the content on a recording medium, such as a DVD.
- the recorder enables recording to be performed only if the bitstream is found by copy protection watermark detector 114 to contain a watermark that permits copying.
- the watermark may include data that permits copying, prohibits copying or permits limited or conditional copying. Detection of the watermark can be performed by any suitable digital filtering process.
- FIG. 2 shows the terminal 100 as it may be connected to a television and analog/digital recording equipment in this invention.
- Encrypted and compressed multimedia content produced by a content provider, obtained via cable, satellite, etc. is applied to the terminal at line 116 .
- a reverse link 118 enables the terminal to communicate back to the provider, via telephone link or other transmission medium, to transfer billing information, polling, etc., in a known manner.
- the output of the terminal 100 produces analog and digital signals, separately, as described previously.
- Analog link 120 corresponding to analog output 1 or analog output 2 in FIG. 1 , is applied to TV 122 , VCR 124 and digital recorder 126 .
- the digital output 128 of the terminal is applied only to the digital recorder 126 .
- the VCR 124 and digital recorder 126 are supplied to television 122 in a conventional manner.
- the watermark added to the data stream each time playback of content received from a provider or reproduced from a prerecorded medium is played, comprises virtually invisible marks embedded into the compressed digital data stream. These marks may identify the player unit, content source and time of play, to help enable trace to the copyist.
- the best mode of the invention is described within the context of a video stream produced in an MPEG-2 domain, although it is to be understood that the invention is not limited thereto.
- the source-of-copying message, embedded in the watermark can be combined into an audio signal or into software using similar principles.
- the watermarks are not visible to a viewer, but can be detected and decoded by hardware maintained by an authorized institution.
- the institution in possession of a DVD, for example, containing protected material, will play the material using equipment that detects and decodes the watermark.
- the information embedded in the watermark for example, the serial number of the player used to make the copy, the serial number of the master from which the copy was made and the time the copy was made, may help the institution trace to the copyist.
- the watermark may contain data that will prevent an unauthorized user to reproduce the content from the master, or limit the number of copies that can be made, as explained previously.
- a pirate copyist may attempt to attack the running mark system for producing digital watermarks by combining video outputs from multiple playback units.
- a copyist may combine the outputs of N players playing a DVD, or other protected medium, to produce a reproduction from which many copies will be made for illicit distribution. The pirate copy is then made by averaging or simply time-multiplexing among the copies.
- This form of attack by a pirate is countered, in accord with the present invention, by adding a further level of signal processing that will alter the image, produced by the playback unit in an imperceptible way.
- Each playback unit imposes a different alteration, known only to the content owner, so that without correction the image produced by combining copies from multiple playback units will be degraded and unwatchable.
- the image reproduced by each playback unit undergoes a spatial transformation that is dictated by a mapping function F( ⁇ ). Altering of the image may be performed by any conventional image mapping functionality.
- Each playback unit may have a prescribed mapping function assigned to it, or may select among any number of pre-stored mapping functions, based on a key that could be read from the video stream, read from the DVD or developed in some other manner.
- the mapping function could, for example, warp the image, shown in FIG. 5 , by compressing the spacing between pixels in the vertical direction and expanding the positions in the horizontal direction.
- the amount of warping is subtle, so that playing a copy made by a single playback unit is not noticed by a viewer.
- the composite image will be distorted (fuzzy) and not of commercial quality.
- a pirate copy with reasonable picture quality cannot be generated without first re-registering the copies to compensate for the deliberate alteration applied by the content owner. Although the pirate may be able to re-register the pixels, this is time consuming and impractical when an illicit copy made by multiple playback units is involved.
- mapping function the time required for a pirate to realign copies made by multiple playback units, each imposing a different mapping function, can be expected to require up to several months or more of labor. This will considerably delay the time when the pirate can distribute usable copies.
- the mapping function and its parameters are known and chosen from a pre-defined library.
- the mapping function may be changed from time to time, such as periodically, to make it more difficult realign pixels if the pirate learns the mapping function.
- the mapping functions preferably are selected such that successive functions alter the image only slightly. (A larger single change in image alignment may be visible, whereas a succession, over time, of several smaller changes may not.)
- the mapping function may change at the time of a scene change. In this example, a larger alteration of the image, by mapping, may be tolerated by the viewer.
- pixels may be shifted in position, by different amounts among different players, and by a different amount each time a medium is played successively by a single player.
- the pixels must be realigned to the original pixel positions in the reproduced video upon decoding, by the pirate, so that the image will not appear distorted.
- a pirate will be able to perform the necessary realignment of pixels only by doing so for each and every copy that is combined to make an unauthorized master copy of a video. This work on the part of the pirate is made more difficult by the fact that the pirate will not have possession of the original.
- mapping function used for altering the image can be selected among many possibilities.
- the function will provide image alteration that is invisible to the viewer, easy to apply, quickly generated and robust (not easily reversed by the pirate).
- mapping functions are examples.
- a geometric transformation ⁇ on image defines the mapping between two image coordinates, (x,y) and (x′,y′).
- the geometric transformation in terms of backward warping so that (x,y) is defined on grid points (i.e., x,y ⁇ Z) while (x′,y′) can fall on sub-pixel locations (c.f. FIG. 5 ).
- ⁇ is the parameter set of the transformation.
- Backward warping is preferred over forward warping because it ensures that every grid point in the target frame has a matching point from the original so that it leaves “no holes” in the target frame.
- Applying an image interpolation function the pixel values in the warped frame can then be computed.
- Popular interpolation schemes are: nearest neighbor, linear interpolation, and bilinear interpolation.
- the warping function remains a 2D geometric transformation at fixed time instant, while at different time both the function form and the parameters can be changed.
- ⁇ (t) the warping function
- Table 15 summarizes a collection of geometric transformations that can be used for anti-tamper warping. The size of the parameter set and parameters are listed for comparison. Here we also provide some mathematical details of some of these functions.
- the 2D scaling takes four parameters: the scaling center (x 0 ,y 0 ), the scaling factor along two image axis s, and s, respectively.
- x′ s x ( x ⁇ x 0 )+ x 0
- y′ s y ( y ⁇ y 0 )+ y 0
- the Quadratic Curves and Surfaces category uses 2 nd order polynomials to represent the coordinate transformation.
- a higher order (greater than three) polynomial or rational functions can be used to generate a more complicated and yet smooth warping function.
- both P x (n) and P y (n) are an n-th order polynomial. Since an n-th order polynomial contains n+1 coefficients, it can be uniquely defined by giving n+1 interpolation points (assuming no three points are colinear). In the non-separable case, a polynomial surface can be defined.
- a rational function R (n,m) is a quotient of two polynomials:
- Projective transformation is a rational function (non-separable) commonly used in image processing to approximate the image change under rigid-body motion and perspective projection. It has the following form:
- x ′ a x ′ ⁇ x ⁇ x + a y ′ ⁇ y ⁇ y + a y ′ a ⁇ ⁇ x + a ⁇ ⁇ y + 1
- y ′ a x ′ ⁇ x ⁇ x + a y ′ ⁇ y ⁇ y + a y ′ a ⁇ ⁇ x + a ⁇ ⁇ y + 1
- Cubic splines have been widely used in computer graphics applications to generate realistic scenes.
- a cubic spline can be defined by a group of points, called control points. Since each curve segment is a cubic polynomial with four coefficients, at least four constraints are needed, allowing us to formulate four equations and solve the four unknowns. The constraints usually comes from the end points, their tangents, and assumptions on the geometric continuity at the segment boundary. Different cubic splines use different constraints, and their capability to interpolate control points vary. For instance, a natural cubic spline interpolates all its control points while uniform B-spline does not interpolate any of its control points. For some splines, extra unknowns (parameters) are used to control the geometric continuity at the segment boundary.
- ⁇ x and ⁇ y are a spline curve.
- the geometric transformation is separable.
- a bicubic spline surface can be defined by given a set of control points in the 2D space. The number of parameters therefore increases significantly.
- One advantage of using spline function for image warping is that it is easy to control the warping of image boundary so that the boundary can be fixed. This makes the warping much more difficult to detect.
- Commonly used cubic splines include natural cubic spline(4), Hermite curve (4), Bezier curve (4), Uniform B-spline (4), Nonuniform B-spline (6), ⁇ -spline (5), Catmull-Rom curve (4), Kochanek-Bartels curve (7), and so on. (The number in the parentheses shows the number of parameters per curve segment.) For more details on these splines, including their constraints and parameters, please refer to [12].
- Motion transform uses a small number of paramters to represent the motion vectors m x and m y in a transform domain (e.g., frequency domain) instead of the image domain.
- the transform is defined based on a set of basis functions.
- B denotes the basis function
- M x and M y represent the transformed motion vectors.
- the transform function ⁇ ) ⁇ can be DFT (Discrete Fourier Transform), Haar transform, KL transform, wavelet tranform, or others.
- the indices u and v indicate the basis functions included.
- u and v are chosen from the sets U and V (i.e., u ⁇ U and v ⁇ V).
- the complexity (or number of parameters) can be represented by
- the elements in U and V can be customized to include some basis functions whose span is our interested motion subspace.
- the Fourier family and wavelet family are two types of basis functions: the Fourier family and wavelet family.
- M and N are the horizontal and vertical size of the frame, respectively.
- Wavelet functions can be used to describe the warping in a similar way as the Fourier family (or sinusoidal functions). The main difference is that wavelet transform is usually hierarchically applied thereby bearing the multi-resolution concept. Denote the scaling and wavelet function as ⁇ and ⁇ for generating the multi-resolution analysis (MRA) in the wavelet representation, the motion transform can be written as:
- l is the index for the resolution level
- l ⁇ 1,0, . . . , L ⁇ 1.
- the basis functions included at each level may vary therefore u and v become a function of I.
- the basis functions can be written as a tensor product of the scaling function ⁇ and wavelet function ⁇ .
- ⁇ the coarsest level
- B ⁇ 1 ( x,y,u ⁇ 1 ,v ⁇ 1 ) ⁇ ( x ⁇ u ⁇ 1 ) ⁇ ( y ⁇ v ⁇ 1 )
- the basis functions have three forms: horizontal (H), vertical (V), and diagonal (D) depending on the construct from the scaling and wavelet functions.
- B l H ( x,y,u l ,v l ) ⁇ ( 2 l x ⁇ u l ) ⁇ ( 2 l y ⁇ v l )
- B l V ( x,y,u l ,v l ) ⁇ ( 2 l x ⁇ u l ) ⁇ ( 2 l y ⁇ v l )
- B l D ( x,y,u l ,v l ) ⁇ ( 2 l x ⁇ u l ) ⁇ ( 2 l y ⁇ v l )
- wavelets is the Cai-Wang wavelet [13,14], in which where for any real number n and
- x + n ⁇ x n if ⁇ ⁇ x ⁇ 0 0 otherwise
- ⁇ ⁇ ( x ) - 3 7 ⁇ ⁇ ⁇ ( 2 ⁇ x ) + 12 7 ⁇ ⁇ ⁇ ( 2 ⁇ x - 1 ) - 3 7 ⁇ ⁇ ⁇ ( 2 ⁇ x - 2 )
- Wavelets and their applications have been very popular recently.
- Other popular wavelet functions are Haar, Daubechies family, Meyer, Lemarie, and a lot more. For more details, please refer to [15].
- Look-up table is a direct way to describe the coordinate mapping by simply storing the mapping of every image pixel (grid point) in a table so that a simple table look-up gives the mapped location. Since the movement of each pixel has two degree of freedom, in the non-separable case, a table of size 2 MN is needed to specify the mapping for an M by N image. In the separable case, two arrays (of size M and N each) are sufficient.
- a LUT can also store only the mapping of a subset of image points to define a mesh structure and be used with different warping functions for each mesh element. They will be further discussed in a later section.
- the warping function can change through time slowly to provide a better protection against pirates' attack. The change must be slow enough so that it does not produce unpleasant visual artifacts.
- ⁇ 0 is the initial parameter set.
- the time-warping function ⁇ t can be either linear, quadratic, cubic, or sinusoidal. Most functions shown in Table 15 can be used for time warping as well. Therefore ⁇ t can be: (c.f. FIG. 15 )
- Piecewise constant In this case, the parameter set remains constant within a time interval.
- Piecewise linear A saw-tooth-like waveform can be used as the time warping function. Each line segment can be defined by its end points and slope.
- Quadratic or cubic curve Same quadratic or cubic curves can be used in the time domain to specify the parameter change through time.
- Sinusoidal Use of sinusoidal function to describe parameter change though time is relatively simple and it does not require a large number of extra parameters.
- ⁇ t ( t ) ⁇ t ( t 0 )+ A ⁇ sin( w ( t ⁇ t 0 ))
- ⁇ t , (t 0 ) is its value at time t 0
- a and w are the amplitude and angular velocity of the sinusoidal function respectively.
- the form of the time-warping function can be changed at selected time instants, preferably at scene change along the video sequence or black frames, which provides a natural way to insert discontinuity into the time-warping function without causing visual artifacts.
- the warping on a single image can be a result from applying multiple transformations.
- ⁇ l is the i-th partition of the image (c.f. FIG. 16 ).
- ⁇ l is the i-th partition of the image (c.f. FIG. 16 ).
- how to partition the image is critical to the overall distortion and one should be careful not to cause undesired visual effect by ill choosing the partition, function form, and parameter set.
- a mesh-like partition can be more easily applied to create the warping, for example, by polygon mesh or non-linear (higher-order) warping on each mesh element.
- FIGS. 6 and 7 depict, respectively, a system for inserting a watermark into and extracting the water mark from the encrypted and compressed video stream, including warping and re-registration.
- the original message B a obtained from a DVD, in this example, by the playback unit is encrypted by unit 202 .
- This unit obfuscates the original message to help prevent insertion of a false but valid watermark message and the retrieval of a watermark message by any unauthorized party. Any one of various encryption algorithms can be used.
- the encrypted message is applied to an error correction coder 204 that improves the ability to recover the message even the presence of significant signal degradation and many bit errors by introducing redundant information. Since signal degradation may be severe, especially in the case of a concerted attempt to eradicate the message, strong error correction with a great deal of redundancy is preferred. Reed-Solomon coding combined with convolutional coding is preferred.
- the error corrected message next is applied to CDMA encoder 206 that maps (transforms) a single message bit into many bits (a chip or spreading waveform), which dramatically increases the spectrum (bandwidth) of the signal representing the message. Consequently, the density of the power spectra of the signal is greatly reduced so that the signal is more easily hidden and less easily eradicated. Expressed less precisely, the signal is spread over a greater part of the content but is inserted at a lower strength which results in it being harder to notice and harder to remove without degrading most of the content. In the best mode, a table of spreading waveforms is maintained so that it is possible to use different waveforms for different bits that are inserted into the content.
- Another (optional) encrypter 212 encrypts the CDMA bitstream.
- the output of encrypter 212 is supplied to a first watermark modulator 214 that converts each bit into a modification to the content to yield the watermarked content. For example, a few of the frequency components of a signal might be modified by a small random amount in order to represent a single bit. The content is compressed at this point.
- Compression decoder 216 decompresses the content, if necessary. If the original content is compressed, it must be decompressed at some point in order to present it to the user.
- This decoder e.g., an MPEG-2 decoder
- This decoder is not part of the watermarking system, but is depicted in the block diagram because it interacts with the watermarking system.
- Watermark modulator 218 converts each bit into a modification to the uncompressed content to yield the watermarked content (C h ).
- the block represents an alternate or additional point at which a watermark can be introduced into the content.
- Anti-tampering encoder 220 applies any one of a set of geometric transformations, as described previously, that may change over time to the uncompressed image or video in order to make the watermark more difficult to detect or remove.
- the watermark extractor 250 first carries out channel compensation in unit 252 , to compensate for the effects of content degradation resulting from, e.g., analog copying or an intentional attempt to remove the watermark.
- This compensation could be implemented, for example, as a filter that has a transfer function which is the inverse of the transfer function of the degradation.
- mapping function in unit 254 This is followed by decoding of the mapping function in unit 254 , to restore image alignment.
- Decoding reverses the effect of the anti-tampering warping encoder of a watermark inserter by applying a geometric transformation that is the inverse of the one used by the encoder.
- Compression decoder 254 decompresses the content, if necessary.
- Watermark demodulator 256 retrieves each bit embedded in the watermarked content by detecting the modification introduced by the modulator.
- Decryptor 258 decrypts the retrieved bit stream to reverse the effect of encryptor 212 .
- CDMA waveform generator 266 duplicates the function of CDMA waveform generator of the watermark inserter 200 by re-creating the spreading waveforms used in the inserter.
- CDMA decoder 260 inverts the effect of the CDMA encoder by mapping an entire spreading waveform back to a single bit. This mapping is accomplished by computing the correlation between the retrieved waveform and a waveform the possibly could have been used by the watermark inserter. The waveform with the largest correlation value is considered to by the correct one, that is, the one that was used by the inserter.
- Error correcting decoder 262 corrects errors in the bits obtained from the CDMA decoder 260 . If strong error correction with a large amount of redundancy is used, it is possible to recover the correct bits even in the presence of severe signal degradation.
- Decryptor 264 decrypts the retrieved bitstream to reverse the effect of decryptor 202 . The resultant bitstream should be identical to the original bitstream.
- watermark data, software, and other information content may be downloaded from a service provider to the terminal by embedding the content in the analog channel of the video supplied by the provider.
- this type of information is supplied by downloading digitally, whereas the invention addresses environments in which the user does not have a digital link.
- Information may be supplied to the terminal over any medium, including the interne.
- the content being downloaded might include software, updates or modifications of terminal resident operating software, such as decryption keys, etc., without limitation.
- the video signal, in the analog domain, such as NTSC is encoded with data to be downloaded, in the active parts of the audio/video signal channel.
- active part of the channel is meant the part of the channel that is visible to the user.
- non-active part of the channel is the part that is not visible, such as within the retrace or blanking interval, or the region of the image outside the screen viewing area.
- the NTSC analog signal has a 6 MHz bandwidth channel within which this content to be downloaded to the user can be carried.
- the data may be embedded in the video in “message holes” as described in the copending application or in any other manner.
- the downloaded content will distort the image or audio perceived by the user, the period of distortion will be limited, and advantageously may be downloaded at a time when the user is not occupying the terminal, such as in the middle of the night. Even where the data is to be downloaded when the terminal is otherwise in use, the television or other equipment may be temporarily disabled or “blanked” or overlaid with a “downloading in process” message, to avoid confusing or annoying the user.
- the present invention capitalizes on the fact that the active region is many times greater in bandwidth capacity than the non-active portion of the channel.
- Downloading per the invention is not limited to any particular standard, for example, PAM or other modulation format can be implemented.
- the downloaded content may be encrypted, compressed, etc.
- the preferred embodiment implements local error checking, utilizing any suitable error checking algorithm. Error correction preferably also is implemented locally since there is no ability to request resending of error laden data.
- FIG. 8 in accord with another aspect of the invention, an improvement is made to the copending application in which a substantial amount of local storage is required for storing the reference CDMA waveform values for correlation with the waveforms received from and bearing watermark information associated with, the playback units.
- the CDMA values are carried, column by column, in the running mark pack (RMG_PCK), such as at the bottom of the pack, and building upward, as shown in FIG. 8 .
- the running mark pack RMG_PCK
- storage of the columns can be made serially downward in the pack, in a conventional way.
- bits of different columns of the table can be selected to comprise a “single column” for exclusive OR bitwise processing.
- two columns of the CDMA waveform table are sent in each RMG_PCK, although the number can be varied.
- An advantage of this methodology is in enhanced security, as the entire CDMA table is not available, in one location, for reverse engineering by a pirate.
- the described methodology provides enhanced flexibility, as different columns can be implemented for embedding in the RMG_PCK, and are changeable.
- FIG. 10 Another aspect of the invention, shown in FIG. 10 , is in an improvement to the RMG_PCK data structure described in FIG. 14 , and associated text, of the copending application.
- the layout of the structure comprises a running mark header, followed by a number of data, within an MPEG bitstream.
- unused regions are reserved between the header and first data and between the successive data, that, together, conform to DVD specifications.
- the data structure hence is expandable, using the reserved areas, such that additional programming such as watermark, encryption, etc., can be added.
- Copy protection watermarking cannot provide comprehensive protection of content. It only prevents the copying of content by a compliant recorder.
- the Macrovision analog protection system APS
- APS may discourage casual copying on some machines, but many modern VCRs have no difficulty recording video signals containing APS and inexpensive devices that defeat APS are available to the public at the local electronics store.
- APS cannot protect the RGB video signals commonly used on computers or the digital video signals on, for instance, a USB or 1394 link.
- tracing watermarks which do not prevent copying, but can be used to identify those who make illegal copies. Tracing watermarks are retrieved by a content provider or service provider and, consequently, a compliant recorder is not required to enable tracing. Consumer electronics devices do not need to detect these watermarks at all. Some consumer electronics devices, like the OPIMA terminal, would need to insert the tracing watermarks into content.
- VLCs Huffman codes
- inverse quantization is performed to get the DCT coefficients
- the DCT coefficients are modified to introduce the watermarks
- the modified coefficients are quantized
- replacement VLCs are generated by Huffman encoding the DCT coefficients.
- the complexity and computation required to do all this in real-time is substantial.
- a more realistic alternative is to insert watermarks by replacing sections of the MPEG bitstream with alternate sections of bitstream.
- a watermark can be introduced into a video so that only some sections of the MPEG bitstream for the watermarked video are different from the bitstream for the unwatermarked video. For instance, if one bit of the watermark is represented by modifying the coefficients of a single 8 ⁇ 8 DCT block and the number of bits comprising the watermark is much less than the number of DCT blocks in the video, the watermarked and unwatermarked bitstreams would be the same except for those MPEG picture slices that contain a modified DCT block.
- a section of the watermarked MPEG bitstream that differs from the unwatermarked bitstream will be referred to as a message hole (MH).
- the coefficients of the DCT block would be modified one way to embed a 0 bit into the watermarked bitstream and would be modified some other way to embed a I bit.
- bit value (0 or 1) can be inserted into the message hole by to inserting the appropriate section of bitstream.
- Any desired number of bits, any one of which can be 0 or 1, can be inserted into the watermarked bitstream this way so that a message (e.g., a tracing message containing a user ID) can be hidden in the video. All that is needed is a sufficient number of message holes and the alternative sections of bitstream for each one.
- One of these alternative slices can be encoded with different quantization levels until its size is as near as possible to the size of the other slice without being larger. Bit stuffing is then added to make the two slices exactly the same size. Either slice then can be inserted into the MPEG bitstream without affecting the decoder buffering.
- the burden imposed on the OPIMA terminal can be reduced dramatically if much of the computation associated with watermarking is performed off-line before the MPEG bitstream is transmitted to the terminal. Everything, including watermarking and the adaptive encoding described in the preceding paragraph, can be done off-line except the final replacement of sections of bitstream with alternative sections of bitstream.
- the OPIMA terminal would need only to replace the appropriate sections of bitstream. This approach is simple and inexpensive to implement in the terminal, but requires that all the alternative sections of bitstream be transmitted to the terminal. These sections of bitstream can be transmitted in some auxiliary data stream, such as a private data stream. If the amount of the bitstream that is replaced is small, the overhead is small.
- An advantage of this approach is that future improvements to the watermarking algorithms do not affect the terminal so long as the watermarks can be inserted by replacing sections of bitstream.
- a variation on this technique attempts to reduce the overhead information that needs to be sent, but imposes a greater burden on the OPIMA terminal.
- the quantization level that keeps the same number of bits in a slice is computed off-line before the video is transmitted to the terminal.
- the alternative sections are created by the terminal using the quantization levels that were computed off-line. If needed, other information that describes how the alternative section of bitstream should be created can be computed off-line and sent to the terminal too. While the computational burden placed on the terminal is increased, the overhead associated with transmitting the quantization levels and other information describing how the alternative sections of bitstream are created should be less than the overhead of sending all the alternative sections of bitstream.
- a packetized elementary stream (PES) of MPEG2 is composed by a sequence of PES packets, all of whose payloads consist of data from a single elementary stream, and all of which have the same stream_id [6].
- An elementary stream is a generic term for one of the coded video, coded audio or other coded bit streams.
- the problem of packet searching is to search for a particular packet along the bit stream, given the target packet's information. If each packet is associated with a unique, sequentially labeled packet number in its header, then the packet searching can be as simple as matching the unique packet number directly using a sequential search.
- the packet number may not exist in the header.
- One solution for that is to count the number of packets from the beginning of the stream until the current count matches with the target's packet number, assuming we know the i-th packet is our target. Obviously, this scheme is not robust because any packet loss between the beginning of the stream to the location of the target packet will cause picking up a wrong packet since the count becomes incorrect right after the packet loss.
- Another method to remedy the lack of packet number is to add the packet number into the header such as using the field of private data. The required bits for the packet numbers will increase the overhead.
- the insertion of packet numbers to packets is quite simple if it is performed during or before multiplexing of different MPEG streams to form the PES.
- An alternative method for handling PES without packet number is to match packets using signatures which are composed from some information of packets.
- a signature should be a unique feature for one or more packets that there is no ambiguity in the matching process.
- There are many ways to create a signature Obviously, if there is packet number in a packet, it can be used as a signature for matching. Three other approaches are described in the following.
- the stream-id is an 8-bit field which specifies the type and number of the elementary streams and may take values in the range ‘1011 1100’ to ‘1111 1111’. Since the first bit of stream-id is always ‘1’, only last 7 bits are used for the signature.
- the PTS is a 33-bit number coded in three separate fields. It indicates the intended time of presentation in the system target decoder of the presentation unit that corresponds to the first access unit that commences in the packet. It is used to synchronize the presentation of multiple elementary streams, such as a coded video stream and the corresponding coded auditory streams.
- the searching of target packet can be stopped or reversed if it passes the target signature. Since all packet stream_ids for an elementary stream are the same and different packets of different elementary streams may have the same PTS, a packet can not be specified uniquely by using either stream_id or PTS. However, a combination of stream_id and PTS can distinguish a specific packet.
- a mismatch will happen for using relative relation to specify a packet when there is packet loss between the reference packet and the target packet.
- multiple reference packets can be used for cross-verification so that a mismatch can happen only when a packet loss exists between all reference location and the target location.
- A, B, and C are potential reference packets.
- the target packet can be located using single or multiple reference packets.
- a packet loss before loc(A) or after loc(C) will not cause any mismatch during the search of target t in this example.
- a packet loss between loc(A) and loc(B) will cause a mismatch only if A is chosen as the only reference packet.
- the second approach of creating a signature is to use lower-layer information within compressed stream that is apparently unique and therefore does not cause ambiguity.
- Examples of such lower-layer information are frame number and time code. Though they seem convenient to use, the drawback of using lower-layer information is that the stream has to be decoded to the desired layer in order to extract such lower-layer. The computation is much higher that that for high-layer signatures such as using stream_id and PTS in the packet header.
- the third approach of forming a signature is to use information of multiple packets. For example, a sequence of multiple stream_id's from consecutive packets can form a signature. To search for the target packet based on the group of fields, a string matching algorithm (or elastic matching to cope with packet loss) can be used. The idea is illustrated in FIG. 18 for using five stream_ids. The approach may save some signature overhead. For example, concatenating a 33-bit PTS with a 7-bit stream_id as a signature requires total 40 bits. (The first bit of stream-id is always 1 and therefore it can be skipped.) On the other hand, using five or fewer 7-bit stream_ids only requires 35 or less bits. See FIG. 18
- An open watermark (OWM) stream is a packetized elementary stream which contains the data for replacing the compressed content stream (s) and the processing parameters. Its packets are called OWM_PCKs. They are encoded as a private_stream — 1, i.e. the stream_id equals to “1011 1101b” as described in page 30 of MPEG-2 Part 1 specification. To distinguish other non-watermark applications using private_stream — 1, a sub_stream_id is introduced as the first PES_packet_data_byte and its value for OWM equals to “1111 1111b”.
- a OWM_PCK is stored physically before any content packets which contain message holes to be modified by that OWM_PCK.
- a OWM_PCK consists of a OWM_header, multiple OWM_data and other watermark processing information.
- a OWN_data_ is used for one replacement. Only one message hold is processed for one watermarking.
- the syntax of the OWM_PCK, OWM_data and other watermark stream information are described in tables 16-20.
- the OWM_PCK header provides global information about watermark replacement algorithms and parameters used by all watermarkings within the OWM_PCK.
- the num_OWM_data is the total number watermarks in the OWM_PCK. Each watermark uses one OWM_data.
- bit_index points to the first bit to be sent for this OWM_PCK in the bit array B e which is the input of WM modulator in FIG. 6 .
- the bit_index is used to resynchronize the bit to be sent.
- n r be the number of bits to be sent for a watermarking
- the size of a message hole is determined by the MH_size. If the size of all message holes in the OWM_PCK do not change, the flag MH_size_flag in the OWM_header is set to 0, and only one MH_size exists in the OWM header. Otherwise, each OWM_data contains a MH_size.
- the location of the message hole in a content packet is determined by its packet location and the MH_location_offset. As described earlier, the packet location is specified by either absolute location or relative location.
- the MH_location_offset specifies the number of bytes between the message hold and the first byte after the PES_packet_length field.
- the first OWM_data and the next_OWM_data_offset are used to jump directly to the first and next OWM_data in a OWM_PCK respectively. They are the offsets in bytes from the first byte after the PES_packet_length field to that OWM_data. For the last OWM_data, next_OWM_data_offset is set to zeo. Future data can be put at the end of each OWM_data. To have a better implementation for run-time processing of watermarking, a few columns of CDMA waveform table may be stored inside the OWM_header. It also provides a way to support more flexible CDMA coding since the CDMA waveforms can be changed for different OWM_PCKs. The flag CDMA_columns_flag controls whether or not there are CDMA columns.
- bit_index It points to the first bit to be sent for this OWN_PCK in the bit array Be which is the input of OWM modulator 1 of FIG. 6 .
- num_OWM_data Number of WMs in this OWN_PCK.
- n r Number of sending bits for a replacement.
- first_replacement_in_MH_flag If the first replacement is put in the MH of compressed content stream, this flag equals to 1. Otherwise, this flag equals to zero and all replacements are put in the OWM_data.
- N_Bits_packet_location_offset Number of bits for the parameter packet_location_offset.
- NBits_MH_location_offset Number of bits for the parameter MH_location_offset.
- NBits_bit_index_incr Number of bits for the parameter bit_index_incr.
- first_OWM_data_offset Offset in bytes from the beginning of a OWM_PCK to the first OWM_data.
- MH_size_flag If the size of message holes within this OWM_PCK may be different, then this flag equals to 1 and there are MH_size data in the OWM_data. Otherwise, this flag equals to 0 and MH_size data is followed.
- CDMA_columns_flag If the CDMA columns are sent for CDMA process of WM bits in this OWM_PCK, this flag equals to 1 and CDMA data are followed.
- num_CDMA_columns Number of CDMA columns.
- CDMA_column_incr The increment of column number respect to a reference column in CDMA table which is calculated from bit_index.
- CDMA_column_data The CDMA column data.
- Void simple_replacement_method(u6 Mode) ⁇ u16 sendbit 0; locate MH bits of Message Hole using SectorNum and Offset; switch(Mode) ⁇ case 0: /* Replace MH bits with b[0] */ replace MH bits with b[0]; break; case 1: /* Replace MH bits with b[sendbit ⁇ 1] */ extract n r bits from Be[ ] pointed by bit_index and store them to sendbit as in figure 6.5; if( first_replacement_in_MH) ⁇ if(0 ⁇ sendbit) replace MH bits with b[sendbit ⁇ 1]; ⁇ else ⁇ replace MH bits with b[sendbit]; ⁇ break; case 2: /* Replace MH bits with b[reverse(sendbit) ⁇ 1] */ extract n r bits from Be[ ] pointed by bit_index and store them to sendbit as in figure 6.5; reverse each one of n r least significant bits
Abstract
Description
v i,j ,i=0,1,2,K,I−1, j=0,1,2,K,J−1
TABLE 1 |
Watermark Insertion Methods |
Insertion | Insertion | ||
Method | Function | ||
replace | r0(v, x) = x | ||
add | r1(v, x) = v + αA · x | ||
product | r2(v, x) = v · (1 + αP · x) | ||
exponential | r3(v, x) = v · exp(αE · x) | ||
-
- Build a collection of marks stored in the terminal. Each mark can be transmitted to the terminal in the body of a message or a message can instruct the terminal to construct the mark using a given algorithm and parameters.
- Insert the marks into the video to represent the bits comprising the watermark.
- Replace or delete marks from the collection, if needed.
TABLE 2 |
Spatial Video Mark Syntax |
No. of | |||
Syntax | Bits | Mnemonic | |
SpatialVidMark( ) { | |||
class_id | TBD | bslbf | |
method | TBD | bslbf | |
obj_id | TBD | uimsbf | |
if (method == constructRandom) { | |||
VidMarklnsertType( ) | |||
x_size | 11 | uimsbf | |
y_size | 11 | uimsbf | |
PseudoRandomGeneratorRef( ) | |||
} else if (method == constructMatrix) { | |||
VidMarkInsertType( ) | |||
SpatialVidMarkPic( ) | |||
} else if (method == destroy) { | |||
} else if (method == insert) { | |||
PictureRef( ) | |||
X | 11 | uimsbf | |
Y | 11 | uimsbf | |
} | |||
} | |||
SpatialVidMarkRef( ) { | |||
class_id | TBD | bslbf | |
obj_id | TBD | bslbf | |
} | |||
class_id: A constant bit string (TBD) which identifies the object as belonging to the SpatialVidMark( ) class.
method: A code that indicates the action (method) to be performed.
obj_id: A value which uniquely identifies an object in the SpatialVidMark( ) class. VidMarkinsertType( ): The insertion method type, which specifies how the mark should be inserted into the video (see Table 13).
x_size: The horizontal dimension of the mark (N).
y_size: The vertical dimension of the mark (M).
PseudoRandomGeneratorRef( ): The pseudo-random number generator to be used to generate the mark (see Table 12).
SpatialVidMarkPic( ): The mark, represented as a small rectangular matrix (image). See Table 3.
PictureRef( ): Specifies which picture (video frame) the mark should be inserted into. x, y: The x, y coordinates, in the picture, where the top left corner of the mark is inserted (i0, j0).
TABLE 3 |
Spatial Video Mark Picture Syntax |
No. of | |||
Syntax | Bits | Mnemonic | |
SpatialVidMarkPic( ) { | |||
x_size | 11 | uimsbf | |
y_size | 11 | uimsbf | |
pel_width | TBD | uimsbf | |
for (j = 0; j < y_size; j++) { | |||
for (i = 0; i < x_size; i++) { | |||
pel | pel_width | tcimsbf | |
} | |||
} | |||
} | |||
x_size: the horizontal dimension of the mark (N).
y_size: The vertical dimension of the mark (M).
pel_width: The value of this integer equals the number of bits used to represent each element of the matrix.
pel: A signed integer value representing one of the elements of the matrix.
TABLE 4 |
Spatial Video Bit Inserter Syntax |
No. of | ||
Syntax | Bits | Mnemonic |
SpatialVidBitInserter( ) { | ||
class_id | TBD | bslbf |
method | TBD | bslbf |
obj_id | TBD | uimsbf |
if (method == construct) { | ||
BitSourceRef( ) | ||
PictureRef( ) | ||
X | 11 | uimsbf |
Y | 11 | uimsbf |
no_zero_mark | 1 | uimsbf |
num_bits | TBD | uimsbf |
for (i = 0; i < ((1<<num_bits) − no_zero); i++) { | ||
SpatialVidMaricRef( ) | ||
} | ||
} else if (method == destroy) { | ||
} else if (method == insert) { | ||
} | ||
} | ||
class_id: A constant bit string (TBD) which identifies the object as belonging to the Spatial VidBitInserter( ) class.
method: A code that indicates the action (method) to be performed.
obj_id: A value which uniquely identifies an object in the SpatialVidBitInserter( ) class.
BitSourceRef( ): Specifies a bit string source (Be) that controls which mark gets inserted.
PictureRef( ): Specifies which picture (video frame) the mark should be inserted into (see Table 11).
x, y: The x, y coordinates, in the picture, where the top left corner of the mark is located (i0, j0).
no_zero_mark: If no_zero_mark=0, there is one mark for each possible value of the bit or group of bits and the number of mark references is 2num
num_bits: The value of num_bits equals the number of bits represented by this collection of marks (K). For instance, num_bits=1, if 1 bit is represented, num_bits=2 for 2 bits, and num_bits=3 for 3 bits.
SpatialVidMarkRef( ): A reference to a mark (see Table 2).
TABLE 5 | ||
Example Watermarking Session | ||
/* Construct a normally distributed pseudo-random number generator object. */ | ||
PseudoRandomNumberGenerator() { | ||
class_id = PseudoRandomNumberGenerator, method = constructNormal, obj_id = 1 | ||
seed = 777, mean = 0, std_dey = 4 | ||
} | ||
/* Construct the first mark . */ | ||
SpatialVidMark( ) { | ||
class_id = SpatialVidMark, method = constructRandom, obj_id = 1 | ||
VidMarklnsertType( ) { insert_type = add, amplitude = 1 } | ||
x_size = 32, y_size = 12 | ||
PseudoRandomNumberGeneratorRef( ) { class_id = PseudoRandomNumberGenerator, | ||
obj_id = 1 } | ||
} | ||
/* Construct the second mark. */ | ||
SpatialVidMark( ) { | ||
class_id = SpatialVidMark, method = constructRandom, obj_id = 2 | ||
VidMarklnsertType( ) { insert_type = add, amplitude = 1 }, | ||
x_size = 32, y_size = 12 | ||
PseudoRandomNumberGeneratorRef( ) { class_id = PseudoRandomNumberGenerator, | ||
obj_id = 1 } | ||
} | ||
/* Construct a bit inserter (a list of the 2 marks). */ | ||
SpatialVidBitInserter( ) { | ||
class_id = SpatialVidBitInserter, method = construct, obj_id = 1 | ||
BitSourceRef( ) { TBD } | ||
PictureRef( ) { TBD } | ||
x = 382, y = 186 | ||
no_zero = 0, num_bits = 0 | ||
SpatialVidMarkRef( ) { class_id = SpatialVidMark, obj_id = 1 } | ||
SpatialVidMarkRef( ) { class_id = SpatialVidMark, obj_id = 2 } | ||
} | ||
/* Insert the appropriate mark, depending of the bit value. */ | ||
SpatialVidBitlnserter( ) { | ||
class_id = SpatialVidBitlnserter, method = insert, obj_id = 1 | ||
} | ||
/* Destroy the bit inserter. */ | ||
SpatialVidBitlnserter( ) { | ||
class_id = SpatialVidBitInserter, method = destroy, obj_id = 1 | ||
}. | ||
/* Destroy the second mark. */ | ||
SpatialVidMark( ) { | ||
class_id = SpatialVidMark, method = destroy, obj_id = 2 | ||
{ | ||
/* Destroy the first mark. */ | ||
SpatialVidMark( ) { | ||
class_id = SpatialVidMark, method = destroy, obj_id = 1 | ||
} | ||
/* Destroy the pseudo-random number generator. */ | ||
PseudoRandomNumberGenerator( ) | ||
class_id = PseudoRandomNumberGenerator, method = destroy, obj_id = 1 | ||
} | ||
v i,j , i=0,1,2,K,I−1, j=0,1,2,K,J−1
v′ s
-
- int v_prime [I] [J], int v[I] [J], int x[M], int s[M], int t [M]
-
- int rl(int, int);
- int m;
- for (m=0; m<M; m++) {v_prime [s[m]] [t[m]]=rl(v[s[m]] [t[m]] x[m]);
- }
v′ i,j =v i,j, if (i,j) ∉{(s m t m):m=0,1,2,K,M−1}.
where bi is the bit (e.g., the ith bit Be) and xm 0 and xm 1 are the marks associated with a bit value of 0 and 1, respectively. xm 0 and xm 1 are vectors that are the same size as xm. As in the spatial domain case, if a watermark represents 2 bits, bi and bi+1, four marks xm,n 0, xm,n 1, xm,n 2, and xm,n 3 are used to denote the four possible values of 2 bits: 00, 01, 10, and 11. To represent three bits with one watermark requires eight marks. Extending these examples to an arbitrary number of bits, K, would require 2K marks: xm k, k=0, 1, 2, K, 2K−1. An alternative is to use the absence of a mark to represent the case where all the bits are 0. This alternative is the same as the first mark being equal to 0(xm 0=0, m=0, 1, 2, hK, M−1).
-
- Build a collection of transform domain marks in the terminal. A mark can be sent to the terminal in a message or the terminal can construct the mark using an algorithm and parameters specified by a message.
- Compute the transform of a section of a picture (frame).
- Insert the mark into the transform coefficients.
- Perform the inverse transform and put the resulting section of a frame back into the original picture.
- Replace or delete marks from the collection as necessary.
TABLE 6 |
Transform Domain Video Mark Syntax |
No. of | ||||
Syntax | Bits | Mnemonic | ||
TransformVidMark( ) { | ||||
class_id | TBD | bslbf | ||
method | TBD | bslbf | ||
obj_id | TBD | uimsbf | ||
if (method == constructRandom) { | ||||
transform_type | TBD | bslbf | ||
VidMarklnsertType( ) | ||||
num _coeffs | TBD | uimsbf | ||
PseudoRandomGeneratorRef( ) | ||||
} else if (method == constructArray) { | ||||
transform_type | TBD | bslbf | ||
VidMarklnsertType( ) | ||||
num_coeffs | TBD | uimsbf | ||
for (i = 0; i < num_coeffs; i++) { | ||||
TransformCoeff(transform_type) | ||||
} | ||||
} else if (method == destroy) { | ||||
} else if (method == insert) { | ||||
VidTransformRef( ) | ||||
ScanPatternRef( ) | ||||
} | ||||
} | ||||
TransformVidMarkRef( ) { | ||||
class_id | TBD | bslbf | ||
obj_id | TBD | uimsbf | ||
} | ||||
TransformCoeff(transform_type) { | ||||
if (transform_type == dct) { | ||||
dct_coeff | TBD | tcimsbf | ||
} else if (transform_type == fft) { | ||||
real_fft_coeff | TBD | TBD | ||
imag_fft_coeff | TBD | TBD | ||
} else if (transform_type == wavelet) { | ||||
TBD | TBD | TBD | ||
} | ||||
} | ||||
class_id: A constant bit string (TBD) which identifies the object as belonging to the TransformVidMark( ) class.
method: A code that indicates the action (method) to be performed. θobj_id: A value which uniquely identifies an object in the TransformVidMark( ) class.
transform_type: A bit string that indicates the type of transform (e.g., DCT, FFT, or wavelet).
VidMarkInsertType( ): The insertion method type (rl), which specifies how the mark should be inserted into the previously computed transform (see Table 13).
num_coeffs: This value equals the number of transform coefficients contained in the array (M)
PseudoRandomGeneratorRef( ): The pseudo-random number generator to be used to generate the mark (see Table 12).
TransformCoeff(transform_type): A transform coefficient value for the given type of transform (xm k).
TABLE 7 |
Transform Domain Video Bit Inserter Syntax |
No. of | ||
Syntax | Bits | Mnemonic |
TransformVidB itInserter( ) { | ||
class id | TBD | bslbf |
method | TBD | bslbf |
obj_id | TBD | uimsbf |
if (method == construct) { | ||
BitSourceRef( ) | ||
PictureRef( ) | ||
X | 11 | uimsbf |
Y | 11 | uimsbf |
VidTransformRef( ) | ||
no_zero | 1 | bslbf |
num_bits | TBD | uimsbf |
for (i = 0; i < ((1<<num_bits) − no_zero); i++) { | ||
ScanPatternRef( ) | ||
TransforrnVidMarkRef( ) | ||
} | ||
} else if (method == destroy) { | ||
} else if (method == insert) { | ||
} | ||
} | ||
class_id: A constant bit string (TBD) which identifies the object as belonging to the TransformVidBitInserter( ) class.
method: A code that indicates the action (method) to be performed.
obj_id: A value which uniquely identifies an object in the Spatial VidBitInserter( ) class.
BitSourceRef( ): Specifies a bit string source to be used to control which mark gets inserted.
PictureRef( ): Specifies which picture (video frame) the mark should be inserted into (see Table 11).
x, y: The x, y coordinates, in the picture, where the top left corner of the mark is located.
no_zero_mark: If no_zero_mark=0, there is one mark for each possible value of the bit or group of bits and the number of mark references is 2num
num_bits: The value of num_bits equals the number of bits represented by this collection of marks (K). For instance, num_bits=1, if 1 bit is represented, num_bits=2 for 2 bits, and num_bits=3 for 3 bits.
ScanPatternRef( ): A reference to the scanning pattern or list of locations, (sm,tm), as defined in Table 8, that determines which of the previously computed transform coefficients is modified by insertion.
TransformVidMarkRef( ): A reference to a mark (see Table 6).
TABLE 8 |
Transform Scan Pattern Syntax |
No. of | ||
Syntax | Bits | Mnemonic |
ScanPattem( ) { | ||
class_id | TBD | bslbf |
method | TBD | bslbf |
obj_id | TBD | uimsbf |
if (method == constructZigZag || method == | ||
constructRectangle) { | ||
corner1_u | 11 | uimsbf |
corner1_v | 11 | uimsbf |
comer2_u | 11 | uimsbf |
comer2_v | 11 | uimsbf |
horizontal | TBD | bslbf |
} else if (method == constructLocations) { | ||
num_locs | TBD | uimsbf |
for (i = 0; i < num_locs; i++) { | ||
u | 11 | uimsbf |
v | 11 | uimsbf |
} | ||
} else if (method == constructChain) { | ||
begin_u | 11 | uimsbf |
begin_v | 11 | uimsbf |
num_steps | TBD | uimsbf |
for (i =0; i < num_steps; i++) { | ||
step_dir | TBD | bsibf |
} | ||
} else if (method == destroy) { | ||
} | ||
} | ||
ScanPatternRef( ) { | ||
class_id | TBD | bslbf |
obj_id | TBD | uimsbf |
} | ||
class_id: A constant bit string (TBD) which identifies the object as belonging to the ScanPattern( ) class.
method: A code that indicates the action (method) to be performed.
obj_id: A value which uniquely identifies an object in the ScanPattern( ) class.
corner1_u, corner1_v: For a zigzag or rectangular scan, the row and column of the first scanned coefficient in the matrix of transform coefficients.
corner2_u, corner2_v: The row and column of the last scanned coefficient. horizontal: A bit flag that specifies if the first step in a zigzag or rectangular scan is horizontal or vertical.
num_locs: The number of locations in the list (M).
u, v: A row and column coordinate pair (sm, tm).
begin_u, begin_v: The starting row and column of the first scanned coefficient of a chain coded scan.
TABLE 9 |
Video Transform Syntax |
No. of |
Syntax | Bits | Mnemonic | ||
VidTransform( ) { | ||||
class_id | TBD | bslbf | ||
method | TBD | bslbf | ||
obj_id | TBD | uimsbf | ||
if (method == construct) { | ||||
transform_type | TBD | bslbf | ||
PictureRef( ) | ||||
begin_x | 11 | uimsbf | ||
begin_y | 11 | uimsbf | ||
end_x | 11 | uimsbf | ||
end_y | 11 | uimsbf | ||
} else if (method == destroy) { | ||||
} | ||||
} | ||||
VidTransformRef( ) { | ||||
class_id | TBD | bslbf | ||
obj_id | TBD | uimsbf | ||
} | ||||
class_id: A constant on string (TBD) which identifies the object as belonging to the VidTransform( ) class.
method: A code that indicates the action (method) to be performed.
obj_id: A value which uniquely identifies an object in the VidTransform( ) class.
transform_type: A bit string that indicates the type of transform (e.g., DCT, FFT, or wavelet).
PictureRef( ): A rectangular region of pixels in this picture (video frame) is the data source (input) for the transform.
begin_x, begin_y: The x, y coordinates of the top left corner of the rectangular region.
end x, end v: The x, y coordinates of the bottom right corner of the rectangular region.
TABLE 10 |
Registration Syntax |
No. of | ||||
Syntax | Bits | Mnemonic | ||
Registration( ) { | ||||
class_id | TBD | bslbf | ||
method | TBD | bslbf | ||
if (method == registerClass) { | ||||
new_class_id | IBD | bslbf | ||
} else if (method == registerMethod) { | ||||
existing_class_id | TBD | bslbf | ||
} | ||||
num_methods | TBD | uimsbf | ||
for (i = 0; i < num methods; i++) { | ||||
method_code | TBD | bslbf | ||
MethodRef( ) | ||||
} | ||||
} | ||||
class_id: A constant bit string (TBD) which identifies the object as belonging to the Registration( ) class. There is only one such object, so no obj_id value is needed.
method: A code that indicates the action (method) to be performed.
new_class_id: The class_id value for the new class that is being registered.
existing_class_id: The class_id value of an existing class for which a new method is being registered.
num_methods: The number of new methods being registered.
method_code: The method value for each new method that is being registered.
MethodRef( ): A reference to a method that has previously been downloaded to the terminal.
TABLE 11 |
Picture Reference Syntax |
No. of | ||||
Syntax | Bits | Mnemonic | ||
PictureRef( ) { | ||||
video_stream_id | 8 | uimsbf | ||
pts | 33 | uimsbf | ||
picture_offset | TBD | uimsbf | ||
} | ||||
video_stream_id: The video stream ID value, which identifies the referenced video stream.
pts: A presentation time stamp (PTS) within the specified video stream. The PTS specifies a particular presentation unit within the video stream.
picture_offset: The number of pictures (frames) beyond the first picture in the presentation unit specified by the PTS value.
| |||
Value | Probability | ||
0 | 0.50 | ||
1 | 0.50 | ||
TABLE 12 |
Pseudo-Random Number Generator Syntax |
No. of | ||||
Syntax | Bits | Mnemonic | ||
PseudoRandomGenerator( ) { | ||||
class_id | TBD | bslbf | ||
method | TBD | bslbf | ||
obj_id | TBD | uimsbf | ||
if (method == constructUniform) { | ||||
seed | TBD | uimsbf | ||
lower_bound | TBD | tcimsbf | ||
upper_bound | TBD | tcimsbf | ||
} else if (method == constructNormal) { | ||||
seed | TBD | uimsbf | ||
mean | TBD | tcimsbf | ||
std_dev | TBD | tcimsbf | ||
} else if (method == constructDiscrete) { | ||||
num_values | TBD | uimsbf | ||
for (i = 0; i < num_values; i++) { | ||||
discrete | TBD | tcimsbf | ||
prob | 16 | uimsbf | ||
} | ||||
} else if (method == destroy) { | ||||
} else if (method == setSeed) { | ||||
seed | TBD | uimsbf | ||
} | ||||
} | ||||
PseudoRandomGeneratorRef( ) { | ||||
class_id | ||||
obj_id | TBD | bslbf | ||
} | TBD | uimsbf | ||
seed: The pseudo-random number generator seed. If the specified seed value is TBD, the terminal should compute and use a seed value such that the seed is different each time this option is invoked (e.g., by computing it from the system clock).
lower bound: The lower bound of the range of values that may be returned by the uniformly distributed pseudo-random number generator.
upper_bound: The upper bound of the range of values that may be returned by the generator.
mean: The mean of the normally distributed pseudo-random number generator.
std_dev: A value representing the standard deviation of the generator.
num_values: The number of discrete values that may be returned by the pseudo-random number generator
discrete: One of the discrete values that may be returned by the generator.
prob: The probability of the generator returning the corresponding discrete value, expressed as the numerator of a fraction with a denominator of 216=65536. For example, if prob=16384, the probability is 16384/65536=0.25. The sum of all the values of prob must equal 65536 (a probability of 1).
TABLE 13 |
Video Mark Insertion Type Syntax |
No. of | ||||
Syntax | Bits | Mnemonic | ||
VidMarkInsertType( ) { | ||||
| 2 | bslbf | ||
if (insert_type == replace) { | ||||
} else if (insert_type == add) { | ||||
amplitude | TBD | uimsbf | ||
} else if (insert_type == product) { | ||||
proportion | TBD | uimsbf | ||
} else if (insert_type == exponential) { | ||||
exponent | TBD | TBD | ||
} | ||||
} | ||||
insert_type: A bit string which indicates the mark insertion method (see Table 14).
amplitude: A value which corresponds to αA that controls the strength of a mark which is added to the video.
proportion: A value which corresponds to αp that controls the strength of a mark which is multiplied with the video.
exponent: A value which corresponds to αE that controls the strength of a mark which is exponentially weighted and multiplied with the video.
TABLE 14 |
Video Mark Insertion Methods |
Bit | Insertion | |||
insert_type | String | Method | ||
replace | TBD | vi′ = xi | ||
add | TBD | vi′ = vi + α4 · x1 | ||
product | TBD | vi′ = vi · (1 + αP · xi) | ||
exponential | TBD | vi′ = vi · exp(αE · xi) | ||
v′i: The marked video signal.
xi: The mark.
vi: The original (unmarked) video signal.
αA, αP, αE: Parameters that control the strength of marks that are inserted by addition, multiplication, and exponentiation, respectively.
x′=ƒ x(Θ,x,y)
y′=ƒ y(Θ,x,y)
x′=ƒ x(Θ,x,y,t)
y′=ƒ y(Θ,x,y,t)
t′=ƒ t(Θ,x,y,t)
A simple example of ƒi is frame-dropping or frame-repeating. In general, although the idea of 3D warping is very appealing and more general, for practical reasons, it is more difficult to apply since a large frame buffer is required to store the whole volume of the video and the computation cost is usually high. Another approach that we shall focus on is to apply a sequence of 2D geometric transformations to the sequence of image frames, while allowing the parameter set of the warping function to be a function of time.
x′(t)=ƒx(Θ(t),x(t),y(t))
y′(t)=ƒy(Θ(t),x(t),y(t))
In this representation, the warping function remains a 2D geometric transformation at fixed time instant, while at different time both the function form and the parameters can be changed. In the following sections, we will first introduce a collection of 2D geometric transformations. Then we will discuss different function forms for achieving temporal warping, i.e., Θ(t).
TABLE 15 |
A collection of geometric transformations for anti-tamper warping. |
Category | Method | # Parameters | Parameter set Θ |
Linear | Translation | 2 | tγ, tv |
Rotation | 3 | θ, x0, y0 | |
Scaling | 4 | sx, sv, x0, y0 | |
Affine | 6 | ax′x, ax′1, ax′x, ar′t, av′ | |
Quadratic | Bilinear | 8 | ax′x, ax′x, av′1, av′, 1v′r, av′r, av′v, av′ |
Pseudo- | 8 | ax′x, ax′x, ax′, ax′x, 1v′v, av′, aa, aβ | |
perspective | |||
Biquadratic | 12 | ax′x, ax′x, ax′x, ax′x, a1′1, 1v′v, av′n, ay′x, ay′v, ay′ | |
Higher- | P(n) | 2(n + 1) | 2(n + 1) interpolation points |
order | |||
Polynomial | |||
Rational | R(n,m) | 2(n + m + 2) | 2(n + m + 2) interpolation points |
Projective | 8 | ax′x, ar′1, a1, 1r, a1′1, a1′, aa, aβ | |
Spline | Cubic | 4 or | 4 control points + other parameters |
Spline | more/ |
Motion | Fourier |
2 · |U| · |V| | Mx(u, v), Mi(u,v) | u ∈ U,v ∈ | ||
Transform | Wavelet | |||
2 · Σi|Ui| · |Vi| | Mx1(u, v), Mi(u,v) | ul ∈ Ul, vl ∈ Vl | ||
LUT | 1-D | M + N | x → x′, y → y′ | x = 1 . . . M; y = 1 . . . N |
2- |
2 MN | (x, y) → x′, (x, y) → y′ | x = 1 . . . M; y = 1 . . . N | |
x′=x+t x
y′=y+t y
x′=(x−x 0)cos(θ)−(y−y 0)sin(θ)+x 0
y′=(x−x 0)sin(θ)+(y−y 0)cos(θ)+y 0
rotation center (x0,y0) and the ratation angle θ.
x′=s x(x−x 0)+x 0
y′=s y(y−y 0)+y 0
x′=x+t x
y′=y+t y
x′=a x′x
y′=a y′x
x′=x+m x(x,y)
y′=y+m x(x,y)
where l is the index for the resolution level, l=−1,0, . . . , L−1. Note that the basis functions included at each level may vary therefore u and v become a function of I.
B −1(x,y,u −1 ,v −1)=φ(x−u −1)φ(y−v −1)
B l H(x,y,u l ,v l)=φ(2 l x−u l)φ(2 l y−v l)
B l V(x,y,u l ,v l)=φ(2 l x−u l)φ(2 l y−v l)
B l D(x,y,u l ,v l)=φ(2 l x−u l)φ(2 l y−v l)
One example of wavelets is the Cai-Wang wavelet [13,14], in which where for any real number n
and
Θ(t)=ƒt(Θ0 ,t)
Θt(t)=Θt(t 0)+A·sin(w(t−t 0))
(x′,y′)=ƒ1(ƒ2( . . . ƒv(x,y)))∀x,y
∀(x,y)εΩl
each partition. Therefore,
(x′,y′)=ƒ(x,y)
bit_index=bit_index+bit_index_incr.
TABLE 16 | ||
No. of | ||
Syntax | bits | Mnemonic |
OWM_PCK( ) { | ||
packet_start_code_prefix | 24 | bslbf |
stream_id | 8 | uimsbf |
PES_packet_length | 16 | uimsbf |
sub_stream_id | 8 | uimsbf |
if (sub_stream_id == ‘1111 1111’) { | ||
new_OWM_system_header_flag | ||
if ( new_OWM_system_header_flag == 1 ) | ||
OWM_system_header ( ) | ||
OWM_header ( ); | ||
for ( i = 0; i < num_OWM_data; i++) | ||
OWM_data ( ) | ||
} | ||
} | ||
TABLE 17 | ||||
No. of | ||||
Syntax | bits | Mnemonic | ||
OWM_system_header( ){ | ||||
TBD | ||||
} | ||||
TABLE 18 | ||
No. of | ||
Syntax | bits | Mnemonic |
OWM_header( ){ | ||
bit_index | ||
num_OWM_data | ||
nr | ||
first_replacement_in_MH_flag | ||
NBits_packet_location_offset | ||
NBits_MH_location_offset | ||
NBits_bit_index_incr | ||
first_OWM_data_offset | ||
MH_size_flag | ||
if (MH_size_flag == 0) | ||
MH_size | ||
MH_replacement_method ( ) | ||
CDMA_columns_flag | ||
if ( CDMA_columns_flag == 1 ){ | ||
num_CDMA_columns | ||
for ( i = 0; i < num_CDMA_columns; i++) { | ||
CDMA_column_incr | ||
for ( j = 0; j < NRows CDMA; j++) | ||
CDMA_column_data | ||
} | ||
} | ||
} | ||
TABLE 19 | ||||
No. of | ||||
Syntax | bits | Mnemonic | ||
OWM_data( ){ | ||||
next_OWM_data_offset | ||||
if (MH_size_flag ==1) | ||||
MH_size | ||||
absolute_packet_location_flag | ||||
if (absolute_packet_location_flag ==1 ) | ||||
absolute_packet_location ( ) | ||||
else | ||||
packet_location_offset | ||||
MH_location_offset | ||||
bit_index_incr NBits_bit_index_incr | ||||
tcimsbf | ||||
for ( i = 0; i < num_replacements; i++){ | ||||
for ( j = 0; j < MH_size; j++) | ||||
replacement_bits[i][j] | 8 | bslbf | ||
} | ||||
} | ||||
TABLE 20 | ||
No. of | ||
Syntax | bits | Mnemonic |
absolute_packet_location ( ){ | ||
if ( packet_type == MPEG2_PES) { | ||
stream_id[6..0] | 8 | bslbf |
PTS [32..0] | 33 | bslbf |
} else if (packet_type == have_packet_numbers) { | ||
packet_num | 32 | bslbf |
} | ||
} | ||
new_OWM_system_header_flag: If new_OWM_system_header_flag=1, new_OWM_system_header is followed for updating OWN system parameters.
bit_index: It points to the first bit to be sent for this OWN_PCK in the bit array Be which is the input of
num_OWM_data: Number of WMs in this OWN_PCK.
nr: Number of sending bits for a replacement.
first_replacement_in_MH_flag: If the first replacement is put in the MH of compressed content stream, this flag equals to 1. Otherwise, this flag equals to zero and all replacements are put in the OWM_data.
N_Bits_packet_location_offset: Number of bits for the parameter packet_location_offset.
NBits_MH_location_offset: Number of bits for the parameter MH_location_offset.
NBits_bit_index_incr: Number of bits for the parameter bit_index_incr.
first_OWM_data_offset: Offset in bytes from the beginning of a OWM_PCK to the first OWM_data.
MH_size_flag: If the size of message holes within this OWM_PCK may be different, then this flag equals to 1 and there are MH_size data in the OWM_data. Otherwise, this flag equals to 0 and MH_size data is followed.
MH_replacement_method ( ): Different methods for replacing MH bits in MHs of this OWM_PCK.
CDMA_columns_flag: If the CDMA columns are sent for CDMA process of WM bits in this OWM_PCK, this flag equals to 1 and CDMA data are followed.
num_CDMA_columns: Number of CDMA columns.
CDMA_column_incr: The increment of column number respect to a reference column in CDMA table which is calculated from bit_index.
CDMA_column_data: The CDMA column data.
Void simple_replacement_method(u6 Mode){ |
u16 sendbit =0; |
locate MH bits of Message Hole using SectorNum and Offset; |
switch(Mode) { |
case 0: /* Replace MH bits with b[0] */ |
replace MH bits with b[0]; |
break; |
case 1: /* Replace MH bits with b[sendbit−1] */ |
extract nr bits from Be[ ] pointed by bit_index and store them to |
sendbit as in |
figure 6.5; |
if( first_replacement_in_MH) { |
if(0< sendbit) |
replace MH bits with b[sendbit−1]; |
} else { |
replace MH bits with b[sendbit]; |
} |
break; |
case 2: /* Replace MH bits with b[reverse(sendbit) −1] */ |
extract nr bits from Be[ ] pointed by bit_index and store them to |
sendbit as in |
figure 6.5; |
reverse each one of nr least significant bits of sendbit; |
if( first_replacement_in_MH) { |
if(0< sendbit) |
replace MH bits with b[sendbit−1]; |
} else { |
replace MH bits with b[sendbit]; |
} |
break; |
case OtherVersions: |
break; |
} |
} A simple replacement method for a watermarking. |
- 1. I. J. Cox, J. Kilian, T. Leighton, and T. Shamoon, “A secure, robust watermark for multimedia,” in Proc. Workshop on Information Hiding, Cambridge Univ., U.K., May 30-Jun. 1, 1996, pp. 185-206.
- 2. B. Schneier, Applied Cryptography, 2nd ed., New York: John Wiley & Sons, 1996.
- 3. F. Hartung and B. Girod, “Digital Watermarking of MPEG-2 coded video in the bitstream domain,” in Proc. ICASSP-97, Munich, Germany, Apr. 21-24, 1997.
- 4. F. Hartung and B. Girod, “Digital Watermarking of raw and compressed video,” Systems for Video Communication, pp. 205-213, October 1996.
- 5. M. D. Swanson, B. Zhu, and A. H. Tewfik, “Multiresolution scene-based video watermarking using perceptual models,” IEEE J. Select. Areas Commun., vol. 16, no. 4, pp. 540-550, May 1998.
- 6. ISO/IEC 13818-2, “Information technology—Generic coding of moving pictures and associated audio information—Part 2: Video,” 1995.
- 7. J. Lubin, “A visual discrimination model for imaging system design and evaluation,” David Sarnoff Research Center.
- 8. B. Girod, “The information theoretical significance of spatial and temporal masking in video signals,” Human Vision, Visual Processing, and Digital Display, SPIE, vol. 1077, 1989.
- 9. A. B. Watson, “DCT quantization matrices visually optimized for individual images,” NASA Ames Research Center.
- 10. C. I. Podilchuk and W. Zeng, “Image-adaptive watermarking using visual models,” IEEE J. Select. Areas Commun., vol. 16, no. 4, pp. 525-539, May 1998.
- 11. A. Ahumada and H. Peterson, “Luminance-model-based DCT quantization for color image compression,” in Human Vision, Visual Processing, and Digital Display, SPIE, 1992.
- 12. J. D. Foley, A. Van Dam, S. K. Feiner, and J. F. Hughes. Computer Graphics: Principles and Practice, 2nd Ed., Reading, Ma.: Addison-Wesley, 1990.
- 13. W. Cai and J. Wang, “Adaptive multiresolution collocation methods for initial boundary value problems of nonlinear PDEs,” SIAM J. Numer. Anal., vol. 33, no. 3, pp. 937-970, June 1996.
- 14. Y.-T. Wu. Image Registration Using Wavelet-Based Motion Model and Its Applications. Ph.D. thesis, University of Pittsburgh, 1997.
- 15. M. Vetterli and J. Kovacevic. Wavelet and Subband Coding, Englewood Cliffs, N.J.: Prentice Hall, 1995.
- 16. S. B. Wicker, Error Control Systems for Digital Communication and Storage, Englewood Cliffs, N.J.: Prentice Hall, N.J. 07458, 1995.
- 17. M. K. Simon, J. K. Omura, R. A. Scholtz, and B. K. Levitt, Spread Spectrum Communications Handbook, revised edition, McGraw-Hill, Inc., 1994.
Claims (28)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/763,917 US8538886B1 (en) | 1998-08-31 | 1999-08-31 | Watermarking system and methodology for digital multimedia content |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US9868798P | 1998-08-31 | 1998-08-31 | |
PCT/US1999/019723 WO2000013136A1 (en) | 1998-08-31 | 1999-08-31 | Watermarking system and methodology for digital multimedia content |
US09/763,917 US8538886B1 (en) | 1998-08-31 | 1999-08-31 | Watermarking system and methodology for digital multimedia content |
Publications (1)
Publication Number | Publication Date |
---|---|
US8538886B1 true US8538886B1 (en) | 2013-09-17 |
Family
ID=22270476
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/763,917 Expired - Lifetime US8538886B1 (en) | 1998-08-31 | 1999-08-31 | Watermarking system and methodology for digital multimedia content |
Country Status (3)
Country | Link |
---|---|
US (1) | US8538886B1 (en) |
AU (1) | AU6131899A (en) |
WO (1) | WO2000013136A1 (en) |
Cited By (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120174232A1 (en) * | 2011-01-04 | 2012-07-05 | Dharawat Parikshit H | Mechanism for embedding device identification information into graphical user interface objects |
US20140098699A1 (en) * | 2011-05-17 | 2014-04-10 | Zte Corporation | Method and system for measuring frame loss ratio |
US20140177953A1 (en) * | 2012-12-21 | 2014-06-26 | Samsung Electronics Co., Ltd. | Method and apparatus for embedding message into image data |
US20150138405A1 (en) * | 2013-11-15 | 2015-05-21 | Linear Algebra Technologies Limited | Apparatus, systems, and methods for removing noise from an image |
US20150350595A1 (en) * | 2014-05-30 | 2015-12-03 | Shidong Chen | Transform-based methods to transmit the high-definition video |
US20170024843A1 (en) * | 2015-07-24 | 2017-01-26 | Le Holdings (Beijing) Co., Ltd. | Method and device for removing video watermarks |
US10200692B2 (en) * | 2017-03-16 | 2019-02-05 | Cisco Technology, Inc. | Compressed domain data channel for watermarking, scrambling and steganography |
US10460704B2 (en) | 2016-04-01 | 2019-10-29 | Movidius Limited | Systems and methods for head-mounted display adapted to human visual mechanism |
USRE48243E1 (en) | 2010-07-27 | 2020-10-06 | Oracle International Corporation | Log based data replication from a source database to a target database |
US10860732B2 (en) * | 2010-07-29 | 2020-12-08 | Oracle International Corporation | System and method for real-time transactional data obfuscation |
US10942909B2 (en) * | 2018-09-25 | 2021-03-09 | Salesforce.Com, Inc. | Efficient production and consumption for data changes in a database under high concurrency |
US10949947B2 (en) | 2017-12-29 | 2021-03-16 | Intel Corporation | Foveated image rendering for head-mounted display devices |
CN113138743A (en) * | 2017-11-28 | 2021-07-20 | 谷歌有限责任公司 | Keyword group detection using audio watermarking |
US11288763B1 (en) * | 2019-06-21 | 2022-03-29 | Gopro, Inc. | Systems and methods for visually encoding information into a pixel-based image |
US11645261B2 (en) | 2018-04-27 | 2023-05-09 | Oracle International Corporation | System and method for heterogeneous database replication from a remote server |
Families Citing this family (27)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6912315B1 (en) | 1998-05-28 | 2005-06-28 | Verance Corporation | Pre-processed information embedding system |
US7644282B2 (en) | 1998-05-28 | 2010-01-05 | Verance Corporation | Pre-processed information embedding system |
US6737957B1 (en) | 2000-02-16 | 2004-05-18 | Verance Corporation | Remote control signaling using audio watermarks |
US7167599B1 (en) * | 2000-05-03 | 2007-01-23 | Thomson Licensing | Method and device for controlling multimedia data watermark |
GB0118352D0 (en) * | 2001-07-27 | 2001-09-19 | Amino Holdings Ltd | Digital image watermarking |
TWI236250B (en) | 2001-09-12 | 2005-07-11 | Nagravision Sa | Data transmission method between a local server and local peripherals |
EP2782337A3 (en) | 2002-10-15 | 2014-11-26 | Verance Corporation | Media monitoring, management and information system |
US20060239501A1 (en) | 2005-04-26 | 2006-10-26 | Verance Corporation | Security enhancements of digital watermarks for multi-media content |
US7616776B2 (en) | 2005-04-26 | 2009-11-10 | Verance Corproation | Methods and apparatus for enhancing the robustness of watermark extraction from digital host content |
US7369677B2 (en) | 2005-04-26 | 2008-05-06 | Verance Corporation | System reactions to the detection of embedded watermarks in a digital host content |
US9055239B2 (en) | 2003-10-08 | 2015-06-09 | Verance Corporation | Signal continuity assessment using embedded watermarks |
US8020004B2 (en) | 2005-07-01 | 2011-09-13 | Verance Corporation | Forensic marking using a common customization function |
JP5016610B2 (en) * | 2005-12-21 | 2012-09-05 | ディジマーク コーポレイション | Rule-driven pan ID metadata routing system and network |
US8838977B2 (en) | 2010-09-16 | 2014-09-16 | Verance Corporation | Watermark extraction and content screening in a networked environment |
US8923548B2 (en) | 2011-11-03 | 2014-12-30 | Verance Corporation | Extraction of embedded watermarks from a host content using a plurality of tentative watermarks |
US9323902B2 (en) | 2011-12-13 | 2016-04-26 | Verance Corporation | Conditional access using embedded watermarks |
US9547753B2 (en) | 2011-12-13 | 2017-01-17 | Verance Corporation | Coordinated watermarking |
US9571606B2 (en) | 2012-08-31 | 2017-02-14 | Verance Corporation | Social media viewing system |
US8869222B2 (en) | 2012-09-13 | 2014-10-21 | Verance Corporation | Second screen content |
US9106964B2 (en) | 2012-09-13 | 2015-08-11 | Verance Corporation | Enhanced content distribution using advertisements |
US9262793B2 (en) | 2013-03-14 | 2016-02-16 | Verance Corporation | Transactional video marking system |
US9251549B2 (en) | 2013-07-23 | 2016-02-02 | Verance Corporation | Watermark extractor enhancements based on payload ranking |
US9208334B2 (en) | 2013-10-25 | 2015-12-08 | Verance Corporation | Content management using multiple abstraction layers |
EP2899723A1 (en) | 2013-12-16 | 2015-07-29 | Thomson Licensing | Method for accelerated restitution of audio content and associated device |
WO2015138798A1 (en) | 2014-03-13 | 2015-09-17 | Verance Corporation | Interactive content acquisition using embedded codes |
CN105898322A (en) * | 2015-07-24 | 2016-08-24 | 乐视云计算有限公司 | Video watermark removing method and device |
CN108711131B (en) * | 2018-04-28 | 2022-08-16 | 北京数科网维技术有限责任公司 | Watermark method and device based on image feature matching |
Citations (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4644422A (en) * | 1982-07-22 | 1987-02-17 | Tvi Systems, Ltd. | Anti-copy system |
US5182771A (en) * | 1991-03-29 | 1993-01-26 | Scientific Atlanta, Inc. | Anti-taping method and apparatus for a multiplexed analog component television system |
US5465308A (en) | 1990-06-04 | 1995-11-07 | Datron/Transoc, Inc. | Pattern recognition system |
US5574787A (en) | 1994-07-25 | 1996-11-12 | Ryan; John O. | Apparatus and method for comprehensive copy protection for video platforms and unprotected source material |
US5765176A (en) | 1996-09-06 | 1998-06-09 | Xerox Corporation | Performing document image management tasks using an iconic image having embedded encoded information |
US5943422A (en) * | 1996-08-12 | 1999-08-24 | Intertrust Technologies Corp. | Steganographic techniques for securely delivering electronic digital rights management control information over insecure communication channels |
US5959717A (en) * | 1997-12-12 | 1999-09-28 | Chaum; Jerry | Motion picture copy prevention, monitoring, and interactivity system |
US6182218B1 (en) * | 1994-12-13 | 2001-01-30 | Mitsubishi Corporation | Digital content management system using electronic watermark |
US6208746B1 (en) * | 1997-05-09 | 2001-03-27 | Gte Service Corporation | Biometric watermarks |
US6320965B1 (en) * | 1998-10-14 | 2001-11-20 | Liquid Audio, Inc. | Secure watermark method and apparatus for digital signals |
US6363159B1 (en) * | 1993-11-18 | 2002-03-26 | Digimarc Corporation | Consumer audio appliance responsive to watermark data |
US6424715B1 (en) * | 1994-10-27 | 2002-07-23 | Mitsubishi Corporation | Digital content management system and apparatus |
US6529600B1 (en) * | 1998-06-25 | 2003-03-04 | Koninklijke Philips Electronics N.V. | Method and device for preventing piracy of video material from theater screens |
US6809792B1 (en) * | 2000-10-09 | 2004-10-26 | Eastman Kodak Company | Spectral watermarking for motion picture image data |
-
1999
- 1999-08-31 US US09/763,917 patent/US8538886B1/en not_active Expired - Lifetime
- 1999-08-31 WO PCT/US1999/019723 patent/WO2000013136A1/en active Application Filing
- 1999-08-31 AU AU61318/99A patent/AU6131899A/en not_active Abandoned
Patent Citations (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4644422A (en) * | 1982-07-22 | 1987-02-17 | Tvi Systems, Ltd. | Anti-copy system |
US5465308A (en) | 1990-06-04 | 1995-11-07 | Datron/Transoc, Inc. | Pattern recognition system |
US5182771A (en) * | 1991-03-29 | 1993-01-26 | Scientific Atlanta, Inc. | Anti-taping method and apparatus for a multiplexed analog component television system |
US6363159B1 (en) * | 1993-11-18 | 2002-03-26 | Digimarc Corporation | Consumer audio appliance responsive to watermark data |
US5574787A (en) | 1994-07-25 | 1996-11-12 | Ryan; John O. | Apparatus and method for comprehensive copy protection for video platforms and unprotected source material |
US6424715B1 (en) * | 1994-10-27 | 2002-07-23 | Mitsubishi Corporation | Digital content management system and apparatus |
US6182218B1 (en) * | 1994-12-13 | 2001-01-30 | Mitsubishi Corporation | Digital content management system using electronic watermark |
US5943422A (en) * | 1996-08-12 | 1999-08-24 | Intertrust Technologies Corp. | Steganographic techniques for securely delivering electronic digital rights management control information over insecure communication channels |
US5765176A (en) | 1996-09-06 | 1998-06-09 | Xerox Corporation | Performing document image management tasks using an iconic image having embedded encoded information |
US6208746B1 (en) * | 1997-05-09 | 2001-03-27 | Gte Service Corporation | Biometric watermarks |
US5959717A (en) * | 1997-12-12 | 1999-09-28 | Chaum; Jerry | Motion picture copy prevention, monitoring, and interactivity system |
US6529600B1 (en) * | 1998-06-25 | 2003-03-04 | Koninklijke Philips Electronics N.V. | Method and device for preventing piracy of video material from theater screens |
US6320965B1 (en) * | 1998-10-14 | 2001-11-20 | Liquid Audio, Inc. | Secure watermark method and apparatus for digital signals |
US6809792B1 (en) * | 2000-10-09 | 2004-10-26 | Eastman Kodak Company | Spectral watermarking for motion picture image data |
Non-Patent Citations (4)
Title |
---|
"A Review of Watermarking and the Importance of Perceptual Modeling", I. Cox et al., Proc. of Electronics Imaging '97, Feb. 1997. |
"The World According to Wavelets", Hubbard, 1996, chapters 4-5. |
"Towards Robust and Hidden Image Copyright Labeling", E. Koch et al., Proc. of 1995 IEEE Workshop on Nonlinear Signal and Image Processing. |
"Wavelets and Subband Coding", M. Vetterli et al., 1995, chapters 4-7. |
Cited By (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
USRE48243E1 (en) | 2010-07-27 | 2020-10-06 | Oracle International Corporation | Log based data replication from a source database to a target database |
US11544395B2 (en) * | 2010-07-29 | 2023-01-03 | Oracle International Corporation | System and method for real-time transactional data obfuscation |
US20210089669A1 (en) * | 2010-07-29 | 2021-03-25 | Oracle International Corporation | System and method for real-time transactional data obfuscation |
US10860732B2 (en) * | 2010-07-29 | 2020-12-08 | Oracle International Corporation | System and method for real-time transactional data obfuscation |
US8677503B2 (en) * | 2011-01-04 | 2014-03-18 | Motorola Mobility Llc | Mechanism for embedding device identification information into graphical user interface objects |
US20120174232A1 (en) * | 2011-01-04 | 2012-07-05 | Dharawat Parikshit H | Mechanism for embedding device identification information into graphical user interface objects |
US20140098699A1 (en) * | 2011-05-17 | 2014-04-10 | Zte Corporation | Method and system for measuring frame loss ratio |
US9485162B2 (en) * | 2011-05-17 | 2016-11-01 | Zte Corporation | Method and system for measuring frame loss ratio |
US20140177953A1 (en) * | 2012-12-21 | 2014-06-26 | Samsung Electronics Co., Ltd. | Method and apparatus for embedding message into image data |
US20150138405A1 (en) * | 2013-11-15 | 2015-05-21 | Linear Algebra Technologies Limited | Apparatus, systems, and methods for removing noise from an image |
US9196017B2 (en) * | 2013-11-15 | 2015-11-24 | Linear Algebra Technologies Limited | Apparatus, systems, and methods for removing noise from an image |
US20150350595A1 (en) * | 2014-05-30 | 2015-12-03 | Shidong Chen | Transform-based methods to transmit the high-definition video |
US20170024843A1 (en) * | 2015-07-24 | 2017-01-26 | Le Holdings (Beijing) Co., Ltd. | Method and device for removing video watermarks |
US10460704B2 (en) | 2016-04-01 | 2019-10-29 | Movidius Limited | Systems and methods for head-mounted display adapted to human visual mechanism |
US10200692B2 (en) * | 2017-03-16 | 2019-02-05 | Cisco Technology, Inc. | Compressed domain data channel for watermarking, scrambling and steganography |
CN113138743A (en) * | 2017-11-28 | 2021-07-20 | 谷歌有限责任公司 | Keyword group detection using audio watermarking |
CN113138743B (en) * | 2017-11-28 | 2022-10-14 | 谷歌有限责任公司 | Keyword group detection using audio watermarking |
US10949947B2 (en) | 2017-12-29 | 2021-03-16 | Intel Corporation | Foveated image rendering for head-mounted display devices |
US11682106B2 (en) | 2017-12-29 | 2023-06-20 | Intel Corporation | Foveated image rendering for head-mounted display devices |
US11645261B2 (en) | 2018-04-27 | 2023-05-09 | Oracle International Corporation | System and method for heterogeneous database replication from a remote server |
US20210117400A1 (en) * | 2018-09-25 | 2021-04-22 | Salesforce.Com, Inc. | Efficient production and consumption for data changes in a database under high concurrency |
US10942909B2 (en) * | 2018-09-25 | 2021-03-09 | Salesforce.Com, Inc. | Efficient production and consumption for data changes in a database under high concurrency |
US11860847B2 (en) * | 2018-09-25 | 2024-01-02 | Salesforce, Inc. | Efficient production and consumption for data changes in a database under high concurrency |
US11288763B1 (en) * | 2019-06-21 | 2022-03-29 | Gopro, Inc. | Systems and methods for visually encoding information into a pixel-based image |
US20220188962A1 (en) * | 2019-06-21 | 2022-06-16 | Gopro, Inc. | Systems and methods for visually encoding information into a pixel-based image |
US11756149B2 (en) * | 2019-06-21 | 2023-09-12 | Gopro, Inc. | Systems and methods for visually encoding information into a pixel-based image |
Also Published As
Publication number | Publication date |
---|---|
WO2000013136A1 (en) | 2000-03-09 |
AU6131899A (en) | 2000-03-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8538886B1 (en) | Watermarking system and methodology for digital multimedia content | |
Doerr et al. | A guide tour of video watermarking | |
Barni et al. | Watermarking systems engineering: enabling digital assets security and other applications | |
US8995711B2 (en) | Efficient watermarking approaches of compressed media | |
Kutter et al. | Digital signature of color images using amplitude modulation | |
Lin et al. | Generating robust digital signature for image/video authentication | |
Hartung et al. | Multimedia watermarking techniques | |
US7298865B2 (en) | Secure robust high-fidelity watermarking | |
JP4860149B2 (en) | Digital content marking method, method for detecting fingerprints in digital content, digital content, device for watermarking digital content, device for applying fingerprint to watermarked digital content, detecting fingerprint in digital content Device and memory for storing information including instructions | |
US7006661B2 (en) | Digital watermarking systems and methods | |
US6359985B1 (en) | Procedure for marking binary coded data sets | |
US6785332B1 (en) | Method for marking a compressed digital video signal | |
US7058979B1 (en) | Method for inserting a watermark into an image | |
US20020188570A1 (en) | Partial protection of content | |
JP2004159309A (en) | Method and apparatus for digital watermarking and watermark decoding | |
US7376241B2 (en) | Discrete fourier transform (DFT) watermark | |
Linnartz et al. | MPEG PTY-marks: Cheap detection of embedded copyright data in DVD-video | |
JP3754847B2 (en) | Data processing method, data processing apparatus and storage medium thereof | |
Duan et al. | A short summary of digital watermarking techniques for multimedia data | |
EP0869454B1 (en) | Watermarking a digital image | |
Dufaux et al. | Securing JPEG 2000 compressed images | |
Battiato et al. | Color opponency watermarking scheme for digital images | |
Yang et al. | Cryptographic and steganographic approaches to ensure multimedia information security and privacy | |
Doërr et al. | VIDEO WATERMARKING | |
JP2024021961A (en) | Digital watermarking method for videos |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: DIGITAL VIDEO EXPRESS, L.P., VIRGINIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:IU, SIU-LEONG;DAVIS, MALCOM;LUO, HUI;AND OTHERS;SIGNING DATES FROM 20010610 TO 20010615;REEL/FRAME:011952/0457 |
|
AS | Assignment |
Owner name: CIRCUIT CITY STORES, INC. LIQUIDATING TRUST, VIRGIFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:DIGITAL VIDEO EXPRESS, LP;REEL/FRAME:026846/0075Effective date: 20110831 |
|
AS | Assignment |
Owner name: INNOVATIVE VIDEO SECURITY LLC C/O BINGHAM MCCUTCHEFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CIRCUIT CITY STORES, INC. LIQUIDATING TRUST;REEL/FRAME:026879/0274Effective date: 20110908 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INOVATIVE VIDEO SECURITY LLC C/O BINGHAM MCCUTCHEN LLP;REEL/FRAME:028083/0108Effective date: 20120309 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: CORRECTIVE ASSIGNMENT TO CORRECT THE NAME OF THE ASSIGNOR PREVIOUSLY RECORDED ON REEL 028083, FRAME 0108;ASSIGNOR:INNOVATIVE VIDEO SECURITY LLC;REEL/FRAME:028431/0159Effective date: 20120309 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0299Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |