KR20240013839A - Auto White Balance (AWB) for camera systems - Google Patents
Auto White Balance (AWB) for camera systems Download PDFInfo
- Publication number
- KR20240013839A KR20240013839A KR1020247000567A KR20247000567A KR20240013839A KR 20240013839 A KR20240013839 A KR 20240013839A KR 1020247000567 A KR1020247000567 A KR 1020247000567A KR 20247000567 A KR20247000567 A KR 20247000567A KR 20240013839 A KR20240013839 A KR 20240013839A
- Authority
- KR
- South Korea
- Prior art keywords
- face
- additional
- human face
- image
- detected
- Prior art date
Links
- 239000002243 precursor Substances 0.000 claims abstract description 92
- 238000000034 method Methods 0.000 claims abstract description 66
- 235000019646 color tone Nutrition 0.000 claims abstract description 55
- 238000010801 machine learning Methods 0.000 description 9
- 238000000205 computational method Methods 0.000 description 7
- 230000001815 facial effect Effects 0.000 description 7
- 238000001914 filtration Methods 0.000 description 7
- 238000013528 artificial neural network Methods 0.000 description 4
- 238000001514 detection method Methods 0.000 description 4
- 230000002123 temporal effect Effects 0.000 description 4
- 230000006870 function Effects 0.000 description 3
- 238000005286 illumination Methods 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- 208000029152 Small face Diseases 0.000 description 1
- 239000003086 colorant Substances 0.000 description 1
- 238000013527 convolutional neural network Methods 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 238000003066 decision tree Methods 0.000 description 1
- 239000011521 glass Substances 0.000 description 1
- 238000003384 imaging method Methods 0.000 description 1
- 230000000306 recurrent effect Effects 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/222—Studio circuitry; Studio devices; Studio equipment
- H04N5/262—Studio circuits, e.g. for mixing, switching-over, change of character of image, other special effects ; Cameras specially adapted for the electronic generation of special effects
- H04N5/2621—Cameras specially adapted for the electronic generation of special effects during image pickup, e.g. digital cameras, camcorders, video cameras having integrated special effects capability
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/80—Camera processing pipelines; Components thereof
- H04N23/84—Camera processing pipelines; Components thereof for processing colour signals
- H04N23/88—Camera processing pipelines; Components thereof for processing colour signals for colour balance, e.g. white-balance circuits or colour temperature control
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/57—Mechanical or electrical details of cameras or camera modules specially adapted for being embedded in other devices
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/61—Control of cameras or camera modules based on recognised objects
- H04N23/611—Control of cameras or camera modules based on recognised objects where the recognised objects include parts of the human body
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/63—Control of cameras or camera modules by using electronic viewfinders
- H04N23/631—Graphical user interfaces [GUI] specially adapted for controlling image capture or setting capture parameters
- H04N23/632—Graphical user interfaces [GUI] specially adapted for controlling image capture or setting capture parameters for displaying or modifying preview images prior to image capturing, e.g. variety of image resolutions or capturing parameters
Abstract
본 문서는 카메라 시스템의 자동 화이트 밸런스를 위한 기법 및 장치에 대해 설명한다. 기법 및 장치는 하나 이상의 검출된 얼굴들을 검출하고 색조를 결정하기 위해 프리커서 이미지를 활용한다. 카메라 시스템은 검출된 얼굴과 동일한 얼굴을 포함하는 것으로 결정된 이미지들의 그룹에 기초하여 색조 데이터를 검색한다. 이 색조 데이터에 기초하여, 프리커서 이미지 내에서 검출된 얼굴의 색조와 연관 색조 데이터의 차이에 기초하여 화이트 밸런스의 차이가 결정된다. 개선된 색조의 이미지를 캡처할수 있도록 화이트 밸런스의 차이에 기초하여 카메라 설정들이 조정된다.This document describes techniques and devices for automatic white balance of camera systems. Techniques and devices utilize precursor images to detect and determine hue of one or more detected faces. The camera system retrieves tonal data based on a group of images determined to contain the same face as the detected face. Based on this hue data, a difference in white balance is determined based on the difference between the hue of the face detected within the precursor image and the associated hue data. Camera settings are adjusted based on differences in white balance to capture images with improved color tones.
Description
카메라 시스템은 일반적으로 이미지 또는 비디오의 특성(예를 들어, 색상, 선명도, 배율)을 조정하는 데 사용할 수 있는 많은 기능을 가지고 있다. 그러한 기능 중 하나는 이미지에서 색상이 렌더링되는 방식을 조정하는 카메라 설정인 화이트 밸런스(WB)를 포함한다. WB는 일반적으로 이미지에서 흰색으로 보이는 객체를 흰색으로 렌더링하는 데 사용된다. 사용자를 어시스트하기 위해, 많은 카메라들은 색상 보정 알고리즘에 따라 WB를 자동으로 조정하는 자동 화이트 밸런스 기능(AWB)을 포함한다. 그러나 기존 카메라 시스템은 특히 얼굴과 같이 가장 중요한 이미지 부분에서 원하는 정확도를 달성하지 못할 수 있다. 또한 이미지의 여러 부분이 중요한 것으로 식별되면 추가적인 문제가 발생한다. 결과적으로 이미지, 특히 이미지의 중요한 부분에서 WB 문제가 나타날 수 있다.Camera systems typically have many features that can be used to adjust the characteristics of an image or video (e.g., color, sharpness, scale). One such feature includes white balance (WB), a camera setting that adjusts how colors are rendered in an image. WB is typically used to render objects that appear white in an image as white. To assist the user, many cameras include an automatic white balance function (AWB) that automatically adjusts WB according to a color correction algorithm. However, existing camera systems may not achieve the desired accuracy, especially in the most important parts of the image, such as faces. Additionally, additional problems arise when multiple parts of the image are identified as important. As a result, WB issues may appear in the image, especially in important parts of the image.
본 문서는 카메라 시스템을 위한 자동 화이트 밸런스에 대한 기법 및 장치를 설명한다. 기법 및 장치는 하나 이상의 검출된 얼굴들을 검출하고 색조를 결정하기 위해 프리커서 이미지를 활용한다. 카메라 시스템은 검출된 얼굴과 동일한 얼굴을 포함하는 것으로 결정된 이미지들의 그룹에 기초하여 색조 데이터를 검색한다. 이 색조 데이터에 기초하여, 프리커서 이미지 내에서 검출된 얼굴의 색조와 연관 색조 데이터의 차이에 기초하여 화이트 밸런스의 차이가 결정된다. 개선된 색조의 이미지를 캡처할 수 있도록 화이트 밸런스의 차이에 기초하여 카메라 설정들이 조정된다. 특히 얼굴과 같이 이미지에서 가장 중요한 부분에서 화이트 밸런스 조정 및 이미지 색조가 개선될 수 있다.This document describes techniques and devices for automatic white balance for camera systems. Techniques and devices utilize precursor images to detect and determine hue of one or more detected faces. The camera system retrieves tonal data based on a group of images determined to contain the same face as the detected face. Based on this hue data, a difference in white balance is determined based on the difference between the hue of the face detected within the precursor image and the associated hue data. Camera settings are adjusted based on differences in white balance to capture images with improved color tones. White balance adjustment and image color tone can be improved, especially in the most important parts of the image, such as the face.
또한, 개선된 색조를 갖는 이미지의 캡처를 가능하게 할 수 있는 조정을 결정하는 데 사용되는 추가 얼굴이 프리커서 이미지 내에서 개시된 단계를 통해 검출될 수 있다. 이러한 조정은 이미지의 가장 중요한 부분을 개선시킬 조정을 결정하기 위해, 우선순위 값에 기초하여, 가중될 수 있다. 대안적으로, 카메라 설정들을 별도로 조정하여 다수의 이미지들을 캡처할 수 있다. 이러한 이미지들은 각 이미지의 일부를 통합하여 색조가 개선된 단일 이미지를 생성하는 이미지 병합 모듈에 제공될 수 있다.Additionally, additional faces may be detected through the disclosed steps within the precursor image, used to determine adjustments that may enable the capture of images with improved color tone. These adjustments may be weighted, based on priority values, to determine which adjustments will improve the most important parts of the image. Alternatively, camera settings can be adjusted separately to capture multiple images. These images can be fed to an image merge module that merges portions of each image to create a single, tonally enhanced image.
이 요약은 카메라 시스템을 위한 AWB에 대한 기법 및 장치의 단순화된 개념을 소개하기 위해 제공되며, 그 개념은 아래의 상세한 설명 및 도면에서 더 설명된다. 이 요약은 청구된 주제의 필수 특징을 식별하기 위한 것이 아니며 청구된 주제의 범위를 결정하는 데 사용하기 위한 것도 아니다.This summary is provided to introduce a simplified concept of techniques and devices for AWB for camera systems, which concepts are further explained in the detailed description and figures below. This summary is not intended to identify essential features of the claimed subject matter or to be used in determining the scope of the claimed subject matter.
카메라 시스템을 위한 AWB의 하나 이상의 측면에 대한 세부사항이 아래에 설명되어 있다. 설명과 도면에서 서로 다른 경우에 동일한 참조 번호를 사용하는 것은 유사한 요소를 나타낸다:
도 1은 카메라 시스템을 위한 AWB의 예시적인 동작 환경을 도시한다;
도 2는 프리퀀트 얼굴 모듈(Frequent Face Module)과 함께 연동하여 작동하는 AWB 모듈의 예시적인 구현예를 도시한다;
도 3은 도 1의 예시적인 동작 환경의 상세한 예를 도시한다;
도 4는 카메라 시스템을 위한 AWB의 맥락 내에서 프리커서 이미지를 캡처하는 예시적인 구현예를 도시한다;
도 5는 도 4의 프리커서 이미지 내에서 얼굴을 검출하는 예시적인 구현예를 도시한다;
도 6은 색조 결정 모듈에 의한 색조 결정의 예시적인 구현예를 도시한다;
도 7은 도 5의 제1 검출된 얼굴과 동일한 얼굴을 포함하는 것으로 결정된 일치하는 이미지들의 세트의 예를 도시한다;
도 8은 도 5의 추가 검출된 얼굴과 동일한 얼굴을 포함하는 것으로 결정된 일치하는 이미지들의 세트의 예를 도시한다;
도 9는 도 7의 일치하는 이미지들의 그룹으로부터 색조를 결정하는 예시적인 구현예를 도시한다;
도 10은 도 7의 일치하는 이미지들의 그룹으로부터의 색조 데이터의 예를 도시한다;
도 11은 도 5의 제1 검출된 얼굴과 동일한 얼굴을 포함하는 것으로 결정된 또 다른 일치하는 이미지들의 세트의 예를 도시한다;
도 12는 도 11의 일치하는 이미지들의 그룹으로부터의 색조 데이터의 예를 도시한다;
도 13은 전자 디바이스 내의 카메라 시스템을 위한 AWB의 예시적인 구현예를 도시한다;
도 14는 전자 디바이스 내의 카메라 시스템을 위한 AWB의 또 다른 예시적인 구현예를 도시한다;
도 15는 도 14의 AWB의 예시적인 구현예를 위한 이미지 병합 모듈의 예시적인 구현예를 도시한다;
도 16은 카메라 시스템을 위한 AWB의 예시적인 방법을 도시한다;
도 17은 카메라 시스템을 위한 AWB의 또 다른 예시적인 방법을 도시한다; 그리고
도 18은 카메라 시스템을 위한 AWB의 또 다른 예시적인 방법을 도시한다.Details of one or more aspects of AWB for camera systems are described below. The use of the same reference numbers in different instances in the description and drawings refers to similar elements:
1 shows an example operating environment of AWB for a camera system;
Figure 2 shows an example implementation of the AWB module operating in conjunction with the Frequent Face Module;
Figure 3 shows a detailed example of the exemplary operating environment of Figure 1;
Figure 4 shows an example implementation of capturing a precursor image within the context of AWB for a camera system;
Figure 5 shows an example implementation of detecting a face within the precursor image of Figure 4;
6 shows an example implementation of hue determination by a hue determination module;
Figure 7 shows an example of a set of matching images determined to contain the same face as the first detected face in Figure 5;
Figure 8 shows an example of a set of matching images determined to contain the same face as the additional detected face in Figure 5;
Figure 9 shows an example implementation of determining hue from the group of matching images of Figure 7;
Figure 10 shows an example of tonal data from the group of matching images in Figure 7;
Figure 11 shows an example of another set of matching images determined to contain the same face as the first detected face in Figure 5;
Figure 12 shows an example of tonal data from the group of matching images of Figure 11;
13 shows an example implementation of AWB for a camera system in an electronic device;
14 shows another example implementation of AWB for a camera system in an electronic device;
Figure 15 shows an example implementation of an image merging module for an example implementation of AWB of Figure 14;
16 shows an example method of AWB for a camera system;
Figure 17 shows another example method of AWB for a camera system; and
18 shows another example method of AWB for a camera system.
개요outline
본 문서는 카메라 시스템을 위한 AWB에 대한 기법 및 장치를 설명한다. 이 기법은 장면의 프리커서 이미지를 활용하여 사람의 얼굴을 검출한다. 그런 다음 검출된 얼굴의 색조가 결정되고 검출된 얼굴과 연관된 색조 데이터와 비교된다. 색조 데이터는 이전 주변 조건들에서 캡처되어 검출된 얼굴과 동일한 얼굴을 포함하는 것으로 결정된 이전에 캡처된 이미지들의 세트로부터 결정된다. 색조 데이터는 이전에 캡처된 이미지들, 이전에 캡처된 이미지들의 그룹, 또는 이전에 캡처된 이미지들의 일부를 설명할 수 있다. 검출된 얼굴의 색조와 색조 데이터의 비교를 통해, 예를 들어, 카메라 설정들을 조정하지 않고 캡처된 등가(equivalent) 이미지와 비교할 때, 개선된 색조로 이미지를 캡처할 수 있도록 카메라 설정들을 조정하기 위해 AWB의 차이가 결정되고 활용된다. 개선된 색조는 검출된 얼굴의 색조보다 제1 색조 데이터와 더 밀접하게 일치할 수 있다. 색조의 개선은 특히 얼굴과 같이 가장 중요한 이미지 부분에 대응할 수 있다. This document describes techniques and devices for AWB for camera systems. This technique detects human faces using precursor images of the scene. The hue of the detected face is then determined and compared to the hue data associated with the detected face. The tonal data is determined from a set of previously captured images determined to contain the same face as the face captured and detected under previous ambient conditions. Tonal data may describe previously captured images, a group of previously captured images, or a portion of previously captured images. By comparing the tonality of the detected face with the tonality data, for example, to adjust the camera settings to capture an image with improved tonality compared to an equivalent image captured without adjusting the camera settings. The difference in AWB is determined and exploited. The improved hue may match the first hue data more closely than the detected hue of the face. Improvements in color tone can especially address the most important parts of the image, such as the face.
추가 얼굴이 프리커서 이미지 내에서 검출될 수 있으며, 위의 기법을 통해 AWB의 추가 차이를 결정하는 데 활용될 수 있다. AWB의 차이는 가중 합, 필터링 또는 기타 계산 방법을 통해 결합되어 개선된 색조로 이미지를 캡처할 수 있는 카메라 설정들을 조정할 수 있다. 대안적으로, 카메라 설정에 대한 별도의 조정들을 사용하여 다수의 이미지들을 캡처하고 이미지 병합 모듈에 제공할 수 있다. 이미지 병합 모듈은 각 이미지의 일부를 통합하여 색조가 개선된 단일 이미지를 만든다.Additional faces may be detected within the precursor image and utilized to determine additional differences in AWB through the above techniques. Differences in AWB can be combined through weighted summing, filtering, or other computational methods to adjust camera settings to capture images with improved color tonality. Alternatively, separate adjustments to camera settings can be used to capture multiple images and provide them to the image merging module. The image merge module merges parts of each image to create a single, tonally enhanced image.
카메라 시스템을 위한 AWB에 대해 설명된 기법 및 장치의 특징 및 개념은 임의의 수의 서로 다른 환경에서 구현될 수 있지만, 측면은 다음 예의 맥락에서 설명된다.Although the features and concepts of the techniques and devices described for AWB for camera systems may be implemented in any number of different environments, aspects are illustrated in the context of the following examples.
예시적인 시스템example system
도 1은 전자 디바이스(102)의 카메라 시스템(104)을 위한 AWB에 대한 예시적인 동작 환경(100)을 도시한다. 전자 디바이스(102)는 카메라 시스템(104)을 포함한다. 예시적인 동작 환경(100)에서, 카메라 시스템(104)은 액추에이터(108)와 디스플레이(110)를 활용하는 카메라 애플리케이션(106)으로 구성된다. 카메라 시스템(104)은 색조 결정 모듈(114)을 사용하여 이미지의 일부 내의 색조를 결정하고 화이트 밸런스 컨트롤러(116)를 활용함으로써 RGB 센서와 같은 이미징 센서를 제어하도록 구성된 자동 화이트 밸런스(AWB) 모듈(112)을 더 포함한다.1 illustrates an example operating environment 100 for AWB for a camera system 104 of an electronic device 102. Electronic device 102 includes a camera system 104 . In the example operating environment 100 , the camera system 104 consists of a camera application 106 utilizing an actuator 108 and a display 110 . The camera system 104 includes an automatic white balance (AWB) module configured to determine the hue within a portion of an image using a hue determination module 114 and to control an imaging sensor, such as an RGB sensor, by utilizing a white balance controller 116. 112) is further included.
카메라 시스템(104)은 또한 AWB 모듈(112)과 함께 동작하는 프리퀀트 얼굴(FF, Frequent Face) 모듈(118)을 포함한다. 프리퀀트 얼굴 모듈(118)은 이미지 내에서 얼굴을 검출하도록 구성된 얼굴 검출기(120), 및 하나 이상의 이미지 내에서 동일한 얼굴에 대한 개별 색조 결정으로부터 색조 데이터를 결정하도록 구성된 색조 템퍼럴(temporal) 필터(122)를 포함한다. 색조 템퍼럴 필터(122)는 합산, 가중 합산, 필터링, 또는 임의의 다른 계산 방법을 통해 템퍼럴 데이터를 결정할 수 있다. 카메라 시스템(104)은 동일한 장면의 다수의 이미지들로부터 단일 이미지를 생성할 수 있는 이미지 병합 모듈(124)을 추가로 포함한다.Camera system 104 also includes a Frequent Face (FF) module 118 that operates in conjunction with AWB module 112. The frequent face module 118 includes a face detector 120 configured to detect a face within an image, and a tonal temporal filter configured to determine tonal data from individual tonal determinations for the same face within one or more images. 122). Hue temporal filter 122 may determine temporal data through summation, weighted summation, filtering, or any other computational method. Camera system 104 further includes an image merging module 124 that can generate a single image from multiple images of the same scene.
도 2는 서로 연동하여 동작하는 도 1의 AWB 모듈(112)과 FF 모듈(118)의 예시적인 구현예(200)를 도시한다. 예시적인 구현예(200)에서, 카메라 애플리케이션(106)은 FF 모듈(118)에 이미지를 제공한다. 제공되는 이미지는 장면의 프리커서(precursor) 이미지일 수도 있고 이전에 캡처된 이미지일 수도 있다. 얼굴 검출기(120)는 이미지 내에서 얼굴을 검출한다. FF 모듈은 얼굴 프리퀀시(face-frequency) 값과 같이 검출된 얼굴과 연관된 값들을 결정할 수 있다. 얼굴 프리퀀시 값은 프리커서 이미지 내에서 하나 이상의 추가 검출된 얼굴이 검출되는 경우에 특히 유용하다. 얼굴 프리퀀시 값은 프리커서 이미지 내에서 검출된 얼굴과 동일한 사람의 얼굴이 포함된 것으로 결정된 이전 이미지들의 개수에 기초하여 결정된다. 일단 프로세싱되면 검출된 얼굴과 이미지가 카메라 애플리케이션(106)에 제공된다.FIG. 2 illustrates an example implementation 200 of the AWB module 112 and FF module 118 of FIG. 1 operating in conjunction with each other. In example implementation 200, camera application 106 provides images to FF module 118. The image provided may be a precursor image of the scene or a previously captured image. Face detector 120 detects faces within the image. The FF module can determine values associated with the detected face, such as face-frequency values. The face frequency value is particularly useful when one or more additional detected faces are detected within the precursor image. The face frequency value is determined based on the number of previous images determined to contain the same person's face as the face detected in the precursor image. Once processed, the detected face and image are provided to the camera application 106.
카메라 애플리케이션(106)은 이들 이미지들을 AWB 모듈(112)에 제공하고, AWB 모듈(112)은 이미지로부터의 데이터와 함께 검출된 얼굴을 프로세싱하고 색조를 포함한 이미지 내의 검출된 얼굴과 연관된 값들을 결정한다. 색조는 색조 결정 모듈(114)을 사용하여 결정되지만, AWB 모듈(112)은 주변 데이터(예를 들어, 광 데이터 및 얼굴 크기 데이터)를 사용하여 이미지 내에서 검출된 얼굴과 연관된 신뢰도 값을 추가로 결정할 수 있다. 색조를 포함하여 결정된 값들은 카메라 애플리케이션(106)에 출력되어 카메라 애플리케이션(106) 내에 유지되거나 FF 모듈(118)에 제공되거나 둘 모두에 제공된다.Camera application 106 provides these images to AWB module 112, which processes the detected face along with data from the image and determines values associated with the detected face in the image, including color tone. . Hue is determined using hue determination module 114, but AWB module 112 uses ambient data (e.g., light data and face size data) to further determine confidence values associated with faces detected within the image. You can decide. The determined values, including color tone, are output to the camera application 106 and either maintained within the camera application 106 or provided to the FF module 118, or both.
FF 모듈(118)에 제공되면, FF 모듈(118)은 색조 템퍼럴 필터(122)를 사용하여 값들을 색조 데이터로 프로세싱할 수 있다. 색조 데이터는 하나 이상의 이미지 내에서 검출된 얼굴과 연관된 색조 값들을 사용하여 계산되는 더 정확한 색조를 포함한다. 또한, 하나 이상의 이미지들 내에서 검출된 얼굴과 연관된 색조 값들과 동일한 이미지들 내에서 검출된 얼굴과 연관된 신뢰도 값들을 결합함으로써 더 정확한 색조 데이터가 계산될 수 있다. 이러한 값들은 가중 합, 필터링 또는 기타 계산 방법을 사용하여 결합될 수 있다. 또한, 색조 데이터는 검출된 얼굴과 동일한 얼굴을 포함하는 이미지들의 개수로 결정된 얼굴 프리퀀시 값을 포함할 수 있다.Once provided to FF module 118, FF module 118 can process the values into hue data using a hue temporal filter 122. Hue data contains more accurate hues that are calculated using hue values associated with faces detected within one or more images. Additionally, more accurate tonal data may be calculated by combining tonal values associated with a face detected within one or more images with confidence values associated with a face detected within the same images. These values can be combined using weighted sums, filtering, or other computational methods. Additionally, the color tone data may include a face frequency value determined by the number of images containing the same face as the detected face.
색조 데이터는 AWB 모듈(112)에 제공되어 프리커서 이미지 내에서 검출된 얼굴의 색조와 비교될 수 있다. 비교 결과에 기초하여, WB 컨트롤러(116)는 검출된 프리커서 이미지 내에서 검출된 얼굴의 색조와 색조 데이터 사이의 WB의 차이를 결정할 수 있다. 추가적으로, WB 컨트롤러(116)는 WB의 차이에 기초하여 카메라 애플리케이션(106) 내의 카메라 설정들을 조정할 수 있다.Hue data may be provided to the AWB module 112 and compared to the shade of the face detected within the precursor image. Based on the comparison result, the WB controller 116 may determine the difference in WB between the hue of the detected face and the hue data within the detected precursor image. Additionally, WB controller 116 may adjust camera settings within camera application 106 based on differences in WB.
도 3은 도 1의 동작 환경(100)의 상세한 예를 도시한다. 구체적으로, 전자 디바이스(102)는 스마트폰(102-1), 태블릿(102-2), 노트북(102-3), 데스크탑 컴퓨터(102-4), 스마트워치(102-5), 디지털 안경(102-102-102-3), 전자 컨트롤러(102-7), 홈 자동화 및 제어 시스템(102-8), 전자레인지(102-9)를 포함하는 다양한 예를 통해 예시된다. 이는 카메라 시스템을 위한 AWB가 채용될 수 있는 많은 전자 디바이스 중 일부일 뿐이며, 다른 디바이스들, 예를 들어 텔레비전, 엔터테인먼트 시스템, 오디오 시스템, 자동차, 드론, 트랙 패드, 드로잉 패드, 넷북, 전자책, 홈 보안 시스템, 기타 가전 제품들도 포함할 수 있다. 전자 디바이스(102)는 모바일, 웨어러블, 비웨어러블일 수 있지만, 그러나 모바일 또는 상대적으로 움직이지 않을 수 있음(예를 들어, 데스크탑 및 가전제품)에 유의한다.Figure 3 shows a detailed example of the operating environment 100 of Figure 1. Specifically, the electronic device 102 includes a smartphone 102-1, a tablet 102-2, a laptop 102-3, a desktop computer 102-4, a smartwatch 102-5, and digital glasses ( 102-102-102-3), electronic controller 102-7, home automation and control system 102-8, and microwave oven 102-9. These are just a few of the many electronic devices in which AWB for camera systems can be employed, as well as others such as televisions, entertainment systems, audio systems, automobiles, drones, trackpads, drawing pads, netbooks, e-books, and home security. It may also include systems and other home appliances. Note that electronic devices 102 may be mobile, wearable, or non-wearable, but may also be mobile or relatively immobile (eg, desktops and consumer electronics).
전자 디바이스(102)는 하나 이상의 프로세서(302), 컴퓨터 판독가능 매체(304) 및 하나 이상의 센서(306)를 더 포함한다. 컴퓨터 판독가능 매체(304)는 메모리 및 저장 매체(308), 애플리케이션(310), 자동 화이트 밸런스(AWB) 모듈 매체(312), 프리퀀트 얼굴(FF) 모듈 매체(314) 및 이미지 병합(IM) 모듈 매체(316)를 포함한다. 컴퓨터 판독가능 매체(304) 상의 컴퓨터 판독가능 명령어로서 구현된 애플리케이션(310)은 컴퓨터 프로세서(302)에 의해 실행되어 본 명세서에 설명된 기능 중 일부 또는 전부를 제공할 수 있다. 예를 들어, 애플리케이션(310)은 카메라 애플리케이션(예를 들어, 카메라 애플리케이션(106)), AWB 모듈(예를 들어, AWB 모듈(112)) 또는 FF 모듈(예를 들어, FF 모듈(118))을 포함하거나 이와 함께 동작하여 카메라 시스템을 위한 AWB를 수행할 수 있다. 또한, 하나 이상의 센서(306)는 이미지, 비디오 및 오디오를 캡처하도록 구성된 하나 이상의 카메라(320)를 포함할 수 있다.Electronic device 102 further includes one or more processors 302, computer-readable media 304, and one or more sensors 306. Computer-readable media 304 includes memory and storage media 308, applications 310, automatic white balance (AWB) module media 312, frequent face (FF) module media 314, and image merge (IM) media. Includes modular media 316. Application 310, implemented as computer-readable instructions on computer-readable medium 304, can be executed by computer processor 302 to provide some or all of the functionality described herein. For example, application 310 may be a camera application (e.g., camera application 106), an AWB module (e.g., AWB module 112), or an FF module (e.g., FF module 118). It may include or operate in conjunction with to perform AWB for a camera system. Additionally, one or more sensors 306 may include one or more cameras 320 configured to capture images, video, and audio.
도 4는 카메라 시스템을 위한 AWB의 맥락 내에서 장면(402)의 프리커서 이미지(404)를 캡처하는 예시적인 구현예를 도시한다. 전자 디바이스(102)는 디스플레이(110) 상에 활성화된 카메라 애플리케이션(106)과 함께 도시된다. 카메라 애플리케이션은 카메라 애플리케이션에 대한 제어를 가능하게 하는 액추에이터(108)를 포함한다. 전자 디바이스(102)는 하나 이상의 센서를 사용하여 장면(402)의 프리커서 이미지(404)를 캡처하는 데 사용되고 있다. 예를 들어, 하나 이상의 센서는 프리커서 이미지(404)가 카메라에 의해 캡처된 디지털 이미지인 카메라를 포함한다. 그러나, 하나 이상의 센서는 저해상도 RGB 센서일 수도 있고, 얼굴 검출 및 검출된 얼굴에 대한 색조 결정을 가능하게 하는 장면으로부터 세부사항을 캡처하는 데 사용가능한 임의의 다른 센서일 수도 있다. 또한, 프리커서 이미지의 하나 이상의 부분이 부적절한 WB로 인해 색상이나 선명도에서 장면과 다르게 나타날 수 있다.4 shows an example implementation of capturing a precursor image 404 of a scene 402 within the context of AWB for a camera system. Electronic device 102 is shown with camera application 106 activated on display 110 . The camera application includes an actuator 108 that enables control over the camera application. Electronic device 102 is being used to capture a precursor image 404 of scene 402 using one or more sensors. For example, the one or more sensors include a camera where the precursor image 404 is a digital image captured by the camera. However, the one or more sensors may be low-resolution RGB sensors or any other sensor available to capture details from the scene to enable face detection and hue determination for the detected face. Additionally, one or more parts of the precursor image may appear different from the scene in color or sharpness due to inadequate WB.
도 5는 프리커서 이미지(예를 들어, 도 4의 프리커서 이미지(404)) 내에서 얼굴을 검출하는 예시적인 구현예를 도시한다. 전자 디바이스(102)는 카메라 애플리케이션(106)이 활성화되어 있고 디스플레이(110)에 프리커서 이미지(404)를 제시하는 것으로 도시된다. 얼굴 검출기(120)를 사용하여, 제1 검출된 얼굴(502)이 프리커서 이미지(404) 내에서 검출된다. 선택적으로, 얼굴 검출기(120)는 추가 검출된 얼굴(504)과 같은 추가 검출된 얼굴을 검출할 수 있다.Figure 5 shows an example implementation of detecting a face within a precursor image (e.g., precursor image 404 of Figure 4). Electronic device 102 is shown with camera application 106 active and presenting precursor image 404 on display 110 . Using face detector 120, a first detected face 502 is detected within precursor image 404. Optionally, face detector 120 may detect additional detected faces, such as additional detected faces 504.
검출된 얼굴 또는 검출된 얼굴과 연관된 신원을 인식하고 추적하는 것은 얼굴 검출기(120)에 의해 요구되지 않는다는 점에 유의한다. 대신, 얼굴 검출기(120)는 검출된 얼굴과 연관된 특징을 분류하여 나중에 일시적으로 다른 이미지의 특징과 일치시킬 수 있다. 분류된 특징은 검출된 얼굴을 다른 이미지의 얼굴과 일치시키는데 사용될 수 있지만, 검출된 얼굴과 연관된 분류된 특징은 검출된 얼굴과 연관된 신원을 결정하는 데 사용될 필요는 없다. 오히려, 분류된 특징은 사용되는 사람의 실제 신원 없이 검출된 얼굴을 다른 이미지의 얼굴과 일치시키는 데 간단히 사용될 수 있다. 이와 같이 서버 저장, 얼굴 식별, 얼굴 인식 등이 필요하지 않으므로, 얼굴 검출기(120)에서 검출된 얼굴과 연관된 신원을 보호할 수 있다.Note that it is not required by face detector 120 to recognize and track the detected face or the identity associated with the detected face. Instead, face detector 120 may classify features associated with detected faces and later temporarily match them with features in other images. Classified features may be used to match a detected face to a face in another image, but classified features associated with a detected face need not be used to determine the identity associated with the detected face. Rather, the classified features can simply be used to match detected faces to faces in other images without the actual identity of the person being used. In this way, since server storage, face identification, face recognition, etc. are not required, the identity associated with the face detected by the face detector 120 can be protected.
일단 검출되면, 제1 검출된 얼굴(502)은 색조 결정 모듈(114)에 제공되어 프리커서 이미지(404) 내의 제1 검출된 얼굴(502)의 색조를 결정한다. 색조 결정 모듈은 프리커서 이미지(404) 내에서 추가 검출된 얼굴(504)에 대한 추가 색조를 결정할 수 있다. 프리커서 이미지 내의 부적절한 WB로 인해, 제1 검출된 얼굴(502)은 장면(예를 들어, 장면(402)) 내의 동일한 얼굴의 색조에 대해 부정확하거나 변경된 색조를 갖는 것처럼 보일 수 있다.Once detected, the first detected face 502 is provided to a hue determination module 114 to determine the hue of the first detected face 502 within the precursor image 404. The hue determination module may determine additional hues for additional detected faces 504 within the precursor image 404 . Due to inadequate WB in the precursor image, the first detected face 502 may appear to have an incorrect or altered color tone relative to the color tone of the same face within the scene (e.g., scene 402).
색조 결정 모듈(예를 들어, 색조 결정 모듈(114))을 사용하여 색조 결정의 예시적인 구현예를 도시하는 도 6을 고려한다. 색조 결정 모듈(114)에는 검출된 얼굴(602)(예를 들어, 검출된 얼굴(602-1), 검출된 얼굴(602-2), 검출된 얼굴(602-3))이 제공된다. 색조 결정 모듈(114)은 검출된 얼굴(602)을 색조 세트(604) 내의 색조(606)과 상관(correlating)시킴으로써 검출된 얼굴(602)에 대한 색조를 결정한다. 검출된 얼굴(602)이 색조 세트(604) 내의 색조(606)와 상관되면, 색조(606)는 하나 이상의 모듈(예를 들어, AWB 모듈(112) 및 FF 모듈(118)) 또는 하나 이상의 애플리케이션(예를 들어, 카메라 애플리케이션 106)에 제공될 수 있다.Consider Figure 6, which illustrates an example implementation of hue determination using a hue determination module (e.g., hue determination module 114). Hue determination module 114 is provided with detected faces 602 (e.g., detected faces 602-1, detected faces 602-2, and detected faces 602-3). The hue determination module 114 determines the hue for the detected face 602 by correlating the detected face 602 with the hue 606 in the hue set 604. If the detected face 602 is correlated with a hue 606 in the hue set 604, the hue 606 may be stored in one or more modules (e.g., AWB module 112 and FF module 118) or one or more applications. (eg, camera application 106).
색조 세트(604)는 미리 결정된 값, 기계 학습 기법, 또는 임의의 다른 계산 방법을 통해 생성될 수 있다. 유사하게, 검출된 얼굴(602)에 대한 색조 결정은 미리 결정된 결정 세트(예를 들어, 결정 트리), 기계 학습 등을 통해 결정될 수 있다. 기계 학습의 사용에는 퍼셉트론, 피드포워드 신경 네트워크, 컨볼루션 신경 네트워크, 방사형 기저 함수 신경 네트워크 또는 순환 신경 네트워크를 포함한 신경 네트워크를 통한 지도 학습 또는 비지도 학습이 포함될 수 있다. 예를 들어, 기계 학습 모델은 지도 기계 학습을 통해 학습될 수 있다. 지도 기계 학습의 예에서는, 이미지 내에서 검출된 얼굴을 식별하는 이전 이미지 캡처의 레이블이 지정된 세트를 제공하여 기계 학습 모델을 구축할 수 있다. 이러한 얼굴은 기계 학습 모델을 트레이닝하고 색조 세트(604)를 구축하기 위해 색조 값들로 분류될 수 있다. 이러한 지도 학습을 통해, 색조 결정 모듈(114)에 입력된 검출된 얼굴은 더 정확한 색조 결정을 수신할 수 있다. 향후 색조 결정은 모델에 피드백되어 모델을 추가로 트레이닝하기 위해 올바른 결정 또는 잘못된 결정으로 마킹될 수 있다. 색조 결정 모듈(114)은 또한 검출된 얼굴(602)의 색조(606)가 색조 세트(604) 내에 있지 않다는 것을 결정하고 이를 색조 세트(604)에 추가할 수 있다.Hue set 604 may be generated through predetermined values, machine learning techniques, or any other computational method. Similarly, a hue decision for a detected face 602 may be determined through a predetermined decision set (e.g., a decision tree), machine learning, etc. Uses of machine learning may include supervised or unsupervised learning with neural networks, including perceptrons, feedforward neural networks, convolutional neural networks, radial basis function neural networks, or recurrent neural networks. For example, a machine learning model can be trained through supervised machine learning. In an example of supervised machine learning, a machine learning model can be built by providing a labeled set of previous image captures that identify faces detected within the image. These faces can be sorted by hue values to train a machine learning model and build a hue set 604. Through this supervised learning, the detected face input to the hue determination module 114 can receive a more accurate hue determination. Future hue decisions can be fed back to the model and marked as correct or incorrect to further train the model. The hue determination module 114 may also determine that the hue 606 of the detected face 602 is not within the hue set 604 and add it to the hue set 604 .
제1 검출된 얼굴(예를 들어, 제1 검출된 얼굴(502))이 검출되고 색조가 결정되면, 이전 이미지들의 그룹(702)이 검색된다. 도 7은 제1 검출된 얼굴(502)과 동일한 얼굴이 이전 이미지들의 그룹(702) 내에서 검출되는 예시적인 구현예를 도시한다. 이전 주변 조건들에서 캡처된 이전 이미지들의 그룹(702)이 검색된다. 이전 이미지들(702)은 온-디바이스 이미지 저장 및 클라우드 기반 이미지 저장을 포함하는 임의의 이미지 저장 매체로부터 검색될 수 있다. 이전 이미지들의 그룹(702)이 검색된 후, 얼굴 검출기(예를 들어, 얼굴 검출기(120))는 이전 이미지들의 그룹(702) 중 제1 검출된 얼굴(502)과 동일한 얼굴(706)(예를 들어, 동일한 얼굴(706-1), 동일한 얼굴(706-2) 및 동일한 얼굴(706-3))을 일치하는 이미지들의 그룹(704)에 포함할 것인지 결정하는데 사용된다. 이전 이미지(708-1), 이전 이미지(708-2) 및 이전 이미지(708-3)와 같이 제1 검출된 얼굴(502)과 동일한 얼굴(706)을 포함하는 것으로 결정된 이전 이미지(708)는 일치하는 이미지들의 그룹(704)에 배치된다. 일치하는 이미지들의 그룹(704)은 하나 이상의 모듈(예를 들어, AWB 모듈(112) 및 FF 모듈(118)) 또는 하나 이상의 애플리케이션(예를 들어, 카메라 애플리케이션(106))에 제공될 수 있다.Once a first detected face (e.g., first detected face 502) is detected and a color tone is determined, a group of previous images 702 is retrieved. FIG. 7 shows an example implementation in which a face identical to the first detected face 502 is detected within a group of previous images 702 . A group 702 of previous images captured at previous ambient conditions is retrieved. Previous images 702 may be retrieved from any image storage medium, including on-device image storage and cloud-based image storage. After the group of previous images 702 has been retrieved, the face detector (e.g., face detector 120) detects a face 706 (e.g. For example, the same face 706-1, the same face 706-2, and the same face 706-3) are used to determine whether to include in the group 704 of matching images. Previous image 708 determined to contain the same face 706 as the first detected face 502, such as previous image 708-1, previous image 708-2, and previous image 708-3. They are placed in a group 704 of matching images. A group of matching images 704 may be provided to one or more modules (e.g., AWB module 112 and FF module 118) or one or more applications (e.g., camera application 106).
도 8은 일치하는 이미지들의 그룹(802)이 프리커서 이미지(예를 들어, 프리커서 이미지(404)) 내의 추가 검출된 얼굴(504)과 동일한 얼굴을 포함하도록 결정되는 예시적인 구현예를 도시한다. 도 7과 유사하게, 이전 이미지들의 그룹(702)이 이미지 저장 매체로부터 검색된다. 이 예에서, 이전 이미지들의 그룹(702)은 도 7에서와 동일한 이미지들의 그룹이지만, 이 그룹은 제1 검출된 얼굴(예를 들어, 제1 검출된 얼굴(502))에 활용된 이전 이미지들의 그룹(702)과 전체적으로 또는 부분적으로 다를 수 있다. 다시, 얼굴 검출기(예를 들어, 얼굴 검출기(120))는 이전 이미지(804)가 추가 검출된 얼굴(504)과 동일한 얼굴(806)을 포함하는지 결정하는 데 사용된다. 따라서, 이전 이미지(804)는 일치하는 이미지들의 그룹(802)에 배치된다.8 shows an example implementation in which a group of matching images 802 is determined to include the same face as an additional detected face 504 in a precursor image (e.g., precursor image 404). . Similar to Figure 7, a group 702 of previous images is retrieved from the image storage medium. In this example, group of previous images 702 is the same group of images as in Figure 7, but this group is a group of previous images utilized for the first detected face (e.g., first detected face 502). It may be completely or partially different from group 702. Again, a face detector (e.g., face detector 120) is used to determine whether the previous image 804 contains the same face 806 as the additional detected face 504. Accordingly, the previous image 804 is placed in the group 802 of matching images.
도 9에서, 색조 결정 모듈(114)은 일치하는 이미지들의 그룹(예를 들어, 일치하는 이미지들의 그룹(704)) 내의 각각의 동일한 얼굴(706)(예를 들어, 동일한 얼굴(706-1), 동일한 얼굴(706-2), 동일한 얼굴(706-3))에 대한 색조(606)를 결정하는 데 사용된다. 도 6의 예시적인 구현예와 유사하게, 색조 결정 모듈(114)은 색조 세트(604)로부터 각각의 동일한 얼굴(706)에 대한 색조(606)를 결정한다. 예를 들어, 색조 결정 모듈(114)을 사용하여 동일한 얼굴(706-1)이 색조(606-1)를 갖는 것으로 결정된다. 마찬가지로, 동일한 얼굴(706-2)과 동일한 얼굴(706-3)은 동일한 색조(606-2)를 갖는 것으로 결정된다. 동일한 얼굴(706)과 연관된 이러한 색조들(606)은 하나 이상의 모듈(예를 들어, AWB 모듈(112) 및 FF 모듈(118)) 또는 하나 이상의 애플리케이션(예를 들어, 카메라 애플리케이션(106))에 제공될 수 있다.9, hue determination module 114 determines each identical face 706 (e.g., identical face 706-1) within a group of matching images (e.g., group of matching images 704). , same face 706-2, same face 706-3). Similar to the example implementation of FIG. 6 , hue determination module 114 determines a hue 606 for each same face 706 from hue set 604 . For example, the same face 706-1 is determined to have a hue 606-1 using hue determination module 114. Likewise, the same face 706-2 and the same face 706-3 are determined to have the same color tone 606-2. These hues 606 associated with the same face 706 may be associated with one or more modules (e.g., AWB module 112 and FF module 118) or one or more applications (e.g., camera application 106). can be provided.
도 10은 검출된 얼굴(예를 들어, 제1 검출된 얼굴(502))과 동일한 얼굴(706)을 포함하는 것으로 결정된 일치하는 이미지들의 그룹(704)으로부터 색조 데이터(1002)가 결정되는 예를 도시한다. 색조 데이터(1002)는 검출된 얼굴(예를 들어, 제1 검출된 얼굴(502))과 연관되고 일치하는 이미지들의 그룹(704)으로부터 결정되는 데이터 세트이다. 일치하는 이미지들의 그룹(704)은 검출된 얼굴(예를 들어, 제1 검출된 얼굴(502))과 동일한 얼굴(706)을 포함하는 것으로 결정된 이전 이미지들(708) 그룹이다. 단순화된 예에서, 색조 데이터(1002)는 더 정확한 색조(1004)로만 구성된다. 더 정확한 색조(1004)는 각각의 동일한 얼굴(706)에 대한 색조(606)를 결합함으로써 결정된다. 각각의 동일한 얼굴(706)에 대한 색조(606)는 임의의 계산 방법을 통해 결합될 수 있으며, 그 중 가장 간단한 방법은 더 정확한 색조 값을 생성하기 위해 색조를 평균화하는 것이다.10 illustrates an example in which tonal data 1002 is determined from a group of matching images 704 determined to contain the same face 706 as a detected face (e.g., first detected face 502). It shows. Hue data 1002 is a data set determined from a group of images 704 that are associated with and match a detected face (e.g., first detected face 502). The group of matching images 704 is a group of previous images 708 determined to contain the same face 706 as the detected face (e.g., the first detected face 502). In a simplified example, hue data 1002 consists only of the more accurate hue 1004. A more accurate hue 1004 is determined by combining the hues 606 for each identical face 706. The hues 606 for each identical face 706 can be combined via any computational method, the simplest of which is averaging the hues to produce more accurate hue values.
도 10의 색조 데이터(1002)와 같은 색조 데이터의 더 복잡한 예는 얼굴 프리퀀시 값(1006)을 포함한다. 얼굴 프리퀀시 값(1006)은 일치하는 이미지들의 그룹(704)에서 이전 이미지들(708)의 개수를 결정함으로써 계산된다. 광범위하게 말하면, 얼굴 프리퀀시 값(906)은 검출된 사람 얼굴(예를 들어, 제1 검출된 얼굴(502))과 동일한 사람 얼굴(706)을 포함하는 것으로 결정된 이전 이미지들(708)의 개수에 기초한다. 얼굴 프리퀀시 값(1006)은 하나 이상의 추가 검출된 얼굴(예를 들어, 추가 검출된 얼굴(504))이 프리커서 이미지 내에서 검출되는 경우에 특히 유용하다. 이러한 경우, 얼굴 프리퀀시 값(1006)은 검출된 얼굴 중 가장 중요한 얼굴(예를 들어, 제1 검출된 얼굴(502) 및 추가 검출된 얼굴(504))을 결정하는 데 사용될 수 있다.A more complex example of tonal data, such as tonal data 1002 in FIG. 10, includes facial frequency values 1006. The facial frequency value 1006 is calculated by determining the number of previous images 708 in the group of matching images 704. Broadly speaking, the face frequency value 906 is the number of previous images 708 determined to contain the same human face 706 as the detected human face (e.g., the first detected face 502). It is based on Face frequency value 1006 is particularly useful when one or more additional detected faces (e.g., additional detected faces 504) are detected within the precursor image. In this case, the face frequency value 1006 can be used to determine the most important face among the detected faces (e.g., the first detected face 502 and the additional detected face 504).
예를 들어, 얼굴 검출기는 프리커서 이미지 내에서 제1 검출된 얼굴과 추가 검출된 얼굴을 검출하여, 개시된 카메라 시스템이 프리커서 이미지 내에서 각각의 검출된 얼굴의 색조를 결정하고 각각의 검출된 얼굴에 대해 일치하는 이미지들의 그룹을 결정하도록 유도한다. 개시된 기법을 사용하여 일치하는 이미지들의 그룹은 더 정확한 색조 값과 얼굴 프리퀀시 값을 포함하는 색조 데이터를 생성한다. 프리커서 이미지 내에서 검출된 각 얼굴의 색조는 검출된 얼굴의 색조와 연관된 더 정확한 색조 사이의 차이를 최소화하는 카메라 설정 조정들을 결정하기 위해 검출된 각 얼굴과 연관된 색조 데이터의 더 정확한 색조 값과 비교된다. 이 예에서는 프리커서 이미지 내에서 검출된 각 얼굴에 대해 하나씩 두 세트의 카메라 조정들이 제공된다. 얼굴 프리퀀시 값을 사용하여 프리커서 이미지 내에서 가장 중요한 얼굴을 결정하기 위한 우선순위 값이 생성된다. 이 우선순위 값은 가중 합을 사용하여 두 세트의 카메라 조정들을 결합하는 데 사용될 수 있다. 이러한 방식으로 우선 순위 값이 가장 높은 검출된 얼굴이 가장 중요하다고 결정되면 카메라 설정 조정에 가장 큰 영향을 미친다.For example, a face detector may detect a first detected face and an additional detected face within a precursor image such that the disclosed camera system determines the color tone of each detected face within the precursor image and leads to determining a group of matching images. Groups of matching images using the disclosed techniques produce tonal data containing more accurate tonal values and facial frequency values. The hue of each face detected within the precursor image is compared to the more accurate hue value of the hue data associated with each detected face to determine camera settings adjustments that minimize the difference between the hue of the detected face and the more accurate hue associated with the face. do. In this example, two sets of camera adjustments are provided, one for each face detected within the precursor image. Using the face frequency value, a priority value is created to determine the most important face within the precursor image. This priority value can be used to combine two sets of camera adjustments using a weighted sum. In this way, the detected faces with the highest priority values are determined to be the most important and have the greatest influence on adjusting camera settings.
우선순위 값은 얼굴 프리퀀시 값에만 기초하여 우선순위 값을 할당하는 등의 다양한 방법을 통해 계산될 수 있다. 대안적으로 또는 이와 관련하여, 프리커서 이미지 내에서 검출된 얼굴의 얼굴 크기는 우선순위 값을 결정하는 데 사용될 수 있다. 특히, 얼굴 크기가 더 큰 검출된 얼굴에는 더 높은 우선순위 값이 부여된다.The priority value can be calculated through various methods, such as assigning a priority value based only on the face frequency value. Alternatively or relatedly, the facial size of the face detected within the precursor image may be used to determine the priority value. In particular, detected faces with larger face sizes are given a higher priority value.
도 11은 제1 검출된 얼굴(502)과 동일한 얼굴을 포함하는 것으로 결정된 일치하는 이미지들의 세트의 보다 복잡한 예를 도시한다. 도 7에서와 같이, 이전 이미지들의 그룹(1104)이 검색되어 제1 검출된 얼굴(502)과 동일한 얼굴(1106)(예를 들어, 동일한 얼굴(1106-1), 동일한 얼굴(1106-2), 동일한 얼굴(1106-3))을 검색한다. 다시 한번, 제1 검출된 얼굴(502)과 동일한 얼굴(1106)을 포함하는 것으로 결정된 이전 이미지들(1108)(예를 들어, 이전 이미지(1008-1), 이전 이미지(1008-2) 및 이전 이미지(1008-3))은 일치하는 이미지들의 그룹(1102)으로 수집된다. 도 7과 달리, 일치하는 이미지들의 그룹(1102)의 이전 이미지들(1108)은 조명 및 얼굴 크기와 같은 이미지 요소를 변경하는 다양한 주변 조건들(1110)에 따른 동일한 얼굴(1106)을 포함한다.Figure 11 shows a more complex example of a set of matching images determined to contain the same face as the first detected face 502. 7 , the group 1104 of previous images is searched to find a face 1106 that is the same as the first detected face 502 (e.g., same face 1106-1, same face 1106-2). , search for the same face (1106-3)). Once again, previous images 1108 determined to contain the same face 1106 as the first detected face 502 (e.g., previous image 1008-1, previous image 1008-2, and Images 1008-3) are collected into a group 1102 of matching images. Unlike Figure 7, previous images 1108 of group of matching images 1102 contain the same face 1106 subject to various ambient conditions 1110 that change image elements such as lighting and face size.
도 12는 도 11의 일치하는 이미지들의 그룹(1102)으로부터의 색조 데이터(1002)의 예를 도시한다. 도 10과 유사하게, 색조 데이터(1002)는 검출된 얼굴(예를 들어, 제1 검출된 얼굴(502))과 연관되고 일치하는 이미지들의 그룹(1102)으로부터 결정된 더 정확한 색조(1004)를 포함하는 데이터 세트이다. 색조 데이터(1002)는 또한 얼굴 프리퀀시 값(1006)을 포함할 수 있으며 일치하는 이미지들의 그룹(1102)으로부터의 이전 이미지들(1108) 내의 동일한 얼굴들(1106) 각각은 도 10에서와 같이 색조(606)와 연관된다. 도 10과 대조적으로, 이제 신뢰도 값(1202)과 색조(606)의 조합을 통해 더 정확한 색조(1004)가 결정된다. 신뢰도 값(1202)은 동일한 얼굴(1106) 각각으로부터의 색조(606) 결정의 확실성을 나타낸다.Figure 12 shows an example of tonal data 1002 from the group of matching images 1102 of Figure 11. Similar to Figure 10, hue data 1002 is associated with a detected face (e.g., first detected face 502) and includes a more accurate hue 1004 determined from a group of matching images 1102. It is a data set that does. The hue data 1002 may also include a face frequency value 1006 such that each of the same faces 1106 in previous images 1108 from the group of matching images 1102 has a hue (as in FIG. 10 ). 606). In contrast to Figure 10, a more accurate hue 1004 is now determined through a combination of the confidence value 1202 and hue 606. Confidence value 1202 indicates the certainty of determining hue 606 from each of the same face 1106.
일치하는 이미지들의 그룹(1102)은 다양한 주변 조건들(1110)에 따라 동일한 얼굴(1106)을 포함한다는 점을 상기한다. 주변 조건들(1110)로부터 수집된 얼굴 크기(1206) 및 조명(1204)과 같은 데이터를 사용하여, 신뢰도 값(1202)은 각각의 동일한 얼굴(1106)의 색조(606)에 대해 결정될 수 있다. 예를 들어, 주변 조건(1110)이 저조도 조건을 포함하는 이전 이미지들(1108)에는 상기 조명(1204)에서 색조 결정의 추가된 가변성으로 인해 낮은 신뢰도 값이 주어질 수 있다. 대안적으로 또는 이와 관련하여, 주변 조건(1110)이 작은 얼굴 크기(1206)를 포함하는 이전 이미지들(1108)에는 이미지의 더 작은 부분에서 색조 결정의 추가된 가변성으로 인해 낮은 신뢰도 값이 주어질 수 있다.Recall that the group of matching images 1102 includes the same face 1106 depending on various surrounding conditions 1110. Using data such as face size 1206 and illumination 1204 collected from ambient conditions 1110, a confidence value 1202 can be determined for the hue 606 of each same face 1106. For example, previous images 1108 where ambient conditions 1110 include low-light conditions may be given low confidence values due to the added variability of color tone determination in the illumination 1204. Alternatively or relatedly, previous images 1108 where ambient conditions 1110 include small face sizes 1206 may be given lower confidence values due to the added variability of tonal determination in smaller portions of the image. there is.
각각의 동일한 얼굴(1106)의 색조(606) 및 연관된 신뢰도(1202)가 결정된 후, 검출된 얼굴(예를 들어, 제1 검출된 얼굴(502))에 대해 더 정확한 색조(1004)가 결정될 수 있다. 더 정확한 색조(1004)는 색조(606)와 신뢰도 값(1202)의 임의의 조합을 통해 결정될 수 있다. 하나의 예시적인 조합 방법은 가중 합을 포함하며, 여기서 각각의 동일한 얼굴(1106)의 색조(606)는 연관된 신뢰도 값(1202)에 의해 가중되어 합산된다. 또 다른 예시적인 방법은 필터링을 포함하는데, 여기서 가장 높은 연관 신뢰도 값(1202)을 갖는 동일한 얼굴(1106)의 색조(606)의 서브세트만이 더 정확한 색조(1004)를 결정하는 데 사용된다. 추가적으로, 필터링은 색조(606)가 필터링된 다음 신뢰도 값(1202)에 의해 가중되도록 가중 합과 조합하여 사용될 수 있다.After the hue 606 and associated confidence 1202 for each identical face 1106 are determined, a more accurate hue 1004 may be determined for the detected face (e.g., the first detected face 502). there is. A more accurate hue 1004 may be determined through any combination of hue 606 and confidence value 1202. One exemplary combining method includes a weighted sum, where the hues 606 of each identical face 1106 are summed, weighted by the associated confidence value 1202. Another example method includes filtering, where only the subset of hues 606 of the same face 1106 with the highest associated confidence value 1202 is used to determine the more accurate hue 1004. Additionally, filtering can be used in combination with a weighted sum such that the hue 606 is filtered and then weighted by the confidence value 1202.
도 13은 전자 디바이스 내의 카메라 시스템을 위한 AWB의 예시적인 구현예를 도시한다. 검출된 얼굴(예를 들어, 제1 검출된 얼굴(502))에 대해 더 정확한 색조 결정이 이루어지면, 검출된 얼굴의 색조가 더 정확한 색조 값과 비교된다. 비교를 통해, 프리커서 이미지 내에서 검출된 얼굴의 색조와 검출된 얼굴에 대해 결정된 더 정확한 색조 사이의 WB의 차이가 결정된다. WB의 차이에 기초하여, 전자 디바이스(102)가 개선된 색조(1302)로 이미지를 캡처할 수 있도록 카메라 설정들이 조정된다. 카메라 설정 조정은 적색, 녹색 및 청색 센서 게인을 포함하는 RGB 센서 게인의 변경과 같은 개선된 색조(1302)로 이미지의 캡처를 가능하게 하는 임의의 조정을 수반할 수 있다. 그러면 카메라는 개선된 색조(1302)로 이미지를 캡처하고 이를 디스플레이(110)에 제공할 수 있다.13 shows an example implementation of AWB for a camera system within an electronic device. When a more accurate hue determination is made for a detected face (e.g., first detected face 502), the hue of the detected face is compared to the more accurate hue value. Through comparison, the difference in WB between the hue of the face detected within the precursor image and the more accurate hue determined for the detected face is determined. Based on the difference in WB, camera settings are adjusted to allow the electronic device 102 to capture an image with improved color tone 1302. Adjusting camera settings may involve making any adjustments to enable capture of images with improved color tone 1302, such as changing the RGB sensor gains, including red, green, and blue sensor gains. The camera can then capture an image with improved color 1302 and provide it to display 110.
카메라 시스템에 대한 AWB의 간단한 예에서, 프리커서 이미지 내에서 단 하나의 검출된 얼굴이 검출된다. 이와 같이 하나의 색조 데이터를 검색하여 하나의 WB의 차이를 결정하고, 하나의 WB의 차이에 기초하여 카메라 설정들이 조정된다. 그러나 더 복잡한 예에는 프리커서 이미지 내에서 하나 이상의 추가 검출된 얼굴이 포함된다. 이 예에서는 다수의 색조 데이터가 검색되고, WB의 다수의 차이가 결정되고, WB의 다수의 차이에 기초하여 카메라 설정들이 조정된다. 프리커서 이미지 내에서 제1 검출된 얼굴과 추가 검출된 각각의 얼굴에 대해 우선순위 값이 결정될 수 있다. 우선순위 값은 색조 데이터, 프리커서 이미지, 또는 이 둘의 조합에 기초하여 결정될 수 있다. 예를 들어, 검출된 얼굴과 연관된 색조 데이터가 더 높은 얼굴 프리퀀시 값을 포함하는 경우, 검출된 얼굴에는 더 높은 우선순위 값이 부여될 수 있으며, 이는 검출된 얼굴이 카메라 시스템에 의해 자주 캡처된다는 것을 나타낸다. 추가적으로 또는 별도로, 검출된 얼굴이 프리커서 이미지 내에서 더 큰 얼굴 크기를 갖는 경우, 검출된 얼굴에 더 높은 우선순위 값이 부여될 수 있다. 검출된 각 얼굴에 대해 우선순위 값이 결정되면 WB와 우선순위 값의 차이에 기초하여 카메라 설정들이 조정된다. WB와 우선순위 값의 차이는 가중 합 및 필터링을 포함한 모든 계산 방법을 통해 결합될 수 있다.In a simple example of AWB for a camera system, only one detected face is detected within the precursor image. In this way, one WB difference is determined by retrieving one color tone data, and the camera settings are adjusted based on the one WB difference. However, more complex examples include one or more additional detected faces within the precursor image. In this example, multiple tonal data is retrieved, multiple differences in WB are determined, and camera settings are adjusted based on the multiple differences in WB. A priority value may be determined for the first detected face and each additionally detected face within the precursor image. The priority value may be determined based on color tone data, precursor images, or a combination of the two. For example, if the tonal data associated with a detected face contains higher facial frequency values, the detected face may be given a higher priority value, indicating that the detected face is frequently captured by the camera system. indicates. Additionally or separately, a detected face may be given a higher priority value if the detected face has a larger face size within the precursor image. Once a priority value is determined for each detected face, camera settings are adjusted based on the difference between the WB and the priority value. Differences between WB and priority values can be combined through any computational method, including weighted summing and filtering.
특정 예에서, 제1 검출된 얼굴은 1개 내지 19개의 추가 검출된 얼굴과 함께 프리커서 이미지 내에서 검출된다. 검출된 각 얼굴에 대해 색조 데이터를 검색하고, 색조 데이터에 기초하여 AWB의 차이를 결정한다. 또한, 프리커서 이미지 내에서 검출된 각 얼굴에 대해 우선순위 값이 결정된다. 최대 20개의 검출된 얼굴은 우선순위 값을 기초로 필터링되어 AWB의 차이 및 연관 색조 데이터와 함께 검출된 얼굴의 서브세트를 생성한다. 일단 필터링되면, 카메라 설정은 WB의 차이가 우선순위 값에 의해 가중되도록 5개의 최고 우선순위 값을 갖는 검출된 얼굴 서브세트의 가중 합에 기초하여 조정될 수 있다. 검출된 얼굴 및 연관 색조 데이터는 임의의 원하는 서브세트로 필터링될 수 있으며 제공된 예는 단지 다수의 검출된 얼굴에 대한 WB의 차이를 결합하는 특정 방법을 설명하기 위해 제공된다는 점에 유의해야 한다.In a specific example, the first detected face is detected within the precursor image along with 1 to 19 additional detected faces. Hue data is retrieved for each detected face, and the difference in AWB is determined based on the hue data. Additionally, a priority value is determined for each face detected within the precursor image. Up to 20 detected faces are filtered based on priority values to create a subset of detected faces along with differences in AWB and associated hue data. Once filtered, the camera settings can be adjusted based on the weighted sum of the detected face subsets with the five highest priority values such that differences in WB are weighted by the priority values. It should be noted that the detected faces and associated hue data can be filtered into any desired subset and that the examples provided are merely to illustrate a particular method of combining differences in WB for multiple detected faces.
도 14는 다수의 이미지(예를 들어, 제1 이미지(1402) 및 추가 이미지(1404))가 서로 다른 카메라 설정 조정으로 캡처되는 전자 디바이스(102) 내의 카메라 시스템을 위한 AWB의 또 다른 예시적인 구현예를 도시한다. 일 측면에서, 제1 검출된 얼굴(502) 및 추가 검출된 얼굴(504)은 프리커서 이미지 내에서 검출된다. 각각의 검출된 얼굴에 대해 색조 데이터가 검색되어 제1 검출된 얼굴(502)과 연관된 WB의 차이 및 추가 검출된 얼굴(504)과 연관된 WB의 차이를 결정하는 데 사용된다. 카메라 설정들은 제1 검출된 얼굴(502)과 연관된 WB의 차이에 기초하여 조정되며, 이는 제1 검출된 얼굴(502)에서 개선된 색조로 제1 이미지(1402)를 캡처한다. 그 다음, 카메라 설정은 추가 검출된 얼굴(504)과 연관된 WB의 차이에 기초하여 조정되고 추가 이미지(1404)는 추가 검출된 얼굴(504)에서 개선된 색조로 캡처된다. 제1 이미지(1402) 및 추가 이미지(1404)는 동일한 카메라 또는 별도의 카메라로 캡처될 수 있고, 하나 이상의 이미지가 메모리에 저장될 수 있으며, 카메라 시스템은 조정된 카메라 설정들로 하나 이상의 추가 이미지를 캡처할 수 있다는 점에 유의해야 한다.14 illustrates another example implementation of AWB for a camera system within electronic device 102 in which multiple images (e.g., first image 1402 and additional images 1404) are captured with different camera settings adjustments. An example is shown. In one aspect, the first detected face 502 and the additional detected face 504 are detected within a precursor image. For each detected face, hue data is retrieved and used to determine the difference in WB associated with the first detected face (502) and the difference in WB associated with the additional detected face (504). Camera settings are adjusted based on the difference in WB associated with the first detected face 502 , which captures the first image 1402 with improved color tone in the first detected face 502 . Camera settings are then adjusted based on the difference in WB associated with the additional detected face 504 and additional images 1404 are captured with improved color tones on the additional detected face 504 . First image 1402 and additional images 1404 may be captured with the same camera or separate cameras, one or more images may be stored in memory, and the camera system may capture one or more additional images with adjusted camera settings. It is important to note that capture is possible.
도 15는 AWB를 수행하는 카메라 시스템의 이미지 병합 모듈(124)의 예시적인 구현예를 도시한다. 두 개의 이미지가 도시된다; 제1 이미지(1402)는 제1 검출된 얼굴(502)에서 개선된 색조를 갖고, 추가 이미지(1404)는 추가 검출된 얼굴(504)에서 개선된 색조를 갖는다. 제1 이미지(1402) 및 추가 이미지(1404)는 이미지 병합 모듈(124)에 제공된다. 이미지 병합 모듈(124)은 이미지 스티칭을 사용하여 제1 이미지(1402) 및 추가 이미지(1404)를 제1 검출된 얼굴(502)과 추가 검출된 얼굴(504)에서 개선된 색조를 갖는 단일 이미지(1504)로 통합한다. 이미지 병합 모듈(124)은 제1 검출된 얼굴(502)에 대한 제1 이미지(1402)와 추가 검출된 얼굴(504)에 대한 추가 이미지(1404)를 통합한다. 단일 이미지(1504)를 생성한 후, 전자 디바이스(102)의 디스플레이(110)에 제공되어 디지털 방식으로 디스플레이된다. 또한, 단일 이미지(1504)는 전자 디바이스 내에 저장되거나 다른 이미지 저장 매체를 통해 저장될 수 있다.Figure 15 shows an example implementation of the image merging module 124 of a camera system performing AWB. Two images are shown; The first image 1402 has improved color tone in the first detected face 502 and the additional image 1404 has improved color tone in the additional detected face 504 . The first image 1402 and the additional images 1404 are provided to the image merging module 124. The image merging module 124 uses image stitching to combine the first image 1402 and the additional images 1404 into a single image ( 1504). The image merging module 124 integrates the first image 1402 for the first detected face 502 and the additional images 1404 for the additional detected faces 504 . After generating the single image 1504, it is provided to the display 110 of the electronic device 102 and displayed digitally. Additionally, single image 1504 may be stored within an electronic device or via other image storage media.
또한, 추가 이미지가 이미지 병합 모듈(124)에 제공될 수 있고 단일 이미지(1502)는 프리커서 이미지 내에서 추가 검출된 얼굴에 대한 추가 이미지를 통합함으로써 이미지 병합 모듈(124)을 통해 생성될 수 있다. 결과적으로, 단일 이미지(1502)는 검출된 얼굴 각각에서 개선된 색조를 갖게 될 것이다.Additionally, additional images may be provided to image merging module 124 and a single image 1502 may be created through image merging module 124 by incorporating additional images for additional detected faces within the precursor image. . As a result, single image 1502 will have improved color tones for each detected face.
예시적인 방법Exemplary method
도 16은 카메라 시스템을 위한 AWB의 예시적인 방법을 도시한다. 1602에서, 검출된 얼굴은 장면의 프리커서 이미지 내에서 검출된다. 얼굴 검출은 지식 기반, 특징 기반, 템플릿 매칭, 외모 기반 얼굴 검출 등 모든 얼굴 검출 방법을 통해 수행될 수 있다.16 shows an example method of AWB for a camera system. At 1602, the detected face is detected within a precursor image of the scene. Face detection can be performed through any face detection method, including knowledge-based, feature-based, template matching, and appearance-based face detection.
1604에서, 검출된 얼굴의 색조가 프리커서 이미지 내에서 결정된다. 검출된 얼굴의 색조는 미리 결정된 색조 값들의 세트 또는 지속적으로 구축된 색조 값들의 세트로부터 결정될 수 있다. 색조 결정은 지도 학습 또는 비지도 학습을 포함한 기계 학습 방법을 통해 수행될 수 있다. 추가적으로, 색조 결정은 미리 트레이닝되거나 시간이 지남에 따라 트레이닝될 수 있다.At 1604, the hue of the detected face is determined within the precursor image. The detected hue of the face may be determined from a predetermined set of hue values or a continuously constructed set of hue values. Hue determination can be performed through machine learning methods, including supervised or unsupervised learning. Additionally, hue decisions can be pre-trained or trained over time.
1606에서, 검출된 얼굴과 연관된 색조 데이터가 검색된다. 이전 주변 조건들에서 캡처된 이전 이미지들의 그룹은 일치하는 이미지들의 그룹을 결정하는 데 사용된다. 일치하는 이미지들의 그룹은 검출된 사람의 얼굴과 동일한 얼굴을 포함하는 것으로 결정된다. 이전 이미지들 내에서 동일한 얼굴은 이전 이미지들 내에서 검출된 얼굴과 동일 또는 유사한 방법을 통해 검출될 수 있다. 색조 데이터는 더 정확한 색조 값을 결정하는 데 사용할 수 있는 색조들을 포함하지만, 색조 데이터는 이전 이미지들과 이전 이미지들 자체 내의 동일한 얼굴에 대한 추가 데이터를 포함할 수도 있다. 이 데이터는 이전 이미지 내 동일한 얼굴의 크기 및 이전 이미지 내 조명과 같은 주변 조건들을 포함할 수 있다. 예로서, 주변 조건들은 각각의 이전 이미지들에서 동일한 얼굴과 연관된 색조에 대한 신뢰도 값을 결정하는 데 사용될 수 있다. 더 정확한 색조를 결정하기 위해 동일한 얼굴의 색조와 결합하여 신뢰도 값이 사용될 수 있다. 추가적으로, 색조 데이터는 검출된 얼굴과 연관된 얼굴 프리퀀시 값과 같은 우선순위 값의 결정을 어시스트하는 데 사용가능한 데이터를 포함할 수 있다.At 1606, hue data associated with the detected face is retrieved. A group of previous images captured at previous ambient conditions is used to determine the group of matching images. The group of matching images is determined to contain the same face as the detected human face. The same face in previous images may be detected through the same or similar method as the face detected in previous images. Hue data contains hues that can be used to determine more accurate hue values, but hue data may also include additional data about the same face in previous images and within the previous images themselves. This data may include ambient conditions such as the size of the same face in the previous image and lighting in the previous image. As an example, ambient conditions can be used to determine a confidence value for a hue associated with the same face in each previous image. The confidence value can be used in combination with the hue of the same face to determine a more accurate hue. Additionally, tonal data may include data that can be used to assist in the determination of priority values, such as facial frequency values associated with a detected face.
1608에서, 검출된 얼굴의 색조와 색조 데이터 사이의 WB의 차이가 결정된다. 이러한 차이는 검출된 얼굴의 색조와 색조 데이터로부터의 더 정확한 색조 사이의 차이에 전적으로 또는 부분적으로 기초하여 결정될 수 있다. WB의 차이는 프리커서 이미지에서 검출된 얼굴의 색조를 색조 데이터의 더 정확한 색조에 맞추기 위해 카메라 설정에서 결정된 차이이다. WB의 차이는 적색, 녹색 및 청색 센서를 포함하는 RGB 센서 게인 값의 변화로 표현될 수 있다.At 1608, the difference in WB between the detected hue of the face and the hue data is determined. This difference may be determined based entirely or in part on the difference between the detected hue of the face and a more accurate hue from hue data. The difference in WB is a difference determined in the camera settings to match the color tone of the face detected in the precursor image to a more accurate color tone in the color tone data. Differences in WB can be expressed as changes in RGB sensor gain values, including red, green, and blue sensors.
1610에서, WB의 차이에 기초하여 카메라 설정들이 조정된다. 카메라 설정 조정은 RGB 센서 게인을 포함한 카메라 센서 게인 값 조정을 포함할 수 있다. 카메라 설정들을 조정함으로써, 카메라 시스템은 예를 들어 카메라 설정들이 조정되지 않았다면 캡처되었을 장면의 이미지와 비교하여 개선된 색조를 갖는 장면의 이미지를 캡처할 수 있다. 또한, 카메라 설정들을 조정하면 카메라가 개선된 색조의 장면 이미지를 캡처할 수 있다. 캡처된 이미지는 디스플레이에 제공되어 디지털 방식으로 디스플레이되거나, 전자 디바이스에 저장되거나, 둘 다로 제공될 수 있다.At 1610, camera settings are adjusted based on the difference in WB. Adjusting camera settings may include adjusting camera sensor gain values, including RGB sensor gain. By adjusting the camera settings, the camera system can capture an image of a scene with improved color tone, for example, compared to an image of the scene that would have been captured if the camera settings had not been adjusted. Additionally, adjusting camera settings allows the camera to capture scene images with improved color tone. The captured image may be provided to a display and displayed digitally, stored on an electronic device, or both.
도 17은 하나 이상의 추가 검출된 얼굴이 프리커서 이미지 내에서 검출되는 카메라 시스템을 위한 AWB의 예시적인 방법을 도시한다. 도 16에 도시된 방법과 유사하게, 1602에서 검출된 얼굴이 프리커서 이미지 내에서 검출된다. 1604에서, 프리커서 이미지 내에서 검출된 얼굴에 대한 색조가 결정되고 검출된 얼굴과 연관된 색조 데이터가 검색된다. 1608에서, 검출된 얼굴의 색조와 검출된 얼굴과 연관된 색조 데이터 사이의 WB의 차이가 결정된다. 도 16과 달리, 검출된 얼굴에 대한 우선순위 값이 결정된다. 우선순위 값은 프리커서 이미지 내에서 검출된 얼굴의 중요도를 결정하는 데 사용된다. 우선순위 값은 색조 데이터, 프리커서 이미지, 또는 이 둘의 조합에 기초하여 결정될 수 있다. 예를 들어, 검출된 얼굴과 연관된 색조 데이터가 더 높은 얼굴 프리퀀시 값을 포함하는 경우, 검출된 얼굴에는 더 높은 우선순위 값이 주어질 수 있으며, 이는 검출된 얼굴이 카메라 시스템에 의해 종종 캡처된다는 것을 나타낸다. 추가적으로 또는 별도로, 검출된 얼굴이 프리커서 이미지 내에서 더 큰 얼굴 크기를 갖는 경우, 검출된 얼굴에 더 높은 우선순위 값이 부여될 수 있다.17 illustrates an example method of AWB for a camera system where one or more additional detected faces are detected within a precursor image. Similar to the method shown in Figure 16, at 1602 the detected face is detected within the precursor image. At 1604, a hue for a face detected within the precursor image is determined and hue data associated with the detected face is retrieved. At 1608, the difference in WB between the hue of the detected face and hue data associated with the detected face is determined. Unlike Figure 16, priority values for detected faces are determined. The priority value is used to determine the importance of the face detected within the precursor image. The priority value may be determined based on color tone data, precursor images, or a combination of the two. For example, a detected face may be given a higher priority value if the tonal data associated with the detected face contains higher facial frequency values, indicating that the detected face is often captured by the camera system. . Additionally or separately, a detected face may be given a higher priority value if the detected face has a larger face size within the precursor image.
선택적으로, 1702에서, 프리커서 이미지 내에서 추가 얼굴이 검출될 수 있다. 1604에서, 추가 얼굴에 대한 색조가 결정되고, 추가 얼굴과 연관된 색조 데이터가 1606에서 검색될 것이다. 1608에서, AWB의 추가 차이는 프리커서 이미지 내에서 추가 검출된 얼굴의 색조와 추가 검출된 얼굴과 연관된 색조 데이터의 차이에 기초하여 결정될 것이다. 1704에서, 추가 검출된 얼굴의 우선순위 값이 결정된다. 방법은 선택적으로 1702에서 프리커서 이미지 내의 추가 얼굴을 검출하고 추가 검출된 얼굴에 대한 단계를 반복하거나 1610에서 카메라 설정들을 조정할 수 있다. 카메라 설정들을 조정하는 경우, 검출된 얼굴과 추가 검출된 얼굴의 WB의 차이와 우선순위 값을 조합하여 조정이 이루어질 수 있다. WB와 우선순위 값의 차이는 가중 합 및 필터링을 포함한 모든 계산 방법을 통해 결합될 수 있다.Optionally, at 1702, additional faces may be detected within the precursor image. At 1604, hues for additional faces will be determined, and hue data associated with the additional faces will be retrieved at 1606. At 1608, a further difference in AWB will be determined based on the difference between the hue of the additional detected face within the precursor image and the hue data associated with the additional detected face. At 1704, priority values for additional detected faces are determined. The method may optionally detect additional faces within the precursor image at 1702 and repeat the steps for additional detected faces or adjust camera settings at 1610. When adjusting camera settings, adjustment can be made by combining the priority value and the difference in WB between the detected face and the additionally detected face. Differences between WB and priority values can be combined through any computational method, including weighted summing and filtering.
도 18은 하나 이상의 추가 검출된 얼굴이 프리커서 이미지 내에서 검출되는 카메라 시스템을 위한 AWB의 또 다른 예시적인 방법을 도시한다. 도 17에서와 같이, 1602에서 프리커서 이미지 내에서 제1 얼굴이 검출되고, 1604에서 프리커서 이미지 내에서 검출된 얼굴에 대한 색조가 결정된다. 1606에서, 검출된 얼굴과 연관된 색조 데이터가 검색되고, 프리커서 이미지 내의 검출된 얼굴의 색조와 검출된 얼굴과 연관된 색조 데이터 사이의 WB의 차이가 결정된다. 그러나 우선순위 값은 결정되지 않는다. 대신, 1802에서 검출된 얼굴의 색조가 개선된 제1 이미지가 WB의 차이에 기초하여 조정된 카메라 설정으로 캡처된다. 추가 검출된 얼굴은 1702에서 프리커서 이미지 내에서 검출되고, 추가 검출된 얼굴에 대해 위의 단계가 반복된다. 따라서, 1608에서, 추가 검출된 얼굴의 색조 및 추가 검출된 얼굴과 연관된 색조 데이터에 기초하여 WB의 추가 차이가 결정된다. 1802에서, WB의 추가 차이에 기초하여 조정된 카메라 설정들로 추가 이미지가 캡처된다. 추가 이미지에서는 추가 검출된 얼굴의 색조가 개선되었다. 추가 검출된 얼굴이 프리커서 이미지 내에서 검출될 수 있으며 단계가 반복될 수 있다.18 shows another example method of AWB for a camera system where one or more additional detected faces are detected within the precursor image. As shown in FIG. 17 , a first face is detected within the precursor image at 1602, and a color tone for the face detected within the precursor image is determined at 1604. At 1606, hue data associated with the detected face is retrieved, and the difference in WB between the hue of the detected face in the precursor image and the hue data associated with the detected face is determined. However, the priority value is not determined. Instead, at 1802, a first image with enhanced color tones of the detected face is captured with camera settings adjusted based on the difference in WB. Additional detected faces are detected within the precursor image at 1702, and the above steps are repeated for the additional detected faces. Accordingly, at 1608, an additional difference in WB is determined based on the hue of the additional detected face and the hue data associated with the additional detected face. At 1802, additional images are captured with camera settings adjusted based on additional differences in WB. In additional images, the color tone of additional detected faces was improved. Additional detected faces may be detected within the precursor image and the steps may be repeated.
1804에서, 제1 이미지와 추가 이미지가 이미지 병합 모듈에 제공된다. 이미지 병합 모듈은 제1 이미지와 추가 이미지를 결합하여 색조가 개선된 단일 이미지를 생성한다. 예를 들어, 이미지 병합 모듈은 검출된 얼굴에 대한 제1 이미지와 추가 검출된 얼굴에 대한 추가 이미지를 통합할 수 있다. 결과적으로, 생성된 단일 이미지는 검출된 얼굴과 추가 검출된 얼굴의 색조가 개선될 수 있다. 단일 이미지는 디스플레이에 제공되어 디지털 방식으로 디스플레이되거나, 전자 디바이스에 저장되거나, 둘 다로 제공될 수 있다.At 1804, the first image and additional images are provided to an image merging module. The image merge module combines the first image and the additional images to produce a single, tonally enhanced image. For example, the image merging module may merge a first image for a detected face with an additional image for an additional detected face. As a result, the single image generated may have improved color tones for the detected face and additional detected faces. A single image may be provided to a display and displayed digitally, stored on an electronic device, or both.
일반적으로, 여기에 설명된 임의의 구성요소, 모듈, 방법 및 동작은 소프트웨어, 펌웨어, 하드웨어(예를 들어, 고정 논리 회로), 수동 처리 또는 이들의 임의의 조합을 사용하여 구현될 수 있다. 예시적인 방법의 일부 동작은 컴퓨터 프로세싱 시스템에 로컬 및/또는 원격인 컴퓨터 판독가능 저장 메모리에 저장된 실행가능한 명령어들의 일반적인 맥락에서 설명될 수 있으며, 구현에는 소프트웨어 애플리케이션, 프로그램, 기능 등이 포함될 수 있다. 대안적으로 또는 추가적으로, 여기에 설명된 기능 중 임의의 기능은 필드 프로그래밍가능 게이트 어레이(FPGA), 애플리케이션 특정 집적 회로(ASIC), 애플리케이션 특정 표준 제품(ASSP), 시스템 온 칩 시스템(SoC), 복합 프로그래밍가능 논리 디바이스(CPLD) 등을 포함하되 이에 국한되지 않는 하나 이상의 하드웨어 논리 구성요소에 의해 적어도 부분적으로 수행될 수 있다.In general, any of the components, modules, methods and operations described herein may be implemented using software, firmware, hardware (e.g., hard logic circuitry), manual processing, or any combination thereof. Some operations of example methods may be described in the general context of executable instructions stored in computer-readable storage memory, local and/or remote to a computer processing system, and implementations may include software applications, programs, functions, etc. Alternatively or additionally, any of the features described herein may be incorporated into a field programmable gate array (FPGA), an application-specific integrated circuit (ASIC), an application-specific standard product (ASSP), a system-on-a-chip (SoC), a complex It may be performed at least in part by one or more hardware logic components, including but not limited to a programmable logic device (CPLD), etc.
일부 예가 아래에 설명된다:Some examples are explained below:
실시 예 1: 전자 디바이스의 카메라 시스템에서 자동 화이트 밸런스(AWB)를 위한 방법으로서, 방법은: 프리커서(precursor) 이미지 내에서 제1 사람 얼굴을 검출하는 단계; 프리커서 이미지 내에서 제1 검출된 사람 얼굴의 제1 색조(tone)를 결정하는 단계; 제1 검출된 사람 얼굴과 연관된 제1 색조 데이터(tonal data)를 검색하는 단계, 제1 색조 데이터는 이전 주변 조건들에서 캡처된 이전 이미지들의 그룹으로부터 결정되고, 이전 이미지들은 제1 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정되며; 제1 색조 데이터에 기초하여, 프리커서 이미지 내에서 제1 검출된 사람 얼굴의 제1 색조와 제1 색조 데이터 사이의 화이트 밸런스(WB)의 제1 차이를 결정하는 단계; 및 WB의 제1 차이에 기초하여 카메라 설정들을 조정하는 단계를 포함하고, 조정하는 단계는 개선된 색조를 갖는 이미지의 캡처를 가능하게 한다.Example 1: A method for automatic white balance (AWB) in a camera system of an electronic device, comprising: detecting a first human face in a precursor image; determining a first tone of a first detected human face in the precursor image; Retrieving first tonal data associated with the first detected human face, the first tonal data being determined from a group of previous images captured at previous ambient conditions, wherein the previous images are associated with the first detected human face. is determined to contain the same human face as; Based on the first hue data, determining a first difference in white balance (WB) between the first hue data and the first hue of the first detected human face in the precursor image; and adjusting camera settings based on the first difference in WB, wherein adjusting allows capture of an image with improved color tone.
실시 예 2: 실시 예 1에 있어서, 프리커서 이미지 내에서 추가 사람 얼굴을 검출하는 단계; 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 색조를 결정하는 단계; 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터를 검색하는 단계, 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터는 이전 주변 조건들에서 캡처된 이전 이미지들의 다른 그룹으로부터 결정되고, 이전 이미지들의 다른 그룹은 추가 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정되며; 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터에 기초하여, 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 색조와 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터 사이의 AWB의 추가 차이를 결정하는 단계를 더 포함하고; 그리고 여기서 카메라 설정들을 조정하는 단계는 WB의 제1 차이와 WB의 추가 차이에 기초한다.Example 2: The method of Example 1, comprising: detecting additional human faces within a precursor image; determining additional color tones of additional detected human faces within the precursor image; Retrieving additional tonal data associated with the additional detected human face, wherein the additional tonal data associated with the additional detected human face is determined from another group of previous images captured at previous ambient conditions, the other group of previous images being further detected. It is determined that it contains the same human face as the human face shown; further comprising determining, based on the additional tonal data associated with the additionally detected human face, an additional difference in AWB between the additional tonal data of the additionally detected human face and the additional tonal data associated with the additionally detected human face within the precursor image. Contains; And here the step of adjusting the camera settings is based on the first difference in WB and the further difference in WB.
실시 예 3: 실시 예 2에 있어서, 프리커서 이미지 내에서 제1 검출된 사람 얼굴의 제1 우선순위 값을 결정하는 단계; 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 우선순위 값을 결정하는 단계를 더 포함하고, 그리고 여기서 카메라 설정들을 조정하는 단계는 제1 우선순위 값에 의해 가중된 WB의 제1 차이와 추가 우선순위 값에 의해 가중된 WB의 추가 차이의 가중 합에 더 기초한다.Example 3: The method of Example 2, comprising: determining a first priority value of a first detected human face within a precursor image; further comprising determining an additional priority value for an additional detected human face in the precursor image, wherein adjusting the camera settings determines the additional priority value and the first difference in WB weighted by the first priority value. It is further based on the weighted sum of the additional differences of the WB weighted by the rank values.
실시 예 4: 실시 예 3에 있어서, 제1 우선순위 값을 결정하는 단계는 프리커서 이미지 내에서 제1 검출된 사람 얼굴의 제1 크기에 기초하고; 그리고 추가 우선순위 값을 결정하는 단계는 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 크기에 기초한다.Example 4: The method of Example 3, wherein determining the first priority value is based on a first size of the first detected human face within the precursor image; And the step of determining the additional priority value is based on the size of the additionally detected human face within the precursor image.
실시 예 5: 실시 예 3에 있어서, 제1 우선순위 값을 결정하는 단계는 제1 결정된 얼굴 프리퀀시(face-frequency) 값에 기초하고, 제1 결정된 얼굴 프리퀀시 값은 제1 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정된 이전 이미지들의 그룹에서 이전 이미지들의 수량에 기초하며, 그리고 추가 우선순위 값을 결정하는 단계는 추가 검출된 사람 얼굴의 추가 결정된 얼굴 프리퀀시 값에 기초하고, 추가 검출된 사람 얼굴의 추가 결정된 얼굴 프리퀀시 값은 추가 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정된 이전 이미지들의 다른 그룹에서 이전 이미지들의 수량에 기초한다.Example 5: The method of Example 3, wherein determining the first priority value is based on a first determined face-frequency value, and the first determined face-frequency value is the same as the first detected human face. Based on the quantity of previous images in the group of previous images determined to contain a human face, and determining the additional priority value is based on the additional determined face frequency value of the additional detected human face, The additionally determined face frequency value of is based on the quantity of previous images in another group of previous images determined to contain the same human face as the additionally detected human face.
실시 예 6: 실시 예 2에 있어서, 추가 사람 얼굴을 검출하는 단계는 최대 19명의 사람 얼굴을 검출하는 것을 포함하고, 그리고 추가 우선순위 값을 결정하는 단계는 최대 19개의 우선순위 값을 결정하는 것을 포함한다.Example 6: The method of Example 2, wherein detecting additional human faces includes detecting up to 19 human faces, and determining additional priority values includes determining up to 19 priority values. Includes.
실시 예 7: 실시 예 1에 있어서, 카메라 설정들을 조정하는 단계는 전자 디바이스로 하여금 개선된 색조로 제1 검출된 사람 얼굴을 갖는 제1 이미지를 캡처하게 하고, 방법은: 프리커서 이미지 내에서 추가 사람 얼굴을 검출하는 단계; 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 색조를 결정하는 단계; 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터를 검색하는 단계, 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터는 이전 주변 조건들에서 캡처된 이전 이미지들의 다른 그룹으로부터 결정되고, 이전 이미지들의 다른 그룹은 추가 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정되며; 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터에 기초하여, 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 색조와 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터 사이의 AWB의 추가 차이를 결정하는 단계; 전자 디바이스로 하여금 또 다른 개선된 색조로 추가 검출된 사람 얼굴을 갖는 추가 이미지를 캡처하게 하는 WB의 추가 차이에 기초하여 카메라 설정들을 조정하는 단계; 제1 검출된 사람 얼굴에 대한 제1 이미지와 추가 검출된 사람 얼굴에 대한 추가 이미지를 통합하는 단일 이미지를 생성하기 위해 이미지 병합 모듈에 제1 이미지 및 추가 이미지를 제공하는 단계를 더 포함한다.Example 7: The method of Example 1, wherein adjusting camera settings causes the electronic device to capture a first image having a first detected human face with improved color tone, the method comprising: adding within a precursor image detecting a human face; determining additional color tones of additional detected human faces within the precursor image; Retrieving additional tonal data associated with the additional detected human face, wherein the additional tonal data associated with the additional detected human face is determined from another group of previous images captured at previous ambient conditions, the other group of previous images being further detected. It is determined that it contains the same human face as the human face shown; based on the additional hue data associated with the additionally detected human face, determining a further difference in AWB between the additional hue of the additionally detected human face and the additional hue data associated with the additionally detected human face within the precursor image; adjusting camera settings based on the additional difference in WB to cause the electronic device to capture additional images with additional detected human faces at another improved color tone; The method further includes providing the first image and the additional images to an image merging module to generate a single image that integrates the first image for the first detected human face and the additional images for the additional detected human faces.
실시 예 8: 실시 예 1에 있어서, 제1 색조 데이터는 신뢰도 값을 포함하고, 신뢰도 값은: 제1 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정된 이전 이미지들 내에서 제1 검출된 사람 얼굴과 동일한 사람 얼굴의 얼굴 크기; 또는 제1 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정된 이전 이미지들 내의 주변 광 조건들에 기초한다.Example 8: The method of Example 1, wherein the first hue data includes a confidence value, wherein the confidence value is: the first detected person within previous images determined to contain the same human face as the first detected person face. Face size of the same human face as the face; or based on ambient light conditions in previous images determined to contain the same human face as the first detected human face.
실시 예 9: 실시 예 8에 있어서, WB의 제1 차이를 결정하는 단계는 필터링된 제1 색조 데이터에 기초하고, 필터링된 제1 색조 데이터는 신뢰도 값에 의해 필터링된 제1 색조 데이터의 서브세트이다.Example 9: The method of Example 8, wherein determining the first difference in WB is based on filtered first hue data, and the filtered first hue data is a subset of the filtered first hue data by a confidence value. am.
실시 예 10: 실시 예 8에 있어서, WB의 제1 차이를 결정하는 단계는 신뢰도 값에 의해 가중된 제1 색조 데이터의 가중 합에 기초한다.Example 10: The method of Example 8, wherein determining the first difference in WB is based on a weighted sum of the first hue data weighted by a confidence value.
실시 예 11: 실시 예 1에 있어서, 프리커서 이미지 내에서 제1 사람 얼굴을 검출하는 단계는 액추에이터에 의해 개시된다.Example 11: The method of Example 1, wherein detecting a first person's face within a precursor image is initiated by an actuator.
실시 예 12: 실시 예 1에 있어서, 카메라 설정들을 조정하는 단계는 전자 디바이스로 하여금 개선된 색조를 갖는 이미지를 캡처하게 한다.Example 12: The method of Example 1, wherein adjusting camera settings causes the electronic device to capture an image with improved color tone.
실시 예 13: 실시 예 12에 있어서, 개선된 색조를 갖는 이미지를 디스플레이에 제공하는 단계를 더 포함한다.Example 13: The method of Example 12 further comprising providing an image with improved color tone to a display.
실시 예 14: 실시 예 1에 있어서, 카메라 설정들을 조정하는 단계는: 적색 센서 게인; 녹색 센서 게인; 또는 청색 센서 게인을 조정하는 것을 포함한다.Example 14: The method of Example 1, wherein adjusting camera settings included: red sensor gain; Green Sensor Gain; or adjusting the blue sensor gain.
실시 예 15: 실시 예 1에 있어서, 제1 사람 얼굴을 검출하는 단계는 저해상도 센서를 사용하는 것을 포함한다.Example 15: The method of Example 1, wherein detecting a first person's face includes using a low resolution sensor.
실시 예 16: 자동 화이트 밸런스(AWB)를 수행할 수 있는 전자 디바이스의 카메라 시스템으로서, 카메라 시스템은: 프로세서; 컴퓨터 판독가능 매체; 프리커서 이미지를 캡처할 수 있는 센서; 이미지 내에서 사람 얼굴을 검출할 수 있는 얼굴 프리퀀시 모듈; 이전 이미지들을 저장할 수 있는 저장소; 검출된 사람 얼굴의 색조를 결정할 수 있는 색조 결정 모듈; 및 카메라(320) 설정들을 조정할 수 있는 화이트 밸런스 컨트롤러(116)를 포함한다.Example 16: A camera system in an electronic device capable of performing automatic white balance (AWB), the camera system comprising: a processor; computer-readable media; A sensor capable of capturing a precursor image; A face frequency module capable of detecting human faces within an image; Storage for storing previous images; A hue determination module capable of determining the hue of a detected human face; and a white balance controller 116 that can adjust camera 320 settings.
결론conclusion
카메라 시스템을 위한 AWB의 측면이 특징 및/또는 방법에 특정한 언어로 설명되었지만, 첨부된 청구범위의 주제는 반드시 설명된 특정 특징 또는 방법으로 제한되지는 않는다. 오히려, 특정 특징 및 방법은 카메라 시스템에 대해 청구된 AWB의 예시적인 구현예로서 개시되고, 다른 동등한 특징 및 방법은 첨부된 청구범위의 범위 내에 있도록 의도된다. 또한, 다양한 측면이 설명되며, 각각의 설명된 측면은 독립적으로 또는 하나 이상의 다른 설명된 측면과 관련하여 구현될 수 있다는 것이 이해되어야 한다.Although aspects of AWB for camera systems have been described in language specific to features and/or methods, the subject matter of the appended claims is not necessarily limited to the specific features or methods described. Rather, certain features and methods are disclosed as example implementations of the claimed AWB for camera systems, and other equivalent features and methods are intended to be within the scope of the appended claims. Additionally, it should be understood that various aspects are described and that each described aspect can be implemented independently or in conjunction with one or more other described aspects.
Claims (18)
프리커서(precursor) 이미지 내에서 제1 사람 얼굴을 검출하는 단계(1602);
프리커서 이미지 내에서 제1 검출된 사람 얼굴의 제1 색조(tone)를 결정하는 단계(1604);
제1 검출된 사람 얼굴과 연관된 제1 색조 데이터(tonal data)를 검색하는 단계(1606), 상기 제1 색조 데이터는 이전 주변 조건들에서 캡처된 이전 이미지들의 그룹으로부터 결정되고, 이전 이미지들은 제1 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정되며;
상기 제1 색조 데이터에 기초하여, 프리커서 이미지 내에서 제1 검출된 사람 얼굴의 제1 색조와 상기 제1 색조 데이터 사이의 화이트 밸런스(WB)의 제1 차이를 결정하는 단계(1608); 및
WB의 제1 차이에 기초하여 카메라 설정들을 조정(1610)하는 단계를 포함하고, 상기 조정하는 단계는 개선된 색조를 갖는 이미지의 캡처를 가능하게 하며, 개선된 색조는 제1 색조보다 상기 제1 색조 데이터와 더 밀접하게 일치하는, 방법.A method for automatic white balance (AWB) in a camera system of an electronic device, the method comprising:
Detecting a first human face within a precursor image (1602);
determining a first tone of the first detected human face within the precursor image (1604);
Retrieving 1606 first tonal data associated with the first detected human face, the first tonal data being determined from a group of previous images captured at previous ambient conditions, the previous images being the first tonal data It is determined that it contains the same human face as the detected human face;
Based on the first hue data, determining a first difference in white balance (WB) between the first hue data and a first hue of a first detected human face in a precursor image (1608); and
adjusting (1610) camera settings based on the first difference in WB, wherein adjusting enables capture of an image with improved color tone, wherein the improved color tone is greater than the first color tone. method, which more closely matches the tonal data.
프리커서 이미지 내에서 추가 사람 얼굴을 검출하는 단계;
프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 색조를 결정하는 단계;
추가 검출된 사람 얼굴과 연관된 추가 색조 데이터를 검색하는 단계, 상기 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터는 이전 주변 조건들에서 캡처된 이전 이미지들의 다른 그룹으로부터 결정되고, 이전 이미지들의 다른 그룹은 추가 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정되며;
상기 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터에 기초하여, 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 색조와 상기 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터 사이의 AWB의 추가 차이를 결정하는 단계를 더 포함하고; 그리고
상기 카메라 설정들을 조정하는 단계는 WB의 제1 차이와 WB의 추가 차이에 기초하는, 방법.According to paragraph 1,
detecting additional human faces within the precursor image;
determining additional color tones of additional detected human faces within the precursor image;
Retrieving additional tonal data associated with the additional detected human face, wherein the additional tonal data associated with the additional detected human face is determined from another group of previous images captured at previous ambient conditions, wherein the other group of previous images is further It is determined that it contains the same human face as the detected human face;
Based on the additional color tone data associated with the additionally detected human face, determining an additional difference in AWB between the additional color tone of the additionally detected human face in a precursor image and the additional color tone data associated with the additionally detected human face. It further includes; and
The method of claim 1, wherein adjusting camera settings is based on a first difference in WB and a further difference in WB.
프리커서 이미지 내에서 제1 검출된 사람 얼굴의 제1 우선순위 값을 결정하는 단계; 및
프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 우선순위 값을 결정하는 단계를 더 포함하고,
상기 카메라 설정들을 조정하는 단계는 제1 우선순위 값에 의해 가중된 WB의 제1 차이와 추가 우선순위 값에 의해 가중된 WB의 추가 차이의 가중 합에 더 기초하는, 방법.According to paragraph 2,
determining a first priority value of a first detected human face within the precursor image; and
Further comprising determining an additional priority value of an additionally detected human face in the precursor image,
wherein the step of adjusting camera settings is further based on a weighted sum of a first difference in WB weighted by a first priority value and a further difference in WB weighted by an additional priority value.
제1 우선순위 값을 결정하는 단계는 프리커서 이미지 내에서 제1 검출된 사람 얼굴의 제1 크기에 기초하고; 그리고
추가 우선순위 값을 결정하는 단계는 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 크기에 기초하는, 방법.According to paragraph 3,
Determining the first priority value is based on a first size of the first detected human face within the precursor image; and
The method wherein determining the additional priority value is based on the size of the additionally detected human face within the precursor image.
제1 우선순위 값을 결정하는 단계는 제1 결정된 얼굴 프리퀀시(face-frequency) 값에 기초하고, 상기 제1 결정된 얼굴 프리퀀시 값은 제1 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정된 이전 이미지들의 그룹에서 이전 이미지들의 수량에 기초하며, 그리고
추가 우선순위 값을 결정하는 단계는 추가 검출된 사람 얼굴의 추가 결정된 얼굴 프리퀀시 값에 기초하고, 상기 추가 검출된 사람 얼굴의 추가 결정된 얼굴 프리퀀시 값은 추가 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정된 이전 이미지들의 다른 그룹에서 이전 이미지들의 수량에 기초하는, 방법.According to paragraph 3,
Determining a first priority value is based on a first determined face-frequency value, wherein the first determined face-frequency value is a previous image determined to contain the same human face as the first detected human face. based on the quantity of previous images in the group, and
The step of determining an additional priority value is based on an additionally determined face frequency value of the additionally detected human face, wherein the additionally determined face frequency value of the additionally detected human face includes the same human face as the additionally detected human face. A method based on the quantity of previous images in different groups of previous images determined.
추가 사람 얼굴을 검출하는 단계는 최대 19명의 사람 얼굴을 검출하는 것을 포함하고, 그리고
추가 우선순위 값을 결정하는 단계는 최대 19개의 우선순위 값을 결정하는 것을 포함하는, 방법.According to any one of claims 2 to 5,
Detecting additional human faces includes detecting up to 19 human faces, and
Wherein determining additional priority values includes determining up to 19 priority values.
상기 카메라 설정들을 조정하는 단계는 전자 디바이스로 하여금 개선된 색조로 제1 검출된 사람 얼굴을 갖는 제1 이미지를 캡처하게 하고, 상기 방법은:
프리커서 이미지 내에서 추가 사람 얼굴을 검출하는 단계;
프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 색조를 결정하는 단계;
추가 검출된 사람 얼굴과 연관된 추가 색조 데이터를 검색하는 단계, 상기 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터는 이전 주변 조건들에서 캡처된 이전 이미지들의 다른 그룹으로부터 결정되고, 이전 이미지들의 다른 그룹은 추가 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정되며;
상기 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터에 기초하여, 프리커서 이미지 내에서 추가 검출된 사람 얼굴의 추가 색조와 상기 추가 검출된 사람 얼굴과 연관된 추가 색조 데이터 사이의 AWB의 추가 차이를 결정하는 단계;
전자 디바이스로 하여금 또 다른 개선된 색조로 추가 검출된 사람 얼굴을 갖는 추가 이미지를 캡처하게 하는 WB의 추가 차이에 기초하여 카메라 설정들을 조정하는 단계; 및
제1 검출된 사람 얼굴에 대한 제1 이미지와 추가 검출된 사람 얼굴에 대한 추가 이미지를 통합하는 단일 이미지를 생성하기 위해 이미지 병합 모듈에 제1 이미지 및 추가 이미지를 제공하는 단계를 더 포함하는, 방법.According to paragraph 1,
Adjusting the camera settings causes the electronic device to capture a first image having a first detected human face with improved color tone, the method comprising:
detecting additional human faces within the precursor image;
determining additional color tones of additional detected human faces within the precursor image;
Retrieving additional tonal data associated with the additional detected human face, wherein the additional tonal data associated with the additional detected human face is determined from another group of previous images captured at previous ambient conditions, wherein the other group of previous images is further It is determined that it contains the same human face as the detected human face;
Based on the additional color tone data associated with the additionally detected human face, determining an additional difference in AWB between the additional color tone of the additionally detected human face in a precursor image and the additional color tone data associated with the additionally detected human face. ;
adjusting camera settings based on the additional difference in WB to cause the electronic device to capture additional images with additional detected human faces at another improved color tone; and
The method further comprising providing the first image and the additional images to an image merging module to produce a single image that integrates the first image for the first detected human face and the additional images for the additional detected human faces. .
상기 제1 색조 데이터는 신뢰도 값을 포함하고, 상기 신뢰도 값은:
제1 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정된 이전 이미지들 내에서 제1 검출된 사람 얼굴과 동일한 사람 얼굴의 얼굴 크기; 또는
제1 검출된 사람 얼굴과 동일한 사람 얼굴을 포함하는 것으로 결정된 이전 이미지들 내의 주변 광 조건들에 기초하는, 방법.In any preceding clause,
The first hue data includes a confidence value, the confidence value being:
a face size of a human face identical to the first detected human face within previous images determined to contain the same human face as the first detected human face; or
A method based on ambient light conditions in previous images determined to contain the same human face as the first detected human face.
WB의 제1 차이를 결정하는 단계는 필터링된 제1 색조 데이터에 기초하고, 상기 필터링된 제1 색조 데이터는 상기 신뢰도 값에 의해 필터링된 상기 제1 색조 데이터의 서브세트인, 방법.According to clause 8,
The method of claim 1, wherein determining the first difference in WB is based on filtered first hue data, wherein the filtered first hue data is a subset of the filtered first hue data by the confidence value.
WB의 제1 차이를 결정하는 단계는 상기 신뢰도 값에 의해 가중된 상기 제1 색조 데이터의 가중 합에 기초하는, 방법.According to clause 8,
Wherein determining the first difference in WB is based on a weighted sum of the first hue data weighted by the confidence value.
프리커서 이미지 내에서 제1 사람 얼굴을 검출하는 단계는 액추에이터에 의해 개시되는, 방법.In any preceding clause,
The method of claim 1, wherein detecting the first human face within the precursor image is initiated by an actuator.
상기 카메라 설정들을 조정하는 단계는 전자 디바이스로 하여금 개선된 색조를 갖는 이미지를 캡처하게 하는, 방법.In any preceding clause,
Wherein adjusting camera settings causes the electronic device to capture an image with improved color tone.
상기 개선된 색조를 갖는 이미지를 디스플레이에 제공하는 단계를 더 포함하는, 방법.According to clause 12,
The method further comprising providing an image with the improved color tone to a display.
상기 카메라 설정들을 조정하는 단계는:
적색 센서 게인;
녹색 센서 게인; 또는
청색 센서 게인을 조정하는 것을 포함하는, 방법.In any preceding clause,
The steps to adjust the camera settings are:
Red Sensor Gain;
Green Sensor Gain; or
A method comprising adjusting a blue sensor gain.
제1 사람 얼굴을 검출하는 단계는 저해상도 센서를 사용하는 것을 포함하는, 방법.In any preceding clause,
The method of claim 1, wherein detecting the first person's face includes using a low resolution sensor.
프로세서(302);
컴퓨터 판독가능 매체(304);
프리커서 이미지를 캡처할 수 있는 센서(306);
이미지 내에서 사람 얼굴을 검출할 수 있는 얼굴 프리퀀시 모듈(118);
이전 이미지들을 저장할 수 있는 저장소(308);
검출된 사람 얼굴의 색조를 결정할 수 있는 색조 결정 모듈(114); 및
카메라(320) 설정들을 조정할 수 있는 화이트 밸런스 컨트롤러(116)를 포함하는, 카메라 시스템.A camera system in an electronic device capable of performing automatic white balance (AWB), comprising:
processor 302;
computer-readable media 304;
A sensor 306 capable of capturing a precursor image;
a face frequency module 118 capable of detecting a human face within an image;
Storage 308 for storing previous images;
A hue determination module 114 capable of determining the hue of a detected human face; and
A camera system, including a white balance controller (116) capable of adjusting camera (320) settings.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163203640P | 2021-07-27 | 2021-07-27 | |
US63/203,640 | 2021-07-27 | ||
PCT/US2021/054630 WO2023009155A1 (en) | 2021-07-27 | 2021-10-12 | Automatic white-balance (awb) for a camera system |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20240013839A true KR20240013839A (en) | 2024-01-30 |
Family
ID=78536598
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020247000567A KR20240013839A (en) | 2021-07-27 | 2021-10-12 | Auto White Balance (AWB) for camera systems |
Country Status (4)
Country | Link |
---|---|
KR (1) | KR20240013839A (en) |
CN (1) | CN117751581A (en) |
TW (1) | TW202306382A (en) |
WO (1) | WO2023009155A1 (en) |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7110597B2 (en) * | 2002-03-18 | 2006-09-19 | Intel Corporation | Correcting digital images using unique subjects |
JP4217698B2 (en) * | 2005-06-20 | 2009-02-04 | キヤノン株式会社 | Imaging apparatus and image processing method |
US20200036888A1 (en) * | 2018-07-26 | 2020-01-30 | Qualcomm Incorporated | Calibration of Automatic White Balancing using Facial Images |
-
2021
- 2021-10-12 CN CN202180100953.3A patent/CN117751581A/en active Pending
- 2021-10-12 WO PCT/US2021/054630 patent/WO2023009155A1/en active Application Filing
- 2021-10-12 KR KR1020247000567A patent/KR20240013839A/en unknown
-
2022
- 2022-05-31 TW TW111120183A patent/TW202306382A/en unknown
Also Published As
Publication number | Publication date |
---|---|
TW202306382A (en) | 2023-02-01 |
WO2023009155A1 (en) | 2023-02-02 |
CN117751581A (en) | 2024-03-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9247106B2 (en) | Color correction based on multiple images | |
US9826210B2 (en) | Identifying gray regions for auto white balancing | |
Cheng et al. | Illuminant estimation for color constancy: why spatial-domain methods work and the role of the color distribution | |
US8200019B2 (en) | Method and system for automatically extracting photography information | |
US9020243B2 (en) | Image adjustment | |
KR101725884B1 (en) | Automatic processing of images | |
JP7152065B2 (en) | Image processing device | |
CN103546803A (en) | Image processing method, client side and image processing system | |
JP2018026115A (en) | Flame detection method, flame detector, and electronic apparatus | |
TW201822708A (en) | Heart rate activity detecting system based on motion images and method thereof | |
US10070111B2 (en) | Local white balance under mixed illumination using flash photography | |
CN116157805A (en) | Camera image or video processing pipeline using neural embedding | |
CN110581950B (en) | Camera, system and method for selecting camera settings | |
KR20240013839A (en) | Auto White Balance (AWB) for camera systems | |
US11082613B2 (en) | Image adjusting method and image adjusting device | |
JP2019032654A (en) | Image processing device, image processing method, and computer program | |
US10447922B2 (en) | Automated color space configuration in machine vision systems | |
US20230064329A1 (en) | Identification model generation apparatus, identification apparatus, identification model generation method, identification method, and storage medium | |
WO2021199366A1 (en) | Information processing device, method, program, and model | |
US11711619B2 (en) | Controlling exposure based on inverse gamma characteristic | |
WO2022174456A1 (en) | Image white balance adjustment method and apparatus, photographing device, and storage medium | |
CN113840134B (en) | Camera tuning method and device | |
Siagian et al. | Comparison of color constancy approaches on images with unbalanced color distribution | |
Hemrit | Revisiting and evaluating colour constancy and colour stabilisation algorithms | |
WO2023009128A1 (en) | Computational photography under low-light conditions |