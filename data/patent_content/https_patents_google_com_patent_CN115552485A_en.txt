CN115552485A - Method, computer program product and apparatus for visual search - Google Patents
Method, computer program product and apparatus for visual search Download PDFInfo
- Publication number
- CN115552485A CN115552485A CN202080100805.7A CN202080100805A CN115552485A CN 115552485 A CN115552485 A CN 115552485A CN 202080100805 A CN202080100805 A CN 202080100805A CN 115552485 A CN115552485 A CN 115552485A
- Authority
- CN
- China
- Prior art keywords
- probability
- parameter
- distribution
- image data
- image
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/30—Scenes; Scene-specific elements in albums, collections or shared content, e.g. social network photos or video
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/53—Querying
- G06F16/532—Query formulation, e.g. graphical querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/24—Classification techniques
- G06F18/241—Classification techniques relating to the classification model, e.g. parametric or non-parametric approaches
- G06F18/2413—Classification techniques relating to the classification model, e.g. parametric or non-parametric approaches based on distances to training or reference patterns
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/24—Classification techniques
- G06F18/243—Classification techniques relating to the number of classes
- G06F18/24323—Tree-organised classifiers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/72—Data preparation, e.g. statistical preprocessing of image or video features
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/74—Image or video pattern matching; Proximity measures in feature spaces
- G06V10/75—Organisation of the matching processes, e.g. simultaneous or sequential comparisons of image or video features; Coarse-fine approaches, e.g. multi-scale approaches; using context analysis; Selection of dictionaries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/764—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using classification, e.g. of video objects
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/77—Processing image or video features in feature spaces; using data integration or data reduction, e.g. principal component analysis [PCA] or independent component analysis [ICA] or self-organising maps [SOM]; Blind source separation
- G06V10/776—Validation; Performance evaluation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/77—Processing image or video features in feature spaces; using data integration or data reduction, e.g. principal component analysis [PCA] or independent component analysis [ICA] or self-organising maps [SOM]; Blind source separation
- G06V10/778—Active pattern-learning, e.g. online learning of image or video features
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
Abstract
Techniques for performing a visual search include updating a probability distribution based on a series of frames containing images of objects until a specified condition has been met, and generating search results for objects only after the specified condition has been met. When a user captures an image of a scene using a device, a front-end visual search application running on the device obtains successive image frames and sends a first image frame to a back-end computer configured to perform classification on the frame. The back-end computer obtains the prior probability distribution and generates a likelihood function indicating whether the image frame includes an object. The back-end computer then updates the prior probability distribution by adding corresponding values of the parameters associated with the prior and likelihood functions.
Description
Technical Field
This description relates to performing visual searches for objects in an image.
Background
Computer vision is a technique for classifying images of objects in a scene. For example, some search engines are configured to generate search results based on input images of objects. In such search engines, a machine learning engine, such as a convolutional neural network, is trained as a classifier to classify images as belonging to one of several classes. For example, images of a four-legged animal may be classified as a dog, cat, horse, sheep, or cow.
Disclosure of Invention
Embodiments provide a back-end visual search function configured to present stable search results based on objects in image data sent from a device running a visual search application or operation. For example, a mobile device (e.g., a smartphone) may use a sensing device (e.g., a camera) to capture an image of a scene that includes an object (e.g., a menu at a restaurant). The visual search application causes the device to compress and transmit the image to a client computer (e.g., a digital supplemental server). The client computer retrieves a prior (i.e., bayesian prior) probability distribution (e.g., beta distribution) of objects belonging to an object class (e.g., menu class). The client computer then initiates a coarse classification of the image data to the back-end server using the image data, and the back-end server generates a current distribution of probabilities that the image includes objects that belong to the object class. In response, the client computer updates the prior probability distribution based on the prior distribution and the current distribution. When the prior probability distribution is a beta distribution, then the current distribution can be considered a conjugate prior, i.e. a binomial distribution with a parameter indicating whether the classification results in the object belonging to the object class. In this case, updating the prior probability distribution comprises adding the values of the parameters of the current probability distribution to the corresponding values of the parameters of the prior probability distribution. Once updated, the client computer compares the metric of the prior probability distribution (e.g., the mean of the distribution) to a threshold. When the updated measure of the prior probability distribution is greater than the threshold, the client computer only returns search results for objects. In this way, the visual search function is more stable and efficient and improves the user experience.
In one general aspect, a method can include receiving, from a device, first image data and second image data during a visual search operation for objects in a scene, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time. The method can also include generating a first visual match probability (i.e., a match probability between an object and an object in the coarse object class) based on the first image data, the first visual match probability indicating a likelihood that an object in a first image of a scene included in the first image of the scene belongs to the object class. The method can also include, in response to determining that the first visual match probability does not satisfy the criterion, updating the first visual match probability based on the second image data to produce a second visual match probability. The method can also include, after determining that the second visual match probability satisfies the criterion, sending a digital complement associated with the object to the device as part of the visual search operation.
In another general aspect, a computer program product includes a non-transitory storage medium, the computer program product including code that, when executed by processing circuitry of a computing device, causes the processing circuitry to perform a method. The method can include receiving, from a device, first image data and second image data during a visual search operation for objects in a scene, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time. The method can also include generating a first visual match probability based on the first image data, the first visual match probability indicating a likelihood that an object in a first image of a scene included in the first image of the scene belongs to a coarse object class. The method can further include, in response to determining that the first visual match probability does not satisfy the first criterion, updating the first visual match probability based on the second image data to produce a second visual match probability. The method can further include, after determining that the second visual match probability satisfies the first criterion, determining a likelihood that the object belongs to the fine object class. The method can further include, in response to determining that the likelihood of the object belonging to the fine object class satisfies a second criterion, sending a digital complement associated with the object to the device as part of the visual search operation.
In another general aspect, an electronic device configured to generate a re-crawl policy includes a memory and control circuitry coupled to the memory. The control circuitry can be configured to receive, from the device during a visual search operation for objects in a scene, first image data and second image data, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time. The control circuit can also be configured to generate a first visual match probability based on the first image data, the first visual match probability indicating a likelihood that an object in a first image of a scene included in the first image of the scene belongs to an object class. The control circuit can also be configured to update the first visual match probability based on the second image data to produce a second visual match probability in response to determining that the first visual match probability does not satisfy the criterion. The control circuit can also be configured to send a digital complement associated with the object to the device as part of the visual search operation after determining that the second visual match probability satisfies the criterion.
The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features will be apparent from the description and drawings, and from the claims.
Drawings
FIG. 1A is a diagram illustrating an example electronic environment in which the improved techniques described herein may be implemented.
FIG. 1B is a diagram illustrating an example scene containing an object and a device configured to capture an image of the object.
FIG. 1C is a diagram illustrating an example digital supplement retrieved by a device associated with an object in a scene in accordance with the disclosed embodiments.
FIG. 2 is a flow diagram illustrating an example method of performing a visual search in accordance with the disclosed embodiments.
FIG. 3 is a sequence diagram of an example visual search in accordance with the disclosed embodiments.
FIG. 4 is a flow diagram illustrating an example visual search decision process.
Fig. 5 is a graph showing a plotted curve of a continuous prior probability distribution.
FIG. 6 is a diagram of an example evaluation process for a re-crawl policy.
Detailed Description
Some classifiers used in visual search applications or operations output, based on an image input, a probability associated with each such classification that indicates a likelihood that the image includes an object that indeed belongs to a particular object class. However, some classifiers have a more refined classification output. For example, assuming that the classifier associates an image with a dog, the classifier can determine whether the dog is a beagle dog, and if it is a beagle dog, whether it is a beagle dog, a baji hound dog, or a beagle dog. The classifier may further assign a probability to each branch of these sub-classes through the classifier, and the probability may generally vary from branch to branch. In this case, the classifier may assign a distribution of probabilities to each class, rather than a single probability value.
Conventional classifiers used in visual search applications return classifications that correspond to the most likely classes above a detection threshold, and update their probability distributions for each of their classes after assigning images to the classes. In this way, if the user indicates that the initial classification of the image is incorrect, the classifier can use the new data provided by the indication.
A technical problem in performing a visual search is that the above-described conventional classifier generates a classification result for each input image. Each classification operation performed by a classifier uses a significant amount of computing resources and may cause a search engine serviced by the classifier to appear sluggish to a user. Furthermore, in many cases, coarse object detection (i.e., classification based on the distribution at the first branch of the search tree) may wobble when the probability distribution mean approaches a threshold. Such wobble may also lead to significant instability in search engine behavior, which may further degrade the user experience. Thus, the coarse object class includes a less specific object class.
According to the embodiments described herein, a technical solution to the above technical problem includes updating a probability distribution based on a series of frames containing images of objects until a specified condition has been satisfied, and generating a search result for an object only after the specified condition has been satisfied. For example, when a user points a device, such as a smartphone camera, at a poster containing a map of a country, a front-end visual search application running on the smartphone obtains successive image frames including an image of the map, compresses each frame, and sends the first compressed frame to a back-end computer configured to perform classification on the frame. Based on previous training results, the back-end computer obtains an initial prior probability distribution. Based on the received image frames, the back-end computer generates a current probability distribution indicating whether the image frames include objects (i.e., a map of a country). The back-end computer then updates the prior probability distribution by calculating a posterior probability distribution. In some embodiments, when the prior distribution is a beta distribution and the current distribution is a conjugate of the prior (i.e., a binomial distribution), then the updating includes adding the respective values of the parameters associated with the distributions. In some implementations, updating includes incrementing a value of one of the parameters of the beta distribution according to whether the frame is classified at a coarse level as including an object. The back-end computer then evaluates the probability measure of the updated prior distribution (e.g., the mean of the distribution) and compares the probability measure to a threshold, i.e., the minimum of the probability measures that the image frame may include objects in the object class. Once the threshold has been exceeded, the back end computer extracts the digital complement from the search server and delivers the search results to the smartphone.
In some embodiments, the object class is a coarse object class, and further refinement of the coarse object class is performed before sending the digital complement to the device. For example, if the object is a map of a marsha vineyard island, the rough object class can be a "map". A finer refinement class may include "the map of the country is the united states", "the map of the united states includes the massachusetts map" and "the map of the massachusetts includes the marshy vineyard island". The back-end computer repeatedly deduces the probability distribution of the visual search; these distributions are expected to become narrower as the class of objects becomes more refined. In some implementations, the back-end computer can determine a level of refinement of the object class at which the back-end computer can obtain and send the digital complement to the device once the prior probability distribution satisfies the refinement criteria. In some embodiments, the determination of the satisfaction of the coarse and refinement criteria is performed in parallel. In some embodiments, there are further criteria for determining the final refinement level.
A technical advantage of the disclosed embodiments is that by receiving consecutive frames and updating the probability distribution in real-time with each frame, a large number of round-trip communications between a front-end application running on the device and a back-end computer performing classification on the images are eliminated, thereby reducing the time and resources required to return correct search results. Furthermore, the search process may be more stable, as the update process on the server may suppress information from the user that may change rapidly.
Fig. 1A is a diagram illustrating an example electronic environment 100 in which the above-described technical solution may be implemented. Computer 120 is configured to perform a visual search for images provided by display device 170.
FIG. 1B is a diagram illustrating an example scene 10 including an object 20 and a user 100 having a device 170 configured to capture an image of the object. Here, the user 100 directs (e.g., points) a camera on the device 170 at the object 20 in order to obtain a digital complement about the object 20, e.g., information from a network such as the world wide web. In some implementations, the user 100 points a camera on the device 170 at the object 20 until such a digital supplement is received at the device 170.
In some embodiments, the device 170 compresses each image, for example using an encoder for a lossy compression scheme, before sending the image over a network to a computer that obtains a digital complement for the object 20. In such embodiments, the images may be quite different from each other, as some data included in the images may be lost in lossy compression schemes. The data lost in one image may be different from the data lost in another image because the compression may vary greatly based on very small differences between images. Thus, a first image captured by the device 170 at a first time is different from a second image captured by the device 170 at a second time because the lossy compression of the first image is different from the lossy compression of the second image. For example, the user 100 may not be completely stationary, and small movements may result in differences in camera position and orientation, and thus small differences in images.
Fig. 1C is a diagram illustrating an example digital complement 110 associated with an object 20 in a scene 10 that is retrieved (e.g., received) by a device 170. In some implementations, the digital supplement 110 takes the form of a web page that provides information about the object 20. In some implementations, the digital supplement 110 takes the form of static text, audio, video, interactive content, and the like.
Returning to FIG. 1A, computer 120 includes a network interface 122, one or more processing units 124, and memory 126. Network interface 122 includes, for example, an ethernet adapter, a token ring adapter, or the like, for converting electronic and/or optical signals received from network 150 into electronic form for use by computer 120. The set of processing units 124 includes one or more processing chips and/or assemblies. The memory 126 includes both volatile memory (e.g., RAM) and non-volatile memory, such as one or more ROMs, disk drives, solid-state drives, or the like. The set of processing units 124 and the memory 126 together form a control circuit configured and arranged to perform various methods and functions as described herein.
In some implementations, one or more components of the computer 120 can be or can include a processor (e.g., the processing unit 124) configured to process instructions stored in the memory 126. Examples of such instructions as depicted in FIG. 1 include an entity manager 130, a prediction manager 140, a re-crawl manager 150, and a re-crawl policy manager 160. Further, as shown in FIG. 1A, the memory 126 is configured to store various data described with respect to the respective manager using such data. Note that in some embodiments, the entity page corresponds to an offer page that includes an offer to sell a product.
The image manager 130 is configured to receive image data 132. In some implementations, the image manager 130 receives the image data 132 from the display device 170 through the network interface 122, i.e., through a network (such as the network 190). In some implementations, the image manager 130 receives the image data 132 from a local storage device (e.g., a disk drive, flash drive, SSD, etc.).
Image data 132 represents an image of a scene as seen by display device 170 via, for example, image acquisition manager 172 configured to obtain the image by a camera and send image data 132 to computer 120. In some embodiments, the image data takes the form of a sequence of frames of compressed image data 134 (1), 134 (2), … …,134 (N).
The compressed images 134 (1), … …,134 (N) represent an encoded version of the image data as generated by the image acquisition manager 172. Display device 170 is configured to perform encoding operations on the generated image data prior to transmission of the image data to computer 120. In some implementations, the type of encoding used for compression (e.g., JPEG) is only important for the effect that any classifier configured to determine whether an image contains an object that belongs to the object class is trained using similarly compressed images. In this way, there is no need to perform any decoding operation for the classification. Furthermore, a successive image frame (e.g., compressed image 134 (2)) may not be the same as a previous frame (e.g., compressed image 134 (1)) because a small change in camera orientation or position may result in a large alteration of the compressed image. However, in some embodiments, there may be a decoding step before any classification occurs.
In some implementations, the image acquisition manager 172 is further configured to identify textual descriptions of objects in the scene. For example, the image acquisition manager 172 associates certain image data with text descriptors such as person name, place name, product, art, and the like. The image acquisition manager 172 may then include such textual descriptions in the image data 132, such that identification of possible objects for classification is simplified.
The prior distribution manager 140 is configured to obtain prior distribution data 142 representing a prior probability distribution. In some implementations, the a priori distribution data 142 is generated by the a priori distribution manager 142 based on training data from the object classifier. In some embodiments, the object classifier includes a Convolutional Neural Network (CNN), and the training data includes a priori visual search results.
The prior distribution data 142 represents a prior probability distribution indicating the likelihood that an object included in an image frame (e.g., 134 (1)) belongs to an object class. In some implementations, the a priori distribution data 142 includes a distribution identifier (e.g., "beta," "gamma," "binomial," etc.) and a parameter value associated with the distribution identifier. In some embodiments, the a priori distribution data includes probability density values that together form a probability distribution. In some embodiments, the prior probability distribution is distributed over possible probability values between 0 and 1. That is, the coarse classification indicates whether the object belongs to a coarse defined object class, wherein further layers of the object class form a tree structure. The various paths along the tree structure provide a roughly defined distribution of the probabilities of the object classes.
In some embodiments, the determination of whether an image containing objects that belong to a coarse class belongs to a more refined class is performed using a set of heuristics derived from empirical statistics. For example, the object identified as a dog may be a lion dog or a beagle dog. Determining whether a dog is a lion dog or a beagle dog includes determining whether there is a higher likelihood that any dog is a lion dog or a beagle dog. In some implementations, there is a white list or black list indicating whether such refined classes should be considered in the visual search.
The current distribution manager 144 is configured to indicate whether the image data 132 (e.g., the compressed image 132 (1)) includes an object that belongs to the object class. The current distribution manager 144 is configured to generate current distribution data 146 based on whether the object belongs to an object class.
The current distribution data 146 represents the likelihood that the image data 132, and in particular the compressed image 134 (1), contains objects belonging to the object class. In some implementations, the current distribution data 146 is a binomial distribution based on a parameter indicating whether an object in the image belongs to an object class. That is, in some arrangements, the parameter of the binomial distribution is the number of times a series of image frames has an object belonging to the object class, and the number of times the series of image frames does not have an object belonging to the object class.
The distribution update manager 150 is configured to update the prior probability distribution based on the prior probability distribution 142 and the current probability distribution 146 to produce updated distribution data 152. In some embodiments, the distribution update manager 150 is configured to multiply the previous prior distribution 142 by the current probability distribution 146. In such embodiments, the distribution update manager 150 is configured to normalize the product by dividing the product by the sum of the products over all probabilities. In some embodiments, when the prior distribution 142 is a beta distribution and the current distribution 146 is a binomial distribution (and is a conjugate of the prior), then the distribution update manager 150 is configured to add the parameter associated with the current distribution 146 to the corresponding value of the parameter associated with the prior distribution 142. In this case, the updated prior distribution 152 is a beta distribution with updated parameter values.
The updated distribution data 152 represents a new a priori distribution resulting from the updates performed by the distribution update manager 150. If the prior distribution 142 is a beta distribution and the current distribution 146 is a binomial distribution, the updated prior distribution 152 is a beta distribution. Further, in this case, if the image frame includes an object belonging to the object class, the first parameter of the beta distribution is incremented, and the second parameter is unchanged. In contrast, if the image frame does not include an object belonging to the object class, the first parameter of the beta distribution is unchanged and the second parameter is incremented.
The information acquisition manager 160 is configured to determine whether the updated prior probability distribution 152 satisfies the criteria represented by the information criterion data 162. In some embodiments, the information acquisition manager 160 is configured to derive a probability metric from the updated prior probability distribution 152. For example, when the criteria states that the probability metric is greater than a threshold, the information acquisition manager 160 is configured to compare the derived probability metric to the threshold. In some embodiments, the probability metric is a mean of the probability distribution. In some embodiments, the probability metric is a mean of the probability distribution.
The information acquisition manager 160 is further configured to obtain information about the object from the search server 180 based on the information criteria data 162. For example, if the object is determined to be a menu from a particular restaurant, the information may take the form of a review of that restaurant. The comments may be taken from the indexed search results generated by the search server. Further, the information acquisition manager 160 sends the information to the display device 170 in response to the criteria specified in the information criteria data 162 being satisfied.
The information criteria data 162 represents criteria or criteria for determining whether to send the retrieved information to the display device 170. In some embodiments, the criterion is that the mean of the prior probability distribution is greater than a threshold. In this case, the information criterion data 162 may take the form of a threshold.
The components (e.g., modules, processing unit 124) of user device 120 can be configured to operate based on one or more platforms (e.g., one or more similar or different platforms) that can include one or more types of hardware, software, firmware, operating systems, runtime libraries, and so forth. In some implementations, components of the computer 120 can be configured to operate within a cluster of devices (e.g., a server farm). In such an embodiment, the functions and processing of the components of computer 120 can be distributed to several devices of a device cluster.
The components of computer 120 can be or include any type of hardware and/or software configured to process attributes. In some implementations, one or more portions of the components shown in the components of the computer 120 in fig. 1 can be or can include a hardware-based module (e.g., a Digital Signal Processor (DSP), a Field Programmable Gate Array (FPGA), a memory), a firmware module, and/or a software-based module (e.g., a computer code module, a set of computer-readable instructions executable at a computer). For example, in some embodiments, one or more portions of the components of the computer 120 can be or can include software modules configured to be executed by at least one processor (not shown). In some implementations, the functionality of the components can be included in different modules and/or different components than those shown in fig. 1, including combining the functionality illustrated as two components into a single component.
Although not shown, in some embodiments, the components of computer 120 (or portions thereof) can be configured to operate within, for example, a data center (e.g., a cloud computing environment), a computer system, one or more servers/host devices, and/or the like. In some implementations, components of computer 120 (or portions thereof) can be configured to operate within a network. Accordingly, components of computer 120 (or portions thereof) can be configured to operate within various types of network environments that can include one or more devices and/or one or more server devices. For example, the network can be or can include a Local Area Network (LAN), a Wide Area Network (WAN), and the like. The network can be or can include a wireless network and/or a wireless network implemented using, for example, gateway devices, bridges, switches, etc. The network can include one or more segments and/or can have portions based on various protocols such as Internet Protocol (IP) and/or proprietary protocols. The network can include at least a portion of the internet.
In some implementations, one or more components of the computer 120 can be or can include a processor configured to process instructions stored in a memory. For example, the image manager 130 (and/or a portion thereof), the a priori distribution manager 140 (and/or a portion thereof), the current distribution manager 144 (and/or a portion thereof), the distribution update manager 150 (and/or a portion thereof), and the information acquisition manager 160 (and/or a portion thereof) can be a combination of a processor and a memory that are configured to execute instructions related to a process that implements one or more functions.
In some implementations, the memory 126 can be any type of memory, such as random access memory, disk drive memory, flash memory, and so forth. In some implementations, the memory 126 can be implemented as more than one memory component (e.g., more than one RAM component or disk drive memory) associated with components of the VR server computer 120. In some implementations, the memory 126 can be a database memory. In some implementations, the memory 126 can be or can include non-local memory. For example, the memory 126 can be or can include a memory shared by multiple devices (not shown). In some implementations, the memory 126 can be associated with a server device (not shown) within a network and configured to serve components of the computer 120. As shown in fig. 1, the memory 126 is configured to store various data including image data 132, a priori distribution data 142, current distribution data 146, updated distribution data 152, and information criteria data 162.
The beta distribution is defined as follows:
where α and β are the hyperparameters of the beta distribution and q is the probability. That is, B (α, β) is a beta function, and Γ (α) is a gamma function. In some embodiments, the prior probability distribution 142 and the posterior probability distribution 152 take this mathematical form. Thus, the prior distribution 142 is a conjugate prior of the likelihood function, which in some embodiments takes the form of a binomial distribution. One such binomial distribution takes the form:
the posterior probability is given by bayes' theorem:
when the prior is a beta distribution, the computation of the posterior probability is reduced to a Bayesian update of the prior as follows:
that is, the updating of the prior probability distributions comprises adding the respective values of the parameters of the respective distributions. Examples of these distributions will be discussed in further detail with reference to fig. 5.
FIG. 2 is a flow diagram depicting an example method 200 of performing a visual search in accordance with the improved techniques described above. The method 200 may be performed by the software structure described in connection with fig. 1 residing in the memory 126 of the computer 120 and being executed by the set of processing units 124.
At 202, the image manager 130 receives first and second image data (e.g., compressed image 134 (1,2)) from a device (e.g., display device 170), the first image data representing a first image of a scene, the first image of the scene including an object. For example, a scene may include a building displaying a menu, and the object can be a menu.
At 204, the information acquisition manager 160 generates a first probability metric based on the first image data, the first probability metric indicating a likelihood that an object included in the first image of the scene belongs to an object class, the first probability metric not satisfying specified criteria (in the information criteria data 162). In some embodiments, the first probability metric is a mean of prior probability distributions represented by prior distribution data 142 obtained by the prior distribution manager 140.
At 206, in response to the first probability metric not satisfying the specified criteria, the distribution update manager 150 updates the first probability metric based on the second image data (e.g., 134 (2)) to produce a second probability metric, the second probability metric satisfying the specified criteria. Again, when the first probability metric is based on a beta distribution, the current distribution manager 144 generates a binomial distribution that is based on whether the classifier determines that the object included in the second image of the scene belongs to the object class. In some embodiments, the second probability measure is the mean of the updated prior probability distribution, i.e. the updated prior probability.
At 208, in response to the second probability metric satisfying the specified criteria, the information acquisition manager 160 sends information associated with the object, such as a digital complement, to the device. In some embodiments, the information takes the form of web content about the object. For example, if the object is a menu from a restaurant, the information may take the form of a restaurant review taken from a restaurant review website.
FIG. 3 is a sequence diagram of an example visual search 300 involving display device 170, computer 120, and search server 180. The visual search 300 may be performed by the software structure described in connection with fig. 1, which resides in the memory 126 of the computer 120 and is executed by the set of processing units 124.
At 302, the display device 170 transmits the image data to the computer 120, as described above with reference to fig. 1 and 2.
At 304, the computer 120 retrieves a prior probability distribution p (q) indicating that an object in the image data belongs to an object class.
At 306, the computer 120 receives an initial coarse classification result in the form of a likelihood function (or current distribution) p (s, f | q). In some embodiments, the data representing the likelihood functions is stored locally on computer 120.
At 308, computer 120 generates a posterior probability distribution p (q | s, f) and evaluates its mean against a specified threshold. In this case, the mean value is less than the threshold.
At 312, the computer 120 replaces the previous prior distribution with the posterior distribution. That is, p (q) ← p (q | s, f).
At 314, the computer 120 receives a new coarse classification result based on the new image data, the new coarse classification result taking the form of a likelihood function (or current distribution) p (s, f | q).
At 316, the computer 120 generates a posterior probability distribution p (q | s, f) and evaluates its mean against a specified threshold. In this case, the mean value is greater than the threshold value.
At 318, the computer 120 retrieves search results, such as a digital complement, for the object from the search server 180.
At 320, the computer 120 sends the search results to the display device 170.
FIG. 4 is a flow diagram illustrating an example visual search decision process 400. The visual search decision-making process 400 may be performed by the software structure described in connection with fig. 1, which resides in the memory 126 of the computer 120 and is executed by the set of processing units 124.
At 402, computer 120 receives compressed image data from display device 170.
At 404, the computer 120 obtains an a priori distribution in the form of a beta distribution as defined above. The prior distribution indicates the likelihood of the object class.
At 406, the computer 120 updates the beta distribution according to whether the classifier determines that an object belonging to the object class is represented in the image data. For example, if the image data does not contain such an object, the computer 120 increments the value of β; otherwise, computer 120 increments the value of α.
At 408, the computer 120 determines whether the mean of the updated prior distribution is greater than a specified threshold. If the mean is greater than the threshold, process 400 proceeds to 410. If not, process 400 returns to 404.
At 410, the computer 120 obtains and transmits search results associated with the object.
Fig. 5 is a graph showing a plotted curve of a continuous a priori probability distribution 500. For example, curve 510 represents a beta distribution with α =8 and β = 20. This occurs innew curve 520 hascurve 530 is atdisplay device 170.
FIG. 6 shows an example of a general purpose computer device 600 and a general purpose mobile computer device 650, which can be used with the techniques described herein. Computer device 600 is one example configuration of computer 120 of fig. 1 and 2.
As shown in FIG. 6, computing device 600 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers. Computing device 650 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smart phones, and other similar computing devices. The components shown herein, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit embodiments of the inventions described and/or claimed in this document.
The memory 604 stores information within the computing device 600. In one implementation, the memory 604 is a volatile memory unit or units. In another implementation, the memory 604 is a non-volatile memory unit or units. The memory 604 may also be another form of computer-readable medium, such as a magnetic or optical disk.
The storage device 606 can provide mass storage for the computing device 600. In one implementation, the storage device 606 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. The computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer-or machine-readable medium, such as the memory 604, the storage device 606, or memory on processor 602.
The high speed controller 608 manages bandwidth-intensive operations for the computing device 500, while the low speed controller 612 manages lower bandwidth-intensive operations. Such allocation of functions is merely exemplary. In one embodiment, the high-speed controller 608 is coupled to memory 604, display 616 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 610, which high-speed expansion ports 610 may accept various expansion cards (not shown). In an embodiment, low-speed controller 612 is coupled to storage device 506 and low-speed expansion port 614. The low-speed expansion port, which may include various communication ports (e.g., USB, bluetooth, ethernet, wireless ethernet), may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a network connection device such as a switch or router, e.g., through a network adapter.
As shown, computing device 600 may be implemented in a number of different forms. For example, it may be implemented as a standard server 620, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 624. Further, it may be implemented in a personal computer such as a laptop computer 622. Alternatively, components from computing device 600 may be combined with other components in a mobile device (not shown), such as device 650. Each such device may contain one or more computing devices 600, 650, and an entire system may be made up of multiple computing devices 600, 650 communicating with each other.
Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation of one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
These computer programs (also known as programs, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine language. As used herein, the terms "machine-readable medium," "computer-readable medium" refers to any computer program product, apparatus and/or device (e.g., magnetic discs, optical disks, memory, programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other types of devices can also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
The systems and techniques described here can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network ("LAN"), a wide area network ("WAN"), and the internet.
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
A number of embodiments have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the description.
It will also be understood that when an element is referred to as being on, connected to, electrically connected to, coupled to, or electrically coupled to another element, it can be directly on, connected to, or coupled to the other element or one or more intervening elements may be present. In contrast, when an element is referred to as being directly on, directly connected to, or directly coupled to another element, there are no intervening elements present. While the terms "directly on … …," "directly connected to," or "directly coupled to" may not be used throughout the detailed description, elements shown as "directly on … …," "directly connected to," or "directly coupled to" can be referred to as such. The claims of the present application may be modified to recite the exemplary relationships described in the specification or shown in the drawings.
While certain features of the described embodiments have been illustrated as described herein, many modifications, substitutions, changes and equivalents will now occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the scope of the embodiments. It is to be understood that they have been presented by way of example only, and not limitation, and various changes in form and details may be made. Any portions of the apparatus and/or methods described herein may be combined in any combination, except mutually exclusive combinations. The embodiments described herein can include various combinations and/or subcombinations of the functions, components and/or features of the different embodiments described.
Moreover, the logic flows depicted in the figures do not require the particular order shown, or sequential order, to achieve desirable results. In addition, other steps may be provided, or steps may be eliminated, from the described flows, and other components may be added to, or deleted from, the described systems. Accordingly, other implementations are within the scope of the following claims.
Some examples are described below.
Example 1: a method, comprising:
receiving, from a device, first image data and second image data during a visual search operation for objects in a scene, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time;
generating a first visual match probability based on the first image data, the first visual match probability indicating a likelihood that the object in the first image of the scene included in the first image of the scene belongs to a coarse object class;
in response to determining that the first visual match probability does not satisfy a criterion, updating the first visual match probability based on the second image data to produce a second visual match probability; and
after determining that the second visual match probability satisfies the criteria, sending a digital complement associated with the object to the device as part of the visual search operation.
Example 2: the method of example 1, wherein the criteria comprises a visual search probability being greater than or equal to a threshold.
Example 3: the method according to example 2, wherein a first visual search probability is a mean of a first probability distribution over probabilities that the object in the first image belongs to the object class, the first probability distribution having the mean as a first probability measure comprising a first set of parameter values, and wherein a second visual search probability is a mean of a second probability distribution having the mean as the second visual search probability comprising a second set of parameter values.
Example 4: the method of example 3, wherein the first probability distribution is a prior distribution after receiving the second image data, and
wherein updating the first probability metric comprises:
multiplying the prior distribution by a current probability distribution representing a distribution of probabilities that parameters of the current probability distribution have particular values given a probability that the object included in the second image of the scene represented by the second image data belongs to the class of objects.
Example 5: the method of example 4, wherein the current probability distribution is a binomial distribution.
Example 6: the method of example 3, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter, wherein the method further comprises:
generating a current probability distribution representing a distribution of probabilities that parameters of the current probability distribution have a particular value given a probability that the object included in the second image of the scene represented by the second image data belongs to the object class, the current probability distribution being based on values of a third parameter and a fourth parameter, and
wherein updating the first visual match probability comprises:
adding the values of the first parameter and the third parameter, and adding the values of the second parameter and the fourth parameter.
Example 7: the method of example 3, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter, and
wherein updating the first visual search probability comprises:
in response to the object being determined to be included in the object class, incrementing the value of the first parameter and not incrementing the value of the second parameter; and
in response to the object being determined to be included in the class of objects, incrementing the value of the second parameter and not incrementing the value of the first parameter.
Example 8: the method of example 3, wherein the first and second probability distributions are beta distributions.
Example 9: the method of at least one of the preceding examples, wherein the digital supplement comprises data about the object not included in the image data, the digital supplement comprising data from the world wide web and/or a database.
Example 10: a computer program product comprising a non-transitory storage medium, the computer program product comprising code that, when executed by processing circuitry of a computer, causes the processing circuitry to perform a method, the method comprising:
receiving, from a device, first image data and second image data during a visual search operation for objects in a scene, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time;
generating a first visual match probability based on the first image data, the first visual match probability indicating a likelihood that the object in the first image of the scene included in the first image of the scene belongs to a coarse object class;
in response to determining that the first visual match probability does not satisfy a first criterion, updating the first visual match probability based on the second image data to produce a second visual match probability;
determining a likelihood that the object belongs to a fine object class after determining that the second visual match probability satisfies the first criterion; and
in response to determining that the likelihood that the object belongs to the fine object class satisfies a second criterion, sending a digital complement associated with the object to the device as part of the visual search operation.
Example 11: the computer program product of example 10, wherein the first criterion comprises a probability metric being greater than or equal to a threshold.
Example 12: the computer program product of example 11, wherein the first probability measure is a mean of a first probability distribution over a probability that the object belongs to the coarse object class, the first probability distribution having the mean as the first probability measure including a first set of parameter values, and
wherein the second probability measure is a mean of a second probability distribution having the mean as the second probability measure comprising a second set of parameter values.
Example 13: the computer program product of example 12, wherein the first probability distribution is a prior distribution after receiving the second image data, and
wherein updating the first probability metric comprises:
multiplying the prior distribution by a current probability distribution representing a distribution of probabilities that parameters of the current probability distribution have particular values given a probability that the object included in the second image of the scene represented by the second image data belongs to the coarse object class.
Example 14: the computer program product of example 13, wherein the current probability distribution is a binomial distribution.
Example 15: the computer program product of example 12, wherein, after receiving the second image data, the first probability distribution is a prior distribution, the prior distribution being based on values of a first parameter and a second parameter,
wherein the method further comprises:
generating a current probability distribution representing a distribution of probabilities that parameters of the current probability distribution have a particular value given a probability that the object included in the second image of the scene represented by the second image data belongs to the coarse object class, the current probability distribution being based on values of a third parameter and a fourth parameter, and
wherein updating the first probability metric comprises:
adding the values of the first parameter and the third parameter, and adding the values of the second parameter and the fourth parameter.
Example 16: the computer program product of example 12, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter, and
wherein updating the first probability metric comprises:
in response to the object included in the second scene being classified as belonging to the coarse object class, incrementing the value of the first parameter and not incrementing the value of the second parameter; and
in response to the object included in the second scene being classified as not belonging to the coarse object class, incrementing the value of the second parameter and not incrementing the value of the first parameter.
Example 17: the computer program product of example 12, wherein the first and second probability distributions are beta distributions.
Example 18: the computer program product of at least one of claims 10 to 17, wherein the digital supplement comprises data on the object not included in the image data, the digital supplement comprising data from the world wide web and/or a database.
Example 19: an electronic device, the electronic device comprising:
a memory; and
a processing circuit coupled to the memory, the processing circuit configured to:
receiving, from a device, first image data and second image data during a visual search operation for objects in a scene, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time;
generating a first visual match probability based on the first image data, the first visual match probability indicating a likelihood that the object in the first image of the scene included in the first image of the scene belongs to a coarse object class;
in response to determining that the first visual match probability does not satisfy a criterion, updating the first visual match probability based on the second image data to produce a second visual match probability; and
after determining that the second visual match probability satisfies the criteria, sending a digital complement associated with the object to the device as part of the visual search operation.
Example 20: the electronic device of example 19, wherein a first visual search probability is a mean of a first probability distribution over probabilities that the object in the first image belongs to the object class, the first probability distribution having the mean as a first probability metric including a first set of parameter values, and
wherein the second visual search probability is a mean of a second probability distribution having the mean as the second visual search probability comprising a second set of parameter values.
Example 21: the electronic device of example 20, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter,
wherein the processing circuit is further configured to:
a current probability distribution representing a distribution of probabilities that parameters of the current probability distribution have a certain value given a probability that the object included in the second image of the scene represented by the second image data belongs to the object class, the current probability distribution being based on values of a third parameter and a fourth parameter, and
wherein the processing circuit configured to update the first visual match probability is further configured to:
adding the values of the first parameter and the third parameter, and adding the values of the second parameter and the fourth parameter.
Example 22: the electronic device of example 20, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter, and
wherein the processing circuit configured to update the first visual match probability is further configured to:
in response to the object included in the second scene being classified as belonging to the object class, incrementing the value of the first parameter and not incrementing the value of the second parameter; and
in response to the object included in the second scene being classified as not belonging to the object class, incrementing the value of the second parameter and not incrementing the value of the first parameter.
Claims (22)
1. A method, comprising:
receiving, from a device, first image data and second image data during a visual search operation for objects in a scene, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time;
generating a first visual match probability based on the first image data, the first visual match probability indicating a likelihood that the object in the first image of the scene included in the first image of the scene belongs to a coarse object class;
in response to determining that the first visual match probability does not satisfy a criterion, updating the first visual match probability based on the second image data to produce a second visual match probability; and
after determining that the second visual match probability satisfies the criteria, sending a digital complement associated with the object to the device as part of the visual search operation.
2. The method of claim 1, wherein the criteria comprises a visual search probability greater than or equal to a threshold.
3. The method of claim 2, wherein the first visual search probability is a mean of a first probability distribution over probabilities that the object in the first image belongs to the object class, the first probability distribution having the mean as a first probability metric including a first set of parameter values, and
wherein the second visual search probability is a mean of a second probability distribution having the mean as the second visual search probability comprising a second set of parameter values.
4. The method of claim 3, wherein the first probability distribution is a prior distribution after receiving the second image data, and
wherein updating the first probability metric comprises:
multiplying the prior distribution by a current probability distribution representing a probability distribution that a parameter of the current probability distribution has a particular value given a probability that the object included in the second image of the scene represented by the second image data belongs to the class of objects.
5. The method of claim 4, wherein the current probability distribution is a binomial distribution.
6. The method of claim 3, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter,
wherein the method further comprises:
generating a current probability distribution representing a probability distribution having a parameter of a particular value given a probability that the object included in the second image of the scene represented by the second image data belongs to the object class, the current probability distribution being based on values of a third parameter and a fourth parameter, and
wherein updating the first visual match probability comprises:
adding the values of the first parameter and the third parameter, and adding the values of the second parameter and the fourth parameter.
7. The method of claim 3, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter, and
wherein updating the first visual search probability comprises:
in response to the object being determined to be included in the object class, incrementing the value of the first parameter and not incrementing the value of the second parameter; and
incrementing the value of the second parameter and not incrementing the value of the first parameter in response to the object being determined to be included in the object class.
8. The method of claim 3, wherein the first and second probability distributions are beta distributions.
9. Method according to at least one of the preceding claims, wherein the digital supplement comprises data on the object not comprised in the image data, the digital supplement comprising data from the world wide web and/or a database.
10. A computer program product comprising a non-transitory storage medium, the computer program product comprising code that, when executed by processing circuitry of a computer, causes the processing circuitry to perform a method, the method comprising:
receiving, from a device, first image data and second image data during a visual search operation for an object in a scene, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time;
generating a first visual match probability based on the first image data, the first visual match probability indicating a likelihood that the object in the first image of the scene included in the first image of the scene belongs to a coarse object class;
in response to determining that the first visual match probability does not satisfy a first criterion, updating the first visual match probability based on the second image data to produce a second visual match probability;
determining a likelihood that the object belongs to a fine object class after determining that the second visual match probability satisfies the first criterion; and
in response to determining that the likelihood that the object belongs to the fine object class satisfies a second criterion, sending a digital complement associated with the object to the device as part of the visual search operation.
11. The computer program product of claim 10, wherein the first criterion comprises a probability metric being greater than or equal to a threshold.
12. The computer program product according to claim 11, wherein the first probability measure is a mean of a first probability distribution over a probability that the object belongs to the coarse object class, the first probability distribution having the mean as the first probability measure including a first set of parameter values, and
wherein the second probability metric is a mean of a second probability distribution having the mean as the second probability metric comprising a second set of parameter values.
13. The computer program product of claim 12, wherein the first probability distribution is a prior distribution after receiving the second image data, and
wherein updating the first probability metric comprises:
multiplying the prior distribution by a current probability distribution representing a probability distribution that a parameter of the current probability distribution has a particular value given a probability that the object included in the second image of the scene represented by the second image data belongs to the coarse object class.
14. The computer program product of claim 13, wherein the current probability distribution is a binomial distribution.
15. The computer program product of claim 12, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter,
wherein the method further comprises:
generating a current probability distribution representing a probability distribution for which a parameter of the current probability distribution has a certain value given a probability that the object included in the second image of the scene represented by the second image data belongs to the coarse object class, the current probability distribution being based on values of a third parameter and a fourth parameter, and
wherein updating the first probability metric comprises:
adding the values of the first parameter and the third parameter, and adding the values of the second parameter and the fourth parameter.
16. The computer program product of claim 12, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter, and
wherein updating the first probability metric comprises:
in response to the object included in the second scene being classified as belonging to the coarse object class, incrementing the value of the first parameter and not incrementing the value of the second parameter; and
in response to the object included in the second scene being classified as not belonging to the coarse object class, incrementing the value of the second parameter and not incrementing the value of the first parameter.
17. The computer program product of claim 12, wherein the first and second probability distributions are beta distributions.
18. The computer program product according to at least one of claims 10 to 17, wherein the digital supplement comprises data on the object not included in the image data, the digital supplement comprising data from the world wide web and/or a database.
19. An electronic device, the electronic device comprising:
a memory; and
a processing circuit coupled to the memory, the processing circuit configured to:
receiving, from a device, first image data and second image data during a visual search operation for objects in a scene, the first image data representing a first image of the scene at a first time and the second image data representing a second image of the scene at a second time;
generating a first visual match probability based on the first image data, the first visual match probability indicating a likelihood that the object in the first image of the scene included in the first image of the scene belongs to a coarse object class;
in response to determining that the first visual match probability does not satisfy a criterion, updating the first visual match probability based on the second image data to produce a second visual match probability; and
after determining that the second visual match probability satisfies the criteria, sending a digital complement associated with the object to the device as part of the visual search operation.
20. The electronic device of claim 19, wherein the first visual search probability is a mean of a first probability distribution over probabilities that the object in the first image belongs to the object class, the first probability distribution having the mean as a first probability metric including a first set of parameter values, and
wherein the second visual search probability is a mean of a second probability distribution having the mean as the second visual search probability comprising a second set of parameter values.
21. The electronic device of claim 20, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter,
wherein the processing circuit is further configured to:
a current probability distribution representing a probability distribution in which a parameter of the current probability distribution has a certain value given a probability that the object included in the second image of the scene represented by the second image data belongs to the object class, the current probability distribution being based on values of a third parameter and a fourth parameter, and
wherein the processing circuit configured to update the first visual match probability is further configured to:
adding the values of the first parameter and the third parameter, and adding the values of the second parameter and the fourth parameter.
22. The electronic device of claim 20, wherein, after receiving the second image data, the first probability distribution is a prior distribution that is based on values of a first parameter and a second parameter, and
wherein the processing circuit configured to update the first visual match probability is further configured to:
in response to the object included in the second scene being classified as belonging to the object class, incrementing the value of the first parameter and not incrementing the value of the second parameter; and
in response to the object included in the second scene being classified as not belonging to the object class, incrementing the value of the second parameter and not incrementing the value of the first parameter.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/032681 WO2021230864A1 (en) | 2020-05-13 | 2020-05-13 | Method, computer program product and apparatus for visual searching |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115552485A true CN115552485A (en) | 2022-12-30 |
Family
ID=70919229
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080100805.7A Pending CN115552485A (en) | 2020-05-13 | 2020-05-13 | Method, computer program product and apparatus for visual search |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230177806A1 (en) |
EP (1) | EP4150505A1 (en) |
JP (1) | JP2023525334A (en) |
KR (1) | KR20230003170A (en) |
CN (1) | CN115552485A (en) |
WO (1) | WO2021230864A1 (en) |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10339622B1 (en) * | 2018-03-02 | 2019-07-02 | Capital One Services, Llc | Systems and methods for enhancing machine vision object recognition through accumulated classifications |
JP7420741B2 (en) * | 2018-05-07 | 2024-01-23 | グーグル エルエルシー | Real-time object detection and tracking |
-
2020
- 2020-05-13 US US17/997,812 patent/US20230177806A1/en active Pending
- 2020-05-13 EP EP20729540.3A patent/EP4150505A1/en active Pending
- 2020-05-13 CN CN202080100805.7A patent/CN115552485A/en active Pending
- 2020-05-13 WO PCT/US2020/032681 patent/WO2021230864A1/en unknown
- 2020-05-13 JP JP2022568937A patent/JP2023525334A/en active Pending
- 2020-05-13 KR KR1020227041775A patent/KR20230003170A/en unknown
Also Published As
Publication number | Publication date |
---|---|
EP4150505A1 (en) | 2023-03-22 |
KR20230003170A (en) | 2023-01-05 |
WO2021230864A1 (en) | 2021-11-18 |
JP2023525334A (en) | 2023-06-15 |
US20230177806A1 (en) | 2023-06-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN111368893B (en) | Image recognition method, device, electronic equipment and storage medium | |
CN107403173B (en) | Face recognition system and method | |
CN109344884B (en) | Media information classification method, method and device for training picture classification model | |
US8463025B2 (en) | Distributed artificial intelligence services on a cell phone | |
CN108229419B (en) | Method and apparatus for clustering images | |
CN111079670B (en) | Face recognition method, device, terminal and medium | |
US20220351081A1 (en) | Model training method and apparatus | |
CN110765860A (en) | Tumble determination method, tumble determination device, computer apparatus, and storage medium | |
US11335127B2 (en) | Media processing method, related apparatus, and storage medium | |
CN111694926A (en) | Interactive processing method and device based on scene dynamic configuration and computer equipment | |
CN113434716B (en) | Cross-modal information retrieval method and device | |
EP3767549A1 (en) | Delivery of compressed neural networks | |
CN111062431A (en) | Image clustering method, image clustering device, electronic device, and storage medium | |
CN110096605B (en) | Image processing method and device, electronic device and storage medium | |
CN110008922B (en) | Image processing method, device, apparatus, and medium for terminal device | |
CN108734718B (en) | Processing method, device, storage medium and equipment for image segmentation | |
US20230177806A1 (en) | Method, computer program product and apparatus for visual searching | |
CN114724144B (en) | Text recognition method, training device, training equipment and training medium for model | |
CN116010655A (en) | Video processing and searching method and device, electronic equipment and storage medium | |
CN113779559B (en) | Method, device, electronic equipment and medium for identifying cheating website | |
CN115374318A (en) | Model calling method and device, computer equipment and storage medium | |
CN113065011B (en) | Picture determination method and device | |
CN116881483B (en) | Multimedia resource recommendation method, device and storage medium | |
US20210406480A1 (en) | Method for generating conversation, electronic device, and storage medium | |
US20230237280A1 (en) | Automatically generating context-based alternative text using artificial intelligence techniques |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |