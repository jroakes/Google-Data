WO2012154152A1 - Apparatus and method for rendering video with retransmission delay - Google Patents
Apparatus and method for rendering video with retransmission delay Download PDFInfo
- Publication number
- WO2012154152A1 WO2012154152A1 PCT/US2011/035470 US2011035470W WO2012154152A1 WO 2012154152 A1 WO2012154152 A1 WO 2012154152A1 US 2011035470 W US2011035470 W US 2011035470W WO 2012154152 A1 WO2012154152 A1 WO 2012154152A1
- Authority
- WO
- WIPO (PCT)
- Prior art keywords
- round
- trip
- current frame
- delay
- frames
- Prior art date
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/61—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N7/00—Television systems
- H04N7/24—Systems for the transmission of television signals using pulse code modulation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L1/00—Arrangements for detecting or preventing errors in the information received
- H04L1/12—Arrangements for detecting or preventing errors in the information received by using return channel
- H04L1/16—Arrangements for detecting or preventing errors in the information received by using return channel in which the return channel carries supervisory signals, e.g. repetition request signals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/61—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio
- H04L65/611—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio for multicast or broadcast
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/61—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio
- H04L65/612—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio for unicast
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/242—Synchronization processes, e.g. processing of PCR [Program Clock References]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/4302—Content synchronisation processes, e.g. decoder synchronisation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/44004—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving video buffer management, e.g. video decoder buffer or video display buffer
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/63—Control signaling related to video distribution between client, server and network components; Network processes for video distribution between server and clients or between remote clients, e.g. transmitting basic layer and enhancement layers over different transmission paths, setting up a peer-to-peer communication via Internet between remote STB's; Communication protocols; Addressing
- H04N21/637—Control signals issued by the client directed to the server or network components
- H04N21/6375—Control signals issued by the client directed to the server or network components for requesting retransmission, e.g. of data packets lost or corrupted during transmission from server
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/63—Control signaling related to video distribution between client, server and network components; Network processes for video distribution between server and clients or between remote clients, e.g. transmitting basic layer and enhancement layers over different transmission paths, setting up a peer-to-peer communication via Internet between remote STB's; Communication protocols; Addressing
- H04N21/647—Control signaling between network components and server or clients; Network processes for video distribution between server and clients, e.g. controlling the quality of the video stream, by dropping packets, protecting content from unauthorised alteration within the network, monitoring of network load, bridging between two different networks, e.g. between IP and wireless
- H04N21/64746—Control signals issued by the network directed to the server or the client
- H04N21/64761—Control signals issued by the network directed to the server or the client directed to the server
- H04N21/64776—Control signals issued by the network directed to the server or the client directed to the server for requesting retransmission, e.g. of data packets lost or corrupted during transmission from server
Definitions
- the present invention relates in general to video encoding and decoding.
- VPx a standard promulgated by Google Inc. of Mountain View, California
- MPEG Moving Picture Experts Group
- H.264 is also known as MPEG-4 Part 10 or MPEG-4 AVC (formally, ISO/IEC 14496-10).
- the method includes receiving the plurality of frames via a network, each frame having an estimated arrival time, determining a retransmission rendering delay for a current frame of the plurality of frames using a processor, determining a render time for the current frame using a sum of the estimated arrival time and the retransmission rendering delay of the current frame, and rendering the current frame at the render time.
- the method can include determining a round-trip delay for the current frame and determining the retransmission rendering delay using the round-trip delay.
- the method can include determining a round-trip delay constant for the current frame and determining the retransmission rendering delay using the round-trip delay and the round-trip delay constant.
- the method can include determining the round-trip delay for the current frame based on a round-trip time of the current frame and a round trip time of one or more previously received frames, the previously received frames received before the current frame, determining the round-trip delay for the current frame as the larger of a round-trip delay of a previous frame and the round-trip time of the current frame, or determining the round-trip delay for the current frame as a maximum of the round-trip times of a pre-determined number of the previously received frames if there is a sudden change in round-trip times of the previous frames and current frame or a drift change in round-trip times of the previous frames and current frame.
- the method can include determining the round-trip delay constant using the
- f p(foss)'
- f a pre-determined function
- p(loss) a packet loss probability for the current frame
- N an upper limit of the summation or determining the round-trip delay constant as a pre-determined integer (such as 1)
- the method can include determining a number of packets received and a number of packets lost over a time period and determining the packet loss probability for the current frame by dividing the number of packets received by the number of packets iost,
- the pre-determined function f can be a unit-step function.
- the method can include determining the retransmission rendering delay based on a product of the round-trip delay and the round-trip delay constant.
- the method can include determining at least one statistic of round-trip times of at least some of the plurality of frames, and determining the round-trip delay as a maximum of the round-trip times of a pre-determined number of previously received frames if a sudden round-trip time change or a drift round-trip time change is detected using the at least one statistic.
- the method can include calculating an average round-trip time of at least some of the plurality of frames, calculating a standard deviation of the round-trip times of at least some of the plurality of frames, and detecting the sudden round-trip time change when Ni - 1 ⁇
- Nt is the pre-determined number of previously received frames
- u() is a unit step function
- T J ( «-*) ⁇ is the difference between the average round-trip time and the round-trip time of frame n-i;
- n is the index of the current frame in the video stream
- Yi is the standard deviation multiplied by a pre-determined constant
- V2 is a sudden-change threshold.
- the method can include calculating a difference between the round-trip delay and the round-trip times of at least some of the plurality of frames, calculating a variance of the round-trip times of at least some of the plurality of frames, and detecting a drift round-trip
- N] is the pre-determined number of previously received frames
- u() is the unit step function
- i(n -i) i s the difference between the average round-trip time and the round-trip delay of frame n-i;
- n is the index of the current frame in the video stream
- ⁇ 3 is the variance multiplied by a pre-determined constant
- ⁇ 4 is a drift-change threshold.
- the method can include determining the estimated arrival time based on actual arrival times of previously received frames, the previously received frames received before the current frame.
- the at least one statistic can include (a) a difference between an average round-trip time and the round-trip time for at least some of the plurality of frames and (b) a standard deviation of round-trip times.
- a sudden change is detected when the result of a series over a pre-determined number of recent frames of the unit-step function of the difference of each frame's difference and the standard deviation multiplied by a predetermined constant is greater than a sudden-change threshold.
- the at least one statistic can alternatively include (a) a difference between the round-trip delay and the round-trip time for at least some of the plurality of frames and (b) a standard deviation of round-trip times.
- a drift change is indicated when the result of a series over a pre-determined number of recent frames of the unit-step function of the difference of each frame's difference and the standard deviation multiplied by a predetermined constant is greater than a drift-change threshold.
- an apparatus for rendering a video stream having a plurality of frames.
- the apparatus comprises a memory and at least one processor configured to execute instructions stored in the memory to receive the plurality of frames via a network, each frame having an estimated arrival time, determine a retransmission rendering delay for a current frame of the plurality of frames, determine a render time for the current frame using the estimated arrival time and the retransmission rendering delay of the current frame, and render the current frame at the render time.
- the apparatus can include instructions to determine a round-trip delay for the current frame based on a round-trip time of the current frame and a round-trip time of one or more previously received frames, the previously received frames received before the current
- p(loss) is a packet loss probability of the current frame
- N is an upper limit of the summation
- the apparatus can include instructions to determine at least one statistic of the round-trip times of at least some of the plurality of frames and determine the round-trip delay as a maximum of the round-trip times of a pre-determined number of previously received frames if a sudden round-trip time change or a drift round-trip time change is detected using the at least one statistic.
- the apparatus can include instructions to calculate an average round-trip time of at least some of the plurality of frames, calculate a standard deviation of the round-trip times of at least some of the plurality of frames, and detect the sudden round-trip time change when
- Nt is the pre-determined number of previously received frames
- u() is a unit step function; ⁇ ( ⁇ - ⁇ - i s the difference between the average round-trip time and the round-trip time of frame n-i;
- n is the index of the current frame in the video stream
- Yt is the standard deviation multiplied by a pre-determined constant
- ⁇ 2 is a sudden-change threshold.
- Also included in the disclosed embodiments is a method for rendering a current frame from a video stream's plurality of frames.
- the method includes receiving the current frame, determining an estimated arrival time for the current frame, determining a jitter rendering delay, determining a packet loss probability for the current frame, determining a retransmission rendering delay using the packet loss probability and the larger of a previous frame's retransmission rendering delay and the current frame's round-trip time, determining a render time for the current frame by adding the estimated arrival time, the jitter rendering delay and the retransmission rendering delay, and rendering the current frame at the render time.
- FIG. 1 is a schematic of a video encoding and decoding system
- FIG. 2 is a diagram of a video stream
- FIG. 3 is a timeline of transmitting and rendering a frame of a video stream
- FIG. 4 is a flow chart of a method of determining a render time for a frame
- FIG. 5 is a flow chart of a method of determining a retransmission rendering delay
- FIG. 6 is a graph illustrating the determination of a round-trip delay
- FIG. 7 is a graph illustrating a sudden round-trip time change
- FIG. 8 is a graph illustrating a drift round-trip time change.
- FIG. 1 is a diagram of an encoder and decoder system 10 for still or dynamic video images.
- An exemplary transmitting station 12 may be, for example, a computer having an internal configuration of hardware including a processor such as a central processing unit (CPU) 14 and a memory 16.
- CPU 14 is a controller for controlling the operations of transmitting station 12, CPU 14 is connected to memory 16 by, for example, a memory bus.
- Memory 16 may be random access memory (RAM) or any other suitable memory device.
- RAM random access memory
- Memory 16 stores data and program instructions that are used by CPU 14, Other suitable implementations of transmitting station 12 are possible.
- a network 28 connects transmitting station 12 and a receiving station 30 for transmission of an encoded video stream.
- the video stream can be encoded by an encoder in transmitting station 12 and the encoded video stream can be decoded by a decoder in receiving station 30.
- Network 28 may, for example, be the Internet, which is a packet-switched network.
- Network 28 may also be a local area network (LAN), wide area network (WAN), virtual private network (VPN), or any other means of transferring the video stream from transmitting station 12.
- LAN local area network
- WAN wide area network
- VPN virtual private network
- the transmission of the encoded video stream can be accomplished using a real-time protocol, such as the real-time transport protocol (RTP) standard as promulgated by the Internet Engineering Task Force (IETF).
- RTP real-time transport protocol
- IETF Internet Engineering Task Force
- RTCP real-time transport control protocol
- RTP real-time transport control protocol
- RTCP can allow a receiving station to determine information about the round-trip time TRTT I) of transmission.
- the round-trip time T R -rr(n) is an estimate by the transmission protocol of the amount of time that would be required for a transmitting station to transmit a frame of video to a receiving station and receive back an acknowledgement of receipt from the receiving station.
- the round-trip time T RT T(n) can alternatively be determined differently if a protocol other than RTCP is used.
- the round-trip time ⁇ ⁇ ⁇ ( ⁇ ) includes only network transmission time and excludes any processing time at the receiving station to send the acknowledgement after receipt of the frame.
- the round-trip time ⁇ ⁇ ⁇ ( ⁇ ) is the round-trip time as of frame n.
- the round-trip time may be determined or received via RTCP at a frequency less than the frame rate. For example, the receiving station may receive thirty frames in one second while only receiving a new round-trip time ⁇ ⁇ ⁇ ( ⁇ ) five times per second,
- Receiving station 30, in one example, may be a computer having an internal configuration of hardware including a processor such as a central processing unit (CPU) 32 and a memory 34.
- CPU 32 is a controller for controlling the operations of receiving station 30, CPU 32 can be connected to memory 34 by, for example, a memory bus.
- Memory 34 may be RAM or any other suitable memory device. Memory 34 stores data and program instructions that are used by CPU 32. Other suitable implementations of receiving station 30 are possible.
- a display 36 configured to display a video stream can be connected to receiving station 30, Display 36 may be implemented in various ways, including by a liquid crystal display (LCD) or a cathode-ray tube (CRT). The display 36 can be configured to display a rendering of the video stream decoded by the decoder in receiving station 30.
- LCD liquid crystal display
- CRT cathode-ray tube
- encoder and decoder system 10 Other implementations of the encoder and decoder system 10 are possible.
- additional components may be added to the encoder and decoder system 10.
- a display or a video camera may be attached to transmitting station 12 to capture the video stream to be encoded.
- a transport protocol other than RTP may be used.
- Real-time encoding, transmission, decoding and rendering can result in a rendered video stream (i.e. on display 36) that includes gaps in the video stream if there are portions of the original video stream that are lost or delayed in transmission.
- One way to recover lost packets is for the transmitting station to re-transmit the missing portion of the video stream, in a packet-switched network, the lost portion would include one or more lost packets, and the re-transmission would include those one or more lost packets.
- the retransmission of packets results in a delay in the receipt of frames by the receiving station. This delay can cause a video freeze or an error that can be displayed on the receiving station.
- At least some gaps can be avoided by rendering at a render time calculated by adding a delay to the actual receive time of video stream frames.
- variations in the arrival time of frames can be caused by, for example, changes in network transmission time (network jitter), changes in the amount of time to encode the frames, and clock drift between the transmitting station and the receiving station. These variations can cause a video stream to be rendered at frame rates different than at which the video stream was encoded or captured.
- the render time can be based on an estimated arrival time instead of the actual arrival time.
- the estimated arrival time is determined using a filter designed to filter out the variations.
- the estimated arrival time can determine an actual render time at which frames are rendered, instead of rendering frames out of a buffer at a constant frame rate and adjusting for variations such as clock drift by manipulating the buffer (i.e. by dropping frames).
- FIG. 2 is a diagram of a typical video stream 50 to be encoded and decoded.
- Video coding formats for example, VP8 or H.264, provide a defined hierarchy of layers for video stream 50.
- Video stream 50 includes a video sequence 52.
- video sequence 52 consists of a number of adjacent frames 54, which can then be further subdivided into a single frame 56.
- frame 56 can be divided into a series of blocks 58, which can contain data corresponding to, for example, a 16x16 block of displayed pixels in frame 56. Each block can contain luminance and chrominance data for the corresponding pixels.
- Blocks 58 can also be of any other suitable size such as 16x8 pixel groups or 8x16 pixel groups.
- Other encoding/decoding formats for frames 54 including those that are not block-based, can be used.
- FIG. 3 is a timeline 60 of transmitting and rendering a frame n (current frame) of a video stream in the video encoding and decoding system of FIG. 1 .
- the frame has a timestamp T s (n) 62 assigned by a transmitting station. T s (n) 62 is generated using the transmitting station's clock.
- the timestamp can be a send time of when the frame is sent to the receiving station by the transmitting station or a capture time of when the frame is captured by a capture device, such as a video camera.
- the frame can be transmitted with the timestamp.
- the frame has an estimated arrival time T c (n) 64 of when the frame is expected to arrive at the receiving station.
- the estimated arrival time T c (n) 64 is determined using the receiving station's clock and is described further later.
- the frame will be rendered at the render time T (H) 66 on the receiving station.
- the frame may be rendered at the render time T R (n) 66 even if the frame is not actually rendered at that time.
- the render time 3 ⁇ 4(n) 66 is a target time for rendering and the time that the rendering actually occurs at may vary from the render time, The difference between these values can be, for example, due to high resource utilization of the receiving station's resources. Other factors may also contribute to the difference.
- the time interval between the timestamp Ts(n) 62 and the estimated arrival time T c (n) 64 is the estimated one-way time offset ⁇ ( ⁇ ) 68.
- the estimated one-way time offset ⁇ ( ⁇ ) 68 includes a one-way transmission time for the frame to transit the network 28 and a clock offset, which is the difference between the transmitting station and receiving station clocks.
- the time interval between the estimated arrival time 64 and the render time T R (n) 66 is the delay D(n) 69.
- the delay D(n) 69 is determined and used by the decoder to account for at least some expected variations in the actual arrival time of the frame.
- Delay D(n) 69 can include, for example, a jitter delay Dj(n) and a retransmission rendering delay DR'IT(II). Delay D(n) 69 may alternatively include other delays in other implementations. [0048] The actual arrival time of the frame can be any time after timestamp Ts(n) 62.
- the delay 69 will be of a time interval where the actual arrival time of frames will be earlier than the render time Tit(n) 66.
- the frame will be rendered at its render time, and gaps in the rendered video stream will be avoided,
- FIG. 4 is a flow chart of a method 70 of determining a render time Tn(n) for a frame n.
- the method 70 can be performed by a decoder on a receiving station, such as receiving station 30, upon receipt of one or more frames of a video stream.
- estimated arrival time Tc(n) of the frame n is determined using various techniques.
- One technique includes estimating arrival time 64 of the frame based on the actual arrival times of previously received frames. For example, an average time interval between actual arrival times of previously received frames could be used to estimate when the frame will arrive. In alternative examples, histograms, curve fitting techniques and statistical analysis could be utilized to determine estimated arrival time 64.
- the time intervals between estimated arrival times 64 of successive frames may be constant. Alternatively, the time intervals between estimated arrival times 64 may change over time to, for example, account for changing network conditions.
- a jitter delay Dj(n) for frame n is determined.
- the purpose of jitter delay Dj(n) is to account for variations in the one-way time offset of the transmission of frames from transmitting station 12 to receiving station 30 caused by jitter.
- the jitter delay can be determined based on the actual arrival times of previously received frames and the timestamps of previously received frames.
- the jitter delay can alternatively be determined using other techniques.
- a retransmission rendering delay is determined.
- the retransmission rendering delay accounts for the time needed to re-transmit a frame in the event that it is lost during transmission.
- the retransmission rendering delay can include a round-trip delay DRTT I) and a round-trip delay constant ⁇ . The determination of these values is described later.
- render time ⁇ ,( ⁇ ) is determined using the values determined above.
- jitter delay Dj(n) may be omitted and/or other delays added.
- timestamp 62 may be used with one-way time offset 68 instead of estimated arrival time 64 to determine render time TR I).
- Other variations are also possible.
- FIG. 5 is a flow chart of a method 90 of determining the retransmission rendering delay of stage 76.
- the method 90 is performed when a new round-trip time is received or determined by the receiving station 30.
- a new round-trip time can be received less often than frames. For example, one updated round-trip time may be received for every five frames. If a new round-trip time has not been received since the previous frame, then that frame's round-trip time is the round-trip time of the previous frame.
- the retransmission rendering delay is the product of round-trip delay DRTTO and round-trip delay constant ⁇
- round-trip delay constant ⁇ is determined.
- Round-trip delay constant ⁇ modifies round-trip delay DRTIO 1 ).
- round-trip delay constant ⁇ may always be one— in other words, the retransmission rendering delay is round- trip delay DRTT -
- round-trip delay constant ⁇ is used to modify round- trip delay DRrr(n) based on the probability of packet loss p(loss).
- p(loss) is a value between 0 and 1 , wherein 0 indicates no probability of packet loss and 1 indicates that there will always be packet loss.
- the packet loss probability can be determined by, for example, dividing the total number of packets lost by the tot l number of packets received over a time period. Other methods of determining packet loss probability are also available. For example, a weighted average technique may be used, wherein recent packet losses are more heavily weighted in the probability determination than more remote packet losses.
- P is a probability threshold
- the probabilities of one and more successive packet losses are evaluated, For each packet loss that exceeds the probability threshold P, the value of round- trip delay constant ⁇ is increased by one. For example, if the packet loss probability indicates that the probability of losing two packets (for the same frame) exceeds P, then the round-trip delay constant ⁇ would be two.
- any pre-determined function fQ can instead be used for determining the round-trip delay constant ⁇ as follows:
- a piecewise function f() is used to "soften" the transition between zero and one.
- the summation may not use infinity as an upper bound.
- the summation's upper bound may be lower based on implementation constraints or based on the level of precision required. For example, a pre-determined upper bound "N" may be used to limit the amount of computation required in an implementation.
- the summation may be stopped at a given value of i when the result of the function for that value of i is zero. In other words, the summation may be stopped when it is known that the probability of additional packet losses will be less than the threshold P.
- round-trip delay ⁇ ( ⁇ ) is determined.
- DR-n(n-l) is the round-trip delay for the previous frame n-1 ;
- T TT(II) is a round-trip time for frame n.
- the round-trip delay D RTT for the first frame in a video stream can be determined using the round-trip time T RTT for that first frame,
- the round trip delay for the frame before the first frame DRTT(O) can be initialized to a small value, such as zero, so that the first frame's round-trip delay D RT T is its round-trip time T RTT .
- Other formulas or methods may be used to determine round-trip delay D R rr(n)
- a measure other than round-trip time T RTT (n) may be used. For example, an experiential model may be used wherein the actual transmission time of previous retransmissions are measured and used to determine round-trip delay D RTT (n).
- FIG. 6 is a graph 120 illustrating the determination of round-trip delay D R iT(n) accoi'ding to formula (9). Round-trip time T rr(n) (solid line 122) is shown over time.
- Round-trip delay DRTT 1 (dashed line 124) shows the round-trip delay that determined using formula (9). As graph 120 shows, round-trip delay D RT r(n) identifies the maximum round- trip time of previously received frames to find the round-trip delay for a current frame.
- the decoder checks for a sudden round- trip time change ("sudden change").
- the decoder uses statistics of previous round-trip times to detect the sudden change.
- a sudden change can be detected using this formula: u( Ti ( - ⁇ )- ! ) >7 2
- Ni is a pre-determined number of recent frames to test
- 3 ⁇ 4 (n) a3 ⁇ 4 (n - 1) +(1 - a)T nTT (n). (12) a is a weighting constant that can be selected from the interval [0.9,0.999];
- ⁇ is a confidence threshold defined as:
- ⁇ is a confidence-interval factor
- 3 ⁇ 4TT( ) is the standard deviation of round-trip times and can be calculated as the square root of the estimated variance of round-trip times o 2 RTr(n), which is defined as:
- drift change a drift round-trip time change
- ⁇ a is defined as:
- 73 is a confidence threshold defined as:
- ⁇ 2 is a confidence- interval factor
- 74 is a drift-change threshold that is a positive integer.
- round-trip delay constant ⁇ determined in stage 92 and round-trip delay D RTT (n) determined in stage 94 will be used to determine the retransmission rendering delay of the frame.
- control will pass to stage 100, where round-trip delay D RT r(n) is re-determined.
- the re-determination of round- trip delay D RTT (n) uses a pre-defined number of round-trip times for recent frames as shown below:
- average round-trip time T ]r is re-determined as follows:
- T nTT z—— - ⁇ T RTT (n ⁇ i)
- formulas (10) and (15) are to detect changes in network delay for retransmissions that are not caused by mere network congestion. These formulas for detecting sudden change and drift change are only two ways of detecting a change in network delay for retransmissions and other detectors are possible in other implementations.
- FIG. 7 is a graph 140 illustrating a sudden round-trip time change.
- Round-trip time T RTT (solid line 142) is shown over time.
- Round-trip delay D RTT (dashed line 144) is shown both before and after the detection of the sudden round-trip change.
- Confidence factor ⁇ (dotted line 146) used for detecting the sudden round-trip change is also shown.
- FIG. 8 is a graph 160 illustrating a drift round-trip time change.
- Round-trip time T RTT (solid line 162) is shown over time.
- Round-trip delay DRTT (dashed line 164) is shown both before and after the detection of the drift round-trip change.
- Confidence factor ⁇ 3 (dotted line 1 6) used for detecting the drift round-trip change is also shown,
- transmitting station 12 and/or receiving station 30 can be realized in hardware, software, or any combination thereof including, for example, IP cores, ASICS, programmable logic arrays, optical processors, programmable logic control lers, microcode, firmware, microcontrollers, servers, microprocessors, digital signal processors or any other suitable circuit.
- processor should be understood as encompassing any the foregoing, either singly or in combination.
- signal and “data” are used interchangeably. Further, portions of transmitting station 12 and receiving station 30 do not necessarily have to be implemented in the same manner.
- transmitting station 12 or receiving station 30 can be implemented using a general purpose computer/processor with a computer program that, when executed, carries out any of the respective methods, algorithms and/or instructions described herein.
- a special purpose computer/processor with a computer program that, when executed, carries out any of the respective methods, algorithms and/or instructions described herein.
- a special purpose computer/processor with a computer program that, when executed, carries out any of the respective methods, algorithms and/or instructions described herein.
- Transmitting station 12 and receiving station 30 can, for example, be implemented on computers in a screencasting or a videoconferencing system.
- transmitting station 12 can be implemented on a server and receiving station 30 can be implemented on a device separate from the server, such as a hand-held communications device (i.e. a cell phone).
- transmitting station 12 can encode content using an encoder into an encoded video signal and transmit the encoded video signal to the communications device.
- the communications device can then decode the encoded video signal using a decoder.
- the communications device can decode content stored locally on the communications device (i.e. no transmission is necessary),
- Other suitable transmitting station 12 and receiving station 30 implementation schemes are available.
- receiving station 30 can be a personal computer rather than a portable communications device.
- all or a portion of embodiments of the present invention can take the form of a computer program product accessible from, for example, a computer-usable or computer-readable medium.
- a computer-usable or computer-readable medium can be any device that can, for example, tangibly contain, store, communicate, or transport the program for use by or in connection with any processor.
- the medium can be, for example, an electronic, magnetic, optical, electromagnetic, or a semiconductor device. Other suitable mediums are also available.
Abstract
A system, apparatus, and method for rendering a video stream, the video stream having a plurality of frames. One method includes receiving the plurality of frames via a network, each frame having an estimated arrival time, determining a retransmission rendering delay for a current frame from the plurality of frames, determining a render time for the current frame using a sum of the current frame's estimated arrival time and the retransmission rendering delay, and rendering the current frame at the render time.
Description
APPARATUS AND METHOD FOR RENDERING VIDEO
WITH RETRANSMISSION DELAY
TECHNICAL FIELD
[0001] The present invention relates in general to video encoding and decoding.
BACKGROUND
[0002] An increasing number of applications today make use of digital video for various purposes including, for example, remote business meetings via video conferencing, high definition video entertainment, video advertisements, and sharing of user-generated videos. As technology is evolving, users have higher expectations for video quality and expect high resolution video even when transmitted over communications channels having limited bandwidth. One type of video transmission includes real-time encoding and transmission, in which the receiver of a video stream decodes and renders frames as they are received.
[0003] To permit transmission of digital video streams while limiting bandwidth consumption, a number of video compression schemes have been devised, including formats such as VPx, promulgated by Google Inc. of Mountain View, California, and H.264, a standard promulgated by ITU-T Video Coding Experts Group (VCBG) and the ISO/IEC Moving Picture Experts Group (MPEG), including present and future versions thereof. H.264 is also known as MPEG-4 Part 10 or MPEG-4 AVC (formally, ISO/IEC 14496-10).
SUMMARY
[0004] Disclosed herein are embodiments of methods and apparatuses for rendering a video signal.
[0005] Included in the disclosed embodiments is a method for rendering a video stream, the video stream having a plurality of frames. The method includes receiving the plurality of frames via a network, each frame having an estimated arrival time, determining a retransmission rendering delay for a current frame of the plurality of frames using a processor, determining a render time for the current frame using a sum of the estimated arrival time and the retransmission rendering delay of the current frame, and rendering the current frame at the render time.
[0006] The method can include determining a round-trip delay for the current frame and determining the retransmission rendering delay using the round-trip delay.
[0007] The method can include determining a round-trip delay constant for the current frame and determining the retransmission rendering delay using the round-trip delay and the round-trip delay constant.
[0008] The method can include determining the round-trip delay for the current frame based on a round-trip time of the current frame and a round trip time of one or more previously received frames, the previously received frames received before the current frame, determining the round-trip delay for the current frame as the larger of a round-trip delay of a previous frame and the round-trip time of the current frame, or determining the round-trip delay for the current frame as a maximum of the round-trip times of a pre-determined number of the previously received frames if there is a sudden change in round-trip times of the previous frames and current frame or a drift change in round-trip times of the previous frames and current frame.
[0009] The method can include determining the round-trip delay constant using the
N
formula f(p(foss)') , wherein f is a pre-determined function, p(loss) is a packet loss probability for the current frame, and N is an upper limit of the summation or determining the round-trip delay constant as a pre-determined integer (such as 1),
[0010] The method can include determining a number of packets received and a number of packets lost over a time period and determining the packet loss probability for the current frame by dividing the number of packets received by the number of packets iost,
[001 1 ] The pre-determined function f can be a unit-step function.
[0012] The method can include determining the retransmission rendering delay based on a product of the round-trip delay and the round-trip delay constant.
[0013] The method can include determining at least one statistic of round-trip times of at least some of the plurality of frames, and determining the round-trip delay as a maximum of the round-trip times of a pre-determined number of previously received frames if a sudden round-trip time change or a drift round-trip time change is detected using the at least one statistic.
[0014] The method can include calculating an average round-trip time of at least some of the plurality of frames, calculating a standard deviation of the round-trip times of at
least some of the plurality of frames, and detecting the sudden round-trip time change when Ni - 1 ^
∑ ι*( Γι (η - »)- 7ι) >72
/ = 0 ; wherein
Nt is the pre-determined number of previously received frames;
u() is a unit step function;
TJ («-*)■ is the difference between the average round-trip time and the round-trip time of frame n-i;
n is the index of the current frame in the video stream;
Yi is the standard deviation multiplied by a pre-determined constant; and
V2 is a sudden-change threshold.
[0015] The method can include calculating a difference between the round-trip delay and the round-trip times of at least some of the plurality of frames, calculating a variance of the round-trip times of at least some of the plurality of frames, and detecting a drift round-trip
Ni - l
time change using the formula / = o , wherein
N] is the pre-determined number of previously received frames;
u() is the unit step function;
i(n -i) is the difference between the average round-trip time and the round-trip delay of frame n-i;
n is the index of the current frame in the video stream;
γ3 is the variance multiplied by a pre-determined constant; and
γ4 is a drift-change threshold.
[0016] The method can include determining the estimated arrival time based on actual arrival times of previously received frames, the previously received frames received before the current frame.
[0017] The at least one statistic can include (a) a difference between an average round-trip time and the round-trip time for at least some of the plurality of frames and (b) a standard deviation of round-trip times. In this aspect, a sudden change is detected when the result of a series over a pre-determined number of recent frames of the unit-step function of the difference of each frame's difference and the standard deviation multiplied by a predetermined constant is greater than a sudden-change threshold.
[0018] The at least one statistic can alternatively include (a) a difference between the round-trip delay and the round-trip time for at least some of the plurality of frames and (b) a
standard deviation of round-trip times. In this aspect, a drift change is indicated when the result of a series over a pre-determined number of recent frames of the unit-step function of the difference of each frame's difference and the standard deviation multiplied by a predetermined constant is greater than a drift-change threshold.
[0019] Also included in the disclosed embodiments is an apparatus for rendering a video stream, the video stream having a plurality of frames. The apparatus comprises a memory and at least one processor configured to execute instructions stored in the memory to receive the plurality of frames via a network, each frame having an estimated arrival time, determine a retransmission rendering delay for a current frame of the plurality of frames, determine a render time for the current frame using the estimated arrival time and the retransmission rendering delay of the current frame, and render the current frame at the render time.
[0020] The apparatus can include instructions to determine a round-trip delay for the current frame based on a round-trip time of the current frame and a round-trip time of one or more previously received frames, the previously received frames received before the current
N
frame, determine a round-trip delay constant using the formula ^fipQoss)1 ) , wherein f is a
=l
pre-determined function, p(loss) is a packet loss probability of the current frame, and N is an upper limit of the summation, and determine the retransmission rendering delay using the round-trip delay and the round-trip delay constant.
[0021] The apparatus can include instructions to determine at least one statistic of the round-trip times of at least some of the plurality of frames and determine the round-trip delay as a maximum of the round-trip times of a pre-determined number of previously received frames if a sudden round-trip time change or a drift round-trip time change is detected using the at least one statistic.
[0022] The apparatus can include instructions to calculate an average round-trip time of at least some of the plurality of frames, calculate a standard deviation of the round-trip times of at least some of the plurality of frames, and detect the sudden round-trip time change when
∑ «( r, (n- t)- l) >72
i = 0 ; wherein
Nt is the pre-determined number of previously received frames;
u() is a unit step function;
ί(η-ο- is the difference between the average round-trip time and the round-trip time of frame n-i;
n is the index of the current frame in the video stream;
Yt is the standard deviation multiplied by a pre-determined constant; and
γ2 is a sudden-change threshold.
[0023] Also included in the disclosed embodiments is a method for rendering a current frame from a video stream's plurality of frames. The method includes receiving the current frame, determining an estimated arrival time for the current frame, determining a jitter rendering delay, determining a packet loss probability for the current frame, determining a retransmission rendering delay using the packet loss probability and the larger of a previous frame's retransmission rendering delay and the current frame's round-trip time, determining a render time for the current frame by adding the estimated arrival time, the jitter rendering delay and the retransmission rendering delay, and rendering the current frame at the render time.
[0024] These and other embodiments, including combinations and variations of these embodiments, will be described in additional detail hereafter.
BRIEF DESCRIPTION OF THE DRAWINGS
[0025] The description herein makes reference to the accompanying drawings wherein like reference numerals refer to like parts throughout the several views, and wherein:
[0026] FIG. 1 is a schematic of a video encoding and decoding system;
[0027] FIG. 2 is a diagram of a video stream;
[0028] FIG. 3 is a timeline of transmitting and rendering a frame of a video stream;
[0029] FIG. 4 is a flow chart of a method of determining a render time for a frame;
[0030] FIG. 5 is a flow chart of a method of determining a retransmission rendering delay;
[0031] FIG. 6 is a graph illustrating the determination of a round-trip delay;
[0032] FIG. 7 is a graph illustrating a sudden round-trip time change; and
[0033] FIG. 8 is a graph illustrating a drift round-trip time change.
DETAILED DESCRIPTION
[0034] FIG. 1 is a diagram of an encoder and decoder system 10 for still or dynamic video images. An exemplary transmitting station 12 may be, for example, a computer having
an internal configuration of hardware including a processor such as a central processing unit (CPU) 14 and a memory 16. CPU 14 is a controller for controlling the operations of transmitting station 12, CPU 14 is connected to memory 16 by, for example, a memory bus. Memory 16 may be random access memory (RAM) or any other suitable memory device. Memory 16 stores data and program instructions that are used by CPU 14, Other suitable implementations of transmitting station 12 are possible.
[0035] A network 28 connects transmitting station 12 and a receiving station 30 for transmission of an encoded video stream. Specifically, the video stream can be encoded by an encoder in transmitting station 12 and the encoded video stream can be decoded by a decoder in receiving station 30. Network 28 may, for example, be the Internet, which is a packet-switched network. Network 28 may also be a local area network (LAN), wide area network (WAN), virtual private network (VPN), or any other means of transferring the video stream from transmitting station 12.
[0036] The transmission of the encoded video stream can be accomplished using a real-time protocol, such as the real-time transport protocol (RTP) standard as promulgated by the Internet Engineering Task Force (IETF). Control of the transmission can be
accomplished using the real-time transport control protocol (RTCP) defined in the RTP standard. For example, RTCP can allow a receiving station to determine information about the round-trip time TRTT I) of transmission. The round-trip time TR-rr(n) is an estimate by the transmission protocol of the amount of time that would be required for a transmitting station to transmit a frame of video to a receiving station and receive back an acknowledgement of receipt from the receiving station.
[0037] However, the round-trip time TRTT(n) can alternatively be determined differently if a protocol other than RTCP is used. The round-trip time ΤβΤτ(η) includes only network transmission time and excludes any processing time at the receiving station to send the acknowledgement after receipt of the frame. The round-trip time Τβττ(η) is the round-trip time as of frame n. However, the round-trip time may be determined or received via RTCP at a frequency less than the frame rate. For example, the receiving station may receive thirty frames in one second while only receiving a new round-trip time Τβττ(η) five times per second,
[0038] Receiving station 30, in one example, may be a computer having an internal configuration of hardware including a processor such as a central processing unit (CPU) 32 and a memory 34. CPU 32 is a controller for controlling the operations of receiving station 30, CPU 32 can be connected to memory 34 by, for example, a memory bus. Memory 34
may be RAM or any other suitable memory device. Memory 34 stores data and program instructions that are used by CPU 32. Other suitable implementations of receiving station 30 are possible.
[0039] A display 36 configured to display a video stream can be connected to receiving station 30, Display 36 may be implemented in various ways, including by a liquid crystal display (LCD) or a cathode-ray tube (CRT). The display 36 can be configured to display a rendering of the video stream decoded by the decoder in receiving station 30.
[0040] Other implementations of the encoder and decoder system 10 are possible. In one implementation, additional components may be added to the encoder and decoder system 10. For example, a display or a video camera may be attached to transmitting station 12 to capture the video stream to be encoded. In another implementation, a transport protocol other than RTP may be used.
[0041] Real-time encoding, transmission, decoding and rendering can result in a rendered video stream (i.e. on display 36) that includes gaps in the video stream if there are portions of the original video stream that are lost or delayed in transmission. One way to recover lost packets is for the transmitting station to re-transmit the missing portion of the video stream, in a packet-switched network, the lost portion would include one or more lost packets, and the re-transmission would include those one or more lost packets. However, the retransmission of packets results in a delay in the receipt of frames by the receiving station. This delay can cause a video freeze or an error that can be displayed on the receiving station.
[0042] At least some gaps can be avoided by rendering at a render time calculated by adding a delay to the actual receive time of video stream frames. However, variations in the arrival time of frames can be caused by, for example, changes in network transmission time (network jitter), changes in the amount of time to encode the frames, and clock drift between the transmitting station and the receiving station. These variations can cause a video stream to be rendered at frame rates different than at which the video stream was encoded or captured.
[0043] To render the video stream while minimizing such variations, the render time can be based on an estimated arrival time instead of the actual arrival time. The estimated arrival time is determined using a filter designed to filter out the variations. The estimated arrival time can determine an actual render time at which frames are rendered, instead of rendering frames out of a buffer at a constant frame rate and adjusting for variations such as clock drift by manipulating the buffer (i.e. by dropping frames).
[0044] FIG. 2 is a diagram of a typical video stream 50 to be encoded and decoded.
Video coding formats, for example, VP8 or H.264, provide a defined hierarchy of layers for video stream 50. Video stream 50 includes a video sequence 52. At the next level, video sequence 52 consists of a number of adjacent frames 54, which can then be further subdivided into a single frame 56. At the next level, frame 56 can be divided into a series of blocks 58, which can contain data corresponding to, for example, a 16x16 block of displayed pixels in frame 56. Each block can contain luminance and chrominance data for the corresponding pixels. Blocks 58 can also be of any other suitable size such as 16x8 pixel groups or 8x16 pixel groups. Other encoding/decoding formats for frames 54, including those that are not block-based, can be used.
[0045] FIG. 3 is a timeline 60 of transmitting and rendering a frame n (current frame) of a video stream in the video encoding and decoding system of FIG. 1 . The frame has a timestamp Ts(n) 62 assigned by a transmitting station. Ts(n) 62 is generated using the transmitting station's clock. The timestamp can be a send time of when the frame is sent to the receiving station by the transmitting station or a capture time of when the frame is captured by a capture device, such as a video camera. The frame can be transmitted with the timestamp. The frame has an estimated arrival time Tc(n) 64 of when the frame is expected to arrive at the receiving station. The estimated arrival time Tc(n) 64 is determined using the receiving station's clock and is described further later.
[0046] The frame will be rendered at the render time T (H) 66 on the receiving station. The frame may be rendered at the render time TR(n) 66 even if the frame is not actually rendered at that time. The render time ¾(n) 66 is a target time for rendering and the time that the rendering actually occurs at may vary from the render time, The difference between these values can be, for example, due to high resource utilization of the receiving station's resources. Other factors may also contribute to the difference.
[0047] The time interval between the timestamp Ts(n) 62 and the estimated arrival time Tc(n) 64 is the estimated one-way time offset Δ(η) 68. The estimated one-way time offset Δ(η) 68 includes a one-way transmission time for the frame to transit the network 28 and a clock offset, which is the difference between the transmitting station and receiving station clocks. The time interval between the estimated arrival time 64 and the render time TR(n) 66 is the delay D(n) 69. The delay D(n) 69 is determined and used by the decoder to account for at least some expected variations in the actual arrival time of the frame. Delay D(n) 69 can include, for example, a jitter delay Dj(n) and a retransmission rendering delay DR'IT(II). Delay D(n) 69 may alternatively include other delays in other implementations.
[0048] The actual arrival time of the frame can be any time after timestamp Ts(n) 62.
Generally, the delay 69 will be of a time interval where the actual arrival time of frames will be earlier than the render time Tit(n) 66. In this case, the frame will be rendered at its render time, and gaps in the rendered video stream will be avoided, However, in certain circumstances, it may be advantageous for the actual arrival time to be after the render time. For example, in the case of severe network congestion where frames are delayed for a significant period of time, allowing video jitter or gaps may be advantageous as compared to introducing a significant delay resulting in a significantly later render time.
[0049] FIG. 4 is a flow chart of a method 70 of determining a render time Tn(n) for a frame n. The method 70 can be performed by a decoder on a receiving station, such as receiving station 30, upon receipt of one or more frames of a video stream. At stage 72, estimated arrival time Tc(n) of the frame n is determined using various techniques. One technique includes estimating arrival time 64 of the frame based on the actual arrival times of previously received frames. For example, an average time interval between actual arrival times of previously received frames could be used to estimate when the frame will arrive. In alternative examples, histograms, curve fitting techniques and statistical analysis could be utilized to determine estimated arrival time 64. The time intervals between estimated arrival times 64 of successive frames may be constant. Alternatively, the time intervals between estimated arrival times 64 may change over time to, for example, account for changing network conditions.
[0050] At stage 74, a jitter delay Dj(n) for frame n is determined. The purpose of jitter delay Dj(n) is to account for variations in the one-way time offset of the transmission of frames from transmitting station 12 to receiving station 30 caused by jitter. The jitter delay can be determined based on the actual arrival times of previously received frames and the timestamps of previously received frames. The jitter delay can alternatively be determined using other techniques.
[0051] At stage 76, a retransmission rendering delay is determined. The
retransmission rendering delay accounts for the time needed to re-transmit a frame in the event that it is lost during transmission. The retransmission rendering delay can include a round-trip delay DRTT I) and a round-trip delay constant η. The determination of these values is described later.
[0052] At stage 78, render time Τκ,(η) is determined using the values determined above. One method of determining the render time is shown below:
Tn{n) = Tc(n)+ Dj(n)+ J]DnTJi ) (i)
[0053] Variations of the method 70 for determining render time Τκ(η) are possible.
For example, jitter delay Dj(n) may be omitted and/or other delays added. Or in another example, timestamp 62 may be used with one-way time offset 68 instead of estimated arrival time 64 to determine render time TR I). Other variations are also possible.
[0054] FIG. 5 is a flow chart of a method 90 of determining the retransmission rendering delay of stage 76. The method 90 is performed when a new round-trip time is received or determined by the receiving station 30. A new round-trip time can be received less often than frames. For example, one updated round-trip time may be received for every five frames. If a new round-trip time has not been received since the previous frame, then that frame's round-trip time is the round-trip time of the previous frame.
[0055] In one implementation, and as shown by example in formula (1) above, the retransmission rendering delay is the product of round-trip delay DRTTO and round-trip delay constant η, At stage 92, round-trip delay constant η is determined. Round-trip delay constant η modifies round-trip delay DRTIO1). In some implementations, round-trip delay constant η may always be one— in other words, the retransmission rendering delay is round- trip delay DRTT -
[0056] In other implementations, round-trip delay constant η is used to modify round- trip delay DRrr(n) based on the probability of packet loss p(loss). In the examples herein, p(loss) is a value between 0 and 1 , wherein 0 indicates no probability of packet loss and 1 indicates that there will always be packet loss. The packet loss probability can be determined by, for example, dividing the total number of packets lost by the tot l number of packets received over a time period. Other methods of determining packet loss probability are also available. For example, a weighted average technique may be used, wherein recent packet losses are more heavily weighted in the probability determination than more remote packet losses.
[0057] One formula for determining the round-trip delay constant η using p(loss) is as follows:
η = E u(p(lossY ~ P)
i = l ; wherein (2)
P is a probability threshold; and
u() is the unit-step function, defined as:
u{x - P) = li if x≥P (3) u(x ~ P) = Q, if x<P (4)
[0058] In formula (2), the probabilities of one and more successive packet losses are evaluated, For each packet loss that exceeds the probability threshold P, the value of round- trip delay constant η is increased by one. For example, if the packet loss probability indicates that the probability of losing two packets (for the same frame) exceeds P, then the round-trip delay constant η would be two.
[0059] In another implementation, any pre-determined function fQ can instead be used for determining the round-trip delay constant η as follows:
oo
ΐ = 1 ); wherein (5) f0 is a function defined as:
f(x) = 0, if x<a. (6) f(x) ^ Y^> if a < x < b
J ! b-a J - ™ ; and (7) f(x) = 1, if x>b. wherein (8) a and b are pre-determined constants.
[0060] In formula (5), a piecewise function f() is used to "soften" the transition between zero and one. In this formula, the transition slope is controlled by the parameters a and b. These parameters may be pre-determined before decoding, or may be determined by the decoder during decoding. However, this function is only one variation of functions that may be used. Others include a unit-step function as described previously (i.e., f(x) = u(x-P)) and other functions.
[0061 ] Variations of formulas (2) or (5) may be used for various implementations.
For example, the summation may not use infinity as an upper bound. Instead, the summation's upper bound may be lower based on implementation constraints or based on the level of precision required. For example, a pre-determined upper bound "N" may be used to limit the amount of computation required in an implementation. In another example, the summation may be stopped at a given value of i when the result of the function for that value of i is zero. In other words, the summation may be stopped when it is known that the probability of additional packet losses will be less than the threshold P.
[0062] In stage 94, round-trip delay ϋβττ(η) is determined. Round-trip delay DRTT(II) for a frame n can be determined using the following formula:
ηττ{η) = max{ ΟΠΤτ{η- 1), /ΪΓ (η)}; wherein (9)
DR-n(n-l) is the round-trip delay for the previous frame n-1 ;
T TT(II) is a round-trip time for frame n.
[0063] With respect to formula (9), the round-trip delay DRTT for the first frame in a video stream can be determined using the round-trip time TRTT for that first frame, In a similar implementation, the round trip delay for the frame before the first frame DRTT(O) can be initialized to a small value, such as zero, so that the first frame's round-trip delay DRTT is its round-trip time TRTT. Other formulas or methods may be used to determine round-trip delay DRrr(n), In other implementations, a measure other than round-trip time TRTT(n) may be used. For example, an experiential model may be used wherein the actual transmission time of previous retransmissions are measured and used to determine round-trip delay DRTT(n).
[0064] FIG. 6 is a graph 120 illustrating the determination of round-trip delay DRiT(n) accoi'ding to formula (9). Round-trip time T rr(n) (solid line 122) is shown over time.
Round-trip delay DRTT 1) (dashed line 124) shows the round-trip delay that determined using formula (9). As graph 120 shows, round-trip delay DRTr(n) identifies the maximum round- trip time of previously received frames to find the round-trip delay for a current frame.
[0065] Referring back to FIG. 5, in stage 96, the decoder checks for a sudden round- trip time change ("sudden change"). The decoder uses statistics of previous round-trip times to detect the sudden change. A sudden change can be detected using this formula: u( Ti ( - ΐ)- !) >72
■ί = 0 ; wherein (10)
Ni is a pre-determined number of recent frames to test;
n'n{n) \$ an average round trip time and is defined
¾ (n) = a¾ (n - 1) +(1 - a)TnTT(n). (12) a is a weighting constant that can be selected from the interval [0.9,0.999];
γι is a confidence threshold defined as:
I = C1iTi T{n). (13) ςι is a confidence-interval factor;
¾TT( ) is the standard deviation of round-trip times and can be calculated as the square root of the estimated variance of round-trip times o2RTr(n), which is defined as:
72 is a sudden-change threshold that is a positive integer,
[0066] If the result of formula (10) is true (i.e., the result of the summation is greater than γ2), then a sudden round-trip time change exists. In alternative implementations, variables in the above formula may be eliminated, added, or calculated differently, For example, the standard deviation may be calculated directly instead of by the square root of a variance, In another example, the actual average round-trip time may be estimated using an arithmetic mean,
[0067] If a sudden round-trip time change is not found in stage 96, the decoder determines whether there has been a drift round-trip time change ("drift change") in stage 98. A drift change can be detected using this formula:
JVt-l
∑ «('7ί 2(η-ί)- 73) >7
ΐ=0 ; wherein (15)
^a is defined as:
f 2(n) = Dnrr{n)~ TnTT(n) . (] 6)
73 is a confidence threshold defined as:
ς2 is a confidence- interval factor; and
74 is a drift-change threshold that is a positive integer.
[0068] If the result of formula (15) is true (i.e., the result of the summation is greater than 74), then a drift round-trip time change exists, In alternative implementations, variables in the above formula may be eliminated, added or calculated differently. For example, the standard deviation may be calculated directly instead of by the square root of a variance. In another example, the actual average round-trip time may be calculated instead of being estimated.
[0069] If a drift change is not found in stage 98, the method ends, Round-trip delay constant η determined in stage 92 and round-trip delay DRTT(n) determined in stage 94 will be used to determine the retransmission rendering delay of the frame. However, if either a sudden or drift change was detected in stage 96 or stage 98 respectively, control will pass to stage 100, where round-trip delay DRTr(n) is re-determined. The re-determination of round-
trip delay DRTT(n) uses a pre-defined number of round-trip times for recent frames as shown below:
DUTT = max{T ηττ(η),Τ nTT(n - 1), ...,TnTT{n - Ni + 1)} (] g)
[0070] In addition, average round-trip time T ]r is re-determined as follows:
TnTT =z—— - ∑ TRTT(n~i)
Ni -l i s= 0 ( I 9)
[0071] These re-determinations replace round-trip delay DRTT(n) with the largest round-trip time TRTT of the recent past and replaces average round-trip time TK1T with the average of round-trip time values from the recent past. The round-trip time values from the recent past are defined by Ni, which is a number of recent frames including the current frame. These new values replace the previous values based on values from the start of the video stream or the last re-determination. Once the values are re-determined in step 100, the new round-trip delay is used along with round-trip delay constant η to determine the
retransmission rendering delay of the current frame.
[0072] The purpose of formulas (10) and (15) is to detect changes in network delay for retransmissions that are not caused by mere network congestion. These formulas for detecting sudden change and drift change are only two ways of detecting a change in network delay for retransmissions and other detectors are possible in other implementations.
[0073] FIG. 7 is a graph 140 illustrating a sudden round-trip time change. Round-trip time TRTT (solid line 142) is shown over time. Round-trip delay DRTT (dashed line 144) is shown both before and after the detection of the sudden round-trip change. Confidence factor γι (dotted line 146) used for detecting the sudden round-trip change is also shown.
[0074] FIG. 8 is a graph 160 illustrating a drift round-trip time change. Round-trip time TRTT (solid line 162) is shown over time. Round-trip delay DRTT (dashed line 164) is shown both before and after the detection of the drift round-trip change. Confidence factor γ3 (dotted line 1 6) used for detecting the drift round-trip change is also shown,
[0075] The above-described embodiments of encoding or decoding may illustrate some exemplary encoding techniques. However, in general, encoding and decoding as those terms are used in the claims are understood to mean compression, decompression, transformation or any other change to data whatsoever,
[0076] The embodiments of transmitting station 12 and/or receiving station 30 (and the algorithms, methods, instructions etc. stored thereon and/or executed thereby) can be realized in hardware, software, or any combination thereof including, for example, IP cores,
ASICS, programmable logic arrays, optical processors, programmable logic control lers, microcode, firmware, microcontrollers, servers, microprocessors, digital signal processors or any other suitable circuit. In the claims, the term "processor" should be understood as encompassing any the foregoing, either singly or in combination. The terms "signal" and "data" are used interchangeably. Further, portions of transmitting station 12 and receiving station 30 do not necessarily have to be implemented in the same manner.
[0077] Further, in certain embodiments, transmitting station 12 or receiving station 30 can be implemented using a general purpose computer/processor with a computer program that, when executed, carries out any of the respective methods, algorithms and/or instructions described herein. In addition or alternatively, for example, a special purpose
computer/processor can be utilized that contains specialized hardware for carrying out any of the methods, algorithms, or instructions described herein.
[0078] Transmitting station 12 and receiving station 30 can, for example, be implemented on computers in a screencasting or a videoconferencing system. Alternatively, transmitting station 12 can be implemented on a server and receiving station 30 can be implemented on a device separate from the server, such as a hand-held communications device (i.e. a cell phone). In this instance, transmitting station 12 can encode content using an encoder into an encoded video signal and transmit the encoded video signal to the communications device. In turn, the communications device can then decode the encoded video signal using a decoder. Alternatively, the communications device can decode content stored locally on the communications device (i.e. no transmission is necessary), Other suitable transmitting station 12 and receiving station 30 implementation schemes are available. For example, receiving station 30 can be a personal computer rather than a portable communications device.
[0079] Further, all or a portion of embodiments of the present invention can take the form of a computer program product accessible from, for example, a computer-usable or computer-readable medium. A computer-usable or computer-readable medium can be any device that can, for example, tangibly contain, store, communicate, or transport the program for use by or in connection with any processor. The medium can be, for example, an electronic, magnetic, optical, electromagnetic, or a semiconductor device. Other suitable mediums are also available.
[0080] The above-described embodiments have been described in order to allow easy understanding of the present invention and do not limit the present invention. On the contrary, the invention is intended to cover various modifications and equivalent
arrangements included within the scope of the appended claims, which scope is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structure as is permitted under the law.
Claims
1 . A method for rendering a video stream, the video stream having a plurality of frames, the method comprising:
receiving the plurality of frames via a network, each frame having an estimated arrival time;
determining a retransmission rendering delay for a current frame of the plurality of frames using a processor;
determining a render time for the current frame using a sum of the estimated arrival time and the retransmission rendering delay of the current frame; and
rendering the current frame at the render time.
2. The method of claim 1 , wherein determining the retransmission rendering delay for the current frame comprises:
determining a round-trip delay for the current frame; and
determining the retransmission rendering delay using the round-trip delay.
3. The method of claim 2, wherein determining the retransmission rendering delay for the current frame further comprises:
determining a round-trip delay constant for the current frame; and determining the retransmission rendering delay using the round-trip delay and the round-trip delay constant.
4. The method of claim 2 or claim 3, wherein determining the round-trip delay for the current frame comprises:
determining the round-trip delay for the current frame based on a round-trip time of the current frame and a round trip time of one or more previously received frames, the previously received frames received before the current frame;
determining the round-trip delay for the current frame as the larger of a round- trip delay of a previous frame and the round-trip time of the current frame; or
determining the round-trip delay for the current frame as a maximum of the round-trip times of a p re-determined number of the previously received frames if there is a sudden change in round-trip times of the previous frames and current frame or a drift change in round-trip times of the previous frames and current frame.
5. The method of claim 3, wherein determining the round-trip delay constant for the current frame comprises:
N
determining the round-trip delay constant using the formula∑f(p(loss)' ) , wherein f is a pre-determined function, p(loss) is a packet loss probability for the current frame, and N is an upper limit of the summation; or
determining the round-trip delay constant as a pre-determined integer.
6. The method of claim 5, further comprising:
determining a number of packets received and a number of packets lost over a time period; and
determining the packet loss probability for the current frame by dividing the number of packets received by the number of packets lost.
7. The method of claim 5 or claim 6, wherein the pre-determined function f is a unit-step function,
8. The method of claim 3 or claim 5, wherein determining the retransmission rendering delay comprises:
determining the retransmission rendering delay based on a product of the round-trip delay and the round-trip delay constant.
9. The method of claim 2 or claim 3, wherein determining the round-trip delay comprises:
determining at least one statistic of round-trip times of at least some of the plurality of frames; and
determining the round-trip delay as a maximum of the round-trip times of a pi e-determined number of previously received frames if a sudden round-trip time change or a drift round-trip time change is detected using the at least one statistic.
10. The method of claim 9, wherein determining the at least one statistic comprises: (a) calculating an average round-trip time of at least some of the plurality of frames; and
(b) calculating a standard deviation of the round-trip times of at least some of the plurality of frames; and wherein determining the round-trip delay includes:
detecting the sudden round-trip time change when
Ni - 1 _
∑ u( T1 (n - i)- 7 l) >72
i = 0 ; wherein
Ni is the pre- determi ed number of previously received frames;
u() is a unit step function;
% («-/)■ is the difference between the average round-trip time and the round-trip time of frame n-i;
n is the index of the current frame in the video stream;
yi is the standard deviation multiplied by a pre-determined constant; and
Y2 is a sudden-change threshold.
11. The method of claim 9, wherein determining the at least one statistic comprises:
(a) a difference between the round-trip delay and the round-trip times of at least some of the plurality of frames; and
(b) a variance of the round-trip times of at least some of the plurality of frames; and wherein determining the round-trip delay includes:
detecting a drift round-trip time change using the formula
∑ u( ? 2(n -i)- 73) >74
i = 0 , wherein
N| is the pre-determined number of previously received frames;
u() is the unit step function;
Τ ι-ή js difference between the average round-trip time and the round-trip delay of frame n-i;
n is the index of the current frame in the video stream;
γ3 is the variance multiplied by a pre-determined constant; and
y4 is a drift-change threshold.
12. The method of claim 1 or claim 2, further comprising: determining the estimated arrival time based on actual arrival times of previously received frames, the previously received frames received before the current frame,
13. An apparatus for rendering a video stream, the video stream having a plurality of frames, the apparatus comprising:
a memory; and
a processor configured to execute instructions stored in the memory to:
receive the plurality of frames via a network, each frame having an estimated arrival time;
determine a retransmission rendering delay for a current frame of the plurality of frames;
determine a render time for the current frame using the estimated arrival time and the retransmission rendering delay of the current frame; and
render the current frame at the render time.
14. The apparatus of claim 13, wherein the instructions to determine the retransmission rendering delay for the current frame include instructions to:
determine a round-trip delay for the current frame based on a round-trip time of the current frame and a round-trip time of one or more previously received frames, the previously received frames received before the current frame;
N
determine a round-trip delay constant using the formula f(p(loss)' ) , wherein f is a pre-determined function, p(loss) is a packet loss probability of the current frame, and N is an upper limit of the summation; and
determine the retransmission rendering delay using the round-trip delay and the round-trip delay constant.
15. The apparatus of claim 14, wherein the instructions to determine the round-trip delay include instructions to:
determine at least one statistic of the round-trip times of at least some of the plurality of frames; and
determine the round-trip delay as a maximum of the round-trip times of a predetermined number of previously received frames if a sudden round-trip time change or a drift round-trip time change is detected using the at least one statistic.
16. The apparatus of claim 15, wherein instructions to determine the at least one statistic include instructions to:
(a) calculate an average round-trip time of at least some of the plurality of frames; and
(b) calculate a standard deviation of the round-trip times of at least some of the plurality of frames; and wherein instructions to determine the round-trip delay includes instructions to:
detect the sudden round-trip time change when
∑ «( T1 (n - f)- 71) >72
i = 0 ; wherein
Ni is the pre-determined number of previously received frames;
u() is a unit step function;
f (n -i)- js fl^ difference between the average round-trip time and the round-trip time of frame n-i;
n is the index of the current frame in the video stream;
yi is the standard deviation multiplied by a pre-determined constant; and
y_ is a sudden-change threshold.
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2011/035470 WO2012154152A1 (en) | 2011-05-06 | 2011-05-06 | Apparatus and method for rendering video with retransmission delay |
US13/144,586 US8750293B2 (en) | 2011-05-06 | 2011-05-06 | Apparatus and method for rendering video with retransmission delay |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2011/035470 WO2012154152A1 (en) | 2011-05-06 | 2011-05-06 | Apparatus and method for rendering video with retransmission delay |
Publications (1)
Publication Number | Publication Date |
---|---|
WO2012154152A1 true WO2012154152A1 (en) | 2012-11-15 |
Family
ID=47090175
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
PCT/US2011/035470 WO2012154152A1 (en) | 2011-05-06 | 2011-05-06 | Apparatus and method for rendering video with retransmission delay |
Country Status (2)
Country | Link |
---|---|
US (1) | US8750293B2 (en) |
WO (1) | WO2012154152A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108184163A (en) * | 2017-12-29 | 2018-06-19 | 深圳华侨城卡乐技术有限公司 | A kind of video broadcasting method, storage medium and player |
CN114025233A (en) * | 2021-10-27 | 2022-02-08 | 网易（杭州）网络有限公司 | Data processing method and device, electronic equipment and storage medium |
Families Citing this family (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10616086B2 (en) | 2012-12-27 | 2020-04-07 | Navidia Corporation | Network adaptive latency reduction through frame rate control |
US9191908B2 (en) | 2013-03-05 | 2015-11-17 | Qualcomm Incorporated | Reducing impact of clock drift in wireless devices |
CN105075323B (en) * | 2013-03-29 | 2019-02-05 | Vid拓展公司 | Early stage packet loss detecting and feedback |
EP3025504B1 (en) * | 2013-07-22 | 2018-11-21 | Intel Corporation | Coordinated content distribution to multiple display receivers |
US9679345B2 (en) | 2014-08-08 | 2017-06-13 | Advanced Micro Devices, Inc. | Method and system for frame pacing |
JP6869135B2 (en) * | 2017-07-28 | 2021-05-12 | キヤノン株式会社 | Reproduction device, control method of reproduction device, and program |
US10686861B2 (en) * | 2018-10-02 | 2020-06-16 | Google Llc | Live stream connector |
CN113497932B (en) * | 2020-04-07 | 2022-10-18 | 上海交通大学 | Method, system and medium for measuring video transmission time delay |
CN112954402B (en) * | 2021-03-11 | 2023-04-28 | 北京字节跳动网络技术有限公司 | Video display method, apparatus and storage medium |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6700893B1 (en) | 1999-11-15 | 2004-03-02 | Koninklijke Philips Electronics N.V. | System and method for controlling the delay budget of a decoder buffer in a streaming data receiver |
-
2011
- 2011-05-06 WO PCT/US2011/035470 patent/WO2012154152A1/en active Application Filing
- 2011-05-06 US US13/144,586 patent/US8750293B2/en active Active
Non-Patent Citations (7)
Title |
---|
ALI C BEGEN ET AL: "An Adaptive Media-Aware Retransmission Timeout Estimation Method for Low-Delay Packet Video", IEEE TRANSACTIONS ON MULTIMEDIA, IEEE SERVICE CENTER, PISCATAWAY, NJ, US, vol. 9, no. 2, 1 February 2007 (2007-02-01), pages 332 - 347, XP011157469, ISSN: 1520-9210, DOI: 10.1109/TMM.2006.886282 * |
AL-OMARI H ET AL: "Avoiding Delay Jitter in Cyber-Physical Systems Using One Way Delay Variations Model", COMPUTATIONAL SCIENCE AND ENGINEERING, 2009. CSE '09. INTERNATIONAL CONFERENCE ON, IEEE, PISCATAWAY, NJ, USA, 29 August 2009 (2009-08-29), pages 295 - 302, XP031544588, ISBN: 978-1-4244-5334-4 * |
BEGEN A C ET AL: "Proxy-assisted interactive-video services over networks with large delays", SIGNAL PROCESSING. IMAGE COMMUNICATION, ELSEVIER SCIENCE PUBLISHERS, AMSTERDAM, NL, vol. 20, no. 8, 1 September 2005 (2005-09-01), pages 755 - 772, XP025323823, ISSN: 0923-5965, [retrieved on 20050901], DOI: 10.1016/J.IMAGE.2005.05.001 * |
HAINING LIU, MAGDA EL ZARKI: "On the adaptive delay abd synchronization control of video conferencing over the internet", INTERNATIONAL CONFERENCE ON NETWORKING (ICN), 2004 - 2004, France, XP002656949 * |
HANG LIU ET AL: "Delay and Synchronization Control Middleware to Support Real-Time Multimedia Services over Wireless PCS Networks", IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, IEEE SERVICE CENTER, PISCATAWAY, US, vol. 17, no. 9, 1 September 1999 (1999-09-01), XP011055015, ISSN: 0733-8716 * |
LIANG Y J ET AL: "Adaptive playout scheduling using time-scale modification in packet voice communications", 2001 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING. PROCEEDINGS. (ICASSP). SALT LAKE CITY, UT, MAY 7 - 11, 2001; [IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING (ICASSP)], NEW YORK, NY : IEEE, US, vol. 3, 7 May 2001 (2001-05-07), pages 1445 - 1448, XP010803129, ISBN: 978-0-7803-7041-8, DOI: 10.1109/ICASSP.2001.941202 * |
NIKOLAOS LAOUTARIS ET AL: "Intrastream Synchronization for Continuous Media Streams: A Survey of Playout Schedulers", IEEE NETWORK, IEEE SERVICE CENTER, NEW YORK, NY, US, vol. 16, no. 3, 1 May 2002 (2002-05-01), pages 30 - 40, XP011093506, ISSN: 0890-8044 * |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108184163A (en) * | 2017-12-29 | 2018-06-19 | 深圳华侨城卡乐技术有限公司 | A kind of video broadcasting method, storage medium and player |
CN114025233A (en) * | 2021-10-27 | 2022-02-08 | 网易（杭州）网络有限公司 | Data processing method and device, electronic equipment and storage medium |
CN114025233B (en) * | 2021-10-27 | 2023-07-14 | 网易（杭州）网络有限公司 | Data processing method and device, electronic equipment and storage medium |
Also Published As
Publication number | Publication date |
---|---|
US20120281562A1 (en) | 2012-11-08 |
US8750293B2 (en) | 2014-06-10 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8750293B2 (en) | Apparatus and method for rendering video with retransmission delay | |
US9106787B1 (en) | Apparatus and method for media transmission bandwidth control using bandwidth estimation | |
US10321138B2 (en) | Adaptive video processing of an interactive environment | |
US7873727B2 (en) | System and method for evaluating streaming multimedia quality | |
RU2497304C2 (en) | Dynamic modification of video properties | |
KR101458852B1 (en) | System and method for handling critical packets loss in multi-hop rtp streaming | |
US9253063B2 (en) | Bi-directional video compression for real-time video streams during transport in a packet switched network | |
CN113271316B (en) | Multimedia data transmission control method and device, storage medium and electronic equipment | |
US9723329B2 (en) | Method and system for determining a quality value of a video stream | |
EP2132908A1 (en) | Reducing effects of packet loss in video transmissions | |
US8750373B2 (en) | Delay aware rate control in the context of hierarchical P picture coding | |
WO2012154156A1 (en) | Apparatus and method for rendering video using post-decoding buffer | |
CN113473185B (en) | Method and device for detecting available bandwidth based on video stream key frame burst characteristics | |
US8270312B2 (en) | Communication system, communication method, communication device, and program | |
JP4787303B2 (en) | Video quality estimation apparatus, method, and program | |
WO2012154155A1 (en) | Apparatus and method for determining a video frame's estimated arrival time | |
WO2012154157A1 (en) | Apparatus and method for dynamically changing encoding scheme based on resource utilization | |
Khorov et al. | Distortion avoidance while streaming public safety video in smart cities | |
JP2011004354A (en) | Video quality estimating device, video quality estimation method, and control program for the video quality estimating device | |
Chattopadhyay et al. | Adaptive rate control for H. 264 based video conferencing over a low bandwidth wired and wireless channel | |
EP2911406A1 (en) | Method and device for encoding a video | |
Bassey et al. | Mitigating the effect of packet losses on real-time video streaming using psnr as video quality assessment metric | |
Chan et al. | Priority early frame discard algorithm for TCP-based video streaming | |
EP2337257A1 (en) | Method and apparatus of sending encoded multimedia digital data taking into account sending deadlines | |
JP2015065518A (en) | Image quality estimation device, image quality estimation method and program |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
WWE | Wipo information: entry into national phase |
Ref document number: 13144586Country of ref document: US |
|
121 | Ep: the epo has been informed by wipo that ep was designated in this application |
Ref document number: 11721173Country of ref document: EPKind code of ref document: A1 |
|
NENP | Non-entry into the national phase |
Ref country code: DE |
|
122 | Ep: pct application non-entry in european phase |
Ref document number: 11721173Country of ref document: EPKind code of ref document: A1 |