US8989521B1 - Determination of dance steps based on media content - Google Patents
Determination of dance steps based on media content Download PDFInfo
- Publication number
- US8989521B1 US8989521B1 US13/303,320 US201113303320A US8989521B1 US 8989521 B1 US8989521 B1 US 8989521B1 US 201113303320 A US201113303320 A US 201113303320A US 8989521 B1 US8989521 B1 US 8989521B1
- Authority
- US
- United States
- Prior art keywords
- dance
- information associated
- computing device
- steps
- sample
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/40—Scenes; Scene-specific elements in video content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/20—Movements or behaviour, e.g. gesture recognition
- G06V40/23—Recognition of whole body movements, e.g. for sport training
Definitions
- Multimedia rich environments have inspired development of media content recognition.
- Software applications can receive audio clips from a song and identify the song, for example.
- Content identification may use digital fingerprint-based technology to identify content using both audio and video image signals. Identification may be based on perceptual characteristics of the audio and video. Accuracy and speed of content identification have been improving with advances in computing power and recognition technologies.
- Content identification can be useful in many fields. Content identification can help protect copyrights, for example.
- a user may attempt to upload a copyrighted audio or video content to a public website and when content of the copyrighted audio or video is identified the copyrighted audio or video may be prevented from being uploaded to the public website, for example.
- a user may be listening to a song or watching a video and may use content identification techniques to identify the song or the video and may obtain information about the song and the video that may have been unknown to the user.
- the present application discloses systems and methods to determine dance steps based on music and/or other dancers.
- a method is described. The method may comprise receiving, from a microphone coupled to a computing device, an audio sample rendered by a media rendering source and receiving, by a camera coupled to the computing device, a video sample of one or more dancers performing a dance gesture associated with a dance.
- the method may also comprise providing the audio sample and the video sample to a content identification module for determination of: (i) information associated with the audio sample and (ii) information associated with the dance based on recognition of the dance gesture in a content of the video sample.
- the method may further comprise receiving, from the content identification module, the information associated with the audio sample and the information associated with the dance.
- the method may also comprise determining one or more predetermined dance steps corresponding to the information associated with the audio sample and the information associated with the dance.
- the method may further comprise generating a display of the one or more predetermined dance steps.
- a computer readable memory having stored thereon instructions executable by a computing device to cause the computing device to perform functions.
- the functions may comprise receiving, by a microphone coupled to the computing device, an audio sample rendered by a media rendering source and receiving, by a camera coupled to the computing device, a video sample of one or more dancers performing a dance gesture associated with a dance.
- the functions may also comprise providing the audio sample and the video sample to a content identification module for determination of: (i) information associated with the audio sample and (ii) information associated with the dance based on recognition of the dance gesture in a content of the video sample.
- the functions may further comprise receiving, from the content identification module, the information associated with the audio sample and the information associated with the dance.
- the functions may also comprise receiving one or more predetermined dance steps corresponding to the information associated with the audio sample and the information associated with the dance.
- the functions may further comprise generating a display of the one or more predetermined dance steps.
- a system may comprise a wearable computer including a head-mounted display (HMD).
- the system may also comprise a camera coupled to the wearable computer and a microphone coupled to the wearable computer.
- the system may further comprise a processor in communication with the wearable computer, the camera, and the microphone.
- the processor may be configured to receive, from the microphone, an audio sample rendered by a media rendering source and receive, from the camera, a video sample of one or more dancers performing a dance gesture associated with a dance.
- the processor may also be configured to provide one or more of the audio sample and the video sample to a content identification module for determination of information associated with one or more of: (i) the audio sample and (ii) the dance based on recognition of the dance gesture in a content of the video sample.
- the processor may further be configured to receive, from the content identification module, the information associated with one or more of the audio sample and the dance.
- the processor may also be configured to determine one or more predetermined dance steps corresponding to the information associated with one or more of the audio sample and the dance.
- the processor may further be configured to generate a display of the one or more predetermined dance steps on the HMD.
- FIG. 1 is an example system for determining dance steps associated with a media sample, in accordance with an example embodiment.
- FIG. 2A illustrates a front view of an example wearable computing system including a head-mounted display (HMD) in an example eyeglasses embodiment.
- HMD head-mounted display
- FIG. 2B illustrates a side view of the HMD in the example eyeglasses embodiment.
- FIG. 3 is an example system, including the HMD, for determining dance steps associated with a media sample, in accordance with an example embodiment.
- FIG. 4 is a flow chart of an example method to determine dance steps based on a media sample.
- FIG. 5 is a flow chart of an example method to provide feedback to a user performing the dance steps.
- FIG. 6 is a functional block diagram illustrating an example computing device used in a computing system that is arranged in accordance with at least some embodiments described herein.
- FIG. 7 is a schematic illustrating a conceptual partial view of an example computer program product that includes a computer program for executing a computer process on a computing device, arranged according to at least some embodiments presented herein.
- a wearable computing system may include a head mounted display (HMD).
- the wearable computing system may receive a media sample including an audio sample associated with a song and/or a video sample associated with one or more dancers performing a dance.
- the wearable computing system may communicate the media sample to a content analysis server that may include a content identification module.
- the content identification module may provide information associated with a content of the media sample, such as identification of the song and the dance, to the wearable computing system.
- the wearable computing system may determine dance steps corresponding to the content of the media sample and may generate a display of the dance steps on the HMD.
- a mobile phone may be used.
- the device e.g., the mobile phone or the wearable computing system
- the device may include a microphone and/or a camera.
- a user of the device may be in an ambient environment where a song may be playing and one or more dancers may be performing dance gestures associated with a dance.
- the device may receive through the microphone an audio sample including the song.
- the device may also receive through the camera a video sample including the one or more dancers performing the dance gestures associated with the dance.
- the device may provide a media sample including the audio sample and/or the video sample to a content identification module.
- the content identification module may be coupled to the device or coupled to a server.
- the content identification module may identify a content of the media sample. For example, the content identification module may identify one or more of the song, a genre of the song, and may identify one or more of the dance and a genre of the dance. The content identification module may also identify more information associated with the content of the audio and video samples including a rhythm, a melody, and a tempo. The content identification module may communicate information associated with the content of the audio and video samples to the device. Based on the information associated with the content of the audio and video samples, the device may determine dance steps appropriate to the song and the dance.
- the device may also receive information associated with the user of the device including an age and a gender of the user.
- the device may also receive or determine information associated with the ambient environment including a geographic location and a time.
- the device may further receive or determine information associated with a demographic of the one or more dancers including a number of dancers, an average age, and a gender.
- the device may then determine the dance steps based on the information associated with the user, the ambient environment, the demographic, and the content of the audio and/or video samples.
- the device may generate a display of the dance steps. For example, the device may compile a video from multiple video segments and each segment may include a dancer performing at least one of the dance steps or may include an animation of a figure performing the dance steps.
- the device may further receive information associated with a performance of the dance steps by the user.
- the device may include a wearable computing system with wearable sensors coupled to the wearable computing system.
- the wearable sensors may, for example, be distributed on a body of the user.
- the wearable sensors may include accelerometers, gyroscopes, magnetic rings, and magnetic anklets, for example.
- the wearable sensors may thus provide to the wearable computing system information associated with a motion of the user while performing the dance steps.
- the device may compare the performance of the dance steps by the user to the dance steps determined by the device.
- the device may further provide to the user an indication of a degree to which the performance of the dance steps by the user matches the dance steps and may provide instructions to the user to improve the performance of the dance steps.
- the instructions may include visual instructions or auditory instructions.
- the wearable computing system may generate a display of an animation of a first pattern of dance steps associated with the dance steps determined by the device and an animation of a second pattern of dance steps associated with the performance of the dance steps by the user. The user may then be able to compare the dance steps determined by the device and the dance steps performed by the user and may attempt to match the dance steps determined by the device.
- the instructions may include voice instructions to the user on how to change the performance of the dance steps.
- FIG. 1 is an example system for determining dance steps associated with a media sample, in accordance with an example embodiment.
- the system includes a media source 102 that may provide or render a media sample to a device 104 , which may be in communication with a content analysis server 106 .
- the content analysis server 106 may also be in direct communication with the media source 102 .
- the media source 102 is shown to communicate the media sample to the device 104 wirelessly as an example. However, depending on a form of the media sample, the media source 102 may provide the media sample using wireless or wired communication techniques.
- a camera feed 108 may also be input to the device 104 .
- a camera providing the camera feed 108 may be external to the device 104 and may record a video of a user of the device 104 .
- External sensors 110 may additionally provide information to the device 104 .
- the device 104 may include a wearable computing system
- the external sensors 110 may include wearable sensors coupled to the wearable computing system and/or a user of the wearable computing system.
- the wearable sensors may provide information associated with a motion of the user, for example.
- Components of the system illustrated in FIG. 1 may be configured to work in an interconnected fashion with each other and/or with other components coupled to respective systems.
- the device 104 and the content analysis server 106 may be coupled to one computing device.
- the media sample may be stored on the media source 102 or received from external sources, such as an analog or digital broadcast.
- the media source 102 may be a media rendering source such as a radio station or a television content provider that broadcasts media streams (e.g., audio and/or video) and/or other information.
- the media source 102 may also include any type of device that may play audio media and/or may display video media in a recorded or live format.
- the media source 102 may include a live performance as a source of audio and/or a source of video.
- the audio sample may include a song, and the video sample may include one or more dancers performing a dance gesture associated with a dance.
- the device 104 may include or may be coupled to sensors 112 .
- the sensors 112 may, for example, include a microphone and a camera.
- the device 104 may be configured to receive portions of the media sample from the media source 102 as an audio sample through the microphone and a video sample through the camera, for example.
- the device 104 may include a preprocessor 114 .
- the preprocessor 114 may be configured to preprocess a media sample including the audio and video samples.
- the preprocessor 114 may be configured to down-sample the media sample to reduce a size of the media sample before communicating the media sample to other modules coupled to the device 104 or to the content analysis server 106 .
- the preprocessor 114 may also be configured to filter noise and distortion from the media sample, for example.
- the pre-processor 114 may be configured to communicate a preprocessed media sample to a query generator 116 .
- the query generator 116 may be configured to combine the preprocessed media along with other information received from other components coupled to the device 104 to generate a content identification query and communicate the content identification query to the content analysis server 106 .
- the device 104 may be configured to receive an indication of time from a clock 118 and may be configured to receive information associated with a location of the device 104 , and thus a location of a user of the device 104 , from a Global Positioning System (GPS) module 120 .
- GPS Global Positioning System
- the device 104 may be configured to receive or determine information associated with the user of the device.
- the user may input information to the device 104 , and the information may be stored in a user information module 122 .
- the user information module 122 may be configured to determine the information associated with the user of the device 104 using the sensors 112 and/or the external sensors 110 to determine the information associated with the user including one or more of an age and a gender of the user.
- the user information module 122 may be configured to receive information associated with a camera facing the user and coupled to the device 104 and may be configured to determine the gender of the user through image recognition techniques.
- the user of the device 104 may be in an environment including a live performance as a source of audio and/or a source of video, for example.
- the video sample may include dancers performing a dance.
- a demographics identification module 124 may be configured to receive information associated with or determine through the sensors 112 and/or the external sensors 110 demographics of the dancers including one or more of a number, a gender, and an average age of the dancers.
- the query generator 116 may be configured to receive a preprocessed media sample from the preprocessor 114 , and may be configured to receive information associated with the indication of time from the clock 118 , the information associated with the location of the device 104 from the GPS module 120 , the information associated with the user from the user information module 122 , and the information associated with demographics of the dancers from the demographics identification module 124 .
- the query generator 116 may be configured to generate a content identification query and may be configured to communicate the content identification query to the content analysis server 106 .
- the content analysis server 106 may be configured to identify the song and dance and other information associated with a content of the content identification query and may determine dance steps associated with the content of the query.
- the content identification query may include the preprocessed media sample but may not include information associated with the indication of time, the information associated with the location of the device 104 , the information associated with the user, and the information associated with demographics of the dancers.
- the query generator 116 may be configured to communicate the content identification query to the content analysis server 106 .
- the content analysis server 106 may be configured to identify the content of the preprocessed media sample including the song and the dance and communicate information associated with the content of the media sample to the device 104 .
- the device 104 may be configured to determine predetermined dance steps stored in a dance data module 125 corresponding to any of the information associated with the content of the media sample received from the content analysis server 106 , the information associated with the indication of time received from the clock 118 , the information associated with the location of the device 104 received from the GPS module 120 , the information associated with the user received from the user information module 122 , and the information associated with demographics of the dancers received from the demographics identification module 124 .
- the dance data module 125 may include a mapping of the predetermined dance steps to characteristics of content of media including one or more of a genre, a rhythm, a melody, and a tempo, for example.
- the dance data module 125 may also map the predetermined dance steps to one or more of the information associated with the user, the information associated with the indication of time, the information associated with the location of the device 104 , and the information associated with demographics of dancers.
- the dance data module 125 is shown to be coupled to the device 104 as an example. In other examples, the dance data module may be coupled to the content analysis server 106 , or may be a separate module in communication with either of the device 104 or the server 106 .
- the device 104 may also be configured to generate a display of the dance steps on a display 126 coupled to the device 104 .
- the predetermined dance steps may be stored in several forms such as a video of each step performed by a dancer or an animation of a figure performing the predetermined dance steps.
- the user of the device 104 may view the dance steps determined by the device 104 or the content analysis server 106 .
- the external sensors 110 , the sensors 112 , or the camera feed 108 may be configured to provide information associated with a performance of the dance steps by the user. For example, a camera may record a video of the user performing the dance steps and provide the device 104 with the camera feed 108 .
- the device 104 may include a wearable computing system and the external sensors 110 may include wearable sensors coupled to the wearable computing system and/or the user of the wearable computing system. The wearable sensors may also provide information associated with a motion of the user, for example.
- a performance feedback module 128 coupled to the device 104 may be configured to compare the performance of the dance steps by the user to the dance steps determined by the device 104 or the content analysis server 106 .
- the performance feedback module 128 may be configured to provide the user with feedback on the performance of the dance steps.
- the performance feedback module 128 may, for example, be configured to provide an indication of a degree to which the performance of the dance steps may match the dance steps identified by the device 104 .
- the indication may, for example, include a score indicative of the degree to which the performance of the dance steps may match the dance steps.
- the performance feedback module 128 may further be configured to provide instructions or corrective dance steps to the user to change or improve the performance of the dance steps by the user.
- Feedback and instructions may include visual instructions.
- Feedback may also be auditory.
- the user may listen to instructions for performance improvements, for example.
- Feedback may include general information such as a percentage of dance steps performed correctly or may include specific feedback including specific steps such as “raise right leg higher and quicker”.
- the device 104 may be in communication with the content server 106 either directly or via a network.
- the content analysis server 106 may include a request module 130 , a content identification module 132 in communication with the request module 130 , and a media search engine 134 in communication with the content identification module 132 .
- the request module 130 may be configured to receive from the device 104 a content identification query generated by the query generator 116 , and may be configured to send identification information associated with the content identification query to the device 104 .
- the query may include a preprocessed media sample and may include other information associated with the user of the device, the indication of time, the location of the device 104 , and the demographics of the dancers.
- the content analysis server 106 may be configured to receive at the request module 130 a media sample from the device 104 or the media source 102 (either over a wired or wireless connection).
- the content identification module 132 may be configured to identify a content of the received media sample.
- the content identification module 132 may be configured to identify a musical content of an audio sample included in the media sample, and provide the device 104 with information about the music content, including a track name, artist, album, genre, etc., for example.
- the content identification module 132 may also be configured to identify a dance content of a video sample included in the media sample, and provide the device 104 with information associated with the dance content, including a dance name and a dance genre, for example.
- the content identification module 132 may be in communication with a media search engine 134 .
- the media search engine 134 may include or have access to a database 136 that may index reference media, for example, to compare the received media sample with stored information so as to identify the content of the media sample. Once the content of the music and/or dance included in the media sample may have been identified, content identities or other information may be sent back to the device 104 .
- the device 104 may be configured to capture the media sample from the media source 102 , and perform initial processing on the media sample in the preprocessor 114 so as to determine a fingerprint, i.e. a characteristic, of the media sample.
- the device 104 may then send the fingerprint information to the content identification module 132 coupled to the content analysis server 106 , which may identify information associated with the media sample based on the fingerprint. In this manner, more computation or identification processing can be performed at the device 104 , rather than at the content identification module 132 , for example.
- the database 136 may include many media recordings and each recording may be identified by a unique identifier (e.g., a fingerprint).
- the database 136 may not necessarily store audio or video files for each recording, since the fingerprint can be used to retrieve audio and/or video files from elsewhere. However, the database 136 may store the audio or video files in some examples.
- a database index may be large, containing indices for possibly billions of files, for example. New recordings can be added incrementally to the database index.
- the database 136 may also include information associated with each stored audio, video, or media file, or for each stored media index. For example, information associated with each file that indicates information about the file, such as an artist name, a length of a song, genre of the song, dance type, or any other identifying or related information to the file may be stored with each file.
- the content analysis server 106 or the device 104 may be configured to determine dance steps corresponding to the content of the media sample. Identified content of the media sample and the dance steps determined for the content of the media may be stored on the device 104 for later use if similar media content is received and for future reference of the user of the device 104 .
- Identifying features of a media recording may begin by receiving the media sample and sampling the media recording at a plurality of sampling points to produce a plurality of signal values.
- a statistical moment of the signal can be calculated using any known formula. The calculated statistical moment may then be compared to a plurality of stored signal identifications and the media sample may be recognized as similar to one of the stored signal identifications.
- the calculated statistical moment can be used to determine a feature vector that may be quantized, and a weighted sum of the quantized feature vector may be used to access a memory or database that stores the signal identifications.
- media content can be identified by identifying or computing characteristics or fingerprints of a media sample and comparing the fingerprints to previously identified fingerprints. Particular locations within the media sample at which fingerprints may be computed depend on reproducible points in the media sample. Such reproducibly computable locations are referred to as “landmarks.”
- a location within the media sample of the landmarks can be determined by the media sample itself, i.e., is dependent upon sample qualities and is reproducible. That is, same or similar landmarks may be computed for a given signal each time identification is repeated.
- a landmarking process may mark about 5 to about 10 landmarks per second of sound recording or video recording; however, landmarking density depends on an amount of activity within a media recording.
- One landmarking technique known as Power Norm, includes calculating an instantaneous power at many time points in the media sample and selecting local maxima. Other methods for calculating landmarks may also be used.
- a fingerprint may be computed at or near each landmark time point in the media sample.
- a nearness of a feature to a landmark may be defined by the fingerprinting method used.
- a feature may be considered near a landmark if the feature corresponds to the landmark and not to a previous or subsequent landmark.
- features correspond to multiple adjacent landmarks.
- the fingerprint may generally include a value or set of values that may summarize a set of features in the media sample at or near the time point.
- each fingerprint may include a single numerical value that may be a hashed function of multiple features.
- Other examples of fingerprints include spectral slice fingerprints, multi-slice fingerprints, cepstral coefficients, and frequency components of spectrogram peaks.
- identifying a dance in a video sample may include comparing scenes of dancers performing the dance to fragments of dance videos recorded and stored in a database.
- a large size database may store videos of all dances and dance patterns.
- dance identification may include determining a fingerprint of the video sample including the dancers performing the dance and comparing the fingerprint to a database of fingerprints associated with relevant fragments of videos including dances and dance patterns.
- Identification of a dance included in a video sample may include determining fingerprints based on semantical features and/or non-semantical included in the video sample. Fingerprints based on semantical features may be determined from high level features such as scene boundaries and color-histograms, for example. Fingerprints based on non-semantical features may be determined from general perceptual invariants that may not necessarily have a semantical interpretation, such as luminance.
- the content identification module 132 may be configured to receive the media sample and may be configured to compute fingerprints of the media sample.
- the content identification module 132 may be configured to compute the fingerprints by communicating with additional recognition engines coupled to or separate from the content analysis server 106 .
- the content identification module 132 may be configured to communicate with the media search engine 134 , which may be configured to access the database 136 to match the fingerprints of the media sample with fingerprints of known audio and video tracks.
- the media search engine 134 may be configured to generate correspondences between equivalent fingerprints and files in the database 136 to locate a file that has the largest number of linearly related correspondences, or whose relative locations of characteristic fingerprints most closely match relative locations of the fingerprints associated with the media sample.
- the content identification module 132 may be coupled to the device 104 or may be coupled to a server such as the content analysis server 106 connected to the device 104 over a network, as shown in FIG. 1 .
- the camera feed 108 may be received by the device 104 from a camera recording a video of the user of the device 104 .
- the camera may provide a video of the user of the device 104 performing the dance steps determined by the device 104 .
- the performance feedback module 128 may compare a performance of the dance steps by the user in the video to the dance steps determined by the device 104 and provide feedback to the user to improve the performance of the dance steps.
- the external sensors 110 may include wearable sensors for detecting movement of the user while the user may be performing the dance steps.
- the wearable sensors may include, for example, magnetic rings, belts, or anklets. Magnetic field from such sensors may be detected by the device 104 to determine information associated with a motion of the user.
- the external sensors 110 may include accelerometers and gyroscopes coupled to the device 104 or the user.
- the device 104 may be configured to receive information associated with the external sensors 110 and may be configured to accordingly evaluate the performance of the dance steps by the user.
- Devices of different types may function as the device 104 .
- a mobile phone with a microphone and a camera may function as the device 104 .
- a wearable computing system may also function as the device 104 .
- the wearable computing system may be configured as, for example, eyeglasses, goggles, a helmet, a hat, a visor, a headband, or in some other form that can be supported on or from a head of a wearer or a user.
- FIG. 2A illustrates a front view of an example wearable computing system including a head-mounted display (HMD) 200 in an example eyeglasses embodiment.
- FIG. 2B presents a side view of the HMD 200 in FIG. 2A .
- FIGS. 2A and 2B will be described together.
- the HMD 200 may include lens frames 202 and 204 , a center frame support 206 , lens elements 208 and 210 , and extending side-arm 212 that may be affixed to lens frame 202 .
- the center frame support 206 and side-arm 212 may be configured to secure the HMD 200 to a head of a wearer via a nose and an ear of the wearer.
- Each of the frame elements 202 , 204 , and 206 and the extending side-arm 212 may be formed of a solid structure of plastic or metal, or may be formed of a hollow structure of similar material so as to allow wiring and component interconnects to be internally routed through the HMD 200 .
- Lens elements 208 and 210 may be at least partially transparent so as to allow the wearer to look through lens elements. In particular, a right eye 214 of the wearer may look through right lens 210 .
- Optical systems 216 and 218 may be positioned in front of lenses 208 and 210 , respectively.
- the optical systems 216 and 218 may be attached to the HMD 200 using support mounts such as 220 shown for the right optical system 216 .
- the optical systems 216 and 218 may be integrated partially or completely into lens elements 208 and 210 , respectively.
- FIG. 2A illustrates an optical system for each eye
- the HMD 200 may include an optical system for only one eye (e.g., right eye 214 ).
- the wearer of the HMD 200 may simultaneously observe from optical systems 216 and 218 a real-world image with an overlaid displayed image.
- the HMD 200 may include various elements such as a processor 222 , a touchpad 224 , a microphone 226 , and a button 228 .
- the processor 222 may use data from, among other sources, various sensors and cameras to determine a displayed image that may be displayed to the wearer.
- the HMD 200 may also include a front-facing camera 230 that may be integrated into the optical systems 216 . Location of the front-facing camera 230 is for illustration only.
- the front-facing camera 230 may be positioned in different locations and may be separate or attached to the HMD 200 . More than one front-facing camera may be used in some examples. Those skilled in the art would understand that other user input devices, user output devices, wireless communication devices, sensors, and cameras may be reasonably included in such a wearable computing system.
- the HMD 200 may enable a user to observe surroundings of the user and also view a displayed image on a display of the optical systems 216 and 218 .
- the user of the HMD 200 may be in an environment including a live performance as a source of audio and/or a source of video, for example.
- the life performance may include one or more persons dancing while a song may be playing.
- the user of the HMD 200 may not be an experienced dancer or may not know dance steps associated with the song being played or a dance being performed by the dancers.
- FIG. 3 is an example system, including the HMD 200 , for determining dance steps associated with a media sample, in accordance with an example embodiment.
- a user may be wearing the HMD 200 .
- the HMD 200 may be configured to use the microphone 226 to capture an audio sample of a song performed by a singer 302 , and may be configured to use the front-facing camera 230 to capture a video sample of dancers 304 A-B performing a dance.
- the song may be played on any media player.
- the dance may be performed on a television or other media players, for example.
- the processor 222 coupled to the HMD 200 may be configured to receive the audio and video and may be configured to preprocess the audio and video to down-sample and filter noise from the audio and video samples, for example.
- the processor 222 may be configured to send a media sample (including the audio and video samples) through a network to the content analysis server 106 , which may have access to the database 136 as described in FIG. 1 .
- the content analysis server 106 may be configured to identify a content of the media sample and determine information associated with the media sample. For example, the content analysis server 106 may be configured to determine or identify one or more of the song, a genre of the song, the dance, and a genre of the dance. The content analysis server 106 may be configured to communicate identified information associated with the media sample to the HMD 200 through the network. The HMD 200 may be configured to determine dance steps corresponding to the identified information associated with the media sample. The HMD 200 may be configured to generate a display of the dance steps on a display coupled to the optical system 216 . The user may accordingly be able to view the dance steps and may attempt to perform the dance steps.
- the content analysis server 106 may determine the dance steps and send the dance steps to the HMD 200 .
- the HMD 200 may include a content analysis module to identify the content of the media sampled without communication with the content analysis server 106 .
- the HMD 200 may be configured to store identification information for future use.
- the content analysis server 106 may be unable to determine the song and the dance but may be able to identify other relevant information, such as the genre of the song and the genre of the dance. Identifying the genre of the song and the genre of the dance may be sufficient for the HMD 200 to determine the dance steps.
- only the audio sample including the song or only the video sample including the dancers 304 A-B may be available.
- the content analysis server 106 may be configured to identify information associated with one of the song or the dance.
- the HMD 200 may be configured to determine the dance steps associated with only the information associated with the song or only the information associated with the dance.
- the user may input information associated with the song and information associated with the dance steps using the touchpad 224 coupled to the HMD 200 .
- the HMD 200 may be configured to determine the dance steps associated with the input information.
- More than one user may each be wearing an HMD.
- a first user wearing a first HMD may have received dance steps associated with a given media sample and may start performing the dance steps.
- a second user wearing a second HMD may be watching the first user.
- the second HMD may include a front-facing camera facing the first user while the first user may be performing the dance steps.
- the first and second HMDs may be in communication with each other and the second HMD may be configured to send a camera feed of the first user performing the dance steps from the front-facing camera coupled to the second HMD.
- the first HMD may be configured to use the camera feed to evaluate a performance of the dance steps by the first user and may be configured to provide feedback and corrective instructions to the first user.
- FIG. 4 is a flow chart of an example method to determine dance steps based on a media sample, in accordance with at least some embodiments of the present disclosure.
- Method 400 may include one or more operations, functions, or actions as illustrated by one or more of blocks 402 , 404 , 406 , and 408 . Although the blocks are illustrated in a sequential order, these blocks may in some instances be performed in parallel, and/or in a different order than those described herein. Also, the various blocks may be combined into fewer blocks, divided into additional blocks, and/or removed based upon the desired implementation
- each block may represent a module, a segment, or a portion of program code, which includes one or more instructions executable by a processor for implementing specific logical functions or steps in the process.
- the program code may be stored on any type of computer readable medium or memory, for example, such as a storage device including a disk or hard drive.
- the computer readable medium may include a non-transitory computer readable medium, for example, such as computer-readable media that stores data for short periods of time like register memory, processor cache and Random Access Memory (RAM).
- the computer readable medium may also include non-transitory media or memory, such as secondary or persistent long term storage, like read only memory (ROM), optical or magnetic disks, compact-disc read only memory (CD-ROM), for example.
- the computer readable media may also be any other volatile or non-volatile storage systems.
- the computer readable medium may be considered a computer readable storage medium, a tangible storage device, or other article of manufacture, for example.
- each block in FIG. 4 may represent circuitry that is wired to perform the specific logical functions in the process.
- a user of a device may be in an ambient environment including a source of audio and/or a source of video, for example.
- the environment may include a live performance including dancers performing a dance while a song may be playing. There may be other sources of audio and video such as any media player.
- the user of the device may not be an experienced dancer or may not know dance steps associated with the song being played or the dance being performed by the dancers.
- the method 400 includes receive a media sample and information associated with the media sample.
- a device may include a microphone and a camera or other means to capture or receive an audio sample and a video sample from the ambient environment, respectively.
- the audio sample may include the song and the video sample may include images of the dancers performing one or more dance gestures associated with the dance.
- the device may be configured to receive the audio sample, the video sample, or both.
- the media sample may comprise both the audio and video samples, or may comprise only one of the audio and video samples.
- the device may also be configured to determine through sensors or receive from the user or from a server information associated with the media sample such as: information associated with a demographic of the dancers (e.g., a gender and an average age of the dancers), information associated with an indication of time, and information associated with a location of the device, and thus a location of the user of the device from a GPS module, and information associated with the user of the device (e.g., age and gender), for example.
- a demographic of the dancers e.g., a gender and an average age of the dancers
- information associated with an indication of time e.g., a location of the device
- information associated with the user of the device e.g., age and gender
- the method 400 includes provide the media sample to a content identification module.
- the device may be configured to provide the media sample to a content identification module for identification of content of the media sample.
- the device may also be configured to provide to the content identification module the information associated with the media sample.
- the device may include the content identification module.
- the content identification module may be coupled to a server in wired or wireless communication with the device.
- the content identification module may be configured to apply audio and/or video recognition techniques to identify the content of the media sample.
- the device or the content identification module may be configured to determine fingerprints associated with the content of the media sample.
- the content identification module may be configured to compare the fingerprints to fingerprints stored on a database.
- the database may be configured to store fingerprints associated with billions of songs and dances.
- the content identification module may be configured to match the fingerprints to fingerprints stored on the database and may be configured to accordingly identify the content of the media sample.
- the content identification module may be configured to identify the song and/or a genre of the song.
- the content identification module may also be configured to identify the dance and/or a genre of the dance.
- the method 400 includes receive information associated with a content of the media sample.
- the device may be configured to receive the information associated with the content of the media sample identified by the content identification module.
- the device may receive the information through network communication with the content identification module, for example.
- the user may input the information associated with the media sample to the device.
- a touchpad or a keyboard may be coupled to the device, and the user may input a name of the song or the genre of the song and a name of the dance or the genre of the dance to the device through the touchpad or the keyboard.
- the device may be configured to determine the location (e.g., a dance club) of the device and access, through a network (e.g., the internet), information associated with songs played and dances performed at the location. Still further, the device may be configured to perform computations to determine information associated with a content of the media sample.
- a network e.g., the internet
- the method 400 includes determine dance steps associated with the content of the media sample and/or the information associated with the media sample. Based on the information associated with the content of the media sample, the device may be configured to determine dance steps corresponding to or appropriate to the media sample. In one example, the device may be configured to determine the dance steps based on the information associated with the media sample (e.g., user information, dancers demographics, geographic location, and time) in addition to the information associated with the content of the media sample (e.g., identified song and/or dance).
- the information associated with the media sample e.g., user information, dancers demographics, geographic location, and time
- the user may attempt to perform the dance steps determined by the device along with the dancers performing the dance.
- the user may not be able to perform the dance steps perfectly.
- the user may receive feedback from the device associated with an indication of a degree to which a performance of the dance steps by the user may match the dance step and possibly how to improve the performance of the dance steps by the user.
- FIG. 5 is a flow chart of an example method 500 to provide feedback to a user performing the dance steps.
- a device may have provided dance steps associated with a content of a media sample to the user as described in method 400 depicted in FIG. 4 .
- the method 500 includes receive information associated with a performance of dance steps.
- the device may be configured to receive information associated with the performance of the dance steps by the user.
- the device may include a mobile phone with gyroscopes and accelerometers coupled to the mobile phone.
- the device may be configured to receive information associated with or output from the gyroscopes and accelerometers and may be configured to track and evaluate the performance of the dance steps by the user.
- wearable sensors may be worn by the user for detecting movement of the user while the user may be performing the dance steps.
- the wearable sensors may include, for example, magnetic rings, belts, or anklets. Magnetic field from such sensors may be detected by the device to determine information associated with the motion of the user.
- the method 500 includes compare the performance of the dance steps to the dance steps (e.g., predetermined dance steps). For example, from the information associated with the performance of the dance steps, a processor coupled to the device may be configured to compare the performance of the dance steps to the dance steps provided to the user. The processor may, for instance, determine that the user may be performing a certain percentage of the dance steps correctly.
- the dance steps e.g., predetermined dance steps.
- the method 500 includes provide an indication of a degree to which the performance of the dance steps matches the dance steps.
- the device may provide performance feedback to the user. For example, the device may provide the user with a score indicative of the degree to which the performance of the dance steps by the user may match the dance steps. The score may be based on a percentage of correct dance steps performed, for instance.
- the device or the processor coupled to the device may be configured to generate a display of a first dancing pattern or figure that may represent the performance of the dance steps by the user.
- the processor may also generate a display of a second dancing pattern or figure that may represent the dance steps provided to the user.
- the first and second dancing patterns may, for example, be animated figures that overlay each other on the display or may be displayed next to each other.
- the dancing patterns may provide the user with visual means of comparing the performance of the dance steps by the user to the dances steps provided to the user and how the dance steps may correctly be performed.
- the device may further be configured to display visual instructions or provide auditory instructions to the user including steps to improve the performance of the dance steps by the user and increase the degree to which the performance of the dance steps may match the dance steps.
- FIG. 6 is a functional block diagram illustrating an example computing device 600 used in a computing system that is arranged in accordance with at least some embodiments described herein.
- the computing device may be a personal computer, mobile device, cellular phone, video game system, or global positioning system, and may be implemented as a client device, a server, a system, a combination thereof, or as a portion of components described in FIGS. 1 , 2 , and 4 .
- computing device 600 may include one or more processors 610 and system memory 620 .
- a memory bus 630 can be used for communicating between the processor 610 and the system memory 620 .
- processor 610 can be of any type including but not limited to a microprocessor ( ⁇ P), a microcontroller ( ⁇ C), a digital signal processor (DSP), or any combination thereof.
- ⁇ P microprocessor
- ⁇ C microcontroller
- DSP digital signal processor
- a memory controller 615 can also be used with the processor 610 , or in some implementations, the memory controller 615 can be an internal part of the processor 610 .
- system memory 620 can be of any type including but not limited to volatile memory (such as RAM), non-volatile memory (such as ROM, flash memory, etc.) or any combination thereof.
- System memory 620 may include one or more applications 622 , and program data 624 .
- Application 622 may include dance steps algorithm 623 that is arranged to provide inputs to the electronic circuits, in accordance with the present disclosure.
- Program Data 624 may include content information 625 that could be directed to any number of types of data.
- application 622 can be arranged to operate with program data 624 on an operating system.
- Computing device 600 can have additional features or functionality, and additional interfaces to facilitate communications between the basic configuration 602 and any devices and interfaces.
- data storage devices 640 can be provided including removable storage devices 642 , non-removable storage devices 644 , or a combination thereof.
- removable storage and non-removable storage devices include magnetic disk devices such as flexible disk drives and hard-disk drives (HDD), optical disk drives such as compact disk (CD) drives or digital versatile disk (DVD) drives, solid state drives (SSD), and tape drives to name a few.
- Computer storage media can include volatile and nonvolatile, non-transitory, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data.
- System memory 620 and storage devices 640 are examples of computer storage media.
- Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 600 . Any such computer storage media can be part of device 600 .
- Computing device 600 can also include output interfaces 650 that may include a graphics processing unit 652 , which can be configured to communicate to various external devices such as display devices 660 or speakers via one or more A/V ports 654 or a communication interface 670 .
- the communication interface 670 may include a network controller 672 , which can be arranged to facilitate communications with one or more other computing devices 680 and one or more sensors 682 over a network communication via one or more communication ports 674 .
- the one or more sensors 682 are shown external to the computing device 600 , but may also be internal to the device.
- the communication connection is one example of a communication media.
- Communication media may be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media.
- a modulated data signal can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.
- communication media can include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared (IR) and other wireless media.
- Computing device 600 can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
- a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
- PDA personal data assistant
- Computing device 600 can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.
- FIG. 7 is a schematic illustrating a conceptual partial view of an example computer program product 700 that includes a computer program for executing a computer process on a computing device, arranged according to at least some embodiments presented herein.
- the example computer program product 700 is provided using a signal bearing medium 701 .
- the signal bearing medium 701 may include one or more program instructions 702 that, when executed by one or more processors may provide functionality or portions of the functionality described above with respect to FIGS. 1-6 .
- one or more features of blocks 402 - 408 and/or blocks 502 - 506 may be undertaken by one or more instructions associated with the signal bearing medium 701 .
- the program instructions 702 in FIG. 7 describe example instructions as well.
- the signal bearing medium 701 may encompass a computer-readable medium 703 , such as, but not limited to, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, memory, etc.
- the signal bearing medium 701 may encompass a computer recordable medium 704 , such as, but not limited to, memory, read/write (R/W) CDs, R/W DVDs, etc.
- the signal bearing medium 701 may encompass a communications medium 705 , such as, but not limited to, a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).
- the signal bearing medium 701 may be conveyed by a wireless form of the communications medium 705 (e.g., a wireless communications medium conforming to the IEEE 802.11 standard or other transmission protocol).
- the one or more programming instructions 702 may be, for example, computer executable and/or logic implemented instructions.
- a computing device such as the computing device 600 of FIG. 6 may be configured to provide various operations, functions, or actions in response to the programming instructions 702 conveyed to the computing device 600 by one or more of the computer readable medium 703 , the computer recordable medium 704 , and/or the communications medium 705 .
- arrangements described herein are for purposes of example only. As such, those skilled in the art will appreciate that other arrangements and other elements (e.g. machines, interfaces, functions, orders, and groupings of functions, etc.) can be used instead, and some elements may be omitted altogether according to the desired results. Further, many of the elements that are described are functional entities that may be implemented as discrete or distributed components or in conjunction with other components, in any suitable combination and location.
Abstract
Description
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/303,320 US8989521B1 (en) | 2011-11-23 | 2011-11-23 | Determination of dance steps based on media content |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/303,320 US8989521B1 (en) | 2011-11-23 | 2011-11-23 | Determination of dance steps based on media content |
Publications (1)
Publication Number | Publication Date |
---|---|
US8989521B1 true US8989521B1 (en) | 2015-03-24 |
Family
ID=52683386
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/303,320 Expired - Fee Related US8989521B1 (en) | 2011-11-23 | 2011-11-23 | Determination of dance steps based on media content |
Country Status (1)
Country | Link |
---|---|
US (1) | US8989521B1 (en) |
Cited By (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150373428A1 (en) * | 2014-06-20 | 2015-12-24 | Google Inc. | Clarifying Audible Verbal Information in Video Content |
US20160267801A1 (en) * | 2013-10-24 | 2016-09-15 | Huawei Device Co., Ltd. | Image display method and apparatus |
US20160306172A1 (en) * | 2015-04-20 | 2016-10-20 | NSF International | Computer-implemented techniques for remotely interacting with performance of food quality, food safety, and workplace safety tasks |
US9805125B2 (en) | 2014-06-20 | 2017-10-31 | Google Inc. | Displaying a summary of media content items |
US9838759B2 (en) | 2014-06-20 | 2017-12-05 | Google Inc. | Displaying information related to content playing on a device |
US9946769B2 (en) | 2014-06-20 | 2018-04-17 | Google Llc | Displaying information related to spoken dialogue in content playing on a device |
US10034053B1 (en) | 2016-01-25 | 2018-07-24 | Google Llc | Polls for media program moments |
CN108615055A (en) * | 2018-04-19 | 2018-10-02 | 咪咕动漫有限公司 | A kind of similarity calculating method, device and computer readable storage medium |
US10349141B2 (en) | 2015-11-19 | 2019-07-09 | Google Llc | Reminders of media content referenced in other media content |
US10789485B2 (en) * | 2016-11-07 | 2020-09-29 | Motorola Solutions, Inc. | Guardian system in a network to improve situational awareness at an incident |
WO2021002522A1 (en) * | 2019-07-04 | 2021-01-07 | 주식회사 펀웨이브 | Dance motion analysis evaluation device and method |
US20220072424A1 (en) * | 2020-09-08 | 2022-03-10 | Com2Us Corporation | Method and system for providing game using switching between continuous and automatic battle and manual battle |
Citations (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4712103A (en) * | 1985-12-03 | 1987-12-08 | Motohiro Gotanda | Door lock control system |
US6001013A (en) * | 1996-08-05 | 1999-12-14 | Pioneer Electronics Corporation | Video dance game apparatus and program storage device readable by the apparatus |
US6353170B1 (en) * | 1998-09-04 | 2002-03-05 | Interlego Ag | Method and system for composing electronic music and generating graphical information |
US6433267B2 (en) | 2000-05-02 | 2002-08-13 | Samsung Electronics Co., Ltd. | Method for automatically creating dance patterns using audio signals |
US6438166B2 (en) * | 1997-12-10 | 2002-08-20 | Hitachi, Ltd. | Method and a apparatus for controlling a bit rate of picture data, and a storage medium which stores a program for controlling the bit rate |
US20020117043A1 (en) * | 2001-02-27 | 2002-08-29 | Powley Morris Leon | Music tone identification method related with apparatus, notation, and instruments |
US6663491B2 (en) * | 2000-02-18 | 2003-12-16 | Namco Ltd. | Game apparatus, storage medium and computer program that adjust tempo of sound |
US6758756B1 (en) * | 1997-12-19 | 2004-07-06 | Konami Co., Ltd. | Method of controlling video game, video game device, and medium recording video game program |
US6898759B1 (en) * | 1997-12-02 | 2005-05-24 | Yamaha Corporation | System of generating motion picture responsive to music |
US7000200B1 (en) * | 2000-09-15 | 2006-02-14 | Intel Corporation | Gesture recognition system recognizing gestures within a specified timing |
US7164076B2 (en) * | 2004-05-14 | 2007-01-16 | Konami Digital Entertainment | System and method for synchronizing a live musical performance with a reference performance |
US7217878B2 (en) * | 1998-05-15 | 2007-05-15 | Ludwig Lester F | Performance environments supporting interactions among performers and self-organizing processes |
US7373377B2 (en) * | 2002-10-16 | 2008-05-13 | Barbaro Technologies | Interactive virtual thematic environment |
US20080258921A1 (en) | 2007-04-19 | 2008-10-23 | Nike, Inc. | Footwork Training System and Method |
WO2009035199A1 (en) | 2007-09-15 | 2009-03-19 | Young-Dae Kim | Virtual studio posture correction machine |
US7517219B2 (en) * | 2004-02-20 | 2009-04-14 | Mcdonald Michael | Method of providing specialized dance videos |
US7528315B2 (en) | 2005-05-03 | 2009-05-05 | Codemasters Software Company Limited | Rhythm action game apparatus and method |
US20090267894A1 (en) * | 2008-04-23 | 2009-10-29 | Jun Doi | Operational object controlling device, system, method and program |
US7758427B2 (en) * | 2006-11-15 | 2010-07-20 | Harmonix Music Systems, Inc. | Facilitating group musical interaction over a network |
US7790976B2 (en) * | 2005-03-25 | 2010-09-07 | Sony Corporation | Content searching method, content list searching method, content searching apparatus, and searching server |
US7806759B2 (en) * | 2004-05-14 | 2010-10-05 | Konami Digital Entertainment, Inc. | In-game interface with performance feedback |
US20100271302A1 (en) | 2008-12-31 | 2010-10-28 | Trevor Pering | Sensor fusion to combine sensor input data from multiple devices into one input stream |
US8010162B2 (en) * | 2007-06-01 | 2011-08-30 | Lg Electronics Inc. | Mobile communication terminal and method of displaying information using the same |
US8057290B2 (en) * | 2008-12-15 | 2011-11-15 | Disney Enterprises, Inc. | Dance ring video game |
US20110306398A1 (en) * | 2010-06-11 | 2011-12-15 | Harmonix Music Systems, Inc. | Prompting a player of a dance game |
US20110309946A1 (en) * | 2010-05-26 | 2011-12-22 | Sony Ericsson Mobile Communications Ab | Adaptive media object reproduction based on social context |
US8132103B1 (en) * | 2006-07-19 | 2012-03-06 | Aol Inc. | Audio and/or video scene detection and retrieval |
US20120058824A1 (en) * | 2010-09-07 | 2012-03-08 | Microsoft Corporation | Scalable real-time motion recognition |
US8145594B2 (en) * | 2009-05-29 | 2012-03-27 | Microsoft Corporation | Localized gesture aggregation |
US8254964B2 (en) * | 2009-02-23 | 2012-08-28 | Sony Ericsson Mobile Communications Ab | Method and arrangement relating to location based services for a communication device |
US8591329B2 (en) * | 2010-02-05 | 2013-11-26 | Pc Concepts Limited | Methods and apparatuses for constructing interactive video games by use of video clip |
US8594846B2 (en) * | 2008-07-16 | 2013-11-26 | Honda Motor Co., Ltd. | Beat tracking apparatus, beat tracking method, recording medium, beat tracking program, and robot |
US8761437B2 (en) * | 2011-02-18 | 2014-06-24 | Microsoft Corporation | Motion recognition |
US20140237038A1 (en) * | 2013-02-15 | 2014-08-21 | Nokia Corporation | Method and Apparatus for Determining an Activity Description |
-
2011
- 2011-11-23 US US13/303,320 patent/US8989521B1/en not_active Expired - Fee Related
Patent Citations (38)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4712103A (en) * | 1985-12-03 | 1987-12-08 | Motohiro Gotanda | Door lock control system |
US6001013A (en) * | 1996-08-05 | 1999-12-14 | Pioneer Electronics Corporation | Video dance game apparatus and program storage device readable by the apparatus |
US6898759B1 (en) * | 1997-12-02 | 2005-05-24 | Yamaha Corporation | System of generating motion picture responsive to music |
US6438166B2 (en) * | 1997-12-10 | 2002-08-20 | Hitachi, Ltd. | Method and a apparatus for controlling a bit rate of picture data, and a storage medium which stores a program for controlling the bit rate |
US6758756B1 (en) * | 1997-12-19 | 2004-07-06 | Konami Co., Ltd. | Method of controlling video game, video game device, and medium recording video game program |
US7217878B2 (en) * | 1998-05-15 | 2007-05-15 | Ludwig Lester F | Performance environments supporting interactions among performers and self-organizing processes |
US6353170B1 (en) * | 1998-09-04 | 2002-03-05 | Interlego Ag | Method and system for composing electronic music and generating graphical information |
US6663491B2 (en) * | 2000-02-18 | 2003-12-16 | Namco Ltd. | Game apparatus, storage medium and computer program that adjust tempo of sound |
US6433267B2 (en) | 2000-05-02 | 2002-08-13 | Samsung Electronics Co., Ltd. | Method for automatically creating dance patterns using audio signals |
US7000200B1 (en) * | 2000-09-15 | 2006-02-14 | Intel Corporation | Gesture recognition system recognizing gestures within a specified timing |
US20020117043A1 (en) * | 2001-02-27 | 2002-08-29 | Powley Morris Leon | Music tone identification method related with apparatus, notation, and instruments |
US7373377B2 (en) * | 2002-10-16 | 2008-05-13 | Barbaro Technologies | Interactive virtual thematic environment |
US7517219B2 (en) * | 2004-02-20 | 2009-04-14 | Mcdonald Michael | Method of providing specialized dance videos |
US7164076B2 (en) * | 2004-05-14 | 2007-01-16 | Konami Digital Entertainment | System and method for synchronizing a live musical performance with a reference performance |
US7806759B2 (en) * | 2004-05-14 | 2010-10-05 | Konami Digital Entertainment, Inc. | In-game interface with performance feedback |
US7790976B2 (en) * | 2005-03-25 | 2010-09-07 | Sony Corporation | Content searching method, content list searching method, content searching apparatus, and searching server |
US7528315B2 (en) | 2005-05-03 | 2009-05-05 | Codemasters Software Company Limited | Rhythm action game apparatus and method |
US8719707B2 (en) * | 2005-11-29 | 2014-05-06 | Mercury Kingdom Assets Limited | Audio and/or video scene detection and retrieval |
US8132103B1 (en) * | 2006-07-19 | 2012-03-06 | Aol Inc. | Audio and/or video scene detection and retrieval |
US7758427B2 (en) * | 2006-11-15 | 2010-07-20 | Harmonix Music Systems, Inc. | Facilitating group musical interaction over a network |
US20080258921A1 (en) | 2007-04-19 | 2008-10-23 | Nike, Inc. | Footwork Training System and Method |
US8010162B2 (en) * | 2007-06-01 | 2011-08-30 | Lg Electronics Inc. | Mobile communication terminal and method of displaying information using the same |
WO2009035199A1 (en) | 2007-09-15 | 2009-03-19 | Young-Dae Kim | Virtual studio posture correction machine |
US20090267894A1 (en) * | 2008-04-23 | 2009-10-29 | Jun Doi | Operational object controlling device, system, method and program |
US8416185B2 (en) * | 2008-04-23 | 2013-04-09 | International Business Machines Corporation | Operational object controlling device, system, method and program |
US8594846B2 (en) * | 2008-07-16 | 2013-11-26 | Honda Motor Co., Ltd. | Beat tracking apparatus, beat tracking method, recording medium, beat tracking program, and robot |
US8057290B2 (en) * | 2008-12-15 | 2011-11-15 | Disney Enterprises, Inc. | Dance ring video game |
US20100271302A1 (en) | 2008-12-31 | 2010-10-28 | Trevor Pering | Sensor fusion to combine sensor input data from multiple devices into one input stream |
US8254964B2 (en) * | 2009-02-23 | 2012-08-28 | Sony Ericsson Mobile Communications Ab | Method and arrangement relating to location based services for a communication device |
US8145594B2 (en) * | 2009-05-29 | 2012-03-27 | Microsoft Corporation | Localized gesture aggregation |
US8591329B2 (en) * | 2010-02-05 | 2013-11-26 | Pc Concepts Limited | Methods and apparatuses for constructing interactive video games by use of video clip |
US20110309946A1 (en) * | 2010-05-26 | 2011-12-22 | Sony Ericsson Mobile Communications Ab | Adaptive media object reproduction based on social context |
US20110306398A1 (en) * | 2010-06-11 | 2011-12-15 | Harmonix Music Systems, Inc. | Prompting a player of a dance game |
US8562403B2 (en) * | 2010-06-11 | 2013-10-22 | Harmonix Music Systems, Inc. | Prompting a player of a dance game |
US8444464B2 (en) * | 2010-06-11 | 2013-05-21 | Harmonix Music Systems, Inc. | Prompting a player of a dance game |
US20120058824A1 (en) * | 2010-09-07 | 2012-03-08 | Microsoft Corporation | Scalable real-time motion recognition |
US8761437B2 (en) * | 2011-02-18 | 2014-06-24 | Microsoft Corporation | Motion recognition |
US20140237038A1 (en) * | 2013-02-15 | 2014-08-21 | Nokia Corporation | Method and Apparatus for Determining an Activity Description |
Cited By (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10283005B2 (en) * | 2013-10-24 | 2019-05-07 | Huawei Device Co., Ltd. | Image display method and apparatus |
US20160267801A1 (en) * | 2013-10-24 | 2016-09-15 | Huawei Device Co., Ltd. | Image display method and apparatus |
US9946769B2 (en) | 2014-06-20 | 2018-04-17 | Google Llc | Displaying information related to spoken dialogue in content playing on a device |
US11425469B2 (en) | 2014-06-20 | 2022-08-23 | Google Llc | Methods and devices for clarifying audible video content |
US9805125B2 (en) | 2014-06-20 | 2017-10-31 | Google Inc. | Displaying a summary of media content items |
US9838759B2 (en) | 2014-06-20 | 2017-12-05 | Google Inc. | Displaying information related to content playing on a device |
US10659850B2 (en) | 2014-06-20 | 2020-05-19 | Google Llc | Displaying information related to content playing on a device |
US11354368B2 (en) | 2014-06-20 | 2022-06-07 | Google Llc | Displaying information related to spoken dialogue in content playing on a device |
US11064266B2 (en) | 2014-06-20 | 2021-07-13 | Google Llc | Methods and devices for clarifying audible video content |
US10206014B2 (en) * | 2014-06-20 | 2019-02-12 | Google Llc | Clarifying audible verbal information in video content |
US11797625B2 (en) | 2014-06-20 | 2023-10-24 | Google Llc | Displaying information related to spoken dialogue in content playing on a device |
US10762152B2 (en) | 2014-06-20 | 2020-09-01 | Google Llc | Displaying a summary of media content items |
US20150373428A1 (en) * | 2014-06-20 | 2015-12-24 | Google Inc. | Clarifying Audible Verbal Information in Video Content |
US10638203B2 (en) | 2014-06-20 | 2020-04-28 | Google Llc | Methods and devices for clarifying audible video content |
US10431108B2 (en) * | 2015-04-20 | 2019-10-01 | NSF International | Computer-implemented techniques for interactively training users to perform food quality, food safety, and workplace safety tasks |
US20160307459A1 (en) * | 2015-04-20 | 2016-10-20 | NSF International | Computer-implemented techniques for interactively training users to perform food quality, food safety, and workplace safety tasks |
US20160306172A1 (en) * | 2015-04-20 | 2016-10-20 | NSF International | Computer-implemented techniques for remotely interacting with performance of food quality, food safety, and workplace safety tasks |
US10349141B2 (en) | 2015-11-19 | 2019-07-09 | Google Llc | Reminders of media content referenced in other media content |
US10841657B2 (en) | 2015-11-19 | 2020-11-17 | Google Llc | Reminders of media content referenced in other media content |
US11350173B2 (en) | 2015-11-19 | 2022-05-31 | Google Llc | Reminders of media content referenced in other media content |
US10034053B1 (en) | 2016-01-25 | 2018-07-24 | Google Llc | Polls for media program moments |
US10789485B2 (en) * | 2016-11-07 | 2020-09-29 | Motorola Solutions, Inc. | Guardian system in a network to improve situational awareness at an incident |
CN108615055A (en) * | 2018-04-19 | 2018-10-02 | 咪咕动漫有限公司 | A kind of similarity calculating method, device and computer readable storage medium |
WO2021002522A1 (en) * | 2019-07-04 | 2021-01-07 | 주식회사 펀웨이브 | Dance motion analysis evaluation device and method |
US20220072424A1 (en) * | 2020-09-08 | 2022-03-10 | Com2Us Corporation | Method and system for providing game using switching between continuous and automatic battle and manual battle |
US11872488B2 (en) * | 2020-09-08 | 2024-01-16 | Com2Us Corporation | Method and system for providing game using switching between continuous and automatic battle and manual battle |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8989521B1 (en) | Determination of dance steps based on media content | |
US11477156B2 (en) | Watermarking and signal recognition for managing and sharing captured content, metadata discovery and related arrangements | |
US10204274B2 (en) | Video to data | |
US9183883B2 (en) | Method and system for generating data for controlling a system for rendering at least one signal | |
US9436875B2 (en) | Method and apparatus for semantic extraction and video remix creation | |
CN109640125B (en) | Video content processing method, device, server and storage medium | |
CN110322760B (en) | Voice data generation method, device, terminal and storage medium | |
CN108270794B (en) | Content distribution method, device and readable medium | |
US20110228983A1 (en) | Information processor, information processing method and program | |
CN111295708A (en) | Speech recognition apparatus and method of operating the same | |
CN112153460B (en) | Video dubbing method and device, electronic equipment and storage medium | |
CN111625682B (en) | Video generation method, device, computer equipment and storage medium | |
US10277834B2 (en) | Suggestion of visual effects based on detected sound patterns | |
CN111512370A (en) | Voice tagging of video while recording | |
CN112883209A (en) | Recommendation method and processing method, device, equipment and readable medium for multimedia data | |
US9367613B1 (en) | Song identification trigger | |
CN113542626B (en) | Video dubbing method and device, computer equipment and storage medium | |
JP2012015809A (en) | Music selection apparatus, music selection method, and music selection program | |
CN116208704A (en) | Sound processing method and device | |
CN115810209A (en) | Speaker recognition method and device based on multi-mode feature fusion network | |
CN113724739A (en) | Method, terminal and storage medium for retrieving audio and training acoustic model | |
WO2020154883A1 (en) | Speech information processing method and apparatus, and storage medium and electronic device | |
CN114329001B (en) | Display method and device of dynamic picture, electronic equipment and storage medium | |
WO2023160515A1 (en) | Video processing method and apparatus, device and medium | |
WO2023224890A1 (en) | System and method for incorporating audio into audiovisual content |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:HO, CASEY KWOK CHING;SENG, PAULINE;NANAVATI, SHARVIL;REEL/FRAME:027275/0869Effective date: 20111122 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044334/0466Effective date: 20170929 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20190324 |