US8078617B1 - Model based ad targeting - Google Patents
Model based ad targeting Download PDFInfo
- Publication number
- US8078617B1 US8078617B1 US12/356,342 US35634209A US8078617B1 US 8078617 B1 US8078617 B1 US 8078617B1 US 35634209 A US35634209 A US 35634209A US 8078617 B1 US8078617 B1 US 8078617B1
- Authority
- US
- United States
- Prior art keywords
- query
- content items
- scores
- features
- odds
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/335—Filtering based on additional data, e.g. user or group profiles
Definitions
- This disclosure relates to information management.
- the server when a user sends a query to a server to request information, the server returns results in response to the query and sponsored content (e.g., advertisements, or ads) that is relevant to the query.
- the server may automatically select ads using a two-step process. In the first step, a set of candidate ads are selected from a large pool of ads. For keyword-based ads, the candidate ads can be selected based on matching the query with a set of keywords associated with each ad. For keyword-less ads, the candidate ads can be selected based on matching features associated with the query and ads.
- the features can include categorizations of the query and the ad, a relevance score between the query and creative text of the ad, and features derived from a landing page of the ad.
- the candidate ads are ranked and the best N (N being an integer) ads are selected. The best N ads are served to the user.
- the present disclosure includes a system and method for quickly selecting content items (e.g., documents) having highest ranking scores in response to a query for content items.
- content items e.g., documents
- base scores for a plurality of content items are determined based on attributes of the content items; a query is received; one or more attributes are extracted from the query; the base scores of at least some of the content items are adjusted based on relationships between the query attributes and the content item attributes; a subset of the plurality of content items having the highest adjusted scores are selected; and the selected subset of content items are output.
- the content items can include, e.g., ads.
- the content items can include, e.g., documents.
- Keywordless ad targeting can be performed in which the query includes a request for ads, and the subset of ads are selected without matching ad keywords with query keywords.
- the attributes of the query can include a property of (a) one or more keywords of a search query or (b) a web page on which an ad is to be displayed.
- the base scores can be determined prior to receiving the query.
- An index structure can be generated in which the content items are arranged in lists, and within each list the content items are sorted according to the base scores.
- the index structure can include parallel lists, each list being associated with a corresponding content item attribute and including content items having the corresponding attribute.
- the index structure can be transformed to generate a transformed index structure such that each content item appears in only one of the lists in the transformed index structure. Selecting a subset of the plurality of content items having the highest adjusted scores can include using the transformed index structure to select the subset of the plurality of content items having the highest adjusted scores.
- Adjusting the scores of at least some of the content items can include adjusting the scores of some of the content items having higher scores in the lists and not adjusting the scores of some of the content items having lower scores in the lists. Adjusting the scores of at least some of the content items can include using an odds model to determine the adjustments to the scores.
- the odds model can be updated to include information about new content items, and the updated odds model can be used to select a number of content items having highest adjusted scores in response to a second query.
- the odds model can include an odds map representing a first mapping relationship that maps query keys to doc keys and a second mapping relationship that doc keys to content items, the query keys representing features of queries and the doc keys representing features of ads.
- the odds model can include a template function to convert a query and content item pair to a collection of features used for prediction. Adjusting the scores of at least some of the content items can include determining which content item attributes are affected by the attributes of the received query, and adjusting the scores of the content items whose attributes are affected by the attributes of the received query.
- a first map that links query keys to content item keys is generated, the query keys representing features of queries, the content item keys representing features of content items; a second map that links content item keys to content items to indicate which content items are associated with each content item feature is generated; and the first and second maps are stored in a storage.
- Implementations may include one or more of the following features.
- a set of template functions that converts content item and query pairs into a set of features used for prediction can be generated.
- a query can be received, features can be extracted from the query using the template function, scores for a plurality of the set of content items can be determined based on the features of the query, the first map, and the second map, and a subset of the content items having the highest scores can be output.
- the content items can include, e.g., ads.
- the content items can include, e.g., documents.
- a query is received, a subset of content items having highest scores are identified among a set of content items based on information about features of the query, a first predetermined mapping relationship between query features and content item features, and a second predetermined mapping relationship between content item features and content items.
- Adjustments to pre-computed baseline scores are computed, in which the pre-computed baseline scores are associated with content items having features that are affected by the features of the received query according to the first and second mapping relationships; and the subset of content items having the highest scores are output.
- Implementations may include the following feature.
- the content items can include, e.g., ads.
- the content items can include, e.g., documents.
- an odds model is trained over a training set of queries and content items, the odds model including a query map that has information about how features of queries affect features of content items, each query feature being associated with one or more content item features, and a content item map that has information about which content items in the training set of content items are associated with each content item feature; and the odds model is output.
- Implementations may include one or more of the following features.
- a query can be received, and the odds model can be used to select a subset of content items having highest scores from among a set of content items in response to the query.
- the content items can include, e.g., documents.
- the content items can include, e.g., ads.
- a query is received, a first subset of content items having highest approximate scores are identified among a set of content items based on information about features of the query and an approximate odds model, the approximate odds model including a first predetermined mapping relationship between query features and content item features, and a second predetermined mapping relationship between content item features and content items.
- An exact odds model is applied to determine exact scores of the first subset of content items.
- a second subset of content items having highest exact scores among the first subset of content items are output.
- Implementations may include one or more of the following features.
- the first subset of content items can be identified by computing adjustments to pre-computed baseline scores for content items having features that are affected by the features of the received query according to the first and second mapping relationships.
- the content items can include, e.g., documents.
- the content items can include, e.g., ads.
- a system in another aspect, includes a storage to store scores of a plurality of content items in which the scores are determined based on features of the content items; and a processing device to receive a query, extract one or more features from the query, adjust the scores of at least some of the content items based on relationships between the query features and the content item features, and select a subset of the plurality of content items having the highest adjusted scores.
- Implementations may include one or more of the following features.
- the content items can include, e.g., documents.
- the content items can include, e.g., ads.
- a system in another aspect, includes means for storing scores of a plurality of content items in which the scores are determined based on attributes of the content items; and means for receiving a query, extracting one or more attributes from the query, adjusting the scores of at least some of the content items based on relationships between the query attributes and the content item attributes, and selecting a number of content items having the highest adjusted scores from the plurality of content items.
- Documents e.g., ads
- High quality keywordless ad targeting can be performed.
- User experiences can be improved.
- FIG. 1 is a schematic diagram of an example information system.
- FIG. 2 is a diagram of an example odds map.
- FIG. 3 is a diagram of an example odds model.
- FIG. 4 is a diagram of an index structure.
- FIGS. 5 and 6 are flow diagrams of example processes.
- FIG. 7 is a schematic representation of a general computing system.
- an information system 100 selects, in response to a query, a subset of content items (e.g., documents) having highest scores from a set of content items (e.g., documents) based on an odds model 110 .
- the odds model 110 is trained over past queries and content items to learn which content items are likely to have the highest scores in response to given queries.
- the scores can be determined based on, e.g., a ranking function or an auction function.
- the odds model 110 has information about base scores of content items (e.g., documents) that are determined using only information about the content items (e.g., without knowledge of the queries), so the base scores can be pre-computed prior to receiving any queries.
- the odds model 110 also has information about how certain features of queries affect the base scores of content items having particular features.
- the information system 100 extracts relevant features from the query, uses the odds model 110 to identify the content items (e.g., documents) whose scores are affected by the query features, and calculates the scores for those content items without calculating the scores of other content items.
- the information system 100 then identifies the content items (e.g., documents) having the highest adjusted scores from among all of the content items.
- the content items can be broadcast on radio or television, transmitted through the Internet, or distributed in printed media, etc.
- the content items can be, e.g., sponsored content, or advertisements (ads).
- the ads can include, e.g., radio ads, television ads, printed ads, etc.
- the ad may include an ad creative and may be associated with zero or more ad descriptors (e.g., keywords or key phrases).
- the ad creative can define the content of the advertisement that is shown to the users.
- the ad creative can be used to define text, images, audio, videos, and/or other data types, or combinations thereof, of the ad.
- the ad creative can also define a layout for the ad.
- the ads can be presented (or served) with a variety of on-line content, such as text messages, web pages, and video programs to users.
- queries as used in this document has a broad meaning and can refer to, for example, queries from end users or queries from web servers. Queries from users may include search queries asking for information related to certain keywords. Queries from web servers can be requests for ads to be placed on web pages served by the web servers. Other types of queries and documents can also be processed by the information system 100 .
- a unique feature of the information system 100 is that the system 100 can identify the subset of documents having the highest scores by calculating the scores for only a small number of documents without calculating the scores for all of the documents. Because the odds model 110 has information about which documents are affected by the query, the system 100 only has to calculate the scores for the documents whose scores are affected by the query. The subset of highest ranking documents selected by the system 100 using the odds model 110 are the same as those that would be selected if the ranking function were applied to all of the documents. This allows the system 100 to be highly scalable and can process a large number of documents in a very short time. For example, the system 100 can select one hundred best ads from a million ads in response to a request for ads from a web server within less than 10 milliseconds.
- odds models are used as examples to determine the scores of the documents. Any scoring function that is computable based on separable functions of the query and the documents can be also be used instead of the odds models.
- the information system 100 includes a search server 102 that receives search queries from users 104 , searches a database to find results in response to the search queries, and delivers the search results to the users 104 .
- the users 104 may send the search queries from, e.g., desktop computers or mobile phones.
- the search server 102 sends a query for ads to an ad server 106 .
- the query for ads may include information about the language of the user search query, the geographical location where the user search query originated, the keywords of the user search query, etc.
- the ad server 106 selects ads 108 using the odds model 110 and the information provided by the query for ads from the search engine 102 .
- the ads 108 are presented with the search results to the users 104 .
- links to the ads 108 are provided with the search results to the users 104 , and user applications (such as web browsers) retrieve the ads 108 based on the links and display the ads 108 along with the search results.
- the ad server 106 also receives query for ads from a web server 114 that hosts web sites for a publisher.
- the publisher may participate in an ad network in which the publisher agrees to show ads on web sites hosted by the web server 114 .
- the web sites may include web pages having reserved ad spaces for displaying ads.
- a query for ads sent by the web server 114 may include information about the web pages on which the ads will be displayed, the language the web pages are written in, the section titles or headings in the web pages, the geographical location where the web server 114 is located, and conditions or restrictions on the ads, e.g., ads having certain keywords or certain types of content should not be selected.
- the ad server 106 selects ads 108 using the odds model 110 and the information associated with the query for ads from the web server 114 , and delivers the ads 108 to the web server 114 .
- the users 104 and the web server 114 may communicate with the information system 100 through a network 122 , which can be, e.g., the Internet or other networks.
- a network 122 can be, e.g., the Internet or other networks.
- the ad server 106 uses an ad selection process to automatically select ads by approximating results of ideal auctions run over large sets of ads in which the same function is used to select candidate ads and rank the candidate ads.
- the ad selection process produces a list of all the ads in sorted order, e.g., in descending order of the best probability of the ads being clicked by a user. This allows the ad selection process to quickly provide the best N (N being an integer) ads for any given query. This improves the quality of ads compared to a two-step ad selection process by reducing the likelihood that good ads are not selected during the first step even though the ads may be considered to be very good in the second step.
- a model builder 118 uses information from a training data set 120 to build an odds ranking model (sometimes referred to simply as “odds model”) 110 using machine learning techniques to learn what scores would result when particular ads are served in response to particular queries.
- the training data set 120 includes past queries, ads that were delivered in response to the queries, and performance data (e.g., scores) associated with the ads.
- the training data set 120 can be updated as the system receives additional queries and delivers additional ads, for example, based on a database 116 that includes search logs for logging information from the search server 102 and ad logs for logging information from the ad sever 106 .
- the scores can be determined based on, e.g., an auction function.
- the model builder 118 analyzes pairs of queries and ads, and their corresponding performance data, and determines how features of queries and features of ads affect the scores.
- an odds ranking model has two parts. First, a set of template functions that receives (document, query) pairs as inputs and generates a set of discrete keys (or features) as output.
- the template functions define how to convert a (document, query) pair to a collection of features used for prediction.
- the second part of the odds ranking model is an “odds map” having information about relationships among keys and how keys affect the odds or scores.
- the odds map have floating point numbers representing odds multipliers for the features that have been learned by the model.
- an odds map 140 of an odds model 110 can be represented using two mapping relationships.
- a first mapping relationship 142 maps query keys 144 to doc keys 146 .
- Query keys 144 represent features of queries
- doc keys 146 represent features of ads.
- the first mapping relationship 142 indicates that, if a query has a feature represented by a particular query key 144 , the query feature will affect certain doc keys 146 that are linked to the query keys 144 according to the first mapping relationship 142 .
- a second mapping relationship 148 maps doc keys 146 to documents 124 (in this example, ads).
- the second mapping relationship 118 indicates which documents 124 have the features represented by the query keys 146 .
- the information system 100 can determine which query keys 144 represent the query features, which doc keys 146 are affected by the query keys 144 , and which documents 124 have features represented by the doc keys 146 that are affected by the query keys 144 .
- the odds model 110 can be used to select documents other than ads.
- Examples of the query keys 144 include the language of the user search query, the geographical location where the user search query originated, and the keywords of the user search query, etc.
- Examples of the doc keys 146 include the language in which the ad is written and keywords in the ad creative, etc.
- the odds model 110 belongs to a particular class of models in which the effects of the query features on the performance and the effects of the ad features on the performance can be separated.
- the model builder 118 computes base scores for the ads according to the ad features alone. The base scores indicate that, if an ad has certain features it will have a certain performance score.
- the odds map 140 For each link from a query key 144 to a doc key 146 , the odds map 140 also provides an adjustment (or odds multiplier) representing the effect of the query key and doc key on documents associated with the doc key.
- the odds model 110 assigns an adjustment a 1 to the link from a query key 144 a to a doc key 146 a , and that ads 124 a and 124 b have features represented by the doc key 146 a .
- the base score of each of ads 124 a and 124 b is adjusted by a 1 .
- the adjustment a 1 can represent an odds multiplier, so that if the base score of the ads 124 a and 124 b are S 1 and S 2 respectively, the adjusted scores for documents 124 a and 124 b are S 1 *a 1 and S 2 *a 2 , respectively.
- the adjustment can also include other functions.
- each query key triggers adjustments to the base scores of a number of documents (in this example, ads).
- the final score for each document is determined by considering cumulative adjustments from the multiple query keys.
- the information system 100 can quickly determine the base scores of all of the documents because only a small number of base scores need to be adjusted.
- a query has a limited number of query features represented by a limited number of query keys, which link to a limited number of doc keys, which in turn link to a limited number of documents (ads).
- the number of documents whose base scores need to be adjusted is small relative to the total number of documents.
- an operator who designs the odds model 110 may initially identify hundreds of potential features of queries and ads in the training data set 124 , and the model builder 118 analyzes the performance data to determine which query features and which ad features are useful in predicting performance. For example, the operator may initially identify query features X 1 to X 10 and ad features Y 1 to Y 10 to be potentially useful, and the model builder 118 after performing a machine learning process may determine that only query features X 1 , X 3 , and X 9 , and ad features Y 2 , Y 4 , and Y 7 affect the performance.
- FIG. 3 shows a diagram of an example odds map 130 and a set of template functions 150 of an odds ranking model 110 .
- the model builder 118 builds the odds map 130 and the set of template functions 150 by applying machine learning to the training data set 120 , in which the odds model 110 models how the features X 1 , X 3 , X 9 , Y 2 , Y 4 , and Y 7 affect the scores of the documents A, B, C, and D.
- the scores of the documents represent the performances of ads (e.g., odds that the ads will be clicked on, or the conversion rate of the ads).
- the query features X 1 , X 3 , and X 9 are represented by query keys 132 a , 132 b , and 132 c , respectively.
- the ad features Y 2 , Y 4 , and Y 7 are represented by doc keys 134 a , 134 b , and 134 c , respectively.
- the performance can be predicted just by determining whether the query has the features X 1 , X 3 , and/or X 9 , whether the ad has the features Y 2 , Y 4 , and/or Y 7 , and calculating the effects of the features X 1 , X 3 , X 9 , Y 2 , Y 4 , and Y 7 on the performance.
- the query key X 1 132 a affects the doc key Y 2 134 a .
- the query key X 3 132 b affects the doc key Y 2 134 a , doc key Y 4 134 b , and doc key Y 7 134 c .
- the query key X 9 132 c affects the doc key Y 7 134 c .
- Document A 136 a and document B 136 b have the feature Y 2 .
- Document A 136 a , document B 136 b , and document C 136 c have the feature Y 4 .
- Document B 136 b , document C 136 c , and document D 136 d have the feature Y 7 .
- the adjustments for the link 138 a from the query key X 1 132 a to the doc key Y 2 134 a , the link 138 b from the query key X 3 132 b to the doe key Y 2 134 a , the link 138 c from the query key X 3 132 b to the doc key Y 4 134 b , the link 138 d from the query key X 3 132 b to the doe key Y 7 134 c , and the link 138 e from the query key X 9 132 c to the doc key Y 7 134 c are 0.5, 0.3, 1.8, 1.1, and 0.9, respectively.
- the system 100 receives a query and needs to select N ads having the highest scores.
- the system 100 uses the template functions 150 to determine that the query has features X 1 and X 3 .
- the system 100 first calculates adjusted scores for the documents that are affected by the features X 1 and X 3 .
- the base score of document A 136 a is multiplied by 0.5 (the adjustment or odds multiplier for the link 138 a ), 0.3 (the adjustment for the link 138 b ), and 1.8 (the adjustment for the link 138 c ).
- the base score of document B 136 b is multiplied by 0.5 (the adjustment for the link 138 a ), 0.3 (the adjustment for the link 138 b ), 1.8 (the adjustment for the link 138 c ), and 1.1 (the adjustment for the link 138 d ).
- the base score of document C 136 c is multiplied by 1.8 (the adjustment for the link 138 c ) and 1.1 (the adjustment for the link 138 d ).
- the base score of document D 136 d is multiplied by 1.1 (the adjustment for the link 138 d ) and 0.9 (the adjustment for the link 138 e ).
- the system 100 examines the adjusted scores of documents A, B, C, and D, and the base scores of other documents, and identifies N documents having the highest scores.
- the system 100 can, for any query, quickly determine the N (N being an integer) best ads from among all of the ads in the training data set 120 .
- the system 100 extracts features from the query, identifies the query keys that correspond to the query features, identifies the doc keys that are affected by the query keys, and applies adjustments to the base scores of documents having features represented by the doc keys.
- the system 100 finds the N ads having the highest scores.
- the N best ads determined using the odds model 130 are the same as the N best ads determined using a brute force method that applies the ranking function to every ad in the training data set 120 to determine the scores of every ad, then selects the N documents having the highest scores.
- the odds model 110 can be used to predict the scores of other ads in response to queries, in which the ads or queries may not necessarily be represented by the training data set 120 .
- the information system 100 logs information about queries that are received and ads 108 that are served in response to the queries, as well as the performances of the ads 108 that are served, in the database 116 ( FIG. 1 ).
- the performance data can include, e.g., click-through rate and conversion rate.
- the model builder 118 uses machine learning techniques to update the odds model 110 to include information about the newly logged queries, ads 108 , and performance data.
- the model builder 118 updates the base scores of ads in the odds model 110 and information about how certain features of the queries affect the base scores of ads having particular features, e.g., the adjustments.
- the odds model 110 may be updated periodically, updated in response to an instruction from an operator, or when the number of new queries and ads received are above a threshold.
- the initial odds ranking model 110 can be performed off-line before receiving any new queries.
- the template functions are used to identify relevant features in the query
- the query features are given to the odds ranking model 110 to determine how the base scores of the documents are adjusted to generate final scores for the documents.
- the system 100 selects a number of documents having the highest adjusted scores, and serve the documents in response to the query.
- One way of determining the best N ads for a given query is to use “brute force” by calculating a score for every ad using a cost function and keeping track of the N ads having the highest scores.
- a more efficient way is to arrange an index data structure in such a way that the information system 100 does not have to consider every ad, and only calculate the scores for the ads that are likely to be the best ones.
- the auction function that determines a ranking score for each ad is dependent on both the ad and the query. In some examples, the auction function can be separated into two parts, the first part being dependent only on information associated with the ad (e.g., content of ad, bid for ad, landing page of ad, etc.), the second part being also dependent on the query.
- the first part of the auction function can be used to generate an index before any query is received, and the index can be used for ranking any query.
- the selection process runs through the index and determines which ads are likely to have a high score, and calculates the exact scores based on the ads and the query only for the ads that are likely to have high scores. Because the exact scores only have to be calculated for a small set of ads, the server can select good ads very quickly.
- the selection process uses a model that describes the probability that a user will click on an ad. This technique works for a specific class of models, and the results are perfect for that class of models. When a model belonging to the specific class of models is used, the selection process provides the same answer as using the brute force method. If an odds model X that does not belong to the specific class of models, another odds model in the specific class of models can be used to approximate the model X.
- the system 100 finds top M (M>N) ads quickly using the approximate model, and then for the top M ads determines the score exactly using the model X and finds the best N ads. For example, to find the top 10 ads, the system 100 can use the approximate model to find the best 100 ads, and then use the exact model to find the top 10 ads from among the 100 ads.
- the best ads can be identified based on an auction function.
- the auction function depends both on the quality of the ad (which affects the probability that users will click on the ad) and what an advertiser bids for the ad. An advertiser whose ad is not very good but bids very high may obtain the same position in the auction as another advertiser whose ad is very good but does not bid as high.
- the information system 100 can compute a prior baseline probability, which is a baseline auction score that depends only on the document and its bid.
- the baseline score does not depend on the query.
- Information other than the bid amount, in which the information can be obtained prior to receiving a query, can also be incorporated in the model and used in calculating the baseline auction score.
- a generic ranking function generates a score based on information about an ad and information about a query.
- the model that is used by the selection process belongs to a subset of the generic ranking functions, in which the models allow one to express the final score as a first function of the query only and a second function of the document only.
- a model can specify that when the query is from California and the document is from an advertiser whose address is in California, the probability that someone will click on the ad is higher. This model depends only on information computed solely from an ad, and information computed solely from a query.
- a feature can be extracted from a query without information about an ad, and a feature can be extracted from an ad without information about any queries.
- the model learns from looking at a combination of these two things in isolation.
- the index allows the system to pre-compute the relationships offline using the learning method.
- the system 100 uses a class of ranking models that are expressible as odds models.
- An odds model expresses the probability of an event in terms of a collection of adjustments to a prior odds of that event (e.g., for ads, the odds of interest are the (probability of a click/probability of no click)). For example, given a prior odds of 1.0 (i.e., click and no-click are equally likely), an odds model trained on historical ad click data may learn an adjustment rule of the form “ads in a different language than the query should have their click odds adjusted by 0.05” (e.g., it is less likely that someone will click on an ad in this case). The final probability of a click can be derived from the prior odds and the odds multipliers. In the examples described here, it is assumed that logistic regression is used as the underlying probabilistic model for the data. However, the model is not limited to using logistic regression.
- the odds ranking model includes an odds map that maps keys to odds multipliers (or adjustments) representing odds multipliers for those features that have been learned by the model.
- the odds map may contain an entry of the form: “one or more terms from the query appear in the ad title”-->1.2. This means that (document, query) pairs that express this feature will have their click odds increased by about 20%.
- predictions can be generated from a model as follows. Given a (document, query) pair, use the template functions for the model to generate the complete set of keys expressed by this pair. For each key, look up the associated odds for the key in the odds map. Compute a final probability from these odds using logistic regression.
- odds ranking models can be learned by analyzing historical log data (e.g., (document, query)-> ⁇ click, no_click ⁇ ), e.g., using methods such as maximum likelihood to estimate the model parameters.
- the goal of the systems is, given an odds ranking model and a large collection of documents (e.g., ads), efficiently rank the entire collection for a given query using the model.
- a large collection of documents e.g., ads
- the system Given a (document, query) pair, the system produces a set of query keys and a set of document keys and the system map odds for each of those keys. The system calculates an adjustment value to each of the keys.
- a baseline score which can be a prior score.
- the prior score takes into account the bid information or any information that can be computed based on the ad alone.
- the system extracts some attributes from the query, based on the odds model looks up the attributes to see how the attributes change the scores for all of the ads that have certain attributes, and applies the adjustments accordingly. For example, a query that contains a term X may affect documents that have the attribute Y and boost their scores by S 1 , and affect documents that have the attribute Z and lower their scores by S 2 .
- the system extracts two features from this query, feature one and feature two that are attributes of the query only.
- feature one is that the query has three words
- feature two is that the query contains a bi-gram “New Year”.
- the bid on the first ad is 10 cents
- the bid on the second ad is 5 cents.
- Each of the ads also expresses a set of attributes. One attribute is whether the ad contains “New Year” in the title, and a second attribute is the length of the title.
- each document e.g., ad
- a function can be used to extract a set of attributes from a given query.
- the odds model is a way of mapping these document attributes and the query attributes into an adjustment value.
- the odds model may indicate that when the query contains “New Year” attribute and the document contains “New Year” in the title attribute, the score is increased by some factor.
- the query length is three and the ad title length is less than three, then the title is likely to be a bit more general than the query, so the score is reduced by some percentage.
- the system applies the odds model to the query and ads. For the given query, the system determines its attributes, looks up how each of the query attributes changes the scores of documents have certain attributes, then applies the changes to all the documents that contain those attributes. Once the changes are applied to all the ads, the system obtains a different score for each of the ads whose bases scores are affected, and ranks the ads based on the modified scores.
- the final score for each ad computed using the odds model is the same as the final score computed by a traditional ads selection system that uses a two-step selection process.
- the difference between the ad selection process described in this document and the traditional two-step method is that in the new method, the system does not have to consider every ad.
- the new method allows the system to, out of a very large group of ads, find the best ads more efficiently by not having to consider all of them.
- the new ad selection process allows the system to avoid explicitly computing the score for every ad.
- the odds model looks at how attributes of the query change the scores of whole sets of ads.
- the learning models may have attributes that either affect a small number of ads, or a large number of ads. For example, there may be a model that learns to predict how features of the query adjust the scores for large collections of ads, such as ads with title lengths greater than three, which is a big set, and there may be 100,000 ads in the set.
- the model may learn that certain queries affect small sets of ads. For example, a specific ad for an auction site X may perform badly when shown on queries that contain the name of a web portal Z. There may be large collections of ads whose scores change in the same way.
- the system determines how the scores of whole sets of ads change, then ranks only the ads in the set that will get the highest final score.
- a matching algorithm is applied to match the keywords of the ads to the keywords of the query and select, e.g., 100,000 candidate ads.
- the scores are calculated using an auction function and the top, e.g., 100, ads having the highest scores are selected. Because advertisers may not necessarily know which queries users are going to send, and which keywords would best match those queries, there may be ads in the ads pool that are really good for certain queries but are not selected through the two-step ad selection process because the advertisers did not select the proper keywords.
- the new ad selection process can be used for keywordless ad targeting. Advertisers can just provide ads without choosing keywords, and the system using the new ad selection process will decide where the ads may be useful to target based on attributes extracted from the ads (e.g., from the ad creative). Using the new ad selection process, the ad is eligible to be shown on every query and ranked based on the auction function, compared to the traditional system where the ad is only eligible to be shown on queries where the advertiser foresaw that particular queries are good for the ad and explicitly chose keywords ahead of time to target the particular queries.
- the first technique is to use the odds model to determine how attributes change the scores of whole sets of ads. These sets may overlap in some way.
- the document attribute sets are organized in such a way that the sets do not overlap, every document appears in exactly one set.
- all of the ads can be classified into several “buckets”, and each ad belongs to exactly one bucket.
- the odds model provides information about the relationship between attributes of the query and how that attribute of the query changes the scores in each bucket.
- one bucket is for ads having titles of length 2
- one bucket is for ads having titles of length 3
- the two buckets are mutually exclusive.
- the ads in each of these two buckets can be ordered in such a way that within each bucket the prior scores are descending.
- the ads in each bucket that have the highest prior probability of a click times their bid occur first.
- the score is decreasing.
- the system can see how all the buckets change, look at the scores in descending order, and stop when all of the ads that are needed (the top N ads) are obtained.
- the system can search for ads in an order where the earlier ads are guaranteed to have higher scores than the later ones.
- the odds model may indicate that the ads in bin one will get a boost of 1.2 and the ads in bin two will get a demotion of 0.5.
- the system can go down the lists of ads in each bin and compute their final scores.
- the first example uses brute force.
- the non-overlapping bins are not used.
- the ads are separated into groups, and within each group the ads are sorted according to their baseline scores.
- an algorithm is applied for extracting attributes from the query and the attributes are applied in order to modify the scores of the ads, for each separate bin the way that the rank scores are modified (e.g., increased or decreased) is the same, so the system can go to the highest ranking ads and apply the changes.
- the system separates properties of the documents from properties of the queries in such a way that the system can compute scores for large numbers of ads more quickly than brute force.
- the system generates an index structure to help determine when to stop calculating the exact scores for the lower scoring ads to reduce the number of calculations. For example, the system may consider to adjust the scores of ads if the ads appear in the first P (P being an integer) entries in the lists in the index structure.
- the third example assumes there are bins (or partitions) that do not overlap.
- the third example is faster that the first and second examples, but may require certain limitations on the class of models that are used.
- the odds model is a predictive model that has historical information about whether certain queries have been clicked and what the results were.
- the system uses the odds model to try to predict for a new query and a new ad the probability of it being clicked.
- the odds model captures historical data to learn and apply to new situations.
- the system can determine the best ads in a large set that are most likely to get the best results for that query. The system can do that in such a way that the set can be quite large and the result can be returned quite efficiently.
- the baseline score is calculated for every ad.
- the learning model looks at the history of all ads and tries to estimate for a given ad, without seeing the query, whether it is a good ad, e.g., what the probability is that it will be clicked.
- the system separates the model being applied in the first example (brute force method) into two parts in such a way to make it more efficient to evaluate every ad as a candidate.
- both the first and second examples one tries to find the best ads in, e.g., one million ads.
- a predictor is applied sequentially to all the ads.
- the predictor is separated in two parts and a transformation is applied to transform it into a different kind of predictor, such that the new predictor provides information about which ones are the best ads without the need to apply the new predictor to every ad.
- the following is an example listing of pseudo code that can be used to implement a “brute force” method that ranks every ad. This example can be used as a baseline for evaluating other methods.
- This section describes an example illustrating the construction and use of an odds ranking model referred to as a “highroller model”.
- a highroller model In this example, bidding is not taken into account, and a large collection of ads are ranked by predicted click-through rate (CTR) only. It is assumed that each document in this example has the same prior odds.
- CTR predicted click-through rate
- the highroller model is a ranking model whose template functions are all separable.
- a separable template function is based on a measurement that is made on the query only, and an independent measurement made on a document only. For example, “the query is from Canada” is a separable query feature, while “the document has a high spam score” is a separable document feature.
- the template function combining these features is a separable template function.
- an index is constructed using the method below. It is assumed that one can determine the appropriate template function for a given key, as well as the constituent doc key and query key components of any template function.
- the resulting index can be represented as a tri-partite graph or odds map 140 of FIG. 2 .
- the odds map 140 shows query keys that are linked to document keys, which in turn are linked to documents. Because the ranking model is fully separable, every key in the odds map can be expressed as a (DocKey, QueryKey) pair. This represents the upper part of the graph. Because the model is separable, given a set of documents to be ranked, the system can pre-compute the relationship between all documents and the doc-keys they express, and link these relationships to the odds model as shown. For example, if the ranking model has only one template function (query_fp:customer_id), the system can pre-compute the lower portion of this graph by linking every document to its customer ID key. In some examples, a given document can be pointed to by more than one (Doc Key, Odds) pair.
- a query key 144 in the graph 140 represents an attribute of a query, such as “the query has 4 terms” or “the query has been classified as commercial”.
- a doc key 146 in the graph 140 represents an attribute of one or more documents, such as “documents that are in English” or “the document with ID 10243455”.
- the relationships between the query keys 144 and the doc keys 146 represent the model that has been learned over historical data. For example, “when the query has 4 terms and the document is in English, the odds of a click should be multiplied by 1.1”.
- the system can collect the top K predicted CTR candidates for a given query.
- the following is an example listing of pseudo code for doing this:
- one useful data structure for highroller serving is the interleaving odds iterator, shown in an index structure 150 in FIG. 4 .
- the index structure 150 includes K lists (e.g., 152 a , 152 b , 152 c , collectively referred to as 152 ) whose elements are document identifiers sorted in ascending order by doc id. Note that a given document id may appear in zero or more lists. Associated with each list is a working_odds multiplier. This odds multiplier applies to all documents in the list.
- the following is a listing of pseudo code of an iterator that, given a set of lists, generates a series of (document ID, posterior odds) pairs in ascending order by document ID:
- the algorithm above improves efficiency when there are a large number of documents because it is not necessary to consider every document to find the best K documents by posterior odds (e.g., the step where the system traverses the working_odds array in the previous algorithm can be skipped because the system can apply all the odds for a given document at the same time).
- interleaving odds iterators when using interleaving odds iterators, they are completely traversed in order to guarantee correctness. If a given document is present in at most one list, and each list is sorted by prior odds, instead of by doc id, then it is possible to efficiently iterate over all docs in descending order of posterior odds. The system can ignore a large numbers of documents and therefore serve much faster. Specifically, the system calls the NextDocOddsPair ( ) method above K times, where K is the number of documents that needs to be returned. Once the system has fetched the K documents, the system knows that all remaining documents have posterior odds lower than these K documents, so does not need to continue to traverse the lists.
- one of the steps in the construction of partitioned iterators is to find a transformation that can be applied to the doc keys in a highroller index. We want the transformed index to have the property that every document appears under exactly one doc key. If such a transformation can be found, the system can iterate over documents in order of descending posterior odds, and thus process only the best documents.
- the query keys be query length (with values 1, 2, and 3) and query language (with values English, Spanish, and Chinese).
- a given query will fall into one of 9 possible classes based on these query keys.
- the Doc Keys be document language (with values English, Spanish, and Chinese), customer ID (with values 0, 1, and 2) and ad cluster (with values 0, 1 and 2).
- a given document will fall into one of 27 possible classes based on these three document keys.
- there are about one million ads under each document key value e.g., one million English ads, one million ads for customer ID 0, etc.
- a new doc key posting lists 3 for language, 3 for customer, 3 for ad cluster
- the transformed index there are 27 doc keys, one for each vector value over the original doc keys.
- the transformed doc keys have the following property: a given document in the index appears in exactly one doc key posting list.
- odds models are designed to generalize over the documents.
- the model will include keys that cover many ads, which means the smallest partitions generally contain several documents.
- the collection of documents can be, e.g., sparse in the document key vector space. For example, a given customer is likely to have ads in only one language, which reduces the total number of possible partitions by a factor.
- odds models can be trained on significantly less data than is statistically required to distinguish all possible documents from each other under the model.
- the system can compute the best documents for a fully partitioned index using the following method. It is assumed that the doc keys have been transformed as described above.
- Using a heap to manage the partitions can improve the efficiency when large numbers of lists are being processed.
- One partitioning method divides the set of all documents such that Di and Dj were in the same partition if and only if Di and Dj always received the same working_odds update on every query (e.g., every path through the highroller graph assigns the same odds to Di and Dj).
- this method produces partitions that can be quite large (e.g., the total number of partitions is much smaller than the total number of documents). The reason seems to be that the models are trained on an amount of data that is very small compared to the total number of unique rankings over all ads, so the data and model are insufficient to distinguish every unique document from every other document.
- Equivalent document partitioning is attractive because the partitions can be computed efficiently in a single-pass over the highroller graph using ordered fingerprints.
- a highroller graph is effectively a set of lists of the form ⁇ QueryKey->(doc_id, odds) ⁇ . This set can be generated by flattening the graph into two levels. We want to construct a set of partitions to minimize the total number of bits required to transmit this set. Given two disjoint sets of DocIDs (Di, Dj) and a single list from the model described above, the compression score can be defined as follows:
- the set of partitions is initialized to be the set of all documents (e.g., every document is its own partition). For every pair of partitions, we want to compute a total compression score by computing the effect of merging Pi and Pj on the total size of the index. For example, if the documents in Pi and Pj are equivalent docs (e.g., the documents in each partition have odds that are the same under the model), the compression can be maximized since Pi and Pj can be merged into a common symbol in every posting list. However, there will be examples where under some lists in the model, Pi and Pj receive different odds updates. In this case we encode the difference as a remainder odds.
- Generalized partitioning can capture both the properties of equivalent ads and remainder partitions in one algorithm, and does not require an arbitrary definition of what constitutes a long list. While the computational complexity of the simple algorithm described above can be high, the simple “choose lists longer than size K to partition” heuristic works very well and generalized partitioning may produce the fastest servable indices.
- the new pipeline passes every query to the AbstractCandidateSelector with a value of N that can be less than the total number of documents.
- the resulting candidates are then passed in as “hints” to the highroller serving algorithm roughly as follows: the difference between this method and the simple separable algorithm is in steps 5 and 6 below (more efficient implementations are possible):
- a related idea is to use highroller methods to explore the space of possible candidates using reinforcement learning. Many ads appear to be identical to each other under a given model. A general theme in reinforcement learning is that greedy selection is rarely the best way to maximize cumulative return over time. Methods that balance greedy with some form of exploration of the space often perform better over time. Since highroller can be used to efficiently rank a large selection of ads, it can be used in a serving system where ranking is a non-deterministic function of both eCPM and, e.g., the number of ads sharing the same prediction keys, or some other measure that may increase the diversity of ads being shown.
- FIG. 5 is a flow diagram of an example process 160 for identifying a subset of highest ranking documents in response to a query for documents.
- the documents can be, e.g., ads 108 .
- base scores for a plurality of documents are determined based on attributes of the documents ( 162 ).
- the attributes can include the language of the documents and the keywords in the documents.
- a query is received ( 164 ).
- the query can be a request for ads.
- One or more attributes are extracted from the query ( 166 ).
- the attributes can be the language in which the query is written, the context of the query (e.g., the web page where the document is to be shown), and the geographical location from which the query was sent.
- the base scores of at least some of the documents are adjusted based on relationships between the query attributes and the document attributes ( 168 ).
- the odds multipliers can be used to adjust the base scores of the documents.
- a subset of the plurality of documents having the highest adjusted scores are selected ( 170 ).
- the selected subset of documents are output ( 172 ).
- FIG. 6 is a flow diagram of an example process 180 for establishing an odds ranking model.
- the process 180 can be implemented by the model builder 118 of FIG. 1 .
- the documents can be, e.g., ads 108 .
- the process 180 generates a first map that links query keys to document keys, the query keys representing features of queries, the document keys representing features of documents ( 182 ).
- a second map that links document keys to documents is generated to indicate which documents are associated with each document feature ( 184 ).
- a set of template functions that converts document and query pairs into a set of features used for prediction are generated ( 186 ).
- the first map, the second map, and the set of template functions are stored in a storage ( 188 ).
- the first map, the second map, and the set of template functions can be the basis of the odds model 110 that is used to select the highest ranking ads in request to a query for ads.
- FIG. 7 is a schematic representation of a general computing system 200 that can be used to implement the information system 100 .
- Computing device 200 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.
- the components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
- Computing device 200 includes a processor 202 , memory 204 , a storage device 306 , a high-speed interface 208 connecting to memory 204 and high-speed expansion ports 210 , and a low speed interface 212 connecting to low speed bus 214 and storage device 206 .
- Each of the components 202 , 204 , 206 , 208 , 210 , and 212 are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 202 can process instructions for execution within the computing device 200 , including instructions stored in the memory 204 or on the storage device 206 to display graphical information for a GUI on an external input/output device, such as display 216 coupled to high speed interface 208 .
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 200 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 204 stores information within the computing device 200 .
- the memory 204 is a volatile memory unit or units.
- the memory 204 is a non-volatile memory unit or units.
- the memory 204 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 206 is capable of providing mass storage for the computing device 200 .
- the storage device 206 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 204 , the storage device 206 , memory on processor 202 , or a propagated signal.
- the high speed controller 208 manages bandwidth-intensive operations for the computing device 200 , while the low speed controller 212 manages lower bandwidth-intensive operations.
- the high-speed controller 208 is coupled to memory 204 , display 216 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 210 , which may accept various expansion cards (not shown).
- low-speed controller 212 is coupled to storage device 206 and low-speed expansion port 214 .
- the low-speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 200 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 220 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system 224 . In addition, it may be implemented in a personal computer such as a laptop computer 222 . Each of such devices (e.g., standard server, rack server system, personal computer, and laptop computer) may contain one or more of computing device 200 , and an entire system may be made up of multiple computing devices 200 communicating with each other.
- a standard server 220 or multiple times in a group of such servers. It may also be implemented as part of a rack server system 224 . In addition, it may be implemented in a personal computer such as a laptop computer 222 .
- Each of such devices e.g., standard server, rack server system, personal computer, and laptop computer
- implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse, trackball, touch-sensitive screen, or iDrive-like component) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse, trackball, touch-sensitive screen, or iDrive-like component
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- the features of queries and features of documents can be different from those described above.
- the structure of the odds map and index can be different from those shown in FIGS. 2-4 .
Abstract
Description
-
- Document: The content associated with a single ad (e.g., the customer identifier, creative, and landing page associated with the ad).
- Query: The content associated with a single ad request (e.g., the personal history of the user, the Internet Protocol (IP) address from which the request originated, and semantic word clusters of the content page where an ad is shown).
- Feature template: A discrete function of an ad request and a document used for click-through prediction (e.g., query_unigram:customer_id).
- Feature template key: An instantiated value for a given template (e.g., query_unigram=“foo”:customer_id=100).
- Doc key: A feature template key whose value is a function of a document only (e.g. customer_id=1011).
- Query key: A feature template key whose value is a function of a query only (e.g., query_unigram=“inference”).
- Separable feature template: A feature template that can be expressed as a function of a query only, and a function of a document only; the value of a separable feature template can be computed by independently measuring a property of a document and a property of a query, but not both at the same time (e.g., query_fp:customer_id is a separable feature template).
- Inseparable feature template: A feature template that requires measuring properties of both a document and a query simultaneously (e.g., the number of query terms that are also in the creative).
- Ranking model: Any function that computes a partial-ordering of eligible documents given a query.
- CoOccurance model: A ranking function based only on separable feature templates.
- eCPM: Expected cost per impression (e.g., predicted_ctr*cpc).
The Odds Ranking Model
-
- 1. For each servable document d:
- Compute all the keys {k} for this (document, query) pair using the template functions for the current model.
- TempOdds=1.0
- For each key k in the set above:
- TempOdds*=OddsMap[k]
- Push the (TempOdds, document) pair onto a priority queue of max size K
- 2. Return the top K documents by final odds.
The Separable Odds Machine
- 1. For each servable document d:
-
- 1. Create two maps: the QueryMap {QueryKey->{(DocKey, Odds)}}, and the DocMap {DocKey->{Document}}, initially empty.
- 2. For each entry (Key k, Odds o) in the Odds Map:
- Since the Template Function that generated k is separable, k can be expressed as a (Doc Key=dk, Query Key=qk) pair.
- Insert (qk, (dk, o)) into the Query Map. If dk is already present, multiply its current map value by o.
- 3. For each Document d in ServableDocumentSet:
- For each Template Function tf in TemplateFunctions:
- Generate the set of Doc Keys expressed by d under
- For each Key k in this set:
- Since k was generated by a separable function, it can be expressed as a (Doc Key=dk, Query Key=qk) pair.
- Insert (dk, d) into the Doc Map.
- For each Template Function tf in TemplateFunctions:
- 4. Return (QueryMap, DocMap)
-
- 1. Assume every servable Document d has an index di in a dense range [0, num_servable_does) that uniquely identifies the document; this is convenient but not essential.
- 2. Initialize a map of working_odds (length=num total servable documents) such that working_odds[i]=1.0.
- 3. Compute all the QueryKeys {qk} for the Query using the Template Functions for the current model.
- 4. For each QueryKey qk:
- For each (DocKey dk, Odds o) node neighboring qk:
- For each Document d with index di neighboring dk:
- Update working_odds[di]*=o
- For each Document d with index di neighboring dk:
- For each (DocKey dk, Odds o) node neighboring qk:
- 5. Traverse the working_odds array, collecting the top K documents in a priority queue.
- 6. Return the top K documents from this queue.
Odds Iterators
-
- 1. // Determine the next smallest doc id across all lists:
- 2. smallest_doc_id=UNKNOWN
- 3. For each i in range(0, current_list_position.length):
- If doc_lists[i][current_list_position[i]]doc_id<smallest_doc_id:
- smallest_doc_id=doc_lists[i][current_list_position[i]].doc_id
- If doc_lists[i][current_list_position[i]]doc_id<smallest_doc_id:
- 4. // Compute the posterior odds for the smallest doc and advance iterators:
- 5. posterior_odds=1.0
- 6. For each i in range(0, current_list_position.length):
- If doc_lists[i][current_list_position[i]]==smallest_doc_id:
- posterior_odds*=doc_lists[i].working_odds* doc_lists[i][current_list_position[i]].odds
- ++current_list_position[i]
- If doc_lists[i][current_list_position[i]]==smallest_doc_id:
- 7. Return (smallest_doc_id, posterior_odds)
-
- 1. Compute all the QueryKeys {qk} for the Query using the Template Functions for the current model.
- 2. For each QueryKey qk:
- Collect each (DocKey dk, Odds o) node neighboring qk into a map from DocKey->(odds_update, doc_list, index). Doc_list is the list of documents under DocKey, sorted in descending order by prior odds. Index is initialized to 0, and represents the current iterator position for the given doc key list. odds_update is the total odds update for dk under all QueryKeys qk.
- 3. Until we have num_candidates ads:
- Set best_odds=0, best_document=NULL, best_doc_key=NULL
- For each DocKey dk in the map:
- Compute the posterior odds of the document at index as posterior_odds=odds_update*prior_odds. Note again that a given document will appear in at most one doc_list, and thus it's final odds update
- If the posterior odds for this document is larger than best_odds, set best_document=document, best_odds=posterior_odds, best_doc_key=dk.
- Add (best_document, best_odds) to the list of candidates to return.
- Advance index for best_doc_key to index+1.
-
- 1. score=len(doc_odds_map)
- 2. For each pi in pi_docs:
- For each pj in pj_docs:
- if (pi,pj) are both in doc_odds_map.keys( ) and doc_odds_map[pi]==doc_odds_map[pj]:
- score−=1
- else:
- score+=1
- if (pi,pj) are both in doc_odds_map.keys( ) and doc_odds_map[pi]==doc_odds_map[pj]:
- For each pj in pj_docs:
- 3. Return score
-
- Given: A Query (Q) and number of candidates (N)
- Return: A list of CandidateHints, length N. A candidate hint consists of a unique document id and a list of one or more arbitrary values (e.g. a score, a list of the terms that match both the query and the doc, etc).
-
- 1. Initialize an array of working_odds and an array of scoreable_documents such that the current odds for scoreable_documents[i]=working_odds[i].
- 2. Compute all the QueryKeys relevant for the query.
- 3. For each QueryKey qk:
- 4. For each (DocKey dk, Odds o) node neighboring qk:
- For each Document d neighboring dk:
- Update working_odds[d]*=o
- For each Document d neighboring dk:
- 5. For each candidate C=(Document d, FeatureList fl):
- For each Feature fin fl:
- Lookup the odds for feature fl in a raw map containing only the non-separable portion of the complete smartass model. Call this odds o′.
- Update working_odds[index(d)]*=o′
- For each Feature fin fl:
- 6. For every Document d NOT present in the candidate_hints list:
- working_odds[index(d)]*=prior_odds
- 7. Traverse the working_odds array, collecting the top K documents in a priority queue.
- 8. Return the docs associated with these top odds.
Bootstrapping
Claims (33)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/356,342 US8078617B1 (en) | 2009-01-20 | 2009-01-20 | Model based ad targeting |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/356,342 US8078617B1 (en) | 2009-01-20 | 2009-01-20 | Model based ad targeting |
Publications (1)
Publication Number | Publication Date |
---|---|
US8078617B1 true US8078617B1 (en) | 2011-12-13 |
Family
ID=45092780
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/356,342 Active 2030-02-19 US8078617B1 (en) | 2009-01-20 | 2009-01-20 | Model based ad targeting |
Country Status (1)
Country | Link |
---|---|
US (1) | US8078617B1 (en) |
Cited By (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110082756A1 (en) * | 2009-10-06 | 2011-04-07 | Sapient, Inc. | Advertising product, and a system and method for implementing the advertising product |
US20110187717A1 (en) * | 2010-01-29 | 2011-08-04 | Sumanth Jagannath | Producing Optimization Graphs in Online Advertising Systems |
US20110196733A1 (en) * | 2010-02-05 | 2011-08-11 | Wei Li | Optimizing Advertisement Selection in Contextual Advertising Systems |
US20110264516A1 (en) * | 2010-04-27 | 2011-10-27 | Yahoo! Inc. | Limiting latency due to excessive demand in ad exchange |
US20120005029A1 (en) * | 2010-07-01 | 2012-01-05 | Yahoo! Inc. | System for handling multiple priorities in ad exchange auction |
US20120030007A1 (en) * | 2010-07-28 | 2012-02-02 | Yahoo Inc. | Online advertisement profiles |
US20120036023A1 (en) * | 2010-08-04 | 2012-02-09 | Yahoo! Inc. | System for conducting demand-side, real-time bidding in an advertising exchange |
US20120054200A1 (en) * | 2010-08-26 | 2012-03-01 | International Business Machines Corporation | Selecting a data element in a network |
US20130013574A1 (en) * | 2011-07-06 | 2013-01-10 | Microsoft Corporation | Block Entropy Encoding for Word Compression |
US20140214786A1 (en) * | 2013-01-31 | 2014-07-31 | Alpine Electronics, Inc. | Internet search apparatus |
US8880438B1 (en) | 2012-02-15 | 2014-11-04 | Google Inc. | Determining content relevance |
CN104899273A (en) * | 2015-05-27 | 2015-09-09 | 东南大学 | Personalized webpage recommendation method based on topic and relative entropy |
US20160246885A1 (en) * | 2015-02-23 | 2016-08-25 | Genesys Telecommunications Laboratories, Inc. | Proactive knowledge offers |
US20160328380A1 (en) * | 2014-02-22 | 2016-11-10 | Tencent Technology (Shenzhen) Company Limited | Method and apparatus for determining morpheme importance analysis model |
US20180101533A1 (en) * | 2016-10-10 | 2018-04-12 | Microsoft Technology Licensing, Llc | Digital Assistant Extension Automatic Ranking and Selection |
US20180210897A1 (en) * | 2015-12-31 | 2018-07-26 | Baidu Online Network Technology (Beijing) Co., Ltd. | Model generation method, word weighting method, device, apparatus, and computer storage medium |
US10325304B2 (en) * | 2014-05-23 | 2019-06-18 | Ebay Inc. | Personalizing alternative recommendations using search context |
US10373171B2 (en) | 2015-02-23 | 2019-08-06 | Genesys Telecommunications Laboratories, Inc. | System and method for making engagement offers based on observed navigation path |
US10609434B2 (en) * | 2018-08-07 | 2020-03-31 | Adobe Inc. | Machine-learning based multi-step engagement strategy generation and visualization |
US10664332B2 (en) | 2018-05-25 | 2020-05-26 | Microsoft Technology Licensing, Llc | Application programming interfaces for identifying, using, and managing trusted sources in online and networked content |
US10922713B2 (en) * | 2017-01-03 | 2021-02-16 | Facebook, Inc. | Dynamic creative optimization rule engine for effective content delivery |
CN112699656A (en) * | 2020-12-31 | 2021-04-23 | 北京有竹居网络技术有限公司 | Advertisement title rewriting method, device, equipment and storage medium |
US11023553B2 (en) * | 2017-04-04 | 2021-06-01 | Microsoft Technology Licensing, Llc | Identifying and managing trusted sources in online and networked content for professional knowledge exchange |
US11107115B2 (en) | 2018-08-07 | 2021-08-31 | Adobe Inc. | Machine-learning based multi-step engagement strategy modification |
US11210685B2 (en) * | 2020-05-15 | 2021-12-28 | Intellisea LLC | System and method for multi-channel digital marketing optimization |
US11354590B2 (en) | 2017-11-14 | 2022-06-07 | Adobe Inc. | Rule determination for black-box machine-learning models |
Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6185558B1 (en) * | 1998-03-03 | 2001-02-06 | Amazon.Com, Inc. | Identifying the items most relevant to a current query based on items selected in connection with similar queries |
US6564213B1 (en) * | 2000-04-18 | 2003-05-13 | Amazon.Com, Inc. | Search query autocompletion |
US20040117367A1 (en) * | 2002-12-13 | 2004-06-17 | International Business Machines Corporation | Method and apparatus for content representation and retrieval in concept model space |
US20060020596A1 (en) * | 2004-06-02 | 2006-01-26 | Yahoo! Inc. | Content-management system for user behavior targeting |
US7031961B2 (en) * | 1999-05-05 | 2006-04-18 | Google, Inc. | System and method for searching and recommending objects from a categorically organized information repository |
US20090006360A1 (en) * | 2007-06-28 | 2009-01-01 | Oracle International Corporation | System and method for applying ranking svm in query relaxation |
US20090112830A1 (en) * | 2007-10-25 | 2009-04-30 | Fuji Xerox Co., Ltd. | System and methods for searching images in presentations |
US20090276414A1 (en) * | 2008-04-30 | 2009-11-05 | Microsoft Corporation | Ranking model adaptation for searching |
US7647314B2 (en) * | 2006-04-28 | 2010-01-12 | Yahoo! Inc. | System and method for indexing web content using click-through features |
US7672969B1 (en) * | 2006-08-25 | 2010-03-02 | The United States Of America As Represented By The Administrator Of The National Aeronautics And Space Administration (Nasa) | Context based configuration management system |
US7693829B1 (en) * | 2005-04-25 | 2010-04-06 | Google Inc. | Search engine with fill-the-blanks capability |
US20100169313A1 (en) * | 2008-12-30 | 2010-07-01 | Expanse Networks, Inc. | Pangenetic Web Item Feedback System |
US7756860B2 (en) * | 2007-05-23 | 2010-07-13 | International Business Machines Corporation | Advanced handling of multiple form fields based on recent behavior |
US7849076B2 (en) * | 2008-03-31 | 2010-12-07 | Yahoo! Inc. | Learning ranking functions incorporating isotonic regression for information retrieval and ranking |
US7853589B2 (en) * | 2007-04-30 | 2010-12-14 | Microsoft Corporation | Web spam page classification using query-dependent data |
US7860852B2 (en) * | 2007-03-27 | 2010-12-28 | Brunner Josie C | Systems and apparatuses for seamless integration of user, contextual, and socially aware search utilizing layered approach |
US7917480B2 (en) * | 2004-08-13 | 2011-03-29 | Google Inc. | Document compression system and method for use with tokenspace repository |
US20110099059A1 (en) * | 2009-10-27 | 2011-04-28 | Yahoo! Inc. | Index-based technique friendly ctr prediction and advertisement selection |
-
2009
- 2009-01-20 US US12/356,342 patent/US8078617B1/en active Active
Patent Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6185558B1 (en) * | 1998-03-03 | 2001-02-06 | Amazon.Com, Inc. | Identifying the items most relevant to a current query based on items selected in connection with similar queries |
US7031961B2 (en) * | 1999-05-05 | 2006-04-18 | Google, Inc. | System and method for searching and recommending objects from a categorically organized information repository |
US6564213B1 (en) * | 2000-04-18 | 2003-05-13 | Amazon.Com, Inc. | Search query autocompletion |
US20040117367A1 (en) * | 2002-12-13 | 2004-06-17 | International Business Machines Corporation | Method and apparatus for content representation and retrieval in concept model space |
US20060020596A1 (en) * | 2004-06-02 | 2006-01-26 | Yahoo! Inc. | Content-management system for user behavior targeting |
US7917480B2 (en) * | 2004-08-13 | 2011-03-29 | Google Inc. | Document compression system and method for use with tokenspace repository |
US7693829B1 (en) * | 2005-04-25 | 2010-04-06 | Google Inc. | Search engine with fill-the-blanks capability |
US7647314B2 (en) * | 2006-04-28 | 2010-01-12 | Yahoo! Inc. | System and method for indexing web content using click-through features |
US7672969B1 (en) * | 2006-08-25 | 2010-03-02 | The United States Of America As Represented By The Administrator Of The National Aeronautics And Space Administration (Nasa) | Context based configuration management system |
US7860852B2 (en) * | 2007-03-27 | 2010-12-28 | Brunner Josie C | Systems and apparatuses for seamless integration of user, contextual, and socially aware search utilizing layered approach |
US7853589B2 (en) * | 2007-04-30 | 2010-12-14 | Microsoft Corporation | Web spam page classification using query-dependent data |
US7756860B2 (en) * | 2007-05-23 | 2010-07-13 | International Business Machines Corporation | Advanced handling of multiple form fields based on recent behavior |
US20090006360A1 (en) * | 2007-06-28 | 2009-01-01 | Oracle International Corporation | System and method for applying ranking svm in query relaxation |
US20090112830A1 (en) * | 2007-10-25 | 2009-04-30 | Fuji Xerox Co., Ltd. | System and methods for searching images in presentations |
US7849076B2 (en) * | 2008-03-31 | 2010-12-07 | Yahoo! Inc. | Learning ranking functions incorporating isotonic regression for information retrieval and ranking |
US20090276414A1 (en) * | 2008-04-30 | 2009-11-05 | Microsoft Corporation | Ranking model adaptation for searching |
US20100169313A1 (en) * | 2008-12-30 | 2010-07-01 | Expanse Networks, Inc. | Pangenetic Web Item Feedback System |
US20110099059A1 (en) * | 2009-10-27 | 2011-04-28 | Yahoo! Inc. | Index-based technique friendly ctr prediction and advertisement selection |
Cited By (38)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110082756A1 (en) * | 2009-10-06 | 2011-04-07 | Sapient, Inc. | Advertising product, and a system and method for implementing the advertising product |
US20110187717A1 (en) * | 2010-01-29 | 2011-08-04 | Sumanth Jagannath | Producing Optimization Graphs in Online Advertising Systems |
US8896604B2 (en) * | 2010-01-29 | 2014-11-25 | Yahoo! Inc. | Producing optimization graphs in online advertising systems |
US20110196733A1 (en) * | 2010-02-05 | 2011-08-11 | Wei Li | Optimizing Advertisement Selection in Contextual Advertising Systems |
US20110264516A1 (en) * | 2010-04-27 | 2011-10-27 | Yahoo! Inc. | Limiting latency due to excessive demand in ad exchange |
US20120005029A1 (en) * | 2010-07-01 | 2012-01-05 | Yahoo! Inc. | System for handling multiple priorities in ad exchange auction |
US20120030007A1 (en) * | 2010-07-28 | 2012-02-02 | Yahoo Inc. | Online advertisement profiles |
US20120036023A1 (en) * | 2010-08-04 | 2012-02-09 | Yahoo! Inc. | System for conducting demand-side, real-time bidding in an advertising exchange |
US20120233180A1 (en) * | 2010-08-26 | 2012-09-13 | International Business Machines Corporation | Selecting a data element in a network |
US8589412B2 (en) * | 2010-08-26 | 2013-11-19 | International Business Machines Corporation | Selecting a data element in a network |
US8589409B2 (en) * | 2010-08-26 | 2013-11-19 | International Business Machines Corporation | Selecting a data element in a network |
US20120054200A1 (en) * | 2010-08-26 | 2012-03-01 | International Business Machines Corporation | Selecting a data element in a network |
US20130013574A1 (en) * | 2011-07-06 | 2013-01-10 | Microsoft Corporation | Block Entropy Encoding for Word Compression |
US8694474B2 (en) * | 2011-07-06 | 2014-04-08 | Microsoft Corporation | Block entropy encoding for word compression |
US8880438B1 (en) | 2012-02-15 | 2014-11-04 | Google Inc. | Determining content relevance |
US20140214786A1 (en) * | 2013-01-31 | 2014-07-31 | Alpine Electronics, Inc. | Internet search apparatus |
US20160328380A1 (en) * | 2014-02-22 | 2016-11-10 | Tencent Technology (Shenzhen) Company Limited | Method and apparatus for determining morpheme importance analysis model |
US10296582B2 (en) * | 2014-02-22 | 2019-05-21 | Tencent Technology (Shenzhen) Company Limited | Method and apparatus for determining morpheme importance analysis model |
US10325304B2 (en) * | 2014-05-23 | 2019-06-18 | Ebay Inc. | Personalizing alternative recommendations using search context |
US20160246885A1 (en) * | 2015-02-23 | 2016-08-25 | Genesys Telecommunications Laboratories, Inc. | Proactive knowledge offers |
US10373171B2 (en) | 2015-02-23 | 2019-08-06 | Genesys Telecommunications Laboratories, Inc. | System and method for making engagement offers based on observed navigation path |
US10127321B2 (en) * | 2015-02-23 | 2018-11-13 | Genesys Telecommunications Laboratories, Inc. | Proactive knowledge offering system and method |
CN104899273A (en) * | 2015-05-27 | 2015-09-09 | 东南大学 | Personalized webpage recommendation method based on topic and relative entropy |
CN104899273B (en) * | 2015-05-27 | 2017-08-25 | 东南大学 | A kind of Web Personalization method based on topic and relative entropy |
US10565253B2 (en) * | 2015-12-31 | 2020-02-18 | Baidu Online Network Technology (Beijing) Co., Ltd. | Model generation method, word weighting method, device, apparatus, and computer storage medium |
US20180210897A1 (en) * | 2015-12-31 | 2018-07-26 | Baidu Online Network Technology (Beijing) Co., Ltd. | Model generation method, word weighting method, device, apparatus, and computer storage medium |
US10437841B2 (en) * | 2016-10-10 | 2019-10-08 | Microsoft Technology Licensing, Llc | Digital assistant extension automatic ranking and selection |
US20180101533A1 (en) * | 2016-10-10 | 2018-04-12 | Microsoft Technology Licensing, Llc | Digital Assistant Extension Automatic Ranking and Selection |
US10922713B2 (en) * | 2017-01-03 | 2021-02-16 | Facebook, Inc. | Dynamic creative optimization rule engine for effective content delivery |
US11023553B2 (en) * | 2017-04-04 | 2021-06-01 | Microsoft Technology Licensing, Llc | Identifying and managing trusted sources in online and networked content for professional knowledge exchange |
US11354590B2 (en) | 2017-11-14 | 2022-06-07 | Adobe Inc. | Rule determination for black-box machine-learning models |
US10664332B2 (en) | 2018-05-25 | 2020-05-26 | Microsoft Technology Licensing, Llc | Application programming interfaces for identifying, using, and managing trusted sources in online and networked content |
US11109084B2 (en) | 2018-08-07 | 2021-08-31 | Adobe Inc. | Machine-learning based multi-step engagement strategy generation and visualization |
US11107115B2 (en) | 2018-08-07 | 2021-08-31 | Adobe Inc. | Machine-learning based multi-step engagement strategy modification |
US10609434B2 (en) * | 2018-08-07 | 2020-03-31 | Adobe Inc. | Machine-learning based multi-step engagement strategy generation and visualization |
US11816696B2 (en) | 2018-08-07 | 2023-11-14 | Adobe Inc. | Machine-learning based multi-step engagement strategy modification |
US11210685B2 (en) * | 2020-05-15 | 2021-12-28 | Intellisea LLC | System and method for multi-channel digital marketing optimization |
CN112699656A (en) * | 2020-12-31 | 2021-04-23 | 北京有竹居网络技术有限公司 | Advertisement title rewriting method, device, equipment and storage medium |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8078617B1 (en) | Model based ad targeting | |
US11392778B2 (en) | Use of statistical flow data for machine translations between different languages | |
CN109284357B (en) | Man-machine conversation method, device, electronic equipment and computer readable medium | |
CN102272754B (en) | Custom language models | |
JP4838529B2 (en) | Enhanced clustering of multi-type data objects for search term proposal | |
WO2020147594A1 (en) | Method, system, and device for obtaining expression of relationship between entities, and advertisement retrieval system | |
JP2021166109A (en) | Fusion sorting model training method and device, search sorting method and device, electronic device, storage medium, and program | |
US8359326B1 (en) | Contextual n-gram analysis | |
CN110704739A (en) | Resource recommendation method and device and computer storage medium | |
US20110125791A1 (en) | Query classification using search result tag ratios | |
CN101297291A (en) | Suggesting and refining user input based on original user input | |
CN110110225B (en) | Online education recommendation model based on user behavior data analysis and construction method | |
CN103593353A (en) | Information search method and display information sorting weight value determination method and device | |
WO2013066929A1 (en) | Method and apparatus of ranking search results, and search method and apparatus | |
US11423018B1 (en) | Multivariate analysis replica intelligent ambience evolving system | |
US20120233096A1 (en) | Optimizing an index of web documents | |
JP7451747B2 (en) | Methods, devices, equipment and computer readable storage media for searching content | |
US11809506B1 (en) | Multivariant analyzing replicating intelligent ambience evolving system | |
CN111597413B (en) | Information pushing method, system, equipment and storage medium | |
Xiong et al. | DNCP: An attention-based deep learning approach enhanced with attractiveness and timeliness of News for online news click prediction | |
CN110110220A (en) | Merge the recommended models of social networks and user's evaluation | |
CN109977292B (en) | Search method, search device, computing equipment and computer-readable storage medium | |
RU2744028C2 (en) | Method and system for storing multiple documents | |
US20220019902A1 (en) | Methods and systems for training a decision-tree based machine learning algorithm (mla) | |
Setia et al. | HPM: a hybrid model for user’s behavior prediction based on N-gram parsing and access logs |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:NEVEITT, WILLIAM T.;GASSER, RALPH U.;REEL/FRAME:022132/0970Effective date: 20090120 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0405Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |