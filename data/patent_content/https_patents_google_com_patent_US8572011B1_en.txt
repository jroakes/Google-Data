US8572011B1 - Outcome estimation models trained using regression and ranking techniques - Google Patents
Outcome estimation models trained using regression and ranking techniques Download PDFInfo
- Publication number
- US8572011B1 US8572011B1 US12/837,890 US83789010A US8572011B1 US 8572011 B1 US8572011 B1 US 8572011B1 US 83789010 A US83789010 A US 83789010A US 8572011 B1 US8572011 B1 US 8572011B1
- Authority
- US
- United States
- Prior art keywords
- outcome
- data
- record
- pair
- feature
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
- G06N20/10—Machine learning using kernel methods, e.g. support vector machines [SVM]
Definitions
- This specification relates to data processing such as data mining and outcome estimation.
- the performance of content items are often tracked by a system that manages the content items.
- an advertisement server may track the performance of advertisements it serves by recording the number of impressions the advertisement receives, and the number of clicks on the advertisements.
- Such performance data can be processed to generate predictive models that can predict the performance of the same or similar content items in future situations.
- Data mining is one such example process.
- Data mining is used, for example, to identify feature values that are associated with a data set of content items and that are indicative of a particular result.
- a feature value is a value that represents a state or measurement of a feature.
- Feature values are often used to represent characteristics of content items (e.g., advertisements, audio, video, or text).
- feature values can be values that represent specific colors, animation characteristics, size characteristics, similarity measures, and other features of content items.
- Feature values can be selected from a specified set of discrete values (e.g., 0 or 1) or feature values can be selected from a continuous range of values (e.g., 0-10).
- a feature value of 0 (representing “no”) or 1 (representing “yes”) can be used to specify whether an advertisement is a static advertisement (i.e., is not animated).
- a set of feature values can be used to specify one or more colors (e.g., 00 representing black and 01 representing yellow) that are included in an advertisement.
- the identified feature values for the data set and results (e.g., performance data) associated with the data set can be used to create and train a model that predicts future outcomes or results for a content item represented by a data record storing feature values that describe the content item.
- curve fitting techniques e.g., regression analysis, logistic regression, etc.
- the model can be applied to feature values of a data record to obtain an outcome or result based on the feature values of the data record.
- Data classifiers e.g., support vector machines
- the quality of models generated using different modeling techniques is generally judged using different measures of prediction quality (e.g., accuracy measures and/or error measures).
- regression techniques may use a measure such as Mean Square Error to measure how accurately a regression model is estimating outcome values
- a ranking model e.g., a support vector machine
- ROC receiver operating characteristic
- one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of training an outcome estimation model using both regression error measures and ranking error measures, the regression error measures specifying error measures associated with training outcomes for respective data records, the ranking error measures specifying error measures associated with training outcomes for respective record pairs, each data record being a data record from a data set of data records, and each record pair being a pair of data records from the data set; receiving a request for one or more content items; computing a predicted outcome using the outcome estimation model and feature values associated with the content item in response to the request and for each content item in a set of content items; computing selection scores for the content items using the predicted outcome; selecting one or more content items based on the selection scores; and providing data that cause presentation of the one or more content items at a client device.
- Other embodiments of this aspect include corresponding systems, apparatus, and computer programs, configured to perform the actions of the methods, encoded on computer storage devices.
- Training the outcome estimation model includes initializing feature weights of the outcome estimation model, each feature weight representing a relative importance of a feature value for predicting an outcome; selecting, as training data with which the feature weights are to be updated, one of a data record and a record pair, each data record being associated with a set of feature values and a reference outcome, the data record being selected with a first probability and the record pair being selected with a second probability; updating the feature weights of the outcome estimation model using the selected training data; determining whether a stop condition has been met; in response to determining that the stop condition has not been met, repeating the selecting, the updating, and the determining; and in response to determining that the stop condition has been met, determining that the outcome estimation model is trained.
- Selecting one of a data record and a record pair includes generating a semi-random value; selecting the data record in response to the semi-random value being a value that is included in a data record value set; and selecting the record pair in response to the semi-random value being a value that is included in a record pair value set.
- Methods can include selecting a record-pair threshold specifying a value that defines the data record value set and the record pair value set. Selecting a record-pair threshold can include initializing the record-pair threshold to a test value for a pre-specified quantity of outcome estimation models; generating a predicted outcome using a data record for the pre-specified quantity of outcome estimation models; computing, for the pre-specified quantity of outcome estimation models, a loss measure using the predicted outcome and a reference outcome for the data record, the loss measure being a value representing a cost of error; and selecting, as a final value for the record-pair threshold, the test value that is associated with a lowest loss measure.
- Updating the feature weights of the outcome estimation model includes adjusting the feature weights using a stochastic gradient step that is computed using a learning rate factor, feature values of the training data, the reference outcome for the training data, and current feature weights of the outcome estimation model. Determining whether the stop condition has been met includes determining whether a pre-specified quantity of feature weight updates have occurred.
- Selecting a record pair includes selecting, from an index in which data records are indexed according to reference outcome, a first data record that is indexed according to a first outcome; selecting, from the index, a second data record that is indexed according to a second outcome.
- Updating the feature weights includes computing pair feature values for the record pair, the set of pair features being based on a mathematical difference between feature values for the first data record and feature values for the second data record; computing a pair outcome for the record pair, the pair outcome being based on a mathematical difference between the reference outcome for the first data record and the reference outcome for the second data record; and adjusting the feature weights using a stochastic gradient step that is computed using a learning rate factor, the pair feature values, the pair outcome, and current feature weights of the outcome estimation model.
- Receiving a request for content items includes receiving a request for advertisements to be placed in advertisement slots that are ranked according to a prominence measure.
- Computing a predicted outcome includes computing a click-through likelihood for each eligible advertisement that is available to be provided in response to the request.
- Computing selection scores includes computing, as a selection score for each eligible advertisement, a result of a function of the click-through likelihood and a bid that is associated with the eligible advertisement.
- Selecting, using the selection scores, one or more content items includes selecting a quantity of advertisements to service the request, each of the selected advertisements having a selection score that exceed a selection threshold.
- Providing data that cause presentation of the one or more content items includes providing data that cause presentation of the selected advertisements in the ranked advertisement slots according to the selection scores.
- Training the outcome estimation model includes training a non-linear outcome estimation model using a kernel technique.
- Training the non-linear outcome estimation model includes selecting a set of reference data records from the data set; selecting a data record from the data set; computing relative feature values for the data record, the relative feature values being computed using feature values for the reference data records and feature values for the data record; computing a training outcome using the relative feature values for the data record and the non-linear outcome estimation model; updating feature weights for the non-linear prediction model using the training outcome; selecting a record pair from the data set; computing relative pair values for the record pair, the relative pair values being computed using pair feature values for the record pair and feature values for the set of reference data records; computing a pair outcome using the relative pair values for the record pair and the updated feature weights; and updating the updated feature weights for the non-linear outcome estimation model using the pair outcome.
- Updating the feature weights includes computing a stochastic gradient step.
- another aspect of the subject matter described in this specification can be embodied in methods that include the actions of receiving a request for content items; selecting a set of eligible content items responsive to the request; receiving feature values for each content item in the set of eligible content items; computing, for each content item in the set of eligible content items, an estimated click-through likelihood using the feature values of the content item and an outcome estimation model that has been trained using regression-based training and ranking-based training; computing, for each content item in the set of eligible content items, a selection score for the content item; selecting, from the set of eligible content items, one or more content items having a selection score that exceeds a selection threshold; providing data that cause presentation of the selected one or more content items at a user device.
- a data processing apparatus can more accurately compute outcome estimations using a model that has been generated using both regression criteria and ranking criteria than using a model that has been generated using only one of the criteria.
- a data processing apparatus can more quickly generate a model using an indexed data set from which pairs of data records can be selected according to indexing attributes rather than determining every possible pair of data records available.
- FIG. 1 is a block diagram of an example environment in which an advertisement management system manages advertising services.
- FIG. 2 is an example process for training an outcome estimation model using both regression-based training and ranking-based training.
- FIG. 3 is an example process for training a non-linear outcome estimation model using both regression-based training and ranking-based training.
- FIG. 4 is a flow chart of an example process for using an outcome estimation model to select content items for presentation in response to a content item request.
- FIG. 5 is block diagram of an example computer system that can be used to train and/or utilize outcome estimation models, as described above.
- Outcome estimation is performed using feature values associated with a data record and an outcome estimation model that has been trained by adjusting the model based on regression-based training techniques (“regression-based training”) that train the model using ranking-based measures of prediction quality (e.g., accuracy or other measures) and ranking-based training techniques (“ranking-based training”) that train the model using ranking-based measures of prediction quality (e.g., accuracy or other measures).
- the outcome estimation model can be trained using an iterative process that, at each iteration, semi-randomly trains the outcome estimation model using regression-based training with a first likelihood and ranking-based training with a second likelihood.
- the regression-based training or the ranking-based training can be semi-randomly selected, where the semi-random selection is constrained by probability constraints that specify probabilities (i.e., first and second likelihoods) with which each of the training techniques is to be selected.
- the resulting outcome estimation model is trained using both regression-based prediction quality measures and ranking-based prediction quality measures.
- the outcome estimation model can be adjusted based on an analysis of the regression-based prediction quality measures during iterations in which regression-based training is selected.
- the outcome estimation model is adjusted based on an analysis of the ranking-based prediction quality measures during iterations in which ranking-based training is selected.
- the outcome estimation model will provide outcome estimates that meet minimum prediction quality thresholds using both regression-based prediction quality measures and ranking-based prediction quality measures (each threshold can be different).
- the outcome estimation model is a model that estimates a likelihood (e.g., a probability) with which a content item (e.g., an advertisement or search result) will be selected (e.g., clicked) by a user.
- a likelihood e.g., a probability
- this estimated likelihood is used to determine whether a particular advertisement will be selected for presentation with a particular web page and to select a relative position at which the advertisement will be presented on the web page.
- the outcome estimation model estimates that a particular advertisement will be clicked with a probability of 20%.
- the advertisement can be selected for presentation and placement of the advertisement on the web page can also be selected.
- the advertisement is ranked relative to other advertisements based on a selection score that is computed as function of the estimated click probability and a bid that is associated with the advertisement.
- the advertisement is provided for presentation at a particular advertisement position based on this selection score.
- the description that follows describes the outcome estimation model as being generated by a modeling apparatus that is part of an advertisement management system that manages advertising services.
- the modeling apparatus can be implemented independent of the advertisement management system and/or with other systems (e.g., a search system) that use expected outcomes that meet prediction quality thresholds using both regression-based prediction quality measures and rank based prediction quality measures.
- the outcome estimation model described below can be used to compute selection scores that are used to select search results for presentation in a search results page (e.g., using prior user selection data as a measure of relevancy of a search result to search queries), selection scores that are used to select an order in which to organize e-mails (e.g., based on user selection history and feature values associated with the selected e-mails), or selection scores that are used to recommend products or items (e.g., movies) to a user based on the user's previous star ranking of other products or items.
- selection scores that are used to select search results for presentation in a search results page e.g., using prior user selection data as a measure of relevancy of a search result to search queries
- selection scores that are used to select an order in which to organize e-mails e.g., based on user selection history and feature values associated with the selected e-mails
- selection scores that are used to recommend products or items e.g., movies
- FIG. 1 is a block diagram of an example environment 100 in which an advertisement management system 110 manages advertising services.
- the example environment 100 includes a network 102 , such as a local area network (LAN), a wide area network (WAN), the Internet, or a combination thereof.
- the network 102 connects websites 104 , user devices 106 , advertisers 108 , and the advertisement management system 110 .
- the example environment 100 may include many thousands of websites 104 , user devices 106 , and advertisers 108 .
- a website 104 is one or more resources 105 associated with a domain name and hosted by one or more servers.
- An example website is a collection of web pages formatted in hypertext markup language (HTML) that can contain text, images, multimedia content, and programming elements, such as scripts.
- HTML hypertext markup language
- Each website 104 is maintained by a publisher, which is an entity that controls, manages and/or owns the website 104 .
- a resource 105 is any data that can be provided over the network 102 .
- a resource 105 is identified by a resource address that is associated with the resource 105 .
- Resources include HTML pages, word processing documents, and portable document format (PDF) documents, images, video, and feed sources, to name only a few.
- the resources can include content, such as words, phrases, images and sounds, that may include embedded information (such as meta-information in hyperlinks) and/or embedded instructions (such as JavaScript scripts). Units of content that are presented in (or with) resources are referred to as content items.
- a user device 106 is an electronic device that is under control of a user and is capable of requesting and receiving resources over the network 102 .
- Example user devices 106 include personal computers, mobile communication devices, and other devices that can send and receive data over the network 102 .
- a user device 106 typically includes a user application, such as a web browser, to facilitate the sending and receiving of data over the network 102 .
- a user device 106 can request resources 105 from a website 104 .
- data representing the resource 105 can be provided to the user device 106 for presentation by the user device 106 .
- the data representing the resource 105 can also include data specifying a portion of the resource or a portion of a user display (e.g., a presentation location of a pop-up window or in a slot of a web page) in which advertisements can be presented. These specified portions of the resource or user display are referred to as advertisement slots.
- the environment 100 can include a search system 112 that identifies the resources 105 by crawling and indexing the resources 105 provided by the publishers on the websites 104 .
- Data about the resources can be indexed based on the resource 105 to which the data corresponds.
- the indexed and, optionally, cached copies of the resources 105 are stored in a search index 114 .
- User devices 106 can submit search queries 116 to the search system 112 over the network 102 .
- the search system 112 accesses the search index 114 to identify resources that are relevant to the search query 116 .
- the search system 112 identifies the resources in the form of search results 118 and returns the search results 118 to the user devices 106 in search results pages.
- a search result 118 is data generated by the search system 112 that identifies a resource that is responsive to a particular search query, and includes a link to the resource.
- An example search result 118 can include a web page title, a snippet of text or a portion of an image extracted from the web page, and the URL of the web page.
- Search results pages can also include one or more advertisement slots in which advertisements can be presented.
- the advertisement management system 110 receives a request for advertisements to be provided with the resource 105 or search results 118 .
- the request for advertisements can include characteristics of the advertisement slots that are defined for the requested resource or search results page, and can be provided to the advertisement management system 110 .
- a reference e.g., URL
- a size of the advertisement slot e.g., a size of the advertisement slot, and/or media types that are eligible for presentation in the advertisement slot
- keywords associated with a requested resource e.g., source keywords”
- a search query 116 for which search results are requested can also be provided to the advertisement management system 110 to facilitate identification of advertisements that are relevant to the resource or search query 116 .
- the advertisement management system 110 selects advertisements that are eligible to be provided in response to the request (“eligible advertisements”).
- eligible advertisements can include advertisements having characteristics matching the characteristics of advertisement slots and that are identified as relevant to specified resource keywords or search queries 116 .
- advertisements having targeting keywords that match the resource keywords or the search query 116 are selected as eligible advertisements by the advertisement management system 110 .
- a targeting keyword can match a resource keyword or a search query 116 by having the same textual content (“text”) as the resource keyword or search query 116 .
- the relevance can be based on root stemming, semantic matching, and topic matching.
- an advertisement associated with the targeting keyword “hockey” can be an eligible advertisement for an advertisement request including the resource keyword “hockey.”
- the advertisement can be selected as an eligible advertisement for an advertisement request including the search query “hockey.”
- a targeting keyword can also match a resource keyword or a search query 116 by having text that is identified as being relevant to a targeting keyword or search query 116 despite having different text than the targeting keyword.
- an advertisement having the targeting keyword “hockey” may also be selected as an eligible advertisement for an advertisement request including a resource keyword or search query for “sports” because hockey is a type of sport, and therefore, is likely to be relevant to the term “sports.”
- Targeting keywords and other data associated with the distribution of advertisements can be stored in an advertising data store 119 a .
- the advertising data store 119 a is a data store that stores data representing the advertisements, such as an advertisement identifier (e.g., Ad 1 . . . Adi) and feature values (FV 1 . . . FVn) that are associated with each respective advertisement.
- the advertising data store can also store associations between advertisements, advertising campaign parameters that are used to control distribution of the advertisements.
- the advertising data store 119 can store targeting keywords, bids, and other criteria with which each respective advertisement can be selected for presentation.
- Data representing conditions under which advertisements were selected for presentation to a user, and user interaction data (Id 1 . . . Idn) representing actions taken by users in response to presentation of the advertisement (e.g., Ad 1 . . . Adi) can be stored in a data store such as performance data store 119 b.
- the performance data store 119 b can store data specifying targeting keywords that caused presentation of the advertisement (e.g., that matched a resource keyword or search query), resource keywords and/or search queries that matched the targeting keywords, ad slots in which the advertisement appeared, characteristics (e.g., locations and sizes) of the ad slots, and any special features that might have been applied to the advertisement.
- Example features that can be applied to an advertisement include the advertisement being presented with an image, the advertisement being presented with (e.g., adjacent to) multiple links (e.g., hypertext links) to different landing pages for the advertiser, or the advertisement being provided with a link that, in response to selection of the link, causes the advertisement to expand and revealing additional information associated with the advertisement (e.g., revealing a map, presenting a video clip, or providing product purchasing information).
- links e.g., hypertext links
- the performance data store 119 b can also store user interaction data specifying user interactions with presented advertisements (or other content items). For example, when an advertisement is presented to the user, data can be stored in the performance data store 119 b representing the advertisement impression.
- selection data is stored in the performance data store 119 b representing the user selection of the advertisement.
- the selection data is stored in response to a request for a web page that is linked to by the advertisement.
- the user selection of the advertisement can initiate a request for presentation of a web page that is provided by (or for) the advertiser.
- the request can include data identifying the particular cookie for the user device, and this data can be stored in the performance data store 119 b .
- data indicating that an advertisement was not selected when it was presented can also be stored in the performance data store 119 b.
- the advertisement management system 110 typically selects the advertisements that are provided for presentation in advertisement slots of a resource or search results page based on results of an auction. For example, the advertisement management system 110 can receive bids for advertisements and allocate the advertisement slots to the advertisements with the highest selection scores at the conclusion of the auction.
- the bids are amounts (e.g., maximum prices) that the advertisers will pay for presentation (or selection) of their advertisement with a resource or search results page.
- a bid can specify an amount that an advertiser will to pay for each 1000 impressions (i.e., presentations) of the advertisement, referred to as a CPM bid.
- the bid can specify an amount that the advertiser is will pay for user selection (i.e., a click-through) of the advertisement or a “conversion” (e.g., when a user performs a particular action related to an advertisement provided with a resource or search results page) following selection of the advertisement.
- a selection score is a value based, in part, on a bid and from which advertisements are selected for presentation. Each selection score can represent a bid value, or a product (or another function) of the bid value and one or more factors. In some implementations, the selection score is a product of the bid specified by the advertiser and an estimated click-through likelihood (eCTL) associated with the advertisement, which can also be referred to as an estimated click-through rate.
- eCTL estimated click-through likelihood
- advertiser A selects a $1.00 cost per click bid (“CPC” bid) and advertiser A's advertisement is associated with an eCTL of 0.5
- advertiser B selects a $0.80 CPC bid and advertiser B's advertisement is associated with an eCTL of 0.9
- Advertiser A will have a selection score of 0.5
- advertiser B will have an auction score of 0.72.
- advertiser B will be the auction winner in this example, even though advertiser A submitted the higher CPC bid.
- the advertisement that is associated with a higher eCTL will be selected for presentation ahead of the advertisement that is associated with a lower eCTL, assuming that the two advertisements are associated with a same bid.
- the advertisement that is associated with a higher bid will be selected for presentation over the advertisement that is associated with the lower bid.
- An eCTL is a value that specifies a likelihood (e.g., a probability) that an advertisement (or another content item) is selected by a user in response to a particular presentation of the advertisement (or other content item). For example, an eCTL of 0.30 for a particular advertisement can specify that there is a 30% likelihood that the particular advertisement will be selected by a user if presented.
- An outcome estimation model is a model with which an eCTL value is computed for a content item using, at least in part, feature values describing the features of the content item.
- the feature values used to compute an eCTL can include, for example, values specifying content item color, size, whether the content item is animated, and other aspects of the content item's appearance as well as targeting criteria (e.g., targeting keywords, demographic targeting criteria, and/or geographic targeting criteria) for the content item and measures of similarity between the feature values of the content item and selection criteria specified in a request for content items (e.g., a cosine similarity measure of match between a targeting keyword and a search query).
- the feature values for each content item can be represented in a data record as a vector of values, where each value of the vector specifies a value for a particular feature.
- the outcome estimation model can be a vector of feature weights, where each feature weight is a value representing a relative importance of the feature value for predicting an outcome (e.g., an eCTL).
- a higher feature weight is indicative of a feature for which the value is more important for determining an eCTL than a feature that is associated with a lower feature weight.
- a feature associated with a feature weight of 0.6 may be considered more important than a feature that is associated with a feature weight of 0.3.
- the estimated outcome (e.g., eCTL) is computed as a dot product of the vector of feature weights for the outcome estimation model and the vector of feature values that represent the content item.
- the estimated outcome can be another function of the feature weights and the feature values.
- Outcome estimation models can be stored, for example, in a model data store 119 c for use by the advertisement management system 110 and/or another data processing apparatus.
- the advertisement management system 110 can identify selection criteria (e.g., a search query, resource keyword, size restrictions, and other criteria). Using the selection criteria, the advertisement management system 110 selects a set of eligible advertisements that are responsive to the request. In turn, the advertisement management system 110 obtains an eCTL that is computed using an outcome estimation model for each of the eligible advertisements.
- the advertisement management system 110 provides advertisement identifiers specifying the eligible advertisements to a data processing apparatus that computes eCTL values for the eligible advertisements. Using the advertisement identifiers, the data processing apparatus retrieves feature values for each of the eligible advertisements (e.g., from the advertising data store 119 a ), computes the eCTL for each advertisement using the feature values and an outcome estimation model, and provides the eCTL values to the advertisement management system 110 . In other implementations, the advertisement management system 110 inputs the feature values of the eligible advertisements into the outcome estimation model and receives, as output, an eCTL for each of the advertisements.
- the environment 100 includes a modeling apparatus 120 that facilitates creation (i.e., training) of outcome estimation models.
- Outcome estimation models are created through an iterative process by which an initial model is applied to data records (or data record pairs) from a data set to compute outcomes (i.e., results) for the data records.
- Data records represent characteristics associated with actual outcomes.
- each data record can include data that represent visual characteristics of an advertisement (i.e., feature values), a presentation position of the advertisement for a particular presentation, and also include user interaction data (e.g., ID1) specifying whether the advertisements were clicked by a user (i.e., the outcome) in response to the particular presentation.
- ID1 user interaction data
- Outcomes that are predicted by an outcome estimation model are compared to the actual outcomes (i.e., data specifying whether an advertisement was clicked by a user) that are associated with the data records, and a measure of error (e.g., a loss measure) is computed and used to adjust the initial model.
- the adjusted model is then used to compute outcomes for additional data records (or data record pairs), and the model is again adjusted based on measures of error.
- the training process iteratively continues until a stop condition (e.g., a pre-specified quantity of iterations) is met.
- Outcome estimation models are generally created using a single modeling technique.
- a particular outcome estimation model can be created using either regression-based training, classification-based training, or ranking-based training.
- a single training technique is used to create (i.e., train) an outcome estimation model, it is possible that the outcome computed by the outcome estimation model meets a minimum prediction quality threshold for the training technique that was used to create the model, but does not meet minimum prediction quality thresholds for other training techniques.
- the ranking model can be trained to compute values that increase the likelihood that data records are more accurately ranked (relative to other data records) using values output by the ranking model, but the absolute values output by the ranking model may not be as accurate when measured according to regression-based measures of prediction quality, which emphasize how close the estimated value is to an actual observed value (i.e., a reference outcome).
- the modeling apparatus 120 is a data processing apparatus that creates an outcome estimation model using two or more training techniques.
- the modeling apparatus 120 is configured to use both regression-based training and ranking-based training.
- the modeling apparatus 120 determines, for each iteration of the training process, whether to use regression-based training or ranking-based training to train the model. For example, at each iteration, the modeling apparatus 120 can semi-randomly select one of the ranking-based training or the regression-based training to train the model.
- the modeling apparatus trains the model using the selected training method, as described in more detail with reference to FIG. 2 .
- both regression measures of prediction quality and ranking measures of prediction quality are used to adjust feature weights of the model.
- the resulting model will be trained to provide estimated outcomes that meet minimum regression prediction quality thresholds and minimum ranking prediction quality thresholds.
- FIG. 2 is an example process 200 for training an outcome estimation model using both regression-based training and ranking-based training.
- the process 200 is a process by which feature weights of an outcome estimation model are initialized and one of a data record or a record pair is selected as training data.
- the feature values of the outcome estimation model are updated using regression training.
- the feature weights of the outcome estimation model are updated using ranking training.
- the process 200 is described below with reference training an outcome estimation model that estimates an eCTL value for advertisements that are distributed in an online environment.
- the process 200 can also be used to train an outcome estimation model to estimate other values for other content items (e.g., video, audio, game, or other content items), where the accuracy of absolute and relative values of the outcome are important.
- the process 200 can be implemented, for example, using the modeling apparatus 120 and/or advertisement management system 110 of FIG. 1 .
- the process 200 can also be implemented as instructions stored on computer storage medium such that execution of the instructions by data processing apparatus cause the data processing apparatus to perform the operations of the process 200 .
- Feature weights for an outcome estimation model are initialized ( 202 ).
- an outcome estimation model can be implemented as a vector of feature weights where each feature weight represents a relative importance of a feature for estimating an outcome.
- the feature weights are initialized by setting the feature weights to default values.
- Each feature weight can be set to a same default value (e.g., 1.0), or the default value for each feature weight can be independently set.
- One of a data record or a record pair is selected as training data with which the feature weights of the outcome estimation model are to be updated ( 204 ).
- selection of either a data record or a record pair is performed on a semi-random basis.
- a semi-random number can be received from a random number generator.
- the semi-random number can be compared to a data record value set and/or a record pair value set, and one of the data record or the record pair can be selected based on the comparison.
- the semi-random number can be compared to a threshold value and a data record can selected when the semi-random number is less than the threshold value, while a record pair can be selected when the semi-random number is greater than the threshold value.
- a data record value set is a set of values that are associated with selection of a data record. For example, when the semi-random number has a value that is included in the data record value set, a data record can be selected from the set of data records.
- the record pair value set is set of values that are associated with selection of a record pair. For example, when the semi-random number has a value that is included in the record pair value set, a record pair can be selected from the set of data records.
- the data record value set and the record pair value set are defined by a threshold value (i.e., a record-pair threshold).
- the threshold value can selected to impose a probability constraint on the semi-random selection of the data record and the record pair. For example, assume that the random number generator generates values between 1 and 10. In this example, if the threshold value is selected to be 5.1, when the semi-random number is an integer between 1 and 5, a record pair can be selected and when the semi-random number is an integer between 6 and 10, an individual data record can be selected. Thus, selecting a threshold value of 5.1 imposes a probability constraint that each of the record pair and the data record be selected with a 50% probability.
- the probability constraint can be adjusted by adjusting the threshold value. For example, if the threshold value is set to 6.1, a record pair will be selected with a 60% probability, while a data record will be selected with a 40% probability.
- the threshold value can be set equal to (or computed based on) a value that provides a minimum aggregate error (i.e., a minimum aggregate loss measure) for models.
- the threshold value can be a value a that minimizes the aggregate loss as computed according to relationship (1), where the aggregate loss is a loss measure that is aggregated over a plurality of models.
- a loss measure is a value representing a cost per unit error:
- ⁇ is the threshold value
- L(w,D) is a measure of regression loss for the model (w) using a data record (D) as the input;
- L(w,P) is a measure of ranking loss for the model (w) using a record pair (P) as the input;
- ⁇ is constant that limits training aggressiveness (i.e., a magnitude of model adjustment for each iteration of training).
- ⁇ w ⁇ 2 2 is the Euclidean norm of the model.
- y c is an estimated outcome value computed using the model (w) and feature values of the data record (D);
- y r is the actual value associated with the data record.
- the measure of ranking loss L(w,P) can be computed, for example, using a logistic loss measure such as that specified by relationship (3).
- l ( p r ,p c ) p r log( p c )+(1 ⁇ p r )log(1 ⁇ p c ) (3)
- p c is an estimated pair outcome value computed using pair feature values for a record pair (e.g., a mathematical difference between feature values for two data records);
- pair outcome value associated with the record pair (P) e.g., a mathematical difference between two reference outcome values (y r1 , y r2 ) that are respectively associated with the data records (D 1 , D 2 ) of the record pair).
- a value that minimizes the aggregate loss of relationship (1) can be selected, for example, by selecting a pre-specified quantity of models (e.g., 10 models) and a set of test threshold values (e.g., 10 test values).
- Each model/test value pair can be used to compute an aggregate loss according to relationship (1) using a set of data records (i.e., training records).
- the test value that is associated with a lowest aggregate loss can be selected as the record-pair threshold value ⁇ .
- the record-pair threshold value ⁇ it can be used to select, for each iteration, whether the model will be trained using a data record (regression training) or a record pair (ranking training).
- selection of an individual data record is performed by semi-randomly selecting a data record from an index of data records.
- the index of data records can be stored, for example in the model data store 119 c of FIG. 1 .
- the index of data records can be, for example, an index in which data records are indexed according to reference outcomes (i.e., outcome values) that are associated with the data records. For example, when the data records represent advertisements, the reference outcomes can represent whether the advertisement was selected in response to being presented. A value of 1 can specify that the advertisement was selected in response to being presented, while a value of 0 can specify that the advertisement was not selected in response to being presented.
- the index of data records is described in more detail below.
- Selection of a record pair can be performed by semi-randomly selecting from the index, one data record that is associated with a particular outcome and a second data record that is associated with a different outcome.
- one data record can be semi-randomly selected from the set of data records that are indexed according to a value (e.g., 1) specifying that the advertisement was clicked in response to presentation, while the other data record can be semi-randomly selected from the set of data records that are indexed according to a value (e.g., 0) specifying that the advertisement was not clicked in response to presentation.
- the feature weights are updated using regression training ( 206 ).
- the feature weights are updated by adjusting the feature weights using a stochastic gradient step that is computed using a learning rate factor, feature values of the data record, the reference outcome for the data record, and current feature weights of the outcome estimation model.
- the actual instantiation of the stochastic gradient step will depend on the loss function used to compute loss associated with the model. For example, when a squared loss function (e.g., relationship (2)), is used to compute loss measures for the model, the stochastic gradient step function used to adjust the feature weights is represented by relationship (4).
- w i (1 ⁇ i ⁇ ) w i-1 + ⁇ i x ( y r ⁇ ( w i-1 ,x )) (4)
- w i is the model (w) with feature weights that have been updated using a stochastic gradient step function
- ⁇ i is a learning rate for the model (e.g., 1/ ⁇ , c/c+i, or c, where c is a constant);
- ⁇ is constant that limits training aggressiveness, as described above;
- w i-1 is the model (w) as of the end of the previous iteration
- x is a vector of feature values associated with the selected data record
- y r is the reference outcome associated with the data record (x).
- Relationship (4) can be used to adjust feature weights of the outcome estimation model for each iteration in which regression training is used to train the model (i.e., each iteration in which a data record was selected to train the model).
- a record pair is selected to train the outcome estimation model.
- the feature weights are updated using ranking training ( 208 ).
- Pair feature values are feature values that represent the record pair.
- the pair feature values are computed as a mathematical (e.g., feature by feature) mathematical difference between the feature values of the data records in the record pair.
- the pair feature values for a pair of data records representing advertisements can be a mathematical difference between the feature values for a data record represents an advertisement that was clicked in response to presentation and the feature values for a data record that represents an advertisement that was not clicked in response to presentation.
- a pair outcome is a value that represents an aggregate outcome for the data records of the record pair.
- the pair outcome is computed as a mathematical difference between the reference outcomes that are respectively associated with the data records in the record pair.
- the reference outcome associated with the advertisement that was clicked can have a value of 1.0
- the reference outcome associated with advertisement that was not clicked can have a value of 0.0.
- the pair outcome is computed to be 1.0 (i.e., 1.0-0.0) or ⁇ 1.0 (i.e., 0.0-1.0).
- the pair feature values, pair outcome, a learning rate factor, and current feature weights of the outcome estimation model can be used to adjust the model feature weights according to a stochastic gradient step, for example, as represented by relationship (5).
- w i is the model (w) with feature weights that have been updated using a stochastic gradient step function
- ⁇ i is a learning rate for the model (e.g., 1/ ⁇ , c/c+i, or c, where c is a constant);
- ⁇ is constant that limits training aggressiveness, as described above;
- w i-1 is the model (w) as of the end of the previous iteration
- x p is a vector representing the pair feature values
- y p is the pair outcome associated with the pair feature values (x p ).
- Relationship (5) can be used to adjust feature weights of the outcome estimation model for each iteration in which ranking training is used to train the model (i.e., each iteration in which a record pair was selected to train the model).
- the stop condition is completion of a pre-specified number of training iterations (i.e., a pre-specified quantity of feature weight updates have been completed).
- the stop condition can be set to a value representing completion of N iterations, where N is a finite positive integer.
- a counter can be incremented upon completion of each iteration (i.e., each feature weight update) and the stop condition can be determined to be met when the counter has a value of N.
- the stop condition is specified as a magnitude of a gradient step with which the model is adjusted.
- a threshold gradient step magnitude can be specified and when a gradient step used to adjust the model is less than the threshold gradient step, it can be determined that the stop condition has been met.
- one of a data record or a record pair are selected ( 204 ), such that the updating ( 206 ), and the determining ( 208 ) are repeated.
- the outcome estimation model is trained ( 212 ). Trained outcome estimation models can be made available for predicting outcomes. For example, a trained outcome estimation model can be used to compute an eCTL, which can be used to select advertisements for presentation and relative presentation positions for the selected advertisements.
- the process 200 can be used to create linear outcome estimation models.
- non-linear outcome estimation models can be created using a process similar to that described above.
- FIG. 3 is an example process 300 for training a non-linear outcome estimation model using both regression-based training and ranking-based training.
- the process 300 is a process by which a set of reference data records are selected from a data set and a selection is made between using regression training or ranking training to update feature weights of an outcome estimation model.
- regression training is selected, a data record is selected from the data set, and relative feature values are computed for the data record.
- the feature weights are updated based on the training outcome using the relative feature values.
- ranking training is selected, a record pair is selected from the data set and relative pair values are computed for the record pair.
- the feature weights for the non-linear prediction model are updated using the relative pair values.
- the process 300 iteratively repeats until a stop condition has occurred (i.e., the stop condition has been met).
- the process 300 is described below with reference to selecting advertisements that are distributed in an online environment.
- the process 300 can also be used to facilitate selection of other content items (e.g., search results, video, audio, game, or other content items).
- the process 300 can be implemented, for example, using the modeling apparatus 120 and/or advertisement management system 110 of FIG. 1 .
- the process 300 can also be implemented as instructions stored on computer storage medium such that execution of the instructions by data processing apparatus cause the data processing apparatus to perform the operations of the process 300 .
- a set of reference data records (“reference set”) is selected from a data set ( 302 ).
- the reference data records are a representative set of data records from the data set.
- the reference set can be selected such that the feature values for the reference data records each represent a set of data records in the data set.
- advertisements that are animated can be represented by one or more data records that are included in the reference set and are associated with an animation feature value of 1.0
- advertisements that are not animated can be represented by one or more data records that are included in the reference set and are associated with an animation feature value of 0.0.
- the reference data records can be selected so that a uniform distribution of data records represents each feature value and/or combination of feature values.
- a selection between regression training and ranking training is made ( 304 ).
- the selection between regression training and ranking training can be made in a manner similar to that described with reference to FIG. 2 .
- a semi-random number can be used to determine whether regression or ranking training will be used for the current training iteration.
- a data record is selected from the data set ( 306 ).
- the data record can be semi-randomly selected in a manner similar to that described with reference to FIG. 2 .
- Relative feature values are computed for the data record ( 308 ).
- relative feature values are compute for the data record using the feature values of the selected data record and the feature values for the data records for the reference data records.
- the selected data record can be separately compared to each of the reference data records and a measure of similarity between the selected data record and the reference data record can be computed.
- each measure of similarity can be defined as a relative feature value for the selected data record, such that the relative feature values for the data record are a vector of the measures of similarity.
- each of these 100 measures of similarity can be defined as one relative feature value in a vector of 100 relative feature values that represent the data record. This vector of 100 relative feature values can then be used to train the outcome estimation model as described below.
- each measure of similarity can be computed as dot a product of the feature value vector for the data record and the feature value vector for a reference data record.
- each measure of similarity can be a Euclidean distance or a cosine similarity that is computed using the feature values of the selected data record and a reference data record.
- Using a similarity measure to transform feature values of a data record to relative feature values is one type of a kernel technique that can be used. Other kernel techniques can also be used.
- Feature weights for the non-linear outcome estimation model are updated using the relative feature values ( 310 ).
- the feature weights can be updated, for example, using relationship (4) above, by using the vector of relative feature values as the vector feature values associated with the selected data record (x).
- the determination can be made in a manner similar to that described above with reference to FIG. 2 .
- the stop condition can be determined to have occurred after a pre-specified quantity of training iterations have completed, or when the magnitude of the feature weight adjustments are less than a pre-specified magnitude.
- the process 300 ends ( 314 ). In response to determining that the stop condition has not occurred, another selection between regression training and ranking training is made ( 304 ).
- a record pair is selected from the data set ( 316 ).
- the record pair can be selected in a manner similar to that described with reference to FIG. 2 .
- one data record can be selected from a set of data records that have been indexed according to a click value of 1.0 (i.e., specifying that the advertisement was clicked in response to presentation), while the other data record can be selected from a set of data records that have been indexed according to a click value of 0.0 (i.e., specifying that the advertisement was not clicked in response to presentation).
- the data records are also indexed according to a query (or reference keyword) for which the advertisement (or other content item) represented by the data record was provided. For example, assume that a set of 1,000,000 advertisements have been provided for presentation on a search results page in response to the query “soccer,” and that 400,000 of these advertisements were clicked by a user, while 600,000 of these advertisements were not clicked by a user. Additionally, assume that 2,000,000 advertisements were provided for presentation in response to the search query “football,” with 1,200,000 of these advertisements being clicked, and 800,000 not being clicked.
- data records representing the instances that the advertisements that were presented in response to the query “soccer,” can be indexed according to the query term “soccer,” and the advertisements that were presented in response to the query “football,” can be indexed according to the query “football.”
- each data record can be indexed at multiple levels (e.g., based on query value and click values).
- record pairs that are indexed according each particular query are selected in proportion to a number of record pairs that are available for the query. Continuing with the example above, 400,000 record pairs can be selected for the query “soccer” without replacement of selected data records, and 800,000 record pairs can be selected for the query “football” without replacement of selected data records.
- query pairs from the “soccer” index can be semi-randomly selected with a probability of 0.333 (i.e., 400,000 soccer pairs/1,200,000 total pairs), while query pairs from the “football” index can be semi-randomly selected with a probability of 0.667 (i.e., 800,000 football pairs/1,200,000 total pairs).
- indexing and weighting techniques can be used to index advertisements according to an order in which the advertisements were clicked by the user and adjust the value of the click based on the order in which the advertisements were clicked.
- each of the advertisements can be indexed according to its click order (e.g., 1 st , 2 nd , or 3 rd ) and the values of these clicks can be weighted to specify a significance of the click as a measure of relevance of the advertisement to the query “football.”
- the value of a first click can have a weight of 1.0
- the value of the second and third clicks can have weights of 0.50, and 0.25 respectively.
- the relative weights of the clicks indicate that the first click is assumed to be the most significant click for determining whether can advertisement was relevant to the search query and therefore will contribute more (based on the higher weight) to the training of the model, while subsequent clicks (e.g., the 2 nd and the 3 rd clicks) are assumed to be less significant for determining whether the advertisement is relevant to the search query, and therefore will contribute less (based on their respective weights).
- relative pair values are computed for the record pair ( 318 ).
- the relative pair values are computed using pair feature values for the record pair and feature values for the set of reference data records.
- the pair feature values for the record pair can be computed as described with reference to FIG. 2 .
- the pair feature values can be a vector of values that result from computation of a mathematical difference between the respective feature value vectors for the data records of the record pair.
- the relative pair values can be computed in a manner similar to that described with reference to step 308 .
- a measure of similarity can be computed between the pair feature values and the feature values for each reference data record.
- a vector of the measures of similarity can be defined as the relative pair values for the record pair.
- Feature weights for the non-linear outcome estimation model are updated using the relative pair values ( 320 ).
- the feature weights for the non-linear outcome estimation model are updated by using the vector of relative pair values as the vector representing the pair feature values (x p ).
- the outcome estimation model is stored in a data store (e.g., model data store 119 c of FIG. 1 ) from which the outcome estimation model can be accessed and/or used.
- a data store e.g., model data store 119 c of FIG. 1
- FIG. 4 is a flow chart of an example process 400 for using an outcome estimation model to select content items for presentation in response to a content item request.
- the process 400 is a process by which a request for content items is received and a set of eligible content items responsive to the request is selected. Feature values that are associated with the selected content items are received, and an estimated click-through likelihood (eCTL) is computed for each content item using the feature values that are associated with the content item and an outcome estimation model. A selection score is computed for each content item using the eCTL and one or more of the content items are selected for presentation based on the selection scores. In turn, data are provided that cause presentation of the selected content items at a user device.
- eCTL estimated click-through likelihood
- the process 400 is described below with reference to selecting advertisements that are distributed in an online environment.
- the process 400 can also be used to facilitate selection of other content items (e.g., search results, video, audio, game, or other content items).
- the process 400 can be implemented, for example, using the modeling apparatus 120 and/or advertisement management system 110 of FIG. 1 .
- the process 400 can also be implemented as instructions stored on computer storage medium such that execution of the instructions by data processing apparatus cause the data processing apparatus to perform the operations of the process 400 .
- a request for content items is received ( 402 ).
- the request for content items is received in response to submission of a search query by a user device.
- the request for content items is received in response to a request for presentation of a web page at a user device (e.g., selection (or entering) of a URL by a user).
- the request for content items can include selection criteria that specify attributes to be used for selecting content items responsive to the request. For example, a request can specify one or more of demographics, location, and/or other information about a user that is associated with the user device from which the request was received.
- the request can specify one or more content item restrictions that can be used to specify content items that are restricted from presentation. For example, a content item restriction can specify that content items (e.g., advertisements) associated with competitors of the publisher of the web page with which the content items will be presented are not eligible for presentation with the web page.
- a set of eligible content items that are responsive to the request are selected ( 404 ).
- the set of eligible content items includes content items that match (e.g., have at least a minimum pre-specified measure of similarity with) the search query (or resource keyword) associated with the request as well as selection criteria. Additionally, the set of eligible content items can be limited to content items that do not violate the content item restrictions specified by the request.
- Feature values for each eligible content item are received ( 406 ).
- the feature values represent characteristics of the content items (e.g., colors, whether the content item is animated, whether the content item includes audio, whether the content item includes video, and/or whether the content item includes a script).
- the feature values are received from a data store that stores feature values for advertisements, such as the advertising data store 119 a of FIG. 1 .
- An estimated click-through likelihood is computed for each eligible content item using the feature values for the eligible content item and an outcome estimation model ( 408 ).
- the outcome estimation model is trained in a manner similar to that described with reference to FIG. 3 and/or FIG. 4 .
- the outcome estimation model can be required to meet minimum prediction quality threshold using both regression-based prediction quality measures (e.g., squared loss) and ranking-based prediction quality measures (e.g., logistic loss).
- a selection score is computed for each eligible content item using the estimated click-through likelihood ( 410 ).
- the selection score for each content item is a function of a bid that is associated with the content item and an eCTL that was computed for the advertisement using the outcome estimation model.
- the selection score for an advertisement can be a product of a maximum bid that an advertiser will pay for distribution of the advertisement and an eCTL of the advertisement, where the eCTL has been computed using the feature values of the advertisement and the outcome estimation model.
- One or more eligible content items are selected, based on the selection scores, to be provided in response to the request ( 412 ).
- the quantity of eligible content items that are selected can be determined based on a number of presentation positions that are available for presenting content items. For example, if three advertisement slots are available for presenting advertisements on a search results page, three advertisements having a highest three selection scores can be selected for presentation with the search results page.
- Data that cause presentation of the selected content items at a user device are provided ( 414 ).
- data that cause presentation of the selected content items at a user device for which the request for content items was received can be provided.
- the data that are provided cause presentation of the content items at specified presentation positions.
- the data can specify that the content item that is associated with a highest selection score be presented at a most prominent presentation position (e.g., a banner position) and that the content item associated with each next lower selection score be presented at a respective next most prominent presentation position.
- the prominence of each presentation position can be specified by the publisher and/or computed using normalized selection rates (e.g., click-through-rates) for content items that are presented at each presentation position.
- FIG. 5 is block diagram of an example computer system 500 that can be used to train and/or utilize outcome estimation models, as described above.
- the system 500 includes a processor 510 , a memory 520 , a storage device 530 , and an input/output device 540 .
- Each of the components 510 , 520 , 530 , and 540 can be interconnected, for example, using a system bus 550 .
- the processor 510 is capable of processing instructions for execution within the system 500 .
- the processor 510 is a single-threaded processor.
- the processor 510 is a multi-threaded processor.
- the processor 510 is capable of processing instructions stored in the memory 520 or on the storage device 530 .
- the memory 520 stores information within the system 500 .
- the memory 520 is a computer-readable medium.
- the memory 520 is a volatile memory unit.
- the memory 520 is a non-volatile memory unit.
- the storage device 530 is capable of providing mass storage for the system 500 .
- the storage device 530 is a computer-readable medium.
- the storage device 530 can include, for example, a hard disk device, an optical disk device, or some other large capacity storage device.
- the input/output device 540 provides input/output operations for the system 500 .
- the input/output device 540 can include one or more of a network interface devices, e.g., an Ethernet card, a serial communication device, e.g., and RS-232 port, and/or a wireless interface device, e.g., and 802.11 card.
- the input/output device can include driver devices configured to receive input data and send output data to other input/output devices, e.g., keyboard, printer and display devices 560 .
- Other implementations, however, can also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, etc.
- Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on computer storage medium for execution by, or to control the operation of, data processing apparatus.
- the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
- a computer storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them.
- a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially-generated propagated signal.
- the computer storage medium can also be, or be included in, one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
- the operations described in this specification can be implemented as operations performed by a data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
- the term “data processing apparatus” encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple ones, or combinations, of the foregoing
- the apparatus can include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- the apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them.
- the apparatus and execution environment can realize various different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
- a computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code).
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- the processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output.
- the processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer.
- a processor will receive instructions and data from a read-only memory or a random access memory or both.
- the essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- a computer need not have such devices.
- a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a universal serial bus (USB) flash drive), to name just a few.
- Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
- the processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to a
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network.
- Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
- LAN local area network
- WAN wide area network
- inter-network e.g., the Internet
- peer-to-peer networks e.g., ad hoc peer-to-peer networks.
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- a server transmits data (e.g., an HTML page) to a client device (e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device).
- client device e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device.
- Data generated at the client device e.g., a result of the user interaction
Abstract
Description
l(y r ,y c)=(y r −y c)2 (2)
l(p r ,p c)=p r log(p c)+(1−p r)log(1−p c) (3)
w i=(1−ηiλ)w i-1+ηi x(y r−(w i-1 ,x)) (4)
Claims (22)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/837,890 US8572011B1 (en) | 2010-07-16 | 2010-07-16 | Outcome estimation models trained using regression and ranking techniques |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/837,890 US8572011B1 (en) | 2010-07-16 | 2010-07-16 | Outcome estimation models trained using regression and ranking techniques |
Publications (1)
Publication Number | Publication Date |
---|---|
US8572011B1 true US8572011B1 (en) | 2013-10-29 |
Family
ID=49448723
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/837,890 Active 2032-08-17 US8572011B1 (en) | 2010-07-16 | 2010-07-16 | Outcome estimation models trained using regression and ranking techniques |
Country Status (1)
Country | Link |
---|---|
US (1) | US8572011B1 (en) |
Cited By (28)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130254175A1 (en) * | 2010-08-04 | 2013-09-26 | Alibaba Group Holding Limited | Returning estimated value of search keywords of entire account |
US20140379460A1 (en) * | 2013-06-24 | 2014-12-25 | Adobe Systems Incorporated | Real-time updates to digital marketing forecast models |
US20150370863A1 (en) * | 2014-06-18 | 2015-12-24 | Adobe Systems Incorporated | Performing predictive analysis on usage analytics |
US20160148251A1 (en) * | 2014-11-24 | 2016-05-26 | Adobe Systems Incorporated | Risk Quantification for Policy Deployment |
US20160148250A1 (en) * | 2014-11-24 | 2016-05-26 | Adobe Systems Incorporated | Searching for Safe Policies to Deploy |
CN105631697A (en) * | 2014-11-24 | 2016-06-01 | 奥多比公司 | Automated system for safe policy deployment |
US20160162799A1 (en) * | 2010-10-04 | 2016-06-09 | Mind Over Matter Ai, Llc. | Coupling of rational agents to quantum processes |
US20160180455A1 (en) * | 2014-12-19 | 2016-06-23 | Yahoo Japan Corporation | Generating device, generating method, and non-transitory computer readable storage medium |
US9665556B1 (en) * | 2012-07-23 | 2017-05-30 | Amazon Technologies, Inc. | Assigning slots to user interface elements |
US20170178181A1 (en) * | 2015-12-17 | 2017-06-22 | Linkedin Corporation | Click through rate prediction calibration |
US9892431B1 (en) | 2011-03-31 | 2018-02-13 | Twitter, Inc. | Temporal features in a messaging platform |
US20180047060A1 (en) * | 2016-08-10 | 2018-02-15 | Facebook, Inc. | Informative advertisements on hobby and strong interests feature space |
US20180081626A1 (en) * | 2016-09-22 | 2018-03-22 | Guangzhou Ucweb Computer Technology Co., Ltd. | Article quality scoring method and device, client, server, and programmable device |
US20190035387A1 (en) * | 2017-07-27 | 2019-01-31 | Microsoft Technology Licensing, Llc | Intent and Slot Detection For Digital Assistants |
US10248667B1 (en) | 2013-03-15 | 2019-04-02 | Twitter, Inc. | Pre-filtering in a messaging platform |
US10438246B1 (en) * | 2011-11-21 | 2019-10-08 | Rightquestion, Llc | Advertising model |
US10650408B1 (en) | 2013-03-15 | 2020-05-12 | Twitter, Inc. | Budget smoothing in a messaging platform |
US10769677B1 (en) | 2011-03-31 | 2020-09-08 | Twitter, Inc. | Temporal features in a messaging platform |
US10824815B2 (en) * | 2019-01-02 | 2020-11-03 | Netapp, Inc. | Document classification using attention networks |
US11113714B2 (en) * | 2015-12-30 | 2021-09-07 | Verizon Media Inc. | Filtering machine for sponsored content |
US20220058019A1 (en) * | 2018-05-10 | 2022-02-24 | Microsoft Technology Licensing, Llc | Coding output |
US11263258B2 (en) * | 2019-03-15 | 2022-03-01 | Fujitsu Limited | Information processing method, information processing apparatus, and non-transitory computer-readable storage medium for storing information processing program of scoring with respect to combination of imaging method and trained model |
US20220108328A1 (en) * | 2020-10-06 | 2022-04-07 | Mastercard International Incorporated | Systems and methods for linking indices associated with environmental impact determinations for transactions |
US11416501B2 (en) * | 2017-06-05 | 2022-08-16 | Ancestry.Com Operations Inc. | Customized coordinate ascent for ranking data records |
US20220277342A1 (en) * | 2020-03-02 | 2022-09-01 | Yieldmo, Inc. | Method for modeling digital advertisement consumption |
US11501334B2 (en) | 2020-01-09 | 2022-11-15 | Walmart Apollo, Llc | Methods and apparatuses for selecting advertisements using semantic matching |
US11562656B2 (en) * | 2017-11-27 | 2023-01-24 | BlueOwl, LLC | Systems and methods for improving driver safety using uplift modeling |
US11574351B2 (en) * | 2020-09-11 | 2023-02-07 | Beijing Wodong Tianjun Information Technology Co., Ltd. | System and method for quality assessment of product description |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7289985B2 (en) * | 2004-04-15 | 2007-10-30 | Microsoft Corporation | Enhanced document retrieval |
US20080183648A1 (en) * | 2006-01-31 | 2008-07-31 | The Board Of Trustees Of The University Of Illinois | Methods and systems for interactive computing |
US7490071B2 (en) * | 2003-08-29 | 2009-02-10 | Oracle Corporation | Support vector machines processing system |
US7558764B2 (en) * | 2004-06-28 | 2009-07-07 | International Business Machines Corporation | Methods for multi-class cost-sensitive learning |
US20100125570A1 (en) * | 2008-11-18 | 2010-05-20 | Olivier Chapelle | Click model for search rankings |
US8126839B2 (en) * | 2008-06-19 | 2012-02-28 | Yahoo! Inc. | Methods and apparatuses for adapting a ranking function of a search engine for use with a specific domain |
-
2010
- 2010-07-16 US US12/837,890 patent/US8572011B1/en active Active
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7490071B2 (en) * | 2003-08-29 | 2009-02-10 | Oracle Corporation | Support vector machines processing system |
US7289985B2 (en) * | 2004-04-15 | 2007-10-30 | Microsoft Corporation | Enhanced document retrieval |
US7558764B2 (en) * | 2004-06-28 | 2009-07-07 | International Business Machines Corporation | Methods for multi-class cost-sensitive learning |
US20080183648A1 (en) * | 2006-01-31 | 2008-07-31 | The Board Of Trustees Of The University Of Illinois | Methods and systems for interactive computing |
US8126839B2 (en) * | 2008-06-19 | 2012-02-28 | Yahoo! Inc. | Methods and apparatuses for adapting a ranking function of a search engine for use with a specific domain |
US20100125570A1 (en) * | 2008-11-18 | 2010-05-20 | Olivier Chapelle | Click model for search rankings |
Cited By (49)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130254175A1 (en) * | 2010-08-04 | 2013-09-26 | Alibaba Group Holding Limited | Returning estimated value of search keywords of entire account |
US9449049B2 (en) * | 2010-08-04 | 2016-09-20 | Alibaba Group Holding Limited | Returning estimated value of search keywords of entire account |
US10733521B2 (en) * | 2010-10-04 | 2020-08-04 | Mind Over Matter Ai, Llc | Coupling of rational agents to quantum processes |
US20160162799A1 (en) * | 2010-10-04 | 2016-06-09 | Mind Over Matter Ai, Llc. | Coupling of rational agents to quantum processes |
US10769677B1 (en) | 2011-03-31 | 2020-09-08 | Twitter, Inc. | Temporal features in a messaging platform |
US9892431B1 (en) | 2011-03-31 | 2018-02-13 | Twitter, Inc. | Temporal features in a messaging platform |
US11783376B2 (en) | 2011-11-21 | 2023-10-10 | Security Technology, Llc | Advertising model |
US11562402B2 (en) | 2011-11-21 | 2023-01-24 | Rightquestion, Llc | Advertising model |
US10977696B1 (en) | 2011-11-21 | 2021-04-13 | Rightquestion, Llc | Advertising model |
US10438246B1 (en) * | 2011-11-21 | 2019-10-08 | Rightquestion, Llc | Advertising model |
US9665556B1 (en) * | 2012-07-23 | 2017-05-30 | Amazon Technologies, Inc. | Assigning slots to user interface elements |
US10346858B2 (en) | 2012-07-23 | 2019-07-09 | Amazon Technologies, Inc. | Assigning slots to user interface elements |
US10650408B1 (en) | 2013-03-15 | 2020-05-12 | Twitter, Inc. | Budget smoothing in a messaging platform |
US10692114B1 (en) | 2013-03-15 | 2020-06-23 | Twitter, Inc. | Exploration in a real time messaging platform |
US11409717B1 (en) | 2013-03-15 | 2022-08-09 | Twitter, Inc. | Overspend control in a messaging platform |
US11216841B1 (en) | 2013-03-15 | 2022-01-04 | Twitter, Inc. | Real time messaging platform |
US11157464B1 (en) | 2013-03-15 | 2021-10-26 | Twitter, Inc. | Pre-filtering of candidate messages for message streams in a messaging platform |
US10963922B1 (en) | 2013-03-15 | 2021-03-30 | Twitter, Inc. | Campaign goal setting in a messaging platform |
US10769661B1 (en) * | 2013-03-15 | 2020-09-08 | Twitter, Inc. | Real time messaging platform |
US10248667B1 (en) | 2013-03-15 | 2019-04-02 | Twitter, Inc. | Pre-filtering in a messaging platform |
US11288702B1 (en) | 2013-03-15 | 2022-03-29 | Twitter, Inc. | Exploration in a real time messaging platform |
US10600080B1 (en) | 2013-03-15 | 2020-03-24 | Twitter, Inc. | Overspend control in a messaging platform |
US20140379460A1 (en) * | 2013-06-24 | 2014-12-25 | Adobe Systems Incorporated | Real-time updates to digital marketing forecast models |
US10181130B2 (en) * | 2013-06-24 | 2019-01-15 | Adobe Systems Inc. | Real-time updates to digital marketing forecast models |
US9609074B2 (en) * | 2014-06-18 | 2017-03-28 | Adobe Systems Incorporated | Performing predictive analysis on usage analytics |
US20150370863A1 (en) * | 2014-06-18 | 2015-12-24 | Adobe Systems Incorporated | Performing predictive analysis on usage analytics |
CN105631339A (en) * | 2014-11-24 | 2016-06-01 | 奥多比公司 | Searching for safe policies to deploy |
US20160148250A1 (en) * | 2014-11-24 | 2016-05-26 | Adobe Systems Incorporated | Searching for Safe Policies to Deploy |
CN105631697A (en) * | 2014-11-24 | 2016-06-01 | 奥多比公司 | Automated system for safe policy deployment |
US20160148251A1 (en) * | 2014-11-24 | 2016-05-26 | Adobe Systems Incorporated | Risk Quantification for Policy Deployment |
CN105631698A (en) * | 2014-11-24 | 2016-06-01 | 奥多比公司 | Risk quantification for policy deployment |
US20160180455A1 (en) * | 2014-12-19 | 2016-06-23 | Yahoo Japan Corporation | Generating device, generating method, and non-transitory computer readable storage medium |
US20170178181A1 (en) * | 2015-12-17 | 2017-06-22 | Linkedin Corporation | Click through rate prediction calibration |
US11113714B2 (en) * | 2015-12-30 | 2021-09-07 | Verizon Media Inc. | Filtering machine for sponsored content |
US10810627B2 (en) * | 2016-08-10 | 2020-10-20 | Facebook, Inc. | Informative advertisements on hobby and strong interests feature space |
US20180047060A1 (en) * | 2016-08-10 | 2018-02-15 | Facebook, Inc. | Informative advertisements on hobby and strong interests feature space |
US10956473B2 (en) * | 2016-09-22 | 2021-03-23 | Guangzhou Ucweb Computer Technology Co., Ltd. | Article quality scoring method and device, client, server, and programmable device |
US20180081626A1 (en) * | 2016-09-22 | 2018-03-22 | Guangzhou Ucweb Computer Technology Co., Ltd. | Article quality scoring method and device, client, server, and programmable device |
US11416501B2 (en) * | 2017-06-05 | 2022-08-16 | Ancestry.Com Operations Inc. | Customized coordinate ascent for ranking data records |
US10453444B2 (en) * | 2017-07-27 | 2019-10-22 | Microsoft Technology Licensing, Llc | Intent and slot detection for digital assistants |
US20190035387A1 (en) * | 2017-07-27 | 2019-01-31 | Microsoft Technology Licensing, Llc | Intent and Slot Detection For Digital Assistants |
US11562656B2 (en) * | 2017-11-27 | 2023-01-24 | BlueOwl, LLC | Systems and methods for improving driver safety using uplift modeling |
US20220058019A1 (en) * | 2018-05-10 | 2022-02-24 | Microsoft Technology Licensing, Llc | Coding output |
US10824815B2 (en) * | 2019-01-02 | 2020-11-03 | Netapp, Inc. | Document classification using attention networks |
US11263258B2 (en) * | 2019-03-15 | 2022-03-01 | Fujitsu Limited | Information processing method, information processing apparatus, and non-transitory computer-readable storage medium for storing information processing program of scoring with respect to combination of imaging method and trained model |
US11501334B2 (en) | 2020-01-09 | 2022-11-15 | Walmart Apollo, Llc | Methods and apparatuses for selecting advertisements using semantic matching |
US20220277342A1 (en) * | 2020-03-02 | 2022-09-01 | Yieldmo, Inc. | Method for modeling digital advertisement consumption |
US11574351B2 (en) * | 2020-09-11 | 2023-02-07 | Beijing Wodong Tianjun Information Technology Co., Ltd. | System and method for quality assessment of product description |
US20220108328A1 (en) * | 2020-10-06 | 2022-04-07 | Mastercard International Incorporated | Systems and methods for linking indices associated with environmental impact determinations for transactions |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8572011B1 (en) | Outcome estimation models trained using regression and ranking techniques | |
US8600809B1 (en) | Predictive model performance | |
US8229786B2 (en) | Click probability with missing features in sponsored search | |
US7921107B2 (en) | System for generating query suggestions using a network of users and advertisers | |
AU2010282449B2 (en) | Context based resource relevance | |
US8788442B1 (en) | Compliance model training to classify landing page content that violates content item distribution guidelines | |
US10580035B2 (en) | Promotion selection for online customers using Bayesian bandits | |
US20100250335A1 (en) | System and method using text features for click prediction of sponsored search advertisements | |
JP6267344B2 (en) | Content selection using quality control | |
US20080103886A1 (en) | Determining relevance of a term to content using a combined model | |
US20110078014A1 (en) | Online resource assignment | |
US9805102B1 (en) | Content item selection based on presentation context | |
US20100010895A1 (en) | Prediction of a degree of relevance between query rewrites and a search query | |
US20120123863A1 (en) | Keyword publication for use in online advertising | |
US20150142557A1 (en) | User Engagement-Based Contextually-Dependent Automated Pricing for Non-Guaranteed Delivery | |
US11288709B2 (en) | Training and utilizing multi-phase learning models to provide digital content to client devices in a real-time digital bidding environment | |
US9256688B2 (en) | Ranking content items using predicted performance | |
US20110040604A1 (en) | Systems and Methods for Providing Targeted Content | |
US8775251B1 (en) | Allocating advertising budgets | |
US20110307323A1 (en) | Content items for mobile applications | |
US20120047020A1 (en) | Contextual advertising with user features | |
US20140372202A1 (en) | Predicting performance of content items using loss functions | |
US9846722B1 (en) | Trend based distribution parameter suggestion | |
US8234265B1 (en) | Content selection data expansion | |
AU2009355571B2 (en) | Content performance estimation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SCULLEY II, DAVID W.;REEL/FRAME:024821/0473Effective date: 20100715 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0299Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |