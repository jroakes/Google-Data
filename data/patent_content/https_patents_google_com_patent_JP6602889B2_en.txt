JP6602889B2 - Creating and updating area description files for mobile device localization by crowdsourcing - Google Patents
Creating and updating area description files for mobile device localization by crowdsourcing Download PDFInfo
- Publication number
- JP6602889B2 JP6602889B2 JP2017550888A JP2017550888A JP6602889B2 JP 6602889 B2 JP6602889 B2 JP 6602889B2 JP 2017550888 A JP2017550888 A JP 2017550888A JP 2017550888 A JP2017550888 A JP 2017550888A JP 6602889 B2 JP6602889 B2 JP 6602889B2
- Authority
- JP
- Japan
- Prior art keywords
- description file
- area description
- mobile device
- localization
- spatial
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Classifications
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/20—Instruments for performing navigational calculations
- G01C21/206—Instruments for performing navigational calculations specially adapted for indoor navigation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5838—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using colour
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5846—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using extracted text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/70—Determining position or orientation of objects or cameras
- G06T7/73—Determining position or orientation of objects or cameras using feature-based methods
- G06T7/74—Determining position or orientation of objects or cameras using feature-based methods involving reference images or patches
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/20—Scenes; Scene-specific elements in augmented reality scenes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/10—Image acquisition modality
- G06T2207/10004—Still image; Photographic image
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/10—Image acquisition modality
- G06T2207/10028—Range image; Depth image; 3D point clouds
Description
関連出願への相互参照
本出願は、同時係属中の特許出願である
本願と同日付けで出願された、「アップロードの前のエリア記述ファイル（area description file）のプライバシーフィルタリング」と題された米国特許出願連続番号第１４／７０８，９５５号（代理人管理番号１５００−Ｔ０１４ＵＳ）、および
本願と同日付けで出願された、「ローカリゼーションエリア記述ファイルに対するプライバシー性が高い問合せ」と題された米国特許出願連続番号第１４／７０８，９７０号（代理人管理番号１５００−Ｔ０１５ＵＳ）に関連し、その全体が本明細書中に引用により援用される。
Cross-reference to related applications This application is a co-pending patent application, US patent entitled “Privacy Filtering of Area Description File Before Upload”, filed on the same date as this application. Application Serial No. 14 / 708,955 (Attorney Administration No. 1500-T014US) and a series of US patent applications entitled “Privacy Query for Localization Area Description File” filed on the same date as this application. No. 14 / 708,970 (Agent Management Number 1500-T015US), which is incorporated herein by reference in its entirety.
開示の分野
本開示は、一般的には視覚的マッピングシステムに、より特定的には視覚的情報を用いた移動体装置のローカリゼーションに関する。
FIELD OF DISCLOSURE The present disclosure relates generally to visual mapping systems, and more particularly to localization of mobile devices using visual information.
背景
視覚的マッピングシステムは、移動体装置が捕捉するイメージ（imagery）中に検出される（「視覚的特徴」とも称される）空間的特徴および慣性情報に依拠して、三次元（３Ｄ）空間中の移動体装置の現在の位置および向きを判断する。典型的に、位置および向きは、規定された座標フレームの文脈で判断されて、仮想現実（ＶＲ）機能性、拡張現実（ＡＲ）機能性、または複数の移動体装置同士の間のゲームもしくは他のデバイス対応（device-enabled）対話などの公知の固定された基準フレームに対する同期を要件とするさまざまな機能性を促進する。同時ローカリゼーションおよびマッピング（ＳＬＡＭ）技術により、移動体装置が以前にマッピングしていないエリア内のその位置および向きを同時に学習しながら当該エリアをマッピングできるようになる。こうして、移動体装置が同じエリアに戻ると、移動体装置は容易に、「ローカリゼーション」として公知のプロセスで、以前に観察した空間的特徴を検出することによって、そのエリア内でのその現在の位置および向きを判断し得る。しかしながら、移動体装置が初めてあるエリアに入っている場合、移動体装置には、これらの以前に検出済みのローカリゼーションの手がかり（cue）がない。従来の視覚的マッピングシステムでは、移動体装置は、視覚的マッピングプロセス−かなりの時間およびリソースを使うプロセス−の実現を通してエリアを「学習」しなければならない。以前にマッピングしていないエリアについての視覚的マッピングプロセスの実行に係る遅延を回避するため、従来の視覚的マッピングシステムは、代わりに、全地球測位システム（ＧＰＳ）情報または慣性センサフィードバックを介した場所マッピングなどの視覚的でない向きの入力に基づく移動体装置の向きまたは位置の検出に立ち返ることがある。しかしながら、これらの非視覚的マッピング解決策は、センサおよび測定のずれのために信頼性が低く（たとえば、室内ではまたは背の高い障害物で囲まれる区域ではＧＰＳの受信が劣り）、不正確であり、かつ誤りやすい可能性がある。
BACKGROUND Visual mapping systems rely on spatial features and inertia information (also referred to as “visual features”) detected in an imagery captured by a mobile device to provide a three-dimensional (3D) space. Determine the current position and orientation of the mobile device inside. Typically, position and orientation are determined in the context of a defined coordinate frame, virtual reality (VR) functionality, augmented reality (AR) functionality, or a game or other between multiple mobile devices Facilitates various functionalities that require synchronization to a known fixed reference frame, such as device-enabled interactions. Simultaneous localization and mapping (SLAM) technology allows a mobile device to map an area while simultaneously learning its position and orientation in an area that has not previously been mapped. Thus, when the mobile device returns to the same area, the mobile device can easily detect its current position within the area by detecting previously observed spatial features in a process known as “localization”. And can determine the orientation. However, if the mobile device is in an area for the first time, the mobile device does not have these previously detected localization cues. In conventional visual mapping systems, mobile devices must “learn” the area through the implementation of a visual mapping process—a process that uses significant time and resources. In order to avoid delays in performing the visual mapping process for previously unmapped areas, traditional visual mapping systems are instead located via global positioning system (GPS) information or inertial sensor feedback. There may be a return to detecting the orientation or position of a mobile device based on non-visual orientation inputs such as mapping. However, these non-visual mapping solutions are unreliable due to sensor and measurement misalignment (eg, poor GPS reception indoors or in areas surrounded by tall obstacles) and are inaccurate There is a possibility of error.
本開示は、添付の図面を参照することによって、当業者によってより十分に理解され得、かつその数多くの特徴および利点が当業者に明らかになり得る。異なる図面での同じ参照符号の使用は、同様のまたは同一の項目を示す。 The present disclosure can be more fully understood by those skilled in the art and numerous features and advantages thereof will be apparent to those skilled in the art by reference to the accompanying drawings. The use of the same reference symbols in different drawings indicates similar or identical items.
詳細な説明
以下の説明は、視覚的マッピングシステムに係る多数の具体的な実施形態および詳細を提供することによって本開示の完全な理解を伝えることを意図する。しかしながら、本開示は、例示にすぎないこれらの具体的な実施形態および詳細に限定されるわけではなく、そのため、開示の範囲は、以下の請求項およびその均等物によってのみ限定されることが意図されると理解される。公知のシステムおよび方法に照らして、当業者ならば、具体的な設計および他の必要性に依存して、その意図される目的および有利のために、任意の数の代替的実施形態での開示の使用を認めるであろうことがさらに理解される。
DETAILED DESCRIPTION The following description is intended to convey a full understanding of the present disclosure by providing a number of specific embodiments and details relating to visual mapping systems. However, the present disclosure is not limited to these specific embodiments and details, which are exemplary only, and therefore the scope of the disclosure is intended to be limited only by the following claims and their equivalents. Will be understood. In light of known systems and methods, those skilled in the art will disclose in any number of alternative embodiments for their intended purposes and advantages, depending on the specific design and other needs. It will be further understood that the use of
図１−図１２は、ローカリゼーションエリアデータファイルのクラウドベースの作成、見直し、および移動体装置に対するその提供のための例示的なシステムおよび技術を示す。少なくとも１つの実施形態では、視覚的マッピングシステムは、１つ以上の有線または無線ネットワークを介して複数の移動体装置に通信するように結合されるエリア記述ファイル（area description file）（ＡＤＦ）サーバを備える。移動体装置が以前にマッピングしていないエリアに入ると、移動体装置はエリア学習プロセスを開始し、これにより移動体装置はエリアのイメージを捕捉し、捕捉したイメージを用いて空間的特徴を検出し、ＡＤＦ中の空間的特徴、それらの相対的外形（outer geometry）、関連の統計的データ、および同時に捕捉されたセンサデータの表示をＡＤＦサーバに送信する。ＡＤＦサーバは、このＡＤＦを用いてローカリゼーションＡＤＦ（ＬＡＤＦ）を生成する。これは、当該エリアの空間的特徴のまばらな点群（sparse point cloud）を表わす。なお、「エリア記述ファイル」において用いるような、またはそれ以外に本明細書中で用いるような「ファイル」という用語は、データおよび他の情報フィールドを関連付けるのに用いられる任意のデータ構造、またはそのようなデータ構造の任意の組合せを指す。次に、ＬＡＤＦがカバーするエリア中の別の移動体装置にＬＡＤＦをダウンロードし得る。ＬＡＤＦを受信する移動体装置は当該エリアのイメージを捕捉し、その中の空間的特徴を検出し、検出された空間的特徴およびそれらの相対的外形をＬＡＤＦが表わす空間的特徴および相対的外形と比較して、ＬＡＤＦが提示する参照座標フレームを用いてエリア内の移動体装置をローカライズし得る。このように、以前にマッピングしていないエリアのエリアディスカバリー（discovery）およびマッピングを、移動体装置によるデータの受動的収集およびアップロードによって効率的にクラウドソーシングしてもよい。 FIGS. 1-12 illustrate exemplary systems and techniques for cloud-based creation, review, and provision of localization area data files to mobile devices. In at least one embodiment, the visual mapping system includes an area description file (ADF) server coupled to communicate to a plurality of mobile devices via one or more wired or wireless networks. Prepare. When a mobile device enters an area that has not previously been mapped, the mobile device initiates an area learning process that causes the mobile device to capture an image of the area and use the captured image to detect spatial features. And sends to the ADF server a representation of the spatial features in the ADF, their outer geometry, associated statistical data, and simultaneously captured sensor data. The ADF server generates a localization ADF (LADF) using this ADF. This represents a sparse point cloud of the spatial features of the area. Note that the term “file” as used in an “area description file” or otherwise used herein refers to any data structure used to associate data with other information fields, or Any combination of such data structures. The LADF can then be downloaded to another mobile device in the area covered by the LADF. A mobile device that receives the LADF captures an image of the area, detects spatial features therein, detects the spatial features and their relative outlines, and the spatial features and relative outlines that the LADF represents In comparison, a reference coordinate frame presented by LADF can be used to localize mobile devices within an area. In this way, area discovery and mapping of previously unmapped areas may be efficiently crowdsourced by passive collection and upload of data by mobile devices.
ある実施形態では、ＡＤＦサーバは、同じエリアについてまたは隣接するエリアについて複数の移動体装置からＡＤＦファイルを受信し、ＡＤＦサーバは、これらの複数のＡＤＦファイルを合成（merged）ＡＤＦファイル（またはＡＤＦファイルの合成クラスタ）に合成するように動作する。次に、合成ＡＤＦファイルを用いてエリアまたはそのサブエリア（sub-area）についての１つ以上のＬＡＤＦを生成し得る。さらに、エリアで変化がありそうな場合、ＡＤＦサーバは、あるエリア中のローカリゼーション用ＬＡＤＦを用いて、移動体装置からのフィードバックに基づいて当該エリアについて生成されるＬＡＤＦのクラウドソーシングされた更新を利用し得る。たとえば、移動体装置がＬＡＤＦ中のいくつかの空間的特徴を観察していないことが確実であると示すフィードバックに応答して、ＡＤＦサーバはこれらの空間的特徴をＬＡＤＦから除外してもよい。反対に、エリア中の移動体装置がＬＡＤＦに含まれていない空間的特徴を観察していることが確実であると示すフィードバックに応答して、ＡＤＦサーバはこれらの空間的特徴をＬＡＤＦに加えてもよい。 In some embodiments, the ADF server receives ADF files from multiple mobile devices for the same area or for adjacent areas, and the ADF server combines these multiple ADF files with a merged ADF file (or ADF file). (Composite cluster). The composite ADF file may then be used to generate one or more LADFs for the area or its sub-area. In addition, if there is likely to be a change in the area, the ADF server uses the LADF for localization in an area and uses a crowdsourced update of LADF generated for that area based on feedback from the mobile device Can do. For example, in response to feedback indicating that the mobile device is certain not to observe some spatial features in LADF, the ADF server may exclude these spatial features from LADF. Conversely, in response to feedback indicating that mobile devices in the area are sure to observe spatial features that are not included in LADF, the ADF server adds these spatial features to LADF. Also good.
ＡＤＦおよびＬＡＤＦが表わす点群および関連のデータは、ある程度まであるエリアの視覚的表示を与えるので、移動体装置からのＡＤＦの収集および移動体装置へのＬＡＤＦの配布がプライバシー侵害（privacy implication）になることがある。そのため、ある実施形態では、視覚的マッピングシステムはあるプライバシー管理を実現する。１つのそのようなプライバシー管理は、ＡＤＦをＡＤＦサーバにアップロードする前にＡＤＦのデータに対して１つ以上のプライバシーフィルタプロセスを実現するよう移動体装置を構成することと、したがってＡＤＦのアップロード版が表わす情報をエリアの有用な視覚的内容を再作成する目的のためには再利用できなくすることとを含み得る。別のそのようなプライバシー管理は、ＬＡＤＦにアクセスして移動体装置に配布する二段階ＬＡＤＦ問合せを含んでもよい。移動体装置それ自身が入手可能なＬＡＤＦを有していないエリアに入ると、移動体装置はイメージを捕捉し、捕捉されたイメージから空間的特徴を検出し、ＬＡＤＦ要求をＡＤＦサーバに送信する。これにより、ＬＡＤＦ要求は、検出された空間的特徴の組と、移動体装置の場所のインジケータ（たとえば、ＧＰＳ座標または無線基地局識別子をもう一つ）とを含む。次に、ＡＤＦサーバは第１の問合せ段階を実行して、検出された空間的特徴の組または場所インジケータの一方に一致する候補ＬＡＤＦの組を同定し、次に、検出された空間的特徴または場所インジケータの他方に基づいて候補ＬＡＤＦの組からＬＡＤＦを選択し得る。このように、移動体装置が送信する空間的識別子の組は、移動体装置が同定されたエリアの中にいるまたはそれへのアクセスを有すること、およびしたがって要求を発している移動体装置にＬＡＤＦを供給する際のプライバシー侵害のおそれが大幅に低減されていることの証明として働き得る。 The point cloud and associated data represented by ADF and LADF give a visual indication of an area to some extent, so the collection of ADF from mobile devices and the distribution of LADF to mobile devices is a privacy implication. May be. Thus, in some embodiments, the visual mapping system provides some privacy management. One such privacy management is to configure the mobile device to implement one or more privacy filtering processes on the ADF data before uploading the ADF to the ADF server, and thus the upload version of the ADF Representing information can include making it unusable for the purpose of recreating useful visual content of the area. Another such privacy management may include a two-stage LADF query that accesses the LADF and distributes it to the mobile device. When the mobile device itself enters an area that does not have an available LADF, the mobile device captures the image, detects spatial features from the captured image, and sends a LADF request to the ADF server. Thus, the LADF request includes a set of detected spatial features and an indicator of the location of the mobile device (eg, another GPS coordinate or radio base station identifier). Next, the ADF server performs a first query stage to identify a set of candidate LADFs that match one of the detected spatial feature set or location indicator, and then detects the detected spatial feature or An LADF may be selected from the set of candidate LADFs based on the other of the location indicators. In this way, the set of spatial identifiers that the mobile device transmits is LADF to the mobile device that is within or has access to the area in which the mobile device is identified, and thus issuing the request. Can serve as proof that the risk of a privacy breach when supplying is greatly reduced.
図１は、本開示の少なくとも１つの実施形態に従う視覚的マッピングシステム１００を示す。描かれた例では、視覚的マッピングシステム１００は、１つ以上の移動体装置１０４に通信するように結合されるＡＤＦサーバ１０２を備える。クラウド１０６で表わされるように、ＡＤＦサーバ１０２は、移動体装置１０４から遠隔であり、無線ローカルエリアネットワーク（ＷＬＡＮ）、セルラーデータネットワーク、インターネット、またはその組合せなどの１つ以上の有線または無線ネットワークを介して移動体装置１０４に結合されるコンピューティングシステムを備える。本明細書中では単一のサーバという例示的な文脈で記載されるが、他の実施形態では、ＡＤＦサーバ１０２は、サーバのクラスタを備えるコンピューティングシステムとして実現されてもよい。ＡＤＦサーバ１０２の例示的な実現例を図２を参照して以下により詳細に説明する。 FIG. 1 illustrates a visual mapping system 100 in accordance with at least one embodiment of the present disclosure. In the depicted example, visual mapping system 100 comprises an ADF server 102 that is communicatively coupled to one or more mobile devices 104. As represented by the cloud 106, the ADF server 102 is remote from the mobile device 104 and includes one or more wired or wireless networks, such as a wireless local area network (WLAN), a cellular data network, the Internet, or a combination thereof. Via a computing system coupled to the mobile device 104. Although described herein in the exemplary context of a single server, in other embodiments, the ADF server 102 may be implemented as a computing system comprising a cluster of servers. An exemplary implementation of the ADF server 102 is described in more detail below with reference to FIG.
移動体装置１０４は、ヘッドマウントディスプレイ（ＨＭＤ）、タブレットコンピュータ、コンピューティング対応携帯電話（たとえば「スマートフォン」）、ノートブック型コンピュータ、パーソナルデジタルアシスタント（ＰＤＡ）、ゲーム機システム、ドローンなどの、１人以上のユーザ１１０が動作させるさまざまな携帯型電子機器のうち任意のものを含むことができる。描かれる例では、移動体装置１０４は、片面１１６とは反対の表面１１４を有する筐体１１２を含む。これにより、筐体１１２は典型的に、ユーザ１１０に対して、ユーザが筐体１１２の表面１１４に対面するような向きにされる。さらに、描かれる実現例では、移動体装置１０４は、視覚的情報をユーザ１１０に提示するための表面１１６に配設されるディスプレイ１１８を含む。応じて、参照の容易のため、表面１１６は本明細書中で「正面向き」面と称され、表面１１４は、本明細書中ではこの例示的な向きの反映として「ユーザ向き」面と称される。尤も、これらの表面の向きは、これらの関連に基づく指定によって限定されるものではない。 The mobile device 104 is a single person such as a head-mounted display (HMD), a tablet computer, a computing-compatible mobile phone (eg, “smartphone”), a notebook computer, a personal digital assistant (PDA), a game machine system, a drone, etc. Any one of various portable electronic devices operated by the user 110 can be included. In the depicted example, the mobile device 104 includes a housing 112 having a surface 114 opposite the one side 116. Thus, the housing 112 is typically oriented with respect to the user 110 such that the user faces the surface 114 of the housing 112. Further, in the depicted implementation, mobile device 104 includes a display 118 disposed on surface 116 for presenting visual information to user 110. Accordingly, for ease of reference, surface 116 is referred to herein as a “front facing” surface and surface 114 is referred to herein as a “user facing” surface as a reflection of this exemplary orientation. Is done. However, the orientation of these surfaces is not limited by designations based on these associations.
移動体装置１０４はさらに、移動体装置１０４が現在位置するエリア１２２に関する情報を得る複数のセンサを含む。移動体装置１０４は、たとえば正面向き面１１６に配設される画像化センサ１２４，１２６などの１つ以上の画像化センサを介してエリア１２２についての視覚的情報（イメージ）を得る。移動体装置１０４からの特定の距離からそれぞれの視野が重なり合うように、画像化センサ１２４，１２６を正面向き面１１６上に位置決めして向けることができる。これにより、多視点分析を介して、重なり合う視野の領域に位置決めされるエリア１２２中のオブジェクトの奥行き検知が可能になる。これに代えて、表面１１６上に配設される奥行きセンサ１３０を用いてエリア中のオブジェクトについての奥行き情報を与えてもよい。 The mobile device 104 further includes a plurality of sensors that obtain information regarding the area 122 in which the mobile device 104 is currently located. The mobile device 104 obtains visual information (image) about the area 122 via one or more imaging sensors such as imaging sensors 124, 126 disposed on the front facing surface 116, for example. The imaging sensors 124 and 126 can be positioned and directed on the front facing surface 116 such that their respective fields of view overlap from a particular distance from the mobile device 104. Thereby, the depth detection of the object in the area 122 positioned in the overlapping visual field region can be performed through multi-view analysis. Alternatively, depth information about the objects in the area may be provided using a depth sensor 130 disposed on the surface 116.
奥行きセンサ１３０は、１つの実施形態では、変調光プロジェクタを用いて正面向き面１１６からエリア１２２へ変調光パターンを投射し、変調光パターンの反射がエリア１２２中のオブジェクトから返ってくると、画像化センサ１２４，１２６の一方または両方を用いてその反射を捕捉する。これらの変調光パターンは、空間変調光パターンまたは時間変調光パターンのいずれかであることができる。捕捉された変調閃光の反射は、本明細書中で「奥行き画像」または「奥行きイメージ」と称される。次に、奥行きセンサ１２０は、奥行きイメージの分析に基づいて、オブジェクトの奥行き、すなわち移動体装置１０４からのオブジェクトの距離、を算出し得る。奥行きセンサ１３０から得た奥行きデータを用いて、画像化センサ１２４，１２６が捕捉した画像データの多視点分析（たとえば、立体視分析）から得た奥行き情報を較正し得る、または他のやり方でこれを増補し得る。これに代えて、多視点分析から得られる奥行き情報の代わりに、奥行きセンサ１３０からの奥行きデータを用いてもよい。移動体装置１０４の電子システムのより詳細な例を図３を参照して以下により詳細に説明する。 In one embodiment, the depth sensor 130 projects a modulated light pattern from the front facing surface 116 onto the area 122 using a modulated light projector, and the reflection of the modulated light pattern returns from an object in the area 122. One or both of the activation sensors 124, 126 are used to capture the reflection. These modulated light patterns can be either spatially modulated light patterns or time modulated light patterns. The reflection of the captured modulated flash is referred to herein as a “depth image” or “depth image”. Next, the depth sensor 120 may calculate the depth of the object, that is, the distance of the object from the mobile device 104, based on the analysis of the depth image. Depth data obtained from the depth sensor 130 can be used to calibrate depth information obtained from multi-view analysis (eg, stereoscopic analysis) of image data captured by the imaging sensors 124, 126, or otherwise. Can be augmented. Instead of this, depth data from the depth sensor 130 may be used instead of the depth information obtained from the multi-view analysis. A more detailed example of the electronic system of the mobile device 104 will be described in more detail below with reference to FIG.
動作の際、移動体装置１０４は、画像化センサ１２４，１２６の一方または両方を介してエリア１２２のイメージを捕捉し、捕捉したイメージを修正するかまたは他のやり方で処理し、処理済みの捕捉イメージを与えて表示装置１０８上に表示する。捕捉イメージの処理は、たとえば、空間的または色フィルタリング、拡張現実（ＡＲ）オーバーレイの追加、対応の仮想現実（ＶＲ）コンテンツへのイメージの現実のコンテンツの変換などを含むことができる。このＡＲまたはＶＲ機能性を提供するために、移動体装置１０４は、特定された座標フレームに対するその現在の６自由度（６ＤＯＦ）の向きおよび位置（本明細書中では総称して「ポーズ（pose）」と称する）の正確な判定に依拠する。このように、ある実施形態では、移動体装置１０４は、画像化センサ１２４，１２６が捕捉したイメージおよび非画像センサデータ（たとえば、慣性センサデータ）も用いて、同時場所およびマッピング（ＳＬＡＭ）プロセス、視覚的走行距離計測法、または他の視覚的マッピングプロセスを用いて、移動体装置１０４の相対的位置／向き、すなわちエリア１２２に対する位置／向き、を判断する。 In operation, the mobile device 104 captures an image of the area 122 via one or both of the imaging sensors 124, 126, modifies or otherwise processes the captured image, and processes the captured capture. An image is given and displayed on the display device 108. Processing the captured image can include, for example, spatial or color filtering, adding augmented reality (AR) overlay, converting the actual content of the image to corresponding virtual reality (VR) content, and the like. In order to provide this AR or VR functionality, the mobile device 104 may have its current six degrees of freedom (6DOF) orientation and position (collectively referred to herein as “pose” relative to the identified coordinate frame. Rely on the accurate determination of)). Thus, in some embodiments, the mobile device 104 also uses the image captured by the imaging sensors 124, 126 and non-image sensor data (eg, inertial sensor data) to perform a simultaneous location and mapping (SLAM) process, Visual odometry or other visual mapping process is used to determine the relative position / orientation of mobile device 104, ie, position / orientation relative to area 122.
従来、移動体装置が新しいエリア（すなわち、特定の移動体装置が以前に入ったことがないエリア）に入ると、移動体装置はエリア学習プロセス（たとえばＳＬＡＭプロセス）を完了して新しいエリアを学習するか、または非視覚的手がかり（たとえばＧＰＳ座標）に依拠して座標フレームに対する移動体装置の現在のポーズを何か示さなければならない。これに対し、視覚的マッピングシステム１００は、エリア中の他の移動体装置が先の探査で提供したクラウドソーシングを活用して、エリアの広範な視覚的マッピングを行なわなくても、エリアに新規の移動体装置が座標フレームに迅速にローカライズできるようにする。この目的のため、ＡＤＦサーバ１０２に接続される移動体装置１０４は、移動体装置１０４がエリア１２２の付近で移動するとＡＤＦ１３２を収集してこれをＡＤＦサーバ１０２にアップロードするように動作する。以下により詳細に説明するように、ＡＤＦ１３２は、移動体装置１０４が検出した空間的特徴の組、空間的特徴の相対的外形、移動体装置のポーズとは実質的に独立したやり方で空間的特徴を記述する空間的特徴に関するさまざまな統計的メタデータ、照明（lighting）条件、または他の一時的な環境条件もしくは装置に特有の条件、ならびに空間的特徴に関連付けられるイメージの捕捉時に慣性管理ユニット（ＩＭＵ）または他の非画像センサから収集されたセンサデータを含む。ＡＤＦサーバ１０２は、ＡＤＦ１３２に含有される情報に基づいて同じエリア（または隣接するエリア）についての複数の移動体装置１０４からのＡＤＦをフィルタリングして合成し、その結果得られた合成ＡＤＦから１つ以上のＬＡＤＦ１３４を生成する。その各々は、エリアまたはその対応のサブエリアの空間的特徴のまばらな点群を表わす。 Traditionally, when a mobile device enters a new area (ie, an area where a particular mobile device has not previously entered), the mobile device completes an area learning process (eg, SLAM process) to learn the new area. Or rely on non-visual cues (eg GPS coordinates) to indicate what the mobile device's current pose is relative to the coordinate frame. On the other hand, the visual mapping system 100 uses the crowdsourcing provided by other mobile devices in the area in the previous exploration, and does not perform extensive visual mapping of the area. Enable mobile devices to quickly localize to coordinate frames. For this purpose, the mobile device 104 connected to the ADF server 102 operates to collect the ADF 132 and upload it to the ADF server 102 as the mobile device 104 moves near the area 122. As will be described in more detail below, the ADF 132 may detect spatial features in a manner that is substantially independent of the set of spatial features detected by the mobile device 104, the relative outer shape of the spatial features, and the pose of the mobile device. Various statistical metadata relating to spatial features describing, lighting conditions, or other transient environmental conditions or equipment-specific conditions, and inertial management unit (when capturing images associated with spatial features) Sensor data collected from IMU) or other non-image sensors. The ADF server 102 filters and synthesizes the ADFs from the plurality of mobile devices 104 for the same area (or adjacent areas) based on the information contained in the ADF 132, and one is obtained from the resultant synthesized ADF. The above LADF 134 is generated. Each of them represents a sparse point cloud of spatial features of an area or its corresponding sub-area.
このように、別の移動体装置１０４が後に新たなエリアに入ると、移動体装置１０４は、エリアに関連付けられるＬＡＤＦについてＡＤＦサーバ１０２に問合せてもよい。この問合せに応答して、ＡＤＦサーバ１０２は、要求を発している移動体装置１０４にＬＡＤＦ１３４を与えてもよい。移動体装置１０４は、エリア１２２のイメージを捕捉し、その中に含有されるある空間的特徴を検出し、かつ検出された空間的特徴およびそれらの相対的外形をＬＡＤＦ１３４が表わす空間的特徴および関連の相対的外形と比較し、閉ループアルゴリズム（loop closure algorithm）の適用などによる空間的特徴の比較に基づいてその現在のポーズをローカライズ（すなわち、その現在のポーズを判断、または以前に判断されたずれたポーズを訂正）し得る。移動体装置１０４はさらに、移動体装置によるＬＡＤＦ１３４の使用に基づいて、移動体装置１０４がＬＡＤＦ１３４の空間的特徴を観察しなかったことを示すフィードバックデータまたは移動体装置１０４がＬＡＤＦ１３４の中にない空間的特徴を観察したことを示すフィードバックデータなどのフィードバックをＡＤＦサーバ１０２に与え得る。 Thus, if another mobile device 104 later enters a new area, the mobile device 104 may query the ADF server 102 for the LADF associated with the area. In response to this inquiry, the ADF server 102 may provide the LADF 134 to the requesting mobile device 104. Mobile device 104 captures an image of area 122, detects certain spatial features contained therein, and the spatial features and associations that LADF 134 represents the detected spatial features and their relative outlines. Localize its current pose based on a comparison of spatial features, such as by applying a loop closure algorithm (ie, determine its current pose, or a previously determined deviation) Correct the pose). The mobile device 104 further includes feedback data indicating that the mobile device 104 did not observe the spatial features of the LADF 134 based on the use of the LADF 134 by the mobile device or a space where the mobile device 104 is not in the LADF 134. Feedback may be provided to the ADF server 102, such as feedback data indicating that the target feature has been observed.
クラウドソーシングによるおよびクラウドベースのＬＡＤＦ１３４の作成、洗練、および配布により、移動体装置１０４は、新しいエリアに入った際に迅速かつ効率的にローカライズできるようになり、およびしたがって時間のかかるエリア学習プロセスを行なう必要性、またはより精度が低くかつ不確実なことが多いＧＰＳセンサもしくは慣性センサからの測定値を用いる必要性を回避する。さらに、ＬＡＤＦ１３４の空間的特徴は、具体的な座標フレームに対して参照され得るので、ＬＡＤＦ１３４を用いる複数の移動体装置１０４は、それらの現在のポーズを共通の座標フレームにローカライズし、これにより複数プレーヤによるゲーム、共有ＡＲまたはＶＲ機能性などの装置ポーズ情報に依拠する機能性について、移動体装置１０４同士の間のより効率的かつ正確な対話が容易になり得る。 The creation, refinement, and distribution of crowdsourced and cloud-based LADFs 134 allows mobile devices 104 to be quickly and efficiently localized when entering a new area, and thus a time-consuming area learning process. It avoids the need to do or the need to use measurements from GPS or inertial sensors that are often less accurate and uncertain. Further, since the spatial features of LADF 134 can be referenced to a specific coordinate frame, multiple mobile devices 104 using LADF 134 localize their current poses to a common coordinate frame, thereby providing multiple More efficient and accurate interaction between mobile devices 104 can be facilitated for functionality that relies on device pose information such as games, shared AR or VR functionality by players.
図２は、本開示の少なくとも１つの実施形態に従う、図１のＡＤＦサーバ１０２の例示的な実現例を示す。描かれる例では、ＡＤＦサーバ１０２は、ネットワークインターフェイス２０２、ＡＤＦデータ記憶２０４、ＬＡＤＦデータ記憶２０６、特徴量データ記憶２０８、ジオリファレンス（幾何補正）（georeference）データ記憶２１０、合成モジュール２１２、ジオリファレンスモジュール２１４、空間的特徴フィルタモジュール２１６、ローカリゼーション生成モジュール２１８、および問合せモジュール２２０を有するコンピューティングシステムを備える。別個のデータ記憶として示されるが、データ記憶２０４，２０６，２０８，２１０のうち１つ以上は、ともに単一のデータ記憶として実現されてもよい。 FIG. 2 illustrates an exemplary implementation of the ADF server 102 of FIG. 1 in accordance with at least one embodiment of the present disclosure. In the depicted example, the ADF server 102 includes a network interface 202, an ADF data store 204, an LADF data store 206, a feature data store 208, a georeference data store 210, a synthesis module 212, a georeference module 214, a computing system having a spatial feature filter module 216, a localization generation module 218, and a query module 220. Although shown as separate data stores, one or more of the data stores 204, 206, 208, 210 may both be implemented as a single data store.
モジュール２１２，２１４，２１６，２１８，２２０は、ハードコード化された論理（たとえば、特定用途向け集積回路またはプログラマブル論理）、メモリ２２６もしくは他の記憶装置に記憶されるソフトウェア命令２２４を実行する１つ以上のプロセッサ２２２、またはその組合せとして実現されてもよい。さらに、図示の容易のために単一のサーバとして描かれるが、代わりに、ＡＤＦサーバ１０２は複数のサーバを備えるコンピューティングシステムとして実現されてもよい。たとえば、モジュール２１２，２１４，２１６および２１８の機能性を１つのサーバで実現してもよく、問合せモジュール２２０およびＬＡＤＦデータ記憶２０６の機能性を別のサーバで実現してもよい。 Modules 212, 214, 216, 218, 220 execute one hard-coded logic (eg, application specific integrated circuit or programmable logic), software instructions 224 stored in memory 226 or other storage device. You may implement | achieve as the above processor 222 or its combination. Further, although depicted as a single server for ease of illustration, the ADF server 102 may instead be implemented as a computing system comprising multiple servers. For example, the functionality of modules 212, 214, 216, and 218 may be implemented on one server, and the functionality of query module 220 and LADF data store 206 may be implemented on another server.
一般的概要として、合成モジュール２１２は、ネットワークインターフェイス２０２を介して、ＬＡＤＦがそれについてはまだコンパイルしていないエリアに入った１つ以上の移動体装置２３２（図１の移動体装置１０４の１つの実施形態）からＡＤＦ１３２を受信するように動作する。合成モジュール２１２は、移動体装置２３２からの１つ以上のＡＤＦ１３２を合成して合成ＡＤＦデータを生成し、これをＡＤＦデータ記憶２０４に記憶する。ジオリファレンスモジュール２１４は、（たとえば、グーグルインコーポレイテッド（Google（登録商標） Inc.）が提供するストリートビュー（Street View）ツールからのイメージおよび関連のジオリファレンス位置を含有し得る）ジオリファレンスデータ記憶２１０からのジオリファレンス情報を利用して、合成ＡＤＦに地理的参照を与えてもよい。ローカリゼーション生成モジュール２１８は、結果的に得られた合成ＡＤＦデータから１つ以上のＬＡＤＦを生成して、１つ以上のＬＡＤＦをＬＡＤＦデータ記憶２０６の中に記憶しかつインデックス付けして後で取出せるようにする。問合せモジュール２２０は、移動体装置２３４（移動体装置１０４の１つの実施形態）からネットワークインターフェイス２０２を介してＬＡＤＦ要求２３６を受信し、ＬＡＤＦ要求２３６に対応するＬＡＤＦ１３４についてＬＡＤＦデータ記憶２０６を探索し、ＬＡＤＦ１３４を移動体装置２３４に与える。移動体装置２３４は、移動体装置２３４のローカリゼーションのためにＬＡＤＦ１３４を用いる。このローカリゼーションプロセスの際に、移動体装置２３４は、ネットワークインターフェイス２０２を介して、ＬＡＤＦ１３４に対するＬＡＤＦフィードバック２３８をＡＤＦサーバ１０２に与えてもよい。ＡＤＦサーバ１０２は、ＬＡＤＦフィードバック２３８を用いて特徴量データ記憶２０８中のその中に表わされる空間的特徴の特徴量を調整して、特徴量に基づいて空間的特徴を追加するまたは除外することによって、ＬＡＤＦ１３４を洗練してもよい。これらの動作を図４−図１２を参照して以下により詳細に説明する。 As a general overview, the compositing module 212 can communicate via the network interface 202 one or more mobile devices 232 (one of the mobile devices 104 of FIG. 1) that have entered an area in which LADF has not yet been compiled. Operate to receive the ADF 132 from the embodiment. The synthesis module 212 synthesizes one or more ADFs 132 from the mobile device 232 to generate synthesized ADF data and stores it in the ADF data storage 204. The georeference module 214 (e.g., may contain images and associated georeference locations from a Street View tool provided by Google Inc.). Georeference information from can be used to provide a geographic reference to the synthetic ADF. The localization generation module 218 generates one or more LADFs from the resulting synthesized ADF data and stores and indexes one or more LADFs in the LADF data store 206 for later retrieval. Like that. The query module 220 receives the LADF request 236 from the mobile device 234 (one embodiment of the mobile device 104) via the network interface 202, searches the LADF data store 206 for the LADF 134 corresponding to the LADF request 236, and The LADF 134 is provided to the mobile device 234. Mobile device 234 uses LADF 134 for localization of mobile device 234. During this localization process, mobile device 234 may provide LADF feedback 238 for LADF 134 to ADF server 102 via network interface 202. The ADF server 102 uses LADF feedback 238 to adjust the feature quantity of the spatial feature represented therein in the feature quantity data storage 208 and add or exclude spatial features based on the feature quantity. The LADF 134 may be refined. These operations are described in more detail below with reference to FIGS.
注記されるように、移動体装置２３２および２３４は移動体装置１０４の実施形態を表わす。それらのそれぞれの動作上の要件により、ＬＡＤＦを用いてローカリゼーションプロセスを行なう移動体装置２３２は、ＡＤＦアップロードプロセスを行なう移動体装置２３４と同じ能力を必要としないことがある。図示のため、移動体装置２３４は、奥行きセンサ１２０またはステレオカメラ構成を利用して、ＡＤＦを生成するおよびアップロードするプロセスに関連してＳＬＡＭ動作を容易にし得る一方で、移動体装置２３２は典型的に、ローカリゼーションプロセスを容易にするのに奥行きセンサ１２０を要件とせず、単眼カメラ構成しか要件としない。 As noted, mobile devices 232 and 234 represent embodiments of mobile device 104. Due to their respective operational requirements, a mobile device 232 that performs a localization process using LADF may not require the same capabilities as a mobile device 234 that performs an ADF upload process. For illustration, mobile device 234 may utilize depth sensor 120 or a stereo camera configuration to facilitate SLAM operation in connection with the process of generating and uploading ADFs, while mobile device 232 is typically In addition, the depth sensor 120 is not a requirement and only a monocular camera configuration is required to facilitate the localization process.
図３は、本開示の少なくとも１つの実施形態に従う、移動体装置１０４が実現する例示的な処理システム３００を示す。処理システム３００は、ディスプレイ１１８、画像化センサ１２４，１２６、および奥行きセンサ１３０を含む。処理システム３００はさらに、グラフィック処理ユニット（ＧＰＵ３０２）、フレームバッファ３０３および３０５、アプリケーションプロセッサ３０４、ディスプレイコントローラ３０６、システムメモリ３０８、非画像センサの組３１０、およびユーザインターフェイス３１２を含む。ユーザインターフェイス３１２は、タッチ画面３１４、マウス、キーボード、マイク３１６、さまざまなボタンまたはスイッチ、およびさまざまな触覚アクチュエータ３１８などの、ユーザ入力を移動体装置１０４に与えるようにユーザが操作する１つ以上の構成要素を含む。非画像センサの組３１０は、移動体装置１０４の非画像文脈または状態を与えるように用いられるさまざまなセンサのうち任意のものを含むことができる。そのようなセンサの例は、ジャイロスコープ３２１、磁気計３２２、および加速度計３２３のうち１つ以上を備える慣性管理ユニット（ＩＭＵ）３２０を含む。非画像センサはさらに、たとえば、周囲光センサ３２６およびＧＰＳセンサ３２８などのさまざまな無線受信または送信ベースのセンサ、無線ローカルエリアネットワーク（ＷＬＡＮ）インターフェイス３３０、セルラーインターフェイス３３２、ピアツーピア（Ｐ２Ｐ）無線インターフェイス３３４、ならびに近距離無線（ＮＦＣ）インターフェイス３３６を含むことができる。非画像センサは、タッチ画面３１４またはマイク３１６などのユーザインターフェイス３１２のユーザ入力構成要素も含むことができる。 FIG. 3 illustrates an exemplary processing system 300 implemented by the mobile device 104 in accordance with at least one embodiment of the present disclosure. Processing system 300 includes display 118, imaging sensors 124, 126, and depth sensor 130. The processing system 300 further includes a graphics processing unit (GPU 302), frame buffers 303 and 305, an application processor 304, a display controller 306, a system memory 308, a set of non-image sensors 310, and a user interface 312. The user interface 312 may include one or more user-operated to provide user input to the mobile device 104, such as a touch screen 314, mouse, keyboard, microphone 316, various buttons or switches, and various haptic actuators 318. Contains components. Non-image sensor set 310 may include any of a variety of sensors that are used to provide a non-image context or state of mobile device 104. Examples of such sensors include an inertial management unit (IMU) 320 that includes one or more of a gyroscope 321, a magnetometer 322, and an accelerometer 323. Non-image sensors further include, for example, various wireless reception or transmission based sensors such as ambient light sensor 326 and GPS sensor 328, wireless local area network (WLAN) interface 330, cellular interface 332, peer-to-peer (P2P) wireless interface 334, As well as a near field radio (NFC) interface 336. The non-image sensor can also include user input components of a user interface 312 such as a touch screen 314 or a microphone 316.
移動体装置１０４はさらに、その画像処理、場所マッピング、および場所利用プロセスに関連して用いられる情報またはメタデータを記憶するさまざまなデータ記憶３３８へのアクセスを有する。データベース３３８は、移動体装置１０４の画像化センサが捕捉するイメージから同定される２Ｄまたは３Ｄ空間的特徴のメタデータを記憶する空間的特徴データ記憶と、移動体装置１０４が既に探査したエリア１２２（図１）のサブエリアのマッピング情報などのＳＬＡＭベースの情報を記憶するＳＬＡＭデータ記憶と、エリア１２２中の対象のオブジェクトの相対的場所のＣＡＤベースの表示などのＡＲオーバーレイ情報またはＶＲ情報を記憶するＡＲデータ記憶とを含むことができる。データ記憶３３８は、ハードドライブ、固体状態メモリ、または取外し可能記憶媒体（図示せず）などの移動体装置１０４の１つ以上の記憶構成要素で実現されてもよい。 The mobile device 104 further has access to various data stores 338 that store information or metadata used in connection with its image processing, location mapping, and location utilization processes. The database 338 includes a spatial feature data store that stores metadata of 2D or 3D spatial features identified from images captured by the imaging sensor of the mobile device 104, and an area 122 (the mobile device 104 has already explored). SLAM data storage for storing SLAM-based information such as sub-area mapping information of FIG. 1), and AR overlay information or VR information such as CAD-based indication of the relative location of the object of interest in area 122. AR data storage. Data storage 338 may be implemented with one or more storage components of mobile device 104, such as a hard drive, solid state memory, or removable storage medium (not shown).
動作の際、画像化センサ１２４，１２６はエリアのイメージを捕捉し、捕捉されたイメージをフレームバッファ３０３，３０５にバッファする。イメージを元の形態または修正された形態で表示するために、ＧＰＵ３０２は、（たとえば、ＡＲオーバーレイをレンダリングすることによって）捕捉イメージを表示用に処理し、ディスプレイコントローラ３０６は、処理済みのイメージを表示するようにディスプレイ１１８を制御する。さらに、本明細書中に記載のように、移動体装置１０４は、以前にマッピングしていない場所についてのＡＤＦ１３４をアップロードし、以前にマッピングした場所についてのＬＡＤＦをダウンロードし、かつダウンロードされたＬＡＤＦを用いて移動体装置１０４のローカリゼーションを容易にするように動作する。この目的のため、１つ以上のソフトウェアプログラムをシステムメモリ３０８または他の非一時的コンピュータ読出可能媒体に記憶し、アプリケーションプロセッサ３０４およびＧＰＵ３０２のうち一方または両方によって実行して、このＡＤＦ生成およびＬＡＤＦ利用の機能性を提供してもよい。図示の容易のため、図３には、１つ以上のソフトウェアプログラムをＡＤＦ生成プログラム３４２およびＬＡＤＦ処理プログラム３４４として描く。これらのプログラムを、処理システム３００が実行するオペレーティングシステム（ＯＳ）中のスレッドもしくは他のプロセスとして、同じソフトウェアアプリケーションのスレッド、プロセスもしくはサブルーチンとして、または別個に実行されるソフトウェアアプリケーションとして実現してもよい。さらに、ある実施形態では、本明細書中に記載されるプログラム３４２，３４４の機能性の一部または全部をＡＳＩＣ、プログラマブル論理、または他のハードコード化論理を介して実現してもよい。 In operation, the imaging sensors 124, 126 capture an image of the area and buffer the captured image in the frame buffers 303, 305. To display the image in its original or modified form, GPU 302 processes the captured image for display (eg, by rendering an AR overlay), and display controller 306 displays the processed image. The display 118 is controlled to In addition, as described herein, mobile device 104 uploads ADF 134 for previously unmapped locations, downloads LADF for previously mapped locations, and downloads downloaded LADFs. Used to operate to facilitate localization of the mobile device 104. For this purpose, one or more software programs are stored in system memory 308 or other non-transitory computer readable medium and executed by one or both of application processor 304 and GPU 302 to generate this ADF and LADF utilization. Functionality may be provided. For ease of illustration, FIG. 3 depicts one or more software programs as an ADF generation program 342 and an LADF processing program 344. These programs may be implemented as threads or other processes in an operating system (OS) executed by processing system 300, as threads, processes or subroutines of the same software application, or as software applications executed separately. . Further, in some embodiments, some or all of the functionality of the programs 342, 344 described herein may be implemented via ASIC, programmable logic, or other hard-coded logic.
ＡＤＦ生成プログラム３４２は、たとえば、プライバシーフィルタモジュール３４６、空間的特徴検出モジュール３４８、およびＡＤＦアセンブリモジュール３５０を含むことができる。図３に描かれるように、プライバシーフィルタモジュール３４６は、テキストフィルタモジュール３５２および顔フィルタモジュールなどの１つ以上の画像コンテンツフィルタならびにダウンサンプラーモジュール３５６を備えてもよい。ＬＡＤＦ処理プログラム３４４は、たとえば、（空間的特徴検出モジュール３４８であってもよい）空間的特徴検出モジュール３５８、要求モジュール３６０、ローカリゼーションモジュール３６２、およびフィードバックモジュール３６４を含むことができる。ＡＤＦ生成プログラム３４２およびＬＡＤＦ処理プログラム３４４の動作を含む処理システム３００の動作を以下に詳細に説明する。 The ADF generation program 342 can include, for example, a privacy filter module 346, a spatial feature detection module 348, and an ADF assembly module 350. As depicted in FIG. 3, the privacy filter module 346 may include one or more image content filters, such as a text filter module 352 and a face filter module, and a downsampler module 356. The LADF processing program 344 may include, for example, a spatial feature detection module 358 (which may be a spatial feature detection module 348), a request module 360, a localization module 362, and a feedback module 364. The operation of the processing system 300 including the operations of the ADF generation program 342 and the LADF processing program 344 will be described in detail below.
上述のように、移動体装置１０４が未マッピングエリア（すなわち、ＡＤＦサーバ１０２が入手可能なＬＡＤＦを有していないエリア）にある場合、移動体装置１０４はＡＤＦ生成モードで動作してもよい。これにより、移動体装置１０４は未マッピングエリアで検出される空間的特徴を表わすＡＤＦを生成し、当該ＡＤＦをＡＤＦサーバ１０２にアップロードする。しかしながら、当該エリアが既にマッピング済でＡＤＦサーバ１０２が当該エリアについてのＬＡＤＦを有する場合、移動体装置１０４は、代わりに、ＬＡＤＦローカリゼーションモードで動作してもよい。これにより、移動体装置１０４は、ＡＤＦサーバ１０２から当該エリアについてのＬＡＤＦを得て、当該ＬＡＤＦが表わすまばらな点群を用いてローカリゼーションプロセスを行なって移動体装置１０４を当該エリアにローカライズする。 As described above, if the mobile device 104 is in an unmapped area (ie, an area that does not have an LADF available to the ADF server 102), the mobile device 104 may operate in ADF generation mode. As a result, the mobile device 104 generates an ADF representing a spatial feature detected in the unmapped area, and uploads the ADF to the ADF server 102. However, if the area is already mapped and the ADF server 102 has an LADF for the area, the mobile device 104 may instead operate in the LADF localization mode. As a result, the mobile device 104 obtains the LADF for the area from the ADF server 102, performs a localization process using the sparse point cloud represented by the LADF, and localizes the mobile device 104 to the area.
図４は、少なくとも１つの実施形態に従う、これらの動作モードを選択するための例示的な方法４００を示す。説明の容易のため、方法４００を図３の処理システム３００の例示的な文脈で説明する。方法４００は、ブロック４０２で開始する。これにより移動体装置１０４は、移動体装置１０４が以前にマッピングしていないエリアに移動したと判断する。応答して、移動体装置１０４は、ローカリゼーションプロセスまたは運動追跡プロセスを開始する。 FIG. 4 illustrates an example method 400 for selecting these modes of operation in accordance with at least one embodiment. For ease of explanation, the method 400 is described in the exemplary context of the processing system 300 of FIG. The method 400 begins at block 402. Thereby, the mobile device 104 determines that the mobile device 104 has moved to an area that has not been previously mapped. In response, the mobile device 104 initiates a localization process or motion tracking process.
ブロック４０４で、移動体装置１０４は、ＡＤＦサーバ１０２に問合せて、当該エリアについてのＬＡＤＦを入手可能か否かを判断する。図１０−図１２を参照して以下に説明するように、ＡＤＦサーバ１０２は二段階問合せプロセスを実現してもよい。これにより、移動体装置１０４は、エリア中の移動体装置が捕捉したイメージから空間的特徴の組と１つ以上の場所インジケータ（たとえば、ＧＰＳ座標またはＷＬＡＮの基地局識別子または移動体装置１０４が検出する携帯電話基地局）との両者を与え、ＡＤＦサーバ１０２は、ＬＡＤＦデータ記憶２０６に問合せて対応のＬＡＤＦを同定する。 At block 404, the mobile device 104 queries the ADF server 102 to determine whether LADF for the area is available. As described below with reference to FIGS. 10-12, the ADF server 102 may implement a two-stage query process. This allows the mobile device 104 to detect a set of spatial features and one or more location indicators (eg, GPS coordinates or WLAN base station identifier or mobile device 104 from an image captured by the mobile device in the area. The ADF server 102 queries the LADF data storage 206 to identify the corresponding LADF.
ＡＤＦサーバ１０２からＬＡＤＦを入手可能でない場合、当該エリアは、未マッピングの場所と考えられ、したがってブロック４０６で、移動体装置１０４およびＡＤＦサーバ１０２は連携して未マッピングの場所についてＡＤＦ／ＬＡＤＦ生成プロセスを行なう。このプロセスを図５を参照して以下により詳細に説明する。ＡＤＦサーバ１０２からＬＡＤＦを入手可能である場合、当該エリアはマッピング済の場所と考えられ、したがってブロック４０８で、移動体装置１０４およびＡＤＦサーバ１０２は連携してＬＡＤＦローカリゼーションおよび更新プロセスを行なう。これを図６を参照して以下により詳細に説明する。 If the LADF is not available from the ADF server 102, the area is considered an unmapped location, so at block 406, the mobile device 104 and the ADF server 102 work together to create an ADF / LADF generation process for the unmapped location. To do. This process is described in more detail below with reference to FIG. If LADF is available from the ADF server 102, the area is considered a mapped location, so at block 408 the mobile device 104 and the ADF server 102 work together to perform the LADF localization and update process. This will be described in more detail below with reference to FIG.
図５は、少なくとも１つの実施形態に従う、ＡＤＦ／ＬＡＤＦ生成プロセスを実現するための例示的な方法５００を示す。以上注記したように、ＡＤＦ／ＬＡＤＦ生成プロセスは、移動体装置１０４が新たに遭遇するエリアについてのＬＡＤＦを入手可能でないという判断に応答して行なわれる。これに応じて、エリア記述データの受動的収集についてのユーザの同意を受信した後に、方法５００は、ブロック５０２で、移動体装置１０４のセンサを用いてエリア学習プロセスを開始することから開始する。エリア学習プロセスを行なうために、移動体装置１０４は、画像化センサ１２４，１２６を介してイメージ３７２（図３）を捕捉し、移動体装置１０４が当該エリアを通って移動すると奥行きセンサ１３０を介して対応の奥行き情報３７３を捕捉する。移動体装置１０４は、移動体装置１０４がイメージ３７２および奥行き情報３７３を捕捉すると、たとえば対話型ゲームを用いて、当該エリアを探査するよう移動体装置１０４のユーザを誘導してもよい。 FIG. 5 illustrates an example method 500 for implementing an ADF / LADF generation process in accordance with at least one embodiment. As noted above, the ADF / LADF generation process is performed in response to a determination that LADF is not available for an area that the mobile device 104 encounters anew. In response, after receiving user consent for passive collection of area description data, the method 500 begins at block 502 by initiating an area learning process using the mobile device 104 sensor. To perform the area learning process, the mobile device 104 captures the image 372 (FIG. 3) via the imaging sensors 124, 126, and via the depth sensor 130 as the mobile device 104 moves through the area. The corresponding depth information 373 is captured. Mobile device 104 may guide the user of mobile device 104 to explore the area, for example using an interactive game, when mobile device 104 captures image 372 and depth information 373.
同時に、ＡＤＦアセンブリモジュール３５０は、非画像センサの組３１０のうち１つ以上から非画像センサデータ３７４（図３）を捕捉する。図示のため、ＡＤＦアセンブリモジュール３５０は、イメージ３７２の捕捉の間、加速度計３２３からセンサデータを捕捉して、したがってイメージ捕捉の際の重力に対する移動体装置１０４の向きを表わしてもよい。同様に、ジャイロスコープ３２１から捕捉したセンサデータを用いて、捕捉したイメージ中に表わされる視覚的特徴に対する移動体装置１０４の移動の方向を判断してもよい。さらに、非画像センサデータ３７４は、移動体装置１０４の場所インジケータとして動作し得るセンサデータを含んでもよい。これらの場所インジケータは、ＧＰＳセンサ３２８が与えるセンサデータ中に表わされる緯度／経度座標などのジオリファレンス済の場所インジケータであってもよい。これに代えて、これらの場所インジケータは、推量（inferred）場所インジケータであってもよい。図示のため、ＷＬＡＮ基地局および携帯電話基地局は固定されていると推定されるので、ＷＬＡＮ基地局または携帯電話基地局の検出は、移動体装置が検出された基地局に近接していることを示すものとして働き、したがって基地局識別子（ＢＳＩＤ）、メディアアクセス制御（ＭＡＣ）アドレス、または基地局の他の識別子は移動体装置の推量場所インジケータとして働くことができる。 At the same time, the ADF assembly module 350 captures non-image sensor data 374 (FIG. 3) from one or more of the non-image sensor set 310. For illustration purposes, the ADF assembly module 350 may capture sensor data from the accelerometer 323 during acquisition of the image 372 and thus represent the orientation of the mobile device 104 with respect to gravity during image acquisition. Similarly, sensor data captured from the gyroscope 321 may be used to determine the direction of movement of the mobile device 104 relative to the visual features represented in the captured image. Further, non-image sensor data 374 may include sensor data that may act as a location indicator for mobile device 104. These location indicators may be georeferenced location indicators such as latitude / longitude coordinates represented in the sensor data provided by the GPS sensor 328. Alternatively, these location indicators may be inferred location indicators. For the sake of illustration, it is assumed that the WLAN base station and the mobile phone base station are fixed. Thus, the base station identifier (BSID), media access control (MAC) address, or other identifier of the base station can serve as a guessing location indicator for the mobile device.
以下に説明するように、捕捉されたイメージ３７２および奥行き情報３７３を用いて空間的特徴の点群を判断し、最終的にこれをＡＤＦサーバ１０２にアップロードする。この点群は画像データそのものではない一方で、点群の密度および他の条件に依存して、未修正の点群を用いて、捕捉されたイメージ３７２中に元々存在するある視覚的内容を再構築することができる可能性がある。たとえば、移動体装置１０４がある文書の特に近くに置かれれば、捕捉された文書のイメージから判断される点群を用いて文書のテキストを再現できる可能性がある。そのため、意図しない視覚的内容の公開を防止するために、プライバシーフィルタモジュール３４６は少なくとも２つのプライバシー管理を実現し得る。 As will be described below, a point cloud of spatial features is determined using the captured image 372 and depth information 373 and is finally uploaded to the ADF server 102. While this point cloud is not image data itself, depending on the density and other conditions of the point cloud, uncorrected point clouds can be used to recreate some visual content originally present in the captured image 372. There is a possibility that it can be built. For example, if the mobile device 104 is placed in particular proximity to a document, the text of the document may be reproducible using a point cloud determined from the captured document image. As such, privacy filter module 346 may implement at least two privacy controls to prevent unintentional disclosure of visual content.
第１のプライバシー管理はブロック５０４で実現される。ここでは、プライバシーフィルタモジュール３４６は、捕捉されたイメージ３７２に対して１つ以上のコンテンツフィルタプロセスを行なって、プライバシー侵害があり得る領域から画像コンテンツを除去する。たとえば、ブロック５０４で、テキストフィルタモジュール３５２はテキストフィルタプロセスを行なってもよい。これにより、ブロック５０２で捕捉された各々の画像は、１つ以上の周知のテキスト認識アルゴリズムを用いてスキャンされ、潜在的にテキストコンテンツを表わす領域が画像の中にあるか否かを判断する。潜在的なテキスト領域として検出された各領域毎に、テキストフィルタモジュール３５２は、たとえば当該領域または隣接する領域の画素との混合動作を行なうことによって、当該領域中の画素値を同じデフォルト画素領域と置き換えることによって、またはさもなければ当該領域の画素値を削除することによってなどして、この領域をぼかしたり削除したりし得る。同様に、ブロック５０４で、顔フィルタモジュール３５４は顔フィルタプロセスを実現してもよい。これにより、各々の捕捉画像を１つ以上の周知の顔認識アルゴリズムを用いてスキャンして、潜在的に人の顔を表わす領域が画像の中にあるか否かを判断し、当該画像をフィルタリングして、各々のそのように同定された領域から画像コンテンツを除去する。このように、イメージを予めフィルタリングして空間的特徴検出の前に潜在的に微妙な視覚的内容を除去するので、結果的に得られた空間的特徴の点群を潜在的に微妙な視覚的内容を再構築するのに用いることはできない。 First privacy management is implemented at block 504. Here, the privacy filter module 346 performs one or more content filtering processes on the captured image 372 to remove image content from areas where there may be privacy violations. For example, at block 504, the text filter module 352 may perform a text filter process. Thus, each image captured at block 502 is scanned using one or more well-known text recognition algorithms to determine if there is an area in the image that potentially represents text content. For each area detected as a potential text area, the text filter module 352 performs a mixing operation with the pixels of the area or an adjacent area, for example, thereby changing the pixel value in the area to the same default pixel area. This area may be blurred or deleted, such as by replacing or otherwise deleting the pixel value of the area. Similarly, at block 504, the face filter module 354 may implement a face filter process. This allows each captured image to be scanned using one or more well-known face recognition algorithms to determine whether there is a potential human face area in the image and to filter that image The image content is then removed from each such identified region. In this way, the image is pre-filtered to remove potentially subtle visual content prior to spatial feature detection, so that the resulting spatial feature point cloud is potentially subtle visual. It cannot be used to reconstruct content.
ブロック５０６で、空間的特徴検出モジュール３４８は、フィルタリングされたイメージを分析して、その中に含有される空間的特徴を検出する。たとえば、スケール不変特徴変換（Scale-Invariant Feature Transform）（ＳＩＦＴ）アルゴリズム、加速ロバスト特徴（Speeded-Up Robust Features）（ＳＵＲＦ）アルゴリズム、階調パッチ（Gray Level Patch）アルゴリズム、勾配場所および向きヒストグラム（Gradient Location and Orientation Histogram）（ＧＬＯＨ）アルゴリズム、ゼルニケモーメント（Zernike Moment）アルゴリズム、２値ロバスト独立基本特徴（Binary Robust Independent Elementary Features）（ＢＲＥＩＦ）アルゴリズム、ＯＲＢ（Oriented BRISK）アルゴリズム、ＢＲＩＳＫ（Binary Robust Invariant Scalable Keypoints）アルゴリズム、ガウシアン差分（Difference of Gaussians）（ＤＯＧ）アルゴリズム、ＦＲＥＡＫ（Fast Retina Keypoint）アルゴリズムなどのさまざまな空間的特徴抽出アルゴリズムのうち任意のものを用いてもよい。空間的特徴検出モジュール３４８は、これらの検出された空間的特徴を空間的特徴データ３７６として与える。図示のため、ＦＲＥＡＫアルゴリズムは、対のうちどちらの画素が明るいか暗いかに基づいて、各々の比較の出力を「０」または「１」にして、画像パッチ内の画素の対を比較できるようにする。ＦＲＥＡＫアルゴリズムでは、５１２回のそのような比較を画像パッチにわたって計算する。その結果は、画像パッチを表わす対応の空間的特徴の長さである５１２の２値のストリングである空間的特徴記述子であり、かつ３Ｄ参照フレーム中の空間的特徴の位置を同定する（ｘ，ｙ，ｚ）ベクトルである。 At block 506, the spatial feature detection module 348 analyzes the filtered image to detect spatial features contained therein. For example, Scale-Invariant Feature Transform (SIFT) algorithm, Speeded-Up Robust Features (SURF) algorithm, Gray Level Patch algorithm, Gradient location and orientation histogram (Gradient Location and Orientation Histogram (GLOH) algorithm, Zernike Moment algorithm, Binary Robust Independent Elementary Features (BREIF) algorithm, ORB (Oriented BRISK) algorithm, BRISK (Binary Robust Invariant Scalable Keypoints) Any of various spatial feature extraction algorithms such as an algorithm, a Gaussian difference (DOG) algorithm, and a FREEAK (Fast Retina Keypoint) algorithm may be used. Spatial feature detection module 348 provides these detected spatial features as spatial feature data 376. For illustration purposes, the FREEAK algorithm allows each pair of pixels in an image patch to be compared by setting the output of each comparison to "0" or "1" based on which pixel in the pair is lighter or darker To do. In the FREEK algorithm, 512 such comparisons are calculated across the image patch. The result is a spatial feature descriptor that is a binary string of 512, the length of the corresponding spatial feature representing the image patch, and identifies the location of the spatial feature in the 3D reference frame (x , Y, z) vector.
さらに、空間的特徴検出モジュール３４８は、検出された各点毎に統計的メタデータ３７８を判断する。統計的メタデータ３７８は、対応のイメージが捕捉されたときに移動体装置１０４の特定の視野角または周囲の照明とは実質的に独立した態様で対応の空間的特徴を記述する。たとえば、統計的メタデータ３７８は、空間的特徴、１つ以上の方向の明るさの勾配（または他の視覚的特徴の勾配）などを表わす画素の明るさの平均偏差および標準偏差を表わす値を備えてもよい。 In addition, the spatial feature detection module 348 determines statistical metadata 378 for each detected point. Statistical metadata 378 describes the corresponding spatial features in a manner that is substantially independent of a particular viewing angle or ambient illumination of the mobile device 104 when the corresponding image is captured. For example, the statistical metadata 378 may include values representing average and standard deviations of pixel brightness representing spatial features, brightness gradients in one or more directions (or gradients of other visual features), and the like. You may prepare.
プライバシーフィルタモジュール３４６は、検出されたテキストおよび顔のコンテンツのイメージを消し、そのため、空間的特徴データ３７６が表わす空間的特徴の元の点群には実質的にテキストおよび顔のコンテンツがなくなっているが、元の点群は依然として、エリアの外観をあるレベルまで元の点群から再構築できるのに十分な空間的特徴密度を有していることがある。このように、第２のプライバシー管理として、ブロック５０８で、プライバシーフィルタモジュール３４６のダウンサンプラーモジュール３５６は、元の点群をダウンサンプリングして、元の点群の空間的特徴の選択されたサブセットしか含有しない空間的特徴のフィルタリング済点群３８０（図３）を生成する。これには、結果的に得られる点群からあるエリアの外観を再構築し得る可能性を低減することと、結果的に得られるフィルタリング済点群３８０を表わすのに必要なデータの量を低減することとの両方の有利がある。ダウンサンプリングのプロセスは、１つ以上のダウンサンプリング判断基準によって制御され得る。たとえば、ある実施形態では、ダウンサンプリングのプロセスは、フィルタリング済点群からの排除のための空間的特徴のランダムな選択、Ｘ番目毎の空間的特徴の除外（Ｘは２よりも大きな整数）、またはフィルタリング済点群に含める最大数以下の空間的特徴の選択を含んでもよい。別の例として、ダウンサンプリングのプロセスは、立方単位（すなわち単位体積）当たり最大数の空間的特徴を特定する最大空間的特徴密度判断基準によって制御されてもよい。たとえば、最大空間的特徴密度判断基準は、フィルタリング済点群３８０が含有する空間的特徴が立方フィート当たり多くても１つであると特定するので、結果的に得られるフィルタリング済点群の中に表わされる空間的特徴が立方フィート当たり１つ以下になるように元の点群をダウンサンプリングし得る。 Privacy filter module 346 erases the image of the detected text and facial content so that the original point cloud of the spatial feature represented by spatial feature data 376 is substantially free of text and facial content. However, the original point cloud may still have sufficient spatial feature density that the area appearance can be reconstructed from the original point cloud to a certain level. Thus, as a second privacy management, at block 508, the downsampler module 356 of the privacy filter module 346 downsamples the original point cloud and only selects a selected subset of the spatial features of the original point cloud. A filtered point cloud 380 (FIG. 3) of spatial features not included is generated. This reduces the likelihood that an area's appearance can be reconstructed from the resulting point cloud, and reduces the amount of data needed to represent the resulting filtered point cloud 380 There are advantages to both. The process of downsampling can be controlled by one or more downsampling criteria. For example, in one embodiment, the downsampling process includes a random selection of spatial features for exclusion from the filtered point cloud, an exclusion of every Xth spatial feature (X is an integer greater than 2), Or it may include selection of no more than the maximum number of spatial features to include in the filtered point cloud. As another example, the downsampling process may be controlled by a maximum spatial feature density criterion that identifies the maximum number of spatial features per cubic unit (ie, unit volume). For example, the maximum spatial feature density criterion specifies that the filtered point cloud 380 contains at most one spatial feature per cubic foot, so that in the resulting filtered point cloud The original point cloud may be downsampled so that the spatial features represented are no more than one per cubic foot.
ブロック５１０で、ＡＤＦアセンブリモジュール３５０は、フィルタリング済点群３８０、統計的メタデータ３７８、および非画像センサデータ３７４を用いてＡＤＦ１３２を生成する。１つの実施形態では、ＡＤＦ１３２は、表わされた空間的特徴の統計的メタデータ３７８を記憶する各多次元座標毎のフィールドとともに、一覧または他の多次元座標の組としてファイルまたはフィルタリング済点群３８０を表わす他のデータ構造を備える。図示のため、各々の多次元座標は、移動体装置１０４の（Ｘ，Ｙ，Ｚ）座標フレーム中の対応の空間的特徴の３Ｄ位置を表わす（ｘ，ｙ，ｚ）浮動小数点ベクトルを備えてもよい。データ構造はさらに、以下に説明するように、非画像センサデータ３７４を記憶する１つ以上のフィールドと、ＡＤＦサーバ１０２がＡＤＦ１３２に割当てた一意の識別子（ＵＩＤ）を記憶するフィールドとを含んでもよい。 At block 510, ADF assembly module 350 generates ADF 132 using filtered point cloud 380, statistical metadata 378, and non-image sensor data 374. In one embodiment, the ADF 132 is a file or filtered point cloud as a list or other set of multidimensional coordinates, with a field for each multidimensional coordinate that stores statistical metadata 378 of the represented spatial features. Other data structures representing 380 are provided. For illustration, each multidimensional coordinate comprises a (x, y, z) floating point vector that represents the 3D position of the corresponding spatial feature in the (X, Y, Z) coordinate frame of the mobile device 104. Also good. The data structure may further include one or more fields that store non-image sensor data 374 and a field that stores a unique identifier (UID) assigned by the ADF server 102 to the ADF 132, as described below. .
ブロック５１２で、ＡＤＦアセンブリモジュール３５０は、ＡＤＦサーバ１０２への送信用の適切なネットワークインターフェイス（たとえば、セルラーインターフェイス３３２またはＷＬＡＮインターフェイス３３０）にＡＤＦ１３２を与える。ある実施形態では、ＡＤＦアセンブリモジュール３５０は、ＡＤＦサーバ１０２に、ＡＤＦをアップロードするように要求を信号で送り、ＡＤＦサーバ１０２は、ＡＤＦがアップロードされる前に、ＡＤＦアセンブリモジュール３５０がＡＤＦ１３２中の適切なフィールドに挿入する、ＡＤＦに割当てられるＵＩＤで応答する。さらに、ブロック５０２−５１２のプロセスを、ＡＤＦ１３２がアップロードされる前にＡＤＦ１３２が完成される順次のプロセスとして説明したが、ある実施形態では、ＡＤＦ１３２は、ＡＤＦブロックのシーケンスとしてＡＤＦ１３２が生成される繰返しプロセスで生成されかつアップロードされる。各々のＡＤＦブロックは、捕捉されたイメージの一部から生成される点群のサブセットを含有し、各々のＡＤＦブロックは、それが生成される際にＡＤＦに割当てられかつＡＤＦサーバ１０２にアップロードされるＵＩＤで標識付けられる。このように、ＡＤＦサーバ１０２はこれらのＡＤＦブロックを個別に記憶してもよく、または同じＵＩＤで示されるＡＤＦブロックを単一のＡＤＦ１３２に組合せてもよい。 At block 512, the ADF assembly module 350 provides the ADF 132 to the appropriate network interface (eg, the cellular interface 332 or the WLAN interface 330) for transmission to the ADF server 102. In some embodiments, the ADF assembly module 350 signals a request to the ADF server 102 to upload the ADF, and the ADF server 102 ensures that the ADF assembly module 350 is in the ADF 132 before the ADF is uploaded. It responds with the UID assigned to the ADF, which is inserted into the correct field. Further, while the process of blocks 502-512 has been described as a sequential process in which ADF 132 is completed before ADF 132 is uploaded, in one embodiment, ADF 132 is an iterative process in which ADF 132 is generated as a sequence of ADF blocks. Generated and uploaded. Each ADF block contains a subset of the point cloud generated from a portion of the captured image, and each ADF block is assigned to the ADF and uploaded to the ADF server 102 when it is generated. Labeled with a UID. In this way, the ADF server 102 may store these ADF blocks individually or may combine ADF blocks indicated by the same UID into a single ADF 132.
移動体装置１０４がアップロードするＡＤＦ１３２は、移動体装置１０４が位置するエリア中に存在するある視覚的特徴を表わす。しかしながら、ブロック５０４および５０８を参照して上述したような移動体装置１０４が実現するプライバシー管理を通じて、ＡＤＦサーバ１０２に与えられるＡＤＦ１３２に含有される情報には実質的に、プライバシー侵害になり得る一切の内容がない。むしろ、結果的に得られるＡＤＦ１３２は、別の移動体装置がこれらの記述された視覚的特徴に基づいて後で実質的にローカライズできるのに十分な程度に当該エリアのさまざまな端縁、角、および他の視覚的特徴を記述し得るまばらな点群を含有する一方で、まばらな点群が含有する情報は、人間の知覚に有意義なようにエリアの外観の複製を支援するには不十分である。そのため、ＡＤＦサーバ１０２は、マッピング済のエリアに関する潜在的に微妙な情報を暴露する測り得る潜在性を有する移動体装置１０４からの一切の情報の所有に至ることはない。 The ADF 132 uploaded by the mobile device 104 represents certain visual features present in the area where the mobile device 104 is located. However, through privacy management implemented by the mobile device 104 as described above with reference to blocks 504 and 508, the information contained in the ADF 132 that is provided to the ADF server 102 is substantially free of any privacy infringement. There is no content. Rather, the resulting ADF 132 has different edges, corners, corners of the area, sufficient to allow another mobile device to be subsequently localized based on these described visual features. And sparse point clouds that can describe other visual features, while the information contained in the sparse point clouds is insufficient to help replicate the appearance of the area as meaningful to human perception It is. As such, the ADF server 102 does not result in possession of any information from the mobile device 104 that has a measurable potential to expose potentially sensitive information about the mapped area.
ＡＤＦ／ＬＡＤＦ生成プロセスにおけるＡＤＦサーバ１０２の役割は、ブロック５１４で、ネットワークインターフェイス２０２を介した移動体装置１０４からのＡＤＦ１３２の、合成モジュール２１２による受信で開始する。ＡＤＦ１３２を受信すると、合成モジュール２１２は一時的にＡＤＦデータ記憶２０４中にＡＤＦ１３２をインデックス付けして記憶する。ＡＤＦ１３２は、ＡＤＦ１３２に割当てられたＵＩＤに基づいて、ＡＤＦ１３２が表わす点群に表わされる空間的特徴に基づいて、ＡＤＦ１３２とともに含まれる場所インジケータに基づいてなど、インデックス付けされて一時的に記憶されてもよい。少なくとも１つの実施形態では、各々のＡＤＦ１３２は、図１０−図１２を参照して以下に説明する２層問合せ方策を用いて、ＡＤＦデータ記憶２０４中に記憶されインデックス付けされる。 The role of the ADF server 102 in the ADF / LADF generation process begins at block 514 with receipt by the synthesis module 212 of the ADF 132 from the mobile device 104 via the network interface 202. Upon receipt of ADF 132, synthesis module 212 temporarily indexes and stores ADF 132 in ADF data store 204. The ADF 132 may be temporarily indexed and stored, such as based on the UID assigned to the ADF 132, based on the spatial features represented in the point cloud represented by the ADF 132, based on the location indicator included with the ADF 132, etc. Good. In at least one embodiment, each ADF 132 is stored and indexed in the ADF data store 204 using a two-layer query strategy described below with reference to FIGS. 10-12.
ある事例では、複数の移動体装置は、あるエリアについてまたは隣接するエリアについての対応のＡＤＦをアップロードしたかもしれない。このように、ＡＤＦサーバ１０２は、ブロック５１６で、得られる合成ＡＤＦを１つ以上のＬＡＤＦに処理する前に、これらのともに位置する（co-located）ＡＤＦを合成するように動作する。ブロック５１６の合成プロセスは、さまざまなトリガのうち任意のものに応答して開始されてもよい。たとえば、合成プロセスは、特定された量の時間の経過、移動体装置からの特定された数のＡＤＦの受信、移動体装置からのＬＡＤＦに対する要求などによってトリガされてもよい。そのようなトリガに応答して、ブロック５１８で、合成モジュール２１２は問合せモジュール２２０に信号を送ってＡＤＦデータ記憶２０４に問合せて、「近隣の」ＡＤＦ−すなわち同じエリアまたは隣接するエリアをカバーするＡＤＦ−があるか否かを同定する。ある実施形態では、近隣のＡＤＦは、ＡＤＦデータ記憶２４０中のＡＤＦに関連付けられる場所インジケータの比較に基づいて同定されてもよい。たとえば、移動体装置１０４からのＡＤＦ１３２のアップロードが合成プロセスをトリガし、アップロードされたＡＤＦ１３２が場所インジケータとして１つ以上のＷＬＡＮ ＭＡＣアドレスを含むと仮定すると、アップロードされたＡＤＦとともに、またはアップロードされたＡＤＦが同定するＷＬＡＮ基地局がカバーするエリアに隣接するとわかっているＷＬＡＮ基地局のＷＬＡＮ ＭＡＣアドレスとともに供給されるのと同じＷＬＡＮ ＭＡＣアドレスを有すると問合せモジュール２２０が同定するＡＤＦデータ記憶２４０中のそれらのＡＤＦが近隣のＡＤＦとして同定される。別の例として、アップロードされたＡＤＦには、場所インジケータとしてＧＰＳ座標が与えられてもよく、問合せモジュール２２０は、それらの対応のＧＰＳ座標に基づいてＡＤＦデータ記憶２４０中のＡＤＦを近隣のものと同定してもよい。他の実施形態では、アップロードされたＡＤＦ中に表わされる空間的特徴とＡＤＦデータ記憶２４０中に記憶されるＡＤＦに表わされる空間的特徴との比較に基づいて、近隣のＡＤＦを同定してもよい。このように、十分に重なり合う空間的特徴の組を有するＡＤＦを同じエリアまたは近隣のエリアを表わすと同定してもよく、したがって近隣のＡＤＦとして同定してもよい。またさらに、図１０−図１２を参照して以下に説明するように、ＡＤＦサーバ１０２は、ＡＤＦデータ記憶２０４およびＬＡＤＦデータ記憶２０６のうち一方または両方について２層問合せを実現してもよく、これにより、各々の記憶されたＡＤＦ／ＬＡＤＦがその空間的特徴の組と１つ以上の場所インジケータとの両方に基づいてインデックス付けされて記憶され、アップロードされたＡＤＦの空間的特徴の組とアップロードされたＡＤＦの１つ以上の場所インジケータとの両方を用いて２層インデックス付けプロセスを行なうことによって近隣のＡＤＦが同定される。 In some cases, multiple mobile devices may have uploaded corresponding ADFs for an area or for an adjacent area. Thus, the ADF server 102 operates at block 516 to synthesize the co-located ADFs before processing the resulting synthesized ADFs into one or more LADFs. The synthesis process of block 516 may be initiated in response to any of various triggers. For example, the compositing process may be triggered by a specified amount of time elapsed, receipt of a specified number of ADFs from the mobile device, a request for LADF from the mobile device, etc. In response to such a trigger, at block 518, the synthesis module 212 signals the query module 220 to query the ADF data store 204 to “neighbor” ADF—that is, an ADF that covers the same or adjacent area. -Identify whether there is. In some embodiments, neighboring ADFs may be identified based on a comparison of location indicators associated with ADFs in ADF data store 240. For example, assuming that the upload of ADF 132 from mobile device 104 triggers the compositing process, and uploaded ADF 132 includes one or more WLAN MAC addresses as location indicators, either with uploaded ADF or with uploaded ADF Those in the ADF data store 240 that the query module 220 identifies as having the same WLAN MAC address supplied with the WLAN MAC address of the WLAN base station known to be adjacent to the area covered by the WLAN base station ADFs are identified as neighboring ADFs. As another example, uploaded ADFs may be provided with GPS coordinates as location indicators, and query module 220 may identify ADFs in ADF data store 240 as neighbors based on their corresponding GPS coordinates. You may identify. In other embodiments, neighboring ADFs may be identified based on a comparison of the spatial features represented in the uploaded ADF and the spatial features represented in the ADF stored in the ADF data store 240. . In this way, ADFs with a sufficiently overlapping set of spatial features may be identified as representing the same area or neighboring areas, and thus may be identified as neighboring ADFs. Still further, as will be described below with reference to FIGS. 10-12, the ADF server 102 may implement a two-layer query for one or both of the ADF data store 204 and the LADF data store 206. Each stored ADF / LADF is indexed and stored based on both its spatial feature set and one or more location indicators, and uploaded with the uploaded ADF spatial feature set. Neighboring ADFs are identified by performing a two-layer indexing process using both the ADF and one or more location indicators.
問合せモジュール２２０が同定する１つ以上の近隣のまたはともに位置するＡＤＦの組を本明細書中では「ＡＤＦクラスタ」と称する。ＡＤＦクラスタが同定されると、ブロック５２０で、合成モジュール２１２は、ＡＤＦクラスタのＡＤＦ中に表わされる重複した空間的特徴を除外する１つ以上の重複排除（deduplication）プロセスを行なうように動作する。さらに、ＡＤＦクラスタが過度に大きなエリアを表わすかまたは過度に多数の空間的特徴を含有する場合、合成モジュール２１２は、ＡＤＦクラスタを１つ以上のより小さなＡＤＦクラスタに分割してもよく、その各々を本明細書中に記載のように処理してもよい。ブロック５２２で、合成モジュール２１２は、１つ以上の周知の閉ループアルゴリズムを用いてＡＤＦクラスタのＡＤＦ同士の間の相対的な整列を判断する。ブロック５２４で、合成モジュール２１２はＡＤＦクラスタを分析して、１つ以上の安定性判断基準を用いて同定されるようなＡＤＦクラスタのＡＤＦの大部分またはすべてにおいて観察されないことが確実な空間的特徴を選択的に除外する。これは、エリアの永久的視覚的特徴を表わしそうにない空間的特徴（およびしたがってローカリゼーションの不確実な源）を排除することと、ＡＤＦクラスタが表わす組合された点群中の空間的特徴の合計数を減らすこととの両方の目的を果たす。除外すべき空間的特徴を選択するにあたり、合成モジュール２１２は、空間的特徴量がＡＤＦクラスタのＡＤＦ内に観察される頻度に基づいて空間的特徴量を与えることなどによって、安定性判断基準に基づくスコア付けシステムを用いてもよい。さらに、ＡＤＦが新しいほどエリアの現在の状態をより表わしやすいので、合成モジュール２１２は、より新しいＡＤＦ中の空間的特徴が優先的に含有されるようにしてもよい。 A set of one or more neighboring or co-located ADFs identified by the query module 220 is referred to herein as an “ADF cluster”. Once the ADF cluster is identified, at block 520, the synthesis module 212 operates to perform one or more deduplication processes that exclude duplicate spatial features represented in the ADF of the ADF cluster. Further, if the ADF cluster represents an excessively large area or contains an excessive number of spatial features, the synthesis module 212 may divide the ADF cluster into one or more smaller ADF clusters, each of which May be processed as described herein. At block 522, the synthesis module 212 determines the relative alignment between the ADFs of the ADF cluster using one or more well-known closed loop algorithms. At block 524, the synthesis module 212 analyzes the ADF cluster to ensure that it is not observed in most or all of the ADFs of the ADF cluster as identified using one or more stability criteria. Is selectively excluded. This eliminates spatial features that are unlikely to represent the permanent visual features of the area (and thus uncertain sources of localization) and the sum of the spatial features in the combined point cloud that the ADF cluster represents It serves both the purpose of reducing the number. In selecting the spatial features to exclude, the synthesis module 212 is based on stability criteria, such as by providing spatial features based on the frequency with which spatial features are observed in the ADF of the ADF cluster. A scoring system may be used. Furthermore, since the newer the ADF, the easier it is to represent the current state of the area, the synthesis module 212 may preferentially contain the spatial features in the newer ADF.
ある事例では、ＡＤＦとともに供給される非画像センサデータ３７４は、ＡＤＦがジオリファレンスされるのを可能にしてもよい。たとえば、非画像センサデータ３７４は、ＡＤＦ中の空間的特徴の検出の際に、ＧＰＳ座標および移動体装置１０４のジオリファレンス済のポーズのインジケータを含んでもよい。ブロック５２２で判断されるＡＤＦクラスタのＡＤＦの相対的整列により、ＡＤＦクラスタ中の１つのＡＤＦがジオリファレンスされると、ブロック５２６で、ＡＤＦクラスタ中の他のクラスタを、ジオリファレンス済のＡＤＦの相対的整列および測位位置（ジオロケーション）情報を用いた座標フレーム変換の適用によってジオリファレンスし得る。さらに、グーグルインコーポレイテッドが提供するストリートビューツールなどを介してジオリファレンス済の視覚的参照データを入手可能である場合、このジオリファレンス済の視覚的参照データを用いてＡＤＦクラスタのＡＤＦをジオリファレンスしてもよい。 In some cases, non-image sensor data 374 supplied with the ADF may allow the ADF to be georeferenced. For example, the non-image sensor data 374 may include GPS coordinates and a georeferenced pose indicator of the mobile device 104 upon detection of spatial features in the ADF. When one ADF in the ADF cluster is georeferenced due to the relative alignment of the ADF clusters determined in block 522, the other cluster in the ADF cluster is compared to the georeferenced ADF in block 526. It can be georeferenced by applying coordinate frame transformation with global alignment and positioning (geolocation) information. In addition, if the georeferenced visual reference data is available through the street view tool provided by Google Inc., etc., the ADF of the ADF cluster can be georeferenced using this georeferenced visual reference data. May be.
ＡＤＦクラスタのＡＤＦが合成されると、ブロック５２８で、ローカリゼーション生成モジュール２１８は、合成ＡＤＦを用いて、合成ＡＤＦが表わすエリアについての１つ以上のＬＡＤＦを生成する。合成ＡＤＦのデータサイズが十分に小さいかまたはカバーするエリアが十分に小さい場合、合成ＡＤＦを単一のＬＡＤＦとして記憶しインデックス付けしてもよい。しかしながら、合成ＡＤＦのデータサイズがしきい値を超える、合成ＡＤＦがあまりに大きなエリアをカバーする、またはエリアが（ＡＤＦの点群中の壁、仕切り、扉、および窓を介して同定されるような）複数の別個のサブエリアを含有する場合には、ローカリゼーション生成モジュール２１８は、合成ＡＤＦを空間的に仕切って、各々が異なるサブエリアをカバーする複数のＬＡＤＦを生成してもよい。そのような事例では、ローカリゼーション生成モジュール２１８は、合成ＡＤＦが表わす点群内の壁または他の部屋分割物の検出に基づいてエリア内の複数の部屋を同定することなどによって、論理的仕切り線を同定して、各々の同定された部屋毎に別個のＬＡＤＦを作成しようとしてもよい。このことには、ＬＡＤＦの範囲を単一の部屋に限定するというプライバシーの観点からの付加的な有利がある。 Once the ADFs of the ADF clusters are combined, at block 528, the localization generation module 218 uses the combined ADF to generate one or more LADFs for the area represented by the combined ADF. If the data size of the synthetic ADF is small enough or the area covered is small enough, the synthetic ADF may be stored and indexed as a single LADF. However, the data size of the synthetic ADF exceeds a threshold, the synthetic ADF covers a too large area, or the area is identified through walls, dividers, doors, and windows in the ADF point cloud If it contains multiple separate subareas, the localization generation module 218 may spatially partition the synthetic ADF to generate multiple LADFs, each covering a different subarea. In such cases, the localization generation module 218 may define logical dividers, such as by identifying multiple rooms within an area based on the detection of walls or other room partitions within the point cloud represented by the composite ADF. Identification may attempt to create a separate LADF for each identified room. This has the additional advantage from a privacy point of view of limiting the scope of LADF to a single room.
生成された各ＬＡＤＦ毎に、ブロック５３０で、ローカリゼーション生成モジュール２１８は、ＬＡＤＦをＬＡＤＦデータ記憶２０６に与えてインデックス付けし、記憶する。以上に注記されるようにかつ以下に詳細に説明するように、ある実施形態では、ＬＡＤＦデータ記憶２０６は、各々のＬＡＤＦ毎の２層インデックスを用いる。これにより、各々のＬＡＤＦを、１つ以上の場所の印とＬＡＤＦが表わす空間的特徴との両方でインデックス付けする。そのため、ＬＡＤＦデータ記憶２０６中にＬＡＤＦを記憶する場合に、ＬＡＤＦデータ記憶２０６は、その場所インジケータまたはその空間的特徴の組（およびその中の相対的外形）の一方でインデックス付けされるデータ記憶エントリ中にＬＡＤＦを記憶し、場所インジケータまたは空間的特徴の組の他方を、同様にインデックス付けされる複数のＬＡＤＦを選択するように用いる。 For each generated LADF, at block 530, the localization generation module 218 provides the LADF to the LADF data store 206 for indexing and storage. As noted above and described in detail below, in one embodiment, the LADF data store 206 uses a two-layer index for each LADF. This indexes each LADF with both one or more place marks and the spatial features that it represents. Thus, when storing LADF in LADF data store 206, LADF data store 206 is a data storage entry that is indexed by either its location indicator or its set of spatial features (and its relative outlines). The LADF is stored in and the other of the location indicator or set of spatial features is used to select multiple LADFs that are similarly indexed.
方法５００のブロック５３０でのプロセスが終わると、ＡＤＦサーバ１０２は、エリアを探査する機会があった１つ以上の移動体装置１０４からアップロードされた１つ以上のＡＤＦを用いて、以前にマッピングしていないエリアについて１つ以上のＬＡＤＦを生成している。このように、ＡＤＦサーバ１０２は、以下の図６によって説明するように、このエリアに初めて遭遇する任意の他の移動体装置にＬＡＤＦを供給する準備が整う。 Upon completion of the process at block 530 of method 500, ADF server 102 previously mapped using one or more ADFs uploaded from one or more mobile devices 104 that had the opportunity to explore the area. One or more LADFs are generated for an area that is not. Thus, the ADF server 102 is ready to supply LADF to any other mobile device that encounters this area for the first time, as described by FIG. 6 below.
図６は、少なくとも１つの実施形態に従う、図４のブロック４０８が表わすＬＡＤＦローカリゼーションおよび更新プロセスを行なうための例示的な方法６００を示す。方法６００はブロック６０２で開始し、移動体装置１０４は、移動体装置１０４が以前に遭遇したことがない未マッピングのエリアに入る。この判断に応答して、移動体装置は、当該エリアについての空間的特徴検出プロセスを開始する。この目的のため、移動体装置１０４は、画像化センサ１２４，１２６をトリガしてエリアのイメージ３８２（図３）の捕捉を始め、かつ奥行きセンサ１３０をトリガしてエリアについての奥行き情報の捕捉を始め、空間的特徴検出モジュール３５８は、イメージ３８２および奥行き情報からエリアを表わす初期の空間的特徴の組を検出する。ブロック６０４で、要求モジュール３６０は、エリア中の空間的特徴の検出の際に移動体装置１０４の場所についての１つ以上の場所インジケータを判断する。以上注記したように、これらの場所インジケータは、ＧＰＳセンサ３２８から得たＧＰＳ座標、ＷＬＡＮ ＭＡＣアドレス、ＷＬＡＮ ＢＳＩＤ、もしくは携帯電話基地局ＢＳＩＤなどの推量的場所インジケータ、またはその組合せなどの具体的な地理的場所インジケータであってもよい。ブロック６０６で、要求モジュール３６０は、初期の空間的特徴の組および１つ以上の場所インジケータを用いてＬＡＤＦ要求２３６を生成し、ＬＡＤＦ要求２３６を送信して、エリアについてのＬＡＤＦの入手可能性についての問合せを開始する。 FIG. 6 illustrates an exemplary method 600 for performing the LADF localization and update process represented by block 408 of FIG. 4, in accordance with at least one embodiment. The method 600 begins at block 602 where the mobile device 104 enters an unmapped area that the mobile device 104 has not previously encountered. In response to this determination, the mobile device initiates a spatial feature detection process for the area. For this purpose, the mobile device 104 triggers the imaging sensors 124, 126 to begin capturing an image 382 of the area (FIG. 3) and triggers the depth sensor 130 to capture depth information about the area. Initially, the spatial feature detection module 358 detects an initial set of spatial features representing an area from the image 382 and depth information. At block 604, the request module 360 determines one or more location indicators for the location of the mobile device 104 upon detection of a spatial feature in the area. As noted above, these location indicators may be specific geography such as GPS coordinates obtained from GPS sensor 328, WLAN MAC address, WLAN BSID, or a probable location indicator such as mobile phone base station BSID, or a combination thereof. It may be a target location indicator. At block 606, the request module 360 generates an LADF request 236 using the initial set of spatial features and one or more location indicators and sends the LADF request 236 for LADF availability for the area. Start the query.
ネットワークインターフェイス２０２を介したＡＤＦサーバ１０２の問合せモジュール２２０でのＬＡＤＦ要求２３６の受信に応答して、ブロック６０８で、問合せモジュール２２０は、ＬＡＤＦデータ記憶２０６に問合せて、移動体装置１０４が用いる、エリアについての好適なＬＡＤＦを同定する。少なくとも１つの実施形態では、問合せモジュール２２０およびＬＡＤＦデータ記憶２０６は、図１０−図１２を参照して以下に詳細に説明するように、２層インデックス付け方式を用いて、初期の空間的特徴の組と場所インジケータとの両方に基づいて好適なＬＡＤＦを同定する。好適なＬＡＤＦが同定されると仮定すると、ブロック６１０で、問合せモジュール２２０は、要求を発している移動体装置１０４に（ＬＡＤＦ１３４として）選択されたＬＡＤＦを送信する。 In response to receipt of the LADF request 236 at the query module 220 of the ADF server 102 via the network interface 202, at block 608, the query module 220 queries the LADF data store 206 to use the area used by the mobile device 104. Identify a suitable LADF for. In at least one embodiment, the query module 220 and the LADF data store 206 use a two-layer indexing scheme, as described in detail below with reference to FIGS. A suitable LADF is identified based on both the tuple and the location indicator. Assuming that a suitable LADF is identified, at block 610, the query module 220 sends the selected LADF (as LADF 134) to the requesting mobile device 104.
ＬＡＤＦ要求２３６に応答したＬＡＤＦ１３４の受信に応答して、要求モジュール３６０は、ＬＡＤＦ１３４をローカリゼーションモジュール３６２とフィードバックモジュール３６４との両方に与える。ブロック６１２で、ローカリゼーションモジュール３６２は、１つ以上の周知の閉ループアルゴリズムを用いて、ＬＡＤＦ１３４中に表わされる空間的特徴のまばらな点群に対する空間的特徴検出モジュール３５８が検出したエリアからの空間的特徴の比較に基づいて、移動体装置１０４をＬＡＤＦ１３４に表わされる座標フレームにローカライズする。その結果は、同定された座標フレーム中の移動体装置１０４の判断ポーズ３８４（図３）である。さらに、ＬＡＤＦをジオリファレンスすることができた場合、判断されたポーズ３８４を同様に適切な変換を通じてジオリファレンスしてもよい。移動体装置１０４がローカライズされポーズ３８４が判断されると、ブロック６１４で、移動体装置１０４の１つ以上の構成要素は、ＡＲまたはＶＲコンテンツ、複数プレーヤによるゲーム、ナビゲーションツールなどの実現例などの正確なポーズ情報に依拠するさまざまな機能性を提供し得る。 In response to receiving LADF 134 in response to LADF request 236, request module 360 provides LADF 134 to both localization module 362 and feedback module 364. At block 612, the localization module 362 uses one or more well-known closed loop algorithms to detect spatial features from the areas detected by the spatial feature detection module 358 for sparse point clouds of spatial features represented in the LADF 134. Based on these comparisons, the mobile device 104 is localized into a coordinate frame represented by the LADF 134. The result is a determination pose 384 (FIG. 3) of the mobile device 104 in the identified coordinate frame. Further, if the LADF can be georeferenced, the determined pose 384 may be georeferenced through an appropriate transformation as well. Once the mobile device 104 is localized and the pose 384 is determined, at block 614, one or more components of the mobile device 104 may include AR or VR content, multiplayer games, navigation tool implementations, etc. A variety of functionality can be provided that relies on accurate pose information.
ＬＡＤＦ１３４の生成は、１つ以上の移動体装置１０４がエリアで観察した空間的特徴の検出および選択に依拠する。しかしながら、エリアは観察された空間的特徴に含まれる過渡的なオブジェクトを有することがあるまたはエリアの構成は時間とともに変化することがあるので、ＬＡＤＦ１３４が有用でなくなるまたは「古くなる」ことがある。そのため、ある実施形態では、ユーザの許可により、移動体装置１０４は、ＬＡＤＦに対するフィードバックを与えてもよく、これをＡＤＦサーバ１０２が用いて他の移動体装置によるその後の使用のためにＬＡＤＦを洗練または「リフレッシュ」してもよい。この目的のため、ブロック６１６で、フィードバックモジュール３６４は、空間的特徴検出モジュール３５８が同定したエリア中の空間的特徴を、ＬＡＤＦ１３４が表わすまばらな点群の空間的特徴と比較して、空間的特徴検出モジュール３５８も観察したＬＡＤＦ１３４の空間的特徴、空間的特徴検出モジュール３５８が観察しなかったＬＡＤＦ１３４の空間的特徴、および、ＬＡＤＦ１３４中に存在しなかった、空間的特徴検出モジュール３５８が観察した空間的特徴のうち１つ以上を表わすＬＡＤＦフィードバック２３８を生成してもよい。ＬＡＤＦフィードバック２３８はＡＤＦサーバ１０２にアップロードされる。ブロック６１８で、空間的特徴フィルタモジュール２１６は、ＬＡＤＦフィードバック２３８を受信し、これに応じて特徴量データ記憶２０８中の空間的特徴の特徴量を更新し、次に更新された特徴量に基づいて新しい空間的特徴を含めるまたは以前に含まれた空間的特徴を除外するようにＬＡＤＦを更新してもよい。 The generation of LADF 134 relies on the detection and selection of spatial features observed by one or more mobile devices 104 in the area. However, the LADF 134 may become unusable or “stale” because the area may have transient objects included in the observed spatial features or the composition of the area may change over time. Thus, in some embodiments, upon user permission, mobile device 104 may provide feedback to LADF that is used by ADF server 102 to refine LADF for subsequent use by other mobile devices. Or you may "refresh". For this purpose, at block 616, the feedback module 364 compares the spatial features in the area identified by the spatial feature detection module 358 with the spatial features of the sparse point cloud represented by the LADF 134. The spatial features of LADF 134 that the detection module 358 also observed, the spatial features of the LADF 134 that the spatial feature detection module 358 did not observe, and the spatial features that the spatial feature detection module 358 observed that was not present in the LADF 134 LADF feedback 238 representing one or more of the features may be generated. The LADF feedback 238 is uploaded to the ADF server 102. At block 618, the spatial feature filter module 216 receives the LADF feedback 238 and updates the feature of the spatial feature in the feature data store 208 accordingly and then based on the updated feature. The LADF may be updated to include new spatial features or to exclude previously included spatial features.
図７−図９はともに、少なくとも１つの実施形態に従う、ＬＡＤＦフィードバック２３８に基づいてＬＡＤＦ１３４を洗練するプロセスの例を示す。まず、ＬＡＤＦ１３４中に表わされるすべての空間的特徴に初期特徴量が与えられる。これは、ＬＡＤＦ１３４中のすべての空間的特徴について同じであってもよく、または空間的特徴の１つ以上の性質に基づいていてもよい。たとえば、空間的特徴には、ＬＡＤＦ１３４がそこから生成されたＡＤＦクラスタのＡＤＦ中に現われた回数に基づいて初期特徴量が割当てられてもよい。以下の説明のため、特徴量がより高いほどより信頼性のある空間的特徴を反映し、逆に特徴量がより低いほどより信頼性の低い特徴量を示すと仮定する。移動体装置１０４が供給するＬＡＤＦフィードバック２３８は１つ以上のエントリを含むことができ、各々のエントリは、移動体装置１０４によるＬＡＤＦ１３４中に存在する空間的特徴の観察を確認する、移動体装置によるＬＡＤＦ１３４中に存在する空間的特徴の観察を否定する、または移動体装置１０４が観察したがＬＡＤＦ１３４中には存在しない新しい空間的特徴を示唆する、のいずれかである。このように、空間的特徴の特徴量は、エントリおよびそれらが表わすフィードバックの種類に基づいて調整されてもよい。 FIGS. 7-9 together illustrate an example process for refining LADF 134 based on LADF feedback 238 in accordance with at least one embodiment. First, initial feature values are given to all spatial features represented in the LADF 134. This may be the same for all spatial features in LADF 134, or may be based on one or more properties of the spatial features. For example, spatial features may be assigned an initial feature based on the number of times LADF 134 has appeared in the ADF of the ADF cluster generated therefrom. For the following description, it is assumed that a higher feature quantity reflects a more reliable spatial feature, and conversely a lower feature quantity indicates a less reliable feature quantity. The LADF feedback 238 provided by the mobile device 104 can include one or more entries, each entry by the mobile device confirming the observation of the spatial features present in the LADF 134 by the mobile device 104. Either deny the observation of spatial features present in the LADF 134 or suggest new spatial features that the mobile device 104 has observed but are not present in the LADF 134. In this way, the feature quantities of the spatial features may be adjusted based on the entries and the type of feedback they represent.
図７の方法７００は、ＬＡＤＦフィードバック２３８の各エントリ毎にＡＤＦサーバ１０２が実現する処理を表わす。ブロック７０２で、空間的特徴フィルタモジュール２１６は、ＬＡＤＦフィードバック２３８の選択されたエントリにアクセスして、エントリが表わすフィードバックの種類を判断する。移動体装置１０４がＬＡＤＦ１３４の対応の空間的特徴を観察したとフィードバックエントリが確認する場合、ブロック７０４で、空間的特徴フィルタモジュール２１６は、移動体装置１０４による空間的特徴の観察の時間を示すタイムスタンプなどの、フィードバックエントリ中に表わされるような空間的特徴の同定に関する１つ以上のパラメータを抽出し、抽出されたパラメータを特徴量データ記憶２０８の中に記録する。さらに、ブロック７０６で、空間的特徴フィルタモジュール２１６は、その最近の観察を反映するように対応の空間的特徴の特徴量を増加させる。 The method 700 of FIG. 7 represents the process that the ADF server 102 implements for each entry in the LADF feedback 238. At block 702, the spatial feature filter module 216 accesses the selected entry of the LADF feedback 238 to determine the type of feedback that the entry represents. If the feedback entry confirms that the mobile device 104 has observed the corresponding spatial feature of the LADF 134, at block 704, the spatial feature filter module 216 indicates a time indicating the time of observation of the spatial feature by the mobile device 104. One or more parameters relating to the identification of the spatial features as represented in the feedback entry, such as a stamp, are extracted and the extracted parameters are recorded in the feature data store 208. Further, at block 706, the spatial feature filter module 216 increases the feature quantity of the corresponding spatial feature to reflect its recent observation.
ブロック７０２に戻って、移動体装置１０４がＬＡＤＦ１３４中に表わされる空間的特徴を観察しなかったとフィードバックエントリが示す場合、ブロック７０８で、空間的特徴フィルタモジュール２１６は、空間的特徴が観察されるはずであったが観察されなかった領域のイメージを移動体装置１０４が捕捉していた時間を示すタイムスタンプなどの、フィードバックエントリ中に表わされるような空間的特徴の同定に関する１つ以上のパラメータを抽出し、抽出されたパラメータを特徴量データ記憶２０８中に記録する。さらに、ブロック７１０で、空間的特徴フィルタモジュール２１６は、そのミスされた観察を反映するように対応の空間的特徴の特徴量を減らす。 Returning to block 702, if the feedback entry indicates that the mobile device 104 did not observe the spatial feature represented in the LADF 134, at block 708, the spatial feature filter module 216 should observe the spatial feature. Extract one or more parameters related to the identification of the spatial features as represented in the feedback entry, such as a time stamp indicating when the mobile device 104 was capturing an image of an area that was not observed Then, the extracted parameters are recorded in the feature data storage 208. Further, at block 710, the spatial feature filter module 216 reduces the feature quantity of the corresponding spatial feature to reflect the missed observation.
再びブロック７０２に戻って、移動体装置１０４がＬＡＤＦ１３４中に表わされなかった空間的特徴を確かに観察したとフィードバックエントリが示す場合、ブロック７１２で、空間的特徴フィルタモジュール２１６は、移動体装置１０４が空間的特徴を最初にまたは最後に観察した時間を示すタイムスタンプ、空間的特徴の観察の頻度（たとえば、移動体装置１０４が空間的特徴を含有する領域の方向に向けられたときに空間的特徴が観察された時間の割合）などの、フィードバックエントリ中に表わされるような以前に観察されなかった空間的特徴の同定に関する１つ以上のパラメータを抽出し、抽出されたパラメータを特徴量データ記憶２０８の中に記録する。さらに、ブロック７１４で、空間的特徴フィルタモジュール２１６は、特徴量データ記憶２０８中の対応の空間的特徴についての特徴量を作り出し、空間的特徴が特徴量データ記憶２０８中に既に表わされているのでなければ初期値を特徴量に割当てる。そうでない場合、特徴量が新たに観察された空間的特徴について既に存在する場合、（すなわち、以前に別の移動体装置１０４も空間的特徴を観察した場合）、空間的特徴フィルタモジュール２１６は当該空間的特徴についての特徴量を増加させる。次に方法７００はブロック７０２に戻って、ＬＡＤＦフィードバック２３８中の次のエントリについてプロセスを繰返す。 Returning again to block 702, if the feedback entry indicates that the mobile device 104 has indeed observed a spatial feature that was not represented in the LADF 134, then at block 712, the spatial feature filter module 216 determines that the mobile device 104 has A timestamp indicating the time at which 104 first or last observed a spatial feature, the frequency of observation of the spatial feature (e.g., space when mobile device 104 is directed toward the region containing the spatial feature. One or more parameters related to the identification of spatial features that were not previously observed as represented in the feedback entry, such as the percentage of time at which the spatial features were observed), and the extracted parameters as feature data Record in memory 208. Further, at block 714, the spatial feature filter module 216 creates a feature quantity for the corresponding spatial feature in the feature quantity data store 208, and the spatial feature is already represented in the feature quantity data store 208. If not, the initial value is assigned to the feature value. Otherwise, if the feature quantity already exists for the newly observed spatial feature (ie if another mobile device 104 has also observed the spatial feature previously), the spatial feature filter module 216 Increase the amount of features for spatial features. The method 700 then returns to block 702 to repeat the process for the next entry in the LADF feedback 238.
図８は、少なくとも１つの実施形態に従う、ＬＡＤＦ１３４中に含めるための候補空間的特徴を評価するための例示的な方法８００を示す。上述したように、移動体装置１０４は、あるエリアについてのＬＡＤＦ１３４に含めるための候補であり得る当該エリア中の新たに観察された空間的特徴を同定するＬＡＤＦフィードバック２３８を与えてもよく、空間的特徴フィルタモジュール２１６は初めて空間的特徴が検出されたときに特徴量を作り出して、別の移動体装置１０４が同じ空間的特徴を観察するたびに特徴量を増加させてもよい。このように、これらの空間的特徴のうちの各々毎の特徴量は、ＬＡＤＦ１３４中に含めるための空間的特徴の候補適格性（candidacy）の可能性の指標（すなわち、空間的特徴がローカリゼーションの目的のためにどの程度「信頼性がある」か）として働く。そのため、ＬＡＤＦ１３４の経年変化があるしきい値を超えるなどのトリガ条件に応答してまたはＬＡＤＦ１３４が確実に改定されるであろうと示す移動体装置１０４からの十分なフィードバックに応答して、ブロック８０２で、空間的特徴フィルタモジュール２１６は、特徴量データ記憶２０８からＬＡＤＦ１３４中に含めるための考慮の下で候補空間的特徴のうち１つを選択し、ブロック８０４で、空間的特徴フィルタモジュール２１６は、選択された候補空間的特徴の特徴量を「ＴＨＲＥＳＨ＿Ｈ」で指定される特定されたしきい値と比較する。このしきい値は固定されたしきい値であってもよく、１つ以上の現在の条件に基づいていてもよい。たとえば、１つの実施形態では、しきい値ＴＨＲＥＳＨ＿Ｈは、ＬＡＤＦ１３４中に現在含まれる空間的特徴の中間の現在の特徴量に設定されてもよい。 FIG. 8 illustrates an example method 800 for evaluating candidate spatial features for inclusion in the LADF 134 in accordance with at least one embodiment. As described above, the mobile device 104 may provide LADF feedback 238 that identifies newly observed spatial features in the area that may be candidates for inclusion in the LADF 134 for the area. The feature filter module 216 may create a feature quantity when a spatial feature is detected for the first time and increase the feature quantity each time another mobile device 104 observes the same spatial feature. Thus, each of these spatial features is a measure of the likelihood of candidate spatial features for inclusion in LADF 134 (ie, spatial features are the purpose of localization). To what extent is “reliable” for). As such, at block 802, in response to a trigger condition, such as the aging of LADF 134 exceeding a certain threshold, or in response to sufficient feedback from mobile device 104 indicating that LADF 134 will be reliably revised. , The spatial feature filter module 216 selects one of the candidate spatial features from the feature data store 208 under consideration for inclusion in the LADF 134, and at block 804 the spatial feature filter module 216 selects The feature amount of the candidate spatial feature is compared with the specified threshold specified by “THRESH_H”. This threshold may be a fixed threshold or may be based on one or more current conditions. For example, in one embodiment, the threshold value THRESH_H may be set to a current feature quantity intermediate the spatial features currently included in the LADF 134.
候補空間的特徴の特徴量がしきい値ＴＨＲＥＳＨ＿Ｈを超えない場合、空間的特徴フィルタモジュール２１６は、（現在の回の評価における）候補空間的特徴の一切のそれ以上の考慮を止めて、方法８００はブロック８０２に戻って、次の候補空間的特徴の選択を行なう。そうでない場合、特徴量がしきい値ＴＨＲＥＳＨ＿Ｈを超えると、ブロック８０６で、空間的特徴フィルタモジュール２１６は、ローカリゼーション生成モジュール２１８に信号を送って、選択された候補空間的特徴をＬＡＤＦ１３４に組入れる。ある実施形態では、ＬＡＤＦ１３４への新しい空間的特徴の組入れは、ＬＡＤＦ１３４からの別の空間的特徴の排除を要件とすることがある。そのような場合、空間的特徴フィルタモジュール２１６は、たとえば、ＬＡＤＦ１３４中に現在含まれる空間的特徴のすべてのうちから特徴量が最も低い空間的特徴を選択してもよい。候補空間的特徴をＬＡＤＦ１３４に組入れた後、方法８００はブロック８０２に戻って、次の候補空間的特徴を選択し評価する。 If the feature value of the candidate spatial feature does not exceed the threshold THRESH_H, the spatial feature filter module 216 stops any further consideration of the candidate spatial feature (in the current round of evaluation) and the method 800 Return to block 802 to select the next candidate spatial feature. Otherwise, if the feature quantity exceeds the threshold THRESH_H, at block 806, the spatial feature filter module 216 sends a signal to the localization generation module 218 to incorporate the selected candidate spatial feature into the LADF 134. In certain embodiments, the incorporation of a new spatial feature into LADF 134 may require the exclusion of another spatial feature from LADF 134. In such a case, the spatial feature filter module 216 may select, for example, the spatial feature with the lowest feature amount from all of the spatial features currently included in the LADF 134. After incorporating the candidate spatial features into LADF 134, method 800 returns to block 802 to select and evaluate the next candidate spatial feature.
図９は、少なくとも１つの実施形態に従う、ＬＡＤＦ１３４からの除外のための空間的特徴を評価するための例示的な方法９００を示す。上述のように、移動体装置１０４は、移動体装置１０４がＬＡＤＦ１３４の空間的特徴を観察したか否かを確認するＬＡＤＦフィードバック２３８を与えてもよく、空間的特徴フィルタモジュール２１６は、これに応じて空間的特徴の特徴量を調整してもよい。このように、これらの空間的特徴のうち各々毎の特徴量は、ローカリゼーションの目的のため、空間的特徴の現在の信頼性の指標として働く。そのため、トリガ条件に応答して、ブロック９０２で、空間的特徴フィルタモジュール２１６は、現在ＬＡＤＦ１３４に含まれる空間的特徴を選択し、ブロック９０４で、空間的特徴フィルタモジュール２１６は、選択された空間的特徴の特徴量を「ＴＨＲＥＳＨ＿Ｌ」で指定された特定されたしきい値と比較する。このしきい値は固定されたしきい値であってもよく、１つ以上の現在の条件に基づいていてもよい。たとえば、１つの実施形態では、しきい値ＴＨＲＥＳＨ＿Ｌは、現在ＬＡＤＦ１３４に含まれていない候補空間的特徴の中間の現在の特徴量に設定されてもよい。 FIG. 9 illustrates an example method 900 for evaluating spatial features for exclusion from the LADF 134 in accordance with at least one embodiment. As described above, the mobile device 104 may provide LADF feedback 238 that confirms whether the mobile device 104 has observed the spatial features of the LADF 134, and the spatial feature filter module 216 responds accordingly. The feature amount of the spatial feature may be adjusted. Thus, the feature quantity for each of these spatial features serves as an indicator of the current reliability of the spatial features for localization purposes. Thus, in response to the trigger condition, at block 902, the spatial feature filter module 216 selects a spatial feature currently included in the LADF 134, and at block 904, the spatial feature filter module 216 selects the selected spatial feature. The feature amount of the feature is compared with the specified threshold value designated by “THRESH_L”. This threshold may be a fixed threshold or may be based on one or more current conditions. For example, in one embodiment, the threshold value THRESH_L may be set to a current feature value intermediate candidate spatial features that are not currently included in the LADF 134.
候補空間的特徴の特徴量がしきい値ＴＨＲＥＳＨ＿Ｌを確かに超えている場合、空間的特徴フィルタモジュール２１６は、（現在の回の評価において）選択された空間的特徴の一切のそれ以上の考慮を止めて、方法９００はブロック９０２に戻って、ＬＡＤＦ１３４中の次の空間的特徴を選択する。そうでない場合、特徴量がしきい値ＴＨＲＥＳＨ＿Ｌを下回ると、ブロック９０６で、空間的特徴フィルタモジュール２１６は、ローカリゼーション生成モジュール２１８に信号を送って、選択された空間的特徴をＬＡＤＦ１３４から除外する。ある実施形態では、ＬＡＤＦ１３４からの空間的特徴の除外は、除外された空間的特徴を置き換える別の空間的特徴の選択を要件とすることがあり、したがって図８の方法８００の候補空間的特徴評価プロセスを開始するトリガ条件として働くことがある。選択された空間的特徴をＬＡＤＦ１３４から除外した後、方法９００はブロック９０２に戻って、ＬＡＤＦ１３４中の次の空間的特徴を選択し評価する。 If the feature value of the candidate spatial feature is indeed above the threshold THRESH_L, the spatial feature filter module 216 will consider any further consideration of the selected spatial feature (in the current round of evaluation). Stopping, method 900 returns to block 902 to select the next spatial feature in LADF 134. Otherwise, if the feature quantity falls below the threshold THRESH_L, at block 906, the spatial feature filter module 216 sends a signal to the localization generation module 218 to exclude the selected spatial feature from the LADF 134. In some embodiments, the exclusion of spatial features from LADF 134 may require the selection of another spatial feature that replaces the excluded spatial feature, and thus candidate spatial feature evaluation of method 800 of FIG. May act as a trigger condition to start the process. After excluding the selected spatial feature from LADF 134, method 900 returns to block 902 to select and evaluate the next spatial feature in LADF 134.
ＡＤＦサーバ１０２が維持するＬＡＤＦは、世界のエリアの視覚的特徴および幾何学的情報の表示を含有する。この情報は潜在的に微妙であり、したがってＡＤＦサーバ１０２は、ＬＡＤＦデータ記憶２０６中に記憶されるＬＡＤＦコンテンツおよび（ある実現例では同じデータ記憶を備え得る）ＡＤＦデータ記憶２０４中に記憶されるＡＤＦコンテンツへの未認証のまたは意図しないアクセスを防止するように配慮する。この目的のため、ＡＤＦサーバ１０２は、ＬＡＤＦデータ記憶２０６のＬＡＤＦコンテンツのための２層インデックス付け方式の形態のプライバシー防衛手段（safeguard）を用いる。図１０−図１２は、問合せモジュール２２０およびＬＡＤＦデータ記憶２０６の例示的な構成ならびにこの２層インデックス付け方式に従うその動作を示す。ＡＤＦデータ記憶２０４を、同様に以下に説明する態様で構成してもよい。 The LADF maintained by the ADF server 102 contains a display of visual features and geometric information of areas of the world. This information is potentially sensitive, so the ADF server 102 can store the LADF content stored in the LADF data store 206 and the ADF stored in the ADF data store 204 (which in some implementations can have the same data store). Care should be taken to prevent unauthorized or unintended access to content. For this purpose, the ADF server 102 uses a privacy guard in the form of a two-layer indexing scheme for LADF content in the LADF data store 206. 10-12 illustrate an exemplary configuration of query module 220 and LADF data store 206 and its operation according to this two-layer indexing scheme. The ADF data storage 204 may be similarly configured in the manner described below.
図１０は、問合せモジュール２２０およびＬＡＤＦデータ記憶２０６が実現する例示的な２層問合せインターフェイス１０００を示す。描かれるように、ＬＡＤＦデータ記憶２０６が記憶する各々のＬＡＤＦ（たとえばＬＡＤＦ１３４）は、ＬＡＤＦデータ記憶２０６中に実現されるＬＡＤＦデータベース１００４の対応のＬＡＤＦエントリ１００２に記憶される。各々のＬＡＤＦエントリ１００２は、その中に記憶されるＬＡＤＦに関連付けられるＵＩＤを記憶するＵＩＤフィールド１００６、ＬＡＤＦが現在表わす空間的特徴の組を記憶する空間的特徴フィールド１００８、およびＬＡＤＦに関連付けられる場所インジケータまたは他の場所データを記憶する場所フィールド１０１０を含む複数のフィールドを含む。 FIG. 10 illustrates an exemplary two layer query interface 1000 implemented by the query module 220 and LADF data store 206. As depicted, each LADF (eg, LADF 134) that LADF data store 206 stores is stored in a corresponding LADF entry 1002 in LADF database 1004 that is implemented in LADF data store 206. Each LADF entry 1002 includes a UID field 1006 that stores the UID associated with the LADF stored therein, a spatial feature field 1008 that stores the set of spatial features that LADF currently represents, and a location indicator associated with the LADF. Or other fields including a location field 1010 for storing location data.
十分な防衛手段がなければ、未認証の当事者がＬＡＤＦデータ記憶２０６からＬＡＤＦ１３４を入手することができ、したがって潜在的に微妙な情報が露出するおそれがあり得る。２層問合せインターフェイス１０００は、要求を発している移動体装置１０４または他の要求者が、それらが要求されたＬＡＤＦに関連付けられるエリアにいる（またはいた）と証明することを要件とすることによって、ＬＡＤＦデータ記憶２０６のＬＡＤＦデータをより十分に確保し得る。ＧＰＳ座標などのいくつかの場所インジケータは、容易になりすましされたりまたは他のやり方で偽造されたりすることがある。さらに、ＷＬＡＮ ＭＡＣアドレスまたは携帯電話基地局ＢＳＩＤなどの他の種類の場所インジケータは、対象のエリアよりもはるかに大きな領域をカバーすることがあり、したがって十分な粒度を欠いていることがある。そのため、場所インジケータのみでは、要求を発している移動体装置が実際に特定されたエリア中にいることの十分な証明にはならないことがある。このように、問合せインターフェイス１０００は、代わりに、特定されたエリア中の移動体装置１０４が観察する空間的特徴の組を移動体装置１０４が送信することを要件とすることによる、移動体装置１０４が特定されたエリア中にいるという証明を要件としてもよい。問合せインターフェイス１０００は次に、この空間的特徴の組をＬＡＤＦエントリの空間的特徴と比較して、一致するＬＡＤＦを同定してもよい。しかしながら、多くのエリアは似たような構造的構成（たとえばオフィスビル内の同様の部屋）を有していて、したがって、複数のＬＡＤＦが、送信された空間的特徴の組に十分に一致し得るおそれがあり、したがって要求を発している移動体装置に誤ったＬＡＤＦが供給されることがある。これは、潜在的なプライバシー侵害になってしまうことと、移動体装置１０４にローカリゼーションのための誤った参照を提供してしまうこととの両方のために、二重に問題である。 Without sufficient defenses, an unauthorized party can obtain LADF 134 from LADF data store 206, thus potentially exposing sensitive information. The two-tier query interface 1000 requires that the requesting mobile device 104 or other requestor prove that they are (or were) in the area associated with the requested LADF, The LADF data in the LADF data storage 206 can be secured more sufficiently. Some location indicators, such as GPS coordinates, can be easily spoofed or otherwise forged. In addition, other types of location indicators, such as WLAN MAC address or mobile phone base station BSID, may cover a much larger area than the area of interest and may therefore lack sufficient granularity. As such, the location indicator alone may not provide sufficient evidence that the requesting mobile device is actually in the identified area. Thus, the query interface 1000 instead requires the mobile device 104 to require the mobile device 104 to transmit a set of spatial features that the mobile device 104 in the identified area observes. The requirement may be proof that is in the specified area. Query interface 1000 may then compare this set of spatial features with the spatial features of the LADF entry to identify matching LADFs. However, many areas have similar structural configurations (eg, similar rooms in an office building), so multiple LADFs can sufficiently match the set of transmitted spatial features There is a possibility that the wrong LADF may be supplied to the requesting mobile device. This is a double problem both due to potential privacy violations and to providing the mobile device 104 with an incorrect reference for localization.
このように、移動体装置が実際にそれがそこにあると表わすエリアの中にいるのを確実にすることと、正しいＬＡＤＦが移動体装置に供給されるのを確実にすることとの両方のために、問合せインターフェイス１０００は、移動体装置が送信する１組の空間的特徴と１つ以上の場所インジケータとの両方を利用して、ＬＡＤＦデータベース１００４からの正しいＬＡＤＦを同定する。この方策の下で、移動体装置または他の要求者は、同定されたエリア中に観察される空間的特徴を送信することによって、要求者が同定されたエリア中にいて、したがって同定されたエリアについてのＬＡＤＦが公開されても潜在的に微妙な情報が意図せず開示されるおそれが低いと証明することを認めるべきである。というのも、要求者は、単に示されたエリアの周りを見て、供給されたＬＡＤＦが表わす視覚的情報とは桁違いにより詳細な視覚的情報を得ることがあるからである。 In this way, both ensuring that the mobile device is actually within the area that it represents and ensuring that the correct LADF is supplied to the mobile device. To do so, the query interface 1000 identifies both the correct LADF from the LADF database 1004 using both a set of spatial features and one or more location indicators transmitted by the mobile device. Under this strategy, the mobile device or other requestor is in the area in which the requester is identified and thus identified by transmitting the spatial features observed in the identified area. It should be acknowledged that even when the LADF for is published, potentially sensitive information is less likely to be unintentionally disclosed. This is because the requester may simply look around the indicated area and obtain more detailed visual information by orders of magnitude than the visual information represented by the supplied LADF.
この目的のため、問合せモジュール２２０は、空間的特徴問合せインターフェイス１０１２および場所選択モジュール１０１４を含む。空間的特徴問合せインターフェイス１０１２は、移動体装置１０４が送信したＬＡＤＦ要求２３６中の空間的特徴の組１０１６を用いて、ＬＡＤＦデータベース１００４のＬＡＤＦエントリ１００２の空間的特徴フィールド１００８の探索に基づいて候補ＬＡＤＦの初期問合せを行なう。この探索は、空間的特徴の相対的外形を考慮する。というのも、それらはＬＡＤＦ要求２３６が表わす画像の中に投影されて、ＬＡＤＦデータベース１００４中の空間的特徴に対する整合性について確認するからである。場所選択モジュール１０１４は次に、ＬＡＤＦ要求２３６とともに送信された１つ以上の場所インジケータ１０１８と候補ＬＡＤＦの場所フィールド１０１０中の各ＬＡＤＦ毎の場所情報との比較に基づいて、同定された候補ＬＡＤＦから選択する。 For this purpose, the query module 220 includes a spatial feature query interface 1012 and a location selection module 1014. The spatial feature query interface 1012 uses the spatial feature set 1016 in the LADF request 236 sent by the mobile device 104 to base candidate LADFs based on a search of the spatial feature field 1008 of the LADF entry 1002 in the LADF database 1004. The initial query is performed. This search takes into account the relative contours of the spatial features. This is because they are projected into the image represented by LADF request 236 to check for consistency with the spatial features in LADF database 1004. The location selection module 1014 then selects from the identified candidate LADFs based on a comparison of the one or more location indicators 1018 sent with the LADF request 236 with the location information for each LADF in the candidate LADF location field 1010. select.
さらに、１組の空間的特徴以外に場所インジケータまたは他の鍵を用いたＬＡＤＦエントリ１００２の探索または他のアクセスを防止するために、ある実施形態では、ＬＡＤＦデータ記憶２０６は、空間的特徴フィールド１００８によってＬＡＤＦエントリ１００２をインデックス付けするように構成され、さらに場所フィールド１０１０によるＬＡＤＦエントリ１００２のインデックス付けを避けるように構成される。この構成では、ＬＡＤＦの空間的特徴の組を介してＬＡＤＦデータベース１００４のＬＡＤＦエントリ１００２を探索することができるが、最初に場所によって探索することはできない。このように、場所インジケータのみを送信しても、ＬＡＤＦデータベース１００４からＬＡＤＦ１３４が同定されたり発生されたりする結果にはならない。 Further, in order to prevent searching or other access of the LADF entry 1002 using a location indicator or other key in addition to a set of spatial features, in one embodiment, the LADF data store 206 includes a spatial feature field 1008. Is configured to index the LADF entry 1002, and is further configured to avoid indexing the LADF entry 1002 by the location field 1010. In this configuration, the LADF entry 1002 of the LADF database 1004 can be searched through the set of LADF spatial features, but cannot be searched by location first. In this way, sending only the location indicator does not result in the LADF 134 being identified or generated from the LADF database 1004.
図１１は、本開示の少なくとも１つの実施形態に従う、図１０の２層問合せインターフェイス１０００の動作の例示的な方法１１００を示す。方法１１００は、ブロック１１０２で、移動体装置または他の要求者からの示されたエリアについてのＬＡＤＦ要求２３６の送信で開始する。少なくとも１つの実施形態では、ＬＡＤＦ要求２３６を受入れて処理するために、ＡＤＦサーバ１０２は、示されたエリア中に観察される空間的特徴の組１０１６と、示されたエリア中の移動体装置が入手しかつ判断した１つ以上の場所インジケータ１０１８とをＬＡＤＦ要求２３６が少なくとも含むことを要件とする。 FIG. 11 illustrates an exemplary method 1100 of operation of the two-tier query interface 1000 of FIG. 10, in accordance with at least one embodiment of the present disclosure. The method 1100 begins at block 1102 with the transmission of an LADF request 236 for the indicated area from a mobile device or other requester. In at least one embodiment, to accept and process the LADF request 236, the ADF server 102 determines the spatial feature set 1016 observed in the indicated area and the mobile device in the indicated area. Require that the LADF request 236 includes at least one or more location indicators 1018 obtained and determined.
ブロック１１０４で、空間的特徴問合せインターフェイス１０１２は、ＬＡＤＦデータベース１００４のＬＡＤＦエントリ１００２を探索して、ＬＡＤＦ要求２３６の空間的特徴の組１０１６と十分に重なりかつ空間的特徴の組１０１６の投影された空間的特徴の外形に整合する相対的外形を有する空間的特徴フィールド１００８中の空間的特徴の組を有するＬＡＤＦエントリ１００２を見出す。１つの実施形態では、分析された各ＬＡＤＦエントリ１００２毎に、空間的特徴問合せインターフェイス１０１２は、空間的特徴の組１０１６とＬＡＤＦエントリ１００２の空間的特徴フィールド１００８との間で一致する空間的特徴のカウントを判断してもよい。空間的特徴問合せインターフェイス１０１２は次に、ＬＡＤＦエントリ１００２について判断されたカウント値に基づいてＮ個の候補ＬＡＤＦ（たとえば、図１０の候補ＬＡＤＦ１０２１，１０２２，１０２３）を選択してもよい。たとえば、ある事例では、特定されたしきい値よりも大きなカウントを有するあらゆるＬＡＤＦが候補ＬＡＤＦとして選択されてもよい。他の事例では、空間的特徴問合せインターフェイス１０１２は、Ｎ個の候補ＬＡＤＦとして、カウント値が最も高いＮ個のＬＡＤＦを選択してもよい。 At block 1104, the spatial feature query interface 1012 searches the LADF entry 1002 in the LADF database 1004 to sufficiently overlap the spatial feature set 1016 of the LADF request 236 and the projected space of the spatial feature set 1016. Find the LADF entry 1002 with the set of spatial features in the spatial feature field 1008 that has a relative outline that matches the outline of the spatial feature. In one embodiment, for each analyzed LADF entry 1002, the spatial feature query interface 1012 includes a spatial feature matching between the spatial feature set 1016 and the spatial feature field 1008 of the LADF entry 1002. The count may be determined. Spatial feature query interface 1012 may then select N candidate LADFs (eg, candidate LADFs 1021, 1022, 1023 in FIG. 10) based on the count value determined for LADF entry 1002. For example, in some cases, any LADF that has a count greater than a specified threshold may be selected as a candidate LADF. In other cases, the spatial feature query interface 1012 may select N LADFs with the highest count value as the N candidate LADFs.
ブロック１１０６で、空間的特徴問合せインターフェイス１０１２は、少なくとも１つの候補ＬＡＤＦがＬＡＤＦデータベース１００４から同定されたことを検証する。そうでない場合、ブロック１１０８で、問合せモジュール２２０は、示されたエリアについてＬＡＤＦが入手可能でないことを、要求を発している移動体装置に信号で通知する。そうでない場合、１つ以上の同定された候補ＬＡＤＦは、（たとえば、候補ＬＡＤＦのＵＩＤを同定することによって）場所選択モジュール１０１４に供給され、ブロック１１１０で、場所選択モジュール１０１４は、ＬＡＤＦ要求２３６の１つ以上の場所インジケータ１０１８を候補ＬＡＤＦの場所フィールド１０１０によって示される場所と比較して、各々の候補ＬＡＤＦと１つ以上の場所インジケータ１０１８との間の一致をスコア化する。ブロック１１１２で、場所選択モジュール１０１４は、１つ以上の場所インジケータ１０１８と候補ＬＡＤＦのうち１つの場所情報との間に十分な一致があるか否かを検証する。ない場合、ブロック１１１４で、問合せモジュール２２０は、示されたエリアについてＬＡＤＦが入手可能でないことを、要求を発している移動体装置に信号で通知する。さもなければ、ブロック１１１６で、場所選択モジュール１０１４は、同定されたエリアとしてともに位置するＬＡＤＦとして、最良の場所一致度を有する候補ＬＡＤＦを選択して、ＬＡＤＦ要求２３６に応答して、当該エリアについてのＬＡＤＦ１３４としてこの選択されたＬＡＤＦを移動体装置に与える。 At block 1106, the spatial feature query interface 1012 verifies that at least one candidate LADF has been identified from the LADF database 1004. Otherwise, at block 1108, the query module 220 signals the requesting mobile device that LADF is not available for the indicated area. Otherwise, one or more identified candidate LADFs are provided to the location selection module 1014 (eg, by identifying the UID of the candidate LADF), and at block 1110, the location selection module 1014 receives the LADF request 236 One or more location indicators 1018 are compared to the location indicated by the candidate LADF location field 1010 to score matches between each candidate LADF and one or more location indicators 1018. At block 1112, the location selection module 1014 verifies whether there is a sufficient match between the one or more location indicators 1018 and the location information of one of the candidate LADFs. If not, at block 1114, query module 220 signals the requesting mobile device that LADF is not available for the indicated area. Otherwise, at block 1116, the location selection module 1014 selects the candidate LADF with the best location match as the LADF that is co-located as the identified area, and in response to the LADF request 236, for the area This selected LADF is provided to the mobile device as the LADF 134 of the mobile device.
ＬＡＤＦデータベース１００４のＬＡＤＦへの未認証のまたは意図しないアクセスに対する保護を与えることに加え、移動体装置が検出するような空間的特徴およびそれらの外形を用いてＬＡＤＦ問合せを行なうことにより、二段階問合せプロセスを通じて最終的に選択されるＬＡＤＦが、一致するＬＡＤＦを用いて移動体装置のローカライズを成功させことが確実になる。これは、ＬＡＤＦ問合せプロセスの第１の段階が、移動体で行なわれるローカリゼーションプロセスと同じまたは同様の候補ＬＡＤＦを同定する「ローカリゼーション」プロセスを行なって、観察されたＬＡＤＦ中の空間的特徴およびそれらの画像外形を用いてＬＡＤＦに対する移動体装置のポーズを見出すからである。 In addition to providing protection against unauthenticated or unintended access to the LADF in the LADF database 1004, a two-stage query is performed by performing a LADF query using spatial features and their outlines as detected by the mobile device. It is ensured that the LADF ultimately selected throughout the process will successfully localize the mobile device with the matching LADF. This is because the first stage of the LADF query process performs a “localization” process that identifies candidate LADFs that are the same or similar to the localization process performed on the mobile, and the spatial features in the observed LADFs and their This is because the pose of the mobile device with respect to LADF is found using the image outline.
図１２は、少なくとも１つの実施形態に従う２層問合せインターフェイス１０００の代替的な構成を示す。図１０に描かれる実現例と同様に、ＬＡＤＦデータ記憶２０６は、各々がＵＩＤフィールド１００６、空間的特徴フィールド１００８、および場所フィールド１０１０を有する複数のＬＡＤＦエントリ１２０２を備えるＬＡＤＦデータベース１２０４を実現する。しかしながら、図１０の実現例とは反対に、ＬＡＤＦデータベース１２０４は、代わりに、場所フィールド１０１０に基づいてＬＡＤＦエントリ１２０２をインデックス付けする。さらに、この実施形態では、問合せモジュール２２０は、ＬＡＤＦデータベース１２０４への場所問合せインターフェイス１２１２と空間的特徴選択モジュール１２１４とを備える。 FIG. 12 illustrates an alternative configuration of a two-tier query interface 1000 in accordance with at least one embodiment. Similar to the implementation depicted in FIG. 10, LADF data store 206 implements a LADF database 1204 comprising a plurality of LADF entries 1202 each having a UID field 1006, a spatial feature field 1008, and a location field 1010. However, contrary to the implementation of FIG. 10, the LADF database 1204 instead indexes the LADF entry 1202 based on the location field 1010. Further, in this embodiment, the query module 220 includes a location query interface 1212 to the LADF database 1204 and a spatial feature selection module 1214.
描かれる実現例では、ＬＡＤＦに対する２層問合せは、１つ以上の候補ＬＡＤＦの組を同定するＬＡＤＦ要求２３６の１つ以上の場所インジケータ１０１８に十分に一致する場所情報を有するＬＡＤＦに対する場所問合せインターフェイス１２１２によるＬＡＤＦエントリ１２０２の第１層の探索として実現される。空間的特徴選択モジュール１２１４は次に、ＬＡＤＦ要求２３６の空間的特徴の組１０１６を比較して、ＬＡＤＦ要求２３６に応答して、要求を発している移動体装置に供給すべきＬＡＤＦ１３４として、空間的特徴の組１０１６に最も一致する候補ＬＡＤＦを選択する。 In the depicted implementation, a two-tier query for LADF is a location query interface 1212 for LADF that has location information that sufficiently matches one or more location indicators 1018 of LADF request 236 that identifies a set of one or more candidate LADFs. This is realized as a search of the first layer of the LADF entry 1202 by the above. The spatial feature selection module 1214 then compares the spatial feature set 1016 of the LADF request 236 and, in response to the LADF request 236, spatially as the LADF 134 to be supplied to the requesting mobile device. The candidate LADF that best matches the feature set 1016 is selected.
上述の発明の機能性の大部分および発明の原則の多くは、特定用途向けＩＣ（ＡＳＩＣ）などの集積回路を用いたまたはそれにおける実現例によく適している。当業者は、本明細書中に開示される概念および原則によって導かれると、たとえば、利用可能な時間、現在の技術および経済的考慮によって動機付けられるおそらくはかなりの労力および多数の設計上の選択肢にも係わらず、最小限の実験によってそのようなＩＣを生成することが容易に可能であることが期待される。したがって、簡潔さ、ならびに本開示に従う原則および概念を曖昧にする一切のおそれの最小化のため、そのようなソフトウェアおよびＩＣのそれ以上の検討は、もしあるとしても、好ましい実施形態の範囲内の原則および概念に対する必須部分に限定されるであろう。 Most of the functionality of the invention described above and many of the inventive principles are well suited to implementations using or in integrated circuits such as application specific ICs (ASICs). Those skilled in the art, when guided by the concepts and principles disclosed herein, may be, for example, available time, possibly significant effort and numerous design options motivated by current technology and economic considerations. Nevertheless, it is expected that such an IC can be easily generated with minimal experimentation. Accordingly, for the sake of brevity and minimizing any fear of obscuring the principles and concepts according to this disclosure, further review of such software and IC, if any, is within the scope of the preferred embodiments. It will be limited to essential parts of principles and concepts.
この文書では、第１および第２などの関係性を表わす用語は、あるエンティティまたは行為を、別のエンティティまたは行為の間の何らかの実際のそのような関係または順序を必ずしも要件としたり暗示したりすることなく当該エンティティまたは行為から区別するためにのみ用いられ得る。「備える」、「備えている」という用語、またはその何らかの他の変形は、非排他的包含をカバーすることが意図されるため、要素の一覧を備えるプロセス、方法、物品、または機器は、それらの要素のみを含むのではなく、明示的に列挙されないまたはそのようなプロセス、方法、物品、もしくは機器に内在的な他の要素を含むことがある。「備える」に続く要素は、それ以上の制約なく、当該要素を備えるプロセス、方法、物品、または機器中の付加的な同一の要素の存在を排除するものではない。本明細書中で用いるような「別の」という用語は、少なくとも第２以降として規定される。本明細書中で用いられるように「含む」および／または「有する」という用語は、備えるとして規定される。電気光学技術を参照して本明細書中で用いるような「結合される」という用語は、必ずしも直接にではなくまた必ずしも機械的ではないが、接続されると規定される。本明細書中で用いるような「プログラム」という用語は、コンピュータシステム上での実行のために設計された命令のシーケンスとして規定される。「プログラム」または「コンピュータプログラム」は、サブルーチン、機能、手順、オブジェクト方法、オブジェクト実現例、実行可能なアプリケーション、アプレット、サーブレット、ソースコード、オブジェクトコード、共有ライブラリ／動的負荷ライブラリ、および／またはコンピュータシステム上での実行のために設計される命令の他のシーケンスを含むことがある。 In this document, terms representing relationships such as first and second necessarily require or imply one entity or action some actual such relationship or order between another entity or action. And can only be used to distinguish it from the entity or action. Since the terms “comprising”, “comprising”, or some other variation thereof, are intended to cover non-exclusive inclusions, a process, method, article, or device comprising a list of elements is May include other elements not explicitly listed or inherent in such processes, methods, articles, or equipment. An element following “comprising” does not exclude the presence of additional identical elements in a process, method, article, or device comprising the element, without further limitation. The term “another” as used herein is defined as at least a second or later. As used herein, the terms “comprising” and / or “having” are defined as comprising. The term “coupled” as used herein with reference to electro-optic technology is defined as connected, although not necessarily directly and not necessarily mechanical. The term “program” as used herein is defined as a sequence of instructions designed for execution on a computer system. A “program” or “computer program” is a subroutine, function, procedure, object method, object implementation, executable application, applet, servlet, source code, object code, shared library / dynamic load library, and / or computer It may include other sequences of instructions designed for execution on the system.
明細書および図面は単なる例示と考えられるべきであり、したがって開示の範囲は以下の請求項およびその均等物によってのみ限定されることが意図される。なお、全般的な説明で上述した活動または要素のすべてを要件とするわけではなく、具体的な活動または装置の一部を要件としないことがあり、説明したものに加えて１つ以上のさらなる活動を行なってもよくまたは１つ以上のさらなる要素を含んでもよい。またさらに、活動が列挙される順序は必ずしもそれらが行なわれる順序とは限らない。以上の描かれたフローチャートの工程は、特段の記載がなければ任意の順序であることができ、実現例に依存して工程を排除、繰返し、および／または追加してもよい。また、具体的な実施形態を参照して概念を説明した。しかしながら、当業者は、以下の請求項に述べるような本開示の範囲から逸脱することなく、さまざまな修正および変更をなすことができることを認める。これに応じて、明細書および図は、制限的な意味よりもむしろ例示と見なされるべきであり、すべてのそのような修正は本開示の範囲内に含まれることが意図される。 It is intended that the specification and drawings be considered as exemplary only, and thus the scope of the disclosure be limited only by the following claims and their equivalents. Note that not all of the activities or elements described above in the general description are required, and some specific activities or devices may not be required, and one or more additional ones in addition to those described. An activity may be performed or one or more additional elements may be included. Still further, the order in which activities are listed is not necessarily the order in which they are performed. The steps of the flowcharts drawn above can be in any order unless otherwise noted, and steps can be eliminated, repeated, and / or added depending on the implementation. The concept has been described with reference to specific embodiments. However, one of ordinary skill in the art appreciates that various modifications and changes can be made without departing from the scope of the present disclosure as set forth in the claims below. Accordingly, the specification and figures are to be regarded as illustrative rather than in a restrictive sense, and all such modifications are intended to be included within the scope of this disclosure.
具体的な実施形態に関して有利、他の利点、および課題に対する解決策を上述した。しかしながら、何らかの有利、利点、または解決策を想到させ得るまたはより顕著にし得る有利、利点、課題に対する解決策、および何らかの特徴を、任意のまたはすべての請求項の決定的な、要件とされる、または必須の特徴として解釈すべきではない。 Advantageous, other advantages, and solutions to problems have been described above with regard to specific embodiments. However, an advantage, an advantage, a solution to a problem, and some feature that may conceive or make any advantage, advantage, or solution a decisive requirement of any or all claims, Or should not be interpreted as an essential feature.
Claims (21)
コンピューティングシステムにおいて、１つ以上の第１の移動体装置の組から１つ以上のエリア記述ファイルの組を受信することを備え、各エリア記述ファイルは、エリアにある対応の第１の移動体装置が検出する空間的特徴の点群を表わし、
前記方法は、さらに、前記コンピューティングシステムにおいて、前記１つ以上のエリア記述ファイルの組から前記エリアについてのローカリゼーションエリア記述ファイルを生成することを備え、前記ローカリゼーションエリア記述ファイルは前記エリアについての空間的特徴の点群を表わし、
前記方法は、さらに、
前記コンピューティングシステムからの前記ローカリゼーションエリア記述ファイルを第２の移動体装置に与えることと、
前記コンピューティングシステムにおいて、前記第２の移動体装置からフィードバックデータを受信することとを備え、前記フィードバックデータは、前記エリア中にある間に、前記ローカリゼーションエリア記述ファイルが表わす前記空間的特徴のうち１つ以上が前記第２の移動体装置によって検出されたか否かを同定する、方法。 A method,
In a computing system, comprising receiving a set of one or more area description files from a set of one or more first mobile devices, each area description file having a corresponding first mobile in an area Represents a point cloud of spatial features detected by the device,
The method may further wherein the computing system comprises generating a localization area description file for the area from the set of the one or more areas description files, spatial for the localization area description file the area Represents a point cloud of features,
The method further
Providing the localization area description file from the computing system to a second mobile device ;
Receiving the feedback data from the second mobile device in the computing system, the feedback data being out of the spatial features represented by the localization area description file while in the area. A method of identifying whether one or more has been detected by the second mobile device .
前記エリア記述ファイルが表わす前記点群の各空間的特徴毎に、対応の座標フレームに基づいて前記空間的特徴の多次元座標を特定する空間的特徴データと、
視野角または照明条件とは独立して前記空間的特徴の外観を各空間的特徴毎に表わす統計的データと、
前記点群の前記空間的特徴の検出と同時に１つ以上の非画像センサから捕捉したセンサデータとを備える、請求項１または２に記載の方法。 Each area description file of the set of one or more area description files is:
For each spatial feature of the point cloud represented by the area description file, spatial feature data that identifies multidimensional coordinates of the spatial feature based on a corresponding coordinate frame;
Statistical data representing the appearance of the spatial features for each spatial feature independent of viewing angle or lighting conditions;
3. A method according to claim 1 or 2, comprising sensor data captured from one or more non-image sensors simultaneously with detection of the spatial features of the point cloud.
少なくとも、前記空間的特徴データのサブセットと前記組の各エリア記述ファイルの前記統計的データとを前記ローカリゼーションエリア記述ファイルに組入れることと、
前記組の中の各エリア記述ファイルの前記センサデータを前記ローカリゼーションエリア記述ファイルから除くこととを備える、請求項３に記載の方法。 Generating the localization area description file includes
Including at least a subset of the spatial feature data and the statistical data of each area description file of the set in the localization area description file;
4. The method of claim 3, comprising removing the sensor data for each area description file in the set from the localization area description file.
前記ローカリゼーションエリア記述ファイルを生成することは、
前記複数のエリア記述ファイルが前記エリアに関連付けられていると同定することと、
前記複数のエリア記述ファイルが表わす前記点群の重複をなくすことと、
前記点群の相対的整列を判断することと、
前記点群を前記ローカリゼーションエリア記述ファイルに組入れることとを備える、請求項１〜４のいずれか１項に記載の方法。 The set of one or more area description files comprises a plurality of area description files;
Generating the localization area description file includes
Identifying the plurality of area description files as being associated with the area;
Eliminating duplication of the point cloud represented by the plurality of area description files;
Determining the relative alignment of the point cloud;
5. The method according to any one of claims 1 to 4, comprising incorporating the point cloud into the localization area description file.
前記点群に基づいて複数のサブエリアを同定することと、
前記サブエリア中に位置する前記点群の前記空間的特徴から各サブエリア毎にローカリゼーションエリア記述ファイルを生成することとを備える、請求項５に記載の方法。 Generating the localization area description file further comprises:
Identifying a plurality of sub-areas based on the point cloud;
6. The method of claim 5, comprising generating a localization area description file for each subarea from the spatial features of the point cloud located in the subarea.
前記コンピューティングシステムにおいて、前記フィードバックデータに基づいて前記ローカリゼーションエリア記述ファイルを更新して更新済みローカリゼーションエリア記述ファイルを生成することと、
前記コンピューティングシステムからの前記更新済みローカリゼーションエリア記述ファイルを第３の移動体装置に与えることとを備える、請求項１〜７のいずれか１項に記載の方法。 The method further includes:
Prior Symbol computing system, and said generating a localization area description file is updated and the updated localization area description file based on the feedback data,
Providing the updated localization area description file from the computing system to a third mobile device.
前記ローカリゼーションエリア記述ファイルが表わす各空間的特徴毎のスコアを維持することと、
前記ローカリゼーションエリア記述ファイルが表わす空間的特徴について、
前記第２の移動体装置が前記空間的特徴を検出したことを示す前記フィードバックデータに応答して前記空間的特徴のスコアを増加させること、
前記第２の移動体装置が前記空間的特徴を検出しなかったことを示す前記フィードバックデータに応答して前記空間的特徴の前記スコアを減らすこと、および
少なくとも１つのしきい値に対する前記スコアの比較に基づいて前記ローカリゼーションエリア記述ファイルから前記空間的特徴を選択的に除外すること、とを備える、請求項８に記載の方法。 Updating the localization area description file
Maintaining a score for each spatial feature represented by the localization area description file;
Regarding spatial features represented by the localization area description file,
Increasing the spatial feature score in response to the feedback data indicating that the second mobile device has detected the spatial feature;
Reducing the score of the spatial feature in response to the feedback data indicating that the second mobile device did not detect the spatial feature, and comparing the score to at least one threshold And selectively excluding the spatial features from the localization area description file based on:
前記ローカリゼーションエリア記述ファイルを更新することは、
前記第２の移動体装置が検出する前記空間的特徴に関連付けられるスコアを増加させることと、
前記スコアと少なくとも１つのしきい値との比較に応答して、前記第２の移動体装置が検出した前記空間的特徴を含めるように前記ローカリゼーションエリア記述ファイルを選択的に修正することとを備える、請求項８に記載の方法。 The feedback data identifies spatial features detected by the second mobile device and not represented by the localization area description file;
Updating the localization area description file
Increasing a score associated with the spatial feature detected by the second mobile device;
Selectively modifying the localization area description file to include the spatial features detected by the second mobile device in response to comparing the score to at least one threshold. The method according to claim 8.
複数の移動体装置に結合するネットワークインターフェイスと、
第１のデータ記憶と、
第２のデータ記憶と、
前記ネットワークインターフェイスおよび前記第１のデータ記憶に結合される合成モジュールとを備え、前記合成モジュールは、１つ以上の第１の移動体装置の組から１つ以上のエリア記述ファイルの組を受信し、各エリア記述ファイルは、エリアにある対応の第１の移動体装置が検出する空間的特徴の点群を表わし、
前記第１のデータ記憶および前記第２のデータ記憶に結合されるローカリゼーション生成モジュールをさらに備え、前記ローカリゼーション生成モジュールは、前記１つ以上のエリア記述ファイルの組から前記エリアについてのローカリゼーションエリア記述ファイルを生成し、かつ前記第２のデータ記憶中に前記ローカリゼーションエリア記述ファイルを記憶し、前記ローカリゼーションエリア記述ファイルは、前記エリアについての空間的特徴の点群を表わし、
前記第２のデータ記憶および前記ネットワークインターフェイスに結合される問合せモジュールをさらに備え、前記問合せモジュールは、前記ネットワークインターフェイスを介して前記ローカリゼーションエリア記述ファイルを少なくとも１つの第２の移動体装置に与え、
前記第１のデータ記憶および前記ネットワークインターフェイスに結合される空間的特徴フィルタモジュールをさらに備え、前記空間的特徴フィルタモジュールは、前記第２の移動体装置からフィードバックデータを受信し、前記フィードバックデータは、前記ローカリゼーションエリア記述ファイルを用いて、前記ローカリゼーションエリア記述ファイルが表わす前記空間的特徴のうち１つ以上が前記第２の移動体装置によって検出されたか否かを同定する、コンピューティングシステム。 A computing system,
A network interface coupled to a plurality of mobile devices;
A first data store;
A second data store;
A synthesis module coupled to the network interface and the first data store, wherein the synthesis module receives a set of one or more area description files from a set of one or more first mobile devices. Each area description file represents a point cloud of spatial features detected by the corresponding first mobile device in the area ,
Further comprising a localization generation module coupled to said first data storage and the second data storage, the localization generation module, a localization area description file for the area from the set of the one or more areas description file Generating and storing the localization area description file in the second data store, the localization area description file representing a point cloud of spatial features for the area ;
Further comprising a query module that is coupled to said second data storage and the network interface, the query module, e given to at least one second mobile device the localization area description file via the network interface,
A spatial feature filter module coupled to the first data store and the network interface, the spatial feature filter module receiving feedback data from the second mobile device; A computing system that uses the localization area description file to identify whether one or more of the spatial features represented by the localization area description file have been detected by the second mobile device .
前記エリア記述ファイルが表わす前記点群の各空間的特徴毎に、対応の座標フレームに基づいて前記空間的特徴の多次元座標を特定する空間的特徴データと、
各空間的特徴毎に、視野角または照明条件とは独立して前記空間的特徴の外観を表わす統計的データと、
前記点群の前記空間的特徴の検出と同時に１つ以上の非画像センサから捕捉したセンサデータとを備え、
前記ローカリゼーションエリア記述ファイルは、
前記組の各エリア記述ファイルの前記空間的特徴データの少なくともサブセットと、
前記組の各エリア記述ファイルの前記統計的データの少なくともサブセットとを備える、請求項１１に記載のコンピューティングシステム。 Each area description file of the set is
For each spatial feature of the point cloud represented by the area description file, spatial feature data that identifies multidimensional coordinates of the spatial feature based on a corresponding coordinate frame;
For each spatial feature, statistical data representing the appearance of the spatial feature independent of viewing angle or lighting conditions;
Sensor data captured from one or more non-image sensors simultaneously with detection of the spatial features of the point cloud,
The localization area description file is
At least a subset of the spatial feature data of each area description file of the set;
12. The computing system of claim 11, comprising at least a subset of the statistical data of each set of area description files.
前記問合せモジュールは、前記複数のエリア記述ファイルが前記エリアに関連付けられていると同定し、
前記合成モジュールは、
前記複数のエリア記述ファイルが表わす前記点群の重複をなくすこと、
前記点群の相対的整列を判断すること、および
前記点群を前記ローカリゼーションエリア記述ファイルに組入れること、
によって前記ローカリゼーションエリア記述ファイルを生成する、請求項１２に記載のコンピューティングシステム。 The set of one or more area description files comprises a plurality of area description files;
The query module identifies that the plurality of area description files are associated with the area;
The synthesis module is
Eliminating duplication of the point cloud represented by the plurality of area description files;
Determining the relative alignment of the point cloud; and incorporating the point cloud into the localization area description file;
13. The computing system of claim 12, wherein the localization area description file is generated by:
前記点群に基づいて複数のサブエリアを同定することと、
前記サブエリアに位置する前記点群の前記空間的特徴から各サブエリア毎にローカルエリア記述ファイルを生成することとによって
前記ローカリゼーションエリア記述ファイルを生成する、請求項１３に記載のコンピューティングシステム。 The combining module further identifies a plurality of sub-areas based on the point cloud;
14. The computing system of claim 13, wherein the localization area description file is generated by generating a local area description file for each subarea from the spatial features of the point cloud located in the subarea.
前記問合せモジュールは、前記ネットワークインターフェイスを介して前記更新済みローカリゼーションエリア記述ファイルを少なくとも１つの第３の移動体装置に与える、請求項１１〜１４のいずれか１項に記載のコンピューティングシステム。 Before SL spatial features filter module is to update the localization area description file to generate an updated localization area description file based on the feedback data,
15. The computing system of any one of claims 11 to 14, wherein the query module provides the updated localization area description file to at least one third mobile device via the network interface.
前記ローカリゼーションエリア記述ファイルが表わす各空間的特徴毎にスコアを維持することと、
前記ローカリゼーションエリア記述ファイルが表わす空間的特徴について、
前記第２の移動体装置が前記空間的特徴を検出したことを示す前記フィードバックデータに応答して前記空間的特徴のスコアを増加させること、
前記第２の移動体装置が前記空間的特徴を検出しなかったことを示す前記フィードバックデータに応答して前記空間的特徴の前記スコアを減らすこと、および
少なくとも１つのしきい値に対する前記スコアの比較に基づいて前記ローカリゼーションエリア記述ファイルから前記空間的特徴を選択的に除外すること、とによって、
前記ローカリゼーションエリア記述ファイルを更新する、請求項１６に記載のコンピューティングシステム。 The spatial feature filter module includes:
Maintaining a score for each spatial feature represented by the localization area description file;
Regarding spatial features represented by the localization area description file,
Increasing the spatial feature score in response to the feedback data indicating that the second mobile device has detected the spatial feature;
Reducing the score of the spatial feature in response to the feedback data indicating that the second mobile device did not detect the spatial feature, and comparing the score to at least one threshold Selectively excluding the spatial features from the localization area description file based on
The computing system of claim 16, wherein the localization area description file is updated.
前記空間的特徴フィルタモジュールは、
前記第２の移動体装置が検出した前記空間的特徴に関連付けられるスコアを増加させること、および
前記スコアと少なくとも１つのしきい値との比較に応答して、前記第２の移動体装置が検出した前記空間的特徴を含めるように前記ローカリゼーションエリア記述ファイルを選択的に修正すること
によって前記ローカリゼーションエリア記述ファイルを更新する、請求項１７に記載のコンピューティングシステム。 The feedback data identifies spatial features detected by the second mobile device and not represented by the localization area description file;
The spatial feature filter module includes:
In response to increasing the score associated with the spatial feature detected by the second mobile device and comparing the score to at least one threshold value, the second mobile device detects The computing system of claim 17, wherein the localization area description file is updated by selectively modifying the localization area description file to include the spatial feature.
遠隔コンピューティングシステムに結合するネットワークインターフェイスと、
前記移動体装置が位置するエリアでイメージを捕捉する複数の画像化センサと、
捕捉された前記イメージ中の空間的特徴の第１の組を検出する空間的特徴検出モジュールと、
前記ネットワークインターフェイスを介して前記遠隔コンピューティングシステムから前記エリアについてのローカリゼーションエリア記述ファイルを得るローカリゼーションモジュールとを備え、前記ローカリゼーションエリア記述ファイルは、前記エリアについての空間的特徴の第２の組を表わし、前記ローカリゼーションモジュールは、前記空間的特徴の第２の組に対する前記空間的特徴の第１の組の比較に基づいて前記移動体装置を前記エリアに関連付けられる座標フレームにローカライズし、
前記ローカリゼーションモジュールはさらに、前記ネットワークインターフェイスを介して前記遠隔コンピューティングシステムにフィードバックデータを与え、前記フィードバックデータは、前記第１の組の中に前記第２の組の空間的特徴が検出されたか否か、および前記第２の組の中に前記第１の組の空間的特徴が検出されなかったか否かのうち少なくとも１つを同定する、移動体装置。 A mobile device comprising:
A network interface coupled to the remote computing system;
A plurality of imaging sensors for capturing images in an area where the mobile device is located;
A spatial feature detection module for detecting a first set of spatial features in the captured image;
A localization module for obtaining a localization area description file for the area from the remote computing system via the network interface, wherein the localization area description file represents a second set of spatial features for the area; the localization module is to localize the mobile device to the coordinate frame associated with the area based on the first set of comparison of the second set with respect to the spatial characteristics of said spatial features,
The localization module further provides feedback data to the remote computing system via the network interface, the feedback data indicating whether the second set of spatial features is detected in the first set. And at least one of whether the first set of spatial features was not detected in the second set .
遠隔コンピューティングシステムに結合するネットワークインターフェイスと、
前記移動体装置が位置するエリアでイメージを捕捉する複数の画像化センサと、
前記複数の画像化センサに結合される空間的特徴検出モジュールとを備え、前記空間的特徴検出モジュールは、捕捉された前記イメージ中の空間的特徴の組を検出し、さらに
前記イメージの前記捕捉と同時にセンサデータを捕捉する１つ以上の非画像センサの組と、
前記ネットワークインターフェイス、前記空間的特徴検出モジュール、および少なくとも１つの前記非画像センサの組に結合されるアセンブリモジュールとを備え、前記アセンブリモジュールは、前記ネットワークインターフェイスを介してエリア記述ファイルを前記遠隔コンピューティングシステムに与え、前記エリア記述ファイルは、前記空間的特徴の組の選択されたサブセットの点群を表わしかつ前記センサデータを含む、移動体装置。 A mobile device comprising:
A network interface coupled to the remote computing system;
A plurality of imaging sensors for capturing images in an area where the mobile device is located;
A spatial feature detection module coupled to the plurality of imaging sensors, wherein the spatial feature detection module detects a set of spatial features in the captured image; and A set of one or more non-image sensors that simultaneously capture sensor data;
An assembly module coupled to the network interface, the spatial feature detection module, and at least one set of non-image sensors, wherein the assembly module transmits an area description file to the remote computing via the network interface. A mobile device provided to a system, wherein the area description file represents a point cloud of a selected subset of the set of spatial features and includes the sensor data.
前記アセンブリモジュールは、同定された前記エリアについての要求された前記ローカリゼーションエリア記述ファイルが入手不可能であると前記遠隔コンピューティングシステムから示されるのに応答して前記エリア記述ファイルを与える、請求項２０に記載の移動体装置。 The assembly module further identifies an area in which the mobile device is located and requests a localization area description file for the identified area from the remote computing system;
Said assembly module, in response to requested the localization area description file for the identified said area is indicated as being unavailable from said remote computing system providing said area description file, claim 20 A mobile device according to claim 1.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/708,877 US9811734B2 (en) | 2015-05-11 | 2015-05-11 | Crowd-sourced creation and updating of area description file for mobile device localization |
US14/708,877 | 2015-05-11 | ||
PCT/US2016/030940 WO2016182843A1 (en) | 2015-05-11 | 2016-05-05 | Crowd-sourced creation and updating of area description file for mobile device localization |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2018519558A JP2018519558A (en) | 2018-07-19 |
JP6602889B2 true JP6602889B2 (en) | 2019-11-06 |
Family
ID=56133022
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2017550888A Active JP6602889B2 (en) | 2015-05-11 | 2016-05-05 | Creating and updating area description files for mobile device localization by crowdsourcing |
Country Status (6)
Country | Link |
---|---|
US (1) | US9811734B2 (en) |
EP (1) | EP3295128A1 (en) |
JP (1) | JP6602889B2 (en) |
KR (1) | KR102044491B1 (en) |
CN (1) | CN107430686B (en) |
WO (1) | WO2016182843A1 (en) |
Families Citing this family (29)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9026994B2 (en) * | 2013-03-07 | 2015-05-05 | Microsoft Technology Licensing, Llc | Cloud-based localization platform |
US9754419B2 (en) | 2014-11-16 | 2017-09-05 | Eonite Perception Inc. | Systems and methods for augmented reality preparation, processing, and application |
US9916002B2 (en) | 2014-11-16 | 2018-03-13 | Eonite Perception Inc. | Social applications for augmented reality technologies |
US10043319B2 (en) | 2014-11-16 | 2018-08-07 | Eonite Perception Inc. | Optimizing head mounted displays for augmented reality |
CN106454884B (en) * | 2015-08-10 | 2018-05-29 | 上海连尚网络科技有限公司 | For distinguishing the method and apparatus of wireless access point of the same name |
US10607139B2 (en) * | 2015-09-23 | 2020-03-31 | International Business Machines Corporation | Candidate visualization techniques for use with genetic algorithms |
US10685035B2 (en) | 2016-06-30 | 2020-06-16 | International Business Machines Corporation | Determining a collection of data visualizations |
CA3032812A1 (en) | 2016-08-04 | 2018-02-08 | Reification Inc. | Methods for simultaneous localization and mapping (slam) and related apparatus and systems |
US11017712B2 (en) | 2016-08-12 | 2021-05-25 | Intel Corporation | Optimized display image rendering |
US9928660B1 (en) | 2016-09-12 | 2018-03-27 | Intel Corporation | Hybrid rendering for a wearable display attached to a tethered computer |
KR20190098216A (en) | 2016-12-29 | 2019-08-21 | 엘지전자 주식회사 | Electronics |
WO2018134587A1 (en) * | 2017-01-23 | 2018-07-26 | Oxford University Innovation Limited | Determining the location of a mobile device |
EP3590014B1 (en) * | 2017-03-02 | 2021-11-17 | Robart GmbH | Method for controlling an autonomous, mobile robot |
US10937214B2 (en) * | 2017-03-22 | 2021-03-02 | Google Llc | System and method for merging maps |
JP6648061B2 (en) * | 2017-03-28 | 2020-02-14 | Kddi株式会社 | Video distribution apparatus, system, program and method for distributing video according to client status |
US10430147B2 (en) | 2017-04-17 | 2019-10-01 | Intel Corporation | Collaborative multi-user virtual reality |
US10692289B2 (en) * | 2017-11-22 | 2020-06-23 | Google Llc | Positional recognition for augmented reality environment |
US10686611B2 (en) * | 2017-11-24 | 2020-06-16 | International Business Machines Corporation | Data anonymizing blockchain system |
US10957100B2 (en) * | 2018-04-06 | 2021-03-23 | Korea University Research And Business Foundation | Method and apparatus for generating 3D map of indoor space |
CN110530363B (en) * | 2018-05-24 | 2022-08-19 | 北京智慧图科技有限责任公司 | Building-level AP crowdsourcing generation method |
DE102018125397A1 (en) | 2018-10-15 | 2020-04-16 | Visualix GmbH | Method and device for determining an area map |
US10346998B1 (en) * | 2019-02-25 | 2019-07-09 | Nurulize, Inc. | Method of merging point clouds that identifies and retains preferred points |
JP7218426B2 (en) * | 2019-03-01 | 2023-02-06 | 株式会社ソニー・インタラクティブエンタテインメント | ENVIRONMENTAL MAP MANAGEMENT DEVICE, ENVIRONMENTAL MAP MANAGEMENT SYSTEM, ENVIRONMENTAL MAP MANAGEMENT METHOD AND PROGRAM |
KR102354776B1 (en) | 2019-03-04 | 2022-01-25 | 어드밴스드 뉴 테크놀로지스 씨오., 엘티디. | Method and device for providing transaction data to a blockchain system for processing |
CN110533719B (en) * | 2019-04-23 | 2020-06-09 | 以见科技(上海)有限公司 | Augmented reality positioning method and device based on environment visual feature point identification technology |
US10846940B1 (en) | 2020-02-24 | 2020-11-24 | SpotMap, Inc. | Multi-modality localization of users |
CN113822806B (en) * | 2020-06-19 | 2023-10-03 | 北京达佳互联信息技术有限公司 | Image processing method, device, electronic equipment and storage medium |
KR102449855B1 (en) * | 2020-12-07 | 2022-10-04 | 서울과학기술대학교 산학협력단 | Indoor position apparatus amd method using visual localization |
EP4135352A1 (en) * | 2021-08-11 | 2023-02-15 | Nokia Technologies Oy | Localizing a camera-equipped device using a captured visual image |
Family Cites Families (32)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8144920B2 (en) * | 2007-03-15 | 2012-03-27 | Microsoft Corporation | Automated location estimation using image analysis |
WO2009045218A1 (en) | 2007-10-04 | 2009-04-09 | Donovan John J | A video surveillance, storage, and alerting system having network management, hierarchical data storage, video tip processing, and vehicle plate analysis |
US8100692B2 (en) * | 2007-10-19 | 2012-01-24 | Cagenix Incorporated | Dental framework |
EP2535883B1 (en) * | 2008-07-10 | 2014-03-19 | Mitsubishi Electric Corporation | Train-of-vehicle travel support device |
WO2010042916A2 (en) * | 2008-10-12 | 2010-04-15 | Fei Company | High accuracy beam placement for local area navigation |
US8442304B2 (en) * | 2008-12-29 | 2013-05-14 | Cognex Corporation | System and method for three-dimensional alignment of objects using machine vision |
US20120047087A1 (en) | 2009-03-25 | 2012-02-23 | Waldeck Technology Llc | Smart encounters |
US8839121B2 (en) | 2009-05-06 | 2014-09-16 | Joseph Bertolami | Systems and methods for unifying coordinate systems in augmented reality applications |
US20110102460A1 (en) | 2009-11-04 | 2011-05-05 | Parker Jordan | Platform for widespread augmented reality and 3d mapping |
US9488488B2 (en) | 2010-02-12 | 2016-11-08 | Apple Inc. | Augmented reality maps |
JP5471626B2 (en) * | 2010-03-09 | 2014-04-16 | ソニー株式会社 | Information processing apparatus, map update method, program, and information processing system |
WO2011112940A1 (en) | 2010-03-12 | 2011-09-15 | Tagwhat, Inc. | Merging of grouped markers in an augmented reality-enabled distribution network |
CN102960035A (en) | 2010-05-19 | 2013-03-06 | 诺基亚公司 | Extended fingerprint generation |
US20110313779A1 (en) | 2010-06-17 | 2011-12-22 | Microsoft Corporation | Augmentation and correction of location based data through user feedback |
CN103459099B (en) | 2011-01-28 | 2015-08-26 | 英塔茨科技公司 | Mutually exchange with a moveable tele-robotic |
US9239849B2 (en) | 2011-06-08 | 2016-01-19 | Qualcomm Incorporated | Mobile device access of location specific images from a remote database |
US8994799B2 (en) | 2011-07-26 | 2015-03-31 | ByteLight, Inc. | Method and system for determining the position of a device in a light based positioning system using locally stored maps |
US20130101163A1 (en) | 2011-09-30 | 2013-04-25 | Rajarshi Gupta | Method and/or apparatus for location context identifier disambiguation |
US8521128B1 (en) | 2011-12-09 | 2013-08-27 | Google Inc. | Method, system, and computer program product for obtaining crowd-sourced location information |
US8908914B2 (en) | 2012-01-17 | 2014-12-09 | Maxlinear, Inc. | Method and system for map generation for location and navigation with user sharing/social networking |
WO2013126784A2 (en) | 2012-02-23 | 2013-08-29 | Huston Charles D | System and method for creating an environment and for sharing a location based experience in an environment |
US20130242106A1 (en) | 2012-03-16 | 2013-09-19 | Nokia Corporation | Multicamera for crowdsourced video services with augmented reality guiding system |
CN103426003B (en) * | 2012-05-22 | 2016-09-28 | 腾讯科技（深圳）有限公司 | The method and system that augmented reality is mutual |
US9335175B2 (en) | 2012-08-15 | 2016-05-10 | Google Inc. | Crowd-sourcing indoor locations |
US9342929B2 (en) | 2013-01-22 | 2016-05-17 | Microsoft Technology Licensing, Llc | Mixed reality experience sharing |
US9323785B2 (en) | 2013-03-06 | 2016-04-26 | Streamoid Technologies Private Limited | Method and system for mobile visual search using metadata and segmentation |
US20140267234A1 (en) * | 2013-03-15 | 2014-09-18 | Anselm Hook | Generation and Sharing Coordinate System Between Users on Mobile |
US20140323148A1 (en) | 2013-04-30 | 2014-10-30 | Qualcomm Incorporated | Wide area localization from slam maps |
US20140357290A1 (en) | 2013-05-31 | 2014-12-04 | Michael Grabner | Device localization using camera and wireless signal |
CN104021350B (en) | 2014-05-13 | 2016-07-06 | 小米科技有限责任公司 | Privacy information hidden method and device |
CN104020447A (en) * | 2014-05-27 | 2014-09-03 | 美新半导体（无锡）有限公司 | Indoor combined positioning system and positioning method thereof |
US9251417B1 (en) | 2014-10-15 | 2016-02-02 | Hrl Laboratories, Llc | Fast open doorway detection for autonomous robot exploration |
-
2015
- 2015-05-11 US US14/708,877 patent/US9811734B2/en active Active
-
2016
- 2016-05-05 JP JP2017550888A patent/JP6602889B2/en active Active
- 2016-05-05 CN CN201680018930.7A patent/CN107430686B/en active Active
- 2016-05-05 WO PCT/US2016/030940 patent/WO2016182843A1/en active Application Filing
- 2016-05-05 EP EP16729653.2A patent/EP3295128A1/en not_active Ceased
- 2016-05-05 KR KR1020177028033A patent/KR102044491B1/en active IP Right Grant
Also Published As
Publication number | Publication date |
---|---|
US20160335497A1 (en) | 2016-11-17 |
CN107430686B (en) | 2022-01-28 |
WO2016182843A1 (en) | 2016-11-17 |
JP2018519558A (en) | 2018-07-19 |
CN107430686A (en) | 2017-12-01 |
US9811734B2 (en) | 2017-11-07 |
EP3295128A1 (en) | 2018-03-21 |
KR102044491B1 (en) | 2019-11-13 |
KR20180004109A (en) | 2018-01-10 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6602889B2 (en) | Creating and updating area description files for mobile device localization by crowdsourcing | |
KR102149374B1 (en) | Privacy-sensitive query for localization area description files | |
EP3295129B1 (en) | Privacy filtering of area description file prior to upload | |
US11830149B2 (en) | Cross reality system with prioritization of geolocation information for localization | |
US10885714B2 (en) | Cloud enabled augmented reality | |
US11532124B2 (en) | Cross reality system with WIFI/GPS based map merge | |
WO2021222371A9 (en) | Cross reality system for large scale environments | |
US11694394B2 (en) | Cross reality system for large scale environment reconstruction | |
CN105023266A (en) | Method and device for implementing augmented reality (AR) and terminal device | |
US11094079B2 (en) | Determining a pose of an object from RGB-D images | |
JP6495538B2 (en) | Image content search | |
US10373385B2 (en) | Subtractive rendering for augmented and virtual reality systems | |
CN113950609A (en) | Coarse relocation using signal fingerprints and session-specific identifiers |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20171205 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20171205 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20181211 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20190205 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20190423 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20190910 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20191009 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6602889Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |