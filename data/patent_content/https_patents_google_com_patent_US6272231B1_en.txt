US6272231B1 - Wavelet-based facial motion capture for avatar animation - Google Patents
Wavelet-based facial motion capture for avatar animation Download PDFInfo
- Publication number
- US6272231B1 US6272231B1 US09/188,079 US18807998A US6272231B1 US 6272231 B1 US6272231 B1 US 6272231B1 US 18807998 A US18807998 A US 18807998A US 6272231 B1 US6272231 B1 US 6272231B1
- Authority
- US
- United States
- Prior art keywords
- image
- facial
- node
- feature sensing
- sensing
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/20—Analysis of motion
- G06T7/246—Analysis of motion using feature-based methods, e.g. the tracking of corners or segments
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/20—Analysis of motion
- G06T7/262—Analysis of motion using transform domain methods, e.g. Fourier domain methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
- G06V10/42—Global feature extraction by analysis of the whole pattern, e.g. using frequency domain transformations or autocorrelation
- G06V10/422—Global feature extraction by analysis of the whole pattern, e.g. using frequency domain transformations or autocorrelation for representing the structure of the pattern or shape of an object therefor
- G06V10/426—Graphical representations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
- G06V10/44—Local feature extraction by analysis of parts of the pattern, e.g. by detecting edges, contours, loops, corners, strokes or intersections; Connectivity analysis, e.g. of connected components
- G06V10/443—Local feature extraction by analysis of parts of the pattern, e.g. by detecting edges, contours, loops, corners, strokes or intersections; Connectivity analysis, e.g. of connected components by matching or filtering
- G06V10/449—Biologically inspired filters, e.g. difference of Gaussians [DoG] or Gabor filters
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
- G06V40/161—Detection; Localisation; Normalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
- G06V40/161—Detection; Localisation; Normalisation
- G06V40/165—Detection; Localisation; Normalisation using facial parts and geometric relationships
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20048—Transform domain processing
- G06T2207/20064—Wavelet transform [DWT]
Definitions
- the present invention relates to dynamic facial feature sensing, and more particularly, to a vision-based motion capture system that allows real-time finding, tracking and classification of facial features for input into a graphics engine that animates an avatar.
- Virtual spaces filled with avatars are an attractive way to allow for the experience of a shared environment.
- existing shared environments generally lack facial feature sensing of sufficient quality to allow for the incarnation of a user, i.e., the endowment of an avatar with the likeness, expressions or gestures of the user.
- Quality facial feature sensing is a significant advantage because facial gestures are a primordial means of communications.
- the incarnation of a user augments the attractiveness of virtual spaces.
- the present invention is embodied in an apparatus, and related method, for sensing a person's facial movements, features or characteristic.
- the results of the facial sensing may be used to animate an avatar image.
- the avatar apparatus uses an image processing technique based on model graphs and bunch graphs that efficiently represent image features as jets composed of wavelet transforms at landmarks on a facial image corresponding to readily identifiable features.
- the sensing system allows tracking of a person's natural characteristics without any unnatural elements to interfere with the person's natural characteristics.
- the feature sensing process operates on a sequence of image frames transforming each image frame using a wavelet transformation to generate a transformed image frame.
- Node locations associated with wavelets jets of a model graph to the transformed image frame are initialized by moving the model graph across the transformed image frame and placing the model graph at a location in the transformed image frame of maximum jet similarity between the wavelet jets at the node locations and the transformed image frame.
- the location of one or more node locations of the model graph is tracked between image frames. A tracked node is reinitialized if the node's position deviates beyond a predetermined position constraint between image frames.
- the facial feature finding may be based on elastic bunch graph matching for individualizing a head model.
- the model graph for facial image analysis may include a plurality of location nodes (e.g., 18 ) associated with distinguishing features on a human face.
- FIG. 1 is a block diagram of an avatar animation system and process, according to the invention.
- FIG. 2 is block diagram of a facial feature sensing apparatus and process, according to the invention, for the avatar animation system and process of FIG. 1 .
- FIG. 3 is a block diagram of a video image processor for implementing the facial feature sensing apparatus of FIG. 2 .
- FIG. 4 is a flow diagram, with accompanying photographs, for illustrating a landmark finding technique of the facial feature sensing apparatus and system of FIG. 2 .
- FIG. 5 is a series of images showing processing of a facial image using Gabor wavelets, according to the invention.
- FIG. 6 is a series of graphs showing the construction of a jet, image graph, and bunch graph using the wavelet processing technique of FIG. 5, according to the invention.
- FIG. 7 is a diagram of a model graph, according to the invention, for processing facial images.
- FIG. 8 includes two diagrams showing the use of wavelet processing to locate facial feature.
- FIG. 9 is a flow diagram showing a tracking technique for tracking landmarks found by the landmark finding technique of FIG. 4 .
- FIG. 10 is a diagram of a Gaussian image pyramid technique for illustrating landmark tracking in one dimension.
- FIG. 11 is a series of two facial images, with accompanying graphs of pose angle versus frame number, showing tracking of facial features over a sequence of 50 image frames.
- FIG. 12 is a flow diagram, with accompanying photographs, for illustrating a pose estimation technique of the facial feature sensing apparatus and system of FIG. 2 .
- FIG. 13 is a schematic diagram of a face with extracted eye and mouth regions, for illustrating a course-to-fine landmark finding technique.
- FIG. 14 are photographs showing the extraction of profile and facial features using the elastic bunch graph technique of FIG. 6 .
- FIG. 15 is a flow diagram showing the generation of a tagged personalized bunch graph along with a corresponding gallery of image patches that encompasses a variety of a person's expressions for avatar animation, according with the invention.
- FIG. 16 is a flow diagram showing a technique for animating an avatar using image patches that are transmitted to a remote site, and that are selected at the remote site based on transmitted tags based on facial sensing associated with a person's current facial expressions.
- FIG. 17 is a flow diagram showing rendering of a three-dimensional head image generated, based on facial feature positions and tags, using volume morphing integrated with dynamic texture generation.
- FIG. 18 is a block diagram of an avatar animation system, according to the invention, that includes audio analysis for animating an avatar.
- the present invention is embodied in an apparatus, and related method, for sensing a person's facial movements, features and characteristics and the like to generate and animate an avatar image based on the facial sensing.
- the avatar apparatus uses an image processing technique based on model graphs and bunch graphs that efficiently represent image features as jets.
- the jets are composed of wavelet transforms that are processed at node or landmark locations on an image corresponding to readily identifiable features.
- the nodes are acquired and tracked to animate an avatar image in accordance with the person's facial movements.
- the facial sensing may use jet similarity to determine the person's facial features and characteristics thus allowing tracking of a person's natural characteristics without any unnatural elements that may interfere with the person's natural characteristics.
- the avatar animation system 10 of the invention includes an imaging system 12 , a facial sensing process 14 , a data communication network 16 , a facial animation process 18 , and an avatar display 20 .
- the imaging system acquires and digitizes a live video image signal of a person thus generating a stream of digitized video data organized into image frames.
- the digitized video image data is provided to the facial sensing process which locates the person's face and corresponding facial features in each frame.
- the facial sensing process also tracks the positions and characteristics of the facial features from frame-to-frame.
- the tracking information may be transmitted via the network to one or more remote sites which receives the information and generates, using a graphics engine, an animated facial image on the avatar display.
- the animated facial image may be based on a photorealistic model of the person, a cartoon character or a face completely unrelated to the user.
- the imaging system 12 and the facial sensing process 14 are shown in more detail in FIGS. 2 and 3.
- the imaging system captures the person's image using a digital video camera 22 which generates a stream of video image frames.
- the video image frames are transferred into a video random-access memory (VRAM) 24 for processing.
- VRAM video random-access memory
- a satisfactory imaging system is the Matrox Meteor II available from MatroxTM which generates digitizing images produced by a conventional CCD camera and transfers the images in real-time into the memory at a frame rate of 30 Hz.
- the image frame is processed by an image processor 26 having a central processing unit (CPU) 28 coupled to the VRAM and random-access memory RAM 30 .
- the RAM stores program code and data for implementing the facial sensing and avatar animation processes.
- the facial feature process operates on the digitized images to find the person's facial feature (block 32 ), track the features (block 34 ), and reinitializes feature tracking as needed.
- the facial features also may be classified (block 36 ).
- the facial feature process generates data associated with the position and classification of the facial features with is provided to an interface with the facial animation process (block 38 )
- the facial feature may be located using an elastic graph matching shown in FIG. 4 .
- a captured image (block 40 ) is transformed into Gabor space using a wavelet transformation (block 42 ) which is described below in more detail with respect to FIG. 5 .
- the transformed image (block 44 ) is represented by 40 complex values, representing wavelet components, per each pixel of the original image.
- a rigid copy of a model graph which is described in more detail below with respect to FIG. 7, is positioned over the transformed image at varying model node positions to locate a position of optimum similarity (block 46 ).
- the search for the optimum similarity may be performed by positioning the model graph in the upper left hand corner of the image, extracting the jets at the nodes, and determining the similarity between the image graph and the model graph.
- the search continues by sliding the model graph left to right starting from the upper-left corner of the image (block 48 ).
- the nodes are individually allowed to move, introducing elastic graph distortions (block 52 ).
- a phase-insensitive similarity function is used in order to locate a good match (block 54 ).
- a phase-sensitive similarity function is then used to locate a jet with accuracy because the phase is very sensitive to small jet displacements.
- the phase-insensitive and the phase-sensitive similarity functions are described below with respect to FIGS. 5-8. Note that although the graphs are shown in FIG. 4 with respect to the original image, the model graph movements and matching are actually performed on the transformed image.
- the wavelet transform is described with reference to FIG. 5 .
- An original image is processed using a Gabor wavelet to generate a convolution result.
- the Gabor-based wavelet consists of a two-dimensional complex wave field modulated by a Gaussian envelope.
- ⁇ k ⁇ ⁇ ( x ) k 2 ⁇ 2 ⁇ ⁇ - x 2 ⁇ k 2 2 ⁇ ⁇ 2 ⁇ ⁇ ⁇ ⁇ ⁇ ⁇ k ⁇ x ⁇ - ⁇ - ⁇ 2 2 ⁇ ( 1 )
- the wavelet is a plane wave with wave vector ⁇ right arrow over (k) ⁇ , restricted by a Gaussian window, the size of which relative to the wavelength is parameterized by ⁇ .
- the term in the brace removes the DC component.
- a wavelet, centered at image position ⁇ right arrow over (x) ⁇ is used to extract the wavelet component J ⁇ right arrow over (k) ⁇ from the image with gray level distribution I( ⁇ right arrow over (x) ⁇ ),
- the space of wave vectors ⁇ right arrow over (k) ⁇ is typically sampled in a discrete hierarchy of 5 resolution levels (differing by half-octaves) and 8 orientations at each resolution level (see, e.g., FIG. 8 ), thus generating 40 complex values for each sampled image point (the real and imaginary components referring to the cosine and sine phases of the plane wave).
- Each jet describes the local features of the area surrounding ⁇ right arrow over (x) ⁇ . If sampled with sufficient density, the image may be reconstructed from jets within the bandpass covered by the sampled frequencies.
- each component of a jet is the filter response of a Gabor wavelet extracted at a point (x, y) of the image.
- a labeled image graph 62 is used to describe the aspect of an object (in this context, a face).
- the nodes 64 of the labeled graph refer to points on the object and are labeled by jets 60 .
- Edges 66 of the graph are labeled with distance vectors between the nodes. Nodes and edges define the graph topology. Graphs with equal topology can be compared. The normalized dot product of the absolute components of two jets defines the jet similarity. This value is independent of contrast changes. To compute the similarity between two graphs, the sum is taken over similarities of corresponding jets between the graphs.
- a model graph 68 that is particularly designed for finding a human face in an image is shown in FIG. 7 .
- the numbered nodes of the graph have the following locations:
- a data structure called a bunch graph 70 (FIG. 6) is used. It is similar to the graph described above, but instead of attaching only a single jet to each node, a whole bunch of jets 72 (a bunch jet) are attached to each node. Each jet is derived from a different facial image.
- a bunch graph a collection of facial images (the bunch graph gallery) is marked with node locations at defined positions of the head. These defined positions are called landmarks.
- the jet extracted from the image is compared to all jets in the corresponding bunch attached to the bunch graph and the best-matching one is selected. This matching process is called elastic bunch graph matching.
- a bunch graph covers a great variety of faces that may have significantly different local properties e.g. samples of male and female faces, and of persons of different ages or races.
- the graph is moved and scaled and distorted until a place is located at which the graph matches best (the best fitting jets within the bunch jets are most similar to jets extracted from the image at the current positions of the nodes). Since face features differ from face to face, the graph is made more general for the task, e.g. each node is assigned with jets of the corresponding landmark taken from 10 to 100 individual faces.
- This function includes a relative displacement vector between the image points to which the two jets refer.
- the similarity between them is maximized with respect to d, leading to an accurate determination of jet position.
- Both similarity functions are used, with preference often given to the phase-insensitive version (which varies smoothly with relative position) when first matching a graph, and to the phase-sensitive version when accurately positioning the jet.
- the facial features may be tracked over consecutive frames as illustrated in FIG. 9 .
- the tracking technique of the invention achieves robust tracking over long frame sequences by using a tracking correction scheme that detects whether tracking of a feature or node has been lost and reinitializes the tracking process for that node.
- the position X_n of a single node in an image I_n of an image sequence is known either by landmark finding on image I_n using the landmark finding method (block 80 ) described above, or by tracking the node from image I_(n ⁇ 1) to I_n using the tracking process.
- the node is then tracked (block 82 ) to a corresponding position X_(n+1) in the image I_(n+1) by one of several techniques.
- the tracking methods described below advantageously accommodate fast motion.
- a first tracking technique involves linear motion prediction.
- the search for the corresponding node position X_(n+1) in the new image I_(n+1) is started at a position generated by a motion estimator.
- a disparity vector (X_n-X_(n ⁇ 1)) is calculated that represents the displacement, assuming constant velocity, of the node between the preceding two frames.
- the disparity or displacement vector D_n may be added to the position X_n to predict the node position X_(n+1).
- This linear motion model is particularly advantageous for accommodating constant velocity motion.
- the linear motion model also provides good tracking if the frame rate is high compared to the acceleration of the objects being tracked. However, the linear motion model performs poorly if the frame rate is too low compared to the acceleration of the objects in the image sequence. Because it is difficult for any motion model to track objects under such conditions, use of a camera having a higher frame rate is recommended.
- the linear motion model may generate too large of an estimated motion vector D_n which could lead to an accumulation of the error in the motion estimation. Accordingly, the linear prediction may be damped using a damping factor f_D.
- FIG. 10 A tracking technique based on a Gaussian image pyramid, applied to one dimension, is illustrated in FIG. 10 .
- the image is down sampled 2-4 times to create a Gaussian pyramid of the image.
- An image pyramid of 4 levels results in a distance of 24 pixels on the finest, original resolution level being represented as only 3 pixels on the coarsest level. Jets may be computed and compared at any level of the pyramid.
- Tracking of a node on the Gaussian image pyramid is generally performed first at the most coarse level and then preceding to the most fine level.
- the position on the next finer Gauss level of the actual image (being 2*X_(n+1)), corresponding to the position X_(n+1) on the coarsest Gauss level is the starting point for the disparity computation on this next finer level.
- the jet extracted at this point is compared to the corresponding jet calculated on the same Gauss level of the previous image frame. This process is repeated for all Gauss levels until the finest resolution level is reached, or until the Gauss level is reached which is specified for determining the position of the node corresponding to the previous frame's position.
- FIG. 10 Two representative levels of the Gaussian image pyramid are shown in FIG. 10, a coarser level 94 above, a finer level 96 below.
- Each jet is assumed to have filter responses for two frequency levels.
- a second disparity move by using all jet coefficients of both frequency levels leads to position 3 , the final position on this Gauss level.
- Position 1 on the finer Gauss level corresponds to position 3 on the coarser level with the coordinates being doubled.
- the disparity move sequence is repeated, and position 3 on the finest Gauss level is the final position of the tracked landmark.
- the number of Gauss and frequency levels may be increased. After the new position of the tracked node in the actual image frame has been determined, the jets on all Gauss levels are computed at this position. A stored array of jets that was computed for the previous frame, representing the tracked node, is then replaced by a new array of jets computed for the current frame.
- Gauss image pyramid has two main advantages: First, movements of nodes are much smaller in terms of pixels on a coarser level than in the original image, which makes tracking possible by performing only a local move instead of an exhaustive search in a large image region. Second, the computation of jet components is much faster for lower frequencies, because the computation is performed with a small kernel window on a down sampled image, rather than on a large kernel window on the original resolution image.
- correspondence level may be chosen dynamically, e.g., in the case of tracking facial features, correspondence level may be chosen dependent on the actual size of the face. Also the size of the Gauss image pyramid may be altered through the tracking process, i.e., the size may be increased when motion gets faster, and decreased when motion gets slower. Typically, the maximal node movement on the coarsest Gauss level is limited to 4 pixels. Also note that the motion estimation is often performed only on the coarsest level.
- jets may be extracted (i.e., computed by convolution) at (integer) pixel positions only, resulting in a systematic rounding error.
- the phases of the complex Gabor filter responses should be shifted according to
- Gabor jets may be tracked with subpixel accuracy without any further accounting of rounding errors. Note that Gabor jets provide a substantial advantage in image processing because the problem of subpixel accuracy is more difficult to address in most other image processing methods.
- Tracking error may be detected by determining whether a confidence or similarity value is smaller than a predetermined threshold (block 84 of FIG. 9 ).
- the similarity (or confidence) value S may be calculated to indicate how well the two image regions in the two image frames correspond to each other simultaneous with the calculation of the displacement of a node between consecutive image frames.
- the confidence value is close to 1, indicating good correspondence. If the confidence value is not close to 1, either the corresponding point in the image has not been found (e.g., because the frame rate was too low compared to the velocity of the moving object), or this image region has changed so drastically from one image frame to the next, that the correspondence is no longer well defined (e.g., for the node tracking the pupil of the eye the eyelid has been closed). Nodes having a confidence value below a certain threshold may be switched off.
- a tracking error also may be detected when certain geometrical constraints are violated (block 86 ). If many nodes are tracked simultaneously, the geometrical configuration of the nodes may be checked for consistency. Such geometrical constraints may be fairly loose, e.g., when facial features are tracked, the nose must be between the eyes and the mouth. Alternatively, such geometrical constraints may be rather accurate, e.g., a model containing the precise shape information of the tracked face. For intermediate accuracy, the constraints may be based on a flat plane model. In the flat plane model, the nodes of the face graph are assumed to be on a flat plane. For image sequences that start with the frontal view, the tracked node positions may be compared to the corresponding node positions of the frontal graph transformed by an affine transformation to the actual frame.
- the 6 parameters of the optimal affine transformation are found by minimizing the least squares error in the node positions. Deviations between the tracked node positions and the transformed node positions are compared to a threshold. The nodes having deviations larger than the threshold are switched off. The parameters of the affine transformation may be used to determine the pose and relative scale (compared to the start graph) simultaneously (block 88 ). Thus, this rough flat plane model assures that tracking errors may not grow beyond a predetermined threshold.
- the node may be reactivated at the correct position (block 90 ), advantageously using bunch graphs that include different poses and tracking continued from the corrected position (block 92 ).
- the system may wait until a predefined pose is reached for which a pose specific bunch graph exists. Otherwise, if only a frontal bunchgraph is stored, the system must until the frontal pose is reached to correct any tracking errors.
- the stored bunch of jets may be compared to the image region surrounding the fit position (e.g., from the flat plane model), which works in the same manner as tracking, except that instead of comparing with the jet of the previous image frame, the comparison is repeated with all jets of the bunch of examples, and the most similar one is taken. Because the facial features are known, e.g., the actual pose, scale, and even the rough position, graph matching or an exhaustive searching in the image and/or pose space is not needed and node tracking correction may be performed in real time.
- bunch graphs are not needed for many different poses and scales because rotation in the image plane as well as scale may be taken into account by transforming either the local image region or the jets of the bunch graph accordingly as shown in FIG. 11 .
- bunch graphs need to be created only for rotations in depth.
- the speed of the reinitialization process may be increased by taking advantage of the fact that the identity of the tracked person remains the same during an image sequence. Accordingly, in an initial learning session, a first sequence of the person may be taken with the person exhibiting a full repertoire of frontal facial expressions. This first sequence may be tracked with high accuracy using the tracking and correction scheme described above based on a large generalized bunch graph that contains knowledge about many different persons. This process may be performed offline and generates a new personalized bunch graph. The personalized bunch graph then may be used for tracking this person at a fast rate in real time because the personalized bunch graph is much smaller than the larger, generalized bunch graph.
- the speed of the reinitialization process also may be increased by using a partial bunch graph reinitialization.
- a partial bunch graph contains only a subset of the nodes of a full bunch graph. The subset may be as small as only a single node.
- a pose estimation bunch graph makes use of a family of two-dimensional bunch graphs defined in the image plane.
- the different graphs within one family account for different poses and/or scales of the head.
- the landmark finding process attempts to match each bunch graph from the family to the input image in order to determine the pose or size of the head in the image.
- An example of such pose-estimation procedure is shown in FIG. 12 .
- the first step of the pose estimation is equivalent to that of the regular landmark finding.
- the image (block 98 ) is transformed (blocks 100 and 102 ) in order to use the graph similarity functions. Then, instead of only one, a family of three bunch graphs is used.
- the first bunch graph contains only the frontal pose faces (equivalent to the frontal view described above), and the other two bunch graphs contain quarter-rotated faces (one representing rotations to the left and one to the right).
- the initial positions for each of the graphs is in the upper left corner, and the positions of the graphs are scanned on the image and the position and graph returning the highest similarity after the landmark finding is selected (blocks 104 - 114 )
- the similarities of the final positions are compared (block 116 ).
- the graph that best corresponds to the pose given on the image will have the highest similarity.
- the left-rotated graph provides the best fit to the image, as indicated by its similarity (block 118 ).
- similarity of the correct graph and graphs for other poses would vary, becoming very close when the face is about half way between the two poses for which the graphs have been defined.
- a finer pose estimation procedure may be implemented that would discriminate between more degrees of head rotation and handle rotations in other directions (e.g. up or down).
- a three dimensional (3D) landmark finding techniques related to the technique described above also may use multiple bunch graphs adapted to different poses.
- the 3D approach employs only one bunch graph defined in 3D space.
- the geometry of the 3D graph reflects an average face or head geometry.
- Each jet is now parameterized with the three rotation angles.
- the nodes are located at the fiducial points of the head surface. Projections of the 3D graph are then used in the matching process.
- One important generalization of the 3D approach is that every node has the attached parameterized family of bunch jets adapted to different poses.
- the second generalization is that the graph may undergo Euclidean transformations in 3D space and not only transformations in the image plane.
- the graph matching process may be formulated as a coarse-to-fine approach that first utilizes graphs with fewer nodes and kernels and then in subsequent steps utilizes more dense graphs.
- the coarse-to-fine approach is particularly suitable if high precision localization of the feature points in certain areas of the face is desired.
- computational effort is saved by adopting a hierarchical approach in which landmark finding is first performed on a coarser resolution, and subsequently the adapted graphs are checked at a higher resolution to analyze certain regions in finer detail.
- the computational workload may be easily split on a multi-processor machine such that once the coarse regions are found, a few child processes start working in parallel each on its own part of the whole image. At the end of the child processes, the processes communicate the feature coordinates that they located to the master process, which appropriately scales and combines them to fit back into the original image thus considerably reducing the total computation time.
- the facial features corresponding to the nodes may be classified to account for inappropriate tracking error indications such as, for example, blinking or mouth opening.
- Labels are attached to the different jets in the bunch graph corresponding the facial features, e.g., eye open/closed, mouth open/closed, etc.
- the labels may be copied along with the corresponding jet in the bunch graph which is most similar one compared to the current image.
- the label tracking may be continuously monitored, regardless of whether a tracking error detected. Accordingly, classification nodes may be attached to the tracked nodes for the following:
- wrinkle detection e.g., on the forehead
- tracking allows utilization of two information sources.
- One information source is based on the feature locations, i.e. the node positions, and the other information source is based on the feature classes.
- the feature class information is more texture based and, by comparing the local image region with a set of stored examples, may function using lower resolution and tracking accuracy then feature class information that is based solely on the node positions.
- the facial sensing of the invention may be applied to the creation and animation of static and dynamic avatars as shown in FIG. 14 .
- the avatar may be based on a generic facial model or based on a person specific facial model.
- the tracking and facial expression recognition may be used for the incarnation the avatar with the person's features.
- the generic facial model may be adapted to a representative number of individuals and may be adapted to perform realistic animation and rendering of a wide range of facial features and/or expressions.
- the generic a model may be obtained by the following techniques.
- Mono-camera systems may be used (T. Akimoto et al. 1993) to produce a realistic avatar for use in low-end tele-immersion systems. Face profile information of individuals, as seen from sagital and coronal planes, may be merged to obtain the avatar.
- Stereo-camera systems are able to perform accurate 3-D measurements when the cameras are fully calibrated (camera parameters are computed through a calibration process). An individual facial model may then be obtained by fitting a generic facial model to the obtained 3-D data. Because stereo algorithms do not provide accurate information on non-textured areas, projection of active-textured light may be used.
- Laser-based surface scanning devices such as those developed by Cyberware, Inc. that provide accurate face measurements.
- a generic three-dimensional head model for a specific person can be generated using two facial images showing a frontal and a profile view. Facial sensing enables efficiently and robustly generation of the 3-D head model.
- Facial contour extraction is performed together with the localization of the person's eyes, nose, mouth and chin.
- This feature location information may be obtained by using the using the elastic bunch graph technique in combination with hierarchical matching to automatically extract facial features as shown in FIG. 14 .
- the feature location information may then be combined (see T. Akimoto and Y. Suenaga. Automatic Creation of 3D Facial Models. In IEEE Computer Graphics & Applications, pages 16-22. September 1993.) to produce a 3D model of the person's head.
- a generic three dimensional head model is adapted so that its proportions are related to the image's measurements.
- both side and front images may be combined to obtain a better texture model for the avatar, i.e. the front view is used to texture map the front of the model and the side view is used for the side of the model. Facial sensing improves this technique because extracted features may be labeled (known points may be defined in the profile) so that the two images need not be taken simultaneously.
- An avatar image may be animated by the following common techniques (see F. I. Parke and K. Waters. Computer Facial Animation. A K Peters, Ltd. Wellesley, Massachusetts, 1996).
- Geometric interpolation is then used between the key frames to provide animation.
- Such a system is frequently referred to as a performance-based (or performance-driven) model.
- Direct parameterization which directly maps expressions and pose to a set of parameters that are then used to drive the model.
- Muscle-based models where muscles and skin are modeled using physical models.
- 2-D and 3-D Morphing which use 2D morphing between images in a video stream to produce 2D animation.
- a set of landmarks are identified and used to warp between two images of a sequence.
- Such a technique can be extended to 3D (See, F. F. Pighin, J. Hecker, D. Lischinski, R. Szeliski, and D. H. Salesin. Synthesizing Realistic Facial Expressions from Photographs. In SIGGRAPH 98 Conference Proceedings, pages 75-84. July 1998.).
- facial sensing enhances the animation process by providing automatic extraction and characterization of facial features.
- Extracted features may be used to interpolate expressions in the case of key framing and interpolation models, or to select parameters for direct parameterized models or pseudo-muscles or muscles models.
- facial sensing may be used to automatically select features on a face providing the appropriate information to perform the geometric transformation.
- FIG. 15 An example of an avatar animation that uses facial feature tracking and classification may be shown with respect to FIG. 15 .
- the individual is prompted for a series of predetermined facial expressions (block 120 ), and sensing is used to track the features (block 122 ).
- jets and image patches are extracted for the various expressions (block 124 ).
- Image patches surrounding facial features are collected along with the jets 126 extracted from these features.
- These jets are used later to classify or tag facial features 128 . This is done by using these jets to generate a personalized bunch graph and by applying the classification method described above.
- the system transmits all image patches 128 , as well as the image of the whole face 130 (the “face frames”) minus the parts shown in the image patches to a remote site (blocks 132 & 134 ).
- the software for the animation engine also may need to be transmitted.
- the sensing system then observes the user's face and facial sensing is applied to determine which of the image patches is most similar to the current facial expression (blocks 136 & 138 ).
- the image tags are transmitted to the remote site (block 140 ) allowing the animation engine to assemble the face 142 using the correct image patches.
- Gaussian blurring may be employed.
- local image morphing may be needed because the animation may not be continuous in the sense that a succession of images may be presented as imposed by the sensing.
- the morphing may be realized using linear interpolation of corresponding points on the image space.
- linear interpolation is applied using the following equations:
- the image interpolation may be implemented using a pre-computed hash table for P i and I i . Based on the number and accuracy of points used, and their accuracy, the interpolated facial model generally determines the resulting image quality.
- the reconstructed face in the remote display may be composed by assembling pieces of images corresponding to the detected expressions in the learning step. Accordingly, the avatar exhibits features corresponding to the person commanding the animation.
- a set of cropped images corresponding to each tracked facial feature and a “face container” as the resulting image of the face after each feature is removed.
- the animation is started and facial sensing is used to generate specific tags which are transmitted as described previously. Decoding occurs by selecting image pieces associated with the transmitted tag, e.g., the image of the mouth labeled with a tag “smiling-mouth” 146 (FIG. 16 ).
- a more advanced level of avatar animation may be reached when the aforementioned dynamic texture generation is integrated with more conventional techniques of volume morphing as shown in FIG. 17 ).
- the location of the node positions may be used to drive control points on a mesh 150 .
- the textures 152 dynamically generated using tags are then mapped onto the mesh to generate a realistic head image 154 .
- An alternative to using the sensed node positions as drivers of control points on the mesh is to use the tags to select local morph targets.
- a morph target is a local mesh configuration that has been determined for the different facial expressions and gestures for which sample jets have been collected. These local mesh geometries can be determined by stereo vision techniques.
- the use of morph targets is further developed in the following references community (see, J. R. Kent, W. E. Carlson, and R. E. Parent, Shape Transformation for Polyhedral Objects, In SIGGRAPH 92 Conference Proceedings, volume 26, pages 47-54, August 1992; Pighin et al. 1998, supra).
- a useful extension to the vision-based avatar animation is to integrate the facial sensing with speech analysis in order to synthesize the correct lip motion as shown in FIG. 18 .
- the lip synching technique is particularly useful to map lip motions resulting from speech onto an avatar. It is also helpful as a back-up in case the vision-based lip tracking fails.
Abstract
Description
Claims (24)
Priority Applications (17)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/188,079 US6272231B1 (en) | 1998-11-06 | 1998-11-06 | Wavelet-based facial motion capture for avatar animation |
KR10-2000-7011375A KR100530812B1 (en) | 1998-04-13 | 1999-04-12 | Wavelet-based facial motion capture for avatar animation |
JP2000543930A JP3970520B2 (en) | 1998-04-13 | 1999-04-12 | Capturing facial movements based on wavelets to animate a human figure |
EP99918494A EP1072018B1 (en) | 1998-04-13 | 1999-04-12 | Wavelet-based facial motion capture for avatar animation |
PCT/US1999/007933 WO1999053443A1 (en) | 1998-04-13 | 1999-04-12 | Wavelet-based facial motion capture for avatar animation |
AU36396/99A AU3639699A (en) | 1998-04-13 | 1999-04-12 | Wavelet-based facial motion capture for avatar animation |
BRPI9909611-0A BR9909611B1 (en) | 1998-04-13 | 1999-04-12 | Method and apparatus for detecting facial features in a sequence of image frames comprising an image of a face. |
CA002327304A CA2327304A1 (en) | 1998-04-13 | 1999-04-12 | Wavelet-based facial motion capture for avatar animation |
AT99918494T ATE248409T1 (en) | 1998-04-13 | 1999-04-12 | WAVELET-BASED FACIAL MOTION CAPTURE FOR AVATA ANIMATION |
DE69910757T DE69910757T2 (en) | 1998-04-13 | 1999-04-12 | WAVELET-BASED FACIAL MOTION DETECTION FOR AVATAR ANIMATION |
US09/871,370 US6580811B2 (en) | 1998-04-13 | 2001-05-31 | Wavelet-based facial motion capture for avatar animation |
US09/915,205 US6714661B2 (en) | 1998-11-06 | 2001-07-24 | Method and system for customizing facial feature tracking using precise landmark finding on a neutral face image |
US09/915,235 US20020067362A1 (en) | 1998-11-06 | 2001-07-24 | Method and system generating an avatar animation transform using a neutral face image |
US09/929,516 US6940454B2 (en) | 1998-04-13 | 2001-08-13 | Method and system for generating facial animation values based on a combination of visual and audio information |
US09/929,295 US7050655B2 (en) | 1998-11-06 | 2001-08-13 | Method for generating an animated three-dimensional video head |
US10/238,289 US20030007666A1 (en) | 1998-04-13 | 2002-09-09 | Method and apparatus for relief texture map flipping |
JP2006329956A JP4177402B2 (en) | 1998-04-13 | 2006-12-06 | Capturing facial movements based on wavelets to animate a human figure |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/188,079 US6272231B1 (en) | 1998-11-06 | 1998-11-06 | Wavelet-based facial motion capture for avatar animation |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US72432000A Continuation-In-Part | 1998-04-13 | 2000-11-27 |
Related Child Applications (5)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US72432000A Continuation-In-Part | 1998-04-13 | 2000-11-27 | |
US09/871,370 Continuation US6580811B2 (en) | 1998-04-13 | 2001-05-31 | Wavelet-based facial motion capture for avatar animation |
US09/915,205 Continuation-In-Part US6714661B2 (en) | 1998-11-06 | 2001-07-24 | Method and system for customizing facial feature tracking using precise landmark finding on a neutral face image |
US09/915,235 Continuation-In-Part US20020067362A1 (en) | 1998-11-06 | 2001-07-24 | Method and system generating an avatar animation transform using a neutral face image |
US09/929,516 Continuation US6940454B2 (en) | 1998-04-13 | 2001-08-13 | Method and system for generating facial animation values based on a combination of visual and audio information |
Publications (1)
Publication Number | Publication Date |
---|---|
US6272231B1 true US6272231B1 (en) | 2001-08-07 |
Family
ID=22691697
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/188,079 Expired - Lifetime US6272231B1 (en) | 1998-04-13 | 1998-11-06 | Wavelet-based facial motion capture for avatar animation |
US09/929,516 Expired - Lifetime US6940454B2 (en) | 1998-04-13 | 2001-08-13 | Method and system for generating facial animation values based on a combination of visual and audio information |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/929,516 Expired - Lifetime US6940454B2 (en) | 1998-04-13 | 2001-08-13 | Method and system for generating facial animation values based on a combination of visual and audio information |
Country Status (1)
Country | Link |
---|---|
US (2) | US6272231B1 (en) |
Cited By (188)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020052708A1 (en) * | 2000-10-26 | 2002-05-02 | Pollard Stephen B. | Optimal image capture |
US20020159627A1 (en) * | 2001-02-28 | 2002-10-31 | Henry Schneiderman | Object finder for photographic images |
US20020181752A1 (en) * | 2001-03-14 | 2002-12-05 | Warren Wallo | Method for measuring changes in portions of a human body |
US20030005439A1 (en) * | 2001-06-29 | 2003-01-02 | Rovira Luis A. | Subscriber television system user interface with a virtual reality media space |
US20030012408A1 (en) * | 2001-05-09 | 2003-01-16 | Jean-Yves Bouguet | Method and system using a data-driven model for monocular face tracking |
US20030063777A1 (en) * | 2001-09-28 | 2003-04-03 | Koninklijke Philips Electronics N.V. | Head motion estimation from four feature points |
US6577308B1 (en) * | 1998-12-16 | 2003-06-10 | Sony Corporation | Data processing method and apparatus and information furnishing medium |
US20030108244A1 (en) * | 2001-12-08 | 2003-06-12 | Li Ziqing | System and method for multi-view face detection |
US6681031B2 (en) * | 1998-08-10 | 2004-01-20 | Cybernet Systems Corporation | Gesture-controlled interfaces for self-service machines and other applications |
KR20040007921A (en) * | 2002-07-12 | 2004-01-28 | (주)아이엠에이테크놀로지 | Animation Method through Auto-Recognition of Facial Expression |
US20040017933A1 (en) * | 2002-04-12 | 2004-01-29 | Canon Kabushiki Kaisha | Face detection and tracking in a video sequence |
US20040068410A1 (en) * | 2002-10-08 | 2004-04-08 | Motorola, Inc. | Method and apparatus for providing an animated display with translated speech |
US20040085259A1 (en) * | 2002-11-04 | 2004-05-06 | Mark Tarlton | Avatar control using a communication device |
US20040120548A1 (en) * | 2002-12-18 | 2004-06-24 | Qian Richard J. | Method and apparatus for tracking features in a video sequence |
US20040131247A1 (en) * | 2003-01-07 | 2004-07-08 | Kazuhiro Hiwada | Image processing device executing image processing on input image and processing method for the same |
US20040136870A1 (en) * | 2002-10-25 | 2004-07-15 | Kochy Thomas E. | Automatic analysis apparatus |
US20040152512A1 (en) * | 2003-02-05 | 2004-08-05 | Collodi David J. | Video game with customizable character appearance |
US20040150642A1 (en) * | 2002-11-15 | 2004-08-05 | George Borshukov | Method for digitally rendering skin or like materials |
US20040161132A1 (en) * | 1998-08-10 | 2004-08-19 | Cohen Charles J. | Gesture-controlled interfaces for self-service machines and other applications |
US20040179008A1 (en) * | 2003-03-13 | 2004-09-16 | Sony Corporation | System and method for capturing facial and body motion |
US20040178955A1 (en) * | 2003-03-11 | 2004-09-16 | Alberto Menache | Radio Frequency Motion Tracking System and Mehod. |
US20040201666A1 (en) * | 2003-03-19 | 2004-10-14 | Matsushita Electric Industrial Co., Ltd. | Videophone terminal |
US20040223649A1 (en) * | 2003-05-07 | 2004-11-11 | Eastman Kodak Company | Composite imaging method and system |
US20040243416A1 (en) * | 2003-06-02 | 2004-12-02 | Gardos Thomas R. | Speech recognition |
US20040240708A1 (en) * | 2003-05-30 | 2004-12-02 | Microsoft Corporation | Head pose assessment methods and systems |
US6831603B2 (en) | 2002-03-12 | 2004-12-14 | Menache, Llc | Motion tracking system and method |
US20050006154A1 (en) * | 2002-12-18 | 2005-01-13 | Xerox Corporation | System and method for controlling information output devices |
US20050041863A1 (en) * | 2003-08-19 | 2005-02-24 | Ray Ajoy K. | Enabling content-based search of objects in an image database with reduced matching |
US20050047661A1 (en) * | 2003-08-29 | 2005-03-03 | Maurer Donald E. | Distance sorting algorithm for matching patterns |
US6880171B1 (en) * | 1996-12-05 | 2005-04-12 | Interval Research Corporation | Browser for use in navigating a body of information, with particular application to browsing information represented by audiovisual data |
US20050083333A1 (en) * | 2003-05-01 | 2005-04-21 | Sony Corporation | System and method for capturing facial and body motion |
US20050180613A1 (en) * | 2002-10-07 | 2005-08-18 | Michael Bronstein | Facial recognition and the open mouth problem |
US20050185060A1 (en) * | 2004-02-20 | 2005-08-25 | Neven Hartmut Sr. | Image base inquiry system for search engines for mobile telephones with integrated camera |
US20050190188A1 (en) * | 2004-01-30 | 2005-09-01 | Ntt Docomo, Inc. | Portable communication terminal and program |
US6948131B1 (en) * | 2000-03-08 | 2005-09-20 | Vidiator Enterprises Inc. | Communication system and method including rich media tools |
US20060012677A1 (en) * | 2004-02-20 | 2006-01-19 | Neven Hartmut Sr | Image-based search engine for mobile phones with camera |
US20060015308A1 (en) * | 2000-08-30 | 2006-01-19 | Microsoft Corporation | Facial image processing |
US20060050933A1 (en) * | 2004-06-21 | 2006-03-09 | Hartwig Adam | Single image based multi-biometric system and method |
US7038715B1 (en) * | 1999-01-19 | 2006-05-02 | Texas Instruments Incorporated | Digital still camera with high-quality portrait mode |
US20060115180A1 (en) * | 2004-11-17 | 2006-06-01 | Lexmark International, Inc. | Method for producing a composite image by processing source images to align reference points |
US20060119572A1 (en) * | 2004-10-25 | 2006-06-08 | Jaron Lanier | Movable audio/video communication interface system |
US20060153429A1 (en) * | 2002-10-24 | 2006-07-13 | Stefan Gehlen | Method for controlling photographs of people |
US20060152512A1 (en) * | 2003-03-13 | 2006-07-13 | Demian Gordon | Mobile motion capture cameras |
US20060184066A1 (en) * | 2005-02-15 | 2006-08-17 | Baylor College Of Medicine | Method for aiding stent-assisted coiling of intracranial aneurysms by virtual parent artery reconstruction |
US7121946B2 (en) * | 1998-08-10 | 2006-10-17 | Cybernet Systems Corporation | Real-time head tracking system for computer games and other applications |
US7127081B1 (en) * | 2000-10-12 | 2006-10-24 | Momentum Bilgisayar, Yazilim, Danismanlik, Ticaret, A.S. | Method for tracking motion of a face |
US20060240862A1 (en) * | 2004-02-20 | 2006-10-26 | Hartmut Neven | Mobile image-based information retrieval system |
US20060251298A1 (en) * | 2002-10-07 | 2006-11-09 | Technion Research & Development Foundation Ltd. | Three-dimensional face recognition |
US20070058839A1 (en) * | 2003-05-01 | 2007-03-15 | Jody Echegaray | System and method for capturing facial and body motion |
US20070064112A1 (en) * | 2003-09-09 | 2007-03-22 | Chatting David J | Video communications method and system |
US20070074114A1 (en) * | 2005-09-29 | 2007-03-29 | Conopco, Inc., D/B/A Unilever | Automated dialogue interface |
US20070159522A1 (en) * | 2004-02-20 | 2007-07-12 | Harmut Neven | Image-based contextual advertisement method and branded barcodes |
US20070188502A1 (en) * | 2006-02-09 | 2007-08-16 | Bishop Wendell E | Smooth morphing between personal video calling avatars |
US20070214461A1 (en) * | 2005-06-08 | 2007-09-13 | Logitech Europe S.A. | System and method for transparently processing multimedia data |
WO2007130691A2 (en) | 2006-05-07 | 2007-11-15 | Sony Computer Entertainment Inc. | Method for providing affective characteristics to computer generated avatar during gameplay |
US20080018595A1 (en) * | 2000-07-24 | 2008-01-24 | Gesturetek, Inc. | Video-based image control system |
US20080020363A1 (en) * | 2006-07-22 | 2008-01-24 | Yao-Jen Chang | Learning Assessment Method And Device Using A Virtual Tutor |
US20080037836A1 (en) * | 2006-08-09 | 2008-02-14 | Arcsoft, Inc. | Method for driving virtual facial expressions by automatically detecting facial expressions of a face image |
US20080151786A1 (en) * | 2006-12-21 | 2008-06-26 | Motorola, Inc. | Method and apparatus for hybrid audio-visual communication |
US20080166016A1 (en) * | 2005-02-21 | 2008-07-10 | Mitsubishi Electric Corporation | Fast Method of Object Detection by Statistical Template Matching |
US20080231686A1 (en) * | 2007-03-22 | 2008-09-25 | Attune Interactive, Inc. (A Delaware Corporation) | Generation of constructed model for client runtime player using motion points sent over a network |
US20080247598A1 (en) * | 2003-07-24 | 2008-10-09 | Movellan Javier R | Weak hypothesis generation apparatus and method, learning apparatus and method, detection apparatus and method, facial expression learning apparatus and method, facial expression recognition apparatus and method, and robot apparatus |
US20080253695A1 (en) * | 2007-04-10 | 2008-10-16 | Sony Corporation | Image storage processing apparatus, image search apparatus, image storage processing method, image search method and program |
US7440590B1 (en) | 2002-05-21 | 2008-10-21 | University Of Kentucky Research Foundation | System and technique for retrieving depth information about a surface by projecting a composite image of modulated light patterns |
US20080263040A1 (en) * | 2007-04-02 | 2008-10-23 | Nikhilesh Talreja | System and method for making a face call |
WO2008156437A1 (en) | 2006-04-10 | 2008-12-24 | Avaworks Incorporated | Do-it-yourself photo realistic talking head creation system and method |
US20090027337A1 (en) * | 2007-07-27 | 2009-01-29 | Gesturetek, Inc. | Enhanced camera-based input |
US20090040231A1 (en) * | 2007-08-06 | 2009-02-12 | Sony Corporation | Information processing apparatus, system, and method thereof |
US20090041310A1 (en) * | 2002-11-07 | 2009-02-12 | Ming-Hsuan Yang | Video-based face recognition using probabilistic appearance manifolds |
US20090067706A1 (en) * | 2007-09-12 | 2009-03-12 | Artec Ventures | System and Method for Multiframe Surface Measurement of the Shape of Objects |
US20090079813A1 (en) * | 2007-09-24 | 2009-03-26 | Gesturetek, Inc. | Enhanced Interface for Voice and Video Communications |
US20090116692A1 (en) * | 1998-08-10 | 2009-05-07 | Paul George V | Realtime object tracking system |
US20090202114A1 (en) * | 2008-02-13 | 2009-08-13 | Sebastien Morin | Live-Action Image Capture |
US20090220159A1 (en) * | 2008-02-28 | 2009-09-03 | Seiko Epson Corporation | Image output method, image output device, and image output program |
US20090276802A1 (en) * | 2008-05-01 | 2009-11-05 | At&T Knowledge Ventures, L.P. | Avatars in social interactive television |
US20090313151A1 (en) * | 2008-06-17 | 2009-12-17 | Searete Llc, A Limited Liability Corporation Of The State Of Delaware | Methods associated with projection system billing |
US20090328122A1 (en) * | 2008-06-25 | 2009-12-31 | At&T Corp. | Method and apparatus for presenting media programs |
US20100008547A1 (en) * | 2008-07-14 | 2010-01-14 | Google Inc. | Method and System for Automated Annotation of Persons in Video Content |
US20100070858A1 (en) * | 2008-09-12 | 2010-03-18 | At&T Intellectual Property I, L.P. | Interactive Media System and Method Using Context-Based Avatar Configuration |
US20100070987A1 (en) * | 2008-09-12 | 2010-03-18 | At&T Intellectual Property I, L.P. | Mining viewer responses to multimedia content |
US20100083320A1 (en) * | 2008-10-01 | 2010-04-01 | At&T Intellectual Property I, L.P. | System and method for a communication exchange with an avatar in a media communication system |
US20100106601A1 (en) * | 2007-09-07 | 2010-04-29 | Ryan Steelberg | System and method for distributing text content for use in one or more creatives |
US7711155B1 (en) * | 2003-04-14 | 2010-05-04 | Videomining Corporation | Method and system for enhancing three dimensional face modeling using demographic classification |
US7710436B2 (en) | 2000-02-11 | 2010-05-04 | Sony Corporation | Automatic color adjustment of a template design |
US20100109998A1 (en) * | 2008-11-04 | 2010-05-06 | Samsung Electronics Co., Ltd. | System and method for sensing facial gesture |
US20100125816A1 (en) * | 2008-11-20 | 2010-05-20 | Bezos Jeffrey P | Movement recognition as input mechanism |
US20100226288A1 (en) * | 2009-03-04 | 2010-09-09 | At&T Intellectual Property I, Lp. | Method and apparatus for group media consumption |
US7810037B1 (en) | 2000-02-11 | 2010-10-05 | Sony Corporation | Online story collaboration |
US7849475B2 (en) | 1995-03-07 | 2010-12-07 | Interval Licensing Llc | System and method for selective recording of information |
US20100315524A1 (en) * | 2007-09-04 | 2010-12-16 | Sony Corporation | Integrated motion capture |
US20110007081A1 (en) * | 2003-03-13 | 2011-01-13 | Sony Corporation | Mobile motion capture cameras |
US20110007142A1 (en) * | 2009-07-09 | 2011-01-13 | Microsoft Corporation | Visual representation expression based on player expression |
US20110043602A1 (en) * | 2009-08-21 | 2011-02-24 | Avaya Inc. | Camera-based facial recognition or other single/multiparty presence detection as a method of effecting telecom device alerting |
US7917286B2 (en) | 2005-12-16 | 2011-03-29 | Google Inc. | Database assisted OCR for street scenes and other images |
US20110080336A1 (en) * | 2009-10-07 | 2011-04-07 | Microsoft Corporation | Human Tracking System |
US20110080475A1 (en) * | 2009-10-07 | 2011-04-07 | Microsoft Corporation | Methods And Systems For Determining And Tracking Extremities Of A Target |
US20110093909A1 (en) * | 2009-10-15 | 2011-04-21 | At&T Intellectual Property I, L.P. | Apparatus and method for transmitting media content |
US20110106612A1 (en) * | 2009-10-30 | 2011-05-05 | At&T Intellectual Property L.L.P. | Apparatus and method for product marketing |
US20110106718A1 (en) * | 2009-11-05 | 2011-05-05 | At&T Intellectual Property I, L.P. | Apparatus and method for managing a social network |
US20110113440A1 (en) * | 2009-11-10 | 2011-05-12 | At&T Intellectual Property I.L.P. | Apparatus and method for transmitting media content |
US20110109648A1 (en) * | 2009-11-06 | 2011-05-12 | At&T Intellectual Property I, L.P. | Apparatus and method for managing marketing |
US20110112665A1 (en) * | 2009-11-10 | 2011-05-12 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US20110119725A1 (en) * | 2009-11-13 | 2011-05-19 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US20110126252A1 (en) * | 2009-11-20 | 2011-05-26 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US20110122220A1 (en) * | 2009-11-20 | 2011-05-26 | At&T Intellectual Property I, L.P. | Apparatus and method for collaborative network in an enterprise setting |
US20110126253A1 (en) * | 2009-11-20 | 2011-05-26 | At&T Intellectual Property I, L.P. | Apparatus and method for managing a social network |
US20110135207A1 (en) * | 2009-12-07 | 2011-06-09 | Google Inc. | Matching An Approximately Located Query Image Against A Reference Image Set |
US20110138326A1 (en) * | 2009-12-04 | 2011-06-09 | At&T Intellectual Property I, L.P. | Apparatus and Method for Tagging Media Content and Managing Marketing |
US20110141105A1 (en) * | 2009-12-16 | 2011-06-16 | Industrial Technology Research Institute | Facial Animation System and Production Method |
US7974714B2 (en) | 1999-10-05 | 2011-07-05 | Steven Mark Hoffberg | Intelligent electronic appliance system and method |
US20110181684A1 (en) * | 2011-02-07 | 2011-07-28 | InnovatioNet | Method of remote video communication and system of synthesis analysis and protection of user video images |
US20110234589A1 (en) * | 2009-10-07 | 2011-09-29 | Microsoft Corporation | Systems and methods for tracking a model |
US8046313B2 (en) | 1991-12-23 | 2011-10-25 | Hoffberg Steven M | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US8046818B2 (en) | 1999-10-08 | 2011-10-25 | Interval Licensing Llc | System and method for the broadcast dissemination of time-ordered data |
US20120147014A1 (en) * | 2010-12-08 | 2012-06-14 | Chao-Hua Lee | Method for extracting personal styles and its application to motion synthesis and recognition |
US8238671B1 (en) | 2009-12-07 | 2012-08-07 | Google Inc. | Scene classification for place recognition |
US8235725B1 (en) | 2005-02-20 | 2012-08-07 | Sensory Logic, Inc. | Computerized method of assessing consumer reaction to a business stimulus employing facial coding |
US8238722B2 (en) | 1996-12-05 | 2012-08-07 | Interval Licensing Llc | Variable rate video playback with synchronized audio |
US8262236B2 (en) | 2008-06-17 | 2012-09-11 | The Invention Science Fund I, Llc | Systems and methods for transmitting information associated with change of a projection surface |
US8267526B2 (en) | 2008-06-17 | 2012-09-18 | The Invention Science Fund I, Llc | Methods associated with receiving and transmitting information related to projection |
US8275623B2 (en) | 2009-03-06 | 2012-09-25 | At&T Intellectual Property I, L.P. | Method and apparatus for analyzing discussion regarding media programs |
US8285791B2 (en) | 2001-03-27 | 2012-10-09 | Wireless Recognition Technologies Llc | Method and apparatus for sharing information using a handheld device |
US8308304B2 (en) | 2008-06-17 | 2012-11-13 | The Invention Science Fund I, Llc | Systems associated with receiving and transmitting information related to projection |
US8376558B2 (en) | 2008-06-17 | 2013-02-19 | The Invention Science Fund I, Llc | Systems and methods for projecting in response to position change of a projection surface |
US8384005B2 (en) | 2008-06-17 | 2013-02-26 | The Invention Science Fund I, Llc | Systems and methods for selectively projecting information in response to at least one specified motion associated with pressure applied to at least one projection surface |
US8407595B1 (en) | 2000-02-11 | 2013-03-26 | Sony Corporation | Imaging service for automating the display of images |
US8429244B2 (en) | 2000-01-28 | 2013-04-23 | Interval Licensing Llc | Alerting users to items of current interest |
US8488011B2 (en) | 2011-02-08 | 2013-07-16 | Longsand Limited | System to augment a visual data stream based on a combination of geographical and visual information |
US8493353B2 (en) | 2011-04-13 | 2013-07-23 | Longsand Limited | Methods and systems for generating and joining shared experience |
US8509525B1 (en) | 2011-04-06 | 2013-08-13 | Google Inc. | Clustering of forms from large-scale scanned-document collection |
US8538458B2 (en) | 2005-04-04 | 2013-09-17 | X One, Inc. | Location sharing and tracking using mobile phones or other wireless devices |
US8602564B2 (en) | 2008-06-17 | 2013-12-10 | The Invention Science Fund I, Llc | Methods and systems for projecting in response to position |
US8608321B2 (en) | 2008-06-17 | 2013-12-17 | The Invention Science Fund I, Llc | Systems and methods for projecting in response to conformation |
US8641203B2 (en) | 2008-06-17 | 2014-02-04 | The Invention Science Fund I, Llc | Methods and systems for receiving and transmitting signals between server and projector apparatuses |
US8723787B2 (en) | 2008-06-17 | 2014-05-13 | The Invention Science Fund I, Llc | Methods and systems related to an image capture projection surface |
US8733952B2 (en) | 2008-06-17 | 2014-05-27 | The Invention Science Fund I, Llc | Methods and systems for coordinated use of two or more user responsive projectors |
US8774527B1 (en) | 2009-12-07 | 2014-07-08 | Google Inc. | Matching an approximately located query image against a reference image set using cellular base station and wireless access point information |
US8820939B2 (en) | 2008-06-17 | 2014-09-02 | The Invention Science Fund I, Llc | Projection associated methods and systems |
US8857999B2 (en) | 2008-06-17 | 2014-10-14 | The Invention Science Fund I, Llc | Projection in response to conformation |
US8867820B2 (en) | 2009-10-07 | 2014-10-21 | Microsoft Corporation | Systems and methods for removing a background of an image |
US8878773B1 (en) | 2010-05-24 | 2014-11-04 | Amazon Technologies, Inc. | Determining relative motion as input |
US8884928B1 (en) | 2012-01-26 | 2014-11-11 | Amazon Technologies, Inc. | Correcting for parallax in electronic displays |
US20140365310A1 (en) * | 2013-06-05 | 2014-12-11 | Machine Perception Technologies, Inc. | Presentation of materials based on low level feature analysis |
US8936367B2 (en) | 2008-06-17 | 2015-01-20 | The Invention Science Fund I, Llc | Systems and methods associated with projecting in response to conformation |
US8947351B1 (en) | 2011-09-27 | 2015-02-03 | Amazon Technologies, Inc. | Point of view determinations for finger tracking |
US8944608B2 (en) | 2008-06-17 | 2015-02-03 | The Invention Science Fund I, Llc | Systems and methods associated with projecting in response to conformation |
EP2835736A1 (en) * | 2012-04-06 | 2015-02-11 | Tencent Technology Shenzhen Company Limited | Method and device for automatically playing expression on virtual image |
US20150062116A1 (en) * | 2013-08-30 | 2015-03-05 | 1-800 Contacts, Inc. | Systems and methods for rapidly generating a 3-d model of a user |
US9015778B2 (en) | 2008-06-25 | 2015-04-21 | AT&T Intellectual Property I. LP | Apparatus and method for media on demand commentaries |
US9030486B2 (en) | 2008-08-22 | 2015-05-12 | University Of Virginia Patent Foundation | System and method for low bandwidth image transmission |
US9035874B1 (en) | 2013-03-08 | 2015-05-19 | Amazon Technologies, Inc. | Providing user input to a computing device with an eye closure |
US9041734B2 (en) | 2011-07-12 | 2015-05-26 | Amazon Technologies, Inc. | Simulating three-dimensional features |
US9063574B1 (en) | 2012-03-14 | 2015-06-23 | Amazon Technologies, Inc. | Motion detection systems for electronic devices |
US9064326B1 (en) | 2012-05-10 | 2015-06-23 | Longsand Limited | Local cache of augmented reality content in a mobile computing device |
US20150228077A1 (en) * | 2014-02-08 | 2015-08-13 | Honda Motor Co., Ltd. | System and method for mapping, localization and pose correction |
US9122917B2 (en) | 2011-08-04 | 2015-09-01 | Amazon Technologies, Inc. | Recognizing gestures captured by video |
US9123272B1 (en) | 2011-05-13 | 2015-09-01 | Amazon Technologies, Inc. | Realistic image lighting and shading |
US9148630B2 (en) | 2008-09-12 | 2015-09-29 | At&T Intellectual Property I, L.P. | Moderated interactive media sessions |
US9223415B1 (en) | 2012-01-17 | 2015-12-29 | Amazon Technologies, Inc. | Managing resource usage for task performance |
US9237294B2 (en) | 2010-03-05 | 2016-01-12 | Sony Corporation | Apparatus and method for replacing a broadcasted advertisement based on both heuristic information and attempts in altering the playback of the advertisement |
EP2966592A3 (en) * | 2014-07-07 | 2016-02-10 | Toshiba TEC Kabushiki Kaisha | Face recognition apparatus and method for recognizing face |
US9269012B2 (en) | 2013-08-22 | 2016-02-23 | Amazon Technologies, Inc. | Multi-tracker object tracking |
US9285895B1 (en) | 2012-03-28 | 2016-03-15 | Amazon Technologies, Inc. | Integrated near field sensor for display devices |
US9304593B2 (en) | 1998-08-10 | 2016-04-05 | Cybernet Systems Corporation | Behavior recognition system |
US9330301B1 (en) | 2012-11-21 | 2016-05-03 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US9336435B1 (en) | 2012-11-21 | 2016-05-10 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US9367203B1 (en) | 2013-10-04 | 2016-06-14 | Amazon Technologies, Inc. | User interface techniques for simulating three-dimensional depth |
US9423886B1 (en) | 2012-10-02 | 2016-08-23 | Amazon Technologies, Inc. | Sensor connectivity approaches |
US9430876B1 (en) | 2012-05-10 | 2016-08-30 | Aurasma Limited | Intelligent method of determining trigger items in augmented reality environments |
USRE46310E1 (en) | 1991-12-23 | 2017-02-14 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US9600713B2 (en) * | 2015-04-27 | 2017-03-21 | AprilAge Inc. | Identification and processing of facial wrinkles in a digital image |
US9832528B2 (en) | 2010-10-21 | 2017-11-28 | Sony Corporation | System and method for merging network-based content with broadcasted programming content |
US20180190000A1 (en) * | 2016-12-30 | 2018-07-05 | Microsoft Technology Licensing, Llc | Morphing chart animations in a browser |
US10055013B2 (en) | 2013-09-17 | 2018-08-21 | Amazon Technologies, Inc. | Dynamic object tracking for user interfaces |
US10088924B1 (en) | 2011-08-04 | 2018-10-02 | Amazon Technologies, Inc. | Overcoming motion effects in gesture recognition |
US10304225B2 (en) | 2016-12-30 | 2019-05-28 | Microsoft Technology Licensing, Llc | Chart-type agnostic scene graph for defining a chart |
US10361802B1 (en) | 1999-02-01 | 2019-07-23 | Blanding Hovenweep, Llc | Adaptive pattern recognition based control system and method |
EP3614304A1 (en) * | 2014-11-05 | 2020-02-26 | INTEL Corporation | Avatar video apparatus and method |
USRE47908E1 (en) | 1991-12-23 | 2020-03-17 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
USRE48056E1 (en) | 1991-12-23 | 2020-06-16 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US10708663B2 (en) | 2009-11-13 | 2020-07-07 | At&T Intellectual Property I, L.P. | Apparatus and method for media on demand commentaries |
US11055889B2 (en) | 2018-02-23 | 2021-07-06 | Samsung Electronics Co., Ltd. | Electronic device displaying avatar motion-performed as per movement of facial feature point and method for operating same |
US11086498B2 (en) | 2016-12-30 | 2021-08-10 | Microsoft Technology Licensing, Llc. | Server-side chart layout for interactive web application charts |
US20210328954A1 (en) * | 2018-03-06 | 2021-10-21 | Didimo, Inc. | Advanced Electronic Messaging Utilizing Animatable 3D Models |
US11199906B1 (en) | 2013-09-04 | 2021-12-14 | Amazon Technologies, Inc. | Global user input management |
USRE49044E1 (en) * | 2010-06-01 | 2022-04-19 | Apple Inc. | Automatic avatar creation |
US11508107B2 (en) | 2018-02-26 | 2022-11-22 | Didimo, Inc. | Additional developments to the automatic rig creation process |
US20230102851A1 (en) * | 2021-09-24 | 2023-03-30 | Gn Hearing A/S | Triggering a head-pose dependent action |
Families Citing this family (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR100455294B1 (en) * | 2002-12-06 | 2004-11-06 | 삼성전자주식회사 | Method for detecting user and detecting motion, and apparatus for detecting user within security system |
JP3950802B2 (en) * | 2003-01-31 | 2007-08-01 | 株式会社エヌ・ティ・ティ・ドコモ | Face information transmission system, face information transmission method, face information transmission program, and computer-readable recording medium |
US7155386B2 (en) * | 2003-03-15 | 2006-12-26 | Mindspeed Technologies, Inc. | Adaptive correlation window for open-loop pitch |
US20050168485A1 (en) * | 2004-01-29 | 2005-08-04 | Nattress Thomas G. | System for combining a sequence of images with computer-generated 3D graphics |
US20060009978A1 (en) * | 2004-07-02 | 2006-01-12 | The Regents Of The University Of Colorado | Methods and systems for synthesis of accurate visible speech via transformation of motion capture data |
US8311294B2 (en) | 2009-09-08 | 2012-11-13 | Facedouble, Inc. | Image classification and information retrieval over wireless digital networks and the internet |
US7587070B2 (en) * | 2005-09-28 | 2009-09-08 | Facedouble, Inc. | Image classification and information retrieval over wireless digital networks and the internet |
US7450740B2 (en) * | 2005-09-28 | 2008-11-11 | Facedouble, Inc. | Image classification and information retrieval over wireless digital networks and the internet |
US7599527B2 (en) * | 2005-09-28 | 2009-10-06 | Facedouble, Inc. | Digital image search system and method |
US8369570B2 (en) * | 2005-09-28 | 2013-02-05 | Facedouble, Inc. | Method and system for tagging an image of an individual in a plurality of photos |
US8600174B2 (en) | 2005-09-28 | 2013-12-03 | Facedouble, Inc. | Method and system for attaching a metatag to a digital image |
US20080124690A1 (en) * | 2006-11-28 | 2008-05-29 | Attune Interactive, Inc. | Training system using an interactive prompt character |
US8875026B2 (en) * | 2008-05-01 | 2014-10-28 | International Business Machines Corporation | Directed communication in a virtual environment |
KR20120059994A (en) | 2010-12-01 | 2012-06-11 | 삼성전자주식회사 | Apparatus and method for control avatar using expression control point |
US8937620B1 (en) | 2011-04-07 | 2015-01-20 | Google Inc. | System and methods for generation and control of story animation |
US10157333B1 (en) | 2015-09-15 | 2018-12-18 | Snap Inc. | Systems and methods for content tagging |
US20170161382A1 (en) * | 2015-12-08 | 2017-06-08 | Snapchat, Inc. | System to correlate video data and contextual data |
US10534955B2 (en) * | 2016-01-22 | 2020-01-14 | Dreamworks Animation L.L.C. | Facial capture analysis and training system |
Citations (35)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4725824A (en) | 1983-06-15 | 1988-02-16 | Mitsubishi Denki Kabushiki Kaisha | Doze prevention system |
US4805224A (en) | 1983-06-08 | 1989-02-14 | Fujitsu Limited | Pattern matching method and apparatus |
US4827413A (en) | 1987-06-16 | 1989-05-02 | Kabushiki Kaisha Toshiba | Modified back-to-front three dimensional reconstruction algorithm |
US5159647A (en) * | 1991-03-04 | 1992-10-27 | David Sarnoff Research Center, Inc. | Fast and efficient search method for graphical data |
US5168529A (en) | 1988-08-29 | 1992-12-01 | Rayethon Company | Confirmed boundary pattern matching |
US5187574A (en) | 1990-08-24 | 1993-02-16 | Kanda Tsushin Kogyo Co., Ltd. | Method for automatically adjusting field of view of television monitor system and apparatus for carrying out the same |
US5220441A (en) | 1990-09-28 | 1993-06-15 | Eastman Kodak Company | Mechanism for determining parallax between digital images |
US5280530A (en) * | 1990-09-07 | 1994-01-18 | U.S. Philips Corporation | Method and apparatus for tracking a moving object |
US5333165A (en) | 1992-02-27 | 1994-07-26 | John K. Grady | Method and apparatus for three-dimensional video signals |
US5383013A (en) | 1992-09-18 | 1995-01-17 | Nec Research Institute, Inc. | Stereoscopic computer vision system |
DE4406020C1 (en) | 1994-02-24 | 1995-06-29 | Zentrum Fuer Neuroinformatik G | Automatic digital image recognition system |
US5430809A (en) | 1992-07-10 | 1995-07-04 | Sony Corporation | Human face tracking system |
US5432712A (en) | 1990-05-29 | 1995-07-11 | Axiom Innovation Limited | Machine vision stereo matching |
US5511153A (en) | 1994-01-18 | 1996-04-23 | Massachusetts Institute Of Technology | Method and apparatus for three-dimensional, textured models from plural video images |
US5533177A (en) | 1990-10-24 | 1996-07-02 | Siemens Aktiengesellschaft | Method for detecting and estimating the spatial position of objects from a two-dimensional image |
US5550928A (en) | 1992-12-15 | 1996-08-27 | A.C. Nielsen Company | Audience measurement system and method |
US5581625A (en) | 1994-01-31 | 1996-12-03 | International Business Machines Corporation | Stereo vision system for counting items in a queue |
US5588033A (en) | 1995-06-06 | 1996-12-24 | St. Jude Children's Research Hospital | Method and apparatus for three dimensional image reconstruction from multiple stereotactic or isocentric backprojections |
US5680487A (en) | 1991-12-23 | 1997-10-21 | Texas Instruments Incorporated | System and method for determining optical flow |
EP0807902A2 (en) | 1996-05-16 | 1997-11-19 | Cyberclass Limited | Method and apparatus for generating moving characters |
US5699449A (en) | 1994-11-14 | 1997-12-16 | The University Of Connecticut | Method and apparatus for implementation of neural networks for face recognition |
US5714997A (en) | 1995-01-06 | 1998-02-03 | Anderson; David P. | Virtual reality television system |
US5715325A (en) | 1995-08-30 | 1998-02-03 | Siemens Corporate Research, Inc. | Apparatus and method for detecting a face in a video image |
US5719954A (en) | 1994-06-07 | 1998-02-17 | Matsushita Electric Industrial Co., Ltd. | Stereo matching method and disparity measuring method |
US5736982A (en) | 1994-08-03 | 1998-04-07 | Nippon Telegraph And Telephone Corporation | Virtual space apparatus with avatars and speech |
US5764803A (en) | 1996-04-03 | 1998-06-09 | Lucent Technologies Inc. | Motion-adaptive modelling of scene content for very low bit rate model-assisted coding of video sequences |
US5774591A (en) | 1995-12-15 | 1998-06-30 | Xerox Corporation | Apparatus and method for recognizing facial expressions and facial gestures in a sequence of images |
US5802220A (en) * | 1995-12-15 | 1998-09-01 | Xerox Corporation | Apparatus and method for tracking facial motion through a sequence of images |
US5809171A (en) | 1996-01-05 | 1998-09-15 | Mcdonnell Douglas Corporation | Image processing method and apparatus for correlating a test image with a template |
US5828769A (en) | 1996-10-23 | 1998-10-27 | Autodesk, Inc. | Method and apparatus for recognition of objects via position and orientation consensus of local image encoding |
US5917937A (en) | 1997-04-15 | 1999-06-29 | Microsoft Corporation | Method for performing stereo matching to recover depths, colors and opacities of surface elements |
US5982853A (en) * | 1995-03-01 | 1999-11-09 | Liebermann; Raanan | Telephone for the deaf and method of using same |
US5995119A (en) * | 1997-06-06 | 1999-11-30 | At&T Corp. | Method for generating photo-realistic animated characters |
US6044168A (en) * | 1996-11-25 | 2000-03-28 | Texas Instruments Incorporated | Model based faced coding and decoding using feature detection and eigenface coding |
US6052123A (en) * | 1997-05-14 | 2000-04-18 | International Business Machines Corporation | Animation reuse in three dimensional virtual reality |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5875108A (en) * | 1991-12-23 | 1999-02-23 | Hoffberg; Steven M. | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US5608839A (en) * | 1994-03-18 | 1997-03-04 | Lucent Technologies Inc. | Sound-synchronized video system |
US6147692A (en) * | 1997-06-25 | 2000-11-14 | Haptek, Inc. | Method and apparatus for controlling transformation of two and three-dimensional images |
US6011562A (en) | 1997-08-01 | 2000-01-04 | Avid Technology Inc. | Method and system employing an NLE to create and modify 3D animations by mixing and compositing animation data |
US6115052A (en) * | 1998-02-12 | 2000-09-05 | Mitsubishi Electric Information Technology Center America, Inc. (Ita) | System for reconstructing the 3-dimensional motions of a human figure from a monocularly-viewed image sequence |
US6181351B1 (en) * | 1998-04-13 | 2001-01-30 | Microsoft Corporation | Synchronizing the moveable mouths of animated characters with recorded speech |
US6504546B1 (en) * | 2000-02-08 | 2003-01-07 | At&T Corp. | Method of modeling objects to synthesize three-dimensional, photo-realistic animations |
-
1998
- 1998-11-06 US US09/188,079 patent/US6272231B1/en not_active Expired - Lifetime
-
2001
- 2001-08-13 US US09/929,516 patent/US6940454B2/en not_active Expired - Lifetime
Patent Citations (35)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4805224A (en) | 1983-06-08 | 1989-02-14 | Fujitsu Limited | Pattern matching method and apparatus |
US4725824A (en) | 1983-06-15 | 1988-02-16 | Mitsubishi Denki Kabushiki Kaisha | Doze prevention system |
US4827413A (en) | 1987-06-16 | 1989-05-02 | Kabushiki Kaisha Toshiba | Modified back-to-front three dimensional reconstruction algorithm |
US5168529A (en) | 1988-08-29 | 1992-12-01 | Rayethon Company | Confirmed boundary pattern matching |
US5432712A (en) | 1990-05-29 | 1995-07-11 | Axiom Innovation Limited | Machine vision stereo matching |
US5187574A (en) | 1990-08-24 | 1993-02-16 | Kanda Tsushin Kogyo Co., Ltd. | Method for automatically adjusting field of view of television monitor system and apparatus for carrying out the same |
US5280530A (en) * | 1990-09-07 | 1994-01-18 | U.S. Philips Corporation | Method and apparatus for tracking a moving object |
US5220441A (en) | 1990-09-28 | 1993-06-15 | Eastman Kodak Company | Mechanism for determining parallax between digital images |
US5533177A (en) | 1990-10-24 | 1996-07-02 | Siemens Aktiengesellschaft | Method for detecting and estimating the spatial position of objects from a two-dimensional image |
US5159647A (en) * | 1991-03-04 | 1992-10-27 | David Sarnoff Research Center, Inc. | Fast and efficient search method for graphical data |
US5680487A (en) | 1991-12-23 | 1997-10-21 | Texas Instruments Incorporated | System and method for determining optical flow |
US5333165A (en) | 1992-02-27 | 1994-07-26 | John K. Grady | Method and apparatus for three-dimensional video signals |
US5430809A (en) | 1992-07-10 | 1995-07-04 | Sony Corporation | Human face tracking system |
US5383013A (en) | 1992-09-18 | 1995-01-17 | Nec Research Institute, Inc. | Stereoscopic computer vision system |
US5550928A (en) | 1992-12-15 | 1996-08-27 | A.C. Nielsen Company | Audience measurement system and method |
US5511153A (en) | 1994-01-18 | 1996-04-23 | Massachusetts Institute Of Technology | Method and apparatus for three-dimensional, textured models from plural video images |
US5581625A (en) | 1994-01-31 | 1996-12-03 | International Business Machines Corporation | Stereo vision system for counting items in a queue |
DE4406020C1 (en) | 1994-02-24 | 1995-06-29 | Zentrum Fuer Neuroinformatik G | Automatic digital image recognition system |
US5719954A (en) | 1994-06-07 | 1998-02-17 | Matsushita Electric Industrial Co., Ltd. | Stereo matching method and disparity measuring method |
US5736982A (en) | 1994-08-03 | 1998-04-07 | Nippon Telegraph And Telephone Corporation | Virtual space apparatus with avatars and speech |
US5699449A (en) | 1994-11-14 | 1997-12-16 | The University Of Connecticut | Method and apparatus for implementation of neural networks for face recognition |
US5714997A (en) | 1995-01-06 | 1998-02-03 | Anderson; David P. | Virtual reality television system |
US5982853A (en) * | 1995-03-01 | 1999-11-09 | Liebermann; Raanan | Telephone for the deaf and method of using same |
US5588033A (en) | 1995-06-06 | 1996-12-24 | St. Jude Children's Research Hospital | Method and apparatus for three dimensional image reconstruction from multiple stereotactic or isocentric backprojections |
US5715325A (en) | 1995-08-30 | 1998-02-03 | Siemens Corporate Research, Inc. | Apparatus and method for detecting a face in a video image |
US5774591A (en) | 1995-12-15 | 1998-06-30 | Xerox Corporation | Apparatus and method for recognizing facial expressions and facial gestures in a sequence of images |
US5802220A (en) * | 1995-12-15 | 1998-09-01 | Xerox Corporation | Apparatus and method for tracking facial motion through a sequence of images |
US5809171A (en) | 1996-01-05 | 1998-09-15 | Mcdonnell Douglas Corporation | Image processing method and apparatus for correlating a test image with a template |
US5764803A (en) | 1996-04-03 | 1998-06-09 | Lucent Technologies Inc. | Motion-adaptive modelling of scene content for very low bit rate model-assisted coding of video sequences |
EP0807902A2 (en) | 1996-05-16 | 1997-11-19 | Cyberclass Limited | Method and apparatus for generating moving characters |
US5828769A (en) | 1996-10-23 | 1998-10-27 | Autodesk, Inc. | Method and apparatus for recognition of objects via position and orientation consensus of local image encoding |
US6044168A (en) * | 1996-11-25 | 2000-03-28 | Texas Instruments Incorporated | Model based faced coding and decoding using feature detection and eigenface coding |
US5917937A (en) | 1997-04-15 | 1999-06-29 | Microsoft Corporation | Method for performing stereo matching to recover depths, colors and opacities of surface elements |
US6052123A (en) * | 1997-05-14 | 2000-04-18 | International Business Machines Corporation | Animation reuse in three dimensional virtual reality |
US5995119A (en) * | 1997-06-06 | 1999-11-30 | At&T Corp. | Method for generating photo-realistic animated characters |
Non-Patent Citations (54)
Title |
---|
Akimoto, T., et al, "Automatic Creation of 3-D Facial Models", IEEE Computer Graphics & Applications., pp. 16-22, Sep. 1993. |
Ayache, N., et al, "Rectification of Images for Binocular and Trinocular Stereovision", In IEEE Proceedings of 9th International Conference on Pattern Recognition, pp. 11-16, 1988, Italy. |
Belhumeur, P., "A Bayesian Approach to Binocular Stereopsis", International Journal of Computer Vision, 19 (3), 1996, pp.237-260. |
Beymer, D. J., "Face Recognition Under Varying Pose", Massachusettes Institute of Technology, Artificial Intelligence Laboratory, A.I. Memo No. 1461, 12/93, pp. 1-13. |
Beymer, D. J., "Face Recognition Under Varying Pose", Massachusetts Institute of Technology, Artificial Intelligence Laboratory research report, 1994, pp. 756-761. |
Buhmann, J. et al, "Distortion Invariant Object Recognition by Matching Hierarchically Labeled Graphs", In Proceedings IJCNN International Conference of Neural Networks, Wash., DC, Jun. 1989, pp. 155-159. |
DeCarlo, D., et al, "The Integration of Optical Flow and Deformable Models with Applications to Human Face Shape and Motion Estimation", pp. 1-15, In Proceedings, CVPR '96, pp. 231-238. |
Devernay, F., et al, "Computing Differential Properties of 3-D Shapes from Stereoscopic Images without 3-D Models", INRIA, RR-2304, 1994, pp. 1-28. |
Dhond, U., et al, "Structure from Stereo-A Review", IEEE Transactions on Systems, Man, and Cybernetics, vol. 19, No. 6, pp. 1489-1510, Nov./Dec. 1989. |
Face recognition by elastic bunch graph matching by, Laurenze Wiskott et al., 1997.* |
Fleet, D. J., et al, "Computation of Component Image Velocity from Local Phase Information", International Journal of Computer Vision, vol. 5, No. 1, 1990, pp. 77-104. |
Fleet, D.J., et al, "Measurement of Image Velocity", Kluwer International Series in Engineering and Computer Science, Kluwer Academic Publishers, Boston, 1992, No. 169, pp. 1-203. |
Hall, E. L., "Computer Image Processing and Recognition", Academic Press, 1979, pp. 468-484. |
Hong, H., et al, "Online Facial Recognition Based on Personalized Gallery", Proceedings of International Conference on Automatic Face and Gesture Recognition, pp. 1-6, Japan, Apr. 1997. |
Kolocsai, P., et al, Statistical Analysis of Gabor-Filter Representation, Proceedings of International Conference on Automatic Face and Gesture Recognition, 1997, 4 pp. |
Kruger, N., "An Algorithm for the Learning of Weights in Discrimination Functions Using a priori Constraints", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 19, No. 7, Jul. 1997, pp. 764-768. |
Kruger, N., "Visual Learning with a priori Constraints", Shaker Verlag, Aachen, Germany, 1998, pp. 1-131. |
Kruger, N., et al, "Autonomous Learning of Object Representation Utilizing Self-Controlled Movements", 1998, Proceedings of NN98, 5 pp. |
Kruger, N., et al, "Object Recognition with a Sparse and Autonomously Learned Representation Based on Banana Wavelets", Internal Report 96-11, Institut fur Neuroinformatik, Dec. 96, pp. 1-24. |
Kruger, N., et al, "Object Recognition with Banana Wavelets", European Symposium on Artificial Neural Networks (ESANN97), 1997, 6 pp. |
Kruger, N., et al, "Principles of Cortical Processing Applied to and Motivated by Artificial Object Recognition", Institut fur Neuroinformatik, Internal Report 97-17, Oct. 97, pp. 1-12. |
Lades, M., et al, "Distortion Invarient Object Recognition in the Dynamic Link Architecture", IEEE Transactions on Computers, vol. 42, No. 3, 1993, 11 pp. |
Luong, Q. T., et al, "The Fundamental Matrix, Theory, Algorithm, and Stability Analysis", INRIA, 1993, pp. 1-46. |
Manjunath, B. S., et al, "A Feature Based Approach to Face Recognition", In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, pp. 373-378, 3/92. |
Mauer, T., et al, "Learning Feature Transformations to Recognize Faces Rotated in Depth", In Proceedings of the International Conference on Artificial Neural Networks, vol. 1, pp. 353-358, Paris, France, Oct. 9-13, 1995. |
Mauer, T., et al, "Single-View Based Recognition of Faces Rotated in Depth", In Proceedings of the International Workshop on Automatic Face and Gesture Recognition, pp. 248-253, Zurich, CH, Jun. 26, 1995. |
Mauer, T., et al, "Tracking and Learning Graphs and Pose on Image Sequences of Faces", Proceedings of 2nd International Conference on Automatic Face and Gesture Recognition, Oct. 14-16, 1996, pp, 176-181. |
Maybank, S. J., et al, "A Theory of Self-Calibration of a Moving Camera", International Journal of Computer Vision, 8(2), pp. 123-151, 1992. |
McKenna, S.J., et al, Tracking Facial Feature Points With Gabor Wavelets and Shape Models, (publication & date unknown), 6 pp. |
Okada, K., et al, "The Bochum/USC Face Recognition System", 19 pp. (publication & date unknown). |
Okutomi, M., et al, "A Multiple-Baseline Stereo", IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 15, No. 4, pp. 353-363, Apr. 1993. |
Peters, G., et al, "Learning Object Representation by Clustering Banana Wavelet Responses", Tech. Report IR-INI 96-09, Institut fur Neuroinformatik, Ruhr Universitat, Bochum, 1996, 6 pp. |
Phillips, P. J., et al, "The Face Recognition Technology (FERET) Program", Proceedings of Office of National Drug Control Policy, CTAC International Technology Symposium, Aug. 18-22, 1997, 10 pp. |
Pighin, F, et al, "Synthesis Realistic Facial Expressions from Photographs", In SIGGRAPH 98 Conference Proceedings, pp. 75-84, Jul. 1998. |
Roy, S., et al, "A Maximum Flow Formulation of the N-Camera Stereo Correspondence Problem", IEEE, Proceedings of International Conference on Computer Vision, Bombay, India, Jan. 1998, pp. 1-6. |
Sara, R. et al "3-D Data Acquision and Interpretation for Virtual Reality and Telepresence", Proceedings IEEE Workshop Computer Vision for Virtual Reality Based Human Communication, Bombay, Jan. 1998, 7 pp. |
Sara, R. et al "Fish-Scales: Representing Fuzzy Manifolds", Proceedings International Conference Computer Vision, ICCV '98, pp. 811-817, Bombay, Jan. 1998. |
Sara, R., et al, "On Occluding Contour Artifacts in Stereo Vision", IEEE, Proceedings of International Conference Computer Vision and Pattern Recognition, Puerto Rico, 1997, 6 pp. |
Steffens, J., et al, "PersonSpotter-Fast and Robust System for Human Detection, Tracking, and Recognition", Proceedings of International Conference on Automatic Face and Gesture Recognition, 6 pp., Japan-Apr. 1998. |
Theimer, W. M., et al, "Phase-Based Binocular Vergence Control and Depth Reconstruction using Active Vision", CVGIP: Image Understanding, vol. 60, No. 3, Nov. 1994, pp. 343-358. |
Tomasi, C., et al., "Stereo Without Search", Proceedings of European Conference on Computer Vision, Cambridge, UK, 1996, 14 pp. (7 sheets). |
Triesch, J., et al, "Robust Classification of Hand Postures Against Complex Backgrounds", Proceedings of the Second International Conference on Automatic Face and Gesture Recognition, Killington, VT, Oct. 1996, 6 pp. |
Turk, M., et al, "Eigenfaces for Recognition", Journal of Cognitive Neuroscience, vol. 3, No. 1, pp. 71-86, 1991. |
Wiskott, L. "Phantom Faces for Face Analysis", Pattern Recognition, vol. 30, No. 6, pp. 837-846, 1997. |
Wiskott, L., "Labeled Graphs and Dynamic Link Matching for Face Recognition and Scene Analysis", Verlag Harri Deutsch, Thun-Frankfurt am Main. Reihe Physik, Dec. 1995, pp. 1-109. |
Wiskott, L., "Phanton Faces for Face Analysis", Internal Report, IR-INI 96-06, Institut fur Neoroinformatik, Ruhr-Universitat, Bochum, Germany, Apr. 1996, 12 pp. |
Wiskott, L., "Phanton Faces for Face Analysis", Proceedings of 3rd Joint Symposium on Neural Computation, Pasadena, CA, vol. 6, pp. 46-52, Jun. 1996. |
Wiskott, L., et al, "Face Recognition and Gender Determination", Proceedings of International Workshop on Automatic Face and Gesture Recognition, pp. 92-97, Zurich CH, Jun. 26, 1995. |
Wiskott, L., et al, "Face Recognition by Elastic Bunch Graph Matching", IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(7), pp. 775-779, 1997. |
Wiskott, L., et al, "Face Recognition by Elastic Bunch Graph Matching", Internal Report, IR-INI 96-08, Institut fur Neuroinformatik, Ruhr-Universitat, Bochum, pp. 1-21, Apr. 1996. |
Wong, R., et al, "PC-Based Human Face Recognition System", IEEE, pp. 641-644, 1992. |
Wurtz, R. et al, "Corner Detection in Color Images by Multiscale Combination of End-stopped Cortical Cells", Artificial Neural Networks-ICANN '97, Lecture Notes in Computer Science, vol. 1327, pp. 901-906, Springer-Verlag, 1997. |
Wurtz, R., "Object Recognition Robust Under Translations, Deformations, and Changes in Background", IEEE Transactions on Patern Analysis and Machine Intelligence, vol. 19, No. 7, Jul. 1997, pp. 769-775. |
Yao, Y., et al, "Tracking a Dynamic Set of Feature Points", IEEE Transactions on Image Processing, vol. 4, No. 10, Oct., 1995, pp. 1382-1394. |
Cited By (440)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
USRE46310E1 (en) | 1991-12-23 | 2017-02-14 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
USRE48056E1 (en) | 1991-12-23 | 2020-06-16 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
USRE49387E1 (en) | 1991-12-23 | 2023-01-24 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US8046313B2 (en) | 1991-12-23 | 2011-10-25 | Hoffberg Steven M | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
USRE47908E1 (en) | 1991-12-23 | 2020-03-17 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US7849475B2 (en) | 1995-03-07 | 2010-12-07 | Interval Licensing Llc | System and method for selective recording of information |
US8584158B2 (en) | 1995-03-07 | 2013-11-12 | Interval Licensing Llc | System and method for selective recording of information |
US6880171B1 (en) * | 1996-12-05 | 2005-04-12 | Interval Research Corporation | Browser for use in navigating a body of information, with particular application to browsing information represented by audiovisual data |
US8176515B2 (en) | 1996-12-05 | 2012-05-08 | Interval Licensing Llc | Browser for use in navigating a body of information, with particular application to browsing information represented by audiovisual data |
US8238722B2 (en) | 1996-12-05 | 2012-08-07 | Interval Licensing Llc | Variable rate video playback with synchronized audio |
US20040161132A1 (en) * | 1998-08-10 | 2004-08-19 | Cohen Charles J. | Gesture-controlled interfaces for self-service machines and other applications |
US7684592B2 (en) | 1998-08-10 | 2010-03-23 | Cybernet Systems Corporation | Realtime object tracking system |
US20090116692A1 (en) * | 1998-08-10 | 2009-05-07 | Paul George V | Realtime object tracking system |
US9304593B2 (en) | 1998-08-10 | 2016-04-05 | Cybernet Systems Corporation | Behavior recognition system |
US6950534B2 (en) | 1998-08-10 | 2005-09-27 | Cybernet Systems Corporation | Gesture-controlled interfaces for self-service machines and other applications |
US20090074248A1 (en) * | 1998-08-10 | 2009-03-19 | Cybernet Systems Corporation | Gesture-controlled interfaces for self-service machines and other applications |
US20070066393A1 (en) * | 1998-08-10 | 2007-03-22 | Cybernet Systems Corporation | Real-time head tracking system for computer games and other applications |
US7121946B2 (en) * | 1998-08-10 | 2006-10-17 | Cybernet Systems Corporation | Real-time head tracking system for computer games and other applications |
US6681031B2 (en) * | 1998-08-10 | 2004-01-20 | Cybernet Systems Corporation | Gesture-controlled interfaces for self-service machines and other applications |
US7668340B2 (en) | 1998-08-10 | 2010-02-23 | Cybernet Systems Corporation | Gesture-controlled interfaces for self-service machines and other applications |
US20060013440A1 (en) * | 1998-08-10 | 2006-01-19 | Cohen Charles J | Gesture-controlled interfaces for self-service machines and other applications |
US7460690B2 (en) | 1998-08-10 | 2008-12-02 | Cybernet Systems Corporation | Gesture-controlled interfaces for self-service machines and other applications |
US6577308B1 (en) * | 1998-12-16 | 2003-06-10 | Sony Corporation | Data processing method and apparatus and information furnishing medium |
US7038715B1 (en) * | 1999-01-19 | 2006-05-02 | Texas Instruments Incorporated | Digital still camera with high-quality portrait mode |
US10361802B1 (en) | 1999-02-01 | 2019-07-23 | Blanding Hovenweep, Llc | Adaptive pattern recognition based control system and method |
US7974714B2 (en) | 1999-10-05 | 2011-07-05 | Steven Mark Hoffberg | Intelligent electronic appliance system and method |
US8341688B2 (en) | 1999-10-08 | 2012-12-25 | Interval Licensing Llc | System and method for the broadcast dissemination of time-ordered data |
US8726331B2 (en) | 1999-10-08 | 2014-05-13 | Interval Licensing Llc | System and method for the broadcast dissemination of time-ordered data |
US8046818B2 (en) | 1999-10-08 | 2011-10-25 | Interval Licensing Llc | System and method for the broadcast dissemination of time-ordered data |
US8429244B2 (en) | 2000-01-28 | 2013-04-23 | Interval Licensing Llc | Alerting users to items of current interest |
US9317560B2 (en) | 2000-01-28 | 2016-04-19 | Interval Licensing Llc | Alerting users to items of current interest |
US8049766B2 (en) | 2000-02-11 | 2011-11-01 | Sony Corporation | Automatic color adjustment of a template design |
US7710436B2 (en) | 2000-02-11 | 2010-05-04 | Sony Corporation | Automatic color adjustment of a template design |
US8407595B1 (en) | 2000-02-11 | 2013-03-26 | Sony Corporation | Imaging service for automating the display of images |
US7810037B1 (en) | 2000-02-11 | 2010-10-05 | Sony Corporation | Online story collaboration |
US8694896B2 (en) | 2000-02-11 | 2014-04-08 | Sony Corporation | Online story collaboration |
US8184124B2 (en) | 2000-02-11 | 2012-05-22 | Sony Corporation | Automatic color adjustment of a template design |
US8345062B2 (en) | 2000-02-11 | 2013-01-01 | Sony Corporation | Automatic color adjustment of a template design |
US7843464B2 (en) | 2000-02-11 | 2010-11-30 | Sony Corporation | Automatic color adjustment of template design |
US6948131B1 (en) * | 2000-03-08 | 2005-09-20 | Vidiator Enterprises Inc. | Communication system and method including rich media tools |
US20060064645A1 (en) * | 2000-03-08 | 2006-03-23 | Vidiator Enterprises Inc. | Communication system and method including rich media tools |
US8963963B2 (en) | 2000-07-24 | 2015-02-24 | Qualcomm Incorporated | Video-based image control system |
US20080018595A1 (en) * | 2000-07-24 | 2008-01-24 | Gesturetek, Inc. | Video-based image control system |
US20080030460A1 (en) * | 2000-07-24 | 2008-02-07 | Gesturetek, Inc. | Video-based image control system |
US8274535B2 (en) | 2000-07-24 | 2012-09-25 | Qualcomm Incorporated | Video-based image control system |
US8624932B2 (en) | 2000-07-24 | 2014-01-07 | Qualcomm Incorporated | Video-based image control system |
US7898522B2 (en) * | 2000-07-24 | 2011-03-01 | Gesturetek, Inc. | Video-based image control system |
US20060015308A1 (en) * | 2000-08-30 | 2006-01-19 | Microsoft Corporation | Facial image processing |
US7433807B2 (en) * | 2000-08-30 | 2008-10-07 | Microsoft Corporation | Facial image processing |
US7127081B1 (en) * | 2000-10-12 | 2006-10-24 | Momentum Bilgisayar, Yazilim, Danismanlik, Ticaret, A.S. | Method for tracking motion of a face |
US20020052708A1 (en) * | 2000-10-26 | 2002-05-02 | Pollard Stephen B. | Optimal image capture |
US6829384B2 (en) * | 2001-02-28 | 2004-12-07 | Carnegie Mellon University | Object finder for photographic images |
US20020159627A1 (en) * | 2001-02-28 | 2002-10-31 | Henry Schneiderman | Object finder for photographic images |
US20020181752A1 (en) * | 2001-03-14 | 2002-12-05 | Warren Wallo | Method for measuring changes in portions of a human body |
US8285791B2 (en) | 2001-03-27 | 2012-10-09 | Wireless Recognition Technologies Llc | Method and apparatus for sharing information using a handheld device |
US20030012408A1 (en) * | 2001-05-09 | 2003-01-16 | Jean-Yves Bouguet | Method and system using a data-driven model for monocular face tracking |
US9400921B2 (en) * | 2001-05-09 | 2016-07-26 | Intel Corporation | Method and system using a data-driven model for monocular face tracking |
US20030005439A1 (en) * | 2001-06-29 | 2003-01-02 | Rovira Luis A. | Subscriber television system user interface with a virtual reality media space |
US6795972B2 (en) * | 2001-06-29 | 2004-09-21 | Scientific-Atlanta, Inc. | Subscriber television system user interface with a virtual reality media space |
US7027618B2 (en) * | 2001-09-28 | 2006-04-11 | Koninklijke Philips Electronics N.V. | Head motion estimation from four feature points |
US20030063777A1 (en) * | 2001-09-28 | 2003-04-03 | Koninklijke Philips Electronics N.V. | Head motion estimation from four feature points |
US7050607B2 (en) * | 2001-12-08 | 2006-05-23 | Microsoft Corp. | System and method for multi-view face detection |
US7324671B2 (en) * | 2001-12-08 | 2008-01-29 | Microsoft Corp. | System and method for multi-view face detection |
US20030108244A1 (en) * | 2001-12-08 | 2003-06-12 | Li Ziqing | System and method for multi-view face detection |
US6831603B2 (en) | 2002-03-12 | 2004-12-14 | Menache, Llc | Motion tracking system and method |
US7146028B2 (en) * | 2002-04-12 | 2006-12-05 | Canon Kabushiki Kaisha | Face detection and tracking in a video sequence |
US20040017933A1 (en) * | 2002-04-12 | 2004-01-29 | Canon Kabushiki Kaisha | Face detection and tracking in a video sequence |
US7440590B1 (en) | 2002-05-21 | 2008-10-21 | University Of Kentucky Research Foundation | System and technique for retrieving depth information about a surface by projecting a composite image of modulated light patterns |
US20080279446A1 (en) * | 2002-05-21 | 2008-11-13 | University Of Kentucky Research Foundation | System and technique for retrieving depth information about a surface by projecting a composite image of modulated light patterns |
KR20040007921A (en) * | 2002-07-12 | 2004-01-28 | (주)아이엠에이테크놀로지 | Animation Method through Auto-Recognition of Facial Expression |
US20060251298A1 (en) * | 2002-10-07 | 2006-11-09 | Technion Research & Development Foundation Ltd. | Three-dimensional face recognition |
US20080292147A1 (en) * | 2002-10-07 | 2008-11-27 | Technion Research & Development Foundation Ltd. | Facial recognition and the open mouth problem |
US7623687B2 (en) | 2002-10-07 | 2009-11-24 | Technion Research & Development Foundation Ltd. | Three-dimensional face recognition |
US20050180613A1 (en) * | 2002-10-07 | 2005-08-18 | Michael Bronstein | Facial recognition and the open mouth problem |
US8155400B2 (en) | 2002-10-07 | 2012-04-10 | Technion Research & Development Foundation L' | Facial recognition and the open mouth problem |
US7421098B2 (en) * | 2002-10-07 | 2008-09-02 | Technion Research & Development Foundation Ltd. | Facial recognition and the open mouth problem |
US20040068410A1 (en) * | 2002-10-08 | 2004-04-08 | Motorola, Inc. | Method and apparatus for providing an animated display with translated speech |
US6925438B2 (en) | 2002-10-08 | 2005-08-02 | Motorola, Inc. | Method and apparatus for providing an animated display with translated speech |
US7715596B2 (en) * | 2002-10-24 | 2010-05-11 | Viisage Technology Ag | Method for controlling photographs of people |
US20060153429A1 (en) * | 2002-10-24 | 2006-07-13 | Stefan Gehlen | Method for controlling photographs of people |
US20040136870A1 (en) * | 2002-10-25 | 2004-07-15 | Kochy Thomas E. | Automatic analysis apparatus |
US20040085259A1 (en) * | 2002-11-04 | 2004-05-06 | Mark Tarlton | Avatar control using a communication device |
US20090041310A1 (en) * | 2002-11-07 | 2009-02-12 | Ming-Hsuan Yang | Video-based face recognition using probabilistic appearance manifolds |
US7499574B1 (en) * | 2002-11-07 | 2009-03-03 | Honda Motor Co., Ltd. | Video-based face recognition using probabilistic appearance manifolds |
US7536047B2 (en) * | 2002-11-15 | 2009-05-19 | Warner Bros. Entertainment Inc. | Method for digitally rendering skin or like materials |
US20090174713A1 (en) * | 2002-11-15 | 2009-07-09 | George Borshukov | Method for digitally rendering skin or like materials |
US8515157B2 (en) | 2002-11-15 | 2013-08-20 | Warner Bros. Entertainment Inc. | Method for digitally rendering skin or like materials |
US20040150642A1 (en) * | 2002-11-15 | 2004-08-05 | George Borshukov | Method for digitally rendering skin or like materials |
US7194110B2 (en) * | 2002-12-18 | 2007-03-20 | Intel Corporation | Method and apparatus for tracking features in a video sequence |
US7991920B2 (en) * | 2002-12-18 | 2011-08-02 | Xerox Corporation | System and method for controlling information output devices |
US20050006154A1 (en) * | 2002-12-18 | 2005-01-13 | Xerox Corporation | System and method for controlling information output devices |
US20040120548A1 (en) * | 2002-12-18 | 2004-06-24 | Qian Richard J. | Method and apparatus for tracking features in a video sequence |
US20040131247A1 (en) * | 2003-01-07 | 2004-07-08 | Kazuhiro Hiwada | Image processing device executing image processing on input image and processing method for the same |
US7239741B2 (en) | 2003-01-07 | 2007-07-03 | Kabushiki Kaisha Toshiba | Image processing device executing image processing on input image and processing method for the same |
US20040152512A1 (en) * | 2003-02-05 | 2004-08-05 | Collodi David J. | Video game with customizable character appearance |
US20040178955A1 (en) * | 2003-03-11 | 2004-09-16 | Alberto Menache | Radio Frequency Motion Tracking System and Mehod. |
US7009561B2 (en) | 2003-03-11 | 2006-03-07 | Menache, Llp | Radio frequency motion tracking system and method |
US7432810B2 (en) | 2003-03-11 | 2008-10-07 | Menache Llc | Radio frequency tags for use in a motion tracking system |
US20060125691A1 (en) * | 2003-03-11 | 2006-06-15 | Alberto Menache | Radio frequency tags for use in a motion tracking system |
US20060152512A1 (en) * | 2003-03-13 | 2006-07-13 | Demian Gordon | Mobile motion capture cameras |
US8106911B2 (en) | 2003-03-13 | 2012-01-31 | Sony Corporation | Mobile motion capture cameras |
US20040179008A1 (en) * | 2003-03-13 | 2004-09-16 | Sony Corporation | System and method for capturing facial and body motion |
US7812842B2 (en) | 2003-03-13 | 2010-10-12 | Sony Corporation | Mobile motion capture cameras |
US20110007081A1 (en) * | 2003-03-13 | 2011-01-13 | Sony Corporation | Mobile motion capture cameras |
US7333113B2 (en) | 2003-03-13 | 2008-02-19 | Sony Corporation | Mobile motion capture cameras |
US7218320B2 (en) | 2003-03-13 | 2007-05-15 | Sony Corporation | System and method for capturing facial and body motion |
US20040201666A1 (en) * | 2003-03-19 | 2004-10-14 | Matsushita Electric Industrial Co., Ltd. | Videophone terminal |
US7202886B2 (en) | 2003-03-19 | 2007-04-10 | Matsushita Electric Industrial Co., Ltd. | Videophone terminal |
US7711155B1 (en) * | 2003-04-14 | 2010-05-04 | Videomining Corporation | Method and system for enhancing three dimensional face modeling using demographic classification |
USRE45768E1 (en) * | 2003-04-14 | 2015-10-20 | Hyacinth Audio Llc | Method and system for enhancing three dimensional face modeling using demographic classification |
US7358972B2 (en) | 2003-05-01 | 2008-04-15 | Sony Corporation | System and method for capturing facial and body motion |
US20050083333A1 (en) * | 2003-05-01 | 2005-04-21 | Sony Corporation | System and method for capturing facial and body motion |
US20070058839A1 (en) * | 2003-05-01 | 2007-03-15 | Jody Echegaray | System and method for capturing facial and body motion |
US7573480B2 (en) | 2003-05-01 | 2009-08-11 | Sony Corporation | System and method for capturing facial and body motion |
US8600191B2 (en) | 2003-05-07 | 2013-12-03 | Apple Inc. | Composite imaging method and system |
US20040223649A1 (en) * | 2003-05-07 | 2004-11-11 | Eastman Kodak Company | Composite imaging method and system |
US20070182829A1 (en) * | 2003-05-07 | 2007-08-09 | Zacks Carolyn A | Composite imaging method and system |
US20110193972A1 (en) * | 2003-05-07 | 2011-08-11 | Zacks Carolyn A | Composite imaging method and system |
US20080298637A1 (en) * | 2003-05-30 | 2008-12-04 | Microsoft Corporation | Head Pose Assessment Methods and Systems |
US7391888B2 (en) * | 2003-05-30 | 2008-06-24 | Microsoft Corporation | Head pose assessment methods and systems |
US20040240708A1 (en) * | 2003-05-30 | 2004-12-02 | Microsoft Corporation | Head pose assessment methods and systems |
US7844086B2 (en) | 2003-05-30 | 2010-11-30 | Microsoft Corporation | Head pose assessment methods and systems |
US8457358B2 (en) | 2003-05-30 | 2013-06-04 | Microsoft Corporation | Head pose assessment methods and systems |
US8135183B2 (en) | 2003-05-30 | 2012-03-13 | Microsoft Corporation | Head pose assessment methods and systems |
US20110050568A1 (en) * | 2003-05-30 | 2011-03-03 | Microsoft Corporation | Head pose assessment methods and systems |
US20040243416A1 (en) * | 2003-06-02 | 2004-12-02 | Gardos Thomas R. | Speech recognition |
US20080247598A1 (en) * | 2003-07-24 | 2008-10-09 | Movellan Javier R | Weak hypothesis generation apparatus and method, learning apparatus and method, detection apparatus and method, facial expression learning apparatus and method, facial expression recognition apparatus and method, and robot apparatus |
US7587069B2 (en) * | 2003-07-24 | 2009-09-08 | Sony Corporation | Weak hypothesis generation apparatus and method, learning apparatus and method, detection apparatus and method, facial expression learning apparatus and method, facial expression recognition apparatus and method, and robot apparatus |
US7317816B2 (en) * | 2003-08-19 | 2008-01-08 | Intel Corporation | Enabling content-based search of objects in an image database with reduced matching |
US20050041863A1 (en) * | 2003-08-19 | 2005-02-24 | Ray Ajoy K. | Enabling content-based search of objects in an image database with reduced matching |
US20050047661A1 (en) * | 2003-08-29 | 2005-03-03 | Maurer Donald E. | Distance sorting algorithm for matching patterns |
US7379598B2 (en) * | 2003-08-29 | 2008-05-27 | The Johns Hopkins University | Distance sorting algorithm for matching patterns |
US20070064112A1 (en) * | 2003-09-09 | 2007-03-22 | Chatting David J | Video communications method and system |
US7982762B2 (en) * | 2003-09-09 | 2011-07-19 | British Telecommunications Public Limited Company | System and method for combining local and remote images such that images of participants appear overlaid on another in substanial alignment |
US20050190188A1 (en) * | 2004-01-30 | 2005-09-01 | Ntt Docomo, Inc. | Portable communication terminal and program |
US20070159522A1 (en) * | 2004-02-20 | 2007-07-12 | Harmut Neven | Image-based contextual advertisement method and branded barcodes |
US8421872B2 (en) | 2004-02-20 | 2013-04-16 | Google Inc. | Image base inquiry system for search engines for mobile telephones with integrated camera |
US7565139B2 (en) | 2004-02-20 | 2009-07-21 | Google Inc. | Image-based search engine for mobile phones with camera |
US20050185060A1 (en) * | 2004-02-20 | 2005-08-25 | Neven Hartmut Sr. | Image base inquiry system for search engines for mobile telephones with integrated camera |
US20060240862A1 (en) * | 2004-02-20 | 2006-10-26 | Hartmut Neven | Mobile image-based information retrieval system |
US20100260373A1 (en) * | 2004-02-20 | 2010-10-14 | Google Inc. | Mobile image-based information retrieval system |
US7962128B2 (en) * | 2004-02-20 | 2011-06-14 | Google, Inc. | Mobile image-based information retrieval system |
US7751805B2 (en) | 2004-02-20 | 2010-07-06 | Google Inc. | Mobile image-based information retrieval system |
US20060012677A1 (en) * | 2004-02-20 | 2006-01-19 | Neven Hartmut Sr | Image-based search engine for mobile phones with camera |
US7697735B2 (en) | 2004-06-21 | 2010-04-13 | Google Inc. | Image based multi-biometric system and method |
US20060050933A1 (en) * | 2004-06-21 | 2006-03-09 | Hartwig Adam | Single image based multi-biometric system and method |
US20060119572A1 (en) * | 2004-10-25 | 2006-06-08 | Jaron Lanier | Movable audio/video communication interface system |
US20100039380A1 (en) * | 2004-10-25 | 2010-02-18 | Graphics Properties Holdings, Inc. | Movable Audio/Video Communication Interface System |
US7626569B2 (en) | 2004-10-25 | 2009-12-01 | Graphics Properties Holdings, Inc. | Movable audio/video communication interface system |
US20060115180A1 (en) * | 2004-11-17 | 2006-06-01 | Lexmark International, Inc. | Method for producing a composite image by processing source images to align reference points |
US7469074B2 (en) * | 2004-11-17 | 2008-12-23 | Lexmark International, Inc. | Method for producing a composite image by processing source images to align reference points |
US20060184066A1 (en) * | 2005-02-15 | 2006-08-17 | Baylor College Of Medicine | Method for aiding stent-assisted coiling of intracranial aneurysms by virtual parent artery reconstruction |
US8235725B1 (en) | 2005-02-20 | 2012-08-07 | Sensory Logic, Inc. | Computerized method of assessing consumer reaction to a business stimulus employing facial coding |
US20080166016A1 (en) * | 2005-02-21 | 2008-07-10 | Mitsubishi Electric Corporation | Fast Method of Object Detection by Statistical Template Matching |
US11356799B2 (en) | 2005-04-04 | 2022-06-07 | X One, Inc. | Fleet location sharing application in association with services provision |
US10341808B2 (en) | 2005-04-04 | 2019-07-02 | X One, Inc. | Location sharing for commercial and proprietary content applications |
US9883360B1 (en) | 2005-04-04 | 2018-01-30 | X One, Inc. | Rendez vous management using mobile phones or other mobile devices |
US9167558B2 (en) | 2005-04-04 | 2015-10-20 | X One, Inc. | Methods and systems for sharing position data between subscribers involving multiple wireless providers |
US9253616B1 (en) | 2005-04-04 | 2016-02-02 | X One, Inc. | Apparatus and method for obtaining content on a cellular wireless device based on proximity |
US10165059B2 (en) | 2005-04-04 | 2018-12-25 | X One, Inc. | Methods, systems and apparatuses for the formation and tracking of location sharing groups |
US8712441B2 (en) | 2005-04-04 | 2014-04-29 | Xone, Inc. | Methods and systems for temporarily sharing position data between mobile-device users |
US10299071B2 (en) | 2005-04-04 | 2019-05-21 | X One, Inc. | Server-implemented methods and systems for sharing location amongst web-enabled cell phones |
US10856099B2 (en) | 2005-04-04 | 2020-12-01 | X One, Inc. | Application-based two-way tracking and mapping function with selected individuals |
US10791414B2 (en) | 2005-04-04 | 2020-09-29 | X One, Inc. | Location sharing for commercial and proprietary content applications |
US11778415B2 (en) | 2005-04-04 | 2023-10-03 | Xone, Inc. | Location sharing application in association with services provision |
US10750310B2 (en) | 2005-04-04 | 2020-08-18 | X One, Inc. | Temporary location sharing group with event based termination |
US10750309B2 (en) | 2005-04-04 | 2020-08-18 | X One, Inc. | Ad hoc location sharing group establishment for wireless devices with designated meeting point |
US10750311B2 (en) | 2005-04-04 | 2020-08-18 | X One, Inc. | Application-based tracking and mapping function in connection with vehicle-based services provision |
US9031581B1 (en) | 2005-04-04 | 2015-05-12 | X One, Inc. | Apparatus and method for obtaining content on a cellular wireless device based on proximity to other wireless devices |
US8750898B2 (en) | 2005-04-04 | 2014-06-10 | X One, Inc. | Methods and systems for annotating target locations |
US9467832B2 (en) | 2005-04-04 | 2016-10-11 | X One, Inc. | Methods and systems for temporarily sharing position data between mobile-device users |
US9942705B1 (en) | 2005-04-04 | 2018-04-10 | X One, Inc. | Location sharing group for services provision |
US9955298B1 (en) | 2005-04-04 | 2018-04-24 | X One, Inc. | Methods, systems and apparatuses for the formation and tracking of location sharing groups |
US9967704B1 (en) | 2005-04-04 | 2018-05-08 | X One, Inc. | Location sharing group map management |
US9854394B1 (en) | 2005-04-04 | 2017-12-26 | X One, Inc. | Ad hoc location sharing group between first and second cellular wireless devices |
US10341809B2 (en) | 2005-04-04 | 2019-07-02 | X One, Inc. | Location sharing with facilitated meeting point definition |
US9854402B1 (en) | 2005-04-04 | 2017-12-26 | X One, Inc. | Formation of wireless device location sharing group |
US9185522B1 (en) | 2005-04-04 | 2015-11-10 | X One, Inc. | Apparatus and method to transmit content to a cellular wireless device based on proximity to other wireless devices |
US10149092B1 (en) | 2005-04-04 | 2018-12-04 | X One, Inc. | Location sharing service between GPS-enabled wireless devices, with shared target location exchange |
US8831635B2 (en) | 2005-04-04 | 2014-09-09 | X One, Inc. | Methods and apparatuses for transmission of an alert to multiple devices |
US10313826B2 (en) | 2005-04-04 | 2019-06-04 | X One, Inc. | Location sharing and map support in connection with services request |
US9584960B1 (en) | 2005-04-04 | 2017-02-28 | X One, Inc. | Rendez vous management using mobile phones or other mobile devices |
US9749790B1 (en) | 2005-04-04 | 2017-08-29 | X One, Inc. | Rendez vous management using mobile phones or other mobile devices |
US8798645B2 (en) | 2005-04-04 | 2014-08-05 | X One, Inc. | Methods and systems for sharing position data and tracing paths between mobile-device users |
US10200811B1 (en) | 2005-04-04 | 2019-02-05 | X One, Inc. | Map presentation on cellular device showing positions of multiple other wireless device users |
US9736618B1 (en) | 2005-04-04 | 2017-08-15 | X One, Inc. | Techniques for sharing relative position between mobile devices |
US8798593B2 (en) | 2005-04-04 | 2014-08-05 | X One, Inc. | Location sharing and tracking using mobile phones or other wireless devices |
US8538458B2 (en) | 2005-04-04 | 2013-09-17 | X One, Inc. | Location sharing and tracking using mobile phones or other wireless devices |
US9654921B1 (en) | 2005-04-04 | 2017-05-16 | X One, Inc. | Techniques for sharing position data between first and second devices |
US8798647B1 (en) | 2005-04-04 | 2014-08-05 | X One, Inc. | Tracking proximity of services provider to services consumer |
US9615204B1 (en) | 2005-04-04 | 2017-04-04 | X One, Inc. | Techniques for communication within closed groups of mobile devices |
US20070214461A1 (en) * | 2005-06-08 | 2007-09-13 | Logitech Europe S.A. | System and method for transparently processing multimedia data |
US8606950B2 (en) | 2005-06-08 | 2013-12-10 | Logitech Europe S.A. | System and method for transparently processing multimedia data |
US20070074114A1 (en) * | 2005-09-29 | 2007-03-29 | Conopco, Inc., D/B/A Unilever | Automated dialogue interface |
WO2007041223A2 (en) * | 2005-09-29 | 2007-04-12 | Unilever N.V. | Automated dialogue interface |
WO2007041223A3 (en) * | 2005-09-29 | 2009-04-23 | Unilever Nv | Automated dialogue interface |
US7917286B2 (en) | 2005-12-16 | 2011-03-29 | Google Inc. | Database assisted OCR for street scenes and other images |
US20070188502A1 (en) * | 2006-02-09 | 2007-08-16 | Bishop Wendell E | Smooth morphing between personal video calling avatars |
US8421805B2 (en) * | 2006-02-09 | 2013-04-16 | Dialogic Corporation | Smooth morphing between personal video calling avatars |
WO2008156437A1 (en) | 2006-04-10 | 2008-12-24 | Avaworks Incorporated | Do-it-yourself photo realistic talking head creation system and method |
US20070268312A1 (en) * | 2006-05-07 | 2007-11-22 | Sony Computer Entertainment Inc. | Methods and systems for processing an interchange of real time effects during video communication |
EP2194509A1 (en) * | 2006-05-07 | 2010-06-09 | Sony Computer Entertainment Inc. | Method for providing affective characteristics to computer generated avatar during gameplay |
WO2007130691A2 (en) | 2006-05-07 | 2007-11-15 | Sony Computer Entertainment Inc. | Method for providing affective characteristics to computer generated avatar during gameplay |
US20080001951A1 (en) * | 2006-05-07 | 2008-01-03 | Sony Computer Entertainment Inc. | System and method for providing affective characteristics to computer generated avatar during gameplay |
EP2016562A4 (en) * | 2006-05-07 | 2010-01-06 | Sony Computer Entertainment Inc | Method for providing affective characteristics to computer generated avatar during gameplay |
EP2016562A2 (en) * | 2006-05-07 | 2009-01-21 | Sony Computer Entertainment Inc. | Method for providing affective characteristics to computer generated avatar during gameplay |
US8766983B2 (en) | 2006-05-07 | 2014-07-01 | Sony Computer Entertainment Inc. | Methods and systems for processing an interchange of real time effects during video communication |
US20080020363A1 (en) * | 2006-07-22 | 2008-01-24 | Yao-Jen Chang | Learning Assessment Method And Device Using A Virtual Tutor |
US8021160B2 (en) * | 2006-07-22 | 2011-09-20 | Industrial Technology Research Institute | Learning assessment method and device using a virtual tutor |
US20080037836A1 (en) * | 2006-08-09 | 2008-02-14 | Arcsoft, Inc. | Method for driving virtual facial expressions by automatically detecting facial expressions of a face image |
US7751599B2 (en) * | 2006-08-09 | 2010-07-06 | Arcsoft, Inc. | Method for driving virtual facial expressions by automatically detecting facial expressions of a face image |
US20080151786A1 (en) * | 2006-12-21 | 2008-06-26 | Motorola, Inc. | Method and apparatus for hybrid audio-visual communication |
WO2008079505A2 (en) * | 2006-12-21 | 2008-07-03 | Motorola, Inc. | Method and apparatus for hybrid audio-visual communication |
WO2008079505A3 (en) * | 2006-12-21 | 2008-10-09 | Motorola Inc | Method and apparatus for hybrid audio-visual communication |
US20080231686A1 (en) * | 2007-03-22 | 2008-09-25 | Attune Interactive, Inc. (A Delaware Corporation) | Generation of constructed model for client runtime player using motion points sent over a network |
US20080263040A1 (en) * | 2007-04-02 | 2008-10-23 | Nikhilesh Talreja | System and method for making a face call |
US20080253695A1 (en) * | 2007-04-10 | 2008-10-16 | Sony Corporation | Image storage processing apparatus, image search apparatus, image storage processing method, image search method and program |
US8687925B2 (en) | 2007-04-10 | 2014-04-01 | Sony Corporation | Image storage processing apparatus, image search apparatus, image storage processing method, image search method and program |
US11960706B2 (en) | 2007-07-27 | 2024-04-16 | Qualcomm Incorporated | Item selection using enhanced control |
US11500514B2 (en) | 2007-07-27 | 2022-11-15 | Qualcomm Incorporated | Item selection using enhanced control |
US10509536B2 (en) | 2007-07-27 | 2019-12-17 | Qualcomm Incorporated | Item selection using enhanced control |
US10268339B2 (en) | 2007-07-27 | 2019-04-23 | Qualcomm Incorporated | Enhanced camera-based input |
US20090027337A1 (en) * | 2007-07-27 | 2009-01-29 | Gesturetek, Inc. | Enhanced camera-based input |
US20090031240A1 (en) * | 2007-07-27 | 2009-01-29 | Gesturetek, Inc. | Item selection using enhanced control |
US8659548B2 (en) | 2007-07-27 | 2014-02-25 | Qualcomm Incorporated | Enhanced camera-based input |
US8726194B2 (en) * | 2007-07-27 | 2014-05-13 | Qualcomm Incorporated | Item selection using enhanced control |
US10262449B2 (en) | 2007-08-06 | 2019-04-16 | Sony Corporation | Information processing apparatus, system, and method for displaying bio-information or kinetic information |
US10937221B2 (en) | 2007-08-06 | 2021-03-02 | Sony Corporation | Information processing apparatus, system, and method for displaying bio-information or kinetic information |
US9568998B2 (en) | 2007-08-06 | 2017-02-14 | Sony Corporation | Information processing apparatus, system, and method for displaying bio-information or kinetic information |
US9972116B2 (en) | 2007-08-06 | 2018-05-15 | Sony Corporation | Information processing apparatus, system, and method for displaying bio-information or kinetic information |
US8797331B2 (en) * | 2007-08-06 | 2014-08-05 | Sony Corporation | Information processing apparatus, system, and method thereof |
US10529114B2 (en) | 2007-08-06 | 2020-01-07 | Sony Corporation | Information processing apparatus, system, and method for displaying bio-information or kinetic information |
US20090040231A1 (en) * | 2007-08-06 | 2009-02-12 | Sony Corporation | Information processing apparatus, system, and method thereof |
US20100315524A1 (en) * | 2007-09-04 | 2010-12-16 | Sony Corporation | Integrated motion capture |
US20100106601A1 (en) * | 2007-09-07 | 2010-04-29 | Ryan Steelberg | System and method for distributing text content for use in one or more creatives |
US20090067706A1 (en) * | 2007-09-12 | 2009-03-12 | Artec Ventures | System and Method for Multiframe Surface Measurement of the Shape of Objects |
US20090079813A1 (en) * | 2007-09-24 | 2009-03-26 | Gesturetek, Inc. | Enhanced Interface for Voice and Video Communications |
US8830292B2 (en) | 2007-09-24 | 2014-09-09 | Qualcomm Incorporated | Enhanced interface for voice and video communications |
US8325214B2 (en) | 2007-09-24 | 2012-12-04 | Qualcomm Incorporated | Enhanced interface for voice and video communications |
US20090202114A1 (en) * | 2008-02-13 | 2009-08-13 | Sebastien Morin | Live-Action Image Capture |
WO2009101153A2 (en) * | 2008-02-13 | 2009-08-20 | Ubisoft Entertainment S.A. | Live-action image capture |
WO2009101153A3 (en) * | 2008-02-13 | 2009-10-08 | Ubisoft Entertainment S.A. | Live-action image capture |
US8170299B2 (en) * | 2008-02-28 | 2012-05-01 | Seiko Epson Corporation | Image output method, image output device, and image output program |
US20090220159A1 (en) * | 2008-02-28 | 2009-09-03 | Seiko Epson Corporation | Image output method, image output device, and image output program |
US20090276802A1 (en) * | 2008-05-01 | 2009-11-05 | At&T Knowledge Ventures, L.P. | Avatars in social interactive television |
US7953255B2 (en) | 2008-05-01 | 2011-05-31 | At&T Intellectual Property I, L.P. | Avatars in social interactive television |
US8098905B2 (en) | 2008-05-01 | 2012-01-17 | At&T Intellectual Property I, L.P. | Avatars in social interactive television |
US8311295B2 (en) | 2008-05-01 | 2012-11-13 | At&T Intellectual Property I, L.P. | Avatars in social interactive television |
US20110225603A1 (en) * | 2008-05-01 | 2011-09-15 | At&T Intellectual Property I, L.P. | Avatars in Social Interactive Television |
US8818054B2 (en) | 2008-05-01 | 2014-08-26 | At&T Intellectual Property I, L.P. | Avatars in social interactive television |
US8308304B2 (en) | 2008-06-17 | 2012-11-13 | The Invention Science Fund I, Llc | Systems associated with receiving and transmitting information related to projection |
US8384005B2 (en) | 2008-06-17 | 2013-02-26 | The Invention Science Fund I, Llc | Systems and methods for selectively projecting information in response to at least one specified motion associated with pressure applied to at least one projection surface |
US8641203B2 (en) | 2008-06-17 | 2014-02-04 | The Invention Science Fund I, Llc | Methods and systems for receiving and transmitting signals between server and projector apparatuses |
US8944608B2 (en) | 2008-06-17 | 2015-02-03 | The Invention Science Fund I, Llc | Systems and methods associated with projecting in response to conformation |
US8939586B2 (en) | 2008-06-17 | 2015-01-27 | The Invention Science Fund I, Llc | Systems and methods for projecting in response to position |
US8540381B2 (en) | 2008-06-17 | 2013-09-24 | The Invention Science Fund I, Llc | Systems and methods for receiving information associated with projecting |
US8936367B2 (en) | 2008-06-17 | 2015-01-20 | The Invention Science Fund I, Llc | Systems and methods associated with projecting in response to conformation |
US8955984B2 (en) | 2008-06-17 | 2015-02-17 | The Invention Science Fund I, Llc | Projection associated methods and systems |
US8723787B2 (en) | 2008-06-17 | 2014-05-13 | The Invention Science Fund I, Llc | Methods and systems related to an image capture projection surface |
US8262236B2 (en) | 2008-06-17 | 2012-09-11 | The Invention Science Fund I, Llc | Systems and methods for transmitting information associated with change of a projection surface |
US8267526B2 (en) | 2008-06-17 | 2012-09-18 | The Invention Science Fund I, Llc | Methods associated with receiving and transmitting information related to projection |
US8733952B2 (en) | 2008-06-17 | 2014-05-27 | The Invention Science Fund I, Llc | Methods and systems for coordinated use of two or more user responsive projectors |
US20090313151A1 (en) * | 2008-06-17 | 2009-12-17 | Searete Llc, A Limited Liability Corporation Of The State Of Delaware | Methods associated with projection system billing |
US8430515B2 (en) | 2008-06-17 | 2013-04-30 | The Invention Science Fund I, Llc | Systems and methods for projecting |
US8602564B2 (en) | 2008-06-17 | 2013-12-10 | The Invention Science Fund I, Llc | Methods and systems for projecting in response to position |
US8608321B2 (en) | 2008-06-17 | 2013-12-17 | The Invention Science Fund I, Llc | Systems and methods for projecting in response to conformation |
US8857999B2 (en) | 2008-06-17 | 2014-10-14 | The Invention Science Fund I, Llc | Projection in response to conformation |
US8820939B2 (en) | 2008-06-17 | 2014-09-02 | The Invention Science Fund I, Llc | Projection associated methods and systems |
US8403501B2 (en) | 2008-06-17 | 2013-03-26 | The Invention Science Fund, I, LLC | Motion responsive devices and systems |
US8376558B2 (en) | 2008-06-17 | 2013-02-19 | The Invention Science Fund I, Llc | Systems and methods for projecting in response to position change of a projection surface |
US9769532B2 (en) | 2008-06-25 | 2017-09-19 | At&T Intellectual Property Ii, L.P. | Method and apparatus for presenting media programs |
US10306325B2 (en) | 2008-06-25 | 2019-05-28 | At&T Intellectual Property I, L.P. | Apparatus and method for monitoring and control on a network |
US9501758B2 (en) | 2008-06-25 | 2016-11-22 | At&T Intellectual Property I, L.P. | Apparatus and method for monitoring and control on a network |
US9015778B2 (en) | 2008-06-25 | 2015-04-21 | AT&T Intellectual Property I. LP | Apparatus and method for media on demand commentaries |
US20110111854A1 (en) * | 2008-06-25 | 2011-05-12 | At&T Intellectual Property I, L.P. | Apparatus and method for gaming |
US20090328122A1 (en) * | 2008-06-25 | 2009-12-31 | At&T Corp. | Method and apparatus for presenting media programs |
US10080056B2 (en) | 2008-06-25 | 2018-09-18 | At&T Intellectual Property Ii, L.P. | Method and apparatus for presenting media programs |
US8839327B2 (en) | 2008-06-25 | 2014-09-16 | At&T Intellectual Property Ii, Lp | Method and apparatus for presenting media programs |
US9584864B2 (en) | 2008-06-25 | 2017-02-28 | At&T Intellectual Property I, L.P. | Apparatus and method for media on demand commentaries |
US9415303B2 (en) | 2008-06-25 | 2016-08-16 | At&T Intellectual Property I, L.P. | Apparatus and method for gaming |
US9369781B2 (en) | 2008-06-25 | 2016-06-14 | At&T Intellectual Property Ii, Lp | Method and apparatus for presenting media programs |
US20100008547A1 (en) * | 2008-07-14 | 2010-01-14 | Google Inc. | Method and System for Automated Annotation of Persons in Video Content |
US8213689B2 (en) | 2008-07-14 | 2012-07-03 | Google Inc. | Method and system for automated annotation of persons in video content |
US9030486B2 (en) | 2008-08-22 | 2015-05-12 | University Of Virginia Patent Foundation | System and method for low bandwidth image transmission |
US20100070987A1 (en) * | 2008-09-12 | 2010-03-18 | At&T Intellectual Property I, L.P. | Mining viewer responses to multimedia content |
US20100070858A1 (en) * | 2008-09-12 | 2010-03-18 | At&T Intellectual Property I, L.P. | Interactive Media System and Method Using Context-Based Avatar Configuration |
US9148630B2 (en) | 2008-09-12 | 2015-09-29 | At&T Intellectual Property I, L.P. | Moderated interactive media sessions |
US9749683B2 (en) | 2008-10-01 | 2017-08-29 | At&T Intellectual Property I, L.P. | System and method for a communication exchange with an avatar in a media communication system |
US20100083320A1 (en) * | 2008-10-01 | 2010-04-01 | At&T Intellectual Property I, L.P. | System and method for a communication exchange with an avatar in a media communication system |
US8935723B2 (en) | 2008-10-01 | 2015-01-13 | At&T Intellectual Property I, Lp | System and method for a communication exchange with an avatar in a media communication system |
US8631432B2 (en) | 2008-10-01 | 2014-01-14 | At&T Intellectual Property I, Lp | System and method for a communication exchange with an avatar in a media communication system |
US8316393B2 (en) * | 2008-10-01 | 2012-11-20 | At&T Intellectual Property I, L.P. | System and method for a communication exchange with an avatar in a media communication system |
US9462321B2 (en) | 2008-10-01 | 2016-10-04 | At&T Intellectual Property I, L.P. | System and method for a communication exchange with an avatar in a media communication system |
US10783351B2 (en) * | 2008-11-04 | 2020-09-22 | Samsung Electronics Co., Ltd. | System and method for sensing facial gesture |
US20100109998A1 (en) * | 2008-11-04 | 2010-05-06 | Samsung Electronics Co., Ltd. | System and method for sensing facial gesture |
US9304583B2 (en) | 2008-11-20 | 2016-04-05 | Amazon Technologies, Inc. | Movement recognition as input mechanism |
US20100125816A1 (en) * | 2008-11-20 | 2010-05-20 | Bezos Jeffrey P | Movement recognition as input mechanism |
US8788977B2 (en) * | 2008-11-20 | 2014-07-22 | Amazon Technologies, Inc. | Movement recognition as input mechanism |
US20100226288A1 (en) * | 2009-03-04 | 2010-09-09 | At&T Intellectual Property I, Lp. | Method and apparatus for group media consumption |
US9276761B2 (en) | 2009-03-04 | 2016-03-01 | At&T Intellectual Property I, L.P. | Method and apparatus for group media consumption |
US8457971B2 (en) | 2009-03-06 | 2013-06-04 | At&T Intellectual Property I, L.P. | Method and apparatus for analyzing discussion regarding media programs |
US8275623B2 (en) | 2009-03-06 | 2012-09-25 | At&T Intellectual Property I, L.P. | Method and apparatus for analyzing discussion regarding media programs |
US8589168B2 (en) | 2009-03-06 | 2013-11-19 | At&T Intellectual Property I, L.P. | Method and apparatus for analyzing discussion regarding media programs |
US20110007142A1 (en) * | 2009-07-09 | 2011-01-13 | Microsoft Corporation | Visual representation expression based on player expression |
US9519989B2 (en) | 2009-07-09 | 2016-12-13 | Microsoft Technology Licensing, Llc | Visual representation expression based on player expression |
US8390680B2 (en) | 2009-07-09 | 2013-03-05 | Microsoft Corporation | Visual representation expression based on player expression |
US8629895B2 (en) * | 2009-08-21 | 2014-01-14 | Avaya Inc. | Camera-based facial recognition or other single/multiparty presence detection as a method of effecting telecom device alerting |
US20110043602A1 (en) * | 2009-08-21 | 2011-02-24 | Avaya Inc. | Camera-based facial recognition or other single/multiparty presence detection as a method of effecting telecom device alerting |
US20110080336A1 (en) * | 2009-10-07 | 2011-04-07 | Microsoft Corporation | Human Tracking System |
US9679390B2 (en) | 2009-10-07 | 2017-06-13 | Microsoft Technology Licensing, Llc | Systems and methods for removing a background of an image |
US8963829B2 (en) | 2009-10-07 | 2015-02-24 | Microsoft Corporation | Methods and systems for determining and tracking extremities of a target |
US9582717B2 (en) | 2009-10-07 | 2017-02-28 | Microsoft Technology Licensing, Llc | Systems and methods for tracking a model |
US8564534B2 (en) | 2009-10-07 | 2013-10-22 | Microsoft Corporation | Human tracking system |
US8970487B2 (en) | 2009-10-07 | 2015-03-03 | Microsoft Technology Licensing, Llc | Human tracking system |
US8542910B2 (en) | 2009-10-07 | 2013-09-24 | Microsoft Corporation | Human tracking system |
US9659377B2 (en) | 2009-10-07 | 2017-05-23 | Microsoft Technology Licensing, Llc | Methods and systems for determining and tracking extremities of a target |
US8861839B2 (en) | 2009-10-07 | 2014-10-14 | Microsoft Corporation | Human tracking system |
US8897495B2 (en) | 2009-10-07 | 2014-11-25 | Microsoft Corporation | Systems and methods for tracking a model |
US8891827B2 (en) | 2009-10-07 | 2014-11-18 | Microsoft Corporation | Systems and methods for tracking a model |
US8867820B2 (en) | 2009-10-07 | 2014-10-21 | Microsoft Corporation | Systems and methods for removing a background of an image |
US20110234589A1 (en) * | 2009-10-07 | 2011-09-29 | Microsoft Corporation | Systems and methods for tracking a model |
US8483436B2 (en) | 2009-10-07 | 2013-07-09 | Microsoft Corporation | Systems and methods for tracking a model |
US9522328B2 (en) | 2009-10-07 | 2016-12-20 | Microsoft Technology Licensing, Llc | Human tracking system |
US20110080475A1 (en) * | 2009-10-07 | 2011-04-07 | Microsoft Corporation | Methods And Systems For Determining And Tracking Extremities Of A Target |
US9821226B2 (en) | 2009-10-07 | 2017-11-21 | Microsoft Technology Licensing, Llc | Human tracking system |
US8325984B2 (en) | 2009-10-07 | 2012-12-04 | Microsoft Corporation | Systems and methods for tracking a model |
US8935724B2 (en) | 2009-10-15 | 2015-01-13 | At&T Intellectual Property I, Lp | Apparatus and method for transmitting media content |
US8266652B2 (en) | 2009-10-15 | 2012-09-11 | At&T Intellectual Property I, L.P. | Apparatus and method for transmitting media content |
US8645997B2 (en) | 2009-10-15 | 2014-02-04 | At&T Intellectual Property I, L.P. | Apparatus and method for transmitting media content |
US9661391B2 (en) | 2009-10-15 | 2017-05-23 | At&T Intellectual Property I, L.P. | Apparatus and method for transmitting media content |
US9432706B2 (en) | 2009-10-15 | 2016-08-30 | At&T Intellectual Property I, L.P. | Apparatus and method for transmitting media content |
US9124908B2 (en) | 2009-10-15 | 2015-09-01 | At&T Intellectual Property I, Lp | Apparatus and method for transmitting media content |
US20110093909A1 (en) * | 2009-10-15 | 2011-04-21 | At&T Intellectual Property I, L.P. | Apparatus and method for transmitting media content |
US9830605B2 (en) | 2009-10-30 | 2017-11-28 | At&T Intellectual Property I, L.P. | Apparatus and method for product marketing |
US20110106612A1 (en) * | 2009-10-30 | 2011-05-05 | At&T Intellectual Property L.L.P. | Apparatus and method for product marketing |
US8504484B2 (en) | 2009-11-05 | 2013-08-06 | At&T Intellectual Property I, Lp | Apparatus and method for managing a social network |
US20110106718A1 (en) * | 2009-11-05 | 2011-05-05 | At&T Intellectual Property I, L.P. | Apparatus and method for managing a social network |
US8224756B2 (en) | 2009-11-05 | 2012-07-17 | At&T Intellectual Property I, L.P. | Apparatus and method for managing a social network |
US9098867B2 (en) | 2009-11-06 | 2015-08-04 | At&T Intellectual Property I, Lp | Apparatus and method for managing marketing |
US9942621B2 (en) | 2009-11-06 | 2018-04-10 | At&T Intellectual Property I, L.P. | Apparatus and method for managing marketing |
US8760469B2 (en) | 2009-11-06 | 2014-06-24 | At&T Intellectual Property I, L.P. | Apparatus and method for managing marketing |
US9565484B2 (en) | 2009-11-06 | 2017-02-07 | At&T Intellectual Property I, L.P. | Apparatus and method for managing marketing |
US20110109648A1 (en) * | 2009-11-06 | 2011-05-12 | At&T Intellectual Property I, L.P. | Apparatus and method for managing marketing |
US20110112665A1 (en) * | 2009-11-10 | 2011-05-12 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US9681190B2 (en) | 2009-11-10 | 2017-06-13 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US8316303B2 (en) | 2009-11-10 | 2012-11-20 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US20110113440A1 (en) * | 2009-11-10 | 2011-05-12 | At&T Intellectual Property I.L.P. | Apparatus and method for transmitting media content |
US9313547B2 (en) | 2009-11-10 | 2016-04-12 | At&T Intellectual Property I, Lp | Method and apparatus for presenting media programs |
US10820054B2 (en) | 2009-11-10 | 2020-10-27 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US9031379B2 (en) | 2009-11-10 | 2015-05-12 | At&T Intellectual Property I, L.P. | Apparatus and method for transmitting media content |
US8996998B2 (en) | 2009-11-10 | 2015-03-31 | At&T Intellectual Property I, Lp | Method and apparatus for presenting media programs |
US20110119725A1 (en) * | 2009-11-13 | 2011-05-19 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US10708663B2 (en) | 2009-11-13 | 2020-07-07 | At&T Intellectual Property I, L.P. | Apparatus and method for media on demand commentaries |
US9830041B2 (en) | 2009-11-13 | 2017-11-28 | At&T Intellectual Property I, Lp | Method and apparatus for presenting media programs |
US8387088B2 (en) | 2009-11-13 | 2013-02-26 | At&T Intellectual Property I, Lp | Method and apparatus for presenting media programs |
US8839306B2 (en) | 2009-11-20 | 2014-09-16 | At&T Intellectual Property I, Lp | Method and apparatus for presenting media programs |
US10353537B2 (en) | 2009-11-20 | 2019-07-16 | At&T Intellectual Property I, Lp | Apparatus and method for collaborative network in an enterprise setting |
US9898785B2 (en) | 2009-11-20 | 2018-02-20 | At&T Intellectual Property I, L.P. | Apparatus and method for managing a social network |
US9351047B2 (en) | 2009-11-20 | 2016-05-24 | At&T Intellectual Property I, Lp | Apparatus and method for managing a social network |
US9380349B2 (en) | 2009-11-20 | 2016-06-28 | At&T Intellectual Property I, Lp | Method and apparatus for presenting media programs |
US9986292B2 (en) | 2009-11-20 | 2018-05-29 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US9100550B2 (en) | 2009-11-20 | 2015-08-04 | At&T Intellectual Property I, L.P. | Apparatus and method for managing a social network |
US8373741B2 (en) | 2009-11-20 | 2013-02-12 | At&T Intellectual Property I, Lp | Apparatus and method for collaborative network in an enterprise setting |
US20110126252A1 (en) * | 2009-11-20 | 2011-05-26 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US20110122220A1 (en) * | 2009-11-20 | 2011-05-26 | At&T Intellectual Property I, L.P. | Apparatus and method for collaborative network in an enterprise setting |
US9639561B2 (en) | 2009-11-20 | 2017-05-02 | At&T Intellectual Property I, L.P. | Apparatus and method for managing a social network |
US10419819B2 (en) | 2009-11-20 | 2019-09-17 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US20110126253A1 (en) * | 2009-11-20 | 2011-05-26 | At&T Intellectual Property I, L.P. | Apparatus and method for managing a social network |
US9094726B2 (en) | 2009-12-04 | 2015-07-28 | At&T Intellectual Property I, Lp | Apparatus and method for tagging media content and managing marketing |
US10511894B2 (en) | 2009-12-04 | 2019-12-17 | At&T Intellectual Property I, L.P. | Apparatus and method for tagging media content and managing marketing |
US10038944B2 (en) | 2009-12-04 | 2018-07-31 | At&T Intellectual Property I, L.P. | Apparatus and method for tagging media content and managing marketing |
US20110138326A1 (en) * | 2009-12-04 | 2011-06-09 | At&T Intellectual Property I, L.P. | Apparatus and Method for Tagging Media Content and Managing Marketing |
US9479844B2 (en) | 2009-12-04 | 2016-10-25 | At&T Intellectual Property I, L.P. | Apparatus and method for tagging media content and managing marketing |
US8532400B1 (en) | 2009-12-07 | 2013-09-10 | Google Inc. | Scene classification for place recognition |
US20110135207A1 (en) * | 2009-12-07 | 2011-06-09 | Google Inc. | Matching An Approximately Located Query Image Against A Reference Image Set |
US8238671B1 (en) | 2009-12-07 | 2012-08-07 | Google Inc. | Scene classification for place recognition |
US8189964B2 (en) | 2009-12-07 | 2012-05-29 | Google Inc. | Matching an approximately located query image against a reference image set |
US8774527B1 (en) | 2009-12-07 | 2014-07-08 | Google Inc. | Matching an approximately located query image against a reference image set using cellular base station and wireless access point information |
US8798378B1 (en) | 2009-12-07 | 2014-08-05 | Google Inc. | Scene classification for place recognition |
US8768107B2 (en) | 2009-12-07 | 2014-07-01 | Google Inc. | Matching an approximately located query image against a reference image set |
US8648866B2 (en) | 2009-12-16 | 2014-02-11 | Industrial Technology Research Institute | Facial animation system and production method |
US20110141105A1 (en) * | 2009-12-16 | 2011-06-16 | Industrial Technology Research Institute | Facial Animation System and Production Method |
US9237294B2 (en) | 2010-03-05 | 2016-01-12 | Sony Corporation | Apparatus and method for replacing a broadcasted advertisement based on both heuristic information and attempts in altering the playback of the advertisement |
US8878773B1 (en) | 2010-05-24 | 2014-11-04 | Amazon Technologies, Inc. | Determining relative motion as input |
US9557811B1 (en) | 2010-05-24 | 2017-01-31 | Amazon Technologies, Inc. | Determining relative motion as input |
USRE49044E1 (en) * | 2010-06-01 | 2022-04-19 | Apple Inc. | Automatic avatar creation |
US9832528B2 (en) | 2010-10-21 | 2017-11-28 | Sony Corporation | System and method for merging network-based content with broadcasted programming content |
US20120147014A1 (en) * | 2010-12-08 | 2012-06-14 | Chao-Hua Lee | Method for extracting personal styles and its application to motion synthesis and recognition |
US20110181684A1 (en) * | 2011-02-07 | 2011-07-28 | InnovatioNet | Method of remote video communication and system of synthesis analysis and protection of user video images |
US8488011B2 (en) | 2011-02-08 | 2013-07-16 | Longsand Limited | System to augment a visual data stream based on a combination of geographical and visual information |
US8953054B2 (en) | 2011-02-08 | 2015-02-10 | Longsand Limited | System to augment a visual data stream based on a combination of geographical and visual information |
US8509525B1 (en) | 2011-04-06 | 2013-08-13 | Google Inc. | Clustering of forms from large-scale scanned-document collection |
US8493353B2 (en) | 2011-04-13 | 2013-07-23 | Longsand Limited | Methods and systems for generating and joining shared experience |
US9235913B2 (en) * | 2011-04-13 | 2016-01-12 | Aurasma Limited | Methods and systems for generating and joining shared experience |
US20130307874A1 (en) * | 2011-04-13 | 2013-11-21 | Longsand Limited | Methods and systems for generating and joining shared experience |
US9691184B2 (en) * | 2011-04-13 | 2017-06-27 | Aurasma Limited | Methods and systems for generating and joining shared experience |
US20150339839A1 (en) * | 2011-04-13 | 2015-11-26 | Longsand Limited | Methods and systems for generating and joining shared experience |
US9123272B1 (en) | 2011-05-13 | 2015-09-01 | Amazon Technologies, Inc. | Realistic image lighting and shading |
US9041734B2 (en) | 2011-07-12 | 2015-05-26 | Amazon Technologies, Inc. | Simulating three-dimensional features |
US9122917B2 (en) | 2011-08-04 | 2015-09-01 | Amazon Technologies, Inc. | Recognizing gestures captured by video |
US10088924B1 (en) | 2011-08-04 | 2018-10-02 | Amazon Technologies, Inc. | Overcoming motion effects in gesture recognition |
US8947351B1 (en) | 2011-09-27 | 2015-02-03 | Amazon Technologies, Inc. | Point of view determinations for finger tracking |
US9223415B1 (en) | 2012-01-17 | 2015-12-29 | Amazon Technologies, Inc. | Managing resource usage for task performance |
US8884928B1 (en) | 2012-01-26 | 2014-11-11 | Amazon Technologies, Inc. | Correcting for parallax in electronic displays |
US10019107B2 (en) | 2012-01-26 | 2018-07-10 | Amazon Technologies, Inc. | Correcting for parallax in electronic displays |
US9063574B1 (en) | 2012-03-14 | 2015-06-23 | Amazon Technologies, Inc. | Motion detection systems for electronic devices |
US9471153B1 (en) | 2012-03-14 | 2016-10-18 | Amazon Technologies, Inc. | Motion detection systems for electronic devices |
US9285895B1 (en) | 2012-03-28 | 2016-03-15 | Amazon Technologies, Inc. | Integrated near field sensor for display devices |
US9652083B2 (en) | 2012-03-28 | 2017-05-16 | Amazon Technologies, Inc. | Integrated near field sensor for display devices |
EP2835736A1 (en) * | 2012-04-06 | 2015-02-11 | Tencent Technology Shenzhen Company Limited | Method and device for automatically playing expression on virtual image |
EP2835736A4 (en) * | 2012-04-06 | 2016-11-02 | Tencent Tech Shenzhen Co Ltd | Method and device for automatically playing expression on virtual image |
US9430876B1 (en) | 2012-05-10 | 2016-08-30 | Aurasma Limited | Intelligent method of determining trigger items in augmented reality environments |
US9064326B1 (en) | 2012-05-10 | 2015-06-23 | Longsand Limited | Local cache of augmented reality content in a mobile computing device |
US9530251B2 (en) | 2012-05-10 | 2016-12-27 | Aurasma Limited | Intelligent method of determining trigger items in augmented reality environments |
US9423886B1 (en) | 2012-10-02 | 2016-08-23 | Amazon Technologies, Inc. | Sensor connectivity approaches |
US9336435B1 (en) | 2012-11-21 | 2016-05-10 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US9330301B1 (en) | 2012-11-21 | 2016-05-03 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US9035874B1 (en) | 2013-03-08 | 2015-05-19 | Amazon Technologies, Inc. | Providing user input to a computing device with an eye closure |
US9483113B1 (en) | 2013-03-08 | 2016-11-01 | Amazon Technologies, Inc. | Providing user input to a computing device with an eye closure |
US20140365310A1 (en) * | 2013-06-05 | 2014-12-11 | Machine Perception Technologies, Inc. | Presentation of materials based on low level feature analysis |
US9269012B2 (en) | 2013-08-22 | 2016-02-23 | Amazon Technologies, Inc. | Multi-tracker object tracking |
US20150062116A1 (en) * | 2013-08-30 | 2015-03-05 | 1-800 Contacts, Inc. | Systems and methods for rapidly generating a 3-d model of a user |
US11199906B1 (en) | 2013-09-04 | 2021-12-14 | Amazon Technologies, Inc. | Global user input management |
US10055013B2 (en) | 2013-09-17 | 2018-08-21 | Amazon Technologies, Inc. | Dynamic object tracking for user interfaces |
US9367203B1 (en) | 2013-10-04 | 2016-06-14 | Amazon Technologies, Inc. | User interface techniques for simulating three-dimensional depth |
US20150228077A1 (en) * | 2014-02-08 | 2015-08-13 | Honda Motor Co., Ltd. | System and method for mapping, localization and pose correction |
US9443309B2 (en) * | 2014-02-08 | 2016-09-13 | Honda Motor Co., Ltd. | System and method for image based mapping, localization, and pose correction of a vehicle with landmark transform estimation |
US9342888B2 (en) * | 2014-02-08 | 2016-05-17 | Honda Motor Co., Ltd. | System and method for mapping, localization and pose correction of a vehicle based on images |
EP2966592A3 (en) * | 2014-07-07 | 2016-02-10 | Toshiba TEC Kabushiki Kaisha | Face recognition apparatus and method for recognizing face |
EP3614304A1 (en) * | 2014-11-05 | 2020-02-26 | INTEL Corporation | Avatar video apparatus and method |
US9600713B2 (en) * | 2015-04-27 | 2017-03-21 | AprilAge Inc. | Identification and processing of facial wrinkles in a digital image |
US20180190000A1 (en) * | 2016-12-30 | 2018-07-05 | Microsoft Technology Licensing, Llc | Morphing chart animations in a browser |
US11086498B2 (en) | 2016-12-30 | 2021-08-10 | Microsoft Technology Licensing, Llc. | Server-side chart layout for interactive web application charts |
US10395412B2 (en) * | 2016-12-30 | 2019-08-27 | Microsoft Technology Licensing, Llc | Morphing chart animations in a browser |
US10304225B2 (en) | 2016-12-30 | 2019-05-28 | Microsoft Technology Licensing, Llc | Chart-type agnostic scene graph for defining a chart |
US11055889B2 (en) | 2018-02-23 | 2021-07-06 | Samsung Electronics Co., Ltd. | Electronic device displaying avatar motion-performed as per movement of facial feature point and method for operating same |
US11508107B2 (en) | 2018-02-26 | 2022-11-22 | Didimo, Inc. | Additional developments to the automatic rig creation process |
US20210328954A1 (en) * | 2018-03-06 | 2021-10-21 | Didimo, Inc. | Advanced Electronic Messaging Utilizing Animatable 3D Models |
US11741650B2 (en) * | 2018-03-06 | 2023-08-29 | Didimo, Inc. | Advanced electronic messaging utilizing animatable 3D models |
US20230102851A1 (en) * | 2021-09-24 | 2023-03-30 | Gn Hearing A/S | Triggering a head-pose dependent action |
Also Published As
Publication number | Publication date |
---|---|
US6940454B2 (en) | 2005-09-06 |
US20020118195A1 (en) | 2002-08-29 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6272231B1 (en) | Wavelet-based facial motion capture for avatar animation | |
US6580811B2 (en) | Wavelet-based facial motion capture for avatar animation | |
KR100653288B1 (en) | Face recognition from video images | |
Wechsler | Reliable Face Recognition Methods: System Design, Impementation and Evaluation | |
Pighin et al. | Modeling and animating realistic faces from images | |
US7133540B2 (en) | Rapid computer modeling of faces for animation | |
US7212664B2 (en) | Constructing heads from 3D models and 2D silhouettes | |
Moghaddam et al. | Model-based 3D face capture with shape-from-silhouettes | |
Gavrila et al. | Tracking of humans in action: A 3-D model-based approach | |
Poggio et al. | A novel approach to graphics | |
Achenbach et al. | Accurate Face Reconstruction through Anisotropic Fitting and Eye Correction. | |
EP1580684B1 (en) | Face recognition from video images | |
Stylianou et al. | Image based 3d face reconstruction: a survey | |
Cohen et al. | 3D body reconstruction for immersive interaction | |
Barros et al. | Real-time monocular 6-dof head pose estimation from salient 2d points | |
Jian et al. | Realistic face animation generation from videos | |
Abeysundera et al. | Nearest neighbor weighted average customization for modeling faces | |
AU2004212509B2 (en) | Face recognition from video images | |
Suen et al. | A survey of techniques for face reconstruction | |
MXPA00010044A (en) | Wavelet-based facial motion capture for avatar animation | |
Yu | Facial feature detection and tracking with a 3d constrained local model | |
Chang et al. | Robust head pose estimation using textured polygonal model with local correlation measure | |
Dornaika et al. | Evaluation of an appearance-based 3D face tracker using dense 3D data | |
Atienza et al. | Face tracking approach for the development of hands-free user interfaces | |
Neumann et al. | Spatio-temporal analysis of human faces using multi-resolution subdivision surfaces |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: EYEMATIC INTERFACES, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MAURER, THOMAS;ELAGIN, EGOR VALERIEVICH;NOCERA, LUCIANO PASQUALE AGOSTINO;AND OTHERS;REEL/FRAME:009739/0290;SIGNING DATES FROM 19981215 TO 19990121 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: EYEMATIC INTERFACES, INC., CALIFORNIAFree format text: SECURITY AGREEMENT;ASSIGNOR:NEVENGINEERING, INC.;REEL/FRAME:014532/0427Effective date: 20030702 |
|
AS | Assignment |
Owner name: NEVENGINEERING, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:EYEMATIC INTERFACES, INC.;REEL/FRAME:015008/0717Effective date: 20031003 |
|
FEPP | Fee payment procedure |
Free format text: PAT HOLDER NO LONGER CLAIMS SMALL ENTITY STATUS, ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: STOL); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
REFU | Refund |
Free format text: REFUND - SURCHARGE, PETITION TO ACCEPT PYMT AFTER EXP, UNINTENTIONAL (ORIGINAL EVENT CODE: R2551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE INC.,CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:NEVENGINEERING, INC.;REEL/FRAME:018616/0814Effective date: 20061206Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:NEVENGINEERING, INC.;REEL/FRAME:018616/0814Effective date: 20061206 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044127/0735Effective date: 20170929 |