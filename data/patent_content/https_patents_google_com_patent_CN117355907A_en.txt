CN117355907A - Actively hiding stress source identification and notification - Google Patents
Actively hiding stress source identification and notification Download PDFInfo
- Publication number
- CN117355907A CN117355907A CN202280037283.XA CN202280037283A CN117355907A CN 117355907 A CN117355907 A CN 117355907A CN 202280037283 A CN202280037283 A CN 202280037283A CN 117355907 A CN117355907 A CN 117355907A
- Authority
- CN
- China
- Prior art keywords
- information
- image data
- user
- text information
- stress
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 230000036541 health Effects 0.000 claims abstract description 118
- 238000000034 method Methods 0.000 claims abstract description 102
- 239000013598 vector Substances 0.000 claims abstract description 85
- 230000008451 emotion Effects 0.000 claims description 43
- 238000012545 processing Methods 0.000 claims description 20
- 238000004891 communication Methods 0.000 claims description 18
- 238000012706 support-vector machine Methods 0.000 claims description 15
- 230000015654 memory Effects 0.000 claims description 14
- 230000000694 effects Effects 0.000 claims description 9
- 230000004044 response Effects 0.000 claims description 2
- 230000000007 visual effect Effects 0.000 abstract description 6
- 238000013459 approach Methods 0.000 abstract description 3
- 238000005516 engineering process Methods 0.000 description 31
- 238000004422 calculation algorithm Methods 0.000 description 20
- 230000009467 reduction Effects 0.000 description 17
- 238000000513 principal component analysis Methods 0.000 description 11
- 238000010801 machine learning Methods 0.000 description 9
- 241000282472 Canis lupus familiaris Species 0.000 description 8
- 238000010586 diagram Methods 0.000 description 7
- 230000008569 process Effects 0.000 description 7
- 230000036772 blood pressure Effects 0.000 description 6
- QVGXLLKOCUKJST-UHFFFAOYSA-N atomic oxygen Chemical compound [O] QVGXLLKOCUKJST-UHFFFAOYSA-N 0.000 description 5
- 230000006870 function Effects 0.000 description 5
- 229910052760 oxygen Inorganic materials 0.000 description 5
- 239000001301 oxygen Substances 0.000 description 5
- 238000012805 post-processing Methods 0.000 description 5
- 238000012549 training Methods 0.000 description 5
- 230000007787 long-term memory Effects 0.000 description 4
- 239000000203 mixture Substances 0.000 description 4
- 241000282326 Felis catus Species 0.000 description 3
- 206010003119 arrhythmia Diseases 0.000 description 3
- 238000013528 artificial neural network Methods 0.000 description 3
- 239000008280 blood Substances 0.000 description 3
- 210000004369 blood Anatomy 0.000 description 3
- 235000013305 food Nutrition 0.000 description 3
- 239000003292 glue Substances 0.000 description 3
- 238000012544 monitoring process Methods 0.000 description 3
- 208000019901 Anxiety disease Diseases 0.000 description 2
- 241001465754 Metazoa Species 0.000 description 2
- 241000981595 Zoysia japonica Species 0.000 description 2
- 230000009471 action Effects 0.000 description 2
- 230000036506 anxiety Effects 0.000 description 2
- 230000006793 arrhythmia Effects 0.000 description 2
- 230000000903 blocking effect Effects 0.000 description 2
- 230000001413 cellular effect Effects 0.000 description 2
- HVYWMOMLDIMFJA-DPAQBDIFSA-N cholesterol Chemical compound C1C=C2C[C@@H](O)CC[C@]2(C)[C@@H]2[C@@H]1[C@@H]1CC[C@H]([C@H](C)CCCC(C)C)[C@@]1(C)CC2 HVYWMOMLDIMFJA-DPAQBDIFSA-N 0.000 description 2
- 238000013135 deep learning Methods 0.000 description 2
- 238000002372 labelling Methods 0.000 description 2
- 230000003340 mental effect Effects 0.000 description 2
- 230000035945 sensitivity Effects 0.000 description 2
- 238000012360 testing method Methods 0.000 description 2
- INGWEZCOABYORO-UHFFFAOYSA-N 2-(furan-2-yl)-7-methyl-1h-1,8-naphthyridin-4-one Chemical compound N=1C2=NC(C)=CC=C2C(O)=CC=1C1=CC=CO1 INGWEZCOABYORO-UHFFFAOYSA-N 0.000 description 1
- 241000283899 Gazella Species 0.000 description 1
- 108010064719 Oxyhemoglobins Proteins 0.000 description 1
- 208000000418 Premature Cardiac Complexes Diseases 0.000 description 1
- 210000000577 adipose tissue Anatomy 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 210000004556 brain Anatomy 0.000 description 1
- 239000003990 capacitor Substances 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 235000012000 cholesterol Nutrition 0.000 description 1
- 238000004140 cleaning Methods 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 230000000875 corresponding effect Effects 0.000 description 1
- 108010002255 deoxyhemoglobin Proteins 0.000 description 1
- 230000003205 diastolic effect Effects 0.000 description 1
- 238000009826 distribution Methods 0.000 description 1
- 230000035622 drinking Effects 0.000 description 1
- 230000002526 effect on cardiovascular system Effects 0.000 description 1
- 230000005611 electricity Effects 0.000 description 1
- 239000004744 fabric Substances 0.000 description 1
- 230000002068 genetic effect Effects 0.000 description 1
- 230000003862 health status Effects 0.000 description 1
- 230000001939 inductive effect Effects 0.000 description 1
- 230000002452 interceptive effect Effects 0.000 description 1
- 239000010985 leather Substances 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 239000002184 metal Substances 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 230000004800 psychological effect Effects 0.000 description 1
- 230000009323 psychological health Effects 0.000 description 1
- 238000007637 random forest analysis Methods 0.000 description 1
- 238000003860 storage Methods 0.000 description 1
- 239000000126 substance Substances 0.000 description 1
- 238000013526 transfer learning Methods 0.000 description 1
- 230000002861 ventricular Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16H—HEALTHCARE INFORMATICS, i.e. INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR THE HANDLING OR PROCESSING OF MEDICAL OR HEALTHCARE DATA
- G16H50/00—ICT specially adapted for medical diagnosis, medical simulation or medical data mining; ICT specially adapted for detecting, monitoring or modelling epidemics or pandemics
- G16H50/20—ICT specially adapted for medical diagnosis, medical simulation or medical data mining; ICT specially adapted for detecting, monitoring or modelling epidemics or pandemics for computer-aided diagnosis, e.g. based on medical expert systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
- G06N20/10—Machine learning using kernel methods, e.g. support vector machines [SVM]
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16H—HEALTHCARE INFORMATICS, i.e. INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR THE HANDLING OR PROCESSING OF MEDICAL OR HEALTHCARE DATA
- G16H40/00—ICT specially adapted for the management or administration of healthcare resources or facilities; ICT specially adapted for the management or operation of medical equipment or devices
- G16H40/60—ICT specially adapted for the management or administration of healthcare resources or facilities; ICT specially adapted for the management or operation of medical equipment or devices for the operation of medical equipment or devices
- G16H40/63—ICT specially adapted for the management or administration of healthcare resources or facilities; ICT specially adapted for the management or operation of medical equipment or devices for the operation of medical equipment or devices for local operation
Abstract
The local and private models may be used to analyze text, visual, and audible content on the user's local device to provide notification of events for which the stress exceeds a predetermined threshold. The trained model may be trained by a combination of analysis of the health sensor data and the content. Multiple models or techniques may be used to analyze the content and vector the content. When a predetermined threshold is met, a vector-based approach may be used to classify future content as stress.
Description
Cross Reference to Related Applications
This application is a continuation of U.S. patent application Ser. No.17/331,077, filed 5/26 of 2021, the disclosure of which is incorporated herein by reference.
Background
Psychological health stress sources are difficult to identify and track, but understanding them is important to maintaining overall health. As computing becomes more common, people may be able to gain specific understanding and control of stress content and the circumstances to which computing devices may expose them. In more detail, specific types of content across news, messaging, and social media have been shown to induce stress and have a negative impact on user health.
Notifications related to "screen time" or "activity" are not tied to live or active health information or underlying content. In this way, psychological, subconscious, or psychological effects of stress sources contained within the media, application, or content are not recognized and may often not be detected or noticed by the user.
Disclosure of Invention
Aspects of the present disclosure include methods, systems, and apparatus for proactively hiding stress source identification and notification.
One aspect of the disclosed technology may include a method for determining a source of health stress. The method may include: receiving input information comprising one or more of text information displayed on a user device of a user and image data displayed on the user device; receiving health information from a wearable device associated with a user at a given time stamp; associating at least one of the text information and the image data with a given time stamp based on determining that the received health information is at least a threshold; and associating other text information or other image data with the text information or image data based on the received health information using the model. The method may further include generating a stress indicator based on determining that other text information and other image data are related to text information and image data associated with the received health information.
In accordance with this aspect of the disclosed technology, the method may, for example, include classifying textual information to produce a first numerical value; determining a topic category associated with the text information to produce a second value; classifying the image data to produce a third value; and forming a first vector comprising the first, second and third values and the received health information. Further, in accordance with this aspect of the present technique, correlating may include searching a vector space having a plurality of vectors using the received health information of the first vector. Thus, the formed first vector may be used to effectively correlate later received input information with previously received input information based on health information in order to determine whether content to be displayed may involve (for an individual user) a risk of stressing the content. Further, in accordance with this aspect of the technology, classifying the text information may include classifying the text information using an emotion classifier. Additionally, the output of the emotion classifier may be mapped to a value comprising the first value. In addition, the emotion classifier may include one of a Support Vector Machine (SVM), a bayesian classifier, or a long-term memory (LSTM) derived model.
Depending on the method, the image data may for example comprise video or still image data. In some examples, the image data may be viewed by an application on the user device. In some examples, the health information may include one or more of heart rate, heart rate variability, temperature, stress from EDA activity, user motion, and sleep data.
According to the method, the stress indicator may comprise a message informing the user of the stress source event.
Another aspect of the disclosed technology may include an apparatus. The apparatus may include a computing device, such as, for example, a portable computing device (e.g., smart phone, laptop computer, tablet computer) or a desktop computing device (e.g., PC, TV).
In accordance with this aspect of the disclosed technology, the apparatus may include a communication interface; a display; and one or more computing devices coupled to the one or more memory devices, the one or more memory devices containing instructions that cause the one or more processing devices to process the input information and the health information. For example, the instructions may cause the one or more processing devices to: obtaining input information comprising one or more of text information and image data displayed on a display; obtaining health information at a given time stamp from a wearable device associated with a user; associating at least one of the text information and the image data with a given time stamp based on determining that the received health information is at least at a threshold; and associating other text information or other image data with the text information or image data using the model based on the received health information. In accordance with this aspect of the disclosed technology, the instructions may cause the one or more processing devices to generate the stress indicator based on determining that other text information and other image data are related to text information and image data associated with the received health information.
In accordance with this aspect of the disclosed technology, the one or more instructions may further cause the one or more processing devices to perform one or more of the following: classifying the text information to produce a first numerical value; determining a topic category associated with the text information to produce a second value; classifying the image data to produce a third value; and forming a first vector comprising the first, second and third values and the received health information. Additionally, the instructions may cause the one or more processing devices to correlate by searching a vector space having a plurality of vectors using the received health information of the first vector. Further, the instructions may cause the one or more processing devices to classify the text information by classifying the text information using an emotion classifier. In some examples, the output of the emotion classifier is mapped to a value comprising the first value. In some examples, the emotion classifier includes one of a Support Vector Machine (SVM), a bayesian classifier, or a long-term memory (LSTM) derived model.
According to this aspect of the disclosed technology, the image data may include video or still image data. Further, the image data may be viewable by an application on the device.
According to this aspect of the disclosed technology, the health information may include one or more of heart rate, heart rate variability, temperature, stress from EDA activity, user motion, and sleep data.
In accordance with this aspect of the disclosed technology, the stress indicator may include a message informing the user of the stress source event.
Drawings
The drawings are not intended to be drawn to scale. Like reference numbers and designations in the various drawings indicate like elements. For purposes of clarity, not every component may be labeled in every drawing.
In the drawings:
fig. 1 is a schematic diagram of an electronic device according to aspects of the present disclosure.
Fig. 2A is an illustration of a wearable user device supporting PPG functionality in accordance with aspects of the present disclosure.
Fig. 2B is a diagram of a user interface according to aspects of the present disclosure.
Fig. 2C is a diagram of a user interface according to aspects of the present disclosure.
Fig. 2D is a schematic diagram of communication between devices according to aspects of the present disclosure.
Fig. 2E is a schematic diagram of communication between devices according to aspects of the present disclosure.
Fig. 2F is a schematic diagram of communication between two PPG modules according to aspects of the present disclosure.
Fig. 3 is a flow chart of an example method in accordance with aspects of the present disclosure.
Fig. 4 is a flow chart of an example method in accordance with aspects of the present disclosure.
Detailed Description
SUMMARY
The present technology relates to techniques for identifying stress-related stimuli of a subject or user. More specifically, the technique measures health statistics associated with the subject and detects content viewed by the subject on a display of the device. The health statistics and detected content may then be correlated to detect, identify and track the subject's psychological stressors. Furthermore, the technique may inform the subject of such stressors that may have an impact on the mental and physical health of the subject to potentially reduce negative impact. Thus, the proposed solution allows combining measured health statistics with content information about content displayed to a user to automatically generate stress indicators that may trigger operational events on a user device, such as displaying notifications, sending stress indicator data (e.g., to another device), and/or classifying future content based on the stress indicators.
The identification and tracking of stress sources via, for example, one or more computing devices, may be used to relieve stress of the subject. Aspects of the disclosed technology use emotion analysis and cross-device hardware and software signals in a framework to identify, track, and notify a user or an object of a stress source, and thereby provide tools to such objects to avoid or alleviate stress content. This in turn should reduce the negative impact such stressors have on the subject on mental and/or physical health.
For example, the wearable device may monitor health-related characteristics associated with the subject, such as heart rate, oxygen saturation level, stress from EDA activity, temperature, movement (e.g., number of steps, walking or running distance), and sleep data. These features may be provided to a second device, such as a smart phone or smart television, on which the user may view content. When the second device determines that one or more of the health-related features meets or exceeds a threshold, the second device may determine what on-screen content the subject is viewing when the threshold is exceeded and notify the user of the stressor event. For example, if the heart rate of the subject exceeds a threshold (e.g., 80 bpm), the second device may determine the type of content on the user's screen when the heart rate of the subject exceeds the threshold. In other examples, a combination of signals may be used to determine a threshold or threshold condition. When the threshold is exceeded, the user may be notified that their heart rate exceeds the threshold and the type of content displayed on the screen when the heart rate exceeds the threshold. The type of content may also be marked within the second device such that when similar content appears on the screen, the object may be notified that such content may be an stressor event of the object.
Aspects of the disclosed technology use multiple inputs to estimate how the stimulus psychologically and physiologically affects a subject or user. All inputs are processed locally on the device of the object using the model. The input signals may include video and images viewable by users via applications (e.g., youTube and a web browser). Text information viewable via a web browser or social media application may also be used as input, but such information is only for the purpose of generating a model of the output that can be read by the user. Furthermore, the model inputs are not shared with the entity providing the service, e.g., google, or any third party. The disclosed techniques may be implemented as a separate application on a user device (e.g., a stressor application) and may only monitor content viewed by a user on applications approved (e.g., whitelisted) by the user. For example, such applications may request from the user which applications should be whitelisted for stress source monitoring and notification. Further, over time, users may add or remove whitelisted applications. Furthermore, the stress application may allow all information generated or related to the application to be deleted or erased such that the stored information, as well as any information generated, including the trained model, is removed. More generally, an application implementing features of the disclosed technology may be configured such that the application does not function without user consent, and all models and stored information may be deleted without any residue, and similarly the application is deleted.
In addition to inputs from the aforementioned applications, the application or model also receives health signals from a wearable device, such as a watch, a ring, or other device that may detect health related signals. The health related signal may be processed to derive a health related parameter or characteristic. Alternatively, the wearable device may derive and provide health-related parameters or features to an application or model.
These inputs may be provided to a machine learning model running on the user's smartphone or other device. In particular, the whitelist text data may be used as input to an emotion classifier. The emotion classifier may be implemented using a Support Vector Machine (SVM), long-term memory (LSTM) derived model, or any model that supports text classification. The emotion classifier may provide discrete outputs such as active, passive, violent, terrible, lengthy, etc. These discrete outputs are mapped to values, e.g., active-1, passive-2, violent-3, etc., which are more convenient for vectorization.
The whitelist text data is also fed to the topic modeler. In general, such topic modelers may utilize dimension reduction, clustering, and automatic (or semi-automatic) topic labeling. Acceptable algorithms that may be used in this aspect of the present technology may include, but are not limited to, any of Linear Discriminant Analysis (LDA), latent Semantic Analysis (LSA), or probabilistic LSA (pLSA) topic model methods. Topics may include a wide variety of categories such as, for example, news, technology, sports, and the like. Topics may also be finer grained such as, for example, "war news", "criminal news", "political news", "space technology", "automotive technology", "food technology", etc. The topic modeler also maps topics to values for vectorization.
The image and video data are classified based on type and provided as input to the model. For example, a cat's video will be labeled "cat video". Videos related to breaking news stories may be labeled "news videos" and "breaking. Tags may be mapped to numerical values. For example, news may be mapped to a value of 5, while "cat video" may be mapped to a value of 10.
Health related statistics, features or parameters, such as heart rate data, heart rate variability data, sleep data, etc., are also provided to the model. Such data may be provided as a signal from the wearable device, or may be derived from a signal provided by the wearable device.
The values thereof are used to vectorize the emotion classifier, the media modeler, the output of the media classifier and the health features. The values of the emotion classifier, the media modeler and the media classifier are mapped onto the same scale. The glue (glue) for each vector is the time, e.g., the time when a particular health signal, text, and image that occurs is mapped to a vector, which then exists in the vector space.
Dimension reduction may be applied in the vector space to determine which dimension of the vector, e.g., which of the N dimensions, contributes the greatest variance. Dimension reduction is used to reduce the size of the data set. Typically, an algorithm is run to select a set of principal components to be used. For example, the target may be set to the amount of variance of the merge (e.g., 95%), and then the number of components needed to obtain the target is determined. Examples of dimension reduction algorithms that may be used include, for example, principal Component Analysis (PCA). The principal component may be used to measure a distance metric. The target variance of the data may be set or determined based on the defined parameters.
To determine the relevance between certain events that occur in a user's life, such as viewing social media and feeling stress, a vector space may be "queried" for certain test cases. For example, if a stressed health signal is detected, the stressor application may query the space with vectors of similar signals given some error buffer (because the sensor/post-processing algorithm is unlikely to output the same value each time) and look at the density of vector space "closest" to the query around a particular vector. As an example, a vector that is close in euclidean distance or another defined distance metric may be selected until a certain number of vectors are found, or the nearest "n" vectors are found.
Dense clustering techniques such as DBSCAN may be used to understand whether there is a correlation. The denser clusters will likely represent relevant factors because the subcomponents are similar, resulting in repeated instances of vectors appearing in the N-dimensional space. The threshold (% or ratio) may be defined before a recommendation can be made to the user or a trend detected. This may be based on the size of the cluster or on a threshold of the size of the cluster relative to other clusters. In some examples, the threshold may be tuned based on user feedback, user sensitivity parameters, or predefined sensitivity settings, such as, for example, a range from 0 to 10.
One aspect of the present technology is to use joint learning to develop and update models associated with processing inputs. Joint learning enables, for example, mobile devices to cooperatively learn a shared predictive model while maintaining training data locally on the device. Thus, according to the disclosed technology, a mobile device may download a sharing model from, for example, the cloud. The sharing model may then be updated by learning from events occurring on the mobile or other user device. In fact, the original sharing model may become more personalized to the user. Without the underlying user data, the anonymous and locally trained model on the user device may be saved as an update, which is then sent back to the cloud to update the shared model. The updated sharing model may then be provided back to the individual user device. Because all training data remains on each user device in the joint learning model environment, user privacy is ensured.
In another aspect, the model may also receive user-marked events as input. For example, when notifying a user of a stress event, the user may be prompted for input regarding their emotion, and so on. The model may then associate the tag with the event and use it to find similar events in the vector space and apply the tag to those vectors.
By analyzing multiple signals, the present technique allows more deep feedback to the user beyond "your screen time was up this week by X% and your sleep was down by Y% (your screen time rises by X% and your sleep falls by Y%)". It allows more specific feedback to be provided to the user, such as: "Your stress levels tend to increase when you watch action videos on YouTube before bed. To sleep better and feel less stressed, you should not watch videos before bed (when you watch motion video on YouTube before sleeping, you' stress level tends to increase. To get better sleep and feel less stress, you should not watch video before sleeping)".
Example System
Fig. 1 illustrates additional aspects of electronics 199, electronics 199 being useful in aspects of the disclosed technology as described in further detail below. Electronics 199 may be any computing device capable of performing the steps and algorithms described herein, such as, but not limited to, a cellular telephone, tablet computer, laptop computer, server, smart device, or smart watch. Although the description in fig. 1 is given with respect to electronics 199, those skilled in the art will appreciate that in some examples electronics 199 may be combined or interoperated with health sensor 140. A double-headed arrow indicating that communication between health sensor 140 and electronics 199 may occur is shown in fig. 1.
The health sensor 140 may be any device, circuitry, or module that may be used to observe or determine information related to the health status of a user, such as, for example, blood pressure, blood oxygen level, stress, or other metrics that may be derived from a combination of the exemplary foregoing metrics. A health sensor device such as an analog front end, a photodetector, an accelerometer, or a health sensor such as a photoplethysmograph sensor, device, or circuitry. In some examples, the health sensor need not be part of the same device as electronics 199, and may be included in a separate device. It should be understood that while the health sensor 140 is shown as having a particular configuration, other arrangements of these components are within the scope of the present disclosure. In other examples, the health sensor 140 may be included or disposed within a user device, such as a mechanical watch, a smart ring, a cellular phone, an ear bud earphone, a headset, an arm band, or a laptop computer. In other examples, the health sensor 140 may be integrated into jewelry, such as a pendant, necklace, bracelet, earring, armband, finger ring, foot chain, or other jewelry.
Electronics 199 may include power supply 190, processor 191, memory 192, data 193, user interface 194, display 195, communication interface 197, and instructions 498. The power source may be any suitable power source for generating electricity, such as a battery, a chemical battery, a capacitor, a solar panel, or an inductive charger. The processor 191 may be any conventional processor such as a commercially available microprocessor or Application Specific Integrated Circuit (ASIC); a memory that may store information accessible to the processor, including instructions and data that may be executed by the processor. Memory 192 may be of a memory type operable to store information accessible to the processor, including non-transitory computer-readable media or other media storing data readable by means of electronic devices such as hard drives, memory cards, read-only memory ("ROM"), random access memory ("RAM"), optical disks, and other devices capable of writing and reading data from a read-only memory. The subject matter disclosed herein may include different combinations of the foregoing, whereby different portions of the instructions and data are stored on different types of media. Data 193 of electronics 199 may be retrieved, stored, or modified by the processor according to instructions 198. For example, although the present disclosure is not limited by a particular data structure, data 193 may be stored in a relational database in a computer register as a table having a plurality of different fields and records, XML documents, or flat files. The data 193 may also be formatted in a computer readable format such as, but not limited to, binary values, ASCII, or Unicode. In addition, data 193 may include information sufficient to identify relevant information, such as numbers, descriptive text, proprietary codes, pointers, references to data stored in other memory (including other network locations), or information used by a function to calculate relevant data.
The instructions 198 may control various components and functions of the health sensor 140. For example, instructions 198 may be executed to selectively activate light source 110 or process information obtained by photodetector 120. In some examples, the algorithm may be included as or otherwise part of a subset of instructions 198 included in electronics 199.
The instructions 198 may include algorithms for interpreting or processing information received from the health sensor 140 or from other portions of the electronics 199, such as information received or generated by analyzing health information from the health sensor 140, information in the data 193, information displayed on the display 195, or information processed by the processor 191. For example, the physical parameters of the user may be extracted or analyzed by an algorithm. Without limitation, the algorithm may use any or all information about the waveform, such as the shape, frequency, or period of the wave, fourier analysis of the signal, harmonic analysis, pulse width, pulse area, peak-to-peak spacing, pulse spacing, intensity or amount of light received by the light detector, wavelength shift, or derivative of the signal generated or received by the photodetector of the health sensor 140. Other algorithms may be included to calculate oxygen uptake in oxyhemoglobin and deoxyhemoglobin, arrhythmia, heart rate, ventricular premature beat, missed heart beat, systolic and diastolic peak values, and large arterial stiffness index. In still other examples, artificial learning or machine learning algorithms may be used in both deterministic and non-deterministic ways to extract information about the physical condition of the user, such as blood pressure and stress levels, from, for example, heart rate variability. PPG can also be used to measure blood pressure by calculating the pulse wave velocity between two points separated by a distance on the skin. The pulse wave velocity is proportional to the blood pressure and this relationship can be used to calculate the blood pressure. In some examples, the algorithm may be modified or used with information entered by the user into the memory of electronics 199, such as the user's weight, height, age, cholesterol, genetic information, body fat percentage, or other physical parameters. In other examples, machine learning algorithms may be used to detect and monitor known or undetected health conditions, such as cardiac arrhythmias, based on information generated by light detectors, health sensors, and/or processors.
The instructions 198 may also include a trained machine learning module that may be used to determine whether a sensor is present or included on the user device.
The user interface 194 may be a screen, such as a touch screen or buttons, that allows a user to interact with the health sensor 140. The display 195 may be an LCD, LED, mobile phone display, electronic ink, or other display to display information about the health sensor 140. The user interface 194 may allow for both input from and output to the user. In some examples, the user interface 194 may be part of the electronics 199 or health sensor 140, while in other examples, the user interface may be considered part of the user device. The user interface 194 may also include devices such as a keyboard.
Communication interface 197 may include hardware and software to enable data communication via standards such as Wi-Fi, bluetooth, infrared, radio waves, and/or other analog and digital communication standards. Communication interface 197 allows electronics 199 to be updated and information generated by health sensor 140 shared to other devices. In some examples, communication interface 197 may send history information stored in memory 192 to another user device for display, storage, or further analysis. In other examples, communication interface 197 may send the signal generated by the photodetector to another user device for display on the device in real-time or later. In other examples, communication interface 197 may communicate with another PPG module. Communication interface 197 may include bluetooth, wi-Fi, gazelle, ANT, LTE, WCDMA, or other wireless protocols and hardware that enable communication between two devices.
Fig. 2A shows a user device 200 that may be worn by a user, such as user 299. The user device may comprise a housing 201 and a strap 202. The housing 201 may have a component such as a rear portion that will contact the skin of the user 299. The rear portion may include an optically transparent portion that allows light to pass through the rear portion. For example, light may be generated from other components housed within the housing 201, such as a light source. The user device 200 and the housing 201 may also have a user interface that allows the user 299 to interact with the user device 200 and view information. The user interface may be part of a touch screen or other device. Additional components that may be included in the user device 200 or the housing 201 are further described above with reference to fig. 1. The housing may further have a suitable thickness to include the components depicted in fig. 1. Strap 202 may be a strap that holds the user device on the user, such as a strap made of metal, leather, cloth, or other material. The user device 200 may include a health sensor module 140 to perform health sensing functions.
Although a smart watch is illustrated as the user device 200, those skilled in the art will appreciate that the user device 200 may take various forms. The user device 200 may also be a health sensor, an ear bud earphone or earplug, a headset or other wearable electronics, a ring, a bracelet, a foot chain, a necklace or other jewelry. The notification on the user device 200 may be a visual notification, such as on the display 203 of the user device, while in other examples, other notifications may be given, such as by vibration, audio alert, beep, flashing light, or other notification, depending on the capabilities of the user device.
Fig. 2B shows a user device 230. User device 230 may contain the various components described in electronics 199 with reference to fig. 1, which are omitted from fig. 2B for simplicity. A display 231 displaying content 232 is shown in fig. 2B. Content 232 may include text content, visual data, such as images or video, and metadata that may or may not be displayed on user device 230.
Superimposed over the content 232 is a notification 235. The notification 235 may be displayed when the displayed content causes a threshold value associated with the user's health to be exceeded and thus triggers the generation of a stress indicator. In other examples, the notification 235 may be preemptively displayed when the content 232 is first loaded or is to be loaded onto the user device 230 based on information contained therein. In some examples, the content may be "paused" before being loaded to prevent the occurrence of potential stress events. Further, a summary of the content types may be provided to the user for the user to determine whether the user wants to continue viewing the content. Based on the previously generated stress indicator (at least one parameter indicating automatically measured wellness statistics of the user exceeding the threshold when the particular content 232 is displayed on the user device 230) and the at least one content identifier of the content to be displayed, the user device 230 may thus be configured to block the content from being displayed until additional approval is received at the user device 230, e.g., through user input.
Fig. 2C and 2D show example formats for displaying information about the physical condition of a user on display 203 or display 231, which may be similar to display 195 described above. FIG. 2C shows a graph of heart rate of a user of a device, such as device 200. The graphical view may be updated in real-time to display the last few seconds of the user's heartbeat. In some examples, "real time" or "actual time" may mean execution of a data instruction or algorithm in a short period of time, which may provide near-instantaneous output to a user or user device. The displayed heartbeat may be obtained from the methods described herein. The notification when the user's heartbeat is above a certain threshold, such as 80 heartbeats per minute, may be represented by an interactable exclamation mark "-! "or other notification. The notification may be associated with content displayed on the user device.
Fig. 2D shows displaying information about the physical condition of the user in text format. For example, fig. 2D shows the current heart rate in Beats Per Minute (BPM), the current blood oxygen saturation level, and any other condition that may be a value of the user, such as arrhythmia. Although the examples given are for cardiovascular conditions, other aspects of the heart may be monitored.
Fig. 2D also shows other options for defining future processing of similar content to be displayed (i.e., content categorized as the same subject matter category and thus labeled with the same content identifier, for example) and/or for triggering actions with respect to currently displayed content, such as blocking content/applications that are causing a particular stress (non-approved applications), approving content/applications (approved applications), not displaying notifications again, or blocking the ability of similar content/applications. Although the information is displayed in visual format, in other examples, the information may be provided through audible methods. The information shown in fig. 2D may be derived from the methods described herein.
Fig. 2E illustrates communication between two user devices worn by a user 299, user device 200 and user device 290. In this example, the user device 290 is an earplug. Although the same reference numerals are used as the devices in fig. 2A-2B in fig. 2E, these devices need not be the same devices. In other examples, the user device 290 may be a headset, pendant, or other device containing a health sensor such as the health sensor 140. As explained further below, each user device may calculate or derive health-related information, and a combination of this information may be used when determining a threshold for the stress of the user. For example, one device may determine heart rate while another device determines blood pressure or blood oxygen level. In some examples, a device that does not contain a health sensor, such as smart phone 291, may receive health-related information from user device 200 and user device 290 and combine the two estimates together.
Fig. 2F shows an example of a user interface in which a user may determine or select which applications she wishes to approve for analysis of a stress source, which may occur locally, anonymously, and privately on a user device. Applications that have been approved or whitelisted may be analyzed by the systems, methods, and devices described herein. In some examples, the whitelist application may be automatically generated based on user preferences or default suggestions. In other cases, applications that contain a particular type of data cannot be whitelisted based on the type of content that the application contains, such as, for example, voice data, email data, or data related to confidential or proprietary applications.
Example method
As explained below, the following techniques or methods may be used to analyze approved or whitelisted data or applications for local stressors.
Fig. 3 shows an example schematic diagram of an architecture 300. Fig. 3 shows an example of how multiple inputs may be used to estimate how a stimulus affects a subject or user psychologically and physiologically. All inputs are processed locally on the device of the object using the model. The input signals may include video and images viewable by users via applications (e.g., youTube and a web browser). Text information viewed via a web browser or social media application may also be used as input.
An approved application 305 is shown in fig. 3. Approved application 305 may include any application that processes data on a device, such as the devices discussed above. Examples of such applications include YouTube, a web browser, a newspaper, or any other application for which a user approves content monitoring for a stress source. In this regard, aspects of the disclosed technology may be implemented as an application that monitors a screen display for data or receives data from other applications, processes the data it receives, and generates stress source indicators.
In this regard, the processes may be implemented using the elements, modules, or blocks shown in FIG. 3. Further in this regard, emotion classifier 320 may include one or more models that may be used to analyze text data. In some examples, emotion classifier 320 may include a bayesian classifier, a long-term memory model, an artificial neural network, or a support vector machine model. Other models or techniques may be used that may analyze the text information to provide an output. The emotion classifier may provide discrete outputs to the text input, such as, for example, positive or negative. Other examples of output may include additional classifications such as violent, hacker, lengthy, aggressive, exciting. The classification value may be associated with or mapped to a numerical value used by the vectorization module 340. For example, a scale may be applied to the possible outputs of the emotion classifier such that the violent output is given a value on the scale, a hacker is given another value, a verbose is given another value, etc. As a specific example, assume a scale from 1 to 100, a value of 90 for violent text, and a value of 10 for exciting text. These values are then output to a vectorization module that includes them in a vector along with other values it receives from other classifiers or modelers. Although numerical values may be used, other output values including text and the like may be output.
Topic modeler 325 may also receive text information from the whitelist application as emotion classifier 320 simultaneously, in real-time, or near-time. Models or techniques may be used that may provide as input text information and as output values for content identifiers related to topic categories, such as "technology", "sports", "news", "food". For example, models using dimension reduction, clustering, or automatic or semi-automatic labeling or themes may be used. Specific examples may include Linear Discriminant Analysis (LDA), latent Semantic Analysis (LSA), probabilistic latent semantic analysis (pLSA) models. In some examples, the model used may include information that has been marked using human-assisted methods. The topics may include a wide variety of categories such as, for example, news, technology, sports, and the like. Topics may also be finer grained such as, for example, "war news", "criminal news", "political news", "space technology", "automotive technology", "food technology", etc. The topic modeler 325 may also be configured to output values to allow for easier vectorization, which may also be referred to as a first content identifier.
The media classifier 330 may include one or more models that may capture video, or metadata related to video or other media, and classify the models. For example, a dog's video may be labeled "dog video" by media classifier 330. In some examples, finer granularity of marking may be used. For example, dog videos related to Dalmatian may be labeled "dog" and "Dalmation", while dog videos related to Shiba Inu may be labeled "dog" and "Shiba. These values may be mapped to any number that corresponds one-to-one to the tags, thereby generating a second content identifier.
The individual models (emotion classification, topic modeler, etc.) may be pre-trained on pre-existing datasets. The trained model may then be supplied as part of the stressor application through, for example, a copy and paste function. The functionality may be implemented using, for example, a transfer learning technique used in deep learning applications.
The module 335 may perform post-processing of the signal, cleaning of the signal or analysis of the information, signal or other data related to the health data 315. For example, signal post-processing may be performed to filter out noise, remove artifacts, or remove artifacts. Health data 315 may be obtained from, for example, health sensor 140. Health related statistics, features or parameters, such as heart rate data, heart rate variability data, sleep data, PPG data, etc. are also provided to the model. Such data may be provided as a signal from the wearable device, or may be derived from a signal provided by the wearable device. In some examples, the module 335 may include additional specialized information for analysis, depending on the type of health data 315 available. In some examples, the stress signal may be provided by EDA sensors on the wearable device or from some combination of cameras that can infer emotion and stress.
Vectorization module 340 may "vectorize" the information obtained from the above modules. The outputs of emotion classifier 320, media modeler 325, media classifier 330, and module 335 are vectorized using their values. The obtained values may be mapped onto the same scale. In some examples, a vector may be created or specified by a time value, such as the time at which particular information forming a numerical value is being mapped into the vector. In this way, each vector may correspond to or be uniquely associated with a particular time value. Although a specific number of examples are given with values, any vector having "N" dimensions may be generated using "N" or more inputs. Although vectorization module 340 is described as a vector, those skilled in the art will appreciate that n-tuples of data or other mathematical formulas may be used.
The dimension reduction module 345 may reduce the "distance" between the generated vectors. The dimension reduction module 345 may include any dimension reduction technique. As one example, principal component analysis may be used to analyze or identify which dimensions of an "N" dimensional vector most contribute to variance. Additional examples and details of dimension reduction are provided with respect to fig. 4. In some examples, stress may be measured or derived from EDA sensors on the wearable device, while in other examples stress may be a metric generated from a combination of data from sensors, such as cameras that may infer emotion or stress.
The density-based clustering module 350 may use a particular test case in which there is a health signal or indicator of stress and query the vector with a similar signal or signature (e.g., within a particular error range) to see the density of vector space around a particular vector that is "close" or similar to the queried vector. The denser clusters will likely indicate that the factors are relevant because the subcomponents are similar, resulting in repeated instances of vectors appearing in the N-dimensional space. For example, for some stress levels represented by 'S', all vectors containing S greater than the established value may exhibit similar or identical things, such as noise level or amount of media consumed. In some examples, a certain threshold must be met before the cluster is considered to be detected or valid, such as measured by a percentage or ratio, or used as a trigger under certain conditions. In some examples, additional thresholds may be added, such as the size of the clusters, the relative sizes of the clusters, or global optimization of the largest or most influential k clusters.
The notification module 355 may provide a stress indicator including user notifications related to stress triggers or events on a model or algorithm that determines that the analyzed information may correspond to a stress event. In some examples, the user notification may be similar to notification 235 given with respect to fig. 2B. In some examples, the notification may be interactive and allow the user to provide additional information, such as whether he or she is actually stressed, describing emotions (e.g., anxiety, excitement, active, passive), or providing notification whether he or she wants to see frequent or custom more or less. For example, this information may be used to provide more customized recommendations. As a specific example, after describing the emotion, the information may be used to retrain or customize the model to better or finer granularity categorize the emotion of the user.
In some examples, notification module 355 may provide other information related to the stress indicator after the event occurs. For example, the user may have been exposed to a particular type of content that may be related to a particular health condition, such as, for example, lack of deep sleep or a lesser number of sleep hours than usual. The notification module 355 may also provide summary information after the stress event, e.g., not in real-time, such as the end of a day or the end of a week, to allow the user to better understand the impact of a particular type of content. In some examples, the notification module 355 may also associate a particular application, topic, or media type with a particular effect, such as viewing a violent video resulting in more sleep, or viewing an anxiety video resulting in an overall elevated heart rate. In other examples, the techniques described herein may also adjust for changes in the user's "baseline" health information, such as, for example, when heart rate increases when no content is read. As one example, if the user's heart rate is elevated at a particular time of day, information that may be relevant to a particular event (e.g., drinking coffee) may be used in making the determination by notification module 355.
In some examples, notification module 355 may provide a notification for the generated stress indicator upon determining that the provided data indicates that the stress is above a predetermined threshold. The notification module 355 may perform the steps described herein to generate notifications, including those described with respect to fig. 4.
In some examples, the classifier, model, and/or module components described with respect to fig. 3 may be updated. However, any updating of the described components need not involve identifying personalized or identifiable data associated with the user. For example, the media classifier may classify videos related to any animal as "animal", whereas after updating, if the video includes dogs, a finer granularity or updated classification, such as "dog", may be obtained. Such updating may be implemented via the joint learning techniques discussed above. In this way, local processing occurring on the personal user device may be made finer granularity or more accurate based on updated models, such as topic modelers, emotions, or media classifiers.
As shown in fig. 3, the process involves obtaining information about health-related parameters or characteristics of the user, as well as information (e.g., video, images) and/or readings (e.g., text) viewed by a device used by the user, such as a device having electronic components discussed with respect to fig. 1. Video and/or image data is received at the media classifier 330, where the video and/or image data is classified according to one or more of the criteria discussed above or other criteria defined by the user or system. The media classifier 330 makes available one or more classification values, e.g., numerical values, determined for output to the vectorization module.
Textual information associated with the image and/or text is provided to emotion classifier 320 and topic modeler 325. In this example, the information to be processed includes text and video/images. However, in other examples, the information may include any type of information. For example, the information read by the user may be a newspaper article without any images or text. Conversely, the information may include images in an online album that would not require processing by emotion classifier 320. Emotion classifier 325 and topic modeler 325 each output a value based on an emotion and topic analysis performed on the text information. These output values may be numerical values, which may be more convenient for vectorization.
The signal post-processing block 335 makes available health related metrics, such as heart rate, heart rate variability, etc., to the vectorization block 340. The output may also include a time value indicating when the health-related metric was captured. The vectorization module 340 may use a timing component to determine which values it receives from the classifier and modeler to include in a given vector. More specifically, when a health-related metric such as heart rate is related to the output of the classifier and modeler in determining the stress source, it is necessary to relate the timing of a given health metric used as a threshold to the time when the user viewed or received the content. As discussed above, the stressor event may be determined relative to the heart rate of the user exceeding a threshold. In some examples, stressor events may be determined based on a combination of signals (e.g., EDA monitoring and HR jitter).
According to one aspect of the disclosed technology, the time that the threshold is exceeded may be used as a vectorized "glue". More specifically, at times when the threshold is exceeded, the output values of the classifiers 320, 335 and modeler 320 are used to create vectors that are further processed in modules 345 and 350 to provide stress source indicators or notifications.
The vectorization module 340 obtains the values generated from the classifiers 320 and 330, the modeler 325, and the post-processing block 335 and derives a vector including values corresponding to times exceeding or meeting a threshold. The vector is then used to query the vector space for information related to, for example, the health metric value of the vector. For example, if a threshold is set based on a heart rate of 90 and heart rate 130 is detected while the user is watching a horror movie, a vector will be created indicating at least heart rate 130, one or more images being associated with the time the heart rate was at 130. This vector can then be used to find other vectors that are close to the vector used in the query. The proximity may be determined based on, for example, a heart rate or value associated with the image, or in some instances, based on the type of image (e.g., based on a user's tag). The proximity may also be determined based on heart rate having a value that approximates the heart rate value in the query.
As shown in fig. 3, after dimension reduction 345 and clustering 350, a notification is provided to the user via notification module 355. Examples of notifications include those shown in the example in fig. 2D, e.g., something is felt to be stressful by you. Other notifications may include an identification of content detected as a possible stressor, statistics related to the content, such as the number of previous instances that the same or related stressor has occurred, heart rate associated with the previous instances, and the like. Further, as shown in FIG. 2D, the user may choose to block similar content.
Fig. 4 illustrates a method 400 associated with aspects of the disclosed technology.
At block 405, information related to the whitelist application may be obtained or extracted. The information may include visual, text, audio, metadata, or other information. This information may be obtained based on user preferences. In some examples, only a subset of the information from the whitelist application may be obtained, such as, for example, only text data, not visual data.
At block 406, health information related to a user of the device using the whitelist application may be obtained. In some examples, this information may be obtained in real time or near real time using block 405. In some examples, health information may be obtained from multiple devices, which may be aggregated to provide more complex analysis.
At block 410, the information obtained at block 405 may be analyzed. In some examples, the modules, techniques, classifiers, or models described with respect to fig. 3 may be used for analysis. In some examples, the information may be analyzed or transformed to output a numerical value related to the obtained or extracted information. This may include, but is not limited to, text analysis, media classification, emotion classification, and topic modeling.
At block 411, the health information obtained at block 406 may be analyzed. The techniques described herein may be used for analyzing the information in block 406 without limitation. In some examples, the health information may be analyzed or transformed to output one or more numerical values related to the obtained health information. Techniques for analyzing health information are provided herein.
At block 420, the information obtained, transformed, or analyzed in blocks 405-411 may be vectorized by a vectorization module, such as vectorization module 340. The vector may be normalized before being processed. In some examples, the vector may be an n-tuple based on n inputs to the vector.
At block 425, dimension reduction may be performed. Dimension reduction may involve techniques that include principal component analysis of a vector space containing vectors related to stress and application data. Principal component analysis is a process or method of determining or calculating principal components within a collection of data points. The principal component of a set of points within a coordinate space or vector space may be a set of orthogonal vectors that form the orthogonal basis of a data set. In some examples, the most relevant or important vectors are kept and the remaining vectors are discarded. For example, the threshold may be set for the amount of variance desired to be represented and captured with the principal component. In this way, principal component analysis can preserve a desired number of principal components to simplify the number of components analyzed and improve computational efficiency while maintaining variation of data within acceptable or predetermined levels. Once determined, the principal component can be used to measure a distance metric between vectors or data points within the vector space. Although the above description is provided using principal component analysis, other dimension reduction techniques may be used to simplify the obtained data or vector.
At block 430, density-based clustering or other clustering techniques may be performed or used to identify clusters or features within the data. Clustering is a method or technique by which clusters can be identified within a dataset. The clusters may be separated from sparse noise surrounding the identified clusters. These clusters may be saved or extracted for classifying future or new data. Any clustering technique may be used within block 430. DBSCAN or defined distance scan is a technique that may use a specified search distance to identify potential clusters. Other variations may include self-adjusting scanning or HDBSCAN techniques. The range may change the search distance to allow the range of distances to be used when separating or identifying clusters of varying density from sparse noise. A multiscale or OPTICS method or algorithm may be used. The OPTICS algorithm uses the distances between neighboring features to determine a reachability graph, which can then be used to separate clusters. The algorithm may be more computationally intensive, but provides flexibility in fine-tuning the clusters. Other clustering techniques may include machine learning based clustering techniques. In some examples, the clustering technique may generate a model that may be queried to classify the obtained data points. In some examples, the obtained data points may be added to the model after the model is classified or analyzed, and the robustness of the model is increased.
At block 435, if the threshold is exceeded, a user recommendation may be made. The obtained vectors may be analyzed in real time or near real time using a proximity method to see if the vectors are close to tightly clustered vectors and meet a threshold that is stress. In other examples, the threshold may be adjusted based on user preferences or parameters. In some examples, the user data may be matched or categorized into the identified clusters (as described, for example, in block 430) to analyze the user data and determine whether it corresponds to a stress event.
Additional steps may be performed in conjunction with method 400 or in lieu of method 400. For example, in some examples, the obtained one or more models may be updated. In some examples, the model may be updated by using a model updated using a joint learning (FL) technique. The FL may protect privacy by updating the model using security coding rather than sensitive data by eliminating the need for specific, individual or sensitive data in training the global model. In this way, joint learning may mitigate privacy risks that may exist in creating machine learning models. Furthermore, joint learning may allow for reduced computational costs in training models. FL techniques may enable training of models on separate devices and periodically providing updates to the model using only global models. The global model may be retrained based on the provided updates.
In some examples, health data from within a predetermined time frame in the future may be analyzed with respect to information from the whitelisted applications. For example, if an individual wakes up a few hours after viewing a particular type of content or using a particular application, the health information may be analyzed relative to the content viewed during, for example, the last 24 or 48 hours.
Example machine learning, statistics, probability, and model creation methods
In some examples, one or more of the following techniques may be used as part of the disclosed techniques.
In some examples, a probabilistic approach may be used. For example, a gaussian mixture model may be used. The gaussian mixture model is a probabilistic model that is used to represent normally distributed sub-populations within the overall population. In a gaussian mixture model, the dataset that does not require observations should characterize or account for which sub-population a particular observation within the distribution belongs to.
Example machine learning techniques that may be used include the following. In some examples, a mixture of supervised and unsupervised learning techniques may be used.
In some examples, generating an countermeasure network may be used to predict or detect network anomalies. The generation of the countermeasure network uses two networks, one of the countermeasure network and one of the generation network, to attempt to spoof the countermeasure network by objects generated by the generation network.
In some examples, the clustering method may be used to cluster inputs, network parameters, trained models, or virtual machines. The clustering method may be used in real-time to classify and match models or groups of models using specific criteria. Clustering may be an unsupervised machine learning technique in which algorithms may define the output. One example clustering method is "K_means," where K represents the number of clusters that a user can select to create. There are various techniques for selecting the value of K, such as, for example, the elbow method.
Some other examples of techniques include dimension reduction. Dimension reduction may be used to remove the amount of information that affects the least or statistically least significant. In networks that generate large amounts of data and where multiple types of data may be observed, dimension reduction may be used in conjunction with any of the techniques described herein. One example dimension reduction method is Principal Component Analysis (PCA). PCA can be used to reduce the dimension or number of variables of "space" by finding new vectors that can maximize the linear variation of the data. PCA allows the amount of information lost to be observed as well, and allows the selection of adjustments in the new vector. Another example technique is t-random neighbor embedding (t-SNE).
An integrated approach may be used that uses mainly the idea of combining several prediction models, which may be supervised ML or unsupervised ML, to obtain a higher quality prediction than each of the models may provide by itself. As one example, a random forest algorithm.
Neural networks and deep learning techniques may also be used for the above techniques. Neural networks typically attempt to replicate the behavior of a biological brain in switching connections between input and output "on" or "off" in an attempt to maximize a selected target.
While this disclosure contains many specific implementation details, these should not be construed as limitations on the scope of what may be claimed, but rather as descriptions of features specific to particular implementations. Certain features described in this specification in the context of separate implementations may also be implemented in combination in a single implementation. Conversely, various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, although operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Reference to "or" may be construed as inclusive such that any term described using "or" may indicate all of the singular, more than one, and all of the terms. The labels "first," "second," "third," etc. are not necessarily meant to indicate ordering and are generally used merely to distinguish between similar or analogous items or elements.
Aspects of the disclosed technology may include any combination of the following features and sub-features:
F1. a method of determining a source of health stress, comprising:
receiving input information, the input information comprising one or more of text information displayed on a user device of a user and image data displayed on the user device;
receiving health information from a wearable device associated with a user at a given time stamp;
associating at least one of the text information and the image data with a given time stamp based on determining that the received health information is at least a threshold;
Associating other text information or other image data with the text information or image data using the model based on the received health information; and is also provided with
A stress indicator is generated based on determining that the other text information and other image data are related to text information and the image data associated with the received health information.
F2. The method of F1, comprising one or more of the following steps:
classifying the text information to produce a first numerical value;
determining a topic category associated with the text information to produce a second value;
classifying the image data to produce a third value; and
forming a first vector comprising the first, second and third values and the received health information, wherein generating the stress indicator is based on the first vector.
F3. The method of any one of F1 and F2, wherein associating comprises searching a vector space having a plurality of vectors using the received health information of the first vector.
F4. The method of any one of F1-F3, wherein classifying the text information comprises classifying the text information using an emotion classifier.
F5. The method of any of claims F1-F4, wherein the output of the emotion classifier is mapped to a value comprising the first value.
F6. The method of any one of F1 to F5, wherein the emotion classifier comprises one of a Support Vector Machine (SVM), a bayesian classifier, or a long-short term memory (LSTM) derived model.
F7. The method of any one of F1 to F6, wherein the image data comprises video or still image data.
F8. The method of any of F1-F7, wherein the image data is viewable by an application on the user device.
F9. The method of any one of F1 to F8, wherein the health information comprises one or more of heart rate, heart rate variability, temperature, stress from EDA activity, user motion, and sleep data.
F10. The method of any one of F1 to F9, wherein the stress indicator comprises a message informing the user of the stress source event.
F11. The method of any one of F1 to F10, further comprising preventing the other text information and/or the other image data from being displayed on the user device based on the stress indicator.
F12. The method of any one of F1 to F11, further comprising: the other text information and/or the other image data is displayed on the user device after approval has been received by the user in response to the block notification to the user.
F13. An apparatus, comprising:
a communication interface;
a display; and
one or more computing devices coupled to one or more memory devices, the one or more memory devices containing instructions that cause the one or more processing devices to:
obtaining input information comprising one or more of text information and image data displayed on a display;
obtaining health information at a given time stamp from a wearable device associated with a user;
associating at least one of the text information and the image data with a given time stamp based on determining that the received health information is at least at a threshold;
associating other text information or other image data to the text information or image data using the model based on the received health information; and
a stress indicator is generated based on determining that the other text information and other image data are related to text information and image data associated with the received health information.
F14. The apparatus of F13, the one or more instructions to cause the one or more processing devices to one or more of:
classifying the text information to produce a first numerical value;
determining a topic category associated with the text information to produce a second value;
classifying the image data to produce a third value; and
a first vector is formed that includes the first, second, and third values and the received health information.
F15. The apparatus of any of F13-F14, wherein the instructions cause the one or more processing devices to correlate by searching a vector space having a plurality of vectors using the received health information of the first vector.
F16. The apparatus of any of F13-F15, wherein the instructions cause the one or more processing devices to classify the text information by classifying the text information using an emotion classifier.
F17. The apparatus of any one of claims F13-F16, wherein an output of the emotion classifier is mapped to a value comprising the first value.
F18. The apparatus of any one of claims F13 to F17, wherein the emotion classifier comprises one of a Support Vector Machine (SVM), a bayesian classifier, or a long-short term memory (LSTM) derived model.
F19. The apparatus of any one of F13 to F18, wherein the image data comprises video or still image data.
F20. The apparatus of any one of F13-F19, wherein the image data is viewable by an application on the apparatus.
F21. The apparatus of any one of F13 to F20, wherein the health information comprises one or more of heart rate, heart rate variability, temperature, stress from EDA activity, user motion, and sleep data.
F22. The apparatus of any one of F13 to F21, wherein the stress indicator comprises a message informing the user of the stress source event.
Various modifications to the implementations described in the disclosure may be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other implementations without departing from the spirit or scope of the disclosure. Thus, the claims are not intended to be limited to the implementations shown herein but are to be accorded the widest scope consistent with the disclosure, principles and novel features disclosed herein.
Claims (22)
1. A method for determining a source of health stress, comprising:
receiving input information, the input information comprising one or more of text information displayed on a user device of a user and image data displayed on the user device;
Receiving health information from a wearable device associated with the user at a given time stamp;
associating at least one of the text information and image data with the given time stamp based on determining that the received health information is at least a threshold;
associating other text information or other image data with the text information or the image data using a model based on the received health information; and
a stress indicator is generated based on determining that the other text information and other image data are associated with text information and image data associated with the received health information.
2. The method of claim 1, comprising one or more of the following steps:
classifying the text information to produce a first numerical value;
determining a topic category associated with the text information to produce a second value;
classifying the image data to produce a third value; and
forming a first vector comprising the first, second and third values and the received health information, wherein generating the stress indicator is based on the first vector.
3. The method of claim 2, wherein associating comprises searching a vector space having a plurality of vectors using the received health information of the first vector.
4. A method according to claim 2 or 3, wherein classifying the text information comprises classifying the text information using an emotion classifier.
5. The method of claim 4, wherein the output of the emotion classifier is mapped to a value comprising the first value.
6. The method of claim 4 or 5, wherein the emotion classifier comprises one of a Support Vector Machine (SVM), a bayesian classifier, or a long-short term memory (LSTM) derived model.
7. A method according to any preceding claim, wherein the image data comprises video or still image data.
8. The method of any preceding claim, wherein the image data is viewable through an application on the user device.
9. The method of any of the preceding claims, wherein the health information comprises one or more of heart rate, heart rate variability, temperature, stress from EDA activity, user motion, and sleep data.
10. The method of any of the preceding claims, wherein the stress indicator comprises a message informing the user of the stress source event.
11. The method of any of the preceding claims, further comprising: the other text information and/or the other image data is prevented from being displayed on the user device based on the stress indicator.
12. The method of any of the preceding claims, further comprising: the other text information and/or the other image data is displayed on the user device after approval has been received by the user in response to the block notification to the user.
13. An apparatus, comprising:
a communication interface;
a display; and
one or more computing devices coupled to one or more memory devices, the one or more memory devices containing instructions that cause the one or more processing devices to:
obtaining input information comprising one or more of text information and image data displayed on the display;
obtaining health information at a given time stamp from a wearable device associated with a user;
Associating at least one of the text information and image data with the given time stamp based on determining that the received health information is at least at a threshold;
associating other text information or other image data to the text information or the image data using a model based on the received health information; and
a stress indicator is generated based on determining that the other text information and other image data are associated with text information and image data associated with the received health information.
14. The apparatus of claim 13, the one or more instructions to cause the one or more processing devices to one or more of:
classifying the text information to produce a first numerical value;
determining a topic category associated with the text information to produce a second value;
classifying the image data to produce a third value; and
a first vector is formed that includes the first, second, and third values and the received health information.
15. The apparatus of claim 14, wherein the instructions cause the one or more processing devices to correlate by searching a vector space having a plurality of vectors using the received health information for the first vector.
16. The apparatus of claim 14 or 15, wherein the instructions cause the one or more processing devices to classify the text information by classifying the text information using an emotion classifier.
17. The apparatus of claim 16, wherein the output of the emotion classifier is mapped to a value comprising the first value.
18. The apparatus of claim 16 or 17, wherein the emotion classifier comprises one of a Support Vector Machine (SVM), a bayesian classifier, or a long-short term memory (LSTM) derived model.
19. The apparatus of any of claims 13 to 18, wherein the image data comprises video or still image data.
20. The apparatus of any of claims 13 to 19, wherein the image data is viewable by an application on the apparatus.
21. The apparatus of any of claims 13 to 20, wherein the health information comprises one or more of heart rate, heart rate variability, temperature, stress from EDA activity, user motion, and sleep data.
22. The apparatus of any of claims 13-21, wherein the stress indicator comprises a message informing the user of the stress source event.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US17/331,077 US20220384034A1 (en) | 2021-05-26 | 2021-05-26 | Active Hidden Stressor Identification and Notification |
US17/331,077 | 2021-05-26 | ||
PCT/US2022/030909 WO2022251350A1 (en) | 2021-05-26 | 2022-05-25 | Active hidden stressor identification and notification |
Publications (1)
Publication Number | Publication Date |
---|---|
CN117355907A true CN117355907A (en) | 2024-01-05 |
Family
ID=82595075
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202280037283.XA Pending CN117355907A (en) | 2021-05-26 | 2022-05-25 | Actively hiding stress source identification and notification |
Country Status (4)
Country | Link |
---|---|
US (1) | US20220384034A1 (en) |
EP (1) | EP4348677A1 (en) |
CN (1) | CN117355907A (en) |
WO (1) | WO2022251350A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN116028617B (en) * | 2022-12-06 | 2024-02-27 | 腾讯科技（深圳）有限公司 | Information recommendation method, apparatus, device, readable storage medium and program product |
-
2021
- 2021-05-26 US US17/331,077 patent/US20220384034A1/en active Pending
-
2022
- 2022-05-25 WO PCT/US2022/030909 patent/WO2022251350A1/en active Application Filing
- 2022-05-25 EP EP22743621.9A patent/EP4348677A1/en active Pending
- 2022-05-25 CN CN202280037283.XA patent/CN117355907A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2022251350A1 (en) | 2022-12-01 |
EP4348677A1 (en) | 2024-04-10 |
US20220384034A1 (en) | 2022-12-01 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9104969B1 (en) | Utilizing semantic analysis to determine how to process measurements of affective response | |
US9955902B2 (en) | Notifying a user about a cause of emotional imbalance | |
US20170095192A1 (en) | Mental state analysis using web servers | |
DE102015113924A1 (en) | Ranking based on affective response of the crowd | |
US10143414B2 (en) | Sporadic collection with mobile affect data | |
Mirchevska et al. | Combining domain knowledge and machine learning for robust fall detection | |
US11430561B2 (en) | Remote computing analysis for cognitive state data metrics | |
US20190261863A1 (en) | System and method for providing an indication of the well-being of an individual | |
CN109285606A (en) | A kind of health control method and system based on big data intelligent algorithm | |
US20170105668A1 (en) | Image analysis for data collected from a remote computing device | |
US20150213012A1 (en) | Document searching using salience | |
Palaghias et al. | A survey on mobile social signal processing | |
WO2023112384A1 (en) | Computer system and emotion estimation method | |
Zhang et al. | Multi-modal interactive fusion method for detecting teenagers’ psychological stress | |
Vildjiounaite et al. | Unsupervised stress detection algorithm and experiments with real life data | |
CN117355907A (en) | Actively hiding stress source identification and notification | |
EP3917400A1 (en) | Mental state determination method and system | |
US20220409134A1 (en) | Using an In-Ear Microphone Within an Earphone as a Fitness and Health Tracker | |
CN113168596A (en) | Behavior recommendation method and device, storage medium and electronic equipment | |
WO2022268492A1 (en) | Patient context detection |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |