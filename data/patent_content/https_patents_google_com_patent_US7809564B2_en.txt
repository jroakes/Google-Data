US7809564B2 - Voice based keyword search algorithm - Google Patents
Voice based keyword search algorithm Download PDFInfo
- Publication number
- US7809564B2 US7809564B2 US11/612,060 US61206006A US7809564B2 US 7809564 B2 US7809564 B2 US 7809564B2 US 61206006 A US61206006 A US 61206006A US 7809564 B2 US7809564 B2 US 7809564B2
- Authority
- US
- United States
- Prior art keywords
- list
- candidates
- keywords
- keyword
- indexed search
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
Definitions
- the present invention relates generally to an improved voice based keyword search system, and in particular to a search algorithm that uses confidence levels of keywords spoken by a caller to identify keyword indexed search items which best match the spoken keywords.
- a search engine is an information retrieval system designed to locate information stored on a computer system.
- the search engine searches and returns to the user a list of items that the search engine determines to be most relevant to the criteria or keywords entered by the user. This list is often sorted with respect to some measure of relevance of the results.
- Different search engines use different methods of determining the relevance of web sites, but most use some sort of quantitative method that determines the relevance of a site based on how many times the keywords appear in that particular site.
- Speech recognition devices are generally known in the art of voice technologies. With speech recognition devices, a caller speaks into a microphone or telephone, and the speech recognition device receives the speech utterance and recognizes the words and phrases spoken by the caller. The speech recognition device may recognize the words or phrases spoken by the caller based on statistical features of the speech utterance as matching to known speech features of words in a vocabulary (e.g., represented in the grammar). A speech feature is normally represented as a feature vector which is a pure mathematical representation as mapped from the utterance waveform. Human speech is truly statistical in nature in that when a person says the same word several times, the waveform of the utterance will not be identical.
- the waveform should be similar, which results in speech feature vectors close to a vector representing the word in the speech feature vector.
- a speech recognition device may identify the word or phrase which was most likely spoken by the caller, the statistical nature of speech recognition may also produce false results. This is due to the fact that the speech feature vectors are not identical every time, and thus there is a possibility the speech feature vector may be closer to another word feature vector, which is a cause for the misrecognition.
- the likely word or phrase identified by the speech recognition engine using statistics may not be the word or phrase actually spoken by the caller. For example, if a caller said the word “Boston”, the speech recognition engine may recognize it as “Austin”, since both words are acoustically close in speech features.
- the illustrative embodiments provide a computer implemented method, data processing system, and computer program product for utilizing recognition confidence levels of keywords spoken by a caller to accommodate the statistical variations of human speech in identifying the keyword indexed search items which best match the spoken keywords in a statistical way.
- keywords are identified in the spoken search request.
- a list of candidates is created comprising a match to at least one of the keywords, wherein each candidate in the list is assigned a level of confidence in the match.
- Keyword indexed search items having at least one of the keywords as an index and an original matching score are then located.
- the original matching score of each keyword indexed search item is weighted with the level of confidence in the list of candidates to form weighted matching scores.
- the keyword indexed search items are sorted based on weighted matching score.
- a list of the sorted keyword indexed search items is then created.
- FIG. 1 depicts a pictorial representation of a distributed data processing system in which the illustrative embodiments may be implemented
- FIG. 2 is a block diagram of a data processing system in which the illustrative embodiments may be implemented
- FIG. 3 is a block diagram of exemplary components with which the illustrative embodiments may be implemented.
- FIGS. 4A and 4B illustrate a flowchart describing a search algorithm for matching keywords spoken by a caller to keyword indexed search items in accordance with the illustrative embodiments.
- FIGS. 1-2 exemplary diagrams of data processing environments are provided in which illustrative embodiments may be implemented. It should be appreciated that FIGS. 1-2 are only exemplary and are not intended to assert or imply any limitation with regard to the environments in which different embodiments may be implemented. Many modifications to the depicted environments may be made.
- FIG. 1 depicts a pictorial representation of a network of data processing systems in which illustrative embodiments may be implemented.
- Network data processing system 100 is a network of computers in which embodiments may be implemented.
- Network data processing system 100 contains network 102 , which is the medium used to provide communications links between various devices and computers connected together within network data processing system 100 .
- Network 102 may include connections, such as wire, wireless communication links, or fiber optic cables.
- server 104 and server 106 connect to network 102 along with storage unit 108 .
- clients 110 , 112 , and 114 connect to network 102 .
- These clients 110 , 112 , and 114 may be, for example, personal computers, network computers, or telephone devices.
- server 104 provides data, such as boot files, operating system images, and applications to clients 110 , 112 , and 114 .
- Clients 110 , 112 , and 114 are clients to server 104 in this example.
- Network data processing system 100 may include additional servers, clients, and other devices not shown.
- network data processing system 100 is the Internet with network 102 representing a worldwide collection of networks and gateways that use the Transmission Control Protocol/Internet Protocol (TCP/IP) suite of protocols to communicate with one another.
- TCP/IP Transmission Control Protocol/Internet Protocol
- At the heart of the Internet is a backbone of high-speed data communication lines between major nodes or host computers, consisting of thousands of commercial, governmental, educational and other computer systems that route data and messages.
- network data processing system 100 also may be implemented as a number of different types of networks, such as for example, an intranet, a local area network (LAN), or a wide area network (WAN).
- FIG. 1 is intended as an example, and not as an architectural limitation for different embodiments.
- Data processing system 200 is an example of a computer, such as server 104 or client 110 in FIG. 1 , in which computer usable code or instructions implementing the processes may be located for the illustrative embodiments.
- data processing system 200 employs a hub architecture including a north bridge and memory controller hub (MCH) 202 and a south bridge and input/output (I/O) controller hub (ICH) 204 .
- MCH north bridge and memory controller hub
- I/O input/output
- main memory 208 main memory 208
- graphics processor 210 are coupled to north bridge and memory controller hub 202 .
- Processing unit 206 may contain one or more processors and even may be implemented using one or more heterogeneous processor systems.
- Graphics processor 210 may be coupled to the MCH through an accelerated graphics port (AGP), for example.
- AGP accelerated graphics port
- local area network (LAN) adapter 212 is coupled to south bridge and I/O controller hub 204 and audio adapter 216 , keyboard and mouse adapter 220 , modem 222 , read only memory (ROM) 224 , universal serial bus (USB) ports and other communications ports 232 , and PCI/PCIe devices 234 are coupled to south bridge and I/O controller hub 204 through bus 238 , and hard disk drive (HDD) 226 and CD-ROM drive 230 are coupled to south bridge and I/O controller hub 204 through bus 240 .
- PCI/PCIe devices may include, for example, Ethernet adapters, add-in cards, and PC cards for notebook computers. PCI uses a card bus controller, while PCIe does not.
- ROM 224 may be, for example, a flash binary input/output system (BIOS).
- Hard disk drive 226 and CD-ROM drive 230 may use, for example, an integrated drive electronics (IDE) or serial advanced technology attachment (SATA) interface.
- IDE integrated drive electronics
- SATA serial advanced technology attachment
- a super I/O (SIO) device 236 may be coupled to south bridge and I/O controller hub 204 .
- An operating system runs on processing unit 206 and coordinates and provides control of various components within data processing system 200 in FIG. 2 .
- the operating system may be a commercially available operating system such as Microsoft® Windows® XP (Microsoft and Windows are trademarks of Microsoft Corporation in the United States, other countries, or both).
- An object oriented programming system such as the JavaTM programming system, may run in conjunction with the operating system and provides calls to the operating system from Java programs or applications executing on data processing system 200 .
- Java and all Java-based trademarks are trademarks of Sun Microsystems, Inc. in the United States, other countries, or both.
- Instructions for the operating system, the object-oriented programming system, and applications or programs are located on storage devices, such as hard disk drive 226 , and may be loaded into main memory 208 for execution by processing unit 206 .
- the processes of the illustrative embodiments may be performed by processing unit 206 using computer implemented instructions, which may be located in a memory such as, for example, main memory 208 , read only memory 224 , or in one or more peripheral devices.
- FIGS. 1-2 may vary depending on the implementation.
- Other internal hardware or peripheral devices such as flash memory, equivalent non-volatile memory, or optical disk drives and the like, may be used in addition to or in place of the hardware depicted in FIGS. 1-2 .
- the processes of the illustrative embodiments may be applied to a multiprocessor data processing system.
- data processing system 200 may be a personal digital assistant (PDA), which is generally configured with flash memory to provide non-volatile memory for storing operating system files and/or user-generated data.
- PDA personal digital assistant
- a bus system may be comprised of one or more buses, such as a system bus, an I/O bus and a PCI bus. Of course the bus system may be implemented using any type of communications fabric or architecture that provides for a transfer of data between different components or devices attached to the fabric or architecture.
- a communications unit may include one or more devices used to transmit and receive data, such as a modem or a network adapter.
- a memory may be, for example, main memory 208 or a cache such as found in north bridge and memory controller hub 202 .
- a processing unit may include one or more processors or CPUs.
- processors or CPUs may include one or more processors or CPUs.
- FIGS. 1-2 and above-described examples are not meant to imply architectural limitations.
- data processing system 200 also may be a tablet computer, laptop computer, or telephone device in addition to taking the form of a PDA.
- the illustrative embodiments provide a search algorithm for voice based keyword searches.
- the search algorithm in the illustrative embodiments utilizes recognition confidence levels of keywords spoken by a caller to accommodate the statistical variations of human speech in identifying the keyword indexed search items which best match the spoken keywords in a statistical way.
- a speech recognition engine is provided which receives a spoken utterance from a caller. The speech recognition engine identifies keywords in the spoken utterance and creates a list of candidates comprising possible matches to the spoken keywords. It should be noted that the illustrative embodiments may employ any known speech recognition technique which allows for recognizing textual candidates to spoken keywords and confidence levels associated with the recognition process.
- a search engine is also provided in the illustrative embodiments which receives the list of candidates and employs the search algorithm to match the candidates to keyword indexed search items in a database.
- the search algorithm employed by the search engine uses overall confidence levels assigned to each candidate by the speech recognition engine, as well as individual confidence levels assigned to each keyword in multiple keyword candidates, to weight existing matching scores obtained using traditional search algorithms, and thus determine which keyword indexed search items best match the keywords spoken by the caller. For example, if a caller says “Boston”, the speech recognition engine may generate a candidate list with the word “Austin” having a confidence level of 0.9 and the word “Boston” with a confidence level of 0.8.
- the search algorithm in the illustrative embodiments allows for using both words “Austin” and “Boston” in the search, thereby allowing “Boston” related search items to also be returned.
- the search algorithm in the illustrative embodiments provides an improved search accuracy for voice based keyword searches by accommodating the statistic nature of human speech to enhance the search accuracy.
- FIG. 3 is a block diagram of exemplary components with which the illustrative embodiments may be implemented.
- Search system 300 may be implemented in network data processing system 100 in FIG. 1 .
- search system 300 comprises caller device 302 , speech recognition engine 304 , search engine 306 , and database 308 .
- Caller device 302 may be any type of mechanism capable of sending and receiving communication signals between speech recognition engine 304 and search engine 306 , by way of a wired or wireless communication connection.
- Caller device 302 may be, for example, a conventional land-line telephone, a cellular telephone, an Internet based telephone device, a computer having a microphone or other audio input device, and the like.
- An example of caller device 302 may include client devices 110 , 112 , or 114 in FIG. 1 .
- Speech recognition engine 304 and search engine 306 may be implemented in a data processing system, such as data processing system 200 in FIG. 2 , as well as within one or more servers, such as servers 104 and 106 in FIG. 1 . In an alternative embodiment, speech recognition engine 304 or search engine 306 may be implemented in the same device as caller device 302 .
- Caller device 302 receives a spoken utterance from a user and transmits a spoken utterance waveform 310 to speech recognition engine 304 .
- speech recognition engine 304 Upon receiving spoken utterance waveform 310 , speech recognition engine 304 performs speech recognition on the utterance against a vocabulary of keywords.
- a keyword is defined in the search system as the key to the meaning of the search items.
- Speech recognition engine 304 uses all of the possible keywords defined in the search system as its vocabulary. If spoken utterance waveform 310 contains a keyword, speech recognition engine 304 then identifies candidates which may be a text match for the spoken keyword. Speech recognition engine 304 may identify candidates for the spoken keyword by analyzing speech utterance waveform 310 and extracting the feature vectors.
- the spoken feature vectors are then compared with the feature vectors saved in the vocabulary to identify possible candidates for the spoken keyword. For instance, if the caller says the word “Boston”, speech recognition engine 304 creates candidate list 312 comprising possible text candidates matching the spoken keyword “Boston”, which may include, for example, “Boston” and “Austin”, among others. This entire identification process is a statistical process. Each spoken word should have only one corresponding feature vector in the feature vector space. If the spoken feature vector is closer to a particular vocabulary word feature vector, then that vocabulary word is more likely to be identified as a candidate.
- speech recognition engine 304 In addition to creating candidate list 312 , speech recognition engine 304 also assigns an overall confidence level to each identified candidate. A confidence level represents the probability measure that the candidate identified by speech recognition engine 304 matches the keywords spoken by the caller. In other words, the confidence level indicates how well each candidate matches the spoken keywords. If a candidate in candidate list 312 contains more than one keyword, speech recognition engine 304 may also assign a confidence level to each individual keyword in the candidate. Speech recognition engine 304 then provides candidate list 312 comprising one or more candidates which are matches to the keywords recognized within spoken utterance waveform 310 and their confidence levels to search engine 306 .
- search engine 306 Upon receiving candidate list 312 with the confidence levels from speech recognition engine 304 , search engine 306 uses search algorithm 314 to identify those keyword indexed search items in database 308 which provide the closest match to the spoken keywords. If there is only one candidate in candidate list 312 and that candidate contains only one keyword, the search engine identifies the search items which have that keyword as the index in database 308 . The search engine then returns the list of identified search items 316 to caller device 302 .
- the search algorithm executes multiple keyword match algorithm 318 .
- Multiple keyword match algorithm 318 obtains all of the search items from an index of database 308 which match at least one of the keywords in the candidate, and also obtains the original matching score for each search item.
- the original matching score is the matching score calculated using a traditional search algorithm and may be obtained from the keyword index.
- Multiple keyword match algorithm 318 then calculates a weighted matching score for each search item, wherein the weighted matching score comprises taking the original matching score from the traditional search algorithm and weighting the original matching score by the sum of all of the individual confidence levels of each of the keywords in the candidate appeared in the search item.
- the existing matching score may be weighted by multiplying the existing matching score by the sum of the confidence levels. In this manner, if the confidence level is low (i.e., a not-so-confident match), the weighted matching score would be lowered to reflect the low confidence level.
- Multiple keyword match algorithm 318 sorts the search items based on the weighted matching scores. In one embodiment, the search items are placed in order from highest matching score to lowest weighted matching score. Search engine 306 then returns the list of identified search items 316 to caller device 302 , where the search items 316 are ordered from highest to lowest weighted matching score.
- speech recognition engine 304 sorts the candidates in candidate list 312 from highest confidence level to lowest confidence level prior to providing candidate list to search engine 306 .
- search engine 306 receives candidate list 312 comprising more than one candidate, if the overall confidence level of the first candidate in candidate list 312 is substantially higher than the second candidate in candidate list 312 , search engine 306 processes the first candidate as if there is only one candidate in candidate list 312 , as previously described. However, if the overall confidence level of the first candidate is not substantially higher than the second candidate, search engine 306 initializes an empty search item reservoir.
- the reservoir may be any place in which to hold search items while remaining candidates in the multiple candidate list are being processed.
- search engine 306 identifies the first few candidates in candidate list 312 whose overall confidence levels are significantly higher than the remaining candidates in candidate list 312 . If a candidate contains only one keyword, search engine 306 creates a list of search items having the keyword as the index. Each of the search items has an original matching score which is weighted by the overall confidence level of the candidate (e.g., by multiplying the original matching score by the confidence level), and the list of search items is added to a reservoir. Search engine 306 processes the remaining first few candidates identified with high overall confidence levels in the same manner if the candidates have only one keyword.
- search engine 306 executes multiple keyword match algorithm 318 .
- multiple keyword match algorithm 318 weights the original matching score with the sum of the confidence levels of each keywords in the candidate as appeared in the search item.
- the search items are sorted from highest weighted matching score to lowest weighted matching score and added to the reservoir.
- all of the search items in the reservoir are sorted from highest weighted matching score to lowest weighted matching score.
- Search engine 306 then returns the list of identified search items 316 to caller device 302 , where the search items 316 are ordered from highest to lowest weighted matching score.
- FIGS. 4A and 4B illustrate a flowchart describing a search algorithm for matching keywords spoken by a caller to keyword indexed search items in accordance with the illustrative embodiments.
- the keyword search process in FIGS. 4A and 4B is implemented when a search request in the form of a spoken utterance from a caller is received at the speech recognition engine 304 in FIG. 3 .
- the speech recognition engine receives the spoken utterance from a caller
- the speech recognition engine identifies keywords within the spoken utterance and returns a list of candidates matching the identified keywords and the candidates' confidence levels to a search engine, such as search engine 306 in FIG. 3 (step 402 ).
- the candidate list comprises multiple candidates, the candidates may be ranked in the candidate list based on the confidence level of each candidate.
- the candidates in the candidate list may be ranked from highest confidence level to lowest confidence level.
- the search engine employs a search algorithm which first makes a determination as to whether the candidate list contains only one candidate (step 404 ). If the candidate list contains only one candidate (‘yes’ output of step 404 ), the search algorithm determines if the candidate contains only one keyword (step 406 ). If the candidate contains only one keyword (‘yes’ output of step 406 ), the search engine returns a result list of search items which have the keyword as the index to the requesting caller (step 408 ), with the process terminating thereafter.
- the search algorithm executes a multiple keyword match algorithm for the multiple keywords in the candidate.
- the multiple keyword match algorithm first obtains all search items from an index of a database which match at least one of the keywords in the candidate and obtains the original matching score for each search item (step 410 ).
- the multiple keyword match algorithm then weights the original matching score for each search item with the sum of the individual confidence levels of each keyword in the candidate (step 412 ).
- the multiple keyword match algorithm sorts the search items obtained based on the weighted matching scores, such as from highest weighted matching score to lowest weighted matching score (step 414 ).
- the search engine then returns a result list of the sorted search items which have the keyword as the index to the requesting caller (step 416 ), with the process terminating thereafter.
- the candidates may be sorted from highest confidence level to lowest confidence level.
- the search algorithm determines whether the overall confidence level of the first candidate in the candidate list is substantially higher than the second candidate in the candidate list (step 418 ). If the overall confidence level of the first candidate is substantially higher than the second candidate (‘yes’ output of step 418 ), the search algorithm takes the first candidate (step 420 ) and continues to step 406 to process the first candidate.
- the search algorithm identifies the first few candidates in the candidate list whose overall confidence levels are significantly higher than the remaining candidates in the candidate list (step 422 ).
- the search algorithm takes the first candidate of the identified candidates (step 424 ) and then determines if the candidate contains only one keyword (step 426 ). If the first candidate only contains one keyword (‘yes’ output of step 426 ), the search algorithm creates a list of search items which have the keyword as the index, and the original matching score of each of the search items is weighted by the overall confidence level of the candidate (step 428 ).
- the list of search items created is then added to a reservoir (step 430 ).
- the search algorithm determines if there are any more of the candidates identified as significantly higher than the remaining candidates in the candidate list left to process (step 432 ). If there are more identified candidates to process (‘yes’ output of step 432 ), the search algorithm takes the next candidate (step 434 ) and continues to step 426 to process the candidate. If there are no more identified candidates to process (‘no’ output of step 432 ), the search algorithm sorts the search items in the reservoir by weighted matching score from highest weighted matching score to lowest matching score, and returns the list to the caller (step 436 ), with the process terminating thereafter.
- the search algorithm executes the multiple keyword match algorithm for the multiple keywords in the candidate.
- the multiple keyword match algorithm first obtains all search items from an index of a database which match at least one of the keywords in the candidate (step 438 ).
- the multiple keyword match algorithm then weights the original matching score for each search item with the sum of the individual confidence levels of each keyword in the candidate (step 440 ).
- the multiple keyword match algorithm then sorts the search items obtained based on the weighted matching scores, such as from highest weighted matching score to lowest matching score (step 442 ).
- the search algorithm then creates a result list of the sorted search items with the weighted matching scores (step 444 ).
- the process then continues to step 430 where the list of search items is added to the reservoir.
- the invention can take the form of an entirely hardware embodiment, an entirely software embodiment or an embodiment containing both hardware and software elements.
- the invention is implemented in software, which includes but is not limited to firmware, resident software, microcode, etc.
- the invention can take the form of a computer program product accessible from a computer-usable or computer-readable medium providing program code for use by or in connection with a computer or any instruction execution system.
- a computer-usable or computer-readable medium can be any tangible apparatus that can contain, store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device.
- the medium can be an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system (or apparatus or device) or a propagation medium.
- Examples of a computer-readable medium include a semiconductor or solid state memory, magnetic tape, a removable computer diskette, a random access memory (RAM), a read-only memory (ROM), a rigid magnetic disk and an optical disk.
- Current examples of optical disks include compact disk-read only memory (CD-ROM), compact disk-read/write (CD-R/W) and DVD.
- a data processing system suitable for storing and/or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus.
- the memory elements can include local memory employed during actual execution of the program code, bulk storage, and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.
- I/O devices including but not limited to keyboards, displays, pointing devices, etc.
- I/O controllers can be coupled to the system either directly or through intervening I/O controllers.
- Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks.
- Modems, cable modem and Ethernet cards are just a few of the currently available types of network adapters.
Abstract
Description
Claims (19)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/612,060 US7809564B2 (en) | 2006-12-18 | 2006-12-18 | Voice based keyword search algorithm |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/612,060 US7809564B2 (en) | 2006-12-18 | 2006-12-18 | Voice based keyword search algorithm |
Publications (2)
Publication Number | Publication Date |
---|---|
US20080147399A1 US20080147399A1 (en) | 2008-06-19 |
US7809564B2 true US7809564B2 (en) | 2010-10-05 |
Family
ID=39528607
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US11/612,060 Active 2029-08-04 US7809564B2 (en) | 2006-12-18 | 2006-12-18 | Voice based keyword search algorithm |
Country Status (1)
Country | Link |
---|---|
US (1) | US7809564B2 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8660847B2 (en) | 2011-09-02 | 2014-02-25 | Microsoft Corporation | Integrated local and cloud based speech recognition |
US20170032783A1 (en) * | 2015-04-01 | 2017-02-02 | Elwha Llc | Hierarchical Networked Command Recognition |
Families Citing this family (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8725492B2 (en) * | 2008-03-05 | 2014-05-13 | Microsoft Corporation | Recognizing multiple semantic items from single utterance |
US8386251B2 (en) * | 2009-06-08 | 2013-02-26 | Microsoft Corporation | Progressive application of knowledge sources in multistage speech recognition |
US10019983B2 (en) * | 2012-08-30 | 2018-07-10 | Aravind Ganapathiraju | Method and system for predicting speech recognition performance using accuracy scores |
US9672827B1 (en) * | 2013-02-11 | 2017-06-06 | Mindmeld, Inc. | Real-time conversation model generation |
US9747899B2 (en) * | 2013-06-27 | 2017-08-29 | Amazon Technologies, Inc. | Detecting self-generated wake expressions |
US10095785B2 (en) * | 2013-09-30 | 2018-10-09 | Sonos, Inc. | Audio content search in a media playback system |
CN103559881B (en) * | 2013-11-08 | 2016-08-31 | 科大讯飞股份有限公司 | Keyword recognition method that languages are unrelated and system |
JP6690484B2 (en) * | 2016-09-15 | 2020-04-28 | 富士通株式会社 | Computer program for voice recognition, voice recognition device and voice recognition method |
US11776046B1 (en) | 2018-01-25 | 2023-10-03 | United Services Automobile Association (Usaa) | Cross-device presentation with conversational user interface |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4928302A (en) | 1987-11-06 | 1990-05-22 | Ricoh Company, Ltd. | Voice actuated dialing apparatus |
US6397179B2 (en) | 1997-12-24 | 2002-05-28 | Nortel Networks Limited | Search optimization system and method for continuous speech recognition |
US6499013B1 (en) | 1998-09-09 | 2002-12-24 | One Voice Technologies, Inc. | Interactive user interface using speech recognition and natural language processing |
US20030078781A1 (en) * | 2001-10-24 | 2003-04-24 | Julia Luc E. | System and method for speech activated navigation |
US6571210B2 (en) * | 1998-11-13 | 2003-05-27 | Microsoft Corporation | Confidence measure system using a near-miss pattern |
US6862713B1 (en) | 1999-08-31 | 2005-03-01 | International Business Machines Corporation | Interactive process for recognition and evaluation of a partial search query and display of interactive results |
US20070043868A1 (en) * | 2005-07-07 | 2007-02-22 | V-Enable, Inc. | System and method for searching for network-based content in a multi-modal system using spoken keywords |
-
2006
- 2006-12-18 US US11/612,060 patent/US7809564B2/en active Active
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4928302A (en) | 1987-11-06 | 1990-05-22 | Ricoh Company, Ltd. | Voice actuated dialing apparatus |
US6397179B2 (en) | 1997-12-24 | 2002-05-28 | Nortel Networks Limited | Search optimization system and method for continuous speech recognition |
US6499013B1 (en) | 1998-09-09 | 2002-12-24 | One Voice Technologies, Inc. | Interactive user interface using speech recognition and natural language processing |
US6571210B2 (en) * | 1998-11-13 | 2003-05-27 | Microsoft Corporation | Confidence measure system using a near-miss pattern |
US6862713B1 (en) | 1999-08-31 | 2005-03-01 | International Business Machines Corporation | Interactive process for recognition and evaluation of a partial search query and display of interactive results |
US20030078781A1 (en) * | 2001-10-24 | 2003-04-24 | Julia Luc E. | System and method for speech activated navigation |
US20070043868A1 (en) * | 2005-07-07 | 2007-02-22 | V-Enable, Inc. | System and method for searching for network-based content in a multi-modal system using spoken keywords |
Non-Patent Citations (2)
Title |
---|
Gu et al., "Spoken Query for Web Search and Navigation", pp. 1-5, retrieved Oct. 20, 2006 http://www10.org/cdrom/posters/p1010/index.htm. |
Murray, "RPP#7 Spoken Word Search Engines and Educational Podcast Promos", retrieved Oct. 20, 2006 http:jdc.jefferson.edu/rpp/8/. |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8660847B2 (en) | 2011-09-02 | 2014-02-25 | Microsoft Corporation | Integrated local and cloud based speech recognition |
US20170032783A1 (en) * | 2015-04-01 | 2017-02-02 | Elwha Llc | Hierarchical Networked Command Recognition |
Also Published As
Publication number | Publication date |
---|---|
US20080147399A1 (en) | 2008-06-19 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US7809564B2 (en) | Voice based keyword search algorithm | |
CN111160017B (en) | Keyword extraction method, phonetics scoring method and phonetics recommendation method | |
US10297252B2 (en) | Predicting and learning carrier phrases for speech input | |
JP4664423B2 (en) | How to find relevant information | |
US7742922B2 (en) | Speech interface for search engines | |
US8650031B1 (en) | Accuracy improvement of spoken queries transcription using co-occurrence information | |
WO2018157789A1 (en) | Speech recognition method, computer, storage medium, and electronic apparatus | |
JP5241379B2 (en) | Method and system for optimal selection strategy for statistical classification in dialogue systems | |
US8024188B2 (en) | Method and system of optimal selection strategy for statistical classifications | |
CN109299228B (en) | Computer-implemented text risk prediction method and device | |
US10242670B2 (en) | Syntactic re-ranking of potential transcriptions during automatic speech recognition | |
WO2016196320A1 (en) | Language modeling for speech recognition leveraging knowledge graph | |
WO2021169423A1 (en) | Quality test method, apparatus and device for customer service recording, and storage medium | |
US20230072171A1 (en) | System and method for training and refining machine learning models | |
WO2020233381A1 (en) | Speech recognition-based service request method and apparatus, and computer device | |
US11625630B2 (en) | Identifying intent in dialog data through variant assessment | |
CN111460117B (en) | Method and device for generating intent corpus of conversation robot, medium and electronic equipment | |
CN114742062B (en) | Text keyword extraction processing method and system | |
CN111858966B (en) | Knowledge graph updating method and device, terminal equipment and readable storage medium | |
US11379669B2 (en) | Identifying ambiguity in semantic resources | |
JP2004053745A (en) | Method, apparatus, and program for language model generation | |
JPH1173419A (en) | Method and device for retrieving electronic document | |
KR20240034572A (en) | Method for evaluating performance of speech recognition model and apparatus thereof | |
CN114547474A (en) | Data searching method, system, electronic equipment and storage medium | |
CN114637818A (en) | Keyword determination method and device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: INTERNATIONAL BUSINESS MACHINES CORPORATION, NEW YFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:JAISWAL, PEEYUSH;NARAYAN, NAVEEN;WANG, FANG;REEL/FRAME:018648/0353Effective date: 20061214 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTERNATIONAL BUSINESS MACHINES CORPORATION;REEL/FRAME:027463/0594Effective date: 20111228 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0405Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552)Year of fee payment: 8 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |