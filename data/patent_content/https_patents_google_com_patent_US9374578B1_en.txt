US9374578B1 - Video coding using combined inter and intra predictors - Google Patents
Video coding using combined inter and intra predictors Download PDFInfo
- Publication number
- US9374578B1 US9374578B1 US13/900,592 US201313900592A US9374578B1 US 9374578 B1 US9374578 B1 US 9374578B1 US 201313900592 A US201313900592 A US 201313900592A US 9374578 B1 US9374578 B1 US 9374578B1
- Authority
- US
- United States
- Prior art keywords
- block
- prediction block
- intra prediction
- pixel
- prediction
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 238000000034 method Methods 0.000 claims description 55
- 230000015654 memory Effects 0.000 claims description 31
- 239000013598 vector Substances 0.000 claims description 12
- 230000007423 decrease Effects 0.000 claims 1
- 230000006835 compression Effects 0.000 abstract description 6
- 238000007906 compression Methods 0.000 abstract description 6
- 230000002093 peripheral effect Effects 0.000 description 34
- 230000008569 process Effects 0.000 description 25
- 238000010586 diagram Methods 0.000 description 18
- 230000006870 function Effects 0.000 description 15
- 239000011159 matrix material Substances 0.000 description 14
- 230000000644 propagated effect Effects 0.000 description 12
- 238000004891 communication Methods 0.000 description 10
- 238000001914 filtration Methods 0.000 description 8
- 238000012545 processing Methods 0.000 description 8
- 208000037170 Delayed Emergence from Anesthesia Diseases 0.000 description 6
- 230000003068 static effect Effects 0.000 description 5
- 230000005540 biological transmission Effects 0.000 description 4
- 238000013139 quantization Methods 0.000 description 4
- 230000015572 biosynthetic process Effects 0.000 description 3
- 230000000903 blocking effect Effects 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000008901 benefit Effects 0.000 description 2
- 238000004590 computer program Methods 0.000 description 2
- 230000006837 decompression Effects 0.000 description 2
- 238000013461 design Methods 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 239000003086 colorant Substances 0.000 description 1
- 230000008867 communication pathway Effects 0.000 description 1
- 238000000354 decomposition reaction Methods 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000010845 search algorithm Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
- 230000001131 transforming effect Effects 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
- 239000011800 void material Substances 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/157—Assigned coding mode, i.e. the coding mode being predefined or preselected to be further used for selection of another element or parameter
-
- H04N19/00569—
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/105—Selection of the reference unit for prediction within a chosen coding or prediction mode, e.g. adaptive choice of position and number of pixels used for prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/167—Position within a video image, e.g. region of interest [ROI]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/182—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being a pixel
Definitions
- Digital video streams typically represent video using a sequence of frames or still images. Each frame can include a number of blocks, which in turn may contain information describing the value of color, brightness or other attributes for pixels.
- the amount of data in a typical video stream is large, and transmission and storage of video can use significant computing or communications resources.
- Various approaches have been proposed to reduce the amount of data in video streams, including compression and other encoding techniques.
- Real-time video streaming, multi-point video conferencing or video broadcasting are examples of applications that employ video stream encoding including compression.
- This disclosure relates in general to encoding and decoding visual data, such as video stream data, for transmission or storage.
- Disclosed herein are aspects of systems, methods and apparatuses for encoding and decoding video frames (e.g., forming a video stream).
- One method described includes identifying an inter prediction block for a first block of a video frame, identifying an intra prediction block for the first block based on an intra prediction mode for the first block, forming a combined prediction block for the first block by combining weighted pixel values of the inter prediction block and weighted pixel values of the intra prediction block, wherein a weighting of each pixel value is based on the intra prediction mode, and encoding the first block using the combined prediction block.
- Another method described herein includes identifying a first block of a video frame predicted using a combined prediction mode by reading bits in a header of the video stream, identifying the intra prediction mode associated with the combined prediction mode, generating an intra prediction block using the intra prediction mode, forming a combined prediction block for the first block by combining weighted pixel values of the inter prediction block and weighted pixel values of the intra prediction block, wherein a weighting of each pixel value is based on the intra prediction mode, and reconstructing the first block using the combined prediction block.
- An apparatus described herein includes a memory and a processor.
- the processor is configured to execute instructions stored in the memory to identify an inter prediction block for a first block of a video frame, identify an intra prediction block for the first block based on an intra prediction mode for the first block, form a combined prediction block for the first block by combining weighted pixel values of the inter prediction block and weighted pixel values of the intra prediction block, wherein a weighting of each pixel value is based on the intra prediction mode, and encode the first block using the combined prediction block.
- FIG. 1 is a schematic of a video encoding and decoding system
- FIG. 2 is a block diagram of an exemplary computing device that can implement a transmitting station or a receiving station;
- FIG. 3 is a diagram of a typical video stream to be encoded and subsequently decoded
- FIG. 4 is a block diagram of a video compression system in according to an aspect of the teachings herein;
- FIG. 5 is a block diagram of a video decompression system in according to an aspect of the teachings herein;
- FIG. 6 is a flowchart diagram of a process for predicting a block using combined intra and inter prediction blocks according to an aspect of the teachings herein;
- FIG. 7 is a flowchart diagram of a process for combining inter and intra prediction blocks according to an aspect of the teachings herein;
- FIG. 8 is a diagram of a 4 ⁇ 4 block used to illustrate adjacent pixels used in the formation of an intra prediction block
- FIGS. 9A-9H are diagrams showing examples of intra prediction modes for the block of FIG. 8 ;
- FIG. 10 is a flowchart diagram of a process for decoding a block predicted using combined inter and intra prediction.
- a video stream may be compressed by a variety of techniques to reduce bandwidth required transmit or store the video stream.
- a video stream can be encoded, which can involve compression, and then transmitted to a decoder that can decode or decompress the video stream to prepare it for viewing or further processing.
- Techniques for encoding video streams include prediction, which attempts to predict the pixel values of a block of a frame of a video stream using either pixels peripheral to the block to be predicted, called intra prediction, or attempts to predict the pixel values of a block using a possibly displaced block or blocks from a temporally nearby frame or frames, called inter prediction.
- a prediction block is generated and subtracted from the block to be encoded to form a residual block representing the difference between the blocks.
- the residual block can be further encoded to reduce the number of bits to be included in the output encoded video bitstream in comparison to encoding the original block while maintaining the quality of the decoded video stream.
- a prediction block resulting from inter prediction may be called an inter predictor herein, while a prediction block resulting from intra prediction may called an intra predictor herein.
- intra predictors are generated using pixels peripheral to the current block to be predicted (e.g., pixel to the top and/or left sides of the block). Implementations of the teachings herein combine intra and inter prediction blocks to form a prediction block that can be used to compare against using only an inter predictor or only an intra predictor. Because pixels of the current block near the pixels used for prediction may be more accurately predicted by the intra predictor than by an inter predictor, the inter and intra predictors may be weighted based on the distance from the predictor edge to improve the formation of the prediction block. In this way, predictive coding of video streams may be improved through the selection of an intra predictor, an inter predictor or a combined predictor.
- FIG. 1 is a schematic of a video encoding and decoding system 100 .
- An exemplary transmitting station 112 can be, for example, a computer having an internal configuration of hardware such as that described in FIG. 2 .
- the processing of transmitting station 112 can be distributed among multiple devices.
- a network 128 can connect transmitting station 112 and a receiving station 130 for encoding and decoding of the video stream.
- the video stream can be encoded in transmitting station 112 and the encoded video stream can be decoded in receiving station 130 .
- Network 128 can be, for example, the Internet.
- Network 128 can also be a local area network (LAN), wide area network (WAN), virtual private network (VPN), cellular telephone network or any other means of transferring the video stream from transmitting station 112 to, in this example, receiving station 130 .
- LAN local area network
- WAN wide area network
- VPN virtual private network
- Receiving station 130 in one example, can be a computer having an internal configuration of hardware such as that described in FIG. 2 .
- Receiving station 130 can be a computer having an internal configuration of hardware such as that described in FIG. 2 .
- the processing of receiving station 130 can be distributed among multiple devices.
- video encoding and decoding system 100 can omit network 128 .
- a video stream can be encoded and then stored for transmission at a later time to receiving station 130 or any other device having memory.
- receiving station 130 receives (e.g., via network 128 , a computer bus, and/or some communication pathway) the encoded video stream and stores the video stream for later decoding.
- a real-time transport protocol RTP
- a transport protocol other than RTP may be used, e.g., an HTTP-based video streaming protocol.
- transmitting station 112 and/or receiving station 130 may include the ability to both encode and decode a video stream as described below.
- receiving station 130 could be a video conference participant who receives an encoded video bitstream from a video conference server (e.g., transmitting station 112 ) to decode and view and further encodes and transmits its own video bitstream to the video conference server for decoding and viewing by other participants.
- FIG. 2 is a block diagram of an exemplary computing device 200 that can implement a transmitting station or a receiving station.
- computing device 200 can implement one or both of transmitting station 112 and receiving station 130 of FIG. 1 .
- Computing device 200 can be in the form of a computing system including multiple computing devices, or in the form of a single computing device, for example, a mobile phone, a tablet computer, a laptop computer, a notebook computer, a desktop computer, and the like.
- a CPU 224 in computing device 200 can be a conventional central processing unit.
- CPU 224 can be any other type of device, or multiple devices, capable of manipulating or processing information now-existing or hereafter developed.
- the disclosed implementations can be practiced with a single processor as shown, e.g., CPU 224 , advantages in speed and efficiency can be achieved using more than one processor.
- a memory 226 in computing device 200 can be a read only memory (ROM) device or a random access memory (RAM) device in an implementation. Any other suitable type of storage device can be used as memory 226 .
- Memory 226 can include code and data 227 that is accessed by CPU 224 using a bus 230 .
- Memory 226 can further include an operating system 232 and application programs 234 , the application programs 234 including at least one program that permits CPU 224 to perform the methods described here.
- application programs 234 can include applications 1 through N, which further include a video coding application that performs the methods described here.
- Computing device 200 can also include a secondary storage 236 , which can, for example, be a memory card used with a mobile computing device 200 . Because the video communication sessions may contain a significant amount of information, they can be stored in whole or in part in secondary storage 236 and loaded into memory 226 as needed for processing.
- Computing device 200 can also include one or more output devices, such as a display 228 .
- Display 228 may be, in one example, a touch sensitive display that combines a display with a touch sensitive element that is operable to sense touch inputs.
- Display 228 can be coupled to CPU 224 via bus 230 .
- Other output devices that permit a user to program or otherwise use computing device 200 can be provided in addition to or as an alternative to display 228 .
- the output device is or includes a display, the display can be implemented in various ways, including by a liquid crystal display (LCD), a cathode-ray tube (CRT) display or light emitting diode (LED) display, such as an OLED display.
- LCD liquid crystal display
- CRT cathode-ray tube
- LED light emitting diode
- Computing device 200 can also include or be in communication with an image-sensing device 238 , for example a camera, or any other image-sensing device 238 now existing or hereafter developed that can sense an image such as the image of a user operating computing device 200 .
- Image-sensing device 238 can be positioned such that it is directed toward the user operating computing device 200 .
- the position and optical axis of image-sensing device 238 can be configured such that the field of vision includes an area that is directly adjacent to display 228 and from which display 228 is visible.
- Computing device 200 can also include or be in communication with a sound-sensing device 240 , for example a microphone, or any other sound-sensing device now existing or hereafter developed that can sense sounds near computing device 200 .
- Sound-sensing device 240 can be positioned such that it is directed toward the user operating computing device 200 and can be configured to receive sounds, for example, speech or other utterances, made by the user while the user operates computing device 200 .
- FIG. 2 depicts CPU 224 and memory 226 of computing device 200 as being integrated into a single unit, other configurations can be utilized.
- the operations of CPU 224 can be distributed across multiple machines (each machine having one or more of processors) that can be coupled directly or across a local area or other network.
- Memory 226 can be distributed across multiple machines such as a network-based memory or memory in multiple machines performing the operations of computing device 200 .
- bus 230 of computing device 200 can be composed of multiple buses.
- secondary storage 236 can be directly coupled to the other components of computing device 200 or can be accessed via a network and can comprise a single integrated unit such as a memory card or multiple units such as multiple memory cards.
- Computing device 200 can thus be implemented in a wide variety of configurations.
- FIG. 3 is a diagram of an example of a video stream 350 to be encoded and subsequently decoded.
- Video stream 350 includes a video sequence 352 .
- video sequence 352 includes a number of adjacent frames 354 . While three frames are depicted as adjacent frames 354 , video sequence 352 can include any number of adjacent frames 354 .
- Adjacent frames 354 can then be further subdivided into individual frames, e.g., a single frame 356 .
- a single frame 356 can be divided into a series of segments or planes 358 . Segments (or planes) 358 can be subsets of frames that permit parallel processing, for example. Segments 358 can also be subsets of frames that can separate the video data into separate colors.
- a frame 356 of color video data can include a luminance plane and two chrominance planes. Segments 358 may be sampled at different resolutions.
- frame 356 may be further subdivided into blocks 360 , which can contain data corresponding to, for example, 16 ⁇ 16 pixels in frame 356 .
- Blocks 360 can also be arranged to include data from one or more planes of pixel data.
- Blocks 360 can also be of any other suitable size such as 4 ⁇ 4, 8 ⁇ 8 16 ⁇ 8, 8 ⁇ 16, 16 ⁇ 16 or larger. Unless otherwise noted, the terms block and macroblock are used interchangeably herein.
- FIG. 4 is a block diagram of an encoder 470 in accordance with an implementation.
- Encoder 470 can be implemented, as described above, in transmitting station 112 such as by providing a computer software program stored in memory, for example, memory 226 .
- the computer software program can include machine instructions that, when executed by a processor such as CPU 224 , cause transmitting station 112 to encode video data in the manner described in FIG. 4 .
- Encoder 470 can also be implemented as specialized hardware included in, for example, transmitting station 112 .
- Encoder 470 has the following stages to perform the various functions in a forward path (shown by the solid connection lines) to produce an encoded or compressed bitstream 488 using input video stream 350 : an intra/inter prediction stage 472 , a transform stage 474 , a quantization stage 476 , and an entropy encoding stage 478 .
- Encoder 470 may also include a reconstruction path (shown by the dotted connection lines) to reconstruct a frame for encoding of future blocks.
- encoder 470 has the following stages to perform the various functions in the reconstruction path: a dequantization stage 480 , an inverse transform stage 482 , a reconstruction stage 484 , and a loop filtering stage 486 .
- Other structural variations of encoder 470 can be used to encode video stream 350 .
- each frame 356 can be processed in units of blocks.
- each block can be encoded using intra-frame prediction (also called intra prediction) or inter-frame prediction (also called inter prediction).
- intra-frame prediction also called intra prediction
- inter-frame prediction also called inter prediction
- a prediction block can be formed.
- intra-prediction a prediction block may be formed from samples in the current frame that have been previously encoded and reconstructed.
- inter-prediction a prediction block may be formed from samples in one or more previously constructed reference frames.
- the prediction block can be subtracted from the current block at intra/inter prediction stage 472 to produce a residual block (also called a residual).
- Transform stage 474 transforms the residual into transform coefficients in, for example, the frequency domain.
- block-based transforms include the Karhunen-Loève Transform (KLT), the Discrete Cosine Transform (DCT), the Singular Value Decomposition Transform (SVD) and the Asymmetric Discrete Sine Transform (ADST).
- KLT Karhunen-Loève Transform
- DCT Discrete Cosine Transform
- SVD Singular Value Decomposition Transform
- ADST Asymmetric Discrete Sine Transform
- the DCT transforms the block into the frequency domain.
- the transform coefficient values are based on spatial frequency, with the lowest frequency (DC) coefficient at the top-left of the matrix and the highest frequency coefficient at the bottom-right of the matrix. Note that the size of the prediction block may be different from the size of the transform block.
- Quantization stage 476 converts the transform coefficients into discrete quantum values, which are referred to as quantized transform coefficients, using a quantizer value or a quantization level.
- the quantized transform coefficients are then entropy encoded by entropy encoding stage 478 .
- the entropy-encoded coefficients, together with other information used to decode the block, which may include for example the type of prediction used, motion vectors and quantizer value, are then output to the compressed bitstream 488 .
- Compressed bitstream 488 can be formatted using various techniques, such as variable length coding (VLC) or arithmetic coding.
- VLC variable length coding
- Compressed bitstream 488 can also be referred to as an encoded video stream or encoded video bitstream and the terms will be used interchangeably herein.
- the reconstruction path in FIG. 4 can be used to ensure that both encoder 470 and a decoder 500 (described below) use the same reference frames to decode compressed bitstream 488 .
- the reconstruction path performs functions that are similar to functions that take place during the decoding process that are discussed in more detail below, including dequantizing the quantized transform coefficients at dequantization stage 480 and inverse transforming the dequantized transform coefficients at inverse transform stage 482 to produce a derivative residual block (also called a derivative residual).
- the prediction block that was predicted at intra/inter prediction stage 472 can be added to the derivative residual to create a reconstructed block.
- Loop filtering stage 486 can be applied to the reconstructed block to reduce distortion such as blocking artifacts.
- encoder 470 can be used to encode compressed bitstream 488 .
- a non-transform based encoder 470 can quantize the residual signal directly without transform stage 474 for certain blocks or frames.
- an encoder 470 can have quantization stage 476 and dequantization stage 480 combined into a single stage.
- FIG. 5 is a block diagram of a decoder 500 in accordance with another implementation.
- Decoder 500 can be implemented in receiving station 130 , for example, by providing a computer software program stored in memory 226 .
- the computer software program can include machine instructions that, when executed by a processor such as CPU 224 , cause receiving station 130 to decode video data in the manner described in FIG. 5 .
- Decoder 500 can also be implemented in hardware included in, for example, transmitting station 112 or receiving station 130 .
- Decoder 500 similar to the reconstruction path of encoder 470 discussed above, includes in one example the following stages to perform various functions to produce an output video stream 516 from compressed bitstream 488 : an entropy decoding stage 502 , a dequantization stage 504 , an inverse transform stage 506 , an intra/inter prediction stage 508 , a reconstruction stage 510 , a loop filtering stage 512 and a deblocking filtering stage 514 .
- Other structural variations of decoder 500 can be used to decode compressed bitstream 488 .
- the data elements within compressed bitstream 488 can be decoded by entropy decoding stage 502 (using, for example, arithmetic coding) to produce a set of quantized transform coefficients.
- Dequantization stage 504 dequantizes the quantized transform coefficients
- inverse transform stage 506 inverse transforms the dequantized transform coefficients to produce a derivative residual that can be identical to that created by inverse transform stage 482 in encoder 470 .
- decoder 500 can use intra/inter prediction stage 508 to create the same prediction block as was created in encoder 470 , e.g., at intra/inter prediction stage 472 .
- the prediction block can be added to the derivative residual to create a reconstructed block.
- Loop filtering stage 512 can be applied to the reconstructed block to reduce blocking artifacts.
- Other filtering can be applied to the reconstructed block.
- deblocking filtering stage 514 is applied to the reconstructed block to reduce blocking distortion, and the result is output as output video stream 516 .
- Output video stream 516 can also be referred to as a decoded video stream, and the terms will be used interchangeably herein.
- decoder 500 can be used to decode compressed bitstream 488 .
- decoder 500 can produce output video stream 516 without deblocking filtering stage 514 .
- an application can be included in a computing device 200 such that, when executed by a processor such as CPU 224 , the application generates an additional predictor that may be used to improve prediction of a current block.
- the additional predictor is a combined predictor that combines pixels of an intra predictor and an inter predictor for the block. The combination may be passed on a weighting of the pixels based on the intra prediction mode as described with reference to FIG. 6 .
- FIG. 6 is a flowchart diagram of a process 600 for predicting a block using combined intra and inter prediction blocks according to an aspect of the teachings herein.
- Process 600 can be implemented in a system such as computing device 200 to code a video stream.
- Process 600 can be implemented, for example, as a software program that is executed by a computing device such as transmitting station 112 or receiving station 130 .
- the software program can include machine-readable instructions that are stored in a memory such as memory 226 that, when executed by a processor such as CPU 224 , cause the computing device to perform process 600 .
- Process 600 can also be implemented using hardware in whole or in part. As explained above, some computing devices may have multiple memories and multiple processors, and the steps of process 600 may in such cases be distributed using different processors and memories.
- Use of the terms “processor” and “memory” in the singular herein encompasses computing devices that have only one processor or one memory as well as devices having multiple processors or memories that may each be used in the performance of some but not
- process 600 is depicted and described as a series of steps. However, steps in accordance with this disclosure can occur in various orders and/or concurrently. Additionally, steps in accordance with this disclosure may occur with other steps not presented and described herein. Furthermore, not all illustrated steps may be required to implement a method in accordance with the disclosed subject matter.
- an inter prediction block for a block of a frame of a video stream is identified.
- identify means to determine, select, choose, calculate or identify in any manner whatsoever.
- inter prediction generally uses another block (e.g., from a temporally close frame) displaced according to one or more motion vectors as an inter predictor for a current block to be encoded.
- the motion vectors may be found through any number of search algorithms that seek to match existing encoded pixel information to the current block so as to provide a good predictor for the current block.
- an inter prediction block can be identified as part of a rate/distortion loop, wherein the “rate” is the number of bits required to represent the encoded block including additional bits added to the output encoded video stream to designate the motion vectors and frame or frames that contribute to the inter predictor for the encoded block and “distortion” is the number of bits required to represent the residual, or difference between the prediction block and the block to be predicted.
- the prediction blocks can be averaged to form a single inter predictor, for example.
- the inter prediction block selected is the one whose motion vector results in the lowest rate distortion value of all of the possible choices.
- an intra prediction block associated with a block of a frame of the video stream is identified.
- intra prediction uses pixels surrounding a block to predict the contents of the block.
- FIG. 8 is a diagram of a 4 ⁇ 4 block used to illustrate adjacent pixels used in the formation of an intra prediction block. While FIG. 8 uses an example of a 4 ⁇ 4 block, techniques disclosed herein can be used with other block sizes including, without limitation, blocks having 8 ⁇ 8, 16 ⁇ 16, 32 ⁇ 32 or 64 ⁇ 64 pixels. Rectangular block sizes, for example those comprising 8 ⁇ 16 or 16 ⁇ 8 pixels, may also be used.
- the 4 ⁇ 4 block in FIG. 8 is represented by pixels a-p, and its peripheral pixels are labeled A-M. Pixel values for pixels A-M can be used to predict pixel values for pixels a-p by extending the values of peripheral pixels A-M to a prediction block having the same size as the block to be predicted.
- intra prediction relies on the fact that for some portions of a video stream, the contents of a block may be accurately predicted using pixels peripheral to the block.
- the pixels A-M which occur on the top and left of a current block are used in the example of FIG. 8 since blocks of a frame are often encoded in raster scan order, from the upper left corner of the frame from left to right along rows descending from the top to the bottom of the frame.
- the pixels A-M peripheral to the block will have been encoded and subsequently decoded prior to being used to predict the block such that the peripheral pixels will attain the same value in the encoder as will be encountered by a decoder.
- other pixels may be used (e.g., when using a different scan order).
- An intra prediction mode may be selected by the encoder as part of a rate distortion loop, either alone or in combination with the rate distortion loop described above with respect to identifying the inter prediction block.
- various intra prediction modes may be tested to determine which type of prediction will have the lowest distortion for a given rate, or number of bits to be transmitted in an encoded video bitstream, including overhead bits included in the bitstream to indicate the type of prediction used.
- Distortion can be measured by calculating a measure of the residual block, which is the data remaining after subtracting a prediction block from a data block.
- a measure of the residual block is a sum of absolute differences (SAD). SAD can be calculated by summing the absolute difference between the prediction block and the block to be predicted on a pixel-by-pixel basis. The smaller the SAD, the more accurately the prediction block predicts the block to be predicted.
- FIGS. 9A-9H are diagrams showing examples of intra prediction modes for the block of FIG. 8 .
- an intra prediction mode referred to generally as a vertical intra prediction mode V_PRED is shown.
- prediction block pixels corresponding to the locations of pixels a, e, i and j of the block to be predicted are set to the value of peripheral pixel A
- prediction block pixels corresponding to the locations of pixels b, f, j and n of the block to be predicted are set to the value of pixel B
- prediction block pixels corresponding to the locations of pixels c, g, k and o of the block to be predicted are set to the value of pixel C
- prediction block pixels corresponding to the locations of pixels d, h, l and p of the block to be predicted are set to the value of pixel D.
- Alternative techniques for implementing vertical intra prediction mode V_PRED may combine two or more peripheral pixels to calculate a pixel value to be used in the prediction block, such as by averaging the values of the peripheral pixels
- FIG. 9B shows a horizontal intra prediction mode H_PRED.
- pixel I is used to set the values of prediction block pixels corresponding to the locations of pixels a, b, c and d of the block to be predicted
- pixel J is used to set the values of prediction block pixels corresponding to the locations of pixels e, f, g and h of the block to be predicted
- pixel K is used to set the values of prediction block pixels corresponding to the locations of pixels i, j, k and l of the block to be predicted
- pixel L is used to set the values of prediction block pixels corresponding to the locations of pixels m, n, o and p of the block to be predicted.
- the peripheral pixels can be combined to set the prediction block pixel values instead of merely repeating the values of a single peripheral pixel across all pixel locations of the prediction block.
- FIG. 9C shows an oblique intra prediction mode D117_PRED, so-called because the direction of the arrows along which the peripheral pixels will be propagated to generate the prediction block form a diagonal at an angle of about 117° from the horizontal.
- the peripheral pixels or combinations of two or three peripheral pixels are propagated to form the prediction block in the direction of the arrows in FIG. 9C .
- pixels in the prediction block corresponding to the locations of pixels i and m of the block to be predicted are set to a value formed from pixels J and K, and so forth.
- FIG. 9D shows another oblique intra prediction mode D63_PRED, so-called because the direction of the arrows along which the peripheral pixels are propagated to generate the prediction block form a diagonal at an angle of about 63° from the horizontal.
- the peripheral pixels or combinations of two or three peripheral pixels are propagated to form the prediction block in the direction of the arrows in FIG. 9D .
- pixels in the prediction block corresponding to the locations of pixels a and e of the block to be predicted are set to a value formed from pixels A and B, and so forth.
- FIG. 9E shows another oblique intra prediction mode D153_PRED, so-called because the direction of the arrows along which the peripheral pixels are propagated to generate the prediction block form a diagonal at an angle of about 153° from the horizontal.
- the peripheral pixels or combinations of two or three peripheral pixels are propagated to form the prediction block in the direction of the arrows in FIG. 9E .
- pixels in the prediction block corresponding to the locations of pixels c and d of the block to be predicted are set to a value formed from pixels B and C, and so forth.
- FIG. 9F shows another oblique intra prediction mode D27_PRED, so-called because the direction of the arrows along which the peripheral pixels are propagated to generate the prediction block form a diagonal at an angle of about 27° from the horizontal.
- the peripheral pixels or combinations of two or three peripheral pixels are propagated to form the prediction block in the direction of the arrows in FIG. 9F .
- pixels in the prediction block corresponding to the locations of pixels a and b in the block to be predicted are set to a value formed from pixels I and J, and so forth.
- FIG. 9G shows another oblique prediction mode D135_PRED, so-called because the direction of the arrows along which the peripheral pixels are propagated to generate the prediction block form a diagonal at an angle of about 135° from the horizontal.
- the peripheral pixels or combinations of two or three peripheral pixels are propagated to form the prediction block in the direction of the arrows in FIG. 9G .
- pixels in the prediction block corresponding to the locations of pixels b and e in the block to be predicted are set to a value formed from pixels B and C, and so forth.
- FIG. 9H shows another oblique prediction mode D45_PRED, so-called because the direction of the arrows along which the peripheral pixels are propagated to generate the prediction block form a diagonal at an angle of about 45° from the horizontal.
- the peripheral pixels or combinations of two or three peripheral pixels are propagated to form the prediction block in the direction of the arrows in FIG. 9H .
- pixels in the prediction block corresponding to the locations of pixels c and h in the block to be predicted are set to a value formed from pixels B and C, and so forth.
- intra prediction modes may form a single value from combinations of the peripheral pixels A-M and set prediction block pixels a-p to the single value. These modes, sometimes called DC_PRED and TM_PRED, form a single pixel value from combinations of subsets of the pixels A-M and propagate the single value throughout the prediction block.
- an intra prediction mode identified in step 604 through the rate distortion loop is used to identify an intra prediction block.
- available intra prediction modes are described above in relation to FIGS. 9A-9H and the single value modes DC_PRED and TM_PRED, so the intra prediction block is generated as described above for the selected intra prediction mode. More, fewer and/or different intra prediction modes than those described herein may be available. Further, and while shown as separate steps, step 606 is frequently combined with step 604 .
- the identified inter and intra prediction blocks are combined.
- the accuracy with which a pixel of a block can be predicted by either inter or intra prediction may be dependent upon the distance of the pixel from the peripheral pixel that formed the prediction value.
- pixel a may be the most accurately predicted by intra prediction (i.e., its value is closest to the corresponding pixel value of the prediction block), while pixel d may be more accurately predicted using inter prediction since it is further from pixel I within the block.
- the peripheral pixels that form prediction pixels for any given intra predictor can be referred to as a prediction edge.
- process 600 combines the intra and inter prediction blocks for a block to be predicted with reference to the intra prediction mode. That is, each intra prediction mode at a given block size may be associated with a constant weighting block of the same size that provides the weight for the intra predictor as compared to the inter predictor.
- the pixels in the same block location from each predictor as the pixel being formed in the combined prediction block are also referred to herein as being co-located since their respective location [i,j] is the same in each block.
- the weighting matrix W[i, j] is designed for a given intra prediction mode to match the prediction direction or type as discussed above, and can be formed in a variety of ways.
- the weighting matrix W[i, j] may be obtained from a 1D exponential decay function of the form A+B exp( ⁇ Kx), where x represents the distance from the nearest prediction edge.
- the variables A, B and K are constants generated experimentally. One way of doing this is by calculating sample combined prediction blocks and determining coefficients that yield unity gain as compared to the original input.
- One possible technique to generate the 2D weighting matrix is to use a 1D array to generate the 2D matrix.
- Pseudo code representing an implementation to generate a 2D weighting matrix and combine the inter and intra prediction blocks for the various oblique intra prediction modes is as follows, where mode is the identified intra prediction mode, interpred is a pointer to the beginning of the block or pixel data representing the identified inter prediction block, interstride is the number to be added to the pixel address to go from one horizontal row of pixels to the next in the inter prediction block, intrapred is a pointer to the beginning of the block of pixel data representing the identified intra prediction block, intrastride is the number to be added to the pixel address to go from one horizontal row of pixels to the next in the intra prediction block, and size is the value of n where the block to be predicted is of size n ⁇ n:
- a single array weights 1d is generated that represents the output of a single 1D exponential function A+B*exp( ⁇ Kx), where x is the horizontal index, for an 8 ⁇ 8 block of pixels.
- the values are based on a maximum pixel value of 256.
- every n value of array weights 1d is selected depending on the size n ⁇ n of the block to be predicted.
- the selected values are used to generate the combined predictor using interpred and intrapred depending on the intraprediction mode.
- the values are used to generate a value scale based on the distance of the current pixel from the prediction edge(s).
- the value scale is then used as a multiplier for the intra predictor values, while (scale_max ⁇ scale) is used as a multiplier for the inter predictor values.
- the combined predictor in the code above, writes over the inter predictor, but this is shown only by example. The combined predictor may be written elsewhere in memory.
- Blocks encoded using a combined intra and inter prediction mode may be identified in the encoded video bitstream along with one or more motion vectors for inter prediction and a single intra prediction mode.
- the set of intra prediction modes used as candidates for such a combination mode may be different from the set of modes used for coding using only an intra prediction mode.
- the determination of whether to encoded a block using an intra prediction mode, an inter prediction mode or the combined inter/intra prediction mode may be made by, for example, generating a rate distortion value for the block encoded using combined inter/intra prediction mode and selecting the coding mode with the lowest rate distortion value. Other ways of selecting the final coding mode for the block are possible.
- FIG. 7 is a flowchart diagram of a process 700 for combining inter and intra prediction blocks according to an aspect of the teachings herein.
- a weighting function is identified.
- the weighting function is the 1D exponential decay function weights 1d[64].
- the block size of the current block i.e., the block to be encoded
- the intra prediction mode used to predict the current block is identified.
- the identified intra prediction mode is used in a switch statement to select the appropriate routine to execute to combine the intra and inter prediction blocks according to the intra prediction mode.
- the intra and inter prediction blocks are combined according to intra prediction mode V_PRED. This corresponds to combining the pixels values as described in case V_PRED above.
- the intra and inter prediction blocks are combined according to intra prediction mode H_PRED. This corresponds to combining the pixels values as described in case H_PRED above.
- the intra and inter prediction blocks are combined according to intra prediction modes D63_PRED and D117_PRED. This corresponds to combining the pixels values as described in cases D63_PRED and D117_PRED above.
- the intra and inter prediction blocks are combined according to intra prediction modes D27_PRED and D153_PRED. This corresponds to combining the pixels values as described in cases D27_PRED and D153_PRED above.
- the intra and inter prediction blocks are combined according to intra prediction mode D135_PRED. This corresponds to combining the pixels values as described in case D135_PRED above.
- the intra and inter prediction blocks are combined according to intra prediction mode D45_PRED. This corresponds to combining the pixels values as described in case D45_PRED above.
- the intra and inter prediction blocks are combined according to intra prediction modes DC_PRED and TM_PRED. In this combination, pixel values of the inter and intra prediction blocks are averaged to form the prediction block, corresponding to cases DC_PRED and TM_PRED above.
- FIG. 10 is a flowchart diagram of a process 1000 for decoding a block of a frame of a video stream according to an aspect of the teachings herein.
- Process 1000 can be implemented in a system such as computing device 200 to adjust the resolution at which a video stream is encoded in real time.
- Process 1000 can be implemented, for example, as a software program that is executed by a computing device such as transmitting station 112 or receiving station 130 .
- the software program can include machine-readable instructions that are stored in a memory such as memory 226 that, when executed by a processor such as CPU 224 , cause the computing device to perform process 1000 .
- Process 1000 can also be implemented using hardware in whole or in part. As explained above, some computing devices may have multiple memories and multiple processors, and the steps of process 1000 may in such cases be distributed using different processors and memories.
- process 1000 is depicted and described as a series of steps. However, steps in accordance with this disclosure can occur in various orders and/or concurrently. Additionally, steps in accordance with this disclosure may occur with other steps not presented and described herein. Furthermore, not all illustrated steps may be required to implement a method in accordance with the disclosed subject matter.
- process 1000 identifies that a block of a frame of the video stream has been encoded using combined inter/intra prediction.
- Combined inter/intra prediction can be identified by reading bits included in a frame or block header of the video stream to indicate that a block has been predicted using combined inter/intra prediction.
- process 1000 can read additional bits included in a frame or block header that indicate which intra prediction mode has been used to form a combined prediction block for the block.
- process 1000 can identify an intra prediction block to be used to combine with an inter prediction block identified at step 1008 .
- the intra prediction block is based on the intra prediction mode identified in step 1004 .
- process 1000 can identify an inter prediction block using motion vectors included in a frame or block header of the video stream and one or more reference frames previously decoded by the decoder.
- the inter and intra prediction blocks are combined based on the identified intra prediction mode and weights calculated according to the techniques described in relation to FIG. 7 , above. As described above, weights are calculated for each pixel of the prediction block, where the individual weights may be numbers between 0 and 1 and relate to the distance from the closest prediction edge. In some implementations, the pixels of the intra prediction block are multiplied by the weights while the pixels of the inter prediction block are multiplied by one minus the respective weight so that the two products for each pixel may be combined to form the combined prediction block pixel.
- the block is reconstructed using its residual from the bitstream and the combined prediction block as part of the multistep decoding process as described in relation to FIG. 5 , above.
- the combined inter-intra prediction mode described herein may improve coding efficiency over using inter or intra prediction alone for a block.
- encoding and decoding illustrate some exemplary encoding and decoding techniques. However, it is to be understood that encoding and decoding, as those terms are used in the claims, could mean compression, decompression, transformation, or any other processing or change of data.
- example or “exemplary” are used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as “example” or “exemplary” is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the words “example” or “exemplary” is intended to present concepts in a concrete fashion.
- the term “or” is intended to mean an inclusive “or” rather than an exclusive “or”. That is, unless specified otherwise, or clear from context, “X includes A or B” is intended to mean any of the natural inclusive permutations.
- Implementations of transmitting station 112 and/or receiving station 130 can be realized in hardware, software, or any combination thereof.
- the hardware can include, for example, computers, intellectual property (IP) cores, application-specific integrated circuits (ASICs), programmable logic arrays, optical processors, programmable logic controllers, microcode, microcontrollers, servers, microprocessors, digital signal processors or any other suitable circuit.
- IP intellectual property
- ASICs application-specific integrated circuits
- programmable logic arrays optical processors
- programmable logic controllers programmable logic controllers
- microcode microcontrollers
- servers microprocessors, digital signal processors or any other suitable circuit.
- signal processors should be understood as encompassing any of the foregoing hardware, either singly or in combination.
- signals and “data” are used interchangeably. Further, portions of transmitting station 112 and receiving station 130 do not necessarily have to be implemented in the same manner.
- transmitting station 112 or receiving station 130 can be implemented using a general purpose computer or general purpose processor with a computer program that, when executed, carries out any of the respective methods, algorithms and/or instructions described herein.
- a special purpose computer/processor can be utilized which can contain other hardware for carrying out any of the methods, algorithms, or instructions described herein.
- Transmitting station 112 and receiving station 130 can, for example, be implemented on computers in a video conferencing system.
- transmitting station 112 can be implemented on a server and receiving station 130 can be implemented on a device separate from the server, such as a hand-held communications device.
- transmitting station 112 can encode content using an encoder 470 into an encoded video signal and transmit the encoded video signal to the communications device.
- the communications device can then decode the encoded video signal using a decoder 500 .
- the communications device can decode content stored locally on the communications device, for example, content that was not transmitted by transmitting station 112 .
- Other suitable transmitting station 112 and receiving station 130 implementation schemes are available.
- receiving station 130 can be a generally stationary personal computer rather than a portable communications device and/or a device including an encoder 470 may also include a decoder 500 .
- implementations of the present invention can take the form of a computer program product accessible from, for example, a tangible computer-usable or computer-readable medium.
- a computer-usable or computer-readable medium can be any device that can, for example, tangibly contain, store, communicate, or transport the program for use by or in connection with any processor.
- the medium can be, for example, an electronic, magnetic, optical, electromagnetic, or a semiconductor device. Other suitable mediums are also available.
Abstract
Description
P[i,j]=W[i,j]*intrapredictor[i,j]+(1−W[i,j])*interpredictor[i,j];
where intrapredictor is the predictor for a given intra prediction mode; and interpredictor is the inter predictor obtained from one or two motion vectors (e.g., in step 602). The pixels in the same block location from each predictor as the pixel being formed in the combined prediction block are also referred to herein as being co-located since their respective location [i,j] is the same in each block.
P[i,j]=(W[i,j]*intrapredictor[i,j]+(256−W[i,j])*interpredictor[i,j]+128)>>8.
-
- 1) V_PRED mode: Generate the weighting matrix W[i, j] using the 1D exponential decay function with x being the vertical position of a pixel.
- 2) H_PRED mode: Generate the weighting matrix W[i, j] using the 1D exponential decay function with x being the horizontal position of a pixel.
- 3) DC_PRED and TM_PRED mode: Use equal weighting (average) pixel values in corresponding locations of the intra and inter predictors.
- 4) Oblique prediction modes (D63_PRED, D117_PRED, D27_PRED, D153_PRED, D135_PRED and D45_PRED: Generate the weighting matrix W[i, j] using the 1D exponential decay function with x being the oblique distance in the direction of prediction from a pixel to the prediction edge (e.g., the left/top edge).
static void combine_interintra(MB_PREDICTION_MODE mode, |
uint8_t *interpred, |
int interstride, |
uint8_t *intrapred, |
int intrastride, |
int size) { |
static const int scale_bits = 8; |
static const int scale_max = 256; // 1 << scale_bits; |
static const int scale_round = 127; // (1 << (scale_bits − 1)); |
// This table is a function A + B*exp(-Kx), where x is the horizontal index |
static const int weights1d[64] = { |
128, 125, 122, 119, 116, 114, 111, 109, |
107, 105, 103, 101, 99, 97, 96, 94, |
93, 91, 90, 89, 88, 86, 85, 84, |
83, 82, 81, 81, 80, 79, 78, 78, |
77, 76, 76, 75, 75, 74, 74, 73, |
73, 72, 72, 71, 71, 71, 70, 70, |
70, 70, 69, 69, 69, 69, 68, 68, |
68, 68, 68, 67, 67, 67, 67, 67, |
}; |
int size_scale = (size >= 64 ? 1: |
size == 32 ? 2 : |
size == 16 ? 4 : |
size == 8 ? 8 : 16); |
int i, j; |
switch (mode) { |
case V_PRED: |
for (i = 0; i < size; ++i) { |
for (j = 0; j < size; ++j) { |
int k = i * interstride + j; |
int scale = weights1d[i * size_scale]; |
interpred[k] = |
((scale_max − scale)*interpred[k] + |
scale * intrapred[i * intrastride + j] + scale_round) |
>> scale_bits; |
} |
} |
break; |
case H_PRED: |
for (i = 0; i < size; ++i) { |
for (j = 0; j < size; ++j) { |
int k = i * interstride + j; |
int scale = weights1d[j * size_scale]; |
interpred[k] = |
((scale_max − scale)*interpred[k] + |
scale * intrapred[i * intrastride + j] + scale_round) |
>> scale_bits; |
} |
} |
break; |
case D63_PRED: |
case D117_PRED: |
for (i = 0; i < size; ++i) { |
for (j = 0; j < size; ++j) { |
int k = i * interstride + j; |
int scale = (weights1d[i * size_scale] * 3 + |
weights1d[j * size_scale]) >> 2; |
interpred[k]= |
((scale_max − scale)*interpred[k] + |
scale * intrapred[i * intrastride + j] + scale_round) |
>> scale_bits; |
} |
} |
break; |
case D27_PRED: |
case D153_PRED: |
for (i = 0; i < size; ++i) { |
for (j = 0; j < size; ++j) { |
int k = i * interstride + j; |
int scale = (weights1d[j * size_scale]* 3 + |
weights1d[i * size_scale]) >> 2; |
interpred[k] = |
((scale_max - scale) * interpred[k] + |
scale * intrapred[i * intrastride + j] + scale_round) |
>> scale_bits; |
} |
} |
break; |
case D135_PRED: |
for (i = 0; i < size; ++i) { |
for (j = 0; j < size; ++j) { |
int k = i * interstride + j; |
int scale = weights1d[(i < j ? i : j) * size_scale]; |
interpred[k] = |
((scale_max − scale) * interpred[k] + |
scale * intrapred[i * intrastride + j] + scale_round) |
>> scale_bits; |
} |
} |
break; |
case D45_PRED: |
for (i = 0; i < size; ++i) { |
for (j = 0; j < size; ++j) { |
int k = i * interstride + j; |
int scale = (weights1d[i * size_scale] + |
weights1d[j * size_scale]) >> 1; |
interpred[k]= |
((scale_max − scale) * interpred[k] + |
scale * intrapred[i * intrastride + j] + scale_round) |
>> scale_bits; |
} |
} |
break; |
case DC_PRED: |
case TM_PRED: |
default: |
// simple average |
for (i = 0; i < size; ++i) { |
for (j = 0; j < size; ++j) { |
int k = i * interstride + j; |
interpred[k] = (interpred[k] + intrapred[i * intrastride + j]) >> 1; |
} |
} |
break; |
} |
} |
Claims (18)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/900,592 US9374578B1 (en) | 2013-05-23 | 2013-05-23 | Video coding using combined inter and intra predictors |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/900,592 US9374578B1 (en) | 2013-05-23 | 2013-05-23 | Video coding using combined inter and intra predictors |
Publications (1)
Publication Number | Publication Date |
---|---|
US9374578B1 true US9374578B1 (en) | 2016-06-21 |
Family
ID=56118413
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/900,592 Active 2034-05-01 US9374578B1 (en) | 2013-05-23 | 2013-05-23 | Video coding using combined inter and intra predictors |
Country Status (1)
Country | Link |
---|---|
US (1) | US9374578B1 (en) |
Cited By (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2018008906A1 (en) * | 2016-07-05 | 2018-01-11 | 주식회사 케이티 | Method and apparatus for processing video signal |
US20180255299A1 (en) * | 2015-08-28 | 2018-09-06 | Kt Corporation | Method and device for processing video signal |
WO2018224004A1 (en) * | 2017-06-07 | 2018-12-13 | Mediatek Inc. | Method and apparatus of intra-inter prediction mode for video coding |
US20180376148A1 (en) * | 2017-06-23 | 2018-12-27 | Qualcomm Incorporated | Combination of inter-prediction and intra-prediction in video coding |
WO2019029560A1 (en) * | 2017-08-08 | 2019-02-14 | Mediatek Inc. | Intra merge prediction |
CN109714596A (en) * | 2019-01-30 | 2019-05-03 | 江苏允博信息科技有限公司 | A method of the HEVC intraframe predictive coding based on deep learning |
US20190215521A1 (en) * | 2016-09-22 | 2019-07-11 | Mediatek Inc. | Method and apparatus for video coding using decoder side intra prediction derivation |
WO2020008107A1 (en) * | 2018-07-05 | 2020-01-09 | Nokia Technologies Oy | A method, an apparatus and a computer program product for video encoding and decoding |
WO2020015699A1 (en) * | 2018-07-18 | 2020-01-23 | Mediatek Inc. | Merge candidates with multiple hypothesis |
CN110832864A (en) * | 2017-06-26 | 2020-02-21 | 交互数字Vc控股公司 | Method and apparatus for intra prediction using multiple weighted references |
WO2020098782A1 (en) * | 2018-11-16 | 2020-05-22 | Beijing Bytedance Network Technology Co., Ltd. | Weights in combined inter intra prediction mode |
WO2020147782A1 (en) * | 2019-01-17 | 2020-07-23 | Huawei Technologies Co., Ltd. | An encoder, a decoder and corresponding methods of deblocking filter adaptation |
US20210136364A1 (en) * | 2017-11-22 | 2021-05-06 | Electronics And Telecommunications Research Institute | Image encoding/decoding method and apparatus, and recording medium for storing bitstream |
KR20210089148A (en) * | 2018-11-12 | 2021-07-15 | 베이징 바이트댄스 네트워크 테크놀로지 컴퍼니, 리미티드 | Simplification of inter- and intra-integrated predictions |
CN113170143A (en) * | 2018-12-07 | 2021-07-23 | 华为技术有限公司 | Corresponding derivation method for boundary strength of encoder, decoder and deblocking filter |
CN113545040A (en) * | 2018-12-06 | 2021-10-22 | 华为技术有限公司 | Weighted prediction method and device for multi-hypothesis coding |
US11206394B2 (en) | 2018-03-22 | 2021-12-21 | Huawei Technologies Co., Ltd. | Apparatus and method for coding an image |
US11218721B2 (en) | 2018-07-18 | 2022-01-04 | Mediatek Inc. | Method and apparatus of motion compensation bandwidth reduction for video coding system utilizing multi-hypothesis |
US11290726B2 (en) | 2019-02-07 | 2022-03-29 | Qualcomm Incorporated | Inter-intra prediction mode for video data |
US20220159241A1 (en) * | 2019-07-29 | 2022-05-19 | Beijing Bytedance Network Technology Co., Ltd. | Palette mode coding in prediction process |
US11412210B2 (en) * | 2018-03-29 | 2022-08-09 | Huawei Technologies Co., Ltd. | Inter prediction method and apparatus for video coding |
US20220286680A1 (en) * | 2018-11-16 | 2022-09-08 | Qualcomm Incorporated | Position-dependent intra-inter prediction combination in video coding |
US11470347B2 (en) * | 2018-05-10 | 2022-10-11 | Samsung Electronics Co., Ltd. | Encoding method and device therefor, and decoding method and device therefor |
US11509923B1 (en) | 2019-03-06 | 2022-11-22 | Beijing Bytedance Network Technology Co., Ltd. | Usage of converted uni-prediction candidate |
US11652984B2 (en) | 2018-11-16 | 2023-05-16 | Qualcomm Incorporated | Position-dependent intra-inter prediction combination in video coding |
US11677953B2 (en) | 2019-02-24 | 2023-06-13 | Beijing Bytedance Network Technology Co., Ltd. | Independent coding of palette mode usage indication |
US11677935B2 (en) | 2019-07-23 | 2023-06-13 | Beijing Bytedance Network Technology Co., Ltd | Mode determination for palette mode coding |
RU2803896C2 (en) * | 2019-02-07 | 2023-09-21 | Квэлкомм Инкорпорейтед | Intra-inter prediction mode for video data |
US11838539B2 (en) | 2018-10-22 | 2023-12-05 | Beijing Bytedance Network Technology Co., Ltd | Utilization of refined motion vector |
US11924432B2 (en) | 2019-07-20 | 2024-03-05 | Beijing Bytedance Network Technology Co., Ltd | Condition dependent coding of palette mode usage indication |
US11956465B2 (en) | 2018-11-20 | 2024-04-09 | Beijing Bytedance Network Technology Co., Ltd | Difference calculation based on partial position |
Citations (92)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5144426A (en) | 1989-10-13 | 1992-09-01 | Matsushita Electric Industrial Co., Ltd. | Motion compensated prediction interframe coding system |
US5737020A (en) | 1995-03-27 | 1998-04-07 | International Business Machines Corporation | Adaptive field/frame encoding of discrete cosine transform |
US5838597A (en) | 1995-12-04 | 1998-11-17 | Sgs-Thomson Microelectronics S.R.L. | MPEG-2 decoding with a reduced RAM requisite by ADPCM recompression before storing MPEG-2 decompressed data |
US6032113A (en) | 1996-10-02 | 2000-02-29 | Aura Systems, Inc. | N-stage predictive feedback-based compression and decompression of spectra of stochastic data using convergent incomplete autoregressive models |
US6134518A (en) | 1997-03-04 | 2000-10-17 | International Business Machines Corporation | Digital audio signal coding using a CELP coder and a transform coder |
US6144322A (en) | 1998-08-10 | 2000-11-07 | Mitsubishi Denki Kabushiki Kaisha | Variable length code processor with encoding and/or decoding |
US6157676A (en) | 1997-07-31 | 2000-12-05 | Victor Company Of Japan | Digital video signal inter-block interpolative predictive encoding/decoding apparatus and method providing high efficiency of encoding |
US6373895B2 (en) | 1995-10-30 | 2002-04-16 | Sony Corporation | Video data compression with trial encoder |
US6449312B1 (en) | 2000-06-08 | 2002-09-10 | Motorola, Inc. | Method of estimating motion in interlaced video |
US20020181594A1 (en) | 2001-03-05 | 2002-12-05 | Ioannis Katsavounidis | Systems and methods for decoding of partially corrupted reversible variable length code (RVLC) intra-coded macroblocks and partial block decoding of corrupted macroblocks in a video decoder |
US20030014674A1 (en) | 2001-07-10 | 2003-01-16 | Huffman James R. | Method and electronic book for marking a page in a book |
US20030022102A1 (en) | 2001-03-28 | 2003-01-30 | Toshiro Hiraoka | Method of manufacturing composite member, photosensitive composition, porous base material, insulating body and composite member |
US20030061040A1 (en) | 2001-09-25 | 2003-03-27 | Maxim Likhachev | Probabalistic networks for detecting signal content |
US20030227977A1 (en) | 2002-05-29 | 2003-12-11 | Canon Kabushiki Kaisha | Method and device for selecting a transcoding method from a set of transcoding methods |
US20040051798A1 (en) | 2002-09-18 | 2004-03-18 | Ramakrishna Kakarala | Method for detecting and correcting defective pixels in a digital image sensor |
US20050018772A1 (en) | 2003-07-25 | 2005-01-27 | Sung Chih-Ta Star | Motion estimation method and apparatus for video data compression |
US20050207497A1 (en) | 2004-03-18 | 2005-09-22 | Stmicroelectronics S.R.I. | Encoding/decoding methods and systems, computer program products therefor |
JP2005348280A (en) | 2004-06-07 | 2005-12-15 | Nippon Telegr & Teleph Corp <Ntt> | Image encoding method, image encoding apparatus, image encoding program, and computer readable recording medium recorded with the program |
US20060029136A1 (en) | 2004-07-02 | 2006-02-09 | Mitsubishi Electric Information Technology Etal | Intra-frame prediction for high-pass temporal-filtered frames in a wavelet video coding |
US20060215751A1 (en) | 2002-12-17 | 2006-09-28 | Visiowave S.A. | Method of selecting among n 'spatial video codecs" the optimum codec for a same input signal |
US20060245497A1 (en) | 2005-04-14 | 2006-11-02 | Tourapis Alexis M | Device and method for fast block-matching motion estimation in video encoders |
US20070047648A1 (en) | 2003-08-26 | 2007-03-01 | Alexandros Tourapis | Method and apparatus for encoding hybrid intra-inter coded blocks |
US20070047649A1 (en) | 2005-08-30 | 2007-03-01 | Sanyo Electric Co., Ltd. | Method for coding with motion compensated prediction |
US20070098067A1 (en) | 2005-11-02 | 2007-05-03 | Samsung Electronics Co., Ltd. | Method and apparatus for video encoding/decoding |
US20070140352A1 (en) | 2005-12-19 | 2007-06-21 | Vasudev Bhaskaran | Temporal and spatial analysis of a video macroblock |
US20070153897A1 (en) | 2006-01-04 | 2007-07-05 | Freescale Semiconductor Inc. | System and method for fast motion estimation |
US20070153899A1 (en) | 2002-04-10 | 2007-07-05 | Shinchiro Koto | Video encoding method and apparatus and video decoding method and apparatus |
US20070206931A1 (en) | 2004-04-08 | 2007-09-06 | Koninklijke Philips Electronics, N.V. | Monochrome frame detection method and corresponding device |
JP2007267414A (en) | 2007-05-24 | 2007-10-11 | Toshiba Corp | In-frame image coding method, and apparatus thereof |
US20080056356A1 (en) | 2006-07-11 | 2008-03-06 | Nokia Corporation | Scalable video coding |
US20080130754A1 (en) | 2006-11-30 | 2008-06-05 | Lsi Logic Corporation | Memory reduced H264/MPEG-4 AVC codec |
US20080212678A1 (en) | 2003-12-10 | 2008-09-04 | Simon Booth | Computational reduction in motion estimation based on lower bound of cost function |
US20080247464A1 (en) | 2007-04-06 | 2008-10-09 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding and decoding based on intra prediction using differential equation |
US20080260031A1 (en) | 2007-04-17 | 2008-10-23 | Qualcomm Incorporated | Pixel-by-pixel weighting for intra-frame coding |
US20080267292A1 (en) | 2007-04-27 | 2008-10-30 | Hiroaki Ito | Method of and Apparatus for Recording Motion Picture |
US20080285655A1 (en) | 2006-05-19 | 2008-11-20 | The Hong Kong University Of Science And Technology | Decoding with embedded denoising |
US7466774B2 (en) | 2003-01-07 | 2008-12-16 | Thomson Licensing | Mixed inter/intra video coding of macroblock partitions |
US20090010556A1 (en) | 2002-01-16 | 2009-01-08 | Kyoko Uchibayashi | Image coding apparatus, image coding method, and image coding program for coding at least one still frame with still frame coding having a higher quality than normal frame coding of other frames |
WO2009051419A2 (en) | 2007-10-16 | 2009-04-23 | Lg Electronics Inc. | A method and an apparatus for processing a video signal |
US20090110067A1 (en) | 2007-06-28 | 2009-04-30 | Mitsubishi Electric Corporation | Image encoding device, image decoding device, image encoding method and image decoding method |
US7529302B2 (en) | 2003-09-07 | 2009-05-05 | Microsoft Corporation | Four motion vector coding and decoding in bi-directionally predicted interlaced pictures |
US20090175338A1 (en) | 2008-01-04 | 2009-07-09 | Segall Christopher A | Methods and Systems for Inter-Layer Image Prediction Parameter Determination |
US7580456B2 (en) | 2005-03-01 | 2009-08-25 | Microsoft Corporation | Prediction-based directional fractional pixel motion estimation for video coding |
US20090232207A1 (en) | 2008-03-12 | 2009-09-17 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding/decoding image based on intra prediction |
US20090257492A1 (en) * | 2006-07-07 | 2009-10-15 | Kenneth Andersson | Video data management |
US7606310B1 (en) | 2004-06-28 | 2009-10-20 | On2 Technologies, Inc. | Video compression and encoding method |
US20100034260A1 (en) | 2006-12-28 | 2010-02-11 | Nippon Telegraph And Telephone Corporation | Video encoding method and decoding method, apparatuses therefor, programs therefor, and storage media which store the programs |
US7733380B1 (en) | 2005-07-19 | 2010-06-08 | Maxim Integrated Products, Inc. | Method and/or architecture for controlling encoding parameters using integrated information from camera ISP |
US20100150394A1 (en) | 2007-06-14 | 2010-06-17 | Jeffrey Adam Bloom | Modifying a coded bitstream |
US20100177826A1 (en) | 2001-07-24 | 2010-07-15 | Sasken Communication Technologies Limited | Motion estimation technique for digital video encoding applications |
US20100195715A1 (en) | 2007-10-15 | 2010-08-05 | Huawei Technologies Co., Ltd. | Method and apparatus for adaptive frame prediction |
US7809059B2 (en) | 2003-06-25 | 2010-10-05 | Thomson Licensing | Method and apparatus for weighted prediction estimation using a displaced frame differential |
US20100278269A1 (en) * | 2008-01-08 | 2010-11-04 | Telefonaktiebolaget Lm Ericsson (Publ) | Systems and Methods for using DC Change Parameters in Video Coding and Decoding |
US20100290530A1 (en) | 2009-05-14 | 2010-11-18 | Qualcomm Incorporated | Motion vector processing |
US20100303149A1 (en) | 2008-03-07 | 2010-12-02 | Goki Yasuda | Video encoding/decoding apparatus |
US20100322306A1 (en) | 2009-06-19 | 2010-12-23 | The Hong Kong University Of Science And Technology | Scalar quantization using bit-stealing for video processing |
US20110002386A1 (en) | 2009-07-06 | 2011-01-06 | Mediatek Singapore Pte. Ltd. | Video encoder and method for performing intra-prediction and video data compression |
US20110051804A1 (en) | 2009-08-31 | 2011-03-03 | Cisco Technology, Inc. | Multiple Description Coding With Spatial Shifting |
US20110182357A1 (en) | 2008-06-24 | 2011-07-28 | Sk Telecom Co., Ltd. | Intra prediction method and apparatus, and image encoding/decoding method and apparatus using same |
US20110200109A1 (en) | 2010-02-18 | 2011-08-18 | Qualcomm Incorporated | Fixed point implementation for geometric motion partitioning |
US20110202160A1 (en) | 2010-02-16 | 2011-08-18 | James Moyne | Methods and apparatuses for utilizing adaptive predictive algorithms and determining when to use the adaptive predictive algorithms for virtual metrology |
US8005144B2 (en) | 2003-09-12 | 2011-08-23 | Institute Of Computing Technology Chinese Academy Of Sciences | Bi-directional predicting method for video coding/decoding |
CN102186086A (en) | 2011-06-22 | 2011-09-14 | 武汉大学 | Audio-video-coding-standard (AVS)-based intra-frame prediction method |
US20110222608A1 (en) | 2010-03-15 | 2011-09-15 | Yongying Gao | Localized in-loop filtering with multiple filters in hybrid video coding |
US20110228858A1 (en) | 2010-03-16 | 2011-09-22 | Madhukar Budagavi | CABAC Decoder with Decoupled Arithmetic Decoding and Inverse Binarization |
US20110228840A1 (en) | 2010-03-17 | 2011-09-22 | Fujitsu Limited | Method and device for encoding moving picture and method and device for decoding moving picture |
US20110235930A1 (en) | 2003-07-18 | 2011-09-29 | Samsung Electronics Ltd., Co. | Image encoding and decoding apparatus and method |
US20110243229A1 (en) | 2008-09-22 | 2011-10-06 | Sk Telecom. Co., Ltd | Apparatus and method for image encoding/decoding using predictability of intra-prediction mode |
US20110249734A1 (en) | 2010-04-09 | 2011-10-13 | Segall Christopher A | Methods and Systems for Intra Prediction |
US20110249741A1 (en) | 2010-04-09 | 2011-10-13 | Jie Zhao | Methods and Systems for Intra Prediction |
US20110261886A1 (en) | 2008-04-24 | 2011-10-27 | Yoshinori Suzuki | Image prediction encoding device, image prediction encoding method, image prediction encoding program, image prediction decoding device, image prediction decoding method, and image prediction decoding program |
US20110280304A1 (en) | 2010-05-17 | 2011-11-17 | Lg Electronics Inc. | Intra prediction modes |
US20120008683A1 (en) | 2010-07-09 | 2012-01-12 | Qualcomm Incorporated | Signaling selected directional transform for video coding |
US20120027094A1 (en) | 2009-02-20 | 2012-02-02 | Kazushi Sato | Image processing device and method |
US8135064B2 (en) | 2004-12-03 | 2012-03-13 | Panasonic Corporation | Intra prediction apparatus |
US20120201293A1 (en) | 2009-10-14 | 2012-08-09 | Guo Liwei | Methods and apparatus for adaptive coding of motion information |
WO2012126340A1 (en) | 2011-03-20 | 2012-09-27 | 华为技术有限公司 | Method and device for determining weight factor, and method and device for intra-frame weighted prediction |
US20120250769A1 (en) | 2009-11-06 | 2012-10-04 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Hybrid video coding |
US20120300837A1 (en) | 2011-05-25 | 2012-11-29 | Google Inc. | Method and apparatus for using segmentation-based coding of prediction information |
US20120307884A1 (en) | 2011-05-31 | 2012-12-06 | Broadcom Corporation | Selective intra and/or inter prediction video encoding |
KR20120135828A (en) | 2011-06-07 | 2012-12-17 | 한양대학교 산학협력단 | Method for performing fast intra-prediction |
US20130016785A1 (en) | 2011-01-14 | 2013-01-17 | General Instrument Corporation | Spatial block merge mode |
US20130022102A1 (en) | 2011-07-18 | 2013-01-24 | Zii Labs Inc. Ltd. | Systems and Methods with Early Variance Measure Used to Optimize Video Encoding |
US20130022119A1 (en) | 2011-07-20 | 2013-01-24 | Qualcomm Incorporated | Buffering prediction data in video coding |
US20130022117A1 (en) | 2011-01-14 | 2013-01-24 | General Instrument Corporation | Temporal block merge mode |
US20130027230A1 (en) | 2010-04-13 | 2013-01-31 | Detlev Marpe | Entropy coding |
US20130259129A1 (en) | 2010-12-20 | 2013-10-03 | Kazushi Sato | Image processing device and method |
US8705616B2 (en) | 2010-06-11 | 2014-04-22 | Microsoft Corporation | Parallel multiple bitrate video encoding to reduce latency and dependences between groups of pictures |
US8718140B1 (en) | 2005-05-12 | 2014-05-06 | Visualon, Inc. | Encoding video data |
US20140140408A1 (en) | 2011-06-14 | 2014-05-22 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding motion information and method and apparatus for decoding same |
US8737824B1 (en) | 2012-03-09 | 2014-05-27 | Google Inc. | Adaptively encoding a media stream with compound prediction |
US9185414B1 (en) | 2012-06-29 | 2015-11-10 | Google Inc. | Video encoding using variance |
-
2013
- 2013-05-23 US US13/900,592 patent/US9374578B1/en active Active
Patent Citations (104)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5144426A (en) | 1989-10-13 | 1992-09-01 | Matsushita Electric Industrial Co., Ltd. | Motion compensated prediction interframe coding system |
US5737020A (en) | 1995-03-27 | 1998-04-07 | International Business Machines Corporation | Adaptive field/frame encoding of discrete cosine transform |
US6373895B2 (en) | 1995-10-30 | 2002-04-16 | Sony Corporation | Video data compression with trial encoder |
US5838597A (en) | 1995-12-04 | 1998-11-17 | Sgs-Thomson Microelectronics S.R.L. | MPEG-2 decoding with a reduced RAM requisite by ADPCM recompression before storing MPEG-2 decompressed data |
US6032113A (en) | 1996-10-02 | 2000-02-29 | Aura Systems, Inc. | N-stage predictive feedback-based compression and decompression of spectra of stochastic data using convergent incomplete autoregressive models |
US6134518A (en) | 1997-03-04 | 2000-10-17 | International Business Machines Corporation | Digital audio signal coding using a CELP coder and a transform coder |
US6157676A (en) | 1997-07-31 | 2000-12-05 | Victor Company Of Japan | Digital video signal inter-block interpolative predictive encoding/decoding apparatus and method providing high efficiency of encoding |
US6144322A (en) | 1998-08-10 | 2000-11-07 | Mitsubishi Denki Kabushiki Kaisha | Variable length code processor with encoding and/or decoding |
US6449312B1 (en) | 2000-06-08 | 2002-09-10 | Motorola, Inc. | Method of estimating motion in interlaced video |
US20020181594A1 (en) | 2001-03-05 | 2002-12-05 | Ioannis Katsavounidis | Systems and methods for decoding of partially corrupted reversible variable length code (RVLC) intra-coded macroblocks and partial block decoding of corrupted macroblocks in a video decoder |
US20030012287A1 (en) | 2001-03-05 | 2003-01-16 | Ioannis Katsavounidis | Systems and methods for decoding of systematic forward error correction (FEC) codes of selected data in a video bitstream |
US20030012285A1 (en) | 2001-03-05 | 2003-01-16 | Jin-Gyeong Kim | Systems and methods for management of data in a ring buffer for error resilient decoding of a video bitstream |
US20030026343A1 (en) | 2001-03-05 | 2003-02-06 | Chang-Su Kim | Systems and methods for enhanced error concealment in a video decoder |
US20050105614A1 (en) | 2001-03-05 | 2005-05-19 | Ioannis Katsavounidis | Systems and methods for decoding of partially corrupted reversible variable length code (RVLC) intra-coded macroblocks and partial block decoding of corrupted macroblocks in a video decoder |
US20050254584A1 (en) | 2001-03-05 | 2005-11-17 | Chang-Su Kim | Systems and methods for enhanced error concealment in a video decoder |
US20050149831A1 (en) | 2001-03-05 | 2005-07-07 | Ioannis Katsavounidis | Systems and methods for decoding of partially corrupted reversible variable length code (RVLC) intra-coded macroblocks and partial block decoding of corrupted macroblocks in a video decoder |
US20050105625A1 (en) | 2001-03-05 | 2005-05-19 | Chang-Su Kim | Systems and methods for enhanced error concealment in a video decoder |
US20030022102A1 (en) | 2001-03-28 | 2003-01-30 | Toshiro Hiraoka | Method of manufacturing composite member, photosensitive composition, porous base material, insulating body and composite member |
US20030014674A1 (en) | 2001-07-10 | 2003-01-16 | Huffman James R. | Method and electronic book for marking a page in a book |
US20100177826A1 (en) | 2001-07-24 | 2010-07-15 | Sasken Communication Technologies Limited | Motion estimation technique for digital video encoding applications |
US20030061040A1 (en) | 2001-09-25 | 2003-03-27 | Maxim Likhachev | Probabalistic networks for detecting signal content |
US20090010556A1 (en) | 2002-01-16 | 2009-01-08 | Kyoko Uchibayashi | Image coding apparatus, image coding method, and image coding program for coding at least one still frame with still frame coding having a higher quality than normal frame coding of other frames |
US20070153899A1 (en) | 2002-04-10 | 2007-07-05 | Shinchiro Koto | Video encoding method and apparatus and video decoding method and apparatus |
US20030227977A1 (en) | 2002-05-29 | 2003-12-11 | Canon Kabushiki Kaisha | Method and device for selecting a transcoding method from a set of transcoding methods |
US20070053427A1 (en) | 2002-05-29 | 2007-03-08 | Canon Kabushiki Kaisha | Method and device for selecting a transcoding method from a set of transcoding methods |
US20040051798A1 (en) | 2002-09-18 | 2004-03-18 | Ramakrishna Kakarala | Method for detecting and correcting defective pixels in a digital image sensor |
US20060215751A1 (en) | 2002-12-17 | 2006-09-28 | Visiowave S.A. | Method of selecting among n 'spatial video codecs" the optimum codec for a same input signal |
US7466774B2 (en) | 2003-01-07 | 2008-12-16 | Thomson Licensing | Mixed inter/intra video coding of macroblock partitions |
US7809059B2 (en) | 2003-06-25 | 2010-10-05 | Thomson Licensing | Method and apparatus for weighted prediction estimation using a displaced frame differential |
US20110235930A1 (en) | 2003-07-18 | 2011-09-29 | Samsung Electronics Ltd., Co. | Image encoding and decoding apparatus and method |
US20050018772A1 (en) | 2003-07-25 | 2005-01-27 | Sung Chih-Ta Star | Motion estimation method and apparatus for video data compression |
US20070047648A1 (en) | 2003-08-26 | 2007-03-01 | Alexandros Tourapis | Method and apparatus for encoding hybrid intra-inter coded blocks |
US8085845B2 (en) | 2003-08-26 | 2011-12-27 | Thomson Licensing | Method and apparatus for encoding hybrid intra-inter coded blocks |
US7529302B2 (en) | 2003-09-07 | 2009-05-05 | Microsoft Corporation | Four motion vector coding and decoding in bi-directionally predicted interlaced pictures |
US8005144B2 (en) | 2003-09-12 | 2011-08-23 | Institute Of Computing Technology Chinese Academy Of Sciences | Bi-directional predicting method for video coding/decoding |
US20080212678A1 (en) | 2003-12-10 | 2008-09-04 | Simon Booth | Computational reduction in motion estimation based on lower bound of cost function |
US20050207497A1 (en) | 2004-03-18 | 2005-09-22 | Stmicroelectronics S.R.I. | Encoding/decoding methods and systems, computer program products therefor |
US20070206931A1 (en) | 2004-04-08 | 2007-09-06 | Koninklijke Philips Electronics, N.V. | Monochrome frame detection method and corresponding device |
JP2005348280A (en) | 2004-06-07 | 2005-12-15 | Nippon Telegr & Teleph Corp <Ntt> | Image encoding method, image encoding apparatus, image encoding program, and computer readable recording medium recorded with the program |
US7606310B1 (en) | 2004-06-28 | 2009-10-20 | On2 Technologies, Inc. | Video compression and encoding method |
US20060029136A1 (en) | 2004-07-02 | 2006-02-09 | Mitsubishi Electric Information Technology Etal | Intra-frame prediction for high-pass temporal-filtered frames in a wavelet video coding |
US8135064B2 (en) | 2004-12-03 | 2012-03-13 | Panasonic Corporation | Intra prediction apparatus |
US7580456B2 (en) | 2005-03-01 | 2009-08-25 | Microsoft Corporation | Prediction-based directional fractional pixel motion estimation for video coding |
US20060245497A1 (en) | 2005-04-14 | 2006-11-02 | Tourapis Alexis M | Device and method for fast block-matching motion estimation in video encoders |
US8718140B1 (en) | 2005-05-12 | 2014-05-06 | Visualon, Inc. | Encoding video data |
US7733380B1 (en) | 2005-07-19 | 2010-06-08 | Maxim Integrated Products, Inc. | Method and/or architecture for controlling encoding parameters using integrated information from camera ISP |
US20070047649A1 (en) | 2005-08-30 | 2007-03-01 | Sanyo Electric Co., Ltd. | Method for coding with motion compensated prediction |
US20070098067A1 (en) | 2005-11-02 | 2007-05-03 | Samsung Electronics Co., Ltd. | Method and apparatus for video encoding/decoding |
US20070140352A1 (en) | 2005-12-19 | 2007-06-21 | Vasudev Bhaskaran | Temporal and spatial analysis of a video macroblock |
US20070153897A1 (en) | 2006-01-04 | 2007-07-05 | Freescale Semiconductor Inc. | System and method for fast motion estimation |
US20080285655A1 (en) | 2006-05-19 | 2008-11-20 | The Hong Kong University Of Science And Technology | Decoding with embedded denoising |
US20090257492A1 (en) * | 2006-07-07 | 2009-10-15 | Kenneth Andersson | Video data management |
US8457200B2 (en) * | 2006-07-07 | 2013-06-04 | Telefonaktiebolaget Lm Ericsson (Publ) | Video data management |
US20080056356A1 (en) | 2006-07-11 | 2008-03-06 | Nokia Corporation | Scalable video coding |
US20080130754A1 (en) | 2006-11-30 | 2008-06-05 | Lsi Logic Corporation | Memory reduced H264/MPEG-4 AVC codec |
US20100034260A1 (en) | 2006-12-28 | 2010-02-11 | Nippon Telegraph And Telephone Corporation | Video encoding method and decoding method, apparatuses therefor, programs therefor, and storage media which store the programs |
US20080247464A1 (en) | 2007-04-06 | 2008-10-09 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding and decoding based on intra prediction using differential equation |
US20080260031A1 (en) | 2007-04-17 | 2008-10-23 | Qualcomm Incorporated | Pixel-by-pixel weighting for intra-frame coding |
US20080267292A1 (en) | 2007-04-27 | 2008-10-30 | Hiroaki Ito | Method of and Apparatus for Recording Motion Picture |
JP2007267414A (en) | 2007-05-24 | 2007-10-11 | Toshiba Corp | In-frame image coding method, and apparatus thereof |
US20100150394A1 (en) | 2007-06-14 | 2010-06-17 | Jeffrey Adam Bloom | Modifying a coded bitstream |
US20090110067A1 (en) | 2007-06-28 | 2009-04-30 | Mitsubishi Electric Corporation | Image encoding device, image decoding device, image encoding method and image decoding method |
US20100195715A1 (en) | 2007-10-15 | 2010-08-05 | Huawei Technologies Co., Ltd. | Method and apparatus for adaptive frame prediction |
US20100220790A1 (en) | 2007-10-16 | 2010-09-02 | Lg Electronics Inc. | method and an apparatus for processing a video signal |
WO2009051419A2 (en) | 2007-10-16 | 2009-04-23 | Lg Electronics Inc. | A method and an apparatus for processing a video signal |
US20090175338A1 (en) | 2008-01-04 | 2009-07-09 | Segall Christopher A | Methods and Systems for Inter-Layer Image Prediction Parameter Determination |
US20100278269A1 (en) * | 2008-01-08 | 2010-11-04 | Telefonaktiebolaget Lm Ericsson (Publ) | Systems and Methods for using DC Change Parameters in Video Coding and Decoding |
US20100303149A1 (en) | 2008-03-07 | 2010-12-02 | Goki Yasuda | Video encoding/decoding apparatus |
US20090232207A1 (en) | 2008-03-12 | 2009-09-17 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding/decoding image based on intra prediction |
US20110261886A1 (en) | 2008-04-24 | 2011-10-27 | Yoshinori Suzuki | Image prediction encoding device, image prediction encoding method, image prediction encoding program, image prediction decoding device, image prediction decoding method, and image prediction decoding program |
US20110182357A1 (en) | 2008-06-24 | 2011-07-28 | Sk Telecom Co., Ltd. | Intra prediction method and apparatus, and image encoding/decoding method and apparatus using same |
US20110243229A1 (en) | 2008-09-22 | 2011-10-06 | Sk Telecom. Co., Ltd | Apparatus and method for image encoding/decoding using predictability of intra-prediction mode |
US20120027094A1 (en) | 2009-02-20 | 2012-02-02 | Kazushi Sato | Image processing device and method |
US20100290530A1 (en) | 2009-05-14 | 2010-11-18 | Qualcomm Incorporated | Motion vector processing |
US20100322306A1 (en) | 2009-06-19 | 2010-12-23 | The Hong Kong University Of Science And Technology | Scalar quantization using bit-stealing for video processing |
US20110002386A1 (en) | 2009-07-06 | 2011-01-06 | Mediatek Singapore Pte. Ltd. | Video encoder and method for performing intra-prediction and video data compression |
US8644374B2 (en) | 2009-08-31 | 2014-02-04 | Cisco Technology, Inc. | Multiple description coding with spatial shifting |
US20110051804A1 (en) | 2009-08-31 | 2011-03-03 | Cisco Technology, Inc. | Multiple Description Coding With Spatial Shifting |
US20120201293A1 (en) | 2009-10-14 | 2012-08-09 | Guo Liwei | Methods and apparatus for adaptive coding of motion information |
US20120250769A1 (en) | 2009-11-06 | 2012-10-04 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Hybrid video coding |
US20110202160A1 (en) | 2010-02-16 | 2011-08-18 | James Moyne | Methods and apparatuses for utilizing adaptive predictive algorithms and determining when to use the adaptive predictive algorithms for virtual metrology |
US20110200109A1 (en) | 2010-02-18 | 2011-08-18 | Qualcomm Incorporated | Fixed point implementation for geometric motion partitioning |
US20110222608A1 (en) | 2010-03-15 | 2011-09-15 | Yongying Gao | Localized in-loop filtering with multiple filters in hybrid video coding |
US20110228858A1 (en) | 2010-03-16 | 2011-09-22 | Madhukar Budagavi | CABAC Decoder with Decoupled Arithmetic Decoding and Inverse Binarization |
US20110228840A1 (en) | 2010-03-17 | 2011-09-22 | Fujitsu Limited | Method and device for encoding moving picture and method and device for decoding moving picture |
US20110249734A1 (en) | 2010-04-09 | 2011-10-13 | Segall Christopher A | Methods and Systems for Intra Prediction |
US20110249741A1 (en) | 2010-04-09 | 2011-10-13 | Jie Zhao | Methods and Systems for Intra Prediction |
US20130027230A1 (en) | 2010-04-13 | 2013-01-31 | Detlev Marpe | Entropy coding |
US20110280304A1 (en) | 2010-05-17 | 2011-11-17 | Lg Electronics Inc. | Intra prediction modes |
US8705616B2 (en) | 2010-06-11 | 2014-04-22 | Microsoft Corporation | Parallel multiple bitrate video encoding to reduce latency and dependences between groups of pictures |
US20120008683A1 (en) | 2010-07-09 | 2012-01-12 | Qualcomm Incorporated | Signaling selected directional transform for video coding |
US20130259129A1 (en) | 2010-12-20 | 2013-10-03 | Kazushi Sato | Image processing device and method |
US20130022117A1 (en) | 2011-01-14 | 2013-01-24 | General Instrument Corporation | Temporal block merge mode |
US20130016785A1 (en) | 2011-01-14 | 2013-01-17 | General Instrument Corporation | Spatial block merge mode |
WO2012126340A1 (en) | 2011-03-20 | 2012-09-27 | 华为技术有限公司 | Method and device for determining weight factor, and method and device for intra-frame weighted prediction |
US20120300837A1 (en) | 2011-05-25 | 2012-11-29 | Google Inc. | Method and apparatus for using segmentation-based coding of prediction information |
US20120307884A1 (en) | 2011-05-31 | 2012-12-06 | Broadcom Corporation | Selective intra and/or inter prediction video encoding |
KR20120135828A (en) | 2011-06-07 | 2012-12-17 | 한양대학교 산학협력단 | Method for performing fast intra-prediction |
US20140140408A1 (en) | 2011-06-14 | 2014-05-22 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding motion information and method and apparatus for decoding same |
CN102186086A (en) | 2011-06-22 | 2011-09-14 | 武汉大学 | Audio-video-coding-standard (AVS)-based intra-frame prediction method |
US20130022102A1 (en) | 2011-07-18 | 2013-01-24 | Zii Labs Inc. Ltd. | Systems and Methods with Early Variance Measure Used to Optimize Video Encoding |
US20130022119A1 (en) | 2011-07-20 | 2013-01-24 | Qualcomm Incorporated | Buffering prediction data in video coding |
US8737824B1 (en) | 2012-03-09 | 2014-05-27 | Google Inc. | Adaptively encoding a media stream with compound prediction |
US9185414B1 (en) | 2012-06-29 | 2015-11-10 | Google Inc. | Video encoding using variance |
Non-Patent Citations (53)
Title |
---|
"Implementors' Guide; Series H: Audiovisual and Multimedia Systems; Coding of moving video: Implementors Guide for H.264: Advanced video coding for generic audiovisual services". H.264. International Telecommunication Union. Version 12. Dated Jul. 30, 2010. |
"Overview; VP7 Data Format and Decoder". Version 1.5. On2 Technologies, Inc. Dated Mar. 28, 2005. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video". H.264. Advanced video coding for generic audiovisual services. International Telecommunication Union. Version 11. Dated Mar. 2009. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video". H.264. Advanced video coding for generic audiovisual services. International Telecommunication Union. Version 12. Dated Mar. 2010. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video". H.264. Advanced video coding for generic audiovisual services. Version 8. International Telecommunication Union. Dated Nov. 1, 2007. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video". H.264. Amendment 2: New profiles for professional applications. International Telecommunication Union. Dated Apr. 2007. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video; Advanced video coding for generic audiovisual services". H.264. Amendment 1: Support of additional colour spaces and removal of the High 4:4:4 Profile. International Telecommunication Union. Dated Jun. 2006. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video; Advanced video coding for generic audiovisual services". H.264. Version 1. International Telecommunication Union. Dated May 2003. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video; Advanced video coding for generic audiovisual services". H.264. Version 3. International Telecommunication Union. Dated Mar. 2005. |
"VP6 Bitstream & Decoder Specification". Version 1.02. On2 Technologies, Inc. Dated Aug. 17, 2006. |
"VP6 Bitstream & Decoder Specification". Version 1.03. On2 Technologies, Inc. Dated Oct. 29, 2007. |
"VP8 Data Format and Decoding Guide". WebM Project. Google On2. Dated: Dec. 1, 2010. |
Bankoski et al. "Technical Overview of VP8, An Open Source Video Codec for the Web". Dated Jul. 11, 2011. |
Bankoski et al. "VP8 Data Format and Decoding Guide; draft-bankoski-vp8-bitstream-02" Network Working Group. Dated May 18, 2011. |
Bankoski, J., Koleszar, J., Quillio, L., Salonen, J., Wilkins, P., and Y. Xu, "VP8 Data Format and Decoding Guide", RFC 6386, Nov. 2011. |
Cassidy, An analysis of VP8, a new video codec for the web, 148 pages. Nov. 2011. |
Chen, et al., "SaVE: Sensor-assisted Motion Estimation for Efficient H.264/AVC Video Encoding." MM'09, Oct. 19-24, 2009, 10 pages, ACM, Beijing, China. |
Chen, Michael C., et al.; "Design and Optimization of a Differentially Coded Variable Block Size Motion Compensation System", IEEE 1996, 4 pp. |
Chen, Xing C., et al.; "Quadtree Based Adaptive Lossy Coding of Motion Vectors", IEEE 1996, 4 pp. |
Guillotel, Philippe, et al.; "Comparison of motion vector coding techniques", SPIE vol. 2308, 1994, 11 pp. |
H.264 video compression standard.: New possibilities within video surveillance. 2008, 10 pages, Axis Communications. |
ISR and Written Opinion of the International Searching Authority for International Application No. PCT/US2012/021599 , Mar. 28, 2012. |
ISR and Written Opinion of the International Searching Authority for International Application No. PCT/US2012/021606, Mar. 28, 2012. |
J. Jung, "Core Experiment 9: Motion Vector Coding," Document # JCTVC-C509, Guangzhou, China, Oct. 2010. |
Karczewicz, Marta, et al.; "Video Coding Using Motion Compensation With Polynomial Motion Vector Fields", IEEE COMSOC EURASIP, First International Workshop on Wireless Image/Video Communications-Sep. 1996, 6 pp. |
Kim, Jong Won, et al.; "On the Hierarchical Variable Block Size Motion Estimation Technique for Motion Sequence Coding", SPIE Visual Communication and Image Processing 1993, Cambridge, MA, Nov. 8, 1993, 29 pp. |
Kuroki et al., Adaptive Arithmetic Coding for Image Prediction Errors, 2004. |
Li B., et al., "Redundancy reduction in Cbf and merge coding", Document # JCTVS-C277, p. 6, Oct. 2, 2010. |
Li S., et al.; "Direct Coding for Bipredicitive Slices in the H.264 Standard," IEEE Transactions on Circuits and Systems for Video Technology; vol. 15; No. 1; pp. 119-126; Jan. 1, 2005. |
Liu, Bede, et al.; "A simple method to segment motion field for video coding", SPIE vol. 1818, Visual Communications and Image Processing 1992, 10 pp. |
Luttrell, Max, et al.; "Simulation Results for Modified Error Resilient Syntax With Data Partitioning and RVLC", ITU-Telecommunications Standardization Sector, Study Group 16, Video Coding Experts Group (Question 15), Sixth Meeting: Seoul, South Korea, Nov. 2, 1998, 34 pp. |
Martin, Graham R., et al.; "Reduced Entropy Motion Compensation Using Variable Sized Blocks", SPIE vol. 3024, 1997, 10 pp. |
Mozilla, "Introduction to Video Coding Part 1: Transform Coding", Video Compression Overview, Mar. 2012, 171 pp. |
Nicolas, H., et al.; "Region-based motion estimation using deterministic relaxation schemes for image sequence coding", IEEE 1992, 4 pp. |
Nokia, Inc., Nokia Research Center, "MVC Decoder Description", Telecommunication Standardization Sector, Study Period 1997-2000, Geneva, Feb. 7, 2000, 99 pp. |
Orchard, Michael T.; "Exploiting Scene Structure in Video Coding", IEEE 1991, 5 pp. |
Orchard, Michael T.; "Predictive Motion-Field Segmentation for Image Sequence Coding", IEEE Transactions on Circuits and Systems for Video Technology, vol. 3, No. 1, Feb. 1993, 17 pp. |
Schiller, H., et al.; "Efficient Coding of Side Information in a Low Bitrate Hybrid Image Coder", Signal Processing 19 (1990) Elsevier Science Publishers B.V. 61-73, 13 pp. |
Schuster, Guido M., et al.; "A Video Compression Scheme With Optimal Bit Allocation Among Segmentation, Motion, and Residual Error", IEEE Transactions on Image Processing, vol. 6, No. 11, Nov. 1997, 16 pp. |
Seiler, et al., "Spatio-Temporal Prediction in Video Coding by Spatially Refined Motion Compensation," ICIP, 2008, pp. 2788-2791. |
Series H: Audiovisual and Multimedia Systems, Infrastructure of audiovisual services-Coding of moving video, Video coding for low bit rate communication, International Telecommunication Union, ITU-T Recommendation H.263, Feb. 1998, 167 pp. |
Somasundaram et al., A Pattern-Based Residual Vector Quantization Algorithm (PBRVQ) for Compressing Images, 2009. |
Steliaros, Michael K., et al.; "Locally-accurate motion estimation for object-based video coding", SPIE vol. 3309, 1997, 11 pp. |
Stiller, Christoph; "Motion-Estimation for Coding of Moving Video at 8 kbit/s with Gibbs Modeled Vectorfield Smoothing", SPIE vol. 1360 Visual Communications and Image Processing 1990, 9 pp. |
Strobach, Peter; "Tree-Structured Scene Adaptive Coder", IEEE Transactions on Communications, vol. 38, No. 4, Apr. 1990, 10 pp. |
Sun et al., Motion-Compensated Vector Quantization with a Dynamic Codebook, 1990. |
WebM Project, WebM Video Hardware RTLs, http://www.webmproject.org/hardware/, 3 pp, (Jun. 27, 2012). |
Wiegand, Thomas, et al.; "Long-Term Memory Motion-Compensated Prediction", Publication Unknown, Date Unknown, 15 pp. |
Wiegand, Thomas, et al.; "Rate-Distortion Optimized Mode Selection for Very Low Bit Rate Video Coding and the Emerging H.263 Standard", IEEE Transactions on Circuits and Systems for Video Technology, vol. 6, No. 2, Apr. 1996, 9 pp. |
Wikipedia, the free encyclopedia, "Application-specific integrated circuit", http://en.wikipedia.org/wiki/Application-specific-integrated-circuit, 7 pp (Jun. 27, 2012). |
Winken (Fraunhofer HHI) M. et al., "Video Coding Technology Proposal by Fraunhoffer HHI", 1. JCT-VC Meeting Apr. 15, 2010-Apr. 23, 2010; Dresden; (Joint Collaborative Team on Video Coding of IS/IEC JTC1/SC29/WG11 and ITU-T SG.16); URL:http://wftp3.itu.int/AV-ARCH/JCTVC-SITE/, No. 24 Apr. 2010, all pages. |
Xiao, "Macroblock Level Hybrid Temporal-Spatial Prediction for H.264/AVC," Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium, Paris, 4 pages. |
Yusuke Itani et al., "Adaptive Direct Vector Derivation for Video Coding," Picture Coding Symposium, Dec. 8, 2010 C509, Guangzhou, China, Oct. 2010. |
Cited By (79)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11563943B2 (en) | 2015-08-28 | 2023-01-24 | Kt Corporation | Method and device for deriving a prediction sample in decoding/encoding video signal using binary and quad trees |
US20180255299A1 (en) * | 2015-08-28 | 2018-09-06 | Kt Corporation | Method and device for processing video signal |
US11368690B2 (en) | 2015-08-28 | 2022-06-21 | Kt Corporation | Method for decoding video signal by deriving reference sample for intra prediction |
US11477452B2 (en) * | 2015-08-28 | 2022-10-18 | Kt Corporation | Method and device for deriving a prediction sample in decoding/encoding video signal using binary and quad trees |
US11470317B2 (en) | 2015-08-28 | 2022-10-11 | Kt Corporation | Method and device for deriving a prediction sample in decoding/encoding video signal using binary and quad trees |
US10750174B2 (en) * | 2015-08-28 | 2020-08-18 | Kt Corporation | Method and device for deriving a prediction sample in decoding/encoding video signal using binary and quad trees |
ES2699748R1 (en) * | 2016-07-05 | 2019-04-05 | Kt Corp | METHOD AND APPARATUS FOR PROCESSING VIDEO SIGNAL |
CN109417641A (en) * | 2016-07-05 | 2019-03-01 | 株式会社Kt | Method and apparatus for handling vision signal |
CN109417641B (en) * | 2016-07-05 | 2022-03-18 | 株式会社Kt | Method and apparatus for processing video signal |
US20190246133A1 (en) * | 2016-07-05 | 2019-08-08 | Kt Corporation | Method and apparatus for processing video signal |
US11876999B2 (en) | 2016-07-05 | 2024-01-16 | Kt Corporation | Method and apparatus for processing video signal |
EP3484160A4 (en) * | 2016-07-05 | 2019-12-25 | KT Corporation | Method and apparatus for processing video signal |
WO2018008906A1 (en) * | 2016-07-05 | 2018-01-11 | 주식회사 케이티 | Method and apparatus for processing video signal |
US20190215521A1 (en) * | 2016-09-22 | 2019-07-11 | Mediatek Inc. | Method and apparatus for video coding using decoder side intra prediction derivation |
TWI678917B (en) * | 2017-06-07 | 2019-12-01 | 聯發科技股份有限公司 | Method and apparatus of intra-inter prediction mode for video coding |
WO2018224004A1 (en) * | 2017-06-07 | 2018-12-13 | Mediatek Inc. | Method and apparatus of intra-inter prediction mode for video coding |
US11070815B2 (en) | 2017-06-07 | 2021-07-20 | Mediatek Inc. | Method and apparatus of intra-inter prediction mode for video coding |
US20180376148A1 (en) * | 2017-06-23 | 2018-12-27 | Qualcomm Incorporated | Combination of inter-prediction and intra-prediction in video coding |
CN110771164A (en) * | 2017-06-23 | 2020-02-07 | 高通股份有限公司 | Combination of inter-prediction and intra-prediction in video coding |
US11350109B2 (en) | 2017-06-23 | 2022-05-31 | Qualcomm Incorporated | Combination of inter-prediction and intra-prediction in video coding |
CN110771163B (en) * | 2017-06-23 | 2023-09-19 | 高通股份有限公司 | Combination of inter prediction and intra prediction in video coding |
US10757420B2 (en) | 2017-06-23 | 2020-08-25 | Qualcomm Incorporated | Combination of inter-prediction and intra-prediction in video coding |
CN110771163A (en) * | 2017-06-23 | 2020-02-07 | 高通股份有限公司 | Combination of inter-prediction and intra-prediction in video coding |
CN110771164B (en) * | 2017-06-23 | 2024-03-15 | 高通股份有限公司 | Combination of inter prediction and intra prediction in video coding |
CN110832864A (en) * | 2017-06-26 | 2020-02-21 | 交互数字Vc控股公司 | Method and apparatus for intra prediction using multiple weighted references |
US11706447B2 (en) | 2017-06-26 | 2023-07-18 | Interdigital Madison Patent Holdings, Sas | Method and apparatus for intra prediction with multiple weighted references |
CN110832864B (en) * | 2017-06-26 | 2024-03-29 | 交互数字麦迪逊专利控股公司 | Method and apparatus for intra prediction using multiple weighted references |
WO2019029560A1 (en) * | 2017-08-08 | 2019-02-14 | Mediatek Inc. | Intra merge prediction |
US11172203B2 (en) | 2017-08-08 | 2021-11-09 | Mediatek Inc. | Intra merge prediction |
TWI690200B (en) * | 2017-08-08 | 2020-04-01 | 聯發科技股份有限公司 | Intra merge prediction |
US11909961B2 (en) * | 2017-11-22 | 2024-02-20 | Intellectual Discovery Co., Ltd. | Image encoding/decoding method and apparatus, and recording medium for storing bitstream that involves performing intra prediction using constructed reference sample |
US20210136364A1 (en) * | 2017-11-22 | 2021-05-06 | Electronics And Telecommunications Research Institute | Image encoding/decoding method and apparatus, and recording medium for storing bitstream |
US11206394B2 (en) | 2018-03-22 | 2021-12-21 | Huawei Technologies Co., Ltd. | Apparatus and method for coding an image |
US11412210B2 (en) * | 2018-03-29 | 2022-08-09 | Huawei Technologies Co., Ltd. | Inter prediction method and apparatus for video coding |
US11910007B2 (en) * | 2018-05-10 | 2024-02-20 | Samsung Electronics Co., Ltd. | Encoding method and device therefor, and decoding method and device therefor |
US11910008B2 (en) * | 2018-05-10 | 2024-02-20 | Samsung Electronics Co., Ltd. | Encoding method and device therefor, and decoding method and device therefor |
US11943471B2 (en) * | 2018-05-10 | 2024-03-26 | Samsung Electronics Co., Ltd. | Encoding method and device therefor, and decoding method and device therefor |
US11470347B2 (en) * | 2018-05-10 | 2022-10-11 | Samsung Electronics Co., Ltd. | Encoding method and device therefor, and decoding method and device therefor |
US11943472B2 (en) * | 2018-05-10 | 2024-03-26 | Samsung Electronics Co., Ltd. | Encoding method and device therefor, and decoding method and device therefor |
WO2020008107A1 (en) * | 2018-07-05 | 2020-01-09 | Nokia Technologies Oy | A method, an apparatus and a computer program product for video encoding and decoding |
US11553173B2 (en) | 2018-07-18 | 2023-01-10 | Hfi Innovation Inc. | Merge candidates with multiple hypothesis |
US11218721B2 (en) | 2018-07-18 | 2022-01-04 | Mediatek Inc. | Method and apparatus of motion compensation bandwidth reduction for video coding system utilizing multi-hypothesis |
US11917185B2 (en) | 2018-07-18 | 2024-02-27 | Hfi Innovation Inc. | Method and apparatus of motion compensation bandwidth reduction for video coding system utilizing multi-hypothesis |
WO2020015699A1 (en) * | 2018-07-18 | 2020-01-23 | Mediatek Inc. | Merge candidates with multiple hypothesis |
US11051010B2 (en) | 2018-07-18 | 2021-06-29 | Mediatek Inc. | Merge candidates with multiple hypothesis |
US11838539B2 (en) | 2018-10-22 | 2023-12-05 | Beijing Bytedance Network Technology Co., Ltd | Utilization of refined motion vector |
US11889108B2 (en) | 2018-10-22 | 2024-01-30 | Beijing Bytedance Network Technology Co., Ltd | Gradient computation in bi-directional optical flow |
KR20210089148A (en) * | 2018-11-12 | 2021-07-15 | 베이징 바이트댄스 네트워크 테크놀로지 컴퍼니, 리미티드 | Simplification of inter- and intra-integrated predictions |
US11516480B2 (en) | 2018-11-12 | 2022-11-29 | Beijing Bytedance Network Technology Co., Ltd. | Simplification of combined inter-intra prediction |
US11843725B2 (en) | 2018-11-12 | 2023-12-12 | Beijing Bytedance Network Technology Co., Ltd | Using combined inter intra prediction in video processing |
EP3857879A4 (en) * | 2018-11-12 | 2022-03-16 | Beijing Bytedance Network Technology Co., Ltd. | Simplification of combined inter-intra prediction |
US11284088B2 (en) | 2018-11-12 | 2022-03-22 | Beijing Bytedance Network Technology Co., Ltd. | Using combined inter intra prediction in video processing |
US11277624B2 (en) | 2018-11-12 | 2022-03-15 | Beijing Bytedance Network Technology Co., Ltd. | Bandwidth control methods for inter prediction |
US11956449B2 (en) | 2018-11-12 | 2024-04-09 | Beijing Bytedance Network Technology Co., Ltd. | Simplification of combined inter-intra prediction |
US11831875B2 (en) * | 2018-11-16 | 2023-11-28 | Qualcomm Incorporated | Position-dependent intra-inter prediction combination in video coding |
US20220286680A1 (en) * | 2018-11-16 | 2022-09-08 | Qualcomm Incorporated | Position-dependent intra-inter prediction combination in video coding |
US11652984B2 (en) | 2018-11-16 | 2023-05-16 | Qualcomm Incorporated | Position-dependent intra-inter prediction combination in video coding |
WO2020098782A1 (en) * | 2018-11-16 | 2020-05-22 | Beijing Bytedance Network Technology Co., Ltd. | Weights in combined inter intra prediction mode |
US11956465B2 (en) | 2018-11-20 | 2024-04-09 | Beijing Bytedance Network Technology Co., Ltd | Difference calculation based on partial position |
CN113545040B (en) * | 2018-12-06 | 2024-05-14 | 华为技术有限公司 | Weighted prediction method and device for multi-hypothesis coding |
CN113545040A (en) * | 2018-12-06 | 2021-10-22 | 华为技术有限公司 | Weighted prediction method and device for multi-hypothesis coding |
JP2022511850A (en) * | 2018-12-07 | 2022-02-01 | 華為技術有限公司 | Corresponding method of derivation of boundary strength of encoder, decoder, and deblocking filter |
US11895292B2 (en) | 2018-12-07 | 2024-02-06 | Huawei Technologies Co., Ltd. | Encoder, decoder and corresponding methods of boundary strength derivation of deblocking filter |
US11240493B2 (en) * | 2018-12-07 | 2022-02-01 | Huawei Technologies Co., Ltd. | Encoder, decoder and corresponding methods of boundary strength derivation of deblocking filter |
CN113170143B (en) * | 2018-12-07 | 2024-01-02 | 华为技术有限公司 | Encoder, decoder and corresponding deduction method of boundary strength of deblocking filter |
CN113170143A (en) * | 2018-12-07 | 2021-07-23 | 华为技术有限公司 | Corresponding derivation method for boundary strength of encoder, decoder and deblocking filter |
WO2020147782A1 (en) * | 2019-01-17 | 2020-07-23 | Huawei Technologies Co., Ltd. | An encoder, a decoder and corresponding methods of deblocking filter adaptation |
US11962783B2 (en) * | 2019-01-17 | 2024-04-16 | Huawei Technologies Co., Ltd. | Encoder, a decoder and corresponding methods of deblocking filter adaptation |
US20210337211A1 (en) * | 2019-01-17 | 2021-10-28 | Huawei Technologies Co., Ltd. | Encoder, a decoder and corresponding methods of deblocking filter adaptation |
CN109714596A (en) * | 2019-01-30 | 2019-05-03 | 江苏允博信息科技有限公司 | A method of the HEVC intraframe predictive coding based on deep learning |
US11290726B2 (en) | 2019-02-07 | 2022-03-29 | Qualcomm Incorporated | Inter-intra prediction mode for video data |
RU2803896C2 (en) * | 2019-02-07 | 2023-09-21 | Квэлкомм Инкорпорейтед | Intra-inter prediction mode for video data |
US11677953B2 (en) | 2019-02-24 | 2023-06-13 | Beijing Bytedance Network Technology Co., Ltd. | Independent coding of palette mode usage indication |
US11930165B2 (en) | 2019-03-06 | 2024-03-12 | Beijing Bytedance Network Technology Co., Ltd | Size dependent inter coding |
US11509923B1 (en) | 2019-03-06 | 2022-11-22 | Beijing Bytedance Network Technology Co., Ltd. | Usage of converted uni-prediction candidate |
US11924432B2 (en) | 2019-07-20 | 2024-03-05 | Beijing Bytedance Network Technology Co., Ltd | Condition dependent coding of palette mode usage indication |
US11677935B2 (en) | 2019-07-23 | 2023-06-13 | Beijing Bytedance Network Technology Co., Ltd | Mode determination for palette mode coding |
US20230127932A1 (en) * | 2019-07-29 | 2023-04-27 | Beijing Bytedance Network Technology Co., Ltd. | Palette mode coding in prediction process |
US20220159241A1 (en) * | 2019-07-29 | 2022-05-19 | Beijing Bytedance Network Technology Co., Ltd. | Palette mode coding in prediction process |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9374578B1 (en) | Video coding using combined inter and intra predictors | |
US10165283B1 (en) | Video coding using compound prediction | |
US10142652B2 (en) | Entropy coding motion vector residuals obtained using reference motion vectors | |
US10555000B2 (en) | Multi-level compound prediction | |
US10798408B2 (en) | Last frame motion vector partitioning | |
US9438915B1 (en) | Selection of transform size in video coding | |
US9344742B2 (en) | Transform-domain intra prediction | |
US11343528B2 (en) | Compound prediction for video coding | |
US10404989B2 (en) | Hybrid prediction modes for video coding | |
US10798402B2 (en) | Same frame motion estimation and compensation | |
US10582212B2 (en) | Warped reference motion vectors for video compression | |
US11025950B2 (en) | Motion field-based reference frame rendering for motion compensated prediction in video coding | |
WO2018169571A1 (en) | Segmentation-based parameterized motion models | |
US9350988B1 (en) | Prediction mode-based block ordering in video coding | |
US10419777B2 (en) | Non-causal overlapped block prediction in variable block size video coding | |
US9967558B1 (en) | Adaptive motion search control for variable block size partitions in video coding | |
US20220078446A1 (en) | Video stream adaptive filtering for bitrate reduction | |
CN111886868B (en) | Method and apparatus for adaptive temporal filtering for substitute reference frame rendering |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MUKHERJEE, DEBARGHA;WILKINS, PAUL GORDON;XU, YAOWU;REEL/FRAME:030586/0393Effective date: 20130521 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044566/0657Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |