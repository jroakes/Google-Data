KR20240038140A - Cellular positioning using local sensors using neural networks - Google Patents
Cellular positioning using local sensors using neural networks Download PDFInfo
- Publication number
- KR20240038140A KR20240038140A KR1020247008322A KR20247008322A KR20240038140A KR 20240038140 A KR20240038140 A KR 20240038140A KR 1020247008322 A KR1020247008322 A KR 1020247008322A KR 20247008322 A KR20247008322 A KR 20247008322A KR 20240038140 A KR20240038140 A KR 20240038140A
- Authority
- KR
- South Korea
- Prior art keywords
- neural network
- reference signal
- output
- dnn
- receiving
- Prior art date
Links
- 238000013528 artificial neural network Methods 0.000 title claims abstract description 310
- 230000001413 cellular effect Effects 0.000 title description 16
- 238000005259 measurement Methods 0.000 claims abstract description 130
- 230000005540 biological transmission Effects 0.000 claims abstract description 38
- 238000000034 method Methods 0.000 claims description 137
- 238000012549 training Methods 0.000 claims description 87
- 230000015654 memory Effects 0.000 claims description 26
- 230000004044 response Effects 0.000 claims description 17
- 230000008859 change Effects 0.000 claims description 10
- 238000007670 refining Methods 0.000 claims description 2
- 238000004891 communication Methods 0.000 abstract description 43
- 238000012545 processing Methods 0.000 description 137
- 230000008569 process Effects 0.000 description 57
- 238000012360 testing method Methods 0.000 description 47
- 238000010801 machine learning Methods 0.000 description 36
- 238000010586 diagram Methods 0.000 description 16
- 238000003384 imaging method Methods 0.000 description 13
- 238000011176 pooling Methods 0.000 description 12
- 230000011664 signaling Effects 0.000 description 12
- 238000013459 approach Methods 0.000 description 11
- 238000004422 calculation algorithm Methods 0.000 description 11
- 230000003190 augmentative effect Effects 0.000 description 9
- 230000008901 benefit Effects 0.000 description 8
- 238000005516 engineering process Methods 0.000 description 8
- 238000001514 detection method Methods 0.000 description 7
- 230000006870 function Effects 0.000 description 7
- 238000013461 design Methods 0.000 description 6
- 230000007246 mechanism Effects 0.000 description 6
- 238000013527 convolutional neural network Methods 0.000 description 5
- 230000000694 effects Effects 0.000 description 5
- 230000003287 optical effect Effects 0.000 description 5
- 241000700159 Rattus Species 0.000 description 4
- 230000003044 adaptive effect Effects 0.000 description 4
- 210000004027 cell Anatomy 0.000 description 4
- 238000012986 modification Methods 0.000 description 4
- 230000004048 modification Effects 0.000 description 4
- 238000004458 analytical method Methods 0.000 description 3
- 238000003491 array Methods 0.000 description 3
- 230000000295 complement effect Effects 0.000 description 3
- 239000000284 extract Substances 0.000 description 3
- 230000007774 longterm Effects 0.000 description 3
- 210000002569 neuron Anatomy 0.000 description 3
- 230000000306 recurrent effect Effects 0.000 description 3
- 230000004913 activation Effects 0.000 description 2
- 230000007613 environmental effect Effects 0.000 description 2
- 230000014509 gene expression Effects 0.000 description 2
- 238000012417 linear regression Methods 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 230000008054 signal transmission Effects 0.000 description 2
- 238000011144 upstream manufacturing Methods 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 230000002730 additional effect Effects 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 238000010276 construction Methods 0.000 description 1
- 238000010219 correlation analysis Methods 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 238000007499 fusion processing Methods 0.000 description 1
- 238000009499 grossing Methods 0.000 description 1
- 230000003116 impacting effect Effects 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 238000007477 logistic regression Methods 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000010606 normalization Methods 0.000 description 1
- 230000000737 periodic effect Effects 0.000 description 1
- 230000001902 propagating effect Effects 0.000 description 1
- 238000000611 regression analysis Methods 0.000 description 1
- 230000003595 spectral effect Effects 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000007619 statistical method Methods 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 238000012706 support-vector machine Methods 0.000 description 1
- 230000001629 suppression Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01S—RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
- G01S5/00—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations
- G01S5/02—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations using radio waves
- G01S5/0278—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations using radio waves involving statistical or probabilistic considerations
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01S—RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
- G01S5/00—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations
- G01S5/0009—Transmission of position information to remote stations
- G01S5/0018—Transmission from mobile station to base station
- G01S5/0036—Transmission from mobile station to base station of measured values, i.e. measurement on mobile and position calculation on base station
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
- G06N3/0442—Recurrent networks, e.g. Hopfield networks characterised by memory or gating, e.g. long short-term memory [LSTM] or gated recurrent units [GRU]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
- G06N3/0455—Auto-encoder networks; Encoder-decoder networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0464—Convolutional networks [CNN, ConvNet]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/09—Supervised learning
Abstract
무선 통신 시스템(100)은 UE들의 RAT-지원(RAT-assisted) 포지셔닝을 제공하기 위해 DNN들 또는 다른 신경망들(120, 128, 134, 148)을 사용한다. BS(108)의 TX DNN(120)은 UE(110)에 대한 레퍼런스 신호(138)의 무선 전송을 생성 및 제공한다. UE(110)의 RX DNN(134)은 입력으로서 레퍼런스 신호(138) 및 로컬 UE 센서 데이터(140)를 수신하고, 이 입력으로부터 UE 측정 및 센서 보고(144)를 생성한다. UE(110)의 TX DNN(148)은 입력으로서 보고(144)를 수신하고, 이 입력으로부터 BS(108)로 전송하기 위한 UE 측정 및 센서 보고(144)를 나타내는 RF 신호(154)를 생성한다. BS(108)의 RX DNN(128)은 입력으로서 RF 신호(154)로부터 보고(144)를 수신하고, 이 입력으로부터 UE(110)의 포지션 추정(130)을 생성한다.The wireless communication system 100 uses DNNs or other neural networks 120, 128, 134, 148 to provide RAT-assisted positioning of UEs. TX DNN 120 of BS 108 generates and provides wireless transmission of reference signal 138 to UE 110. RX DNN 134 of UE 110 receives reference signal 138 and local UE sensor data 140 as input and generates UE measurements and sensor reports 144 from these inputs. The TX DNN 148 of the UE 110 receives the report 144 as input and generates from this input an RF signal 154 representing the UE measurements and sensor reports 144 for transmission to the BS 108. . The RX DNN 128 of the BS 108 receives a report 144 from the RF signal 154 as input and generates a position estimate 130 of the UE 110 from this input.
Description
사용자 장비(UE)와 같은 셀룰러 네트워크 디바이스의 정확하고 견고한 포지셔닝(positioning)은 종종 셀룰러 네트워크의 효과적이고 효율적인 동작에 중요한 기여를 한다. 높은 정확도(즉, 센티미터 레벨 이하)의 UE 포지셔닝은 증강/가상 현실 애플리케이션, 센서 기반 애플리케이션 및 산업 애플리케이션과 같은 다양한 애플리케이션에서 특히 중요하다. 높은 정확도의 UE 포지셔닝을 제공하는 기술 중 하나는 글로벌 내비게이션 위성 시스템(GNSS)이다. 그러나 GNSS는 일반적으로 도시 및 실내 환경에서 간섭, 다중 경로 손실, 낮은 신호 대 잡음비(SNR)로 인해 어려움을 겪는다. 따라서 셀룰러 네트워크는 종종 GNSS 및 유사한 기술을 무선 액세스 기술(RAT) 지원 UE 포지셔닝과 같은 하나 이상의 다른 UE 포지셔닝 기술로 보완하거나 대체하기도 한다. 예를 들어, 현재 및 최근 셀룰러 네트워크는 네트워크 구성요소가 UE 포지셔닝을 수행하는 데 사용할 수 있는 시그널링(signaling) 또는 레퍼런스 신호를 구현한다. UE(또는 기지국(BS))는 레퍼런스 신호를 수신할 때 레퍼런스 신호(들)에 대한 다양한 측정(measurement)들을 수행한다. UE(또는 BS)는 BS(또는 위치 서버)와 같은 하나 이상의 다른 네트워크 구성요소에 레퍼런스 신호 측정(들)을 전송하고, 이들은 측정들을 사용하여 UE의 위치 추정(estimate)을 계산한다.Accurate and robust positioning of cellular network devices, such as user equipment (UE), often makes an important contribution to the effective and efficient operation of cellular networks. High accuracy (i.e., sub-centimeter level) UE positioning is particularly important in a variety of applications such as augmented/virtual reality applications, sensor-based applications, and industrial applications. One of the technologies that provides high accuracy UE positioning is the Global Navigation Satellite System (GNSS). However, GNSS typically suffers from interference, multipath loss, and low signal-to-noise ratio (SNR) in urban and indoor environments. Therefore, cellular networks often complement or replace GNSS and similar technologies with one or more other UE positioning technologies, such as radio access technology (RAT) assisted UE positioning. For example, current and emerging cellular networks implement signaling or reference signals that network components can use to perform UE positioning. When a UE (or base station (BS)) receives a reference signal, it performs various measurements on the reference signal(s). The UE (or BS) transmits reference signal measurement(s) to one or more other network components, such as the BS (or location server), which use the measurements to calculate an estimate of the UE's position.
일부 실시예에 따르면, 제1 디바이스에서 컴퓨터로 구현되는 방법은: 제1 디바이스의 송신 신경망에 대한 입력으로서 레퍼런스 신호 정보를 수신하는 단계; 송신 신경망에 의해, 레퍼런스 신호 정보에 기초하여 제1 출력을 생성하는 단계, 여기서 제1 출력은 레퍼런스 신호를 나타내고; 제2 디바이스에 의한 수신을 위해 제1 출력을 나타내는 제1 RF 신호를 전송하기 위해 제1 디바이스의 무선 주파수(RF) 안테나 인터페이스를 제어하는 단계; 제1 RF 신호의 전송에 응답하여, 제1 디바이스의 수신 신경망에서, 제2 디바이스와 연관된 하나 이상의 RF 신호들을 나타내는 입력을 수신하는 단계; 및 수신 신경망에 의해, 수신 신경망에 대한 입력에 기초하여 제2 디바이스의 포지션 추정(estimate)을 나타내는 제2 출력을 생성하는 단계를 포함한다.According to some embodiments, a computer-implemented method in a first device includes: receiving reference signal information as an input to a transmission neural network in the first device; generating, by the transmission neural network, a first output based on the reference signal information, where the first output represents the reference signal; controlling a radio frequency (RF) antenna interface of the first device to transmit a first RF signal representative of a first output for reception by a second device; In response to transmitting the first RF signal, receiving, at a receiving neural network of the first device, an input representative of one or more RF signals associated with the second device; and generating, by the receiving neural network, a second output representing an estimate of the position of the second device based on the input to the receiving neural network.
다양한 실시예에서, 이 방법은 다음 측면 중 하나 이상을 추가로 포함할 수 있다. 제2 디바이스와 연관된 하나 이상의 RF 신호들을 나타내는 입력을 수신하는 단계는 제1 RF 신호와 연관된 신호 측정들을 나타내는 제2 디바이스로부터 제2 RF 신호를 수신하는 단계를 포함한다. 제2 디바이스로부터 수신된 제2 RF 신호는 또한 제2 디바이스에서 생성된 로컬 센서 데이터를 더 나타낸다. 포지션 추정은 제2 디바이스의 위치 및 제2 디바이스의 배향(orientation)을 표시한다. 제1 출력은 사용자 장비 포지셔닝에 전용(dedicated) 심볼을 포함하는 다운링크 포지션 레퍼런스 신호를 더 나타낸다. 제1 출력을 생성하는 단계는 송신 신경망에 대한 제1 신경망 아키텍처 구성에 기초하여 송신 신경망에서 제1 출력을 생성하는 단계를 포함한다. 방법은 제1 디바이스 또는 제2 디바이스 중 적어도 하나의 하나 이상의 성능들에 기초하여 복수의 신경망 아키텍처 구성들 중 제1 신경망 아키텍처 구성을 선택하는 단계를 더 포함한다. 제1 신경망 아키텍처 구성을 선택하는 단계는: 제2 디바이스의 하나 이상의 성능들을 나타내는 정보를 제2 디바이스로부터 수신하는 단계; 및 정보를 사용하여 제1 신경망 아키텍처 구성을 선택하는 단계를 포함한다. 제2 출력을 생성하는 단계는 수신 신경망에 대한 제2 신경망 아키텍처 구성에 기초하여 수신 신경망에서 제2 출력을 생성하는 단계를 포함한다. 방법은 또한 제1 디바이스 또는 제2 디바이스 중 적어도 하나의 하나 이상의 성능들에 기초하여 복수의 신경망 아키텍처 구성들 중 제2 신경망 아키텍처 구성을 선택하는 단계를 포함한다. 제2 신경망 아키텍처 구성을 선택하는 단계는: 제2 디바이스의 하나 이상의 성능들을 나타내는 정보를 제2 디바이스로부터 수신하는 단계; 및 정보를 사용하여 제2 신경망 아키텍처 구성을 선택하는 단계를 포함한다. 방법은 송신 신경망에 대한 제1 신경망 아키텍처 구성 또는 수신 신경망에 대한 제2 신경망 아키텍처 구성 중 적어도 하나를 구현하기 위해 관리 인프라스트럭처(infrastructure) 구성요소로부터 명령을 수신하는 단계를 더 포함한다. 방법은 또한, 제1 디바이스 또는 제2 디바이스 중 적어도 하나 이상의 성능들의 변경에 응답하여, 송신 신경망에 대한 제3 신경망 아키텍처 구성 또는 수신 신경망에 대한 제4 신경망 아키텍처 구성 중 적어도 하나를 선택하는 단계를 포함한다. 송신 신경망과 수신 신경망 중 적어도 하나는 심층 신경망(DNN)을 포함한다. 방법은 제1 디바이스의 송신 신경망 및 수신 신경망과 제2 디바이스의 송신 신경망 및 수신 신경망의 공동 트레이닝에 참여하는 단계를 더 포함한다. 방법은 또한 송신 신경망을 구현하는 제3 디바이스와 통신하는 단계; 및 제2 디바이스에 의한 수신을 위한 레퍼런스 신호를 나타내는 출력을 생성하도록 제3 디바이스의 송신 신경망을 구성하는 단계를 포함한다. 방법은 제1 디바이스의 수신 신경망에서, 제4 디바이스로부터 수신된 하나 이상의 RF 신호에 기초하여 제4 디바이스의 포지션 추정을 나타내는 제3 출력을 생성하는 단계; 제1 디바이스의 수신 신경망에서, 제2 출력 및 제3 출력이 제2 디바이스와 제4 디바이스가 동일한 공간을 점유하고 있음을 표시하는 것으로 결정하는 단계; 및 제2 디바이스와 제4 디바이스가 동일한 공간을 점유하고 있음을 표시하는 제2 출력 및 제3 출력에 응답하여, 제1 디바이스의 수신 신경망의 하나 이상의 파라미터들을 정제하는 단계를 더 포함한다.In various embodiments, the method may further include one or more of the following aspects. Receiving an input representative of one or more RF signals associated with the second device includes receiving a second RF signal from the second device representative of signal measurements associated with the first RF signal. The second RF signal received from the second device is also indicative of local sensor data generated by the second device. The position estimate indicates the location of the second device and the orientation of the second device. The first output further represents a downlink position reference signal containing symbols dedicated to user equipment positioning. Generating the first output includes generating a first output in the transmit neural network based on a first neural network architecture configuration for the transmit neural network. The method further includes selecting a first neural network architecture configuration from the plurality of neural network architecture configurations based on one or more capabilities of at least one of the first device or the second device. Selecting a first neural network architecture configuration may include: receiving information from a second device indicative of one or more capabilities of the second device; and using the information to select a first neural network architecture configuration. Generating the second output includes generating a second output in the receiving neural network based on a second neural network architecture configuration for the receiving neural network. The method also includes selecting a second neural network architecture configuration from the plurality of neural network architecture configurations based on one or more capabilities of at least one of the first device or the second device. Selecting a second neural network architecture configuration may include: receiving information from a second device indicative of one or more capabilities of the second device; and using the information to select a second neural network architecture configuration. The method further includes receiving instructions from a management infrastructure component to implement at least one of a first neural network architecture configuration for the transmitting neural network or a second neural network architecture configuration for the receiving neural network. The method also includes selecting at least one of a third neural network architecture configuration for the transmit neural network or a fourth neural network architecture configuration for the receive neural network in response to a change in the capabilities of at least one of the first device or the second device. do. At least one of the transmitting neural network and the receiving neural network includes a deep neural network (DNN). The method further includes participating in joint training of the transmit neural network and the receive neural network of the first device and the transmit neural network and receive neural network of the second device. The method also includes communicating with a third device implementing a transmission neural network; and configuring the transmit neural network of the third device to produce an output representative of a reference signal for reception by the second device. The method includes generating, in a receive neural network of a first device, a third output representing a position estimate of the fourth device based on one or more RF signals received from the fourth device; determining, in the receive neural network of the first device, that the second output and the third output indicate that the second device and the fourth device occupy the same space; and in response to the second and third outputs indicating that the second device and the fourth device occupy the same space, refining one or more parameters of the receiving neural network of the first device.
일부 실시예에 따르면, 제1 디바이스에서 컴퓨터로 구현되는 방법은: 제1 디바이스의 무선 주파수(RF) 안테나 인터페이스에서, 제2 디바이스로부터 제1 RF 신호를 수신하는 단계, 제1 RF 신호는 레퍼런스 신호를 나타내고; 제1 디바이스의 수신 신경망에 대한 제1 입력으로서 제1 RF 신호의 표현(representation)을 제공하는 단계; 및 수신 신경망에 의해, 수신 신경망에 대한 제1 입력에 기초하여 제1 디바이스에서의 측정 보고(measurement report)를 나타내는 제1 출력을 생성하는 단계를 포함한다.According to some embodiments, a computer-implemented method in a first device includes: receiving, at a radio frequency (RF) antenna interface of the first device, a first RF signal from a second device, the first RF signal being a reference signal; represents; providing a representation of the first RF signal as a first input to a receiving neural network of the first device; and generating, by the receiving neural network, a first output representing a measurement report at the first device based on the first input to the receiving neural network.
다양한 실시예에서, 이 방법은 다음 측면 중 하나 이상을 추가로 포함할 수 있다. 제1 디바이스의 송신 신경망에서, 입력으로서 수신 신경망으로부터의 제1 출력을 수신하는 단계; 송신 신경망에 의해 측정 보고를 나타내는 제2 출력을 생성하는 단계; 및 제2 디바이스에 의한 수신을 위해 제2 출력을 나타내는 제2 RF 신호를 전송하기 위해 제1 디바이스의 RF 안테나 인터페이스를 제어하는 단계를 포함한다. 제1 출력을 생성하는 단계는 레퍼런스 신호를 나타내는 제1 입력에 대해 하나 이상의 레퍼런스 신호 측정들을 수행하는 단계를 포함하며, 측정 보고는 하나 이상의 레퍼런스 신호 측정들 중 적어도 하나를 포함한다. 방법은 제1 디바이스의 수신 신경망에 대한 제2 입력으로서 제1 디바이스의 하나 이상의 센서들에 의해 생성된 센서 데이터의 표현을 제공하는 단계를 더 포함한다. 측정 보고는 센서 데이터와 융합된 하나 이상의 레퍼런스 신호 측정들을 포함한다. 제1 출력을 생성하는 단계는 수신 신경망에 대한 제1 신경망 아키텍처 구성에 기초하여 수신 신경망에서 제1 출력을 생성하는 단계를 포함한다. 방법은 또한 제1 디바이스 또는 제2 디바이스 중 적어도 하나의 하나 이상의 성능들에 기초하여 복수의 신경망 아키텍처 구성들 중 제1 신경망 아키텍처 구성을 선택하는 단계를 포함한다. 제1 신경망 아키텍처 구성을 선택하는 단계는: 제1 디바이스의 하나 이상의 성능들이 변경되었음을 나타내는 정보를 생성하는 단계; 및 수신 신경망에 입력으로서 정보를 제공하는 단계를 포함한다. 제2 출력을 생성하는 단계는 송신 신경망에 대한 제2 신경망 아키텍처 구성에 기초하여 송신 신경망에서 제2 출력을 생성하는 단계를 포함한다. 방법은 제1 디바이스 또는 제2 디바이스 중 적어도 하나의 하나 이상의 성능들에 기초하여 복수의 신경망 아키텍처 구성들 중 제2 신경망 아키텍처 구성을 선택하는 단계를 더 포함한다. 제2 신경망 아키텍처 구성을 선택하는 단계는: 제1 디바이스의 하나 이상의 성능들이 변경되었음을 나타내는 정보를 생성하는 단계; 및 송신 신경망에 입력으로서 표시되는 정보를 제공하는 단계를 포함한다. 방법은 또한 수신 신경망에 대한 제1 신경망 아키텍처 구성 또는 송신 신경망에 대한 제2 신경망 아키텍처 구성 중 적어도 하나를 구현하기 위해 네트워크 인프라스트럭처 구성요소로부터 명령을 수신하는 단계를 포함한다. 방법은 제1 디바이스의 하나 이상의 성능들의 변경에 응답하여, 하나 이상의 성능들의 변경을 표시하는 메시지를 네트워크 인프라스트럭처 구성요소에 전송하는 단계; 및 메시지 전송에 응답하여, 네트워크 인프라스트럭처 구성요소로부터 수신 신경망 또는 송신 신경망 중 적어도 하나에 대한 제2 신경망 아키텍처 구성을 수신하는 단계를 더 포함한다. 수신 신경망과 송신 신경망 중 적어도 하나는 심층 신경망(DNN)을 포함한다. 방법은 제1 디바이스의 송신 신경망 및 수신 신경망과 제2 디바이스의 송신 신경망 및 수신 신경망의 공동 트레이닝에 참여하는 단계를 더 포함한다. In various embodiments, the method may further include one or more of the following aspects. receiving, in a transmit neural network of a first device, a first output from a receive neural network as an input; generating a second output representing a measurement report by the transmit neural network; and controlling an RF antenna interface of the first device to transmit a second RF signal representing a second output for reception by the second device. Generating the first output includes performing one or more reference signal measurements on the first input representing the reference signal, and the measurement report includes at least one of the one or more reference signal measurements. The method further includes providing a representation of sensor data generated by one or more sensors of the first device as a second input to a receiving neural network of the first device. A measurement report includes one or more reference signal measurements fused with sensor data. Generating the first output includes generating a first output in the receiving neural network based on a first neural network architecture configuration for the receiving neural network. The method also includes selecting a first neural network architecture configuration from the plurality of neural network architecture configurations based on one or more capabilities of at least one of the first device or the second device. Selecting a first neural network architecture configuration includes: generating information indicating that one or more capabilities of the first device have changed; and providing the information as input to the receiving neural network. Generating the second output includes generating a second output in the transmit neural network based on a second neural network architecture configuration for the transmit neural network. The method further includes selecting a second neural network architecture configuration from the plurality of neural network architecture configurations based on one or more capabilities of at least one of the first device or the second device. Selecting a second neural network architecture configuration includes: generating information indicating that one or more capabilities of the first device have changed; and providing the displayed information as input to the transmission neural network. The method also includes receiving instructions from a network infrastructure component to implement at least one of a first neural network architecture configuration for a receiving neural network or a second neural network architecture configuration for a transmitting neural network. The method includes, in response to a change in one or more capabilities of a first device, sending a message to a network infrastructure component indicating the change in one or more capabilities; and in response to sending the message, receiving a second neural network architecture configuration for at least one of the receiving neural network or the transmitting neural network from the network infrastructure component. At least one of the receiving neural network and the transmitting neural network includes a deep neural network (DNN). The method further includes participating in joint training of the transmit neural network and the receive neural network of the first device and the transmit neural network and receive neural network of the second device.
일부 실시예에 따르면, 컴퓨터로 구현되는 방법은: 제1 디바이스 또는 제2 디바이스 중 적어도 하나로부터 성능 정보를 수신하는 단계; 성능 정보에 기초하여 후보 신경망 아키텍처 구성들의 세트로부터 신경망 아키텍처 구성들의 쌍을 선택하는 단계, 여기서 신경망 아키텍처 구성들의 쌍은 제1 디바이스와 제2 디바이스 사이의 셀룰러 디바이스 포지셔닝 추정 프로세스를 구현하기 위해 공동으로 트레이닝되고; 제1 디바이스의 송신 신경망 및 수신 신경망 중 하나 이상에서의 구현을 위한 상기 쌍의 제1 신경망 아키텍처 구성의 제1 표시를 제1 디바이스에 전송하는 단계; 및 제2 디바이스의 수신 신경망 및 송신 신경망 중 하나 이상에서의 구현을 위한 상기 쌍의 제2 신경망 아키텍처 구성의 제2 표시를 제2 디바이스에 전송하는 단계를 포함한다.According to some embodiments, a computer-implemented method includes: receiving performance information from at least one of a first device or a second device; Selecting a pair of neural network architecture configurations from the set of candidate neural network architecture configurations based on the performance information, wherein the pair of neural network architecture configurations are jointly trained to implement a cellular device positioning estimation process between the first device and the second device. become; transmitting to a first device a first indication of a first neural network architecture configuration of the pair for implementation in one or more of a transmit neural network and a receive neural network of the first device; and transmitting to a second device a second indication of a second neural network architecture configuration of the pair for implementation in one or more of a receiving neural network and a transmitting neural network of the second device.
다양한 실시예에서, 이 방법은 다음 측면 중 하나 이상을 추가로 포함할 수 있다. 적어도 하나의 성능은: 안테나 어레이 성능; 프로세싱 성능; 전력 성능; 온도 관련 성능; 또는 센서 성능 중 적어도 하나를 포함한다. 제1 디바이스의 송신 신경망 및 수신 신경망과, 제2 디바이스의 송신 신경망 및 수신 신경망은 각각 심층 신경망(DNN)을 포함한다.In various embodiments, the method may further include one or more of the following aspects. At least one performance is: antenna array performance; processing performance; power performance; temperature-related performance; or at least one of sensor performance. The transmitting neural network and receiving neural network of the first device, and the transmitting neural network and receiving neural network of the second device each include a deep neural network (DNN).
일부 실시예에서, 디바이스는 무선 주파수(RF) 안테나 인터페이스; RF 안테나 인터페이스에 연결된 적어도 하나의 프로세서; 및 실행가능한 명령어들을 저장하는 메모리를 포함하며, 실행가능한 명령어들은 상기 및 본 명세서에 기술된 방법 중 임의의 방법을 수행하기 위해 적어도 하나의 프로세서를 조작하도록 구성된다.In some embodiments, the device includes a radio frequency (RF) antenna interface; at least one processor coupled to an RF antenna interface; and a memory storing executable instructions, the executable instructions being configured to manipulate the at least one processor to perform any of the methods described above and herein.
첨부된 도면을 참조함으로써 본 개시 내용이 더 잘 이해되고, 그 수많은 특징 및 장점이 당업자에게 명백해진다. 서로 다른 도면에서 동일한 레퍼런스 기호를 사용하는 것은 유사하거나 동일한 항목을 나타낸다.
도 1은 일부 실시예에 따라 하나 이상의 UE들의 포지션 추정을 계산하기 위해 UE 포지셔닝 신경망 아키텍처를 사용하는 예시적인 무선 시스템을 도시하는 다이어그램이다.
도 2는 일부 실시예에 따른 도 1의 무선 시스템의 UE의 예시적인 하드웨어 구성을 도시하는 다이어그램이다.
도 3은 일부 실시예에 따른 도 1의 무선 시스템의 기지국의 예시적인 하드웨어 구성을 도시하는 다이어그램이다.
도 4는 일부 실시예에 따른 도 1의 무선 시스템의 관리 인프라스트럭처 구성요소의 예시적인 하드웨어 구성을 도시하는 다이어그램이다.
도 5는 일부 실시예에 따른 UE 포지셔닝 신경망 아키텍처에 사용하기 위한 신경망을 사용하는 기계 학습(ML) 모듈을 도시하는 다이어그램이다.
도 6은 일부 실시예에 따른 하나 이상의 BS들과 UE 사이의 레퍼런스 신호들의 프로세싱 및 전송을 위한 공동 트레이닝된 신경망들의 쌍을 도시하는 다이어그램이다.
도 7은 일부 실시예에 따라 UE와 BS 사이에서 로컬 UE 센서 데이터와 융합된 레퍼런스 신호 측정들을 포함하는, UE 측정 및 센서 보고의 프로세싱 및 전송을 위한 공동 트레이닝된 신경망들의 쌍을 도시하는 다이어그램이다.
도 8은 일부 실시예에 따라 무선 시스템에서 UE 포지셔닝을 용이하게 하기 위해 신경망 세트의 공동 트레이닝을 위한 예시적인 방법을 나타내는 흐름도이다.
도 9는 일부 실시예에 따라 선택되고 공동으로 트레이닝된 신경망 세트를 사용하여 UE 포지션 추정을 계산하는 예시적인 방법을 나타내는 흐름도이다.
도 10은 일부 실시예에 따른 도 9의 방법의 예시적인 동작을 도시하는 래더(ladder) 시그널링 다이어그램이다.
도 11은 일부 실시예에 따라 선택되고 공동으로 트레이닝된 신경망 세트를 사용하여 UE 포지션 추정을 계산하는 또 다른 예시적인 방법을 나타내는 흐름도이다.
도 12는 일부 실시예에 따른 도 11의 방법의 예시적인 동작을 도시하는 래더 시그널링 다이어그램이다.The present disclosure will be better understood and its numerous features and advantages will become apparent to those skilled in the art by referring to the accompanying drawings. Use of the same reference symbol in different drawings indicates similar or identical items.
1 is a diagram illustrating an example wireless system using a UE positioning neural network architecture to calculate a position estimate of one or more UEs, in accordance with some embodiments.
FIG. 2 is a diagram illustrating an example hardware configuration of a UE of the wireless system of FIG. 1 according to some embodiments.
FIG. 3 is a diagram illustrating an example hardware configuration of a base station of the wireless system of FIG. 1 in accordance with some embodiments.
FIG. 4 is a diagram illustrating an example hardware configuration of management infrastructure components of the wireless system of FIG. 1 in accordance with some embodiments.
FIG. 5 is a diagram illustrating a machine learning (ML) module using a neural network for use in a UE positioning neural network architecture according to some embodiments.
FIG. 6 is a diagram illustrating a pair of co-trained neural networks for processing and transmission of reference signals between one or more BSs and a UE according to some embodiments.
FIG. 7 is a diagram illustrating a pair of jointly trained neural networks for processing and transmission of UE measurements and sensor reports, including reference signal measurements fused with local UE sensor data, between a UE and a BS according to some embodiments.
8 is a flow diagram illustrating an example method for joint training of a set of neural networks to facilitate UE positioning in a wireless system, according to some embodiments.
9 is a flow diagram illustrating an example method of calculating a UE position estimate using a set of selected and jointly trained neural networks, according to some embodiments.
FIG. 10 is a ladder signaling diagram illustrating example operation of the method of FIG. 9 in accordance with some embodiments.
11 is a flow diagram illustrating another example method of calculating a UE position estimate using a set of selected and jointly trained neural networks, according to some embodiments.
FIG. 12 is a ladder signaling diagram illustrating example operation of the method of FIG. 11 in accordance with some embodiments.
종래의 무선 통신 시스템에서 RAT-지원(RAT-assisted) UE 포지셔닝은 일반적으로 레퍼런스 신호 전송, 레퍼런스 신호 측정, 레퍼런스 신호 측정 보고 및 UE 포지션 추정과 같은 일련의 프로세싱 단계/블록에 의존한다. 이러한 프로세싱 단계의 설계, 테스트 및 구현예는 상대적으로 서로 분리되어 있다. 각 프로세스 단계에 대한 이러한 맞춤형(custom) 및 독립적 설계 접근 방식은 일반적으로 과도한 복잡성, 리소스 소비 및 오버헤드를 초래한다. 또한, 종래의 RAT-지원 UE 포지셔닝 기술은 일반적으로 UE에 의해 계산되거나, 일부 경우에는 BS 또는 기타 인프라스트럭처 네트워크 구성요소에 의해 계산된 레퍼런스 신호 측정에 기초한다. 그러나 UE에는 글로벌 포지셔닝 위성(GPS)/글로벌 내비게이션 위성 시스템(GNSS) 칩셋, 카메라, 객체 검출 센서, 가속도계, 관성 측정 유닛(IMU), 고도계, 온도 센서, 기압계 등과 같은 다양한 로컬 센서가 포함되는 경우가 많다. 이러한 UE 센서의 정보 또는 데이터는 RAT-지원 UE 포지셔닝 기술의 정확성을 향상시킬 수 있다. RAT-assisted UE positioning in conventional wireless communication systems typically relies on a series of processing steps/blocks such as reference signal transmission, reference signal measurement, reference signal measurement reporting, and UE position estimation. The design, testing, and implementation of these processing steps are relatively separate from each other. This custom and independent design approach for each process step typically results in excessive complexity, resource consumption, and overhead. Additionally, conventional RAT-assisted UE positioning techniques are generally based on reference signal measurements calculated by the UE or, in some cases, by the BS or other infrastructure network components. However, the UE often includes various local sensors such as Global Positioning Satellites (GPS)/Global Navigation Satellite System (GNSS) chipsets, cameras, object detection sensors, accelerometers, inertial measurement units (IMUs), altimeters, temperature sensors, barometers, etc. many. Information or data from these UE sensors can improve the accuracy of RAT-assisted UE positioning techniques.
따라서, 각 프로세스 단계에 대해 수작업으로 접근하는 대신, 다음은 종래의 RAT-지원 UE 포지셔닝 기술에 비해 향상된 효율성 및 정확성 외에도 신속한 개발 및 배포(deployment)를 제공하는 RAT-지원 UE 포지셔닝을 위한 엔드-투-엔드 신경망 구성을 활용하는 예시적인 시스템 및 기술을 설명한다. RAT-지원 UE 포지셔닝을 위한 종래의 프로세싱 단계는 보다 정확하고 의미 있는 UE 포지션 추정을 생성하기 위해 UE의 이용가능한 센서로부터의 센서 데이터를 UE 레퍼런스 신호 측정(또는 신호)과 융합하도록 동작하는 공동으로 트레이닝된 신경망으로 대체되거나 보완된다. 예를 들어, UE 로컬 센서 정보와 융합된 UE 제공 레퍼런스 신호 측정(또는 신호)을 프로세싱함으로써, BS(또는 위치 서버와 같은 다른 네트워크 구성요소)는 UE의 로컬 상황을 통합하고, UE의 배향을 표시하며, 및/또는 움직임(예: 회전, 방향, 속도 등)과 같은 2차 정보를 포함하는 UE 포지션 추정을 생성할 수 있다. 따라서, 공동으로 트레이닝된 신경망 아키텍처는 신경망들의 세트를 포함하며, 각 신경망은 RAT-지원 UE 포지셔닝 단계의 해당 시퀀스에 대해 특별히 설계 및 테스트할 필요 없이 RAT-지원 UE 포지셔닝 단계의 기존 시퀀스보다 더 정확하고 효율적인 UE 포지셔닝을 제공하도록 트레이닝되었다. 적어도 일부 실시예에서, 공동 트레이닝된 신경망 아키텍처는 레퍼런스 신호 전송 프로세스, 레퍼런스 신호 측정 프로세스, 로컬 UE 센서 정보 수집 및 융합 프로세스, 레퍼런스 신호 측정 및 센서 보고 프로세스, 및 UE 포지션 추정 프로세스와 같은 RAT-지원 UE 포지셔닝 기술의 하나 이상의 프로세스를 구현한다. Therefore, instead of taking a manual approach for each process step, the following is an end-to-end solution for RAT-enabled UE positioning that provides rapid development and deployment in addition to improved efficiency and accuracy compared to conventional RAT-enabled UE positioning techniques. -Describe example systems and techniques utilizing end neural network configurations. The conventional processing steps for RAT-assisted UE positioning are jointly training, which operates to fuse sensor data from the UE's available sensors with UE reference signal measurements (or signals) to produce more accurate and meaningful UE position estimates. It is replaced or supplemented by a neural network. For example, by processing UE-provided reference signal measurements (or signals) fused with UE local sensor information, the BS (or another network component, such as a location server) integrates the UE's local context and indicates the UE's orientation. and/or generate a UE position estimate that includes secondary information such as movement (e.g., rotation, direction, speed, etc.). Accordingly, the jointly trained neural network architecture includes a set of neural networks, each of which is more accurate and efficient than existing sequences of RAT-assisted UE positioning steps, without having to be specifically designed and tested for that sequence of RAT-assisted UE positioning steps. Trained to provide efficient UE positioning. In at least some embodiments, the co-trained neural network architecture is capable of supporting RAT-enabled UE processes, such as a reference signal transmission process, a reference signal measurement process, a local UE sensor information collection and fusion process, a reference signal measurement and sensor reporting process, and a UE position estimation process. Implements one or more processes of positioning technology.
적어도 일부 실시예에서, 무선 시스템은 BS의 동작 특성(예: 주파수, 대역폭 등), UE 보고 레퍼런스 신호 수신 전력(RSRP), 도플러 추정, 배포 정보, 컴퓨팅 리소스, 센서 리소스, 전력 리소스, 안테나 리소스, 기타 기능 등과 같은 임의의 다양한 파라미터들에 기초하여 BS와 UE 사이에 사용되는 다양한 신경망에 대한 다수의 후보 신경망 아키텍처 구성의 공동 트레이닝을 사용할 수 있다. 따라서, BS 및 UE 각각에 사용되는 특정 신경망 구성은 이러한 디바이스의 특정 구성과 대응하는 신경망 아키텍처 구성을 트레이닝하는 데 사용되는 파라미터들 사이의 상관관계(correlation)들에 기초하여 선택될 수 있다.In at least some embodiments, the wireless system includes operating characteristics of the BS (e.g., frequency, bandwidth, etc.), UE reported reference signal received power (RSRP), Doppler estimation, distribution information, computing resources, sensor resources, power resources, antenna resources, Joint training of multiple candidate neural network architecture configurations for the various neural networks used between the BS and the UE based on any of a variety of parameters such as other features, etc. may be used. Accordingly, the specific neural network configuration used for each of the BS and UE may be selected based on correlations between the specific configuration of that device and the parameters used to train the corresponding neural network architecture configuration.
도 1은 일부 실시예에 따라 신경망 활용 UE 포지셔닝을 사용하는 무선 통신 시스템(100)을 도시한다. 도시된 바와 같이, 무선 통신 시스템(100)은 하나 이상의 광역 네트워크(WAN)(104) 또는 인터넷과 같은 다른 패킷 데이터 네트워크(PDN)에 연결된 코어 네트워크(102)를 포함하는 셀룰러 네트워크이다. 무선 통신 시스템(100)은 하나 이상의 BS(108)(BS(108-1 및 108-2)로 도시됨)를 더 포함하고, 각각의 BS(108)는 단방향 또는 양방향일 수 있는 하나 이상의 무선 통신 링크(112)(통신 링크(112-1 및 112-2)로 도시됨)를 통해 하나 이상의 UE(110)(UE(110-1 및 110-2)로 도시됨)와의 무선 통신을 지원한다. 적어도 일부 실시예에서, 각각의 BS(108)는 하나 이상의 통신 프로토콜 또는 표준에 의해 지정된 바와 같은 하나 이상의 적용가능한 RAT를 사용하여 무선 주파수(RF) 시그널링을 통해 무선 통신 링크(112)를 통해 UE(110)와 통신하도록 구성된다. 이와 같이, 각각의 BS(108)는 UE(110)와 코어 네트워크(102) 및 패킷 스위칭(PS) 데이터 서비스, 서킷 스위칭(CS) 서비스 등과 같은 다른 네트워크에 의해 제공되는 다양한 네트워크 및 서비스 사이의 무선 인터페이스로서 동작한다. 일반적으로, BS(108)로부터 UE(110)로의 데이터 또는 시그널링의 통신은 "다운링크" 또는 "DL"로 지칭되는 반면, UE(110)로부터 BS(108)로의 데이터 또는 시그널링의 통신은 "업링크" 또는 "UL"로 지칭된다. 적어도 일부 실시예에서, BS(108)는 또한 다른 BS(108) 사이에서 사용자 평면 및 제어 평면 데이터를 교환하도록 구성된 Xn 및/또는 X2 인터페이스와 같은 기지국 간 인터페이스(114)를 포함한다.1 illustrates a wireless communication system 100 using neural network utilizing UE positioning in accordance with some embodiments. As shown, the wireless communication system 100 is a cellular network that includes a core network 102 connected to one or more wide area networks (WANs) 104 or other packet data networks (PDNs), such as the Internet. The wireless communication system 100 further includes one or more BSs 108 (shown as BSs 108-1 and 108-2), each BS 108 capable of supporting one or more wireless communications, which may be one-way or two-way. Supports wireless communication with one or more UEs 110 (shown as UEs 110-1 and 110-2) via link 112 (shown as communication links 112-1 and 112-2). In at least some embodiments, each BS 108 communicates with a UE (UE) via a wireless communications link 112 via radio frequency (RF) signaling using one or more applicable RATs, as specified by one or more communications protocols or standards. It is configured to communicate with 110). As such, each BS 108 provides wireless communication between the UE 110 and various networks and services provided by the core network 102 and other networks such as packet switching (PS) data services, circuit switching (CS) services, etc. It operates as an interface. Generally, communication of data or signaling from BS 108 to UE 110 is referred to as “downlink” or “DL,” while communication of data or signaling from UE 110 to BS 108 is referred to as “uplink.” Referred to as “Link” or “UL”. In at least some embodiments, the BS 108 also includes an inter-base station interface 114, such as the Xn and/or X2 interfaces, configured to exchange user plane and control plane data between other BSs 108.
각각의 BS(108)는 UMTS(Universal Mobile Telecommunications System) RAT("3G"로도 알려져 있음)에 대한 NodeB(또는 BTS(Base Transceiver Station))로 동작하거나, 3GPP(Third Generation Partnership Project) LTE(Long Term Evolution) RAT를 위한 향상된 NodeB(eNodeB)로 동작하거나, 또는 3GPP 5세대(5G) NR(New Radio) RAT 등을 위한 5G node B("gNB")로 동작하는 것과 같은 RAT의 다양한 조합 또는 조합 중 임의의 것을 사용할 수 있다. 다음으로 UE(110)는 예를 들어, 모바일 휴대폰, 셀룰러 지원 태블릿 컴퓨터 또는 랩탑 컴퓨터, 데스크탑 컴퓨터, 셀룰러 지원 비디오 게임 시스템, 서버, 셀룰러 지원 기기, 셀룰러 지원 자동차 통신 시스템, 셀룰러 지원 스마트워치나 기타 웨어러블 기기 등을 포함하여 적절한 RAT를 통해 BS(108)와 통신하도록 동작가능한 다양한 전자 디바이스 중 임의의 것을 구현할 수 있다.Each BS 108 operates as a NodeB (or Base Transceiver Station (BTS)) for the Universal Mobile Telecommunications System (UMTS) RAT (also known as “3G”), or the Third Generation Partnership Project (3GPP) Long Term (LTE) Evolution) or various combinations or combinations of RATs, such as operating as an enhanced NodeB (eNodeB) for RAT, or as 5G node B (“gNB”) for 3GPP 5th generation (5G) NR (New Radio) RAT, etc. You can use any one. Next, the UE 110 may be connected to, for example, a mobile cell phone, a cellular enabled tablet computer or laptop computer, a desktop computer, a cellular enabled video game system, a server, a cellular enabled device, a cellular enabled automotive communication system, a cellular enabled smartwatch or other wearable. Any of a variety of electronic devices operable to communicate with BS 108 via an appropriate RAT, including devices and the like, may be implemented.
적어도 일부 실시예에서, UE(110)는 UE(110)와 연관된 높은 정확도의 포지셔닝 정보를 획득하기 위해 GNSS와 같은 하나 이상의 포지셔닝 기술을 사용한다. 그러나 GNSS는 일반적으로 도시 및 실내 환경에서 간섭, 다중 경로 및 낮은 신호 대 잡음비로 인해 어려움을 겪는다. 적어도 일부 실시예에서, 무선 통신 시스템(100)은 GNSS와 연관된 어려움을 극복하기 위해 GNSS 및 유사한 기술을 RAT-지원 UE 포지셔닝과 같은 하나 이상의 다른 UE 포지셔닝 기술로 보완하거나 심지어 대체할 수 있다. RAT-지원 UE 포지셔닝은 예를 들어 BS(108) 또는 UE(110)에 의해 생성 및 전송되는 시그널링 또는 레퍼런스 신호에 적어도 부분적으로 기초한다. 이러한 레퍼런스 신호의 예로는 PRS(Positioning Reference Signal), CSI-RS(Channel State Information Reference Signal), SS/PBCH(Synchronization/Physical Broadcast Channel Block), SRS(Sounding Reference Signal) 등이 있다. 적어도 일부 실시예에서 RAT-지원 UE 포지셔닝은 일반적으로 BS(108)가 UE(110)에 레퍼런스 신호(들)를 전송하는 것(또는 그 반대)을 포함한다. 그 다음, UE(110)(또는 BS(108))는 레퍼런스 신호(들)에 대해 다양한 측정들을 수행한다. 레퍼런스 신호 측정의 예로는 신호 강도, 관측된 도착 시간차(OTDoA)에 대한 레퍼런스 신호 시간차 측정(RSTD), 업링크 도착 시간차(UTDoA), 타이밍 어드밴스(TDAV), 도착 각도(AoA), 출발 각도(AoD), 왕복 시간(RTT) 등이 있다. UE(110)(또는 BS(108))는 UE 위치의 추정을 계산하기 위해 측정들을 사용하는 BS(108)(또는 위치 서버)와 같은 하나 이상의 다른 네트워크 구성요소에 레퍼런스 신호 측정(들)을 전송한다.In at least some embodiments, UE 110 uses one or more positioning technologies, such as GNSS, to obtain high accuracy positioning information associated with UE 110. However, GNSS typically suffers from interference, multipath, and low signal-to-noise ratio in urban and indoor environments. In at least some embodiments, wireless communication system 100 may supplement or even replace GNSS and similar technologies with one or more other UE positioning technologies, such as RAT-assisted UE positioning, to overcome difficulties associated with GNSS. RAT-assisted UE positioning is based at least in part on signaling or reference signals generated and transmitted by, for example, BS 108 or UE 110. Examples of such reference signals include Positioning Reference Signal (PRS), Channel State Information Reference Signal (CSI-RS), Synchronization/Physical Broadcast Channel Block (SS/PBCH), and Sounding Reference Signal (SRS). RAT-assisted UE positioning, in at least some embodiments, generally involves BS 108 transmitting reference signal(s) to UE 110 (or vice versa). UE 110 (or BS 108) then performs various measurements on the reference signal(s). Examples of reference signal measurements include signal strength, reference signal time difference measurement (RSTD) to observed time difference of arrival (OTDoA), uplink time difference of arrival (UTDoA), timing advance (TDAV), angle of arrival (AoA), and angle of departure (AoD). ), round trip time (RTT), etc. UE 110 (or BS 108) transmits reference signal measurement(s) to one or more other network components, such as BS 108 (or location server), which uses the measurements to calculate an estimate of the UE location. do.
전술한 바와 같이, 종래의 무선 통신 시스템에서 RAT-지원 UE 포지셔닝은 일반적으로 과도한 복잡성, 리소스 소비 및 오버헤드를 초래하는 일련의 프로세싱 단계/블록에 의존한다. 또한, 종래의 RAT-지원 UE 포지셔닝 기술은 일반적으로 UE 포지션 추정을 계산할 때 UE 센서 데이터를 고려하지 않는다. 따라서, 적어도 일 실시예에서, BS(108) 및 UE(110)는 RAT-지원 UE 포지셔닝을 용이하게 하도록 트레이닝되거나 달리 구성된 하나 이상의 신경망(NN)을 통합하는 송신기(transmitter)(TX) 및 수신기(receiver)(RX) 프로세싱 경로를 구현한다. 적어도 하나의 구성에서, NN은 UE(110)의 이용가능한 센서로부터의 센서 데이터를 UE 레퍼런스 신호 측정(또는 신호)과 융합하여 종래의 RAT-지원 UE 포지셔닝 메커니즘보다 더 정확하고 의미 있는 UE 포지션 추정을 생성한다. 설명을 위해, 하나 이상의 BS(108)와 UE(110) 사이에 설정된 RAT-지원 UE 포지셔닝 경로(116)(또는 간략하게 설명하기 위해 "UE 포지셔닝 경로(116)")와 관련하여, BS(108)는 BS 포지션 레퍼런스 TX DNN(120)(TX DNN(120-1 및 120-2)으로 도시됨) 또는 다른 신경망을 갖는 TX 프로세싱 경로(118)(프로세싱 경로(118-1 및 118-2)로 도시됨)를 사용한다. BS 포지션 레퍼런스 TX DNN(120)은 포지션 레퍼런스 신호(PRS)와 같은 레퍼런스 신호(138)를 생성하기 위한 레퍼런스 신호 정보(122)(정보(122-1 및 122-2)로 도시됨)를 수신하도록 구성된 입력을 갖는다. BS 포지션 레퍼런스 TX DNN(120)은 또한 BS(108)의 RF 프런트 엔드(124)(RF 프런트 엔드(124-1 및 124-2)로 도시됨)에 결합된 출력을 포함한다. BS(108)는 BS 포지션 RX DNN(128) 또는 다른 신경망을 갖는 RX 프로세싱 경로(126)를 추가로 사용한다. BS 포지션 RX DNN(128)은 RF 프런트 엔드(124)에 결합된 입력과 UE 포지션 추정(130)을 생성하도록 구성된 출력을 갖는다.As mentioned above, RAT-assisted UE positioning in conventional wireless communication systems typically relies on a series of processing steps/blocks that result in excessive complexity, resource consumption, and overhead. Additionally, conventional RAT-assisted UE positioning techniques generally do not consider UE sensor data when calculating UE position estimates. Accordingly, in at least one embodiment, BS 108 and UE 110 include a transmitter (TX) and a receiver (TX) that integrate one or more neural networks (NNs) trained or otherwise configured to facilitate RAT-assisted UE positioning. receiver)(RX) implements the processing path. In at least one configuration, the NN fuses sensor data from available sensors of the UE 110 with UE reference signal measurements (or signals) to produce more accurate and meaningful UE position estimates than conventional RAT-assisted UE positioning mechanisms. Create. For purposes of illustration, with respect to a RAT-assisted UE positioning path 116 (or “UE positioning path 116” for brevity) established between one or more BSs 108 and UE 110, BS 108 ) is a BS position reference TX DNN 120 (shown as TX DNN 120-1 and 120-2) or a TX processing path 118 with another neural network (shown as processing paths 118-1 and 118-2). shown) is used. BS Position Reference TX DNN 120 is configured to receive reference signal information 122 (shown as information 122-1 and 122-2) to generate a reference signal 138, such as a position reference signal (PRS). It has a configured input. BS Position Reference TX DNN 120 also includes an output coupled to RF front end 124 of BS 108 (shown as RF front ends 124-1 and 124-2). BS 108 further uses RX processing path 126 with BS position RX DNN 128 or other neural network. BS Position RX DNN 128 has an input coupled to an RF front end 124 and an output configured to generate a UE position estimate 130.
UE(110)는 UE 포지션 레퍼런스 RX DNN(134) 또는 다른 신경망을 갖는 RX 프로세싱 경로(132)를 사용한다. UE 포지션 레퍼런스 RX DNN(134)은 RF 프런트 엔드(136)에 연결된 입력을 갖는다. UE 포지션 레퍼런스 RX DNN(134)의 입력은 예를 들어, 적어도 하나의 레퍼런스 신호(138)(레퍼런스 신호(138-1 및 138-2)로 도시됨) 또는 하나 이상의 BS(108)로부터의 다른 레퍼런스 신호, 로컬 센서 데이터(140) 등을 수신하도록 구성된다. UE 포지션 레퍼런스 RX DNN(134)은 또한 UE 포지션 레퍼런스 RX DNN(134)에 대한 입력에 기초하여 UE 측정 및 센서 보고(144)를 생성하도록 구성된 출력을 갖는다. UE(110)는 UE 포지션 피드백 TX DNN(148) 또는 다른 신경망을 갖는 TX 프로세싱 경로(146)를 추가로 사용한다. UE 포지션 피드백 TX DNN(148)은 UE 포지션 레퍼런스 RX DNN(134)의 출력에 결합된 입력을 가지며, 또한 RF 프런트 엔드(136)에 결합된 출력을 갖는다. 적어도 일부 실시예에서, 서빙 BS(108-1)(또는 다른 셀룰러 네트워크 구성요소)는 서빙 셀의 동작 특성, UE 보고 RSRP, 도플러 추정, 배포 정보 등에 기초하여 UE(110)의 UE 포지션 레퍼런스 RX DNN(134) 및 UE 포지션 피드백 TX DNN(148)을 구성한다. 적어도 일부 실시예에서, UE(110)는 RRC 메시지와 같은 하나 이상의 제어 메시지를 통해 서빙 BS(108-1)(또는 다른 네트워크 구성요소)로부터 특정 신경망 아키텍처를 수신한다.UE 110 uses RX processing path 132 with a UE position reference RX DNN 134 or another neural network. The UE position reference RX DNN 134 has an input connected to the RF front end 136. The input of the UE position reference RX DNN 134 may be, for example, at least one reference signal 138 (shown as reference signals 138-1 and 138-2) or another reference from one or more BSs 108. It is configured to receive signals, local sensor data 140, etc. UE Position Reference RX DNN 134 also has an output configured to generate UE measurements and sensor reports 144 based on inputs to UE Position Reference RX DNN 134. UE 110 further uses TX processing path 146 with UE position feedback TX DNN 148 or other neural network. UE position feedback TX DNN 148 has an input coupled to the output of UE position reference RX DNN 134 and also has an output coupled to RF front end 136. In at least some embodiments, serving BS 108 - 1 (or other cellular network component) determines the UE position reference RX DNN of UE 110 based on the operating characteristics of the serving cell, UE reported RSRP, Doppler estimates, distribution information, etc. (134) and UE position feedback TX DNN (148). In at least some embodiments, UE 110 receives a specific neural network architecture from serving BS 108-1 (or other network component) via one or more control messages, such as RRC messages.
동작 시, BS 포지션 레퍼런스 TX DNN(120), BS 포지션 RX DNN(128), UE 포지션 레퍼런스 RX DNN(134), UE 포지션 피드백 TX DNN(148) 또는 이들의 조합은 RAT-지원 UE 포지셔닝 동작 중 하나 이상을 수행하기 위해 공동으로 트레이닝되거나 함께 구성된다. 적어도 일부 실시예에서, BS 포지션 레퍼런스 TX DNN(120)은 레퍼런스 신호 정보(122)를 입력으로 수신한다. BS 포지션 레퍼런스 TX DNN(120)은 UE(110)로의 RF 전송 및 UE(110)의 UE 포지션 레퍼런스 RX DNN(134)에 의한 프로세싱에 적합한 레퍼런스 신호 정보(122)(및 임의의 다른 입력)로부터 출력되는 레퍼런스 신호(138)를 생성한다. 적어도 일 실시예에서, 레퍼런스 신호(138) 출력은 UE 포지셔닝 전용 심볼들을 포함하는 다운링크 포지션 레퍼런스 신호인 포지셔닝 레퍼런스 신호를 나타낸다. 그러나 레퍼런스 신호(138) 출력은 CSI-RS 또는 SS/PBCH와 같은 다른 유형의 레퍼런스 신호를 나타낼 수 있다. 이러한 공동 트레이닝 또는 다른 구성의 일부로서, 적어도 일 실시예에서, BS 포지션 레퍼런스 TX DNN(120)은 실제로 레퍼런스 신호(138) 또는 BS(108)에 의한 UE(110)로의 전송을 위한 다른 레퍼런스 신호를 생성 및 구성하도록 트레이닝되거나 구성된다. 따라서, BS 포지션 레퍼런스 TX DNN(120)은 BS(108)의 RF 프런트 엔드(124)에 대한 출력으로서 레퍼런스 신호(138)를 제공한다. RF 프론트엔드(124)는 출력을 프로세싱하고, 프로세싱된 출력을 아날로그 신호로 변환하며, 레퍼런스 신호(138)의 UE(110)로의 RF 전송(152)(RF 전송(152-1 및 152-2)으로 도시됨)을 위한 적절한 캐리어 주파수로 아날로그 신호를 변조한다.In operation, the BS position reference TX DNN (120), BS position RX DNN (128), UE position reference RX DNN (134), UE position feedback TX DNN (148) or a combination thereof may be used in one of the RAT-assisted UE positioning operations. Jointly trained or jointly organized to carry out the above. In at least some embodiments, the BS position reference TX DNN 120 receives reference signal information 122 as input. BS Position Reference TX DNN 120 outputs reference signal information 122 (and any other inputs) suitable for RF transmission to UE 110 and processing by UE Position Reference RX DNN 134 at UE 110. A reference signal 138 is generated. In at least one embodiment, the reference signal 138 output represents a positioning reference signal that is a downlink position reference signal that includes symbols specific to UE positioning. However, the reference signal 138 output may represent other types of reference signals, such as CSI-RS or SS/PBCH. As part of this joint training or other configuration, in at least one embodiment, the BS position reference TX DNN 120 actually provides reference signal 138 or another reference signal for transmission by BS 108 to UE 110. Trained or configured to create and configure. Accordingly, the BS Position Reference TX DNN 120 provides a reference signal 138 as an output to the RF front end 124 of the BS 108. The RF frontend 124 processes the output, converts the processed output to an analog signal, and RF transmits 152 (RF transmits 152-1 and 152-2) of the reference signal 138 to the UE 110. (shown as ) modulates the analog signal with an appropriate carrier frequency.
적어도 일부 실시예에서, 다수의 BS(108)는 레퍼런스 신호(138)를 생성하여 UE(110)에 전송하기 위한 대응하는 BS 포지션 레퍼런스 TX DNN(120)으로 구성된다. 그러한 실시예에서, 제1 BS는 서빙/레퍼런스 BS(108-1)의 역할을 하고, 나머지 BS는 이웃 BS(108-2)이다. 서빙 BS(108-1)는 이웃 BS(108-2)의 BS 포지션 레퍼런스 TX DNN(120-2)을 구성하기 위해 기지국간 인터페이스(114)를 통해 각각의 이웃 BS(108-2)와 통신할 수 있다. 예를 들어, 서빙 BS(108-1)는 서빙 셀의 동작 특성(예: 주파수, 대역폭 등), UE 보고 RSRP, 도플러 추정, 배포 정보(예: 도시/지방 배포 또는 각도 추정이 BS(108)에 의해 수행되는지 여부) 등에 기초하여 이웃 BS(108-2)의 BS 포지션 레퍼런스 TX DNN(120-2)을 구성할 수 있다. 다른 실시예에서, BS(108)가 다중 안테나 어레이를 포함하는 경우, 각각의 안테나 어레이는 BS 포지션 레퍼런스 TX DNN(120)과 연관될 수 있다. 적어도 일부 실시예에서, 서빙 BS(108-1)는 BS 포지션 레퍼런스 TX DNN(120)에 추가하여 BS 포지션 RX DNN(128)을 구현한다.In at least some embodiments, multiple BSs 108 are configured with corresponding BS position reference TX DNNs 120 for generating and transmitting reference signals 138 to UE 110 . In such an embodiment, the first BS acts as the serving/reference BS 108-1, and the remaining BSs are neighboring BSs 108-2. The serving BS 108-1 communicates with each neighboring BS 108-2 via the inter-base station interface 114 to configure the BS position reference TX DNN 120-2 of the neighboring BS 108-2. You can. For example, the serving BS 108-1 may provide the operating characteristics of the serving cell (e.g., frequency, bandwidth, etc.), UE reported RSRP, Doppler estimates, distribution information (e.g., urban/rural distribution, or angle estimates) to BS 108-1. The BS position reference TX DNN (120-2) of the neighboring BS (108-2) can be configured based on whether the TX DNN (120-2) is performed by . In another embodiment, where BS 108 includes multiple antenna arrays, each antenna array may be associated with a BS position reference TX DNN 120. In at least some embodiments, serving BS 108-1 implements a BS position RX DNN 128 in addition to a BS position reference TX DNN 120.
UE(110)에서, 하나 이상의 구성요소는 수신된 레퍼런스 신호(138)에 대해 RSRP, RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT 등과 같은 레퍼런스 신호 측정(142)을 수행한다. UE(110)는 UE 포지션 레퍼런스 RX DNN(134)에 대한 입력으로서 레퍼런스 신호 측정(142)을 제공한다. 대안적으로, RF 프런트 엔드(136)는 UE 포지션 레퍼런스 RX DNN(134)에 대한 입력으로서 레퍼런스 신호(138)(또는 그 표현)를 제공할 수 있다. 그러면 UE 포지션 레퍼런스 RX DNN(134)은 레퍼런스 신호(138)에 대한 하나 이상의 레퍼런스 신호 측정(142)을 계산할 수 있다. 적어도 일부 실시예에서, UE(110)의 센서로부터의 센서 데이터(140)와 같은 다른 입력은 UE 포지션 레퍼런스 RX DNN(134)에 대한 입력으로서 동시에 제공된다. 센서 데이터(140) 입력의 예로는 GPS 데이터, 카메라 데이터, 가속도계 데이터, IMU 데이터, 고도계 데이터, 온도 데이터, 기압계 데이터, 객체 검출 센서(예: 레이더 센서, 라이더 센서, 이미징 센서 또는 구조광 기반 깊이) 등이 포함된다. 이들 입력으로부터, 그리고 공동 트레이닝 또는 다른 구성에 기초하여, UE 포지션 레퍼런스 RX DNN(134)은 UE(110)와 연관된 UE 측정 및 센서 보고(144)를 출력하도록 동작한다. 예를 들어, UE 포지션 레퍼런스 RX DNN(134)은 UE 측정 및 센서 보고(144)를 나타내는 출력을 생성하기 위해 레퍼런스 신호 측정(142) 또는 레퍼런스 신호(138) 자체를 프로세싱한다. 다른 실시예에서, UE 포지션 레퍼런스 RX DNN(134)은 또한 센서 데이터(140) 입력을 프로세싱하고 입력된 센서 데이터(140)를 레퍼런스 신호 측정(들)과 융합하여 UE 측정 및 센서 보고(144)를 나타내는 출력을 생성한다.At the UE 110, one or more components perform reference signal measurements 142, such as RSRP, RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT, etc., on the received reference signal 138. UE 110 provides reference signal measurements 142 as input to UE position reference RX DNN 134. Alternatively, RF front end 136 may provide reference signal 138 (or a representation thereof) as an input to UE position reference RX DNN 134. The UE position reference RX DNN 134 may then calculate one or more reference signal measurements 142 for the reference signal 138. In at least some embodiments, other inputs, such as sensor data 140 from sensors of UE 110, are simultaneously provided as inputs to UE position reference RX DNN 134. Examples of sensor data 140 inputs include GPS data, camera data, accelerometer data, IMU data, altimeter data, temperature data, barometer data, object detection sensors (e.g., radar sensors, lidar sensors, imaging sensors, or structured light-based depth). etc. are included. From these inputs, and based on joint training or other configuration, UE position reference RX DNN 134 operates to output UE measurements and sensor reports 144 associated with UE 110 . For example, the UE position reference RX DNN 134 processes the reference signal measurements 142 or the reference signal 138 itself to generate output representative of UE measurements and sensor reports 144. In another embodiment, the UE position reference RX DNN 134 also processes sensor data 140 input and fuses the input sensor data 140 with reference signal measurement(s) to produce UE measurements and sensor reports 144. Generates output that represents
UE 포지션 레퍼런스 RX DNN(134)은 UE 측정 및 센서 보고(144)를 나타내는 출력을 입력으로서 UE 포지션 피드백 TX DNN(148)에 제공한다. 이 입력으로부터, UE 포지션 피드백 TX DNN(148)은 UE 측정 및 센서 보고(144)를 나타내는 출력을 생성하고 UE(110)의 RF 프런트 엔드(136)에 출력을 제공한다. RF 프론트 엔드(136) 송수신기(transceiver)는 UE 측정 및 센서 보고(144)를 포함하는 RF 신호(154)(무선 통신)를 생성하고 서빙 BS(108-1)로 전송하기 위한 출력을 프로세싱한다. UE(110)는 RF 신호(154)를 구성하고 서빙 BS(108-1)에 전송하기 위해, RRC(Radio Resource Control) 프로토콜, LTE(Long Term Evolution) 포지셔닝 프로토콜(LPP) 등과 같은 다양한 메시징 메커니즘을 사용할 수 있다. 따라서, UE(110)의 UE 포지션 피드백 TX DNN(148)은 생성된 출력을 RF 프런트 엔드(136)에 제공하고, 그 결과 출력은 프로세싱되어 아날로그 신호로 변환된 다음, 서빙 BS(108-1)로의 RF 전송을 위해 적절한 캐리어 주파수로 변조된다.The UE position reference RX DNN 134 provides output representing UE measurements and sensor reports 144 as input to the UE position feedback TX DNN 148. From this input, UE position feedback TX DNN 148 generates output representing UE measurements and sensor reports 144 and provides output to the RF front end 136 of UE 110. The RF front end 136 transceiver generates RF signals 154 (wireless communications) including UE measurements and sensor reports 144 and processes the output for transmission to serving BS 108-1. UE 110 uses various messaging mechanisms, such as Radio Resource Control (RRC) protocol, Long Term Evolution (LTE) Positioning Protocol (LPP), etc., to construct and transmit RF signal 154 to serving BS 108-1. You can use it. Accordingly, the UE position feedback TX DNN 148 of the UE 110 provides the generated output to the RF front end 136, where the resulting output is processed and converted to an analog signal, and then to the serving BS 108-1. It is modulated to the appropriate carrier frequency for RF transmission to the radio.
서빙 BS(108-1)에서, RF 프론트 엔드(124)는 UE(110)로부터 RF 신호(154)를 수신하고 RF 신호(154)를 UE 측정 및 센서 보고(144)를 나타내는 디지털 신호로 변환한다. 다음으로, RF 프런트 엔드(124)는 디지털 신호를 서빙 BS(108-1)의 BS 포지션 RX DNN(128)에 대한 입력으로 제공한다. 이 입력으로부터, 그리고 공동 트레이닝 또는 다른 구성에 기초하여, BS 포지션 RX DNN(128)은 UE(110)와 연관된 UE 포지션 추정(130)을 출력하도록 동작한다. 예를 들어, BS 포지션 RX DNN(128)은 입력으로서 수신된 UE 측정 및 센서 보고(144)로부터의 레퍼런스 신호 측정(들) 및 UE 센서 데이터(140)를 프로세싱한다. 이들 입력으로부터, BS 포지션 RX DNN(128)은 UE(110)에 대한 포지션 추정(130)을 나타내는 출력을 생성한다. 적어도 일부 실시예에서, UE 포지션 추정(130)은 UE(110)에 의해 제공되는 레퍼런스 신호 측정(들)(142)을 통합할 뿐만 아니라, UE 센서 데이터(140)도 통합하여, 예를 들어 UE의 로컬 상황, UE 배향의 표시, 움직임(예를 들어, 회전, 방향 등)과 같은 2차 정보 등을 포함하는 UE 포지션 추정을 생성한다. 이와 같이, UE 센서 데이터(140)를 고려함으로써, 서빙 BS(108-1)는 종래의 RAT-지원 포지셔닝 기술보다 더 정확하고 의미 있는 UE 포지션 추정을 생성할 수 있다. 적어도 일부 실시예에서, 서빙 BS(108-1)는 UE 포지션 추정(130)을 프로세싱하거나 추가 프로세싱을 위해 UE 포지션 추정(130)을 무선 통신 시스템(100)의 하나 이상의 다른 구성요소에 전송한다.At serving BS 108-1, RF front end 124 receives RF signal 154 from UE 110 and converts RF signal 154 into digital signals representing UE measurements and sensor reports 144. . Next, the RF front end 124 provides a digital signal as an input to the BS position RX DNN 128 of the serving BS 108-1. From this input, and based on joint training or other configuration, BS Position RX DNN 128 operates to output a UE position estimate 130 associated with UE 110. For example, BS Position RX DNN 128 processes reference signal measurement(s) and UE sensor data 140 from UE measurements and sensor reports 144 received as input. From these inputs, BS Position RX DNN 128 produces an output representing a position estimate 130 for UE 110. In at least some embodiments, UE position estimate 130 not only integrates reference signal measurement(s) 142 provided by UE 110, but also integrates UE sensor data 140, e.g. Generates a UE position estimate including local context, an indication of UE orientation, and secondary information such as movement (e.g., rotation, direction, etc.). As such, by considering UE sensor data 140, serving BS 108-1 can generate a more accurate and meaningful UE position estimate than conventional RAT-assisted positioning techniques. In at least some embodiments, serving BS 108 - 1 processes UE position estimate 130 or transmits UE position estimate 130 to one or more other components of wireless communication system 100 for further processing.
적어도 일부 실시예에서, 서빙 BS(108-1)는 각각 UE 측정 및 센서 보고(144) 또는 다른 UE(110)와 연관된 UE 측정 보고(UE 센서 데이터 없음)를 포함하는 신호를 다수의 UE(110)로부터 수신할 수 있다. 이들 실시예에서, 서빙 BS(108-1)의 BS 포지션 RX DNN(128)은 2개 이상의 개별 UE(110)에 대해 계산된 UE 포지션 추정(130)을 비교하여 포지션 추정(130)이 개별 UE(110)가 동일한 공간을 점유한다는 것을 나타내는지 여부를 결정한다. 포지션 추정(130)이 둘 이상의 개별 UE(110)가 동일한 공간을 점유하고 있음을 나타내는 경우, 서빙 BS(108-1)(또는 다른 셀룰러 네트워크 구성요소)는 BS 포지션 RX DNN(128)이 포지셔닝 오류를 발생시켰으며 다수의 개별 객체가 동일한 물리적 공간을 점유할 수 없기 때문에 개선되어야 한다고 결정한다. 서빙 BS(108-1)(또는 다른 셀룰러 네트워크 구성요소)는 식별된 포지셔닝 오류를 수정하기 위해, 가중치와 같은 BS 포지션 RX DNN(128)의 하나 이상의 파라미터들을 조정하는 작업을 진행한다.In at least some embodiments, the serving BS 108 - 1 sends signals to multiple UEs 110 each including UE measurements and sensor reports 144 or UE measurement reports (without UE sensor data) associated with other UEs 110 . ) can be received from. In these embodiments, the BS Position RX DNN 128 of the Serving BS 108-1 compares the UE position estimates 130 calculated for two or more individual UEs 110 to determine whether the position estimate 130 is specific to an individual UE. Determine whether 110 indicates that they occupy the same space. If the position estimate 130 indicates that two or more individual UEs 110 are occupying the same space, the serving BS 108-1 (or another cellular network component) determines that the BS position RX DNN 128 has a positioning error. It is determined that improvements must be made because multiple individual objects cannot occupy the same physical space. The serving BS 108-1 (or other cellular network component) adjusts one or more parameters of the BS position RX DNN 128, such as weights, to correct the identified positioning error.
설명된 기술은 BS(108)가 UE(110)에 레퍼런스 신호를 전송하는 것을 포함하지만, UE(110)는 유사하게 레퍼런스 신호를 BS(108)에 전송할 수 있다. 이 구성에서, UE 포지션 피드백 TX DNN(148) 또는 UE(110)의 다른 TX DNN은 SRS와 같은 레퍼런스 신호를 전송하기 위한 BS(108)의 BS 포지션 레퍼런스 TX DNN(120)과 유사하게 구성된다. UE(110)의 UE 포지션 피드백 TX DNN(148)은 또한 UE(110)에서 이용가능한 하나 이상의 센서로부터의 센서 데이터(140)로 레퍼런스 신호를 증강(augment)시키고 증강된 레퍼런스 신호를 나타내는 출력을 생성할 수 있다. 그 다음, UE(110)는 증강된 레퍼런스 신호를 서빙 BS(108-1)에 전송한다. 서빙 BS(108-1)의 BS 포지션 RX DNN(128-1)은 적어도 하나의 구성에서, UE(110)로부터 수신된 레퍼런스 신호에 대해 하나 이상의 측정을 수행하고 UE가 전송한 증강된 레퍼런스 신호의 일부로서 수신된 UE 센서 데이터(140) 및 레퍼런스 신호 측정에 기초하여 UE 포지션 추정(130)을 계산한다. 대안적인 실시예에서, BS(108)에서 증강된 레퍼런스 신호 또는 측정 및 센서 보고를 프로세싱하는 대신, 적어도 하나의 구성에서, 로컬로 생성된 증강된 레퍼런스 신호 측정(또는 UE 제공 측정 및 센서 보고)을 관리 구성요소(150)에 전송한다. 이 실시예에서, 관리 구성요소(150)는 UE 포지션 추정을 계산하기 위해 BS(108)로부터 수신된 레퍼런스 신호 측정 및 UE 센서 데이터를 프로세싱하도록 구성된 RX 신경망을 구현한다.Although the described technique involves BS 108 transmitting a reference signal to UE 110, UE 110 may similarly transmit a reference signal to BS 108. In this configuration, the UE position feedback TX DNN 148 or another TX DNN of UE 110 is configured similarly to the BS position reference TX DNN 120 of BS 108 for transmitting reference signals such as SRS. The UE position feedback TX DNN 148 of UE 110 also augments the reference signal with sensor data 140 from one or more sensors available at UE 110 and generates an output representing the augmented reference signal. can do. Next, UE 110 transmits the augmented reference signal to serving BS 108-1. The BS position RX DNN 128-1 of the serving BS 108-1, in at least one configuration, performs one or more measurements on a reference signal received from the UE 110 and an augmented reference signal transmitted by the UE. A UE position estimate 130 is calculated based on, as part of, the received UE sensor data 140 and reference signal measurements. In an alternative embodiment, instead of processing augmented reference signals or measurements and sensor reports at BS 108, in at least one configuration, locally generated augmented reference signal measurements (or UE provided measurements and sensor reports) are used. Transmit to management component 150. In this embodiment, management component 150 implements an RX neural network configured to process UE sensor data and reference signal measurements received from BS 108 to calculate UE position estimates.
위에서 언급하고 여기에 더 자세히 설명한 바와 같이, BS(108)와 UE(110)는 각각 하나 이상의 DNN 또는 전체 RAT-지원 UE 포지셔닝 프로세스를 용이하게 하기 위해 컨텍스트-특정(context-specific) 파라미터들에 기초하여 공동으로 트레이닝되고 선택되는 다른 신경망을 사용한다. 이러한 신경망의 공동 트레이닝, 선택 및 유지 관리를 관리하기 위해, 시스템(100)은 적어도 하나의 실시예에서, 관리 인프라스트럭처 구성요소(150)(또는 간략하게 설명하기 위해 "관리 구성요소(150)")를 더 포함한다. 이 관리 구성요소(150)는 예를 들어 코어 네트워크(102) 또는 WAN(104) 내와 같은 무선 통신 시스템(100)의 네트워크 인프라스트럭처(106) 내의 서버 또는 다른 구성요소를 포함할 수 있다. 또한, 도시된 예에서는 별도의 구성요소로 도시되어 있지만, BS(108)는 적어도 일부 실시예에서 관리 구성요소(150)를 구현한다. 관리 구성요소(150)에 의해 제공되는 감독(oversight) 기능은 예를 들어, 신경망의 공동 트레이닝을 감독하는 것, BS(108) 또는 UE(110)에 대한 특정 신경망 아키텍처 구성의 선택을 그들의 특정 성능 또는 기타 구성요소-특정 파라미터들에 기초하여 관리하는 것, 신경망 구성 선택을 위해 성능 업데이트를 수신하고 프로세싱하는 것, 신경망 트레이닝이나 선택 등을 위해 피드백을 수신하고 프로세싱하는 것의 일부 또는 전부를 포함할 수 있다. As mentioned above and described in more detail herein, BS 108 and UE 110 each use one or more DNNs or a full RAT-assisted UE positioning process based on context-specific parameters to facilitate the process. This uses different neural networks that are jointly trained and selected. To manage the joint training, selection, and maintenance of these neural networks, system 100, in at least one embodiment, includes a management infrastructure component 150 (or, for brevity, “management component 150”). ) further includes. This management component 150 may include servers or other components within the network infrastructure 106 of the wireless communication system 100, such as within the core network 102 or WAN 104, for example. Additionally, although shown as a separate component in the illustrated example, BS 108 implements management component 150 in at least some embodiments. Oversight functions provided by the management component 150 may include, for example, overseeing the joint training of neural networks, selection of specific neural network architecture configurations for the BS 108 or UE 110 to determine their specific performance. or other components - which may include some or all of managing based on specific parameters, receiving and processing performance updates for neural network configuration selection, receiving and processing feedback for neural network training or selection, etc. there is.
도 4와 관련하여 더 상세히 후술되는 바와 같이, 일부 실시예에서, 관리 구성요소(150)는 후보 신경망 아키텍처 구성(414)(도 4)의 세트(412)(도 4)를 유지한다. 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 대응하는 신경망을 구현하는 구성요소의 현재 성능, 송신 체인(transmission chain) 내 다른 구성요소의 현재 성능, 수신 체인(receiving chain) 내 다른 구성요소의 현재 성능 또는 이들의 조합에 적어도 부분적으로 기초하여 대응하는 RAT-지원 UE 포지셔닝 경로 내의 특정 구성요소에서 사용될 후보 신경망 아키텍처 구성(414)을 선택할 수 있다. 이러한 성능에는 예를 들어 센서 성능, 프로세싱 리소스 성능, 배터리/전원 성능, RF 안테나 성능, 구성요소의 하나 이상의 액세서리 성능 등이 포함될 수 있다. BS(108) 및 UE(110)에 대한 이들 성능을 나타내는 정보는 관리 구성요소(150)에 의해 각각 BS 성능 정보(420)(도 4) 및 UE 성능 정보(422)(도 4)로서 획득되어 저장된다. 관리 구성요소(150)는 또한 채널의 캐리어 주파수, 알려진 객체 또는 다른 간섭자의 존재 등과 같은 대응하는 채널 또는 환경의 전파 채널의 파라미터들 또는 다른 측면들을 고려할 수 있다.As described in more detail below with respect to Figure 4, in some embodiments, management component 150 maintains a set 412 (Figure 4) of candidate neural network architecture configurations 414 (Figure 4). The management component 150 (or other network component) can determine the current performance of the component implementing the corresponding neural network, the current performance of other components in the transmission chain, and the current performance of other components in the receiving chain. A candidate neural network architecture configuration 414 may be selected to be used in a particular component within the corresponding RAT-assisted UE positioning path based at least in part on the current performance of or a combination thereof. These capabilities may include, for example, sensor performance, processing resource performance, battery/power performance, RF antenna performance, performance of one or more accessories of the component, etc. Information representative of these capabilities for BS 108 and UE 110 is obtained by management component 150 as BS performance information 420 (FIG. 4) and UE performance information 422 (FIG. 4), respectively. It is saved. Management component 150 may also consider parameters or other aspects of the propagation channel of the corresponding channel or environment, such as the channel's carrier frequency, the presence of known objects or other interferers, etc.
이러한 접근 방식을 지원하기 위해, 일부 실시예에서, 관리 구성요소(150)는 서로 다른 성능/컨텍스트 조합에 대한 후보 신경망 아키텍처 구성(414)의 서로 다른 조합의 공동 트레이닝을 관리할 수 있다. 그 다음, 관리 구성요소(150)는 BS(108)로부터 성능 정보(420), UE(110)로부터 성능 정보(422), 또는 둘 다를 획득할 수 있고, 이 성능 정보로부터 관리 구성요소(150)는 대응하는 표시된 성능, RF 시그널링 환경 등에 적어도 부분적으로 기초하여 각 구성요소에 대한 후보 신경망 아키텍처 구성(414)의 세트(412)로부터 신경망 아키텍처 구성을 선택한다. 적어도 일부 실시예에서, 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 BS(108)에 대한 특정 성능 세트에 대한 각각의 후보 신경망 아키텍처 구성이 UE(110)에 대한 특정 성능 세트에 대한 단일 대응하는 후보 신경망 아키텍처 구성과 공동으로 트레이닝되도록, 후보 신경망 아키텍처 구성을 페어링된(paired) 서브 세트로로 공동 트레이닝한다. 다른 실시예에서, 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 BS(108)에 대한 각 후보 구성이 UE(110)에 대한 다수의 후보 구성과 일대다 대응을 갖고 그 반대의 경우도 가능하도록 후보 신경망 아키텍처 구성을 관리한다.To support this approach, in some embodiments, management component 150 may manage joint training of different combinations of candidate neural network architecture configurations 414 for different performance/context combinations. Management component 150 may then obtain performance information 420 from BS 108, performance information 422 from UE 110, or both, and from this performance information, management component 150 selects a neural network architecture configuration from the set 412 of candidate neural network architecture configurations 414 for each component based at least in part on the corresponding indicated performance, RF signaling environment, etc. In at least some embodiments, management component 150 (or another network component) determines that each candidate neural network architecture configuration for a particular performance set for BS 108 is a single candidate neural network architecture configuration for a particular performance set for UE 110. Co-train candidate neural network architecture configurations into paired subsets, such that they are co-trained with corresponding candidate neural network architecture configurations. In other embodiments, management component 150 (or other network component) ensures that each candidate configuration for BS 108 has a one-to-many correspondence with multiple candidate configurations for UE 110 and vice versa. Manage the candidate neural network architecture configuration to make it possible.
따라서, 시스템(100)은 호환성을 위해 특별히 설계되지 않았을 수 있는 독립적으로 설계된 프로세스 블록보다는, UE 포지셔닝을 위해 하나 이상의 BS(108)와 하나 이상의 UE(110) 사이의 관리되고 공동 트레이닝되고 선택적으로 사용되는 신경망 세트에 의존하는 RAT-지원 UE 포지셔닝 접근 방식을 활용한다. 이는 향상된 유연성을 제공할 뿐만 아니라, 어떤 상황에서는 각 디바이스에서 더 빠른 프로세싱을 제공할 수 있을 뿐만 아니라 더 정확한 UE 포지션 추정 및 레퍼런스 신호, UE 측정 및 센서 보고의 더 효율적인 전송 및 프로세싱을 제공할 수 있다.Accordingly, the system 100 provides managed, co-trained and selective use between one or more BSs 108 and one or more UEs 110 for UE positioning, rather than independently designed process blocks that may not have been specifically designed for compatibility. utilizes a RAT-assisted UE positioning approach that relies on a set of neural networks that This not only provides increased flexibility, but in some situations can provide faster processing on each device, as well as more accurate UE position estimation and reference signals, more efficient transmission and processing of UE measurements and sensor reports. .
도 2는 일부 실시예에 따른 UE(110)에 대한 예시적인 하드웨어 구성을 도시한다. 도시된 하드웨어 구성은 하나 이상의 실시예의 신경망 기반 프로세스에 가장 직접적으로 관련된 프로세싱 구성요소 및 통신 구성요소를 나타내고, 디스플레이, 비-센서 주변 기기, 외부 전원 공급 디바이스 등과 같은 전자 디바이스에서 자주 구현되는 것으로 잘 이해되는 특정 구성요소를 생략한다는 것에 유의한다.2 shows an example hardware configuration for UE 110 according to some embodiments. The depicted hardware configuration represents the processing components and communication components most directly related to the neural network-based process of one or more embodiments, and is well understood as frequently implemented in electronic devices such as displays, non-sensor peripherals, external power supplies, etc. Note that certain components are omitted.
도시된 구성에서, UE(110)는 하나 이상의 안테나(202)를 갖는 RF 프런트 엔드(136) 및 하나 이상의 RAT를 지원하기 위한 하나 이상의 모뎀을 갖는 RF 안테나 인터페이스(204)를 포함한다. RF 프런트 엔드(136)는 다양한 유형의 무선 통신을 용이하게 하기 위해 UE(110)의 하나 이상의 프로세서(206)와 안테나(202) 사이의 시그널링을 수행하고 프로세싱하는 물리적(PHY) 송수신기 인터페이스로서 사실상 동작한다. 안테나(202)는 서로 유사하거나 다르게 구성된 다중 안테나의 하나 이상의 어레이로 배열될 수 있고, 대응하는 RAT와 연관된 하나 이상의 주파수 대역에 동조될 수 있다. 하나 이상의 프로세서(206)는 예를 들어, 하나 이상의 중앙 프로세싱 유닛(CPU), 그래픽 프로세싱 유닛(GPU), 텐서 프로세싱 유닛(TPU) 또는 기타 주문형 집적 회로(ASIC) 등을 포함할 수 있다. 예를 위해, 프로세서(206)는 운영 체제 및 다양한 사용자 레벨 소프트웨어 애플리케이션을 실행하기 위해 UE(110)에 의해 활용되는 애플리케이션 프로세서(AP)뿐만 아니라 RF 프런트 엔드(136)의 기저대역 프로세서 또는 모뎀에 의해 활용되는 하나 이상의 프로세서를 포함할 수 있다. UE(110)는 RAM(Random Access Memory), ROM(Read-Only Memory), 캐시, 플래시 메모리, SSD(Solid-State Drive) 또는 기타 대용량 저장 디바이스 등과 같은 데이터 및/또는 실행가능한 명령어를 저장하기 위해 전자 디바이스에 의해 사용되는 다양한 매체 중 임의의 것을 포함하는 하나 이상의 컴퓨터 판독가능 매체(208)를 더 포함한다. 예시 및 간결성을 용이하게 하기 위해, 컴퓨터 판독가능 매체(208)는 프로세서(206)에 의한 실행을 위한 데이터 및 명령어를 저장하기 위해 시스템 메모리 또는 다른 메모리의 빈번한 사용을 고려하여 본 명세서에서 "메모리(208)"로 지칭되지만, "메모리(208)"에 대한 언급은 달리 명시되지 않는 한 다른 유형의 저장 매체에도 동일하게 적용된다는 것으로 이해될 것이다.In the depicted configuration, UE 110 includes an RF front end 136 with one or more antennas 202 and an RF antenna interface 204 with one or more modems to support one or more RATs. RF front end 136 operates in effect as a physical (PHY) transceiver interface that performs and processes signaling between one or more processors 206 and antennas 202 of UE 110 to facilitate various types of wireless communications. do. Antennas 202 may be arranged in one or more arrays of multiple antennas similarly or differently configured, and may be tuned to one or more frequency bands associated with a corresponding RAT. One or more processors 206 may include, for example, one or more central processing units (CPUs), graphics processing units (GPUs), tensor processing units (TPUs), or other application specific integrated circuits (ASICs). For example, processor 206 may be implemented by a baseband processor or modem of RF front end 136 as well as an application processor (AP) utilized by UE 110 to run an operating system and various user-level software applications. It may include one or more processors utilized. The UE 110 is used to store data and/or executable instructions, such as random access memory (RAM), read-only memory (ROM), cache, flash memory, solid-state drive (SSD), or other mass storage devices. It further includes one or more computer-readable media 208 including any of a variety of media used by electronic devices. For ease of illustration and brevity, computer-readable medium 208 is referred to herein as “memory ( 208), but it will be understood that reference to “memory 208” applies equally to other types of storage media, unless otherwise specified.
적어도 일 실시예에서, UE(110)는 본 명세서에서 센서 세트(210)로 지칭되는 복수의 센서를 더 포함하며, 이들 중 적어도 일부는 하나 이상의 실시예의 신경망 기반 방식에서 활용된다. 일반적으로, 센서 세트(210)의 센서는 예를 들어, UE(110)의 위치, UE(110)의 배향, 움직임, 또는 이들의 조합에 적어도 일부 영향을 미치거나 반영하는 파라미터를 감지할 가능성이 있는, 사용자에 의한 UE(110)의 환경 또는 UE(110) 사용의 일부 측면을 감지하는 센서들을 포함한다. 센서 세트(210)의 센서는 레이더 센서, 라이더 센서, 이미징 센서, 구조광 기반 깊이 센서 등과 같은 객체 검출을 위한 하나 이상의 센서를 포함할 수 있다. 센서 세트(210)는 또한 GPS 센서, 글로벌 내비게이션 위성 시스템(GNSS) 센서, 관성 측정 유닛(IMU) 센서, 시각적 주행 거리 측정 센서, 자이로스코프, 기울기 센서 또는 기타 경사계, 초광대역(UWB) 기반 센서 등과 같은 위성 포지셔닝 센서와 같이 UE(110)의 포지션 또는 포즈(pose)/배향을 결정하기 위한 하나 이상의 센서를 포함할 수 있다. 센서 세트(210)의 센서 유형의 다른 예는 온도 센서, 기압계, 고도계 등과 같은 환경 센서 또는 사용자에 의한 이미지 캡처용 카메라, 얼굴 검출용 카메라, 입체 관찰 또는 시각적 주행 거리 측정용 카메라, 디바이스의 피처(feature)에 근접한 객체를 검출하기 위한 광 센서, 객체 검출 센서(예: 레이더 센서, 라이더 센서, 이미징 센서 또는 구조광 기반 깊이 센서) 등과 같은 이미징 센서를 포함할 수 있다. UE(110)는 하나 이상의 배터리(212) 또는 다른 휴대용 전원뿐만 아니라 터치 스크린, 사용자 조작가능 입/출력 디바이스(예: "버튼" 또는 키보드), 기타 터치/접촉 센서, 마이크로폰, 오디오 컨텐츠 캡처용 기타 보이스 센서, 비디오 컨텐츠 캡처용 이미지 센서, 열 센서(예: 사용자와의 근접성 감지용) 등과 같은 하나 이상의 사용자 인터페이스(UI) 구성요소(214)를 포함할 수 있다.In at least one embodiment, UE 110 further includes a plurality of sensors, referred to herein as sensor sets 210, at least some of which are utilized in the neural network-based approach of one or more embodiments. In general, the sensors of sensor set 210 are likely to detect parameters that at least partially affect or reflect, for example, the location of UE 110, the orientation of UE 110, movement, or a combination thereof. It includes sensors that sense some aspect of the environment of the UE 110 or the use of the UE 110 by the user. Sensors of sensor set 210 may include one or more sensors for object detection, such as a radar sensor, lidar sensor, imaging sensor, structured light-based depth sensor, etc. Sensor set 210 may also include GPS sensors, Global Navigation Satellite System (GNSS) sensors, inertial measurement unit (IMU) sensors, visual odometry sensors, gyroscopes, tilt sensors or other inclinometers, ultra-wideband (UWB) based sensors, etc. Like the same satellite positioning sensor, it may include one or more sensors for determining the position or pose/orientation of the UE 110. Other examples of sensor types in sensor set 210 include environmental sensors such as temperature sensors, barometers, altimeters, etc., or cameras for capturing images by the user, cameras for face detection, cameras for stereoscopic observation or visual odometry, and features of the device ( It may include an imaging sensor such as an optical sensor for detecting objects close to a feature, an object detection sensor (e.g., a radar sensor, a lidar sensor, an imaging sensor, or a structured light-based depth sensor). UE 110 may include one or more batteries 212 or other portable power sources, as well as a touch screen, user-operable input/output devices (e.g., “buttons” or keyboards), other touch/contact sensors, microphones, and other devices for capturing audio content. It may include one or more user interface (UI) components 214, such as a voice sensor, an image sensor for capturing video content, a thermal sensor (e.g., to detect proximity to a user), etc.
UE(110)의 하나 이상의 메모리(208)는 UE(110)에 부여된 다양한 기능을 수행하기 위해 UE(110)의 하나 이상의 프로세서(206) 및 기타 구성요소를 조작하는 실행가능한 소프트웨어 명령어 및 연관 데이터의 하나 이상의 세트를 저장한다. 실행가능한 소프트웨어 명령어 세트는 예를 들어 운영 체제(OS), 다양한 드라이버(미도시), 다양한 소프트웨어 애플리케이션을 포함한다. 실행가능한 소프트웨어 명령어 세트는 신경망 관리 모듈(216), 성능 관리 모듈(218) 또는 레퍼런스 신호 측정 모듈(220) 중 하나 이상을 더 포함한다. 신경망 관리 모듈(216)은 아래에 상세히 설명되는 바와 같이 UE(110)에 대한 하나 이상의 신경망을 구현한다. 성능 관리 모듈(218)은 신경망 구성 또는 선택과 관련될 수 있는 UE(110)의 다양한 성능을 결정하고 이러한 성능을 관리 구성요소(150)에 보고할 뿐만 아니라, RF 및 프로세싱 성능의 변경, 액세서리 가용성 또는 성능의 변경, 센서 가용성의 변경 등을 포함하는 그러한 성능들의 변경에 대해 UE(110)를 모니터링하고, 그러한 성능 및 성능의 변경을 관리 구성요소(150)에 보고하는 것을 관리한다. 위에서 설명한 것과 유사하게, 레퍼런스 신호 측정 모듈(220)은 하나 이상의 BS(108)로부터 수신된 레퍼런스 신호에 대한 RSRP, RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT 등과 같은 신호 측정을 생성하도록 동작한다.One or more memories 208 of the UE 110 contain executable software instructions and associated data that manipulate one or more processors 206 and other components of the UE 110 to perform various functions assigned to the UE 110. Stores one or more sets of The executable software instruction set includes, for example, an operating system (OS), various drivers (not shown), and various software applications. The executable software instruction set further includes one or more of a neural network management module 216, a performance management module 218, or a reference signal measurement module 220. Neural network management module 216 implements one or more neural networks for UE 110, as described in detail below. Performance management module 218 determines various performances of UE 110 that may be related to neural network configuration or selection and reports these performances to management component 150, as well as changes in RF and processing performance, accessory availability. Alternatively, it monitors the UE 110 for changes in performance, including changes in performance, changes in sensor availability, etc., and manages reporting of such performance and changes in performance to the management component 150. Similar to what was described above, the reference signal measurement module 220 is operative to generate signal measurements such as RSRP, RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT, etc. on reference signals received from one or more BSs 108. do.
UE(110)의 동작을 용이하게 하기 위해, UE(110)의 하나 이상의 메모리(208)는 이러한 동작과 연관된 데이터를 추가로 저장할 수 있다. 이 데이터는 예를 들어 디바이스 데이터(222) 및 하나 이상의 신경망 아키텍처 구성(224)을 포함할 수 있다. 디바이스 데이터(222)는 예를 들어 사용자 데이터, 멀티미디어 데이터, 빔포밍 코드북, 소프트웨어 애플리케이션 구성 정보 등을 나타낸다. 디바이스 데이터(222)는 특정 센서 또는 센서 유형의 존재 또는 부재를 포함하는 센서 세트(210)의 하나 이상의 센서에 관한 센서 성능 정보와 같은 UE(110)에 대한 성능 정보와, 존재하는 센서에 대해 그들의 대응하는 성능에 대한 하나 이상의 표현, 예를 들어 라이다 또는 레이더 센서의 범위 및 해상도, 이미징 카메라의 이미지 해상도 및 색 심도 등을 더 포함할 수 있다. 성능 정보는 예를 들어, 배터리(212)의 성능 또는 상태, UI(214)의 성능 또는 상태(예를 들어, 화면 해상도, 색 영역 또는 디스플레이의 프레임 레이트) 등에 관한 정보를 더 포함할 수 있다.To facilitate operations of UE 110, one or more memories 208 of UE 110 may additionally store data associated with such operations. This data may include, for example, device data 222 and one or more neural network architecture configurations 224. Device data 222 represents, for example, user data, multimedia data, beamforming codebook, software application configuration information, etc. Device data 222 may include performance information for the UE 110, such as sensor performance information about one or more sensors in the sensor set 210, including the presence or absence of a particular sensor or sensor type, and their information about the sensors present. It may further include one or more expressions for corresponding performance, such as range and resolution of a lidar or radar sensor, image resolution and color depth of an imaging camera, etc. Performance information may further include information about, for example, the performance or status of the battery 212, the performance or status of the UI 214 (e.g., screen resolution, color gamut, or frame rate of the display), etc.
하나 이상의 신경망 아키텍처 구성(224)은 관리 구성요소(150)에 의해 유지되는 후보 신경망 아키텍처 구성(414)의 세트(412)로부터 선택된 UE 구현 예를 나타낸다. 각각의 신경망 아키텍처 구성(224)은 UE(110)의 대응하는 신경망을 형성하기 위해 신경망 관리 모듈(216)에 의해 사용되는 대응하는 아키텍처 및/또는 파라미터 구성을 나타내는 데이터 및 기타 정보를 포함하는 하나 이상의 데이터 구조를 포함한다. 신경망 아키텍처 구성(224)에 포함된 정보는 예를 들어, 완전 연결 계층 신경망 아키텍처, 컨볼루션 계층 신경망 아키텍처, 순환 신경망 계층, 연결된 은닉(hidden) 신경망 계층의 수, 입력 계층 아키텍처, 출력 계층 아키텍처, 신경망에 의해 활용되는 노드 수, 신경망에 의해 활용되는 계수(예: 가중치 및 바이어스), 커널 파라미터, 신경망에 의해 활용되는 필터 수, 신경망에 의해 활용되는 스트라이드/풀링 구성, 각 신경망 계층의 활성화 함수(function), 신경망 계층 간의 상호 연결, 스킵할 신경망 계층 등을 지정하는 파라미터를 포함한다. 따라서, 신경망 아키텍처 구성(224)은 DNN을 정의 및/또는 형성하는 NN 형성 구성(예: 하나 이상의 NN 형성 구성요소의 조합)을 생성하기 위한 NN 형성 구성요소(예: 아키텍처 및/또는 파라미터 구성)의 임의의 조합을 포함한다.One or more neural network architecture configurations 224 represent UE implementation examples selected from a set 412 of candidate neural network architecture configurations 414 maintained by management component 150 . Each neural network architecture configuration 224 includes one or more data and other information representative of the corresponding architecture and/or parameter configuration used by the neural network management module 216 to form the corresponding neural network of the UE 110. Includes data structures. Information included in the neural network architecture configuration 224 may include, for example, a fully connected layer neural network architecture, a convolutional layer neural network architecture, a recurrent neural network layer, the number of connected hidden neural network layers, an input layer architecture, an output layer architecture, a neural network. number of nodes utilized by the neural network, coefficients (e.g. weights and biases) utilized by the neural network, kernel parameters, number of filters utilized by the neural network, stride/pooling configuration utilized by the neural network, and activation function of each neural network layer. ), interconnections between neural network layers, and parameters that specify which neural network layer to skip, etc. Accordingly, neural network architecture configuration 224 includes NN forming components (e.g., architecture and/or parameter configurations) to create a NN forming configuration (e.g., a combination of one or more NN forming components) that defines and/or forms a DNN. Contains any combination of.
도 3은 일부 실시예에 따른 BS(108)에 대한 예시적인 하드웨어 구성을 도시한다. 도시된 하드웨어 구성은 하나 이상의 실시예의 신경망 기반 프로세스에 가장 직접적으로 관련된 프로세싱 구성요소 및 통신 구성요소를 나타내고, 디스플레이, 비-센서 주변 기기, 외부 전원 공급 디바이스 등과 같은 전자 디바이스에서 자주 구현되는 것으로 잘 이해되는 특정 구성요소를 생략한다는 것에 유의한다. 또한, 도시된 다이어그램은 단일 네트워크 노드(예를 들어, 5G NR 노드 B 또는 "gNB")로서 BS(108)의 구현예를 나타내지만, BS(108)의 기능 및 그에 따른 하드웨어 구성요소는 대신에 다수의 네트워크 노드 또는 디바이스에 걸쳐 분산될 수 있고 하나 이상의 실시예의 기능을 수행하는 방식으로 분산될 수 있다는 것에 유의한다.Figure 3 shows an example hardware configuration for BS 108 according to some embodiments. The depicted hardware configuration represents the processing components and communication components most directly related to the neural network-based process of one or more embodiments, and is well understood as frequently implemented in electronic devices such as displays, non-sensor peripherals, external power supplies, etc. Note that certain components are omitted. Additionally, although the depicted diagram represents an implementation of BS 108 as a single network node (e.g., 5G NR Node B or “gNB”), the functionality of BS 108 and resulting hardware components may instead be Note that it may be distributed across multiple network nodes or devices and may be distributed in a manner that performs the functionality of one or more embodiments.
도시된 구성에서, BS(108)는 하나 이상의 안테나(302)를 갖는 RF 프런트 엔드(124) 및 하나 이상의 RAT를 지원하기 위한 하나 이상의 모뎀을 갖는 RF 안테나 인터페이스(또는 프론트 엔드)(304)를 포함하며, 이는 다양한 유형의 무선 통신을 용이하게 하기 위해 BS(108)의 하나 이상의 프로세서(306)와 안테나(302) 사이의 시그널링을 수행하고 프로세싱하는 PHY 송수신기 인터페이스로서 동작한다. 안테나(302)는 서로 유사하거나 다르게 구성된 다중 안테나의 하나 이상의 어레이로 배열될 수 있고, 대응하는 RAT와 연관된 하나 이상의 주파수 대역에 동조될 수 있다. 하나 이상의 프로세서(306)는 예를 들어, 하나 이상의 CPU, GPU, TPU 또는 기타 ASIC 등을 포함할 수 있다. BS(108)는 RAM, ROM, 캐시, 플래시 메모리, SSD 또는 기타 대용량 저장 디바이스 등과 같은 데이터 및/또는 실행가능한 명령어를 저장하기 위해 전자 디바이스에 의해 사용되는 다양한 매체 중 임의의 것을 포함하는 하나 이상의 컴퓨터 판독가능 매체(308)를 더 포함한다. UE(110)의 메모리(208)와 마찬가지로, 예시 및 간결성을 용이하게 하기 위해, 컴퓨터 판독가능 매체(308)는 프로세서(306)에 의한 실행을 위한 데이터 및 명령어를 저장하기 위해 시스템 메모리 또는 다른 메모리를 자주 사용한다는 점에서 본 명세서에서 "메모리(308)"로 지칭되지만, "메모리(308)"에 대한 언급은 달리 명시되지 않는 한 다른 유형의 저장 매체에도 동일하게 적용된다는 것으로 이해될 것이다.In the depicted configuration, BS 108 includes an RF front end 124 with one or more antennas 302 and an RF antenna interface (or front end) 304 with one or more modems to support one or more RATs. It operates as a PHY transceiver interface that performs and processes signaling between one or more processors 306 of the BS 108 and the antenna 302 to facilitate various types of wireless communications. Antennas 302 may be arranged in one or more arrays of multiple antennas similarly or differently configured, and may be tuned to one or more frequency bands associated with a corresponding RAT. One or more processors 306 may include, for example, one or more CPUs, GPUs, TPUs, or other ASICs. BS 108 is one or more computers that include any of a variety of media used by electronic devices to store data and/or executable instructions, such as RAM, ROM, cache, flash memory, SSD, or other mass storage devices. It further includes a readable medium (308). Like memory 208 of UE 110, to facilitate illustration and brevity, computer-readable medium 308 may include system memory or other memory for storing data and instructions for execution by processor 306. Although referred to as “memory 308” in this specification in that it is frequently used, it will be understood that reference to “memory 308” applies equally to other types of storage media unless otherwise specified.
적어도 일 실시예에서, BS(108)는 본 명세서에서 센서 세트(310)로 지칭되는 복수의 센서를 더 포함하며, 이들 중 적어도 일부는 하나 이상의 실시예의 신경망 기반 방식에서 활용된다. 일반적으로, 센서 세트(310)의 센서는 BS(108)의 환경의 일부 측면을 감지하고, 대응하는 UE(110)에 대한 BS(108)에 의한 RF 송신/수신 성능에 적어도 일부 영향을 미치거나 또는 이를 반영하는 파라미터를 감지할 가능성이 있는 센서들을 포함한다. 센서 세트(310)의 센서는 레이더 센서, 라이더 센서, 이미징 센서, 구조광 기반 깊이 센서 등과 같은 객체 검출을 위한 하나 이상의 센서를 포함할 수 있다. BS(108)가 모바일 BS인 경우, 센서 세트(310)는 또한 BS(108)의 포지션 또는 포즈/배향을 결정하기 위한 하나 이상의 센서를 포함할 수 있다. 센서 세트(310)의 센서 유형의 다른 예는 이미징 센서, BS(108)의 피처에 근접한 객체를 검출하기 위한 광 센서 등을 포함할 수 있다.In at least one embodiment, BS 108 further includes a plurality of sensors, referred to herein as sensor sets 310, at least some of which are utilized in the neural network-based approach of one or more embodiments. Generally, the sensors of sensor set 310 sense some aspect of the environment of BS 108 and have at least some effect on the RF transmit/receive performance by BS 108 to a corresponding UE 110 or Or, it includes sensors that have the potential to detect parameters reflecting this. The sensors of sensor set 310 may include one or more sensors for object detection, such as a radar sensor, a lidar sensor, an imaging sensor, a structured light-based depth sensor, etc. If BS 108 is a mobile BS, sensor set 310 may also include one or more sensors for determining the position or pose/orientation of BS 108. Other examples of sensor types in sensor set 310 may include imaging sensors, optical sensors for detecting objects proximate to features of BS 108, etc.
BS(108)의 하나 이상의 메모리(308)는 하나 이상의 실시예의 다양한 기능을 수행하고 BS(108)에 귀속되도록 BS(108)의 하나 이상의 프로세서(306) 및 다른 구성요소를 조작하는 실행가능한 소프트웨어 명령어 및 연관 데이터의 하나 이상의 세트를 저장한다. 실행가능한 소프트웨어 명령어 세트는 예를 들어 OS, 다양한 드라이버(도시되지 않음) 및 다양한 소프트웨어 애플리케이션을 포함한다. 실행가능한 소프트웨어 명령어 세트는 신경망 관리 모듈(314), 레퍼런스 신호 관리 모듈(316), UE 포지셔닝 관리 모듈(318), 또는 성능 관리 모듈(320) 중 하나 이상을 더 포함한다.One or more memories 308 of BS 108 may include executable software instructions to manipulate one or more processors 306 and other components of BS 108 to perform various functions of one or more embodiments and to be attributed to BS 108. and stores one or more sets of associated data. The executable software instruction set includes, for example, an OS, various drivers (not shown), and various software applications. The set of executable software instructions further includes one or more of a neural network management module 314, a reference signal management module 316, a UE positioning management module 318, or a performance management module 320.
신경망 관리 모듈(314)은 아래에 상세히 설명되는 바와 같이, BS(108)에 대한 하나 이상의 신경망을 구현한다. 레퍼런스 신호 관리 모듈(316)은 하나 이상의 레퍼런스 신호의 생성 및 전송을 관리하며, 일부 실시예에서는 신경망 관리 모듈(314)에 의해 구현되는 하나 이상의 신경망에 기초한다. UE 포지셔닝 관리 모듈(318)은 일부 실시예에서 신경망 관리 모듈(314)에 의해 구현되는 하나 이상의 신경망에 기초하는 UE 포지션 추정의 생성을 관리한다. 성능 관리 모듈(320)은 신경망 구성 또는 선택과 관련될 수 있는 BS(108)의 다양한 성능을 결정하고 이러한 성능을 관리 구성요소(150)에 보고할 뿐만 아니라, RF 및 프로세싱 성능의 변경 등을 포함하여 이러한 성능의 변경에 대해 BS(108)를 모니터링하고, 그러한 성능 및 성능의 변경을 관리 구성요소(150)에 보고하는 것을 관리한다.Neural network management module 314 implements one or more neural networks for BS 108, as described in detail below. Reference signal management module 316 manages the generation and transmission of one or more reference signals, in some embodiments based on one or more neural networks implemented by neural network management module 314. UE positioning management module 318 manages generation of UE position estimates based on one or more neural networks implemented by neural network management module 314 in some embodiments. Performance management module 320 determines various performances of BS 108 that may be related to neural network configuration or selection and reports these performances to management component 150, as well as changes in RF and processing performance, etc. This monitors the BS 108 for changes in performance and manages reporting of such performance and changes in performance to the management component 150.
BS(108)의 동작을 용이하게 하기 위해, BS(108)의 하나 이상의 메모리(308)는 이러한 동작과 연관된 데이터를 추가로 저장할 수 있다. 이 데이터는 예를 들어 BS 데이터(322) 및 하나 이상의 신경망 아키텍처 구성(324)을 포함할 수 있다. BS 데이터(322)는 예를 들어 빔포밍 코드북, 소프트웨어 애플리케이션 구성 정보 등을 나타낸다. BS 데이터(322)는 특정 센서 또는 센서 유형의 존재 또는 부재를 포함하는 센서 세트(310)의 하나 이상의 센서에 관한 센서 성능 정보와 같은 BS(108)에 대한 성능 정보와, 존재하는 센서에 대해 그들의 대응하는 성능에 대한 하나 이상의 표현, 예를 들어 라이다 또는 레이더 센서의 범위 및 해상도, 이미징 카메라의 이미지 해상도 및 색 심도 등을 더 포함할 수 있다. 하나 이상의 신경망 아키텍처 구성(324)은 관리 구성요소(150)에 의해 유지되는 후보 신경망 아키텍처 구성(414)의 세트(412)로부터 선택된 BS 구현 예를 나타낸다. 따라서, 도 2의 신경망 아키텍처 구성(224)과 마찬가지로, 각각의 신경망 아키텍처 구성(324)은 BS(108)의 대응하는 신경망을 형성하기 위해 신경망 관리 모듈(314)에 의해 사용되는 파라미터 구성 및/또는 대응하는 아키텍처를 나타내는 데이터 및 기타 정보를 포함하는 하나 이상의 데이터 구조를 포함한다.To facilitate operation of BS 108, one or more memories 308 of BS 108 may additionally store data associated with such operations. This data may include, for example, BS data 322 and one or more neural network architecture configurations 324. BS data 322 represents, for example, a beamforming codebook, software application configuration information, etc. BS data 322 may include performance information for BS 108, such as sensor performance information about one or more sensors in sensor set 310, including the presence or absence of a particular sensor or sensor type, and their It may further include one or more expressions for corresponding performance, such as range and resolution of a lidar or radar sensor, image resolution and color depth of an imaging camera, etc. One or more neural network architecture configurations 324 represent BS implementation examples selected from a set 412 of candidate neural network architecture configurations 414 maintained by management component 150 . Accordingly, like the neural network architecture configuration 224 of FIG. 2, each neural network architecture configuration 324 is a parameter configuration and/or parameter configuration used by the neural network management module 314 to form the corresponding neural network of BS 108. Contains one or more data structures containing data representing the corresponding architecture and other information.
도 4는 일부 실시예에 따른 관리 구성요소(150)에 대한 예시적인 하드웨어 구성을 도시한다. 도시된 하드웨어 구성은 하나 이상의 실시예의 신경망 기반 프로세스에 가장 직접적으로 관련된 프로세싱 구성요소 및 통신 구성요소를 나타내고 이러한 전자 디바이스에서 자주 구현되는 것으로 잘 이해되는 특정 구성요소를 생략한다는 점에 유의한다. 또한, 하드웨어 구성이 단일 구성요소에 위치하는 것으로 도시되어 있지만, 관리 구성요소(150)의 기능, 즉 하드웨어 구성요소는 대신 다수의 인프라스트럭처 구성요소 또는 노드에 걸쳐 분산될 수 있고 하나 이상의 실시예의 기능을 수행하는 방식으로 분산될 수 있다. 4 shows an example hardware configuration for management component 150 according to some embodiments. Note that the depicted hardware configurations represent the processing components and communication components most directly related to the neural network-based processes of one or more embodiments and omit certain components that are well understood to be frequently implemented in such electronic devices. Additionally, although the hardware components are shown as being located in a single component, the functionality of management component 150, i.e., the hardware components, may instead be distributed across multiple infrastructure components or nodes and may include the functionality of one or more embodiments. It can be distributed in a way that performs .
위에서 언급한 바와 같이, 네트워크 인프라스트럭처(106) 내의 임의의 다양한 구성요소 또는 구성요소의 조합은 관리 구성요소(150)를 구현할 수 있다. 설명의 용이함을 위해, 관리 구성요소(150)는 코어 네트워크(102) 중 하나의 서버 또는 다른 구성요소로서의 예시적인 구현예를 참조하여 설명되지만, 다른 실시예에서 관리 구성요소(150)는 예를 들어 BS(108)의 일부로서 구현될 수 있다.As mentioned above, any of the various components or combinations of components within network infrastructure 106 may implement management component 150. For ease of explanation, management component 150 is described with reference to an example implementation as a server or other component of one of the core networks 102, although in other embodiments management component 150 may be used, e.g. For example, it may be implemented as part of BS 108.
도시된 바와 같이, 관리 구성요소(150)는 시스템(100)의 하나 이상의 네트워크에 결합하기 위한 하나 이상의 네트워크 인터페이스(402)(예를 들어, 이더넷 인터페이스), 하나 이상의 네트워크 인터페이스(402)에 결합된 하나 이상의 프로세서(404), 및 하나 이상의 프로세서(404)에 결합된 하나 이상의 비일시적 컴퓨터 판독가능 저장 매체(406)(본 명세서에서는 간략하게 "메모리(406)"라고 함)를 포함한다. 하나 이상의 메모리(406)는 하나 이상의 실시예의 다양한 기능을 수행하고 관리 구성요소(150)에 귀속되는 관리 구성요소(150)의 하나 이상의 프로세서(404) 및 다른 구성요소를 조작하는 실행가능한 소프트웨어 명령어 및 연관 데이터의 하나 이상의 세트를 저장한다. 실행가능한 소프트웨어 명령어 세트에는 예를 들어 OS 및 다양한 드라이버(미도시)가 포함된다. 하나 이상의 메모리(406)에 저장된 소프트웨어는 트레이닝 모듈(408) 또는 신경망 선택 모듈(410) 중 하나 이상을 더 포함할 수 있다. 트레이닝 모듈(408)은 하나 이상의 트레이닝 데이터 세트(416)를 사용하여 UE 포지셔닝 경로의 송신 및 수신 디바이스에서 사용될 수 있는 후보 신경망 세트(412)에 대한 후보 신경망 아키텍처 구성(414)의 공동 트레이닝을 관리하도록 동작한다. 트레이닝은 오프라인 상태(즉, 통신 프로세싱에 활발히 참여하지 않는 동안) 및/또는 온라인 상태에서(즉, 통신 프로세싱에 활발히 참여하는 동안) 신경망을 트레이닝하는 것을 포함할 수 있다. 또한, 트레이닝은 결과가 송신 경로의 반대쪽 끝에서 DNN 트레이닝에 전달되거나 영향을 주지 않고 각 신경망이 자체 트레이닝 데이터 세트에 대해 개별적으로 트레이닝되도록 개별적이거나 분리될 수 있고 또는 트레이닝은 데이터 스트림 송신 경로의 신경망이 동일하거나 보완적인 데이터 세트에 대해 공동으로 트레이닝되도록 공동 트레이닝일 수 있다.As shown, management component 150 includes one or more network interfaces 402 (e.g., an Ethernet interface) for coupling to one or more networks of system 100, coupled to one or more network interfaces 402. It includes one or more processors 404, and one or more non-transitory computer-readable storage media 406 (simply referred to herein as “memory 406”) coupled to the one or more processors 404. One or more memories 406 may include executable software instructions to perform the various functions of one or more embodiments and to manipulate one or more processors 404 and other components of management component 150 that are attributed to management component 150 and Stores one or more sets of related data. The executable software instruction set includes, for example, an OS and various drivers (not shown). Software stored in one or more memories 406 may further include one or more of a training module 408 or a neural network selection module 410 . The training module 408 uses one or more training data sets 416 to manage joint training of a candidate neural network architecture configuration 414 for a set of candidate neural networks 412 that can be used in transmitting and receiving devices in the UE positioning path. It works. Training may include training the neural network offline (i.e., while not actively participating in communication processing) and/or online (i.e., while actively participating in communication processing). Additionally, training can be separate or decoupled such that each neural network is trained individually on its own training data set, without the results being passed on to or impacting the DNN training at the other end of the transmission path, or training can be done by the neural network on the data stream transmission path. It can be co-training so that they are jointly trained on the same or complementary data sets.
신경망 선택 모듈(410)은 RAT-지원 UE 포지셔닝 경로에서 BS(108) 및 UE(110) 중 하나 또는 둘 다로부터 선택 관련 정보(418)를 획득, 필터링 및 프로세싱하도록 동작하며, 이 선택 관련 정보(418)를 사용하여 RAT-지원 UE 포지셔닝 경로의 송신 디바이스 및 수신 디바이스에서의 구현을 위해 후보 세트(412)로부터 공동 트레이닝된 신경망 아키텍처 구성 쌍(414)을 선택한다. 전술한 바와 같이, 이 선택 관련 정보(418)는 예를 들어 BS 성능 정보(420) 또는 UE 성능 정보(422), 현재 전파 경로 정보, 채널-특정 파라미터 등 중 하나 이상을 포함할 수 있다. 신경망 선택 모듈(410)이 선택을 한 후, 신경망 선택 모듈(410)은 선택된 구성요소와 연관된 인덱스 번호의 전송, 신경망 아키텍처 구성 자체를 나타내는 하나 이상의 데이터 구조의 전송 또는 이들의 조합을 통해 각 네트워크 구성요소에 대해 선택된 신경망 아키텍처 구성(414)의 표시 전송을 시작한다. The neural network selection module 410 is operative to obtain, filter, and process selection-related information 418 from one or both the BS 108 and the UE 110 in the RAT-assisted UE positioning path, which selection-related information ( 418) is used to select jointly trained neural network architecture configuration pairs 414 from the candidate set 412 for implementation at the transmitting device and the receiving device of the RAT-assisted UE positioning path. As described above, this selection-related information 418 may include, for example, one or more of BS capability information 420 or UE capability information 422, current propagation path information, channel-specific parameters, etc. After the neural network selection module 410 makes a selection, the neural network selection module 410 configures each network through transmission of an index number associated with the selected component, transmission of one or more data structures representing the neural network architecture configuration itself, or a combination thereof. Begins transmitting an indication of the selected neural network architecture configuration 414 for the element.
도 5는 일부 실시예에 따라 신경망을 구현하기 위한 예시적인 기계 학습(ML) 모듈(500)을 도시한다. UE 포지셔닝 경로(116)에 있는 적어도 하나의 BS(108) 및 UE(110)는 레퍼런스 신호 전송, 레퍼런스 신호에 대한 측정 수행, 레퍼런스 신호 측정과 UE 센서 데이터 융합, UE 측정 및 센서 보고 생성, 및 UE 포지셔닝 추정 생성 중 하나 이상을 위해 하나 이상의 DNN 또는 다른 신경망을 구현한다. 따라서 ML 모듈(500)은 이러한 신경망 중 하나 이상을 구현하기 위한 예시적인 모듈을 예시한다.5 shows an example machine learning (ML) module 500 for implementing a neural network, according to some embodiments. At least one BS 108 and UE 110 in the UE positioning path 116 transmit reference signals, perform measurements on the reference signals, fuse reference signal measurements with UE sensor data, generate UE measurements and sensor reports, and generate sensor reports for the UE. Implement one or more DNNs or other neural networks for one or more of the positioning estimate generation. Accordingly, ML module 500 illustrates an example module for implementing one or more of these neural networks.
도시된 예에서, ML 모듈(500)은 3개 이상의 계층으로 구성된 연결된 노드(예: 뉴런 및/또는 퍼셉트론) 그룹으로 적어도 하나의 심층 신경망(DNN)(502)을 구현한다. 계층들 사이의 노드는, 제1 계층에 있는 노드의 제1 서브세트가 제2 계층에 있는 제2 서브세트와 연결되는 부분 연결 구성, 제1 계층의 각 노드가 제2 계층의 각 노드와 연결되는 완전 연결 구성 등의 다양한 방식으로 구성가능하다. 뉴런은 입력 데이터를 프로세싱하여 0과 1 사이의 실수와 같은 연속적인 출력 값을 생성한다. 경우에 따라, 출력 값은 입력 데이터가 원하는 카테고리에 얼마나 가까운지를 나타낸다. 퍼셉트론은 입력 데이터에 대해 이진 분류와 같은 선형 분류를 수행한다. 뉴런이든 퍼셉트론이든 노드는 다양한 알고리즘을 사용하여 적응형 학습에 기초하여 출력 정보를 생성할 수 있다. DNN(502)을 사용하여 ML 모듈(500)은 단일 선형 회귀, 다중 선형 회귀, 로지스틱 회귀, 단계적 회귀, 이진 분류, 다중 클래스 분류, 다변량 적응형 회귀 스플라인, 로컬 추정 산점도 평활화 등을 포함하여 다양한 유형의 분석을 수행한다.In the example shown, the ML module 500 implements at least one deep neural network (DNN) 502 with a group of connected nodes (e.g., neurons and/or perceptrons) comprised of three or more layers. The nodes between the layers are configured in a partially connected configuration such that a first subset of nodes in a first layer is connected to a second subset in a second layer, and each node in the first layer is connected to each node in the second layer. It can be configured in various ways, such as a fully connected configuration. Neurons process input data and produce continuous output values, such as real numbers between 0 and 1. In some cases, the output value indicates how close the input data is to the desired category. Perceptron performs linear classification, such as binary classification, on input data. Nodes, whether neurons or perceptrons, can generate output information based on adaptive learning using various algorithms. Using DNN 502, ML module 500 can perform various types of regression, including single linear regression, multiple linear regression, logistic regression, stepwise regression, binary classification, multiclass classification, multivariate adaptive regression spline, local estimation scatter plot smoothing, etc. perform analysis.
일부 구현예에서, ML 모듈(500)은 지도 학습에 기초하여 적응적으로 학습한다. 지도 학습에서 ML 모듈(500)은 다양한 유형의 입력 데이터를 트레이닝 데이터로 수신한다. ML 모듈(500)은 트레이닝 데이터를 프로세싱하여 원하는 출력에 입력을 매핑하는 방법을 학습한다. 일 예로서, ML 모듈(500)은 BS 포지션 레퍼런스 신호 TX 모드에서 구현될 때, PRS, BS(108)의 성능 정보, UE(110)의 성능 정보, BS(108)의 동작 환경 특성, UE(110)의 동작 환경 특성 등과 같은 레퍼런스 신호 중 하나 이상을 입력으로 수신하고, UE(110)로의 전송을 위해 이 입력 트레이닝 데이터를 하나 이상의 구성된 출력 레퍼런스 신호에 매핑하는 방법을 학습한다. 또 다른 예로서, ML 모듈(500)은 UE 포지션 레퍼런스 신호 RX 모드에서 구현될 때, 수신된 레퍼런스 신호의 표현, UE 레퍼런스 신호 측정, UE 센서 데이터 등 중 하나 이상을 입력으로 수신하고, 이 입력 트레이닝 데이터를 UE 측정을 나타내는 출력 및 UE 센서 데이터를 UE 레퍼런스 신호 측정과 융합하는 센서 보고에 매핑하는 방법을 학습한다. 또 다른 예에서, ML 모듈(500)은 UE 포지션 피드백 TX 모드에서 구현될 때, 발신 UE 측정 및 센서 보고를 입력으로 수신하고, 예를 들어 적어도 채널 인코딩되고 RF 안테나 인터페이스를 통한 무선 전송에 적합한 출력을 생성하는 방법을 학습한다. 또 다른 예로서, ML 모듈(500)은 BS 포지션 RX 모드에서 구현될 때, UE 센서 데이터 및 UE 레퍼런스 신호 측정, BS 위치 정보, UE 위치 정보 등을 포함하는 UE 측정 및 센서 보고 중 하나 이상을 입력으로 수신하고, 적어도 하나의 UE의 포지션 추정을 나타내는 출력을 생성하는 방법을 학습한다. 적어도 일부 실시예에서, 트레이닝 프로세스는 UE의 실제 포지션과 추정된 UE 포지션의 평균 제곱 오차(MSE)를 UE의 실제 포지션과 최소화하도록 ML 모듈(500)을 트레이닝한다. 또한, TX 모드 또는 RX 모드 중 하나 또는 둘 다에서의 트레이닝은 센서 데이터를 입력으로, 성능 정보를 입력으로, RF 안테나 구성, 또는 기타 동작 파라미터 정보 등을 입력으로 사용하는 트레이닝을 더 포함할 수 있다.In some implementations, ML module 500 learns adaptively based on supervised learning. In supervised learning, the ML module 500 receives various types of input data as training data. The ML module 500 processes training data and learns how to map input to a desired output. As an example, when the ML module 500 is implemented in the BS position reference signal TX mode, PRS, performance information of the BS 108, performance information of the UE 110, operating environment characteristics of the BS 108, UE ( 110) receives as an input one or more reference signals, such as operating environment characteristics, and learns how to map this input training data to one or more configured output reference signals for transmission to the UE 110. As another example, the ML module 500, when implemented in the UE position reference signal RX mode, receives as input one or more of a representation of the received reference signal, UE reference signal measurement, UE sensor data, etc., and performs training on this input. Learn how to map data to outputs representing UE measurements and sensor reports that fuse UE sensor data with UE reference signal measurements. In another example, ML module 500, when implemented in UE position feedback TX mode, receives outgoing UE measurements and sensor reports as input and outputs, for example, at least channel encoded and suitable for wireless transmission via an RF antenna interface. Learn how to create. As another example, the ML module 500, when implemented in BS position RX mode, inputs one or more of UE measurement and sensor reports, including UE sensor data and UE reference signal measurements, BS location information, UE location information, etc. and learn how to generate an output representing the position estimate of at least one UE. In at least some embodiments, the training process trains the ML module 500 to minimize the mean square error (MSE) of the actual position of the UE and the estimated UE position relative to the actual position of the UE. Additionally, training in one or both of the TX mode or RX mode may further include training using sensor data as input, performance information as input, RF antenna configuration, or other operating parameter information, etc. as input. .
트레이닝 절차 동안, ML 모듈(500)은 레이블이 지정된 데이터 또는 알려진 데이터를 DNN(502)에 대한 입력으로 사용한다. DNN(502)은 노드를 사용하여 입력을 분석하고 대응하는 출력을 생성한다. ML 모듈(500)은 대응하는 출력을 실제 데이터와 비교하고 노드에 의해 구현된 알고리즘을 적응시켜 출력 데이터의 정확성을 향상시킨다. 그 후, DNN(502)은 적응된 알고리즘을 레이블이 지정되지 않은 입력 데이터에 적용하여 대응하는 출력 데이터를 생성한다. ML 모듈(500)은 통계 분석 및 적응형 학습 중 하나 또는 둘 모두를 사용하여 입력을 출력에 매핑한다. 예를 들어, ML 모듈(500)은 트레이닝 데이터로부터 학습된 특성을 사용하여 알려지지 않은 입력을 임계값 범위 또는 값 내에서 통계적으로 가능성이 있는 출력과 연관시킨다. 이를 통해 ML 모듈(500)은 복잡한 입력을 수신하고 대응하는 출력을 식별할 수 있다. 일부 구현예에서, 트레이닝 프로세스는 그러한 시스템에서 사용되는 데이터 인코딩/디코딩 방식의 특성과 동시에 무선 통신 시스템을 통해 전송되는 통신의 특성(예: 시간/주파수 인터리빙, 시간/주파수 디인터리빙, 컨볼루션 인코딩, 컨볼루션 디코딩, 전력 레벨, 채널 등화, 기호 간 간섭, 직교 진폭 변조/복조, 주파수 분할 다중화/역다중화, 송신 채널 특성)에 대해 ML 모듈(500)을 트레이닝한다. 이를 통해 트레이닝된 ML 모듈(500)은 신호 샘플을 입력으로 수신하고 신호에 내장된 이진 데이터와 같은 신호로부터 정보를 복구할 수 있다.During the training procedure, ML module 500 uses labeled or known data as input to DNN 502. DNN 502 uses nodes to analyze input and generate corresponding output. The ML module 500 compares the corresponding output with actual data and adapts the algorithm implemented by the node to improve the accuracy of the output data. DNN 502 then applies the adapted algorithm to the unlabeled input data to generate corresponding output data. ML module 500 maps input to output using one or both statistical analysis and adaptive learning. For example, ML module 500 uses features learned from training data to associate unknown inputs with outputs that are statistically likely within a threshold range or value. Through this, the ML module 500 can receive complex input and identify the corresponding output. In some implementations, the training process may determine the characteristics of the data encoding/decoding schemes used in such systems simultaneously with the characteristics of the communications transmitted over the wireless communication system (e.g., time/frequency interleaving, time/frequency deinterleaving, convolutional encoding, Train the ML module 500 for convolutional decoding, power levels, channel equalization, intersymbol interference, orthogonal amplitude modulation/demodulation, frequency division multiplexing/demultiplexing, and transmit channel characteristics. The ML module 500 trained through this can receive signal samples as input and recover information from the signal, such as binary data embedded in the signal.
도시된 예에서, DNN(502)은 입력 계층(504), 출력 계층(506), 및 입력 계층(504)과 출력 계층(506) 사이에 위치한 하나 이상의 은닉 계층(508)을 포함한다. 각 계층에는 임의의 수의 노드가 있으며, 계층 간 노드 수는 같거나 다를 수 있다. 즉, 입력 계층(504)은 출력 계층(506)과 동일한 수 및/또는 다른 수의 노드를 가질 수 있고, 출력 계층(506)은 하나 이상의 은닉 계층(508)과 동일한 수 및/또는 다른 수의 노드를 가질 수 있다.In the example shown, DNN 502 includes an input layer 504, an output layer 506, and one or more hidden layers 508 located between the input layer 504 and the output layer 506. Each layer has an arbitrary number of nodes, and the number of nodes between layers can be the same or different. That is, the input layer 504 may have the same number and/or a different number of nodes as the output layer 506, and the output layer 506 may have the same number and/or a different number of nodes as the one or more hidden layers 508. Can have nodes.
노드(510)는 입력 계층(504)에 포함된 여러 노드 중 하나에 대응하고, 여기서 노드는 개별적이고 독립적인 계산을 수행한다. 추가로 설명되는 바와 같이, 노드는 입력 데이터를 수신하고 하나 이상의 알고리즘을 사용하여 입력 데이터를 프로세싱하여 출력 데이터를 생성한다. 일반적으로, 알고리즘은 적응형 학습에 기초하여 변경되는 가중치 및/또는 계수를 포함한다. 따라서 가중치 및/또는 계수는 신경망에서 학습한 정보를 반영한다. 경우에 따라 각 노드는 프로세싱된 입력 데이터를 하나 이상의 다음 노드에 전달할지 여부를 결정할 수 있다. 설명하자면, 입력 데이터를 프로세싱한 후 노드(510)는 프로세싱된 입력 데이터를 은닉 계층(508)의 노드(512)와 노드(514) 중 하나 또는 둘 다에 전달할지 여부를 결정할 수 있다. 대안적으로 또는 추가적으로, 노드(510)는 프로세싱된 입력 데이터를 계층 연결 아키텍처에 기초하여 노드에 전달한다. 이 프로세스는 DNN(502)이 출력 계층(506)의 노드(예: 노드(516))를 사용하여 출력을 생성할 때까지 여러 계층에 걸쳐 반복될 수 있다.Node 510 corresponds to one of several nodes included in input layer 504, where nodes perform separate and independent calculations. As further described, a node receives input data and processes the input data using one or more algorithms to generate output data. Typically, the algorithm includes weights and/or coefficients that change based on adaptive learning. Therefore, the weights and/or coefficients reflect information learned by the neural network. In some cases, each node may decide whether to forward processed input data to one or more next nodes. To illustrate, after processing the input data, node 510 may determine whether to forward the processed input data to one or both of node 512 and node 514 of hidden layer 508. Alternatively or additionally, node 510 forwards processed input data to nodes based on a hierarchical connectivity architecture. This process may be repeated across multiple layers until DNN 502 produces output using a node of output layer 506 (e.g., node 516).
신경망은 또한 신경망 내의 어떤 노드가 연결되어 있는지, 신경망에서 데이터가 어떻게 진행 및/또는 유지되는지, 신경망이 입력 데이터를 프로세싱하기 위해 어떤 가중치와 계수를 사용할 것인지, 데이터가 프로세싱되는 방법 등을 결정하는 다양한 아키텍처를 사용할 수 있다. 이러한 다양한 요소는 위에서 간략하게 설명한 신경망 아키텍처 구성과 같은 신경망 아키텍처 구성을 집합적으로 설명한다. 예를 들면, 장단기 기억(LSTM) 신경망과 같은 순환 신경망은 노드 연결 사이에 주기를 형성하여 입력 데이터 시퀀스의 이전 부분의 정보를 유지한다. 그런 다음 순환 신경망은 입력 데이터 시퀀스의 후속 부분에 대해 유지된 정보를 사용한다. 또 다른 예로서, 피드포워드 신경망은 정보를 유지하기 위한 주기를 형성하지 않고 정보를 포워드 연결에 전달한다. 노드 연결의 맥락에서 설명되었지만, 신경망 아키텍처 구성은 DNN(502) 또는 다른 신경망이 입력 데이터를 프로세싱하는 방법에 영향을 미치는 다양한 파라미터 구성을 포함할 수 있다는 것이 이해되어야 한다.Neural networks also have various components that determine which nodes within the network are connected, how data progresses and/or is maintained in the neural network, what weights and coefficients the neural network will use to process the input data, how the data is processed, etc. architecture can be used. These various elements collectively describe a neural network architecture configuration, such as the neural network architecture configuration outlined above. For example, recurrent neural networks, such as long-short-term memory (LSTM) networks, maintain information from previous parts of the input data sequence by forming cycles between node connections. The recurrent neural network then uses the information maintained for subsequent parts of the input data sequence. As another example, a feedforward neural network passes information to forward connections without forming a cycle to retain the information. Although described in the context of node connections, it should be understood that neural network architecture configurations may include various parameter configurations that affect how the DNN 502 or another neural network processes input data.
신경망의 신경망 아키텍처 구성은 다양한 아키텍처 및/또는 파라미터 구성으로 특징지어질 수 있다. 예를 들면, DNN(502)이 컨볼루션 신경망(CNN)을 구현하는 예를 고려한다. 일반적으로 컨벌루션 신경망은 입력 데이터를 필터링하기 위해 컨볼루션 연산을 사용하여 계층에서 데이터를 프로세싱하는 DNN 유형에 대응한다. 따라서, CNN 아키텍처 구성은 예를 들어 풀링(pooling) 파라미터(들), 커널 파라미터(들), 가중치, 및/또는 계층 파라미터(들)로 특징지어질 수 있다.The neural network architecture configuration of a neural network may be characterized by various architectures and/or parameter configurations. For example, consider an example where DNN 502 implements a convolutional neural network (CNN). In general, convolutional neural networks correspond to a type of DNN that processes data in layers using convolutional operations to filter input data. Accordingly, the CNN architecture configuration may be characterized by, for example, pooling parameter(s), kernel parameter(s), weights, and/or layer parameter(s).
풀링 파라미터는 입력 데이터의 차원을 감소시키는 컨벌루션 신경망 내의 풀링 계층을 지정하는 파라미터에 대응한다. 설명하자면, 풀링 계층은 제1 계층의 노드 출력을 제2 계층의 노드 입력으로 결합할 수 있다. 대안적으로 또는 추가적으로 풀링 파라미터는 신경망이 데이터를 풀링하는 데이터 계층의 방법과 위치를 지정한다. 예를 들어, "최대 풀링"을 나타내는 풀링 파라미터는 제1 계층의 노드에서 생성된 데이터 그룹에서 최대값을 선택하고 해당 최대값을 제2 계층의 단일 노드에 대한 입력으로 사용하여 풀링하도록 신경망을 구성한다. "평균 풀링"을 나타내는 풀링 파라미터는 제1 계층의 노드에서 생성된 데이터 그룹에서 평균값을 생성하도록 신경망을 구성하고, 이 평균값을 제2 계층의 단일 노드에 대한 입력으로 사용한다.Pooling parameters correspond to parameters that specify a pooling layer within a convolutional neural network that reduces the dimensionality of the input data. To explain, a pooling layer may combine node outputs from a first layer with node inputs from a second layer. Alternatively or additionally, the pooling parameters specify how and where in the data layer the neural network pools data. For example, a pooling parameter that stands for "maximum pooling" configures the neural network to select the maximum value from a group of data generated by a node in the first layer and pool it using that maximum value as input to a single node in the second layer. do. The pooling parameter, which stands for "average pooling", configures the neural network to generate an average value from a group of data generated by a node in the first layer, and uses this average value as input to a single node in the second layer.
커널 파라미터는 입력 데이터를 프로세싱하는데 사용되는 필터 크기(폭, 높이 등)를 나타낸다. 대안적으로 또는 추가적으로, 커널 파라미터는 입력 데이터를 필터링하고 프로세싱하는데 사용되는 커널 방법 유형을 지정한다. 예를 들어, 지원 벡터 머신은 회귀 분석을 사용하여 데이터를 식별 및/또는 분류하는 커널 방법에 대응한다. 다른 유형의 커널 방법에는 가우스 프로세스, 표준 상관 분석, 스펙트럼 클러스터링 방법 등이 있다. 따라서, 커널 파라미터는 신경망에 적용할 필터 크기 및/또는 커널 방법의 종류를 나타낼 수 있다. 가중치 파라미터는 입력 데이터를 분류하기 위해 노드 내 알고리즘에서 사용되는 가중치와 바이어스를 지정한다. 일부 구현예에서, 가중치와 바이어스는 트레이닝 데이터에서 생성된 파라미터 구성과 같은 학습된 파라미터 구성이다. 계층 파라미터는 예를 들어, 제1 계층(예: 출력 계층(506))의 모든 노드를 제2 계층(예: 은닉 계층(508))의 모든 노드에 연결함을 나타내는 완전 연결 계층 유형, 제1 계층의 어떤 노드가 제2 계층과 연결 해제되는지를 나타내는 부분 연결 계층 유형, 신경망 내에서 활성화할 필터 및/또는 계층을 나타내는 활성화 계층 유형 등과 같이 계층 연결 및/또는 계층 유형을 지정한다. 대안적으로 또는 추가적으로, 계층 파라미터는 정규화 계층 유형, 컨벌루션 계층 유형, 풀링 계층 유형 등과 같은 노드 계층의 유형을 지정한다.Kernel parameters indicate the filter size (width, height, etc.) used to process the input data. Alternatively or additionally, the kernel parameter specifies the type of kernel method used to filter and process the input data. For example, support vector machines correspond to kernel methods that use regression analysis to identify and/or classify data. Other types of kernel methods include Gaussian processes, canonical correlation analysis, and spectral clustering methods. Accordingly, the kernel parameter may indicate the type of filter size and/or kernel method to be applied to the neural network. The weight parameter specifies the weight and bias used in the in-node algorithm to classify the input data. In some implementations, the weights and biases are learned parameter configurations, such as parameter configurations generated from training data. The layer parameter is a fully connected layer type, first layer indicating, for example, connecting all nodes of a first layer (e.g., output layer 506) to all nodes of a second layer (e.g., hidden layer 508). Specifies the layer connectivity and/or layer type, such as a partially connected layer type indicating which nodes in the layer are disconnected from the second layer, an activation layer type indicating which filters and/or layers to activate within the neural network, etc. Alternatively or additionally, the layer parameters specify the type of node layer, such as normalization layer type, convolutional layer type, pooling layer type, etc.
풀링 파라미터, 커널 파라미터, 가중치 파라미터 및 계층 파라미터의 맥락에서 설명되었지만, 여기에 제공된 라이드라인과 일치하는 DNN을 형성하기 위해 다른 파라미터 구성이 사용될 수 있다는 것이 이해될 것이다. 따라서 신경망 아키텍처 구성에는 DNN이 입력 데이터를 프로세싱하여 출력 데이터를 생성하는 방법에 영향을 주는 DNN이 적용할 수 있는 임의의 적합한 유형의 구성 파라미터가 포함될 수 있다.Although described in the context of pooling parameters, kernel parameters, weight parameters and layer parameters, it will be understood that other parameter configurations may be used to form a DNN consistent with the ridelines provided herein. Accordingly, the neural network architecture configuration may include any suitable type of configuration parameters that the DNN can apply that affect how the DNN processes input data to produce output data.
ML 모듈(500)의 아키텍처 구성은 ML 모듈(500)을 구현하는 노드, ML 모듈(500)을 구현하는 노드의 업스트림 또는 다운스트림 하나 이상의 노드, 또는 이들의 조합의 성능(센서 포함)에 기초할 수 있다. 예를 들어, UE(110)는 하나 이상의 센서가 활성화 또는 비활성화되거나 배터리 전력이 제한될 수 있으므로, UE(110) 및 BS(108) 모두에 대한 ML 모듈(500)은 예를 들어, 양단의 ML 모듈(500)이 UE(110)의 상이한 센서 구성 또는 더 낮은 전력 소비에 더 적합한 RAT-지원 UE 포지셔닝 기술을 채택하는 것을 용이하게 하기 위해 입력으로서의 UE(110)의 상이한 센서 구성 또는 배터리 전력에 기초하여 트레이닝될 수 있다.The architectural configuration of the ML module 500 may be based on the performance (including sensors) of the node implementing the ML module 500, one or more nodes upstream or downstream of the node implementing the ML module 500, or a combination thereof. You can. For example, the UE 110 may have one or more sensors activated or deactivated or may have limited battery power, so the ML module 500 for both the UE 110 and the BS 108 may, for example, Based on different sensor configurations or battery power of the UE 110 as input to facilitate the module 500 to adopt RAT-assisted UE positioning techniques that are more suitable for different sensor configurations or lower power consumption of the UE 110 It can be trained.
따라서, 일부 실시예에서, ML 모듈(500)을 구현하는 디바이스는 성능 파라미터, 센서 파라미터, RF 환경 파라미터, 동작 파라미터 등의 서로 다른 조합에 대해 서로 다른 신경망 아키텍처 구성을 구현하도록 구성될 수 있다. 예를 들어, 디바이스는 UE(110)에서 이미징 카메라를 사용할 수 있을 때 사용하기 위한 하나 이상의 신경망 아키텍처 구성 및 UE(110)에서 이미징 카메라를 사용할 수 없을 때 사용하기 위한 하나 이상의 신경망 아키텍처 구성의 상이한 세트에 액세스할 수 있다. Accordingly, in some embodiments, devices implementing ML module 500 may be configured to implement different neural network architecture configurations for different combinations of performance parameters, sensor parameters, RF environmental parameters, operating parameters, etc. For example, the device may have a different set of one or more neural network architecture configurations for use when an imaging camera is available at the UE 110 and one or more neural network architecture configurations for use when an imaging camera is not available at the UE 110. can be accessed.
적어도 일부 실시예에서, ML 모듈(500)을 구현하는 디바이스는 ML 모듈(500)이 사용할 수 있는 후보 신경망 아키텍처 구성 세트의 일부 또는 전부를 로컬에 저장한다. 예를 들어, 구성요소는 하나 이상의 BS 성능 파라미터, 하나 이상의 UE 성능 파라미터, 하나 이상의 BS 동작 파라미터, 하나 이상의 UE 동작 파라미터, 하나 이상의 채널 파라미터 등과 같은, 하나 이상의 파라미터를 입력으로 사용하는 룩업 테이블(LUT) 또는 기타 데이터 구조를 통해 후보 신경망 아키텍처 구성을 인덱싱할 수 있고, 입력 파라미터의 관점에서 동작에 적합한 대응하는 로컬 저장된 후보 신경망 아키텍처 구성과 연관된 식별자를 출력할 수 있다. 그러나 일부 실시예에서, BS(108)에서 사용되는 신경망과 UE(110)에서 사용되는 신경망은 공동으로 트레이닝되므로, 각 디바이스가 자신의 ML 모듈(500)에 대해 다른 디바이스가 상호 보완적인 ML 모듈(500)에 대해 선택한 신경망 아키텍처 구성과 공동으로 트레이닝되었거나, 또는 적어도 동작적으로 호환되는 신경망 아키텍처 구성을 선택하는 것을 보장하기 위해, BS(108)와 UE(110) 사이에 메커니즘이 채택될 필요가 있을 수 있다. 이 메커니즘은 예를 들어 직접적으로 또는 관리 구성요소(150)를 통해 BS(108)와 UE(110) 사이에 전송되는 시그널링을 조정하는 것을 포함할 수 있거나, 관리 구성요소(150)는 각 디바이스에 의해 제안된 서브세트로부터 호환가능한 공동 트레이닝된 아키텍처 구성 쌍을 선택하는 심판 역할을 할 수 있다.In at least some embodiments, a device implementing ML module 500 locally stores some or all of the set of candidate neural network architecture configurations that ML module 500 can use. For example, the component may have a lookup table (LUT) that takes one or more parameters as input, such as one or more BS performance parameters, one or more UE performance parameters, one or more BS operating parameters, one or more UE operating parameters, one or more channel parameters, etc. ) or other data structures, can index the candidate neural network architecture configuration, and output an identifier associated with a corresponding locally stored candidate neural network architecture configuration suitable for operation in terms of the input parameters. However, in some embodiments, the neural network used in BS 108 and the neural network used in UE 110 are trained jointly, so that each device has its own ML module 500, while the other device has a complementary ML module (500). A mechanism may need to be adopted between the BS 108 and the UE 110 to ensure that a neural network architecture configuration is selected that has been jointly trained, or is at least operationally compatible, with the neural network architecture configuration selected for 500). You can. This mechanism may include, for example, coordinating the signaling transmitted between the BS 108 and the UE 110, either directly or via the management component 150, or the management component 150 may provide a It can act as a referee to select compatible pairs of co-trained architecture configurations from the subset proposed by .
그러나, 다른 실시예에서는, 송신 디바이스 및 수신 디바이스의 상대(counterpart) ML 모듈(500)에서 사용될 적절한 공동 트레이닝된 신경망 아키텍처 구성 쌍을 선택하도록 관리 구성요소(150)를 동작시키는 것이 더 효율적이거나 유리할 수 있다. 이러한 접근 방식에서, 관리 구성요소(150)는 송신 및 수신 디바이스로부터 선택 프로세스에 사용될 수 있는 파라미터 중 일부 또는 전부를 나타내는 정보를 획득하고, 이 정보로부터 관리 구성요소(150)에서 유지되는 구성의 세트(412)로부터 공동으로 트레이닝된 신경망 아키텍처 구성 쌍(414)을 선택한다. 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 예를 들어 하나 이상의 알고리즘, LUT 등을 사용하여 이러한 선택 프로세스를 구현할 수 있다. 그러면 관리 구성요소(150)는 해당 디바이스의 ML 모듈(500)에 대해 선택된 신경망 아키텍처 구성의 식별자 또는 다른 표시를 각 디바이스에 전송할 수 있거나(각 디바이스가 로컬로 저장된 복사본을 갖는 경우), 관리 구성요소(150)는 해당 디바이스에 대해 선택된 신경망 아키텍처 구성을 나타내는 하나 이상의 데이터 구조를 전송할 수 있다.However, in other embodiments, it may be more efficient or advantageous to operate the management component 150 to select an appropriate pair of co-trained neural network architecture configurations to be used in the counterpart ML module 500 of the transmitting device and the receiving device. there is. In this approach, management component 150 obtains information from transmitting and receiving devices indicating some or all of the parameters that can be used in the selection process, and from this information creates a set of configurations maintained in management component 150. Select a jointly trained neural network architecture configuration pair (414) from (412). Management component 150 (or another network component) may implement this selection process using, for example, one or more algorithms, LUTs, etc. Management component 150 may then transmit to each device an identifier or other indication of the neural network architecture configuration selected for that device's ML module 500 (if each device has a locally stored copy), or 150 may transmit one or more data structures representing the neural network architecture configuration selected for the device.
송신 및 수신 디바이스에 대한 신경망 아키텍처 구성의 적절한 쌍을 선택하는 프로세스를 용이하게 하기 위해, 적어도 하나의 실시예에서, 관리 구성요소(150)는 신경망 관리 모듈 및 트레이닝 모듈의 적절한 조합을 사용하여 UE 포지셔닝 경로에서 ML 모듈(500)을 트레이닝한다. 트레이닝은 활성 통신 교환이 발생하지 않을 때 오프라인으로 수행되거나 활성 통신 교환 중에 온라인으로 수행될 수 있다. 예를 들어, 관리 구성요소(150)는 수학적으로 트레이닝 데이터를 생성하고, 트레이닝 데이터를 저장하는 파일에 액세스하고, 실제 통신 데이터를 획득하는 등을 수행할 수 있다. 그런 다음, 관리 구성요소(150)는 후속 사용을 위해 다양한 학습된 신경망 아키텍처 구성을 추출하고 저장한다. 일부 구현예에서는 각 신경망 아키텍처 구성과 함께 입력 특성을 저장하며, 이에 따라 입력 특성은 각각의 신경망 아키텍처 구성에 대응하는 BS(108) 또는 UE(110) 동작 특성 및 성능 구성 중 하나 또는 둘 다의 다양한 속성을 설명한다. 구현예에서, 신경망 관리자는 입력 특성에 BS(108) 또는 UE(110) 중 하나 이상의 현재 동작 환경을 센서 성능, RF 성능, 프로세싱 성능 등과 같은 트레이닝 UE 포지셔닝 경로를 따른 하나 이상의 노드의 성능 표시를 포함하는 현재 동작 특성과 매칭함으로써 신경망 아키텍처 구성을 선택한다.To facilitate the process of selecting an appropriate pair of neural network architecture configurations for the transmitting and receiving devices, in at least one embodiment, the management component 150 uses an appropriate combination of a neural network management module and a training module to position the UE. Train the ML module 500 on the path. Training may be performed offline when no active communication exchange is occurring or online during an active communication exchange. For example, management component 150 may mathematically generate training data, access files storing training data, obtain actual communication data, etc. Management component 150 then extracts and stores the various learned neural network architecture configurations for subsequent use. Some implementations store input characteristics with each neural network architecture configuration, such that the input characteristics may be one or both of the BS 108 or UE 110 operating characteristics and performance configurations corresponding to each neural network architecture configuration. Describe the properties. In an implementation, the neural network manager may include in the input characteristics the current operating environment of one or more of the BS 108 or the UE 110, an indication of the performance of one or more nodes along the training UE positioning path, such as sensor performance, RF performance, processing performance, etc. The neural network architecture configuration is selected by matching it with the current operating characteristics.
언급한 바와 같이, BS(108) 및 UE(110)와 같은 무선 통신 중인 네트워크 디바이스는 각각의 네트워크화된 디바이스에서 하나 이상의 DNN을 사용하여 무선 통신 교환을 프로세싱하도록 구성될 수 있으며, 여기서 각 DNN은 RAT-지원 UE 포지셔닝 프로세스를 용이하게 하기 위해 하나 이상의 하드 코딩되거나 고정된 설계 블록에 의해 일반적으로 구현되는 하나 이상의 기능에 새로운 기능을 대체 및/또는 추가한다. 또한, 각각의 DNN은 네트워크화된 디바이스의 센서 세트의 하나 이상의 센서로부터의 현재 센서 데이터 및/또는 UE 포지셔닝 경로(116)에 있는 일부 또는 모든 노드로부터의 성능 데이터를 추가로 통합하여 현재 동작 환경을 고려하여 사실상 수정하거나 적응시킬 수 있다.As mentioned, network devices in wireless communication, such as BS 108 and UE 110, may be configured to process wireless communication exchanges using one or more DNNs in each networked device, where each DNN has a RAT. -Supports replaces and/or adds new functionality to one or more functions typically implemented by one or more hard-coded or fixed design blocks to facilitate the UE positioning process. Additionally, each DNN may further integrate current sensor data from one or more sensors in the networked device's sensor set and/or performance data from some or all nodes in the UE positioning path 116 to take into account the current operating environment. So it can actually be modified or adapted.
이를 위해, 도 6 및 도 7은 도 1의 예시적인 UE 포지셔닝 경로(116)에서 DNN 구현을 위한 예시적인 동작 환경(600)을 함께 도시한다. 도시된 예에서, 동작 환경(600)은 RAT-지원 UE 포지셔닝을 용이하게 하기 위해 신경망 기반 접근 방식을 사용한다. 적어도 하나의 실시예에서, 하나 이상의 BS(108)의 신경망 관리 모듈(314)은 BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)(TX 프로세싱 모듈(602-1 및 602-2)로 도시됨)을 구현하는 반면, UE(110)의 신경망 관리 모듈(216)은 UE 포지션 레퍼런스 신호 수신기(RX) 프로세싱 모듈(604)을 구현한다. UE(110)의 신경망 관리 모듈(216)은 UE 포지션 피드백 TX 프로세싱 모듈(702)을 추가로 구현하는 반면, 서빙 BS(108-1)의 신경망 관리 모듈(314)은 BS 포지션 RX 프로세싱 모듈(704)을 추가로 구현한다.To this end, Figures 6 and 7 together illustrate an example operating environment 600 for a DNN implementation in the example UE positioning path 116 of Figure 1. In the example shown, operating environment 600 uses a neural network-based approach to facilitate RAT-assisted UE positioning. In at least one embodiment, the neural network management module 314 of one or more BSs 108 implements a BS position reference signal TX processing module 602 (shown as TX processing modules 602-1 and 602-2). On the other hand, the neural network management module 216 of the UE 110 implements the UE position reference signal receiver (RX) processing module 604. The neural network management module 216 of the UE 110 further implements the UE position feedback TX processing module 702, while the neural network management module 314 of the serving BS 108-1 implements the BS position RX processing module 704. ) is additionally implemented.
적어도 일 실시예에서, 이들 프로세싱 모듈 각각은 도 5의 ML 모듈(500)의 하나 이상의 DNN(502)을 참조하여 전술한 바와 같이 대응하는 ML 모듈의 구현을 통해 하나 이상의 DNN을 구현한다. 이와 같이, 하나 이상의 BS(108)의 BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602) 및 UE(110)의 UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 RAT-지원 UE 포지셔닝을 용이하게 하기 위해 데이터를 생성하고 통신하기 위해 BS(108)와 UE(110) 사이의 다운링크 신경망 기반 무선 통신 경로를 지원하도록 상호 동작한다. 마찬가지로, UE(110)의 UE 포지션 피드백 TX 프로세싱 모듈(702) 및 서빙 BS(108-1)의 BS 포지션 RX 프로세싱 모듈(704)은 RAT-지원 UE 포지셔닝을 용이하게 하기 위해 데이터를 생성하고 통신하기 위해 UE(110)와 서빙 BS 사이의 업링크 신경망 기반 무선 통신 경로를 지원하도록 상호 동작한다.In at least one embodiment, each of these processing modules implements one or more DNNs through the implementation of corresponding ML modules, as described above with reference to one or more DNNs 502 of ML module 500 of Figure 5. As such, the BS position reference signal TX processing module 602 of one or more BSs 108 and the UE position reference signal RX processing module 604 of UE 110 generate data to facilitate RAT-assisted UE positioning. and operate mutually to support a downlink neural network-based wireless communication path between the BS 108 and the UE 110 for communication. Likewise, the UE position feedback TX processing module 702 of UE 110 and the BS position RX processing module 704 of serving BS 108-1 generate and communicate data to facilitate RAT-assisted UE positioning. To this end, they operate mutually to support an uplink neural network-based wireless communication path between the UE 110 and the serving BS.
적어도 하나의 BS(108)의 BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)의 하나 이상의 DNN은 BS 레퍼런스 신호 관리 모듈(316)(모듈(316-1 및 316-2)로 도시됨)로부터 레퍼런스 신호 정보(122)(정보(122-1 및 122-2)로 도시됨)를 입력으로 수신하도록 트레이닝된다. 일 예로서, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)은 UE(110), 위치 관리 서버(미도시), 원격 애플리케이션 등과 같은 구성요소가 UE 포지션 정보를 요청하는 것에 대한 응답하여 레퍼런스 신호 정보(122)를 입력으로 수신한다. 적어도 일부 실시예에서, 레퍼런스 신호 정보(122)는 BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)의 DNN(들)이 하나 이상의 레퍼런스 신호를 생성 및 구성하기 위해 입력으로서 활용하는 하나 이상의 서로 다른 유형의 정보를 포함한다. 레퍼런스 신호 정보(122)의 예는 송신 전력, 안테나 매핑, 물리적 다운링크 제어 채널(PDCCH) 심볼 수, 연속된 다운링크 서브프레임의 전송 수, PRS 대역폭, PRS 전송 시간 오프셋, PRS 구성 인덱스, PRS 주기성, PRS 서브프레임 오프셋, PRS 뮤팅 시퀀스, PRS 등 뮤팅 시퀀스 길이, 타임-도메인 동작, 타임/주파수 리소스 요소 밀도(density), QCL(quasi co-location) 정보, UE(110)의 RX 패널 정보 등과 같은 레퍼런스 신호 관련 파라미터 또는 속성을 포함한다. 레퍼런스 신호 정보(122)의 다른 예는 서빙 셀의 동작 특성(예를 들어, 주파수, 대역폭 등), UE 보고 레퍼런스 신호 수신 전력(RSRP), 도플러 추정, 배포 정보(예를 들어, 도시/지방 배포 또는 각도 추정이 BS(108)에 의해 수행되는지 여부), UE 성능 정보 등을 포함한다.One or more DNNs of the BS position reference signal TX processing module 602 of at least one BS 108 may receive reference signal information from the BS reference signal management module 316 (shown as modules 316-1 and 316-2). It is trained to receive 122 (shown as information 122-1 and 122-2) as input. As an example, the BS position reference signal TX processing module 602 may generate reference signal information 122 in response to a component such as the UE 110, a location management server (not shown), a remote application, etc. requesting UE position information. ) is received as input. In at least some embodiments, the reference signal information 122 is one or more different types of information that the DNN(s) of the BS position reference signal TX processing module 602 utilize as input to generate and configure one or more reference signals. Includes. Examples of reference signal information 122 include transmit power, antenna mapping, number of physical downlink control channel (PDCCH) symbols, number of transmissions in consecutive downlink subframes, PRS bandwidth, PRS transmission time offset, PRS configuration index, and PRS periodicity. , PRS subframe offset, PRS muting sequence, PRS muting sequence length, time-domain operation, time/frequency resource element density, QCL (quasi co-location) information, RX panel information of the UE 110, etc. Contains parameters or properties related to the reference signal. Other examples of reference signal information 122 include operating characteristics of the serving cell (e.g., frequency, bandwidth, etc.), UE reported reference signal received power (RSRP), Doppler estimation, deployment information (e.g., urban/rural distribution) or whether angle estimation is performed by the BS 108), UE performance information, etc.
레퍼런스 신호 정보(122) 입력으로부터, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)의 하나 이상의 DNN은 PRS 출력과 같은 하나 이상의 대응하는 레퍼런스 신호(138) 출력(출력(138-1 및 138-1)으로 도시됨)을 생성 및 구성하도록 트레이닝된다. 예를 들어, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)은 레퍼런스 신호 정보(122) 입력에 기초하여 특정 파라미터 또는 특성(예를 들어, 대역폭, 리소스 또는 리소스 세트, 반복, 주기성, 간섭 억제 등)을 포함하도록 레퍼런스 신호(138)를 생성 및 구성한다. BS(108)의 RF 안테나 인터페이스(304)(인터페이스(304-1 및 304-2)로 도시됨) 및 하나 이상의 안테나(302)(안테나(302-1 및 302-2)로 도시됨)는 레퍼런스 신호(138) 출력을 UE(110)에 의한 수신을 위해 무선으로 전송되는 대응하는 RF 신호(606)(RF 신호(606-1, 606-2)로 도시됨)로 변환한다. 특히, 일부 실시예에서, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)의 하나 이상의 DNN들은, 실제로, BS(108)에 의해 UE(110)로의 전송을 위해 구성되고 변조된 레퍼런스 신호를 생성하는 프로세싱을 제공하도록 트레이닝되며, 이와 같은 프로세싱은 레퍼런스 신호의 생성, 구성 및 변조를 구현하기 위해 힘들고 비효율적인 알고리즘의 하드코딩이나 별도의 개별 프로세싱 블록을 요구하는 대신 공동 트레이닝을 통해 하나 이상의 DNN으로 트레이닝된다.From reference signal information 122 input, one or more DNNs of BS position reference signal TX processing module 602 output one or more corresponding reference signal 138 outputs, such as PRS outputs (outputs 138-1 and 138-1). shown) is trained to create and configure. For example, the BS position reference signal TX processing module 602 may determine certain parameters or characteristics (e.g., bandwidth, resource or resource set, repetition, periodicity, interference suppression, etc.) based on the reference signal information 122 input. Generate and configure the reference signal 138 to include. RF antenna interface 304 (shown as interfaces 304-1 and 304-2) of BS 108 and one or more antennas 302 (shown as antennas 302-1 and 302-2) are reference Converts the signal 138 output to a corresponding RF signal 606 (shown as RF signals 606-1 and 606-2) that is transmitted wirelessly for reception by UE 110. In particular, in some embodiments, one or more DNNs of the BS position reference signal TX processing module 602 may, in fact, perform processing to generate a reference signal configured and modulated for transmission by the BS 108 to the UE 110. This processing is trained by one or more DNNs through joint training, rather than requiring separate individual processing blocks or hard-coding laborious and inefficient algorithms to implement the generation, composition, and modulation of reference signals.
RF 신호(606)는 하나 이상의 안테나(202) 및 RF 안테나 인터페이스(204)를 통해 UE(110)에서 수신 및 프로세싱되고, 결과적으로 캡처된 신호(608)는 레퍼런스 신호 측정 모듈(220)에 의해 분석되어 RSRP, RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT 등과 같은 하나 이상의 레퍼런스 신호 측정(142)을 생성한다. UE(110)의 UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)의 하나 이상의 DNN은 레퍼런스 신호 측정(142)뿐만 아니라 다른 입력을 입력으로서 수신하도록 트레이닝되고, 이러한 입력으로부터 대응하는 UE 측정 및 센서 보고(144) 출력을 생성한다. 적어도 일부 실시예에서, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 다른 입력을 수신하지 않으며, 결과적으로 UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 (UE 측정 및 센서 보고가 아닌) UE 측정 보고를 생성한다. 또한, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 레퍼런스 신호 측정 모듈(220)로부터 레퍼런스 신호 측정(142)을 수신하는 것과 비교하여 캡처된 신호(608) 신호를 입력으로서 수신하고 이에 대한 레퍼런스 신호 측정(142)를 계산할 수 있다.RF signal 606 is received and processed at UE 110 via one or more antennas 202 and RF antenna interface 204, and the resulting captured signal 608 is analyzed by reference signal measurement module 220. to generate one or more reference signal measurements 142, such as RSRP, RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT, etc. One or more DNNs of the UE position reference signal RX processing module 604 of the UE 110 are trained to receive reference signal measurements 142 as well as other inputs as inputs and generate corresponding UE measurements and sensor reports 144 from these inputs. ) produces output. In at least some embodiments, the UE Position Reference Signal RX processing module 604 does not receive any other input, and as a result, the UE Position Reference Signal RX processing module 604 receives UE measurement reports (rather than UE measurements and sensor reports). Create. Additionally, the UE position reference signal RX processing module 604 receives the captured signal 608 as an input and performs reference signal measurement thereon compared to receiving the reference signal measurement 142 from the reference signal measurement module 220. (142) can be calculated.
UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)에 제공되는 다른 입력은 예를 들어 센서 세트(210)로부터의 센서 데이터(140)를 포함할 수 있다. 센서 데이터(140) 입력의 예로는 GPS 데이터, 카메라 데이터, 가속도계 데이터, IMU 데이터, 고도계 데이터, 온도 데이터, 기압계 데이터, 객체 검출 데이터(예: 레이더 데이터, 라이더 데이터, 이미징 센서 데이터, 구조광 기반 깊이 센서 데이터 등) 등이 있다. 또한, 이용가능한 센서를 포함하는 UE(110)의 성능은 순간순간 변할 수 있다는 것이 이해될 것이다. 예를 들어, UE(110)는 현재 배터리 레벨, 열(thermal) 상태, 또는 UE(110)의 다른 조건에 기초하여 하나 이상의 센서를 비활성화할 수 있다. 변화하는 센서 성능을 보상하기 위해, RX 프로세싱 모듈(604)의 하나 이상의 DNN은 UE(110)의 상이한 센서 성능을 고려하는 UE 측정 및 센서 보고(144) 출력을 제공하기 위해 상이한 센서 데이터(140) 입력에 대해 트레이닝될 수 있다. 따라서, 일부 실시예에서, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)의 하나 이상의 DNN은 실제로 UE 레퍼런스 신호 측정(142)과 UE(110)의 이용가능한 센서로부터의 센서 데이터(140)를 융합하는 UE 측정 및 센서 보고(144)를 생성하는 프로세싱을 제공하도록 트레이닝되며, 이러한 프로세싱은 동일한 프로세스를 구현하기 위해 힘들고 비효율적인 알고리즘의 하드코딩이나 별도의 개별 프로세싱 블록을 요구하는 대신 공동 트레이닝을 통해 하나 이상의 DNN으로 트레이닝된다.Other inputs provided to the UE Position Reference Signal RX processing module 604 may include sensor data 140 from sensor set 210, for example. Examples of sensor data 140 inputs include GPS data, camera data, accelerometer data, IMU data, altimeter data, temperature data, barometer data, object detection data (e.g., radar data, lidar data, imaging sensor data, structured light-based depth). sensor data, etc.). Additionally, it will be appreciated that the performance of UE 110, including available sensors, may vary from moment to moment. For example, UE 110 may disable one or more sensors based on current battery level, thermal state, or other conditions of UE 110. To compensate for changing sensor performance, one or more DNNs in the RX processing module 604 may output different sensor data 140 to provide UE measurement and sensor reporting 144 outputs that take into account the different sensor performance of the UE 110. Can be trained on input. Accordingly, in some embodiments, one or more DNNs in the UE position reference signal RX processing module 604 actually fuse UE reference signal measurements 142 with sensor data 140 from available sensors of the UE 110. One or more DNNs are trained to provide processing to generate measurements and sensor reports (144), through joint training, rather than requiring separate, individual processing blocks or hardcoding of laborious and inefficient algorithms to implement the same processes. is trained with
도 7에 도시된 예에 묘사된 바와 같이, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 UE 측정 및 센서 보고(144) 출력을 UE(110)의 UE 포지션 피드백 TX 프로세싱 모듈(702)에 입력으로 제공하고, 이 입력으로부터 UE 측정 및 센서 보고(144)를 나타내는 대응하는 출력 신호(706)를 생성한다. RF 안테나 인터페이스(204) 및 하나 이상의 안테나(202)는 출력 신호(706)를 서빙 BS(108-1)에 의한 수신을 위해 무선으로 전송되는 무선 통신을 나타내는 대응하는 RF 신호(708)로 변환한다. UE(110)는 무선 통신을 구성하고 전송하기 위해 RRC(Radio Resource Control) 프로토콜, LTE(Long Term Evolution) 포지셔닝 프로토콜(LPP) 등과 같은 다양한 메시징 메커니즘을 사용할 수 있다. 특히, 일부 실시예에서, UE 포지션 피드백 TX 프로세싱 모듈(702)의 하나 이상의 DNN은 실제로 예를 들어 RF 안테나 인터페이스(204)에 의한 무선 전송에 적합한 UE 측정 및 센서 보고(144)의 채널 인코딩된(변조 포함) 표현을 초래하는 프로세싱을 제공하도록 트레이닝되며, 이러한 프로세싱은 동일한 프로세스를 구현하기 위해 힘들고 비효율적인 알고리즘의 하드코딩이나 별도의 개별 프로세싱 블록을 요구하는 대신 공동 트레이닝을 통해 하나 이상의 DNN으로 트레이닝된다.As depicted in the example shown in FIG. 7 , the UE position reference signal RX processing module 604 feeds the UE measurement and sensor report 144 output as input to the UE position feedback TX processing module 702 of the UE 110. and generates from this input a corresponding output signal 706 representing UE measurements and sensor reports 144. RF antenna interface 204 and one or more antennas 202 convert output signal 706 into a corresponding RF signal 708 representing the wireless communication transmitted wirelessly for reception by serving BS 108-1. . UE 110 may use various messaging mechanisms, such as Radio Resource Control (RRC) protocol, Long Term Evolution (LTE) Positioning Protocol (LPP), etc., to configure and transmit wireless communications. In particular, in some embodiments, one or more DNNs of the UE position feedback TX processing module 702 may actually channel-encode ( DNNs are trained to provide the processing that results in a representation (including modulation), and this processing is trained by one or more DNNs through joint training, rather than requiring separate individual processing blocks or hardcoding of laborious and inefficient algorithms to implement the same processes. .
UE(110)로부터 전파되는 RF 신호(708)는 예를 들어, RF 신호(708)를 UE 측정 및 센서 보고(144)를 나타내는 디지털 신호로 변환하기 위해, 서빙 BS(108-1)의 안테나(302-1) 및 RF 안테나 인터페이스(304-1)에 의해 수신되고 초기에 프로세싱된다. BS 포지션 RX 프로세싱 모듈(704)의 하나 이상의 DNN은 UE 측정 및 센서 보고(144)를 나타내는 RF 안테나 인터페이스(304)의 결과 출력(710)을 입력으로 수신하고 이 입력으로부터 대응하는 UE 포지션 추정(130)을 생성하도록 트레이닝된다. 예를 들어, BS 포지션 RX 프로세싱 모듈(704)의 하나 이상의 DNN은 UE 레퍼런스 신호 측정(들)(142) 및 일부 실시예에서는 UE 센서 데이터(140)를 포함하는 UE 포지션 추정(130)을 입력으로서 수신한다. 이들 입력으로부터, BS 포지션 RX 프로세싱 모듈(704)의 하나 이상의 DNN은 UE(110)에 대한 포지션 추정(130)을 나타내는 출력(712)을 생성한다. 적어도 일부 실시예에서, UE 포지션 추정(130)은 UE(110)에 의해 제공되는 레퍼런스 신호 측정(들)(142)을 통합할 뿐만 아니라 UE 센서 데이터(140)도 통합하여, 예를 들어 UE(110)의 지리적 위치, UE(110)의 로컬 상황, UE 배향의 표시, 움직임(예를 들어, 회전, 방향 등)과 같은 2차 정보 등을 포함하는 UE 포지션 추정(130)을 생성한다. 특히, 일부 실시예에서, BS 포지션 RX 프로세싱 모듈(704)의 하나 이상의 DNN은 실제로 예를 들어 UE 센서 데이터(140)와 융합된 UE 레퍼런스 신호 측정(142)에 기초한 UE 포지션 추정(130)을 나타내는 출력을 생성하는 프로세싱을 제공하도록 트레이닝되며, 그러한 프로세싱은 동일한 프로세스를 구현하기 위해 힘들고 비효율적인 알고리즘의 하드코딩이나 별도의 개별 프로세싱 블록을 요구하는 대신 공동 트레이닝을 통해 하나 이상의 DNN으로 트레이닝된다. 이와 같이, UE 레퍼런스 신호 측정(142) 외에 UE 센서 데이터(140)를 고려함으로써, BS 포지션 RX 프로세싱 모듈(704)은 기존의 RAT-지원 포지셔닝 기술보다 더 정확하고 의미 있는 UE 포지션 추정을 생성할 수 있다.The RF signal 708 propagating from the UE 110 may be connected to an antenna of the serving BS 108-1, for example, to convert the RF signal 708 into a digital signal representing UE measurements and sensor reports 144. 302-1) and RF antenna interface 304-1. One or more DNNs in the BS position RX processing module 704 receive as input the resulting output 710 of the RF antenna interface 304 representing UE measurements and sensor reports 144 and generate a corresponding UE position estimate 130 from this input. ) is trained to generate. For example, one or more DNNs of BS position RX processing module 704 may use UE reference signal measurement(s) 142 and, in some embodiments, UE position estimate 130 including UE sensor data 140 as input. Receive. From these inputs, one or more DNNs in the BS position RX processing module 704 generate an output 712 representing a position estimate 130 for the UE 110. In at least some embodiments, UE position estimation 130 integrates reference signal measurement(s) 142 provided by UE 110 as well as UE sensor data 140, e.g. Generates a UE position estimate 130 that includes the geographic location of the UE 110, the local context of the UE 110, an indication of the UE orientation, and secondary information such as movement (e.g., rotation, direction, etc.). In particular, in some embodiments, one or more DNNs in the BS position RX processing module 704 may actually represent a UE position estimate 130, for example based on UE reference signal measurements 142 fused with UE sensor data 140. They are trained to provide the processing that produces the output, and that processing is trained by one or more DNNs through joint training, rather than requiring separate individual processing blocks or hardcoding of laborious and inefficient algorithms to implement the same process. As such, by considering UE sensor data 140 in addition to UE reference signal measurements 142, BS position RX processing module 704 can generate more accurate and meaningful UE position estimates than existing RAT-assisted positioning techniques. there is.
적어도 일부 실시예에서, 서빙 BS(108-1)는 UE 포지션 추정(130)을 프로세싱하거나 추가 프로세싱을 위해, UE 포지션 추정(130)을 UE(110) 또는 위치 관리 기능(LMF) 서버(도시되지 않음)와 같은 무선 통신 시스템(100)의 하나 이상의 다른 구성요소에 전송한다. UE 포지션 추정(130)은 다양한 표준 또는 비표준 포맷으로 전송될 수 있으며, 추정된 오류(불확실성), UE 포지션 추정을 획득하기 위해 사용되는 방법 등과 같은 추가 정보를 포함할 수 있다. 서빙 BS(108-1)가 UE 포지션 추정(130)을 하나 이상의 다른 구성요소로 전송하면, 서빙 BS(108-1)의 RF 안테나 인터페이스(304) 및 하나 이상의 안테나(302-1)는 포지션 추정(130)을 나타내는 출력(712)을 UE(110)(또는 다른 네트워크 구성요소)에 의한 수신을 위해 무선으로 전송되는 대응하는 RF 신호(714)로 변환한다. 적어도 일부 실시예에서, 서빙 BS(108-1)는 실제로 RF 안테나 인터페이스(304)에 의한 무선 전송에 적합한 UE 포지션 추정(130)의 데이터 인코딩(예: 압축) 및/또는 채널 인코딩 표현을 생성하는 프로세싱을 제공하도록 트레이닝된 하나 이상의 DNN을 갖는 UE 포지션 추정 TX 프로세싱 모듈(미도시)을 구현하며, 이러한 프로세싱은 공동 트레이닝을 통해 하나 이상의 DNN으로 트레이닝된다.In at least some embodiments, serving BS 108 - 1 processes UE position estimate 130 or sends UE position estimate 130 to UE 110 or a location management function (LMF) server (not shown) for further processing. transmits to one or more other components of the wireless communication system 100, such as UE position estimate 130 may be transmitted in various standard or non-standard formats and may include additional information such as estimated error (uncertainty), method used to obtain the UE position estimate, etc. When the serving BS 108-1 transmits the UE position estimate 130 to one or more other components, the RF antenna interface 304 of the serving BS 108-1 and one or more antennas 302-1 perform the position estimate. The output 712 representing 130 is converted to a corresponding RF signal 714 that is transmitted wirelessly for reception by UE 110 (or other network component). In at least some embodiments, serving BS 108-1 may actually generate a data encoded (e.g., compressed) and/or channel encoded representation of UE position estimate 130 suitable for wireless transmission by RF antenna interface 304. Implements a UE position estimation TX processing module (not shown) with one or more DNNs trained to provide processing, which processing is trained with one or more DNNs through joint training.
BS(108)와 UE(110) 사이의 RAT-지원 UE 포지셔닝 경로를 구현하기 위한 DNN 또는 다른 신경망은 설계의 유연성을 제공하고 종래의 블록별 설계 및 테스트 접근 방식에 비해 효율적인 업데이트를 용이하게 하는 동시에, UE 포지셔닝 경로 내의 디바이스가 현재 동작 파라미터 및 성능에 기초하여 레퍼런스 신호의 생성, 전송 및 프로세싱, UE 측정 및 센서 보고, 및 UE 포지션 추정을 신속하게 적응시킬 수 있도록 허용한다. 그러나 DNN을 배포하고 동작시키기 전에 일반적으로 주어진 하나 이상의 입력 세트에 적합한 출력을 제공하도록 트레이닝되거나 구성된다. 이를 위해, 도 8은 일부 실시예에 따른 다양한 동작 환경 또는 성능에 대한 RAT-지원 UE 포지셔닝 경로의 디바이스에 대한 옵션으로서 하나 이상의 공동 트레이닝된 DNN 아키텍처 구성을 개발하기 위한 예시적인 방법(800)을 도시한다. 도 8을 참조하여 설명된 동작 순서는 단지 예시를 위한 것이며, 다른 동작 순서가 수행될 수 있고, 또한 하나 이상의 동작이 생략될 수 있거나 예시된 방법에 하나 이상의 추가 동작이 포함될 수 있다는 점에 유의한다. 또한, 도 8은 하나 이상의 테스트 노드를 사용하는 오프라인 트레이닝 접근 방식을 도시하지만, 활성화 동작 중인 하나 이상의 노드를 사용하는 온라인 트레이닝을 위해 유사한 접근 방식이 구현될 수 있다.DNN or other neural networks to implement RAT-assisted UE positioning paths between BS 108 and UE 110 while providing design flexibility and facilitating efficient updates compared to conventional block-by-block design and test approaches. , allowing devices within the UE positioning path to quickly adapt the generation, transmission, and processing of reference signals, UE measurements and sensor reporting, and UE position estimation based on current operating parameters and capabilities. However, before deploying and operating a DNN, it is typically trained or configured to provide appropriate output given a set of one or more inputs. To this end, FIG. 8 illustrates an example method 800 for developing one or more co-trained DNN architecture configurations as an option for devices in RAT-assisted UE positioning paths for various operating environments or capabilities according to some embodiments. do. Note that the sequence of operations described with reference to Figure 8 is for illustrative purposes only and that other sequences of operations may be performed, and also that one or more operations may be omitted or one or more additional operations may be included in the illustrated method. . Additionally, while Figure 8 shows an offline training approach using one or more test nodes, a similar approach could be implemented for online training using one or more nodes in active operation.
위에서 설명된 바와 같이, 대응하는 RAT-지원 UE 포지셔닝 경로를 형성하는 DNN 체인의 하나 또는 두 디바이스 모두에 사용되는 DNN의 동작은, 대응하는 DNN을 사용하는 디바이스, 하나 이상의 업스트림 또는 다운스트림 디바이스, 또는 이들의 조합의 동작 파라미터 및/또는 성능과 같은 RAT-지원 UE 포지셔닝 경로의 특정 성능 및 현재 동작 파라미터에 기초할 수 있다. 이러한 성능 및 동작 파라미터는 예를 들어, 디바이스의 현재 상황을 감지하는 데 사용되는 센서 유형, 이러한 센서의 성능, 하나 이상의 디바이스의 전력 용량, 하나 이상의 디바이스의 프로세싱 용량, RF 안테나 인터페이스 구성(예: 빔 수 , 안테나 포트, 지원되는 주파수) 등을 포함할 수 있다. 설명된 DNN은 이러한 정보를 활용하여 해당 동작을 지시하기 때문에, 많은 경우에 노드 중 하나에서 구현된 특정 DNN 구성은 해당 디바이스 또는 RAT-지원 UE 포지셔닝 경로의 반대편에 있는 디바이스에서 현재 사용되는 특정 성능 및 동작 파라미터에 기초한다는 것이 이해될 것이며; 즉, 구현된 특정 DNN 구성은 BS(108) 및 UE(110)에 의해 구현된 RAT-지원 UE 포지셔닝 경로에 의해 현재 나타나는 성능 정보 및 동작 파라미터를 반영한다.As described above, the operation of a DNN used by one or both devices in a DNN chain forming a corresponding RAT-assisted UE positioning path may be performed by either the device using the corresponding DNN, one or more upstream or downstream devices, or It may be based on the specific performance and current operating parameters of the RAT-assisted UE positioning path, such as the operating parameters and/or performance of a combination thereof. These performance and operating parameters include, for example, the type of sensor used to sense the current state of the device, the performance of these sensors, the power capabilities of one or more devices, the processing capacity of one or more devices, and the RF antenna interface configuration (e.g. beam number, antenna ports, supported frequencies), etc. Because the DNN described leverages this information to direct its behavior, in many cases the specific DNN configuration implemented at one of the nodes will depend on the specific performance and functionality currently used by that device or a device on the other side of the RAT-enabled UE positioning path. It will be understood that based on operating parameters; That is, the specific DNN configuration implemented reflects the performance information and operating parameters currently exhibited by the RAT-assisted UE positioning path implemented by BS 108 and UE 110.
따라서, 방법(800)은 하나 이상의 테스트 BS 및 하나 이상의 테스트 UE(간단히 "테스트 디바이스"라고도 함)를 포함하는, 테스트 RAT-지원 UE 포지셔닝 경로의 하나 이상의 테스트 노드의 예상 성능(예상 동작 파라미터 또는 파라미터 범위 포함)을 식별하여 블록(802)에서 시작한다. 이하에서는, 관리 구성요소(150)의 트레이닝 모듈(408)이 공동 트레이닝을 관리하고 있고, 따라서 테스트 디바이스에 대한 성능 정보가 트레이닝 모듈(408)에 (예를 들어, 이 정보를 저장하는 데이터베이스 또는 다른 로컬로 저장된 데이터 구조를 통해) 알려져 있다고 가정한다. 그러나 관리 구성요소(150)는 임의의 주어진 UE의 성능에 대한 사전 지식을 갖고 있지 않을 가능성이 높기 때문에, 테스트 UE는 예를 들어, 테스트 UE에서 이용가능한 센서 유형 표시, 이러한 센서에 대한 다양한 파라미터 표시(예: 이미징 카메라의 이미징 해상도 및 사진 데이터 형식, 위성 기반 포지션 센서의 위성-포지셔닝 유형 및 형식 등), 디바이스에서 이용할 수 있는 액세서리 및 적용가능한 파라미터(예: 오디오 채널 수) 등과 같은 자신의 성능 표시를 관리 구성요소(150)에 제공한다. 예를 들어, 테스트 UE는 적어도 4G LTE 및 5G NR 사양에 따라 BS에 의해 전송된 UECapabilityEnquiry RRC 메시지에 대한 응답으로 UE에 의해 제공되는 UECapabilityInformation Radio Resource Control (RRC) 메시지의 일부로서 이러한 성능 표시를 제공할 수 있다. 대안적으로, 테스트 UE는 별도의 사이드-채널 또는 제어-채널 통신으로 센서 성능 표시를 제공할 수 있다. 또한, 일부 실시예에서, 테스트 디바이스의 성능은 관리 구성요소(150)가 사용할 수 있는 로컬 또는 원격 데이터베이스에 저장될 수 있으며, 따라서 관리 구성요소(150)는 테스트 디바이스와 연관된 IMSI(International Mobile Subscriber Identity) 값과 같은 테스트 디바이스의 식별자의 어떤 형태에 기초하여 이 데이터베이스에 쿼리할 수 있다.Accordingly, method 800 provides expected performance (expected operating parameters or We begin at block 802 by identifying a range (including ranges). Hereinafter, the training module 408 of the management component 150 is managing joint training, such that performance information about test devices is stored in the training module 408 (e.g., in a database or other database storing this information). is assumed to be known (via locally stored data structures). However, since the management component 150 likely does not have prior knowledge of the performance of any given UE, the test UE may be configured to display, for example, the types of sensors available on the test UE and various parameters for these sensors. Indication of their capabilities, such as imaging resolution and picture data format of imaging cameras, satellite-positioning type and format of satellite-based position sensors, etc., accessories available on the device and applicable parameters (e.g. number of audio channels), etc. is provided to the management component 150. For example, the test UE may provide this performance indication as part of a UECapabilityInformation Radio Resource Control (RRC) message provided by the UE in response to a UECapabilityEnquiry RRC message sent by the BS, at least according to the 4G LTE and 5G NR specifications. You can. Alternatively, the test UE may provide sensor performance indications with separate side-channel or control-channel communications. Additionally, in some embodiments, the performance of the test device may be stored in a local or remote database that may be used by management component 150, such that management component 150 may determine the International Mobile Subscriber Identity (IMSI) associated with the test device. ) You can query this database based on some form of identifier of the test device, such as a value.
적어도 일부 실시예에서, 트레이닝 모듈(408)은 모든 RAT-지원 UE 포지셔닝 구성(또는 간결성을 위해 "UE 포지셔닝 구성") 순열(permutation)을 트레이닝하려고 시도할 수 있다. 그러나, BS(108) 및 UE(110)가 비교적 많은 수 및 다양한 성능 및 기타 동작 파라미터를 가질 가능성이 있는 구현예에서는 이러한 노력이 실행 불가능할 수 있다. 따라서, 블록(804)에서 트레이닝 모듈(408)은 후보 RAT-지원 UE 포지셔닝 구성의 지정된 세트로부터 테스트 디바이스의 DNN을 공동으로 트레이닝하기 위한 특정 UE 포지셔닝 구성을 선택할 수 있다. 따라서 각각의 후보 UE 포지셔닝 구성은 UE 포지셔닝 관련 파라미터, 파라미터 범위, 또는 이들의 조합의 특정 조합을 나타낼 수 있다. 이러한 파라미터 또는 파라미터 범위는 센서 성능 파라미터, 프로세싱 성능 파라미터, 배터리 전력 파라미터, RF-시그널링 파라미터(예: 안테나 수 및 유형, 서브채널 수 및 유형 등)를 포함할 수 있다. 이러한 UE 포지셔닝 관련 파라미터는 또한 BS(108)에 의해 사용될 특정 유형의 레퍼런스 신호, UE(110)가 레퍼런스 신호 측정을 수행하는 방식, 레퍼런스 신호 측정과 융합될 센서 데이터의 유형 등을 나타낼 수 있다. 트레이닝을 위해 선택된 후보 UE 포지셔닝 구성을 사용하여, 추가로 블록(804)에서 트레이닝 모듈(408)은 테스트 BS 및 테스트 UE 각각에 대한 초기 DNN 아키텍처 구성을 식별하고, 테스트 디바이스가 후보 초기 DNN 아키텍처 구성의 복사본을 저장하는 경우 초기 DNN 아키텍처 구성과 연관된 식별자를 테스트 디바이스에 제공하거나, 초기 DNN 아키텍처 구성 자체를 나타내는 데이터를 테스트 디바이스에 전송함으로써, 테스트 디바이스가 이들 각각의 초기 DNN 아키텍처 구성을 구현하도록 지시한다.In at least some embodiments, training module 408 may attempt to train permutations of all RAT-supported UE positioning configurations (or “UE positioning configurations” for brevity). However, this effort may not be feasible in implementations where BS 108 and UE 110 are likely to have relatively large numbers and varying performance and other operating parameters. Accordingly, at block 804 the training module 408 may select a specific UE positioning configuration to jointly train the test device's DNN from the designated set of candidate RAT-assisted UE positioning configurations. Accordingly, each candidate UE positioning configuration may represent a specific combination of UE positioning-related parameters, parameter ranges, or combinations thereof. These parameters or ranges of parameters may include sensor performance parameters, processing performance parameters, battery power parameters, RF-signaling parameters (e.g., number and type of antennas, number and type of subchannels, etc.). These UE positioning-related parameters may also indicate the specific type of reference signal to be used by the BS 108, how the UE 110 will perform the reference signal measurement, the type of sensor data to be fused with the reference signal measurement, etc. Using the candidate UE positioning configurations selected for training, further at block 804 the training module 408 identifies an initial DNN architecture configuration for each of the test BS and test UE, and determines whether the test device is configured to use any of the candidate initial DNN architecture configurations. When saving a copy, the test device is instructed to implement each of these initial DNN architecture configurations by providing the test device with an identifier associated with the initial DNN architecture configuration or by transmitting data representing the initial DNN architecture configuration itself to the test device.
UE 포지셔닝 구성이 선택되고 선택된 UE 포지셔닝 구성에 기초한 DNN 아키텍처 구성으로 테스트 디바이스가 초기화되면, 블록(806)에서 트레이닝 모듈(408)은 선택된 UE 포지셔닝 구성 및 초기 DNN 아키텍처 구성에 기초하여 DNN 체인의 DNN을 공동으로 트레이닝하는 데 사용하기 위한 하나 이상의 트레이닝 데이터 세트를 식별한다. 즉, 하나 이상의 트레이닝 데이터 세트는 오프라인 또는 온라인 동작에서 대응하는 DNN에 대한 입력으로 제공될 수 있고 따라서 DNN을 트레이닝하는 데 적합한 데이터를 포함하거나 나타낸다. 설명하자면, 이 트레이닝 데이터는 테스트 포지셔닝(또는 기타) 레퍼런스 신호의 스트림, 테스트 포지셔닝(또는 기타) 레퍼런스 신호의 테스트 수신 표현, 테스트 포지셔닝(또는 기타) 레퍼런스 신호에 대한 테스트 파라미터 또는 구성, 레퍼런스 신호 측정 테스트, 테스트 중인 구성에 포함된 센서와 일치하는 센서 데이터 테스트, UE 측정 보고 테스트, UE 측정 및 센서 보고 테스트, UE 측정 보고의 수신된 표현 테스트, UE 측정 및 센서 보고의 수신된 표현 테스트, UE 위치 추정 테스트 등을 포함할 수 있다.Once the UE positioning configuration is selected and the test device is initialized with a DNN architecture configuration based on the selected UE positioning configuration, at block 806 the training module 408 generates a DNN in the DNN chain based on the selected UE positioning configuration and the initial DNN architecture configuration. Identify one or more training data sets to use for joint training. That is, one or more training data sets may serve as input to a corresponding DNN in offline or online operation and thus contain or represent data suitable for training the DNN. To illustrate, this training data includes a stream of test positioning (or other) reference signals, a test reception representation of the test positioning (or other) reference signals, test parameters or configurations for the test positioning (or other) reference signals, and test reference signal measurements. , test sensor data matching sensors included in the configuration under test, test UE measurement reports, test UE measurements and sensor reports, test received representations of UE measurement reports, test received representations of UE measurements and sensor reports, estimate UE location. May include testing, etc.
하나 이상의 트레이닝 세트가 획득되면, 블록(808)에서 트레이닝 모듈(408)은 테스트 UE 포지셔닝 경로의 DNN의 공동 트레이닝을 시작한다. 이러한 공동 트레이닝은 일반적으로 의사-무작위로(pseudo-randomly) 선택되는 초기 값으로 다양한 DNN의 바이어스 가중치 및 계수를 초기화하는 것을 포함하고, 그 다음 테스트 BS 디바이스의 TX 프로세싱 모듈(예를 들어, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602))에 트레이닝 데이터 세트를 입력하고, 테스트 UE 디바이스의 RX 프로세싱 모듈(예를 들어, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604))에 대한 전송으로서 결과 출력을 전송하고, 결과 출력을 분석한 다음, 분석에 기초하여 DNN 아키텍처 구성들을 업데이트하는 것을 포함한다. 공동 트레이닝은 또한 테스트 UE 디바이스의 TX 프로세싱 모듈(예를 들어, UE 포지션 피드백 TX 프로세싱 모듈(702))에 트레이닝 데이터 세트를 입력하고, 테스트 BS 디바이스의 RX 프로세싱 모듈(예를 들어, BS 포지션 RX 프로세싱 모듈(704))에 대한 전송으로서 결과 출력을 무선으로 전송하고, 결과 출력을 분석한 다음 분석에 기초하여 DNN 아키텍처 구성을 업데이트하는 것을 포함한다. 다른 예에서, 공동 트레이닝은 테스트 BS 디바이스의 TX 프로세싱 모듈(예를 들어, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602))에 트레이닝 데이터 세트를 입력하고, 테스트 UE 디바이스의 RX 프로세싱 모듈(예를 들어, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604))에 대한 전송으로서 결과 출력을 무선으로 전송하고, 테스트 UE 디바이스의 RX 프로세싱 모듈의 출력을 테스트 UE 디바이스의 TX 프로세싱 모듈(예를 들어, UE 포지션 피드백 TX 프로세싱 모듈(702))에 대한 입력으로 제공하고, 테스트 BS 디바이스의 RX 프로세싱 모듈(예: BS 포지션 RX 프로세싱 모듈(704))에 대한 전송으로서 결과 출력을 무선으로 전송하고, 결과 출력을 분석한 다음 분석에 기초하여 DNN 아키텍처 구성을 업데이트하는 것을 포함하는 엔드-두-엔드 공동 트레이닝을 포함한다. 적어도 일부 실시예에서, 하나 이상의 테스트 디바이스의 DNN 아키텍처 구성 중 적어도 하나는 개별적으로 트레이닝된다.Once one or more training sets are obtained, at block 808 the training module 408 begins joint training of the DNN of the test UE positioning path. Such joint training typically involves initializing the bias weights and coefficients of the various DNNs with initial values that are pseudo-randomly chosen, and then Input the training data set to the reference signal TX processing module 602 and transmit the resulting output as a transmission to the RX processing module of the test UE device (e.g., the UE position reference signal RX processing module 604) , which involves analyzing the resulting output and then updating the DNN architecture configurations based on the analysis. Co-training also involves inputting the training data set to the TX processing module of the test UE device (e.g., UE position feedback TX processing module 702) and the RX processing module of the test BS device (e.g., BS position RX processing Transmission to module 704 includes wirelessly transmitting the resulting output, analyzing the resulting output, and then updating the DNN architecture configuration based on the analysis. In another example, co-training involves inputting a training data set to a TX processing module of a test BS device (e.g., BS position reference signal TX processing module 602) and inputting a training data set to the RX processing module of a test UE device (e.g., Transmit the resulting output wirelessly as a transmission to the UE position reference signal RX processing module 604), and transmit the output of the RX processing module of the test UE device to the TX processing module of the test UE device (e.g., UE position feedback TX processing). module 702), wirelessly transmit the resulting output as a transmission to an RX processing module of the test BS device (e.g., BS position RX processing module 704), and analyze the resulting output. It involves end-to-end joint training, including updating the DNN architecture configuration based on In at least some embodiments, at least one of the DNN architecture configurations of one or more test devices is trained individually.
DNN 트레이닝에 흔히 사용되는 바와 같이, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602), UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604), UE 포지션 피드백 TX 프로세싱 모듈(702), 또는 BS 포지션 RX 프로세싱 모듈(704) 중 하나 이상의 실제 결과 출력의 결과로서 획득된 피드백은 역전파 등을 통해 UE 포지셔닝 경로의 하나 이상의 DNN의 파라미터를 수정하거나 개선하는 데 사용된다. 따라서, 블록(810)에서 관리 구성요소(150) 및/또는 DNN 체인은 전송된 트레이닝 세트에 대한 피드백을 획득한다. 이 피드백의 구현은 다양한 형태 또는 형태의 조합을 취할 수 있다. 적어도 일부 실시예에서, 피드백은 실제 결과 출력과 예상 결과 출력 사이의 오류를 결정하고, DNN 체인의 DNN 전체에 걸쳐 이 오류를 역전파하는 트레이닝 모듈(408) 또는 다른 트레이닝 모듈을 포함한다. 예를 들어, DNN 체인에 의한 프로세싱은 UE 포지션 추정의 형태를 효과적으로 제공하므로, 트레이닝 데이터 세트에 대한 객관적인 피드백은 예를 들어 알려진 UE 위치, 알려진 UE 배향, 알려진 UE 속도 등과 비교하여 DNN 체인으로부터의 출력으로서 획득된 UE 포지션 추정의 정확성을 측정하는 형태일 수 있다.As commonly used in DNN training, the BS position reference signal TX processing module 602, the UE position reference signal RX processing module 604, the UE position feedback TX processing module 702, or the BS position RX processing module 704. The feedback obtained as a result of one or more actual result outputs is used to modify or improve the parameters of one or more DNNs of the UE positioning path, such as through backpropagation. Accordingly, at block 810 the management component 150 and/or the DNN chain obtains feedback about the transmitted training set. Implementation of this feedback can take various forms or combinations of forms. In at least some embodiments, the feedback includes a training module 408 or another training module that determines the error between the actual and expected result outputs and backpropagates this error throughout the DNNs in the DNN chain. For example, processing by the DNN chain effectively provides some form of UE position estimate, so that objective feedback on the training data set can be achieved by comparing the output from the DNN chain to, for example, known UE position, known UE orientation, known UE speed, etc. It may be in the form of measuring the accuracy of the obtained UE position estimate.
블록(812)에서, 관리 구성요소(150) 또는 DNN 체인은 DNN 체인을 통한 테스트 데이터 세트의 전송 결과로서 획득된 피드백을 사용하고, 테스트 송신 디바이스에서 결과 출력의 프리젠테이션 또는 기타 소비(consumption)는 오류의 역전파를 통해 대응하는 DNN의 가중치, 연결 또는 계층을 변경하거나 이러한 피드백에 응답하여 관리 구성요소(150)에 의한 관리된 수정을 통해 UE 포지셔닝 경로의 하나 이상의 DNN의 다양한 측면을 업데이트하는 것이다. 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 블록(806)의 다음 반복에서 선택된 트레이닝 데이터의 다음 세트에 대해 블록(806 내지 812)의 트레이닝 프로세스를 수행하고 특정 횟수의 트레이닝 반복이 수행될 때까지 또는 특정 최소 오류율에 도달할 때까지 반복된다.At block 812, the management component 150 or the DNN chain uses the feedback obtained as a result of transmission of the test data set through the DNN chain, and the presentation or other consumption of the resulting output at the test transmitting device is updating various aspects of one or more DNNs in the UE positioning path by changing the weights, connections or layers of the corresponding DNN through backpropagation of errors or managed modifications by the management component 150 in response to such feedback. . Management component 150 (or another network component) performs the training process of blocks 806 through 812 on the next set of training data selected in the next iteration of block 806 and determines that a certain number of training iterations will be performed. This is repeated until or until a certain minimum error rate is reached.
테스트 BS 디바이스와 테스트 UE 디바이스 사이의 UE 포지셔닝 경로를 따라 신경망을 공동(또는 개별) 트레이닝한 결과로서, 각 신경망은 특정 신경망 아키텍처 구성이 있거나, 구현된 신경망이 DNN인 경우 각 노드에 구현된 은닉 계층 수, 각 계층의 노드 수, 각 계층 간의 연결, 가중치, 계수 및 기타 바이어스 값 등과 같은 대응하는 DNN의 아키텍처 및 파라미터를 나타내는 DNN 아키텍처 구성을 갖는다. 따라서, 선택된 UE 포지셔닝 구성에 대한 UE 포지셔닝 경로의 DNN의 공동 또는 개별 트레이닝이 완료되면, 블록(814)에서, 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 트레이닝된 DNN 구성 중 일부 또는 전부를 시스템(100)의 BS(108) 및 UE(110)에 배포한다. 각 노드는 대응하는 DNN의 결과 DNN 구성을 DNN 아키텍처 구성으로 저장한다. 적어도 일 실시예에서, 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 공동 트레이닝 종료 시에, 은닉 계층 수, 노드 수, 연결, 계수 및 기타 바이어스 값 등과 같은 대응하는 DNN의 아키텍처 및 파라미터를 추출하여 DNN 아키텍처 구성을 생성할 수 있다. 다른 실시예에서, 관리 구성요소(150)는 쌍을 이루는 DNN 아키텍처 구성의 복사본을 세트(412)의 후보 신경망 아키텍처 구성(414)으로 저장한다. 그 다음, 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 필요에 따라 이러한 DNN 아키텍처 구성을 BS(108) 및 UE(110)에 배포한다.As a result of jointly (or separately) training neural networks along the UE positioning path between the test BS device and the test UE device, each neural network has a specific neural network architecture configuration or, if the implemented neural network is a DNN, a hidden layer implemented in each node. It has a DNN architecture configuration that represents the architecture and parameters of the corresponding DNN, such as number, number of nodes in each layer, connections between each layer, weights, coefficients and other bias values, etc. Accordingly, once joint or individual training of the DNNs of the UE positioning path for the selected UE positioning configuration is complete, at block 814, the management component 150 (or another network component) can configure some or all of the trained DNN configurations. Distribute to BS 108 and UE 110 of system 100. Each node stores the resulting DNN configuration of the corresponding DNN as a DNN architecture configuration. In at least one embodiment, the management component 150 (or another network component) determines the architecture and parameters of the corresponding DNN, such as the number of hidden layers, number of nodes, connectivity, coefficients and other bias values, etc. at the end of joint training. By extracting it, a DNN architecture configuration can be created. In another embodiment, management component 150 stores copies of the paired DNN architecture configurations as candidate neural network architecture configurations 414 in set 412. Management component 150 (or other network component) then distributes this DNN architecture configuration to BS 108 and UE 110 as needed.
트레이닝될 하나 이상의 다른 후보 UE 포지셔닝 구성이 남아 있는 경우, 방법(800)은 공동 트레이닝될 다음 후보 UE 포지셔닝 구성의 선택을 위해 블록(804)으로 돌아가고, 트레이닝 모듈(408)에 의해 선택된 다음 UE 포지셔닝 구성에 대해 블록(804 내지 814)의 서브 프로세스가 반복된다. 그렇지 않고, UE 포지셔닝 경로의 DNN이 모든 의도된 UE 포지셔닝 구성에 대해 공동으로 트레이닝된 경우, 방법(800)은 완료되고 시스템(100)은 도 9 내지 도 12를 참조하여 아래에 설명되는 바와 같이 신경망 지원 RAT-지원 UE 포지셔닝으로 전환할 수 있다.If one or more other candidate UE positioning configurations remain to be trained, the method 800 returns to block 804 for selection of the next candidate UE positioning configuration to be jointly trained, and the next UE positioning configuration selected by training module 408 The subprocesses of blocks 804 to 814 are repeated. Otherwise, if the DNNs in the UE positioning path have been jointly trained for all intended UE positioning configurations, method 800 is complete and system 100 is configured to use the neural network as described below with reference to FIGS. 9-12. Can switch to supported RAT-assisted UE positioning.
위에서 언급한 바와 같이, 관리 구성요소(150)(또는 다른 네트워크 구성요소)는 오프라인 테스트 노드를 사용하여(즉, 제어 정보 또는 사용자 평면 데이터의 활성 통신이 발생하지 않는 동안) 또는 의도된 송신 경로의 실제 노드가 온라인 동안(즉, 제어 정보 또는 사용자 평면 데이터의 활성 통신이 발생하는 동안) 공동 트레이닝 프로세스를 수행할 수 있다. 또한, 일부 실시예에서는, 관리 구성요소(150)가 모든 DNN을 공동으로 트레이닝하는 대신, 일부 경우에는 관리 구성요소(150)가 다른 DNN을 정적으로 유지하는 동안 DNN의 서브 세트가 트레이닝되거나 재트레이닝될 수 있다. 예시를 위해, 관리 구성요소(150)는 예를 들어 DNN을 구현하는 디바이스의 성능 변경으로 인해 또는 이전에 보고되지 않은 프로세싱 용량 손실에 응답하여 특정 디바이스의 DNN이 비효율적으로 또는 부정확하게 동작하고 있음을 감지할 수 있으며, 따라서 관리 구성요소(150)는 다른 디바이스의 다른 DNN을 현재 구성으로 유지하면서 디바이스의 DNN(들)의 개별적인 재트레이닝을 스케줄링할 수 있다.As mentioned above, management component 150 (or other network components) may use test nodes offline (i.e., while no active communication of control information or user plane data is occurring) or on the intended transmission path. The joint training process can be performed while the actual nodes are online (i.e., while active communication of control information or user plane data is taking place). Additionally, in some embodiments, instead of management component 150 jointly training all DNNs, in some cases a subset of DNNs are trained or retrained while management component 150 holds other DNNs static. It can be. By way of example, management component 150 may determine that a DNN on a particular device is operating inefficiently or incorrectly, for example, due to a change in the performance of the device implementing the DNN or in response to a previously unreported loss of processing capacity. and thus management component 150 may schedule individual retraining of the device's DNN(s) while maintaining other DNNs on other devices in their current configuration.
또한, 많은 수의 UE 포지셔닝 구성을 지원하는 매우 다양한 디바이스가 있을 수 있지만, 많은 다른 노드가 동일하거나 유사한 UE 포지셔닝 구성을 지원할 수 있다는 것을 알 수 있을 것이다. 따라서, 대표 디바이스의 공동 트레이닝에 이어, UE 포지셔닝 경로에 통합된 모든 디바이스에 대해 공동 트레이닝을 반복해야 하는 대신, 해당 디바이스는 UE 포지셔닝 구성에 대한 트레이닝된 DNN 아키텍처 구성의 표현을 관리 구성요소(150)에 전송할 수 있고, 관리 구성요소(150)는 DNN 아키텍처 구성을 저장한 다음 이를 UE 포지셔닝 경로의 DNN에서의 구현을 위해 동일하거나 유사한 UE 포지셔닝 구성을 지원하는 다른 디바이스에 전송할 수 있다.Additionally, while there may be a wide variety of devices supporting a large number of UE positioning configurations, it will be appreciated that many different nodes may support the same or similar UE positioning configurations. Therefore, instead of having to repeat joint training for all devices integrated in the UE positioning path, following joint training of a representative device, that device can create a representation of the trained DNN architecture configuration for the UE positioning configuration in the management component 150. The management component 150 may store the DNN architecture configuration and then transmit it to another device supporting the same or similar UE positioning configuration for implementation in the DNN of the UE positioning path.
또한, DNN 아키텍처 구성은 대응하는 디바이스가 DNN을 사용하여 동작함에 따라 시간이 지남에 따라 변경되는 경우가 많다. 따라서 동작이 진행됨에 따라, 주어진 디바이스의 신경망 관리 모듈(예: 신경망 관리 모듈(216, 314))은, 예를 들어 트리거에 응답하여 업데이트된 그래디언트(gradient) 및 관련 정보를 관리 구성요소(150)에 제공함으로써, 해당 노드에서 사용되는 하나 이상의 DNN의 업데이트된 아키텍처 구성의 표현을 전송하도록 구성될 수 있다. 이 트리거는 주기적 타이머의 만료, 관리 구성요소(150)로부터의 쿼리, 변경의 크기가 지정된 임계값을 초과했다는 결정 등일 수 있다. 그러면 관리 구성요소(150)는 이러한 수신된 DNN 업데이트를 대응하는 DNN 아키텍처 구성에 통합하고 그에 따라 송신 경로의 노드에 적절하게 배포할 수 있는 업데이트된 DNN 아키텍처 구성을 갖는다.Additionally, DNN architecture configurations often change over time as corresponding devices operate using DNNs. Accordingly, as the operation progresses, the neural network management module of a given device (e.g., neural network management modules 216, 314) may update the gradient and related information, for example in response to a trigger, to the management component 150. The node may be configured to transmit a representation of an updated architectural configuration of one or more DNNs used by that node. This trigger may be the expiration of a periodic timer, a query from management component 150, a determination that the size of the change has exceeded a specified threshold, etc. The management component 150 then has an updated DNN architecture configuration that can incorporate these received DNN updates into the corresponding DNN architecture configuration and distribute them accordingly to the nodes in the transmission path.
도 9 및 도 10은 일부 실시예에 따라 무선 디바이스들 사이에서 공동으로 트레이닝된 DNN 기반 UE 포지셔닝 경로를 사용하여 RAT-지원 UE 포지셔닝을 위한 예시적인 방법(900)을 함께 도시한다. 논의의 편의를 위해, 도 9의 방법(900)은 도 1, 도 6 및 도 7의 UE 포지셔닝 경로(116)의 예시적인 맥락에서 아래에서 설명된다. 또한, 방법(900)의 프로세스는 도 10의 예시적인 래더 다이어그램(1000)을 참조하여 설명된다. 방법(900)은 블록(902)에서 BS(108) 및 UE(110)가 셀룰러 컨텍스트에서 5G NR 독립형 등록(registration)/어태치(attach) 프로세스를 통해 또는 무선 로컬 영역 네트워크네트워크(WLAN) 컨텍스트에서 IEEE 802.11 연관 프로세스를 통해 무선 연결을 설정하는 것으로 시작된다. 블록(904)에서, 관리 구성요소(150)는 BS(108)의 성능 관리 모듈(320)(도 3)에 의해 제공되는 성능 정보(1002)(도 10) 및 UE(110)의 성능 관리 모듈(218)(도 2)에 의해 제공되는 성능 정보(1004)(도 10)와 같은, 성능 정보를 BS(108) 및 UE(110) 각각으로부터 획득한다. 적어도 일부 실시예에서, 관리 구성요소(150)는 동일한 인프라스트럭처 네트워크의 일부일 때 BS(108)의 성능에 대해 이미 통보받을 수 있으며, 이 경우 BS(108)에 대한 성능 정보(1002)를 획득하는 것은 이 정보에 대한 로컬 또는 원격 데이터베이스 또는 다른 데이터 저장소에 액세스하는 것을 포함할 수 있다. UE(110)에 대해, BS(108)는 UE(110)에 성능 요청을 전송할 수 있고, UE(110)는 성능 정보(1004)로 이 요청에 응답하고, BS(108)는 이를 관리 구성요소(150)에 전달한다. 예를 들어, BS(108)는 UECapabilityEnquiry RRC 메시지를 전송할 수 있으며, UE(110)는 이에 CSI 관련 성능 정보를 포함하는 UECapabilityInformation RRC 메시지로 응답한다.9 and 10 together illustrate an example method 900 for RAT-assisted UE positioning using a DNN-based UE positioning path jointly trained between wireless devices, according to some embodiments. For ease of discussion, the method 900 of Figure 9 is described below in the example context of the UE positioning path 116 of Figures 1, 6, and 7. Additionally, the process of method 900 is described with reference to the example ladder diagram 1000 of FIG. 10 . Method 900 at block 902 allows the BS 108 and the UE 110 to perform a 5G NR standalone registration/attach process in a cellular context or in a wireless local area network (WLAN) context. It begins with establishing a wireless connection through the IEEE 802.11 association process. At block 904, management component 150 receives performance information 1002 (FIG. 10) provided by performance management module 320 (FIG. 3) of BS 108 and performance management module of UE 110. Performance information, such as performance information 1004 (FIG. 10) provided by 218 (FIG. 2), is obtained from BS 108 and UE 110, respectively. In at least some embodiments, management component 150 may already be informed about the performance of BS 108 when it is part of the same infrastructure network, in which case obtaining performance information 1002 for BS 108. This may include accessing local or remote databases or other data stores for this information. For UE 110, BS 108 may send a capability request to UE 110, and UE 110 responds to this request with capability information 1004, which BS 108 sends to the management component. Deliver to (150). For example, BS 108 may transmit a UECapabilityEnquiry RRC message, and UE 110 responds with a UECapabilityInformation RRC message including CSI-related performance information.
블록(906)에서, 관리 구성요소(150)의 신경망 선택 모듈(410)은 예를 들어, BS(108)와 UE(110) 사이의 UE 포지셔닝 구성을 나타내는 성능 정보 및 기타 정보를 사용하여, UE 포지셔닝 경로(116)를 지원하기 위해 BS(108) 및 UE(110)에서 구현될 DNN 아키텍처 구성 쌍을 선택한다(DNN 선택(1006), 도 10). 적어도 일부 실시예에서, 신경망 선택 모듈(410)은 DNN 아키텍처 구성의 적합한 쌍을 식별하기 위해 BS(108) 및 UE(110)로부터 획득된 성능 정보 및 UE 포지셔닝 경로(116)의 UE 포지셔닝 구성 파라미터를 세트(412)의 후보 신경망 아키텍처 구성 쌍(414)의 속성과 비교하는 알고리즘 선택 프로세스를 사용한다. 다른 실시예에서, 신경망 선택 모듈(410)은 하나 이상의 LUT에서 후보 DNN 아키텍처 구성을 구성할 수 있고, 각 항목은 대응하는 DNN 아키텍처 구성 쌍을 저장하고 입력 파라미터 또는 파라미터 범위의 대응하는 조합에 의해 인덱싱되며, 따라서 신경망 선택 모듈(410)은 블록(904)에서 하나 이상의 LUT에 대한 입력으로서 식별된 성능 및 UE 포지셔닝 구성 파라미터의 제공을 통해 BS(108) 및 UE(110)에 의해 사용될 DNN 아키텍처 구성의 적합한 쌍을 선택할 수 있다. 적어도 일부 실시예에서, 관리 구성요소(150)는 블록(901 및 903)에 도시된 바와 같이 BS(108) 및 UE(110)로부터 업데이트된 성능 정보를 획득한다. 그 다음 관리 구성요소(150)는 업데이트된 성능 정보에 기초하여 BS(108) 또는 UE(110) 중 하나 이상에 대해 서로 다른 DNN 아키텍처를 선택할 수 있다.At block 906, the neural network selection module 410 of the management component 150 uses performance information and other information, e.g., indicative of the UE positioning configuration between the BS 108 and the UE 110, to select the UE. Select a pair of DNN architecture configurations to be implemented at BS 108 and UE 110 to support positioning path 116 (DNN selection 1006, FIG. 10). In at least some embodiments, neural network selection module 410 uses performance information obtained from BS 108 and UE 110 and UE positioning configuration parameters of UE positioning path 116 to identify suitable pairs of DNN architecture configurations. An algorithmic selection process is used to compare the properties of a set 412 of candidate neural network architecture configuration pairs 414 . In another embodiment, neural network selection module 410 may construct candidate DNN architecture configurations from one or more LUTs, each storing a pair of corresponding DNN architecture configurations and indexed by a corresponding combination of input parameters or parameter ranges. Thus, the neural network selection module 410 selects the DNN architecture configuration to be used by the BS 108 and the UE 110 through providing the identified performance and UE positioning configuration parameters as input to one or more LUTs at block 904. You can choose a suitable pair. In at least some embodiments, management component 150 obtains updated performance information from BS 108 and UE 110, as shown in blocks 901 and 903. Management component 150 may then select a different DNN architecture for one or more of BS 108 or UE 110 based on the updated performance information.
또한 블록(906)에서, 관리 구성요소(150)는 선택된 공동 트레이닝된 DNN 아키텍처 구성 쌍으로부터 각자의 DNN 아키텍처 구성을 구현하도록 BS(108) 및 UE(110)에 지시한다. BS(108) 및 UE(110) 각각이 잠재적인 향후 사용을 위해 후보 DNN 아키텍처 구성을 저장하는 구현예에서, 관리 구성요소(150)는 BS(108) 및 UE(110)에 의해 구현될 DNN 아키텍처 구성의 식별자와 함께 메시지를 전송할 수 있다. 그렇지 않으면, 관리 구성요소(150)는 예를 들어 Layer 1 신호, Layer 2 제어 요소, Layer 3 RRC 메시지 또는 이들의 조합으로서 DNN 아키텍처 구성을 나타내는 정보를 전송할 수 있다. 예를 들어, 도 10을 참조하면, 관리 구성요소(150)는 BS(108)에 대해 선택된 DNN 아키텍처 구성을 나타내는 데이터를 포함하는 DNN 구성 메시지(1008)를 BS(108)에 전송한다. 이 메시지를 수신한 것에 응답하여, BS(108)의 신경망 관리 모듈(314)은 DNN 구성 메시지(1008)로부터 데이터를 추출하고 BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602) 또는 BS 포지셔닝 RX 프로세싱 모듈(704) 중 하나 이상을 구성하여 추출된 데이터에 표시된 DNN 아키텍처 구성을 갖는 하나 이상의 DNN을 구현한다. 마찬가지로, 관리 구성요소(150)는 UE(110)에 대해 선택된 DNN 아키텍처 구성을 나타내는 데이터를 포함하는 DNN 구성 메시지(1010)(도 10)를 UE(110)에 전송한다. 이 메시지를 수신한 것에 응답하여, UE(110)의 신경망 관리 모듈(216)은 DNN 구성 메시지(1010)로부터 데이터를 추출하고, 추출된 데이터에 표시된 DNN 아키텍처 구성을 갖는 하나 이상의 DNN을 구현하기 위해 UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604) 또는 UE 포지션 피드백 TX 프로세싱 모듈(702) 중 하나 이상을 구성한다.Also at block 906, management component 150 instructs BS 108 and UE 110 to implement their respective DNN architecture configurations from the selected co-trained DNN architecture configuration pairs. In implementations where BS 108 and UE 110 each store candidate DNN architecture configurations for potential future use, management component 150 stores the DNN architectures to be implemented by BS 108 and UE 110. You can send a message with the configuration's identifier. Alternatively, the management component 150 may transmit information indicating the DNN architecture configuration as, for example, a Layer 1 signal, a Layer 2 control element, a Layer 3 RRC message, or a combination thereof. For example, referring to FIG. 10 , management component 150 sends to BS 108 a DNN configuration message 1008 containing data indicating the DNN architecture configuration selected for BS 108 . In response to receiving this message, the neural network management module 314 of the BS 108 extracts data from the DNN configuration message 1008 and sends it to the BS position reference signal TX processing module 602 or the BS positioning RX processing module 704. ) to implement one or more DNNs with the DNN architecture configuration indicated in the extracted data. Likewise, management component 150 sends to UE 110 a DNN configuration message 1010 (FIG. 10) containing data indicating the DNN architecture configuration selected for UE 110. In response to receiving this message, the neural network management module 216 of the UE 110 extracts data from the DNN configuration message 1010 and implements one or more DNNs having the DNN architecture configuration indicated in the extracted data. Configures one or more of the UE position reference signal RX processing module 604 or the UE position feedback TX processing module 702.
UE 포지셔닝 경로(116)의 DNN이 초기에 구성되면, RAT-지원 UE 포지셔닝 프로세스가 시작될 수 있다. 따라서, 블록(908)에서 BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)은 입력으로서 BS 레퍼런스 신호 관리 모듈(316)로부터 레퍼런스 신호 정보(122)를 수신하고, 이 입력으로부터 대응하는 레퍼런스 신호(1012)(도 10) 출력(들)을 생성 및 구성한다. 앞서 도 6을 참조하여 설명한 바와 같이, 레퍼런스 신호 정보(122)는 BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)의 DNN(들)이 하나 이상의 레퍼런스 신호(1012)를 생성 및 구성하기 위해 입력으로서 활용하는 BS 및/또는 UE 동작 특성 또는 레퍼런스 신호 파라미터와 같은 하나 이상의 서로 다른 유형의 정보를 포함한다. 레퍼런스 신호 정보(122)는 또한 사용될 특정 빔, 안테나, 서브캐리어 등과 같은 UE 포지셔닝 경로(116)의 UE 포지셔닝 구성에 관한 정보를 포함할 수 있다. 블록(910)에서, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602)은 UE(110)에 대한 레퍼런스 신호(1012)의 무선 전송을 제공한다.Once the DNN of the UE positioning path 116 is initially configured, the RAT-assisted UE positioning process can begin. Accordingly, at block 908, the BS position reference signal TX processing module 602 receives reference signal information 122 from the BS reference signal management module 316 as an input and generates a corresponding reference signal 1012 from this input ( Figure 10) Generating and configuring output(s). As previously described with reference to FIG. 6, the reference signal information 122 is used as an input by the DNN(s) of the BS position reference signal TX processing module 602 to generate and configure one or more reference signals 1012. Contains one or more different types of information, such as BS and/or UE operating characteristics or reference signal parameters. Reference signal information 122 may also include information regarding the UE positioning configuration of the UE positioning path 116, such as the specific beam, antenna, subcarrier, etc. to be used. At block 910 , the BS position reference signal TX processing module 602 provides wireless transmission of the reference signal 1012 to the UE 110 .
블록(912)에서, 레퍼런스 신호(1012)는 UE(110)의 RF 프론트 엔드(204)에 의해 수신 및 프로세싱되고, UE(110)의 레퍼런스 신호 측정 모듈(220)은 결과 출력에 대해 RSRP, RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT 등과 같은 하나 이상의 레퍼런스 신호 측정(1014)을 수행한다(도 10). 블록(914)에서, UE(110)의 UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 레퍼런스 신호 측정(1014) 및 일부 실시예에서, UE 센서 데이터(1016)(도 10)를 입력으로서 수신한다. 적어도 일부 실시예에서, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 레퍼런스 신호(1012)를 입력으로서 수신하고, 레퍼런스 신호 측정 모듈(220)로부터 레퍼런스 신호 측정(1014)을 수신하는 것과 비교하여 레퍼런스 신호 측정(1014)을 수행한다. 이들 입력으로부터, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 UE 센서 데이터(1016)를 UE 레퍼런스 신호 측정(1014)과 융합하는 대응하는 UE 측정 및 센서 보고(1018)(도 10) 출력을 생성한다. 적어도 일부 실시예에서, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 UE 센서 데이터(1016)를 입력으로서 수신하지 않는다. 이들 실시예에서, UE 포지션 레퍼런스 신호 RX 프로세싱 모듈(604)은 (대응하는 UE 측정 및 센서 보고 출력과 비교하여) 대응하는 UE 측정 출력을 생성한다.At block 912, the reference signal 1012 is received and processed by the RF front end 204 of the UE 110, and the reference signal measurement module 220 of the UE 110 performs RSRP, RSTD measurements on the resulting output. , perform one or more reference signal measurements 1014, such as OTDoA, UTDoA, TDAV, AoA, AoD, RTT, etc. (FIG. 10). At block 914, the UE position reference signal RX processing module 604 of UE 110 receives reference signal measurements 1014 and, in some embodiments, UE sensor data 1016 (FIG. 10) as input. In at least some embodiments, the UE position reference signal RX processing module 604 receives the reference signal 1012 as an input and compares the reference signal measurement 1014 from the reference signal measurement module 220 to Perform measurement 1014. From these inputs, the UE Position Reference Signal RX Processing module 604 generates corresponding UE Measurement and Sensor Report 1018 (FIG. 10) outputs that fuse UE sensor data 1016 with UE Reference Signal Measurements 1014. . In at least some embodiments, the UE position reference signal RX processing module 604 does not receive UE sensor data 1016 as input. In these embodiments, the UE position reference signal RX processing module 604 generates corresponding UE measurement outputs (compared to corresponding UE measurement and sensor report outputs).
블록(916)에서, UE(110)의 UE 포지션 피드백 TX 프로세싱 모듈(702)은 UE 측정 및 센서 보고(1018)를 입력으로서 수신하고, 이 입력으로부터 BS(108)로의 무선 전송을 위한 UE 측정 및 센서 보고(144)를 나타내는 대응하는 출력 신호를 생성한다. UE(110)는 무선 통신을 구성하고 전송하기 위해 RRC 프로토콜, LPP 등과 같은 다양한 메시징 메커니즘을 사용할 수 있다. 블록(918)에서, UE 측정 및 센서 보고(1018)를 나타내는 출력 신호는 BS(108)의 RF 프런트 엔드(304)에 의해 수신 및 프로세싱되고, BS(108)의 BS 포지션 RX 프로세싱 모듈(704)에 대한 입력으로서 UE 측정 및 센서 보고(1018)를 제공한다. BS 포지션 RX 프로세싱 모듈(704)은 UE 측정 및 센서 보고(1018)를 프로세싱하며, 이는 적어도 일부 실시예에서 UE 레퍼런스 신호 측정(1014) 및 UE 센서 데이터(1016)를 포함하여 UE(110)에 대한 포지션 추정(1020)(도 10)을 나타내는 출력을 생성한다. 앞서 도 6을 참조하여 설명한 바와 같이, UE 포지션 추정(1020)은 적어도 일부 실시예에서, UE(110)에 의해 제공되는 레퍼런스 신호 측정(들)(1014)을 통합할 뿐만 아니라, UE 센서 데이터(1016)도 통합하여 예를 들어 UE(110)의 로컬 상황, UE 배향의 표시, 움직임(예를 들어, 회전, 방향 등)과 같은 2차 정보 등을 포함하는 UE 포지션 추정을 생성한다.At block 916, the UE position feedback TX processing module 702 of the UE 110 receives the UE measurements and sensor reports 1018 as input and processes the UE measurements and sensor reports 1018 from this input for wireless transmission to the BS 108. Generates a corresponding output signal representing the sensor report 144. UE 110 may use various messaging mechanisms, such as RRC protocol, LPP, etc., to configure and transmit wireless communications. At block 918, output signals representing UE measurements and sensor reports 1018 are received and processed by the RF front end 304 of BS 108 and the BS position RX processing module 704 of BS 108. Provides UE measurements and sensor reports 1018 as input to . BS position RX processing module 704 processes UE measurements and sensor reports 1018, which in at least some embodiments include UE reference signal measurements 1014 and UE sensor data 1016, for UE 110. Produces output representing position estimate 1020 (FIG. 10). As previously described with reference to FIG. 6 , UE position estimation 1020, in at least some embodiments, incorporates reference signal measurement(s) 1014 provided by UE 110, as well as UE sensor data ( 1016) is also integrated to generate a UE position estimate that includes, for example, the local context of the UE 110, an indication of the UE orientation, secondary information such as movement (e.g., rotation, direction, etc.).
블록(920)에서, BS 포지션 레퍼런스 신호 TX 프로세싱 모듈(602) 또는 BS(108)의 다른 TX 프로세싱 모듈은 UE 포지션 추정(1020)에 기초하여 구성되는 RF 신호(1022)(도 10)를 선택적으로 생성하여 UE(110)(또는 다른 네트워크 구성요소)에 전송한다. 블록(922)에서 BS(108)의 신경망 관리 모듈(216) 또는 관리 구성요소(150)의 신경망 선택 모듈(410)은 선택적으로 현재 UE(110)에 대해 계산된 UE 포지션 추정(1020) 및 하나 이상의 다른 UE(110)에 대해 계산된 UE 포지션 추정에 기초하여 BS 포지션 RX 프로세싱 모듈(704)의 하나 이상의 DNN을 조정한다. 예를 들어, BS(108) 또는 관리 구성요소(150)는 현재 UE(110)에 대해 계산된 UE 포지션 추정(1020) 및 하나 이상의 다른 UE(110)에 대해 계산된 UE 포지션 추정이 UE(110)가 동일한 물리적 공간을 점유하고 있음을 표시하는지 여부를 결정한다. 그렇다면, BS(108) 또는 관리 구성요소(150)는 BS 포지션 RX 프로세싱 모듈(604)이 포지셔닝 오류를 범했으며 다수의 UE(110)가 동일한 물리적 공간을 점유할 수 없기 때문에 개선될 필요가 있다고 결정한다. BS(108) 또는 관리 구성요소(150)는 식별된 포지셔닝 오류를 정정하기 위해 BS 포지션 RX 프로세싱 모듈(704)(또는 BS(108) 또는 UE(110)의 나머지 프로세스 모듈 중 임의의 것)의 가중치와 같은 하나 이상의 파라미터를 조정할 수 있다 .At block 920, the BS position reference signal TX processing module 602 or another TX processing module of BS 108 optionally processes the RF signal 1022 (FIG. 10) that is constructed based on the UE position estimate 1020. It is generated and transmitted to the UE 110 (or other network component). At block 922 , the neural network management module 216 of the BS 108 or the neural network selection module 410 of the management component 150 optionally selects a UE position estimate 1020 calculated for the current UE 110 and one One or more DNNs of the BS position RX processing module 704 are adjusted based on the UE position estimates calculated for the other UEs 110 . For example, the BS 108 or management component 150 may configure the UE position estimate 1020 calculated for the current UE 110 and the UE position estimate calculated for one or more other UEs 110 to be the UE 110 . ) indicates that they occupy the same physical space. If so, the BS 108 or management component 150 determines that the BS position RX processing module 604 has made a positioning error and needs to be improved because multiple UEs 110 cannot occupy the same physical space. do. BS 108 or management component 150 weights BS Position RX processing module 704 (or any of the remaining processing modules of BS 108 or UE 110) to correct the identified positioning error. You can adjust one or more parameters such as .
도 9의 방법(900) 및 도 10의 래더 다이어그램(1000)의 대응하는 예시적인 동작이 BS(108)가 레퍼런스 신호를 전송하고 UE(110)가 레퍼런스 신호 측정을 수행하는 구현예를 도시하지만, UE(110)는 레퍼런스 신호를 전송하도록 유사하게 구성될 수 있고, BS(108)는 레퍼런스 신호 측정을 수행하도록 구성될 수 있다. 예를 들어, 도 11 및 도 12는 레퍼런스 신호를 전송하도록 구성된 UE(110) 및 레퍼런스 신호 측정을 수행하도록 구성된 BS(108)를 갖는 실시예에 따라 무선 디바이스들 사이에서 공동으로 트레이닝된 DNN 기반 UE 포지셔닝 경로를 사용하여 RAT-지원 UE 포지셔닝을 위한 예시적인 방법(1100)을 함께 도시한다. 방법(1100)의 프로세스는 도 12의 예시적인 래더 다이어그램(1200)을 참조하여 설명된다. 방법(1100)은 블록(1102)에서 시작하는데, 이는 BS(108) 및 UE(110)의 DNN이 이미 초기에 구성되도록 방법(900)의 블록(906) 이후일 수 있다.Although the corresponding example operations of method 900 of FIG. 9 and ladder diagram 1000 of FIG. 10 illustrate an implementation in which BS 108 transmits a reference signal and UE 110 performs reference signal measurements, UE 110 may be similarly configured to transmit a reference signal, and BS 108 may be configured to perform reference signal measurements. For example, Figures 11 and 12 illustrate a DNN-based UE jointly trained among wireless devices according to an embodiment with a UE 110 configured to transmit a reference signal and a BS 108 configured to perform reference signal measurements. An example method 1100 for RAT-assisted UE positioning using a positioning path is also shown. The process of method 1100 is described with reference to example ladder diagram 1200 in FIG. 12 . Method 1100 begins at block 1102, which may be after block 906 of method 900 such that the DNNs of BS 108 and UE 110 are already initially configured.
따라서, 블록(1102)에서 UE 포지션 레퍼런스 신호 TX 프로세싱 모듈(1202)(도 12)은 레퍼런스 신호 정보(122)를 입력으로서 수신하고, 이 입력으로부터 대응하는 변조된 레퍼런스 신호(1208)(도 12) 출력을 생성 및 구성한다. 앞서 도 6을 참조하여 설명한 바와 같이, 레퍼런스 신호 정보(122)는 UE 포지션 레퍼런스 신호 TX 프로세싱 모듈(1202)의 DNN(들)이 하나 이상의 레퍼런스 신호(1208)를 생성 및 구성하기 위해 입력으로서 활용하는, BS 및/또는 UE 동작 특성 또는 레퍼런스 신호 파라미터와 같은 하나 이상의 다른 유형의 정보를 포함한다. 블록(1104)에서, UE 포지션 레퍼런스 신호 TX 프로세싱 모듈(1202)은 UE(110)에서 이용가능한 하나 이상의 센서로부터 로컬 UE 센서 데이터(1210)(도 12)를 추가로 수신한다. 또한 블록(1104)에서, UE 포지션 레퍼런스 신호 TX 프로세싱 모듈(1202)은 레퍼런스 신호(1208)를 센서 데이터(1210)로 증강시키고 증강된 레퍼런스 신호(1208)를 나타내는 출력을 생성한다. 적어도 일부 실시예에서, 레퍼런스 신호는 센서 데이터(1210)로 증강된 SRS이다. 블록(1106)에서, UE 포지션 레퍼런스 신호 TX 프로세싱 모듈(1202)은 BS(108)로의 증강된 레퍼런스 신호(1208)의 무선 송신을 제공한다.Accordingly, in block 1102 the UE position reference signal TX processing module 1202 (FIG. 12) receives reference signal information 122 as input and generates a corresponding modulated reference signal 1208 (FIG. 12) from this input. Generate and configure output. As previously described with reference to FIG. 6, the reference signal information 122 is used as an input by the DNN(s) of the UE position reference signal TX processing module 1202 to generate and configure one or more reference signals 1208. , BS and/or UE operating characteristics or reference signal parameters. At block 1104, UE position reference signal TX processing module 1202 further receives local UE sensor data 1210 (FIG. 12) from one or more sensors available on UE 110. Also at block 1104, the UE position reference signal TX processing module 1202 augments the reference signal 1208 with sensor data 1210 and generates an output representative of the augmented reference signal 1208. In at least some embodiments, the reference signal is SRS augmented with sensor data 1210. At block 1106, the UE position reference signal TX processing module 1202 provides wireless transmission of the augmented reference signal 1208 to BS 108.
블록(1108)에서, 레퍼런스 신호(1208)는 BS(108)의 RF 프런트 엔드(304)에 의해 수신 및 프로세싱되고, BS(108)의 레퍼런스 신호 측정 모듈(미도시)은 결과 출력에 대해 RSRP, RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT 등과 같은 하나 이상의 레퍼런스 신호 측정(1212)(도 12)을 수행한다. 블록(1110)에서 BS(108)의 BS 포지션 레퍼런스 신호 RX 프로세싱 모듈(1204)(또는 다른 프로세싱 모듈)은 레퍼런스 신호 측정(1212) 및 레퍼런스 신호(1208)와 함께 전송된 UE 센서 데이터(1210)를 입력으로서 수신하고, 이들 입력으로부터 UE(110)에 대한 포지션 추정(1214)(도 12)을 나타내는 출력을 생성한다. 적어도 일부 실시예에서, BS 포지션 레퍼런스 신호 RX 프로세싱 모듈(1204)은 레퍼런스 신호 측정(1212)을 입력으로서 수신하는 것과 비교하여 레퍼런스 신호 측정(1212)을 계산하기 위한 입력으로서 레퍼런스 신호(1208)를 수신한다. 적어도 일부 실시예에서, UE 포지션 추정(1214)은 레퍼런스 신호 측정(1212) 및 UE 센서 데이터(1210) 모두를 통합하여, 예를 들어 UE(110)의 로컬 상황, UE 배향, 움직임(예를 들어, 회전, 방향 등)과 같은 2차 정보 등을 포함하는 UE 포지션 추정을 생성한다.At block 1108, the reference signal 1208 is received and processed by the RF front end 304 of BS 108, and a reference signal measurement module (not shown) of BS 108 performs RSRP, Perform one or more reference signal measurements 1212 (FIG. 12), such as RSTD, OTDoA, UTDoA, TDAV, AoA, AoD, RTT, etc. At block 1110, the BS position reference signal RX processing module 1204 (or another processing module) of BS 108 measures reference signal measurement 1212 and UE sensor data 1210 transmitted with reference signal 1208. Receives as input, and from these inputs produces an output representing a position estimate 1214 (FIG. 12) for the UE 110. In at least some embodiments, the BS position reference signal RX processing module 1204 receives the reference signal 1208 as an input for calculating a reference signal measurement 1212 as compared to receiving the reference signal measurement 1212 as an input. do. In at least some embodiments, UE position estimation 1214 integrates both reference signal measurements 1212 and UE sensor data 1210 to determine, for example, local context of UE 110, UE orientation, movement (e.g. , rotation, direction, etc.) to generate a UE position estimate including secondary information.
블록(1112)에서, BS(108)의 BS TX 프로세싱 모듈(1206)은 선택적으로 UE 포지션 추정(1214)에 기초하여 구성된 RF 신호(1216)(도 12)를 생성하여 UE(110)(또는 다른 네트워크 구성요소)에 전송한다. 블록(1114)에서 BS(108)의 신경망 관리 모듈(216) 또는 관리 구성요소(150)의 신경망 선택 모듈(410)은 도 9의 블록(922)과 관련하여 위에서 논의된 프로세스와 유사하게 현재 UE(110)에 대해 계산된 UE 포지션 추정(1214) 및 하나 이상의 다른 UE(110)에 대해 계산된 UE 포지션 추정에 기초하여 BS 포지션 RX 프로세싱 모듈(704)의 DNN들 중 하나 이상을 선택적으로 조정한다.At block 1112, the BS TX processing module 1206 of BS 108 optionally generates an RF signal 1216 (FIG. 12) configured based on the UE position estimate 1214 to transmit to UE 110 (or other transmitted to network components). At block 1114, the neural network management module 216 of BS 108 or the neural network selection module 410 of management component 150 selects the current UE, similar to the process discussed above with respect to block 922 of FIG. Selectively adjust one or more of the DNNs of the BS position RX processing module 704 based on the UE position estimate 1214 calculated for 110 and the UE position estimate calculated for one or more other UEs 110. .
적어도 일부 실시예에서, 위에 설명된 기술의 특정 측면은 소프트웨어를 실행하는 프로세싱 시스템의 하나 이상의 프로세서에 의해 구현될 수 있다. 소프트웨어는 비일시적 컴퓨터 판독가능 저장 매체에 저장되거나 그렇지 않으면 유형적으로 구현되는 하나 이상의 실행가능한 명령어 세트를 포함한다. 소프트웨어는 하나 이상의 프로세서에 의해 실행될 때 위에서 설명된 기술의 하나 이상의 측면을 수행하기 위해 하나 이상의 프로세서를 조작하는 명령어 및 특정 데이터를 포함할 수 있다. 비일시적 컴퓨터 판독가능 저장 매체는 예를 들어, 자기 또는 광 디스크 저장 디바이스, 플래시 메모리, 캐시, 랜덤 액세스 메모리(RAM)와 같은 고체 상태 저장 디바이스, 또는 기타 비휘발성 메모리 디바이스 또는 디바이스들 등을 포함할 수 있다. 비일시적 컴퓨터 판독가능 저장 매체에 저장된 실행가능한 명령어는 소스 코드, 어셈블리 언어 코드, 목적 코드, 또는 하나 이상의 프로세서에 의해 해석되거나 실행가능한 다른 명령어 형식일 수 있다.In at least some embodiments, certain aspects of the techniques described above may be implemented by one or more processors of a processing system executing software. Software includes one or more sets of executable instructions stored on or otherwise tangibly embodied in a non-transitory computer-readable storage medium. The software may include certain data and instructions that, when executed by one or more processors, manipulate one or more processors to perform one or more aspects of the techniques described above. Non-transitory computer-readable storage media may include, for example, magnetic or optical disk storage devices, flash memory, cache, solid-state storage devices such as random access memory (RAM), or other non-volatile memory device or devices, etc. You can. Executable instructions stored on a non-transitory computer-readable storage medium may be in the form of source code, assembly language code, object code, or other instructions that can be interpreted or executed by one or more processors.
컴퓨터 판독가능 저장 매체는 컴퓨터 시스템에 명령어 및/또는 데이터를 제공하기 위해 사용 중에 컴퓨터 시스템에 의해 액세스가능한 임의의 저장 매체 또는 저장 매체의 조합을 포함할 수 있다. 이러한 저장 매체에는 광학 매체(예: 컴팩트 디스크(CD), 디지털 다목적 디스크(DVD), 블루레이 디스크), 자기 매체(예: 플로피 디스크, 자기 테이프 또는 자기 하드 드라이브), 휘발성 메모리(예: 랜덤 액세스 메모리(RAM) 또는 캐시), 비휘발성 메모리(예: 읽기 전용 메모리(ROM) 또는 플래시 메모리) 또는 MEMS(Microelectromechanical Systems) 기반 저장 매체를 포함할 수 있지만, 이에 국한되지는 않는다. 컴퓨터 판독가능 저장 매체는 컴퓨팅 시스템에 내장되거나(예: 시스템 RAM 또는 ROM), 컴퓨팅 시스템에 고정적으로 부착되거나(예: 자기 하드 드라이브), 컴퓨팅 시스템에 제거가능하게 부착되거나(예: 광 디스크 또는 USB(Universal Serial Bus), 유선 또는 무선 네트워크(예: NAS(Network Accessible Storage))를 통해 컴퓨터 시스템에 연결될 수 있다.A computer-readable storage medium may include any storage medium, or combination of storage media, that is accessible by a computer system during use to provide instructions and/or data to the computer system. These storage media include optical media (such as compact disks (CDs), digital versatile disks (DVDs), and Blu-ray discs), magnetic media (such as floppy disks, magnetic tape, or magnetic hard drives), and volatile memory (such as random access media). It may include, but is not limited to, memory (such as RAM or cache), non-volatile memory (such as read-only memory (ROM) or flash memory), or Microelectromechanical Systems (MEMS)-based storage media. A computer-readable storage medium may be embedded in the computing system (e.g., system RAM or ROM), permanently attached to the computing system (e.g., a magnetic hard drive), or removably attached to the computing system (e.g., an optical disk or USB drive). (Universal Serial Bus), and can be connected to a computer system via a wired or wireless network (e.g., Network Accessible Storage (NAS)).
일반적인 설명에서 위에 설명된 모든 활동이나 요소가 필요한 것은 아니며, 특정 활동이나 디바이스의 일부가 필요하지 않을 수 있으며, 설명된 것 외에 하나 이상의 추가 활동이 수행될 수 있거나 요소가 포함될 수 있다는 점에 유의한다. 또한 활동이 나열되는 순서가 반드시 수행되는 순서와 일치하지는 않는다. 또한, 구체적인 실시예를 참조하여 개념을 설명하였다. 그러나, 당업자는 아래 청구범위에 기재된 본 개시의 범위를 벗어나지 않고 다양한 수정 및 변경이 이루어질 수 있음을 인식한다. 따라서, 명세서 및 도면은 제한적인 의미가 아닌 예시적인 의미로 간주되어야 하며, 이러한 모든 변형은 본 개시의 범위 내에 포함되도록 의도된다.Please note that in general descriptions, not all activities or elements described above may be required, some of the specific activities or devices may not be required, and one or more additional activities may be performed or elements other than those described may be included. . Additionally, the order in which activities are listed does not necessarily correspond to the order in which they are performed. Additionally, the concept was explained with reference to specific examples. However, those skilled in the art will recognize that various modifications and changes may be made without departing from the scope of the present disclosure as set forth in the claims below. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense, and all such modifications are intended to be included within the scope of this disclosure.
이점, 다른 장점 및 문제에 대한 해결책은 특정 실시예와 관련하여 위에서 설명되었다. 그러나 문제에 대한 이점, 장점, 해결책 및 이점, 장점 또는 해결책이 발생하거나 더욱 두드러지게 만들 수 있는 특징은 청구범위의 일부 또는 전부에 대해 중요하거나 필수이거나 필수적인 특징으로 해석되어서는 안 된다. 더욱이, 위에 개시된 특정 실시예는 단지 예시일 뿐이며, 개시된 주제는 본 명세서의 교시의 이점을 갖는 당업자에게 명백하지만 상이하지만 동등한 방식으로 수정되고 실시될 수 있다. 아래 청구범위에 설명된 것 외에 여기에 표시된 구성 또는 설계의 세부 사항에는 제한이 없다. 따라서 위에 개시된 특정 실시예는 변경되거나 수정될 수 있으며 이러한 모든 변형은 개시된 주제의 범위 내에서 고려된다는 것이 명백하다. 따라서, 여기서 추구하는 보호는 아래 청구범위에 기술된 바와 같다.Advantages, other advantages and solutions to problems have been described above with respect to specific embodiments. However, any advantage, advantage, solution to the problem and any feature that may give rise to or make the advantage, advantage or solution more prominent shall not be construed as a material, essential or essential feature of any or all of the claims. Moreover, the specific embodiments disclosed above are by way of example only, and the disclosed subject matter may be modified and practiced in different but equivalent ways, as will be apparent to those skilled in the art having the benefit of the teachings herein. There are no limitations on the details of construction or design shown herein other than those set forth in the claims below. Accordingly, it is clear that certain embodiments disclosed above may be changed or modified and that all such modifications are considered within the scope of the disclosed subject matter. Accordingly, the protection sought herein is as set forth in the claims below.
Claims (20)
제1 디바이스의 송신 신경망(120)에 대한 입력으로서 레퍼런스 신호 정보(122)를 수신하는 단계;
송신 신경망(120)에 의해, 레퍼런스 신호 정보(122)에 기초하여 제1 출력(138)을 생성하는 단계, 제1 출력(138)은 레퍼런스 신호를 나타내고;
제2 디바이스(110)에 의한 수신을 위해 제1 출력(138)을 나타내는 제1 RF 신호(152)를 전송하기 위해 제1 디바이스(108)의 무선 주파수(RF) 안테나 인터페이스(304)를 제어하는 단계;
제1 RF 신호(152)의 전송에 응답하여, 제1 디바이스(108)의 수신 신경망(128)에서, 제2 디바이스(110)와 연관된 하나 이상의 RF 신호들(154)을 나타내는 입력(710)을 수신하는 단계; 및
수신 신경망(128)에 의해, 수신 신경망(128)에 대한 입력(710)에 기초하여 제2 디바이스(110)의 포지션 추정(estimate)(130)을 나타내는 제2 출력(712)을 생성하는 단계를 포함하는, 방법.1. A computer-implemented method of a first device (108), said method comprising:
Receiving reference signal information (122) as input to a transmit neural network (120) of the first device;
generating, by the transmit neural network (120), a first output (138) based on the reference signal information (122), the first output (138) representing a reference signal;
Controlling a radio frequency (RF) antenna interface 304 of a first device 108 to transmit a first RF signal 152 representing a first output 138 for reception by a second device 110. step;
In response to transmission of the first RF signal 152, the receiving neural network 128 of the first device 108 receives an input 710 representing one or more RF signals 154 associated with the second device 110. receiving; and
generating, by the receive neural network 128, a second output 712 representing a position estimate 130 of the second device 110 based on the input 710 to the receive neural network 128. Including, method.
제2 디바이스(110)와 연관된 하나 이상의 RF 신호들(154)을 나타내는 입력(710)을 수신하는 단계는:
제1 RF 신호(152)와 연관된 신호 측정(measurement)들(142)을 나타내는 제2 디바이스(110)로부터의 제2 RF 신호(154)를 수신하는 단계를 포함하는, 방법.According to paragraph 1,
Receiving an input 710 representing one or more RF signals 154 associated with a second device 110 includes:
A method comprising receiving a second RF signal (154) from a second device (110) indicative of signal measurements (142) associated with the first RF signal (152).
제2 디바이스(110)로부터 수신된 제2 RF 신호(154)는 제2 디바이스(110)에서 생성된 로컬 센서 데이터(140)를 더 나타내는, 방법.According to paragraph 2,
The method of claim 1 , wherein the second RF signal (154) received from the second device (110) further represents local sensor data (140) generated at the second device (110).
상기 포지션 추정(130)은 제2 디바이스(110)의 위치 및 제2 디바이스(110)의 배향(orientation)을 표시하는, 방법.According to any one of claims 1 to 3,
The method of claim 1, wherein the position estimate (130) indicates a location of the second device (110) and an orientation of the second device (110).
제1 출력(138)을 생성하는 단계는,
송신 신경망(120)에 대한 제1 신경망 아키텍처 구성(324)에 기초하여 송신 신경망(120)에서 제1 출력(138)을 생성하는 단계를 포함하고; 그리고
제2 출력(712)을 생성하는 단계는 수신 신경망(128)에 대한 제2 신경망 아키텍처 구성(324)에 기초하여 수신 신경망(128)에서 제2 출력(712)을 생성하는 단계를 포함하는, 방법.According to any one of claims 1 to 4,
The step of generating the first output 138 is:
generating a first output (138) in the transmit neural network (120) based on a first neural network architecture configuration (324) for the transmit neural network (120); and
Generating the second output (712) includes generating the second output (712) in the receiving neural network (128) based on a second neural network architecture configuration (324) for the receiving neural network (128). .
제1 디바이스(108) 또는 제2 디바이스(110) 중 적어도 하나의 하나 이상의 성능(capability)들에 기초하여 복수의 신경망 아키텍처 구성들 중에서 제1 신경망 아키텍처 구성(324) 또는 제2 신경망 아키텍처 구성(324) 중 적어도 하나를 선택하는 단계를 더 포함하는, 방법.According to clause 5,
A first neural network architecture configuration 324 or a second neural network architecture configuration 324 among a plurality of neural network architecture configurations based on one or more capabilities of at least one of the first device 108 or the second device 110. ), the method further comprising the step of selecting at least one of.
제1 신경망 아키텍처 구성(324)을 선택하는 단계는:
제2 디바이스(110)의 하나 이상의 성능들(1004)을 나타내는 정보를 제2 디바이스(110)로부터 수신하는 단계; 및
제1 신경망 아키텍처 구성(324)을 선택하기 위해 상기 정보를 사용하는 단계를 포함하는, 방법.According to clause 6,
The steps for selecting a first neural network architecture configuration 324 are:
Receiving information from a second device (110) indicating one or more capabilities (1004) of the second device (110); and
A method comprising using the information to select a first neural network architecture configuration (324).
제1 디바이스(108) 또는 제2 디바이스(110) 중 적어도 하나의 하나 이상의 성능들(1002, 1004)에 기초하여 복수의 신경망 아키텍처 구성들 중에서 제2 신경망 아키텍처 구성(324)을 선택하는 단계를 더 포함하는, 방법.According to clause 6 or 7,
further comprising selecting a second neural network architecture configuration (324) from among the plurality of neural network architecture configurations based on one or more capabilities (1002, 1004) of at least one of the first device (108) or the second device (110). Including, method.
송신 신경망(120)에 대한 제1 신경망 아키텍처 구성(324) 또는 수신 신경망(128)에 대한 제2 신경망 아키텍처 구성(324) 중 적어도 하나를 구현하기 위해 관리 인프라스트럭처(infrastructure) 구성요소(150)로부터 명령(1008)을 수신하는 단계를 더 포함하는, 방법.According to any one of claims 5 to 8,
From a management infrastructure component 150 to implement at least one of a first neural network architecture configuration 324 for the transmit neural network 120 or a second neural network architecture configuration 324 for the receiving neural network 128. The method further comprising receiving a command (1008).
제1 디바이스(108) 또는 제2 디바이스(110) 중 적어도 하나의 하나 이상의 성능들(1002, 1004)의 변경에 응답하여, 송신 신경망(120)에 대한 제3 신경망 아키텍처 구성(324) 또는 수신 신경망(128)에 대한 제4 신경망 아키텍처 구성(324) 중 적어도 하나를 선택하는 단계를 더 포함하는, 방법.According to any one of claims 5 to 9,
In response to a change in one or more capabilities 1002, 1004 of at least one of the first device 108 or the second device 110, a third neural network architecture configuration 324 for the transmit neural network 120 or the receive neural network The method further comprising selecting at least one of the fourth neural network architecture configurations (324) for (128).
제1 디바이스(108)의 송신 신경망(120) 및 수신 신경망(128)과 제2 디바이스(110)의 송신 신경망(148) 및 수신 신경망(134)의 공동 트레이닝에 참여하는 단계를 더 포함하는, 방법.According to any one of claims 1 to 10,
The method further comprising participating in joint training of the transmit neural network 120 and the receive neural network 128 of the first device 108 and the transmit neural network 148 and the receive neural network 134 of the second device 110. .
송신 신경망(120-2)을 구현하는 제3 디바이스(108-2)와 통신하는 단계; 및
제2 디바이스(110)에 의한 수신을 위한 레퍼런스 신호(138-2)를 나타내는 출력을 생성하도록 제3 디바이스(108-2)의 송신 신경망(120-2)을 구성하는 단계를 더 포함하는, 방법.According to any one of claims 1 to 11,
communicating with a third device (108-2) implementing the transmit neural network (120-2); and
The method further comprising configuring the transmit neural network 120-2 of the third device 108-2 to produce an output representative of the reference signal 138-2 for reception by the second device 110. .
제1 디바이스(108)의 수신 신경망(128)에서, 제3 디바이스(110-2)로부터 수신된 하나 이상의 RF 신호들(1208)에 기초하여 제3 디바이스(110-2)의 포지션 추정(214)을 나타내는 제3 출력을 생성하는 단계;
제1 디바이스(108)의 수신 신경망(120)에서, 제2 출력 및 제3 출력이 제2 디바이스(110)와 제3 디바이스(110-2)가 동일한 공간을 점유하고 있음을 표시하는 것으로 결정하는 단계; 및
제2 디바이스(110)와 제3 디바이스(110-2)가 동일한 공간을 점유하고 있음을 표시하는 제2 출력 및 제3 출력에 응답하여, 제1 디바이스(108)의 수신 신경망(120)의 하나 이상의 파라미터들을 정제(refining)하는 단계를 더 포함하는, 방법.According to any one of claims 1 to 11,
In the receive neural network 128 of the first device 108, estimate the position 214 of the third device 110-2 based on one or more RF signals 1208 received from the third device 110-2. generating a third output representing:
The receiving neural network 120 of the first device 108 determines that the second output and the third output indicate that the second device 110 and the third device 110-2 occupy the same space. step; and
In response to the second and third outputs indicating that the second device 110 and the third device 110-2 occupy the same space, one of the receiving neural networks 120 of the first device 108 The method further comprising refining the above parameters.
제1 디바이스(110)의 무선 주파수(RF) 안테나 인터페이스(204)에서, 제2 디바이스(108)로부터 제1 RF 신호(152)를 수신하는 단계, 제1 RF 신호(152)는 레퍼런스 신호(138)를 나타내고;
제1 디바이스(110)의 수신 신경망(134)에 대한 제1 입력으로서 제1 RF 신호(152)의 표현(representation)을 제공하는 단계; 및
수신 신경망(134)에 의해, 수신 신경망(134)에 대한 제1 입력에 기초하여 제1 디바이스(110)에서의 측정 보고(measurement report)(144)를 나타내는 제1 출력(706)을 생성하는 단계를 포함하는, 방법.1. A computer-implemented method of a first device, the method comprising:
At a radio frequency (RF) antenna interface 204 of the first device 110, receiving a first RF signal 152 from a second device 108, wherein the first RF signal 152 is connected to a reference signal 138. );
providing a representation of the first RF signal (152) as a first input to a receiving neural network (134) of the first device (110); and
generating, by the receive neural network 134, a first output 706 representing a measurement report 144 at the first device 110 based on the first input to the receive neural network 134. Method, including.
제1 디바이스(110)의 송신 신경망(148)에서, 입력으로서 수신 신경망(134)으로부터의 제1 출력(706)을 수신하는 단계;
송신 신경망(148)에 의해, 상기 측정 보고(144)를 나타내는 제2 출력을 생성하는 단계; 및
제2 디바이스(108)에 의한 수신을 위해 제2 출력을 나타내는 제2 RF 신호(154)를 전송하기 위해 제1 디바이스(110)의 RF 안테나 인터페이스(204)를 제어하는 단계를 더 포함하는, 방법.According to clause 14,
receiving, at a transmit neural network (148) of the first device (110), a first output (706) from the receive neural network (134) as input;
generating, by a transmission neural network (148), a second output representing the measurement report (144); and
The method further comprising controlling the RF antenna interface 204 of the first device 110 to transmit a second RF signal 154 representing a second output for reception by the second device 108. .
제1 출력을 생성하는 단계(706)는:
레퍼런스 신호(138)를 나타내는 제1 입력에 대해 하나 이상의 레퍼런스 신호 측정들(142)을 수행하는 단계를 포함하며, 상기 측정 보고(144)는 하나 이상의 레퍼런스 신호 측정들(142) 중 적어도 하나를 포함하는, 방법.According to claim 14 or 15,
Step 706 of generating the first output:
performing one or more reference signal measurements (142) on a first input representing a reference signal (138), wherein the measurement report (144) includes at least one of the one or more reference signal measurements (142). How to.
제1 디바이스(110)의 수신 신경망(134)에 대한 제2 입력으로서 제1 디바이스(110)의 하나 이상의 센서들(210)에 의해 생성된 센서 데이터(140)의 표현을 제공하는 단계를 더 포함하고, 상기 측정 보고(144)는 상기 센서 데이터(140)와 융합된 하나 이상의 레퍼런스 신호 측정들(142)을 포함하는, 방법.According to clause 16,
further comprising providing a representation of sensor data 140 generated by one or more sensors 210 of first device 110 as a second input to a receiving neural network 134 of first device 110. and wherein the measurement report (144) includes one or more reference signal measurements (142) fused with the sensor data (140).
수신 신경망(134)에 대한 제1 신경망 아키텍처 구성(224) 또는 송신 신경망(148)에 대한 제2 신경망 아키텍처 구성(324) 중 적어도 하나를 구현하기 위해 네트워크 인프라스트럭처 구성요소(150)로부터 명령(1010)을 수신하는 단계를 더 포함하는, 방법.According to any one of claims 14 to 17,
Instructions 1010 are received from network infrastructure component 150 to implement at least one of a first neural network architecture configuration 224 for receiving neural network 134 or a second neural network architecture configuration 324 for transmitting neural network 148. ), the method further comprising receiving.
제1 디바이스(110)의 하나 이상의 성능들(1004)의 변경에 응답하여, 하나 이상의 성능들(1004)의 변경을 표시하는 메시지를 네트워크 인프라스트럭처 구성요소(150)에 전송하는 단계; 및
메시지 전송에 응답하여, 네트워크 인프라스트럭처 구성요소(150)로부터, 수신 신경망(134) 또는 송신 신경망(148) 중 적어도 하나에 대한 제2 신경망 아키텍처 구성(414)을 수신하는 단계를 더 포함하는, 방법.According to clause 18,
In response to a change in one or more capabilities (1004) of the first device (110), sending a message to the network infrastructure component (150) indicating the change in the one or more capabilities (1004); and
In response to sending the message, the method further comprising receiving, from the network infrastructure component 150, a second neural network architecture configuration 414 for at least one of the receiving neural network 134 or the transmitting neural network 148. .
무선 주파수(RF) 안테나 인터페이스(204, 304);
상기 RF 안테나 인터페이스(204, 304)에 연결된 적어도 하나의 프로세서(206, 306); 및
실행가능한 명령어들을 저장하는 메모리(208, 308)를 포함하고, 상기 실행가능한 명령어들은 제1항 내지 제19항 중 어느 한 항의 방법을 수행하기 위해 상기 적어도 하나의 프로세서(206, 306)를 조작하도록 구성되는, 디바이스.Devices 108 and 110, which:
radio frequency (RF) antenna interfaces 204, 304;
at least one processor (206, 306) connected to the RF antenna interface (204, 304); and
and a memory (208, 308) storing executable instructions, the executable instructions to operate the at least one processor (206, 306) to perform the method of any one of claims 1 to 19. Configured device.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163242312P | 2021-09-09 | 2021-09-09 | |
US63/242,312 | 2021-09-09 | ||
PCT/US2022/042785 WO2023038991A2 (en) | 2021-09-09 | 2022-09-07 | Cellular positioning with local sensors using neural networks |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20240038140A true KR20240038140A (en) | 2024-03-22 |
Family
ID=83692906
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020247008322A KR20240038140A (en) | 2021-09-09 | 2022-09-07 | Cellular positioning using local sensors using neural networks |
Country Status (3)
Country | Link |
---|---|
KR (1) | KR20240038140A (en) |
CN (1) | CN117957462A (en) |
WO (1) | WO2023038991A2 (en) |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2020213964A1 (en) * | 2019-04-16 | 2020-10-22 | Samsung Electronics Co., Ltd. | Method and apparatus for reporting channel state information |
EP3997619A1 (en) * | 2019-08-14 | 2022-05-18 | Google LLC | Communicating a neural network formation configuration |
-
2022
- 2022-09-07 WO PCT/US2022/042785 patent/WO2023038991A2/en active Search and Examination
- 2022-09-07 KR KR1020247008322A patent/KR20240038140A/en unknown
- 2022-09-07 CN CN202280060288.4A patent/CN117957462A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2023038991A3 (en) | 2023-06-01 |
CN117957462A (en) | 2024-04-30 |
WO2023038991A2 (en) | 2023-03-16 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20220052925A1 (en) | Predicting Network Communication Performance using Federated Learning | |
US20220343167A1 (en) | Methods and apparatus for machine learning model life cycle | |
US20230134701A1 (en) | Gnss data in non-terrestrial network system information | |
US20230284060A1 (en) | Synchronization signal block measurement timing configuration window and measurement gap configuration for non-terrestrial networks | |
CN116057853A (en) | Method and apparatus for fusing radio frequency and sensor measurements for beam management | |
Mohamed et al. | DeepFeat: Robust large-scale multi-features outdoor localization in LTE networks using deep learning | |
KR20230073305A (en) | Managing radio access network behavior | |
US20230059954A1 (en) | Method, electronic device and non-transitory computer-readable storage medium for determining indoor radio transmitter distribution | |
KR20240038140A (en) | Cellular positioning using local sensors using neural networks | |
US20220360944A1 (en) | Method and apparatus for sensor selection for localization and tracking | |
KR20230170975A (en) | Wireless networks using neural networks for channel state feedback | |
WO2023220145A1 (en) | Conditional neural networks for cellular communication systems | |
WO2023150348A2 (en) | Random-access channel procedure using neural networks | |
WO2022221388A1 (en) | Wireless system employing end-to-end neural network configuration for data streaming | |
US20240146620A1 (en) | Device using neural network for combining cellular communication with sensor data | |
WO2023151657A1 (en) | Information processing method and communication device | |
WO2023185566A1 (en) | Method for wireless communication, and electronic device and computer-readable storage medium | |
US20230319867A1 (en) | Methods and apparatuses for radio communication | |
EP4254837A1 (en) | Methods and apparatuses for radio communication | |
EP4250181A1 (en) | Utilizing machine learning models to estimate user device spatiotemporal behavior | |
WO2022263892A1 (en) | Extended reality overlay optimization via distributed computing | |
JP2023549330A (en) | Method and system for signaling ephemeris data in non-terrestrial networks | |
CN117441176A (en) | Selection of a global machine learning model for collaborative machine learning in a communication network | |
JP2024519274A (en) | Wireless system employing end-to-end neural network configuration for data streaming - Patents.com | |
JP2024514567A (en) | Dynamic Search Windows for Angle of Arrival Estimation |