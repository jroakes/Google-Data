JP2021061000A - Digital assistant processing of data structure in stack format - Google Patents
Digital assistant processing of data structure in stack format Download PDFInfo
- Publication number
- JP2021061000A JP2021061000A JP2020191600A JP2020191600A JP2021061000A JP 2021061000 A JP2021061000 A JP 2021061000A JP 2020191600 A JP2020191600 A JP 2020191600A JP 2020191600 A JP2020191600 A JP 2020191600A JP 2021061000 A JP2021061000 A JP 2021061000A
- Authority
- JP
- Japan
- Prior art keywords
- profile
- data structure
- processing system
- data processing
- profile layer
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Abstract
Description
本発明は、スタック形式のデータ構造のデジタルアシスタント処理に関する。 The present invention relates to digital assistant processing of stack-type data structures.
公共空間に置かれたコンピューティングデバイスは、安全ではない可能性がある。様々なエンティティが、公共のコンピューティングデバイスにアクセスするかまたは利用する可能性がある。異なるエンティティが公共のコンピューティングデバイスにアクセスするかまたは利用するとき、異なるエンティティのためのポリシーに伴う曖昧性が原因で特定のエンティティのための遠隔手続き呼び出し、アプリケーション、またはスクリプトを正確に処理することが難しくなり、それによって、無駄なネットワークおよび処理リソースにつながる誤ったネットワーク送信、アプリケーションの呼び出し、および遠隔手続き呼び出しを引き起こすことがある。 Computing devices placed in public spaces may not be secure. Various entities may access or utilize public computing devices. Accurately handle remote procedure calls, applications, or scripts for a particular entity due to the ambiguity associated with policies for the different entity when they access or utilize public computing devices. Can be difficult, which can lead to false network transmissions, application calls, and remote procedure calls that lead to wasted networks and processing resources.
概して、本開示は、公共の場所にあるデジタルアシスタントの効率を改善するためにスタック形式のデータ構造を処理することを対象とする。データ処理システムが、電子アカウントを特定するために話者認識を実行し、それから、公共の場所に関連する第三者エンティティによって確立されたベースラインプロファイルを有する第1のレイヤを含むプロファイルスタックデータ構造に話者に関連するプロファイルをプッシュすることができる。データ処理システムは、トリガイベントに応答してプロファイルスタックデータ構造を分解することができ、それによって、セキュリティを維持し、誤った遠隔手続き呼び出しを削減する。 In general, the present disclosure is intended to process stacked data structures to improve the efficiency of digital assistants in public places. A profile stack data structure containing a first layer in which a data processing system performs speaker recognition to identify an electronic account and then has a baseline profile established by a third party entity associated with a public place. You can push profiles related to the speaker to. Data processing systems can decompose profile stack data structures in response to trigger events, thereby maintaining security and reducing false remote procedure calls.
少なくとも1つの態様は、スタック形式のデータ構造を処理するためのシステムを対象とする。システムは、自然言語プロセッサコンポーネント、インターフェース、話者認識コンポーネント、およびダイレクトアクションアプリケーションプログラミングインターフェースを実行するための1つまたは複数のプロセッサおよびメモリを有するデータ処理システムを含み得る。インターフェースは、ローカルコンピューティングデバイスのセンサによって検出された入力オーディオ信号を含むデータパケットを受信することができる。データ処理システムは、入力オーディオ信号から音響シグネチャ(acoustic signature)を特定することができる。データ処理システムは、データリポジトリ内でのルックアップに基づいて音響シグネチャに対応する電子アカウントを特定することができる。データ処理システムは、電子アカウントを特定したことに応答して、セッションおよびセッションにおいて使用するためのプロファイルスタックデータ構造を確立することができる。プロファイルスタックデータ構造は、第三者エンティティのデバイスによって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含み得る。データ処理システムは、アカウントから取り出された第2のプロファイルレイヤを、セッションのために確立されたプロファイルスタックデータ構造にプッシュすることができる。データ処理システムは、要求および要求に対応するトリガキーワードを特定するために入力オーディオ信号をパースすることができる。データ処理システムは、プロファイルスタックデータ構造の第1のプロファイルレイヤに適合する要求に応答する第1のアクションデータ構造を、トリガキーワードとプロファイルスタックデータ構造にプッシュされた第2のプロファイルレイヤとに基づいて生成することができる。データ処理システムは、実行するために第1のアクションデータ構造を提供することができる。データ処理システムは、トリガイベントを検出したことに応答して、プロファイルスタックデータ構造を分解して、プロファイルスタックデータ構造から第1のプロファイルレイヤまたは第2のプロファイルレイヤのうちの一方を取り除くことができる。 At least one aspect is intended for systems for processing stacked data structures. The system may include a natural language processor component, an interface, a speaker recognition component, and a data processing system having one or more processors and memory for performing direct action application programming interfaces. The interface can receive data packets containing input audio signals detected by the sensors of the local computing device. The data processing system can identify the acoustic signature from the input audio signal. The data processing system can identify the electronic account corresponding to the acoustic signature based on the lookup in the data repository. The data processing system can establish a session and a profile stack data structure for use in the session in response to identifying the electronic account. The profile stack data structure may include a first profile layer with one or more policies configured by devices of third party entities. The data processing system can push the second profile layer retrieved from the account to the profile stack data structure established for the session. The data processing system can parse the input audio signal to identify the request and the trigger keyword corresponding to the request. The data processing system bases the first action data structure, which responds to requests that match the first profile layer of the profile stack data structure, on the trigger keyword and the second profile layer pushed into the profile stack data structure. Can be generated. The data processing system can provide a first action data structure to perform. In response to detecting a trigger event, the data processing system can decompose the profile stack data structure to remove either the first profile layer or the second profile layer from the profile stack data structure. ..
少なくとも1つの態様は、スタック形式のデータ構造を処理する方法を対象とする。方法は、1つまたは複数のプロセッサおよびメモリを有するデータ処理システムによって実行され得る。方法は、データ処理システムのインターフェースがローカルコンピューティングデバイスのセンサによって検出された入力オーディオ信号を含むデータパケットを受信するステップを含み得る。方法は、データ処理システムが入力オーディオ信号から音響シグネチャを特定するステップを含み得る。方法は、データ処理システムがデータリポジトリ内でのルックアップに基づいて音響シグネチャに対応する電子アカウントを特定するステップを含み得る。方法は、データ処理システムが電子アカウントを特定したことに応答してセッションおよびセッションにおいて使用するためのプロファイルスタックデータ構造を確立するステップを含み得る。プロファイルスタックデータ構造は、第三者エンティティのデバイスによって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含み得る。方法は、データ処理システムがアカウントから取り出された第2のプロファイルレイヤをセッションのために確立されたプロファイルスタックデータ構造にプッシュするステップを含み得る。方法は、データ処理システムが要求および要求に対応するトリガキーワードを特定するために入力オーディオ信号をパースするステップを含み得る。方法は、データ処理システムがプロファイルスタックデータ構造の第1のプロファイルレイヤに適合する要求に応答する第1のアクションデータ構造を、トリガキーワードとプロファイルスタックデータ構造にプッシュされた第2のプロファイルレイヤとに基づいて生成するステップを含み得る。方法は、データ処理システムが実行するために第1のアクションデータ構造を提供するステップを含み得る。方法は、データ処理システムがトリガイベントを検出したことに応答してプロファイルスタックデータ構造を分解して、プロファイルスタックデータ構造から第1のプロファイルレイヤまたは第2のプロファイルレイヤのうちの一方を取り除くステップを含み得る。 At least one aspect is intended for methods of processing stacked data structures. The method can be performed by a data processing system with one or more processors and memory. The method may include the interface of the data processing system receiving a data packet containing an input audio signal detected by a sensor of a local computing device. The method may include a step in which the data processing system identifies the acoustic signature from the input audio signal. The method may include the step of the data processing system identifying the electronic account corresponding to the acoustic signature based on the lookup in the data repository. The method may include the session and the step of establishing a profile stack data structure for use in the session in response to the data processing system identifying the electronic account. The profile stack data structure may include a first profile layer with one or more policies configured by devices of third party entities. The method may include a step in which the data processing system pushes a second profile layer retrieved from the account into the profile stack data structure established for the session. The method may include a step in which the data processing system parses the input audio signal to identify the request and the trigger keyword corresponding to the request. The method involves a first action data structure in which the data processing system responds to requests that match the first profile layer of the profile stack data structure, with trigger keywords and a second profile layer pushed into the profile stack data structure. It may include steps to generate based on. The method may include a step of providing a first action data structure for the data processing system to perform. The method involves decomposing the profile stack data structure in response to the data processing system detecting a trigger event and removing either the first or second profile layer from the profile stack data structure. Can include.
少なくとも1つの態様は、デジタルアシスタントデバイスを対象とする。デジタルアシスタントデバイスは、オーディオドライバと、トランスデューサと、入力オーディオ信号を検出するためのセンサと、オーディオドライバ、トランスデューサ、およびセンサに結合されたプリプロセッサコンポーネントとを含み得る。プリプロセッサコンポーネントは、フィルタリングされた入力オーディオ信号を生成するために入力オーディオ信号をフィルタリングすることができる。プリプロセッサコンポーネントは、フィルタリングされた入力オーディオ信号をデータパケットに変換することができる。プリプロセッサコンポーネントは、自然言語プロセッサコンポーネント、インターフェース、話者認識コンポーネント、およびダイレクトアクションアプリケーションプログラミングインターフェースを実行する、1つまたは複数のプロセッサおよびメモリを含むデータ処理システムにデータパケットを送信することができる。データ処理システムは、センサによって検出されたフィルタリングされた入力オーディオ信号を含むデータパケットをプリプロセッサコンポーネントからインターフェースを介して受信することができる。データ処理システムは、入力オーディオ信号から音響シグネチャを特定することができる。データ処理システムは、データリポジトリ内でのルックアップに基づいて音響シグネチャに対応する電子アカウントを特定することができる。データ処理システムは、電子アカウントを特定したことに応答して、セッションおよびセッションにおいて使用するためのプロファイルスタックデータ構造を確立することができる。プロファイルスタックデータ構造は、第三者エンティティのデバイスによって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含み得る。データ処理システムは、電子アカウントから取り出された第2のプロファイルレイヤを、セッションのために確立されたプロファイルスタックデータ構造にプッシュすることができる。データ処理システムは、要求および要求に対応するトリガキーワードを特定するために入力オーディオ信号をパースすることができる。データ処理システムは、プロファイルスタックデータ構造の第1のプロファイルレイヤに適合する要求に応答する第1のアクションデータ構造を、トリガキーワードとプロファイルスタックデータ構造にプッシュされた第2のプロファイルレイヤとに基づいて生成することができる。データ処理システムは、実行するために第1のアクションデータ構造を提供することができる。データ処理システムは、トリガイベントを検出したことに応答して、プロファイルスタックデータ構造を分解して、プロファイルスタックデータ構造から第1のプロファイルレイヤまたは第2のプロファイルレイヤのうちの一方を取り除くことができる。データ処理システムは、プロファイルスタックデータ構造のステータスをプリプロセッサコンポーネントに提供することができる。デジタルアシスタントデバイスのオーディオドライバは、さらに、プロファイルスタックデータ構造のステータスの指示を受信し、指示に基づいて出力信号を生成することができる。デジタルアシスタントデバイスのトランスデューサは、さらに、オーディオドライバによって生成された出力信号に基づいて音を生成することができる。 At least one aspect is intended for digital assistant devices. The digital assistant device may include an audio driver, a transducer, a sensor for detecting the input audio signal, and an audio driver, a transducer, and a preprocessor component coupled to the sensor. The preprocessor component can filter the input audio signal to produce a filtered input audio signal. The preprocessor component can convert the filtered input audio signal into data packets. The preprocessor component can send a data packet to a data processing system that contains one or more processors and memory that runs a natural language processor component, an interface, a speaker recognition component, and a direct action application programming interface. The data processing system can receive a data packet containing the filtered input audio signal detected by the sensor from the preprocessor component via the interface. The data processing system can identify the acoustic signature from the input audio signal. The data processing system can identify the electronic account corresponding to the acoustic signature based on the lookup in the data repository. The data processing system can establish a session and a profile stack data structure for use in the session in response to identifying the electronic account. The profile stack data structure may include a first profile layer with one or more policies configured by devices of third party entities. The data processing system can push a second profile layer retrieved from the electronic account into the profile stack data structure established for the session. The data processing system can parse the input audio signal to identify the request and the trigger keyword corresponding to the request. The data processing system bases the first action data structure, which responds to requests that match the first profile layer of the profile stack data structure, on the trigger keyword and the second profile layer pushed into the profile stack data structure. Can be generated. The data processing system can provide a first action data structure to perform. In response to detecting a trigger event, the data processing system can decompose the profile stack data structure to remove either the first profile layer or the second profile layer from the profile stack data structure. .. The data processing system can provide the status of the profile stack data structure to the preprocessor component. The audio driver of the digital assistant device can also receive an indication of the status of the profile stack data structure and generate an output signal based on the indication. Transducers in digital assistant devices can also generate sound based on the output signal generated by the audio driver.
これらのおよびその他の態様および実装が、下で詳細に検討される。上述の情報および下の詳細な説明は、様々な態様および実装の例示的な例を含み、請求される態様および実装の本質および特徴を理解するための概要または枠組みを提供する。図面は、様々な態様および実装の例示をし、さらに理解させ、本明細書の一部に組み込まれ、本明細書の一部を構成する。 These and other aspects and implementations are discussed in detail below. The information above and the detailed description below include exemplary examples of various aspects and implementations and provide an overview or framework for understanding the essence and characteristics of the claimed aspects and implementations. The drawings exemplify various aspects and implementations, make them more understandable, incorporated into parts of this specification, and constitute parts of this specification.
添付の図面は、正しい縮尺で描かれるように意図されていない。様々な図面における同様の参照番号および参照指示は、同様の要素を示す。明瞭にする目的で、あらゆる図面においてあらゆるコンポーネントがラベル付けされるとは限らない可能性がある。 The attached drawings are not intended to be drawn to the correct scale. Similar reference numbers and reference instructions in various drawings indicate similar elements. Not all components may be labeled in every drawing for clarity purposes.
以下は、コンピュータネットワークを介してパケット化されたアクション(packetized action)をルーティングする方法、装置、およびシステムに関連する様々な概念ならびにそれらの方法、装置、およびシステムの実装のより詳細な説明である。上で導入され、下でより詳細に検討される様々な概念は、多数の方法のいずれかで実装される可能性がある。 The following is a more detailed description of how to route packetized actions over a computer network, devices, and various concepts related to the system, as well as implementations of those methods, devices, and systems. .. The various concepts introduced above and discussed in more detail below can be implemented in any of a number of ways.
概して、本開示は、公共の場所にあるデジタルアシスタントを動作させ、その効率を改善するためにスタック形式のデータ構造を処理することを対象とする。データ処理システムが、電子アカウントを特定するために話者認識を実行し、それから、公共の場所に関連する第三者エンティティによって確立されたベースラインプロファイルを有する第1のレイヤを含むプロファイルスタックデータ構造に、話者に関連するプロファイルをプッシュすることができる。データ処理システムは、トリガイベントに応答してプロファイルスタックデータ構造を分解することができ、それによって、セキュリティを維持し、誤った遠隔手続き呼び出しを削減する。 In general, the present disclosure is intended to operate digital assistants in public places and process stacked data structures to improve their efficiency. A profile stack data structure containing a first layer in which a data processing system performs speaker recognition to identify an electronic account and then has a baseline profile established by a third party entity associated with a public place. You can push profiles related to the speaker. Data processing systems can decompose profile stack data structures in response to trigger events, thereby maintaining security and reducing false remote procedure calls.
この解決策は、エンドユーザからの音声に基づく命令をパースし、音響シグネチャを特定し、対応するプロファイルを選択し、第1のレイヤ内にデフォルトプロファイルを含むプロファイルスタックにプロファイルをプッシュし、選択されたプロファイルを使用してアクションデータ構造を構築し、アクションデータ構造がデフォルトプロファイルに適合するかどうかを判定し、アクションデータ構造を対応するデバイスにルーティングし、それから、トリガイベントに応答してプロファイルスタックを分解することによってリソースの消費、プロセッサの利用、バッテリーの消費、帯域幅の利用、オーディオファイルのサイズ、またはスピーカによって消費される時間の量を削減することができる。 The solution is to parse voice-based instructions from the end user, identify the acoustic signature, select the corresponding profile, push the profile to the profile stack that contains the default profile in the first layer, and select it. Use the profile to build the action data structure, determine if the action data structure fits the default profile, route the action data structure to the corresponding device, and then populate the profile stack in response to a trigger event. Decomposition can reduce resource consumption, processor usage, battery consumption, bandwidth usage, audio file size, or the amount of time consumed by the speaker.
この解決策のシステムおよび方法は、ホテルの部屋などの公共の場において使用するために、または来客が一時的な使用(たとえば、10分、30分、1時間、2時間、24時間、48時間、72時間)のためにデジタルアシスタントにサインインすることを可能にするためにデジタルアシスタントを構成することができる。解決策は、以前の構成に戻し、すべてのセッション情報を消去するかまたは保護することによってデジタルアシスタントがインテリジェントにアカウントと結合およびアカウントから分離することを可能にすることができる。デジタルアシスタントは、任意の第三者デバイスまたはインターフェースとのセッションまたはリンクをさらに確立することによってインテリジェントに結合することができる。デジタルアシスタントは、クイックレスポンスコード、光符号、バーコード、またはフィンガープリンティングを提供することが可能であるその他の視覚もしくは音響信号を示すなど、正しいデバイスがサービスのために利用されることを保証するのを助けるための安全な認証メカニズムを提供することができる。解決策は、デジタルアシスタントを工場出荷時設定にリセットし、分離を自動的にトリガし、適切な分離を保証するための冗長なメカニズムを提供することによって分離することができる。解決策は、デジタルアシスタントまたはデジタルアシスタントによって提供されるデジタルコンテンツのカスタマイズを許すこともできる。たとえば、デジタルアシスタントを提供するホテルのためのデジタルコンポーネントが、ホテルのブランディングを提供するためにより重く重み付けされ得る。また、ユーザがデジタルアシスタントをまだ持っていない場合に、デジタルコンポーネントが、デジタルアシスタントのために提供され得る。 The systems and methods of this solution are for use in public places such as hotel rooms, or for temporary use by guests (eg, 10 minutes, 30 minutes, 1 hour, 2 hours, 24 hours, 48 hours). , 72 hours) You can configure your digital assistant to allow you to sign in to your digital assistant. The solution can revert to the previous configuration and allow the digital assistant to intelligently combine and separate accounts by erasing or protecting all session information. Digital assistants can be intelligently coupled by further establishing sessions or links with any third party device or interface. The digital assistant ensures that the correct device is used for service, such as showing a quick response code, optical code, barcode, or other visual or acoustic signal capable of providing fingerprinting. A secure authentication mechanism can be provided to help. The solution can be isolated by resetting the digital assistant to factory settings, automatically triggering the isolation, and providing a redundant mechanism to ensure proper isolation. The solution can also allow the digital assistant or the customization of digital content provided by the digital assistant. For example, digital components for hotels that provide digital assistants can be weighted more heavily to provide hotel branding. Also, digital components may be provided for the digital assistant if the user does not already have the digital assistant.
図1は、プロファイルスタックを処理するための例示的なシステム100を示す。システム100は、コンテンツ選択インフラストラクチャを含み得る。システム100は、データ処理システム102を含み得る。データ処理システム102は、ネットワーク105を介して1つまたは複数のコンテンツプロバイダコンピューティングデバイス106、第三者デバイス146、またはローカルコンピューティングデバイス104と通信することができる。ネットワーク105は、インターネット、ローカルエリアネットワーク、ワイドエリアネットワーク、メトロエリアネットワーク、またはその他のエリアネットワークなどのコンピュータネットワーク、イントラネット、衛星ネットワーク、および音声またはデータモバイル電話ネットワークなどのその他の通信ネットワークを含み得る。ネットワーク105は、ラップトップ、デスクトップ、タブレット、デジタルアシスタントデバイス、スマートフォン、ポータブルコンピュータ、またはスピーカなどの少なくとも1つのローカルコンピューティングデバイス104上で提示されるか、出力されるか、レンダリングされるか、または表示され得るウェブページ、ウェブサイト、ドメイン名、またはユニフォームリソースロケータなどの情報リソースにアクセスするために使用され得る。たとえば、ネットワーク105を介して、ローカルコンピューティングデバイス104のユーザは、コンテンツプロバイダ106によって提供される情報またはデータにアクセスすることができる。コンピューティングデバイス104は、ディスプレイを含む可能性があり、または含まない可能性があり、たとえば、コンピューティングデバイスは、マイクロフォンおよびスピーカなどの限られた種類のユーザインターフェースを含む可能性がある。場合によっては、コンピューティングデバイス104の主なユーザインターフェースは、マイクロフォンおよびスピーカ、または音声インターフェースである可能性がある。
Figure 1 shows an
ローカルコンピューティングデバイス104は、公共の場所202などの公共の場かまたは私的な場所402などの私的な場に置かれるコンピューティングデバイスまたはクライアントデバイスを指す可能性がある。ローカルという用語は、ユーザが音声入力またはその他の入力を使用してコンピューティングデバイスとインタラクションすることができる場所にコンピューティングデバイスが置かれていることを指す可能性がある。ローカルコンピューティングデバイスは、データ処理システム102などの遠隔のサーバから離れて置かれ得る。したがって、ローカルコンピューティングデバイス104は、ユーザが音声入力を使用してローカルコンピューティングデバイス104とインタラクションすることができるホテルの部屋、モール、小個室、またはその他の建物または住居内に配置され得る一方、データ処理システム102は、たとえば、遠隔のデータセンター内に置かれ得る。ローカルコンピューティングデバイス104は、デジタルアシスタントデバイスと呼ばれる可能性がある。
Local computing device 104 may refer to a computing device or client device that is placed in a public place such as
ネットワーク105は、表示ネットワーク(display network)、たとえば、コンテンツ配置または検索エンジン結果システムに関連付けられるか、または第三者のデジタルコンポーネントをデジタルコンポーネント配置キャンペーン(digital component placement campaign)の一部として含むのにふさわしいインターネット上で利用可能な情報リソースのサブセットを、含むかまたは成すことが可能である。ネットワーク105は、ローカルクライアントコンピューティングデバイス104によって提示されるか、出力されるか、レンダリングされるか、または表示され得るウェブページ、ウェブサイト、ドメイン名、またはユニフォームリソースロケータなどの情報リソースにアクセスするためにデータ処理システム102によって使用され得る。たとえば、ネットワーク105を介して、ローカルクライアントコンピューティングデバイス104のユーザは、コンテンツプロバイダコンピューティングデバイス106またはサービスプロバイダコンピューティングデバイス108によって提供される情報またはデータにアクセスすることができる。
ネットワーク105は、任意の種類または形態のネットワークであってよく、以下、すなわち、ポイントツーポイントネットワーク、ブロードキャストネットワーク、ワイドエリアネットワーク、ローカルエリアネットワーク、電気通信ネットワーク、データ通信ネットワーク、コンピュータネットワーク、ATM(非同期転送モード)ネットワーク、SONET(同期光ネットワーク)ネットワーク、SDH(同期デジタルハイアラーキ)ネットワーク、ワイヤレスネットワーク、および有線ネットワークのいずれかを含む可能性がある。ネットワーク105は、赤外線チャネルまたは衛星帯域などのワイヤレスリンクを含む可能性がある。ネットワーク105のトポロジーは、バス型、スター型、またはリング型ネットワークトポロジーを含む可能性がある。ネットワークは、改良型移動電話プロトコル(「AMPS」)、時分割多元接続(「TDMA」)、符号分割多元接続(「CDMA(登録商標)」)、移動体通信用グローバルシステム(global system for mobile communication)(「GSM(登録商標)」)、汎用パケット無線サービス(general packet radio services)(「GPRS」)、またはユニバーサル移動体通信システム(universal mobile telecommunications system)(「UMTS」)を含む、モバイルデバイスの間で通信するために使用される任意の1つのプロトコルまたは複数のプロトコルを使用するモバイル電話ネットワークを含む可能性がある。異なる種類のデータが、異なるプロトコルによって送信されてもよく、または同じ種類のデータが、異なるプロトコルによって送信されてもよい。
The
システム100は、少なくとも1つのデータ処理システム102を含み得る。データ処理システム102は、ネットワーク105を介して、たとえば、コンピューティングデバイス104、コンテンツプロバイダコンピューティングデバイス106(コンテンツプロバイダ106)、または第三者デバイス146(第三者146)と通信するためのプロセッサを有するコンピューティングデバイスなどの少なくとも1つの論理デバイスを含み得る。データ処理システム102は、少なくとも1つの計算リソース、サーバ、プロセッサ、またはメモリを含み得る。たとえば、データ処理システム102は、少なくとも1つのデータセンターに置かれた複数の計算リソースまたはサーバを含み得る。データ処理システム102は、複数の論理的にグループ分けされたサーバを含み、分散型コンピューティング技術を促進することができる。サーバの論理的グループは、データセンター、サーバファーム、またはマシンファームと呼ばれる場合がある。また、サーバは、地理的に分散され得る。データセンターまたはマシンファームは、単一のエンティティとして運用されてもよく、またはマシンファームは、複数のマシンファームを含み得る。各マシンファーム内のサーバは、異種である可能性がある--サーバまたはマシンのうちの1つまたは複数が、1つまたは複数の種類のオペレーティングシステムプラットフォームに応じて動作することができる。
マシンファーム内のサーバは、関連するストレージシステムと一緒に高密度ラックシステムに収容され、エンタープライズデータセンターに置かれ得る。たとえば、このようにしてサーバをまとめることは、サーバおよび高性能ストレージシステムを局所的な高性能ネットワーク上に置くことによってシステムの管理の容易性、データセキュリティ、システムの物理的セキュリティ、およびシステムの性能を改善する可能性がある。サーバおよびストレージシステムを含み、それらを高度なシステム管理ツールに結合するデータ処理システム102のコンポーネントのすべてまたは一部の集中化は、電力および処理の要件を減らし、帯域幅の使用を削減する、サーバリソースのより効率的な使用を可能にする。
Servers in a machine farm can be housed in a high-density rack system along with associated storage systems and placed in an enterprise data center. For example, grouping servers in this way puts servers and high-performance storage systems on a local high-performance network for system manageability, data security, system physical security, and system performance. May be improved. Centralization of all or part of the components of
システム100は、少なくとも1つの第三者デバイス146を含むか、少なくとも1つの第三者デバイス146にアクセスするか、または別の方法で少なくとも1つの第三者デバイス146とインタラクションすることができる。第三者デバイス146は、ネットワーク105を介して、たとえば、コンピューティングデバイス104、データ処理システム102、またはコンテンツプロバイダ106と通信するためのプロセッサを有するコンピューティングデバイスなどの少なくとも1つの論理デバイスを含み得る。第三者デバイス146は、少なくとも1つの計算リソース、サーバ、プロセッサ、またはメモリを含み得る。たとえば、第三者デバイス146は、少なくとも1つのデータセンターに置かれた複数の計算リソースまたはサーバを含み得る。
コンテンツプロバイダデバイス106は、ローカルコンピューティングデバイス104によって表示するためのオーディオに基づくデジタルコンポーネントをオーディオ出力デジタルコンポーネントとして提供することができる。デジタルコンポーネントは、「タクシーを呼びましょうか。」と述べる音声に基づくメッセージなどの、物またはサービスの申し出を含み得る。たとえば、コンテンツプロバイダコンピューティングデバイス106は、音声に基づく問い合わせに応答して提供され得る一連のオーディオデジタルコンポーネントを記憶するためのメモリを含み得る。コンテンツプロバイダコンピューティングデバイス106は、オーディオに基づくデジタルコンポーネント(またはその他のデジタルコンポーネント)をデータ処理システム102に提供することもでき、データ処理システム102において、それらのオーディオに基づくデジタルコンポーネント(またはその他のデジタルコンポーネント)は、データリポジトリ124に記憶され得る。データ処理システム102は、オーディオデジタルコンポーネントを選択し、オーディオデジタルコンポーネントをローカルクライアントコンピューティングデバイス104に提供する(または提供するようにコンテンツプロバイダコンピューティングデバイス106に命令する)ことができる。オーディオに基づくデジタルコンポーネントは、オーディオのみであることができ、またはテキスト、画像、またはビデオデータと組み合わされることが可能である。
The content provider device 106 can provide an audio-based digital component for display by the local computing device 104 as an audio output digital component. Digital components may include offers for goods or services, such as voice-based messages stating "Call a taxi." For example, the content provider computing device 106 may include memory for storing a set of audio digital components that may be provided in response to voice-based queries. The content provider computing device 106 can also provide audio-based digital components (or other digital components) to the
第三者デバイス146は、データ処理システム102を含むか、データ処理システム102とインターフェースを取るか、または別の方法でデータ処理システム102と通信することができる。第三者デバイス146は、ローカルコンピューティングデバイス104を含むか、ローカルコンピューティングデバイス104とインターフェースを取るか、または別の方法でローカルコンピューティングデバイス104と通信することができる。第三者デバイス146は、モバイルコンピューティングデバイス144を含むか、モバイルコンピューティングデバイス144とインターフェースを取るか、または別の方法でモバイルコンピューティングデバイス144と通信することができる。第三者デバイス146は、コンテンツプロバイダデバイス106を含むか、コンテンツプロバイダデバイス106とインターフェースを取るか、または別の方法でコンテンツプロバイダデバイス106と通信することができる。たとえば、第三者デバイス146は、ローカルコンピューティングデバイス104に関連する要求に対する応答を生成するために使用されるスタック形式のプロファイルデータ構造をデータ処理システム102に更新させるためにデータ処理システム102にプロファイルを提供することができる。第三者デバイス106は、ローカルコンピューティングデバイス104のための構成情報または設定を提供することができる。
The third-
ローカルコンピューティングデバイス104は、少なくとも1つのセンサ134、トランスデューサ136、オーディオドライバ138、もしくはプリプロセッサ140を含むか、少なくとも1つのセンサ134、トランスデューサ136、オーディオドライバ138、もしくはプリプロセッサ140とインターフェースを取るか、または別の方法で少なくとも1つのセンサ134、トランスデューサ136、オーディオドライバ138、もしくはプリプロセッサ140と通信することができる。ローカルコンピューティングデバイス104は、ライトインジケータ、発光ダイオード(「LED」)、有機発光ダイオード(「OLED」)、または視覚的もしくは光学的出力を提供するように構成されたその他の視覚的インジケータなどの光源148を含み得る。センサ134は、たとえば、環境光センサ、近接センサ、温度センサ、加速度計、ジャイロスコープ、モーションディテクタ、GPSセンサ、位置センサ、マイクロフォン、またはタッチセンサを含み得る。トランスデューサ136は、スピーカまたはマイクロフォンを含み得る。オーディオドライバ138は、ハードウェアトランスデューサ136にソフトウェアインターフェースを提供することができる。オーディオドライバは、対応する音響波または音波を生成するようにトランスデューサ136を制御するためにデータ処理システム102によって提供されるオーディオファイルまたはその他の命令を実行することができる。プリプロセッサ140は、キーワードを検出し、キーワードに基づいてアクションを実行するように構成されたハードウェアを有する処理ユニットを含み得る。プリプロセッサ140は、さらなる処理のためにデータ処理システム102に語を送信する前に1つまたは複数の語をフィルタリングして取り除くかまたは語を修正することができる。プリプロセッサ140は、マイクロフォンによって検出されたアナログオーディオ信号をデジタルオーディオ信号に変換し、デジタルオーディオ信号を運ぶ1つまたは複数のデータパケットをネットワーク105を介してデータ処理システム102に送信することができる。場合によっては、プリプロセッサ140は、そのような送信を実行するための命令を検出したことに応答して入力オーディオ信号の一部またはすべてを運ぶデータパケットを送信することができる。命令は、
たとえば、入力オーディオ信号を含むデータパケットをデータ処理システム102に送信するためのトリガキーワードまたはその他のキーワードまたは承認を含み得る。
The local computing device 104 includes at least one
For example, it may include a trigger keyword or other keyword or approval for sending a data packet containing an input audio signal to the
ローカルクライアントコンピューティングデバイス104は、(センサ134を介して)音声問い合わせをローカルクライアントコンピューティングデバイス104にオーディオ入力として入力し、トランスデューサ136(たとえばスピーカ)から出力される、データ処理システム102(またはコンテンツプロバイダコンピューティングデバイス106またはサービスプロバイダコンピューティングデバイス108)からローカルクライアントコンピューティングデバイス104に提供され得るコンピュータによって生成された音声の形態のオーディオ出力を受け取るエンドユーザに関連付けられ得る。コンピュータによって生成された音声は、実際の人からの録音またはコンピュータによって生成された言葉を含み得る。 The local client computing device 104 inputs a voice query (via the sensor 134) to the local client computing device 104 as an audio input and outputs it from the transducer 136 (for example, a speaker), the data processing system 102 (or content provider). It may be associated with an end user receiving audio output in the form of computer-generated voice that may be provided from a computing device 106 or a service provider computing device 108) to a local client computing device 104. Computer-generated audio can include recordings from real people or computer-generated words.
データリポジトリ124は、1つまたは複数のローカルまたは分散型データベースを含むことができ、データベース管理システムを含むことができる。データリポジトリ124は、コンピュータデータストレージまたはメモリを含むことができ、データの中でもとりわけ、1つもしくは複数のパラメータ126、1つもしくは複数のポリシー128、コンテンツデータ130、シグネチャおよびアカウント132、またはプロファイルスタック142を記憶することができる。パラメータ126、ポリシー128、およびシグネチャ132、またはプロファイルスタック142は、ローカルクライアントコンピューティングデバイス104とデータ処理システム102(または第三者デバイス146)との間の音声に基づくセッションについての規則などの情報を含み得る。コンテンツデータ130は、オーディオ出力または関連するメタデータに関するデジタルコンポーネントと、ローカルクライアントコンピューティングデバイス104との1つまたは複数の通信セッションの一部である可能性がある入力オーディオメッセージとを含み得る。
The
データ処理システム102は、少なくとも1つの計算リソースまたはサーバを有するコンテンツ配置システムを含み得る。データ処理システム102は、少なくとも1つのインターフェース110を含むか、少なくとも1つのインターフェース110とインターフェースを取るか、または別の方法で少なくとも1つのインターフェース110と通信することができる。データ処理システム102は、少なくとも1つの自然言語プロセッサコンポーネント112を含むか、少なくとも1つの自然言語プロセッサコンポーネント112とインターフェースを取るか、または別の方法で少なくとも1つの自然言語プロセッサコンポーネント112と通信することができる。データ処理システム102は、少なくとも1つのスタック作成エンジンコンポーネント114を含むか、少なくとも1つのスタック作成エンジンコンポーネント114とインターフェースを取るか、または別の方法で少なくとも1つのスタック作成エンジンコンポーネント114と通信することができる。データ処理システム102は、少なくともダイレクトアクションアプリケーションプログラミングインターフェース(「API」)116を含むか、少なくとも1つのダイレクトアクションAPI 116とインターフェースを取るか、または別の方法で少なくとも1つのダイレクトアクションAPI 116と通信することができる。データ処理システム102は、少なくとも1つのコンテンツセレクタコンポーネント118を含むか、少なくとも1つのコンテンツセレクタコンポーネント118とインターフェースを取るか、または別の方法で少なくとも1つのコンテンツセレクタコンポーネント118と通信することができる。データ処理システム102は、少なくとも1つの話者認識コンポーネント120を含むか、少なくとも1つの話者認識コンポーネント120とインターフェースを取るか、または別の方法で少なくとも1つの話者認識コンポーネント120と通信することができる。データ処理システム102は、少なくとも1つのデータリポジトリ124を含むか、少なくとも1つのデータリポジトリ124とインターフェースを取るか、または別の方法で少なくとも1つのデータリポジトリ124と通信することができる。少なくとも1つのデータリポジトリ124は、パラメータ126、ポリシー128、コンテンツデータ130、シグネチャ132、またはプロファイルスタック142を1つまたは複数のデータ構造またはデータベースに含むかまたは記憶することができる。パラメータ126は、たとえば、閾値、距離、時間間隔、継続時間、スコア、または重みを含み得る。コンテンツデータ130は、たとえば、コンテンツキャンペーン情報、コンテンツグループ、コンテンツ選択基準、デジタルコンポーネントオブジェクト、あるいはコンテンツの選択を容易にするためにコンテンツプロバイダ106によって提供されるかまたはデータ処理システムによって取得されるかもしくは決定されるその他の情報を含み得る。コンテンツデータ130は、たとえば、コンテンツキャンペーンの過去の成果を含み得る。ポリシー128は、たとえば、ローカルコンピューティングデバイス104において特定の種類のアクションまたはコンテンツ配信を許可またはブロックするためのポリシーを含み得る。シグネチャ132は、音響またはオーディオシグネチャを含み得る。シグネチャ132は、縮約されたデジタルサマリ(digital summary)を含み得る音響フィンガープリント、オーディオサンプルを特定するかまたはオーディオデータベース内の同様のアイテムの位置を迅速に特定するために使用され得る、オーディオ信号から確定的に(deterministically)生成されたフィンガープリントを指す可能性がある。シグネチャ132は、話者認識コンポーネント120によってプロファイルを特定することを容易にするためのデータを含み得る。プロファイルスタックデータ構造142は、レイヤ形式で積み重ねられるか、スタック形式で積み重ねられるか、または合併され、ローカルコンピューティングデバイス104において入力オーディオ信号を処理するために適用される1つまたは複数のプロファイルを含み得る。
The
インターフェース110、自然言語プロセッサコンポーネント112、スタック作成エンジンコンポーネント114、ダイレクトアクションAPI 116、コンテンツセレクタコンポーネント118、または話者認識コンポーネント120は、それぞれ、少なくとも1つの処理ユニットもしくはプログラミング可能な論理アレーエンジンなどのその他の論理デバイス、またはデータベースリポジトリもしくはデータベース124と通信するように構成されたモジュールを含み得る。インターフェース110、自然言語プロセッサコンポーネント112、スタック作成エンジンコンポーネント114、ダイレクトアクションAPI 116、コンテンツセレクタコンポーネント118、または話者認識コンポーネント120、およびデータリポジトリ124は、別々のコンポーネント、単一のコンポーネント、またはデータ処理システム102の一部である可能性がある。システム100およびデータ処理システム102などのそのコンポーネントは、1つまたは複数のプロセッサ、論理デバイス、または回路などのハードウェア要素を含み得る。
データ処理システム102は、複数のコンピューティングデバイス104に関連する匿名のコンピュータネットワーク活動情報を取得することができる。ローカルコンピューティングデバイス104またはモバイルコンピューティングデバイス144のユーザは、ローカルコンピューティングデバイス104またはモバイルコンピューティングデバイス144に対応するネットワーク活動情報を取得することをデータ処理システム102に肯定的に認可することが可能である。たとえば、データ処理システム102は、1つまたは複数の種類のネットワーク活動情報を取得することに同意するようにコンピューティングデバイス104のユーザに促すことができる。モバイルコンピューティングデバイス144またはローカルコンピューティングデバイス104のユーザの識別情報は、匿名のままであることができ、コンピューティングデバイス104または144は、一意識別子(たとえば、データ処理システムまたはコンピューティングデバイスのユーザによって提供されるユーザまたはコンピューティングデバイスの一意識別子)に関連付けられ得る。データ処理システムは、各観測値(observation)を対応する一意識別子と関連付けることができる。
The
コンテンツプロバイダ106は、電子コンテンツキャンペーンを確立することができる。電子コンテンツキャンペーンは、データリポジトリ124内にコンテンツデータ130として記憶され得る。電子コンテンツキャンペーンは、共通のテーマに対応する1つまたは複数のコンテンツグループを指す可能性がある。コンテンツキャンペーンは、コンテンツグループ、デジタルコンポーネントデータオブジェクト、およびコンテンツ選択基準を含む階層的なデータ構造を含み得る。コンテンツキャンペーンを作成するために、コンテンツプロバイダ106は、コンテンツキャンペーンのキャンペーンレベルパラメータに関する値を指定することができる。キャンペーンレベルパラメータは、たとえば、キャンペーン名、デジタルコンポーネントオブジェクトを配置するための好ましいコンテンツネットワーク、コンテンツキャンペーンのために使用されるリソースの値、コンテンツキャンペーンの開始日および終了日、コンテンツキャンペーンの継続時間、デジタルコンポーネントオブジェクトの配置のためのスケジュール、言語、地理的位置、デジタルコンポーネントオブジェクトを提供すべきコンピューティングデバイスの種類を含み得る。場合によっては、インプレッションが、デジタルコンポーネントオブジェクトがそのソース(たとえば、データ処理システム102またはコンテンツプロバイダ106)からいつフェッチされるかを指す可能性があり、数えられ得る。場合によっては、クリック詐欺の可能性があるため、インプレッションとして、ロボットの活動がフィルタリングされ、除外され得る。したがって、場合によっては、インプレッションは、ロボットの活動およびエラーコードからフィルタリングされ、コンピューティングデバイス104上に表示するためにデジタルコンポーネントオブジェクトをレンダリングする機会にできるだけ近い時点で記録される、ブラウザからのページ要求に対するウェブサーバからの応答の測定値を指す可能性がある。場合によっては、インプレッションは、可視インプレッションまたは可聴インプレッションを指す可能性があり、たとえば、デジタルコンポーネントオブジェクトは、ローカルクライアントコンピューティングデバイス104のディスプレイデバイス上で少なくとも部分的に(たとえば、20%、30%、40%、50%、60%、70%、もしくはそれ以上)可視であるか、またはコンピューティングデバイス104のスピーカ136を介して少なくとも部分的に(たとえば、20%、30%、40%、50%、60%、70%、もしくはそれ以上)可聴である。クリックまたは選択は、可聴インプレッションに対する音声応答、マウスクリック、タッチインタラクション、ジェスチャ、振り動かし、オーディオインタラクション、またはキーボードクリックなどのデジタルコンポーネントオブジェクトとのユーザインタラクションを指す可能性がある。コンバージョンは、ユーザがデジタルコンポーネントオブジェクトに関連して所望のアクションを行うこと、たとえば、製品もしくはサービスを購入すること、調査を完了すること、デジタルコンポーネントに対応する物理的な店舗を訪れること、または電子取引を完了することを指すことができる。
Content provider 106 can establish an electronic content campaign. The electronic content campaign may be stored as content data 130 in the
コンテンツプロバイダ106は、コンテンツキャンペーンに関する1つまたは複数のコンテンツグループをさらに確立することができる。コンテンツグループは、1つまたは複数のデジタルコンポーネントオブジェクトと、キーワード、単語、語、語句、地理的位置、コンピューティングデバイスの種類、時刻、関心、話題、または垂直位置などの対応するコンテンツ選択基準とを含む。同じコンテンツキャンペーンの下のコンテンツグループは、同じキャンペーンレベルパラメータを共有することが可能であるが、キーワード、(たとえば、主コンテンツに除外キーワードが存在する場合にデジタルコンポーネントの配置をブロックする)除外キーワード、キーワードの入札単価(bid)、または入札単価もしくはコンテンツキャンペーンに関連するパラメータなどの特定のコンテンツグループレベルパラメータに関するカスタマイズされた仕様を有する可能性がある。 Content provider 106 may further establish one or more content groups for content campaigns. Content groups contain one or more digital component objects and corresponding content selection criteria such as keywords, words, words, phrases, geographic locations, computing device types, times, interests, topics, or vertical locations. Including. Content groups under the same content campaign can share the same campaign-level parameters, but keywords, such as negative keywords (for example, blocking the placement of digital components if the main content has negative keywords). You may have customized specifications for specific content group level parameters, such as bids for keywords, or parameters related to bids or content campaigns.
新しいコンテンツグループを作成するために、コンテンツプロバイダは、コンテンツグループのコンテンツグループレベルパラメータの値を与えることができる。コンテンツグループレベルパラメータは、たとえば、コンテンツグループ名もしくはコンテンツグループのテーマ、および異なるコンテンツ配置機会(たとえば、自動配置もしくは管理された配置)または結果(たとえば、クリック、インプレッション、もしくはコンバージョン)の入札単価を含む。コンテンツグループ名またはコンテンツグループのテーマは、コンテンツグループのデジタルコンポーネントオブジェクトが表示するために選択されるべきである話題または主題を捕捉するためにコンテンツプロバイダ106が使用することができる1つまたは複数の語である可能性がある。たとえば、自動車の特約販売店は、その特約販売店が扱う車両の各ブランドのために異なるコンテンツグループを作成することができ、その特約販売店が扱う各モデルのために異なるコンテンツグループをさらに作成してもよい。自動車の特約販売店が使用することができるコンテンツグループのテーマの例は、たとえば、「Aスポーツカーを製造する」、「Bスポーツカーを製造する」、「Cセダンを製造する」、「Cトラックを製造する」、「Cハイブリッドを製造する」、または「Dハイブリッドを製造する」を含む。例示的なコンテンツキャンペーンのテーマは、「ハイブリッド」であり、たとえば、「Cハイブリッドを製造する」と「Dハイブリッドを製造する」との両方のためのコンテンツグループを含み得る。 To create a new content group, the content provider can give the value of the content group level parameter of the content group. Content group level parameters include, for example, the content group name or content group theme, and bids for different content placement opportunities (eg, automatic placement or managed placement) or results (eg, clicks, impressions, or conversions). .. The content group name or content group theme is one or more words that content provider 106 can use to capture the topic or subject that the content group's digital component object should be selected for display. It may be. For example, an automobile dealer can create different content groups for each brand of vehicle handled by the dealer, and further create different content groups for each model handled by the dealer. You may. Examples of content group themes that can be used by car dealers are, for example, "Manufacture A sports car", "Manufacture B sports car", "Manufacture C sedan", "C truck". Includes "manufacture", "manufacture C hybrid", or "manufacture D hybrid". An exemplary content campaign theme is "hybrid," which may include, for example, content groups for both "manufacturing a C hybrid" and "manufacturing a D hybrid."
コンテンツグループ106は、各コンテンツグループに1つまたは複数のキーワードおよびデジタルコンポーネントオブジェクトを提供することができる。キーワードは、デジタルコンポーネントオブジェクトに関連するかまたはデジタルコンポーネントオブジェクトによって特定される製品またはサービスに関連する語を含み得る。キーワードは、1つまたは複数の語または語句を含み得る。たとえば、コンテンツグループまたはコンテンツキャンペーンに関するキーワードとして自動車の特約販売店は、「スポーツカー」、「V-6エンジン」、「4輪駆動」、「燃費」を含み得る。場合によっては、除外キーワードが、特定の語またはキーワードに対するコンテンツ配置を避けるか、防止するか、ブロックするか、または無効にするためにコンテンツプロバイダによって指定され得る。コンテンツプロバイダは、デジタルコンポーネントオブジェクトを選択するために使用される、完全一致(exact match)、フレーズ一致、または部分一致(broad match)などのマッチングの種類を指定することができる。 Content group 106 can provide one or more keywords and digital component objects for each content group. Keywords may include terms related to the digital component object or related to the product or service identified by the digital component object. Keywords can include one or more words or phrases. For example, a car dealer may include "sports car," "V-6 engine," "four-wheel drive," and "fuel economy" as keywords for content groups or content campaigns. In some cases, negative keywords may be specified by the content provider to avoid, prevent, block, or disable content placement for a particular word or keyword. Content providers can specify the type of match used to select digital component objects, such as exact match, phrase match, or broad match.
コンテンツプロバイダ106は、コンテンツプロバイダ106によって提供されるデジタルコンポーネントオブジェクトを選択するためにデータ処理システム102によって使用される1つまたは複数のキーワードを提供することができる。コンテンツプロバイダ106は、入札する1つまたは複数のキーワードを特定し、様々なキーワードの入札単価の額をさらに与えることができる。コンテンツプロバイダ106は、デジタルコンポーネントオブジェクトを選択するためにデータ処理システム102によって使用される追加的なコンテンツ選択基準を与えることができる。複数のコンテンツプロバイダ106は、同じまたは異なるキーワードに入札することができ、データ処理システム102は、電子的メッセージのキーワードの指示を受け取ったことに応答してコンテンツ選択プロセスまたは広告オークションを実行することができる。
Content provider 106 may provide one or more keywords used by
コンテンツプロバイダ106は、データ処理システム102による選択のために1つまたは複数のデジタルコンポーネントオブジェクトを提供することができる。(たとえば、コンテンツセレクタコンポーネント118を介して)データ処理システム102は、リソース割り当て、コンテンツスケジュール、最大入札単価、キーワード、およびコンテンツグループに関して指定されたその他の選択基準に一致するコンテンツ配置機会が利用可能になるときにデジタルコンポーネントオブジェクトを選択することができる。音声デジタルコンポーネント、オーディオデジタルコンポーネント、テキストデジタルコンポーネント、画像デジタルコンポーネント、ビデオデジタルコンポーネント、マルチメディアデジタルコンポーネント、またはデジタルコンポーネントリンクなどの異なる種類のデジタルコンポーネントオブジェクトが、コンテンツグループに含まれ得る。デジタルコンポーネントオブジェクト(またはデジタルコンポーネント)は、たとえば、コンテンツアイテム、オンラインドキュメント、オーディオ、画像、ビデオ、マルチメディアコンテンツ、またはスポンサー付きコンテンツを含み得る。デジタルコンポーネントを選択すると、データ処理システム102は、コンピューティングデバイス104またはコンピューティングデバイス104のディスプレイデバイス上でレンダリングするためにデジタルコンポーネントオブジェクトを送信することができる。レンダリングは、ディスプレイデバイス上にデジタルコンポーネントを表示すること、またはコンピューティングデバイス104のスピーカによってデジタルコンポーネントを再生することを含み得る。データ処理システム102は、デジタルコンポーネントオブジェクトをレンダリングするためにコンピューティングデバイス104に命令を与えることができる。データ処理システム102は、オーディオ信号または音響波を生成するようにコンピューティングデバイス104またはコンピューティングデバイス104のオーディオドライバ138に命令することができる。
Content provider 106 may provide one or more digital component objects for selection by the
データ処理システム102は、たとえばデータパケットを使用して、情報を受信および送信するように設計されたか、構成されたか、構築されたか、または動作可能であるインターフェースコンポーネント110を含み得る。インターフェース110は、ネットワークプロトコルなどの1つまたは複数のプロトコルを使用して情報を受信および送信することができる。インターフェース110は、ハードウェアインターフェース、ソフトウェアインターフェース、有線インターフェース、またはワイヤレスインターフェースを含み得る。インターフェース110は、あるフォーマットから別のフォーマットにデータを変換するかまたはフォーマットすることを容易にすることができる。たとえば、インターフェース110は、ソフトウェアコンポーネントなどの様々なコンポーネントの間で通信するための定義を含むアプリケーションプログラミングインターフェースを含み得る。インターフェース110は、ネットワーク105を介してローカルコンピューティングデバイス104、コンテンツプロバイダデバイス106、第三者デバイス146、またはモバイルコンピューティングデバイス144のうちの1つまたは複数と通信することができる。
The
データ処理システム102は、入力オーディオ信号をデータ処理システム102のインターフェース110に通信し、出力オーディオ信号をレンダリングするようにローカルクライアントコンピューティングデバイスのコンポーネントを駆動するためのアプリなどの、ローカルクライアントコンピューティングデバイス104にインストールされたアプリケーション、スクリプト、またはプログラムとインターフェースを取ることができる。データ処理システム102は、オーディオ入力信号を含むかまたは特定するデータパケットまたはその他の信号を受信することができる。
The
データ処理システム102は、ローカルコンピューティングデバイス104によって検出されたオーディオ入力信号を受信し、音響シグネチャを特定し、音響シグネチャに対応する電子アカウントを特定するように設計され、構築され、動作可能である話者認識コンポーネント120を含み得る。話者認識コンポーネント120は、ローカルコンピューティングデバイス104のセンサ134またはトランスデューサ136によって検出された入力オーディオ信号を含むデータパケットをインターフェース110を介して受信することができる。話者認識コンポーネント120は、入力オーディオ信号から音響シグネチャを特定することができる。話者認識コンポーネント120は、データリポジトリ124内でのルックアップに基づいて音響シグネチャに対応する電子アカウントを特定することができる。
The
話者認識コンポーネント120は、入力オーディオ信号を運ぶペイロードを有するデータパケットを受信することができる。話者認識コンポーネント120は、オーディオの特定の周波数を取り除くために入力オーディオ信号に対して事前フィルタリングまたは前処理を実行することができる。事前フィルタリングは、低域通過フィルタ、高域通過フィルタ、または帯域通過フィルタなどのフィルタを含み得る。フィルタは、周波数領域において適用され得る。フィルタは、デジタル信号処理技術を使用して適用され得る。フィルタは、人の発話の通常の周波数の外側にある周波数を除去しながら人の声または人の発話に対応する周波数を維持するように構成され得る。たとえば、帯域通過フィルタが、第1の閾値(たとえば、70Hz、75Hz、80Hz、85Hz、90Hz、95Hz、100Hz、または105Hz)未満の周波数および第2の閾値(たとえば、200Hz、205Hz、210Hz、225Hz、235Hz、245Hz、または255Hz)を超える周波数を取り除くように構成され得る。帯域通過フィルタを適用することは、下流の処理における計算リソースの利用を減らすことができる。場合によっては、ローカルコンピューティングデバイス104のプリプロセッサ140が、データ処理システム102に入力オーディオ信号を送信する前に帯域通過フィルタを適用することができ、それによって、ネットワーク帯域幅の利用を削減する。しかし、ローカルコンピューティングデバイス104が利用可能な計算リソースに基づいて、データ処理システム102がフィルタリングを実行することを可能にするためにデータ処理システム102に入力オーディオ信号を提供することがより効率的である可能性がある。
The speaker recognition component 120 can receive a data packet having a payload carrying an input audio signal. The speaker recognition component 120 can perform pre-filtering or pre-processing on the input audio signal to remove specific frequencies of audio. Pre-filtering may include filters such as low pass filters, high pass filters, or band pass filters. The filter can be applied in the frequency domain. Filters can be applied using digital signal processing techniques. The filter may be configured to maintain a frequency corresponding to the human voice or human utterance while removing frequencies outside the normal frequency of the human utterance. For example, the bandpass filter has frequencies below the first threshold (eg 70Hz, 75Hz, 80Hz, 85Hz, 90Hz, 95Hz, 100Hz, or 105Hz) and the second threshold (eg 200Hz, 205Hz, 210Hz, 225Hz, It can be configured to remove frequencies above 235Hz, 245Hz, or 255Hz). Applying a passband filter can reduce the use of computational resources in downstream processing. In some cases, the preprocessor 140 of the local computing device 104 can apply a passband filter before sending the input audio signal to the
話者認識コンポーネント120は、話者に対応する電子アカウントを特定することを容易にするために追加的な前処理または事前フィルタリング技術を適用することができる。たとえば、話者認識コンポーネント120は、話者認識を邪魔する可能性がある環境雑音レベルを低減するために雑音低減技術を適用することができる。雑音低減技術は、話者認識の正確性および速度を改善することができ、それによって、電子アカウントを特定する際のデータ処理システム102の性能を改善する。
Speaker recognition component 120 can apply additional pre-processing or pre-filtering techniques to facilitate identification of the electronic account that corresponds to the speaker. For example, the speaker recognition component 120 can apply noise reduction techniques to reduce environmental noise levels that can interfere with speaker recognition. Noise reduction technology can improve the accuracy and speed of speaker recognition, thereby improving the performance of the
話者認識コンポーネント120は、データリポジトリ124に記憶されたシグネチャ132にアクセスすることができる。話者認識コンポーネント120は、シグネチャを特定するためにフィルタリングされた入力オーディオ信号を分析し、電子アカウントを特定するためにシグネチャを使用することができる。したがって、話者認識コンポーネント120は、入力オーディオ信号のシグネチャに対応する電子アカウントを特定するために話者認識または音声認識を実行することができる。
The speaker recognition component 120 can access the
話者認識コンポーネント120は、パターン認識などの1つまたは複数の話者認識技術を用いて構成され得る。話者認識コンポーネント120は、テキストに依存しない話者認識プロセスを用いて構成され得る。テキストに依存しない話者認識プロセスにおいては、電子アカウントを確立するために使用されるテキストが、後で話者を認識するために使用されるテキストと異なることができる。 The speaker recognition component 120 may be configured using one or more speaker recognition techniques such as pattern recognition. The speaker recognition component 120 may be configured using a text-independent speaker recognition process. In a text-independent speaker recognition process, the text used to establish an electronic account can be different from the text used to recognize the speaker later.
たとえば、話者認識コンポーネント120は、入力された発話ソースの間で異なる入力オーディオ信号の音響的特徴を特定することができる。音響的特徴は、一意の入力された発話ソースに対応する可能性がある物理的なまたは学習されたパターンを反映することができる。音響的特徴は、たとえば、音声のピッチまたは発話のスタイルを含み得る。シグネチャを特定し、処理し、記憶するために使用される技術は、周波数推定(たとえば、瞬時基本周波数(instantaneous fundamental frequency)、もしくは離散エネルギー分離アルゴリズム(discrete energy separation algorithm))、隠れマルコフモデル(たとえば、将来の状態が現在の状態に依存し、モデル化されているシステムが観測されていない状態を有するランダムに変化するシステムをモデル化するために使用される確率モデル)、混合ガウスモデル(たとえば、ガウス成分密度(Gaussian component density)の加重和として表されるパラメトリック確率密度関数)、パターンマッチングアルゴリズム、ニューラルネットワーク、行列表現、ベクトル量子化(たとえば、プロトタイプベクトルの分布によって確率密度関数のモデル化を可能にする信号処理からの量子化技術)、または決定木を含み得る。さらなる技術は、コホートモデルおよび世界モデル(world model)などの非話者技術(anti-speaker technique)を含み得る。話者認識コンポーネント120は、パターン認識を容易にするためまたは話者の特徴に適合するために機械学習モデルを用いて構成され得る。 For example, the speaker recognition component 120 can identify the acoustic characteristics of different input audio signals between the input utterance sources. Acoustic features can reflect physical or learned patterns that may correspond to a unique input utterance source. Acoustic features can include, for example, voice pitch or speech style. The techniques used to identify, process, and store signatures are frequency estimation (eg, instantaneous fundamental frequency, or discrete energy separation algorithm), and hidden Markov models (eg, hidden Markov models). , A probabilistic model used to model a randomly changing system whose future state depends on the current state and the modeled system has an unobserved state), a mixed Gaussian model (eg,) Parametric probability density function expressed as a weighted sum of Gaussian component density), pattern matching algorithm, neural network, matrix representation, vector quantization (for example, distribution of prototype vector allows modeling of probability density function) Quantification techniques from signal processing), or decision trees can be included. Further techniques may include anti-speaker techniques such as cohort models and world models. The speaker recognition component 120 may be configured using a machine learning model to facilitate pattern recognition or to fit speaker characteristics.
入力オーディオ信号内の音響シグネチャを特定すると、話者認識コンポーネント120は、データリポジトリ124またはシグネチャデータ構造132においてルックアップを実行することができる。シグネチャデータ構造132に記憶されたシグネチャは、電子アカウントの識別子にマッピングされ得る。話者認識コンポーネント120は、入力オーディオのシグネチャに対応する電子アカウントを取り出すために入力オーディオ信号内で特定されたシグネチャを使用してシグネチャデータ構造132においてルックアップを実行することができる。
Identifying the acoustic signature in the input audio signal allows the speaker recognition component 120 to perform a lookup in the
場合によっては、話者認識コンポーネント120は、ルックアップに基づいて、音響シグネチャに対応する電子アカウントがないと判定する可能性がある。たとえば、シグネチャは、シグネチャデータ構造132に記憶されていない可能性があり、またはシグネチャに関する電子アカウントが、まだ確立されていない可能性がある。ルックアップは、ヌル値または空集合を返す場合がある。シグネチャまたは電子アカウントがないと判定したことに応答して、話者認識コンポーネント120は、データリポジトリ内に電子アカウントを作成することができる。話者認識コンポーネント120は、入力オーディオ信号から構築された新しいシグネチャおよび対応する電子アカウントを含むようにシグネチャデータ構造132を更新することができる。話者認識コンポーネント120は、電子アカウントを新しい音響シグネチャにマッピングすることができる。
In some cases, the speaker recognition component 120 may determine that there is no electronic account corresponding to the acoustic signature based on the lookup. For example, the signature may not be stored in the
データ処理システム102は、セッションを確立し、セッション中に使用するために1つまたは複数のプロファイルを組み合わせるように設計され、構築され、動作可能なスタック作成エンジンコンポーネント114を含むか、そのようなスタック作成エンジンコンポーネント114とインターフェースを取るか、または別の方法でそのようなスタック作成エンジンコンポーネント114にアクセスすることができる。スタック作成エンジンコンポーネント114は、話者認識コンポーネント120から電子アカウントの指示を受信することができる。スタック作成エンジンコンポーネント114は、シグネチャおよびアカウントデータ構造132から電子アカウントに関連する情報を取り出すことができる。電子アカウントは、入力オーディオ問い合わせを処理し、応答を生成することを容易にする情報を記憶することができる。電子アカウントは、入力オーディオ信号を与えた話者に対応するプロファイルを含み得る。プロファイルは、ラベル、規則、好み、識別子、サブスクリプション、アカウントの設定、またはデバイス構成の設定を含み得る。プロファイルは、電子アカウントに関連するモバイルコンピューティングデバイス144または電子アカウントに関連するその他のネットワークに接続されたデバイスなどのその他の遠隔のデバイスとインタラクションするための構成情報を含み得る。
The
たとえば、電子アカウントは、ネットワーク105とインターフェースを取るように構成されたサーモスタットなどのネットワークに接続されたデバイスに関するラベルを含み得る。サーモスタットは、電子アカウントに対応する話者に関連する第1の場所(たとえば、住居)に置かれ得る。プロファイル内に、サーモスタットは、「居間」サーモスタットというラベルを有する可能性がある。データ処理システム102が入力された問い合わせ「居間の温度は何度ですか」または「居間の温度を21度に設定せよ」を受信するとき、データ処理システム102は、電子アカウントがラベル「居間」を有するサーモスタットにリンクされることをプロファイルによって判定し、それから、「居間」とラベル付けされたサーモスタットに対応するアクションデータ構造を生成するためにラベルをダイレクトアクションAPI 116に与えることができる。
For example, an electronic account may include labels for networked devices such as thermostats that are configured to interface with
しかし、入力オーディオ信号を検出するローカルコンピューティングデバイス104は、第1の場所に置かれていない場合がある。むしろ、ローカルコンピューティングデバイス104は、第1の場所と物理的におよび地理的に分かれている第2の場所に置かれ得る。第2の場所は、第三者デバイスに関連する第三者エンティティによって管理されるか、運用されるか、制御されるか、または別の方法で維持される場所である可能性がある。第2の場所は、ホテルの部屋、打ち合わせ室、会議室、小売店、レンタル車両、客室、ホステル、または寮などの安全でない場所、公共の場所、または一時的な場所である可能性がある。 However, the local computing device 104 that detects the input audio signal may not be located in the first place. Rather, the local computing device 104 may be located in a second location that is physically and geographically separated from the first location. The second location may be a location managed, operated, controlled, or otherwise maintained by a third party entity associated with a third party device. The second location can be an unsafe location such as a hotel room, meeting room, conference room, retail store, rental vehicle, guest room, hostel, or dormitory, a public location, or a temporary location.
公共の場所または安全でない場所を維持する第三者デバイス146は、ローカルコンピューティングデバイス104を確立し、維持することができる。第三者デバイス146は、ローカルコンピューティングデバイス104のためのベースラインプロファイルまたはデフォルトプロファイルを確立することができる。第三者デバイス146は、第1のプロファイルを提供することができる。第1のプロファイルは、ベースラインプロファイル、デフォルトプロファイル、または第三者プロファイルである可能性がある。第三者デバイス146は、第1のプロファイルを確立することができる。第1のプロファイルは、第三者デバイス146によって確立された1つまたは複数のポリシーまたは規則を含み得る。たとえば、第三者デバイス146は、その他の種類の活動またはアクションをより重く重み付けしながら特定の種類の活動またはアクションをブロックするかまたは防止するポリシー、規則、または構成の設定を提供することができる。ポリシーは、第1のプロファイルに記憶され得る。
第1のプロファイルは、インターネットに接続されたデバイスのラベルを含み得る。第1のプロファイル内のラベルは、第三者デバイス146によって確立されるかまたは提供され得る。たとえば、ラベルは、インターネットに接続されたデバイス(たとえば、インターネットに接続されたサーモスタット、インターネットに接続された光源、インターネットに接続された煙警報器、インターネットに接続された家電製品、インターネットに接続されたディスプレイ、インターネットに接続されたテレビ、またはインターネットに接続されたスピーカ)に対応することが可能である。これらのインターネットに接続されたデバイスのラベルは、第三者エンティティによって与えられ得る。たとえば、ラベルは、「ホテルのサーモスタット」または「ブランドAのホテルのサーモスタット」である可能性がある。
The first profile may include labels for devices connected to the Internet. The label in the first profile may be established or provided by a
第三者デバイス146は、データ処理システム102に、ローカルコンピューティングデバイス104に関連するセッションのために開始されたプロファイルスタックに第1のプロファイルをプッシュさせるためにデータ処理システム102に第1のプロファイルを提供することができる。スタック作成エンジンコンポーネント114は、セッションのために確立されたプロファイルスタック内の第1のプロファイルレイヤに第1のプロファイルを記憶するか、置くか、またはスタックすることができる。プロファイルスタックデータ構造は、第三者エンティティのデバイス(たとえば、第三者デバイス146)によって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含み得る。
The third-
スタック作成エンジンコンポーネント114は、電子アカウントの特定に応じてセッションを確立することができる。セッションは、通信セッション、デジタルアシスタントセッション、ダイレクトアクションセッション、コンテンツ選択セッション、デジタルコンポーネント選択セッション、またはプロファイルセッションを指す可能性がある。セッションは、継続時間を有する可能性がある。セッションは、終了イベントまたは条件が発生するまで継続することができる。終了イベントは、セッションを終了させることができる。終了したとき、セッションの状態が記憶され得る。プロファイルスタック内のプロファイルは、セッションが終了すると更新され得る。 The stack creation engine component 114 can establish a session depending on the identification of the electronic account. A session can refer to a communication session, a digital assistant session, a direct action session, a content selection session, a digital component selection session, or a profile session. The session may have a duration. The session can continue until an end event or condition occurs. The end event can end the session. When finished, the state of the session may be remembered. Profiles in the profile stack can be updated at the end of the session.
スタック作成エンジンコンポーネント114は、セッションにおいて使用するためにプロファイルスタックデータ構造を確立することができる。スタック作成エンジンコンポーネント114は、第三者デバイス146によって提供された第1のプロファイルを含むようにプロファイルスタックデータ構造を初期化することができる。
The stack creation engine component 114 can establish a profile stack data structure for use in a session. The stack creation engine component 114 can initialize the profile stack data structure to include the first profile provided by the
スタック作成エンジンコンポーネント114は、プロファイルスタックの第1のレイヤに第1のプロファイル(たとえば、ローカルコンピューティングデバイス104のためのデフォルトプロファイル)をプッシュすることができる。たとえば、スタック作成エンジンコンポーネント114は、ローカルコンピューティングデバイス104を維持するか、所有するか、管理するか、または運用する同じ第三者に関連付けられる第三者デバイス146によってデフォルトプロファイルが提供されると判定する可能性がある。
The stack creation engine component 114 can push the first profile (for example, the default profile for the local computing device 104) to the first layer of the profile stack. For example, if the stack creation engine component 114 is provided with a default profile by a
そして、スタック作成エンジンコンポーネント114は、電子アカウントおよびシグネチャに対応する第2のプロファイルを取り出すことができる。スタック作成エンジンコンポーネント114は、プロファイルデータ構造に第2のプロファイルをプッシュすることができる。たとえば、第1のプロファイルレイヤが、第1のプロファイルを含むことができ、第2のプロファイルレイヤが、第2のプロファイルを含むことができる。 The stack creation engine component 114 can then retrieve a second profile that corresponds to the electronic account and signature. The stack creation engine component 114 can push a second profile into the profile data structure. For example, the first profile layer can contain the first profile and the second profile layer can contain the second profile.
スタック作成エンジンコンポーネント114は、第1のプロファイルレイヤおよび第2のプロファイルレイヤを含むプロファイルスタックを、さらに処理するためにデータ処理システム102の1つまたは複数のコンポーネントに提供することができる。場合によっては、スタック作成エンジンコンポーネント114は、単一のプロファイルレイヤを作成するために第1のプロファイルレイヤと第2のプロファイルレイヤとを併合させるか、合併するか、または別の方法で組み合わせることができる。場合によっては、スタック作成エンジンコンポーネント114は、2つのプロファイルレイヤを有するプロファイルスタックを、さらに処理するためにダイレクトアクションAPI 116またはコンテンツセレクタコンポーネント118に提供することができる。
The stack creation engine component 114 can provide a profile stack containing a first profile layer and a second profile layer to one or more components of the
第2のプロファイルレイヤおよび第1のプロファイルレイヤを有するプロファイルスタックデータ構造を確立することは、第1のプロファイルレイヤおよび第2のプロファイルレイヤにおいて関連付けられるまたは示される1つまたは複数のインターネットに接続されたデバイス、セッション、インターフェース、または第三者デバイスと結合することを含み得る。たとえば、第1のプロファイルレイヤは、図2の安全な公共の場202に示されるインターネットに接続されたデバイス204、206、208、210、および212を含むことができ、第2のプロファイルレイヤは、図4の私的な場402に示されるインターネットに接続されたデバイス204、206、208、210、および212を含むことができる。公共の場202にあるインターネットに接続されたデバイスは、私的な場402にあるインターネットに接続されたデバイスと比較して異なる識別子を有する可能性がある。データ処理システム102は、プロファイルスタックデータ構造を確立すると、ステータスチェックを実行するかまたは準備完了(readiness)状態になるためにインターネットに接続されたデバイスの各々にpingするか、ポーリングするか、または別の方法で問い合わせることができる。
Establishing a profile stack data structure with a second profile layer and a first profile layer is connected to one or more Internets associated or shown in the first profile layer and the second profile layer. It may include combining with a device, session, interface, or third party device. For example, the first profile layer can include the internet-connected
データ処理システム102は、ローカルコンピューティングデバイス104から入力オーディオ信号を介して受信された問い合わせまたはアクションを処理するためにプロファイルスタックを使用することができる。データ処理システム102は、入力オーディオ信号内の問い合わせを特定するためにNLPコンポーネント112を使用することができ、そして、ダイレクトアクションAPI 116は、プロファイルスタックに従い、準拠するアクションデータ構造を生成するために入力された問い合わせを処理するためにプロファイルスタックを使用することができる。
The
たとえば、データ処理システム102は、オーディオ信号を受信するかまたは取得し、オーディオ信号をパースするためにNLPコンポーネント112を実行するかまたは走らせることができる。たとえば、NLPコンポーネント112は、人とコンピュータとの間のインタラクションを提供することができる。NLPコンポーネント112は、自然言語を理解し、データ処理システム102が人間のまたは自然言語入力から意味を導出することを可能にするための技術を用いて構成され得る。NLPコンポーネント112は、統計的機械学習などの機械学習に基づく技術を含むかまたはそのような技術を用いて構成され得る。NLPコンポーネント112は、入力オーディオ信号をパースするために決定木、統計モデル、または確率モデルを利用することができる。NLPコンポーネント112は、たとえば、固有表現認識(たとえば、テキストのストリームが与えられたものとして、テキスト内のどのアイテムが人または場所などの適切な名前にマッピングされるか、およびそれぞれのそのような名前の種類が人、場所、または組織などのどれであるのかを決定すること)、自然言語生成(たとえば、コンピュータデータベースからの情報または意味的意図(semantic intent)を理解可能な人間の言語に変換すること)、自然言語理解(たとえば、テキストをコンピュータモジュールが操作することができる一階論理構造などのより形式的な表現に変換すること)、機械翻訳(たとえば、テキストをある人間の言語から別の人間の言語に自動的に翻訳すること)、形態素分割(たとえば、考慮されている言語の言葉の形態論または構造の複雑さに基づいて困難である可能性があるが、単語を個々の形態素に分け、形態素のクラスを特定すること)、質問応答(たとえば、特定的であるかまたは自由である可能性がある人間の言語の質問に対する答えを決定すること)、意味処理(たとえば、単語を特定し、特定された単語を同様の意味を有するその他の単語に関連付けるために、その単語の意味を符号化した後に行われることができる処理)などの機能を実行することができる。
For example, the
NLPコンポーネント112は、入力信号を(たとえば、データリポジトリ124内の)オーディオ波形の記憶された代表的なセットと比較し、最も近い一致を選択することによってオーディオ入力信号を認識されたテキストに変換する。オーディオ波形のセットは、データリポジトリ124、またはデータ処理システム102がアクセス可能なその他のデータベースに記憶され得る。代表的な波形が、ユーザの大きなセット全体で生成され、それから、ユーザからの発話サンプルによって増強されてもよい。オーディオ信号が認識されたテキストに変換された後、NLPコンポーネント112は、たとえば、ユーザ全体にわたって訓練することによってまたは手動で指定することによって、データ処理システム102が提供することができるアクションと関連付けられる単語にテキストをマッチングする。
NLP component 112 compares the input signal to a memorized representative set of audio waveforms (eg, in the data repository 124) and converts the audio input signal into recognized text by selecting the closest match. .. The set of audio waveforms may be stored in the
オーディオ入力信号は、ローカルクライアントコンピューティングデバイス104のセンサ134またはトランスデューサ136(たとえば、マイクロフォン)によって検出され得る。トランスデューサ136、オーディオドライバ138、またはその他のコンポーネントを介して、ローカルクライアントコンピューティングデバイス104は、(たとえば、ネットワーク105を介して)オーディオ入力信号をデータ処理システム102に提供することができ、データ処理システム102において、オーディオ入力信号は、(たとえば、インターフェース110によって)受信され、NLPコンポーネント112に提供されるか、またはデータリポジトリ124に記憶され得る。
The audio input signal can be detected by the
NLPコンポーネント112は、入力オーディオ信号を取得することができる。入力オーディオ信号から、NLPコンポーネント112は、少なくとも1つの要求または要求に対応する少なくとも1つのトリガキーワードを特定することができる。要求は、入力オーディオ信号の意図または主題を示すことができる。トリガキーワードは、行われる見込みが大きいアクションの種類を示すことができる。たとえば、NLPコンポーネント112は、夜に食事会に参加し、映画を見るために家を出る少なくとも1つの要求を特定するために入力オーディオ信号をパースし得る。トリガキーワードは、行われるアクションを示す少なくとも1つの単語、語句、語根もしくは部分的な単語、または派生語を含み得る。たとえば、入力オーディオ信号からのトリガキーワード「go」または「to go to」は、輸送の必要性を示す可能性がある。この例において、入力オーディオ信号(または特定された要求)は、輸送の意図を直接表さないが、トリガキーワードが、輸送が要求によって示される少なくとも1つのその他のアクションの補助的なアクションであることを示す。 The NLP component 112 can acquire the input audio signal. From the input audio signal, the NLP component 112 can identify at least one request or at least one trigger keyword corresponding to the request. The request can indicate the intent or subject of the input audio signal. The trigger keyword can indicate the type of action that is likely to be performed. For example, NLP component 112 may parse the input audio signal to identify at least one request to attend a dinner at night and leave home to watch a movie. The trigger keyword can include at least one word, phrase, root or partial word, or derivative that indicates the action to be taken. For example, the trigger keyword "go" or "to go to" from an input audio signal may indicate the need for transport. In this example, the input audio signal (or the identified request) does not directly represent the intent of transport, but the trigger keyword is that transport is an adjunct to at least one other action indicated by the request. Is shown.
NLPコンポーネント112は、要求およびトリガキーワードを特定するか、判定するか、取り出すか、またはそれ以外の方法で取得するために入力オーディオ信号をパースすることができる。たとえば、NLPコンポーネント112は、トリガキーワードまたは要求を特定するために入力オーディオ信号に意味処理技術を適用することができる。NLPコンポーネント112は、第1のトリガキーワードおよび第2のトリガキーワードなどの1つまたは複数のトリガキーワードを含むトリガ語句を特定するために入力オーディオ信号に意味処理技術を適用することができる。たとえば、入力オーディオ信号は、文「I need someone to do my laundry and my dry cleaning.」を含み得る。NLPコンポーネント112は、トリガ語句「do my laundry」および「do my dry cleaning」を特定するために文を含むデータパケットに意味処理技術またはその他の自然言語処理技術を適用することができる。NLPコンポーネント112は、laundry(洗濯)およびdry cleaning(ドライクリーニング)などの複数のトリガキーワードをさらに特定し得る。たとえば、NLPコンポーネント112は、トリガ語句がトリガキーワードおよび第2のトリガキーワードを含むと判定する可能性がある。 NLP component 112 can parse the input audio signal for identifying, determining, retrieving, or otherwise retrieving request and trigger keywords. For example, NLP component 112 can apply semantic processing techniques to the input audio signal to identify trigger keywords or requests. NLP component 112 can apply semantic processing techniques to the input audio signal to identify a trigger phrase that contains one or more trigger keywords, such as a first trigger keyword and a second trigger keyword. For example, the input audio signal may include the sentence "I need someone to do my laundry and my dry cleaning." NLP component 112 can apply semantic processing techniques or other natural language processing techniques to data packets containing statements to identify the trigger phrases "do my laundry" and "do my dry cleaning". NLP component 112 may further identify multiple trigger keywords such as laundry and dry cleaning. For example, NLP component 112 may determine that a trigger phrase contains a trigger keyword and a second trigger keyword.
NLPコンポーネント112は、トリガキーワードを特定するために入力オーディオ信号をフィルタリングすることができる。たとえば、入力オーディオ信号を運ぶデータパケットは、「It would be great if I could get someone that could help me go to the airport」を含む可能性があり、その場合、NLPコンポーネント112は、以下の通りの1つまたは複数の語、すなわち、「it」、「would」、「be」、「great」、「if」、「I」、「could」、「get」、「someone」、「that」、「could」、または「help」をフィルタリングして取り除くことができる。これらの語をフィルタリングして取り除くことによって、NLPコンポーネント112は、「go to the airport」などのトリガキーワードをより正確で信頼性高く特定し、これがタクシーまたは相乗りサービスの要求であると判定する可能性がある。 NLP component 112 can filter the input audio signal to identify the trigger keyword. For example, a data packet carrying an input audio signal could contain "It would be great if I could get someone that could help me go to the airport", in which case the NLP component 112 would have one of: One or more words: "it", "would", "be", "great", "if", "I", "could", "get", "someone", "that", "could" , Or "help" can be filtered out. By filtering and removing these words, NLP component 112 may more accurately and reliably identify trigger keywords such as "go to the airport" and determine that this is a taxi or carpooling service request. There is.
場合によっては、NLPコンポーネントは、入力オーディオ信号を運ぶデータパケットが1つまたは複数の要求を含むと判定し得る。たとえば、入力オーディオ信号は、文「I need someone to do my laundry and my dry cleaning.」を含み得る。NLPコンポーネント112は、これがランドリーサービスおよびドライクリーニングサービスの要求であると判定し得る。NLPコンポーネント112は、これがランドリーサービスとドライクリーニングサービスとの両方を提供することができるサービスプロバイダの単一の要求であると判定し得る。NLPコンポーネント112は、これが2つの要求、すなわち、ランドリーサービスを行うサービスプロバイダに対する第1の要求およびドライクリーニングサービスを提供するサービスプロバイダに対する第2の要求であると判定し得る。場合によっては、NLPコンポーネント112は、複数の判定された要求を単一の要求に組合せ、単一の要求を第三者デバイス146に送信することができる。場合によっては、NLPコンポーネント112は、個々の要求を別のサービスプロバイダデバイスに送信するか、または両方の要求を同じ第三者デバイス146に別々に送信する可能性がある。
In some cases, the NLP component may determine that the data packet carrying the input audio signal contains one or more requests. For example, the input audio signal may include the sentence "I need someone to do my laundry and my dry cleaning." NLP component 112 may determine that this is a request for laundry and dry cleaning services. NLP component 112 may determine that this is a single request of a service provider capable of providing both laundry and dry cleaning services. The NLP component 112 may determine that this is two requests, a first request for the service provider providing the laundry service and a second request for the service provider providing the dry cleaning service. In some cases, the NLP component 112 may combine multiple determined requests into a single request and send the single request to a
データ処理システム102は、要求に応答してトリガキーワードに基づいてアクションデータ構造を生成するように設計され、構築されたダイレクトアクションAPI 116を含み得る。データ処理システム102のプロセッサは、カーシェアリングサービスの自動車などのサービスまたは製品を注文するために第三者デバイス146またはその他のサービスプロバイダに提供するデータ構造を生成するスクリプトを実行するためにダイレクトアクションAPI 116を呼び出すことができる。ダイレクトアクションAPI 116は、第三者デバイス146がカーシェアリングサービスの自動車を予約するなどの動作を実行することを可能にするために場所、時間、ユーザアカウント、物流、またはその他の情報を決定するために、データリポジトリ124からのデータと、ローカルクライアントコンピューティングデバイス104からのエンドユーザの同意とともに受信されたデータとを取得することができる。ダイレクトアクションAPI 116を使用して、データ処理システム102は、この例においてはカーシェアリングのピックアップ予約をすることによってコンバージョンを完了するために第三者デバイス146と通信することもできる。
The
ダイレクトアクションAPI 116は、セッションのためにスタック作成エンジンコンポーネント114によって構築されたプロファイルスタックを受信することができる。ダイレクトアクションAPI 116は、データ処理システム102によって決定されたようにエンドユーザの意図を満足するために指定されたアクションを実行するときにプロファイルスタックからの1つまたは複数のポリシーを適用することができる。その入力内で指定されたアクション、ならびにセッションのためにスタック作成エンジンコンポーネント114によって構築されたプロファイルスタック内のレイヤ形式で積み重ねられたプロファイルおよびポリシーに応じて、ダイレクトアクションAPI 116は、ユーザの要求を履行するために必要とされるパラメータを特定するコードまたはダイアログスクリプトを実行することができる。そのようなコードは、たとえば、データリポジトリ124内で、ホームオートメーションサービスまたは第三者サービスの名前などの追加的な情報をルックアップすることができ、または要求されたタクシーの意図される目的地などの質問をエンドユーザにするためにローカルクライアントコンピューティングデバイス104においてレンダリングするためのオーディオ出力を提供することができる。ダイレクトアクションAPI 116は、パラメータを決定することができ、情報をアクションデータ構造にパッケージングすることができ、そして、アクションデータ構造は、履行されるためにコンテンツセレクタコンポーネント118またはサービスプロバイダコンピューティングデバイス108などの別のコンポーネントに送信され得る。
The Direct Action API 116 can receive the profile stack built by the stack creation engine component 114 for the session. Direct Action API 116 can apply one or more policies from the profile stack when performing the specified action to satisfy the end user's intent as determined by the
ダイレクトアクションAPI 116は、アクションデータ構造を生成または構築するためにNLPコンポーネント112またはデータ処理システム102のその他のコンポーネントから命令またはコマンドを受信することができる。ダイレクトアクションAPI 116は、データリポジトリ124に記憶されたテンプレートリポジトリ122からのテンプレートを選択するためにアクションの種類を決定することができる。アクションの種類は、たとえば、サービス、製品、予約、またはチケットを含み得る。アクションの種類は、サービスまたは製品の種類をさらに含み得る。たとえば、サービスの種類は、カーシェアリングサービス、食品配達サービス、ランドリーサービス、メイドサービス、修理サービス、家事サービス、デバイスオートメーションサービス、またはメディアストリーミングサービスを含み得る。製品の種類は、たとえば、服、靴、おもちゃ、電子機器、コンピュータ、本、または宝飾品を含み得る。予約の種類は、たとえば、夕食の予約またはヘアサロンの予約を含み得る。チケットの種類は、たとえば、映画のチケット、スポーツ会場のチケット、または航空券を含み得る。場合によっては、サービス、製品、予約、またはチケットの種類は、価格、場所、配送の種類、入手のしやすさ、またはその他の属性に基づいてカテゴリ分けされ得る。
Direct action API 116 can receive instructions or commands from NLP component 112 or other components of
NLPコンポーネント112は、要求および要求に対応するトリガキーワードを特定するために入力オーディオ信号をパースし、プロファイルスタックデータ構造の第1のプロファイルレイヤに適合する要求に応答する第1のアクションデータ構造を、トリガキーワードとプロファイルスタックデータ構造にプッシュされた第2のプロファイルレイヤとに基づいてダイレクトアクションAPIに生成させるためにダイレクトアクションAPI 116に要求およびトリガキーワードを提供することができる。 The NLP component 112 parses the input audio signal to identify the request and the trigger keyword that corresponds to the request, and provides a first action data structure that responds to requests that match the first profile layer of the profile stack data structure. Requests and trigger keywords can be provided to the Direct Action API 116 for the Direct Action API to generate based on the trigger keywords and the second profile layer pushed into the profile stack data structure.
ダイレクトアクションAPI 116は、要求の種類を特定すると、テンプレートリポジトリ122からの対応するテンプレートにアクセスすることができる。テンプレートは、(ピックアップ場所でエンドユーザをピックアップし、エンドユーザを目的地に輸送するためにタクシーを送る動作などの)第三者デバイス146のローカルコンピューティングデバイスによって検出された入力オーディオによって要求される動作をさらに実行するためにダイレクトアクションAPI 116によってデータを投入されうる構造化されたデータセットのフィールドを含み得る。ダイレクトアクションAPI 116は、トリガキーワードおよび要求の1つまたは複数の特徴に一致するテンプレートを選択するためにテンプレートリポジトリ122内のルックアップを実行することができる。たとえば、要求が目的地までの車または乗車の要求に対応する場合、データ処理システム102は、カーシェアリングサービスのテンプレートを選択することができる。カーシェアリングサービスのテンプレートは、以下のフィールド、すなわち、デバイス識別子、ピックアップ場所、目的地、乗客数、またはサービスの種類のうちの1つまたは複数を含み得る。ダイレクトアクションAPI 116は、フィールドに値を投入することができる。フィールドに値を投入するために、ダイレクトアクションAPI 116は、コンピューティングデバイス104の1つもしくは複数のセンサ134またはデバイス104のユーザインターフェースにpingするか、ポーリングするか、あるいはそうでなければそれらのセンサ134またはユーザインターフェースから情報を取得することができる。たとえば、ダイレクトアクションAPI 116は、GPSセンサなどの位置センサを使用してソースの位置を検出することができる。ダイレクトアクションAPI 116は、コンピューティングデバイス104のエンドユーザに調査、プロンプト、または問い合わせを送ることによってさらなる情報を取得することができる。ダイレクトアクションAPIは、データ処理システム102のインターフェース110およびコンピューティングデバイス104のユーザインターフェース(たとえば、オーディオインターフェース、音声に基づくユーザインターフェース、ディスプレイ、またはタッチスクリーン)を介して調査、プロンプト
、または問い合わせを送ることができる。したがって、ダイレクトアクションAPI 116は、トリガキーワードまたは要求に基づいてアクションデータ構造のためのテンプレートを選択し、1つもしくは複数のセンサによって検出されたかまたはユーザインターフェースを介して取得された情報をテンプレートの1つまたは複数のフィールドに投入し、第三者デバイス146による動作の実行を容易にするためにアクションデータ構造を生成するか、作成するか、または別の方法で構築することができる。
The direct action API 116 can access the corresponding template from the
アクションデータ構造を構築するかまたは生成するために、データ処理システム102は、値を投入する選択されたテンプレートの1つまたは複数のフィールドを特定することができる。フィールドは、数値、文字列、ユニコード値、ブール論理、2進値、16進値、識別子、位置座標、地理的地域、タイムスタンプ、またはその他の値を投入され得る。フィールドまたはデータ構造自体は、データのセキュリティを保つために暗号化されるかまたはマスクされ得る。
To build or generate an action data structure, the
テンプレートのフィールドを決定すると、データ処理システム102は、アクションデータ構造を作成するためにテンプレートのフィールドに投入するためのフィールドの値を特定することができる。データ処理システム102は、データリポジトリ124に対してルックアップまたはその他の問い合わせ動作を実行することによってフィールドの値を取得するか、取り出すか、決定するか、または別の方法で特定することができる。
Once the template fields have been determined, the
場合によっては、データ処理システム102は、フィールドのための情報または値がデータリポジトリ124にないと判定する可能性がある。データ処理システム102は、データリポジトリ124に記憶された情報または値が期限切れであるか、古いか、またはNLPコンポーネント112によって特定されたトリガキーワードおよび要求に応じてアクションデータ構造を構築する目的にその他の点で適さない(たとえば、ローカルクライアントコンピューティングデバイス104の位置が古い位置である可能性があり、現在位置でない可能性がある、アカウントが失効している可能性がある、目的地のレストランが新しい場所に移転した可能性がある、物理的な活動の情報、または交通手段)と判定する可能性がある。
In some cases, the
データ処理システム102は、そのデータ処理システム102がデータ処理システム102のメモリ内でテンプレートのフィールドのための値または情報に現在アクセスすることができないと判定する場合、値または情報を獲得することができる。データ処理システム102は、ローカルクライアントコンピューティングデバイス104の1つもしくは複数の利用可能なセンサに問い合わせるかもしくはポーリングするか、ローカルクライアントコンピューティングデバイス104のエンドユーザに情報を求めるプロンプトを表示するか、またはHTTPプロトコルを使用してオンラインのウェブに基づくリソースにアクセスすることによって情報を獲得するかまたは取得することができる。たとえば、データ処理システム102は、そのデータ処理システム102がテンプレートの必要とされるフィールドである可能性があるローカルクライアントコンピューティングデバイス104の現在位置を持たないと判定する可能性がある。データ処理システム102は、ローカルクライアントコンピューティングデバイス104に位置情報を問い合わせることができる。データ処理システム102は、全地球測位システムセンサなどの1つもしくは複数の位置センサ134、WiFi三角測量、セルタワー三角測量、Bluetooth(登録商標)ビーコン、IPアドレス、またはその他の位置感知技術を使用して位置情報を提供するようにローカルクライアントコンピューティングデバイス104に要求することができる。
The
場合によっては、データ処理システム102は、第2のプロファイルを使用してアクションデータ構造を生成することができる。そして、データ処理システム102は、第2のプロファイルを使用して生成されたアクションデータ構造が第1のプロファイルに準拠しているかどうかを判定することができる。たとえば、第1のプロファイルは、ローカルコンピューティングデバイス104によって電子的なオンライン小売業者から製品を購入するなどの、ある種類のアクションデータ構造をブロックするためのポリシーを含み得る。ローカルコンピューティングデバイス104によって検出された入力オーディオは、電子的なオンライン小売業者から製品を購入する要求を含んでいた可能性がある。データ処理システム102は、電子的なオンライン小売業者に関連するアカウント情報を特定するために第2のプロファイルを使用し、それから、製品を購入するためにアクションデータ構造を生成した可能性がある。アクションデータ構造は、話者認識コンポーネント120によって特定された音響シグネチャに関連する電子アカウントに対応するアカウント識別子を含み得る。
In some cases, the
アクションデータ構造を生成すると、ダイレクトアクションAPI 116は、電子的なオンライン小売業者にアクションデータ構造を送信しようと試みる可能性がある。しかし、スタック作成エンジンコンポーネント114は、アクションデータ構造を傍受することができる。スタック作成エンジンコンポーネント114は、アクションデータ構造がセッションのために確立されたプロファイルスタック内の第1のプロファイルレイヤの1つまたは複数のポリシーに準拠するかどうかを判定するためにそのアクションデータ構造を分析することができる。スタック作成エンジンコンポーネント114は、電子的な小売業者から製品を購入するためのアクションデータ構造が準拠していると判定する場合、アクションデータ構造を開放することができる。しかし、アクションデータ構造が第1のプロファイルレイヤに反しているかまたは準拠していないとスタック作成エンジンコンポーネントが判定する場合、スタック作成エンジンコンポーネント114は、アクションデータ構造をブロックすることができる。 After generating the action data structure, Direct Action API 116 may attempt to send the action data structure to an electronic online retailer. However, the stack creation engine component 114 can intercept the action data structure. The stack creation engine component 114 analyzes the action data structure to determine if it complies with one or more policies of the first profile layer in the profile stack established for the session. can do. The stack creation engine component 114 can release the action data structure if it determines that the action data structure for purchasing a product from an electronic retailer is compliant. However, if the stack creation engine component determines that the action data structure violates or does not conform to the first profile layer, the stack creation engine component 114 may block the action data structure.
場合によっては、ダイレクトアクションAPI 116が、プロファイルスタックを取り出し、第1のプロファイルレイヤおよび第2のプロファイルレイヤを特定することができ、第2のプロファイルレイヤが、その後プッシュされた第2のプロファイルに対応する。ダイレクトアクションAPI 116は、第2のプロファイルなどの最後にプッシュされたプロファイルを使用してアクションデータ構造を生成することができる。そして、ダイレクトアクションAPI 116は、第2のプロファイルを使用して生成されたアクションデータ構造を第1のプロファイルに含まれる1つまたは複数のポリシーと比較することができる。ポリシーを使用した比較に基づいて、ダイレクトアクションAPI 116は、アクションデータ構造を承認すべきかまたはアクションデータ構造をブロックすべきかを判定することができる。 In some cases, Direct Action API 116 can retrieve the profile stack and identify the first and second profile layers, with the second profile layer corresponding to the second profile that was subsequently pushed. To do. Direct Action API 116 can generate action data structures using the last pushed profile, such as the second profile. The Direct Action API 116 can then compare the action data structures generated using the second profile with one or more policies contained in the first profile. Based on policy-based comparisons, Direct Action API 116 can determine whether an action data structure should be approved or blocked.
たとえば、データ処理システム102は、トリガキーワードとプロファイルスタックにプッシュされた第2のプロファイルレイヤとに基づいて第1のアクションデータ構造を生成することができる。データ処理システム102は、入力オーディオ信号内の要求に応答して第1のアクションデータ構造を生成することができる。データ処理システム102は、第1のアクションデータ構造を第1のプロファイルレイヤの1つまたは複数のポリシーと比較することができ、第1のプロファイルレイヤは、デフォルトプロファイルレイヤまたはベースラインプロファイルレイヤに対応する。データ処理システム102は、第1のプロファイルレイヤの1つまたは複数のポリシーとの第1のアクションデータ構造の比較に基づいて、第1のアクションデータ構造が第1のプロファイルレイヤに適合していると判定する可能性がある。第1のプロファイルレイヤに適合していると判定された第1のアクションデータ構造に応答して、データ処理システム102は、実行するために第1のアクションデータ構造を提供することができる。
For example, the
第1のプロファイルレイヤのポリシーは、ある種類のアクションデータ構造をブロックするためのポリシーを含み得る。ブロックされる可能性があるアクションデータ構造の種類は、たとえば、第三者の競争相手のエンティティから製品もしくはサービスを購入するためのアクションデータ構造、安全でないアクション、またはネットワーク帯域幅を大量に消費するアクション(たとえば、4K解像度のマルチメディアコンテンツをストリーミングする、50メガバイト、100メガバイトなどを超えるような大きなデータファイルをダウンロードする)を含み得る。データ処理システムは、第1のアクションデータ構造が第1のプロファイルレイヤに適合するかどうかを判定するために、第1のアクションの種類を第1のプロファイルレイヤの1つまたは複数のポリシーによって示されたアクションデータ構造の種類と比較することができる。第1のアクションデータ構造がポリシーによって許可される(たとえば、ポリシーによってブロックされない)場合、データ処理システム102は、第1のアクションデータ構造を承認し得る。
The policy of the first profile layer may include a policy for blocking certain types of action data structures. The types of action data structures that can be blocked are, for example, action data structures for purchasing products or services from third-party competitor entities, insecure actions, or consuming large amounts of network bandwidth. It can include actions (for example, streaming 4K resolution multimedia content, downloading large data files that exceed 50 megabytes, 100 megabytes, etc.). The data processing system indicates the type of first action by one or more policies of the first profile layer to determine if the first action data structure fits into the first profile layer. It can be compared with the types of action data structures. If the first action data structure is allowed by the policy (for example, not blocked by the policy), the
場合によっては、データ処理システム102は、自然言語プロセッサによって特定されたトリガキーワード、およびプロファイルスタックデータ構造を受信することができる。データ処理システム102は、トリガキーワードおよびプロファイルスタックデータ構造に基づいて、第1のプロファイルレイヤと第2のプロファイルレイヤとの両方に適合しているデジタルコンポーネントを選択することができる。デジタルコンポーネントは、補足的なデジタルコンポーネントを指す可能性がある。たとえば、データ処理システム102は、自然言語プロセッサによって特定されたトリガキーワードを受信し、トリガキーワードに基づいてリアルタイムのコンテンツ選択プロセスによってデジタルコンポーネントを選択するためにコンテンツセレクタコンポーネント118を含むか、実行するか、または別の方法でそのようなコンテンツセレクタコンポーネント118と通信することができる。コンテンツ選択プロセスは、第三者コンテンツプロバイダ106によって提供されたスポンサー付きデジタルコンポーネントオブジェクトを選択することを指すかまたは含む可能性がある。リアルタイムのコンテンツ選択プロセスは、複数のコンテンツプロバイダによって提供されたデジタルコンポーネントが、コンピューティングデバイス104に提供する1つまたは複数のデジタルコンポーネントを選択するためにパースされるか、処理されるか、重み付けされるか、またはマッチングされるサービスを含む可能性がある。コンテンツセレクタコンポーネント118は、コンテンツ選択プロセスをリアルタイムで実行することができる。コンテンツ選択プロセスをリアルタイムで実行することは、ローカルクライアントコンピューティングデバイス104を介して受信されたコンテンツの要求に応答してコンテンツ選択プロセスを実行することを指す可能性がある。リアルタイムのコンテンツ選択プロセスは、要求を受信する時間間隔(たとえば、5秒、10秒、20秒、30秒、1分、2分、3分、5分、10分、または20分)以内に実行される(たとえば、開始されるかまたは完了される)可能性がある。リアルタイムのコンテンツ選択プロセスは、ローカルクライアントコンピューティングデバイス104との通信セッション中に、または通信セッションが終了された後にある時間間隔以内に実行される可能性がある。
In some cases, the
たとえば、データ処理システム102は、デジタルコンポーネントオブジェクトを選択するように設計されたか、構築されたか、構成されたか、または動作可能であるコンテンツセレクタコンポーネント118を含み得る。音声に基づく環境内に表示するためにデジタルコンポーネントを選択するために、データ処理システム102は、(たとえば、NLPコンポーネント112によって)キーワード(たとえば、トリガキーワード)を特定するために入力オーディオ信号をパースし、部分一致、完全一致、またはフレーズ一致に基づいて一致するデジタルコンポーネントを選択するためにキーワードを使用することができる。たとえば、コンテンツセレクタコンポーネント118は、候補デジタルコンポーネントの主題がローカルクライアントコンピューティングデバイス104のマイクロフォンによって検出された入力オーディオ信号のキーワードまたはフレーズの主題に対応するかどうかを判定するために候補デジタルコンポーネントの主題を分析するか、パースするか、または別の方法で処理することができる。コンテンツセレクタコンポーネント118は、画像処理技術、文字認識技術、自然言語処理技術、またはデータベースルックアップを使用して候補デジタルコンポーネントの音声、オーディオ、語、文字、テキスト、記号、または画像を特定するか、分析するか、または認識する可能性がある。候補デジタルコンポーネントは、候補デジタルコンポーネントの主題を示すメタデータを含む可能性があり、その場合、コンテンツセレクタコンポーネント118は、候補デジタルコンポーネントの主題が入力オーディオ信号に対応するかどうかを判定するためにメタデータを処理する可能性がある。
For example, the
コンテンツセレクタコンポーネント118は、コンテンツ選択を実行するためにプロファイルスタック内に与えられた情報をさらに利用することができる。コンテンツセレクタコンポーネント118は、ローカルコンピューティングデバイス104によって検出された入力オーディオ信号を与えた話者に関連する電子アカウントに対応し得る第2のプロファイルレイヤを利用することができる。コンテンツセレクタ118は、第三者デバイス146によって提供されたデフォルトプロファイルレイヤに対応し得る第1のプロファイルレイヤに関連する情報を使用することもできる。コンテンツプロバイダ106によって提供されるコンテンツキャンペーンは、第2のプロファイルレイヤまたは第1のプロファイルレイヤ内で示された基準にデータ処理システム102がマッチングすることができるコンテンツ選択基準を含み得る。
Content selector component 118 can further utilize the information given in the profile stack to perform content selection. The content selector component 118 can utilize a second profile layer that may correspond to the electronic account associated with the speaker who gave the input audio signal detected by the local computing device 104. Content selector 118 may also use information related to a first profile layer that may correspond to the default profile layer provided by
プロファイルレイヤは、デジタルコンポーネントを選択するためにコンテンツセレクタコンポーネント118によって使用される重みまたはスコアを変えることができる。たとえば、第三者デバイスによって確立される第1のプロファイルレイヤは、第三者エンティティの競争相手によって提供される製品またはサービスの重みまたはスコアを下げる一方で、第三者エンティティによって提供される製品またはサービスに関するまたはそれらの製品またはサービスを説明するデジタルコンポーネントの重みまたはスコアを上げることができる。ローカルコンピューティングデバイス104は第三者エンティティによって制御される場に置かれる可能性があるので、第三者エンティティは、コンテンツ選択中にコンテンツセレクタコンポーネント118によって利用されるべき第1のプロファイルレイヤ内のコンテンツ選択規則、ポリシー、または重み付けを確立することができる。 The profile layer can change the weights or scores used by the content selector component 118 to select the digital component. For example, the first profile layer established by a third party device reduces the weight or score of a product or service offered by a competitor of a third party entity, while the product or service offered by a third party entity. You can increase the weight or score of digital components that relate to or describe their products or services. Since the local computing device 104 may be placed in a place controlled by a third party entity, the third party entity is in the first profile layer that should be utilized by the content selector component 118 during content selection. Content selection rules, policies, or weights can be established.
デジタルコンポーネントを選択するために第2のプロファイルレイヤを使用することによって、コンテンツセレクタコンポーネント118は、第1のプロファイルレイヤだけでなく、第2のプロファイルレイヤに基づいてデジタルコンポーネントをより精密に選択することによってデジタルコンポーネントの余分な送信を削減することができる。複数のプロファイルから構築されたプロファイルスタックを使用してデジタルコンポーネントを選択することは、第1のレイヤ(もしくはデフォルトレイヤ)または単に第2のレイヤ(電子アカウントに関連するプロファイル)を使用してデジタルコンポーネントを選択するだけとは対照的に、誤ったまたは関連性のないデジタルコンポーネントの選択をもたらす可能性がある。第1のプロファイルレイヤが、コンテンツ選択を容易にするかまたは誤ったコンテンツ選択をブロックする可能性がある、第三者エンティティ、またはローカルコンピューティングデバイス104が置かれる公共のもしくは安全でない場所に関連する情報を提供することができる。たとえば、入力オーディオ信号は、ドライクリーニングサービスの要求を含み得る。コンテンツセレクタコンポーネント118は、要求を受信し、コンテンツプロバイダデバイス106によって提供される補足的なデジタルコンポーネントを特定しようと試みる可能性がある。補足的なコンテンツプロバイダを特定するために、コンテンツセレクタコンポーネント118は、要求に関連する1つまたは複数の特徴を使用してリアルタイムのコンテンツ選択プロセスを実行することができる。コンテンツセレクタコンポーネント118は、第2のプロファイルレイヤから取得された情報をさらに入力することができる。第2のプロファイルレイヤからの情報を使用して、コンテンツセレクタコンポーネント118は、ドライクリーニングサービスプロバイダに対応するデジタルコンポーネントを選択する可能性がある。しかし、第1のプロファイルレイヤは、第1のプロファイルレイヤを確立した第三者エンティティが好ましいドライクリーニングサービスを提供する可能性があるので、ドライクリーニングサービスプロバイダに関連する補足的なデジタルコンポーネントの供給をブロックするポリシーを含み得る。コンテンツセレクタコンポーネント118は、第三者エンティティが独自のドライクリーニングサービスに関するコンテンツキャンペーンを確立しなかった可能性があるために、第三者エンティティによって提供されるドライクリーニングサービスに関するデジタルコンポーネントを選択しなかった可能性がある。したがって、第1のプロファイルレイヤと第2のプロファイルレイヤとの両方を含むプロファイルスタックを利用せずに、データ処理システム102は、好むデジタルコンポーネントが、第1のプロファイルレイヤにおいて特定される、第三者エンティティによって提供されるドライクリーニングサービスに対応するとき、ドライクリーニングサービスプロバイダに対応する補足的なデジタルコンポーネントを誤って提供した可能性がある。したがって、データ処理システム102は、選択されたデジタルコンポーネントを、第1のプロファイルレイヤ(またはデフォルトプロファイルレイヤ)によって示された好ましいデジタルコンポーネントによって上書きするかまたは置き換えることができる。
By using a second profile layer to select digital components, the content selector component 118 selects digital components more precisely based on the second profile layer as well as the first profile layer. Can reduce the extra transmission of digital components. Selecting a digital component using a profile stack built from multiple profiles is a digital component using a first layer (or default layer) or simply a second layer (profiles associated with an electronic account). In contrast to just choosing, it can lead to the wrong or irrelevant selection of digital components. The first profile layer relates to public or insecure locations where third party entities, or local computing devices 104, may facilitate content selection or block incorrect content selection. Information can be provided. For example, the input audio signal may include a request for a dry cleaning service. The content selector component 118 may receive the request and attempt to identify the complementary digital component provided by the content provider device 106. To identify the complementary content provider, the content selector component 118 can perform a real-time content selection process using one or more features related to the request. The content selector component 118 can further input the information obtained from the second profile layer. Using the information from the second profile layer, the content selector component 118 may select the digital component that corresponds to the dry cleaning service provider. However, the first profile layer may provide a preferred dry cleaning service to the third party entity that established the first profile layer, so it may provide a supplementary digital component associated with the dry cleaning service provider. May include blocking policies. Content Selector Component 118 did not select the digital component for dry cleaning services provided by the third party entity because the third party entity may not have established a content campaign for its own dry cleaning service. there is a possibility. Therefore, without utilizing a profile stack that includes both a first profile layer and a second profile layer, the
場合によっては、コンテンツセレクタコンポーネント118は、第1のプロファイルレイヤがある種類のデジタルコンポーネントの選択をブロックするポリシーまたは情報を含むかどうかを判定するために第1のプロファイルレイヤをパースし、リアルタイムのコンテンツ選択プロセスを実行することを防止することができ、それによって、入力オーディオ信号に含まれる要求に応答してデジタルコンポーネントを提供する際の計算リソースの利用を減らし、遅延またはレイテンシーを潜在的に減らす。 In some cases, the content selector component 118 parses the first profile layer to determine if it contains policies or information that block the selection of certain types of digital components, and real-time content. It can prevent the selection process from running, thereby reducing the use of computational resources in providing digital components in response to requests contained in the input audio signal, potentially reducing latency or latency.
コンテンツプロバイダ106は、デジタルコンポーネントを含むコンテンツキャンペーンを設定するときに追加的なインジケータを提供する可能性がある。コンテンツプロバイダ106は、候補デジタルコンポーネントについての情報を使用してルックアップを実行することによってコンテンツセレクタコンポーネント118が特定し得るコンテンツキャンペーンまたはコンテンツグループレベルの情報を提供する可能性がある。たとえば、候補デジタルコンポーネントは、コンテンツグループ、コンテンツキャンペーン、またはコンテンツプロバイダにマッピングされ得る一意識別子を含む可能性がある。コンテンツセレクタコンポーネント118は、データリポジトリ124内のコンテンツキャンペーンデータ構造に記憶された情報に基づいてコンテンツプロバイダ106についての情報を決定する可能性がある。
Content provider 106 may provide additional indicators when setting up content campaigns that include digital components. Content provider 106 may provide content campaign or content group level information that content selector component 118 can identify by performing a lookup using information about candidate digital components. For example, a candidate digital component may contain a unique identifier that can be mapped to a content group, content campaign, or content provider. The content selector component 118 may determine information about the content provider 106 based on the information stored in the content campaign data structure in the
データ処理システム102は、コンピューティングデバイス104上で提示するためのコンテンツの要求をコンピュータネットワークを介して受信することができる。データ処理システム102は、ローカルクライアントコンピューティングデバイス104のマイクロフォンによって検出された入力オーディオ信号を処理することによって要求を特定することができる。要求は、要求に関連するデバイスの種類、場所、およびキーワードなどの要求の選択基準を含み得る。要求は、アクションデータ構造を含み得る。
The
要求に応答して、データ処理システム102は、データリポジトリ124、またはコンテンツプロバイダ106に関連するデータベースからデジタルコンポーネントオブジェクトを選択し、コンピューティングデバイス104によって提示するためのデジタルコンポーネントをネットワーク105を介して提供することができる。デジタルコンポーネントオブジェクトは、第三者デバイス146とは異なるコンテンツプロバイダデバイス108によって提供され得る。デジタルコンポーネントは、アクションデータ構造のサービスの種類とは異なるサービスの種類に対応し得る(たとえば、タクシーサービスに対して食品配達サービス)。コンピューティングデバイス104は、デジタルコンポーネントオブジェクトとインタラクションすることができる。コンピューティングデバイス104は、デジタルコンポーネントに対するオーディオ応答を受信することができる。コンピューティングデバイス104は、コンピューティングデバイス104がサービスプロバイダ108を特定すること、サービスプロバイダ108からのサービスを要求すること、サービスを実行するようにサービスプロバイダ108に命令すること、サービスプロバイダ108に情報を送信すること、もしくは別の方法で第三者デバイス146に問い合わせることを引き起こすかまたは可能にするデジタルコンポーネントオブジェクトに関連するハイパーリンクまたはその他のボタンを選択するための指示を受信し得る。
In response to the request, the
データ処理システム102は、(たとえば、インターフェース110およびネットワーク105を介して)入力オーディオ信号またはその要求もしくは問い合わせに応答する出力信号を含むデータパケットを送信することができる。出力信号は、クライアントデバイス104のまたはクライアントデバイス104によって実行されるオーディオドライバコンポーネント138に、出力信号に対応する音響波を生成させるようにローカルコンピューティングデバイス104のスピーカ(たとえば、トランスデューサ136)を駆動させることができる。
The
データ処理システム102は、(たとえば、スタック作成エンジンコンポーネント114によって)プロファイルスタックデータ構造を分解して、プロファイルスタックデータ構造から第1のプロファイルレイヤまたは第2のプロファイルレイヤのうちの一方を取り除くことができる。データ処理システムは、前の構成またはデフォルト構成に戻し、セッションおよび電子アカウントに関連するすべての情報を消去するかまたは保護することによって電子アカウントから分離することができる。たとえば、データ処理システムは、ローカルコンピューティングデバイス104のために構成されたプロファイルスタックデータ構造から第2のプロファイルレイヤを取り除くかまたは削除することができる。データ処理システム102は、ローカルコンピューティングデバイス104を工場出荷時設定またはデフォルト構成に戻すかまたはリセットすることができる。データ処理システム102は、データ処理システム102に記憶された第2のプロファイルに任意のセッションに関連する情報をアップロードし、第2のプロファイルに関連する情報の任意のローカルのコピーを取り除くかまたはパージすることができる。
The
データ処理システム102は、トリガイベントの検出に応じてプロファイルスタックから第1のプロファイルレイヤまたは第2のプロファイルレイヤのうちの一方を取り除くことができる。トリガイベントは、時間間隔、命令、イベント、場所、ジオフェンス、認可されていない使用、詐欺の検出、または新しい話者認識に基づく可能性がある。データ処理システム102は、トリガイベントの種類に基づいて第1のプロファイルまたは第2のプロファイルのうちの一方を取り除くと決定することができる。
The
データ処理システム102は、(たとえば、話者認識コンポーネント120によって)異なるユーザがローカルコンピューティングデバイス104に入力オーディオ信号を提供していると判定する可能性がある。異なるユーザは、第1のユーザと同じでない第2のユーザである可能性がある。第2のユーザは、異なる音響シグネチャを有する可能性がある。話者認識コンポーネント120は、第2の音響シグネチャを検出し、異なるユーザが存在すると判定し、それから、第1のユーザとのセッションを終了することができる。話者認識コンポーネント120は、第2の、異なるユーザの指示をスタック作成エンジンコンポーネント114に提供することができ、スタック作成エンジンコンポーネント114は、プロファイルスタックから第2のプロファイルレイヤを取り除くことができる。スタック作成エンジンコンポーネント114は、第1のユーザとは異なる第2のユーザの指示を受信することに応答して、プロファイルスタックデータ構造をクリアするか、または単に第1のユーザに対応する第2のプロファイルレイヤを取り除くことができる。
The
データ処理システム102は、クライアントデバイス(たとえば、ローカルコンピューティングデバイス104)のセンサ134によって検出された第2の入力オーディオ信号を含む第2のデータパケットをインターフェース110を介して受信する。第2の入力オーディオ信号は、オーディオ信号の後に検出され得る。データ処理システム102(たとえば、話者認識コンポーネント120)は、第2の入力オーディオ信号から第2の音響シグネチャを特定することができる。第2の音響シグネチャは、第1の音響シグネチャと異なる可能性がある。データ処理システム102は、第1の音響シグネチャと異なる第2の音響シグネチャの特定に基づいてトリガイベントを判定することができる。
The
スタック作成エンジンコンポーネント114は、時間間隔の間不活発であったことに応答してプロファイルスタックをクリアするかまたは第2のプロファイルレイヤを取り除くことができる。スタック作成エンジンコンポーネント114は、第2のプロファイルレイヤに対応するユーザが5分、10分、15分、20分、25分、30分、1時間、またはそれ以上などの時間間隔の間いかなる音声入力も与えなかったことに応答してプロファイルスタックまたは第2のプロファイルレイヤをクリアすることができる。プロファイルスタックをクリアするかまたは第2のプロファイルレイヤを取り除くことにより、セキュリティを高め、メモリ内のプロファイルスタックを最小限に維持することができる。 The stack creation engine component 114 can either clear the profile stack or remove the second profile layer in response to being inactive during the time interval. The stack creation engine component 114 allows the user corresponding to the second profile layer to input any voice during a time interval such as 5 minutes, 10 minutes, 15 minutes, 20 minutes, 25 minutes, 30 minutes, 1 hour, or more. You can also clear the profile stack or the second profile layer in response to not giving. By clearing the profile stack or removing the second profile layer, security can be increased and the profile stack in memory can be kept to a minimum.
スタック作成エンジンコンポーネント114は、第2のプロファイルレイヤに対応するユーザがローカルコンピューティングデバイス104または第三者エンティティに対応する公共の場所または安全でない場所を離れたと判定したことに応答してプロファイルスタックをクリアすることができる。スタック作成エンジンコンポーネント114は、モバイルコンピューティングデバイス144がローカルコンピューティングデバイス104から閾値の距離を超えて離れているという指示をユーザによって持ち運ばれ得るモバイルコンピューティングデバイス144から受信することができる。閾値の距離は、20メートル、25メートル、50メートル、100メートル、200メートル、500メートル、750メートル、1000メートル、またはそれ以上である可能性がある。たとえば、スタック作成エンジンコンポーネント114は、ローカルコンピューティングデバイス104の周りの地理的フェンス(geographic fence)を確立することができる。地理的フェンスは、モバイルデバイスがローカルコンピューティングデバイス104の周りの特定の領域に入るかまたはその特定の領域を離れるときにソフトウェアが応答をトリガすることを可能にする、全地球測位システム(「GPS」)または無線周波数識別(「RFID」)または近距離無線通信ビーコンによって画定される仮想的な地理的境界を指す可能性がある。したがって、ユーザがそれらのユーザのモバイルコンピューティングデバイス144とともにホテルの部屋を離れるとき、データ処理システム102は、ローカルコンピューティングデバイス104によって検出された音声入力を処理するために使用されるプロファイルスタックから第2のプロファイルレイヤを自動的に取り除くことができる。
The stack creation engine component 114 sets the profile stack in response to determining that the user corresponding to the second profile layer has left a public or unsafe place corresponding to the local computing device 104 or a third party entity. Can be cleared. The stack creation engine component 114 can receive instructions from the
スタック作成エンジンコンポーネント114は、第三者デバイス146とインターフェースを取り、プロファイルスタックをクリアするかまたは第2のプロファイルレイヤを取り除くために第三者デバイス146から指示を受信することができる。たとえば、第三者デバイス146は、第2のプロファイルレイヤに関連するユーザがホテルの部屋をチェックアウトしたという指示を受信する電子的なホテルの宿泊客管理システムを含み得る。宿泊客がチェックアウトしたという指示を受信したことに応答して、第三者デバイス146は、指示をデータ処理システム102に転送することができる。データ処理システム102(たとえば、スタック作成エンジンコンポーネント114)は、宿泊客がチェックアウトしたという指示を受信し、指示に応答して、ローカルコンピューティングデバイス104に関連する音声入力を処理するために使用されるプロファイルスタックから第2のプロファイルレイヤを取り除くことができ、それによって、プロファイルスタックを分解する。
The stack creation engine component 114 can interface with the
プロファイルスタックデータ構造を分解することは、プロファイルスタックから1つまたは複数のプロファイルを取り除くかまたはクリアすることを含み得る。プロファイルスタックを分解することは、第1のプロファイルレイヤのみを取り除くこと、第2のプロファイルレイヤのみを取り除くこと、または第1のプロファイルレイヤと第2のプロファイルレイヤとの両方を取り除くことを含み得る。たとえば、データ処理システムは、デフォルトプロファイルレイヤに対応する第1のプロファイルレイヤを維持しながら、音響シグネチャに対応する電子アカウントに対応する第2のプロファイルレイヤを取り除くことができる。 Decomposing a profile stack data structure can include removing or clearing one or more profiles from the profile stack. Decomposing the profile stack can include removing only the first profile layer, removing only the second profile layer, or removing both the first and second profile layers. For example, a data processing system can keep the first profile layer corresponding to the default profile layer while removing the second profile layer corresponding to the electronic account corresponding to the acoustic signature.
図2は、プロファイルスタックを処理するためのシステム100の動作の図である。システム100は、環境200内で動作することができる。環境200は、図1に示されるシステム100または図6に示されるシステム600の1つまたは複数のコンポーネントを含み得る。環境200は、安全な公共の場所202を含み得る。安全な公共の場所202は、公共の場所を指す可能性がある。公共の場所は、場所、土地、建物、家、部屋、あるいは同じ時間にもしくは異なる時間に複数のユーザによって占有され得るかまたは複数のユーザによってアクセスされ得るその他の構造または場を指す可能性がある。たとえば、公共の土地または公共の場所は、ホテルの部屋、モーテルの部屋、客室、レンタカー、物理的な小売店、モール、公園、オフィス、または小個室を含み得る。この例において、安全な公共の場所202は、ホテルの部屋である可能性がある。公共の場所202は、モバイルコンピューティングデバイス144が場所202の中に置かれている可能性があり、それによって、ユーザが存在する可能性があることを示すので安全であり得る。しかし、システムは、モバイルコンピューティングデバイス144が場所202の中に置かれているかどうかに関係なく、トリガイベント、または活動のない時間間隔に基づいて場所202を安全でないとみなす可能性がある。
FIG. 2 is a diagram of the operation of the
ホテルの部屋(または安全な公共の場所202)は、接続された電気通信デバイス204(たとえば、接続された電話)、接続されたサーモスタット206、接続されたランプ208、接続されたスピーカ210(もしくはサウンドシステム)、または接続されたマルチメディアディスプレイ212(もしくはスマートテレビ)などのいくつかのインターネットに接続されたデバイスを含み得る。インターネットに接続されたデバイス204、206、208、210、または212は、ワイヤレスゲートウェイ214(たとえば、ネットワークルータ、ワイヤレスルータ、またはモデム)を介してネットワーク105に接続することが可能であり、ワイヤレスゲートウェイ214は、ネットワーク105へのアクセスを提供することができる。インターネットに接続されたデバイス204、206、208、210、または212は、データ処理システム102を介して監視されるか、管理されるか、または制御される可能性がある。場合によっては、インターネットに接続されたデバイス204、206、208、210、または212は、データ処理システム102を介して第三者デバイス146によって監視されるか、管理されるか、または制御される可能性がある。
A hotel room (or a secure public place 202) has a connected telecommunications device 204 (eg, a connected telephone), a connected thermostat 206, a
図2に示される例示的な環境200において、モバイルコンピューティングデバイス144は、ホテルの部屋または安全な公共の場所202に置かれる。ローカルコンピューティングデバイス104も、安全な公共の場所202に置かれる。ローカルコンピューティングデバイス104は、ホテルの部屋の中にいるユーザから音声入力を受け取ることができる。ローカルコンピューティングデバイス104は、入力オーディオを含むデータパケットを生成し、ワイヤレスゲートウェイ214およびネットワーク105を介してデータ処理システム102にデータパケットを送信することができる。データ処理システム102は、データパケットを受信し、入力オーディオ信号から音響シグネチャを特定するために話者認識を実行することができる。それから、データ処理システム102は、音響シグネチャに対応する電子アカウントを特定することができる。データ処理システム102は、電子アカウントに対応するプロファイルを選択し、それから、ローカルコンピューティングデバイス104のためのプロファイルスタックデータ構造142にプロファイルをプッシュすることができる。プロファイルスタックデータ構造142は、ローカルコンピューティングデバイス104に固有である可能性がある。たとえば、各ローカルコンピューティングデバイス104は、それぞれのプロファイルスタックデータ構造142を持ち得る。ローカルコンピューティングデバイス104のためのプロファイルスタックデータ構造142は、プロファイルスタックデータ構造142を使用して処理を容易にするためにデータ処理システム102上に(たとえば、データ処理システム102のデータリポジトリまたはメモリに)記憶され得るかまたは保持され得る。場合によっては、プロファイルスタックデータ構造142は、ローカルコンピューティングデバイス104のメモリにローカルに記憶され得る。
In the
プロファイルスタックデータ構造142は、第三者デバイス146によって確立されたデフォルトプロファイルまたはベースラインプロファイルに対応する第1のプロファイルレイヤ「レイヤ1」を含み得る。第三者デバイス146は、プロファイルスタックデータ構造142に配置するためにデータ処理システム102にレイヤ1のプロファイルを提供し得る。データ処理システム102は、音響シグネチャを検出したことに応答して、第2のプロファイルレイヤ「レイヤ2」に配置するためにプロファイルスタックデータ構造142に電子アカウントに対応する第2のプロファイルをプッシュすることができる。
The profile
レイヤ1のプロファイルは、インターネットに接続されたデバイス204、206、208、210、または212に関する所定のラベルを含み得る。ラベルは、第三者デバイス146を介して確立され得る。第三者デバイス146は、安全な公共の場所202(たとえば、ホテル)を管理するか、所有するか、または運用する第三者エンティティに関連付けられ得る。
The Layer 1 profile may include predetermined labels for
レイヤ2の第2のプロファイルレイヤは、音響シグネチャに対応するユーザの電子アカウントに関連するプロファイル情報を含み得る。第2のプロファイルは、インターネットに接続されたデバイス204、206、208、210、または212に関するラベルを含む可能性がありまたは含まない可能性がある。第2のプロファイルがレイヤ1に与えられたラベルと同様であるインターネットに接続されたデバイスに関するラベルを含む場合、データ処理システム102は、レイヤ1内のラベルがレイヤ2内のラベルよりも高くランク付けされるかまたはより高く優先順位付けされる可能性があるので、レイヤ1のラベルを使用すると決定し得る。場合によっては、データ処理システム102は、曖昧さをなくすことを容易にし、インターネットに接続されたデバイスに送信されるアクションデータ構造の数を減らすために、どのインターネットに接続されたデバイスが参照されているのかを明確にするためのプロンプトをユーザに提供することができ、それによって、意図しないインターネットに接続されたデバイスによるネットワーク帯域幅の利用および計算リソースの利用を削減する。
The second profile layer of layer 2 may contain profile information related to the user's electronic account corresponding to the acoustic signature. The second profile may or may not include labels for
たとえば、入力オーディオは、「私の居間のランプをつける」要求を含み得る。プロファイルスタックデータ構造がレイヤ1のプロファイルのみを含んでいた場合、データ処理システム102は、ホテルの部屋202に1つの接続されたランプのみが存在するので、ランプが、接続されたランプ208に対応すると判定する可能性がある。そして、データ処理システム102は、ネットワーク105を介して接続されたランプ208に命令を含むアクションデータ構造を送信することによって接続されたランプ208をつける可能性がある。しかし、プロファイルスタックデータ構造142にロードされたレイヤ2のプロファイルが存在する場合、データ処理システム102は、第2のプロファイルがラベル「居間のランプ」を含むかどうかを判定するためにその第2のプロファイルをパースし得る。ラベル「居間のランプ」は、電子アカウントに関連する私邸のランプに対応する可能性がある。データ処理システム102がラベル「居間のランプ」を検出する場合、データ処理システム102は、私邸に置かれた接続された居間のランプに命令を含むアクションデータ構造を送信する可能性がある。
For example, input audio can include a request to "turn on the lamp in my living room." If the profile stack data structure contained only Layer 1 profiles, then the
ローカルコンピューティングデバイス104は、オーディオドライバ138、トランスデューサ136、センサ134、およびプリプロセッサコンポーネント140を含み得る。センサ134は、入力オーディオ信号(たとえば、音声入力)を受信するかまたは検出することができる。プリプロセッサコンポーネント140は、オーディオドライバ、トランスデューサ、およびセンサに結合され得る。プリプロセッサコンポーネント140は、(たとえば、特定の周波数を取り除くかまたは雑音を抑制することによって)フィルタリングされた入力オーディオ信号を生成するために入力オーディオ信号をフィルタリングすることができる。プリプロセッサコンポーネント140は、(たとえば、ソフトウェアまたはハードウェアデジタル-アナログコンバータを使用して)フィルタリングされた入力オーディオ信号をデータパケットに変換することができる。場合によっては、プリプロセッサコンポーネント140は、フィルタリングされていない入力オーディオ信号をデータパケットに変換し、データパケットをデータ処理システム102に送信することができる。プリプロセッサコンポーネント140は、自然言語プロセッサコンポーネント、インターフェース、話者認識コンポーネント、およびダイレクトアクションアプリケーションプログラミングインターフェースを実行する1つまたは複数のプロセッサおよびメモリを含むデータ処理システム102にデータパケットを送信することができる。
The local computing device 104 may include an audio driver 138, a
データ処理システム102は、センサによって検出されたフィルタリングされた(またはフィルタリングされていない)入力オーディオ信号を含むデータパケットをプリプロセッサコンポーネントからインターフェースを介して受信することができる。データ処理システム102は、入力オーディオ信号から音響シグネチャを特定することができる。データ処理システム102は、データリポジトリ内でのルックアップ(たとえば、データベースに問い合わせること)に基づいて音響シグネチャに対応する電子アカウントを特定することができる。データ処理システム102は、電子アカウントを特定したことに応答して、セッションおよびセッションにおいて使用するためのプロファイルスタックデータ構造を確立することができる。プロファイルスタックデータ構造は、第三者エンティティのデバイスによって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含む。データ処理システム102は、電子アカウントから取り出された第2のプロファイルレイヤを、セッションのために確立されたプロファイルスタックデータ構造にプッシュすることができる。データ処理システム102は、要求および要求に対応するトリガキーワードを特定するために入力オーディオ信号をパースすることができる。データ処理システム102は、プロファイルスタックデータ構造の第1のプロファイルレイヤに適合する要求に応答する第1のアクションデータ構造を、トリガキーワードとプロファイルスタックデータ構造にプッシュされた第2のプロファイルレイヤとに基づいて生成することができる。データ処理システム102は、実行するために第1のアクションデータ構造を提供することができる。データ処理システム102は、トリガイベントを検出したことに応答して、プロファイルスタックデータ構造を分解して、プロファイルスタックデータ構造から第1のプロファイルレイヤまたは第2のプロファイルレイヤのうちの一方を取り除くことができる。
The
データ処理システム102は、プロファイルスタックデータ構造のステータスをローカルコンピューティングデバイス104のプリプロセッサコンポーネントに提供することができる。ステータスは、第2のプロファイルレイヤがプロファイルスタックにプッシュされたことを示す可能性がある。ステータスは、第1のプロファイルレイヤと第2のプロファイルレイヤとの両方がプロファイルスタック内にあることを示す可能性がある。ステータスは、第2のプロファイルレイヤがプロファイルスタックから取り除かれたことを示す可能性がある。ステータスは、プロファイルスタックがクリアされたかまたは(たとえば、プロファイルスタック内に第1のプロファイルレイヤのみを有する)デフォルト状態に戻されたことを示す可能性がある。たとえば、「安全な場」、「公共の場」、「<電子アカウントの識別子>」、または「準備完了(ready)」を含む様々な用語が、ステータスを示すために使用され得る。
The
ローカルコンピューティングデバイス104は、ステータスの指示を受信することができる。オーディオドライバは、プロファイルスタックデータ構造のステータスの指示を受信し、指示に基づいて出力信号を生成することができる。オーディオドライバは、指示を音声信号または音響出力信号などの出力信号に変換することができる。オーディオドライバは、オーディオドライバによって生成された出力信号に基づいて音を生成するようにトランスデューサ136(たとえば、スピーカ)を駆動することができる。 The local computing device 104 can receive status instructions. The audio driver can receive an indication of the status of the profile stack data structure and generate an output signal based on the indication. The audio driver can convert the instruction into an output signal such as a voice signal or an acoustic output signal. The audio driver can drive the transducer 136 (eg, a speaker) to produce sound based on the output signal generated by the audio driver.
場合によっては、ローカルコンピューティングデバイス104は、光源を含み得る。光源は、1つもしくは複数のLED、ライト、ディスプレイ、または光または視覚的出力を提供するように構成されたその他のコンポーネントもしくはデバイスを含み得る。プリプロセッサコンポーネントは、光源にプロファイルスタックデータ構造のステータスに対応する視覚的な指示を提供させることができる。たとえば、視覚的な指示は、オンになるステータスインジケータライト、光の色の変化、1つもしくは複数の色を用いたライトパターン、またはテキストもしくは画像の視覚的表示である可能性がある。 In some cases, the local computing device 104 may include a light source. A light source may include one or more LEDs, lights, displays, or other components or devices configured to provide light or visual output. The preprocessor component can allow the light source to provide visual indications corresponding to the status of the profile stack data structure. For example, the visual indication can be a status indicator light that turns on, a change in the color of the light, a light pattern with one or more colors, or a visual display of text or images.
図3は、プロファイルスタックを処理するためのシステム100の動作の図である。システム100は、図1に示されるシステム100、図2に示される環境200、または図6に示されるシステム600の1つまたは複数のコンポーネントを含み得る環境300内で動作することができる。環境300は、図2に示される同じ場所202を含み得るが、場所は、安全な公共の場所202とは対照的に安全でない公共の場所302である可能性がある。公共の場所は、モバイルコンピューティングデバイス144が安全な公共の場所の外304に置かれているので安全でない公共の場所302である可能性がある。安全な場所の外304は、地理フェンスの外にあるか、またはローカルコンピューティングデバイス104から距離の閾値よりも離れていることを指す可能性がある。安全でない公共の場所302にあるインターネットに接続されたデバイス204、206、208、210、および212は、安全な公共の場所202にある同じインターネットに接続されたデバイスである可能性がある。しかし、モバイルコンピューティングデバイス144が場所302を離れることは、データ処理システム102にプロファイルスタックデータ構造142を分解させる終了イベントをトリガすることができる。プロファイルスタックデータ構造142を分解することは、レイヤ1に第1のプロファイルを残しながらレイヤ2内の第2のプロファイルを取り除くことを含み得る。データ処理システム102は、プロファイルスタックデータ構造142を、第三者によって確立されたローカルコンピューティングデバイス104のために構成されたデフォルト状態に戻すことができる。たとえば、データ処理システム102は、プロファイルスタックデータ構造142からレイヤ2を取り除くための命令306を送信することができる。
FIG. 3 is a diagram of the operation of the
図4は、プロファイルスタックを処理するためのシステム100の動作の図である。システム100は、図1に示されるシステム100、または図6に示されるシステム600の1つまたは複数のコンポーネントを含み得る環境400内で動作することができる。環境400は、第2のプロファイルに関連する音響シグネチャを有する電子アカウントに関連するユーザに対応する私邸などの安全な私的な場所402を含み得る。安全な私的な場所402は、データ処理システム102によって管理されるか、監視されるか、または制御され得るいくつかのインターネットに接続されたデバイスを含み得る。インターネットに接続されたデバイスは、たとえば、接続された電気通信デバイス204、接続されたサーモスタット206、接続されたランプ208、接続されたスピーカ210、および接続されたマルチメディアディスプレイ212を含み得る。安全な私的な場所402は、ローカルコンピューティングデバイス104も含み得る。ローカルコンピューティングデバイスは、ローカルコンピューティングデバイス104としての1つまたは複数のコンポーネントまたは機能を含み得る。安全な私的な場所402は、ワイヤレスゲートウェイ214も含む可能性があり、ワイヤレスゲートウェイ214は、図2に示された公共の場所202に置かれたワイヤレスゲートウェイ214としての1つまたは複数のコンポーネントまたは機能を含み得る。
FIG. 4 is a diagram of the operation of the
安全な私的な場所402に置かれた接続された電気通信デバイス204は、図2に示された公共の場所202に置かれた接続された電気通信デバイス204としての1つまたは複数のコンポーネントまたは機能を含み得る。しかし、安全な私的な場所402に置かれた接続された電気通信デバイス204は、図2に示された公共の場所202に置かれた接続された電気通信デバイス204と比較して異なる構成の設定または識別子を含み得る。
The connected telecommunications device 204 located in a secure
安全な私的な場所402に置かれた接続されたサーモスタット206は、図2に示された公共の場所202に置かれた接続されたサーモスタット206としての1つまたは複数のコンポーネントまたは機能を含み得る。しかし、安全な私的な場所402に置かれた接続されたサーモスタット206は、図2に示された公共の場所202に置かれた接続されたサーモスタット206と比較して異なる構成の設定または識別子を含み得る。
A connected thermostat 206 placed in a secure
安全な私的な場所402に置かれた接続されたランプ208は、図2に示された公共の場所202に置かれた接続されたランプ208としての1つまたは複数のコンポーネントまたは機能を含み得る。しかし、安全な私的な場所402に置かれた接続されたランプ208は、図2に示された公共の場所202に置かれた接続されたランプ208と比較して異なる構成の設定または識別子を含み得る。
The
安全な私的な場所402に置かれた接続されたスピーカ210は、図2に示された公共の場所202に置かれた接続されたスピーカ210としての1つまたは複数のコンポーネントまたは機能を含み得る。しかし、安全な私的な場所402に置かれた接続されたスピーカ210は、図2に示された公共の場所202に置かれた接続されたスピーカ210と比較して異なる構成の設定または識別子を含み得る。
The
安全な私的な場所402に置かれた接続されたマルチメディアディスプレイ212は、図2に示された公共の場所202に置かれた接続されたマルチメディアディスプレイ212としての1つまたは複数のコンポーネントまたは機能を含み得る。しかし、安全な私的な場所402に置かれた接続されたマルチメディアディスプレイ212は、図2に示された公共の場所202に置かれた接続されたマルチメディアディスプレイ212と比較して異なる構成の設定または識別子を含み得る。
The connected multimedia display 212 placed in a secure
安全な私的な場所402は、ユーザの私邸、家、またはアパートを指す可能性がある。安全な私的な場所402内のローカルコンピューティングデバイス104は、第三者デバイス146によって提供されたデフォルトまたはベースラインプロファイルを利用しない可能性がある。したがって、データ処理システム102は、第2のユーザの電子アカウントに関連するレイヤ2のプロファイルのみを追加する可能性がある。安全な私的な場所402に置かれたローカルコンピューティングデバイス104のための(プロファイルスタックデータ構造142の1つまたは複数のコンポーネントまたは機能を含み得る)プロファイルスタックデータ構造142は、第三者デバイスによって確立されたレイヤ1のプロファイルを含まない可能性がある。したがって、データ処理システム102は、プロファイルスタックデータ構造142にレイヤ2 404を追加するのみである可能性がある。
A safe
しかし、万が一、第2のユーザが安全な私的な場所402に入り、ローカルコンピューティングデバイス104によって検出される音声入力を与えるならば、データ処理システム102は、第2のユーザに対応する第3のプロファイルを選択し、それから、プロファイルスタックデータ構造142に第3のプロファイルをレイヤ3としてプッシュすることができる(プロファイルスタックデータ構造142と一致するレイヤ構造を示すために示されたレイヤ1は存在しない)。
However, in the unlikely event that a second user enters a safe
場合によっては、安全な私的な場所402内のローカルコンピューティングデバイス104およびデータ処理システム102は、プロファイルスタックデータ構造142に1つまたは複数の追加的なプロファイルレイヤをプッシュすることができる。たとえば、安全な私的な場所402の来客が、ローカルコンピューティングデバイス104によって検出され得る音声入力を与えることができる。ローカルコンピューティングデバイス104は、音声入力または入力オーディオ信号を検出すると、入力オーディオ信号に対して前処理を実行し、さらに処理するためにデータ処理システム102に入力オーディオ信号に対応するデータパケットを送信することができる。データ処理システム102は、入力オーディオ信号から音響シグネチャを検出しようと試みることができる。データ処理システム102は、音響シグネチャを特定し、それから、来客のための対応する電子アカウントを特定しようと試みる可能性がある。しかし、データ処理システム102は、来客のための対応する電子アカウントを特定することができない可能性がある--または、データ処理システム102は、音響シグネチャを特定することができない可能性がある。どちらの場合も、データ処理システム102は、入力オーディオ信号またはその音響シグネチャに応じてプロファイルレイヤにアクセスすることができないかまたはプロファイルレイヤを選択することができない可能性がある。この場合、データ処理システムは、別個の処理フローを利用することができる。
In some cases, the local computing device 104 and the
たとえば、入力オーディオ信号を与えたゲストユーザは、データ処理システム102によって確立された電子アカウントまたはプロファイルを持たない可能性がある。来客は、モバイルコンピューティングデバイス144を有する可能性がある。データ処理システム102は、入力オーディオ信号に対応する電子アカウントがないと判定し得る。場合によっては、データ処理システム102は、新しいプロファイルを作成するプロンプトまたは要求を生成し得る。しかし、ゲストユーザが新しいプロファイルを作成するプロンプトまたは要求を拒否する場合、またはデータ処理システム102がプロファイルを作成することなく処理フローを続けると決定する場合、データ処理システム102は、プロファイルの入らないフローを開始するかまたはゲストモードに入ることができる。ゲストモードにおいて、データ処理システム102は、別個の認証メカニズムを利用することができる。たとえば、データ処理システム102は、ローカルコンピューティングデバイス104に結合されたディスプレイデバイスによってQRコード(登録商標)などの光符号(またはアカウントの一意識別子、識別子、もしくは金融商品(financial instrument)などの何らかのその他のコード)を提示することができる。一意識別子またはQRコード(登録商標)は、プロファイルまたは電子アカウントを作成する結果とならない一時的セッションを来客が確立することを可能にし得る。データ処理システム102は、一時的セッションによってアクションデータ構造を構築し始めるかまたはその他のタスクを実行し始める可能性がある。
For example, a guest user who feeds an input audio signal may not have an electronic account or profile established by the
場合によっては、データ処理システム102は、ローカルコンピューティングデバイス104自体などの製品を購入するためのデジタルコンポーネントを来客のモバイルコンピューティングデバイス144に送信する可能性がある。
In some cases, the
図5は、コンピュータネットワークを介してスタック形式のデータ構造を処理する方法の図である。方法500は、図1に示されるシステム100または図6に示されるシステム600の1つまたは複数のコンポーネント、システム、または要素によって実行され得る。方法500は、図2に示される環境200、図3に示される環境300、または図4に示される環境400内で実行され得る。方法500は、行為502においてデータ処理システムが入力オーディオ信号を受信することを含み得る。データ処理システムは、インターフェースを介して入力オーディオ信号を含むデータパケットを受信する。入力オーディオ信号は、マイクロフォンなどのローカルコンピューティングデバイスのセンサによって検出された可能性がある。ローカルコンピューティングデバイスは、ホテルなどの公共の場所に置かれる可能性がある。場合によっては、ローカルコンピューティングデバイスは、住居などの安全な私的な場所に置かれる可能性がある。ローカルコンピューティングデバイスは、音声入力を検出し、音声入力を前処理し、音声入力の少なくとも一部を含むデータパケットを生成し、データパケットをデータ処理システムに送信することができる。ローカルコンピューティングデバイスは、音声入力を検出することをローカルコンピューティングデバイスに示すトリガキーワードを特定したことに応答してデータパケットを送信し、その音声入力をデジタルデータパケットに変換し、さらなる処理のためにデジタルデータパケットをデータ処理システムに送信する可能性がある。
FIG. 5 is a diagram of how to process a stacked data structure over a computer network.
行為504において、データ処理システムがシグネチャを特定する。データ処理システムは、入力オーディオ信号から音響シグネチャを特定することができる。データ処理システムは、音響シグネチャを特定するために話者認識技術、パターン認識、またはその他の技術を適用することができる。データ処理システムは、1つまたは複数の音響シグネチャを特定することができる。場合によっては、データ処理システムは、パスコード、パスワード、PIN、パスフレーズ、その他の生体認証、またはモバイルデバイスに送られたセキュリティコードによるような多要素認証をユーザに促すことができる。
In
行為506において、データ処理システムがアカウントを特定する。データ処理システムは、電子アカウントを特定するためにデータリポジトリ内で音響シグネチャのルックアップを実行することができる。データ処理システムは、音響シグネチャに基づく認証または多要素認証が満たされたことに応答してルックアップを実行することができる。電子アカウントは、好み、ラベル、ポリシー、規則、あるいは誤ったもしくは無駄な遠隔手続き呼び出しまたはデータ送信を削減することができるその他の情報などのプロファイル情報を含み得る。
In
場合によっては、データ処理システムは、音響シグネチャを使用せずにアカウントを特定することができる。データ処理システムは、様々な入力、センサ、またはインターフェースを使用してアカウントを特定することができる。たとえば、アカウントを特定するために音響シグネチャを使用するのではなく、データ処理システムは、ユーザが所有するモバイルデバイスに基づいてアカウントを特定し得る。モバイルデバイスは、ローカルコンピューティングデバイスと通信するまたはインタラクションすることができる。ユーザは、アカウントを使用してモバイルデバイスにログインすることができる。アカウントを使用してモバイルデバイスにログインすることは、ユーザ名(またはその他のアカウント識別子)およびパスワード(またはその他のトークン、キー、もしくは生体パスワード)などの資格証明情報をモバイルデバイス上で実行されるソフトウェアアプリケーションまたはオペレーティングシステムに入力し、資格証明情報を認証することを指す可能性がある。モバイルデバイスは、アカウント情報(たとえば、ユーザ名)をローカルコンピューティングデバイスに通信し、アカウントがモバイルデバイス上で認証されたことを示すことができる。ローカルコンピューティングデバイスは、アカウント識別子と、アカウント識別子が認証されたかまたは確認されたこととの指示をデータ処理システムを送信することができる。データ処理システムは、ローカルコンピューティングデバイスからアカウント識別子を受信し、対応する電子アカウントにアクセスし、対応するプロファイルを取り出すことができる。したがって、データ処理システムは、音響シグネチャを使用することを含む可能性がありまたは含まない可能性がある1つまたは複数の技術を使用してユーザに関連するアカウントを特定することができる。その他の技術は、光符号(たとえば、クイックリファレンスコード(quick reference code))、生物測定(たとえば、指紋、虹彩スキャナ、もしくは顔認識)を使用すること、アカウント識別子をタイピングするためにキーボード、マウス、もしくはタッチインターフェースを使用すること、またはアカウント識別子を与えるために音声入力を使用することを含み得る。 In some cases, the data processing system can identify the account without using acoustic signatures. Data processing systems can identify accounts using a variety of inputs, sensors, or interfaces. For example, instead of using acoustic signatures to identify accounts, data processing systems can identify accounts based on user-owned mobile devices. Mobile devices can communicate or interact with local computing devices. Users can use their accounts to log in to mobile devices. Using an account to log in to a mobile device is software that executes credentials such as a username (or other account identifier) and password (or other token, key, or biometric password) on the mobile device. May refer to entering into an application or operating system to authenticate credentials. The mobile device can communicate account information (eg, username) to the local computing device to indicate that the account has been authenticated on the mobile device. The local computing device can send a data processing system with an account identifier and instructions that the account identifier has been authenticated or verified. The data processing system can receive the account identifier from the local computing device, access the corresponding electronic account, and retrieve the corresponding profile. Thus, the data processing system can use one or more techniques that may or may not include the use of acoustic signatures to identify the account associated with the user. Other techniques include using optical codes (eg, quick reference code), biometrics (eg, fingerprints, iris scanners, or facial recognition), keyboards, mice, and keyboards to type account identifiers. Alternatively, it may include using a touch interface or using voice input to give an account identifier.
行為508において、データ処理システムがセッションおよびプロファイルスタックを確立する。データ処理システムは、セッションおよびセッションにおいて使用するためのプロファイルスタックデータ構造を確立することができる。データ処理システムは、電子アカウントの特定または認証手順(たとえば、音響シグネチャに基づく認証、もしくは多要素認証、もしくは追加的な生体認証)の完了に応答してセッションおよびプロファイルスタックデータ構造を確立することができる。プロファイルスタックデータ構造は、第三者によって維持される公共の場所に置かれたローカルコンピューティングデバイスのためのものである可能性があるので、第三者エンティティ(たとえば、ホテルの管理者、モールの管理者、またはレンタカーの管理者)のデバイスによって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含み得る。
In
行為510において、データ処理システムが第2のプロファイルをプッシュする。データ処理システムは、セッションのために確立されるプロファイルスタックデータ構造に第2のプロファイルを第2のプロファイルレイヤとしてプッシュすることができる。第1のプロファイルレイヤは、第2のプロファイルレイヤよりも優先される特定のラベルまたはポリシーを有する可能性がある。第2のプロファイルレイヤはデジタルコンポーネントを選択し、アクションデータ構造を生成するために利用され得るが、第1のプロファイルレイヤが、特定の種類のデジタルコンポーネントまたはアクションデータ構造が実行される(たとえば、ユーザに対して提示するために配信されるか、意図されるインターネットに接続されたデバイスに送信されるか、または相乗りサービスなどのサービスプロバイダに送信される)ことをブロックする可能性がある。
In
行為512において、データ処理システムが要求を特定する。データ処理システムは、要求および要求に対応するトリガキーワードを特定するために入力オーディオ信号をパースすることができる。データ処理システムは、音響シグネチャ、電子アカウント、および第2のプロファイルを特定するために使用される同じ入力オーディオ信号をパースすることができる。場合によっては、データ処理システムは、電子アカウントおよびプロファイルを特定するために使用される第1の入力オーディオ信号の後に受信される第2の入力オーディオ信号を処理する可能性がある。データ処理システムは、第2の入力オーディオ信号内の要求およびトリガキーワードを特定する可能性がある。
In
行為514において、データ処理システムがアクションデータ構造を生成し、提供する。データ処理システムは、要求と、トリガキーワードと、プロファイルスタックデータ構造にプッシュされた第2のプロファイルレイヤとに基づいてアクションデータ構造を生成することができる。アクションデータ構造は、要求に応じて生成され得る。アクションデータ構造は、プロファイルスタックデータ構造の第1のプロファイルレイヤに適合し得る。アクションデータ構造は音響シグネチャに関連する電子アカウントに関連する第2のプロファイルを使用して生成され得るが、データ処理システムは、生成されたアクションデータ構造が第1のプロファイルレイヤに適合するかまたは準拠しているかどうかを判定するためにエラーチェックを実行することができる。たとえば、第1のプロファイルレイヤは、誤りがあるか、または余分なネットワーク帯域幅もしくは計算リソースを消費する可能性がある特定の種類のアクションデータ構造をブロックするか、防止するか、または禁止する可能性がある。
In
アクションデータ構造が第1のプロファイルレイヤに準拠していると判定すると、データ処理システムは、実行するために第1のアクションデータ構造を提供することができる。実行するためにアクションデータ構造を提供することは、アクションを実行するかもしくは命令を与えるためにインターネットに接続されたデバイスにアクションデータ構造を送信すること、サービスプロバイダにアクションデータ構造を送信すること、またはデジタルコンポーネントを受信するためにコンテンツセレクタコンポーネントにアクションデータ構造を提供することを含み得る。 If it determines that the action data structure conforms to the first profile layer, the data processing system can provide the first action data structure for execution. Providing an action data structure to perform is to send the action data structure to a device connected to the Internet to perform an action or give an instruction, to send an action data structure to a service provider, Alternatively, it may include providing an action data structure to the content selector component to receive the digital component.
行為516において、データ処理システムがプロファイルスタック142を分解する。データ処理システムは、トリガイベントの検出に応じてプロファイルスタックを分解することができる。データ処理システムは、プロファイルスタックデータ構造から第1のプロファイルレイヤまたは第2のプロファイルレイヤのうちの一方を取り除くことによってプロファイルスタックデータ構造を分解することができる。たとえば、データ処理システムは、音響シグネチャに対応する第2のプロファイルを取り除くことによってプロファイルスタックをデフォルト設定にリセットすることができる。トリガイベントは、時間間隔(たとえば、ユーザによって設定されたカスタムの時間間隔、または10分、20分、30分、1時間、12時間、もしくは24時間などの所定の時間間隔)を含み得る。トリガイベントは、地理的フェンス、または第1のユーザとは異なる第2のユーザの検出を含み得る。
In
プロファイルスタックデータ構造を使用することによって、データ処理システムは、ローカルコンピューティングデバイスによって受信されるコマンドの曖昧さをなくすことを容易にし得る。たとえば、データ処理システムは、「家のライト」という文法を用いたコマンドを受信する可能性がある。データ処理システムは、「家のライト」に対応する1つまたは複数のインターネットに接続されたデバイスを特定するために第2のプロファイルを調べることができる。しかし、第1のプロファイルレイヤは、「家のライト」に対応するラベルも含む可能性がある。データ処理システムは、どのインターネットに接続されたデバイスが制御されるべきかを解読するためにユーザにプロンプトを与える可能性がある。たとえば、データ処理システムは、第2のプロファイルに基づいてアクションデータ構造を生成し、それから、生成されたアクションデータ構造が第1のプロファイルに準拠しているかどうかを判定するためにアクションデータ構造を第1のプロファイル内のポリシーまたは規則と比較することができる。場合によっては、データ処理システムは、ラベルが第1のプロファイル内のラベルと重なり合うのでアクションデータ構造が準拠していないと判定し、したがって、さらなるプロンプトなしにアクションデータ構造の送信または実行をブロックすることができる。 By using profile stack data structures, data processing systems can facilitate disambiguation of commands received by local computing devices. For example, a data processing system may receive commands using the "house light" grammar. The data processing system can look at a second profile to identify one or more Internet-connected devices that correspond to "home lights." However, the first profile layer may also contain a label corresponding to "house light". The data processing system may prompt the user to decipher which Internet-connected device should be controlled. For example, a data processing system generates an action data structure based on a second profile, and then uses the action data structure to determine if the generated action data structure conforms to the first profile. Can be compared with policies or rules in one profile. In some cases, the data processing system determines that the action data structure is not compliant because the label overlaps the label in the first profile, and therefore blocks the transmission or execution of the action data structure without further prompting. Can be done.
図6は、例示的なコンピュータシステム600のブロック図である。コンピュータシステムまたはコンピューティングデバイス600は、システム100、またはデータ処理システム102などのそのシステム100のコンポーネントを含むかまたはそれらを実装するために使用され得る。データ処理システム102は、インテリジェントなパーソナルアシスタントまたは音声に基づくデジタルアシスタントを含み得る。コンピューティングシステム600は、情報を通信するためのバス605またはその他の通信コンポーネントと、情報を処理するためのバス605に結合されたプロセッサ610または処理回路とを含む。また、コンピューティングシステム600は、情報を処理するためのバスに結合された1つまたは複数のプロセッサ610または処理回路を含み得る。コンピューティングシステム600は、情報およびプロセッサ610によって実行される命令を記憶するためのバス605に結合されたランダムアクセスメモリ(RAM)またはその他のダイナミックストレージデバイスなどのメインメモリ615も含む。メインメモリ615は、データリポジトリ124であるかまたはデータリポジトリ124を含む可能性がある。メインメモリ615は、位置情報、一時的な変数、またはプロセッサ610による命令の実行中のその他の中間情報を記憶するためにも使用され得る。コンピューティングシステム600は、静的な情報およびプロセッサ610のための命令を記憶するためのバス605に結合された読み出し専用メモリ(ROM)620またはその他のスタティックストレージデバイスをさらに含む可能性がある。ソリッドステートデバイス、磁気ディスク、または光ディスクなどのストレージデバイス625が、情報および命令を永続的に記憶するためにバス605に結合され得る。ストレージデバイス625は、データリポジトリ124を含むかまたはデータリポジトリ124の一部である可能性がある。
FIG. 6 is a block diagram of an
コンピューティングシステム600は、ユーザに対して情報を表示するための液晶ディスプレイまたはアクティブマトリックスディスプレイなどのディスプレイ635にバス605を介して結合される可能性がある。英数字およびその他のキーを含むキーボードなどの入力デバイス630が、プロセッサ610に情報およびコマンド選択を通信するためにバス605に結合される可能性がある。入力デバイス630は、タッチスクリーンディスプレイ635を含み得る。入力デバイス630は、プロセッサ610に方向情報およびコマンド選択を通信するためおよびディスプレイ635上でカーソルの動きを制御するためのマウス、トラックボール、またはカーソル方向キーなどのカーソルコントロールも含み得る。ディスプレイ635は、たとえば、図1のデータ処理システム102、クライアントコンピューティングデバイス104、またはその他のコンポーネントの一部である可能性がある。
The
本明細書において説明されるプロセス、システム、および方法は、メインメモリ615に含まれる命令の配列をプロセッサ610が実行したことに応答してコンピューティングシステム600によって実施され得る。そのような命令は、ストレージデバイス625などの別のコンピュータ可読媒体からメインメモリ615に読まれ得る。メインメモリ615に含まれる命令の配列の実行は、コンピューティングシステム600に本明細書において説明される例示的なプロセスを実行させる。マルチプロセッシング配列の1つまたは複数のプロセッサも、メインメモリ615に含まれる命令を実行するために使用される可能性がある。配線による回路が、本明細書において説明されるシステムおよび方法と一緒にソフトウェア命令の代わりにまたはソフトウェア命令と組み合わせて使用され得る。本明細書において説明されるシステムおよび方法は、ハードウェア回路とソフトウェアとのいかなる特定の組合せにも限定されない。
The processes, systems, and methods described herein may be performed by the
例示的なコンピューティングシステムが図6に示されたが、本明細書に記載の動作を含む対象は、本明細書において開示された構造およびそれらの構造的均等物を含む、その他の種類のデジタル電子回路、またはコンピュータソフトウェア、ファームウェア、もしくはハードウェア、またはそれらのうちの1つもしくは複数の組合せで実装され得る。 An exemplary computing system is shown in FIG. 6, but objects including the operations described herein include other types of digital, including the structures disclosed herein and their structural equivalents. It can be implemented in electronic circuits, or computer software, firmware, or hardware, or a combination of one or more of them.
本明細書に記載のシステムがユーザについての個人情報を収集するか、または個人情報を利用する可能性がある状況に関して、ユーザは、プログラムまたは機能が個人情報(たとえば、ユーザのソーシャルネットワーク、ソーシャルなアクションもしくは活動、ユーザの好み、またはユーザの位置についての情報)を収集し得るかどうかを制御するか、あるいはユーザにより関連性がある可能性があるコンテンツをコンテンツサーバもしくはその他のデータ処理システムから受信すべきかどうかまたはどのようにして受信すべきかを制御する機会を与えられる可能性がある。さらに、特定のデータが、パラメータを生成するときに個人を特定することができる情報が削除されるように、記憶されるかまたは使用される前に1つまたは複数の方法で匿名化される可能性がある。たとえば、ユーザの識別情報が、個人を特定することができる情報がユーザに関して決定され得ないように匿名化される可能性があり、または(都市、郵便番号、もしくは州のレベルまでなど)位置情報が取得される場合に、ユーザの地理的位置が、ユーザの特定の位置が決定され得ないように一般化される可能性がある。したがって、ユーザは、情報がユーザについてどのように収集され、コンテンツサーバによって使用されるかを制御し得る。 With respect to situations in which the systems described herein may collect or use personal information about you, you may program or function personal information (eg, your social network, social). Controls whether actions or activities, user preferences, or information about the user's location) can be collected, or receives content that may be more relevant to the user from a content server or other data processing system. You may be given the opportunity to control whether or how it should be received. In addition, certain data can be anonymized in one or more ways before being stored or used so that personally identifiable information is removed when generating parameters. There is sex. For example, a user's identity may be anonymized so that personally identifiable information cannot be determined for the user, or location information (such as to the city, zip code, or state level). Is obtained, the geographic location of the user may be generalized so that a particular location of the user cannot be determined. Therefore, the user can control how the information is collected about the user and used by the content server.
本明細書に記載の対象および動作は、本明細書において開示された構造およびそれらの構造的均等物を含むデジタル電子回路、またはコンピュータソフトウェア、ファームウェア、もしくはハードウェア、またはこれらのうちの1つもしくは複数の組合せで実装され得る。本明細書に記載の対象は、1つまたは複数のコンピュータプログラム、たとえば、データ処理装置による実行のために、またはデータ処理装置の動作を制御するために1つまたは複数のコンピュータストレージ媒体上に符号化されたコンピュータプログラム命令の1つまたは複数の回路として実装され得る。代替的にまたは追加的に、プログラム命令は、データ処理装置による実行のために好適なレシーバ装置に送信するために情報を符号化するように生成される人為的に生成された伝播信号、たとえば、機械によって生成された電気的信号、光学的信号、または電磁的信号上に符号化され得る。コンピュータストレージ媒体は、コンピュータ可読ストレージデバイス、コンピュータ可読ストレージ基板、ランダムもしくはシリアルアクセスメモリアレイもしくはデバイス、またはこれらのうちの1つもしくは複数の組合せであるか、あるいはこれらに含まれる可能性がある。コンピュータストレージ媒体は、伝播信号ではないが、人為的に生成された伝播信号に符号化されたコンピュータプログラム命令の送信元または送信先である可能性がある。コンピュータストレージ媒体は、1つまたは複数の別個のコンポーネントまたは媒体(たとえば、複数のCD、ディスク、もしくはその他のストレージデバイス)であるか、またはそれらに含まれる可能性もある。本明細書に記載の動作は、1つもしくは複数のコンピュータ可読ストレージデバイスに記憶された、またはその他のソースから受信されたデータに対してデータ処理装置によって実行される動作として実装され得る。 The objects and operations described herein are digital electronic circuits, including the structures disclosed herein and their structural equivalents, or computer software, firmware, or hardware, or one or more of them. It can be implemented in multiple combinations. The subject matter described herein is encoded on one or more computer programs, eg, for execution by a data processor or to control the operation of the data processor. It can be implemented as one or more circuits of computerized computer program instructions. Alternatively or additionally, the program instruction is an artificially generated propagating signal, eg, generated to encode information for transmission to a receiver device suitable for execution by a data processor. It can be encoded on a machine-generated electrical, optical, or electromagnetic signal. The computer storage medium may be, or may be contained in, a computer-readable storage device, a computer-readable storage board, a random or serial access memory array or device, or a combination thereof. The computer storage medium is not a propagated signal, but may be the source or destination of a computer program instruction encoded in an artificially generated propagated signal. Computer storage media may be or may be contained in one or more separate components or media (eg, multiple CDs, disks, or other storage devices). The actions described herein can be implemented as actions performed by a data processor on data stored in one or more computer-readable storage devices or received from other sources.
「データ処理システム」、「コンピューティングデバイス」、「コンポーネント」、または「データ処理装置」という用語は、例として、1つのプログラミング可能なプロセッサ、1台のコンピュータ、1つのシステムオンチップ、またはそれらの複数もしくは組合せを含む、データを処理するための様々な装置、デバイス、および機械を包含する。装置は、専用の論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)を含み得る。装置は、ハードウェアに加えて、問題にしているコンピュータプログラムのための実行環境を作成するコード、たとえば、プロセッサのファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、クロスプラットフォームランタイム環境、仮想マシン、またはそれらのうちの1つもしくは複数の組合せを構成するコードも含み得る。装置および実行環境は、ウェブサービスインフラストラクチャ、分散コンピューティングインフラストラクチャ、およびグリッドコンピューティングインフラストラクチャなどの様々な異なるコンピューティングモデルインフラストラクチャを実現することができる。たとえば、ダイレクトアクションAPI 116、コンテンツセレクタコンポーネント118、またはNLPコンポーネント112、およびその他のデータ処理システム102のコンポーネントは、1つまたは複数のデータ処理装置、システム、コンピューティングデバイス、またはプロセッサを含むかまたは共有し得る。
The terms "data processing system," "computing device," "component," or "data processing device" are, for example, one programmable processor, one computer, one system-on-chip, or theirs. Includes various devices, devices, and machines for processing data, including multiple or combinations. The device may include dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). In addition to the hardware, the device creates code that creates an execution environment for the computer program in question, such as processor firmware, protocol stacks, database management systems, operating systems, cross-platform runtime environments, virtual machines, or It may also include code that constitutes one or more combinations of them. Equipment and execution environments can implement a variety of different computing model infrastructures, such as web service infrastructures, distributed computing infrastructures, and grid computing infrastructures. For example, a direct action API 116, a content selector component 118, or an NLP component 112, and other components of a
コンピュータプログラム(プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、スクリプト、またはコードとしても知られる)は、コンパイラ型言語もしくはインタープリタ型言語、宣言型言語もしくは手続き型言語を含む任意の形態のプログラミング言語で記述可能であり、独立型プログラムとしての形態、またはモジュール、コンポーネント、サブルーチン、オブジェクト、もしくはコンピューティング環境での使用に好適なその他の単位としての形態を含む任意の形態で展開され得る。コンピュータプログラムは、ファイルシステム内のファイルに対応し得る。コンピュータプログラムは、その他のプログラムもしくはデータを保持するファイルの一部(たとえば、マークアップ言語のドキュメントに記憶された1つもしくは複数のスクリプト)、問題にしているプログラムに専用の単一のファイル、または複数の連携されたファイル(たとえば、1つもしくは複数のモジュール、サブプログラム、もしくはコードの一部を記憶するファイル)に記憶され得る。コンピュータプログラムは、1つのコンピュータ上で、または1つの場所に置かれるか、もしくは複数の場所に分散され、通信ネットワークによって相互に接続される複数のコンピュータ上で実行されるように展開され得る。 Computer programs (also known as programs, software, software applications, apps, scripts, or code) can be written in any form of programming language, including compiler or interpreted languages, declarative or procedural languages. It can be deployed in any form, including as a stand-alone program, or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. The computer program may correspond to the files in the file system. A computer program may be some of the other programs or files that hold the data (for example, one or more scripts stored in a document in the markup language), a single file dedicated to the program in question, or It can be stored in multiple linked files (eg, a file that stores one or more modules, subprograms, or parts of code). Computer programs can be deployed on one computer, in one location, or distributed over multiple locations and run on multiple computers interconnected by communication networks.
本明細書に記載のプロセスおよび論理フローは、入力データに対して演算を行い、出力を生成することによってアクションを行うために1つまたは複数のコンピュータプログラム(たとえば、データ処理システム102のコンポーネント)を1つまたは複数のプログラミング可能なプロセッサが実行することによって実行され得る。また、プロセスおよび論理フローは、専用の論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)によって実行される可能性があり、さらに、装置は、それらの専用の論理回路として実装される可能性がある。コンピュータプログラム命令およびデータを記憶するのに適したデバイスは、例として、半導体メモリデバイス、たとえば、EPROM、EEPROM、およびフラッシュメモリデバイス、磁気ディスク、たとえば、内蔵ハードディスクまたはリムーバブルディスク、光磁気ディスク、ならびにCD-ROMディスクおよびDVD-ROMディスクを含む、すべての形態の不揮発性メモリ、媒体、およびメモリデバイスを含む。プロセッサおよびメモリは、専用の論理回路によって補完されるか、または専用の論理回路に組み込まれ得る。 The processes and logical flows described herein involve one or more computer programs (eg, components of data processing system 102) to perform operations on input data and perform actions by producing output. It can be done by running by one or more programmable processors. In addition, processes and logic flows can be executed by dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits), and the devices have their own logic. It may be implemented as a circuit. Suitable devices for storing computer program instructions and data include, for example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices, magnetic disks such as internal hard disks or removable disks, magneto-optical disks, and CDs. -Includes all forms of non-volatile memory, media, and memory devices, including ROM disks and DVD-ROM disks. Processors and memory can be complemented by dedicated logic or incorporated into dedicated logic.
本明細書に記載の対象は、バックエンドコンポーネントを、たとえば、データサーバとして含むか、またはミドルウェアコンポーネント、たとえば、アプリケーションサーバを含むか、またはフロントエンドコンポーネント、たとえば、ユーザが本明細書に記載の対象の実装とインタラクションすることができるグラフィカルユーザインターフェースもしくはウェブブラウザを有するクライアントコンピュータを含むか、または1つもしくは複数のそのようなバックエンドコンポーネント、ミドルウェアコンポーネント、もしくはフロントエンドコンポーネントの組合せを含むコンピューティングシステムに実装され得る。システムのコンポーネントは、任意の形態または媒体のデジタルデータ通信、たとえば、通信ネットワークによって相互に接続され得る。通信ネットワークの例は、ローカルエリアネットワーク(「LAN」)およびワイドエリアネットワーク(「WAN」)、インターネットワーク(たとえば、インターネット)、ならびにピアツーピアネットワーク(たとえば、アドホックピアツーピアネットワーク)を含む。 The subject matter described herein includes a back-end component, eg, as a data server, or a middleware component, eg, an application server, or a front-end component, eg, a user described herein. In a computing system that includes a client computer with a graphical user interface or web browser that can interact with the implementation of, or a combination of one or more such back-end, middleware, or front-end components. Can be implemented. The components of the system can be interconnected by any form or medium of digital data communication, such as a communication network. Examples of communication networks include local area networks (“LAN”) and wide area networks (“WAN”), internetworks (eg, the Internet), and peer-to-peer networks (eg, ad hoc peer-to-peer networks).
システム100またはシステム600などのコンピューティングシステムは、クライアントおよびサーバを含み得る。クライアントおよびサーバは、概して互いに離れており、通常は通信ネットワーク(たとえば、ネットワーク105)を通じてインタラクションする。クライアントとサーバとの関係は、それぞれのコンピュータ上で実行されており、互いにクライアント-サーバの関係にあるコンピュータプログラムによって生じる。一部の実装において、サーバは、(たとえば、クライアントデバイスとインタラクションするユーザに対してデータを表示し、そのようなユーザからユーザ入力を受け取る目的で)クライアントデバイスにデータ(たとえば、デジタルコンポーネントを表すデータパケット)を送信する。クライアントデバイスにおいて生成されたデータ(たとえば、ユーザインタラクションの結果)は、サーバにおいてクライアントデバイスから受信され得る(たとえば、ローカルコンピューティングデバイス104またはコンテンツプロバイダコンピューティングデバイス106または第三者デバイス146からデータ処理システム102によって受信され得る)。
A computing system, such as
動作が特定の順序で図面に示されているが、そのような動作は、示された特定の順序でまたは逐次的順序で実行される必要があるわけではなく、すべての示された動作が、実行される必要があるわけではない。本明細書に記載のアクションは、異なる順序で実行され得る。 Although the actions are shown in the drawings in a particular order, such actions do not have to be performed in the particular order shown or in a sequential order, and all the shown actions, It doesn't have to be done. The actions described herein can be performed in a different order.
様々なシステムコンポーネントの分割は、すべての実装において分割を必要とするわけではなく、説明されたプログラムコンポーネントは、単一のハードウェアまたはソフトウェア製品に含まれる可能性がある。たとえば、NLPコンポーネント112またはコンテンツセレクタコンポーネント118は、単一のコンポーネント、アプリ、もしくはプログラム、または1つもしくは複数の処理回路を有する論理デバイス、またはデータ処理システム102の1つもしくは複数のサーバの一部である可能性がある。
Separation of various system components does not require division in all implementations, and the program components described may be contained in a single hardware or software product. For example, NLP component 112 or content selector component 118 may be a single component, app, or program, or a logical device with one or more processing circuits, or part of one or more servers in
ここにいくつかの例示的な実装を説明したが、以上は例示的であり、限定的でなく、例として提示されたことは明らかである。特に、本明細書において提示された例の多くは方法の行為またはシステムの要素の特定の組合せを含むが、それらの行為およびそれらの要素は、同じ目的を達成するためにその他の方法で組み合わされる可能性がある。1つの実装に関連して検討された行為、要素、および特徴は、その他の実装または実装の同様の役割から除外されるように意図されていない。 Although some exemplary implementations have been described here, it is clear that the above are exemplary, not limiting, and presented as examples. In particular, many of the examples presented herein include specific combinations of method actions or elements of the system, but those actions and those elements are combined in other ways to achieve the same purpose. there is a possibility. Actions, elements, and features considered in connection with one implementation are not intended to be excluded from other implementations or similar roles in implementations.
本明細書において使用された語法および術語は、説明を目的としており、限定と見なされるべきでない。本明細書における「〜を含む(including)」、「〜を含む(comprising)」、「〜を有する」、「〜を含む(containing)」、「〜を含む(involving)」、「〜によって特徴付けられる(characterized by)」、「〜ことを特徴とする(characterized in that)」、およびこれらの変化形の使用は、その後に列挙された項目、それらの項目の均等物、および追加的な項目、ならびにその後に列挙された項目だけからなる代替的な実装を包含するように意図される。1つの実装において、本明細書に記載のシステムおよび方法は、説明された要素、行為、またはコンポーネントのうちの1つ、2つ以上のそれぞれの組合せ、またはすべてからなる。 The terminology and terminology used herein are for illustration purposes only and should not be considered limiting. Characterized by "including", "comprising", "having", "containing", "involving", "involving" in the present specification. "Characted by", "characterized in that", and the use of these variants are the items listed thereafter, their equivalents, and additional items. , As well as an alternative implementation consisting only of the items listed after it. In one implementation, the systems and methods described herein consist of one, a combination of two or more, or all of the elements, actions, or components described.
本明細書において単数形で言及されたシステムおよび方法の実装または要素または行為へのすべての言及は、複数のこれらの要素を含む実装も包含する可能性があり、本明細書における任意の実装または要素または行為への複数形のすべての言及は、単一の要素のみを含む実装も包含する可能性がある。単数形または複数形の言及は、ここに開示されたシステムもしくは方法、それらのコンポーネント、行為、または要素を単一のまたは複数の構成に限定するように意図されていない。任意の情報、行為、または要素に基づいている任意の行為または要素への言及は、行為または要素が任意の情報、行為、または要素に少なくとも部分的に基づく実装を含み得る。 All references to implementations or elements or actions of systems and methods referred to in the singular herein may also include implementations that include more than one of these elements, and any implementation or element or action herein. All references to elements or actions in the plural may also include implementations containing only a single element. References to the singular or plural are not intended to limit the systems or methods disclosed herein, their components, actions, or elements to a single or plural configuration. References to any action or element that is based on any information, action, or element may include an implementation in which the action or element is at least partially based on any information, action, or element.
本明細書において開示された任意の実装は、任意のその他の実装または実施形態と組み合わされる可能性があり、「実装」、「いくつかの実装」、「1つの実装」などの言及は、必ずしも相互排他的ではなく、実装に関連して説明された特定の特徴、構造、または特色が少なくとも1つの実装または実施形態に含まれる可能性があることを示すように意図される。本明細書において使用されるそのような用語は、必ずしもすべてが同じ実装に言及していない。任意の実装は、本明細書において開示された態様および実装に合致する任意の方法で包括的または排他的に任意のその他の実装と組み合わされる可能性がある。 Any implementation disclosed herein may be combined with any other implementation or embodiment, and references such as "implementation," "some implementations," "one implementation," are not necessarily referred to. It is not mutually exclusive and is intended to indicate that a particular feature, structure, or feature described in relation to an implementation may be included in at least one implementation or embodiment. Such terms as used herein do not necessarily all refer to the same implementation. Any implementation may be combined with any other implementation in a comprehensive or exclusive manner in any manner consistent with the embodiments and implementations disclosed herein.
「または(or)」との言及は、「または(or)」を使用して記載された任意の項が、記載された項のうちの1つ、2つ以上、およびすべてのいずれかを示す可能性があるように包括的であると見なされ得る。たとえば、「『A』および『B』のうちの少なくとも一方」との言及は、「A」のみ、「B」のみ、および「A」と「B」との両方を含み得る。「〜を含む」またはその他の非限定的用語(open terminology)と関連して使用されるそのような言及は、追加的な項を含み得る。 Reference to "or (or)" indicates that any term described using "or (or)" refers to one, two or more, or all of the described terms. It can be considered as inclusive as it may be. For example, the reference to "at least one of'A'and'B'" can include only "A", only "B", and both "A" and "B". Such references used in connection with "including" or other open terminology may include additional terms.
図面、詳細な説明、または任意の請求項の技術的な特徴が後に参照符号を付されている場合、参照符号は、図面、詳細な説明、および請求項を理解し易くするために含められたものである。したがって、参照符号があることもないことも、いかなる請求項の要素の範囲に対してのいかなる限定的な効果も持たない。 Where a drawing, detailed description, or technical feature of any claim is followed by a reference code, the reference code is included to make the drawing, detailed description, and claim easier to understand. It is a thing. Therefore, it has no reference code and has no limiting effect on the scope of any claim element.
本明細書に記載のシステムおよび方法は、それらの特徴を逸脱することなくその他の特定の形態で具現化される可能性がある。上述の実装は、説明されたシステムおよび方法の限定ではなく、例示的である。したがって、本明細書に記載のシステムおよび方法の範囲は、上述の説明ではなく添付の請求項によって示され、請求項の均等の意味および範囲内に入る変更は、それに包含される。 The systems and methods described herein may be embodied in other particular forms without departing from their characteristics. The implementations described above are not limited to the systems and methods described, but are exemplary. Accordingly, the scope of the systems and methods described herein is set forth in the appended claims rather than in the description above, and any modifications that fall within the equal meaning and scope of the claims are included therein.
100 システム
102 データ処理システム
104 ローカルコンピューティングデバイス
105 ネットワーク
106 コンテンツプロバイダコンピューティングデバイス、コンテンツプロバイダ
108 サービスプロバイダコンピューティングデバイス、サービスプロバイダ
110 インターフェース
112 自然言語プロセッサコンポーネント
114 スタック作成エンジンコンポーネント
116 ダイレクトアクションAPI
118 コンテンツセレクタコンポーネント
120 話者認識コンポーネント
122 テンプレートリポジトリ
124 データリポジトリ
126 パラメータ
128 ポリシー
130 コンテンツデータ
132 シグネチャおよびアカウント
134 センサ
136 トランスデューサ
138 オーディオドライバ
140 プリプロセッサ
142 プロファイルスタック
144 モバイルコンピューティングデバイス
146 第三者デバイス、第三者
148 光源
200 環境
202 安全な公共の場所
204 インターネットに接続された電気通信デバイス
206 インターネットに接続されたサーモスタット
208 インターネットに接続されたランプ
210 インターネットに接続されたスピーカ
212 インターネットに接続されたマルチメディアディスプレイ
214 ワイヤレスゲートウェイ
300 環境
302 安全でない公共の場所
304 安全な公共の場所の外
306 命令
400 環境
402 安全な私的な場所
500 方法
600 システム
605 バス
610 プロセッサ
615 メインメモリ
620 ROM
625 ストレージデバイス
630 入力デバイス
635 ディスプレイ
100 systems
102 Data processing system
104 Local computing device
105 network
106 Content Providers Computing Devices, Content Providers
108 Service Providers Computing Devices, Service Providers
110 interface
112 Natural language processor component
114 Stack Creation Engine Component
116 Direct Action API
118 Content Selector Component
120 Speaker recognition component
122 template repository
124 Data repository
126 parameters
128 policy
130 content data
132 Signatures and Accounts
134 sensor
136 Transducer
138 Audio driver
140 preprocessor
142 profile stack
144 Mobile Computing Devices
146 Third party device, third party
148 Light source
200 environment
202 Safe public place
204 Telecommunications devices connected to the Internet
206 Thermostat connected to the internet
208 Lamps connected to the internet
210 Speakers connected to the internet
212 Multimedia display connected to the Internet
214 Wireless gateway
300 environment
302 Unsafe public places
304 Outside a safe public place
306 instructions
400 environment
402 Safe and private place
500 ways
600 system
605 bus
610 processor
615 Main memory
620 ROM
625 storage device
630 input device
635 display
Claims (20)
自然言語プロセッサコンポーネント、インターフェース、話者認識コンポーネント、およびダイレクトアクションアプリケーションプログラミングインターフェースを実行するための1つまたは複数のプロセッサおよびメモリを含むデータ処理システムを含み、前記データ処理システムが、
ローカルコンピューティングデバイスのセンサによって検出された入力オーディオ信号を含むデータパケットを前記インターフェースを介して受信することと、
前記入力オーディオ信号から音響シグネチャを特定することと、
データリポジトリ内でのルックアップに基づいて前記音響シグネチャに対応する電子アカウントを特定することと、
前記電子アカウントを特定したことに応答して、セッションおよび前記セッションにおいて使用するためのプロファイルスタックデータ構造を確立することであって、前記プロファイルスタックデータ構造が、第三者エンティティのデバイスによって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含む、確立することと、
前記電子アカウントから取り出された第2のプロファイルレイヤを、前記セッションのために確立された前記プロファイルスタックデータ構造にプッシュすることと、
要求および前記要求に対応するトリガキーワードを特定するために前記入力オーディオ信号をパースすることと、
前記プロファイルスタックデータ構造の前記第1のプロファイルレイヤに適合する前記要求に応答する第1のアクションデータ構造を、前記トリガキーワードと前記プロファイルスタックデータ構造にプッシュされた前記第2のプロファイルレイヤとに基づいて生成することと、
実行するために前記第1のアクションデータ構造を提供することと、
トリガイベントを検出したことに応答して、前記プロファイルスタックデータ構造を分解して、前記プロファイルスタックデータ構造から前記第1のプロファイルレイヤまたは前記第2のプロファイルレイヤのうちの一方を取り除くこととを行うためのものである、システム。 A system for processing stack-type data structures,
A data processing system that includes a natural language processor component, an interface, a speaker recognition component, and a data processing system that includes one or more processors and memory for performing direct action application programming interfaces.
Receiving a data packet containing an input audio signal detected by a sensor of a local computing device through the interface, and
Identifying the acoustic signature from the input audio signal and
Identifying the electronic account corresponding to the acoustic signature based on the lookup in the data repository,
In response to identifying the electronic account, establishing a session and a profile stack data structure for use in the session, wherein the profile stack data structure was configured by a device of a third party entity. Establishing, including a first profile layer with one or more policies,
Pushing a second profile layer retrieved from the electronic account onto the profile stack data structure established for the session.
Parsing the input audio signal to identify the request and the trigger keyword corresponding to the request.
A first action data structure in response to the request that conforms to the first profile layer of the profile stack data structure is based on the trigger keyword and the second profile layer pushed into the profile stack data structure. To generate
To provide the first action data structure to perform,
In response to the detection of the trigger event, the profile stack data structure is decomposed to remove one of the first profile layer and the second profile layer from the profile stack data structure. The system, which is for.
前記ないと判定したことに応答して前記データリポジトリ内に前記電子アカウントを作成することと、
前記電子アカウントを前記音響シグネチャにマッピングすることとを行うための前記データ処理システムを含む、請求項1に記載のシステム。 Determining that there is no electronic account corresponding to the acoustic signature based on the lookup.
Creating the electronic account in the data repository in response to the determination that it is not the case,
The system of claim 1, comprising said data processing system for mapping the electronic account to the acoustic signature.
前記第1のアクションデータ構造を前記第1のプロファイルレイヤの前記1つまたは複数のポリシーと比較することと、
前記第1のプロファイルレイヤの前記1つまたは複数のポリシーとの前記第1のアクションデータ構造の比較に基づいて、前記第1のアクションデータ構造が前記第1のプロファイルレイヤに適合していると判定することと、
前記第1のプロファイルレイヤに適合していると判定された前記第1のアクションデータ構造に応答して、実行するために前記第1のアクションデータ構造を提供することとを行うための前記データ処理システムを含む、請求項1に記載のシステム。 Generating the first action data structure in response to the request based on the trigger keyword and the second profile layer pushed into the profile stack data structure.
Comparing the first action data structure with the one or more policies of the first profile layer.
Based on the comparison of the first action data structure with the one or more policies of the first profile layer, it is determined that the first action data structure conforms to the first profile layer. To do and
The data processing for providing the first action data structure for execution in response to the first action data structure determined to conform to the first profile layer. The system of claim 1, including the system.
前記第1のアクションデータ構造が前記第1のプロファイルレイヤに適合すると判定するために、前記第1のアクションデータ構造の種類を前記第1のプロファイルレイヤの前記1つまたは複数のポリシーによって示されたアクションデータ構造の前記種類と比較することを行うための前記データ処理システムを含む、請求項5に記載のシステム。 The system comprises a policy for blocking certain types of action data structures, said one or more of the policies of the first profile layer.
The type of the first action data structure is indicated by the one or more policies of the first profile layer in order to determine that the first action data structure is compatible with the first profile layer. The system of claim 5, comprising said data processing system for performing comparisons with said types of action data structures.
前記自然言語プロセッサコンポーネントによって特定された前記トリガキーワード、および前記プロファイルスタックデータ構造を受信することと、
前記トリガキーワードおよび前記プロファイルスタックデータ構造に基づいて、前記第1のプロファイルレイヤと前記第2のプロファイルレイヤとの両方に適合しているデジタルコンポーネントを選択することとを行うためのコンテンツセレクタコンポーネントを含む、請求項1に記載のシステム。 The data processing system includes a policy for blocking certain types of content.
Receiving the trigger keyword identified by the natural language processor component and the profile stack data structure.
Includes a content selector component for selecting digital components that match both the first profile layer and the second profile layer based on the trigger keyword and the profile stack data structure. , The system according to claim 1.
前記第2の入力オーディオ信号から第2の音響シグネチャを特定することであって、前記第2の音響シグネチャが、前記音響シグネチャと異なる、特定することと、
前記音響シグネチャと異なる前記第2の音響シグネチャの特定に基づいて前記トリガイベントを判定することとを行うための前記データ処理システムを含む、請求項1に記載のシステム。 Receiving a second data packet including a second input audio signal detected by the sensor of the local computing device via the interface, wherein the second input audio signal is the input audio. Detected after the signal, receiving and
Identifying a second acoustic signature from the second input audio signal, wherein the second acoustic signature is different from the acoustic signature.
The system according to claim 1, further comprising the data processing system for determining the trigger event based on the identification of the second acoustic signature that is different from the acoustic signature.
ローカルコンピューティングデバイスのセンサによって検出された入力オーディオ信号を含むデータパケットを、1つまたは複数のプロセッサを含むデータ処理システムのインターフェースを介して受信するステップと、
前記データ処理システムによって、前記入力オーディオ信号から音響シグネチャを特定するステップと、
前記データ処理システムによって、データリポジトリ内でのルックアップに基づいて前記音響シグネチャに対応する電子アカウントを特定するステップと、
前記データ処理システムによって、前記電子アカウントを特定したことに応答して、セッションおよび前記セッションにおいて使用するためのプロファイルスタックデータ構造を確立するステップであって、前記プロファイルスタックデータ構造が、第三者エンティティのデバイスによって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含む、確立するステップと、
前記データ処理システムによって、前記電子アカウントから取り出された第2のプロファイルレイヤを、前記セッションのために確立された前記プロファイルスタックデータ構造にプッシュするステップと、
前記データ処理システムによって、要求および前記要求に対応するトリガキーワードを特定するために前記入力オーディオ信号をパースするステップと、
前記データ処理システムによって、前記プロファイルスタックデータ構造の前記第1のプロファイルレイヤに適合する前記要求に応答する第1のアクションデータ構造を、前記トリガキーワードと前記プロファイルスタックデータ構造にプッシュされた前記第2のプロファイルレイヤとに基づいて生成するステップと、
前記データ処理システムによって、実行するために前記第1のアクションデータ構造を提供するステップと、
前記データ処理システムによって、トリガイベントを検出したことに応答して、前記プロファイルスタックデータ構造を分解して、前記プロファイルスタックデータ構造から前記第1のプロファイルレイヤまたは前記第2のプロファイルレイヤのうちの一方を取り除くステップとを含む、方法。 A way to handle stack-style data structures
A step of receiving a data packet containing an input audio signal detected by a sensor of a local computing device through an interface of a data processing system containing one or more processors.
A step of identifying an acoustic signature from the input audio signal by the data processing system.
A step of identifying an electronic account corresponding to the acoustic signature by the data processing system based on a lookup in the data repository.
A step of establishing a session and a profile stack data structure for use in the session in response to the identification of the electronic account by the data processing system, wherein the profile stack data structure is a third party entity. Steps to establish, including a first profile layer with one or more policies configured by the device
A step of pushing a second profile layer retrieved from the electronic account by the data processing system onto the profile stack data structure established for the session.
A step of parsing the input audio signal by the data processing system to identify the request and the trigger keyword corresponding to the request.
The second action data structure pushed by the data processing system into the trigger keyword and the profile stack data structure in response to the request conforming to the first profile layer of the profile stack data structure. Steps to generate based on the profile layer of
The step of providing the first action data structure for execution by the data processing system, and
In response to the detection of the trigger event by the data processing system, the profile stack data structure is decomposed from the profile stack data structure to one of the first profile layer and the second profile layer. How to get rid of, including steps.
ないと判定したことに応答して前記データリポジトリ内に前記電子アカウントを作成するステップと、
前記電子アカウントを前記音響シグネチャにマッピングするステップとを含む、請求項12に記載の方法。 Based on the lookup, the step of determining that there is no electronic account corresponding to the acoustic signature, and
The step of creating the electronic account in the data repository in response to the determination that there is no
12. The method of claim 12, comprising mapping the electronic account to the acoustic signature.
前記第1のアクションデータ構造を前記第1のプロファイルレイヤの前記1つまたは複数のポリシーと比較するステップと、
前記第1のプロファイルレイヤの前記1つまたは複数のポリシーとの前記第1のアクションデータ構造の比較に基づいて、前記第1のアクションデータ構造が前記第1のプロファイルレイヤに適合していると判定するステップと、
前記第1のプロファイルレイヤに適合していると判定された前記第1のアクションデータ構造に応答して、実行するために前記第1のアクションデータ構造を提供するステップとを含む、請求項12に記載の方法。 A step of generating the first action data structure in response to the request based on the trigger keyword and the second profile layer pushed into the profile stack data structure.
A step of comparing the first action data structure with the one or more policies of the first profile layer.
Based on the comparison of the first action data structure with the one or more policies of the first profile layer, it is determined that the first action data structure conforms to the first profile layer. Steps to do and
12. The first action data structure is determined to conform to the first profile layer, and the first action data structure is provided for execution in response to the first action data structure. The method described.
前記第1のアクションデータ構造が前記第1のプロファイルレイヤに適合すると判定するために、前記第1のアクションデータ構造の種類を前記第1のプロファイルレイヤの前記1つまたは複数のポリシーによって示されたアクションデータ構造の前記種類と比較するステップを含む、請求項14に記載の方法。 The method comprises a policy for blocking certain types of action data structures, said one or more of the policies of the first profile layer.
The type of the first action data structure is indicated by the one or more policies of the first profile layer in order to determine that the first action data structure is compatible with the first profile layer. 14. The method of claim 14, comprising a step of comparing to said type of action data structure.
自然言語プロセッサコンポーネントによって特定された前記トリガキーワード、および前記プロファイルスタックデータ構造を受信するステップと、
前記トリガキーワードおよび前記プロファイルスタックデータ構造に基づいて、前記第1のプロファイルレイヤと前記第2のプロファイルレイヤとの両方に適合しているデジタルコンポーネントを選択するステップとを含む、請求項12に記載の方法。 The method comprises a policy for blocking certain types of content.
The step of receiving the trigger keyword identified by the natural language processor component and the profile stack data structure, and
12. The step of selecting a digital component that conforms to both the first profile layer and the second profile layer based on the trigger keyword and the profile stack data structure. Method.
前記第2の入力オーディオ信号から第2の音響シグネチャを特定するステップであって、前記第2の音響シグネチャが、前記音響シグネチャと異なる、特定するステップと、
前記音響シグネチャと異なる前記第2の音響シグネチャの特定に基づいて前記トリガイベントを判定するステップとを含む、請求項12に記載の方法。 A step of receiving a second data packet including a second input audio signal detected by the sensor of the local computing device via the interface, wherein the second input audio signal is the input audio. The step to receive, which is detected after the signal,
A step of identifying a second acoustic signature from the second input audio signal, wherein the second acoustic signature is different from the acoustic signature.
12. The method of claim 12, comprising determining the trigger event based on the identification of the second acoustic signature that is different from the acoustic signature.
トランスデューサと、
入力オーディオ信号を検出するためのセンサと、
前記オーディオドライバ、前記トランスデューサ、および前記センサに結合されたプリプロセッサコンポーネントと
を含むデジタルアシスタントデバイスであって、前記プリプロセッサコンポーネントが、
フィルタリングされた入力オーディオ信号を生成するために前記入力オーディオ信号をフィルタリングすること、
前記フィルタリングされた入力オーディオ信号をデータパケットに変換すること、
自然言語プロセッサコンポーネント、インターフェース、話者認識コンポーネント、およびダイレクトアクションアプリケーションプログラミングインターフェースを実行する1つまたは複数のプロセッサおよびメモリを含むデータ処理システムに前記データパケットを送信することを行うためのものであり、前記データ処理システムが、
前記センサによって検出された前記フィルタリングされた入力オーディオ信号を含む前記データパケットを前記プリプロセッサコンポーネントから前記インターフェースを介して受信すること、
前記入力オーディオ信号から音響シグネチャを特定すること、
データリポジトリ内でのルックアップに基づいて前記音響シグネチャに対応する電子アカウントを特定すること、
前記電子アカウントを特定したことに応答して、セッションおよび前記セッションにおいて使用するためのプロファイルスタックデータ構造を確立することであって、前記プロファイルスタックデータ構造が、第三者エンティティのデバイスによって構成された1つまたは複数のポリシーを有する第1のプロファイルレイヤを含む、確立すること、
前記電子アカウントから取り出された第2のプロファイルレイヤを、前記セッションのために確立された前記プロファイルスタックデータ構造にプッシュすること、
要求および前記要求に対応するトリガキーワードを特定するために前記入力オーディオ信号をパースすること、
前記プロファイルスタックデータ構造の前記第1のプロファイルレイヤに適合する前記要求に応答する第1のアクションデータ構造を、前記トリガキーワードと前記プロファイルスタックデータ構造にプッシュされた前記第2のプロファイルレイヤとに基づいて生成すること、
実行するために前記第1のアクションデータ構造を提供すること、
トリガイベントを検出したことに応答して、前記プロファイルスタックデータ構造を分解して、前記プロファイルスタックデータ構造から前記第1のプロファイルレイヤまたは前記第2のプロファイルレイヤのうちの一方を取り除くこと、ならびに
前記プロファイルスタックデータ構造のステータスを前記プリプロセッサコンポーネントに提供することを行うためのものであり、
前記オーディオドライバが、前記プロファイルスタックデータ構造の前記ステータスの指示を受信し、前記指示に基づいて出力信号を生成するためのものであり、
前記トランスデューサが、前記オーディオドライバによって生成された前記出力信号に基づいて音を生成するためのものである、デバイス。 With an audio driver
Transducer and
A sensor for detecting the input audio signal and
A digital assistant device including the audio driver, the transducer, and a preprocessor component coupled to the sensor, wherein the preprocessor component is:
Filtering the input audio signal to generate a filtered input audio signal,
Converting the filtered input audio signal into a data packet,
It is intended to send said data packets to a data processing system that includes one or more processors and memory running a natural language processor component, an interface, a speaker recognition component, and a direct action application programming interface. The data processing system
Receiving the data packet containing the filtered input audio signal detected by the sensor from the preprocessor component via the interface.
Identifying the acoustic signature from the input audio signal,
Identifying the electronic account corresponding to the acoustic signature based on the lookup in the data repository,
In response to identifying the electronic account, establishing a session and a profile stack data structure for use in the session, wherein the profile stack data structure was configured by a device of a third party entity. Establishing, including a first profile layer with one or more policies,
Pushing a second profile layer retrieved from the electronic account onto the profile stack data structure established for the session.
Parsing the input audio signal to identify the request and the trigger keyword corresponding to the request,
A first action data structure in response to the request that conforms to the first profile layer of the profile stack data structure is based on the trigger keyword and the second profile layer pushed into the profile stack data structure. To generate
To provide the first action data structure to perform,
Decomposing the profile stack data structure in response to detecting a trigger event to remove one of the first profile layer or the second profile layer from the profile stack data structure, as well as said. It is intended to provide the status of the profile stack data structure to the preprocessor component.
The audio driver receives an instruction of the status of the profile stack data structure and generates an output signal based on the instruction.
A device in which the transducer is intended to generate sound based on the output signal generated by the audio driver.
前記光源に前記プロファイルスタックデータ構造の前記ステータスに対応する視覚的な指示を提供させるための前記プリプロセッサコンポーネントとを含む、請求項19に記載のデバイス。 Light source and
19. The device of claim 19, comprising said the preprocessor component for causing the light source to provide visual instructions corresponding to said status of the profile stack data structure.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
JP2020191600A JP6995966B2 (en) | 2020-11-18 | 2020-11-18 | Digital assistant processing of stacked data structures |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
JP2020191600A JP6995966B2 (en) | 2020-11-18 | 2020-11-18 | Digital assistant processing of stacked data structures |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2018526062A Division JP6797916B2 (en) | 2017-12-08 | 2017-12-08 | Digital assistant processing of stacked data structures |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2021061000A true JP2021061000A (en) | 2021-04-15 |
JP6995966B2 JP6995966B2 (en) | 2022-01-17 |
Family
ID=75380298
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2020191600A Active JP6995966B2 (en) | 2020-11-18 | 2020-11-18 | Digital assistant processing of stacked data structures |
Country Status (1)
Country | Link |
---|---|
JP (1) | JP6995966B2 (en) |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2005512208A (en) * | 2001-11-30 | 2005-04-28 | インターナショナル・ビジネス・マシーンズ・コーポレーション | Method and apparatus for distributing computer content |
JP2014531816A (en) * | 2011-09-16 | 2014-11-27 | クアルコム，インコーポレイテッド | Detecting that a mobile device is in the vehicle |
US20160162469A1 (en) * | 2014-10-23 | 2016-06-09 | Audience, Inc. | Dynamic Local ASR Vocabulary |
US20160170774A1 (en) * | 2014-12-16 | 2016-06-16 | International Business Machines Corporation | Mobile computing device reconfiguration in response to environmental factors |
US20170133012A1 (en) * | 2015-11-05 | 2017-05-11 | Acer Incorporated | Voice control method and voice control system |
US20170236512A1 (en) * | 2016-02-12 | 2017-08-17 | Amazon Technologies, Inc. | Processing spoken commands to control distributed audio outputs |
JP2017530567A (en) * | 2014-06-30 | 2017-10-12 | アップル インコーポレイテッド | Intelligent automatic assistant for TV user interaction |
-
2020
- 2020-11-18 JP JP2020191600A patent/JP6995966B2/en active Active
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2005512208A (en) * | 2001-11-30 | 2005-04-28 | インターナショナル・ビジネス・マシーンズ・コーポレーション | Method and apparatus for distributing computer content |
JP2014531816A (en) * | 2011-09-16 | 2014-11-27 | クアルコム，インコーポレイテッド | Detecting that a mobile device is in the vehicle |
JP2017530567A (en) * | 2014-06-30 | 2017-10-12 | アップル インコーポレイテッド | Intelligent automatic assistant for TV user interaction |
US20160162469A1 (en) * | 2014-10-23 | 2016-06-09 | Audience, Inc. | Dynamic Local ASR Vocabulary |
US20160170774A1 (en) * | 2014-12-16 | 2016-06-16 | International Business Machines Corporation | Mobile computing device reconfiguration in response to environmental factors |
US20170133012A1 (en) * | 2015-11-05 | 2017-05-11 | Acer Incorporated | Voice control method and voice control system |
US20170236512A1 (en) * | 2016-02-12 | 2017-08-17 | Amazon Technologies, Inc. | Processing spoken commands to control distributed audio outputs |
Also Published As
Publication number | Publication date |
---|---|
JP6995966B2 (en) | 2022-01-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6797916B2 (en) | Digital assistant processing of stacked data structures | |
US11508371B2 (en) | Digital assistant processing of stacked data structures | |
US11855988B2 (en) | Synchronizing access controls between computing devices | |
JP6968897B2 (en) | Establishing an audio-based network session with unregistered resources | |
JP2021506008A (en) | Decentralized identification in networked systems | |
JP6995966B2 (en) | Digital assistant processing of stacked data structures | |
JP2022009571A (en) | Establishment of audio-based network session with unregistered resource |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20201216 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20201216 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20211025 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20211115 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20211215 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6995966Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |