CN107071404B - Method and device for coding a sequence of images having a plurality of images - Google Patents
Method and device for coding a sequence of images having a plurality of images Download PDFInfo
- Publication number
- CN107071404B CN107071404B CN201610842086.1A CN201610842086A CN107071404B CN 107071404 B CN107071404 B CN 107071404B CN 201610842086 A CN201610842086 A CN 201610842086A CN 107071404 B CN107071404 B CN 107071404B
- Authority
- CN
- China
- Prior art keywords
- field
- current
- picture
- pictures
- fields
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
- 238000000034 method Methods 0.000 title claims abstract description 59
- 239000013598 vector Substances 0.000 claims description 114
- 230000002123 temporal effect Effects 0.000 claims description 81
- 238000004364 calculation method Methods 0.000 description 14
- 230000006835 compression Effects 0.000 description 11
- 238000007906 compression Methods 0.000 description 11
- 239000003550 marker Substances 0.000 description 3
- 230000003044 adaptive effect Effects 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 2
- 238000010276 construction Methods 0.000 description 2
- 238000001914 filtration Methods 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 230000009286 beneficial effect Effects 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/105—Selection of the reference unit for prediction within a chosen coding or prediction mode, e.g. adaptive choice of position and number of pixels used for prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/112—Selection of coding mode or of prediction mode according to a given display mode, e.g. for interlaced or progressive display mode
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/137—Motion inside a coding unit, e.g. average field, frame or block difference
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/573—Motion compensation with multiple frame prediction using two or more reference frames in a given prediction direction
Abstract
A method and system for encoding or decoding digital video content. Digital video content comprises a stream of pictures, each of which may be intra, predicted, or bi-predicted. Each picture contains macroblocks that can be further divided into smaller blocks. This method requires encoding and decoding each picture in the picture stream in frame mode or field mode.
Description
The present application is a divisional application of the chinese patent application No.02827402.4 entitled "method and apparatus for encoding an image sequence having a plurality of images" by the applicant's general instrument company, having an application date of 2002, 11/21/2002.
Technical Field
The present invention relates to encoding and decoding of digital video content. More particularly, the present invention relates to the encoding and decoding of digital video content at the picture level in frame mode and field mode as used in the MPEG-4Part10 AVC/h.264 video coding standard.
Background
Video compression is used in many current and emerging products. It is the core of digital television set-top boxes (STBs), Digital Satellite Systems (DSS), High Definition Television (HDTV) decoders, Digital Versatile Disc (DVD) players, video conferencing, internet video and multimedia content, and other digital video applications. Without video compression, the digital video content can be extremely bulky, making it difficult, if not impossible, to efficiently store, transmit, or view the digital video content.
Digital video content comprises a stream of images that can be displayed as a picture on a television receiver, computer monitor, or some other electronic device capable of displaying digital video content. An image that is displayed temporally before a particular image is in a "forward direction" with respect to the particular image. Similarly, an image that is displayed temporally after a particular image is in a "backward direction" with respect to the particular image.
Video compression is done in a video encoding process in which each picture is encoded either in frames or in two fields. Each frame contains multiple lines of spatial information. For example, a typical frame contains 480 horizontal lines. Each field contains half the number of lines in the frame. For example, if a frame contains 480 horizontal lines, each field contains 240 horizontal lines. In a typical configuration, one field contains the odd-numbered lines in the frame and the other field contains the even-numbered lines in the frame. Hereinafter and in the appended claims, unless otherwise specifically indicated, a field containing odd-numbered lines will be referred to as a "top" (top) field. Also, hereinafter and in the appended claims, unless otherwise specifically indicated, a field containing even-numbered lines will be referred to as a "bottom" field. The two fields may be interlaced together to form an interlaced frame.
The general idea behind video coding is to remove "unnecessary" content from digital video content. The reduced amount of data then requires less bandwidth for broadcasting or transmission. After the compressed video data is transmitted, it must be decoded, or decompressed. In this process, the transmitted video data is processed to generate approximate data substituted into the video data for replacing "unnecessary" data that was removed in the encoding process.
Video coding transforms digital video content into a compressed form that can be stored in less space and transmitted with less bandwidth than uncompressed digital video content. This is done to exploit temporal and spatial redundancies in the pictures of the video content. The digital video content may be stored in a storage medium such as a hard drive, a DVD, or some other non-volatile storage unit.
There are many video encoding methods that compress digital video content. Accordingly, video coding standards have been developed to standardize various video coding methods so that compressed digital video content is provided in a format recognizable by most video encoders and decoders. For example, the Motion Picture Experts Group (MPEG) and the International telecommunication Union (ITU-T) have developed video coding standards that are in widespread use. Examples of such standards include the MPEG-1, MPEG-2, MPEG-4, ITU-T H261, and ITU-T H263 standards.
Most modern video coding standards, such as those developed by MPEG and ITU-T, are based in part on a temporal prediction with Motion Compensation (MC) algorithms. Temporal prediction with motion compensation is used to remove temporal redundancy between successive pictures in digital video broadcasting.
Temporal prediction with motion compensation algorithms typically encodes a particular picture using one or two reference pictures. The reference picture is a picture that has already been encoded. By comparing a particular picture to be encoded with one of the reference pictures, temporal prediction with a motion compensation algorithm can utilize the temporal redundancy that exists between the reference picture and the particular picture to be encoded and encode the picture with a higher amount of compression than when the picture is encoded without using temporal prediction with a motion compensation algorithm. One of the reference images may be located in a backward direction with respect to the particular image to be encoded. The other reference image is located in a forward direction with respect to the particular image to be encoded.
However, as the demand for higher resolution, more complex image content, and faster transmission speed increases, the demand for better video encoding methods also increases. For this reason, a new video coding standard is currently being developed. This new video coding standard is called the MPEG-4Part10 AVC/H.264 standard.
The new MPEG-4Part10 AVC/H.264 standard requires many new video compression methods. For example, one of the features of the new MPEG-4Part10 AVC/H.264 standard, it allows for multiple reference pictures, rather than just two. The use of multiple reference pictures allows the encoder to find the reference picture that most closely matches the picture to be encoded, thereby improving the performance of temporal prediction with motion compensation algorithms. By using a reference image that most closely matches the image to be encoded in the encoding process, it is possible to obtain the maximum amount of compression in the encoding of the image. The reference picture is stored in the frame buffer and/or the field buffer.
As described earlier, the encoder can encode one picture by one frame or by two fields. A greater degree of compression is possible if, in a sequence of pictures to be encoded, some pictures are encoded frame by frame and some are encoded field by field.
Summary of The Invention
In one of many possible embodiments, the present invention provides a method of encoding, decoding, and bitstream generation of digital video content. Digital video content comprises a stream of pictures, which may be intra (intra), predicted (predicted), or bi-predicted pictures, respectively. Each picture contains macroblocks that can be further divided into smaller blocks. The method requires that each picture in the picture stream is encoded and decoded either in frame mode or in field mode.
Brief Description of Drawings
The accompanying drawings illustrate various embodiments of the present invention and are a part of the specification. Together with the following description, the drawings demonstrate and explain the principles of the present invention. The illustrated embodiments are examples of the present invention and do not limit the scope of the invention.
FIG. 1 illustrates an exemplary sequence of three types of images defined by an exemplary video coding standard, such as the MPEG-4Part10 AVC/H.264 standard, that can be used to implement the present invention.
Fig. 2 shows that each picture is preferably divided into slices (slices) containing macroblocks, according to an embodiment of the present invention.
Fig. 3a shows that a macroblock can be further divided into block sizes of 16X8 pixels according to an embodiment of the present invention.
Fig. 3b shows that a macroblock can be further divided into block sizes of 8X16 pixels according to an embodiment of the present invention.
Fig. 3c shows that a macroblock may be further divided into block sizes of 8X8 pixels, according to an embodiment of the invention.
Fig. 3d shows that a macroblock may be further divided into block sizes of 8X4 pixels, according to an embodiment of the invention.
Fig. 3e shows that a macroblock can be further divided into block sizes of 4X8 pixels according to an embodiment of the present invention.
Fig. 3f shows that a macroblock can be further divided into block sizes of 4X4 pixels according to an embodiment of the present invention.
Fig. 4 shows an example of image construction using temporal prediction with motion compensation, which explains an embodiment of the present invention.
Fig. 5 shows an exemplary image stream explaining the advantages of using multiple reference images in temporal prediction with motion compensation, according to an embodiment of the present invention.
FIG. 6 illustrates the assignment of a unique reference frame number to each reference frame in the frame buffer based on the distance of each reference frame in the frame buffer from the current frame being encoded in frame mode, according to an embodiment of the present invention.
Fig. 7a shows an exemplary reference field numbering configuration in which the same reference fields having field parities as the current field are given smaller numbers than their corresponding second fields, in accordance with embodiments of the present invention.
Fig. 7b shows an exemplary reference field numbering configuration, where the current field is the second field of a picture to be coded in two fields.
Fig. 8 shows an alternative reference field numbering arrangement in a field buffer according to an embodiment of the invention.
Fig. 9 shows a method of direct mode vector calculation, where both the current macroblock and the co-located (co-located) macroblock are in frame mode.
Fig. 10 shows a method of direct mode vector calculation, where both the current macroblock and the macroblock co-located with it are in field mode.
Fig. 11 shows another method of direct mode vector calculation, where both the current macroblock and the macroblock co-located with it are in field mode.
Fig. 12 shows a method of direct mode vector calculation, where the current macroblock is in field mode and the co-located macroblock is in frame mode.
Fig. 13 shows a method of direct mode vector calculation, where the current macroblock is in frame mode and the co-located macroblock is in field mode.
Fig. 14 shows a B-picture with two reference pictures in the temporally forward direction according to an embodiment of the present invention.
Fig. 15 shows a B-image having two reference images in a temporally backward direction according to an embodiment of the present invention.
Fig. 16 shows a B picture having one forward reference picture in the forward direction in time and one backward reference picture in the backward direction in time.
In the drawings, like reference numerals designate similar, but not necessarily identical, elements.
Detailed description of embodiments of the invention
The present invention provides a method of adaptive frame/field (AFF) coding of digital video content comprising a stream of pictures at the picture level. In the AFF coding process at the picture level, each picture in the picture stream to be coded is coded either in frame mode or in field mode, regardless of the frame or field coding mode of the other pictures. If a picture is coded in a frame mode, two fields constituting an interlaced frame are coded in common. In contrast, if a picture is coded in a field mode, two fields constituting an interlaced frame are separately coded. The encoder determines which of frame mode encoding and field mode encoding is more beneficial for each picture and selects that encoding mode for that picture. The particular method of selecting between frame mode and field mode is not important to the invention and will not be described in detail here.
As described above, the MPEG-4Part10 AVC/H.264 standard is a new standard for encoding and compressing digital video content. The files that establish the MPEG-4Part10 AVC/H.264 standard, including "Joint Final Committee Draft (JFCD) of Joint Video Specification" (ITU-T Rec.H.264& ISO/IEC 14496-AVC 10), published by the Joint Video Team (JVT) (Joint Video Team) on 8/10.2002, are hereby incorporated by reference. The JVT consists of experts in ISO or MPEG and ITU-T. Due to the public nature of the MPEG-4Part10 AVC/H.264 standard, the present specification will not attempt to demonstrate all of the existing aspects of MPEG-4Part10 AVC/H.264 video coding, but will rely on the cited specifications of the standard.
Although this AFF encoding method is compatible with the MPEG-4Part10 AVC/H.264 standard guide, and will be explained with the latter, the method may be modified to best suit a standard or application.
Preferred embodiments of the present invention will now be explained using the drawings.
FIG. 1 illustrates an exemplary sequence of three types of images defined by an exemplary video coding standard, such as the MPEG-4Part10 AVC/H.264 standard, that can be used to implement the present invention. As mentioned earlier, the encoder encodes the image and the decoder decodes the image. The encoder or decoder may be a processor, an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), a CODEC, a Digital Signal Processor (DSP), or some other electronic device capable of encoding an image stream. However, hereinafter and in the appended claims, unless otherwise specified, the term "encoder" will be used to refer broadly to all electronic devices that encode digital video content comprising one image stream. Also, hereinafter and in the appended claims, unless otherwise specified, the term "decoder" will be used to refer broadly to all electronic devices that decode digital video content comprising one image stream.
As shown in fig. 1, there are preferably three types of images that can be used in the video coding method. Three categories of pictures are defined to support random access to stored digital video content while exploring maximum redundancy reduction with temporal prediction with motion compensation. These three types of images are: intra (I) pictures (100), predicted (P) pictures (102a, B), bi-predicted (B) pictures (101 a-d). The I-picture (100) provides an access point for random access to stored digital video content and can only be encoded with slight compression. The reference picture is not referred to when the intra picture (100) is encoded.
When encoding a predicted image (102a, B), an I, P or B image that has already been encoded is used as a reference image. The reference picture may be in a forward or backward temporal direction relative to the P picture being encoded. The predicted pictures (102a, b) can be encoded with more compression than the intra pictures (100).
When encoding a bi-predictive picture (101a-d), two temporal reference pictures are used: a forward reference picture and a backward reference picture. The forward reference picture is sometimes referred to as a past reference picture and the backward reference picture is sometimes referred to as a future reference picture. One embodiment of the present invention is that the forward reference picture and the backward reference picture may be located in the same temporal direction with respect to the B picture being encoded. Bi-predicted pictures (101a-d) can be coded with the greatest compression among the three picture types.
The reference relationship (103) between these three image types is shown in fig. 1. For example, a P picture (102a) can be encoded using the encoded I picture (100) as its reference picture. As shown in fig. 1, B pictures (101a-B) can be encoded with an encoded I picture (100) and/or an encoded P picture (102a) as their reference pictures. According to the principles of one embodiment of the present invention, the encoded B pictures (101a-d) can also be used as reference pictures for other B pictures to be encoded. For example, fig. 1 shows that the B-picture (101c) has two other B-pictures (101B and 101d) as its reference pictures.
The number and specific order of the I (100), B (101a-d), and P (102a, B) pictures shown in FIG. 1 are given as an exemplary picture configuration, but are not necessary to practice the invention. Any number of I, B and P-pictures in any order may be used as best suited for a particular application. The MPEG-4Part10 AVC/H.264 standard does not limit the number of B pictures between two reference pictures, nor the number of pictures between two I pictures.
Fig. 2 shows that each image is preferably divided into slices (202). A slice (202) contains a set of macroblocks (201). A macroblock is a rectangular group of pixels. As shown in fig. 2, one preferred macroblock (201) size is 16X16 pixels.
Figures 3a-f show that a macroblock can be further divided into smaller sized blocks. For example, as shown in fig. 3a-f, a macroblock can be further divided into block sizes as follows: 16X8 pixels (fig. 3 a; 300), 8X16 pixels (fig. 3 b; 301), 8X8 pixels (fig. 3 c; 302), 8X4 pixels (fig. 3 d; 303), 4X8 pixels (fig. 3 e; 304), or 4X4 pixels (fig. 3 f; 305).
Fig. 4 shows an example of image construction using temporal prediction with motion compensation, which explains an embodiment of the present invention. Temporal prediction with motion compensation assumes that a current image, image N (400), can be modeled locally as a translation of another image, image N-1 (401). The image N-1(401) is a reference image for encoding the image N (400), and may be located in a forward or backward time direction with respect to the image N (400).
As shown in fig. 4, each picture is preferably divided into slices containing macroblocks (201a, b). Image N-1(401) contains an image (403) to be displayed in image N (400). As shown in fig. 4, image (403) will be at a different temporal location (402) in image N (400) than it was in image N-1 (401). The image content of each macroblock (201a) of the image N (400) is predicted from the image content of each corresponding macroblock (201b) of the image N-1(401), in particular by estimating the amount of temporal motion of the image content of each macroblock (201b) of the image N-1(401) required for the image (403) to move to its new temporal position (402) in the image N (400). Actually encoded and transmitted, not the original image (402), but the difference (404) between the image (402) and its prediction (403).
For each image (402) in image N (400), the temporal prediction can often be represented by a motion vector representing the amount of temporal motion required by the image (403) to move to its new position (402) in image N (400). The motion vectors (406) used for temporal prediction with motion compensation need to be encoded and transmitted.
Fig. 4 shows that a picture (402) in picture N (400) can be represented by the difference (404) between the picture and its prediction and the associated motion vector (406). There may be different specific methods of encoding using motion vectors, which can be easily implemented by those skilled in the art, to be best suited for a particular application.
Fig. 5 shows an exemplary image stream explaining the advantages of using multiple reference images in temporal prediction with motion compensation, according to an embodiment of the present invention. The use of multiple reference pictures increases the likelihood that picture N (400) is encoded with the greatest possible compression. In this example, the images N-1(401), N-2(500), N-3(501) have been encoded. As shown in FIG. 5, one image (504) of images N-3(501) is more similar to image (402) of image N (400) than images N-2(500) and N-1(401), respectively (503,502). The use of multiple reference images allows image N (400) to be encoded with image N-3(501) as the reference image rather than image N-1 (401).
The AFF encoding at the picture level of one picture stream will now be explained in more detail. A frame of an interleaved sequence contains two fields, an upper field and a lower field, which are alternating and separated in time by one field period. The field period is half the frame period time. During picture-level AFF coding, the two fields of an interlaced frame can be coded together or separately. If jointly coded, frame mode coding is employed. Conversely, if the two fields are coded separately, field mode coding is employed.
Fixed frame/field coding, on the other hand, encodes all pictures of a picture stream in only one mode. The mode may be a frame mode or a field mode. Picture-level AFF coding is preferably fixed frame/field coding because it allows the encoder to select which of the frame mode and the field mode is to be used to encode each picture in the picture stream, depending on the content of the digital video material.
The frame mode encoding uses an already encoded image as a reference frame. The reference frame may be any encoded I, P or B frame. The reference frame is stored in a frame buffer that is part of the encoder. One embodiment of the present invention is to assign a unique reference frame number to each reference frame in the frame buffer based on the distance between each reference frame in the frame buffer and the current picture being encoded in frame mode, as shown in the exemplary configuration in fig. 6. For example, as shown in fig. 6, a current picture to be encoded in one frame (600) has a plurality of reference frames (0-5) in a frame buffer (601). Fig. 6 also shows fields (f1, f2) corresponding to the current frame (600) and the reference frames (0-5). F1 marked with a dotted line is the first field and f2 marked with a dotted line is the second field. The first field is the first field encoded in a two-field picture. Similarly, the second field is the second field encoded in a two-field picture. In one embodiment of the invention, the first field may be a top field or a bottom field. In another embodiment of the invention, the second field may also be a top field or a bottom field. Each frame is represented by a solid line. As shown in fig. 6, the reference frame 0 is the reference frame temporally closest to the current frame (600). The further a reference frame is temporally from a current frame (600), the greater its reference frame number.
According to the principles of one embodiment of the present invention, a B picture coded as one frame may have a plurality of forward and backward reference pictures. Wherein each of said forward and backward reference images is assigned a unique number.
In temporal prediction with motion compensation algorithms, sub-pixel interpolation (sub-pel interpolation) is performed on each pixel in an image that is coded in one frame. The reference image, which is encoded on a frame-by-frame basis, may also be padded by repeating pixels on the frame boundary. In temporal prediction with motion compensation algorithms, padding is sometimes appropriate. A loop filtering or de-blocking scheme may be applied to the frame blocks to solve the problem of discontinuity of pixel values at the edges of the adjacent blocks.
According to another embodiment of the present invention, a macroblock in a P picture can be skipped during AFF coding. If a macroblock is skipped, its data is not transmitted during the encoding of the picture. A skipped macroblock in a P picture is reconstructed by copying a co-located macroblock with motion compensation in an I or P reference picture that has been most recently encoded.
The field mode encoding uses an already encoded picture as a reference field. The reference field may be any coded I, P or B field. The reference field is stored in a field buffer that is part of the encoder. One embodiment of the invention assigns a unique reference field number to each reference field in the field buffer based on the distance of each reference field in the field buffer from the current picture being encoded as two fields. Fig. 7a and 7b show exemplary reference field numbering configurations in which the same reference field having a field parity less than that of the current field is given a smaller number than their corresponding second field, in accordance with embodiments of the present invention. If both fields are top fields or both are bottom fields, the two fields have the same field parity. In the example of fig. 7a and 7b, if the first field of the current picture to be encoded is a top field, the first field of each reference picture is also a top field. The second field is then the bottom field. The first fields may also both be bottom fields and the second fields may both be top fields.
As shown in fig. 7a, a current picture to be coded in field mode has a plurality of reference fields (0-10) in a field buffer (701). F1 marked with a dotted line is the first field and f2 marked with a dotted line is the second field. The frame corresponding to a field is also shown in fig. 7a and is indicated by a solid line. As shown in fig. 7a, if the first field of the picture to be encoded is the current frame (700), a number 0 is allocated to the first field of the first picture in the field buffer (701), while a number 1 is allocated to the second field of the first picture in the field buffer (701). The further in time a reference field is from the current field (700), the larger its reference field number. The first fields of each picture in the field buffer have a lower reference number than their corresponding second fields.
Fig. 7b shows an exemplary reference field numbering configuration, where the current field (702) is the second field of a picture to be coded in two fields. F1 marked with a dotted line is the first field and f2 marked with a dotted line is the second field. The first field of the current picture has already been encoded. As shown in fig. 7b, since the current field (702) is a second field, the second field of the first picture in the field buffer (701) is assigned the number 0. The first coded field of the current picture is assigned the number 1. The further in time a reference field is from the current field (702), the larger its reference field number. The second fields of the pictures in the field buffer have a lower reference number than their corresponding first fields.
Fig. 8 shows an alternative reference field numbering arrangement in a field buffer according to an embodiment of the invention. In this configuration, the field whose parity is the same as that of the current field is not treated specifically. For example, as shown in FIG. 8, the current field (800) is the first field. The most recently coded field of the most recently coded picture in the field buffer is given reference number 0. The further a reference field is temporally from the current field (800), the larger its reference field number, regardless of their field parity.
According to another embodiment of the present invention, if the encoder selects field coding for a particular P picture, the encoder can encode the second field with the first field encoded as a reference field. If the picture is a B picture, the first field being encoded may be used as one of two reference fields for encoding the second field.
For adaptive bi-prediction (ABP), two reference pictures may be encoded in field mode. In this case, the temporal distance used in calculating the scaled motion vector is in field intervals. In the ABP encoding process, the two reference frames are in the same direction.
In temporal prediction with motion compensation algorithms, sub-pixel interpolation is performed for each pixel in an image coded in field mode. Padding may also be applied to the reference picture coded by field by repeating pixels on the field boundaries. In temporal prediction with motion compensation algorithms, padding is sometimes appropriate. A loop filtering or de-blocking scheme may be applied to the field blocks to solve the problem of discontinuity of pixel values at the edges of neighboring blocks.
According to another embodiment of the present invention, a macroblock in a P picture can be skipped during AFF coding. If a macroblock is skipped, its data is not transmitted during the encoding of the picture. A skipped macroblock in a P picture is reconstructed by duplicating the co-located macroblock with motion compensation in the most recently coded I or P reference field of the same field parity. Another embodiment is to reconstruct the skipped macroblock in the P picture by duplicating the co-located macroblock in the most recently coded reference field whose field parity may be different.
Another embodiment of the invention is direct mode encoding of B pictures. In direct mode coding, the forward and backward motion vectors for macroblocks in a B picture are derived from the motion vectors used in the corresponding, or co-located, macroblocks of a backward reference picture. Macroblocks co-located in both pictures occupy the same geometric position in both pictures. The backward reference picture is sometimes referred to as a forward reference picture, although according to one embodiment of the invention, the backward reference picture does not necessarily temporally precede the current picture being encoded.
The direct coding mode is advantageous over other coding methods because, in inter mode coding, a macroblock can have up to 16 motion vectors and up to 4 reference frames. Inter mode coding encodes a macroblock using temporal prediction with motion compensation. The MPEG-4Part10 AVC/h.264 standard allows each of the 6 smaller block sizes of fig. 3a-f (16X8 pixels, 8X16 pixels, 8X8 pixels, 8X4 pixels, 4X8 pixels, 4X4 pixels) to have its own motion vector if a macroblock is encoded with inter-coding. The block size of 16X16 pixels may also have its own motion vector. The MPEG-4Part10 AVC/H.264 standard also allows block sizes of 16X16 pixels, 16X8 pixels, 8X16 pixels, 8X8 pixels to have their own reference frames. Thus, a macroblock can have up to 16 motion vectors and up to 4 reference frames. With so many potential motion vectors, it is advantageous to derive the motion vector of a macroblock to be encoded from the already calculated motion vectors of co-located macroblocks of the backward reference picture. In the direct mode encoding process, the forward motion vector and the backward motion vector of a macroblock to be encoded are calculated as scaled versions (scaled versions) of the forward motion vector of the co-located macroblock in the backward reference image.
In picture-level AFF coding, a B picture and its backward reference picture can each be coded in frame mode or in field mode. Thus, with respect to frame coding mode and field coding mode, there may be four different combinations for a pair of macroblocks in the B picture and its co-located one in the backward reference picture. In the first case, both the current macroblock and its co-located macroblock are frame mode. In the second case, both the current macroblock and its co-located macroblock are field mode. In a third scenario, the current macroblock is field mode and its co-located macroblock is frame mode. Finally, in a fourth scenario, the current macroblock is frame mode and its co-located macroblock is field mode. The method of direct mode motion vector calculation for the macroblock to be encoded is different in each of these four cases. The 4 methods of direct mode motion vector calculation for macroblocks in B pictures will be described in detail below.
A method of direct mode vector calculation in the first case will be explained with reference to fig. 9. As shown in fig. 9, a current B picture (900) is to be encoded in frame mode using a backward reference picture (901) and a forward reference picture (902) that have been encoded in frame mode as reference pictures. The frames in fig. 9 are indicated by vertical solid lines, and their corresponding fields f1 and f2 are indicated by vertical dashed lines. According to one embodiment of the invention, the backward reference picture (901) may be an I, P or B picture that has been encoded in frame mode. Similarly, the forward reference picture (902) may also be an encoded I, P or B picture.
As shown in fig. 9, there is one block (903) in the current B image (900), and there is a block (904) co-located with it in the backward reference image (901). The block (903) and the co-located block (904) have equal pixel dimensions. These dimensions may be 16X16 pixels, 16X8 pixels, 8X16 pixels, 8X8 pixels, 8X4 pixels, 4X8 pixels, or 4X4 pixels. According to one embodiment of the invention, an encoder derives two motion vectors for a block (903) in a current B picture (900) for use in temporal prediction with a motion compensation algorithm. One of the motion vectors MVFPointing to the forward reference picture (902). Another motion vector MVBPoints to the backward reference image (901). These two motion vectors are calculated according to the following formula:
MVF＝TRB·MV/TRD
MVB＝(TRB-TRD)·MV/TRD(formulae 1 and 2)
In equations 1 and 2, TRBIs the temporal distance between the current B picture (900) to be coded in frame mode and the forward reference picture (902), an approximation of the temporal distance, a distance proportional to the temporal distance, or an approximation proportional to the approximation of the temporal distance. TR (transmitter-receiver)DIs the temporal distance between the forward reference picture (902) and the backward reference picture (901) that have been encoded in frame mode, an approximation of the temporal distance, a distance proportional to the temporal distance, or an approximation proportional to the approximation of the temporal distance. A preferred method of calculating the temporal distance between the reference images will be explained below. The MV is a motion vector pointing to the forward reference picture (902) that has been calculated for the co-located block (904) in the backward reference picture (901).
A method of direct mode vector calculation in the second case will be described with reference to fig. 10 and 11. As shown in fig. 10 and 11, a current B picture (900) is to be coded in field mode using a backward reference picture (901) and a forward reference picture (902) that have been coded in field mode as reference pictures. The frames in fig. 10 and 11 are indicated by vertical solid lines and their corresponding fields f1 and f2 are indicated by vertical dashed lines. According to one embodiment of the invention, the backward reference picture (901) may be an I, P or B picture that has been encoded in field mode. Similarly, the forward reference picture (902) may also be an encoded I, P or B picture.
As shown in fig. 10, there is one block (905) in the first field of the current B picture (900). Its motion vector is the forward motion vector MV of the block (906) co-located with it from the backward reference image (901)1And (4) deriving. According to the embodiment shown in fig. 10, the co-located block (906) is located in a field with the same parity as the field in which the block (905) in the current B picture (900) is located. The block (905) and the co-located block (906) have equal pixel dimensions. These dimensions may be 16X16 pixels, 16X8 pixels, 8X16 pixels, 8X8 pixels, 8X4 pixels, 4X8 pixels, or 4X4 pixels.
According to one embodiment of the invention, an encoder derives two motion vectors for a block (905) in a current B picture (900) for use in temporal prediction with a motion compensation algorithm. One of the motion vectors MVF,1Pointing to MV1A field in a forward reference image (902) pointed at. Another motion vector MVB,1Points to the field of a co-located block (906) in the backward reference image (901). The two motion vectors are expressed as followsCalculating the formula:
MVF,i＝TRB,i·MVi/TRD,i
MVB,i＝(TRB,i-TRD,i)·MVi/TRD,i(formulae 3 and 4)
In equations 3 and 4, the subscript i is a field mark (index). The first field has field marks 1 and the second field has field marks 2. Thus, in the exemplary scenario of FIG. 10, the field flag is 1 because the first field is being encoded. MV (Medium Voltage) data baseiIs the forward motion vector of the co-located macroblock in field i of the backward reference image (901). TR (transmitter-receiver)B,iIs the ith field and MV of the current B frame (900)iThe distance in time between the pointed to reference fields, an approximation of the distance in time, a distance proportional to the distance in time, or an approximation proportional to the approximation of the distance in time. TR (transmitter-receiver)D,iIs the i field and MV of the backward reference image (901)iThe distance in time between the pointed to reference fields, an approximation of the distance in time, a distance proportional to the distance in time, or an approximation proportional to the approximation of the distance in time.
As shown in fig. 10, there is one block (907) in the second field of the current B picture (900). It has a co-located block (908) in the second field of the backward reference picture (901). If the forward motion vector of the co-located block (908) points to a previously encoded field in any image other than its own image, the calculation of the forward and backward motion vectors follows equations 3 and 4, except that the field label equals 2.
However, as shown in FIG. 11, the forward motion vector of the co-located block (908) in the second field of the backward reference image (901) may also point to the first field of the same backward reference image (901), in accordance with one embodiment of the present invention. FIG. 11 shows that the co-located block (908) has a forward motion vector MV pointing to the first field of the backward reference image (901)2. In this case, the two motion vectors of the current block (907) are calculated as follows:
MVF,2＝-TRB,2·MV2/TRD,2
MVB,2＝-(TRB,2+TRD,2)·MV2/TRD,2(equations 5 and 6)
In equations 5 and 6, TRB,2Is the 2 nd field and MV of the current B frame (900)2The distance in time between the pointed to reference fields, an approximation of the distance in time, a distance proportional to the distance in time, or an approximation proportional to the approximation of the distance in time. TR (transmitter-receiver)D,2Is the 2 nd field and MV of the backward reference picture (901)2The distance in time between the pointed to reference fields, an approximation of the distance in time, a distance proportional to the distance in time, or an approximation proportional to the approximation of the distance in time. As shown in fig. 11, in this case, both of the motion vectors point in the backward direction.
A method of direct mode vector calculation in the third case will be explained with reference to fig. 12. As shown in fig. 12, a current B picture (900) is to be encoded in field mode using a backward reference picture (901) that has been encoded in frame mode and a forward reference picture (902) as reference pictures. The frames in fig. 12 are indicated by vertical solid lines, and their corresponding fields f1 and f2 are indicated by vertical dashed lines. According to one embodiment of the invention, the backward reference picture (901) may be an I, P or B picture that has been encoded in frame mode. Similarly, the forward reference picture (902) may also be an encoded I, P or B picture.
As shown in fig. 12, there is one block (905) in the first field of the current B picture (900). According to the embodiment shown in fig. 12, the co-located blocks (904) are coded in frame mode. According to one embodiment of the invention, an encoder derives two motion vectors for a block (905) in a current B picture (900) for use in temporal prediction with a motion compensation algorithm. As shown in fig. 12, one of the motion vectors MVF,1Points to a field in the forward reference picture (902) having the same parity as the field parity of the current block (905). In the example of fig. 12, the current block (905) is located in the first field of the current B picture (900). Another motion vector MVB,1Points to a parity-like field in the backward reference picture (901). The two motion vectors areCalculated according to the following formula:
MVF,i＝TRB,i·MV/TRD
MVB,i＝(TRB,i-TRD)·MV/TRD(equations 7 and 8)
In equations 7 and 8, the MV is derived by dividing the frame-based forward motion vector of the co-located block (904) by 2 in the vertical direction. This compensates for the fact that the co-located block (904) is frame mode and the current block (905) is field mode. The subscript i is a field mark. The first field has field marks 1 and the second field has field marks 2. Thus, in the exemplary case of fig. 12, the field flag is 1 because the first field is being encoded. TR (transmitter-receiver)DIs the time distance between the i-th field of the backward reference picture (901) and the i-th field of the forward reference frame (902), an approximate value of the time distance, a distance proportional to the time distance, or an approximate value proportional to the approximate value of the time distance. TR (transmitter-receiver)B,iIs the temporal distance between the i-th field of the current B picture (900) and the i-th field of the reference frame of the co-located block (904) in the backward reference picture (901), an approximate value of the temporal distance, a distance proportional to the temporal distance, or an approximate value proportional to the approximate value of the temporal distance. The same formula is used to calculate the motion vector of the block (907) in the second field in the current B picture (900).
A method of direct mode vector calculation in the fourth case will be described with reference to fig. 13. As shown in fig. 13, a current B picture (900) is to be encoded in frame mode using a backward reference picture (901) that has been encoded in field mode and a forward reference picture (902) as reference pictures. The frames in fig. 13 are indicated by vertical solid lines, and their corresponding fields f1 and f2 are indicated by vertical dashed lines. According to one embodiment of the invention, the backward reference picture (901) may be an I, P or B picture that has been encoded in field mode. Similarly, the forward reference picture (902) may also be an encoded I, P or B picture.
As shown in fig. 13, the current B picture (900) to be coded on a frame basis has one block (903). Its motion vector is backward from it to the reference picture(901) Forward motion vector MV of the co-located block (906)1And (6) obtaining the result. According to one embodiment of the invention, an encoder derives two motion vectors for a block (903) in a current B picture (900) for use in temporal prediction with a motion compensation algorithm. These two motion vectors are calculated according to the following formula:
MVF＝TRB·MV1/TRD,1
MVB＝(TRB-TRD,1)·MV1/TRD,1(equations 9 and 10)
In equations 9 and 10, MV1Is derived by multiplying in the vertical direction the field-based motion vector of a co-located block (906) in the first field of the backward reference image (901). TR (transmitter-receiver)BIs the temporal distance between the current B picture (900) and the reference frame (902), an approximation of the temporal distance, a distance proportional to the temporal distance, or an approximation proportional to the approximation of the temporal distance, the forward motion vector of the co-located block (906) pointing to one of its fields. In FIG. 13, this motion vector is MV1。TRD,1Is the temporal distance between the first field of the backward reference image (901) and the field in the forward reference image (902) to which the forward motion vector of the co-located block (906) points, an approximation of the temporal distance, a distance proportional to the temporal distance, or an approximation proportional to the approximation of the temporal distance.
Another embodiment of the invention extends direct mode coding to P pictures. In picture-level AFF coding, a P-picture and its forward reference picture can be coded in frame mode or in field mode. Thus, with respect to frame coding mode and field coding mode, there may be four different combinations for a pair of macroblocks in the P picture and its co-located one in the forward reference picture. In the first case, both the current macroblock and its co-located macroblock are frame mode. In the second case, both the current macroblock and its co-located macroblock are field mode. In the third case, the current macroblock is field mode and its co-located macroblock is frame mode. Finally, in the fourth case, the current macroblock is frame mode and its co-located macroblock is field mode. A block in a P picture has only one motion vector, the forward motion vector. The method of direct mode motion vector calculation for the macroblock to be encoded is different in each of these four cases. The 4 methods of direct mode motion vector calculation for macroblocks in P pictures will be described in detail below.
In the first case, both the current P picture and its forward reference picture are coded in frame mode. The forward reference picture for a block of the current P picture uses the same picture as its co-located block in the forward reference picture. Forward motion vector MV of current blockFThe forward motion vector of the co-located block is the same.
In the second case, both the current P picture and its forward reference picture are coded in field mode. The motion vector in direct mode encoding of a block in a field of the current P picture is calculated from the forward motion vectors of co-located blocks in fields of the same parity in the forward reference picture. Forward motion vector MV of block of i-th field of current P-pictureF,iThe forward motion vector of its co-located block in the i-th field in the forward reference image is the same.
In the third case, the current P picture is in field mode and the backward reference picture is in frame mode. Since the co-located block of a block in one of the fields in the current P-picture is coded on a frame-by-frame basis, the forward motion vector of a block in one of the fields in the current P-picture is derived by dividing the co-located block's motion vector by 2 in the vertical direction.
In the fourth case, the current P picture is in frame mode and the forward reference picture is in field mode. The co-located blocks in the first field of the forward reference image are used to calculate the forward motion vectors of the blocks in the current P-image in frame mode. By doubling the field-based motion vector of the co-located block in the first field of the forward reference image in the vertical direction, the forward motion vector MV of a block in the current P-image in frame mode is derivedF。
Another embodiment of the invention is a multi-frame interpolated (multi-frame interpolated) prediction Mode (MFIP). MFIP is a common frame interpolation prediction architecture. As explained earlier, a B picture coded in frame mode or field mode has two reference pictures coded in frame mode or field mode. Both reference images may be forward reference images as shown in fig. 14. Fig. 14 shows a B picture (140) to be encoded having two reference pictures. One of the reference pictures is a forward reference picture (141) and the other is a backward reference picture (142). As shown in fig. 14, they are both in the same forward direction in time. The two reference images may also be in both the same temporally rearward direction, as shown in fig. 15. In fig. 15, the B picture (140) has a forward reference picture (141) and a backward reference picture (142) both in the backward direction in time. Fig. 16 shows another embodiment of the present invention. As shown in fig. 16, the B image (140) has one forward reference image (141) in a forward direction in time and one backward reference image (142) in a backward direction in time.
In MFIP, a prediction signal is a linear interpolation of the motion compensated signal. The prediction signal (pred) in MPIF for a B picture can be calculated as follows:
pred＝w1ref1+w2ref2+ d (formula 11)
In equation 11, the variable ref1And ref2Are two reference images. Variable w1And w2Is a weighting factor. The default value of the variable d is set to 0. The linear interpolation coefficient w can be determined explicitly for each macroblock1、w2And d. If ref is present1And ref2Both are forward reference images or both are backward reference images, the reference image ref1Is a reference image closer to the B image in terms of temporal distance. For a bi-directional reference picture, ref1And ref2Respectively a forward reference picture and a backward reference picture.
Two motion vectors of an MFIP macroblock are connected with each otherThis is encoded relatively. ref (r) ref2Motion vector MV of2By adding a compensation quantity DMV to ref using the following formula1Proportional motion vector MV1And generating:
in equation 12, the variable DMV is an incremental (δ) motion vector and is a compensation value. Variable TR1And TR2Respectively the current image and the nearest reference image ref1And the farthest reference image ref2A distance in time between, an approximation of the distance in time, a distance proportional to the distance in time, or an approximation proportional to the approximation of the distance in time.
In picture-level AFF, one B picture can be encoded by one B frame picture or by two B field pictures. The rule for processing MFIP in field mode, where the current B picture to be encoded is in field structure, is given below:
the prediction signal is generated using equation 11. However, ref1And ref2Are the fields marked by the reference field numbers ref _ idx _ fws and ref _ idx _ bwd. Field ref1And ref2Either the top or bottom field. Default weighting factor w1And w2Are (.5,.5,0) and (2, -1,0), respectively.
Generation of MVs using equation 122. Since both reference pictures are field structured, TR is determined from the temporal distance between the reference field and the current field1And TR2。
The code numbers (code numbers) of the reference field numbers ref _ idx _ fwd and ref _ idx _ bwd in the MFIP mode follow the known conventional convention for field pictures.
The temporal distance between pictures in AFF coding can be calculated with a variable, the Time Reference (TR), or by calculating the picture numbers and calculating their difference. One embodiment of the invention is that for image level AFF, TR is incremented by 1 per field and is bounded by a constant (e.g., 256) (wrap). TR is the field interval. Let n be the frame marker or frame number. The variable n is incremented by 1 every frame. If a frame with a frame marker n is coded in frame mode, the TR for this frame is 2 n. If a frame with a frame marker n is coded in field mode, the TR of the first field of this frame is 2n and the TR of the second field is 2n + 1.
The foregoing descriptions are only used to explain and describe embodiments of the present invention. The foregoing description is not intended to be exhaustive or to limit the invention to any precise form disclosed. Many modifications and variations are possible in light of the above teaching.
The above-described embodiments were chosen in order to explain the principles of the invention and some practical applications. The previous description is provided to enable others skilled in the art to utilize the invention in various embodiments and with various modifications as are suited to the particular use contemplated. The scope of the invention should be determined from the following claims.
Claims (30)
1. A method of encoding a sequence of pictures having a plurality of pictures, wherein at least one picture of the plurality of pictures is a current picture comprising a pair of current fields to be encoded as a bi-predictive encoded B-picture, wherein each current field of the current fields is divided into at least a plurality of macroblocks, comprising:
at the encoder:
selectively encoding at least one of the plurality of images in a frame encoding mode;
selectively encoding at least one picture of the plurality of pictures in a field coding mode; and
calculating a first motion vector and a second motion vector derived from two associated reference fields for each of said macroblocks,
wherein the second motion vector is calculated using a compensation value applied to the first motion vector.
2. The method of claim 1, wherein weighting is applied to the two associated reference fields.
3. The method of claim 1, wherein the second motion vector is calculated as follows:
wherein MV2 is the second motion vector, wherein MV1Is said first motion vector, where DMV is said compensation value, where TR is1And TR2Is the temporal distance between the current image and the two associated reference fields.
4. An apparatus for encoding a sequence of pictures having a plurality of pictures, wherein at least one picture of said plurality of pictures is a current picture comprising a pair of current fields to be encoded as a bi-predictive encoded B-picture, wherein each current field of said current fields is divided into at least a plurality of macroblocks, comprising:
selectively encoding at least one of the plurality of images in a frame encoding mode;
selectively encoding at least one picture of the plurality of pictures in a field coding mode; and
calculating a first motion vector and a second motion vector derived from two associated reference fields for each of said macroblocks,
wherein the second motion vector is calculated using a compensation value applied to the first motion vector.
5. The apparatus of claim 4, wherein weighting is applied to the two associated reference fields.
6. The apparatus of claim 4, wherein the second motion vector is calculated as follows:
wherein the MV2Is thatA second motion vector, wherein MV1Is said first motion vector, where DMV is said compensation value, where TR is1And TR2Is the temporal distance between the current image and the two associated reference fields.
7. A method of decoding a sequence of pictures from a bitstream having a plurality of coded pictures, wherein a coded current picture comprising a pair of current fields is coded as a bi-predictively coded B-picture, and wherein each current field of said current fields is divided into at least a plurality of macroblocks, comprising:
at a decoder:
decoding at least one picture of the plurality of coded pictures in a frame coding mode and decoding at least one picture of the plurality of coded pictures in a field coding mode; wherein the decoding step applies a first motion vector and a second motion vector derived from two associated reference fields for each of the macroblocks, wherein the second motion vector is calculated using a compensation value applied to the first motion vector; and
constructing the sequence of images using the plurality of decoded images.
8. The method of claim 7, wherein weighting is applied to the two associated reference fields.
9. The method of claim 7, wherein the second motion vector is calculated as follows:
wherein the MV2Is the second motion vector, wherein MV1Is said first motion vector, where DMV is said compensation value, where TR is1And TR2Is the temporal distance between the current image and the two associated reference fields.
10. The method of claim 9, wherein each of the temporal distances is an approximation of the temporal distance, a distance proportional to the temporal distance, or an approximation proportional to the approximation of the temporal distance between the current image and one of the two associated reference fields.
11. The method of claim 9, wherein the first and second light sources are selected from the group consisting of a red light source, a green light source, and a blue light source,
wherein each of the temporal distances is incremented by 1 per field in a field coding mode; and
wherein each of the temporal distances is incremented by 1 per frame for a variable n in a frame coding mode, where n is a frame number.
12. The method of claim 7, wherein each of the two associated reference fields is a top field or a bottom field.
13. An apparatus for decoding a sequence of pictures from a bitstream having a plurality of coded pictures, wherein a coded current picture comprising a pair of current fields is coded as a bi-predictive coded (B) picture, and wherein each current field in the current fields is divided into at least a plurality of macroblocks, comprising:
means for decoding at least one picture of the plurality of coded pictures in a frame coding mode and at least one picture of the plurality of coded pictures in a field coding mode; wherein the decoding step applies a first motion vector and a second motion vector derived from two associated reference fields for each of the macroblocks, wherein the second motion vector is calculated using a compensation value applied to the first motion vector; and
means for constructing the sequence of images using the plurality of decoded images.
14. The apparatus of claim 13, wherein weights are applied to the two associated reference fields.
15. The apparatus of claim 13, wherein the second motion vector is calculated as follows:
wherein the MV2Is the second motion vector, wherein MV1Is said first motion vector, where DMV is said compensation value, where TR is1And TR2Is the temporal distance between the current image and the two associated reference fields.
16. The apparatus of claim 15, wherein each of the temporal distances is an approximation of the temporal distance, a distance proportional to the temporal distance, or an approximation proportional to the approximation of the temporal distance between the current image and one of the two associated reference fields.
17. The apparatus as set forth in claim 15, wherein,
wherein each of the temporal distances is incremented by 1 per field in a field coding mode; and
wherein each of the temporal distances is incremented by 1 per frame for a variable n in a frame coding mode, where n is a frame number.
18. The apparatus of claim 13, wherein each of the two associated reference fields is a top field or a bottom field.
19. A computer readable medium having stored thereon a plurality of instructions, the plurality of instructions comprising instructions, which when executed by a processor, cause the processor to perform a method of encoding a sequence of pictures having a plurality of pictures, wherein at least one picture of the plurality of pictures is a current picture to be encoded as a predictive coded P-picture, the method comprising:
selectively encoding at least one of the plurality of pictures in a frame encoding mode;
selectively encoding at least one picture of the plurality of pictures in a field coding mode;
wherein if the current image is in frame encoding, dividing the current image into a plurality of macroblocks, wherein the macroblocks are divided into at least one block including at least one of 16 × 16 pixels, 16 × 8 pixels, 8 × 16 pixels, 8 × 8 pixels, 8 × 4 pixels, 4 × 8 pixels, and 4 × 4 pixels;
wherein if the current picture comprising a pair of current fields is in field coding, dividing each current field into a plurality of macroblocks, wherein the macroblocks are divided into at least one block, the at least one block comprising at least one of 16 × 16 pixels, 16 × 8 pixels, 8 by 16 pixels, 8 by 8 pixels, 8 by 4 pixels, 4 by 8 pixels, and 4 by 4 pixels; and
at least one motion vector is calculated and for at least one current block of said macroblock an associated reference picture or field is derived to which said at least one motion vector points, wherein each of the two associated reference pictures or fields is a forward or backward reference picture or field.
20. A method for decoding an image sequence having a plurality of encoded images from a bitstream, wherein an encoded current frame or field is encoded as a predictive-encoded P-picture and divided into a plurality of macroblocks, wherein the macroblocks are divided into at least one block comprising at least one of 16x16 pixels, 16x8 pixels, 8 by 16 pixels, 8 by 8 pixels, 8 by 4 pixels, 4 by 8 pixels, and 4 by 4 pixels, the method comprising:
decoding at least one picture of said plurality of coded pictures in a frame coding mode and at least one picture of said plurality of coded pictures in a field coding mode, wherein said decoding applies at least two motion vectors and two associated decoded reference pictures or fields to which said at least two motion vectors point for decoding at least one current block of said macroblock, wherein each of said two associated reference pictures or fields is a forward or backward reference picture or field; and
constructing an image sequence using the plurality of decoded images.
21. The method of claim 20, wherein the associated reference image or field to which the at least one motion vector points may be in the past or in the future relative to a current image or field.
22. The method of claim 21, wherein the current block or co-located block is decoded in a frame encoding mode or a field decoding mode.
23. A computer-readable medium having stored thereon a plurality of instructions, the plurality of instructions comprising instructions, which when executed by a processor, cause the processor to perform a method for decoding an image sequence from a bitstream having a plurality of encoded images, wherein an encoded current frame or field is encoded as a predictive encoded P-picture and divided into a plurality of macroblocks, wherein the macroblocks are divided into at least one block, the at least one block comprising at least one of 16x16 pixels, 16x8 pixels, 8 by 16 pixels, 8 by 8 pixels, 8 by 4 pixels, 4 by 8 pixels, and 4 by 4 pixels, the method comprising:
decoding at least one picture of said plurality of coded pictures in a frame coding mode and at least one picture of said plurality of coded pictures in a field coding mode, wherein said decoding applies at least two motion vectors and two associated decoded reference pictures or fields to which said at least two motion vectors point for decoding at least one current block of said macroblock, wherein each of said two associated reference pictures or fields is a forward or backward reference picture or field; and
constructing an image sequence using the plurality of decoded images.
24. A method of decoding an image sequence having a plurality of images, comprising:
selectively decoding, at a decoder, at least one picture of the plurality of pictures in a frame coding mode;
selectively decoding at least one picture of the plurality of pictures in a field coding mode, wherein a current field of a current picture in the field coding mode has at least one reference field, wherein each of the at least one reference field is assigned a unique reference field number,
wherein the unique reference field number assigned to the at least one reference field is based on a temporal distance between the at least one reference field and the current field and a field parity of the current field, wherein the current field is a first field or a second field of the current picture, and
wherein, given the current field, a reference field having the same field parity as the current field is given a smaller unique reference field number relative to its corresponding other reference fields of the same reference picture.
25. An apparatus for decoding a sequence of images having a plurality of images, comprising:
a decoding unit that decodes at least one of the plurality of pictures in a frame encoding mode; and decoding at least one picture of the plurality of pictures in a field coding mode, wherein a current field in the field coding mode has at least one reference field, wherein each of the at least one reference field is assigned a unique reference field number,
wherein the unique reference field number assigned to the at least one reference field is based on a temporal distance between the at least one reference field and the current field and a field parity of the current field, wherein the current field is a first field or a second field of a current picture, and
wherein, given the current field, a reference field having the same field parity as the current field is given a smaller unique reference field number relative to its corresponding other reference fields of the same reference picture.
26. An apparatus for decoding a sequence of images having a plurality of images, comprising:
a decoding unit configured to decode at least one picture of the plurality of pictures in a frame coding mode and decode at least one picture of the plurality of pictures in a field coding mode, wherein a current field in the field coding mode has at least one reference field, wherein each of the at least one reference field is assigned a unique reference field number,
wherein the unique reference field number assigned to the reference field is based on a temporal distance between the reference field and the current field, wherein the current field is a first field or a second field of a current picture,
wherein the reference field closest in time to the current field is assigned a reference field number 0, and the reference field closest in time to the current field is assigned a reference field number 1.
27. A method of encoding an image sequence having a plurality of images, comprising:
selectively encoding, at an encoder, at least one of the plurality of images in a frame encoding mode; and
selectively encoding at least one of the plurality of pictures in a field coding mode, wherein a current field of a current picture in the field coding mode has at least one reference field, wherein each of the at least one reference field is assigned a unique reference field number,
wherein the unique reference field number assigned to the at least one reference field is based on a temporal distance between the at least one reference field and the current field and a field parity of the current field, wherein the current field is a first field or a second field of the current picture,
wherein, given the current field, a reference field having the same field parity as the current field is given a smaller unique reference field number relative to its corresponding other reference fields of the same reference picture.
28. A method of encoding an image sequence having a plurality of images, comprising:
selectively encoding, at an encoder, at least one picture of the plurality of pictures in a frame encoding mode; and
selectively encoding at least one picture of the plurality of pictures in a field coding mode, wherein a current field of a current picture in the field coding mode has at least one reference field, wherein each of the at least one reference field is assigned a unique reference field number,
wherein the unique reference field number assigned to the reference field is based on a temporal distance between the reference field and the current field, wherein the current field is a first field or a second field of the current picture,
wherein the reference field closest in time to the current field is assigned a reference field number 0, and the reference field closest in time to the current field is assigned a reference field number 1.
29. An apparatus for encoding a sequence of images having a plurality of images, comprising:
an encoding unit configured to encode at least one of the plurality of images in a frame encoding mode; and encoding at least one picture of the plurality of pictures in a field coding mode, wherein a current field in the field coding mode has at least one reference field, wherein each of the at least one reference field is assigned a unique reference field number,
wherein the unique reference field number assigned to the at least one reference field is based on a temporal distance between the at least one reference field and the current field and a field parity of the current field, wherein the current field is a first field or a second field of a current picture, and
wherein, given the current field, a reference field having the same field parity as the current field is given a smaller unique reference field number relative to its corresponding other reference fields of the same reference picture.
30. An apparatus for encoding a sequence of images having a plurality of images, comprising:
an encoding unit configured to encode at least one of the plurality of images in a frame encoding mode; and encoding at least one picture of the plurality of pictures in a field coding mode, wherein a current field in the field coding mode has at least one reference field, wherein each of the at least one reference field is assigned a unique reference field number,
wherein the unique reference field number assigned to the reference field is based on a temporal distance between the reference field and the current field, wherein the current field is a first field or a second field of a current picture, and
wherein the reference field closest in time to the current field is assigned a reference field number 0, and the reference field closest in time to the current field is assigned a reference field number 1.
Applications Claiming Priority (11)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US33300401P | 2001-11-21 | 2001-11-21 | |
US60/333004 | 2001-11-21 | ||
US33392101P | 2001-11-27 | 2001-11-27 | |
US60/333921 | 2001-11-27 | ||
US39570802P | 2002-07-12 | 2002-07-12 | |
US39571702P | 2002-07-12 | 2002-07-12 | |
US60/395717 | 2002-07-12 | ||
US60/395708 | 2002-07-12 | ||
US10/301203 | 2002-11-20 | ||
US10/301,203 US20030099294A1 (en) | 2001-11-27 | 2002-11-20 | Picture level adaptive frame/field coding for digital video content |
CN02827402A CN100584028C (en) | 2001-11-21 | 2002-11-21 | Method and equipment for coding image sequence having multiple images |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN02827402A Division CN100584028C (en) | 2001-11-21 | 2002-11-21 | Method and equipment for coding image sequence having multiple images |
Publications (2)
Publication Number | Publication Date |
---|---|
CN107071404A CN107071404A (en) | 2017-08-18 |
CN107071404B true CN107071404B (en) | 2020-01-24 |
Family
ID=44166572
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201610842086.1A Expired - Lifetime CN107071404B (en) | 2001-11-21 | 2002-11-21 | Method and device for coding a sequence of images having a plurality of images |
Country Status (2)
Country | Link |
---|---|
CN (1) | CN107071404B (en) |
CA (3) | CA2738339C (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20210118952A (en) * | 2019-03-12 | 2021-10-01 | 엘지전자 주식회사 | Video or image coding to derive weighted index information for pair prediction |
CN111885335B (en) * | 2020-06-19 | 2022-03-29 | 成都东方盛行电子有限责任公司 | Ultrahigh-definition down-conversion rendering method |
Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP0577428A2 (en) * | 1992-07-03 | 1994-01-05 | Sony Corporation | Image signal coding and decoding and image signal recording medium |
EP0786906A2 (en) * | 1996-01-29 | 1997-07-30 | International Business Machines Corporation | MPEG decoder |
CN1206298A (en) * | 1997-03-07 | 1999-01-27 | 次级系统有限公司 | Prediction and coding of BI-directionally predicted video object planes for interlaced digital video |
CN1211372A (en) * | 1996-12-12 | 1999-03-17 | 松下电器产业株式会社 | Picture encoder and picture decoder |
CN1237067A (en) * | 1998-03-05 | 1999-12-01 | 松下电器产业株式会社 | Picture encoding and decoding apparatus, method and data storage medium |
CN1302510A (en) * | 1999-04-30 | 2001-07-04 | 皇家菲利浦电子有限公司 | Video encoding method with selection of B-frame encoding mode |
CN1306725A (en) * | 1999-03-26 | 2001-08-01 | 皇家菲利浦电子有限公司 | Video coding method and corresponding video coder |
CN1319309A (en) * | 1999-08-03 | 2001-10-24 | 皇家菲利浦电子有限公司 | Method and device for encoding sequences of frames including either video-type or film-type images |
-
2002
- 2002-11-21 CA CA2738339A patent/CA2738339C/en not_active Expired - Lifetime
- 2002-11-21 CA CA2738322A patent/CA2738322C/en not_active Expired - Lifetime
- 2002-11-21 CA CA2738329A patent/CA2738329C/en not_active Expired - Lifetime
- 2002-11-21 CN CN201610842086.1A patent/CN107071404B/en not_active Expired - Lifetime
Patent Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP0577428A2 (en) * | 1992-07-03 | 1994-01-05 | Sony Corporation | Image signal coding and decoding and image signal recording medium |
EP0786906A2 (en) * | 1996-01-29 | 1997-07-30 | International Business Machines Corporation | MPEG decoder |
CN1211372A (en) * | 1996-12-12 | 1999-03-17 | 松下电器产业株式会社 | Picture encoder and picture decoder |
CN1206298A (en) * | 1997-03-07 | 1999-01-27 | 次级系统有限公司 | Prediction and coding of BI-directionally predicted video object planes for interlaced digital video |
CN1237067A (en) * | 1998-03-05 | 1999-12-01 | 松下电器产业株式会社 | Picture encoding and decoding apparatus, method and data storage medium |
CN1306725A (en) * | 1999-03-26 | 2001-08-01 | 皇家菲利浦电子有限公司 | Video coding method and corresponding video coder |
CN1302510A (en) * | 1999-04-30 | 2001-07-04 | 皇家菲利浦电子有限公司 | Video encoding method with selection of B-frame encoding mode |
CN1319309A (en) * | 1999-08-03 | 2001-10-24 | 皇家菲利浦电子有限公司 | Method and device for encoding sequences of frames including either video-type or film-type images |
Also Published As
Publication number | Publication date |
---|---|
CA2738329C (en) | 2012-09-18 |
CA2738339A1 (en) | 2003-06-05 |
CA2738329A1 (en) | 2003-06-05 |
CN107071404A (en) | 2017-08-18 |
CA2738339C (en) | 2012-09-25 |
CA2738322C (en) | 2013-12-31 |
CA2738322A1 (en) | 2003-06-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US7839931B2 (en) | Picture level adaptive frame/field coding for digital video content | |
US8625669B2 (en) | Predicting motion vectors for fields of forward-predicted interlaced video frames | |
US7310374B2 (en) | Macroblock level adaptive frame/field coding for digital video content | |
KR101076506B1 (en) | A method of encoding and decoding an image sequence having a plurality of pictures | |
US8009739B2 (en) | Intensity estimation/compensation for interlaced forward-predicted fields | |
US8107531B2 (en) | Signaling and repeat padding for skip frames | |
US20050053144A1 (en) | Selecting between dominant and non-dominant motion vector predictor polarities | |
US20050053134A1 (en) | Number of reference fields for an interlaced forward-predicted field | |
US20050053140A1 (en) | Signaling macroblock mode information for macroblocks of interlaced forward-predicted fields | |
JP2005510985A (en) | Adaptive frame / field coding at the macroblock level of digital video content | |
JP2005510984A5 (en) | ||
CN107071404B (en) | Method and device for coding a sequence of images having a plurality of images |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
REG | Reference to a national code |
Ref country code: HKRef legal event code: DERef document number: 1242093Country of ref document: HK |
|
GR01 | Patent grant | ||
GR01 | Patent grant | ||
CX01 | Expiry of patent term |
Granted publication date: 20200124 |
|
CX01 | Expiry of patent term |