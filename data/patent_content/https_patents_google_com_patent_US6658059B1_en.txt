US6658059B1 - Motion field modeling and estimation using motion transform - Google Patents
Motion field modeling and estimation using motion transform Download PDFInfo
- Publication number
- US6658059B1 US6658059B1 US09/484,038 US48403800A US6658059B1 US 6658059 B1 US6658059 B1 US 6658059B1 US 48403800 A US48403800 A US 48403800A US 6658059 B1 US6658059 B1 US 6658059B1
- Authority
- US
- United States
- Prior art keywords
- image
- motion
- transform
- values
- optical flow
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/547—Motion estimation performed in a transform domain
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
Definitions
- the present invention relates to the field of video processing, and more particularly to motion field modeling and estimation of video content using a motion transform.
- Motion field modeling and estimation is important to computer vision and image processing. Accurate and efficient motion field estimation is meaningful for general video processing and applications, such as motion compensation coding of digital TV, noise reduction for video sequences, frame rate conversion and target tracking. Motion field estimation is also important for computer vision and human vision, such as for the recovery of 3-D motion and the structure of moving objects, and image registration.
- motion field estimation is particularly useful in MPEG video data compression.
- One of the main techniques to produce high compression techniques relies on accurately determining blocks of each frame that are in motion. Data describing the motion for only those blocks in the video determined to be in motion are encoded in the video stream between frames. This results in memory and bandwidth savings.
- Motion fields are typically represented as motion vector fields that are a pixel-by-pixel map of image motion from one image frame to the next image frame. Each pixel in the frame has a motion vector that defines a matching pixel in the next or previous frame. The combination of these motion vectors is the motion vector field. Storage requirements for vector fields may be large. There is a need for an apparatus and method that can efficiently model and estimate a motion vector field thereby reducing the memory requirements for storing the motion vector field.
- FIG. 1 depicts a video frame.
- Each rectangle portion corresponds to a respectively different image component which is preferably a pixel or group of pixels.
- the pixels may be referenced by x and y values respectively.
- Each pixel may have a value that is preferably represented by an intensity value E(x,y,t) in the image plane at time t.
- the horizontal location of the pixel is represented by ‘x’ and is preferably numbered between 1 and a maximum value illustrated in this example as ‘a’.
- the vertical location of the pixel is represented by ‘y’ and is preferably numbered between 1 and a maximum value as illustrated here as ‘b’.
- Time is represented as ‘t’.
- the exemplary image data used by the apparatus and methods described have pixels with random values. The image is shown having contrasting central and surrounding parts for clarity in the description.
- FIG. 2 illustrates how a video sequence may be made from a series of successive video frames. Each frame is shown sequentially as time ‘t’ increases. In the present invention, motion is preferably analyzed between a series of adjacent frames.
- a motion vector field 300 such as that shown in FIG. 3 may be generated. In this motion vector field, all vector elements are zero, indicating no motion in the image.
- a central area 404 moves to the position of a central area 402 , as indicated by the broken-line box in a field of observation 400 between a current frame and a next frame.
- a method according to the present invention is used to generate a motion vector field from the frames, one containing the area 404 and the other containing the area 402 , a motion vector field such as that shown in FIG. 4B is generated.
- a motion vector for each pixel in the area indicates that the pixel has moved in the direction of the motion.
- Another category is the parametric or model-based approach which assumes that a motion field may be described by a single or multiple motion model(s) or geometric transformation(s) by using a relatively small number of parameters.
- the present invention uses a motion transform, in which the motion field is represented in the transform domain and is treated as the unknown signal to be estimated. Note that this approach is different from motion estimation using the phase-correlation method as described in a paper by J. Fleet et al. entitled “Computation of component image velocity from local phase information” Int'l J. Comput. Vis., 5:77-104, 1990 or spatio-temporal frequency domain analysis as described in a paper by C. Lien et al.
- a motion transform offers a great generality for motion modeling since the estimated motion surface does not need to be restricted to a planar (e.g., affine) or a polynomial surface (e.g., pseudo-perspective, biquadratic, or any other second or higher-order polynomial model).
- the motion transform offers the flexibility to choose/remove certain time-frequency components in order to accommodate the underlying motion field. Very often, a small number of selected transform coefficients may be effective to describe the motion or warping between frames, which may provide an economic means for motion-compensated video coding.
- Motion estimation results by using the DCT/DFT for motion modeling, especially DCT due to its simplicity, efficiency, and greater flexibility are quite comparable to a wavelet-based approach proposed by Wu et al. in a paper entitled “Optical flow estimation using wavelet motion model”, ICCV '98, 1998, in which a wavelet function as described in a paper by Cai et al. entitled “Adaptive multiresolution collocation methods for initial boundary value problems of nonlinear pdes” SIAM J. Numer. Anal., 33(3):937-970, June 1996 is adopted to model the motion field.
- One advantage of the invention is in more accurately and efficiently processing consecutive video frames to determine the motion of objects in video frames and output a representation of that motion as an image motion vector field, wherein each component of the image vector field represents a pixel or group of pixels of a frame.
- Another advantage of this invention is that it can model any motion field including motion discontinuities.
- Yet a further advantage of this invention is that it offers the flexibility of dynamically choosing the significant time-frequency components used to model the underlying motion.
- an apparatus for generating an image motion vector field which describes a motion of individual image components of a first image frame and corresponding image components of a second image frame in a sequence of image frames
- the apparatus comprising a first frame memory for receiving said first image frame; a second frame memory for receiving a second image frame; and an optical flow calculator configured for generating an image motion vector field by iteratively comparing a predicted image with the second image frame, the predicted image being produced based upon said first memory frame and image gradients generated according to a motion estimate that is produced according to a transform function using transform coefficients.
- the estimated transform coefficients are estimated based upon a previously determined image gradient.
- the optical flow calculator further includes a coefficient estimator configured to generate the estimated transform coefficients by solving a linear coefficient equation using the image gradients and a plurality of individual image components, wherein the transform coefficients are unknown values in the coefficient equation.
- the optical flow calculator further includes a motion estimator configured to generate a motion estimate from the transform coefficients using an inverse transform equation.
- the optical flow calculator further includes a coefficient updater configured to generate image gradients from the motion estimates.
- a method for generating an image motion vector field comprising the steps of receiving a first image frame having individual image components; receiving a second image frame having corresponding image components; initializing an image gradient; and generating the image motion vector field.
- the step of generating the image motion field further comprises iteratively: estimating transform coefficients from the individual image components and the image gradient according to a transform coefficient function; calculating a motion field according to the estimated transform coefficients; calculating image gradients according to the motion field; generating a predicted image frame according to the image gradients and the first memory frame; calculating a residual error by taking a difference between the predicted image and the second image frame; determining if the residual error is less than a predetermined threshold, and accordingly if the predicted image has converged. If the image has converged, then ending the iterations; and outputting the image motion vector field.
- FIG. 1 is a drawing of an input video frame.
- FIG. 2 is a drawing of a video sequence.
- FIG. 3 is a drawing of a motion vector field.
- FIG. 4A is a drawing of a moving component in two consecutive input video frames.
- FIG. 4B is a drawing of a motion vector field produced using an embodiment of the present invention.
- FIG. 5 is a block diagram of a motion vector field generator.
- FIG. 6 is a block diagram of an aspect of the present invention which performs a vector motion field transform.
- FIG. 7 is a flow diagram of an aspect of the present invention which performs a vector motion field transform.
- FIG. 8 is a drawing showing how an embodiment of the invention may perform a zig-zag scan.
- a motion transform is a representation for modeling the motion field in the transform domain. Compared to other parametric motion models (e.g., affine, projective, etc.), a motion transform offers a considerable advantage by its capability to model any motion field, including multiple object motions, large motions or motion discontinuities. This approach may also allow the flexibility to adaptively choose the set of coefficients to fit a particular motion field. A motion transform may also offer the flexibility of dynamically choosing the significant time-frequency components used to model the underlying motion.
- the following is a mathematical derivation of an exemplary method, according to the present invention, for generating data values representing a motion vector field from other data values representing individual picture elements (pixels) of two or more images.
- This transform may be the DCT (Discrete Cosine Transform), the DFT (Discrete Fourier Transform), the Haar transform, the KL transform, the wavelet transform, or many others.
- ⁇ (k,x) denote the value of the k-th basis function at pixel x
- M x (k) and M y (k) denote the coefficients of the k-th basis function for the horizontal and vertical motion component, respectively. Note that for 2D images, these 2D basis functions may always be sequentially ordered and indexed by k.
- v(x) M N ⁇ N (x)
- the next step is to estimate the transform coefficients in M N .
- M N the transform coefficients in M N .
- the image intensity remains constant.
- the optimization process may be iteratively applied. Each time the system equations are updated based on the current motion estimates, denoted by ⁇ circumflex over (v) ⁇ .
- the updated incremental change of the coefficients (i.e. ⁇ M′ N ) may then be used to update ⁇ circumflex over (v) ⁇ . This process may proceed iteratively:
- ⁇ circumflex over (v) ⁇ (j+1) ⁇ circumflex over (v) ⁇ (j) + ⁇ M N (j) ⁇ N
- DCT-based motion estimation Similar to transform coding in which the intensity is represented in the transform domain, the idea behind DCT-based motion estimation is to represent the motion field in terms of its DCT coefficients. Unlike the role of image intensity in transform coding, however, the motion field is not directly observable. It has to be inferred from the intensity map as in any other motion estimation algorithm.
- the present invention may impose a zig-zag sequential ordering to these coefficients for motion modeling as illustarted in FIG. 8 .
- the iteration process may start from a small number of coefficients. New coefficients may then gradually added into the iterative process. When the number of coefficients increases from N 1 to N 2 (N 1 ⁇ N 2 ), M N1 retains its previous values while newly added coefficients are initialized to zero.
- N 1 ⁇ N 2 N 1 ⁇ N 2
- M N1 retains its previous values while newly added coefficients are initialized to zero.
- the choice of the number of coefficients is quite flexible since all N ⁇ Z, 0 ⁇ N ⁇ X ⁇ Y are permissible.
- the present invention could start with 16 DCT coefficients. Each time when the current coefficient set converges, the next 16 coefficients in the zig-zag order may be added to M, until the preset maximum number of coefficients are reached.
- Coefficients with their magnitude smaller than a threshold T c may be discarded adaptively during the iterative process. This treatment effectively reduces the size of D and M′.
- the computation cost is also directly affected by the number of pixels we consider in D and Y.
- the following schemes may be embedded into the system.
- a pixel x may be excluded from the matrix Y if y(x) ⁇ T e . This treatment may effectively reduce the computation cost without compromising much on the quality of the solution.
- a parameter step may be defined to control the subsampling rate.
- a multi-resolution (coarse to fine) approach in which different low pass filtered versions of the images are extracted may also be used.
- the algorithm starts by finding the motion field at the coarsest resolution using a small number of coefficients, with a larger pixel sub-sampling step.
- the number of coefficients may gradually increase when the resolution becomes finer. It may be critical that at coarser resolution a smoother gradient field is present.
- Low-pass filtering based on expanding the Gaussian pyramids to the same size as the original images may be used.
- Look-up tables may also be used to save the basis functions at fixed sampling points for a faster implementation.
- ⁇ overscore (u) ⁇ and ⁇ overscore (v) ⁇ may be estimated first and then u ⁇ overscore ( ⁇ circumflex over (u) ⁇ ) ⁇ and v ⁇ overscore ( ⁇ circumflex over (v) ⁇ ) ⁇ may be estimated where ⁇ overscore ( ⁇ circumflex over (u) ⁇ ) ⁇ and ⁇ overscore ( ⁇ circumflex over (v) ⁇ ) ⁇ are the estimate of the average (or DC terms) of the signal.
- the Levenberg-Marquardt method may be used for finding the DC terms, which is a combined gradient and Hessian method. This treatment is particularly useful when the warping between two images may be described by a simple global translation. Faster convergence may be achieved and sometimes there is no need to even estimate the wavelet coefficients if the global motion model has already captured the warping function. For an arbitrary motion, this scheme may provide a slightly faster convergence.
- Motion estimation using wavelets on a sub-image of quarter size may take much less than a quarter of the processing time needed for registering the entire image.
- the image may be partitioned into smaller sub-images and results then combined together.
- overlapping sub-images may be used so that motion vectors at the boundary region may be properly interpolated.
- Residual errors may be pre-calculated within a pre-defined search range for every pixel.
- a hierarchical sub-sampling scheme e.g. 3-step search of block-matching algorithm used for motion estimation in MPEG
- 3-step search of block-matching algorithm used for motion estimation in MPEG may be adopted.
- FIG. 5 is a block diagram of a motion detection apparatus 500 which may be used to generate motion vector fields in accordance with the present invention.
- This apparatus 500 preferably accepts a video sequence 502 as input.
- the video sequence 502 takes two separate routes.
- a first route preferably takes the video sequence 502 through a frame delay device 506 to a first frame memory 512 .
- a second route preferably takes the video sequence to a second frame memory 514 .
- the first memory frame 512 and the second frame memory 514 provide their respective frames to an optical flow calculator that 508 .
- the optical flow calculator 508 then preferably processes a pair of images from the video sequence 502 as previously described and outputs an image motion vector field 510 , which describes any motion that may have occurred between the frames.
- motion detection apparatus 500 is shown as receiving two frames of data, it is contemplated that, in a steady state operation, only one new frame of data may be applied to the apparatus 500 at any given time.
- Data located in frame memory 514 may simply be moved to delayed frame memory 512 thereby becoming the first frame when the frame memories are moved to the optical flow calculator.
- FIG. 6 is a block diagram of an optical flow calculator 600 in accordance with the present invention.
- the optical flow calculator 600 generates an image motion vector field 660 by iteratively generating a predicted image according to a transform function using estimated transform coefficients.
- the estimated transform coefficients are estimated according to a previous motion estimate, whereby improving said transform coefficients.
- the predicted image is compared with the second image frame to determine if the coefficients have converged.
- the coefficients in conjunction with the transform function form a motion model which may estimate an image motion vector field.
- the optical flow calculator 600 includes a controller 602 , a memory 610 , a coefficient estimator 620 , an motion estimator 630 , a coefficient updater 640 , an image predictor 650 and a convergence checker 660 .
- a controller 602 controls the optical flow calculator 600 to generate the image motion vector field 670 from a first image frame 602 a the second image frame 604 .
- the memory 610 includes a first frame memory 612 which preferably accepts as input the first image frame 602 , and a second frame memory 614 which preferably accepts as input the second image frame 604 .
- the memory 610 may also include locations to hold variables such as iteration counts, thresholds values, and current estimates for use in assisting the controller 602 in controlling the operation of the optical flow calculator 600 .
- the image frames contained in the first frame memory 612 and the second frame memory 614 are made up of a plurality of image components, each image component represented by an intensity value. Each image component may be a pixel or group of pixels.
- the optical flow calculator 600 controller may initialize several variables at the beginning of each image component calculation including the iteration count, the initial motion estimate, and the transform coefficients.
- the coefficient estimator 620 inputs intensity values from the first and second frame memories to determine in conjunction with the previous motion estimate transform coefficients. The previous discussion of equation 8 describes this calculation.
- the coefficient estimates output from the coefficient estimator is inputted to the motion estimator 630 which calculates the adjusted velocity ( ⁇ u and ⁇ v) for the iteration as described by equation 1.
- the coefficient estimates are updated by the coefficient updater 640 .
- the coefficient updater is configured to generates image gradients according to equation 5. The coefficient updater may also make determinations as to whether coefficients should be adaptively added or excluded for further calculations.
- the output of the coefficient updater 640 is input to the image predictor 650 which will create a predicted image around the point of interest based on the first frame memory and the predicted motion vector using motion compensation.
- the convergence checker 660 will then compare this image with the values stored in the second frame memory 614 and determine if the error is below a predetermined threshold value. When the image converges the convergence detector 660 informs the controller that the estimation is complete, and the calculated image motion vectors are output to the image motion vector field 670 .
- FIG. 7 is a flow-chart diagram which illustrates the operation of the optical flow calculator 508 in an exemplary embodiment of the invention.
- the process begins at step S 702 where the first and second image frame are input to the optical flow calculator 508 .
- the first image frame is preferably delayed such that the second frame represents a frame from video sequence 502 that is later in time than the first frame by delta time T.
- transform coefficients, image gradients, and motion estimates are initialized at step S 704 .
- estimates of transform coefficients are made according to equation 8, which was previously described.
- the estimated transform coefficients are then used at step S 708 to calculate a motion field according to equation 1, which was previously described.
- Step S 712 generates a predicted image based on the first image frame and the current motion estimate.
- Step S 714 a determination of whether the current motion estimate has converged by comparing the predicted image is compared with the second image frame 604 . The determination is positive if the residual value (the difference between the predicted image and the second image frame 604 ) is less than a predetermined threshold value. If the determination at step S 716 is negative, then processing proceeds back to step S 706 for another iteration. If the determination at step S 716 is positive, then processing proceeds to step S 718 where the present estimate may be used as the image vector field. Optionally, the transform coefficients may also be output at this step.
Abstract
Description
Claims (38)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/484,038 US6658059B1 (en) | 1999-01-15 | 2000-01-18 | Motion field modeling and estimation using motion transform |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11607899P | 1999-01-15 | 1999-01-15 | |
US09/484,038 US6658059B1 (en) | 1999-01-15 | 2000-01-18 | Motion field modeling and estimation using motion transform |
Publications (1)
Publication Number | Publication Date |
---|---|
US6658059B1 true US6658059B1 (en) | 2003-12-02 |
Family
ID=29552647
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/484,038 Expired - Lifetime US6658059B1 (en) | 1999-01-15 | 2000-01-18 | Motion field modeling and estimation using motion transform |
Country Status (1)
Country | Link |
---|---|
US (1) | US6658059B1 (en) |
Cited By (58)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020173952A1 (en) * | 2001-01-10 | 2002-11-21 | Mietens Stephan Oliver | Coding |
US20030081682A1 (en) * | 2001-10-08 | 2003-05-01 | Lunter Gerard Anton | Unit for and method of motion estimation and image processing apparatus provided with such estimation unit |
US20030103568A1 (en) * | 2001-11-30 | 2003-06-05 | Samsung Electronics Co., Ltd. | Pixel data selection device for motion compensated interpolation and method thereof |
US20040086046A1 (en) * | 2002-11-01 | 2004-05-06 | Yu-Fei Ma | Systems and methods for generating a motion attention model |
US20040088723A1 (en) * | 2002-11-01 | 2004-05-06 | Yu-Fei Ma | Systems and methods for generating a video summary |
US20040091047A1 (en) * | 2002-11-11 | 2004-05-13 | Sony Corporation | Method and apparatus for nonlinear multiple motion model and moving boundary extraction |
US20040152229A1 (en) * | 2002-10-18 | 2004-08-05 | Khalil Najafi | Manufacturing methods and vacuum or hermetically packaged micromachined or MEMS devices formed thereby having substantially vertical feedthroughs |
US20050025358A1 (en) * | 2001-06-14 | 2005-02-03 | Miicrosoft Corporation | Method and apparatus for shot detection |
US20050069206A1 (en) * | 2003-09-30 | 2005-03-31 | Yu-Fei Ma | Contrast-based image attention analysis framework |
US20050129330A1 (en) * | 2003-12-16 | 2005-06-16 | Genesis Microchip Inc. | Method and apparatus for MPEG artifacts reduction |
US20050135482A1 (en) * | 2003-12-23 | 2005-06-23 | Genesis Microchip Inc. | Motion vector computation for video sequences |
US20050135485A1 (en) * | 2003-12-23 | 2005-06-23 | Genesis Microchip Inc. | Vector selection decision for pixel interpolation |
US20050135483A1 (en) * | 2003-12-23 | 2005-06-23 | Genesis Microchip Inc. | Temporal motion vector filtering |
US20050195278A1 (en) * | 2003-12-23 | 2005-09-08 | Genesis Microchip Inc. | Robust camera pan vector estimation using iterative center of mass |
US20060002601A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | DRR generation using a non-linear attenuation model |
US20060002632A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | Motion field generation for non-rigid image registration |
US20060002615A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | Image enhancement method and system for fiducial-less tracking of treatment targets |
US20060002631A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | ROI selection in image registration |
US20060002630A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | Fiducial-less tracking with non-rigid image registration |
US20060062303A1 (en) * | 2004-09-17 | 2006-03-23 | Sony Corporation | Hybrid global motion estimator for video encoding |
US20060107289A1 (en) * | 2004-07-28 | 2006-05-18 | Microsoft Corporation | Thumbnail generation and presentation for recorded TV programs |
US20060291710A1 (en) * | 2005-06-23 | 2006-12-28 | Bai Wang | DRR generation and enhancement using a dedicated graphics device |
US20070101269A1 (en) * | 2005-10-31 | 2007-05-03 | Microsoft Corporation | Capture-intention detection for video content analysis |
US20070112583A1 (en) * | 2003-02-18 | 2007-05-17 | Microsoft Corporation | Learning-Based Automatic Commercial Content Detection |
US20070156647A1 (en) * | 2005-12-29 | 2007-07-05 | Microsoft Corporation | Dynamic Search with Implicit User Intention Mining |
US7274741B2 (en) | 2002-11-01 | 2007-09-25 | Microsoft Corporation | Systems and methods for generating a comprehensive user attention model |
US20080037843A1 (en) * | 2006-08-11 | 2008-02-14 | Accuray Incorporated | Image segmentation for DRR generation and image registration |
US20080165278A1 (en) * | 2007-01-04 | 2008-07-10 | Sony Corporation | Human visual system based motion detection/estimation for video deinterlacing |
US20080212687A1 (en) * | 2007-03-02 | 2008-09-04 | Sony Corporation And Sony Electronics Inc. | High accurate subspace extension of phase correlation for global motion estimation |
US20080212676A1 (en) * | 2007-03-02 | 2008-09-04 | Sony Corporation And Sony Electronics Inc. | Motion parameter engine for true motion |
US7471827B2 (en) | 2003-10-16 | 2008-12-30 | Microsoft Corporation | Automatic browsing path generation to present image areas with high attention value as a function of space and time |
US20090262800A1 (en) * | 2008-04-18 | 2009-10-22 | Sony Corporation, A Japanese Corporation | Block based codec friendly edge detection and transform selection |
US20090310681A1 (en) * | 2006-03-23 | 2009-12-17 | Nicolas Gaude | System for analysis of motion |
US20100014001A1 (en) * | 2008-07-16 | 2010-01-21 | Sony Corporation, A Japanese Corporation | Simple next search position selection for motion estimation iterative search |
US20100014588A1 (en) * | 2008-07-16 | 2010-01-21 | Sony Corporation, A Japanese Corporation | Speculative start point selection for motion estimation iterative search |
US20100027905A1 (en) * | 2008-07-29 | 2010-02-04 | Sony Corporation, A Japanese Corporation | System and method for image and video encoding artifacts reduction and quality improvement |
US20100067818A1 (en) * | 2008-09-15 | 2010-03-18 | Sony Corporation, A Japanese Corporation | System and method for high quality image and video upscaling |
US20110050930A1 (en) * | 2009-09-02 | 2011-03-03 | Sony Corporation | Fast iterative motion estimation method on gradually changing images |
US20110176013A1 (en) * | 2010-01-19 | 2011-07-21 | Sony Corporation | Method to estimate segmented motion |
US7986372B2 (en) | 2004-08-02 | 2011-07-26 | Microsoft Corporation | Systems and methods for smart media content thumbnail extraction |
US20110229056A1 (en) * | 2010-03-19 | 2011-09-22 | Sony Corporation | Method for highly accurate estimation of motion using phase correlation |
US8180826B2 (en) | 2005-10-31 | 2012-05-15 | Microsoft Corporation | Media sharing and authoring on the web |
US8196032B2 (en) | 2005-11-01 | 2012-06-05 | Microsoft Corporation | Template-based multimedia authoring and sharing |
US20120147263A1 (en) * | 2010-12-14 | 2012-06-14 | Wei Chen | Method and apparatus for motion-compensated interpolation (mci) with conservative motion model |
US20120147014A1 (en) * | 2010-12-08 | 2012-06-14 | Chao-Hua Lee | Method for extracting personal styles and its application to motion synthesis and recognition |
US8218811B2 (en) | 2007-09-28 | 2012-07-10 | Uti Limited Partnership | Method and system for video interaction based on motion swarms |
US20160125584A1 (en) * | 2014-11-05 | 2016-05-05 | Canon Kabushiki Kaisha | Image processing apparatus, image processing method and storage medium |
US10089713B2 (en) | 2015-05-29 | 2018-10-02 | Canon Kabushiki Kaisha | Systems and methods for registration of images |
US10176567B2 (en) | 2015-12-21 | 2019-01-08 | Canon Kabushiki Kaisha | Physical registration of images acquired by Fourier Ptychography |
US10686968B1 (en) * | 2019-02-27 | 2020-06-16 | Augentix Inc. | Motion detection method and circuit thereof |
US10742473B1 (en) | 2019-10-03 | 2020-08-11 | United States Government As Represented By The Secretary Of The Navy | Enhanced signal acquisition based on adaptive multiresolution modulation |
US10826746B1 (en) | 2020-03-04 | 2020-11-03 | United States Of America As Represented By The Secretary Of The Navy | Transmission security based on adaptive multiresolution modulation |
CN112884813A (en) * | 2021-02-18 | 2021-06-01 | 北京小米松果电子有限公司 | Image processing method, device and storage medium |
US11044049B1 (en) | 2019-12-23 | 2021-06-22 | United States Of America As Represented By The Secretary Of The Navy | Hybrid unequal error protection (UEP) for heterogeneous multi-service provisioning |
CN113160277A (en) * | 2021-01-29 | 2021-07-23 | 北京小米松果电子有限公司 | Image processing method and device, electronic equipment and storage medium |
US11272305B2 (en) * | 2016-03-15 | 2022-03-08 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e. V. | Apparatus, method or computer program for generating a sound field description |
US11308858B2 (en) * | 2019-09-24 | 2022-04-19 | Lg Electronics Inc. | Signal processing device and image display apparatus including same |
WO2023081091A3 (en) * | 2021-11-04 | 2023-06-22 | Op Solutions, Llc | Systems and methods for motion information transfer from visual to feature domain |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5654771A (en) * | 1995-05-23 | 1997-08-05 | The University Of Rochester | Video compression system using a dense motion vector field and a triangular patch mesh overlay model |
US6526096B2 (en) * | 1996-09-20 | 2003-02-25 | Nokia Mobile Phones Limited | Video coding system for estimating a motion vector field by using a series of motion estimators of varying complexity |
-
2000
- 2000-01-18 US US09/484,038 patent/US6658059B1/en not_active Expired - Lifetime
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5654771A (en) * | 1995-05-23 | 1997-08-05 | The University Of Rochester | Video compression system using a dense motion vector field and a triangular patch mesh overlay model |
US6526096B2 (en) * | 1996-09-20 | 2003-02-25 | Nokia Mobile Phones Limited | Video coding system for estimating a motion vector field by using a series of motion estimators of varying complexity |
Non-Patent Citations (3)
Title |
---|
C.-C. Lien, C.-L. Huang, and J.-G. Chen. Complex-subband transform for subband-based motion estimation/compensation and coding. IEEE Trans. on Image Processing, 6(5):694-702, 1997. |
W. Cai amd J. Wang. Adaptive multiresolution collocation methods for initial boundary value problems of nonlinear pdes. SIAM J. Numer. Anal., 33(3):937-970, Jun. 1996. |
Y.-T. Wu, T. Kanade, J. Cohen, and C.-C LI. Optical Flow Estimation Using Wavelet Motion Model. ICCV'98, 1998, pp. 992-998. |
Cited By (112)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020173952A1 (en) * | 2001-01-10 | 2002-11-21 | Mietens Stephan Oliver | Coding |
US20050025358A1 (en) * | 2001-06-14 | 2005-02-03 | Miicrosoft Corporation | Method and apparatus for shot detection |
US7444018B2 (en) | 2001-06-14 | 2008-10-28 | Microsoft Corporation | Method and apparatus for shot detection |
US20030081682A1 (en) * | 2001-10-08 | 2003-05-01 | Lunter Gerard Anton | Unit for and method of motion estimation and image processing apparatus provided with such estimation unit |
US20030103568A1 (en) * | 2001-11-30 | 2003-06-05 | Samsung Electronics Co., Ltd. | Pixel data selection device for motion compensated interpolation and method thereof |
US7720150B2 (en) * | 2001-11-30 | 2010-05-18 | Samsung Electronics Co., Ltd. | Pixel data selection device for motion compensated interpolation and method thereof |
US20040152229A1 (en) * | 2002-10-18 | 2004-08-05 | Khalil Najafi | Manufacturing methods and vacuum or hermetically packaged micromachined or MEMS devices formed thereby having substantially vertical feedthroughs |
US20040086046A1 (en) * | 2002-11-01 | 2004-05-06 | Yu-Fei Ma | Systems and methods for generating a motion attention model |
US7116716B2 (en) * | 2002-11-01 | 2006-10-03 | Microsoft Corporation | Systems and methods for generating a motion attention model |
US20060165178A1 (en) * | 2002-11-01 | 2006-07-27 | Microsoft Corporation | Generating a Motion Attention Model |
US8098730B2 (en) * | 2002-11-01 | 2012-01-17 | Microsoft Corporation | Generating a motion attention model |
US7274741B2 (en) | 2002-11-01 | 2007-09-25 | Microsoft Corporation | Systems and methods for generating a comprehensive user attention model |
US20040088723A1 (en) * | 2002-11-01 | 2004-05-06 | Yu-Fei Ma | Systems and methods for generating a video summary |
US20040091047A1 (en) * | 2002-11-11 | 2004-05-13 | Sony Corporation | Method and apparatus for nonlinear multiple motion model and moving boundary extraction |
KR101021409B1 (en) * | 2002-11-11 | 2011-03-14 | 소니 일렉트로닉스 인코포레이티드 | Method and apparatus for nonlinear multiple motion model and moving boundary extraction |
US20050213660A1 (en) * | 2002-11-11 | 2005-09-29 | Sony Corporation | Method and apparatus for nonlinear multiple motion model and moving boundary extraction |
US7751479B2 (en) * | 2002-11-11 | 2010-07-06 | Sony Corporation | Method and apparatus for nonlinear multiple motion model and moving boundary extraction |
US7565016B2 (en) | 2003-02-18 | 2009-07-21 | Microsoft Corporation | Learning-based automatic commercial content detection |
US20070112583A1 (en) * | 2003-02-18 | 2007-05-17 | Microsoft Corporation | Learning-Based Automatic Commercial Content Detection |
US7400761B2 (en) | 2003-09-30 | 2008-07-15 | Microsoft Corporation | Contrast-based image attention analysis framework |
US20050069206A1 (en) * | 2003-09-30 | 2005-03-31 | Yu-Fei Ma | Contrast-based image attention analysis framework |
US7471827B2 (en) | 2003-10-16 | 2008-12-30 | Microsoft Corporation | Automatic browsing path generation to present image areas with high attention value as a function of space and time |
US7346226B2 (en) | 2003-12-16 | 2008-03-18 | Genesis Microchip Inc. | Method and apparatus for MPEG artifacts reduction |
US20050129330A1 (en) * | 2003-12-16 | 2005-06-16 | Genesis Microchip Inc. | Method and apparatus for MPEG artifacts reduction |
US8019124B2 (en) | 2003-12-23 | 2011-09-13 | Tamiras Per Pte. Ltd., Llc | Robust camera pan vector estimation using iterative center of mass |
US8315436B2 (en) | 2003-12-23 | 2012-11-20 | Tamiras Per Pte. Ltd., Llc | Robust camera pan vector estimation using iterative center of mass |
US8335257B2 (en) | 2003-12-23 | 2012-12-18 | Tamiras Per Pte. Ltd., Llc | Vector selection decision for pixel interpolation |
US8494054B2 (en) | 2003-12-23 | 2013-07-23 | Genesis Microchip, Inc. | Motion vector computation for video sequences |
US8588306B2 (en) | 2003-12-23 | 2013-11-19 | Tamiras Per Pte. Ltd., Llc | Temporal motion vector filtering |
US20050195278A1 (en) * | 2003-12-23 | 2005-09-08 | Genesis Microchip Inc. | Robust camera pan vector estimation using iterative center of mass |
US20090135913A1 (en) * | 2003-12-23 | 2009-05-28 | Nair Hari N | Vector selection decision for pixel interpolation |
US20090116557A1 (en) * | 2003-12-23 | 2009-05-07 | Nair Hari N | Temporal motion vector filtering |
US20090086103A1 (en) * | 2003-12-23 | 2009-04-02 | Nair Hari N | Robust camera pan vector estimation using iterative center of mass |
US20080043850A1 (en) * | 2003-12-23 | 2008-02-21 | Genesis Microchip Inc. | Motion vector computation for video sequences |
US20050135483A1 (en) * | 2003-12-23 | 2005-06-23 | Genesis Microchip Inc. | Temporal motion vector filtering |
US7346109B2 (en) | 2003-12-23 | 2008-03-18 | Genesis Microchip Inc. | Motion vector computation for video sequences |
US7499494B2 (en) | 2003-12-23 | 2009-03-03 | Genesis Microchip Inc. | Vector selection decision for pixel interpolation |
US7480334B2 (en) | 2003-12-23 | 2009-01-20 | Genesis Microchip Inc. | Temporal motion vector filtering |
US20050135485A1 (en) * | 2003-12-23 | 2005-06-23 | Genesis Microchip Inc. | Vector selection decision for pixel interpolation |
US7457438B2 (en) | 2003-12-23 | 2008-11-25 | Genesis Microchip Inc. | Robust camera pan vector estimation using iterative center of mass |
US20050135482A1 (en) * | 2003-12-23 | 2005-06-23 | Genesis Microchip Inc. | Motion vector computation for video sequences |
US7231076B2 (en) | 2004-06-30 | 2007-06-12 | Accuray, Inc. | ROI selection in image registration |
US20060002601A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | DRR generation using a non-linear attenuation model |
US20060002630A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | Fiducial-less tracking with non-rigid image registration |
US7426318B2 (en) | 2004-06-30 | 2008-09-16 | Accuray, Inc. | Motion field generation for non-rigid image registration |
US20060002631A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | ROI selection in image registration |
US20080159612A1 (en) * | 2004-06-30 | 2008-07-03 | Dongshan Fu | DRR generation using a non-linear attenuation model |
US20080101673A1 (en) * | 2004-06-30 | 2008-05-01 | Dongshan Fu | Fiducial-less tracking with non-rigid image registration |
US7366278B2 (en) | 2004-06-30 | 2008-04-29 | Accuray, Inc. | DRR generation using a non-linear attenuation model |
US20060002615A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | Image enhancement method and system for fiducial-less tracking of treatment targets |
US7505617B2 (en) * | 2004-06-30 | 2009-03-17 | Accuray, Inc. | Fiducial-less tracking with non-rigid image registration |
US20060002632A1 (en) * | 2004-06-30 | 2006-01-05 | Accuray, Inc. | Motion field generation for non-rigid image registration |
US20090091567A1 (en) * | 2004-06-30 | 2009-04-09 | Accuray, Inc. | Image enhancement method and system for fiducial-less tracking of treatment targets |
US7522779B2 (en) | 2004-06-30 | 2009-04-21 | Accuray, Inc. | Image enhancement method and system for fiducial-less tracking of treatment targets |
US7840093B2 (en) | 2004-06-30 | 2010-11-23 | Accuray, Inc. | Image enhancement method and system for fiducial-less tracking of treatment targets |
US7327865B2 (en) * | 2004-06-30 | 2008-02-05 | Accuray, Inc. | Fiducial-less tracking with non-rigid image registration |
US20060107289A1 (en) * | 2004-07-28 | 2006-05-18 | Microsoft Corporation | Thumbnail generation and presentation for recorded TV programs |
US9053754B2 (en) | 2004-07-28 | 2015-06-09 | Microsoft Technology Licensing, Llc | Thumbnail generation and presentation for recorded TV programs |
US9355684B2 (en) | 2004-07-28 | 2016-05-31 | Microsoft Technology Licensing, Llc | Thumbnail generation and presentation for recorded TV programs |
US7986372B2 (en) | 2004-08-02 | 2011-07-26 | Microsoft Corporation | Systems and methods for smart media content thumbnail extraction |
US20060062303A1 (en) * | 2004-09-17 | 2006-03-23 | Sony Corporation | Hybrid global motion estimator for video encoding |
US7330578B2 (en) | 2005-06-23 | 2008-02-12 | Accuray Inc. | DRR generation and enhancement using a dedicated graphics device |
US20060291710A1 (en) * | 2005-06-23 | 2006-12-28 | Bai Wang | DRR generation and enhancement using a dedicated graphics device |
US20080069422A1 (en) * | 2005-06-23 | 2008-03-20 | Bai Wang | DRR generation and enhancement using a dedicated graphics device |
US7773813B2 (en) | 2005-10-31 | 2010-08-10 | Microsoft Corporation | Capture-intention detection for video content analysis |
US20070101269A1 (en) * | 2005-10-31 | 2007-05-03 | Microsoft Corporation | Capture-intention detection for video content analysis |
US8180826B2 (en) | 2005-10-31 | 2012-05-15 | Microsoft Corporation | Media sharing and authoring on the web |
US8196032B2 (en) | 2005-11-01 | 2012-06-05 | Microsoft Corporation | Template-based multimedia authoring and sharing |
US20070156647A1 (en) * | 2005-12-29 | 2007-07-05 | Microsoft Corporation | Dynamic Search with Implicit User Intention Mining |
US7599918B2 (en) | 2005-12-29 | 2009-10-06 | Microsoft Corporation | Dynamic search with implicit user intention mining |
US8170109B2 (en) | 2006-03-23 | 2012-05-01 | Nds Limited | System for analysis of motion |
US20090310681A1 (en) * | 2006-03-23 | 2009-12-17 | Nicolas Gaude | System for analysis of motion |
US20080037843A1 (en) * | 2006-08-11 | 2008-02-14 | Accuray Incorporated | Image segmentation for DRR generation and image registration |
US20080165278A1 (en) * | 2007-01-04 | 2008-07-10 | Sony Corporation | Human visual system based motion detection/estimation for video deinterlacing |
US20080212676A1 (en) * | 2007-03-02 | 2008-09-04 | Sony Corporation And Sony Electronics Inc. | Motion parameter engine for true motion |
US20080212687A1 (en) * | 2007-03-02 | 2008-09-04 | Sony Corporation And Sony Electronics Inc. | High accurate subspace extension of phase correlation for global motion estimation |
US8553758B2 (en) | 2007-03-02 | 2013-10-08 | Sony Corporation | Motion parameter engine for true motion |
US8218811B2 (en) | 2007-09-28 | 2012-07-10 | Uti Limited Partnership | Method and system for video interaction based on motion swarms |
US20090262800A1 (en) * | 2008-04-18 | 2009-10-22 | Sony Corporation, A Japanese Corporation | Block based codec friendly edge detection and transform selection |
US8363728B2 (en) | 2008-04-18 | 2013-01-29 | Sony Corporation | Block based codec friendly edge detection and transform selection |
US8144766B2 (en) | 2008-07-16 | 2012-03-27 | Sony Corporation | Simple next search position selection for motion estimation iterative search |
US20100014588A1 (en) * | 2008-07-16 | 2010-01-21 | Sony Corporation, A Japanese Corporation | Speculative start point selection for motion estimation iterative search |
US8094714B2 (en) | 2008-07-16 | 2012-01-10 | Sony Corporation | Speculative start point selection for motion estimation iterative search |
US20100014001A1 (en) * | 2008-07-16 | 2010-01-21 | Sony Corporation, A Japanese Corporation | Simple next search position selection for motion estimation iterative search |
US8139883B2 (en) | 2008-07-29 | 2012-03-20 | Sony Corporation | System and method for image and video encoding artifacts reduction and quality improvement |
US20100027905A1 (en) * | 2008-07-29 | 2010-02-04 | Sony Corporation, A Japanese Corporation | System and method for image and video encoding artifacts reduction and quality improvement |
US20100067818A1 (en) * | 2008-09-15 | 2010-03-18 | Sony Corporation, A Japanese Corporation | System and method for high quality image and video upscaling |
US20110050930A1 (en) * | 2009-09-02 | 2011-03-03 | Sony Corporation | Fast iterative motion estimation method on gradually changing images |
US8179474B2 (en) | 2009-09-02 | 2012-05-15 | Sony Corporation | Fast iterative motion estimation method on gradually changing images |
US20110176013A1 (en) * | 2010-01-19 | 2011-07-21 | Sony Corporation | Method to estimate segmented motion |
US8488007B2 (en) | 2010-01-19 | 2013-07-16 | Sony Corporation | Method to estimate segmented motion |
US20110229056A1 (en) * | 2010-03-19 | 2011-09-22 | Sony Corporation | Method for highly accurate estimation of motion using phase correlation |
US8285079B2 (en) | 2010-03-19 | 2012-10-09 | Sony Corporation | Method for highly accurate estimation of motion using phase correlation |
US20120147014A1 (en) * | 2010-12-08 | 2012-06-14 | Chao-Hua Lee | Method for extracting personal styles and its application to motion synthesis and recognition |
US8559763B2 (en) * | 2010-12-14 | 2013-10-15 | The United States Of America As Represented By The Secretary Of The Navy | Method and apparatus for motion-compensated interpolation (MCI) with conservative motion model |
US20120147263A1 (en) * | 2010-12-14 | 2012-06-14 | Wei Chen | Method and apparatus for motion-compensated interpolation (mci) with conservative motion model |
US20160125584A1 (en) * | 2014-11-05 | 2016-05-05 | Canon Kabushiki Kaisha | Image processing apparatus, image processing method and storage medium |
US10867423B2 (en) | 2014-11-05 | 2020-12-15 | Canon Kabushiki Kaisha | Deformation field calculation apparatus, method, and computer readable storage medium |
US10157486B2 (en) * | 2014-11-05 | 2018-12-18 | Canon Kabushiki Kaisha | Deformation field calculation apparatus, method, and computer readable storage medium |
US10089713B2 (en) | 2015-05-29 | 2018-10-02 | Canon Kabushiki Kaisha | Systems and methods for registration of images |
US10176567B2 (en) | 2015-12-21 | 2019-01-08 | Canon Kabushiki Kaisha | Physical registration of images acquired by Fourier Ptychography |
US11272305B2 (en) * | 2016-03-15 | 2022-03-08 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e. V. | Apparatus, method or computer program for generating a sound field description |
US10686968B1 (en) * | 2019-02-27 | 2020-06-16 | Augentix Inc. | Motion detection method and circuit thereof |
US11308858B2 (en) * | 2019-09-24 | 2022-04-19 | Lg Electronics Inc. | Signal processing device and image display apparatus including same |
US20220223097A1 (en) * | 2019-09-24 | 2022-07-14 | Lg Electronics Inc. | Signal processing device and image display apparatus including same |
US11710444B2 (en) * | 2019-09-24 | 2023-07-25 | Lg Electronics Inc. | Signal processing device and image display apparatus including same |
US10742473B1 (en) | 2019-10-03 | 2020-08-11 | United States Government As Represented By The Secretary Of The Navy | Enhanced signal acquisition based on adaptive multiresolution modulation |
US11044049B1 (en) | 2019-12-23 | 2021-06-22 | United States Of America As Represented By The Secretary Of The Navy | Hybrid unequal error protection (UEP) for heterogeneous multi-service provisioning |
US10826746B1 (en) | 2020-03-04 | 2020-11-03 | United States Of America As Represented By The Secretary Of The Navy | Transmission security based on adaptive multiresolution modulation |
CN113160277A (en) * | 2021-01-29 | 2021-07-23 | 北京小米松果电子有限公司 | Image processing method and device, electronic equipment and storage medium |
CN112884813A (en) * | 2021-02-18 | 2021-06-01 | 北京小米松果电子有限公司 | Image processing method, device and storage medium |
WO2023081091A3 (en) * | 2021-11-04 | 2023-06-22 | Op Solutions, Llc | Systems and methods for motion information transfer from visual to feature domain |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6658059B1 (en) | Motion field modeling and estimation using motion transform | |
Lertrattanapanich et al. | High resolution image formation from low resolution frames using Delaunay triangulation | |
Bovik | The essential guide to video processing | |
Kokaram et al. | Detection of missing data in image sequences | |
Papenberg et al. | Highly accurate optic flow computation with theoretically justified warping | |
Bruhn et al. | Lucas/Kanade meets Horn/Schunck: Combining local and global optic flow methods | |
KR0171154B1 (en) | Method and apparatus for encoding video signals using feature point based motion prediction | |
JP5547739B2 (en) | Digital processing method and system for optical flow determination | |
US20050094852A1 (en) | Global motion estimation image coding and processing | |
JP4744276B2 (en) | 2D image representation method, 2D image comparison method, image sequence processing method, motion representation derivation method, image position determination method, control device, apparatus, and computer-readable storage medium | |
JP2003274416A (en) | Adaptive motion estimation apparatus and method | |
Philip et al. | A comparative study of block matching and optical flow motion estimation algorithms | |
Wei et al. | An efficient two-pass MAP-MRF algorithm for motion estimation based on mean field theory | |
JP4250237B2 (en) | Image processing apparatus, method, and computer-readable storage medium | |
KR100819563B1 (en) | System for tracking car objects using mosaic video image and a method thereof | |
Al-Regib et al. | Hierarchical motion estimation with content-based meshes | |
JP4095204B2 (en) | Image processing apparatus, method, and computer-readable storage medium | |
Sim et al. | Robust reweighted MAP motion estimation | |
JP4201958B2 (en) | Moving image object extraction device | |
Zhang et al. | Video superresolution reconstruction using iterative back projection with critical-point filters based image matching | |
Stiller et al. | Combined displacement estimation and segmentation in image sequences | |
Patanavijit et al. | An iterative super-resolution reconstruction of image sequences using a Bayesian approach with BTV prior and affine block-based registration | |
JP3651093B2 (en) | Motion vector detection apparatus and method | |
He et al. | Choice of threshold of the Huber-Markov prior in map-based video resolution enhancement | |
JPH08242454A (en) | Method for detecting global motion parameter |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: DIGITAL VIDEO EXRESS, L.P., VIRGINIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:LIN, YUN-TING;REEL/FRAME:013094/0821Effective date: 20000306Owner name: DIGITAL VIDEO EXRESS, L.P., VIRGINIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:LU, SIU-LEONG;REEL/FRAME:013094/0816Effective date: 20000306 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
REMI | Maintenance fee reminder mailed | ||
AS | Assignment |
Owner name: CIRCUIT CITY STORES, INC. LIQUIDATING TRUST, VIRGIFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:DIGITAL VIDEO EXPRESS, LP;REEL/FRAME:026846/0075Effective date: 20110831 |
|
AS | Assignment |
Owner name: INNOVATIVE VIDEO SECURITY LLC C/O BINGHAM MCCUTCHEFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CIRCUIT CITY STORES, INC. LIQUIDATING TRUST;REEL/FRAME:026879/0274Effective date: 20110908 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
SULP | Surcharge for late payment |
Year of fee payment: 7 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INOVATIVE VIDEO SECURITY LLC C/O BINGHAM MCCUTCHEN LLP;REEL/FRAME:028083/0108Effective date: 20120309 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: CORRECTIVE ASSIGNMENT TO CORRECT THE NAME OF THE ASSIGNOR PREVIOUSLY RECORDED ON REEL 028083, FRAME 0108;ASSIGNOR:INNOVATIVE VIDEO SECURITY LLC;REEL/FRAME:028431/0159Effective date: 20120309 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044213/0313Effective date: 20170929 |