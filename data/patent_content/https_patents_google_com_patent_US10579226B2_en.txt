US10579226B2 - Time proximity based map user interactions - Google Patents
Time proximity based map user interactions Download PDFInfo
- Publication number
- US10579226B2 US10579226B2 US15/708,552 US201715708552A US10579226B2 US 10579226 B2 US10579226 B2 US 10579226B2 US 201715708552 A US201715708552 A US 201715708552A US 10579226 B2 US10579226 B2 US 10579226B2
- Authority
- US
- United States
- Prior art keywords
- time
- user interface
- user
- contextual information
- relevant time
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/0483—Interaction with page-structured environments, e.g. book metaphor
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/265—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network constructional aspects of navigation devices, e.g. housings, mountings, displays
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/34—Route searching; Route guidance
- G01C21/36—Input/output arrangements for on-board computers
- G01C21/3664—Details of the user input interface, e.g. buttons, knobs or sliders, including those provided on a touch screen; remote controllers; input using gestures
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/34—Route searching; Route guidance
- G01C21/36—Input/output arrangements for on-board computers
- G01C21/3697—Output of additional, non-guidance related information, e.g. low fuel level
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/29—Geographical information databases
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/0485—Scrolling or panning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/10—Office automation; Time management
- G06Q10/109—Time management, e.g. calendars, reminders, meetings or time accounting
- G06Q10/1093—Calendar-based scheduling for persons or groups
- G06Q10/1095—Meeting or appointment
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04847—Interaction techniques to control parameter settings, e.g. interaction with sliders or dials
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/02—Reservations, e.g. for tickets, services or events
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/04—Forecasting or optimisation specially adapted for administrative or management purposes, e.g. linear programming or "cutting stock problem"
- G06Q10/047—Optimisation of routes or paths, e.g. travelling salesman problem
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T11/00—2D [Two Dimensional] image generation
- G06T11/60—Editing figures and text; Combining figures or text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2200/00—Indexing scheme for image data processing or generation, in general
- G06T2200/24—Indexing scheme for image data processing or generation, in general involving graphical user interfaces [GUIs]
Definitions
- the present disclosure relates generally to user interfaces for geographic information system applications, such as mapping applications.
- GIS Geographic information systems
- GIS applications can include, for instance, mapping applications that display imagery (e.g., map imagery, satellite imagery, three-dimensional models, etc.) of a geographic area. GIS applications can be used for a variety of purposes, such as for navigation, searching of relevant information associated with a geographic area, etc.
- GIS applications can also provide and/or include contextual information associated with the imagery. For instance, the GIS application can include and/or provide information associated with points of interest, events, and/or users of the GIS application.
- the contextual information can be provided for display in conjunction with imagery of the geographic area to enrich the imagery and/or to facilitate user interaction with the GIS application.
- One example aspect of the present disclosure is directed to a computer-implemented method for processing user interface elements associated with contextual information in a geographic information system.
- the method includes providing for display, by one or more computing devices, a user interface on a display device.
- the user interface can display imagery of a geographic area.
- the method can include obtaining, by the one or more computing devices, data indicative of a relevant time for contextual information.
- the method can include obtaining, by the one or more computing devices, contextual information associated with the geographic area.
- the method can include obtaining, by the one or more computing devices, a configuration for a user interface element associated with the time based contextual information based at least in part on time proximity of the contextual information to the relevant time.
- the method can include providing for display, by the one or more computing devices, the user interface element based at least in part on the configuration.
- FIG. 1 depicts an overview of an example system for implementing a user interface associated with a GIS application according to example embodiments of the present disclosure
- FIG. 2 depicts example implementation of one or more display configurations of contextual information in a user interface according to example embodiments of the present disclosure
- FIG. 3 depicts an example a user interface according to example embodiments of the present disclosure
- FIG. 4 depicts example scrolling of a user interface providing time based contextual information based on time proximity according to example embodiments of the present disclosure
- FIG. 5 depicts an example interface element for changing a relevant time according to example embodiments of the present disclosure
- FIG. 6 depicts an example interface element for changing a relevant time according to example embodiments of the present disclosure
- FIG. 7 depicts an example interface element for changing a relevant time according to example embodiments of the present disclosure
- FIG. 8 depicts an example interface element for changing a relevant time according to example embodiments of the present disclosure
- FIG. 9 depicts a flow diagram of an example method according to example embodiments of the present disclosure.
- FIG. 10 depicts a flow diagram of an example method according to example embodiments of the present disclosure.
- FIG. 11 depicts an example computing system according to example embodiments of the present disclosure.
- Example aspects of the present disclosure are directed to systems and methods for implementing time based contextual information in a user interface associated with geographic information system (GIS) applications, such as mapping applications, to obtain more efficient user inputs.
- the user interface can display contextual information (e.g., cards, callouts, icons, etc.) and/or map information in conjunction with imagery or other data associated with a geographic area (e.g., a map).
- the contextual information and/or map information can be associated with a particular date and time.
- contextual information associated with a particular date and time can be selected and/or prioritized for receiving user interaction relative to contextual information associated with a different date and time.
- the GIS application can be configured to tailor the user interface to provide more efficient interactions from a user based on time proximity of contextual information.
- the user interface can be configured to display imagery of a geographic area, such as a map of the geographic area or other imagery (e.g., satellite imagery, street level imagery, three-dimensional models, aerial imagery, etc.)
- Contextual information associated with time based events can be displayed in conjunction with the imagery.
- the contextual information can be associated with a particular date and time.
- Contextual information can include, for instance, information associated with dinner reservations, travel information (e.g., flight times), calendar information (e.g., meetings, appointments, etc.), events (e.g., concerts, festivals, fairs, rallies), suggested activities, suggested trips, etc.
- the contextual information can be associated with personalized information of a user, such as a user's appointments, commute, schedule, calendar, reservations, etc.
- the contextual information can be provided in the user interface as user interface elements capable of receiving a user interaction (e.g., a touch input, click input, swipe input, or other gesture indicative of a user interaction).
- a user interaction e.g., a touch input, click input, swipe input, or other gesture indicative of a user interaction.
- the user interface can be modified to provide details or other interface elements associated with the contextual information.
- the user may be required to allow the analysis of data for transmission over a communication channel, or other information associated with a user or user's computing device or communication device. Therefore, in some implementations, users can be provided with an opportunity to control settings associated with whether programs or features collect such information. If the user does not allow collection and use of such information, then the user may not receive the benefits of the techniques described herein. In some implementations, the user can also be provided with tools to revoke or modify consent. In addition, in some implementations, certain information or data can be treated in one or more ways before it is stored or used, so that personally identifiable information is removed.
- user interface elements for contextual information associated with dates and times closer to a current or selected date and time can be prioritized higher relative to information associated with further away dates.
- Configurations for user interface elements associated with the contextual information can be determined so that higher prioritized information is featured with higher prominence and easier for user interaction relative to other information and/or interface elements.
- contextual information can be provided with different user interface element treatments based on the time proximity associated with the contextual information. For instance, contextual information closer in time proximity can be provided with higher prominence (e.g., as a card user interface element). Contextual information further away in time proximity can be configured for display with lower prominence (e.g., as smaller icons, off screen so that the user has to scroll the see the information, etc.).
- the user interface associated with the GIS application can adapt (e.g., without further user interaction) to display different and/or display with higher prominence contextual information depending on time proximity of the information.
- the contextual information becomes prioritized relative to other contextual information.
- the user interface is automatically adapted as time progresses to prioritize user interface elements for user interaction based on time proximity.
- a user interface can be configured to display an icon associated with “Pete's Restaurant” based on a dinner reservation for a user at Pete's Restaurant.
- the user interface can be configured to display text providing a date and time associated with the dinner reservation in conjunction with the icon (e.g., Wednesday at 8:30).
- the user interface can be configured to display a callout in conjunction with the restaurant. The callout is more prominently displayed relative to the icon.
- the user can interact with the callout to obtain more information about the restaurant (e.g., menu, reviews, busiest times, etc.). Within a few hours of the time associated with the dinner reservation, the user interface can display more information, such as travel directions to the restaurant.
- a plurality of user interface elements can be organized in the user interface based at least in part on time proximity to a current time. For instance, user interface elements can be grouped into a plurality of relevant time groups.
- the relevant time groups can be associated with discrete time periods. For instance, the relevant time groups can include one or more of a this morning time group, today time group, tonight time group, this week time group, this weekend time group, next month time group, etc.
- the this morning time group can be associated with contextual information relevant for this morning.
- the today time group can be associated with contextual information relevant for today.
- the tonight time group can be associated with contextual information relevant for tonight or this evening.
- the this week time group can be associated with contextual information relevant for this week.
- the this weekend time group can be associated with contextual information relevant for this weekend.
- the next month time group can be associated with contextual information relevant for next month, and so forth.
- the user interface can be configured to receive a user interaction to change the relevant time for display of time based contextual information. As the user changes the relevant time, different time based contextual information is prioritized for display in conjunction with the geographic area. In this way, time can be treated as a lens to view different information as the user interacts with the user interface.
- Various user interactions can be implemented to change the relevant time for display of time based contextual information. For instance, in some embodiments, the user can simply scroll (e.g., vertically and/or horizontally) to change the relevant time for display of information. In one example, by scrolling down vertically, the user interface can display information associated with time further in time proximity to the relevant time. For instance, the user can view user interface elements associated with different relevant time groups further in proximity from the relevant time.
- the user can change the relevant time. For instance, the user can change the display of contextual information proximate the current time to the display of contextual information associated with a later time (e.g., the weekend) by scrolling horizontally.
- a later time e.g., the weekend
- a relevant time change interface element can be provided in conjunction with the imagery to allow the user to change the relevant time for display of contextual information.
- a semi-transparent circular element can be provided for display overlaying the imagery.
- the user can change the relevant time for display of contextual information by interacting with the circular element. As an example, rotating a marker about the interface element in a clockwise direction can advance the relevant time towards the future. Rotating the marker about the interface element in a counter-clockwise direction can advance the relevant time backwards.
- user interface elements associated with different contextual information can be displayed in conjunction with the imagery. For instance, a user can interact with an interface element to advance a relevant time from a current time to a time associated with the upcoming weekend.
- the user interface can change the display of contextual information to prioritize user interface elements associated with contextual information in time proximity to the upcoming weekend relative to other times. Different points of interest, different colors, and/or different display elements can be provided in conjunction with the imagery as the user changes the relevant time.
- the user interface can be configured to change the display of the geographic imagery itself in response to a user interaction changing the relevant time. For instance, as the relevant time changes to a time later in the future, the geographic imagery can be zoomed out to display more information associated with a wider geographic area. This can accommodate the ability of the user to travel over a larger geographic area over the course of time. In this way, the map imagery itself can be modified to display potentially more relevant information to the user based on time.
- the user interface can provide contextual information in conjunction with the imagery based at least in part on user familiarity with a particular geographic area. For instance, based on information associated with the user (e.g., historical user data, preferences submitted by the user, user settings, user location history, etc.) a signal indicative of user familiarity with a geographic area can be determined. Different contextual information can be given different treatment in the user interface based at least in part on the signal indicative user familiarity. For instance, the GIS application can provide increased user interface elements associated with assistance of the user in traveling and conducting tasks (e.g., eating, attending a meeting, etc.) in the geographic area if it is determined that the user is in an unfamiliar area. The GIS application can provide decreased user interface elements associated with assistance of the user in the geographic area if it is determined that the user is in a familiar space.
- information associated with the user e.g., historical user data, preferences submitted by the user, user settings, user location history, etc.
- Different contextual information can be given different treatment in the user interface based at least in part
- Example aspects of the present disclosure have a number of technical effects and benefits. For instance, by automatically configuring a user interface associated with a GIS application to provide contextual information based on time proximity, information can be processed by the GIS application with fewer user interactions, leading to preservation of memory and processing resources. More particularly, relevant contextual information can be provided for user interaction without requiring multiple user inputs (e.g., search queries, selection inputs, etc.) to locate the information. Because less user inputs are required to obtain relevant information, processing and memory storage resources can be preserved for other aspects of computing technology (e.g., communication of information over a network) used to implement the GIS application.
- computing technology e.g., communication of information over a network
- One example aspect of the present disclosure is directed to a computer-implemented method for processing user interactions in a geographic information system.
- the method includes displaying, by a computing device using a display unit, a user interface displaying geographic imagery of a geographic area. Responsive to receiving an input indicative of a relevant time for display of contextual information the method includes requesting, by the computing device using a communication unit, time based contextual information associated with the geographic area; and requesting, by the computing device using the communication unit, one or more display configurations for the time based contextual information based at least in part on time proximity of the contextual information to the relevant time. Responsive to receiving time based contextual information and one or more display configurations, the method includes displaying, by the computing device using the display unit, received contextual information in conjunction with the geographic imagery based at least in part on the received one or more display configurations.
- the relevant time includes a current time.
- the method includes adjusting, by the computing device, the one or more display configurations for the contextual information as the relevant time changes from a first time to a second time, the second time being later than the first time.
- the method includes adjusting the one or more display configurations comprises adjusting, by the computing device, a user interface treatment of the contextual information.
- the method includes adjusting, by the computing device, the geographic imagery displayed in the user interface as the relevant time changes from a first time to a second time. Adjusting the geographic imagery can include zooming the geographic imagery.
- the method includes responsive to receiving, by the computing device using an input unit, data indicative of a first type of user interaction directed to the user interface, displaying, by the computing device, different time based contextual information in conjunction with the geographic imagery.
- the first type of user interaction includes a vertical scrolling user interaction.
- the method responsive to receiving, by the computing device using an input unit, data indicative of a second type of user interaction directed to the user interface, the method includes adjusting, by the computing device, the relevant time from a first time to a second time.
- the method includes adjusting, by the computing device, the one or more display configurations for the contextual information as the relevant time changes from the first time to the second time, the second time being later than the first time.
- the method includes displaying, by the computing device using the display unit, a user interface element configured to receive the second type of user interaction for adjusting the relevant time.
- the user interface element can include a circular interface element.
- the one or more display configurations are obtained, at least in part, based at least in part on data indicative of a user familiarity with the geographic area.
- a computer-readable medium can include instructions which, when executed by a processor, cause the processor to carry out one or more aspects of any of the methods described herein.
- FIG. 1 depicts an overview of an example system according to example embodiments of the present disclosure.
- the system can be configured to change the configuration of a user interface 110 associated with a geographic information system application 120 .
- the GIS application 120 can be, for instance, a mapping application, navigation application, virtual globe application, etc.
- the GIS application 120 can be implemented on one or more computing devices.
- the GIS application 120 can be implemented on a mobile computing device that is capable of being carried by a user (e.g., in the user's hand) during operation.
- Example mobile computing devices can include, for instance, smartphones, tablets, display devices with one or more processors, wearable devices, PDAs, smart watches, smart glasses, laptops, or other devices.
- the arrangement of user interface elements capable of receiving a user interaction from a user 115 in the user interface 110 can be determined based on time proximity and/or user familiarity to provide for more efficient user interaction with the user interface 110 .
- UI logic 125 can obtain map data 122 and/or contextual data 124 from a geographic information system 150 .
- the GIS 150 , the map data 122 and/or the contextual data 124 can be stored or implemented locally in one or more memory devices associated with the computing device implementing the GIS application 120 .
- the GIS 150 , the map data 122 , and/or the contextual data 124 can be stored or implemented on one or more other computing devices (e.g., a server).
- the map data 122 and/or the contextual data 124 can be communicated, for instance, from the GIS 150 as data packets over a network (e.g., the Internet).
- the map data 122 can include, for instance, data used to render imagery of a geographic area (e.g., map imagery, satellite imagery, aerial imagery, three-dimensional models, etc.).
- the map data 122 can also include data used to enrich the imagery, such as data associated with points of interest, locals, etc.
- the contextual data 124 can be contextual data to be provided in conjunction with the map data 124 .
- the contextual data 124 can be associated with a particular date and time.
- Example time based contextual information can include, for instance, information associated with dinner reservations, travel information (e.g., flight times), calendar information (e.g., meetings, appointments, etc.), events (e.g., concerts, festivals, fairs, rallies), suggested activities, suggested trips, etc.
- the contextual information can be associated with personalized information of a user, such as a user's appointments, commute, schedule, calendar, reservations, etc.
- the UI logic 125 can obtain a signal 132 indicative of a relevant time.
- the signal 132 indicative of the relevant time can be a signal indicative of a current time 135 (e.g., from a real time clock).
- the signal 132 indicative of the relevant time 132 can be based at least in part on a user interaction with the user interface 110 .
- a user 115 can interact with the user interface 110 to provide a signal 137 used to change the signal 132 indicative of the relevant time (e.g., either forward or backward in time).
- the UI logic 125 can determine one or more configurations for user interface elements associated with the contextual information based at least in part on the signal 132 indicative of relevant time. For instance, as provided in example below, the UI logic 125 can determine configurations for user interface elements to prioritize user interaction based at least in part on time proximity of contextual information to the relevant time.
- the UI logic 125 can obtain a signal 140 indicative of user familiarity with a geographic area.
- the signal 140 can be determined based on information associated with the user 115 , such as location history, browsing history, number of visits to a geographic area, search queries directed to the geographic area, distance to the geographic area from a user's home or place of business, the number of friends or social media connections tied to the geographic area, etc.
- the UI logic 125 can change one or more display configurations for user interface elements in the user interface 110 based at least in part on the signal 140 .
- the UI logic 125 can provide increased user interface elements associated with assistance of the user in traveling and conducting tasks (e.g., eating, attending a meeting, etc.) in the geographic area if it is determined that the user is in an unfamiliar area.
- the UI logic 125 can provide decreased user interface elements associated with assistance of the user in the geographic area if it is determined that the user is in a familiar space.
- the UI logic 125 can include computer-readable instructions that when executed by one or more processors cause the one or more processors to perform operations.
- the instructions can be implemented in software and/or hardware. When software is used, any suitable programming language can be used to implement the instructions.
- Example operations that can be performed by UI logic 125 are discussed with referenced to FIGS. 8 and 9 below.
- Example user interfaces that can be implemented by UI logic 125 will now be set forth.
- FIG. 2 depicts example user interfaces 210 a , 210 b , and 210 c provided for display on a display device 205 according to example embodiments of the present disclosure.
- the user interfaces 210 a , 210 b , 210 c can each include imagery 215 (e.g., map imagery) of a geographic area.
- the imagery 215 can include markers or other user interface elements for various points of interest.
- the user interfaces 210 a , 210 b , and 210 c can also include search tool 212 for conducting search queries.
- Other interface elements can be included in the user interfaces 210 a , 210 b , and 210 c without deviating from the scope of the present disclosure.
- User interface 210 a , user interface 210 b , and user interface 210 c are each associated with different relevant times.
- user interface 210 a can be associated with a first relevant time.
- user interface 210 b can be associated with a second relevant time that is later in the future relative to the first relevant time.
- User interface 210 c can be associated with a third relevant time that is later in the future relative to the first relevant time and the second relevant time.
- one or more display configurations for user interface elements associated with contextual information can be modified as the relevant time progress from the first relevant time to the second relevant time and to the third relevant time. More particularly, user interface 210 a associated with a first relevant time can present a user interface element 230 associated with contextual information directed to a dinner reservation at “Restaurant A.”
- the contextual information can be associated with a date and time that is far in time proximity relative to the relevant time. For example, the dinner reservation can be for a time a week out from the relevant time.
- the interface element 230 includes a waypoint marker along with text describing the restaurant and the time of the reservation (e.g., 8:30 Wednesday).
- the interface element(s) associated with the contextual information can be modified to make user interaction with the contextual information more prominent as time proximity gets closer to the time associated with the contextual information.
- user interface 210 b can be associated with a relevant time that is the same day as the date and time associated with the contextual information directed to the dinner reservation at “Restaurant A.”
- the user interface 210 b presents an interface element 235 that is more prominent and capable of receiving user interaction relative to the interface element 230 in user interface 210 a .
- the user interface 210 b has been changed to include a callout interface element 235 that lists more information about the dinner reservation (e.g., “Dinner for 3”).
- a user is capable of interacting with the callout interface element 235 (e.g., through a touch or click interaction) to obtain more information about the restaurant (e.g., a dinner menu, popular times, address, navigation directions, etc.).
- the interface element(s) associated with the contextual information can be changed to make user interaction with the contextual information even more prominent as time proximity gets closer to the time associated with the contextual information.
- user interface 210 c can be associated with a relevant time that is within one hour of the date and time associated with the contextual information directed to the dinner reservation at “Restaurant A.”
- the user interface 210 c presents interface element 235 that is capable of receiving user interaction relative to the interface element 230 in user interface 210 a .
- the user interface 210 c has been changed to include a callout interface element 235 that lists more information about the dinner reservation (e.g., “Dinner for 3”).
- a user is capable of interacting with the callout interface element 235 (e.g., through a touch or click interaction) to obtain more information about the restaurant (e.g., a dinner menu, popular times, address, navigation directions, etc.).
- the user interface 210 c presents interface element(s) 240 associated with navigation directions to “Restaurant A.”
- the interface element(s) 240 can include a walking route rendered in polyline with the imagery 215 .
- the interface element(s) 240 can include approximate travel time (e.g., 18 minutes) to travel to “Restaurant A.”
- a user can obtain more information about the navigation route and/or other navigation information by interacting with the interface elements 240 .
- the user interface 210 c is automatically modified to facilitate efficient user interaction with the GIS application (e.g., by providing multiple interface elements 235 and 240 ) to obtain information relevant to the dinner reservation.
- a user interface associated with a GIS application can organize interface elements associated with time based contextual information at least in part based on time proximity. For instance, the GIS application can organize interface elements in the user interface into relevant time groups, such as relevant time groups associated with this morning, this evening, tomorrow, this weekend, and so forth.
- a user can access interface elements for contextual information that is further in time proximity from the relevant time by performing a suitable user interaction with the user interface. For instance, a user can scroll (e.g., scroll vertically) to view information associated with contextual information that is further in time proximity from the relevant time.
- FIG. 3 depicts a portion of a user interface 310 a for a GIS application on a display device 305 .
- the user interface 310 a provides imagery 315 of a geographic area (e.g., map imagery).
- the user interface 310 a includes a search tool 312 for conducting search queries.
- the imagery 315 can include markers or other user interface elements for various points of interest.
- a bottom portion of the user interface 310 a extending off screen includes one or more card interface elements 317 .
- Card interface elements 317 can present information associated with time based contextual information. For instance, card interface elements 317 can provide suggestions for “this morning.” The suggestions can be, for instance, associated with breakfast spots, a place for a morning jog, a café, or other event. A user can obtain more information about the suggestions via a user interaction with the card interface elements 317 (e.g., via a touch or click interaction).
- a user can access more contextual information organized based at least in part on time proximity via a user interaction, such as vertical scroll interaction 320 .
- the vertical scroll interaction 320 can bring items in the user interface 310 a that are currently off screen into view.
- a user can obtain information further in time proximity to a relevant time (e.g., the current time) as the user scrolls vertically.
- FIG. 4 depicts the vertical scrolling of a user interface to obtain information further in time proximity according to example embodiments of the present disclosure.
- user interface portion 310 b contains contextual information associated with a time further in time proximity.
- user interface portion 310 b provides information associated with a relevant time group, “This Evening.”
- the user interface portion 310 b can include a banner interface element 319 indicating that the current information is associated with a particular time period, in this example “This Evening.”
- the banner interface element 319 can provide other information, such as the weather for the time period.
- the banner interface element 319 can remain towards the top of the interface element during a vertical scrolling operation until information associated with the next time period is reached.
- the user interface portion 310 b depicts map imagery 321 .
- Map imagery 321 is zoomed out relative to imagery 315 of FIG. 3 . This is because a user has the ability to travel over a wider geographic region prior to time period associated with map imagery 321 , namely “This Evening.” In that regard, zoomed out map imagery is provided in the user interface 310 b to provide additional relevant information to the user.
- the user interface portion 310 b also includes card interface elements 323 .
- Card user interface elements 323 can provide information associated with time based contextual information. For instance, card user interface elements 323 can provide suggestions for “this evening.” The suggestions can be, for instance, associated with restaurants, a place to grab dessert, a concert, or other event. A user can obtain more information about the suggestions via a user interaction with the card interface elements 323 (e.g., via a touch or click interaction).
- User interface portion 310 c is depicted after further vertical scrolling. As shown, user interface portion 310 c still includes banner interface element 319 . A top portion of card interface elements 323 are still visible. Card interface elements 325 have come into view. Card interface elements 325 can be associated with time based contextual information suitable for “This Evening.” For example, as shown, card interface elements 325 can provide information associated with nearby neighborhoods for dinner. The geographic scope of the suggestions (e.g., nearby neighborhoods) can be determined based on time proximity to the relevant time. For instance, a user can travel to a nearby neighborhood by “This Evening.” In that regard, the suggestions associated with card interface elements 325 can be associated with nearby neighborhoods.
- User interface portion 310 d is depicted after further vertical scrolling. As shown, user interface portion 310 d still includes a top portion of card interface elements 325 . A new banner interface element 327 associated with a different time period for contextual information (e.g., “This Weekend”) has been scrolled into view. The banner interface element 327 can present information associated with a time period further in time proximity, such as “This Weekend.” Additional information can be included with the banner interface element 327 , such as the weather for the time period.
- contextual information e.g., “This Weekend”
- the banner interface element 327 can present information associated with a time period further in time proximity, such as “This Weekend.” Additional information can be included with the banner interface element 327 , such as the weather for the time period.
- the user interface portion 310 d depicts map imagery 329 .
- Map imagery 321 is zoomed out relative to imagery 315 of FIG. 3 and imagery 329 provided in user interface portion 310 b . This is because a user has the ability to travel over a wider geographic region prior to the time period associated with map imagery 329 , namely “This Weekend.” In that regard, zoomed out map imagery is provided in the user interface 310 d to provide additional relevant information to the user.
- Card interface elements 333 have come into view. Card interface elements 333 can be associated with time based contextual information suitable for “This Weekend.” For example, as shown, card interface elements 333 can provide information associated with suggestions for “This Weekend.” The geographic scope of the suggestions can be determined based on time proximity to the relevant time. For instance, a user can travel to nearby cities by “This Weekend.” In that regard, the suggestions associated with card interface elements 333 can be associated with nearby cities. A user can obtain more information associated with the suggestions via a user interaction with the card interface elements 333 .
- User interface portion 310 f is depicted after further vertical scrolling. User interface portion 310 f still includes banner interface element 327 . Card interface elements 333 have been scrolled to the top of the user interface portion 310 f . A portion of card interface elements 335 have come into view. Card interface elements 335 can provide suggestions for day trips for “This Weekend.” A user can obtain more information associated with the suggestions via a user interaction with the card interface elements 335 .
- User interface portion 310 g is depicted after further vertical scrolling. User interface portion 310 g still includes banner interface element 327 . Card interface elements 333 have almost been scrolled off screen. Card interface elements 335 have come into more prominent view in the user interface portion 310 g.
- the user interface can provide a user interface element for changing the relevant time either forward or backward in time relative to a current time or other time.
- a user interface element for changing the relevant time either forward or backward in time relative to a current time or other time.
- one or more display configurations for user interface elements can be modified to facilitate interaction with the user interface elements based on time proximity to a user selected relevant time.
- FIG. 5 depicts a user interface 410 a provided for display on a display device 405 .
- the user interface 410 a depicts geographic imagery 415 (e.g. map imagery) of a geographic area.
- the imagery 415 can include markers or other user interface elements for various points of interest.
- a relevant time change interface element 450 can be presented in conjunction with the imagery 415 .
- a user can interact with the relevant time change interface element 450 to change the relevant time (e.g., from a current time to a time in the future).
- the relevant time e.g., from a current time to a time in the future.
- one or more display configurations for interface elements in the user interface 410 a can also be changed based on time proximity to the selected relevant time. For instance, a color of the imagery 415 , the markers displayed in conjunction with the imagery 415 , the zoom level of the imagery 415 , and/or the user interface treatment of one or more user interface elements can be modified as the user changes the relevant time.
- the relevant time change interface element 450 includes a circular element 454 .
- the circular element 454 can include tick marks to approximate the appearance of a clock.
- a clock marker 452 can be controlled to move about the circular element 454 . As the clock marker 452 is moved clockwise, the relevant time is modified forward. As the clock marker 452 is moved counterclockwise, the relevant time is changed backward.
- a callout element 455 can be provided in conjunction with the marker 452 . The callout element 455 can display the relevant time associated with the current position of the marker 452 .
- the marker 452 has been changed from a first position associated with a relevant time of “Today at 12:20 pm” to a second position associated with a relevant time of “Today at 8:20 pm.”
- the imagery 415 has been changed in response to the change in relevant time. More particularly, the imagery 415 has been zoomed out.
- different markers associated with points of interest more suitable for the relevant time are displayed in conjunction with the relevant time.
- FIG. 6 depicts example user interfaces 510 a , 510 b , and 510 c .
- Each of the user interfaces 510 a , 510 b , and 510 c can be associated with a different relevant time.
- user interface 510 a can be associated with “Right Now.”
- User interface 510 b can be associated with “Tonight.”
- User interface 510 c can be associated with “Weekend.”
- Each of the user interfaces 510 a , 510 b , and 510 c can have different display configurations for its user interface elements.
- user interface 510 a includes imagery 515 a (e.g., map imagery).
- User interface 510 b includes imagery 515 b (e.g., map imagery).
- Imagery 515 b is zoomed out relative to imagery 515 a .
- imagery 515 b displays markers and other information associated with different points of interest and events relative to imagery 515 a .
- Imagery 515 c is zoomed out relative to imagery 515 b and 515 a .
- imagery 515 c displays markers and other information associated with different points of interests and events relative to imagery 515 a and 515 b.
- User interface 510 a includes card interface elements 517 a .
- Card interface elements 517 a can be associated with time-based contextual data (e.g., suggestions) for “Right Now.”
- Card interface elements 517 b can be associated with time-based contextual data (e.g., suggestions) for “Tonight.”
- Card interface elements 517 c can be associated with time-based contextual data (e.g., suggestions) for “Weekend.”
- a user can change the relevant time by interacting with tab interface element 520 .
- Tab interface element 520 includes tabs for each of the relevant time periods, including “Right Now”, “Tonight,” “Tomorrow,” “Weekend,” “Next Month,” etc. Other suitable time periods can be used without deviating from the scope of the present disclosure.
- a user can change the user interface (e.g., among user interface 510 a , 510 b , and 510 c ) by selecting a desired relevant time through interaction with the tab interface 520 .
- FIG. 7 is similar to FIG. 6 .
- a user can change the user interface (e.g., among user interface 510 a , 510 b , and 510 c ) through user interaction with a button interface 530 .
- the button interface 530 can include buttons for each of the relevant time periods, including “Now,” “Tonight,” “Tomorrow,” “This Week,” “This Weekend,” etc. Other suitable time periods can be used without deviating from the scope of the present disclosure.
- a user can change the user interface (e.g., among user interface 510 a , 510 b , and 510 c ) by selecting a desired relevant time through user interaction with the button interface 530 .
- FIG. 8 depicts a user interface 410 provided for display on a display device 405 .
- the user interface 410 depicts geographic imagery 415 (e.g. map imagery) of a geographic area.
- the imagery 415 can include markers or other user interface elements for various points of interest.
- a relevant time change interface element 470 can be presented in conjunction with the imagery 415 .
- a user can interact with the relevant time change interface element 470 to change the relevant time (e.g., from a current time to a time in the future).
- the relevant time e.g., from a current time to a time in the future.
- one or more display configurations for interface elements in the user interface 410 can also be changed based on time proximity to the selected relevant time. For instance, a color of the imagery 415 , the markers displayed in conjunction with the imagery 415 , the zoom level of the imagery 415 , and/or the user interface treatment of one or more user interface elements can be modified as the user changes the relevant time.
- the relevant time change interface element 470 includes a horizontal scrubber interface element.
- a marker 472 can be controlled by user interaction to move horizontally along the interface element 470 . As the marker 472 is moved in a first direction, the relevant time is changed forward. As the clock marker 472 is moved in a second direction, the relevant time is changed backward.
- a callout element 475 can be provided in conjunction with the marker 472 . The callout element 475 can display the relevant time and/or time group associated with the current position of the marker 472 .
- FIG. 9 depicts a flow diagram of an example method ( 600 ) according to example embodiments of the present disclosure.
- the method ( 600 ) can be implemented using one or more computing devices, such as one or more of the computing devices depicted in FIG. 11 .
- FIG. 9 depicts steps performed in a particular order for purposes of illustration and discussion. Those of ordinary skill in the art, using the disclosures provided herein, will understand that various steps of any of the methods disclosed herein can be adapted, expanded, rearranged, omitted, performed simultaneously, and/or modified in various ways without deviating from the scope of the present disclosure.
- the use of the term “obtaining” in conjunction with data and/or information can include receiving, determining, calculating, accessing, reading or otherwise obtaining data.
- the method can include providing for display a user interface on a display device.
- the user interface can be associated with a GIS application, such as a mapping application.
- the user interface can display imagery of the geographic area, such map imagery, satellite imagery, aerial imagery, three-dimensional models, street level imagery, or other imagery depicting a geographic area.
- the imagery can be obtained, for instance, from a geographic information system database or other database (e.g., over a network).
- the imagery can be obtained, for instance, from local memory storage on a computing device implementing the GIS application.
- the method can include obtaining data indicative of a relevant time.
- the data indicative of the relevant time can be data indicative of the current time (e.g., from a real time clock).
- the data indicative of a relevant time can be an modified relevant time as determined from a user interaction with the user interface (e.g., via a relevant time change interface element).
- the method can include obtaining contextual information for display in conjunction with the imagery.
- the contextual information can include, for instance, information associated with dinner reservations, travel information (e.g., flight times), calendar information (e.g., meetings, appointments, etc.), events (e.g., concerts, festivals, fairs, rallies), suggested activities, suggested trips, etc.
- the contextual information can be associated with personalized information of a user, such as a user's appointments, commute, schedule, calendar, reservations, etc.
- the contextual information can be associated with a particular date and time.
- the contextual information can be obtained, for instance, from a geographic information system database or other database (e.g., over a network).
- the contextual information can be obtained, for instance, from local memory storage on a computing device implementing the GIS application.
- the method can include obtaining a configuration for one or more user interface elements associated with the contextual information based on time proximity of the contextual information to the relevant time. For instance, UI logic implemented by the GIS application can configure user interface elements based on time proximity to prioritize and/or emphasize user interface elements closer in time proximity to the relevant time. Example configurations for user interface elements obtained based on time proximity are discussed with reference to FIGS. 2-8 .
- the method can include providing for display the user interface elements in the user interface based on the obtained configuration.
- the one or more user interface elements are capable of receiving a user interaction via the user interface. In this way, the user interface elements can be arranged for more efficient interaction with the user interface and use of computing resources dedicated to receiving user inputs.
- FIG. 10 depicts a flow diagram of an example method ( 620 ) for changing a relevant time via a relevant time change interface according to example embodiments of the present disclosure.
- the method ( 620 ) can be implemented using one or more computing devices, such as one or more of the computing devices depicted in FIG. 11 .
- FIG. 10 depicts steps performed in a particular order for purposes of illustration and discussion. Those of ordinary skill in the art, using the disclosures provided herein, will understand that various steps of any of the methods disclosed herein can be adapted, expanded, rearranged, omitted, performed simultaneously, and/or modified in various ways without deviating from the scope of the present disclosure.
- the method includes providing for display a relevant time change interface in the user interface.
- Example relevant time change interfaces are illustrated in FIGS. 5-8 .
- the method can include obtaining data indicative of a user interaction with the relevant time change interface. For instance, a user can interact with the relevant time change interface using a gesture (e.g., a touch gesture) to signify a change to the relevant time.
- a gesture e.g., a touch gesture
- the method can include changing the relevant time from a first time to a second time.
- the relevant time can be changed from a current time to a time in the future, such as a relevant time associated with this weekend.
- the method can include changing the configuration of user interface elements based on the modified relevant time. For instance, the configuration of user interface elements can be changed based on time proximity to the changed relevant time to prioritize and/or emphasize user interface elements closer in time proximity to the relevant time.
- the method can include providing for display the user interface elements in the user interface based on the configuration.
- the one or more user interface elements are capable of receiving a user interaction via the user interface. In this way, the user interface elements can be arranged for more efficient interaction with the user interface and use of computing resources dedicated to receiving user inputs.
- FIG. 11 depicts an example computing system 700 that can be used to implement one or more aspects of the present disclosure.
- the system 700 can be implemented using a client-server architecture that includes a server 710 that communicates with one or more client devices 730 over a network 740 .
- the system 700 can be implemented using other suitable architectures, such as a single computing device.
- the system 700 includes a server 710 , such as a web server.
- the server 710 can host a geographic information system, such as a geographic information system associated with a mapping service.
- the server 710 can be implemented using any suitable computing device(s).
- the server 710 can have one or more processors 712 and one or more memory devices 714 .
- the server 710 can also include a network interface used to communicate with one or more client devices 730 over the network 740 .
- the network interface can include any suitable components for interfacing with one more networks, including for example, transmitters, receivers, ports, controllers, antennas, or other suitable components.
- the one or more processors 712 can include any suitable processing device, such as a microprocessor, microcontroller, integrated circuit, logic device, or other suitable processing device.
- the one or more memory devices 714 can include one or more computer-readable media, including, but not limited to, non-transitory computer-readable media, RAM, ROM, hard drives, flash drives, or other memory devices.
- the one or more memory devices 714 can store information accessible by the one or more processors 712 , including computer-readable instructions 716 that can be executed by the one or more processors 712 .
- the instructions 716 can be any set of instructions that when executed by the one or more processors 712 , cause the one or more processors 712 to perform operations.
- the one or more memory devices 714 can also store data 718 that can be retrieved, manipulated, created, or stored by the one or more processors 712 .
- the data 718 can include, for instance, map data, contextual data, and/or other data.
- the data 718 can be stored in one or more databases.
- the one or more databases can be connected to the server 710 by a high bandwidth LAN or WAN, or can also be connected to server 710 through network 740 .
- the one or more databases can be split up so that they are located in multiple locales.
- the server 710 can exchange data with one or more client devices 730 over the network 740 . Although two client devices 730 are illustrated in FIG. 11 , any number of client devices 730 can be connected to the server 710 over the network 740 .
- Each of the client devices 730 can be any suitable type of computing device, such as a general purpose computer, special purpose computer, laptop, desktop, mobile device, navigation system, smartphone, tablet, wearable computing device, a display with one or more processors, or other suitable computing device.
- a client device 730 can include one or more processor(s) 732 and a memory 734 .
- the one or more processor(s) 732 can include one or more central processing units (CPUs), graphics processing units (GPUs), and/or other processing devices.
- the memory 734 can include one or more computer-readable media and can store information accessible by the one or more processors 732 , including instructions 736 that can be executed by the one or more processors 732 and data 738 . For instance, the memory 734 can store instructions 736 for implementing UI logic as discussed with reference to FIG. 1 .
- the client device 730 of FIG. 11 can include various input/output devices for providing and receiving information from a user, such as a touch screen, touch pad, data entry keys, speakers, and/or a microphone suitable for voice recognition.
- the client device 730 can have a display device 735 for display a user interface configured based on time proximity according to example aspects of the present disclosure.
- the client device 730 can also include a network interface used to communicate with one or more remote computing devices (e.g. server 710 ) over the network 740 .
- the network interface can include any suitable components for interfacing with one or more networks, including for example, transmitters, receivers, ports, controllers, antennas, or other suitable components.
- the network 740 can be any type of communications network, such as a local area network (e.g. intranet), wide area network (e.g. Internet), cellular network, or some combination thereof.
- the network 740 can also include a direct connection between a client device 730 and the server 710 .
- communication between the server 710 and a client device 730 can be carried via network interface using any type of wired and/or wireless connection, using a variety of communication protocols (e.g. TCP/IP, HTTP, SMTP, FTP), encodings or formats (e.g. HTML, XML), and/or protection schemes (e.g. VPN, secure HTTP, SSL).
- server processes discussed herein may be implemented using a single server or multiple servers working in combination.
- Databases and applications may be implemented on a single system or distributed across multiple systems. Distributed components may operate sequentially or in parallel.
Abstract
Description
Claims (20)
Priority Applications (6)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/708,552 US10579226B2 (en) | 2017-09-19 | 2017-09-19 | Time proximity based map user interactions |
CN201880044449.4A CN110869922B (en) | 2017-09-19 | 2018-05-10 | Map user interaction based on temporal proximity |
PCT/US2018/032038 WO2019059967A1 (en) | 2017-09-19 | 2018-05-10 | Time proximity based map user interactions |
EP18731241.8A EP3625692A1 (en) | 2017-09-19 | 2018-05-10 | Time proximity based map user interactions |
JP2019572596A JP7046991B2 (en) | 2017-09-19 | 2018-05-10 | Map user interaction based on temporal accessibility |
KR1020197038447A KR102318341B1 (en) | 2017-09-19 | 2018-05-10 | Temporal proximity-based map user interaction |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/708,552 US10579226B2 (en) | 2017-09-19 | 2017-09-19 | Time proximity based map user interactions |
Publications (2)
Publication Number | Publication Date |
---|---|
US20190087058A1 US20190087058A1 (en) | 2019-03-21 |
US10579226B2 true US10579226B2 (en) | 2020-03-03 |
Family
ID=62599682
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/708,552 Active 2038-01-05 US10579226B2 (en) | 2017-09-19 | 2017-09-19 | Time proximity based map user interactions |
Country Status (6)
Country | Link |
---|---|
US (1) | US10579226B2 (en) |
EP (1) | EP3625692A1 (en) |
JP (1) | JP7046991B2 (en) |
KR (1) | KR102318341B1 (en) |
CN (1) | CN110869922B (en) |
WO (1) | WO2019059967A1 (en) |
Cited By (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20210025965A1 (en) * | 2019-07-23 | 2021-01-28 | Here Global B.V. | Positioning based on calendar information |
USD911375S1 (en) * | 2019-01-17 | 2021-02-23 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD911371S1 (en) * | 2019-01-17 | 2021-02-23 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD913309S1 (en) * | 2019-01-17 | 2021-03-16 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD921666S1 (en) * | 2019-01-17 | 2021-06-08 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD921665S1 (en) * | 2019-01-17 | 2021-06-08 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD922417S1 (en) * | 2019-01-17 | 2021-06-15 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD922415S1 (en) * | 2019-01-17 | 2021-06-15 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD925564S1 (en) * | 2019-01-17 | 2021-07-20 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD926209S1 (en) * | 2019-01-17 | 2021-07-27 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD934273S1 (en) * | 2018-06-04 | 2021-10-26 | Apple Inc. | Display screen or portion thereof with graphical user interface |
USD934889S1 (en) * | 2017-10-02 | 2021-11-02 | Schuler-Haas Electric Corp. | Display screen or a portion thereof with a graphical user interface |
USD942998S1 (en) * | 2020-05-22 | 2022-02-08 | Autel Intelligent Technology Corp., Ltd. | Display screen or portion of a device with transitional graphical user interface |
USD957454S1 (en) * | 2020-05-22 | 2022-07-12 | Autel Intelligent Technology Corp., Ltd. | Display screen or portion thereof of a device with transitional graphical user interface |
USD957451S1 (en) * | 2020-05-22 | 2022-07-12 | Autel Intelligent Technology Corp., Ltd. | Display screen or portion thereof of a device with transitional graphical user interface |
Families Citing this family (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP3920025A1 (en) | 2019-05-06 | 2021-12-08 | Google LLC | Proactive caching of transient assistant action suggestions at a feature phone |
USD925593S1 (en) * | 2019-10-24 | 2021-07-20 | Google Llc | Display screen with animated graphical user interface |
USD924925S1 (en) * | 2019-10-24 | 2021-07-13 | Google Llc | Display screen with animated graphical user interface |
USD924924S1 (en) * | 2019-10-24 | 2021-07-13 | Google Llc | Display screen with animated graphical user interface |
CN111831932A (en) * | 2020-04-14 | 2020-10-27 | 北京嘀嘀无限科技发展有限公司 | Information interaction method, device, equipment and storage medium |
US11635867B2 (en) * | 2020-05-17 | 2023-04-25 | Google Llc | Viewing images on a digital map |
Citations (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040153509A1 (en) * | 1999-06-30 | 2004-08-05 | Alcorn Robert L. | Internet-based education support system, method and medium with modular text-editing component for use in a web-based application |
US20080109718A1 (en) * | 2006-11-06 | 2008-05-08 | International Business Machines Corporation | Combining calendar entries with map views |
EP2150034A1 (en) | 2008-08-01 | 2010-02-03 | LG Electronics Inc. | Mobile terminal capable of managing schedule and method of controlling the mobile terminal |
US20100216491A1 (en) * | 2009-02-20 | 2010-08-26 | David Winkler | Dynamic elements on a map within a mobile device, such as elements that facilitate communication between users |
US20130317665A1 (en) * | 2012-05-22 | 2013-11-28 | Steven J. Fernandes | System and method to provide telematics data on a map display |
US8605094B1 (en) * | 2012-08-13 | 2013-12-10 | Ribbon Labs, Inc. | Graphical display of locations |
US20140316835A1 (en) | 2013-04-23 | 2014-10-23 | Navteq B.V. | Method and apparatus for visualizing fixed and flexible daily calendar events on a map |
US20150187127A1 (en) * | 2012-07-19 | 2015-07-02 | Google Inc. | Varying map content and styles based on time |
US9585988B2 (en) | 2010-11-12 | 2017-03-07 | Tyrx, Inc. | Anchorage devices comprising an active pharmaceutical ingredient |
US20170169363A1 (en) * | 2015-12-10 | 2017-06-15 | Max2 Inc. | Integrated System of Search, Commerce and Analytics Engines Supported by Beacons, Mobile Consumer and Merchant Applications Which Discover, Connect to, Report on, Communicate and Transact with Places, People and Objects Based on Their Proximal, Ephemeral and Analytical Attributes on a Symmetric Basis |
US20170344948A1 (en) * | 2015-02-19 | 2017-11-30 | DocBuddy, Inc. | Coordinated mobile access to electronic medical records |
US20180005434A1 (en) * | 2014-12-22 | 2018-01-04 | Robert Bosch Gmbh | System and Methods for Interactive Hybrid-Dimension Map Visualization |
US20180341394A1 (en) * | 2017-05-25 | 2018-11-29 | Brocade Communications Systems, Inc. | Network Visualization Using Circular Heat Maps |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP3072925B2 (en) * | 1991-10-09 | 2000-08-07 | オリンパス光学工業株式会社 | Interferometer for transmitted wavefront measurement |
JP2001092878A (en) | 1999-09-27 | 2001-04-06 | Fujitsu Ltd | Device for executing schedule presentation and action proposal suited to the schedule, its processing method, recording medium recording its processing program, schedule recording medium and automatic schedule making device |
JP4740462B2 (en) * | 2001-01-11 | 2011-08-03 | クラリオン株式会社 | Map display control device, map information update device, map information update system, and control program |
JP2003132036A (en) | 2001-10-23 | 2003-05-09 | Casio Comput Co Ltd | Electronic device and electronic device control program, electronic device control method |
JP4130828B2 (en) | 2004-07-13 | 2008-08-06 | 松下電器産業株式会社 | Destination display device and destination display method |
CN103856896B (en) * | 2014-03-24 | 2017-07-11 | 南京大学 | With the path duration prediction method based on map calendar prompting function in a kind of Android phone |
-
2017
- 2017-09-19 US US15/708,552 patent/US10579226B2/en active Active
-
2018
- 2018-05-10 CN CN201880044449.4A patent/CN110869922B/en active Active
- 2018-05-10 KR KR1020197038447A patent/KR102318341B1/en active IP Right Grant
- 2018-05-10 WO PCT/US2018/032038 patent/WO2019059967A1/en unknown
- 2018-05-10 EP EP18731241.8A patent/EP3625692A1/en not_active Withdrawn
- 2018-05-10 JP JP2019572596A patent/JP7046991B2/en active Active
Patent Citations (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040153509A1 (en) * | 1999-06-30 | 2004-08-05 | Alcorn Robert L. | Internet-based education support system, method and medium with modular text-editing component for use in a web-based application |
US20080109718A1 (en) * | 2006-11-06 | 2008-05-08 | International Business Machines Corporation | Combining calendar entries with map views |
EP2150034A1 (en) | 2008-08-01 | 2010-02-03 | LG Electronics Inc. | Mobile terminal capable of managing schedule and method of controlling the mobile terminal |
US20100216491A1 (en) * | 2009-02-20 | 2010-08-26 | David Winkler | Dynamic elements on a map within a mobile device, such as elements that facilitate communication between users |
US9585988B2 (en) | 2010-11-12 | 2017-03-07 | Tyrx, Inc. | Anchorage devices comprising an active pharmaceutical ingredient |
US20130317665A1 (en) * | 2012-05-22 | 2013-11-28 | Steven J. Fernandes | System and method to provide telematics data on a map display |
US20150187127A1 (en) * | 2012-07-19 | 2015-07-02 | Google Inc. | Varying map content and styles based on time |
US8605094B1 (en) * | 2012-08-13 | 2013-12-10 | Ribbon Labs, Inc. | Graphical display of locations |
US20140316835A1 (en) | 2013-04-23 | 2014-10-23 | Navteq B.V. | Method and apparatus for visualizing fixed and flexible daily calendar events on a map |
US20180005434A1 (en) * | 2014-12-22 | 2018-01-04 | Robert Bosch Gmbh | System and Methods for Interactive Hybrid-Dimension Map Visualization |
US20170344948A1 (en) * | 2015-02-19 | 2017-11-30 | DocBuddy, Inc. | Coordinated mobile access to electronic medical records |
US20170169363A1 (en) * | 2015-12-10 | 2017-06-15 | Max2 Inc. | Integrated System of Search, Commerce and Analytics Engines Supported by Beacons, Mobile Consumer and Merchant Applications Which Discover, Connect to, Report on, Communicate and Transact with Places, People and Objects Based on Their Proximal, Ephemeral and Analytical Attributes on a Symmetric Basis |
US20180341394A1 (en) * | 2017-05-25 | 2018-11-29 | Brocade Communications Systems, Inc. | Network Visualization Using Circular Heat Maps |
Non-Patent Citations (3)
Title |
---|
Chi-Yi Lin et al., A Location-based Personal Task Management Application for Indoor and Outdoor Environments, Sep. 1, 2012, IEEE, pp. 582-586 (Year: 2012). * |
International Search Report with Written Opinion for PCT/US2018/032038 dated Jul. 23, 2018, 10 pages. |
Sushil J Louis et al., Conext Learning Can Improve User Interaction, Jan. 1, 2004, IEEE, pp. 115-120 (Year: 2004). * |
Cited By (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
USD958815S1 (en) * | 2017-10-02 | 2022-07-26 | Schuler-Haas Electric Corp. | Display screen or a portion thereof with a graphical user interface |
USD934889S1 (en) * | 2017-10-02 | 2021-11-02 | Schuler-Haas Electric Corp. | Display screen or a portion thereof with a graphical user interface |
USD934273S1 (en) * | 2018-06-04 | 2021-10-26 | Apple Inc. | Display screen or portion thereof with graphical user interface |
USD1015358S1 (en) | 2018-06-04 | 2024-02-20 | Apple Inc. | Display screen or portion thereof with animated graphical user interface |
USD987664S1 (en) | 2018-06-04 | 2023-05-30 | Apple Inc. | Display screen or portion thereof with graphical user interface |
USD925564S1 (en) * | 2019-01-17 | 2021-07-20 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD913309S1 (en) * | 2019-01-17 | 2021-03-16 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD922415S1 (en) * | 2019-01-17 | 2021-06-15 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD911375S1 (en) * | 2019-01-17 | 2021-02-23 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD926209S1 (en) * | 2019-01-17 | 2021-07-27 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD921665S1 (en) * | 2019-01-17 | 2021-06-08 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD921666S1 (en) * | 2019-01-17 | 2021-06-08 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD911371S1 (en) * | 2019-01-17 | 2021-02-23 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
USD922417S1 (en) * | 2019-01-17 | 2021-06-15 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Mobile phone or portion thereof with graphical user interface |
US11592516B2 (en) * | 2019-07-23 | 2023-02-28 | Here Global B.V. | Positioning based on calendar information |
US20210025965A1 (en) * | 2019-07-23 | 2021-01-28 | Here Global B.V. | Positioning based on calendar information |
USD957451S1 (en) * | 2020-05-22 | 2022-07-12 | Autel Intelligent Technology Corp., Ltd. | Display screen or portion thereof of a device with transitional graphical user interface |
USD957454S1 (en) * | 2020-05-22 | 2022-07-12 | Autel Intelligent Technology Corp., Ltd. | Display screen or portion thereof of a device with transitional graphical user interface |
USD942998S1 (en) * | 2020-05-22 | 2022-02-08 | Autel Intelligent Technology Corp., Ltd. | Display screen or portion of a device with transitional graphical user interface |
Also Published As
Publication number | Publication date |
---|---|
JP2020531941A (en) | 2020-11-05 |
JP7046991B2 (en) | 2022-04-04 |
CN110869922B (en) | 2021-05-25 |
KR20200010509A (en) | 2020-01-30 |
WO2019059967A1 (en) | 2019-03-28 |
US20190087058A1 (en) | 2019-03-21 |
CN110869922A (en) | 2020-03-06 |
EP3625692A1 (en) | 2020-03-25 |
KR102318341B1 (en) | 2021-10-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10579226B2 (en) | Time proximity based map user interactions | |
US11573097B2 (en) | Location-based features for commute assistant | |
US9110573B2 (en) | Personalized viewports for interactive digital maps | |
US20230230301A1 (en) | Data visualization implementation | |
US8605094B1 (en) | Graphical display of locations | |
US20160179353A1 (en) | Analog clock display with time events | |
TW201828233A (en) | Method for displaying service object and processing map data, client and server | |
US8584051B1 (en) | Location and time user interface dial | |
US20150262428A1 (en) | Hierarchical clustering for view management augmented reality | |
US20150067598A1 (en) | System and method for dynamic visualization of poi attributes and method for refreshing poi attributes | |
US20140047357A1 (en) | Communicating future locations in a social network | |
US20150338974A1 (en) | Definition and use of node-based points, lines and routes on touch screen devices | |
EP3552117B1 (en) | Contextual map view | |
US20190186946A1 (en) | Travel time mapping using isochrones | |
US10489014B2 (en) | Venue and event interface | |
JP6038099B2 (en) | SEARCH SERVICE PROVIDING DEVICE AND METHOD, AND COMPUTER PROGRAM | |
WO2014167363A1 (en) | Systems and methods for interacting with a touch screen | |
CN106796498B (en) | Method, system, and storage medium for rendering a map for a user | |
EP3278292A1 (en) | Providing content items to a user | |
CN110663052B (en) | Computing system and computer-implemented method | |
US10198164B1 (en) | Triggering location selector interface by continuous zooming |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044567/0001Effective date: 20170929 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:LEONG, SU CHUIN;RUSTON, DANIEL PETER;SIGNING DATES FROM 20171126 TO 20171127;REEL/FRAME:044275/0636 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: ADVISORY ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |