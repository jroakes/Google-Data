CN110175678A - System and method for simulating complicated intensified learning environment - Google Patents
System and method for simulating complicated intensified learning environment Download PDFInfo
- Publication number
- CN110175678A CN110175678A CN201910354811.4A CN201910354811A CN110175678A CN 110175678 A CN110175678 A CN 110175678A CN 201910354811 A CN201910354811 A CN 201910354811A CN 110175678 A CN110175678 A CN 110175678A
- Authority
- CN
- China
- Prior art keywords
- resource
- entity
- model
- intensified learning
- output
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/004—Artificial life, i.e. computing arrangements simulating life
- G06N3/006—Artificial life, i.e. computing arrangements simulating life based on simulated virtual individual or collective life forms, e.g. social simulations or particle swarm optimisation [PSO]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
- G06N5/043—Distributed expert systems; Blackboards
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N7/00—Computing arrangements based on specific mathematical models
- G06N7/01—Probabilistic graphical models, e.g. probabilistic networks
Abstract
Disclose a kind of computing system for simulating to multiple entity allocating resources.The computing system, which can be configured as, is input to the entity profile of the preference of description simulation entity and/or demand in intensified learning agent model, and the distribution output as the output of intensified learning agent model is received, resource allocation of the distribution output description for the simulation entity.The computing system can select one or more resources based on the resource allocation of the distribution output description, and provide resource to physical model, and the physical model is configured as the analog response output of the response of simulation description simulation entity.The computing system can receive the analog response output of the output as physical model, and is exported based on the analog response and update the resource profile and/or entity profile that describe at least one resource.
Description
Technical field
The present disclosure relates generally to the system and method for simulating intensified learning environment.More specifically, this disclosure relates to
In the system and method for simulation system, a variety of different intensified learning strategies or mould can be tested or otherwise learnt
Type.
Background technique
Various technologies training intensified learning agency (agent) in simulated environment can be used.In general, intensified learning is acted on behalf of
Reward is given to the movement of simulated environment based on it.Agency is with time learning strategy (policy), it is therefore an objective to maximize it
The reward received.However, actual environment is usually more more complicated than the simulated environment used in reinforcement learning system at present.
Summary of the invention
The aspect and advantage of embodiment of the disclosure will illustrate partly in the following description, or can be from description middle school
It practises, or can be learnt by the practice of embodiment.
One exemplary aspect of the disclosure is related to a kind of computing system for simulating to multiple entity allocating resources.It calculates
System may include one or more processors and intensified learning agent model, be configured as receiving the inclined of description simulation entity
The entity profile (profile) of at least one of good or demand.In response to receiving entity profile, intensified learning agent model can
It is exported with exporting the distribution for the resource allocation to simulation entity for describing multiple entities.Computing system may include being configured as connecing
The physical model for describing the data of at least one resource is received, and describes the data of at least one resource, mould in response to receiving
Quasi- description simulation entity exports the analog response of the response for the data for describing at least one resource.Computing system may include altogether
It is when executed by one or more processors, described with one or more non-transitory computer-readable mediums of store instruction
Instruction makes computing system execute operation.Operation may include being input to entity profile in intensified learning agent model；It receives and makees
For the distribution output of the output of intensified learning agent model, the resource allocation to simulation entity is described；Based on by distribution output
The resource allocation of description, selection will be supplied at least one resource of physical model；At least one resource is provided to physical model；
Receive the analog response output of the output as physical model, response of the description simulation entity at least one resource；And
It is exported based on analog response and updates description at least one of at least one resource or the resource profile of entity profile.
Another exemplary aspect of the disclosure is related to a kind of method for simulating to multiple entity allocating resources.This method can
To include calculating equipment from one or more to input entity profile, the entity profile description simulation to intensified learning agent model
At least one of preference or demand of entity.Intensified learning agent model can be configured as receiving entity profile, and ring
The distribution of the resource allocation of simulation entity should be exported in the received entity profile of institute, output description.This method may include by
One or more calculates the distribution output for the output that equipment is received as intensified learning agent model, describes to simulation entity
Resource allocation；Based on described resource allocation is exported by distribution, equipment is calculated by one or more and selects at least one resource
It is provided arranged to receive the physical model for the data for describing at least one resource to physical model to simulate, and in response to connecing
Receive the data for describing at least one resource, simulation of the simulation description simulation entity to the response for the data for describing at least one resource
Response output；From one or more equipment that calculate to the data of at least one resource of physical model offer description；By one or more
A analog response output for calculating the output that equipment is received as physical model, description simulation entity is at least one resource
Response；And it is exported by one or more of calculating equipment based on analog response and updates the resource letter for describing at least one resource
At least one of shelves or entity profile.
Other aspects of the disclosure are related to various systems, device, non-transitory computer-readable medium, user interface and electricity
Sub- equipment.
With reference to the following description and the appended claims, it is better understood with the various embodiments of the disclosure these and other
Features, aspects and advantages.It is incorporated in the present specification and the attached drawing that forms part of this specification shows the example of the disclosure
Embodiment, and be used to illustrate relative theory together with specification.
Detailed description of the invention
Being discussed in detail for the embodiment for being directed to those of ordinary skill in the art is elaborated in the specification with reference to attached drawing,
Wherein:
Figure 1A depict according to an example embodiment of the present disclosure for being simulated using intensified learning agent model to more
The block diagram of the exemplary computing system of the resource allocation of a entity.
Figure 1B depict according to an example embodiment of the present disclosure for being simulated using intensified learning agent model to more
The block diagram of the Example Computing Device of the resource allocation of a entity.
Fig. 1 C depict according to an example embodiment of the present disclosure for being simulated using intensified learning agent model to more
The block diagram of the Example Computing Device of the resource allocation of a entity.
Fig. 2 depicts the intensified learning agent model of machine learning according to an example embodiment of the present disclosure.
Fig. 3 depicts the system for simulating the resource allocation to multiple entities according to an example embodiment of the present disclosure
Embodiment.
Fig. 4 depicts the system for simulating the resource allocation to multiple entities according to an example embodiment of the present disclosure
Another embodiment.
Fig. 5 A depicts the embodiment of the system for simulating recommender system according to an example embodiment of the present disclosure.
Fig. 5 B shows the example of user's transition model of the system for Fig. 5 A according to an example embodiment of the present disclosure
Update the exemplary diagram of correlation function.
Fig. 6 depict according to an example embodiment of the present disclosure for being simulated using intensified learning agent model to multiple
The flow chart of the exemplary method of the resource allocation of entity.
Fig. 7 A to Fig. 7 C shows the analogue data of the system of Fig. 5 A, including mean program (episode) length, prediction
The average return (return) of the function of clicking rate (pCTR) and the training step as various models.
Fig. 8 A to Fig. 8 U shows the analogue data above with reference to Fig. 7 A to Fig. 7 C experiment described, including uses in agency
Each recommend column (slate), the ratio that cluster (cluster) is watched at any time.
Fig. 9 A to Fig. 9 C shows the analogue data of the system for Fig. 5 A, wherein the parameter of preference pattern makes multinomial
Ratio generates similar return with the randomized policy of index cascade model.
Figure 10 A to Figure 10 C is shown using cascade model for the user's selection and multinomial ratio in CSDQN model
As a result.
Figure 11 A to Figure 11 U shows the analogue data of the experiment for describing above with reference to Figure 10 A to Figure 10 C, including makes
The column recommended with each of agency, the ratio that cluster is watched at any time.
Duplicate appended drawing reference is intended to identify the same characteristic features in various realizations in multiple attached drawings.
Specific implementation
In general, this disclosure relates to the system and method for being used for simulation system, the simulation system can test or with other
Mode learns a variety of different intensified learning strategies or model.It therefore, can be with simulated environment, wherein can be real in actual environment
(or not implementing) Test Strategy, rule, setting or other intensified learning attributes before applying.As an example, simulation system can
To include operating to provide the different components of simulated environment, wherein intensified learning agency can learn to allocate resources to multiple realities
Body, resource allocation in such as industrial setting, compete calculating task computing resource distribution, and/or selection document or other
Content is to be supplied to user via recommender system.Specifically, according to one aspect of the disclosure, system and method can be based on it
With the interaction of simulated environment and/or the result observed in simulated environment come real to the resource consumption changed at any time
Body and/or resource are modeled.Therefore, disclosed system and method are particularly useful for simulated environment, the simulated environment
Allowing intensified learning to act on behalf of study influences to pay the utmost attention to long-term benefit for cost with the short-term negative in this dynamic environment
Strategy.Therefore, simulation strategy or other intensified learning attributes before can implementing in actual environment, wherein testing may mistake
In expensive or unrealistic.
In some implementations, system and method can be provided as to service based on cloud, wherein user can provide pre- instruction
The intensified learning agent model practiced or be pre-configured.User can be set or adjust input and/or is arranged to customize simulated environment, example
The actual environment for being intended to deployment intensified learning agent model as simulated wherein user.Then, user can in simulated environment mould
The quasi- performance of intensified learning agent model at any time, to predict and/or optimize in actual environment agent model or its is multiple not
With the performance of variant.
According to one aspect of the disclosure, computing system may include intensified learning agent model and in simulated environment
The physical model of solid modelling.Intensified learning agent model can be configured as in the preference or demand that receive description simulation entity
The entity profile of at least one (for example, industrial process).In response to receiving entity profile, intensified learning agent model can be defeated
The distribution output of resource allocation for simulating entity is described out (for example, the input of industrial process, such as raw material, fuel, setting
It sets and/or similar).For example, intensified learning agent model can be generated using the strategy of institute's acquistion according to various example arrangements
Distribution output, to attempt to maximize by agent model received progressive award at any time.
Physical model can be configured as the data for receiving the resource allocation that description is generated by intensified learning agent model.It rings
It should be in receiving data, physical model can be configured as the mould that simulation description simulation entity describes the response of resource allocation to data
Quasi- response output (for example, more new state or performance metric of industrial process).
Therefore, physical model can be used to simulate the environment of intensified learning agent model in computing system, one of them or
Multiple simulation entity responses are by one or more resource allocations that intensified learning agent model is that entity generates.
More specifically, entity profile can be input in intensified learning agent model by computing system, and receive conduct
The distribution of the output of intensified learning agent model exports, and describes the resource allocation to simulation entity.Computing system can be based on
Described resource allocation is exported by distribution to select at least one resource to be supplied to physical model.Computing system can be to reality
Body Model provides resource, and receives the analog response output of the output as physical model, and description simulation entity is at least
The response of one resource.
According to one aspect of the disclosure, computing system can be exported based on analog response to update at least one money of description
At least one of the resource profile in source or entity profile.For example, after simulation entity is to the response of resource allocation, Ke Yigeng
Newly or otherwise change the various features or state of physical model.It can be iteratively performed some or complete in above-mentioned steps
Portion is to simulate the study of intensified learning agent model at any time in simulated environment.In addition, updating entity profile and/or resource letter
Shelves can permit the corresponding state of entity and/or resource or characteristic change over time in simulations with simulate transaction and/or
Resource.Therefore, the ability of simulated environment simulation substance feature, behavior or state change can make intensified learning agency's study clear
Consider and being based on entity may have dynamic and variation to respond resource allocation at any time, and in addition, this dynamic and variation
Response the fact that can be the function for being supplied to the provided resource allocation of entity at any time strategy.In this way,
Make it possible to learn in simulated environment in terms of the disclosure relative to dynamically changing resource consumption entity with improved property
The intensified learning agency of energy.
Disclosed system and method can be used for simulating the entity and environment of various real worlds.As described above, one
In a little realizations, simulation entity may include industrial process (for example, manufacture, power generation etc.).Resource may include to industrial process
Input, such as raw material, fuel, setting (for example, temperature, processing speed, throughput rate) and/or analog.Analog response is defeated
It out may include more new state, state change or description industrial process or its other number in response to receiving the variation of resource
According to.
As another example, simulation entity may include the source of calculating task or calculating task.Resource may include being used for
The computing resource of calculating task is run, such as worker is (for example, the processing core of server computing device, processor, physics meter
Calculate equipment, virtual machine etc.).Analog response output may include more new state, state change or description in response to receiving resource
Calculating task or other data of response or variation in calculating task source.
As another example, system and method disclosed herein can be used for simulating for human user recommendation
Recommender system.Simulating entity may include simulated person class user.Resource may include for being looked by simulated person class user
The content seen or participated in.Example resources include text, audio or graphical content (for example, image, video, article or other media
Content).Such resource may be collectively referred to as " document ".Analog response output may include participate in measurement, such as document whether by
Check (for example, " click "), interaction time, user rating etc..
In some implementations, agent model may include the reward based on the function exported as analog response and learn
Intensified learning agency.The desired character that reward can be exported with analog response is positively correlated.Example includes and industrial process or calculating
The associated output of process or performance metric.In another example, reward can be with description simulated person's class user about resource
Participation or one or more measurements that participate in of positive feedback be positively correlated.
In some implementations, entity profile can describe " stylized " model of entity, and wherein entity is some or all of
Feature has interpretable meaning.It can be provided to the response of special entity at any time such as using the feature with interpretable meaning
What influences how intensified learning agent model and/or the movement of intensified learning agent model influence seeing clearly for entity.Entity profile
May include or description industrial process and/or calculating process demand (for example, temperature, rate etc.).As another example, entity
Profile may include the user profiles for describing the interest and/or preference of simulated person's class user.
For example, entity profile may include one or more " interest " features.Interest characteristics may include description simulation
Associated element of the human user to each theme (for example, sport, music etc.).The range of interest characteristics can be from representing to phase
Answer theme do not like strongly it is negative under be limited to represent the positive upper limit liked strongly to corresponding theme.
As another example, entity profile may include one or more " budget " features.Budget feature can describe mould
The pot life amount that quasi- human user is interacted with content.Resource can be provided to simulated person class user, until budget reaches
Minimum threshold (for example, zero).Then it can choose another simulated person class user to simulate.However, in some implementations,
Can resource be provided to multiple simulated person's class users (or other entities) simultaneously.
In some implementations, computing system may include user's transition model, be configured to respond to receive description mould
Quasi- one group of user's hidden state feature for responding the data exported and generating update.Computing system can provide description analog response
The data of user's transition model are output to, and entity profile is updated based on user's hidden state feature.It can be from intensified learning generation
Reason hides some or all of user's hidden state features.Entity profile may include can be by intensified learning proxy access (for example, defeated
Enter) user's observable characteristic.User's observable characteristic can be updated based on user's hidden state feature.Therefore, extensive chemical
Practise agency possibly can not find certain information in relation to the entity immediately.Intensified learning can be trained to act on behalf of to select resource to mention
Entity is supplied, allows to find the information about entity during simulation.Therefore, intensified learning can be trained to act on behalf of to balance
The exploitation and exploration of information about the entity in " multi-arm Slot Machine " context.
In some implementations, computing system may include resource model, be configured as receiving the number for describing multiple resources
According to, and the data in response to receiving the multiple resources of description, export resource observable characteristic.Intensified learning can be trained to act on behalf of mould
Type selects distribution to export to be based at least partially on resource observable characteristic.Resource observable characteristic can describe resource and
(for example, input) can be accessed by intensified learning agent model.More specifically, computing system can will describe the data of multiple resources
It is input in resource model, and receives the resource observable characteristic of the output as resource model.Computing system can will provide
Source observable characteristic is input in intensified learning agent model.Resource profile can also include that intensified learning agent model can not visit
Ask the hiding feature of (for example, input).Therefore, intensified learning can be trained to act on behalf of to balance about " multi-arm Slot Machine " context
In resource information exploitation and exploration.
The feature (for example, observable and/or hiding feature) of resource profile can describe resource.As an example,
In recommender system application, resource profile may include " attribute " feature comprising describe the one or more member of document subject matter
Element." attribute " feature may include the element corresponding to each topic.The range of element can be from minimum value to maximum value, to refer to
Show the correlation of document with corresponding theme.
As another example, resource profile may include " length " feature.Length characteristic can describe to participate in document
(engaging) associated time span.For example, length characteristic can describe the length of video.
As another example, resource profile may include " quality " feature.It includes height that " qualitative character ", which can describe document,
The degree of mass content, rather than at first appear to interesting but be not provided with meaning or about the relevant information further participated in
Content (for example, " clicking bait ")." quality " feature can describe more objective mass measurement, the video quality of such as video,
Writing quality of article etc..
In some implementations, computing system can be simulated to simulation entity and provide multiple resources, and simulation entity can be therefrom
" selection " participates in or the resource of consumption.More specifically, analog response output may include being less than to be supplied to all of simulation entity
The selection of resource.For example, in recommender system example, intensified learning agency can choose multiple documents (for example, video, article,
Image, advertisement etc.) and document is provided to simulated person class user in " column "." column " may include recommending file column
Table, for checking or otherwise participating in.In such an implementation, analog response output can describe entity to all or fewer than
The selection of multiple resource items.For example, simulated person's class user can select a document from the multiple documents presented in column.
For example, physical model may include Discrete Choice Model.Discrete Choice Model is typically configured as from limited item
A project is selected in mesh group.Discrete Choice Model can be configured as the selection from multiple resources (for example, column of document)
One resource.Discrete Choice Model can use various suitable functions, including multinomial proportion function, multinomial logit function, refer to
Number cascaded functions and/or similar function.
The system and method for the disclosure are defined to be realized for simulating to the particular technology of multiple entity allocating resources.It is retouched
The realization for the technology stated thus provides technical functionality, allows virtual test, is the practical of the kit of those of skill in the art
And practice guiding a part.In addition, the system and method for the disclosure provide many additional technical effects and benefit.Make
For an example, system and method described herein can help to develop and/or optimize (such as to send out for controlling industrial process
Electricity) intensified learning agency.Waste can be reduced and save the energy by improving efficiency control and/or monitoring these processes.
As an example, the system and method for the disclosure may include or otherwise be used in application, browsing
In the context of device plug-in unit or other environment.Therefore, in some implementations, the model of the disclosure may include or with other
Mode is stored and is realized in the user calculating equipment of such as laptop computer, column computer or smart phone etc.As again
One example, model may include in or otherwise storage and real now according to client-server relation and user's calculating
The server computing device of equipment communication.For example, model can be embodied as a part of web services by server computing device
(for example, web E-mail service).
Referring now to the drawings, the example embodiment of the disclosure will be discussed in more detail.
Example apparatus and system
Figure 1A depicts the exemplary computing system for being used to simulate intensified learning environment according to an example embodiment of the present disclosure
100 block diagram.System 100 includes the user calculating equipment 102 being communicatively coupled by network 180, server computing systems 130
With training computing system 150.
User calculating equipment 102 can be any kind of calculating equipment, and such as, personal computing devices are (for example, on knee
Or it is desk-top), mobile computing device (for example, smart phone or column computer), game console or controller, wearable computing set
The calculating equipment of standby, embedding assembly equipment or any other type.
User calculating equipment 102 includes one or more processors 112 and memory 114.One or more processors 112
It can be any suitable processing equipment (for example, processor core, microprocessor, ASIC, FPGA, controller, microcontroller etc.)
And it can be a processor or multiple processors being operably connected.Memory 114 may include one or more non-
Temporary computer readable storage medium, such as RAM, ROM, EEPROM, EPROM, flash memory device and their combination.Storage
Device 114 can store the data 116 and instruction 118 run by processor 112, so that user calculating equipment 102 executes operation.
User calculating equipment 102 can store or including one or more intensified learning agent models 120, physical model
122 and/or resource model 124.For example, intensified learning agent model 120, physical model 122 and/or resource model 124 can be with
It is or may include various machine learning models, such as neural network (for example, deep neural network) or other multilayered nonlinears
Model.Neural network may include recurrent neural network (for example, long-term short-term memory Recurrent Neural Network), feedforward neural network
Or the neural network of other forms.Example intensified learning agent model 120 is discussed referring to figs. 2 to Fig. 5.
In some implementations, one or more intensified learning agent models 120 can be calculated by network 180 from server
System 130 receives, and is stored in user calculating equipment memory 114, and by the use of one or more processors 112 or with it
He realizes mode.In some implementations, the multiple parallel of single intensified learning agent model may be implemented in user calculating equipment 102
Example.
Additionally or alternatively, one or more intensified learning agent models 140, physical model 142 and/or resource model
144 may include or otherwise store and realize in server computing systems 130, according to client-server
Relationship is communicated with user calculating equipment 102.For example, intensified learning agent model 140, physical model 142 and/or resource model
144 can be embodied as a part (for example, intensified learning analog service) of web services by server computing systems 140.Therefore,
One or more models 120,122,124 can be stored and realized at user calculating equipment 102 and/or can be in server meter
One or more models 140,142,144 are stored and realized at calculation system 130.
User calculating equipment 102 can also include the one or more user's input modules 122 for receiving user's input.Example
Such as, user's input module 122 can be the sensitive sensitive component of the touch to user's input object (for example, finger or stylus)
(for example, touch-sensitive display screen or touch tablet).Sensitive component can be used for realizing dummy keyboard.Other example user input module packets
The other modes of communication can be inputted by including microphone, conventional keyboard or user.
Server computing systems 130 include one or more processors 132 and memory 134.One or more processors
132 can be any suitable processing equipment (for example, processor core, microprocessor, ASIC, FPGA, controller, microcontroller
Deng), and can be a processor or multiple processors being operably connected.Memory 134 may include one or more
A non-transitory computer-readable storage media, RAM, ROM, EEPROM, EPROM, flash memory device, disk etc. and they
Combination.Memory 134 can store the data 136 and instruction 138 run by processor 132, so that server computing systems
130 execute operation.
In some implementations, server computing systems 130 include one or more server computing devices or by one or
Multiple server computing devices are otherwise realized.It include multiple server computing devices in server computing systems 130
In the case of, such server computing device can be according to sequence counting system structure, parallel computation architecture or its certain
Combination operation.
As described above, server computing systems 130 can store or otherwise include one or more intensified learnings
Agent model 140, physical model 142 and/or resource model 144.For example, model 140 can be or can otherwise wrap
Include various machine-learning models, such as neural network (for example, depth recurrent neural network) or other multilayered nonlinear models.
Example model 140,142,144 is discussed referring to figs. 2 to Fig. 5.
In some implementations, system and method can be provided as to service based on cloud (for example, calculating system by server
System is 130).User can provide the intensified learning agent model of pre-training or pre-configuration.User can be set or adjust input and/
Or setting is to customize simulated environment, such as the actual environment of analog subscriber intention deployment intensified learning agent model.Then, user
The performance of intensified learning agent model at any time can be simulated, in simulated environment to predict and/or optimize in actual environment
The performance of agent model or its multiple and different variant.
Server computing systems 130 can be via the friendship with the training computing system 150 being communicatively coupled by network 180
Mutually carry out training pattern 140.Training computing system 150 can separate or can be server meter with server computing systems 130
A part of calculation system 130.
Training computing system 150 includes one or more processors 152 and memory 154.One or more processors 152
It can be any suitable processing equipment (for example, processor core, microprocessor, ASIC, FPGA, controller, microcontroller etc.),
And it can be a processor or multiple processors being operably connected.Memory 154 may include one or more non-
Temporary computer readable storage medium, RAM, ROM, EEPROM, EPROM, flash memory device, disk etc. and their group
It closes.Memory 154 can store the data 156 and instruction 158 run by processor 152, so that training computing system 150 executes
Operation.In some implementations, training computing system 150 include one or more server computing devices or otherwise by
One or more server computing devices are realized.
Training computing system 150 may include model trainer 160, using various training or learning art (such as, to
Mistake is propagated afterwards) train the machine learning model 140,142,144 being stored at server computing systems 130.In some realizations
In, the back-propagation for executing mistake may include the backpropagation that truncation is executed by the time.Model trainer 160 can execute
The generalization ability for the model that a variety of general magnificent technologies (for example, weight decaying, dropout etc.) are trained to improvement.
Specifically, model trainer 160 can or pre-training intensified learning agent model trained based on training data 142
140, physical model 142 and/or resource model 144.Training data 142 may include label and/or unlabelled data.Example
Such as, training data 142 may include resource allocation number associated with actual environment (for example, industrial process, recommender system etc.)
According to.
In some implementations, if agreement has been provided in user, training example can be mentioned by user calculating equipment 102
For (for example, the communication previously provided based on the user by user calculating equipment 102).Therefore, in such an implementation, it is supplied to
The model 120 of user calculating equipment 102 can be by training computing system 150 to special from the received user of user calculating equipment 102
Determine communication data to be trained.In some cases, which can be referred to as personalized model.
Model trainer 160 includes for providing the computer logic of required function.Model trainer 160 can use control
Hardware, firmware and/or the software of general purpose processor is realized.For example, in some implementations, model trainer 160 includes
The program file of storage on a storage device, is loaded into memory and is run by one or more processors.In other realizations
In, model trainer 160 includes being stored in tangible computer readable storage medium (such as RAM hard disk or optically or magnetically media)
In one or more groups of computer executable instructions.
Network 180 can be any kind of communication network, such as local area network (for example, Intranet), wide area network (for example,
Internet) or its certain combination, and may include any amount of wired or wireless link.In general, passing through network 180
Communication can wiredly and/or wirelessly be connected via any kind of, using various communication protocols (for example, TCP/IP, HTTP,
SMTP, FTP), coding or format (for example, HTML, XML) and/or protection scheme (for example, VPN, secure HTTP, SSL) hold
It carries.
Figure 1A shows the exemplary computing system that can be used for realizing the disclosure.Also other computing systems can be used.
For example, in some implementations, user calculating equipment 102 may include model trainer 160 and training dataset 162.In this way
Realization in, model 120 local training and can use at user calculating equipment 102.In some such realizations, use
Family calculate equipment 102 may be implemented model trainer 160 with based on user's specific data come personalized model 120.
Figure 1B depicts the block diagram of the Example Computing Device 10 executed according to an example embodiment of the present disclosure.Calculate equipment 10
It can be user calculating equipment or server computing device.
Calculating equipment 10 includes multiple applications (for example, arriving N using 1).Each application includes the machine learning library of their own
And machine learning model.For example, each application may include machine learning model.Sample application includes that text message transmitting is answered
With, e-mail applications, dictation application, dummy keyboard application, browser application etc..
As shown in Figure 1B, each application can be communicated with the multiple other assemblies for calculating equipment, such as, such as one or more
A sensor, context manager, equipment state component and/or add-on assemble.In some implementations, each application can be used
API (for example, public API) is communicated with each apparatus assembly.In some implementations, by it is each using API specific to this
Using.
Fig. 1 C depicts the block diagram of the Example Computing Device 50 executed according to an example embodiment of the present disclosure.Calculate equipment 50
It can be user calculating equipment or server computing device.
Calculating equipment 50 includes multiple applications (for example, arriving N using 1).Each application is communicated with central intelligent layer.Example is answered
With including text messaging application, e-mail applications, dictation application, the application of virtual dummy keyboard, browser application etc..?
In some realizations, (and the storage of API (for example, public API across all applications) and central intelligent layer is can be used in each application
In model wherein) communication.
Central intelligent layer includes multiple machine learning models.For example, as shown in Figure 1 C, can be provided respectively for each application
Machine learning model (for example, model) and by central intelligent layer-management.In other implementations, two or more applications can be with
Shared individual machine learning model.For example, in some implementations, central intelligent layer can provide single model for all applications
(for example, single model).In some implementations, central intelligent layer includes in the operating system for calculating equipment 50 or with its other party
Formula is realized by the operating system of calculating equipment 50.
Central intelligent layer can be communicated with central equipment data Layer.Central equipment data Layer can be for calculating equipment 50
Intensive data repository.As shown in Figure 1 C, central equipment data Layer can with calculate equipment multiple other assemblies (such as,
Such as one or more sensors, context manager, equipment state component and/or add-on assemble) communication.In some realizations
In, central equipment data Layer can be used API (for example, privately owned API) and communicate with each apparatus assembly.
Example model arrangement
Fig. 2 depicts the block diagram of example intensified learning model 200 according to an example embodiment of the present disclosure.In some realizations
In, intensified learning model 200 is trained to receive at least the one of the preference of description simulation entity (for example, industrial process) or demand
A entity profile 202.In response to receiving entity profile 202, description is provided, the distribution of the resource allocation of simulation entity is exported
204 (for example, the input of industrial process, raw material, fuel, settings etc.).For example, according to various example arrangements, extensive chemical
Practising agent model 200 can be indirect at any time by agent model to attempt to maximize with Applied Learning strategy next life ingredient with output 204
The progressive award of receipts.
Fig. 3 depicts the block diagram of example intensified learning analogue system 300 according to an example embodiment of the present disclosure.Extensive chemical
Practising analogue system 300 may include intensified learning agent model 302, such as above with reference to described in Fig. 2.
Intensified learning simulation system 300 can select at least one money based on the resource allocation of 306 description of distribution output
Source 308 is to be supplied to physical model 310.Physical model 308 can be configured as the data for receiving description resource 308, and ring
Output 312 should be responded in the data for receiving description resource 308, analogsimulation, description simulation entity is provided at least one is described
The response of the data in source 308.
Intensified learning simulation system 300 can export 312 based on analog response to update the money for describing at least one resource
At least one of source profile or entity profile 304.
Therefore, physical model 310 can be used to simulate for intensified learning agent model in intensified learning simulation system 300
302 environment, wherein one or more simulation entity responses are by one or more that intensified learning agent model 302 is that entity generates
A resource allocation.
More specifically, entity profile 304 can be input in intensified learning agent model 302 by computing system, and connect
It is incorporated as exporting 306 for the distribution of the output of intensified learning agent model 302, describes the resource allocation to simulation entity.It calculates
System can select at least one resource 308 to be supplied to physical model based on the resource allocation of 306 description of distribution output
310.Resource 308 can be supplied to physical model 310 and receive the simulation sound of the output as physical model by computing system
310 should be exported, response of the description simulation entity at least one resource 308.
According to one aspect of the disclosure, computing system can export 312 based on analog response to update description at least one
At least one of the resource profile of a resource or entity profile 304.For example, simulation entity to the response of resource allocation it
Afterwards, it can update or otherwise various characteristics or state of conversion entity model 310.Above-mentioned steps can be iteratively performed
Some or all of to simulate the study of intensified learning agent model 302 in simulated environment at any time.In addition, more novel entities
Profile 304 and/or resource profile can permit the corresponding state of entity and/or resource or characteristic change over time in simulations with
Simulate transaction and/or resource.Therefore, the ability of the simulation substance feature, behavior or state change of simulated environment can make
Intensified learning agency's study is taken explicitly into account and may be had the thing of dynamic and variation response to resource allocation at any time based on entity
Real strategy, in addition, the response of this dynamic and variation can be the provided resource allocation for being supplied to entity at any time
Function.In this way, make it possible to the resource consumption for learning to change relative to dynamic in simulated environment in terms of the disclosure
The intensified learning agency that entity has improved properties.
Disclosed system and method can be used for simulating the entity and environment of various real worlds.As described above, one
In a little realizations, simulation entity may include industrial process (for example, manufacture, power generation etc.).Resource 308 may include to industrial process
Input, raw material, fuel, setting (for example, temperature, processing speed, productivity) etc..Analog response output 312 can be with
Including more new state, state change or the description industrial process or its other data changed in response to receiving resource.
As another example, simulation entity may include the source of calculating task or calculating task.Resource 308 may include using
In the computing resource of operation calculating task, such as worker is (for example, the processing core of server computing device, processor, physics
Calculate equipment, virtual machine etc.).Analog response output 312 may include more new state, state change or description in response to connecing
Receive resource, the response in calculating task or calculating task source or other data of variation.
Fig. 4 depicts the block diagram of example intensified learning simulation system 400 according to an example embodiment of the present disclosure.Extensive chemical
Practising simulation system 400 may include intensified learning agent model 402 and physical model 403, such as above with reference to Fig. 2 and Fig. 3 institute
It states.
Intensified learning simulation system 400 can be retouched based on the distribution output 406 exported by intensified learning agent model 402
The resource allocation stated selects at least one resource 404 to be supplied to physical model 403.Physical model 403 can be configured as reception
The data of description resource 404, and the data in response to receiving description resource 404, simulation describe to simulate entity to description at least
The analog response output 408 of the response of the data of one resource 404.
According to one aspect of the disclosure, computing system can export 408 based on analog response to update description at least one
The resource profile 410 and/or entity profile 412 (for example, using entity transformation model 414) of a resource.For example, in simulation entity
After the response of resource allocation, it can update or otherwise various characteristics or state of conversion entity model 403.It calculates
System can export 408 resource profiles 410 or entity profile 412 for updating description resource 404 based on analog response.For example, being
System 400 may include resource model 411, be configured as receiving description include at least one resource (e.g., including resource profile
410) data of multiple resources.Resource model 411, which can be configured as, describes multiple resources (for example, resource in response to receiving
Profile 410) data and export resource observable characteristic 413.Intensified learning agent model 402 can be trained at least partly
Distribution output 406 is selected based on resource observable characteristic 413.Therefore, computing system can simulate wherein that resource characteristics are at any time
Between the environment that changes.
In some implementations, intensified learning simulation system 400 may include entity transformation model 414, be configured as ringing
It should be in the group object hidden state feature 416 for receiving the data for describing analog response output 408 and generating update.Computing system
The data of description analog response output 408 can be provided to entity transformation model 414, and be based on entity hidden state feature 416
Update entity profile 412.For example, entity profile 412 may include entity hidden state feature 416.Entity hidden state feature
Some or all of 416 can hide from intensified learning agent model 402.Entity profile 412 may include can be by intensified learning
The entity observable characteristic 418 of the access of agent model 402 (for example, input).Entity observable characteristic 418 can be hidden based on entity
Hiding state feature 416 updates.It may not be able to be immediately by intensified learning agent model 402 accordingly, with respect to some information of entity
It was found that.Intensified learning agent model 402 can be trained to select resource to be supplied to entity, allow to find during simulation
Information about entity.Therefore, intensified learning can be trained to act on behalf of to balance about the entity in " multi-arm Slot Machine " context
Information exploitation and exploration.
In some implementations, agent model 402 may include based on as analog response output 408 function reward and
The intensified learning of study is acted on behalf of.The desired character that reward can export 408 with analog response is positively correlated.Example includes and industrial mistake
Journey or the relevant output of calculating process or performance metric.In another example, reward can be closed with description simulated person's class user
Measurement is participated in the participation of resource or the one or more of positive feedback to be positively correlated.
In some implementations, entity profile 412 can describe " stylized " model of entity, wherein some or institute of entity
There is feature that there is interpretable meaning.It can be provided using the feature with interpretable meaning and be rung about special entity at any time
How answer 408 influences how intensified learning agent model 402 and/or the movement of intensified learning agent model 402 influence entity (example
Such as, as described by entity profile 412) see clearly.For example, entity profile 412 may include or description industrial process and/or calculating
The demand (for example, temperature, rate etc.) of process.As another example, entity profile 412 may include that description simulated person's class is used
The interest at family and/or the user profiles of preference.
Therefore, computing system can be used physical model 403, resource model 411 and/or entity transformation model 414 and carry out mould
The environment of quasi- intensified learning agent model 402, wherein one or more simulation entity responses are by intensified learning agent model 402
One or more resource allocations that entity generates.In addition, system can interaction based on them and simulated environment and/or
The result observed in simulated environment simulates the resource consumption entity converted at any time and/or resource.For example, more novel entities are simple
Shelves 412 and/or resource profile 410 can permit entity and/or the respective state or characteristic of resource change over time in simulations
To simulate transaction and/or resource.
Fig. 5 A is depicted according to the aspect of the disclosure for simulating for the recommender system to human user recommendation
System 500 block diagram.Simulating entity may include simulated person class user.Resource may include for being used by simulated person's class
The content that family is checked or participated in.Example resources include text, audio or graphical content (for example, image, video, article or other
Media content).These resources may be collectively referred to as " document ".Although describing system below with reference to " simulated person's class user " and " document "
System 500, it should be appreciated that, the various aspects of system 500 can be used for other contexts, including industrial process and/or calculate
Journey.
Above with reference to Fig. 4 describe system 400 certain elements can correspond to Fig. 5 system 500 element.For example,
The analog response output 408 of Fig. 4 can correspond to the analog subscriber response 508 of Fig. 5.User response 508 may include participation
Whether amount, document are checked (for example, " click "), interaction time, user rating etc..
In some implementations, agent model 502 may include the reward based on the function exported as analog response and learn
The intensified learning agency (for example, analog subscriber response 508) of habit.Reward can with analog response export desired character (for example,
508) analog subscriber response is positively correlated.For example, reward can be with description simulated person's class user about the participation of resource or positive and negative
One or more measurements that participate in of feedback are positively correlated.
In some implementations, user profiles 512 can describe " stylized " model of simulated person class user, wherein simulating
The some or all of features of human user there is interpretable meaning.It can be provided using the feature with interpretable meaning
How intensified learning agent model 502 and/or intensified learning agent model are influenced on specific analog subscriber response 508 at any time
How 502 movement influences seeing clearly for simulated person's class user (for example, user profiles 512).User profiles 512 can describe mould
The interest and/or preference of quasi- human user.
User profiles 512 may include user's observable characteristic and/or context 518, user's hidden state feature 516
And/or elemental user profile 513, user's hidden state feature 516 can initially be described before any update generation.With
Family transition model 514 can be configured as from user profiles 512 and receive user's hidden state feature 516, from user's preference pattern
503 receive analog subscriber response 508, and/or receive resource 504 (for example, column of document) from document model 511.As sound
It answers, user's transition model 514 can be configured as the next user's hidden state feature 517 of output.Then, system 500 can be with
Existing user's hidden state feature 516 is updated with next user's hidden state feature 517.502 can be acted on behalf of from intensified learning
Hide all user's hidden state features 516.User's observable characteristic 518 can act on behalf of 502 by intensified learning to access (example
Such as, it inputs).User's observable characteristic 518 can be updated based on user's hidden state feature 516.Therefore, intensified learning is acted on behalf of
502 possibly can not find some information about user immediately.Intensified learning agency 502 can be trained to selection resource 504
(for example, selection includes the document in column) allows to find during simulation to close to be supplied to simulated person class user
In the information of simulated person class user.Therefore, intensified learning agency 502 can be trained to put down in " multi-arm Slot Machine " context
The exploitation and exploration weighed about the information of simulated person class user.
Therefore, user's preference pattern 503, document model 511 and/or user's transition model 514 can be used in computing system
Simulate the environment of intensified learning agent model 502, wherein one or more simulated person's class user response one or more by
The more resources (for example, document) of simulated person's class user are given in the selection of intensified learning agent model 502 for rendering.In addition, being
System can model simulated person's class user and/or the document of consumption resource, their interactions based on them and simulated environment and/or
The result (outcome) observed in simulated environment changes at any time.For example, updating user profiles 512 and/or resource profile
510, which can permit the corresponding state of simulated person's class user and/or resource or characteristic, changes over time in simulations to simulate and move
State human user and/or resource.
User profiles 512 may include the various information about simulated person class user.For example, user profiles 512 can be with
Including one or more " interest " features.Interest characteristics may include describing simulated person's class user to each topic (for example, body
Educate, music etc.) associated element.The range of interest characteristics can be from the negative lower limit not liked strongly represented to corresponding theme
To the positive upper limit liked strongly represented to corresponding theme.
As another example, user profiles 512 may include one or more " budget " features.Budget feature can describe
It can be used for the time quantum (for example, for watching video) that simulated person's class user interacts with document.Document can be supplied to mould
Quasi- human user, until budget reaches minimum threshold (for example, zero).Then can choose another simulated person's class user into
Row simulation.However, in some implementations, resource can be provided to multiple simulated person's class users (or other entities) simultaneously.
As described above, user's transition model 514 can column 504 based on presentation and such as in simulated person's class user response
The project of the selection indicated in 508 updates User Status.
Interest updates
Interest can be updated just for the document (for example, clicking, viewing) that analog subscriber participates in:
Target (u, d)=Propertiesd-Interestsu
Following update correlation function can be used to scale above-mentioned update, wherein y represents possible maximum update score, x
Represent the maximum point that update should be 0.
Fig. 5 B show for user's transition model 514 update correlation function when x=1 and y=0.3 ∝i's
Exemplary diagram.For neutral interest, update can be bigger, and for more specific interest, update can be smaller.
Mask can be applied, only to update interest relevant to the attribute of document (for example, matching).For example, attribute can
To be 1 hot vector coding.
Mask=Propertiesd
Based on analog subscriber to the interest of document F (u, d), can allow to be updated to certain probability positive or negative.Therefore, most
Updating rule eventually can be expressed as follows:
In some implementations, computing system may include document model 511, be configured as receiving the multiple resources of description
Data, and the data in response to receiving the multiple resources of description (e.g., including document profile 510).Document model 511 can be by
It is configured as output to document observable characteristic 513.It can train intensified learning agent model 502 can be based at least partially on document
Observe the output distribution of feature 513 output 506.Document observable characteristic 513 can describe be visited by intensified learning agent model 502
Ask the document of (for example, input).More specifically, computing system can will describe the data of multiple resources (for example, document profile
510) it is input in document model 511, and receives the document observable characteristic 513 as the output of document model 511.It calculates
Document observable characteristic 513 can be input in intensified learning agent model 502 by system.Document profile 510 can also include
The hiding feature of intensified learning agent model 502 inaccessible (for example, input).Therefore, intensified learning can be trained to act on behalf of 502
To balance the exploitation and exploration about information about the document in " multi-arm Slot Machine " context.
The feature (for example, observable and/or hiding feature) of document profile can describe document.As an example, literary
Shelves profile 510 and/or document observable characteristic 513 may include " attribute " feature comprising describe one of document subject matter or
Multiple elements." attribute " feature may include the element corresponding to respective theme.The range of element can be from minimum value to maximum
Value, to indicate the correlation of document with respective theme.
As another example, document profile 510 and/or document observable characteristic 513 may include " length " feature.Length
Feature can describe time span associated with document participation.For example, length characteristic can describe the length of video.
As another example, document profile 510 and/or document observable characteristic 513 may include " quality " feature." matter
Measure feature " can describe document and include the degree of high-quality content, rather than at first appears to interesting but be not provided with meaning
Or the content (for example, " clicking bait ") of the relevant information further participated in." quality " feature can describe more objective quality
Measurement, such as video quality, writing quality of article of video etc..
In some implementations, computing system can be simulated to simulated person class user and provide multiple documents 504 (for example, text
Shelves " column "), simulated person's class user can therefrom " select " participate in or consumption resource.More specifically, analog subscriber is rung
It may include less than the selection for all documents for being supplied to simulated person class user that 508, which should be exported,.For example, intensified learning is acted on behalf of
502 can choose multiple videos, article, image, advertisement etc., and provide document to simulated person class user in column 504.Version
Block 504 may include for check or otherwise participate in recommendation document list.In such an implementation, analog subscriber
Response output 508 can describe simulated person's class user to multiple documents in column 504 all or less than selection.For example,
Simulated person's class user can select a document from the multiple documents presented in column.
For example, user's preference pattern 503 may include Discrete Choice Model.Discrete Choice Model is typically configured as from having
A project is selected in the project team of limit.Discrete Choice Model can be configured as the choosing from multiple documents 504 (for example, column)
Select a document.Discrete Choice Model can use various suitable functions, including multinomial proportion function, multinomial logit function,
Index cascaded functions and/or similar function.
Discrete Choice Model can calculate nonstandardized technique score F (u, d) as user interest InterestsuWith document category
Property PropertiesdBetween dot product:
F (u, d)=Interestsu·Propertiesd
The vector of the non-standardized score F of the given different document for being supplied to simulated person class user, user's preference pattern
503 sample/select to document according to " probability function " of preference pattern 503.Example probability function includes multinomial ratio
Example function, multinomial logit function and index cascaded functions.
Multinomial ratio
This model calculates the probability that document d is selected in column are as follows:
Since F (u, d) can be negative, score can be shifted to minimum possible score (example shown in here
In, it is -1) to ensure Effective Probability.Furthermore, it is possible to which " no click (noclick) " score is added to F to consider not select
Select the result of project.
Multinomial Logit
Multinomial logit model can calculate the probability of the document d in selection column, as follows:
Using this model, it is not usually required to additional displacement.Identical " no to click " score can be used not to be had to simulate
Selection.
Index cascade
Both multinomial ratio and multinomial Logit mode do not consider the item location in column usually when distributing score.Phase
Than under, index cascade model hypothesis once gives a project " concern ", and the concern for project farther away in column is in refer to
Number decline.Index cascade model is it is also supposed that each project has the elementary probability P (u, d) for the selection sufficiently paid close attention to.At the i of position
The click chance of project may be calculated:
ρ(u,d)i=β0βiP (u, d) for i=0,1,2 ... slate_size
Wherein β0Represent basic select probability；βiRepresent decay factor；And slate_size represents the document in column
Quantity.P (u, d) can represent in the case where not considering position options purpose probability (for example, using in above-mentioned two model
One).Can sequence from i=0 to slate_size consider project.Once having selected a project, so that it may which terminating should
Process.Cond depth network (CSDQN) algorithm described herein assumes that preference pattern is multinomial proportional type.
Budget updates
Budget updates the angle for using effectiveness.We assume that simulated person's class user it is expected received effectiveness according to them,
UtilityeTo select document.
Utilitye(d)=F (u, d)
However, the practical received effectiveness Utility of simulated person's class userrIt is its expected utility, UtilityeWith document matter
The weighted sum of amount:
Utilityr(d)=θe·Utilitye(d)+θd·Utilityd
All mass distributions are shown bigger gap by following result to document quality, but use lesser quantity
Effectively.Budget will be updated according to the length of the effectiveness and video received.Simulated person's class user if " viewing " video, budget
It updates are as follows:
Budgetu←Budgetu-VideoLength(d)+αb·VideoLength(d)·Utilityr(d)
Wherein αbIt is a part of video length, extending sessions is used for, multiplied by norming constant so that Utilityr[-
1,1] between.Therefore, when analog subscriber watches higher-quality video, simulated person class user is ready extending sessions, and shows
Show that low quality content can shorten session.
It, can be using constant step punishment (being 0.5 chronomere in our example) if video is not clicked on:
Budgetu←Budgetu-κ
Response model
Simulated person's class user provides response for each element on column.There are two response variables at present:
" 1. click ": whether clicking document；And
" 2. viewing time ": the time span of simulated person class user viewing document.
For this experiment, it will be assumed that the video of click has been completely consumed or checked.Training agency is to optimize entire session
Total viewing time.
The system and method for the disclosure are defined to be realized for simulating to the particular technology of multiple entity allocating resources.Cause
This, the realization of described technology provides technical functionality, allows virtual test, is the reality of the kit of those of skill in the art
Trample and practice a part of guiding.However, the system and method for the disclosure provide many additional technical effects and benefit.Make
For an example, system and method described herein can help to develop and/or optimize (such as to be sent out for controlling industrial process
Electricity) intensified learning agency.Waste can be reduced and save the energy by improving efficiency control and/or monitoring these processes.
Exemplary method
Fig. 6 depicts the flow chart of exemplary method according to an example embodiment of the present disclosure.Although for explanation and discussing
Purpose, Fig. 6 depicts the step of executing with particular order, but disclosed method is not limited to specifically shown sequence or cloth
It sets.Without departing from the scope of the disclosure, it can omit, rearrange in various ways, combining and/or method of adjustment
600 each step.
At 602, computing system can be by the entity profile of the preference of description simulation entity or at least one of demand
It is input to intensified learning agent model, such as above with reference to described in Fig. 2 to Fig. 5 B.
At 604, computing system can receive the distribution output as the output of intensified learning agent model, description pair
The resource allocation of entity is simulated, such as above with reference to described in Fig. 2 to Fig. 5 B.
At 606, computing system can choose at least one resource with based on by distribution output description resource allocation come
The offer to physical model is simulated, such as above with reference to described in Fig. 3 to Fig. 5 B.
At 608, computing system can provide the data for describing at least one resource to physical model, such as joined above
It examines described in Fig. 3 to Fig. 5 B.
At 610, computing system can receive the analog response output of the output as physical model, and description simulation is real
Response of the body at least one resource, such as above with reference to described in Fig. 3 to Fig. 5 B.
At 612, computing system can based on analog response export update describe at least one resource resource profile or
At least one of entity profile, such as above with reference to described in Fig. 3 to Fig. 5 B.
Simulation result
Firstly, it is contemplated that the case where simulated person class user follows multinomial scale model.The Model Matching is used for condition
Prediction clicking rate (pCTR) model of state depth q network (CSDQN) model.Fig. 7 A, Fig. 7 B and Fig. 7 C were shown for the CSDQN service life
Be worth (LTV) model, CSDQN myopic model (gamma=0), perfect greedy model (K pCTR project before always selecting) and
Mean program length, the pCTR on column and training step (non-program) letter of each of random multinomial scale model
Several average returns.As shown, LTV method provide it is highest return (2 chronomeres, account for about the 1% of budget, than
1.2%) myopic/greedy increases.As expected, myopic model converges on the identical return of perfect greedy model.At any time
Between the influence to cluster that shows show the reason of randomness of height is " small " gain.
Fig. 8 A to Fig. 8 U is shown using each of agency of the above-mentioned experiment with reference to described in Fig. 7 A to 7C recommendation
Column, the ratio for the number that cluster is watched at any time.Fig. 8 A to Fig. 8 M is low quality cluster；Fig. 8 N and Fig. 8 O are mean qualities；With
And Fig. 8 P to Fig. 8 U is high quality.As shown, CSDQN LTV model has learned the higher-quality cluster of suggestion at any time.For
Low quality cluster, CSDQN LTV model are usually less than other clusters, and for high quality cluster, it is higher than other clusters.Due to a total of 20
A cluster, and primary only 10 clusters of display, therefore be not always the cluster that can choose high quality.Therefore, agency must select sometimes
Select low-quality cluster.The ratio for not watching the number of video is shown in Fig. 8 U, is labeled as " AverageClusterWatch_
None." on all clusters prison viewing ratio (except " AverageClusterWatch_None ") of greedy agency converge to substantially
Identical value (~0.035-0.036), since the interest of simulated person class user is also equally distributed, it is therefore proposed that equably
Selection cluster.
Fig. 9 A to Fig. 9 C, which is shown, can occur what if underlying user preference pattern difference.CSDQN model hypothesis is used
Family selection is with the execution of multinomial ratio, but actual user's model is that there is the index of multinomial ratio elementary probability to cascade.In order to make this
Test it is suitable with the last one experiment, adjust the parameter of preference pattern so that both multinomial ratio and index cascade model with
Machine strategy generates similar return.
Figure 10 A to Figure 10 C, which is shown, selects for user using cascade model and uses in CSDQN model multinomial ratio
Result.Use this preference pattern, it is contemplated that viewing time increase about 2 to 2.5%.It is similar with the first situation as the result is shown
Effect.Finally, Figure 11 A to Figure 11 U shows the data above with reference to Figure 10 A to Figure 10 C experiment described.These charts are logical
Cross what single operation generated, each point carries out 50 assessments.More specifically, Figure 11 A to Figure 11 U is shown using above-mentioned with reference to figure
The ratio of the number for watching cluster at any time for the column that each of agency of experiment of 10A to Figure 10 C recommends.Figure 11 A is extremely
11M is low quality cluster；Figure 11 N and Figure 11 O are mean qualities；And Figure 11 P to Figure 11 U is high quality.
It is additional open
Technical Reference server, database, software application and other computer based systems for being discussed herein and this
The movement and the information for being sent to these systems and being sent from these systems that a little systems are taken.Computer based system
Intrinsic flexibility allows stroke of various possible configurations between the neutralizations component of good component, combination and task and function
Point.For example, individual equipment or component or multiple equipment or component work in combination can be used to realize in the process being discussed herein.Number
It can realize or be distributed in multiple systems on a single according to library and application.Distributed component can sequence or parallel fortune
Row.
Although this theme is described in detail about various specific example embodiments of the invention, each example is
It is provided by the illustrative and not limiting disclosure.Those skilled in the art, can be with after obtaining to the understanding of foregoing teachings
Easily generate change, variation and the equivalent to these embodiments.Therefore, this theme disclosure is not precluded comprising to this
These modifications, variation and/or the addition of theme, such as will be apparent to practitioners skilled in this.For example, making
The feature that a part for one embodiment shows or describes can be used together to generate another reality with another embodiment
Apply example.Therefore, the disclosure is intended to cover such change, variation and equivalent.
Claims (20)
1. a kind of computing system for simulating to multiple entity allocating resources, the computing system include:
One or more processors；
Intensified learning agent model is configured as receiving the preference of description simulation entity or the entity letter of at least one of requirement
Shelves, and in response to receiving the entity profile, resource point of the output description to the simulation entity of the multiple entity
The distribution output matched；
Physical model is configured as receiving the data for describing at least one resource, and in response to receiving description described at least one
The data of a resource, analog response of the simulation description simulation entity to the response for the data for describing at least one resource
Output；
The non-transitory computer-readable medium of one or more common store instructions, runs when by one or more processors
When, described instruction makes the computing system execute operation, and the operation includes:
The entity profile is input to the intensified learning agent model；
The distribution output of the output as the intensified learning agent model is received, the distribution output is described to the simulation
The resource allocation of entity；
Based on the resource allocation by the distribution output description, selection will be supplied at least one described money of the physical model
Source；
At least one described resource is provided to the physical model；
The analog response output of the output as the physical model is received, the analog response output describes the simulation entity
Response at least one resource；And
It is exported, is updated in the resource profile for describing at least one resource or entity profile at least based on the analog response
One.
2. computing system as described in claim 1, wherein the intensified learning agent model includes intensified learning agency, institute
It states intensified learning reward of the agency based on the function exported as the analog response and is learnt.
3. computing system as described in claim 1, in which:
The simulation entity includes at least one of the source of calculating task or calculating task；And
At least one described resource includes the worker for being configured as running the calculating task.
4. computing system as described in claim 1, in which:
The simulation entity includes industrial process；And
At least one described resource includes the input to the industrial process.
5. computing system as described in claim 1, wherein the simulation entity includes simulated person class user, and described
Entity profile includes the user profiles for describing the interest or at least one of preference of institute simulated person class user.
6. computing system as claimed in claim 5, wherein the analog response output describes participation measurement, the participation
Measurement description institute simulated person class user is at least one of the interaction time of at least one resource or grading.
7. computing system as described in claim 1, wherein based on the analog response export update the resource profile or
At least one of described entity profile includes providing to describe one group of use that the data that the analog response exports are updated to generation
User's transition model of family hidden state feature, and the entity configuration file is updated based on user's hidden state feature.
8. computing system as described in claim 1, wherein at least one described resource includes at least one document, the text
Shelves include at least one of text, audio or graphical content.
9. computing system as described in claim 1, further includes: resource model is configured as receiving description including described at least
The data of multiple resources of one resource, and the data in response to receiving the multiple resource of description export resource observable
Feature, and wherein, the trained intensified learning agent model is based at least partially on the resource observable characteristic to select
Distribution output, and the wherein operation further include:
The data for describing the multiple resource are input in the resource model；
Receive the resource observable characteristic of the output as the resource model；And
The resource observable characteristic is input in the intensified learning agent model.
10. computing system as described in claim 1, in which:
At least one described resource includes multiple resource items；And
The analog response output describes the selection all or fewer than the multiple resource items.
11. computing system as claimed in claim 10, wherein the physical model includes Discrete Choice Model.
12. computing system as claimed in claim 11, wherein the Discrete Choice Model includes multinomial proportion function, multinomial
At least one of logit function or index cascaded functions.
13. a kind of method for simulating to multiple entity allocating resources, which comprises
By one or more equipment that calculate by the entity profile input of the preference of description simulation entity or at least one of demand
Into intensified learning agent model, the intensified learning agent model is configured as receiving the entity profile, and in response to
The entity profile is received, output description exports the distribution of the resource allocation of the simulation entity；
The distribution output of the output as the intensified learning agent model is received by one or more of calculating equipment, it is described
Distribution output describes the resource allocation to the simulation entity；
At least one resource is selected as one or more of calculating equipment to simulate and be based on as described in distribution output
Resource allocation is supplied to physical model, and the physical model is configured as receiving the data for describing at least one resource, and
And the data of at least one resource are described in response to receiving, simulation describe the simulation entity to described in description at least one
The analog response of the response of the data of resource exports；
The data for describing at least one resource are provided to the physical model by one or more of calculating equipment；
The analog response output of the output as the physical model, the simulation are received by one or more of calculating equipment
Response of the response output description simulation entity at least one resource；And
It is exported by one or more of calculating equipment based on the analog response, updates the money for describing at least one resource
At least one of source profile or entity profile.
14. method as claimed in claim 13, wherein the agent model includes intensified learning agency, the intensified learning
It acts on behalf of the reward based on the function exported as the analog response and is learnt.
15. method as claimed in claim 13, wherein the simulation entity includes simulated person class user, and the reality
Body profile includes the user profiles for describing the interest or at least one of preference of institute simulated person class user.
16. method as claimed in claim 13, wherein the analog response output describes participation measurement, the participation
Amount description institute simulated person class user is at least one of the interaction time of at least one resource or grading.
17. method as claimed in claim 13, wherein it is defeated to be based on the analog response by one or more of calculating equipment
At least one of the resource profile or the entity profile are updated out, including are provided by one or more of calculating equipment
Data that the analog response exports are described to the user's transition model for generating the one group of user's hidden state feature updated, and by
One or more of calculating equipment are based on user's hidden state feature and update the entity profile.
18. method as claimed in claim 13, wherein at least one described resource includes at least one document, the document
Including at least one of text, audio or graphical content.
19. method as claimed in claim 13, further includes:
The data for describing the multiple resource are input in resource model by one or more of calculating equipment, the resource
Model is configured as receiving the data that description includes multiple resources of at least one resource, and describes institute in response to receiving
The data of multiple resources are stated, resource observable characteristic is exported；
The resource observable characteristic of the output as the resource model is received by one or more of calculating equipment；And
The resource observable characteristic is input in the intensified learning agent model by one or more of calculating equipment,
Wherein, the training intensified learning agent model is defeated to select to distribute to be based at least partially on the resource observable characteristic
Out.
20. method as claimed in claim 13, further includes: by one or more of calculating equipment by the entity profile
It is input to before the intensified learning agent model, receives the intensified learning by one or more of calculating equipment and act on behalf of mould
Type.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201962801719P | 2019-02-06 | 2019-02-06 | |
US62/801,719 | 2019-02-06 |
Publications (1)
Publication Number | Publication Date |
---|---|
CN110175678A true CN110175678A (en) | 2019-08-27 |
Family
ID=67690307
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201910354811.4A Pending CN110175678A (en) | 2019-02-06 | 2019-04-29 | System and method for simulating complicated intensified learning environment |
Country Status (2)
Country | Link |
---|---|
US (2) | US11475355B2 (en) |
CN (1) | CN110175678A (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN114467101A (en) * | 2019-10-07 | 2022-05-10 | 瑞典爱立信有限公司 | Arbitrator for federal learning |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11455311B2 (en) * | 2019-03-29 | 2022-09-27 | Datadog, Inc. | Multi-locator system for tracking data elements in resources |
US11429869B2 (en) * | 2019-11-21 | 2022-08-30 | International Business Machines Corporation | Artificially intelligent interaction agent |
US20220164225A1 (en) * | 2020-11-25 | 2022-05-26 | Beijing Didi Infinity Technology And Development Co., Ltd. | Self-play to improve task-oriented dialog systems and methods |
CN114816722A (en) * | 2021-01-27 | 2022-07-29 | 伊姆西Ip控股有限责任公司 | Method, apparatus and program product for managing computing systems |
US20230061206A1 (en) * | 2021-08-25 | 2023-03-02 | Royal Bank Of Canada | Systems and methods for reinforcement learning with local state and reward data |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11461145B2 (en) * | 2019-01-28 | 2022-10-04 | EMC IP Holding Company LLC | Building neural networks for resource allocation for iterative workloads using reinforcement learning |
US11748611B2 (en) * | 2019-02-18 | 2023-09-05 | Sumit Sanyal | Method and apparatus for reinforcement learning training sessions with consideration of resource costing and resource utilization |
-
2019
- 2019-02-28 US US16/288,279 patent/US11475355B2/en active Active
- 2019-04-29 CN CN201910354811.4A patent/CN110175678A/en active Pending
-
2022
- 2022-10-17 US US17/967,595 patent/US20230117499A1/en active Pending
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN114467101A (en) * | 2019-10-07 | 2022-05-10 | 瑞典爱立信有限公司 | Arbitrator for federal learning |
Also Published As
Publication number | Publication date |
---|---|
US20230117499A1 (en) | 2023-04-20 |
US11475355B2 (en) | 2022-10-18 |
US20200250575A1 (en) | 2020-08-06 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN110175678A (en) | System and method for simulating complicated intensified learning environment | |
Fortmann-Roe | Insight Maker: A general-purpose tool for web-based modeling & simulation | |
Agarwal et al. | An interdisciplinary review of research in conjoint analysis: Recent developments and directions for future research | |
Bobadilla et al. | Collaborative filtering adapted to recommender systems of e-learning | |
Hu et al. | iTCM: Toward learning-based thermal comfort modeling via pervasive sensing for smart buildings | |
Capuano et al. | Fuzzy group decision making for influence-aware recommendations | |
Chu et al. | PC 2 PSO: personalized e-course composition based on Particle Swarm Optimization | |
El-Bishouty et al. | Smart e-course recommender based on learning styles | |
CN106327339A (en) | Second-pass ranker for push notifications in a social network | |
US20180341378A1 (en) | Computer-implemented frameworks and methodologies configured to enable delivery of content and/or user interface functionality based on monitoring of activity in a user interface environment and/or control access to services delivered in an online environment responsive to operation of a risk assessment protocol | |
US10290040B1 (en) | Discovering cross-category latent features | |
Fazeli et al. | User-centric evaluation of recommender systems in social learning platforms: accuracy is just the tip of the iceberg | |
Das et al. | The effects of feedback on human behavior in social media: An inverse reinforcement learning model | |
Sawyer et al. | Balancing learning and engagement in game-based learning environments with multi-objective reinforcement learning | |
Chang et al. | A crowdsourcing development approach based on a neuro-fuzzy network for creating innovative product concepts | |
Hu et al. | Learning peer recommendation using attention-driven CNN with interaction tripartite graph | |
Xia et al. | Student performance in computing education: an empirical analysis of online learning in programming education environments | |
Wang et al. | Deep reinforcement learning for sequential targeting | |
Tkachenko et al. | Customer simulation for direct marketing experiments | |
CN109190040A (en) | Personalized recommendation method and device based on coevolution | |
Chen et al. | Evolutionary dynamics from fluctuating environments with deterministic and stochastic noises | |
Lv et al. | Macro-influencers or meso-influencers, how do companies choose? | |
Hassouni et al. | Using generative adversarial networks to develop a realistic human behavior simulator | |
Cranford et al. | Combining machine learning and cognitive models for adaptive phishing training | |
Pascoal et al. | A social-evolutionary approach to compose a similarity function used on event recommendation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |