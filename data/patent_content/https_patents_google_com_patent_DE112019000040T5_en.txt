QUERVERWEIS AUF VERWANDTE ANWENDUNGENCROSS REFERENCE TO RELATED APPLICATIONS
Diese Anmeldung beansprucht die Priorität der US-Patentanmeldung Nr. 15/943,961 , eingereicht am 3. April 2018, mit dem Titel „DETECTING AC-TIONS TO DISCOURAGE RECOGNITION“, deren Inhalt hier durch Bezugnahme vollständig mit aufgenommen ist.This application claims priority from U.S. Patent Application No. 15 / 943,961 , submitted on April 3, 2018, with the title "DETECTING AC-TIONS TO DISCOURAGE RECOGNITION", the content of which is hereby fully incorporated by reference.
HINTERGRUNDBACKGROUND
Diese Spezifikation bezieht sich auf eine Erkennungsanwendung, die bestimmt, ob Erkennung einer Person in einem Bild oder einem Video ausgeführt werden soll.This specification relates to a recognition application that determines whether recognition of a person in an image or video should be performed.
Wenn eine Person nicht möchte, dass sie in einem Bild oder einem Video erkannt wird, war es ausreichend, das Gesicht der Person zu verdecken, weil das Verdecken des Gesichts der Person unterbinden würde, dass ein Gesichtserkennungsalgorithmus genug Gesichtsmerkmale identifiziert, um Gesichtserkennung auszuführen. In modernen Computer-Sichtsystemen können Menschen jedoch auch durch Extrahieren von Merkmalen aus dem gesamten Körper in einem Bild oder aus einer Folge von Bildern oder in einem Video erkannt werden, selbst wenn das Gesicht nicht sichtbar ist oder in hohem Maße verdeckt ist. Beispielsweise kann eine Person, die in einem ersten Foto ein markantes Hemd trägt, dann durch zuerst Entdecken, dass das Hemd in einem weiteren Foto, in dem das Gesicht sichtbar ist, getragen wird, und dann durch Erkennen dieser Person erkannt werden. Ähnlich kann eine Person durch einen markanten Haarschnitt, einen Schmuckgegenstand, eine Tätowierung, einen gehaltenen Gegenstand, eine Haltung oder irgendwelche anderen Kennzeichen erkannt werden. Als ein Ergebnis können moderne Computer-Sichtsysteme Menschen entgegen ihrem Willen identifizieren.If a person does not want them to be recognized in an image or video, it was sufficient to mask the person's face because masking the person's face would prevent a facial recognition algorithm from identifying enough facial features to perform facial recognition. However, in modern computer vision systems, people can be recognized by extracting features from the whole body in an image or from a sequence of images or in a video, even if the face is not visible or is highly obscured. For example, a person wearing a striking shirt in a first photo can then be recognized by first discovering that the shirt is worn in another photo in which the face is visible, and then by recognizing that person. Similarly, a person can be recognized by a distinctive haircut, jewelry, tattoo, held object, posture, or any other characteristic. As a result, modern computer vision systems can identify people against their will.
Die Hintergrundbeschreibung, die hier bereitgestellt ist, dient dem Zweck, den Kontext der Offenbarung allgemein zu präsentieren. Sowohl die Arbeit der hier genannten Erfinder, in dem Maß, in dem sie in diesem Hintergrundabschnitt beschrieben ist, als auch Aspekte der Beschreibung, die nicht anderweitig zur Zeit der Einreichung als Stand der Technik bezeichnet werden können, sind weder ausdrücklich noch implizit als Stand der Technik gegenüber der vorliegenden Offenbarung anerkannt.The background description provided here is for the purpose of generally presenting the context of the disclosure. Both the work of the present inventors, to the extent that it is described in this background section, and aspects of the description that cannot otherwise be referred to as the state of the art at the time of filing, are neither express nor implied as prior art Technology recognized over the present disclosure.
ZUSAMMENFASSUNGSUMMARY
Ausführungsformen beziehen sich allgemein auf ein Verfahren, beispielsweise ein computerimplementiertes Verfahren, zum Bestimmen, ob Erkennung auf einem Bild oder einem Video ausgeführt werden soll. Der Verfahren enthält Detektieren einer Person in einem Bild oder einem Video durch Bestimmen eines Personenbildbereichs, der Grenzen der Person entspricht, oder eines Gesichtsbildbereichs, der einer Position eines Gesichts der Person entspricht. Das Verfahren enthält ferner das Analysieren von Pixelwerten, die der Person oder der Position des Gesichts der Person entsprechen, basierend auf den Grenzen der Person oder dem Gesichtsbildbereich, um ein Erkennungsvermeidungssignal zu erzeugen. Das Verfahren enthält ferner das Bestimmen, ob das Erkennungsvermeidungssignal angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern. Das Verfahren enthält ferner das Ablehnen der Erkennung der Person in Reaktion darauf, dass das Erkennungsvermeidungssignal angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern.Embodiments generally relate to a method, such as a computer-implemented method, for determining whether recognition should be performed on an image or a video. The method includes detecting a person in an image or video by determining a person image area that corresponds to boundaries of the person or a face image area that corresponds to a position of a face of the person. The method further includes analyzing pixel values corresponding to the person or the position of the person's face based on the boundaries of the person or the face image area to generate a detection avoidance signal. The method further includes determining whether the recognition avoidance signal indicates that a measure has been taken to prevent the person from being recognized. The method further includes refusing to recognize the person in response to the detection avoidance signal indicating that the measure has been taken to prevent the person from being recognized.
In einigen Ausführungsformen enthält das Ablehnen, die Erkennung der Person auszuführen, das Ausführen wenigstens eines aus Speichern des Erkennungsvermeidungssignals in Zuordnung zu dem Bild oder dem Video, um anzugeben, dass Personenerkennung nicht ausgeführt werden soll, Löschen des Bilds oder Videos, Archivieren des Bilds oder Videos oder Verschieben nach unten des Bilds oder Videos in Suchergebnissen. In einigen Ausführungsformen umfasst das Verfahren ferner in Reaktion darauf, dass Erkennungsvermeidungssignal nicht angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, Ausführen der Erkennung der Person durch Bestimmen einer Identität der Person und Indexieren des Bilds oder Videos in Zuordnung zu der Identität. In einigen Ausführungsformen enthält das Bestimmen, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, ferner eine Bestimmung, dass das Erkennungsvermeidungssignal einem Vermeidungswert entspricht, der einen Schwellenwert nicht erfüllt, und Ausführen der Erkennung der Person auch in Reaktion darauf ist, dass der Vermeidungswert den Schwellenwert nicht erfüllt. In einigen Ausführungsformen ist die Person eine erste Person, das Bestimmen, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, enthält ferner eine Bestimmung, dass das Erkennungsvermeidungssignal einem Vermeidungswert entspricht, der einen Schwellenwert erfüllt, und das Verfahren umfasst ferner in Reaktion darauf, dass der Vermeidungswert den Schwellenwert erfüllt, Detektieren einer zweiten Person in dem Bild und Erzeugen des Erkennungsvermeidungssignals für die zweite Person. In einigen Ausführungsformen enthält die Maßnahme, dass (1) die Person ein Objekt verwendet, um wenigstens einen Teil des Gesichts der Person zu verdecken, oder dass (2) wenigstens ein Teil des Gesichts der Person digital verdeckt ist. In einigen Ausführungsformen basiert das Ausführen der Erkennung der Person auf dem Extrahieren einer Erkennungsschablone. In einigen Ausführungsformen, wobei das Bild ein erstes Bild ist, das Video ein erstes Video ist, und umfasst ferner: Identifizieren eines oder mehrerer zusätzlicher Bilder oder eines oder mehrere zusätzlicher Videos, die einem Ereignis zugeordnet sind, und Bestimmen, eine Person innerhalb des einen oder der mehreren zusätzlichen Bilder oder des einen oder der mehreren zusätzlichen Videos, die dem Ereignis zugeordnet sind, nicht zu erkennen. In einigen Ausführungsformen enthält das Bestimmen, dass das Erkennungsvermeidungssignal angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, das Bestimmen eines Typs der Maßnahme und umfasst ferner: Ausführen der Erkennung der Person durch Identifizieren der Person und Teilen der Identifizierung der Person mit einer Gruppe von Anwendern in einem sozialen Netzwerk basierend auf dem Typ der Maßnahme und nicht Teilen der Identifizierung der Person mit irgendwelchen Anwendern, die nicht Teil der Gruppe von Anwendern in dem sozialen Netzwerk sind.In some embodiments, refusing to perform the recognition of the person includes performing at least one of storing the recognition avoidance signal associated with the image or video to indicate that person recognition should not be performed, deleting the image or video, archiving the image, or Videos or move down the image or videos in search results. In some embodiments, the method further comprises, in response to the detection avoidance signal not indicating that the measure has been taken to prevent the person from being recognized, performing the detection of the person by determining an identity of the person and indexing the image or video in association with of identity. In some embodiments, determining that the measure has been taken to prevent the person from being recognized further includes determining that the detection avoidance signal corresponds to an avoidance value that does not meet a threshold and performing the detection of the person in response thereto, that the avoidance value does not meet the threshold. In some embodiments, the person is a first person, determining that the measure has been taken to prevent the person from being recognized further includes determining that the detection avoidance signal corresponds to an avoidance value that meets a threshold, and the method further includes FIG In response to the avoidance value meeting the threshold, detecting a second person in the image and generating the detection avoidance signal for the second person. In some embodiments, the measure includes (1) the person using an object to obscure at least part of the person's face, or (2) digitally obscuring at least part of the person's face. In some embodiments, executing the detection of the Person on extracting a recognition template. In some embodiments, wherein the image is a first image, the video is a first video, and further comprises: identifying one or more additional images or one or more additional videos associated with an event and determining a person within the one or the plurality of additional images or the one or more additional videos associated with the event. In some embodiments, determining that the detection avoidance signal indicates that the measure has been taken to prevent the person from being recognized includes determining a type of the measure and further comprises: performing the detection of the person by identifying the person and partially identifying the person Person with a group of users in a social network based on the type of measure and not sharing the identification of the person with any users who are not part of the group of users in the social network.
In einigen Ausführungsformen enthält ein nicht-transitorisches computerlesbares Medium darauf gespeichert Anweisungen, die dann, wenn sie durch einen oder mehrere Computer ausgeführt werden, bewirken, dass der eine oder die mehreren Computer Operationen ausführen, wobei die Operationen umfassen: Detektieren einer Person in einem Bild oder einem Video durch Bestimmen eines Personenbildbereichs, der Grenzen der Person entspricht, oder eines Gesichtsbildbereichs, der einer Position des Gesichts der Person entspricht, Analysieren von Pixelwerten, die der Person oder der Position des Gesichts der Person entsprechen, basierend auf den Grenzen der Person oder dem Gesichtsbildbereich, um ein Erkennungsvermeidungssignal zu erzeugen, Bestimmen, ob das Erkennungsvermeidungssignal angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, und in Reaktion darauf, dass das Erkennungsvermeidungssignal nicht angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, Ausführen der Erkennung der Person.In some embodiments, a non-transitory computer readable medium includes instructions stored thereon that, when executed by one or more computers, cause the one or more computers to perform operations, the operations comprising: detecting a person in an image or a video by determining a person image area corresponding to the person's borders or a face image area corresponding to a position of the person's face, analyzing pixel values corresponding to the person or the position of the person's face based on the person's borders or the face image area to generate a detection avoidance signal, determining whether the detection avoidance signal indicates that an action has been taken to prevent recognition of the person, and in response to the detection avoidance signal not indicating that the action has been taken to detectto prevent the person from performing the person's detection.
In einigen Ausführungsformen umfasst das Ausführen der Erkennung der Person das Bestimmen einer Identität der Person und Indexieren des Bilds oder des Videos in Zuordnung zu der Identität. In einigen Ausführungsformen umfassen die Operationen ferner: in Reaktion darauf, dass das Erkennungsvermeidungssignal angibt, dass die Maßnahme ergriffen worden ist, die Erkennung der Person zu verhindern, Ausführen wenigstens eines aus Speichern des Erkennungsvermeidungssignals in Zuordnung zu dem Bild oder dem Video, um anzugeben, dass Personenerkennung nicht ausgeführt werden soll, Löschen des Bilds oder Videos, Archivieren des Bilds oder Videos oder Verschieben nach unten des Bilds oder Videos in Suchergebnissen. In einigen Ausführungsformen umfassen die Operationen ferner: in Reaktion darauf, dass das Erkennungsvermeidungssignal angibt, dass die Maßnahme ergriffen worden ist, die Erkennung der Person zu verhindern, Bestimmen ob das Erkennungsvermeidungssignal einem Vermeidungswert entspricht, der einen Schwellenwert erfüllt, und in Reaktion darauf, dass der Vermeidungswert den Schwellenwert nicht erfüllt, Ausführen von Erkennung der Person . In einigen Ausführungsformen enthält die Aktion, dass (1) die Person ein Objekt verwendet, um wenigstens einen Teil des Gesichts der Person zu verdecken, oder dass (2) wenigstens ein Teil des Gesichts der Person ist digital verdeckt ist. In einigen Ausführungsformen umfassen die Operationen ferner: Bestimmen von Berechtigungen, die der Person zugeordnet sind, und wobei das Ausführen der Erkennung der Person auf den Berechtigungen basiert, die der Person zugeordnet sind.In some embodiments, performing the recognition of the person includes determining an identity of the person and indexing the image or video in association with the identity. In some embodiments, the operations further include: in response to the detection avoidance signal indicating that action has been taken to prevent the person from being recognized, performing at least one of storing the detection avoidance signal in association with the image or video to indicate that people should not be recognized, delete the picture or video, archive the picture or video, or move down the picture or video in search results. In some embodiments, the operations further include: in response to the detection avoidance signal indicating that the measure has been taken to prevent detection of the person, determining whether the detection avoidance signal corresponds to an avoidance value that meets a threshold, and in response to that the avoidance value does not meet the threshold, perform recognition of the person. In some embodiments, the action includes (1) the person using an object to obscure at least part of the person's face, or (2) at least part of the person's face being digitally obscured. In some embodiments, the operations further include: determining permissions associated with the person and performing the recognition of the person based on the permissions associated with the person.
In einigen Ausführungsformen umfasst ein System ein oder mehrere Prozessoren und einen Speicher, der Anweisungen speichert, die durch den einen oder die mehreren Prozessoren ausgeführt werden, wobei die Anweisungen umfassen: Detektieren einer Person in einem Bild oder einem Video durch Bestimmen eines Personenbildbereichs, der Grenzen der Person entspricht, oder eines Gesichtsbildbereichs, der einer Position des Gesichts der Person entspricht, Analysieren von Pixelwerten, die der Person oder der Position des Gesichts der Person entsprechen, basierend auf den Grenzen der Person oder dem Gesichtsbildbereich, um ein Erkennungsvermeidungssignal zu erzeugen, Bestimmen, ob das Erkennungsvermeidungssignal angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, und in Reaktion darauf, dass das Erkennungsvermeidungssignal nicht angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, Ausführen der Erkennung der Person. Mit anderen Worten, Pixelwerte des Bilds oder Videos werden auf den und/oder innerhalb der Grenzen analysiert.In some embodiments, a system includes one or more processors and a memory that stores instructions executed by the one or more processors, the instructions comprising: detecting a person in an image or video by determining a person image area, the boundaries corresponds to the person, or a face image area corresponding to a position of the face of the person, analyzing pixel values corresponding to the person or position of the face of the person based on the boundaries of the person or face image area to generate a detection avoidance signal whether the detection avoidance signal indicates that a measure has been taken to prevent the person from being recognized, and in response to the detection avoidance signal not indicating that the measure has been taken to prevent the person from being recognized, performing the detection of the person , In other words, pixel values of the image or video are analyzed on and / or within the limits.
In einigen Ausführungsformen enthält das Ablehnen, die Erkennung der Person auszuführen, Ausführen wenigstens eines aus Speichern des Erkennungsvermeidungssignals in Zuordnung zu dem Bild oder dem Video, um anzugeben, dass Personenerkennung nicht ausgeführt werden soll, Löschen des Bilds oder Videos, Archivieren des Bilds oder Videos oder Verschieben nach unten des Bilds oder Videos in Suchergebnissen. In einigen Ausführungsformen speichert der Speicher zusätzliche Anweisungen, die umfassen: in Reaktion darauf, dass Erkennungsvermeidungssignal nicht angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, Ausführen der Erkennung der Person durch Bestimmen einer Identität der Person und Indexieren des Bilds oder Videos in Zuordnung zu der Identität. In einigen Ausführungsformen enthält das Bestimmen, dass die Maßnahme ergriffen wurde, die Erkennung der Person zu verhindern, ferner eine Bestimmung, dass das Erkennungsvermeidungssignal einem Vermeidungswert entspricht, der einen Schwellenwert nicht erfüllt, und Ausführen der Erkennung der Person auch in Reaktion darauf ist, dass der Vermeidungswert den Schwellenwert nicht erfüllt. In einigen Ausführungsformen ist die Person eine erste Person, enthält das Bestimmen, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, ferner eine Bestimmung, dass das Erkennungsvermeidungssignal einem Vermeidungswert entspricht, der einem Schwellenwert entspricht, und der Speicher speichert zusätzliche Anweisungen, die, Reaktion darauf, dass der Vermeidungswert den Schwellenwert erfüllt, Detektieren einer zweiten Person in dem Bild und Erzeugen des Erkennungsvermeidungssignals für die zweite Person umfassen.In some embodiments, refusing to perform the recognition of the person includes executing at least one of storing the recognition avoidance signal associated with the image or video to indicate that person recognition should not be performed, deleting the image or video, archiving the image or video or move down the image or video in search results. In some embodiments, the memory stores additional instructions, including: in response to the detection avoidance signal not indicating that the measure has been taken to prevent the person from being recognized, performing the person's detection by determining an identity of the person and Index the image or video in association with the identity. In some embodiments, determining that the measure to prevent the person from being recognized further includes determining that the detection avoidance signal corresponds to an avoidance value that does not meet a threshold, and performing the detection of the person in response to that the avoidance value does not meet the threshold. In some embodiments, the person is a first person, includes determining that the measure has been taken to prevent detection of the person, further includes determining that the detection avoidance signal corresponds to an avoidance value that corresponds to a threshold value, and the memory stores additional instructions comprising, in response to the avoidance value meeting the threshold, detecting a second person in the image and generating the second person detection avoidance signal.
In einigen Ausführungsformen speichert ein maschinenlesbarer Speicher Anweisungen, die dann, wenn sie ausgeführt werden, bewirken, dass eine Verarbeitungsvorrichtung Operationen ausführt, die ein Verfahren nach irgendeiner/irgendeinem hier beschriebenen Ausführungsformen oder Aspekt umfassen.In some embodiments, machine readable memory stores instructions that, when executed, cause a processing device to perform operations that include a method according to any embodiment or aspect described herein.
Die nachstehend beschriebenen verschiedenen Ausführungsformen unterbinden vorteilhafterweise, dass eine Person in einem Bild erkannt wird, wenn die Person nicht erkannt werden möchte. Das Unterbinden der Erkennung kann das Unterbinden enthalten, dass eine Person identifiziert wird und dass das Bild in Zuordnung zu einer Identität der Person indexiert wird. In einigen Ausführungsformen kann die Erkennung mehrere Ebenen enthalten, wie z. B. (1) Löschen des Bilds; (2) nicht Ausführen der Erkennung einer Person in dem Bild; (3) Ausführen einer Erkennung der Person in dem Bild, jedoch Teilen einer Identifizierung der Person nur mit Anwendern, die eine Autorisierung von der Person besitzen, die Identität der Person zu kennen.The various embodiments described below advantageously prevent a person from being recognized in an image if the person does not want to be recognized. Preventing detection can include preventing a person from being identified and indexing the image in association with an identity of the person. In some embodiments, the detection may include multiple levels, such as: B. (1) delete the image; (2) not performing recognition of a person in the image; (3) Recognizing the person in the image, but sharing identifying the person only with users who have authorization from the person to know the person's identity.
Figurenlistelist of figures
-
Die Offenbarung ist als Beispiel und nicht als Einschränkung in den Figuren der begleitenden Zeichnungen dargestellt, in denen gleiche Bezugszeichen verwendet sind, um ähnliche Elemente zu bezeichnen.The disclosure is shown by way of example and not limitation in the figures of the accompanying drawings, in which like reference numerals are used to indicate similar elements.
-
1 stellt ein Blockdiagramm eines Beispielsystems, das bestimmt, ob die Erkennung einer Person in einem Bild oder einem Video ausgeführt werden soll, gemäß einigen Ausführungsformen dar. 1 FIG. 13 illustrates a block diagram of an example system that determines whether to recognize a person in an image or video, in accordance with some embodiments.
-
2 stellt ein Blockdiagramm einer beispielhaften Berechnungsvorrichtung, die bestimmt, ob die Erkennung einer Person in einem Bild oder einem Video ausgeführt werden soll, gemäß einigen Ausführungsformen dar. 2 FIG. 13 illustrates a block diagram of an example computing device that determines whether to recognize a person in an image or video, in accordance with some embodiments.
-
3A-3D stellen Beispiele für unterschiedliche Maßnahmen, die durch eine Person in Bildern ergriffen werden können, um die Erkennung zu verhindern, gemäß einigen Ausführungsformen dar. 3A-3D illustrate examples of different measures that a person can take in images to prevent detection, according to some embodiments.
-
4 stellt eine beispielhafte digitale Veränderung von Menschen in einem Bild, um die Erkennung zu verhindern, gemäß einigen Ausführungsformen dar. 4 FIG. 13 illustrates an example digital change of people in an image to prevent recognition, according to some embodiments.
-
5 stellt einen Ablaufplan eines Beispielverfahrens zum Bestimmen, ob eine Person Maßnahmen ergriffen hat, die Erkennung in einem Bild zu verhindern, gemäß einigen Ausführungsformen dar. 5 10 illustrates a flowchart of an example method for determining whether a person has taken measures to prevent recognition in an image, in accordance with some embodiments.
AUSFÜHRLICHE BESCHREIBUNGDETAILED DESCRIPTION
Beispielsystemexample system
1 stellt ein Blockdiagramm eines Beispielsystems 100, das bestimmt, ob die Erkennung einer Person in einem Bild oder einem Video ausgeführt werden soll, dar. Das dargestellte System 100 enthält einen Erkennungsserver 101, Anwendergeräte 115a, 115n, einen zweiten Server 120 und ein Netz 105. Die Anwender 125a, 125n können entsprechenden Anwendergeräten 115a, 115n zugeordnet sein- In einigen Ausführungsformen kann das System 100 andere Server oder Vorrichtungen enthalten, die in 1 nicht gezeigt sind. In 1 und den restlichen Figuren repräsentiert ein Buchstabe nach einem Bezugszeichen, z. B. 115a", einen Bezug auf das Element, das dieses spezielle Bezugszeichen aufweist. Ein Bezugszeichen in dem Text ohne nachfolgenden Buchstaben, z. B. „115“, repräsentiert einen allgemeinen Bezug zu Ausführungsformen des Elements, das dieses Bezugszeichen trägt. 1 provides a block diagram of an example system 100 , which determines whether the recognition of a person should be carried out in an image or a video. The system shown 100 contains a detection server 101 , User equipment 115a . 115n , a second server 120 and a network 105 , The users 125a . 125n can appropriate user devices 115a . 115n may be associated - In some embodiments, the system 100 other servers or devices included in 1 are not shown. In 1 and the remaining figures represent a letter after a reference symbol, e.g. B. 115a ", a reference to the element which has this special reference symbol. A reference symbol in the text without subsequent letters, for example" 115 ", represents a general reference to embodiments of the element which carries this reference symbol.
Der Erkennungsserver 101 kann einen Prozessor, einen Speicher und Netzkommunikationsfähigkeiten enthalten. In einigen Ausführungsformen ist der Erkennungsserver 101 ein Hardware-Server. Der Erkennungsserver 101 ist mit dem Netz 105 über die Signalleitung 102 kommunikationstechnisch gekoppelt. Die Signalleitung 102 kann eine drahtgebundene Verbindung, wie z. B. Ethernet, ein Koaxialkabel, ein Lichtwellenleiter usw., oder eine drahtlose Verbindung wie z. B. Wi-Fi®, Bluetooth® oder eine andere Drahtlostechnologie sein. In einigen Ausführungsformen sendet und empfängt der Erkennungsserver 101 Daten zu und von einem oder mehreren der Anwendergeräte 115a, 115n und dem zweiten Server 120 über das Netz 105. Der Erkennungsserver 101 kann eine Erkennungsanwendung 103a und eine Datenbank 199 enthalten.The detection server 101 may include a processor, memory, and network communication capabilities. In some embodiments, the discovery server 101 a hardware server. The detection server 101 is with the network 105 via the signal line 102 coupled in terms of communication technology. The signal line 102 can a wired connection, such as. B. Ethernet, a coaxial cable, an optical fiber, etc., or a wireless connection such. B. Wi-Fi®, Bluetooth® or other wireless technology. In some embodiments, the discovery server sends and receives 101 Data to and from one or more of the user devices 115a . 115n and the second server 120 over the network 105 , The detection server 101 can be a detection application 103a and a database 199 contain.
Die Erkennungsanwendung 103a kann Code und Routinen sein, die betrieben werden können, um zu bestimmen, ob Erkennung einer Person in einem Bild oder einem Video ausgeführt werden soll. In einigen Ausführungsformen kann die Erkennungsanwendung 103a unter Verwendung von Hardware, die ein feldprogrammierbares Gatter-Array (FPGA) oder eine anwendungsspezifische integrierte Schaltung (ASIC) enthält, implementiert sein. In einigen Ausführungsformen kann die Erkennungsanwendung 103a unter Verwendung einer Kombination aus Hardware und Software implementiert sein. The detection application 103a can be code and routines that can be used to determine whether recognition of a person in an image or video should be performed. In some embodiments, the detection application 103a using hardware that includes a field programmable gate array (FPGA) or application specific integrated circuit (ASIC). In some embodiments, the detection application 103a implemented using a combination of hardware and software.
Die Datenbank 199 kann animierte Objekte, Nachrichtenübermittlungsströme usw. speichern. Beispielsweise kann die Datenbank 199 Bilder und/oder Videos speichern. In Ausführungsformen, in denen Menschen in Bildern und Videos erkannt werden, kann die Datenbank 199 Bilder und Videos speichern, die indexiert und Identitäten der Menschen zugeordnet sind. Beispielsweise kann ein Bild in Zuordnung zu Metadaten, die einen Anwender eines sozialen Netzwerks beschreiben und einen Link auf ein Profil des Anwenders in dem sozialen Netzwerk enthalten, indexiert sein. Die Datenbank 199 kann außerdem Daten des sozialen Netzwerks, die Anwendern 125 zugeordnet sind, Anwenderpräferenzen für die Anwender 125 usw. speichern.Database 199 can store animated objects, messaging streams, etc. For example, the database 199 Save pictures and / or videos. In embodiments in which people are recognized in images and videos, the database 199 Store images and videos that are indexed and associated with people's identities. For example, an image can be indexed in association with metadata that describe a user of a social network and contain a link to a profile of the user in the social network. Database 199 can also share social network data, users 125 are assigned user preferences for users 125 etc. save.
Das Anwendergerät 115 kann eine Berechnungsvorrichtung sein, die einen Speicher und einen Hardware-Prozessor enthält. Beispielsweise kann das Anwendergerät einen Desktop-Computer, eine mobile Vorrichtung, einen Tablet-Computer, ein Mobiltelefon, eine tragbare Vorrichtung, eine am Kopf getragene Vorrichtung, eine mobile E-Mail-Vorrichtung, eine tragbare Spielkonsole, ein tragbares Musikabspielgerät, eine Lesevorrichtung oder eine andere elektronische Vorrichtung, die zum Zugreifen auf ein Netz 105 fähig ist, enthalten.The user device 115 may be a computing device that includes memory and a hardware processor. For example, the user device may be a desktop computer, a mobile device, a tablet computer, a mobile phone, a portable device, a head-worn device, a mobile email device, a portable game console, a portable music player, a reading device or another electronic device used to access a network 105 is able to contain.
In der dargestellten Implementierung ist das Anwendergerät 115a mit dem Netz 105 über die Signalleitung 108 gekoppelt, und das Anwendergerät 115n ist mit dem Netz 105 über die Signalleitung 110 gekoppelt. Die Signalleitungen 108 und 110 können eine drahtgebundene Verbindung, wie z. B. Ethernet, ein Koaxialkabel, ein Lichtwellenleiter usw., oder eine drahtlose Verbindung wie z. B. Wi-Fi®, Bluetooth@ oder eine andere Drahtlostechnologie sein. Auf die Anwendergeräte 115a, 115n wird durch die Anwender 125a bzw. 125n zugegriffen. Die Anwendergeräte 115a, 115n in 1 sind als Beispiel verwendet. Obwohl 1 zwei Anwendergeräte, 115a und 115n, darstellt, gilt die Offenbarung für eine Systemarchitektur, die ein oder mehr Anwendergeräte 115 aufweist.In the implementation shown, the user device is 115a with the network 105 via the signal line 108 coupled, and the user device 115n is with the network 105 via the signal line 110 coupled. The signal lines 108 and 110 can a wired connection such. B. Ethernet, a coaxial cable, an optical fiber, etc., or a wireless connection such. B. Wi-Fi®, Bluetooth @ or another wireless technology. On the user devices 115a . 115n is by the user 125a respectively. 125n accessed. The user devices 115a . 115n in 1 are used as an example. Even though 1 two user devices, 115a and 115n , the disclosure applies to a system architecture that includes one or more user devices 115 having.
In einigen Ausführungsformen kann das Anwendergerät 115 ein Anwendergerät sein, das in einer tragbaren Vorrichtung, die durch den Anwender 125 getragen wird, enthalten ist. Beispielsweise ist das Anwendergerät 115 als Teil einer Spange (z. B. eines Armbands), Teil von Schmuck oder Teil einer Brille enthalten. In einem weiteren Beispiel kann das Anwendergerät 115 eine Smartwatch sein. Der Anwender 125 kann Daten, die der Erkennungsanwendung 103 zugeordnet sind, auf einer Anzeigevorrichtung der Vorrichtung, die durch den Anwender 125 getragen wird. Beispielsweise kann die Erkennungsanwendung 103a Bilder, Videos und/oder Fragen zu der Berechtigung, die einer Person, die in einem Bild oder einem Video erkannt wird, zugeordnet ist, auf einer Anzeigevorrichtung einer Smartwatch oder eines intelligenten Armbands anzeigen.In some embodiments, the user device 115 be a user device that is in a portable device designed by the user 125 is worn, is included. For example, the user device 115 included as part of a clasp (e.g. a bracelet), part of jewelry or part of glasses. In another example, the user device 115 be a smartwatch. The user 125 can data that the detection application 103 are assigned on a display device of the device by the user 125 will be carried. For example, the detection application 103a Display images, videos and / or questions about the authorization assigned to a person who is recognized in an image or a video on a display device of a smartwatch or an intelligent bracelet.
In einigen Ausführungsformen kann die Erkennungsanwendung 103b auf einem Anwendergerät 115a gespeichert sein. Die Erkennungsanwendung 103 kann eine „Thin-Client“-Erkennungsanwendung 103b, die auf dem Anwendergerät 115a gespeichert ist, und eine Erkennungsanwendung 103a, die auf dem Erkennungsserver 101 gespeichert ist, enthalten. Beispielsweise kann die Erkennungsanwendung 103b, die auf dem Anwendergerät 115a gespeichert ist, einen Nachrichtenübermittlungsstrom, der ein animiertes Objekt enthält, anzeigen. Das Anwendergerät 115a kann eine Kamera enthalten, die ein Bild oder ein Video aufnimmt, das die Erkennungsanwendung 103b zur Verarbeitung zu dem Erkennungsserver 101 sendet. Die Erkennungsanwendung 103a, die auf dem Erkennungsserver 101 gespeichert ist, kann das Bild oder Video empfangen und bestimmen, ob ein Erkennungsvermeidungssignal, das dem Bild oder Video zugeordnet ist, angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern.In some embodiments, the detection application 103b on a user device 115a be saved. The detection application 103 can be a “thin client” detection application 103b that are on the user device 115a and a detection application 103a that are on the detection server 101 saved. For example, the detection application 103b that are on the user device 115a stored, display a messaging stream that contains an animated object. The user device 115a may include a camera that takes a picture or video that the detection application 103b for processing to the recognition server 101 sends. The detection application 103a that are on the detection server 101 stored, the image or video may receive and determine whether a detection avoidance signal associated with the image or video indicates that action has been taken to prevent the person from being recognized.
Der zweite Server 120 kann einen Prozessor, einen Speicher und Netzkommunikationsfähigkeiten enthalten. Der zweite Server 120 kann über die Signalleitung 109 auf das Netz 105 zugreifen. Der zweite Server 120 kann eine Anwendung enthalten, die Informationen über Menschen, die in Bildern und Videos durch die Erkennungsanwendung 103a erkannt werden, verwendet. Beispielsweise kann der zweite Server 120 eine Anwendung für soziale Netzwerke enthalten, die Identifizierungsinformationen über Menschen in Bildern und Videos von der Erkennungsanwendung 103a empfängt und die Identifizierungsinformationen Anwendern der Anwendung für soziale Netzwerke zuordnet. In einem weiteren Beispiel kann der zweite Server 120 eine Fotobearbeitungsanwendung zum digitalen Verdecken eines Bilds oder eines Videos, beispielsweise durch Verwischung oder Verpixelung von Gesichtern von Menschen in dem Bild, enthalten. In noch einem weiteren Beispiel kann der zweite Server 120 eine Fotoanwendung, eine Kalenderanwendung, eine Ereignis-Organizer-Anwendung usw. enthalten.The second server 120 may include a processor, memory, and network communication capabilities. The second server 120 can over the signal line 109 on the net 105 access. The second server 120 can contain an application that provides information about people in pictures and videos through the recognition application 103a are recognized, used. For example, the second server 120 an application for social networks that contain identification information about people in pictures and videos from the recognition application 103a receives and associates the identification information with users of the social networking application. In another example, the second server 120 a photo editing application for digitally obscuring an image or video, for example, by blurring or pixelating faces of people in the image. In yet another example, the second server 120 a photo application, a calendar application, an event organizer application, etc.
In der dargestellten Implementierung sind die Entitäten des Systems 100 über ein Netz 105 kommunikationstechnisch gekoppelt. Das Netz 105 kann vom herkömmlichen Typ sein, drahtgebunden oder drahtlos, und kann zahlreiche unterschiedliche Konfigurationen aufweisen, die eine Sternkonfiguration, eine Token Ring-Konfiguration oder andere Konfigurationen enthalten. Darüber hinaus kann das Netz 105 ein lokales Netz (LAN), ein Weitbereichsnetz (WAN) (z. B. das Internet) und/oder andere miteinander verbundene Datenpfade, über die mehrere Vorrichtungen kommunizieren können, enthalten. In einigen Ausführungsformen kann das Netz 105 ein Peer-to-Peer-Netz sein. Das Netz 105 kann mit auch einem Telekommunikationsnetz zum Senden von Daten in einer Vielzahl von unterschiedlichen Kommunikationsprotokollen gekoppelt sein oder Abschnitte davon enthalten. In einigen Ausführungsformen enthält das Netz 105 Bluetooth@-Kommunikationsnetze, WiFi®, durch IEEE 902.11 spezifizierte Computerkommunikation über ein drahtloses lokales Netz (WLAN) oder ein zelluläres Kommunikationsnetz zum Senden und Empfangen von Daten, einschließlich über Kurznachrichtendienst (SMS), Multimedianachrichtendienst (MMS), Hypertextübertragungsprotokoll (HTTP), direkte Datenverbindung, E-Mail usw. Obwohl 1 ein Netz 105 darstellt, das mit den Anwendergeräten 115 und dem Erkennungsserver 101 gekoppelt ist, können in der Praxis ein oder mehrere Netze 105 mit diesen Entitäten gekoppelt sein. In the implementation shown are the entities of the system 100 over a network 105 coupled in terms of communication technology. The network 105 can be of the conventional type, wired or wireless, and can have numerous different configurations including a star configuration, a Token Ring configuration, or other configurations. In addition, the network 105 a local area network (LAN), a wide area network (WAN) (e.g., the Internet) and / or other interconnected data paths over which multiple devices can communicate. In some embodiments, the network 105 be a peer-to-peer network. The network 105 can also be coupled to or contain sections of a telecommunications network for sending data in a multiplicity of different communication protocols. In some embodiments, the network includes 105 Bluetooth @ communication networks, WiFi®, computer communication specified by IEEE 902.11 via a wireless local area network (WLAN) or a cellular communication network for sending and receiving data, including via short message service (SMS), multimedia message service (MMS), hypertext transmission protocol (HTTP), direct Data connection, email, etc. Although 1 a net 105 represents that with the user devices 115 and the detection server 101 in practice, one or more networks can be coupled 105 be coupled with these entities.
In Situationen, in denen die hier diskutierten Systeme und Verfahren persönliche Informationen über Anwender (z. B. Anwenderdaten, Informationen über das soziale Netzwerk eines Anwenders, den Aufenthaltsort eines Anwenders, biometrische Informationen über den Anwender, Aktivitäten und/oder Demographieinformationen des Anwenders, Speichern und Analysieren von Bildern oder Videos durch den Erkennungsserver 101 oder die Erkennungsanwendung 103 usw.) sammeln oder verwenden können, sind die Anwender mit Gelegenheiten ausgestattet, zu steuern, ob persönliche Informationen gesammelt werden, ob die persönlichen Informationen gespeichert werden, ob die persönlichen Informationen verwendet werden, ob die Bilder oder Videos analysiert werden und wie Informationen über den Anwender gesammelt, gespeichert und verwendet werden. Das heißt, die Systeme und Verfahren, die hier diskutiert sind, können persönliche Informationen des Anwenders nur nach dem Empfangen einer ausdrücklichen Autorisierung von den relevanten Anwendern, die das erlauben, sammeln, speichern und/oder verwenden. Beispielsweise ist ein Anwender mit der Kontrolle darüber ausgestattet, ob Programme oder Merkmale Anwenderinformationen über diesen speziellen Anwender oder andere Anwender, die für das Programm oder das Merkmal relevant sind, sammeln. Jedem Anwender, für den persönliche Informationen gesammelt werden sollen, werden eine oder mehrere Optionen präsentiert, um die Kontrolle über die Informationssammlung, die für diesen Anwender relevant ist, zu ermöglichen, um Berechtigung oder Autorisierung dafür zu erteilen, ob die Informationen gesammelt werden und welche Abschnitte der Informationen gesammelt werden sollen. Beispielsweise können Anwender mit einer oder mehreren solcher Steuerungsoptionen über ein Kommunikationsnetz versorgt werden. Zusätzlich können spezielle Daten auf eine oder mehrere Arten behandelt werden, bevor sie gespeichert oder verwendet werden, so dass persönlich identifizierbare Informationen entfernt werden. Als ein Beispiel können die Identitätsinformationen eines Anwenders behandelt, z. B. anonymisiert, werden, so dass keine persönlich identifizierbaren Informationen aus einem Video bestimmt werden können. Als ein weiteres Beispiel kann der geographische Aufenthaltsort eines Anwenders auf ein größeres Gebiet verallgemeinert werden, so dass der spezielle Aufenthaltsort des Anwenders nicht bestimmt werden kann.In situations where the systems and methods discussed here store personal information about users (e.g., user data, information about a user's social network, location of a user, biometric information about the user, activities, and / or demographic information of the user) and analyzing images or videos by the recognition server 101 or the detection application 103 etc.), users are provided with opportunities to control whether personal information is collected, whether the personal information is stored, whether the personal information is used, whether the images or videos are analyzed and how information about the Users are collected, saved and used. That is, the systems and methods discussed here can only collect, store, and / or use the user's personal information after receiving express authorization from the relevant users that allow it. For example, a user is provided with control over whether programs or features collect user information about this particular user or other users that are relevant to the program or feature. Each user for whom personal information is to be collected is presented with one or more options to allow control over the information collection relevant to that user, to give authorization or authorization for whether the information is collected and which Sections of the information to be collected. For example, users can be supplied with one or more such control options via a communication network. In addition, special data can be treated in one or more ways before it is stored or used, so that personally identifiable information is removed. As an example, a user's identity information can be treated e.g. B. anonymized, so that no personally identifiable information can be determined from a video. As another example, a user's geographic location can be generalized to a larger area so that the user's specific location cannot be determined.
Beispielhafte BerechnungsvorrichtungExemplary calculation device
2 stellt ein Blockdiagramm einer beispielhaften Berechnungsvorrichtung 200, die bestimmt, ob eine Person in einem Bild oder einem Video erkannt werden soll, dar. Die Berechnungsvorrichtung 200 kann ein Erkennungsserver 101, ein Anwendergerät 115 oder eine Kombination aus einem Erkennungsserver 101 und einem Anwendergerät 115 sein. Die Berechnungsvorrichtung 200 kann einen Prozessor 235, einen Speicher 237, eine Kommunikationseinheit 239, eine Anzeigevorrichtung 241 und eine Speichervorrichtung 247 enthalten. Zusätzliche Komponenten können vorhanden sein, oder einige der vorstehenden Komponenten können weggelassen sein, abhängig von dem Typ der Berechnungsvorrichtung 200. Falls beispielsweise die Berechnungsvorrichtung 200 der Erkennungsserver 101 ist, kann die Berechnungsvorrichtung 200 die Anzeigevorrichtung 241 nicht enthalten. Eine Erkennungsanwendung 103 kann in dem Speicher 237 gespeichert sein. In Ausführungsformen, in denen die Berechnungsvorrichtung 200 eine tragbare Vorrichtung ist, kann die Berechnungsvorrichtung 200 die Speichervorrichtung 247 nicht enthalten. In einigen Ausführungsformen kann die Berechnungsvorrichtung 200 andere Komponenten, die hier nicht aufgelistet sind, wie z. B. eine Batterie usw., enthalten. Die Komponenten der Berechnungsvorrichtung 200 können durch einen Bus 220 kommunikationstechnisch gekoppelt sein. 2 FIG. 4 illustrates a block diagram of an example computing device 200 , which determines whether a person should be recognized in an image or a video. The computing device 200 can be a detection server 101 , a user device 115 or a combination of a discovery server 101 and a user device 115 his. The calculation device 200 can be a processor 235 , a memory 237 , a communication unit 239 , a display device 241 and a storage device 247 contain. Additional components may be present, or some of the above components may be omitted, depending on the type of computing device 200 , For example, if the computing device 200 the detection server 101 is, the computing device 200 the display device 241 not included. A detection application 103 can in the store 237 be saved. In embodiments in which the computing device 200 is a portable device, the computing device 200 the storage device 247 not included. In some embodiments, the computing device 200 other components that are not listed here, such as B. a battery, etc. included. The components of the computing device 200 can by a bus 220 be coupled in terms of communication technology.
Der Prozessor 235 enthält eine Arithmetiklogikeinheit, einen Mikroprozessor, eine Allzwecksteuereinheit oder irgendein anderes Prozessor-Array, um Berechnungen auszuführen und Anweisungen für eine Anzeigevorrichtung bereitzustellen. Der Prozessor 235 verarbeitet Daten und kann verschiedene Berechnungsarchitekturen enthalten, die eine Computer-Architektur mit komplexem Befehlssatz (CISC-Architektur) oder eine Computer-Architektur mit reduziertem Befehlssatz (RISC-Architektur) oder eine Architektur, die eine Kombination von Befehlssätzen implementiert, enthalten. Obwohl 2 einen einzigen Prozessor 235 enthält, können mehrere Prozessoren 235 enthalten sein. Andere Prozessoren, Betriebssysteme, Sensoren, Anzeigevorrichtungen und physikalische Konfigurationen können Teil der Berechnungsvorrichtung 200 sein. Der Prozessor 235 ist mit dem Bus 220 zur Kommunikation mit den anderen Komponenten über die Signalleitung 222 gekoppelt.The processor 235 includes an arithmetic logic unit, a microprocessor, a general-purpose control unit, or any other processor array to perform calculations and provide instructions to a display device. The processor 235 processes data and can be different Computation architectures include a computer architecture with a complex instruction set (CISC architecture) or a computer architecture with a reduced instruction set (RISC architecture) or an architecture that implements a combination of instruction sets. Even though 2 a single processor 235 contains multiple processors 235 be included. Other processors, operating systems, sensors, displays, and physical configurations can be part of the computing device 200 his. The processor 235 is on the bus 220 for communication with the other components via the signal line 222 coupled.
Der Speicher 237 speichert Anweisungen, die durch den Prozessor 235 ausgeführt werden können, und/oder Daten. Die Anweisungen können Code zum Ausführen der hier beschriebenen Techniken enthalten. Der Speicher 237 kann eine Vorrichtung mit dynamischem Direktzugriffsspeicher (DRAM), ein statischer RAM oder eine andere Speichervorrichtung sein. In einigen Ausführungsformen enthält der Speicher 237 auch einen nichtflüchtigen Speicher, wie z. B. eine Vorrichtung mit statischem Direktzugriffsspeicher (SRAM) oder Flash-Speicher oder eine ähnliche Permanentspeichervorrichtung, und Medien, die ein Festplattenlaufwerk, eine Vorrichtung mit Compact-Disc-Festwertspeicher (CD-ROM), eine DVD-ROM-Vorrichtung, eine DVD-RAM-Vorrichtung, eine DVD-RW-Vorrichtung, eine Flash-Speichervorrichtung oder eine andere Massenspeichervorrichtung zum Speichern von Informationen auf einer mehr permanenten Basis. Der Speicher 237 enthält Code und Routinen, die betrieben werden können, um die Erkennungsanwendung 103, die nachstehend genauer beschrieben ist, auszuführen. Der Speicher 237 ist mit dem Bus 220 zur Kommunikation mit den anderen Komponenten über die Signalleitung 224 gekoppelt.The memory 237 stores instructions by the processor 235 can be executed and / or data. The instructions can include code to perform the techniques described here. The memory 237 may be a dynamic random access memory (DRAM) device, a static RAM, or other memory device. In some embodiments, the memory contains 237 also a non-volatile memory, such as. B. a device with static random access memory (SRAM) or flash memory or a similar permanent storage device, and media that a hard disk drive, a device with compact disc read-only memory (CD-ROM), a DVD-ROM device, a DVD- RAM device, DVD-RW device, flash memory device or other mass storage device for storing information on a more permanent basis. The memory 237 contains code and routines that can be operated to the detection application 103 , which is described in more detail below. The memory 237 is on the bus 220 for communication with the other components via the signal line 224 coupled.
Die Kommunikationseinheit 239 sendet und empfängt Daten zu und von dem Anwendergerät 115 und/oder dem Erkennungsserver 101, abhängig davon, wo die Erkennungsanwendung 103 gespeichert sein kann. In einigen Ausführungsformen enthält die Kommunikationseinheit 239 einen Anschluss zur direkten physikalischen Verbindung mit dem Netz 105 oder mit einem weiteren Kommunikationskanal. Beispielsweise enthält die Kommunikationseinheit 239 einen universellen seriellen Bus- (USB-), sicheren digitalen (SD-), Kategorie-5-Kabel- (CAT-5-) oder ähnlichen Anschluss zur drahtgebundenen Kommunikation mit dem Anwendergerät 115 oder dem Erkennungsserver 101, abhängig davon, wo die Erkennungsanwendung 103 gespeichert sein kann. In einigen Ausführungsformen enthält die Kommunikationseinheit 239 einen drahtlosen Sender/Empfänger zum Austauschen von Daten mit dem Anwendergerät 115, dem Erkennungsserver 101 oder anderen Kommunikationskanälen unter Verwendung eines oder mehrerer Drahtloskommunikationsverfahren, die IEEE 802.11, IEEE 802.16, Bluetooth@ oder ein anderes geeignetes Drahtloskommunikationsverfahren enthalten. Die Kommunikationseinheit 239 ist mit dem Bus 220 zur Kommunikation mit den anderen Komponenten über die Signalleitung 226 gekoppelt.The communication unit 239 sends and receives data to and from the user device 115 and / or the recognition server 101 , depending on where the detection application 103 can be saved. In some embodiments, the communication unit includes 239 a connection for direct physical connection to the network 105 or with another communication channel. For example, the communication unit contains 239 a universal serial bus (USB), secure digital (SD), category 5 cable (CAT-5) or similar connection for wired communication with the user device 115 or the detection server 101 , depending on where the detection application 103 can be saved. In some embodiments, the communication unit includes 239 a wireless transmitter / receiver for exchanging data with the user device 115 , the recognition server 101 or other communication channels using one or more wireless communication methods that include IEEE 802.11, IEEE 802.16, Bluetooth @ or other suitable wireless communication method. The communication unit 239 is on the bus 220 for communication with the other components via the signal line 226 coupled.
In einigen Ausführungsformen enthält die Kommunikationseinheit 239 einen Sender/Empfänger für zelluläre Kommunikation zum Senden und Empfangen von Daten über ein zelluläres Kommunikationsnetz, einschließlich über Kurznachrichtendienst (SMS), Multimedianachrichtendienst (MMS), Hypertextübertragungsprotokoll (HTTP), direkte Datenverbindung, E-Mail oder einen anderen geeigneten Typ elektronischer Kommunikation. In einigen Ausführungsformen enthält die Kommunikationseinheit 239 einen drahtgebundenen Anschluss und einen drahtlosen Sender/Empfänger. Die Kommunikationseinheit 239 stellt außerdem andere herkömmliche Verbindung mit dem Netz 105 zur Verteilung von Dateien und/oder Medienobjekten unter Verwendung von Standard-Netzprotokollen, die, ohne darauf beschränkt zu sein, Anwenderdatagrammprotokoll (UDP), TCP/IP, HTTP, sicheres HTTP (HTTPS), einfaches Mail-Übertragungsprotokoll (SMTP), SPDY, schnelle UDP-Internetverbindung (QUIC) usw. enthalten.In some embodiments, the communication unit includes 239 a cellular communication transceiver for sending and receiving data over a cellular communication network, including via short message service (SMS), multimedia message service (MMS), hypertext transmission protocol (HTTP), direct data connection, email or other suitable type of electronic communication. In some embodiments, the communication unit includes 239 a wired connection and a wireless transmitter / receiver. The communication unit 239 also provides other conventional connection to the network 105 for the distribution of files and / or media objects using standard network protocols which, without being limited to them, user datagram protocol (UDP), TCP / IP, HTTP, secure HTTP (HTTPS), simple mail transmission protocol (SMTP), SPDY, Fast UDP internet connection (QUIC) etc. included.
Die Anzeigevorrichtung 241 kann Hardware enthalten, die betrieben werden kann, um Grafikdaten, die von der Erkennungsanwendung 103 empfangen werden, anzuzeigen. Beispielsweise kann die Anzeigevorrichtung 241 Grafik rendern, um ein Bild oder eine Frage über Berechtigungen, die einem Bild zugeordnet sind, anzuzeigen. Die Anzeigevorrichtung 241 ist mit dem Bus 220 zur Kommunikation mit den anderen Komponenten über die Signalleitung 228 gekoppelt.The display device 241 may include hardware that can be operated to receive graphics data from the recognition application 103 received to display. For example, the display device 241 Render graphic to display an image or question about permissions associated with an image. The display device 241 is on the bus 220 for communication with the other components via the signal line 228 coupled.
Die Speichervorrichtung 247 kann ein nicht-transitorisches computerlesbares Speichermedium sein, das Daten, die die hier beschriebene Funktionalität bereitstellen, speichert. In Ausführungsformen, in denen die Berechnungsvorrichtung 200 der Erkennungsserver 101 ist, kann die Speichervorrichtung 247 die Datenbank 199 in 1 enthalten. Die Speichervorrichtung 247 kann eine DRAM-Vorrichtung, eine SRAM-Vorrichtung, Flash-Speicher oder eine andere Speichervorrichtung sein. In einigen Ausführungsformen enthält die Speichervorrichtung 247 außerdem einen nichtflüchtigen Speicher oder eine ähnliche Permanentspeichervorrichtung und Medien, die ein Festplattenlaufwerk, eine CD-ROM-Vorrichtung, eine DVD-ROM-Vorrichtung, eine DVD-RAM-Vorrichtung, eine DVD-RW-Vorrichtung, eine Flash-Speichervorrichtung oder eine andere Massenspeichervorrichtung zum Speichern von Informationen auf einer mehr permanenten Basis enthalten. Die Speichervorrichtung 247 ist mit dem Bus 220 zur Kommunikation mit den anderen Komponenten über die Signalleitung 230 gekoppelt.The storage device 247 may be a non-transitory computer readable storage medium that stores data that provides the functionality described herein. In embodiments in which the computing device 200 the detection server 101 the storage device 247 database 199 in 1 contain. The storage device 247 may be a DRAM device, an SRAM device, flash memory, or other storage device. In some embodiments, the storage device includes 247 also a non-volatile memory or similar permanent storage device and media comprising a hard disk drive, a CD-ROM device, a DVD-ROM device, a DVD-RAM device, a DVD-RW device, a flash memory device or another Mass storage device for storing information on a more permanent basis contain. The storage device 247 is on the bus 220 for communication with the other components via the signal line 230 coupled.
Die Erkennungsanwendung 103 kann einen Detektor 202, einen Analysator 204, ein Erkennungsmodul 206 und ein Anwenderschnittstellenmodul 208 enthalten.The detection application 103 can be a detector 202 , an analyzer 204 , a detection module 206 and a user interface module 208 contain.
Der Detektor 202 detektiert eine Person in einem Bild oder einem Video. In einigen Ausführungsformen enthält der Detektor 202 eine Gruppe von Anweisungen, die durch den Prozessor 235 ausführbar sind, um die Person zu detektieren. In einigen Ausführungsformen ist der Detektor 202 in dem Speicher 237 der Berechnungsvorrichtung 200 gespeichert und kann durch den Prozessor 235 zugänglich und ausführbar sein.The detector 202 detects a person in an image or video. In some embodiments, the detector includes 202 a group of instructions by the processor 235 are executable to detect the person. In some embodiments, the detector 202 in the store 237 the calculation device 200 stored and can by the processor 235 be accessible and executable.
In einigen Ausführungsformen verarbeitet der Detektor 202 ein Bild oder ein Video unter Verwendung von Computersichtalgorithmen. Die Computersichtalgorithmen können einen Personendetektor und einen Gesichtsdetektor zum Detektieren von Menschen und/oder Gesichtern enthalten. Der Personendetektor und der Gesichtsdetektor können Personenschablonen und Gesichtsschablonen verwenden, die Schablonen für Daten, die einer Person bzw. einem Gesicht zugeordnet sind, beschreiben. Beispielsweise können die Personenschablonen und die Gesichtsschablonen Objektvorgängern entsprechen, die unterschiedliche Typen von Menschen und Gesichtern beschreiben. Die Gesichtsschablonen und die Personenschablonen können auf erwarteten Punkten, die einem/einer erwarteten Gesicht oder Person entsprechen, basieren. Beispielsweise kann eine Personenschablone den erwarteten Ort eines Kopfes, von Schultern, Armen, Brust, Beinen, Füßen usw. und den Abstand zwischen den Orten enthalten. Der Detektor 202 kann außerdem bestimmen, ob die Orte der Punkte auf einer Person Haltungen für Menschen entsprechen. Beispielsweise können die Punkte einer Person entsprechen, die steht, sitzt, läuft usw.In some embodiments, the detector processes 202 an image or video using computer vision algorithms. The computer vision algorithms can include a person detector and a face detector for detecting people and / or faces. The person detector and face detector can use person stencils and face stencils that describe stencils for data associated with a person and a face, respectively. For example, the personal templates and the facial templates can correspond to object predecessors that describe different types of people and faces. The face templates and person templates can be based on expected points that correspond to an expected face or person. For example, a person's template may include the expected location of a head, shoulders, arms, chest, legs, feet, etc., and the distance between locations. The detector 202 can also determine whether the locations of the points on a person correspond to people's attitudes. For example, the points may correspond to a person standing, sitting, running, etc.
Der Detektor 202 kann einen Personenbildbereich, der den Grenzen der Person entspricht, oder einen Gesichtsbildbereich, der einer Position des Gesichts der Person entspricht, bestimmen. Beispielsweise kann der Detektor 202 einen Grenzrahmen erzeugen, der ein Gesicht und/oder einen Körper einer Person umgibt. In einigen Ausführungsformen kann der Detektor 202 ein Gesicht basierend auf Gesichtspunkten und einem Abstand zwischen den Gesichtspunkten detektieren. Beispielsweise kann der Detektor 202 Augen, Augenbrauen, eine Nase, einen Mund und Haar identifizieren und bestätigen, dass diese Gesichtspunkte einem Gesicht entsprechen, falls die Gesichtspunkte den erwarteten Abständen zwischen den Gesichtspunkten entsprechen. Der Detektor 202 kann das Gesicht basierend auf einer konvexen Hülle durch Erzeugen einer Form aus den Gesichtspunkten (z. B. eines konvexen Polygons) und Bestätigen, dass die Form einer erwarteten Form für ein Gesicht entspricht, bestimmen. In einigen Ausführungsformen, in denen ein Bild eine Pixelmaske anstelle eines Gesichts enthält, kann der Detektor 202 die Pixelmaske identifizieren und bestimmen, dass die Pixelmaske einem Gesicht entspricht. In einigen Ausführungsformen kann der Detektor 202 Clustern verwenden, um Menschen zu identifizieren. In Beispielen, in denen der Detektor 202 ein Video verarbeitet, kann der Detektor 202 jeden Bildrahmen des Videos verarbeiten, um Gesichter und/oder Menschen zu detektieren.The detector 202 may determine a person image area that corresponds to the boundaries of the person or a face image area that corresponds to a position of the face of the person. For example, the detector 202 create a border frame that surrounds a person's face and / or body. In some embodiments, the detector 202 detect a face based on points of view and a distance between the points of view. For example, the detector 202 Identify eyes, eyebrows, a nose, a mouth and hair and confirm that these points of view correspond to a face if the points of view correspond to the expected distances between the points of view. The detector 202 may determine the face based on a convex hull by creating a shape from the viewpoints (e.g., a convex polygon) and confirming that the shape corresponds to an expected shape for a face. In some embodiments, where an image contains a pixel mask instead of a face, the detector can 202 identify the pixel mask and determine that the pixel mask corresponds to a face. In some embodiments, the detector 202 Use clusters to identify people. In examples where the detector 202 the detector can process a video 202 Process every frame of the video to detect faces and / or people.
Der Analysator 204 erzeugt ein Erkennungsvermeidungssignal. In einigen Ausführungsformen enthält der Analysator 204 eine Gruppe von Anweisungen, die durch den Prozessor 235 ausführbar sind, um das Erkennungsvermeidungssignal zu erzeugen. In einigen Ausführungsformen ist der Analysator 204 in dem Speicher 237 der Berechnungsvorrichtung 200 gespeichert und kann durch den Prozessor 235 zugänglich und ausführbar sein.The analyzer 204 generates a detection avoidance signal. In some embodiments, the analyzer includes 204 a group of instructions by the processor 235 are executable to generate the detection avoidance signal. In some embodiments, the analyzer is 204 in the store 237 the calculation device 200 stored and can by the processor 235 be accessible and executable.
Der Analysator 204 verarbeitet jede/s detektierte Person und/oder Gesicht in dem Bild oder Video, um ein Erkennungsvermeidungssignal zu bestimmen, das angibt, ob die Person es nicht zu wünschen scheint, fotografiert zu werden, oder ob das Foto bearbeitet wurde, um die Identität der Person zu maskieren oder zu verändern.The analyzer 204 processes each detected person and / or face in the image or video to determine a detection avoidance signal that indicates whether the person does not appear to want to be photographed or whether the photo has been edited to determine the person's identity to mask or change.
Der Analysator 204 kann das Erkennungsvermeidungssignal durch Analysen von Pixelwerten, die der Person entsprechen, oder der Position des Gesichts der Person, basierend auf den Grenzen der Person oder dem Gesichtsbildbereich erzeugen. Der Analysator 204 kann ferner bestimmen, ob das Erkennungsvermeidungssignal angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern. Beispielsweise kann die Maßnahme enthalten, dass die Person ein Objekt in dem Bild verwendet, um wenigstens einen Teil des Gesichts der Person zu verdecken, wobei das Objekt ein Körperteil, wie z. B. eine Hand, Kleidung usw. ist. 3A-3D stellen Beispiele für unterschiedliche Maßnahmen, die durch eine Person in Bildern ergriffen werden können, um die Erkennung zu verhindern, gemäß einigen Ausführungsformen dar. Alternativ oder zusätzlich kann die Maßnahme das digitale Verdecken wenigstens eines Teils des Gesichts der Person enthalten.The analyzer 204 may generate the detection avoidance signal by analyzing pixel values corresponding to the person or the position of the person's face based on the boundaries of the person or the face image area. The analyzer 204 may further determine whether the recognition avoidance signal indicates that a measure has been taken to prevent the person from being recognized. For example, the measure may include the person using an object in the image to hide at least part of the person's face, the object being a body part, such as a body part. B. is a hand, clothes, etc. 3A-3D illustrate examples of different measures that can be taken by a person in images to prevent recognition, according to some embodiments. Alternatively or additionally, the measure may include digitally masking at least part of the face of the person.
Weiter zu 3A enthält ein Bild 300 eine Frau, die ihre Hand hebt, was ein Anzeichen sein kann, dass die Frau nicht wollte, in dem Bild erkannt zu werden. Weil die Hand der Frau ihr Gesicht nicht vollständig verdeckt, ist nicht klar, ob sie versuchte, ihr Gesicht zu verdecken, sie ihre Hand bewegt hat, um etwas zu fassen, oder sie dabei war, jemandem zu winken.Further to 3A contains an image 300 a woman raising her hand, which may be an indication that the woman did not want to be recognized in the picture. Because the woman’s hand isn’t completely covering her face, it’s not clear if she’s trying covering her face, moving her hand to catch something, or going to wave to someone.
In einigen Ausführungsformen kann der Analysator 204 das Erkennungsvermeidungssignal durch Analysen von Pixelwerten, die der Person entsprechen, oder der Position des Gesichts der Person, basierend auf den Grenzen der Person oder dem Gesichtsbildbereich erzeugen. Der Analysator 204 kann den Ausdruck einer Person basierend auf Schablonenausdrücken wie z. B. glücklich, traurig, ärgerlich, beunruhigt usw. kategorisieren. Die Schablonenausdrücke können darauf basieren, dass der Mund der Person nach oben gerichtet, gerade, nach unten gerichtet oder breit ist; die Augen einer Person weit, geschlossen, zusammengekniffen sind; die Augenbrauen einer Person hochgezogen oder gewinkelt sind; das Stirnrunzeln einer Person sichtbar ist, usw. Beispielsweise kann in 3A der Analysator 204 bestimmen, dass die Frau nicht erkannt werden möchte, weil ein Teil ihrer Hand ihr Gesicht überlappt und sie einen Ausdruck der Besorgnis aufweist, wie dadurch angezeigt ist, dass ihr Mund ein O bildet, ihre Augen weit sind und ihre Augenbrauen hochgezogen sind. Umgekehrt kann, falls die Hand in der gleichen Position war, aber die Frau gelächelt hat, der Analysator 204 bestimmen, dass sich die Frau mit dem Erkanntwerden in dem Bild wohlfühlt.In some embodiments, the analyzer 204 generate the detection avoidance signal by analyzing pixel values corresponding to the person or the position of the person's face based on the boundaries of the person or the face image area. The analyzer 204 can express a person's expression based on template expressions such as B. categorize happy, sad, angry, worried, etc. The template expressions can be based on the person's mouth being upward, straight, downward, or wide; a person's eyes are wide, closed, narrowed; a person's eyebrows raised or angled; a person's frown is visible, etc. For example, in 3A the analyzer 204 determine that the woman does not want to be recognized because part of her hand overlaps her face and shows an expression of concern, as indicated by her mouth forming an O, her eyes wide, and her eyebrows raised. Conversely, if the hand was in the same position but the woman smiled, the analyzer can 204 determine that the woman feels comfortable with being recognized in the picture.
In einigen Ausführungsformen bewertet der Analysator das Erkennungsvermeidungssignal durch Bestimmen eines Vermeidungswerts, der dem Erkennungsvermeidungssignal entspricht. In einigen Ausführungsformen bestimmt der Analysator 204, falls der Vermeidungswert einen Schwellenwert erfüllt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern. Andere Schemas sind möglich, wie z. B. Bestimmen, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, falls der Vermeidungswert den Schwellenwert nicht erfüllt. Der Analysator 204 kann einen Vermeidungswert basierend auf einem prozentualen Anteil des Gesichts, der verdeckt ist, bestimmen. Beispielsweise kann der Analysator 204 bestimmen, dass dann, wenn mehr als 50 % des Gesichts verdeckt ist, die Person eine Maßnahme ergriffen hat, um die Erkennung der Person zu vermeiden. In einem weiteren Beispiel bestimmt der Analysator 204, dass, weil das Bild der Person enthält, dass das Gesicht verdeckt ist, und die Person in einer zusammengekauerten Position ist, der Vermeidungswert 90 auf einer Skala von 100 ist.In some embodiments, the analyzer evaluates the detection avoidance signal by determining an avoidance value that corresponds to the detection avoidance signal. In some embodiments, the analyzer determines 204 if the avoidance value meets a threshold value that a measure has been taken to prevent the person from being recognized. Other schemes are possible, such as: B. Determine that a measure has been taken to prevent recognition of the person if the avoidance value does not meet the threshold. The analyzer 204 can determine an avoidance value based on a percentage of the face that is hidden. For example, the analyzer 204 determine that if more than 50% of the face is covered, the person has taken action to avoid recognizing the person. In another example, the analyzer determines 204 that because the image of the person contains that the face is covered and the person is in a crouched position, the avoidance value 90 on a scale of 100.
Weiter zu 9B enthält ein Bild 325 eine Frau, die eine Angabe zeigt, dass sie in dem Bild nicht erkannt werden wollte. In diesem Beispiel ist ein größerer Abschnitt des Gesichts der Frau durch ihre Hand verdeckt, was ein stärkeres Anzeichen dafür ist, dass die Frau in dem Bild nicht erkannt werden wollte. In einigen Ausführungsformen kann der Analysator 204 eine Reihe von Bildern, die einem Ereignis zugeordnet sind, verarbeiten und das Erkennungsvermeidungssignal basierend auf der Reihe von Bildern erzeugen. Beispielsweise können 3A und 3B Teil desselben Ereignisses sein. Der Analysator 204 kann bestimmen, dass, weil beide Bilder der Frau enthalten, dass wenigstens ein Abschnitt ihres Gesichts mit ihrer Hand verdeckt ist, die Frau anzeigte, dass die Frau in dem Bild nicht erkannt werden wollte. Der Analysator 204 kann einen Vermeidungswert erzeugen, der auf der Reihe von Bildern basiert. Beispielsweise kann der Analysator 204 basierend auf den 3A und 3B bestimmen, dass die Frau nicht erkannt werden wollte, weil der Durchschnitt (oder Mittelwert) des Vermeidungswerts für die zwei Bilder einem Vermeidungswert entspricht, der den Schwellenwert erfüllt (oder übersteigt oder unter ihn fällt usw.). In einem weiteren Beispiel kann der Analysator 204 basierend auf 3A, 3B und einer Reihe von Bildern, in denen die Frau ihre Hand nicht vor ihrem Gesicht hat, bestimmen, dass die Frau nichts dagegen hat, erkannt zu werden.Further to 9B contains an image 325 a woman who shows an indication that she did not want to be recognized in the picture. In this example, a larger portion of the woman's face is covered by her hand, which is a stronger indication that the woman did not want to be recognized in the picture. In some embodiments, the analyzer 204 process a series of images associated with an event and generate the detection avoidance signal based on the series of images. For example 3A and 3B Be part of the same event. The analyzer 204 may determine that because both images of the woman include that at least a portion of her face is covered with her hand, the woman indicated that the woman did not want to be recognized in the picture. The analyzer 204 can generate an avoidance value based on the series of images. For example, the analyzer 204 based on the 3A and 3B determine that the woman did not want to be recognized because the average (or mean) of the avoidance value for the two images corresponds to an avoidance value that meets (or exceeds or falls below, etc.) the threshold. In another example, the analyzer 204 based on 3A . 3B and a series of images in which the woman does not have her hand in front of her face determine that the woman does not mind being recognized.
Weiter zu 3C enthält ein Bild 350 einen Mann, dessen Hand sein Gesicht beinahe vollständig verdeckt. Das ist ein Beispiel für eine Person, die nicht erkannt werden möchte. In einigen Ausführungsformen können keine weiteren Maßnahmen einem solchen direkten Anzeichen entgegenstehen, dass die Person nicht erkannt werden möchte. Für dieses Beispiel erzeugt der Analysator 204 ein Erkennungsvermeidungssignal, das angibt, dass die Person nicht erkannt werden möchte.Further to 3C contains an image 350 a man whose hand almost completely covers his face. This is an example of a person who does not want to be recognized. In some embodiments, no further measures can stand in the way of such a direct indication that the person does not want to be recognized. For this example, the analyzer creates 204 a detection avoidance signal indicating that the person does not want to be recognized.
Weiter zu 3D enthält ein Bild 375 eine Person mit einem Hut, der über das Obere des Gesichts der Person nach unten gezogen ist, und Händen vor dem unteren Teil des Gesichts der Person. Das ist ein weiteres Beispiel für eine Person, die nicht erkannt werden möchte. Für dieses Beispiel erzeugt der Analysator 204 ein Erkennungsvermeidungssignal, das angibt, dass die Person nicht erkannt werden möchte.Further to 3D contains an image 375 a person with a hat pulled down over the top of the person's face and hands in front of the lower part of the person's face. This is another example of a person who does not want to be recognized. For this example, the analyzer creates 204 a detection avoidance signal indicating that the person does not want to be recognized.
Der Analysator 204 kann bestimmen, dass das Erkennungsvermeidungssignal angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, wobei die Maßnahme enthält, dass wenigstens ein Teil des Gesichts der Person digital verdeckt ist. Digitales Verdecken des Gesichts kann Verwischen, Verpixeln oder Maskieren eines Gesichts enthalten. Ein Anwender kann ein Gesicht unter Verwendung von Bearbeitungs-Software, die Teil einer Kamera ist, oder Fotobearbeitungs-Software auf dem Telefon eines Anwenders digital verdecken. Ein Anwender kann auch eine Software Dritter verwenden, wie z. B. Software, die durch einen zweiten Server 120 bereitgestellt ist, um ein Gesicht digital zu verdecken.The analyzer 204 may determine that the detection avoidance signal indicates that a measure has been taken to prevent the person from being recognized, the measure including that at least a portion of the person's face is digitally obscured. Digitally hiding the face may include blurring, pixelating, or masking a face. A user can digitally mask a face using editing software that is part of a camera or photo editing software on a user's phone. A user can also use third party software such as B. Software running through a second server 120 is provided to digitally hide a face.
Weiter zu 4 ist ein Beispielbild 400 dargestellt, das eine digitale Veränderung von Menschen, um Erkennung zu verhindern, enthält. In diesem Beispiel sind die zwei Menschen rechts so dargestellt, dass sie verpixelte Gesichter aufweisen. Der Anwender kann Nachverarbeitung des Bilds ausgeführt haben, um diesen Gesichtern die Verpixelung hinzuzufügen. Der Analysator 204 kann basierend darauf, dass der Anwender die zwei Menschen rechts digital verdeckt, bestimmen, dass eine Maßnahme ergriffen wurde, um zu verhindern, dass die zwei Menschen rechts erkannt werden. Als ein Ergebnis kann der Analysator 204 ein Erkennungsvermeidungssignal für jeden dieser zwei Menschen erzeugen, um anzugeben, dass sie nicht identifiziert werden sollten. Wie nachstehend genauer diskutiert ist, kann das Erkennungsmodul 206 bestimmen, die Erkennung dieser beiden Menschen nicht auszuführen. Das Erkennungsmodul 206 kann jedoch bestimmen, die Erkennung der drei Menschen im linken Teil des Bilds 400 auszuführen, weil die Gesichter dieser drei Menschen nicht verdeckt sind. Further to 4 is a sample picture 400 that includes a digital change of people to prevent detection. In this example, the two people on the right are shown with pixelated faces. The user may have post-processed the image to add the pixelation to these faces. The analyzer 204 may determine that a measure has been taken to prevent the two people from being recognized on the right, based on the user digitally obscuring the two people on the right. As a result, the analyzer 204 generate a detection avoidance signal for each of these two people to indicate that they should not be identified. As discussed in more detail below, the detection module 206 determine not to carry out the detection of these two people. The detection module 206 however, can determine the detection of the three people in the left part of the image 400 because the faces of these three people are not covered.
In einigen Ausführungsformen bestimmt der Analysator 204 eine Identität sensibler Objekte innerhalb eines Bilds oder Videos und erzeugt das Erkennungsvermeidungssignal basierend auf der Identität der sensiblen Objekte. Die sensiblen Objekte können Drogenutensilien, illegale Objekte, Nacktheit usw. enthalten. Beispielsweise kann der Analysator 204 bestimmen, dass ein Bild einer Person mit einer Hand, die 10 % des Gesichts der Person verdeckt, in Kombination mit einem sensiblen Objekt im Hintergrund zur Erzeugung eines Erkennungsvermeidungssignals führt, das angibt, dass die Person nicht erkannt werden sollte.In some embodiments, the analyzer determines 204 an identity of sensitive objects within an image or video and generates the detection avoidance signal based on the identity of the sensitive objects. The sensitive objects can include drug paraphernalia, illegal objects, nudity, etc. For example, the analyzer 204 determine that an image of a person with a hand covering 10% of the person's face, in combination with a sensitive object in the background, will result in the generation of a detection avoidance signal indicating that the person should not be recognized.
In einigen Ausführungsformen identifiziert der Analysator 204 einen Typ der Maßnahme und bestimmt, ob das Erkennungsvermeidungssignal angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, basierend auf dem Typ der Maßnahme. Beispielsweise kann der Typ der Maßnahme enthalten, dass eine Person ihre Hand hebt, um das Gesicht der Person zu verdecken, oder um eine Krempe des Huts der Person zusammenzudrücken. Der Analysator 204 kann bestimmen, dass Heben der Hand angibt, dass die Person nicht erkannt werden möchte, und dass Zusammendrücken einer Krempe des Huts der Person angibt, dass das Bild oder das Video mit einer Gruppe von Anwendern in einem sozialen Netzwerk geteilt werden kann (z. B. Anwendern, mit denen diese Person in dem sozialen Netzwerk verbunden ist).In some embodiments, the analyzer identifies 204 a type of the measure and determines whether the detection avoidance signal indicates that the measure has been taken to prevent recognition of the person based on the type of the measure. For example, the type of measure may include that a person raises their hand to cover the person's face or to squeeze a brim of the person's hat. The analyzer 204 may determine that raising the hand indicates that the person does not want to be recognized and that squeezing a brim of the person's hat indicates that the image or video can be shared with a group of users on a social network (e.g. Users with whom this person is connected in the social network).
In einigen Ausführungsformen kann der Analysator 204 Maschinenlernen implementieren, das Klassifizierer zum Erzeugen eines Erkennungsvermeidungssignals erzeugen und/oder verbessern kann. In einigen Ausführungsformen kann Maschinenlernen in einer oder mehreren Komponenten der Erkennungsanwendung 103 implementiert sein, beispielsweise unter Verwendung trainierter Modelle. Trainierte Modelle können unter Verwendung synthetischer Daten trainiert werden, z. B. Daten, die durch einen Computer automatisch erzeugt werden, ohne Verwendung von Anwenderinformationen.In some embodiments, the analyzer 204 Implement machine learning that can generate and / or improve classifiers for generating a detection avoidance signal. In some embodiments, machine learning can be in one or more components of the recognition application 103 be implemented, for example using trained models. Trained models can be trained using synthetic data, e.g. B. Data that is automatically generated by a computer without using user information.
In einigen Ausführungsformen können trainierte Modelle z. B. basierend auf Trainingsdaten trainiert werden, für die Berechtigungen, Anwenderdaten zum Trainieren zu benutzten, ausdrücklich von Anwendern erhalten worden sind. Die Trainingsdaten können irgendwelche Daten enthalten, z. B. Videos und entsprechende Metadaten, die zur Verwendung zum Trainieren erlaubt sind, wie z. B. synthetische oder computererzeugte Daten, Daten, die zur Verwendung zum Trainieren lizenziert sind, usw. Die Trainingsdaten können Bilder und Videos enthalten, die eine Maßnahme enthalten, die identifiziert worden ist, dass sie ergriffen worden ist, um die Erkennung der Person zu verhindern. Die Bilder und Videos können aus Videos, die intern erzeugt werden, wie z. B. diejenigen, die in der Datenbank 199 des Erkennungsservers 101 gespeichert sind, oder aus Bildern und Videos, die von dem zweiten Server 120 empfangen werden, kommen. Beispielsweise kann der zweite Server 120 ein Mediaserver sein, der Bilder und Videos mit Metadaten versieht, die angeben, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern.In some embodiments, trained models may e.g. B. are trained based on training data for which authorizations to use user data for training have been expressly obtained from users. The training data can contain any data, e.g. B. Videos and corresponding metadata that are permitted for use for training, such as. B. Synthetic or computer generated data, data licensed for use in training, etc. The training data may include images and videos that contain a measure that has been identified to have been taken to prevent recognition of the person , The images and videos can be from videos that are generated internally, such as. B. those in the database 199 of the detection server 101 stored, or from pictures and videos by the second server 120 be received, come. For example, the second server 120 be a media server that provides images and videos with metadata indicating that action has been taken to prevent the person from being recognized.
In einigen Ausführungsformen kann ein trainiertes Modell basierend auf überwachtem Lernen erhalten werden, beispielsweise basierend auf Trainingsdaten, die Bilder und Videos und entsprechende Metadaten enthalten. Beispielsweise kann ein trainiertes Modell Modellform oder Struktur enthalten (die z. B. für eine Anzahl und Organisation von mehreren Knoten in Schichten eines neuronalen Netzes mit zugeordneten Gewichten erläuternd sind). In einigen Ausführungsformen kann ein trainiertes Modell so trainiert werden, dass der Analysator 204 das trainierte Modell anwendet, um ein Erkennungsvermeidungssignal zu erzeugen, das angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern. Auf diese Weise wird ein Signal aus dem Inhalt eines Bilds oder Videos extrahiert, das die Verarbeitung und die weitere Analyse des Bilds oder des Videos selbst, wie z. B. Erkennung der in dem Bild oder Video gezeigten Person, steuert. Das ist vorteilhaft, weil die Verarbeitung und weitere Analyse gesteuert wird, ohne zusätzliche Informationen zu erfordern, außer dem Video oder dem Bild selbst. Darüber hinaus können Personen, die in den Bildern von Videos gezeigt sind, zur Zeit, wenn das Bild oder Video aufgenommen wird, steuern, ob nachfolgende Verarbeitung und weitere Analyse des Bilds oder Videos erlaubt sein sollte, so dass beispielsweise die Erkennung der Person verhindert oder nicht ausgeführt wird, und somit die Vertraulichkeit und Privatsphäre der in dem Bild oder Video gezeigten Person steigern, selbst wenn das Bild oder Video in einem sozialen Netzwerk geteilt wird.In some embodiments, a trained model may be obtained based on supervised learning, for example based on training data that includes images and videos and corresponding metadata. For example, a trained model can contain model shape or structure (which are, for example, explanatory for a number and organization of several nodes in layers of a neural network with assigned weights). In some embodiments, a trained model can be trained so that the analyzer 204 uses the trained model to generate a detection avoidance signal indicating that action has been taken to prevent the person from being recognized. In this way, a signal is extracted from the content of an image or video, which processing and further analysis of the image or video itself, such as. B. Detection of the person shown in the picture or video controls. This is advantageous because processing and further analysis are controlled without requiring any additional information other than the video or the image itself. In addition, people who are shown in the images of videos can currently view the image or video will control whether subsequent processing and further analysis of the image or video should be permitted, so that, for example, the recognition of the person is prevented or not is carried out, and thus increase the confidentiality and privacy of the person shown in the picture or video, even if the picture or video is shared on a social network.
In einigen Ausführungsformen tragen Anwender durch Bereitstellen von Anwendereingabe dazu bei, die Trainingsdaten zu erzeugen. Anwender können gebeten werden, Bilder und Videos mit einer Maßnahme, die ergriffen wurde, um die Erkennung der Person zu verhindern, zu identifizieren. Als ein Ergebnis der Anwendereingabe können die Trainingsdaten genaue Identifizierung der Typen von Maßnahmen, die ergriffen werden, um die Erkennung der Person zu verhindern, besitzen.In some embodiments, users provide the training data by providing user input. Users can be asked to identify images and videos with a measure taken to prevent recognition of the person. As a result of user input, the training data may have accurate identification of the types of measures taken to prevent the person from being recognized.
Basierend auf den Trainingsdaten kann der Analysator 204 ein trainiertes Modell erzeugen, das basierend auf Bildern und Videos Erkennungsvermeidungssignale erzeugen kann, die angeben, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern. Das trainierte Modell kann ein temporäres Maßnahmenlokalisierungsmodell sein. In verschiedenen Ausführungsformen kann der Analysator Bayessche Klassifizierer, Stützvektormaschinen, neuronale Netze oder andere Lerntechniken verwenden, um das trainierte Modell zu erzeugen.Based on the training data, the analyzer can 204 generate a trained model that can generate recognition avoidance signals based on images and videos that indicate that action has been taken to prevent recognition of the person. The trained model can be a temporary measure localization model. In various embodiments, the analyzer can use Bayesian classifiers, support vector machines, neural networks, or other learning techniques to generate the trained model.
In einigen Ausführungsformen kann das trainierte Modell eine oder mehrere Modellformen oder Strukturen enthalten. Beispielsweise können Modellformen und Strukturen irgendeinen Typ eines neuronalen Netzes, z. B. ein lineares Netz, ein tiefes neuronales Netz, das mehrere Schichten implementiert (z. B. „verdecke Schichten“ zwischen einer Eingabeschicht und einer Ausgabeschicht, wobei jede Schicht ein lineares Netz ist), ein neuronales Faltungsnetz (z. B. ein Netz, das Eingabedaten in mehrere Teile oder Kacheln aufspaltet oder aufteilt, jede Kachel separat unter Verwendung einer oder mehrere Schichten des neuronalen Netzes verarbeitet, und die Ergebnisse aus der Verarbeitung jeder Kachel zusammenfasst), ein neuronales Sequenz-auf-Sequenz-Netz (z. B. ein Netz, das sequenzielle Daten wie z. B. Wörter in einem Satz, Rahmen in einem Video usw. aufnimmt und als Ausgabe eine Ergebnissequenz produziert), usw. enthalten. Die Modellform oder Struktur kann die Konnektivität zwischen verschiedenen Knoten und die Organisation von Knoten in Schichten spezifizieren. Beispielsweise können Knoten einer ersten Schicht (z. B. der Eingabeschicht) Daten als Eingabedaten oder Anwendungsdaten empfangen. Solche Daten können beispielsweise ein oder mehrere Pixel pro Knoten enthalten, z. B. wenn das trainierte Modell zur Bildanalyse verwendet wird. Nachfolgende Zwischenschichten können als Eingabe die Ausgabe von Knoten einer vorhergehenden Schicht je nach Konnektivität, die in der Modellform oder Struktur spezifiziert ist, empfangen. Diese Schichten können auch als verdeckte Schichten bezeichnet sein. Eine letzte Schicht (z. B. die Ausgabeschicht) produziert eine Ausgabe der Maschinenlernanwendung. Beispielsweise kann die Ausgabe eine Menge von Kennzeichen für ein Bild, eine Repräsentation des Bilds, die den Vergleich des Bilds mit anderen Bildern erlaubt (z. B. ein Merkmalsvektor für das Bild), ein Ausgabesatz in Reaktion auf einen Eingabesatz, eine oder mehrere Kategorien für die Eingabedaten usw. sein, abhängig von dem spezifischen trainierten Modell. In einigen Ausführungsformen spezifiziert die Modellform oder Struktur auch eine Anzahl und/oder einen Typ der Knoten in jeder Schicht.In some embodiments, the trained model may include one or more model shapes or structures. For example, model shapes and structures can be any type of neural network, e.g. For example, a linear network, a deep neural network that implements multiple layers (e.g., "hide layers" between an input layer and an output layer, with each layer being a linear network), a neural convolution network (e.g., a network that splits or splits input data into multiple pieces or tiles, processes each tile separately using one or more layers of the neural network, and summarizes the results from processing each tile), a neural sequence-on-sequence network (e.g. a network that includes sequential data such as words in a sentence, frames in a video, etc. and produces a sequence of results as output), etc. The model shape or structure can specify the connectivity between different nodes and the organization of nodes in layers. For example, nodes of a first layer (e.g. the input layer) can receive data as input data or application data. Such data may include, for example, one or more pixels per node, e.g. B. if the trained model is used for image analysis. Subsequent intermediate layers can receive as input the output of nodes from a previous layer depending on the connectivity specified in the model form or structure. These layers can also be referred to as hidden layers. A final layer (e.g. the output layer) produces an output of the machine learning application. For example, the output may include a set of tags for an image, a representation of the image that allows the image to be compared to other images (e.g., a feature vector for the image), an output set in response to an input set, one or more categories for the input data, etc., depending on the specific model being trained. In some embodiments, the model shape or structure also specifies a number and / or a type of nodes in each layer.
In unterschiedlichen Ausführungsformen kann ein trainiertes Modell mehrere Knoten enthalten, die in Schichten je nach Modellstruktur oder Form angeordnet sind. In einigen Ausführungsformen können die Knoten Berechnungsknoten ohne Speicher sein, die z. B. konfiguriert sind, eine Eingabeeinheit zu verarbeiten, um eine Ausgabeeinheit zu produzieren. Berechnung, die durch einen Knoten ausgeführt wird, kann beispielsweise Multiplizieren jede aus mehreren Knoteneingaben mit einem Gewicht, Erhalten einer gewichteten Summe und Anpassen der gewichteten Summe mit einem Bias- oder Intercept-Wert, um die Knotenausgabe zu produzieren, enthalten. In einigen Ausführungsformen kann die durch einen Knoten ausgeführte Berechnung außerdem das Anwenden einer Schritt-/Aktivierungsfunktion auf die angepasste gewichtete Summe enthalten. In einigen Ausführungsformen kann die Schritt-/Aktivierungsfunktion eine nichtlineare Funktion sein. In verschiedenen Ausführungsformen kann eine solche Berechnung Operationen wie z. B. eine Matrixmultiplikation enthalten. In einigen Ausführungsformen können Berechnungen durch die mehreren Knoten parallel ausgeführt werden, z. B. unter Verwendung mehrerer Prozessorkerne eines Mehrkernprozessors, Verwendung individueller Verarbeitungseinheiten einer allgemeinen Verarbeitungseinheit oder neuronaler Spezial-Schaltungsanordnung. In einigen Ausführungsformen können die Knoten einen Speicher enthalten, können z. B. fähig sein, eine oder mehrere frühere Eingaben zu speichern und in der Verarbeitung einer nachfolgenden Eingabe zu verwenden. Beispielsweise können Knoten mit Speicher Knoten mit langem Kurzzeitgedächtnis (LSTM-Knoten) enthalten. LSTM-Knoten können den Speicher verwenden, um einen „Zustand“ aufrechtzuerhalten, der es dem Knoten ermöglicht, wie ein endlicher Zustandsautomat (FSM) zu agieren. Modelle mit solchen Knoten können bei der Verarbeitung sequenzieller Daten nützlich sein, z. B. Wörtern in einem Satz oder Absatz, Rahmen in einem Video, Sprache oder anderes Audio usw.In different embodiments, a trained model can contain several nodes, which are arranged in layers depending on the model structure or shape. In some embodiments, the nodes may be compute nodes without memory, e.g. B. are configured to process an input device to produce an output device. Calculation performed by a node may include, for example, multiplying each of a plurality of node inputs by weight, obtaining a weighted sum, and adjusting the weighted sum by a bias or intercept to produce the node output. In some embodiments, the computation performed by a node may also include applying a step / activation function to the adjusted weighted sum. In some embodiments, the step / activate function may be a non-linear function. In various embodiments, such a calculation can perform operations such as e.g. B. contain a matrix multiplication. In some embodiments, calculations may be performed by the multiple nodes in parallel, e.g. B. using multiple processor cores of a multi-core processor, using individual processing units of a general processing unit or special neural circuitry. In some embodiments, the nodes may include memory, e.g. B. be able to save one or more previous entries and use them in processing a subsequent entry. For example, nodes with memory can contain nodes with long short-term memory (LSTM nodes). LSTM nodes can use the memory to maintain a "state" that enables the node to act like a finite state machine (FSM). Models with such nodes can be useful in processing sequential data, e.g. B. Words in a sentence or paragraph, frames in a video, speech or other audio, etc.
In einigen Ausführungsformen kann ein trainiertes Modell Einbettungen oder Gewichte für individuelle Knoten enthalten. Beispielsweise kann ein trainiertes Modell als mehrere Knoten initiiert werden, die in Schichten organisiert sind, wie durch die Modellform oder Struktur spezifiziert ist. Zur Initialisierung kann ein entsprechendes Gewicht auf eine Verbindung zwischen jedem Knotenpaar, das je nach Modellform verbunden ist, z. B. Knoten in aufeinanderfolgenden Schichten des neuronalen Netzes, angewandt werden. Beispielsweise können die entsprechenden Gewichte zufällig zugewiesen werden oder auf Standardwerte initialisiert werden. Das trainierte Modell kann dann trainiert werden, z. B. unter Verwendung von Daten, um ein Ergebnis zu produzieren.In some embodiments, a trained model can embed or weight for individual knots included. For example, a trained model can be initiated as multiple nodes organized in layers as specified by the model shape or structure. For initialization, a corresponding weight can be placed on a connection between each pair of nodes, which is connected depending on the model shape, e.g. B. nodes in successive layers of the neural network. For example, the corresponding weights can be assigned randomly or initialized to standard values. The trained model can then be trained, e.g. B. using data to produce a result.
Das Erkennungsmodul 206 führt die Erkennung der Person in dem Bild oder Video aus. In einigen Ausführungsformen enthält das Erkennungsmodul 206 eine Gruppe von Anweisungen, die durch den Prozessor 235 ausführbar sind, um die Erkennung auszuführen. In einigen Ausführungsformen ist das Erkennungsmodul 206 in dem Speicher 237 der Berechnungsvorrichtung 200 gespeichert und kann durch den Prozessor 235 zugänglich und ausführbar sein.The detection module 206 performs recognition of the person in the picture or video. In some embodiments, the detection module includes 206 a group of instructions by the processor 235 are executable to perform the detection. In some embodiments, the recognition module 206 in the store 237 the calculation device 200 stored and can by the processor 235 be accessible and executable.
In einigen Ausführungsformen führt das Erkennungsmodul 206 die Erkennung der Person in Reaktion darauf aus, dass das Erkennungsvermeidungssignal angibt, dass keine Maßnahme ergriffen worden ist, um die Erkennung der Person zu verhindern, und/oder das Erkennungsvermeidungssignal einem Vermeidungswert entspricht, der unter einen Schwellenwert fällt.In some embodiments, the detection module performs 206 recognizes the person in response to the detection avoidance signal indicating that no action has been taken to prevent the person's detection and / or the detection avoidance signal corresponds to an avoidance value that falls below a threshold.
In einigen Ausführungsformen führt das Erkennungsmodul 206 Erkennung der Person durch Extrahieren einer Erkennungsschablone aus. Falls es schwierig ist, die Person in dem Bild zu identifizieren, beispielsweise weil ein Teil des Gesichts der Person verdeckt ist, die Beleuchtung zur Erkennung zu gering ist, das Gesicht der Person im Profil ist usw., kann das Erkennungsmodul 206 andere Bilder von demselben Ereignis oder andere Bildrahmen in demselben Video verwenden, um die Erkennung der Person auszuführen. In einigen Ausführungsformen kann das Erkennungsmodul 206 eine Identität der Person basierend auf identifizierbaren Informationen wie z. B. Kleidungsmuster, Logos, persönlichen Gegenständen, einem markanten Haarschnitt, einem Schmuckgegenstand, einer Tätowierung, der Haltung usw. bestimmen. In einigen Ausführungsformen kann das Erkennungsmodul 206 ein Maschinenlernklassifizierungssystem verwenden, um die Person zu identifizieren. In einigen Ausführungsformen kann das Erkennungsmodul 206 Maschinenlernen verwenden, um die Person zu identifizieren. Der Prozess zum Verwenden von Maschinenlernen ist vorstehend mit Bezug auf das Erzeugen des Erkennungsvermeidungssignals beschrieben und wird hier mit Bezug auf das Identifizieren der Person nicht wiederholt. Das Erkennungsmodul 206 kann das Bild in Zuordnung zu der Identität der Person indexieren.In some embodiments, the detection module performs 206 Recognize the person by extracting a recognition template. If it is difficult to identify the person in the image, for example because part of the face of the person is obscured, the lighting for recognition is too low, the face of the person is in profile, etc., the recognition module can 206 Use different pictures from the same event or different picture frames in the same video to perform the person detection. In some embodiments, the detection module 206 an identity of the person based on identifiable information such as B. Determine clothing patterns, logos, personal items, a distinctive haircut, a jewelry item, a tattoo, posture, etc. In some embodiments, the detection module 206 use a machine learning classification system to identify the person. In some embodiments, the detection module 206 Use machine learning to identify the person. The process of using machine learning is described above with reference to generating the detection avoidance signal, and is not repeated here with reference to the identification of the person. The detection module 206 can index the image in relation to the person's identity.
Falls das Erkennungsvermeidungssignal angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, und/oder das Erkennungsvermeidungssignal einem Vermeidungswert entspricht, der einen Schwellenwert erfüllt, kann das Erkennungsmodul 206 bestimmen, die Person nicht zu erkennen. Falls andere Menschen in dem Bild vorhanden sind, kann das Erkennungsmodul 206 den Detektor 202 anweisen, eine weitere Person in dem Bild zu detektieren, bis alle Menschen in dem Bild verarbeitet worden sind.If the detection avoidance signal indicates that a measure has been taken to prevent the person from being recognized, and / or the detection avoidance signal corresponds to an avoidance value that meets a threshold value, the detection module can 206 determine not to recognize the person. If there are other people in the image, the recognition module can 206 the detector 202 instruct to detect another person in the image until all people in the image have been processed.
Das Bestimmen, eine Person in dem Bild oder Video nicht zu erkennen, kann mehrere Formen annehmen. Beispielsweise kann in einigen Ausführungsformen das Bestimmen, eine Person in dem Bild nicht zu erkennen, das Löschen des Bilds oder des Videos aus der Speichervorrichtung 247, Archivieren des Bilds oder Videos oder Verschieben nach unten des Bilds oder des Videos in Suchergebnissen enthalten. In anderen Ausführungsformen kann das Bestimmen, die Person nicht zu erkennen, das Indexieren des Bilds ohne eine Zuordnung zu einer Identität der Person enthalten.Determining not to recognize a person in the image or video can take several forms. For example, in some embodiments, determining not to recognize a person in the image may delete the image or video from the storage device 247 , Archive the image or video, or move down the image or video in search results. In other embodiments, determining not to recognize the person may include indexing the image without association with the person's identity.
In einigen Ausführungsformen kann eine Person Berechtigungen spezifizieren, die einem Bild zugeordnet ist, und das Erkennungsmodul 206 kann die Person basierend auf den Berechtigungen identifizieren. Beispielsweise kann ein Anwender die Berechtigungen erteilen, die erlauben, dass die Bilder des Anwenders für Menschen, die mit dem Anwender in einem sozialen Netzwerk zugeordnet sind (z. B. mit ihm verbunden, ihm folgen, Freunde usw.) identifiziert werden, jedoch nicht den Anwender in öffentlichen Bildern zu identifizieren. Als ein Ergebnis kann das Erkennungsmodul 206 bestimmen, dass das Erkennungsvermeidungssignal angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, und die Erkennung der Person ausführen. Das Erkennungsmodul 206 kann Berechtigungen bestimmen, die der Person zugeordnet sind, und die Person in dem Bild basierend auf der der Person zugeordneten Berechtigung identifizieren. Beispielsweise kann das Erkennungsmodul 206 basierend auf den Berechtigungen bestimmen, dass der Anwender in irgendwelchen Bildern nicht erkannt werden möchte. In einem weiteren Beispiel kann das Erkennungsmodul 206 basierend auf den Berechtigungen bestimmen, dass der Anwender in Bildern und Videos, die mit Freuden geteilt werden, identifiziert werden kann, jedoch nicht für die Öffentlichkeit, und als ein Ergebnis die Identifizierung bereitstellen, wenn die Bilder und Videos mit Freunden geteilt werden.In some embodiments, a person can specify permissions associated with an image and the recognition module 206 can identify the person based on the permissions. For example, a user can grant the permissions that allow the user's pictures to be identified for people associated with the user (e.g., connected to, following, friends, etc.) in a social network identify the user in public images. As a result, the recognition module 206 determine that the detection avoidance signal indicates that the measure has been taken to prevent the person from being recognized, and perform the detection of the person. The detection module 206 can determine entitlements associated with the person and identify the person in the image based on the entitlement associated with the person. For example, the recognition module 206 determine based on the permissions that the user does not want to be recognized in any images. In a further example, the recognition module 206 determine based on the permissions that the user can be identified in images and videos that are shared with pleasure, but not for the public, and as a result provide identification when the images and videos are shared with friends.
In einigen Ausführungsformen kann das Erkennungsmodul 206 das Anwenderschnittstellenmodul 208 anweisen, Grafikdaten zum Anzeigen einer Anwenderschnittstelle, die die identifizierte Person um eine Bestätigung bittet, dass die Person nicht identifiziert werden wollte, zu erzeugen. Beispielsweise kann das Erkennungsmodul 206 die Identifizierung einer Person ausführen, basierend auf ihren Berechtigungen bestimmen, dass das Bild gelöscht werden soll, und das Anwenderschnittstellenmodul 208 anweisen, um eine Bestätigung zu bitten, bevor das Bild gelöscht wird.In some embodiments, the detection module 206 the User interface module 208 instruct to generate graphic data for displaying a user interface that asks the identified person for confirmation that the person did not want to be identified. For example, the recognition module 206 perform identification of a person based on their permissions, determine that the image should be deleted, and the user interface module 208 to ask for confirmation before deleting the image.
Das Anwenderschnittstellenmodul 208 erzeugt Grafikdaten zum Anzeigen einer Anwenderschnittstelle. In einigen Ausführungsformen enthält das Erkennungsmodul 206 eine Gruppe von Anweisungen, die durch den Prozessor 235 ausführbar sind, um die Grafikdaten zu erzeugen. In einigen Ausführungsformen ist das Anwenderschnittstellenmodul 208 in dem Speicher 237 der Berechnungsvorrichtung 200 gespeichert und kann durch den Prozessor 235 zugänglich und ausführbar sein.The user interface module 208 generates graphic data for displaying a user interface. In some embodiments, the detection module includes 206 a group of instructions by the processor 235 are executable to generate the graphic data. In some embodiments, the user interface module 208 in the store 237 the calculation device 200 stored and can by the processor 235 be accessible and executable.
In einigen Ausführungsformen erzeugt das Anwenderschnittstellenmodul 208 Grafikdaten zum Anzeigen einer Anwenderschnittstelle für einen Anwender, um Berechtigungen zu erstellen. Die Berechtigungen beziehen sich darauf, wie ein Bild oder ein Video behandelt werden sollte. Beispielsweise kann der Anwender eine Präferenz bereitstellen, dass ein Bild oder Video, für das der Anwender angegeben hat, dass der Anwender in dem Bild oder Video nicht erkannt werden möchte, was dazu führt, dass die Identität des Anwenders dem Bild oder Video für Menschen, die mit dem Anwender in sozialen Netzwerken in Beziehung stehen, zugeordnet wird, jedoch nicht für eine Version des Bilds oder Videos, die mit Menschen geteilt werden, die nicht zu dem Anwender in dem sozialen Netzwerk in Beziehung stehen.In some embodiments, the user interface module generates 208 Graphic data for displaying a user interface for a user to create authorizations. Permissions relate to how an image or video should be treated. For example, the user may provide a preference that an image or video for which the user has indicated that the user does not want to be recognized in the image or video, resulting in the user's identity to the image or video for humans, associated with the user on social networks, but not for a version of the image or video that is shared with people who are unrelated to the user on the social network.
In einigen Ausführungsformen empfängt das Anwenderschnittstellenmodul 208 Anweisungen von dem Analysator 204 oder dem Erkennungsmodul 206, eine Anwenderschnittstelle zu erzeugen, die ein Bild oder ein Video enthält. Die Anwenderschnittstelle kann außerdem eine Anforderung für einen Anwender aufnehmen, eine Maßnahme zu bestätigen. Beispielsweise kann die Anwenderschnittstelle eine Anfrage an den Anwender zu bestätigen, dass der Anwender in dem Bild oder Video identifiziert oder nicht identifiziert werden wollte, dass der Anwender wollte, dass das Bild oder Video mit einer Gruppe von Menschen geteilt wird, dass der Anwender wollte, dass das Bild oder Video gelöscht, archiviert oder in Suchergebnissen nach unten geschoben wird, usw. enthalten.In some embodiments, the user interface module receives 208 Instructions from the analyzer 204 or the recognition module 206 to create a user interface that contains an image or video. The user interface can also accept a request for a user to confirm an action. For example, the user interface may ask the user to confirm that the user wanted to be identified or not identified in the image or video, that the user wanted the image or video to be shared with a group of people that the user wanted, that the image or video is deleted, archived, or pushed down in search results, etc.
Beispielverfahrenexample process
5 stellt einen Ablaufplan eines Beispielverfahrens 500 zum Bestimmen, ob eine Person Maßnahmen ergriffen hat, die Erkennung in einem Bild zu verhindern, gemäß einigen Ausführungsformen dar. Das Verfahren 500 wird durch eine Erkennungsanwendung 103, die auf einer Berechnungsvorrichtung 200, wie z. B. einem Anwendergerät 115, einem Erkennungsserver 101, oder teilweise einem Anwendergerät 115 und teilweise einem Erkennungsserver 101 gespeichert ist, ausgeführt. 5 provides a flow chart of a sample procedure 500 for determining whether a person has taken measures to prevent recognition in an image, according to some embodiments 500 is through a detection application 103 based on a computing device 200 , such as B. a user device 115 , a recognition server 101 , or partially a user device 115 and partly a recognition server 101 saved, executed.
In Block 502 wird eine Person in einem Bild oder einem Video durch Bestimmen eines Personenbildbereichs, der Grenzen der Person entspricht, oder eines Gesichtsbildbereichs, der einer Position eines Gesichts der Person entspricht, detektiert. In Block 504 werden Pixelwerte, die der Person oder der Position des Gesichts der Person entsprechen, basierend auf den Grenzen der Person oder dem Gesichtsbildbereich analysiert, um ein Erkennungsvermeidungssignal zu erzeugen.In block 502 a person is detected in an image or a video by determining a person image area that corresponds to boundaries of the person or a face image area that corresponds to a position of a face of the person. In block 504 pixel values corresponding to the person or the position of the face of the person are analyzed based on the boundaries of the person or the face image area to generate a detection avoidance signal.
In Block 506 wird bestimmt, ob das Erkennungsvermeidungssignal angibt, dass eine Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern. Falls das Erkennungsvermeidungssignal nicht angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, wird in Block 508 die Erkennung der Person ausgeführt. Falls das Erkennungsvermeidungssignal angibt, dass die Maßnahme ergriffen wurde, um die Erkennung der Person zu verhindern, wird in Block 510 bestimmt, ob das Erkennungsvermeidungssignal einem Vermeidungswert entspricht, der einen Schwellenwert erfüllt. Falls der Vermeidungswert den Schwellenwert nicht erfüllt, fährt das Verfahren 500 zu Block 508 fort, und die Erkennung der Person wird ausgeführt. Falls der Vermeidungswert den Schwellenwert erfüllt, fährt das Verfahren 500 zu Block 502 fort und detektiert eine weitere Person in dem Bild oder dem Video und wiederholt das Verfahren 500, bis alle Menschen in dem Bild oder Video analysiert worden sind.In block 506 it is determined whether the recognition avoidance signal indicates that a measure has been taken to prevent the recognition of the person. If the detection avoidance signal does not indicate that the measure has been taken to prevent the person from being recognized, block is passed to 508 recognized the person. If the detection avoidance signal indicates that the measure has been taken to prevent the person from being recognized, the block 510 determines whether the detection avoidance signal corresponds to an avoidance value that meets a threshold. If the avoidance value does not meet the threshold value, the method continues 500 to block 508 and the person is recognized. If the avoidance value meets the threshold, the method continues 500 to block 502 and detects another person in the image or video and repeats the process 500 until all people in the picture or video have been analyzed.
In der vorstehenden Beschreibung sind zahlreiche spezifische Einzelheiten zum Zweck der Erläuterung dargelegt, um ein umfassendes Verständnis der Spezifikation bereitzustellen. Es ist jedoch für einen Fachmann offensichtlich, dass die Offenbarung ohne diese spezifischen Einzelheiten praktiziert werden kann. In einigen Fällen sind Strukturen und Vorrichtungen in Blockdiagrammform gezeigt, um das Verdecken der Beschreibung zu vermeiden. Beispielsweise können die Ausführungsformen vorstehend primär mit Bezug auf Anwenderschnittstellen und spezielle Hardware beschrieben sein. Die Ausführungsformen können jedoch für jeden Typ einer Berechnungsvorrichtung, der Daten und Befehle empfangen kann, und irgendwelche peripheren Vorrichtungen, die Diente bereitstellen, gelten.In the foregoing description, numerous specific details are set forth for purposes of illustration to provide a thorough understanding of the specification. However, it will be apparent to those skilled in the art that the disclosure can be practiced without these specific details. In some cases, structures and devices are shown in block diagram form to avoid obscuring the description. For example, the embodiments may be described above primarily with respect to user interfaces and special hardware. However, the embodiments may apply to any type of computing device that can receive data and commands and any peripheral devices that serve.
Bezugnahme in der Spezifikation auf „einige Ausführungsformen“ oder „einige Fälle“ bedeutet, dass ein/e spezielle/s Merkmal, Struktur oder Eigenschaft, das/die in Verbindung mit den Ausführungsformen oder Fällen beschrieben ist, in wenigstens einer Implementierung der Beschreibung enthalten sein kann. Das Auftreten des Ausdrucks „in einigen Ausführungsformen“ an verschiedenen Orten in der Spezifikation bezieht sich nicht notwendigerweise immer auf dieselben Ausführungsformen. Reference in the specification to "some embodiments" or "some cases" means that a particular feature, structure, or characteristic described in connection with the embodiments or cases is included in at least one implementation of the description can. The appearance of the phrase "in some embodiments" at different locations in the specification does not always refer to the same embodiments.
Einige Abschnitte der vorstehenden ausführlichen Beschreibungen sind hinsichtlich Algorithmen und symbolischer Darstellungen von Operationen auf Datenbits innerhalb eines Computerspeichers präsentiert. Diese algorithmischen Beschreibungen und Darstellungen sind die Mittel, die durch Fachleute der Datenverarbeitungstechnik verwendet werden, um das Wesentliche ihrer Arbeit am effektivsten zu anderen Fachleuten zu transportieren. Ein Algorithmus ist hier, und allgemein, so betrachtet, dass er eine in sich konsistente Folge von Schritten ist, die zu einem gewünschten Ergebnis führt. Die Schritte sind diejenigen, die physikalische Manipulationen physikalischer Größen erfordern. Normalerweise, jedoch nicht notwendigerweise, nehmen diese Größen die Form elektrischer oder magnetischer Daten an, die gespeichert, übertragen, kombiniert, verglichen oder auf andere Weise manipuliert werden können. Es hat sich mit der Zeit als günstig gezeigt, besonders aus Gründen der gemeinsamen Verwendung, diese Daten als Bits, Werte, Elemente, Symbole, Schriftzeichen, Terme, Zahlen oder dergleichen zu bezeichnen.Some sections of the foregoing detailed descriptions are presented with respect to algorithms and symbolic representations of operations on data bits within computer memory. These algorithmic descriptions and representations are the means used by data processing professionals to most effectively convey the essence of their work to other professionals. An algorithm, here and more generally, is considered to be a consistent sequence of steps leading to a desired result. The steps are those that require physical manipulations of physical quantities. Usually, but not necessarily, these quantities take the form of electrical or magnetic data that can be stored, transmitted, combined, compared, or otherwise manipulated. Over time, it has proven to be beneficial, especially for reasons of common use, to refer to this data as bits, values, elements, symbols, characters, terms, numbers or the like.
Es sollte jedoch bedacht werden, dass alle diese und ähnliche Begriffe den geeigneten physikalischen Größen zuzuordnen sind und lediglich günstige Bezeichnungen sind, die auf diese Größen angewandt werden. Sofern es nicht spezifisch anderweitig festgestellt ist, wie es aus der folgenden Diskussion offensichtlich ist, ist zu verstehen, dass sich durchgehend durch die Beschreibung Diskussionen, die Begriffe benutzen, die „Verarbeiten“ oder „Berechnen“ oder „Ausrechnen“ oder „Bestimmen“ oder „Anzeigen“ oder dergleichen enthalten, auf die Aktion und die Prozesse eines Computersystems oder einer ähnlichen elektronischen Berechnungsvorrichtung beziehen, die Daten, die als physikalische (elektronische) Größen innerhalb der Register und Speicher des Computersystems repräsentiert sind, manipuliert und in andere Daten transformiert, die auf ähnliche Weise als physikalische Größen innerhalb der Speicher oder Register des Computersystems oder anderen solchen Datenspeichern, Übertragungs- oder Anzeigevorrichtungen repräsentiert sind.However, it should be borne in mind that all of these and similar terms are to be assigned to the appropriate physical quantities and are merely favorable terms that are applied to these quantities. Unless specifically stated otherwise, as is evident from the following discussion, it is to be understood that throughout the description, discussions that use the terms, the "process" or "calculate" or "calculate" or "determine" or "Displays" or the like include the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical (electronic) quantities within the registers and memories of the computer system and transforms it into other data are similarly represented as physical quantities within the memories or registers of the computer system or other such data stores, transmission or display devices.
Die Ausführungsformen der Spezifikation können sich auch auf einen Prozessor zum Ausführen eines oder mehrerer Schritte der vorstehend beschriebenen Verfahren beziehen. Der Prozessor kann ein Spezialprozessor sein, der durch ein in dem Computer gespeichertes Computerprogramm selektiv aktiviert oder neukonfiguriert wird. Ein solches Computerprogramm kann in einem nichttransitorischen computerlesbaren Speichermedium gespeichert sein, das, ohne darauf beschränkt zu sein, irgendeinen Typ einer Platte, die optische Platten, ROMs, CD-ROMs, magnetische Platten, RAMs, EPROMs, EEPROMs, magnetische oder optische Karten, Flash-Speicher, die USB-Schlüssel mit nichtflüchtigem Speicher enthalten, oder irgendeinen Typ von Medien, der zum Speichern elektronischer Anweisungen geeignet ist, von denen jedes mit einem Computersystembus gekoppelt ist, enthalten.The embodiments of the specification may also refer to a processor for performing one or more steps of the methods described above. The processor can be a special processor that is selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a non-transitory computer readable storage medium which, without being limited to, any type of disk, which includes optical disks, ROMs, CD-ROMs, magnetic disks, RAMs, EPROMs, EEPROMs, magnetic or optical cards, flash -Storage containing USB keys with non-volatile memory or any type of media suitable for storing electronic instructions, each of which is coupled to a computer system bus.
Die Spezifikation kann die Form einiger Ausführungsformen vollständig in Hardware, einiger Ausführungsformen vollständig in Software oder einiger Ausführungsformen, die sowohl Hardware- als auch Software-Elemente enthalten, annehmen. In einigen Ausführungsformen ist die Spezifikation in Software implementiert, die, ohne darauf beschränkt zu sein, Firmware, residente Software, Mikrocode usw. enthält.The specification may take the form of some embodiments entirely in hardware, some embodiments entirely in software, or some embodiments that contain both hardware and software elements. In some embodiments, the specification is implemented in software that includes, but is not limited to, firmware, resident software, microcode, etc.
Darüber hinaus kann die Beschreibung die Form eines Computerprogrammprodukts annehmen, das von einem durch einen Computer verwendbaren oder computerlesbaren Medium zugreifbar ist, das Programmcode zur Verwendung durch einen oder in Verbindung mit einem Computer oder irgendein Anweisungsausführungssystem bereitstellt. Für die Zwecke dieser Beschreibung kann ein durch einen Computer verwendbares oder computerlesbares Medium irgendeine Einrichtung sein, die das Programm zum Gebrauch durch ein/e oder in Verbindung mit einem/einer Anweisungsausführungssystem, Einrichtung oder Vorrichtung beinhalten, speichern, kommunizieren, verbreiten oder transportieren kann.In addition, the description may take the form of a computer program product that is accessible from a computer-usable or computer-readable medium that provides program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description, a computer-usable or computer-readable medium may be any device that can include, store, communicate, distribute, or transport the program for use by or in connection with an instruction execution system, device, or device.
Ein Datenverarbeitungssystem, das zum Speichern oder Ausführen von Programmcode geeignet ist, wird wenigstens einen Prozessor enthalten, der über einen Systembus direkt oder indirekt mit Speicherelementen gekoppelt ist. Die Speicherelemente können lokalen Speicher, der während der tatsächlichen Ausführung des Programmcode eingesetzt wird, Massenspeicher und Cache-Speicher, die temporäres Speichern wenigstens eines Teils des Programmcodes bereitstellen, um die Häufigkeit, mit der Code aus dem Massenspeicher während der Ausführung abgerufen werden muss, zu reduzieren.A data processing system which is suitable for storing or executing program code will contain at least one processor which is coupled directly or indirectly to memory elements via a system bus. The storage elements may include local memory that is used during the actual execution of the program code, mass storage, and cache memory that provide temporary storage of at least a portion of the program code in order to increase the frequency with which code must be retrieved from the mass memory during execution to reduce.
In Situationen, in denen die vorstehend diskutierten Systeme persönlichen Informationen sammeln oder verwenden, stellen die Systeme für die Anwender eine Gelegenheit bereit, zu steuern, ob Programme oder Merkmale Anwenderinformationen (z. B. Informationen über das soziale Netzwerk eines Anwenders, soziale Aktionen oder Aktivitäten, Beruf, Präferenzen des Anwenders oder ein aktueller Aufenthaltsort des Anwenders) sammeln, oder zu steuern, ob und/oder wie Inhalt von dem Server, der für den Anwender relevanter sein kann, empfangen wird. Zusätzlich können spezielle Daten auf eine oder mehrere Arten behandelt werden, bevor sie gespeichert oder verwendet werden, so dass persönlich identifizierbare Informationen entfernt werden. Beispielsweise kann die Identität eines Anwenders so behandelt werden, dass keine persönlich identifizierbaren Informationen für den Anwender bestimmt werden können, oder der geographische Aufenthaltsort eines Anwenders kann verallgemeinert werden, wo Ortsinformationen erhalten werden, (wie z. B. auf die Ebene einer Stadt, einer Postleitzahl oder eines Staates), so dass ein spezieller Aufenthaltsort eines Anwenders nicht bestimmt werden kann. Somit kann der Anwender die Kontrolle darüber haben, wie Informationen über den Anwender gesammelt und durch den Server verwendet werden.In situations where the systems discussed above collect or use personal information, the systems provide users with an opportunity to control whether programs or features are user information (e.g. B. Collect information about a user's social network, social actions or activities, profession, user's preferences, or a user's current location), or control whether and / or how content from the server that may be more relevant to the user , Will be received. In addition, special data can be treated in one or more ways before it is stored or used, so that personally identifiable information is removed. For example, the identity of a user can be treated such that no personally identifiable information can be determined for the user, or the geographic location of a user can be generalized where location information is obtained (such as at the city level, one Zip code or a state) so that a specific location of a user cannot be determined. Thus, the user can have control over how information about the user is collected and used by the server.
ZITATE ENTHALTEN IN DER BESCHREIBUNG QUOTES INCLUDE IN THE DESCRIPTION
Diese Liste der vom Anmelder aufgeführten Dokumente wurde automatisiert erzeugt und ist ausschließlich zur besseren Information des Lesers aufgenommen. Die Liste ist nicht Bestandteil der deutschen Patent- bzw. Gebrauchsmusteranmeldung. Das DPMA übernimmt keinerlei Haftung für etwaige Fehler oder Auslassungen.This list of documents listed by the applicant has been generated automatically and is only included for the better information of the reader. The list is not part of the German patent or utility model application. The DPMA assumes no liability for any errors or omissions.
Zitierte PatentliteraturPatent literature cited
-
US 15943961 [0001]US 15943961 [0001]