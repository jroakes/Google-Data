US6141011A - User interface methodology supporting light data entry for microprocessor device having limited user input - Google Patents
User interface methodology supporting light data entry for microprocessor device having limited user input Download PDFInfo
- Publication number
- US6141011A US6141011A US09/186,732 US18673298A US6141011A US 6141011 A US6141011 A US 6141011A US 18673298 A US18673298 A US 18673298A US 6141011 A US6141011 A US 6141011A
- Authority
- US
- United States
- Prior art keywords
- input
- user
- control
- key
- keys
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/02—Input arrangements using manually operated switches, e.g. using keyboards or dials
- G06F3/023—Arrangements for converting discrete items of information into a coded form, e.g. arrangements for interpreting keyboard generated codes as alphanumeric codes, operand codes or instruction codes
- G06F3/0233—Character input methods
- G06F3/0236—Character input methods using selection techniques to select from displayed items
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/02—Input arrangements using manually operated switches, e.g. using keyboards or dials
- G06F3/023—Arrangements for converting discrete items of information into a coded form, e.g. arrangements for interpreting keyboard generated codes as alphanumeric codes, operand codes or instruction codes
- G06F3/0233—Character input methods
- G06F3/0237—Character input methods using prediction or retrieval techniques
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M1/00—Substation equipment, e.g. for use by subscribers
- H04M1/26—Devices for calling a subscriber
- H04M1/27—Devices whereby a plurality of signals may be stored simultaneously
- H04M1/274—Devices whereby a plurality of signals may be stored simultaneously with provision for storing more than one subscriber number at a time, e.g. using toothed disc
- H04M1/2745—Devices whereby a plurality of signals may be stored simultaneously with provision for storing more than one subscriber number at a time, e.g. using toothed disc using static electronic memories, e.g. chips
- H04M1/2753—Devices whereby a plurality of signals may be stored simultaneously with provision for storing more than one subscriber number at a time, e.g. using toothed disc using static electronic memories, e.g. chips providing data content
- H04M1/2757—Devices whereby a plurality of signals may be stored simultaneously with provision for storing more than one subscriber number at a time, e.g. using toothed disc using static electronic memories, e.g. chips providing data content by data transmission, e.g. downloading
Definitions
- the present invention relates generally to the field of portable hand-held devices and, more particularly, to system and methodology for facilitating user input in such devices having limited input capability.
- Another problem facing small electronic devices is the difficulty of inputting information. With a small form factor or pocket-size device, it is simply not feasible to include a substantial keyboard for inputting information. Again, the size of the devices reduces the physical surface area available for accommodating input keys or the like.
- a conventional approach to the problem is to simply build a smaller keyboard, one using miniature input keys. The approach is problematic. In particular, most users find that their fingers are simply too big to use small keys with any degree of efficiency. Further, any efforts to increase the size of a keyboard or keypad in such a device reduces the amount of surface area available for the display screen.
- PalmPilot Another popular PC companion is PalmPilot, which is designed to be used like a small writing tablet (i.e., requiring two hands).
- the success of the PalmPilot has, to an extent, resulted from a simplified handwriting recognition system called "Graffiti," which allows users to enter one letter at a time, using a specialized alphabet.
- Graffiti requires the use of a separate stylus, which is used to enter a modified single-stroke alphabet and a few special "gestures" on a specially designated area of the PalmPilot, separate from its main screen.
- users must employ a stylus on a touch-sensitive screen to draw single-stroke characters one at a time.
- the Graffiti area of the screen is further divided into two regions--one for letters and the other for numbers. Input mistakes are corrected by using the Backspace gesture--a horizontal line drawn from right to left. Once drawn, the figures are interpreted by Graffiti and displayed in the currently selected text input area.
- the input for Graffiti is essentially simple text that is entered in a field, one character at a time, Graffiti is basically a pen-based replacement for an on-screen keyboard.
- What is needed is an improved input system and methodology for small devices, particularly credit card-sized devices having limited input capability.
- Such a system should facilitate user input by intelligently learning from and anticipating the user's actions.
- the system adapts to that user's personal styles and needs. In this manner, such a system may refine the user's choices, so that the process of entering and updating data becomes increasingly faster and easier, especially in devices where traditional input means (e.g., stylus) are awkward.
- the present invention fulfills this and other needs.
- a portable computing device or "information appliance” having terse user input is provided with a user interface for navigating user data.
- the computing device comprises a central processing unit (e.g., microprocessor) connected via a system bus to a display, an input, I/O (input/output) ports, and memory.
- a display is a screen device for displaying information, such as a liquid crystal display (LCD) screen.
- An input comprises a keypad, either physical or logical (e.g., on screen buttons), but limited to a terse set numbering about three to ten buttons and more preferably about five buttons.
- Memory comprises persistent memory, volatile memory, and non-volatile RAM memory.
- Persistent memory is typically implemented as a ROM or read-only memory. It stores a single-purpose operating system (SPOS) and application(s). Volatile memory is a "scratch" memory, for storing temporary computation results. It typically is implemented as a RAM (random-access memory), for providing a work space for the operating system and applications. Non-volatile RAM memory represents battery-backed RAM memory, for storing context information from one session to another. When the device is powered down, the memory stores user data from that session.
- SPOS single-purpose operating system
- Volatile memory is a "scratch” memory, for storing temporary computation results. It typically is implemented as a RAM (random-access memory), for providing a work space for the operating system and applications.
- RAM random-access memory
- Non-volatile RAM memory represents battery-backed RAM memory, for storing context information from one session to another. When the device is powered down, the memory stores user data from that session.
- SPOS single purpose operating system
- API application programming interface
- Applications are software application programs or modules provided for user operation of the device.
- the application programs can be implemented as separate modules, which are controlled by a module selector.
- the module selector serves as a user interface or shell representing the top-level or "home" display presented to a user.
- the module selector presents the user with selection icons for navigating to different applications or modules of functionality.
- other modules include a calendar module, a to do module, and an address book module.
- the device In typical use, the device is used in tandem with a desktop computer or PC.
- the desktop PC is used by the user when “at the office," and the portable computing device is employed when the user is "on the road” (i.e., out of the office).
- large repositories of data reside on the desktop PC which are periodically transferred or synchronized with data residing on the portable computing device.
- a device input/output (I/O) protocol or standard such as the PC card standard (formerly PCMCIA standard)
- the user can easily transfer data to the device via a direct memory transfer.
- data can be streamed from the desktop PC to the portable computing device via a direct cable (or infrared) connection, such as using a serial port-to-serial port connection.
- a direct cable (or infrared) connection such as using a serial port-to-serial port connection. Since the data transferred is that of an application operating on the desktop PC, potentially thousands of data items or records might be downloaded into the portable computing device. This potentially large dataset, coupled with the terse key set available at the portable computing device, poses a challenge to the location of desired information by a user. Therefore, improved user interface methodology is needed.
- the present invention provides a user interface implementing a "single-click" style of button operation, so that users can associate each button with a particular task for a given program context.
- the preferred embodiment imposes "click consistency" for each button.
- the same buttons are used over and over again to perform their respective tasks, even though the user has navigated to different modules of an application. In this manner, the user is presented with a consistent interface or metaphor which can be easily mastered.
- the user interface supports in a small form factor device the browser-style navigation that users have become accustomed to on desktop computers (e.g., using Web browsers). More particularly, the interface supports up, down, forward, and backward (reverse) navigation for allowing a user to "drill down” to "drill across” his or her data. This allows the user to find a data item (link) of interest and then drill down into it. Once at the appropriate level, the user can then easily select the particular item of interest. Further, once the user has selected or entered an item, the system provides the ability for the user to return to "home" with a single button click. In this manner, the present invention provides an interface allowing browser-style navigation in a device having a terse set of input keys.
- a method for providing users with access to applications and user information in a computing device having a limited set of input keys may be summarized by the following method steps.
- the device displays a user interface having a top-level view for allowing a user to select among applications available for the computing device.
- User interface navigation is provided in response to user operation of the limited set of input keys.
- the device moves a screen cursor in a forward relative direction among screen objects at a given level.
- the device moves the screen cursor in a reverse relative direction among screen objects at a given level.
- the device In response to user selection of a select key from said limited set of input keys, the device selects a particular screen object at which the screen cursor is currently located, whereupon the device displays a lower level view of the user interface which pertains to the particular screen object. In response to user selection of a home key from said limited set of input keys, the device returns to the top level view. In this manner, access to the applications and user information is achieved for the computing device through use of said limited set of input keys.
- a device having a terse set of input keys provides password protection as follows.
- the interface implements a "graphical password" which can be entered directly from the terse set of keys.
- the graphical password comprises a sequence of non-alphabetic key strokes from the terse set.
- an exemplary graphical password might comprise, for example, FORWARD, FORWARD, BACK, BACK, SELECT, or, alternatively, the user could select HOME, SELECT, FORWARD, HOME, HOME, BACK.
- a password entry screen When the device is configured for password protection, the screen appears each time the device is powered up. To gain access to information on the device, the user must at this point enter the same sequence of key strokes as that which comprises the user's graphical password.
- a password mask field indicates entries of each key stroke, but with the actual keys themselves being masked.
- a method for controlling access to a computing device having a limited set of input keys may, therefore, be summarized as follows.
- the device records a user-provided sequence of key strokes entered from the non-alphanumeric keys.
- the device stores the recorded sequence of key strokes as a "graphical password"--that is, a password comprising non-alphanumeric key strokes.
- the device Upon request from a user for access to the computing device, the device prompts the user to enter the graphical password. If the user enters a sequence of key strokes which matches that of the sequence of key strokes stored as the graphical password, the device grants device access to the user.
- Additional methodology is provided for dynamically adjusting tab categories and subcategories.
- the method is, in the preferred embodiment, driven in part by the number of lines supported by the display.
- the interface supports seven displayable lines which the user can navigate.
- the number of displayable lines is employed to set a threshold number of items which must exist before creating further tab categories (i.e., subcategories).
- the number is set equal to the number of displayable lines plus 1 (e.g., the number 8, for a display having 7 displayable lines). Any three-letter category which qualifies for subcategory tabs is determined by eight or greater items which satisfy that key.
- the method adopted always creates a boundary tab--that is, a category tab for the starting index after the subcategory set.
- the next tab category created is "Mo" (instead of the tab category "N"), even though the number of "Mo” entries might be less than the threshold value.
- the methodology ignores combinations which do not exist in the user data. If no "J” items exist, for example, then a "J” tab is not created.
- the system provides the user with a "find” operation based, not on a linear search, but on dynamically-created categories.
- a method for providing access to a data set which stores information in data records having data fields may, therefore, be summarized as follows.
- An initial order for displaying the data set based on values of a particular data field is established. Commonly, this will be an alphabetic sort order, such as a descending sort by Last Name.
- the data set is displayed according to this established order.
- category tabs for navigating among individual data records of the data set. This entails the following.
- the device determines dynamically, based on actual values stored at the particular data field of the data records, categories of information available for the particular data field. Based on this determination, the device displays a tab identifier allowing navigation to a particular category if at least one data item exists for the particular category. In this manner, at least some tab identifiers are eliminated from display--particularly, tab identifiers are eliminated for those categories of information which currently have no data items.
- the result is much faster and efficient navigation through large data sets when using a terse or limited key set.
- An alternative six-key embodiment providing system and methodology for user input affords highly-efficient, simple one-handed operation of the underlying device, thus making it well suited for use with credit card-sized devices--devices where simplicity and efficiency are critical factors.
- the approach provided foregoes any special input system, such as input gestures, and adjusts to a user's own working style. It includes adaptive techniques or built-in intelligence that allows the device to be faster and easier to use with each user session. In this manner, the target device may anticipate the tasks users need to perform in specific situations and thus make those tasks increasingly easier.
- the present invention facilitates data input for ultra-portable devices, including credit card-sized devices.
- the present invention provides a "super-key" light entry and editing input system for ultra-portable devices, such as a credit card-sized device.
- Underlying the super-key input is a heuristic sub-system that remembers and anticipates user input. By remembering what the user has previously inputted and by using context-sensitive menus and adaptive "quick" lists, the system can anticipate what the user needs to do at any given time and can guide the user through a step-by-step process to complete each task, thus facilitating the tasks that users most often perform.
- a credit card-sized device such as a REXTM device, is modified to include an additional input button, an EDIT key or button.
- the system provides an integrated set of tools that interface directly with the applications on the target device. In user operation, pressing the EDIT key brings up a context sensitive pop-up menu, thus invoking the super-key feature.
- the input system in conjunction with the EDIT key, functions intelligently to present the user with appropriate choices as he or she performs different tasks on the hand-held device.
- the super-key system guides the user through the process of entering appropriate information step by step.
- the system learns from the user's employment of the device, and increasingly adapts to and anticipates the user's actions. Since users tend to select titles for items such as tasks or meetings from a relatively small set of words and phrases, the super-key system may employ simplified key entry for completing input. From the user's perspective, the system's unique context sensitivity means the ability to get the job done faster, with far less effort, and with no need to worry about methodology or input systems.
- a method of the present invention for assisting a user with entering user input in a computing device having a limited set of input keys may be summarized as follows.
- the device is provided with a terse set of input keys comprising navigation keys, a select key, and an edit key.
- the device displays a user interface that requires input of information from the user.
- the device receives user input at the navigation keys for moving a screen cursor to different regions of the user interface. With the screen cursor positioned at a particular region of the user interface, the device receives user input at the edit key for invoking a context-sensitive input system.
- the device can determine a set of appropriate user input entries for the device for the particular region of the user interface where the screen cursor is currently positioned, and display at the particular region a control based on at least some of said set of appropriate user input entries.
- the device can receive user input at the navigation keys for positioning the screen cursor at a desired entry from said set of appropriate user input entries, and can receive user input at the select key for inputting the desired entry as user input for the device.
- a method of the present invention for assisting a user with completing input in a device may be summarized as follows.
- the device displays a user interface comprising a sequence of input controls that are arranged sequentially for receiving user input and marks all input controls as initially unfilled, for indicating that each of the controls has not yet received input from the user.
- the device can assist the user with completing input for the input controls, by performing substeps of: (1) receiving navigational input for moving a screen cursor among the sequence of input controls; (2) if the navigational input specifies forward movement, positioning the screen cursor at a next one of the sequence of input controls that is unfilled; (3) if the navigational input specifies backward movement, positioning the screen cursor at a previous one of the sequence of input controls that is unfilled; (4) receiving input from the user for the input control that the screen cursor is currently positioned at; (5) upon completion of input by the user at the control, marking the control as filled, for indicating that the control has received input; and (6) repeating substeps (1)-(5) until the user has completed all input desired.
- a microprocessor-based device with improved user input capability in accordance with the present invention may be summarized as follows.
- the device comprises a microprocessor, a memory, a display, and a set of input keys, said device requiring input of information by a user, said display for displaying input controls for receiving input in response to user activation of at least some of said input keys.
- the device is provided with initialization logic for initializing all input controls to an activated and an unfilled state.
- the device is also provided with control logic operating to: set focus of input to a first located input control that is activated and unfilled if one is located, and otherwise transfer control to navigation logic of the device.
- the device includes entry logic operating to process input by a user at an input control currently having focus and thereafter mark the input control as filled and transfer control to the control logic of the device, and otherwise transfer focus to a prior input control that is activated and unfilled.
- the device has navigation logic operating to (1) set, in response to a forward navigation request from the user, focus of input to a next located input control that is activated and unfilled if one exists, (2) set, in response to a backward navigation request from the user, focus of input to a prior input control that is activated and unfilled if one exists, and (3) transfer, in response to an edit request from the user, control to the entry logic of the device.
- FIG. 1 is a block diagram illustrating the general architecture of a portable computing device or "information appliance" in which the present invention may be embodied.
- FIG. 2 is a block diagram illustrating implementation of the application programs as modules under the control of a module selector.
- FIG. 3 is a bitmap screen shot illustrating a display interface comprising a plurality of application or module icons, from which the user can invoke particular application functionality.
- FIGS. 4A-G are bitmap screen shots illustrating use of a high-level navigation model of the present invention applied to a variety of types of user information.
- FIGS. 5A-C are bitmap screen shots illustrating use of the navigation model for setting user preferences.
- FIG. 5D is a flowchart summarizing internal methodology supporting the navigational model.
- FIG. 6A is a bitmap screen shot illustrating use of "graphical" passwords for controlling user access to the device.
- FIG. 6B is a flowchart summarizing internal methodology supporting device access with a graphical password.
- FIGS. 7A-D are bitmap screen shots illustrating use of a dynamically adjusting tab (category) interface for managing a large set of data.
- FIG. 7E is a flowchart summarizing internal methodology supporting dynamically adjusting tab categories.
- FIGS. 8A-F are bitmap screen shots illustrating the action of tabbing through dynamically-created subcategory tabs.
- FIGS. 9A-B are bitmap screen shots illustrating a special sort tab, whereupon the tab categories are automatically updated.
- FIG. 10 illustrates the inclusion of a sixth button, the EDIT button.
- FIG. 11 illustrates a bitmap screen shot that is invoked upon selection of the EDIT button.
- FIGS. 12A-C illustrate bitmap screen shots showing changes to the user interface, which includes a modified status bar.
- FIGS. 13A-K illustrate bitmap screen shots that demonstrate user input controls, including new user input controls employed by the six-key embodiment of the present invention.
- FIGS. 14A-G illustrate bitmap screen shots for exemplary input screens for the user task of scheduling an event.
- FIGS. 15A-C illustrate bitmap screen shots for exemplary input screens for the user task of scheduling a meeting.
- FIGS. 16A-B illustrate bitmap screen shots for the specific example of entering a birthday event.
- FIGS. 17A-C illustrate bitmap screen shots for the specific example of entering a wireless conference event.
- FIGS. 18A-D illustrate bitmap screen shots for the specific example of entering a meeting with a particular individual.
- FIGS. 19A-H illustrate bitmap screen shots for the specific example of entering a trip, which includes a specific departure time and arrival time, as well as a specific destination.
- FIGS. 20A-C illustrate bitmap screen shots for an entry having a recurrence pattern.
- FIGS. 21A-C illustrate bitmap screen shots for setting a reminder for an event, such as a reminder for a meeting.
- FIGS. 22A-J illustrate bitmap screen shots for making corrections using a "Smart Assistant" provided by the system of the present invention.
- FIGS. 23A-F illustrate bitmap screen shots showing how the Smart Assistant may adapt in response to user input.
- FIGS. 24A-G illustrate bitmap screen shots that demonstrate exemplary input screens for the task of adding a new contact.
- FIGS. 25A-E illustrate bitmap screen shots that demonstrate exemplary input screens for the task of creating a to do entry.
- FIG. 26 illustrates a bitmap screen shot of an alternative text input control that includes a special, functional character, "Erase”.
- FIG. 27A is a flowchart illustrating a "Smart Entry Assistant" control flow methodology of the present invention.
- FIG. 27B is a flowchart illustrating a "Control Mode" for the control flow methodology of the present invention.
- FIG. 27C is a flowchart illustrating an "Entry Mode" for the control flow methodology of the present invention.
- FIG. 27D is a flowchart illustrating a "Next/back Mode" for the control flow methodology of the present invention.
- FIG. 27E is a flowchart illustrating an "Edit Mode" for the control flow methodology of the present invention.
- FIG. 27F is a flowchart illustrating an Edit Input processing loop for the control flow methodology of the present invention.
- FIGS. 28A-B are bitmap screen shots illustrating a "Find in Contacts" feature of the present invention.
- FIG. 1 is a block diagram illustrating the general architecture of a portable computing device or "information appliance" in which the present invention may be embodied.
- computing device 100 comprises a central processing unit 105 (e.g., microprocessor) connected via a system bus 140 to a display 101, an input 102, ports 103, and memory 110.
- Display 101 is a screen device for displaying information, such as a liquid crystal display (LCD) screen.
- Input 102 comprises a keypad, either physical or logical (e.g., on screen buttons), but limited to a terse set numbering about three to ten buttons and more preferably about five buttons.
- Memory 110 comprises persistent memory 111, volatile memory 120, and non-volatile RAM memory 130.
- Persistent memory 111 is typically implemented as a ROM or read-only memory. As shown, it stores a single-purpose operating system (SPOS) 112 and application(s) 113, which are described in further detail below.
- Volatile memory 120 is a "scratch" memory, for storing temporary computation results. It typically is implemented as a RAM (random-access memory), for providing a work space for the operating system and applications.
- Non-volatile RAM memory 130 represents battery-backed RAM memory, for storing context information from one session to another. When the device 100 is powered down, the memory 130 stores user data from that session.
- the single purpose operating system functions to provide a consistent mechanism by which applications 113 can communicate with the device 100.
- applications 113 are shielded from hardware complexity, such as hardware interrupts and ports.
- hardware complexity such as hardware interrupts and ports.
- API application programming interface
- Applications 113 are software application programs or modules provided for user operation of the device. As shown in FIG. 2, for instance, the application programs can be implemented as modules 201-206, which are controlled by a module selector 200.
- the module selector 200 serves as a user interface or shell representing the top-level or "home" display presented to a user. In the currently-preferred embodiment, the module selector 200 presents the user with selection icons for navigating to different applications or modules of functionality.
- other modules include a calendar module, a to do module, and an address book module.
- the device 100 is used in tandem with a desktop computer or PC.
- the desktop PC is used by the user when “at the office," and the portable computing device 100 is employed when the user is "on the road” (i.e., out of the office).
- large repositories of data reside on the desktop PC which are periodically transferred or synchronized with data residing on the portable computing device 100.
- a device input/output (I/O) protocol or standard such as the PC card standard (formerly PCMCIA standard)
- the user can easily transfer data to the device 100 via a direct memory transfer.
- data can be streamed from the desktop PC to the portable computing device via a direct cable (or infrared) connection, such as using a serial port-to-serial port connection. Since the data transferred is that of an application operating on the desktop PC, potentially thousands of data items or records might be downloaded into the portable computing device 100. This potentially large dataset, coupled with the terse key set available at the portable computing device, poses a challenge to the location of desired information by a user. Therefore, improved user interface methodology is needed.
- the user interface of the present invention implements a "single-click" style of button operation. Given a device with five input buttons, for instance, various key combinations beyond the simple clicking of each individual button could be created. Buttons could, for example, be “double clicked” by users or combined to create double or triple (or even more) key combinations. Although such an approach yields more logical buttons from the available physical buttons, the approach requires users to memorize key combinations which are not intuitive (and are a source of endless grief for users of such devices). Accordingly, in the most-preferred embodiment, a single-click style is adopted, so that users can associate each button with a particular task for a given program context.
- buttons are used over and over again to perform their respective tasks, even though the user has navigated to different modules of an application. In this manner, the user is presented with a consistent interface or metaphor which can be easily mastered. If, on the other hand, behavior of the button changed from one portion or context of the application to another, the user must relearn the functionality of each button.
- the user interface supports in a small form factor device the browser-style navigation that users have become accustomed to on desktop computers (e.g., using Web browsers). More particularly, the interface supports up, down, forward, and backward navigation for allowing a user to "drill down” to "drill across” his or her data. This allows the user to find a data item (link) of interest and then drill down into it. Once at the appropriate level, the user can then easily select the particular item of interest. Further, once the user has selected or entered an item, the system provides the ability for the user to return to "home" with a single button click. As set forth below, the present invention provides an interface allowing browser-style navigation in a device having a terse set of input keys.
- the module selector presents an array of icons, each one corresponding to a particular application within the system. At all times, the system displays a highlight on screen for indicating "focus"--that a particular item is the focus of further user input (at that point in time). At the top level or "home,” focus is indicated by a highlight around one of the application icons.
- display interface 320 comprises a plurality of application or module icons (e.g., icons 321, 323), from which the user can invoke particular application functionality.
- icon 321 currently has "focus,” as indicated by focus outline (rectangle) 325.
- the device 300 includes five buttons 310. These buttons function as follows.
- Home key 311 provides a browser-like key allowing a user to always return to "home"--that is, a general or overview display screen.
- "home” is the module selector display or shell shown by display screen 320. In this manner, no matter how far a user has "drilled down" in the interface, the home key 311 will always return the user to the top-level view or shell, with a single button click.
- Forward key 319 and backward key 317 allow the user to navigate forward or backward (respectively), within a given level of the interface.
- the forward and backward keys move the selective or highlight from one icon to another, either in a forward or reverse direction depending on which of the two buttons 317, 319 is activated.
- a highlight or selector is presented at all levels of the interface, so that the functionality of buttons 317, 319 remains consistent and intuitive. As a result, the user always knows how to shift focus from one item to another regardless of what level of the interface the user has navigated to.
- select button 315 invokes (or "selects") the item currently having focus, when the button is activated by the user.
- select button 315 serves to select the calendar module represented by icon 321. In response to this selection, the system "drills down" into the calendar module.
- buttons provide a navigation model where the user can move from point to point for changing direction within a level, selection itself always indicates the current focus or point of activity (which will occur) within a given level. Selecting that item with the select button 315 causes the system to drill down into the functionality represented by the selected item. Regardless of how many levels the user has drilled down into using this technique, the home button 311 will always return the interface back to the top-level view (e.g., such as the "home" view represented by display 320).
- buttons 310 include a fifth key or button, view switch button 313.
- the view switch button 313 allows the user to instruct the system to switch to a different view within a given level, thus providing the user with a different way of viewing the data.
- presentation of calendar data by a calendar module can be represented or displayed in multiple ways.
- One way to represent such information for example, is to display a linear (event-by-event) list.
- such information could be presented on a week-by-week basis---that is, viewing data over a span of a given week.
- Yet another way to view such information is a monthly view which highlights dates for a given month which have events (or other user data).
- the view switch 313, therefore, cycles through different views at a particular level, with the actual views available being dictated by the particular application (module).
- the number of views available at a given level should typically not exceed about four views.
- the high-level navigation model can be applied to other types of user information. This is illustrated in FIGS. 4A-B.
- the calendar module has focus, as indicated at 401.
- the interface invokes the calendar module, as indicated at 410 in FIG. 4B.
- the view switch key By activating the view switch key, the user can switch the display to get another view of the data. For instance, upon the user first invoking the key, the display switches to a weekly view, as indicated at 420 in FIG. 4C. Further activation of the key switches the display to a monthly view, as shown at 430 in FIG. 4D.
- the user can select an item and drill down into it. For the present example, this is illustrated by FIGS.
- FIG. 4E the user selects an item, shown at 440, using forward/backward keys. Now that a particular item has focus, the user can drill down into that item, by activating the select key. The result is shown at 450 in FIG. 4F.
- the system displays the particular record corresponding to the selected item.
- the user can continue navigating using the selection and drill down approach.
- the user has selected item 460 from the displayed list of items.
- the user can invoke the select key for displaying further information about the selected item--detailed information for a particular time interval for this example (not shown).
- the foregoing example illustrates that the navigation module of the present invention can easily be applied to completely different data sets. At the same time, the user is still able to efficiently navigate among items in each data set even though the device itself only includes a terse set of input keys.
- the interface methodology also has application to a variety of other devices.
- PDA personal digital assistant
- the interface methodology also has application to a variety of other devices.
- enhanced processing power becomes available to more and more devices, including household appliances, there is a growing need for an interface for efficiently controlling such devices.
- those devices will continue to have a small set of input keys, instead of larger keypads or handwriting recognition.
- the physical size of the device makes it undesirable to incorporate a large keypad or a stylus for handwriting recognition.
- FIGS. 5A-C illustrate use of the navigation model for setting user preferences.
- the user begins by invoking the preference module from the module selector screen.
- the preference setting screen as illustrated in FIG. 5A, the user employs the forward and backward keys for navigating to a particular item, such as "date display.”
- the user invokes the select key to navigate to the item's value, such as the date display value 510 as shown in FIG. 5B.
- the user can change the value by using the backward and forward keys.
- the user can select that to be the preference value by invoking the select key.
- the selected value is now entered as the preferred setting.
- a method for providing users with access to applications and user information in a computing device having a limited set of input keys may be summarized as shown in FIG. 5D.
- the device displays a user interface having a top level view for allowing a user to select among applications available for the computing device (step 531).
- User interface navigation is provided in response to user operation of the limited set of input keys (step 532).
- the device moves a screen cursor in a forward relative direction among screen objects at a given level (step 533).
- the device moves the screen cursor in a reverse relative direction among screen objects at a given level (step 534).
- the device selects or invokes a particular screen object at which the screen cursor is currently located (step 535), whereupon the device displays a lower level view of the user interface which pertains to the particular screen object.
- the device returns to the top level view (step 536). The method or process loops (step 532) or continues for other user input. In this manner, access to the applications and user information is achieved for the computing device through use of said limited set of input keys.
- a device having a terse set of input keys implements password protection as follows.
- the interface implements a "graphical password" which can be entered directly from the terse set of keys.
- the graphical password comprises a sequence of non-alphabetic key strokes from the terse set.
- an exemplary graphical password might comprise, for example, FORWARD, FORWARD, BACK, BACK, SELECT, or, alternatively, the user could select HOME, SELECT, FORWARD, HOME, HOME, BACK.
- a password entry screen 600 upon the user entering a graphical password, the device displays a password entry screen 600, as shown in FIG. 6A.
- the screen appears each time the device is powered up.
- the user To gain access to information on the device, the user must at this point enter the same sequence of key strokes as that which comprises the user's graphical password.
- a password mask field 610 indicates entries of each key stroke, but with the actual keys themselves being masked.
- a method for controlling access to a computing device having a limited set of input keys may, therefore, be summarized as shown in FIG. 6B.
- the device records a user-provided sequence of key strokes entered from the non-alphanumeric keys (step 631).
- the device stores the recorded sequence of key strokes as a "graphical password" (step 632)--that is, a password comprising non-alphanumeric key strokes.
- the device Upon request from a user for access to the computing device (step 633), the device prompts the user to enter the graphical password (step 634). If the user enters a sequence of key strokes which matches that of the sequence of key strokes stored as the graphical password (step 635), the device grants device access to the user (step 636). Otherwise, the method repeats the prompt (step 634) or fails.
- a user desires to employ a portable computing device for storing and managing large lists of information, such as an electronic address book.
- information is sorted by a particular key (i.e., indexed by one or more fields).
- information can be indexed on the key of last name plus first name.
- information is potentially a very large list.
- a quick way to navigate to a desired entry in a large list is to perform a search. If one wanted to find an entry in an electronic address book beginning with the letter "S," for instance, the user could quickly search to names beginning with "S" if he or she could easily enter such a letter. For a portable computing device having a terse set of input keys, such as the device 100, the user does not have this option. Given a device with a terse set of input keys or buttons, therefore, a problem arises as to how one navigates such information efficiently.
- the difficulty with the approach is that the user must still navigate a potentially large list. If something more than simple input is required, such as the input of alphabetic characters, the fast repeat approach becomes unacceptable. For instance, when inputting characters from an entire alphabetic character set, including both upper case and lower case characters, the approach is simply not a practical way to input the information into a device. The fast repeat approach is not practical for navigating large data sets, such as an electronic address book containing hundreds of entries.
- list information is organized into discrete categories.
- information is grouped in a Rolodex.
- tabs are provided for individual letters of the alphabet. Adopting that approach electronically, however, is not an optimal approach, as the user would have to navigate or "tab through" a lot of information before reaching the desired target information.
- information is grouped intelligently at runtime (i.e., dynamically) such that a user can rapidly reach a destination or target item without having to tab through a lot of categories which are not of interest.
- the tabs themselves adjust dynamically at runtime to the user's actual data. Specifically, the tabs adjust on-the-fly to correspond to entries in the user's data. In this manner, the system eliminates the need for navigating or tabbing to categories which do not correspond to the actual user data present in the system.
- both a high level approach and a low level approach are adopted.
- the system employs the alphabet (and digits) broken down into sets of three characters, such as "#AB,” "CDE,” and the like. If no "E” entries are present in the user's data, for instance, the second tab can adjust to "CDF.”
- the approach provides an interface allowing the user to quickly navigate among categories. Unlike a Rolodex, however, the categories are simplified based on the user's actual data.
- FIGS. 7A-D illustrate an interface which embodies the approach.
- FIG. 7A illustrates address book interface 700 displaying list information 701.
- the interface 700 includes category tabs 710, such as "#AB" tab 711. Since the tab 711 currently has focus, it is highlighted (e.g., displayed in reverse video).
- the user activates forward (i.e., right or down) and backward (i.e., left or up) keys 715, 713.
- FIG. 7B the user activity of clicking the forward button or key 715 twice.
- the interface 700 shifts focus to tab 721, as shown.
- the displayed list 701 (now 701a) is updated, for displaying entries corresponding to the now-selected category (i.e., tab 721).
- the user can now invoke the select button, shown at 725 in FIG. 7B, for drilling down into the then currently-selected category.
- Interface 700 displays the tab 721 (now 721a) as the first category. Further, focus has shifted to a particular item on the list 701 (now 701b). Hence, once the user has quickly navigated to the desired category of information, the user can select into that category and proceed to quickly select a particular item from that category.
- the input events can be summarized as follows: across ⁇ select ⁇ down ⁇ select.
- the system displays the information record pertaining to that item.
- Final selection of item 722 for instance, invokes the display of information record 730, as illustrated in FIG. 7D. At any point during this process, the user can easily return to the top-level view by selecting the "home" key.
- a method for providing access to a data set which stores information in data records having data fields may be summarized as shown in FIG. 7E.
- An initial order for displaying the data set based on values of a particular data field is established (step 741). Commonly, this will be an alphabetic sort order, such as a descending sort by Last Name.
- the data set is displayed according to this established order (step 742).
- the device displays category tabs for navigating among individual data records of the data set. This entails the following.
- the device determines dynamically, based on actual values stored at the particular data field of the data records, categories of information available for the particular data field (step 743).
- the device Based on this determination (tested at step 744), the device displays a tab identifier allowing navigation to a particular category if at least one data item exists for the particular category (step 745). In this manner, at least some tab identifiers are eliminated from display--particularly, tab identifiers are eliminated for those categories of information which currently have no data items. The result is much faster and efficient navigation through large data sets when using a terse or limited key set.
- FIG. 8A illustrates this scenario.
- the user has tabbed to a category including "M" entries.
- the list 701 is updated and, for this example, includes a large number of "M” entries.
- the interface 700 updates, as indicated in FIG. 8B.
- the category tab has, in effect, "split" into subcategory tabs.
- "M” entries are now represented by three tabs 811: "M,” “Mc,” and “Mo” tabs.
- the system has synthesized dynamically an "Mc” tab, so those entries have their own subcategory tab. In this fashion, the user can quickly navigate to a particular subcategory of interest, thereby avoiding the need to linearly scan through a subcategory having a large number of entries which are not of interest (e.g., "Mc" entries).
- FIGS. 8C-E illustrate the action of the user tabbing through the subcategory tabs 811.
- the display list 701 (now 701d) updates to display items corresponding to the newly-selected subcategory tab.
- the user selecting subcategory tab 811b as shown in FIG. 8D or selecting subcategory tab 811c in FIG. 8E also leads to updating the display list 701, as shown at 701e and 701f, respectively.
- the user can select into or drill down to a particular item, such as indicated in FIG. 8F.
- the user can select the target item of interest using the select key or button.
- the system displays the corresponding information record (not shown) for that selected item.
- the methodology adopted for dynamically adjusting tab categories and subcategories is, in the preferred embodiment, driven in part by the number of lines supported by the display.
- the interface supports seven displayable lines which the user can navigate.
- the number of displayable lines is employed to set a threshold number of items which must exist before creating further tab categories (i.e., subcategories).
- the number is set equal to the number of displayable lines plus 1 (e.g., the number 8, for a display having 7 displayable lines).
- Any three-letter category which qualifies for subcategory tabs is determined by eight or greater items which satisfy that key.
- the method adopted always creates a boundary tab--that is, a category tab for the starting index after the subcategory set.
- the next tab category created is "Mo" (instead of the tab category "N"), even though the number of "Mo” entries might be less than the threshold value.
- the methodology ignores combinations which do not exist in the user data. If no "J” items exist, for example, then a "J” tab is not created.
- the system provides the user with a "find” operation based, not on a linear search, but on dynamically-created categories. The result is much faster and efficient navigation through large data sets when using a terse key set.
- the interface includes a special sort tab 901.
- the device displays selection screen 903.
- the user can select another index for presenting the data, such as index by "title” or by "company.”
- FIG. 9B at display screen 910, the user data is now sorted by company name. Accordingly, the tab categories are updated.
- REX a desktop or laptop PC to enter and edit the bulk of their information.
- REX Classic the first generation REX device, gave users the ability to carry critical contact, scheduling and task management information in their shirt pockets or wallets, information that was originally entered in a desktop application such as Starfish Sidekick® or Microsoft® Outlook.
- REX downloads this information from the users' PCs, and keeps it synchronized, by using Starfish TrueSync technology.
- PC companion devices for their portability and convenience. They do not need--and would not want--a credit-card-sized device to include a full-blown text processing system, say for composing lengthy documents or designing a spreadsheet.
- users do not expect a PC companion to perform like a full-blown desktop or laptop computer, users do want the ability to perform light editing and input tasks on the PC companion, and then later re-synchronize with their desktop, laptop or hand-held computer.
- Such light-duty input tasks include, for example, rescheduling an event, entering a phone number, or creating a new to do item. All told, users want a simple, light data entry mechanism that solves their input needs without sacrificing the size and efficiency advantages of the device.
- An improved input system and methodology constructed in accordance with the present invention should provide highly-efficient, simple one-handed operation of the underlying device, thus making it well suited for use with credit card-sized devices--devices where simplicity and efficiency are critical factors.
- User should not have to fumble with a stylus or have to use both hands to input data.
- the approach should be designed so as to not require a touch screen, thereby allowing the highest possible screen resolution while minimizing hardware requirements.
- the approach provided should not only forego any special input system, such as input gestures, but should in fact adjust to a user's own working style.
- the approach employed should include adaptive techniques or built-in intelligence that allows the device to be faster and easier to use with each user session.
- the device may anticipate the tasks users need to perform in specific situations and thus make those tasks increasingly easier.
- the present invention facilitates data input for ultra-portable devices, including credit card-sized devices.
- the present invention provides a "super-key" light entry and editing input system for ultra-portable devices. Underlying the super-key input is a heuristic sub-system that remembers and anticipates user input. By remembering what the user has previously inputted and by using context-sensitive menus and adaptive "quick" lists, the system can anticipate what the user needs to do at any given time and can guide the user through a step-by-step process to complete each task, thus facilitating the tasks that users most often perform.
- the REX device is modified to include an additional input button--the EDIT key--as illustrated in FIG. 10.
- the system provides an integrated set of tools that interface directly with the applications on the target device. In user operation, pressing the EDIT key brings up a context sensitive pop-up menu, thus invoking the super-key feature.
- the EDIT key functions intelligently to present the users with appropriate choices as he or she performs different tasks on the hand-held device.
- the super-key system guides the user through the process of entering appropriate information step by step.
- the system learns from the user's employment of the device, and increasingly adapts to and anticipates the user's actions. Since users tend to select titles for items such as tasks or meetings from a relatively small set of words and phrases, the super-key system may employ a simple two-key entry system for completing input (e.g., one key to navigate to a choice, and another to select the choice). From the user's perspective, the system's unique context sensitivity means the ability to get the job done faster, with far less effort, and with no need to worry about methodology or input systems.
- the alternative six-key embodiment includes HOME, VIEW, SELECT, BACK and NEXT buttons together with the new EDIT key or button.
- the HOME key or button is used to return to the upper most level of the navigation scheme, the module selector screen. Return to home is done in a step-wise fashion, with each click of HOME moving back a logical step toward the module selector screen. Functionality of the button is, however, modified in this embodiment for use within input controls. Specifically, the HOME key operates as a step-wise undo within a control. For date-time controls, for example, HOME will back through each element of the control. For text input controls, HOME will undo the last typed letter. Holding the HOME key down will return control all the way back to the module selector screen, skipping any intermediate steps. Holding HOME down at the module selector will force the device to shut off. Holding HOME down while in a Smart Entry Assistant (described below) pops up a menu with the option to cancel or continue; choosing to cancel will return focus to the module selector screen and cancel the Smart Entry Assistant.
- a Smart Entry Assistant described below
- the VIEW button switches views where available.
- the VIEW button switches between daily, weekly and monthly views.
- the view switches between contact categories and among address, number and note views.
- the alternative embodiment adds a VIEW menu. Rather than cycle through views immediately, the VIEW key pops up a menu of view choices. Clicking VIEW a second time dismisses the VIEW menu.
- the VIEW button is used in the text input control to switch between letter text input and number/symbol text input.
- the VIEW button does not have a function in every situation. When the VIEW button is operating, therefore, the symbol for the button appears in the status bar.
- the EDIT button operates on the current context and allows the user to add new data or modify existing data.
- users can start various Smart Entry Assistants to create new schedule, contact, and to do list items. Users can also operate on existing schedule, contact, and to do list items, with the option to change or remove an existing item.
- the EDIT button pops up an edit menu which offers the relevant choices available for the context in which it was pressed. The EDIT button does not have a function in every situation. When the EDIT button is available, the symbol for the button appears in the status bar.
- BACK and NEXT arrow buttons operate as before. BACK and NEXT arrow buttons either move the highlight to the next logical position (vertically or horizontally depending on context) or increment/decrement the currently highlighted value, depending on context, and SELECT acts on the currently selected item.
- the status bar icons are slightly changed in the six-button embodiment.
- the scroll arrow indicators are as before but with the addition of horizontal direction as well as vertical direction options.
- the VIEW and EDIT key icons appear left of the vertical scroll arrows.
- the battery warning is removed from the status bar altogether. Instead, battery low alerts will pop up when the unit is first powered on. This alert, which is similar to the unit's memory low alert, must be dismissed before proceeding.
- the status bar provides mode cycling--that is, switching content on the status bar every few seconds, thus allowing more information to be packed into the same space.
- the time of day cycles between the time of day and the name of the time zone city every few seconds when the current zone is not the home zone.
- the status bar provides help "hints" during operation of Smart Entry Assistants.
- hint mode the status bar icons and time are replaced by a simple legend of key icons and functions. The only standard icons available during hint mode are the scroll indicators.
- the six-button embodiment supports standard (i.e., system-provided) controls that are furnished in the five-key embodiment. These controls remain fundamentally unchanged (except for the occasional use of HOME as an undo operation, as previously described).
- the six-button embodiment introduces three new controls: a menu control, a text input control, and a "Smart (Entry) Assistant" control. These old and new controls are further described below.
- the item list control allows the user to select from a list of items.
- the list control can render content as text and include optional graphical icons. Scroll indicators can exist inside the list control or on the status bar in the right hand corner.
- Keys that are functional for an item list control include the BACK, NEXT and SELECT keys. HOME will undo the selection, where applicable, or back out of the current control, where applicable.
- the chooser control illustrated in FIG. 13B, is a compressed one-line item list control.
- the chooser control has spin indicators to the right hand side. Keys that are functional for a chooser control include BACK, NEXT and SELECT keys. HOME will undo the selection, where applicable, or back out of the current control, where applicable.
- the menu control illustrated in FIG. 13C, is a frame extension to the item list control.
- the menu control contains a caption bar with an optional icon.
- the menu control is designed to pop up over the screen and to restore the contents beneath after it has been dismissed. As a visual aid, the menu control dithers the backdrop screen while it is operational. Keys that are functional for this control include the BACK, NEXT and SELECT keys.
- the HOME key as well as the key which activated the menu will both dismiss the menu once it is up.
- the tabbed list control illustrated in FIG. 13D, combines a horizontal item list control rendered as tabs with a vertical list control.
- the tabbed list control allows the user to isolate a position within a very large list using the tabs and then to choose a particular item within the list using the vertical item list.
- the VIEW key can optionally switch lists if there are more than one. This control operates in the exact same manner as the contacts module in the five-key embodiment. Scroll arrows are optionally available in the list or at the right hand corner of the status bar. Keys that are functional in the control include the BACK, NEXT, SELECT and HOME keys. VIEW is available if there are multiple lists to choose from.
- the password control illustrated in FIG. 13E, is similar to that in the five-key embodiment except that it allows for the use of the sixth EDIT button. This control allows the user to enter a graphical password using any of the keys available on the device. All buttons function with this control.
- the date-time control illustrated in FIG. 13F, in its three versions, is similar to that used by the five-key embodiment, except that the HOME key is used to back through elements.
- the system displays a highlight over the data element (hour, minutes, etc.) currently being set.
- BACK and NEXT decrement or increment the shown value, respectively.
- SELECT chooses the shown value and moves the highlight to the next data element to be set, or, if there is no such next data element, completes the entire time/date entry.
- HOME Prior to completing the time/date entry, HOME returns the highlight to a previous data element within the time-date control. If there is no previous data element (i.e., the current data element being set is the first one), then HOME backs out of the date-time control.
- the EDIT key is generally not active in this control.
- the EDIT key may be used to complete the entire time/date entry, without requiring the user to select through all data elements (in sequence).
- the date-time control can optionally display both date and time or either date or time elements individually. Keys that are functional in the control include BACK, NEXT, SELECT and HOME keys.
- the text input control illustrated in FIG. 13G, is new to the six-key embodiment. This control allows the entry of simple free-form text.
- the control uses a letter strip with an active highlight to enter text.
- the user clicks BACK and NEXT to move to the desired letter (the strip may scroll), and presses SELECT to enter it.
- HOME acts as a backspace or undo button, reversing the operation of SELECT.
- FIG. 13H illustrates the control when used for numeric input.
- the numbers include digits and special characters: 0 1 2 3 4 5 6 7 8 9 (-) @./ -- #*! ⁇ (space).
- the number strip also wraps around in both directions.
- the status bar is in hint mode with a legend for the key operations while a text input control is active.
- the BACK, NEXT and SELECT keys are used to pick letters.
- the HOME key is used to undo letters.
- the VIEW key is used to toggle between letter and number strips and the EDIT key is used to complete the entry.
- FIG. 13I A simple pop-up control, illustrated in FIG. 13I, is provided for this purpose. As shown, the control includes a selectable associated icon (e.g., "i" icon for "information").
- This Message Box which includes a drop-shadow outline, automatically resizes vertically to accommodate the message text, and centers horizontally and vertically over a dithered background.
- the Smart Entry Assistant control (or simply, "Smart Entry Assistant"), shown in FIG. 13J, is a form-based control which houses text fields and instructions, as well as the other types of controls.
- the Smart Entry Assistant is broken down into four major areas. The first is the form title area 1381 which includes the form number and a title bar. The second is the instruction area 1383 which houses a simple text statement describing the use of the form. The third is a field title area 1385 which contains right-justified field titles for the various data fields of the form. The fourth area is the data entry area 1387 in which already-entered values for the data fields are displayed and in which the various controls for accepting or editing values for the fields operate.
- the status bar shown at 1389, operates in hint mode.
- the status bar indicates that "undo" is accomplished by the HOME key, for instance.
- Other exemplary hint icons are shown in the leftmost two columns of FIG. 13K.
- the rightmost two columns of FIG. 13K show exemplary icons that may appear for example as field values or field value choices.
- a Smart Entry Assistant is dedicated to a particular task and includes a sequence of one or more "smart" forms. Each of these forms is capable of accepting input or edit of one or more data fields. Each form may itself be considered a separate Smart Entry Assistant.
- the Smart Entry Assistant is capable of dynamically determining its sequence of forms, and within each form, the sequence of data fields for which input or edit is solicited, and for each field, the initial value, if any, to be presented to the user for edit. This dynamic determination is based on context, including the particular choices and values that the user has already entered, as will be further described.
- new data is entered by the user at the user interface by stepping through a series of fields and controls grouped into a sequence of "smart" forms.
- Creating new data is preferably done using the EDIT key.
- the EDIT key operates both from within the home screen and within each module.
- the EDIT key invokes a list of edit options that relate to the context in which it was called. From within daily view of the calendar, for instance, the edit options include new, change and delete event.
- the EDIT key invokes only a single option, new event, but if a particular event is currently highlighted in the daily view, the EDIT key invokes the options "Follow UP", "Reschedule”, or "Cancel Event”. From within the home screen, the edit options include new event, new contact, new to do and new QuickMemo. Specific examples will now be presented.
- the first step in scheduling an event is to choose the subject of the event from a list, here list 1401.
- This list contains a small set of common defaults as well as any new subjects which the user has created over time. If the list of choices does not contain the appropriate subject, the user can select "New Subject" 1403 and create a custom one. If the user selects a subject from the list, the NEXT indicator 1405, shown in FIG. 14B, appears at the bottom of the screen, confirming the user's choice and allowing the user to move on to the next step.
- the Smart Assistant adapts and allows the user to create a custom subject.
- the process is illustrated in FIG. 14C.
- the first step in creating a custom subject is to choose an event type from a list 1407 of generic event types (e.g., six types).
- generic event types e.g., six types.
- the system provides types covering a broad range of business and personal scheduling needs; examples include:
- Meeting time of day event, optional participant, optionally recurring, optional alarm (e.g., meeting with person, weekly staff meeting, and the like)
- Event time of day event, optionally recurring, optional alarm (e.g., doctor's appointment)
- All-Day Event one day event, optionally recurring (e.g., company outing or casual day)
- Multi-Day Event event over multiple days (e.g., conference, vacation)
- Travel time of day event, time zones, alarm, and the like (e.g., flight)
- the next step is to enter the subject text using the text input control, as shown at 1409 in FIG. 14D.
- the NEXT indicator 1411 appears, as shown in FIG. 14E, allowing the user to confirm the newly entered subject and move on to the next step.
- This newly entered subject will appear in the subject list along with its type icon the next time the user schedules an event. Clicking the SELECT button moves the user on to the next Smart Assistant form.
- the next step is to select an optional participant.
- Event types such as holidays, can be defined to not support participants.
- at least one participant is supported.
- participants can be people or companies.
- the first step in choosing a participant is to choose whether the participant is a person or a company and whether the participant exists in the contacts list or must be entered in. The option to have "no participants" is always available as well. If the user chooses "no participant", as shown at 1413 in FIG. 14F, the familiar NEXT indicator appears, as shown at 1415 in FIG. 14G, and the user can click the SELECT button to move on to the next step.
- the Smart Assistant adapts in a similar manner to the case of a new person, as shown in FIG. 15A.
- the form allows the user to enter the name of the company. Once the user has completed the name, the user can choose whether and where to file the new company name in the contact database, as shown in FIG. 15B.
- the NEXT indicator appears, as shown in FIG. 15C. The user can click SELECT to move on to the next step.
- the Smart Assistant uses a series of time and date choosers to enter the date and time.
- the "Time" Smart Assistant takes on four different forms depending on the type of event. For all-day events and annual events, the Smart Assistant will take on a date form. For multi-day events, the Smart Assistant will take on a date-span form. For meetings and events, the Smart Assistant will take on a time-span form. For travel events, the Smart Assistant will take on a zone-span form.
- the date form is used for all-day events and annual events. As illustrated in FIG. 16A, this form has only one item, the date on which the event happens. Once the date has been entered, the NEXT indicator appears, allowing the user to confirm the entry and move on to the next step, as shown in FIG. 16B. The user can move on to the next step using the SELECT key.
- the date-span form is used for multi-day events. This form is similar to the date form with the addition of an end date element.
- the first step is to enter the event starting date, as illustrated in FIG. 17A.
- the next step is to enter the ending day for the event, as shown in FIG. 17B.
- the NEXT indicator appears, as shown in FIG. 17C, allowing the user to confirm the date range and continue on to the next step. The user can move on to the next step using the SELECT key.
- the time-span form shown in FIG. 18A, is used for meetings and events.
- the time-span form is similar to the date-span form except that it uses starting and ending times in addition to a starting date.
- the first step is to enter the starting date, as illustrated in FIG. 18A. Once the starting date is entered, the user enters the starting time, as shown in FIG. 18B. Once the starting time is entered, the user enters the ending time, as shown in FIG. 18C. Once the ending time is entered, the familiar NEXT indicator appears, allowing the user to review the choices and move on to the next step, as shown in FIG. 18D. The user can move on to the next step using the SELECT key.
- the zone-span form is a special form used for travel events. This form allows the user to specify a departure time and an arrival time as it would be printed on a travel ticket. This form will compute any time-zone translations if the event crosses time zones.
- the first step is to enter the departure date, as shown in FIG. 19A.
- the next step is to enter the departure time, as shown in FIG. 19B.
- the third step is to select the departure city from the list of available cities as shown in FIG. 19C. This is the same list which is used by the EarthTime clock module (which is described in further detail in commonly-owned U.S. application Ser. No. 08/609,983, filed Feb. 29, 1996, the disclosure of which is hereby incorporated by reference).
- the NEXT indicator appears, as shown in FIG. 19D, confirming the user's selection and allowing the user to move on to selecting the arrival time.
- the arrival time sequence is identical to the departure time sequence.
- the first step is to enter the arrival date, as shown in FIG. 19E.
- the next step is to enter the arrival time, as shown in FIG. 19F.
- the final step is to enter the arrival city, as shown in FIG. 19G. If this city is in a different time zone from the departure city, the system will automatically compute time zone adjustments when storing the event.
- the usual NEXT indicator appears, confirming the arrival time and allowing the user to move on to the next step, as shown in FIG. 19H. The user can move on to the next step using the SELECT key.
- the next step for those event types which support recurring behavior, such as meetings, is to enter the recurrence pattern.
- the first choice is always "none" if the user does not require recurring behavior.
- the other choices are weekly, biweekly, monthly on a day, monthly on a date and yearly.
- the actual text for the choices is based on the starting date entered earlier. In this example, the starting date was Thursday, Dec. 4, 1997. The choices would then be:
- the user selects the duration of the recurrence.
- the granularity of choices is limited by the recurrence type, weekly, monthly or yearly.
- the choices which are displayed as illustrated in FIG. 20B, include:
- the familiar NEXT indicator appears, confirming the user's choices, as shown in FIG. 20C.
- the user can hit SELECT to move on to the next stage.
- This Smart Assistant allows the user to activate the reminder and specify the prior notification period of the reminder.
- the familiar NEXT indicator appears, as shown in FIG. 21B, confirming the user's choice.
- the user can hit SELECT to move on to the next stage.
- the final stage of any sequence of Smart Assistant is the "Summary" (display).
- the Summary illustrates the complete sequence of user choices and allows the user to review the event before submitting it to the system, as demonstrated in FIG. 21C.
- the user To accept the new event, the user simply hits the SELECT key and the Smart Assistant entry system returns to the screen and module from which it was invoked.
- the first step is to hit the left arrow key to reverse to the BACK indicator and then press the select key to go back to the previous form, as shown in FIG. 22B.
- Hitting SELECT will move the input focus back to the previous form, the reminder, with the BACK indicator showing, as illustrated in FIG. 22C; hitting SELECT again will take the user to the previous form, the recurrence form, with the BACK indicator showing, as illustrated in FIG. 22D.
- Hitting SELECT yet again will take the user to the previous form, the participant form, with the BACK indicator showing, as illustrated in FIG. 22E. This is the form with the last name field which needs to be changed.
- the next step is to hit the EDIT key as indicated in the status bar to begin editing the form.
- the BACK/NEXT indicator is removed and the first field on the form is highlighted, as shown in FIG. 22F.
- the user can move the highlight to a particular field for editing. Hitting the down arrow key moves the highlight from the "with" field to the "first" name field, as shown in FIG. 22G. Hitting the down arrow key again moves the highlight to the "last" name field which is the field the user wishes to change, as shown in FIG. 22H.
- the user can hit the SELECT key to change the field value, as indicated by the status bar. In this case, the user changes "Doe" to "Dunn," as shown in FIG. 22I.
- the highlight returns to the BACK/NEXT indicator, as shown in FIG. 22J. The user can use SELECT to continue to the next form until reaching the summary again. The user can make additional changes anywhere along the way.
- the Smart Assistant In certain cases, such as during a change to the type of participant, the Smart Assistant must adapt in response. In the example above, if the user selected the "with" field and changed it to a "New Company" instead of "New Person," the Smart Assistant would remove the first and last name fields and add a blank company title field. Instead of moving immediately to the BACK/NEXT indicator, in this case, the Smart Assistant would require that the user enter data to complete the form first. This will now be illustrated.
- FIG. 23A illustrates.
- the user hits SELECT to change the "with" field.
- the list control will pop up with the current selection already highlighted, as shown in FIG. 23B.
- the user changes the selection to "New Company," as illustrated in FIG. 23C.
- the Smart Assistant resets.
- the "Company” text field is added and the user is required to enter the text for the company name, as shown in FIG. 23D.
- the Smart Assistant then continues with the form as though all fields from the point of modification on are blank. In this case, the user also has the option of filing the company, as shown in FIG. 23E.
- the Smart Assistant returns to the BACK/NEXT state shown in FIG. 23F, once the form is completed. This mechanism allows the user to review and make changes to any data in the Smart Assistant system.
- FIGS. 24A-E demonstrate exemplary input screens for the task of adding a new contact.
- This example illustrates the additional task of inputting the company name of a new company.
- the user selects the type of contact, here a "business contact”.
- the user enters a name for the business contact, a person.
- the user enters a first and last name for the business contact, using the Text Input Control.
- the user enters a company name, as shown at FIG. 24C, again using the Text Input Control.
- FIG. 24D the user can now specify how the new entry should be filed. In this example, the user decides to file the new entry under "Business".
- FIG. 24A the user selects the type of contact, here a "business contact”.
- the user enters a name for the business contact, a person.
- the user enters a first and last name for the business contact, using the Text Input Control.
- the user enters a company name, as shown at FIG. 24C, again using the Text In
- 24E demonstrates the process for the task of adding company information for the contact, here Westridge Associates.
- the user may simply select it from the company pull-down list.
- the company name is new. Therefore, the user enters the name of the new company, using the Text Input Control.
- the company name need only be entered once; for subsequent contacts of that company, the user will be able to simply select the company name from the pull-down list.
- the user enters contact information, such as a work phone number.
- the user provides this input using the Text Input Control.
- the user has completed input of the "Business Contact” entry and may select the "Next" button, for proceeding to the Summary screen as illustrated in FIG. 24G.
- the user completes the task by invoking the "Done" screen button.
- FIGS. 25A-E illustrates exemplary input screens for the task of creating a "to do" item.
- FIG. 25A illustrates the additional task of specifying a new task description (i.e., one which is not available from the pull-down list).
- the user may select a task description from the task description pull-down list, such as the task of "pick up laundry".
- the user may define a new task description. This is done by instead selecting "New Task", as shown.
- FIG. 25B the user now enters a new description, again providing the input via the Text Input Control.
- the user enters a task description of "make sandwich".
- FIGS. 25C-D demonstrates the task of completing input for a "call" to do item.
- the user simply selects a contact (i.e., person) from the Tabbed List Control. Had this been a new contact, however, the user could have entered a new individual using the Text Input Control.
- the user can specify a due date by selecting from a "Due by" pull-down list. For example, the user could specify that this is due by "this week”. For this example, however, the user specifies that the due date is a specific date. Accordingly, the user enters a particular date, using a date input control.
- the user selects the "Next" button, for proceeding to the Summary screen, as demonstrated in FIG. 25E. The user completes the task by invoking the "Done" screen button.
- the text input control automatically performs intelligent capitalization as the user types. This provides a great convenience for the user and largely eliminates any need for the text input control to accept both upper- and lower-case letters.
- Automatic capitalization depends on context (e.g., the type of data field involved). Automatic capitalization works for names (e.g., of a contacts) and titles (e.g., subject of an event) according to the following rules:
- an Alternative Text Input Control as shown in FIG. 26, is used.
- This Alternative Text Input Control resembles the original version described above (e.g., in FIG. 13H) except for the following features.
- the letter strip includes multiple rows (e.g., two rows) of entries (e.g., characters) on the screen, instead of just one, and all entries within the letter strip are simultaneously visible on-screen.
- the entries, as well as the highlight for the entries wrap from one end of one row to an end of an adjacent row (e.g., top row's right end to second row's left end), and vice versa.
- the first of two available letter strips includes the following entries: Erase A B C D E F G H I J K L M N O P Q R S T U V W X Y Z (period) Space.
- the second available letter strip includes the following entries: Erase 1 2 3 4 5 6 7 8 9 0 (-)*#@ -- / ⁇ $ % & '?”! (period) Space.
- the Erase entry if selected by the user in the same manner as any other entry, acts as a backspace or undo button.
- the HOME key is not used as a backspace button. Rather, the HOME key acts to bring the user back one logical step before the user entered text entry mode. For example, the HOME key brings the user back to the previously displayed screen before the Alternative Text Input Control was invoked. A user who has already entered text in the Alternative Text Input Control may depress the HOME key just once to return to the previous screen, without backspacing over (and thereby losing) all text that has already been selected.
- the status bar in hint mode, identifies the HOME key with a "Back" function.
- the device will retain in its memory the text that has already been selected in the Alternative Text Input Control for a particular information field.
- the user who is entering information for one information field is provided with a way to correct choices or entries made at previous screen(s) and then resume entering information for the one field without losing data already entered for the one field and without having to first complete the entry of the one field (e.g., by pressing EDIT).
- the user can use a single-click "previous screen" command (namely, HOME) to return to the previous screen (or step-wise to an even earlier screen) for this purpose.
- the user can push the HOME key once to return to the previous, second screen, without thereby erasing any already-entered text, for example, "Doe”.
- the previously entered first name, "John” is already, automatically displayed and the user can re-edit this text.
- the user can also push the HOME key again, to return to the next previous, first screen.
- the previously chosen entry, "Business Contact” is highlighted and the user can move the highlight to select a new entry, for example, "Personal Contact”.
- the Smart Assistant control again proceeds forward to present screens that are appropriate for the user's corrected (first screen) selection.
- the Smart Assistant control first brings up a screen to receive the next field, First Name.
- the previously entered first name, "John” is already, automatically displayed and the user can re-edit this text.
- the Smart Assistant control brings up a screen to receive the next field, Last Name, with the previously entered text, "Doe", already, automatically displayed for any further editing.
- the Smart Entry Assistant can simply return the user to the actual form that the user used to enter even multiple fields.
- the user is returned to a screen showing the form, with the entry control for the form's last field invoked. From that entry control, the user can simply press HOME again, to go to the next previous screen, which will typically show the same form with an entry control invoked for editing the next-to-last field (if the form has multiple fields).
- An exit-confirmation feature is provided to prevent accidental exit by the user from a task of entering a new information record or revising an existing record. To appreciate this feature, it may be useful to recall that as the user enters information through a sequence of forms, which sequentially invoke controls for specific fields, he may traverse these fields and forms in a reverse direction in order to make corrections, without losing information already entered in the sequence of forms. As the user makes this rearward traversal, for example, by repeatedly pressing the HOME key of the Alternative Text Input Control, the optional exit-confirmation feature presents a yes-no confirmation screen just before the user would otherwise exit the sequence of forms altogether.
- the confirmation is an item list that can be satisfied using a button (e.g., SELECT) other than the one that the user has been using (e.g., HOME) to cause rearward traversal.
- a button e.g., SELECT
- HOME the one that the user has been using
- overenthusiastic, repeated pressing of the HOME key will not cause accidental exit (and loss of entered information) from the forms.
- An alternative sequence of smart forms may be used for entering new events that differs from the particular scheme described earlier. To appreciate this alternative sequence, it is helpful to summarize the earlier-described scheme.
- entry of a new event (“Schedule Event") starts with selecting a subject from a softlist of subjects.
- the softlist includes known subjects (i.e., factory-programmed and previously-user-entered subjects).
- the choices also include an "other subject” choice for entry of a new subject.
- Each subject is of a specific type.
- an icon indicates its type (e.g., a person's head for "meeting", a clock for "event", a calendar for "annual event”).
- the user chooses an associated type from a list (e.g., a factory-programmed list) of possible event types, and the user enters an associated subject (text) title.
- a list e.g., a factory-programmed list
- the software may optionally limit the length of the list by choosing only the N most recently used subjects for the softlist.
- Another consequence of this old scheme is that if the user desires to use the same text to describe different event subjects (i.e., subjects of different types, e.g., multi-day event AND all-day event), then there may be multiple entries in the softlist of known subjects that have the same text and differ only in their type icons. This may be confusing.
- the alternative sequence of smart forms provides improved usability.
- entry of a new event e.g., called "New Event” starts with selecting an event type followed by the selecting of a subject, from a type-dependent softlist of leg subjects.
- This type-dependent subject softlist includes all known subjects (i.e., factory-programmed and previously-user-entered subjects) for only the selected event type.
- the choices also include an "other subject” choice for entry of a new subject for the selected event type.
- the appropriate remaining fields are accepted from the user in the previously-described manner. Note that entry of a new subject requires only new text, since the type is already selected.
- the event types are reorganized such that the "Meeting” type described in a previous section is renamed “Recurring Event”, and the sequence of smart forms used by the other types (e.g., "Event” and "All-Day Event” types) are modified to not ask the user for a recurrence pattern.
- the device when the user hits the EDIT key from a non-edit (e.g., ordinary navigation) mode, the device generally responds by providing a context-dependent list of possible actions (e.g., in an item list control) for the user's choice or confirmation.
- a context-dependent list of possible actions e.g., in an item list control
- the choices include New Event, New Contact, New To Do, and New QuickNote.
- the initial highlight for the choices is also generally context-dependent. For example, if in the top-level view, the Contacts icon was highlighted when the EDIT key was hit, then the New Contact choice is automatically initially highlighted in the item list control.
- the general paradigm for offering context-dependent initial choices is as follows:
- Context 1a Any view in the Calendar module capable of listing multiple events (e.g., Daily view), when a (user-navigable) highlight is on a single listed event.
- Choices follow Up, Reschedule, Cancel Event, and New Event. Also, Find in Contacts (described in further detail below), if the highlighted event includes a participant (e.g., in its Subject string) that matches a contact in the Contacts module.
- a participant e.g., in its Subject string
- Context 1b Any detailed (e.g., full page) view in the Calendar module of a specific event.
- Choices follow Up, Reschedule, and Cancel Event. Also, Find in Contacts, if the specific event includes a participant (in its Subject string) that matches a contact in the Contacts module.
- Context 1c Any other view in the Calendar module (e.g., monthly view, weekly view, or daily view without any (user-navigable) highlight on a single event).
- Choice New Event.
- Context 2a Any view in the Calendar module capable of listing multiple contacts, when a (user-navigable) highlight is on a single listed contact. (For example, a navigation view using the category tabs with the (user-navigable) highlight on a particular name in the list of names.)
- Context 2b1 Any view of a particular contact in the Contacts module, when a (user-navigable) highlight is on a particular field (generally, from among multiple displayed fields). (For example, the Numbers view that displays all non-empty fields for phone numbers and email and Web addresses, etc.)
- Context 2b2 Any view of a particular contact in the Contacts module in which no (usernavigable) highlight is to be provided or shown. (For example, the Work Address, Home Address, or Notes views.)
- Choices Change ⁇ view's fields' collective name> (e.g., "Change Work Address"), Remove ⁇ view's fields' collective name>, and New Number.
- Context 2c Any other view in the Contacts module. (For example, a navigation view using the category tabs before the highlight descends from the tabs onto any particular name in the list of contact names. Note that this list typically includes on each row a contact's name followed by the value of a contact-specific, user-chosen one of the contact's fields, e.g., Work Phone, called the "Display" field.)
- Context 3a Any view in the To Do module capable of listing multiple tasks, when a (user-navigable) highlight is on a single listed To Do item.
- Context 3b Any detailed (e.g., full page) view in the To Do List module of a specific To Do item.
- Context 4a Any view in the Memos module capable of listing multiple memos, when a (user-navigable) highlight is on a single listed memo.
- Context 4b Any detailed (e.g., full page) view in the Memos module of a specific memo.
- This Smart Assistant creates a new event.
- the fields that this Smart Assistant accepts are as follows.
- Event Type Event, Recurring Event, All-Day Event, Multi-Day Event, and Annual Event.
- the Person in Contacts choice causes the Smart Assistant to invoke a tabbed list control allowing selection of a name from a list of all contacts (from all files) of the Contacts module.
- the Company in Contacts choice causes the Smart Assistant to invoke a tabbed list control allowing selection of a company name from a list having a row for each contact of the Contacts module, wherein each row lists ⁇ company>: ⁇ person> (e.g., "Acme Inc.:Smith”) for a contact (e.g, Bill Smith of Acme Inc.).
- the New Person choice causes the Smart Assistant to invoke a form for accepting only limited information for a new contact to be added also into the Contacts module, wherein the limited information includes just first name, last name, and the file from the Contacts module in which to file the new contact.
- the New Company choice is like the New Person choice, except that the limited information collected for the new contact includes just the company name and the file from the Contacts module.
- the participant name is appended to the end of the Subject field, prefaced by "with” (e.g., "Meeting with Bill Smith”).
- Date ⁇ highlighted/current date>. If a date was highlighted or selected on entry into the Smart Assistant, it is the initial choice to be edited/confirmed. Otherwise, the current (today's) date is the initial choice.
- Time ⁇ first free hour of Date, starting with 9am, or if no free hour, 9am>.
- Reminder None, 5 minutes before, 15 minutes before, 30 minutes before, 1 hour before, 2 hours before, 3 hours before, 4 hours before, and 5 hours before.
- This Smart Assistant creates a new follow-up event to an existing event.
- This Smart Assistant automatically creates the Subject field of the follow-up event by pre-pending "Follow up to” to the existing event's Subject.
- the other fields that this Smart Assistant accepts are as follows.
- Time ⁇ existing event's end time>.
- This Smart Assistant reschedules an existing event.
- the fields that this Smart Assistant accepts are as follows.
- This Smart Assistant cancels an existing event. It simply asks for yes-no confirmation ("Are you sure?") via an item list control and deletes the event if user confirms "yes”.
- this Smart Assistant For an existing event with a participant that matches a contact in the Contacts module, this Smart Assistant immediately takes the user to a view (preferably, Numbers view) of the matching contact in the Contacts module. This Smart Assistant is further described in detail elsewhere in this document.
- This Smart Assistant creates a new contact.
- the fields that this Smart Assistant accepts are as follows.
- This Smart Assistant creates a new event that will involve an existing contact as a participant.
- This Smart Assistant automatically creates the Subject field of the new event by pre-pending "Meet" to the existing contact's name (or, if none, the existing contact's company), e.g., "Meet John Hansen”.
- the other fields that this Smart Assistant accepts are as follows.
- Time ⁇ first free hour of Date, starting with 9 am, or if no free hour, 9 am>.
- This Smart Assistant creates a new To Do item (of type Call) that will involve an existing contact as a callee, or participant.
- This Smart Assistant automatically creates the Subject field of the new event by pre-pending "Call" to the existing contact's name (or, if none, the existing contact's company), e.g., "Call Bob Jones”.
- the other fields that this Smart Assistant accepts are as follows.
- Due Date No due date, Today, Tomorrow, This Week, Next Week, and Specific date. If the user chooses This Week (or Next Week), the date of the next (or next after next) last-day-of-week is automatically used, wherein last-day-of-week is user-settable to, e.g., Friday, Saturday, or Sunday. If the user chooses Specific date, a date input control is invoked.
- This Smart Assistant removes an existing contact. It simply asks for yes-no confirmation ("Are you sure?") via an item list control and deletes the contact if the user confirms "yes".
- This Smart Assistant simply invokes an appropriate control (e.g., text input control) for editing/confirming the existing value of an existing field.
- an appropriate control e.g., text input control
- This Smart Assistant removes an existing field's value. It simply asks for yes-no confirmation ("Are you sure?") via an item list control and resets the existing field's value to null or empty if the user confirms "yes".
- This Smart Assistant accepts a new phone number or email or Web address for an existing contact.
- the fields that this Smart Assistant accepts are as follows.
- This Smart Assistant designates an existing field as the "Display" field (which will be displayed alongside the contact's name in the navigation view). This Smart Assistant does not ask for confirmation.
- This Smart Assistant invokes an appropriate control to accept input of values for a set of fields.
- the control is simply a text control for editing/confirming the entire current address displayed as a single string.
- the Smart Assistant parses the string according to standard methods into its constituent fields (Address, City, State, etc.)
- Subject Report, Review, Plan, Forecast, Proposal, Schedule, Presentation, Gift, and Other Deliverable.
- Smart Assistants for the To Do module include Check Off, Remove, and Find in Contacts. These Smart Assistants behave in ways essentially as described above for similarly named Smart Assistants.
- the New QuickNote Smart Assistant invokes a text input control to accept a single field, Text, which may be quite long.
- the Append Smart Assistant invokes a text input control to edit/confirm an existing memo.
- the Remove Smart Assistant deletes an existing memo, upon yes-no confirmation by the user.
- FIGS. 27A-F illustrate a methodology of the present invention for Smart Entry Assistant control flow--that is, the general flow of control for each Smart Entry Assistant.
- the system provides a variety of Smart Entry Assistants, used for entering a variety of different information (e.g., new contact, new event, and the like) on a target device.
- Each assistant is composed of one or more pages. The pages are sequentially arranged, with the user typically starting at a first page and then proceeding to one or more subsequent pages. Each page itself may be "on” or “off”, which determines whether the page is currently displayed to the user. Typically, the first page will be turned “on”, with subsequent pages being turned either "on” or “off” depending on the user input in prior pages. For example, user input of a particular type on the first page may render certain subsequent pages irrelevant; thus, the system may turn "off” these irrelevant pages, as desired.
- Each page itself is composed of individual controls. As previously demonstrated above, each page includes input controls together with a "Next/Back” control (or in the case of the last page, a “Back/Done” control). Like a page, each control on a page can be “on” or “off”. In a manner similar to that described for pages, the system may turn “on” or “off” a particular control, based on the then-current state of user input. Thus, irrelevant controls may be removed from display (i.e., made invisible), as desired. Further, each control has an associated value, which corresponds to the input value for that control (e.g., value entered by the user). Also, each control can be “filled” or “unfilled”. “Filled” means that the user has entered a value into that field; “unfilled” means that the user has yet to enter any value into that field. The following description will focus on exemplary logic employed for navigating among pages and navigating among individual controls on a given page.
- the methodology begins with an initialization sequence 2700, which begins as indicated by step 2701. Specifically, the method proceeds as follows. At step 2702, the system initializes all relevant controls to their default values (if any). For a counter control, for example, the system might initialize it to the current date. At step 2703, the states of the individual controls are set to "unfilled”. This indicates that the controls, at this point in time, do not yet contain values completed or confirmed by the user. In a similar manner, at step 2704, all pages are initialized to their default values (i.e., initializing each page to either "on” or "off", depending on the page's default value). Then, at step 2705, the method sets the current page (focus) to the first page of the Smart Entry Assistant (SEA). Finally, the method has completed initialization, and now may enter a "Control Mode,” as indicated at step 2706.
- SEA Smart Entry Assistant
- Control Mode is a transitional mode--a decision state--where the system determines where it is going to go next (i.e., what mode it is to enter next) after an event has occurred.
- Entry Mode is a mode where the system receives user input.
- the Next/Back Mode is a navigational mode where the user has gone through all the (relevant) controls of a page and focus is now at the Next/Back button at the bottom of the screen, for moving among pages.
- the Edit Mode is a mode where the user is going to pick a particular control on a page, for entering a correction or making a change.
- FIG. 27B illustrates a flowchart 2710 illustrating the basic operation or methodology for the Control Mode.
- Step 2711 indicates that the system has entered the Control Mode (e.g., after completion of the initialization sequence 2700).
- the method scans the current page for the first control which is "on" and "unfilled". Note at this point that there may not be a control at the current page meeting these conditions. This is tested at step 2713.
- the purpose of step 2712 is to find the appropriate control for setting focus, based on the then-current state of user input. If such a control does not exist, then the system will switch into a Next/Back mode.
- the method is able to save the user a lot of time with the task of inputting information.
- step 2713 the method sets the current control to that control, as indicated at step 2715. Now, the method is ready to switch the system into the Entry Mode. This is indicated at step 2716.
- FIG. 27C illustrates operation of the method during Entry Mode, as represented by flowchart 2730.
- Step 2731 indicates that the system has entered Entry Mode.
- the method simply executes the current control.
- the system at this point passes execution control to the control for executing its own logic, which varies from control to control depending on control type (e.g., text input control, calendar control, or the like).
- control type e.g., text input control, calendar control, or the like.
- the method may test, at step 2733, whether the control was "filled”.
- the method marks the control as "filled” at step 2734. Then, at step 2735, the method switches back into the Control Mode (which will effectively take the user down to the next "unfilled” control).
- step 2741 to mark the control as "unfilled”. Situations where the user has provided input but then suspended or canceled the input (e.g., via the HOME key) are also treated as "unfilled”.
- step 2742 for determining whether there exists a previous "on" control on the current page. If such a control is found (i.e., "yes” at step 2742), then the method proceeds to step 2743 to set the current control (focus) to the previous "on” control. In other words, the method at this point sets focus to the previous control. Now, the method may enter the Entry Mode for providing input to that control, as indicated at step 2744.
- step 2745 for determining whether a previous page exists. If there is no previous page at step 2745, then the user has canceled out of the Smart Entry Assistant, as indicated at step 2748. If there is a previous page, however, the method will switch the system back to that page. This is indicated at step 2746, where the method sets the current page (focus) to the previous page. Now, the method may enter Control Mode, as indicated at step 2747.
- the Control Mode as previously described, will function to find the first "unfilled” control on that page. Hence, the particular control that the user ends up on upon entering Control Mode depends on the then-current state of user input. On the other hand, if everything had already been filled on that page, the system would switch into the Next/Back Mode, thereby allowing the user to navigate to another page as appropriate.
- FIG. 27D shows a flowchart 2750 that illustrates operation of the system during Next/Back Mode.
- Step 2751 illustrates that the system has now entered the Next/Back Mode.
- the Next/Back Mode arises, for instance, when the system enters Control Mode with no unfilled controls on the current page.
- the Next/Back mode there are four basic possibilities that may happen.
- the system displays the Next/Back button (arrows) at the bottom of the screen and awaits a user keystroke.
- the simplest scenario is where the user has selected the Edit key. In this case, the system simply enters Edit Mode, as indicated by the method proceeding to step 2770.
- step 2753 determines whether there exists a next "on" page (i.e., is there a next page in this sequence that is enabled). If one in fact exists (i.e., "yes” at step 2753), then the method proceeds to step 2755 to set the current page to the next "on” page and then switches back to the Control Mode, as indicated by step 2756. Typically when switching back in this manner, the next page will not have been filled before and, therefore, the system will set control or focus to the first (unfilled) control up on that page. If there is not a next (on) page at step 2753, then the user must be on the last page of the Wizard or Assistant.
- Step 2754 represents, therefore, the completion or finish point for operation of the Smart Entry Assistant.
- step 2771 the method determines whether there exists a previous "on" page. If such a page does exist, the method sets the current page to that previous "on” page, as indicated by step 2772, and then enter Control Mode, as indicated by step 2773. If, however, there is not a previous "on” page at step 2771, the method simply stays in Next/Back Mode, as shown at step 2775. In effect, nothing happens (i.e., the system remains in the same mode) if there is no previous "on" page.
- the method determines whether there exists any "on" control on this (current) page, as indicated by decision step 2761. Typically, there will be a control meeting this condition, as the only page usually not having controls in the preferred embodiment is a Summary page (at the very end). If one is found (i.e., "yes” at step 2761), the method proceeds to set the current control to the last "on” control on this (current) page, regardless of filled status, as indicated at step 2762. This is immediately followed by switching into Entry Mode, as indicated by step 2763.
- step 2765 the method tests whether there exists a previous "on” page. If there is a previous page (which there typically will be), the system switches back to that page by setting the current page to this previous "on” page, as shown at step 2766, and then reenters the Next/Back Mode, as shown at step 2767. Thus, in other words, hitting the Home key causes the system to jump back to the previous page, if any.
- step 2765 In the case where there is no previous "on” page (i.e., "no" at step 2765), the method simply reenters the Next/Back Mode, as indicated by step 2768. In the wizards for the currently-preferred embodiment, this scenario does not arise.
- FIG. 27E shows a flowchart 2780 that illustrates operation of the Edit Mode.
- the system only enters this mode when the user has invoked the Edit key during the Next/Back Mode.
- the user is navigating between pages (i.e., operating the system in Next/Back Mode) and sees something that he or she wishes to edit and, thus, presses the Edit key.
- the system provides highlighting of descriptive text (e.g., field name) provided next to the control (e.g., field), thus allowing the user to easily pick an appropriate choice.
- Step 2781 indicates that the system has entered Edit Mode.
- the method determines whether there exists an "on" control on this (current) page.
- step 2785 If there is not one (which only occurs at the Summary page), the system simply returns to the Next/Back Mode, as indicated by step 2785. If there is such a control (which typically will be the case), then the current control is set to be the first enabled (i.e., "on") control, indicated by step 2783, and the system enters an Edit Input loop, as indicated by step 2784.
- FIG. 27F shows a flowchart 2790 illustrating operation of the system during the Edit Input loop.
- Step 2791 indicates that the system has entered this loop.
- the system highlights the description of the current control. This is a visual cue provided by the system that allows the user to complete input by selection, instead of actual data entry.
- the method proceeds to step 2793, where the system awaits a keystroke. At this point, four input options are available: (1) Edit or Home, (2) Next, (3) Back, and (4) Enter or Select. In the event that the user selects the Next key, the method proceeds to step 2811. Here, the system will determine whether there exists a next "on" control on this (current) page.
- the method sets the current control to the next "on” control, as indicated at step 2812, and then reenters (loops back to) the Edit Input loop, as indicated at step 2813. If there is not a next "on” control (i.e., "no" at step 2811), the method simply loops, as indicated at step 2815, with no change.
- Operation of Back is, essentially, that of Next in reverse. If there exists a previous "on" control on the current page, tested at step 2821, the method sets the current control to that previous "on” control (including highlighting its description), as indicated at step 2822. Thereafter, at step 2823, the method reenters the Edit Input loop. If there is no previous "on” control (i.e., "no" at step 2821), the method simply reenters the Edit Input loop, as indicated at step 2825.
- step 2801 the system switches into the Entry Mode on that control, as indicated by step 2831.
- the system of the present invention is able to provide intelligent support for light data entry for terse-input devices in a manner that facilitates user input, while eliminating unnecessary navigation for completing input.
- the above described input methodology of the present invention allows users to navigate smoothly among controls, navigate smoothly among pages (i.e., groups of controls), enter data in those controls, and easily cancel out of input.
- the user may need to quickly reference that participant's phone, address, or notes information, for example, when entering Event or To Do information, such as illustrated in FIG. 28A.
- the present invention solves this problem as follows.
- an Event or To Do contains the name of a person that exists in Contacts
- a "Find in Contacts" menu item is made available to the user, using the Edit menu for that Event or To Do, as shown in the figure.
- the participant associated with that Meeting, Call, or Task with Deliverable is located in Contacts and displayed to the user.
- the "Find in Contacts" menu item is not displayed for Events or To Dos that do not contain a personal name matching an entry in Contacts. In other words, the contact is actually looked up before presenting the menu item. If there is a matching contact, the "Find in Contacts" selection immediately jumps the user to that contact. If there is no matching contact, the user is not even presented with the menu item.
- FIG. 28B illustrates this scenario with a "Not in Contacts" entry. As shown, the pop-up menu does not include a "Find in Contacts" choice.
- the device begins searching the Contacts module for names or company names that match word(s) in an Event's or To Do's Subject string as soon as any single listed Event or To Do is highlighted during navigation, just in case the user decides to press EDIT. This searching happens automatically "in the background" without needing the user's awareness.
- the search may optionally be limited to the last words in an Event following the word "with” or "Meet” (e.g., the last words in “Interview with Bill Jones” or “Meet Bob Smith") or the last words following the word "for” in a To Do of type Task With Deliverable (e.g., the last words in "Report for Acme Corp.") or the last words in a To Do of type Call (e.g., the last, and only, words in "Bob Smith”).
Abstract
Description
Claims (55)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/186,732 US6141011A (en) | 1997-08-04 | 1998-11-04 | User interface methodology supporting light data entry for microprocessor device having limited user input |
US09/687,988 US6310634B1 (en) | 1997-08-04 | 2000-10-13 | User interface methodology supporting light data entry for microprocessor device having limited user input |
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US90546397A | 1997-08-04 | 1997-08-04 | |
US9394998P | 1998-07-24 | 1998-07-24 | |
US9860798P | 1998-08-31 | 1998-08-31 | |
US09/186,732 US6141011A (en) | 1997-08-04 | 1998-11-04 | User interface methodology supporting light data entry for microprocessor device having limited user input |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US90546397A Continuation-In-Part | 1997-06-13 | 1997-08-04 |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/687,988 Continuation US6310634B1 (en) | 1997-08-04 | 2000-10-13 | User interface methodology supporting light data entry for microprocessor device having limited user input |
Publications (1)
Publication Number | Publication Date |
---|---|
US6141011A true US6141011A (en) | 2000-10-31 |
Family
ID=46255243
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/186,732 Expired - Lifetime US6141011A (en) | 1997-08-04 | 1998-11-04 | User interface methodology supporting light data entry for microprocessor device having limited user input |
US09/687,988 Expired - Lifetime US6310634B1 (en) | 1997-08-04 | 2000-10-13 | User interface methodology supporting light data entry for microprocessor device having limited user input |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/687,988 Expired - Lifetime US6310634B1 (en) | 1997-08-04 | 2000-10-13 | User interface methodology supporting light data entry for microprocessor device having limited user input |
Country Status (1)
Country | Link |
---|---|
US (2) | US6141011A (en) |
Cited By (69)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP0994409A2 (en) * | 1998-10-12 | 2000-04-19 | Hewlett-Packard Company | Index tabs |
FR2818398A1 (en) * | 2000-12-20 | 2002-06-21 | Sagem | Capture of alphanumeric passwords from a television remote control reduced key keyboard, uses global dissimulation time stating from end of password capture |
US20020093492A1 (en) * | 2001-01-18 | 2002-07-18 | Baron John M. | System for a navigable display |
WO2002065330A1 (en) * | 2001-02-13 | 2002-08-22 | Justsystem Corporation | Learning from user modifications and revisions to text |
US6459422B1 (en) * | 1998-12-22 | 2002-10-01 | Canon Kabushiki Kaisha | Graphical user interface for inputting data |
US20020143544A1 (en) * | 2001-03-29 | 2002-10-03 | Koninklijke Philips Electronic N.V. | Synchronise an audio cursor and a text cursor during editing |
US20020154159A1 (en) * | 2001-04-19 | 2002-10-24 | International Business Machines Corporation | Method, apparatus, and program for associating successive repointing of a browser's load function with navigational links in web pages |
US6489976B1 (en) * | 1998-12-15 | 2002-12-03 | International Business Machines Corporation | System and method for displaying pop-up symbols for indicating accelerator keys for implementing computer software options |
US6570596B2 (en) | 1998-03-25 | 2003-05-27 | Nokia Mobile Phones Limited | Context sensitive pop-up window for a portable phone |
US20030164844A1 (en) * | 2000-09-25 | 2003-09-04 | Kravitz Dean Todd | System and method for processing multimedia content, stored in a computer-accessible storage medium, based on various user-specified parameters related to the content |
US6671757B1 (en) | 2000-01-26 | 2003-12-30 | Fusionone, Inc. | Data transfer and synchronization system |
US6683626B1 (en) * | 2000-10-04 | 2004-01-27 | Sun Microsystems, Inc. | Focus-based scrolling |
EP1412907A1 (en) * | 2001-06-20 | 2004-04-28 | Capital One Financial Corporation | System and method for indetifying applications loaded in the smart card |
US6733455B2 (en) | 1999-08-20 | 2004-05-11 | Zonare Medical Systems, Inc. | System and method for adaptive clutter filtering in ultrasound color flow imaging |
US6738789B2 (en) | 2000-01-25 | 2004-05-18 | Fusionone, Inc. | Data package including synchronization data |
US20040138569A1 (en) * | 1999-08-20 | 2004-07-15 | Sorin Grunwald | User interface for handheld imaging devices |
US20050099963A1 (en) * | 2000-01-26 | 2005-05-12 | Multer David L. | Data transfer and synchronization system |
US20050149376A1 (en) * | 1999-05-04 | 2005-07-07 | Accenture Llp | Component based interface to handle tasks during claim processing |
US6925476B1 (en) | 2000-08-17 | 2005-08-02 | Fusionone, Inc. | Updating application data including adding first change log to aggreagate change log comprising summary of changes |
US6944651B2 (en) | 2000-05-19 | 2005-09-13 | Fusionone, Inc. | Single click synchronization of data from a public information store to a private information store |
US20060064649A1 (en) * | 2004-09-23 | 2006-03-23 | Microsoft Corporation | Systems and methods for navigation of a graphical user environment |
US7035878B1 (en) | 2000-01-25 | 2006-04-25 | Fusionone, Inc. | Base rolling engine for data transfer and synchronization system |
US20060149790A1 (en) * | 2004-12-30 | 2006-07-06 | Gert Rusch | Synchronization method for an object oriented information system (IS) model |
US20060158436A1 (en) * | 2004-12-07 | 2006-07-20 | Jacques Lapointe | User interface with augmented searching characteristics |
WO2006125133A2 (en) * | 2005-05-19 | 2006-11-23 | Hillcrest Laboratories, Inc. | Global navigation objects in user interfaces |
US20070266334A1 (en) * | 2000-05-11 | 2007-11-15 | Palmsource, Inc. | Automatically centered scrolling in a tab-based user interface |
US20080201662A1 (en) * | 2007-02-13 | 2008-08-21 | Harman Becker Automotive Systems Gmbh | Methods for controlling a navigation system |
US20080215691A1 (en) * | 2001-07-16 | 2008-09-04 | Rupesh Chhatrapati | Method and apparatus for calendaring reminders |
US20090013052A1 (en) * | 1998-12-18 | 2009-01-08 | Microsoft Corporation | Automated selection of appropriate information based on a computer user's context |
US7587446B1 (en) | 2000-11-10 | 2009-09-08 | Fusionone, Inc. | Acquisition and synchronization of digital media to a personal information space |
US7617240B2 (en) | 1999-05-04 | 2009-11-10 | Accenture Llp | Component based task handling during claim processing |
US7643824B2 (en) | 2004-02-27 | 2010-01-05 | Cooligy Inc | Wireless telephone data backup system |
US7685298B2 (en) | 2005-12-02 | 2010-03-23 | Citrix Systems, Inc. | Systems and methods for providing authentication credentials across application environments |
US20100250321A1 (en) * | 2009-03-26 | 2010-09-30 | International Business Machines Corporation | Quorum management of appointment scheduling |
US7818435B1 (en) | 2000-12-14 | 2010-10-19 | Fusionone, Inc. | Reverse proxy mechanism for retrieving electronic content associated with a local network |
US7836412B1 (en) * | 2004-12-03 | 2010-11-16 | Escription, Inc. | Transcription editing |
US7895334B1 (en) | 2000-07-19 | 2011-02-22 | Fusionone, Inc. | Remote access communication architecture apparatus and method |
US7933786B2 (en) | 2005-11-01 | 2011-04-26 | Accenture Global Services Limited | Collaborative intelligent task processor for insurance claims |
US7979382B2 (en) | 1999-05-04 | 2011-07-12 | Accenture Global Services Limited | Component based information linking during claim processing |
US8073954B1 (en) | 2000-07-19 | 2011-12-06 | Synchronoss Technologies, Inc. | Method and apparatus for a secure remote access system |
US20120019995A1 (en) * | 2010-07-26 | 2012-01-26 | Hon Hai Precision Industry Co., Ltd. | Embedded system and method for adjusting content |
US20120046986A1 (en) * | 2010-08-18 | 2012-02-23 | Hannon Meaghan | Optimizing organization and display of scheduling classes |
US8126742B2 (en) | 2003-05-09 | 2012-02-28 | Accenture Global Services Limited | Automated assignment of insurable events |
US8181111B1 (en) | 2007-12-31 | 2012-05-15 | Synchronoss Technologies, Inc. | System and method for providing social context to digital activity |
US8255006B1 (en) | 2009-11-10 | 2012-08-28 | Fusionone, Inc. | Event dependent notification system and method |
US20130055164A1 (en) * | 2011-08-24 | 2013-02-28 | Sony Ericsson Mobile Communications Ab | System and Method for Selecting Objects on a Touch-Sensitive Display of a Mobile Communications Device |
US8478769B2 (en) | 2008-02-22 | 2013-07-02 | Accenture Global Services Limited | Conversational question generation system adapted for an insurance claim processing system |
US8504369B1 (en) | 2004-06-02 | 2013-08-06 | Nuance Communications, Inc. | Multi-cursor transcription editing |
US8515786B2 (en) | 2008-02-22 | 2013-08-20 | Accenture Global Services Gmbh | Rule generation system adapted for an insurance claim processing system |
US8576167B2 (en) | 1999-05-27 | 2013-11-05 | Tegic Communications, Inc. | Directional input system with automatic correction |
US8611873B2 (en) | 2004-05-12 | 2013-12-17 | Synchronoss Technologies, Inc. | Advanced contact identification system |
US8615566B1 (en) | 2001-03-23 | 2013-12-24 | Synchronoss Technologies, Inc. | Apparatus and method for operational support of remote network systems |
US8620286B2 (en) | 2004-02-27 | 2013-12-31 | Synchronoss Technologies, Inc. | Method and system for promoting and transferring licensed content and applications |
US8645471B2 (en) | 2003-07-21 | 2014-02-04 | Synchronoss Technologies, Inc. | Device message management system |
US20140040772A1 (en) * | 2011-12-12 | 2014-02-06 | Adobe Systems Incorporated | Highlighting graphical user interface components based on usage by other users |
US8679018B2 (en) | 1999-08-20 | 2014-03-25 | Zonare Medical Systems, Inc. | Broad-beam imaging |
US8943428B2 (en) | 2010-11-01 | 2015-01-27 | Synchronoss Technologies, Inc. | System for and method of field mapping |
USD743995S1 (en) * | 2014-01-09 | 2015-11-24 | Microsoft Corporation | Display screen with graphical user interface |
USD743996S1 (en) * | 2014-01-09 | 2015-11-24 | Microsoft Corporation | Display screen with graphical user interface |
US20160018308A1 (en) * | 2014-07-16 | 2016-01-21 | Mitutoyo Corporation | Hardness tester |
US9400782B2 (en) | 1999-05-27 | 2016-07-26 | Nuance Communications, Inc. | Virtual keyboard system with automatic correction |
US20160224539A1 (en) * | 2008-03-14 | 2016-08-04 | Sony Mobile Communications Inc. | Character input apparatus, character input assist method, and character input assist program |
US9542076B1 (en) | 2004-05-12 | 2017-01-10 | Synchronoss Technologies, Inc. | System for and method of updating a personal profile |
US20170075704A1 (en) * | 2000-06-21 | 2017-03-16 | Microsoft Technology Licensing, Llc | Task-Sensitive Methods and Systems for Displaying Command Sets |
US20180101762A1 (en) * | 2015-12-10 | 2018-04-12 | Pablo Gutierrez | Graphical interfaced based intelligent automated assistant |
CN110858216A (en) * | 2018-08-13 | 2020-03-03 | 株式会社日立制作所 | Dialogue method, dialogue system, and storage medium |
CN112000877A (en) * | 2020-07-15 | 2020-11-27 | 北京搜狗科技发展有限公司 | Data processing method, device and medium |
USD1014552S1 (en) * | 2021-11-02 | 2024-02-13 | Abiomed, Inc. | Display panel or portion thereof with graphical user interface |
USD1017634S1 (en) * | 2021-11-02 | 2024-03-12 | Abiomed, Inc. | Display panel or portion thereof with graphical user interface |
Families Citing this family (90)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6675233B1 (en) * | 1998-03-26 | 2004-01-06 | O2 Micro International Limited | Audio controller for portable electronic devices |
US6954804B2 (en) * | 1998-03-26 | 2005-10-11 | Micro, Inc. | Controller for portable electronic devices |
US6895448B2 (en) * | 1998-03-26 | 2005-05-17 | O2 Micro, Inc. | Low-power audio CD player for portable computers |
US6343318B1 (en) | 1998-05-29 | 2002-01-29 | Palm, Inc. | Method and apparatus for communicating information over low bandwidth communications networks |
US6590588B2 (en) * | 1998-05-29 | 2003-07-08 | Palm, Inc. | Wireless, radio-frequency communications using a handheld computer |
US6674449B1 (en) * | 1998-11-25 | 2004-01-06 | Ge Medical Systems Global Technology Company, Llc | Multiple modality interface for imaging systems |
US6733131B1 (en) * | 1998-12-03 | 2004-05-11 | Jeffrey N. Weiss | Eye self-test device |
US7079166B1 (en) * | 2000-01-07 | 2006-07-18 | Ricoh Company, Ltd. | Graphical user interface with enhanced operations when changing display screen |
US6654038B1 (en) * | 2000-06-02 | 2003-11-25 | Sun Microsystems, Inc. | Keyboard navigation of non-focusable components |
US7130930B1 (en) * | 2000-06-16 | 2006-10-31 | O2 Micro Inc. | Low power CD-ROM player with CD-ROM subsystem for portable computer capable of playing audio CDs without supply energy to CPU |
US6983424B1 (en) * | 2000-06-23 | 2006-01-03 | International Business Machines Corporation | Automatically scaling icons to fit a display area within a data processing system |
US6831568B1 (en) * | 2000-06-30 | 2004-12-14 | Palmone, Inc. | Method and apparatus for visual silent alarm indicator |
US6950994B2 (en) * | 2000-08-31 | 2005-09-27 | Yahoo! Inc. | Data list transmutation and input mapping |
US6822664B2 (en) * | 2000-10-11 | 2004-11-23 | Microsoft Corporation | Browser navigation for devices with a limited input system |
US7421666B2 (en) * | 2000-10-11 | 2008-09-02 | Microsoft Corporation | Browser navigation for devices with a limited input system |
US7526349B2 (en) * | 2000-12-01 | 2009-04-28 | O2Micro International Limited | Low power digital audio decoding/playing system for computing devices |
US7890741B2 (en) * | 2000-12-01 | 2011-02-15 | O2Micro International Limited | Low power digital audio decoding/playing system for computing devices |
US7522966B2 (en) * | 2000-12-01 | 2009-04-21 | O2Micro International Limited | Low power digital audio decoding/playing system for computing devices |
US7522964B2 (en) | 2000-12-01 | 2009-04-21 | O2Micro International Limited | Low power digital audio decoding/playing system for computing devices |
US7818443B2 (en) * | 2000-12-01 | 2010-10-19 | O2Micro International Ltd. | Low power digital audio decoding/playing system for computing devices |
US7522965B2 (en) * | 2000-12-01 | 2009-04-21 | O2Micro International Limited | Low power digital audio decoding/playing system for computing devices |
US7123212B2 (en) * | 2000-12-22 | 2006-10-17 | Harman International Industries, Inc. | Information transmission and display method and system for a handheld computing device |
US20020087603A1 (en) * | 2001-01-02 | 2002-07-04 | Bergman Eric D. | Change tracking integrated with disconnected device document synchronization |
US20020135614A1 (en) * | 2001-03-22 | 2002-09-26 | Intel Corporation | Updating user interfaces based upon user inputs |
US6621697B2 (en) | 2001-05-24 | 2003-09-16 | Palm, Inc. | Stylus visual indicator system |
CA2357160A1 (en) * | 2001-09-10 | 2003-03-10 | Ibm Canada Limited-Ibm Canada Limitee | Wizard user interface providing interim system product generation and reversion during wizard traversal |
US20030128236A1 (en) * | 2002-01-10 | 2003-07-10 | Chen Meng Chang | Method and system for a self-adaptive personal view agent |
US7343484B2 (en) * | 2002-03-28 | 2008-03-11 | O2Micro International Limited | Personal computer integrated with personal digital assistant |
US7424623B2 (en) * | 2002-03-28 | 2008-09-09 | O2 Micro International Limited | Personal computer integrated with personal digital assistant |
US20030193481A1 (en) * | 2002-04-12 | 2003-10-16 | Alexander Sokolsky | Touch-sensitive input overlay for graphical user interface |
US6924667B2 (en) | 2002-07-19 | 2005-08-02 | O2Micro International Limited | Level shifting and level-shifting amplifier circuits |
JP4310084B2 (en) * | 2002-07-30 | 2009-08-05 | 富士通株式会社 | Information processing terminal and guidance display program |
US7185271B2 (en) * | 2002-08-20 | 2007-02-27 | Hewlett-Packard Development Company, L.P. | Methods and systems for implementing auto-complete in a web page |
JP2004234505A (en) * | 2003-01-31 | 2004-08-19 | Toshiba Corp | Information processing equipment and state notifying method |
US7793233B1 (en) | 2003-03-12 | 2010-09-07 | Microsoft Corporation | System and method for customizing note flags |
US7774799B1 (en) | 2003-03-26 | 2010-08-10 | Microsoft Corporation | System and method for linking page content with a media file and displaying the links |
US7454763B2 (en) | 2003-03-26 | 2008-11-18 | Microsoft Corporation | System and method for linking page content with a video media file and displaying the links |
US20040230915A1 (en) * | 2003-05-13 | 2004-11-18 | International Business Machines Corporation | System and method for improved distributed menu performance |
US7373603B1 (en) | 2003-09-18 | 2008-05-13 | Microsoft Corporation | Method and system for providing data reference information |
US8136050B2 (en) * | 2003-11-21 | 2012-03-13 | Nuance Communications, Inc. | Electronic device and user interface and input method therefor |
US7516414B2 (en) * | 2004-02-02 | 2009-04-07 | International Business Machines Corporation | System and method for tab order mapping of user interfaces |
US20050172235A1 (en) * | 2004-02-02 | 2005-08-04 | International Business Machines Corporation | System and method for excluded elements mapping in a user interface |
US7315988B2 (en) * | 2004-02-02 | 2008-01-01 | International Business Machines Corporation | System and method for using short captions to map user interfaces |
US20050216834A1 (en) * | 2004-03-29 | 2005-09-29 | Microsoft Corporation | Method, apparatus, and computer-readable medium for dynamically rendering a user interface menu |
US7587679B1 (en) * | 2004-08-25 | 2009-09-08 | Adobe Systems Incorporated | System and method for displaying elements using a single tab |
GB0420056D0 (en) * | 2004-09-10 | 2004-10-13 | Radioscape Ltd | A method of editing screen elements on a display with limited input devices |
US7788589B2 (en) * | 2004-09-30 | 2010-08-31 | Microsoft Corporation | Method and system for improved electronic task flagging and management |
US7712049B2 (en) | 2004-09-30 | 2010-05-04 | Microsoft Corporation | Two-dimensional radial user interface for computer software applications |
US7441089B2 (en) * | 2004-10-25 | 2008-10-21 | Searete Llc | Preserving content of serial use devices in view of purge |
US20060090038A1 (en) * | 2004-10-26 | 2006-04-27 | Jung Edward K | Auto purge of serial use devices |
KR100606078B1 (en) * | 2005-05-17 | 2006-07-28 | 삼성전자주식회사 | Apparatus for displaying location information of file and method thereof |
US7797638B2 (en) | 2006-01-05 | 2010-09-14 | Microsoft Corporation | Application of metadata to documents and document objects via a software application user interface |
US7747557B2 (en) | 2006-01-05 | 2010-06-29 | Microsoft Corporation | Application of metadata to documents and document objects via an operating system user interface |
US20070238489A1 (en) * | 2006-03-31 | 2007-10-11 | Research In Motion Limited | Edit menu for a mobile communication device |
US20080066018A1 (en) * | 2006-08-31 | 2008-03-13 | Ronald Scotte Zinn | Agenda determination in an electronic device |
US8146014B2 (en) * | 2006-08-31 | 2012-03-27 | Research In Motion Limited | Controlling a message display in an electronic device |
US20080059890A1 (en) * | 2006-08-31 | 2008-03-06 | Ronald Scotte Zinn | Conflict checking and notification in an electronic device |
US7761785B2 (en) | 2006-11-13 | 2010-07-20 | Microsoft Corporation | Providing resilient links |
US7707518B2 (en) | 2006-11-13 | 2010-04-27 | Microsoft Corporation | Linking information |
US20080163046A1 (en) * | 2006-12-29 | 2008-07-03 | Paul Christopher J | Method, system and program product for managing controls within an mdi environment |
US7930651B2 (en) * | 2007-01-18 | 2011-04-19 | Research In Motion Limited | Agenda display in an electronic device |
KR100860940B1 (en) * | 2007-01-22 | 2008-09-29 | 광주과학기술원 | Method of providing contents using a color marker and system for performing the same |
US7266693B1 (en) * | 2007-02-13 | 2007-09-04 | U.S. Bancorp Licensing, Inc. | Validated mutual authentication |
US8330625B2 (en) * | 2007-03-30 | 2012-12-11 | Honeywell International Inc. | Aircraft systems with flight management systems that display reports |
US20080270949A1 (en) * | 2007-04-25 | 2008-10-30 | Liang Younger L | Methods and Systems for Navigation and Selection of Items within User Interfaces with a Segmented Cursor |
US8095889B2 (en) * | 2008-05-12 | 2012-01-10 | Honeywell International Inc. | Heuristic and intuitive user interface for access control systems |
US20100161667A1 (en) * | 2008-12-22 | 2010-06-24 | Research In Motion Limited | Method and system for data record management in a computing device |
US20100161372A1 (en) * | 2008-12-22 | 2010-06-24 | Research In Motion Limited | Method and system for coordinating data records across a plurality of computing devices |
KR100984817B1 (en) * | 2009-08-19 | 2010-10-01 | 주식회사 컴퍼니원헌드레드 | User interface method using touch screen of mobile communication terminal |
US9524493B2 (en) * | 2009-11-24 | 2016-12-20 | International Business Machines Corporation | Chronologically navigating among time-based entries |
US20110126095A1 (en) * | 2009-11-25 | 2011-05-26 | T-Mobile USA, Inc | Router Management via Touch-Sensitive Display |
KR101731843B1 (en) * | 2010-09-02 | 2017-05-02 | 삼성전자 주식회사 | Method and Apparatus for displaying items |
EP2649503A4 (en) * | 2011-01-18 | 2014-12-24 | Nokia Corp | Task performance |
US8868123B2 (en) | 2012-07-16 | 2014-10-21 | Motorola Mobility Llc | Method and system for managing transmit power on a wireless communication network |
US9256366B2 (en) | 2012-08-14 | 2016-02-09 | Google Technology Holdings LLC | Systems and methods for touch-based two-stage text input |
US9021380B2 (en) * | 2012-10-05 | 2015-04-28 | Google Inc. | Incremental multi-touch gesture recognition |
US8782549B2 (en) | 2012-10-05 | 2014-07-15 | Google Inc. | Incremental feature-based gesture-keyboard decoding |
US8701032B1 (en) | 2012-10-16 | 2014-04-15 | Google Inc. | Incremental multi-word recognition |
US8843845B2 (en) | 2012-10-16 | 2014-09-23 | Google Inc. | Multi-gesture text input prediction |
US8850350B2 (en) | 2012-10-16 | 2014-09-30 | Google Inc. | Partial gesture text entry |
US8819574B2 (en) | 2012-10-22 | 2014-08-26 | Google Inc. | Space prediction for text input |
US9220070B2 (en) | 2012-11-05 | 2015-12-22 | Google Technology Holdings LLC | Method and system for managing transmit power on a wireless communication network |
US8832589B2 (en) | 2013-01-15 | 2014-09-09 | Google Inc. | Touch keyboard using language and spatial models |
US9274685B2 (en) | 2013-03-15 | 2016-03-01 | Google Technology Holdings LLC | Systems and methods for predictive text entry for small-screen devices with touch-based two-stage text input |
US9081500B2 (en) | 2013-05-03 | 2015-07-14 | Google Inc. | Alternative hypothesis error correction for gesture typing |
CN103701614B (en) * | 2014-01-15 | 2018-08-10 | 网易宝有限公司 | A kind of auth method and device |
US9319524B1 (en) * | 2014-04-28 | 2016-04-19 | West Corporation | Applying user preferences, behavioral patterns and/or environmental factors to an automated customer support application |
US10192205B2 (en) | 2014-05-30 | 2019-01-29 | Visa International Service Association | Method for providing a graphical user interface for an electronic transaction |
USD774056S1 (en) * | 2015-10-12 | 2016-12-13 | Yahoo! Inc. | Display screen with graphical user interface |
JP2018128829A (en) * | 2017-02-08 | 2018-08-16 | 富士ゼロックス株式会社 | Information processing apparatus and information processing program |
Citations (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5398310A (en) * | 1992-04-13 | 1995-03-14 | Apple Computer, Incorporated | Pointing gesture based computer note pad paging and scrolling interface |
US5477447A (en) * | 1992-05-27 | 1995-12-19 | Apple Computer, Incorporated | Method and apparatus for providing computer-implemented assistance |
US5544358A (en) * | 1992-10-02 | 1996-08-06 | Apple Computer, Inc. | Interface for a computerized database having card and list views |
US5588105A (en) * | 1992-11-16 | 1996-12-24 | Apple Computer, Inc. | Status bar for application windows |
US5621903A (en) * | 1992-05-27 | 1997-04-15 | Apple Computer, Inc. | Method and apparatus for deducing user intent and providing computer implemented services |
US5634100A (en) * | 1995-08-07 | 1997-05-27 | Apple Computer, Inc. | System and method for event parameter interdependence and adjustment with pen input |
US5666502A (en) * | 1995-08-07 | 1997-09-09 | Apple Computer, Inc. | Graphical user interface using historical lists with field classes |
US5745716A (en) * | 1995-08-07 | 1998-04-28 | Apple Computer, Inc. | Method and apparatus for tab access and tab cycling in a pen-based computer system |
US5774540A (en) * | 1995-11-15 | 1998-06-30 | Lucent Technologies Inc. | Hierarchical menu screen interface for displaying and accessing telephone terminal features |
US5805159A (en) * | 1996-08-22 | 1998-09-08 | International Business Machines Corporation | Mobile client computer interdependent display data fields |
US5864340A (en) * | 1996-08-22 | 1999-01-26 | International Business Machines Corporation | Mobile client computer programmed to predict input |
Family Cites Families (32)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5237651A (en) | 1987-08-21 | 1993-08-17 | Eden Group Limited | Electronic personal organizer |
DE68924196T2 (en) | 1988-06-03 | 1996-05-09 | Sharp Kk | Electronic arrangement with a calendar function. |
JP3178531B2 (en) * | 1988-11-15 | 2001-06-18 | 株式会社日立製作所 | Menu presentation method and data processing device |
US5199104A (en) | 1988-12-15 | 1993-03-30 | Sony Corporation | Electronic organizer with electronic book marker |
US5276794A (en) | 1990-09-25 | 1994-01-04 | Grid Systems Corporation | Pop-up keyboard system for entering handwritten data into computer generated forms |
US5570109A (en) | 1992-05-27 | 1996-10-29 | Apple Computer, Inc. | Schedule and to-do list for a pen-based computer system |
US5708840A (en) | 1992-06-29 | 1998-01-13 | Elonex I.P. Holdings, Ltd. | Micro personal digital assistant |
US5612719A (en) | 1992-12-03 | 1997-03-18 | Apple Computer, Inc. | Gesture sensitive buttons for graphical user interfaces |
US5345550A (en) | 1992-12-23 | 1994-09-06 | International Business Machines Corporation | User-modifiable popup menus for object oriented behavior |
US5465358A (en) | 1992-12-28 | 1995-11-07 | International Business Machines Corporation | System for enhancing user efficiency in initiating sequence of data processing system user inputs using calculated probability of user executing selected sequences of user inputs |
US5588107A (en) | 1993-03-22 | 1996-12-24 | Island Graphics Corporation | Method and apparatus for selectably expandable menus |
US5749070A (en) | 1993-09-09 | 1998-05-05 | Apple Computer, Inc. | Multi-representational data structure for recognition in computer systems |
US5760773A (en) | 1995-01-06 | 1998-06-02 | Microsoft Corporation | Methods and apparatus for interacting with data objects using action handles |
US5873108A (en) | 1995-02-27 | 1999-02-16 | Fuga Corporation | Personal information manager information entry allowing for intermingling of items belonging to different categories within a single unified view |
US5825353A (en) | 1995-04-18 | 1998-10-20 | Will; Craig Alexander | Control of miniature personal digital assistant using menu and thumbwheel |
US5664228A (en) | 1995-08-09 | 1997-09-02 | Microsoft Corporation | Portable information device and system and method for downloading executable instructions from a computer to the portable information device |
US6011546A (en) | 1995-11-01 | 2000-01-04 | International Business Machines Corporation | Programming structure for user interfaces |
US5917493A (en) | 1996-04-17 | 1999-06-29 | Hewlett-Packard Company | Method and apparatus for randomly generating information for subsequent correlating |
US5874954A (en) | 1996-04-23 | 1999-02-23 | Roku Technologies, L.L.C. | Centricity-based interface and method |
JPH09311861A (en) | 1996-05-21 | 1997-12-02 | Sharp Corp | Data processor |
US6049329A (en) | 1996-06-04 | 2000-04-11 | International Business Machines Corporartion | Method of and system for facilitating user input into a small GUI window using a stylus |
US5745116A (en) | 1996-09-09 | 1998-04-28 | Motorola, Inc. | Intuitive gesture-based graphical user interface |
US6052120A (en) | 1996-10-01 | 2000-04-18 | Diamond Multimedia Systems, Inc. | Method of operating a portable interactive graphics display tablet and communications systems |
GB2322513B (en) | 1997-02-21 | 2001-12-19 | Nokia Mobile Phones Ltd | A phone displaying alternative functionality menu |
JPH10240502A (en) | 1997-02-21 | 1998-09-11 | Internatl Intelligent Inf:Kk | System for transferring environment in information equipment |
US6112126A (en) | 1997-02-21 | 2000-08-29 | Baker Hughes Incorporated | Adaptive object-oriented optimization software system |
US6028604A (en) | 1997-08-27 | 2000-02-22 | Microsoft Corporation | User friendly remote system interface providing previews of applications |
US6037937A (en) | 1997-12-04 | 2000-03-14 | Nortel Networks Corporation | Navigation tool for graphical user interface |
US5978591A (en) * | 1998-02-24 | 1999-11-02 | Franklin Electronics Publishers, Inc. | Personal information device and method for downloading reprogramming data from a computer to the personal information device via the PCMCIA port or through a docking station with baud rate conversion means |
US6202209B1 (en) * | 1998-02-24 | 2001-03-13 | Xircom, Inc. | Personal information device and method for downloading reprogramming data from a computer to the personal information device via the PCMCIA port or through a docking station with baud rate conversion means |
US6034686A (en) | 1998-03-09 | 2000-03-07 | 3Com Corporation | Collapsing event display for small screen computer |
US6154750A (en) | 1998-04-01 | 2000-11-28 | Cyberpulse Llc | Method and system for navigation and data entry in heirarchically-organized database views |
-
1998
- 1998-11-04 US US09/186,732 patent/US6141011A/en not_active Expired - Lifetime
-
2000
- 2000-10-13 US US09/687,988 patent/US6310634B1/en not_active Expired - Lifetime
Patent Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5398310A (en) * | 1992-04-13 | 1995-03-14 | Apple Computer, Incorporated | Pointing gesture based computer note pad paging and scrolling interface |
US5477447A (en) * | 1992-05-27 | 1995-12-19 | Apple Computer, Incorporated | Method and apparatus for providing computer-implemented assistance |
US5621903A (en) * | 1992-05-27 | 1997-04-15 | Apple Computer, Inc. | Method and apparatus for deducing user intent and providing computer implemented services |
US5644735A (en) * | 1992-05-27 | 1997-07-01 | Apple Computer, Inc. | Method and apparatus for providing implicit computer-implemented assistance |
US5544358A (en) * | 1992-10-02 | 1996-08-06 | Apple Computer, Inc. | Interface for a computerized database having card and list views |
US5588105A (en) * | 1992-11-16 | 1996-12-24 | Apple Computer, Inc. | Status bar for application windows |
US5634100A (en) * | 1995-08-07 | 1997-05-27 | Apple Computer, Inc. | System and method for event parameter interdependence and adjustment with pen input |
US5666502A (en) * | 1995-08-07 | 1997-09-09 | Apple Computer, Inc. | Graphical user interface using historical lists with field classes |
US5745716A (en) * | 1995-08-07 | 1998-04-28 | Apple Computer, Inc. | Method and apparatus for tab access and tab cycling in a pen-based computer system |
US5774540A (en) * | 1995-11-15 | 1998-06-30 | Lucent Technologies Inc. | Hierarchical menu screen interface for displaying and accessing telephone terminal features |
US5805159A (en) * | 1996-08-22 | 1998-09-08 | International Business Machines Corporation | Mobile client computer interdependent display data fields |
US5864340A (en) * | 1996-08-22 | 1999-01-26 | International Business Machines Corporation | Mobile client computer programmed to predict input |
Cited By (109)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6570596B2 (en) | 1998-03-25 | 2003-05-27 | Nokia Mobile Phones Limited | Context sensitive pop-up window for a portable phone |
EP0994409A3 (en) * | 1998-10-12 | 2001-05-09 | Hewlett-Packard Company, A Delaware Corporation | Index tabs |
EP0994409A2 (en) * | 1998-10-12 | 2000-04-19 | Hewlett-Packard Company | Index tabs |
US6489976B1 (en) * | 1998-12-15 | 2002-12-03 | International Business Machines Corporation | System and method for displaying pop-up symbols for indicating accelerator keys for implementing computer software options |
US9183306B2 (en) | 1998-12-18 | 2015-11-10 | Microsoft Technology Licensing, Llc | Automated selection of appropriate information based on a computer user's context |
US9906474B2 (en) | 1998-12-18 | 2018-02-27 | Microsoft Technology Licensing, Llc | Automated selection of appropriate information based on a computer user's context |
US20090013052A1 (en) * | 1998-12-18 | 2009-01-08 | Microsoft Corporation | Automated selection of appropriate information based on a computer user's context |
US6459422B1 (en) * | 1998-12-22 | 2002-10-01 | Canon Kabushiki Kaisha | Graphical user interface for inputting data |
US7617240B2 (en) | 1999-05-04 | 2009-11-10 | Accenture Llp | Component based task handling during claim processing |
US8224859B2 (en) | 1999-05-04 | 2012-07-17 | Accenture Global Services Limited | Component based information linking during claim processing |
US20050149376A1 (en) * | 1999-05-04 | 2005-07-07 | Accenture Llp | Component based interface to handle tasks during claim processing |
US7979382B2 (en) | 1999-05-04 | 2011-07-12 | Accenture Global Services Limited | Component based information linking during claim processing |
US9400782B2 (en) | 1999-05-27 | 2016-07-26 | Nuance Communications, Inc. | Virtual keyboard system with automatic correction |
US9557916B2 (en) | 1999-05-27 | 2017-01-31 | Nuance Communications, Inc. | Keyboard system with automatic correction |
US8576167B2 (en) | 1999-05-27 | 2013-11-05 | Tegic Communications, Inc. | Directional input system with automatic correction |
US8679018B2 (en) | 1999-08-20 | 2014-03-25 | Zonare Medical Systems, Inc. | Broad-beam imaging |
US6733455B2 (en) | 1999-08-20 | 2004-05-11 | Zonare Medical Systems, Inc. | System and method for adaptive clutter filtering in ultrasound color flow imaging |
US20060100520A1 (en) * | 1999-08-20 | 2006-05-11 | Mo Larry Y L | Ultrasound system with iterative high pass filter selection |
US7022075B2 (en) | 1999-08-20 | 2006-04-04 | Zonare Medical Systems, Inc. | User interface for handheld imaging devices |
US20040138569A1 (en) * | 1999-08-20 | 2004-07-15 | Sorin Grunwald | User interface for handheld imaging devices |
US20040199078A1 (en) * | 1999-08-20 | 2004-10-07 | Mo Larry Y. L. | System and method for adaptive clutter filtering in ultrasound color flow imaging |
US20060116578A1 (en) * | 1999-08-20 | 2006-06-01 | Sorin Grunwald | User interface for handheld imaging devices |
US6997876B2 (en) | 1999-08-20 | 2006-02-14 | Zonare Medical Systems, Inc. | Ultrasound clutter filtering with iterative high pass filter selection |
US6738789B2 (en) | 2000-01-25 | 2004-05-18 | Fusionone, Inc. | Data package including synchronization data |
US6757696B2 (en) * | 2000-01-25 | 2004-06-29 | Fusionone, Inc. | Management server for synchronization system |
US8621025B2 (en) | 2000-01-25 | 2013-12-31 | Synchronoss Technologis, Inc. | Mobile data transfer and synchronization system |
US7035878B1 (en) | 2000-01-25 | 2006-04-25 | Fusionone, Inc. | Base rolling engine for data transfer and synchronization system |
US7007041B2 (en) | 2000-01-25 | 2006-02-28 | Fusionone, Inc. | Synchronization system application object interface |
US6671757B1 (en) | 2000-01-26 | 2003-12-30 | Fusionone, Inc. | Data transfer and synchronization system |
US7415486B2 (en) | 2000-01-26 | 2008-08-19 | Fusionone, Inc. | System using change log stored at a server to identify changes to user's application data for synchronizing data between systems |
US20050099963A1 (en) * | 2000-01-26 | 2005-05-12 | Multer David L. | Data transfer and synchronization system |
US8156074B1 (en) | 2000-01-26 | 2012-04-10 | Synchronoss Technologies, Inc. | Data transfer and synchronization system |
US20040054711A1 (en) * | 2000-01-26 | 2004-03-18 | Multer David L. | Data transfer and synchronization system |
US8442943B2 (en) | 2000-01-26 | 2013-05-14 | Synchronoss Technologies, Inc. | Data transfer and synchronization between mobile systems using change log |
US8315976B2 (en) | 2000-01-26 | 2012-11-20 | Synchronoss Technologies, Inc. | Data transfer and synchronization system |
US20070266334A1 (en) * | 2000-05-11 | 2007-11-15 | Palmsource, Inc. | Automatically centered scrolling in a tab-based user interface |
US7412660B2 (en) | 2000-05-11 | 2008-08-12 | Palmsource, Inc. | Automatically centered scrolling in a tab-based user interface |
US6944651B2 (en) | 2000-05-19 | 2005-09-13 | Fusionone, Inc. | Single click synchronization of data from a public information store to a private information store |
US20170075704A1 (en) * | 2000-06-21 | 2017-03-16 | Microsoft Technology Licensing, Llc | Task-Sensitive Methods and Systems for Displaying Command Sets |
US8073954B1 (en) | 2000-07-19 | 2011-12-06 | Synchronoss Technologies, Inc. | Method and apparatus for a secure remote access system |
US7895334B1 (en) | 2000-07-19 | 2011-02-22 | Fusionone, Inc. | Remote access communication architecture apparatus and method |
US6925476B1 (en) | 2000-08-17 | 2005-08-02 | Fusionone, Inc. | Updating application data including adding first change log to aggreagate change log comprising summary of changes |
US20030164844A1 (en) * | 2000-09-25 | 2003-09-04 | Kravitz Dean Todd | System and method for processing multimedia content, stored in a computer-accessible storage medium, based on various user-specified parameters related to the content |
US6683626B1 (en) * | 2000-10-04 | 2004-01-27 | Sun Microsystems, Inc. | Focus-based scrolling |
US7587446B1 (en) | 2000-11-10 | 2009-09-08 | Fusionone, Inc. | Acquisition and synchronization of digital media to a personal information space |
US7818435B1 (en) | 2000-12-14 | 2010-10-19 | Fusionone, Inc. | Reverse proxy mechanism for retrieving electronic content associated with a local network |
FR2818398A1 (en) * | 2000-12-20 | 2002-06-21 | Sagem | Capture of alphanumeric passwords from a television remote control reduced key keyboard, uses global dissimulation time stating from end of password capture |
EP1217503A1 (en) * | 2000-12-20 | 2002-06-26 | Sagem SA | Method for inputting alphanumeric passwords from a reduced key set |
US20020093492A1 (en) * | 2001-01-18 | 2002-07-18 | Baron John M. | System for a navigable display |
WO2002065330A1 (en) * | 2001-02-13 | 2002-08-22 | Justsystem Corporation | Learning from user modifications and revisions to text |
US8615566B1 (en) | 2001-03-23 | 2013-12-24 | Synchronoss Technologies, Inc. | Apparatus and method for operational support of remote network systems |
US8117034B2 (en) | 2001-03-29 | 2012-02-14 | Nuance Communications Austria Gmbh | Synchronise an audio cursor and a text cursor during editing |
US8706495B2 (en) | 2001-03-29 | 2014-04-22 | Nuance Communications, Inc. | Synchronise an audio cursor and a text cursor during editing |
US20020143544A1 (en) * | 2001-03-29 | 2002-10-03 | Koninklijke Philips Electronic N.V. | Synchronise an audio cursor and a text cursor during editing |
US8380509B2 (en) | 2001-03-29 | 2013-02-19 | Nuance Communications Austria Gmbh | Synchronise an audio cursor and a text cursor during editing |
US20020154159A1 (en) * | 2001-04-19 | 2002-10-24 | International Business Machines Corporation | Method, apparatus, and program for associating successive repointing of a browser's load function with navigational links in web pages |
EP1412907A1 (en) * | 2001-06-20 | 2004-04-28 | Capital One Financial Corporation | System and method for indetifying applications loaded in the smart card |
EP1412907A4 (en) * | 2001-06-20 | 2005-03-02 | Capital One Financial Corp | System and method for indetifying applications loaded in the smart card |
US9407707B2 (en) | 2001-07-16 | 2016-08-02 | Facebook, Inc. | Method and apparatus for demographic-based reminders |
US8108436B2 (en) * | 2001-07-16 | 2012-01-31 | Aol Inc. | Method and apparatus for calendaring reminders |
US20080215691A1 (en) * | 2001-07-16 | 2008-09-04 | Rupesh Chhatrapati | Method and apparatus for calendaring reminders |
US8126742B2 (en) | 2003-05-09 | 2012-02-28 | Accenture Global Services Limited | Automated assignment of insurable events |
US9615221B1 (en) | 2003-07-21 | 2017-04-04 | Synchronoss Technologies, Inc. | Device message management system |
US9723460B1 (en) | 2003-07-21 | 2017-08-01 | Synchronoss Technologies, Inc. | Device message management system |
US8645471B2 (en) | 2003-07-21 | 2014-02-04 | Synchronoss Technologies, Inc. | Device message management system |
US8620286B2 (en) | 2004-02-27 | 2013-12-31 | Synchronoss Technologies, Inc. | Method and system for promoting and transferring licensed content and applications |
US7643824B2 (en) | 2004-02-27 | 2010-01-05 | Cooligy Inc | Wireless telephone data backup system |
US9542076B1 (en) | 2004-05-12 | 2017-01-10 | Synchronoss Technologies, Inc. | System for and method of updating a personal profile |
US8611873B2 (en) | 2004-05-12 | 2013-12-17 | Synchronoss Technologies, Inc. | Advanced contact identification system |
US8504369B1 (en) | 2004-06-02 | 2013-08-06 | Nuance Communications, Inc. | Multi-cursor transcription editing |
US20060064649A1 (en) * | 2004-09-23 | 2006-03-23 | Microsoft Corporation | Systems and methods for navigation of a graphical user environment |
US8028248B1 (en) | 2004-12-03 | 2011-09-27 | Escription, Inc. | Transcription editing |
US9632992B2 (en) | 2004-12-03 | 2017-04-25 | Nuance Communications, Inc. | Transcription editing |
US7836412B1 (en) * | 2004-12-03 | 2010-11-16 | Escription, Inc. | Transcription editing |
US20060158436A1 (en) * | 2004-12-07 | 2006-07-20 | Jacques Lapointe | User interface with augmented searching characteristics |
US7907122B2 (en) | 2004-12-07 | 2011-03-15 | Zi Corporation Of Canada, Inc. | User interface with augmented searching characteristics |
US7680805B2 (en) * | 2004-12-30 | 2010-03-16 | Sap Ag | Synchronization method for an object oriented information system (IS) model |
US20060149790A1 (en) * | 2004-12-30 | 2006-07-06 | Gert Rusch | Synchronization method for an object oriented information system (IS) model |
WO2006125133A3 (en) * | 2005-05-19 | 2009-05-07 | Hillcrest Lab Inc | Global navigation objects in user interfaces |
WO2006125133A2 (en) * | 2005-05-19 | 2006-11-23 | Hillcrest Laboratories, Inc. | Global navigation objects in user interfaces |
US20060262116A1 (en) * | 2005-05-19 | 2006-11-23 | Hillcrest Laboratories, Inc. | Global navigation objects in user interfaces |
US8180668B2 (en) | 2005-11-01 | 2012-05-15 | Accenture Global Services Limited | Collaborative intelligent task processor for insurance claims |
US8401896B2 (en) | 2005-11-01 | 2013-03-19 | Accenture Global Services Limited | Automated task processor for insurance claims |
US7933786B2 (en) | 2005-11-01 | 2011-04-26 | Accenture Global Services Limited | Collaborative intelligent task processor for insurance claims |
US7685298B2 (en) | 2005-12-02 | 2010-03-23 | Citrix Systems, Inc. | Systems and methods for providing authentication credentials across application environments |
US9140572B2 (en) * | 2007-02-13 | 2015-09-22 | Harman Becker Automotive Systems Gmbh | Methods for controlling a navigation system |
US20080201662A1 (en) * | 2007-02-13 | 2008-08-21 | Harman Becker Automotive Systems Gmbh | Methods for controlling a navigation system |
US8181111B1 (en) | 2007-12-31 | 2012-05-15 | Synchronoss Technologies, Inc. | System and method for providing social context to digital activity |
US8515786B2 (en) | 2008-02-22 | 2013-08-20 | Accenture Global Services Gmbh | Rule generation system adapted for an insurance claim processing system |
US8478769B2 (en) | 2008-02-22 | 2013-07-02 | Accenture Global Services Limited | Conversational question generation system adapted for an insurance claim processing system |
US20160224539A1 (en) * | 2008-03-14 | 2016-08-04 | Sony Mobile Communications Inc. | Character input apparatus, character input assist method, and character input assist program |
US10311142B2 (en) * | 2008-03-14 | 2019-06-04 | Sony Corporation | Character input apparatus, character input assist method, and character input assist program |
US20100250321A1 (en) * | 2009-03-26 | 2010-09-30 | International Business Machines Corporation | Quorum management of appointment scheduling |
US8626552B2 (en) | 2009-03-26 | 2014-01-07 | International Business Machines Corporation | Quorum management of appointment scheduling |
US8255006B1 (en) | 2009-11-10 | 2012-08-28 | Fusionone, Inc. | Event dependent notification system and method |
US20120019995A1 (en) * | 2010-07-26 | 2012-01-26 | Hon Hai Precision Industry Co., Ltd. | Embedded system and method for adjusting content |
US20120046986A1 (en) * | 2010-08-18 | 2012-02-23 | Hannon Meaghan | Optimizing organization and display of scheduling classes |
US8401885B2 (en) * | 2010-08-18 | 2013-03-19 | Meaghan HANNON | System and method for automatically generating and populating a school calendar utilizing a predetermined class rotation scheduling pattern |
US8943428B2 (en) | 2010-11-01 | 2015-01-27 | Synchronoss Technologies, Inc. | System for and method of field mapping |
US20130055164A1 (en) * | 2011-08-24 | 2013-02-28 | Sony Ericsson Mobile Communications Ab | System and Method for Selecting Objects on a Touch-Sensitive Display of a Mobile Communications Device |
US20140040772A1 (en) * | 2011-12-12 | 2014-02-06 | Adobe Systems Incorporated | Highlighting graphical user interface components based on usage by other users |
USD743996S1 (en) * | 2014-01-09 | 2015-11-24 | Microsoft Corporation | Display screen with graphical user interface |
USD743995S1 (en) * | 2014-01-09 | 2015-11-24 | Microsoft Corporation | Display screen with graphical user interface |
US20160018308A1 (en) * | 2014-07-16 | 2016-01-21 | Mitutoyo Corporation | Hardness tester |
US20180101762A1 (en) * | 2015-12-10 | 2018-04-12 | Pablo Gutierrez | Graphical interfaced based intelligent automated assistant |
CN110858216A (en) * | 2018-08-13 | 2020-03-03 | 株式会社日立制作所 | Dialogue method, dialogue system, and storage medium |
CN112000877A (en) * | 2020-07-15 | 2020-11-27 | 北京搜狗科技发展有限公司 | Data processing method, device and medium |
USD1014552S1 (en) * | 2021-11-02 | 2024-02-13 | Abiomed, Inc. | Display panel or portion thereof with graphical user interface |
USD1017634S1 (en) * | 2021-11-02 | 2024-03-12 | Abiomed, Inc. | Display panel or portion thereof with graphical user interface |
Also Published As
Publication number | Publication date |
---|---|
US6310634B1 (en) | 2001-10-30 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6141011A (en) | User interface methodology supporting light data entry for microprocessor device having limited user input | |
US6232970B1 (en) | User interface methodology supporting light data entry for microprocessor device having limited user input | |
US6417874B2 (en) | User interface methodology for microprocessor device having limited user input | |
US5644735A (en) | Method and apparatus for providing implicit computer-implemented assistance | |
US5802516A (en) | Method of controlling an electronic book for a computer system | |
JP4361726B2 (en) | Control method to execute functions in diary watch | |
US5446882A (en) | Interface for a computerized database having card and list views | |
US5457476A (en) | Method for controlling a computerized organizer | |
US6957397B1 (en) | Navigating through a menu of a handheld computer using a keyboard | |
US5555369A (en) | Method of creating packages for a pointer-based computer system | |
JP5021030B2 (en) | Calendar events, notifications, and alert bars embedded in email | |
KR100425831B1 (en) | Method of stroing data in a personal information terminal | |
US20040142720A1 (en) | Graphical user interface features of a browser in a hand-held wireless communication device | |
US20040139435A1 (en) | Associating appointments and tasks on a computer device | |
US20070192742A1 (en) | Method and arrangment for a primary actions menu that defaults according to historical user activity on a handheld electronic device | |
EP0713187B1 (en) | Schedule-managing apparatus being capable of moving or copying a schedule of a date to another date | |
US20080163121A1 (en) | Method and arrangement for designating a menu item on a handheld electronic device | |
US20080163112A1 (en) | Designation of menu actions for applications on a handheld electronic device | |
JP2008545212A (en) | Keyboard accelerator | |
US20040075693A1 (en) | Compact method of navigating hierarchical menus on an electronic device having a small display screen | |
US7571384B1 (en) | Method and system for handwriting recognition with scrolling input history and in-place editing | |
US5870713A (en) | Information processor | |
JPH10154069A (en) | Application starter system based on input data | |
JPH0895926A (en) | Data storage device | |
US6714932B1 (en) | Display-equipped information terminal device having mailing function and electronic mail transmitting method |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: STARFISH SOFTWARE, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BODNAR, ERIC O.;LEE, JENNIFER J.;KAHN, PHILIPPE R.;AND OTHERS;REEL/FRAME:009793/0250;SIGNING DATES FROM 19990224 TO 19990225 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:STARFISH SOFTWARE, INC.;REEL/FRAME:014692/0621Effective date: 20030326 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282Effective date: 20120622 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:035354/0420Effective date: 20141028 |