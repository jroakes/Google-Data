Diese Anmeldung beansprucht die Priorität der am 30. März 2011 eingereichten US-Anmeldung mit der Serial Number 13/075,434, deren gesamter Inhalt hiermit durch Verweis einbezogen wird.This application claims priority to US Serial No. 13 / 075,434 filed Mar. 30, 2011, the entire contents of which are hereby incorporated by reference.
TECHNISCHES GEBIETTECHNICAL AREA
Die Offenbarung betrifft berührungsbasierte Benutzer-Interfaces.The disclosure relates to touch-based user interfaces.
HINTERGRUNDBACKGROUND
Elektronische Vorrichtungen wie z. B. Computer, Mobiltelefone, Personal Media Player (PMP), Spielkonsolen oder andere elektronische Vorrichtungen erfordern typischerweise ein Benutzer-Interface, um einem Benutzer die Interaktion mit den Vorrichtungen zu ermöglichen. Bei berührungsempfindlichen Bildschirmen (”Touch Screens”) handelt es sich um einen Typ von Benutzer-Interface, mittels dessen ein Benutzer mit der Vorrichtung interagieren kann, indem er physisch mit der Vorrichtung in Kontakt tritt. Gemäß einem Beispiel kann ein Benutzer den Bildschirm einer mobilen Vorrichtung berühren, um die Ausführung einer in der mobilen Vorrichtung gespeicherten Anwendung zu initiieren. Zu den Techniken, die bei diesen Vorrichtungen verwendet werden, um die Stelle einer Berührung zu detektieren, zählen mechanische Tasten, einander schneidende Infrarotlichtstrahlen, akustische Oberflächenwellen, und kapazitive Sensor- und Widerstandssensor-Techniken.Electronic devices such. As computers, mobile phones, personal media players (PMP), game consoles or other electronic devices typically require a user interface to allow a user to interact with the devices. Touch-screens are a type of user interface by which a user can interact with the device by physically contacting the device. According to one example, a user may touch the screen of a mobile device to initiate the execution of an application stored in the mobile device. Among the techniques used in these devices to detect the location of a touch are mechanical keys, intersecting infrared beams, surface acoustic wave, and capacitive sensor and resistive sensor techniques.
Bestimmte Touch Screens können dahingehend konzipiert sein, dass sie Berührungen an mehr als einem Punkt auf dem Bildschirm erkennen, wobei dieses Feature üblicherweise als ”Multi-Touch” bezeichnet wird. Bei Multi-Touch-Bildschirmen werden Berührungen, die in verschiedenen Bereichen des Bildschirms erfolgen, separat identifiziert und interpretiert. Das gleichzeitige Berühren eines Multi-Touch-Bildschirms an mehr als einer Stelle kann einem Benutzer zusätzliche Möglichkeiten der Interaktion mit der Vorrichtung bieten (z. B. im Vergleich zu einer einzelnen Berührung).Certain touch screens may be designed to detect touches at more than one point on the screen, which feature is commonly referred to as "multi-touch." For multi-touch screens, touches that occur in different areas of the screen are identified and interpreted separately. Simultaneously touching a multi-touch screen in more than one location may provide a user with additional options for interacting with the device (eg, as compared to a single touch).
ÜBERBLICKOVERVIEW
Generell betreffen Aspekte der Offenbarung Techniken zum Stützen der Interaktion zwischen einem Benutzer und einer Vorrichtung mit einem berührungsempfindlichen Bildschirm (”Touch Screen”). Gemäß einigen Beispielen betreffen Aspekte der Offenbarung das Bereitstellen eines Interaktionsmodus vom ”Hover”- oder ”Hovering”-Stil für eine Vorrichtung mit Touch Screen. Beispielsweise kann ein Hover-Modus einem Benutzer ermöglichen, mit einem auf der Vorrichtung angezeigten Benutzer-Interface-(UI-)Element zu interagieren, ohne das UI-Element zu aktivieren. Zu den Beispielen von Hover-Funktionen zählen ein Highlighting oder anderweitiges Verändern von Text auf dem UI-Element, um einem Benutzer mitzuteilen, dass das Element betätigt werden kann, das Initialisieren eines Preview-Fensters, das dem UI-Element zugehörigen Inhalt enthält, und das Initialisieren von neuem Inhalt wie z. B. eines anzuzeigenden ”Tool-Tip”-Fensters.Generally, aspects of the disclosure relate to techniques for supporting interaction between a user and a touch screen device. According to some examples, aspects of the disclosure relate to providing a "hover" or "hovering" style of interaction mode for a touch screen device. For example, a hover mode may allow a user to interact with a user interface (UI) item displayed on the device without activating the UI element. Examples of hover functions include highlighting or otherwise altering text on the UI element to notify a user that the element can be operated, initialize a preview window containing content associated with the UI element, and initializing new content such as: For example, a tool tip window to be displayed.
Gemäß einem Beispiel betreffen Aspekte der Offenbarung ein Verfahren, das ein mittels einer Computervorrichtung durchgeführtes Detektieren einer ersten Benutzer-Eingabe umfasst, die eine erste Geste zum Interagieren mit einem berührungsempfindlichen Bildschirm der Computervorrichtung aufweist. Das Verfahren umfasst ferner ein mittels einer Computervorrichtung durchgeführtes Detektieren einer zweiten Benutzer-Eingabe, die eine zweite Geste zum Interagieren mit dem berührungsempfindlichen Bildschirm der Computervorrichtung aufweist, wobei sich die zweite Benutzer-Eingabe von der ersten Benutzer-Eingabe unterscheidet. Das Verfahren umfasst ferner, dass als Reaktion auf das Detektieren der ersten Benutzer-Eingabe ein Hover-Interaktionsmodus in einem graphischen Benutzer-Interface initiiert wird, das von dem berührungsempfindlichen Bildschirm der Computervorrichtung angezeigt wird, wobei der Hover-Interaktionsmodus einem Benutzer ermöglicht, mittels der zweiten Benutzer-Eingabe eine graphische Interaktion mit mindestens einem Benutzer-Interface-Element in dem graphischen Benutzer-Interface zu initiieren, wobei die graphische Interaktion das Bereitstellen dem mindestens einen Benutzer-Interface-Element zugeordneter graphischer Information umfasst, ohne dass das mindestens eine Benutzer-Interface-Element in dem graphischen Benutzer-Interface aktiviert wird.In one example, aspects of the disclosure relate to a method that includes detecting, by a computing device, a first user input having a first gesture for interacting with a touch-sensitive screen of the computing device. The method further comprises detecting, by a computing device, a second user input having a second gesture for interacting with the touch-sensitive screen of the computing device, the second user input being different than the first user input. The method further comprises, in response to detecting the first user input, initiating a hover interaction mode in a graphical user interface displayed by the touch-sensitive screen of the computing device, wherein the hover interaction mode allows a user to initiate a graphical interaction with at least one user interface element in the graphical user interface via the second user input, wherein the graphical interaction comprises providing the one associated with the at least one user interface element graphical information without activating the at least one user interface element in the graphical user interface.
Gemäß einem weiteren Beispiel betreffen Aspekte der Offenbarung ein computerlesbares Speichermedium, das mit Instruktionen kodiert ist, um einen oder mehrere programmierbare Prozessoren einer Computervorrichtung zu veranlassen, Operationen durchzuführen, zu denen das mittels einer Computervorrichtung vorgenommene Detektieren einer ersten Benutzer-Eingabe zählt, die eine erste Geste zum Interagieren mit einem berührungsempfindlichen Bildschirm der Rechenvorrichtung aufweist. Zu den Operationen zählen ferner das mittels einer Computervorrichtung vorgenommene Detektieren einer zweiten Benutzer-Eingabe, die eine zweite Geste zum Interagieren mit dem berührungsempfindlichen Bildschirm der Rechenvorrichtung aufweist, wobei sich die zweite Benutzer-Eingabe von der ersten Benutzer-Eingabe unterscheidet. Die Operationen umfassen ferner, dass als Reaktion auf das Detektieren der ersten Benutzer-Eingabe ein Hover-Interaktionsmodus in einem graphischen Benutzer-Interface initiiert wird, das von dem berührungsempfindlichen Bildschirm der Computervorrichtung angezeigt wird, wobei der Hover-Interaktionsmodus einem Benutzer ermöglicht, mittels der zweiten Benutzer-Eingabe eine graphische Interaktion mit mindestens einem Benutzer-Interface-Element in dem graphischen Benutzer-Interface zu initiieren, wobei die graphische Interaktion das Bereitstellen dem mindestens einen Benutzer-Interface-Element zugeordneter graphischer Information umfasst, ohne dass das mindestens eine Benutzer-Interface-Element in dem graphischen Benutzer-Interface aktiviert wird.In another example, aspects of the disclosure relate to a computer-readable storage medium encoded with instructions to cause one or more programmable processors of a computing device to perform operations involving the first user input being detected by a computing device to detect a first user input Gesture for interacting with a touch-sensitive screen of the computing device. The operations further include detecting, by a computing device, a second user input having a second gesture for interacting with the touch-sensitive screen of the computing device, the second user input being different than the first user input. The operations further include, in response to detecting the first user input, initiating a hover interaction mode in a graphical user interface displayed by the touch-sensitive screen of the computing device, wherein the hover interaction mode enables a user to use the second user input to initiate a graphical interaction with at least one user interface element in the graphical user interface, wherein the graphical interaction comprises providing the graphical information associated with the at least one user interface element without the at least one user interface Interface element in the graphical user interface is activated.
Gemäß einem weiteren Beispiel betreffen Aspekte der Offenbarung eine Computervorrichtung, die einen oder mehrere Prozessoren und ein Benutzer-Interface mit einem berührungsempfindlichen Bildschirm aufweist. Die Computervorrichtung enthält ferner eine Vorrichtung zum Detektieren einer ersten Benutzer-Eingabe und einer zweiten Benutzer-Eingabe, die sich von der ersten Benutzer-Eingabe unterscheidet, wobei die erste Benutzer-Eingabe eine erste Geste zum Interagieren mit dem berührungsempfindlichen Bildschirm aufweist und wobei die zweite Benutzer-Eingabe eine zweite Geste zum Interagieren mit dem berührungsempfindlichen Bildschirm aufweist. Der eine oder die mehreren Prozessoren sind ferner dahingehend konfiguriert, dass sie als Reaktion auf das Detektieren der ersten Benutzer-Eingabe einen Hover-Interaktionsmodus in einem graphischen Benutzer-Interface initiieren, der von dem berührungsempfindlichen Bildschirm der Computervorrichtung angezeigt wird, wobei der Hover-Interaktionsmodus einem Benutzer ermöglicht, mittels der zweiten Benutzer-Eingabe eine Benutzer-Interaktion mit mindestens einem Benutzer-Interface-Element in dem graphischen Benutzer-Interface zu initiieren, wobei die graphische Interaktion das Bereitstellen dem mindestens einen Benutzer-Interface-Element zugeordneter graphischer Information umfasst, ohne dass das mindestens eine Benutzer-Interface-Element in dem graphischen Benutzer-Interface aktiviert wird.In another example, aspects of the disclosure relate to a computing device having one or more processors and a user interface with a touch-sensitive screen. The computing device further includes means for detecting a first user input and a second user input that is different from the first user input, wherein the first user input has a first gesture for interacting with the touch-sensitive screen, and wherein the second User input has a second gesture for interacting with the touch-sensitive screen. The one or more processors are further configured to initiate a hover interaction mode in a graphical user interface displayed by the touch-sensitive screen of the computing device in response to detecting the first user input, wherein the hover interaction mode enabling a user to initiate user interaction with at least one user interface element in the graphical user interface via the second user input, wherein the graphical interaction comprises providing graphical information associated with the at least one user interface element, without activating the at least one user interface element in the graphical user interface.
Die Details eines oder mehrerer Aspekte der Offenbarung sind in den beigefügten Zeichnungen und in der folgenden Beschreibung aufgeführt. Weitere Merkmale, Aufgaben und Vorteile der Offenbarung werden aus der Beschreibung und den Zeichnungen und aus den Ansprüchen ersichtlich.The details of one or more aspects of the disclosure are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the disclosure will be apparent from the description and drawings, and from the claims.
KURZBESCHREIBUNG DER ZEICHNUNGENBRIEF DESCRIPTION OF THE DRAWINGS
1 zeigt ein Schaubild eines Beispiels eines graphischen Benutzer-Interface, das ein Benutzer-Interface-Element mit zugeordnetem Hover-Inhalt aufweist, gemäß einem oder mehreren Aspekten der vorliegenden Offenbarung. 1 FIG. 12 is a diagram of an example of a graphical user interface having a user interface element with associated hover content, in accordance with one or more aspects of the present disclosure.
2 zeigt ein Schaubild eines weiteren Beispiels eines Benutzer-Interface, das ein weiteres Benutzer-Interface-Element mit zugeordnetem Hover-Inhalt aufweist, gemäß einem oder mehreren Aspekten der vorliegenden Offenbarung. 2 FIG. 12 is a diagram of another example of a user interface having another user interface element with associated hover content, in accordance with one or more aspects of the present disclosure.
3A zeigt ein Schaubild eines Beispiels eines Benutzer-Interface einer Computervorrichtung, die einen Touch Screen mit einem bezeichneten Bereich zum Empfang einer Benutzer-Eingabe aufweist, welche einen ”Hover”-Interaktionsmodus initiiert, gemäß einem oder mehreren Aspekten der vorliegenden Offenbarung. 3A FIG. 12 is a diagram of an example of a user interface of a computing device having a touch screen with a designated area for receiving a user input that initiates a "hover" interaction mode, in accordance with one or more aspects of the present disclosure.
3B zeigt ein Schaubild der Benutzer-Interface- und Computervorrichtung gemäß 3A, die um 90 Grad gedreht ist, gemäß einem oder mehreren Aspekten der vorliegenden Offenbarung. 3B FIG. 12 is a diagram of the user interface and computing device according to FIG 3A rotated 90 degrees, in accordance with one or more aspects of the present disclosure.
4 zeigt ein Schaubild eines Beispiels einer Computervorrichtung, die zum Empfang einer Benutzer-Eingabe zum Initiieren eines ”Hover”-Interaktionsmodus konfiguriert sein kann, gemäß einem oder mehreren Aspekten der vorliegenden Offenbarung. 4 FIG. 12 is a diagram of an example of a computing device that may be configured to receive a user input to initiate a "hover" interaction mode, in accordance with one or more aspects of the present disclosure.
5 zeigt ein Flussdiagramm eines Beispiels eines Verfahrens zum Bereitstellen einer Hover-Funktionalität in einer Vorrichtung mit einem Touch Screen, gemäß einem oder mehreren Aspekten der vorliegenden Offenbarung. 5 FIG. 12 shows a flowchart of an example of a method for providing hover functionality in a device having a touch screen, in accordance with one or more aspects of the present disclosure.
DETAILLIERTE BESCHREIBUNGDETAILED DESCRIPTION
Generell betreffen Aspekte der Offenbarung Techniken zum Stützen der Interaktion zwischen einem Benutzer und einer Vorrichtung mit einem berührungsempfindlichen Bildschirm (”Touch Screen”). Entsprechend einigen Beispielen betreffen Aspekte der Offenbarung das Vorsehen eines gemäß dem ”Mouse-Over”- oder ”Hovering”-Stil praktizierten Interaktions-Modus für eine Vorrichtung mit einem Touch Screen. Ein ”Hover”-Interaktionsmodus ist normalerweise in berührungslosen Desktop-Computer-Plattformen verfügbar. Beispielsweise kann ein ”Hover”-Modus initiiert werden, wenn ein Benutzer einen Maus-Cursor über ein interaktives Benutzer-Interface-(UI-)Element (z. B. einen Taster, Hypertext etc.) bewegt, ohne das UI-Element zu betätigen. Die Präsenz des Cursors in der Umgebung des UI-Elements triggert ein UI-Ereignis, das zusätzliche Information über das UI-Element liefert, ohne das UI-Element zu aktivieren. In der hier vorliegenden Verwendung betreffen die Ausdrücke ”Hover-Funktion” und ”Hover-Inhalt” generell einen interaktiven Aspekt eines UI-Elements und können austauschbar verwendet werden. Zu den Beispielen von Hover-Funktionen zählen ein visuelles Highlighting oder anderweitiges Verändern des Texts des UI-Elements, um einem Benutzer mitzuteilen, dass das Element betätigt werden kann, das Initialisieren eines Preview-Fensters, das dem UI-Element zugehörigen Inhalt enthält, oder das Initialisieren eines neuen Inhalts, wie z. B. eines anzuzeigenden ”Tool-Tip”-Fensters.Generally, aspects of the disclosure relate to techniques for supporting interaction between a user and a touch screen device. According to some examples, aspects of the disclosure relate to providing an interaction mode for a device with a touch screen practiced according to the "mouse-over" or "hovering" style. A hover interaction mode is typically available in non-contact desktop computer platforms. For example, a "hover" mode may be initiated when a user moves a mouse cursor over an interactive user interface (UI) element (eg, a button, hypertext, etc.) without the UI element actuate. The presence of the cursor in the environment of the UI element triggers a UI event that provides additional information about the UI element without activating the UI element. As used herein, the terms "hover function" and "hover content" generally refer to an interactive aspect of a UI element and may be used interchangeably. Examples of hover functions include visually highlighting or otherwise altering the text of the UI element to notify a user that the element can be actuated, initialize a preview window containing content associated with the UI element, or initializing a new content, such as For example, a tool tip window to be displayed.
Konventionell wird ein auf Berührung durch den Benutzer basierender Kontakt mit einem Touch Screen typischerweise als Touch-down- oder Tap-Ereignis (d. h. äquivalent zum Betätigen oder ”Klicken” einer Maustaste an herkömmlichen Personal Computern oder PCs) oder als ein Scroll-Ereignis interpretiert (d. h. äquivalent zur Benutzung eines Scroll-Rads einer Maus zum Scrollen durch Inhalte bei herkömmlichen PCs). Gemäß einem oder mehreren Aspekten der Offenbarung ist ein UI derart konfiguriert, dass es eine erste Benutzer-Eingabe erkennt, wie z. B. eine Berührung an einer vorbestimmten Stelle eines Touch-Screen-UIs. Die erste Eingabe wird verwendet, um ein auf der Touch-Screen-Anzeige wiedergegebenes Bild in Position zu halten oder zu ”fixieren”. Die erste Eingabe kann auch verwendet werden, um Touch-down-/Tap-Ereignisse zu deaktivieren. Das UI ist ferner zum Erkennen einer zweiten Benutzer-Eingabe konfiguriert, wie z. B. einer zweiten Berührung, die unabhängig von der ersten Berührung ist. Die zweite Benutzer-Eingabe kann zum Implementieren einer ”Hover”-Interaktions-Modus-Funktion verwendet werden. Beispielsweise triggert die zweite Benutzer-Eingabe eine Interaktion mit einem UI-Element, ohne die Funktion des UI-Elements zu wählen oder zu initiieren. Gemäß einigen Beispielen ist die erste Benutzer-Eingabe eine kontinuierliche Benutzer-Eingabe, während derer der Benutzer den Kontakt mit dem Touch Screen aufrechterhält, während er die zweite Benutzer-Eingabe abschließt. Conventionally, touch-based contact with a touch screen is typically interpreted as a touchdown or tap event (ie, equivalent to pressing or "clicking" a mouse button on conventional personal computers or personal computers) or as a scrolling event ( ie equivalent to using a scroll wheel of a mouse to scroll through content on conventional PCs). In one or more aspects of the disclosure, a UI is configured to recognize a first user input, such as a user input. B. a touch at a predetermined location of a touch-screen UI. The first input is used to position or "lock" an image displayed on the touch screen display. The first input can also be used to disable touchdown / tap events. The UI is further configured to recognize a second user input, such as a user input. B. a second touch, which is independent of the first touch. The second user input may be used to implement a "hover" interaction mode function. For example, the second user input triggers an interaction with a UI element without selecting or initiating the function of the UI element. According to some examples, the first user input is a continuous user input during which the user maintains contact with the touch screen while completing the second user input.
Gemäß einigen Aspekten der Offenbarung kann die erste Benutzer-Eingabe an einer spezifischen, vorbestimmten Stelle des Touch Screen erkannt werden. Bei der vorbestimmten Stelle kann es sich, ohne darauf beschränkt zu sein, um einen Bereich in der unteren linken Ecke oder der unteren rechten Ecke des Touch Screen handeln. Mit der ersten Benutzer-Eingabe kann ein Modus der Interaktion mit dem UI derart geschaltet werden, dass die zweite Benutzer-Eingabe bei dem UI als eine ”Hover”-Interaktion statt als Scroll- oder Tap-Interaktion registriert wird. Gemäß einigen Beispielen wird dem Benutzer mitgeteilt, dass der Interaktions-Modus geändert worden ist (z. B. kann ein traditioneller Maus-Cursor vom Pfeil-Typ auf dem Bildschirm angezeigt werden). Ferner kann das der zweiten Benutzer-Eingabe zugeordnete Hover-Ereignis auf dem UI um einem Abstand von der physischen Stelle der zweiten Geste versetzt werden. Beispielsweise kann das Hover-Ereignis (z. B. ein Preview-Fenster oder ein anderer Hover-Inhalt) um einen bestimmten Abstand oberhalb, unterhalb oder seitlich der physischen Stelle der zweiten Benutzer-Eingabe präsentiert werden. Das UI kann auch die Fähigkeit haben, das Hover-Ereignis auf das wahrnehmungsmäßig nächstgelegene UI-Element zu ”herüberschnellen” zu lassen.In accordance with some aspects of the disclosure, the first user input may be recognized at a specific, predetermined location of the touch screen. The predetermined location may be, but is not limited to, an area in the lower left corner or the lower right corner of the touch screen. With the first user input, a mode of interaction with the UI may be switched such that the second user input is registered with the UI as a "hover" interaction rather than a scroll or tap interaction. According to some examples, the user is notified that the interaction mode has been changed (eg, a traditional arrow-type mouse cursor may be displayed on the screen). Further, the hover event associated with the second user input may be offset on the UI by a distance from the physical location of the second gesture. For example, the hover event (eg, a preview window or other hover content) may be presented a certain distance above, below, or to the side of the physical location of the second user input. The UI may also have the ability to "skip" the hover event to the perceptually closest UI element.
Die erste Benutzer-Eingabe kann verwendet werden, um ein vom Benutzer getätigtes ”Fixieren” oder Festhalten einer beweglichen Web-Seite zu emulieren, so dass die zweite Benutzer-Eingabe den Inhalt der Web-Seite nicht verändert oder bewegt. Auf diese Weise hat der Benutzer die Freiheit, die UI-Elemente auf einer Web-Seite zu prüfen, ohne den Inhalt der unterliegenden Web-Seite zu ändern. Die Stelle der ersten Benutzer-Eingabe kann gemäß ergonomischen Erwägungen gewählt werden. Beispielsweise kann ein Daumen eines Benutzers natürlicherweise in der unteren linken oder unteren rechten Ecke eines Touch Screens positioniert werden, etwa beim Halten einer Mobilvorrichtung wie z. B. eines Mobiltelefons, eines Tablet-Computers oder einer anderen tragbaren Computervorrichtung. Es können jedoch auch andere Stellen auf dem Bildschirm für die erste Benutzer-Eingabe bezeichnet sein. Gemäß einigen Beispielen kann sich die für die erste Benutzer-Eingabe bezeichnete Stelle entsprechend der physischen Ausrichtung der Vorrichtung ändern.The first user input may be used to emulate a user-initiated "fix" or capture of a mobile web page such that the second user input does not alter or move the content of the web page. In this way, the user has the freedom to check the UI elements on a web page without changing the content of the underlying web page. The location of the first user input may be selected according to ergonomic considerations. For example, a user's thumb may be naturally positioned in the lower left or lower right corner of a touch screen, such as when holding a mobile device, such as a mobile device. A mobile phone, a tablet computer or other portable computing device. However, other locations on the screen may be designated for the first user input. According to some examples, the location designated for the first user input may change according to the physical orientation of the device.
Dementsprechend betreffen Aspekte der Erfindung generell eine gestenmäßige Interaktion, die eine erste Benutzer-Eingabe an einer bekannten Stelle enthält, mittels derer bewirkt wird, dass eine zweite Benutzer-Eingabe als ”Hover” oder ”Hover”-Ereignis interpretiert wird. Die Stelle und die Heuristik der ersten Benutzer-Eingabe können auf ergonomischen Erwägungen oder normalen Verwendungsmustern basieren. Ferner kann die erste Benutzer-Eingabe bei Präsenz anderer Multi-Touch-Interaktionen detektiert werden (wie z. B. einer ”Pinch-to-Zoom”-Geste.Accordingly, aspects of the invention generally relate to a gestural interaction that includes a first user input at a known location that causes a second user input to be interpreted as a "hover" or "hover" event. The location and heuristics of the first user input may be based on ergonomic considerations or normal usage patterns. Further, the first user input may be detected in the presence of other multi-touch interactions (such as a pinch-to-zoom gesture).
Bestimmte Aspekte der Offenbarung betreffen eine ”erste” Benutzer-Eingabe an einer bekannten Stelle eines UI, die einen Interaktionsmodus initiiert, der eine Interpretation einer ”zweiten” Benutzer-Eingabe als ”Hover”-Ereignis ermöglicht. Es sollte sich jedoch verstehen, dass Aspekte der Offenbarung generell die Aktivierung eines Interaktionsmodus in einem UI betreffen, die einem Benutzer ermöglichen, über zwei distinkte Benutzer-Eingaben eine Interaktion mit einem UI-Element zu triggern, ohne die Funktion des UI-Elements zu wählen oder zu aktivieren. Der Benutzer kann die distinkten Benutzer-Eingaben in jeder Reihenfolge vornehmen. Beispielsweise kann der Benutzer eine Benutzer-Eingabe vornehmen, um den Interaktionsmodus zu aktivieren, und eine Benutzer-Eingabe vornehmen, um in irgendeiner Reihenfolge mit einem UI-Element zu interagieren. Ferner kann die Reihenfolge, in welcher der Benutzer die Benutzer-Eingabe vornimmt, die Interaktion des Benutzers mit der Rechenvorrichtung beeinflussen.Certain aspects of the disclosure relate to a "first" user input at a known location of a UI that initiates an interaction mode that allows interpretation of a "second" user input as a "hover" event. It should be understood, however, that aspects of the disclosure generally pertain to enabling an interaction mode in a UI that allows a user to interact with a UI element via two distinct user inputs without choosing the function of the UI element or activate. The user can make the distinct user inputs in any order. For example, the user may make a user input to activate the interaction mode and make a user input to interact with a UI element in any order. Further, the order in which the user makes the user input may affect the interaction of the user with the computing device.
Beispielsweise betreffen Aspekte der Offenbarung mindestens vier nichteinschränkende Beispiele für Interaktionen zwischen einem Benutzer und einer Rechenvorrichtung, bei denen der Benutzer ”erste” und ”zweite” Benutzer-Eingaben in Form eines aufrechterhaltenen Kontakts mit einem Touch-Screen-UI vornimmt. Gemäß einem ersten Beispiel kann ein Benutzer eine erste Benutzer-Eingabe auf dem UI vornehmen, um mit einem UI-Element zu interagieren. Der Benutzer kann ferner an einer vorbestimmten Stelle des UI eine zweite Eingabe vornehmen, die einen ”Hover”-Interaktionsmodus initiiert. Das Initiieren des ”Hover”-Interaktionsmodus mittels der zweiten Benutzer-Eingabe ermöglicht dem Benutzer, das UI zu fixieren und mit einem UI-Element zu interagieren oder dieses zu erforschen, ohne die Funktion des UI-Elements zu wählen oder zu initiieren. Der Benutzer kann dann die erste Benutzer-Eingabe aufheben (z. B. den Kontakt mit dem UI unterbrechen) und die zweite Benutzer-Eingabe aufheben.For example, aspects of the disclosure pertain to at least four non-limiting examples of interactions between a user and a computing device in which the user makes "first" and "second" user inputs in the form of maintained contact with a touch-screen UI. According to a first example, a user may make a first user input on the UI to interact with a UI element. The user may also make a second entry at a predetermined location of the UI that initiates a "hover" interaction mode. Initiating the "hover" interaction mode via the second user input allows the user to lock the UI and interact with or explore a UI element without choosing or initiating the function of the UI element. The user may then cancel the first user input (eg, break contact with the UI) and override the second user input.
Gemäß einem zweiten Beispiel kann der Benutzer eine erste Benutzer-Eingabe an dem UI vornehmen, um mit einem UI-Element zu interagieren. Der Benutzer kann ferner an einer vorbestimmten Stelle eines UI eine zweite Benutzer-Eingabe vornehmen, die einen ”Hover”-Interaktionsmodus initiiert. Das Initiieren des ”Hover”-Interaktionsmodus mittels der zweiten Benutzer-Eingabe ermöglicht dem Benutzer, das UI zu fixieren und mit einem UI-Element zu interagieren oder dieses zu erforschen, ohne die Funktion des UI-Elements zu wählen oder zu initiieren. Der Benutzer kann dann die zweite Benutzer-Eingabe aufheben. Nach dem Aufheben der zweiten Benutzer-Eingabe kann das UI das der ersten Benutzer-Eingabe zugeordnete UI-Element ”aktivieren”. Beispielsweise kann sich das ”Aktivieren” eines UI-Elements auf das Wählen des Elements mittels eines ”Mouse-down-Ereignisses” (z. B. typischerweise einhergehend mit dem Klicken einer Maustaste bei einem herkömmlichen PC) dahingehend beziehen, dass der einem Mouse-down-Ereignis zugeordnete Inhalt getriggert wird. Nach dem Aktivieren des UI-Elements kann der Benutzer dann die erste Benutzer-Eingabe aufheben.According to a second example, the user may make a first user input to the UI to interact with a UI element. The user may also make a second user input at a predetermined location of a UI that initiates a "hover" interaction mode. Initiating the "hover" interaction mode via the second user input allows the user to lock the UI and interact with or explore a UI element without choosing or initiating the function of the UI element. The user can then cancel the second user input. After canceling the second user input, the UI may "activate" the UI element associated with the first user input. For example, "activating" a UI element may refer to selecting the element by means of a "mouse-down event" (eg, typically associated with the click of a mouse button on a conventional PC) such that the mouse button content associated with down event is triggered. After activating the UI element, the user can then cancel the first user input.
Gemäß einem dritten Beispiel kann ein Benutzer an einer vorbestimmten Stelle des UI eine erste Benutzer-Eingabe vornehmen, um einen ”Hover”-Interaktionsmodus zu aktivieren und das UI zu fixieren. Der Benutzer kann dann eine zweite Benutzer-Eingabe an einem UI-Element vornehmen, um mit einem UI-Element zu interagieren oder dieses zu erforschen, ohne die Funktion des UI-Elements zu wählen oder zu aktivieren. Der Benutzer kann dann die zweite Benutzer-Eingabe aufheben, um die Interaktion mit dem UI-Element zu stoppen, und er kann die erste Benutzer-Eingabe aufgeben, um den ”Hover”-Interaktionsmodus zu deaktivieren.According to a third example, a user may make a first user input at a predetermined location of the UI to activate a "hover" interaction mode and to fix the UI. The user may then make a second user input to a UI element to interact with or explore a UI element without selecting or activating the function of the UI element. The user may then override the second user input to stop interacting with the UI element and may abandon the first user input to disable the "hover" interaction mode.
Gemäß einem vierten Beispiel kann ein Benutzer an einer vorbestimmten Stelle des UI eine erste Benutzer-Eingabe vornehmen, um einen ”Hover”-Interaktionsmodus zu aktivieren und das UI zu fixieren. Der Benutzer kann dann eine zweite Benutzer-Eingabe an einem UI-Element vornehmen, um mit einem UI-Element zu interagieren oder dieses zu erforschen, ohne die Funktion des UI-Elements zu wählen oder zu aktivieren. Der Benutzer kann dann die erste Benutzer-Eingabe aufheben, um den ”Hover”-Interaktionsmodus zu deaktivieren. Nach dem Aufheben der ersten Benutzer-Eingabe und dem Deaktivieren des ”Hover”-Interaktionsmodus kann das UI das der zweiten Benutzer-Eingabe zugeordnete UI-Element derart ”aktivieren”, dass der dem Mouse-down-Ereignis zugeordnete Inhalt getriggert wird. Der Benutzer kann dann die zweite Benutzer-Eingabe aufheben.According to a fourth example, a user may make a first user input at a predetermined location of the UI to activate a "hover" interaction mode and to fix the UI. The user may then make a second user input to a UI element to interact with or explore a UI element without selecting or activating the function of the UI element. The user may then override the first user input to disable the "hover" interaction mode. After clearing the first user input and disabling the "hover" interaction mode, the UI may "activate" the UI element associated with the second user input such that the content associated with the mouse-down event is triggered. The user can then cancel the second user input.
1 zeigt ein Schaubild eines Beispiels eines graphischen Benutzer-Interface (UI) 20 mit einem UI-Element 24, das einen zugehörigen Hover-Inhalt 28 enthält. Gemäß einigen Aspekten der Offenbarung kann das UI 20 auf einer Anzeigevorrichtung 32 einer Computervorrichtung 36 angezeigt werden, die eine Benutzer-Eingabevorrichtung 40 aufweist Obwohl in 1 das UI 20 im Sinne eines Beispiels als mit einer Webseite verbundene Suchmaschine gezeigt ist, können auf der Anzeigevorrichtung 32 auch andere UIs 20 mit einer Vielfalt anderer UI-Elemente angezeigt werden. 1 shows a diagram of an example of a graphical user interface (UI) 20 with a UI element 24 that has an associated hover content 28 contains. According to some aspects of the disclosure, the UI 20 on a display device 32 a computer device 36 displayed, which is a user input device 40 Although in 1 the UI 20 For example, as a search engine associated with a web page, shown on the display device 32 also other UIs 20 with a variety of other UI elements.
Die Computervorrichtung 36 kann gemäß einigen Beispielen eine tragbare Computervorrichtung (z. B. ein Mobiltelefon, ein Netbook, einen Laptop, eine Tablet-Vorrichtung oder eine andere Computervorrichtung) oder eine nichttragbare Vorrichtung wie z. B. einen Desktop-Computer enthalten oder ein Teil einer derartigen Vorrichtung sein. Gemäß einigen Beispielen kann die Benutzer-Eingabevorrichtung Zeigevorrichtungen wie z. B. eine Maus, einen Trackball, einen Joystick, eine Tastatur oder andere taktile Eingabevorrichtungen enthalten.The computer device 36 According to some examples, a portable computing device (eg, a mobile phone, a netbook, a laptop, a tablet device, or another computing device) or a non-portable device, such as a mobile device, may be used. B. include a desktop computer or be part of such a device. According to some examples, the user input device may include pointing devices, such as a pointing device. As a mouse, a trackball, a joystick, a keyboard or other tactile input devices.
Bei dem in 1 gezeigten Beispiel kann ein Benutzer das UI 20 mittels eines Cursors 46 navigieren, der unter Verwendung der Benutzer-Eingabevorrichtung gesteuert wird. Dementsprechend kann der Benutzer das UI-Element 24 mittels der Eingabevorrichtung derart wählen, dass der Cursor 46 an die korrekte Stelle auf der Anzeigevorrichtung 32 bewegt wird. Mit dem Wählen des UI-Elements 24 kann bewirkt werden, dass sich der auf der Anzeigevorrichtung 32 angezeigte Inhalt entsprechend dem Inhalt, der dem UI-Element 24 zugeordnet ist, ändert. Beispielsweis kann das Wählen eines Hyperlink-UI-Elements 24 bewirken, dass eine dem Hyperlink zugeordnete Webseite auf der Anzeigevorrichtung 32 angezeigt wird.At the in 1 As shown, a user can use the UI 20 by means of a cursor 46 navigated using the user input device. Accordingly, the user can use the UI element 24 select by means of the input device such that the cursor 46 to the correct location on the display device 32 is moved. By selecting the UI element 24 may be caused to be on the display device 32 displayed content according to the content of the UI element 24 is assigned, changes. For example, choosing a hyperlink UI element 24 cause a hyperlink associated web page on the display device 32 is shown.
Gemäß einigen Aspekten der Offenbarung können die Computervorrichtung 36 und das UI 20 derart konfiguriert sein, dass der Hover-Inhalt 28 auf der Anzeigevorrichtung 32 angezeigt wird. Von einem Benutzer kann ein Hover-Interaktionsmodus zum Anzeigen des Hover-Inhalts 28 aktiviert werden, wenn der Benutzer mittels der Eingabevorrichtung den Cursor 46 auf das UI-Element 24 bewegt, ohne das UI-Element 24 durch die Eingabevorrichtung zu aktivieren. Beispielsweise kann sich gemäß der hier vorliegenden Verwendung das ”Aktivieren” eines UI-Elements darauf beziehen, dass das Element mittels eines ”Mouse-down-Ereignisses” (z. B. typischerweise einhergehend mit dem Klicken einer Maustaste bei einem herkömmlichen PC) dahingehend gewählt wird, dass der einem Mouse-down-Ereignis zugeordnete Inhalt getriggert wird. Gemäß einem nichteinschränkenden Beispiel kann das ”Aktivieren” eines Hyperlink-UI-Elements auf einer Webseite bewirken, dass die Computervorrichtung 36 auf die dem Hyperlink-UI-Element zugeordnete Webseite navigiert.According to some aspects of the disclosure, the computing device may 36 and the UI 20 be configured such that the hover content 28 on the display device 32 is shown. Of a User can use a hover interaction mode to view the hover content 28 be activated when the user by means of the input device, the cursor 46 on the UI element 24 moves without the UI element 24 to activate through the input device. For example, as used herein, "activating" a UI element may refer to having the element selected by means of a "mouse-down event" (eg, typically associated with the click of a mouse button on a conventional PC) will trigger the content associated with a mouse-down event. As one non-limiting example, "turning on" a hyperlink UI element on a web page may cause the computing device 36 navigate to the web page associated with the hyperlink UI element.
Gemäß 1 wird durch die Präsenz des Cursors 46 in dem Umfeld des UI-Elements 24 ein UI-Ereignis getriggert, das zusätzliche Information über das UI-Element liefert, ohne das UI-Element zu aktivieren. Zu den Beispielen einer Hover-Funktion zählen das Highlighten oder anderweitige Verändern von Text des UI-Elements 24, um dem Benutzer zu benachrichtigen, dass das UI-Element 24 aktiviert werden kann (beispielsweise enthält das UI-Element 24 Inhalt, der durch Klicken einer Maustaste bei Benutzung eines herkömmlichen PC oder durch Berühren eines Touch Screen getriggert werden kann. Gemäß einem weiteren Beispiel kann eine Hover-Funktion das Anzeigen von Text enthalten, der dem UI-Element 24 zugeordneten Inhalt beschreibt. (Beispielsweise kann Hover-Inhalt, der einem Anwendungs-Icon zugeordnet ist, Information über die Anwendung geben.) Gemäß einem weiteren Beispiel kann die Hover-Funktion das Initialisieren eines Preview-Fensters enthalten, das dem UI-Element 24 zugeordneten Inhalt aufweist. (Beispielsweise kann Hover-Inhalt, der einem Webseiten-Interlink zugeordnet ist, ein Preview-Fenster präsentieren, das den Inhalt der dem Hyperlink zugeordneten Webseite enthält.)According to 1 is due to the presence of the cursor 46 in the environment of the UI element 24 triggered a UI event that provides additional information about the UI element without activating the UI element. Examples of hovering include highlighting or otherwise altering the text of the UI element 24 to notify the user that the UI element 24 can be activated (for example, contains the UI element 24 Content that can be triggered by clicking a mouse button when using a conventional PC or by touching a touch screen. As another example, a hover function may include displaying text associated with the UI element 24 describes associated content. (For example, hover content associated with an application icon may provide information about the application.) As another example, the hover function may include initializing a preview window corresponding to the UI element 24 has associated content. (For example, hover content associated with a web page interlink may present a preview window containing the content of the web page associated with the hyperlink.)
2 ist ein Schaubild, das ein weiteres Beispiel eines UI 60 mit einem UI-Element 64 zeigt, das einen zugeordneten Hover-Inhalt 68 enthält. Gemäß einigen Aspekten der Offenbarung wird das UI 60 auf einer berührungsempfindlichen Anzeigevorrichtung (”Touch Screen”) 72 einer Computervorrichtung 76 angezeigt, die in der Lage ist, eine Benutzer-Eingabe von einem Benutzer 78 zu empfangen (z. B. wie in 2 durch die Hände eines Benutzers gezeigt und repräsentiert). Beispielsweise kann ein Benutzer 78 die Benutzer-Eingabe durch Herstellen eines physischen Kontakt mit dem Touch Screen 72 vornehmen, wodurch der Benutzer mit der Computervorrichtung 76 interagieren kann. Die Computervorrichtung 76 kann gemäß einigen Beispielen eine tragbare Computervorrichtung (z. B. ein Mobiltelefon, ein Netbook, einen Laptop, eine Tablet-Vorrichtung oder eine andere tragbare Computervorrichtung) oder einen Desktop-Computer enthalten oder ein Teil einer derartigen Vorrichtung sein. Bei dem in 2 gezeigten Beispiel enthält das UI 60 ferner einen bezeichneten Bereich 82 zum Empfang einer Benutzer-Eingabe, die einen Hover-Modus initiiert. 2 is a chart that is another example of a UI 60 with a UI element 64 shows that has an associated hover content 68 contains. In some aspects of the disclosure, the UI 60 on a touch-sensitive display device ("touch screen") 72 a computer device 76 which is capable of receiving a user input from a user 78 to receive (eg as in 2 shown and represented by the hands of a user). For example, a user 78 the user input by establishing a physical contact with the touch screen 72 make the user with the computer device 76 can interact. The computer device 76 For example, according to some examples, a portable computing device (eg, a mobile phone, a netbook, a laptop, a tablet device, or another portable computing device) or a desktop computer may be included or part of such device. At the in 2 example shown contains the UI 60 and a designated area 82 for receiving a user input that initiates a hover mode.
Bei Betrieb kann der Touch Screen ein oder mehrere Ereignisse (z. B. Signale) generieren, die den Koordinaten einer auf dem Touch Screen 72 berührten Relativposition entsprechen. Eine derartige Benutzer-Eingabe in Form eines physischen Kontakts mit dem Touch Screen 72 kann als Touch-Geste bezeichnet werden. Die durch den Touch Screen 72 erzeugten Ereignisse können an eine weitere Komponente der Computervorrichtung 76 (z. B. einen Prozessor einer Computervorrichtung 76, wie anhand von 4 gezeigt und beschrieben) übertragen und von dieser empfangen werden. Die Computervorrichtung 76 kann dann eine Funktion durchführen, die der Benutzer-Eingabe entspricht. Beispielsweise kann, falls ein Hyperlink einer Webseite an der Relativposition der Touch-Geste angezeigt wird, die Computervorrichtung 76 den Hyperlink aktivieren und die dem Hyperlink zugeordnete Webseite starten.In operation, the touch screen may generate one or more events (eg, signals) that correspond to the coordinates of one on the touch screen 72 correspond to touched relative position. Such user input in the form of physical contact with the touch screen 72 can be called a touch gesture. The through the touch screen 72 generated events can be sent to another component of the computing device 76 (eg, a processor of a computing device 76 as based on 4 shown and described) and received by the latter. The computer device 76 can then perform a function corresponding to the user input. For example, if a hyperlink of a web page is displayed at the relative position of the touch gesture, the computing device may 76 activate the hyperlink and start the web page associated with the hyperlink.
Gemäß einigen Beispielen ist der Touch Screen 72 in der Lage, mehrere und im Wesentlichen gleichzeitige distinkte Benutzer-Eingaben zu empfangen (die z. B. als ”Multi-Touch-Eingabe” bezeichnet werden). Beispielsweise kann der Benutzer 32 eine erste Benutzer-Eingabe (z. B. eine Touch-Geste) vornehmen, indem er zuerst einen einzelnen Finger in Kontakt mit dem Touch Screen 72 platziert. Der Benutzer kann dann eine zweite Benutzer-Eingabe (z. B. eine weitere Touch-Geste) vornehmen, die sich von der ersten Benutzer-Eingabe unterscheidet (z. B. eine Touch-Geste in einem anderen Bereich des Touch Screen 72). Der Touch Screen 72 kann sowohl die erste Touch-Geste als auch die zweite Touch-Geste detektieren und registrieren, während der Kontakt mit dem Touch Screen 72 besteht, und anschließend ein oder mehrere entsprechende Signale erzeugen. Jede verschiedene Geste kann einer distinkten Funktion in einer Komponente der Computervorrichtung 76 entsprechen. Mit einer zweiten Touch-Geste, die sich von der ersten Touch-Geste unterscheidet, kann eine zweite Funktion durchgeführt werden, die sich von der ersten Funktion unterscheidet. In dieser Weise kann der Benutzer Touch-Gesten verwenden, um Funktionen an der Computervorrichtung 76 effizient durchzuführen.According to some examples, the touch screen is 72 being able to receive multiple and substantially concurrent distinct user inputs (for example, referred to as "multi-touch input"). For example, the user may 32 make a first user input (eg, a touch gesture) by first placing a single finger in contact with the touch screen 72 placed. The user may then make a second user input (eg, another touch gesture) that differs from the first user input (eg, a touch gesture in another area of the touch screen) 72 ). The touch screen 72 can detect and register both the first touch gesture and the second touch gesture while in contact with the touch screen 72 and then generate one or more corresponding signals. Each distinct gesture may have a distinct function in a component of the computing device 76 correspond. With a second touch gesture that is different from the first touch gesture, a second function may be performed that differs from the first function. In this way, the user can use touch gestures to perform functions on the computing device 76 perform efficiently.
Gemäß Aspekten der Offenbarung kann der Benutzer 78 den bezeichneten Bereich 82 des Touch Screen 72 zum Initiieren eines Hover-Modus verwenden, indem er eine Benutzer-Eingabe wie z. B. eine Touch-Geste, in dem bezeichneten Bereich 82 vornimmt. Zum Beispiel interpretiert in konventioneller Art die Computervorrichtung 76 typischerweise einen auf Berührung basierenden Kontakt mit dem Touch Screen 72 als Mouse-down-Ereignis (z. B. äquivalent zum Betätigen oder ”Klicken” einer Maustaste an einem herkömmlichen PC, hier als Tap- oder Touch-down-Ereignis bezeichnet), oder als ein Scroll-Ereignis (z. B. äquivalent zur Verwendung eines Scroll-Rads einer Maus zum Scrollen durch den Inhalt an einem herkömmlichen PC). Gemäß Aspekten der Offenbarung kann die Computervorrichtung 76 eine Benutzer-Eingabe wie z. B. eine Touch-Geste in dem bezeichneten Bereich 82 des UI 60 als Initiieren eines Hover-Modus interpretieren. Der Hover-Modus ermöglicht dem Benutzer 78 das Triggern eines UI-Ereignisses, wie z. B. das Anzeigen von Hover-Inhalt 68, der dem UI-Element 564 zugeordnet ist, ohne dass das UI-Element 64 aktiviert wird. Beispielsweise kann der Hover-Inhalt 68 graphische Information über den dem UI-Element 64 zugeordneten Inhalt liefern. Zu den Beispielen von Hover-Inhalt zählen ein Highlighting oder anderweitiges Verändern von Text des UI-Elements 64, um dem Benutzer mitzuteilen, dass das UI-Element 64 betätigt werden kann, das Anzeigen eines Preview- oder ”Pop-up”-Fensters mit Text, der dem UI-Element 64 zugeordneten Inhalt beschreibt, das Anzeigen eines Preview-Fensters, das dem UI-Element 64 zugeordneten Inhalt enthält (z. B. eine ausgezoomte oder geschrumpfte Version des dem UI-Element 64 zugeordneten Inhalts), oder andere Hover-Inhalte.According to aspects of the disclosure, the user may 78 the designated area 82 of the touch screen 72 to initiate a hover mode by specifying a user input such as. As a touch gesture, in the designated area 82 performs. For example, in a conventional way, the computing device interprets 76 typically one touch-based contact with the touch screen 72 as a mouse-down event (e.g., equivalent to pressing or "clicking" a mouse button on a conventional PC, referred to herein as a tap or touch-down event), or as a scrolling event (eg, equivalent for using a scroll wheel of a mouse to scroll through the content on a conventional PC). According to aspects of the disclosure, the computing device 76 a user input such. B. a touch gesture in the designated area 82 of the UI 60 interpret as initiating a hover mode. The hover mode allows the user 78 triggering a UI event, such as For example, viewing hover content 68 that is the UI element 564 is assigned without the UI element 64 is activated. For example, the hover content 68 graphical information about the UI element 64 deliver associated content. Examples of hover content include highlighting or otherwise altering the text of the UI element 64 to inform the user that the UI element 64 can be pressed, displaying a preview or "pop-up" window with text that corresponds to the UI element 64 Associated content describes how to display a preview window that corresponds to the UI element 64 associated content (for example, a zoomed out or shrunken version of the UI element 64 associated content), or other hover content.
Der Benutzer 78 kann, indem er einen bezeichneten Bereich 82 benutzt, einen Hover-Modus in vielfältiger Weise initiieren oder aktivieren. Gemäß einem Beispiel führt der Benutzer 78 eine Single-Touch-Geste in dem bezeichneten Bereich 82 aus, um den Hover-Modus zu aktivieren. Beispielsweise kann der Benutzer 78 den Touch Screen 72 in dem bezeichneten Bereich 82 antippen, um einen Hover-Modus zu initiieren. Bei aktivem Hover-Modus kann der Benutzer 78 Touch-Gesten an UI-Elementen 64 vornehmen, um die Inhalte der UI-Elemente 64 zu erforschen, ohne die UI-Elemente 64 zu betätigen. Zudem kann auf dem Touch Screen 72 wiedergegebener Inhalt in Position fixiert werden. Zum Deaktivieren des Hover-Modus kann der Benutzer 78 eine weitere Touch-Geste in dem bezeichneten Bereich 82 vornehmen. Der Benutzer 78 ist dann frei, UI-Elemente 64 zu betätigen.The user 78 can by giving a designated area 82 used to initiate or activate a hover mode in a variety of ways. According to one example, the user performs 78 a single-touch gesture in the designated area 82 to activate the hover mode. For example, the user may 78 the touch screen 72 in the designated area 82 Tap to initiate a hover mode. When the hover mode is active, the user can 78 Touch gestures on UI elements 64 make the content of the UI elements 64 to explore without the UI elements 64 to press. In addition, on the touch screen 72 contents are fixed in position. To deactivate the hover mode, the user can 78 another touch gesture in the designated area 82 make. The user 78 is then free, UI elements 64 to press.
Gemäß einem weiteren Beispiel führt der Benutzer 78 eine kontinuierliche Touch-Geste in dem bezeichneten Bereich 82 durch, um den Hover-Modus zu aktivieren. Beispielsweise hält der Benutzer 78 den Kontakt mit dem Touch Screen 72 in dem bezeichneten Bereich 82 so lange aufrecht, wie der Benutzer 78 den Hover-Modus aktiv haben möchte. Bei aktivem Hover-Modus kann der Benutzer 78 Touch-Gesten separat von der in dem bezeichneten Bereich 82 erfolgenden Touch-Geste ausführen, um UI-Elemente 64 zu erforschen, ohne die UI-Elemente 64 zu betätigen. Der Benutzer 78 kann den Hover-Modus deaktivieren, indem er den Kontakt mit dem bezeichneten Bereich 82 unterbricht.As another example, the user performs 78 a continuous touch gesture in the designated area 82 to activate the hover mode. For example, the user stops 78 the contact with the touch screen 72 in the designated area 82 upright as long as the user 78 want to have the hover mode active. When the hover mode is active, the user can 78 Touch gestures separately from those in the designated area 82 Perform a touch gesture to UI elements 64 to explore without the UI elements 64 to press. The user 78 can disable the hover mode by making contact with the designated area 82 interrupts.
Ein Benutzer kann ferner kontinuierliche Touch-Gesten in anderen Abfolgen vornehmen, um unterschiedliche Interaktionen mit dem UI 60 zu erzeugen. Gemäß einem weiteren Beispiel kann der Benutzer 78 den Kontakt mit dem Touch Screen 72 in dem bezeichneten Bereich 82 so lange aufrechthalten, wie der Benutzer 78 den Hover-Modus aktiv haben möchte. Bei aktivem Hover-Modus kann der Benutzer 78 andere Touch-Gesten separat von der in dem bezeichneten Bereich 82 erfolgenden Touch-Geste ausführen, um UI-Elemente 64 zu erforschen, ohne die UI-Elemente 64 zu betätigen. Der Benutzer 78 kann dann bestimmen, dass er das UI-Element 64 aktivieren möchte. Der Benutzer 78 kann das UI-Element 64 aktivieren, indem er den Kontakt mit dem UI-Element 64 aufrechthält, während er die erste Touch-Geste in dem bezeichneten Bereich 82 aufhebt (z. B. den Kontakt mit dem Touch Screen 72 unterbricht). Nach dem Unterbrechen des Kontakts mit dem Touch Screen 72 in dem bezeichneten Bereich 82 kann die Computervorrichtung 76 den Hover-Modus deaktivieren und zum normalen Betrieb zurückkehren (z. B. ein Tap-Ereignis bewirken), wodurch das UI-Element 64 aktiviert wird.A user may also make continuous touch gestures in other sequences to different interactions with the UI 60 to create. As another example, the user may 78 the contact with the touch screen 72 in the designated area 82 as long as the user 78 want to have the hover mode active. When the hover mode is active, the user can 78 other touch gestures separately from those in the designated area 82 Perform a touch gesture to UI elements 64 to explore without the UI elements 64 to press. The user 78 can then determine that he is the UI element 64 want to activate. The user 78 can the UI element 64 Enable by making contact with the UI element 64 while holding the first touch gesture in the designated area 82 (eg contact with the touch screen 72 interrupts). After breaking the contact with the touch screen 72 in the designated area 82 can the computer device 76 disable the hover mode and return to normal operation (eg cause a tap event), causing the UI element 64 is activated.
Gemäß einem weiteren Beispiel kann der Benutzer 78 zunächst eine Touch-Geste in dem UI 60 vornehmen (z. B. Scrollen oder Berühren eines UI-Elements 64). Der Benutzer 78 kann dann eine zweite, distinkte Touch-Geste in dem bezeichneten Bereich 82 vornehmen, um den Hover-Interaktionsmodus zu initiieren. Der Benutzer 78 kann den Kontakt mit dem Touch Screen 72 in dem bezeichneten Bereich 82 so lange aufrechthalten, wie der Benutzer 78 den Hover-Modus aktiv haben möchte. Bei aktivem Hover-Modus kann das UI 60 den dem UI-Element 64 zugeordneten Inhalt Hover-Modus-Inhalt 68 anzeigen. Der Benutzer kann dann die erste Touch-Geste aufheben (z. B. den Kontakt mit dem Touch Screen 72 unterbrechen), um den Inhalt 68 zu entfernen, und die zweite Touch-Geste aufheben, um den Hover-Modus zu deaktivieren.As another example, the user may 78 first a touch gesture in the UI 60 (for example, scrolling or touching a UI element 64 ). The user 78 may then have a second, distinct touch gesture in the designated area 82 to initiate hover interaction mode. The user 78 can contact the touch screen 72 in the designated area 82 as long as the user 78 want to have the hover mode active. With active hover mode, the UI 60 the UI element 64 associated content hover mode content 68 Show. The user can then cancel the first touch gesture (eg contact with the touch screen 72 interrupt) to the content 68 remove the second touch gesture to disable the hover mode.
Gemäß einem weiteren Beispiel kann der Benutzer 78 zuerst eine Touch-Geste an dem UI 60 vornehmen (z. B. Scrollen oder Berühren eines UI-Elements 64). Dann kann der Benutzer 78 eine zweite Touch-Geste an dem bezeichneten Bereich 82 vornehmen, um den Hover-Interaktionsmodus zu initiieren. Der Benutzer 78 kann den Kontakt mit dem Touch Screen 72 in dem bezeichneten Bereich 82 so lange aufrechthalten, wie der Benutzer 78 den Hover-Modus aktiv haben möchte. Bei aktivem Hover-Modus kann das UI 60 den dem UI-Element 64 zugeordneten Inhalt Hover-Modus-Inhalt 68 anzeigen. Der Benutzer 78 dann bestimmen, dass er das UI-Element 64 aktivieren möchte. Der Benutzer 78 kann das UI-Element 64 aktivieren, indem er die zweite Touch-Geste aufhebt und den Hover-Modus deaktiviert. Nach dem Unterbrechen des Kontakts mit dem Touch Screen 72 in bezeichneten Bereichen 82 kann die Computervorrichtung 76 den normalen Betrieb wiederaufnehmen, wodurch das UI-Element 64 aktiviert wird. Der Benutzer 78 kann dann die erste Touch-Geste aufheben.As another example, the user may 78 first a touch gesture on the UI 60 (for example, scrolling or touching a UI element 64 ). Then the user can 78 a second touch gesture on the designated area 82 to initiate hover interaction mode. The user 78 can contact the touch screen 72 in the designated area 82 as long as the user 78 want to have the hover mode active. With active hover mode, the UI 60 the UI element 64 associated content hover mode content 68 Show. The user 78 then determine that he is the UI element 64 want to activate. The user 78 can the UI element 64 activate by lifting the second touch gesture and disabling the hover mode. After breaking the contact with the touch screen 72 in designated areas 82 can the computer device 76 resume normal operation, eliminating the UI element 64 is activated. The user 78 can then pick up the first touch gesture.
Gemäß einigen Aspekten der Offenbarung muss der Benutzer 78 eine Benutzer-Eingabe, wie z. B. eine Touch-Geste in dem bezeichneten Bereich 82, während einer vorbestimmten Dauer vornehmen, bevor die Computervorrichtung 76 den Hover-Modus initiiert. Es ist beispielsweise möglich, das der Benutzer 78 eine oder mehrere Sekunden lang (z. B. zwei Sekunden, drei Sekunden oder über eine längere Dauer) eine kontinuierliche Touch-Geste in dem bezeichneten Bereich 82 vornehmen muss, bevor die Computervorrichtung 76 den Hover-Modus initiiert. Bei den Beispielen, bei denen zum Initiieren des Hover-Modus eine Single-Touch-Geste erforderlich ist, kann verlangt sein, dass der Benutzer 78 den Kontakt mit dem Touch Screen 72 während einer vorbestimmten Dauer aufrechterhält, bevor die Computervorrichtung 76 den Hover-Modus initiiert. Bei den Beispielen, bei denen eine kontinuierliche Touch-Geste zum Initiieren des Hover-Initiationsmodus erforderlich ist, kann der Benutzer 78 eine Verzögerung beim Initiieren des Hover-Modus erfahren, während er den Kontakt mit dem Touch Screen 72 beibehält.According to some aspects of the disclosure, the user must 78 a user input, such as B. a touch gesture in the designated area 82 to make a predetermined period before the computer device 76 initiated the hover mode. For example, it is possible for the user 78 for one or more seconds (eg, two seconds, three seconds or longer), a continuous touch gesture in the designated area 82 must make before the computer device 76 initiated the hover mode. In the examples where a single-touch gesture is required to initiate the hover mode, the user may be required to 78 the contact with the touch screen 72 for a predetermined duration before the computing device 76 initiated the hover mode. In the examples where a continuous touch gesture is required to initiate the hover initiation mode, the user may 78 experience a delay in initiating hover mode while having contact with the touch screen 72 maintains.
Gemäß einigen Aspekten der Offenbarung kann, während der Hover-Modus vorliegt, die Computervorrichtung 76 den präsentierten Inhalt auf dem Touch Screen 72 in Position halten oder ”fixieren”. Beispielsweise kann der Benutzer 78 eine Benutzer-Eingabe in dem bezeichneten Bereich 82 vornehmen, um den Hover-Modus zu initiieren. Bei aktiviertem Hover-Modus kann die Computervorrichtung 76 die Fähigkeit zum Scrollen oder Neupositionieren von auf dem Touch Screen 72 wiedergegebenem Inhalt oder zum Betätigen von UI-Elementen wie z. B. des UI-Elements 64 zeitweilig deaktivieren.In some aspects of the disclosure, while the hover mode is in effect, the computing device may be 76 the presented content on the touch screen 72 hold in position or "fix". For example, the user may 78 a user input in the designated area 82 to initiate the hover mode. When the hover mode is activated, the computing device can 76 the ability to scroll or reposition on the touch screen 72 played back content or to operate UI elements such as B. the UI element 64 temporarily disable.
Die Computervorrichtung 76 kann, während sie sich im Hover-Modus befindet, Hover-Inhalt 68 anzeigen, der einem UI-Element zugeordnet ist, das auf dem Touch Screen 72 perzeptiv am nächsten zu der physischen Stelle der Benutzer-Eingabe (z. B. der Touch-Geste) liegt. Beispielsweise kann ein Benutzer 78 den bezeichneten Bereich 82 zum Initiieren des Hover-Modus verwenden. Der Benutzer 78 kann dann eine Touch-Geste an oder nahe einem auf dem Touch Screen 72 angezeigten UI-Element wie z. B. dem UI-Element 64 vornehmen. Als Reaktion kann die Computervorrichtung 76 Hover-Inhalt 68 anzeigen, der dem UI-Element zugeordnet ist, das perzeptiv am nächsten zu der Touch-Gesten-Benutzer-Interface-Wahl angeordnet ist.The computer device 76 can hover while in hover mode 68 that is associated with a UI element that is on the touch screen 72 perceptually closest to the physical location of the user input (eg, the touch gesture). For example, a user 78 the designated area 82 to initiate the hover mode. The user 78 can then do a touch gesture on or near one on the touch screen 72 displayed UI element such. For example, the UI element 64 make. In response, the computing device 76 Hover Content 68 associated with the UI element that is perceptually closest to the touch gesture user interface selection.
Gemäß einigen Beispielen kann die Computervorrichtung 76 eine Benutzer-Eingabe, wie z. B. Touch-Gesten, interpretieren, die um einen vorbestimmten Abstand oberhalb, unterhalb oder seitlich der physischen Stelle der Benutzer-Eingabe erfolgt. Beispielsweise kann die Computervorrichtung 76 einen Interaktionsmodus bereitstellen, in dem der Benutzer 78 auf ein UI-Element wie z. B. das UI-Element 64 zeigt, statt dass vom Benutzer 78 verlangt wird, das UI-Element 64 zu berühren oder ”abzudecken”. Ein derartiger Interaktionsmodus kann einem Benutzer 78 ermöglichen, das Anzeigen des Hover-Inhalts 68 zu initiieren, ohne das dem Hover-Inhalt 68 zugeordnete UI-Element 64 zu verdecken. Falls der Benutzer 78 keine Touch-Geste direkt an dem auf dem Touch Screen 72 angezeigten UI-Element vornimmt, kann die Computervorrichtung 76 eine Fähigkeit aufweisen, die Touch-Gesten-Benutzer-Interface-Wahl virtuell zu dem perzeptuell nahegelegensten UI-Element zu bewegen oder ”herüberschnellen” zu lassen.According to some examples, the computing device may 76 a user input, such as Touch, gestures that occur a predetermined distance above, below, or to the side of the physical location of the user input. For example, the computing device 76 provide an interaction mode in which the user 78 on a UI element such as. For example, the UI element 64 shows, instead of the user 78 is required, the UI element 64 to touch or "cover". Such an interaction mode may be a user 78 enable viewing the hover content 68 without initiating the hover content 68 associated UI element 64 to cover up. If the user 78 no touch gesture directly on the on the touch screen 72 displayed UI element, the computer device 76 have an ability to virtually move or "skip" the touch gesture user interface choice to the perceptually closest UI element.
Zudem kann die Computervorrichtung 76 den Hover-Inhalt 68 um einen vorbestimmten Abstand oberhalb, unterhalb oder seitlich der physischen Stelle der Benutzer-Eingabe anzeigen. Beispielsweise kann die Computervorrichtung 76 den Hover-Inhalt 68 um einen vorbestimmten Abstand oberhalb, unterhalb oder seitlich der physischen Stelle der Benutzer-Eingabe transponieren. Das Transponieren des Hover-Inhalts 68 um einen vorbestimmten Abstand von der Stelle der Benutzer-Eingabe kann dazu beitragen, sicherzustellen, dass der Akt des Tätigens der Benutzer-Eingabe (z. B. das Vornehmen einer Touch-Geste auf dem Touch Screen 72) den Hover-Inhalt 68 nicht verdeckt.In addition, the computer device 76 the hover content 68 by a predetermined distance above, below, or to the side of the physical location of the user input. For example, the computing device 76 the hover content 68 transpose by a predetermined distance above, below, or to the side of the physical location of the user input. Transposing the hover content 68 a predetermined distance from the location of the user input may help to ensure that the act of making the user input (e.g., making a touch gesture on the touch screen 72 ) the hover content 68 not covered.
Gemäß einigen Beispielen gibt die Computervorrichtung 76 dem Benutzer 78 eine Benachrichtigung, wenn ein Interaktionsmodus geändert worden ist. Beispielsweise kann die Computervorrichtung 76 dem Benutzer 78 signalisieren, dass ein Hover-Modus aktiv ist, indem sie ein graphisches Symbol oder Zeichen auf dem Touch Screen 72 anzeigt (z. B. einen traditionellen Maus-Cursor vom Pfeil-Typ, einen zeigenden Finger wie z. B. den Cursor 80, oder ein alternatives Symbol oder Zeichen). Gemäß einem weiteren Beispiel kann die Computervorrichtung 76 einige oder sämtliche der auf dem Touch Screen 72 präsentierten Inhalte ändern, wenn ein Interaktionsmodus geändert worden ist. Beispielsweise kann die Computervorrichtung 76 einige oder sämtliche der auf dem Touch Screen 72 präsentierten Inhalte ausblenden. Zusätzlich oder alternativ kann die Computervorrichtung 76 eine haptische Rückmeldung (z. B. Vibration) ausgeben, um dem Benutzer 78 mitzuteilen, dass ein Interaktionsmodus geändert worden ist.According to some examples, the computing device gives 76 the user 78 a notification when an interaction mode has been changed. For example, the computing device 76 the user 78 signal that a hover mode is active by displaying a graphic icon or character on the touch screen 72 indicates (eg, a traditional arrow type mouse cursor, a pointing finger such as the cursor 80 , or an alternative symbol or sign). As another example, the computing device may 76 some or all of those on the touch screen 72 change content presented when an interaction mode has been changed. For example, the computing device 76 some or all of those on the touch screen 72 Hide displayed content. Additionally or alternatively, the computing device 76 To issue a haptic feedback (eg vibration) to the user 78 notify that an interaction mode has been changed.
Gemäß einigen Aspekten der Offenbarung gibt die Computervorrichtung 76 dem Benutzer 78 einen Hinweis auf den bezeichneten Bereich 82 zum Initiieren des Hover-Modus. Beispielsweise kann bei dem in 2 gezeigten Beispiel die Computervorrichtung 76 ein graphisches Symbol, ein Zeichen, einen gefärbten Bereich, ein pulsierendes Licht oder Blinklicht oder einen anderen Hinweis in dem bezeichneten Bereich 82 anzeigen, um den Benutzer 78 darauf hinzuweisen, dass der bezeichnete Bereich 82 zum Initiieren eines Hover-Modus verfügbar ist. Gemäß einigen Beispielen kann die Computervorrichtung 76 den Hinweis nur geben, wenn der Touch Screen 72 UI-Elemente anzeigt, die einen zugeordneten Hover-Inhalt haben, wie z. B. bei dem UI-Element 64 und dem Hover-Inhalt 68. Falls der Benutzer 78 auf ein UI navigiert, das keine UI-Elemente mit Hover-Inhalt enthält, kann der Hinweis verschwinden. In accordance with some aspects of the disclosure, the computing device provides 76 the user 78 an indication of the designated area 82 to initiate the hover mode. For example, in the in 2 example shown the computer device 76 a graphic symbol, a character, a colored area, a pulsating light or flashing light or other indication in the designated area 82 Show to the user 78 to point out that the designated area 82 is available to initiate a hover mode. According to some examples, the computing device may 76 give the hint only if the touch screen 72 Displays UI elements that have an associated hover content, such as B. at the UI element 64 and the hover content 68 , If the user 78 Navigating to a UI that does not contain UI elements with hover content may cause the hint to disappear.
In dem nichteinschränkenden Beispiel gemäß 2 wird der bezeichnete Bereich 82 in der unteren linken Ecke des Touch Screen 72 angezeigt. Gemäß anderen Beispielen jedoch kann der bezeichnete Bereich 82 in anderen Bereichen des Touch Screen 72 positioniert werden (z. B. der unteren rechten Ecke, der oberen rechten oder oberen linken Ecke, entlang einer Seite des Touch Screen 72 oder in anderen Bereichen des Touch Screen 72). Beispielsweise kann die Position des bezeichneten Bereichs 82 gemäß ergonomischen Erwägungen gewählt werden und kann je nach der Konfiguration der Computervorrichtung 76 variieren. Bei Beispielen, gemäß denen die Computervorrichtung 76 eine mobile oder handgehaltene Vorrichtung ist, kann ein Daumen des Benutzers 78 natürlicherweise an der unteren linken oder unteren rechten Ecke des Touch Screen 72 positioniert werden, wenn der Benutzer 78 die Computervorrichtung 76 ergreift.In the non-limiting example of FIG 2 becomes the designated area 82 in the lower left corner of the touch screen 72 displayed. However, according to other examples, the designated area 82 in other areas of the touch screen 72 be positioned (for example, the lower right corner, the upper right or upper left corner, along one side of the touch screen 72 or in other areas of the touch screen 72 ). For example, the position of the designated area 82 can be chosen according to ergonomic considerations and may vary depending on the configuration of the computing device 76 vary. In examples, according to which the computing device 76 A mobile or handheld device can be a thumb of the user 78 naturally at the lower left or lower right corner of the touch screen 72 be positioned when the user 78 the computer device 76 grasps.
Gemäß einigen Beispielen kann, wie anhand von 3A und 3B noch detaillierter beschrieben wird, die Stelle des bezeichneten Bereichs 82 entsprechend der Ausrichtung der Computervorrichtung 76 verändert werden. So etwa kann bei denjenigen Beispielen, gemäß denen die die Computervorrichtung 76 eine handgehaltene oder tragbare Computervorrichtung ist, die Computervorrichtung 76 die Stelle des bezeichneten Bereichs 82 dynamisch derart ändern, dass der bezeichnete Bereich 82 in dem unteren linken Bereich des Touch Screen 72 verbleibt, selbst falls der Touch Screen 72 relativ zu dem Benutzer 78 gedreht wird. Die Computervorrichtung kann eine Vielfalt von Komponenten implementieren (z. B. ein Gyroskop, einen Beschleunigungsmesser oder andere Komponenten), um das Bestimmen der geeigneten Stelle für den bezeichneten Bereich 82 zu unterstützen.According to some examples, as shown by 3A and 3B will be described in more detail, the location of the designated area 82 according to the orientation of the computer device 76 to be changed. For example, in those examples according to which the computer device 76 is a handheld or portable computing device, the computing device 76 the location of the designated area 82 change dynamically such that the designated area 82 in the lower left area of the touch screen 72 remains even if the touch screen 72 relative to the user 78 is turned. The computing device may implement a variety of components (eg, a gyroscope, an accelerometer, or other components) to determine the appropriate location for the designated area 82 to support.
Zusätzlich oder alternativ kann die Computervorrichtung 76 einem Benutzer 78 ermöglichen, eine bevorzugte Stelle für den bezeichneten Bereich 82 zu wählen. Beispielsweise kann bei denjenigen Beispielen, gemäß denen die die Computervorrichtung 76 eine handgehaltene oder tragbare Computervorrichtung ist, ein rechtshändiger Benutzer 78 den Wunsch haben, dass der bezeichnete Bereich 82 an derjenigen Seite des Touch Screen 72 angeordnet ist, die für einen linkshändigen Benutzer vorgesehenen Seite gegenüberliegt. Alternativ kann der Benutzer 78 vorziehen, dass der bezeichnete Bereich 82 relativ weit oben auf dem Touch Screen 72 statt relativ weit unten auf dem Touch Screen 72 positioniert ist. Dementsprechend kann eine Funktion der Computervorrichtung 76 vorgesehen sein, die dem Benutzer 78 ermöglicht, anfangs eine bevorzugte Stelle für den bezeichneten Bereich 82 einzustellen oder diese anschließend zu ändern.Additionally or alternatively, the computing device 76 a user 78 allow a preferred location for the designated area 82 to choose. For example, in those examples according to which the computer device 76 is a hand-held or portable computing device, a right-handed user 78 have the desire that the designated area 82 on the side of the touch screen 72 is arranged, which is opposite to a left-handed user side. Alternatively, the user can 78 prefer that the designated area 82 relatively high on the touch screen 72 instead of relatively far down on the touch screen 72 is positioned. Accordingly, a function of the computing device 76 be provided to the user 78 initially allows a preferred location for the designated area 82 to adjust or to change this afterwards.
Bei dem nichteinschränkenden Beispiel gemäß 2 ist der Hover-Modus dahingehend beschrieben worden, dass er durch eine Benutzer-Eingabe, wie z. B. eine Touch-Geste, in dem bezeichneten Bereich 82 initiiert wird. Gemäß anderen Beispielen jedoch kann die Computervorrichtung 76 einen Hover-Modus mittels einer Vielfalt anderer Benutzer-Eingaben oder einer Kombination von Benutzer-Eingaben initiieren. Beispielsweise können, statt das die Benutzer-Eingabe in dem bezeichneten Bereich 82 vorgesehen ist, die Computervorrichtung 76 und der Touch Screen 72 eine speziell vorgesehene Taste aufweisen (z. B. ein Soft Key, der in einem vordefinierten Bereich des Touch Screen 72 abgeordnet und bezeichnet ist), um einen Hover-Modus zu initiieren. Alternativ oder zusätzlich kann das Benutzer-Interface 60 eine Menü-Funktion enthalten, die dem Benutzer das Wählen oder Abwählen eines Hover-Modus ermöglicht. Gemäß weiteren Beispielen kann die Computervorrichtung 76 ein Gyroskop, einen Beschleunigungsmesser oder eine Vielfalt anderer Benutzer-Eingabevorrichtungen aufweisen, um einen Hover-Modus zu initiieren.In the non-limiting example of FIG 2 For example, the hover mode has been described as being triggered by a user input, such as a user. As a touch gesture, in the designated area 82 is initiated. However, according to other examples, the computing device may 76 initiate a hover mode using a variety of other user inputs or a combination of user inputs. For example, instead of the user input in the designated area 82 is provided, the computer device 76 and the touch screen 72 have a dedicated key (eg a soft key located in a predefined area of the touch screen) 72 seconded and designated) to initiate a hover mode. Alternatively or additionally, the user interface 60 include a menu function that allows the user to select or deselect a hover mode. In other examples, the computing device may 76 a gyroscope, an accelerometer or a variety of other user input devices to initiate a hover mode.
Die Computervorrichtung 76 kann zusätzliche Komponenten oder Merkmale enthalten, die aus Gründen der Übersicht in 2 nicht gezeigt sind. Beispielsweise kann die Computervorrichtung 76 auch ein Mikrophon und einen Lautsprecher enthalten, was für Beispiele gilt, bei denen die Computervorrichtung 76 zum Tätigen oder Empfangen von Video- oder Telefonanrufen konfiguriert ist. Ferner brauchen die in 2 gezeigten Komponenten und Merkmale der Computervorrichtung 76 nicht notwendigerweise in jedem Beispiel der Computervorrichtung 76 vorhanden zu sein. Beispielsweise brauchen bestimmte in Bezug auf die Computervorrichtung 76 beschriebene Merkmale, wie z. B. das Ausgeben einer Meldung an den Benutzer 78, wenn ein Interaktionsmodus geändert worden ist, oder das Ausgeben eines Hinweises auf den bezeichneten Bereich 82, nicht in jedem Ausführungsbeispiel der Computervorrichtung 76 enthalten zu sein.The computer device 76 may contain additional components or features that are included in the overview for clarity 2 not shown. For example, the computing device 76 Also included are a microphone and a speaker, which is for examples where the computer device 76 configured to make or receive video or phone calls. Further, in 2 shown components and features of the computer device 76 not necessarily in every example of the computing device 76 to be present. For example, certain with regard to the computing device 76 described features such. For example, issuing a message to the user 78 when an interaction mode has been changed, or issuing an indication of the designated area 82 . not in every embodiment of the computing device 76 to be included.
In dem nichteinschränkenden Beispiel gemäß 2 ist der Benutzer 78 dahingehend gezeigt und beschrieben worden, dass er die Benutzer-Eingabe mit den Zeigefingern beider Hände vornimmt. Es sollte sich jedoch verstehen, dass der Benutzer 78 die Benutzer-Eingabe, wie z. B. eine Touch-Geste, auch in anderer Weise als in der in 2 gezeigten Weise durchführen kann. Beispielsweise kann der Benutzer 78 eine erste Touch-Geste in einem bezeichneten Bereich 82 mit einem Daumen und eine zweite Touch-Geste mit einem Finger derselben Hand vornehmen. Gemäß einem anderen Beispiel, bei dem die Computervorrichtung 76 eine tragbare Computervorrichtung 76 ist, kann der Benutzer 78 die Computervorrichtung 76 mit einer Hand greifen und eine erste Touch-Geste in dem bezeichneten Bereich 82 mit dem Daumen der greifenden Hand vornehmen, während er eine zweite Touch-Geste mit einem Finger der nichtgreifenden Hand vornimmt. Es sind auch andere Wege zur Durchführung der Touch-Gesten möglich.In the non-limiting example of FIG 2 is the user 78 has been shown and described as making the user input with the index fingers of both hands. It should be understood, however, that the user 78 the user input, such as. B. a touch gesture, in other ways than in the 2 can perform manner shown. For example, the user may 78 a first touch gesture in a designated area 82 with one thumb and a second touch gesture with a finger of the same hand. According to another example, where the computing device 76 a portable computer device 76 is, the user can 78 the computer device 76 grab with one hand and a first touch gesture in the designated area 82 with the thumb of the gripping hand while making a second touch gesture with a finger of the non-gripping hand. There are also other ways to perform the touch gestures possible.
3A zeigt ein Schaubild eines Beispiels einer UI 90 einer Computervorrichtung 94, die einen Touch Screen 98 mit einem bezeichneten Bereich 102 zum Empfangen einer Benutzer-Eingabe aufweist, welche einen Hover-Modus initiiert. Gemäß einigen Aspekten der Offenbarung kann die Computervorrichtung 94 ähnlich oder gleich der in 2 gezeigten Computervorrichtung 76 oder der in 1 gezeigten Computervorrichtung 36 konfiguriert sein. Bei dem Beispiel gemäß 3A weist die Computervorrichtung 94 ferner mehrere berührungsempfindliche Tasten 106 auf, die von einem Benutzer 110 betätigt werden können. 3A shows a diagram of an example of a UI 90 a computer device 94 that have a touch screen 98 with a designated area 102 for receiving a user input initiating a hover mode. According to some aspects of the disclosure, the computing device may 94 similar or equal to the one in 2 shown computer device 76 or the in 1 shown computer device 36 be configured. In the example according to 3A has the computer device 94 Furthermore, several touch-sensitive buttons 106 on, by a user 110 can be operated.
In dem nichteinschränkenden Beispiel gemäß 3A ist der bezeichnete Bereich 102 in dem unteren linken Bereich des UI 90 positioniert, obwohl, wie im Zusammenhang mit 2 beschrieben, der bezeichnete Bereich 102 auch in anderen Bereichen des Touch Screen 98 positioniert sein kann. Gemäß Aspekten der Offenbarung kann der Benutzer 110 den bezeichneten Bereich 102 zum Initiieren eines Hover-Modus verwenden. Beispielsweise kann der Benutzer 110 den bezeichneten Bereich 102 des Touch Screen 98 zum Initiieren eines Hover-Modus verwenden, indem er eine Benutzer-Eingabe, wie z. B. eine Touch Geste, in dem bezeichneten Bereich 102 vornimmt. Der Hover-Modus ermöglicht dem Benutzer 110 das Triggern eines UI-Ereignisses, wie z. B. das Anzeigen eines einem UI-Element 118 zugeordneten Hover-Inhalts 114, ohne das UI-Element 118 zu aktivieren.In the non-limiting example of FIG 3A is the designated area 102 in the lower left area of the UI 90 positioned, though, as related to 2 described, the designated area 102 also in other areas of the touch screen 98 can be positioned. According to aspects of the disclosure, the user may 110 the designated area 102 to initiate a hover mode. For example, the user may 110 the designated area 102 of the touch screen 98 to initiate a hover mode by specifying a user input, such as As a touch gesture, in the designated area 102 performs. The hover mode allows the user 110 triggering a UI event, such as For example, displaying a UI element 118 associated hover content 114 without the UI element 118 to activate.
Gemäß einigen Beispielen kann die Computervorrichtung 94 eine Benutzer-Eingabe, wie z. B. eine Touch-Geste, interpretieren, die um einen vorbestimmten Abstand oberhalb, unterhalb oder seitlich der physischen Stelle der Benutzer-Eingabe erfolgt. Beispielsweise nimmt gemäß 3A der Benutzer 110 eine Touch-Geste an einer Stelle an dem UI 90, die der physischen Stelle der Benutzer-Eingabe auf dem Touch Screen 98 zugeordnet ist, etwas unterhalb des UI-Elements 118 vor, wobei der Hover-Modus aktiv (d. h. durch die Touch-Geste in dem bezeichneten Bereich 102 aktiviert) ist. Die Computervorrichtung 94 interpretiert jedoch die Touch-Geste als dem UI-Element 118 oberhalb der Touch-Geste zugeordnet, und sie initiiert ein UI-Ereignis, welches das Anzeigen des Hover-Inhalts 114 enthält. Auf diese Weise wird von dem Benutzer 110 nicht notwendigerweise verlangt, die Benutzer-Eingabe direkt auf dem UI-Element 118 vorzunehmen, wodurch dem Benutzer 110 ermöglicht wird, die Anzeige des Hover-Inhalts 114 zu initiieren, ohne das UI-Element 118 zu verdecken.According to some examples, the computing device may 94 a user input, such as A touch gesture that occurs a predetermined distance above, below, or to the side of the physical location of the user input. For example, according to 3A the user 110 a touch gesture at one point on the UI 90 , the physical location of the user input on the touch screen 98 is assigned, slightly below the UI element 118 before, wherein the hover mode is active (ie by the touch gesture in the designated area 102 activated) is. The computer device 94 however, interprets the touch gesture as the UI element 118 is assigned above the touch gesture, and it initiates a UI event that indicates the hover content 114 contains. This is done by the user 110 does not necessarily require the user input directly on the UI element 118 make, giving the user 110 allows the display of hover content 114 to initiate without the UI element 118 to cover up.
Beispielsweise kann die Computervorrichtung 94 den Hover-Inhalt 114 um einen vorbestimmten Abstand oberhalb, unterhalb oder seitlich einer Stelle an dem UI anzeigen, die der physischen Stelle der Benutzer-Eingabe zugeordnet ist. In dem Beispiel gemäß 3A zeigt die Computervorrichtung 94 den Hover-Inhalt 114 rechts und oberhalb des UI-Elements 118 an. Dadurch verdeckt der Benutzer 110 nicht den Hover-Inhalt 114 durch das Ausführen der Touch-Geste an dem UI-Element 118.For example, the computing device 94 the hover content 114 to indicate a predetermined distance above, below, or to the side of a location on the UI associated with the physical location of the user input. In the example according to 3A shows the computer device 94 the hover content 114 right and above the UI element 118 at. This obscures the user 110 not the hover content 114 by performing the touch gesture on the UI element 118 ,
In dem nichteinschränkenden Beispiel gemäß 3A meldet die Computervorrichtung 94 dem Benutzer 110, dass ein Hover-Modus aktiv ist, indem ein Cursor 122 auf dem Touch Screen 98 angezeigt wird. Gemäß weiteren Beispielen kann die Computervorrichtung 94 dem Benutzer 110 melden, dass ein Hover-Modus aktiv ist, indem andere graphische Symbole oder Zeichen auf dem Touch Screen 98 angezeigt werden. Gemäß einigen Beispielen kann der Cursor 122 seine Position entsprechend der physischen Stelle der Touch-Geste des Benutzers verändern. Falls z. B. der Benutzer 110 ein UI-Element, bei dem es sich um ein anderes als das UI-Element 118 handelt und das an einer anderen Stelle auf dem Touch Screen 98 angeordnet ist, mit einer Touch-Geste erforscht, zeigt die Computervorrichtung 94 den Cursor 122 nahe der Touch-Geste an.In the non-limiting example of FIG 3A reports the computer device 94 the user 110 that a hover mode is active by placing a cursor 122 on the touch screen 98 is shown. In other examples, the computing device may 94 the user 110 Report that a hover mode is active by displaying other graphical symbols or characters on the touch screen 98 are displayed. According to some examples, the cursor may 122 change its position according to the physical location of the user's touch gesture. If z. For example, the user 110 a UI element that is other than the UI element 118 and that in another place on the touch screen 98 arranged, explored with a touch gesture, shows the computer device 94 the cursor 122 near the touch gesture.
Gemäß einigen Aspekten der Offenbarung gibt die Computervorrichtung 94 dem Benutzer 110 einen Hinweis 126 auf den bezeichneten Bereich 102 zum Initiieren des Hover-Modus. Bei dem Beispiel gemäß 3A handelt es sich bei dem Hinweis um ein Licht (z. B. eine gepulstes farbiges Licht), das den Benutzer 110 darauf hinweist, dass der Hover-Modus mittels des bezeichneten Bereichs 102 initiiert werden kann. Gemäß weiteren Beispielen kann die Computervorrichtung 94 einen anderen Hinweis 126 geben (z. B. ein Symbol oder Icon, wie z. B. das Icon eines zeigenden Fingers). Gemäß einigen Beispielen gibt die Computervorrichtung 94 einen Hinweis 126 nur dann, wenn der Touch Screen 98 UI-Elemente anzeigt, die einen zugeordneten Hover-Inhalt haben, wie z. B. bei dem UI-Element 118 und dem Hover-Inhalt 114. Falls der Benutzer 110 auf ein UI navigiert, das keine UI-Elemente mit Hover-Inhalt enthält, kann der Hinweis 126 verschwinden.In accordance with some aspects of the disclosure, the computing device provides 94 the user 110 a hint 126 to the designated area 102 to initiate the hover mode. In the example according to 3A the indicator is a light (eg a pulsed colored light) representing the user 110 indicating that the hover mode by means of the designated area 102 can be initiated. In other examples, the computing device may 94 another hint 126 (eg a symbol or icon, such as the icon of a pointing finger). According to some examples, the computing device gives 94 a hint 126 only if the touch screen 98 Displays UI elements that have an associated hover content, such as B. at the UI element 118 and the hover content 114 , If the user 110 navigate to a UI that does not contain UI elements with hover content, the hint may 126 disappear.
3B ist ein Schaubild des UI 90 und der Computervorrichtung 94 aus 3A, die um 90° gedreht worden ist. Gemäß einigen Beispielen der Offenbarung kann die Stelle des bezeichneten Bereichs 102 entsprechend der Ausrichtung der Computervorrichtung 94 relativ zu dem Benutzer 110 geändert werden. Beispielsweise kann die Computervorrichtung 94 die Stelle des bezeichneten Bereichs 102 virtuell derart neupositionieren, dass die Position des bezeichneten Bereichs 102 relativ zu dem Benutzer 110 die gleiche bleibt, selbst wenn die relative Ausrichtung der Computervorrichtung 94 in Bezug auf den Benutzer 110 geändert wird. Bei dem Beispiel gemäß 3B positioniert die Computervorrichtung 94 den bezeichneten Bereich 102 in dem unteren linken Teil (z. B. relativ zu dem Benutzer 110) des Touch Screen 98, unabhängig von der Ausrichtung der Computervorrichtung 94 relativ zu dem Benutzer 110. Die Computervorrichtung 94 kann eine Vielfalt von Hardware- oder Software-Komponenten implementieren (z. B. ein Gyroskop, einen Beschleunigungsmesser oder andere Hardware- oder Software-Komponenten), um das Bestimmen der geeigneten Stelle für den bezeichneten Bereich 82 zu unterstützen. 3B is a diagram of the UI 90 and the computer device 94 out 3A which has been rotated 90 °. According to some examples of the disclosure, the location of the designated area 102 according to the orientation of the computer device 94 relative to the user 110 be changed. For example, the computing device 94 the location of the designated area 102 virtually reposition that position of the designated area 102 relative to the user 110 the same remains, even if the relative orientation of the computing device 94 in terms of the user 110 will be changed. In the example according to 3B positions the computing device 94 the designated area 102 in the lower left part (eg, relative to the user 110 ) of the touch screen 98 regardless of the orientation of the computing device 94 relative to the user 110 , The computer device 94 may implement a variety of hardware or software components (eg, a gyroscope, an accelerometer, or other hardware or software components) to determine the appropriate location for the designated area 82 to support.
Die Computervorrichtung 94 gemäß 3A und 3B kann zusätzliche Komponenten oder Merkmale enthalten, die aus Gründen der Übersicht in 3A und 3B nicht gezeigt sind. Beispielsweise kann die Computervorrichtung 94 auch ein Mikrophon, einen Lautsprecher, eine Tastatur oder eine Vielfalt anderer Vorrichtungen enthalten. Ferner brauchen die in Bezug auf die Computervorrichtung 94 beschriebenen Komponenten und Merkmale nicht notwendigerweise in jedem Beispiel der Computervorrichtung 96 vorhanden zu sein. Beispielsweise brauchen bestimmte in Bezug auf die Computervorrichtung 96 beschriebene Merkmale, wie z. B. das Ausgeben einer Meldung an den Benutzer 110, wenn ein Interaktionsmodus geändert worden ist, oder das Ausgeben eines Hinweises 126 auf den bezeichneten Bereich 102, nicht in jedem Ausführungsbeispiel der Computervorrichtung 96 enthalten zu sein.The computer device 94 according to 3A and 3B may contain additional components or features that are included in the overview for clarity 3A and 3B not shown. For example, the computing device 94 Also include a microphone, a speaker, a keyboard or a variety of other devices. Further, those with respect to the computing device need 94 described components and features not necessarily in each example of the computing device 96 to be present. For example, certain with regard to the computing device 96 described features such. For example, issuing a message to the user 110 when an interaction mode has been changed, or issuing a hint 126 to the designated area 102 not in every embodiment of the computing device 96 to be included.
4 zeigt ein Schaubild einer Computervorrichtung 140, die derart konfiguriert sein kann, dass sie eine Benutzer-Eingabe zum Initiieren eines Hover-Interaktionsmodus gemäß Aspekten der vorliegenden Offenbarung empfangen kann. Gemäß einigen Beispielen kann die Computervorrichtung 140 ähnlich oder gleich der in 1 gezeigten Computervorrichtung 36, der in 2 gezeigten Computervorrichtung 76 oder der in 3A und 3B gezeigten Computervorrichtung 94 konfiguriert sein. Bei dem Beispiel gemäß 4 weist die Computervorrichtung 140 einen oder mehrere Prozessoren 144, eine Speichervorrichtung 148, einen Speicher 152 und ein Network-Interface 156 auf. Zudem weist die Computervorrichtung 140 ein Benutzer-Interface 160 mit einem berührungsempfindlichen Bildschirm 164 und einem Gesten-Detektionsmodul 168 auf. 4 shows a diagram of a computer device 140 , which may be configured to receive user input for initiating a hover interaction mode in accordance with aspects of the present disclosure. According to some examples, the computing device may 140 similar or equal to the one in 1 shown computer device 36 who in 2 shown computer device 76 or the in 3A and 3B shown computer device 94 be configured. In the example according to 4 has the computer device 140 one or more processors 144 , a storage device 148 , a store 152 and a network interface 156 on. In addition, the computer device 140 a user interface 160 with a touch-sensitive screen 164 and a gesture detection module 168 on.
Die Computervorrichtung 140 kann zusätzliche Komponenten enthalten, die aus Gründen der Übersicht in 4 nicht gezeigt sind. Beispielsweise kann die Computervorrichtung 140 auch ein Mikrophon und einen Lautsprecher enthalten, was für Beispiele gilt, bei denen die Computervorrichtung 140 zum Tätigen von Telefonanrufen in der Lage ist. Die Computervorrichtung 140 kann auch eine Batterie enthalten, die den Komponenten der Computervorrichtung 140 Energie liefert. Die Computervorrichtung 140 kann auch weitere Benutzer-Interface-Komponenten enthalten, wie z. B. eine Tastatur, einen Trackball, eine Maus oder andere derartige Benutzer-Interfaces, die einem Benutzer die Interaktion mit der Computervorrichtung 140 ermöglichen. Ferner brauchen die in 4 gezeigten Komponenten der Computervorrichtung 140 nicht notwendigerweise in jedem Beispiel der Computervorrichtung 140 vorhanden zu sein.The computer device 140 may contain additional components, for the sake of clarity in 4 not shown. For example, the computing device 140 Also included are a microphone and a speaker, which is for examples where the computer device 140 is able to make phone calls. The computer device 140 can also contain a battery, which is the components of the computer device 140 Energy supplies. The computer device 140 can also contain other user interface components, such as: A keyboard, a trackball, a mouse, or other such user interface that allows a user to interact with the computing device 140 enable. Further, in 4 shown components of the computer device 140 not necessarily in every example of the computing device 140 to be present.
In der Computervorrichtung 140 können Prozessoren 144 zum Implementieren und/oder Verarbeiten von Instruktionen konfiguriert sein. Die Prozessoren 144 können in der Lage sein, in dem Speicher 152 gespeicherte Instruktionen oder in der Speichervorrichtung 148 gespeicherte Instruktionen zu verarbeiten. Die Prozessoren 144 können ein oder mehrere Elemente unter einem Mikroprozessor, einer Steuervorrichtung, einer Digitalsignalverarbeitungsvorrichtung (DSP), einer anwendungsspezifischen integrierten Schaltung (ASIC), einem feldprogrammierbaren Gate-Array (FPGA) oder einer äquivalenten diskreten oder integrierten Logikschaltung enthalten. Zusätzlich können die Funktionen, die in dieser Offenbarung dem Prozessor 144 zugeteilt sind, als Software, Firmware, Hardware oder Kombinationen derselben realisiert sein.In the computer device 140 can processors 144 be configured to implement and / or process instructions. The processors 144 may be able to be in the store 152 stored instructions or in the storage device 148 process stored instructions. The processors 144 may include one or more elements under a microprocessor, control device, digital signal processing device (DSP), application specific integrated circuit (ASIC), field programmable gate array (FPGA), or equivalent discrete or integrated logic circuit. In addition, the functions disclosed in this disclosure may be used by the processor 144 assigned to be realized as software, firmware, hardware or combinations thereof.
Die Speichervorrichtung 148 kann ein oder mehrere computerlesbare Speichermedien enthalten. Die Speichervorrichtung 148 kann nichtflüchtige Speicherelemente enthalten. Zu den Beispielen derartiger nichtflüchtiger Speicherelemente können magnetische Festplatten, optische Platten, Floppy Discs, Flash-Speicher oder Formen elektrisch programmierbarer Speicher (EPROM) oder elektrisch löschbarer und programmierbarer Speicher (EEPROM) zählen. Zudem kann die Speichervorrichtung 148 gemäß einigen Beispielen als nicht-transitorisches Speichermedium aufgefasst werden. Der Ausdruck ”nicht-transitorisch” gibt an, dass das Speichermedium nicht in einer Trägerwelle oder einem sich ausbreitenden Signal realisiert ist. Jedoch sollte der Ausdruck ”nicht-transitorisch” nicht in dem Sinn interpretiert werden, dass die Speichervorrichtung 148 nicht beweglich wäre. Gemäß einem Beispiel kann die Speichervorrichtung 148 von der Computervorrichtung 140 entfernt werden und zu einer anderen Vorrichtung bewegt werden. Gemäß einem weiteren Beispiel kann eine Speichervorrichtung, die der Speichervorrichtung 148 im Wesentlichen ähnlich ist, in die Computervorrichtung 140 eingesetzt werden. Gemäß einigen Beispielen kann die Speichervorrichtung 148 derart konfiguriert sein, dass sie größere Informationsmengen als der Speicher 152 speichern kann. Gemäß bestimmten Beispielen kann ein nicht-transitorisches Speichermedium Daten speichern, die sich über der Zeit ändern können (z. B. in einem RAM oder Cache).The storage device 148 may contain one or more computer-readable storage media. The storage device 148 can contain nonvolatile storage elements. Examples of such nonvolatile memory elements may include magnetic hard disks, optical disks, floppy disks, flash memories, or forms of electrically programmable memory (EPROM) or electrically erasable and programmable memory Count (EEPROM). In addition, the storage device 148 according to some examples, as a non-transitory storage medium. The term "non-transitory" indicates that the storage medium is not realized in a carrier wave or a propagating signal. However, the term "non-transitory" should not be interpreted in the sense that the storage device 148 would not be movable. According to one example, the memory device 148 from the computer device 140 be removed and moved to another device. According to another example, a memory device that is the memory device 148 is substantially similar to the computing device 140 be used. According to some examples, the memory device 148 be configured to have larger amounts of information than the memory 152 can save. According to certain examples, a non-transitory storage medium may store data that may change over time (eg, in a RAM or cache).
Der Speicher 152 kann derart konfiguriert sein, dass er während des Betriebs Information in der Computervorrichtung 140 speichern kann. Gemäß einigen Beispielen lässt sich der Speicher als computerlesbares Speichermedium beschreiben. Der Speicher 152 kann als flüchtiger Speicher beschrieben werden, was bedeutet, dass der Speicher den gespeicherten Inhalt nicht beibehält, wenn der Computer ausgeschaltet wird. Zu den Beispielen flüchtiger Speicher zählen Direktzugriffsspeicher (RAM), dynamische Direktzugriffsspeicher (DRAM), statische Direktzugriffsspeicher (SRAM), und andere Formen flüchtiger Speicher, die auf dem Gebiet bekannt sind. Gemäß einigen Beispielen kann der Speicher 152 verwendet werden, um Programminstruktionen zur Ausführung durch die Prozessoren 144 zu speichern.The memory 152 may be configured to provide information in the computing device during operation 140 can save. According to some examples, the memory may be described as a computer-readable storage medium. The memory 152 may be described as volatile memory, which means that the memory will not retain the stored contents when the computer is turned off. Examples of volatile memory include Random Access Memory (RAM), Dynamic Random Access Memory (DRAM), Static Random Access Memory (SRAM), and other forms of volatile memory known in the art. According to some examples, the memory may 152 used to program instructions for execution by the processors 144 save.
Die Computervorrichtung 140 kann ein Netzwerk-Interface 156 verwenden, um über ein oder mehrere Netzwerke, wie z. B. ein oder mehrere drahtlose Netzwerke, mit externen Vorrichtungen zu kommunizieren. Das Netzwerk-Interface 156 kann eine Netzwerk-Interface-Karte wie z. B. eine Ethernet-Karte, ein optischer Transceiver, ein Funkfrequenz-Transceiver oder irgendein anderer Typ von Vorrichtung sein, der Information senden und empfangen kann. Zu den Beispielen derartiger Netzwerk-Interfaces zählen Bluetooth®, 3G- und WiFi®-Radios in mobilen Computervorrichtungen, sowie USB. Zu den Beispielen derartiger drahtloser Netzwerke zählen WiFi®, Bluetooth® und 3G. Gemäß einigen Beispielen kann die Computervorrichtung 140 das Netzwerk-Interface 156 zum drahtlosen Kommunizieren mit einer (nicht gezeigten) drahtlosen Vorrichtung verwenden, wie z. B. einem Server, einem Mobiltelefon oder einer anderen netzwerkbetriebenen Computervorrichtung.The computer device 140 can be a network interface 156 use to connect over one or more networks, such as One or more wireless networks to communicate with external devices. The network interface 156 can a network interface card such. An Ethernet card, an optical transceiver, a radio frequency transceiver, or any other type of device that can send and receive information. Examples of such network interfaces include Bluetooth ®, 3G and WiFi ® -Radios in mobile computing devices as well as USB. Examples of such wireless networks include WiFi ®, Bluetooth ® and 3G. According to some examples, the computing device may 140 the network interface 156 for wireless communication with a wireless device (not shown), such as a wireless device. A server, a mobile phone, or other network-powered computing device.
Das Benutzer-Interface (”UI”) 160 ermöglicht einem Benutzer der Computervorrichtung 140 das Interagieren mit der Computervorrichtung 140. Das UI 160 kann ein graphisches Benutzer-Interface (”GUI”) erzeugen, das einem Benutzer das Initiieren von Befehlen ermöglicht. Beispielsweise generiert gemäß einigen Aspekten der Offenbarung das UI 160 ein GUI, das auf dem berührungsempfindlichen Bildschirm (”Touch Screen”) 164 angezeigt wird. Das GUI kann ein oder mehrere berührungsempfindliche UI-Elemente enthalten. Beispielsweise kann ein Benutzer die Möglichkeit haben, mit der Computervorrichtung 140 zu interagieren und einen Befehl zu initiieren, indem er ein oder mehrere der auf dem Touch Screen 164 angezeigten berührungsempfindlichen UI-Elemente berührt.The user interface ("UI") 160 allows a user of the computing device 140 interacting with the computing device 140 , The UI 160 may generate a graphical user interface ("GUI") that allows a user to initiate commands. For example, according to some aspects of the disclosure, the UI generates 160 a GUI that's on the touch-sensitive screen ("touch screen") 164 is shown. The GUI may include one or more touch-sensitive UI elements. For example, a user may have the option of using the computing device 140 to interact and initiate a command by placing one or more of them on the touch screen 164 touched UI elements touched.
Der Touch Screen 164 kann eine Vielfalt von Anzeigevorrichtungen aufweisen, wie z. B. eine Flüssigkristallanzeige (LCD), eine e-ink-Anzeige, eine Kathodenstrahlröhre (CRT), eine Plasmaanzeige, eine Anzeige mit organischer lichtemittierender Diode (OLED) oder einen anderen Typ von Anzeigevorrichtung. Zu den Techniken, die bei diesen Vorrichtungen verwendet werden, um die Stelle einer Berührung zu detektieren, zählen mechanische Tasten, einander schneidende Infrarotlicht-Strahlen, akustische Oberflächenwellen, kapazitives Erkennen, und Widerstands-Erkennungstechniken. Der Touch Screen 164 kann gemäß einem Beispiel ein oder mehrere Signale erzeugen, die den Koordinaten einer auf dem Touch Screen 164 berührten Position entsprechen. Diese Signale können dann als Information an Komponenten der Computervorrichtung 140 ausgegeben werden, wie z. B. an Prozessoren 144.The touch screen 164 may have a variety of display devices, such. A liquid crystal display (LCD), an e-ink display, a cathode ray tube (CRT), a plasma display, an organic light emitting diode (OLED) display or other type of display. Among the techniques used in these devices to detect the location of a touch are mechanical keys, intersecting infrared light beams, surface acoustic wave, capacitive detection, and resistance detection techniques. The touch screen 164 According to one example, it may generate one or more signals corresponding to the coordinates of one on the touch screen 164 correspond to touched position. These signals may then be used as information to components of the computing device 140 are issued, such. B. to processors 144 ,
Gemäß einigen Aspekten der Offenbarung reagiert der Touch Screen 164 auf mehr als eine distinkte Berührung des Touch Screens 164 (z. B. als ”Multi-Touch-Screen”) bezeichnet. Beispielsweise kann ein Benutzer eine Touch-Geste durchführen, indem er zunächst einen Finger an einer ersten Stelle in Kontakt mit dem Touch Screen 164 platziert. Der Benutzer kann dann eine zweite Geste durchführen, indem er einen weiteren Finger an einer zweiten Stelle in Kontakt mit dem Touch Screen 164 platziert. Der Touch Screen 164 kann beide Touch-Gesten unabhängig detektieren und entsprechende Signale erzeugen. Jede unterschiedliche Geste kann einer distinkten Funktion in einer Komponente der Computervorrichtung 140 entsprechen. Beispielsweise kann mit der ersten Touch-Geste eine erste Funktion in einer Komponente der Computervorrichtung 140 durchgeführt werden. Mit der zweiten Touch-Geste, die sich von der ersten Touch-Geste unterscheidet, kann eine zweite Funktion durchgeführt werden, die sich von der ersten Funktion unterscheidet. Auf diese Weise kann der Benutzer Touch-Gesten verwenden, um eine Vielfalt von Funktionen an der Computervorrichtung 140 auszuführen.In accordance with some aspects of the disclosure, the touch screen responds 164 on more than one distinct touch of the touch screen 164 (for example referred to as "multi-touch screen"). For example, a user may make a touch gesture by first placing a finger at a first location in contact with the touch screen 164 placed. The user may then make a second gesture by placing another finger in a second location in contact with the touch screen 164 placed. The touch screen 164 can detect both touch gestures independently and generate corresponding signals. Each distinct gesture may have a distinct function in a component of the computing device 140 correspond. For example, with the first touch gesture, a first function may be in a component of the computing device 140 be performed. With the second touch gesture, which is different from the first touch gesture, a second function may be performed that differs from the first function. In this way, the user can use touch gestures to perform a variety of functions on the computing device 140 perform.
Gemäß einigen Aspekten der Offenbarung unterstützt das Gesten-Detektions-Modul 168 das Erzeugen eines Hover-Interaktionsmodus an der Computervorrichtung 140, der einem Benutzer ermöglicht, mit einem auf dem Touch Screen 164 der Computervorrichtung 140 angezeigten UI-Element zu interagieren, ohne das UI-Element zu aktivieren. Gemäß einigen Beispielen detektiert das Gesten-Detektions-Modul 168 eine erste Benutzer-Eingabe, wie z. B. eine Touch-Geste in einem bezeichneten Bereich des Touch Screen 164, und initiiert den Hover-Modus. Nachdem das Gesten-Detektions-Modul 168 den Hover-Modus initiiert hat, kann der Benutzer separat von der ersten Benutzer-Eingabe eine weitere Benutzer-Eingabe, z. B. eine zweite Touch-Geste, an einem UI-Element vornehmen, um das UI-Element zu erforschen, ohne das UI-Element zu aktivieren. In accordance with some aspects of the disclosure, the gesture detection module supports 168 generating a hover interaction mode at the computing device 140 enabling a user with one on the touch screen 164 the computer device 140 UI element to interact without activating the UI element. According to some examples, the gesture detection module detects 168 a first user input, such as. B. a touch gesture in a designated area of the touch screen 164 , and initiates the hover mode. After the gesture detection module 168 has initiated the hover mode, the user may enter another user input, e.g. A second touch gesture on a UI element to explore the UI element without activating the UI element.
Um einen Hover-Interaktionsmodus zu erzeugen, kann das Gesten-Detektions-Modul 168 mit einer Applikation (z. B. einer gerade von dem Prozessor 144 ausgeführten Anwendung) kommunizieren, die für das Erzeugen eines oder mehrerer UI-Elemente verantwortlich ist, welche auf dem Touch Screen 164 der Computervorrichtung 140 angezeigt werden. Beispielsweise kann das Gesten-Detektions-Modul 164 Signale erzeugen, die an dem Touch Screen 164 durchgeführten Touch-Gesten zugeordnet sind, und diese Signale an ein Anwendung übermitteln, bei der ein oder mehrere UI-Elemente auf dem Touch Screen 164 angezeigt werden (z. B. ein Web-Browser oder eine andere Anwendung, die ein oder mehrere UI-Elemente aufweist). Nach dem Empfang der Signale von dem Gesten-Detektions-Modul 168 kann die Anwendung die geeignete UI-Reaktion erzeugen.To generate a hover interaction mode, the gesture detection module may 168 with an application (eg one just from the processor 144 running application) that is responsible for creating one or more UI elements that are on the touch screen 164 the computer device 140 are displayed. For example, the gesture detection module 164 Generate signals on the touch screen 164 performed touch gestures are assigned, and these signals to an application, in which one or more UI elements on the touch screen 164 (for example, a web browser or other application that has one or more UI elements). After receiving the signals from the gesture detection module 168 the application can generate the appropriate UI response.
Gemäß einigen Aspekten übermittelt das Gesten-Detektions-Modul 168 an eine Anwendung ein Signal, das angibt, dass der Benutzer eine erste Touch-Geste durchgeführt hat (z. B. eine Touch-Geste in dem bezeichneten Bereich 82 gemäß 2), um einen Hover-Interaktionsmodus zu aktivieren. Das Gesten-Detektions-Modul 168 übermittelt ferner an die Anwendung ein Signal, das die relative Position der zweiten Touch-Geste repräsentiert (z. B. der Touch-Geste, die an dem UI-Element 64 gemäß 2 durchgeführt wird). Nach dem Empfangen der Signale von dem Gesten-Detektions-Modul 168 kann die Anwendung feststellen, dass ein Hover-Interaktionsmodus aktiv ist, und die Relativposition der zweiten Touch-Geste dahingehend interpretieren, dass der Hover-Inhalt generiert werden soll, der dem auf dem Touch Screen 164 in der Relativposition der zweiten Touch-Geste angezeigten UI-Element zugeordnet ist. Gemäß einigen Beispielen kann die Anwendung auch das perzeptiv nächstliegende UI-Element, das auf dem Touch Screen 164 angezeigt ist, auf der Basis der Relativposition der zweiten Touch-Geste identifizieren.In some aspects, the gesture detection module transmits 168 to an application, a signal indicating that the user has performed a first touch gesture (eg, a touch gesture in the designated area 82 according to 2 ) to activate a hover interaction mode. The gesture detection module 168 It also sends to the application a signal that represents the relative position of the second touch gesture (eg, the touch gesture on the UI element 64 according to 2 is carried out). After receiving the signals from the gesture detection module 168 For example, the application may determine that a hover interaction mode is active and interpret the relative position of the second touch gesture to generate the hover content that is on the touch screen 164 assigned in the relative position of the second touch gesture displayed UI element. According to some examples, the application may also have the perceptually closest UI element on the touch screen 164 is displayed on the basis of the relative position of the second touch gesture.
Das Gesten-Detektions-Modul 168 kann einen Hover-Modus auf verschiedene Arten erzeugen. Gemäß einem Beispiel aktiviert das Gesten-Detektions-Modul 168 einen Hover-Modus durch Identifizieren einer Single-Touch-Geste in einem bezeichneten Bereich des Touch Screen 164. Beispielsweise empfängt das Gesten-Detektions-Modul 168 von dem Touch Screen 164 eine Eingangssignal, das einem einmaligen Berühren oder ”Antippen” in einem bezeichneten Bereich des Touch Screen 164 entspricht, und initiiert einen Hover-Modus auf der Basis des Eingangssignals. Das Gesten-Detektions-Modul 168 kann den Hover-Modus deaktivieren, wenn es eine zweite Single-Touch-Geste in dem bezeichneten Bereich feststellt.The gesture detection module 168 can generate a hover mode in several ways. According to one example, the gesture detection module activates 168 a hover mode by identifying a single-touch gesture in a designated area of the touch screen 164 , For example, the gesture detection module receives 168 from the touch screen 164 an input signal that is a one touch or "tap" in a designated area of the touch screen 164 corresponds to and initiates a hover mode based on the input signal. The gesture detection module 168 can disable hover mode if it detects a second single-touch gesture in the designated area.
Gemäß einem weiteren Beispiel aktiviert das Gesten-Detektions-Modul 168 den Hover-Modus durch Identifizieren einer kontinuierlichen Berührung, die durch eine Geste in dem bezeichneten Bereich des Touch Screen 164 vorgenommen wird. Beispielsweise empfängt das Gesten-Detektions-Modul 168 von dem Touch Screen 164 ein Eingangssignal, das einer kontinuierlichen Touch-and-Hold-Geste (z. B. daraus resultierend, dass der Benutzer den Kontakt mit dem Touch Screen 164 beibehält) in einem bezeichneten Bereich des Touch Screen 164 entspricht, und initiiert einen Hover-Modus auf der Basis des Eingangssignals. Gemäß einigen Beispielen initiiert das Gesten-Detektions-Modul 168 den Hover-Modus nicht, bis ein Benutzer den Kontakt mit dem Touch Screen 164 während einer vorbestimmten Dauer beibehalten hat. Beispielsweise kann das Gesten-Detektions-Modul 168 verlangen, dass eine kontinuierliche Touch-Gesten-Eingabe von dem Touch Screen 164 eine oder mehrere Sekunden lang erfolgt, bevor es einen Hover-Modus initiiert. Das Gesten-Detektions-Modul 168 kann den Hover-Modus deaktivieren, wenn es feststellt, dass der Benutzer den Kontakt mit dem Touch Screen 164 in dem bezeichneten Bereich unterbrochen hat.As another example, the gesture detection module activates 168 the hover mode by identifying a continuous touch caused by a gesture in the designated area of the touch screen 164 is made. For example, the gesture detection module receives 168 from the touch screen 164 an input signal that is a continuous touch-and-hold gesture (eg, resulting in the user contacting the touch screen 164 maintains) in a designated area of the touch screen 164 corresponds to and initiates a hover mode based on the input signal. According to some examples, the gesture detection module initiates 168 the hover mode is not until a user makes contact with the touch screen 164 has maintained for a predetermined duration. For example, the gesture detection module 168 require a continuous touch gesture input from the touch screen 164 for one or more seconds before initiating a hover mode. The gesture detection module 168 can disable hover mode if it detects that the user is in contact with the touch screen 164 interrupted in the designated area.
Gemäß einigen Aspekten kann das Gesten-Detektions-Modul 168 den Hover-Modus deaktivieren, während der Benutzer ein UI-Element erforscht, und dadurch das UI-Element aktivieren. Beispielsweise kann das Gesten-Detektions-Modul 168 den Hover-Modus initiieren, wenn es von dem Touch Screen 164 ein Eingangssignal empfängt, das einer kontinuierlichen Touch-Geste in einem bezeichneten Bereich des Touch Screen 164 entspricht. Dementsprechend ermöglicht die Computervorrichtung 140 dem Benutzer das Interagieren mit einem oder mehreren auf dem Touch Screen 164 angezeigten UI-Elementen, ohne dass die UI-Element 64 aktiviert werden. Das Gesten-Detektions-Modul 168 kann dann von dem Touch Screen 164 ein zweites Eingangssignal empfangen, das einer zweiten Touch-Geste eines auf dem Touch Screen 164 angezeigten UI-Elements entspricht. Während des Empfangs des zweiten Eingangssignals kann der Benutzer den Kontakt mit dem Touch Screen 164 unterbrechen, was zur Folge hat, dass der Touch Screen 164 das Übermitteln des ersten Eingangssignals an das Gesten-Detektions-Modul 168 stoppt. Das Gesten-Detektions-Modul 168 kann dann den Hover-Modus deaktivieren, so dass das zweite Eingangssignal veranlasst wird, das UI-Element zu aktivieren.In some aspects, the gesture detection module may 168 disable the hover mode while the user is exploring a UI element, thereby enabling the UI element. For example, the gesture detection module 168 initiate the hover mode when it is off the touch screen 164 receives an input signal indicative of a continuous touch gesture in a designated area of the touch screen 164 equivalent. Accordingly, the computing device allows 140 the user interacting with one or more on the touch screen 164 displayed UI elements without the UI element 64 to be activated. The gesture detection module 168 can then from the touch screen 164 receive a second input signal, a second touch gesture on the touch screen 164 corresponds to the UI element displayed. During the reception of the second input signal, the user can contact the touch screen 164 interrupt, which has the result that the touch screen 164 transmitting the first input signal to the gesture detection module 168 stops. The gesture detection module 168 can then disable the hover mode so that the second input signal is made to activate the UI element.
Das Gesten-Detektions-Modul 168 kann veranlassen, dass auf dem Touch Screen 164 angezeigter Inhalt in Position gehalten oder auf der Stelle ”fixiert” wird. Beispielsweise kann nach dem Initiieren des Hover-Modus das Gesten-Detektions-Modul 168 die Fähigkeit zum Scrollen oder Neupositionieren auf dem Touch Screen 164 angezeigten Inhalts oder zum Betätigen auf dem Touch Screen 164 angezeigter UI-Elemente vorübergehend deaktivieren. In dem Hover-Modus kann das Gesten-Detektions-Modul 168 ein UI-Element identifizieren, das perzeptuell am nächsten zu der Touch-Geste eines Benutzers angeordnet ist, und die Computervorrichtung 140 dazu veranlassen, den dem nächstgelegenen UI-Element zugeordneten Hover-Inhalt anzuzeigen. Zudem kann das Gesten-Detektions-Modul 168 die Computervorrichtung 140 veranlassen, Touch-Gesten zu interpretieren, die um einen vorbestimmten Abstand oberhalb, unterhalb oder seitlich der physischen Stelle einer Touch-Geste erfolgen. Beispielsweise kann das Gesten-Detektions-Modul 168 die Computervorrichtung 140 zum Anzeigen von Hover-Inhalt veranlassen, wenn ein Benutzer auf ein UI-Element weist (z. B. mit einer Touch-Geste etwas oberhalb, unterhalb oder seitlich des UI-Elements), statt dass von dem Benutzer verlangt wird, das UI-Element zu berühren. Auf diese Weise bietet das Gesten-Detektions-Modul 168 die Möglichkeit, die Touch-Geste des Benutzers virtuell zu dem perzeptuell nahegelegensten UI-Element zu bewegen oder ”herüberschnellen” zu lassen. Gemäß einigen Beispielen kann das Gesten-Detektions-Modul 168 auch veranlassen, dass die Computervorrichtung 140 den Hover-Inhalt um einen vorbestimmten Abstand oberhalb, unterhalb oder seitlich der physischen Stelle der Benutzer-Eingabe anzeigt. Beispielsweise kann das Gesten-Detektions-Modul 168 die Computervorrichtung 76 veranlassen, den Hover-Inhalt um einen vorbestimmten Abstand oberhalb, unterhalb oder seitlich der Stelle des UI-Elements oder der physischen Stelle der Benutzer-Eingabe zu transponieren.The gesture detection module 168 can cause that on the touch screen 164 displayed content is held in place or "fixed" in place. For example, after initiating the hover mode, the gesture detection module may 168 the ability to scroll or reposition on the touch screen 164 displayed content or to press on the touch screen 164 Temporarily disable displayed UI elements. In the hover mode, the gesture detection module 168 identify a UI element that is perceptually closest to a user's touch gesture, and the computing device 140 to display the hover content associated with the nearest UI element. In addition, the gesture detection module 168 the computer device 140 cause to interpret touch gestures that occur a predetermined distance above, below, or to the side of the physical location of a touch gesture. For example, the gesture detection module 168 the computer device 140 to display hover content when a user points to a UI element (eg, with a touch gesture slightly above, below, or to the side of the UI element) instead of being prompted by the user to Touch element. This is what the gesture detection module offers 168 the ability to virtually move or "skip" the user's touch gesture to the perceptually closest UI element. According to some examples, the gesture detection module 168 also cause the computer device 140 display the hover content by a predetermined distance above, below, or to the side of the physical location of the user input. For example, the gesture detection module 168 the computer device 76 cause the hover content to be transposed a predetermined distance above, below, or to the side of the location of the UI element or the physical location of the user input.
Gemäß einigen Beispielen veranlasst das Gesten-Detektions-Modul 168 die Computervorrichtung 140 dazu, den Benutzer zu benachrichtigen, wenn ein Interaktionsmodus geändert worden ist. Beispielsweise kann das Gesten-Detektions-Modul 168 die Computervorrichtung 140 veranlassen, dem Benutzer zu signalisieren, dass ein Hover-Modus aktiv ist, indem sie ein graphisches Symbol oder Zeichen auf dem Touch Screen 164 anzeigt, einige oder sämtliche Inhalte auf dem Touch Screen 164 ändert, dem Benutzer eine haptische Rückmeldung gibt oder irgendeine Kombination dieser Aktionen durchführt. Gemäß einigen Beispielen kann das Gesten-Detektions-Modul 168 die Computervorrichtung 94 veranlassen, auf dem Touch Screen 164 einen Hinweis auf den bezeichneten Bereich zum Initiieren des Hover-Modus zu geben (z. B. das Anzeigen eines graphischen Symbols, eines Zeichens, eines farbigen Bereichs, eines pulsierenden Lichts oder Blinklichts oder eines anderen Hinweises). Es kann vorgesehen sein, dass das Gesten-Detektions-Modul 168 die Computervorrichtung 140 nur dann zur Ausgabe des Hinweises veranlassen kann, wenn der Touch Screen 164 UI-Elemente anzeigt, die einen zugeordneten Hover-Inhalt haben.According to some examples, the gesture detection module causes 168 the computer device 140 to notify the user when an interaction mode has been changed. For example, the gesture detection module 168 the computer device 140 cause the user to signal that a hover mode is active by displaying a graphic icon or character on the touch screen 164 displays some or all content on the touch screen 164 changes, gives the user a haptic feedback, or makes any combination of these actions. According to some examples, the gesture detection module 168 the computer device 94 cause, on the touch screen 164 to give an indication of the designated area for initiating the hover mode (eg, displaying a graphical symbol, a sign, a colored area, a pulsating light or flashing light, or other indication). It may be provided that the gesture detection module 168 the computer device 140 only then can cause to issue the reference when the touch screen 164 Displays UI elements that have an associated hover content.
Das Gesten-Detektions-Modul 168 kann einen bezeichneten Bereich zum Initiieren eines Hover-Modus in irgendeinem Bereich des Touch Screen 164 vorgeben (z. B. in Ecken des Touch Screen 164, entlang einer Seite des Touch Screen 164 oder in anderen Bereichen des Touch Screen 164). Das Gesten-Detektions-Modul 168 kann mit dem bezeichneten Bereich vorprogrammiert sein oder kann einem Benutzer ermöglichen, einen bevorzugten bezeichneten Bereich zu wählen. Gemäß einigen Aspekten der Offenbarung ändert das Gesten-Detektions-Modul 168 die Stelle des bezeichneten Bereichs entsprechend einer Ausrichtung der Computervorrichtung 140. Beispielsweise kann das Gesten-Detektions-Modul 168 die Stelle des bezeichneten Bereichs dynamisch derart ändern, dass unabhängig von der Ausrichtung der Computervorrichtung 140 der bezeichnete Bereich relativ zu dem Benutzer an der gleichen Position des Bildschirms verbleibt. Um die Position des bezeichneten Bereichs in Bezug auf den Benutzer beizubehalten, kann das Gesten-Detektions-Modul 168 Signale von einer Vielfalt von Computer-Komponenten empfangen, zu denen z. B. ein Gyroskop oder ein Beschleunigungsmesser zählen.The gesture detection module 168 may have a designated area for initiating a hover mode in any area of the touch screen 164 specify (eg in corners of the touch screen 164 , along one side of the touch screen 164 or in other areas of the touch screen 164 ). The gesture detection module 168 may be preprogrammed with the designated area or may allow a user to select a preferred designated area. In accordance with some aspects of the disclosure, the gesture detection module changes 168 the location of the designated area corresponding to an orientation of the computing device 140 , For example, the gesture detection module 168 dynamically change the location of the designated area such that, regardless of the orientation of the computing device 140 the designated area remains relative to the user at the same position of the screen. To maintain the position of the designated area with respect to the user, the gesture detection module may 168 Receive signals from a variety of computer components, including, for. As a gyroscope or an accelerometer count.
Das Gesten-Detektions-Modul 168 ist anhand von 4 dahingehend beschrieben, dass es einen bezeichneten Bereich zum Empfang einer Touch-Geste zwecks Initiierens eines Hover-Modus vorsieht. Gemäß weiteren Beispielen jedoch können das Gesten-Detektions-Modul 168 und die Computervorrichtung 140 einen Hover-Modus mittels einer Vielfalt anderer Benutzer-Eingaben oder einer Kombination von Benutzer-Eingaben initialisieren. Beispielsweise kann das Gesten-Detektions-Modul 168 derart konfiguriert sein, dass es zum Initiieren eines Hover-Modus eine Eingabe von einer speziell zugewiesenen Taste empfängt, die an der Computervorrichtung 140 angeordnet ist. Alternativ oder zusätzlich können das Gesten-Detektions-Modul 168 und die Computervorrichtung 140 eine software-basierte Option (z. B. ein Menü eines UI) bieten, die einem Benutzer das Wählen oder Abwählen eines Hover-Modus ermöglicht. Gemäß weiteren Beispielen kann das Gesten-Detektions-Modul 168 Signale von einem Gyroskop, einem Beschleunigungsmesser oder einer Vielfalt anderer Benutzer-Eingabevorrichtungen empfangen, um einen Hover-Modus zu initiieren.The gesture detection module 168 is based on 4 is described as providing a designated area for receiving a touch gesture for initiating a hover mode. However, according to further examples, the gesture detection module 168 and the computer device 140 initialize a hover mode using a variety of other user inputs or a combination of user inputs. For example, the gesture detection module 168 configured to receive an input from a dedicated dedicated key on the computing device to initiate a hover mode 140 is arranged. Alternatively or additionally, the gesture detection module 168 and the computer device 140 provide a software-based option (such as a menu of a UI) that allows a user to dial or deselect a user Hover mode allows. According to further examples, the gesture detection module 168 Receive signals from a gyroscope, an accelerometer, or a variety of other user input devices to initiate a hover mode.
Bei dem Beispiel gemäß 4 ist das Gesten-Detektions-Modul 168 als ein separates Modul gezeigt, das in das UI 160 einbezogen ist. Gemäß weiteren Beispielen jedoch können die dem Gesten-Detektions-Modul 168 zugewiesenen Funktionen von anderen Komponenten der Computervorrichtung 140 ausgeführt werden, wie z. B. von den Prozessoren 144 und dem Speicher 152. Die dem Gesten-Detektions-Modul 168 zugewiesenen Funktionen können auch durch Implementieren von Software, Firmware, Hardware oder eine beliebige Kombination derselben ausgeführt werden. Beispielsweise kann das Gesten-Detektions-Modul 168 eine oder mehrere Elemente unter einem Mikroprozessor, einer Steuervorrichtung, einem Digitalsignalprozessor (DSP), einer anwendungsspezifischen integrierten Schaltung (ASIC), einem feldprogrammierbaren Gate-Array (FPGA) oder einer äquivalenten diskreten oder integrierten Logikschaltung enthalten.In the example according to 4 is the gesture detection module 168 shown as a separate module in the UI 160 is involved. However, according to other examples, the gesture detection module 168 assigned functions of other components of the computing device 140 be executed, such. From the processors 144 and the memory 152 , The gesture detection module 168 Assigned functions may also be performed by implementing software, firmware, hardware, or any combination thereof. For example, the gesture detection module 168 include one or more elements under a microprocessor, control device, digital signal processor (DSP), application specific integrated circuit (ASIC), field programmable gate array (FPGA), or equivalent discrete or integrated logic circuit.
5 zeigt ein Flussdiagramm zur Veranschaulichung eines gemäß Aspekten der vorliegenden Offenbarung vorgesehenen Verfahrens 190 zum Bereitstellen einer Hover-Funktionalität in einer Vorrichtung mit einem Touch Screen. Obwohl dieses zur beispielhaften Erläuterung im Zusammenhang mit der Computervorrichtung 140 gemäß 4 beschrieben wird, sollte ersichtlich sein, dass das Verfahren 190 gemäß 5 auch mittels einer Vielfalt anderer Computervorrichtungen oder Verarbeitungseinheiten ausgeführt werden kann. Beispielsweise kann das Verfahren 190 gemäß 5 auch von der Computervorrichtung 36 gemäß 1, der Computervorrichtung 76 gemäß 2 oder der Computervorrichtung 94 gemäß 3A und 3B ausgeführt werden. 5 FIG. 12 is a flowchart illustrating a method provided in accordance with aspects of the present disclosure. FIG 190 for providing a hover functionality in a device with a touch screen. Although this is illustrative in the context of the computing device 140 according to 4 should be apparent that the procedure 190 according to 5 can also be performed by a variety of other computer devices or processing units. For example, the method 190 according to 5 also from the computer device 36 according to 1 , the computer device 76 according to 2 or the computer device 94 according to 3A and 3B be executed.
Gemäß dem in 5 gezeigten Beispiel detektiert die Computervorrichtung 140 anfangs eine erste Benutzer-Eingabe, um die Hover-Funktionalität bereitzustellen (192). Gemäß einigen Beispielen detektiert die Computervorrichtung 140 eine erste Touch-Geste, die von einem Benutzer durchgeführt wird, indem er den Touch Screen 164 der Computervorrichtung 140 berührt. Die Computervorrichtung 140 kann einen bestimmten Bereich auf dem Touch Screen 164 für das Empfangen der ersten Touch-Geste reservieren. Beispielsweise kann gemäß 2 und 3A und 3B ein bezeichneter Bereich in einer Ecke des Touch Screen 164 positioniert werden. Bei der ersten Benutzer-Eingabe kann es sich um eine Single-Touch-Geste oder eine kontinuierliche Touch-Geste handeln.According to the in 5 The example shown detects the computer device 140 initially a first user input to provide the hover functionality ( 192 ). According to some examples, the computing device detects 140 a first touch gesture performed by a user while holding the touch screen 164 the computer device 140 touched. The computer device 140 can a certain area on the touch screen 164 reserve for receiving the first touch gesture. For example, according to 2 and 3A and 3B a designated area in a corner of the touch screen 164 be positioned. The first user input may be a single-touch gesture or a continuous touch gesture.
Die Computervorrichtung 140 reagiert auf die erste Benutzer-Eingabe, indem sie einen Hover-Interaktionsmodus initiiert (194). Beispielsweise ermöglicht ein Hover-Modus einem Benutzer, mit einem oder mehreren der auf dem Touch Screen 164 angezeigten UI-Elementen zu interagieren, ohne dass die UI-Elemente aktiviert werden. Zu den Beispielen von Hover-Inhalt und -Funktionen, die den UI-Elementen zugeordnet sind, zählen ein Highlighting oder anderweitiges Verändern von Text des UI-Elements, um dem Benutzer mitzuteilen, dass das UI-Element aktiviert werden kann, das Initialisieren eines Preview-Fensters, das dem UI-Element zugeordneten Inhalt enthält, das Anzeigen eines Preview-Fensters, oder das Initialisieren neuen Inhalts wie z. B. eines ”Tool-Tip”-Fensters zur Anzeige.The computer device 140 responds to the first user input by initiating a hover interaction mode ( 194 ). For example, a hover mode allows a user to interact with one or more of the touch screen 164 UI elements that interact with the UI elements without activating the UI elements. Examples of hover content and functions associated with the UI elements include highlighting or otherwise modifying text of the UI element to inform the user that the UI element can be activated, initializing a preview Window containing content associated with the UI element, displaying a preview window, or initializing new content, such as B. a "Tool-Tip" window for display.
Nachdem die Computervorrichtung 140 den Hover-Modus initiiert hat, kann die Computervorrichtung 140 eine zweite Benutzer-Eingabe detektieren, die sich von der ersten Benutzer-Eingabe unterscheidet (196). Beispielsweise kann der Touch Screen 164 ein Multi-Touch-Screen sein, der in der Lage ist, mehr als eine Touch-Geste gleichzeitig zu empfangen und zu identifizieren. Gemäß einigen Aspekten der Offenbarung kann die Computervorrichtung 140 an einem UI-Element, das auf dem Touch Screen 164 angezeigten Hover-Inhalt enthält, eine zweite Touch-Geste empfangen, die sich von der ersten Touch-Geste unterscheidet.After the computer device 140 initiated the hover mode, the computing device 140 detect a second user input that differs from the first user input ( 196 ). For example, the touch screen 164 a multi-touch screen able to simultaneously receive and identify more than one touch gesture. According to some aspects of the disclosure, the computing device may 140 at a UI element on the touch screen 164 displayed hover content receives a second touch gesture, which differs from the first touch gesture.
Nach dem Detektieren der zweiten Benutzer-Eingabe triggert die Computervorrichtung 140 eine Interaktion mit dem UI-Element, ohne dass das UI-Element aktiviert wird (198). Beispielsweise gibt die Computervorrichtung 140 dem UI-Element zugeordneten Hover-Inhalt aus, ohne das UI-Element zu aktivieren. Gemäß einigen Aspekten der Offenbarung hält ein Benutzer die erste Benutzer-Eingabe aufrecht, während er die zweite Benutzer-Eingabe durchführt, um mit dem UI-Element zu interagieren, ohne dass das UI-Element aktiviert wird.Upon detecting the second user input, the computing device triggers 140 an interaction with the UI element without activating the UI element ( 198 ). For example, the computing device gives 140 hover content associated with the UI element without enabling the UI element. In accordance with some aspects of the disclosure, a user maintains the first user input while performing the second user input to interact with the UI element without activating the UI element.
Es sollte ersichtlich sein, dass Aspekte der Offenbarung generell das Detektieren einer ersten Benutzer-Eingabe, das Detektieren einer zweiten Benutzer-Eingabe und das Initiieren eines Interaktionsmodus auf der Basis der ersten Benutzer-Eingabe umfassen, wobei die zweite Benutzer-Eingabe eine Interaktion mit einem Benutzer-Interface-Element initiiert, ohne das Benutzer-Interface-Element zu aktivieren. Dies bedeutet, dass das Verfahren 190 lediglich als ein Beispiel angeführt wird und die anhand von 5 beschriebenen und wiedergegebenen Schritte auch in anderer Reihenfolge ausgeführt werden können. Beispielsweise kann die Computervorrichtung 140 anfangs die zweite Benutzer-Eingabe an einem UI-Element detektieren. Die Computervorrichtung 140 kann dann die erste Benutzer-Eingabe detektieren und einen Hover-Interaktionsmodus initiieren. Ferner können mehrere Schritte des Verfahrens 190 gleichzeitig ausgeführt werden. Beispielsweise kann die Computervorrichtung 140 anfangs die erste Benutzer-Eingabe detektieren und den Hover-Interaktionsmodus initiieren und, während sie die erste Benutzer-Eingabe detektiert, die zweite Benutzer-Eingabe detektieren, die sich von der ersten Benutzer-Eingabe unterscheidet. Alternativ kann die Computervorrichtung 140 anfangs die zweite Benutzer-Eingabe an einem UI-Element detektieren und, während sie die zweite Benutzer-Eingabe detektiert, die erste Benutzer-Eingabe detektieren und den Hover-Interaktionsmodus initiieren.It should be appreciated that aspects of the disclosure generally include detecting a first user input, detecting a second user input, and initiating an interaction mode based on the first user input, the second user input interacting with a user input User interface element initiated without activating the user interface element. This means that the procedure 190 merely cited as an example and based on 5 described and reproduced steps can also be performed in a different order. For example, the computing device 140 initially detect the second user input to a UI element. The computer device 140 can then detect the first user input and a hover interaction mode initiate. Further, several steps of the method 190 be executed simultaneously. For example, the computing device 140 initially detect the first user input and initiate the hover interaction mode and, while detecting the first user input, detect the second user input that is different from the first user input. Alternatively, the computing device 140 initially detecting the second user input on a UI element and, while detecting the second user input, detecting the first user input and initiating the hover interaction mode.
Gemäß einem oder mehreren Beispielen können die beschriebenen Funktionen in Hardware, Software, Firmware oder einer beliebigen Kombination derselben implementiert werden. Bei Implementierung in Software können die Instruktionen auf einem computerlesbaren Medium gespeichert oder in Form einer oder mehrerer Instruktionen oder eines Code über dieses Medium übermittelt werden und von einer hardware-basierten Verarbeitungseinheit ausgeführt werden. Zu den computerlesbaren Medien können computerlesbare Speichermedien, was einem fassbaren Medium wie z. B. einem Datenaufzeichnungsmedium entspricht, oder Kommunikationsmedien zählen, zu denen jegliches Medium gehört, das die Übertragung eines Computerprogramms von einer Stelle zu einer anderen erleichtert, z. B. gemäß einem Kommunikationsprotokoll. Somit können computerlesbare Medien generell (1) fassbaren computerlesbaren Speichermedien, die nicht transitorisch sind, oder (2) einem Kommunikationsmedium wie z. B. einer Signal- oder Trägerwelle entsprechen. Bei den Datenspeichermedien kann es sich um jedes verfügbares Medium, das für den Zugriff durch einen oder mehrere Prozessoren zwecks Abrufs von Instruktionen geeignet ist, um Codes und/oder um Datenstrukturen zum Implementieren der in dieser Offenbarung beschriebenen Techniken handeln. Ein Computerprogrammprodukt kann ein computerlesbares Speichermedium enthalten.According to one or more examples, the described functions may be implemented in hardware, software, firmware, or any combination thereof. When implemented in software, the instructions may be stored on a computer-readable medium or transmitted in the form of one or more instructions or code over that medium and executed by a hardware-based processing unit. Computer-readable media may include computer-readable storage media, which may be a tangible medium such as a computer-readable medium. B. a data recording medium, or include communication media to which any medium that facilitates the transfer of a computer program from one location to another, for. B. according to a communication protocol. Thus, computer-readable media may generally include (1) tangible computer-readable storage media that is non-transitory, or (2) a communication medium, such as a computer. B. correspond to a signal or carrier wave. The data storage media may be any available medium that is suitable for access by one or more processors to retrieve instructions, codes, and / or data structures for implementing the techniques described in this disclosure. A computer program product may include a computer readable storage medium.
Beispielsweise – und nicht im Sinn einer Beschränkung – können derartige computerlesbare Speichermedien RAM-, ROM-, EEPROM-, CD-ROM- oder andere Optikplattenspeicher, Magnetplattenspeicher oder andere magnetische Speichervorrichtungen, Flash-Speicher oder jedes andere Medium umfassen, das zum Speichern eines gewünschten Programmcodes in Form von Instruktionen oder Datenstrukturen geeignet ist und auf das mittels eines Computers zugegriffen werden kann. Ferner ist jede Verbindung korrekt als computerlesbares Medium bezeichnet. Falls beispielsweise Instruktionen von einer Webseite, einem Server oder einer anderen entfernten Quelle mittels eines Koaxialkabels, eines faseroptischen Kabels, eines Twisted-Pair-Kabels, einer digitalen Teilnehmerleitung (DSL) oder mittels Drahtlos-Technologien wie z. B. Infrarot, Funk und Mikrowellen übertragen werden, dann sind die Koaxialkabel-, Faseroptik-Kabel-, Twisted-Pair-, DSL- oder Drahtlos-Technologien wie Infrarot, Funk und Mikrowellen in der Definition des Mediums enthalten. Es sollte sich jedoch verstehen, dass computerlesbare Speichermedien und Datenspeichermedien keine Verbindungen, Trägerwellen, Signale oder andere transitorische Medien enthalten, sondern nicht-transitorische, fassbare Speichermedien betreffen. Zu den Platten und Disks zählen in der hier vorliegenden Verwendung eine Compact Disc (CD), eine Laser-Disc, eine optische Platte, eine Digital Versatile Disc (DVD), eine Floppy Disk und eine Blue-Ray-Disk, wobei Platten normalerweise die Daten magnetisch wiedergeben, während bei Discs die Daten optische mittels Laserstrahlen reproduziert werden. Unter den Umfang computerlesbarer Medien fallen auch Kombinationen der vorstehend genannten.By way of example and not by limitation, such computer readable storage media may include RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, flash memory or any other medium capable of storing a desired one Program codes in the form of instructions or data structures is suitable and can be accessed by means of a computer. Furthermore, each connection is correctly labeled as a computer-readable medium. For example, if instructions from a web page, server, or other remote source are provided by means of a coaxial cable, a fiber optic cable, a twisted pair cable, a digital subscriber line (DSL), or wireless technologies such as wireless LAN. As infrared, radio and microwaves are transmitted, then the coaxial cable, fiber optic cable, twisted pair, DSL or wireless technologies such as infrared, radio and microwaves are included in the definition of the medium. It should be understood, however, that computer-readable storage media and data storage media do not include connections, carrier waves, signals, or other transitory media, but rather relate to non-transitory, tangible storage media. The discs and discs as used herein include a compact disc (CD), a laser disc, an optical disc, a digital versatile disc (DVD), a floppy disc, and a blue-ray disc, which discs are typically the Magnetically reproduce data, while in discs the data are reproduced optically by means of laser beams. The scope of computer-readable media also includes combinations of the foregoing.
Instruktionen können mittels eines oder mehrerer Prozessoren ausgeführt werden, wie z. B. mittels eines oder mehrerer Digitalsignalprozessoren (DSPs), Allzweck-Mikroprozessoren, anwendungsspezifischer integrierter Schaltungen (ASICs), feldprogrammierbarer Logik-Array (FPGAs) oder anderen äquivalenten integrierten oder diskreten Logikschaltungen. Dementsprechend kann sich der Ausdruck ”Prozessor” in der hier vorliegenden Verwendung auf jede der vorstehend genannten Strukturen oder jegliche andere Struktur beziehen, die zur Implementierung der hier beschriebenen Techniken geeignet ist. Zudem kann gemäß einigen Aspekten die hier beschriebene Funktionalität in speziell vorgesehenen Hardware- und/oder Software-Modulen vorgesehen sein, die zum Kodieren und Dekodieren konfiguriert sind, oder in einen kombinierten Codec einbezogen sein. Ferner könnten die Techniken voll in einer oder mehreren Schaltungen oder Logik-Elementen implementiert sein.Instructions may be executed by one or more processors, such as: By means of one or more digital signal processors (DSPs), general purpose microprocessors, application specific integrated circuits (ASICs), field programmable logic arrays (FPGAs) or other equivalent integrated or discrete logic circuits. Accordingly, the term "processor" as used herein may refer to any of the foregoing structures or any other structure suitable for implementing the techniques described herein. Additionally, in some aspects, the functionality described herein may be provided in dedicated hardware and / or software modules configured for encoding and decoding, or included in a combined codec. Furthermore, the techniques could be fully implemented in one or more circuits or logic elements.
Die Techniken dieser Offenbarung können in einer breiten Vielfalt von Vorrichtungen oder Geräten implementiert sein, zu denen ein Drahtlos-Handset, eine integrierte Schaltung (IC) oder ein Set von ICs (z. B. ein Chip-Set) zählen. Es wurden in dieser Offenbarung verschiedene Komponenten, Module oder Einheiten beschrieben, um funktionale Aspekte von Vorrichtungen herauszustellen, die zum Ausführen der offenbarten Techniken konfiguriert sind, jedoch brauchen diese Komponenten, Module oder Einheiten nicht notwendigerweise durch verschiedene Hardware-Einheiten realisiert zu sein. Vielmehr können, wie oben beschrieben, verschiedene Einheiten in einer Codec-Hardware-Einheit kombiniert sein oder durch als Sammlung interoperativer Hardware-Einheiten vorgesehen sein, zu denen ein oder mehrere Prozessoren gemäß der obigen Beschreibung in Verbindung mit geeigneter Software und/oder Firmware zählen.The techniques of this disclosure may be implemented in a wide variety of devices or devices, including a wireless handset, an integrated circuit (IC), or a set of ICs (eg, a chip set). Various components, modules, or units have been described in this disclosure to highlight functional aspects of devices configured to practice the disclosed techniques, but these components, modules, or devices may not necessarily be implemented by various hardware devices. Rather, as described above, various units may be combined in a codec hardware unit or provided as a collection of interoperable hardware units, including one or more processors as described above in conjunction with appropriate software and / or firmware.
Es sind verschiedene Aspekte der Offenbarung beschrieben worden. Diese und weitere Aspekte liegen innerhalb des Umfangs der folgenden Ansprüche.Various aspects of the disclosure have been described. These and other aspects are within the scope of the following claims.