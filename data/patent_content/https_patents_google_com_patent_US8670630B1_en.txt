US8670630B1 - Fast randomized multi-scale energy minimization for image processing - Google Patents
Fast randomized multi-scale energy minimization for image processing Download PDFInfo
- Publication number
- US8670630B1 US8670630B1 US13/308,836 US201113308836A US8670630B1 US 8670630 B1 US8670630 B1 US 8670630B1 US 201113308836 A US201113308836 A US 201113308836A US 8670630 B1 US8670630 B1 US 8670630B1
- Authority
- US
- United States
- Prior art keywords
- image
- labels
- low resolution
- input images
- label map
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 238000012545 processing Methods 0.000 title abstract description 72
- 238000000034 method Methods 0.000 claims abstract description 61
- 238000004590 computer program Methods 0.000 claims description 13
- 230000002708 enhancing effect Effects 0.000 claims description 9
- 238000007781 pre-processing Methods 0.000 claims description 4
- 238000007670 refining Methods 0.000 claims 6
- 230000008569 process Effects 0.000 abstract description 34
- 230000006870 function Effects 0.000 description 41
- 238000010586 diagram Methods 0.000 description 8
- 238000013459 approach Methods 0.000 description 7
- 238000001914 filtration Methods 0.000 description 5
- 238000002372 labelling Methods 0.000 description 4
- 238000005429 filling process Methods 0.000 description 3
- 238000005457 optimization Methods 0.000 description 3
- 230000000007 visual effect Effects 0.000 description 3
- 230000008901 benefit Effects 0.000 description 2
- 239000003086 colorant Substances 0.000 description 2
- 238000013507 mapping Methods 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 238000009472 formulation Methods 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 230000008520 organization Effects 0.000 description 1
- 230000002194 synthesizing effect Effects 0.000 description 1
Images
Classifications
-
- G06T5/77—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T15/00—3D [Three Dimensional] image rendering
- G06T15/10—Geometric effects
- G06T15/20—Perspective computation
- G06T15/205—Image-based rendering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T3/00—Geometric image transformation in the plane of the image
- G06T3/40—Scaling the whole image or part thereof
- G06T3/4053—Super resolution, i.e. output image resolution higher than sensor resolution
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/50—Depth or shape recovery
- G06T7/55—Depth or shape recovery from multiple images
- G06T7/593—Depth or shape recovery from multiple images from stereo images
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20016—Hierarchical, coarse-to-fine, multiscale or multiresolution image processing; Pyramid transform
Definitions
- This invention generally relates to image processing and more specifically to enhancing images.
- map applications often provide views of the surrounding area for a given map location and contain many images of streets and buildings, sometimes obtained from multiple sources, such as aerial and ground photos. Such images may be taken from a large distance, thereby providing broad coverage, but resulting in a lack of the resolution needed to provide a user with fine detail.
- these images often include “holes,” i.e., missing or obscured portions of the object or scene depicted in the image. As a result, these systems provide users with image data of less than desirable quality.
- Some image processing systems apply optimization techniques to automatically enhance images, thereby improving quality of the available image data.
- traditional techniques are very slow.
- a first embodiment comprises a method for enhancing an image.
- a low resolution version of the one or more input images is generated.
- a low resolution label map (corresponding to an intermediate processing stage) is generated corresponding to the low resolution versions of the one or more input images.
- Each label in the low resolution label map corresponds to an output pixel position and each label points to a pixel position in the low resolution version of the one or more input images.
- An output label map corresponding to a high resolution output image is initialized using initial labels determined based on the low resolution label map.
- the output label map is refined to minimize an energy function.
- the high resolution output image is generated by copying pixels from the one or more input images according to the output label map.
- the high resolution output image is stored to a storage medium.
- a second embodiment comprises a non-transitory computer-readable storage medium storing computer executable computer program instructions for enhancing an image.
- the computer program instructions comprise instructions for generating a low resolution version of the one or more input images is generated.
- a low resolution label map is generated corresponding to the low resolution versions of the one or more input images.
- Each label in the low resolution label map corresponds to an output pixel position and each label points to a pixel position in the low resolution version of the one or more input images.
- An output label map corresponding to a high resolution output image is initialized using initial labels determined based on the low resolution label map.
- the output label map is refined to minimize an energy function.
- the high resolution output image is generated by copying pixels from the one or more input images according to the output label map.
- the high resolution output image is stored to a storage medium.
- a third embodiment comprises a computer system for enhancing an image.
- the computer system includes a computer-readable storage medium storing executable computer program instructions.
- the computer program instructions comprise instructions for generating a low resolution version of the one or more input images is generated.
- a low resolution label map is generated corresponding to the low resolution versions of the one or more input images.
- Each label in the low resolution label map corresponds to an output pixel position and each label points to a pixel position in the low resolution version of the one or more input images.
- An output label map corresponding to a high resolution output image is initialized using initial labels determined based on the low resolution label map.
- the output label map is refined to minimize an energy function.
- the high resolution output image is generated by copying pixels from the one or more input images according to the output label map.
- the high resolution output image is stored to a storage medium.
- the computer system further comprises a processor configured to execute the computer program instructions stored on the computer-readable storage medium.
- FIG. 1 is a high-level block diagram of an image processing server according to one embodiment.
- FIG. 2 is a block diagram of an image processing module according to one embodiment.
- FIG. 3 is a flowchart illustrating a process for enhancing an image via hole-filling according to one embodiment.
- FIG. 4 is a diagram illustrating a hole-filling process for an example image, according to one embodiment.
- FIG. 5 is a diagram illustrating a technique for determining a smoothness cost according to one embodiment.
- FIG. 6A is a flowchart illustrating a downsampling phase of a multi-scale energy minimization process according to one embodiment.
- FIG. 6B is a flowchart illustrating an upsampling phase of a multi-scale energy minimization process according to one embodiment.
- FIG. 7 is a diagram illustrating a set of example images and corresponding label maps enhanced via hole-filling according to one embodiment.
- FIG. 8 is a flowchart illustrating a process for image enhancement via super-resolution according to one embodiment.
- FIG. 9 is a computer for use as the image processing server according to one embodiment.
- FIG. 1 is a high-level block diagram of an image processing server 100 according to one embodiment.
- the server 100 includes an image processing module 110 and an image database 120 . Only one server 100 , image processing module 110 , and image database 120 are shown in FIG. 1 in order to simplify and clarify the description. Embodiments can have multiple ones of these entities. Moreover, the entities can be distributed across multiple machines. For example, the image processing module 110 and database 120 can be distributed across multiple servers.
- the image database 120 stores a set of images.
- image as employed herein includes image data in general, such as individual still image files or frames from a video file.
- An image I comprises a two-dimensional array of pixels.
- the images in the image database 120 may be obtained from a variety of sources.
- the images are obtained from an organization that produces aerial or street view images of a portion of a city for use with a map system, such as GOOGLE MAPS, GOOGLE STREET VIEW or GOOGLE EARTH.
- images may be obtained from users, e.g. as submitted by a user uploading images to a photo repository such as PICASA WEB, or a video repository such as YOUTUBE or GOOGLE VIDEO.
- these images vary in image quality depending on the locations from where the images were taken, the hardware used to capture the images, the fields of view shown by the images, the weather when the images were captured, the times of day that the images were captured, and other factors.
- the images in the image database 120 may include undesirable characteristics such as holes (portions of the image that are missing or obscured) resulting from how the images were captured and/or processed.
- some images may have lower resolution than is desired for the intended uses of the images.
- the image database 120 may also store enhanced versions of the images.
- the enhanced version of an image lacks one or more of the undesirable characteristics present in the original image. For example, an enhanced version of an image having a hole (e.g., an occluded portion of an object depicted in the image) lacks the hole. Likewise, an enhanced version of an image having low resolution has increased resolution.
- the image processing module 110 processes the original unenhanced images in the image database 120 to produce enhanced versions of the images.
- the image processing module 110 performs image enhancement using a labeling approach.
- the image processing module 110 generates the enhanced output image by creating a label map that maps each pixel location in an enhanced output image to a pixel location in one or more input images (e.g., from the image database 120 ).
- the image processing module 110 then synthesizes the output image by copying the pixel values (e.g., RGB color values) from the designated input image pixel locations to the output image according to the labels.
- the image processing chooses the labels such that they minimize an energy (cost) function defined on an image that is configured to achieve the desired enhancement. Examples of energy functions for various applications will be described in further detail below.
- FIG. 2 is a block diagram of an example embodiment of the image processing module 110 .
- the image processing module 110 comprises a downsampling module 202 , an upsampling module 204 , a candidate label selection module 206 , an energy optimization module 208 , and an image generation module 210 .
- Alternative embodiments of the image processing module 110 have different and/or additional modules than the ones described here. Similarly, the functions can be distributed among the modules in a different manner than is described here.
- the downsampling module 202 performs downsampling of an image to generate a lower resolution version of the image.
- the downsampling module 202 further applies filtering to downsampled images in order to provide a smoother appearance to the downsampled image.
- the upsampling module 204 upsamples images to generate a higher resolution version of the image.
- an interpolation filter adds additional pixels to an image and infers their values in a manner that is visually consistent.
- the upsampling module 204 upsamples label maps instead of operating directly on the images.
- the upsampling module 204 generates a higher resolution label map from a lower resolution label map and infers the label values based on the energy function.
- the downsampling module 202 and upsampling module 204 may be utilized in a multi-scale process to enables fast minimization of the energy function for the enhanced output image.
- the downsampling module 202 first progressively downsamples input images to create a plurality of images of varying resolution.
- the upsampling module 202 then progressively generates label maps for each downsampled image beginning with the coarsest image.
- the label map is initialized based on the labels from the previous lower resolution label map, and then iteratively refined to further improve the energy function.
- the multi-scale minimization process will be described in further detail below with reference to FIGS. 6-7 .
- the candidate label selection module 206 applies various techniques to choose a set of candidate labels for each pixel position in the label map.
- the candidate label selection module 206 may determine candidate labels based on, for example, spatial proximity, pixel (color) similarity, and/or a randomized function. The particular criteria applied to select candidate labels may vary depending on the type of enhancement being performed.
- the energy optimization module 208 applies an energy function to choose the candidate label from the set of candidate labels that best minimizes the energy function. Specific techniques for finding candidate labels and selecting candidate labels to minimize an energy function are described in further detail below.
- the image generation module 210 generates an output image by copying pixels from the one or more input images according to the label map.
- the output image is an enhanced version of the input image.
- the image processing server 100 can be utilized to enhance images in variety of different ways. By utilizing different energy functions, the image processing server 100 can enhance different characteristics of an input image to generate an enhanced output image. For example, in one application, the image processing module 110 fills holes in an input image with pixels that estimate the actual appearance of the missing or occluded portions of the image. Thus, in the hole-filling application, the energy function is defined such that the enhanced output image will have the holes filled in a manner that is appears visually realistic and estimates the actual appearance of the missing or occluded portions of the image. In another application, the image processing module 110 generates a super-resolved output image that accurately represents the low resolution input image.
- the energy function is defined such that the enhanced output image will be a high resolution image that is visually consistent with the low resolution input image.
- Example processes for hole-filling and super-resolution image enhancement are described in further detail below with reference to FIGS. 3-8 .
- An image of an object (e.g., a building) or scene may contain one or more “holes.”
- a hole is a region of pixels of the image that meet a certain set of conditions.
- a brightness thresholding technique may be used to detect holes where pixels are compared against a threshold and pixels having brightness values below the threshold are deemed hole pixels.
- the threshold is set such that only pixels having zero brightness are deemed hole pixels (e.g., (0, 0, 0) in a RGB color space).
- a region meets these conditions when the region's visual appearance does not accurately reflect the true appearance of the object or scene.
- a hole may appear in areas where the object is partially occluded. Generally, a hole appears as a dark region in an image.
- An original image may be enhanced by replacing a region of pixels corresponding to a hole with other pixels that better estimate the true appearance of the object.
- hole-filling should be done in a way that looks plausible to a human viewer.
- the filled regions should appear seamless at boundaries and should visually match the appearance of the rest of the image.
- the image processing module 110 generates an output image that appears identical or similar to the input image in the non-hole regions, and includes synthesized pixels that fill the holes and estimate the actual appearance of the object in the image in a manner that appears visually realistic to a human viewer.
- FIG. 3 illustrates an embodiment of a hole-filling process for generating a enhanced output image based on an original input image.
- the image processing module 110 receives 302 the original image/with one or more holes for filling.
- the image processing module 110 then identifies 304 holes in the original input image (e.g., by the locations of the pixels that form the hole). For example in one embodiment, the image processing module 110 identifies, for each pixel I(x,y) in the original image I, whether or not the pixel is located within a hole region of the image.
- the image processing module 110 creates and stores a hole mask identifying the locations of the hole(s).
- the hole mask may comprise a two-dimensional array with each element in the array corresponding to a pixel and storing a binary value indicating whether or not the corresponding pixel is a hole pixel.
- the image processing module 110 then creates 306 a label map that maps each pixel location in an output image to a pixel location in the original, choosing the labels such that an energy function is minimized.
- the enhanced output image is then synthesized 308 by copying the pixels from the original image to the output image according to the labels.
- the enhanced output image is then stored 310 to a storage medium (e.g., image database 120 ).
- FIG. 4 illustrates a visual representation of the hole-filling process described above for an example 5 ⁇ 5 image.
- the original image 402 comprises a 5 ⁇ 5 array of pixels with each pixel given by I(x,y).
- a hole region 406 is identified in FIG. 4 by the shaded pixels (e.g., including pixels I(2,5), I(3,4), I(3,5), I(4,3), I(4,4), I(4,5)).
- the image processing module 110 generates the label map 404 .
- the energy function is generally configured such that hole pixel locations will map to a non-hole location.
- hole locations in the output image are filled by copying pixels from non-hole locations in the original image.
- the specific pixels chosen to fill hole locations in the output image are selected to optimize the smoothness of the visual appearance of output image.
- an energy function E having the above described characteristics for a label map L is defined as:
- E ⁇ ( L ) ⁇ p ⁇ DC ⁇ ( L p ) + ⁇ p , q ⁇ SC ⁇ ( L p , L q ) ( 1 )
- L p is a label for a pixel position p
- L q is a label for a pixel position q that is in the neighborhood of p
- DC is a data cost
- SC is a smoothness cost.
- DC ⁇ ( L p ) ⁇ 0 ⁇ ⁇ if ⁇ ⁇ L p ⁇ ⁇ points ⁇ ⁇ to ⁇ ⁇ a ⁇ ⁇ “ valid ” ⁇ ⁇ location ⁇ ⁇ ( not ⁇ ⁇ a ⁇ ⁇ hole ⁇ ⁇ and ⁇ within ⁇ ⁇ image ⁇ ⁇ boundaries ) ⁇ ⁇ ⁇ if ⁇ ⁇ L p ⁇ ⁇ points ⁇ ⁇ to ⁇ ⁇ a ⁇ ⁇ hole ⁇ ⁇ location ( 2 )
- the data cost is zero (or other predefined minimum value) if L p points to a valid location, or otherwise infinite (or other predefined maximum value).
- a “valid” pixel location refers to a location that is within the boundary of the original image and is not a hole location.
- the data cost component will be zero only if all labels in the label map are valid, and will otherwise be infinite. In this way, minimizing the energy function will force all labels to be valid.
- the set of pixels that are included in the neighborhood of a given pixel may vary with different implementations.
- the neighborhood of a given pixel comprises the four pixels spatially located directly to the left, to the right, above, and below the given pixel.
- the neighborhood may also include pixels directly diagonal to the given pixel (eight neighboring pixels).
- a larger radius may define the neighborhood (e.g., a two pixel or three pixel radius).
- the smoothness cost measures the “seamlessness” (or lack of it) of the labeling across two neighboring positions p and q.
- I is the original image and p and q are neighboring positions.
- FIG. 5 illustrates an image 502 having a hole 504 .
- the hole 504 includes a pixel at a position p and a pixel at a neighboring position q.
- p and q are spatial neighbors.
- Pixel position p has a label L p
- pixel position q has a label L q .
- a good assumption is that if L q is a label for q, a label for p that will provide good smoothness is L q +p ⁇ q, because this pixel position is the same distance and direction away from L p as position p is from q.
- represents the difference between the pixel at the actual position L p and the pixel at the position L q +p ⁇ q (assumed to provide good smoothness).
- a good assumption is that if L p is a label for p, a label for q that will provide good smoothness is L p +q ⁇ p, because this pixel position is the same distance and direction away from L q as position q is from p.
- represents the difference between the pixel at the actual position L q and the pixel at the position L p +q ⁇ p (assumed to provide good smoothness).
- the first and second components of the smoothness cost are summed to provide an overall smoothness cost for the pixel position pair p, q.
- the process of generating the label map can be performed efficiently using an iterative approach.
- the label map is first initialized using a set of initial labels.
- the initial labels may be assigned according to a random process, according to predefined values (e.g., each position mapping to itself), or according to multi-scale process that is described in further detail below.
- the image processing module 110 then iteratively refines the labels by finding new labels that further minimize the energy function. For example, in one embodiment, the image processing module 110 refines the labels by processing each pixel position one at a time (e.g., in a raster scan order). In the refinement steps, the image processing module 110 first determines a set of candidate labels S[p] for the pixel position p. Then, the image processing module 110 selects the candidate label that will best minimize the energy function.
- candidate labels can be determined using either a randomization technique (i.e., randomized candidates), a coherence technique (i.e. coherence candidates), or both.
- the candidate label selection module 206 selects randomized candidates according to a function having some random component. For example, in one embodiment, the candidate label selection module 206 selects a random set of “valid” pixel locations within a radius of the position referenced by the current label L p . The radius and/or number of candidates may be predefined constants. In another embodiment, a weighted randomized function may be used that weights likelihoods of selecting a particular pixel location based on distance. Thus, for example, pixel positions closer to the position pointed to by the current label L p may be more likely to be selected than pixels positions farther away. These randomized candidates are included in the candidate set S[p].
- the energy minimization module 208 determines which of the candidate labels S[p] will minimize the energy function.
- the image processing module 110 performs a fixed number of iterations (e.g., 5-10 iterations) with each iteration seeking to further improve the energy function.
- the image processing module 110 may continue iterating until a particular criterion is met (e.g., the energy cost falls below a threshold or the incremental improvement in energy cost falls below a threshold).
- FIGS. 6A and 6B are flowcharts illustrating an embodiment of a process for creating the label map using a multi-scale implementation to initialize the labels.
- FIG. 6A illustrates a downsampling, or pre-processing, phase of the multi-scale process.
- the image processing module 110 progressively downsamples (via the downsampling module 202 ) and filters the original image to create a “pyramid” of downsampled/filtered images of varying resolution.
- the downsampling phase starts 602 with the original image.
- the image processing module 110 downsamples and filters 604 the image.
- downsampling comprises removing selected pixels from the image depending on the downsampling factor.
- the image processing module 110 removes every second row and column of the image.
- a different downsampling factor may be used. Filtering is applied to smooth the pixels that still remain after downsampling.
- each pixel in the downsampled image is assigned a value that is an average of the corresponding pixel in the pre-downsampled image and its “neighboring” pixels in the pre-downsampled image, with the exception of hole pixels which are excluded from the average.
- the downsampled pixel may be assigned a predefined value (e.g., 0) that indicates that the downsampled pixel is also a hole pixel.
- the set of neighboring pixels may be defined in different ways according to different embodiments and is not necessarily defined in the same way as the neighborhood used to calculate the smoothness cost discussed above.
- the neighboring pixels of a given pixel include pixels directly above, below, to the left and to the right of the given pixel (if within the boundaries of the image and not a hole pixel).
- the neighboring pixels may also include pixels directly diagonal from a given pixel.
- neighboring pixels may include pixels not directly adjacent to a given pixel (e.g., within a two or three pixel radius).
- the hole will shrink around its edges each downsampling/filtering iteration. After downsampling and filtering, hole pixels will remain only where the corresponding pre-downsampled pixel and all of its neighboring pixels are hole pixels.
- the image processing module 110 After downsampling and filtering the image, the image processing module 110 identifies 606 the hole(s) still remaining in the downsampled image. A new hole mask is created that identifies the location of the hole(s) in the downsampled image. The image processing module 110 then determines 608 whether to downsample further. This may be determined, for example, based on a stopping criterion such as the downsampled image reaching a particular size. In one embodiment, the image processing module 110 continues downsampling until the image size reaches a single pixel. If the image processing module 110 determines to downsample further, the process loops back to step 604 and iterates again.
- the image processing module 110 determines to stop downsampling (e.g., when the image is dowsampled to a single pixel), then the image processing module 110 stores the “pyramid” 610 of successively downsampled and filtered images (each having a different resolution) and corresponding hole masks.
- FIG. 6B illustrates an embodiment of an upsampling phase of the multiscale process.
- the image processing module 110 generates a series of label maps from each of the downsampled images in the downsampling pyramid by progressively upsampling (via the upsampling module 204 ) the label maps.
- the image processing module 110 starts 622 with the coarsest image in the pyramid of downsampled images.
- this coarsest image may comprise only a single pixel.
- the image processing module initializes 624 a label map having dimensions equivalent to the dimensions of the coarsest image.
- initial labels are determined based on the label map for the previous lower resolution image in the downsampling pyramid. For example, in one embodiment, labels for the previous low resolution image map are first scaled based on the upsampling factor to generate labels for the higher resolution label map.
- some labels may initialize to invalid pixel locations (e.g., pixel locations that are holes or outside the image boundaries). To prevent this, labels that would be initialized to an invalid position may instead be projected to a valid pixel location (e.g., the closest valid location).
- the equations above may be modified for different upsampling factors.
- the image processing module 110 After initialization, the image processing module 110 then refines 626 the labels as described above in order to improve the energy function (e.g., by generating a set of candidate labels for each pixel position and selecting the candidate label that best minimizes the energy function). As described above, the refinement step 626 may iterate multiple times at each stage of the pyramid.
- the image processing module 110 determines 628 whether or not to upsample further by, for example, checking if a stopping criterion is met. For example, in one embodiment, the stopping criterion is met when the label map reaches a size equal to the original image size. If the image processing module 110 determines to upsample further, the label map is upsampled 630 to create a new label map having dimensions equivalent to the dimensions of the next largest image in the pyramid. If the image processing module 110 determines not to upsample further (e.g., because the original image size is reached), the image processing module 110 stores 632 a label map having the same dimensions as the original image. The image generation module 210 may then use this label map to synthesize the output image as described above.
- FIG. 7 illustrates several example stages of the multi-scale process described in FIGS. 6A-6B .
- FIG. 7 illustrates the last three iterations of the downsampling phase of FIG. 6A and the first three iterations of the upsampling phase of FIG. 6B .
- the downsampled image 702 comprises a 7 ⁇ 7 array of pixels with hole pixels indicated by the shaded portion 703 (i.e., the hole mask).
- the image 702 is downsampled by removing the odd rows and columns, thus leaving only the pixels outlined in bold. This results in the 3 ⁇ 3 image 704 .
- the pixel value is set by computing an average of the corresponding pixel in image 702 and its neighboring pixels, with the neighborhood being defined in this example as a one pixel radius (including diagonal pixels, excluding hole pixels or positions outside the image boundary.
- the hole mask 705 is smaller in image 704 as a result of this averaging technique because the hole remains only where a pixel and all of its neighboring pixels are holes.
- the image 704 is then downsampled and filtered again, resulting in the single pixel 706 .
- L 3,3 cannot map to (3,3) because this is a hole location, and instead be mapped to any other pixel location as determined by the energy applying the energy function.
- the label map 715 is then upsampled again and new labels are generated to generate the label map 717 . This process continues until a label map of the original image size is reached.
- the image processing module 110 only calculates smoothness cost for hole pixel positions and only performs the iterative refinement process on these pixel positions.
- the smoothness cost component of the energy function is a summation, choosing a candidate label for each pixel location that minimizes smoothness cost will decrease the overall smoothness cost component of the energy function.
- a benefit of the multi-scale process described process is that the energy function need not be explicitly computed for all possible combinations of labels. Unlike some traditional texture-mapping techniques, the above described implementation does not necessarily perform an explicit “nearest neighbor search.” Rather, each stage just determines a label map that best improves the previous labeling in terms of smoothness while satisfying boundary constraints. While this is a greedy approach, the use of a multi-scale pyramid alleviates the problem by taking long-range interactions into account at the coarser level.
- extensions may be used to make the algorithm less greedy.
- the image processing module 110 pre-processes the labels into contiguous chunks/regions that have the same label. The algorithm then proceeds at region level, updating the label for “all” pixels within a region at once. The cost for a region is computed by summing the costs for all pixels within that region. In the case of hole filling, where it is the smoothness cost that matters, the image processing module 110 only computes the smoothness cost at the boundary pixels for that region, and measures whether consistency with respect to the neighboring regions is increased or decreased by the candidate label. The candidate set is constructed by looking at labels for all neighboring regions.
- Another alternative embodiment uses the multi-scale pyramid to modify the data cost by providing a low-resolution soft constraint, similar to that described below in the context of super-resolution image enhancement.
- This approach can require that the synthesized image at the finer pyramid level, when filtered and downsampled, match the coarser synthesized image.
- super-resolution the goal is to enhance a low resolution image by synthesizing a high resolution enhanced version of the image as output.
- a particular formulation of this problem assumes that other high resolution images of the same object or scene are available as input images. These high resolution input images may be taken from different perspectives than the low resolution image being enhanced or may include only a portion of the object or scene.
- super-resolution synthesizes a high-resolution version of a low-resolution image based on one or more high-resolution input images.
- the super-resolution problem can be cast as a labeling problem by determining a label map for an output image that minimizes an energy function, and constructing the output image according to the labels.
- the labels map a pixel position in the output image to a pixel position in one of the high-resolution input images.
- super-resolution image enhancement may be implemented similarly to hole-filling described above with several differences discussed in the description below.
- FIG. 8 illustrates an example embodiment of a process for generating a super-resolved image.
- the image processing module 110 receives 802 a low resolution image I LR to be super-resolved and one or more high-resolution input images I 1 . . . I n .
- the image processing module 110 then creates 804 a label map, with each position in the label map corresponding to a pixel position in the super-resolved output image. Each label points to a pixel position in one of the high-resolution input images.
- the labels are chosen to minimize an energy function.
- the overall energy function described above in Eq. (1) and the smoothness cost described in Eq. (3) are used, but the data cost (DC) is defined differently.
- I LR is the low-resolution image being super-resolved
- I c is a coarse-scale (i.e., downsampled) version of the high resolution input image I referenced in label L p .
- This coarse-scale image I C has a resolution that matches the resolution of the low-resolution image I LR .
- the overall data cost represents a difference in pixel values (e.g., color) between the original low resolution image being super-resolved and a downsampled version of the output image. This data cost is effective because it may be reasonably assumed that a good super-resolved image, when downsampled, will match the original image very closely.
- the image processing module 110 then synthesizes 806 the super-resolved output image by copying pixels from the high-resolution input images to the proper locations in the output image based on the labels. This process is similar to the process illustrated in FIG. 4 described above, except that the labels are now three-dimensional and may come from different input images.
- the process of generating the label map for super-resolution can be performed efficiently using an iterative approach.
- the label map is first initialized using a set of initial labels and in subsequent iterations, the labels are then refined to further minimize the energy function.
- Initialization may be implemented using a multi-scale process similar to that described above.
- the downsampling phase for super-resolution does not need to consider the locations of holes (i.e., no pixels are hole pixels).
- the image processing module 110 may utilize an expanded set of candidate labels in addition to those described above for hole-filing.
- the set of coherence candidates is expanded to include both spatial coherence candidates (as described above) and “signal coherence” candidates.
- the image processing module 110 may first pre-process the low resolution image I LR to identify pixels having similar pixel values (e.g., colors intensities) or gradients. Pixels that fall within a certain threshold similarity of each other are identified as “signal neighbors.” Thus, each pixel now has both a set of spatial neighbors (pixels that are spatially close) and a set of signal neighbors (pixels that are qualitatively similar). Alternatively, a gradient comparison can be used to identify signal neighbors.
- FIG. 9 is a high-level block diagram illustrating an example of a computer 900 for use as an image processing server 100 . Illustrated are at least one processor 902 coupled to a chipset 904 .
- the chipset 904 includes a memory controller hub 920 and an input/output (I/O) controller hub 922 .
- a memory 906 and a graphics adapter 912 are coupled to the memory controller hub 920 , and a display device 918 is coupled to the graphics adapter 912 .
- a storage device 908 , keyboard 910 , pointing device 914 , and network adapter 916 are coupled to the I/O controller hub 922 .
- Other embodiments of the computer 900 have different architectures.
- the memory 906 is directly coupled to the processor 902 in some embodiments.
- the storage device 908 is a non-transitory computer-readable storage medium such as a hard drive, compact disk read-only memory (CD-ROM), DVD, or a solid-state memory device.
- the memory 906 holds instructions and data used by the processor 902 .
- the pointing device 914 is a mouse, track ball, or other type of pointing device, and is used in combination with the keyboard 910 to input data into the computer 900 .
- the graphics adapter 912 displays images and other information on the display device 918 .
- the network adapter 916 couples the computer 900 to a network. Some embodiments of the computer 900 have different and/or other components than those shown in FIG. 9 .
- the types of computer 900 can vary depending upon the embodiment and the desired processing power.
- the computer 900 may comprise multiple blade servers working together to provide the functionality described herein.
- the computer 900 is adapted to execute computer program modules for providing functionality described herein.
- module refers to computer program instructions and other logic used to provide the specified functionality.
- a module can be implemented in hardware, firmware, and/or software.
- program modules formed of executable computer program instructions are stored on the storage device 908 , loaded into the memory 906 , and executed by the processor 902 .
Abstract
Description
where Lp is a label for a pixel position p, Lq is a label for a pixel position q that is in the neighborhood of p, DC is a data cost, and SC is a smoothness cost.
of the energy function sums data costs (DC) over all labels Lp in the label map. The data cost (DC) for a particular label Lp is calculated as follows:
of the energy function sums smoothness cost (SC) over all pairs of “neighboring” labels in the label map (i.e., labels Lp and Lq contribute to the smoothness cost only if p and q are neighbors). The set of pixels that are included in the neighborhood of a given pixel may vary with different implementations. For example, in one embodiment, the neighborhood of a given pixel comprises the four pixels spatially located directly to the left, to the right, above, and below the given pixel. In another embodiment, the neighborhood may also include pixels directly diagonal to the given pixel (eight neighboring pixels). In yet other embodiments, a larger radius may define the neighborhood (e.g., a two pixel or three pixel radius).
SC(L p ,L q)=|I(L p)−I(L q +p−q)|+|I(L p +q−p)| (3)
High Res— L(2p)=2*Low Res— L(p) (4)
where HighRes_L is the label map currently being initialized and LowRes_L is the lower resolution label map created in the previous iteration of the multi-scale process.
High Res— L(2p+offset)=2*Low Res— L(p)+offset (5)
for offset values of (0,1), (1,0), or (1,1). Using the initialization equations above, some labels may initialize to invalid pixel locations (e.g., pixel locations that are holes or outside the image boundaries). To prevent this, labels that would be initialized to an invalid position may instead be projected to a valid pixel location (e.g., the closest valid location). The equations above may be modified for different upsampling factors.
DC(L p)=|I C(L p)−I LR(p)| (6)
where ILR is the low-resolution image being super-resolved and Ic is a coarse-scale (i.e., downsampled) version of the high resolution input image I referenced in label Lp. This coarse-scale image IC has a resolution that matches the resolution of the low-resolution image ILR. Thus, the overall data cost represents a difference in pixel values (e.g., color) between the original low resolution image being super-resolved and a downsampled version of the output image. This data cost is effective because it may be reasonably assumed that a good super-resolved image, when downsampled, will match the original image very closely.
Claims (38)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/308,836 US8670630B1 (en) | 2010-12-09 | 2011-12-01 | Fast randomized multi-scale energy minimization for image processing |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US42160210P | 2010-12-09 | 2010-12-09 | |
US13/308,836 US8670630B1 (en) | 2010-12-09 | 2011-12-01 | Fast randomized multi-scale energy minimization for image processing |
Publications (1)
Publication Number | Publication Date |
---|---|
US8670630B1 true US8670630B1 (en) | 2014-03-11 |
Family
ID=50192807
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/308,836 Active 2032-07-12 US8670630B1 (en) | 2010-12-09 | 2011-12-01 | Fast randomized multi-scale energy minimization for image processing |
US13/309,125 Expired - Fee Related US8737723B1 (en) | 2010-12-09 | 2011-12-01 | Fast randomized multi-scale energy minimization for inferring depth from stereo image pairs |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/309,125 Expired - Fee Related US8737723B1 (en) | 2010-12-09 | 2011-12-01 | Fast randomized multi-scale energy minimization for inferring depth from stereo image pairs |
Country Status (1)
Country | Link |
---|---|
US (2) | US8670630B1 (en) |
Cited By (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120120192A1 (en) * | 2010-11-11 | 2012-05-17 | Georgia Tech Research Corporation | Hierarchical hole-filling for depth-based view synthesis in ftv and 3d video |
US9240055B1 (en) | 2014-09-16 | 2016-01-19 | Google Inc. | Symmetry-based interpolation in images |
CN105335965A (en) * | 2015-09-29 | 2016-02-17 | 中国科学院遥感与数字地球研究所 | High-resolution remote sensing image multi-scale self-adaptive decision fusion segmentation method |
US20160150210A1 (en) * | 2014-11-20 | 2016-05-26 | Samsung Electronics Co., Ltd. | Method and apparatus for matching stereo images |
WO2017092592A1 (en) * | 2015-12-03 | 2017-06-08 | 阿里巴巴集团控股有限公司 | Image fusion method, apparatus and device |
CN107451986A (en) * | 2017-08-10 | 2017-12-08 | 南京信息职业技术学院 | A kind of single width infrared image enhancing method based on integration technology |
CN109345485A (en) * | 2018-10-22 | 2019-02-15 | 北京达佳互联信息技术有限公司 | A kind of image enchancing method, device, electronic equipment and storage medium |
US10311540B2 (en) * | 2016-02-03 | 2019-06-04 | Valve Corporation | Radial density masking systems and methods |
US10321112B2 (en) * | 2016-07-18 | 2019-06-11 | Samsung Electronics Co., Ltd. | Stereo matching system and method of operating thereof |
CN109919948A (en) * | 2019-02-26 | 2019-06-21 | 华南理工大学 | Nasopharyngeal Carcinoma Lesions parted pattern training method and dividing method based on deep learning |
US10430959B2 (en) | 2015-12-14 | 2019-10-01 | Samsung Electronics Co., Ltd. | Method and apparatus for matching stereo images |
CN111008955A (en) * | 2019-11-06 | 2020-04-14 | 重庆邮电大学 | Multi-scale image block matching rapid copying pasting tampering detection method |
US10657623B2 (en) | 2018-08-10 | 2020-05-19 | Apple Inc. | Two stage multi-scale processing of image data |
US10672164B2 (en) | 2017-10-16 | 2020-06-02 | Adobe Inc. | Predicting patch displacement maps using a neural network |
US10699453B2 (en) * | 2017-08-17 | 2020-06-30 | Adobe Inc. | Digital media environment for style-aware patching in a digital image |
US10755391B2 (en) | 2018-05-15 | 2020-08-25 | Adobe Inc. | Digital image completion by learning generation and patch matching jointly |
CN111583147A (en) * | 2020-05-06 | 2020-08-25 | 北京字节跳动网络技术有限公司 | Image processing method, device, equipment and computer readable storage medium |
US20210342975A1 (en) * | 2020-05-03 | 2021-11-04 | Shiwei Liu | Marine survey image enhancement system |
US11250548B2 (en) | 2017-10-16 | 2022-02-15 | Adobe Inc. | Digital image completion using deep learning |
Families Citing this family (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2012177166A1 (en) * | 2011-06-24 | 2012-12-27 | Intel Corporation | An efficient approach to estimate disparity map |
US9659372B2 (en) * | 2012-05-17 | 2017-05-23 | The Regents Of The University Of California | Video disparity estimate space-time refinement method and codec |
TWI502544B (en) * | 2013-03-07 | 2015-10-01 | Acer Inc | Disparity estimation method of stereoscopic image |
US10074158B2 (en) * | 2014-07-08 | 2018-09-11 | Qualcomm Incorporated | Systems and methods for stereo depth estimation using global minimization and depth interpolation |
CN104156957B (en) * | 2014-08-06 | 2017-02-01 | 昆山天工智能科技有限公司 | Stable and high-efficiency high-resolution stereo matching method |
CN106355619A (en) * | 2016-08-31 | 2017-01-25 | 天津大学 | Method for adjusting object parallax in stereo image |
CN107071383A (en) * | 2017-02-28 | 2017-08-18 | 北京大学深圳研究生院 | The virtual visual point synthesizing method split based on image local |
US10834374B2 (en) | 2017-02-28 | 2020-11-10 | Peking University Shenzhen Graduate School | Method, apparatus, and device for synthesizing virtual viewpoint images |
US10386851B2 (en) * | 2017-09-22 | 2019-08-20 | Locus Robotics Corp. | Multi-resolution scan matching with exclusion zones |
EP3695597A4 (en) * | 2017-10-11 | 2021-06-30 | Nokia Technologies Oy | An apparatus, a method and a computer program for volumetric video |
US10803606B2 (en) * | 2018-07-19 | 2020-10-13 | National Taiwan University | Temporally consistent belief propagation system and method |
CN109410259B (en) * | 2018-08-27 | 2020-10-27 | 中国科学院自动化研究所 | Structured binocular depth map up-sampling method based on confidence |
US11025842B2 (en) | 2019-04-05 | 2021-06-01 | Apple Inc. | Binner circuit for image signal processor |
US11024006B2 (en) | 2019-04-22 | 2021-06-01 | Apple Inc. | Tagging clipped pixels for pyramid processing in image signal processor |
US11127115B2 (en) * | 2019-12-13 | 2021-09-21 | NextVPU (Shanghai) Co., Ltd. | Determination of disparity |
CN112991254A (en) * | 2019-12-13 | 2021-06-18 | 上海肇观电子科技有限公司 | Disparity estimation system, method, electronic device, and computer-readable storage medium |
US11488318B2 (en) * | 2020-05-13 | 2022-11-01 | Microsoft Technology Licensing, Llc | Systems and methods for temporally consistent depth map generation |
US11481914B2 (en) * | 2020-05-13 | 2022-10-25 | Microsoft Technology Licensing, Llc | Systems and methods for low compute depth map generation |
CN112700532B (en) * | 2020-12-21 | 2021-11-16 | 杭州反重力智能科技有限公司 | Neural network training method and system for three-dimensional reconstruction |
Citations (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6630950B1 (en) * | 1998-03-19 | 2003-10-07 | Canon Kabushiki Kaisha | Apparatus for improving image vibration suppression |
US6750974B2 (en) * | 2002-04-02 | 2004-06-15 | Gsi Lumonics Corporation | Method and system for 3D imaging of target regions |
US20050285874A1 (en) | 2004-06-28 | 2005-12-29 | Microsoft Corporation | System and process for generating a two-layer, 3D representation of a scene |
US20050286759A1 (en) | 2004-06-28 | 2005-12-29 | Microsoft Corporation | Interactive viewpoint video system and process employing overlapping images of a scene captured from viewpoints forming a grid |
US6987544B2 (en) * | 2001-06-20 | 2006-01-17 | Sony Corporation | Method and apparatus for processing image |
US6993167B1 (en) * | 1999-11-12 | 2006-01-31 | Polartechnics Limited | System and method for examining, recording and analyzing dermatological conditions |
US7026830B2 (en) * | 1996-03-05 | 2006-04-11 | Hitachi, Ltd. | Method and apparatus for inspecting integrated circuit pattern |
US7102662B2 (en) * | 2000-12-28 | 2006-09-05 | Fuji Xerox Co., Ltd. | Data sequence conversion circuit and printer using the same |
US20070024614A1 (en) | 2005-07-26 | 2007-02-01 | Tam Wa J | Generating a depth map from a two-dimensional source image for stereoscopic and multiview imaging |
US20070071311A1 (en) | 2005-09-28 | 2007-03-29 | Deere & Company, A Delaware Corporation | Method for processing stereo vision data using image density |
US20080031327A1 (en) | 2006-08-01 | 2008-02-07 | Haohong Wang | Real-time capturing and generating stereo images and videos with a monoscopic low power mobile device |
US7440610B1 (en) * | 2004-01-28 | 2008-10-21 | The United States Of America As Represented By The Secretary Of The Navy | Apparatus and method for image based coordinate determination |
US7463816B2 (en) * | 2003-09-18 | 2008-12-09 | Cyberlink Corp. | Method of encoding and decoding pictured data for enhancing image resolution |
US7616885B2 (en) | 2006-10-03 | 2009-11-10 | National Taiwan University | Single lens auto focus system for stereo image generation and method thereof |
US7805011B2 (en) * | 2006-09-13 | 2010-09-28 | Warner Bros. Entertainment Inc. | Method and apparatus for providing lossless data compression and editing media content |
US8350932B2 (en) * | 2008-07-30 | 2013-01-08 | Panasonic Corporation | Image generation device and image generation method for generating a high-quality image by using information from a low-quality image |
US20130250123A1 (en) | 2011-11-04 | 2013-09-26 | Qualcomm Incorporated | Multispectral imaging system |
-
2011
- 2011-12-01 US US13/308,836 patent/US8670630B1/en active Active
- 2011-12-01 US US13/309,125 patent/US8737723B1/en not_active Expired - Fee Related
Patent Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7026830B2 (en) * | 1996-03-05 | 2006-04-11 | Hitachi, Ltd. | Method and apparatus for inspecting integrated circuit pattern |
US6630950B1 (en) * | 1998-03-19 | 2003-10-07 | Canon Kabushiki Kaisha | Apparatus for improving image vibration suppression |
US6993167B1 (en) * | 1999-11-12 | 2006-01-31 | Polartechnics Limited | System and method for examining, recording and analyzing dermatological conditions |
US7102662B2 (en) * | 2000-12-28 | 2006-09-05 | Fuji Xerox Co., Ltd. | Data sequence conversion circuit and printer using the same |
US6987544B2 (en) * | 2001-06-20 | 2006-01-17 | Sony Corporation | Method and apparatus for processing image |
US6750974B2 (en) * | 2002-04-02 | 2004-06-15 | Gsi Lumonics Corporation | Method and system for 3D imaging of target regions |
US7463816B2 (en) * | 2003-09-18 | 2008-12-09 | Cyberlink Corp. | Method of encoding and decoding pictured data for enhancing image resolution |
US7440610B1 (en) * | 2004-01-28 | 2008-10-21 | The United States Of America As Represented By The Secretary Of The Navy | Apparatus and method for image based coordinate determination |
US20050285875A1 (en) | 2004-06-28 | 2005-12-29 | Microsoft Corporation | Interactive viewpoint video system and process |
US20050286759A1 (en) | 2004-06-28 | 2005-12-29 | Microsoft Corporation | Interactive viewpoint video system and process employing overlapping images of a scene captured from viewpoints forming a grid |
US20050285874A1 (en) | 2004-06-28 | 2005-12-29 | Microsoft Corporation | System and process for generating a two-layer, 3D representation of a scene |
US20070024614A1 (en) | 2005-07-26 | 2007-02-01 | Tam Wa J | Generating a depth map from a two-dimensional source image for stereoscopic and multiview imaging |
US20070071311A1 (en) | 2005-09-28 | 2007-03-29 | Deere & Company, A Delaware Corporation | Method for processing stereo vision data using image density |
US20080031327A1 (en) | 2006-08-01 | 2008-02-07 | Haohong Wang | Real-time capturing and generating stereo images and videos with a monoscopic low power mobile device |
US7805011B2 (en) * | 2006-09-13 | 2010-09-28 | Warner Bros. Entertainment Inc. | Method and apparatus for providing lossless data compression and editing media content |
US7616885B2 (en) | 2006-10-03 | 2009-11-10 | National Taiwan University | Single lens auto focus system for stereo image generation and method thereof |
US8350932B2 (en) * | 2008-07-30 | 2013-01-08 | Panasonic Corporation | Image generation device and image generation method for generating a high-quality image by using information from a low-quality image |
US20130250123A1 (en) | 2011-11-04 | 2013-09-26 | Qualcomm Incorporated | Multispectral imaging system |
Non-Patent Citations (3)
Title |
---|
Barnes, C., et al., "PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing," ACM Transactions on Graphics (Proc. SIGGRAPH), Aug. 2009, 10 pages. |
Google, "Google building maker" 2011, 1 page [online][retrieved on May 31, 2012] Retrieved from the internet . |
Google, "Google building maker" 2011, 1 page [online][retrieved on May 31, 2012] Retrieved from the internet <URL:http://sketchup.google.com/3dwh/buildingmaker.html>. |
Cited By (29)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9094660B2 (en) * | 2010-11-11 | 2015-07-28 | Georgia Tech Research Corporation | Hierarchical hole-filling for depth-based view synthesis in FTV and 3D video |
US20120120192A1 (en) * | 2010-11-11 | 2012-05-17 | Georgia Tech Research Corporation | Hierarchical hole-filling for depth-based view synthesis in ftv and 3d video |
US9240055B1 (en) | 2014-09-16 | 2016-01-19 | Google Inc. | Symmetry-based interpolation in images |
US20160150210A1 (en) * | 2014-11-20 | 2016-05-26 | Samsung Electronics Co., Ltd. | Method and apparatus for matching stereo images |
US9832454B2 (en) * | 2014-11-20 | 2017-11-28 | Samsung Electronics Co., Ltd. | Method and apparatus for matching stereo images |
CN105335965A (en) * | 2015-09-29 | 2016-02-17 | 中国科学院遥感与数字地球研究所 | High-resolution remote sensing image multi-scale self-adaptive decision fusion segmentation method |
WO2017092592A1 (en) * | 2015-12-03 | 2017-06-08 | 阿里巴巴集团控股有限公司 | Image fusion method, apparatus and device |
US10430959B2 (en) | 2015-12-14 | 2019-10-01 | Samsung Electronics Co., Ltd. | Method and apparatus for matching stereo images |
US11107178B2 (en) | 2016-02-03 | 2021-08-31 | Valve Corporation | Radial density masking systems and methods |
US10311540B2 (en) * | 2016-02-03 | 2019-06-04 | Valve Corporation | Radial density masking systems and methods |
US10321112B2 (en) * | 2016-07-18 | 2019-06-11 | Samsung Electronics Co., Ltd. | Stereo matching system and method of operating thereof |
CN107451986A (en) * | 2017-08-10 | 2017-12-08 | 南京信息职业技术学院 | A kind of single width infrared image enhancing method based on integration technology |
US10699453B2 (en) * | 2017-08-17 | 2020-06-30 | Adobe Inc. | Digital media environment for style-aware patching in a digital image |
US11436775B2 (en) | 2017-10-16 | 2022-09-06 | Adobe Inc. | Predicting patch displacement maps using a neural network |
US11250548B2 (en) | 2017-10-16 | 2022-02-15 | Adobe Inc. | Digital image completion using deep learning |
US10672164B2 (en) | 2017-10-16 | 2020-06-02 | Adobe Inc. | Predicting patch displacement maps using a neural network |
US11334971B2 (en) | 2018-05-15 | 2022-05-17 | Adobe Inc. | Digital image completion by learning generation and patch matching jointly |
US10755391B2 (en) | 2018-05-15 | 2020-08-25 | Adobe Inc. | Digital image completion by learning generation and patch matching jointly |
US11010870B2 (en) | 2018-08-10 | 2021-05-18 | Apple Inc. | Two stage multi-scale processing of image data |
US10657623B2 (en) | 2018-08-10 | 2020-05-19 | Apple Inc. | Two stage multi-scale processing of image data |
CN109345485B (en) * | 2018-10-22 | 2021-04-16 | 北京达佳互联信息技术有限公司 | Image enhancement method and device, electronic equipment and storage medium |
CN109345485A (en) * | 2018-10-22 | 2019-02-15 | 北京达佳互联信息技术有限公司 | A kind of image enchancing method, device, electronic equipment and storage medium |
CN109919948A (en) * | 2019-02-26 | 2019-06-21 | 华南理工大学 | Nasopharyngeal Carcinoma Lesions parted pattern training method and dividing method based on deep learning |
CN111008955A (en) * | 2019-11-06 | 2020-04-14 | 重庆邮电大学 | Multi-scale image block matching rapid copying pasting tampering detection method |
CN111008955B (en) * | 2019-11-06 | 2023-05-26 | 重庆邮电大学 | Rapid copying, pasting and tampering detection method for multi-scale image block matching |
US20210342975A1 (en) * | 2020-05-03 | 2021-11-04 | Shiwei Liu | Marine survey image enhancement system |
US11763426B2 (en) * | 2020-05-03 | 2023-09-19 | Shiwei Liu | Marine survey image enhancement system |
CN111583147A (en) * | 2020-05-06 | 2020-08-25 | 北京字节跳动网络技术有限公司 | Image processing method, device, equipment and computer readable storage medium |
CN111583147B (en) * | 2020-05-06 | 2023-06-06 | 北京字节跳动网络技术有限公司 | Image processing method, device, equipment and computer readable storage medium |
Also Published As
Publication number | Publication date |
---|---|
US8737723B1 (en) | 2014-05-27 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8670630B1 (en) | Fast randomized multi-scale energy minimization for image processing | |
Bailer et al. | Flow fields: Dense correspondence fields for highly accurate large displacement optical flow estimation | |
KR101195942B1 (en) | Camera calibration method and 3D object reconstruction method using the same | |
US8885941B2 (en) | System and method for estimating spatially varying defocus blur in a digital image | |
Newson et al. | Video inpainting of complex scenes | |
US8547389B2 (en) | Capturing image structure detail from a first image and color from a second image | |
Barnes et al. | Patchtable: Efficient patch queries for large datasets and applications | |
US8160391B1 (en) | Panoramic image fill | |
EP2556490B1 (en) | Generation of multi-resolution image pyramids | |
CN111243071A (en) | Texture rendering method, system, chip, device and medium for real-time three-dimensional human body reconstruction | |
CN110033475B (en) | Aerial photograph moving object detection and elimination method based on high-resolution texture generation | |
US9454803B1 (en) | System and method for scene dependent multi-band blending | |
EP3367334B1 (en) | Depth estimation method and depth estimation apparatus of multi-view images | |
WO2013074561A1 (en) | Modifying the viewpoint of a digital image | |
JP2007000205A (en) | Image processing apparatus, image processing method, and image processing program | |
Hasinoff et al. | Boundary matting for view synthesis | |
Thonat et al. | Multi-view inpainting for image-based scene editing and rendering | |
Bebeselea-Sterp et al. | A comparative study of stereovision algorithms | |
Pickup et al. | Overcoming registration uncertainty in image super-resolution: maximize or marginalize? | |
Pickup et al. | Optimizing and Learning for Super-resolution. | |
KR101837286B1 (en) | Laplacian patch-based image synthesis method and apparatus therefor | |
Ribal et al. | Efficient graph cut optimization for shape from focus | |
Klose et al. | Flowlab-an interactive tool for editing dense image correspondences | |
Jung et al. | Intensity-guided edge-preserving depth upsampling through weighted L0 gradient minimization | |
Pintus et al. | A Streaming Framework for Seamless Detailed Photo Blending on Massive Point Clouds. |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:KWATRA, VIVEK;REEL/FRAME:027317/0568Effective date: 20111130 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551)Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0299Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |