JP2021523457A - Recommend automated assistant actions for inclusion in automated assistant routines - Google Patents
Recommend automated assistant actions for inclusion in automated assistant routines Download PDFInfo
- Publication number
- JP2021523457A JP2021523457A JP2020562676A JP2020562676A JP2021523457A JP 2021523457 A JP2021523457 A JP 2021523457A JP 2020562676 A JP2020562676 A JP 2020562676A JP 2020562676 A JP2020562676 A JP 2020562676A JP 2021523457 A JP2021523457 A JP 2021523457A
- Authority
- JP
- Japan
- Prior art keywords
- automated assistant
- user
- action
- routine
- routines
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24575—Query processing with adaptation to user needs using context
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
- G06F9/453—Help systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/242—Query formulation
- G06F16/243—Natural language query formulation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/25—Integrating or interfacing systems involving database management systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/36—Creation of semantic tools, e.g. ontology or thesauri
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/06—Creation of reference templates; Training of speech recognition systems, e.g. adaptation to the characteristics of the speaker's voice
- G10L15/065—Adaptation
- G10L15/07—Adaptation to the speaker
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/225—Feedback of the input speech
Abstract
ユーザの既存の自動化されたアシスタントルーチン内に含めるための自動化されたアシスタントアクションを推奨することであって、既存の自動化されたアシスタントルーチンは、複数の前から存在する自動化されたアシスタントアクションを含む。ユーザが、肯定的なユーザインターフェース入力を介して推奨を確認した場合、自動化されたアシスタントアクションは、既存の自動化されたアシスタントルーチンに自動的に追加され得る。その後、自動化されたアシスタントルーチンが初期化された場合、推奨に応答して受信された肯定的なユーザインターフェース入力に応答してルーチンに自動的に追加された自動化されたアシスタントアクションと同様に、ルーチンの前から存在する自動化されたアシスタントアクションは、実行される。 By recommending automated assistant actions to include within the user's existing automated assistant routines, existing automated assistant routines include multiple pre-existing automated assistant actions. If the user confirms the recommendation through positive user interface input, the automated assistant action can be automatically added to the existing automated assistant routine. If the automated assistant routine is then initialized, the routine is similar to the automated assistant action that was automatically added to the routine in response to the positive user interface input received in response to the recommendation. The automated assistant actions that existed before are performed.
Description
人間は、本明細書で「自動化されたアシスタント」(「デジタルエージェント」、「チャットボット」、「対話型パーソナルアシスタント」、「インテリジェントパーソナルアシスタント」、「会話エージェント」などとも呼ばれる)と呼ばれる対話型ソフトウェアアプリケーションを用いて人間対コンピュータの対話に従事することができる。例えば、(自動化されたアシスタントと対話するとき、「ユーザ」と呼ばれる場合もある)人間は、場合によってはテキストに変換されて次いで処理される場合がある口頭の自然言語入力(すなわち、発話)を使用して、および/またはテキスト(例えば、タイプされた)自然言語入力を提供することによって、コマンドおよび/または要求を提供することができる。 Humans are interactive software referred to herein as "automated assistants" (also referred to as "digital agents", "chatbots", "interactive personal assistants", "intelligent personal assistants", "conversation agents", etc.). Applications can be used to engage in human-to-computer dialogue. For example, a human (sometimes referred to as a "user" when interacting with an automated assistant) can perform verbal natural language input (ie, utterances) that may sometimes be converted to text and then processed. Commands and / or requests can be provided using and / or by providing text (eg, typed) natural language input.
自動化されたアシスタントは、例えば、特定のコマンド(例えば、ショートカットコマンド)に応答して、複数のアクションのルーチンを実行することができる。例えば、「おやすみ」という発話を受信したことに応答して、自動化されたアシスタントは、ネットワーク化されたライトをオフにさせる、明日の天気予報をレンダリングさせる、および明日のユーザの予定表をレンダリングさせるなどの、一連のアクションを引き起こすことができる。自動化されたアシスタントルーチンは、ユーザおよび/またはクライアントデバイスのエコシステムに特定化され得、ユーザは、特定のアクションを特定のルーチンに手動で追加するための制御を提供され得る。例えば、第1のユーザは、第1のユーザによって定義されたおはよう自動化されたアシスタントアクションの第1のセットを有する「おはよう」自動化されたアシスタントルーチン、第1のユーザによって定義されたおやすみ自動化されたアシスタントアクションの第1のセットを有する「おやすみ」自動化されたアシスタントルーチン、および第1のユーザによって定義された追加の自動化されたアシスタントアクションを有する追加の自動化されたアシスタントルーチンを有することができる。別の第2のユーザは、第2のユーザによって定義されたおはよう自動化されたアシスタントアクションの異なるセットを有する「おはよう」自動化されたアシスタントルーチン、第2のユーザによって定義されたおやすみ自動化されたアシスタントアクションの異なるセットを有する「おやすみ」ルーチンなどを有することができる。 An automated assistant can, for example, execute a routine of multiple actions in response to a particular command (eg, a shortcut command). For example, in response to receiving the utterance "Good night", an automated assistant turns off networked lights, renders tomorrow's weather forecast, and renders tomorrow's user's calendar. Can trigger a series of actions such as. Automated assistant routines can be specified in the ecosystem of users and / or client devices, and users can be provided with control to manually add specific actions to specific routines. For example, the first user is a "good morning" automated assistant routine with a first set of good morning automated assistant actions defined by the first user, good night automated defined by the first user. It can have a "good night" automated assistant routine with a first set of assistant actions, and an additional automated assistant routine with additional automated assistant actions defined by the first user. Another second user is a "good morning" automated assistant routine with a different set of good morning automated assistant actions defined by the second user, a good night automated assistant action defined by the second user. You can have a "good night" routine with different sets of.
本明細書で説明したように、様々な自動化されたアシスタントルーチンが、ユーザの発話もしくはタイプされたユーザインターフェース入力内のショートカットコマンドを検出することに応答して開始され得、クライアントデバイスにおける仮想もしくはハードウェア要素とのユーザ対話に応答して開始され得、ユーザジェスチャを検出することに応答して開始され得、および/または、他の短縮されたユーザインターフェース入力に応答して開始され得る。自動化されたアシスタントルーチンを開始するための短縮されたユーザインターフェース入力は、それらが、短縮されたユーザ入力なければ自動化されたアシスタントルーチンのアクションの実行を引き起こすために必要とされるよりも少ないユーザ入力および/またはユーザ入力のより少ない処理を必要とすることになろうという点で短縮されている。例えば、一連のアクションの自動化されたルーチンの実行を引き起こすショートカットコマンドは、自動化されたアシスタントにアクションのセットを実行させるために、凝縮されたコマンドがなければ発話/タイプされる必要があるコマンドよりも短いという点で短縮され得る。様々な自動化されたアシスタントルーチンは、加えてまたは代替的に、1つまたは複数の条件の発生時に自動的に、オプションでは明示的なユーザインターフェース入力を必要とすることなく開始され得る。自動化されたアシスタントルーチンのそのような自動開始は、そうでなければ自動化されたアシスタントルーチンのアクションの実行を引き起こすために必要とされるよりも少ないユーザ入力および/またはユーザ入力のより少ない処理を必要とする可能性もある。 As described herein, various automated assistant routines can be initiated in response to detecting a shortcut command in a user's speech or typed user interface input, virtual or hard on the client device. It can be initiated in response to a user interaction with a wear element, it can be initiated in response to detecting a user gesture, and / or it can be initiated in response to other shortened user interface inputs. The shortened user interface inputs to start the automated assistant routines are less user inputs than would otherwise be required to trigger the execution of the automated assistant routine's actions. And / or shortened in that it would require less processing of user input. For example, a shortcut command that causes an automated routine execution of a series of actions is better than a command that would have to be spoken / typed without a condensed command to have the automated assistant perform a set of actions. It can be shortened in that it is short. Various automated assistant routines, in addition or alternatives, can be started automatically when one or more conditions occur, optionally without requiring explicit user interface input. Such an automatic start of an automated assistant routine requires less user input and / or less processing of user input than would otherwise be required to trigger the execution of the automated assistant routine's actions. There is also the possibility of
自動化されたアシスタントルーチンの存在にもかかわらず、ユーザのいかなる自動化されたアシスタントルーチンにも組み込まれておらず、代わりにユーザが自動化されたアシスタントとの長引く対話を通じておよび/または他のコンピュータアプリケーションとの長引く対話を通じて実行する様々な自動化されたアシスタントアクションが、依然として存在する。そのような長引く対話の各発生は、かなりのコンピュータリソースおよび/またはネットワークリソースを消費する可能性がある。例えば、自動化されたアシスタントを介してキッチンのネットワーク化されたライトをオンにするために、ユーザは、「キッチンのライトをオンにして」または同様の発話をクライアントデバイスの自動化されたアシスタントインターフェースに話すことを要求され得る。発話に対応するオーディオデータは、クライアントデバイスからリモートシステムに送信され得る。リモートシステムは、発話のための適切なコマンドを決定するためにオーディオデータを処理(例えば、音声からテキストへの処理、テキストの自然言語処理など)することができ、キッチンのライトをオンにさせるためのコマンドをエージェントに送信することができ、キッチンのライトがオンにされたことの確認をエージェントから受信することができ、ライトがオンにされたことの通知をクライアントデバイスにレンダリングさせるためにクライアントデバイスにデータを送信することができる。 Despite the existence of automated assistant routines, they are not incorporated into any of the user's automated assistant routines, instead the user interacts with the automated assistant and / or with other computer applications. There are still various automated assistant actions that are performed through protracted dialogue. Each occurrence of such a protracted dialogue can consume significant computer and / or network resources. For example, to turn on the networked lights in the kitchen through an automated assistant, the user speaks "turn on the kitchen lights" or a similar utterance to the automated assistant interface on the client device. Can be required. Audio data corresponding to the utterance can be transmitted from the client device to the remote system. The remote system can process audio data (eg, voice-to-text processing, text natural language processing, etc.) to determine the appropriate command for utterance, to turn on the kitchen lights. You can send the command to the agent, receive confirmation from the agent that the kitchen light has been turned on, and have the client device render the notification that the light has been turned on. Data can be sent to.
これらおよび他の考慮事項に照らして、本明細書で開示した実装形態は、ユーザの既存の自動化されたアシスタントルーチン内に含めるための自動化されたアシスタントアクションを推奨することに関し、既存の自動化されたアシスタントルーチンは、1つまたは複数の前から存在する自動化されたアシスタントアクションを含む。ユーザが、肯定的なユーザインターフェース入力を介して推奨を確認した場合、自動化されたアシスタントアクションは、既存の自動化されたアシスタントルーチンに自動的に追加され得る。その後、自動化されたアシスタントルーチンが初期化された場合、推奨に応答して受信された肯定的なユーザインターフェース入力に応答してルーチンに自動的に追加された自動化されたアシスタントアクションと同様に、ルーチンの前から存在する自動化されたアシスタントアクションは、実行される。 In light of these and other considerations, the implementations disclosed herein have been automated with respect to recommending automated assistant actions for inclusion within the user's existing automated assistant routines. An assistant routine contains one or more pre-existing automated assistant actions. If the user confirms the recommendation through positive user interface input, the automated assistant action can be automatically added to the existing automated assistant routine. If the automated assistant routine is then initialized, the routine is similar to the automated assistant action that was automatically added to the routine in response to the positive user interface input received in response to the recommendation. The automated assistant actions that existed before are performed.
これは、アクションを実行させるために、ユーザがさらなる資源集約的な長引く対話を代わりに実行する必要性を除去する。むしろ、アクションは、それが追加された自動化されたアシスタントルーチンの複数のアクションのうちの1つとして実行される。これは、例えば、アクションの実行を引き起こすためにユーザによって提供される(例えば、ユーザによって自動化されたアシスタントインターフェースに提供される)必要がある入力の量を減らすことによって、改善された人間とコンピュータとの対話をもたらすことができる。人間とコンピュータとの対話を改善することに加えて、これは、例えば、そうではなくアクションを実行させるためにさらなるユーザインターフェース入力を提供することをユーザに要求することに比べて、様々なコンピュータ効率および/またはネットワーク効率を直接もたらすことができる。さらに、上記および本明細書の別の箇所で説明したように、自動化されたアシスタントルーチンの初期化は、効率的に処理され得るおよび/またはユーザインターフェース入力の処理を必要としない状態の発生時に自動的であり得る短縮されたユーザインターフェース入力に応答することができる。さらに、既存のルーチン内に含めるための自動化されたアシスタントアクションを推奨すること、ならびに、ワンタッチおよび/または単一の発話(例えば、「はい、追加して」)の肯定的入力に応答してアクションをルーチンに自動的に追加することは、既存のルーチンの効率的な補足を提供する。例えば、単純化されたユーザインターフェース入力に応答してアクションを自動的に追加することは、変更されるべきルーチンを手動で選択すること、ルーチンに追加するためのアクションを指定すること、アクションがルーチンに追加されるべきであることを確認することなどをユーザに要求する長引く対話など、アクションを手動で追加するために長引く対話に従事することをユーザに要求するよりも、計算的に効率的である可能性がある。 This eliminates the need for the user to instead perform a more resource-intensive and protracted dialogue in order to perform the action. Rather, the action is performed as one of several actions in the automated assistant routine to which it has been added. This is improved with humans and computers, for example, by reducing the amount of input that needs to be provided by the user (eg, provided to the user-automated assistant interface) to trigger the execution of an action. Can bring about dialogue. In addition to improving human-computer interaction, this has a variety of computer efficiencies, compared to, for example, requiring users to provide additional user interface input to perform actions instead. And / or can directly bring network efficiency. Moreover, as described above and elsewhere herein, automated assistant routine initialization can be processed efficiently and / or automatically in the event of a condition that does not require processing of user interface input. Can respond to shortened user interface inputs that can be targeted. In addition, recommend automated assistant actions for inclusion within existing routines, and actions in response to positive input of one-touch and / or single utterances (eg, "yes, add"). Automatically adding to a routine provides an efficient supplement to existing routines. For example, automatically adding an action in response to a simplified user interface input can manually select a routine to be modified, specify an action to add to the routine, or an action is a routine. Computationally more efficient than requiring the user to engage in a protracted dialogue to manually add an action, such as a protracted dialogue that requires the user to confirm that it should be added to There is a possibility.
本明細書で開示する実装形態は、ユーザの1つまたは複数の自動化されたアシスタントルーチン内に含めることを潜在的に推奨するための自動化されたアシスタントアクションを決定することができる。さらに、自動化されたアシスタントアクションは、ユーザに関連して記憶されている複数の自動化されたアシスタントルーチンの各々と比較され得、比較に基づいて(例えば、1つまたは複数の基準が満たされた場合)、自動化されたアシスタントルーチンのサブセット(例えば、1つ)が、選択され得る。グラフィカルおよび/または聴覚型ユーザインターフェース出力は、ユーザのクライアントデバイスを介してレンダリングされ得、ユーザインターフェース出力は、サブセットの選択されたルーチンにアクションを追加するようにユーザに促す。肯定的なユーザインターフェース入力が、ユーザインターフェース出力に応答して受信された場合、自動化されたアシスタントアクションは、肯定的なユーザインターフェース入力によって示される選択されたルーチンのうちの1つに自動的に(例えば、さらなるユーザインターフェース入力が必要とされることなく)追加され得る。その後、選択されたルーチンのうちの1つが、開始された場合、ルーチンの前から存在する自動化されたアシスタントアクションの自動的な実行が、選択されたアクションのうちの追加された1つの自動的な実行と同様に、初期化され得る。 The implementations disclosed herein can determine automated assistant actions to potentially recommend inclusion within one or more automated assistant routines of the user. In addition, automated assistant actions can be compared to each of a number of automated assistant routines stored in relation to the user, based on the comparison (eg, if one or more criteria are met). ), A subset of automated assistant routines (eg, one) may be selected. Graphical and / or auditory user interface output can be rendered through the user's client device, and the user interface output prompts the user to add actions to a subset of selected routines. If a positive user interface input is received in response to the user interface output, the automated assistant action automatically goes to one of the selected routines indicated by the positive user interface input ( For example, it can be added (without requiring additional user interface input). Then, if one of the selected routines is started, the automatic execution of the pre-existing automated assistant action of the routine will be the automatic execution of the added one of the selected actions. Like execution, it can be initialized.
様々な技法が、ユーザの1つまたは複数の自動化されたアシスタントルーチン内に含めることを潜在的に推奨するための自動化されたアシスタントアクションを決定するために利用され得る。いくつかの実装形態では、自動化されたアシスタントアクションを決定することは、ユーザによって提供されたユーザインターフェース入力の1つまたは複数のインスタンスを介して、自動化されたアシスタントアクションがユーザによって開始されることに基づく。例えば、「スマートサーモスタットを72度に調整する」自動化されたアシスタントアクションは、自動化されたアシスタントに提供された口頭および/または他のユーザインターフェース入力を介して自動化されたアシスタントアクションを開始するユーザの1つまたは複数の以前のインスタンスに基づいて決定され得る。いくつかの実装形態では、自動化されたアシスタントアクションを決定することは、異なるが関連する自動化されたアシスタントアクションが、ユーザによって提供されたユーザインターフェース入力の1つまたは複数のインスタンスを介してユーザによって開始されることに基づく。例えば、実行されるたびにグリルに関連する異なるヒントをレンダリングさせる「グリルのヒント」自動化されたアシスタントアクションは、グリルに関連するユーザインターフェース入力の1つまたは複数の過去のインスタンス(例えば、「どれくらい長くグリルにおいて鶏肉を料理するか」)をユーザが提供することに基づいて決定され得る。いくつかの実装形態では、自動化されたアシスタントアクションを決定することは、自動化されたアシスタントアクションが、ユーザの1つまたは複数の自動化されていないアシスタント対話に関連していることを決定することに基づく。例えば、「スマートサーモスタットを72度に調整する」自動化されたアシスタントアクションは、スマートサーモスタットを手動で(例えば、スマートサーモスタットとの直接対話を通じて)調整するか、またはスマートサーモスタットの制御専用の自動化されていないアシスタントアプリケーションを介してスマートサーモスタットを調整するユーザの1つまたは複数の発生を検出することに基づいて決定され得る。検出することは、例えば、自動化されたアシスタントに送信され、スマートサーモスタットが72度に調整されたことを示す状態変化指標に基づくことができる。状態変化指標は、スマートサーモスタットを制御するエージェントによって自動化されたアシスタントに送信され得、自動化されたアシスタントからの状態要求に応答してプッシュまたは提供され得る。いくつかの実装形態では、自動化されたアシスタントアクションを決定することは、ユーザが、自動化されたアシスタントアクションおよび/または関連するアクションを実行したことを必ずしも決定することなく、アクションが、人間と自動化されたアシスタントとの対話を改善し得ることを決定することに基づく。 Various techniques can be used to determine automated assistant actions to potentially recommend inclusion within one or more automated assistant routines of the user. In some implementations, determining an automated assistant action means that the automated assistant action is initiated by the user via one or more instances of the user interface input provided by the user. Based on. For example, an automated assistant action that "adjusts the smart thermostat to 72 degrees" is one of the users who initiates the automated assistant action via verbal and / or other user interface input provided to the automated assistant. It can be determined based on one or more previous instances. In some implementations, determining an automated assistant action is different, but related automated assistant actions are initiated by the user through one or more instances of the user interface input provided by the user. Based on being done. For example, a "grill hint" automated assistant action that renders different grill-related hints each time it is executed is one or more past instances of the grill-related user interface input (for example, "how long". Whether to cook chicken on the grill ") can be determined based on the user's provision. In some implementations, determining an automated assistant action is based on determining that the automated assistant action is related to one or more non-automated assistant dialogues of the user. .. For example, an automated assistant action that "adjusts the smart thermostat to 72 degrees" either adjusts the smart thermostat manually (for example, through direct interaction with the smart thermostat) or is not automated specifically for controlling the smart thermostat. It can be determined based on detecting the occurrence of one or more users adjusting the smart thermostat via an assistant application. The detection can be based, for example, on a state change indicator sent to an automated assistant to indicate that the smart thermostat has been adjusted to 72 degrees. The state change indicator may be sent to an automated assistant by an agent controlling the smart thermostat and may be pushed or provided in response to a state request from the automated assistant. In some implementations, determining an automated assistant action does not necessarily determine that the user has performed an automated assistant action and / or related action, and the action is automated with a human. Based on determining that the dialogue with the assistant can be improved.
アクションをルーチンと比較することに基づいて、自動化されたアシスタントアクションを追加することを推奨する、ユーザの自動化されたアシスタントルーチンのサブセットを選択することは、正しいルーチン(ある場合には)がアクションに対して推奨される尤度を高めることができ、それによって、無視または却下される推奨を提供するリスクを軽減する。さらに、ユーザのルーチン全体の代わりに、自動化されたアシスタントルーチンのサブセットをレンダリングすることは、レンダリングにおいて利用されるリソースを節約して使うことができる。いくつかの実装形態では、自動化されたアシスタントルーチンのサブセットは、ルーチンの過去の発生の時間的属性を、自動化されたアシスタントアクションの(または、自動化されたアシスタントアクションに関連するアクションの)過去の発生の時間的属性と比較することに基づいて選択される。例えば、ユーザに関する自動化されたアシスタントアクションの過去の発生が、平日の朝にのみ発生した場合、平日の朝に頻繁に開始されるユーザのルーチンは、平日の夜に頻繁に開始されるユーザのルーチン、または週末の朝に頻繁に開始されるユーザのルーチンよりも、サブセットに選択される可能性が高くなり得る。 Choosing a subset of the user's automated assistant routines, which recommends adding automated assistant actions based on comparing the action to the routine, makes the correct routine (if any) an action. The likelihood of being recommended can be increased, thereby reducing the risk of providing recommendations that are ignored or rejected. Moreover, rendering a subset of automated assistant routines instead of the entire user's routine can save resources used in rendering. In some implementations, a subset of automated assistant routines have a temporal attribute of the routine's past occurrences, the past occurrences of the automated assistant action (or the action associated with the automated assistant action). Selected based on comparison with the temporal attribute of. For example, if the past occurrence of automated assistant actions for a user occurred only on weekday mornings, then a user's routine that starts frequently on weekday mornings would be a user's routine that starts frequently on weekday nights. , Or may be more likely to be selected as a subset than a user's routine that starts frequently on weekend mornings.
いくつかの実装形態では、自動化されたアシスタントルーチンのサブセットは、追加的または代替的には、ルーチンにおいて利用されるデバイスのデバイストポロジ属性を、自動化されたアシスタントアクションにおいて利用されるデバイスのデバイストポロジ属性と比較することに基づいて選択される。例えば、自動化されたアシスタントアクションが、「場所=居間」という割り当てられたデバイストポロジ属性を有するテレビの制御に関連している場合、「場所=居間」という割り当てられたデバイストポロジ属性を有する他のデバイス(例えば、居間のライト、居間のスピーカなど)を制御するアクションを含むルーチンは、「場所=居間」というデバイストポロジ属性を有するデバイスを制御するいかなるアクションもないルーチンよりも、サブセットに選択される可能性が高くなり得る。別の例として、自動化されたアシスタントアクションが、「表示可能」の割り当てられたデバイストポロジ属性を有するデバイスを介するコンテンツの表示を必要とする場合、「表示可能」デバイストポロジ属性を有するデバイスを有するエリア内に位置するデバイスを制御するアクションを含むルーチンは、「表示可能」デバイストポロジ属性を有するデバイスを有するエリア内のデバイスを制御するいかなるアクションもないルーチンよりも、サブセットに選択される可能性が高くなり得る。 In some implementations, a subset of automated assistant routines, in addition or alternative, device topology attributes of the device utilized in the routine, and device topology attributes of the device utilized in the automated assistant action. Selected based on comparison with. For example, if an automated assistant action is related to controlling a TV with the assigned device topology attribute "location = living room", then other devices with the assigned device topology attribute "location = living room". Routines that contain actions that control (for example, living room lights, living room speakers, etc.) can be selected in a subset over routines that have no action that controls devices with the "location = living room" device topology attribute. Can be highly sexual. As another example, if an automated assistant action requires the display of content through a device that has the "visible" assigned device topology attribute, an area that has a device that has the "visible" device topology attribute. Routines that contain actions that control devices located within are more likely to be selected as a subset than routines that do not have any actions that control devices in an area that has devices with the "visible" device topology attribute. Can be.
いくつかの実装形態では、自動化されたアシスタントルーチンのサブセットは、追加的または代替的には、自動化されたアシスタントアクションとの矛盾を含む任意のルーチンをサブセットから除外することに基づいて選択される。例えば、「スマートサーモスタットを72度に調整する」自動化されたアシスタントアクションについて、所与のルーチンは、競合する「スマートサーモスタットを75度に調整する」アクションを有することに基づいて除外され得る。また、例えば、夕方にのみ利用可能なサービスを実行するためにエージェントとインターフェースする自動化されたアシスタントアクションについて、所与のルーチンは、それが夕方ではなく朝に自動的に発生することに基づいて除外され得る。 In some implementations, a subset of automated assistant routines are selected based on, in addition or alternative, excluding any routines from the subset that contain inconsistencies with automated assistant actions. For example, for an automated assistant action that "adjusts the smart thermostat to 72 degrees", a given routine can be excluded based on having a competing "adjust smart thermostat to 75 degrees" action. Also, for example, for an automated assistant action that interfaces with an agent to perform a service that is only available in the evening, a given routine is excluded based on that it happens automatically in the morning rather than in the evening. Can be done.
いくつかの実装形態では、自動化されたアシスタントルーチンに追加するための複数の競合するアクションが、考慮され得、競合するアクションのサブセット(例えば、その1つ)のみが、ルーチンに追加するために、ユーザインターフェース出力を介して、実際に推奨するために選択され得る。それらの実装形態のうちのいくつかでは、複数の競合するアクションの各々が、ルーチンと比較され得、選択されたアクションは、ルーチンに最も密接に従う、ルーチンとのいかなる競合もない、および/または他の基準を満たす、複数の競合するアクションのうちの1つであり得る。いくつかの追加または代替の実装形態では、複数の競合するアクションは、第1のエージェントによって実行される第1のアクションと、第2のエージェントによって実行される第2のアクションとを含むことができる。例えば、第1のアクションは、音楽をストリーミングする第1のエージェントによってジャズ音楽をレンダリングさせることであり得、第2のアクションは、音楽をストリーミングする第2のエージェントによってジャズ音楽をレンダリングさせることであり得る。それらの実装形態のうちのいくつかでは、第1のエージェントおよび第2のエージェントのうちの1つが、第1のエージェントおよび第2のエージェントに関連付けられた1つまたは複数の尺度に基づいて選択され得る。そのような尺度は、例えば、ユーザによる第1のエージェントおよび/もしくは第2のエージェントの使用頻度、ユーザの集団による第1のエージェントおよび/もしくは第2のエージェントの使用頻度、(ユーザおよび/またはユーザの集団による)第1のエージェントおよび/もしくは第2のエージェントに割り当てられた評価、ならびに/またはアクションを実行するためのそれぞれのエージェントの能力および/もしくは欲求を示す第1のエージェントおよび/もしくは第2のエージェントによっておよび/もしくはその代わりに提供されたデータを含むことができる。 In some implementations, multiple competing actions to add to an automated assistant routine can be considered, and only a subset of the competing actions (eg, one of them) can be added to the routine. It may be selected to actually recommend via the user interface output. In some of those implementations, each of the multiple conflicting actions can be compared to a routine, the selected action follows the routine most closely, there is no conflict with the routine, and / or others. Can be one of multiple competing actions that meet the criteria of. In some additional or alternative implementations, multiple conflicting actions can include a first action performed by a first agent and a second action performed by a second agent. .. For example, the first action could be to have the jazz music rendered by the first agent that streams the music, and the second action would be to have the jazz music rendered by the second agent that streams the music. obtain. In some of those implementations, one of the first and second agents is selected based on one or more scales associated with the first and second agents. obtain. Such measures include, for example, how often users use the first and / or second agent, how often a group of users use the first and / or second agent, (users and / or users). 1st agent and / or 2nd showing the assessment assigned to the 1st agent and / or the 2nd agent (by a population of) and / or the ability and / or desire of each agent to perform an action. Can include data provided by and / or instead of agents of.
いくつかの実装形態では、少なくとも1つの選択された自動化されたアシスタントルーチンに自動化されたアシスタントアクションを追加するようにユーザに促すユーザインターフェース出力が、選択されたルーチンの実行の終了時、または自動化されたアシスタントアクションの実行の終了時に提供され得る。例えば、「おはよう」ルーチンを実行した後、自動化されたアシスタントは、「ところで、アクションXは、このルーチンに追加するのがよいようですが、私にそれを追加してほしいですか」のグラフィカルおよび/または可聴プロンプトを提供することができ、肯定的な入力が、応答において受信された場合、「アクションX」は、「おはよう」ルーチンに追加され得る。例えば、ユーザのユーザインターフェース入力(例えば、「アシスタント、アクションXを実行して」の口頭入力)に応答して「アクションX」を実行した後、自動化されたアシスタントは、「ところで、これは、あなたのおはようルーチンに追加するのがよいようですが、私にそれを追加してほしいですか」のグラフィカルおよび/または可聴プロンプトを提供することができる。肯定的な入力が、応答において受信された場合、「アクションX」は、「おはよう」ルーチンに追加され得る。これらおよび他の方法において、提示されたユーザインターフェース出力は、人間と自動化されたアシスタントとの対話を促進し、肯定的な入力が応答において受信された場合、ルーチンの前から存在するアクションと、ルーチンに追加されたアクションの両方を実行するために将来必要になるユーザ入力の量を低減する。例えば、「アクションX」は、接続されたデバイスを制御していることができ、提示されたユーザインターフェース入力は、ユーザが応答において肯定的な入力を提供することを可能にし、結果として、対応するルーチンのさらなる開始に応答して、接続されたデバイスの制御を自動的に生じさせることによって、人間と自動化されたアシスタントとの対話を促進することができる。 In some implementations, user interface output prompting the user to add an automated assistant action to at least one selected automated assistant routine is at the end of execution of the selected routine, or is automated. Can be provided at the end of the execution of an assistant action. For example, after running the "Good morning" routine, the automated assistant said, "By the way, Action X seems like it would be nice to add it to this routine, do you want me to add it?" Graphically and / Or an audible prompt can be provided and if positive input is received in the response, "action X" may be added to the "good morning" routine. For example, after performing "Action X" in response to a user's user interface input (eg, "Assistant, perform Action X" verbal input), the automated assistant says, "By the way, this is you. It seems like it would be nice to add it to the good morning routine, but would you like me to add it? ”Can provide a graphical and / or audible prompt. If a positive input is received in the response, "action X" may be added to the "good morning" routine. In these and other ways, the presented user interface output facilitates human interaction with the automated assistant, and if a positive input is received in the response, the pre-existing action of the routine and the routine. Reduce the amount of user input that will be required in the future to perform both of the actions added to. For example, "action X" can control the connected device, and the presented user interface input allows the user to provide a positive input in the response and, as a result, responds. Interaction between humans and automated assistants can be facilitated by automatically giving rise to control of connected devices in response to further initiation of the routine.
いくつかの実装形態では、自動化されたアシスタントアクションをルーチンに追加する際に、ルーチンの前から存在するアクションの中に、自動化されたアシスタントアクションの実行の位置が、決定され得る。それらの実装形態のいくつかの変形例では、位置は、自動化されたアシスタントアクションによって必要とされるユーザインターフェース出力(もしあれば)の持続時間と、ルーチンの前から存在するアクションによって必要とされるユーザインターフェース出力(もしあれば)の持続時間とに基づいて決定され得る。例えば、自動化されたアシスタントアクションが、スマートデバイスを制御しており、ユーザインターフェース出力を必要としない(または、非常に短い「デバイス制御」出力を必要とする)場合、それは、より永続的なユーザインターフェース出力がレンダリングされることを必要とする1つまたは複数のアクションの前に実行されるように配置され得る。いくつかの追加または代替の変形例では、実行の位置は、最後であり得、オプションでは時間的遅延を伴って発生することができる。時間的遅延は、例えば、ルーチンの過去の実行に対する(ユーザの過去の入力に応答した)自動化されたアシスタントアクションの過去の実行の時間的遅延に基づくことができる。例えば、自動化されたアシスタントアクションが、スマートコーヒーメーカーの抽出サイクルを開始しており、「おはよう」ルーチンに追加されたと仮定する。自動化されたアシスタントアクションが、(「おはよう」ルーチンに追加する前に)「アシスタント、私のコーヒーを淹れて」の発話に応答して、おはようルーチンの終了後に3回以前に実行されたとさらに仮定する。3つの発話が、おはようルーチンの終了の2分後、3分後、および4分後に発生した場合、自動化されたアシスタントアクションは、3分(3つの遅延の平均)の時間的遅延などの時間的遅延を伴っておはようルーチンに追加され得る。 In some implementations, when adding an automated assistant action to a routine, the position of execution of the automated assistant action can be determined among the pre-existing actions of the routine. In some variants of those implementations, the position is required by the duration of the user interface output (if any) required by the automated assistant action and by the pre-existing action of the routine. It can be determined based on the duration of the user interface output (if any). For example, if an automated assistant action controls a smart device and does not require user interface output (or requires very short "device control" output), it is a more persistent user interface. The output can be arranged to be performed before one or more actions that require it to be rendered. In some additional or alternative variants, the position of execution can be last and can optionally occur with a time delay. The time delay can be based, for example, on the time delay of the past execution of an automated assistant action (in response to the user's past input) with respect to the past execution of the routine. For example, suppose an automated assistant action has started the smart coffee maker brewing cycle and has been added to the "good morning" routine. Further assume that the automated assistant action was performed three times before the end of the good morning routine in response to the utterance "Assistant, brew my coffee" (before adding it to the "good morning" routine). do. If three utterances occur two minutes, three minutes, and four minutes after the end of the good morning routine, the automated assistant action will have a time delay of three minutes (the average of the three delays). It can be added to the good morning routine with a delay.
上記で参照したように、いくつかの自動化されたアシスタントルーチンは、ユーザの口頭のまたはタイプされた自然言語入力におけるショートカットフレーズまたはコマンドを検出したことに応答して初期化され得る。ショートカットコマンドは、オプションでは特定の順序で、自動化されたアシスタントにアクションのセットを実行させるための短縮されたコマンドを提供する。アクションのセットのためのより長いコマンドの代わりにアクションのセットの実行を引き起こさせるショートカットコマンドを提供することは、より少ないユーザ入力が提供される(ならびに送信および/または処理される)ことを可能にし、それによって、計算リソースおよびネットワークリソースを節約して使うことができる。加えて、既存のショートカットコマンドに応答して実行されるルーチンの追加アクションとして自動化されたアシスタントアクションを自動的に追加することは、その後、ルーチンの追加のアクションおよび前から存在するアクションがショートカットコマンドに応答して実行されることを可能にする。したがって、ショートカットコマンドは、その後、追加のアクションのためのコマンドとショートカットコマンドの両方を話す代わりに、ユーザによって話されるかまたはタイプされ得る。自動化されたアシスタントルーチンのための短縮されたコマンドの一例として、ユーザが朝起きたときに、ユーザは、キッチンアシスタントデバイス(すなわち、キッチンに配置されたクライアントコンピューティングデバイス)に発話を提供することによって「おはよう」ルーチンをトリガすることができる。発話は、例えば、「おはよう」ルーチンを初期化するためにアシスタントデバイスおよび/または(アシスタントデバイスと通信している)リモートアシスタントデバイスによって処理され得る「おはよう」であり得る。例えば、アシスタントデバイスおよび/またはリモートデバイスは、発話をテキストに変換するために発話に対応するオーディオデータを処理することができ、さらに、「おはよう」というテキストが、ユーザのために、「おはよう」の発話に応答して実行される自動化されたアシスタントアクションのセットに割り当てられていることを決定することができる。本明細書で説明した実装形態に従って「おはよう」ルーチンに新しいアクションを追加することは、ユーザのために、新しいアクションを「おはよう」というテキストにさらに割り当てる。 As referenced above, some automated assistant routines may be initialized in response to detecting a shortcut phrase or command in the user's verbal or typed natural language input. Shortcut commands optionally provide a shortened command that allows an automated assistant to perform a set of actions, in a particular order. Providing shortcut commands that trigger the execution of a set of actions instead of longer commands for the set of actions allows less user input to be provided (and sent and / or processed). , It saves computational and network resources. In addition, automatically adding an automated assistant action as an additional action for a routine that is executed in response to an existing shortcut command will then add the routine's additional actions and pre-existing actions to the shortcut command. Allows it to be executed in response. Thus, the shortcut command can then be spoken or typed by the user instead of speaking both the command for the additional action and the shortcut command. As an example of a shortened command for an automated assistant routine, when the user wakes up in the morning, the user "is" by providing an utterance to the kitchen assistant device (ie, a client computing device located in the kitchen). You can trigger a "good morning" routine. The utterance can be, for example, "good morning" that can be processed by the assistant device and / or the remote assistant device (which is communicating with the assistant device) to initialize the "good morning" routine. For example, an assistant device and / or a remote device can process the audio data corresponding to the utterance to convert the utterance to text, and the text "Good morning" is for the user, "Good morning". You can determine that you are assigned to a set of automated assistant actions that are performed in response to an utterance. Adding a new action to the "Good morning" routine according to the implementation described herein further assigns the new action to the text "Good morning" for the user.
様々な自動化されたアシスタントルーチンは、話されるかまたはタイプされたショートカットコマンドに応答して初期化され得るが、いくつかの実装形態では、自動化されたアシスタントルーチンは、追加的または代替的に、ユーザが、クライアントデバイスもしくは周辺デバイスにおいて仮想もしくはハードウェア要素を押下すること、クライアントデバイスのセンサを介して検出されるジェスチャを実行すること、クライアントデバイスにおいて他の触覚入力を提供すること、および/または任意の他のタイプのコンピュータ可読ユーザインターフェース入力を提供することに応答して初期化され得る。例えば、グラフィカルユーザインターフェース(GUI)は、選択可能なアイコンとともにクライアントデバイスにおいて提示され得、そこで、選択可能なアイコンは、自動化されたアシスタントルーチンを初期化するための提案をユーザに提供する。ユーザが選択可能なアイコン(例えば、「おはよう」と書いてあるGUIボタン)を選択した場合、自動化されたアシスタントは、それに応じて対応する自動化されたアシスタントルーチンを初期化することができる。加えてまたは代替的に、自動化されたアシスタントルーチンは、例えば、自動化されたアシスタントが、ユーザの存在を検出したこと(例えば、音声認証および/または顔認識を使用して特定のユーザを検出すること)、ユーザの場所を検出したこと(例えば、家、車内、居間、および/または追加の場所などの場所において音声認証および/または顔認識を使用して特定のユーザを検出すること)、アラーム(例えば、関連する電話または他のデバイスにおいて設定されている目覚ましアラーム)が解除されていることを検出したこと、アプリケーションの起動を検出したこと、および/または自動化されたアシスタントによって(例えば、1つまたは複数のクライアントデバイスからの信号に基づいて)認識され得る他のユーザアクションを検出したことに応答して、自動的に初期化され得る。例えば、「おはよう」ルーチンは、「朝」(すなわち、特定の時間、時間範囲の間、および/またはルーチンに関連する追加の時間)において、顔認識を使用して、ユーザが、キッチンにおいて検出された場合、初期化され得る。 Various automated assistant routines can be initialized in response to spoken or typed shortcut commands, but in some implementations automated assistant routines are additional or alternative. A user presses a virtual or hardware element on a client device or peripheral device, performs a gesture detected through a sensor on the client device, provides other tactile inputs on the client device, and / or It can be initialized in response to providing any other type of computer-readable user interface input. For example, a graphical user interface (GUI) may be presented on the client device along with selectable icons, where the selectable icons provide the user with suggestions for initializing an automated assistant routine. If the user selects a selectable icon (eg, a GUI button labeled "Good morning"), the automated assistant can initialize the corresponding automated assistant routine accordingly. In addition or alternatives, an automated assistant routine is, for example, that the automated assistant has detected the presence of a user (eg, using voice authentication and / or face recognition to detect a particular user. ), Detecting a user's location (eg, using voice authentication and / or face recognition in locations such as homes, cars, living rooms, and / or additional locations), alarms ( For example, it has detected that the wake-up alarm set on the associated phone or other device has been cleared, it has detected the launch of an application, and / or it has been detected by an automated assistant (eg, one or more). It can be automatically initialized in response to detecting other recognizable user actions (based on signals from multiple client devices). For example, a "good morning" routine is detected in the kitchen by a user using facial recognition in the "morning" (ie, during a particular time, time range, and / or additional time associated with the routine). If so, it can be initialized.
例示的な「おはよう」ルーチンは、ユーザのスケジュールをレンダリングさせること、特定の器具をオンにさせること、およびポッドキャストをレンダリングさせることなどのアクションを含むことができる。再び、自動化されたアシスタントがショートカットコマンドに応答することを可能にすることによって、ユーザは、自動化されたアシスタントに対応するアクションを実行させるために、必ずしも一連のコマンドを提供する必要はない(例えば、ユーザは、「アシスタント、私のスケジュールを読んで、私の器具をオンにして、私のポッドキャストを再生して」という発話を暗唱する必要はない)。代わりに、自動化されたアシスタントは、ショートカットコマンドに応答することができ、ショートカットコマンドは、自動化されたアシスタントがショートカットコマンドに対応するアクションを識別するために処理することができる。いくつかの実装形態では、ルーチンは、パーソナライズされ得、それによって、自動化されたアシスタントによってアクションの特定のセットをあるユーザのために実行させるためのルーチンの実行を引き起こす特定のショートカットコマンドまたは他の入力を可能にし、一方、同じ入力は、自動化されたアシスタントによってアクションの異なるセットを異なるユーザのために実行させる。例えば、特定のユーザは、ショートカットコマンドに応答してアクションの第1のセットを実行するように、自動化されたアシスタントを具体的に構成してもよく、特定のユーザの配偶者は、同じショートカットコマンドに応答してアクションの第2のセットを実行するように、自動化されたアシスタントを構成することができる。自動化されたアシスタントは、1つもしくは複数のセンサ入力、ならびに/または音声署名、顔認識、画像フィード、動作特性、および/もしくは他のデータなどの1つもしくは複数の決定された特性を使用して、ショートカットコマンドを提供するユーザを区別することができる。さらに、本明細書で説明したように、自動化されたアシスタントは、所与のユーザに推奨されるべき自動化されたアシスタントアクションを決定する際、ユーザに固有の自動化されたアシスタントルーチンを決定する際、およびユーザのルーチンに自動化されたアシスタントアクションを追加するように促すユーザインターフェース出力をいつ提供するかを決定する(例えば、ユーザに特定化されたユーザインターフェース出力は、ユーザが自動化されたアシスタントと対話していると決定された場合にのみ提供され得る)際に、ユーザを区別することができる。 An exemplary "good morning" routine can include actions such as rendering a user's schedule, turning on certain instruments, and rendering a podcast. Again, by allowing the automated assistant to respond to shortcut commands, the user does not necessarily have to provide a set of commands to perform the action corresponding to the automated assistant (eg,). The user does not have to recite the utterance "Assistant, read my schedule, turn on my equipment, and play my podcast"). Instead, the automated assistant can respond to the shortcut command, and the shortcut command can be processed by the automated assistant to identify the action corresponding to the shortcut command. In some implementations, a routine can be personalized, thereby causing a specific shortcut command or other input to cause the routine to execute a specific set of actions for a user by an automated assistant. On the other hand, the same input causes a different set of actions to be performed for different users by an automated assistant. For example, a particular user may specifically configure an automated assistant to perform a first set of actions in response to a shortcut command, and the spouse of a particular user may have the same shortcut command. An automated assistant can be configured to perform a second set of actions in response to. Automated assistants use one or more sensor inputs and / or one or more determined characteristics such as voice signatures, facial recognition, image feeds, behavioral characteristics, and / or other data. , Can distinguish the user who provides the shortcut command. Further, as described herein, an automated assistant may be responsible for determining a user-specific automated assistant routine when determining an automated assistant action that should be recommended for a given user. And determine when to provide user interface output that prompts users to add automated assistant actions to their routines (for example, user-specific user interface output allows the user to interact with the automated assistant. Users can be distinguished when (can only be provided if determined to be).
ユーザが、「おはよう」などのショートカットコマンドをキッチンアシスタントデバイスなどのアシスタントデバイスに提供した場合、ルーチンの1つまたは複数のアクションに対応するコンテンツは、キッチンアシスタントデバイスに向けられている発話の結果として、キッチンアシスタントデバイスによって最初にレンダリングされ得る。例えば、コンテンツは、他のデバイスがショートカットコマンドを認識していても、最初にキッチンアシスタントデバイスにおいて排他的に(すなわち、いかなる他のクライアントデバイスにおいても同時にレンダリングされることなく)レンダリングされ得る。例えば、複数のデバイスは、それらのそれぞれの自動化されたアシスタントインターフェースにおいて受信されているショートカットコマンドを認識することができるが、最も音が大きいおよび/または最も歪が少ないショートカットコマンドを受信したデバイスは、自動化されたアシスタントルーチンが初期化されるデバイスとして指定され得る。 If the user provides a shortcut command such as "Good morning" to an assistant device such as the kitchen assistant device, the content corresponding to one or more actions of the routine is the result of an utterance directed to the kitchen assistant device. Can be rendered first by the kitchen assistant device. For example, content can be rendered exclusively on the kitchen assistant device first (ie, without being rendered simultaneously on any other client device), even if other devices are aware of the shortcut command. For example, multiple devices can recognize the shortcut commands being received in their respective automated assistant interfaces, while the device receiving the loudest and / or least distorted shortcut command An automated assistant routine can be designated as the device to be initialized.
ユーザが、オフィスアシスタントデバイスを用いてオフィス内でアクションを実行した場合、自動化されたアシスタントは、アクションを「おはよう」ルーチンに追加することを依然として提案することができる。例えば、ユーザが、キッチン内でユーザの「おはよう」ルーチンを完了した後にユーザのオフィスに移動し、次いで、オフィスアシスタントデバイスにニュースの見出しに関する発話を行った場合、自動化されたアシスタントは、キッチンアシスタントデバイスを介してキッチン内で実行される「おはよう」ルーチンに、ニュースの見出しをレンダリングするアクションを追加することを提案することができる。いくつかの実装形態では、オフィスアシスタントデバイスは、アクションが、「おはよう」ルーチンとは異なるデバイスにおいて実行された場合であっても、オフィスにおいて実行されたアクション(すなわち、ニュースの見出しをレンダリングすること)を「おはよう」ルーチンに追加することを提案することができる。いくつかの実装形態では、ユーザが、オフィスアシスタントにニュースの見出しを要求した後、ユーザが、オフィスにいる間、オフィスデバイスは、ニュースの見出しをレンダリングするアクションを「おはよう」ルーチンに追加することを提案するために利用され得る。他の実装形態では、「おはよう」ルーチンの完了後、ユーザがまだキッチンデバイスの近くにいる間、キッチンアシスタントデバイスは、ニュースの見出しをレンダリングする新しいアクションを「おはよう」ルーチンに追加することをユーザに提案することができる。加えてまたは代替的に、いくつかの実装形態では、自動化されたアシスタントは、「おはよう」ルーチンが実行される前であるが、ユーザが、キッチンデバイスによってショートカットコマンドを介してルーチンを要求した後に、ユーザが、キッチンデバイスの近くで検出された場合、オフィス内で過去に実行されたアクションを追加することをユーザに提案することができる。 If the user performs an action in the office using the office assistant device, the automated assistant can still suggest adding the action to the "good morning" routine. For example, if a user moves to the user's office after completing the user's "good morning" routine in the kitchen and then speaks to the office assistant device about a news headline, the automated assistant will be the kitchen assistant device. It can be suggested to add an action that renders news headlines to the "good morning" routine that runs in the kitchen via. In some implementations, the office assistant device is an action performed in the office (ie, rendering a news headline), even if the action was performed on a device different from the "good morning" routine. Can be suggested to be added to the "Good morning" routine. In some implementations, after the user requests a news headline from the office assistant, the office device adds an action to the "good morning" routine to render the news headline while the user is in the office. Can be used to make suggestions. In other implementations, after the "Good Morning" routine is complete, the Kitchen Assistant device tells the user to add a new action to the "Good Morning" routine to render the news headline while the user is still near the kitchen device. I can make a suggestion. In addition or alternatively, in some implementations, the automated assistant is before the "good morning" routine is executed, but after the user requests the routine via a shortcut command by the kitchen device. If the user is detected near the kitchen device, he can suggest to the user to add an action that was previously performed in the office.
いくつかの実装形態では、自動化されたアシスタントルーチンにアクションを追加することに制限が課され得る。例えば、配偶者と一緒に暮らしているユーザは、「おはよう」ルーチンを有する場合があり、ユーザの配偶者は、配偶者自身の「おはよう」ルーチンを有する場合がある。ユーザは、ユーザの配偶者のおはようルーチンにアクションを追加したくない場合がある(逆も同様)。いくつかの実装形態では、自動化されたアシスタントは、センサ入力、ならびに/または音声署名、顔認識、画像フィード、動作特性、および/もしくは他のデータなどの1つもしくは複数の決定された特徴を介して、ユーザまたはユーザの配偶者がアクションを実行しているかどうかを決定することができる。いくつかの実装形態では、マルチユーザ世帯における自動化されたアシスタントルーチンにおけるデフォルト設定は、ルーチンのユーザのみがユーザの個人ルーチンを変更する権限を有するためのものであり得る。いくつかの実装形態では、ユーザは、他のユーザ(ユーザの配偶者など)がユーザの個人ルーチンにアクションを追加することを可能にするために、自動化されたアシスタントに許可を与えることができる。加えて、いくつかの実装形態では、アクションを追加するルーチンを提案する前に、適切な同意が得られた場合、自動化されたアシスタントは、世帯の他のメンバのための同様のルーチンにおけるアクションを再調査することができる。例えば、スマートコーヒーメーカーなどのデバイスをオンにするアクションをユーザのおはようルーチンに追加することを提案する前に、自動化されたアシスタントは、配偶者のおはようルーチンを再調査し、アクションが朝の間に世帯内ですでに実行されているかどうかを決定することができる。言い換えれば、アクションを追加することを提案するルーチンを決定するとき、例えば、2人のユーザの両方が、2人のユーザの「おはよう」ルーチンの一部として、朝にコーヒーメーカーをオンにするなどの、重複アクションを防ぐために、自動化されたアシスタントは、ユーザのルーチンを再調査し、それらを世帯の他のメンバに関連付けられたルーチンと比較することができる。 Some implementations may impose restrictions on adding actions to automated assistant routines. For example, a user living with a spouse may have a "good morning" routine, and the user's spouse may have a spouse's own "good morning" routine. The user may not want to add an action to the user's spouse's good morning routine (and vice versa). In some implementations, the automated assistant is via sensor input and / or one or more determined features such as voice signatures, face recognition, image feeds, behavioral characteristics, and / or other data. You can determine if the user or the user's spouse is performing the action. In some implementations, the default settings in an automated assistant routine in a multi-user household may be such that only the user of the routine has the authority to modify the user's personal routine. In some implementations, the user can grant permission to an automated assistant to allow other users (such as the user's spouse) to add actions to the user's personal routines. In addition, in some implementations, if appropriate consent is obtained before proposing a routine to add an action, the automated assistant will perform the action in a similar routine for other members of the household. Can be re-examined. For example, before proposing to add an action to turn on a device such as a smart coffee maker to the user's good morning routine, an automated assistant re-examines the spouse's good morning routine and the action is during the morning. You can decide if it is already running in your household. In other words, when deciding on a routine to suggest adding an action, for example, both of the two users turn on the coffee maker in the morning as part of the two users' "good morning" routine. To prevent duplicate actions, the automated assistant can review the user's routines and compare them with the routines associated with other members of the household.
いくつかの実装形態では、ルーチンを実行する際に、自動化されたアシスタントは、1つまたは複数のローカルエージェントおよび/またはリモートエージェントとインターフェースする。例えば、3つのアクションを含むルーチンについて、自動化されたアシスタントは、第1のアクションを実行する際に第1のエージェントと、第2のアクションを実行する際に第2のエージェントと、第3のアクションを実行する際に第3のエージェントとインターフェースすることができる。本明細書で使用される場合、「エージェント」は、自動化されたアシスタントによって利用される1つまたは複数のコンピューティングデバイスおよび/またはソフトウェアを指す。いくつかの状況では、エージェントは、自動化されたアシスタントとは別であり得、および/または1つもしくは複数の通信チャネルを介して自動化されたアシスタントと通信してもよい。それらの状況のうちのいくつかでは、自動化されたアシスタントは、第1のネットワークノードから、データ(例えば、エージェントコマンド)を、エージェントの機能のすべてまたは態様を実装する第2のネットワークノードに送信してもよい。いくつかの状況では、エージェントは、自動化されたアシスタントを管理するパーティとは別のパーティによって管理されるという点で、サードパーティ(3P)エージェントであってもよい。いくつかの他の状況では、エージェントは、自動化されたアシスタントを管理するのと同じパーティによって管理されるという点で、ファーストパーティ(1P)エージェントであってもよい。 In some implementations, the automated assistant interfaces with one or more local and / or remote agents when executing routines. For example, for a routine that contains three actions, the automated assistant will have the first agent when performing the first action, the second agent when performing the second action, and the third action. Can be interfaced with a third agent when executing. As used herein, "agent" refers to one or more computing devices and / or software utilized by an automated assistant. In some situations, the agent may be separate from the automated assistant and / or may communicate with the automated assistant via one or more communication channels. In some of those situations, the automated assistant sends data (eg, agent commands) from the first network node to the second network node that implements all or aspects of the agent's functionality. You may. In some situations, the agent may be a third-party (3P) agent in that it is managed by a party other than the party that manages the automated assistant. In some other situations, the agent may be a first-party (1P) agent in that it is managed by the same party that manages the automated assistant.
エージェントは、自動化されたアシスタントからの呼び出し要求および/または他のエージェントコマンドを(例えば、ネットワークを介して、および/またはAPIを介して)受信するように構成される。エージェントコマンドを受信したことに応答して、エージェントは、エージェントコマンドに基づいて応答コンテンツを生成し、応答コンテンツに基づくユーザインターフェース出力の供給のために応答コンテンツを送信する。例えば、エージェントは、応答コンテンツに基づく自動化されたアシスタントによる出力の供給のために、応答コンテンツを自動化されたアシスタントに送信してもよい。別の例として、エージェント自体が、出力を提供することができる。例えば、ユーザは、クライアントデバイスを介して自動化されたアシスタントと対話することができ(例えば、自動化されたアシスタントは、クライアントデバイス上および/またはクライアントデバイスとのネットワーク通信において実装され得る)、エージェントは、クライアントデバイス上にインストールされたアプリケーション、またはクライアントデバイスから離れて実行可能であるが、クライアントデバイス上に「ストリーミング可能」なアプリケーションであり得る。アプリケーションが呼び出された場合、アプリケーションは、クライアントデバイスによって実行され得、および/またはクライアントデバイスによって最前面に置かれ得る(例えば、そのコンテンツが、クライアントデバイスの表示を引き継ぐことができる)。 Agents are configured to receive call requests and / or other agent commands from automated assistants (eg, over the network and / or via APIs). In response to receiving the agent command, the agent generates response content based on the agent command and sends the response content to provide user interface output based on the response content. For example, the agent may send the response content to the automated assistant for delivery of output by the automated assistant based on the response content. As another example, the agent itself can provide the output. For example, a user can interact with an automated assistant through a client device (eg, an automated assistant can be implemented on a client device and / or in network communication with a client device). It can be an application installed on a client device, or an application that can run away from the client device but is "streamable" on the client device. When the application is called, the application can be run by the client device and / or brought to the foreground by the client device (for example, its content can take over the display of the client device).
上記は、本明細書で開示した様々な実装形態の概要として提供されている。それらの様々な実装形態、ならびに追加の実装形態に関して、追加の詳細が、本明細書で提供される。 The above is provided as an overview of the various implementations disclosed herein. Additional details are provided herein with respect to their various implementations, as well as additional implementations.
いくつかの実装形態では、1つまたは複数のプロセッサによって実行される方法が、提供され、自動化されたアシスタントによって開始されるアクションを決定するステップを含む。アクションは、自動化されたアシスタントと対話する1つまたは複数の自動化されたアシスタントインターフェースを介してユーザによって提供されたユーザインターフェース入力の1つまたは複数のインスタンスに応答して、自動化されたアシスタントによって開始される。方法は、ユーザに関連して記憶された複数の自動化されたアシスタントルーチンを識別するステップをさらに含む。自動化されたアシスタントルーチンの各々は、自動化されたアシスタントルーチンの初期化に応答して自動化されたアシスタントを介して自動的に実行されるべき複数の対応するアクションを定義し、アクションは、自動化されたアシスタントルーチンのアクションに追加される。方法は、アクションを、ユーザに関連して記憶された複数の自動化されたアシスタントルーチンと比較するステップをさらに含む。方法は、比較に基づいて、ユーザに関連して記憶された自動化されたアシスタントルーチンのサブセットを選択するステップをさらに含む。方法は、ユーザによって提供されたユーザインターフェース入力に応答してアクションが開始されることに基づくとともに、自動化されたアシスタントルーチンのサブセットを選択したことに基づいて、ユーザのクライアントデバイスを介してユーザインターフェース出力をレンダリングさせるステップをさらに含む。ユーザインターフェース出力は、サブセットの自動化されたアシスタントルーチンのうちの1つまたは複数にアクションを追加するようにユーザに促す。方法は、ユーザインターフェース出力に応答して肯定的なユーザインターフェース入力を受信するステップをさらに含み、肯定的なユーザインターフェース入力は、サブセットの自動化されたアシスタントルーチンのうちの所与のルーチンを示す。方法は、肯定的なユーザインターフェース入力を受信したことに応答して、所与のルーチンの初期化に応答して自動的に実行されるべき所与のルーチンの複数の対応するアクションの追加の1つとしてアクションを自動的に追加するステップをさらに含む。 In some implementations, a method performed by one or more processors is provided and involves determining the action initiated by an automated assistant. The action is initiated by the automated assistant in response to one or more instances of user interface input provided by the user through one or more automated assistant interfaces that interact with the automated assistant. NS. The method further comprises identifying multiple automated assistant routines stored in relation to the user. Each of the automated assistant routines defines multiple corresponding actions that should be performed automatically through the automated assistant in response to the initialization of the automated assistant routine, and the actions are automated. Added to the actions of the assistant routine. The method further includes the step of comparing the action with a plurality of automated assistant routines stored in relation to the user. The method further comprises selecting a subset of automated assistant routines stored in relation to the user based on the comparison. The method is based on the action being initiated in response to the user interface input provided by the user, as well as the user interface output through the user's client device based on selecting a subset of automated assistant routines. Includes additional steps to render. The user interface output prompts the user to add an action to one or more of a subset of automated assistant routines. The method further comprises the step of receiving a positive user interface input in response to the user interface output, where the positive user interface input indicates a given routine of a subset of automated assistant routines. The method is to add multiple corresponding actions for a given routine that should be performed automatically in response to the initialization of the given routine in response to receiving positive user interface input. It also includes a step to automatically add actions.
本明細書で開示した技術のこれらおよび他の実装形態は、以下の特徴のうちの1つまたは複数を含むことができる。 These and other implementations of the techniques disclosed herein may include one or more of the following features:
いくつかの実装形態では、ユーザインターフェース入力の1つまたは複数のインスタンスは、テキストに変換された場合に第1の長さの第1のテキストである1つまたは複数の発話を含む。それらの実装形態では、所与のルーチンの初期化は、テキストに変換された場合に第2の長さの第2のテキストである所与の発話に応答して発生し、第2の長さは、第1の長さよりも短い。 In some implementations, one or more instances of user interface input include one or more utterances that are the first text of first length when converted to text. In their implementation, the initialization of a given routine occurs in response to a given utterance, which is the second text of the second length when converted to text, and of the second length. Is shorter than the first length.
いくつかの実装形態では、ユーザのクライアントデバイスを介してユーザインターフェース出力をレンダリングさせるステップは、所与のルーチンを実行するステップにさらに基づき、所与のルーチンを実行するステップの終了時に発生する。 In some implementations, the step of rendering the user interface output through the user's client device is based on the step of executing a given routine and occurs at the end of the step of executing a given routine.
いくつかの実装形態では、アクションを開始したユーザインターフェース入力の1つまたは複数のインスタンスは、発話を含む。それらの実装形態のいくつかの変形例では、方法は、発話の1つまたは複数の音声特性に基づいてユーザのプロファイルを識別するステップをさらに含む。それらの変形例では、ユーザに関連して記憶された複数の自動化されたアシスタントルーチンを識別するステップは、複数の自動化されたアシスタントルーチンがユーザのプロファイルに関連して記憶されていることに基づいて複数の自動化されたアシスタントルーチンを識別するステップを含む。さらに、それらの変形例では、所与のルーチンを実行するステップは、ユーザからの追加の発話に応答して発生することができ、ユーザのクライアントデバイスを介してユーザインターフェース出力をレンダリングさせるステップは、追加の発話がユーザのプロファイルに対応する1つまたは複数の音声特性を有すると決定したことにさらに基づくことができる。 In some implementations, one or more instances of the user interface input that initiated the action contains an utterance. In some variants of those implementations, the method further comprises identifying the user's profile based on one or more speech characteristics of the utterance. In those variants, the step of identifying multiple automated assistant routines stored in relation to the user is based on the multiple automated assistant routines being stored in relation to the user's profile. Includes steps to identify multiple automated assistant routines. Further, in those variants, the step of executing a given routine can occur in response to additional speech from the user, and the step of rendering the user interface output through the user's client device. It can be further based on the determination that the additional utterance has one or more voice characteristics corresponding to the user's profile.
いくつかの実装形態では、ユーザのクライアントデバイスを介してユーザインターフェース出力をレンダリングさせるステップは、ユーザインターフェース入力の1つまたは複数のインスタンスに応答して自動化されたアシスタントによって開始されたアクションの終了時に発生する。 In some implementations, the step of rendering the user interface output through the user's client device occurs at the end of the action initiated by the automated assistant in response to one or more instances of the user interface input. do.
いくつかの実装形態では、アクションは、自動化されたアシスタントによって管理される接続されたデバイスの少なくとも1つの状態を変更するコマンドを提供することを含む。 In some implementations, the action involves providing a command to change the state of at least one connected device managed by an automated assistant.
いくつかの実装形態では、アクションは、自動化されたアシスタントを制御するパーティとは異なるサードパーティによって制御されるエージェントにコマンドを提供することを含む。 In some implementations, the action involves providing a command to an agent controlled by a third party that is different from the party that controls the automated assistant.
いくつかの実装形態では、自動化されたアシスタントルーチンのサブセットを選択するステップは、アクションを、自動化されたアシスタントルーチンの各々の中の複数の対応するアクションの各々と比較するステップと、比較するステップに基づいて、自動化されたアシスタントルーチンの各々について、アクションが、自動化されたアシスタントルーチン内の複数の対応するアクションのいずれかとの1つまたは複数の矛盾を含むかどうかを決定するステップと、サブセットの自動化されたアシスタントルーチンの複数の対応するアクションには、アクションとの1つまたは複数の矛盾がないと決定したことに基づいて、自動化されたアシスタントルーチンのサブセットを選択するステップとを含む。 In some implementations, the step of selecting a subset of automated assistant routines is a step of comparing an action with each of a plurality of corresponding actions within each of the automated assistant routines, and a step of comparing. Based on, for each of the automated assistant routines, the steps to determine if an action contains one or more inconsistencies with any of the corresponding actions in the automated assistant routine, and a subset of automation. The corresponding actions of an assistant routine that have been made include the step of selecting a subset of automated assistant routines based on the determination that there is no conflict with the action.
いくつかの実装形態では、1つまたは複数の矛盾は、時間的矛盾および/またはデバイスの非互換性の矛盾を含む。時間的矛盾は、複数の対応するアクションの各々の時間枠内にアクションを完了することができないことを含むことができる。デバイスの非互換性の矛盾は、アクションが特定の能力を有するデバイスを必要とすることと、複数の対応するアクションの各々が特定の能力を有するいかなるデバイスにも関連付けられていないこととを含むことができる。 In some implementations, one or more inconsistencies include temporal inconsistencies and / or device incompatibility inconsistencies. Temporal contradictions can include the inability to complete an action within each time frame of a plurality of corresponding actions. Inconsistencies in device incompatibility include that an action requires a device with a particular capability and that each of the multiple corresponding actions is not associated with any device with a particular capability. Can be done.
いくつかの実装形態では、アクションを自動的に追加するステップは、所与のルーチン内のアクションを実行するための位置を決定するステップを含み、位置は、所与のルーチンの複数の対応するアクションに対するものである。それらの実装形態のいくつかの変形例では、アクションを実行するための位置は、複数の対応するアクションの前、複数の対応するアクションの後、または複数の対応するアクションのうちの2つの間である。それらの変形例のうちのいくつかでは、位置は、複数の対応するアクションの後であり、時間的遅延を含む。時間的遅延は、ユーザによる所与のルーチンの1つまたは複数の過去の開始に続く、ユーザによるアクションの過去の開始における1つまたは複数の過去の時間的遅延に基づくことができる。 In some implementations, the step of automatically adding an action includes a step of determining a position to perform an action within a given routine, where the position is multiple corresponding actions of a given routine. For. In some variants of those implementations, the position for performing an action is before the corresponding action, after the corresponding action, or between two of the corresponding actions. be. In some of those variants, the position is after multiple corresponding actions and includes a time delay. The time delay can be based on one or more past time delays in the past start of an action by the user following one or more past starts of a given routine by the user.
いくつかの実装形態では、アクションを開始したユーザインターフェース入力の1つまたは複数のインスタンスは、ユーザインターフェース出力がそれを介してレンダリングされるクライアントデバイスにリンクされているが、それとは別の追加のクライアントデバイスを介して受信される。 In some implementations, one or more instances of the user interface input that initiated the action are linked to the client device from which the user interface output is rendered, but another additional client. Received through the device.
いくつかの実装形態では、ユーザインターフェース出力は、グラフィカル出力を含み、方法は、クライアントデバイスが表示能力を欠いており、かつ追加のクライアントデバイスが表示能力を含むと決定したことに基づいて、ユーザインターフェース出力を提供するための追加のクライアントデバイスを選択するステップをさらに含む。 In some embodiments, the user interface output includes a graphical output, and the method is based on the determination that the client device lacks display capability and that additional client devices include display capability. It further includes the step of selecting additional client devices to provide the output.
いくつかの実装形態では、アクションを開始したユーザインターフェース入力の1つまたは複数のインスタンスは、発話を含み、方法は、発話の1つまたは複数の音声特性に基づいてユーザのプロファイルを識別するステップをさらに含む。それらの実装形態のうちのいくつかでは、ユーザに関連して記憶された複数の自動化されたアシスタントルーチンを識別するステップは、複数の自動化されたアシスタントルーチンが、発話の音声特性に基づいて識別されたユーザのプロファイルに関連して記憶されていることに基づく。 In some implementations, one or more instances of the user interface input that initiated the action include the utterance, and the method involves identifying the user's profile based on the voice characteristics of the utterance. Including further. In some of those implementations, the step of identifying multiple automated assistant routines stored in relation to the user is such that multiple automated assistant routines are identified based on the speech characteristics of the utterance. Based on being remembered in relation to the user's profile.
いくつかの実装形態では、1つまたは複数のプロセッサによって実行される方法が、提供され、自動化されたアシスタントアクションを決定するステップと、ユーザに関連して記憶された複数の自動化されたアシスタントルーチンを識別するステップとを含む。自動化されたアシスタントルーチンの各々は、自動化されたアシスタントルーチンの初期化に応答して自動化されたアシスタントを介して自動的に実行されるべき複数の対応するアクションを定義する。決定された自動化されたアシスタントアクションは、自動化されたアシスタントルーチンの複数の対応するアクションに追加され得る。方法は、自動化されたアシスタントアクションを、ユーザに関連して記憶された複数の自動化されたアシスタントルーチンと比較するステップをさらに含む。方法は、比較に基づいて、ユーザに関連して記憶された自動化されたアシスタントルーチンのサブセットを選択するステップをさらに含む。方法は、クライアントデバイスの1つまたは複数のセンサからのセンサデータに基づいて、ユーザがクライアントデバイスと対話していることを決定するステップをさらに含む。方法は、ユーザがクライアントデバイスと対話していると決定したことに基づくとともに、自動化されたアシスタントルーチンのサブセットを選択したことに基づいて、クライアントデバイスを介してユーザインターフェース出力をレンダリングさせるステップをさらに含み、ユーザインターフェース出力は、サブセットの自動化されたアシスタントルーチンのうちの1つまたは複数に自動化されたアシスタントアクションを追加するようにユーザに促す。方法は、ユーザインターフェース出力に応答して肯定的なユーザインターフェース入力を受信するステップをさらに含み、肯定的なユーザインターフェース入力は、サブセットの自動化されたアシスタントルーチンのうちの所与のルーチンを示す。方法は、肯定的なユーザインターフェース入力を受信したことに応答して、所与のルーチンの初期化に応答して自動的に実行されるべき所与のルーチンの複数の対応するアクションの追加の1つとして、自動化されたアシスタントアクションを追加するステップをさらに含む。 In some implementations, a method performed by one or more processors is provided with steps to determine automated assistant actions and multiple automated assistant routines stored in relation to the user. Includes a step to identify. Each of the automated assistant routines defines multiple corresponding actions that should be performed automatically through the automated assistant in response to the initialization of the automated assistant routine. The determined automated assistant action can be added to multiple corresponding actions in the automated assistant routine. The method further includes the step of comparing the automated assistant action with a plurality of automated assistant routines stored in relation to the user. The method further comprises selecting a subset of automated assistant routines stored in relation to the user based on the comparison. The method further comprises determining that the user is interacting with the client device based on sensor data from one or more sensors on the client device. The method is based on determining that the user is interacting with the client device, and further includes the step of rendering the user interface output through the client device based on selecting a subset of automated assistant routines. The user interface output prompts the user to add an automated assistant action to one or more of a subset of automated assistant routines. The method further comprises the step of receiving a positive user interface input in response to the user interface output, where the positive user interface input indicates a given routine of a subset of automated assistant routines. The method is to add multiple corresponding actions for a given routine that should be performed automatically in response to the initialization of the given routine in response to receiving positive user interface input. It also includes the step of adding automated assistant actions.
いくつかの実装形態では、追加するステップは、肯定的なユーザインターフェース入力を受信したことに応答して、いかなるさらなるユーザインターフェース入力も要求することなく実行される。 In some implementations, the additional step is performed in response to receiving a positive user interface input without requiring any further user interface input.
いくつかの実装形態では、センサデータは、クライアントデバイスの1つまたは複数のマイクロフォンに基づく音声データを含み、ユーザがクライアントデバイスと対話していることを決定するステップは、音声データに基づいて1つまたは複数の音声特性を決定するステップと、ユーザのプロファイルに一致する音声特性に基づいてユーザを識別するステップとを含む。 In some embodiments, the sensor data includes voice data based on one or more microphones on the client device, and one step based on the voice data is to determine that the user is interacting with the client device. Alternatively, it includes a step of determining a plurality of voice characteristics and a step of identifying the user based on voice characteristics that match the user's profile.
いくつかの実装形態では、自動化されたアシスタントアクションは、特定の接続されたデバイスを制御することを含む。それらの実装形態のいくつかの変形例では、自動化されたアシスタントアクションを、ユーザに関連して記憶された複数の自動化されたアシスタントルーチンと比較するステップは、ユーザの接続されたデバイスのデバイストポロジに基づいて、所与のルーチンの複数の対応するアクションのうちの少なくとも1つによって制御される特定の接続されたデバイスと追加の接続されたデバイスが両方ともデバイストポロジ内の同じ物理的な場所に割り当てられていることを決定するステップを含む。これらの変形例のうちのいくつかでは、比較に基づいて、サブセット内に含めるための所与のルーチンを選択するステップは、特定の接続されたデバイスと追加の接続されたデバイスが両方とも同じ物理的な場所に割り当てられていると決定したことに基づいて、サブセット内に含めるための所与のルーチンを選択するステップを含む。同じ物理的な場所は、例えば、ユーザの家の中の部屋の、ユーザにより割り当てられた意味論的識別子であり得る。 In some implementations, automated assistant actions include controlling a particular connected device. In some variants of those implementations, the step of comparing an automated assistant action with multiple automated assistant routines stored in relation to the user is in the device topology of the user's connected device. Based on, both a particular connected device and additional connected devices controlled by at least one of multiple corresponding actions in a given routine are assigned to the same physical location in the device topology. Includes steps to determine what is being done. In some of these variants, the step of selecting a given routine to include in a subset based on comparison is the same physics for both a particular connected device and an additional connected device. Includes the step of selecting a given routine to include within a subset based on the determination that it is assigned to a suitable location. The same physical location can be, for example, a user-assigned semantic identifier for a room in the user's home.
いくつかの実装形態では、自動化されたアシスタントアクションは、特定の接続されたデバイスを制御することを含み、自動化されたアシスタントアクションを決定するステップは、特定の接続されたデバイスの報告された状態に基づいて、特定の接続されたデバイスが自動化されていないアシスタントの対話に応答して特定の方法で制御されたことを決定するステップと、特定の接続されたデバイスを特定の方法で制御させるための自動化されたアシスタントアクションを決定するステップとを含む。 In some implementations, the automated assistant action involves controlling a particular connected device, and the step of determining the automated assistant action is in the reported state of the particular connected device. Based on the steps to determine that a particular connected device was controlled in a particular way in response to a non-automated assistant dialogue, and to get a particular connected device to be controlled in a particular way. Includes steps to determine automated assistant actions.
いくつかの実装形態では、自動化されたアシスタントアクションを、ユーザに関連して記憶された複数の自動化されたアシスタントルーチンと比較するステップは、ユーザによる自動化されたアシスタントアクションまたは関連するアクションの1つまたは複数の過去の実行に基づいて、自動化されたアシスタントアクションの少なくとも1つのアクションの時間的特性を決定するステップと、自動化されたアシスタントルーチンの1つまたは複数の過去の実行に基づいて、自動化されたアシスタントルーチンの少なくとも1つのルーチンの時間的特性を決定するステップと、少なくとも1つのアクションの時間的特性を少なくとも1つのルーチンの時間的特性と比較するステップとを含む。 In some implementations, the step of comparing an automated assistant action to multiple automated assistant routines stored in relation to the user is one of the user's automated assistant actions or related actions. Automated based on the steps of determining the temporal characteristics of at least one of the automated assistant actions based on multiple past executions, and one or more past executions of the automated assistant routine. It includes determining the temporal characteristics of at least one of the assistant routines and comparing the temporal characteristics of at least one action with the temporal characteristics of at least one routine.
いくつかの実装形態では、自動化されたアシスタントアクションは、特定のサードパーティによって制御されるサードパーティエージェントとの対話を含み、自動化されたアシスタントアクションを決定するステップは、ユーザによる別個のサードパーティとの別個の対話の過去の実行を決定するステップを含む。 In some implementations, an automated assistant action involves interacting with a third-party agent controlled by a particular third party, and the step of determining an automated assistant action is with a separate third party by the user. Includes steps to determine past executions of separate dialogues.
いくつかの実装形態では、自動化されたアシスタントアクションを決定するステップは、別個の対話と自動化されたアシスタントアクションとの間の関係を決定することに基づく。 In some implementations, the step of determining an automated assistant action is based on determining the relationship between a separate dialogue and the automated assistant action.
加えて、いくつかの実装形態は、1つまたは複数のコンピューティングデバイスの1つまたは複数のプロセッサを含み、1つまたは複数のプロセッサは、関連するメモリ内に記憶された命令を実行するように動作可能であり、命令は、前述の方法のいずれかの実行を引き起こすように構成される。いくつかの実装形態は、前述の方法のいずれかを実行するために1つまたは複数のプロセッサによって実行可能なコンピュータ命令を記憶している1つまたは複数の非一時的なコンピュータ可読記憶媒体も含む。 In addition, some implementations include one or more processors of one or more computing devices so that one or more processors execute instructions stored in the associated memory. It is operational and the instructions are configured to trigger the execution of any of the methods described above. Some implementations also include one or more non-temporary computer-readable storage media that store computer instructions that can be executed by one or more processors to perform any of the methods described above. ..
本明細書で開示された実装形態は、自動化されたアシスタントアクションがユーザのための自動化されたアシスタントルーチンに組み込まれることを推奨するかどうかを決定するための方法、装置、およびコンピュータ可読媒体(一時的および非一時的)に向けられている。それらの実装形態のうちのいくつかでは、アクションをルーチンに組み込むことを推奨することが決定された場合、ユーザインターフェース出力が、ユーザに提示するためにレンダリングされる。ユーザインターフェース出力は、ユーザがアクションをルーチンに追加することを望むかどうかに関してユーザに促すことができる。さらに、それらの実装形態のいくつかの変形例では、ユーザインターフェース出力に応答して受信されている肯定的なユーザインターフェース入力に応答して、アクションは、ルーチンに追加される。例えば、受信されている肯定的なユーザインターフェース入力に応答して、アクションは、ルーチンに自動的に追加され得る。 The implementations disclosed herein are methods, devices, and computer-readable media (temporary) for determining whether it is recommended that automated assistant actions be incorporated into automated assistant routines for users. Targeted and non-temporary). In some of those implementations, the user interface output is rendered for presentation to the user if it is decided to recommend incorporating the action into the routine. The user interface output can prompt the user as to whether he or she wants to add the action to the routine. Moreover, in some variants of those implementations, the action is added to the routine in response to the positive user interface input received in response to the user interface output. For example, actions may be automatically added to the routine in response to positive user interface input being received.
例示的なルーチンは、朝のルーチンであり得、朝のルーチンでは、自動化されたアシスタントが、ユーザにその日の準備をさせるために朝に複数の異なるアクションを順次実行する。例えば、朝のルーチンは、自動化されたアシスタントが、特定の日(例えば、今日)のユーザのスケジュールを、クライアントデバイスを介して聴覚的にレンダリングさせ、デバイス(例えば、スマート照明)をオンにさせ、次いで、ユーザが準備をしている間にクライアントデバイスを介してポッドキャストを聴覚的にレンダリングさせることを含むことができる。朝のルーチンの完了後、ユーザは、朝のルーチン内に含まれ得るアクションの実行を引き起こす場合がある。例えば、ユーザは、朝のルーチンが完了した後、第2のクライアントデバイスのアシスタントインターフェースに発話を提供してもよく、発話は、自動化されたアシスタントに、自動化されたアシスタントに関連付けられた器具(例えば、スマートコーヒーメーカー)をオンにさせる。朝のルーチンの実行の時間的近接性と、ユーザが自動化されたアシスタントに器具をオンにさせる発話を提供したこととに少なくとも部分的に基づいて、「器具をオンにする」アクションは、朝のルーチンに含めることを推奨され得る。ユーザが、推奨に同意した場合、「器具をオンにする」アクションは、ルーチンに自動的に追加され得る。その後、ユーザが器具をオンにするためにアシスタントに個別のコマンドを与えなければならない代わりに、自動化されたアシスタントは、朝のルーチンの開始に応答して器具をオンにさせることができる。 An exemplary routine can be a morning routine, in which an automated assistant sequentially performs several different actions in the morning to prepare the user for the day. For example, in a morning routine, an automated assistant renders a user's schedule for a particular day (eg today) audibly through a client device and turns on the device (eg smart lighting). It can then include audibly rendering the podcast through the client device while the user is preparing. After completing the morning routine, the user may trigger the execution of actions that may be contained within the morning routine. For example, the user may provide an utterance to the assistant interface of the second client device after the morning routine is completed, and the utterance is to the automated assistant and the instrument associated with the automated assistant (eg,). , Smart coffee maker) turn on. The "turn on the device" action is based, at least in part, on the temporal proximity of the morning routine execution and the user's provision of an automated assistant to turn on the device. It may be recommended to include it in the routine. If the user agrees to the recommendation, the "turn on device" action may be automatically added to the routine. Instead of the user then having to give the assistant a separate command to turn on the device, the automated assistant can turn on the device in response to the start of the morning routine.
ここで図に向かうと、図1は、様々な実装形態が実行され得る例示的な環境100を示す。例示的な環境100は、1つまたは複数のクライアントデバイス102を含む。各クライアントデバイスは、自動化されたアシスタントクライアント112のそれぞれのインスタンスを実行してもよい。自然言語プロセッサ122および/またはルーチンモジュール124などの1つまたは複数のクラウドベースの自動化されたアシスタント構成要素116は、全体として114として示されている1つまたは複数のローカルエリアネットワークおよび/またはワイドエリアネットワーク(例えば、インターネット)を介してクライアントデバイス102に通信可能に結合された1つまたは複数のコンピューティングシステム(まとめて「クラウド」コンピューティングシステムと呼ばれる)上に実装され得る。
Looking back at the figure, FIG. 1 shows an
様々な実装形態では、自動化されたアシスタントクライアント108のインスタンスは、1つまたは複数のクラウドベースの自動化されたアシスタント構成要素116とのその対話として、ユーザの観点から、ユーザがそれとの対話に従事し得る自動化されたアシスタント112の論理インスタンスのように見えるものを形成してもよい。自動化されたアシスタント112の1つのそのような例が、破線によって図1中に示されている。したがって、クライアントデバイス102上で実行されている自動化されたアシスタントクライアント108と係わっている各ユーザは、事実上、自動化されたアシスタント112のそれら自体の論理インスタンスと係わってもよいことが、理解されるべきである。簡潔さおよび単純さのために、特定のユーザに「サービスする」ものとして本明細書で使用される「自動化されたアシスタント」という用語は、しばしば、ユーザによって操作される自動化されたアシスタントクライアント108と、1つまたは複数のクラウドベースの自動化されたアシスタント構成要素116(複数の自動化されたアシスタントクライアント108間で共有され得る)との組合せを指す場合がある。いくつかの実装形態では、自動化されたアシスタント112は、ユーザが、自動化されたアシスタント112のその特定のインスタンスによって実際に「サービス」されているかどうかにかかわらず、任意のユーザからの要求に応答してもよいことも理解されるべきである。
In various implementations, an instance of the
クライアントデバイス102は、例えば、デスクトップコンピューティングデバイス、ラップトップコンピューティングデバイス、タブレットコンピューティングデバイス、タッチ感応コンピューティングデバイス(例えば、ユーザからのタッチを介して入力を受信することができるコンピューティングデバイス)、携帯電話コンピューティングデバイス、ユーザのビークル内のコンピューティングデバイス(例えば、ビークル内通信システム、ビークル内エンターテインメントシステム、ビークル内ナビゲーションシステム)、独立型対話式スピーカ、スマートテレビなどのスマート器具、および/またはコンピューティングデバイスを含むユーザのウェアラブル装置(例えば、コンピューティングデバイスを有するユーザの腕時計、コンピューティングデバイスを有するユーザの眼鏡、仮想または拡張現実コンピューティングデバイス)のうちの1つまたは複数を含んでもよい。追加のおよび/または代替的なクライアントコンピューティングデバイスが、提供されてもよい。
The
様々な実装形態では、クライアントデバイス102は、様々な形態になり得る1つまたは複数のセンサ(図示せず)を含んでもよい。センサは、口頭ベースの入力、テキストベースの入力、グラフィカルベースの入力、物理ベースの入力(例えば、コンピューティングデバイスのタッチ感応プロジェクタおよび/またはタッチ感応スクリーンを含むディスプレイデバイスへのタッチ)、および/または視覚ベースの入力(例えば、ジェスチャ)などの、自動化されたアシスタント112への様々なタイプの入力を感知することができる。いくつかのクライアントデバイス102は、視野内で検出された動きを示す信号をキャプチャして提供するように構成された1つまたは複数のデジタルカメラを備えてもよい。追加的または代替的に、いくつかのクライアントデバイスは、1つまたは複数のマイクロフォンなどの、音響(または圧力)波を検出するセンサを備えてもよい。
In various implementations, the
クライアントデバイス102および/またはクラウドベースの自動化されたアシスタント構成要素116は、1つまたは複数のデバイス104と通信することができる。デバイス104は、スマート器具、スマートサーモスタット、スマートコーヒーメーカー、スマートライト、スマートロックなどのインターネットオブシングスデバイスを含む様々なデバイスのうちのいずれかを含むことができる。デバイス104は、クライアントデバイス102(および/またはクライアントデバイス102の特定のユーザ)とリンクされ、および互いにリンクされている。例えば、デバイス104は、クライアントデバイス102(およびオプションで他のクライアントデバイス)に割り当てられたプロファイルにリンクされ得、および/またはクライアントデバイス102のユーザに割り当てられたプロファイルにリンクされ得る。集合的に、クライアントデバイス102、他のクライアントデバイス、およびデバイス104は、デバイスの調整されたエコシステムを定義することができる。様々な実装形態では、デバイスは、ユーザによって作成および/または自動的に作成され得、様々なアシスタントクライアントデバイス、様々なスマートデバイス、各々のための識別子、および/または各々に関する属性を定義し得るデバイストポロジ表現を介して互いにリンクされる。例えば、デバイスのための識別子は、デバイスが配置されている構造の部屋(および/または他のエリア)(例えば、居間、キッチン)を指定することができ、および/またはデバイスに関するニックネームおよび/または別名(例えば、ソファーランプ、玄関ロック、寝室スピーカ、キッチンアシスタントなど)を指定することができる。このように、デバイスの識別子は、ユーザがそれぞれのデバイスに関連付ける可能性が高いそれぞれのデバイスの名前、別名、および/または場所であり得る。本明細書で説明したように、そのような識別子は、本明細書で開示した様々な実装形態において利用され得る。例えば、そのような識別子は、自動化されたアシスタントアクションが自動化されたアシスタントルーチンに適合するかどうかを決定する際に利用され得る。
デバイス104は、自動化されたアシスタント112によって直接制御され得、および/またはデバイス104は、リモートデバイス(例えば、別のクラウドベースの構成要素)によってホストされる1つまたは複数のサードパーティエージェント106によって制御され得る。さらに、1つまたは複数のサードパーティエージェント106は、デバイス104を制御することおよび/または他のハードウェアデバイスを制御することに加えて機能を実行することもできる。例えば、自動化されたアシスタント112は、サービスを実行させる、取引を開始させるなどのために、サードパーティエージェント106と対話することができる。例えば、「エージェントXから大きいペパロニピザを注文して」というユーザ音声コマンドは、自動化されたアシスタントクライアント108(またはクラウドベースの自動化されたアシスタント構成要素116)に、エージェントコマンドをサードパーティエージェント「エージェントX」に送信させることができる。エージェントコマンドは、例えば、音声コマンドから決定された「注文」インテントを示すインテント値、ならびに「タイプ=ピザ」、「トッピング=ペパロニ」、および「サイズ=大」などのオプションのスロット値を含むことができる。それに応じて、サードパーティエージェントは、大きいペパロニピザの注文を開始させ、自動化されたアシスタント112に、注文が正常に開始されたことを示すコンテンツを提供することができる。コンテンツ(またはその変換)は、次いで、クライアントデバイス102の出力デバイス(例えば、スピーカおよび/またはディスプレイ)を介してユーザにレンダリングされるようにされ得る。本明細書で説明したように、いくつかの実装形態は、「エージェントXから大きいペパロニピザを注文する」アクションおよび/または同様のアクションがユーザの既存のルーチンに追加されることを推奨することができる。ユーザの既存のルーチンに追加された場合、「エージェントXから大きいペパロニピザを注文する」自動化されたアシスタントアクションは、次いで、ユーザが「エージェントXから大きいペパロニピザを注文して」の発話を個別に提供する必要なしに、既存のルーチンの開始に応答して開始され得る。したがって、そのような発話をキャプチャするオーディオデータの送信および/または処理は、不要にされ得、それによって、コンピュータリソースおよび/またはネットワークリソースを節約して使うことができる。
多くの実装形態では、自動化されたアシスタント112は、1つまたは複数のクライアントデバイス102のユーザインターフェース入力および出力デバイスを介して、1人または複数のユーザとの対話セッションに従事してもよい。いくつかの実装形態では、自動化されたアシスタント112は、クライアントデバイス102のうちの1つの1つまたは複数のユーザインターフェース入力デバイスを介してユーザによって提供されたユーザインターフェース入力に応答して、ユーザとの対話セッションに従事してもよい。それらの実装形態のうちのいくつかでは、ユーザインターフェース入力は、自動化されたアシスタント112に対して明示的に直接的である。例えば、ユーザは、自動化されたアシスタント112に積極的に聞き取りを開始させるために、「オーケー、アシスタント」または「ねえ、アシスタント」などの所定の呼び出しフレーズを話してもよい。多くの実装形態では、ユーザは、おはようルーチンの実行を開始するために「オーケーアシスタント、おはよう」など、ルーチンの実行を開始するための所定のショートカットフレーズを話してもよい。
In many implementations, the
いくつかの実装形態では、自動化されたアシスタント112は、そのユーザインターフェース入力が自動化されたアシスタント112に対して明示的に直接的ではない場合でも、ユーザインターフェース入力に応答して対話セッションに従事してもよい。例えば、自動化されたアシスタント112は、ユーザインターフェース入力の内容を調べ、ユーザインターフェース入力内に存在する特定の用語に応答して、および/または他の合図に基づいて、対話セッションに従事してもよい。多くの実装形態では、自動化されたアシスタント112は、ユーザからの発話をテキストに変換するために音声認識を利用し、それに応じて、例えば、視覚的情報を提供することによって、検索結果を提供することによって、一般的な情報を提供することによって、および/または1つまたは複数の応答アクション(例えば、メディアを再生すること、ゲームを起動すること、食べ物を注文することなど)をとることによって、テキストに応答してもよい。いくつかの実装形態では、自動化されたアシスタント112は、発話をテキストに変換することなく、発話に追加的または代替的に応答することができる。例えば、自動化されたアシスタント112は、音声入力を(音声入力内に存在するエンティティを示す)エンティティ表現および/または他の「非テキスト」表現への埋め込みに変換し、そのような非テキスト表現において動作することができる。したがって、音声入力から変換されたテキストに基づいて動作するものとして本明細書で説明した実装形態は、直接音声入力においておよび/または音声入力の他の非テキスト表現において、追加的および/または代替的に動作してもよい。
In some implementations, the
クライアントコンピューティングデバイス102およびクラウドベースの自動化されたアシスタント構成要素116を動作させるコンピューティングデバイスの各々は、データおよびソフトウェアアプリケーションの記憶のための1つまたは複数のメモリと、データにアクセスし、アプリケーションを実行するための1つまたは複数のプロセッサと、ネットワークを介する通信を容易にする他の構成要素とを含んでもよい。1つまたは複数のコンピューティングデバイス102および/または自動化されたアシスタント112によって実行される動作は、複数のコンピュータシステムにわたって分散され得る。自動化されたアシスタント112は、例えば、ネットワークを介して互いに結合された1つまたは複数の場所において実行されている1つまたは複数のコンピュータ上で実行されているコンピュータプログラムとして実装され得る。
Each of the
上記のように、様々な実装形態では、クライアントコンピューティングデバイス102は、自動化されたアシスタントクライアント108を動作させてもよい。様々な実装形態では、各自動化されたアシスタントクライアント108は、対応する音声キャプチャ/テキスト音声化(「TTS」)/音声テキスト化(「STT」)モジュール110を含んでもよい。他の実装形態では、音声キャプチャ/TTS/STTモジュール110の1つまたは複数の態様は、自動化されたアシスタントクライアント108とは別個に実装され得る。
As mentioned above, in various implementations, the
各音声キャプチャ/TTS/STTモジュール110は、1つまたは複数の機能を実行し、例えば、(場合によっては、クライアントデバイス102内のセンサを含んでもよい)マイクロフォンを介して、ユーザの音声をキャプチャし、キャプチャした音声をテキスト(および/または他の表現もしくは埋め込み)に変換し、および/またはテキストを音声に変換するように構成され得る。例えば、いくつかの実装形態では、クライアントデバイス102は、コンピューティングリソース(例えば、プロセッササイクル、メモリ、バッテリなど)に関して比較的制約される場合があるので、各クライアントデバイス102にローカルである音声キャプチャ/TTS/STTモジュール110は、有限数の異なる口頭フレーズ、特に、自動化されたアシスタント112を呼び出すフレーズをテキスト(または、より低次元性の埋め込みなどの他の形式)に変換するように構成され得る。他の音声入力は、クラウドベースのTTSモジュール118および/またはクラウドベースのSTTモジュール120を含み得るクラウドベースの自動化されたアシスタント構成要素116に送信され得る。
Each voice capture / TTS /
クラウドベースのSTTモジュール120は、音声キャプチャ/TTS/STTモジュール110によってキャプチャされたオーディオデータをテキスト(次いで、自然言語プロセッサ122に提供され得る)に変換するために、クラウドの事実上無制限のリソースを活用するように構成され得る。クラウドベースのTTSモジュール118は、テキストデータ(例えば、自動化されたアシスタント112によって定式化された自然言語応答)をコンピュータ生成音声出力に変換するために、クラウドの事実上無制限のリソースを活用するように構成され得る。いくつかの実装形態では、TTSモジュール118は、例えば、1つまたは複数のスピーカを使用して直接出力されるように、コンピュータ生成音声出力をクライアントデバイス102に提供してもよい。他の実装形態では、自動化されたアシスタント112によって生成されたテキストデータ(例えば、自然言語応答)は、音声キャプチャ/TTS/STTモジュール110に提供され得、音声キャプチャ/TTS/STTモジュール110は、次いで、テキストデータを、ローカルに出力されるコンピュータ生成音声に変換してもよい。
The cloud-based
自動化されたアシスタント112(例えば、クラウドベースのアシスタント構成要素116)は、自然言語プロセッサ122と、前述のTTSモジュール118と、前述のSTTモジュール120と、他の構成要素とを含んでもよく、他の構成要素のうちのいくつかについて、以下でより詳細に説明する。いくつかの実装形態では、自動化されたアシスタント112のエンジンおよび/またはモジュールのうちの1つまたは複数は、省略、結合、および/または自動化されたアシスタント112とは別の構成要素内に実装され得る。いくつかの実装形態では、プライバシーを保護するために、自然言語プロセッサ122、音声キャプチャ/TTS/STTモジュール110、ルーチンモジュール124などの、自動化されたアシスタント112の構成要素のうちの1つまたは複数は、クライアントデバイス102(例えば、クラウドを除外する)において少なくとも部分的に実装され得る。
The automated assistant 112 (eg, cloud-based assistant component 116) may include a
いくつかの実装形態では、自動化されたアシスタント112は、自動化されたアシスタント112との人間対コンピュータの対話セッション中にクライアントデバイス102のユーザによって生成された様々な入力に応答して応答コンテンツを生成する。自動化されたアシスタント112は、対話セッションの一部としてユーザに提示するための応答コンテンツを(例えば、ユーザのクライアントデバイスとは別の場合、1つまたは複数のネットワークを介して)提供してもよい。例えば、自動化されたアシスタント112は、クライアントデバイス102を介して提供された自由形式の自然言語入力に応答して応答コンテンツを生成してもよい。本明細書で使用される場合、自由形式の入力は、ユーザによる選択のために提示されたオプションのグループに制約されない、ユーザによって定式化された入力である。
In some implementations, the
自動化されたアシスタント112の自然言語プロセッサ122は、クライアントデバイス102を介してユーザによって生成された自然言語入力を処理し、自動化されたアシスタント112の1つまたは複数の構成要素によって使用するための注釈付き出力を生成してもよい。例えば、自然言語プロセッサ122は、クライアントデバイス102の1つまたは複数のユーザインターフェース入力デバイスを介してユーザによって生成された自然言語の自由形式入力を処理してもよい。生成された注釈付き出力は、自然言語入力の1つまたは複数の注釈と、オプションで自然言語入力の用語のうちの1つまたは複数(例えば、すべて)とを含む。
The
いくつかの実装形態では、自然言語プロセッサ122は、自然言語入力内の様々なタイプの文法情報を識別して注釈を付けるように構成される。例えば、自然言語プロセッサ122は、用語にそれらの文法的役割を注釈付けするように構成された品詞タグ付け器を含んでもよい。また、例えば、いくつかの実装形態では、自然言語プロセッサ122は、自然言語入力内の用語間の構文関係を決定するように構成された係り受けパーサ(図示せず)を追加的および/または代替的に含んでもよい。
In some implementations, the
いくつかの実装形態では、自然言語プロセッサ122は、人(例えば、文学のキャラクタ、有名人、公人などを含む)、組織、場所(実在および架空)などへの参照などの、1つまたは複数のセグメント内のエンティティ参照に注釈を付けるように構成されたエンティティタグ付け器(図示せず)を追加的および/または代替的に含んでもよい。自然言語プロセッサ122のエンティティタグ付け器は、(例えば、人などのエンティティクラスへのすべての参照の識別を可能にする)高レベルの粒度および/または(例えば、特定の人などの特定のエンティティへのすべての参照の識別を可能にする)より低いレベルの粒度においてエンティティへの参照に注釈を付けてもよい。エンティティタグ付け器は、特定のエンティティを解決するために自然言語入力のコンテンツに依存してもよく、および/または特定のエンティティを解決するためにナレッジグラフもしくは他のエンティティデータベースとオプションで通信してもよい。
In some implementations, the
いくつかの実装形態では、自然言語プロセッサ122は、1つまたは複数の文脈上の合図に基づいて同じエンティティへの参照をグループ化または「クラスタ化」するように構成された共参照リゾルバ(図示せず)を追加的および/または代替的に含んでもよい。例えば、共参照リゾルバは、「私は、前回そこで食べたときに、仮想カフェが好きでした」という自然言語入力内の「そこで」という語句を「仮想カフェ」に解決するために利用され得る。
In some implementations, the
多くの実装形態では、自然言語プロセッサ122の1つまたは複数の構成要素は、自然言語プロセッサ122の1つまたは複数の他の構成要素からの注釈に依存してもよい。例えば、いくつかの実装形態では、名前付きエンティティタグ付け器は、特定のエンティティへのすべての言及に注釈を付ける際に、共参照リゾルバおよび/または係り受けパーサからの注釈に依存してもよい。また、例えば、いくつかの実装形態では、共参照リゾルバは、同じエンティティへの参照をクラスタ化する際に、係り受けパーサからの注釈に依存してもよい。多くの実装形態では、特定の自然言語入力を処理する際に、自然言語プロセッサ122の1つまたは複数の構成要素は、1つまたは複数の注釈を決定するために、特定の自然言語入力の外部の関連する以前の入力および/または他の関連するデータを使用してもよい。
In many implementations, one or more components of the
自動化されたアシスタント112のルーチンモジュール124は、ユーザの自動化されたアシスタントルーチンに追加するための候補アクションを決定することができ、候補アクションを追加することを推奨するユーザの利用可能なルーチンのサブセットを決定することができ、サブセットのルーチンにアクションを追加するための推奨を提供することができ、推奨に応答して受信されている、ルーチンのうちの1つを示す肯定的な入力に基づいて、ルーチンのうちの1つにアクションを追加することができる。ルーチンモジュール124は、図示のようにクラウドベースの自動化されたアシスタント構成要素116によって実行され得、および/またはクライアントデバイス102の自動化されたアシスタントクライアント108によって実装され得る。
いくつかの実装形態では、ルーチンモジュール124は、自動化されたアシスタント112の1つまたは複数のインスタンスとの対話を通じてユーザによって開始されているアクションに基づいて、ユーザのルーチンに追加することを潜在的に推奨するための自動化されたアシスタントアクションを決定する。いくつかの実装形態では、ルーチンモジュール124は、自動化されたアシスタント112の1つまたは複数のインスタンスとの対話を通じてユーザによって開始されている関連するが異なるアクションに基づいて、ユーザのルーチンに追加することを潜在的に推奨するための自動化されたアシスタントアクションを追加的または代替的に決定する。いくつかの実装形態では、ルーチンモジュール124は、ユーザがアクションまたは関連するアクションを実行した可能性が高いことを示すユーザに関連付けられたデータに基づいて、ユーザのルーチンに追加することを潜在的に推奨するための自動化されたアシスタントアクションを追加的または代替的に決定する。ユーザに関連付けられたデータは、他の自動化されていないアシスタントアプリケーションとのユーザの対話に基づくデータ、スマートデバイスの直接的なユーザ制御に応答したそれらのスマートデバイスの状態に基づくデータ、ユーザの場所および/または取引を示すデータなどを含むことができる。
In some implementations,
いくつかの実装形態では、ルーチンモジュール124は、ユーザのためのルーチンの記憶されたリストにアクセスし、決定された自動化されたアシスタントアクションを追加することを推奨するルーチンのサブセットを決定することができる。それらの実装形態のうちのいくつかでは、ルーチンモジュール124は、ルーチンの過去の発生の時間的属性を、自動化されたアシスタントアクションの(または自動化されたアシスタントアクションに関連するアクションの)過去の発生の時間的属性と比較することに基づいて、自動化されたアシスタントルーチンのサブセットを選択する。例えば、自動化されたアシスタントアクションが、スマートサーモスタットをユーザが手動で調整したことの過去の発生に基づいて決定された「スマートサーモスタットの設定値を3度低下させる」アクションである場合、それらの過去の発生の時間は、それらの低下を反映するスマートサーモスタットからの状態更新の時間に基づいて決定され得る。さらに、それらの時間の近く(例えば、1時間以内)で頻繁に開始されるユーザのルーチンは、それらの時間の近くでめったにまたは決して開始されないユーザのルーチンよりも、サブセットのために選択される可能性が高くなり得る。
In some implementations,
それらの実装形態のうちのいくつかでは、ルーチンモジュール124は、ルーチンにおいて利用されるデバイスのデバイストポロジ属性を、自動化されたアシスタントアクションにおいて利用されるデバイスのデバイストポロジ属性と比較することに基づいて、自動化されたアシスタントルーチンのサブセットを追加的または代替的に選択する。例えば、自動化されたアシスタントアクションが、「場所=ビークル」という割り当てられたデバイストポロジ属性を有するユーザのビークルの構成要素の制御に関連している場合、「場所=ビークル」という割り当てられたデバイストポロジ属性を有する他のデバイスを制御するアクションを含むルーチンは、「場所=ビークル」というデバイストポロジ属性を有するデバイスを制御するいかなるアクションもないルーチンよりも、サブセットのために選択される可能性が高くなり得る。
In some of those implementations,
それらの実装形態のうちのいくつかでは、ルーチンモジュール124は、自動化されたアシスタントアクションとの矛盾を含む任意のルーチンをサブセットから除外して、自動化されたアシスタントルーチンのサブセットを追加的または代替的に選択する。例えば、「居間のライトを50%に暗くする」自動化されたアシスタントアクションについて、所与のルーチンは、競合する「居間のライトをオフにする」アクションを有することに基づいて除外され得る。また、例えば、ユーザの家へのアイテムのオンデマンド配達をもたらすサービスを実行するためにエージェントとインターフェースする自動化されたアシスタントアクションについて、所与のルーチンは、ユーザの「作業」場所に割り当てられていることに基づいて(例えば、明示的に、または「作業」デバイストポロジ属性を有するリンクされたデバイスにのみ関連付けられていることに基づいて)除外され得る。
In some of those implementations,
いくつかの実装形態では、ルーチンモジュールは、自動化されたアシスタントルーチンに追加するための複数の競合するアクションを考慮し、ルーチンに追加するためにユーザインターフェース出力を介して実際に推奨するために選択され得る、競合するアクション(例えば、その1つ)のサブセットのみを選択する。それらの実装形態のいくつかでは、複数の競合するアクションの各々が、ルーチンと比較され得、選択されたアクションは、ルーチンに最も密接に従う、ルーチンとのいかなる競合もない、および/または他の基準を満たすアクションのうちの1つまたは複数であり得る。 In some implementations, the routine module is selected to take into account multiple conflicting actions to add to the automated assistant routine and to actually recommend it through the user interface output to add to the routine. Select only a subset of the competing actions (eg, one of them) that you get. In some of those implementations, each of the multiple conflicting actions can be compared to a routine, the selected action follows the routine most closely, there is no conflict with the routine, and / or other criteria. Can be one or more of the actions that satisfy.
アクションおよび/またはアクションが追加され得るルーチンを決定するために利用された技法に関係なく、ルーチンモジュール124は、アクションをルーチンに追加するかどうかに関してユーザに促すユーザインターフェース出力を追加させることができる。いくつかの実装形態では、アクションをルーチンに追加することを推奨する際に、ルーチンモジュール124は、アクションを実行するための自動化されたアシスタントとのユーザ対話に応答して(例えば、アクションが、ユーザ対話に応答して完了した後)、対応するユーザインターフェース出力をレンダリングさせる。いくつかの実装形態では、アクションをルーチンに追加することを推奨する際に、ルーチンモジュール124は、ルーチンの開始に応答して(例えば、ルーチンの任意のアクションを実行する前、またはルーチンのすべてのアクションの完了後に)、対応するユーザインターフェース出力をレンダリングさせる。
Regardless of the action and / or the technique used to determine the routine to which the action can be added, the
ルーチンモジュール124によって提供された推奨に応答して、肯定的なユーザインターフェース入力が受信された場合、ルーチンモジュール124は、対応するアクションを対応するルーチンに追加させることができる。例えば、ルーチンモジュール124は、ユーザからのいかなるさらなるユーザインターフェース入力も必要とすることなく、アクションをルーチンに自動的に追加することができる。いくつかの実装形態では、自動化されたアシスタントアクションをルーチンに追加する際に、ルーチンモジュール124は、ルーチンの前から存在するアクションの中に、自動化されたアシスタントアクションの実行の位置を決定することができる。それらの実装形態のいくつかの変形例では、位置は、自動化されたアシスタントアクションによって必要とされるユーザインターフェース出力(もしあれば)の持続時間と、ルーチンの前から存在するアクションによって必要とされるユーザインターフェース出力(もしあれば)の持続時間とに基づいて決定され得る。いくつかの追加的または代替的変形例では、実行の位置は、最後であり得、オプションでは時間的遅延を伴って発生することができる。
If a positive user interface input is received in response to the recommendations provided by
アクションを自動化されたアシスタントルーチンに追加するためにクライアントデバイスと対話するユーザの例を、図2に示す。画像200は、ユーザ202とクライアントデバイス204とを含む部屋のシーンを含む。ユーザ202は、ダイアログボックス206内に示される発話を介してクライアントデバイス204と対話する。ダイアログボックス206の発話は、自動化されたアシスタントが、クライアントデバイス204にリンクされているスマートサーモスタットの設定点の5度の上昇を引き起こすアクションを実行することを要求する。クライアントデバイス204に関連付けられた自動化されたアシスタントは、スマートサーモスタットの設定点を5度だけ上昇させるための適切なコマンドを決定するために、発話を処理することができる。いくつかの実装形態では、クライアントデバイス204に関連付けられた自動化されたアシスタントは、温度を変更するために、スマートサーモスタットと直接インターフェースすることができる。例えば、自動化されたアシスタントは、コマンドをスマートサーモスタットに直接提供することができる。追加的または代替的に、自動化されたアシスタントは、温度を変更するために、スマートサーモスタットに関連付けられたサードパーティエージェントとインターフェースすることができる。例えば、自動化されたアシスタントは、コマンドをサードパーティエージェントに提供することができ、サードパーティエージェントは、温度変更を実現するために、対応するコマンドを生成し、スマートサーモスタットに送信する。
Figure 2 shows an example of a user interacting with a client device to add an action to an automated assistant routine.
いくつかの実装形態では、クライアントデバイス204は、ダイアログボックス208に示すように、温度が上昇したことを確認する可聴ユーザインターフェース入力をレンダリングすることができ、さらに、温度を5度だけ上昇させることをユーザの「おはよう」ルーチンに追加することを推奨することができる。この推奨は、ユーザが推奨されたルーチンにアクションを追加することを望むかどうかを尋ねるプロンプトを含むことができる。いくつかの実装形態では、この推奨は、ユーザが、ユーザの「おはよう」ルーチンを完了した後、朝の温度を一般に上げる場合、行われ得る。いくつかの実装形態では、この推奨は、ユーザが、第1のクライアントデバイスを使用して「おはよう」ルーチンを実行し、ユーザが、第2のクライアントデバイスを使用して温度を変更した場合でも行われ得る。
In some implementations, the
この推奨を行う前に、クライアントデバイス204に関連付けられた自動化されたアシスタントは、「温度上昇」の自動化されたアシスタントアクションが追加することを推奨されるべきルーチンとして、ユーザの複数の他のルーチンから「おはよう」ルーチンを選択することができる。本明細書で詳細に説明した様々な技法など、様々な技法が、ユーザの他のルーチンを除外して「おはよう」ルーチンを選択するために利用され得る。
Prior to making this recommendation, the automated assistant associated with
ユーザは、アクションを推奨ルーチンに追加したいかどうかを決定し、ダイアログボックス210によって示されたさらなる発話を介してプロンプトに応答することができる。ユーザが、ダイアログボックス210の発話によって示されるように、プロンプトに肯定的に応答した場合、自動化されたアシスタントは、アクションをユーザの「おはよう」ルーチンに自動的に追加する。さらに、自動化されたアシスタントは、ダイアログボックス212によって示されるように、クライアントデバイス204を介してさらなる可聴ユーザインターフェース出力を提供させ、さらなる可聴出力は、温度を5度だけ上げることが「おはよう」ルーチンに追加されたことを確認する。しかしながら、いくつかの実装形態では、この確認は、オプションであり得る。追加的または代替的に、クライアントデバイス204は、ユーザがルーチンを次に実行するときに、アクションがルーチンに追加されたことを確認することができる。例えば、アクションをユーザのルーチンに追加する権限をユーザが配偶者に与えた様々な実装形態では、これは、アクションが特定のルーチン内に追加されることをユーザが望むことの追加の確認をユーザに提供することができる。
The user can decide whether he wants to add the action to the recommended routine and respond to the prompt through the additional utterances indicated by
いくつかの実装形態では、ユーザ202は、スマートデバイスを制御するアクションではないアクションの実行を引き起こすために、クライアントデバイスを1つまたは複数のサードパーティエージェントと対話させるために、クライアントデバイス204に入力を提供することができる。例えば、温度が変更されることを要求する代わりに、ユーザは、「ローカルコーヒーショップ」に関連付けられたサードパーティエージェントからオンライン注文を行うためにクライアントデバイス204を使用し、次いで、ユーザが仕事に行く途中に、ユーザが注文したコーヒーを受け取ることができる。ユーザは、そのような注文を行う際にクライアントデバイス204に関連付けられた自動化されたアシスタントと、またはクライアントデバイス204の別個のアプリケーションと対話することができる。多くの実装形態では、クライアントデバイス204に関連付けられた自動化されたアシスタント(図1において上記で説明したそのルーチンモジュール124など)は、コーヒー注文アクションを決定し、アクションをユーザの「おはよう」ルーチンおよび/または他の自動化されたアシスタントルーチンに追加することを推奨するかどうかを決定することができる。例えば、ユーザが、「おはよう」ルーチンの完了直後に毎朝クライアントデバイス204を使用して「ローカルコーヒーショップ」からコーヒー注文を行う場合、自動化されたアシスタントアクションは、「おはよう」ルーチンに対するアクションの時間的近接性に少なくとも部分的に基づいて、アクションを「おはよう」ルーチンに追加することを推奨することを決定することができる。いくつかの実装形態では、ユーザは、クライアントデバイス204が「おはよう」ルーチンのレンダリングを完了した後、例えば、平均25分だけ、クライアントデバイス204を使用して「ローカルコーヒーショップ」からコーヒー注文を行うことを遅らせる可能性がある(すなわち、ユーザは、ユーザが家を出るときに注文を行い、これは、「おはよう」ルーチンの完了後、平均25分で発生する)ので、ユーザは、「ローカルコーヒーショップ」に到着したときに、ユーザは、カップ一杯の熱いコーヒーを待たせている。それらの実装形態のうちのいくつかでは、「ローカルコーヒーショップ」からのコーヒー注文は、「おはよう」ルーチンの実行に応答して、「おはよう」ルーチンの他の前から存在するアクションとともに自動的に実行されるように、「おはよう」ルーチンに依然として追加され得る。しかしながら、自動化されたアシスタントは、「おはよう」ルーチンがサードパーティエージェントを介してユーザのための「ローカルコーヒーショップ」からのコーヒー注文を行う前に、遅延(例えば、前から存在する「おはよう」ルーチンにおける最後のアクションの完了後25分)をオプションで含むことができる。追加的または代替的に、自動化されたアシスタントは、前から存在する「おはよう」ルーチンにおける最後のアクションの完了に続く遅延後に、プロンプト(例えば、「あなたのコーヒーを注文する準備ができました」)を提供させ、プロンプトに応答して肯定的な入力が受信された場合にのみ、注文が開始されるように、それを「おはよう」ルーチンに追加することができる。
In some implementations,
追加的または代替的に、いくつかの実装形態では、ユーザが、クライアントデバイス204を使用して「ローカルコーヒーショップ」からコーヒー注文を一回だけ行った場合、自動化されたアシスタントは、「おはよう」ルーチンにおけるアクションを再調査することができる。例えば、ルーチンが、コーヒーメーカーをオンにすることを含む場合、ユーザが単にその朝コーヒーを切らしていた可能性があり、自動化されたアシスタントは、コーヒー注文を「おはよう」ルーチンに追加することを推奨するべきではない。しかしながら、いくつかの実装形態では、ユーザが、クライアントデバイスを使用して事前にコーヒーを予約していなくても、ユーザが、朝に「ローカルコーヒーショップ」を頻繁に訪れる場合、自動化されたアシスタントは、コーヒー注文を行うアクションを「おはよう」ルーチンに追加することを推奨することを決定することができる。
Additional or alternative, in some implementations, if the user places a coffee order from the "local coffee shop" only once using the
さらに、ユーザが、アクションがそれを介して実行されるサードパーティと以前対話していなかったとしても、自動化されたアシスタントは、自動化されたアシスタントアクションをルーチンに追加することを提案することができる。例えば、ユーザは、先月オープンした、ユーザの家と職場との間のルート上の便利な場所にある新しいコーヒーショップ「新しいコーヒーショップ」に気付かない可能性がある。「新しいコーヒーショップ」においてコーヒーを注文させるアクションは、現在どのようなコーヒー注文アクションもないユーザの「おはよう」ルーチンに追加するために推奨され得る。追加的または代替的に、いくつかの実装形態では、「新しいコーヒーショップ」においてコーヒーを注文させるアクションは、既存のルーチンに追加し、代替のコーヒーショップにおいてコーヒーを注文させるルーチンの既存のアクションを置き換えるために推奨され得る。 In addition, the automated assistant can suggest adding an automated assistant action to the routine, even if the user has not previously interacted with a third party through which the action is performed. For example, a user may not be aware of the new coffee shop "New Coffee Shop," which opened last month and is conveniently located on the route between the user's home and work. The action of ordering coffee in the "new coffee shop" may be recommended to add to the "good morning" routine of users who currently do not have any coffee ordering action. Additional or alternative, in some implementations, the action of ordering coffee in a "new coffee shop" adds to the existing routine and replaces the existing action of the routine of ordering coffee in an alternative coffee shop. Can be recommended for.
いくつかの実装形態では、ユーザは、ルーチンに潜在的に追加するための2つ以上のアクションを提示され得、アクションの各々は、異なるサードパーティエージェントに関連付けられている。例えば、「ローカルコーヒーショップ」からクライアントデバイス204を介して毎日の朝のコーヒー注文を行うユーザは、3つの別個のアクションのうちのいずれか1つを既存の「おはよう」ルーチンに追加するための推奨を提示され得る。3つのアクションの各々は、コーヒー注文を開始させることができるが、第1のアクションは、「ローカルコーヒーショップ」で注文させ、第2のアクションは、「新しいコーヒーショップ」で注文させ、第3のアクションは、「クラッシックコーヒーショップ」で注文させることができる。いくつかの実装形態では、アクションの各々は、対応するコーヒーショップを訪問する時間量がユーザの通勤を増加および/または減少させること、コーヒー注文の対応する価格、対応する報酬プログラム、および/またはユーザがどのコーヒーショップをユーザの「おはよう」ルーチンに追加するかに関して十分な情報に基づいて決定を行うのに役立つ他の情報などの、対応する追加情報とともに提示され得る。いくつかの実装形態では、推奨されるアクションのうちの1つまたは複数は、対応するパーティがその包含について金銭的報酬を提供することに基づいて推奨され得る。いくつかの実装形態では、包含のために必要な金銭的報酬の量は、アクションが追加のために提案されているルーチンにどれくらい厳密に一致するか、ルーチンがユーザによってどれくらい頻繁に実行されるか、および/または他の基準に関連することができる。
In some implementations, the user may be presented with two or more actions to potentially add to the routine, each of which is associated with a different third-party agent. For example, a user who places a daily morning coffee order from a "local coffee shop" via
ユーザ202の発話およびクライアントデバイス204の可聴出力が、図2に示されているが、追加的または代替的なユーザ入力が、ユーザ202によって、および/またはクライアントデバイス204の追加的もしくは代替的なモダリティを介してレンダリングされたコンテンツによって提供され得る。例えば、ユーザ202は、タイプされた入力、タッチ入力、ジェスチャ入力などを、追加的または代替的に提供することができる。また、例えば、出力は、クライアントデバイス204によって追加的または代替的にグラフィカルにレンダリングされ得る。1つの特定の例として、クライアントデバイス204は、アクションをルーチンに自動的に追加させるユーザ202のタッチ対話によって選択され得る選択可能なインターフェース要素とともに、アクションをルーチンに追加するためのプロンプトをグラフィカルにレンダリングすることができる。
The utterance of
アクションを自動化されたアシスタントルーチンに追加するためにクライアントデバイスと対話するユーザの追加の例を、図3に示す。画像300は、ユーザ302とクライアントデバイス304とを含む部屋のシーンを含む。ユーザ302は、事前定義されたショートカットフレーズを含む発話を提供することによって、ルーチンを開始するためにクライアントデバイス304と対話することができる。例えば、ダイアログボックス306において、ユーザ302は、クライアントデバイス304によって検出され、「おはよう」というフレーズを含む発話を提供することによって、「おはよう」ルーチンを開始する。クライアントデバイス304に関連付けられた自動化されたアシスタントは、発話をキャプチャしたオーディオデータを処理し、発話が「おはよう」ルーチンのためのショートカットフレーズを含むと決定し、それに応じて、「おはよう」ルーチン内の各アクションの実行を引き起こすことができる。いくつかの実装形態では、自動化されたアシスタントは、クライアントデバイス304を介して、ルーチンの完了時に、ユーザがちょうど完了したルーチンにアクションを追加したいかどうかをユーザ302に尋ねることができる。例えば、ダイアログボックス308は、クライアントデバイス304がユーザの「おはよう」ルーチンを完了したことを示し、次いで、ユーザがユーザの「おはよう」ルーチンに照明制御を追加したいかどうかを尋ねる。追加的または代替的に、いくつかの実装形態では、クライアントデバイス304は、ルーチンを実行する前に、ユーザがユーザの「おはよう」ルーチンに照明制御を追加したいかどうかを尋ね、ルーチンを実行することの一部として新しいアクションを含めることができる。
Figure 3 shows an example of adding a user to interact with a client device to add an action to an automated assistant routine.
多くの実装形態では、クライアントデバイス304に関連付けられた自動化されたアシスタントは、ユーザの過去のアクションに基づいて、ちょうど完了したルーチン(この場合、「おはよう」ルーチン)に新しいアクションを追加するためにこの推奨を決定することができる。例えば、推奨は、ユーザが、「おはよう」ルーチンの完了時にクライアントデバイス304を使用してユーザのスマートライトを常にオンにすることに基づいて決定され得る。追加的または代替的に、いくつかの実装形態では、ユーザは、ユーザの家にスマートライトを持っているが、自動化されたアシスタントを利用してスマートライトを制御する能力に気付いておらず、したがって、スマートライトを制御するために自動化されたアシスタントを以前に利用していない場合がある。そのような例では、自動化されたアシスタントは、そうでなければユーザが気付いていない場合がある機能をユーザルーチンに追加しようとして、ユーザが照明制御アクションを実行していないと決定したことに基づいて推奨を行うことができる。追加的または代替的に、いくつかの実装形態では、自動化されたアシスタントは、スマートライトの制御が、他のユーザが関連するルーチンにおいて頻繁に行うアクションであると決定したことに基づいて推奨を行うことができる。例えば、アシスタントは、(ユーザのデバイストポロジを介して決定される)照明制御に必要なデバイスを有するユーザの90%超がユーザの「おはよう」ルーチンにおいて照明制御アクションも有する場合、照明制御を「おはよう」ルーチンに追加するように推奨することができる。
In many implementations, the automated assistant associated with the
ユーザは、提案されたアクションをルーチンに追加するかどうかを決定することができる。例えば、ダイアログボックス310は、ユーザが、提案されたアクション(すなわち、照明制御)をユーザの「おはよう」ルーチンに追加することを肯定的に決定したことを示す。しかしながら、ユーザは、推奨されたアクションを提案されたルーチンに追加する必要はない。いくつかの実装形態では、自動化されたアシスタントに関連付けられたクライアントデバイス304は、推奨されたアクションがルーチンに追加されたことを確認することができる。例えば、ダイアログボックス312は、照明制御がユーザの「おはよう」ルーチンに追加されたことを示す。しかしながら、様々な実装形態では、クライアントデバイス304は、ユーザがそのルーチンを次に実行するときに、アクションが特定のルーチンに追加されたことをユーザに確認することができる。いくつかの実装形態では、これは、ユーザが、ルーチンにおいて新しいアクションを依然として望んでおり、次回のルーチンで気が変わっていないことを確認するために、追加のバックアップを提供することができる。さらに、いくつかの実装形態では、ユーザは、ユーザのルーチンを変更する他者の許可を与えることができる。いくつかのそのような実装形態では、ユーザがルーチンを実行する前に新しいアクションが追加されたことを確認することは、ユーザが、ユーザの配偶者などの異なるユーザがユーザのルーチンに追加したアクションを確認することを可能にすることができる。
The user can decide whether to add the proposed action to the routine. For example,
様々な実装形態による、自動化されたアシスタントルーチンにアクションを追加するかどうかを決定するためのプロセスを、図4に示す。プロセス400は、1つもしくは複数のクライアントデバイス、および/または自動化されたアシスタントと対話することができる任意の他の装置によって実行され得る。プロセスは、自動化されたアシスタントアクションを決定すること(402)を含む。いくつかの実装形態では、アクションは、自動化されたアシスタントとのユーザによる対話に応答して1つまたは複数回実行されたことに基づいて決定され得る。いくつかの実装形態では、アクションは、物理的デバイスを制御すること(例えば、スマートサーモスタットを制御すること、スマートコーヒーメーカーをオンにすること、スマートスピーカを制御することなど)、および/またはリモートエージェント(例えば、ユーザにデイリーエージェントを提供することができるカレンダーエージェント、ユーザにその日の天気を提供することができる天気エージェントなど)と対話することを含むことができる。いくつかの実装形態では、アクションは、ユーザによって過去に何度も実行されたことに基づいて決定され得る。例えば、特定のスマートライトの制御のためのアクションは、ユーザが就寝前に毎晩特定のスマートライトを制御することに基づいて、自動化されたアシスタントとの対話を介して、手動対話を介して、および/またはスマートライトの制御に特化したアプリとの対話を介して決定され得る。アクションは、少なくともしきい値の回数実行されたことに基づいて決定され得る。いくつかの実装形態では、ユーザが、アクションの実行を引き起こしたことが一度もない場合であっても、自動化されたアシスタントアクションは、決定され得る。例えば、スマートロックを制御することに関連するアクションは、スマートロックが、ユーザによってちょうどインストールされた、および/または自動化されたアシスタントによって制御可能なリンクされたデバイスのトポロジに追加されたとの決定に応答して決定され得る。例えば、ユーザは、新しく、いかなるルーチンにも関連付けられていないスマートロックをちょうどインストールした場合がある。
Figure 4 shows the process for deciding whether to add an action to an automated assistant routine in various implementations.
自動化されたアシスタントは、ユーザのためのルーチンを識別することができる(404)。ユーザは、多くのルーチンを有することができ、そのうちのいくつかは、重複する可能性がある。例えば、ユーザは、平日のための第1の「おはよう」ルーチンと、週末のための第2の「おはよう」ルーチンとを有することができる。追加的または代替的に、ユーザは、ユーザが仕事から帰宅したときから選択するいくつかのルーチンを有することができる。例えば、ユーザは、「のんびりする(Veg Out)」ルーチンと「本を読む」ルーチンとを有することができる。いくつかの実装形態では、ユーザのプロファィルが、識別され得、ユーザのプロファィルに割り当てられたルーチンのセットは、そのユーザに関連付けられたルーチンの識別されたセットであり得る。それらの実装形態のうちのいくつかでは、ユーザのプロファイルに関するルーチンのセットは、(402)におけるアクションがユーザのプロファイルに関して実行されたと決定したことに基づいて、(402)において決定されたアクションに対して識別される。図1に関して上記で説明した様々なセンサのいずれかが、自動化されたアシスタントへの入力に関連付けられたユーザプロファイル(例えば、オーディオデータに基づく音声マッチング)と、そのユーザプロファイルに関連付けられた自動化されたアシスタントルーチンとを識別するために使用され得る。様々な実装形態では、ルーチンのセットは、同じ世帯のメンバ間で共有され得る。例えば、ユーザおよびユーザの配偶者は、一緒に料理を楽しむ場合があり、両方のユーザが1つまたは複数の自動化されたアシスタントクライアントおよび1つまたは複数のクライアントデバイスと対話する共有された「グリルナイト(Grilling Night)」ルーチンを有する場合がある。例えば、グリルナイトルーチンは、キッチンのライトをオンにし、グリルが加熱を開始することができるように、屋外のグリルをオンにし、同じ音楽を再生するために、キッチンと屋外のグリルのエリアの両方においてスピーカをレンダリングするアクションを含むことができる。両方のユーザは、様々な時点でキッチンおよびグリルにおけるデバイスと対話することができる。いくつかの実装形態では、共有ルーチンであるので、「グリルナイト」ルーチンは、両方のユーザのユーザプロファイルに含まれ得、新しいアクションを新しいルーチンに潜在的に追加する場合、両方のユーザについて考慮されるべきである。両方のユーザは、新しいアクションを共有ルーチンに追加するプロセスを手動で行う必要はないので、一方のユーザがアクションを共有ルーチンに追加することを可能にすることは、計算リソースをさらに共有することができる。 The automated assistant can identify the routine for the user (404). The user can have many routines, some of which can be duplicated. For example, a user may have a first "good morning" routine for weekdays and a second "good morning" routine for weekends. Additional or alternative, the user may have several routines to choose from when the user returns home from work. For example, a user can have a "Veg Out" routine and a "read a book" routine. In some implementations, a user's profile can be identified, and the set of routines assigned to a user's profile can be an identified set of routines associated with that user. In some of those implementations, the set of routines for a user's profile is based on the determination that the action in (402) was performed on the user's profile, for the action determined in (402). Is identified. One of the various sensors described above with respect to FIG. 1 has a user profile associated with an automated assistant input (eg, audio data-based voice matching) and an automated user profile associated with that user profile. Can be used to identify with assistant routines. In various implementations, a set of routines can be shared among members of the same household. For example, a user and a user's spouse may enjoy cooking together, and both users interact with one or more automated assistant clients and one or more client devices in a shared "grill night." May have a "Grilling Night" routine. For example, a grill night routine turns on the kitchen lights, turns on the outdoor grill so that the grill can start heating, and both the kitchen and outdoor grill areas to play the same music. Can include actions that render the speaker in. Both users can interact with the device in the kitchen and grill at various times. Being a shared routine in some implementations, the "Grill Night" routine can be included in the user profile of both users and is considered for both users when potentially adding new actions to the new routine. Should be. Allowing one user to add an action to a shared routine can further share computational resources, as both users do not have to manually add a new action to the shared routine. can.
自動化されたアシスタントルーチンのグループが、(402)において識別されたアクションを潜在的に追加する(404)において識別されたアクションのグループから選択され得る(406)。例えば、ユーザが、仕事から帰宅したときにアクションを実行している場合、「のんびりする」ルーチンおよび「本を読む」ルーチンは、アクションに追加する潜在的な自動化されたアシスタントルーチンである。しかしながら、自動化されたアシスタントは、すべての利用可能な自動化されたアシスタントルーチンのサブセットである自動化されたアシスタントルーチンのグループを選択するために、アクションをそれらのルーチンおよび/または他のルーチンと比較することができる。例えば、「のんびりする」ルーチンは、居間のテレビをオンにすることと、居間のライトをオフにすることとを含むことができる。対照的に、「本を読む」ルーチンは、書斎内の読書のためにカスタマイズされた照明を設定することと、書斎内でソフトジャズ音楽を再生することとを含むことができる。ユーザアクションが、その夜に放映している現在のテレビ番組に関連する情報を要求することである場合、多くの実装形態では、自動化されたアシスタントは、アクションを潜在的に追加するグループ内に含めるためのテレビを含むルーチンを選択する。さらに、例えば、ユーザのためのリンクされたデバイスのデバイストポロジを使用して、自動化されたアシスタントは、「本を読む」ルーチンに関するアクションのすべてに関連付けられている部屋である書斎に、表示することができるデバイスがないと決定することができる。結果として、アクションは、表示することができるデバイスに情報をプッシュすることを含み、「本を読む」ルーチンは、表示可能なデバイスがない部屋にのみ現在関連付けられているので、自動化されたアシスタントは、アクションを潜在的に追加するグループから「本を読む」ルーチンを除外することができる。いくつかの実装形態では、自動化されたアシスタントは、アクションを分析し、ユーザに関する、および/またはアクションを潜在的に追加するルーチンのグループを生成するためにルーチンが一般的に実行される場所に関するすべてのルーチン内のすべてのアクションと比較することができる。 A group of automated assistant routines may be selected from the group of actions identified in (404) to potentially add the actions identified in (402) (406). For example, if a user is performing an action when they return home from work, the "relaxing" and "reading" routines are potential automated assistant routines that add to the action. However, automated assistants compare actions with those routines and / or other routines in order to select a group of automated assistant routines that are a subset of all available automated assistant routines. Can be done. For example, a "relaxing" routine can include turning on the TV in the living room and turning off the lights in the living room. In contrast, a "reading a book" routine can include setting customized lighting for reading in the study and playing soft jazz music in the study. If the user action is to request information related to the current TV show that is airing that night, in many implementations the automated assistant will be included in the group that potentially adds the action. Select a routine that includes a television for. Further, for example, using the device topology of the linked device for the user, the automated assistant can be displayed in the study, which is the room associated with all the actions related to the "read book" routine. Can be determined that there is no device that can. As a result, the action involves pushing information to a device that can be viewed, and the "read book" routine is currently associated only with rooms that do not have a device that can be viewed, so automated assistants , You can exclude the "read book" routine from the group that potentially adds actions. In some implementations, the automated assistant analyzes actions and / or everything about where routines are typically performed to generate groups of routines that potentially add actions. Can be compared to all actions in the routine of.
いくつかの実装形態では、潜在的なアクションは、アクションを潜在的に追加するためにルーチン(またはルーチンのグループ)を選択する前に、多くのルーチンと比較され得る。例えば、ユーザは、「パーティタイム」、「おはよう」、「おやすみ」、および「車で家に帰る(Drive Home)」の4つのルーチンを有することができる。「パーティタイム」ルーチンは、居間のスピーカにパーティ音楽をレンダリングするアクションと、居間のネットワーク化されたライトをランダムな色のパターンで点滅するように調整するアクションと、「ローカルピザショップ」からサードパーティエージェントを介して配達するためのピザを注文するアクションとを含むことができる。「おはよう」ルーチンは、ユーザのためのその日のスケジュールをレンダリングするアクションと、寝室のネットワーク化されたライトをオンにするアクションと、ユーザに対してその日の天気をレンダリングするアクションと、ユーザに対してニュースの見出しをレンダリングするアクションとを含むことができる。ユーザのための「おやすみ」ルーチンは、家の中のすべてのネットワーク化されたライトをオフにすることと、ユーザに対して明日のスケジュールをレンダリングすることと、ユーザに対して明日の天気をレンダリングすることと、ユーザに対して2時間ホワイトノイズをレンダリングすることとを含むことができる。加えて、ユーザの「車で家に帰る」ルーチンは、ユーザに対して夕方のスケジュールをレンダリングするアクションと、ユーザが車で家に帰っていることを別のクライアントデバイスにおいてユーザの配偶者に通知するアクションと、ユーザが決定した株価のグループに関する情報をレンダリングするアクションと、ドライブの残りの間、ポッドキャストをレンダリングするアクションとを含むことができる。 In some implementations, a potential action can be compared to many routines before selecting a routine (or group of routines) to potentially add an action. For example, a user can have four routines: "party time," "good morning," "good night," and "drive home." The "Party Time" routine includes the action of rendering party music to the living room speakers, adjusting the networked lights in the living room to blink in a random color pattern, and a third party from the "Local Pizza Shop". It can include actions such as ordering pizza for delivery via an agent. The "Good morning" routine is an action that renders the schedule for the day for the user, an action that turns on the networked lights in the bedroom, an action that renders the weather for the day for the user, and the action for the user. It can include actions that render news headlines. The "good night" routine for the user turns off all networked lights in the house, renders tomorrow's schedule for the user, and renders tomorrow's weather for the user. It can include doing and rendering white noise to the user for 2 hours. In addition, the user's "drive home" routine informs the user of the action of rendering the evening schedule and the user's spouse on another client device that the user is driving home. Actions to render, actions to render information about a user-determined group of stock prices, and actions to render a podcast for the rest of the drive can be included.
例として、自動化されたアシスタントは、ユーザの4つのルーチンを再調査し、「ローカルコーヒーショップ」からコーヒーを注文するアクションを追加することを提案するルーチンを選択することができる。様々な実装形態では、自動化されたアシスタントは、新しいアクションと比較されたルーチン内に含まれるアクション、(もしあれば)新しいアクションとルーチンとの間の履歴的関係、(もしあれば)新しいアクションとルーチンとの間の時間的関係、他のユーザが一般に同様のルーチン内にアクションを有しているかどうかなどを含む、各ルーチンに関する様々な情報を分析することができる。「パーティタイム」ルーチンに関して、自動化されたアシスタントは、コーヒーを注文する新しいアクションをルーチンと比較することができる。他のユーザは、一般に、パーティを開く前に(すなわち、ユーザがパーティ中に起きているように)コーヒーを注文する場合がある。「パーティタイム」は、固有の時間的制約を有し、「ローカルピザショップ」が開いている間に実行される必要がある。ユーザは、ユーザが「パーティタイム」ルーチンを実行したのとほぼ同じ時間に過去にコーヒーを注文した場合がある(すなわち、ユーザは、家で仕事をしているときに午後のコーヒーを注文するが、ユーザは、午後の同じ時間にパーティも開く)ので、ユーザが「パーティタイム」ルーチンを実行したときの履歴データは、それがユーザへの提案であるべきであることを示す可能性がある。しかしながら、「ローカルピザショップ」から配達のためのピザを注文するアクションは、家を出て一杯のコーヒーを受け取りに行くことと矛盾する(すなわち、ユーザは、家を出てコーヒーの注文を受け取りに行く場合、ピザが配達されたときに家にいない場合がある)。したがって、自動化されたアシスタントは、一般に、「ローカルコーヒーショップ」から一杯のコーヒーを注文するアクションを「パーティタイム」ルーチンに追加することを推奨するべきではない。追加的または代替的に、いくつかの実装形態では、自動化されたアシスタントは、「パーティタイム」ルーチンを実行した後、ユーザの過去のアクションを確認することができる。 As an example, an automated assistant can review the user's four routines and select a routine that suggests adding an action to order coffee from the "local coffee shop". In various implementations, automated assistants include actions contained within the routine compared to the new action, the historical relationship between the new action (if any) and the routine, and the new action (if any). Various information about each routine can be analyzed, including the temporal relationship with the routines, whether other users generally have actions within similar routines, and so on. For "party time" routines, automated assistants can compare new actions to order coffee with routines. Other users may generally order coffee before having a party (ie, as the user is awake during the party). "Party time" has its own time constraints and must be run while the "local pizza shop" is open. The user may have ordered coffee in the past at about the same time that the user ran the "party time" routine (ie, the user ordered afternoon coffee while working at home. , The user also has a party at the same time in the afternoon), so historical data when the user executes the "party time" routine may indicate that it should be a suggestion to the user. However, the action of ordering pizza for delivery from a "local pizza shop" contradicts leaving home to pick up a cup of coffee (ie, the user leaves home to pick up a coffee order). If you go, you may not be at home when the pizza is delivered). Therefore, automated assistants should generally not recommend adding the action of ordering a cup of coffee from the "local coffee shop" to the "party time" routine. Additional or alternative, in some implementations, an automated assistant can see the user's past actions after performing a "party time" routine.
同様に、自動化されたアシスタントは、新しいコーヒー注文アクションと比較して「おはよう」ルーチンを分析することができる。他のユーザは、一般に、同様のルーチンにおいてコーヒーを注文する。「ローカルコーヒーショップ」は、ユーザがユーザの「おはよう」ルーチンを実行している間、開いている可能性がある。加えて、「おはよう」ルーチン内の前から存在するアクションは、コーヒーを注文することと競合しない(例えば、コーヒーメーカーをオンすることは、「おはよう」ルーチン内に含まれない)。さらに、ユーザが「おはよう」ルーチンを実行するのとほぼ同じ時間に朝にコーヒーを注文するユーザのアクションは、すべて、「ローカルコーヒーショップ」からコーヒー注文を行う新しいアクションを「おはよう」ルーチンに追加することを提案する指標となり得る。 Similarly, automated assistants can analyze "good morning" routines in comparison to new coffee ordering actions. Other users generally order coffee in a similar routine. The "local coffee shop" may be open while the user is running the user's "good morning" routine. In addition, pre-existing actions in the "good morning" routine do not conflict with ordering coffee (for example, turning on the coffee maker is not included in the "good morning" routine). In addition, all user actions that order coffee in the morning at about the same time that the user executes the "good morning" routine add a new action to the "good morning" routine to order coffee from the "local coffee shop". It can be an index to propose that.
対照的に、「おやすみ」ルーチンは、「ローカルコーヒーショップ」が閉まっているときに実行され得、これは、アクションを追加することを提案しないことのアシスタントへの指標となり得る。しかしながら、いくつかの実装形態では、自動化されたアシスタントは、ユーザの好みのコーヒーショップが閉まっている場合、コーヒーを注文する別のコーヒーショップの推奨を行うことができる。大部分のユーザは、コーヒーを注文することを同様の夕方のルーチン内に含めておらず、これは、自動化されたアシスタントに、アクションを提案しないように指示することができる。加えて、家全体のネットワーク化された照明をオフにし、ホワイトノイズを2時間再生するアクションを続けるなどの、「おやすみ」ルーチン内のユーザアクションは、一杯のコーヒーを受け取るために家を出ることと矛盾する。家全体のライトをオフにするアクション自体は、一杯のコーヒーを受け取ることと矛盾しないが、「おやすみ」ルーチン内の他のアクションと対になったアクションは、コーヒーを受け取るために家を出ることと矛盾する。 In contrast, a "good night" routine can be performed when the "local coffee shop" is closed, which can be an indicator to the assistant not to suggest adding an action. However, in some implementations, the automated assistant can make recommendations for another coffee shop to order coffee if the user's favorite coffee shop is closed. Most users do not include ordering coffee in a similar evening routine, which can instruct an automated assistant not to suggest an action. In addition, user actions within the "good night" routine, such as turning off networked lights throughout the house and continuing the action of playing white noise for two hours, are to leave the house to receive a cup of coffee. Inconsistent. The action of turning off the lights throughout the house is consistent with receiving a cup of coffee, but the action paired with other actions in the "good night" routine is leaving the house to receive coffee. Contradictory.
さらに、「車で家に帰る」ルーチンは、新しいコーヒー注文アクションと比較され得る。ユーザは、すでに車を運転しているので、「車で家に帰る」ルーチン内の任意のアクションと一杯のコーヒーを受け取ることとの間に矛盾は、存在しない。しかしながら、自動化されたアシスタントは、一般に、新しいアクションを追加するルーチンを提案する前に、多くの要因を再調査する。自動化されたアシスタントは、他のユーザの同様のルーチンと比較して、大部分のユーザが、仕事から車で家に帰るときに、夕方にコーヒーを注文しないことを確認することができる。これは、自動化されたアシスタントに、「車で家に帰る」ルーチンにアクションを追加することを提案しないことを示す可能性がある。加えて、コーヒーを注文するユーザの過去のアクションは、分析され得、自動化されたアシスタントは、ユーザが、午後3時以降にコーヒーを一度も注文しておらず、ユーザが、一般に、午後5時と午後6時との間に「車で家に帰る」ルーチンを開始することを確認することができる。ユーザが「車で家に帰る」ルーチンを実行する時間は、ユーザが「ローカルコーヒーショップ」からコーヒーを注文したときに関する履歴データと矛盾する。これは、自動化されたアシスタントに、コーヒーを注文する新しいアクションを「車で家に帰る」ルーチンに追加することを提案しないことをさらに示す可能性がある。 In addition, the "drive home" routine can be compared to the new coffee ordering action. Since the user is already driving, there is no contradiction between any action in the "drive home" routine and receiving a cup of coffee. However, automated assistants generally review many factors before proposing routines to add new actions. Automated assistants can ensure that most users do not order coffee in the evening when they drive home from work, compared to similar routines for other users. This may indicate that the automated assistant does not suggest adding actions to the "drive home" routine. In addition, past actions of users ordering coffee can be analyzed, and automated assistants have never ordered coffee after 3 pm and users generally have 5 pm You can be sure to start the "drive home" routine between and 6 pm. The time the user runs the "drive home" routine is inconsistent with historical data about when the user ordered coffee from the "local coffee shop". This could further indicate that the automated assistant would not suggest adding a new action to order coffee to the "drive home" routine.
したがって、ユーザに関するすべてのルーチンを分析した後、この例における自動化されたアシスタントは、「ローカルコーヒーショップ」から一杯のコーヒーを注文する新しいアクションを追加することを提案するために「おはよう」ルーチンを選択すべきである。 Therefore, after analyzing all the routines for the user, the automated assistant in this example selects the "Good morning" routine to suggest adding a new action to order a cup of coffee from the "local coffee shop". Should.
自動化されたアシスタントは、アクションが、潜在的な自動化されたアシスタントルーチンのグループ内のルーチンのいずれかに追加されるべきであるかどうかを促すユーザインターフェース出力をレンダリングすることができる(408)。いくつかの実装形態では、ユーザは、同じアクションをいくつかのルーチンに追加してもよい。いくつかの実装形態では、ユーザは、アクションを単一のルーチンに追加したい場合がある。さらに、いくつかの実装形態では、ユーザは、上記で説明した図2と同様のアクションを実行した後、アクションがルーチンに追加されるべきかどうかを尋ねられ得る。追加的または代替的に、ユーザは、上記で説明した図3と同様の特定のルーチンを実行した後、アクションがルーチンに追加されるべきかどうかを尋ねられ得る。 Automated assistants can render user interface output that prompts if an action should be added to any of the routines in a group of potential automated assistant routines (408). In some implementations, the user may add the same action to some routines. In some implementations, the user may want to add an action to a single routine. In addition, in some implementations, the user may be asked if an action should be added to the routine after performing an action similar to Figure 2 described above. Additional or alternative, the user may be asked if an action should be added to the routine after performing a particular routine similar to Figure 3 described above.
(408)における出力に応答して、肯定的なユーザインターフェース入力が、受信された場合(410)、自動化されたアシスタントは、対応する自動化されたアシスタントルーチンにアクションを追加することができる。例えば、(408)における出力が、アクションが特定のルーチンに追加されるべきであるかどうかを促す場合、「はい」の発話は、アクションを特定のルーチンに追加させることができる。また、例えば、(408)における出力が、アクションが第1の特定のルーチンまたは第2の特定のルーチンのいずれに追加されるべきかを促す場合、「第1のもの」の発話は、アクションを第1の特定のルーチンに追加させることができるが、第2の特定のルーチンには追加させず、「第2のもの」の発話は、アクションを第2の特定のルーチンに追加させることができるが、第1の特定のルーチンには追加させず、「両方」の発話は、アクションを第1の特定のルーチンと第2の特定のルーチンの両方に追加させることができる。多くの実装形態では、自動化されたアシスタントは、特定のルーチンの名前をユーザに促すことができ、ユーザは、特定のルーチンの名前を言うことによって、アクションをルーチンに追加することができる。例えば、出力(408)が、おはようルーチンおよび車で仕事に行くルーチンにルーチンを追加する提案をユーザに促した場合、ルーチンの名前、例えば、「車で仕事に行く」の発話は、アクションを「車で仕事に行く」ルーチンに追加させることができる。いくつかの実装形態では、自動化されたアシスタントは、アクションをルーチンに自動的に追加することができ、アクションがルーチンに追加されるとユーザに合図することができる。いくつかの実装形態では、自動化されたアシスタントは、上記の図2における説明と同様に、前から存在するルーチン内の一連のアクションのどこに新しいアクションを追加するかを決定することができる。 If a positive user interface input is received in response to the output in (408) (410), the automated assistant can add actions to the corresponding automated assistant routine. For example, if the output in (408) prompts whether an action should be added to a particular routine, the "yes" utterance can cause the action to be added to a particular routine. Also, for example, if the output in (408) prompts whether the action should be added to either the first specific routine or the second specific routine, the "first thing" utterance takes the action. It can be added to the first specific routine, but not to the second specific routine, and the "second thing" utterance can cause the action to be added to the second specific routine. However, the "both" utterance can cause the action to be added to both the first specific routine and the second specific routine without adding it to the first specific routine. In many implementations, an automated assistant can prompt the user for the name of a particular routine, and the user can add actions to the routine by saying the name of the particular routine. For example, if output (408) prompts the user for suggestions to add a routine to the good morning routine and the routine to go to work by car, the name of the routine, for example, the utterance of "go to work by car" will take the action " It can be added to the "Go to work by car" routine. In some implementations, an automated assistant can automatically add an action to a routine and signal the user when an action is added to the routine. In some implementations, the automated assistant can decide where to add a new action in a set of actions in a pre-existing routine, similar to the description in Figure 2 above.
図5は、例示的なコンピュータシステム510のブロック図である。コンピュータシステム510は、典型的には、バスサブシステム512を介していくつかの周辺デバイスと通信する少なくとも1つのプロセッサ514を含む。これらの周辺デバイスは、例えば、メモリ525とファイル記憶サブシステム526とを含む記憶サブシステム524と、ユーザインターフェース出力デバイス520と、ユーザインターフェース入力デバイス522と、ネットワークインターフェースサブシステム516とを含んでもよい。入力デバイスおよび出力デバイスは、コンピュータシステム510とのユーザ対話を可能にする。ネットワークインターフェースサブシステム516は、外部ネットワークへのインターフェースを提供し、他のコンピュータシステム内の対応するインターフェースデバイスに結合される。
FIG. 5 is a block diagram of an
ユーザインターフェース入力デバイス522は、キーボード、マウス、トラックボール、タッチパッド、もしくはグラフィックタブレットなどのポインティングデバイス、スキャナ、ディスプレイに組み込まれたタッチスクリーン、音声認識システム、マイクロフォンなどのオーディオ入力デバイス、および/または他のタイプの入力デバイスを含んでもよい。一般に、「入力デバイス」という用語の使用は、コンピュータシステム510または通信ネットワークに情報を入力するすべての可能なタイプのデバイスおよび方法を含むことを意図している。
The user
ユーザインターフェース出力デバイス520は、ディスプレイサブシステム、プリンタ、ファックス機、またはオーディオ出力デバイスなどの非視覚的ディスプレイを含んでもよい。ディスプレイサブシステムは、陰極線管(CRT)、液晶ディスプレイ(LCD)などのフラットパネルデバイス、投影デバイス、または視覚的画像を作成するためのなにか他のメカニズムを含んでもよい。ディスプレイサブシステムはまた、オーディオ出力デバイスを介するなどして、非視覚的ディスプレイを提供してもよい。一般に、「出力デバイス」という用語の使用は、コンピュータシステム510からユーザまたは別のマシンもしくはコンピュータシステムに情報を出力するためのすべての可能なタイプのデバイスおよび方法を含むことを意図している。
The user
記憶サブシステム524は、本明細書で説明したモジュールのうちのいくつかまたはすべての機能を提供するプログラミング構造およびデータ構造を記憶する。例えば、記憶サブシステム524は、図1の選択された態様、および/もしくはプロセス400、本明細書で説明した任意の動作を実行するため、ならびに/またはクラウドベースの自動化された構成要素116、自動化されたアシスタント112、クライアントデバイス102、および/もしくは本明細書で説明した任意の他のデバイスもしくはアプリケーションを実装するためのロジックを含んでもよい。
The storage subsystem 524 stores programming and data structures that provide some or all of the functionality of the modules described herein. For example, storage subsystem 524 may perform the selected aspects of FIG. 1 and / or
これらのソフトウェアモジュールは、一般に、プロセッサ514によって単独で、または他のプロセッサと組み合わせて実行される。記憶サブシステム524において使用されるメモリ525は、プログラム実行中の命令およびデータの記憶のためのメインランダムアクセスメモリ(RAM)530と、固定命令が記憶されている読み取り専用メモリ(ROM)532とを含むいくつかのメモリを含むことができる。ファイル記憶サブシステム526は、プログラムファイルおよびデータファイルのための永続的なストレージを提供することができ、ハードディスクドライブ、関連するリムーバブルメディアを伴うフロッピーディスクドライブ、CD-ROMドライブ、光学ドライブ、またはリムーバブルメディアカートリッジを含んでもよい。特定の実装形態の機能を実装するモジュールは、ファイル記憶サブシステム426によって、記憶サブシステム524内に、またはプロセッサ514によってアクセス可能な他のマシン内に記憶され得る。
These software modules are generally executed by
バスサブシステム512は、コンピュータシステム510の様々な構成要素およびサブシステムを意図されたように互いに通信させるためのメカニズムを提供する。バスサブシステム512は、単一のバスとして概略的に示されているが、バスサブシステムの代替実装形態は、複数のバスを使用してもよい。
The
コンピュータシステム510は、ワークステーション、サーバ、コンピューティングクラスタ、ブレードサーバ、サーバファーム、または任意の他のデータ処理システムもしくはコンピューティングデバイスを含む様々なタイプのものであり得る。コンピュータおよびネットワークの絶えず変化する性質のために、図5に示すコンピュータシステム510の説明は、いくつかの実装形態を説明する目的のための特定の例としてのみ意図されている。図5に示すコンピュータシステムよりも多いまたは少ない構成要素を有するコンピュータシステム510の多くの他の構成が、可能である。
The
本明細書で説明したシステムが、ユーザ(または、本明細書ではしばしば「参加者」と呼ばれる)に関する個人情報を収集するか、または個人情報を利用する可能性がある状況では、ユーザは、プログラムまたは機能がユーザ情報(例えば、ユーザの社会的ネットワーク、社会的行為または活動、職業、ユーザの好み、またはユーザの現在の地理的位置に関する情報)を収集するかどうかを制御する機会、またはユーザにより関連性がある可能性があるコンテンツサーバからのコンテンツを受信するかどうかおよび/もしくはどのように受信するかを制御する機会を提供され得る。また、特定のデータは、個人を特定し得る情報が除去されるように、記憶または使用される前に1つまたは複数の方法で処理され得る。例えば、ユーザの識別情報は、個人を特定し得る情報がユーザに関して決定され得ないように処理され得、またはユーザの特定の地理的位置が決定され得ないように、ユーザの地理的位置が、地理的位置情報が取得される場所(都市、郵便番号、または州レベルなど)で一般化され得るように処理され得る。したがって、ユーザは、ユーザに関する情報がどのように収集および/または使用されるかについて制御してもよい。 In situations where the systems described herein may collect or utilize personal information about you (or often referred to herein as "participants"), you may program. Or an opportunity to control whether a feature collects user information (eg, information about the user's social network, social actions or activities, occupation, user preferences, or the user's current geographic location), or by the user. You may be offered the opportunity to control whether and / or how content is received from content servers that may be relevant. Also, certain data may be processed in one or more ways before being stored or used so that personally identifiable information is removed. For example, the user's identification information may be processed so that personally identifiable information cannot be determined with respect to the user, or the user's geographic location cannot be determined. It can be processed so that it can be generalized at the location where geolocation is obtained (such as city, zip code, or state level). Therefore, the user may control how information about the user is collected and / or used.
100 環境
102 クライアントデバイス
104 デバイス
106 サードパーティエージェント
108 自動化されたアシスタントクライアント
110 音声キャプチャ/テキスト音声化(「TTS」)/音声テキスト化(「STT」)モジュール、音声キャプチャ/TTS/STTモジュール
112 自動化されたアシスタントクライアント、自動化されたアシスタント
114 ローカルエリアネットワークおよび/またはワイドエリアネットワーク
116 クラウドベースの自動化されたアシスタント構成要素
118 クラウドベースのTTSモジュール、TTSモジュール
120 クラウドベースのSTTモジュール、STTモジュール
122 自然言語プロセッサ
124 ルーチンモジュール
200 画像
202 ユーザ
204 クライアントデバイス
206 ダイアログボックス
208 ダイアログボックス
210 ダイアログボックス
212 ダイアログボックス
300 画像
302 ユーザ
304 クライアントデバイス
306 ダイアログボックス
308 ダイアログボックス
310 ダイアログボックス
312 ダイアログボックス
510 コンピュータシステム
512 バスサブシステム
514 プロセッサ
516 ネットワークインターフェースサブシステム
520 ユーザインターフェース出力デバイス
522 ユーザインターフェース入力デバイス
524 記憶サブシステム
525 メモリ
526 ファイル記憶サブシステム
530 メインランダムアクセスメモリ(RAM)
532 読み取り専用メモリ(ROM)
100 environment
102 Client device
104 devices
106 Third Party Agent
108 Automated Assistant Client
110 Voice capture / text voice conversion (“TTS”) / voice text conversion (“STT”) module, voice capture / TTS / STT module
112 Automated Assistant Client, Automated Assistant
114 Local Area Network and / or Wide Area Network
116 Cloud-based automated assistant component
118 Cloud-based TTS module, TTS module
120 Cloud-based STT module, STT module
122 natural language processor
124 Routine module
200 images
202 users
204 Client device
206 dialog box
208 dialog box
210 dialog box
212 dialog box
300 images
302 users
304 Client device
306 Dialog Box
308 dialog box
310 dialog box
312 dialog box
510 computer system
512 bus subsystem
514 processor
516 Network Interface Subsystem
520 User Interface Output Device
522 User Interface Input Device
524 Storage subsystem
525 memory
526 File Storage Subsystem
530 Main Random Access Memory (RAM)
532 Read-only memory (ROM)
Claims (25)
自動化されたアシスタントによって開始されるアクションを決定するステップであって、前記アクションが、前記自動化されたアシスタントと対話する1つまたは複数の自動化されたアシスタントインターフェースを介してユーザによって提供されたユーザインターフェース入力の1つまたは複数のインスタンスに応答して、前記自動化されたアシスタントによって開始される、ステップと、
前記ユーザに関連して記憶された複数の自動化されたアシスタントルーチンを識別するステップであって、前記自動化されたアシスタントルーチンの各々が、前記自動化されたアシスタントルーチンの初期化に応答して前記自動化されたアシスタントを介して自動的に実行されるべき複数の対応するアクションを定義し、前記アクションが、前記自動化されたアシスタントルーチンの前記アクションに追加される、ステップと、
前記アクションを、前記ユーザに関連して記憶された前記複数の自動化されたアシスタントルーチンと比較するステップと、
前記比較に基づいて、前記ユーザに関連して記憶された前記自動化されたアシスタントルーチンのサブセットを選択するステップと、
前記ユーザによって提供されたユーザインターフェース入力に応答して前記アクションが開始されることに基づくとともに、前記自動化されたアシスタントルーチンの前記サブセットを選択したことに基づいて、
前記ユーザのクライアントデバイスを介してユーザインターフェース出力をレンダリングさせるステップであって、前記ユーザインターフェース出力が、前記サブセットの前記自動化されたアシスタントルーチンのうちの1つまたは複数に前記アクションを追加するように前記ユーザに促す、ステップと、
前記ユーザインターフェース出力に応答して肯定的なユーザインターフェース入力を受信するステップであって、前記肯定的なユーザインターフェース入力が、前記サブセットの前記自動化されたアシスタントルーチンのうちの所与のルーチンを示す、ステップと、
前記肯定的なユーザインターフェース入力を受信したことに応答して、
前記所与のルーチンの初期化に応答して自動的に実行されるべき前記所与のルーチンの前記複数の対応するアクションの追加の1つとして前記アクションを自動的に追加するステップと
を含む、方法。 A method performed by one or more processors, said method:
A step that determines an action initiated by an automated assistant, wherein the action is a user interface input provided by the user through one or more automated assistant interfaces that interact with the automated assistant. In response to one or more instances of, the steps and, initiated by the automated assistant,
A step of identifying a plurality of automated assistant routines stored in relation to the user, each of which is automated in response to initialization of the automated assistant routine. A step and a step that defines a plurality of corresponding actions to be automatically performed through the assistant, and the action is added to the action of the automated assistant routine.
A step of comparing the action with the plurality of automated assistant routines stored in relation to the user.
Based on the comparison, the step of selecting a subset of the automated assistant routines stored in relation to the user, and
Based on the action being initiated in response to the user interface input provided by the user and on selecting the subset of the automated assistant routine.
The step of rendering the user interface output through the user's client device, such that the user interface output adds the action to one or more of the automated assistant routines of the subset. Steps and steps to encourage users
A step of receiving a positive user interface input in response to the user interface output, wherein the positive user interface input indicates a given routine of the automated assistant routines of the subset. Steps and
In response to receiving the positive user interface input
Includes a step of automatically adding the action as one of the additions to the plurality of corresponding actions of the given routine that should be performed automatically in response to the initialization of the given routine. Method.
前記発話の1つまたは複数の音声特性に基づいて前記ユーザのプロファイルを識別するステップをさらに含み、
前記ユーザに関連して記憶された前記複数の自動化されたアシスタントルーチンを識別するステップが、前記複数の自動化されたアシスタントルーチンが前記ユーザの前記プロファイルに関連して記憶されていることに基づいて前記複数の自動化されたアシスタントルーチンを識別するステップを含み、
前記所与のルーチンを実行するステップが、前記ユーザからの追加の発話に応答して発生し、
前記ユーザの前記クライアントデバイスを介して前記ユーザインターフェース出力をレンダリングさせるステップが、前記追加の発話が前記ユーザの前記プロファイルに対応する1つまたは複数の音声特性を有すると決定したことにさらに基づく、
請求項3に記載の方法。 One or more instances of the user interface that initiated the action include an utterance, the method.
Further comprising identifying the user's profile based on one or more voice characteristics of the utterance.
The step of identifying the plurality of automated assistant routines stored in connection with the user is based on the fact that the plurality of automated assistant routines are stored in relation to the profile of the user. Includes steps to identify multiple automated assistant routines
The step of executing the given routine occurs in response to additional utterances from the user.
Further based on the step of rendering the user interface output through the user's client device is determined that the additional utterance has one or more voice characteristics corresponding to the user's profile.
The method according to claim 3.
前記アクションを、前記自動化されたアシスタントルーチンの各々の中の前記複数の対応するアクションの各々と比較するステップと、
前記比較するステップに基づいて、前記自動化されたアシスタントルーチンの各々について、前記アクションが、前記自動化されたアシスタントルーチン内の前記複数の対応するアクションのいずれかとの1つまたは複数の矛盾を含むかどうかを決定するステップと、
前記サブセットの前記自動化されたアシスタントルーチンの前記複数の対応するアクションには、前記アクションとの前記1つまたは複数の矛盾がないと決定したことに基づいて、前記自動化されたアシスタントルーチンの前記サブセットを選択するステップと
を含む、請求項1から7のいずれか一項に記載の方法。 The step of selecting the subset of the automated assistant routine
A step of comparing the action with each of the plurality of corresponding actions in each of the automated assistant routines.
For each of the automated assistant routines, based on the comparing steps, whether the action contains one or more inconsistencies with any of the plurality of corresponding actions in the automated assistant routine. And the steps to decide
The subset of the automated assistant routine is based on the determination that the plurality of corresponding actions of the automated assistant routine of the subset are consistent with the one or more of the actions. The method of any one of claims 1-7, including the steps to be selected.
前記クライアントデバイスが表示能力を欠いており、かつ前記追加のクライアントデバイスが表示能力を含むと決定したことに基づいて、前記ユーザインターフェース出力を提供するための前記追加のクライアントデバイスを選択するステップをさらに含む、請求項16に記載の方法。 The user interface output includes a graphical output, the method.
Further steps are taken to select the additional client device to provide the user interface output based on the determination that the client device lacks display capability and that the additional client device includes display capability. The method of claim 16, including.
前記発話の1つまたは複数の音声特性に基づいて前記ユーザのプロファイルを識別するステップをさらに含み、
前記ユーザに関連して記憶された前記複数の自動化されたアシスタントルーチンを識別するステップが、前記複数の自動化されたアシスタントルーチンが前記ユーザの前記プロファイルに関連して記憶されていることに基づいて前記複数の自動化されたアシスタントルーチンを識別するステップを含む、
請求項1に記載の方法。 One or more instances of the user interface input that initiated the action include an utterance, the method.
Further comprising identifying the user's profile based on one or more voice characteristics of the utterance.
The step of identifying the plurality of automated assistant routines stored in connection with the user is based on the fact that the plurality of automated assistant routines are stored in relation to the profile of the user. Includes steps to identify multiple automated assistant routines,
The method according to claim 1.
自動化されたアシスタントアクションを決定するステップと、
ユーザに関連して記憶された複数の自動化されたアシスタントルーチンを識別するステップであって、前記自動化されたアシスタントルーチンの各々が、前記自動化されたアシスタントルーチンの初期化に応答して前記自動化されたアシスタントを介して自動的に実行されるべき複数の対応するアクションを定義し、前記自動化されたアシスタントアクションが、前記自動化されたアシスタントルーチンの前記複数の対応するアクションに追加される、ステップと、
前記自動化されたアシスタントアクションを、前記ユーザに関連して記憶された前記複数の自動化されたアシスタントルーチンと比較するステップと、
前記比較に基づいて、前記ユーザに関連して記憶された前記自動化されたアシスタントルーチンのサブセットを選択するステップと、
クライアントデバイスの1つまたは複数のセンサからのセンサデータに基づいて、前記ユーザが前記クライアントデバイスと対話していることを決定するステップと、
前記ユーザが前記クライアントデバイスと対話していると決定したことに基づくとともに、前記自動化されたアシスタントルーチンの前記サブセットを選択したことに基づいて、
前記クライアントデバイスを介してユーザインターフェース出力をレンダリングさせるステップであって、前記ユーザインターフェース出力が、前記サブセットの前記自動化されたアシスタントルーチンのうちの1つまたは複数に前記自動化されたアシスタントアクションを追加するように前記ユーザに促す、ステップと、
前記ユーザインターフェース出力に応答して肯定的なユーザインターフェース入力を受信するステップであって、前記肯定的なユーザインターフェース入力が、前記サブセットの前記自動化されたアシスタントルーチンのうちの所与のルーチンを示す、ステップと、
前記肯定的なユーザインターフェース入力を受信したことに応答して、
前記所与のルーチンの初期化に応答して自動的に実行されるべき前記所与のルーチンの前記複数の対応するアクションの追加の1つとして、前記自動化されたアシスタントアクションを追加するステップと
を含む、方法。 A method performed by one or more processors, said method:
Steps to determine automated assistant actions and
A step of identifying a plurality of automated assistant routines stored in relation to a user, each of the automated assistant routines being automated in response to initialization of the automated assistant routine. A step that defines a plurality of corresponding actions to be automatically performed through the assistant, and the automated assistant action is added to the plurality of corresponding actions in the automated assistant routine.
A step of comparing the automated assistant action with the plurality of automated assistant routines stored in relation to the user.
Based on the comparison, the step of selecting a subset of the automated assistant routines stored in relation to the user, and
A step of determining that the user is interacting with the client device based on sensor data from one or more sensors on the client device.
Based on determining that the user is interacting with the client device and selecting the subset of the automated assistant routine.
The step of rendering the user interface output through the client device so that the user interface output adds the automated assistant action to one or more of the automated assistant routines in the subset. To urge the user to step and
A step of receiving a positive user interface input in response to the user interface output, wherein the positive user interface input indicates a given routine of the automated assistant routines of the subset. Steps and
In response to receiving the positive user interface input
One of the additions to the plurality of corresponding actions of the given routine that should be performed automatically in response to the initialization of the given routine is to add the automated assistant action. Including, method.
前記音声データに基づいて1つまたは複数の音声特性を決定するステップと、
前記ユーザのユーザプロファイルに一致する前記音声特性に基づいて前記ユーザを識別するステップと
を含む、請求項19に記載の方法。 The step of determining that the sensor data includes voice data based on one or more microphones of the client device and that the user is interacting with the client device.
A step of determining one or more voice characteristics based on the voice data,
19. The method of claim 19, comprising identifying the user based on said voice characteristics that match the user's user profile.
前記自動化されたアシスタントアクションを、前記ユーザに関連して記憶された前記複数の自動化されたアシスタントルーチンと比較するステップが、
前記ユーザの接続されたデバイスのデバイストポロジに基づいて、前記所与のルーチンの前記複数の対応するアクションのうちの少なくとも1つによって制御される前記特定の接続されたデバイスと追加の接続されたデバイスが両方とも前記デバイストポロジ内の同じ物理的な場所に割り当てられていることを決定するステップを含み、
前記比較に基づいて、前記サブセット内に含めるための前記所与のルーチンを選択するステップが、
前記特定の接続されたデバイスと前記追加の接続されたデバイスが両方とも前記同じ物理的な場所に割り当てられていると決定したことに基づいて、前記サブセット内に含めるための前記所与のルーチンを選択するステップを含む、
請求項19または20に記載の方法。 The automated assistant action involves controlling a particular connected device.
The step of comparing the automated assistant action with the plurality of automated assistant routines stored in relation to the user.
The particular connected device and additional connected devices controlled by at least one of the plurality of corresponding actions of the given routine, based on the device topology of the user's connected device. Includes the step of determining that both are assigned to the same physical location within the device topology.
Based on the comparison, the step of selecting the given routine to include within the subset
Based on the determination that both the particular connected device and the additional connected device are assigned to the same physical location, the given routine for inclusion within the subset Including steps to select,
The method of claim 19 or 20.
前記特定の接続されたデバイスの報告された状態に基づいて、前記特定の接続されたデバイスが自動化されていないアシスタントの対話に応答して特定の方法で制御されたことを決定するステップと、
前記特定の接続されたデバイスを前記特定の方法で制御させるための前記自動化されたアシスタントアクションを決定するステップと
を含む、請求項19から22のいずれか一項に記載の方法。 The step of determining the automated assistant action includes controlling the particular connected device by the automated assistant action.
Based on the reported state of the particular connected device, the step of determining that the particular connected device was controlled in a particular way in response to a non-automated assistant dialogue.
The method of any one of claims 19-22, comprising the step of determining the automated assistant action for controlling the particular connected device in said particular way.
前記ユーザによる前記自動化されたアシスタントアクションまたは関連するアクションの1つまたは複数の過去の実行に基づいて、前記自動化されたアシスタントアクションの少なくとも1つのアクションの時間的特性を決定するステップと、
前記自動化されたアシスタントルーチンの1つまたは複数の過去の実行に基づいて、前記自動化されたアシスタントルーチンの少なくとも1つのルーチンの時間的特性を決定するステップと、
前記少なくとも1つのアクションの時間的特性を前記少なくとも1つのルーチンの時間的特性と比較するステップと
を含む、請求項19から23のいずれか一項に記載の方法。 The step of comparing the automated assistant action with the plurality of automated assistant routines stored in relation to the user.
A step of determining the temporal characteristics of at least one action of the automated assistant action based on the past execution of one or more of the automated assistant actions or related actions by the user.
A step of determining the temporal characteristics of at least one routine of the automated assistant routine based on the past execution of one or more of the automated assistant routines.
The method of any one of claims 19-23, comprising the step of comparing the temporal characteristics of the at least one action with the temporal characteristics of the at least one routine.
前記ユーザによる別個のサードパーティとの別個の対話の過去の実行を決定するステップと、
前記別個の対話と前記自動化されたアシスタントアクションとの間の関係に基づいて前記自動化されたアシスタントアクションを決定するステップと
を含む、請求項19に記載の方法。 The step in which the automated assistant action includes a dialogue with a third party agent controlled by a particular third party and determines the automated assistant action is
The steps that determine the past execution of a separate dialogue with a separate third party by the user, and
19. The method of claim 19, comprising the step of determining the automated assistant action based on the relationship between the separate dialogue and the automated assistant action.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862668156P | 2018-05-07 | 2018-05-07 | |
US62/668,156 | 2018-05-07 | ||
PCT/US2019/030760 WO2019217248A1 (en) | 2018-05-07 | 2019-05-04 | Recommending automated assistant action for inclusion in automated assistant routine |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2021523457A true JP2021523457A (en) | 2021-09-02 |
JP7012883B2 JP7012883B2 (en) | 2022-01-28 |
Family
ID=66794074
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2020562676A Active JP7012883B2 (en) | 2018-05-07 | 2019-05-04 | Recommend automated assistant actions for inclusion within automated assistant routines |
Country Status (6)
Country | Link |
---|---|
US (3) | US11398231B2 (en) |
EP (1) | EP3776253A1 (en) |
JP (1) | JP7012883B2 (en) |
KR (3) | KR20230136696A (en) |
CN (1) | CN112236762A (en) |
WO (1) | WO2019217248A1 (en) |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20230136696A (en) * | 2018-05-07 | 2023-09-26 | 구글 엘엘씨 | Recommending automated assistant action for inclusion in automated assistant routine |
US11017772B1 (en) * | 2019-05-30 | 2021-05-25 | Josh.Ai, Inc. | Natural language programming |
US11164585B2 (en) * | 2019-06-07 | 2021-11-02 | Mitsubishi Electric Automotive America, Inc. | Systems and methods for virtual assistant routing |
US11657095B1 (en) * | 2020-03-31 | 2023-05-23 | Amazon Technologies, Inc. | Supplemental content placement for natural language interfaces |
US11748660B2 (en) * | 2020-09-17 | 2023-09-05 | Google Llc | Automated assistant training and/or execution of inter-user procedures |
US11909823B2 (en) | 2020-12-17 | 2024-02-20 | Samsung Electronics Co., Ltd. | Method and apparatus for generating alternative routines in an IoT environment |
US11885632B2 (en) * | 2021-04-15 | 2024-01-30 | Google Llc | Conditional preparation for automated assistant input from a user in a vehicle |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150269508A1 (en) * | 2014-03-18 | 2015-09-24 | Mckesson Financial Holdings | Method And Apparatus For Configuring A Task List |
US20170031711A1 (en) * | 2015-07-28 | 2017-02-02 | TCL Research America Inc. | Function-based action sequence derivation for personal assistant system |
JP2019537802A (en) * | 2016-11-21 | 2019-12-26 | グーグル エルエルシー | Providing prompts during an automated dialog session based on the selected content of a prior automated dialog session |
Family Cites Families (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6513006B2 (en) | 1999-08-26 | 2003-01-28 | Matsushita Electronic Industrial Co., Ltd. | Automatic control of household activity using speech recognition and natural language |
JP4684739B2 (en) | 2005-05-13 | 2011-05-18 | クラリオン株式会社 | Audio processing device |
US9318108B2 (en) * | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
JP5366173B2 (en) | 2008-02-28 | 2013-12-11 | インターナショナル・ビジネス・マシーンズ・コーポレーション | Operation support server device, operation support method, and computer program |
US9171092B2 (en) * | 2012-12-07 | 2015-10-27 | Empire Technology Development Llc | Personal assistant context building |
US9047271B1 (en) | 2013-02-28 | 2015-06-02 | Google Inc. | Mining data for natural language system |
KR102252258B1 (en) * | 2013-11-21 | 2021-05-14 | 삼성전자주식회사 | Method and apparatus for controlling a group of home devices in a home network system |
US9930519B2 (en) * | 2013-11-21 | 2018-03-27 | Samsung Electronics Co., Ltd. | Method and apparatus for controlling home devices on group basis based upon history of the home devices |
US9576575B2 (en) | 2014-10-27 | 2017-02-21 | Toyota Motor Engineering & Manufacturing North America, Inc. | Providing voice recognition shortcuts based on user verbal input |
US10270609B2 (en) | 2015-02-24 | 2019-04-23 | BrainofT Inc. | Automatically learning and controlling connected devices |
US9792281B2 (en) * | 2015-06-15 | 2017-10-17 | Microsoft Technology Licensing, Llc | Contextual language generation by leveraging language understanding |
US10262654B2 (en) | 2015-09-24 | 2019-04-16 | Microsoft Technology Licensing, Llc | Detecting actionable items in a conversation among participants |
US10018977B2 (en) | 2015-10-05 | 2018-07-10 | Savant Systems, Llc | History-based key phrase suggestions for voice control of a home automation system |
US11227017B2 (en) | 2016-05-17 | 2022-01-18 | Google Llc | Providing suggestions for interaction with an automated assistant in a multi-user message exchange thread |
US10387888B2 (en) | 2016-07-08 | 2019-08-20 | Asapp, Inc. | Assisting entities in responding to a request of a user |
US10444717B2 (en) | 2016-09-16 | 2019-10-15 | Whirlpool Corporation | Coordination of control modes among appliances and utilities |
KR101741647B1 (en) | 2016-09-30 | 2017-05-30 | 현대자동차주식회사 | Vehicle and method of controlling the same |
US20180277123A1 (en) | 2017-03-22 | 2018-09-27 | Bragi GmbH | Gesture controlled multi-peripheral management |
US11074280B2 (en) | 2017-05-18 | 2021-07-27 | Aiqudo, Inc | Cluster based search and recommendation method to rapidly on-board commands in personal assistants |
US10546023B2 (en) * | 2017-10-03 | 2020-01-28 | Google Llc | Providing command bundle suggestions for an automated assistant |
KR20230136696A (en) | 2018-05-07 | 2023-09-26 | 구글 엘엘씨 | Recommending automated assistant action for inclusion in automated assistant routine |
-
2019
- 2019-05-04 KR KR1020237031862A patent/KR20230136696A/en active IP Right Grant
- 2019-05-04 CN CN201980037318.8A patent/CN112236762A/en active Pending
- 2019-05-04 US US16/617,975 patent/US11398231B2/en active Active
- 2019-05-04 KR KR1020207033556A patent/KR102439144B1/en active IP Right Grant
- 2019-05-04 WO PCT/US2019/030760 patent/WO2019217248A1/en unknown
- 2019-05-04 JP JP2020562676A patent/JP7012883B2/en active Active
- 2019-05-04 KR KR1020227029828A patent/KR102581348B1/en active IP Right Grant
- 2019-05-04 EP EP19729389.7A patent/EP3776253A1/en active Pending
-
2022
- 2022-07-25 US US17/872,465 patent/US11749278B2/en active Active
-
2023
- 2023-07-05 US US18/218,333 patent/US20230352018A1/en active Pending
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150269508A1 (en) * | 2014-03-18 | 2015-09-24 | Mckesson Financial Holdings | Method And Apparatus For Configuring A Task List |
US20170031711A1 (en) * | 2015-07-28 | 2017-02-02 | TCL Research America Inc. | Function-based action sequence derivation for personal assistant system |
JP2019537802A (en) * | 2016-11-21 | 2019-12-26 | グーグル エルエルシー | Providing prompts during an automated dialog session based on the selected content of a prior automated dialog session |
Non-Patent Citations (1)
Title |
---|
安蔵 靖志: "製品選びと使いこなしのコツ スマートスピーカー購入ガイド", 日経パソコン, JPN6021050705, 9 April 2018 (2018-04-09), pages 38 - 49, ISSN: 0004665515 * |
Also Published As
Publication number | Publication date |
---|---|
KR102581348B1 (en) | 2023-09-22 |
US11398231B2 (en) | 2022-07-26 |
JP7012883B2 (en) | 2022-01-28 |
EP3776253A1 (en) | 2021-02-17 |
US20200175983A1 (en) | 2020-06-04 |
KR20220124819A (en) | 2022-09-14 |
CN112236762A (en) | 2021-01-15 |
US20230352018A1 (en) | 2023-11-02 |
US11749278B2 (en) | 2023-09-05 |
US20220358927A1 (en) | 2022-11-10 |
KR20230136696A (en) | 2023-09-26 |
KR20210002604A (en) | 2021-01-08 |
KR102439144B1 (en) | 2022-09-02 |
WO2019217248A1 (en) | 2019-11-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7012883B2 (en) | Recommend automated assistant actions for inclusion within automated assistant routines | |
JP7297836B2 (en) | Voice user interface shortcuts for assistant applications | |
US11256390B2 (en) | Providing composite graphical assistant interfaces for controlling various connected devices | |
JP7354301B2 (en) | Detection and/or registration of hot commands to trigger response actions by automated assistants | |
CN112119379B (en) | Transferring an auto-assistant routine between client devices during execution of the routine | |
JP7384976B2 (en) | determining whether to automatically resume the first automated assistant session upon termination of the interrupting second session; | |
JP2024020472A (en) | Semi-delegated calls with automated assistants on behalf of human participants | |
EP4133402A1 (en) | On-device generation and personalization of zero-prefix suggestion(s) and use thereof | |
JP7164615B2 (en) | Selecting content to render on the assistant device display |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20210105 |
|
TRDD | Decision of grant or rejection written | ||
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20211217 |
|
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20211220 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20220118 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7012883Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |