KR20230162721A - Integrating decision trees into neural networks - Google Patents
Integrating decision trees into neural networks Download PDFInfo
- Publication number
- KR20230162721A KR20230162721A KR1020237038523A KR20237038523A KR20230162721A KR 20230162721 A KR20230162721 A KR 20230162721A KR 1020237038523 A KR1020237038523 A KR 1020237038523A KR 20237038523 A KR20237038523 A KR 20237038523A KR 20230162721 A KR20230162721 A KR 20230162721A
- Authority
- KR
- South Korea
- Prior art keywords
- layer
- group
- neural network
- layers
- decision tree
- Prior art date
Links
- 238000013528 artificial neural network Methods 0.000 title claims abstract description 155
- 238000003066 decision tree Methods 0.000 title claims abstract description 134
- 238000010801 machine learning Methods 0.000 claims abstract description 64
- 238000000034 method Methods 0.000 claims abstract description 58
- 238000012549 training Methods 0.000 claims description 67
- 238000013139 quantization Methods 0.000 claims description 33
- 230000008569 process Effects 0.000 claims description 21
- 230000006870 function Effects 0.000 claims description 15
- 238000005259 measurement Methods 0.000 claims description 4
- 230000003044 adaptive effect Effects 0.000 claims description 2
- 238000004590 computer program Methods 0.000 abstract description 13
- 239000010410 layer Substances 0.000 description 238
- 238000012545 processing Methods 0.000 description 18
- 238000012986 modification Methods 0.000 description 13
- 230000004048 modification Effects 0.000 description 13
- 238000004364 calculation method Methods 0.000 description 12
- 239000011159 matrix material Substances 0.000 description 11
- 238000007667 floating Methods 0.000 description 9
- 230000004913 activation Effects 0.000 description 8
- 238000001994 activation Methods 0.000 description 8
- 239000012634 fragment Substances 0.000 description 5
- 230000004044 response Effects 0.000 description 5
- 230000009471 action Effects 0.000 description 4
- 238000013459 approach Methods 0.000 description 4
- 238000004891 communication Methods 0.000 description 4
- 238000010586 diagram Methods 0.000 description 4
- 230000004927 fusion Effects 0.000 description 4
- 230000003993 interaction Effects 0.000 description 3
- 230000008901 benefit Effects 0.000 description 2
- 238000004422 calculation algorithm Methods 0.000 description 2
- 239000003795 chemical substances by application Substances 0.000 description 2
- 238000012937 correction Methods 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 238000003062 neural network model Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 229920002803 thermoplastic polyurethane Polymers 0.000 description 2
- 238000013518 transcription Methods 0.000 description 2
- 230000035897 transcription Effects 0.000 description 2
- 241000009334 Singa Species 0.000 description 1
- 238000009825 accumulation Methods 0.000 description 1
- 230000006978 adaptation Effects 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000001149 cognitive effect Effects 0.000 description 1
- 238000001514 detection method Methods 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 238000003709 image segmentation Methods 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 230000010354 integration Effects 0.000 description 1
- 239000011229 interlayer Substances 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 238000011176 pooling Methods 0.000 description 1
- 238000013138 pruning Methods 0.000 description 1
- 230000002787 reinforcement Effects 0.000 description 1
- 230000011218 segmentation Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 238000011524 similarity measure Methods 0.000 description 1
- 238000004088 simulation Methods 0.000 description 1
- 239000002356 single layer Substances 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000013519 translation Methods 0.000 description 1
- 238000010200 validation analysis Methods 0.000 description 1
- 238000012795 verification Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
- G06N20/20—Ensemble learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/042—Knowledge-based neural networks; Logical representations of neural networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/049—Temporal neural networks, e.g. delay elements, oscillating neurons or pulsed inputs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0495—Quantised networks; Sparse networks; Compressed networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/01—Dynamic search techniques; Heuristics; Dynamic trees; Branch-and-bound
Abstract
계산 그래프에 표시된 동작들을 스케줄링하기 위한 방법, 시스템 및 장치는 컴퓨터 저장 매체에 인코딩된 컴퓨터 프로그램을 포함한다. 방법 중 하나는 시퀀스로 배열된 복수의 계층을 포함하는 신경망을 나타내는 데이터를 수신하는 단계와; 시퀀스에서 서로 인접한 하나 이상의 계층을 각각 포함하는 하나 이상의 계층 그룹을 선택하는 단계와; 새로운 기계 학습 모델을 생성하는 단계로서, 각 계층 그룹에 대해, 계층 그룹을 대체하는 개별 의사결정 트리를 선택하는 단계를 포함하고, 개별 의사결정 트리는 그룹 내의 각각의 첫 번째 계층에 대한 입력의 양자화 버전을 입력으로 수신하고 그룹 내의 각각의 마지막 계층 출력의 양자화 버전을 출력으로 생성하며, 개별 의사결정 트리의 트리 깊이는 그룹의 계층 수에 적어도 부분적으로 기초한다.Methods, systems, and apparatus for scheduling operations displayed in a computational graph include a computer program encoded in a computer storage medium. One of the methods includes receiving data representing a neural network comprising a plurality of layers arranged in a sequence; selecting one or more layer groups each containing one or more layers adjacent to each other in the sequence; Creating a new machine learning model, comprising: for each layer group, selecting an individual decision tree to replace the layer group, wherein the individual decision tree is a quantized version of the input for each first layer within the group. as input and produces as output a quantized version of the output of each last layer in the group, with the tree depth of an individual decision tree being based at least in part on the number of layers in the group.
Description
본 명세서는 대규모 신경망에 의사결정 트리를 통합하는 것에 관한 것이다.This specification relates to the integration of decision trees into large-scale neural networks.
신경망은 하나 이상의 비선형 단위 계층을 사용하여 수신된 입력에 대한 출력을 예측하는 기계 학습 모델이다. 일부 신경망에는 출력 계층 외에 하나 이상의 은닉 계층이 포함되어 있다. 각 은닉 계층의 출력은 네트워크의 다음 계층, 즉 다음 은닉 계층이나 출력 계층의 입력으로 사용된다. 네트워크의 각 계층은 개별 파라미터 세트의 현재 값에 따라 수신된 입력으로부터 출력을 생성한다.A neural network is a machine learning model that uses one or more layers of non-linear units to predict an output for received input. Some neural networks include one or more hidden layers in addition to the output layer. The output of each hidden layer is used as input to the next layer of the network, that is, the next hidden layer or output layer. Each layer of the network generates an output from the input received according to the current values of the individual parameter sets.
보다 구체적으로, 각 신경망 계층은 복수의 노드를 포함하고, 각 계층은 신경망에 의해 정의된 일련의 연산을 나타낸다. 일반적으로, 이러한 연산은 덧셈 및 곱셈과 같은 선형 연산과 "Relu" 또는 "시그모이드(Sigmoid)" 함수와 같은 비선형 활성화 함수와 같은 비선형 연산을 포함할 수 있는 산술 연산이다. 선형 연산은 계층 입력과 계층의 가중치를 결합한다. 각 계층에 대한 선형 연산은 텐서 연산을 사용하여 구현할 수 있으며, 여기서 계층의 가중치는 행렬 또는 텐서 형식으로 표시되고 해당 계층에 대한 계층 입력은 벡터 형식으로 표시된다.More specifically, each neural network layer includes a plurality of nodes, and each layer represents a series of operations defined by the neural network. Typically, these operations are arithmetic operations that may include linear operations such as addition and multiplication and non-linear operations such as non-linear activation functions such as the “Relu” or “Sigmoid” functions. Linear operations combine the layer input and the layer's weights. Linear operations for each layer can be implemented using tensor operations, where the weights of the layer are represented in matrix or tensor form and the layer inputs for that layer are expressed in vector form.
대규모 신경망, 즉 많은 계층과 많은 수의 파라미터를 가진 신경망은 다양한 기계 학습 태스크에서 좋은 성능을 보여왔다. 그러나, 이러한 대규모 신경망은 대기 시간이 길고 계산 리소스를 많이 소비할 수 있는데, 예를 들어 메모리 요구 사항이 크고 예측을 위해 상당한 수의 프로세서 주기를 소비한다. 신경망의 계산 효율성을 높이기 위한 기존 기술 중 하나는 가중치 행렬 중 일부를 희소 행렬로 조작하는 것이다. 희소 행렬은 많은 수의 항이 0인 행렬이다.Large-scale neural networks, that is, neural networks with many layers and a large number of parameters, have shown good performance in a variety of machine learning tasks. However, these large-scale neural networks can have high latency and consume a lot of computational resources, for example, they have large memory requirements and consume a significant number of processor cycles for prediction. One of the existing techniques to increase the computational efficiency of neural networks is to manipulate some of the weight matrices into sparse matrices. A sparse matrix is a matrix in which a large number of terms are 0.
본 명세서는 새로운 기계 학습 모델을 생성하기 위해 대규모 신경망에 의사결정 트리를 통합하는 기술에 대해 설명한다.This specification describes techniques for integrating decision trees into large-scale neural networks to create new machine learning models.
일반적으로, 본 명세서에 설명된 주제의 혁신적인 일 양태는 시퀀스로 배열된 복수의 계층을 포함하는 신경망을 나타내는 데이터를 수신하는 단계와, 복수의 계층으로부터 서로 인접한 하나 이상의 계층을 각각 포함하는 하나 이상의 계층 그룹을 선택하는 단계와, 신경망에 해당하는 새로운 기계 학습 모델을 생성하는 단계의 동작들을 포함하는 방법으로 구현될 수 있다.In general, an innovative aspect of the subject matter described herein includes receiving data representative of a neural network comprising a plurality of layers arranged in a sequence, and one or more layers each comprising one or more layers adjacent to each other from the plurality of layers. It can be implemented in a way that includes the steps of selecting a group and creating a new machine learning model corresponding to a neural network.
새로운 기계 학습 모델의 생성에는 각 계층 그룹에 대해, 계층 그룹을 대체하는 개별 의사결정 트리를 선택하는 단계가 포함된다. 개별 의사결정 트리는 입력으로 그룹내의 각각의 첫 번째 계층에 대한 입력의 양자화(된) 버전을 수신하고 출력으로 그룹내의 각각의 마지막 계층의 출력의 양자화 버전을 생성한다. 개별 의사결정 트리의 트리 깊이는 그룹의 계층 수에 적어도 부분적으로 기초한다.Creating a new machine learning model involves selecting, for each layer group, an individual decision tree that replaces the layer group. Each decision tree receives as input a quantized (quantized) version of the input for each first layer in the group and produces as output a quantized version of the output of each last layer in the group. The tree depth of an individual decision tree is based at least in part on the number of layers in the group.
이 양태의 다른 실시예는 대응하는 컴퓨터 시스템, 장치, 및 하나 이상의 컴퓨터 저장 디바이스에 기록된 컴퓨터 프로그램을 포함하며, 각각은 방법의 동작들을 수행하도록 구성된다.Another embodiment of this aspect includes a corresponding computer system, apparatus, and computer program recorded on one or more computer storage devices, each configured to perform the operations of the method.
전술한 실시예와 다른 실시예는 각각 선택적으로 다음 특징들 중 하나 이상을 단독으로 또는 조합하여 포함할 수 있다. 특히, 일 실시예는 다음의 모든 특징을 조합하여 포함한다.The above-described embodiments and other embodiments may each optionally include one or more of the following features alone or in combination. In particular, one embodiment includes a combination of all of the following features.
방법은 신경망에 대한 트레이닝 데이터에 기초하여, 개별 의사 의사결정 트리에 의해 대체되지 않은 신경망의 계층들 중 적어도 일부를 트레이닝함으로써 새로운 기계 학습 모델을 트레이닝하는 단계의 동작을 더 포함할 수 있다.The method may further include training a new machine learning model based on the training data for the neural network by training at least some of the layers of the neural network that have not been replaced by the individual decision tree.
위에서 논의된 바와 같이 하나 이상의 계층 그룹 각각을 선택하는 단계의 동작은, 신경망에서 개별 초기 계층을 선택하는 단계와; 각각이 후보 그룹의 첫 번째 계층으로서 개별 초기 계층을 갖는 각각의 복수의 후보 그룹을 생성하는 단계와; 각각의 복수의 후보 그룹 각각에 대해, 후보 그룹의 계층이 개별 의사결정 트리에 의해 대체된 대응하는 새로운 기계 학습 모델의 성능을 측정하는 후보 그룹에 대한 개별 성능 측정치를 결정하는 단계와; 그리고 그룹으로서, 각각의 복수의 후보 그룹에 대한 개별 성능 측정치에 기초하여 후보 그룹 중 하나를 선택하는 단계의 동작을 포함한다. The operation of selecting each of one or more groups of layers as discussed above includes selecting individual initial layers in the neural network; generating a plurality of candidate groups, each having a respective initial layer as the first layer of the candidate group; For each of the plurality of candidate groups, determining an individual performance measure for the candidate group that measures the performance of a corresponding new machine learning model whose hierarchy of candidate groups has been replaced by an individual decision tree; and selecting, as a group, one of the candidate groups based on individual performance measurements for each of the plurality of candidate groups.
각각의 초기 계층의 선택은 랜덤 프로세스에 의해 구현될 수도 있고, 신경망의 시퀀스에 기초하여 구현될 수 있다.The selection of each initial layer may be implemented by a random process or based on a sequence of a neural network.
그룹 내의 각각의 첫 번째 계층에 대한 입력의 양자화 버전 및 그룹 내의 각각의 마지막 계층의 출력의 양자화 버전은 이진 또는 삼진 양자화를 사용하여 생성될 수 있다.The quantized version of the input for each first layer in the group and the quantized version of the output of each last layer in the group can be generated using binary or ternary quantization.
계층 그룹을 대체하는 개별 의사결정 트리 계층은 GradientBoost 의사결정 트리 또는 AdaBoost 의사결정 트리를 포함할 수 있다.Individual decision tree layers that replace groups of layers may include GradientBoost decision trees or AdaBoost decision trees.
방버은 새로운 기계 학습 모델을 구현하도록 구성된 시스템에 새로운 기계 학습 모델을 출력하는 단계를 더 포함할 수 있으며, 시스템은 추가(add), 선택 또는 전환(switch) 기능으로부터 선택된 하나 이상의 기능을 통해 의사결정 트리를 구현하기 위한 하나 이상의 컴퓨팅 유닛을 포함한다. 즉, (예를 들어 트레이닝된) 새로운 기계 학습 모델은 곱셈을 수행하기 위해 곱셈 누산기 유닛(MAC)와 같은 더 비싼 계산 유닛을 요구하지 않고 의사결정 트리를 구현하기 위한 하나 이상의 컴퓨팅 유닛(예를 들어 멀티플렉서 또는 산술 논리 유닛)을 포함하는 시스템으로 출력될 수 있다.The method may further include outputting the new machine learning model to a system configured to implement the new machine learning model, wherein the system makes a decision through one or more functions selected from the add, select, or switch functions. Contains one or more computing units to implement the tree. This means that a new machine learning model (trained for example) does not require more expensive computational units such as a multiply accumulator unit (MAC) to perform the multiplication, but rather requires one or more computational units to implement the decision tree (e.g. The output may be a system including a multiplexer or an arithmetic logic unit).
본 명세서에 설명된 주제는 다음 장점 중 하나 이상을 실현하기 위해 특정 실시예에서 구현될 수 있다.The subject matter described herein may be implemented in certain embodiments to realize one or more of the following advantages.
아래에 설명된 기술을 구현하는 설명된 시스템은 대규모 신경망에 대한 추론 계산을 수행하기 위한 계산 비용을 줄이고 효율성을 높일 수 있다.The described system, which implements the techniques described below, can reduce computational cost and increase efficiency for performing inference calculations for large-scale neural networks.
첫째, 대규모 신경망의 하나 이상의 네트워크 계층을 의사 의사결정 트리로 대체하기 위한 설명된 기술은 시스템이 신경망에 대한 추론 계산을 수행할 때 연산량을 줄일 수 있다. 예를 들어 신경망의 하나 이상의 계층을 대체하는 의사결정 트리는 하나 또는 두 개의 계층(예를 들어, 나무 그루터기 또는 얕은 나무)만 가질 수 있다. 나무 그루터기와 얕은 나무에 대한 연산을 수행하는데 드는 계산 비용은 대규모 신경망의 신경망 계층을 계산하는데 필요한 비용보다 훨씬 적다. 다른 예로서, 의사결정 트리가 Adaboost 트리인 경우, Adaboost 트리에 대해 곱셈 연산이 수행될 필요가 없으므로 시스템은 일반적으로 곱셈과 덧셈이 모두 필요한 기존 신경망 계층을 계산하는 것보다 더 적은 연산을 수행하고 효율성을 향상시킬 수 있다.First, the described technique for replacing one or more network layers of a large-scale neural network with a decision tree can reduce the amount of computation when the system performs inferential calculations for the neural network. For example, a decision tree that replaces one or more layers of a neural network may have only one or two layers (e.g., a tree stump or a shallow tree). The computational cost of performing operations on tree stumps and shallow trees is much less than that required to compute the neural network layers of a large-scale neural network. As another example, if the decision tree is an Adaboost tree, no multiplication operations need to be performed on the Adaboost tree, so the system typically performs fewer operations and is less efficient than computing a traditional neural network layer that requires both multiplication and addition. can be improved.
둘째, 설명된 기술은 하나 이상의 의사결정 트리에 의해 대체되는 네트워크 계층에 대한 적어도 입력 및 출력을 양자화함으로써 신경망의 전체 크기를 줄일 수 있다. 컴퓨팅에 더 적은 수의 유효 자릿수를 포함하도록 이러한 입력 및 출력을 양자화하면 특히 삽입된 의사결정 트리와 적어도 의사결정 트리 옆의 신경망 레이어(즉, 의사결정 트리의 이전 또는 후속 계층)에 대해 계산 비용을 줄일 수 있다. 양자화는 또한 신경망의 크기가 양자화에 의해 줄어들기 때문에 컴퓨팅 시스템의 총 메모리/스토리지 요구 사항을 줄일 수 있다. 이를 고려할 때, 설명된 기술을 사용하면 더 작은 메모리와 계산 능력을 갖춘 디바이스(예를 들어, 스마트폰, 태블릿)가 수정된 신경망의 추론 계산을 효율적으로 수행할 수 있다. 일부 상황에서, 특정 수정된 신경망의 추론 계산을 수행하기 위한 디바이스의 하나 이상의 하드웨어 가속기가 커스터마이즈될 수 있으며(즉, 하나 이상의 계층이 하나 이상의 의사결정 트리로 대체되었으며 하나 이상의 계층 입력 및 출력이 양자화됨), 이는 디바이스의 사용량을 줄이고, 전력 소비를 줄이며, 추론 계산을 보다 효율적이고 빠르게 수행할 수 있다.Second, the described technique can reduce the overall size of a neural network by quantizing at least the inputs and outputs to the network layers, which are replaced by one or more decision trees. Quantizing these inputs and outputs to involve fewer significant digits to compute reduces computational cost, especially for the embedded decision tree and at least the neural network layer next to the decision tree (i.e., the previous or subsequent layer of the decision tree). It can be reduced. Quantization can also reduce the total memory/storage requirements of a computing system because the size of the neural network is reduced by quantization. Considering this, the described technique allows devices with smaller memory and computational power (e.g., smartphones, tablets) to efficiently perform the inferential computations of the modified neural network. In some situations, one or more hardware accelerators on the device may be customized to perform inferential computations of a particular modified neural network (i.e., one or more layers have been replaced with one or more decision trees and one or more layer inputs and outputs are quantized). ), which can reduce device usage, reduce power consumption, and perform inference calculations more efficiently and quickly.
추가적으로, 종종 양자화되지 않은 입력 및 출력에 의해 제공되는 더 높은 정밀도는 신경망에 대한 추론 계산을 수행할 때 중요한 특징의 존재나 부재를 정확하게 감지하고 표현하는데 필요하지 않다. 즉, 의사결정 트리에 의해 대체된 계층들에 대한 입력과 출력을 양자화함으로써 발생하는 오류는 효율성 향상에 비해 최소화된다.Additionally, the higher precision provided by unquantized inputs and outputs is often not necessary to accurately detect and represent the presence or absence of important features when performing inferential computations for neural networks. In other words, the errors that occur by quantizing the input and output of the layers replaced by the decision tree are minimized compared to the efficiency improvement.
실제로는 신경망 트레이닝과 컴퓨팅을 위한 양자화된 데이터가 사용되어 왔지만, 개별(respective) 의사결정 트리와 나머지 신경망 계층에 적합하도록 입력과 출력을 양자화하는 것은 아래 설명된 기술에 중요하다. 보다 구체적으로, 시스템은 부동 소수점 숫자를 양자화하여 부동 소수점 숫자를 나타내는 자릿수를 줄일 수 있으므로 시스템은 부동 소수점 숫자의 부호, 지수 및 가수(mantissa)에 대해 더 적은 자릿수를 사용할 수 있다. 이진 양자화 및 삼진(ternary) 양자화의 경우, 시스템은 몇가지 예를 들면 부동 소수점을 {1, -1} 또는 {1, 0, -1}과 같은 정수로 매핑할 수 있다.Although quantized data has been used in practice for neural network training and computing, quantizing inputs and outputs to suit individual (respective) decision trees and the remaining neural network layers is critical to the techniques described below. More specifically, a system can quantize a floating-point number to reduce the number of digits representing the floating-point number, so the system can use fewer digits for the sign, exponent, and mantissa of the floating-point number. For binary quantization and ternary quantization, the system can map floating point numbers to integers such as {1, -1} or {1, 0, -1}, to name a few.
또한, 설명된 기술은 수정된 신경망(즉, 의사결정 트리에 의해 대체되는 계층들이 있는 새로운 신경망)을 효율적으로 트레이닝할 수 있다. 시스템은 원래 신경망을 트레이닝하기 위한 동일한 트레이닝 예제 중 적어도 일부를 사용하여 수정된 신경망의 파라미터를 미세 조정하기만 하면 된다. 따라서, 수정된 신경망을 트레이닝하는데 필요한 시간은 원래 신경망을 트레이닝하는 것보다 훨씬 짧을 수 있다.Additionally, the described technique can efficiently train modified neural networks (i.e., new neural networks whose layers are replaced by decision trees). The system only needs to fine-tune the parameters of the modified neural network using at least some of the same training examples for training the original neural network. Therefore, the time required to train a modified neural network can be much shorter than training the original neural network.
더욱이, 설명된 기술은 의사결정 트리 작업을 수행하기 위해 저비용 프로그래밍 가능 하드웨어를 사용하여 비용을 절감할 수 있다. 예를 들어, 컴퓨팅 시스템은 곱셈 누산기 유닛(MAC) 대신 멀티플렉서(MUX) 유닛을 사용하여 의사결정 트리의 연산을 계산할 수 있다. MUX 유닛이 MAC 유닛보다 전력과 공간을 덜 소비한다는 것은 당업자에게 알려져 있다. 따라서, 컴퓨팅 시스템에는 GPU나 TPU와 같은 고가의 하드웨어 가속기가 아닌 수정된 신경망에 적합한 프로그래밍 가능한 하드웨어 유닛만 포함될 수 있다. 따라서 수정된 신경망에 대한 추론 계산을 수행하기 위한 하드웨어 시스템을 구축하는데 드는 총 비용은 원래 신경망의 비용보다 훨씬 적다.Moreover, the described technique can reduce costs by using low-cost programmable hardware to perform decision tree operations. For example, a computing system may use a multiplexer (MUX) unit instead of a multiply accumulator unit (MAC) to compute the operations of a decision tree. It is known to those skilled in the art that MUX units consume less power and space than MAC units. Therefore, the computing system may only include programmable hardware units suitable for modified neural networks rather than expensive hardware accelerators such as GPUs or TPUs. Therefore, the total cost of building a hardware system to perform inference calculations for a modified neural network is much less than the cost of the original neural network.
본 명세서의 주제에 대한 하나 이상의 실시예의 세부사항은 첨부 도면 및 아래 설명에서 설명된다. 주제의 다른 특징, 측면 및 이점은 설명, 도면 및 청구범위로부터 명백해질 것이다.The details of one or more embodiments of the subject matter herein are set forth in the accompanying drawings and the description below. Other features, aspects and advantages of the subject matter will become apparent from the description, drawings and claims.
도 1은 예시적인 신경망 수정 엔진을 포함하는 예시적인 신경망 배치 시스템을 도시한다.
도 2a는 이진 양자화 출력을 갖는 의사결정 트리를 갖는 예시적인 새로운 기계 학습 모델의 일부를 도시한다.
도 2b는 삼진 양자화 출력을 갖는 의사결정 트리를 갖는 다른 예시적인 새로운 기계 학습 모델의 일부를 도시한다.
도 3은 트레이닝된 새로운 기계 학습 모델을 생성하기 위한 예시적인 프로세스의 흐름도이다.
도 4는 신경망 계층의 하나 이상의 그룹을 선택하기 위한 예시적인 프로세스의 흐름도이다.
도 5는 의사결정 트리의 예를 도시한다.
도 6은 고정 기능 하드웨어를 사용하는 의사결정 트리의 예시적인 구현을 도시한다.
도 7은 의사결정 트리에 대한 추론 계산을 수행하기 위한 예시적인 프로그램 가능 코어를 도시한다.
다양한 도면에서 유사한 참조 번호 및 지정은 유사한 요소를 나타냅니다.1 illustrates an example neural network deployment system including an example neural network modification engine.
2A shows a portion of an example new machine learning model with a decision tree with binary quantized output.
2B shows part of another example new machine learning model with a decision tree with ternary quantized output.
3 is a flow diagram of an example process for creating a new trained machine learning model.
4 is a flow diagram of an example process for selecting one or more groups of neural network layers.
Figure 5 shows an example of a decision tree.
Figure 6 shows an example implementation of a decision tree using fixed function hardware.
7 shows an example programmable core for performing inferential computations for a decision tree.
Similar reference numbers and designations in the various drawings indicate similar elements.
대규모 신경망을 트레이닝하고 계산하는데 효율성을 높이기 위한 기존 접근 방식 중 하나는 각 계층의 활성화 입력 및 가중치에 대해 개별 희소 행렬을 구성하는 것이다. 그러나, 희소 행렬을 구성하는 접근 방식은 새로운 문제를 일으킬 수 있다. 예를 들어, 희소 행렬을 사용하면 컴퓨팅 시스템이 일정 기간 동안 동일한 메모리 주소에 액세스하지 못하게 될 수 있으며, 이는 추론 지역성이 부족한 것으로도 지칭된다. 보다 구체적으로, 희소 행렬을 구성할 때, 컴퓨팅 시스템은 물리적으로 서로 멀리 떨어져 있을 수 있는 서로 다른 메모리 주소에 원래 행렬의 0이 아닌 항을 저장한다. 일부 상황에서, 희소 행렬의 각 항에 대한 메모리 주소는 계산 중에 동적으로 변경될 수 있다. 예를 들어, 0항은 0이 아닌 다른 항을 가산한 후 0이 아닌 값이 될 수 있다. 따라서 컴퓨팅 시스템은 메모리에 저장된 데이터에 액세스할 때 메모리 대기시간(latency), 캐시 폐기, 심지어 캐시 오염으로 인해 어려움을 겪을 수 있으며, 이는 결국 대규모 신경망을 사용하여 입력을 트레이닝하거나 처리하는 작업 효율성을 감소시킨다.One existing approach to increase efficiency in training and computing large-scale neural networks is to construct separate sparse matrices for the activation inputs and weights of each layer. However, this approach to constructing sparse matrices can cause new problems. For example, using sparse matrices can cause a computing system to not access the same memory address for a period of time, also referred to as lack of inference locality. More specifically, when constructing a sparse matrix, a computing system stores the nonzero terms of the original matrix at different memory addresses that may be physically distant from each other. In some situations, the memory address for each term of a sparse matrix may change dynamically during computation. For example, a zero term can become a non-zero value after adding another non-zero term. Therefore, computing systems may suffer from memory latency, cache abandonment, and even cache corruption when accessing data stored in memory, which ultimately reduces the operational efficiency of training or processing inputs using large-scale neural networks. I order it.
대안으로, 다른 기존 기술 접근 방식은 가중치 행렬을 계층 로직에 융합하는 것이다. 예를 들어, 가중치 융합 기법을 채택한 시스템은 가중치 행렬에서 0항을 결정할 수 있으므로 이 항에 대한 곱셈과 누산 연산을 수행하지 않는다. 이를 고려하면 융합 가중치 기술은 입력 중 하나가 0이기 때문에 0을 출력하는 임의의 계산을 수행하지 않음으로써 대규모 신경망의 계산 비용을 줄일 수 있다. 그러나 융합 가중치에는 대가가 따른다. 첫째, 가중치 융합 기술에서는 신경망이 하드웨어 가속기에 배포된 후에는 수정되지 않아야 한다. 즉, 가중치 행렬의 0항은 계산 동안 0으로 유지되어야 한다. 그러나, 실제로, 배포된 신경망의 가중치 행렬은 새로운 트레이닝 데이터를 사용하여 미세 조정되어야 할 수도 있다. 둘째, 희소 가중치 행렬내의 0항이 다수의 연산(예를 들어, 곱셈 다음에 덧셈이 뒤따르고 또 다른 곱셈이 뒤따름)에 의해 공유되는 경우, 시스템은 여전히 0항에 대한 연산을 수행해야 한다.Alternatively, another existing technical approach is to fuse the weight matrix into the hierarchical logic. For example, a system adopting the weight fusion technique can determine the 0 term in the weight matrix and therefore does not perform multiplication and accumulation operations on this term. Considering this, fusion weighting techniques can reduce the computational cost of large-scale neural networks by not performing arbitrary calculations that output 0 because one of the inputs is 0. However, fusion weights come at a cost. First, weight fusion techniques require that the neural network not be modified after it is deployed on the hardware accelerator. That is, the 0 term of the weight matrix must remain 0 during calculation. However, in practice, the weight matrix of the deployed neural network may need to be fine-tuned using new training data. Second, if the zero term in the sparse weight matrix is shared by multiple operations (e.g., a multiplication followed by an addition followed by another multiplication), the system still has to perform the operation on the zero term.
아래 명세서에 설명된 기술은 위에서 언급한 문제를 해결할 수 있다. 보다 구체적으로, 설명된 기술은 양자화 및 의사결정 트리를 사용하여 대규모 신경망에 대한 하나 이상의 추론 계산을 효율적으로 수행할 수 있다. 일반적으로, 설명된 기술은 신경망의 하나 이상의 계층을 개별 의사결정 트리로 대체하는 것과 관련되며, 의사결정 트리의 입력 및 출력은 해당 계층들에 대한 입력 및 출력의 양자화 버전이다.The technology described in the specification below can solve the problems mentioned above. More specifically, the described technique can efficiently perform one or more inference calculations for large-scale neural networks using quantization and decision trees. Generally, the techniques described involve replacing one or more layers of a neural network with individual decision trees, the inputs and outputs of which are quantized versions of the inputs and outputs for those layers.
본 명세서는 경제적인 하드웨어를 사용하여 추론 계산을 수행하기 위한 계산 비용을 줄이고 효율성을 향상시키기 위해 신경망의 하나 이상의 네트워크 계층 그룹을 하나 이상의 의사결정 트리로 대체함으로써 새로운 기계 학습 모델을 생성하는 하나 이상의 위치에 있는 하나 이상의 컴퓨터에 컴퓨터 프로그램으로 구현되는 시스템을 설명한다.This specification provides one or more positions for creating new machine learning models by replacing one or more groups of network layers in a neural network with one or more decision trees to reduce computational cost and improve efficiency for performing inference calculations using economical hardware. Describes a system implemented as a computer program on one or more computers.
도 1은 예시적인 신경망 수정 엔진(120)을 포함하는 예시적인 신경망 배치 시스템(100)을 도시한다.1 illustrates an example neural network deployment system 100 including an example neural network modification engine 120.
일반적으로, 신경망 배치 시스템(100)은 신경망(110)을 나타내는 데이터를 입력으로 수신하고 트레이닝된 새로운 기계 학습 모델(180)을 출력한다. 신경망 배치 시스템(100)은 입력 신경망 모델에 대한 새로운 기계 학습 모델(130)을 생성하기 위한 신경망 수정 엔진(120)을 포함한다. 새로운 기계 학습 모델(130)은 하나 이상의 의사결정 트리로 대체된 하나 이상의 신경망 계층을 갖는 원래 입력 신경망 모델의 하이브리드이다. 새로운 기계학습 모델(130)을 생성하는 구체적인 내용은 후술한다. 신경망 배치 시스템(100)은 또한 트레이닝 데이터(150)를 사용하여 새로운 기계 학습 모델을 트레이닝하도록 구성된 트레이닝 엔진(140)과, 트레이닝 엔진(140)을 위한 데이터(예를 들어, 기계 학습 모델을 위한 트레이닝 및 출력 데이터, 기계 학습 모델을 정의하는 데이터)를 저장하고 제공하도록 구성된 메모리(160)를 포함한다.In general, the neural network deployment system 100 receives data representing the neural network 110 as input and outputs a new trained machine learning model 180. The neural network deployment system 100 includes a neural network modification engine 120 for generating a new machine learning model 130 for the input neural network model. The new machine learning model 130 is a hybrid of the original input neural network model with one or more neural network layers replaced by one or more decision trees. The specific details of creating a new machine learning model 130 will be described later. Neural network deployment system 100 also includes a training engine 140 configured to use training data 150 to train a new machine learning model, and data for training engine 140 (e.g., training for a machine learning model). and a memory 160 configured to store and provide output data, data defining a machine learning model.
보다 구체적으로, 배치 시스템(100)에 의해 수신된 신경망(110)을 나타내는 데이터에는 신경망의 각 계층의 동작, 각 네트워크 계층에 대한 가중치와 같이 신경망을 정의하는 정보가 포함될 수 있다.More specifically, data representing the neural network 110 received by the deployment system 100 may include information defining the neural network, such as the operation of each layer of the neural network and weights for each network layer.
데이터(110)는 신경망의 다른 양태를 나타낼 수도 있다. 예를 들어, 데이터(110)에는 신경망 내의 다수의 네트워크 계층, 각 계층내의 개별 노드 수, 하나 이상의 계층간(inter-layer) 연결 유형(예를 들어, 요소별 연결 또는 전체 연결)을 나타내는 데이터, 및 신경망 내의 각 계층 유형(예를 들어, 풀링 계층, 완전 연결 계층 또는 SoftMax 계층)을 나타내는 데이터가 포함될 수 있다. Data 110 may also represent other aspects of a neural network. For example, data 110 may include data representing a number of network layers within a neural network, the number of individual nodes within each layer, one or more inter-layer connection types (e.g., element-by-element connection or overall connection); and data representing each type of layer within the neural network (e.g., pooling layer, fully connected layer, or SoftMax layer).
일반적으로, 데이터(110)는 복수의 트레이닝 데이터(150)에 대해 트레이닝된 트레이닝된 신경망 또는 아직 트레이닝되지 않은 신경망을 나타낼 수 있다.Generally, data 110 may represent a trained neural network that has been trained on a plurality of training data 150 or a neural network that has not yet been trained.
신경망 배치 시스템(100)은 수신된 데이터(110)를 신경망 수정 엔진(120)에 제공할 수 있다. 수정 엔진(120)은 신경망의 하나 이상의 계층 그룹을 선택하고, 각 계층 그룹을 개별 의사결정 트리로 대체하여 새로운 기계 학습 모델(130)을 출력할 수 있다. 하나 이상의 계층 그룹의 선택은 아래에서 더 자세히 설명된다.Neural network deployment system 100 may provide received data 110 to neural network modification engine 120. The modification engine 120 may output a new machine learning model 130 by selecting one or more hierarchical groups of the neural network and replacing each hierarchical group with an individual decision tree. The selection of one or more hierarchical groups is described in more detail below.
개별 계층 그룹을 대체하는 각각의 의사결정 트리는 메모리(160)에 저장될 수 있고 수정 엔진(120)에 대해 액세스 가능하다. 보다 구체적으로, 의사결정 트리를 나타내며 메모리(160)에 저장된 데이터는 노드의 총 개수(예를 들어, 루트 및 복수의 리프), 노드 간 연결성(예를 들어, 리프가 하나 이상의 다른 리프 연결되는 방법), 및 하나 이상의 노드 연산(예를 들어, 하나 이상의 노드에 대한 논리 비교)을 지정하는 데이터를 포함할 수 있다. Each decision tree replacing an individual hierarchical group may be stored in memory 160 and accessible to modification engine 120. More specifically, data representing a decision tree and stored in memory 160 may include the total number of nodes (e.g., a root and multiple leaves), the connectivity between nodes (e.g., how a leaf is connected to one or more other leaves), ), and data specifying one or more node operations (e.g., a logical comparison for one or more nodes).
수정 엔진(120)은 계층 그룹을 대체하기 위해 개별 의사결정 트리를 자동으로 결정할 수 있다. 대안적으로, 개별 계층 그룹을 대체하기 위한 의사결정 트리의 유형은 수정 엔진(120) 외부의 하나 이상의 컴퓨터에 의해 구현되는 컴퓨터 프로그램 또는 사용자에 의해 미리 결정될 수 있다. 의사결정 트리는 GradientBoost 트리 또는 AdaBoost 트리일 수 있다.Modification engine 120 may automatically determine individual decision trees to replace hierarchical groups. Alternatively, the type of decision tree for replacing individual hierarchical groups may be predetermined by a user or a computer program implemented by one or more computers external to modification engine 120. The decision tree can be a GradientBoost tree or an AdaBoost tree.
GradientBoost(또는 Gradient Boost) 트리는 하나 이상의 단순 예측 모델(예를 들어, 의사결정 트리)을 조합(예를 들어, 가중 합)하여 모델을 생성하는 기계 학습 방법인 기울기 부스팅(Gradient Boosting)을 통해 획득될 수 있다. AdaBoost (또는 적응적 부스팅)는 하나 이상의 단순 예측 모델(예를 들어, 의사결정 트리)을 적응적으로 결합하므로 트레이닝 중에 AdaBoost에 의해 생성된 트레이닝된 모델이 특정 입력에 대해 예측을 올바르게 생성할 가능성이 더 높도록 성능이 낮은 단순 예측 모델에 더 큰 가중치가 할당된다.GradientBoost (or Gradient Boost) trees may be obtained through gradient boosting, a machine learning method that generates a model by combining (e.g., weighted sum) one or more simple prediction models (e.g., decision trees). You can. AdaBoost (or adaptive boosting) adaptively combines one or more simple prediction models (e.g., decision trees), so that during training, the trained model produced by AdaBoost is more likely to produce predictions correctly for a particular input. A greater weight is assigned to simple prediction models with lower performance so that they are higher.
수정 엔진(120)은 또한 데이터(110)에 의해 표현되는 신경망의 적어도 일부를 양자화할 수 있다. 예를 들어, 수정 엔진(120)은 의사결정 트리에 의해 대체된 계층 그룹 중 첫 번째 계층에 대한 입력과 계층 그룹 중 마지막 계층로부터의 출력을 양자화할 수 있다. 대안적으로, 수정 엔진(120)은 각 계층의 입력과 출력이 양자화되도록 신경망 전체를 양자화할 수 있다. 더욱이, 수정 엔진(120)은 트레이닝 데이터(150)의 적어도 일부를 양자화할 수 있고, 양자화된 트레이닝 데이터를 사용하여 개별 의사결정 트리, 또는 새로운 기계 학습 모델(130)의 적어도 일부, 또는 둘 다를 트레이닝할 수 있다.Correction engine 120 may also quantize at least a portion of the neural network represented by data 110 . For example, the modification engine 120 may quantize the input to the first layer of the layer group replaced by the decision tree and the output from the last layer of the layer group. Alternatively, the correction engine 120 may quantize the entire neural network such that the input and output of each layer are quantized. Moreover, modification engine 120 may quantize at least a portion of training data 150 and use the quantized training data to train an individual decision tree, or at least a portion of a new machine learning model 130, or both. can do.
양자화는 큰 세트의 입력 값을 작은 세트의 출력 값으로 매핑하는 프로세스이며, 일반적으로 반올림(rounding) 및 잘림(truncation)에 사용된다. 보다 구체적으로, 양자화는 숫자 값의 정밀도를 줄이는데 사용될 수 있다. 예를 들어, 양자화는 부동 소수점 숫자의 정밀도를 32비트에서 8비트로 줄일 수 있다. 신경망의 맥락과 관련하여, 수정 엔진(120)은 활성화 텐서, 신경망 계층의 가중치 텐서, 또는 계층 출력을 8비트에서 4비트 또는 심지어 1비트(예를 들어, 가수에 대해 1비트)의 정밀도로 양자화할 수 있다. 양자화의 세부사항(예를 들어, 이진 양자화 및 삼진 양자화)은 도 2a 및 도 2b와 관련하여 설명될 것이다.Quantization is the process of mapping a large set of input values to a small set of output values, and is typically used for rounding and truncation. More specifically, quantization can be used to reduce the precision of numeric values. For example, quantization can reduce the precision of floating point numbers from 32 bits to 8 bits. In the context of a neural network, the modification engine 120 quantizes the activation tensor, the weight tensor of a neural network layer, or the layer output to a precision of 8 bits to 4 bits or even 1 bit (e.g., 1 bit for the mantissa). can do. Details of quantization (e.g., binary quantization and ternary quantization) will be described with respect to FIGS. 2A and 2B.
수정 엔진(120)은 새로운 기계 학습 모델(130)을 트레이닝 엔진(140)에 제공할 수 있다. 그런 다음 트레이닝 엔진(140)은 원래 신경망(110)을 트레이닝하는데 사용된 트레이닝 데이터(150)에 기초하여 새로운 기계 학습 모델(130)의 적어도 일부를 트레이닝하고 트레이닝된 새로운 기계 학습 모델(180)을 시스템(100)의 출력으로 출력할 수 있다. 보다 구체적으로, 트레이닝 엔진(140)은 트레이닝 데이터(150)를 이용하여 일정 기간 동안 의사결정 트리에 의해 대체되지 않은 신경망의 나머지 계층들을 트레이닝할 수 있다. 대안적으로 또는 추가적으로, 트레이닝 엔진(140)은 각 의사결정 트리에 대한 개별 기울기를 가정하여 양자화된 트레이닝 데이터에 기초하여 전체 새로운 기계 학습 모델(130)을 트레이닝할 수 있다.Modification engine 120 may provide a new machine learning model 130 to training engine 140. The training engine 140 then trains at least a portion of the new machine learning model 130 based on the training data 150 used to train the original neural network 110 and generates the trained new machine learning model 180 into the system. It can be output as an output of (100). More specifically, the training engine 140 may use the training data 150 to train the remaining layers of the neural network that have not been replaced by the decision tree for a certain period of time. Alternatively or additionally, training engine 140 may train an entire new machine learning model 130 based on the quantized training data assuming individual gradients for each decision tree.
새로운 기계 학습 모델(130)을 트레이닝하는 기간은 몇 분, 몇 시간 또는 몇일일 수 있다. 대안적으로 또는 추가적으로, 기간은 새로운 기계 학습 모델(130)의 적어도 일부를 트레이닝하는데 사용되는 트레이닝 데이터(150)의 크기에 기초할 수 있다. 예를 들어, 기간은 트레이닝 데이터(150)의 100개의 미니 배치(batch) 또는 1000개의 미니 배치를 사용하여 새로운 기계 학습 모델(130)을 트레이닝(예를 들어, 미세 조정)하는데 필요한 시간에 의해 결정될 수 있다.The period of training a new machine learning model 130 may be minutes, hours, or days. Alternatively or additionally, the time period may be based on the size of the training data 150 used to train at least a portion of the new machine learning model 130. For example, the duration may be determined by the time required to train (e.g., fine-tune) a new machine learning model 130 using 100 mini-batches or 1000 mini-batches of training data 150. You can.
트레이닝 엔진(140)은 원래 신경망의 하나 이상의 계층을 대체하는 의사결정 트리를 트레이닝할 수 있다.Training engine 140 may train a decision tree that replaces one or more layers of the original neural network.
보다 구체적으로, 트레이닝 엔진(140)은 원래 신경망의 네트워크 계층을 의사결정 트리로 대체하기 전에 의사결정 트리를 트레이닝한다. 트레이닝 엔진(140)은 또한 전술한 바와 같이 새로운 기계 학습 모델(130)의 의사결정 트리를 미세 조정할 수 있다.More specifically, training engine 140 trains a decision tree before replacing the network layer of the original neural network with a decision tree. Training engine 140 may also fine-tune the decision tree of new machine learning model 130 as described above.
의사결정 트리를 트레이닝하기 위해, 트레이닝 엔진(140)은 원래 신경망을 트레이닝하기 위해 동일하지만 양자화된 트레이닝 데이터(150)의 대응 부분을 트레이닝 데이터로서 사용할 수 있다. 구체적으로, 트레이닝 엔진(140)은 개별 트레이닝 샘플을 이용하여 의사결정 트리를 트레이닝한다. 개별 트레이닝 예에는 계층 그룹의 첫 번째 계층에 대한 계층 입력의 양자화 버전과 계층 그룹의 마지막 계층로부터의 계층 출력의 양자화 버전을 포함한다. 계층 그룹은 의사결정 트리에 의해 대체된다. 계층 입력 및 출력의 양자화(된) 버전은 원래 신경망에서 계층 그룹을 트레이닝하는데 사용되었던 대응하는 트레이닝 데이터(150)에 대한 계층 입력 및 출력과 연관된다.To train the decision tree, training engine 140 may use as training data a corresponding portion of the same but quantized training data 150 to train the original neural network. Specifically, the training engine 140 trains a decision tree using individual training samples. Individual training examples include a quantized version of the layer input for the first layer in the layer group and a quantized version of the layer output from the last layer in the layer group. Hierarchical groups are replaced by decision trees. Quantized (quantized) versions of the layer inputs and outputs are associated with the layer inputs and outputs to the corresponding training data 150 that were originally used to train groups of layers in the neural network.
트레이닝 엔진(140)은 의사결정 트리를 트레이닝할 때 손실을 정의하고 손실이 특정 기준 아래에 도달할 때까지 손실을 줄이기 위해 노드 연산을 조정할 수 있다. 손실은 잘못된 라벨링(mislabeling)을 지정하는 힌지 손실, 엔트로피 이론에 기초한 정보 이득을 나타내는 로그 손실, 또는 의사결정 트리를 트레이닝하기 위한 기타 적절한 손실일 수 있다. 트레이닝 엔진(140)은 하나 이상의 노드 상의 논리 비교 연산에 대한 각각의 임계값과 같은 노드 연산을 조정할 수 있다. 일부 상황에서, 트레이닝 엔진(140)은 트레이닝 동안 의사결정 트리를 가지치기(pruning)함으로써, 즉 하나 이상의 리프(leaf)와 그 하나 이상의 리프와 연관된 모든 분기 및 자식 리프들을 삭제함으로써 과적합(overfitting)을 줄일 수 있다. 트레이닝 엔진(140)은 과적합을 검출하고 개선하기 위한 검증 세트로서 원본 트레이닝 데이터 세트의 일부를 남겨둘 수 있다.Training engine 140 may define a loss when training a decision tree and adjust node operations to reduce the loss until the loss reaches below a certain criterion. The loss may be a hinge loss that specifies mislabeling, a logarithmic loss that represents information gain based on entropy theory, or any other suitable loss for training a decision tree. Training engine 140 may adjust node operations, such as respective thresholds for logical comparison operations on one or more nodes. In some situations, training engine 140 overfits the decision tree by pruning it during training, i.e., deleting one or more leaves and all branches and child leaves associated with that one or more leaves. can be reduced. The training engine 140 may retain a portion of the original training data set as a validation set to detect and improve overfitting.
새로운 기계 학습 모델(130)의 적어도 일부를 트레이닝하는데 사용되는 트레이닝 엔진(140)은 중앙 처리 유밋(CPU), 그래픽 처리 유닛(GPU), 텐서 처리 유닛(TPU) 또는 신경망 연산을 수행하는데 적합한 기타 컴퓨팅 유닛이 포함될 수 있다. 특히, 새로운 기계 학습 모델에는 선형 연산(예를 들어, 대부분 텐서 연산)을 포함하여 대체되지 않은 계층이 여전히 있을 수 있으므로, 트레이닝 엔진(140)은 트레이닝 프로세스를 용이하게 하기 위해 CPU 또는 GPU보다 더 많은 TPU를 포함할 수 있다.The training engine 140 used to train at least a portion of the new machine learning model 130 may be a central processing unit (CPU), a graphics processing unit (GPU), a tensor processing unit (TPU), or other computing power suitable for performing neural network operations. Units may be included. In particular, since a new machine learning model may still have unreplaced layers containing linear operations (e.g., mostly tensor operations), the training engine 140 may have more than a CPU or GPU to facilitate the training process. May include TPU.
트레이닝된 새로운 기계 학습 모델(180)은 입력이 주어지면 추론을 효율적으로 생성하는데 사용될 수 있다. 트레이닝된 새로운 기계 학습 모델(180)은 더 적은 계산 능력을 사용하여 추론을 생성하는데 사용될 수 있다. 예를 들어, 트레이닝된 새로운 기계 학습 모델(180)은 원래 신경망의 메모리 크기보다 저장하는데 더 적은 메모리 크기가 필요한데, 그 이유는 신경망 계층들 중 하나 이상의 계층이 더 적은 수의 노드를 가진 얕은 의사 의사결정 트리로 대체되었기 때문이다. 다른 예로, 트레이닝된 새로운 기계 학습 모델은 더 적은 비트를 사용하여 표현되는 양자화된 입력 및 출력과 호환되므로 계산 중에 시스템 메모리 대역폭이 줄어든다. 더욱이, MUX 유닛 또는 산술 논리(ALC) 유닛과 같은 컴퓨팅 유닛을 사용하여 의사결정 트리에서 연산을 수행할 수 있기 때문에, 신경망 추론 엔진 또는 시스템은 새로운 기계 학습 모델(180)의 의사결정 트리에 대한 추론 계산을 수행하기 위해 TPU 또는 GPU와 같은 크고 값비싼 컴퓨팅 유닛을 하나 이상의 MUX 유닛 또는 ALC 유닛을 갖춘 더 작고 저렴한 프로그램 가능 코어로 대체할 수 있다. 따라서 새로운 기계 학습 모델에 대한 추론을 생성하기 위해 디바이스에 대한 총 비용과 총 크기가 줄어들 수 있다.The new trained machine learning model 180 can be used to efficiently generate inferences given the input. The new trained machine learning model 180 can be used to generate inferences using less computational power. For example, a new trained machine learning model 180 may require less memory size to store than the memory size of the original neural network because one or more of the neural network layers may be shallower with fewer nodes. This is because it has been replaced by decision trees. As another example, a new trained machine learning model is compatible with quantized inputs and outputs that are represented using fewer bits, thus reducing system memory bandwidth during computation. Moreover, because computing units such as MUX units or arithmetic logic (ALC) units can be used to perform operations on decision trees, a neural network inference engine or system can provide inference on decision trees in new machine learning models 180. To perform computations, large, expensive compute units such as TPUs or GPUs can be replaced by smaller, less expensive programmable cores equipped with one or more MUX units or ALC units. This can reduce the total cost and total size of devices to generate inference for new machine learning models.
도 2a는 이진 양자화 출력(225)을 갖는 의사결정 트리를 갖는 예시적인 새로운 기계 학습 모델(295)의 일부를 도시한다.2A shows a portion of an example new machine learning model 295 with a decision tree with binary quantized output 225.
도 2a에 도시된 바와 같이, 입력 데이터(110)에 의해 표현된 원래 신경망(200)의 일부는 복수의 네트워크 계층을 포함한다. 복수의 네트워크 계층은 대응하는 의사결정 트리에 의해 대체되도록 시스템(100)에 의해 결정된 네트워크 계층 그룹(290), 네트워크 계층 그룹(290)의 첫 번째 계층을 선행하는 제1 네트워크 계층(210), 및 네트워크 계층 그룹의 마지막 계층을 후속하는(succeeding) 제2 네트워크 계층(230)을 포함할 수 있다.As shown in Figure 2A, the portion of the original neural network 200 represented by input data 110 includes a plurality of network layers. The plurality of network layers includes a network layer group 290 determined by system 100 to be replaced by a corresponding decision tree, a first network layer 210 preceding the first layer of network layer group 290, and It may include a second network layer 230 succeeding the last layer of the network layer group.
신경망(200)의 일부에 있는 복수의 계층 중 각 계층은 각각 선형 및 비선형 연산을 나타내는 다중 노드를 갖는다. 예를 들어, 네트워크 계층(210)은 노드(210a-f)를 포함한다. 다른 예로서, 네트워크 계층(230)은 노드(230a-230f)를 포함한다. 또한, 네트워크 계층 그룹(290)의 각 계층은 개별 개수의 노드(미도시)를 포함한다.Among the plurality of layers in a portion of the neural network 200, each layer has multiple nodes representing linear and non-linear operations, respectively. For example, network layer 210 includes nodes 210a-f. As another example, network layer 230 includes nodes 230a-230f. Additionally, each layer of the network layer group 290 includes a separate number of nodes (not shown).
신경망(200)의 일부의 네트워크 계층은 신경망에 대한 각 입력에 대해 이전 계층이 계층 출력을 생성하고 해당 출력을 계층 활성화 입력으로서 다음 계층에 제공할 수 있도록 시퀀스에 따라 배치된다. 예를 들어, 네트워크 계층 그룹(290)의 첫 번째 계층은 네트워크 계층(210)으로부터 계층 활성화 입력(213)을 수신한다. 다른 예로서, 네트워크 계층 그룹(290)의 마지막 계층은 계층 출력(217)을 후속 계층(230)에 제공한다.The network layers of some of the neural network 200 are arranged according to a sequence such that for each input to the neural network, the previous layer produces a layer output and provides that output to the next layer as a layer activation input. For example, the first layer of network layer group 290 receives layer activation input 213 from network layer 210. As another example, the last layer of the network layer group 290 provides layer output 217 to the subsequent layer 230.
입력과 출력은 계산 요구 사항에 따라 각각의 정밀도를 가질 수 있다. 예를 들어, 입력 및 출력은 32비트 정밀도의 부동 소수점 형식을 가질 수 있다. 또 다른 예로, 신경망의 처음 몇 개 계층의 입력과 마지막 몇 개의 계층의 출력은 중간 계층보다 더 높은 정밀도를 가질 수 있다.Input and output can have respective precisions depending on computational requirements. For example, inputs and outputs can have floating point format with 32-bit precision. As another example, the input of the first few layers of a neural network and the output of the last few layers may have higher precision than the middle layers.
일부 구현에서, 시스템(100)은 다양한 양자화 방법을 사용하여 정밀도를 감소시키기 위해 신경망의 하나 이상의 계층의 입력 및 출력을 양자화할 수 있다. 예를 들어, 활성화 입력(213)과 계층 출력(217)은 이진 양자화 또는 삼진 양자화를 사용하여 양자화될 수 있으며 8비트 또는 심지어 1비트의 정밀도를 가질 수 있다. 대안적으로, 시스템(100)은 네트워크 계층에 입력된 가중치 또는 활성화의 일부만을 양자화할 수 있다.In some implementations, system 100 may quantize the input and output of one or more layers of a neural network to reduce precision using various quantization methods. For example, activation input 213 and layer output 217 may be quantized using binary quantization or ternary quantization and may have a precision of 8 bits or even 1 bit. Alternatively, system 100 may quantize only a portion of the weights or activations input to the network layer.
전술한 바와 같이, 양자화란 숫자 값의 정밀도를 감소시키는(예를 들어, 수치의 부호, 지수, 가수를 표현하기 위한 비트 수를 감소시키는) 프로세스이다. 이진 양자화와 삼진 양자화는 양자화 과정의 한 분야이다.As described above, quantization is a process that reduces the precision of a numeric value (e.g., reduces the number of bits for representing the sign, exponent, and mantissa of a numeric value). Binary quantization and ternary quantization are branches of the quantization process.
이진 양자화의 경우, 신경망 배치 시스템(100) 및 도 2A와 관련하여, 시스템(100)은 부동 소수점 숫자를 이진 집합 {1, -1}로 양자화할 수 있다. 이진 양자화는 시스템(100)이 부호에 대해 한 자리, 지수 거듭제곱에 대해 0 자리, 부동 소수점 숫자의 유효 숫자에 대해 한 자리만을 사용하는 특정 양자화 프로세스로 간주될 수 있다. 보다 구체적으로, 이진 양자화를 사용하면, 부동 소수점 형식 0.744의 가중치는 1로 양자화될 수 있고, 부동 소수점 형식 -0.21의 활성화 입력은 -1로 양자화될 수 있다.For binary quantization, with respect to neural network deployment system 100 and Figure 2A, system 100 may quantize floating point numbers into the binary set {1, -1}. Binary quantization can be considered a specific quantization process in which the system 100 uses only one digit for the sign, one digit for the power of the exponent, and one digit for the significant digits of a floating point number. More specifically, using binary quantization, a weight of floating point format 0.744 can be quantized to 1, and an activation input of floating point format -0.21 can be quantized to -1.
마찬가지로, 삼진 양자화는 이진 양자화의 대안으로 더 큰 모델 크기의 비용으로 더 높은 정확도를 허용한다. 도 2b와 관련하여, 시스템(100)은 부동 소수점 숫자를 삼진 집합 {1, 0, -1}로 양자화할 수 있다. 더 구체적으로, 0.66보다 큰 부동 소수점 형식의 정규화된 가중치는 1로 양자화될 수 있고, 0.66보다 작고 -0.66보다 큰 다른 정규화된 가중치는 0으로 양자화될 수 있으며, -0.66보다 작은 또 다른 정규화된 가중치는 -1로 양자화될 수 있다.Likewise, ternary quantization is an alternative to binary quantization, allowing higher accuracy at the cost of larger model size. 2B, system 100 may quantize floating point numbers into the ternary set {1, 0, -1}. More specifically, a normalized weight in floating point format greater than 0.66 may be quantized to 1, another normalized weight less than 0.66 and greater than -0.66 may be quantized to 0, and another normalized weight less than -0.66 can be quantized to -1.
시스템(100)은 각각의 양자화된 입력 또는 출력에 개별 스케일링 인자를 곱함으로써 각각의 양자화된 입력 및 출력에 개별 스케일링 인자를 적용할 수 있다. 시스템(100)은 특정 입력이 주어지면 양자화된 신경망과 양자화되지 않은 원래의 신경망 사이의 근사치(또는 유사성) 측정에 기초하여 각각의 스케일링 인자를 획득할 수 있다. 시스템(100)은 수정된 신경망을 트레이닝한 후 스케일링 인자를 결정하고, 수정된 신경망에 대한 추론 계산을 수행할 때 이를 상수로 설정할 수 있다.System 100 may apply a separate scaling factor to each quantized input or output by multiplying each quantized input or output by the respective scaling factor. System 100 may obtain each scaling factor based on a measure of approximation (or similarity) between the quantized neural network and the original, unquantized neural network, given a particular input. System 100 may determine a scaling factor after training the modified neural network and set it to a constant when performing inference calculations on the modified neural network.
도 2a를 다시 참조하면, 신경망 수정 엔진(120)은 신경망(200)의 원래 부분의 네트워크 계층 그룹(290)을 네트워크 계층 그룹(290)의 계층 수에 적어도 기초한 트리 깊이를 갖는 의사결정 트리(220)로 대체함으로써 새로운 기계 학습 모델(295)(또는 그의 새로운 부분)을 생성할 수 있다. 의사결정 트리는 네트워크 계층 그룹을 대체하는데 적합하다면 어떤 유형이든 될 수 있다. 예를 들어, 의사결정 트리는 GradientBoost 의사결정 트리 또는 AdaBoost 의사결정 트리일 수 있다.Referring back to FIG. 2A , the neural network modification engine 120 transforms the network layer group 290 of the original portion of the neural network 200 into a decision tree 220 with a tree depth based at least on the number of layers in the network layer group 290. ), thereby creating a new machine learning model 295 (or a new part thereof). Decision trees can be of any type as long as they are suitable for replacing groups of network layers. For example, the decision tree could be a GradientBoost decision tree or an AdaBoost decision tree.
시스템(100)은 적어도 네트워크 계층 그룹(290)의 첫 번째 계층에 대한 입력(213)과 네트워크 계층 그룹(290)의 마지막 계층으로부터의 출력(217)에 대해 이진 양자화를 수행할 수 있다. 대안적으로, 시스템(100)은 전체 신경망에 대해 이진 양자화를 수행한다.System 100 may perform binary quantization on at least an input 213 to a first layer of network layer group 290 and an output 217 from the last layer of network layer group 290. Alternatively, system 100 performs binary quantization on the entire neural network.
의사결정 트리(200)는 이전 계층(210)으로부터 이진 양자화된 입력(215)을 수신하고, 양자화된 출력(225)을 후속 계층(230)으로 출력할 수 있다. 보다 구체적으로, 양자화된 입력(215)은 이전 계층(210)의 노드(210a-f)로부터의 이진 입력(1 또는 -1)을 포함한다. 유사하게, 단지 예시의 목적으로, 양자화된 출력(225)은 {1}을 나타내는 출력(225a) 또는 {-1}을 나타내는 출력(225b)일 수 있다. 의사결정 트리의 각 출력은 1 또는 -1로 양자화되어 후속 계층(230)에 제공된다.The decision tree 200 may receive a binary quantized input 215 from the previous layer 210 and output a quantized output 225 to the subsequent layer 230. More specifically, quantized input 215 includes a binary input (1 or -1) from nodes 210a-f of the previous layer 210. Similarly, for purposes of illustration only, quantized output 225 may be output 225a representing {1} or output 225b representing {-1}. Each output of the decision tree is quantized to 1 or -1 and provided to the subsequent layer 230.
네트워크 계층 그룹(290)을 의사결정 트리(220)로 대체하기 전에, 시스템(100)은 트레이닝 예제들의 대응하는 부분의 양자화 버전을 사용하여 의사결정 트리(220)를 트레이닝할 수 있다. 보다 구체적으로, 시스템(100)은 원래의 신경망에 대한 트레이닝 예제가 주어진 계층 그룹(290)의 첫 번째 계층에 대한 입력의 양자화 버전과, 계층 그룹(290)의 마지막 계층으로부터의 출력의 양자화 버전을 획득할 수 있다. 시스템(100)은 입력의 양자화 버전을 의사결정 트리(220)에 대한 입력으로 설정하고, 출력의 양자화 버전을 의사결정 트리(220)의 출력으로 설정하고, 입력 및 출력의 양자화 버전을 사용하여 의사결정 트리(220)를 트레이닝할 수 있다.Before replacing network layer group 290 with decision tree 220, system 100 may train decision tree 220 using quantized versions of corresponding portions of the training examples. More specifically, system 100 generates a quantized version of the input for the first layer of layer group 290, given the training examples for the original neural network, and a quantized version of the output from the last layer of layer group 290. It can be obtained. System 100 sets a quantized version of an input as an input to decision tree 220, sets a quantized version of an output as an output of decision tree 220, and uses the quantized versions of the input and output to make a decision. The decision tree 220 can be trained.
도 2b는 3진 양자화 출력(275)을 가진 의사결정 트리를 갖는 다른 예시적인 새로운 기계 학습 모델(255)의 일부를 도시한다.2B shows a portion of another example new machine learning model 255 with a decision tree with ternary quantization output 275.
도 2a와 유사하게, 시스템(100)은 신경망(250)의 일부에 있는 다른 계층 그룹(285)을 다른 의사결정 트리(270)로 대체할 수 있고, 삼진 양자화를 사용하여 의사결정 트리에 대한 입력 및 출력을 양자화할 수 있다. 양자화된 입력(265) 및 양자화된 출력(275)은 값 집합 {-1, 0, 1} 중 하나를 포함한다. 단지 예시의 목적으로, 양자화된 출력(275)은 {1}을 나타내는 출력(275a), {0}을 나타내는 출력(275b), 및 {-1}을 나타내는 출력(275c) 중 하나일 수 있다.Similar to FIG. 2A , system 100 may replace another group of layers 285 in a portion of neural network 250 with another decision tree 270 and use ternary quantization to determine the input to the decision tree. and the output can be quantized. Quantized input 265 and quantized output 275 include one of the set of values {-1, 0, 1}. For purposes of illustration only, quantized output 275 may be one of output 275a representing {1}, output 275b representing {0}, and output 275c representing {-1}.
네트워크 계층 그룹의 수는 설명의 편의를 위해 도 2a에서는 3개이고, 도 2b에서는 5개이지만, 의사결정 트리에 의해 대체될 네트워크 계층 그룹의 수는 시스템(100)에 의해 결정된 임의의 적합한 값일 수 있다. 예를 들어, 그 수는 1, 10 또는 50일 수 있다.The number of network layer groups is 3 in FIG. 2A and 5 in FIG. 2B for convenience of explanation, but the number of network layer groups to be replaced by the decision tree may be any suitable value determined by system 100. . For example, the number could be 1, 10, or 50.
도 3은 트레이닝된 새로운 기계 학습 모델을 생성하기 위한 예시적인 프로세스(300)의 흐름도이다. 편의상, 프로세스(300)는 하나 이상의 위치에 위치한 하나 이상의 컴퓨터 시스템에 의해 수행되는 것으로 설명될 것이다. 예를 들어, 본 명세서에 따라 적절히 프로그래밍된 신경망 배치 시스템(100), 예를 들어 도 1에 도시된 시스템(100)은 프로세스(300)를 수행할 수 있다.Figure 3 is a flow diagram of an example process 300 for creating a new trained machine learning model. For convenience, process 300 will be described as being performed by one or more computer systems located at one or more locations. For example, a neural network deployment system 100 appropriately programmed in accordance with the present disclosure, such as system 100 shown in FIG. 1, may perform process 300.
시스템은 시퀀스로 배열된 복수의 계층을 포함하는 신경망을 나타내는 데이터를 수신한다(310). 수신된 데이터에는 몇가지 예를 들면 신경망의 각 네트워크 계층에 의해 수행되는 연산과 각 네트워크 계층의 가중치가 포함될 수 있다. 네트워크 계층은 이전 계층으로부터의 계층 출력이 후속 계층에 계층 입력으로서 제공되도록 시퀀스에 따라 배열된다.The system receives data representing a neural network comprising a plurality of layers arranged in a sequence (310). The received data may include the operations performed by each network layer of the neural network and the weights of each network layer, to name a few. Network layers are arranged in a sequence such that layer outputs from previous layers are provided as layer inputs to subsequent layers.
시스템은 복수의 계층으로부터 하나 이상의 계층 그룹을 선택하는데(320), 각각의 계층 그룹은 시퀀스에서 서로 인접한 하나 이상의 계층을 포함한다. 예를 들어, 시스템은 3개의 계층 그룹을 선택할 수 있는데, 첫 번째 계층 그룹은 단 하나의 계층을 포함하고, 두 번째 계층 그룹은 3개의 계층을 포함하며, 마지막 계층 그룹은 신경망의 마지막 두 번째 계층을 포함하는 5개의 계층을 포함한다.The system selects 320 one or more layer groups from the plurality of layers, each layer group including one or more layers adjacent to each other in the sequence. For example, the system may select three layer groups: the first layer group contains only one layer, the second layer group contains three layers, and the final layer group contains the second-last layer of the neural network. It includes 5 layers including:
시스템은 선택된 하나 이상의 계층 그룹 각각을 개별 의사결정 트리로 대체함으로써(330) 신경망에 대응하는 새로운 기계 학습 모델을 생성한다.The system creates a new machine learning model corresponding to the neural network by replacing each selected group of one or more layers with an individual decision tree (330).
개별 계층 그룹을 대체하기 위한 개별 의사결정 트리는 적어도 계층 그룹의 계층 수에 기초한 트리 깊이를 가질 수 있다. 예를 들어, 의사결정 트리의 트리 깊이는 계층 그룹의 계층 수와 같다. 다른 예로, 의사결정 트리의 트리 깊이는 3이고 의사결정 트리로 대체된 대체된 계층 그룹에는 5개의 네트워크 계층이 있다.An individual decision tree for replacing an individual hierarchical group may have a tree depth based at least on the number of layers in the hierarchical group. For example, the tree depth of a decision tree is equal to the number of layers in the hierarchical group. As another example, the tree depth of a decision tree is 3 and the replaced layer group replaced by the decision tree has 5 network layers.
의사결정 트리에는 임의의 적절한 트리 유형이 포함될 수 있다. 예를 들어, 의사결정 트리는 GradientBoost 트리 또는 AdaBoost 트리일 수 있다.Decision trees can include any suitable tree type. For example, a decision tree can be a GradientBoost tree or an AdaBoost tree.
시스템은 적어도 계층 그룹 중 첫 번째 계층에 대한 입력과 계층 그룹 중 마지막 계층로부터의 출력을 양자화하고, 양자화된 입력 및 출력을 개별 의사결정 트리에 제공할 수 있다. 보다 구체적으로, 하나 이상의 계층 그룹 각각에 대해, 개별 의사결정 트리는 그룹의 각각의 첫 번째 계층에 대한 입력의 양자화 버전을 입력으로 수신하고 그룹의 각각의 마지막 계층의 출력의 양자화 버전을 출력으로 생성한다.The system may quantize the input to at least the first layer of the layer group and the output from the last layer of the layer group, and provide the quantized input and output to the individual decision tree. More specifically, for each group of one or more layers, a separate decision tree receives as input a quantized version of the input for each first layer in the group and produces as output a quantized version of the output of each last layer in the group. .
일부 구현에서, 시스템은 개별 스케일링 인자에 기초하여 개별 의사결정 트리에 대한 입력 및 출력의 양자화 버전을 획득할 수 있다. 보다 구체적으로, 시스템은 양자화된 입력에 개별 스케일링 인자를 곱함으로써 의사 의사결정 트리에 대한 입력의 양자화 버전을 생성할 수 있다. 전술한 바와 같이, 스케일링 인자는 적어도 양자화된 계층과 원본 계층 사이의 유사성 척도에 기초하여 획득된다.In some implementations, the system may obtain quantized versions of the input and output for individual decision trees based on individual scaling factors. More specifically, the system can generate a quantized version of the input to the decision tree by multiplying the quantized input by a separate scaling factor. As described above, the scaling factor is obtained based at least on a similarity measure between the quantized layer and the original layer.
시스템은 원래의 신경망에 대한 트레이닝 데이터에 기초하여 새로운 기계 학습 모델을 트레이닝한다(340). 시스템은 개별 의사결정 트리로 대체되지 않은 원래 신경망의 계층 중 적어도 일부를 트레이닝한다. 일부 구현에서, 시스템은 시퀀스에서 신경망의 하나 이상의 계층 그룹에 후속하는 신경망의 계층들을 트레이닝한다.The system trains a new machine learning model based on the training data for the original neural network (340). The system trains at least some of the layers of the original neural network that have not been replaced by individual decision trees. In some implementations, the system trains layers of a neural network that follow one or more groups of layers of the neural network in sequence.
일부 상황에서, 시스템은 원래 신경망에 대해 동일하지만 양자화된 트레이닝 샘플을 사용하여 전체 새로운 기계 학습 모델을 트레이닝할 수 있다. 일부 구현에서, 시스템은 트레이닝 중에 순방향 전파를 위해 양자화된 입력 및 출력을 사용할 수 있고, 역방향 전파 중에 가중치를 업데이트하기 위해 부동 유형(floating-type) 입력 및 출력을 사용할 수 있다. 대안적으로, 시스템은 새로운 기계 학습 모델의 개별 의사결정 트리에 대한 개별 기울기를 나타내는 데이터를 계산할 수 있다.In some situations, the system can train an entirely new machine learning model using the same but quantized training samples for the original neural network. In some implementations, the system may use quantized inputs and outputs for forward propagation during training and floating-type inputs and outputs to update weights during backward propagation. Alternatively, the system can compute data representing individual slopes for individual decision trees of a new machine learning model.
시스템은 임의의 적절한 알고리즘을 선택하여 계층 그룹을 선택하고 해당 의사결정 트리로 계층 그룹을 대체할 수 있다. 일부 구현에서, 시스템은 계층 그룹을 반복적으로 선택할 수 있다. 보다 구체적으로, 계층 그룹을 선택하기 위한 하나의 예시적인 알고리즘은 아래와 같이 설명된다.The system may select any suitable algorithm to select hierarchical groups and replace the hierarchical groups with corresponding decision trees. In some implementations, the system may select hierarchical groups iteratively. More specifically, one example algorithm for selecting a hierarchical group is described below.
신경망에 N개의 네트워크 계층이 포함되어 있다고 가정하면, 시스템은 시퀀스에 따라 신경망의 각 계층을 계층 i로 인덱싱하며, 여기서 i∈ [0,1,2,… ,N-1]이다.Assuming that the neural network contains N network layers, the system indexes each layer of the neural network into layer i according to the sequence, where i ∈ [0,1,2,…. ,N-1].
시스템은 계층 그룹을 선택할 계층의 총 개수(모든 계층)를 신경망의 크기(N 계층)와 동일하게 설정한다.The system sets the total number of layers (all layers) from which to select a layer group equal to the size of the neural network (N layers).
시스템은 모든 계층 중에서 계층(L)을 계층 그룹의 첫 번째 계층으로 무작위로 선택한다. 일부 구현예에서, 시스템은 계층 시퀀스에 따라 계층 그룹의 첫 번째 계층을 선택할 수 있다. 예를 들어, 시스템은 계층 그룹의 첫 번째 계층인 계층(0)으로 시작할 수 있다.The system randomly selects layer (L) among all layers as the first layer in the layer group. In some implementations, the system may select the first layer of a layer group according to the layer sequence. For example, a system might start with layer (0), which is the first layer in a group of layers.
계층(L)에서부터 시작하여 마지막 계층 N까지 시퀀스의 각 계층에 대해, 시스템은 먼저 현재 계층이 이미 의사결정 트리로 대체되었는지 또는 의사결정 트리에 속하는지 체크한다.For each layer in the sequence, starting from layer L up to the last layer N, the system first checks whether the current layer has already been replaced by a decision tree or belongs to a decision tree.
현재 계층이 의사결정 트리로 대체되지 않았거나 의사결정 트리에 속하지 않는다고 결정할 때, 시스템은 현재 계층을 계층 그룹에 추가한다.When the system determines that the current layer has not been replaced by a decision tree or does not belong to a decision tree, the system adds the current layer to the layer group.
시스템은 계층 그룹의 초기 계층(L)에 대한 입력과 현재 계층의 출력에 대해 양자화를 수행하고 계층(L)에서 현재 계층까지 계층들을 개별 의사결정 트리로 잠정적으로 대체한다. 전술한 바와 같이, 시스템은 신경망 계층에 대한 입력 및 출력에 대해 이진 양자화 또는 삼진 양자화를 수행할 수 있다. 일부 구현에서, 시스템은 누산기 크기가 특정 수의 의사결정 트리로 제한될 수 있도록 신경망의 각 계층의 모든 출력을 양자화한다The system performs quantization on the input to the initial layer (L) of the layer group and the output of the current layer and temporarily replaces the layers from layer (L) to the current layer with individual decision trees. As described above, the system may perform binary quantization or ternary quantization on the inputs and outputs to the neural network layers. In some implementations, the system quantizes all outputs of each layer of the neural network so that the accumulator size can be limited to a certain number of decision trees.
시스템은 계층 그룹에 대한 계층 정보를 업데이트하고 수정된 네트워크의 성능(예를 들어, 추론 정확도)을 측정한다. 계층 그룹 결정 및 성능 측정에 대한 자세한 내용은 도 4에서 더 자세히 설명하기로 한다.The system updates layer information for layer groups and measures the performance (e.g., inference accuracy) of the modified network. Details on hierarchical group determination and performance measurement will be described in more detail in FIG. 4.
계층 그룹을 결정한 후, 시스템은 계층 그룹을 개별 의사결정 트리로 대체한다.After determining the hierarchical groups, the system replaces the hierarchical groups with individual decision trees.
시스템은 그룹의 마지막 계층부터 시작하여 신경망의 마지막 계층까지 나머지 계층을 트레이닝한다. 보다 구체적으로, 시스템은 원래 신경망을 트레이닝하는 데 사용된 것과 동일한 트레이닝 예제의 해당 부분을 사용하여 나머지 계층의 가중치를 미세 조정한다.The system starts with the last layer of the group and trains the remaining layers up to the last layer of the neural network. More specifically, the system fine-tunes the weights of the remaining layers using those parts of the same training examples that were originally used to train the neural network.
도 4는 하나 이상의 신경망 계층 그룹을 선택하기 위한 예시적인 프로세스(400)의 흐름도이다. 편의상, 프로세스(400)는 하나 이상의 위치에 위치한 하나 이상의 컴퓨터 시스템에 의해 수행되는 것으로 설명될 것이다. 예를 들어, 본 명세서에 따라 적절하게 프로그래밍된 신경망 배치 시스템(100), 예를 들어 도 1에 도시된 시스템(100)은 프로세스(400)를 수행할 수 있다.Figure 4 is a flow diagram of an example process 400 for selecting a group of one or more neural network layers. For convenience, process 400 will be described as being performed by one or more computer systems located at one or more locations. For example, a neural network deployment system 100 appropriately programmed in accordance with the present disclosure, such as system 100 shown in FIG. 1, may perform process 400.
시스템은 신경망에서 각각의 초기 계층을 선택한다(410). 전술한 바와 같이, 시스템은 무작위로 또는 계층 시퀀스에 기초하여 계층 그룹에 대한 초기 계층을 선택할 수 있다.The system selects each initial layer in the neural network (410). As described above, the system may select an initial layer for a layer group randomly or based on layer sequence.
시스템은 후보 그룹의 첫 번째 계층로서 각각의 초기 계층을 갖는 복수의 후보 그룹 각각을 생성한다(420). 보다 구체적으로, 시스템은 동일한 초기 계층을 갖는 각 후보 그룹에 대해 각각의 계층 수를 잠정적으로 설정한다. 예를 들어, 시스템은 2개의 계층만으로 구성된 제1 후보 그룹, 4개의 계층으로 구성된 제2 후보 그룹, 6개의 계층으로 구성된 제3 후보 그룹을 생성한다. 일부 구현에서, 후보 그룹은 연속적인 수의 계층을 가질 수 있다. 예를 들어, 제1 후보 그룹은 단일 계층으로 구성되고, 제2 후보 그룹은 2개의 계층으로 구성되며, 제3 후보 그룹은 3개의 계층으로 구성된다.The system generates each of a plurality of candidate groups with each initial layer as the first layer of the candidate group (420). More specifically, the system tentatively sets the number of layers for each candidate group with the same initial layer. For example, the system generates a first candidate group consisting of only two layers, a second candidate group consisting of four layers, and a third candidate group consisting of six layers. In some implementations, candidate groups may have a contiguous number of layers. For example, the first candidate group consists of a single layer, the second candidate group consists of two layers, and the third candidate group consists of three layers.
복수의 후보 그룹 각각에 대해, 시스템은 개별 의사결정 트리에 의해 대체된 후보 그룹의 계층을 갖는 대응하는 새로운 기계 학습 모델의 성능을 측정하는 후보 그룹에 대한 각각의 성능 측정치를 결정한다(430). 보다 구체적으로, 시스템은 복수의 새로운 기계 학습 모델을 생성하며, 그 각 모델은 개별 의사결정 트리에 의해 대체된 각각의 후보 계층 그룹을 포함한다. 시스템은 동일한 입력 데이터를 사용하여 각각의 새로운 기계 학습 모델에 대해 추론 계산을 수행하고 각각의 새로운 기계 학습 모델에 대한 개별 성능 스코어를 획득한다. 개별 성능 스코어는 추론 정확도에 기초하여 획득될 수 있다.For each of the plurality of candidate groups, the system determines 430 a respective performance measure for the candidate group that measures the performance of a corresponding new machine learning model with the hierarchy of candidate groups replaced by individual decision trees. More specifically, the system generates a plurality of new machine learning models, each model including each candidate hierarchy group replaced by a separate decision tree. The system performs inference calculations for each new machine learning model using the same input data and obtains an individual performance score for each new machine learning model. Individual performance scores may be obtained based on inference accuracy.
시스템은 의사결정 트리에 의해 대체될 계층 그룹으로서, 각각의 복수의 후보 그룹에 대한 개별 성능 측정치에 기초하여 계층의 후보 그룹 중 하나를 선택한다(440). 일부 구현에서, 시스템은 개별 성능 측정치 중에서 최대 성능 측정치를 결정하고, 그룹으로서, 각각의 복수의 후보 그룹으로부터 최대 성능 측정치와 연관된 후보 그룹을 그룹으로 선택한다. 대안적으로, 시스템은 상대적으로 성능 스코어가 높지만 추론 계산을 수행하는 속도가 가장 빠른 후보 그룹을 선택한다.The system selects one of the candidate groups of the hierarchy based on individual performance measurements for each of the plurality of candidate groups, as the hierarchy group to be replaced by the decision tree (440). In some implementations, the system determines a maximum performance measure among the individual performance measures and selects, as a group, a candidate group associated with the maximum performance measure from each of the plurality of candidate groups. Alternatively, the system selects a group of candidates that have relatively high performance scores but are the fastest to perform inference calculations.
도 5는 의사결정 트리(500)의 예를 도시한다.Figure 5 shows an example of a decision tree 500.
도 5에 도시된 바와 같이, 의사결정 트리(500)는 특정 트리 깊이를 갖는 복수의 노드를 포함할 수 있다. 트리 깊이는 트리 계층의 총 개수에 기초하여 결정된다. 결정 트리의 각 계층에는 논리 비교 또는 기타 적절한 기준과 같은 개별 노드 연산을 나타내는 노드가 포함될 수 있다.As shown in Figure 5, decision tree 500 may include a plurality of nodes with a specific tree depth. Tree depth is determined based on the total number of tree layers. Each layer of the decision tree may contain nodes representing individual node operations, such as logical comparisons or other appropriate criteria.
예를 들어, 도 5에 도시된 바와 같이, 의사결정 트리(500)는 루트 노드(510)와 서로 다른 트리 계층의 각각의 비-루트(non-root) 노드(520, 530)를 포함하는 복수의 노드를 가질 수 있다. 루트 노드(510)는 의사결정 트리(500)의 시작점으로서 부모 노드를 갖지 않으며, 비-루트 노드(520, 530)는 각각 부모 노드를 가지며 자식 노드라고 지칭된다. 일반적으로, 트리 계층에서 리프 노드를 제외한 각 노드는 해당 노드를 다음 트리 계층의 개별 자식 노드에 연결하는 하나 이상의 분기(도 5의 화살표)를 가질 수 있다. 자식 노드들가 있는 노드는 비-리프(non-leaf) 노드(예를 들어, 노드(510, 520a 및 520b))라고 지칭된다.For example, as shown in Figure 5, the decision tree 500 includes a root node 510 and a plurality of non-root nodes 520 and 530 of different tree hierarchies, respectively. It can have nodes. The root node 510 is the starting point of the decision tree 500 and does not have a parent node, and the non-root nodes 520 and 530 each have a parent node and are referred to as child nodes. In general, each node in a tree hierarchy, except leaf nodes, may have one or more branches (arrows in Figure 5) connecting that node to individual child nodes in the next tree hierarchy. Nodes that have child nodes are referred to as non-leaf nodes (e.g., nodes 510, 520a, and 520b).
가장 깊은 또는 마지막 트리 계층의 리프 노드(예를 들어, 노드(530a, 530b, 530c 및 530d))의 경우, 각각은 의사결정 트리(500)에 대한 추론 출력을 나타낼 수 있으며, 다른 자식 노드에 연결되는 분기를 갖지 않는다. 추론 출력은 예측, 예를 들어 리프 노드(530a)에 대한 확률(P1)일 수 있다.For the leaf nodes of the deepest or last tree layer (e.g., nodes 530a, 530b, 530c, and 530d), each may represent an inference output for decision tree 500, and may be connected to other child nodes. It does not have any branches. The inference output may be a prediction, for example probability P1 for leaf node 530a.
도 5를 참조하면, 시스템(예를 들어, 도 1의 시스템(100))이 인자(nf1, nf2, nf3)를 나타내는 입력 데이터를 이용하여 의사결정 트리의 추론 연산을 수행하는 경우, 가장 깊은 트리 계층의 리프 노드를 제외한 각각의 비-리프 노드는 각각의 노드 연산(예를 들어, 도 5에 도시된 논리 비교)을 갖는다. 시스템은 루트 노드(510)에 대한 노드 연산을 수행하고, 노드 연산으로부터 논리적 결과(예를 들어, 참 또는 거짓)를 얻고, 그 결과에 기초하여 각각의 분기를 따라 해당 자식 노드에 접근할 수 있다. 예를 들어, 결과가 거짓인 경우, 시스템은 노드(520a)에 접근한다. 일부 구현에서, 시스템은 정수 0과 1을 사용하여 거짓과 참을 나타낼 수 있다. 결국, 시스템은 의사결정 트리의 가장 깊은 계층에 있는 특정 리프 노드에 접근하고 특정 리프 노드가 나타내는 추론을 반환한다.Referring to Figure 5, when a system (e.g., system 100 of Figure 1) performs an inference operation of a decision tree using input data representing factors (n f1 , n f2 , n f3 ), Each non-leaf node except the leaf nodes of the deepest tree layer has a respective node operation (e.g., logical comparison shown in Figure 5). The system can perform a node operation on the root node 510, obtain a logical result (e.g., true or false) from the node operation, and access the corresponding child nodes along each branch based on the result. . For example, if the result is false, the system approaches node 520a. In some implementations, the system may use the integers 0 and 1 to represent false and true. Eventually, the system accesses a specific leaf node in the deepest layer of the decision tree and returns the inference represented by that specific leaf node.
도 6은 고정 기능(fixed function) 하드웨어(600)를 사용하는 의사결정 트리의 예시적인 구현을 도시한다.6 shows an example implementation of a decision tree using fixed function hardware 600.
도 6에 도시된 바와 같이, 시스템(예를 들어, 도 1에 도시된 시스템(100))은 고정 기능 하드웨어(600)를 사용하여 의사결정 트리의 추론 계산을 수행할 수 있다. 보다 구체적으로, 시스템은 입력(x)(610)를 수신하고 도 5에 도시된 예시적인 의사결정 트리에 대한 최종 추론 출력(620)을 반환할 수 있다. 의사결정 트리(600)는 상이한 노드로부터 추론 결과를 획득하고 의사결정 트리의 특정 리프 노드에 의해 표시되는 최종 추론 출력(620)을 생성하기 위해 다중 계산 유닛(630 및 640)을 포함할 수 있다.As shown in Figure 6, a system (e.g., system 100 shown in Figure 1) may use fixed function hardware 600 to perform inferential computation of a decision tree. More specifically, the system may receive input (x) 610 and return a final inference output 620 for the example decision tree shown in FIG. 5 . Decision tree 600 may include multiple computation units 630 and 640 to obtain inference results from different nodes and produce a final inference output 620 represented by a specific leaf node of the decision tree.
고정 기능 하드웨어(600)를 사용하는 시스템은 각 입력 데이터를 대응하는 트리 노드에 할당하고, 개별 비교기 및 멀티플렉서를 사용하여 각 노드에서 개별 기능을 구현할 수 있다. 도 6에 도시된 바와 같이, 시스템은 입력 데이터(x∈[h1,l1])를 최상위 노드(도 5의 루트 노드(510)와 동일)에 할당하고, 입력 데이터(x∈[h2,l2])를 왼쪽 노드(630a)(두 번째 트리 계층의 왼쪽 비-리프 노드(520a)와 동일)에 할당하고, 입력 데이터(x∈[h3,l3])를 오른쪽 노드(630b)(두 번째 트리 계층의 오른쪽 비-리프 노드(520b)와 동일)에 할당한다. 시스템은 개별 비교기(640)와 멀티플렉서(630)를 사용하여 각 노드에서 연산을 구현할 수 있다. 예를 들어, 시스템은 비교기(630c)와 멀티플렉서(630c)를 사용하여 최상위 노드에 대한 연산을 구현한다. 보다 구체적으로, 시스템은 실수 값의 벡터일 수 있는 입력(x)을 수신하고 x∈[h1,l1] 범위를 갖는 입력 부분을 선택하여 최상위 루트 노드에 제공한다. 시스템은 비교기(640c)를 사용하여 입력의 일부를 기준(a1)과 비교하는데, 여기서 기준(a1)은 실수 값 스칼라를 나타낼 수 있다. 입력 데이터(x)가 a1보다 크거나 같으면, 시스템은 노드에 할당된 멀티플렉서(630c)를 사용하여 "참(true)"을 나타내는 결과를 출력한다. 예를 들어, 멀티플렉서는 "참"을 나타내는 정수 1을 출력할 수 있다. 시스템은 대응하는 트리 분기를 따라 현재 노드가 연결된 자식 노드에 대한 연산을 계속 수행할 수 있다. 마지막 두 번째 트리 계층의 비-리프 노드에 대한 연산을 처리한 후, 시스템은 의사결정 트리의 대응하는 리프 노드가 나타내는 값(예를 들어, 확률)에 기초하여 최종 결과(620)를 출력할 수 있다.A system using fixed function hardware 600 can assign each input data to a corresponding tree node and implement individual functions at each node using individual comparators and multiplexers. As shown in Figure 6, the system assigns input data (x∈[h 1 ,l 1 ]) to the top node (same as root node 510 in Figure 5), and input data (x∈[h 2) ,l 2 ]) to the left node 630a (same as the left non-leaf node 520a of the second tree layer), and input data (x∈[h 3 ,l 3 ]) to the right node 630b ) (same as the right non-leaf node 520b of the second tree layer). The system can implement operations at each node using individual comparators 640 and multiplexers 630. For example, the system uses comparator 630c and multiplexer 630c to implement operations on the top node. More specifically, the system receives an input (x), which can be a vector of real values, and selects a portion of the input with the range x ∈ [h 1 , l 1 ] and provides it to the top-level root node. The system uses comparator 640c to compare a portion of the input to a reference (a 1 ), where reference (a 1 ) may represent a real-valued scalar. If the input data (x) is greater than or equal to a 1 , the system outputs a result indicating “true” using the multiplexer 630c assigned to the node. For example, a multiplexer may output the integer 1, which represents "true". The system can continue to perform operations on child nodes to which the current node is connected along the corresponding tree branch. After processing operations on the non-leaf nodes of the penultimate tree layer, the system may output a final result 620 based on the value (e.g., probability) represented by the corresponding leaf node of the decision tree. there is.
도 7은 의사결정 트리에 대한 추론 계산을 수행하기 위한 예시적인 프로그램 가능 코어(700)를 도시한다.Figure 7 shows an example programmable core 700 for performing inferential computations for a decision tree.
도 7에 도시된 바와 같이, 시스템(예를 들어, 도 1에 도시된 시스템(100))은 프로그램 가능 코어(700)를 사용하여 의사결정 트리에 대한 추론 계산을 수행할 수 있다. 프로그램 가능 코어(700)는 트리 입력(710)을 수신하여 트리 입력에 대한 추론 출력(720)을 생성할 수 있다. 프로그램 가능 코어(700)는 예를 들어 MUX 유닛, ALU 유닛 및 SRAM(Static Random-Access Memory)과 같은 복수의 컴퓨팅 구성요소를 포함할 수 있다. 프로그램 가능 코어(700)는 컴퓨팅 구성요소에 구성된 기능을 추가, 선택 및 전환하는 것만으로 노드 연산을 수행할 수 있다. 따라서 프로그램 가능 코어(700)는 의사결정 트리에 대한 추론 출력을 생성하기 위한 노드 연산으로서 곱셈과 덧셈을 수행하기 위한 임의의 MAC 유닛을 포함할 필요가 없다.As shown in Figure 7, a system (e.g., system 100 shown in Figure 1) may use a programmable core 700 to perform inferential calculations for a decision tree. Programmable core 700 may receive tree input 710 and generate inference output 720 for the tree input. Programmable core 700 may include a plurality of computing components, such as, for example, a MUX unit, an ALU unit, and a static random-access memory (SRAM). The programmable core 700 can perform node operations simply by adding, selecting, and switching functions configured in computing components. Accordingly, the programmable core 700 does not need to include any MAC units to perform multiplication and addition as node operations to generate inference output for the decision tree.
도 7을 참조하면, 루트 노드(예를 들어, 도 5의 루트 노드(510))에 대한 연산을 구현하기 위해, 시스템은 입력(710)을 수신하고 수신된 입력(710)을 루트 노드에 특정되고 이전에 큐에 저장된 어레이(x,a,l,h,i0,i1)를 사용하여 결합 유닛(join unit)에 의해 수정될 수 있다. 위에서 설명한 바와 같이, a는 노드 기준을 나타내고, l과 h는 입력(x)의 수치 범위를 나타내며, 인덱스(i0,i1)는 현재 노드와 해당 자식 노드를 연결하는 트리 분기를 각각 나타낼 수 있고, 각각의 정수 값에 할당되어 노드 연산에 대한 연산 수행 결과를 나타낼 수 있다.Referring to Figure 7, to implement an operation on a root node (e.g., root node 510 in Figure 5), the system receives input 710 and specifies the received input 710 to the root node. and can be modified by a join unit using the array (x,a,l,h,i 0 ,i 1 ) previously stored in the queue. As described above, a represents the node base, l and h represent the numerical range of the input (x), and the indices (i 0 , i 1 ) can represent tree branches connecting the current node and its child nodes, respectively. It can be assigned to each integer value to indicate the result of performing a node operation.
시스템은 임의의 유닛을 사용하여 결합된 입력을 선택하고 루트 노드에서 노드 연산을 구현할 수 있다. 예를 들어, 시스템은 개별 비교기를 사용하여 입력(x∈[h,l])과 기준(a1) 간의 비교를 구현할 수 있다. 이에 응답하여, 인덱스(i0,i1)는 시스템에 의해 개별 정수 값에 할당되어 비교 결과를 나타내고, 의사결정 트리를 해당 하위 노드로 직접 계산할 수 있다. 예를 들어, 시스템이 x∈[h,l]이 기준(a1)보다 크다고 결정하는 경우, 시스템은 i0 = 0, i1 = 1을 할당하여 시스템이 i1로 표시되는 트리 분기를 따라 해당하는 다음 자식 노드에서 연산을 수행할 수 있도록 한다.The system can use arbitrary units to select combined inputs and implement node operations at the root node. For example, a system can implement a comparison between input (x∈[h,l]) and reference (a 1 ) using individual comparators. In response, indices (i 0 , i 1 ) are assigned by the system to individual integer values to represent the comparison results, and the decision tree can be calculated directly to the corresponding child nodes. For example , if the system determines that Allows operations to be performed on the corresponding next child node.
다음 자식 노드에서 연산을 구현하기 위해, 시스템은 먼저 전환(switch) 유닛을 적용하여 다음 자식 노드가 번호 지정(numbering) 기준(N)에 기초하여 비-리프 노드인지 리프 노드인지 결정할 수 있다. 결정하기 위해, 시스템은 개별 태그(K)(예를 들어, 정수)를 사용하여 각 노드에 번호를 매기고 미리 결정된 번호 지정 기준에 따라 다음 자식 노드의 유형을 결정할 수 있다. 예를 들어, 도 5와 관련하여, 시스템은 노드(510, 520a 및 520b)를 노드0, 노드 1 및 노드 2로 태그 지정하고, 리프 노드(530a, 530b, 530c 및 530d)를 노드 3, 노드 4, 노드 5 및 노드 6으로 태그 지정할 수 있다. 시스템은 번호 지정 기준(N = 3)을 설정할 수 있으므로 태그가 K < 3인 노드들은 비-리프 노드이고, 태그가 K >= 3인 노드들은 리프 노드이다.To implement an operation on the next child node, the system may first apply a switch unit to determine whether the next child node is a non-leaf node or a leaf node based on a numbering criterion (N). To determine, the system may number each node using an individual tag (K) (e.g., an integer) and determine the type of the next child node according to predetermined numbering criteria. For example, with reference to Figure 5, the system tags nodes 510, 520a, and 520b as node 0, node 1, and node 2, and leaf nodes 530a, 530b, 530c, and 530d as node 3, node. They can be tagged as node 4, node 5, and node 6. The system can set the numbering criteria (N = 3), so nodes with tags K < 3 are non-leaf nodes, and nodes with tags K >= 3 are leaf nodes.
다음 자식 노드가 비-리프 노드라고 결정하는 것에 응답하여, 시스템은 비-리프 SRAM에 저장된 데이터로부터 다음 자식 노드에 대한 각 어레이(x,a,l,h,i0,i1)을 업데이트할 수 있다. 유사하게, 다음 자식 노드가 리프 노드라고 결정하는 것에 응답하여, 시스템은 리프 SRAM에 저장된 리프 노드와 연관된 최종 출력을 제공할 수 있다.In response to determining that the next child node is a non-leaf node, the system will update each array (x,a,l,h,i 0 ,i 1 ) for the next child node from data stored in the non-leaf SRAM. You can. Similarly, in response to determining that the next child node is a leaf node, the system may provide a final output associated with the leaf node stored in the leaf SRAM.
병렬 계산을 위해, 시스템은 포크(fork) 기능을 채택하여 대기열(queue)의 노드에 대한 입력 데이터 부분을 저장하고 SRAM의 노드 유형과 연산을 식별하는 개별 어레이를 저장할 수 있다. 시스템은 병렬 계산 중에 각 컴퓨팅 유닛에 대해 관찰된 각각의 대기 시간에 기초하여 하나 이상의 결합(joint) 유닛을 사용하여 개별 어레이로 입력 데이터를 수정할 시기를 자동으로 결정할 수 있다.For parallel computation, the system can adopt a fork function to store a portion of input data for a node in a queue and a separate array identifying the node type and operation in SRAM. The system can automatically determine when to modify input data into individual arrays using one or more joint units based on the respective latency observed for each compute unit during parallel computation.
본 명세서에 언급된 실시예는 신경망을 트레이닝하기 위한 개선된 방법을 제공한다. 신경망은 임의의 종류의 디지털 데이터 입력을 수신하고 그 입력에 기초하여 임의의 종류의 스코어, 분류 또는 회귀 출력을 생성하도록 구성될 수 있다. 입력 데이터 항목은 자연어로 된 이미지 데이터(여기서는 비디오 데이터 포함), 오디오 데이터 또는 텍스트 데이터(예를 들어, 단어 또는 단어 조각(또는 이에 대한 표현, 예를 들어, 임베딩))를 포함할 수 있다. 입력 데이터 항목은 순차적 데이터, 예를 들어 디지털화된 오디오를 나타내는 데이터 샘플의 시퀀스 또는 픽셀의 시퀀스로 표현되는 이미지, 이미지의 시퀀스로 표현되는 비디오, 또는 자연 언어로 된 단어의 시퀀스를 나타내는 시퀀스를 포함할 수 있다. 여기서 "이미지"에는 예를 들어 라이다(LIDAR) 이미지가 포함된다.Embodiments mentioned herein provide improved methods for training neural networks. A neural network can be configured to receive any kind of digital data input and produce any kind of score, classification, or regression output based on that input. Input data items may include image data (here including video data), audio data, or text data (e.g., words or word fragments (or representations thereof, e.g., embeddings)) in natural language. The input data item may contain sequential data, for example a sequence of data samples representing digitized audio, or an image represented as a sequence of pixels, a video represented as a sequence of images, or a sequence representing a sequence of words in a natural language. You can. Here, “image” includes, for example, LIDAR images.
일부 구현에서 신경망 출력은 특징 표현을 포함할 수 있으며, 이는 시스템 출력을 생성하기 위해 추가로 처리될 수 있다. 예를 들어, 시스템 출력은 입력 데이터 항목을 복수의 카테고리(예를 들어, 이미지, 비디오 또는 오디오 카테고리) 중 하나로 분류하기 위한 분류 출력(예를 들어, 입력 데이터 항목 또는 입력 데이터 항목의 객체/요소가 카테고리에 속할 추정된 가능성을 나타내는 데이터), 또는 입력 데이터 항목의 영역을 예를 들어 이미지 또는 비디오에 표현된 객체 또는 동작으로 분할하기 위한 분할(segmentation) 출력을 포함할 수 있다. 또는 시스템 출력은 강화 학습 시스템의 동작 선택 출력일 수 있다.In some implementations, neural network output may include feature representations, which may be further processed to generate system output. For example, a system output may be a classification output to classify an input data item into one of a plurality of categories (e.g., an image, video, or audio category) (e.g., whether the input data item or an object/element of the input data item is data representing an estimated likelihood of belonging to a category), or a segmentation output to segment a region of an input data item into objects or actions represented, for example, in an image or video. Alternatively, the system output may be the action selection output of a reinforcement learning system.
일부 다른 구현에서, 네트워크 출력은 동일하거나 다른 유형의 또 다른 데이터 항목을 포함할 수 있다. 예를 들어 입력 데이터 항목은 이미지, 오디오 또는 텍스트일 수 있고, 출력 데이터 항목은 이미지, 오디오 또는 텍스트의 수정된 버전, 예를 들어, 입력 데이터 항목 또는 입력 데이터 항목 내의 하나 이상의 객체나 요소의 스타일, 컨텐츠, 속성, 포즈 등을 변경하는 것; 또는 입력 데이터 항목의 (누락된) 부분을 채우는 것; 또는 데이터 항목의 다른 버전이나 비디오 또는 오디오 데이터 항목의 확장을 예측하는 것; 또는 입력 데이터 항목의 업샘플링(또는 다운샘플링) 버전을 제공하는 것일 수 있다. 예를 들어, 입력 데이터 항목은 제1 언어로 된 텍스트의 표현일 수 있고, 출력 데이터 항목은 텍스트를 다른 언어로 번역하거나 텍스트를 다른 언어로 번역하기 위한 스코어일 수 있다. 다른 예에서 입력 이미지는 비디오, 와이어 프레임 모델 또는 CAD 모델로 변환될 수 있으며, 2D의 입력 이미지는 3D로 또는 그 반대로 변환될 수 있다. 또는 입력 데이터 항목은 음성 발언 또는 음성 발언 시퀀스 또는 그로부터 도출된 특징으로부터 도출된 특징을 포함할 수 있으며, 네트워크 시스템 출력은 텍스트 조각 세트 각각에 대한 스코어를 포함할 수 있으며, 각 스코어는 특징에 기초하여 텍스트 조각이 올바른 전사일 추정된 가능성을 나타낸다. 다른 예에서, 입력 데이터 항목은 이미지, 오디오 또는 텍스트일 수 있고, 출력 데이터 항목은 입력 데이터 항목을 다른 형식으로 표현한 것일 수 있다. 예를 들어, 신경망은 텍스트를 음성으로 변환하거나 (음성 인식을 위해) 그 반대로 변환하거나 이미지(또는 비디오)를 (예를 들어, 캡션을 위해) 텍스트로 변환할 수 있다. 순차 데이터를 포함하는 출력을 생성할 때, 신경망은 하나 이상의 컨벌루션 계층, 예를 들어 확장된(dilated) 컨벌루션 계층을 포함할 수 있다.In some other implementations, the network output may include another data item of the same or a different type. For example, an input data item may be an image, audio, or text, and an output data item may be a modified version of the image, audio, or text, e.g., a style of the input data item or one or more objects or elements within the input data item; Changing content, properties, poses, etc.; or filling in (missing) parts of input data items; or predicts another version of a data item or an extension of a video or audio data item; Alternatively, it may be to provide an upsampled (or downsampled) version of the input data item. For example, an input data item may be a representation of text in a first language and an output data item may be a translation of the text into another language or a score for translating the text into another language. In other examples, the input image may be converted to video, a wireframe model, or a CAD model, and an input image in 2D may be converted to 3D or vice versa. Alternatively, the input data item may include features derived from a spoken utterance or a sequence of spoken utterances or features derived therefrom, and the network system output may include a score for each set of text fragments, each score based on the feature. Indicates the estimated probability that a piece of text is a correct transcription. In other examples, the input data item may be an image, audio, or text, and the output data item may be a representation of the input data item in another format. For example, a neural network can convert text to speech (for speech recognition, for example) or vice versa, or an image (or video) to text (for captions, for example). When generating output containing sequential data, a neural network may include one or more convolutional layers, for example, a dilated convolutional layer.
일부 다른 구현에서, 네트워크 출력은 환경, 예를 들어 현실 환경 또는 현실 환경의 시뮬레이션에서 로봇 또는 다른 기계적 에이전트와 같은 에이전트에 의해 수행될 액션을 선택하기 위한 출력을 포함할 수 있다. In some other implementations, the network output may include an output for selecting an action to be performed by an agent, such as a robot or other mechanical agent, in an environment, e.g., a real environment or a simulation of a real environment.
일부 구현에서 신경망은 입력 데이터 항목을 수신하고 입력 데이터 항목을 처리하여 네트워크 파라미터에 따라 입력 데이터 항목의 특징 표현을 생성하도록 구성된다. 일반적으로, 데이터 항목의 특징 표현은 데이터 항목을 다차원 특징 공간의 한 점으로 나타내는 벡터와 같은 숫자 값의 정렬된 모음이다. 즉, 각 특징 표현은 입력 데이터 항목의 복수의 특징 각각에 대한 숫자 값을 포함할 수 있다. 이전에 설명한 바와 같이 신경망은 모든 종류의 디지털 데이터 입력을 입력으로 수신하고 그 입력으로부터 특징 표현을 생성하도록 구성될 수 있다. 예를 들어, 네트워크 입력이라고도 지칭될 수 있는 입력 데이터 항목은 이미지, 문서의 일부, 텍스트 시퀀스, 오디오 데이터, 의료 데이터 등일 수 있다.In some implementations, a neural network is configured to receive input data items and process the input data items to generate feature representations of the input data items according to network parameters. Typically, a feature representation of a data item is an ordered collection of numeric values, such as a vector, that represents the data item as a point in a multidimensional feature space. That is, each feature expression may include a numeric value for each of a plurality of features of the input data item. As previously explained, a neural network can be configured to receive any kind of digital data input as input and generate a feature representation from that input. For example, input data items, which may also be referred to as network inputs, may be images, portions of documents, text sequences, audio data, medical data, etc.
일단 트레이닝되면, 특징 표현은 예를 들어 네트워크 입력에 대한 기계 학습 태스크를 수행하는데 사용하기 위해 다른 시스템에 입력을 제공할 수 있다. 예시적인 태스크에는 특징 기반 검색, 클러스터링, 거의 중복된(near duplicate) 감지, 검증, 특징 매칭, 도메인 적응, 비디오 기반 약한 지도 학습이 포함될 수 있으며, 비디오의 경우, 예를 들어 비디오 프레임 전반에 걸친 객체 추적, 비디오에 묘사된 개체에 의해 수행하는 제스처의 제스처 인식 등이 포함될 수 있다.Once trained, the feature representation can provide input to other systems for use, for example, in performing machine learning tasks on network inputs. Exemplary tasks may include feature-based search, clustering, near duplicate detection, verification, feature matching, domain adaptation, video-based weakly supervised learning, and in the case of video, e.g., objects across video frames. This may include tracking, gesture recognition of gestures performed by objects depicted in the video, etc.
신경망에 대한 입력이 이미지이거나 이미지로부터 추출된 특징인 경우, 주어진 이미지에 대해 신경망에 의해 생성된 출력은 객체 카테고리 세트 각각에 대한 스코어일 수 있으며, 각 스코어는 이미지가 카테고리에 속하는 객체의 이미지를 포함될 추정된 가능성을 나타낸다. 보다 구체적으로, 각각의 입력 이미지 또는 입력 이미지로부터 추출된 특징은 개별 강도 값을 갖는 하나 이상의 픽셀을 포함할 수 있다. 신경망은 입력 이미지의 개별 강도 값 또는 이미지로부터 추출된 특징을 처리하고 예측(예를 들어, 이미지 분류, 이미지 인식 또는 이미지 분할)을 생성하도록 구성된다.If the input to a neural network is an image or features extracted from an image, the output produced by the neural network for a given image may be a score for each of a set of object categories, with each score containing images of objects to which the image belongs. Indicates the estimated probability. More specifically, each input image or features extracted from an input image may include one or more pixels with individual intensity values. A neural network is configured to process individual intensity values of an input image or features extracted from the image and generate predictions (e.g., image classification, image recognition, or image segmentation).
다른 예로, 신경망에 대한 입력이 인터넷 리소스(예를 들어, 웹 페이지), 문서 또는 문서의 일부이거나, 인터넷 리소스, 문서 또는 문서의 일부로부터 추출된 특징인 경우, 주어진 인터넷 리소스, 문서 또는 문서의 일부에 대해 신경망에 의해 생성된 출력은 주제 세트 각각에 대한 스코어일 수 있으며, 각 점수는 인터넷 리소스, 문서 또는 문서 일부가 주제에 관한 것일 추정된(예상) 가능성을 나타낸다.As another example, if the input to the neural network is an Internet resource (e.g., a web page), document, or portion of a document, or features extracted from an Internet resource, document, or portion of a document, then The output generated by the neural network may be a score for each of the set of topics, with each score representing the estimated (expected) likelihood that an Internet resource, document, or portion of a document is about the topic.
다른 예로, 신경망에 대한 입력이 특정 광고에 대한 노출 컨텍스트의 특징인 경우, 신경망에 의해 생성된 출력은 특정 광고가 클릭될 추정된 가능성을 나타내는 스코어일 수 있다.As another example, if the input to the neural network is a feature of the exposure context for a particular advertisement, the output produced by the neural network may be a score representing the estimated likelihood that the particular advertisement will be clicked.
또 다른 예로, 신경망에 대한 입력이 사용자를 위한 개인화된 추천의 특징(예를 들어, 추천에 대한 컨텍스트를 특징짓는 특징, 예를 들어 사용자에 의해 취해진 이전 동작을 특징짓는 특징)인 경우, 신경망에 의해 생성된 출력은 컨텐츠 항목 세트 각각에 대한 스코어일 수 있으며, 각 스코어는 사용자가 컨텐츠 항목 추천에 호의적으로 반응할 추정된 가능성을 나타낸다.As another example, if the input to the neural network is features of a personalized recommendation for the user (e.g., features characterizing the context for the recommendation, e.g., features characterizing previous actions taken by the user), the neural network The output generated by may be a score for each set of content items, with each score representing an estimated likelihood that the user will respond favorably to the content item recommendation.
또 다른 예로, 신경망에 대한 입력이 한 언어로 된 텍스트 시퀀스인 경우, 신경망에 의해 생성된 출력은 다른 언어로 된 텍스트 조각 세트 각각에 대한 스코어일 수 있으며, 각 스코어는 다른 언어로 된 텍스트 조각이 입력 텍스트를 다른 언어로 적절하게 번역할 추정된 가능성을 나타낸다.As another example, if the input to a neural network is a sequence of text in one language, the output produced by the neural network may be a score for each of a set of text fragments in a different language, with each score Indicates the estimated likelihood of appropriately translating the input text into another language.
또 다른 예로, 신경망에 대한 입력이 음성 발언을 나타내는 시퀀스인 경우, 신경망에 의해 생성된 출력은 텍스트 조각 세트 각각에 대한 스코어일 수 있으며, 각 스코어는 텍스트 조각이 발언에 대한 올바른 전사일 추정된 가능성을 나타낸다.As another example, if the input to a neural network is a sequence representing a spoken utterance, the output produced by the neural network may be a score for each of a set of text fragments, with each score being an estimated probability that the text fragment is a correct transcription of the utterance. represents.
본 명세서에 기술된 주제 및 기능적 동작의 실시예는 디지털 전자 회로, 유형으로 구현된 컴퓨터 소프트웨어 또는 펌웨어, 본 명세서에 개시된 구조 및 그 구조적 등가물을 포함하는 컴퓨터 하드웨어, 또는 이들 중 하나 이상의 조합으로 구현될 수 있다. 본 명세서에 설명된 주제의 실시예는 하나 이상의 컴퓨터 프로그램, 즉 데이터 처리 장치에 의해 실행되거나 데이터 처리 장치의 동작을 제어하기 위해 유형의 비-일시적 저장 매체에 인코딩된 컴퓨터 프로그램 명령의 하나 이상의 모듈로 구현될 수 있다. 컴퓨터 저장 매체는 기계 판독 가능 저장 디바이스, 기계 판독 가능 저장 기판, 랜덤 또는 직렬 액세스 메모리 디바이스, 또는 이들 중 하나 이상의 조합일 수 있다. 대안적으로 또는 추가적으로, 프로그램 명령은 데이터 처리 장치에 의한 실행을 위해 적절한 수신기 장치로 전송하기 위한 정보를 인코딩하기 위해 생성된 인공적으로 생성된 전파 신호, 예를 들어 기계 생성 전기, 광학 또는 전자기 신호에 인코딩될 수 있다.Embodiments of the subject matter and functional operations described herein may be implemented in digital electronic circuitry, tangible computer software or firmware, computer hardware including the structures disclosed herein and structural equivalents thereof, or a combination of one or more of these. You can. Embodiments of the subject matter described herein may be comprised of one or more computer programs, i.e., one or more modules of computer program instructions encoded in a tangible, non-transitory storage medium for execution by or controlling the operation of a data processing device. It can be implemented. A computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of these. Alternatively or additionally, the program instructions may be translated into artificially generated radio signals, for example machine-generated electrical, optical or electromagnetic signals, to encode information for transmission to an appropriate receiver device for execution by a data processing device. Can be encoded.
"데이터 처리 장치"라는 용어는 데이터 처리 하드웨어를 지칭하며, 예를 들어 프로그램 가능 프로세서, 컴퓨터 또는 다중 프로세서 또는 컴퓨터를 비롯하여 데이터를 처리하기 위한 모든 종류의 장치, 디바이스 및 기계를 포함한다. 장치는 또한 특수 목적 논리 회로, 예를 들어 FPGA(필드 프로그램 가능 게이트 어레이) 또는 주문형 집적회로(ASIC)일 수 있거나 이를 더 포함할 수 있다. 장치는 하드웨어에 추가하여 컴퓨터 프로그램의 실행 환경을 생성하는 코드(예를 들어, 프로세서 펌웨어, 프로토콜 스택, 데이터베이스 관리 시스템, 운영 체제 또는 이들 중 하나 이상의 조합을 구성하는 코드)를 선택적으로 포함할 수 있다.The term “data processing equipment” refers to data processing hardware and includes all types of apparatus, devices and machines for processing data, including, for example, programmable processors, computers or multiprocessors or computers. The device may also be or further include special purpose logic circuitry, such as a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC). In addition to the hardware, the device may optionally include code that creates an execution environment for a computer program (e.g., code comprising processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of these). .
프로그램, 소프트웨어, 소프트웨어 애플리케이션, 앱, 모듈, 소프트웨어 모듈, 스크립트 또는 코드라고도 지칭되거나 설명될 수 있는 컴퓨터 프로그램은 컴파일된 언어나 해석된 언어, 선언적 언어나 절차적 언어를 포함한 모든 형태의 프로그래밍 언어로 작성될 수 있으며, 독립 실행형 프로그램, 모듈, 구성 요소, 서브루틴 또는 컴퓨팅 환경에서 사용하기에 적합한 기타 유닛을 포함하여 모든 형태로 배포될 수 있다. 프로그램은 파일 시스템의 파일에 해당할 수 있지만 반드시 그럴 필요는 없다. 프로그램은 다른 프로그램이나 데이터를 보유하는 파일의 일부(예를 들어, 마크업 언어 문서에 저장된 하나 이상의 스크립트), 해당 프로그램 전용 단일 파일 또는 다수의 조정된 파일(예를 들어, 하나 이상의 모듈, 하위 프로그램 또는 코드 일부를 저장하는 파일)에 저장될 수 있다. 컴퓨터 프로그램은 하나의 컴퓨터 또는 하나의 사이트에 위치하거나 다수의 사이트에 걸쳐 분산되고 데이터 통신 네트워크로 상호 연결된 다수의 컴퓨터에서 실행되도록 배포될 수 있다.A computer program, which may also be referred to or described as a program, software, software application, app, module, software module, script, or code, is written in any form of programming language, including a compiled language, an interpreted language, a declarative language, or a procedural language. It may be distributed in any form, including as a stand-alone program, module, component, subroutine, or other unit suitable for use in a computing environment. Programs can, but do not have to, correspond to files in a file system. A program can be a portion of a file that holds other programs or data (for example, one or more scripts stored in a markup language document), a single file dedicated to that program, or a number of coordinated files (for example, one or more modules, subprograms, etc.). or a file that stores part of the code). A computer program may be distributed to run on a single computer, located at a single site, or distributed across multiple sites and interconnected by a data communications network.
본 명세서에서, "데이터베이스"라는 용어는 임의의 데이터 모음(collection)을 지칭하는데 광범위하게 사용되며, 데이터는 특정 방식으로 구성되거나 전혀 구성될 필요가 없으며 하나 이상의 위치에 있는 저장 디바이스에 저장될 수 있다. 따라서, 예를 들어 인덱스 데이터베이스에는 다수의 데이터 모음이 포함될 수 있으며, 각 데이터 모음은 다르게 구성되고 액세스될 수 있다.As used herein, the term "database" is used broadly to refer to any collection of data, which need not be organized in a particular way or at all, and may be stored on a storage device in one or more locations. . Thus, for example, an index database may contain multiple collections of data, each of which may be organized and accessed differently.
마찬가지로, 본 명세서에서 "엔진"이라는 용어는 하나 이상의 특정 기능을 수행하도록 프로그래밍된 소프트웨어 기반 시스템, 서브시스템 또는 프로세스를 지칭하는데 광범위하게 사용된다. 일반적으로, 엔진은 하나 이상의 위치에 있는 하나 이상의 컴퓨터에 설치된 하나 이상의 소프트웨어 모듈 또는 구성 요소로 구현된다. 일부 경우, 하나 이상의 컴퓨터는 특정 엔진 전용으로 사용되고 다른 경우에서는 다수의 엔진이 동일한 컴퓨터 또는 컴퓨터들에 설치되어 실행될 수 있다.Likewise, the term “engine” is used broadly herein to refer to a software-based system, subsystem, or process that is programmed to perform one or more specific functions. Typically, an engine is implemented as one or more software modules or components installed on one or more computers at one or more locations. In some cases, one or more computers may be dedicated to a particular engine, and in other cases multiple engines may be installed and run on the same computer or computers.
본 명세서에 설명된 프로세스 및 논리 흐름은 입력 데이터에 대해 작동하고 출력을 생성함으로써 기능을 수행하는 하나 이상의 컴퓨터 프로그램을 실행하는 하나 이상의 프로그래밍 가능한 컴퓨터에 의해 수행될 수 있다. 프로세스 및 논리 흐름은 FPGA 또는 ASIC과 같은 특수 목적 논리 회로에 의해 수행되거나 특수 목적 논리 회로와 하나 이상의 프로그래밍된 컴퓨터의 조합에 의해 수행될 수도 있다.The processes and logic flows described herein may be performed by one or more programmable computers executing one or more computer programs that perform functions by operating on input data and producing output. Processes and logic flows may be performed by special-purpose logic circuits, such as FPGAs or ASICs, or by a combination of special-purpose logic circuits and one or more programmed computers.
컴퓨터 프로그램 실행에 적합한 컴퓨터는 범용 또는 특수 목적의 마이크로프로세서 또는 둘 다를 기반으로 하거나 다른 종류의 중앙 처리 장치를 기반으로 할 수 있다. 일반적으로, 중앙 처리 유닛(장치)은 판독 전용 메모리나 랜덤 액세스 메모리 또는 둘 다로부터 명령과 데이터를 수신한다. 컴퓨터의 필수 요소는 명령을 수행하거나 실행하는 중앙 처리 유닛과 명령 및 데이터를 저장하는 하나 이상의 메모리 디바이스이다. 중앙 처리 유닛과 메모리는 특수 목적 논리 회로에 의해 보완되거나 통합될 수 있다. 일반적으로, 컴퓨터는 또한 데이터를 저장하기 위한 하나 이상의 대용량 저장 디바이스, 예를 들어 자기, 광자기 디스크 또는 광 디스크로부터 데이터를 수신하거나 전송하거나 둘 모두를 포함하거나 작동 가능하게 결합될 것이다. 그러나, 컴퓨터에 이러한 디바이스들이 있을 필요는 없다. 더욱이, 컴퓨터는 다른 디바이스, 예를 들어 휴대폰, PDA(Personal Digital Assistant), 모바일 오디오 또는 비디오 플계층, 게임 콘솔, GPS(Global Positioning System) 수신기, 또는 휴대용 저장 디바이스(예를 들어, USB(범용 직렬 버스) 플래시 드라이브) 등에 내장될 수 있다.A computer suitable for running computer programs may be based on a general-purpose or special-purpose microprocessor, or both, or on another type of central processing unit. Typically, a central processing unit (device) receives instructions and data from read-only memory, random access memory, or both. The essential elements of a computer are a central processing unit that carries out or executes instructions and one or more memory devices that store instructions and data. The central processing unit and memory may be supplemented or integrated by special-purpose logic circuits. Typically, a computer will also include, or be operably coupled to, one or more mass storage devices for storing data, such as magnetic, magneto-optical or optical disks, or both. However, your computer does not need to have these devices. Moreover, the computer can connect to other devices, such as a cell phone, personal digital assistant (PDA), mobile audio or video processor, game console, Global Positioning System (GPS) receiver, or portable storage device (such as a USB (Universal Serial) It can be embedded in a bus), flash drive, etc.
컴퓨터 프로그램 명령 및 데이터를 저장하는데 적합한 컴퓨터 판독 가능 매체에는 예를 들어 반도체 메모리 디바이스(예를 들어, EPROM, EEPROM 및 플래시 메모리 디바이스); 자기 디스크(예를 들어, 내부 하드 디스크 또는 이동식 디스크); 광자기 디스크; CD ROM 및 DVD-ROM 디스크를 비롯하여 모든 형태의 비휘발성 메모리, 매체 및 메모리 디바이스가 포함된다. . Computer-readable media suitable for storing computer program instructions and data include, for example, semiconductor memory devices (e.g., EPROM, EEPROM, and flash memory devices); Magnetic disks (e.g., internal hard disks or removable disks); magneto-optical disk; Includes all forms of non-volatile memory, media, and memory devices, including CD ROM and DVD-ROM disks. .
사용자와의 상호 작용을 제공하기 위해, 본 명세서에 설명된 주제의 실시예는 정보를 표시하기 위한 디스플레이 디바이스(예를 들어, CRT(음극선관) 또는 LCD(액정 디스플레이) 모니터)와 사용자가 컴퓨터에 입력을 제공할 수 있는 키보드 및 포인팅 디바이스(예를 들어, 마우스 또는 트랙볼)를 갖춘 컴퓨터에서 구현될 수 있다. 사용자와의 상호작용을 제공하기 위해 다른 종류의 장치도 사용될 수 있는데, 예를 들어, 사용자에게 제공되는 피드백은 시각적 피드백, 청각 피드백 또는 촉각 피드백과 같은 임의의 형태의 감각 피드백일 수 있고, 사용자로부터의 입력은 음향, 음성 또는 촉각 입력을 포함한 모든 형태로 수신될 수 있다. 더욱이, 컴퓨터는 사용자가 사용하는 디바이스와 문서를 주고받는 방식으로 사용자와 상호 작용할 수 있는데, 예를 들어, 웹 브라우저에서 받은 요청에 대한 응답으로 사용자 디바이스의 웹 브라우저로 웹 페이지를 보낸다. 또한, 컴퓨터는 문자 메시지 또는 다른 형태의 메시지를 개인 디바이스(예를 들어, 메시징 애플리케이션을 실행하는 스마트폰)로 전송하고 그 대가로 사용자로부터 응답 메시지를 수신함으로써 사용자와 상호 작용할 수 있다.To provide interaction with a user, embodiments of the subject matter described herein may include a display device (e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor) for displaying information and a display device (e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor) for displaying information and allowing the user to access the computer. The implementation may be implemented on a computer equipped with a keyboard and a pointing device (e.g., a mouse or trackball) capable of providing input. Other types of devices may also be used to provide interaction with the user, for example, the feedback provided to the user may be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback, and The input may be received in any form, including acoustic, voice, or tactile input. Moreover, the computer may interact with the user by exchanging documents with the device the user is using, for example, sending a web page to the web browser on the user's device in response to a request received from the web browser. Additionally, the computer may interact with the user by sending text messages or other forms of messages to a personal device (e.g., a smartphone running a messaging application) and receiving response messages from the user in return.
기계 학습 모델을 구현하기 위한 데이터 처리 장치는 또한 예를 들어, 기계 학습 트레이닝 또는 생산의 공통적이고 컴퓨팅 집약적인 부분, 즉 추론, 워크로드를 처리하기 위한 특수 목적 하드웨어 가속기 유닛을 포함할 수 있다.Data processing devices for implementing machine learning models may also include special-purpose hardware accelerator units for processing common, compute-intensive parts of machine learning training or production, i.e., inference, workloads, for example.
기계 학습 모델은 기계 학습 프레임워크 예를 들어, TensorFlow 프레임워크, Microsoft Cognitive Toolkit 프레임워크, Apache Singa 프레임워크 또는 Apache MXNet 프레임워크를 사용하여 구현 및 배포될 수 있다.Machine learning models can be implemented and deployed using machine learning frameworks, such as the TensorFlow framework, Microsoft Cognitive Toolkit framework, Apache Singa framework, or Apache MXNet framework.
본 명세서에 설명된 주제의 실시예는 백엔드 구성요소(예를 들어, 데이터 서버)를 포함하거나, 미들웨어 구성 요소(예를 들어, 애플리케이션 서버)를 포함하거나, 프런트엔드 구성 요소(예를 들어, 사용자가 본 명세서에 설명된 주제의 구현과 상호 작용할 수 있는 그래픽 사용자 인터페이스, 웹 브라우저 또는 앱을 갖춘 클라이언트 컴퓨터)를 포함하거나, 또는 백엔드, 미들웨어 또는 프런트엔드 구성 요소 중 하나 이상의 조합을 포함하는 컴퓨팅 시스템에서 구현될 수 있다. 시스템의 구성 요소는 통신 네트워크와 같은 디지털 데이터 통신의 모든 형태나 매체를 통해 상호 연결될 수 있다. 통신 네트워크의 예로는 LAN(Local Area Network) 및 WAN(Wide Area Network), 예를 들어 인터넷이 포함된다.Embodiments of the subject matter described herein may include a back-end component (e.g., a data server), a middleware component (e.g., an application server), or a front-end component (e.g., a user (a client computer equipped with a graphical user interface, web browser, or app capable of interacting with implementations of the subject matter described herein), or on a computing system that includes a combination of one or more of backend, middleware, or frontend components. It can be implemented. The components of a system may be interconnected through any form or medium of digital data communication, such as a telecommunications network. Examples of communications networks include local area networks (LANs) and wide area networks (WANs), such as the Internet.
컴퓨팅 시스템에는 클라이언트와 서버가 포함될 수 있다. 클라이언트와 서버는 일반적으로 서로 멀리 떨어져 있으며 일반적으로 통신 네트워크를 통해 상호 작용한다. 클라이언트와 서버의 관계는 각 컴퓨터에서 실행되고 서로 클라이언트-서버 관계를 갖는 컴퓨터 프로그램으로 인해 발생한다. 일부 실시예에서, 서버는 예를 들어 클라이언트 역할을 하는 장치와 상호 작용하는 사용자에게 데이터를 디스플레이하고 사용자 입력을 수신할 목적으로 데이터(예를 들어, HTML 페이지)를 사용자 디바이스로 전송한다. 사용자 디바이스에서 생성된 데이터(예를 들어, 사용자 상호 작용의 결과)는 디바이스로부터 서버에 수신될 수 있다.A computing system may include clients and servers. Clients and servers are usually remote from each other and typically interact through a communications network. The relationship between client and server arises due to computer programs running on each computer and having a client-server relationship with each other. In some embodiments, a server transmits data (e.g., an HTML page) to a user device, for example, for the purpose of displaying data and receiving user input to a user interacting with the device acting as a client. Data generated on a user device (eg, results of user interactions) may be received from the device to a server.
본 명세서에는 많은 구체적인 구현 세부 정보가 포함되어 있지만, 이는 임의의 발명의 범위 또는 청구될 수 있는 범위에 대한 제한으로 해석되어서는 안 되며, 오히려 특정 발명의 특정 실시예에 특정할 수 있는 특징들에 대한 설명으로 해석되어야 한다. 별도의 실시예와 관련하여 본 명세서에 설명된 특정 특징은 단일 실시예에서 조합하여 구현될 수도 있다. 반대로, 단일 실시예의 맥락에서 설명된 다양한 특징은 다수의 실시예에서 개별적으로 또는 임의의 적절한 하위 조합으로 구현될 수도 있다. 더욱이, 위에서는 특징들이 특정 조합으로 작용하는 것으로 설명될 수 있고 심지어 처음에는 그렇게 주장되었을 수도 있지만, 청구된 조합의 하나 이상의 특징은 경우에 따라 조합에서 삭제될 수 있으며, 청구된 조합은 하위 조합 또는 하위 조합의 변형과 관련될 수 있다.Although this specification contains many specific implementation details, this should not be construed as a limitation on the scope of any invention or what may be claimed, but rather as a description of features that may be specific to particular embodiments of a particular invention. It should be interpreted as an explanation. Certain features described herein in relation to separate embodiments may also be implemented in combination in a single embodiment. Conversely, various features described in the context of a single embodiment may be implemented in multiple embodiments individually or in any suitable sub-combination. Moreover, although the features above may be described, and may even have initially been claimed, as operating in a particular combination, one or more features of a claimed combination may in some cases be deleted from the combination, and the claimed combination may be a sub-combination or It may be related to variations in sub-combinations.
유사하게, 동작들은 특정 순서로 도면에 묘사되고 청구범위에 기재되어 있지만, 이는 원하는 결과를 달성하기 위해 그러한 동작들이 표시된 특정 순서 또는 순차적 순서로 수행되거나 모든 설명된 동작이 수행되어야 한다고 요구하는 것으로 이해되어서는 안 된다. 특정 상황에서는 멀티태스킹과 병렬 처리가 유리할 수 있다. 더욱이, 전술한 실시예에서 다양한 시스템 모듈 및 구성요소의 분리는 모든 실시예에서 그러한 분리를 요구하는 것으로 이해되어서는 안 되며, 설명된 프로그램 구성 요소 및 시스템은 일반적으로 단일 소프트웨어 제품에 함께 통합되거나 다수의 소프트웨어 제품에 패키지될 수 있다는 점을 이해해야 한다.Similarly, although acts are depicted in the drawings and recited in the claims in a particular order, this is to be understood as requiring that those acts be performed in the particular order shown or sequential order or that all described acts be performed to achieve the desired result. It shouldn't be. In certain situations, multitasking and parallel processing can be advantageous. Moreover, the separation of various system modules and components in the foregoing embodiments should not be construed as requiring such separation in all embodiments, and the described program components and systems are generally integrated together in a single software product or in multiple instances. You should understand that it can be packaged into a software product.
주제의 특정 실시예들이 설명되었다. 다른 실시예는 다음 청구범위의 범위 내에 있다. 예를 들어, 청구범위에 인용된 동작들은 다른 순서로 수행될 수 있으며 여전히 원하는 결과를 얻을 수 있다. 일 예로서, 첨부 도면에 도시된 프로세스는 바람직한 결과를 달성하기 위해 도시된 특정 순서 또는 순차적 순서를 반드시 필요로 하는 것은 아니다. 일부 경우에는 멀티태스킹과 병렬 처리가 유리할 수 있다.Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the operations recited in the claims can be performed in a different order and still obtain the desired result. By way of example, the processes depicted in the accompanying drawings do not necessarily require the specific order or sequential order shown to achieve desirable results. In some cases, multitasking and parallel processing can be advantageous.
Claims (15)
시퀀스로 배열된 복수의 계층을 포함하는 신경망을 나타내는 데이터를 수신하는 단계와;
복수의 계층으로부터 하나 이상의 계층 그룹을 선택하는 단계와, 상기 계층 그룹 각각은 시퀀스에서 서로 인접한 하나 이상의 계층을 포함하고;
신경망에 대응하는 새로운 기계 학습 모델을 생성하는 단계를 포함하고, 상기 새로운 기계 학습 모델을 생성하는 단계는,
각 계층 그룹에 대해, 계층 그룹을 대체하는 개별 의사결정 트리를 선택하는 단계를 포함하며, 상기 개별 의사결정 트리는 입력으로 그룹 내의 각각의 첫 번째 계층에 대한 입력의 양자화(quantized) 버전을 수신하고 출력으로 그룹 내의 각각의 마지막 계층 출력의 양자화 버전을 생성하고, 상기 개별 의사결정 트리의 트리 깊이는 그룹의 계층 수에 적어도 부분적으로 기초하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.1. A method implemented by one or more computers, said method comprising:
Receiving data representing a neural network comprising a plurality of layers arranged in a sequence;
selecting one or more layer groups from a plurality of layers, each layer group comprising one or more layers adjacent to each other in the sequence;
A step of generating a new machine learning model corresponding to a neural network, wherein the step of generating the new machine learning model includes,
For each layer group, selecting an individual decision tree to replace the layer group, wherein the individual decision tree receives as input a quantized version of the input for each first layer in the group and outputs generating a quantized version of the output of each last layer in a group, wherein the tree depth of the individual decision tree is based at least in part on the number of layers in the group.
신경망에 대한 트레이닝 데이터에 기초하여, 개별 의사 의사결정 트리에 의해 대체되지 않은 신경망의 계층들 중 적어도 일부를 트레이닝함으로써 새로운 기계 학습 모델을 트레이닝하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to paragraph 1,
Based on the training data for the neural network, training a new machine learning model by training at least some of the layers of the neural network that have not been replaced by the individual decision tree. How to implement it.
개별 의사결정 트리에 의해 대체되지 않은 신경망의 계층들 중 적어도 일부를 트레이닝하는 단계는,
시퀀스에 따라 신경망의 하나 이상의 계층 그룹을 뒤따르는 신경망의 계층들을 트레이닝하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to paragraph 2,
Training at least some of the layers of the neural network that have not been replaced by individual decision trees comprises:
One or more computer-implemented methods, comprising training layers of a neural network that follow one or more groups of layers of the neural network according to a sequence.
하나 이상의 계층 그룹 각각을 선택하는 단계는,
신경망에서 개별 초기 계층을 선택하는 단계와;
각각이 후보 그룹의 첫 번째 계층으로서 개별 초기 계층을 갖는 각각의 복수의 후보 그룹을 생성하는 단계와;
각각의 복수의 후보 그룹 각각에 대해, 후보 그룹의 계층이 개별 의사결정 트리에 의해 대체된 대응하는 새로운 기계 학습 모델의 성능을 측정하는 후보 그룹에 대한 개별 성능 측정치를 결정하는 단계와; 그리고
그룹으로서, 각각의 복수의 후보 그룹에 대한 개별 성능 측정치에 기초하여 후보 그룹 중 하나를 선택하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to any one of claims 1 to 3,
The steps for selecting each of one or more hierarchical groups are:
selecting individual initial layers in the neural network;
generating a plurality of candidate groups, each having a respective initial layer as the first layer of the candidate group;
For each of the plurality of candidate groups, determining an individual performance measure for the candidate group that measures the performance of a corresponding new machine learning model whose hierarchy of candidate groups has been replaced by an individual decision tree; and
At least one computer-implemented method comprising selecting one of the candidate groups based on individual performance measurements for each of the plurality of candidate groups, as a group.
개별 계층 그룹을 생성하기 위해, 신경망에서 개별 초기 계층을 선택하는 단계는,
랜덤 프로세스에 의해 또는 신경망의 시퀀스에 기초하여 개별 초기 계층을 선택하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to clause 4,
To create individual layer groups, the steps to select individual initial layers in the neural network are:
One or more computer-implemented methods, comprising selecting individual initial layers by a random process or based on a sequence in a neural network.
그룹으로서, 개별 성능 측정치에 기초하여 후보 그룹 중 하나를 선택하는 단계는,
개별 성능 측정치 중에서 최대 성능 측정치를 결정하는 단계와; 그리고
그룹으로서, 각각의 복수의 후보 그룹으로부터 최대 성능 측정치와 연관된 후보 그룹을 선택하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to clause 4 or 5,
As a group, selecting one of the candidate groups based on individual performance measures includes:
determining a maximum performance measure from among the individual performance measures; and
At least one computer-implemented method comprising selecting, as a group, a candidate group associated with a maximum performance measure from each of the plurality of candidate groups.
그룹 내의 각각의 첫 번째 계층에 대한 입력의 양자화 버전 및 그룹 내의 각각의 마지막 계층의 출력의 양자화 버전은,
이진 또는 삼진 양자화를 사용하여 생성되는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to any one of claims 1 to 6,
The quantized version of the input for each first layer in the group and the quantized version of the output of each last layer in the group are:
One or more computer-implemented methods characterized by being generated using binary or ternary quantization.
계층 그룹을 대체하는 개별 의사결정 트리 계층은,
기울기 부스트(GradientBoost) 의사결정 트리 또는 적응적 부스트(AdaBoost) 의사결정 트리를 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to any one of claims 1 to 7,
Individual decision tree layers replace groups of layers:
One or more computer-implemented methods comprising a GradientBoost decision tree or an Adaptive Boost (AdaBoost) decision tree.
각각의 계층은 개별 가중치 세트를 포함하고, 상기 방법은,
하나 이상의 계층 그룹에 속하지 않은 신경망의 각 계층에 대해, 계층과 연관된 가중치의 적어도 일부를 양자화하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to any one of claims 1 to 8,
Each layer contains a separate set of weights, and the method:
A method implemented by one or more computers, further comprising, for each layer of a neural network that does not belong to one or more layer groups, quantizing at least a portion of the weights associated with the layer.
개별 의사결정 트리의 트리 깊이는 그룹의 계층 수와 동일한 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to any one of claims 1 to 9,
A method of implementation by one or more computers, wherein the tree depth of an individual decision tree is equal to the number of layers of the group.
그룹 내의 각각의 첫 번째 계층에 대한 입력의 양자화 버전 또는 그룹 내의 각각의 마지막 계층의 출력의 양자화 버전은,
하나 이상의 스케일링 인자에 의해 생성되는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to any one of claims 1 to 10,
The quantized version of the input for each first layer in the group or the quantized version of the output of each last layer in the group is:
One or more computer-implemented methods, characterized in that they are generated by one or more scaling factors.
수신된 데이터에 의해 표현되는 신경망은 트레이닝 데이터 세트에 의해 초기 트레이닝된 신경망이고,
개별 계층 그룹을 대체하는 각 의사결정 트리는 트레이닝 데이터 세트의 양자화 버전의 개별 부분에 기초하여 트레이닝되었으며,
트레이닝 데이터 세트의 양자화 버전의 개별 부분의 각 트레이닝 샘플은
(i) 그룹 내의 첫 번째 계층에 대한 계층 입력의 양자화 버전, 및 (ii) 그룹의 마지막 계층의 계층 출력의 양자화 버전을 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to any one of claims 1 to 11,
The neural network represented by the received data is a neural network initially trained by the training data set,
Each decision tree replacing each individual layer group was trained based on individual parts of the quantized version of the training data set;
Each training sample from a separate part of the quantized version of the training data set is
One or more computer-implemented methods comprising: (i) a quantized version of the layer input for the first layer in the group, and (ii) a quantized version of the layer output of the last layer in the group.
새로운 기계 학습 모델을 구현하도록 구성된 시스템에 새로운 기계 학습 모델을 출력하는 단계를 더 포함하고,
시스템은 추가, 선택 또는 전환 기능으로부터 선택된 하나 이상의 기능을 통해 의사결정 트리를 구현하기 위한 하나 이상의 컴퓨팅 유닛을 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의한 구현 방법.According to any one of claims 1 to 12,
further comprising outputting the new machine learning model to a system configured to implement the new machine learning model,
One or more computer-implemented methods, wherein the system includes one or more computing units for implementing a decision tree with one or more functions selected from add, select or switch functions.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2021/031636 WO2022240391A1 (en) | 2021-05-10 | 2021-05-10 | Incorporation of decision trees in a neural network |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20230162721A true KR20230162721A (en) | 2023-11-28 |
Family
ID=76250447
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020237038523A KR20230162721A (en) | 2021-05-10 | 2021-05-10 | Integrating decision trees into neural networks |
Country Status (4)
Country | Link |
---|---|
EP (1) | EP4315165A1 (en) |
KR (1) | KR20230162721A (en) |
CN (1) | CN117396888A (en) |
WO (1) | WO2022240391A1 (en) |
-
2021
- 2021-05-10 CN CN202180098074.1A patent/CN117396888A/en active Pending
- 2021-05-10 KR KR1020237038523A patent/KR20230162721A/en unknown
- 2021-05-10 WO PCT/US2021/031636 patent/WO2022240391A1/en active Application Filing
- 2021-05-10 EP EP21729708.4A patent/EP4315165A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2022240391A1 (en) | 2022-11-17 |
CN117396888A (en) | 2024-01-12 |
EP4315165A1 (en) | 2024-02-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN109885842B (en) | Processing text neural networks | |
US11423233B2 (en) | On-device projection neural networks for natural language understanding | |
CN107836000B (en) | Improved artificial neural network method and electronic device for language modeling and prediction | |
CN112860866B (en) | Semantic retrieval method, device, equipment and storage medium | |
US11010664B2 (en) | Augmenting neural networks with hierarchical external memory | |
CN111274811A (en) | Address text similarity determining method and address searching method | |
JP2021152963A (en) | Word meaning feature generating method, model training method, apparatus, device, medium, and program | |
CN111368993A (en) | Data processing method and related equipment | |
US11915129B2 (en) | Method and system for table retrieval using multimodal deep co-learning with helper query-dependent and query-independent relevance labels | |
CN112016332A (en) | Multi-modal machine translation method based on variational reasoning and multi-task learning | |
CN112749300B (en) | Method, apparatus, device, storage medium and program product for video classification | |
JP2024512628A (en) | Method and apparatus for generating a caption generator and method and apparatus for outputting a caption | |
CN113761868A (en) | Text processing method and device, electronic equipment and readable storage medium | |
CN116757224A (en) | Intent understanding method, apparatus, device, and medium | |
CN113535912B (en) | Text association method and related equipment based on graph rolling network and attention mechanism | |
US20220138425A1 (en) | Acronym definition network | |
CN117435685A (en) | Document retrieval method, document retrieval device, computer equipment, storage medium and product | |
KR20230162721A (en) | Integrating decision trees into neural networks | |
CN112966513B (en) | Method and apparatus for entity linking | |
CN117371447A (en) | Named entity recognition model training method, device and storage medium | |
CN110442706B (en) | Text abstract generation method, system, equipment and storage medium | |
JP2024519326A (en) | Embedding decision trees in neural networks | |
CN114115878A (en) | Workflow node recommendation method and device | |
CN113239215B (en) | Classification method and device for multimedia resources, electronic equipment and storage medium | |
CN116611477B (en) | Training method, device, equipment and medium for data pruning method and sequence model |