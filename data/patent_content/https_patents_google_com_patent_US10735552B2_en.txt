US10735552B2 - Secondary transmissions of packetized data - Google Patents
Secondary transmissions of packetized data Download PDFInfo
- Publication number
- US10735552B2 US10735552B2 US15/603,701 US201715603701A US10735552B2 US 10735552 B2 US10735552 B2 US 10735552B2 US 201715603701 A US201715603701 A US 201715603701A US 10735552 B2 US10735552 B2 US 10735552B2
- Authority
- US
- United States
- Prior art keywords
- interface
- candidate
- component
- content
- computing device
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 208000032370 Secondary transmission Diseases 0.000 title 1
- 230000005540 biological transmission Effects 0.000 claims abstract description 40
- 238000012545 processing Methods 0.000 claims description 280
- 230000005236 sound signal Effects 0.000 claims description 115
- 238000000034 method Methods 0.000 claims description 104
- 230000015654 memory Effects 0.000 claims description 55
- 230000008569 process Effects 0.000 claims description 36
- 238000001914 filtration Methods 0.000 claims description 2
- 230000009471 action Effects 0.000 description 176
- 238000007726 management method Methods 0.000 description 54
- 230000004044 response Effects 0.000 description 38
- 238000009877 rendering Methods 0.000 description 36
- 238000004891 communication Methods 0.000 description 34
- 238000006243 chemical reaction Methods 0.000 description 22
- 238000003860 storage Methods 0.000 description 19
- 238000013515 script Methods 0.000 description 12
- 230000000475 sunscreen effect Effects 0.000 description 12
- 239000000516 sunscreening agent Substances 0.000 description 12
- 239000000047 product Substances 0.000 description 11
- 238000004590 computer program Methods 0.000 description 9
- 238000012384 transportation and delivery Methods 0.000 description 9
- 238000010586 diagram Methods 0.000 description 8
- 230000009193 crawling Effects 0.000 description 6
- 230000000694 effects Effects 0.000 description 6
- 238000013459 approach Methods 0.000 description 4
- 238000004422 calculation algorithm Methods 0.000 description 4
- 230000006870 function Effects 0.000 description 4
- 230000000670 limiting effect Effects 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 4
- 230000008901 benefit Effects 0.000 description 3
- 238000004364 calculation method Methods 0.000 description 3
- 238000009826 distribution Methods 0.000 description 3
- 230000003993 interaction Effects 0.000 description 3
- 238000013439 planning Methods 0.000 description 3
- 230000002829 reductive effect Effects 0.000 description 3
- 238000012552 review Methods 0.000 description 3
- 230000000007 visual effect Effects 0.000 description 3
- 230000001413 cellular effect Effects 0.000 description 2
- 235000014510 cooky Nutrition 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 230000002708 enhancing effect Effects 0.000 description 2
- 230000036541 health Effects 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 230000001737 promoting effect Effects 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 239000013589 supplement Substances 0.000 description 2
- 230000001360 synchronised effect Effects 0.000 description 2
- IRLPACMLTUPBCL-KQYNXXCUSA-N 5'-adenylyl sulfate Chemical compound C1=NC=2C(N)=NC=NC=2N1[C@@H]1O[C@H](COP(O)(=O)OS(O)(=O)=O)[C@@H](O)[C@H]1O IRLPACMLTUPBCL-KQYNXXCUSA-N 0.000 description 1
- 244000141353 Prunus domestica Species 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000003416 augmentation Effects 0.000 description 1
- 230000003190 augmentative effect Effects 0.000 description 1
- 238000013475 authorization Methods 0.000 description 1
- 238000003287 bathing Methods 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 239000003795 chemical substances by application Substances 0.000 description 1
- 238000012790 confirmation Methods 0.000 description 1
- 238000001816 cooling Methods 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000003306 harvesting Methods 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 238000003780 insertion Methods 0.000 description 1
- 230000037431 insertion Effects 0.000 description 1
- 238000009434 installation Methods 0.000 description 1
- 230000002452 interceptive effect Effects 0.000 description 1
- 238000005304 joining Methods 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 230000005055 memory storage Effects 0.000 description 1
- 238000010295 mobile communication Methods 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 230000036961 partial effect Effects 0.000 description 1
- 238000013138 pruning Methods 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000012549 training Methods 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000001960 triggered effect Effects 0.000 description 1
- XLYOFNOQVPJJNP-UHFFFAOYSA-N water Substances O XLYOFNOQVPJJNP-UHFFFAOYSA-N 0.000 description 1
Images
Classifications
-
- H04L67/32—
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/60—Scheduling or organising the servicing of application requests, e.g. requests for application data transmissions using the analysis and optimisation of the required network resources
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L43/00—Arrangements for monitoring or testing data switching networks
- H04L43/08—Monitoring or testing based on specific metrics, e.g. QoS, energy consumption or environmental parameters
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
-
- H04L67/42—
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
Definitions
- Excessive network transmissions, packet-based or otherwise, of network traffic data between computing devices can prevent a computing device from properly processing the network traffic data, completing an operation related to the network traffic data, or timely responding to the network traffic data.
- the excessive network transmissions of network traffic data can also complicate data routing or degrade the quality of the response if the responding computing device is at or above its processing capacity, which may result in inefficient bandwidth utilization.
- the control of network transmissions corresponding to content item objects can be complicated by the large number of content item objects that can initiate network transmissions of network traffic data between computing devices.
- a system to transmit packetized data in a voice activated computer network environment can include a data processing system.
- the data processing system can include a processor and a memory.
- the data processing system can receive, via an interface, data packets that can include an input audio signal detected by a sensor of a client computing device.
- the data processing system can identify a first request within the input audio signal detected by the sensor of the client computing device.
- the data processing system can determine, based on the first request, a primary search result having a primary digital component and a secondary search result URL related to the primary search result.
- the data processing system can identify a plurality of canonicalized digital components associated with the secondary search result URL.
- the data processing system can calculate a respective score for each of the plurality of canonicalized digital components.
- the data processing system can select one of the plurality of canonicalized digital components based on the respective score for each of the plurality of canonicalized digital components and a filter rule.
- the data processing system can transmit a primary output audio signal comprising the primary digital component.
- the data processing system can transmit a secondary output signal comprising the selected one of the plurality of canonicalized digital components.
- a method of data transmission in a voice activated computer network environment can include receiving, via an interface, data packets comprising an input audio signal detected by a sensor of a client computing device.
- the method can include identifying a first request within the input audio signal detected by the sensor of the client computing device.
- the method can include determining, based on the first request, a primary search result having a primary digital component and a secondary search result URL related to the primary search result.
- the method can include identifying a plurality of canonicalized digital components associated with the secondary search result URL.
- the method can include calculating a respective score for each of the plurality of canonicalized digital components.
- the method can include selecting one of the plurality of canonicalized digital components based on the respective score for each of the plurality of canonicalized digital components and a filter rule.
- the method can include transmitting a primary output audio signal comprising the primary digital component.
- the method can include transmitting a secondary output signal comprising the selected one of the plurality of canonicalized digital components.
- FIG. 1 is a block diagram depicting an example environment.
- FIG. 2A is a diagram of an example serving system shown in FIG. 1 , in which an aspect of the methods and systems described herein may be employed in accordance with one embodiment of the present disclosure.
- FIG. 2B depicts a system to of multi-modal transmission of packetized data in a voice activated computer network environment.
- FIG. 2C depicts a flow diagram for multi-modal transmission of packetized data in a voice activated computer network environment.
- FIG. 3A is a sample screenshot showing representative search results arising from a search specified by a user.
- FIG. 3B is an example screenshot showing representative search results arising from a search specified by a user, in accordance with one embodiment of the present disclosure, in which additional or secondary sitelinks with associated creative texts are provided.
- FIG. 4A is a flowchart of an example method for enhancing sitelinks with creative content.
- FIG. 4B illustrates a block diagram of an example method of transmitting data in a voice activated computer network in accordance with one embodiment of the present disclosure.
- FIG. 5 is a diagram of example computing systems that may be used in the environment shown in FIG. 1 in accordance with one embodiment of the present disclosure.
- FIG. 6 is an example bipartite graph that may be used in matching sitelinks with creative content in accordance with one embodiment of the present disclosure.
- FIG. 7 is another example bipartite graph that may be used in matching sitelinks with creative content in accordance with one embodiment of the present disclosure.
- Systems and methods of the present disclosure relate generally to a data processing system that identifies an optimal transmission modality for data packet (or other protocol based) transmission in a voice activated computer network environment.
- the data processing system can improve the efficiency and effectiveness of data packet transmission over one or more computer networks by, for example, selecting a transmission modality from a plurality of options for data packet routing through a computer network of content items to one or more client computing device, or to different interfaces (e.g., different apps or programs) of a single client computing device.
- Data packets or other protocol based signals corresponding to the selected operations can be routed through a computer network between multiple computing devices. For example the data processing system can route a content item to a different interface than an interface from which a request was received.
- the different interface can be on the same client computing device or a different client computing device from which a request was received.
- the data processing system can select at least one candidate interface from a plurality of candidate interfaces for content item transmission to a client computing device.
- the candidate interfaces can be determined based on technical or computing parameters such as processor capability or utilization rate, memory capability or availability, battery status, available power, network bandwidth utilization, interface parameters or other resource utilization values.
- the data processing system can reduce network bandwidth usage, latency, or processing utilization or power consumption of the client computing device that renders the content item. This saves processing power and other computing resources such as memory, reduces electrical power consumption by the data processing system and the reduced data transmissions via the computer network reduces bandwidth requirements and usage of the data processing system.
- the systems and methods described herein can include a data processing system that receives an input audio query, which can also be referred to as an input audio signal. From the input audio query the data processing system can identify a request and a trigger keyword corresponding to the request. Based on the trigger keyword or the request, the data processing system can generate a first action data structure.
- the first action data structure can include an organic response to the input audio query received from a client computing device, and the data processing system can provide the first action data structure to the same client computing device for rendering as audio output via the same interface from which the request was received.
- the data processing system can also select at least one content item based on the trigger keyword or the request.
- the data processing system can identify or determine a plurality of candidate interfaces for rendering of the content item(s).
- the interfaces can include one or more hardware or software interfaces, such as display screens, audio interfaces, speakers, applications or programs available on the client computing device that originated the input audio query, or on different client computing devices.
- the interfaces can include java script slots for online documents for the insertion of content items, as well as push notification interfaces.
- the data processing system can determine utilization values for the different candidate interfaces.
- the utilization values can indicate power, processing, memory, bandwidth, or interface parameter capabilities, for example.
- the data processing system can select a candidate interface as a selected interface for presentation or rendering of the content item. For example, the data processing system can convert or provide the content item for delivery in a modality compatible with the selected interface.
- the selected interface can be an interface of the same client computing device that originated the input audio signal or a different client computing device.
- the data processing system selects a destination for the content item in a manner that can use the least amount of processing power, memory, or bandwidth from available options, or that can conserve power of one or more client computing devices.
- the data processing system can provide the content item or the first action data structure by packet or other protocol based data message transmission via a computer network to a client computing device.
- the output signal can cause an audio driver component of the client computing device to generate an acoustic wave, e.g., an audio output, which can be output from the client computing device.
- the audio (or other) output can correspond to the first action data structure or to the content item.
- the first action data structure can be routed as audio output, and the content item can be routed as a text based message.
- the data processing system can conserve resources utilized by each interface, relative to providing both the first action data structure and the content item to the same interface. This results in fewer data processing operations, less memory usage, or less network bandwidth utilization by the selected interfaces (or their corresponding devices) than would be the case without separation and independent routing of the first action data structure and the content item.
- the subject matter described herein relates generally to online content and/or online content delivery.
- the methods and systems herein enable relevant items of creative text (“creatives”) stored in a content provider database to be matched with specific sitelinks.
- the resulting presentation to an online user referred to as an “enhanced sitelink,” provides additional relevant information regarding the sitelink.
- a typical content provider/content provider may have provided a content providing network or system with hundreds or thousands of creatives, each of which may be associated with one or more keywords, geographies or languages. Some of these creatives may be relevant to a set of sitelinks that the content provider may choose to add subsequently to a campaign.
- the sitelinks do not need to originate from or belong to the same content item campaign, content item group or other entity, as the creatives with which the sitelinks are ultimately matched, as long as the sitelinks and creatives are associated with the same content provider. From a content provider standpoint, having to manually manage and possibly duplicate the creatives for sitelinks purposes can be burdensome. Manual management of creative and sitelink matching may also create consistency issues that may arise when one of the creatives or campaigns needs to be paused or changed.
- the methods and systems described herein may be implemented using computer programming or engineering techniques including computer software, firmware, hardware or any combination or subset thereof, wherein the technical effect may be achieved by performing at least one of the following steps: a) storing within a memory device a plurality of creatives, each creative being associated with a uniform resource locator (URL); b) canonicalizing each URL associated with each of the plurality of creatives; c) clustering the plurality of canonicalized URLs into creative clusters, wherein each creative cluster includes a plurality of clustered creatives each having a substantially similar canonicalized URL associated therewith; d) receiving, at the computing device, a sitelink having a sitelink URL associated therewith; e) canonicalizing the received sitelink URL; (f) matching the canonicalized sitelink URL with one of the creative clusters to generate a candidate set of creatives for the received sitelink; g) associating a selected creative from the candidate set of creatives with the received sitelink based on at least one of filter rules
- an example content providing 100 may include one or more service providers 102 , one or more publishers 104 (which can be referred to as content providers 104 ), a data processing system (DPS) 106 , and one or more user access devices 108 (also referred to as client computing devices), used by one or more users 107 .
- User access devices 108 may be coupled to a network 110 .
- Each of the elements 102 , 104 , 106 , 108 and 110 in FIG. 1 may be implemented or associated with hardware components, software components, or firmware components or any combination of such components.
- the elements 102 , 104 , 106 , 108 and 110 can, for example, be implemented or associated with general purpose servers, software processes and engines, and/or various embedded systems.
- the elements 102 , 104 , 106 and 110 may serve, for example, as a content providing distribution network. While reference is made to distributing content items, the system 100 can be suitable for distributing other forms of content including other forms of sponsored content.
- the service providers 102 may include any entities that are associated with online content such as content items.
- a content item can include a digital component.
- a digital component is a content item.
- a digital component can include a content item.
- a content item can refer to any form of communication in which one or more products, services, ideas, messages, people, organizations or other items are identified and promoted (or otherwise communicated). Content items are not limited to commercial promotions or other communications.
- a content item may be a public service announcement or any other type of notice, such as a public notice published in printed or electronic press or a broadcast.
- a content item may be referred to or include sponsored content.
- Content items may be communicated via various mediums and in various forms.
- content items may be communicated through an interactive medium, such as the Internet, and may include graphical content items (e.g., banner content items), textual content items, image content items, audio content items, video content items, content items combining one of more of any of such components, or any form of electronically delivered content item.
- Content items may include embedded information, such as embedded media, links, meta-information, and/or machine executable instructions.
- Content items could also be communicated through RSS (Really Simple Syndication) feeds, radio channels, television channels, print media, and other media.
- RSS Resource Simple Syndication
- content item can refer to both a single content item or a group of content items.
- Content items can include or also be referred to as creatives.
- Creative can refer to any entity that represents one content item impression.
- a content item impression refers to any form of presentation of a content item such that it is viewable/receivable by a user. In some examples, a content item impression may occur when a content item is displayed on a display device of a user access device.
- a content item group refers, for example, to an entity that represents a group of creatives that share a common characteristic, such as having the same content item selection and recommendation criteria.
- Content item groups can be used to create a content item campaign.
- the service providers 102 may provide (or be otherwise associated with) products and/or services related to online content.
- the service providers 102 may include or be associated with, for example, retailers, wholesalers, warehouses, manufacturers, distributors, health care providers, educational establishments, financial establishments, technology providers, energy providers, utility providers, or any other product or service providers or distributors.
- the service providers 102 may directly or indirectly generate maintain, review and/or analyze online content, which may be related to products or services offered by or otherwise associated with the service providers 102 .
- the service providers 102 may include or maintain one or more processing unit 112 , such as servers or embedded systems, coupled to the network 110 .
- the service providers 102 may include or maintain one or more processes that run on one or more data processing systems.
- the publishers 104 may include any entities that generate, maintain, provide, present and/or otherwise process publications in the system 100 .
- the term “publications” refers to various types of web-based and/or otherwise presented information, such as articles, discussion threads, reports, analyses, financial statements, music, video, graphics, search results, web page listings, information feeds (e.g., RSS feeds), television broadcasts, radio broadcasts, printed publications, etc.
- the publishers 104 may have an Internet presence, such as online publication and news providers (e.g., online newspapers, online magazines, television websites, etc.), online service providers (e.g., financial service providers, health service providers, etc.), and the like.
- the publishers 104 can include television broadcasters, radio broadcasters, satellite broadcasters, and other publication providers.
- One or more of the publishers 104 may represent a publication network that is associated with the data processing system 106 .
- the publishers 104 may receive requests from the user access devices 108 (or other elements in the system 100 ) and provide or present publications to the requesting devices.
- the publishers may provide or present publications via various mediums and in various forms, including web based and non-web based mediums and forms.
- the publishers 104 may generate and/or maintain such publications and/or retrieve the publications from other network resources.
- the publishers 104 may be configured to integrate or combine retrieved publications with online content such as content items that are related or relevant to the retrieved content for display to users. As discussed further below, this relevant online content, such as content items, may be provided from the data processing system 106 and be combined with publications for display to users. In some examples, the publishers 104 may retrieve publications for display on a particular user access device 108 and then forward the publications to the user access device 108 along with code that causes one or more content items from the data processing system 106 to be displayed to the user. In other examples, the publishers 104 may retrieve publications, retrieve one or more relevant content items (e.g., from the data processing system 106 or the service providers 102 ), and then integrate the content items and the article to form a content page for display to the user.
- relevant online content such as content items
- this relevant online content such as content items
- the publishers 104 may retrieve publications for display on a particular user access device 108 and then forward the publications to the user access device 108 along with code that causes one or more content items from the data
- one or more of the publishers 104 may represent a publications network.
- the service providers 102 may be able to present content items to users through this publications network.
- the publishers 104 may include or maintain one or more processing unit 114 , such as servers or embedded systems, coupled to the network 110 . They may include or maintain one or more processes that run on data processing systems. In some examples, the publishers 104 may include one or more content repositories 124 for storing publications and other information.
- the data processing system 106 manages online content including content items and provides various services to the service providers 102 , the publishers 104 , and the user access devices 108 .
- the data processing system 106 may store online content, such as content items, in a content item repository 136 and facilitate the distribution or selective provision and recommendation of content items through the system 100 to the user access devices 108 .
- the data processing system 106 may include or access functionality associated with other content provider systems.
- the data processing system 106 may include one or more processing unit 116 , such as servers or embedded systems, coupled to the network 110 . It can also include one or more processes, such as server processes.
- the data processing system 106 may include a content item serving system 120 and one or more backend processing systems 118 .
- the content item serving system 120 may include one or more processing unit 116 and may perform functionality associated with delivering content items to publishers or user access devices.
- the backend processing systems 118 may include one or more processing unit 116 may perform functionality associated with identifying relevant content items to deliver, processing various rules, performing filtering processes, generating reports, maintaining accounts and usage information, and other backend system processing.
- the data processing system 106 can use the backend processing systems 118 and the content item serving system 120 to selectively recommend and provide relevant content items from the service providers 102 through the publishers 104 to the user access devices 108 .
- the data processing system 106 may include or access one or more crawling, indexing and searching modules (not shown). These modules may browse accessible resources (e.g., the World Wide Web, publisher content, data feeds, etc.) to identify, index and store information. The modules may browse information and create copies of the browsed information for subsequent processing. The modules may also check links, validate code, harvest information, and/or perform other maintenance or other tasks.
- crawling, indexing and searching modules may browse accessible resources (e.g., the World Wide Web, publisher content, data feeds, etc.) to identify, index and store information.
- the modules may browse information and create copies of the browsed information for subsequent processing.
- the modules may also check links, validate code, harvest information, and/or perform other maintenance or other tasks.
- Searching modules may search information from various resources, such as the World Wide Web, publisher content, intranets, newsgroups, databases, and/or directories.
- the search modules may employ one or more known search or other processes to search data.
- the search modules may index crawled content and/or content received from data feeds to build one or more search indices.
- the search indices may be used to facilitate rapid retrieval of information relevant to a search query.
- the data processing system 106 may include one or more interface or frontend modules for providing the various features to content providers, publishers, and user access devices.
- the data processing system 106 may provide one or more publisher front-end interfaces (PFEs) for allowing publishers to interact with the data processing system 106 .
- PFEs publisher front-end interfaces
- AFEs content provider front-end interfaces
- the front-end interfaces may be configured as web applications that provide users with network access to features available in the data processing system 106 .
- the data processing system 106 provides various online content management features to the service providers 102 .
- the data processing system 106 online content management features may allow users to set up user accounts, set account preferences, create content items, select keywords for content items, create campaigns or initiatives for multiple products or businesses, view reports associated with accounts, analyze costs and return on investment, selectively identify customers in different regions, selectively recommend and provide content items to particular publishers, analyze financial information, analyze content item performance, estimate content item traffic, access keyword tools, add graphics and animations to content items, etc.
- the data processing system 106 may allow the service providers 102 to create content items and input keywords for which those content items will appear. In some examples, the data processing system 106 may provide content to user access devices or publishers when keywords associated with that content are included in a user request or requested content. The data processing system 106 may also allow the service providers 102 to set bids for content items. A bid may represent the maximum amount a content provider is willing to pay for each content item impression, user click-through of a content item or other interaction with a content item. A click-through can include any action a user takes to select a content item. The service providers 102 may also choose a currency and monthly budget.
- the data processing system 106 may also allow the service providers 102 to view information about content item impressions, which may be maintained by the data processing system 106 .
- the data processing system 106 may be configured to determine and maintain the number of content item impressions relative to a particular website or keyword.
- the data processing system 106 may also determine and maintain the number of click-throughs for a content item as well as the ratio of click-throughs to impressions.
- the data processing system 106 may also allow the service providers 102 to select and/or create conversion types for content items.
- a “conversion” may occur when a user consummates a transaction related to a given content item.
- a conversion could be defined to occur when a user clicks on a content item, is referred to the content provider's web page, and consummates a purchase there before leaving that web page.
- a conversion could be defined as the display of a content item to a user and a corresponding purchase on the content provider's web page within a predetermined time (e.g., seven days).
- the data processing system 106 may store conversion data and other information in a conversion data repository 146 .
- the data processing system 106 may allow the service providers 102 to input description information associated with online content, such as content items. This information could be used to assist the publishers 104 in determining content items to publish.
- the service providers 102 may additionally input a cost/value associated with selected conversion types, such as a five dollar credit to the publishers 104 for each product or service purchased.
- the data processing system 106 may provide various features to the publishers 104 .
- the data processing system 106 may deliver content items (associated with the service providers 102 ) to the user access devices 108 when users access content from the publishers 104 .
- the data processing system 106 can be configured to deliver content items that are relevant to publisher sites, site content and publisher audiences.
- the data processing system 106 may crawl publications provided by the publishers 104 and deliver content items that are relevant to publisher sites, site publications and publisher audiences based on the crawled publications.
- the data processing system 106 may also selectively recommend and/or provide content items based on user information and behavior, such as particular search queries performed on a search engine website, etc.
- the data processing system 106 may store user-related information in a general database (not shown).
- the data processing system 106 can add search services (e.g., a search box) to a publisher site and deliver content items configured to provide appropriate and relevant content relative to search results generated by requests from visitors of the publisher site. A combination of these and other approaches can be used to deliver relevant content items.
- the data processing system 106 may allow the publishers 104 to search and select specific products and services as well as associated content items to be displayed with publications provided by the publishers 104 .
- the publishers 104 may search through content items in the content item repository 136 and select certain content items for display with their publications.
- the data processing system 106 may be configured to selectively recommend and provide content items created by the service providers 102 to the user access devices 108 directly or through the publishers 104 .
- the data processing system 106 may selectively recommend and provide online content, such as content items, to a particular publisher 104 (as described in further detail herein) or a requesting user access device 108 when a user requests search results or loads a publication from the publisher 104 .
- the data processing system 106 may manage and process financial transactions among and between elements in the system 100 .
- the data processing system 106 may credit accounts associated with the publishers 104 and debit accounts of the service providers 102 . These and other transactions may be based on conversion data, impressions information and/or click-through rates received and maintained by the data processing system 106 .
- the user access devices 108 may include any devices capable of receiving information from the network 110 .
- the user access devices 108 could include general computing components and/or embedded systems optimized with specific components for performing specific tasks. Examples of user access devices include personal computers (e.g., desktop computers), mobile computing devices, cell phones, smart phones, media players/recorders, music players, game consoles, media centers, media players, electronic tablets, personal digital assistants (PDAs), television systems, audio systems, radio systems, removable storage devices, navigation systems, set top boxes, other electronic devices and the like.
- PDAs personal digital assistants
- the user access devices 108 can also include various other elements, such as processes running on various machines.
- the network 110 may include any element or system that facilitates communications among and between various network nodes, such as elements 108 , 112 , 114 and 116 .
- the network 110 may include one or more telecommunications networks, such as computer networks, telephone or other communications networks, the Internet, etc.
- the network 110 may include a shared, public, or private data network encompassing a wide area (e.g., WAN) or local area (e.g., LAN).
- the network 110 may facilitate data exchange by way of packet switching using the Internet Protocol (IP).
- IP Internet Protocol
- the network 110 may facilitate wired and/or wireless connectivity and communication.
- system 100 further includes a website 148 including one or more resources 149 (e.g., text, images, multimedia content, and programming elements, such as scripts) associated with a domain name and hosted by one or more servers.
- Resources 149 can be relatively static (e.g., as in a publisher's webpage) or dynamically generated in response to user query (e.g., as in a search engine's result page).
- User devices 108 can request resources 149 from a website 148 .
- build data representing the resource 149 can be provided to the user access device 108 for presentation by the user access device 108 .
- the build data representing the resource 149 can also include data specifying a content item slot in which content items can be presented.
- the data processing system 106 receives a request for content items to be provided with the resource 149 .
- the request for content items can include characteristics of the content item slots (e.g., size, web address of the resource, media type of the requested content item, etc.) that are defined for the requested resource or search results page, and can be provided to the data processing system 106 .
- the data processing system 106 can identify content items that are eligible to be provided in response to the request. For example, eligible content items can have characteristics matching the characteristics of available content item slots and have content item serving keywords that match the specified resource keywords or search queries.
- Each service provider 102 can create one or more content item campaigns using various campaign parameters that are used to control distribution of the content provider's content items.
- Each content item campaign can include one or more content item groups that have modified campaign parameters that are specific to the content item group. Examples of campaign parameters can include content item serving keywords and corresponding bids, geographic or other factors used to facilitate content item serving, delivery period, publication network, keyword match type, as well as other parameters corresponding to one or more content items.
- the campaign data can be stored in the campaign data store 150 .
- the data processing system 106 can retrieve the information in the campaign data store 150 when preparing a response to a content item request.
- Dynamic content items are content items that are dynamically generated according to a content item template using one or more components.
- a content item template can be a creative that specifies one or more component slots each requiring a component of a desired component type, such as a background image, a headline, a promotional slogan, a product image, a price quote, a landing page URL, a call-to-action (e.g., a message promoting a viewer action such as “Register Now!”), and so on.
- a component can be associated with a single component type based on the component's structural or format characteristics or the component's function in the content item template.
- a component may also be associated with various attribute values (e.g., color, font, model number, customer rating, etc.).
- attribute values e.g., color, font, model number, customer rating, etc.
- a component is a data item that has structural and format qualities meeting the specifications of a component type. Components of the same component type are interchangeable in a corresponding component slot of a content item template when constructing a content item. Content items generated using different components for the same component slots are identical except for the portions of each content item that are affected by the content and/or attributes of the different components.
- Parameters related to a content item can include, for example, creative identifier, creative name, creative type, size, first line, web address of the landing page, display URL, media type, and so on.
- One of the creative types that a content provider can specify for a content item is the dynamic content item type.
- the content provider can provide a content item template as the creative, and the content item template can be selected (e.g., in the same manner as other types of creatives) to fulfill a received content item request for an available content item slot.
- a content item template or in other words, a dynamic content item creative
- a dynamic content item can be generated on-the-fly based on the content item template to fulfill the content item request.
- the data processing system 106 can have access to a large number of available components of various types, for example, through a component data feed store 156 .
- the components can have varying content.
- the component data feed store 156 can be provided and updated by the content provider from time to time.
- the component data feed store 156 can be linked to the content provider's product catalogs or other business data stores, such that real-time data can be made available to the data processing system 106 without active intervention by the content provider.
- the data processing system 106 can select components from among the large number of components available in the component data feed store 156 .
- the data processing system 106 can also apply the selected components to the component slots in a dynamic content item according to the specifications in a content item template selected from the content item template data store 152 .
- the dynamic content item can be provided by an data processing system to fulfill the received content item request.
- a component selection module 158 can be implemented to carry out actions related to component selection.
- the component selection module 158 can be part of the data processing system 106 or a standalone module in communication with the data processing system 106 .
- the data processing system 106 When the data processing system 106 selects components for the selected content item template in response to a received content item request, the data processing system 106 observes the business rules including the co-occurrence constraints specified for the selected content item template.
- the business rules can be specified by the content provider through an interface provided by the data processing system 106 .
- the business rules can be stored in the campaign data store along with other campaign data. Alternatively, the business rules can be stored in a business rule data store 154 apart from other types of campaign data.
- the business rules can be campaign specific, content item group specific or content item template specific, for example.
- the system 100 can include any number of geographically-dispersed service providers 102 , publishers 104 and/or user access devices 108 , which may be discrete, integrated modules or distributed systems.
- the system 100 is not limited to a single data processing system 106 and may include any number of integrated or distributed data processing system or elements.
- FIG. 1 additional and/or different elements not shown may be contained in or coupled to the elements shown in FIG. 1 , and/or certain illustrated elements may be absent.
- the functions provided by the illustrated elements could be performed by less than the illustrated number of components or even by a single element.
- the illustrated elements could be implemented as individual processes run on separate machines or a single process running on a single machine.
- a content provider can specify parameters of content item campaigns and content items through a content item management system.
- the or content item management system can receive content item requests from user devices and select content items according to information in the content item requests and the parameters of the content item campaigns.
- the content items that are delivered can include dynamically generated content items as described above.
- FIG. 2A illustrates an example data flow 200 within the system 100 .
- the data flow 200 is an example only and not intended to be restrictive. Other data flows may therefore occur in the system 100 and, even with the data flow 200 , the illustrated events and their particular order in time may vary.
- the data processing system 106 stores content items from the service providers 102 and receives content item decisions 202 from a particular publisher 104 .
- the content item decisions 202 can include decisions to approve and/or disapprove certain content items and/or content providers. These content item decisions can be based on aggregated ratings or scores, associated with content items/content providers that are provided to the publisher 104 by the data processing system 106 . Such aggregated scores can represent ratings of content items/content providers received from multiple publishers 104 .
- the publisher 104 may receive a content or publication request 204 from a particular user access device 108 .
- the content request 204 may, for example, include a request for a web document on a given topic (e.g., automobiles).
- the publisher 104 may retrieve relevant publications (e.g., an automobile article) from the content repository 124 or some other source.
- the publisher 104 may respond to the content request 204 by sending a content page 206 or other presentation to the requesting user access device 108 .
- the content page 206 may include the requested content 208 (e.g., the automobile article) as well as a code “snippet” 205 associated with a content item.
- a code “snippet” refers, for example, to a method used by one device (e.g., a server) to ask another device (e.g., a browser running on a client device) to perform actions after or while downloading information.
- a code “snippet” may be implemented in JAVASCRIPT® code or may be part of HTML (Hypertext Markup Language) or other web page markup language or content.
- the data processing system 106 may provide the code snippet 205 to the publisher 104 and/or the user access device 108 .
- the code snippet can originate and/or be provided from other sources.
- the code snippet 205 causes the user access device 108 to contact the data processing system 106 and receive additional code (e.g., JAVASCRIPT® or the like), which causes the content page 206 to load with an portion 210 .
- the portion 210 may include any element that allows information to be embedded within the content page 206 .
- the portion 210 may be implemented as an HTML element, such an I-Frame (inline frame) or other type of frame.
- the portion 210 may be hosted by the data processing system 106 or the publisher 104 and may allow content (e.g., content items) from the data processing system 106 or the publisher 104 to be embedded inside the content page 206 .
- Parameters associated with the portion 210 e.g., its size and shape
- Other implementations of portion 210 may also be used.
- the portion 210 may send the data processing system 106 formatting and content information 212 .
- This information 212 may include information describing the manner (e.g., how, when, and/or where) in which content items can be rendered by the user access devices 108 .
- the information 212 may also include content item attributes and parameters, such as size, shape, color, font, presentation style (e.g., audio, video, graphical, textual, etc.), etc.
- the information 212 may also specify a quantity of content items desired.
- the formatting and content information 212 can include information associated with the requested content 208 displayed in content page 206 . Such information may include a URL associated with the requested content page 206 .
- the information 212 can include the requested content itself, a category corresponding to the requested publication or the content request, part or all of the content request 204 , content age, content type (e.g., text, graphics, video, audio, mixed media, etc.), geo-location information, and the like.
- the data processing system 106 may provide the user access device 108 with content item information 214 .
- the content item information 214 may include one or more content items 225 for placement in the portion 210 of the content page 206 .
- the content item information 214 may also include a signed or encoded specification of a content item.
- the content item information 214 may include content items that are relevant to user interest.
- the data processing system 106 may retrieve and provide relevant content items based on the information 212 received from the user access device 108 .
- the data processing system 106 may retrieve the content item information 214 from the content item repository 136 using the backend processing systems 118 .
- the data processing system 106 may retrieve relevant content items using information from a crawling module, various keywords, various statistical associations between content items and publications, and/or preference information associated with the publishers.
- the data processing system 106 may decide whether to serve certain content items with publisher content based on the content item decision 202 received from the publisher 104 . For example, the data processing system 106 may identify a relevant content item from the content item repository 136 based on keywords but may decide that the content item should not be served with the publisher content (e.g., the requested automobile document) because the publisher 104 has indicated in the content item decisions 202 a disapproval of the identified content item. In some examples, these content item serving decisions may be based on rules maintained by the backend processing systems 118 .
- the portion 210 may populate with content items included in the content item information 214 , such as content items 225 .
- the portion 210 and the displayed content items 225 may occupy a portion of the content page 206 , which may be distinct from other content (e.g., the requested content 208 ) in the content page 206 .
- an embedded code snippet may direct the user access device 108 to contact the data processing system 106 .
- the user access device 108 may receive an information parcel, such as a signed browser cookie, from the data processing system 106 .
- This information parcel can include information, such as an identifier of the selected content item 225 , an identifier of the publisher 104 , and the date/time the content item 225 was selected by the user.
- the information parcel may facilitate processing of conversion activities or other user transactions.
- the user access device 108 may then be redirected to the service provider 102 associated with the selected content item 225 .
- the user access device 108 may send a request 216 to the associated service provider 102 and then load a landing page 218 from the service provider 102 .
- the user may then perform a conversion action at the landing page 218 , such as purchasing a product or service, registering, joining a mailing list, etc.
- a code snippet 220 which may be provided by the data processing system 106 , may be included within a conversion confirmation page script, such as a script within a web page presented after the purchase.
- the user access device 108 may execute the code snippet 220 , which may then contact the data processing system 106 and report conversion data 222 to the data processing system 106 .
- the conversion data 222 may include conversion types and numbers as well as information from cookies.
- the conversion data 222 may be maintained in the conversion data repository 146 .
- FIG. 2A is an example only and not intended to be restrictive. Other data flows may therefore occur in the system 100 and, even with the data flow 200 , the illustrated events and their particular order in time may vary. Further, the illustrated events may overlap and/or may exist in fewer steps. Moreover, certain events may not be present and additional and/or different events may be included.
- the data processing system 106 can allow content providers to approve publishers in a manner similar to the manner in which publishers approve content providers.
- the data processing system 106 can receive publisher decisions (i.e., decisions about publishers) from one or more service providers 102 .
- the publisher decisions made by content providers can include approvals and disapprovals of certain publishers. These approval/disapproval decisions can be based on aggregated scores, associated with publishers that are provided to content providers.
- the aggregated scores can represent ratings of publishers received from multiple service providers 102 .
- the data processing system 106 may take into account these publisher approvals/disapprovals.
- the data processing system 106 may decide to not provide an otherwise relevant content item to a given publisher based on the content provider's disapproval of that publisher. Not providing a relevant content item to a publisher can include not bidding in an auction for publisher content item space.
- the publisher 104 can send a content item request to the data processing system 106 prior to sending a content page to the user access device 108 .
- the data processing system 106 may respond by sending relevant content items to the publisher 104 .
- the publisher 104 may combine the received content items with requested publications in the publication page and then send the publication page, including the portion, to the user access device 108 for display to a user.
- the data processing system 106 may selectively recommend and provide content items to the user access devices 108 based on search terms provided by the user access devices 108 .
- the data processing system 106 may provide searching services and receive search terms directly from the user access devices.
- the data processing system 106 can also receive search terms from a dedicated searching system that receives user search requests.
- the data processing system 106 may selectively recommend and provide content items to the user access devices based on the received search terms and content item keywords provided by the content providers.
- Other modifications to the data flow 200 are also possible.
- the users may be provided with an opportunity to control whether programs or features collect user information (e.g., information about a user's social network, social actions or activities, profession, a user's preferences, or a user's current location), or to control whether and/or how to receive content from the content server that may be more relevant to the user.
- user information e.g., information about a user's social network, social actions or activities, profession, a user's preferences, or a user's current location
- certain data may be treated in one or more ways before it is stored or used, so that personally identifiable information is removed.
- a user's identity may be treated so that no personally identifiable information can be determined for the user, or a user's geographic location may be generalized where location information is obtained (such as to a city, ZIP code, or state level), so that a particular location of a user cannot be determined.
- location information such as to a city, ZIP code, or state level
- the user may have control over how information is collected about the user and used by a content server.
- FIG. 2B depicts an example system 100 to for multi-modal transmission of packetized data in a voice activated data packet (or other protocol) based computer network environment.
- the system 100 can include at least one data processing system 106 .
- the data processing system 106 can include at least one server having at least one processor.
- the data processing system 106 can include a plurality of servers located in at least one data center or server farm.
- the data processing system 106 can determine, from an audio input signal a request and a trigger keyword associated with the request. Based on the request and trigger keyword the data processing system 106 can determine or select at least one action data structure, and can select at least one content item (and initiate other actions as described herein).
- the data processing system 106 can identify candidate interfaces for rendering of the action data structures or the content items, and can provide the action data structures or the content items for rendering by one or more candidate interfaces on one or more client computing devices based on resource utilization values for or of the candidate interfaces, for example as part of a voice activated communication or planning system.
- the action data structures (or the content items) can include one or more audio files that when rendered provide an audio output or acoustic wave.
- the action data structures or the content items can include other content (e.g., text, video, or image content) in addition to audio content.
- the data processing system 106 can include multiple, logically-grouped servers and facilitate distributed computing techniques.
- the logical group of servers may be referred to as a data center, server farm or a machine farm.
- the servers can be geographically dispersed.
- a data center or machine farm may be administered as a single entity, or the machine farm can include a plurality of machine farms.
- the servers within each machine farm can be heterogeneous—one or more of the servers or machines can operate according to one or more type of operating system platform.
- the data processing system 106 can include servers in a data center that are stored in one or more high-density rack systems, along with associated storage systems, located for example in an enterprise data center.
- the data processing system 106 with consolidated servers in this way can improve system manageability, data security, the physical security of the system, and system performance by locating servers and high performance storage systems on localized high performance networks.
- Centralization of all or some of the data processing system 106 components, including servers and storage systems, and coupling them with advanced system management tools allows more efficient use of server resources, which saves power and processing requirements and reduces bandwidth usage.
- the data processing system 106 can include at least one natural language processor (NLP) component 170 , at least one interface 115 , at least one prediction component 171 , at least one content selector component 125 , at least one audio signal generator component 130 , at least one direct action application programming interface (API) 135 , at least one interface management component 140 , and at least one data repository 145 .
- NLP natural language processor
- API application programming interface
- the NLP component 170 , interface 115 , prediction component 171 , content selector component 125 , audio signal generator component 130 , direct action API 135 , and interface management component 140 can each include at least one processing unit, server, virtual server, circuit, engine, agent, appliance, or other logic device such as programmable logic arrays configured to communicate with the data repository 145 and with other computing devices (e.g., at least one client computing device 108 , at least one content provider computing device 104 , or at least one service provider computing device 102 ) via the at least one computer network 110 .
- the network 110 can include computer networks such as the internet, local, wide, metro or other area networks, intranets, satellite networks, other computer networks such as voice or data mobile phone communication networks, and combinations thereof.
- the network 110 can include or constitute a display network, e.g., a subset of information resources available on the internet that are associated with a content placement or search engine results system, or that are eligible to include third party content items as part of a content item placement campaign.
- the network 110 can be used by the data processing system 106 to access information resources such as web pages, web sites, domain names, or uniform resource locators that can be presented, output, rendered, or displayed by the client computing device 108 .
- information resources such as web pages, web sites, domain names, or uniform resource locators that can be presented, output, rendered, or displayed by the client computing device 108 .
- a user of the client computing device 108 can access information or data provided by the data processing system 106 , the content provider computing device 104 or the service provider computing device 102 .
- the network 110 can include, for example a point-to-point network, a broadcast network, a wide area network, a local area network, a telecommunications network, a data communication network, a computer network, an ATM (Asynchronous Transfer Mode) network, a SONET (Synchronous Optical Network) network, a SDH (Synchronous Digital Hierarchy) network, a wireless network or a wireline network, and combinations thereof.
- the network 110 can include a wireless link, such as an infrared channel or satellite band.
- the topology of the network 110 may include a bus, star, or ring network topology.
- the network 110 can include mobile telephone networks using any protocol or protocols used to communicate among mobile devices, including advanced mobile phone protocol (“AMPS”), time division multiple access (“TDMA”), code-division multiple access (“CDMA”), global system for mobile communication (“GSM”), general packet radio services (“GPRS”) or universal mobile telecommunications system (“UMTS”).
- AMPS advanced mobile phone protocol
- TDMA time division multiple access
- CDMA code-division multiple access
- GSM global system for mobile communication
- GPRS general packet radio services
- UMTS universal mobile telecommunications system
- Different types of data may be transmitted via different protocols, or the same types of data may be transmitted via different protocols.
- the client computing device 108 , the content provider computing device 104 , and the service provider computing device 102 can each include at least one logic device such as a computing device having a processor to communicate with each other or with the data processing system 106 via the network 110 .
- the client computing device 108 , the content provider computing device 104 , and the service provider computing device 102 can each include at least one server, processor or memory, or a plurality of computation resources or servers located in at least one data center.
- the client computing device 108 , the content provider computing device 104 , and the service provider computing device 102 can each include at least one computing device such as a desktop computer, laptop, tablet, personal digital assistant, smartphone, portable computer, server, thin client computer, virtual server, or other computing device.
- the client computing device 108 can include at least one sensor 151 , at least one transducer 175 , at least one audio driver 153 , and at least one speaker 176 .
- the sensor 151 can include a microphone or audio input sensor.
- the transducer 175 can convert the audio input into an electronic signal, or vice-versa.
- the audio driver 153 can include a script or program executed by one or more processors of the client computing device 108 to control the sensor 151 , the transducer 175 or the audio driver 153 , among other components of the client computing device 108 to process audio input or provide audio output.
- the speaker 176 can transmit the audio output signal.
- the client computing device 108 can be associated with an end user that enters voice queries as audio input into the client computing device 108 (via the sensor 151 ) and receives audio output in the form of a computer generated voice that can be provided from the data processing system 106 (or the content provider computing device 104 or the service provider computing device 102 ) to the client computing device 108 , output from the speaker 176 .
- the audio output can correspond to an action data structure received from the direct action API 135 , or a content item selected by the content selector component 125 .
- the computer generated voice can include recordings from a real person or computer generated language.
- the content provider computing device 104 (or the data processing system 106 or service provider computing device 102 ) can provide audio based content items or action data structures for display by the client computing device 108 as an audio output.
- the action data structure or content item can include an organic response or offer for a good or service, such as a voice based message that states: “Today it will be sunny and 80 degrees at the beach” as an organic response to a voice-input query of “Is today a beach day?”.
- the data processing system 106 (or other system 100 component such as the content provider computing device 104 can also provide a content item as a response, such as a voice or text message based content item offering sunscreen.
- the content provider computing device 104 or the data repository 145 can include memory to store a series of audio action data structures or content items that can be provided in response to a voice based query.
- the action data structures and content items can include packet based data structures for transmission via the network 110 .
- the content provider computing device 104 can also provide audio or text based content items (or other content items) to the data processing system 106 where they can be stored in the data repository 145 .
- the data processing system 106 can select the audio action data structures or text based content items and provide (or instruct the content provider computing device 104 to provide) them to the same or different client computing devices 108 responsive to a query received from one of those client computing device 108 .
- the audio based action data structures can be exclusively audio or can be combined with text, image, or video data.
- the content items can be exclusively text or can be combined with audio, image or video data.
- the service provider computing device 102 can include at least one service provider natural language processor (NLP) component 161 and at least one service provider interface 162 .
- the service provider NLP component 161 (or other components such as a direct action API of the service provider computing device 102 ) can engage with the client computing device 108 (via the data processing system 106 or bypassing the data processing system 106 ) to create a back-and-forth real-time voice or audio based conversation (e.g., a session) between the client computing device 108 and the service provider computing device 102 .
- the service provider interface 162 can receive or provide data messages (e.g., action data structures or content items) to the direct action API 135 of the data processing system 106 .
- the direct action API 135 can also generate the action data structures independent from or without input from the service provider computing device 102 .
- the service provider computing device 102 and the content provider computing device 104 can be associated with the same entity.
- the content provider computing device 104 can create, store, or make available content items for beach relates services, such as sunscreen, beach towels or bathing suits, and the service provider computing device 102 can establish a session with the client computing device 108 to respond to a voice input query about the weather at the beach, directions for a beach, or a recommendation for an area beach, and can provide these content items to the end user of the client computing device 108 via an interface of the same client computing device 108 from which the query was received, a different interface of the same client computing device 108 , or an interface of a different client computing device.
- the data processing system 106 via the direct action API 135 , the NLP component 170 or other components can also establish the session with the client computing device, including or bypassing the service provider computing device 102 , to for example to provide an organic response to a query related to the beach.
- the data repository 145 can include one or more local or distributed databases, and can include a database management system.
- the data repository 145 can include computer data storage or memory and can store one or more parameters 172 , one or more policies 147 , content data 173 , or templates 174 among other data.
- the parameters 172 , policies 147 , and templates 174 can include information such as rules about a voice based session between the client computing device 108 and the data processing system 106 (or the service provider computing device 102 ).
- the content data 173 can include content items for audio output or associated metadata, as well as input audio messages that can be part of one or more communication sessions with the client computing device 108 .
- the system 100 can optimize processing of action data structures and content items in a voice activated data packet (or other protocol) environment.
- the data processing system 106 can include or be part of a voice activated assistant service, voice command device, intelligent personal assistant, knowledge navigator, event planning, or other assistant program.
- the data processing system 106 can provide one or more instances of action data structures as audio output for display from the client computing device 108 to accomplish tasks related to an input audio signal.
- the data processing system can communicate with the service provider computing device 102 or other third party computing devices to generate action data structures with information about a beach, among other things.
- an end user can enter an input audio signal into the client computing device 108 of: “OK, I would like to go to the beach this weekend” and an action data structure can indicate the weekend weather forecast for area beaches, such as “it will be sunny and 80 degrees at the beach on Saturday, with high tide at 3 pm.”
- the action data structures can include a number of organic or non-sponsored responses to the input audio signal.
- the action data structures can include a beach weather forecast or directions to a beach.
- the action data structures in this example include organic or non-sponsored content that is directly responsive to the input audio signal.
- the content items responsive to the input audio signal can include sponsored or non-organic content, such as an offer to buy sunscreen from a convenience store located near the beach.
- the organic action data structure (beach forecast) is responsive to the input audio signal (a query related to the beach), and the content item (a reminder or offer for sunscreen) is also responsive to the same input audio signal.
- the data processing system 106 can evaluate system 100 parameters (e.g., power usage, available displays, formats of displays, memory requirements, bandwidth usage, power capacity or time of input power (e.g., internal battery or external power source such as a power source from a wall output) to provide the action data structure and the content item to different candidate interfaces on the same client computing device 108 , or to different candidate interfaces on different client computing devices 108 .
- system 100 parameters e.g., power usage, available displays, formats of displays, memory requirements, bandwidth usage, power capacity or time of input power (e.g., internal battery or external power source such as a power source from a wall output) to provide the action data structure and the content item to different candidate interfaces on the same client computing device 108 , or to different candidate interfaces on different client computing devices 108 .
- the data processing system 106 can include an application, script or program installed at the client computing device 108 , such as an app to communicate input audio signals (e.g., as data packets via a packetized or other protocol based transmission) to at least one interface 115 of the data processing system 106 and to drive components of the client computing device 108 to render output audio signals (e.g., for action data structures) or other output signals (e.g., content items).
- the data processing system 106 can receive data packets or other signal that includes or identifies an audio input signal. For example, the data processing system 106 can execute or run the NLP component 170 to receive the audio input signal.
- the NLP component 170 can convert the audio input signal into recognized text by comparing the input signal against a stored, representative set of audio waveforms (e.g., in the data repository 145 ) and choosing the closest matches.
- the representative waveforms are generated across a large set of users, and can be augmented with speech samples.
- the NLP component 170 can match the text to words that are associated, for example via training across users or through manual specification, with actions that the data processing system 106 can serve.
- the audio input signal can be detected by the sensor 151 (e.g., a microphone) of the client computing device. Via the transducer 175 , the audio driver 153 , or other components the client computing device 108 can provide the audio input signal to the data processing system 106 (e.g., via the network 110 ) where it can be received (e.g., by the interface 115 ) and provided to the NLP component 170 or stored in the data repository 145 as content data 173 .
- the data processing system 106 e.g., via the network 110
- the NLP component 170 can receive or otherwise obtain the input audio signal. From the input audio signal, the NLP component 170 can identify at least one request or at least one trigger keyword corresponding to the request.
- the request can indicate intent or subject matter of the input audio signal.
- the trigger keyword can indicate a type of action likely to be taken. For example, the NLP component 170 can parse the input audio signal to identify at least one request to go to the beach for the weekend.
- the trigger keyword can include at least one word, phrase, root or partial word, or derivative indicating an action to be taken.
- the trigger keyword “go” or “to go to” from the input audio signal can indicate a need for transport or a trip away from home.
- the input audio signal (or the identified request) does not directly express an intent for transport, however the trigger keyword indicates that transport is an ancillary action to at least one other action that is indicated by the request.
- the prediction component 171 (or other mechanism of the data processing system 106 ) can generate, based on the request or the trigger keyword, at least one action data structure associated with the input audio signal.
- the action data structure can indicate information related to subject matter of the input audio signal.
- the action data structure can include one or more than one action, such as organic responses to the input audio signal.
- the input audio signal “OK, I would like to go to the beach this weekend” can include at least one request indicating an interest for a beach weather forecast, surf report, or water temperature information, and at least one trigger keyword, e.g., “go” indicating travel to the beach, such as a need for items one may want to bring to the beach, or a need for transportation to the beach.
- the prediction component 171 can generate or identify subject matter for at least one action data structure, an indication of a request for a beach weather forecast, as well as subject matter for a content item, such as an indication of a query for sponsored content related to spending a day at a beach. From the request or the trigger keyword the prediction component 171 (or other system 100 component such as the NLP component 170 or the direct action API 135 ) predicts, estimates, or otherwise determines subject matter for action data structures or for content items. From this subject matter, the direct action API 135 can generate at least one action data structure and can communicate with at least one content provider computing device 104 to obtain at least one content item 155 .
- the prediction component 171 can access the parameters 172 or policies 147 in the data repository 145 to determine or otherwise estimate requests for action data structures or content items.
- the parameters 172 or policies 147 could indicate requests for a beach weekend weather forecast action or for content items related to beach visits, such as a content item for sunscreen.
- the content selector component 125 can obtain indications of any of the interest in or request for the action data structure or for the content item.
- the prediction component 171 can directly or indirectly (e.g., via the data repository 145 ) provide an indication of the action data structure or content item to the content selector component 125 .
- the content selector component 125 can obtain this information from the data repository 145 , where it can be stored as part of the content data 173 .
- the indication of the action data structure can inform the content selector component 125 of a need for area beach information, such as a weather forecast or products or services the end user may need for a trip to the beach.
- the content selector component 125 can identify at least one content item.
- the content item can be responsive or related to the subject matter of the input audio query.
- the content item can include data message identifying a store near the beach that has sunscreen, or offering a taxi ride to the beach.
- the content selector component 125 can query the data repository 145 to select or otherwise identify the content item, e.g., from the content data 173 .
- the content selector component 125 can also select the content item from the content provider computing device 104 .
- the content provider computing device 104 can provide a content item to the data processing system 106 (or component thereof) for eventual output by the client computing device 108 that originated the input audio signal, or for output to the same end user by a different client computing device 108 .
- the content selector component 125 can select or identify a primary search result and a secondary search result. Based on the primary search result, the content selector component 125 can select a digital component or content item the data repository 145 . The content selector component 125 can also identify a secondary search result that is related to the primary search result. The secondary search results can have a secondary search URL. The content selector component 125 can select canonicalized digital components that are related to the secondary search URL. The digital components can also be received from the creatives database. The digital components, primary search results, canonicalized digital components and the secondary search results can be included in the action data structure. The digital components can be associated with a secondary search result URL. The identified canonicalized URL can be associated with the primary content item or digital component selected by the content selector component 125 .
- the audio signal generator component 130 can generate or otherwise obtain an output signal that includes the content item (as well as the action data structure) responsive to the input audio signal.
- the data processing system 106 can execute the audio signal generator component 130 to generate or create an output signal corresponding to the action data structure or to the content item.
- the interface component 115 of the data processing system 106 can provide or transmit one or more data packets that include the output signal via the computer network 110 to any client computing device 108 .
- the interface 115 can be designed, configured, constructed, or operational to receive and transmit information using, for example, data packets.
- the interface 115 can receive and transmit information using one or more protocols, such as a network protocol.
- the interface 115 can include a hardware interface, software interface, wired interface, or wireless interface.
- the interface 115 can facilitate translating or formatting data from one format to another format.
- the interface 115 can include an application programming interface that includes definitions for communicating between various components, such as software components of the system 100 .
- the data processing system 106 can provide the output signal including the action data structure from the data repository 145 or from the audio signal generator component 130 to the client computing device 108 .
- the data processing system 106 can provide the output signal including the content item from the data repository 145 or from the audio signal generator component 130 to the same or to a different client computing device 108 .
- the data processing system 106 can also instruct, via data packet transmissions, the content provider computing device 104 or the service provider computing device 102 to provide the output signal (e.g., corresponding to the action data structure or to the content item) to the client computing device 108 .
- the output signal can be obtained, generated, transformed to or transmitted as one or more data packets (or other communications protocol) from the data processing system 106 (or other computing device) to the client computing device 108 .
- the content selector component 125 can select the content item or the action data structure for the as part of a real-time content selection process.
- the action data structure can be provided to the client computing device 108 for transmission as audio output by an interface of the client computing device 108 in a conversational manner in direct response to the input audio signal.
- the real-time content selection process to identify the action data structure and provide the content item to the client computing device 108 can occur within one minute or less from the time of the input audio signal and be considered real-time.
- the data processing system 106 can also identify and provide the content item to at least one interface of the client computing device 108 that originated the input audio signal, or to a different client computing device 108 .
- the action data structure (or the content item), for example obtained or generated by the audio signal generator component 130 transmitted via the interface 115 and the computer network 110 to the client computing device 108 , can cause the client computing device 108 to execute the audio driver 153 to drive the speaker 176 to generate an acoustic wave corresponding to the action data structure or to the content item.
- the acoustic wave can include words of or corresponding to the action data structure or content item.
- the acoustic wave representing the action data structure can be output from the client computing device 108 separately from the content item.
- the acoustic wave can include the audio output of “Today it will be sunny and 80 degrees at the beach.”
- the data processing system 106 obtains the input audio signal of, for example, “OK, I would like to go to the beach this weekend.”
- the NLP component 170 identifies at least one request or at least one trigger keyword, and the prediction component 171 uses the request(s) or trigger keyword(s) to identify a request for an action data structure or for a content item.
- the content selector component 125 (or other component) can identify, select, or generate a content item for, e.g., sunscreen available near the beach.
- the direct action API 135 (or other component) can identify, select, or generate an action data structure for, e.g., the weekend beach forecast.
- the data processing system 106 or component thereof such as the audio signal generator component 130 can provide the action data structure for output by an interface of the client computing device 108 .
- the acoustic wave corresponding to the action data structure can be output from the client computing device 108 .
- the data processing system 106 can provide the content item for output by a different interface of the same client computing device 108 or by an interface of a different client computing device 108 .
- the packet based data transmission of the action data structure by data processing system 106 to the client computing device 108 can include a direct or real-time response to the input audio signal of “OK, I would like to go to the beach this weekend” so that the packet based data transmissions via the computer network 110 that are part of a communication session between the data processing system 106 and the client computing device 108 with the flow and feel of a real-time person to person conversation.
- This packet based data transmission communication session can also include the content provider computing device 104 or the service provider computing device 102 .
- the content selector component 125 can select the content item or action data structure based on at least one request or at least one trigger keyword of the input audio signal. For example, the requests of the input audio signal “OK, I would like to go to the beach this weekend” can indicate subject matter of the beach, travel to the beach, or items to facilitate a trip to the beach.
- the NLP component 170 or the prediction component 171 (or other data processing system 106 components executing as part of the direct action API 135 ) can identify the trigger keyword “go” “go to” or “to go to” and can determine a transportation request to the beach based at least in part on the trigger keyword.
- the NLP component 170 (or other system 100 component) can also determine a solicitation for content items related to beach activity, such as for sunscreen or beach umbrellas.
- the data processing system 106 can infer actions from the input audio signal that are secondary requests (e.g., a request for sunscreen) that are not the primary request or subject of the input audio signal (information about the beach this weekend).
- the action data structures and content items can correspond to subject matter of the input audio signal.
- the direct action API 135 can execute programs or scripts, for example from the NLP component 170 , the prediction component 171 , or the content selector component 125 to identify action data structures or content items for one or more of these actions.
- the direct action API 135 can execute a specified action to satisfy the end user's intention, as determined by the data processing system 106 .
- the direct action API 135 can execute code or a dialog script that identifies the parameters required to fulfil a user request.
- Such code can lookup additional information, e.g., in the data repository 145 , such as the name of a home automation service, or it can provide audio output for rendering at the client computing device 108 to ask the end user questions such as the intended destination of a requested taxi.
- the direct action API 135 can determine necessary parameters and can package the information into an action data structure, which can then be sent to another component such as the content selector component 125 or to the service provider computing device 102 to be fulfilled.
- the direct action API 135 of the data processing system 106 can generate, based on the request or the trigger keyword, the action data structures.
- the action data structures can be generated responsive to the subject matter of the input audio signal.
- the action data structures can be included in the messages that are transmitted to or received by the service provider computing device 102 .
- the direct action API 135 can determine to which, if any, of a plurality of service provider computing devices 102 the message should be sent. For example, if an input audio signal includes “OK, I would like to go to the beach this weekend,” the NLP component 170 can parse the input audio signal to identify requests or trigger keywords such as the trigger keyword word “to go to” as an indication of a need for a taxi.
- the direct action API 135 can package the request into an action data structure for transmission as a message to a service provider computing device 102 of a taxi service.
- the message can also be passed to the content selector component 125 .
- the action data structure can include information for completing the request. In this example, the information can include a pick up location (e.g., home) and a destination location (e.g., a beach).
- the direct action API 135 can retrieve a template 174 from the data repository 145 to determine which fields to include in the action data structure.
- the direct action API 135 can retrieve content from the data repository 145 to obtain information for the fields of the data structure.
- the direct action API 135 can populate the fields from the template with that information to generate the data structure.
- the direct action API 135 can also populate the fields with data from the input audio signal.
- the templates 174 can be standardized for categories of service providers or can be standardized for specific service providers. For example, ride sharing service providers can use the following standardized template 174 to create the data structure: ⁇ client deviceidentifier ; authentication credentials ; pick uplocation ; destination location ; no passengers ; service level ⁇ .
- the content selector component 125 can identify, select, or obtain multiple content items resulting from a multiple content selection processes.
- the content selection processes can be real-time, e.g., part of the same conversation, communication session, or series of communications sessions between the data processing system 106 and the client computing device 108 that involve common subject matter.
- the conversation can include asynchronous communications separated from one another by a period of hours or days, for example.
- the conversation or communication session can last for a time period from receipt of the first input audio signal until an estimated or known conclusion of a final action related to the first input audio signal, or receipt by the data processing system 106 of an indication of a termination or expiration of the conversation.
- the data processing system 106 can determine that a conversation related to a weekend beach trip begins at the time or receipt of the input audio signal and expires or terminates at the end of the weekend, e.g., Sunday night or Monday morning.
- the data processing system 106 that provides action data structures or content items for rendering by one or more interfaces of the client computing device 108 or of another client computing device 108 during the active time period of the conversation (e.g., from receipt of the input audio signal until a determined expiration time) can be considered to be operating in real-time.
- the content selection processes and rendering of the content items and action data structures occurs in real time.
- the interface management component 140 can poll, determine, identify, or select interfaces for rendering of the action data structures and of the content items related to the input audio signal. For example, the interface management component 140 can identify one or more candidate interfaces of client computing devices 108 associated with an end user that entered the input audio signal (e.g., “What is the weather at the beach today?”) into one of the client computing devices 108 via an audio interface.
- the interfaces can include hardware such as sensor 151 (e.g., a microphone), speaker 176 , or a screen size of a computing device, alone or combined with scripts or programs (e.g., the audio driver 153 ) as well as apps, computer programs, online documents (e.g., webpage) interfaces and combinations thereof.
- the interfaces can include social media accounts, text message applications, or email accounts associated with an end user of the client computing device 108 that originated the input audio signal.
- Interfaces can include the audio output of a smartphone, or an app based messaging device installed on the smartphone, or on a wearable computing device, among other client computing devices 108 .
- the interfaces can also include display screen parameters (e.g., size, resolution), audio parameters, mobile device parameters, (e.g., processing power, battery life, existence of installed apps or programs, or sensor 151 or speaker 176 capabilities), content slots on online documents for text, image, or video renderings of content items, chat applications, laptops parameters, smartwatch or other wearable device parameters (e.g., indications of their display or processing capabilities), or virtual reality headset parameters.
- the interface management component 140 can poll a plurality of interfaces to identify candidate interfaces.
- Candidate interfaces include interfaces having the capability to render a response to the input audio signal, (e.g., the action data structure as an audio output, or the content item that can be output in various formats including non-audio formats).
- the interface management component 140 can determine parameters or other capabilities of interfaces to determine that they are (or are not) candidate interfaces. For example, the interface management component 140 can determine, based on parameters 172 of the content item or of a first client computing device 108 (e.g., a smartwatch wearable device), that the smartwatch includes an available visual interface of sufficient size or resolution to render the content item.
- the interface management component 140 can also determine that the client computing device 108 that originated the input audio signal has a speaker 176 hardware and installed program e.g., an audio driver or other script to render the action data structure.
- the interface management component 140 can determine utilization values for candidate interfaces.
- the utilization values can indicate that a candidate interface can (or cannot) render the action data structures or the content items provided in response to input audio signals.
- the utilization values can include parameters 172 obtained from the data repository 145 or other parameters obtained from the client computing device 108 , such as bandwidth or processing utilizations or requirements, processing power, power requirements, battery status, memory utilization or capabilities, or other interface parameters that indicate the available of an interface to render action data structures or content items.
- the battery status can indicate a type of power source (e.g., internal battery or external power source such as via an output), a charging status (e.g., currently charging or not), or an amount of remaining battery power.
- the interface management component 140 can select interfaces based on the battery status or charging status.
- the interface management component 140 can order the candidate interfaces in a hierarchy or ranking based on the utilization values. For example different utilization values (e.g., processing requirements, display screen size, accessibility to the end user) can be given different weights.
- the interface management component 140 can rank one or more of the utilization values of the candidate interfaces based on their weights to determine an optimal corresponding candidate interface for rendering of the content item (or action data structure). Based on this hierarchy, the interface management component 140 can select the highest ranked interface for rendering of the content item.
- the interface management component 140 can select at least one candidate interface as a selected interface for the content item.
- the selected interface for the content item can be the same interface from which the input audio signal was received (e.g., an audio interface of the client computing device 108 ) or a different interface (e.g., a text message based app of the same client computing device 108 , or an email account accessible from the same client computing device 108 .
- the interface management component 140 can select an interface for the content item that is an interface of a different client computing device 108 than the device that originated the input audio signal.
- the data processing system 106 can receive the input audio signal from a first client computing device 108 (e.g., a smartphone), and can select an interface such as a display of a smartwatch (or any other client computing device for rendering of the content item.
- the multiple client computing devices 108 can all be associated with the same end user.
- the data processing system 106 can determine that multiple client computing devices 108 are associated with the same end user based on information received with consent from the end user such as user access to a common social media or email account across multiple client computing devices 108 .
- the interface management component 140 can also determine that an interface is unavailable. For example the interface management component 140 can poll interfaces and determine that a battery status of a client computing device 108 associated with the interface is low, or below a threshold level such as 10%. Or the interface management component 140 can determine that the client computing device 108 associated with the interface lacks sufficient display screen size or processing power to render the content item, or that the processor utilization rate is too high, as the client computing device is currently executing another application, for example to stream content via the network 110 . In these and other examples the interface management component 140 can determine that the interface is unavailable and can eliminate the interface as a candidate for rendering the content item or the action data structure.
- the interface management component 140 can determine that a candidate interface accessible by the first client computing device 108 is linked to an account of an end user, and that a second candidate interface accessible by a second client computing device 108 is also linked to the same account.
- both client computing devices 108 may have access to the same social media account, e.g., via installation of an app or script at each client computing device 108 .
- the interface management component 140 can also determine that multiple interfaces correspond to the same account, and can provide multiple, different content items to the multiple interfaces corresponding to the common account.
- the data processing system 106 can determine, with end user consent, that an end user has accessed an account from different client computing devices 108 .
- These multiple interfaces can be separate instances of the same interface (e.g., the same app installed on different client computing devices 108 ) or different interfaces such as different apps for different social media accounts that are both linked to a common email address account, accessible from multiple client computing devices 108 .
- the interface management component 140 can also determine or estimate distances between client computing devices 108 associated with candidate interfaces.
- the data processing system 106 can obtain, with user consent, an indication that the input audio signal originated from a smartphone or virtual reality headset computing device 108 , and that the end user is associated with an active smartwatch client computing device 108 . From this information the interface management component can determine that the smartwatch is active, e.g., being worn by the end user when the end user enters the input audio signal into the smartphone, so that the two client computing devices 108 are within a threshold distance of one another.
- the data processing system 106 can determine, with end user consent, the location of a smartphone that is the source of an input audio signal, and can also determine that a laptop account associated with the end user is currently active. For example, the laptop can be signed into a social media account indicating that the user is currently active on the laptop. In this example the data processing system 106 can determine that the end user is within a threshold distance of the smartphone and of the laptop, so that the laptop can be an appropriate choice for rendering of the content item via a candidate interface.
- the interface management component 140 can select the interface for the content item based on at least one utilization value indicating that the selected interface is the most efficient for the content item. For example, from among candidate interfaces, the interface to render the content item at the smartwatch uses the least bandwidth due as the content item is smaller and can be transmitted with fewer resources. Or the interface management component 140 can determine that the candidate interface selected for rendering of the content item is currently charging (e.g., plugged in) so that rendering of the content item by the interface will not drain battery power of the corresponding client computing device 108 . In another example, the interface management component 140 can select a candidate interface that is currently performing fewer processing operations than another, unselected interface of for example a different client computing device 108 that is currently streaming video content from the network 110 and therefore less available to render the content item without delay.
- the interface management component 140 (or other data processing system 106 component) can convert the content item for delivery in a modality compatible with the candidate interface. For example, if the candidate interface is a display of a smartwatch, smartphone, or tablet computing device, the interface management component 140 can size the content item for appropriate visual display given the dimensions of the display screen associated with the interface. The interface management component 140 can also convert the content item to a packet or other protocol based format, including proprietary or industry standard format for transmission to the client computing device 108 associated with the selected interface.
- the interface selected by the interface management component 140 for the content item can include an interface accessible from multiple client computing devices 108 by the end user. For example, the interface can be or include a social media account that the end user can access via the client computing device 108 that originated the input audio signal (e.g., a smartphone) as well as other client computing devices such as tabled or desktop computers or other mobile computing devices.
- the interface management component 140 can also select at least one candidate interface for the action data structure.
- This interface can be the same interface from which the input audio signal was obtained, e.g., a voice activated assistant service executed at a client computing device 108 .
- This can be the same interface or a different interface than the interface management component 140 selects for the content item.
- the interface management component 140 (or other data processing system 106 components) can provide the action data structure to the same client computing device 108 that originated the input audio signal for rendering as audio output as part of the assistant service.
- the interface management component 140 can also transmit or otherwise provide the content item to the selected interface for the content item, in any converted modality appropriate for rendering by the selected interface.
- the interface management component 140 can provide the action data structure as audio output for rendering by an interface of the client computing device 108 responsive to the input audio signal received by the same client computing device 108 .
- the interface management component 140 can also provide the content item for rendering by a different interface of the same client computing device 108 or of a different client computing device 108 associated with the same end user.
- the action data structure e.g., “it will be sunny and 80 degrees at the beach on Saturday” can be provided for audio rendering by the client computing device as part of an assistant program interface executing in part at the client computing device 108
- the content item e.g., a text, audio, or combination content item indicating that “sunscreen is available from the convenience store near the beach”
- an interface of the same or a different computing device 108 such as an email or text message accessible by the same or a different client computing device 108 associated with the end user.
- Separating the content item from the action data structure and sending the content item as, for example, a text message rather than an audio message can result in reduced processing power for the client computing device 108 that accesses the content item since, for example, text message data transmissions are less computationally intensive than audio message data transmissions.
- This separation can also reduce power usage, memory storage, or transmission bandwidth used to render the content item.
- This increases the efficiency of the computing devices that process these transactions, and increases the speed with which the content items can be rendered.
- the data processing system 106 can process thousands, tens of thousands or more input audio signals simultaneously so the bandwidth, power, and processing savings can be significant and not merely incremental or incidental.
- the interface management component 140 can provide or deliver the content item to the same client computing device 108 (or a different device) as the action data structure subsequent to delivery of the action data structure to the client computing device 108 .
- the content item can be provided for rendering via the selected interface upon conclusion of audio output rendering of the action data structure.
- the interface management component 140 can also provide the content item to the selected interface concurrent with the provision of the action data structure to the client computing device 108 .
- the interface management component 140 can provide the content item for delivery via the selected interface within a pre-determined time period from receipt of the input audio signal by the NLP component 170 .
- the time period for example, can be any time during an active length of the conversation of session.
- the pre-determined time period can be any time from receipt of the input audio signal through the end of the weekend, e.g., the active period of the conversation.
- the pre-determined time period can also be a time triggered from rendering of the action data structure as audio output by the client computing device 108 , such as within 5 minutes, one hour or one day of this rendering.
- the interface management component 140 can provide the action data structure to the client computing device 108 with an indication of the existence of the content item.
- the data processing system 106 can provide the action data structure that renders at the client computing device 108 to provide the audio output “it will be sunny and 80 degrees at the beach on Saturday, check your email for more information.”
- the phrase “check your email for more information” can indicate the existence of a content item, e.g., for sunscreen, provided by the data processing system 106 to an interface (e.g., email).
- sponsored content can be provided as content items to the email (or other) interface and organic content such as the weather can be provided as the action data structure for audio output.
- the data processing system 106 can also provide the action data structure with a prompt that queries the user to determine user interest in obtaining the content item.
- the action data structure can indicate “it will be sunny and 80 degrees at the beach on Saturday, would you like to hear about some services to assist with your trip?”
- the data processing system 106 can receive another audio input signal from the client computing device 108 in response to the prompt “would you like to hear about some services to assist with your trip?” such as “sure”.
- the NLP component 170 can parse this response, e.g., “sure” and interpret it as authorization for audio rendering of the content item by the client computing device 108 .
- the data processing system 106 can provide the content item for audio rendering by the same client computing device 108 from which the response “sure” originated.
- the data processing system 106 can delay transmission of the content item associated with the action data structure to optimize processing utilization. For example, the data processing system 106 provide the action data structure for rendering as audio output by the client computing device in real-time responsive to receipt of the input audio signal, e.g., in a conversational manner, and can delay content item transmission until an off-peak or non-peak period of data center usage, which results in more efficient utilization of the data center by reducing peak bandwidth usage, heat output or cooling requirements.
- the data processing system 106 can also initiate a conversion or other activity associated with the content item, such as ordering a car service responsive to a response to the action data structure or to the content item, based on data center utilization rates or bandwidth metrics or requirements of the network 110 or of a data center that includes the data processing system 106 .
- the data processing system 106 can identify a conversion, or initiate a conversion or action.
- Processors of the data processing system 106 can invoke the direct action API 135 to execute scripts that facilitate the conversion action, such as to order a car from a car share service to take the end user to or from the beach.
- the direct action API 135 can obtain content data 173 (or parameters 172 or policies 147 ) from the data repository 145 , as well as data received with end user consent from the client computing device 108 to determine location, time, user accounts, logistical or other information in order to reserve a car from the car share service.
- the data processing system 106 can also communicate with the service provider computing device 102 to complete the conversion by in this example making the car share pick up reservation.
- FIG. 2C depicts another example flow diagram 200 for multi-modal transmission of packetized data in a voice activated computer network environment.
- the data processing system 106 can receive the input audio signal 250 , e.g., “OK, I would like to go to the beach this weekend.” In response, the data processing system generates at least one action data structure 255 and at least one content item 215 .
- the action data structure 255 can include organic or non-sponsored content, such as a response for audio rendering stating “It will be sunny and 80 degrees at the beach this weekend” or “high tide is at 3 pm.”
- the data processing system 106 can provide the action data structure 255 to the same client computing device 108 that originated the input audio signal 250 , for rendering by a candidate interface of the client computing device 108 , e.g., as output in a real time or conversational manner as part of a digital or conversational assistant platform.
- the data processing system 106 can select the candidate interface 270 as a selected interface for the content item 215 , and can provide the content item 215 to the selected interface 270 .
- the content item 215 can also include a data structure, converted to the appropriate modality by the data processing system 106 for rendering by the selected interface 270 .
- the content item 215 can include sponsored content, such as an offer to rent a beach chair for the day, or for sunscreen.
- the selected interface 270 can be part of or executed by the same client computing device 108 or by a different device accessible by the end user of the client computing device 108 . Transmission of the action data structure 255 and the content item 215 can occur at the same time or subsequent to one another.
- the action data structure 255 can include an indicator that the content item 215 is being or will be transmitted separately via a different modality or format to the selected interface, alerting the end user to the existence of the content item 215 .
- the action data structure 255 and the content item 215 can be provided separately for rendering to the end user.
- This can reduce bandwidth requirements associated with transmission of the action data structure 255 via the network 110 and can simplify rendering of the action data structure 255 , for example without audio disclaimer or warning messages.
- the data processing system 106 can receive a response audio signal 265 .
- the response audio signal 265 can include an audio signal such as, “great, please book me a hotel on the beach this weekend.” Receipt by the data processing system 106 of the response audio signal 265 can cause the data processing system to invoke the direct action API 135 to execute a conversion to, for example, book a hotel room on the beach.
- the direct action API 135 can also communicate with at least one service provider computing device 102 to provide information to the service provider computing device 102 so that the service provider computing device 102 can complete or confirm the booking process.
- FIG. 3A is a sample screenshot 300 showing representative search results arising from a search for “items” specified by a user 107 .
- an content delivery system such as data processing system 106 , also shown in FIG. 1
- the search provider will provide additional content in the form of one or more content items, to be presented to the user.
- a search specified by user 107 may yield a primary result 302 , which is a link to a content provider-specified landing page.
- service provider 102 and/or data processing system 106 provides several additional or secondary results 304 - 310 .
- Each additional or secondary result displays a sitelink specified by a service provider 102 to appear in response to a specific user search inquiry.
- result 304 includes sitelink 312
- result 306 includes sitelink 314
- result 308 includes sitelink 316
- result 310 includes sitelink 318 .
- the texts appearing in sitelinks 312 - 318 alone may not contain sufficient information to enable a user to reach a decision whether to click on any of sitelinks 312 - 318 .
- FIG. 3B is an example screenshot 350 according to the present disclosure, showing representative search results arising from a search for “items” specified by a user 107 .
- a search specified by user 107 yields a primary result 352 , which is a link to a content provider-specified landing page.
- Primary result 352 includes a link 354 , as well as a descriptive creative 356 .
- the search may also yield several additional or secondary results 358 - 364 including sitelinks 366 - 372 . Appearing with sitelinks 366 - 372 are descriptive texts (referred to as “creatives” or “creative texts”).
- additional or secondary result 358 includes sitelink 366 and creative 374
- result 360 includes sitelink 368 and creative 376
- result 362 includes sitelink 370 and creative 378
- result 364 includes sitelink 372 and creative 380 .
- Data processing system 106 attempts to provide the most relevant content items to user 107 .
- a service provider 102 may have a plurality of landing pages, with associated URLs (forming additional or secondary results 358 - 364 , for example), that are relevant to the search ordered by user 107 .
- Each landing page (and associated URL) has one or more creative texts associated with it. These creative texts may also be associated with other landing pages (and URLs) within the content provider website.
- data processing system 106 matches creatives with URLs so as to increase the relevance of the combined creative and URL to the search conducted by user 107 .
- FIG. 4A is a flowchart of an example method 400 for enhancing, for example, sitelink 312 with creative content, such as text 320 (shown in FIG. 3 ).
- Method 400 is described in the context of the results of a search performed by a user 107 , which yields a primary result 302 (shown in FIG. 3 ), and a plurality of additional or secondary results (also referred to as the “extension”), although some of the steps such as the storing and/or canonicalization of creatives and/or sitelinks may be performed prior to a search by a user 107 .
- “canonicalization” refers to a process for converting data that has more than one possible representation into a “standard”, “normal”, or canonical form.
- Data processing system 106 generates and stores 402 in a creatives database (which in an example embodiment is content item repository 136 shown in FIG. 1 ) a candidate set of creatives associated with each content provider specified sitelink. Each sitelink has a URL associated with it, as does each creative. In one embodiment of the present disclosure, data processing system 106 simply associates all creatives with the same URL as the sitelink as being part of a candidate set.
- a creatives database which in an example embodiment is content item repository 136 shown in FIG. 1
- Each sitelink has a URL associated with it, as does each creative.
- data processing system 106 simply associates all creatives with the same URL as the sitelink as being part of a candidate set.
- data processing system 106 canonicalizes 404 the creative URLs to identify characteristics of the URLs that will enable the creative URLs to be grouped into creative clusters.
- Canonicalization of creative-associated URLs may be accomplished through a variety of schemes, including analyzing landing pages associated with the sitelinks to compare the contents of the respective landing pages to identify significant similarities amongst the landing pages, wherein significant similarities are determined using one or more predefined rules or parameters.
- canonicalization of creative-associated URLs includes crawling the creative-associated URL with and without a URL parameter associated with the creative-associated URL, comparing the landing pages, and removing the parameter from the creative-associated URL when the landing pages match.
- Data processing system 106 stores data regarding content item campaigns in campaign database or repository 150 (shown in FIG. 1 ).
- the campaign data includes sitelinks associated with various landing pages.
- sitelink URLs are canonicalized 412 to identify and account for content provider redirects and other parameters in the URLs, used for recording and reporting site activity, that are otherwise inconsequential to directing a user to the final landing page associated with each URL.
- data processing system 106 identifies parameters in a link URL that are not important to identify a corresponding landing page by crawling the link URL with and without the parameter and then comparing the landing pages in each iteration for matches. Where landing pages match after crawling, the parameter is removed.
- data processing system 106 applies webmaster supplied rules as to relevance of URL parameters for landing page purposes. Following a user search, data processing system 106 identifies a plurality of relevant sitelinks and refers 414 to the saved creative cluster lookup table for one or more clusters of candidate creatives to match to the specified sitelinks. In addition to, or as an alternative to associating sitelinks with content item campaigns, sitelinks may also be associated with other entities, such as content item groups.
- data processing system 106 applies specific filter rules and/or policy checks related to the suitability of the creative for the specific sitelink, to eliminate matches of creatives to sitelinks that are expressly excluded, or simply inappropriate, relative to the search specified by user 107 .
- filter rules or policy checks include demographic, geographic and language checks (to ensure that the creative is appropriate to user device location, for example), user device and/or platform rules, as well as checks to ensure that the candidate creatives are compatible with the status of the content item campaign.
- data processing system 106 prunes the set of candidate creatives by performing deduping to remove redundancies and duplication between creatives found for a specific sitelink and by applying other policy checks such as the size of the available candidate set and estimated measures of the improvement to content item CTR (“click-through-rate”).
- data processing system 106 performs creative matching 416 .
- data processing system 106 saves 418 data representing the enhanced sitelink, to be served to user 107 .
- data processing system 106 performs creative matching by generating permutations of matches between one or more specified sitelinks and corresponding candidate creatives, and assigning scores to each permutation that reflects a relative value of the “fit” of each proposed match.
- the score may be based on various signals such as an impression score, which is a measure of how many times that creative was shown over a recent timeframe such as a week, and an IDF-score, which is a measure of similarity of terms between a sitelink text and a creative text.
- impression count refers to the number of times that an item, such as a creative, has been presented to online users.
- each sitelink is matched with an as yet unmatched creative with the highest score.
- Remaining sitelinks are successively matched with the next highest scoring creatives, until all sitelinks are matched with creatives.
- a total match score is determined that is below a predefined threshold, data processing system 106 uses a more globally optimal matching algorithm.
- the globally optimal matching algorithm is implemented as follows. For example, two sitelinks S 1 and S 2 are to be provided to a user 107 in response to a search. Assume S 1 can be matched to two (non-duplicative) creatives C 1 and C 2 , having match scores of 10 and 8, respectively. Likewise, S 2 can also be matched to C 1 and C 2 , but with corresponding match scores of 8 and 2, respectively. In a matching scheme in which a first creative match score is optimized, the resulting association is S 1 -C 1 and S 2 -C 2 with an overall score of 12.
- FIG. 6 is an example bipartite graph 600 that may be used in matching sitelinks S 1 and S 2 with creatives C 1 and C 2 .
- data processing system 106 constructs bipartite graph 600 in which a set of specified sitelinks (S 1 , S 2 ) constitutes one set of nodes and the creatives (C 1 , C 2 ) in a candidate set form the other set of nodes.
- Data processing system 106 adds an edge (shown as a connecting line in graph 600 ) between a sitelink node and a creative to which it can be matched and the weight of the edge (the number adjacent the connecting line) is the match-score for the respective sitelink-creative pairing.
- Data processing system 106 performs a constrained maximal matching on this graph to obtain the overall best score subject to the constraint that there is no inter-sitelink creative duplication.
- the bipartite matching scheme uses the numerical values from the previous example to generate an improved matching of S 1 -C 2 and S 2 -C 1 with a total score of 16.
- a path growing heuristic is used, with additional modifications to avoid seed-bias, to provide match augmentation and to account for conflict resolution.
- the basic approach is to maintain two sets of paths obtained by alternatively performing 1) expansion from a sitelink to get its best remaining creative (e.g., the assignment S 1 -C 2 provided above), with 2) expansion from a creative for its best remaining sitelink to which it can be assigned (e.g., the assignment S 2 -C 1 provided above).
- the edges visited in each step get added to one of the two path-sets in alternating fashion.
- data processing system 106 checks for duplicate creatives and/or redundant creatives (similar but not identically-duplicate creatives) from amongst the selected creatives, and rejects them. In addition, data processing system 106 applies a predefined size constraint, in which matches that yield a score below a predefined threshold are discarded. If there are no choices available to grow a path from a certain node, data processing system 106 restarts the process with the next sitelink that has not yet been explored. Data processing system 106 also does not revisit a sitelink or creative node.
- data processing system 106 when all sitelink nodes have been explored, data processing system 106 obtains two possible assignments, In one example, data processing system 106 additionally attempts to ‘augment’ these assignments by checking if there are any unassigned sitelinks in each assignment. If unassigned sitelinks exist, they are matched with any available creatives that are eligible.
- Data processing system 106 selects the assignment that has a higher score and meets the size constraint.
- the creative matching process using the described algorithm, could yield different results based on the order in which sitelinks are initially arranged. This ‘seed-bias’ can be resolved by repeating the matching with different orders.
- data processing system 106 may apply rules, applicable for example to more than 6 sitelinks, to define subsets in order to limit the number of permutations that are performed, to streamline the matching process.
- FIG. 7 is another example bipartite graph 700 illustrating a slightly more complex scenario than that illustrated in FIG. 6 .
- sitelinks S 1 and S 2 can be potentially matched with creatives C 1 , C 2 or C 3 .
- S 1 can be matched with C 1 , C 2 , and C 3 , with scores of 10, 8, and 5, respectively.
- C 2 can be matched with C 1 and C 2 with scores of 8 and 5, respectively.
- an optimal matching must take this constraint into consideration. Further, it is possible that C 1 and C 2 cannot both be part of the same matching as they may be deemed redundant to one another. In such a situation, an optimal matching would be S 1 -C 3 and S 2 -C 1 .
- creatives may be ranked by metrics in addition to, or other than, impression count. Such an approach is desirable when a set of candidate creatives are not otherwise clearly differentiated by their respective impression counts. In addition, such an approach improves the quality of the results of the matching process by ensuring that the creatives shown in association with the selected sitelinks are related to the text in the sitelink. Accordingly, an additional scoring factor, referred to herein as an IDF score, is used.
- IDF refers to “inverse-document-frequency,” which refers to one of a number of known methodologies for analyzing term frequency within a document (or item of publication), while correcting for terms that are simply generally frequently encountered in a group of documents (or items of publication). Accordingly, a creative score is represented as:
- both sitelink text and creative text are normalized.
- “normalized” means that terms are reduced to their stems, and stopwords (typically, short, functional words such as “the,” “is,” “at,” “which,” and “on”) are removed.
- the IDF score is the weighted sum of words common to both a creative and an associated sitelink.
- IDF scoring may be performed in a uniform mode, in which no external influences are used, and all terms are given equal weight.
- the term “sale” may have a high IDF weight in a general corpus of text items, but may carry a lower weight in a corpus comprised of only creatives.
- FIG. 4B illustrates a block diagram of an example method 450 of transmitting data in a voice activated computer network.
- the method 450 can include receiving an input audio signal (step 451 ).
- the method 450 can include identifying a first request within the input audio signal (step 452 ).
- the method 450 can include determining a primary search result that has a primary digital component and a secondary search result URL (step 453 ).
- the method 450 can include identifying a plurality of candidate canonicalized digital components (step 454 ).
- the method 450 can include calculating a score for each of the plurality of candidate canonicalized digital components (step 455 ).
- the method 450 can include selecting one of the plurality of candidate canonicalized digital components (step 456 ).
- the method 450 can include transmitting the primary output audio signal (step 457 ).
- the method 450 can include transmitting a secondary output signal that includes the selected candidate canonicalized digital component (step 458 ).
- the method 450 can include receiving, via an interface, data packets that can include an input audio signal (ACT 451 ).
- the input audio signal can be detected by a sensor, such as a microphone, of a client computing device.
- the NLP component executed by the data processing system, can receive from the client computing device data packets that include an input audio signal.
- the received data packets can be received via the network as packet or other protocol based data transmissions.
- the method 450 can include identifying a first request within the input audio signal (ACT 452 ).
- the request can be identified by the NLP component.
- the NLP component can also identify a trigger keyword within the input audio signal.
- the NLP component can parse the input audio signal to identify requests that relate to subject matter of the input audio signal, or to identify trigger keywords that can indicate, for example, actions associated with the requests.
- the method 450 can include determining a primary search result that has a primary digital component and a secondary search result URL (ACT 453 ).
- the primary search result can be based on the first request.
- the secondary search result URL can be related to the primary search result.
- the content selected component can receive the first request and the trigger keyword.
- the content selector component can select the primary digital component based on the first request and the trigger keyword via a real-time content selection process.
- the secondary search result URL can be to or be included in an action data structure.
- the secondary search results URL can be a link to a digital component that can provide additional information about the primary search results.
- the secondary search URL can be a link to possible actions that can be taken based on the response to the input.
- the secondary search URL could be an action to locate the reservation number of the airline with which the flight is book, location the URL of the airline's website, or determine the flight status of the flight.
- the response to the primary search results can be included in a first action data structure.
- the secondary search URL can be used to generate a second action data structure.
- the first and second action data structures can be sent to the client computing device that transmitted the request in a conversational manner.
- the method 450 can include identifying a plurality of candidate canonicalized digital components associated with the secondary search result URL (ACT 454 ).
- Each of canonicalized digital components can be digital components that are identified in response to executing the action identified by the secondary search URL.
- Each of the canonicalized digital components can be in the same or different format from one another.
- the canonicalized digital components can be video-based, audio-based, text-based, image-based, or a combination thereof.
- Each of the plurality of candidate canonicalized digital components can include a URL to a video-based digital component.
- the canonicalized digital components for a secondary search URL to provide the phone number of the airline could be a text string of the phone number to the airline, a link to a webpage containing the airline's phone number, or an audio file of a computerized voice reading the airline's phone number.
- the method 450 can include calculating a respective score for each of the plurality of candidate canonicalized digital components (ACT 455 ).
- the score for each of the plurality of canonicalized digital components can be based on a term frequency within each of the plurality of canonicalized digital components.
- the score can be the above described impression score, IDF score, or a combination thereof, such as a creative score.
- the method can include selecting one of the plurality of candidate canonicalized digital components (ACT 456 ).
- the selection of one of the candidate canonicalized digital components can be based on the respective score for each of the plurality of canonicalized digital components.
- the data processing system can use a filter rule to selecting one of the candidate canonicalized digital components.
- the filter rules can include at least one of a language rule, a geographic rule, a user device rule, and a platform rule.
- the filter rules or policy checks can be used to ensure that the selected candidate digital component is appropriate to user device location, for example.
- the candidate canonicalized digital components can be scored based on the resources or capabilities of the client computing device to receive the canonicalized digital component.
- the resources can include the battery life, a processor utilization, a memory utilization, an interface parameter, or a bandwidth utilization.
- the capabilities can include the output capabilities of the client computing device that will receive the canonicalized digital component.
- the capabilities can include whether the device has is capable of displaying video or images or playing audio messages. For example, if the receiving device includes speakers but not a screen, image- and video-based canonicalized digital components can be given a low score while an audio-based canonicalized digital component can be given a relatively higher score.
- the device receiving the canonicalized digital component can be the same device that originally transmitted the input audio signal.
- the method 450 can include transmitting a primary output audio signal (ACT 457 ).
- the output audio signal can include the primary digital component.
- the interface management component can transmit the primary output audio signal to the primary interface.
- the digital component can be included in an action data structure.
- the action data structure can be generated by the direction action API.
- the action data structure can be based on the request and the trigger keyword.
- the action data structures can indicate organic or non-sponsored content related to the input audio signal.
- the data processing system can generate the primary output audio signal responsive to processing the action data structure.
- the action data structure can be transmitted to a service provider that can generate the primary output audio signal for transmission to a client computing device.
- the method 450 can include transmitting a secondary output signal comprising the selected candidate canonicalized digital component (ACT 458 ).
- the secondary output signal can be transmitted, by the interface management component, to a secondary interface.
- the secondary interface can be the primary interface or another interface of the client computing device that transmitted the audio input signal to the system.
- the secondary interface can be an interface of a second client computing device that is associated with the client computing device that transmitted the audio input signal to the system.
- the two client computing devices can be associated with the same user account.
- the second interface which can be on a second client computing device, can be selected through a polling process.
- the polling process can include polling, by an interface management component, a plurality of interfaces to identify different candidate interfaces, such as a first candidate interface and a second candidate interface.
- the candidate interfaces can include candidate interfaces that can render, display, or receive the selected digital component, canonicalized digital component, or action data structure.
- the interface management component can query interfaces that are capable of displaying video of the digital component includes video.
- the interface management component can determine different attributes of the digital component to determine if the candidate interfaces can render, display, or receive the selected digital component, canonicalized digital component, or action data structure.
- the attributes can include the shape, size, color, font, presentation style (e.g., audio, video, graphical, textual), and resource requirements of the digital component, canonicalized digital component, or action data structure.
- the polling process can also include determining, by the interface management component, resource utilization values for each of the candidate interfaces.
- the resource utilization values can be based on at least one of a battery status, a processor utilization, a memory utilization, an interface parameter, or a bandwidth utilization of the device associated with the respective candidate interface.
- the method can include selecting, by the interface management component, the first candidate interface as the primary interface based on a comparison of the resource utilization values of the candidate interfaces, the attributes of the digital component, a combination thereof, or a comparison thereof.
- the input audio signal can be “Ok, what actor plays in the movie [movie name]” can be received from an audio-based digital assistant.
- the system can identify a primary digital component that includes the actor's name.
- the secondary search URL can be a search for Internet videos that include the actor. Each of the videos can be a canonicalized digital component.
- the digital component including the actor's name can be transmitted back to the audio-based digital assistant, which can play the message of the digital component, “The actor's name is [actor's name].
- the data processing system can select one of the canonicalized digital components for transmission the user's Internet connected TV.
- the data processing system determining that the audio-based digital assistant is not configured to display video could identify the TV during the above-described polling process.
- the canonicalized digital component once received by the Internet connected TV, can begin to play the video associated with the canonicalized digital component.
- FIG. 5 is a diagram of example computing devices 500 and 550 that may be used in the environment shown in FIG. 1 . More specifically, FIG. 5 shows an example of a generic computing device 500 and a generic mobile computing device 550 , which may be used with the techniques described here.
- Computing device 500 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.
- Computing device 550 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smart phones, and other similar computing devices.
- the components shown here, their connections and relationships, and their functions, are meant to be examples only, and are not meant to limit implementations of the disclosures described and/or claimed in this document.
- Computing device 500 includes a processor 502 , a memory 504 , a storage device 506 , a high-speed interface/controller 508 connecting to memory 504 and high-speed expansion ports 510 , and a low speed interface/controller 512 connecting to a low speed bus 514 and storage device 506 .
- Each of the components 502 , 504 , 506 , 508 , 510 , and 512 are interconnected using various buses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 502 can process instructions for execution within the computing device 500 , including instructions stored in the memory 504 or on the storage device 506 to display graphical information for a GUI on an external input/output device, such as display 516 coupled to high speed interface 508 .
- an external input/output device such as display 516 coupled to high speed interface 508 .
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 500 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 504 stores information within the computing device 500 .
- the memory 504 is a volatile memory unit or units.
- the memory 504 is a non-volatile memory unit or units.
- the memory 504 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 506 is capable of providing mass storage for the computing device 500 .
- the storage device 506 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 504 , the storage device 506 , or memory on processor 502 .
- the high speed controller 508 manages bandwidth-intensive operations for the computing device 500 , while the low speed controller 512 manages lower bandwidth-intensive operations. Such allocation of functions is example only.
- the high-speed controller 508 is coupled to memory 504 , display 516 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 510 , which may accept various expansion cards (not shown).
- low-speed controller 512 is coupled to storage device 506 and low-speed bus 514 .
- the low-speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 500 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 520 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system 524 . In addition, it may be implemented in a personal computer such as a laptop computer 522 . Alternatively, components from computing device 500 may be combined with other components in a mobile device (not shown), such as computing device 550 . Each of such devices may contain one or more of computing device 500 , 550 , and an entire system may be made up of multiple computing devices 500 , 550 communicating with each other.
- Computing device 550 includes a processor 552 , memory 564 , an input/output device such as a display 554 , a communication interface 566 , and a transceiver 568 , among other components.
- the computing device 550 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 550 , 552 , 564 , 554 , 566 , and 568 are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 552 can execute instructions within the computing device 550 , including instructions stored in the memory 564 .
- the processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors.
- the processor may provide, for example, for coordination of the other components of the computing device 550 , such as control of user interfaces, applications run by computing device 550 , and wireless communication by computing device 550 .
- Processor 552 may communicate with a user through control interface 558 and display interface 556 coupled to a display 554 .
- the display 554 may be, for example, a TFT LCD (Thin-Film-Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology.
- the display interface 556 may comprise appropriate circuitry for driving the display 554 to present graphical and other information to a user.
- the control interface 558 may receive commands from a user and convert them for submission to the processor 552 .
- an external interface 562 may be provide in communication with processor 552 , so as to enable near area communication of computing device 550 with other devices. External interface 562 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
- the memory 564 stores information within the computing device 550 .
- the memory 564 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.
- Expansion memory 574 may also be provided and connected to computing device 550 through expansion interface 572 , which may include, for example, a SIMM (Single In Line Memory Module) card interface.
- SIMM Single In Line Memory Module
- expansion memory 574 may provide extra storage space for computing device 550 , or may also store applications or other information for computing device 550 .
- expansion memory 574 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 574 may be provide as a security module for computing device 550 , and may be programmed with instructions that permit secure use of computing device 550 .
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include, for example, flash memory and/or NVRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 564 , expansion memory 574 , or memory on processor 552 that may be received, for example, over transceiver 568 or external interface 562 .
- Computing device 550 may communicate wirelessly through communication interface 566 , which may include digital signal processing circuitry where necessary. Communication interface 566 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 568 . In addition, short-range communication may occur, such as using a Bluetooth, Wi-Fi, or other such transceiver (not shown). In addition, GPS (Global Positioning system) receiver module 570 may provide additional navigation- and location-related wireless data to computing device 550 , which may be used as appropriate by applications running on computing device 550 .
- GPS Global Positioning system
- Computing device 550 may also communicate audibly using audio codec 560 , which may receive spoken information from a user and convert it to usable digital information. Audio codec 560 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of computing device 550 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on computing device 550 .
- Audio codec 560 may receive spoken information from a user and convert it to usable digital information. Audio codec 560 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of computing device 550 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on computing device 550 .
- the computing device 550 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 580 . It may also be implemented as part of a smart phone 582 , personal digital assistant, a computer tablet, or other similar mobile device.
- various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- computing systems 500 and 550 are configured to receive and/or retrieve data pertaining to the creation, review and revision of online content items; data regarding content providers, content delivery links or impressions corresponding to those content providers that appear on a web page, and metrics corresponding to the appearance of those impressions on that web page, etc., from various other computing devices connected to computing devices 500 and 550 through a communication network, and store this data within at least one of memory 504 , storage device 506 , and memory 564 .
- Computing systems 500 and 550 are further configured to manage and organize the data within at least one of memory 504 , storage device 506 , and memory 564 using the techniques described herein.
- references to implementations or elements or acts of the systems and methods herein referred to in the singular may also embrace implementations including a plurality of these elements, and any references in plural to any implementation or element or act herein may also embrace implementations including only a single element.
- References in the singular or plural form are not intended to limit the presently disclosed systems or methods, their components, acts, or elements to single or plural configurations.
- References to any act or element being based on any information, act or element may include implementations where the act or element is based at least in part on any information, act, or element.
- any implementation disclosed herein may be combined with any other implementation or embodiment, and references to “an implementation,” “some implementations,” “one implementation” or the like are not necessarily mutually exclusive and are intended to indicate that a particular feature, structure, or characteristic described in connection with the implementation may be included in at least one implementation or embodiment. Such terms as used herein are not necessarily all referring to the same implementation. Any implementation may be combined with any other implementation, inclusively or exclusively, in any manner consistent with the aspects and implementations disclosed herein.
- references to “or” may be construed as inclusive so that any terms described using “or” may indicate any of a single, more than one, and all of the described terms. For example, a reference to “at least one of ‘A’ and ‘B’” can include only ‘A’, only ‘B’, as well as both ‘A’ and ‘B’. Such references used in conjunction with “comprising” or other open terminology can include additional items.
Abstract
Description
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/603,701 US10735552B2 (en) | 2013-01-31 | 2017-05-24 | Secondary transmissions of packetized data |
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201361758979P | 2013-01-31 | 2013-01-31 | |
US13/840,380 US10650066B2 (en) | 2013-01-31 | 2013-03-15 | Enhancing sitelinks with creative content |
US15/395,703 US10032452B1 (en) | 2016-12-30 | 2016-12-30 | Multimodal transmission of packetized data |
US15/603,701 US10735552B2 (en) | 2013-01-31 | 2017-05-24 | Secondary transmissions of packetized data |
Related Parent Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/840,380 Continuation-In-Part US10650066B2 (en) | 2013-01-31 | 2013-03-15 | Enhancing sitelinks with creative content |
US15/395,703 Continuation-In-Part US10032452B1 (en) | 2004-06-30 | 2016-12-30 | Multimodal transmission of packetized data |
Publications (2)
Publication Number | Publication Date |
---|---|
US20170257456A1 US20170257456A1 (en) | 2017-09-07 |
US10735552B2 true US10735552B2 (en) | 2020-08-04 |
Family
ID=59724476
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/603,701 Active US10735552B2 (en) | 2013-01-31 | 2017-05-24 | Secondary transmissions of packetized data |
Country Status (1)
Country | Link |
---|---|
US (1) | US10735552B2 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11431718B2 (en) * | 2014-10-07 | 2022-08-30 | Ricoh Company, Ltd. | Text chat management system connected to a video conference management system |
Families Citing this family (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN105678586B (en) | 2016-01-12 | 2020-09-29 | 腾讯科技（深圳）有限公司 | Information supporting method and device |
US10353978B2 (en) * | 2016-07-06 | 2019-07-16 | Facebook, Inc. | URL normalization |
US11144584B2 (en) | 2017-10-03 | 2021-10-12 | Google Llc | Coordination of parallel processing of audio queries across multiple devices |
US11087751B2 (en) | 2017-12-08 | 2021-08-10 | Google Llc | Detection of duplicate packetized data for selective transmission into one of a plurality of a user's devices |
US11145300B2 (en) | 2018-05-07 | 2021-10-12 | Google Llc | Activation of remote devices in a networked system |
JP7004834B2 (en) | 2018-05-07 | 2022-01-21 | グーグル エルエルシー | Synchronization of access control between computing devices |
US11087748B2 (en) | 2018-05-11 | 2021-08-10 | Google Llc | Adaptive interface in a voice-activated network |
CN108989383B (en) * | 2018-05-31 | 2021-08-27 | 创新先进技术有限公司 | Data processing method and client |
US10963492B2 (en) * | 2018-06-14 | 2021-03-30 | Google Llc | Generation of domain-specific models in networked system |
US20200042650A1 (en) * | 2018-08-06 | 2020-02-06 | Ca, Inc. | Methods of rendering a mobile application page based on past usage information and related wireless devices |
US10777186B1 (en) * | 2018-11-13 | 2020-09-15 | Amazon Technolgies, Inc. | Streaming real-time automatic speech recognition service |
US11003566B2 (en) * | 2018-12-31 | 2021-05-11 | Paypal, Inc. | Tracking data flow through data services using a processing request identifier in callstack data |
CN110289015B (en) * | 2019-05-27 | 2021-09-17 | 北京大米科技有限公司 | Audio processing method, device, server, storage medium and system |
US11922193B2 (en) | 2020-02-28 | 2024-03-05 | Google Llc | Interface and mode selection for digital action execution |
US11645465B2 (en) | 2020-12-10 | 2023-05-09 | International Business Machines Corporation | Anaphora resolution for enhanced context switching |
US20220398691A1 (en) * | 2021-06-10 | 2022-12-15 | Citrix Systems, Inc. | Content display with focused area |
Citations (240)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
GB2305747A (en) | 1995-09-30 | 1997-04-16 | Ibm | Load balancing of connections to parallel servers |
WO1997021183A1 (en) | 1995-12-08 | 1997-06-12 | Bell Communications Research, Inc. | Method and system for placing advertisements in a computer network |
US5675788A (en) | 1995-09-15 | 1997-10-07 | Infonautics Corp. | Method and apparatus for generating a composite document on a selected topic from a plurality of information sources |
US5724521A (en) | 1994-11-03 | 1998-03-03 | Intel Corporation | Method and apparatus for providing electronic advertisements to end users in a consumer best-fit pricing manner |
US5740549A (en) | 1995-06-12 | 1998-04-14 | Pointcast, Inc. | Information and advertising distribution system and method |
US5749069A (en) | 1994-03-18 | 1998-05-05 | Atr Human Information Processing Research Laboratories | Pattern and speech recognition using accumulated partial scores from a posteriori odds, with pruning based on calculation amount |
US5848397A (en) | 1996-04-19 | 1998-12-08 | Juno Online Services, L.P. | Method and apparatus for scheduling the presentation of messages to computer users |
US5850433A (en) | 1996-05-01 | 1998-12-15 | Sprint Communication Co. L.P. | System and method for providing an on-line directory service |
JPH1165950A (en) | 1997-08-15 | 1999-03-09 | Sony Corp | Method and system for communicating information, portable radio communication terminal and server equipment |
US5930773A (en) | 1997-12-17 | 1999-07-27 | Avista Advantage, Inc. | Computerized resource accounting methods and systems, computerized utility management methods and systems, multi-user utility management methods and systems, and energy-consumption-based tracking methods and systems |
US5948061A (en) | 1996-10-29 | 1999-09-07 | Double Click, Inc. | Method of delivery, targeting, and measuring advertising over networks |
JPH11265347A (en) | 1998-01-16 | 1999-09-28 | Toshiba Corp | Distributed network computing system, information switching device and method to be used for the system and computer readable storage medium storing information switching method program information |
US6026368A (en) | 1995-07-17 | 2000-02-15 | 24/7 Media, Inc. | On-line interactive system and method for providing content and advertising information to a targeted set of viewers |
US6044376A (en) | 1997-04-24 | 2000-03-28 | Imgis, Inc. | Content stream analysis |
US6078914A (en) | 1996-12-09 | 2000-06-20 | Open Text Corporation | Natural language meta-search system and method |
WO2000042544A2 (en) | 1999-01-15 | 2000-07-20 | Imandi Corporation | Extraction of vendor information from web sites |
KR20000054165A (en) | 2000-05-24 | 2000-09-05 | 김병남 | Internet advertisement system and the method therefore using geographical information. |
US6125284A (en) | 1994-03-10 | 2000-09-26 | Cable & Wireless Plc | Communication system with handset for distributed processing |
US6144944A (en) | 1997-04-24 | 2000-11-07 | Imgis, Inc. | Computer system for efficiently selecting and providing information |
US6167382A (en) | 1998-06-01 | 2000-12-26 | F.A.C. Services Group, L.P. | Design and production of print advertising and commercial display materials over the Internet |
US6189003B1 (en) | 1998-10-23 | 2001-02-13 | Wynwyn.Com Inc. | Online business directory with predefined search template for facilitating the matching of buyers to qualified sellers |
US6259127B1 (en) | 1995-12-19 | 2001-07-10 | Micron Technology, Inc. | Integrated circuit container having partially rugged surface |
US6259405B1 (en) | 1995-06-06 | 2001-07-10 | Wayport, Inc. | Geographic based communications service |
US6269361B1 (en) | 1999-05-28 | 2001-07-31 | Goto.Com | System and method for influencing a position on a search result list generated by a computer network search engine |
US6275806B1 (en) | 1999-08-31 | 2001-08-14 | Andersen Consulting, Llp | System method and article of manufacture for detecting emotion in voice signals by utilizing statistics for voice signal parameters |
WO2001059546A2 (en) | 2000-02-11 | 2001-08-16 | Wynwyn.Com, Inc. | Online business directory with thesaurus and search template |
JP2001236410A (en) | 2000-02-21 | 2001-08-31 | Kyota Iwaoka | Method and system for interconnection type advertisement distribution |
US20010020236A1 (en) | 1998-03-11 | 2001-09-06 | Cannon Mark E. | Method and apparatus for analyzing data and advertising optimization |
US20010025275A1 (en) | 2000-03-23 | 2001-09-27 | Nobuaki Tanaka | System for internet connections, method for calculating connection fees for network connection services, billing system for network connection services, and system for network connection management |
JP2001282982A (en) | 2000-03-28 | 2001-10-12 | Hisahiro Negi | Web marketing system |
JP2001297256A (en) | 2000-04-12 | 2001-10-26 | Kuku:Kk | Method for controlling server computer |
JP2001312649A (en) | 2000-05-01 | 2001-11-09 | Adc Technology Kk | Advertising system and recording medium |
JP2001312646A (en) | 2000-04-28 | 2001-11-09 | Occs Planning Corp | Advertisement medium rental system in outdoor advertisement |
WO2001093138A1 (en) | 2000-05-31 | 2001-12-06 | Ntt Docomo, Inc. | Method and system for distributing advertisements over network |
US6332127B1 (en) | 1999-01-28 | 2001-12-18 | International Business Machines Corporation | Systems, methods and computer program products for providing time and location specific advertising via the internet |
JP2002007253A (en) | 2000-06-19 | 2002-01-11 | Freebit.Com Co Ltd | Internet connection system, and system and method for providing information to internet user |
JP2002016970A (en) | 2000-06-29 | 2002-01-18 | Toshiba Corp | Position information notifying system and position information notifying server and mobile communication terminal |
US20020029226A1 (en) | 2000-09-05 | 2002-03-07 | Gang Li | Method for combining data with maps |
JP2002073666A (en) | 2000-08-29 | 2002-03-12 | Sharp Corp | Information providing system, information providing server, information receiving terminal and recording medium with information providing program recorded thereon |
KR200269767Y1 (en) | 2001-12-07 | 2002-03-25 | 김동춘 | Pipe connecting member for assembling a chair |
JP2002099822A (en) | 2000-09-26 | 2002-04-05 | Minoru Sato | Advertisement system, advertisement method, and information storage medium |
US20020042829A1 (en) | 1998-01-16 | 2002-04-11 | Kabushiki Kaisha Toshiba | Method and system for a distributed network computing system for providing application services |
JP2002132827A (en) | 2000-03-06 | 2002-05-10 | Katsuyoshi Nagashima | Device and method for automatic retrieval of advertisement information from internet information |
JP2002140359A (en) | 2000-11-01 | 2002-05-17 | Masayuki Hasegawa | Advertisement distribution system, advertisement contents, and device and method for advertisement distribution |
US6401075B1 (en) | 2000-02-14 | 2002-06-04 | Global Network, Inc. | Methods of placing, purchasing and monitoring internet advertising |
JP2002169744A (en) | 2000-12-04 | 2002-06-14 | Ntt Me Corp | Device and method for additional information distribution |
JP2002170027A (en) | 2000-12-04 | 2002-06-14 | Standard J:Kk | Advertisement delivery business and system |
US20020077130A1 (en) | 1998-01-21 | 2002-06-20 | Craig A. Owensby | System and method for providing targeted messages based on wireless mobile location |
US20020082938A1 (en) | 2000-07-19 | 2002-06-27 | Dana Borger | Systems, methods and computer program products that facilitate and account for call-through advertising between advertisers and users of web-enabled telephone devices |
US20020091571A1 (en) | 2000-11-10 | 2002-07-11 | Thomas Nicholas A. | Methods and systems for electronic coupon issuance transmission and mangement |
JP2002245048A (en) | 2001-02-20 | 2002-08-30 | Mitsubishi Electric Corp | Method and device for retrieving image |
US6446045B1 (en) | 2000-01-10 | 2002-09-03 | Lucinda Stone | Method for using computers to facilitate and control the creating of a plurality of functions |
KR20020069767A (en) | 2001-02-27 | 2002-09-05 | 안성균 | Sales promotion and advertisement providing system using personal information communication terminal |
US20020128908A1 (en) | 2000-09-15 | 2002-09-12 | Levin Brian E. | System for conducting user-specific promotional campaigns using multiple communications device platforms |
JP2002288541A (en) | 2001-03-28 | 2002-10-04 | Ntt Comware Corp | Advertisement rate charging system, program therefor, and computer-readable recording medium with the program recorded |
US20020161646A1 (en) | 2001-04-27 | 2002-10-31 | Gailey Michael L. | Advertising campaign and business listing management for a location-based services system |
US20020164977A1 (en) | 2001-04-02 | 2002-11-07 | Link Ii Charles M. | System and method for providing short message targeted advertisements over a wireless communications network |
US20020188680A1 (en) | 2001-06-11 | 2002-12-12 | Mccormack Tony | Establishing telephone calls at specified times |
EP1271458A2 (en) | 2001-06-22 | 2003-01-02 | Navigation Technologies Corporation | Geographic database organization that facilitates location-based advertising |
US20030008661A1 (en) | 2001-07-03 | 2003-01-09 | Joyce Dennis P. | Location-based content delivery |
JP2003016348A (en) | 2001-07-04 | 2003-01-17 | Nec Commun Syst Ltd | Advertisement distributing method |
US20030018479A1 (en) | 2001-07-19 | 2003-01-23 | Samsung Electronics Co., Ltd. | Electronic appliance capable of preventing malfunction in speech recognition and improving the speech recognition rate |
US20030028529A1 (en) | 2001-08-03 | 2003-02-06 | Cheung Dominic Dough-Ming | Search engine account monitoring |
US20030033079A1 (en) | 2001-08-11 | 2003-02-13 | Endicott William L. | Computer-implemented system and method for wayfinding |
US20030032409A1 (en) | 2001-03-16 | 2003-02-13 | Hutcheson Stewart Douglas | Method and system for distributing content over a wireless communications system |
US20030032406A1 (en) | 2001-08-13 | 2003-02-13 | Brian Minear | System and method for licensing applications on wireless devices over a wireless network |
US20030033292A1 (en) | 1999-05-28 | 2003-02-13 | Ted Meisel | System and method for enabling multi-element bidding for influencinga position on a search result list generated by a computer network search engine |
US20030046161A1 (en) | 2001-09-06 | 2003-03-06 | Kamangar Salar Arta | Methods and apparatus for ordering advertisements based on performance information and price information |
US20030061211A1 (en) | 2000-06-30 | 2003-03-27 | Shultz Troy L. | GIS based search engine |
JP2003122781A (en) | 2001-10-17 | 2003-04-25 | Super Contents Distrubutions Ltd | Method for distributing merchandise information |
US20030105677A1 (en) | 2001-11-30 | 2003-06-05 | Skinner Christopher J. | Automated web ranking bid management account system |
US20030125977A1 (en) | 2001-11-20 | 2003-07-03 | Mikio Morioka | Electronic commerce service system, electronic commerce terminal, electronic commerce service server, and computer program |
US6600930B1 (en) | 1997-07-11 | 2003-07-29 | Sony Corporation | Information provision system, information regeneration terminal, and server |
US20030154072A1 (en) | 1998-03-31 | 2003-08-14 | Scansoft, Inc., A Delaware Corporation | Call analysis |
JP2003263584A (en) | 2002-03-07 | 2003-09-19 | Fujitsu Ltd | Method and device for transmitting advertisement |
US20030220835A1 (en) | 2002-05-23 | 2003-11-27 | Barnes Melvin L. | System, method, and computer program product for providing location based services and mobile e-commerce |
JP2003337893A (en) | 2002-05-20 | 2003-11-28 | Sharp Corp | Device, method, and program for distributing information, and computer readable recording medium in which information distribution program is recorded |
US6665293B2 (en) | 1999-11-10 | 2003-12-16 | Quintum Technologies, Inc. | Application for a voice over IP (VoIP) telephony gateway and methods for use therein |
US6677894B2 (en) | 1998-04-28 | 2004-01-13 | Snaptrack, Inc | Method and apparatus for providing location-based information via a computer network |
US6684249B1 (en) | 2000-05-26 | 2004-01-27 | Sonicbox, Inc. | Method and system for adding advertisements over streaming audio based upon a user profile over a world wide area network of computers |
JP2004032037A (en) | 2002-06-21 | 2004-01-29 | Hitachi Ltd | Information reception and transmission system, information processing apparatus used therefor and mobile terminal |
KR200339736Y1 (en) | 2003-09-16 | 2004-01-31 | 고재석 | Apparatus for activating energy and water treatment using ultrasonic vibration |
US20040023666A1 (en) | 2002-03-19 | 2004-02-05 | Moon George Christopher | Location based service provider |
US20040030556A1 (en) | 1999-11-12 | 2004-02-12 | Bennett Ian M. | Speech based learning/training system using semantic decoding |
US20040044565A1 (en) | 2002-08-28 | 2004-03-04 | Manoj Kumar | Targeted online marketing |
US20040043770A1 (en) | 2000-07-10 | 2004-03-04 | Assaf Amit | Broadcast content over cellular telephones |
US20040044571A1 (en) | 2002-08-27 | 2004-03-04 | Bronnimann Eric Robert | Method and system for providing advertising listing variance in distribution feeds over the internet to maximize revenue to the advertising distributor |
US20040059712A1 (en) | 2002-09-24 | 2004-03-25 | Dean Jeffrey A. | Serving advertisements using information associated with e-mail |
US20040076279A1 (en) | 2000-05-16 | 2004-04-22 | John Taschereau | Method and system for providing geographically targeted information and advertising |
US20040083133A1 (en) | 2001-06-14 | 2004-04-29 | Nicholas Frank C. | Method and system for providing network based target advertising and encapsulation |
US6731612B1 (en) | 1998-06-29 | 2004-05-04 | Microsoft Corporation | Location-based web browsing |
US20040085894A1 (en) | 2002-10-31 | 2004-05-06 | Linghsiao Wang | Apparatus for link failure detection on high availability Ethernet backplane |
US20040120323A1 (en) | 2002-11-12 | 2004-06-24 | Nokia Corporation | Method and system for providing location-based services in multiple coverage area environments |
US20040172389A1 (en) | 2001-07-27 | 2004-09-02 | Yaron Galai | System and method for automated tracking and analysis of document usage |
US20040220778A1 (en) | 2001-08-02 | 2004-11-04 | Kanehisa Imai | Remote maintenance system and stock management system |
US20050027659A1 (en) | 2003-07-31 | 2005-02-03 | Rajnish Kumar | Fortuitous combinations of ad-hoc available sets of different electronic devices to respond to user jobs |
US6857007B1 (en) | 2000-08-30 | 2005-02-15 | Bloomfield Enterprises, Llc | Personal digital assistant facilitated communication system |
US20050065999A1 (en) | 1998-09-01 | 2005-03-24 | Swarup Acharya | Computer implemented method and apparatus for fulfilling a request for information content with a user-selectable version of a file containing that information content |
US20050076017A1 (en) | 2003-10-03 | 2005-04-07 | Rein Douglas R. | Method and system for scheduling search terms in a search engine account |
US20050074102A1 (en) | 2003-10-06 | 2005-04-07 | Ebbe Altberg | Method and apparatus to provide pay-per-call performance based advertising |
US20050086104A1 (en) | 2003-10-17 | 2005-04-21 | Mcfadden Jeffrey A. | Delivery of advertising to telephone users |
US20050097204A1 (en) | 2003-09-23 | 2005-05-05 | Horowitz Russell C. | Performance-based online advertising system and method |
US20050137939A1 (en) | 2003-12-19 | 2005-06-23 | Palo Alto Research Center Incorporated | Server-based keyword advertisement management |
US20050144069A1 (en) | 2003-12-23 | 2005-06-30 | Wiseman Leora R. | Method and system for providing targeted graphical advertisements |
US20050144065A1 (en) | 2003-12-19 | 2005-06-30 | Palo Alto Research Center Incorporated | Keyword advertisement management with coordinated bidding among advertisers |
US20050187823A1 (en) | 2004-02-23 | 2005-08-25 | Howes Jeffrey V. | Method and system for geographically-targeted internet advertising |
US20050225810A1 (en) | 2004-04-02 | 2005-10-13 | Sun Fang C | Image retrieval and memory-accessing business card scanning device |
US6956816B1 (en) | 2001-02-15 | 2005-10-18 | Extreme Networks | Fault tolerant automatic protection switching for distributed routers |
US20050234879A1 (en) | 2004-04-15 | 2005-10-20 | Hua-Jun Zeng | Term suggestion for multi-sense query |
US6983331B1 (en) | 2000-10-17 | 2006-01-03 | Microsoft Corporation | Selective display of content |
US20060004627A1 (en) | 2004-06-30 | 2006-01-05 | Shumeet Baluja | Advertisements for devices with call functionality, such as mobile phones |
US6985882B1 (en) | 1999-02-05 | 2006-01-10 | Directrep, Llc | Method and system for selling and purchasing media advertising over a distributed communication network |
US7016343B1 (en) | 2001-12-28 | 2006-03-21 | Cisco Technology, Inc. | PSTN call routing control features applied to a VoIP |
US7039599B2 (en) | 1997-06-16 | 2006-05-02 | Doubleclick Inc. | Method and apparatus for automatic placement of advertising |
US20060149624A1 (en) | 2004-12-30 | 2006-07-06 | Shumeet Baluja | Generating and/or serving local area advertisements, such as advertisements for devices with call functionality |
US20060195819A1 (en) | 2005-02-25 | 2006-08-31 | Microsoft Corporation | Method and system for verifying rule compliance of an application object |
JP2006236324A (en) | 2005-02-22 | 2006-09-07 | Samsung Electronics Co Ltd | Home network system and method for transmitting content thereof |
US20060247913A1 (en) | 2005-04-29 | 2006-11-02 | International Business Machines Corporation | Method, apparatus, and computer program product for one-step correction of voice interaction |
US7136875B2 (en) | 2002-09-24 | 2006-11-14 | Google, Inc. | Serving advertisements based on content |
US20060274869A1 (en) | 2005-06-07 | 2006-12-07 | Yahoo! Inc. | Dynamically generating content based on capabilities of a mobile device |
US20060287919A1 (en) | 2005-06-02 | 2006-12-21 | Blue Mustard Llc | Advertising search system and method |
US20070005570A1 (en) | 2005-06-30 | 2007-01-04 | Microsoft Corporation | Searching for content using voice search queries |
US20070088609A1 (en) | 2002-10-25 | 2007-04-19 | Medio Systems, Inc. | Optimizer For Selecting Supplemental Content Based on Content Productivity of a Document |
US20070100822A1 (en) * | 2005-10-31 | 2007-05-03 | Freeman Jackie A | Difference control for generating and displaying a difference result set from the result sets of a plurality of search engines |
US20070097975A1 (en) | 2005-11-02 | 2007-05-03 | Sbc Knowledge Ventures, L.P. | Service to push author-spoken audio content with targeted audio advertising to users |
US20070127688A1 (en) | 2006-02-10 | 2007-06-07 | Spinvox Limited | Mass-Scale, User-Independent, Device-Independent Voice Messaging System |
US20070282612A1 (en) | 2006-05-31 | 2007-12-06 | Funai Electric Co., Ltd. | Electronic equipment |
US20070294229A1 (en) | 1998-05-28 | 2007-12-20 | Q-Phrase Llc | Chat conversation methods traversing a provisional scaffold of meanings |
US20080021604A1 (en) | 2006-07-20 | 2008-01-24 | The Boeing Company | Maintenance interval determination and optimization tool and method |
US20080049696A1 (en) | 1995-06-06 | 2008-02-28 | Stewart Brett B | Method and apparatus for geographic-based communications service |
US20080052219A1 (en) | 2006-03-31 | 2008-02-28 | Combinenet, Inc. | System for and method of expressive auctions of user events |
US20080071536A1 (en) | 2006-09-15 | 2008-03-20 | Honda Motor Co., Ltd. | Voice recognition device, voice recognition method, and voice recognition program |
US20080103781A1 (en) | 2006-10-28 | 2008-05-01 | General Motors Corporation | Automatically adapting user guidance in automated speech recognition |
US7376640B1 (en) | 2000-11-14 | 2008-05-20 | At&T Delaware Intellectual Property, Inc. | Method and system for searching an information retrieval system according to user-specified location information |
US7406434B1 (en) | 2000-12-15 | 2008-07-29 | Carl Meyer | System and method for improving the performance of electronic media advertising campaigns through multi-attribute analysis and optimization |
US20080227484A1 (en) | 2005-06-13 | 2008-09-18 | France Telecom | Method for Modifying Service Mode Requested by a Communications Terminal |
US20080228494A1 (en) * | 2007-03-13 | 2008-09-18 | Cross Charles W | Speech-Enabled Web Content Searching Using A Multimodal Browser |
US20080243785A1 (en) * | 2007-03-30 | 2008-10-02 | Tyron Jerrod Stading | System and methods of searching data sources |
US20080249855A1 (en) | 2007-04-04 | 2008-10-09 | Yahoo! Inc. | System for generating advertising creatives |
US20080270223A1 (en) | 2005-07-29 | 2008-10-30 | Yahoo! Inc. | System and Method for Creating and Providing a User Interface for Displaying Advertiser Defined Groups of Advertisement Campaign Information |
US20080270224A1 (en) | 2001-04-27 | 2008-10-30 | Accenture Llp | Location-based services system |
US20080294609A1 (en) | 2003-04-04 | 2008-11-27 | Hongche Liu | Canonicalization of terms in a keyword-based presentation system |
US20080305778A1 (en) | 2007-06-11 | 2008-12-11 | Cvon Innovations Limited | System and Method for Determining Mobile Device Capabilities |
US20090210491A1 (en) | 2008-02-20 | 2009-08-20 | Microsoft Corporation | Techniques to automatically identify participants for a multimedia conference event |
US20090228281A1 (en) | 2008-03-07 | 2009-09-10 | Google Inc. | Voice Recognition Grammar Selection Based on Context |
US20090240670A1 (en) | 2008-03-20 | 2009-09-24 | Yahoo! Inc. | Uniform resource identifier alignment |
US7613637B2 (en) | 2004-12-19 | 2009-11-03 | Bcks | Participant node for a searchable distributed information network |
US20100198772A1 (en) | 2009-02-05 | 2010-08-05 | Google Inc. | Determining conversion probability using session metrics |
US20100306229A1 (en) | 2009-06-01 | 2010-12-02 | Aol Inc. | Systems and Methods for Improved Web Searching |
US7853255B2 (en) | 2004-04-16 | 2010-12-14 | Broadcom Corporation | Digital personal assistance via a broadband access gateway |
US20110010240A1 (en) | 2003-01-10 | 2011-01-13 | Eric Veach | Governing the serving of advertisements based on a cost target |
US20110014925A1 (en) | 2005-11-08 | 2011-01-20 | Mario Antic | Base Station System Performance Measurement System in a GSM Radio Communication Network |
US20110022460A1 (en) | 2009-07-22 | 2011-01-27 | Yahoo! Inc. | Explicit online advertising exposure terms |
US7881936B2 (en) | 1998-12-04 | 2011-02-01 | Tegic Communications, Inc. | Multimodal disambiguation of speech recognition |
US7904460B2 (en) | 2008-04-23 | 2011-03-08 | Microsoft Corporation | Determining computer information from processor properties |
US7920682B2 (en) | 2001-08-21 | 2011-04-05 | Byrne William J | Dynamic interactive voice interface |
US20110087660A1 (en) | 2007-03-01 | 2011-04-14 | Microsoft Corporation | Scoring relevance of a document based on image text |
US20110141925A1 (en) | 2009-12-10 | 2011-06-16 | Mihails Velenko | Measuring call quality |
US20110202494A1 (en) | 2010-02-17 | 2011-08-18 | Gm Global Technology Operations, Inc. | Method and apparatus for vehicle component health prognosis by integrating aging model, usage information and health signatures |
JP2011192102A (en) | 2010-03-16 | 2011-09-29 | Yahoo Japan Corp | Device and method for creating summary, and program |
US8041709B2 (en) | 2007-05-25 | 2011-10-18 | Microsoft Corporation | Domain collapsing of search results |
US20110264644A1 (en) | 2009-03-20 | 2011-10-27 | Ad-Vantage Networks, Llc. | Methods and systems for searching, selecting, and displaying content |
US8068604B2 (en) | 2008-12-19 | 2011-11-29 | Computer Product Introductions Corporation | Method and system for event notifications |
US20110295990A1 (en) | 2010-06-01 | 2011-12-01 | Meltwater News International Holdings, GmbH | Method and Apparatus for Embedding Information in a Short URL |
US20110295682A1 (en) | 2009-03-02 | 2011-12-01 | Yahoo! Inc. | Optimized search result columns on search results pages |
US20110307436A1 (en) | 2010-06-10 | 2011-12-15 | Microsoft Corporation | Pattern tree-based rule learning |
US20110320114A1 (en) | 2010-06-28 | 2011-12-29 | Microsoft Corporation | Map Annotation Messaging |
US20120016897A1 (en) * | 2010-07-16 | 2012-01-19 | Altruik, Inc. | System and method for improving webpage indexing and optimization |
US8108383B2 (en) | 2006-01-31 | 2012-01-31 | Google Inc. | Enhanced search results |
US20120030015A1 (en) | 2010-07-29 | 2012-02-02 | Google Inc. | Automatic abstracted creative generation from a web site |
US20120036226A1 (en) | 2010-08-09 | 2012-02-09 | Mskynet, Inc. | Uri service system and method |
US20120102087A1 (en) | 2010-10-20 | 2012-04-26 | Mskynet, Inc. | Link status system and method |
US20120101776A1 (en) | 2010-10-26 | 2012-04-26 | Brower Alfred N | Embedded prognostic health management system for aeronautical machines and devices and methods thereof |
US20120102020A1 (en) | 2003-12-04 | 2012-04-26 | Mark Pearson | Generating Search Result Listing with Anchor Text Based Description of Website Corresponding to Search Result |
US8175914B1 (en) | 2007-07-30 | 2012-05-08 | Google Inc. | Automatic adjustment of advertiser bids to equalize cost-per-conversion among publishers for an advertisement |
US8195133B2 (en) | 2005-09-14 | 2012-06-05 | Jumptap, Inc. | Mobile dynamic advertisement creation and placement |
US20120138671A1 (en) | 2010-12-03 | 2012-06-07 | Echostar Technologies L.L.C. | Provision of Alternate Content in Response to QR Code |
US8204881B2 (en) | 1999-06-18 | 2012-06-19 | Vision Point Services, Llc | Information search, retrieval and distillation into knowledge objects |
US20120155838A1 (en) | 2010-12-20 | 2012-06-21 | Echostar Technologies L.L.C. | Matrix Code-Based User Interface |
US20120158954A1 (en) | 2010-09-22 | 2012-06-21 | Ronan Heffernan | Methods and apparatus to determine impressions using distributed demographic information |
US20120166277A1 (en) | 2010-12-28 | 2012-06-28 | Yahoo! Inc. | Variation of minimum advertisement relevance quality threshold based on search query attributes |
US8214342B2 (en) | 2001-08-23 | 2012-07-03 | Michael Meiresonne | Supplier identification and locator system and method |
WO2012094329A1 (en) | 2011-01-05 | 2012-07-12 | Envidient, Inc. | System and method for managing media content |
US20120221724A1 (en) | 2011-02-28 | 2012-08-30 | Mskynet, Inc. | Smart link system and method |
US20120265528A1 (en) | 2009-06-05 | 2012-10-18 | Apple Inc. | Using Context Information To Facilitate Processing Of Commands In A Virtual Assistant |
US8312014B2 (en) | 2003-12-29 | 2012-11-13 | Yahoo! Inc. | Lateral search |
US20120297174A1 (en) | 2011-05-17 | 2012-11-22 | Michael Frank | Modifying Operating Parameters Based on Device Use |
US8326637B2 (en) | 2009-02-20 | 2012-12-04 | Voicebox Technologies, Inc. | System and method for processing multi-modal device interactions in a natural language voice services environment |
US20130013749A1 (en) | 2007-03-30 | 2013-01-10 | Kane Jr Francis J | Services for providing item association data |
US8386386B1 (en) | 2009-01-05 | 2013-02-26 | Sprint Communications Company L.P. | Phone usage pattern as credit card fraud detection trigger |
US20130073400A1 (en) | 2011-09-15 | 2013-03-21 | Stephan HEATH | Broad and alternative category clustering of the same, similar or different categories in social/geo/promo link promotional data sets for end user display of interactive ad links, promotions and sale of products, goods and services integrated with 3d spatial geomapping and social networking |
US20130117022A1 (en) | 2010-01-18 | 2013-05-09 | Apple Inc. | Personalized Vocabulary for Digital Assistant |
US20130124606A1 (en) | 2011-11-14 | 2013-05-16 | Boopsie, Inc. | Automatic personalization of downloadable mobile apps |
US8453058B1 (en) | 2012-02-20 | 2013-05-28 | Google Inc. | Crowd-sourced audio shortcuts |
US20130144720A1 (en) | 2011-12-06 | 2013-06-06 | Yahoo! Inc. | System for Advertisement Display |
US20130191226A1 (en) | 2012-01-20 | 2013-07-25 | Bradley Hopkins Smallwood | Pricing and delivery of advertising based on exposure time |
US20130275164A1 (en) * | 2010-01-18 | 2013-10-17 | Apple Inc. | Intelligent Automated Assistant |
JP2013540306A (en) | 2010-09-17 | 2013-10-31 | トムソン ライセンシング | Communication method and communication system |
US20130304758A1 (en) | 2012-05-14 | 2013-11-14 | Apple Inc. | Crowd Sourcing Information to Fulfill User Requests |
US20130325449A1 (en) | 2012-05-31 | 2013-12-05 | Elwha Llc | Speech recognition adaptation systems based on adaptation data |
US8612226B1 (en) | 2013-01-28 | 2013-12-17 | Google Inc. | Determining advertisements based on verbal inputs to applications on a computing device |
US20130339030A1 (en) | 2012-06-13 | 2013-12-19 | Fluential, Llc | Interactive spoken dialogue interface for collection of structured data |
WO2014004489A1 (en) | 2012-06-25 | 2014-01-03 | Google, Inc. | System and method for deploying ads based on a content exposure interval |
US20140074895A1 (en) | 2012-08-27 | 2014-03-13 | David Ingerman | Geographic location coding system |
US20140095583A1 (en) | 2012-09-28 | 2014-04-03 | Disney Enterprises, Inc. | Client-side web site selection according to device capabilities |
US20140115635A1 (en) * | 2012-10-23 | 2014-04-24 | Samsung Electronics Co., Ltd. | Program recommendation device and program recommendation program |
US8762156B2 (en) | 2011-09-28 | 2014-06-24 | Apple Inc. | Speech recognition repair using contextual information |
US20140229184A1 (en) | 2013-02-14 | 2014-08-14 | Google Inc. | Waking other devices for additional data |
US20140337028A1 (en) | 2013-05-12 | 2014-11-13 | Shyh-Jye Wang | Message-triggered voice command interface in portable electronic devices |
US20140350938A1 (en) | 2008-04-11 | 2014-11-27 | At&T Intellectual Property I, L.P. | System and method for detecting synthetic speaker verification |
JP2015001815A (en) | 2013-06-14 | 2015-01-05 | 西日本電信電話株式会社 | Digital signage system |
US20150081288A1 (en) | 2013-09-17 | 2015-03-19 | Electronics And Telecommunications Research Institute | Speech recognition device and the operation method thereof |
US20150106085A1 (en) | 2013-10-11 | 2015-04-16 | Apple Inc. | Speech recognition wake-up of a handheld portable electronic device |
US20150221305A1 (en) | 2014-02-05 | 2015-08-06 | Google Inc. | Multiple speech locale-specific hotword classifiers for selection of a speech locale |
WO2015133022A1 (en) | 2014-03-03 | 2015-09-11 | ソニー株式会社 | Information processing apparatus, information processing method, and program |
US9275637B1 (en) | 2012-11-06 | 2016-03-01 | Amazon Technologies, Inc. | Wake word evaluation |
US20160105718A1 (en) | 2013-06-05 | 2016-04-14 | Thomson Licensing | Method and apparatus for content distribution for multiscreen viewing |
US9318107B1 (en) | 2014-10-09 | 2016-04-19 | Google Inc. | Hotword detection on multiple devices |
JP2016111406A (en) | 2014-12-02 | 2016-06-20 | ソニー株式会社 | Information processing device, information processing method, and program |
US20160180846A1 (en) | 2014-12-17 | 2016-06-23 | Hyundai Motor Company | Speech recognition apparatus, vehicle including the same, and method of controlling the same |
US20160223640A1 (en) | 2015-02-03 | 2016-08-04 | Nokia Technologies Oy | Radio and audio localization |
US9424841B2 (en) | 2014-10-09 | 2016-08-23 | Google Inc. | Hotword detection on multiple devices |
US20160246929A1 (en) | 2013-10-07 | 2016-08-25 | President And Fellows Of Harvard College | Computer implemented method, computer system and software for reducing errors associated with a situated interaction |
US9431006B2 (en) | 2009-07-02 | 2016-08-30 | Apple Inc. | Methods and apparatuses for automatic speech recognition |
US20160259497A1 (en) * | 2015-03-08 | 2016-09-08 | Apple Inc. | Devices, Methods, and Graphical User Interfaces for Manipulating User Interface Objects with Visual and/or Haptic Feedback |
US9542941B1 (en) | 2015-10-01 | 2017-01-10 | Lenovo (Singapore) Pte. Ltd. | Situationally suspending wakeup word to enable voice command input |
US20170069317A1 (en) | 2015-09-04 | 2017-03-09 | Samsung Electronics Co., Ltd. | Voice recognition apparatus, driving method thereof, and non-transitory computer-readable recording medium |
US20170092278A1 (en) | 2015-09-30 | 2017-03-30 | Apple Inc. | Speaker recognition |
US20170110144A1 (en) | 2015-10-16 | 2017-04-20 | Google Inc. | Hotword recognition |
US20170110130A1 (en) | 2015-10-16 | 2017-04-20 | Google Inc. | Hotword recognition |
US20170132019A1 (en) | 2015-11-06 | 2017-05-11 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US9653075B1 (en) | 2015-11-06 | 2017-05-16 | Google Inc. | Voice commands across devices |
US20170147585A1 (en) | 2014-07-22 | 2017-05-25 | Nuance Communications, Inc. | Systems and methods for speech-based searching of content repositories |
US20170289596A1 (en) | 2016-03-31 | 2017-10-05 | Microsoft Technology Licensing, Llc | Networked public multi-screen content delivery |
US20170358301A1 (en) | 2016-06-10 | 2017-12-14 | Apple Inc. | Digital assistant providing whispered speech |
US20170358302A1 (en) * | 2016-06-08 | 2017-12-14 | Apple Inc. | Intelligent automated assistant for media exploration |
US10032452B1 (en) | 2016-12-30 | 2018-07-24 | Google Llc | Multimodal transmission of packetized data |
US20180322536A1 (en) | 2014-01-14 | 2018-11-08 | Google Inc. | Resource utilization based cross device transmissions |
US10165091B1 (en) | 2015-04-03 | 2018-12-25 | Sprint Communications Company L.P. | User device parameter allocation based on internet protocol version capabilities |
US10193465B2 (en) | 2015-09-30 | 2019-01-29 | Murata Manufacturing Co., Ltd. | DC/DC conversion apparatus |
-
2017
- 2017-05-24 US US15/603,701 patent/US10735552B2/en active Active
Patent Citations (254)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6125284A (en) | 1994-03-10 | 2000-09-26 | Cable & Wireless Plc | Communication system with handset for distributed processing |
US5749069A (en) | 1994-03-18 | 1998-05-05 | Atr Human Information Processing Research Laboratories | Pattern and speech recognition using accumulated partial scores from a posteriori odds, with pruning based on calculation amount |
US5724521A (en) | 1994-11-03 | 1998-03-03 | Intel Corporation | Method and apparatus for providing electronic advertisements to end users in a consumer best-fit pricing manner |
US20080049696A1 (en) | 1995-06-06 | 2008-02-28 | Stewart Brett B | Method and apparatus for geographic-based communications service |
US6259405B1 (en) | 1995-06-06 | 2001-07-10 | Wayport, Inc. | Geographic based communications service |
US5740549A (en) | 1995-06-12 | 1998-04-14 | Pointcast, Inc. | Information and advertising distribution system and method |
US6026368A (en) | 1995-07-17 | 2000-02-15 | 24/7 Media, Inc. | On-line interactive system and method for providing content and advertising information to a targeted set of viewers |
US5675788A (en) | 1995-09-15 | 1997-10-07 | Infonautics Corp. | Method and apparatus for generating a composite document on a selected topic from a plurality of information sources |
GB2305747A (en) | 1995-09-30 | 1997-04-16 | Ibm | Load balancing of connections to parallel servers |
WO1997021183A1 (en) | 1995-12-08 | 1997-06-12 | Bell Communications Research, Inc. | Method and system for placing advertisements in a computer network |
US6259127B1 (en) | 1995-12-19 | 2001-07-10 | Micron Technology, Inc. | Integrated circuit container having partially rugged surface |
US5848397A (en) | 1996-04-19 | 1998-12-08 | Juno Online Services, L.P. | Method and apparatus for scheduling the presentation of messages to computer users |
US5850433A (en) | 1996-05-01 | 1998-12-15 | Sprint Communication Co. L.P. | System and method for providing an on-line directory service |
US5948061A (en) | 1996-10-29 | 1999-09-07 | Double Click, Inc. | Method of delivery, targeting, and measuring advertising over networks |
US6078914A (en) | 1996-12-09 | 2000-06-20 | Open Text Corporation | Natural language meta-search system and method |
US6144944A (en) | 1997-04-24 | 2000-11-07 | Imgis, Inc. | Computer system for efficiently selecting and providing information |
US6044376A (en) | 1997-04-24 | 2000-03-28 | Imgis, Inc. | Content stream analysis |
US7039599B2 (en) | 1997-06-16 | 2006-05-02 | Doubleclick Inc. | Method and apparatus for automatic placement of advertising |
US6600930B1 (en) | 1997-07-11 | 2003-07-29 | Sony Corporation | Information provision system, information regeneration terminal, and server |
JPH1165950A (en) | 1997-08-15 | 1999-03-09 | Sony Corp | Method and system for communicating information, portable radio communication terminal and server equipment |
US5930773A (en) | 1997-12-17 | 1999-07-27 | Avista Advantage, Inc. | Computerized resource accounting methods and systems, computerized utility management methods and systems, multi-user utility management methods and systems, and energy-consumption-based tracking methods and systems |
US6088688A (en) | 1997-12-17 | 2000-07-11 | Avista Advantage, Inc. | Computerized resource accounting methods and systems, computerized utility management methods and systems, multi-user utility management methods and systems, and energy-consumption-based tracking methods and systems |
US20020042829A1 (en) | 1998-01-16 | 2002-04-11 | Kabushiki Kaisha Toshiba | Method and system for a distributed network computing system for providing application services |
JPH11265347A (en) | 1998-01-16 | 1999-09-28 | Toshiba Corp | Distributed network computing system, information switching device and method to be used for the system and computer readable storage medium storing information switching method program information |
US6647257B2 (en) | 1998-01-21 | 2003-11-11 | Leap Wireless International, Inc. | System and method for providing targeted messages based on wireless mobile location |
US20020077130A1 (en) | 1998-01-21 | 2002-06-20 | Craig A. Owensby | System and method for providing targeted messages based on wireless mobile location |
US20010020236A1 (en) | 1998-03-11 | 2001-09-06 | Cannon Mark E. | Method and apparatus for analyzing data and advertising optimization |
US20030154072A1 (en) | 1998-03-31 | 2003-08-14 | Scansoft, Inc., A Delaware Corporation | Call analysis |
US6677894B2 (en) | 1998-04-28 | 2004-01-13 | Snaptrack, Inc | Method and apparatus for providing location-based information via a computer network |
US20070294229A1 (en) | 1998-05-28 | 2007-12-20 | Q-Phrase Llc | Chat conversation methods traversing a provisional scaffold of meanings |
US6167382A (en) | 1998-06-01 | 2000-12-26 | F.A.C. Services Group, L.P. | Design and production of print advertising and commercial display materials over the Internet |
US6731612B1 (en) | 1998-06-29 | 2004-05-04 | Microsoft Corporation | Location-based web browsing |
US20050065999A1 (en) | 1998-09-01 | 2005-03-24 | Swarup Acharya | Computer implemented method and apparatus for fulfilling a request for information content with a user-selectable version of a file containing that information content |
US6189003B1 (en) | 1998-10-23 | 2001-02-13 | Wynwyn.Com Inc. | Online business directory with predefined search template for facilitating the matching of buyers to qualified sellers |
US7881936B2 (en) | 1998-12-04 | 2011-02-01 | Tegic Communications, Inc. | Multimodal disambiguation of speech recognition |
WO2000042544A2 (en) | 1999-01-15 | 2000-07-20 | Imandi Corporation | Extraction of vendor information from web sites |
US6332127B1 (en) | 1999-01-28 | 2001-12-18 | International Business Machines Corporation | Systems, methods and computer program products for providing time and location specific advertising via the internet |
US6985882B1 (en) | 1999-02-05 | 2006-01-10 | Directrep, Llc | Method and system for selling and purchasing media advertising over a distributed communication network |
US6269361B1 (en) | 1999-05-28 | 2001-07-31 | Goto.Com | System and method for influencing a position on a search result list generated by a computer network search engine |
US20030033292A1 (en) | 1999-05-28 | 2003-02-13 | Ted Meisel | System and method for enabling multi-element bidding for influencinga position on a search result list generated by a computer network search engine |
US8204881B2 (en) | 1999-06-18 | 2012-06-19 | Vision Point Services, Llc | Information search, retrieval and distillation into knowledge objects |
US6275806B1 (en) | 1999-08-31 | 2001-08-14 | Andersen Consulting, Llp | System method and article of manufacture for detecting emotion in voice signals by utilizing statistics for voice signal parameters |
US6665293B2 (en) | 1999-11-10 | 2003-12-16 | Quintum Technologies, Inc. | Application for a voice over IP (VoIP) telephony gateway and methods for use therein |
US20040030556A1 (en) | 1999-11-12 | 2004-02-12 | Bennett Ian M. | Speech based learning/training system using semantic decoding |
US7240025B2 (en) | 2000-01-10 | 2007-07-03 | Lucinda Stone | Internet advertising system and method |
US6446045B1 (en) | 2000-01-10 | 2002-09-03 | Lucinda Stone | Method for using computers to facilitate and control the creating of a plurality of functions |
WO2001059546A2 (en) | 2000-02-11 | 2001-08-16 | Wynwyn.Com, Inc. | Online business directory with thesaurus and search template |
US6401075B1 (en) | 2000-02-14 | 2002-06-04 | Global Network, Inc. | Methods of placing, purchasing and monitoring internet advertising |
JP2001236410A (en) | 2000-02-21 | 2001-08-31 | Kyota Iwaoka | Method and system for interconnection type advertisement distribution |
JP2002132827A (en) | 2000-03-06 | 2002-05-10 | Katsuyoshi Nagashima | Device and method for automatic retrieval of advertisement information from internet information |
US20010025275A1 (en) | 2000-03-23 | 2001-09-27 | Nobuaki Tanaka | System for internet connections, method for calculating connection fees for network connection services, billing system for network connection services, and system for network connection management |
JP2001282982A (en) | 2000-03-28 | 2001-10-12 | Hisahiro Negi | Web marketing system |
JP2001297256A (en) | 2000-04-12 | 2001-10-26 | Kuku:Kk | Method for controlling server computer |
JP2001312646A (en) | 2000-04-28 | 2001-11-09 | Occs Planning Corp | Advertisement medium rental system in outdoor advertisement |
JP2001312649A (en) | 2000-05-01 | 2001-11-09 | Adc Technology Kk | Advertising system and recording medium |
US20040076279A1 (en) | 2000-05-16 | 2004-04-22 | John Taschereau | Method and system for providing geographically targeted information and advertising |
KR20000054165A (en) | 2000-05-24 | 2000-09-05 | 김병남 | Internet advertisement system and the method therefore using geographical information. |
US6684249B1 (en) | 2000-05-26 | 2004-01-27 | Sonicbox, Inc. | Method and system for adding advertisements over streaming audio based upon a user profile over a world wide area network of computers |
EP1286288A1 (en) | 2000-05-31 | 2003-02-26 | NTT DoCoMo, Inc. | Method and system for distributing advertisements over network |
WO2001093138A1 (en) | 2000-05-31 | 2001-12-06 | Ntt Docomo, Inc. | Method and system for distributing advertisements over network |
JP2002007253A (en) | 2000-06-19 | 2002-01-11 | Freebit.Com Co Ltd | Internet connection system, and system and method for providing information to internet user |
JP2002016970A (en) | 2000-06-29 | 2002-01-18 | Toshiba Corp | Position information notifying system and position information notifying server and mobile communication terminal |
US20030061211A1 (en) | 2000-06-30 | 2003-03-27 | Shultz Troy L. | GIS based search engine |
US20040043770A1 (en) | 2000-07-10 | 2004-03-04 | Assaf Amit | Broadcast content over cellular telephones |
US20020082938A1 (en) | 2000-07-19 | 2002-06-27 | Dana Borger | Systems, methods and computer program products that facilitate and account for call-through advertising between advertisers and users of web-enabled telephone devices |
JP2002073666A (en) | 2000-08-29 | 2002-03-12 | Sharp Corp | Information providing system, information providing server, information receiving terminal and recording medium with information providing program recorded thereon |
US6857007B1 (en) | 2000-08-30 | 2005-02-15 | Bloomfield Enterprises, Llc | Personal digital assistant facilitated communication system |
US20020029226A1 (en) | 2000-09-05 | 2002-03-07 | Gang Li | Method for combining data with maps |
US20020128908A1 (en) | 2000-09-15 | 2002-09-12 | Levin Brian E. | System for conducting user-specific promotional campaigns using multiple communications device platforms |
JP2002099822A (en) | 2000-09-26 | 2002-04-05 | Minoru Sato | Advertisement system, advertisement method, and information storage medium |
US6983331B1 (en) | 2000-10-17 | 2006-01-03 | Microsoft Corporation | Selective display of content |
JP2002140359A (en) | 2000-11-01 | 2002-05-17 | Masayuki Hasegawa | Advertisement distribution system, advertisement contents, and device and method for advertisement distribution |
US20020091571A1 (en) | 2000-11-10 | 2002-07-11 | Thomas Nicholas A. | Methods and systems for electronic coupon issuance transmission and mangement |
US7376640B1 (en) | 2000-11-14 | 2008-05-20 | At&T Delaware Intellectual Property, Inc. | Method and system for searching an information retrieval system according to user-specified location information |
JP2002169744A (en) | 2000-12-04 | 2002-06-14 | Ntt Me Corp | Device and method for additional information distribution |
JP2002170027A (en) | 2000-12-04 | 2002-06-14 | Standard J:Kk | Advertisement delivery business and system |
US7406434B1 (en) | 2000-12-15 | 2008-07-29 | Carl Meyer | System and method for improving the performance of electronic media advertising campaigns through multi-attribute analysis and optimization |
US6956816B1 (en) | 2001-02-15 | 2005-10-18 | Extreme Networks | Fault tolerant automatic protection switching for distributed routers |
JP2002245048A (en) | 2001-02-20 | 2002-08-30 | Mitsubishi Electric Corp | Method and device for retrieving image |
KR20020069767A (en) | 2001-02-27 | 2002-09-05 | 안성균 | Sales promotion and advertisement providing system using personal information communication terminal |
US20030032409A1 (en) | 2001-03-16 | 2003-02-13 | Hutcheson Stewart Douglas | Method and system for distributing content over a wireless communications system |
JP2002288541A (en) | 2001-03-28 | 2002-10-04 | Ntt Comware Corp | Advertisement rate charging system, program therefor, and computer-readable recording medium with the program recorded |
US20020164977A1 (en) | 2001-04-02 | 2002-11-07 | Link Ii Charles M. | System and method for providing short message targeted advertisements over a wireless communications network |
US20080270224A1 (en) | 2001-04-27 | 2008-10-30 | Accenture Llp | Location-based services system |
US20020161646A1 (en) | 2001-04-27 | 2002-10-31 | Gailey Michael L. | Advertising campaign and business listing management for a location-based services system |
US20020188680A1 (en) | 2001-06-11 | 2002-12-12 | Mccormack Tony | Establishing telephone calls at specified times |
US20040083133A1 (en) | 2001-06-14 | 2004-04-29 | Nicholas Frank C. | Method and system for providing network based target advertising and encapsulation |
EP1271458A2 (en) | 2001-06-22 | 2003-01-02 | Navigation Technologies Corporation | Geographic database organization that facilitates location-based advertising |
US20030008661A1 (en) | 2001-07-03 | 2003-01-09 | Joyce Dennis P. | Location-based content delivery |
JP2003016348A (en) | 2001-07-04 | 2003-01-17 | Nec Commun Syst Ltd | Advertisement distributing method |
US20030018479A1 (en) | 2001-07-19 | 2003-01-23 | Samsung Electronics Co., Ltd. | Electronic appliance capable of preventing malfunction in speech recognition and improving the speech recognition rate |
US20040172389A1 (en) | 2001-07-27 | 2004-09-02 | Yaron Galai | System and method for automated tracking and analysis of document usage |
US20040220778A1 (en) | 2001-08-02 | 2004-11-04 | Kanehisa Imai | Remote maintenance system and stock management system |
US20030028529A1 (en) | 2001-08-03 | 2003-02-06 | Cheung Dominic Dough-Ming | Search engine account monitoring |
US20030033079A1 (en) | 2001-08-11 | 2003-02-13 | Endicott William L. | Computer-implemented system and method for wayfinding |
US20030032406A1 (en) | 2001-08-13 | 2003-02-13 | Brian Minear | System and method for licensing applications on wireless devices over a wireless network |
US7920682B2 (en) | 2001-08-21 | 2011-04-05 | Byrne William J | Dynamic interactive voice interface |
US8214342B2 (en) | 2001-08-23 | 2012-07-03 | Michael Meiresonne | Supplier identification and locator system and method |
US20030046161A1 (en) | 2001-09-06 | 2003-03-06 | Kamangar Salar Arta | Methods and apparatus for ordering advertisements based on performance information and price information |
JP2003122781A (en) | 2001-10-17 | 2003-04-25 | Super Contents Distrubutions Ltd | Method for distributing merchandise information |
JP2003223591A (en) | 2001-11-20 | 2003-08-08 | Matsushita Electric Ind Co Ltd | Electronic commerce service system, electronic commerce terminal, electronic commerce service server and computer program |
US20030125977A1 (en) | 2001-11-20 | 2003-07-03 | Mikio Morioka | Electronic commerce service system, electronic commerce terminal, electronic commerce service server, and computer program |
US20030105677A1 (en) | 2001-11-30 | 2003-06-05 | Skinner Christopher J. | Automated web ranking bid management account system |
KR200269767Y1 (en) | 2001-12-07 | 2002-03-25 | 김동춘 | Pipe connecting member for assembling a chair |
US7016343B1 (en) | 2001-12-28 | 2006-03-21 | Cisco Technology, Inc. | PSTN call routing control features applied to a VoIP |
JP2003263584A (en) | 2002-03-07 | 2003-09-19 | Fujitsu Ltd | Method and device for transmitting advertisement |
US20040023666A1 (en) | 2002-03-19 | 2004-02-05 | Moon George Christopher | Location based service provider |
JP2003337893A (en) | 2002-05-20 | 2003-11-28 | Sharp Corp | Device, method, and program for distributing information, and computer readable recording medium in which information distribution program is recorded |
US20030220835A1 (en) | 2002-05-23 | 2003-11-27 | Barnes Melvin L. | System, method, and computer program product for providing location based services and mobile e-commerce |
JP2004032037A (en) | 2002-06-21 | 2004-01-29 | Hitachi Ltd | Information reception and transmission system, information processing apparatus used therefor and mobile terminal |
US20040044571A1 (en) | 2002-08-27 | 2004-03-04 | Bronnimann Eric Robert | Method and system for providing advertising listing variance in distribution feeds over the internet to maximize revenue to the advertising distributor |
US20040044565A1 (en) | 2002-08-28 | 2004-03-04 | Manoj Kumar | Targeted online marketing |
US7136875B2 (en) | 2002-09-24 | 2006-11-14 | Google, Inc. | Serving advertisements based on content |
US20040059712A1 (en) | 2002-09-24 | 2004-03-25 | Dean Jeffrey A. | Serving advertisements using information associated with e-mail |
US20070088609A1 (en) | 2002-10-25 | 2007-04-19 | Medio Systems, Inc. | Optimizer For Selecting Supplemental Content Based on Content Productivity of a Document |
US20040085894A1 (en) | 2002-10-31 | 2004-05-06 | Linghsiao Wang | Apparatus for link failure detection on high availability Ethernet backplane |
US20040120323A1 (en) | 2002-11-12 | 2004-06-24 | Nokia Corporation | Method and system for providing location-based services in multiple coverage area environments |
US20110010240A1 (en) | 2003-01-10 | 2011-01-13 | Eric Veach | Governing the serving of advertisements based on a cost target |
US20080294609A1 (en) | 2003-04-04 | 2008-11-27 | Hongche Liu | Canonicalization of terms in a keyword-based presentation system |
US20050027659A1 (en) | 2003-07-31 | 2005-02-03 | Rajnish Kumar | Fortuitous combinations of ad-hoc available sets of different electronic devices to respond to user jobs |
KR200339736Y1 (en) | 2003-09-16 | 2004-01-31 | 고재석 | Apparatus for activating energy and water treatment using ultrasonic vibration |
US7668950B2 (en) | 2003-09-23 | 2010-02-23 | Marchex, Inc. | Automatically updating performance-based online advertising system and method |
US20050097204A1 (en) | 2003-09-23 | 2005-05-05 | Horowitz Russell C. | Performance-based online advertising system and method |
US20050076017A1 (en) | 2003-10-03 | 2005-04-07 | Rein Douglas R. | Method and system for scheduling search terms in a search engine account |
US7120235B2 (en) | 2003-10-06 | 2006-10-10 | Ingenio, Inc. | Method and apparatus to provide pay-per-call performance based advertising |
US20050074102A1 (en) | 2003-10-06 | 2005-04-07 | Ebbe Altberg | Method and apparatus to provide pay-per-call performance based advertising |
US20050086104A1 (en) | 2003-10-17 | 2005-04-21 | Mcfadden Jeffrey A. | Delivery of advertising to telephone users |
US20120102020A1 (en) | 2003-12-04 | 2012-04-26 | Mark Pearson | Generating Search Result Listing with Anchor Text Based Description of Website Corresponding to Search Result |
US20050137939A1 (en) | 2003-12-19 | 2005-06-23 | Palo Alto Research Center Incorporated | Server-based keyword advertisement management |
US20050144065A1 (en) | 2003-12-19 | 2005-06-30 | Palo Alto Research Center Incorporated | Keyword advertisement management with coordinated bidding among advertisers |
US20050144069A1 (en) | 2003-12-23 | 2005-06-30 | Wiseman Leora R. | Method and system for providing targeted graphical advertisements |
US8312014B2 (en) | 2003-12-29 | 2012-11-13 | Yahoo! Inc. | Lateral search |
US20050187823A1 (en) | 2004-02-23 | 2005-08-25 | Howes Jeffrey V. | Method and system for geographically-targeted internet advertising |
US20050225810A1 (en) | 2004-04-02 | 2005-10-13 | Sun Fang C | Image retrieval and memory-accessing business card scanning device |
US20050234879A1 (en) | 2004-04-15 | 2005-10-20 | Hua-Jun Zeng | Term suggestion for multi-sense query |
US7853255B2 (en) | 2004-04-16 | 2010-12-14 | Broadcom Corporation | Digital personal assistance via a broadband access gateway |
US20060004627A1 (en) | 2004-06-30 | 2006-01-05 | Shumeet Baluja | Advertisements for devices with call functionality, such as mobile phones |
US7613637B2 (en) | 2004-12-19 | 2009-11-03 | Bcks | Participant node for a searchable distributed information network |
US20060149624A1 (en) | 2004-12-30 | 2006-07-06 | Shumeet Baluja | Generating and/or serving local area advertisements, such as advertisements for devices with call functionality |
JP2006236324A (en) | 2005-02-22 | 2006-09-07 | Samsung Electronics Co Ltd | Home network system and method for transmitting content thereof |
US20060195819A1 (en) | 2005-02-25 | 2006-08-31 | Microsoft Corporation | Method and system for verifying rule compliance of an application object |
US20060247913A1 (en) | 2005-04-29 | 2006-11-02 | International Business Machines Corporation | Method, apparatus, and computer program product for one-step correction of voice interaction |
US20060287919A1 (en) | 2005-06-02 | 2006-12-21 | Blue Mustard Llc | Advertising search system and method |
US20060274869A1 (en) | 2005-06-07 | 2006-12-07 | Yahoo! Inc. | Dynamically generating content based on capabilities of a mobile device |
US20080227484A1 (en) | 2005-06-13 | 2008-09-18 | France Telecom | Method for Modifying Service Mode Requested by a Communications Terminal |
US20070005570A1 (en) | 2005-06-30 | 2007-01-04 | Microsoft Corporation | Searching for content using voice search queries |
US20080270223A1 (en) | 2005-07-29 | 2008-10-30 | Yahoo! Inc. | System and Method for Creating and Providing a User Interface for Displaying Advertiser Defined Groups of Advertisement Campaign Information |
US8195133B2 (en) | 2005-09-14 | 2012-06-05 | Jumptap, Inc. | Mobile dynamic advertisement creation and placement |
US20070100822A1 (en) * | 2005-10-31 | 2007-05-03 | Freeman Jackie A | Difference control for generating and displaying a difference result set from the result sets of a plurality of search engines |
US20070097975A1 (en) | 2005-11-02 | 2007-05-03 | Sbc Knowledge Ventures, L.P. | Service to push author-spoken audio content with targeted audio advertising to users |
US20110014925A1 (en) | 2005-11-08 | 2011-01-20 | Mario Antic | Base Station System Performance Measurement System in a GSM Radio Communication Network |
US8108383B2 (en) | 2006-01-31 | 2012-01-31 | Google Inc. | Enhanced search results |
US20070127688A1 (en) | 2006-02-10 | 2007-06-07 | Spinvox Limited | Mass-Scale, User-Independent, Device-Independent Voice Messaging System |
US20080052219A1 (en) | 2006-03-31 | 2008-02-28 | Combinenet, Inc. | System for and method of expressive auctions of user events |
US20070282612A1 (en) | 2006-05-31 | 2007-12-06 | Funai Electric Co., Ltd. | Electronic equipment |
US20080021604A1 (en) | 2006-07-20 | 2008-01-24 | The Boeing Company | Maintenance interval determination and optimization tool and method |
US20130185074A1 (en) | 2006-09-08 | 2013-07-18 | Apple Inc. | Paraphrasing of User Requests and Results by Automated Digital Assistant |
US20080071536A1 (en) | 2006-09-15 | 2008-03-20 | Honda Motor Co., Ltd. | Voice recognition device, voice recognition method, and voice recognition program |
US20080103781A1 (en) | 2006-10-28 | 2008-05-01 | General Motors Corporation | Automatically adapting user guidance in automated speech recognition |
US20110087660A1 (en) | 2007-03-01 | 2011-04-14 | Microsoft Corporation | Scoring relevance of a document based on image text |
US20080228494A1 (en) * | 2007-03-13 | 2008-09-18 | Cross Charles W | Speech-Enabled Web Content Searching Using A Multimodal Browser |
US20080243785A1 (en) * | 2007-03-30 | 2008-10-02 | Tyron Jerrod Stading | System and methods of searching data sources |
US20130013749A1 (en) | 2007-03-30 | 2013-01-10 | Kane Jr Francis J | Services for providing item association data |
US20080249855A1 (en) | 2007-04-04 | 2008-10-09 | Yahoo! Inc. | System for generating advertising creatives |
US8041709B2 (en) | 2007-05-25 | 2011-10-18 | Microsoft Corporation | Domain collapsing of search results |
US20080305778A1 (en) | 2007-06-11 | 2008-12-11 | Cvon Innovations Limited | System and Method for Determining Mobile Device Capabilities |
US8175914B1 (en) | 2007-07-30 | 2012-05-08 | Google Inc. | Automatic adjustment of advertiser bids to equalize cost-per-conversion among publishers for an advertisement |
US20090210491A1 (en) | 2008-02-20 | 2009-08-20 | Microsoft Corporation | Techniques to automatically identify participants for a multimedia conference event |
KR20100126796A (en) | 2008-03-07 | 2010-12-02 | 구글 인코포레이티드 | Voice recognition grammar selection based on context |
KR20150097816A (en) | 2008-03-07 | 2015-08-26 | 구글 인코포레이티드 | Voice recognition grammar selection based on context |
US20090228281A1 (en) | 2008-03-07 | 2009-09-10 | Google Inc. | Voice Recognition Grammar Selection Based on Context |
US20090240670A1 (en) | 2008-03-20 | 2009-09-24 | Yahoo! Inc. | Uniform resource identifier alignment |
US20140350938A1 (en) | 2008-04-11 | 2014-11-27 | At&T Intellectual Property I, L.P. | System and method for detecting synthetic speaker verification |
US7904460B2 (en) | 2008-04-23 | 2011-03-08 | Microsoft Corporation | Determining computer information from processor properties |
US8068604B2 (en) | 2008-12-19 | 2011-11-29 | Computer Product Introductions Corporation | Method and system for event notifications |
US8386386B1 (en) | 2009-01-05 | 2013-02-26 | Sprint Communications Company L.P. | Phone usage pattern as credit card fraud detection trigger |
US20100198772A1 (en) | 2009-02-05 | 2010-08-05 | Google Inc. | Determining conversion probability using session metrics |
US8326637B2 (en) | 2009-02-20 | 2012-12-04 | Voicebox Technologies, Inc. | System and method for processing multi-modal device interactions in a natural language voice services environment |
US20110295682A1 (en) | 2009-03-02 | 2011-12-01 | Yahoo! Inc. | Optimized search result columns on search results pages |
US20110264644A1 (en) | 2009-03-20 | 2011-10-27 | Ad-Vantage Networks, Llc. | Methods and systems for searching, selecting, and displaying content |
US8234275B2 (en) | 2009-03-20 | 2012-07-31 | Ad-Vantage Networks, Llc | Methods and systems for searching, selecting, and displaying content |
US20100306229A1 (en) | 2009-06-01 | 2010-12-02 | Aol Inc. | Systems and Methods for Improved Web Searching |
US20120265528A1 (en) | 2009-06-05 | 2012-10-18 | Apple Inc. | Using Context Information To Facilitate Processing Of Commands In A Virtual Assistant |
US9431006B2 (en) | 2009-07-02 | 2016-08-30 | Apple Inc. | Methods and apparatuses for automatic speech recognition |
US20110022460A1 (en) | 2009-07-22 | 2011-01-27 | Yahoo! Inc. | Explicit online advertising exposure terms |
US20110141925A1 (en) | 2009-12-10 | 2011-06-16 | Mihails Velenko | Measuring call quality |
US20130117022A1 (en) | 2010-01-18 | 2013-05-09 | Apple Inc. | Personalized Vocabulary for Digital Assistant |
US20130275164A1 (en) * | 2010-01-18 | 2013-10-17 | Apple Inc. | Intelligent Automated Assistant |
US8903716B2 (en) | 2010-01-18 | 2014-12-02 | Apple Inc. | Personalized vocabulary for digital assistant |
US20110202494A1 (en) | 2010-02-17 | 2011-08-18 | Gm Global Technology Operations, Inc. | Method and apparatus for vehicle component health prognosis by integrating aging model, usage information and health signatures |
JP2011192102A (en) | 2010-03-16 | 2011-09-29 | Yahoo Japan Corp | Device and method for creating summary, and program |
US20110295990A1 (en) | 2010-06-01 | 2011-12-01 | Meltwater News International Holdings, GmbH | Method and Apparatus for Embedding Information in a Short URL |
US20110307436A1 (en) | 2010-06-10 | 2011-12-15 | Microsoft Corporation | Pattern tree-based rule learning |
US20110320114A1 (en) | 2010-06-28 | 2011-12-29 | Microsoft Corporation | Map Annotation Messaging |
US20120016897A1 (en) * | 2010-07-16 | 2012-01-19 | Altruik, Inc. | System and method for improving webpage indexing and optimization |
US20120030015A1 (en) | 2010-07-29 | 2012-02-02 | Google Inc. | Automatic abstracted creative generation from a web site |
US20120036226A1 (en) | 2010-08-09 | 2012-02-09 | Mskynet, Inc. | Uri service system and method |
JP2013540306A (en) | 2010-09-17 | 2013-10-31 | トムソン ライセンシング | Communication method and communication system |
US20120158954A1 (en) | 2010-09-22 | 2012-06-21 | Ronan Heffernan | Methods and apparatus to determine impressions using distributed demographic information |
US20120102087A1 (en) | 2010-10-20 | 2012-04-26 | Mskynet, Inc. | Link status system and method |
US20120101776A1 (en) | 2010-10-26 | 2012-04-26 | Brower Alfred N | Embedded prognostic health management system for aeronautical machines and devices and methods thereof |
US20120138671A1 (en) | 2010-12-03 | 2012-06-07 | Echostar Technologies L.L.C. | Provision of Alternate Content in Response to QR Code |
US20120155838A1 (en) | 2010-12-20 | 2012-06-21 | Echostar Technologies L.L.C. | Matrix Code-Based User Interface |
US20120166277A1 (en) | 2010-12-28 | 2012-06-28 | Yahoo! Inc. | Variation of minimum advertisement relevance quality threshold based on search query attributes |
WO2012094329A1 (en) | 2011-01-05 | 2012-07-12 | Envidient, Inc. | System and method for managing media content |
US20120221724A1 (en) | 2011-02-28 | 2012-08-30 | Mskynet, Inc. | Smart link system and method |
US20120297174A1 (en) | 2011-05-17 | 2012-11-22 | Michael Frank | Modifying Operating Parameters Based on Device Use |
US20130073400A1 (en) | 2011-09-15 | 2013-03-21 | Stephan HEATH | Broad and alternative category clustering of the same, similar or different categories in social/geo/promo link promotional data sets for end user display of interactive ad links, promotions and sale of products, goods and services integrated with 3d spatial geomapping and social networking |
US8762156B2 (en) | 2011-09-28 | 2014-06-24 | Apple Inc. | Speech recognition repair using contextual information |
US20130124606A1 (en) | 2011-11-14 | 2013-05-16 | Boopsie, Inc. | Automatic personalization of downloadable mobile apps |
US20130144720A1 (en) | 2011-12-06 | 2013-06-06 | Yahoo! Inc. | System for Advertisement Display |
US20130191226A1 (en) | 2012-01-20 | 2013-07-25 | Bradley Hopkins Smallwood | Pricing and delivery of advertising based on exposure time |
US8453058B1 (en) | 2012-02-20 | 2013-05-28 | Google Inc. | Crowd-sourced audio shortcuts |
US20130304758A1 (en) | 2012-05-14 | 2013-11-14 | Apple Inc. | Crowd Sourcing Information to Fulfill User Requests |
US20130325449A1 (en) | 2012-05-31 | 2013-12-05 | Elwha Llc | Speech recognition adaptation systems based on adaptation data |
US20130339030A1 (en) | 2012-06-13 | 2013-12-19 | Fluential, Llc | Interactive spoken dialogue interface for collection of structured data |
WO2014004489A1 (en) | 2012-06-25 | 2014-01-03 | Google, Inc. | System and method for deploying ads based on a content exposure interval |
US20140074895A1 (en) | 2012-08-27 | 2014-03-13 | David Ingerman | Geographic location coding system |
US20140095583A1 (en) | 2012-09-28 | 2014-04-03 | Disney Enterprises, Inc. | Client-side web site selection according to device capabilities |
US20140115635A1 (en) * | 2012-10-23 | 2014-04-24 | Samsung Electronics Co., Ltd. | Program recommendation device and program recommendation program |
US9275637B1 (en) | 2012-11-06 | 2016-03-01 | Amazon Technologies, Inc. | Wake word evaluation |
US8612226B1 (en) | 2013-01-28 | 2013-12-17 | Google Inc. | Determining advertisements based on verbal inputs to applications on a computing device |
US20140229184A1 (en) | 2013-02-14 | 2014-08-14 | Google Inc. | Waking other devices for additional data |
US20140337028A1 (en) | 2013-05-12 | 2014-11-13 | Shyh-Jye Wang | Message-triggered voice command interface in portable electronic devices |
US20160105718A1 (en) | 2013-06-05 | 2016-04-14 | Thomson Licensing | Method and apparatus for content distribution for multiscreen viewing |
JP2015001815A (en) | 2013-06-14 | 2015-01-05 | 西日本電信電話株式会社 | Digital signage system |
US20150081288A1 (en) | 2013-09-17 | 2015-03-19 | Electronics And Telecommunications Research Institute | Speech recognition device and the operation method thereof |
US20160246929A1 (en) | 2013-10-07 | 2016-08-25 | President And Fellows Of Harvard College | Computer implemented method, computer system and software for reducing errors associated with a situated interaction |
US20150106085A1 (en) | 2013-10-11 | 2015-04-16 | Apple Inc. | Speech recognition wake-up of a handheld portable electronic device |
US20180322536A1 (en) | 2014-01-14 | 2018-11-08 | Google Inc. | Resource utilization based cross device transmissions |
US20150221305A1 (en) | 2014-02-05 | 2015-08-06 | Google Inc. | Multiple speech locale-specific hotword classifiers for selection of a speech locale |
WO2015133022A1 (en) | 2014-03-03 | 2015-09-11 | ソニー株式会社 | Information processing apparatus, information processing method, and program |
US20170147585A1 (en) | 2014-07-22 | 2017-05-25 | Nuance Communications, Inc. | Systems and methods for speech-based searching of content repositories |
US9424841B2 (en) | 2014-10-09 | 2016-08-23 | Google Inc. | Hotword detection on multiple devices |
US20160217790A1 (en) | 2014-10-09 | 2016-07-28 | Google Inc. | Hotword detection on multiple devices |
US9318107B1 (en) | 2014-10-09 | 2016-04-19 | Google Inc. | Hotword detection on multiple devices |
JP2016111406A (en) | 2014-12-02 | 2016-06-20 | ソニー株式会社 | Information processing device, information processing method, and program |
US20160180846A1 (en) | 2014-12-17 | 2016-06-23 | Hyundai Motor Company | Speech recognition apparatus, vehicle including the same, and method of controlling the same |
US20160223640A1 (en) | 2015-02-03 | 2016-08-04 | Nokia Technologies Oy | Radio and audio localization |
US20160259497A1 (en) * | 2015-03-08 | 2016-09-08 | Apple Inc. | Devices, Methods, and Graphical User Interfaces for Manipulating User Interface Objects with Visual and/or Haptic Feedback |
US10165091B1 (en) | 2015-04-03 | 2018-12-25 | Sprint Communications Company L.P. | User device parameter allocation based on internet protocol version capabilities |
US20170069317A1 (en) | 2015-09-04 | 2017-03-09 | Samsung Electronics Co., Ltd. | Voice recognition apparatus, driving method thereof, and non-transitory computer-readable recording medium |
US20170092278A1 (en) | 2015-09-30 | 2017-03-30 | Apple Inc. | Speaker recognition |
US10193465B2 (en) | 2015-09-30 | 2019-01-29 | Murata Manufacturing Co., Ltd. | DC/DC conversion apparatus |
US9542941B1 (en) | 2015-10-01 | 2017-01-10 | Lenovo (Singapore) Pte. Ltd. | Situationally suspending wakeup word to enable voice command input |
US20170110130A1 (en) | 2015-10-16 | 2017-04-20 | Google Inc. | Hotword recognition |
US20170110144A1 (en) | 2015-10-16 | 2017-04-20 | Google Inc. | Hotword recognition |
US20170132019A1 (en) | 2015-11-06 | 2017-05-11 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US9653075B1 (en) | 2015-11-06 | 2017-05-16 | Google Inc. | Voice commands across devices |
US20170289596A1 (en) | 2016-03-31 | 2017-10-05 | Microsoft Technology Licensing, Llc | Networked public multi-screen content delivery |
US20170358302A1 (en) * | 2016-06-08 | 2017-12-14 | Apple Inc. | Intelligent automated assistant for media exploration |
US20170358301A1 (en) | 2016-06-10 | 2017-12-14 | Apple Inc. | Digital assistant providing whispered speech |
US10032452B1 (en) | 2016-12-30 | 2018-07-24 | Google Llc | Multimodal transmission of packetized data |
US10535348B2 (en) | 2016-12-30 | 2020-01-14 | Google Llc | Multimodal transmission of packetized data |
Non-Patent Citations (269)
Title |
---|
"Best practices for creating adaptive user interface with the mobile internet toolkit", MICROSOFT COOPERATION, XX, US, US, pages 1 - 16, XP008144654, Retrieved from the Internet <URL:http://msdn.microsoft.com/library/default.asp?url=/library/en-us/dnmitta/html/bestpractaui.asp> |
"Amazon and Google Want to Turn Their Smart Home Speakers Into Telephone Replacements—Mac Rumors" MacRumors, 9 pages. |
"An Investigation of Conceptual Model of SMS Marketing", Dickinger A. and Haghirian P., Proceedings of 37th Hawaii International Conference on System Sciences, Jan. 2004, p. 8 paragraph 6.3.2 (Year:2004). |
"Apple Patent Reveals a New Security Feature Coming to Siri" 6 pages. |
"eStara Push to Talk: The most popular click to call service in the world," downloaded from htto://www.estara.com on Jun. 29, 2004, 2 pgs. |
"How to Deep Link to Alexa Skills" dtd Oct. 11, 2017. |
"Ingenio: Click to Call Solutions," downloaded fromhtto://www.in2enio.com/documents/cominfo/clicktocall.aso?TF=l on Jun. 29, 2004, 3 pgs. |
"Introducing Echo Look Hands-Free Camera and Style Assistant" 1996-2017, Amazon.com, Inc. 5 pages. |
"The Patent Behind Google Home's New Feature of Understanding Different Voices in the Home Surfaced Today", Apr. 20, 2017, 5 pages. |
"Walmart and Google to offer voice-enabled shopping", BBC News, Aug. 23, 2017. |
"Wiley Encyclopedia of Computer Science and Engineering: vol. I", Wiley-Interscience, Nov. 2008 (2365 pages). |
95/001,061 Reexamination—Miscellaneous Action dated Jul. 2, 2013 (4 pages). |
95/001,061 Reexamination—Reexamination Terminated dated Jul. 2, 2013 (4 pages). |
95/001,068 Reexamination—"Certificate of Service" dated Mar. 24, 2012 (1 page). |
95/001,068 Reexamination—"Inter Partes Reexamination Certificate" for U.S. Pat. No. 6,829,587-C1 dated Jan. 8, 2013 (2 pages). |
95/001,068 Reexamination—Appeal No. 2011-013241, "Decision on Appeal" dated Jan. 27, 2012 (34 pages). |
95/001,068 Reexamination—Appeal No. 2011-013241, "Notice of Appeal" dated Mar. 24, 2012 (3 pages). |
95/001,068 Reexamination—Case 12-1379, Document 20, "Order"by the US Court of Appeals for the Federal Circuit dated Sep. 6, 2012 (2 pages). |
95/001,069 Reexamination—"Certificate of Service" dated Mar. 24, 2012 (1 page). |
95/001,069 Reexamination—"Inter Partes Reexamination Certificate" for U.S. Pat. No. 7,249,059-C1 dated Jul. 23, 2013 (2 pages). |
95/001,069 Reexamination—Appeal No. 2011-010893, "Decision on Appeal" dated Jan. 27, 2012 (34 pages). |
95/001,069 Reexamination—Appeal No. 2011-010893, "Notice of Appeal" dated Mar. 24, 2012 (3 pages). |
95/001,069 Reexamination—Case 12-1380, Document 54-1, Decision by the US Court of Appeals for the Federal Circuit dated Mar. 7, 2013 (8 pages). |
95/001,069 Reexamination—Case 12-1380, Document 54-2, "Information Sheet" dated Mar. 7, 2013 (1 page). |
95/001,069 Reexamination—Case 12-1380, Document 54-3, "Questions and Answers: Petitions for Panel Rehearing (Fed. Cir. R. 40) and Petitions for Hearing or Rehearing En Banc (Fed. Cir. R. 35)" dated Mar. 7, 2013 (1 page). |
95/001,069 Reexamination—Case 12-1380, Document 54-4, "Notice of Entry of Judgment Accompanied by Opinion" dated Mar. 7, 2013 (2 pages). |
95/001,069 Reexamination—Case 12-1380, Document 55-3, "Mandate" dated Apr. 29, 2013 (2 pages). |
95/001,073 Reexamination—"Certificate of Service" dated Mar. 24, 2012 (1 page). |
95/001,073 Reexamination—"Inter Partes Reexamination Certificate" for U.S. Pat. No. 7,240,025-C1 dated Jul. 23, 2013 (2 pages). |
95/001,073 Reexamination—Appeal No. 2011-010719, "Decision on Appeal" dated Jan. 27, 2012 (27 pages). |
95/001,073 Reexamination—Appeal No. 2011-010719, "Notice of Appeal" dated Mar. 24, 2012 (3 pages). |
95/001,073 Reexamination—Case 12-1380, Document 54-1, Decision by the US Court of Appeals for the Federal Circuit dated Mar. 7, 2013 (8 pages). |
95/001,073 Reexamination—Case 12-1380, Document 55-3, "Mandate" by the US Court of Appeals for the Federal Circuit dated Apr. 29, 2013 (2 pages). |
Abrams, Help users find, interact & re-engage with your app on the Google Assistant, Google Developers Blog, Nov. 15, 2017, 16 pages. |
AdForce, Inc., A Complete Guide to AdForce, Version 2.6, 1998. |
AdForce, Inc., S-1/A SEC Filing, May 6, 1999. |
AdKnowledge Campaign Manager: Reviewer's Guide, AdKnowledge, Aug. 1998. |
AdKnowledge Market Match Planner: Reviewer's Guide, AdKnowledge, May 1998. |
Ad-Star.com website archive from www. Archive.org, Apr. 12, 1997 and Feb. 1, 1997. |
Albrecht, "Alexa, How Can You Be Used in Restaurants?", the spoon, Dec. 10, 2017, 6 pages. |
Barr, "AWS DeepLens—Get Hands-On Experience with Deep Learning With Our New Video Camera", AWS News Blog, Nov. 29, 2017, 11 pages. |
Baseview Products, Inc., AdManagerPro Administration Manual v. 2.0, Dec. 1998. |
Baseview Products, Inc., ClassManagerPro Administration Manual v. 1.0.5, Feb. 1, 1997. |
Best practices for creating adaptive user interfaces with the mobile Internet toolkit:, Microsoft Corporation, Jan. 2002, pp. 1-2. Downloaded Dec. 21, 2006 from http://msdn.microsoft.com/library/default.asp?url=/library/en-_us/dnmitta/html/bestpractaui.asp. |
Broussard, Mitchel, "Chatbot-Like Siri Patent Includes Intelligent Image, Video, and Audio Recognition Within Messages", MacRumors, May 11, 2017, 11 pages. |
Buckland et al., "Amazon's Alexa Takes Open-Source Route to Beat Google Into Cars", Bloomberg, Feb. 27, 2018, 6 pages. |
Business Wire, "Global Network, Inc. Enters Into Agreement in Principle With Major Advertising Agency," Oct. 4, 1999. |
Canadian Office Action on 2572468 dated Dec. 4, 2014. |
Canadian Office Action on 2572468 dated Sep. 17, 2013. |
Canadian Office Action on 2572471 dated Jan. 9, 2014. |
Canadian Office Action on CA 2,572,471 dated Mar. 3, 2015. |
Canadian Office Action to Canadian Patent Application No. 2,572,471 dated Mar. 16, 2009. |
Chapter 12, Managing the Product, Class Notes, University of Delaware, http://www.udel.edu/alex/chapt12.html, accessed Mar. 13, 2015, 10 pgs. |
Chen, Yilun Lulu, "Alibaba Challenges Google, Amazon With New Echo-Like Device", Bloomberg, Jul. 5, 2017, 3 pages. |
Close, "Amazon Echo Will Give You These Deals If You Order Through Alexa This Weekend," Web Article, Nov. 18, 2016, Time.com (2 pages). |
Coberly, "Apple patent filing reveals potential whispering Siri functionality", Techspot, Dec. 14, 2017, 4 pages. |
Collins, Terry "Can Twitter Save itself? The Social Network is Slowly gaining users, but still Lags Far Behind Rivals. Is a Turnaround Possible?" 3 pages. |
Cook, "A Siri for advertising: These mobile ads talk back to you," Web Article, Apr. 1, 2013, Geekwire.com (7 pages). |
Crist, Ry, "Logitech Harmony's Alexa Skill just got a whole lot better", cnet, Jul. 13, 2017 (2 pages). |
Decision of Rejection for Japanese Patent Application No. 2007-519374, dated Jun. 15, 2010 (3 pgs.) with translation (3 pgs.). |
Decision of Rejection for Japanese Patent Application No. 2007-519407 dated Feb. 23, 2010. |
Decision to Dismiss the Amendment for Korean Patent Application No. 10-2007-7002383 dated Jul. 9, 2010. |
Dedrick, R., A Consumption Model for Targeted Electronic Advertising, Intel Architecture Labs, IEEE, 1995. |
Dedrick, R., Interactive Electronic Advertising, IEEE, 1994. |
Dickinger et al., "An Investigation and Conceptual Model of SMS Marketing," Proceedins of the 37th Hawaii International Conference on System Sciences, 2004, 10 pages. |
Estes, "Amazon's Newest Gadget Is a Tablet That's Also an Echo", Gizmodo, Sep. 19, 2017, 3 pages. |
European Office Action for EP Application No. 05763971.8, dated Mar. 29, 2011. |
European Office Action on 05768157.9 dated Jan. 27, 2014. |
European Office Action on EP 05 768 157.9 dated Aug. 21, 2014. |
European Office Action on EP 05 768 157.9 dated Jul. 23, 2015. |
Examination Report for AU Appln. Ser. No. 2017384996 dated Nov. 25, 2019 (2 pages). |
Examiner's First Report on Australian Patent Application No. 2005259861 dated Mar. 6, 2008 (2 pgs.). |
Examiner's First Report to Australian Patent Application No. 2005260566 dated Mar. 4, 2008. |
Examiner's Re-Examination Report for Australian Patent Application No. 2005259861, dated Dec. 1, 2011 (2 pgs.). |
Examiner's Report for Canadian Patent Application No. 2,572,468, dated Dec. 29, 2011 (4 pgs.). |
Feng et al., "Active Profiling of Physical Devices at Internet Scale", IEEE, 2016 (9 pages). |
Final Office Action for U.S. Appl. No. 10/880,868 dated Apr. 13, 2010 (8 pages). |
Final Office Action for U.S. Appl. No. 10/880,868 dated Jul. 17, 2009 (7 pages). |
Final Office Action for U.S. Appl. No. 15/638,291 dated Jan. 30, 2020 (24 pages). |
Final Office Action for U.S. Appl. No. 15/638,295 dated Jan. 30, 2020 (25 pages). |
Final Office Action on U.S. Appl. No. 13/840,380 dated Aug. 3, 2018. |
Final Office Action on U.S. Appl. No. 14/172,353 dated Dec. 14, 2018. |
Final Office Action on U.S. Appl. No. 15/189,826 dated Jun. 3, 2019. |
Final Office Action on U.S. Appl. No. 15/491,734 dated May 28, 2019. |
Final Office Action on U.S. Appl. No. 15/584,970 dated May 31, 2019. |
First Examination Report for Indian Patent Application No. 144/MUMNP/2007, dated Jun. 19, 2008 (2 pgs.). |
First Office Action for Japanese Patent Application No. 2010-142707 dated Nov. 13, 2012. |
First Office Action for Japanese Patent Application No. 2010-232591, dated Feb. 19, 2013 (3 pgs.) with translation (4 pgs.). |
Fisher et al., "The Role of Text Analytics and Information Retrieval in the Accounting Domain," Journal of Emerging Technologies in Accounting, vol. 7, Dec. 2010 (25 pages). |
Foghorn Labs, 10 Tips to Improve the Performance of Google Product Listing Ads, printed from Internet address: http://www.foghornlabs.com/2012/11/21/product-listing-ads-best-practices/, on Mar. 18, 2013, 5 pages. |
Forrest, Conner, "Essential Home wants to be ‘bridge’ between Amazon Alexa, Apple's Siri, and Google Assistant," TechRepublic, May 31, 2017, 9 pages. |
Foxx, Chris, "Apple reveals HomePod smart speaker", BBC, Jun. 5, 2017, 9 pages. |
Gebhart, Andrew, "Google Assistant is spreading, but it needs its own ‘Echo Dot’", Cnet, May 20, 2017, 6 pages. |
Gebhart, Andrew, "Google Home to the Amazon Echo: ‘Anything you can do . . . ’" Cnet, May 18, 2017, 7 pages. |
Gibbs, Samuel, "Your Facebook Messenger app is about to be filled with ads", The Guardian, Jul. 12, 2017 (3 pages). |
Golgowski, Nina, "This Burger King Ad Is Trying to Control Your Google Home Device", Apr. 12, 2017, 7 pages. |
Google Developers Newsletter "Google Assistant SDK", developers.google.com, 2 pages. |
Google Inc., Products Feed Specification, printed from Internet address: http://www.support.google.com/merchants/bin/answer.py?hl=en&answer=188494#US, on Mar. 18, 2013, 6 pages. |
Google Inc., Supported File Formats, printed from Internet address: http://www.support.google.com/merchants/bin/answer.py?hl=en&answer=160567, on Mar. 18, 2013, 1 page. |
Gurma, Mark and Webb, Alex, "Apple Is Manufacturing a Siri Speaker to Outdo Google and Amazon", Bloomberg, May 31, 2017, 3 pages. |
Hardwick, Tim, "Facebook Smart Speaker Coming Next Year With 15-inch Touch Panel", MacRumors, Jul. 25, 2017 (5 pages). |
Heater, "Amazon Alexa devices can finally tell voices apart", TechCrunch, Oct. 11, 2017, 6 pages. |
Information Access Technologies, Inc., Aaddzz brochure, "The Best Way to Buy and Sell Web Advertising Space," © 1997. |
Information Access Technologies, Inc., Aaddzz.com website archive from www.Archive.org, archived on Jan. 30, 1998. |
International Preliminary Report on Patentability (Chapter 1 of the Patent Cooperation Treaty) for application No. 31549-00189 dated Aug. 13, 2015. |
International Preliminary Report on Patentability for Appl. Ser. No. PCT/US2017/049782 dated Jul. 11, 2019 (12 pages). |
International Search Report & Written Opinion on PCT/US2013/042376 dated Feb. 28, 2014. |
International Search Report and Written Opinion on International Application No. PCT/US2017/049782, dated Oct. 25, 2017, 16 pages. |
International Search Report on International Application No. PCT/US2005/023023, dated Oct. 23, 2006, 2 pages. |
Japanese Decision of Rejection on 2010-232591 dated Jan. 27, 2014. |
Japanese Office Action issued in JP application 2010-142707 dated Jul. 23, 2013. |
Japanese Office Action on JP 2014-010608 dated Nov. 18, 2014, 12 pages (English translation). |
Japanese Office Action on JP2010-232591 dated Jun. 9, 2015. |
Johnston, "Amazon Whirlwind: New Echo, Plus, Spot, Connect, Fire TV Take the Stage", Twice, Sep. 27, 2017, 4 pages. |
Jones, Matt et al., "Improving Web Interaction in Small Displays", Computer Networks, vol. 31, pp. 1129-1137 (May 17, 1999). |
JP Notice of Allowance for Appln. Ser. No. 2017-556912 dated Aug. 9, 2019 (6 pages). |
Kato, Sako, "Keyword Advertisement", Internet Magazine, 2nd Stage, No. 2,pp. 112-123, Japan, Impress Holdings, Inc. (May 1, 2004). |
Kelion, "Amazon revamps Echo smart speaker family", BBC News, Sep. 27, 2017, 11 pages. |
Kelion, Leo, "Amazon's race to make Alexa smarter", BBC News, Jul. 28, 2017 (8 pages). |
Koetsier, John, "Ads on Amazon Echo: Wendy's, ESPN, and Progressive Among Brands Testing", Forbes, May 11, 2017, 3 pages. |
Korean Office Action for application No. 10-2017-7031603 dated Jan. 22, 2019. |
Krishna, "Jim Beam's smart decanter will pour you a shot when you ask", engadget, Nov. 29, 2017, 3 pages. |
Lacy, "Improving search and advertising are the next frontiers for voice-activated devices", TechCrunch, Dec. 20, 2017, 13 pages. |
Larson, Selena "Google Home Now Recognizes your Individual Voice" dated Apr. 20, 2017, 3 pages. |
Lee, Dave, "The five big announcements from Google I/O", BBC, May 18, 2017, 11 pages. |
Lee, Take Two for Samsung's troubled Bixby assistant, BBC News, Oct. 19, 2017, 6 pages. |
Lund, Pamela, Mastering Google Product Feeds and Product Listing Ads $2013 Part 1, found at http://www.blueglass.com/blog/mastering-google-product-feeds-and-product-listing-ads-part-1/#comments, Dec. 28, 2013, 17 pages. |
Microsoft Corporation, "Best Practices for Creating Adaptive User Interfaces with the Mobile Internet Toolkit", Jan. 2002, pp. 1-2, XP008144654. |
Morton to Baluja email (1 pg). |
Nieva, Richard, "Google Home and eBay can tell you how much that's worth", 3 pages. |
Non-Final Office Action for U.S. Appl. No. 10/880,868 dated Sep. 23, 2009 (7 pages). |
Non-Final Office Action for U.S. Appl. No. 13/840,380 dated Mar. 26, 2015 (26 pages). |
Non-Final Office Action for U.S. Appl. No. 15/587,132 dated Mar. 5, 2020 (24 pages). |
Non-Final Office Action for U.S. Appl. No. 15/638,291 dated Sep. 6, 2019 (22 pages). |
Non-Final Office Action for U.S. Appl. No. 15/638,295 dated Sep. 6, 2019 (26 pages). |
Non-Final Office Action for U.S. Appl. No. 16/666,780 dated Jan. 27, 2020 (10 pages). |
Non-Final Office Action on U.S. Appl. No. 15/084,223 dated Sep. 4, 2018. |
Non-Final Office Action on U.S. Appl. No. 15/189,826 dated Nov. 9, 2018. |
Non-Final Office Action on U.S. Appl. No. 15/491,734 dated Jan. 30, 2019. |
Non-Final Office Action on U.S. Appl. No. 15/584,970 dated Nov. 16, 2018. |
Non-Final Office Action on U.S. Appl. No. 15/638,291 dated Sep. 6, 2019 (22 pages). |
Non-Final Office Action on U.S. Appl. No. 15/638,295 dated Sep. 6, 2019 (26 pages). |
Non-Final Office Action on U.S. Appl. No. 15/674,838 dated Nov. 30, 2018. |
Non-Final Office Action on U.S. Appl. No. 16/039,202 dated Aug. 14, 2018. |
Non-Final Office Action on U.S. Appl. No. 16/039,204 dated Aug. 15, 2018. |
Notice of Allowance for JP 2017-556912 dated Aug. 9, 2019 (8 pages). |
Notice of Allowance for KR 10-2017-7031603 dated Mar. 28, 2019 (3 pages). |
Notice of Allowance for KR Appln. Ser. No. 10-2019-7018803 dated Oct. 11, 2019 (3 pages). |
Notice of Allowance for U.S. Appl. No. 13/441,298 dated Nov. 2, 2017, 11 pages. |
Notice of Allowance for U.S. Appl. No. 13/840,380 dated Dec. 11, 2019 (12 pages). |
Notice of Allowance for U.S. Appl. No. 13/840,380 dated Sep. 20, 2019 (11 pages). |
Notice of Allowance for U.S. Appl. No. 15/491,734 dated Jan. 31, 2020 (18 pages). |
Notice of Allowance for U.S. Appl. No. 15/638,298 dated Feb. 21, 2020 (15 pages). |
Notice of Allowance for U.S. Appl. No. 15/674,838 dated Dec. 3, 2019 (2 pages). |
Notice of Allowance for U.S. Appl. No. 15/674,838 dated Mar. 11, 2020 (8 pages). |
Notice of Allowance for U.S. Appl. No. 15/674,838 dated Sep. 20, 2019 (8 pages). |
Notice of Allowance for U.S. Appl. No. 16/039,202 dated Oct. 9, 2019 (8 pages). |
Notice of Allowance for U.S. Appl. No. 16/039,204 dated Oct. 30, 2019 (8 pages). |
Notice of Allowance for U.S. Appl. No. 16/666,780 dated Apr. 14, 2020 (6 pages). |
Notice of Allowance on U.S. Appl. No. 13/478,998 dated Sep. 21, 2018. |
Notice of Allowance on U.S. Appl. No. 13/840,380 dated May 14, 2019. |
Notice of Allowance on U.S. Appl. No. 16/039,202 dated Apr. 4, 2019. |
Notice of Allowance on U.S. Appl. No. 16/039,202 dated Dec. 10, 2018. |
Notice of Allowance on U.S. Appl. No. 16/039,204 dated Dec. 10, 2018. |
Notice of Allowance on U.S. Appl. No. 16/039,204 dated Jan. 17, 2019. |
Notice of Allowance on U.S. Appl. No. 16/039,204 dated Mar. 20, 2019. |
Notice of Final Rejection for Korean Patent Application No. 10-2007-7002383 dated Apr. 22, 2010. |
Notice of Final Rejection for Korean Patent Application No. 10-2007-7002385 dated Jul. 30, 2009 (5 pgs.) with translation (5 ps.). |
Notice of Final Rejection for Korean Patent Application No. 10-2010-7013914 dated Sep. 14, 2011. |
Notice of Preliminary Rejection for Korean Patent Application No. 10-2007-7002383 dated Jun. 10, 2008. |
Notice of Preliminary Rejection for Korean Patent Application No. 10-2007-7002385, dated Jun. 10, 2008 (5 pgs.) with translation (6 pgs.). |
Notice of Preliminary Rejection for Korean Patent Application No. 10-2010-7013914, dated Sep. 17, 2010. |
Notice of Reasons for Rejection for application No. 2017-556912 dated Mar. 4, 2019. |
Notice of Reasons for Rejection for Japanese Patent Application No. 2007-519374 dated Aug. 25, 2009 (3 pgs.) with translation (4 pgs.). |
Notice of Reasons for Rejection for Japanese Patent Application No. 2007-519407 dated Jul. 7, 2009. |
Notification of Preliminary Rejection for Korean Patent Application No. 10-2007-7002383 dated Jun. 10, 2009. |
Notification of the First Office Action for Chinese Patent Application No. 200580025826.2 dated Dec. 18, 2009 (6 pgs.) with translation (7 pgs.). |
Notification of the Second Office Action for Chinese Patent Application No. 200580025826.2, dated Jul. 22, 2011 (3 pgs.) with translation (4 pgs.). |
Notification of the Second Office Action for Chinese Patent Application No. 200580025878.X, dated Oct. 26, 2011. |
Notification of the Third Office Action for Chinese Patent Application No. 200580025826.2 dated Apr. 11, 2012 (5 pgs.) with translation (7 pgs.). |
Notification of the Third Office Action for Chinese Patent Application No. 200580025878.X, dated Feb. 21, 2012. |
Novet, et al., "Amazon is getting ready to bring Alexa to work", CNBC, Nov. 29, 2017, 4 pages. |
Office Action for Canadian Patent Application No. 2,572,471, dated May 21, 2010. |
Office Action for Chinese Patent Application No. 200580025878.X, dated May 7, 2010. |
Office Action for European Patent Application No. 05 763 971.8-2221 dated Mar. 29, 2011 (4 pgs.). |
Office Action for European Patent Application No. 05768157. 9-1958, dated Feb. 15, 2013. |
Office Action for Japanese Patent Application No. 2007-519374, dated May 29, 2012 (19 pgs.) with translation (28 pgs.). |
Office Action on U.S. Appl. No. 14/230,508 dated Nov. 28, 2014. |
Official Letter of Inquiry for Japanese Patent Application No. 2007-519374 dated Oct. 4, 2011 (3 pgs.). |
Page to Karima email (1 page). |
Palladino, "Garmin teamed up with Amazon to make a tiny Echo Dot for your car", ars Technica, Oct. 17, 2017, 2 pages. |
PCT International Search Report (PCT/ISA/210) for International Application No. PCT/US05/23023 (2 pgs.) (dated Oct. 23, 2006). |
PCT Written Opinion of the International Searching Authority (PCT/ISA/237) for International Application No. PCT/US05/23023 (3 pgs.). |
PCT/ISA/210, International Search Report for PCT/US05/23162 dated Feb. 5, 2007. |
PCT/ISA/237, Written Opinion of the International Searching Authority forPCT/US05/23162 dated Feb. 5, 2007. |
Perez, "Alexa's ‘Routines’ will combine smart home control with other actions, like delivering your news and weather", TechCrunch, Sep. 28, 2017, 10 pages. |
Perez, Sarah, "The first ad network for Alexa Skills shuts down following Amazon's policy changes", Tech Crunch, Jun. 15, 2017, 8 pages. |
Porter, Jon, "Amazon Echo Show release date, price, news and features", Tech Radar, Jun. 26, 2017, 11 pages. |
Pringle, "‘I'm sorry to hear that’: Why training Siri to be a therapist won't be easy", CBC News, Sep. 24, 2017, 3 pages. |
Purcher, Jack, Today Google Home's Virtual Assistant can learn its Owner's voice for Security Reasons like Apple's Patent Pending Idea, Apr. 20, 2017, 4 pages. |
Request for Reexamination of U.S. Pat. No. 6,446,045 B1, Control No. 95/001,061. |
Request for Reexamination of U.S. Pat. No. 6,829,587 B2, Control No. 95/001,068. |
Request for Reexamination of U.S. Pat. No. 7,240,025 B2, Control No. 95/001,073. |
Request for Reexamination of U.S. Pat. No. 7,249,059 B2, Control No. 95/001,069. |
Sablich, Justin, "Planning a Trip With the Help of Google Home", New York Times, dated May 31, 2017, 6 pages. |
Seifert, Dan "Samsung's New Virtual Assistant Will Make Using Your Phone Easier", Mar. 20, 2017, 7 pages. |
Sherr, Ian "IBM Built a Voice Assistant for Cybersecurity" dated Feb. 13, 2017, 4 pages. |
Shintaro Gotoh et al., "Citizens Lectures on GIS using MANDARA and EXCEL, Make a Map by PC," Kokin Shoin (1st ed., Apr. 5, 2004, ISBN 4-7722-4051-9, Kokon, Japan) p. 62. |
Siegal, Daniel, "IP Attys Load Up Apps' Legal Challenges at Silicon Beach" 6 pages. |
Simonite, "How Alexa, Siri, and Google Assistant Will Make Money off You," Web Article, May 31, 2016, technologyreview.com (11 pages). |
Simonite, "How Assistant Could End Up Eating Google's Lunch," Web Article, Sep. 23, 2016, technologyreview.com (9 pages). |
Smith, Dave, "The Amazon Echo got 2 incredibly useful features thanks to a new update", Business Insider, Jun. 1, 2017, 2 pages. |
Statement of Grounds and Particulars in Support of Opposition for Australian Patent Application No. 2005259861, dated Jan. 22, 2010 (13 pgs.). |
Supplementary European Search Report for European Patent Application No. 05768157.9 dated Oct. 31, 2012. |
Tedeschi, Bob, "Transforming Clicks Into Rings," (Jun. 7, 2004) downloaded fromwww.nvtimes.com on Jun. 6, 2004, 3 pgs. |
The International Search Report and the Written Opinion of the International Searching Authority for Application No. PCT/US2013/077834 dated Apr. 24, 2014, 5 pages. |
U.S. Appl. No. 95/001,061, Reexamination of Stone et al. |
U.S. Appl. No. 95/001,068, Reexamination of Stone et al. |
U.S. Appl. No. 95/001,069, Reexamination of Stone et al. |
U.S. Appl. No. 95/001,073, Reexamination of Stone et al. |
U.S. Final Office Action on U.S. Appl. No. 13/441,298 dated Dec. 30, 2013. |
U.S. Notice of Allowance for U.S. Appl. No. 13/478,998 dated Apr. 23, 2018, 8 pages. |
U.S. Notice of Allowance for U.S. Appl. No. 13/478,998 dated Jan. 26, 2018, 8 pages. |
U.S. Notice of Allowance for U.S. Appl. No. 15/395,703 dated Apr. 4, 2018, 2 pages. |
U.S. Notice of Allowance for U.S. Appl. No. 15/395,703 dated Feb. 14, 2018, 9 pages. |
U.S. Notice of Allowance for U.S. Appl. No. 16/039,202 dated Jul. 17, 2019 (8 pages). |
U.S. Notice of Allowance for U.S. Appl. No. 16/039,204 dated Jul. 15, 2019 (8 pages). |
U.S. Notice of Allowance on U.S. Appl. No. 13/478,998 dated Sep. 12, 2017. |
U.S. Notice of Allowance on U.S. Appl. No. 15/395,703 dated May 17, 2018. |
U.S. Office Action for U.S. Appl. No. 13/840,380 dated Dec. 6, 2017, 13 pages. |
U.S. Office Action for U.S. Appl. No. 14/172,353 dated Apr. 4, 2018, 22 pages. |
U.S. Office Action for U.S. Appl. No. 15/491,734 dated May 28, 2019 (24 pages). |
U.S. Office Action for U.S. Appl. No. 15/674,838 dated Jun. 10, 2019 (6 pages). |
U.S. Office Action on U.S. Appl. No. 10/880,686 dated May 7, 2008. |
U.S. Office Action on U.S. Appl. No. 10/880,868 dated Apr. 1, 2016. |
U.S. Office Action on U.S. Appl. No. 10/880,868 dated Dec. 4, 2008. |
U.S. Office Action on U.S. Appl. No. 10/880,868 dated Mar. 24, 2015. |
U.S. Office Action on U.S. Appl. No. 10/880,868 dated Nov. 28, 2014. |
U.S. Office Action on U.S. Appl. No. 11/026,507 dated Apr. 6, 2015. |
U.S. Office Action on U.S. Appl. No. 11/026,507 dated Aug. 14, 2014. |
U.S. Office Action on U.S. Appl. No. 11/026,507 dated Jan. 12, 2010. |
U.S. Office Action on U.S. Appl. No. 11/026,507 dated Jul. 21, 2010. |
U.S. Office Action on U.S. Appl. No. 11/026,507 dated Mar. 24, 2011. |
U.S. Office Action on U.S. Appl. No. 11/026,507 dated Mar. 30, 2009. |
U.S. Office Action on U.S. Appl. No. 11/026,507 dated Oct. 29, 2015. |
U.S. Office Action on U.S. Appl. No. 13/441,298 dated Jan. 13, 2017. |
U.S. Office Action on U.S. Appl. No. 13/441,298 dated Jul. 17, 2013. |
U.S. Office Action on U.S. Appl. No. 13/441,298 dated Jul. 6, 2015. |
U.S. Office Action on U.S. Appl. No. 13/441,298 dated Nov. 20, 2015. |
U.S. Office Action on U.S. Appl. No. 13/478,998 dated Feb. 27, 2017. |
U.S. Office Action on U.S. Appl. No. 13/478,998 dated Jan. 20, 2016. |
U.S. Office Action on U.S. Appl. No. 13/478,998 dated Jul. 31, 2015. |
U.S. Office Action on U.S. Appl. No. 13/478,998 dated Oct. 5, 2016. |
U.S. Office Action on U.S. Appl. No. 13/840,380 dated Aug. 12, 2016. |
U.S. Office Action on U.S. Appl. No. 13/840,380 dated Feb. 27, 2017. |
U.S. Office Action on U.S. Appl. No. 13/840,380 dated Oct. 22, 2015. |
U.S. Office Action on U.S. Appl. No. 14/155,323 dated May 7, 2015. |
U.S. Office Action on U.S. Appl. No. 14/172,353 dated Aug. 10, 2017, 15 pages. |
U.S. Office Action on U.S. Appl. No. 14/172,353 dated Feb. 9, 2017. |
U.S. Office Action on U.S. Appl. No. 14/172,353 dated Jan. 21, 2016. |
U.S. Office Action on U.S. Appl. No. 14/172,353 dated Jul. 6, 2015. |
U.S. Office Action on U.S. Appl. No. 14/172,353 dated May 17, 2018. |
U.S. Office Action on U.S. Appl. No. 14/230,508 dated Feb. 1, 2016. |
U.S. Office Action on U.S. Appl. No. 14/230,508 dated Jun. 3, 2015. |
U.S. Office Action on U.S. Appl. No. 15/395,703 dated Oct. 19, 2017. |
Unknown Author, "‘Dolphin’ attacks fool Amazon, Google voice assistants", BBC News, Sep. 7, 2017, 8 pages. |
Willens, Max, "For publishers, Amazon Alexa holds promise but not much money (yet)", Digiday, Jul. 6, 2017, 5 pages. |
Xue et al., "Unstructured Queries Based on Mobile User Context," International Journal of Pervasive Computing and Communications, vol. 8, No. 4, dated Aug. 27, 2012 (28 pages). |
Zeff, R. et al., Advertising on the Internet, 2nd Ed., John Wiley & Sons, 1999. |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11431718B2 (en) * | 2014-10-07 | 2022-08-30 | Ricoh Company, Ltd. | Text chat management system connected to a video conference management system |
Also Published As
Publication number | Publication date |
---|---|
US20170257456A1 (en) | 2017-09-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10735552B2 (en) | Secondary transmissions of packetized data | |
US10776435B2 (en) | Canonicalized online document sitelink generation | |
US20210096815A1 (en) | Systems and methods for enabling user voice interaction with a host computing device | |
US20210358498A1 (en) | Multimodal transmission of packetized data | |
JP6334696B2 (en) | Hashtag and content presentation | |
US20180322536A1 (en) | Resource utilization based cross device transmissions | |
US20140156416A1 (en) | Previewing, approving and testing online content | |
US11093692B2 (en) | Extracting audiovisual features from digital components | |
US10776830B2 (en) | Methods and systems for identifying new computers and providing matching services | |
US9219788B1 (en) | Online resource serving to a traveling user | |
US20190104199A1 (en) | Cross device bandwidth utilization control | |
US9319486B2 (en) | Predicting interest levels associated with publication and content item combinations | |
EP2954480A2 (en) | Directing communications to semantic bundles of locations | |
US20150100435A1 (en) | Methods and systems for managing bids for online content based on merchant inventory levels | |
US20220303225A1 (en) | Content Source Allocation Between Computing Devices | |
US9521172B1 (en) | Method and system for sharing online content | |
US9456058B1 (en) | Smart asset management for a content item | |
US10778746B1 (en) | Publisher specified load time thresholds for online content items | |
US9311361B1 (en) | Algorithmically determining the visual appeal of online content | |
US20210366481A1 (en) | Detection of duplicate packetized data transmission | |
US10692111B1 (en) | Systems and methods for reducing online content delivery latency |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:VAISH, VAIBHAV;RAMACHANDRAN, VENKY;KANDHAN, RAMAKRISHNAN;AND OTHERS;SIGNING DATES FROM 20170526 TO 20170607;REEL/FRAME:042677/0832 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044129/0001Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |