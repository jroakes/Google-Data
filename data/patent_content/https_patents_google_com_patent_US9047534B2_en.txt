US9047534B2 - Method and apparatus for detecting near-duplicate images using content adaptive hash lookups - Google Patents
Method and apparatus for detecting near-duplicate images using content adaptive hash lookups Download PDFInfo
- Publication number
- US9047534B2 US9047534B2 US13/572,075 US201213572075A US9047534B2 US 9047534 B2 US9047534 B2 US 9047534B2 US 201213572075 A US201213572075 A US 201213572075A US 9047534 B2 US9047534 B2 US 9047534B2
- Authority
- US
- United States
- Prior art keywords
- image
- feature vector
- data
- reliability
- images
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G06K9/38—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/51—Indexing; Data structures therefor; Storage structures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G06F17/30247—
-
- G06F17/3028—
-
- G06K9/4671—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/20—Image preprocessing
- G06V10/28—Quantising the image, e.g. histogram thresholding for discrimination between background and foreground patterns
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
- G06V10/46—Descriptors for shape, contour or point-related descriptors, e.g. scale invariant feature transform [SIFT] or bags of words [BoW]; Salient regional features
- G06V10/462—Salient features, e.g. scale invariant feature transforms [SIFT]
Definitions
- the present disclosure relates primarily to image detection and, more specifically, to detecting near-duplicate images in printed material.
- a scalable and high performance near-duplicate image search method utilizing short hashes improves performance over existing methods.
- the search algorithm analyzes the reliability of each bit of a hash and performs content adaptive hash lookups by adaptively adjusting the “range” of each hash bit based on reliability. Matched features are post-processed to determine the final match results.
- the method can detect cropped, resized, print-scanned and re-encoded images and pieces from images among thousands of images.
- a method uses local features to be able to detect cropped and shifted images and segments.
- Scale invariance is achieved by computing a local scale for the feature and incorporating the scale in the feature computations. The extrema are picked in the scale space, and a linear transform of the local data is used to compute local features.
- Features are quantized and become the hashes, which, in turn, become the keys in a key-value table.
- Searching for features is performed using content adaptive hash lookups.
- Using the computed hashes directly on key-value tables to perform searches is typically not successful because the query hashes must exactly match the original hashes.
- an exact match is hard to achieve due to typical image modifications, including, but not limited to, re-encoding, print-scan, resizing, rotation, or mismatched interest points.
- a reliability function which depends on the content of each bit compensates for image modifications to adjust the search range of each hash bit.
- each quantized feature is inserted directly into the table.
- each quantized feature is associated with a per-bit reliability value, which is a function of the quantization and feature extraction methods utilized. If a bit is not reliable, the range of the hash lookup is increased to compensate for the unreliability of the hash. Proper selection of the increased range removes the mismatches introduced by the unreliable bit and very high performance key-value table lookups result.
- a method of generating a plurality of indexes to detect content in a query image related to content in at least one stored image includes the steps of identifying at least one interest point in the query image and generating a feature vector as a function of the interest point.
- the feature vector includes a plurality of data values, and each data value corresponds to a numeric representation of a feature of an additional point within a predetermined distance of the interest point.
- a first index is generated as a function of the feature vector, and a reliability vector, including a plurality of reliability values, is generated. Each reliability value corresponds to one of the data values of the feature vector.
- the indexes are generated as a function of the reliability vector and the first index.
- the method may further include the step of normalizing the feature vector prior to generating the first index.
- Normalizing the feature vector includes resizing the feature vector from a plurality of data values over the predetermined distance to a plurality of data values over a normalized distance.
- the first index may be generated using binary quantization of the feature vector, and the reliability values may be linearly proportional to an absolute magnitude of each of the data values in the feature vector.
- the method may also include the steps of identifying at most five unreliable bits in the first index that have a reliability value less than a predetermined threshold, and generating a unique index for each combination of the unreliable bits.
- the plurality of indexes includes each of the unique indexes, and a plurality of interest points from each stored image is stored in a table.
- the table includes an index and data corresponding to the index for each of the interest points.
- the method may also include the steps of retrieving the data for the stored image corresponding to each of the plurality of indexes, comparing the data corresponding to the interest point in the stored image to the data corresponding to one of the interest points identified in the query image, and identifying a matching interest point if the data corresponding to the interest point identified in the query image matches the data corresponding to one of the interest points in the stored image.
- the content of the query image may be identified as matching the content of one of the stored images if at least three matching interest points are identified.
- a method of identifying related images includes the steps of receiving a query image from an input device operatively connected to a processor, identifying at least one interest point in the query image, generating a feature vector for each interest point as a function of the interest point, generating a reliability vector as a function of the feature vector, comparing the query image to a plurality of other images, and identifying at least one image from the plurality of other images related to the query image as a function of the feature vector and the reliability vector.
- the method may further include the step of quantizing the feature vector.
- the reliability vector may be a function of the quantized feature vector.
- the method may include initial steps of identifying at least one interest point from the plurality of images, generating a feature vector for each interest point for the plurality of images as a function of the interest point, quantizing each feature vector for the plurality of images, and storing image data of the plurality of images in a database as a function of the quantized feature vectors. Quantizing the feature vector for the plurality of images generates an index to a table in the database, and the image data is stored in the database according to the index. Identifying at least one image may further include the step of generating a plurality of indexes to the table as a function of the reliability vector and the quantized value of each feature vector of the query image.
- a scale space of the image around the interest point is normalized prior to generating the feature vector.
- At least three points of interest of the query image are related to corresponding points of interest in one of the plurality of other images, and image data of the query image located within a first triangle defined by the three points of interest of the query image is related to image data of the located image within a second triangle defined by the corresponding three points of interest for the other image.
- a system for identifying related images includes an input device configured to receive a query image, at least one memory device storing a plurality of instructions and a plurality of images, and a processor operatively connected to the memory device.
- the processor is configured to execute the plurality of instructions to identify at least one interest point from the query image, generate a feature vector for each interest point as a function of the interest point, generate a reliability vector as a function of the feature vector, compare the query image to the plurality of images, and identify at least one image related to the query image from the plurality of images as a function of the feature vector and the reliability vector.
- FIG. 1 schematically illustrates an exemplary system used for detecting near-duplicate images
- FIG. 2 is a block diagram representation of the exemplary system of FIG. 1 ;
- FIG. 3 is a block diagram representation of an indexing and/or a query operation according to one embodiment of the present invention
- FIG. 4 is a flowchart illustrating the process of indexing and/or querying near-duplicate images
- FIG. 5 a is an exemplary image which may be stored or retrieved according to the present invention.
- FIG. 5 b schematically illustrates a technique for subdividing the exemplary image in FIG. 5 a
- FIG. 5 c schematically illustrates a technique for interest point identification of the image in FIG. 5 a
- FIG. 6 schematically illustrates a technique for feature identification of one interest point identified in FIG. 5 c;
- FIG. 7 schematically illustrates a technique for near-duplicate image identification according to one embodiment of the invention.
- FIG. 8 schematically illustrates a technique for duplicate image identification from a portion of a full page query
- FIG. 9 illustrates partial matches of a modified image to a master image according to one embodiment of the invention.
- FIG. 10 illustrates an irregular partial match of a search image to a master image according to one embodiment of the invention.
- a system for detecting near-duplicate images includes a computer 10 and related peripheral devices.
- the computer 10 may be, for example, a desktop, a laptop, a notebook, a server, or any other suitable processing device.
- the computer 10 preferably includes a display 20 to provide visual feedback to a user and a keyboard 22 to accept input from the user.
- the system may further include other suitable user interface 24 devices, for example, a mouse, a track ball, a touch screen, and the like.
- Image data may be received, for example, from a scanner 26 or via a cable 32 connected to a network 34 .
- the network 34 may be internal or external, such as the Internet.
- a drive 28 may accept corresponding storage media, including but not limited to, a floppy disk, a compact disc (CD), a digital video disc (DVD), or a memory card.
- Still other suitable input devices 30 such as a universal serial bus (USB) memory device may be connected to the computer 10 .
- the computer 10 includes suitable interfaces, such as a network interface card (NIC) 16 to receive image data and transfer them to the processor 12 .
- NIC network interface card
- the processor 12 may act directly on the image data, store the image data in memory 14 , or perform a combination thereof.
- Hash tables provide an efficient method of storing and retrieving large quantities of data. As illustrated in FIG. 3 , data to be stored in a hash table 44 is received as input 40 and passed through a hash function 42 . The hash function 42 converts the input 40 to a numerical value which provides an index value 46 representing an entry 48 , or bucket, in the hash table 44 . The data is then stored at the identified bucket 48 in the hash table 44 .
- Hash tables 44 are data structures that implement an associative array, storing data related to the input 40 in the data structure. For example, the hash table 44 may store a first numerical value identifying a feature of an interest point 76 (see also FIG.
- the hash table 44 has at least two fields defined in the data structure per input 40 to be stored.
- the first field 46 is an index value identifying the position within the data structure that the item is stored and the second field 48 contains the data to be stored in the data structure.
- the hash function 42 is selected to transform the input 40 into the index value 46 such that the associated data may then be stored at that position within the hash table 44 .
- the input 40 may be, for example, a second numerical value corresponding to the interest point 76 such as the coordinates, the brightness, or the magnitude of color in a Red-Blue-Green color model of the interest point 76 .
- the input 40 is transformed by the hash function 42 into an index value 46 in the hash table 44 . Therefore, the second numerical value is used to generate an index value 46 which identifies the point in the hash table 44 that the first numerical value is then stored.
- the hash function 42 distributes inputs 40 in a generally uniform manner throughout the hash table 44 .
- Data is retrieved from the hash table 44 in a manner similar to storing the data in the hash table 44 .
- An interest point 76 is identified and the second numerical value associated with the interest point 76 is provided as an input 40 to the hash function 42 .
- the hash function 44 generates the index value 46 identifying the desired bucket 48 in the hash table 44 from which to read the first numerical value.
- the first and second numerical values may initially be determined based on an interest point 76 in a first image.
- the image data for the first image is then stored in the hash table 44 .
- An interest point on a second image may then be used to generate another set of first and second numerical values.
- the hash function 44 generates an index value 46 based on the data from the second image.
- the data stored in the hash table 44 which corresponds to the first image, at the index value 46 generated by data from the second image is read. If the data read from the hash 44 matches the data corresponding to the interest point 76 of the second image, a match is detected. Because copying, image transformation, and noise may introduce variations in the data between two images, copies of images may not always return a match. As discussed in more detail below, the present invention provides an improved method for indexing and retrieving data from a hash table.
- an exemplary process 50 of inserting and retrieving image data into the hash table 44 begins by identifying an interest point 76 , see FIG. 5 c , as shown in step 52 .
- Interest points 76 are locations or features of images that are generally immune to image transformations such as scaling, compression, rotation, perspective transformation, and signal noise. By selecting an interest point 76 that is generally immune to image transformation, the interest point 76 is more likely to be present in a second image that is a duplicate of the first image even if the second image has been transformed in some manner.
- a feature vector is computed based on a normalized region around the interest point 76 .
- the feature vector may be a single-dimensional or multi-dimensional array of varying length that includes a numerical representation of image data around the interest point.
- a feature such as the luminance, of additional points of the image within a preselected distance, ⁇
- ⁇ is numerically represented, for example, according to its brightness.
- These numerical values are stored within the feature vector.
- a normalized feature vector having a fixed size is determined as a function of the first feature vector where any suitable method of resizing the feature vector may be used.
- the normalized feature vector is used as an input 40 to the hash function 42 which determines an index 46 within the hash table 44 at which the data from the interest point 76 is stored.
- a binary quantization function is selected as the hash function 42 .
- the binary quantization function converts the normalized feature vector to an index value 46 for inserting data to or comparing data against the hash table 44 .
- other quantization functions may be selected to generate the index value 46 .
- the binary quantization function is a 1-bit scalar function that generates a zero or a one for each value in the feature vector.
- the binary quantization function may, for example, assign a one to the presence of a feature and a zero to the absence of a feature.
- a threshold may be selected and the binary quantization function may return a one if the value in the feature vector is greater than the threshold and a zero if the value in the feature vector is less than the threshold.
- the resulting index value 46 is generated by concatenating each of the bits generated by the quantization function.
- the number of bits in the index value 46 defines the size of the hash table 44 and the amount of memory required to store the hash table 44 .
- the feature vector may include forty values.
- the data stored in the bucket 48 of the hash table may be any data associated with the interest point including, but not limited to, the coordinates of the interest point 76 and an identifier of the image from which the interest point 76 was detected.
- a reliability vector is computed for use in the searching process.
- the reliability vector is of the same length as the feature vector and includes a reliability value corresponding to each of the data values in the feature vector.
- the reliability value provides a numerical weighting indicating which of the data values in the feature vector for the second image are more likely to return a match from stored data corresponding to a first image.
- the reliability value is linearly proportional to the absolute magnitude of each data value in the feature vector.
- the reliability vector may provide an indication of the proximity of a data value to the boundary of the region represented by the feature vector. Still other reliability functions may be selected without deviating from the scope of the invention.
- a set of indexes 46 is then generated at step 64 as a function of the reliability vector and the first index 46 previously generated at step 56 .
- a determination of the least reliable bits in the first index 46 is made based on the reliability vector.
- another index 46 is generated as a function of the quantization function used. For example, with a binary quantization function, a second index 46 may be generated in which the least reliable bit is set to its opposite value in the first index 46 . If the least reliable bit is a one in the first index 46 , it becomes a zero in the second index 46 , and if the least reliable bit is a zero in the first index 46 , it becomes a one in the second index.
- the data in the hash table 44 at both indexes 46 is then read and evaluated for a match between images.
- the five least reliable bits of the first index 46 as identified by the reliability vector, are selected and each of the various combinations of those bits are used to generate additional indexes 46 , resulting in a set of 32 indexes at which data is retrieved from the hash table 44 .
- the disclosed method uses local features to be able to detect cropped and shifted images and segments.
- Scale invariance is achieved by computing a local scale for the feature and incorporating the scale in the feature computations. The extrema in the scale space are selected and a linear transform of the local data is used to compute local features.
- Features are quantized and become the hashes, which in turn become the key values 46 , also known as keys, in the hash table 44 .
- Feature computation is a two step process: i) detecting interest points, and ii) computing feature vectors using image data around the detected interest points.
- Interest point detection finds the points on an image, and their associated invariant scales, that are most likely to be reproduced under various transformations, such as scaling, compression, rotation, or general perspective transformations, or in the presence of signal noise.
- a scale space representation of the image is first generated.
- the most stable and uniformly distributed points of interest from the scale space representation of the image are selected.
- a minimum number of interest points are identified in a given region.
- a 200 ⁇ 200 pixel region preferably includes at least three interest points and more preferably includes at least six interest points.
- the size of the hash table 44 is dependent on the memory 14 available in the computer 10 .
- the most stable interest points 76 up to the allotted number, M, are then stored in the table 44 .
- an image 70 may be selected for storage in the hash table 44 .
- the image 70 may be of varying size and resolution. As shown in FIG. 5 b , if the region exceeds a certain size, it may be first divided into rows 72 and columns 74 such that smaller portions can be analyzed. Each region is analyzed to identify interest points 76 . Any suitable interest point detection method may be implemented, including but not limited to, corner detection as shown in FIG. 5 c . Preferably, the detection method is capable of detecting the same interest point 76 regardless of modifications performed on the image.
- a feature vector For each interest point 76 that is detected, a feature vector is computed.
- the feature vectors preferably use local image data around the interest point 76 from the luminance channel only.
- the luminance channel provides an indication of the brightness of each pixel.
- other feature computation methods may be used without deviating from the scope of the invention.
- the feature vector, v i is computed by transforming the pixels within a distance, ⁇ , from the coordinates (x i , y i ) of the interest point as shown in FIG. 6 .
- a linear transformation of the pixels is used to provide robustness against minor geometric modifications and a desired level of differentiation.
- any suitable non-linear transformation can also be used.
- ⁇ is selected based on the size of the normalized region
- ⁇ is selected based on the size of the normalized region.
- ⁇ is selected as 1 ⁇ 8 the magnitude of L and ⁇ is selected as 1/24 the magnitude of L.
- Data is indexed, or stored, in the hash table based on keys generated from each feature vector.
- a feature vector, previously computed around an interest point 76 from a master image, is quantized into a numerical representation of the vector, and the resulting numerical value is the key, or index, value 46 into the hash table 44 at which the data is stored.
- the data stored in each bucket 48 are the coordinates of the interest point 76 corresponding to the feature vector and the identifier of the master image from which the interest point 76 was obtained.
- quantization of the feature vector is performed using a 1-bit scalar quantizer applied to each element of the feature vector.
- the resulting key, k i is the concatenation of the quantized bits of the feature vector as shown in Equation 3. It is contemplated that any suitable quantization function may be used without deviating from the scope of the invention.
- k i [Q ( v i (1)) Q ( v i (2)) . . . Q ( v i ( B ))] (3) where: Q( ) denotes the quantization function, and
- B is the number of coefficients in the feature vector.
- a reliability value is computed in conjunction with the quantization of the feature vector for each key value to identify the reliability of the corresponding element.
- the reliability of each element increases with the absolute magnitude of that element. Consequently, the reliability value may be selected as linearly proportional to the magnitude of each feature element and may be calculated as shown in Equation 4.
- the reliability vector is a function of the transformation used to determine the feature vector and a function of the quantization method utilized to determine the numerical value of the feature vector. Therefore, it is contemplated that other methods of calculating the reliability vector may be used without deviating from the scope of the invention.
- the image is processed as described above. If the method invokes indexing the image, the coordinates of the points of interest as well as the image identifier are directly inserted into a bucket 48 of the hash table 44 according to the key values 46 calculated from the quantized feature vector. Indexing is performed independent of the reliability values. However, searching incorporates the reliability values in the hash lookup process.
- Searching is performed by content adaptive hash lookups from the hash table 44 .
- the query value must match the stored value. Consequently, searching for a stored image that is a duplicate, or near-duplicate, of a queried image requires matching at least one key from the queried image to a corresponding key in the hash table 44 .
- feature noise results in variations between the indexed image and the queried image.
- Feature noise is a change in an element of a feature vector due to a modification of the image including, but not limited to, resizing, scanning, printing, image compression, or misalignment.
- the content adaptive search generates a set of keys for each queried feature as a function of the reliability value to identify matches between the queried feature and a stored feature even if small differences exist between the two features.
- the query image is related to a stored image according to Equation 5.
- the values of ⁇ and ⁇ n may be selected using a training set of images to achieve an acceptable balance between detecting false positive and false negative search results. It is contemplated that searching may be performed by other methods which incorporate the reliability value without deviating from the scope of the present invention.
- v i ( ) is the feature vector of the stored image
- v i ′( ) is the feature vector of the queried image
- j is in the range of 1 to M
- ⁇ is selected according to the application requirements
- ⁇ n is the variance due to feature noise.
- the number of unreliable bits is limited to, for example, 5 bits.
- binary, or 1-bit quantization is used.
- the number of potential combinations is 2 5 or 32 possible keys to test for each of the queried feature vectors. It is contemplated that the number of unreliable bits may be less than or greater than five or still other methods of limiting the number of potential keys may be selected without deviating from the scope of the present invention.
- an image match is reported if at least 3 matching keys are found and the triangles, 80 and 80 ′, created by the corresponding locations on the master and query images, satisfy the triangle similarity conditions.
- Triangle similarity conditions are used to detect similar triangles, for example having two angles of equal measure, which indicate that the matching keys between the two images have similar spatial relationships within the image even if the actual distance varies, for example due to scaling of the image. This also increases the differentiation capability which is lowered due to short hashes.
- the region created by all such matching points is reported as a match.
- a match may be the whole query image, 94 and 94 ′, between the master image and query image, respectively, as shown in FIGS.
- the detection method may additionally return an irregular partial match of a portion, 96 and 96 ′, of the master image and query image, respectively, as shown in FIG. 10 .
- results are acceptable when identifying near-duplicate images.
Abstract
Description
f v =G(β,β)−G(β,γ) (1)
f h =G(β,β)−G(γ,β) (2)
where: fv is the Gaussian filter in the vertical direction,
k i =[Q(v i(1))Q(v i(2)) . . . Q(v i(B))] (3)
where: Q( ) denotes the quantization function, and
r i =[|v i(1)∥v i(2)| . . . |v i(B)|] (4)
Q(v i′(j)−ασn)
where: vi( ) is the feature vector of the stored image,
Claims (19)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/572,075 US9047534B2 (en) | 2011-08-11 | 2012-08-10 | Method and apparatus for detecting near-duplicate images using content adaptive hash lookups |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201161522416P | 2011-08-11 | 2011-08-11 | |
US13/572,075 US9047534B2 (en) | 2011-08-11 | 2012-08-10 | Method and apparatus for detecting near-duplicate images using content adaptive hash lookups |
Publications (2)
Publication Number | Publication Date |
---|---|
US20130039584A1 US20130039584A1 (en) | 2013-02-14 |
US9047534B2 true US9047534B2 (en) | 2015-06-02 |
Family
ID=47677593
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/572,075 Active 2032-10-06 US9047534B2 (en) | 2011-08-11 | 2012-08-10 | Method and apparatus for detecting near-duplicate images using content adaptive hash lookups |
Country Status (1)
Country | Link |
---|---|
US (1) | US9047534B2 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11457275B2 (en) | 2018-01-04 | 2022-09-27 | Samsung Electronics Co., Ltd. | Display apparatus and control method thereof |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9530072B2 (en) | 2013-03-15 | 2016-12-27 | Dropbox, Inc. | Duplicate/near duplicate detection and image registration |
IL226219A (en) * | 2013-05-07 | 2016-10-31 | Picscout (Israel) Ltd | Efficient image matching for large sets of images |
CN106033426B (en) * | 2015-03-11 | 2021-03-19 | 中国科学院西安光学精密机械研究所 | Image retrieval method based on latent semantic minimum hash |
US10015541B2 (en) * | 2015-03-25 | 2018-07-03 | Cisco Technology, Inc. | Storing and retrieval heuristics |
CN106954012A (en) * | 2017-03-29 | 2017-07-14 | 武汉嫦娥医学抗衰机器人股份有限公司 | A kind of high definition polyphaser full-view stereo imaging system and method |
US11050552B2 (en) * | 2017-05-03 | 2021-06-29 | Infosys Limited | System and method for hashing a data string using an image |
US11074434B2 (en) * | 2018-04-27 | 2021-07-27 | Microsoft Technology Licensing, Llc | Detection of near-duplicate images in profiles for detection of fake-profile accounts |
Citations (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5577135A (en) * | 1994-03-01 | 1996-11-19 | Apple Computer, Inc. | Handwriting signal processing front-end for handwriting recognizers |
US5917943A (en) * | 1995-03-31 | 1999-06-29 | Canon Kabushiki Kaisha | Image processing apparatus and method |
US6026189A (en) * | 1997-11-13 | 2000-02-15 | National Research Council Of Canada | Method of recognizing objects within two-dimensional and three-dimensional images |
US6173275B1 (en) * | 1993-09-20 | 2001-01-09 | Hnc Software, Inc. | Representation and retrieval of images using context vectors derived from image information elements |
US6404925B1 (en) * | 1999-03-11 | 2002-06-11 | Fuji Xerox Co., Ltd. | Methods and apparatuses for segmenting an audio-visual recording using image similarity searching and audio speaker recognition |
US20020159641A1 (en) * | 2001-03-14 | 2002-10-31 | Whitney Paul D. | Directed dynamic data analysis |
US6539395B1 (en) * | 2000-03-22 | 2003-03-25 | Mood Logic, Inc. | Method for creating a database for comparing music |
US20030195883A1 (en) * | 2002-04-15 | 2003-10-16 | International Business Machines Corporation | System and method for measuring image similarity based on semantic meaning |
US6711293B1 (en) | 1999-03-08 | 2004-03-23 | The University Of British Columbia | Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image |
US20050125368A1 (en) * | 2003-03-24 | 2005-06-09 | Fuji Photo Film Co., Ltd. | Apparatus and program for learning data and apparatus for deciding meaning of image |
US6975755B1 (en) * | 1999-11-25 | 2005-12-13 | Canon Kabushiki Kaisha | Image processing method and apparatus |
US20060101060A1 (en) * | 2004-11-08 | 2006-05-11 | Kai Li | Similarity search system with compact data structures |
US20070025606A1 (en) * | 2005-07-27 | 2007-02-01 | Bioimagene, Inc. | Method and system for storing, indexing and searching medical images using anatomical structures of interest |
US20070217676A1 (en) * | 2006-03-15 | 2007-09-20 | Kristen Grauman | Pyramid match kernel and related techniques |
US20080166057A1 (en) * | 2004-12-24 | 2008-07-10 | Nec Corporation | Video Structuring Device and Method |
US20090324026A1 (en) * | 2008-06-27 | 2009-12-31 | Palo Alto Research Center Incorporated | System and method for finding a picture image in an image collection using localized two-dimensional visual fingerprints |
US20110219035A1 (en) * | 2000-09-25 | 2011-09-08 | Yevgeny Korsunsky | Database security via data flow processing |
US8160366B2 (en) * | 2008-06-20 | 2012-04-17 | Sony Corporation | Object recognition device, object recognition method, program for object recognition method, and recording medium having recorded thereon program for object recognition method |
US8200021B2 (en) * | 2009-06-16 | 2012-06-12 | Nec Corporation | Image signature matching device |
US8515212B1 (en) * | 2009-07-17 | 2013-08-20 | Google Inc. | Image relevance model |
-
2012
- 2012-08-10 US US13/572,075 patent/US9047534B2/en active Active
Patent Citations (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6173275B1 (en) * | 1993-09-20 | 2001-01-09 | Hnc Software, Inc. | Representation and retrieval of images using context vectors derived from image information elements |
US5577135A (en) * | 1994-03-01 | 1996-11-19 | Apple Computer, Inc. | Handwriting signal processing front-end for handwriting recognizers |
US5917943A (en) * | 1995-03-31 | 1999-06-29 | Canon Kabushiki Kaisha | Image processing apparatus and method |
US6026189A (en) * | 1997-11-13 | 2000-02-15 | National Research Council Of Canada | Method of recognizing objects within two-dimensional and three-dimensional images |
US6711293B1 (en) | 1999-03-08 | 2004-03-23 | The University Of British Columbia | Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image |
US6404925B1 (en) * | 1999-03-11 | 2002-06-11 | Fuji Xerox Co., Ltd. | Methods and apparatuses for segmenting an audio-visual recording using image similarity searching and audio speaker recognition |
US6975755B1 (en) * | 1999-11-25 | 2005-12-13 | Canon Kabushiki Kaisha | Image processing method and apparatus |
US6539395B1 (en) * | 2000-03-22 | 2003-03-25 | Mood Logic, Inc. | Method for creating a database for comparing music |
US20110219035A1 (en) * | 2000-09-25 | 2011-09-08 | Yevgeny Korsunsky | Database security via data flow processing |
US20020159641A1 (en) * | 2001-03-14 | 2002-10-31 | Whitney Paul D. | Directed dynamic data analysis |
US20030195883A1 (en) * | 2002-04-15 | 2003-10-16 | International Business Machines Corporation | System and method for measuring image similarity based on semantic meaning |
US20050125368A1 (en) * | 2003-03-24 | 2005-06-09 | Fuji Photo Film Co., Ltd. | Apparatus and program for learning data and apparatus for deciding meaning of image |
US20060101060A1 (en) * | 2004-11-08 | 2006-05-11 | Kai Li | Similarity search system with compact data structures |
US20080166057A1 (en) * | 2004-12-24 | 2008-07-10 | Nec Corporation | Video Structuring Device and Method |
US20070025606A1 (en) * | 2005-07-27 | 2007-02-01 | Bioimagene, Inc. | Method and system for storing, indexing and searching medical images using anatomical structures of interest |
US20070217676A1 (en) * | 2006-03-15 | 2007-09-20 | Kristen Grauman | Pyramid match kernel and related techniques |
US8160366B2 (en) * | 2008-06-20 | 2012-04-17 | Sony Corporation | Object recognition device, object recognition method, program for object recognition method, and recording medium having recorded thereon program for object recognition method |
US20090324026A1 (en) * | 2008-06-27 | 2009-12-31 | Palo Alto Research Center Incorporated | System and method for finding a picture image in an image collection using localized two-dimensional visual fingerprints |
US8200021B2 (en) * | 2009-06-16 | 2012-06-12 | Nec Corporation | Image signature matching device |
US8515212B1 (en) * | 2009-07-17 | 2013-08-20 | Google Inc. | Image relevance model |
Non-Patent Citations (7)
Title |
---|
A. Andoni and P. Indyk, "Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions", in Proceedings of the Symposium on Foundations of Computer Science, Jan. 2006, 10 pages. |
A. Joly, O. Buisson and C. Frélicot, "Content-based Copy Retrieval using Distortion-based Probabilistic Similarity Search", IEEE Transactions on Multimedia, vol. 9, No. 2, p. 1-14, Feb. 2007. |
D. G. Lowe, "Object Recognition from Local Scale-Invariant Features", in International Conference on Computer Vision, vol. 2, 1999, pp. 1-8. |
J. Matas, O. Chum, M. Urban, T. Pajdla, "Robust Wide Baseline Stereo from Maximally Stable Extremal Regions", in British Machine Vision Conference., 2002, pp. 384-393. |
K. Mihcak and R. Venkatesan, "Blind Image Watermarking Via Derivation and Quantization of Robust Semi-Global Statistics", in IEEE International Conference on Acoustics, Speech and Signal Processing, 2002, (4 pages). |
K. Mikolajczyk and C. Schmid, "Indexing based on scale invariant interest points", in Proc. ICCV, 2001, 7 pages. |
T. Lindeberg, "Feature Detection with Automatic Scale Selection", International Journal of Computer Vision, vol. 30, No. 2, 1998, pp. 1-51. |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11457275B2 (en) | 2018-01-04 | 2022-09-27 | Samsung Electronics Co., Ltd. | Display apparatus and control method thereof |
Also Published As
Publication number | Publication date |
---|---|
US20130039584A1 (en) | 2013-02-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9047534B2 (en) | Method and apparatus for detecting near-duplicate images using content adaptive hash lookups | |
Jégou et al. | On the burstiness of visual elements | |
US8781255B2 (en) | Methods and apparatus for visual search | |
JP5596792B2 (en) | Content-based image search | |
US8144921B2 (en) | Information retrieval using invisible junctions and geometric constraints | |
US8868569B2 (en) | Methods for detecting and removing duplicates in video search results | |
US8086038B2 (en) | Invisible junction features for patch recognition | |
US8699789B2 (en) | Document classification using multiple views | |
US8428397B1 (en) | Systems and methods for large scale, high-dimensional searches | |
EP2172856A2 (en) | Image processing apparatus, image processing method and program | |
US20120143853A1 (en) | Large-scale asymmetric comparison computation for binary embeddings | |
Minarno et al. | Batik image retrieval based on color difference histogram and gray level co-occurrence matrix | |
WO2019136897A1 (en) | Image processing method, apparatus, electronic device and storage medium | |
US20180165540A1 (en) | Image object retrieval | |
CN109697240B (en) | Image retrieval method and device based on features | |
Sun et al. | Search by detection: Object-level feature for image retrieval | |
JP6017277B2 (en) | Program, apparatus and method for calculating similarity between contents represented by set of feature vectors | |
Iwanowski et al. | Comparing images for document plagiarism detection | |
CN108694411A (en) | A method of identification similar image | |
CN105224619B (en) | A kind of spatial relationship matching process and system suitable for video/image local feature | |
Liu et al. | Feature grouping and local soft match for mobile visual search | |
Jadhav et al. | Content based image retrieval system with hybrid feature set and recently retrieved image library | |
Moraleda | Large scalability in document image matching using text retrieval | |
KR102054211B1 (en) | Method and system for video retrieval based on image queries | |
Özkan et al. | Visual group binary signature for video copy detection |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: ANVATO, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:HARMANCI, OZTAN;HARITAOGLU, ISMAIL;REEL/FRAME:035502/0151Effective date: 20150427 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FEPP | Fee payment procedure |
Free format text: PAT HOLDER NO LONGER CLAIMS SMALL ENTITY STATUS, ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: STOL); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:ANVATO, INC.;REEL/FRAME:040694/0041Effective date: 20161116 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044334/0466Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |