CN115997212A - Encrypted information retrieval - Google Patents
Encrypted information retrieval Download PDFInfo
- Publication number
- CN115997212A CN115997212A CN202280005729.0A CN202280005729A CN115997212A CN 115997212 A CN115997212 A CN 115997212A CN 202280005729 A CN202280005729 A CN 202280005729A CN 115997212 A CN115997212 A CN 115997212A
- Authority
- CN
- China
- Prior art keywords
- client
- server
- encrypted
- secret sharing
- client device
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/08—Key distribution or management, e.g. generation, sharing or updating, of cryptographic keys or passwords
- H04L9/0816—Key establishment, i.e. cryptographic processes or cryptographic protocols whereby a shared secret becomes available to two or more parties, for subsequent use
- H04L9/085—Secret sharing or secret splitting, e.g. threshold schemes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/28—Databases characterised by their database models, e.g. relational or object models
- G06F16/284—Relational databases
- G06F16/285—Clustering or classification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6227—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database where protection concerns the structure of data, e.g. records, types, queries
Abstract
Methods, systems, and computer readable media for facilitating retrieval of encrypted information. A method may include receiving a batch of queries including queries for a particular bucket in each database tile. Query results responsive to the batch of queries are transmitted to the client device. The query result includes a server-encrypted secret sharing portion obtained from the special bucket. A client encrypted version of the secret sharing portion is received. The complete set of server-encrypted secret sharing portions is transmitted to the client device, which is encrypted by the client device to create the complete set of client-server-encrypted secret sharing portions. The client device is classified based on how many secret sharing portions are included in both the client-encrypted secret sharing portion received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device.
Description
Cross Reference to Related Applications
The present application claims the benefit of U.S. patent application Ser. No. 63/218,120 entitled "ENCRYPTED INFORMATION RETRIEVAL (encrypted information retrieval)" filed on 7/2 of 2021. The disclosures of the foregoing applications are incorporated herein by reference in their entirety for all purposes.
Background
The present description relates to data processing and information retrieval.
User devices such as content distributors and content platforms may query content providers to retrieve information stored by the content providers. However, there may be situations where any details disclosed to the content provider regarding what information is being queried are not in the interests of the content platform. In other cases, any details disclosed to the content platform regarding other information stored on the content provider's computing system may not be in line with the interests of the content provider.
Disclosure of Invention
In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include the acts of: receiving, at the server device, a batch of queries from the client device, the batch of queries comprising queries for a particular bucket in each of a plurality of database shards queried by the batch of queries, wherein the particular bucket comprises a server-encrypted secret sharing portion generated by the server; generating, by the server device, a set of query results in response to the batch of queries, wherein the set of query results includes a server-encrypted secret sharing portion obtained from a particular bucket queried by the batch of queries; transmitting, by the server device, the query result set to the client device; receiving, at the server device, a client encrypted secret sharing portion from the client device, wherein the client encrypted secret sharing portion is a client encrypted version of the secret sharing portion included in the query result set transmitted to the client device; transmitting, by the server device to the client device, a complete set of server-encrypted secret sharing portions, wherein the complete set of server-encrypted secret sharing portions includes more server-encrypted secret sharing portions than the set of query results; receiving, at the server device, a complete client-server encrypted set of secret sharing portions from the client device, wherein the complete client-server encrypted set of secret sharing portions is a client encrypted version of the complete server encrypted set of secret sharing portions transmitted to the client device; determining, by the server device, how many secret sharing portions are included in both the client-encrypted secret sharing portion received from the client device and the complete set of client-server-encrypted secret sharing portions received from the client device; and classifying, by the server device, the client device based on how many secret sharing portions are included in both the client-encrypted secret sharing portion received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device.
Other embodiments of this aspect include corresponding apparatuses, systems, and computer programs configured to perform aspects of the methods encoded on computer storage devices. These and other embodiments may each optionally include one or more of the following features.
The method may include removing, by the server device, the server decryption from the complete client-server encrypted set of secret sharing portions received from the client device to obtain the complete client encrypted set of secret sharing portions. Determining how many secret sharing portions are included in both the client-encrypted secret sharing portion received from the client device and the complete set of client-server-encrypted secret sharing portions received from the client device may include comparing the client-encrypted secret sharing portion received from the client device with the complete set of client-encrypted secret sharing portions obtained by removing server decryption from the complete set of client-server-encrypted secret sharing portions.
Classifying the client device may include determining that the client device is malicious based on the comparison indicating that less than the required number of secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-encrypted secret sharing portions obtained by removing server decryption from the complete set of client-server-encrypted secret sharing portions.
A method may include receiving a client encrypted set of entity identifiers from a client device; encrypting, by the server, the client-encrypted set of entity identifiers to create a server-client encrypted set of identifiers; and transmitting, by the server, the server-client encrypted set of identifiers to the client device.
The method may include generating a partitioned database in which the database is partitioned into a plurality of database shards, each database shard having a shard identifier that logically distinguishes each database shard from other database shards, and database entries in each database shard being partitioned into buckets having bucket identifiers that logically distinguish each bucket in a shard from other buckets in the shard.
The method may include: adding a special bucket to each slice; in each special bucket special data is included that is known to the server device but not to the client device; and updating the special data in the special bucket of the given tile after each query to the given tile to maintain privacy of information contained in the special bucket of the given tile.
The method may include: generating, by the client device, a query set using the server-client encrypted set of identifiers; generating, by the client device, a set of decryption keys using the server-client encrypted set of identifiers; the set of queries is encrypted by the client device to create a batch of client-encrypted queries.
The subject matter described in this specification can be implemented in specific embodiments to realize one or more of the following advantages. The techniques and methods described in this specification describe techniques for retrieving data from a database while protecting client and server privacy. This allows the client to query the server without revealing to the server any details about the data being queried. Meanwhile, when a client is querying a server, the server does not reveal any details about the contents of the database that are not queried by the client. In contrast, prior art querying a server typically involves encrypting an entire server database and providing the encrypted database to a client for querying. This approach requires significantly more computing resources because the size of the database is typically large. Other methods of querying a server include providing an index of a database to a client and receiving a selection of the index from the client that does not consider the privacy of the server and the client. Furthermore, the subject matter of the present application can ensure that client devices adhere to agreed-upon protocols, for example, by ensuring that client devices submit an appropriate number of filled queries, which helps ensure that the privacy of the queried data is maintained.
Drawings
FIG. 1 is a block diagram of an example environment in which content is distributed and presented to user devices.
FIG. 2 is a swim lane diagram of an example process of retrieving content from a server by a client.
FIG. 3 is a flow chart of an example process of partitioning a server database.
FIG. 4 is a flow chart of an example process of generating a query from a server encrypted identifier.
FIG. 5 is a flow chart of an example process for processing a query by a server.
FIG. 6 is a block diagram of an example computer system.
Detailed Description
The present description relates to data processing and information retrieval. In particular, the techniques and methods described in this specification describe techniques for retrieving data from a database while protecting client and server privacy. For example, if a client queries a server database, the client does not reveal any details to the server about the data being queried (also referred to as client query privacy). At the same time, the server does not reveal any details to the client about the content of the database that was not queried by the client (also referred to as server database privacy). These techniques enable batch processing of queries to provide a more efficient information retrieval system that also protects user privacy. For example, user privacy is protected by ensuring that the server being queried is not aware of information about the user that the client is querying the server, and also preventing the client from learning other information about the user that may be stored by the server.
FIG. 1 is a block diagram of an example environment 100 in which content is distributed and presented to user devices. The example environment 100 includes a network 102, such as a Local Area Network (LAN), wide Area Network (WAN), the Internet, or a combination thereof. Network 102 connects content platform 106 and content provider 110. The example environment 100 may include many different content providers 110, content platforms 106, and user devices 104.
The user device 104 is an electronic device capable of requesting and receiving content over the network 102. Example user devices 104 include personal computers, mobile communication devices, digital assistant devices, and other devices that can send and receive data over the network 102. The user device 104 typically includes an operating system 112 that is primarily responsible for managing device hardware and software resources, such as applications. The user device 104 also includes device storage 120 for temporarily or permanently storing data based on particular implementations, applications, and use cases. User device 104 typically includes user applications 116 and 117, such as web browsers or email clients, to facilitate the sending and receiving of data over network 102, although native applications executed by user device 104 may also facilitate the sending and receiving of content over network 102. Examples of content presented at the user device 104 include web pages, word processing documents, portable Document Format (PDF) documents, images, video and search result pages, and digital advertisements.
In some embodiments, content platform 106 may distribute digital content to one or more users. For example, content platform 106 may have one or more users subscribe and/or register with content platform 106. In response, the content platform 106 may retrieve digital content from the content provider 110 and provide the retrieved content to the user device 104 of the user. The content provider 110 includes a data storage device (also referred to as a database) that stores digital content in the form of key-value pairs. For example, the database of content provider 110 may include a plurality of keys and, for each key, a corresponding value retrieved by content platform 106.
In some embodiments, content platform 106 may assign an identifier to each user such that the content platform may distinguish between users. In some embodiments, content platform 106 may use information provided by one or more users and/or user devices as a unique identifier. For example, content platform 106 may use an email identifier (email id) provided by the user, a cell phone number provided by the user, or a Media Access Control (MAC) address of user device 104 of the user as the unique identifier. In some embodiments, content platform 106 may assign identifiers to groups of two or more users based on characteristics of the users in the group of users. For example, content platform 106 may assign a public identifier to a user group based on similar interests in the context of digital content accessed by the user. In another example, users may be assigned to a group and may be assigned a common identifier based on subscriptions to digital content. In some embodiments, content platform 106 may assign multiple identifiers to a single user. For example, content platform 106 may assign both an email id and a cell phone number as identifiers for the user.
To retrieve digital content from content provider 110, content platform 106 and content provider 110 implement information retrieval techniques that ensure data privacy in a manner that content platform 106 does not reveal to content provider 110 any details about what information is being queried. The retrieval technique further ensures that the content provider 110 does not reveal any details to the content platform 106 about other information stored on the computing system of the content provider 110. While this description refers to content provider 110 and content platform 106, the information retrieval techniques discussed herein may be used by any two systems that want to exchange information in a privacy-preserving manner. The information retrieval technique is further explained with reference to fig. 2, and an entity that requests information from a database is referred to as a client, and an entity that maintains a database of information and returns information stored in the database is referred to as a server.
FIG. 2 is a swim lane diagram of an example process 200 for retrieving content from a server by a client. The operations of process 200 may be implemented, for example, by client 202 and server 204. The operations of process 200 may also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus may cause the one or more data processing apparatus to perform the operations of process 200.
The server implements a database (also referred to as a server database) that stores digital content in the form of mappings between keys and values (referred to as key-value pairs). The key may be an identifier and/or pointer to a value that is digital content being queried by the client. The database may include a plurality of keys and, for each key, a respective value corresponding to that key. For example, the server may include a plurality of keys in the database, where each key may uniquely identify one or more users of the client for whom the client is retrieving content from the server. In another example, the server may include keys in the database that do not necessarily identify the user. In such embodiments, the value of the corresponding key is data that the server allows the client to query based on other factors, such as client permissions or user permissions granted to the client or user, respectively.
In some embodiments, the keys of the key-value pairs of the server database are associated with identifiers assigned to users by the clients. When querying a server, the client provides the server with a query including the identifier in such a way that details of the identifier are not disclosed to the server. As further explained in this document, even if the identifier is masked from the server, the server may select content (e.g., any kind of data) from the server database based on the identifier.
The client 202 obtains the unique identifier (212). For example, client 202 may provide digital content to one or more users. To uniquely identify one or more users, client 202 may assign an identifier to each of the one or more users. In some embodiments, the client 202 may use information provided by one or more users and/or user devices 104 as identifiers of the one or more users and/or user devices 104. For example, the client 202 may use an email identifier (email id or email address), a cell phone number, or a Media Access Control (MAC) address of the user device 104 as the unique identifier. A client may be any computing system that requests information from another system (e.g., a server system) that stores information or maintains a database.
The client 202 device encrypts the identifier (214). To prevent server 204 from accessing the user's identifier in plain text, client 202 encrypts the identifier using deterministic and exchangeable encryption techniques to generate an encrypted version of the identifier (referred to as a "client encrypted identifier"). In general, exchangeable encryption is an encryption that enables plaintext to be encrypted more than once using encryption keys of different entities. In this system, decryption is not required prior to the encryption/re-encryption process. In addition, the resulting ciphertext (also referred to as encrypted text) may be decrypted by a specified decryption technique regardless of the order of the encryption keys used in the encryption/re-encryption process. In other words, the order of keys used in encryption and decryption does not affect the computation results and allows one encryptor (e.g., client 202) to remove the encryption of data encrypted by the first encryptor even after the other party (e.g., server) has applied further encryption to them.
The client 202 transmits the client encrypted identifier to the server 204 (216). For example, after encrypting the identifier, the client 202 transmits the client encrypted identifier to the server 204 over the network 102.
The hash function may further utilize an encryption salt added to each key of the key-value pair prior to hashing. In some embodiments, encryption salts are also known to the client 202 and may be used by the client 202 in encrypting queries.
FIG. 3 is a flow chart of an example process 300 for partitioning a database into partitions and buckets. The operations of process 300 may be implemented, for example, by server 204, with server 204 including any entity implementing a database storing retrievable data. The operations of process 300 may also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus may cause the one or more data processing apparatus to perform the operations of process 300.
After partitioning each tile into a plurality of buckets, the AES encryption values of the record key-AES encryption value pairs are stored inside each bucket, such that the record key of the record key-AES encryption value pairs indexes both the tile and the bucket inside the tile. It should be noted that server 204 derives the fragment number and bucket id from each key of the key-value pair in the server database using the same method as client 202.
In some embodiments, server 204 places the special bucket in a location known to client 202. In other words, the bucket id of the special bucket is either predefined by the client 202 and the server 204 or provided to the client 202 by the server 204 at some point in time during the interaction between the client and the server. For example, server 204 may change the bucket id with a different timestamp and notify client 202 of the bucket id of the particular bucket using a secure encryption protocol. In some embodiments, server 204 may have different bucket ids for different sliced special buckets. In such embodiments, server 204 may inform the server database of the bucket id of the particular bucket of each shard.
The server 204 combines and serializes the encrypted values (308). At this stage, the special bucket included in step 306 is processed in a similar manner to a conventional bucket, but in some embodiments the contents of the special bucket change on a per-query basis. The server 204 concatenates the AES encrypted value of each non-special bucket or special data of a special bucket into a byte string. For example, if a particular bucket includes 3 AES encrypted values, the 3 AES encrypted values are concatenated one after the other to generate a byte string. The server 204 identifies an offset value (index position of byte string) of the AES encrypted value, and encrypts the offset value using an encryption technique such as AES based on the corresponding record key. For example, if the byte string includes 3 AES encryption values of uniform length, the server encrypts an offset value of each of the 3 AES encryption values in the byte string using AES based on a corresponding record key of the record key-AES encryption value pair. After generating the encrypted offset value, the server 203 presets the encrypted offset value onto the byte string. The server 204 further prepends the number of AES encrypted values onto the byte string. In this example, server 204 prepends a value of 3 onto the byte string. Server 204 further splits the byte string into blocks of c bytes each, where c is an integer that is known a priori by both the client and the server. The c-byte chunks may be further indexed based on their relative positions in the byte string. For example, if c=1, bucket B may be represented as b= [ "p", "q", "r", "s" ], where "pqrs" may be a byte string split into c byte blocks "p", "q", "r", and "s" having indices 1 through 4, respectively, in the bucket. In another example, if c=2, bucket B may be represented as b= [ "pq", "rs", "tu", "v" ], where "pqrstuv" may be a string of bytes split into c-byte blocks "pq", "rs", "tu", "v" with indices 1 to 4, respectively, in the bucket.
Returning now to FIG. 2, the client 202 removes the previous client encryption from the server and client encrypted identifiers (226). In some embodiments, after receiving the server and client encrypted identifiers, the client 202 uses techniques to decrypt (or remove) the encryption performed by the client 202 in step 214 to generate a "server encrypted identifier" for each of the one or more users. Note that client 202 is able to remove client encryption because encryption techniques are exchangeable in nature. Note also that the server encrypted identifier generated after removal of the client encryption is an identifier encrypted by the server using exchangeable and deterministic encryption techniques. In other words, after the client 202 removes the original encryption applied to the identifier, the identifier remains encrypted by the server, and then is merely a server encrypted version of the client identifier that is used by the client 202 to generate a query to be submitted to the server 204 to request information corresponding to the identifier.
In some embodiments, steps 214 through 220 and 226 of process 200 may be implemented using an unintentional pseudo-random function (also referred to as an unintentional PRF or OPRF). An inadvertent PRF is a protocol between a server holding keys for Pseudo Random Functions (PRFs) and a client holding inputs. At the end of the server-client interaction, the client knows the output of the OPRF through the input provided by the client, among other things. The server has no knowledge of the client's input or the output of the OPRF.
To facilitate the creation of the query, the client 202 generates a shard index and bucket identifier for each server encrypted identifier (228). In some embodiments, client 202 implements hashing techniques to generate a query, which may include a shard index and a bucket identifier (also referred to as a bucket id). An example hashing technique to generate a query is further explained with reference to fig. 4.
FIG. 4 is a flow diagram of an example process 400 for generating a query from a server encrypted identifier. The operations of process 400 may be implemented, for example, by a client 202, the client 202 including any entity that implements the techniques described in this document to retrieve content from another entity. The operations of process 400 may also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus may cause the one or more data processing apparatus to perform the operations of process 400.
Fig. 4 illustrates a process 400 for generating a query using an example identifier 450 (john. Smith@sample. Com). After processing the identifier 450 using step 226 of process 200, the server-encrypted identifier 460 of the identifier 450 is represented as serv_enc { john. Smith@sample. Com: = adhf8f2g & 34-! d0sfgn2, where serv_enc is the server encryption of the server and client encrypted identifier after client 202 removes the client encryption of step 214, and "adhf8f2g & 34-! d0sfgn2 "is the ciphertext of identifier 450.
The client 202 converts the unsigned integer into a converted number within a specified range (420). In some embodiments, the client 202 may implement a conversion function configured to process the unsigned integer 470 to generate a converted number 480 within a specified range. Since the hash function and the conversion function are known to both the client 202 and the server 204, the range of converted numbers generated using the conversion function is pre-specified. In this example, the converted number 480 is represented as CONV [ hash_fn [ serv_enc { john. Smith@sample. Com } ] } ] = 324425, where CONV is the conversion function implemented by the client 202. For example, one method of converting an unsigned integer to a number between 0 and 9999 is to use the remainder of the unsigned integer divided by 10000.
Returning to process 200, client 202 uses process 400 to generate a query of identifiers encrypted for each server of one or more users. For example, as described above, each query generated for each identifier will include a sharded index and bucket id created using the server encrypted identifier.
The client 202 generates a decryption key using the encrypted identifier for each server (230). In some embodiments, the client 202 may generate a decryption key for each server encrypted identifier. For example, client 202 may implement an HMAC-based extraction and expansion key derivation function (HKDF), which is a hash-based message authentication code (HMAC) cryptographic Key Derivation Function (KDF) for expanding a key into one or more confidentiality-enhanced secret keys. For example, client 202 may process the server encrypted identifier using HKDF to generate a decryption key.
After encrypting the indicator vector, the client 202 can generate a query that includes the sharded index and the corresponding FHE encrypted bucket vector. The QUERY may be represented as an FHE QUERY (database, QUERY), where the database represents a data store storing a mapping of keys and values, i.e. the database stores a plurality of keys and for each key stores a corresponding value.
Populating the number of queries
= (number of slices × number of queries per slice)
Number of true queries
The number of pad queries generated by the client 202 is distributed as 3 pad queries for the first tile, 0 pad queries for the second tile, 2 pad queries for the third tile, 1 pad query for the fourth tile, and 2 pad queries for the fifth tile.
In some embodiments, client 202 generates an indicator vector for a particular bucket using the bucket id of the particular bucket added by server 204 calculated using process 300. Similar to step 232 of process 200, the indicator vector for a particular bucket may be compressed using well-known compression techniques and encrypted using Fully Homomorphic Encryption (FHE) techniques to generate a corresponding FHE-encrypted bucket vector for the particular bucket.
In some embodiments, each filled query is directed to a particular bucket of shards of queries that are queried by a real query (e.g., a query generated using an identifier). For example, to query a database in a privacy-preserving manner, a client may be required to generate 99 populated queries for each real query. In this example, each of the 99 fill queries would be formed such that they are directed to a particular bucket and would be queries for particular data contained in the particular bucket. In some embodiments, the special data may be a random value or other data. As discussed further below, each filled query will return different special data stored in one of the special buckets that can be used by the server to ensure that the client device generated the required number of filled queries (e.g., by comparing the special data returned in response to the query to the complete special data set known to the server). If the special data in each special bucket is different, the server may conclude that the client 202 is not compromised and/or not malicious if the number of different special data provided to the client matches the number of filler queries that the client device needs to create.
The client 202 transmits the query to the server 204 (236). For example, after generating the query for each server-encrypted identifier and populating the query, the client 202 transmits the complete set of queries to the server 204 over the network 102. In some embodiments, multiple queries are sent to the server in batches so that the server can process the queries simultaneously (e.g., in a batch process).
FIG. 5 is a flow diagram of an example process 500 of processing a query. The operations of process 500 may be implemented, for example, by server 204, with server 204 including any entity implementing a database from which content is retrieved. The operations of process 500 may also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus may cause the one or more data processing apparatus to perform the operations of process 500.
For each query, server 204 identifies the shard using the shard index of the query (502). As previously mentioned with reference to steps 232 and 234 of process 200, each query includes a sharded index and a corresponding FHE encrypted bucket vector. After receiving the query, server 204 identifies the particular shard based on the shard index of the query. For example, if the shard index of the query is 32, the server identifies the 32 nd shard based on the shard index of the server database. Furthermore, the system may be designed such that each tile is selected exactly the same number of times to prevent any information about the query from being collected based on the queried tile.
For each query, the server 204 queries each bucket in the shard and generates a list of FHE encrypted values (504). In some embodiments, the server 204 uses the FHE encrypted bucket vector from the query to query each bucket of the particular shard identified by the shard index. For example, if there are 32 buckets in a tile identified using the tile index from the query, server 204 will query each of the 32 buckets.
The presence bucket may be a variety of ways of querying, and any suitable bucket querying technique may be used. For example, the server 204 performs an inadvertent expansion operation on the FHE encrypted bucket vector from the query to obtain the FHE encrypted value for the particular bucket. It then performs a separate FHE absorption operation between the FHE encryption value for the particular bucket and each c-byte block in the bucket. This can be logically explained with the following non-limiting examples.
Assume that there are 4 buckets in a particular slice. Further, it is assumed that the first bucket has the following blocks [ "a", "B", "C", "D" ]. Similarly, the second, third, and fourth buckets have the following blocks [ "E", "F", "G" ], [ "H" ] and [ "I", "J", "K" ], respectively. Further, assume that the indicator vector is [0,1, 0]. The absorb operation will generate FHE encryption values for blocks indexed 1 across all four buckets, which may be denoted as [0, "E", 0]. Similarly, the FHE encryption values for blocks indexed 2 to 4 across all four buckets are [0, "F", 0], [0, "G", 0] and [0, 0], respectively.
In some embodiments, the server 204 may aggregate the FHE encrypted values of the bucket vector and the values of the c-byte chunks using FHE addition operations across all buckets and generate a list of FHE encrypted values. In other words, by summing the FHE values, all entries in the previously described triplet set with the same query and chunk_index are combined into one. For example, an aggregate operation on the FHE encryption value of a bucket vector and the value of a c-byte block with a particular index (e.g., index 1) will select block "E" from among all blocks with index 1 across all four buckets of the tile. Similarly, the aggregate values of the blocks at index 2, 3, and 4 are "F", "G", and 0, respectively, across all buckets of the tile. After the server 204 selects a block from the bucket, the server 204 may generate a list of FHE encrypted values and transmit the list to the client 202. For example, the server may generate a list of FHE encrypted values [ "E", "F", "G" ] selected using the absorption operation and transmit the list to the client 202. As described above, server 204 cannot identify a true query from the populated query. Thus, the fill query is processed in the same manner as the real query, and the server 204 selects special data from the special buckets of the corresponding shards based on the fill query. The structure of the fill query is pre-specified such that fragmenting the fill query with the fill query results in the server returning special data in response to the fill query.
The process 500 is implemented in a manner that processes multiple queries in parallel on multiple computing systems. In some embodiments, a map reduction process may be used that enables all queries to be processed as batches of queries, which reduces the time required to generate responses to queries and saves processing resources relative to processing each query separately. For example, assume that a database is partitioned into n buckets by a hash key, and the buckets are partitioned into partitions based on the first k bits. In this example, the server may partition the queries by sharding based on the provided sharding index submitted with each query. The server may then fan out each query to the FHE value of each (existing) bucket in its shard by decompressing the encrypted bucket selector. Within each slice, each bucket is connected with the FHE value of the query from the bucket. For each bucket: FHE absorption is performed for each pair of Cartesian products of FHE values from the blocks of queries and buckets. The output of this step is a multiple mapping from (query_id, chunk_index) pairs to FHE encryption values. These values are aggregated using FHE addition as an aggregator. This has the same output format as the previous step except that it is not a multiple mapping-there is just one FHE value per key. A list of encrypted values ordered by chunk_index is aggregated and the output format is a mapping from the query to the list of FHE encrypted values. By providing the same number of queries per shard and using the appropriate sharding operations, computational costs can be reduced by having many shards without revealing any information about the distribution of the queries. Returning now to fig. 2.
The server 204 transmits the list of FHE encrypted values to the client 202 (240). After generating a list of FHE encrypted values for the bucket vector and c-byte block for each query, the server 204 transmits one or more lists to the client 202 over the network 102.
The client 202 decrypts the FHE encryption (242). In some embodiments, after receiving the list of FHE encrypted values for the bucket vector and c-byte block for each query transmitted by the client 202, the client 202 may separate the FHE encrypted values for the filled queries from the actual queries, as the client device knows which queries are filled queries. At this point, the client may decrypt the FHE encryption using the decryption key generated in step 230 of process 200 to obtain the value of the key-value pair that was queried and originally stored in the server database. In decrypting the FHE encrypted values, the client 202 also obtains the special data retrieved from the server database for each fill query transmitted by the client 202 in step 236. The particular data retrieved from the server database for each fill query is collectively referred to as the retrieved particular data set.
The server 204 transmits server encrypted special data to the client 202 (246). After generating the universal set of server-encrypted special data, server 204 transmits the universal set to client 202 over network 102. The client 202 cannot decrypt the general set of server-encrypted special data, but as described below, the client 202 may apply further encryption that will allow the server to compare the client-encrypted version of the special data returned to the client device 202 in response to processing the query to the general set of server-encrypted special data in the query results returned to the client device 202.
The client 202 transmits the general set of client and server encrypted special data to the server 204 (250). The server 204 receives the client and server encrypted generic set of special data and processes the client and server encrypted generic set of special data to determine whether the client device 202 has used the required number of filler queries (e.g., a specified number of filler queries per real query), as described below.
The client 202 encrypts the special data retrieved from the server database to generate client encrypted special data (254). In some embodiments, after obtaining the retrieved special data sets, the client 202 encrypts each special data in the retrieved sets using the same exchangeable encryption technique as used in step 248 of process 200 to generate the retrieved client-encrypted special data sets. The retrieved client encrypted special data set does not include any server encryption and, thus, can be compared to the generic set of client encrypted special data to determine how many matches occur without revealing the underlying special data, as revealing the underlying special data can reveal to the server which queries are filler queries. For example, the server may use the number of matches to ensure that the client device adheres to the agreed-upon protocol without the client device revealing the information it actually submitted in the query. For example, as described below, the server device may verify that the client device has submitted an agreed-upon minimum number of filled queries based on the number of matches identified. This ensures that the client device submits a sufficient number of filled queries, which helps ensure the privacy of the underlying data queried by the client device.
The client 202 transmits the client encrypted special data to the server 204 (256). Server 204 receives the retrieved client-encrypted special data set over network 102 and further processes the client-encrypted special data as described below.
In some embodiments, the server 204 may hide some information after concluding that the client 202 is compromised and/or malicious to prevent the client 202 from accessing data retrieved from the server database. For example, server 204 may add another layer of encryption to the values of the key-value pairs of the server database using any known encryption technique based on an encryption key known only to server 204. If the server 204 concludes that the client 202 is compromised and/or malicious, the server 204 does not transmit the encryption key to the client 202, thereby preventing the client from accessing the retrieved data in plain text. Conversely, if the server 204 concludes that the client 202 is not compromised and/or not malicious, the server 204 will transmit the encryption key to the client 202, allowing the client 202 to access the retrieved data in plain text. In another example, the server 204 may hide the encryption salt used by the HKDF to derive the AES key.
In some embodiments, the server 204 may verify whether the client 202 is not compromised or malicious by implementing a secret sharing scheme, such as Shamir Secret Sharing (SSS). In such an embodiment, the server 204 generates a secret share (secret share) of secret data that is known only to the server 204. The server 204 includes the secret sharing portion into the special bucket of each tile such that for each query, the server 204 places the secret sharing portion into the special bucket of each tile. As described above, the secret sharing portion included in each bucket may vary on a per-query basis. Similar to how the client retrieves the special data corresponding to each filled query in step 242, the client 202 retrieves the secret sharing portion corresponding to each filled query. The client 202 attempts to reconstruct the secret data using the retrieved secret sharing portion and transmits the secret data to the server 204. After receiving the secret data, the server 204 compares the secret data received from the client 202 with the secret data that was originally known only to the server 204. If the two secret data do not match, the server 204 may conclude that the client 202 is compromised and/or malicious. The parameters of the secret sharing scheme should be selected in such a way that the client 202 can retrieve the encoded secret only when the client 202 honest queries the specific data as specified.
FIG. 6 is a block diagram of an example computer system 600 that may be used to perform the operations described above. The system 600 includes a processor 610, a memory 620, a storage device 630, and an input/output device 640. Each of the components 610, 620, 630, and 640 may be interconnected, for example, using a system bus 650. The processor 610 is capable of processing instructions for execution within the system 600. In some implementations, the processor 610 is a single-threaded processor. In another implementation, the processor 610 is a multi-threaded processor. The processor 610 is capable of processing instructions stored in the memory 620 or on the storage device 630.
The storage device 630 is capable of providing mass storage for the system 600. In some implementations, the storage device 630 is a computer-readable medium. In various different embodiments, storage device 630 may include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices over a network (e.g., a cloud storage device), or some other mass storage device.
Input/output device 640 provides input/output operations for system 600. In some embodiments, the input/output device 640 may include one or more of a network interface device (e.g., an ethernet card), a serial communication device (e.g., an RS-232 port), and/or a wireless interface device (e.g., an 802.11 card). In another embodiment, the input/output device may include a driver device configured to receive input data and send output data to external devices 560 (e.g., keyboard, printer, and display device). However, other embodiments may be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, and the like.
Although an example processing system has been described in FIG. 5, embodiments of the subject matter and functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on a computer storage medium (or media) for execution by, or to control the operation of, data processing apparatus. Alternatively or additionally, the program instructions may be encoded on a manually generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus. The computer storage medium may be or be included in a computer readable storage device, a computer readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Furthermore, while the computer storage medium is not a propagated signal, the computer storage medium may be a source or destination of computer program instructions encoded in an artificially generated propagated signal. Computer storage media may also be or be included in one or more separate physical components or media (e.g., a plurality of CDs, discs, or other storage devices).
The operations described in this specification may be implemented as operations performed by a data processing apparatus on data stored on one or more computer readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system-on-a-chip, or a combination of the foregoing. The apparatus may comprise a dedicated logic circuit, such as an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit). In addition to hardware, the apparatus may include code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment may implement a variety of different computing model infrastructures, such as web services, distributed computing, and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. The computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data. Typically, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, the computer need not have such a device. In addition, the computer may be embedded in another device, such as a mobile phone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), among others. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disk; CD-ROM and DVD-ROM discs. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other types of devices may also be used to provide for interaction with a user; for example, feedback provided to the user may be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form, including acoustic, speech, or tactile input. Further, the computer may interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on a user's client device in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include local area networks ("LANs") and wide area networks ("WANs"), interworking networks (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing system may include clients and servers. The client and server are typically remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data (e.g., HTML pages) to the client device (e.g., in order to display data to and receive user input from a user interacting with the client device). Data generated at the client device (e.g., results of the user interaction) may be received at the server from the client device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, although operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Furthermore, the processes depicted in the accompanying drawings do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In certain embodiments, multitasking and parallel processing may be advantageous.
Claims (20)
1. A method, comprising:
receiving, at a server device, a batch of queries from a client device, the batch of queries comprising queries for a special bucket in each of a plurality of database shards queried by the batch of queries, wherein the special bucket comprises a server-encrypted secret sharing portion generated by the server;
Generating, by the server device, a set of query results in response to the batch of queries, wherein the set of query results includes a secret sharing portion encrypted by the server obtained from the particular bucket queried by the batch of queries;
transmitting, by the server device, the query result set to the client device;
receiving, at the server device, a client encrypted secret sharing portion from the client device, wherein the client encrypted secret sharing portion is a client encrypted version of the secret sharing portion included in the set of query results transmitted to the client device;
transmitting, by the server device, a complete set of server-encrypted secret sharing portions to the client device, wherein the complete set of server-encrypted secret sharing portions includes more server-encrypted secret sharing portions than the set of query results;
receiving, at the server device, a complete set of client-server encrypted secret sharing portions from the client device, wherein the complete set of client-server encrypted secret sharing portions is a client encrypted version of the complete set of server encrypted secret sharing portions transmitted to the client device;
Determining, by the server device, how many of the secret sharing portions are included in both the client-encrypted secret sharing portion received from the client device and the complete set of client-server-encrypted secret sharing portions received from the client device; and
the client device is classified by the server device based on how many of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device.
2. The method of claim 1, further comprising:
removing, by the server device, server decryption from the complete set of client-server encrypted secret sharing portions received from the client device to obtain a complete set of client-encrypted secret sharing portions, wherein determining how many of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device comprises: the client encrypted secret sharing portion received from the client device is compared to the complete set of client encrypted secret sharing portions obtained by removing the server decryption from the complete set of client-server encrypted secret sharing portions.
3. The method of claim 2, wherein classifying the client device comprises: determining that the client device is malicious based on the comparison indicating that less than the required number of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-encrypted secret sharing portions obtained by removing the server decryption from the complete set of client-server encrypted secret sharing portions.
4. A method according to claim 3, further comprising:
receiving a client-encrypted set of entity identifiers from the client device;
encrypting, by the server, the client-encrypted set of entity identifiers to create a server-client encrypted set of identifiers;
transmitting, by the server, the server-client encrypted set of identifiers to the client device.
5. The method of claim 4, further comprising:
a partitioned database is generated in which the database is partitioned into the plurality of database shards, each database shard having a shard identifier that logically distinguishes each database shard from other database shards, and database entries in each database shard are partitioned into buckets having bucket identifiers that logically distinguish each bucket in the shard from other buckets in the shard.
6. The method of claim 5, further comprising:
adding a special bucket to each slice;
including in each special bucket special data that is known to the server device but not to the client device; and
after each query for a given tile, the special data in the special bucket of the given tile is updated to maintain the privacy of information contained in the special bucket of the given tile.
7. The method of claim 6, further comprising:
generating, by the client device, a query set using the server-client encrypted identifier set;
generating, by the client device, a set of decryption keys using the set of server-client encrypted identifiers;
encrypting, by the client device, the set of queries to create a batch of client-encrypted queries.
8. A system, comprising:
a database configured to store data; and
a server device configured to process queries using the database and execute instructions for causing the server device to perform operations comprising:
receiving a batch of queries from a client device, the batch of queries comprising queries for a special bucket in each of a plurality of database shards queried by the batch of queries, wherein the special bucket comprises a server-encrypted secret sharing portion generated by the server;
Generating a set of query results in response to the batch of queries, wherein the set of query results includes a secret sharing portion encrypted by the server obtained from the particular bucket queried by the batch of queries;
transmitting the query result set to the client device;
receiving, by the client device, a client encrypted secret sharing portion, wherein the client encrypted secret sharing portion is a client encrypted version of the secret sharing portion included in the set of query results transmitted to the client device;
transmitting a complete set of server-encrypted secret sharing portions to the client device, wherein the complete set of server-encrypted secret sharing portions includes more server-encrypted secret sharing portions than the set of query results;
receiving a complete client-server encrypted set of secret sharing portions from the client device, wherein the complete client-server encrypted set of secret sharing portions is a client encrypted version of the complete server encrypted set of secret sharing portions transmitted to the client device;
Determining how many of the secret sharing portions are included in both the client-encrypted secret sharing portion received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device; and
the client device is classified based on how many of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device.
9. The system of claim 8, wherein the instructions cause the server device to perform operations further comprising:
removing server decryption from the complete set of client-server encrypted secret sharing portions received from the client device to obtain a complete set of client-encrypted secret sharing portions, wherein determining how many of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device comprises: the client encrypted secret sharing portion received from the client device is compared to the complete set of client encrypted secret sharing portions obtained by removing the server decryption from the complete set of client-server encrypted secret sharing portions.
10. The system of claim 9, wherein classifying the client device comprises: determining that the client device is malicious based on the comparison indicating that less than the required number of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-encrypted secret sharing portions obtained by removing the server decryption from the complete set of client-server encrypted secret sharing portions.
11. The system of claim 10, wherein the instructions cause the server device to perform operations further comprising:
receiving a set of entity identifiers encrypted by a client;
encrypting the client-encrypted set of entity identifiers to create a server-client encrypted set of identifiers;
transmitting the server-client encrypted set of identifiers to the client device.
12. The system of claim 11, wherein the instructions cause one or more processors to perform operations comprising:
a partitioned database is generated in which the database is partitioned into the plurality of database shards, each database shard having a shard identifier that logically distinguishes each database shard from other database shards, and database entries in each database shard are partitioned into buckets having bucket identifiers that logically distinguish each bucket in the shard from other buckets in the shard.
13. The system of claim 12, wherein the instructions cause the one or more processors to perform operations comprising:
adding a special bucket to each slice;
including in each special bucket special data that is known to the server device but not to the client device; and
after each query for a given tile, the special data in the special bucket of the given tile is updated to maintain the privacy of information contained in the special bucket of the given tile.
14. The system of claim 13, wherein the client device is configured to perform operations comprising:
generating a set of queries using the server-client encrypted set of identifiers;
generating a set of decryption keys using the set of server-client encrypted identifiers;
the set of queries is encrypted to create a batch of client-encrypted queries.
15. A non-transitory computer-readable medium storing instructions that, when executed by one or more data processing apparatus, cause the one or more data processing apparatus to perform operations comprising:
Receiving a batch of queries from a client device, the batch of queries comprising queries for a special bucket in each of a plurality of database shards queried by the batch of queries, wherein the special bucket comprises a server-encrypted secret sharing portion generated by a server;
generating a set of query results in response to the batch of queries, wherein the set of query results includes a secret sharing portion encrypted by the server obtained from the particular bucket queried by the batch of queries;
transmitting the query result set to the client device;
receiving a client encrypted secret sharing portion from the client device, wherein the client encrypted secret sharing portion is a client encrypted version of the secret sharing portion included in the set of query results transmitted to the client device;
transmitting a complete set of server-encrypted secret sharing portions to the client device, wherein the complete set of server-encrypted secret sharing portions includes more server-encrypted secret sharing portions than the set of query results;
receiving a complete client-server encrypted set of secret sharing portions from the client device, wherein the complete client-server encrypted set of secret sharing portions is a client encrypted version of the complete server encrypted set of secret sharing portions transmitted to the client device;
Determining how many of the secret sharing portions are included in both the client-encrypted secret sharing portion received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device; and
the client device is classified based on how many of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device.
16. The non-transitory computer-readable medium of claim 15, wherein the instructions cause the one or more data processing apparatus to perform operations further comprising:
removing server decryption from the complete set of client-server encrypted secret sharing portions received from the client device to obtain a complete set of client-encrypted secret sharing portions, wherein determining how many of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-server encrypted secret sharing portions received from the client device comprises: the client encrypted secret sharing portion received from the client device is compared to the complete set of client encrypted secret sharing portions obtained by removing the server decryption from the complete set of client-server encrypted secret sharing portions.
17. The non-transitory computer-readable medium of claim 16, wherein classifying the client device comprises: determining that the client device is malicious based on the comparison indicating that less than the required number of the secret sharing portions are included in both the client-encrypted secret sharing portions received from the client device and the complete set of client-encrypted secret sharing portions obtained by removing the server decryption from the complete set of client-server encrypted secret sharing portions.
18. The non-transitory computer-readable medium of claim 17, wherein the instructions cause the one or more data processing apparatus to perform operations further comprising:
receiving a set of entity identifiers encrypted by a client;
encrypting the client-encrypted set of entity identifiers to create a server-client encrypted set of identifiers;
transmitting the server-client encrypted set of identifiers to the client device.
19. The non-transitory computer-readable medium of claim 18, wherein the instructions cause one or more data processing apparatus to perform operations comprising:
A partitioned database is generated in which the database is partitioned into the plurality of database shards, each database shard having a shard identifier that logically distinguishes each database shard from other database shards, and database entries in each database shard are partitioned into buckets having bucket identifiers that logically distinguish each bucket in the shard from other buckets in the shard.
20. The non-transitory computer-readable medium of claim 19, wherein the instructions cause the one or more data processing apparatus to perform operations comprising:
adding a special bucket to each slice;
including in each special bucket special data that is known to the server device but not to the client device; and
after each query for a given tile, the special data in the special bucket of the given tile is updated to maintain the privacy of information contained in the special bucket of the given tile.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163218120P | 2021-07-02 | 2021-07-02 | |
US63/218,120 | 2021-07-02 | ||
PCT/US2022/035965 WO2023278848A1 (en) | 2021-07-02 | 2022-07-01 | Encrypted information retrieval |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115997212A true CN115997212A (en) | 2023-04-21 |
Family
ID=82899105
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202280005729.0A Pending CN115997212A (en) | 2021-07-02 | 2022-07-01 | Encrypted information retrieval |
Country Status (4)
Country | Link |
---|---|
US (1) | US20230006813A1 (en) |
EP (1) | EP4185978A1 (en) |
CN (1) | CN115997212A (en) |
WO (1) | WO2023278848A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11449520B1 (en) * | 2021-10-14 | 2022-09-20 | Snowflake Inc. | Parallel fetching of query result data |
-
2022
- 2022-07-01 EP EP22754599.3A patent/EP4185978A1/en active Pending
- 2022-07-01 WO PCT/US2022/035965 patent/WO2023278848A1/en active Application Filing
- 2022-07-01 CN CN202280005729.0A patent/CN115997212A/en active Pending
- 2022-07-01 US US17/856,629 patent/US20230006813A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20230006813A1 (en) | 2023-01-05 |
WO2023278848A1 (en) | 2023-01-05 |
EP4185978A1 (en) | 2023-05-31 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP3058678B1 (en) | System and method for dynamic, non-interactive, and parallelizable searchable symmetric encryption | |
Yuan et al. | Secure cloud data deduplication with efficient re-encryption | |
Liu et al. | One-tag checker: Message-locked integrity auditing on encrypted cloud deduplication storage | |
US20240104234A1 (en) | Encrypted information retrieval | |
WO2018122287A1 (en) | Method and system for search pattern oblivious dynamic symmetric searchable encryption | |
CN112270006A (en) | Searchable encryption method for hiding search mode and access mode in e-commerce platform | |
Hoang et al. | A secure searchable encryption framework for privacy-critical cloud storage services | |
WO2019090841A1 (en) | Encrypted file retrieval method and system, terminal device and storage medium | |
EP4073673B1 (en) | Encrypted search with a public key | |
KR20120068524A (en) | Method and apparatus for providing data management | |
He et al. | Secure encrypted data deduplication based on data popularity | |
Wen et al. | BDO-SD: An efficient scheme for big data outsourcing with secure deduplication | |
KR20220092811A (en) | Method and device for storing encrypted data | |
Jiang et al. | An Efficient Symmetric Searchable Encryption Scheme for Cloud Storage. | |
Sun et al. | A dynamic and non-interactive boolean searchable symmetric encryption in multi-client setting | |
CN109783456B (en) | Duplication removing structure building method, duplication removing method, file retrieving method and duplication removing system | |
US20230006813A1 (en) | Encrypted information retrieval | |
Yan et al. | Secure and efficient big data deduplication in fog computing | |
CN108141462B (en) | Method and system for database query | |
EP4193290B1 (en) | Multi-key information retrieval | |
Zhang et al. | Secure deduplication based on Rabin fingerprinting over wireless sensing data in cloud computing | |
YueJuan et al. | A Searchable Ciphertext Retrieval Method Based on Counting Bloom Filter over Cloud Encrypted Data | |
Chen et al. | Searchable encryption system for big data storage | |
Bhavya et al. | EFUMS: Efficient File Upload and Mutli-Keyword Search over Encrypted Cloud Data | |
Shruthishree et al. | Secure Conjunctive Keyword Ranked Search over Encrypted Cloud Data |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |