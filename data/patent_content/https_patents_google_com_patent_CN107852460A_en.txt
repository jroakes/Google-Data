CN107852460A - Three-dimensional auto-focusing - Google Patents
Three-dimensional auto-focusing Download PDFInfo
- Publication number
- CN107852460A CN107852460A CN201680042155.9A CN201680042155A CN107852460A CN 107852460 A CN107852460 A CN 107852460A CN 201680042155 A CN201680042155 A CN 201680042155A CN 107852460 A CN107852460 A CN 107852460A
- Authority
- CN
- China
- Prior art keywords
- image
- image capturing
- capturing components
- scene
- parallax
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/67—Focus control based on electronic image sensor signals
- H04N23/676—Bracketing for image capture at varying focusing conditions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/50—Depth or shape recovery
- G06T7/55—Depth or shape recovery from multiple images
- G06T7/593—Depth or shape recovery from multiple images from stereo images
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/20—Image signal generators
- H04N13/204—Image signal generators using stereoscopic image cameras
- H04N13/239—Image signal generators using stereoscopic image cameras using two 2D image sensors having a relative position equal to or related to the interocular distance
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/20—Image signal generators
- H04N13/204—Image signal generators using stereoscopic image cameras
- H04N13/246—Calibration of cameras
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/20—Image signal generators
- H04N13/296—Synchronisation thereof; Control thereof
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/10—Image acquisition modality
- G06T2207/10004—Still image; Photographic image
- G06T2207/10012—Stereo images
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20228—Disparity calculation for image-based rendering
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N2013/0074—Stereoscopic image analysis
- H04N2013/0081—Depth or disparity estimation from stereoscopic image signals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/63—Control of cameras or camera modules by using electronic viewfinders
- H04N23/631—Graphical user interfaces [GUI] specially adapted for controlling image capture or setting capture parameters
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/67—Focus control based on electronic image sensor signals
- H04N23/673—Focus control based on electronic image sensor signals based on contrast or high frequency components of image signals, e.g. hill climbing method
Abstract
First image capturing components can catch the first image of scene, and the second image capturing components can catch the second image of scene.There may be a specific parallax range between first image capturing components and the second image capturing components, and at least one in the first image capturing components or the second image capturing components there can be focal length.Parallax between the part of the scene presented in a part for the scene that can determine to be presented in the first image and the second image.Possibly, focal distance can be determined based on the parallax, specific parallax range and focal length.First image capturing components and the second image capturing components can be set to focusing and arrive focal distance.
Description
Background technology
Digital camera have can focus lens, it can be used for catching the clear figure that can show details in scene exactly
Picture.These some magazine offer manual focus controls.But many cameras (such as wireless computing device (such as smart phone
And tablet personal computer) in camera) use auto-focusing (automatic focusing or AF) algorithm, must be directed to each field to mitigate user
Scape carries out the burden of manual focus to camera.
Existing Autofocus Technology catches image, estimates the definition of captured image, correspondingly adjustment focusing, catches
Another image, and so on.The process can repeat several iteration.Finally, most clearly image is stored and/or is shown to use
Family.As a result, auto-focusing process can spend the time, and during the time, scene may move, or in given current scene
In the case of definition can be difficult to estimate.
Stereoscopic camera (such as smart phone with two or more image capturing components) can catch multiple images simultaneously,
An image is caught by each image capturing components.Stereoscopic camera or display device can be then in some way by these
Image combines, to form or simulate three-dimensional (3D) stereo-picture.But it can not be performed well on stereoscopic camera existing
Autofocus Technology.In addition to the delay related to auto-focusing repeatedly, if each independent image capturing components is independently
Perform auto-focusing process, then each image capturing components can be formed can not be compatible focusing.As a result, stereo-picture can obscure not
Clearly.
The content of the invention
The embodiments herein discloses a kind of three-dimensional Autofocus Technology, and it can be used for allowing the multiple images capture unit of camera
Part rapid focus.The alternative manner of single camera auto-focusing is not used, this paper technology can be used for image with direct estimation
Catch the focal distance of part.As a result, each image capturing components can be focused at same distance, wherein being caught for image
Part is caught, focal distance is selected as forming rational picture rich in detail.Based on the focal distance, each image capturing components can
To catch an image, and these images can be used for being formed as stereo-picture.
Thus, in the first exemplary embodiment, the first image capturing components can catch the first image of scene, and
Two image capturing components can catch the second image of scene.Can between first image capturing components and the second image capturing components
A specific parallax range be present, and at least one in the first image capturing components or the second image capturing components can have
Focal length.The part of the scene presented in a part for the scene that can determine to be presented in the first image and the second image it
Between parallax.Possibly, the image capturing components of focusing first can be determined based on the parallax, specific parallax range and focal length
Focusing, which can be set to, with the second image capturing components arrives focal distance.It is focused the first image capturing portion of focal distance
Part can catch the 3rd image of scene, and the second image capturing components for being focused focal distance can catch the of scene
Four images.3rd image and the 4th image can be combined to form the stereo-picture of scene.
In the second exemplary embodiment, a kind of product can include non-emporary computer-readable medium, be stored thereon
Programmed instruction, it causes computing device to perform the operation according to first exemplary embodiment when being executed by a computing apparatus.
In the 3rd exemplary embodiment, computing device can include at least one processor and data storage and journey
Sequence instructs.Programmed instruction can be stored in data storage, and can to calculate when by least one computing device
Device performs the operation according to the first exemplary embodiment.
In the 4th exemplary embodiment, system can include being used for each operation for performing the first exemplary embodiment
Various devices.
By the detailed description after reading, and with reference to appended drawings it will be appreciated by those skilled in the art that these and its
His embodiment, aspect, advantage and replace.Further, it should be appreciated that provided herein is the content and other description and accompanying drawing mesh
Be that embodiment is only shown by example, and therefore, many changes may be present.For example, structural detail and process steps can be again
Arrangement, combination, distribution, cancellation otherwise change, and still in the range of claimed embodiment.
Brief description of the drawings
Figure 1A shows the front view and right view of the digital camera device according to exemplary embodiment.
Figure 1B shows the rearview of the digital camera device according to exemplary embodiment.
Fig. 2 shows the block diagram of the computing device with image capture capabilities according to exemplary embodiment.
Fig. 3 shows the three-dimensional imaging according to exemplary embodiment.
Fig. 4 shows the lens location of the image capturing components according to exemplary embodiment.
Fig. 5 is shown determines the distance between object and two cameras according to exemplary embodiment.
Fig. 6 shows the mapping between focal distance and focus value according to exemplary embodiment.
Fig. 7 is the flow chart according to exemplary embodiment.
Embodiment
Examples described herein methods, devices and systems.It should be understood that in word used herein " example " and " exemplary "
For referring to " being used as example, example or displaying ".As " example " or " exemplary " any embodiment as described herein
Or feature shall not necessarily be understood as being relative to other embodiment or feature more preferably or favorably.Using other embodiment, and can do
Go out other changes, without departing from the scope of theme given herein.
Thus, exemplary embodiment as described herein is not restricted.Many aspects of the present invention are (as generally herein
Description and be shown in the drawings) can be arranged, replace, combine, separate and design with a variety of configurations, own
These belong to concepts herein.
Further, describe unless the context otherwise, the feature shown in each figure can be used for being combined with each other.By
This, in terms of accompanying drawing should generally be considered as the composition of one or more overview embodiments, it should be appreciated that feature shown in not every
It is necessary for each embodiment.
In description herein, disclose and be related to single stereoscopic camera device with two image capturing components or each other
Two camera apparatus of co-ordination.But these implementations exemplify what is provided with exemplary purpose.The techniques described herein
It can apply to the stereoscopic camera device with two or more (such as four, eight etc.) image capturing components arrays.Enter one
Step ground, these technologies can also be applied to each two or more with one or more image capturing components it is three-dimensional or
Non-cubic camera.Moreover, in some embodiments, image processing step as described herein can be held by stereoscopic camera device
OK, and in other embodiments, image processing step can be by communicating (and perhaps to it with one or more camera apparatus
Be controlled) computing device perform.
Depending on context, " camera " can refer to single image capturing components or containing one or more picture catchings
The device of part.Generally, image capturing components include aperture, camera lens, recording surface and shutter, as described below.
1.Exemplary image capture device
As camera becomes to become more and more popular, they are used as independent hardware unit or are incorporated into other kinds of
In device.For example, photography video camera (still and video camera) is generally included in wireless computing device (example at present
Such as smart phone and tablet personal computer), notebook computer, video game interface (video game interface), family it is automatic
Makeup puts, even in automobile and other types carrier.
The image capturing components of camera can include one or more apertures (light passes through the aperture entrance), for catching
One or more recording surfaces of image representated by light and it is positioned in front of each aperture with by least a portion of image
One or more camera lenses of the focusing on recording surface (one or more).Aperture can be fixed dimension or adjustable.
In analogue camera, recording surface can be photographic film.In digital camera, recording surface can include electronic image and sense
Device (such as charge coupled device (CCD) or complementary metal oxide semiconductor (CMOS) sensor) is with the caught image of transmission
And/or the image caught is stored in data storage cell (such as memory).
One or more shutters can be connected to camera lens or recording surface or in its vicinity.Each shutter may be at hindering
It is in the light and reaches the closed position of recording surface or in the open position for allowing light to reach recording surface.The position of each shutter
It can be controlled by shutter release button.For example, shutter can give tacit consent to it is in the closed position.It is triggered (such as being pressed) in shutter release button
When, shutter can change to open position and after a period of time, referred to as shutter cycle (shutter from closed position
cycle).During the shutter cycle, image can be trapped on recording surface.In shutter end cycle, shutter can become
Return to closed position.
Alternatively, the shutter course of work can be by electronically realizing.For example, the electronics in ccd image sensor is fast
Before door " opening ", sensor can be reset to remove any residue signal in its photodiode.Protected in electronic shutter
When holding opening, photodiode can assemble electric charge.In shutter close or afterwards, these electric charges can be for transmission to long term data
Memory.The combination of both mechanically and electrically tripper can also be used.
Regardless of type, shutter can be activated and/or controlled by the something of not shutter release button.For example, shutter can
To be activated by soft key, timer or some other triggers.Herein, term " picture catching " can refer to it is any machinery and/
Or the electronic shutter course of work, it causes one or more images to be recorded, but regardless of the shutter course of work be how to trigger or
Control.
Catch the exposure of image (can be also referred to as by aperture scale, into the brightness and the length in shutter cycle of aperture
For shutter length or exposure length) combination determine.In addition, numeral and/or analog gain can apply to image, thus shadow
Ring exposure.
Photograph camera can catch one or more images when each picture catching is triggered.Video camera camera can be with
Specific speed (such as 24 images per second or frame) catches image, as long as picture catching keeps being triggered (such as in shutter
When button keeps pressing).Some digital photographing cameras can open shutter when camera apparatus or application are activated, and shutter can
To be maintained at the position until camera apparatus or application disable.When shutter is opened, camera apparatus or application can catch and show
Show that the scene on view finder is presented.When picture catching is triggered, one or more different digitals of current scene can be caught
Image.
Camera with more than one image capturing components can be referred to as stereoscopic camera.Stereoscopic camera can be simultaneously or several
Simultaneously two or more images are caught by each image capturing components.These images can be used for being formed as representing field
The 3D stereo-pictures of subject depth (depth of object) in scape.
Camera can include be used for control one or more camera functions and/or setting (such as aperture size, exposure when
Between, gain etc.) software.Image is carried out in addition, some cameras can be included in during or after these images are captured
The software of digital processing.
As it was previously stated, digital camera can be independent device or be integrated with other devices.As an example, Figure 1A is shown
The form factor (form factor) of digital camera device 100 from front view 101A and side view 101B.Digital camera
Device 100 for example can be mobile phone, tablet personal computer or wearable computing device.However, other embodiment is also feasible.
Digital camera device 100 can include various elements, such as body 102, Front camera 104, multicomponent display
106th, shutter release button 108 and other buttons 110.Front camera 104 can be positioned at generally being faced in operation for body 102
The side of user, or be positioned at and the identical side of multicomponent display 106.
As shown in Figure 1B, digital camera device 100 can further comprise rearmounted camera 112A and 112B.These cameras can be determined
Position is in the side opposite with Front camera 104 of body 102.Rearview 101C and 101D show rearmounted camera 112A and 112B
Two replacement arrangements.In both arrangements, camera is positioned in a plane, and fixed in x-axis or y-axis
Position is in same point.Nevertheless, other arrangements are also feasible.Further, by camera be referred to as it is preposition or it is rearmounted be appoint
Meaning, and digital camera device 100 can include the multiple cameras for each side for being positioned at body 102.
Multicomponent display 106 can represent cathode-ray tube (CRT) display, light emitting diode (LED) display, liquid crystal
(LCD) display of display, plasma display or any other type known in the art.In certain embodiments, it is more
Element display 106 can show the present image or logical by Front camera 104 and/or rearmounted camera 112A and 112B seizure
Cross these it is magazine any one or more can catch or nearest seizure image numeral expression.Thus, multicomponent
Display 106 may be used as the view finder for camera.Multicomponent display 106 can also support touch-screen and/or exist quick
Feel function (presence-sensitive function), it can adjust the setting of any aspect of digital camera device 100
And/or configuration.
Front camera 104 can include imaging sensor and related optical element, such as camera lens.Front camera 104 can
To provide zoom capabilities or can have fixed focal length.In other embodiments, replaceable camera lens can be used for Front camera 104.
Front camera 104 can have variable mechanical aperture and machinery and/or electronic shutter.Front camera 104 can also be configured
To catch still image, video image or both.Further, Front camera 104 can for example represent single picture (monoscopic)
Camera.
Rearmounted camera 112A and 112B may be arranged to stereogram (stereo pair).These cameras each can be with
It is different individually controllable image capturing components, including aperture, camera lens, recording surface and shutter.Digital camera device 100 can
To indicate that rearmounted camera 112A and 112B simultaneously catch the corresponding list of scene as image, and can be then single as figure using these
The combination of picture is to form the stereo-picture with depth.
Any or both in Front camera 104 and rearmounted camera 112A and 112B can include or be associated with offer light field
With the illuminace component being illuminated to destination object.For example, illuminace component can provide flash of light or the constant illumination to destination object.
Illuminace component, which is also configured to offer, to be included structure light, polarised light and has peculiar spectrum content (spectral
Content light).It is known and for from object recover 3D models other kinds of light field in the case of embodiment hereof
It is also possible.
One or more Front cameras 104 and/or rearmounted camera 112A and 112B can include or be associated with ambient light biography
Sensor, the ambient light sensor can continue or determine once in a while the ambient brightness of the seizable scene of camera.In some devices
In, ambient light sensor can be used for the display brightness for adjusting the screen (such as view finder) related to camera.It is determined that environment is bright
When degree is higher, the luminance level of screen can increase such that screen is easier to observe.When it is determined that ambient brightness is relatively low, screen
Luminance level can reduce, screen is easier to observe and can be saved electric power.Ambient light sensor can also be used
In it is determined that time for exposure for picture catching.
Digital camera device 100 can be configured with multicomponent display 106 and Front camera 104 or rearmounted camera
112A and 112B catches the image of destination object.The image of seizure can be multiple still image or video flowing.Picture catching
It can be triggered by activating shutter release button 108, the soft key on pressing multicomponent display 106 or by some other mechanisms.Depend on
In embodiment, image can be automatically captured with specific time interval, such as when pressing shutter release button 108, in target
During the appropriate illumination condition of object, plan when allowing digital camera device 100 to move preset distance, or according to predetermined catch.
As described above, the function of digital camera device 100 (or another type digital camera) can be integrated into calculating dress
In putting, such as wireless computing device, mobile phone, tablet personal computer, notebook computer etc..For exemplary purposes, Fig. 2 is display
The simplification block diagram of some parts of the exemplary computing devices 200 of camera components 224 can be included.
By example and without limitation, computing device 200 can be cellular mobile telephone (such as smart phone), photograph
Machine, video camera, facsimile machine, computer (such as desktop computer, notebook computer, tablet personal computer or HPC), individual number
Word assistant (PDA), home automation part, digital video recorder (DVR), DTV, remote controllers, wearable computing
Device or equipped with least some picture catchings and/or the device of some other types of image-capable.It should be understood that meter
Physics camera apparatus, such as digital camera, specific physical hardware platform can be represented (thereon with running software by calculating device 200
Camera applications) or be configured to perform camera function hardware and software other combination.
Deposited as shown in Fig. 2 computing device 200 can include communication interface 202, user interface 204, processor 206, data
Reservoir 208 and camera components 224, it is all these communicatedly to be connected by system bus, network or other bindiny mechanisms 210
Together.
Communication interface 202 can allow computing device 200 using analog or digital modulate and with other devices, access network
And/or transport network communication.Thus, communication interface 202 can aid in circuit switching and/or packet-switched communications, such as commonly
Telephone service (POTS) communicates and/or Internet Protocol (IP) or the communication of other packetizeds.For example, communication interface 202 can wrap
Chipset and antenna are included, it is disposed for and radio access network or access point radio communication.Further, communication interface 202
The form of wireline interface or more including wireline interface, such as Ethernet, USB (USB) or high-resolution can be taken
Media interface (HDMI) port.Communication interface 202 can also take the form of wave point or including wave point, such as
Wifi、Global positioning system (GPS) or wide area wireless interface (such as WiMAX or 3GPP are drilled for a long time
Enter technology (LTE)).However, it is possible in communication interface 202 using other forms physical layer interface and other types standard or
Proprietary communication protocol.And then communication interface 202 can include multiple physical communication interfaces (such as Wifi interfaces,Interface and wide area wireless interface).
User interface 204 can be used for allowing computing device 200 and people or inhuman user interaction, such as defeated from user's reception
Enter and provide a user output.Thus, user interface 204 can include input block, such as keypad, keyboard, touch sensitivity
Sensitive plate, computer mouse, trackball, rocking bar, microphone etc. be present in plate.User interface 204 can also include one or
Multiple output blocks, such as display screen, it can for example be combined with sensitive plate be present.Display screen can be based on CRT, LCD,
And/or LED technology or other technologies that are currently known or then developing.User interface 204 can be additionally configured to via raising one's voice
Device, speaker receptacle, audio output port, audio output device, earphone, and/or other similar installations produce sense of hearing output (one
It is individual or multiple).
In certain embodiments, user interface 204 can include display, and it is used for camera and/or video camera
The view finder of function (it is supported by computing device 200).In addition, user interface 204 can include one or more buttons, open
Pass, knob, and/or rotating disk, it contributes to the configuration of camera function and focusing and the seizure of image (such as catching picture).Can
It is capable, it is some or all of by sensitive plate implementation be present in these buttons, switch, knob and/or rotating disk.
Processor 206 can include one or more generally purpose processors (such as microprocessor) and/or one or more
Individual specific purposes processor (such as digital signal processor (DSP), graphics processing unit (GPU), FPU Float Point Unit (FPU),
Network processing unit or application specific integrated circuit (ASIC).In some cases, specific purposes processor can carry out image procossing, figure
As alignment (image alignment) and merge image, may also in the presence of other.Data storage 208 can include one or
Multiple volatile and/or non-volatile memory component, such as magnetic, optics, flash or organic memory, and can be whole or in part
It is integrated with processor 206.Data storage 208 can include detachable and/or non-dismountable part.
Processor 206 can perform be stored in data storage 208 programmed instruction 218 (such as compiling or decomplier
Programmed logic and/or machine code), to perform various functionality described herein.Therefore, data storage 208 can include
Non-emporary computer-readable medium, there is the programmed instruction being stored thereon, when being performed by computing device 200 so that calculate
Device 200 performs any method, process or the operation disclosed in this specification and/or accompanying drawing.Journey is performed by processor 206
Sequence instruction can cause processor 206 to use data 212.
By way of example, programmed instruction 218 can include (the example of operating system 222 being arranged on computing device 200
Such as operating system kernel, device driver (one or more), and/or other modules) and one or more application programs 220
(such as camera function, address book, Email, web browser, social networks, and/or game application).Similarly, data
212 can include operating system data 216 and application data 214.Operating system data 216 can be first by operating system 222
Access, and application data 214 can be accessed by one or more application programs 220 first.Application data 214 can be arranged in pair
For the user of computing device 200 in visible or hiding file system.
Application program 220 can be communicated by one or more programmatic interfaces (API) with operating system 222.These
API can for example contribute to application program 220 to read and/or write application data 214, transmit or connect via communication interface 202
Collect mail and cease, reception and/or display information, etc. on user interface 204.
In some popular expression, application program 220 is briefly termed as " app ".In addition, application program 220 can lead to
Cross one or more on-line Application memories or application market and be downloaded to computing device 200.However, application program can be with
Otherwise it is arranged on computing device 200, such as via web browser or passes through the physical interface on computing device 200
(such as USB port).
Camera components 224 can include but is not limited to aperture, shutter, recording surface, and (such as photographic film and/or image pass
Sensor), camera lens and/or shutter release button.Camera components 224 can be controlled by the software that processor 206 performs at least in part.
2.Exemplary stereo is imaged and auto-focusing
Fig. 3 shows the exemplary embodiment of three-dimensional imaging.In the figure, left camera 302 and right camera 304 catch scene
300 image.Scene 300 includes people in the foreground and cloud in the background.Left camera 302 and right camera 304 are with baseline distance
Separated from (baseline distance).
Each can include image capturing components for left camera 302 and right camera 304, such as corresponding aperture, camera lens, fast
Door and recording surface.In figure 3, left camera 302 and right camera 304 are shown as different physics cameras, still, for example, left
Camera 302 and right camera 304 can be the separated combination (separate of the image capturing components of same physics digital camera
set)。
Howsoever, left camera 302 and right camera 304 can catch left image 306 and right image 308 simultaneously respectively.This
Wen Zhong, this while picture catching can occur simultaneously, or are separated by number (such as 1,5,10 or 25) millisecond and occur.Due to a left side
The respective position of camera 302 and right camera 304, the people in the prospect of scene 300 seem in left image 306 slightly keep right and
Seem in right image 308 and slightly keep left.
Left image 306 and right image 308 can be in alignment with each other and the use that then combines, to form the vertical of scene 300
Body graphical representation.Image alignment can be related to for left image 306 and right image 308 to be arranged in above each other to cause them
The computational methods of " matching ".A kind of technology for image alignment is global alignment, wherein fixed x-axis and y-axis skew
Amount is applied to each pixel in an image so that the image and another image are substantially aligned.In this case
Substantially aligned (substantial alignment) can be that error factor between pixel is minimized or is determined to be below and faces
A kind of alignment of dividing value.For example, can be alignd for multiple candidates to calculate minimum variance, and missed with minimum least square
The alignment of difference can be determined that it is substantially aligned.
If however, an image is broken down into multiple m × n-pixel block, and each root tuber is according to respective offset quilt
Align respectively, then more preferable result generally can be achieved.Result is probably that some blocks are differently offset each other.For each of block
Individual candidate alignment, the net difference between all pixels in the original image that is translated and in target image is determined and asked
With.The net difference is stored, and the translation carried out by lowest difference may be selected, as substantially aligned.
In addition to image alignment technology as described herein or image alignment technology as described herein is replaced, it can be used
His image alignment technology.
In addition, various technologies can be used for forming stereo-picture expression from left image 306 and right image 308.Stereo-picture
Represent that 310 can be seen in the case where being with or without the auxiliary of 3D glasses.For example, left image 306 and right image 308 can be in screens
On overlap each other, and user can wear 3D glasses, and it can be filtered to overlapping image so that each eye of user is seen
Suitable view.Alternatively, screen quick (e.g., from about every 100 milliseconds) can be cut between left image 306 and right image 308
Change.This can form 3D effect, and 3D glasses are worn without user.
Fig. 4 shows that simplifying for the image capturing components for catching object images represents.Image capturing components include camera lens 402
With recording surface 404.The light of object 400 is represented by camera lens 402 and formed on recording surface 404 object 400 image (by
It is to turn upside down in the image appearance on the optical characteristics of camera lens 402, recording surface 404).Camera lens 402 can be it is adjustable,
Wherein it can be moved to the left or to the right relative to Fig. 4.For example, can (Fig. 4 be not by the motor of position to control camera lens 402
Show) apply voltage and realize adjustment.Motor can allow camera lens 402 to be moved further away from or close to recording surface 404.By
This, image capturing components can focus at a certain distance on scope focusing object.Point at any time, camera lens 402 and record sheet
The distance between face 404 is referred to as lens location, and generally in terms of millimeter.The distance between camera lens 402 and its focusing area quilt
Referred to as focal distance, and can be by millimeter or in terms of other unit.
Focal length is the intrinsic property of camera lens, and focal length is fixed if camera lens is not zoom lens.Lens location is
Refer to the distance between camera lens surface and recording surface.Lens location may be adjusted such that object seems that clear (focus is aligned
(in-focus)).In certain embodiments, lens location by focal length come approximate, if camera lens is actuated to focusing infinite
At a distance, then lens location is equal to focal length.Catching focal length for part accordingly, for non-zoom image is known and fixes,
And lens location is unknown but can be estimated so that image capturing components to be focused on object.
Auto-focusing is for not needing or assisting the method with regard to image capturing components can be allowed to focus with little need for user.
Auto-focusing can automatically select the region to be focused of scene, or can focus in the pre-selected areas of scene.Automatically
Focusing software can automatically adjust the lens location of image capturing components, until its determination image capturing components is fully and good
Focus on object on ground.
Exemplary Atomatic focusing method is as described below.But the example is only a kind of mode for realizing auto-focusing, and
Other technologies can be used.
In the auto-focusing based on contrast, the image on recording surface is through numerical analysis.Specifically, determine pixel it
Between luminance contrast (such as brightest pixel and difference least between the brightness of bright pixel).Generally, the contrast is higher, then schemes
As focusing is better.It is determined that after contrast, lens location is adjusted, and measures contrast again.The process is repeated until right
Than degree at least in a certain predetermined value.Once the predetermined value reaches, then the image of scene is captured and stored.
The defects of two kinds of differences be present in this kind of auto-focusing.First, auto-focusing algorithm can with some of iteration times (such as
Tens of or hundreds of milliseconds or longer), cause undesirable delay.During the iterative process, the object in scene can move.This
It can cause to continue the iteration longer time in the auto-focusing algorithm.Second, assess low luminosity scene or have the scene of luminous point
When, the auto-focusing (and other Autofocus Technologies) based on contrast can have inaccuracy.For example, attempting to catch secretly
During the image of the Christmas tree (having lamp thereon) in room, contrast meeting " interference " auto-focusing between lamp and room remainder
Algorithm, all it is acceptable focusing so as to cause substantially any lens location.Its reason is, according to based on contrast auto-focusing
Algorithm, it is clear enough to defocus the edge of spot light, and focus alignment is realized so as to will be considered that.
And then any camera apparatus of part is caught for stereoscopic camera or with multiple images, caught in each image
Catch and auto-focusing is operated independently from part can cause undesirable result.May be because image capturing components be relative to scene pair
As the possible hardware differences in slightly different position, and between image capturing components, each image capturing components
Eventually focus at different distance.Further, then because may even if an image capturing components are used for determining lens location
Hardware differences, same lens location can not use reliably by other image capturing components.
3.Exemplary non-iterative solid auto-focusing
The embodiments herein proposes to improve to Autofocus Technology.Specifically, open one kind estimates picture catching exactly
The non-iterative Autofocus Technology of distance between part and object.Then, using the portion for being mapped this distance with voltage
Part special table, appropriate voltage can be applied to the motor of each camera lens so that each image capturing components is focused in phase
Same focal distance, for picture catching.
The embodiments herein assumes that multiple images be present catches part, is the form of multiple cameras or the shape of single camera
Formula.In addition, in order to simple, the embodiments herein describes the three-dimensional auto-focusing for two image capturing components, but this
A little technologies can also be applied to the array of three or more image capturing components.
Triangulation based on the position of object in two image capturing components and scene can be used for estimation to be caught from image
Part is caught to the distance of object.Fig. 5 is gone to, left camera 302 and right camera 304 are assumed to be in x-axis the distance that is separated from each other
b.One of these cameras or both have focal length f (for the purpose of displaying, its position and size are exaggerated in Figure 5).Two
Camera has also aimed at the object with camera distance z in z-axis line.B and f value is known, but z value will be estimated
Meter.
The mode so done is that the image of object is caught at both left camera 302 and right camera 304.Such as Fig. 3
Shown in situation, object will seem in the image caught by left camera 302 slightly keeps right, and the image caught in right camera 304
In seem and slightly keep left.The x-axis distance between the object presented in catching image is parallax (disparity) d.
The first triangle MNO can be drawn between left camera 302, right camera 304 and object.Further, from point P (in this place
Object is appeared in the image caught by left camera 302) to point Q, (object appears in the figure by the seizure of right camera 304 in this place
As in) to point O it can draw the second triangle PQO.Parallax d can also be expressed as the distance between point P and point Q.
In form, triangle MNO and triangle PQO is similar triangle, and its all corresponding angle has identical
Measured value.As a result, they also have ratio of the identical width to height.Therefore：
B (z-f)=z (b-d) (2)
Bz-bf=bz-dz (3)
- bf=-dz (4)
By this way, the distance z from camera to object can be estimated directly.Only remaining parallax d is unknown.But the value be can
Based on the object images estimation caught by left camera 302 and right camera 304.
So far, the feature occurred in these images in each can be identified.This feature can be object (such as in Fig. 5
People) or can be different characteristic.Can be based on the pixel-shift (offset appeared between feature of two images in each
In pixels) estimate the parallax.
Alignment algorithm can be used for finding out the parallax.For example, contain at least a portion feature from one of two images
M × n-pixel block can match similarly sized block of pixels in another image.In other words, the algorithm can be directed to left figure
The best matching blocks in corresponding block search right image as in, or in turn can also.Various block sizes, such as 5 can be used
× 5,7 × 7,9 × 9,11 × 11,3 × 5,5 × 7, etc..
The search can be carried out along polar curve (epipolar line).In some cases, multiresolution method
(multiresolution approach) can be used for performing the search.As set forth above, it is possible to find out with least square error
Alignment.Alternatively, any alignment schemes that error measuring value is less than critical value can be used instead.
Once have found alignment, then the parallax is being in skew between the respective pixel of feature in two images
Pixel count., can be by only being scanned for along x-axis to simplify the alignment procedure in the case where two cameras align along x-axis.
Similarly, can be by only being scanned for along y-axis to simplify the alignment procedure if two cameras align along y-axis.
In replacement or extra embodiment, corner (or similar edge feature) in one of two images can be with
Match the same corner in another image.Such as Harris and Stephens technologies or from accelerate sectionalization test obtain feature
(FAST：Features from Accelerated Segment Test) corner detection algorithm as technology.Then, accordingly
Conversion (transform) between corner can be calculated as affine transformation (affine transform) or plane shock wave
(planar homography), such as use the random sampling uniformity for 8 algorithms of normalization and for Outlier Detection
Algorithm.The translational component of this conversion can be then extracted, and its size is the parallax.The technology can not schemed even
High quality estimation as providing parallax in the case of alignment, but also can be more expensive in terms of calculating compared with by image alignment.
Further, because camera is not focused correctly generally when starting, detection technique possible working effect in corner is poor, causes not
Blurred picture with the corner clearly limited.As a result, it may be desirable to which at least some regions progress to image is down-sampled
(downsampling) corner detection and on down-sampled region is performed.
Once distance z is known, then two (or more) it is magazine each can focus to the distance.But no
Same image capturing components can have different set, and they focus at specific distance according to the setting.Thus, to two phases
The same commands that machine provides can cause two camera focusings at different distance.
In order to solve the problem, the focal property of each group of image capturing components hardware can be mapped to by calibration
Determine the focus value (focal value) in scope.For purposes of example, 0-100 scope will be used herein.Thus,
Focus value is that, according to manufacturing tolerance, it sets the lens location in away from recording surface certain distance without unit integer value.With
Voltage or other mechanism can be further mapped in these values of specific image capturing components so that image capturing components can incite somebody to action
Its camera motion is to so that the lens location that image capturing components are focused at the distance.
Fig. 6 provides the exemplary map between 0-100 focus value and focal distance.Row 600 represent focal distance, row
602 represent the focus value for left camera, and row 604 represent the focus value for right camera.Each table of articles in mapping
Show the focus value that each camera can be set so that the focusing of these cameras is at given focal distance.For example, in order to allow two-phase
Machine is focused at 909 millimeters of distance, and the focus value for left camera can be set to 44 and the focus value of right camera can be set
It is set to 36.
As described above, the focus value for camera (such as one group of image capturing components), which represents hardware, specifies lens location.
Thus, each focus value can be related to specific voltage, such as camera lens is adjusted to realize the phase when being applied to camera lens
Hope the voltage of focal distance.In some cases, voltage setting will be applied to the specific power of camera lens, rather than position.Closed loop
Image capturing components can by can from their module (its with camera lens wherein and it is focused and still still had during exercise
Close) offer state renewal and support this feature.In other cases, the particular location of focus value setting camera lens, such as pass through volume
Code device determines.
In order to determine the association between focal distance, lens location and voltage, each group of image capturing components can be by school
It is accurate.For example, object can move, until its shape library at the lens location of each image capturing components, and for every
One lens location, the distance from image capturing components to object can be measured.Or in other words, object is located at away from image
Catch at member distance D, then focus value is adjusted until the image of object is clear enough.Focus value V is recorded, and is then found out
Mapping between distance D and focus value V.In order to obtain the mapping table between D and V, object can (distance be fallen according to diopter
Number) it is placed in there is mutually equidistant diverse location.
From the data, lens location can be designated the focus value in the range of 0-100.Any this calibration can be occurred with off line
(such as during camera manufactures or during three-dimensional auto-focusing software merit rating), and the mapping between focal distance and focus value
And the mapping between focus value and lens location can provide in the data file.
4.Exemplary operation
Fig. 7 is showing the flow chart of exemplary embodiment.Embodiment shown in Fig. 7 can be executed by a computing apparatus, such as
Digital camera device 100.However, the embodiment can be performed by other kinds of device or device subsystem.Further, the reality
Applying example can be with any aspect or combinations of features disclosed in this specification or accompanying drawing.
Fig. 7 segment 700 is related to the first image that scene is caught by the first image capturing components.Segment 702 can relate to
And the second image of scene is caught by the second image capturing components.First image capturing components and the second image capturing components are every
One can include respective aperture, camera lens and recording surface.
Further, there may be specific baseline distance between the first image capturing components and the second image capturing components
From.Further, at least one in the first image capturing components or the second image capturing components can have focal length.In some implementations
In example, the first image capturing components and the second image capturing components can be some parts of stereoscopic camera device.In other realities
Apply in example, the first image capturing components and the second image capturing components can be independent and different cameral device (it passes through at it
Between software and communication mode and co-ordination) some parts.First image capturing components and the second picture catching
Part can have identical or different picture catching resolution ratio.
Segment 704 can be related to the part of scene for determining to be presented in the first image and be presented in the second image
Parallax between the part of scene.
Segment 706, which can be related to, is possibly based on parallax, specific parallax range and focal length to determine focal distance.Focusing
From product that can be based on specific baseline and focal length divided by parallax.
Segment 708 can be related to is set as that focusing is arrived in focusing by the first image capturing components and the second image capturing components
From.Setting focusing, which can be related to the first image capturing components and the second image capturing components, sends the corresponding command to adjust them
Lens location so that these parts focusing arrive focal distance.
Although it is not shown, Fig. 7 embodiment can be further to by focusing to the first image of focal distance
The 3rd image that part catches scene is caught, and passes through focusing and catches the of scene to the second image capturing components of focal distance
Four images.3rd image and the 4th image can be combined to form and/or show the stereo-picture of scene.It is this vertical through display
Body image can require or can not require the use of 3D glasses to be observed.
In certain embodiments, it is determined that the part of the scene presented in the first image and being in the second image
Parallax between the part of existing scene is related to, and identifies in the second image of one m × n-pixel block and identification in the first image
Two m × n-pixel block.One m × n-pixel block or two m × n-pixel block can shift, until one m × n-pixel block and
Two m × n-pixel block substantial alignment.Parallax is based upon the pixel distance represented by this displacement.In some cases,
One m × n-pixel block or two m × n-pixel block displacement can be related to, by one m × n-pixel block or the only in x-axis
Two m × n-pixel block displacement.
Such as it is as described herein it is substantially aligned can be that error factor between block is minimized or is determined to be below critical
A kind of alignment of value.For example, can be alignd for multiple candidates to calculate minimum variance, and there is minimum least square error
Alignment can be determined that it is substantially aligned.
In certain embodiments, the part of scene can include the feature with corner.In these cases, is determined
Parallax between the part of the scene presented in the part of the scene presented in one image and the second image can relate to
And the corner in the first image of detection and the second image, and the first image or the second figure are made according to translation (translation)
As distortion (warp) arrives another so that the corner in the first image and the second image substantially matches.Parallax can be based on
Pass through the pixel distance of parallel transformation expressing.
In certain embodiments, focus value is the integer selected from the integer value of specific scope.Integer in specific scope
Value can be related to voltage respectively.These voltages can be with when being applied to the first image capturing components and the second image capturing components
So that the first image capturing components and the second image capturing components are about focused at the part of scene.The first image is set to catch
Catching part and the second image capturing components can be related to focusing to focal distance, and the voltage related to focal distance is applied to
First image capturing components and the second image capturing components each.
In certain embodiments, before the first image and the second image are captured, the first image capturing portion can be based on
The characteristic of part and the second image capturing components calibrates the respective associated between integer value and voltage in specific scope.
5.Conclusion
The present invention is not limited to specific embodiment described herein, and the purpose of embodiment is displaying various aspects.Can be with
Many modifications and changes are made in the case of without departing from the scope, those skilled in the art will be understood by.From foregoing
Description, it will be appreciated by those skilled in the art that except the function within the scope of the present invention cited herein in addition to those is first-class
Same method and structure.This modifications and changes should be fallen within the scope of the appended claims.
Refer to the attached drawing, detailed descriptions above have been described for the various features and function of disclosed system and method.Herein
Exemplary embodiment described and shown in the drawings is not restricted.Using other embodiment, and other can be made and changed
Become, without departing from the scope of theme given herein.It is readily appreciated that, generally described herein and of the invention one that is shown in figure
A little aspects can be all these to belong to concepts herein with various different configuration arrangement, replacement, combination, separation and designs.
For shown in figure and any or all message flow diagram, script and flow chart as described herein, each step,
Segment, and/or communication can represent information processing and/or the information transmission according to exemplary embodiment.Alternative embodiment also includes
In the range of these exemplary embodiments.For example, in these alternative embodiments, it is described as step, segment, transmission, logical
Letter, request, response, and/or message function can by shown in not or described order perform, including substantially simultaneously or with
Reverse order, this depends on involved function.Further, more or less segments and/or function can be used for being described herein
Any Ladder chart, script and flow chart, and these Ladder charts, script and flow chart can be combined partly or entirely each other.
Representative information processing the step of or segment may correspond to circuit, its can be configured as perform method described herein or
The specific logic function of technology.Alternately or additionally, the step of representative information is handled or segment may correspond to program code
Module, section or a part (including related data).Program code may include one or more instructions, its be executed by processor with
Specific logic function or action in implementation or technology.Program code and/or related data are storable in any types
Computer-readable medium on, such as include the storage device of disc, hard disk drive or other storage mediums.
Computer-readable medium may also include non-emporary computer-readable medium, such as the computer of short-term storage data can
Medium is read, such as register, processor cache and random access storage device (RAM).Computer-readable medium may also include non-momentary
Computer-readable medium, it can store program codes and/or data for a long time.Thus, computer-readable medium can include secondary
Or long-term storage, such as read-only storage (ROM), optical disc or disk, compact disc read-only memory (CD-ROM).It is computer-readable
Medium can also be any other volatile and nonvolatile storage system.Computer-readable medium can be considered as e.g. computer can
Read storage medium, or tangible memory.
Moreover, the software that the step of representing one or more information transmissions or segment may correspond in same physical unit
And/or the information transmission between hardware module.However, other information transmission can be the software module in different physical units
And/or between hardware module.
Specific configuration shown in the drawings should not be construed as limiting.It should be understood that in other embodiments, give institute in figure
Each element shown can become more or less.Further, some in shown element can be combined or omit.Further,
Exemplary embodiment may include the element not shown in figure.
In addition, any enumerate of element, segment or step in this specification or claim is in order to clear.Thus, this
Kind, which is enumerated, is not considered as requiring or implies that these elements, segment or step must be strictly according to concrete structures or with specific suitable
Sequence performs.
Although disclosed herein is various aspects and embodiment, other aspects and embodiment are to those skilled in the art
For be obvious.Open this paper various aspects and embodiment are used for the purpose shown rather than restricted, actual model
Enclose and spirit is provided by claim afterwards.
Claims (20)
1. a kind of method, including:
The first image of scene is caught by the first image capturing components of stereoscopic camera；
The second image of scene is caught by the second image capturing components of stereoscopic camera, wherein the first image capturing components and the
A specific parallax range, and wherein the first image capturing components or the second image capturing components between two image capturing components be present
In at least one there is focal length；
Between the part of the scene presented in a part for the scene for determining to be presented in the first image and the second image
Parallax；
Focal distance is determined based on parallax, specific parallax range and focal length；With
The first image capturing components and the second image capturing components are set, the focal distance is arrived with focusing.
2. the method as described in claim 1, including：
The 3rd image of scene is caught by the first image capturing components focused to focal distance；
The 4th image of scene is caught by the second image capturing components focused to focal distance；With
The stereo-picture of scene is formed using the combination of the 3rd image and the 4th image.
3. the method as described in claim 1, wherein determining the part of scene and the second image presented in the first image
Parallax between the part of middle presented scene includes：
Identify one m × n-pixel block in the first image；
Identify two m × n-pixel block in the second image；With
One m × n-pixel block or two m × n-pixel block are shifted, until one m × n-pixel block and two m × n-pixel block base
Alignd on this, wherein parallax is based upon the pixel distance that displacement represents.
4. method as claimed in claim 3, wherein one m × n-pixel block or two m × n-pixel block displacement are included only in x
One m × n-pixel block or two m × n-pixel block are shifted on axis.
5. the method as described in claim 1, the part of its Scene includes the feature with corner, and wherein determines first
Parallax between the part of the scene presented in the part of the scene presented in image and the second image includes：
Detect the corner in the first image and the second image；With
First image or the second scalloping are arrived by another according to translation so that the corner base in the first image and the second image
Matched on this, wherein parallax is based on the represented pixel distance of translation.
6. the method as described in claim 1, wherein the first image capturing components and the second image capturing components have it is different
Image catches resolution ratio.
7. the product of the method as described in claim 1, wherein focal distance based on specific baseline and focal length divided by parallax.
8. the method as described in claim 1, wherein focus value are from the integer value of the integer value selection of specific scope, wherein should
Integer value in specific scope is related to voltage respectively, and wherein voltage is being applied to the first image capturing components and the second image
When catching part the first image capturing components and the second image capturing components are about focused at the part of scene.
9. method as claimed in claim 8, wherein setting the first image capturing components and the second image capturing components to focus
Include to focal distance, the voltage related to focal distance is applied to the first image capturing components and the second image capturing components
Each.
10. method as claimed in claim 8, further comprises:
Before the first image and the second image is caught, the characteristic based on the first image capturing components and the second image capturing components
To calibrate the respective associated between integer value and voltage in specific scope.
11. the method as described in claim 1, wherein the first image capturing components and the second image capturing components each include
Respective aperture, camera lens and recording surface.
12. a kind of product, including non-emporary computer-readable medium, there is the programmed instruction stored thereon, the programmed instruction
Computing device is caused to perform operation when being executed by a computing apparatus, including：
The first image of scene is caught by the first image capturing components；
The second image of scene is caught by the second image capturing components, wherein the first image capturing components and the second picture catching
A specific parallax range between part be present, and at least one in wherein the first image capturing components or the second image capturing components
It is individual that there is focal length；
Between the part of the scene presented in a part for the scene for determining to be presented in the first image and the second image
Parallax；
Focal distance is determined based on the parallax, specific parallax range and focal length；With
The first image capturing components and the second image capturing components are set to focus to the focal distance.
13. product as claimed in claim 12, wherein operation further comprises：
The 3rd image of scene is caught by the first image capturing components focused to focal distance；
The 4th image of scene is caught by the second image capturing components focused to focal distance；With
The 3rd image and the 4th image are combined to form the stereo-picture of scene.
14. product as claimed in claim 12, wherein determining the part of scene and the second figure presented in the first image
Parallax between the part of the scene presented as in includes：
Identify one m × n-pixel block in the first image；
Identify two m × n-pixel block in the second image；With
One m × n-pixel block or two m × n-pixel block are shifted, until one m × n-pixel block and two m × n-pixel block base
Alignd on this, wherein parallax is based upon the pixel distance that displacement represents.
15. product as claimed in claim 12, the part of its Scene includes the feature with corner, and wherein determines the
Parallax between the part of the scene presented in the part of the scene presented in one image and the second image includes：
Detect the corner in the first image and the second image；With
First image or the second scalloping are arrived by another according to translation so that the corner base in the first image and the second image
Matched on this, wherein parallax is based on the represented pixel distance of translation.
16. the product of product as claimed in claim 12, wherein focal distance based on specific baseline and focal length divided by parallax.
17. product as claimed in claim 12, wherein focus value are from the integer value of the integer value selection of specific scope, wherein
Integer value in the specific scope is related to voltage respectively, and wherein voltage is being applied to the first image capturing components and the second figure
As causing the first image capturing components and the second image capturing components about to focus at the part of scene when catching part.
18. product as claimed in claim 17, wherein setting the first image capturing components and the second image capturing components with right
Jiao includes to focal distance, and the voltage related to focal distance is applied into the first image capturing components and the second image capturing portion
Part each.
19. product as claimed in claim 12, wherein operation further comprises：
Before the first image and the second image is caught, the characteristic based on the first image capturing components and the second image capturing components
To calibrate the respective associated between integer value and voltage in specific scope.
20. a kind of computing device, including：
First image capturing components；
Second image capturing components；
At least one processor；
Memory；With
Programmed instruction, memory is stored in, it causes computing device to perform operation when by least one computing device, bag
Include：
The first image of scene is caught by the first image capturing components；
The second image of scene is caught by the second image capturing components, wherein image capturing components and the second image capturing portion
A specific parallax range between part be present, and it is at least one in wherein the first image capturing components or the second image capturing components
With focal length；
Between the part of the scene presented in a part for the scene for determining to be presented in the first image and the second image
Parallax；
Focal distance is determined based on the parallax, specific parallax range and focal length；With
The first image capturing components and the second image capturing components are set to focus to the focal distance.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/965,575 US20170171456A1 (en) | 2015-12-10 | 2015-12-10 | Stereo Autofocus |
US14/965,575 | 2015-12-10 | ||
PCT/US2016/048021 WO2017099854A1 (en) | 2015-12-10 | 2016-08-22 | Stereo autofocus |
Publications (1)
Publication Number | Publication Date |
---|---|
CN107852460A true CN107852460A (en) | 2018-03-27 |
Family
ID=56843060
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680042155.9A Pending CN107852460A (en) | 2015-12-10 | 2016-08-22 | Three-dimensional auto-focusing |
Country Status (6)
Country | Link |
---|---|
US (1) | US20170171456A1 (en) |
EP (1) | EP3292689A1 (en) |
JP (1) | JP2018528631A (en) |
KR (1) | KR20180008588A (en) |
CN (1) | CN107852460A (en) |
WO (1) | WO2017099854A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110913143A (en) * | 2019-12-09 | 2020-03-24 | Oppo广东移动通信有限公司 | Image processing method, image processing device, storage medium and electronic equipment |
CN111814659A (en) * | 2020-07-07 | 2020-10-23 | 杭州海康威视数字技术股份有限公司 | Living body detection method and system |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10187623B2 (en) * | 2014-12-26 | 2019-01-22 | Korea Electronics Technology Institute | Stereo vision SoC and processing method thereof |
CN107172410A (en) * | 2017-07-14 | 2017-09-15 | 闻泰通讯股份有限公司 | Dual camera focusing method and device |
US11218626B2 (en) * | 2017-07-28 | 2022-01-04 | Black Sesame International Holding Limited | Fast focus using dual cameras |
WO2019029934A1 (en) * | 2017-08-11 | 2019-02-14 | Brainlab Ag | Video based patient registration and tracking |
AU2019205949A1 (en) * | 2018-01-07 | 2020-07-16 | Ocula Corporation | Digital-optical object tracker |
JP2019168479A (en) * | 2018-03-22 | 2019-10-03 | キヤノン株式会社 | Controller, imaging device, method for control, program, and, and storage medium |
JP7271653B2 (en) * | 2018-08-08 | 2023-05-11 | グーグル エルエルシー | Optical Image Stabilization Operation to Generate a Super-Resolved Image of a Scene |
US11381729B1 (en) | 2021-01-08 | 2022-07-05 | Hand Held Products, Inc. | Systems, methods, and apparatuses for focus selection using image disparity |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN102740095A (en) * | 2011-04-08 | 2012-10-17 | 索尼公司 | Analysis of 3d video |
TW201300930A (en) * | 2011-06-24 | 2013-01-01 | Mstar Semiconductor Inc | Auto focusing method and apparatus |
US20140307054A1 (en) * | 2013-04-11 | 2014-10-16 | Altek Semiconductor Corp. | Auto focus method and auto focus apparatus |
Family Cites Families (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070165942A1 (en) * | 2006-01-18 | 2007-07-19 | Eastman Kodak Company | Method for rectifying stereoscopic display systems |
JP2007263657A (en) * | 2006-03-28 | 2007-10-11 | Denso It Laboratory Inc | Three-dimensional coordinates acquisition system |
JP5147500B2 (en) * | 2007-08-03 | 2013-02-20 | キヤノン株式会社 | Imaging apparatus and control method thereof |
WO2010116300A1 (en) * | 2009-04-08 | 2010-10-14 | Koninklijke Philips Electronics N. V. | Oled device with aesthetical appearance |
WO2011013175A1 (en) * | 2009-07-31 | 2011-02-03 | 株式会社 東芝 | 3d display apparatus and 3d display system |
JP5440927B2 (en) * | 2009-10-19 | 2014-03-12 | 株式会社リコー | Distance camera device |
JP5637995B2 (en) * | 2009-10-30 | 2014-12-10 | 株式会社オプトエレクトロニクス | Optical information reader |
US8390369B2 (en) * | 2010-08-05 | 2013-03-05 | Freescale Semiconductor, Inc. | Electronic circuit and method for operating a module in a functional mode and in an idle mode |
US9395546B2 (en) * | 2010-10-29 | 2016-07-19 | Lg Electronics Inc. | Stereoscopic image processing system and device and glasses |
US8274552B2 (en) * | 2010-12-27 | 2012-09-25 | 3Dmedia Corporation | Primary and auxiliary image capture devices for image processing and related methods |
JP5252023B2 (en) * | 2011-03-30 | 2013-07-31 | カシオ計算機株式会社 | Code reader and program |
US9007441B2 (en) * | 2011-08-04 | 2015-04-14 | Semiconductor Components Industries, Llc | Method of depth-based imaging using an automatic trilateral filter for 3D stereo imagers |
US9560334B2 (en) * | 2011-09-08 | 2017-01-31 | Qualcomm Incorporated | Methods and apparatus for improved cropping of a stereoscopic image pair |
TWI528833B (en) * | 2011-11-09 | 2016-04-01 | 鴻海精密工業股份有限公司 | 3d imaging device |
US9172939B2 (en) * | 2011-12-30 | 2015-10-27 | Stmicroelectronics (Canada), Inc. | System and method for adjusting perceived depth of stereoscopic images |
JP5943693B2 (en) * | 2012-04-24 | 2016-07-05 | キヤノン株式会社 | Imaging device, control method thereof, and control program |
EP2902960A4 (en) * | 2012-09-27 | 2015-09-23 | Panasonic Ip Man Co Ltd | Stereo image processing device and stereo image processing method |
JP2015010948A (en) * | 2013-06-28 | 2015-01-19 | キヤノン株式会社 | Article processing device, generation method, and program |
US9703175B2 (en) * | 2015-07-02 | 2017-07-11 | Qualcomm Incorporated | Systems and methods for autofocus trigger |
US9661298B2 (en) * | 2015-08-06 | 2017-05-23 | Intel Corporation | Depth image enhancement for hardware generated depth images |
-
2015
- 2015-12-10 US US14/965,575 patent/US20170171456A1/en not_active Abandoned
-
2016
- 2016-08-22 JP JP2017562268A patent/JP2018528631A/en active Pending
- 2016-08-22 EP EP16758053.9A patent/EP3292689A1/en not_active Withdrawn
- 2016-08-22 CN CN201680042155.9A patent/CN107852460A/en active Pending
- 2016-08-22 WO PCT/US2016/048021 patent/WO2017099854A1/en unknown
- 2016-08-22 KR KR1020177035811A patent/KR20180008588A/en not_active Application Discontinuation
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN102740095A (en) * | 2011-04-08 | 2012-10-17 | 索尼公司 | Analysis of 3d video |
TW201300930A (en) * | 2011-06-24 | 2013-01-01 | Mstar Semiconductor Inc | Auto focusing method and apparatus |
US20140307054A1 (en) * | 2013-04-11 | 2014-10-16 | Altek Semiconductor Corp. | Auto focus method and auto focus apparatus |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110913143A (en) * | 2019-12-09 | 2020-03-24 | Oppo广东移动通信有限公司 | Image processing method, image processing device, storage medium and electronic equipment |
CN111814659A (en) * | 2020-07-07 | 2020-10-23 | 杭州海康威视数字技术股份有限公司 | Living body detection method and system |
CN111814659B (en) * | 2020-07-07 | 2024-03-29 | 杭州海康威视数字技术股份有限公司 | Living body detection method and system |
Also Published As
Publication number | Publication date |
---|---|
US20170171456A1 (en) | 2017-06-15 |
JP2018528631A (en) | 2018-09-27 |
EP3292689A1 (en) | 2018-03-14 |
WO2017099854A1 (en) | 2017-06-15 |
KR20180008588A (en) | 2018-01-24 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107852460A (en) | Three-dimensional auto-focusing | |
JP7186672B2 (en) | System and method for multiscopic noise reduction and high dynamic range | |
US9179070B2 (en) | Method for adjusting focus position and electronic apparatus | |
US9544574B2 (en) | Selecting camera pairs for stereoscopic imaging | |
KR101345012B1 (en) | Two-dimensional polynomial model for depth estimation based on two-picture matching | |
US11570376B2 (en) | All-in-focus implementation | |
US8379105B2 (en) | Methods and apparatus for full-resolution light-field capture and rendering | |
CN107950018B (en) | Image generation method and system, and computer readable medium | |
KR20190052031A (en) | How to use wide-angle image capturing elements and long-focus image capturing elements to achieve a sharp and accurate zooming mechanism | |
WO2016168783A1 (en) | Methods and apparatus for filtering image data to reduce noise and/or generating an image | |
US20140002606A1 (en) | Enhanced image processing with lens motion | |
CN109922255A (en) | For generating the dual camera systems of real-time deep figure | |
CN108024053A (en) | Camera device, focus adjusting method and recording medium | |
CN104253939A (en) | Focusing position adjusting method and electronic device | |
EP3395059A1 (en) | Method and apparatus for computational scheimpflug camera | |
CN105306921A (en) | Three-dimensional photo shooting method based on mobile terminal and mobile terminal | |
US20160292842A1 (en) | Method and Apparatus for Enhanced Digital Imaging | |
KR20130053040A (en) | Photographing appratus and photographing method | |
KR20160123757A (en) | Image photographig apparatus and image photographing metheod | |
JP5972485B2 (en) | Image processing apparatus, imaging apparatus, image processing method, and image processing program | |
WO2014191613A1 (en) | Light field imaging | |
Baek et al. | Mirrorless interchangeable-lens light field digital photography camera system | |
WO2015044514A1 (en) | Method and apparatus for plenoptic imaging |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
WD01 | Invention patent application deemed withdrawn after publication | ||
WD01 | Invention patent application deemed withdrawn after publication |
Application publication date: 20180327 |