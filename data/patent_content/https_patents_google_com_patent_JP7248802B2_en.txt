JP7248802B2 - Rendering video with dynamic components - Google Patents
Rendering video with dynamic components Download PDFInfo
- Publication number
- JP7248802B2 JP7248802B2 JP2021539667A JP2021539667A JP7248802B2 JP 7248802 B2 JP7248802 B2 JP 7248802B2 JP 2021539667 A JP2021539667 A JP 2021539667A JP 2021539667 A JP2021539667 A JP 2021539667A JP 7248802 B2 JP7248802 B2 JP 7248802B2
- Authority
- JP
- Japan
- Prior art keywords
- layers
- dynamic
- video
- rendering
- static
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/957—Browsing optimisation, e.g. caching or content distillation
- G06F16/9577—Optimising the visualization of content, e.g. distillation of HTML documents
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/44012—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving rendering scenes according to scene graphs, e.g. MPEG-4 scene graphs
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/431—Generation of visual interfaces for content selection or interaction; Content or additional data rendering
- H04N21/4318—Generation of visual interfaces for content selection or interaction; Content or additional data rendering by altering the content in the rendering process, e.g. blanking, blurring or masking an image region
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T15/00—3D [Three Dimensional] image rendering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T5/00—Image enhancement or restoration
- G06T5/50—Image enhancement or restoration by the use of more than one image, e.g. averaging, subtraction
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/90—Determination of colour characteristics
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/10—Protocols in which an application is distributed across nodes in the network
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/53—Network services using third party service providers
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/23424—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving splicing one content stream with another content stream, e.g. for inserting or substituting an advertisement
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/2343—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements
- H04N21/234327—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements by decomposing into layers, e.g. base layer and one or more enhancement layers
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/81—Monomedia components thereof
- H04N21/8166—Monomedia components thereof involving executable data, e.g. software
- H04N21/8173—End-user applications, e.g. Web browser, game
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/854—Content authoring
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/222—Studio circuitry; Studio devices; Studio equipment
- H04N5/262—Studio circuits, e.g. for mixing, switching-over, change of character of image, other special effects ; Cameras specially adapted for the electronic generation of special effects
- H04N5/278—Subtitling
Description
本文献は、動的コンポーネントを有するビデオの効率的なレンダリングのための方法に関する。 This document relates to a method for efficient rendering of videos with dynamic components.
一般に、本明細書において説明する本主題の革新的な一態様は、動的コンポーネントを有するビデオの効率的なレンダリングのための方法として具現化することができる。方法は、1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを含む、ビデオをレンダリングするためのファイルを識別することと、ビデオをレンダリングするためのファイルの1つまたは複数のフィールドの解析に基づいて、1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを検出することであって、各動的レイヤが、可変コンポーネントであることを示すコメントを含む、検出することと、ファイルの1つまたは複数の静的レイヤをレンダリングすることと、ユーザデバイスから、ユーザ情報を含む、ビデオを求める要求を受信することと、ユーザ情報に基づいて、動的レイヤに挿入されるように指定された変数定義を決定することと、1つまたは複数の動的レイヤを、変数定義を使用してレンダリングすることと、レンダリングされた1つまたは複数の静的レイヤおよびレンダリングされた1つまたは複数の動的レイヤから、再生用の合成ビデオ(composite video)を生成することとを含むことができる。 In general, one innovative aspect of the present subject matter described herein can be embodied as a method for efficient rendering of videos with dynamic components. A method includes identifying a file for rendering a video containing one or more static layers and one or more dynamic layers, and one or more fields of the file for rendering the video. detecting one or more static layers and one or more dynamic layers, each dynamic layer including a comment indicating that it is a variable component, based on an analysis of rendering one or more static layers of the file; receiving a request from a user device for a video that includes user information; Rendering one or more dynamic layers using the variable definitions; Rendering one or more static layers and rendering and generating a composite video for playback from one or more dynamic layers.
上記および他の実施形態はそれぞれ、任意選択で、以下の特徴のうちの1つまたは複数を含むことができる。 Each of the above and other embodiments can optionally include one or more of the following features.
いくつかの実装形態では、方法は、深さ優先走査アルゴリズムを使用して、ビデオをレンダリングするためのファイルのドキュメントオブジェクトモデルをフラット化することを含む。方法は、レンダリングされた1つまたは複数の静的レイヤに基づいて、1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを示すテンプレートを生成することを含むことができる。1つまたは複数の動的レイヤを、変数定義を使用してレンダリングすることは、変数定義を使用してテンプレートを埋めることを含むことができる。 In some implementations, a method includes flattening a document object model of a file for rendering a video using a depth-first scanning algorithm. The method can include generating a template indicative of the one or more static layers and the one or more dynamic layers based on the rendered one or more static layers. Rendering one or more dynamic layers using the variable definitions can include filling a template with the variable definitions.
いくつかの実装形態では、ファイルが1つまたは複数のフレームを含み、ファイルの1つまたは複数の静的レイヤをレンダリングすることが、1つまたは複数の静的レイヤの各レイヤについて、各フレームの画像を保存することを含む。 In some implementations, a file contains one or more frames, and rendering one or more static layers of the file may be performed by rendering Including saving images.
いくつかの実装形態では、レンダリングされた1つまたは複数の静的レイヤおよびレンダリングされた1つまたは複数の動的レイヤから、再生用の合成ビデオを生成することが、アルファブレンディング操作を実施して、レンダリングされた1つまたは複数の静的レイヤとレンダリングされた1つまたは複数の動的レイヤを組み合わせることを含む。 In some implementations, generating a composite video for playback from one or more rendered static layers and one or more rendered dynamic layers performs an alpha blending operation. , including combining one or more rendered static layers with one or more rendered dynamic layers.
いくつかの実装形態では、1つまたは複数の動的レイヤのうちの少なくとも1つが、ロゴを表す画像、テキスト、ビデオ、および色のうちの少なくとも1つを含む。 In some implementations, at least one of the one or more dynamic layers includes at least one of an image representing a logo, text, video, and color.
本態様の他の実施形態は、対応するシステムと、装置と、方法のアクションを実施するように構成され、コンピュータ記憶デバイス上に符号化された、コンピュータプログラムとを含むことができる。 Other embodiments of this aspect may include corresponding systems, apparatus, and computer programs encoded on computer storage devices configured to perform the actions of the methods.
本文献において説明する本主題の特定の実施形態は、以下の利点のうちの1つまたは複数を実現するように実装することができる。ある特定の環境においては、要求時に、ユーザエクスペリエンスが変わらないように予測可能なまたは一定の時間で、ビデオデザインをカスタマイズしユーザへの提示のためにレンダリングできるようにデザインを動的に変更する方途がこれまでなかった。その欠点が、本明細書において論じる技法、デバイス、およびシステムによって対処される。本文献において説明する技法により、システムが、比較的少ないリソースを使用し、比較的少ない動作を実施して、さまざまな使用事例の中でもとりわけ、特定のアプリケーション、ユーザ、製品、またはサービスに関連のある、カスタマイズされたビデオを生成することが可能になる。 Particular embodiments of the present subject matter described in this document can be implemented to achieve one or more of the following advantages. How to dynamically change a video design so that it can be customized and rendered for presentation to the user, on demand, in a predictable or constant amount of time in a given environment so that the user experience does not change. never before. That shortcoming is addressed by the techniques, devices, and systems discussed herein. The techniques described in this document allow the system to use relatively few resources, perform relatively few operations, and be relevant to particular applications, users, products, or services, among other use cases. , making it possible to generate customized videos.
一般に、ビデオ合成プログラムのレンダリング時間は、レンダリングされているビデオプロジェクトの複雑さに応じて決まる。ビデオの編集および合成のための既存の解決策では、ビデオプロジェクトの一部分に対して変更を加えるために、ビデオプロジェクト全体が完全に再レンダリングされる必要がある。これらの解決策はしばしば、時間およびリソースを多用し、また要求時に、要求者が編集されたビデオを受信する以前に顕著な遅延を被らずには実施することができない。 In general, the rendering time of a video compositing program depends on the complexity of the video project being rendered. Existing solutions for video editing and compositing require that the entire video project be completely re-rendered in order to make changes to a portion of the video project. These solutions are often time and resource intensive and cannot be implemented without incurring significant delays before the requester receives the edited video when requested.
この新たなシステムは、グラフィックの複雑さとは無関係に、一定のレンダリング時間をサポートすることができる。換言すれば、システムは、グラフィックの複雑さに関わらず、O(1)時間で、ビデオを動的に変更しレンダリングすることができる。システムは、例えば、レイヤのグループを画像または静的レイヤの系列として保存することができる。システムは、動的レイヤとして示されたレイヤを検出すると、例えば、そのレイヤの構造および他のレイヤに対するその位置を示す命令データを画像の代わりに保存することができる。保存された命令データは、動的レイヤを形成するために使用される。動的レイヤは、静的レイヤとともに適所に保存され得る。静的レイヤは画像として保存されているので、最終レンダリング時に必要となるコンピュータ計算作業の大部分は、静的と動的の両方のレイヤを単一画像に、正しいz深度順に合成または組み合わせることである。この新たなシステムは、合成の実施に合わせて最適化されており、したがって、グラフィックの複雑さに関わらず、予測可能なまたは一定の時間で、動的レイヤの動的要素を更新し最終レンダリングを実施することが可能である。 This new system can support constant rendering times regardless of graphics complexity. In other words, the system can dynamically change and render videos in O(1) time regardless of the complexity of the graphics. The system can, for example, store groups of layers as images or sequences of static layers. When the system detects a layer that is designated as a dynamic layer, it can, for example, save instructional data indicating the layer's structure and its position relative to other layers in place of the image. The stored instruction data is used to form dynamic layers. Dynamic layers can be saved in place with static layers. Since static layers are stored as images, most of the computational effort required during final rendering is to composite or combine both static and dynamic layers into a single image in correct z-depth order. be. This new system is optimized for performing compositing, thus updating dynamic elements in dynamic layers and delivering final renders in predictable or constant time, regardless of the complexity of the graphics. It is possible to implement.
システムは、実行時に最小のコンピュータ計算を用いて、カスタマイズされたビデオが配信されることを可能にする、効率的な解決策を提供し、というのも、ビデオを求める要求の受信の際に必要となる動作の複雑さを低減させることが可能なためである。システムは、静的レイヤを画像として保存することによって、コンピュータ計算を多用する処理の大部分を要求以前に実施し、したがって、要求時にビデオを変更しレンダリングするのに必要となるコンピュータ計算リソース量を低減させ、ひいてはそのビデオを要求したエンドユーザに対する遅延を低減させる。 The system provides an efficient solution that allows customized videos to be delivered with minimal computational effort at run time, because upon receipt of a request for the video This is because it is possible to reduce the complexity of the operation. By storing static layers as images, the system performs most of the computationally intensive processing ahead of time on demand, thus reducing the amount of computational resources required to modify and render the video on demand. reduce the delay to the end user who requested the video.
システムは、ビデオプロジェクトが、さまざまな要因の中でもとりわけ、特定のアプリケーション、ユーザの嗜好、および地理的ロケーションに合わせてカスタマイズされることを可能にする。システムは、要求ごとにビデオをカスタマイズしレンダリングするために必要となるリソース量を低減させることに加えて、消費されるリソースの全体量も、単一のビデオプロジェクトがさまざまなアプリケーションおよび視聴者に適合され、使用されることを可能にすることによって、低減させる。 The system allows video projects to be customized to specific applications, user preferences, and geographic location, among other factors. In addition to reducing the amount of resources required to customize and render videos for each request, the system also reduces the overall amount of resources consumed so that a single video project can fit a wide variety of applications and audiences. reduced by allowing it to be used.
本方法を活用することにより、リソースを節約し、やり直す必要のあるビデオデザイン作業を低減しながら、ユーザの要求および期待をより厳密に満たすビデオのカスタマイゼーションが可能になる。さらに、改善された更新プロセスにより、ビデオの動的に変更または更新されない部分を再レンダリングする必要がなくなることによって、コンテンツの個人化および配信システムの効率がもたらされる。本システムは、ビデオデザイナ、開発者、およびコンテンツプロバイダがリソースの大量消費を要するデザイン段階、編集段階、およびポストプロセッシング段階の後に画像およびビデオコンテンツを調整するための手段を提供する。 Leveraging this method allows customization of the video to more closely meet the user's needs and expectations while saving resources and reducing the amount of video design work that needs to be redone. Additionally, the improved update process provides efficiencies for content personalization and delivery systems by eliminating the need to re-render portions of the video that are not dynamically changed or updated. The system provides a means for video designers, developers, and content providers to adjust image and video content after the resource-intensive design, editing, and post-processing stages.
本明細書において説明する本主題の1つまたは複数の実施形態の詳細は、添付の図面および下の説明中に記載されている。本主題の他の特徴、態様、利点が、説明、図面、および特許請求の範囲から明らかとなろう。 The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the present subject matter will become apparent from the description, drawings, and claims.
さまざまな図面中の同様の参照番号および名称は、同様の要素を示す。 Like reference numbers and designations in the various drawings indicate like elements.
本文献では、ビデオの編集およびレンダリングのスピードを改善し、単一のビデオプロジェクトが複数のアプリケーションに使用され、さまざまな視聴者の嗜好に合わせて調整されることを可能にすることのできる、方法、システム、およびデバイスについて説明する。 This document describes a method that can improve the speed of video editing and rendering, allowing a single video project to be used for multiple applications and tailored to different audience preferences. , systems, and devices.
いくつかの実装形態では、システムは、完了したビデオプロジェクトが、要求時に変更され、顕著な遅延がほとんどないかまたは全くない状態で要求側ユーザに提供されることを可能にする。ユーザは、例えば、ビデオプロジェクトを特定のクライアントに適合させたいと望むビデオクリエータ、またはコンテンツ配信用システムのエンドユーザとすることができる。システムは、例えば、ビデオ合成プログラムから、合成アイテム(composite item)の形態をとるビデオプロジェクトファイルを受信することができる。次いでシステムは、ファイルをフラット化してレイヤを識別するように処理し、各レイヤが動的であるか、それとも静的であるかを判定し、レイヤ内に収容されているデータタイプに基づいて、各レイヤを分類し、各レイヤにラベル付与することができる。動的レイヤは、例えば、最終レンダリング以前に埋めるかまたは変更すべき可変コンポーネントを含むことができる。レイヤが分類された後、レイヤデータが、レイヤをレンダリングするのに必要な全てのソースデータを収容したクラスにラップされて、オブジェクトに変換される。連続する静的レイヤは一緒にラップされ得、というのも、これらの静的レイヤは事前レンダリングされた画像として一緒に出力され得るためであり、それによって、記憶空間およびエクスポート時間が節減される。次いで、静的レイヤを事前レンダリングし、動的レイヤに関する命令データを含めることによって、オブジェクトがデータタイプに基づいてマルチレイヤテンプレートにエクスポートされる。いくつかの実装形態では、システムは、静的レイヤの事前レンダリングを、各テンプレートについて1回実施する。システムは、このビデオプロジェクトファイルに関連するビデオを求める要求を受信すると、動的レイヤの変数部分を埋め、事前レンダリングされた静的レイヤと埋められた動的レイヤとの合成を実施して、要求に応答して提示すべき最終ビデオを生成することができる。いくつかの実装形態では、システムは、ビデオの異なるバージョンなど、ビデオの1つまたは複数のインスタンス化物について、動的レイヤの変数部分を埋め、事前レンダリングされた静的レイヤと埋められた動的レイヤとの合成をすることができる。 In some implementations, the system allows completed video projects to be modified on demand and provided to the requesting user with little or no noticeable delay. A user can be, for example, a video creator who wants to adapt a video project to a particular client, or an end user of a system for content distribution. The system can receive, for example, a video project file in the form of a composite item from a video compositing program. The system then flattens the file and processes it to identify layers, determines whether each layer is dynamic or static, and based on the data types contained within the layer: Each layer can be classified and labeled. A dynamic layer, for example, can contain variable components to be filled or changed before final rendering. After the layer is classified, the layer data is converted into an object wrapped in a class containing all the source data needed to render the layer. Consecutive static layers can be wrapped together because they can be output together as pre-rendered images, thereby saving storage space and export time. Objects are then exported to a multi-layer template based on data type by pre-rendering static layers and including instruction data for dynamic layers. In some implementations, the system performs static layer pre-rendering once for each template. When the system receives a request for the video associated with this video project file, the system fills the variable portion of the dynamic layer and performs a composite of the pre-rendered static layer and the filled dynamic layer to render the request A final video to be presented can be generated in response to . In some implementations, the system fills the variable portion of the dynamic layer for one or more instantiations of the video, such as different versions of the video, and divides the pre-rendered static layer and the filled dynamic layer. can be synthesized with
図1は、ビデオの効率的で動的な編集およびレンダリングのための例示的環境100のブロック図である。例示的環境100は、ローカルエリアネットワーク(LAN)、広域ネットワーク(WAN)、インターネット、またはそれらの組合せなどのネットワーク102を含む。ネットワーク102は、電子ドキュメントサーバ104(「電子ドキュメントサーバ」)、ユーザデバイス106、およびデジタルコンポーネント配信システム110(DCDS110とも呼ぶ)を接続する。例示的環境100は、多くの異なる電子ドキュメントサーバ104およびユーザデバイス106を含んでよい。
FIG. 1 is a block diagram of an
ユーザデバイス106は、ネットワーク102経由でリソース(例えば電子ドキュメント)を要求および受信することの可能な電子デバイスである。ユーザデバイス106の例としては、ネットワーク102経由でデータを送出および受信することのできる、パーソナルコンピュータ、モバイル通信デバイス、および他のデバイスがある。ユーザデバイス106は、典型的には、ネットワーク102経由でのデータの送出および受信を容易にするためのウェブブラウザなどのユーザアプリケーションを含むが、ユーザデバイス106によって実行されるネイティブアプリケーションも、ネットワーク102経由でのデータの送出および受信を容易にすることができる。
1つまたは複数のサードパーティ150としては、ビデオ、製品、および/またはサービスのデザイン、開発、マーケティング、または配信に関与する、コンテンツプロバイダ、製品デザイナ、製品メーカー、および他のパーティがある。
The one or more
電子ドキュメントとは、ユーザデバイス106においてコンテンツのセットを提示するデータである。電子ドキュメントの例としては、ウェブページ、ワードプロセシングドキュメント、ポータブルドキュメントフォーマット(PDF)ドキュメント、画像、ビデオ、検索結果ページ、およびフィードソースがある。モバイルコンピューティングデバイス、タブレットコンピューティングデバイス、またはデスクトップコンピューティングデバイス上にインストールされたアプリケーションなどのネイティブアプリケーション(例えば「アプリ」)も、電子ドキュメントの例である。電子ドキュメント105(「電子ドキュメント」)は、電子ドキュメントサーバ104によってユーザデバイス106に提供され得る。例えば、電子ドキュメントサーバ104は、発行者ウェブサイトをホストするサーバを含むことができる。この例では、ユーザデバイス106は、所与の発行者ウェブページを求める要求を開始することができ、その所与の発行者ウェブページをホストする電子ドキュメントサーバ104がこの要求に、ユーザデバイス106においてその所与のウェブページの提示を開始するマシンハイパーテキストマークアップ言語(HTML)コードを送出することによって応答することができる。
An electronic document is data that presents a set of content on
電子ドキュメントは、多様なコンテンツを含むことができる。例えば、電子ドキュメント105は、電子ドキュメント自体の中にあり、かつ/または時間の経過とともに変化しない、静的コンテンツ(例えばテキストまたは他の指定されたコンテンツ)を含むことができる。電子ドキュメントは、時間の経過とともに、または要求ごとに変化することのある、動的コンテンツを含むこともできる。例えば、所与の電子ドキュメントの発行者は、電子ドキュメントの一部分を埋めるために使用されるデータソースを維持することができる。この例では、所与の電子ドキュメントはタグまたはスクリプトを含むことができ、このタグまたはスクリプトがあることにより、ユーザデバイス106は、所与の電子ドキュメントがユーザデバイス106によって処理される(例えばレンダリングまたは実行される)ときに、データソースにコンテンツを要求する。ユーザデバイス106は、データソースから取得したコンテンツを所与の電子ドキュメントの提示内に統合して、データソースから取得したコンテンツを含む合成電子ドキュメントを作成する。
Electronic documents can contain a wide variety of content. For example,
状況によっては、所与の電子ドキュメントは、DCDS110を参照するデジタルコンテンツタグまたはデジタルコンテンツスクリプトを含むことができる。これらの状況下では、所与の電子ドキュメントがユーザデバイス106によって処理されるときに、デジタルコンテンツタグまたはデジタルコンテンツスクリプトがユーザデバイス106によって実行される。デジタルコンテンツタグまたはデジタルコンテンツスクリプトの実行により、ユーザデバイス106が、デジタルコンテンツを求める要求108を生成するように構成され、この要求108は、ネットワーク102経由でDCDS110に送信される。例えば、デジタルコンテンツタグまたはデジタルコンテンツスクリプトは、ユーザデバイス106がヘッダおよびペイロードデータを含むパケット化データ要求を生成することを可能にすることができる。要求108は、デジタルコンテンツの要求先のサーバの名前(もしくはネットワークロケーション)、要求側デバイス(例えばユーザデバイス106)の名前(もしくはネットワークロケーション)、および/または要求に応答してDCDS110が提供されたデジタルコンテンツを選択するために使用することのできる情報などのデータを含むことができる。要求108は、ユーザデバイス106によって、ネットワーク102(例えば電気通信ネットワーク)経由でDCDS110のサーバに送信される。
In some circumstances, a given electronic document may contain digital content tags or digital content scripts that reference
要求108は、電子ドキュメントとデジタルコンテンツが提示され得るロケーションの特徴とを明記したデータを含むことができる。例えば、デジタルコンテンツがその中に提示される電子ドキュメント(例えばウェブページ)への参照(例えばURL)、電子ドキュメントの、デジタルコンテンツを提示するのに利用可能なロケーション(例えばデジタルコンテンツスロット)、利用可能なロケーションのサイズ、電子ドキュメントの提示内の利用可能なロケーションの位置、および/またはそのロケーションにおいて提示するのに適格な媒体タイプを明記したデータが、DCDS110に提供され得る。同様に、電子ドキュメントの選択のために指定されたキーワード(「ドキュメントキーワード」)、または電子ドキュメントによって参照されるエンティティ(例えば人々、場所、もしくはもの)を明記したデータも、電子ドキュメントと一緒に提示するのに適格なデジタルコンテンツアイテムの識別を容易にするために、(例えばペイロードデータとして)要求108内に含められ、DCDS110に提供され得る。
The
要求108は、ユーザが提供した情報、要求の提出元の州または地域を示す地理的情報、またはデジタルコンテンツが表示される環境に関するコンテキストを提供する他の情報(例えば、モバイルデバイスやタブレットデバイスなど、デジタルコンテンツが表示されるデバイスのタイプ)など、他の情報に関係するデータを含むこともできる。ユーザにより提供される情報は、ユーザデバイス106のユーザに関するデモグラフィックデータを含むことができる。例えば、デモグラフィック情報としては、さまざまな特徴の中でもとりわけ、年齢、性別、地理的ロケーション、教育水準、配偶者の有無、世帯収入、職業、趣味、ソーシャルメディアデータ、およびユーザが特定のアイテムを所有しているかどうかがあり得る。
The
本明細書において論じるシステムが、ユーザについての個人情報を収集するかまたは個人情報を使用することのできる状況では、ユーザには、プログラムまたは機能が個人情報(例えばユーザのソーシャルネットワーク、社会的行為もしくは社会的活動、職業、ユーザの嗜好、またはユーザの現在のロケーションについての情報)を収集するかどうかを制御する、またはコンテンツサーバからユーザにとってより関連のあり得るコンテンツを受信するかどうか、かつ/もしくはその受信の仕方を制御する、機会が与えられてよい。加えて、ある特定のデータが、それが格納または使用される前に、個人を識別可能な情報が取り除かれるように1つまたは複数の方途で匿名化されてよい。例えば、ユーザの識別情報が、そのユーザにとって個人を識別可能な情報が特定できないように匿名化されてよく、またはロケーション情報が取得されるユーザの地理的ロケーションが、ユーザの特定のロケーションが特定できないように(市、郵便番号、または州レベルなどに)一般化されてよい。したがって、ユーザは、自身についてどのように情報が収集され、それがどのようにコンテンツサーバによって使用されるかに対して制御することができてよい。 In situations where the systems discussed herein may collect or use personal information about the user, the user will have the ability to access the program or feature with personal information (e.g., the user's social networks, social behavior, or information about social activity, occupation, user preferences, or user's current location), or whether to receive content that may be more relevant to the user from a content server; and/or Opportunity may be given to control how it is received. Additionally, certain data may be anonymized in one or more ways to remove personally identifiable information before it is stored or used. For example, a user's identity may be anonymized so that no personally identifiable information can be identified to that user, or the user's geographic location from which location information is obtained may not identify the user's specific location. (to city, zip code, or state level, etc.). Thus, users may be able to control how information is collected about them and how it is used by the content server.
ユーザデバイス106のモデル、ユーザデバイス106の構成、または電子ドキュメントがその上に提示される電子ディスプレイ(例えばタッチスクリーンもしくはデスクトップモニタ)のサイズ(例えば物理的なサイズもしくは解像度)を識別する情報など、ユーザデバイス106の特徴を明記したデータが、要求108内に提供されてもよい。要求108は、例えば、パケット形式のネットワーク経由で送信され得、要求108自体は、ヘッダおよびペイロードデータを有するパケット化データとしてフォーマットされ得る。ヘッダは、パケットの宛先を指定することができ、ペイロードデータは、上で論じた情報のいずれかを含むことができる。
DCDS110は、所与の電子ドキュメントと一緒に提示されることになるデジタルコンテンツを、要求108を受信したことに応答して、かつ/または要求108内に含められた情報を使用して、選択する。いくつかの実装形態では、DCDS110は、例えばサーバと複数のコンピューティングデバイスのセットとを含む分散コンピューティングシステム(または環境)内に実装され、この複数のコンピューティングデバイスは相互接続されており、要求108に応答してデジタルコンテンツを識別し、配信する。複数のコンピューティングデバイスのセットは一緒に動作して、数百万以上の利用可能なデジタルコンテンツのコーパスの中から、電子ドキュメント内に提示するのに適格なデジタルコンテンツのセットを識別する。数百万以上の利用可能なデジタルコンテンツは、例えば、デジタルコンポーネントデータベース112においてインデックス付けされ得る。各デジタルコンテンツインデックスエントリが、対応するデジタルコンテンツを参照することができ、かつ/または対応するデジタルコンテンツの配信の条件となる配信パラメータ(例えば選択基準)を含むことができる。
いくつかの実装形態では、デジタルコンポーネントデータベース112からのデジタルコンポーネントが、サードパーティ150によって提供されたコンテンツを含むことができる。例えば、デジタルコンポーネントデータベース112は、機械学習および/または人工知能を使用して公道をナビゲーションするサードパーティ150から、公共の交差点の写真を受信することができる。別の例では、デジタルコンポーネントデータベース112は、二輪車の乗り手にサービスを提供するサードパーティ150から、サードパーティ150がユーザから応答をもらいたいと思う具体的な質問を受信することができる。加えて、DCDS110は、例えばビデオレンダリングプロセッサ130からのコンテンツを含むビデオコンテンツ、およびビデオレンダリングプロセッサ130によって提供され、デジタルコンポーネントデータベース112内に格納されたビデオコンテンツを提示することもできる。
In some implementations, digital components from
適格なデジタルコンテンツの識別は、複数のタスクに分割され、次いでそれらが、複数のコンピューティングデバイスのセット内のコンピューティングデバイスの間で割り当てられ得る。例えば、異なるコンピューティングデバイスがそれぞれ、要求108内に含められた情報と合致する配信パラメータを有するさまざまなデジタルコンテンツを識別するために、デジタルコンポーネントデータベース112の異なる部分を解析することができる。
Identifying eligible digital content can be divided into multiple tasks, which can then be assigned among computing devices in a set of multiple computing devices. For example, different computing devices may each analyze different portions of
DCDS110は、複数のコンピューティングデバイスのセットから受信した結果を集約し、集約した結果に関連する情報を使用して、要求108に応答して提供されるデジタルコンテンツの1つまたは複数のインスタンスを選択することができる。次に、DCDS110は、応答データ114(例えば応答を表すデジタルデータ)を生成して、ネットワーク102経由で送信することができ、この応答データ114により、ユーザデバイス106がデジタルコンテンツの選択セットを所与の電子ドキュメント内に統合し、それによって、デジタルコンテンツの選択されたセットと電子ドキュメントのコンテンツとがユーザデバイス106のディスプレイにおいて一緒に提示されることが可能になる。
ビデオ合成プログラム(VCP)120は、ユーザがビデオプロジェクトファイルを作成することを可能にするものである。ビデオプロジェクトファイルは、ビデオをレンダリングするためのデータのコレクションを表す。いくつかの実装形態では、ビデオプロジェクトファイルは、それぞれが操作されることが可能であり、アイテムのコレクション内のオブジェクトについての情報を提供する、コンポジションアイテムである。コンポジションアイテムは、例えば、アルファチャンネルをもつ複数のレイヤが一緒にアルファブレンディングされたものを含むアイテムとすることができる。説明を簡単にするために、VCP120については、ビデオ合成プログラムと説明しているが、VCP120は、デジタルの視覚効果処理、モーショングラフィックス処理、および/または合成処理を実施することもできる。例えば、VCP120は、ビデオのポストプロダクション処理用のプログラムとすることができる。 The Video Compositing Program (VCP) 120 allows users to create video project files. A video project file represents a collection of data for rendering a video. In some implementations, a video project file is a composition item, each of which can be manipulated to provide information about objects in a collection of items. A composition item can be, for example, an item containing multiple layers with alpha channels alpha-blended together. For simplicity of explanation, VCP 120 is described as a video compositing program, but VCP 120 may also perform digital visual effects processing, motion graphics processing, and/or compositing processing. For example, VCP 120 may be a program for post-production processing of video.
ビデオレンダリングプロセッサ(VRP)130は、VCP120からビデオプロジェクトファイルを受領し、そのビデオプロジェクトファイルを、ビデオプロジェクトファイルコンポーネントを検出し、ビデオプロジェクトファイルコンポーネントにラベル付与し、ビデオプロジェクトファイルコンポーネントを埋め、レンダリングするように、処理する。VRP130は、フラットナ(flattener)132、分類器134、およびエクスポータ136を含む。フラットナ132は、受領したビデオプロジェクトファイルのレイヤなどのコンポーネントをフラット化する。分類器134は、受領したビデオプロジェクトファイルのレイヤを分類し、それにラベル付与する。エクスポータ136は、テンプレートファイルを生成するために、ラベル付与したレイヤをどのように処理するか、また最終出力を得るために、テンプレートファイルおよび1つまたは複数の変更された、または埋められたレイヤをどのように処理するかを決定する。
A video rendering processor (VRP) 130 receives the video project file from the VCP 120, detects the video project file components, labels the video project file components, fills the video project file components, and renders the video project file. so as to process.
説明を簡単にするために、フラットナ132、分類器134、およびエクスポータ136は図1に、VRP130の別々のコンポーネントとして示されている。VRP130は、非一時的コンピュータ可読媒体上の単一システムとして実装することができる。いくつかの実装形態では、フラットナ132、分類器134、およびエクスポータ136のうちの1つまたは複数を、単一システムの統合されたコンポーネントとして実装することができる。VRP130、そのコンポーネントであるフラットナ132、分類器134、エクスポータ136、およびそれらのそれぞれに対応する出力について、下でさらに詳細に説明する。
テンプレートインスタンス化システム140が、VRP130によって作成されたテンプレートを、テンプレートの動的レイヤを埋め、かつ/または変更して、インスタンス化する。いくつかの実装形態では、テンプレートインスタンス化システム140は、例えばビデオのバージョンごとに1つまたは複数のテンプレートをインスタンス化することによって、ビデオの1つまたは複数のバージョンの動的レイヤを埋め、かつ/または変更することができる。この特定の実装形態では、テンプレートインスタンス化システム140は、VRP130とは独立したものとして示されている。テンプレートインスタンス化システム140は、例えば、特定のレイヤをどのようにインスタンス化すべきかを示す入力を受信することができる。テンプレートインスタンス化システム140は、システム100の、ユーザデバイス106、VCP120、およびサードパーティ150を含む他のコンポーネントから、入力を受信することができる。いくつかの実装形態では、テンプレートインスタンス化システム140は、VRP130によって作成されたテンプレートの特定のレイヤを埋めるための所定の値を含む。テンプレートインスタンス化システム140は、例えばユーザデバイス106、VCP120、および/またはサードパーティ150からの入力に基づいて、テンプレートを埋めるためのさまざまな値を決定することができる。
Template instantiation system 140 instantiates the template created by
いくつかの実装形態では、テンプレートインスタンス化システム140は、VRP130と統合することもでき、あるいはVRP130のコンポーネントとすることもできる。例えば、テンプレートインスタンス化システム140は、VRP130のモジュールとすることができ、システム100の残りのコンポーネントと通信することができる。
In some implementations, template instantiation system 140 may be integrated with
テンプレートインスタンス化システム140は、インスタンス化したテンプレートを、最終レンダリングおよび出力のためにVRP130に提供する。例えば、テンプレートインスタンス化システム140は、各動的レイヤを、そのレイヤの可変コンポーネントが埋められたオブジェクトとしてインスタンス化することができる。次いで、これらのオブジェクトは、コレクション内に格納されて、最終レンダリングのためにVRP130に渡され得る。いくつかの実装形態では、テンプレートインスタンス化システム140は、コレクションをマルチレイヤレンダリング要求としてVRP130に提供することができる。
Template instantiation system 140 provides instantiated templates to
下で説明する技法は、システムがビデオを、複雑さに関わらず効率的に編集しレンダリングすることを可能にするものである。 The techniques described below allow the system to efficiently edit and render videos of any complexity.
図2は、図1の例示的環境における、ビデオの効率的で動的な編集およびレンダリングプロセスの例示的データフロー200を示す。データフロー200の動作は、システム100のさまざまなコンポーネントによって実施される。例えば、データフロー200の動作は、DCDS110、ビデオ合成プログラム120、テンプレートインスタンス化システム140、およびユーザデバイス106と通信する、ビデオレンダリングプロセッサ130によって実施され得る。
FIG. 2 shows an
フローはステップAから開始し、ステップAでは、VCP120がビデオプロジェクトファイル202をVRP130に提供する。ビデオプロジェクトファイル202は、コンポジションを表すオブジェクトである。例えば、ビデオプロジェクトファイル202は、アイテムコレクションを有するCompItemオブジェクトとすることができる。ビデオプロジェクトファイル202は、操作することができ、オブジェクトおよびそのアイテムコレクションについての情報は、取得することができる。いくつかの実装形態では、ビデオプロジェクトファイル202のコレクション内のアイテムには、コレクション内の位置インデックス番号によってアクセスすることができる。これらのアイテムは、ビデオを作り上げるさまざまなコンポーネントの中でもとりわけ、画像、テキスト、オーディオ、および/またはオブジェクトを収容した、ビデオレイヤなどのオブジェクトである。
Flow begins at step A, where VCP 120 provides video project file 202 to
ビデオプロジェクトファイル202は、VCP120のユーザによって生成され得る。例えば、ビデオクリエータまたはビデオデザイナが、ビデオプロジェクトファイル202を作成することができる。ユーザは、ビデオの置換または変更することのできる部分を示すことができる。いくつかの実装形態では、ユーザは、コメントフィールドなど、VCP120の組込みのフィールドを使用して、特定のレイヤに動的のマークを付けることができる。例えば、VCP120のユーザは、レイヤのコメントフィールドを使用して、変数「var」をtrueに設定し、したがって、そのレイヤの少なくとも一部分を置換または変更できることを示すことができる。いくつかの実装形態では、ユーザは、レイヤの示された部分が置換または変更されない場合に使用すべき、既存レイヤなどのデフォルト値を示すことができる。いくつかの実装形態では、ユーザは、受信したユーザの嗜好、ユーザのデモグラフィック、ロケーション情報、および他の情報などの要因に基づいてレイヤの示された部分の代わりに使用すべき所定の値のセットを示すことができる。 Video project file 202 may be created by a user of VCP 120 . For example, a video creator or video designer can create the video project file 202 . The user can indicate portions of the video that can be replaced or changed. In some implementations, users can mark specific layers as dynamic using built-in fields in VCP 120, such as the comment field. For example, a user of VCP 120 can use a layer's comment field to set the variable "var" to true, thus indicating that at least a portion of that layer can be replaced or modified. In some implementations, the user can indicate default values, such as existing layers, to use if the indicated portion of the layer is not replaced or modified. In some implementations, the user can select predetermined values to substitute for the indicated portion of the layer based on factors such as user preferences, user demographics, location information, and other information received. set can be indicated.
フローはステップBに進み、ステップBでは、VRP130がビデオプロジェクトファイル202のドキュメントオブジェクトモデル(DOM)をフラット化する。DOMは、クロスプラットフォームのかつ言語非依存のインターフェースであり、このインターフェースはドキュメントを、各ノードがドキュメントの一部を表すオブジェクトである論理ツリー構造を用いて表す。ツリーの各ブランチがノードで終わり、各ノードがオブジェクトを収容している。いくつかの実装形態では、ビデオプロジェクトファイル202内のレイヤのうちの1つが、別のコンポジションへのポインタであり、階層または深さの点になっている。VRP130のフラットナ132が、ビデオプロジェクトファイル202のDOM内のオブジェクトにわたって反復適用され得る。例えば、VRP130のフラットナ132は、ビデオプロジェクトファイル202のDOM内の全てのレイヤの深さ優先フラット化を行うことができる。深さ優先フラット化は、例えば、ビデオプロジェクトファイル202のDOMの開始ノードを選択し、その隣接ノードを全てスタック内にプッシュし、スタックからあるノードをポップして、訪れるべき次ノードを選択し、そのノードの隣接ノードを全てスタック内にプッシュし、このプロセスをスタックが空になるまで繰り返すことによって、実施され得る。いくつかの実装形態では、フラットナ132は、z深度順に、すなわち幅方向(breadth-wise)順に、各レイヤにわたって反復適用され得る。幅方向フラット化は、例えば、深さ優先フラット化とは逆のストラテジを使用して、ビデオプロジェクトファイル202のDOMルートにおいて開始し、現在の深さにおける近隣ノードを全て探査してから、次の深さレベルにおけるノードに移ることによって、実施され得る。
Flow proceeds to step B, where
フローはステップCに進み、ステップCでは、VRP130がビデオプロジェクトファイル202の各レイヤを分類し、それによって、適切なエクスポートモジュールが後の使用のために識別され得るようにする。いくつかの実装形態では、VRP130がレイヤを、レイヤが深さ優先アルゴリズムを通じてフラット化されるときに分類するように、ステップCはステップBと同時に実施される。例えば、フラットナ132が各ノードを探査するとき、分類器134は、検出されたレイヤごとに特定のファイルフォーマットを検出し、レイヤに、そのレイヤをレンダリングするのに適切なエクスポートモジュールをVRP130が選択できるように、ラベル付与することができる。
Flow proceeds to step C, where
分類器134は、レイヤが動的レイヤ、すなわち可変コンポーネントまたは変更され得るコンポーネントを有するレイヤであるか、それとも静的レイヤ、すなわち可変コンポーネントまたは変更され得るコンポーネントを有していないレイヤであるかを検出することができる。例えば、静的レイヤは、ビデオの背景に残る太陽の画像などの画像とすることができる。いくつかの実装形態では、静的レイヤは、最終レンダリング時に変化しないレイヤとすることができる。例えば、ビデオ内の静的レイヤは、可変コンポーネントを有していない全てのレイヤを含むことができ、要求時以前にレンダリングされ得る。いくつかの実装形態では、動的レイヤは、例えば、ビデオシーンの方々に配置または移動される必要のある、2Dまたは3Dの画像またはビデオとすることができる。例えば、動的レイヤは、(5つ星のうちから格付けするための)格付け用の星(rating star)などのビジネスロジック画像要素とすることもでき、あるいは緑色背景などのカラーレイヤとすることもできる。
The
いくつかの実装形態では、分類器134は、レイヤが動的レイヤであるかどうかを、レイヤのフィールドが特定の値を有するかどうかを判定することによって識別することができる。分類器134は、例えば、レイヤのコメントフィールドが特定の変数またはテキストのセットを収容しているかどうかを判定することができる。一例では、分類器134は、特定のレイヤに関するステートメントLayer.comment.contains('var=true')の値がTRUEであるかどうかをチェックして、そのレイヤが動的であるかどうかを判定することができる。
In some implementations,
レイヤが動的であるか、それとも静的であるかを判定することに加えて、分類器134は、レイヤ内に収容されているデータのタイプに基づいて、各レイヤを分類し、各レイヤにラベル付与することができる。これらのラベルは、レイヤをレンダリングするのに適切なエクスポートモジュールを決定するために使用され得る。例えば、分類器134は、ステートメントLayer.constructor == AVLayerの値がTRUEであるかどうかをチェックして、そのレイヤがビデオレイヤであるかどうかを判定することができる。ビデオレイヤは、例えば、オーディオまたは画像データを含むことができる。
In addition to determining whether a layer is dynamic or static,
別の例では、分類器134は、ステートメントLayer.constructor == TextLayerの値がTRUEであるかどうかをチェックして、そのレイヤがテキストレイヤであるかどうかを判定することができる。レイヤが動的テキストレイヤである場合、例えば、レイヤの変更され得る特徴としては、さまざまな特徴の中でもとりわけ、テキスト自体、配置、透明度、サイズ、色、およびフォントがあり得る。テキストレイヤは、例えば、2Dまたは3Dのテキストを含むことができる。
In another example,
別の例では、分類器134は、ステートメントLayer.source.typeName == 'Composition'の値がTRUEであるかどうかをチェックして、そのレイヤがDOMの階層ノードであるかどうかを判定することができる。例えば、レイヤが階層ノードであると分類器134が判定した場合、VRP130は、このノードをDOMの階層内の点として使用し、再帰を使用して、ツリー全体が走査されるまでビデオプロジェクトファイル202のDOMのフラット化を継続する。
In another example,
別の例では、分類器134は、ステートメントLayer.comment DOES NOT contain('var=true')の値がTRUEであるかどうかをチェックして、そのレイヤが静的レイヤであるかどうかを判定することができる。静的レイヤは、最終レンダリング時に変化せず、したがって、動的レイヤとは別様に取り扱われ得る。静的レイヤおよび動的レイヤのハンドリングについては、以下のステップにおいてさらに説明する。
In another example,
フローはステップDに進み、ステップDでは、VRP130がビデオプロジェクトファイル202のフラット化され、分類されたレイヤを使用して、テンプレートを作成する。例えば、エクスポータ136が、ビデオプロジェクトファイル202の動的レイヤおよび静的レイヤを表すテンプレートを作成することができる。各レイヤが分類された後、エクスポータ136はレイヤを、キューイングされるクラス(queued class)にラップすることができる。例えば、エクスポータ136はレイヤを、そのレイヤをレンダリングするのに必要な全てのソースマテリアルを収容したクラスにラップすることができる。これらのアイテムが、キュー内に格納されて、テンプレートにエクスポートされ得る。いくつかの実装形態では、レイヤがクラスにラップされ、そのクラスのアイテムがインスタンス化された後は、ビデオプロジェクトファイル202へのさらなる参照は行われない。このフォーマットにより、VRP130が、ビデオプロジェクトファイル202への参照およびアクセスの回数を低減することが可能になり、したがって、ビデオをレンダリングするために必要なコンピュータ計算リソース量が低減する。
Flow proceeds to step D, where
いくつかの実装形態では、2つ以上の静的レイヤがクラスの単一アイテムにラップされ得る。例えば、z深度順に、または他の適切な順序付け方式において連続する静的レイヤ同士が一緒に、事前レンダリングされた画像としてテンプレートにエクスポート出力され得る。例えば、エクスポータ136は、z深度順に連続する3つの静的レイヤを単一のPNGとしてレンダリング出力することができる。いくつかの実装形態では、エクスポータ136は、単一画像としてエクスポートすべき静的レイヤの系列を識別することができる。エクスポータ136は、例えば、静的レイヤが検出されると系列を開始し、動的レイヤを検出すると系列を終了することができ、それによって、系列が動的レイヤを含まないようになる。エクスポータ136は、複数の静的レイヤを一括してエクスポートすることによって、静的レイヤを保存するのに必要となる記憶リソース量を低減させ、また最終レンダリングプロセスが費やす時間量を低減させる。
In some implementations, two or more static layers may be wrapped in a single item of class. For example, successive static layers together in z-depth order, or in some other suitable ordering scheme, can be exported out to the template as pre-rendered images. For example, the
いくつかの実装形態では、他のタイプは、ただ1つのレイヤを含む。例えば、ただ1つの動的レイヤがクラスの単一アイテムにラップされてよい。動的レイヤを収容するクラスのアイテムは、さまざまな情報の中でもとりわけ、レイヤの可変な部分やアイテムの構造に関する命令などの情報を含むことができる。 In some implementations, other types contain only one layer. For example, a single dynamic layer may be wrapped in a single item of class. Items of the class containing the dynamic layer can contain information such as instructions on the variable parts of the layer and the structure of the item, among other information.
いくつかの実装形態では、エクスポータ136は、キューイングされるアイテムの格納をハンドリングし、それらのアイテムを出力フォーマットにエクスポートして、テンプレートを作成し、またエクスポータ136は、テンプレートがインスタンス化されると、テンプレートを埋め、埋められたテンプレートをディスクに保存する。例えば、エクスポータ136は、テンプレート自体をJavaScript Object Notation(JSON)フォーマットでプロトコルバッファオブジェクトとして保存することができる。プロトコルバッファオブジェクト、またはメッセージは、保存されたソースマテリアルを、相対パスを使用して参照することができる。
In some implementations, the
テンプレートがインスタンス化された後、エクスポータ136は、テンプレート変数を、ビデオプロジェクトファイル202のプロパティで埋める。例えば、エクスポータ136は、インスタンス化されたテンプレートを、ビデオプロジェクトファイル202からのビデオパラメータで埋めることができる。エクスポータ136は、テンプレートをパラメータで埋めるために、トランスフォームライブラリ(transform library)を使用する。
After the template is instantiated,
トランスフォーム(transform)は、レイヤの時間変化する調整を可能にするものである。レイヤ内の任意の所与のフレームに、1つまたは複数のトランスフォームを適用することができる。例えば、エクスポータ136は、位置変換、透明度変換、マスク変換、ぼかし変換、およびテクスチャ変換などのトランスフォームを適用することができる。例えば、エクスポータ136は、画像系列を使用してマスクトランスフォームを実施することができる。別の例では、エクスポータ136は、オブジェクトの位置をコンピュータ計算するトランスフォームを実施することができる。エクスポータ136は、例えば、各要素のコーナー上に、あるタイプのヌル要素を配置および固定し、各ヌル要素のコーナーに別のタイプのヌル要素を追加することにより、各フレーム内のオブジェクトの2D投影画像位置をコンピュータ計算する、ライブラリを使用することができる。例えば、エクスポータ136は、各要素のコーナー上にヌル3D要素を配置および固定し、各3D要素のコーナーに2Dヌルを追加することができる。いくつかの実装形態では、エクスポータ136は、VCP120などのプログラムからの既存のライブラリを使用することができる。
A transform allows for time-varying adjustments of layers. One or more transforms can be applied to any given frame within a layer. For example,
各フレームについての一群の変換は、そのフレーム内のオブジェクトを調整するのに必要な全てのデータをもたらす。トランスフォームは所与のフレームに内蔵されており、それによって、キーフレームが不要になり、また前向きおよび後ろ向きの外挿(forward-looking and backward-looking extrapolation)が必要とされず、その結果、並列化が可能になる。エクスポータ136は、例えば、処理時間を低減させるために全てのフレーム変換を並列に実施することができる。トランスフォームは、各フレームに対して開始時間、終了時間、およびタイムスタンプを共有する。エクスポータ136は、これらの値のうちの1つのみを使用し、残りの2つの値をエラーの検出および訂正に使用できるようにすることによって、必要となる記憶リソース量を低減させる。例えば、エクスポータ136は、タイムスタンプを使用して、特定のフレームに透明度変換を適用することができ、開始時間を使用して、透明度変換の時間プロパティにエラーが含まれていないことを検証することができる。
A set of transforms for each frame provides all the data needed to adjust the objects in that frame. Transforms are built into a given frame, which eliminates the need for keyframes and forward-looking and backward-looking extrapolation, resulting in parallel become possible.
エクスポータ136は、レイヤのタイプごとに1つのエクスポートモジュールを含む。エクスポータ136は、VRSによる分類に基づいて、適切な出力を生成するための特定のエクスポートモジュールを選択し、使用することができる。エクスポートモジュールは、例えば、VCP120のエクスポートモジュールと同様に動作することができる。
エクスポータ136は、さまざまなタイプのエクスポートモジュールの中でもとりわけ、静的レイヤエクスポートモジュール、メディアレイヤエクスポートモジュール、およびテキストレイヤエクスポートモジュールを含む。
エクスポータ136の静的レイヤエクスポートモジュールは、静的として分類されたレイヤを受領し、静的レイヤメッセージと呼ばれるプロトコルバッファメッセージを出力する。静的レイヤエクスポートモジュールは、1つまたは複数の静的レイヤから、1つのプロトコルバッファメッセージを出力する。例えば、静的レイヤエクスポートモジュールは、6つの静的レイヤを受領し、6つの静的レイヤを表す1つのプロトコルバッファメッセージを出力することができる。静的レイヤエクスポートモジュールは、ビデオプロジェクトファイル202の全ての静的レイヤを出力することができる。いくつかの実装形態では、静的レイヤは連続していなければならない。静的レイヤエクスポートモジュールは静的レイヤを、例えばビデオプロジェクトファイル202の静的レイヤ以外のタイプとして分類された全てのレイヤをディスエーブルにし、ビデオプロジェクトファイル202の静的レイヤとして分類された全てのレイヤをイネーブルにし、フレームごとに保存済み画像を呼び出すことによって、エクスポートすることができる。いくつかの実装形態では、エクスポータ136の静的レイヤエクスポートモジュールは、フレームごとに保存済み画像を呼び出すことによって、ビデオプロジェクトファイル202の全ての静的レイヤを事前レンダリングし(というのもこれらのフレームは最終レンダリング時に変化しないためであり)、したがって、最終レンダリング時にビデオを完全なものにするために行われる必要のある処理の量を低減させる。
The static layer export module of
エクスポータ136のメディアレイヤエクスポートモジュールは、動的メディアレイヤとして分類されたレイヤを受領し、動的メディアレイヤメッセージと呼ばれるプロトコルバッファメッセージを出力する。動的メディアレイヤは、画像およびビデオを含む。例えば、動的メディアレイヤエクスポートモジュールは、可変な置換され得る画像を含むレイヤを受領し、その動的メディアレイヤを示すプロトコルバッファメッセージをエクスポートすることができる。動的メディアレイヤは、例えば、さまざまなオブジェクトの中でもとりわけ、ロゴや写真などの画像、ビデオロゴ、プロダクトクリップ、スポークスパーソンからのメッセージなどのビデオ、色やテクスチャなどの視覚要素、およびタグライン、スローガン、または名前などのテキストを含むことができる。
The media layer export module of
テンプレートがインスタンス化されると、メディアレイヤエクスポートモジュールは、テンプレート変数を、ビデオプロジェクトファイル202のプロパティで埋める。例えば、メディアレイヤエクスポートモジュールは、VCP120からのライブラリを使用して、特定の動的メディアレイヤに関するテンプレート変数のサイドプロパティおよび位置プロパティを埋めることができる。 When the template is instantiated, the media layer export module fills the template variables with properties from the video project file 202 . For example, the media layer export module can use libraries from VCP 120 to populate the side and position properties of template variables for a particular dynamic media layer.
フローはステップEに進み、ステップEでは、DCDS110が、ユーザデバイス106から、コンテンツを求める要求108を受信する。要求108は、ユーザデバイス106がデジタルコンテンツと対話したときに、そのクライアントデバイスによってDCDS110に対して送信される。例えば、ユーザデバイス106のユーザが、ショッピングアプリケーションをダウンロードするためのリンクをクリックした場合、このリンクがユーザデバイス106に、DCDS110に対して要求108を送信させることができる。要求108は、クライアントデバイス106からの対話追跡データを含むことができる。例えば、要求108は、対話を示す標識、ユーザデバイス106が対話したデジタルコンテンツ、およびユーザデバイス106を一意に識別する識別子などの追跡データを含むことができる。いくつかの実装形態では、要求108は、デジタルコンテンツのプロバイダを示す標識、および要求されたリソースをホストする宛先サーバのロケーションを含む。
Flow proceeds to step E, where
DCDS110は、要求を処理し、カスタマイゼーション情報を含む、特定のビデオを求める要求を、テンプレートインスタンス化システム140に転送する。例えば、DCDS110は、上で図1に関して説明したコンテンツ選択プロセスを使用して特定のビデオを選択し、テンプレートインスタンス化システム140用の個人化情報を決定することができる。いくつかの実装形態では、DCDS110は、個人化情報を、ユーザデバイス106のユーザに関するユーザ情報に基づいて決定する。いくつかの実装形態では、DCDS110は、個人化情報を、例えばDCDS110にコンテンツを提供するサードパーティ150からの情報に基づいて決定する。
いくつかの実装形態では、データフロー200においてステップEが行われず、VCP120のユーザ、VRP130のユーザ、またはユーザデバイス106のユーザが、変更されたビデオを求める要求を直接テンプレートインスタンス化システム140に出すことができる。
In some implementations, step E does not occur in
フローはステップFに進み、ステップFでは、テンプレートインスタンス化システム140が、テンプレートの変数部分をどのように埋めるかに関する変数定義、または命令を提供して、テンプレートをインスタンス化し、エクスポータ136が変数を埋める。いくつかの実装形態では、変数定義は、テンプレート内の特定の変数を定義するデータを含む。例えば、テンプレートインスタンス化システム140は、動的レイヤの可変コンポーネントを埋めることに関する命令を用いてテンプレートをインスタンス化し、マルチレイヤ要求を生成する。次いで、テンプレートインスタンス化システム140は、マルチレイヤ要求をエクスポータ136に出す。
Flow proceeds to step F, where the template instantiation system 140 provides variable definitions, or instructions, on how to fill in the variable portion of the template to instantiate the template, and the
エクスポータ136は、マルチレイヤ要求を受領し、静的レイヤプロトコルバッファメッセージの形態をとる事前レンダリングされた静的レイヤと、テンプレートインスタンス化システム140によってマルチレイヤ要求内に提供された命令とを使用して、ビデオの最終レンダリングを実施する。ビデオプロジェクトファイル202に関するテンプレートが生成されたときに静的レイヤが事前レンダリングされたので、要求時に実施される最終レンダリング動作に含まれるのは、変数を埋めること、およびレイヤ同士を合成することだけである。例えば、エクスポータ136は、静的レイヤプロトコルバッファメッセージ内の画像と埋められた動的レイヤとのアルファブレンディングを実施して、ビデオプロジェクトファイル202の最終レンダリングを生じさせることができる。これらの動作はVRP130において、さまざまなレベルのグラフィックの複雑さをもつビデオを求める要求時のレンダリング時間がO(1)であるように最適化されており、というのも、テンプレートが生成されたときに静的レイヤが事前レンダリングされたためである。したがって、システム100、およびシステム100によって実施されるプロセス200は、ビデオの変更およびレンダリングの既存の解決策に勝る技術的改善をもたらす。
The
フローはステップGに進み、ステップGでは、VRP130が、応答114とともに、または応答114として、レンダリングされたビデオをユーザデバイス106への提示のためにDCDS110に提供する。上で説明したように、応答データ114は、要求された電子ドキュメントに加えて、VRP130によってレンダリングされたビデオコンテンツを示すことができる。応答データ114は、DCDS110が要求108を受信し、受領した配信パラメータおよび要求108内に示されたユーザデータに基づいて配信パラメータが満たされたと判定したことに応答して、DCDS110によってユーザデバイス106に送信される。
Flow proceeds to step G, where
図3は、ビデオの効率的で動的な変更およびレンダリングのための、例示的プロセス300のフローチャートである。いくつかの実装形態では、プロセス300は、1つまたは複数のシステムによって実施され得る。例えば、プロセス300は、図1～図2のVRP130、DCDS110、ユーザデバイス106、および/またはサードパーティ150によって実装することができる。いくつかの実装形態では、プロセス300は、非一時的コンピュータ可読媒体上に格納された命令として実装することができ、この命令は、1つまたは複数のサーバによって実行されると1つまたは複数のサーバに、プロセス300の動作を実施させることができる。
FIG. 3 is a flowchart of an
プロセス300は、1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを含む、ビデオをレンダリングするためのファイルを識別すること(302)から開始する。例えば、VRP130が、VCP120によって生成されたビデオをレンダリングするためのビデオプロジェクトファイル202を受信または識別することができる。ビデオプロジェクトファイル202は、1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを収容することができる。いくつかの実装形態では、VCP120がビデオプロジェクトファイル202をVRP130に提供する。いくつかの実装形態では、VRP130はビデオプロジェクトファイル202を記憶デバイスから取り出すことができる。
プロセス300は、ビデオをレンダリングするためのファイルの1つまたは複数のフィールドの解析に基づいて、1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを検出することであって、各動的レイヤが、可変コンポーネントであることを示すコメントを含む、検出すること(304)に進む。例えば、VRP130のフラットナ132が、ビデオプロジェクトファイル202のDOMをフラット化することができる。同時に、VRP130の分類器134が、ビデオプロジェクトファイル202の1つまたは複数のフィールドを、例えば、特定のレイヤが静的であるか、それとも動的、すなわち可変であるかを示すコメントフィールドを検出するように解析することができる。
The
プロセス300は、ファイルの1つまたは複数の静的レイヤをレンダリングすること(306)によって継続する。例えば、エクスポータ136がレイヤをラップして、プロトコルバッファメッセージにエクスポートすることができる。エクスポータ136は、動的レイヤに関する変数と事前レンダリングされた静的レイヤとを含むテンプレートを生成する。例えば、エクスポータ136は各静的レイヤを、静的レイヤのフレームの保存済み画像を呼び出し、それらの保存済み画像をエクスポートすることによって、事前レンダリングすることができる。ファイルの1つまたは複数の静的レイヤのレンダリングは、要求時以前に、すなわちユーザ情報を含む、ビデオを求める要求の受信以前に行われ(したがって静的レイヤは事前レンダリングされ)、要求時に行われなければならないレンダリングの量を低減させる。
プロセス300は、ユーザデバイスから、ユーザ情報を含む、ビデオを求める要求を受信すること(308)に進む。例えば、DCDS110が、ユーザデバイス106のユーザから要求108を受信し、その要求を、テンプレートインスタンス化システム140に転送することができる。
プロセス300は、ユーザ情報に基づいて、動的レイヤに挿入されるように指定された変数定義を決定すること(310)に進む。例えば、テンプレートインスタンス化システム140が、DCDS110によって転送された要求内に提供されたユーザ情報に基づいて、動的レイヤの変数を変更または置換するための命令を決定することができる。次いで、テンプレートインスタンス化システム140は、エクスポータ136によって生成されたテンプレートをインスタンス化することができる。
The
プロセス300は、1つまたは複数の動的レイヤを、変数定義を使用してレンダリングすること(312)に進む。例えば、VRP130のエクスポータ136が、テンプレートインスタンス化システム140によってインスタンス化されたテンプレートを、テンプレートインスタンス化システム140によって提供された、動的レイヤの変数を変更または置換するための命令に基づいて、埋めることができる。
The
プロセス300は、レンダリングされた1つまたは複数の静的レイヤおよびレンダリングされた1つまたは複数の動的レイヤから、再生用の合成ビデオを生成すること(314)で終わる。例えば、VRP130のエクスポータ136が、埋められたテンプレートを使用して、ビデオプロジェクトファイル202のビデオの最終レンダリングを実施し、それによって、再生用のビデオを生成することができる。テンプレートが静的レイヤの事前レンダリングしたものを含むので、最終レンダリングプロセスの相対的に大きな部分は、レイヤ同士を一緒にアルファブレンディングすることであり、テンプレートを埋めることによる追加の処理時間は、最終レンダリングプロセスの大きな割合を占めない。したがって、システム100は、さまざまなグラフィックの複雑さをもつビデオを一定の時間で変更し動的にレンダリングするための、効率的な解決策を提供する。
The
図4は、上で説明した動作を実施するために使用することのできる例示的コンピュータシステム400のブロック図である。システム400は、プロセッサ410、メモリ420、記憶デバイス430、および入力/出力デバイス440を含む。コンポーネント410、420、430、および440はそれぞれ、例えばシステムバス450を使用して相互接続することができる。プロセッサ410は、システム400内で実行するための命令を処理することが可能である。一実装形態では、プロセッサ410はシングルスレッドプロセッサである。別の実装形態では、プロセッサ410はマルチスレッドプロセッサである。プロセッサ410は、メモリ420内または記憶デバイス430上に格納された命令を処理することが可能である。
FIG. 4 is a block diagram of an
メモリ420は、システム400内の情報を格納する。一実装形態では、メモリ420はコンピュータ可読媒体である。一実装形態では、メモリ420は揮発性メモリユニットである。別の実装形態では、メモリ420は不揮発性メモリユニットである。
記憶デバイス430は、システム400のマスストレージを提供することが可能である。一実装形態では、記憶デバイス430はコンピュータ可読媒体である。異なるさまざまな実装形態では、記憶デバイス430は、例えば、ハードディスクデバイス、光ディスクデバイス、ネットワーク経由で複数のコンピューティングデバイスによって共有される記憶デバイス(例えばクラウド記憶デバイス)、または他の何らかの大容量記憶デバイスを含むことができる。
入力/出力デバイス440は、システム400の入力/出力動作を行う。一実装形態では、入力/出力デバイス440は、1つまたは複数のネットワークインターフェースデバイス、例えばイーサネットカード、シリアル通信デバイス、例えばRS-232ポート、および/またはワイヤレスインターフェースデバイス、例えば802.11カードを含むことができる。別の実装形態では、入力/出力デバイスは、入力データを受領し、出力データを他の入力/出力デバイス、例えばキーボード、プリンタ、およびディスプレイデバイス460に送出するように構成された、ドライバデバイスを含むことができる。しかし、モバイルコンピューティングデバイス、モバイル通信デバイス、セットトップボックステレビジョンクライアントデバイスなど、他の実装形態を使用することもできる。
Input/
例示的処理システムについて、図4において説明してきたが、本明細書において説明した本主題および機能的動作の実装形態は、他のタイプのデジタル電子回路として、またはコンピュータソフトウェア、コンピュータファームウェア、もしくは本明細書において開示した構造およびそれらの構造的等価物を含むコンピュータハードウェアとして、またはそれらのうちの1つまたは複数のものの組合せとして、実装することができる。 Although an exemplary processing system has been described in FIG. 4, implementations of the subject matter and functional operations described herein may be implemented as other types of digital electronic circuits, or as computer software, computer firmware, or as computer software, firmware, or implementations herein. can be implemented as computer hardware including the structures disclosed herein and their structural equivalents, or as a combination of one or more of them.
電子ドキュメント(略して単にドキュメントと呼ぶ)は、必ずしもファイルに対応しているとは限らない。ドキュメントは、他のドキュメントを保持するファイルの一部分内に、当該のドキュメントに専用の単一のファイル内に、または複数の連係されたファイル内に、格納することができる。 Electronic documents (simply called documents for short) do not necessarily correspond to files. A document can be stored within a portion of a file that holds other documents, within a single file dedicated to that document, or within multiple linked files.
本明細書において説明した本主題および動作の実施形態は、デジタル電子回路として、またはコンピュータソフトウェア、コンピュータファームウェア、もしくは本明細書において開示した構造およびそれらの構造的等価物を含むコンピュータハードウェアとして、またはそれらのうちの1つもしくは複数のものの組合せとして、実装することができる。本明細書において説明した本主題の実施形態は、データ処理装置によって実行できるように、またはデータ処理装置の動作を制御するために、複数のコンピュータ記憶媒体(または1つのコンピュータ記憶媒体)上に符号化された、1つまたは複数のコンピュータプログラム、すなわちコンピュータプログラム命令の1つまたは複数のモジュールとして、実装することができる。その代わりにまたはそれに加えて、プログラム命令は、情報をデータ処理装置によって実行する目的で適切なレシーバ装置に送信できるように符号化するために生成される、人工的に生成された伝搬信号、例えばマシンにより生成された電気信号、光信号、または電磁信号上に、符号化することもできる。コンピュータ記憶媒体は、コンピュータ可読記憶デバイス、コンピュータ可読記憶基板、ランダムアクセスもしくはシリアルアクセスのメモリアレイもしくはデバイス、またはそれらのうちの1つもしくは複数のものの組合せとすることもでき、あるいはその中に含めることもできる。さらに、コンピュータ記憶媒体は、伝搬信号ではないが、人工的に生成された伝搬信号内に符号化されたコンピュータプログラム命令の供給元または供給先とすることもできる。コンピュータ記憶媒体はまた、1つまたは複数の別々の物理的コンポーネントまたは媒体(例えば複数のCD、ディスク、または他の記憶デバイス)とすることもでき、あるいはその中に含めることもできる。 Embodiments of the subject matter and operations described herein may be implemented as digital electronic circuitry, or as computer software, computer firmware, or computer hardware including the structures disclosed herein and their structural equivalents; It can be implemented as a combination of one or more of them. Embodiments of the present subject matter described herein may be encoded on a plurality of computer storage media (or a single computer storage medium) for execution by or for controlling operation of a data processing apparatus. can be implemented as one or more computer programs, ie, one or more modules of computer program instructions, coded. Alternatively or additionally, the program instructions may be an artificially generated propagated signal, e.g. It can also be encoded onto machine-generated electrical, optical, or electromagnetic signals. The computer storage medium may also be or be included in a computer readable storage device, a computer readable storage substrate, a random or serial access memory array or device, or a combination of one or more thereof. can also Further, a computer storage medium can be a source or destination of computer program instructions encoded within an artificially generated propagated signal, rather than the propagated signal. A computer storage medium can also be or be contained within one or more separate physical components or media (eg, multiple CDs, disks, or other storage devices).
本明細書において説明した動作は、1つまたは複数のコンピュータ可読記憶デバイス上に格納されたかまたは他の供給元から受領したデータに対してデータ処理装置によって実施される動作として、実装することができる。 The operations described herein may be implemented as operations performed by a data processing apparatus on data stored on one or more computer readable storage devices or received from other sources. .
「データ処理装置」という用語は、例としてプログラマブルプロセッサ、コンピュータ、システムオンチップ、または前述したもののうちの複数のもの、もしくは前述したものの組合せを含めて、データを処理するためのあらゆる種類の装置、デバイス、およびマシンを包含する。装置は、専用論理回路、例えばFPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)を含むことができる。装置は、ハードウェアに加えて、当該のコンピュータプログラムのための実行環境を作り出すコード、例えばプロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、クロスプラットフォーム実行環境、仮想マシン、またはそれらのうちの1つもしくは複数のものの組合せを構成するコードを含むこともできる。装置および実行環境は、ウェブサービス、分散コンピューティング、およびグリッドコンピューティングのインフラストラクチャなど、異なるさまざまなコンピューティングモデルインフラストラクチャを実現することができる。 The term "data processing device" means any kind of device for processing data, including, by way of example, a programmable processor, computer, system-on-chip, or any number or combination of the foregoing; Including devices and machines. The device may include dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). The apparatus comprises, in addition to hardware, code that creates an execution environment for the computer program in question, such as processor firmware, protocol stacks, database management systems, operating systems, cross-platform execution environments, virtual machines, or one of them. It can also include code that constitutes a combination of one or more. The devices and execution environments can implement a variety of different computing model infrastructures, such as web services, distributed computing, and grid computing infrastructures.
(プログラム、ソフトウェア、ソフトウェアアプリケーション、スクリプト、またはコードとしても知られる)コンピュータプログラムは、コンパイル型言語またはインタープリタ型言語、宣言型言語または手続き型言語を含む、任意の形態のプログラミング言語で記述することができ、またそれは、スタンドアロンプログラムとして、またはモジュール、コンポーネント、サブルーチン、オブジェクト、もしくはコンピューティング環境で使用するのに適した他のユニットとして、を含む、任意の形態でデプロイすることができる。コンピュータプログラムは、その必要はないが、ファイルシステム内のファイルに対応していてよい。プログラムは、他のプログラムもしくはデータを保持するファイルの一部分(例えばマークアップ言語ドキュメント内に格納された1つもしくは複数のスクリプト)内に、当該のプログラムに専用の単一のファイル内に、または複数の連係されたファイル(例えばコードの1つもしくは複数のモジュール、サブプログラム、もしくは一部分を格納したファイル)内に、格納することができる。コンピュータプログラムは、1つのコンピュータ上で、または1つのサイトに位置するかもしくは複数のサイトにわたって分散され、通信ネットワークによって相互接続された複数のコンピュータ上で実行されるように、デプロイすることができる。 A computer program (also known as a program, software, software application, script, or code) may be written in any form of programming language, including compiled or interpreted, declarative, or procedural languages. and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. Computer programs may, but need not, correspond to files in a file system. A program may reside within a portion of a file holding other programs or data (e.g., one or more scripts stored within a markup language document), within a single file dedicated to that program, or within multiple linked files (eg, files containing one or more modules, subprograms, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers located at one site or distributed across multiple sites and interconnected by a communication network.
本明細書において説明したプロセスおよび論理フローは、アクションを実施するための1つまたは複数のコンピュータプログラムを、入力データに作用し出力を生成することによって実行する、1つまたは複数のプログラマブルプロセッサによって実施され得る。プロセスおよび論理フローは、専用論理回路、例えばFPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)によっても実施され得、装置は、専用論理回路、例えばFPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)として実装することもできる。 The processes and logic flows described herein are implemented by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. can be The processes and logic flows may also be implemented by dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits), and the device may be implemented with dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs. It can also be implemented as an (application specific integrated circuit).
コンピュータプログラムの実行に適したプロセッサとしては、例として、汎用マイクロプロセッサと専用マイクロプロセッサの両方がある。一般に、プロセッサは、読出し専用メモリ、またはランダムアクセスメモリ、またはその両方から、命令およびデータを受領する。コンピュータの不可欠な要素が、命令に従ってアクションを実施するためのプロセッサ、ならびに命令およびデータを格納するための1つまたは複数のメモリデバイスである。一般に、コンピュータはまた、データを格納するための1つまたは複数のマスストレージデバイス、例えば磁気ディスク、光磁気ディスク、または光ディスクを含むか、またはそこからデータを受領し、もしくはそこにデータを転送し、もしくはその両方を行うように動作可能に結合される。しかし、コンピュータは、そのようなデバイスを有している必要はない。さらに、コンピュータは別のデバイスに、例えば、ほんの数例を挙げると、モバイル電話、パーソナルデジタルアシスタント(PDA)、モバイルオーディオプレーヤもしくはモバイルビデオプレーヤ、ゲームコンソール、グローバルポジショニングシステム(GPS)レシーバ、またはポータブル記憶デバイス(例えばユニバーサルシリアルバス(USB)フラッシュドライブ)に、埋め込むことができる。コンピュータプログラム命令およびデータを格納するのに適したデバイスとしては、例として、半導体メモリデバイス、例えばEPROM、EEPROM、およびフラッシュメモリデバイス;磁気ディスク、例えば内蔵ハードディスクまたはリムーバブルディスク;光磁気ディスク;ならびにCD ROMディスクおよびDVD-ROMディスクを含む、あらゆる形態の不揮発性のメモリ、媒体、およびメモリデバイスがある。プロセッサおよびメモリは、専用論理回路によって補完するかまたはそれに組み込むことができる。 Processors suitable for the execution of computer programs include, by way of example, both general and special purpose microprocessors. Generally, a processor receives instructions and data from read-only memory, random-access memory, or both. The essential elements of a computer are a processor, for performing actions according to instructions, and one or more memory devices for storing instructions and data. Generally, a computer also includes, receives data from, or transfers data to one or more mass storage devices, such as magnetic, magneto-optical, or optical disks, for storing data. , or operably coupled to do both. However, a computer need not have such a device. Additionally, the computer may be connected to another device, such as a mobile phone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a global positioning system (GPS) receiver, or portable storage, just to name a few. It can be embedded in a device, such as a Universal Serial Bus (USB) flash drive. Devices suitable for storing computer program instructions and data include, by way of example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices; magnetic disks such as internal or removable disks; magneto-optical disks; and CD ROMs. There are all forms of non-volatile memory, media and memory devices, including disks and DVD-ROM disks. The processor and memory may be supplemented by or incorporated in dedicated logic circuitry.
ユーザとの対話を可能にするために、本明細書において説明した本主題の実施形態は、ユーザに情報を表示するためのディスプレイデバイス、例えばCRT(陰極線管)またはLCD(液晶ディスプレイ)モニタと、ユーザがそれによってコンピュータに入力を行うことのできるキーボードおよびポインティングデバイス、例えばマウスまたはトラックボールとを有するコンピュータ上に実装することができる。他の種類のデバイスを使用して、ユーザとの対話を可能にすることもでき、例えば、ユーザに提供されるフィードバックは、任意の形態の感覚フィードバック、例えば視覚フィードバック、聴覚フィードバック、または触覚フィードバックとすることができ、ユーザからの入力は、音響入力、音声入力、または触覚入力を含む任意の形態で受領することができる。加えて、コンピュータは、ユーザが使用しているデバイスにドキュメントを送出し、そこからドキュメントを受信することによって、例えば、ユーザのクライアントデバイス上のウェブブラウザに、そのウェブブラウザから受信した要求に応答してウェブページを送出することによって、ユーザと対話することができる。 To enable user interaction, embodiments of the present subject matter described herein include a display device, such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to a user; It can be implemented on a computer having a keyboard and pointing device, such as a mouse or trackball, by which a user can provide input to the computer. Other types of devices can also be used to enable interaction with the user, e.g., the feedback provided to the user can be any form of sensory feedback, e.g., visual, auditory, or tactile feedback. and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, the computer responds to requests received from, for example, a web browser on the user's client device by sending documents to and receiving documents from the device the user is using. You can interact with users by sending web pages through
本明細書において説明した本主題の実施形態は、例えばデータサーバとしてのバックエンドコンポーネントを含むコンピューティングシステム内、またはミドルウェアコンポーネント、例えばアプリケーションサーバを含むコンピューティングシステム内、またはフロントエンドコンポーネント、例えば本明細書において説明した本主題の一実装形態とユーザがそれを通じて対話することのできるグラフィカルユーザインターフェースもしくはウェブブラウザを有するクライアントコンピュータを含むコンピューティングシステム内、または1つもしくは複数のそのようなバックエンドコンポーネント、ミドルウェアコンポーネント、もしくはフロントエンドコンポーネントの任意の組合せを含むコンピューティングシステム内に、実装することができる。システムのコンポーネント同士は、任意の形態または媒体のデジタルデータ通信、例えば通信ネットワークによって、相互接続され得る。通信ネットワークの例としては、ローカルエリアネットワーク(「LAN」)および広域ネットワーク(「WAN」)、インターネットワーク(例えばインターネット)、ならびにピアツーピアネットワーク(例えばアドホックピアツーピアネットワーク)がある。 Embodiments of the present subject matter described herein may be implemented within a computing system that includes back-end components, such as data servers, or within computing systems that include middleware components, such as application servers, or front-end components, such as those described herein. in a computing system including a client computer having a graphical user interface or web browser through which a user can interact with an implementation of the subject matter described in the document, or one or more such backend components; It can be implemented in a computing system including any combination of middleware components or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, eg, a communication network. Examples of communication networks include local area networks (“LAN”) and wide area networks (“WAN”), internetworks (eg, the Internet), and peer-to-peer networks (eg, ad-hoc peer-to-peer networks).
コンピューティングシステムは、クライアントおよびサーバを含むことができる。クライアントとサーバは一般に、互いに遠隔にあり、典型的には通信ネットワークを通じて対話する。クライアントとサーバの関係は、それぞれのコンピュータ上で実行され、互いにクライアント-サーバ関係を有する、コンピュータプログラムによって生じる。いくつかの実施形態では、(例えばクライアントデバイスと対話しているユーザにデータを表示し、そのユーザからユーザ入力を受領する目的で)サーバがデータ(例えばHTMLページ)をクライアントデバイスに送信する。クライアントデバイスにおいて生成されたデータ(例えばユーザ対話の結果)は、クライアントデバイスからサーバにおいて受信され得る。 The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, a server sends data (eg, HTML pages) to a client device (eg, for the purposes of displaying data to and receiving user input from a user interacting with the client device). Data generated at the client device (eg, results of user interactions) may be received at the server from the client device.
本明細書は、実装形態の多くの具体的詳細を含んでいるが、これらは、任意の発明の範囲または特許請求され得るものの範囲に対する限定と解釈するのではなく、特定の発明の特定の実施形態に特有の特徴についての説明と解釈すべきである。本明細書において別々の実施形態のコンテキストの中で説明される、ある特定の特徴は、単一の実施形態において組み合わせて実装することもできる。反対に、単一の実施形態のコンテキストの中で説明されるさまざまな特徴は、複数の実施形態において別々に、または任意の適切な部分組合せで、実装することもできる。さらに、特徴については上で、ある特定の組合せで作用するものとして説明されていることがあり、そのようなものとして最初に特許請求されていることすらあるが、特許請求された組合せからの1つまたは複数の特徴を、場合によってはその組合せから削除することができ、特許請求された組合せが、部分組合せまたは部分組合せの変形を対象としてよい。 While this specification contains many specific details of implementations, these are not to be construed as limitations on the scope of any invention or what may be claimed, but rather by specific implementations of the particular invention. It should be interpreted as a description of features specific to the form. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Further, features may have been described above as operating in a particular combination, and may even have been originally claimed as such, but only one from the claimed combination. One or more features may optionally be omitted from the combination, and the claimed combination may cover subcombinations or variations of subcombinations.
同様に、動作は図面中に特定の順序で描かれているが、これは、望ましい結果を達成するために、そのような動作が図示のその特定の順序で、もしくは順番に実施されること、または図示の全ての動作が実施されることを要求するものと理解すべきではない。ある特定の状況下では、マルチタスキングおよび並列処理が有利となることがある。さらに、上で説明した実施形態におけるさまざまなシステムコンポーネントの分離は、全ての実施形態においてそのような分離を要求するものと理解すべきではなく、説明したプログラムコンポーネントとシステムは一般に、単一のソフトウェア製品内に一緒に統合するかまたは複数のソフトウェア製品にパッケージ化できることを理解されたい。 Similarly, although operations have been illustrated in the figures in a particular order, this indicates that such operations are performed in that particular order shown, or in sequence, to achieve desirable results. or should not be construed as requiring that all illustrated acts be performed. Multitasking and parallel processing can be advantageous under certain circumstances. Furthermore, the separation of various system components in the above-described embodiments should not be understood to require such separation in all embodiments, as the described program components and system are generally implemented in a single software package. It should be appreciated that they can be integrated together within a product or packaged into multiple software products.
以上、本主題の特定の実施形態について説明してきた。他の実施形態が、添付の特許請求の範囲に記載の範囲内にある。場合によっては、特許請求の範囲に記載されたアクションを異なる順序で実施し、それでもなお、望ましい結果を達成することができる。加えて、添付の図中に描かれたプロセスは、望ましい結果を達成するために、図示の特定の順序、または順番を必ずしも要求するとは限らない。ある特定の実装形態では、マルチタスキングおよび並列処理が有利となることがある。 Particular embodiments of the present subject matter have been described above. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Additionally, the processes depicted in the accompanying figures do not necessarily require a particular order or order of illustration to achieve desirable results. Multitasking and parallel processing may be advantageous in certain implementations.
100 例示的環境、システム
102 ネットワーク
104 電子ドキュメントサーバ
105 電子ドキュメント
106 ユーザデバイス、クライアントデバイス
108 要求
110 デジタルコンポーネント配信システム、DCDS
112 デジタルコンポーネントデータベース
114 応答データ、応答
120 ビデオ合成プログラム(VCP)
130 ビデオレンダリングプロセッサ(VRP)
132 フラットナ
134 分類器
136 エクスポータ
140 テンプレートインスタンス化システム
150 サードパーティ
200 例示的データフロー、データフロー、プロセス
202 ビデオプロジェクトファイル
300 例示的プロセス、プロセス
400 例示的コンピュータシステム、システム
410 プロセッサ、コンポーネント
420 メモリ、コンポーネント
430 記憶デバイス、コンポーネント
440 入力/出力デバイス、コンポーネント
450 システムバス
460 ディスプレイデバイス
100 illustrative environments, systems
102 network
104 Electronic Document Server
105 electronic documents
106 User Device, Client Device
108 requests
110 Digital Component Distribution System, DCDS
112 Digital Component Database
114 response data, response
120 Video Compositing Program (VCP)
130 Video Rendering Processor (VRP)
132 Flatna
134 classifier
136 Exporter
140 template instantiation system
150 Third Party
200 Exemplary Data Flows, Data Flows, Processes
202 Video Project File
300 illustrative processes, processes
400 Exemplary Computer System, System
410 processors, components
420 memory, components
430 storage devices, components
440 Input/Output Devices, Components
450 system bus
460 display device
Claims (14)
1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを含む、ビデオをレンダリングするためのファイルを、1つまたは複数のコンピュータによって識別するステップと、
ビデオをレンダリングするための前記ファイルの1つまたは複数のフィールドの解析に基づいて、前記1つまたは複数の静的レイヤおよび前記1つまたは複数の動的レイヤを、前記1つまたは複数のコンピュータによって検出するステップであって、各動的レイヤが、可変コンポーネントであることを示すコメントを含む、ステップと、
前記ファイルの前記1つまたは複数の静的レイヤを、前記1つまたは複数のコンピュータによってレンダリングするステップと、
前記レンダリングされた1つまたは複数の静的レイヤに基づいて、前記1つまたは複数の静的レイヤおよび前記1つまたは複数の動的レイヤを示すテンプレートを、前記1つまたは複数のコンピュータによって生成するステップと、
ユーザデバイスから、ユーザ情報を含む、前記ビデオを求める要求を、前記1つまたは複数のコンピュータによって受信するステップと、
前記ユーザ情報に基づいて、動的レイヤに挿入されるように指定された変数定義を、前記1つまたは複数のコンピュータによって決定するステップと、
前記1つまたは複数の動的レイヤを、前記変数定義を使用して、前記1つまたは複数のコンピュータによってレンダリングするステップであって、前記1つまたは複数の動的レイヤを、前記変数定義を使用してレンダリングするステップが、前記変数定義を使用して前記テンプレートを埋めるステップを含む、ステップと、
前記レンダリングされた1つまたは複数の静的レイヤおよび前記レンダリングされた1つまたは複数の動的レイヤから、再生用の合成ビデオを、前記1つまたは複数のコンピュータによって生成するステップと
を含む、コンピュータ実装方法。 A computer-implemented method for efficient dynamic rendering of video, comprising:
identifying, by one or more computers, a file for rendering a video that includes one or more static layers and one or more dynamic layers;
said one or more static layers and said one or more dynamic layers based on analysis of one or more fields of said file for rendering a video; detecting, wherein each dynamic layer includes a comment indicating that it is a variable component;
rendering the one or more static layers of the file by the one or more computers;
generating, by the one or more computers, a template showing the one or more static layers and the one or more dynamic layers based on the rendered one or more static layers; a step;
receiving by the one or more computers a request for the video, including user information, from a user device;
determining, by the one or more computers, variable definitions designated to be inserted into a dynamic layer based on the user information;
rendering the one or more dynamic layers by the one or more computers using the variable definitions, wherein the one or more dynamic layers are rendered using the variable definitions; and rendering with the variable definition includes filling the template with the variable definition ;
generating, by the one or more computers, a composite video for playback from the rendered one or more static layers and the rendered one or more dynamic layers. How to implement.
命令を含む1つまたは複数のメモリ要素であって、前記命令が、実行されると前記1つまたは複数のプロセッサに、
1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを含む、ビデオをレンダリングするためのファイルを識別すること、
ビデオをレンダリングするための前記ファイルの1つまたは複数のフィールドの解析に基づいて、前記1つまたは複数の静的レイヤおよび前記1つまたは複数の動的レイヤを検出することであって、各動的レイヤが、可変コンポーネントであることを示すコメントを含む、検出すること、
前記ファイルの前記1つまたは複数の静的レイヤをレンダリングすること、
前記レンダリングされた1つまたは複数の静的レイヤに基づいて、前記1つまたは複数の静的レイヤおよび前記1つまたは複数の動的レイヤを示すテンプレートを生成すること、
ユーザデバイスから、ユーザ情報を含む、前記ビデオを求める要求を受信すること、
前記ユーザ情報に基づいて、動的レイヤに挿入されるように指定された変数定義を決定すること、
前記1つまたは複数の動的レイヤを、前記変数定義を使用してレンダリングすることであって、前記1つまたは複数の動的レイヤを、前記変数定義を使用してレンダリングすることが、前記変数定義を使用して前記テンプレートを埋めることを含む、こと、ならびに
前記レンダリングされた1つまたは複数の静的レイヤおよび前記レンダリングされた1つまたは複数の動的レイヤから、再生用の合成ビデオを生成すること
を含む動作を実施させる、1つまたは複数のメモリ要素と
を備える、システム。 one or more processors;
one or more memory elements containing instructions that, when executed, cause the one or more processors to:
identifying a file for rendering a video containing one or more static layers and one or more dynamic layers;
detecting the one or more static layers and the one or more dynamic layers based on analysis of one or more fields of the file for rendering a video; detecting that the target layer contains a comment indicating that it is a variable component;
rendering the one or more static layers of the file;
generating a template showing the one or more static layers and the one or more dynamic layers based on the rendered one or more static layers;
Receiving a request for the video, including user information, from a user device;
determining variable definitions designated to be inserted into a dynamic layer based on the user information;
rendering the one or more dynamic layers using the variable definitions ; rendering the one or more dynamic layers using the variable definitions; filling said template with a definition; and generating a composite video for playback from said rendered one or more static layers and said rendered one or more dynamic layers. and one or more memory elements that cause operations to be performed, including:
1つまたは複数の静的レイヤおよび1つまたは複数の動的レイヤを含む、ビデオをレンダリングするためのファイルを識別することと、
ビデオをレンダリングするための前記ファイルの1つまたは複数のフィールドの解析に基づいて、前記1つまたは複数の静的レイヤおよび前記1つまたは複数の動的レイヤを検出することであって、各動的レイヤが、可変コンポーネントであることを示すコメントを含む、検出することと、
前記ファイルの前記1つまたは複数の静的レイヤをレンダリングすることと、
前記レンダリングされた1つまたは複数の静的レイヤに基づいて、前記1つまたは複数の静的レイヤおよび前記1つまたは複数の動的レイヤを示すテンプレートを生成することと、
ユーザデバイスから、ユーザ情報を含む、前記ビデオを求める要求を受信することと、
前記ユーザ情報に基づいて、動的レイヤに挿入されるように指定された変数定義を決定することと、
前記1つまたは複数の動的レイヤを、前記変数定義を使用してレンダリングすることであって、前記1つまたは複数の動的レイヤを、前記変数定義を使用してレンダリングすることが、前記変数定義を使用して前記テンプレートを埋めることを含む、ことと、
前記レンダリングされた1つまたは複数の静的レイヤおよび前記レンダリングされた1つまたは複数の動的レイヤから、再生用の合成ビデオを生成することと
を含む動作を実施させる、非一時的コンピュータ記憶媒体。 A non-transitory computer storage medium encoded with instructions that, when executed by a distributed computing system, cause the distributed computing system to:
identifying a file for rendering a video that includes one or more static layers and one or more dynamic layers;
detecting the one or more static layers and the one or more dynamic layers based on analysis of one or more fields of the file for rendering a video; detecting that the target layer contains a comment indicating that it is a variable component;
rendering the one or more static layers of the file;
generating a template indicative of the one or more static layers and the one or more dynamic layers based on the rendered one or more static layers;
receiving a request for the video, including user information, from a user device;
determining variable definitions designated to be inserted into a dynamic layer based on the user information;
rendering the one or more dynamic layers using the variable definitions ; rendering the one or more dynamic layers using the variable definitions; filling the template with a definition; and
generating a composite video for playback from the rendered static layer(s) and the rendered dynamic layer(s). .
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/032889 WO2021230872A1 (en) | 2020-05-14 | 2020-05-14 | Rendering video having dynamic components |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2022536009A JP2022536009A (en) | 2022-08-12 |
JP7248802B2 true JP7248802B2 (en) | 2023-03-29 |
Family
ID=71016631
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021539667A Active JP7248802B2 (en) | 2020-05-14 | 2020-05-14 | Rendering video with dynamic components |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230058512A1 (en) |
EP (1) | EP3928223A1 (en) |
JP (1) | JP7248802B2 (en) |
KR (1) | KR102519049B1 (en) |
CN (1) | CN113966619A (en) |
WO (1) | WO2021230872A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11587208B2 (en) * | 2021-05-26 | 2023-02-21 | Qualcomm Incorporated | High quality UI elements with frame extrapolation |
CN117667278A (en) * | 2022-08-31 | 2024-03-08 | 华为技术有限公司 | Interface display method, device and system |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050286759A1 (en) | 2004-06-28 | 2005-12-29 | Microsoft Corporation | Interactive viewpoint video system and process employing overlapping images of a scene captured from viewpoints forming a grid |
US10002115B1 (en) | 2014-09-29 | 2018-06-19 | Amazon Technologies, Inc. | Hybrid rendering of a web page |
Family Cites Families (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP4167747B2 (en) * | 1998-04-13 | 2008-10-22 | 株式会社ルネサステクノロジ | Frequency variable oscillation circuit and phase synchronization circuit using the same |
WO2012160499A1 (en) * | 2011-05-23 | 2012-11-29 | Strangeloop Networks, Inc. | Optimized rendering of dynamic content |
WO2013116577A1 (en) * | 2012-01-31 | 2013-08-08 | Newblue, Inc. | Systems and methods for media personalization using templates |
MY192602A (en) * | 2013-03-14 | 2022-08-29 | Wix Com Ltd | Device, system, and method of website building by utilizing data lists |
GB2520334B (en) * | 2013-11-18 | 2015-11-25 | Helen Bradley Lennon | A video broadcast system and a method of disseminating video content |
US9361635B2 (en) * | 2014-04-14 | 2016-06-07 | Yahoo! Inc. | Frequent markup techniques for use in native advertisement placement |
US9996976B2 (en) * | 2014-05-05 | 2018-06-12 | Avigilon Fortress Corporation | System and method for real-time overlay of map features onto a video feed |
CN105320662B (en) * | 2014-06-10 | 2019-09-20 | 腾讯科技（北京）有限公司 | Webpage generating method and device |
KR101980414B1 (en) | 2015-02-06 | 2019-08-29 | 전자부품연구원 | Method and System for Extensible Video Rendering |
US11412312B2 (en) * | 2016-09-28 | 2022-08-09 | Idomoo Ltd | System and method for generating customizable encapsulated media files |
CN109308729B (en) * | 2017-07-27 | 2023-01-24 | 阿里巴巴集团控股有限公司 | Picture synthesis processing method, device and system |
CN110580163B (en) * | 2018-06-07 | 2022-03-08 | 腾讯科技（深圳）有限公司 | Method and device for manufacturing pendant through template and storage equipment |
US11423063B2 (en) * | 2018-07-31 | 2022-08-23 | Salesforce, Inc. | Flattening hierarchical database records using inverted indexing |
-
2020
- 2020-05-14 KR KR1020217021523A patent/KR102519049B1/en active IP Right Grant
- 2020-05-14 CN CN202080008316.9A patent/CN113966619A/en active Pending
- 2020-05-14 US US17/417,268 patent/US20230058512A1/en active Pending
- 2020-05-14 EP EP20731266.1A patent/EP3928223A1/en active Pending
- 2020-05-14 WO PCT/US2020/032889 patent/WO2021230872A1/en unknown
- 2020-05-14 JP JP2021539667A patent/JP7248802B2/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050286759A1 (en) | 2004-06-28 | 2005-12-29 | Microsoft Corporation | Interactive viewpoint video system and process employing overlapping images of a scene captured from viewpoints forming a grid |
JP2006012161A (en) | 2004-06-28 | 2006-01-12 | Microsoft Corp | Interactive viewpoint video system and process |
US10002115B1 (en) | 2014-09-29 | 2018-06-19 | Amazon Technologies, Inc. | Hybrid rendering of a web page |
Also Published As
Publication number | Publication date |
---|---|
CN113966619A (en) | 2022-01-21 |
US20230058512A1 (en) | 2023-02-23 |
KR20210141444A (en) | 2021-11-23 |
WO2021230872A1 (en) | 2021-11-18 |
JP2022536009A (en) | 2022-08-12 |
KR102519049B1 (en) | 2023-04-06 |
EP3928223A1 (en) | 2021-12-29 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN109863527B (en) | Method and system for server-side rendering of rendered local content | |
US20130326333A1 (en) | Mobile Content Management System | |
KR102626274B1 (en) | Image Replacement Restore | |
US11269953B2 (en) | Server-based conversion of autoplay content to click-to-play content | |
US10084878B2 (en) | Systems and methods for hosted application marketplaces | |
WO2015041711A1 (en) | Systems and methods for managing loading priority or sequencing of fragments of a web object | |
CN102027476A (en) | File access via conduit application | |
US11119973B2 (en) | Managing white space in a portal web page | |
JP7248802B2 (en) | Rendering video with dynamic components | |
CN110968314A (en) | Page generation method and device | |
CN113495730A (en) | Resource package generation and analysis method and device | |
EP2763051B1 (en) | Serving font glyphs | |
US11361048B2 (en) | Conditional interpretation of a single style definition identifier on a resource | |
CN113608737A (en) | Page generation method, device, equipment and medium | |
CN117951409A (en) | Page nested relation element processing method, device, equipment and storage medium | |
CN117032666A (en) | Page editing method and device based on editor, terminal equipment and storage medium | |
US20170315972A1 (en) | Transforming web-based digital content to enable native rendering | |
Le | Using Web Services for Image Processing in a Desktop Widgets Engine |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210714 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20210714 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20220920 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20221107 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20230220 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20230316 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7248802Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |