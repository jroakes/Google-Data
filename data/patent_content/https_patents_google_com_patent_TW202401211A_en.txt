TW202401211A - Gesture detection via image capture of subdermal tissue from a wrist-pointing camera system - Google Patents
Gesture detection via image capture of subdermal tissue from a wrist-pointing camera system Download PDFInfo
- Publication number
- TW202401211A TW202401211A TW112121356A TW112121356A TW202401211A TW 202401211 A TW202401211 A TW 202401211A TW 112121356 A TW112121356 A TW 112121356A TW 112121356 A TW112121356 A TW 112121356A TW 202401211 A TW202401211 A TW 202401211A
- Authority
- TW
- Taiwan
- Prior art keywords
- user
- wrist
- gesture
- electromagnetic radiation
- radiation
- Prior art date
Links
- 238000001514 detection method Methods 0.000 title claims abstract description 42
- 230000005855 radiation Effects 0.000 claims abstract description 63
- 238000000034 method Methods 0.000 claims abstract description 48
- 210000000707 wrist Anatomy 0.000 claims abstract description 42
- 230000005670 electromagnetic radiation Effects 0.000 claims abstract description 26
- 230000010412 perfusion Effects 0.000 claims abstract description 16
- 230000008859 change Effects 0.000 claims abstract description 11
- 230000015654 memory Effects 0.000 claims description 78
- 239000013060 biological fluid Substances 0.000 claims description 25
- 238000012545 processing Methods 0.000 claims description 17
- 238000004590 computer program Methods 0.000 claims description 15
- 230000003190 augmentative effect Effects 0.000 claims description 13
- 238000013528 artificial neural network Methods 0.000 claims description 7
- 238000005070 sampling Methods 0.000 claims description 3
- 230000005057 finger movement Effects 0.000 abstract description 10
- 230000002500 effect on skin Effects 0.000 abstract description 2
- 238000004891 communication Methods 0.000 description 23
- 230000003287 optical effect Effects 0.000 description 15
- 238000010586 diagram Methods 0.000 description 14
- 239000004984 smart glass Substances 0.000 description 13
- 230000033001 locomotion Effects 0.000 description 12
- 210000003491 skin Anatomy 0.000 description 11
- 210000003743 erythrocyte Anatomy 0.000 description 9
- 238000012549 training Methods 0.000 description 9
- 238000013186 photoplethysmography Methods 0.000 description 7
- 230000006870 function Effects 0.000 description 5
- 238000005286 illumination Methods 0.000 description 5
- 230000003993 interaction Effects 0.000 description 5
- 230000008569 process Effects 0.000 description 5
- 238000013527 convolutional neural network Methods 0.000 description 4
- 239000011521 glass Substances 0.000 description 4
- 230000001413 cellular effect Effects 0.000 description 3
- 210000004207 dermis Anatomy 0.000 description 3
- 210000002615 epidermis Anatomy 0.000 description 3
- 238000013507 mapping Methods 0.000 description 3
- 238000005259 measurement Methods 0.000 description 3
- 238000012986 modification Methods 0.000 description 3
- 230000004048 modification Effects 0.000 description 3
- 206010033675 panniculitis Diseases 0.000 description 3
- 230000001953 sensory effect Effects 0.000 description 3
- 210000000434 stratum corneum Anatomy 0.000 description 3
- 210000004304 subcutaneous tissue Anatomy 0.000 description 3
- 230000000007 visual effect Effects 0.000 description 3
- 230000004888 barrier function Effects 0.000 description 2
- 230000008901 benefit Effects 0.000 description 2
- 210000004369 blood Anatomy 0.000 description 2
- 239000008280 blood Substances 0.000 description 2
- 230000017531 blood circulation Effects 0.000 description 2
- 210000004027 cell Anatomy 0.000 description 2
- 238000007796 conventional method Methods 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 238000003384 imaging method Methods 0.000 description 2
- 230000002452 interceptive effect Effects 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 230000000541 pulsatile effect Effects 0.000 description 2
- 238000001429 visible spectrum Methods 0.000 description 2
- 102000001554 Hemoglobins Human genes 0.000 description 1
- 108010054147 Hemoglobins Proteins 0.000 description 1
- 229920005830 Polyurethane Foam Polymers 0.000 description 1
- 230000009471 action Effects 0.000 description 1
- 230000004913 activation Effects 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 230000000712 assembly Effects 0.000 description 1
- 238000000429 assembly Methods 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 230000009977 dual effect Effects 0.000 description 1
- 239000010408 film Substances 0.000 description 1
- 210000004247 hand Anatomy 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 239000004033 plastic Substances 0.000 description 1
- 229920003023 plastic Polymers 0.000 description 1
- 239000011496 polyurethane foam Substances 0.000 description 1
- 238000011176 pooling Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 229910052709 silver Inorganic materials 0.000 description 1
- 239000004332 silver Substances 0.000 description 1
- -1 silver halide Chemical class 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 239000010409 thin film Substances 0.000 description 1
- 239000013598 vector Substances 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/017—Gesture based interaction, e.g. based on a set of recognized hand gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F1/00—Details not covered by groups G06F3/00 - G06F13/00 and G06F21/00
- G06F1/16—Constructional details or arrangements
- G06F1/1613—Constructional details or arrangements for portable computers
- G06F1/163—Wearable computers, e.g. on a belt
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/011—Arrangements for interaction with the human body, e.g. for user immersion in virtual reality
- G06F3/015—Input arrangements based on nervous system activity detection, e.g. brain waves [EEG] detection, electromyograms [EMG] detection, electrodermal response detection
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/0304—Detection arrangements using opto-electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/766—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using regression, e.g. by projecting features on hyperplanes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/82—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using neural networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/20—Scenes; Scene-specific elements in augmented reality scenes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/12—Fingerprints or palmprints
- G06V40/13—Sensors therefor
- G06V40/1318—Sensors therefor using electro-optical elements or layers, e.g. electroluminescent sensing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/15—Biometric patterns based on physiological signals, e.g. heartbeat, blood flow
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/20—Movements or behaviour, e.g. gesture recognition
- G06V40/28—Recognition of hand or arm movements, e.g. recognition of deaf sign language
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/011—Arrangements for interaction with the human body, e.g. for user immersion in virtual reality
Abstract
Description
本描述係關於判定在擴增實境(AR)系統中用於控制物件之手勢。This description relates to determining gestures used to control objects in augmented reality (AR) systems.
擴增實境(AR)係一真實世界環境之一互動式體驗，其中藉由電腦產生之感知資訊(有時跨多種感官模態，包含視覺、聽覺及/或觸覺)來增強存在於真實世界中之物件。一些AR系統使用智慧型眼鏡來提供此一互動式體驗，該等智慧型眼鏡可經由安裝於一框架上之一相機以及框架中之波導及鏡片提供視覺資訊，及經由框架提供音訊及觸覺資訊。Augmented Reality (AR) is an interactive experience of a real-world environment in which presence in the real world is enhanced by computer-generated sensory information (sometimes across multiple sensory modalities, including vision, hearing, and/or touch) objects in. Some AR systems provide this interactive experience using smart glasses that provide visual information through a camera mounted on a frame and waveguides and lenses in the frame, as well as audio and tactile information through the frame.
本文中所描述之實施方案係關於識別擴增實境(AR)系統之基於手勢之輸入。例如，AR系統之使用者可能希望捏縮一虛擬物件(例如，一鉛筆)以使該虛擬物件在一顯示場中四處移動。因此，一手勢偵測系統可需要識別一捏縮運動。一些AR系統可區分手勢運動之細微差別。此之一實例將為食指-拇指捏縮與中指-拇指捏縮之間的一區分。更進一步而言，一手指上之不同位置可能指示一顯示器上之不同物件選擇。此手勢區分對於習知方法而言可能係困難的。然而，經改良技術係基於在腕處光學量測之灌注指數(PI)之變化可提供關於手及手指移動的資訊之觀察。此外，PI之全二維成像可以足夠準確度精確定位此等變化以執行手勢之間的細微區分。Implementations described herein relate to recognizing gesture-based input for augmented reality (AR) systems. For example, a user of an AR system may wish to pinch a virtual object (eg, a pencil) to move the virtual object around a display field. Therefore, a gesture detection system may need to recognize a pinching motion. Some AR systems can distinguish subtle differences in gesture movements. An example of this would be a distinction between index finger-thumb pinch and middle finger-thumb pinch. Furthermore, different positions on a finger may indicate different object selections on a display. This gesture distinction may be difficult for conventional methods. However, improved techniques based on the observation of changes in perfusion index (PI) optically measured at the wrist can provide information about hand and finger movements. In addition, PI's full 2D imaging can pinpoint these changes with enough accuracy to perform fine distinctions between gestures.
在一個一般態樣中，一種方法可包含捕獲穿過一使用者的腕之皮膚之一影像序列。該方法亦可包含基於該影像序列判定一生物流體流動度量。該方法可進一步包含基於該生物流體流動度量判定由該使用者形成之一手勢。該方法可進一步包含基於該手勢觸發與在一擴增實境(AR)系統中顯示一物件相關的一命令之執行。In a general aspect, a method may include capturing a sequence of images across the skin of a user's wrist. The method may also include determining a biological fluid flow metric based on the image sequence. The method may further include determining a gesture performed by the user based on the biological fluid flow metric. The method may further include triggering execution of a command related to displaying an object in an augmented reality (AR) system based on the gesture.
在另一一般態樣中，一種擴增實境(AR)系統包含經組態以捕獲穿過一使用者的腕之皮膚之一影像序列之一影像捕獲裝置。該AR系統亦包含耦合至一記憶體之手勢偵測電路。該手勢偵測電路經組態以基於該影像序列判定一生物流體流動度量。該手勢偵測電路亦經組態以基於該生物流體流動度量判定由該使用者形成之一手勢。該手勢偵測電路進一步經組態以基於該手勢觸發與在一擴增實境(AR)系統中顯示一物件相關的一命令之執行。In another general aspect, an augmented reality (AR) system includes an image capture device configured to capture a sequence of images across the skin of a user's wrist. The AR system also includes gesture detection circuitry coupled to a memory. The gesture detection circuit is configured to determine a biological fluid flow metric based on the image sequence. The gesture detection circuit is also configured to determine a gesture formed by the user based on the biofluid flow measure. The gesture detection circuit is further configured to trigger execution of a command related to displaying an object in an augmented reality (AR) system based on the gesture.
在另一一般態樣中，一種電腦程式產品包括一非暫時性儲存媒體，該電腦程式產品包含程式碼，該程式碼在由處理電路執行時引起該處理電路執行一方法。該方法可包含捕獲穿過一使用者的腕之皮膚之一影像序列。該方法亦可包含基於該影像序列判定一生物流體流動度量。該方法可進一步包含基於該生物流體流動度量判定由該使用者形成之一手勢。該方法可進一步包含基於該手勢觸發與在一擴增實境(AR)系統中顯示一物件相關的一命令之執行。In another general aspect, a computer program product includes a non-transitory storage medium, the computer program product includes program code that, when executed by a processing circuit, causes the processing circuit to perform a method. The method may include capturing a sequence of images across the skin of a user's wrist. The method may also include determining a biological fluid flow metric based on the image sequence. The method may further include determining a gesture performed by the user based on the biological fluid flow metric. The method may further include triggering execution of a command related to displaying an object in an augmented reality (AR) system based on the gesture.
在隨附圖式及下文描述中闡述一或多個實施方案之細節。將從描述及圖式且從發明申請專利範圍明白其他特徵。The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features will be apparent from the description and drawings and from the patentable scope of the invention.
相關申請案之交叉參考Cross-references to related applications
本申請案係2022年6月29日申請之美國申請案第17/809,772號之一接續申請案且主張其優先權，該案揭示內容之全文以引用的方式併入本文中。This application is a continuation of US Application No. 17/809,772 filed on June 29, 2022 and claims priority. The full text of the disclosure of this application is incorporated herein by reference.
AR系統之一挑戰係提供智慧型眼鏡100與使用者之間之一穩健介面。一些介面利用使用者手勢來實現各種命令。一穩健介面可能夠區別一拇指-食指捏縮與一拇指-中指捏縮。One of the challenges of AR systems is to provide a robust interface between the smart glasses 100 and the user. Some interfaces use user gestures to implement various commands. A robust interface might be able to differentiate between a thumb-index finger pinch and a thumb-middle finger pinch.
用以提供一穩健AR介面之一習知方法包含使用安裝於一智慧型眼鏡框架上之一面向世界RGB相機來提供影像，自此，一骨架手追蹤用於完整手/手指互動及手勢推斷。然而，可能存在與一面向世界RGB相機之使用有關之一些問題。例如，安裝於智慧型眼鏡之一框架上(通常在一鉸鏈附近)之此一面向世界RGB相機具有消耗相對大量功率之一相機感測器及一影像堆疊處理器(ISP)。歸因於此大功率消耗，使用來自面向世界RGB相機之RBG影像來推斷使用者手勢之一技術問題係僅可少量使用面向世界RGB相機。One known method for providing a robust AR interface involves using a world-facing RGB camera mounted on a smart glasses frame to provide images, from which a skeletal hand tracking is used for complete hand/finger interaction and gesture inference. However, there may be some problems associated with the use of a world-facing RGB camera. For example, a world-facing RGB camera mounted on a frame of smart glasses (usually near a hinge) has a camera sensor and an image stack processor (ISP) that consume a relatively large amount of power. Due to this high power consumption, a technical issue with using RBG images from world-facing RGB cameras to infer user gestures is that world-facing RGB cameras are only available in small quantities.
上述技術問題之一技術解決方案包含基於自一紅外線(即，近紅外線)相機獲取之穿過一使用者的腕之皮膚之一影像序列判定由該使用者形成之手勢。在論述此技術解決方案之細節之前，在圖1A至圖1D中綜述一例示性AR系統。One technical solution to the above technical problem involves determining a gesture formed by a user based on a sequence of images obtained from an infrared (ie, near-infrared) camera passing through the skin of the user's wrist. Before discussing the details of this technical solution, an exemplary AR system is reviewed in Figures 1A-1D.
圖1A繪示佩戴用於一擴增實境(AR)系統中之一例示性頭戴式可穿戴裝置之一使用者。在此實例中，出於論述及繪示之目的，例示性頭戴式可穿戴裝置100係呈包含顯示能力及運算/處理能力之例示性智慧型眼鏡之形式。待在本文中描述之原理可適用於具有及不具有顯示能力及/或運算/處理能力兩者之其他類型之眼鏡。圖1B係圖1A中所展示之例示性頭戴式可穿戴裝置100之一前視圖，圖1C係一後視圖，且圖1D係一透視圖。如上文所述，在一些實例中，例示性頭戴式可穿戴裝置100可採取一副智慧型眼鏡或擴增實境眼鏡之形式。1A illustrates a user wearing an exemplary head-mounted wearable device for use in an augmented reality (AR) system. In this example, for purposes of discussion and illustration, the exemplary head-mounted wearable device 100 is in the form of exemplary smart glasses that include display capabilities and computing/processing capabilities. The principles to be described herein may be applied to other types of glasses, both with and without display capabilities and/or computing/processing capabilities. FIG. 1B is a front view of the exemplary head-mounted wearable device 100 shown in FIG. 1A , FIG. 1C is a rear view, and FIG. 1D is a perspective view. As discussed above, in some examples, the exemplary head-mounted wearable device 100 may take the form of a pair of smart glasses or augmented reality glasses.
如圖1B至圖1D中所展示，例示性頭戴式可穿戴裝置100包含一框架102。框架102包含由包圍呈鏡片107之形式之各自光學部分的邊緣部分103界定之一前框架部分，其中一橋接部分109連接邊緣部分103。臂部分105係藉由鉸鏈部分110在各自邊緣部分103處耦合(例如，可樞轉地或可旋轉地耦合)至前框架。在一些實例中，鏡片107可為矯正/處方鏡片。在一些實例中，鏡片107可為包含不一定併有矯正/處方參數之玻璃及/或塑膠部分之一光學材料。As shown in FIGS. 1B-1D , the exemplary head-mounted wearable device 100 includes a frame 102 . The frame 102 includes a front frame portion defined by an edge portion 103 surrounding respective optical portions in the form of lenses 107, with a bridge portion 109 connecting the edge portions 103. The arm portions 105 are coupled (eg, pivotably or rotatably coupled) to the front frame at respective edge portions 103 by hinge portions 110 . In some examples, lenses 107 may be corrective/prescription lenses. In some examples, lens 107 may be an optical material including glass and/or plastic portions that do not necessarily have corrective/prescription parameters.
一顯示裝置104可耦合於框架102之一部分中。在圖1B及圖1C中所展示之實例中，顯示裝置104係耦合於框架102之臂部分105中。在顯示裝置104耦合於臂部分105中之情況下，一可視區(eye box) 140朝向(若干)鏡片107延伸，用於在一輸出耦合器144處輸出內容，在輸出耦合器144處使用者可看見由顯示裝置104輸出之內容。在一些實例中，輸出耦合器144可與(若干)鏡片107實質上重合。在一些實例中，頭戴式可穿戴裝置100亦可包含一音訊輸出裝置106 (舉例而言，諸如一或多個揚聲器)、一照明裝置108、一感測系統111、一控制系統112、至少一個處理器114及一影像捕獲裝置116或相機116。相機(或影像捕獲裝置) 116可經由一快門觸發器或按鈕捕獲影像；快門觸發器經組態以引起一快門打開以允許自一場景反射或散射朝向影像捕獲裝置116之光入射於一光偵測器(例如，一電荷耦合裝置(CCD)陣列、一光電倍增管、鹵化銀照相軟片及類似者)上。A display device 104 may be coupled to a portion of frame 102 . In the example shown in FIGS. 1B and 1C , the display device 104 is coupled in the arm portion 105 of the frame 102 . With the display device 104 coupled in the arm portion 105, an eye box 140 extends toward the lens(s) 107 for outputting content at an output coupler 144 where the user The content output by the display device 104 can be seen. In some examples, output coupler 144 may be substantially coincident with lens(s) 107 . In some examples, the head-mounted wearable device 100 may also include an audio output device 106 (for example, such as one or more speakers), a lighting device 108, a sensing system 111, a control system 112, at least A processor 114 and an image capture device 116 or camera 116. The camera (or image capture device) 116 can capture images via a shutter trigger or button; the shutter trigger is configured to cause a shutter to open to allow light reflected or scattered from a scene toward the image capture device 116 to be incident on a light detector. on a detector (e.g., a charge-coupled device (CCD) array, a photomultiplier tube, silver halide photographic film, and the like).
在一些實例中，顯示裝置104可包含一透視近眼顯示器。例如，顯示裝置104可經組態以將來自一顯示源之光投影至以一角度(例如，30度至45度)座落之用作一光束分離器之提詞機玻璃之一部分上。光束分離器可允許反射及透射值，而允許來自顯示源之光被部分反射而剩餘光被透射。此一光學設計可允許一使用者例如透過鏡片107看見世界上之實體品項其次由顯示裝置104產生之內容(例如，數位影像、使用者介面元件、虛擬內容及類似者)兩者。在一些實施方案中，波導光學器件可用來描繪顯示裝置104上之內容。In some examples, display device 104 may include a see-through near-eye display. For example, display device 104 may be configured to project light from a display source onto a portion of the teleprompter glass that serves as a beam splitter that is located at an angle (eg, 30 degrees to 45 degrees). The beam splitter allows reflection and transmission values, allowing light from the display source to be partially reflected and the remaining light to be transmitted. Such an optical design may allow a user to see both physical items in the world and content generated by display device 104 (eg, digital images, user interface elements, virtual content, and the like), such as through lens 107 . In some implementations, waveguide optics may be used to depict content on display device 104.
在一些實例中，頭戴式可穿戴裝置100可包含一視線追蹤裝置120，視線追蹤裝置120包含例如一或多個感測器125以偵測及追蹤視線方向及移動。可處理由該(等)感測器125捕獲之資料以偵測及追蹤視線方向及移動作為一使用者輸入。在一些實例中，感測系統111可包含各種感測裝置，且控制系統112可包含各種控制系統裝置，包含例如可操作地耦合至控制系統112之組件之一或多個處理器114。在一些實例中，控制系統112可包含提供頭戴式可穿戴裝置100與其他外部裝置之間的通信及資訊交換之一通信模組。In some examples, the head-mounted wearable device 100 may include a gaze tracking device 120 that includes, for example, one or more sensors 125 to detect and track gaze direction and movement. Data captured by the sensor(s) 125 can be processed to detect and track gaze direction and movement as a user input. In some examples, sensing system 111 may include various sensing devices, and control system 112 may include various control system devices, including, for example, one or more processors 114 operably coupled to the components of control system 112 . In some examples, the control system 112 may include a communication module that provides communication and information exchange between the head-mounted wearable device 100 and other external devices.
如上文所提及之AR系統之挑戰係提供智慧型眼鏡100與使用者之間之一穩健介面。一些介面利用使用者手勢來實現各種命令。一穩健介面可能夠區別一拇指-食指捏縮與一拇指-中指捏縮。例如，不同手勢可能指示一智慧型眼鏡顯示器上之不同圖示之啟動或不同物件在一顯示場內移動之指示。As mentioned above, the challenge of the AR system is to provide a robust interface between the smart glasses 100 and the user. Some interfaces use user gestures to implement various commands. A robust interface might be able to differentiate between a thumb-index finger pinch and a thumb-middle finger pinch. For example, different gestures may indicate the activation of different icons on a smart glasses display or the movement of different objects within a display field.
用以提供一穩健AR介面之一習知方法包含使用安裝於一智慧型眼鏡框架上之一面向世界RGB相機來提供影像，自此，一骨架手追蹤用於完整手/手指互動及手勢推斷。即，安裝於一框架鉸鏈上之RGB相機將追蹤一使用者的手之手及/或手指運動且藉此推斷一手勢並實現與該手勢相關聯之一命令。One known method for providing a robust AR interface involves using a world-facing RGB camera mounted on a smart glasses frame to provide images, from which a skeletal hand tracking is used for complete hand/finger interaction and gesture inference. That is, an RGB camera mounted on a frame hinge will track hand and/or finger movements of a user's hand and thereby infer a gesture and implement a command associated with the gesture.
然而，可能存在與一面向世界RGB相機之使用有關之問題。例如，安裝於智慧型眼鏡之一框架上(通常在一鉸鏈附近)之此一面向世界RGB相機具有消耗相對大量功率之一相機感測器及一影像堆疊處理器(ISP)。歸因於此大功率消耗，使用來自面向世界RGB相機之RBG影像來推斷使用者手勢之一技術問題係僅可少量使用面向世界RGB相機。例如，使用面向世界RGB相機，基於相機之功率消耗，板載感測器可能每天僅偵測手勢幾次。此外，在具有一高延時之操作中，圖框速率(其應係約30個圖框每秒以獲得細微手移動差別之解析度種類)可能小於5個圖框每秒。However, there may be problems associated with the use of a world-facing RGB camera. For example, a world-facing RGB camera mounted on a frame of smart glasses (usually near a hinge) has a camera sensor and an image stack processor (ISP) that consume a relatively large amount of power. Due to this high power consumption, a technical issue with using RBG images from world-facing RGB cameras to infer user gestures is that world-facing RGB cameras are only available in small quantities. For example, with a world-facing RGB camera, the onboard sensor may only detect gestures a few times per day based on the power consumption of the camera. Furthermore, in operations with a high latency, the frame rate (which should be about 30 frames per second to obtain a resolution of small hand movement differences) may be less than 5 frames per second.
此外，即使可克服高功率消耗之技術問題，亦存在涉及一窄視場內之可能遮擋之另一技術問題；若手及/或手指在顯示場內不可見，則手勢偵測將不起作用。Furthermore, even if the technical problem of high power consumption can be overcome, there is another technical problem involving possible occlusion within a narrow field of view; if the hand and/or fingers are not visible within the display field, gesture detection will not work.
在繼續之前，一生物流體流動度量被定義為體內之一生物流體之一流動之一量測。此一度量可基於產生一影像序列之非侵入式光學量測來判定。Before proceeding, a biological fluid flow metric is defined as a measurement of the flow of a biological fluid in the body. This metric can be determined based on non-invasive optical measurements that produce a sequence of images.
存在一灌注指數(PI) (脈動血流速率與非脈動血流速率之一比率)之變化之光學量測含有關於手及手指移動的有用資訊之一些證據。圖2A至圖2B中呈現此證據。商品智慧型手錶中容易獲得之LED光電二極體(PD)對可提供一空間稀疏的PI變化量測，該PI變化量測可用來區別從一互動視角來看相隔甚遠、易於區別之一些手勢，例如，捏縮對揮手。然而，此稀疏光學陣列不具備提供此處所尋求之細微差別的能力。There is some evidence that optical measurement of changes in the perfusion index (PI) (the ratio of pulsatile to non-pulsatile blood flow rate) contains useful information about hand and finger movements. This evidence is presented in Figures 2A-2B. LED photodiode (PD) pairs readily available in commercial smart watches can provide a spatially sparse measure of PI change that can be used to distinguish easily distinguishable gestures that are far apart from an interaction perspective , for example, pinch and wave your hand. However, this sparse optical array does not have the ability to provide the nuances sought here.
根據本文中所描述之實施方案，上述技術問題之一技術解決方案包含基於自一近紅外線相機獲取之穿過一使用者的腕之皮膚之一影像序列判定由該使用者形成之手勢。具體地，安置在佩戴於一使用者的腕上之一腕帶上之一影像捕獲裝置包含：一電磁輻射源，例如在紅外線(IR)波長帶(例如，約850 nm左右之一窄帶)中之將輻射發射至使用者的腕中之發光二極體(LED)；及一IR偵測器，其產生使用者的腕中之一真皮層內之一區之二維影像序列。自此序列，手勢偵測電路基於一經訓練模型判定一生物流體流動度量之值(例如，在序列之圖框之間灌注指數(PI)之一變化)，該經訓練模型自序列產生度量。最後，手勢偵測電路將生物流動度量之值映射至判定一手勢之特定手及/或手指移動。According to embodiments described herein, one technical solution to the above technical problem includes determining a gesture performed by a user based on a sequence of images acquired from a near-infrared camera through the skin of the user's wrist. Specifically, an image capture device disposed on a wristband worn on a user's wrist includes: a source of electromagnetic radiation, such as in the infrared (IR) wavelength band (e.g., a narrow band around 850 nm) a light emitting diode (LED) that emits radiation into the user's wrist; and an IR detector that generates a two-dimensional image sequence of an area within a dermal layer of the user's wrist. From this sequence, the gesture detection circuit determines the value of a biological fluid flow metric (eg, a change in perfusion index (PI) between frames of the sequence) based on a trained model that generated the metric from the sequence. Finally, the gesture detection circuit maps the value of the bioflow metric to the specific hand and/or finger movements that determine a gesture.
在一些實施方案中，經訓練模型包含一卷積(convolutional)迴歸神經網路，該卷積迴歸神經網路係基於包含二維影像序列及生物度量之對應值(例如，PI變化)之一資料集進行訓練。In some embodiments, the trained model includes a convolutional regression neural network based on data including a two-dimensional image sequence and corresponding values of the biometric (e.g., PI changes). set for training.
在一些實施方案中，電磁輻射源(例如，LED)係配置於偵測器之任一側(例如，左側及右側)上。在一些實施方案中，偵測器形成用於自電磁輻射源(LED)發射的輻射之一左通道及一右通道。如此，二維影像序列包含自其判定PI變化之一左序列及一右序列。In some implementations, electromagnetic radiation sources (eg, LEDs) are disposed on either side of the detector (eg, left and right sides). In some embodiments, the detector forms a left channel and a right channel for radiation emitted from an electromagnetic radiation source (LED). Thus, the two-dimensional image sequence includes a left sequence and a right sequence from which PI changes are determined.
在一些實施方案中，一IR電磁輻射源係定位於亦包含偵測器之一相機上。In some embodiments, a source of IR electromagnetic radiation is positioned on a camera that also includes a detector.
技術解決方案之一技術優點係與習知方法相比，使用足夠低的功率使得影像捕獲裝置始終可用且能夠提供一高圖框速率(例如，30個圖框每秒)及低延時(例如，約10毫秒)。此外，由於照明及偵測器係定位成距腕幾毫米，所以遮擋不再係問題。具體地，影像捕獲裝置安裝於其上之一腕帶之一z深度係由影像捕獲裝置之z深度而非比如在智慧型眼鏡框架上之一安裝高度控制。One of the technical advantages of the technical solution is that compared to conventional methods, it uses low enough power so that the image capture device is always available and can provide a high frame rate (e.g., 30 frames per second) and low latency (e.g., about 10 milliseconds). Additionally, since the lighting and detectors are positioned a few millimeters from the wrist, occlusion is no longer an issue. Specifically, the z-depth of a wristband on which the image capture device is mounted is controlled by the z-depth of the image capture device rather than a mounting height such as on a smart glasses frame.
在描述經組態以基於一使用者的腕之一內部之一個二維影像序列判定一手勢之影像捕獲裝置及手勢偵測電路之前，說明操作原理將有所幫助。圖2A至圖2B中說明此原理。Before describing the image capture device and gesture detection circuitry configured to determine a gesture based on a sequence of two-dimensional images of the interior of a user's wrist, it will be helpful to describe the principles of operation. This principle is illustrated in Figures 2A-2B.
圖2A係繪示運用一紅外線(IR)發光二極體(LED) 210對皮下組織236中之一毛細血管240之一例示性照明之一圖200。如圖2A中所展示，IR LED發射在IR波長帶(例如，約850 nm左右之一窄帶)中之輻射212。輻射212經組態以行進穿過皮膚表面230、角質層232及表皮234，而亮度不會過度下降，即，比爾-朗伯(Beer-Lambert)係數足夠小。FIG. 2A is a diagram 200 illustrating exemplary illumination of a capillary 240 in subcutaneous tissue 236 using an infrared (IR) light emitting diode (LED) 210 . As shown in Figure 2A, an IR LED emits radiation 212 in an IR wavelength band (eg, a narrow band around 850 nm). Radiation 212 is configured to travel through skin surface 230, stratum corneum 232, and epidermis 234 without excessive decrease in brightness, ie, the Beer-Lambert coefficient is sufficiently small.
如圖2A中所展示，輻射212係入射於一毛細血管240上。亦如圖2A中所展示，毛細血管240含有流動血液。流動血液含有紅血球246，例如，可吸收輻射212之血紅蛋白分子。輻射212係從毛細血管240反射以產生反射輻射242，反射輻射242傳播穿過真皮236、表皮234、角質層232及皮膚表面230而至一IR偵測器220，IR偵測器220接著以一指定取樣率對由反射輻射242產生之一信號進行取樣。例如，IR偵測器220係一光體積變化描記圖法(photoplethysmography) (PPG)感測器。As shown in Figure 2A, radiation 212 is incident on a capillary 240. As also shown in Figure 2A, capillaries 240 contain flowing blood. The flowing blood contains red blood cells 246 , for example, hemoglobin molecules that can absorb radiation 212 . Radiation 212 is reflected from capillaries 240 to produce reflected radiation 242, which propagates through the dermis 236, epidermis 234, stratum corneum 232, and skin surface 230 to an IR detector 220, which then detects The specified sampling rate samples a signal produced by reflected radiation 242. For example, IR detector 220 is a photoplethysmography (PPG) sensor.
圖2B係繪示由PPG感測器220產生之一例示性信號260之一圖250。如圖2B中所展示，信號260之強度取決於一毛細血管270、280中之紅血球密度。具體地，因為紅血球吸收IR輻射，所以具有一低紅血球密度之毛細血管270產生一信號峰值，因為很少輻射212已被吸收。相比之下，具有一高紅血球密度之毛細血管280產生一信號谷值，因為大部分輻射212已被吸收。FIG. 2B illustrates a graph 250 of an exemplary signal 260 generated by the PPG sensor 220. As shown in Figure 2B, the intensity of signal 260 depends on the density of red blood cells in a capillary 270, 280. Specifically, because red blood cells absorb IR radiation, capillaries 270 with a low red blood cell density produce a signal peak because less radiation 212 has been absorbed. In contrast, capillaries 280 with a high density of red blood cells produce a signal valley because most of the radiation 212 has been absorbed.
此外，存在手及手指移動引起毛細血管中之不同紅血球密度之進一步證據。例如，一抓取運動可引起毛細血管中之紅血球密度之一增加，此被視為一PPG偵測器處之信號強度之一下降。此指示IR輻射信號強度可指示手及/或手指移動，且此等移動可定義由一AR系統之使用者形成之手勢。In addition, there is further evidence that hand and finger movements cause different red blood cell densities in capillaries. For example, a grasping motion can cause an increase in the density of red blood cells in the capillaries, which is seen as a decrease in signal strength at a PPG detector. This indication of IR radiation signal strength may indicate hand and/or finger movements, and these movements may define gestures made by a user of an AR system.
此外，進一步分析已表明，信號強度/輻射強度與手/手指移動之間的此等關係可使用現成相機中之光學偵測器(諸如在經改變用途用於腕上感測之Intel® RealSense Depth Camera D435中找到之光學偵測器)來捕獲。使用此一相機而非諸如一PPG偵測器之一小像素偵測器之一優點在於相機可產生較大場之二維影像序列。此等影像提供細微手及手指運動差別所需之解析度。Additionally, further analysis has shown that these relationships between signal strength/radiation strength and hand/finger movement can be achieved using optical detectors in off-the-shelf cameras (such as the Intel® RealSense Depth Depth repurposed for wrist-based sensing). Optical detector found in Camera D435) to capture. One advantage of using such a camera rather than a small pixel detector such as a PPG detector is that the camera can produce a larger field of two-dimensional image sequences. These images provide the resolution needed for subtle differences in hand and finger movements.
圖3係繪示一例示性腕戴式影像捕獲裝置300之一圖。腕戴式影像捕獲裝置300包含一LED驅動器310、一LED微控制器320、一底座330、一相機340及一可調整彈性腕帶350。如圖3中所展示，腕戴式影像捕獲裝置300包含或經連接至手勢偵測電路360。此僅僅係一影像捕獲裝置之一個實例且並不意謂係限制性的。FIG. 3 is a diagram illustrating an exemplary wrist-worn image capture device 300. The wrist-mounted image capture device 300 includes an LED driver 310, an LED microcontroller 320, a base 330, a camera 340 and an adjustable elastic wristband 350. As shown in FIG. 3 , the wrist-worn image capture device 300 includes or is connected to a gesture detection circuit 360 . This is merely one example of an image capture device and is not meant to be limiting.
LED驅動器310經組態以將一電流提供至LED輻射源使得經發射輻射之亮度相對穩定。此穩定性可透過將一恆定電流提供至LED使得在例如電力供應下降之情況下強度不會變化來實現。為抑制輻射強度之雜訊變動，保持亮度穩定係重要的。此等變動可能致使難以判定生物流體流動度量(例如，圖框之間的PI變化)。一例示性LED驅動器310係來自Adafruit Industries公司之一Adafruit 12通道16位元PWM LED驅動器。LED driver 310 is configured to provide a current to the LED radiation source such that the brightness of the emitted radiation is relatively stable. This stability can be achieved by supplying a constant current to the LED so that the intensity does not change if, for example, the power supply drops. In order to suppress noise changes in radiation intensity, it is important to maintain brightness stability. Such variations may make it difficult to determine biological fluid flow metrics (eg, PI changes between plots). An exemplary LED driver 310 is an Adafruit 12-channel 16-bit PWM LED driver from Adafruit Industries.
LED微控制器320經組態以根據一指定型樣或排程控制LED輻射之發射。例如，為實現一個二維影像序列之產生，LED微控制器320可引起LED輻射源在一指定頻率下閃爍(例如，30次每秒，以產生一所所要圖框速率)。一例示性LED微控制器320使用來自Adafruit Industries公司之一Adafruit QT Py 0 SAMD21 Dev Board。LED microcontroller 320 is configured to control the emission of LED radiation according to a specified pattern or schedule. For example, to achieve the generation of a two-dimensional image sequence, the LED microcontroller 320 can cause the LED radiation source to flash at a specified frequency (eg, 30 times per second to produce a desired frame rate). An exemplary LED microcontroller 320 uses the Adafruit QT Py 0 SAMD21 Dev Board from Adafruit Industries.
底座330係經組態以將相機340固持於影像捕獲裝置300內之適當位置中之一3D列印固持器。在一些實施方案中，底座330係使用兩個M3螺絲附接至相機340。底座330亦包含一凹槽，腕帶350可透過該凹槽滑動及鎖定至適當位置中。再次，此僅僅係一個實例且不應係限制性的。The base 330 is a 3D printed holder configured to hold the camera 340 in place within the image capture device 300 . In some embodiments, the base 330 is attached to the camera 340 using two M3 screws. The base 330 also includes a groove through which the wristband 350 can slide and lock into place. Again, this is merely an example and should not be limiting.
相機340經組態以接收來自使用者的腕之內部之反射輻射且在一指定視場(例如，90度乘60度)內產生圖框或二維影像。在一些實施方案中，指定視場在任一維度(例如，x或y)上顯著大於從相機至使用者的腕之內部之距離之一角範圍。一例示性相機340係由Intel公司製造之一Intel® RealSense Depth Camera D435。在一些實施方案中，影像係經格式化用於圖框之間的比較(例如，用於絕對差異)之原始影像。在此等實施方案中，影像可經正規化以防止或最小化強度值隨時間之漂移。關於圖4展示相機340之進一步細節。Camera 340 is configured to receive reflected radiation from the interior of the user's wrist and produce a frame or two-dimensional image within a specified field of view (eg, 90 degrees by 60 degrees). In some embodiments, the specified field of view is an angular range in any dimension (eg, x or y) that is significantly greater than the distance from the camera to the interior of the user's wrist. An exemplary camera 340 is the Intel® RealSense Depth Camera D435 manufactured by Intel Corporation. In some implementations, the image is a raw image formatted for comparison between frames (eg, for absolute differences). In such implementations, images may be normalized to prevent or minimize drift in intensity values over time. Further details of camera 340 are shown with respect to FIG. 4 .
圖4係繪示腕戴式影像捕獲裝置300內用於偵測一對通道中之輻射之相機340之一圖。如圖4中所展示，相機340包含一右成像器410、一IR投影儀420、一左成像器430及一RGB模組440。FIG. 4 is a diagram illustrating a camera 340 in a wrist-worn image capture device 300 for detecting radiation in a pair of channels. As shown in FIG. 4 , camera 340 includes a right imager 410 , an IR projector 420 , a left imager 430 and an RGB module 440 .
左成像器430及右成像器410各自經組態以接收自腕內部反射之輻射且在偵測器上形成各自影像。在一些實施方案中，左成像器430及右成像器410各自包含經組態以將經接收輻射聚焦至各自偵測器上之光學器件。在一些實施方案中，光學器件及偵測器經組態用於IR輻射，例如850 nm左右之一窄帶。在一些實施方案中，左成像器430及右成像器410 (即，左及右通道偵測器)實質上同時捕獲其等各自影像。此允許自雙手進行更準確手勢偵測。The left imager 430 and the right imager 410 are each configured to receive radiation reflected from the interior of the wrist and form respective images on the detector. In some implementations, left imager 430 and right imager 410 each include optics configured to focus received radiation onto respective detectors. In some embodiments, the optics and detector are configured for IR radiation, such as a narrow band around 850 nm. In some implementations, left imager 430 and right imager 410 (ie, left and right channel detectors) capture their respective images substantially simultaneously. This allows for more accurate gesture detection from both hands.
IR投影儀420係與左成像器430及右成像器410共置於一單個外殼(即，一相機外殼)中，且經組態以將IR輻射發射至使用者的腕上及中以用於背反射。在一些實施方案中，IR投影包含在IR中(例如，在850 nm左右之一窄帶中)發射之一雷射。在一些實施方案中，IR投影儀420經組態以將IR輻射發射至左成像器430或右成像器410之一者中。在一些實施方案中，IR投影儀420包含一分離器使得IR輻射被反射回至左投影儀430及右投影儀410兩者。在一些實施方案中，IR投影儀420係與左投影儀430及右投影儀410焊接至同一電路板。IR projector 420 is co-located with left imager 430 and right imager 410 in a single housing (i.e., a camera housing) and is configured to emit IR radiation onto and into the user's wrist for use Back reflection. In some embodiments, IR projection involves emitting a laser in the IR (eg, in a narrow band around 850 nm). In some implementations, IR projector 420 is configured to emit IR radiation into one of left imager 430 or right imager 410 . In some implementations, IR projector 420 includes a splitter such that IR radiation is reflected back to both left projector 430 and right projector 410 . In some implementations, IR projector 420 is soldered to the same circuit board as left projector 430 and right projector 410 .
RGB模組440經組態以產生及/或偵測在可見光譜中之照明。在一些情況下，在可見光譜之紅色端中之輻射可在腕之內部中具有顯著亮度(即，足夠小的比爾-朗伯係數)。因此，RGB模組440可提供用於產生圖框以進行手勢偵測之一替代影像平台。RGB module 440 is configured to generate and/or detect illumination in the visible spectrum. In some cases, radiation in the red end of the visible spectrum can have significant brightness in the interior of the wrist (ie, a sufficiently small Beer-Lambert coefficient). Therefore, the RGB module 440 may provide an alternative imaging platform for generating frames for gesture detection.
應注意，如上文所描述之相機340僅為一個實例且並不意謂係限制性的。例如，相機340不需要包含RGB模組440。It should be noted that camera 340 as described above is only one example and is not meant to be limiting. For example, camera 340 need not include RGB module 440.
圖5係繪示腕戴式影像捕獲裝置300之一仰視圖500之一圖。如圖5中所展示，腕戴式影像捕獲裝置300進一步包含一輻射擋板510以及IR LED對520及522。FIG. 5 is a diagram illustrating a bottom view 500 of the wrist-worn image capture device 300 . As shown in FIG. 5 , the wrist-worn image capture device 300 further includes a radiation baffle 510 and IR LED pairs 520 and 522 .
輻射擋板510經組態以阻止輻射透過腕戴式影像捕獲裝置300洩漏。在一些實施方案中，輻射擋板510係由一篩分(sift)聚氨酯發泡體構造而成，以令使用者在佩戴腕戴式影像捕獲裝置300時感到舒適。在一些實施方案中，輻射擋板510係約四分之一英寸厚且對於用於與使用者的皮膚接觸而言係安全的。Radiation baffle 510 is configured to prevent radiation from leaking through wrist-worn image capture device 300 . In some embodiments, the radiation baffle 510 is constructed from a sift polyurethane foam to provide comfort to the user while wearing the wrist-worn image capture device 300 . In some embodiments, the radiation barrier 510 is approximately one-quarter of an inch thick and safe for use in contact with the user's skin.
IR LED對520及522經組態以將IR輻射發射至使用者的腕之內部中以用於分別背反射至左成像器430及右成像器410中。腕戴式影像捕獲裝置300中所使用之IR LED之一實例係由Vishay Semiconductors製造之以850 nm為中心之GaAlAs雙異質高速IR發射二極體。應注意，輻射可由IR LED 520及/或522及/或IR投影儀420提供。圖6中展示關於IR LED之組態之進一步細節。IR LED pairs 520 and 522 are configured to emit IR radiation into the interior of the user's wrist for back reflection into left and right imagers 430 and 410 respectively. One example of an IR LED used in wrist-worn image capture device 300 is a GaAlAs dual heterogeneous high-speed IR emitting diode centered at 850 nm manufactured by Vishay Semiconductors. It should be noted that radiation may be provided by IR LEDs 520 and/or 522 and/or IR projector 420. Further details on the configuration of the IR LED are shown in Figure 6.
圖6係繪示例示性腕戴式影像捕獲裝置300之一平面側視圖之一圖，其中輻射由IR LED對520及522提供。圖6中所繪示之圖僅展示LED對520及522以及其等發射之各自輻射束612及616。6 is a diagram illustrating a plan side view of an exemplary wrist-worn image capture device 300 with radiation provided by IR LED pairs 520 and 522. The diagram depicted in Figure 6 only shows LED pairs 520 and 522 and the respective radiation beams 612 and 616 they emit.
假定在圖6中，LED對520及522相對於彼此對稱地放置使得LED對520之組態之描述亦適用於LED對522。如圖6中所展示，LED對520中之LED與腕戴式影像捕獲裝置300之外殼330對準。因此，由於外殼330之幾何形狀，LED對520之各LED具有相對於輻射擋板510之一表面之一法線以一角度620定向之一對稱軸線。在一些實施方案中，角度620實質上等於35度。It is assumed that in FIG. 6 , LED pairs 520 and 522 are placed symmetrically relative to each other so that the description of the configuration of LED pair 520 also applies to LED pair 522 . As shown in FIG. 6 , the LEDs in LED pair 520 are aligned with housing 330 of wrist-worn image capture device 300 . Therefore, due to the geometry of housing 330, each LED of LED pair 520 has an axis of symmetry oriented at an angle 620 relative to a normal to a surface of radiation barrier 510. In some embodiments, angle 620 is substantially equal to 35 degrees.
輻射束612具有由LED對520所發射之輻射相對於沿著對稱軸線發射之強度最大值之一半強度定義之一半發散角630。在一些實施方案中，一全發散角(即，半發散角630之兩倍)實質上等於22度。角度620及630對於IR偵測器相對於LED對520及522之放置係重要的。The radiation beam 612 has a half divergence angle 630 defined by half the intensity of the radiation emitted by the LED pair 520 relative to the intensity maximum emitted along the axis of symmetry. In some embodiments, a full divergence angle (ie, twice the half divergence angle 630) is substantially equal to 22 degrees. The angles 620 and 630 are important for the placement of the IR detector relative to the LED pairs 520 and 522.
返回圖3且如先前所陳述，腕戴式影像捕獲裝置300包含手勢偵測電路360。手勢偵測電路360經組態以判定一生物流體流動度量，例如跨圖框之一PI變化，且因此基於生物流體流動度量判定一手勢。關於圖7展示關於手勢偵測電路360之進一步細節。Returning to FIG. 3 and as previously stated, the wrist-worn image capture device 300 includes a gesture detection circuit 360 . Gesture detection circuit 360 is configured to determine a biofluid flow metric, such as a PI change across a frame, and thus determine a gesture based on the biofluid flow metric. Further details regarding gesture detection circuit 360 are shown with respect to FIG. 7 .
圖7係繪示連接至腕戴式影像捕獲裝置300或嵌入於腕戴式影像捕獲裝置300中之例示性手勢偵測電路360之一圖。手勢偵測電路360經組態以自相機340接收一個二維影像序列，且判定在產生該影像序列時由使用者形成之一手勢。FIG. 7 is a diagram illustrating an exemplary gesture detection circuit 360 connected to or embedded in the wrist-worn image capture device 300 . Gesture detection circuit 360 is configured to receive a two-dimensional image sequence from camera 340 and determine a gesture formed by the user when the image sequence was generated.
手勢偵測電路360包含一網路介面722、一或多個處理單元724及非暫時性記憶體726。網路介面722包含例如用於將自網路接收之電子及/或光學信號轉換為電子形式以供手勢偵測電路360使用之乙太網路配接器、符記環配接器及類似者。該組處理單元724包含一或多個處理晶片及/或總成。記憶體726包含揮發性記憶體(例如，RAM)及非揮發性記憶體(諸如一或多個ROM、磁碟機、固態驅動機及類似者)兩者。該組處理單元724及記憶體726一起形成控制電路，該控制電路經組態且經配置以實行如本文中所描述之各種方法及功能。The gesture detection circuit 360 includes a network interface 722, one or more processing units 724, and non-transitory memory 726. Network interface 722 includes, for example, an Ethernet adapter, a Token Ring adapter, and the like for converting electronic and/or optical signals received from the network into electronic form for use by gesture detection circuit 360 . The set of processing units 724 includes one or more processing dies and/or assemblies. Memory 726 includes both volatile memory (eg, RAM) and non-volatile memory (such as one or more ROMs, disk drives, solid-state drives, and the like). The set of processing units 724 and memory 726 together form control circuitry configured and configured to perform the various methods and functions as described herein.
在一些實施方案中，手勢偵測電路360之組件之一或多個者可為或可包含經組態以處理儲存於記憶體726中之指令之處理器(例如，處理單元724)。如圖7中所描繪之此等指令之實例包含一影像管理器730、一灌注指數模型管理器740、一手勢模型管理器750及一基於手勢之命令管理器760。此外，如圖7中所繪示，記憶體726經組態以儲存各種資料，此係關於使用此資料之各自管理器進行描述。In some implementations, one or more components of gesture detection circuit 360 may be or may include a processor (eg, processing unit 724) configured to process instructions stored in memory 726. Examples of such instructions as depicted in Figure 7 include an image manager 730, a perfusion index model manager 740, a gesture model manager 750, and a gesture-based command manager 760. Additionally, as shown in Figure 7, memory 726 is configured to store various data, which is described with respect to respective managers using this data.
影像管理器730經組態以自腕戴式影像捕獲裝置300之相機340獲得影像資料732。在一些實施方案中，影像管理器730經由網路介面722透過一網路獲得影像資料732。在一些實施方案中，影像管理器730透過一直接連接獲得影像資料732。在一些實施方案中，影像管理器730自一本端儲存裝置裝置獲得影像資料732。Image manager 730 is configured to obtain image data 732 from camera 340 of wrist-worn image capture device 300 . In some implementations, image manager 730 obtains image data 732 over a network via network interface 722. In some implementations, image manager 730 obtains image data 732 through a direct connection. In some implementations, image manager 730 obtains image data 732 from a primary storage device.
影像資料732表示由腕戴式影像捕獲裝置300捕獲之一個二維影像序列732(1)、732(2)、…、732(N)。在一些實施方案中，影像資料732表示在一使用者的腕之內部中之一指定場內拍攝之影像樣本。在一些實施方案中，序列732(1)、732(2)、…、732(N)之各者採取指示一生物流體流動度量之值(例如，指定場內之各個關鍵點處之灌注指數)之一熱圖之形式。The image data 732 represents a two-dimensional image sequence 732(1), 732(2), ..., 732(N) captured by the wrist-mounted image capture device 300. In some embodiments, image data 732 represents image samples captured within a specified field within a user's wrist. In some embodiments, each of sequences 732(1), 732(2), ..., 732(N) takes a value indicative of a biological fluid flow metric (e.g., a perfusion index at various critical points within a given field) in the form of a heat map.
在一些實施方案中，由腕戴式影像捕獲裝置300捕獲之序列732(1)、732(2)、…、732(N)表示在一指定時期內例如以一指定圖框速率拍攝之二維影像。在一些實施方案中，圖框速率係30個圖框每秒，即，序列732(1)、732(2)、…、732(N)中之圖框係相隔1/30秒拍攝。一較高圖框速率提供判定關鍵點處之生物流體流動度量的變化之更佳時間解析度。此外，若序列732(1)、732(2)、…、732(N)係以低延時捕獲，則即時地準確判定手勢。在圖7中，生物流體流動速率被展示為灌注指數(PI)，或更具體地，圖框之間PI之變化。In some embodiments, the sequences 732(1), 732(2), . . . , 732(N) captured by the wrist-worn image capture device 300 represent two-dimensional images captured during a specified period of time, such as at a specified frame rate. image. In some embodiments, the frame rate is 30 frames per second, ie, frames in sequence 732(1), 732(2), ..., 732(N) are taken 1/30 of a second apart. A higher frame rate provides better time resolution for determining changes in biological fluid flow metrics at critical points. In addition, if the sequence 732(1), 732(2), ..., 732(N) is captured with low latency, the gesture can be accurately determined instantly. In Figure 7, the biological fluid flow rate is shown as the perfusion index (PI), or more specifically, the change in PI between plots.
在一些實施方案中，序列732(1)、732(2)、…、732(N)包含一個以上獨立通道，例如，來自相機340中之左偵測器430及右偵測器410之一左通道及右通道。在此等實施方案中，來自不同通道之圖框係彼此獨立地模型化。In some embodiments, sequence 732(1), 732(2), ..., 732(N) includes more than one independent channel, for example, one of the left and right detectors 430, 410 from camera 340. channel and right channel. In these implementations, frames from different channels are modeled independently of each other.
PI模型管理器740經組態以產生由PI模型資料742表示之一PI模型，該PI模型將影像資料732映射至PI隨時間之一變化。如圖7中所展示，PI模型係一監督式模型，具體地一卷積迴歸因子神經網路，或具有迴歸因子之一卷積神經網路。在此內容背景中，一迴歸因子係二維影像序列732(1)、732(2)、…、732(N)中之一組關鍵點，在該等關鍵點處對PI進行評估。如此處所描述之模型僅為一個實例且不應被理解為限制性的。PI模型管理器740包含一PI模型訓練管理器741。PI model manager 740 is configured to generate a PI model represented by PI model data 742 that maps image data 732 to changes in PI over time. As shown in Figure 7, the PI model is a supervised model, specifically a convolutional regression factor neural network, or a convolutional neural network with regression factors. In the context of this content, a regressor is a set of key points in the two-dimensional image sequence 732(1), 732(2), ..., 732(N) at which the PI is evaluated. The model as described herein is an example only and should not be construed as limiting. PI model manager 740 includes a PI model training manager 741.
PI模型訓練管理器741經組態以基於PI模型訓練資料743產生CNN迴歸因子資料744。PI模型訓練資料743包含二維影像序列746(1)、…、746(T)及對應PI資料747(1)、…、747(T)之一語料庫，對應PI資料747(1)、…、747(T)表示PI值，或在相鄰圖框之間在由關鍵點資料745表示之關鍵點處的PI值之變化。PI模型訓練管理器741使用PI模型訓練資料743及一歐幾里德(Euclidean)損失函數來產生由卷積層資料748表示之在一些實施方案中具有彙集層及/或跳躍連接的隱藏層之參數。接著，PI模型管理器740預測由PI/FC層資料749表示之一最終全連接層處之PI值。PI model training manager 741 is configured to generate CNN regressor data 744 based on PI model training data 743 . The PI model training data 743 includes two-dimensional image sequences 746(1),...,746(T) and one corpus of corresponding PI data 747(1),...,747(T), corresponding to the PI data 747(1),..., 747(T) represents the PI value, or the change in PI value at the key point represented by key point data 745 between adjacent frames. The PI model training manager 741 uses the PI model training data 743 and a Euclidean loss function to generate parameters represented by the convolutional layer data 748 , which in some embodiments have pooling layers and/or skip connections. . Next, the PI model manager 740 predicts the PI value at a final fully connected layer represented by the PI/FC layer data 749.
手勢模型管理器750經組態以使用手勢模型資料752 (例如，表示相鄰圖框之間如取自FC層資料749的PI變化之增量PI資料754)來預測在捕獲影像資料732時由一使用者形成之一或若干手勢。Gesture model manager 750 is configured to use gesture model data 752 (e.g., delta PI data 754 representing PI changes between adjacent frames as taken from FC layer data 749) to predict the behavior of gestures performed when image data 732 is captured. A user forms one or several gestures.
在一些實施方案中且如圖7中所展示，手勢模型管理器750基於手勢映射資料756之一增量PI來預測手勢。在一些實施方案中，映射資料756包含一查找表，該查找表包含增量PI之值以及手及手指移動之識別符，例如「右手抓取」、「左手拇指-食指捏縮」等。在一些實施方案中，識別符係數字。In some implementations and as shown in FIG. 7 , gesture model manager 750 predicts gestures based on one of the delta PIs of gesture mapping profile 756 . In some embodiments, mapping data 756 includes a lookup table that includes values for delta PI and identifiers of hand and finger movements, such as "right hand grasp," "left thumb-index finger pinch," etc. In some embodiments, the identifier is a number.
在一些實施方案中，手勢模型管理器750使用利用PI值及對應手指/手運動訓練之一監督式神經網路來預測手勢。在一些實施方案中，手指/手運動被表示為嵌入項，即，低維向量。In some embodiments, gesture model manager 750 predicts gestures using a supervised neural network trained using PI values and corresponding finger/hand movements. In some embodiments, finger/hand motions are represented as embeddings, i.e., low-dimensional vectors.
基於手勢之命令管理器760基於由手勢模型管理器750預測之一手勢執行一動作。例如，一抓取運動可引起基於手勢之命令管理器760在其視場內搜尋AR顯示之一物件以抓取，且接著透過視場根據手勢之移動使物件移動。Gesture-based command manager 760 performs an action based on a gesture predicted by gesture model manager 750 . For example, a grabbing movement may cause the gesture-based command manager 760 to search for an AR display object within its field of view to grab, and then move the object through the field of view according to the movement of the gesture.
手勢偵測電路360之組件(例如，模組、處理單元724)可經組態以基於可包含一或多種類型之硬體、軟體、韌體、作業系統、運行時間程式庫等等之一或多個平台(例如，一或多個類似或不同平台)來操作。在一些實施方案中，手勢偵測電路360之組件可經組態以在一裝置叢集(例如，一伺服器群)內操作。在此一實施方案中，手勢偵測電路360之組件之功能性及處理可分佈至裝置叢集之數個裝置。Components of gesture detection circuit 360 (eg, modules, processing unit 724) may be configured to be based on one or more types of hardware, software, firmware, operating systems, runtime libraries, etc., which may include one or more types of hardware, software, firmware, operating systems, runtime libraries, etc. Operate on multiple platforms (eg, one or more similar or different platforms). In some implementations, components of gesture detection circuit 360 may be configured to operate within a cluster of devices (eg, a server cluster). In such an implementation, the functionality and processing of the components of gesture detection circuit 360 may be distributed to several devices in a device cluster.
手勢偵測電路360之組件可為或可包含經組態以處理屬性之任何類型之硬體及/或軟體。在一些實施方案中，圖7中之手勢偵測電路360之組件中所展示之組件之一或多個部分可為或可包含一基於硬體之模組(例如，一數位信號處理器(DSP)、一場可程式化閘陣列(FPGA)、一記憶體)、一韌體模組及/或一基於軟體之模組(例如，一電腦程式碼模組、可在一電腦處執行之一組電腦可讀指令)。例如，在一些實施方案中，手勢偵測電路360之組件之一或多個部分可為或可包含經組態用於由至少一個處理器(未展示)執行之一軟體模組。在一些實施方案中，組件之功能性可包含於不同於圖7中所展示之模組及/或組件之模組及/或組件中，包含將繪示為兩個組件之功能性組合成一單個組件。The components of gesture detection circuit 360 may be or may include any type of hardware and/or software configured to process attributes. In some implementations, one or more of the components shown in the components of gesture detection circuit 360 in FIG. 7 may be or may include a hardware-based module (e.g., a digital signal processor (DSP) ), a programmable gate array (FPGA), a memory), a firmware module and/or a software-based module (e.g., a computer code module, a set of computer readable instructions). For example, in some implementations, one or more portions of the components of gesture detection circuit 360 may be or may include a software module configured for execution by at least one processor (not shown). In some implementations, the functionality of a component may be included in modules and/or components that are different from those shown in Figure 7, including combining functionality illustrated as two components into a single components.
儘管未展示，但在一些實施方案中，手勢偵測電路360之組件(或其部分)可經組態以在例如一資料中心(例如，一雲端運算環境)、一電腦系統、一或多個伺服器/主機裝置等等內操作。在一些實施方案中，手勢偵測電路360之組件(或其部分)可經組態以在一網路內操作。因此，手勢偵測電路360之組件(或其部分)可經組態以在可包含一或多個裝置及/或一或多個伺服器裝置之各種類型之網路環境內運作。例如，網路可為或可包含一區域網路(LAN)、一廣域網路(WAN)等等。網路可為或可包含使用例如閘道器裝置、橋接器、交換機等等實施之一無線網路及/或有線網路。網路可包含一或多個段及/或可具有基於各種協定(諸如網際網路協定(IP)及/或一專有協定)之部分。網路可包含網際網路之至少一部分。Although not shown, in some implementations, components of gesture detection circuit 360 (or portions thereof) may be configured to operate in, for example, a data center (eg, a cloud computing environment), a computer system, one or more Operate within a server/host device, etc. In some implementations, components of gesture detection circuit 360 (or portions thereof) may be configured to operate within a network. Accordingly, components of gesture detection circuit 360 (or portions thereof) may be configured to operate within various types of network environments that may include one or more devices and/or one or more server devices. For example, the network may be or include a local area network (LAN), a wide area network (WAN), etc. The network may be or may include a wireless network and/or a wired network implemented using, for example, gateway devices, bridges, switches, and the like. A network may include one or more segments and/or may have portions based on various protocols, such as Internet Protocol (IP) and/or a proprietary protocol. A network may include at least a portion of the Internet.
在一些實施方案中，搜尋系統之組件之一或多者可為或可包含經組態以處理儲存於一記憶體中之指令之處理器。例如，影像管理器730 (及/或其之一部分)、一PI模型管理器740 (及/或其之一部分)、手勢模型管理器750 (及/或其之一部分)及基於手勢之命令管理器760 (及/或其之一部分)係此等指令之實例。In some implementations, one or more of the components of the search system may be or include a processor configured to process instructions stored in a memory. For example, image manager 730 (and/or a portion thereof), a PI model manager 740 (and/or a portion thereof), a gesture model manager 750 (and/or a portion thereof), and a gesture-based command manager 760 (and/or parts thereof) are examples of these directives.
在一些實施方案中，記憶體726可為任何類型之記憶體，諸如一隨機存取記憶體、一磁碟機記憶體、快閃記憶體等等。在一些實施方案中，記憶體726可被實施為與手勢偵測電路360之組件相關聯之一個以上記憶體組件(例如，一個以上RAM組件或磁碟機記憶體)。在一些實施方案中，記憶體726可為一資料庫記憶體。在一些實施方案中，記憶體726可為或可包含一非本端記憶體。例如，記憶體726可為或可包含由多個裝置(未展示)共用之一記憶體。在一些實施方案中，記憶體726可與一網路內之一伺服器裝置(未展示)相關聯且經組態以伺服手勢偵測電路360之組件。如圖7中所繪示，記憶體726經組態以儲存各種資料，包含影像資料732、PI模型資料742及手勢模型資料752。In some implementations, memory 726 may be any type of memory, such as a random access memory, a disk drive memory, flash memory, etc. In some implementations, memory 726 may be implemented as one or more memory components (eg, one or more RAM components or disk drive memory) associated with components of gesture detection circuit 360 . In some implementations, memory 726 may be a database memory. In some implementations, memory 726 may be or may include non-local memory. For example, memory 726 may be or may include a memory shared by multiple devices (not shown). In some implementations, memory 726 may be associated with a server device (not shown) within a network and configured to serve components of gesture detection circuit 360 . As shown in Figure 7, memory 726 is configured to store various data, including image data 732, PI model data 742, and gesture model data 752.
圖8係描繪基於一使用者的腕之一內部之一個二維影像序列判定手勢的一例示性方法800之一流程圖。方法800可由結合圖7所描述之軟體建構來執行，該等軟體建構駐留於手勢偵測電路360之記憶體726中且係由該組處理單元724運行。FIG. 8 is a flowchart depicting an exemplary method 800 for determining gestures based on a sequence of two-dimensional images of the interior of a user's wrist. Method 800 may be performed by software constructs described in conjunction with FIG. 7 that reside in memory 726 of gesture detection circuit 360 and are executed by the set of processing units 724 .
在802，影像捕獲裝置300捕獲穿過一使用者的腕之皮膚之一影像序列(例如，二維影像序列732(1)、732(2)、…、732(N))。例如，在由使用者形成一手勢時，影像捕獲裝置300引起一輻射源(例如，IR LED 520、522)照明使用者的腕之內部內(即，在其中血液在毛細血管中流動之一真皮層中)之一區。輻射經背反射朝向IR偵測器(例如，偵測器430及410)而形成二維影像。序列係由例如以一指定圖框速率使LED閃爍開啟及關閉之一LED微控制器320形成。At 802, the image capture device 300 captures a sequence of images (eg, two-dimensional image sequences 732(1), 732(2), ..., 732(N)) across the skin of a user's wrist. For example, when a gesture is formed by the user, the image capture device 300 causes a radiation source (e.g., IR LEDs 520, 522) to illuminate the interior of the user's wrist (i.e., the dermis where blood flows in the capillaries). layer) one area. The radiation is back-reflected toward IR detectors (eg, detectors 430 and 410) to form a two-dimensional image. The sequence is formed by, for example, an LED microcontroller 320 that flashes the LEDs on and off at a specified frame rate.
在804，PI模型管理器740基於影像序列732(1)、732(2)、…、732(N)判定一生物流體流動度量(例如，在序列之圖框之間PI之變化或增量PI)。模型係具有迴歸因子之一卷積神經網路，其接收表示迴歸因子之關鍵點之關鍵點資料745且預測二維影像序列732(1)、732(2)、…、732(N)之圖框之間PI之一變化。At 804, PI model manager 740 determines a biological fluid flow metric (eg, change in PI or delta PI between frames of the sequence) based on the image sequence 732(1), 732(2), ..., 732(N). ). The model is a convolutional neural network with a regressor, which receives key point data 745 representing key points of the regressor and predicts a graph of a two-dimensional image sequence 732(1), 732(2), ..., 732(N) One of the PI changes between boxes.
在806，手勢模型管理器750基於生物流體流動度量(例如，二維影像序列732(1)、732(2)、…、732(N)之圖框之間PI之變化)判定由使用者形成之一手勢。此判定可使用例如一查找表或一監督式預測模型來進行。At 806, the gesture model manager 750 determines whether the gesture was performed by the user based on a biological fluid flow metric (eg, a change in PI between frames of the two-dimensional image sequence 732(1), 732(2), ..., 732(N)). A gesture. This determination may be made using, for example, a lookup table or a supervised prediction model.
在808，基於手勢之命令管理器760基於手勢觸發與在一AR系統中顯示一物件相關的一命令之執行。At 808, gesture-based command manager 760 triggers execution of a command related to displaying an object in an AR system based on the gesture.
圖9繪示一通用電腦裝置900及一通用行動電腦裝置950之一實例，通用電腦裝置900及通用行動電腦裝置950可與此處所描述之技術一起使用。電腦裝置900係圖7之手勢偵測電路360之一個例示性組態。Figure 9 illustrates an example of a general purpose computer device 900 and a general purpose mobile computer device 950 that may be used with the techniques described herein. The computer device 900 is an exemplary configuration of the gesture detection circuit 360 of FIG. 7 .
如圖9中所展示，運算裝置900意欲表示各種形式之數位電腦，諸如膝上型電腦、桌上型電腦、工作站、個人數位助理、伺服器、刀鋒伺服器、大型主機及其他適當電腦。運算裝置950意欲表示各種形式之行動裝置，諸如個人數位助理、蜂巢式電話、智慧型電話及其他類似運算裝置。此處所展示之組件、其等連接及關係以及其等功能僅意謂著係實例，且並不意謂限制本文件中所描述及/或主張之本發明之實施方案。As shown in Figure 9, computing device 900 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other suitable computers. Computing device 950 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular phones, smart phones, and other similar computing devices. The components, their connections and relationships, and their functions shown herein are meant to be examples only and are not meant to limit the embodiments of the invention described and/or claimed in this document.
運算裝置900包含一處理器902、記憶體904、一儲存裝置906、連接至記憶體904及高速擴展埠910之一高速介面908以及連接至低速匯流排914及儲存裝置906之一低速介面912。組件902、904、906、908、910及912之各者係使用各種匯流排來互連，且可安裝於一共同主機板上或適當地以其他方式安裝。處理器902可處理用於在運算裝置900內執行之指令，包含儲存於記憶體904中或儲存裝置906上之指令，以在一外部輸入/輸出裝置(諸如耦合至高速介面908之顯示器916)上顯示一GUI之圖形資訊。在其他實施方案中，可適當地使用多個處理器及/或多個匯流排，連同多個記憶體及多種類型之記憶體。再者，可連接多個運算裝置900，其中各裝置提供必要操作之部分(例如，作為一伺服器組、一刀鋒伺服器群組或一個多處理器系統)。The computing device 900 includes a processor 902, memory 904, a storage device 906, a high-speed interface 908 connected to the memory 904 and the high-speed expansion port 910, and a low-speed interface 912 connected to the low-speed bus 914 and the storage device 906. Each of components 902, 904, 906, 908, 910, and 912 are interconnected using various busses and may be mounted on a common motherboard or otherwise mounted as appropriate. Processor 902 may process instructions for execution within computing device 900 , including instructions stored in memory 904 or on storage device 906 , to an external input/output device (such as display 916 coupled to high-speed interface 908 ) Displays graphical information of a GUI. In other embodiments, multiple processors and/or multiple buses may be used as appropriate, along with multiple memories and multiple types of memory. Furthermore, multiple computing devices 900 may be connected, with each device providing portions of the necessary operations (eg, as a server bank, a blade server group, or a multi-processor system).
記憶體904儲存運算裝置900內之資訊。在一個實施方案中，記憶體904係一或若干揮發性記憶體單元。在另一實施方案中，記憶體904係一或若干非揮發性記憶體單元。記憶體904亦可為另一形式之電腦可讀媒體，諸如一磁碟或光碟。The memory 904 stores information within the computing device 900 . In one embodiment, memory 904 is one or several volatile memory cells. In another embodiment, memory 904 is one or several non-volatile memory cells. Memory 904 may also be another form of computer-readable media, such as a magnetic disk or optical disk.
儲存裝置906能夠為運算裝置900提供大容量儲存。在一個實施方案中，儲存裝置906可為或含有一電腦可讀媒體，諸如一軟碟裝置、一硬碟裝置、一光碟裝置或一磁帶裝置、一快閃記憶體或其他類似固態記憶體裝置，或一裝置陣列，包含呈一儲存區域網路或其他組態之裝置。一電腦程式產品可有形地體現於一資訊載體中。電腦程式產品亦可含有指令，該等指令在被執行時執行一或多種方法，諸如上文所描述之方法。資訊載體係一電腦或機器可讀媒體，諸如記憶體904、儲存裝置906或處理器902上之記憶體。The storage device 906 can provide large-capacity storage for the computing device 900 . In one embodiment, storage device 906 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device or a magnetic tape device, a flash memory or other similar solid state memory device , or a device array including devices in a storage area network or other configuration. A computer program product can be tangibly embodied in an information carrier. Computer program products may also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrying system is a computer or machine-readable medium, such as memory 904, storage device 906, or memory on processor 902.
高速控制器908管理運算裝置900之頻寬密集型操作，而低速控制器912管理較低頻寬密集型操作。此功能分配僅為實例。在一個實施方案中，高速控制器908係耦合至記憶體904、顯示器916 (例如，透過一圖形處理器或加速器)，且耦合至高速擴展埠910，高速擴展埠910可接受各種擴展卡(未展示)。在實施方案中，低速控制器912係耦合至儲存裝置906及低速擴展埠914。可包含各種通信埠(例如，USB、藍牙、乙太網路、無線乙太網路)之低速擴展埠可例如透過一網路配接器耦合至一或多個輸入/輸出裝置，諸如一鍵盤、一指向裝置、一掃描器或一網路裝置，諸如一交換機或路由器。The high-speed controller 908 manages bandwidth-intensive operations of the computing device 900, while the low-speed controller 912 manages less bandwidth-intensive operations. This feature is assigned to instances only. In one embodiment, high-speed controller 908 is coupled to memory 904, display 916 (eg, through a graphics processor or accelerator), and to high-speed expansion port 910, which can accept various expansion cards (not yet exhibit). In an embodiment, low speed controller 912 is coupled to storage device 906 and low speed expansion port 914 . Low-speed expansion ports, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, Wireless Ethernet), may be coupled to one or more input/output devices, such as a keyboard, e.g., through a network adapter , a pointing device, a scanner or a network device such as a switch or router.
運算裝置900可以若干不同形式實施，如圖中所展示。例如，其可被實施為一標準伺服器920，或在此等伺服器之一群組中實施多次。其亦可被實施為一機架伺服器系統924之部分。另外，其可在諸如一膝上型電腦922之一個人電腦中實施。替代地，來自運算裝置900之組件可與一行動裝置(未展示) (諸如裝置950)中之其他組件組合。此等裝置之各者可含有運算裝置900、950之一或多者，且整個系統可由彼此通信之多個運算裝置900、950組成。Computing device 900 may be implemented in several different forms, as shown in the figure. For example, it may be implemented as a standard server 920, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 924. Alternatively, it may be implemented in a personal computer such as a laptop 922. Alternatively, components from computing device 900 may be combined with other components in a mobile device (not shown), such as device 950. Each of these devices may include one or more of computing devices 900, 950, and the overall system may consist of multiple computing devices 900, 950 in communication with each other.
運算裝置950包含一處理器952、記憶體964、諸如一顯示器954之一輸入/輸出裝置、一通信介面966及一收發器968，以及其他組件。裝置950亦可具備一儲存裝置，諸如一微型硬碟或其他裝置，以提供額外儲存。組件950、952、964、954、966及968之各者係使用各種匯流排互連，且數個組件可安裝於一共同主機板上或適當地以其他方式安裝。Computing device 950 includes a processor 952, memory 964, an input/output device such as a display 954, a communications interface 966, and a transceiver 968, among other components. Device 950 may also have a storage device, such as a micro drive or other device, to provide additional storage. Each of components 950, 952, 964, 954, 966, and 968 are interconnected using various busbars, and several components may be mounted on a common motherboard or otherwise mounted as appropriate.
處理器952可執行運算裝置950內之指令，包含儲存於記憶體964中之指令。處理器可被實施為包含單獨及多個類比及數位處理器之晶片之一晶片組。例如，處理器可提供裝置950之其他組件之協調，諸如對使用者介面、由裝置950運行之應用程式及裝置950之無線通信的控制。Processor 952 may execute instructions within computing device 950 , including instructions stored in memory 964 . The processor may be implemented as a chipset including individual and multiple analog and digital processor chips. For example, the processor may provide coordination of other components of device 950 , such as control of the user interface, applications run by device 950 , and wireless communications of device 950 .
處理器952可透過耦合至一顯示器954之控制介面958及顯示介面956與一使用者通信。顯示器954可為例如一TFT LCD (薄膜電晶體液晶顯示器)或一OLED (有機發光二極體)顯示器，或其他適當顯示技術。顯示介面956可包括用於驅動顯示器954以向一使用者呈現圖形及其他資訊之適當電路。控制介面958可自一使用者接收命令且轉換該等命令以用於提交給處理器952。另外，可提供與處理器952通信之一外部介面960，以實現裝置950與其他裝置之近區通信。外部介面960可例如在一些實施方案中提供有線通信，或在其他實施方案中提供無線通信，且亦可使用多個介面。The processor 952 can communicate with a user through a control interface 958 and a display interface 956 coupled to a display 954 . Display 954 may be, for example, a TFT LCD (Thin Film Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other suitable display technology. Display interface 956 may include appropriate circuitry for driving display 954 to present graphics and other information to a user. Control interface 958 can receive commands from a user and convert the commands for submission to processor 952 . In addition, an external interface 960 that communicates with the processor 952 may be provided to implement near-area communication between the device 950 and other devices. External interface 960 may, for example, provide wired communications in some embodiments, or wireless communications in other embodiments, and multiple interfaces may also be used.
記憶體964儲存運算裝置950內之資訊。記憶體964可被實施為一或若干電腦可讀媒體、一或若干揮發性記憶體單元或一或若干非揮發性記憶體單元之一或多者。擴展記憶體974亦可被提供且透過擴展介面972連接至裝置950，擴展介面972可包含例如一SIMM (單列直插式記憶模組)卡介面。此擴展記憶體974可為裝置950提供額外儲存空間，或亦可儲存裝置950之應用程式或其他資訊。具體地，擴展記憶體974可包含實行或補充上文所描述之程序之指令，且亦可包含安全資訊。因此，例如，擴展記憶體974可被提供為裝置950之一安全模組，且可用容許安全使用裝置950之指令進行程式化。另外，可經由SIMM卡提供安全應用程式以及額外資訊，諸如以一不可破解方式將識別資訊放置於SIMM卡上。Memory 964 stores information within computing device 950 . Memory 964 may be implemented as one or more of one or more computer-readable media, one or more volatile memory units, or one or more non-volatile memory units. Expansion memory 974 may also be provided and connected to device 950 through expansion interface 972, which may include, for example, a SIMM (Single Inline Memory Module) card interface. This extended memory 974 can provide additional storage space for the device 950, or can also store applications or other information of the device 950. Specifically, extended memory 974 may contain instructions to execute or supplement the procedures described above, and may also contain security information. Thus, for example, extended memory 974 may be provided as a security module of device 950 and programmed with instructions that allow device 950 to be used securely. In addition, security applications and additional information can be provided via the SIMM card, such as identification information placed on the SIMM card in an unbreakable manner.
記憶體可包含例如快閃記憶體及/或NVRAM記憶體，如下文所論述。在一個實施方案中，一電腦程式產品係有形地體現於一資訊載體中。電腦程式產品含有指令，該等指令在被執行時執行一或多種方法，諸如上文所描述之方法。資訊載體係可例如透過收發器968或外部介面960接收之一電腦或機器可讀媒體，諸如記憶體、擴展記憶體974或處理器952上之記憶體。Memory may include, for example, flash memory and/or NVRAM memory, as discussed below. In one embodiment, a computer program product is tangibly embodied in an information carrier. A computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrying system may receive a computer or machine-readable medium, such as memory, extended memory 974, or memory on processor 952, for example, through transceiver 968 or external interface 960.
裝置950可透過通信介面966進行無線通信，通信介面966必要時可包含數位信號處理電路。通信介面966可提供各種模式或協定下之通信，諸如GSM語音呼叫、SMS、EMS或MMS訊息傳遞、CDMA、TDMA、PDC、WCDMA、CDMA2000或GPRS等等。此通信可例如透過射頻收發器968發生。另外，可發生短程通信，諸如使用一藍牙、WiFi或其他此收發器(未展示)。另外，GPS (全球定位系統)接收器模組970可將額外導航及位置相關無線資料提供至裝置950，該資料可由在裝置950上運行之應用程式適當地使用。The device 950 can communicate wirelessly through the communication interface 966, which can include a digital signal processing circuit if necessary. The communication interface 966 can provide communication under various modes or protocols, such as GSM voice calling, SMS, EMS or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000 or GPRS, etc. This communication may occur through radio frequency transceiver 968, for example. Additionally, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). Additionally, a GPS (Global Positioning System) receiver module 970 can provide additional navigation and location-related wireless data to the device 950 , which data can be appropriately used by applications running on the device 950 .
裝置950亦可使用音訊編解碼器960進行音可聽通信，音訊編解碼器960可接收來自一使用者之口語資訊且將其轉換為可用數位資訊。音訊編解碼器960同樣可為一使用者產生可聽聲音，諸如透過一揚聲器，例如在裝置950之一手機中。此聲音可包含來自語音電話呼叫之聲音，可包含經記錄聲音(例如，語音訊息、音樂檔案等)且亦可包含由在裝置950上操作之應用程式產生之聲音。Device 950 may also perform audio-visual communication using audio codec 960, which may receive spoken information from a user and convert it into usable digital information. Audio codec 960 may also generate audible sound for a user, such as through a speaker, such as in a mobile phone at device 950. This sound may include sounds from voice phone calls, may include recorded sounds (eg, voice messages, music files, etc.) and may also include sounds generated by applications operating on device 950.
運算裝置950可以若干不同形式實施，如圖中所展示。例如，其可被實施為一蜂巢式電話980。其亦可被實施為一智慧型電話982、個人數位助理或其他類似行動裝置之部分。Computing device 950 may be implemented in several different forms, as shown in the figure. For example, it may be implemented as a cellular phone 980. It may also be implemented as part of a smart phone 982, personal digital assistant or other similar mobile device.
圖10展示一通用電腦系統1000之一實例，其可為圖7之手勢偵測電路360，其可與此處所描述之技術一起使用。運算系統1000意欲表示大規模資料處理裝置之各種實例形式，諸如伺服器、刀鋒伺服器、資料中心、大型主機及其他大規模運算裝置。運算系統1000可為具有多個處理器之一分佈式系統，可能包含由一或多個通信網路互連之網路附接儲存節點。此處所展示之組件、其等連接及關係以及其等功能僅意謂著係實例，且並不意謂限制本文件中所描述及/或主張之本發明之實施方案。FIG. 10 shows an example of a general-purpose computer system 1000, which may be the gesture detection circuit 360 of FIG. 7, which may be used with the techniques described herein. Computing system 1000 is intended to represent various example forms of large-scale data processing devices, such as servers, blade servers, data centers, mainframes, and other large-scale computing devices. Computing system 1000 may be a distributed system with multiple processors, possibly including network-attached storage nodes interconnected by one or more communications networks. The components, their connections and relationships, and their functions shown herein are meant to be examples only and are not meant to limit the embodiments of the invention described and/or claimed in this document.
運算系統1000可包含任何數目個運算裝置1080a至1080d。運算裝置1080a至1080d可包含透過一區域或廣域網路、專用光學鏈路、數據機、橋接器、路由器、交換機、有線或無線網路等進行通信之一伺服器或機架伺服器、大型主機等。Computing system 1000 may include any number of computing devices 1080a-1080d. Computing devices 1080a - 1080d may include a server or rack server, mainframe, etc. that communicates over a regional or wide area network, dedicated optical link, modem, bridge, router, switch, wired or wireless network, etc. .
在一些實施方案中，各運算裝置可包含多個機架。例如，運算裝置1080a包含多個機架1058a至1058n。各機架可包含一或多個處理器，諸如處理器1052a至1052n及1062a至1062n。處理器可包含資料處理器、網路附接儲存裝置及其他電腦控制裝置。在一些實施方案中，一個處理器可作為一主控處理器操作且控制排程及資料分配任務。處理器可透過一或多個機架交換機1062a至1062n互連，且一或多個機架可透過交換機1078連接。交換機1078可處置多個經連接運算系統1000之間的通信。In some implementations, each computing device may include multiple racks. For example, computing device 1080a includes multiple racks 1058a through 1058n. Each rack may include one or more processors, such as processors 1052a-1052n and 1062a-1062n. Processors may include data processors, network attached storage devices, and other computer control devices. In some embodiments, one processor may operate as a master processor and control scheduling and data distribution tasks. Processors may be interconnected through one or more rack switches 1062a-1062n, and one or more racks may be connected through switch 1078. The switch 1078 may handle communications between multiple connected computing systems 1000 .
各機架可包含記憶體，諸如記憶體1054及記憶體1064，以及儲存器，諸如1056及1066。儲存器1056及1066可提供大容量儲存且可包含揮發性或非揮發性儲存器，諸如網路附接磁碟、軟碟、硬碟、光碟、磁帶、快閃記憶體或其他類似固態儲存器裝置，或一裝置陣列，包含呈一儲存區域網路或其他組態之裝置。儲存器1056或1066可在多個處理器、多個機架或多個運算裝置之間共用，且可包含儲存可由該等處理器之一或多者執行之指令之一電腦可讀媒體。記憶體1054及1064可包含例如一或若干揮發性記憶體單元、一或若干非揮發性記憶體單元及/或其他形式之電腦可讀媒體，諸如一磁碟或光碟、快閃記憶體、快取區、隨機存取記憶體(RAM)、唯讀記憶體(ROM)及其等之組合。諸如記憶體1054之記憶體亦可在處理器1052a至1052n之間共用。諸如一索引之資料結構可例如跨儲存器1056及記憶體1054儲存。運算系統1000可包含未展示之其他組件，諸如控制器、匯流排、輸入/輸出裝置、通信模組等。Each rack may include memory, such as memory 1054 and memory 1064, and storage, such as 1056 and 1066. Storage 1056 and 1066 may provide mass storage and may include volatile or non-volatile storage, such as network-attached disks, floppy disks, hard disks, optical disks, tapes, flash memory, or other similar solid-state storage A device, or an array of devices, includes devices in a storage area network or other configuration. Storage 1056 or 1066 may be shared among multiple processors, multiple racks, or multiple computing devices, and may include computer-readable media storing instructions executable by one or more of the processors. Memories 1054 and 1064 may include, for example, one or more volatile memory units, one or more non-volatile memory units, and/or other forms of computer-readable media, such as a magnetic or optical disk, flash memory, flash memory, or other forms of computer-readable media. Fetch area, random access memory (RAM), read only memory (ROM) and combinations thereof. Memory, such as memory 1054, may also be shared among processors 1052a-1052n. A data structure such as an index may be stored across storage 1056 and memory 1054, for example. The computing system 1000 may include other components not shown, such as controllers, buses, input/output devices, communication modules, etc.
整個系統可由彼此通信之多個運算裝置1000組成。例如，裝置1080a可與裝置1080b、1080c及1080d通信，且此等可統稱為運算裝置1000。作為另一實例，圖7之手勢偵測電路360可包含一或多個運算裝置1000。一些運算裝置可能在地理上靠近彼此定位，而其他運算裝置可能在地理上遙遠地定位。系統1000之佈局僅為一實例且系統可呈現其他佈局或組態。The entire system may be composed of multiple computing devices 1000 communicating with each other. For example, device 1080a may communicate with devices 1080b, 1080c, and 1080d, and these may collectively be referred to as computing device 1000. As another example, the gesture detection circuit 360 of FIG. 7 may include one or more computing devices 1000. Some computing devices may be located geographically close to each other, while other computing devices may be located geographically distant. The layout of system 1000 is one example only and the system may assume other layouts or configurations.
此處所描述之系統及技術之各種實施方案可在數位電子電路、積體電路、經專門設計之ASIC (特定應用積體電路)、電腦硬體、韌體、軟體及/或其等之組合中實現。此各種實施方案可包含可在包含至少一個可程式化處理器之一可程式化系統上執行及/或解譯的一或多個電腦程式中之實施方案，該至少一個可程式化理器可為專用的或通用的，經耦合以自一儲存系統、至少一個輸入裝置及至少一個輸出裝置接收資料及指令以及將資料及指令傳輸至該儲存系統、該至少一個輸入裝置及該至少一個輸出裝置。Various implementations of the systems and techniques described herein may be implemented in digital electronic circuits, integrated circuits, specially designed ASICs (Application Specific Integrated Circuits), computer hardware, firmware, software, and/or combinations thereof. Realize. Such various implementations may include implementations in one or more computer programs that may be executed and/or interpreted on a programmable system including at least one programmable processor that may Special purpose or general purpose, coupled to receive data and instructions from and transmit data and instructions to a storage system, at least one input device and at least one output device .
此等電腦程式(亦稱為程式、軟體、軟體應用程式或程式碼)包含一可程式化處理器之機器指令，且可以一高階程序及/或物件導向程式設計語言及/或以組合/機器語言實施。如本文中所使用，術語「機器可讀媒體」、「電腦可讀媒體」指代用來將機器指令及/或資料提供至一可程式化處理器之任何電腦程式產品、設備及/或裝置(例如，磁碟、光碟、記憶體、可程式化邏輯裝置(PLD))，包含接收機器指令作為一機器可讀信號之一機器可讀媒體。術語「機器可讀信號」指代用來將機器指令及/或資料提供至一可程式化處理器之任何信號。These computer programs (also referred to as programs, software, software applications or code) contain machine instructions for a programmable processor and may be implemented in a high-level procedural and/or object-oriented programming language and/or in a combination/machine Language implementation. As used herein, the terms "machine-readable medium" and "computer-readable medium" refer to any computer program product, apparatus and/or device for providing machine instructions and/or data to a programmable processor ( For example, a magnetic disk, an optical disk, a memory, a programmable logic device (PLD)), including a machine-readable medium that receives machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
為提供與一使用者之互動，此處所描述之系統及技術可在一電腦上實施，該電腦具有用於向使用者顯示資訊之一顯示裝置(例如，一CRT (陰極射線管)或LCD (液晶顯示器)監視器)，以及使用者可藉由其將輸入提供至電腦之一鍵盤及一指向裝置(例如，一滑鼠或一軌跡球)。亦可使用其他種類之裝置來提供與一使用者之互動；例如，提供給使用者之回饋可為任何形式之感官回饋(例如，視覺回饋、聽覺回饋或觸覺回饋)；且可以任何形式接收來自使用者之輸入，包含聲音、語音或觸覺輸入。To provide interaction with a user, the systems and techniques described herein may be implemented on a computer having a display device (eg, a CRT (cathode ray tube) or LCD ( A liquid crystal display (LCD) monitor), and a keyboard and a pointing device (e.g., a mouse or a trackball) by which a user can provide input to the computer. Other types of devices can also be used to provide interaction with a user; for example, the feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and the feedback received from the user can be in any form. User input includes sound, voice or tactile input.
此處所描述之系統及技術可在一運算系統中實施，該運算系統包含一後端組件(例如，作為一資料伺服器)，或包含一中介軟體組件(例如，一應用程式伺服器)，或包含一前端組件(例如，具有一圖形使用者介面或一網頁瀏覽器之一用戶端電腦，一使用者可透過該用戶端電腦與此處所描述之系統及技術之一實施方案互動)，或此等後端、中介軟體或前端組件之任何組合。系統之組件可由數位資料通信之任何形式或媒體(例如，一通信網路)互連。通信網路之實例包含一區域網路(「LAN」)、一廣域網路(「WAN」)及網際網路。The systems and techniques described herein may be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes an intermediary software component (e.g., an application server), or Includes a front-end component (e.g., a client computer with a graphical user interface or a web browser through which a user can interact with an implementation of the systems and technologies described herein), or that Any combination of back-end, middleware or front-end components. The components of the system may be interconnected by any form or medium of digital data communication (eg, a communications network). Examples of communication networks include a local area network ("LAN"), a wide area network ("WAN") and the Internet.
運算系統可包含用戶端及伺服器。一用戶端及伺服器通常彼此遠離且通常透過一通信網路互動。用戶端與伺服器之關係憑藉在各自電腦上運行且彼此具有一用戶端-伺服器關係之電腦程式產生。The computing system may include clients and servers. A client and server are usually remote from each other and usually interact through a communications network. The client and server relationship arises by virtue of computer programs running on the respective computers and having a client-server relationship with each other.
已描述若干實施方案。然而，將理解，可在不脫離本說明書之精神及範疇之情況下進行各種修改。Several embodiments have been described. However, it will be understood that various modifications can be made without departing from the spirit and scope of the specification.
亦將理解，當一元件被稱為在另一元件上、連接至、電連接至、耦合至或電耦合至另一元件時，該元件可直接在該另一元件上、直接連接或耦合至該另一元件，或可存在一或多個中介元件。相比之下，當一元件被稱為直接在另一元件上、直接連接至或直接耦合至另一元件時，不存在中介元件。儘管術語直接在…上、直接連接至或直接耦合至可能未貫穿[實施方式]使用，但被展示為直接在…上、直接連接或直接耦合之元件可如此稱呼。可修正本申請案之發明申請專利範圍以敘述本說明書中所描述或圖中所展示之例示性關係。It will also be understood that when an element is referred to as being on, connected to, electrically connected to, coupled to or electrically coupled to another element, it can be directly on, directly connected or coupled to the other element. This other element may be present in one or more intervening elements. In contrast, when an element is referred to as being directly on, directly connected to, or directly coupled to another element, there are no intervening elements present. Although the terms directly on, directly connected to, or directly coupled to may not be used throughout [the embodiments], elements shown as being directly on, directly connected, or directly coupled may be so referred to. The patentable scope of this application may be amended to describe the illustrative relationships described in this specification or shown in the drawings.
雖然已如本文中所描述般闡釋所描述實施方案之特定特徵，但熟習此項技術者現在將想到許多修改、置換、改變及等效物。因此，應理解，隨附發明申請專利範圍意欲涵蓋如落入實施方案之範疇內之所有此等修改及改變。應理解，其等僅以實例而非限制之方式呈現，且可在形式及細節上進行各種改變。本文中所描述之設備及/或方法之任何部分可以任何組合進行組合，惟互斥組合除外。本文中所描述之實施方案可包含所描述之不同實施方案之功能、組件及/或特徵之各種組合及/或子組合。Although specific features of the described embodiments have been set forth as described herein, many modifications, permutations, changes and equivalents will now occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the scope of the embodiments. It is to be understood that they are presented by way of example only and not limitation, and that various changes in form and details may be made. Any portion of the apparatus and/or methods described herein may be combined in any combination, except mutually exclusive combinations. The implementations described herein may include various combinations and/or subcombinations of the functions, components, and/or features of the different implementations described.
另外，圖中所描繪之邏輯流程不要求所展示之特定順序或循序順序以達成所要結果。另外，可提供其他步驟，或可自所描述流程消除步驟，且可將其他組件添加至所描述系統或自所描述系統移除。因此，其他實施方案係在以下發明申請專利範圍之範疇內。Additionally, the logical flows depicted in the figures do not require the specific order shown, or sequential order, to achieve desirable results. Additionally, other steps may be provided or eliminated from the described processes, and other components may be added to or removed from the described systems. Accordingly, other embodiments are within the scope of the following invention claims.
100:智慧型眼鏡/頭戴式可穿戴裝置 102:框架 103:邊緣部分 104:顯示裝置 105:臂部分 106:音訊輸出裝置 107:鏡片 108:照明裝置 109:橋接部分 110:鉸鏈部分 111:感測系統 112:控制系統 114:處理器 116:影像捕獲裝置/相機 120:視線追蹤裝置 125:感測器 140:可視區 144:輸出耦合器 200:圖 210:紅外線(IR)發光二極體(LED) 212:輻射 220:紅外線(IR)偵測器/光體積變化描記圖法(PPG)感測器 230:皮膚表面 232:角質層 234:表皮 236:皮下組織/真皮 240:毛細血管 242:反射輻射 246:紅血球 250:圖 260:信號 270:毛細血管 280:毛細血管 300:腕戴式影像捕獲裝置 310:發光二極體(LED)驅動器 320:發光二極體(LED)微控制器 330:底座/外殼 340:相機 350:腕帶 360:手勢偵測電路 410:右成像器/右投影儀/偵測器 420:紅外線(IR)投影儀 430:左成像器/左投影儀/左偵測器 440:RGB模組 500:仰視圖 510:輻射擋板 520:紅外線(IR)發光二極體(LED)對/紅外線(IR)發光二極體(LED) 522:紅外線(IR)發光二極體(LED)對/紅外線(IR)發光二極體(LED) 612:輻射束 616:輻射束 620:角度 630:半發散角/角度 722:網路介面 724:處理單元 726:非暫時性記憶體 730:影像管理器 732:影像資料 732(1)至732(N):二維影像序列 740:灌注指數(PI)模型管理器 741:灌注指數(PI)模型訓練管理器 742:灌注指數(PI)模型資料 743:灌注指數(PI)模型訓練資料 744:CNN迴歸因子資料 745:關鍵點資料 746(1)至746(T):二維影像序列 747(1)至747(T):灌注指數(PI)資料 748:卷積層資料 749:灌注指數(PI)/FC層資料 750:手勢模型管理器 752:手勢模型資料 754:增量灌注指數(PI)資料 756:手勢映射資料 760:基於手勢之命令管理器 800:方法 802:影像捕獲裝置捕獲穿過使用者的腕之皮膚之影像序列 804:PI模型管理器基於影像序列判定生物流體流動度量 806:手勢模型管理器基於生物流體流動度量判定由使用者形成之手勢 808:基於手勢之命令管理器基於手勢觸發與在AR系統中顯示物件相關的命令之執行 900:通用電腦裝置/運算裝置 902:處理器 904:記憶體 906:儲存裝置 908:高速介面/高速控制器 910:高速擴展埠 912:低速介面/低速控制器 914:低速匯流排/低速擴展埠 916:顯示器 920:伺服器 922:膝上型電腦 924:機架伺服器系統 950:通用行動電腦裝置/運算裝置 952:處理器 954:顯示器 956:顯示介面 958:控制介面 960:外部介面/音訊編解碼器 966:通信介面 968:收發器 970:全球定位系統(GPS)接收器模組 972:擴展介面 974:擴展記憶體 980:蜂巢式電話 982:智慧型電話 1000:通用電腦系統/運算系統/運算裝置 1052a至1052n:處理器 1054:記憶體 1056:儲存器 1058a至1058n:機架 1062a至1062n:處理器/機架交換機 1064:記憶體 1066:儲存器 1078:交換機 1080a至1080d:運算裝置 100:Smart glasses/head-mounted wearable devices 102:Frame 103: Edge part 104:Display device 105:Arm part 106:Audio output device 107:Lens 108:Lighting device 109:Bridge part 110:Hinge part 111: Sensing system 112:Control system 114: Processor 116:Image capture device/camera 120: Gaze tracking device 125: Sensor 140:Visual area 144:Output coupler 200: Figure 210: Infrared (IR) light-emitting diode (LED) 212:Radiation 220: Infrared (IR) detector/Photoplethysmography (PPG) sensor 230:Skin surface 232: stratum corneum 234: Epidermis 236: Subcutaneous tissue/dermis 240:Capillaries 242: Reflected radiation 246:Red blood cells 250: Figure 260:signal 270:Capillaries 280:Capillaries 300: Wrist-worn image capture device 310:Light-emitting diode (LED) driver 320: Light Emitting Diode (LED) Microcontroller 330:Base/casing 340:Camera 350: Wristband 360: Gesture detection circuit 410: Right imager/right projector/detector 420: Infrared (IR) projector 430: Left imager/left projector/left detector 440:RGB module 500: Bottom view 510: Radiation baffle 520: Infrared (IR) light-emitting diode (LED) pair/Infrared (IR) light-emitting diode (LED) 522: Infrared (IR) light-emitting diode (LED) pair/Infrared (IR) light-emitting diode (LED) 612: Radiation Beam 616: Radiation Beam 620:Angle 630: Half divergence/angle 722:Network interface 724:Processing unit 726: Non-transitory memory 730:Image Manager 732:Image data 732(1) to 732(N): 2D image sequence 740:Perfusion Index (PI) Model Manager 741:Perfusion Index (PI) Model Training Manager 742:Perfusion Index (PI) model data 743:Perfusion Index (PI) model training data 744:CNN regression factor data 745:Key point information 746(1) to 746(T): 2D image sequence 747(1) to 747(T): Perfusion Index (PI) data 748: Convolutional layer data 749:Perfusion Index (PI)/FC layer data 750: Gesture Model Manager 752: Gesture model information 754: Incremental perfusion index (PI) data 756: Gesture mapping information 760: Gesture-based command manager 800:Method 802: The image capture device captures an image sequence passing through the skin of the user's wrist 804: PI model manager determines biological fluid flow metrics based on image sequences 806: Gesture model manager determines gestures formed by the user based on biofluid flow metrics 808: Gesture-based command manager triggers execution of commands related to displaying objects in the AR system based on gestures 900:General computer device/computing device 902: Processor 904:Memory 906:Storage device 908: High-speed interface/high-speed controller 910:High-speed expansion port 912:Low speed interface/low speed controller 914: Low-speed bus/low-speed expansion port 916:Display 920:Server 922:Laptop 924:Rack server system 950: General mobile computer device/computing device 952: Processor 954:Display 956:Display interface 958:Control interface 960:External interface/audio codec 966: Communication interface 968:Transceiver 970: Global Positioning System (GPS) receiver module 972:Extended interface 974:Extended memory 980: Cellular Telephone 982:Smart phone 1000: General computer system/computing system/computing device 1052a to 1052n: Processor 1054:Memory 1056:Storage 1058a to 1058n: Rack 1062a to 1062n: Processor/Rack Switch 1064:Memory 1066:Storage 1078:Switch 1080a to 1080d: computing device
圖1A繪示根據本文中所描述之實施方案之一例示性系統。Figure 1A illustrates an exemplary system according to implementations described herein.
圖1B係根據本文中所描述之實施方案之圖1A中所展示的例示性頭戴式可穿戴裝置之一前視圖，圖1C係一後視圖，且圖1D係一透視圖。Figure IB is a front view of the exemplary head-mounted wearable device shown in Figure IA, Figure 1C is a rear view, and Figure ID is a perspective view, according to embodiments described herein.
圖2A係繪示運用一紅外線(IR)發光二極體(LED)對皮下組織中之一毛細血管之一例示性照明之一圖。2A is a diagram illustrating exemplary illumination of a capillary blood vessel in subcutaneous tissue using an infrared (IR) light emitting diode (LED).
圖2B係繪示其中強度取決於一毛細血管中之紅血球密度之一例示性信號之一圖。Figure 2B is a graph illustrating an exemplary signal in which intensity depends on the density of red blood cells in a capillary blood vessel.
圖3係繪示一例示性腕戴式影像捕獲裝置之一圖。FIG. 3 is a diagram illustrating an exemplary wrist-worn image capture device.
圖4係繪示腕戴式影像捕獲裝置內用於偵測一對通道中之IR及/或RGB照明一之例示性相機之一圖。4 is a diagram illustrating an exemplary camera within a wrist-worn image capture device for detecting IR and/or RGB illumination in a pair of channels.
圖5係繪示例示性腕戴式影像捕獲裝置之一仰視圖之一圖。FIG. 5 illustrates a bottom view of an exemplary wrist-worn image capture device.
圖6係繪示例示性腕戴式影像捕獲裝置之一側視圖之一圖，其中照明由IR LED提供。6 is a diagram illustrating a side view of an exemplary wrist-worn image capture device with illumination provided by an IR LED.
圖7係繪示例示性手勢偵測電路之一圖。FIG. 7 is a diagram illustrating an exemplary gesture detection circuit.
圖8係繪示根據所揭示實施方案之一例示性方法之一流程圖。Figure 8 is a flowchart illustrating an exemplary method in accordance with the disclosed embodiments.
圖9係繪示可用來實施所描述技術之一電腦裝置及一行動電腦裝置之一實例之一圖。9 is a diagram illustrating an example of a computer device and a mobile computer device that may be used to implement the described techniques.
圖10係繪示可用來實施所描述技術之一分佈式電腦裝置之一實例之一圖。Figure 10 is a diagram illustrating an example of a distributed computer device that may be used to implement the described techniques.
100:智慧型眼鏡/頭戴式可穿戴裝置 100:Smart glasses/head-mounted wearable devices
102:框架 102:Frame
103:邊緣部分 103: Edge part
105:臂部分 105:Arm part
107:鏡片 107:Lens
109:橋接部分 109:Bridge part
Claims (20)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US17/809,772 US11934586B2 (en) | 2022-06-29 | 2022-06-29 | Gesture detection via image capture of subdermal tissue from a wrist-pointing camera system |
US17/809,772 | 2022-06-29 |
Publications (1)
Publication Number | Publication Date |
---|---|
TW202401211A true TW202401211A (en) | 2024-01-01 |
Family
ID=87003304
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
TW112121356A TW202401211A (en) | 2022-06-29 | 2023-06-08 | Gesture detection via image capture of subdermal tissue from a wrist-pointing camera system |
Country Status (3)
Country | Link |
---|---|
US (1) | US11934586B2 (en) |
TW (1) | TW202401211A (en) |
WO (1) | WO2024006603A1 (en) |
Family Cites Families (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10921886B2 (en) | 2012-06-14 | 2021-02-16 | Medibotics Llc | Circumferential array of electromyographic (EMG) sensors |
US9081417B2 (en) * | 2012-11-30 | 2015-07-14 | Blackberry Limited | Method and device for identifying contactless gestures |
US20170000392A1 (en) * | 2015-07-01 | 2017-01-05 | Rememdia LC | Micro-Camera Based Health Monitor |
KR102570068B1 (en) * | 2015-11-20 | 2023-08-23 | 삼성전자주식회사 | Gesture recognition method, gesture recognition apparatus, wearable device |
US10105608B1 (en) * | 2015-12-18 | 2018-10-23 | Amazon Technologies, Inc. | Applying participant metrics in game environments |
CN111052047B (en) | 2017-09-29 | 2022-04-19 | 苹果公司 | Vein scanning device for automatic gesture and finger recognition |
US10970936B2 (en) * | 2018-10-05 | 2021-04-06 | Facebook Technologies, Llc | Use of neuromuscular signals to provide enhanced interactions with physical objects in an augmented reality environment |
US11481030B2 (en) | 2019-03-29 | 2022-10-25 | Meta Platforms Technologies, Llc | Methods and apparatus for gesture detection and classification |
US10466783B2 (en) | 2018-03-15 | 2019-11-05 | Sanmina Corporation | System and method for motion detection using a PPG sensor |
US11754824B2 (en) * | 2019-03-26 | 2023-09-12 | Active Medical, BV | Method and apparatus for diagnostic analysis of the function and morphology of microcirculation alterations |
US20200375513A1 (en) | 2019-06-03 | 2020-12-03 | Rajesh S. Kasbekar | Pulse oximeter sensors with reduced sensitivity to motion artifacts |
US11422623B2 (en) | 2019-10-23 | 2022-08-23 | Interlake Research, Llc | Wrist worn computing device control systems and methods |
WO2021091604A1 (en) * | 2019-11-08 | 2021-05-14 | Apple Inc. | Machine-learning based gesture recognition using multiple sensors |
US20220233096A1 (en) * | 2021-01-27 | 2022-07-28 | Covidien Lp | Systems and methods for non-contact respiratory monitoring |
CN112783326A (en) | 2021-01-28 | 2021-05-11 | 唐庆圆 | Gesture recognition device and gesture recognition system |
-
2022
- 2022-06-29 US US17/809,772 patent/US11934586B2/en active Active
-
2023
- 2023-05-31 WO PCT/US2023/067681 patent/WO2024006603A1/en unknown
- 2023-06-08 TW TW112121356A patent/TW202401211A/en unknown
Also Published As
Publication number | Publication date |
---|---|
WO2024006603A1 (en) | 2024-01-04 |
US11934586B2 (en) | 2024-03-19 |
US20240004476A1 (en) | 2024-01-04 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8933912B2 (en) | Touch sensitive user interface with three dimensional input sensor | |
CN110352364B (en) | Multispectral illumination and sensor module | |
US9304594B2 (en) | Near-plane segmentation using pulsed light source | |
US9710973B2 (en) | Low-latency fusing of virtual and real content | |
US9285872B1 (en) | Using head gesture and eye position to wake a head mounted device | |
CN105917292B (en) | Utilize the eye-gaze detection of multiple light sources and sensor | |
US9710130B2 (en) | User focus controlled directional user input | |
US11256336B2 (en) | Integration of artificial reality interaction modes | |
CN108700932A (en) | It can carry out the wearable device of eye tracks | |
US20160131902A1 (en) | System for automatic eye tracking calibration of head mounted display device | |
CN116027894A (en) | Passive optical and inertial tracking for slim form factors | |
CN104749777B (en) | The interactive approach of wearable smart machine | |
JP2017102768A (en) | Information processor, display device, information processing method, and program | |
US20220121292A1 (en) | Control method, control device, electronic device, and storage medium | |
US20210365535A1 (en) | Eye scanner for user identification and security in an eyewear device | |
KR20170028130A (en) | Wearable device | |
US20180075294A1 (en) | Determining a pointing vector for gestures performed before a depth camera | |
WO2021047331A1 (en) | Control method, electronic device, and storage medium | |
CN108279496B (en) | Eyeball tracking module and method of video glasses and video glasses | |
Czuszynski et al. | Septic safe interactions with smart glasses in health care | |
US10936061B2 (en) | Eye tracking using reverse-biased light-emitting diode devices | |
US11934586B2 (en) | Gesture detection via image capture of subdermal tissue from a wrist-pointing camera system | |
KR20220148922A (en) | Geospatial image surfacing and selection |