CN108604451A - Filter the wind noise in video content - Google Patents
Filter the wind noise in video content Download PDFInfo
- Publication number
- CN108604451A CN108604451A CN201680081782.3A CN201680081782A CN108604451A CN 108604451 A CN108604451 A CN 108604451A CN 201680081782 A CN201680081782 A CN 201680081782A CN 108604451 A CN108604451 A CN 108604451A
- Authority
- CN
- China
- Prior art keywords
- wind noise
- audio
- segment
- replacement operation
- artifact
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/439—Processing of audio elementary streams
- H04N21/4394—Processing of audio elementary streams involving operations for analysing the audio stream, e.g. detecting features or characteristics in audio streams
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/48—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use
- G10L25/51—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for comparison or discrimination
- G10L25/57—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for comparison or discrimination for processing of video signals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/09—Arrangements for device control with a direct linkage to broadcast information or to broadcast space-time; Arrangements for control of broadcast-related services
- H04H60/11—Arrangements for counter-measures when a portion of broadcast information is unavailable
- H04H60/12—Arrangements for counter-measures when a portion of broadcast information is unavailable wherein another information is substituted for the portion of broadcast information
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/56—Arrangements characterised by components specially adapted for monitoring, identification or recognition covered by groups H04H60/29-H04H60/54
- H04H60/58—Arrangements characterised by components specially adapted for monitoring, identification or recognition covered by groups H04H60/29-H04H60/54 of audio
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/61—Arrangements for services using the result of monitoring, identification or recognition covered by groups H04H60/29-H04H60/54
- H04H60/65—Arrangements for services using the result of monitoring, identification or recognition covered by groups H04H60/29-H04H60/54 for using the result on users' side
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/233—Processing of audio elementary streams
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/439—Processing of audio elementary streams
- H04N21/4398—Processing of audio elementary streams involving reformatting operations of audio signals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/44016—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving splicing one content stream with another content stream, e.g. for substituting a video clip
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/44—Receiver circuitry for the reception of television signals according to analogue transmission standards
- H04N5/60—Receiver circuitry for the reception of television signals according to analogue transmission standards for the sound signals
- H04N5/602—Receiver circuitry for the reception of television signals according to analogue transmission standards for the sound signals for digital sound signals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/76—Television signal recording
- H04N5/91—Television signal processing therefor
- H04N5/911—Television signal processing therefor for the suppression of noise
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N9/00—Details of colour television systems
- H04N9/79—Processing of colour television signals in connection with recording
- H04N9/80—Transformation of the television signal for recording, e.g. modulation, frequency changing; Inverse transformation for playback
- H04N9/802—Transformation of the television signal for recording, e.g. modulation, frequency changing; Inverse transformation for playback involving processing of the sound signal
Abstract
Embodiment discloses the wind noise in filtering video content.A kind of method include receive include audio component and video component video content；The generation of the wind noise pseudomorphism in the segment of audio component is detected by processing equipment；Identify the intensity of the duration and wind noise artifact of wind noise pseudomorphism；Wind noise replacement operation is selected by the duration that is identified of the processing equipment based on wind noise artifact and intensity；And selected wind noise replacement operation is applied to remove wind noise artifact from segment by the segment of audio component by processing equipment.
Description
Technical field
This disclosure relates to content shared platform field, and in particular it relates to the wind noise in filtering video content.
Background technology
Many contents, which share website, allows user to issue the image and video shown for both privately and publicly owned.Nearest technology
Progress has also made user increasingly facilitate capture and has shared themselves vision content.For example, with one or more high
The smart mobile phone of quality digital camera, rich store space and mobile broadband allows user from substantially any place record and shares
Themselves video.But the video recorded outdoors is easy by distortion caused by environment.Common arch-criminal is wind
Noise leads to the undesirable slicing of audio signal, significantly decreases the experience of user.
Invention content
The invention content of following simplification for being the disclosure is in order to providing the basic comprehension to some aspects of the disclosure.This
Invention content is not the extensive overview ot to the disclosure.It is neither intended to the key or important elements of the mark disclosure, is not intended to
Any range of the particular implementation of the disclosure or any range of claim are described.Its sole purpose is in simplified form
Some concepts that the disclosure is presented, as the preamble in greater detail presented later.
In one aspect of the present disclosure, a kind of method includes extracting audio component from the video content received, this is regarded
Frequency content includes audio component and video component；The hair of the wind noise artifact in the segment of audio component is detected by processing equipment
It is raw；Identify the intensity of the duration and wind noise artifact of wind noise artifact；It is pseudo- based on the wind noise identified by processing equipment
The duration of shadow and intensity select at least one wind noise replacement operation；And by processing equipment by selected wind noise
Replacement operation is applied to the segment of audio component to remove wind noise artifact from segment.In one embodiment, processing is set
It is standby that at least one wind noise replacement operation is selected from multiple and different wind noise replacement operations.In one embodiment, should
Method can also include receiving video content.
In one embodiment, wind noise replacement operation includes being carried with from other segments of the audio component around segment
The interpolation of the audio signal taken carrys out stuffer.It adds or alternatively, wind noise replacement operation may include filtering segment
To remove wind noise artifact from the segment.It adds or alternatively, wind noise replacement operation may include with mute replacement blade
Section.It adds or alternatively, wind noise replacement operation may include being believed with the audio of another snippet extraction from audio component
Number replace wind noise artifact.It adds or alternatively, wind noise replacement operation may include being replaced with different audio components
Audio component.
In another embodiment, user is prompted to select with different audio components.In addition, the selection in method is extremely
A few wind noise replacement operation may further include, from the strong of the duration identified and the wind noise artifact identified
Degree exports multiple signals；Signal derived from institute is mapped to corresponding threshold set, and selects and is mapped to institute's sending out signals
The corresponding at least one wind noise replacement operation of threshold set.
In addition, derived from signal may include one or more frequencies of wind noise artifact and opposite with wind noise artifact
The signal-to-noise ratio answered.In addition, the duration of the identification wind noise artifact in method can also include identification wind-engaging noise artifacts shadow
The percentage of loud audio component.In one embodiment, machine learning be used to detect the generation of wind noise artifact.Another
In one embodiment, deep learning be used to detect the generation of wind noise artifact.In addition, frequency spectrum map analysis can be used to detect
The generation of wind noise artifact.
In another aspect of the present disclosure, a kind of system includes：Memory；And processing equipment, the processing equipment are coupled to
Memory, wherein processing equipment are configured to execute the method according to any aspect described herein or embodiment.
In another aspect of the present disclosure, machine readable storage medium (it can be non-transitory machinable medium,
But this aspect is without being limited thereto) store instruction, it includes according to described herein any to make processing equipment execution when executing an instruction
The operation of the method for aspect or embodiment.In another aspect of the present disclosure, computer program product includes instruction, when program by
When computer executes, which makes computer execute according to any aspect described herein or the method for embodiment.
The computing device of open operation and various embodiments described herein for executing the above method.It is also disclosed and deposits
Computer-readable Jie of the storage for executing associated with the above method operation and the instruction of various embodiments described herein
Matter.It will be understood that embodiment can be combined so that the feature in one aspect or described in the context of embodiment can
It is combined with the feature of other aspects or embodiment.Particularly, it although various embodiments are described above, will manage
Solution, features described above can be combined into one or more combinations of the feature of embodiment, to provide further embodiment.
Description of the drawings
In the figure of attached drawing, the disclosure is illustrated by example in a non-limiting manner.
Fig. 1 is the block diagram for the exemplary network architecture that embodiment of the present disclosure may be implemented in diagram.
Fig. 2 is the block diagram according to the audio regulating system of embodiment of the present disclosure.
Fig. 3 is the flow chart for illustrating the method for filtering the wind noise in video content according to embodiment.
Fig. 4 is the flow chart for illustrating the another method for filtering the wind noise in video content according to embodiment.
Fig. 5 is a kind of block diagram for the embodiment for illustrating the computer system according to embodiment.
Specific implementation mode
The aspect and embodiment of the disclosure are for the wind noise in filtering video content.In one embodiment, wind
Noise regulating system provides automatic wind noise measuring and correction/replacement of wind noise in the user video of content shared platform.
When user is by videograph and/or when uploading to content shared platform, wind noise regulating system automatically analyzes video content
Audio component is to identify the wind noise (that is, wind noise artifact) of any appearance.For any wind noise detected, identification is wherein
There is the audio fragment of wind noise, the intensity of wind noise and duration and the audio fragment with the wind noise identified
Surrounding context audio is (that is, other before the audio fragment of the wind noise including detecting identified and/or after it
The predetermined time interval of segment) it is used for determining that the wind noise for being applied to the audio fragment with identified wind noise replaces behaviour
The type of work.Wind noise replacement operation may include being filled out with the interpolation (interpolation) of ambient audio signal or spectrogram
Wind noise audio fragment is filled, wind noise is filtered from audio fragment, by from video or mute non-slicing (non-clipped)
The estimation of ambient noise replace audio fragment, or replace the entire audio file of video with background music or other tracks
(after prompting user).
For reducing wind noise existing solution do not provide using based on wind noise characteristic carry out wind noise replace
The various methods changed.Audio letter is recorded simultaneously dependent on several microphones for reducing the Previous solutions of wind noise
Number and reduce unnecessary ambient noise using these multiple records.It is competition source that another approach, which is by environmental modeling, and is made
With source separate technology to filter wind noise.However, wind noise can result in slicing (that is, sending signal to peak swing), this
It is that it excludes the destructive transformation of the application of these existing solutions.Embodiment of the present disclosure is based on the wind noise detected
Characteristic the uses of various wind noise replacement operations is provided, wherein generating video and/or video being uploaded to content share platform
When wind noise (including slicing) detection and replacement be performed automatically.In this way, embodiment from record on the mobile apparatus and/or
It uploads to and removes wind noise artifact in the video of content shared platform automatically, so as to improve the whole user in content shared platform
Experience.
In order to simple and succinct, the disclosure usually quotes video.However, the introduction of the disclosure is usually applied to media item,
And perhaps media item, including such as video, audio, text, image, program instruction in various types of can be applied to
Deng.
The example system architecture 100 of Fig. 1 diagrams in accordance with one embodiment of the present disclosure.System architecture 100 includes client
End equipment 110A to 110Z, network 105, data storage 106, content shared platform 120 and server 130.In an embodiment party
In formula, network 105 may include public network (for example, internet), dedicated network (for example, LAN (LAN) or wide area network
(WAN)), cable network (for example, Ethernet), wireless network (for example, 802.11 networks or Wi-Fi network), Cellular Networks network diagram
Network (for example, long term evolution (LTE) network), router, hub, interchanger, server computer and/or a combination thereof.One
In a embodiment, data storage 106 can be memory (for example, random access memory), cache, driver (example
Such as, hard disk drive), flash drive, Database Systems or data-storable other kinds of component or equipment.Data
Storage 106 can also include multiple storage assemblies (for example, multiple drivers or multiple databases), can also cross over multiple meters
Calculate equipment (for example, multiple server computers).
Client device 110A to 110Z can include computing device, such as personal computer (PC), calculating on knee
Machine, mobile phone, smart phone, tablet computer, netbook computer, network connection TV etc..In some embodiments
In, client device 110A to 110Z is referred to as " user equipment ".Each client device includes Media Viewer 111.
In one embodiment, Media Viewer 111 can be that user is allowed to check content, such as image, video, webpage, document
Etc. application.For example, Media Viewer 111 can be being able to access that, retrieve, presents and/or leading by Web Server Service
The web browser of content of navigating (for example, webpage of hypertext markup language (HTML) page, digital media item etc.).Media
Reader 111 can be to user's presentation, display and/or presentation content (for example, webpage, Media Viewer).Media Viewer 111
Can also show be embedded in it is embedding in webpage (for example, the webpage of the information about the product sold by online merchants can be provided)
Enter formula media player (for example,Player or HTML5 players).In another example, Media Viewer 111 can
To be that user is allowed to check the independent utility of digital media item (for example, digital video, digital picture, e-book etc.) (for example, moving
Dynamic application or application).According to the aspect of the disclosure, Media Viewer 111 can be for user record, edit and/or upload
Content shared platform application for the content shared in content shared platform, and realize that the wind in filtering video content is made an uproar
Sound.
Media Viewer 111 can be supplied to client device 110A by server 130 and/or content shared platform 120
To 110Z.For example, Media Viewer 111 can be built-in the embedded matchmaker in the webpage provided by content shared platform 120
Body player.In another example, Media Viewer 111 can be the application downloaded from server 130.
In general, if appropriate, being described as also capable of by the function that content shared platform 120 executes in one embodiment
It is executed on client device 110A to 110Z in other embodiments.In addition, the function of being attributed to specific components can be by
The different or multiple components that operate together execute.Content shared platform 120 can also be used as and be connect by application programming appropriate
Mouth is supplied to the service of other systems or equipment to access, and is therefore not limited to the use in website.
In one embodiment, content shared platform 120 can be that (such as rack takes one or more computing devices
Be engaged in device, router computer, server computer, personal computer, mainframe computer, laptop computer, tablet computer,
Desktop computer etc.), data storage (for example, hard disk, memory, database), network, component software and/or hardware component,
The access to media item can be used to provide a user and/or provide media item to user.For example, content shared platform 120
It can allow customer consumption, upload, search, approval (" liking "), not like and/or comment on media item.Content shared platform 120
Can also include that can be used for providing a user the website (for example, webpage) of the access to media item or using back-end software.
In embodiment of the present disclosure, " user " can be expressed as single individual.However, other of the disclosure realize packet
It is the entity controlled by one group of user and/or automatic source containing " user ".For example, joint is of the community in social networks
People user's set can be considered as " user ".In another example, automation consumer can be oneself of content shared platform 120
Dynamic intake pipeline, such as topic channel.
Content shared platform 120 may include multiple channels (for example, channel A to Z).Channel can be can from common source
Data content or data content with topics common, theme or essence.Data content can be number selected by user
Word content, by the available digital content of user, by user upload digital content, by content supplier selection digital content,
By the digital content etc. of broadcaster's selection.For example, channel X can include video Y and Z.Channel can be associated with the owner,
The owner be can on channel execution act user.It can be produced on channel based on the action of the owner, such as owner
Upper available digital content, the owner select (for example, liking) digital content associated with another channel, owner's comment and
Another associated digital content of channel etc., different activities is associated with channel.It can will work associated with channel
It is dynamic to be collected into the activity feeding for channel.User other than channel owners can subscribe to wherein that they are interested
One or more channels.The concept of " subscription " is referred to as " liking (liking) ", " concern (following) ", " plusing good friend
(friending) " etc..
Once user subscribes to channel, it will be able to the information of the activity feeding from channel be presented to user.If user orders
Multiple channels are read, then the activity feed combination for each channel that user subscribes to can be fed at combined activities.It lives from joint
The information of dynamic feeding can be presented to user.Channel may have the feeding of oneself.For example, when navigating to content shared platform
On channel homepage when, the feeding item generated by the channel can be shown on channel homepage.User can have joint feedback
It send (syndicated feed), joint feeding is the subset group of the content item at least by all channels subscribed to from user
At feeding.Joint feeding can also include the content item from the unsubscribed channel of user.For example, content shared platform 120
Or the content item of recommendation can be inserted into the joint feeding of user by other social networks, or can be inserted in joint is fed
Enter the associated content item of relevant connection with user.
Each channel may include one or more media items 121.The example of media item 121 can include but not limited to count
Word video, digital movie, digital photos, digital music, web site contents, social media update, e-book (e-book), electronics
Magazine, digital newspaper, digital talking book, electronic journal, web blog, Simple Syndication (RSS) feeding, electronics caricature
Book, software application etc..In some embodiments, media item 121 is also referred to as content item.
Media item 121 can be consumed via internet and/or via mobile device application.For succinct and simple
See, example of the Online Video (hereinafter also referred to video) as media item 121 is used in entire document.As used herein
, " media ", media item, " online Media item ", " Digital Media ", " digital media item ", " content " and " content item " can
Including that the software, firmware or hardware that are configured to that digital media item is presented to entity can be used to execute or the electronics of load text
Part.In one embodiment, content shared platform 120 can store 106 to store media item 121 using data.
In one embodiment, server 130 can be one or more computing devices (for example, rack-mount server,
Server computer etc.).In one embodiment, in 130 includable appearance shared platform 120 of server.Server
130 may include audio regulating system 140.Audio regulating system 140, which makes it possible to filter in embodiment of the present disclosure, to be used
Wind noise in indoor appearance.In some embodiments, client device 110A-110Z may include that client-side audio is adjusted
System 115 can filter the wind noise in user content.Client-side audio regulating system 115 can be independently of server
130 audio regulating system 140 executes embodiments of the present invention, or can be worked with combining audio regulating system 140.Under although
The description in face can refer to the audio regulating system 140 for executing embodiments of the present invention, it should be appreciated that audio regulating system 140
Function can be similarly executed separately simultaneously by the client-side audio regulating system 115 of client device 110A-110Z
And/or the client-side audio regulating system 115 at person's collaboration customer end equipment 110A-110Z executes.
In one embodiment, user content may include video.Video is the sequential chart for indicating the scene in movement
As frame set.For example, a series of consecutive images can be rebuild continuously or later to generate animation.Video content can be with various
Format is presented, including but not limited to simulation, number, two and three dimensions video.In addition, video content may include showing in order
Film, video clipping or any animated image set shown.In addition, video content can be stored in including video component and audio
In the video file of component.Video component also refer to video code model video data (for example, H.264,
H.264MPEG-4 part 2 etc.).Audio component also refers to the audio data of audio coding formats (for example, advanced audio is compiled
Code (AAC), MP3 etc.).
The user of content shared platform 120 may include in the case of can not considering weather condition outdoors theirs
The amateur of video is recorded on equipment (for example, camera phone) 110A-Z.For example, on bad weather, seabeach, such as
The video recorded during the hazardous sports such as skiing is usually easily influenced by the noise caused by wind regime.Audio regulating system 140 can
The automatic wind noise measuring and correction of video content are provided to analyze video content.Audio regulating system 140 can be analyzed and be regarded
The audio component (also referred to as audio file, audio stream, audio signal, auditory information etc.) of frequency content is to detect in audio component
The generation of wind noise artifact.Wind noise artifact also refer to auditory information capture (e.g., including the video of audio component
Record) during mistake or exception in the perception or expression of the auditory information (for example, audio component) that are introduced by wind.
Audio regulating system 140 according to the wind noise artifact detected characteristic selection wind noise replacement operation for correction and/or
Replace the wind noise artifact detected in audio component.
In one embodiment, the wind noise replacement operation that audio regulating system 140 uses can depend on detecting
Wind noise artifact direction and intensity and change.In one embodiment, wind noise replacement operation may include but unlimited
Wind noise artifact is filled in the interpolation for the audio signal extracted by surrounding's segment (segment) from audio component, use is quiet
Sound replaces wind noise artifact, replaces wind noise artifact with the audio fragment of surrounding's snippet extraction from audio component, or with not
Same audio component replaces entire audio component.
In some embodiments, the audio regulating system 140 of server 130 can be interacted with content shared platform 120
To provide embodiment of the present disclosure.Below with reference to Fig. 2 be more fully described audio regulating system 140 and its specific function into
One step describes.
Although in content shared platform and the shared aspect of social networks of the content item in content shared platform is promoted to discuss
Embodiment of the present disclosure, but embodiment generally also can be applied to provide any kind of society of the connection between user
Hand over network.Embodiment of the present disclosure is not limited to provide a user the content shared platform of channel subscription.
The system discussed herein wherein collects the personal information about user or can utilize the feelings of personal information
Under condition, it can provide a user whether control content shared platform 120 collects user information (for example, the social network about user
The information of network, social action or movable, profession, the preference of user or the current location of user.), or control whether and/or how
The chance of content that may be more relevant with user is received from content server.In addition, certain data can be stored or made at it
With handling in one or more ways before so that remove personal identifiable information.For example, the identity of user can be handled,
So that cannot determine personally identifiable information for user, or can extensive acquisition location information (such as city, postcode or state
Rank) user geographical location so that not can determine that the specific position of user.Therefore, user can close for controlling how collecting
In user information and used by content shared platform 120.
Fig. 2 is the block diagram for illustrating audio regulating system 140 according to embodiment of the present invention.As discussed above
, audio regulating system 140 can be interacted with single social networks, or can be used in multiple social networks (for example,
Service as the content shared platform used by other third party's social networks provides).In one embodiment, audio tune
Section system 140 includes audio analysis module 210, wind noise detection module 220, audio replacement operation selecting module 230 and audio
Adjustment module 240.May include more or fewer components in audio regulating system 140 in the case of without loss of generality.Example
Such as, two modules can be combined into individual module or one in the block of mould is segmented into two or more modules.At one
In embodiment, one or more modules may reside on different computing devices (for example, different server computers,
In single client equipment, or multiple client equipment is distributed in when medium).In addition, one or more modules can be resident
On different content shared platforms, third party's social networks and/or external server.
Audio regulating system 140 is communicatively coupled to data storage 106.For example, audio regulating system 140 can be via
Network (for example, via network 105 as illustrated in fig. 1) is coupled to data storage 106.In another example, data store
106 may be coupled directly to the server (for example, may be coupled directly to server 130) that audio regulating system 140 is resident.
Data storage 106 can be memory (for example, random access memory), cache, driver (for example, hard drive
Device), flash drive, Database Systems or data-storable other kinds of component or equipment.Data storage 106 may be used also
To include multiple storage assemblies (for example, multiple drivers or multiple databases), multiple computing device (examples can also be crossed over
Such as, multiple server computers).Data storage 106 includes content item data 290, Ad Hoc audio data 291 and audio calibration number
According to 292.
As has been discussed hereinabove, audio regulating system 140 allows to filter with indoor in embodiment of the present disclosure
Wind noise in appearance.In one embodiment, user content may include the video for being referred to herein as video content.In video
Appearance can be stored in as content item data 290 in data storage 106.The audio analysis module 210 of audio regulating system 140 can
To identify the logic of audio component and video component including analysis video content.Audio component can be with audio coding lattice
The audio data for the video content that formula indicates.
Then the audio component identified can be supplied to wind noise detection module 220.Wind noise detection module 220 wraps
Include the logic of the generation for detecting the wind noise artifact in audio component.As has been discussed hereinabove, wind noise artifact can be with
Refer to the perception or expression of the audio component introduced by wind during the audio-frequency information that capture is indicated by audio component
In mistake or exception.Various operations may be implemented to detect going out for the wind noise in audio component in wind noise detection module 220
Existing (for example, searching abnormal noncontinuity).
In one embodiment, wind noise detection module 220 can generate the spectrogram of audio component.Spectrogram is sound
The visual representation of the frequency occurred in frequency component because they at any time or its certain dependent variable and change.It can analyze and locate
The spectrogram of audio component is managed to identify whether audio component includes any frequency for representing wind noise artifact.For example, wind noise
With a large amount of low-frequency content, and usually it is happened in the low frequency region of spectrogram.
In another embodiment, machine learning techniques may be implemented to identify audio component in wind noise detection module 220
In wind noise artifact.Machine learning is a kind of data analysing method of automated analysis model construction.It changes using from data
The algorithm of generation ground study, it is hiding that machine learning allows computing device to be found in the case where wherein being checked without clearly programming
Opinion.For example, can be provided to grader about every in the training set and training set of the existing video of wind noise artifact
The classification of a video, the grader export between the characteristic and the classification provided for these videos of video (or its audio component)
Correspondence.Once training grader, grader that can handle new video using video training set, determine whether they include wind
Noise artifacts, and identification includes the video clip of these artifacts.
In one embodiment, audio component can be identified using the branch for the machine learning for being referred to as deep learning
In wind noise artifact.Deep learning (also referred to as deep structure chemistry habit, Layered Learning or depth machine learning) is based on algorithm
Set, attempts to carry out the high-level abstractions in modeling data by using multiple process layers with labyrinth, or with other
Mode is made of multiple nonlinear transformations.Deep learning can also be described as the wider machine indicated based on learning data
A part for device learning art family.Deep learning can be utilized to develop various audio event detection methods, can described
The classification of the audio event (for example, wind noise) occurred in given audio component.Then, wind noise detection module 220 can be with
Realize that developed audio event detects approach, to identify the appearance of the wind noise artifact in audio component.
Use one or more of above-mentioned technology, the sound of 220 recognition detection of wind noise detection module to wind noise artifact
The segment (for example, part, editing and/or subset) of frequency component.In some embodiments, wind noise detection module 220 can be with
Identify more than one segment.Wind noise detection module 220 can also provide characteristic corresponding with identified segment.The spy of segment
Property can include but is not limited to define audio component in segment start and end time label, the time span of segment, piece
One or more of the amplitude of the frequency and/or segment that occur in section.In one embodiment, the characteristic of audio fragment can
To be stored in the Ad Hoc audio data 291 of data storage 106.
Audio replacement operation selecting module 230 can be received detects wind noise for wherein wind noise detection module 220
The characteristic of each segment identification of the generation of artifact.In some embodiments, other than the characteristic identified for segment, also
Identified segment itself can be provided by wind noise detection module 220.In other embodiments, no any associated
Characteristic in the case of identified segment is provided by wind noise detection module 220.Wind noise detection module 220 can also provide
With for the corresponding data of the ambient audio context of segment (that is, the other before or after audio fragment identified
The predetermined time interval of segment).In further embodiment, wind noise detection module 220 can also be provided and be identified
The corresponding video component of audio component segment.
In one embodiment, the characteristic depending on the wind noise artifact detected, audio replacement operation selecting module
230 selection wind noise replacement operations are to be used to correct for and/or replace the wind noise artifact detected in audio fragment.One
In a embodiment, wind noise replacement operation can include but is not limited to the audio by surrounding's snippet extraction from audio component
The interpolation of signal fills wind noise artifact, and filtering/cleaning audio fragment is to remove wind noise artifact, for being cut from the non-of video
Audio fragment is replaced in the estimation of the ambient noise of wave, with mute replacement wind noise artifact, different audio components is used in combination to replace sound
Frequency component.
In one embodiment, the wind noise replacement operation selected by audio replacement operation selecting module 230 can take
Certainly change in the characteristic of the segment identified.Audio replacement operation selecting module 230 can keep detecting with from by wind noise
The corresponding threshold value of signal derived from the characteristic for the audio component segment that module 220 provides.Threshold value is for determining that applied wind is made an uproar
Sound replacement operation.
For example, signal can correspond to duration and the intensity of wind noise artifact, for example, as by wind noise artifact
It one or more frequencies and measures corresponding to the signal-to-noise ratio of wind noise.When these signals are combined, these signals
The wind noise to detecting is capable of providing to the extent of the destruction of audio component segment and entire audio component (for example, impacted
Video percentage) estimation.Threshold value can be based on user satisfaction research (example by audio replacement operation selecting module 230
Such as, determine which threshold value leads to highest user satisfaction) it establishes.
In one embodiment, when the sending out signals from the audio fragment identified meet the first predetermined threshold set
When, it can be by the audio replacement operation of 230 Selective filling wind noise artifact of audio replacement operation selecting module.It is pseudo- to fill wind noise
Shadow includes replacing wind noise artifact with the estimation of the background audio of the non-slicing in segment and/or audio component.Wind is replaced to make an uproar
Sound artifact can include the audio texture (example occurred except the audio-frequency unit being destroyed being replicated in the audio-frequency unit being destroyed
Such as, the audio context around use).It can be carried by determining from the ambient audio context (for example, other segments) of audio component
The interpolation of the audio signal and/or spectrogram that take replicates audio texture.In this case, surrounding's sound from other segments
Frequency context can be utilized, the audio fragment for being identified.In some embodiments, when in the audio fragment identified
Frequency domain in (wind noise artifact) frequency domain in the audio fragment that is identified length it is shorter and/or almost without saying
It, can be using Selective filling wind noise artifact as audio replacement operation when language.
In another embodiment, when the second predetermined threshold set of signal satisfaction derived from the audio fragment identified
When, the audio replacement operation of filtering and/or cleaning audio signal can be selected by audio replacement operation selecting module 230.Filtering
The operation of audio signal is intended to restore the audio signal below in the segment.Various filtering techniques may be used, including but not
It is limited to dynamic noise limiter (DNL), DNR dynamic noise reduction (DNR), Time frequency Filter, other special noise reduction programs etc..In some realities
Apply in mode, when the width and intensity of the frequency domain of identified audio fragment it is not high (for example, instruction audio fragment in it is extreme and/
Or destructive wind noise) when, it can select to filter and/or clean audio signal as audio replacement operation.
In further embodiment, when derived from the audio fragment identified signal meet third predetermined threshold set
When conjunction, it can be selected by audio replacement operation selecting module 230 with the mute audio replacement operation for replacing wind noise artifact.With quiet
It is zero that the operation that sound is replaced, which may include by the amplitude adjusted of audio fragment,.When the length of frequency domain, width and intensity instruction wind are made an uproar
Sound artifact is destructive and when extending on long interval of time, can be selected with the wind noise in mute replacement audio fragment
Artifact is as audio replacement operation.In other embodiments, when the length of frequency domain in short-term, can select with mute replacement audio
Wind noise artifact in segment is as audio replacement operation, but width and intensity indicate the destruction of the audio component in segment.
In addition, when wind noise artifact is destructive and to fill be not feasible replacement option (for example, sound of the word said in surrounding
In frequency context) when, it can select to use mute replacement wind noise artifact as audio replacement operation.
In one embodiment, when the 4th predetermined threshold set of signal satisfaction derived from the audio fragment identified
When, it can select to be used for replacing from the estimation of the non-slicing ambient noise of video by audio replacement operation selecting module 230
The audio replacement operation of wind noise artifact.Operation for being replaced from the estimation of the non-slicing ambient noise of video may include profit
Use ambient audio snippets (for example, close near time of identified audio fragment) as non-slicing background noise to replace wind
Noise artifacts.When the length of frequency domain is shorter, can select to be replaced in audio fragment with the estimation of non-slicing ambient noise
Wind noise artifact is as audio replacement operation, but width and intensity indicate the destruction of the audio component in segment.
In another embodiment, when the 5th predetermined threshold set of signal satisfaction derived from the audio fragment identified
When, the audio for replacing wind noise artifact with different audio components can be selected to replace by audio replacement operation selecting module 230
Change operation.The operation replaced with different audio components may include replacing entire audio component with background music track.At one
In embodiment, user can be prompted to select the audio component of his or her first choice for use as replacement.Length, width when frequency domain
With intensity instruction wind noise artifact it is destructive and when extending in long interval of time, can selects with different audio components
The wind noise artifact in audio fragment is replaced as audio replacement operation (for example, not can be used for the audio of filling/interpolation
The good segment of component).
Once selecting wind noise replacement operation appropriate, wind noise replacement operation is applied to sound by audio adjustment module 240
Frequency segment from audio fragment to remove wind noise artifact.In one embodiment, original audio fragment and the audio after correction
Segment can be stored in the audio calibration data 292 of data storage 106.Then audio adjustment module 240 can provide update
Audio component using the part as video be stored in data storage 106 content item data 290 in.
Fig. 3 is the method for filtering the wind noise in video content for illustrating some embodiments according to the disclosure
300 flow chart.Method 300 can be executed by processing logic, the processing logic include hardware (for example, circuit, special logic,
Programmable logic, microcode etc.), software (for example, being run on a processing device to execute the instruction of hardware simulation) or combinations thereof.
In order to which explanation by disclosed method for the sake of simplicity, be depicted and described as a series of actions.However, according to this public affairs
The action opened can occur in various orders and/or simultaneously, and occur with together with this acts not presented and described.
Furthermore, it is possible to not need all actions being illustrated to realize the method according to disclosed theme.In addition, the technology of this field
Personnel will be understood that this method should alternatively be expressed as a series of states that are mutually related via state diagram or event.In addition,
It should be understood that method disclosed in this specification can be stored on manufacture product, to help that such method is transmitted and passed
It is defeated to arrive computing device.Term " manufacture product " used herein is intended to cover from any computer readable device or storage to be situated between
The computer program that matter accesses.In one embodiment, method 300 can be executed by audio adjustment module 140, in Fig. 2
It is shown.
Method 300 starts from block 302, wherein reception includes the video content of audio component and video component.Then, in block
At 304, the generation of wind noise artifact is detected in the segment of audio component.In one embodiment, as discussed above
It states, wind noise artifact can be detected via frequency spectrum map analysis, machine learning or deep learning, named a few.Then,
At block 306, duration and the intensity of wind noise artifact can be identified.
Then, at block 308, wind noise is selected to replace based on the duration of the wind noise artifact identified and intensity
Operation.It in one embodiment, can be from the duration of wind noise artifact and intensity export corresponding to the one of audio fragment
A or multiple signals.Signal may include one or more in frequency domain length, frequency domain width and the frequency domain intensity of wind noise artifact
It is a.Then these signals can be mapped to the threshold value of each signal, to determine that the wind noise corresponding to the threshold value of mapping is replaced
Operation.Wind noise operation can include but is not limited to by the interpolation of the audio signal of surrounding's snippet extraction from audio component come
Filling wind noise artifact, filtering/cleaning audio fragment with remove wind noise artifact, with mute replacement wind noise artifact, with from
The estimation of the non-slicing ambient noise of video replaces audio component to replace wind noise artifact with different audio components.
Finally, at block 310, selected wind noise replacement operation is applied to the segment of audio component.It is selected
Wind noise replacement operation be used to remove wind noise artifact from the audio fragment of audio component.
If two or more audio fragments of identification with wind noise artifact at block 304, can be according to block
406-410 processing has the audio fragment that each of wind noise artifact identifies.
Fig. 4 is the another method for filtering the wind noise in video content illustrated according to embodiment of the present disclosure
400 flow chart.Method 400 can be executed by processing logic, the processing logic include hardware (for example, circuit, special logic,
Programmable logic, microcode etc.), software (for example, being run on a processing device to execute the instruction of hardware simulation) or combinations thereof.
In one embodiment, method 400 can be executed by audio adjustment module 140, as shown in Figure 2.
Method 400 starts from block 402, wherein receiving video content.Then, at block 404, sound is extracted from video content
Frequency component.At block 406, analysis audio component is to identify the audio fragment with wind noise artifact.In one embodiment,
Wind noise artifact can be detected by frequency spectrum map analysis, machine learning or deep learning, named a few.Then, in block
At 408, the characteristic of audio fragment is determined.In one embodiment, characteristic may include the wind noise artifact in audio fragment
Duration and intensity.
Then, at block 410, wind noise replacement operation is selected based on the characteristic identified.In one embodiment,
One or more signals corresponding to audio fragment can be exported from the characteristic of wind noise artifact.Signal may include wind noise puppet
The duration of shadow and intensity, as in such as wind noise artifact one or more frequencies and/or corresponding to wind noise artifact
It is measured under signal-to-noise ratio.Then these signals can be mapped to the threshold value of each signal, to determine the threshold value corresponding to mapping
Wind noise replacement operation.Wind noise operation can include but is not limited to the audio by surrounding's snippet extraction from audio component
The interpolation of signal fills wind noise artifact, and filtering/cleaning audio fragment is to remove wind noise artifact, with mute replacement wind noise
Artifact, for, to replace wind noise artifact, and being replaced from the estimation of the non-slicing ambient noise of video with different audio components
Change audio component.
At block 412, selected wind noise replacement operation is applied to the segment of audio component.Selected wind noise
Replacement operation be used to remove wind noise artifact from audio fragment.Finally, at block 414, modified audio component is deposited
Store up the part as video content.
If two or more audio fragments of identification with wind noise artifact at block 406, can be according to block
408-414 processing has the audio fragment that each of wind noise artifact identifies.
Fig. 5 illustrates the graphical representation of the machine of the exemplary form of computer system 500, can be executed in it for using
The instruction set in this any one or more of method discussed is executed in making machine.In alternative embodiment, machine
The other machines that can be connected (e.g., networked) in LAN (LAN), Intranet, extranet or internet.Machine can be with
With the capability operation of server or client machine in client-server network environment, or as equity (or distribution
Formula) peer machines operation in network environment.The machine can be personal computer (PC), tablet computer, set-top box
(STB), personal digital assistant (PDA), cellular phone, the network equipment, server, network router, interchanger or bridge, or appoint
What, which can (sequentially or in other ways) be executed, is specified the machine of the instruction set of the action to be taken of the machine.Although in addition,
Individual machine is only illustrated, but term " machine " should also be viewed as including executing (or multiple) instruction set alone or in combination to hold
Any collection of machines of the row in this any one or more of method discussed.In one embodiment, computer system 500
The server 102 of audio regulating system 140 can be such as executed, as about described in Fig. 1 and Fig. 2 with representative server.
Exemplary computer system 500 includes the processing equipment 502 to communicate with one another via bus 530, main memory 504
(for example, read-only memory (ROM), flash memory, dynamic random access memory (DRAM) (such as synchronous dram (SDRAM) or
Rambus DRAM) (RDRAM) etc.), static memory 506 (for example, flash memory, static RAM (SRAM) etc.) and
Data storage device 518.When can be with other signals by any one in the signal of various buses offers described here
Between be multiplexed and provided by one or more common bus.In addition, the interconnection between circuit unit or block can be shown as bus
Or individual signals line.Each bus can be alternatively that one or more single-signal-line and every single-signal-line can be alternative
Ground is bus.
Processing equipment 502 indicates one or more general purpose processing devices, microprocessor, central processing unit etc..More
Specifically, processing equipment can be complex instruction set calculation (CISC) microprocessor, the micro- place Reduced Instruction Set Computer (RISC)
Reason device, very long instruction word (VLIW) microprocessor realize the processor of other instruction set or realize the processing of instruction set combination
Device.Processing equipment 902 can also be one or more dedicated treatment facilities, such as application-specific integrated circuit (ASIC), field programmable
Gate array (FPGA), digital signal processor (DSP), network processing unit etc..Processing equipment 502 is configured to execute for executing
In the processing logic 526 for the operation and step that this is discussed.
Computer system 500 can also include network interface device 508.Computer system 500 can also be aobvious including video
Show unit 510 (for example, liquid crystal display (LCD) or cathode-ray tube (CRT)), Alphanumeric Entry Device 512 (for example, key
Disk), cursor control device 514 (for example, mouse) and signal generate equipment 516 (for example, loud speaker).
Data storage device 518 may include computer readable storage medium 528 (also referred to as machine readable storage medium),
It is stored with the 522 (example of one or more instruction set for embodying any one or more of functional method described here on it
Such as, software).Instruction 522 can also completely or at least partially reside in main memory during being executed by computer system 500
In 504 and/or in processing equipment 502；Main memory 504 and processing equipment 502 also constitute machine readable storage medium.It can be with
Instruction 722 is transmitted or received on network 520 via network interface device 508.
Computer readable storage medium 528 may be utilized for store instruction to execute for filtering the wind in video content
The method of noise, as discussed at this.Although computer readable storage medium 528 is shown as list in the exemplary embodiment
A medium, but term " machine readable storage medium " should be considered as including the single medium or more for storing one or more groups of instructions
A medium (for example, centralized or distributed database and/or associated cache and server).Machine readable media
Any mechanism including being used for (for example, software, processing application) storage information in the form of machine (for example, computer) is readable.
Machine readable media can include but is not limited to magnetic storage medium (for example, floppy disk)；Optical storage media (such as CD-ROM)；Magneto-optic
Storage medium；Read-only memory (ROM)；Random access memory (RAM)；Erasable and programable memory (for example, EPROM and
EEPROM)；Flash memory；Or the other kinds of medium suitable for storing e-command.
Description above-mentioned illustrates many details, the example of particular system, component, method etc., in order to provide
To the well-understood of several realizations of the disclosure.It will be apparent, however, to one skilled in the art that can not have
There are at least some embodiments of the disclosure in the case of these details.In other cases, it is not described in
Well known component or method, or presented with simple block diagram format, to avoid the disclosure is unnecessarily obscured.Therefore, it is explained
The detail stated is only exemplary.Specific implementation mode can be different from these exemplary details, and it is still anticipated that
Within the scope of this disclosure.
Mean the spy of combination embodiment description in this specification to the reference of " embodiment " or " embodiment "
Determine feature, structure or characteristic includes at least one embodiment.Therefore, run through this specification in the short of each place appearance
Language " in one embodiment " is not necessarily all referring to identical embodiment " in embodiments ".In addition, term "or"
It is intended to mean the "or" of inclusive rather than exclusive "or".
Although the operation of context of methods is shown and described with particular order, the suitable of the operation of each method can be changed
Sequence so that can execute certain operations in reverse order simultaneously at least partly with other operations or can execute certain
Operation.In another embodiment, the instruction of different operation or sub-operation can be interval and/or alternate mode.
Claims (26)
1. a kind of method, including：
Video content is received, the video content includes audio component and video component；
The generation of the wind noise artifact in the segment of the audio component is detected by processing equipment；
Identify the intensity of the duration and the wind noise artifact of the wind noise artifact；
The duration identified and intensity selection wind noise by the processing equipment at least based on the wind noise artifact replace
Change operation；And
Selected wind noise replacement operation is applied to the segment of the audio component with from institute by the processing equipment
It states and removes the wind noise artifact in segment.
2. according to the method described in claim 1, the wherein described wind noise replacement operation includes with the institute from the circular segment
The interpolation for the audio signal extracted in other segments of audio component is stated to fill the segment.
3. according to the method described in claim, wherein the wind noise replacement operation includes filtering the segment with from described
Section removes the wind noise artifact.
4. according to the method described in claim, wherein the wind noise replacement operation includes replacing the segment with mute.
5. according to the method described in claim, wherein the wind noise replacement operation includes with from the another of the audio component
The audio signal of snippet extraction replaces the wind noise artifact.
6. according to the method described in claim, wherein the wind noise replacement operation includes replacing institute with different audio components
State audio component.
7. according to the method described in claim 6, wherein user is prompted to select the different audio component.
8. according to method described in any preceding claims, wherein selecting the wind noise replacement operation to further include：
Multiple signals are exported from the duration of the wind noise artifact identified and the intensity identified；
Signal derived from institute is mapped to corresponding threshold set；And
Select be mapped to derived from the corresponding wind noise replacement operation of the threshold set of signal.
9. according to the method described in claim 8, wherein derived from signal include the wind noise artifact one or more
Frequency and signal-to-noise ratio corresponding with the wind noise artifact.
10. according to method described in any preceding claims, wherein machine learning be used to detect the wind noise artifact
The generation.
11. according to method described in any preceding claims, wherein deep learning be used to detect the wind noise artifact
The generation.
12. according to method described in any preceding claims, wherein frequency spectrum map analysis be used to detect the wind noise artifact
The generation.
13. a kind of system, including：
Memory；With
It is coupled to the processing equipment of the memory, wherein the processing equipment is to be used for：
Audio component is extracted from video content；
Analyze the generation of the wind noise artifact in segment of the audio component to identify the audio component；
Identify the characteristic of the segment；
Wind noise replacement operation is selected based on the characteristic identified；And
The wind noise artifact is removed from the segment applied to the segment via by selected wind noise replacement operation.
14. system according to claim 13, wherein the wind noise replacement operation includes with from around the segment
The interpolation of the audio signal extracted in other segments of the audio component fills the segment.
15. according to the system described in claim 13 or 14, wherein the wind noise replacement operation includes filtering the segment
To remove the wind noise artifact from the segment.
16. according to the system described in claim 13,14 or 15, wherein the wind noise replacement operation includes with from the sound
The audio signal of another snippet extraction of frequency component replaces the wind noise artifact.
17. according to the system described in any one in claim 13 to 16, wherein the wind noise replacement operation includes using
It is mute to replace the segment.
18. according to the system described in any one in claim 13 to 17, wherein the wind noise replacement operation includes using
Different audio components replaces the audio component.
19. according to the system described in any one in claim 13-18, wherein the characteristic of the segment includes described
The intensity of the duration of wind noise artifact and the wind noise artifact.
20. according to the system described in any one in claim 13-19, wherein the processing equipment is configured under
State the selection wind noise replacement operation：
Multiple signals are exported from the characteristic identified；
Signal derived from institute is mapped to corresponding threshold set；And
Select be mapped to derived from the corresponding wind noise replacement operation of the threshold set of signal.
21. a kind of non-transitory machinable medium of store instruction, when executed so that processing equipment
Execution includes operation below：
Audio component is extracted from video content；
The generation of the wind noise artifact in the segment of the audio component is detected by the processing equipment；
The characteristic of the wind noise artifact is identified by the processing equipment；
Wind noise replacement operation is selected based on the characteristic of the wind noise artifact identified by the processing equipment；
Selected wind noise replacement operation is applied to the segment of the audio component to remove institute from the segment
It states wind noise artifact and generates modified audio component；
The modified audio component and the video content is combined；And
The video content is transmitted to content shared platform by the processing equipment.
22. non-transitory machinable medium according to claim 21, wherein the wind noise replacement operation packet
It includes and fills described with the interpolation for the audio signal extracted from other segments of the audio component around the segment
Section.
23. the non-transitory machinable medium according to claim 21 or 22, wherein the wind noise replaces behaviour
Work includes the filtering segment to remove the wind noise artifact from the segment.
24. according to the non-transitory machinable medium described in claim 21,22 or 23, wherein the wind noise is replaced
Operation includes replacing the segment with mute.
25. according to the non-transitory machinable medium described in claim 21,22,23 or 24, wherein the wind noise
Replacement operation includes replacing the wind noise artifact with the audio signal of another snippet extraction from the audio component.
26. according to the non-transitory machinable medium described in claim 21,22,23,24 or 25, wherein the wind is made an uproar
Sound replacement operation includes replacing the audio component with different audio components.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/147,040 US9838737B2 (en) | 2016-05-05 | 2016-05-05 | Filtering wind noises in video content |
US15/147,040 | 2016-05-05 | ||
PCT/US2016/069206 WO2017192180A1 (en) | 2016-05-05 | 2016-12-29 | Filtering wind noises in video content |
Publications (2)
Publication Number | Publication Date |
---|---|
CN108604451A true CN108604451A (en) | 2018-09-28 |
CN108604451B CN108604451B (en) | 2023-01-03 |
Family
ID=57861270
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680081782.3A Active CN108604451B (en) | 2016-05-05 | 2016-12-29 | Filtering wind noise in video content |
Country Status (6)
Country | Link |
---|---|
US (2) | US9838737B2 (en) |
EP (1) | EP3403262B1 (en) |
JP (1) | JP6755324B2 (en) |
KR (1) | KR102138185B1 (en) |
CN (1) | CN108604451B (en) |
WO (1) | WO2017192180A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111246283A (en) * | 2020-01-17 | 2020-06-05 | 北京达佳互联信息技术有限公司 | Video playing method and device, electronic equipment and storage medium |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10446170B1 (en) | 2018-06-19 | 2019-10-15 | Cisco Technology, Inc. | Noise mitigation using machine learning |
US11818426B2 (en) * | 2019-11-14 | 2023-11-14 | Dish Network L.L.C. | Method and system for adaptive audio modification |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060233407A1 (en) * | 2005-03-21 | 2006-10-19 | Andre Steinbuss | Hearing device and method for wind noise suppression |
JP2013106298A (en) * | 2011-11-16 | 2013-05-30 | Sony Corp | Imaging controller, imaging control method, program for imaging control method, and imaging apparatus |
CN104040627A (en) * | 2011-12-22 | 2014-09-10 | 欧胜软件方案公司 | Method and apparatus for wind noise detection |
Family Cites Families (48)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR100189961B1 (en) * | 1992-04-09 | 1999-06-01 | 윤종용 | Noise elimination apparatus |
JP3186892B2 (en) * | 1993-03-16 | 2001-07-11 | ソニー株式会社 | Wind noise reduction device |
CA2125220C (en) * | 1993-06-08 | 2000-08-15 | Joji Kane | Noise suppressing apparatus capable of preventing deterioration in high frequency signal characteristic after noise suppression and in balanced signal transmitting system |
ATE277400T1 (en) * | 1999-10-29 | 2004-10-15 | Ericsson Telefon Ab L M | METHOD AND DEVICE FOR ROBUST FEATURE EXTRACTION FOR SPEECH RECOGNITION |
US7457750B2 (en) * | 2000-10-13 | 2008-11-25 | At&T Corp. | Systems and methods for dynamic re-configurable speech recognition |
US7885420B2 (en) * | 2003-02-21 | 2011-02-08 | Qnx Software Systems Co. | Wind noise suppression system |
US7895036B2 (en) * | 2003-02-21 | 2011-02-22 | Qnx Software Systems Co. | System for suppressing wind noise |
AU2005228148A1 (en) * | 2004-03-24 | 2005-10-13 | That Corporation | Configurable filter for processing television audio signals |
US7477325B2 (en) * | 2004-03-29 | 2009-01-13 | Ati Technologies, Inc. | Audio/video separator |
JP4218573B2 (en) * | 2004-04-12 | 2009-02-04 | ソニー株式会社 | Noise reduction method and apparatus |
WO2005125272A1 (en) * | 2004-06-16 | 2005-12-29 | Matsushita Electric Industrial Co., Ltd. | Howling suppression device, program, integrated circuit, and howling suppression method |
EP1666967B1 (en) * | 2004-12-03 | 2013-05-08 | Magix AG | System and method of creating an emotional controlled soundtrack |
JP4466384B2 (en) * | 2005-01-19 | 2010-05-26 | カシオ計算機株式会社 | Electronic camera, noise reduction device, and noise reduction method |
KR101118217B1 (en) * | 2005-04-19 | 2012-03-16 | 삼성전자주식회사 | Audio data processing apparatus and method therefor |
US8019103B2 (en) * | 2005-08-02 | 2011-09-13 | Gn Resound A/S | Hearing aid with suppression of wind noise |
JP4356670B2 (en) * | 2005-09-12 | 2009-11-04 | ソニー株式会社 | Noise reduction device, noise reduction method, noise reduction program, and sound collection device for electronic device |
CN101617362B (en) * | 2007-03-02 | 2012-07-18 | 松下电器产业株式会社 | Audio decoding device and audio decoding method |
US8488803B2 (en) * | 2007-05-25 | 2013-07-16 | Aliphcom | Wind suppression/replacement component for use with electronic systems |
US8428275B2 (en) * | 2007-06-22 | 2013-04-23 | Sanyo Electric Co., Ltd. | Wind noise reduction device |
US20080320545A1 (en) * | 2007-06-22 | 2008-12-25 | Schwartz Richard T | System and method for providing audio-visual programming with alternative content |
US20110022992A1 (en) * | 2008-03-31 | 2011-01-27 | Koninklijke Philips Electronics N.V. | Method for modifying a representation based upon a user instruction |
US8515097B2 (en) * | 2008-07-25 | 2013-08-20 | Broadcom Corporation | Single microphone wind noise suppression |
US9253568B2 (en) * | 2008-07-25 | 2016-02-02 | Broadcom Corporation | Single-microphone wind noise suppression |
JP2010057085A (en) * | 2008-08-29 | 2010-03-11 | Canon Inc | Tv receiver and control method thereof |
US8223990B1 (en) * | 2008-09-19 | 2012-07-17 | Adobe Systems Incorporated | Audio noise attenuation |
US8184212B2 (en) * | 2009-07-28 | 2012-05-22 | Himax Media Solutions, Inc. | Sound intermediate frequency demodulator and sound intermediate frequency detecting method thereof |
US8600073B2 (en) * | 2009-11-04 | 2013-12-03 | Cambridge Silicon Radio Limited | Wind noise suppression |
WO2011096156A1 (en) * | 2010-02-08 | 2011-08-11 | パナソニック株式会社 | Sound identification device and method |
JP2011237753A (en) * | 2010-04-14 | 2011-11-24 | Sony Corp | Signal processing device, method and program |
US8538035B2 (en) * | 2010-04-29 | 2013-09-17 | Audience, Inc. | Multi-microphone robust noise suppression |
US8639516B2 (en) | 2010-06-04 | 2014-01-28 | Apple Inc. | User-specific noise suppression for voice quality improvements |
JP5529635B2 (en) | 2010-06-10 | 2014-06-25 | キヤノン株式会社 | Audio signal processing apparatus and audio signal processing method |
US8983833B2 (en) * | 2011-01-24 | 2015-03-17 | Continental Automotive Systems, Inc. | Method and apparatus for masking wind noise |
CN105792071B (en) * | 2011-02-10 | 2019-07-05 | 杜比实验室特许公司 | The system and method for detecting and inhibiting for wind |
JP5926490B2 (en) * | 2011-02-10 | 2016-05-25 | キヤノン株式会社 | Audio processing device |
JP5836616B2 (en) * | 2011-03-16 | 2015-12-24 | キヤノン株式会社 | Audio signal processing device |
JP5919647B2 (en) * | 2011-05-11 | 2016-05-18 | 富士通株式会社 | Wind noise suppression device, semiconductor integrated circuit, and wind noise suppression method |
JP2013047710A (en) * | 2011-08-29 | 2013-03-07 | Sony Corp | Sound signal processing apparatus, imaging apparatus, sound signal processing method, program, and recording medium |
US9986356B2 (en) * | 2012-02-15 | 2018-05-29 | Harman International Industries, Incorporated | Audio surround processing system |
US8976040B2 (en) * | 2012-02-16 | 2015-03-10 | Bianca RAY AVALANI | Intelligent driver assist system based on multimodal sensor fusion |
WO2013150340A1 (en) * | 2012-04-05 | 2013-10-10 | Nokia Corporation | Adaptive audio signal filtering |
CN103886863A (en) * | 2012-12-20 | 2014-06-25 | 杜比实验室特许公司 | Audio processing device and audio processing method |
US20140347565A1 (en) * | 2013-05-21 | 2014-11-27 | Aliphcom | Media devices configured to interface with information appliances |
WO2014168021A1 (en) * | 2013-04-11 | 2014-10-16 | 日本電気株式会社 | Signal processing device, signal processing method, and signal processing program |
JP2015114444A (en) * | 2013-12-11 | 2015-06-22 | キヤノン株式会社 | Voice processing device and voice processing method |
EP2945303A1 (en) * | 2014-05-16 | 2015-11-18 | Thomson Licensing | Method and apparatus for selecting or removing audio component types |
JP6381367B2 (en) * | 2014-08-26 | 2018-08-29 | キヤノン株式会社 | Audio processing apparatus, audio processing method, and program |
EP2996352B1 (en) * | 2014-09-15 | 2019-04-17 | Nxp B.V. | Audio system and method using a loudspeaker output signal for wind noise reduction |
-
2016
- 2016-05-05 US US15/147,040 patent/US9838737B2/en active Active
- 2016-12-29 JP JP2018543130A patent/JP6755324B2/en active Active
- 2016-12-29 EP EP16829208.4A patent/EP3403262B1/en active Active
- 2016-12-29 WO PCT/US2016/069206 patent/WO2017192180A1/en active Application Filing
- 2016-12-29 CN CN201680081782.3A patent/CN108604451B/en active Active
- 2016-12-29 KR KR1020187023466A patent/KR102138185B1/en active IP Right Grant
-
2017
- 2017-11-29 US US15/826,622 patent/US10356469B2/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060233407A1 (en) * | 2005-03-21 | 2006-10-19 | Andre Steinbuss | Hearing device and method for wind noise suppression |
JP2013106298A (en) * | 2011-11-16 | 2013-05-30 | Sony Corp | Imaging controller, imaging control method, program for imaging control method, and imaging apparatus |
CN104040627A (en) * | 2011-12-22 | 2014-09-10 | 欧胜软件方案公司 | Method and apparatus for wind noise detection |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111246283A (en) * | 2020-01-17 | 2020-06-05 | 北京达佳互联信息技术有限公司 | Video playing method and device, electronic equipment and storage medium |
CN111246283B (en) * | 2020-01-17 | 2022-09-30 | 北京达佳互联信息技术有限公司 | Video playing method and device, electronic equipment and storage medium |
Also Published As
Publication number | Publication date |
---|---|
JP2019518229A (en) | 2019-06-27 |
CN108604451B (en) | 2023-01-03 |
KR20180103125A (en) | 2018-09-18 |
KR102138185B1 (en) | 2020-07-27 |
US20180084301A1 (en) | 2018-03-22 |
EP3403262A1 (en) | 2018-11-21 |
US20170324990A1 (en) | 2017-11-09 |
JP6755324B2 (en) | 2020-09-16 |
EP3403262B1 (en) | 2020-02-05 |
WO2017192180A1 (en) | 2017-11-09 |
US9838737B2 (en) | 2017-12-05 |
US10356469B2 (en) | 2019-07-16 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN110574387B (en) | Recommending live streaming content using machine learning | |
EP3816998A1 (en) | Method and system for processing sound characteristics based on deep learning | |
US10192583B2 (en) | Video editing using contextual data and content discovery using clusters | |
US20190392866A1 (en) | Video summarization and collaboration systems and methods | |
CN106063282B (en) | Merge content channel | |
CN108369715B (en) | Interactive commentary based on video content characteristics | |
US10347294B2 (en) | Generating moving thumbnails for videos | |
US10795560B2 (en) | System and method for detection and visualization of anomalous media events | |
EP4009651A1 (en) | Methods and systems of providing visual content editing functions | |
Schwach et al. | Policy and knowledge in fisheries management: a policy brief | |
US10652075B2 (en) | Systems and methods for selecting content items and generating multimedia content | |
CN110879851A (en) | Video dynamic cover generation method and device, electronic equipment and readable storage medium | |
CN103136253A (en) | Method and device of acquiring information | |
US20150213136A1 (en) | Method and System for Providing a Personalized Search List | |
CN108604451A (en) | Filter the wind noise in video content | |
JP2013117830A (en) | Recommendation device, recommendation system, recommendation method and program | |
JP6159989B2 (en) | Scenario generation system, scenario generation method, and scenario generation program | |
CN106572390A (en) | Audio and video recommending method and equipment | |
CN104866490B (en) | A kind of video intelligent recommended method and its system | |
US9569213B1 (en) | Semantic visual hash injection into user activity streams | |
Sihag et al. | A data-driven approach for finding requirements relevant feedback from tiktok and youtube | |
US20130054687A1 (en) | Online communities | |
CN108334729A (en) | Health information management method and management system | |
CN105791908A (en) | Method and device for obtaining video key frames | |
GB2494619A (en) | Automated creation of online communities, message boards, social networks, email distribution lists or other virtual hubs |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |