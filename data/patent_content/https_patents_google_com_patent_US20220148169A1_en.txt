US20220148169A1 - Artificial intelligence prediction of prostate cancer outcomes - Google Patents
Artificial intelligence prediction of prostate cancer outcomes Download PDFInfo
- Publication number
- US20220148169A1 US20220148169A1 US17/453,953 US202117453953A US2022148169A1 US 20220148169 A1 US20220148169 A1 US 20220148169A1 US 202117453953 A US202117453953 A US 202117453953A US 2022148169 A1 US2022148169 A1 US 2022148169A1
- Authority
- US
- United States
- Prior art keywords
- gleason
- image
- risk
- risk group
- model
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 206010060862 Prostate cancer Diseases 0.000 title claims abstract description 43
- 208000000236 Prostatic Neoplasms Diseases 0.000 title claims abstract description 43
- 238000013473 artificial intelligence Methods 0.000 title claims abstract description 25
- 210000002307 prostate Anatomy 0.000 claims abstract description 63
- 238000000034 method Methods 0.000 claims abstract description 45
- 230000004083 survival effect Effects 0.000 claims description 31
- 238000004393 prognosis Methods 0.000 claims description 18
- 238000011471 prostatectomy Methods 0.000 claims description 14
- 238000001574 biopsy Methods 0.000 claims description 12
- 238000010200 validation analysis Methods 0.000 description 30
- 238000004458 analytical method Methods 0.000 description 19
- 210000001519 tissue Anatomy 0.000 description 19
- 206010028980 Neoplasm Diseases 0.000 description 15
- 238000011161 development Methods 0.000 description 11
- 230000018109 developmental process Effects 0.000 description 11
- 230000015654 memory Effects 0.000 description 10
- 238000013135 deep learning Methods 0.000 description 8
- 238000004422 calculation algorithm Methods 0.000 description 7
- 238000004891 communication Methods 0.000 description 7
- 238000013527 convolutional neural network Methods 0.000 description 7
- 201000010099 disease Diseases 0.000 description 7
- 208000037265 diseases, disorders, signs and symptoms Diseases 0.000 description 7
- 230000006870 function Effects 0.000 description 6
- 238000011282 treatment Methods 0.000 description 6
- 238000013517 stratification Methods 0.000 description 5
- 238000012549 training Methods 0.000 description 5
- 238000013528 artificial neural network Methods 0.000 description 4
- 230000008901 benefit Effects 0.000 description 4
- 230000001575 pathological effect Effects 0.000 description 4
- 238000012545 processing Methods 0.000 description 4
- 210000001625 seminal vesicle Anatomy 0.000 description 4
- 201000010653 vesiculitis Diseases 0.000 description 4
- 238000009098 adjuvant therapy Methods 0.000 description 3
- 238000013459 approach Methods 0.000 description 3
- 201000011510 cancer Diseases 0.000 description 3
- 238000002790 cross-validation Methods 0.000 description 3
- 238000003745 diagnosis Methods 0.000 description 3
- 238000011156 evaluation Methods 0.000 description 3
- 238000012552 review Methods 0.000 description 3
- 230000003190 augmentative effect Effects 0.000 description 2
- 238000007475 c-index Methods 0.000 description 2
- 230000000875 corresponding effect Effects 0.000 description 2
- 238000013136 deep learning model Methods 0.000 description 2
- 238000003384 imaging method Methods 0.000 description 2
- 230000006872 improvement Effects 0.000 description 2
- 238000001325 log-rank test Methods 0.000 description 2
- 238000010801 machine learning Methods 0.000 description 2
- 238000013507 mapping Methods 0.000 description 2
- 230000006855 networking Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000001959 radiotherapy Methods 0.000 description 2
- 238000002271 resection Methods 0.000 description 2
- 238000001356 surgical procedure Methods 0.000 description 2
- 210000004881 tumor cell Anatomy 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- 206010061818 Disease progression Diseases 0.000 description 1
- 238000010824 Kaplan-Meier survival analysis Methods 0.000 description 1
- 238000012952 Resampling Methods 0.000 description 1
- 241000269849 Thunnus Species 0.000 description 1
- 230000006978 adaptation Effects 0.000 description 1
- 230000002411 adverse Effects 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000000295 complement effect Effects 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 238000011257 definitive treatment Methods 0.000 description 1
- 230000005750 disease progression Effects 0.000 description 1
- 238000009826 distribution Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000002962 histologic effect Effects 0.000 description 1
- 238000001794 hormone therapy Methods 0.000 description 1
- 238000011835 investigation Methods 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000007170 pathology Effects 0.000 description 1
- 230000037361 pathway Effects 0.000 description 1
- 208000023958 prostate neoplasm Diseases 0.000 description 1
- 238000004451 qualitative analysis Methods 0.000 description 1
- 238000011472 radical prostatectomy Methods 0.000 description 1
- 230000011218 segmentation Effects 0.000 description 1
- 230000035945 sensitivity Effects 0.000 description 1
- 238000010206 sensitivity analysis Methods 0.000 description 1
- 238000012706 support-vector machine Methods 0.000 description 1
- 230000002123 temporal effect Effects 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 238000013334 tissue model Methods 0.000 description 1
- 231100000419 toxicity Toxicity 0.000 description 1
- 230000001988 toxicity Effects 0.000 description 1
Images
Classifications
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/72—Signal processing specially adapted for physiological signals or for diagnostic purposes
- A61B5/7271—Specific aspects of physiological measurement analysis
- A61B5/7275—Determining trends in physiological measurement data; Predicting development of a medical condition based on physiological measurements, e.g. determining a risk factor
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/43—Detecting, measuring or recording for evaluating the reproductive systems
- A61B5/4375—Detecting, measuring or recording for evaluating the reproductive systems for evaluating the male reproductive system
- A61B5/4381—Prostate evaluation or disorder diagnosis
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/72—Signal processing specially adapted for physiological signals or for diagnostic purposes
- A61B5/7235—Details of waveform analysis
- A61B5/7264—Classification of physiological signals or data, e.g. using neural networks, statistical classifiers, expert systems or fuzzy systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
-
- G06K9/6217—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/0002—Inspection of images, e.g. flaw detection
- G06T7/0012—Biomedical image inspection
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/82—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using neural networks
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16H—HEALTHCARE INFORMATICS, i.e. INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR THE HANDLING OR PROCESSING OF MEDICAL OR HEALTHCARE DATA
- G16H30/00—ICT specially adapted for the handling or processing of medical images
- G16H30/40—ICT specially adapted for the handling or processing of medical images for processing medical images, e.g. editing
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16H—HEALTHCARE INFORMATICS, i.e. INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR THE HANDLING OR PROCESSING OF MEDICAL OR HEALTHCARE DATA
- G16H50/00—ICT specially adapted for medical diagnosis, medical simulation or medical data mining; ICT specially adapted for detecting, monitoring or modelling epidemics or pandemics
- G16H50/30—ICT specially adapted for medical diagnosis, medical simulation or medical data mining; ICT specially adapted for detecting, monitoring or modelling epidemics or pandemics for calculating health indices; for individual health risk assessment
-
- G06K2209/051—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20081—Training; Learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/30—Subject of image; Context of image processing
- G06T2207/30004—Biomedical image processing
- G06T2207/30024—Cell structures in vitro; Tissue sections in vitro
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/30—Subject of image; Context of image processing
- G06T2207/30004—Biomedical image processing
- G06T2207/30081—Prostate
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/30—Subject of image; Context of image processing
- G06T2207/30004—Biomedical image processing
- G06T2207/30096—Tumor; Lesion
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V2201/00—Indexing scheme relating to image or video recognition or understanding
- G06V2201/03—Recognition of patterns in medical or anatomical images
- G06V2201/031—Recognition of patterns in medical or anatomical images of internal organs
Definitions
- Prostate cancer affects 1 in 9 men in their lifetime but disease aggressiveness and prognosis can vary substantially among individuals based on factors such as the cancer grade.
- Gleason grading of prostate cancer involves assigning different histologic patterns, known as Gleason patterns, to each region of a patient's tumor. Based on the prevalence of these patterns, one of five Gleason Grade Groups (GG), i.e., GG1, GG2, GG3, GG4 or GG5, is assigned. A patient's prognosis worsens as the Gleason grade group grade increases. The resulting GG is among the most prognostic factors for prostate cancer patients, and is used for patient risk stratification and to match patients to treatment plans most appropriate for their risk of disease progression.
- GG Gleason Grade Groups
- One example method includes receiving an image of prostate tissue; assigning Gleason pattern values to one or more regions within the image using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image; determining relative areal proportions of the Gleason patterns within the image; assigning at least one of a risk score or risk group value to the image based on the determined relative areal proportions; and outputting at least one of the risk score or the risk group value.
- One example system for assessing a prognosis of a prostate cancer patient includes a non-transitory computer-readable medium; and one or more processors communicatively coupled to the non-transitory computer-readable medium, the one or more processors configured to execute processor-executable instructions stored in the non-transitory computer-readable medium to receive an image of prostate tissue; assign Gleason pattern values to one or more regions within the image using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image; determine relative areal proportions of the Gleason patterns within the image; assign at least one of a risk score or risk group value to the image based on the determined relative areal proportions; and output at least one of the risk score or the risk group value.
- One example non-transitory computer-readable medium comprising processor-executable instructions configured to cause one or more to receive an image of prostate tissue; assign Gleason pattern values to one or more regions within the image using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image; determine relative areal proportions of the Gleason patterns within the image; assign at least one of a risk score or risk group value to the image based on the determined relative areal proportions; and output at least one of the risk score or the risk group value.
- FIG. 1 is an illustration showing the development of a deep learning system in the form of an AI Gleason Grading Model, which generates Gleason pattern predictions for a digital prostate sample image on an image patch-by-patch basis.
- FIG. 2 is an illustration showing a method we used to generate our new AI risk score paradigm, including continuous risk scores and discrete risk groups, from (1) a set of samples (which included both image data and survival data for each go the samples), (2) the Gleason Grading Model of FIG. 1 , and (3) a Cox proportional hazards regression model using the survival data and Gleason pattern patch predictions from the set.
- FIG. 3 is a flow chart showing a method of generating a risk group value or risk score for a prostate cancer tissue specimen image.
- This risk group value or score could be implemented as a stand-alone prediction, as a second read (e.g., as an adjunct to an overall Gleason Grade assigned by a pathologist) or as a combined manner in which the risk group score is combined with the pathologist's overall Gleason Grade assignment.
- FIG. 4 is an illustration of one possible example of how the AI risk group score (“4” in this example) could be presented on a workstation used by a clinician, e.g., primary care physician, oncologist, pathologist, etc.
- a clinician e.g., primary care physician, oncologist, pathologist, etc.
- FIGS. 6A-6E are Kaplan-Meier plots showing the sub-stratification of patients by risk groups 1-2 vs. 3-5 within each pathologist-determine Gleason Grade.
- FIGS. 7A-7E are plots of percentage Gleason patterns 4 and 5 for different pathologist-determined Gleason Grades and showing the risk group definitions for such percentages.
- FIG. 9 illustrate an example system for AI prediction of prostate cancer outcomes.
- FIG. 10 illustrates an example method for AI prediction of prostate cancer outcomes.
- FIG. 11 illustrates an example computing device suitable for use with example systems and methods for AI prediction of prostate cancer outcomes.
- Gleason grading suffers from large discordance rates between pathologists (30-50%), thus introducing a potential source of variability and prognostic inaccuracies.
- grades from experts are more consistent and result in more accurate risk stratification than grades from less experienced pathologists, suggesting an opportunity to improve the clinical utility of the system by improving grading consistency and accuracy.
- several AI algorithms for Gleason grading have been developed and validated using expert-provided Gleason scores. See e.g., Nagpal, K. et al.
- a new prognostic risk score paradigm may be used, including a continuous artificial intelligence (“AI”) risk score, and then further discretizing these risk scores into new AI “risk groups.”
- the risk score can be reported, or the risk group value, or both, for a given prostate tissue image.
- the use of a system to analyze images of prostate tissue to generate such AI risk scores or AI risk groups enables predicting prostate cancer patient prognosis directly from a digital image of a prostate cancer specimen, such as a needle core biopsy or prostatectomy specimen. Further, such techniques may be used to generate either a stand-alone prediction, or as a second read, or in a combined system in which the risk score or risk group value is combined with the pathologist's own Gleason Grade evaluation of the specimen.
- a system can assign Gleason pattern categorizations (e.g., 3, 4, or 5) to regions of an image of prostate tissue from the patient containing tumor cells using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image. It can then determine the relative areal proportions, e.g., percentages of the Gleason pattern categorizations, such as the relative size or area of tumor patches graded Gleason pattern 3, 4, and 5.
- Gleason pattern categorizations e.g., 3, 4, or 5
- the system can then assign a risk score or risk group value, or both, to the image using the determined relative proportions.
- the risk score or risk group value is correlated to prognosis of the patient.
- the assigning step can make use of a Cox proportional hazards regression model fitted to a set of Gleason pattern scores or proportions thereof assigned to a multitude of images in a data set by the AI Gleason grading model and associated survival data associated with the data set.
- the image of the prostate tissue can be an image of a specimen obtained from a prostatectomy or it could be of a specimen obtained from a needle core biopsy.
- the specimen or portion thereof is placed on a tissue slide and imaged with a digital whole slide scanner at some particular magnification or combination of magnifications, such as 40 ⁇ or 10 ⁇ , as is conventional.
- the system can also present the risk score, risk group values, or both, on a workstation used by clinician, such as for example a pathologist or oncologist.
- a workstation used by clinician, such as for example a pathologist or oncologist.
- clinician such as for example a pathologist or oncologist.
- workstation is intended to be interpreted broadly to encompass any computer device with a display and user interface for interacting with the display, including a desktop computer, tablet, smart phone, laptop computer and the like.
- the workstation has an interface providing a feature for the pathologist or oncologist to input a human-derived Gleason Grade for the image, e.g., after visual examination of the specimen with a microscope or by study of a magnified digital image of the specimen.
- This feature can facilitate a comparison of the risk score, risk group value, or both, to the human-derived Gleason Grade.
- the risk group values take on values of 1, 2, 3, 4 or 5 and correspond at least approximately to GG of 1, 2, 3, 4, and 5 (respectively).
- the user may be motivated to reconsider their own Gleason grade group assignment or perhaps take the risk group value in consideration along with the pathologist Gleason Grade group assignment when planning a course of treatment for the patient.
- the risk group values can take the form of integers from 1 to 5, inclusive.
- the survival probability of each of the risk group values approximates the survival probability of prostate cancer patients with Gleason Grades of integers 1-5 inclusive, respectively.
- an AI risk group may not only approximate the prognosis provided by Gleason Grade group, but can provide a grouping system that more accurately categorizes patients based on more complex Gleason pattern thresholds.
- the current Gleason grade group system uses “simple” thresholds (e.g. GG1 vs GG2 vs. GG3 essentially is >0% or >50% pattern 4 respectively)
- example systems according this disclosure may provide more precise groupings that better correlate with prognosis.
- a method for developing a model for predicting prognosis of a prostate cancer patient, which includes a system that can obtain a data set comprising a multitude of prostate cancer tissue images and associated survival data for prostate cancer patients associated with the tissue images. It can then assign Gleason patterns to regions of each image containing tumor cells using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image.
- the present methods can be implemented in a computing environment including a processing unit and a machine-readable memory storing program instructions.
- the computing environment could be local to the clinician, such as executed in a processing unit and memory of a workstation.
- the computing environment could be in a remote server or cloud environment, in which the Gleason grading model is implemented in a remote computer from the clinician workstation, receives images over a network, determines the Gleason patterns in the image and computes the relative proportions, assigns a risk score and/or risk group to the image, and then returns the result to the workstation, possible along with a version of the image with a “heatmap” showing the different Gleason patterns in the image as determined by the Gleason grading model.
- a machine-readable memory storing a procedure for calculating a risk group value or a risk group score associated with a prognosis of a prostate cancer patient from input in the form of relative proportions of the Gleason pattern scores assigned to a prostate tissue image by an artificial intelligence Gleason grading model trained to identify Gleason patters on a patch-by-patch basis in a prostate tissue image.
- This procedure can be in the form of a table, mathematical formula, or combination thereof, correlating a multitude of possible Gleason pattern score proportions (e.g., percentages) to one of a finite number of risk group values, such as five of such values, i.e., 1, 2, 3, 4, 5 corresponding approximately to Gleason Grade scores.
- the plots of FIGS. 5 and 6 demonstrate the correlation between risk group values and prognosis under the present inventive risk scoring paradigm.
- a system for assessing the prognosis of a prostate cancer patient.
- the system includes a computer memory storing a digital image of a prostate specimen of the patient; and a programmed computer containing code for assigning Gleason pattern scores to regions of the image using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image; wherein the computer is further programmed with code to compute the relative proportions of the Gleason pattern scores; and wherein the computer is further programmed with a procedure for assigning a risk score or risk group value, or both, to the image using the relative proportions.
- FIG. 1 shows an example system that employs a trained deep learning system, referred to as Gleason Grading model 10 (or “model 10 ”).
- the model 10 in this example is a deep artificial neural network, though in other examples, it may be a pattern recognizer or any other suitable deep learning model.
- This example model 10 was developed using a development set 12 of images and associated ground truth.
- the model 10 has an ancillary or second model (not shown), e.g., a trained convolutional neural network or pattern recognizer, that is trained to distinguish between prostate tissue and non-prostate tissue to ensure that the Gleason Grading Model 10 only operates on those portions of an image that actually contain prostate tissue.
- the ancillary model may not be employed in some examples.
- Gleason Grading Model 10 The details of the Gleason Grading Model 10 are illustrated in FIG. 8 , and the associated discussion below.
- This model is trained from a development set of samples (magnified digital images of prostate specimens) with associated ground truth to make predictions of Gleason patterns (e.g., Gleason 1, 2, 3, 4, 5) on a patch-by patch basis. Once trained, the model 10 can then be used to make predictions 16 based on input digital images 14 of prostate specimens.
- Gleason patterns e.g., Gleason 1, 2, 3, 4, 5
- the computing device 210 receives the images of prostate tissue from its own data store 212 , in some examples, it may obtain images of prostate tissue from the server 240 , which may access its own data store 242 to obtain and provide requested histopathology images. In some examples, the computing device 210 may be connected to a microscope that can capture images of prostate tissue. Further, while the analysis is performed by model 220 executed by the computing device 210 itself, in some examples, the model 220 may be part of the server 240 , and the computing device 210 may provide images of prostate tissue to the server 240 for analysis, via network 230 , and later receive the results, which may be stored in the data store 212 or displayed on the display 214 .
- FIG. 2 is an illustration showing a processing flow for AI prediction of prostate cancer outcomes, including continuous risk scores and discrete risk groups, from a set of samples 20 (which included both image data and survival data for each of the samples), the model 10 of FIG. 1 , and a Cox regression model 30 using the survival data and Gleason pattern patch predictions from the set 20 .
- this set of samples 20 include both digital images of a prostate specimen and associated survival data for the patient providing the samples.
- the set 20 consisted of all archived slides in prostatectomy cases from 1995-2014 at the BioBank at the Medical University of Graz in Austria. The slides were scanned at magnification and digitized. There were typically several slides per case/patient. After excluding 9 cases for death within 30 days of the surgery, 2,811 cases remained. The median follow-up time was 13.1 years (interquartile range 8.5-17.2).
- validation set 1 contains all prostatectomy cases from the Biobank Graz between 1995-2014, while validation set 2 is a subset of validation set 1 and contains all prostatectomy cases between 2000-2014 where a diagnostic Grade Group was recorded.
- the images in the set 20 were input into the model 10 to assess the tumor composition and generate patch-level predictions of Gleason pattern on each of the images.
- the areal percentages were then determined at block 24 for three different Gleason patterns 3, 4 and 5 (% GP 3, % GP 4, % GP 5).
- the percentages were determined by determining the size of the patches of a given Gleason pattern (taking into account such things as pixel pitch, magnification, etc.) and dividing that size (area) by the total area of the tumor having Gleason patterns 3, 4 or 5.
- areal percentages were only computed for Gleason patterns 3, 4 and 5, any of the Gleason patterns 1-5 may be used in some examples.
- it could instead determine the areal percent of the prostate tissue that is tumorous, and use that as additional or alternative input to the Cox regression model.
- the system fits a Cox proportional hazards regression model directly on these percentages, which in some examples may be augmented with the tumor percentage as explained above, to produce continuous AI risk scores 32 , and use leave-one-out-cross-validation to adjust for optimism.
- the risk scores are a number between 0 to 1, with 0 being lowest risk, best prognosis, and 1 being highest risk, worst prognosis. The manner of calculation of the risk score is explained below.
- this continuous risk score achieved a concordance index (C-index) of 0.83 (95% confidence interval (CI) 0.80-0.87) as shown in Table 2 below.
- C-index concordance index
- the C-index for the AI risk score was significantly greater than for the pathologist GG (0.79), an improvement of 0.08 (95% CI 0.01-0.15).
- the AI risk score is a continuous risk score from a Cox regression fit on Gleason pattern percentages from the AI.
- the AI risk group is a discretized version of the AI risk score. The discretization was done to match the number and frequency of pathologist Grade Groups in validation set 2.
- the c-index for the AI risk score was statistically significantly higher than that for the pathologists' Grade Group (p ⁇ 0.05, pre-specified analysis).
- the Pathologist Grade Groups for validation set 1 the data was not available because pathologist Grade Groups were not available for all cases in validation set 1 due to it being from an earlier time period.
- risk groups consist of numbers 1, 2, 3, 4 and 5, which matched or approximated the pathologist Grade Group (GG) distributions in terms of number of cases per risk group (see FIGS. 5A-5C and 6A-6E ).
- Other paradigms for discretizing the continuous risk scores may be used according to other examples.
- FIGS. 7A-7E shows a series of plots where the model 10 was used to categorize the two independent features (percent GP4 and GP5) as risk groups 1 through 5, for each pathologist-assigned Gleason Grade in the set of samples.
- the plots show that as the pathologist-assigned Gleason Grade increases, the relative proportion or percentage of Gleason patterns 4 and 5 in the images changes.
- the Gleason pattern 3 percentage information can be extracted from these plots as the sum of the percentages of Gleason patterns 3, 4 and 5, which equal one.
- risk groups there may be discordances between the risk groups and pathologist GG.
- a sizable subgroup 182 of 436, 42%) were assigned AI risk groups of 1-2 and these patients did not experience any disease-specific mortality events, as shown in Table 4 and in FIGS. 6A-6E .
- the Hazard Ratios (HR) for Gleason patterns 4 and 5 are fit by a Cox Regression model.
- the specific Hazard Ratios fit by the model can be seen in FIGS. 5A-5C , and these values may vary depending on the size, composition and clinical characteristics of the members of the development set 20 .
- the risk score is calculated from the percent Gleason patterns according to Equation 2:
- risk score 0.0975*% GP 4+0.10*% GP 5 Eq. 2.
- Equation (1) or Equation (2) and a table storing the values above in Table 5, or equivalently, a code procedure, are stored in computer memory and used to generate the risk score and/or risk group value for a given slide in the procedure of FIG. 3 from the computation of the areal percentages of Gleason patterns 4 and 5 (% GP4 and % GP5 in Equations 1 and 2).
- FIG. 3 is an illustration of an example workflow for generating a risk score or risk group value for a digital image 50 of a prostate sample at the time of use.
- the sample is imaged, e.g., by a whole slide scanner at a given magnification, such as 40 ⁇ , and the image 50 is input to the AI Gleason Grading Model 10 of FIGS. 1 and 2 .
- the Model 10 first determines prostate tissue/non-tissue regions of the image and then, for the tissue portion, predicts the Gleason patterns 3, 4, and 5 for the tumor areas of the slide, indicated at block 52 .
- the percentages of Gleason patterns 3, 4 and 5 are then determined as indicated at block 54 .
- the risk score and/or risk group definitions are then applied to the percentages determined at block 54 resulting in the generation of a risk score and/or risk group value assignment for the image.
- the risk score and/or risk group value assignment is then presented to the user, e.g., via a workstation 100 having a display 102 , an example of which is shown in FIG. 4 .
- the specimen image 50 is presented to the user, along with the percentages of Gleason pattern 3, 4 and 5 (represented by the numbers X1, X2 and X3) and along with a risk score (in this example 0.7 on a scale of between 0 and 1, with 0 being lowest risk, good prognosis and 1 being highest risk, worse prognosis) and/or the risk group value, here the value “4.”
- FIGS. 3 and 4 can function as an automated, standalone method for prediction of prostate cancer outcomes. We have demonstrated the utility of this method, see the Appendix and the Kaplan-Meier plots of FIGS. 5A-5C and Table 2, rows 3 and 4 above.
- the methodology of FIGS. 3 and 4 can also function as a second read.
- the “user” of the workstation 100 in this embodiment could be a pathologist.
- the pathologist may be presented with a dialog box on the workstation display to input their own assessment of the image, e.g., Gleason Grade 3, and the display presents the AI risk group value, e.g. “4.”
- the pathologist seeing this discrepancy, may be prompted to reassess the image and reconsider their Gleason Grade assignment to the image.
- the presentation of the risk score and/or risk group functions as a second read.
- the utility of this methodology is demonstrated in the Kaplan-Meier plots of FIGS. 6A-6E and Table 2 above.
- the pathologist-determined Gleason Grade and the AI risk score and/or risk group value can be combined in an ensemble manner in yet another further possible implementation.
- the utility of this approach is demonstrated in the last row of Table 6 below.
- the pathologist Gleason Grade and AI risk group value numbers can be combined in several fashions, such as by simple averaging, or using a weighting of the two numbers to reflect relative confidence in the predictions of the AI system and the confidence of the pathologist in their Gleason Grade assignment.
- some examples can employ an “ensembling” approach by determining the arithmetic mean of the AI risk group and pathologist-provided GG, resulting in a C-index of 0.86 (95% CI 0.80-91) vs. 0.79 for pathologists and 0.85 for the AI risk groups, shown in Table 6 above.
- a qualitative analysis of algorithm and pathologist discordances suggests several ways in which the algorithmic grading and pathologist grading may be complementary, including consistent grading of regions by the AI which may be variably overgraded by pathologists, or identification of small, high grade regions which may otherwise be missed by pathologists, such as shown in FIG. 6E .
- Another example involves presenting the AI risk group value or risk score to an oncologist treating a prostate cancer patient.
- the oncologist could be presented with either or both the AI risk group value assignment or risk score, along with the pathologist Gleason Grade assignment.
- the oncologist could then guide the treatment of the patient using both pieces of information, for example to recommend earlier, more aggressive, treatment of the cancer or conversely to initiate a watchful waiting regime, for example where both the AI risk group value or risk score and the pathologist Gleason Grade for the image are low.
- FIG. 8 shows an example configuration of the Gleason Grade Model 10 of FIG. 1 .
- the model includes of two stages: a convolutional neural network (CNN) 1100 that classifies image patches within each slide by Gleason pattern (1, 2, 3, 4 or 5). These predictions can be converted into a predictions heatmap 1102 from which the color-coded Gleason score overlays are generated in a viewer on a workstation, for example as explained in our prior patent application.
- CNN convolutional neural network
- this convolutional neural network 1100 is followed by a second machine learning model 1104 (in one implementation, a support vector machine, or SVM) that uses features extracted from the resulting heatmap 1102 to classify the biopsy/slide's overall Grade Group (GG).
- this second model 1104 may be omitted in some examples.
- some examples could be augmented with a first machine learning model (e.g., deep CNN) that is trained to distinguish prostate tissue from non-prostate tissue, such that the CNN 1100 only operates on prostate tissue.
- a first machine learning model e.g., deep CNN
- some slides from a prostatectomy “specimen” may also contain non-prostate tissue such as seminal vesicles. It is undesirable if the Gleason model 10 generates “false” Gleason pattern predictions on these non-prostate tissue types.
- Extraprostatic tissue and seminal vesicle annotations were combined into one ‘Extraprostatic Tissue’ class.
- An additional 150 slides were randomly sampled from the Gleason grading dataset (see “Gleason Grading Model” in the Methods), and any benign or Gleason pattern 3, 4, or 5 annotation was considered to be part of the ‘Prostatic Tissue’ class.
- the resulting 371 slides were randomly split into a training and tuning split.
- a convolutional neural network using the same architecture, training methodology, and hyperparameter tuning methodology described for the Gleason Grading model, was trained for the binary ‘Extraprostatic Tissue’ vs. ‘Prostatic Tissue’ task, with a resulting AUC of 0.99 on the tuning set.
- the threshold for binarization was chosen to achieve 97% precision (at 84% recall) of prostatic tissue.
- Suitable architectures for Gleason grading prostatectomy specimens may be based on a classic “Inception” neural network architecture, Nagpal, K. et al. Development and validation of a deep learning algorithm for improving Gleason scoring of prostate cancer . NPJ Digit Med 2, 48 (2019), or a second for Gleason grading biopsy specimens based on a customized neural network architecture. Nagpal, K. et al. Development and Validation of a Deep Learning Algorithm for Gleason Grading of Prostate Cancer From Biopsy Specimens . JAMA Oncol (2020). To train these models, a prostatectomy dataset from an initial study was used to train a new model using the customized neural network architecture introduced in the second study, such as shown in FIG.
- the training dataset contained 112 million pathologist-annotated “image patches” from a completely independent set of prostatectomy cases from the validation data used in this study. Briefly, the system takes as input 512 ⁇ 512 pixel image patches (at 10 ⁇ magnification, 1 ⁇ m per pixel) and classifies each patch as one of four categories: non-tumor, Gleason pattern 3, 4, or 5. The hyperparameters used for training this network were determined using a random grid search over fifty potential settings and shown in Table 7 below.
- Validation set 1 included all available cases from 1995-2014 as discussed above. Because Gleason scoring at the Medical University of Graz was adopted in routine practice from 2000 onwards, validation set 2 included all cases from 2000 onwards for which a Gleason score was available. Sensitivity analysis for inclusion of Gleason grades prior to the year 2000 (before Gleason scoring became routine at the institution) is presented in Table 8 below.
- the Gleason grading model was run at stride 256 (at 10 ⁇ magnification, 1 ⁇ m per pixel) on all prostate tissue patches.
- the classification of each patch as non-tumor or GP 3, 4, or 5 was determined via argmax on re-weighted predicted class probabilities.
- the percentage of prostate tumor patches that belong to Gleason patterns 3, 4 and 5 were subsequently computed.
- AI risk scores were computed by fitting a Cox regression model using these case-level Gleason pattern percentages as input, and the right-censored outcomes as the events.
- the primary analysis consisted of the comparison of Concordance (C)-indices for DSS between pathologist GG and the AI risk scores, shown in Table 4.
- the secondary analysis consisted of the comparison between C-indices for pathologist GG and the discretized AI risk groups. All other analyses were exploratory.
- the prognostic performance of the pathologist GG, the AI risk scores and the AI risk group values were measured using Harrel's C-index, a generalization of area under the receiver operating characteristic curve (AUC) for time-censored data. Confidence intervals for both the C-index of AI and pathologists, and the differences between them, were computed via bootstrap resampling with 1000 samples.
- FIG. 10 shows an example method 1000 for AI prediction of prostate cancer outcomes.
- the example will be discussed with respect to the system 200 shown in FIG. 9 and the model 10 shown in FIG. 1 ; however, any suitable system according to this disclosure may be employed.
- the computing device 210 obtains an images of prostate tissue.
- the computing device 210 obtains the images from its data store 212 ; however, in some examples, it may obtain the images from an imaging system 250 or from a remote server 240 or data store 242 .
- the model 10 assigns Gleason patterns values to one or more regions within the image.
- the model assigns Gleason values of 3, 4, and 5 for the tumor areas of the slide, as discussed above with respect to FIG. 3 .
- the model 10 may first determine prostate tissue versus non-prostate tissue regions of the image, which may ensure that the model 10 only determines predictions for prostate tissue.
- the computing device 210 determines relative areal proportions of the Gleason patterns, generally as discussed above with respect to block 24 of FIG. 2 .
- the computing device 210 determines a risk score or risk group value based on the areal proportions, generally as discussed above with respect to blocks 30 of FIG. 2 or 50 of FIG. 3 , which may involve the use of a Cox proportional hazard regression model fitted to a set of Gleason patterns or proportions thereof assigned to a multitude of images in a data set by the artificial intelligence Gleason grading model and associated survival data associated with the data set.
- the computing device 210 receives a Gleason Grade corresponding to the image from a user of the computing device 210 .
- the user may be prompted to provide a Gleason Grade.
- the user-provided Gleason Grade may be combined with the determined risk score or risk group value, generally as discussed above with respect to FIGS. 3 and 4 . It should be appreciated that the functionality of block 1050 may be omitted in some examples.
- the risk score or risk group value is provided.
- the risk score or risk group value (or both, in some examples), may be displayed on display 214 , stored in data store 212 , stored in data store 242 , or otherwise communicated to a pathologist, oncologist, or other medical professional.
- a combined risk score or risk group value may be provided, such as may be generated at block 1050 in some examples.
- FIG. 11 shows an example computing device 1200 suitable for use in example systems or methods for AI prediction of prostate cancer outcomes according to this disclosure.
- the example computing device 1200 includes a processor 1210 which is in communication with the memory 1220 and other components of the computing device 1200 using one or more communications buses 1202 .
- the processor 1210 is configured to execute processor-executable instructions stored in the memory 1220 to perform one or more methods for AI prediction of prostate cancer outcomes according to different examples, such as part or all of the example method 1000 described above with respect to FIG. 10 .
- the memory 1220 includes a deep learning system 1260 , such as the example model 10 shown in FIG. 1, 2 , or 8 .
- the computing device 1200 also includes one or more user input devices 1250 , such as a keyboard, mouse, touchscreen, microphone, etc., to accept user input; however, in some examples, the computing device 1200 may lack such user input devices, such as remote servers or cloud servers.
- the computing device 1200 also includes a display 1240 to provide visual output to a user.
- user input devices or displays may be optional in some examples.
- the computing device 1200 also includes a communications interface 1240 .
- the communications interface 1230 may enable communications using one or more networks, including a local area network (“LAN”); wide area network (“WAN”), such as the Internet; metropolitan area network (“MAN”); point-to-point or peer-to-peer connection; etc. Communication with other devices may be accomplished using any suitable networking protocol.
- LAN local area network
- WAN wide area network
- MAN metropolitan area network
- point-to-point or peer-to-peer connection etc.
- Communication with other devices may be accomplished using any suitable networking protocol.
- one suitable networking protocol may include the Internet Protocol (“IP”), Transmission Control Protocol (“TCP”), User Datagram Protocol (“UDP”), or combinations thereof, such as TCP/IP or UDP/IP.
- IP Internet Protocol
- TCP Transmission Control Protocol
- UDP User Datagram Protocol
- a device may include a processor or processors.
- the processor comprises a computer-readable medium, such as a random access memory (RAM) coupled to the processor.
- the processor executes computer-executable program instructions stored in memory, such as executing one or more computer programs.
- Such processors may comprise a microprocessor, a digital signal processor (DSP), an application-specific integrated circuit (ASIC), field programmable gate arrays (FPGAs), and state machines.
- Such processors may further comprise programmable electronic devices such as PLCs, programmable interrupt controllers (PICs), programmable logic devices (PLDs), programmable read-only memories (PROMs), electronically programmable read-only memories (EPROMs or EEPROMs), or other similar devices.
- Such processors may comprise, or may be in communication with, media, for example one or more non-transitory computer-readable media, that may store processor-executable instructions that, when executed by the processor, can cause the processor to perform methods according to this disclosure as carried out, or assisted, by a processor.
- Examples of non-transitory computer-readable medium may include, but are not limited to, an electronic, optical, magnetic, or other storage device capable of providing a processor, such as the processor in a web server, with processor-executable instructions.
- non-transitory computer-readable media include, but are not limited to, a floppy disk, CD-ROM, magnetic disk, memory chip, ROM, RAM, ASIC, configured processor, all optical media, all magnetic tape or other magnetic media, or any other medium from which a computer processor can read.
- the processor, and the processing, described may be in one or more structures, and may be dispersed through one or more structures.
- the processor may comprise code to carry out methods (or parts of methods) according to this disclosure.
- references herein to an example or implementation means that a particular feature, structure, operation, or other characteristic described in connection with the example may be included in at least one implementation of the disclosure.
- the disclosure is not restricted to the particular examples or implementations described as such.
- the appearance of the phrases “in one example,” “in an example,” “in one implementation,” or “in an implementation,” or variations of the same in various places in the specification does not necessarily refer to the same example or implementation.
- Any particular feature, structure, operation, or other characteristic described in this specification in relation to one example or implementation may be combined with other features, structures, operations, or other characteristics described in respect of any other example or implementation.
- a or B or C includes any or all of the following alternative combinations as appropriate for a particular usage: A alone; B alone; C alone; A and B only; A and C only; B and C only; and A and B and C.
Abstract
Description
- This application claims priority to U.S. Provisional Patent Application No. 63/110,786 filed Nov. 6, 2020, entitled “Artificial Intelligence Prediction Of Prostate Cancer Outcomes,” which is related to U.S. provisional application Ser. No. 63/001,664 filed Mar. 30, 2020, entitled “Artificial Intelligence-based assistant for concurrent review of needle core prostate biopsies,” the entire content of each which are incorporated by reference herein.
- The present application generally relates to artificial intelligence systems and methods for tumor analysis, and more specifically relates to artificial intelligence prediction of prostate cancer outcomes.
- Prostate cancer affects 1 in 9 men in their lifetime but disease aggressiveness and prognosis can vary substantially among individuals based on factors such as the cancer grade. Gleason grading of prostate cancer involves assigning different histologic patterns, known as Gleason patterns, to each region of a patient's tumor. Based on the prevalence of these patterns, one of five Gleason Grade Groups (GG), i.e., GG1, GG2, GG3, GG4 or GG5, is assigned. A patient's prognosis worsens as the Gleason grade group grade increases. The resulting GG is among the most prognostic factors for prostate cancer patients, and is used for patient risk stratification and to match patients to treatment plans most appropriate for their risk of disease progression.
- The Gleason system is used at distinct points in the clinical management of prostate cancer. First, for patients undergoing diagnostic biopsies, if tumor is identified, the GG impacts the decision between active surveillance versus definitive treatment options such as surgical removal of the prostate or radiation therapy. For patients who subsequently undergo a surgical resection of the prostate (radical prostatectomy), the GG is one key component of decisions regarding additional treatment such as radiotherapy or hormone therapy. In large clinical trials, use of adjuvant therapy following prostatectomy has demonstrated benefits such as improved progression-free survival for some patients, but can also result in adverse side effects. Given the tradeoff between potential benefit and toxicity for these adjuvant treatments, identifying the patients most likely to benefit from adjuvant treatment remains an important area of investigation in prostate cancer care.
- Various examples are described for artificial intelligence prediction of prostate cancer outcomes. One example method includes receiving an image of prostate tissue; assigning Gleason pattern values to one or more regions within the image using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image; determining relative areal proportions of the Gleason patterns within the image; assigning at least one of a risk score or risk group value to the image based on the determined relative areal proportions; and outputting at least one of the risk score or the risk group value.
- One example system for assessing a prognosis of a prostate cancer patient includes a non-transitory computer-readable medium; and one or more processors communicatively coupled to the non-transitory computer-readable medium, the one or more processors configured to execute processor-executable instructions stored in the non-transitory computer-readable medium to receive an image of prostate tissue; assign Gleason pattern values to one or more regions within the image using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image; determine relative areal proportions of the Gleason patterns within the image; assign at least one of a risk score or risk group value to the image based on the determined relative areal proportions; and output at least one of the risk score or the risk group value.
- One example non-transitory computer-readable medium comprising processor-executable instructions configured to cause one or more to receive an image of prostate tissue; assign Gleason pattern values to one or more regions within the image using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image; determine relative areal proportions of the Gleason patterns within the image; assign at least one of a risk score or risk group value to the image based on the determined relative areal proportions; and output at least one of the risk score or the risk group value.
- These illustrative examples are mentioned not to limit or define the scope of this disclosure, but rather to provide examples to aid understanding thereof. Illustrative examples are discussed in the Detailed Description, which provides further description. Advantages offered by various examples may be further understood by examining this specification.
- The accompanying drawings, which are incorporated into and constitute a part of this specification, illustrate one or more certain examples and, together with the description of the example, serve to explain the principles and implementations of the certain examples.
-
FIG. 1 is an illustration showing the development of a deep learning system in the form of an AI Gleason Grading Model, which generates Gleason pattern predictions for a digital prostate sample image on an image patch-by-patch basis. -
FIG. 2 is an illustration showing a method we used to generate our new AI risk score paradigm, including continuous risk scores and discrete risk groups, from (1) a set of samples (which included both image data and survival data for each go the samples), (2) the Gleason Grading Model ofFIG. 1 , and (3) a Cox proportional hazards regression model using the survival data and Gleason pattern patch predictions from the set. -
FIG. 3 is a flow chart showing a method of generating a risk group value or risk score for a prostate cancer tissue specimen image. This risk group value or score could be implemented as a stand-alone prediction, as a second read (e.g., as an adjunct to an overall Gleason Grade assigned by a pathologist) or as a combined manner in which the risk group score is combined with the pathologist's overall Gleason Grade assignment. -
FIG. 4 is an illustration of one possible example of how the AI risk group score (“4” in this example) could be presented on a workstation used by a clinician, e.g., primary care physician, oncologist, pathologist, etc. -
FIGS. 5A-5C are Kaplan-Meier curves of survival probability as a function of time for the risk groups assigned for members of a validation set. -
FIGS. 6A-6E are Kaplan-Meier plots showing the sub-stratification of patients by risk groups 1-2 vs. 3-5 within each pathologist-determine Gleason Grade. -
FIGS. 7A-7E are plots ofpercentage Gleason patterns -
FIG. 8 is an illustration of one possible embodiment of the deep learning system ofFIGS. 1 and 2 which assigns Gleason patterns on a patch-by-patch basis and an overall Gleason Grade for a prostate tissue image. -
FIG. 9 illustrate an example system for AI prediction of prostate cancer outcomes. -
FIG. 10 illustrates an example method for AI prediction of prostate cancer outcomes. -
FIG. 11 illustrates an example computing device suitable for use with example systems and methods for AI prediction of prostate cancer outcomes. - Examples are described herein in the context of artificial intelligence prediction of prostate cancer outcomes. Those of ordinary skill in the art will realize that the following description is illustrative only and is not intended to be in any way limiting. Reference will now be made in detail to implementations of examples as illustrated in the accompanying drawings. The same reference indicators will be used throughout the drawings and the following description to refer to the same or like items.
- In the interest of clarity, not all of the routine features of the examples described herein are shown and described. It will, of course, be appreciated that in the development of any such actual implementation, numerous implementation-specific decisions must be made in order to achieve the developer's specific goals, such as compliance with application- and business-related constraints, and that these specific goals will vary from one implementation to another and from one developer to another.
- Due to the complexity and intrinsic subjectivity of the system, Gleason grading suffers from large discordance rates between pathologists (30-50%), thus introducing a potential source of variability and prognostic inaccuracies. However, grades from experts (such as those with urologic subspeciality training) are more consistent and result in more accurate risk stratification than grades from less experienced pathologists, suggesting an opportunity to improve the clinical utility of the system by improving grading consistency and accuracy. To this end, several AI algorithms for Gleason grading have been developed and validated using expert-provided Gleason scores. See e.g., Nagpal, K. et al. Development and validation of a deep learning algorithm for improving Gleason scoring of prostate cancer, NPJ Digit Med 2, 48 (2019), and Nagpal, K. et al., Development and Validation of a Deep Learning Algorithm for Gleason Grading of Prostate Cancer From Biopsy Specimens, JAMA Oncol (2020), the content of both of which is incorporated by reference herein. However, an evaluation of the prognostic value of the algorithms and a direct comparison to the prognostic value of Gleason grading provided by pathologists has not, to our knowledge, been conducted. While the GG for biopsies as well as prostatectomy specimens both provide important prognostic information, retrospective studies to evaluate long-term clinical outcomes is more straightforward from prostatectomy cases given widely divergent treatment pathways following biopsy alone.
- To address these issues, a new prognostic risk score paradigm may be used, including a continuous artificial intelligence (“AI”) risk score, and then further discretizing these risk scores into new AI “risk groups.” The risk score can be reported, or the risk group value, or both, for a given prostate tissue image. The use of a system to analyze images of prostate tissue to generate such AI risk scores or AI risk groups enables predicting prostate cancer patient prognosis directly from a digital image of a prostate cancer specimen, such as a needle core biopsy or prostatectomy specimen. Further, such techniques may be used to generate either a stand-alone prediction, or as a second read, or in a combined system in which the risk score or risk group value is combined with the pathologist's own Gleason Grade evaluation of the specimen.
- In one example implementation, a system can assign Gleason pattern categorizations (e.g., 3, 4, or 5) to regions of an image of prostate tissue from the patient containing tumor cells using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image. It can then determine the relative areal proportions, e.g., percentages of the Gleason pattern categorizations, such as the relative size or area of tumor patches graded Gleason
pattern - The system can then assign a risk score or risk group value, or both, to the image using the determined relative proportions. The risk score or risk group value is correlated to prognosis of the patient. Further, in some cases, the assigning step can make use of a Cox proportional hazards regression model fitted to a set of Gleason pattern scores or proportions thereof assigned to a multitude of images in a data set by the AI Gleason grading model and associated survival data associated with the data set.
- To provide a suitable sample, the image of the prostate tissue can be an image of a specimen obtained from a prostatectomy or it could be of a specimen obtained from a needle core biopsy. To generate such an image, the specimen (or portion thereof) is placed on a tissue slide and imaged with a digital whole slide scanner at some particular magnification or combination of magnifications, such as 40× or 10×, as is conventional.
- The system can also present the risk score, risk group values, or both, on a workstation used by clinician, such as for example a pathologist or oncologist. Note that the term “workstation” is intended to be interpreted broadly to encompass any computer device with a display and user interface for interacting with the display, including a desktop computer, tablet, smart phone, laptop computer and the like.
- In one embodiment the workstation has an interface providing a feature for the pathologist or oncologist to input a human-derived Gleason Grade for the image, e.g., after visual examination of the specimen with a microscope or by study of a magnified digital image of the specimen. This feature can facilitate a comparison of the risk score, risk group value, or both, to the human-derived Gleason Grade. For example, the risk group values take on values of 1, 2, 3, 4 or 5 and correspond at least approximately to GG of 1, 2, 3, 4, and 5 (respectively). In case of discordance between the risk group valuation and the Gleason Grade the user (pathologist or oncologist) may be motivated to reconsider their own Gleason grade group assignment or perhaps take the risk group value in consideration along with the pathologist Gleason Grade group assignment when planning a course of treatment for the patient.
- It is also envisioned that the risk group valuation can be combined with a human-derived Gleason Grade in an ensemble manner, including for example computing an average of the two values.
- As noted above, in some examples, the risk group values can take the form of integers from 1 to 5, inclusive. The survival probability of each of the risk group values approximates the survival probability of prostate cancer patients with Gleason Grades of integers 1-5 inclusive, respectively. However, based on the systems and methods according to this disclosure, an AI risk group may not only approximate the prognosis provided by Gleason Grade group, but can provide a grouping system that more accurately categorizes patients based on more complex Gleason pattern thresholds. In particular, whereas the current Gleason grade group system uses “simple” thresholds (e.g. GG1 vs GG2 vs. GG3 essentially is >0% or >50
% pattern 4 respectively), example systems according this disclosure may provide more precise groupings that better correlate with prognosis. - In still another aspect, a method is described for developing a model for predicting prognosis of a prostate cancer patient, which includes a system that can obtain a data set comprising a multitude of prostate cancer tissue images and associated survival data for prostate cancer patients associated with the tissue images. It can then assign Gleason patterns to regions of each image containing tumor cells using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image.
- Subsequently, the system determines the relative areal proportions of the Gleason patterns in each of the images assigned by the artificial intelligence Gleason grading model and performs a Cox proportional hazards regression on the relative proportions and the survival data to generate continuous risk scores associated with prognosis for the patients in the data set. It can then define discrete risk group values from the continuous risk scores.
- As will be appreciated from the following description, the present methods can be implemented in a computing environment including a processing unit and a machine-readable memory storing program instructions. The computing environment could be local to the clinician, such as executed in a processing unit and memory of a workstation. As an alternative, the computing environment could be in a remote server or cloud environment, in which the Gleason grading model is implemented in a remote computer from the clinician workstation, receives images over a network, determines the Gleason patterns in the image and computes the relative proportions, assigns a risk score and/or risk group to the image, and then returns the result to the workstation, possible along with a version of the image with a “heatmap” showing the different Gleason patterns in the image as determined by the Gleason grading model.
- In still another aspect, a machine-readable memory is provided storing a procedure for calculating a risk group value or a risk group score associated with a prognosis of a prostate cancer patient from input in the form of relative proportions of the Gleason pattern scores assigned to a prostate tissue image by an artificial intelligence Gleason grading model trained to identify Gleason patters on a patch-by-patch basis in a prostate tissue image. This procedure can be in the form of a table, mathematical formula, or combination thereof, correlating a multitude of possible Gleason pattern score proportions (e.g., percentages) to one of a finite number of risk group values, such as five of such values, i.e., 1, 2, 3, 4, 5 corresponding approximately to Gleason Grade scores. The plots of
FIGS. 5 and 6 demonstrate the correlation between risk group values and prognosis under the present inventive risk scoring paradigm. - In still another aspect, a system is provided for assessing the prognosis of a prostate cancer patient. The system includes a computer memory storing a digital image of a prostate specimen of the patient; and a programmed computer containing code for assigning Gleason pattern scores to regions of the image using an artificial intelligence Gleason grading model, the model trained to identify Gleason patterns on a patch-by-patch basis in a prostate tissue image; wherein the computer is further programmed with code to compute the relative proportions of the Gleason pattern scores; and wherein the computer is further programmed with a procedure for assigning a risk score or risk group value, or both, to the image using the relative proportions.
- These illustrative examples are given to introduce the reader to the general subject matter discussed herein and the disclosure is not limited to this example. The following sections describe various additional non-limiting examples and examples of artificial intelligence prediction of prostate cancer outcomes.
- Referring now to
FIG. 1 ,FIG. 1 shows an example system that employs a trained deep learning system, referred to as Gleason Grading model 10 (or “model 10”). Themodel 10 in this example is a deep artificial neural network, though in other examples, it may be a pattern recognizer or any other suitable deep learning model. Thisexample model 10 was developed using a development set 12 of images and associated ground truth. Themodel 10 has an ancillary or second model (not shown), e.g., a trained convolutional neural network or pattern recognizer, that is trained to distinguish between prostate tissue and non-prostate tissue to ensure that theGleason Grading Model 10 only operates on those portions of an image that actually contain prostate tissue. However, it should be appreciated that the ancillary model may not be employed in some examples. - The details of the
Gleason Grading Model 10 are illustrated inFIG. 8 , and the associated discussion below. This model is trained from a development set of samples (magnified digital images of prostate specimens) with associated ground truth to make predictions of Gleason patterns (e.g.,Gleason model 10 can then be used to makepredictions 16 based on inputdigital images 14 of prostate specimens. - While the present methods make use of the model described above and shown in
FIG. 8 , it will be appreciated that other deep learning models that make Gleason pattern predictions on a patch by patch basis could be used and so the model described in this document is offered by way of example and not limitation. - Referring now to
FIG. 9 ,FIG. 9 shows anexample system 200 for AI prediction of prostate cancer outcomes. Theexample system 200 includes acomputing device 210 that has access to adata store 212 and is connected toserver 240 and itsdata store 242 vianetwork 230. In this example, thecomputing device 210 is also connected toimaging system 250, which can capture and provide images of prostate tissue to thecomputing device 210. In addition, thecomputing device 210 can access digitized images of prostate tissue fromdata store 212 and provide them to themodel 220 for analysis, such as using thesystem 100 described above with respect toFIG. 1 . After completing the analysis, themodel 220 provides the results to thecomputing device 210, stores them indata store 222 for later retrieval, e.g., by medical personnel, or displays them on thedisplay 214, or any combination. - While in this example, the
computing device 210 receives the images of prostate tissue from itsown data store 212, in some examples, it may obtain images of prostate tissue from theserver 240, which may access itsown data store 242 to obtain and provide requested histopathology images. In some examples, thecomputing device 210 may be connected to a microscope that can capture images of prostate tissue. Further, while the analysis is performed bymodel 220 executed by thecomputing device 210 itself, in some examples, themodel 220 may be part of theserver 240, and thecomputing device 210 may provide images of prostate tissue to theserver 240 for analysis, vianetwork 230, and later receive the results, which may be stored in thedata store 212 or displayed on thedisplay 214. - In this example, the
server 220 is maintained by a medical provider, e.g., a hospital or laboratory, while thecomputing device 210 is resident at a medical office, e.g., in a pathologist's office. Thus, such asystem 200 may enable medical providers at remote locations to obtain predictions for prostate cancer outcomes, even if they lack the trainedmodel 220. However, it should be appreciated that example systems according to this disclosure may only includecomputing device 210, which may perform the analysis itself without communicating with a remote computing device. - Referring to
FIG. 2 ,FIG. 2 is an illustration showing a processing flow for AI prediction of prostate cancer outcomes, including continuous risk scores and discrete risk groups, from a set of samples 20 (which included both image data and survival data for each of the samples), themodel 10 ofFIG. 1 , and aCox regression model 30 using the survival data and Gleason pattern patch predictions from theset 20. - The particulars of this set of
samples 20 include both digital images of a prostate specimen and associated survival data for the patient providing the samples. In this example, theset 20 consisted of all archived slides in prostatectomy cases from 1995-2014 at the BioBank at the Medical University of Graz in Austria. The slides were scanned at magnification and digitized. There were typically several slides per case/patient. After excluding 9 cases for death within 30 days of the surgery, 2,811 cases remained. The median follow-up time was 13.1 years (interquartile range 8.5-17.2). This group of cases were grouped into two validations sets: all cases (validation set 1), and the subset of cases from 2000-2014 for which Gleason grading was performed at the time of pathologic diagnosis (n=1,517 cases, validation set 2), illustrated in Table 1, which provides the overall survival and disease-specific survival rates in each validation set. -
TABLE 1 Validation Set 1Validation Set 2Number of Cases 2,815 1,517 Number of Slides 83,943 47,626 Overall Survival Median years of follow-up 13.1 (8.5, 17.2) 11.2 (7.4, 15.2) (interquartile range) Censored 2,152 1,306 Observed 663 211 Disease-specific survival Censored 2,681 1,464 Observed 134 53 Grade Group 1 611 608 2 476 473 3 224 224 4 128 127 5 85 85 Unknown 1,291 0 Pathologic T- stage T1 22 3 T2 1,626 1,110 T3 791 366 T4 25 8 Unknown 351 32 Age at diagnosis <60 955 537 60-65 925 501 >65 935 479 - In Table 1, validation set 1 contains all prostatectomy cases from the Biobank Graz between 1995-2014, while validation set 2 is a subset of validation set 1 and contains all prostatectomy cases between 2000-2014 where a diagnostic Grade Group was recorded.
- As indicated at
block 22, the images in theset 20 were input into themodel 10 to assess the tumor composition and generate patch-level predictions of Gleason pattern on each of the images. The areal percentages were then determined atblock 24 for threedifferent Gleason patterns % GP 3,% GP 4, % GP 5). In this example, the percentages were determined by determining the size of the patches of a given Gleason pattern (taking into account such things as pixel pitch, magnification, etc.) and dividing that size (area) by the total area of the tumor havingGleason patterns Gleason patterns Gleason patterns Gleason pattern 3 is one minus the combined percentage ofGleason patterns Gleason 4 areal percentage is computed as 0.5 (50 percent) and theGleason 5 areal percentage is computed as 0.3 (30 percent) then theGleason 3 percentage is 0.2 (20 percent), i.e., 1−(0.5+0.3)=0.2. - In one variation, it could instead determine the areal percent of the prostate tissue that is tumorous, and use that as additional or alternative input to the Cox regression model.
- As indicated at 30, using the percentages computed at 24 and using the survival data from the
set 20, the system fits a Cox proportional hazards regression model directly on these percentages, which in some examples may be augmented with the tumor percentage as explained above, to produce continuous AI risk scores 32, and use leave-one-out-cross-validation to adjust for optimism. The risk scores are a number between 0 to 1, with 0 being lowest risk, best prognosis, and 1 being highest risk, worst prognosis. The manner of calculation of the risk score is explained below. On validation set 1, this continuous risk score achieved a concordance index (C-index) of 0.83 (95% confidence interval (CI) 0.80-0.87) as shown in Table 2 below. In pre-specified primary analysis, on validation set 2, the C-index for the AI risk score (0.87) was significantly greater than for the pathologist GG (0.79), an improvement of 0.08 (95% CI 0.01-0.15). -
TABLE 2 C-index [95% CI] Validation Set 1Validation Set 2Pathologist Grade Groups N/A 0.79 [0.71, 0.86] AI risk score 0.83 [0.80-0.87] 0.87 [0.81, 0.91] (continuous) AI risk groups 0.82 [0.78-0.85] 0.84 [0.79, 0.90] (discretized) - With respect to Table 2 above, the AI risk score is a continuous risk score from a Cox regression fit on Gleason pattern percentages from the AI. The AI risk group is a discretized version of the AI risk score. The discretization was done to match the number and frequency of pathologist Grade Groups in
validation set 2. In validation set 2, the c-index for the AI risk score was statistically significantly higher than that for the pathologists' Grade Group (p<0.05, pre-specified analysis). With respect to the Pathologist Grade Groups for validation set 1, the data was not available because pathologist Grade Groups were not available for all cases in validation set 1 due to it being from an earlier time period. - As indicated at
step 34 to additionally compare with pathologists' Gleason Grade Group (GG) categorizations, we also discretized these risk scores into “risk groups.” These risk groups consist ofnumbers FIGS. 5A-5C and 6A-6E ). Other paradigms for discretizing the continuous risk scores may be used according to other examples. - Referring to
FIGS. 7A-7E ,FIGS. 7A-7E shows a series of plots where themodel 10 was used to categorize the two independent features (percent GP4 and GP5) asrisk groups 1 through 5, for each pathologist-assigned Gleason Grade in the set of samples. The plots show that as the pathologist-assigned Gleason Grade increases, the relative proportion or percentage ofGleason patterns Gleason pattern 3 percentage information can be extracted from these plots as the sum of the percentages ofGleason patterns - The C-index for the discretized risk groups (0.85) also trended higher than for the pathologist GG, an improvement of 0.07 (95% CI 0.00-0.14) (see Table 2 above). Kaplan-Meier analyses also showed significant AI risk stratification in both validation sets (p<0.001 for log-rank test, see also
FIG. 5 ), and multivariable regression models indicated a trend of increasing hazard ratio with both higher GG and higher risk group value shown in Table 3 below. -
TABLE 3 Univariable Hazard ratio [95% CI] P- value Grade Group 1 1.0 (reference) — 2 3.85 [1.39, 10.70] p = 0.010 3 4.68 [1.49, 14.76] p = 0.009 4 14.30 [5.03, 40.62] p < 0.001 5 35.87 [13.00, 98.97] p < 0.001 Grade Group 1 1.0 (reference) — 2 0.71 [0.17, 2.97] p = 0.641 3 6.23 [2.19, 17.69] p < 0.001 4 13.16 [4.74, 36.54] p < 0.001 5 35.54 [13.26, 95.27] p < 0.001 - In some cases, there may be discordances between the risk groups and pathologist GG. First, we compared 10-year disease-specific survival rates for cases where the risk group was higher or lower risk than the pathologist GG, shown in Table 4 below. Within each pathologist-determined GG, the 10-year survival rates were higher for cases where the AI provided a lower risk classification, especially for GG ≥3. The survival rates also tended to be lower where the AI provided a higher risk classification. Second, risk stratification by the risk groups 1-2 vs. 3-5 remained significant within each pathologist-determined GG (see the plots of
FIG. 6 ). In particular, among the GG 3-5 patients, a sizable subgroup (182 of 436, 42%) were assigned AI risk groups of 1-2 and these patients did not experience any disease-specific mortality events, as shown in Table 4 and inFIGS. 6A-6E . -
TABLE 4 Pathologist Grade AI risk group Group All Lower Same Higher 1 1.00 [0.99, 1.00] N/A 1.00 [1.00, 1.00] 0.99 [0.97, 1.00] n = 608 n = 327 n = 281 2 0.98 [0.96, 0.99] 1.00 [1.00, 1.00] 0.98 [0.94, 1.00] 0.93 [0.84, 0.97] n = 473 n = 212 n = 179 n = 82 3 0.99 [0.95, 1.00] 1.00 [1.00, 1.00] 0.98 [0.87, 1.00] 0.97 [0.81, 1.00] n = 224 n = 117 n = 56 n = 51 4 0.92 [0.83, 0.96] 1.00 [1.00, 1.00] 0.81 [0.56, 0.93] 0.72 [0.33, 0.91] n = 127 n = 83 n = 26 n = 18 5 0.83 [0.70, 0.90] 0.93 [0.74, 0.98] 0.65 [0.42, 0.81] N/A n = 85 n = 53 n = 32 - It will be appreciated that after the development work of
FIG. 2 has been performed and the risk score and risk group definitions determined, such definitions are then stored in memory, e.g., as a table or mathematical formula, or combination thereof so that they can be used in the future for generating a risk score or risk group value for a particular prostate tissue sample. For the present work, we have usedEquation 1 to calculate the risk score: -
risk score=(log(HR_GP4)*%GP4+log(HR_GP5)*%GP5))/(100*log(HR_GP5)) Eq. 1: - The Hazard Ratios (HR) for
Gleason patterns FIGS. 5A-5C , and these values may vary depending on the size, composition and clinical characteristics of the members of the development set 20. In one specific embodiment, the risk score is calculated from the percent Gleason patterns according to Equation 2: -
risk score=0.0975*%GP4+0.10*%GP5 Eq. 2. - The range for risk scores that correspond to the risk groups in one specific embodiment of our scoring paradigm are as shown in Table 5:
-
TABLE 5 Risk Group Risk Scores 1 0.000-0.167 2 0.168-0.447 3 0.448-0.698 4 0.699-0.881 5 0.882-1.000 - In practice, the above Equation (1), or Equation (2) and a table storing the values above in Table 5, or equivalently, a code procedure, are stored in computer memory and used to generate the risk score and/or risk group value for a given slide in the procedure of
FIG. 3 from the computation of the areal percentages ofGleason patterns 4 and 5 (% GP4 and % GP5 inEquations 1 and 2). - Referring now to
FIG. 3 ,FIG. 3 is an illustration of an example workflow for generating a risk score or risk group value for adigital image 50 of a prostate sample at the time of use. The sample is imaged, e.g., by a whole slide scanner at a given magnification, such as 40×, and theimage 50 is input to the AIGleason Grading Model 10 ofFIGS. 1 and 2 . In this example, theModel 10 first determines prostate tissue/non-tissue regions of the image and then, for the tissue portion, predicts theGleason patterns block 52. The percentages ofGleason patterns block 54. Atblock 56, the risk score and/or risk group definitions are then applied to the percentages determined atblock 54 resulting in the generation of a risk score and/or risk group value assignment for the image. Atblock 58 the risk score and/or risk group value assignment is then presented to the user, e.g., via aworkstation 100 having adisplay 102, an example of which is shown inFIG. 4 . Thespecimen image 50 is presented to the user, along with the percentages ofGleason pattern - The methodology of
FIGS. 3 and 4 can function as an automated, standalone method for prediction of prostate cancer outcomes. We have demonstrated the utility of this method, see the Appendix and the Kaplan-Meier plots ofFIGS. 5A-5C and Table 2,rows - The methodology of
FIGS. 3 and 4 can also function as a second read. As one possible example of this, the “user” of theworkstation 100 in this embodiment could be a pathologist. For example, the pathologist may be presented with a dialog box on the workstation display to input their own assessment of the image, e.g.,Gleason Grade 3, and the display presents the AI risk group value, e.g. “4.” The pathologist, seeing this discrepancy, may be prompted to reassess the image and reconsider their Gleason Grade assignment to the image. In this situation, the presentation of the risk score and/or risk group functions as a second read. The utility of this methodology is demonstrated in the Kaplan-Meier plots ofFIGS. 6A-6E and Table 2 above. - The pathologist-determined Gleason Grade and the AI risk score and/or risk group value can be combined in an ensemble manner in yet another further possible implementation. The utility of this approach is demonstrated in the last row of Table 6 below. The pathologist Gleason Grade and AI risk group value numbers can be combined in several fashions, such as by simple averaging, or using a weighting of the two numbers to reflect relative confidence in the predictions of the AI system and the confidence of the pathologist in their Gleason Grade assignment.
-
TABLE 6 Year of Analysis 1995-2014 2000-2014 No. of Cases 2,815 1,517 A) Pathologist 0.79 [0.71, 0.85] 0.79 [0.71, 0.85] Grade Group B) AI risk score 0.86 [0.81, 0.89] 0.86 [0.81, 0.89] C) AI risk group 0.85 [0.79, 0.90] 0.85 [0.79, 0.90] D) Combined 0.86 [0.80, 0.90] 0.86 [0.80, 0.90] risk group - In addition, some examples can employ an “ensembling” approach by determining the arithmetic mean of the AI risk group and pathologist-provided GG, resulting in a C-index of 0.86 (95% CI 0.80-91) vs. 0.79 for pathologists and 0.85 for the AI risk groups, shown in Table 6 above. A qualitative analysis of algorithm and pathologist discordances suggests several ways in which the algorithmic grading and pathologist grading may be complementary, including consistent grading of regions by the AI which may be variably overgraded by pathologists, or identification of small, high grade regions which may otherwise be missed by pathologists, such as shown in
FIG. 6E . - Another example involves presenting the AI risk group value or risk score to an oncologist treating a prostate cancer patient. The oncologist could be presented with either or both the AI risk group value assignment or risk score, along with the pathologist Gleason Grade assignment. The oncologist could then guide the treatment of the patient using both pieces of information, for example to recommend earlier, more aggressive, treatment of the cancer or conversely to initiate a watchful waiting regime, for example where both the AI risk group value or risk score and the pathologist Gleason Grade for the image are low.
- Referring now to
FIG. 8 ,FIG. 8 shows an example configuration of theGleason Grade Model 10 ofFIG. 1 . The model includes of two stages: a convolutional neural network (CNN) 1100 that classifies image patches within each slide by Gleason pattern (1, 2, 3, 4 or 5). These predictions can be converted into apredictions heatmap 1102 from which the color-coded Gleason score overlays are generated in a viewer on a workstation, for example as explained in our prior patent application. In the configuration shown inFIG. 8 , this convolutionalneural network 1100 is followed by a second machine learning model 1104 (in one implementation, a support vector machine, or SVM) that uses features extracted from the resultingheatmap 1102 to classify the biopsy/slide's overall Grade Group (GG). However, thissecond model 1104 may be omitted in some examples. Further, some examples could be augmented with a first machine learning model (e.g., deep CNN) that is trained to distinguish prostate tissue from non-prostate tissue, such that theCNN 1100 only operates on prostate tissue. For example, some slides from a prostatectomy “specimen” may also contain non-prostate tissue such as seminal vesicles. It is undesirable if theGleason model 10 generates “false” Gleason pattern predictions on these non-prostate tissue types. - For example, to collect data for model development, pathologists were asked to coarsely outline extraprostatic tissue and seminal vesicle regions across 221 slides from The Cancer Genome Atlas 40 and previously digitized slides from the Navy Medical
Center San Diego 8. Extraprostatic tissue and seminal vesicle annotations were combined into one ‘Extraprostatic Tissue’ class. An additional 150 slides were randomly sampled from the Gleason grading dataset (see “Gleason Grading Model” in the Methods), and any benign orGleason pattern - The resulting 371 slides were randomly split into a training and tuning split. A convolutional neural network, using the same architecture, training methodology, and hyperparameter tuning methodology described for the Gleason Grading model, was trained for the binary ‘Extraprostatic Tissue’ vs. ‘Prostatic Tissue’ task, with a resulting AUC of 0.99 on the tuning set. The threshold for binarization was chosen to achieve 97% precision (at 84% recall) of prostatic tissue.
- Suitable architectures for Gleason grading prostatectomy specimens may be based on a classic “Inception” neural network architecture, Nagpal, K. et al. Development and validation of a deep learning algorithm for improving Gleason scoring of prostate cancer.
NPJ Digit Med 2, 48 (2019), or a second for Gleason grading biopsy specimens based on a customized neural network architecture. Nagpal, K. et al. Development and Validation of a Deep Learning Algorithm for Gleason Grading of Prostate Cancer From Biopsy Specimens. JAMA Oncol (2020). To train these models, a prostatectomy dataset from an initial study was used to train a new model using the customized neural network architecture introduced in the second study, such as shown inFIG. 8 . The training dataset contained 112 million pathologist-annotated “image patches” from a completely independent set of prostatectomy cases from the validation data used in this study. Briefly, the system takes as input 512×512 pixel image patches (at 10× magnification, 1 μm per pixel) and classifies each patch as one of four categories: non-tumor,Gleason pattern -
TABLE 7 Gleason Grading Model Prostatic Tumor Segmentation Architecture Custom TuNAS Architecture L2 Weight Decay: 0.004 Color Saturation delta: 0.80 perturbations Brightness delta: 0.96 Contrast delta: 0.17 Hue delta: 0.02 Learning rate Exponential decay schedule Exponential decay schedule schedule Base rate: 0.0042 Base rate: 0.0001 Decay rate: 0.95 Decay rate: 0.90 Decay steps: 51,733 steps Decay steps: 25,000 steps RMSProp Decay: 0.95 Decay: 0.95 optimizer Momentum: 0.7 Momentum: 0.7 Epsilon: 0.001 Epsilon: 0.001 Other Image input magnification: Image input magnification: 10X (1 μm/pixel) 5X (2 μm/pixel) Loss function: softmax Loss function: softmax cross-entropy cross-entropy Batch size: 32 Batch size: 16 - All available slides for archived prostate cancer resection cases between 1995 and 2014 in the BioBank Graz at the Medical University of Graz were retrieved, de-identified, and scanned using a Leica Aperio AT2 scanner at 40× magnification (0.25 μm/pixel). Gleason scores were extracted from the original pathology reports, along with pathologic TNM staging, and patient age at diagnosis. Disease-specific survival (DSS) was inferred from International Classification of Diseases (ICD) codes from the Statistik Austria database. Codes considered for prostate-cancer related death were C61 and C68. Institutional Review Board approval for this retrospective study using de-identified slides and associated pathologic and clinical data was obtained from the Medical University of Graz (Protocol no. 32-026
ex 19/20). - Validation set 1 included all available cases from 1995-2014 as discussed above. Because Gleason scoring at the Medical University of Graz was adopted in routine practice from 2000 onwards, validation set 2 included all cases from 2000 onwards for which a Gleason score was available. Sensitivity analysis for inclusion of Gleason grades prior to the year 2000 (before Gleason scoring became routine at the institution) is presented in Table 8 below.
-
TABLE 8 Year of Analysis 2000-2014 1995-2014 No. of Cases 1,517 1,524 A) Pathologist 0.79 [0.71, 0.86] 0.78 [0.71, 0.85] Grade Group B) AI risk score 0.86 [0.81, 0.91] 0.86 [0.81, 0.91] C) AI risk group 0.85 [0.79, 0.90] 0.85 [0.80, 0.90] - All slides underwent manual review by 21 pathologists to confirm stain type and tissue type. Briefly, immunohistochemically stained slides were excluded from analysis and only slides containing primarily prostatic tissue were included. Slides containing exclusively prostatic tissue were included in their entirety. Slides with both prostatic tissue and seminal vesicle tissue were included, but processed using a prostatic tissue model meant to provide only prostatic tissue to the Gleason grading model. All other slides were excluded from analysis.
- The Gleason grading model was run at stride 256 (at 10× magnification, 1 μm per pixel) on all prostate tissue patches. The classification of each patch as non-tumor or
GP Gleason patterns -
TABLE 9 C-index [95% CI] Validation Set 1Validation Set 2 A) LOOCV 0.82 [0.78, 085] 0.85 [0.79, 0.90] B) Temporal Split N/A 0.85 [0.80, 0.90] C) Rule-based 0.80 [0.76, 0.83] 0.84 [0.78, 0.88] -
Gleason pattern 3 percentage was dropped as an input feature to avoid linear dependence between features. Leave-one-case-out cross-validation was used to adjust for optimism, similar to the 10-fold cross validation used in Epstein et al. AI risk groups were derived from the AI risk scores by discretizing the AI risk scores to match the number and frequency of pathologist GG invalidation set 2. - Primary and secondary analyses were pre-specified and documented prior to evaluation on the validation sets. The primary analysis consisted of the comparison of Concordance (C)-indices for DSS between pathologist GG and the AI risk scores, shown in Table 4. The secondary analysis consisted of the comparison between C-indices for pathologist GG and the discretized AI risk groups. All other analyses were exploratory.
- The prognostic performance of the pathologist GG, the AI risk scores and the AI risk group values were measured using Harrel's C-index, a generalization of area under the receiver operating characteristic curve (AUC) for time-censored data. Confidence intervals for both the C-index of AI and pathologists, and the differences between them, were computed via bootstrap resampling with 1000 samples.
- In Kaplan-Meier analysis of the pathologist GG and AI risk groups, the multivariate log-rank test was used to test for differences in survival curves across groups. All survival analysis were conducted using the Lifelines python package39 (version 0.25.4).
- Referring now to
FIG. 10 ,FIG. 10 shows anexample method 1000 for AI prediction of prostate cancer outcomes. The example will be discussed with respect to thesystem 200 shown inFIG. 9 and themodel 10 shown inFIG. 1 ; however, any suitable system according to this disclosure may be employed. - At
block 1010, thecomputing device 210 obtains an images of prostate tissue. In this example, thecomputing device 210 obtains the images from itsdata store 212; however, in some examples, it may obtain the images from animaging system 250 or from aremote server 240 ordata store 242. - At
block 1020, themodel 10 assigns Gleason patterns values to one or more regions within the image. In this example, the model assigns Gleason values of 3, 4, and 5 for the tumor areas of the slide, as discussed above with respect toFIG. 3 . In some examples, themodel 10 may first determine prostate tissue versus non-prostate tissue regions of the image, which may ensure that themodel 10 only determines predictions for prostate tissue. - At
block 1030, thecomputing device 210 determines relative areal proportions of the Gleason patterns, generally as discussed above with respect to block 24 ofFIG. 2 . - At
block 1040, thecomputing device 210 determines a risk score or risk group value based on the areal proportions, generally as discussed above with respect toblocks 30 ofFIG. 2 or 50 ofFIG. 3 , which may involve the use of a Cox proportional hazard regression model fitted to a set of Gleason patterns or proportions thereof assigned to a multitude of images in a data set by the artificial intelligence Gleason grading model and associated survival data associated with the data set. - At
block 1050, thecomputing device 210 receives a Gleason Grade corresponding to the image from a user of thecomputing device 210. For example, the user may be prompted to provide a Gleason Grade. The user-provided Gleason Grade may be combined with the determined risk score or risk group value, generally as discussed above with respect toFIGS. 3 and 4 . It should be appreciated that the functionality ofblock 1050 may be omitted in some examples. - At
block 1060, the risk score or risk group value is provided. For example, the risk score or risk group value (or both, in some examples), may be displayed ondisplay 214, stored indata store 212, stored indata store 242, or otherwise communicated to a pathologist, oncologist, or other medical professional. In some examples, a combined risk score or risk group value may be provided, such as may be generated atblock 1050 in some examples. - Referring now to
FIG. 11 ,FIG. 11 shows anexample computing device 1200 suitable for use in example systems or methods for AI prediction of prostate cancer outcomes according to this disclosure. Theexample computing device 1200 includes aprocessor 1210 which is in communication with thememory 1220 and other components of thecomputing device 1200 using one or more communications buses 1202. Theprocessor 1210 is configured to execute processor-executable instructions stored in thememory 1220 to perform one or more methods for AI prediction of prostate cancer outcomes according to different examples, such as part or all of theexample method 1000 described above with respect toFIG. 10 . In this example, thememory 1220 includes adeep learning system 1260, such as theexample model 10 shown inFIG. 1, 2 , or 8. In addition, thecomputing device 1200 also includes one or moreuser input devices 1250, such as a keyboard, mouse, touchscreen, microphone, etc., to accept user input; however, in some examples, thecomputing device 1200 may lack such user input devices, such as remote servers or cloud servers. Thecomputing device 1200 also includes adisplay 1240 to provide visual output to a user. However, it should be appreciated that user input devices or displays may be optional in some examples. - The
computing device 1200 also includes acommunications interface 1240. In some examples, thecommunications interface 1230 may enable communications using one or more networks, including a local area network (“LAN”); wide area network (“WAN”), such as the Internet; metropolitan area network (“MAN”); point-to-point or peer-to-peer connection; etc. Communication with other devices may be accomplished using any suitable networking protocol. For example, one suitable networking protocol may include the Internet Protocol (“IP”), Transmission Control Protocol (“TCP”), User Datagram Protocol (“UDP”), or combinations thereof, such as TCP/IP or UDP/IP. - While some examples of methods and systems herein are described in terms of software executing on various machines, the methods and systems may also be implemented as specifically-configured hardware, such as field-programmable gate array (FPGA) specifically to execute the various methods according to this disclosure. For example, examples can be implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in a combination thereof. In one example, a device may include a processor or processors. The processor comprises a computer-readable medium, such as a random access memory (RAM) coupled to the processor. The processor executes computer-executable program instructions stored in memory, such as executing one or more computer programs. Such processors may comprise a microprocessor, a digital signal processor (DSP), an application-specific integrated circuit (ASIC), field programmable gate arrays (FPGAs), and state machines. Such processors may further comprise programmable electronic devices such as PLCs, programmable interrupt controllers (PICs), programmable logic devices (PLDs), programmable read-only memories (PROMs), electronically programmable read-only memories (EPROMs or EEPROMs), or other similar devices.
- Such processors may comprise, or may be in communication with, media, for example one or more non-transitory computer-readable media, that may store processor-executable instructions that, when executed by the processor, can cause the processor to perform methods according to this disclosure as carried out, or assisted, by a processor. Examples of non-transitory computer-readable medium may include, but are not limited to, an electronic, optical, magnetic, or other storage device capable of providing a processor, such as the processor in a web server, with processor-executable instructions. Other examples of non-transitory computer-readable media include, but are not limited to, a floppy disk, CD-ROM, magnetic disk, memory chip, ROM, RAM, ASIC, configured processor, all optical media, all magnetic tape or other magnetic media, or any other medium from which a computer processor can read. The processor, and the processing, described may be in one or more structures, and may be dispersed through one or more structures. The processor may comprise code to carry out methods (or parts of methods) according to this disclosure.
- The foregoing description of some examples has been presented only for the purpose of illustration and description and is not intended to be exhaustive or to limit the disclosure to the precise forms disclosed. Numerous modifications and adaptations thereof will be apparent to those skilled in the art without departing from the spirit and scope of the disclosure.
- Reference herein to an example or implementation means that a particular feature, structure, operation, or other characteristic described in connection with the example may be included in at least one implementation of the disclosure. The disclosure is not restricted to the particular examples or implementations described as such. The appearance of the phrases “in one example,” “in an example,” “in one implementation,” or “in an implementation,” or variations of the same in various places in the specification does not necessarily refer to the same example or implementation. Any particular feature, structure, operation, or other characteristic described in this specification in relation to one example or implementation may be combined with other features, structures, operations, or other characteristics described in respect of any other example or implementation.
- Use herein of the word “or” is intended to cover inclusive and exclusive OR conditions. In other words, A or B or C includes any or all of the following alternative combinations as appropriate for a particular usage: A alone; B alone; C alone; A and B only; A and C only; B and C only; and A and B and C.
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US17/453,953 US20220148169A1 (en) | 2020-11-06 | 2021-11-08 | Artificial intelligence prediction of prostate cancer outcomes |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202063110786P | 2020-11-06 | 2020-11-06 | |
US17/453,953 US20220148169A1 (en) | 2020-11-06 | 2021-11-08 | Artificial intelligence prediction of prostate cancer outcomes |
Publications (1)
Publication Number | Publication Date |
---|---|
US20220148169A1 true US20220148169A1 (en) | 2022-05-12 |
Family
ID=81454687
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US17/453,953 Pending US20220148169A1 (en) | 2020-11-06 | 2021-11-08 | Artificial intelligence prediction of prostate cancer outcomes |
Country Status (5)
Country | Link |
---|---|
US (1) | US20220148169A1 (en) |
EP (1) | EP4241198A1 (en) |
JP (1) | JP2023550009A (en) |
CN (1) | CN116324874A (en) |
WO (1) | WO2022099309A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11568539B1 (en) * | 2021-12-30 | 2023-01-31 | Seoul National University Hospital | Apparatus and method for prostate cancer analysis |
US11710034B2 (en) * | 2019-02-27 | 2023-07-25 | Intel Corporation | Misuse index for explainable artificial intelligence in computing environments |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN117727443A (en) * | 2023-12-13 | 2024-03-19 | 南方医科大学珠江医院 | Prediction system and prediction model for prognosis of prostate cancer patient |
Citations (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070019854A1 (en) * | 2005-05-10 | 2007-01-25 | Bioimagene, Inc. | Method and system for automated digital image analysis of prostrate neoplasms using morphologic patterns |
US20130308849A1 (en) * | 2011-02-11 | 2013-11-21 | Emory University | Systems, methods and computer readable storage mediums storing instructions for 3d registration of medical images |
US20140233826A1 (en) * | 2011-09-27 | 2014-08-21 | Board Of Regents Of The University Of Texas System | Systems and methods for automated screening and prognosis of cancer from whole-slide biopsy images |
US20170032090A1 (en) * | 2015-07-30 | 2017-02-02 | Siemens Medical Solutions Usa, Inc. | Virtual biopsy techniques for analyzing diseases |
US20190340468A1 (en) * | 2018-05-07 | 2019-11-07 | Google Llc | Focus-Weighted, Machine Learning Disease Classifier Error Prediction for Microscope Slide Images |
US20190370965A1 (en) * | 2017-02-22 | 2019-12-05 | The United States Of America, As Represented By The Secretary, Department Of Health And Human Servic | Detection of prostate cancer in multi-parametric mri using random forest with instance weighting & mr prostate segmentation by deep learning with holistically-nested networks |
US20200015734A1 (en) * | 2017-12-05 | 2020-01-16 | Rulon Mayer | “One Stop Shop” for Prostate Cancer Staging using Imaging Biomarkers and Spatially Registered Multi-Parametric MRI |
US20200263255A1 (en) * | 2016-10-05 | 2020-08-20 | University Of East Anglia | Classification and prognosis of cancer |
US20210304405A1 (en) * | 2018-08-07 | 2021-09-30 | Deep Bio Inc. | System and method for disease diagnosis using neural network |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DK3303616T3 (en) * | 2015-05-29 | 2021-03-01 | Koninklijke Philips Nv | PROCEDURES FOR PROSTATE PROSTATE CANCER |
WO2019190518A1 (en) * | 2018-03-29 | 2019-10-03 | Google Llc | Similar medical image search |
-
2021
- 2021-11-08 WO PCT/US2021/072277 patent/WO2022099309A1/en active Application Filing
- 2021-11-08 EP EP21890346.6A patent/EP4241198A1/en active Pending
- 2021-11-08 CN CN202180068502.6A patent/CN116324874A/en active Pending
- 2021-11-08 US US17/453,953 patent/US20220148169A1/en active Pending
- 2021-11-08 JP JP2023520048A patent/JP2023550009A/en active Pending
Patent Citations (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070019854A1 (en) * | 2005-05-10 | 2007-01-25 | Bioimagene, Inc. | Method and system for automated digital image analysis of prostrate neoplasms using morphologic patterns |
US20130308849A1 (en) * | 2011-02-11 | 2013-11-21 | Emory University | Systems, methods and computer readable storage mediums storing instructions for 3d registration of medical images |
US20140233826A1 (en) * | 2011-09-27 | 2014-08-21 | Board Of Regents Of The University Of Texas System | Systems and methods for automated screening and prognosis of cancer from whole-slide biopsy images |
US20170032090A1 (en) * | 2015-07-30 | 2017-02-02 | Siemens Medical Solutions Usa, Inc. | Virtual biopsy techniques for analyzing diseases |
US20200263255A1 (en) * | 2016-10-05 | 2020-08-20 | University Of East Anglia | Classification and prognosis of cancer |
US20190370965A1 (en) * | 2017-02-22 | 2019-12-05 | The United States Of America, As Represented By The Secretary, Department Of Health And Human Servic | Detection of prostate cancer in multi-parametric mri using random forest with instance weighting & mr prostate segmentation by deep learning with holistically-nested networks |
US20200015734A1 (en) * | 2017-12-05 | 2020-01-16 | Rulon Mayer | “One Stop Shop” for Prostate Cancer Staging using Imaging Biomarkers and Spatially Registered Multi-Parametric MRI |
US20190340468A1 (en) * | 2018-05-07 | 2019-11-07 | Google Llc | Focus-Weighted, Machine Learning Disease Classifier Error Prediction for Microscope Slide Images |
US20210304405A1 (en) * | 2018-08-07 | 2021-09-30 | Deep Bio Inc. | System and method for disease diagnosis using neural network |
Non-Patent Citations (6)
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11710034B2 (en) * | 2019-02-27 | 2023-07-25 | Intel Corporation | Misuse index for explainable artificial intelligence in computing environments |
US11568539B1 (en) * | 2021-12-30 | 2023-01-31 | Seoul National University Hospital | Apparatus and method for prostate cancer analysis |
Also Published As
Publication number | Publication date |
---|---|
CN116324874A (en) | 2023-06-23 |
WO2022099309A1 (en) | 2022-05-12 |
EP4241198A1 (en) | 2023-09-13 |
JP2023550009A (en) | 2023-11-30 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20220148169A1 (en) | Artificial intelligence prediction of prostate cancer outcomes | |
Zelic et al. | Predicting prostate cancer death with different pretreatment risk stratification tools: a head-to-head comparison in a nationwide cohort study | |
JP5603639B2 (en) | Learning device for prediction device and computer program therefor | |
Corcoran et al. | Underestimation of Gleason score at prostate biopsy reflects sampling error in lower volume tumours | |
Hong et al. | Predicting emergency visits and hospital admissions during radiation and chemoradiation: An internally validated pretreatment machine learning algorithm | |
US8032308B2 (en) | Modeling lung cancer survival probability after or side-effects from therapy | |
Lange et al. | A joint model for multistate disease processes and random informative observation times, with applications to electronic medical records data | |
JP2018504674A (en) | Computational pathology system and method for early cancer prediction | |
Schiller-Frühwirth et al. | Cost-effectiveness models in breast cancer screening in the general population: a systematic review | |
Zhu et al. | Progress on deep learning in digital pathology of breast cancer: a narrative review | |
Marti-Bonmati et al. | Considerations for artificial intelligence clinical impact in oncologic imaging: an AI4HI position paper | |
Zhang et al. | Deep learning-based methods for classification of microsatellite instability in endometrial cancer from HE-stained pathological images | |
EP4002382A1 (en) | Using unstructured temporal medical data for disease prediction | |
Dix et al. | How would MRI-targeted prostate biopsy alter radiation therapy approaches in treating prostate cancer? | |
Wang et al. | External validation of a mammographic texture marker for breast cancer risk in a case–control study | |
Geng et al. | Artificial intelligence neural network analysis and application of CT imaging features to predict lymph node metastasis in non-small cell lung cancer | |
US20220327690A1 (en) | Cad device and method for analysiing medical images | |
Ivy | Can we do better? Optimization models for breast cancer screening | |
Nguyen | Improving Early Prostate Cancer Detection in New Zealand | |
US20220260507A1 (en) | Method and system for analyzing prostate biopsy | |
US20220230728A1 (en) | Methods and apparatus for generating a graphical representation | |
Grootes | The Development of the Prognostic Breast Cancer Model PREDICT | |
US20230113064A1 (en) | Diagnostic system using diffraction analysis of in vitro samples | |
US20230048995A1 (en) | Machine learning analysis techniques for clinical and patient data | |
US20220367062A1 (en) | Prediction tool for patient immune response to a therapy |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: VERILY LIFE SCIENCES LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:GOOGLE LLC;REEL/FRAME:058073/0968Effective date: 20211101Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MERMEL, CRAIG;LIU, YUN;MANOJ, NAREN;AND OTHERS;SIGNING DATES FROM 20210415 TO 20210515;REEL/FRAME:058073/0798 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |