CN113272800A - Predicting review decisions in a matching graph using bayesian inference - Google Patents
Predicting review decisions in a matching graph using bayesian inference Download PDFInfo
- Publication number
- CN113272800A CN113272800A CN201980087180.2A CN201980087180A CN113272800A CN 113272800 A CN113272800 A CN 113272800A CN 201980087180 A CN201980087180 A CN 201980087180A CN 113272800 A CN113272800 A CN 113272800A
- Authority
- CN
- China
- Prior art keywords
- media item
- segment
- prediction value
- tagged
- current media
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/9035—Filtering based on additional data, e.g. user or group profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N7/00—Computing arrangements based on specific mathematical models
- G06N7/01—Probabilistic graphical models, e.g. probabilistic networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
- G06F16/635—Filtering based on additional data, e.g. user or group profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/901—Indexing; Data structures therefor; Storage structures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
Abstract
Implementations disclose methods and systems for predicting review decisions in a matching graph using bayesian inference. One method comprises the following steps: identifying a current media item to be processed; processing the tagged media item to identify a tagged media item that includes at least one corresponding segment that is similar to one of the segments of the current media item; for each of the segments of the current media item, generating a segment prediction value indicative of a particular attribute associated with a corresponding segment of the current media item based on an attribute associated with the corresponding tagged media item, each tagged media item including a corresponding segment that is similar to the corresponding segment; calculating a media item prediction value for the current media item based on the generated segment prediction values for each of the segments of the current media item; and causing the current media item to be processed based on the calculated media item prediction value.
Description
Technical Field
Aspects and implementations of the present disclosure relate to predictive review decisions, and in particular to predictive review decisions for media items.
Background
Media items, such as video items, audio items, and the like, may be uploaded to the media item platform. The media items may be tagged based on the content type of the media item, the appropriateness of the media item, the quality of the media item, and so forth.
Disclosure of Invention
The following presents a simplified summary of the disclosure in order to provide a basic understanding of some aspects of the disclosure. This summary is not an extensive overview of the disclosure. It is intended to neither identify key or critical elements of the disclosure nor delineate any scope of particular implementations of the disclosure or any scope of the claims. Its sole purpose is to present some concepts of the disclosure in a simplified form as a prelude to the more detailed description that is presented later.
Aspects of the present disclosure automatically determine attributes of media items. Bayesian inference can be used to predict the attributes of media items in the matching graph.
In one aspect of the disclosure, a method may include identifying a current media item to be processed, and processing a plurality of tagged media items to identify a tagged media item that includes at least one respective segment that is similar to one of a plurality of segments of the current media item. The method may further include, for each of a plurality of segments of the current media item, generating a segment prediction value indicative of a particular attribute associated with a corresponding segment of the current media item based on an attribute associated with the corresponding tagged media item, each tagged media item including a corresponding segment that is similar to the corresponding segment of the current media item. The method may further include calculating a media item prediction value for the current media item based on the generated segment prediction value for each of the plurality of segments of the current media item, and causing the current media item to be processed based on the calculated media item prediction values.
Each of the tagged media items may be assigned a respective tag; and each of the plurality of segments of the current media item may at least partially match one or more segments of the tagged media item. Generating a segment prediction value for a corresponding segment for each of a plurality of segments of the current media item may be based on a plurality of parameters including at least one of a length of the corresponding segment, a length of the current media item, or a length of a respective tagged media item, each tagged media item including a respective segment similar to the corresponding segment of the current media item. The method may further comprise: determining that a first segment of the current media item matches a first corresponding segment of the first tagged media item; determining that a second segment of the current media item matches a second corresponding segment of the second tagged media item; determining that the first segment is a sub-segment of a second segment, wherein the second segment comprises the first segment and a third segment, wherein generating a segment predictor for each of the plurality of segments comprises: generating a first segment prediction value indicative of a first label of the first segment based on a first respective label of the first tagged media item and a second respective label of the second tagged media item; and generating a second segment prediction value indicative of a second label for the third segment based on a second corresponding label for the second tagged media item, wherein calculating the media item prediction value is based on the generated first segment prediction value and the generated second segment prediction value. Causing the current media item to be processed may comprise one of: in response to the calculated media item prediction value satisfying a first threshold condition, causing playback of the current media item via the media item platform to be prevented; in response to the calculated media item prediction value satisfying a second threshold condition, causing playback of the current media item via the media item platform to be permitted; and in response to the calculated media item prediction value satisfying a third threshold condition, causing the current media item to be reviewed to generate a tag indicating whether playback of the current media item via the media item platform is permitted. A segment prediction value for each of a plurality of segments is generated based on a plurality of parameters and one or more weights associated with one or more of the plurality of parameters. The method may further include adjusting one or more weights based on the generated tags for the current media item. The adjusting of the one or more weights comprises: training a machine learning model to provide adjusted one or more weights based on the tuning input and a target tuning output for the tuning input; for each of a plurality of segments of the current media item, the tuning input contains a length of the corresponding segment, a length of the current media item, and a length of a respective tagged media item, each respective tagged media item including a respective segment that is similar to the corresponding segment of the current media item; and the tuning target output for the tuning input contains a generated tag for the current media item.
It will be appreciated that the aspects may be implemented in any convenient form. For example, the various aspects may be implemented by means of a suitable computer program which may be carried on a suitable carrier medium which may be a tangible carrier medium (e.g. a diskette) or an intangible carrier medium (e.g. a communications signal). Aspects may also be implemented using suitable apparatus in the form of a programmable computer running a computer program arranged to implement the invention. Various aspects may be combined such that features described in the context of one aspect may be implemented in another aspect.
Drawings
In the drawings, the present disclosure is illustrated by way of example and not by way of limitation.
Fig. 1 is a block diagram illustrating an exemplary system architecture according to an implementation of the present disclosure.
Fig. 2 is an exemplary tuning set generator that creates tuning data for a machine learning model according to an implementation of the present disclosure.
3A-D are flow diagrams illustrating an exemplary method of predicting a review decision for a media item according to an implementation of the present disclosure.
4A-B are tables illustrating review decisions for predictive media items according to implementations of the present disclosure.
FIG. 5 is a block diagram illustrating one implementation of a computer system according to an implementation of the present disclosure.
Detailed description of the invention
Aspects and implementations of the present disclosure relate to automatically determining attributes of media items, such as review decisions in predictive matching graphs, using bayesian inference. The server device may receive the media item uploaded by the user device. The server device may make the media item playable by these or other user devices via the media item platform. In response to a user marking a media item (e.g., during playback) as having a certain type of content, the server device can submit the media item for review (e.g., manual review). During review, a user (e.g., an administrator of the media item platform) can perform playback of the media item and can mark the media item. Based on the tags from the reviews, the server can associate the media item with the tag. The tags may indicate that the media item has an inappropriate content type, infringes the rights, has technical issues, has a rating, is appropriate for advertising, and so forth.
The server device may perform different actions for the media item based on the tag of the media item. For example, media items marked as containing inappropriate content types (e.g., having a "negative review" tag) may be prevented from being played. Alternatively, media items marked as not containing inappropriate content types (e.g., having a "positive review" tag) may be allowed to be played. In another example, based on the tags of the media items, advertisements may be included during playback of the tag-based media items. In yet another example, a message may be transmitted to a user device that uploaded a media item that is flagged as having a technical issue.
The newly uploaded media item may at least partially match the tagged media item. Typically, each newly uploaded media item is typically tagged, submitted to a manual review, and tagged based on the manual review (e.g., whether the media item matches the tagged media item). In general, reviewing a first media item that at least partially matches a tagged media item may require the same amount of time and resources (e.g., processor overhead, bandwidth, power consumption, available human reviewers, etc.) as reviewing a second media item that at least partially does not match the tagged media item. Reviewing the media item before it is allowed to be available for play may take a long time and may require peak required resources (e.g., high processor overhead, power consumption, and bandwidth). Allowing the media item to be available for playback prior to reviewing the media item may allow playback of media items that include problematic and inappropriate content. Incorrectly tagging media items may require time and resources to correct.
Aspects of the present disclosure address the above and other challenges by automatically determining attributes of media items (e.g., using bayesian inference to predict review decisions in a matching graph). The processing device may identify a current media item (e.g., a newly uploaded media item) to process, and may identify a tagged media item (e.g., a previously reviewed media item) for a tagged media item that includes at least one corresponding segment that is similar to one of the segments of the current media item (e.g., a match graph may be created that includes tagged media items that match at least a portion of the current media item). For each of the segments of the current media item (e.g., segments similar to at least a portion of the tagged media item), the processing device may generate a segment prediction value that indicates a particular attribute associated with the corresponding segment of the current media item (e.g., based on attributes associated with tagged media items having respective segments similar to the corresponding segment of the current media item, based on the match map). The processing device may calculate a media item prediction value based on the generated segment prediction value for each of the segments of the current media item and may cause the current media item to be processed based on the calculated media item prediction values. For example, based on the media item prediction value, playback of the current media item via the media item platform may be allowed or blocked, or the current media item may be caused to be reviewed to generate a tag for the current media item that indicates whether playback of the current media item is allowed.
As disclosed herein, automatically generating attributes (e.g., predictive review decisions) for media items is advantageous because it improves the user experience and provides technical advantages. Many newly uploaded media items may have segments similar to tagged (e.g., previously reviewed) media items. By performing initial processing to select a media item for further processing, assigning attributes to the media item may be performed more efficiently, and fewer media items may be required for further processing. Thus, processing a newly uploaded media item based on the calculated media item prediction value (e.g., based on a tagged media item that at least partially matches the newly uploaded media item) can reduce processor overhead, required bandwidth, and energy consumption, regardless of whether the media item at least partially matches a previously tagged media item, as compared to performing the same process to tag any media item. Allowing or preventing play of newly uploaded media items based on the calculated media item prediction values may allow faster processing of the media items and thus may provide a better user experience than providing all newly uploaded media items for play and only preventing play after the user marks the media items and subsequent manual review marks the media items. Generating media item prediction values for uploaded media items may be beneficial to users uploading media items and to users of the media item platform. For example, in response to generating a media item prediction value indicating a technical issue, an indication based on the media item prediction value may be transmitted to a user of the media item to alert the user that the media item has a technical issue (e.g., suggest modifying the media item). In another example, in response to generating media item prediction values for media items, the media items may be processed such that the media items are tagged (e.g., age, category, etc.) to improve search results and suggestions for users of the media item platform.
Fig. 1 illustrates an exemplary system architecture 100 in accordance with implementations of the present disclosure. The system architecture 100 includes a media item server 110, a user device 120, a prediction server 130, a content owner device 140, a network 150, and a data store 160. The prediction server 130 may be part of the prediction system 105.
The media item server 110 can include one or more computing devices (such as a rack-mounted server, a router computer, a server computer, a personal computer, a mainframe computer, a laptop computer, a tablet computer, a desktop computer, etc.), data stores (e.g., hard disks, memory, databases, etc.), networks, software components, and/or hardware components. The media item server 110 may be used to provide a user with access to media items 112 (e.g., media items that have been tagged ("tagged media items" 114), media items that are currently undergoing a tagging process ("current media items" 116), etc.). The media item server 110 can provide the media item 112 to the user (e.g., the user can select the media item 112 and download the media item 112 from the media item server 110 in response to a request or purchase of the media item 112). The media item server 110 can be part of a media item platform (e.g., a content hosting platform that provides content hosting services) that can allow users to consume, develop, upload, download, rate, mark, share, search, approve ("like"), dislike, and/or comment on the media item 112. The media item platform may also include a website (e.g., a web page) or application backend software that may be used to provide users with access to the media items 112.
The media item 112 may be consumed via a web browser on the user device 120 or via a mobile application program ("app") that may be installed on the user device 120 via an app store. The web browser or mobile application may allow the user to perform one or more searches (e.g., for explanatory information, for other media items 112, etc.). As used herein, an "application," "mobile application," "smart television application," "desktop application," "software application," "digital content," "content item," "media item," "video item," "audio item," "contact invitation," "game," and "advertisement" may comprise an electronic file that may be executed or loaded using software, firmware, or hardware configured to present the media item 112 to an entity. In one implementation, the media item platform may use the data store 160 to store the media item 112. The media item 112 may be presented to a user of the user device 120 or downloaded by a user of the user device 120 from a media item server 110 (e.g., a media item platform such as a content hosting platform). The media items 112 may be played via an embedded media player (as well as other components) provided by the media item platform or stored locally. The media item platform may be, for example, an application distribution platform, a content hosting platform, or a social networking platform, and may be used to provide users with access to the media items 112 or to provide users with the media items 112. For example, the media item platform may allow users to consume, denote, upload, search, approve ("like"), dislike, and/or comment on the media item 112. The media item server 110 can be part of a media item platform, can be a stand-alone system, or can be part of a different platform.
The data store 160 can be a memory (e.g., random access memory), a drive (e.g., hard drive, flash drive), a database system, or another type of component or device capable of storing data. The data store 160 can include multiple storage components (e.g., multiple drives or multiple databases) that can span multiple computing devices (e.g., multiple server computers). In some implementations, the data store 160 can store information 162 associated with media items, tags 164, or prediction values 166 (e.g., segment prediction values 168, media item prediction values 169). Each of the tagged media items 114 may have a corresponding tag 164. Each of the tagged media items 114 may have been tagged (e.g., by a user during playback via a machine learning model trained with image input and tag output). Each of the media items 112 may have corresponding information 162 (e.g., total length, length of each segment, media item identifier, etc.).
The user device 120 and the content owner device 140 may include computing devices such as Personal Computers (PCs), laptops, mobile phones, smart phones, tablets, netbooks, network-connected televisions ("smart televisions"), network-connected media players (e.g., blu-ray players), set-top boxes, television-box (OTT) streaming devices, operation boxes, and so forth.
Each user device 120 may include an operating system that allows a user to perform the playing of the media item 112 and the marking of the media item 112. The media items 112 may be presented via a media viewer or web browser. A web browser may access, retrieve, render, and/or navigate content (e.g., web pages such as hypertext markup language (HTML) pages, digital media items, text conversations, notifications, etc.) served by a web server. An embedded media player (e.g.,
The user device 120 can include one or more of a play component 124, an indication component 126, and a data store 122. In some implementations, one or more of the play component 124 or the mark-up component 126 can be provided by a web browser or application (e.g., mobile application, desktop application) executing on the user device 120.
The data store 122 can be a memory (e.g., random access memory), a drive (e.g., hard drive, flash drive), a database system, or another type of component or device capable of storing data. The data store 122 can include multiple storage components (e.g., multiple drives or multiple databases) that can span multiple computing devices (e.g., multiple server computers). The data store 122 can include a media item cache 123 and a markup cache 125.
The play component 124 can provide for the playing of the media item 112 via the user device 120. Playback of the media item 112 can be in response to the playback component 124 receiving a user input (via a Graphical User Interface (GUI) displayed by a user device) requesting playback of the media item 112 and transmitting the request to the media item server 110. In some implementations, the media item server 110 can stream the media item 112 to the user device 120. In some implementations, the media item server 110 can transmit the media item 112 to the user device 120. The play component 124 can store the media item 112 in the media item cache 123 for play at a later point in time (e.g., subsequent play regardless of connectivity to the network 150).
The designation component 126 can receive user input (e.g., via a GUI during playback of the media item 112) to designate the media item 112. The media items 112 may be labeled as one or more types of content. The user input may indicate the type of content (e.g., by selecting the type of content from a list). Based on the user input, the tagging component 126 can tag the media item 112 as having an inappropriate content type (e.g., including one or more of sexual content, violent or repugnant content, hate or mashup content, harmful dangerous behavior, abusing children, pronouncing terrorism, spam or misleading, etc.), infringing rights, having technical issues (e.g., caption issues, etc.), having ratings (e.g., age-appropriate ratings, etc.), being suitable for advertising, etc. The designation component 126 can communicate an indication to one or more of the prediction system 105, the prediction server 130, the data store 160, and the like that the media item 112 has been designated.
In response to being flagged, the media item 112 may be flagged (e.g., by manual review) to generate a flagged media item 114. Information 162 associated with the tagged media item 114 and a tag 164 may be stored with the tagged media item 114 in the data store 160. Alternatively, the tagged media item 114 may be stored in a separate data store and associated with the information 162 and tag 164 via a media item identifier.
The content owner device 140 can include a transmission component 144, a reception component 146, a modification component 148, and a data store 142.
The data store 142 can be a memory (e.g., random access memory), a drive (e.g., hard drive, flash drive), a database system, or another type of component or device capable of storing data. The data store 142 may include multiple storage components (e.g., multiple drives or multiple databases) that may span multiple computing devices (e.g., multiple server computers). The data store 142 may include a media item cache 143.
The transmission component 144 may receive media items 112 created, modified, uploaded, or otherwise associated by a content owner corresponding to the content owner device 140. The transfer component 144 can store the media item 112 in the media item cache 143. The transmission component 144 may transmit (e.g., upload) the media item 112 to the media item server 110 (e.g., in response to a content owner input to the above media item 112).
The receiving component 146 can receive an indication from the prediction server 130 based on the media item prediction value 169 (e.g., generated by the prediction manager 132). The receiving component 146 may store the indication in the data store 142.
The modification component 148 may modify the media item 112 based on the indication based on the media item prediction value 169. For example, in response to an indication based on the media item prediction value 169 that indicates that the content of the media item 112 is inappropriate or has a technical issue (e.g., an error in subtitles, etc.), the modification component 148 can cause the content of the media item 112 to be modified (e.g., remove inappropriate content, fix the technical issue). In some implementations, to cause the content to be modified, the modification component 148 can provide an indication or recommendation to the content owner via the GUI of how to modify the content. In some implementations, to cause the content to be modified, the modification component 148 can automatically modify the content (e.g., fix technical issues, remove inappropriate content, etc.).
The prediction server 130 can be coupled to the user device 120 and the content owner device 140 via a network 150 to facilitate review decisions for the predicted media items 112. In one implementation, prediction server 130 may be part of a media item platform (e.g., media item server 110 and prediction server 130 may be part of the same media item platform). In another implementation, the prediction server 130 may be a standalone platform, including one or more computing devices, such as a rack server, router computer, server computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer, etc., and may provide review decision prediction services that may be used by a media item platform and/or various other platforms (e.g., social networking platform, online news platform, messaging platform, video conferencing platform, online conferencing platform, etc.).
The prediction server 130 may include a prediction manager 132. According to some aspects of the present disclosure, the prediction manager 132 may identify a current media item 116 (e.g., a newly uploaded media item) to process (e.g., automatically evaluated without user input based on, for example, an indication provided by the designation component 126), and may process the tagged media item 114 to find a tagged media item 114 that includes at least one corresponding segment that is similar to one of the segments of the current media item (e.g., generate a matching graph of the tagged media item 114). For each of the segments of the current media item 116 (e.g., at least partially matching the tagged media item 114), the prediction manager 132 may generate a segment prediction value 168 that indicates a particular attribute associated with the corresponding segment of the current media item 116 (e.g., based on the matching graph based on attributes associated with the respective tagged media item 114 that teach a respective segment that includes a corresponding segment that is similar to the corresponding segment of the current media item 116). The prediction manager 132 may calculate a media item prediction value 169 for the current media item 116 based on the generated segment prediction value 168 for each of the segments of the current media item 116, and may process the current media item 116 based on the calculated media item prediction values 169. In some implementations, the prediction manager (e.g., via the trained machine learning model 190, the machine learning model 190 without training) can use bayesian inference to predict review decisions (e.g., media item prediction values 169) in the matching graph (e.g., based on tagged media items 114 that at least partially match the current media item 116, based on the table 400A of fig. 4A, etc.).
In response to the media item prediction value 169 (e.g., indicating that the current media item 116 has inappropriate content or has technical issues), the prediction manager 132 may cause the current media item 116 to be blocked from being available for play via the media item platform. The prediction manager 132 may transmit an indication to the media item platform (or any other platform) or directly to the content owner device 140 indicating the determined attributes of the current media item 116 based on the media prediction value 169. The content owner device 140 may receive an indication (e.g., from the media item platform or from the prediction manager 132), cause the current media item 116 to be modified based on the indication, and re-upload the modified current media item (e.g., to the media item server 110, the prediction server 130, or the media item platform).
In some implementations, the prediction manager 132 may use a trained machine learning model 190 to determine the media item prediction values 169. Prediction system 105 may include one or more of prediction server 130, server machine 170, or server machine 180. Server machine 170 and 180 may be one or more computing devices (such as a rack server, router computer, server computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer, etc.), data storage (e.g., hard disk, memory, database, etc.), networks, software components, or hardware components.
The server machine 170 includes a tuning set generator 171 that is capable of generating tuning data (e.g., a set of tuning inputs and a set of target outputs) to train the machine learning model. The server machine 180 includes a tuning engine 181 that can train a machine learning model 190 using tuning data from the tuning set generator 171. The machine learning model 190 may be trained using tuning inputs 210 and target outputs 220 (e.g., target tuning outputs) described herein (see fig. 2 and 3C). The trained machine learning model 190 may then be used to determine media item prediction values 169. The machine learning model 190 may refer to a model artifact created by the tuning engine 181 using tuning data that includes tuning inputs and corresponding target outputs (correct answers to the respective tuning inputs). Patterns (correct answers) that map tuning inputs to target outputs may be found in the tuning data and a machine learning model 190 that captures these patterns is provided. The machine learning model 190 may include parameters 191 (e.g., k, f, g, configuration parameters, hyper-parameters, etc.) that may be tuned (e.g., associated weights may be adjusted) based on subsequent labels of the current media item 116 for which the media item prediction values 169 are determined. In some implementations, the parameters 191 include one or more of k, f, or g, as described below. In some implementations, the parameter includes at least one of a length of the corresponding segment of the current media item 116, a length of the current media item 116, or a length of the respective tagged media item 114 (e.g., each including a respective segment similar to the corresponding segment of the current media item 116).
The prediction manager 132 may determine information associated with the current media item 116 (e.g., the length of the current media item 116, the length of a segment of the current media item 116 that is similar to a corresponding segment of the tagged media item 114), and information associated with the tagged media item 114 (e.g., the length of the tagged media item 114), and provide the information to the trained machine learning model 190. The trained machine learning model 190 may produce an output, and the prediction manager 132 may determine the media item prediction value 169 from the output of the trained machine learning model. For example, the prediction manager 132 may extract the media item prediction values 169 from the output of the trained machine learning model 190 and may extract confidence data from the output indicating a confidence level that the current media item 116 contains the type of content indicated by the media item prediction values 169 (e.g., a confidence level that the media item prediction values 169 accurately predict manual review decisions).
In implementations, the confidence data can include or indicate a confidence level that the current media item 116 has a particular attribute (e.g., contains a content type). In one example, the confidence level is a real number between 0 and 1, where 0 indicates that the current media item 116 is not believed to have the particular type of content and 1 indicates that the current media item 116 is absolutely believed to have the particular type of content.
Also as described above, for purposes of illustration and not limitation, aspects of the present disclosure describe using information 162 associated with media items 112 to train machine learning model 190 and using the trained machine learning model 190. In other implementations, a heuristic model or a rule-based model is used to determine the media item prediction value 169 for the current media item 116. It may be noted that any of the information described with reference to tuning input 210 of FIG. 2 may be monitored or otherwise used in a heuristic or rule-based model.
It should be noted that in some other implementations, the functionality of server machine 170, server machine 180, prediction server 130, or media item server 110 may be provided by a fewer number of machines. For example, in some implementations, server machines 170 and 180 may be integrated into a single machine, while in some other implementations, server machine 170, server machine 180, and prediction server 130 may be integrated into a single machine. Additionally, in some implementations, one or more of server machine 170, server machine 180, and prediction server 130 may be integrated into media item server 110.
In general, the functions described in one implementation as being performed by media item server 110, server machine 170, server machine 180, or prediction server 130 may also be performed on user device 120 in other implementations, as appropriate. For example, media item server 110 may stream media item 112 to user device 120 and may receive user input indicating a designation of media item 112.
In general, functions described as being performed on user device 120 in one implementation may also be performed by media item server 110 or prediction server 130 in other implementations, as appropriate. For example, media item server 110 may stream media item 112 to user device 120 and may receive an indication of media item 112.
In addition, the functionality attributed to a particular component may be performed by different or multiple components operating together. The media item server 110, server machine 170, server machine 180, or prediction server 130 may also be accessed as a service provided to other systems or devices through an appropriate Application Programming Interface (API), and thus is not limited to use in websites and applications.
In implementations of the present disclosure, a "user" may be represented as a single individual. However, other implementations of the present disclosure include "users" that are entities controlled by a group of users and/or automated sources. For example, a group of individual users that are joined as a community in a social network may be considered a "user". In another example, the automated consumer may be an automated ingestion pipeline of the application distribution platform.
Although implementations of the present disclosure are discussed in terms of media item server 110, prediction server 130, and media item platforms, implementations may generally be applied to any type of platform that provides a connection between content and a user.
In addition to the above, the user may be provided with controls that allow the user to select whether and when the systems, programs, or features described herein are capable of collecting user information (e.g., information about the user's social network, social behavior or activity, profession, user preferences, or the user's current location), and whether to send content or communications to the user from a server (e.g., media item server 110 or prediction server 130). In addition, certain data may be processed in one or more ways prior to storage or use in order to eliminate personally identifiable information. For example, the identity of the user may be processed such that no personal identity information can be determined for the user, or the geographic location of the user (such as at a city, zip code, or state level) may be summarized where location information is obtained such that no particular location of the user can be determined. Thus, the user may have control over what information is collected about the user, how the information is used, and what information is provided to the user.
Fig. 2 is an example tuning set generator that uses information to create tuning data for a machine learning model according to an implementation of the present disclosure. System 200 shows a tuning set generator 171, a tuning input 210, and a target output 220 (e.g., a target tuning output). As described with reference to fig. 1, system 200 may include similar components as system 100. The components described with reference to the system 100 of fig. 1 may be used to help describe the system 200 of fig. 2.
In an implementation, tuning set generator 171 generates tuning data that includes one or more tuning inputs 210 and one or more target outputs 220. The tuning data may also include mapping data that maps the tuning input 210 to the target output 220. Tuning input 210 may also be referred to as a "feature," "attribute," or "information," in some implementations, tuning set generator 171 may provide tuning data in a tuning set used to train machine learning model 190 and provide the tuning set to tuning engine 181. Some implementations of generating a tuning set may be described with further reference to fig. 3C.
In one implementation, the tuning input 210 may include information 162 associated with the current media item 116 and one or more tagged media items 114, the tagged media items 114 including at least one corresponding segment that is similar to one of the segments of the current media item 116. For the current media item 116, the information 162 may include a length 212A of a segment 214A of the current media item 116, a length 212B of a segment 214B of the current media item 116, and so on (hereinafter length 212 of segment 214), and a length 216 of the current media item 116. For each tagged media item 114, the information 162 may include a length 218 of the tagged media item 114.
In an implementation, the target output 220 may include the generated tags 164 of the current media item 116. In some implementations, the generated tags 164 may have been generated by manual review of the current media item 116. In some implementations, the generated tags 164 may have been generated by an automatic review of the current media item 116.
In some implementations, subsequent to generating a tuning set and using the tuning set to train the machine learning model 190, the machine learning model 190 may be further trained (e.g., additional data for the tuning set) or adjusted (e.g., adjustment weights for the parameters 191) using the generated tags 164 for the current media item 116.
3A-D depict flowcharts of illustrative examples of methods 300, 320, 340, and 360 of predicting a review decision for a media item according to implementations of the present disclosure. Methods 300, 320, 340, and 360 are exemplary methods from the perspective of prediction system 105 (e.g., one or more of server machine 170, server machine 180, or prediction server 130) (e.g., and/or media item platform or media item server 110). The methods 300, 320, 340, and 360 may be performed by a processing device that may comprise hardware (e.g., circuitry, dedicated logic), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both. Each of the methods 300, 320, 340, and 360 and their individual functions, routines, subroutines, or operations may be performed by one or more processors of a computer device that performs the method. In particular implementations, each of methods 300, 320, 340, and 360 may be performed by a single processing thread. Alternatively, each of the methods 300, 320, 340, and 360 may be performed by two or more processing threads, each thread performing one or more individual functions, routines, subroutines, or operations of the method.
For simplicity of explanation, the methodologies of the present disclosure are depicted and described as a series of acts. However, acts in accordance with this disclosure may occur in various orders and/or concurrently, and with other acts not presented and described herein. Moreover, not all illustrated acts may be required to implement a methodology in accordance with the disclosed subject matter. In addition, those skilled in the art will understand and appreciate that the methodologies could alternatively be represented as a series of interrelated states via a state diagram or events. Additionally, it should be appreciated that the methodologies disclosed herein are capable of being stored on an article of manufacture to facilitate transporting and transferring such methodologies to computing devices. The term "article of manufacture" as used herein is intended to encompass a computer program accessible from any computer-readable device or storage media. For example, a non-transitory machine-readable storage medium may store instructions that, when executed, cause a processing device (e.g., prediction system 105, media item server 110, user device 120, prediction server 130, content owner device 140, server machine 170, server machine 180, media item platform, etc.) to perform operations comprising the methods disclosed herein. In another example, a system includes a memory to store instructions and a processing device communicatively coupled to the memory that executes the instructions to perform the method disclosed herein. In one implementation, the methods 300, 320, 340, and 360 may be performed by the prediction system 105 of fig. 1.
Referring to fig. 3A, a method 300 may be performed by one or more processing devices of the prediction server 130 for predicting review decisions for a media item. Method 300 may be performed by an application or background thread executing on one or more processing devices on prediction server 130. In some implementations, one or more portions of method 300 may be performed by one or more of prediction system 105, media item server 110, prediction server 130 (e.g., prediction manager 132), or a media item platform.
At block 302, the processing device identifies the current media item 116 to be processed. For example, the current media item 116 may have been uploaded by the content owner device 140 to be available for play via the media item platform. In some implementations, the current media item 116 has been previously reviewed (e.g., associated with the tag 164), and the current media item 116 is identified as undergoing further processing (e.g., via the method 300) to update or confirm the tag 164. In some implementations, the media item 116 has been tagged (e.g., by the user device 120 during playback, by a machine learning model trained with images and tags 164), and the current media item 116 is identified as undergoing further processing (e.g., via the method 300). In some implementations, the current media item 116 is the next media item in the queue of media items to be processed.
At block 304, the processing device processes the tagged media item 114 to identify a tagged media item that includes at least one corresponding segment that is similar to (e.g., matches, is substantially the same as) one of the segments of the current media item 116. For example, the frame of the current media item 116 may be compared to the frame of the tagged media item 114 (e.g., the frame of the current media item 116 is compared to an index of the frame of the tagged media item 114). The processing device may determine that the first segment of the tagged media item 114 and the second segment of the current media item 116 are similar (e.g., match, substantially similar) even though one of the segments has a boundary or frame, and/or is inverted, and/or is accelerated or decelerated, and/or is static, and/or has a different quality, etc. The processing device may determine that at least a portion of the frame or audio segment of the current media item 116 matches at least a portion of the frame or audio segment of the tagged media item 114. The processing device may identify segments of the current media item 116, where each segment at least partially matches one or more segments of the tagged media item 114. The processing device may divide the current media item 116(V) into segments (S) (e.g., V ═ S)1+...+Sk) Where adjacent segments belong to different clusters or do not belong to a cluster.
At block 306, for each segment of the current media item 116, the processing device generates a segment prediction value 168 indicating a particular attribute associated with the corresponding segment of the current media item 116 based on the attribute associated with the respective tagged media item 114. The processing device may combine a positive prediction (e.g., the segment is similar to the one or more tagged media items having a "positive review" tag) with a negative prediction (e.g., the segment is also similar to the one or more tagged media items having a "negative review" tag). Determining that a segment is similar to one or more tagged media items having a "positive review" label (labeled "good") and one or more media items having a "negative review" label (labeled "bad") can be referred to as determining a match graph for the segment. Bayesian inference can be used to predict a review decision (e.g., media item prediction value 169 based on the segment prediction value 168) for the current media item 116 in a matching graph (e.g., having one or more segments similar to the corresponding segment of the tagged media item 114).
For media item (V), the following values may be used (e.g., based on table 400A of FIG. 4A):
These values (e.g., via bayesian formulas) can be connected by the following equation:
this equation can be verified by using the values in table 400A:
20/21＝24/100*20/24*100/21
the method 300 can predict the media item prediction value 169 (e.g., whether the predicted media item should have a "positive review" tag or a "negative review" tag) based on the tags 164 (event E) that tag the media item 114 (e.g., represented as a previous reviewer decision for event E). If the media item contains disjoint segments S1、...、SkThe probability that media item V should have a "positive review" tag is the product of the probabilities of the segments:
media item 112 is marked as not containing a content type only if each segment of media item 112 does not contain a content type (e.g., media item 112 has a "positive review" tag only if each portion of media item 112 has a "positive review" tag). If there is no evidence, the equation also holds:
whereinparameter 191, the probability that any media item should have a "negative review" tag in the absence of information). Under the assumption that the (previous) probability that a media item 112 containing a content type (e.g., a media item 112 having a "negative review" tag) is independent of the length of the media item 112, the (previous) probability that a segment of the current media item 116 (e.g., the media item 112 under consideration) contains a content type (e.g., has a "negative review" tag) decreases exponentially with the fractional length of the segment. The shorter the segment of the current media item 116 (e.g., the corresponding segment that matches the tagged media item 114 having a "negative review" tag), the lower the probability that the current media item 116 should have a "negative review" tag.
Tagged media item 116 that is tagged as containing a content type (e.g., having a "negative review" tag) can be referred to as media item a, and tagged media item 116 that is tagged as not containing a content type (e.g., having a "positive review" tag) can be referred to as media item O.
The segment (S) of the current media item 116(V) may be similar to (e.g., match) the tagged media item 114(a) that has been tagged as containing a content type (e.g., both V and a contain S).
wherein f is a constant factor
In response to the tagged media item 114 being tagged as not containing a content type (e.g., having a "positive review" tag), all segments of the tagged media item 114 also do not contain a content type (e.g., also having a "positive review" tag). For long media items 112, it is unlikely that the reviewer will consider all of the media items 112 (e.g., without a signal indicating that the reviewer should consider all of the media items 112).
The constant g may be specific to the tagged media item (O). Based on the segment similar to the tagged media item 114 that is tagged as containing a content type, the probability (x) that the segment (S) does not contain a content type (e.g., x is based on the probability that S should have a "positive review" tag if it is a "negative review" tag) can be represented by the following equation:
based on the segment of the tagged media item 114 being tagged as not containing a content type, the probability (y) that the segment (S) contains a content type (e.g., the probability that S should have a "negative review" tag if y is based on a "positive review" tag) can be represented by the following equation:
these probabilities may be combined based on table 400B of fig. 4B. There are two separate pieces of evidence and four possibilities, two of which (e.g., the shaded cells of table 400B) may be excluded.
The resulting probability that a segment (S) does not contain a content type (e.g., has a particular attribute associated with tag 164, the resulting probability that S should have a "positive review" tag) can be shown by the following equation:
if the prediction is the same (i.e., if x ═ 1-y), the equation reduces to x2/(x2+(1-x)2) (e.g., sigmoid function). If y is 1/2, the equation reduces to
In the absence of a segment (S) similar to the tagged media item 114 that is tagged as not containing a content type (e.g., in the absence of a "positive review" tag), the prior probability of the assumption that the segment (S) contains a content type (e.g., should have a "negative review" tag) may be half (e.g.,
In some implementations, for each segment Si, there is a review
wherein
(factor 1/2 in y comes from the combination of the "Positive review" tag and the "negative review" tag, which is neutral)
And make
If not reviewed, this reduces to k | SiI/V I. In other implementations, the x and y probabilities based on the "positive review" tag and the "negative review" tag can be combined in other ways.
At block 308, the processing device calculates a media item prediction value 169 (e.g., a combined probability) for the current media item 116 based on the generated segment prediction values 168 for each segment of the current media item 116. The segment prediction values 168 may be combined into a media item prediction value 169 for the entire current media item 116 by the following equation:
in some implementations, the media item prediction value 169 may indicate a probability that the current media item 116 does not contain a type of content or attribute (e.g., a probability that a "positive review" tag should be had). For example, the media item prediction value 169 may indicate that the current media item 116 does not contain a type of content or attribute with a 90% probability. In some implementations, the segment prediction values 168 and the media item prediction values 169 may be scores that indicate relative probabilities of containing content or attribute types. For example, a first media item prediction value for a first current media item may indicate a greater final score, and a second media item prediction value for a second current media item may indicate a lesser final score. A relatively larger final score indicates that the first current media item is more likely to contain the content type than the second current media item. In some implementations, the segment prediction values 168 are multiplied together to calculate a media item prediction value 169. In some implementations, the segment predictors 168 are combined using one or more other operations (e.g., instead of multiplication, in conjunction with multiplication, etc.). In some implementations, the segment prediction values 168 are combined with previous prediction values (e.g., probabilities or scores generated by previous reviews of the current media item 116) of the current media item 116 via one or more operations (e.g., multiplication, etc.).
In an example, at block 304, the processing device may determine that a first segment (e.g., 0-15 seconds) of the current media item 116 matches a first corresponding segment of the first tagged media item 114A, that a second segment (e.g., 0-30 seconds) of the current media item 116 matches a second corresponding segment of the second tagged media item 114B, and that the first segment is a sub-segment of the second segment. The second segment of the current media item 116 may include the first segment and the third segment of the current media item 116. At block 306, the processing device may process the first segment based on the first respective tag 164A of the first tagged media 114A item and the second respective tag 164B of the second tagged media item 114B (e.g., generate a first segment prediction value indicative of a first tag of the first segment). At block 306, the processing device may process the second segment based on the second corresponding tag 164B of the second tagged media item 114B (e.g., generate a second segment prediction value indicative of the second tag of the first segment). At block 308, the processing device may calculate a media item prediction value 169 based on the generated first segment prediction value 168 and the generated second segment prediction value 168.
At block 310, the processing device causes the current media item 116 to be processed based on the media item prediction value 169. For example, the processing device may provide the media item prediction value 169 (or information about the media item prediction value 169) to the media item platform to initiate processing of the current media item 116. Alternatively, the processing device itself may perform the processing of the current media item 116 based on the media item prediction value 169. In some implementations, processing of the current media item 116 includes applying a policy (e.g., preventing play, applying play, sending for review, etc.) to the current media item 116 based on the media item prediction value 169. In some implementations, the processing of the current media item 116 based on the media item prediction value 169 is illustrated by FIG. 3B. In some implementations, the processing device may associate one or more media items (e.g., advertisements, interstitial media items) with the playing of the current media item 116 (e.g., such that the playing of additional media items is in conjunction with the playing of the current media item 116). In some implementations, the processing device may cause an indication to be transmitted to the content owner device 140 associated with the current media item 116 based on the media item prediction value 169 (e.g., indicating a problem with the current media item 116, etc.). In some implementations, the processing device may modify or cause the current media item 116 to be modified based on the media item prediction value 169. In some implementations, the processing device associates the tag 164 with the current media item 116 based on the media item prediction value 169.
In some implementations, the processing device can send the current media item 116 for review (e.g., manual review) and can receive one or more review decisions (e.g., manual review decisions). The processing device may tune k, f based on the review decisioniAnd gi(e.g., parameters 191) (e.g., via retraining, via a feedback loop). In some implementations, the tuning optimizes the area under the curve (AUC). In some implementations, the tuning optimizes the accuracy of a particular recall point.
Referring to fig. 3B, method 320 can be performed by one or more processing devices and/or media item platforms of prediction system 105 for predicting review decisions. The method 320 may be used to process the current media item 116 based on the media item prediction value 169. In some implementations, block 310 of fig. 3A includes method 320. Method 320 may be performed by an application or background thread executing on one or more processing devices and/or media item platforms of prediction system 105. As described herein, the threshold condition may be one or more of a threshold media item prediction value, probability, score, confidence level, and the like. For example, the first threshold condition may be a media item prediction value of 99% or greater. In some implementations, the threshold condition can be a combination of one or more of a threshold media item prediction value, a probability, a score, a confidence level, and the like. For example, a first threshold condition may satisfy a first media item prediction value and a threshold confidence level.
At block 322, the processing device determines whether the calculated media item prediction value 169 satisfies a first threshold condition. In response to the calculated media item prediction value 169 satisfying the first threshold condition, flow proceeds to block 324. In response to the calculated media item prediction value 169 not satisfying the first threshold condition, flow continues to block 326.
At block 324, the processing device prevents playback of the current media item 116 via the media item platform. For example, if the media item prediction value 169 satisfies a first probability (e.g., a probability of at or above 99%) that the current media item 116 contains a content type (e.g., inappropriate, having a technical issue, infringing a content owner right, etc.), the current media item 116 may be blocked by the media item platform. In some implementations, an indication of the content type (e.g., inappropriate, technical problem, infringement, etc.) may be transmitted to the content owner device 140 that uploaded the current media item 116. The content owner device may modify (e.g., or replace) the current media item 116 and upload the modified (or new) media item 112.
At block 326, the processing device determines whether the calculated media item prediction value 168 satisfies a second threshold condition. In response to the calculated media item prediction value 168 satisfying the second threshold condition, flow continues to block 328. In response to the calculated media item prediction value 168 not satisfying the second threshold condition, flow continues to block 330.
At block 328, the processing device allows playback of the media item via the media item platform. For example, if the media item prediction value 169 satisfies a second probability (e.g., a probability of less than or equal to 50%) that the current media item 116 contains a content type (e.g., inappropriate, having technical issues, infringing a content owner right, etc.), then playback of the current media item 116 may be allowed (e.g., the current media item 116 may be accessed for playback via the media item platform). In some implementations, an indication of permission to play the current media item 116 via the media item platform can be transmitted to the content owner device 140 that uploaded the current media item 116.
At block 330, the processing device determines whether the calculated media item prediction value 169 satisfies a third threshold condition. In response to the calculated media item prediction value 169 satisfying the third threshold condition, flow proceeds to block 332. In response to the calculated media item prediction value 169 not satisfying the third threshold condition, the flow ends.
At block 332, the processing device causes the current media item 116 to be reviewed to generate a tag 164 indicating whether playback via the media item platform is permitted. In some implementations, the third threshold condition is between the first and second threshold conditions (e.g., a lower probability than the first threshold condition and a higher probability than the second threshold condition, such as a 50-99% probability). The processing device may cause the current media item 116 to be manually reviewed.
At block 334, the processing device receives the generated tag 164 for the current media item 116. The processing device may receive the generated tags 164 generated by a user (e.g., an administrator of the media item platform) who manually reviews the current media item 116 in response to the media item prediction value 169 satisfying the third threshold condition.
In some implementations, at block 336, the processing device adjusts weights (e.g., of parameters 191 of model 190) based on the generated labels 164 for generating segment prediction values 168 (e.g., retuning the trained machine learning model 190).
At block 338, the processing device determines whether the generated tag 164 indicates that playback is allowed. In response to the generated tag 164 indicating that playback is allowed, flow continues to block 328. In response to the generated tag 164 indicating that playback is not allowed, flow continues to block 324.
Referring to FIG. 3C, the method 340 can be performed by one or more processing devices of the predictive system 105 for predicting a review decision. According to implementations of the present disclosure, prediction system 105 may use method 340 to train a machine learning model. In one implementation, some or all of the operations of method 340 may be performed by one or more components of system 100 of FIG. 1. In other implementations, one or more operations of the method 340 may be performed by the tuning set generator 171 of the server machine 170 described with reference to fig. 1-2.
The method 340 generates tuning data for the machine learning model. In some implementations, at block 342, the processing logic implementing the method 300 initializes a data set (e.g., a tuning set) T to an empty set.
At block 344, processing logic generates tuning inputs that include, for each segment 214 of the current media item 116, the length 212 of the corresponding segment 214, the length 216 of the current media item 116, and the length 218 of the corresponding tagged media item 114 (e.g., having a similar segment as the segment of the current media item 116).
At block 346, processing logic generates a target output for one or more of the tuning inputs. The target output may include the tag 164 of the current media item 116. In some implementations, the tag 164 may be received at block 334 of fig. 3B.
At block 348, processing logic optionally generates mapping data indicative of the input/output mapping (e.g., information 162 associated with the current media item 116 mapped to the tag 164 of the current media item 116). The input/output map (or mapping data) may refer to a tuning input (e.g., one or more tuning inputs described herein), a target output of the tuning input (e.g., where the target output identifies an indication of a user's preference to cancel a respective transmission), and an association between the tuning input and the target output.
At block 350, processing logic adds the mapping data to the data set T initialized at block 342.
At block 352, processing logic branches based on whether the tuning set T is sufficient to train the machine learning model 190. If so, execution proceeds to block 354, otherwise, execution continues back to block 344. It should be noted that in some implementations, the sufficiency of the tuning set T may be determined based solely on the number of input/output maps in the tuning set, while in some other implementations, the sufficiency of the tuning set T may be determined based on one or more other criteria (e.g., a measure of diversity, accuracy of tuning examples, etc.) in addition to, or instead of, the number of input/output maps.
At block 354, processing logic provides the tuning set T to train the machine learning model 190. In one implementation, the tuning set T is provided to the tuning engine 181 of the server machine 180 to perform training or retraining of the model 190. In some implementations, the training or retraining of the model includes adjusting the weights of the parameters 191 of the model 190 (see block 336 of FIG. 3B). After block 354, the machine learning model 190 may be trained or retrained based on the tuning set T, and the trained machine learning model 190 may be implemented (e.g., by the prediction manager 132) to predict a review decision for the current media item 116.
Referring to fig. 3D, the method 360 can be performed by one or more processing devices of the predictive system 105 for predicting review decisions. The method 360 may be used to predict review decisions. The method 360 may be performed by an application or background thread executing on one or more processing devices (e.g., the prediction manager 132) of the prediction system 105.
At block 362, for each segment 214 of the current media item 116, the processing device provides the length 212 of the corresponding segment 214, the length 216 of the current media item 116, and the length 218 of the corresponding tagged media item 114 to the trained machine learning model 190. The trained machine learning model 190 may be trained by the method 340 of FIG. 3C. The trained machine learning model 190 may perform one or more of the blocks 306-308 of the method of FIG. 3A. For example, the trained machine learning model may determine the segment prediction values 168 based on the tuning inputs and parameters 191 provided in block 362. In some implementations, the trained machine learning model may process the segment prediction values 168 (e.g., multiply the segment prediction values 168, combine the segment prediction values 168) to generate the media item prediction values 169.
At block 344, the processing device may obtain one or more outputs from the trained machine learning model 190. At block 346, the processing device may determine a media item prediction value 169 for the current media item 116 based on the one or more outputs. In some implementations, the processing device may extract from the one or more outputs a confidence level that the media item prediction values 169 will correspond to (e.g., match) the generated tags 164 (e.g., the tags 164 received in response to a manual review of the current media item 116).
4A-B depict a table 400 associated with predictive media item 112 review decisions in accordance with implementations of the present disclosure. As used herein, the terms "positive review" (e.g., rated as good, actual good, good review, etc.) and "negative review" (rated as bad, actual bad, bad review) can indicate attributes of the tags 164 or media items 112. In some implementations, a "negative review" can be a tag indicating that the media item 112 contains a certain type of content or attribute (e.g., inappropriate, has a technical problem, infringes others rights, etc.), and a "positive review" can be a tag indicating that the type of content or attribute is not present. In some implementations, the media item 112 can be associated with multiple tags at the same time. For example, a first tag of a media item 112 may indicate an age rating (e.g., teenagers and above), a second tag of the media item 112 may indicate that the media item 112 is suitable for a particular advertisement, a third tag of the media item 112 may indicate a particular technical issue (e.g., a caption issue), and so on. Tags may indicate that a particular type of content is inappropriate (e.g., including one or more of sexual content, violent or repugnant content, hate or abuse content, harmful dangerous behavior, abusing children, rising terrorism, spam or misleading, etc.), infringing rights, having technical issues (e.g., caption issues, etc.), having ratings (e.g., age-appropriate ratings, etc.), being suitable for advertising, etc.
FIG. 4A depicts a table 400A associated with tags 164 of media items 112 (e.g., tagged media items 114) according to an implementation of the present disclosure. The media item 112 may have been manually reviewed to be assigned a tag 164. As depicted in table 400A, manual review results in the tag 164 indicating a probability of 79% for a positive review of the media item 112 and 21% for a negative review of the media item 112. A positive review may indicate that the media item does not contain inappropriate content or has no technical issues. A negative review may indicate that the media item contains inappropriate content or has technical issues. Although the terms "positive review" and "negative review" and the term "content type" are used herein, it should be understood that the present disclosure applies to any type of tag for a media item 112.
The manual review may be partially accurate. For example, during a manual review, one or more portions of the media item 112 may be reviewed and one or more other portions of the media item 112 may not be reviewed (e.g., a portion of the media item 112 is spot-checked, the media item 112 is perused, etc.). Different users may provide different tags for the same media item 112. For example, for a tab of suggestive dance, a first user may consider dancing in the media item 112 to be less than suggestive and not worth obtaining a negative review tab, and a second user may consider dancing in the media item 112 to be more than suggestive and worth obtaining a negative review tab.
The actual accuracy may be determined by a manual review by an administrator (e.g., a supervisor of the user performing the initial manual review). As depicted in table 400A, the actual values result in a tag 164 indicating a probability of a positive review for the media item 112 of 76% (e.g., actually positive, the administrator will assign a positive review tag) and a probability of a negative review for the media item 112 of 24% (e.g., actually negative, the administrator will assign a negative review tag). The values from table 400A may be used to calculate media item prediction values 169.
The actual percentages in table 400A may be replaced with actual data (when available). The values in table 400A may be updated periodically as the distribution changes. The values in table 400A may have a recency bias (e.g., newer reviews for media items 112 may be weighted more heavily than less recent reviews for media items 112).
FIG. 4B depicts a table 400B that shows review decisions for the predicted media items 112 according to an implementation of the present disclosure.
As discussed herein, the segment prediction values 168 may be calculated using equations. The first segment 214A of the current media item 116 can be a corresponding first segment similar to the first tagged media item 114A having a "positive review" tag, and the second segment 214B of the current media item 116 can be a corresponding second segment similar to the second tagged media item 114B having a "negative review" tag. Based on the tagged media item 114A having a "positive review" label (e.g., good from good review), the probability that the segment of the current media item 116 has a "positive review" label can be represented by a first equation:
x*(1-y)
based on the tagged media item 114A having a "positive review" label (e.g., good from good reviews), the probability that the segment of the current media item 116 has a "negative review" label can be represented by the second equation:
(1-x)*y
the segment prediction values 168 may be calculated based on the first and second equations described in block 306 of fig. 3A.
FIG. 5 is a block diagram illustrating one implementation of a computer system according to an implementation of the present disclosure. In particular implementations, computer system 500 may be connected (e.g., via a network, such as a Local Area Network (LAN), intranet, extranet, or the internet) to other computer systems. Computer system 500 may operate in the capacity of a server or a client computer in a client-server environment, or as a peer computer in a peer-to-peer or distributed network environment. Computer system 500 may be provided by a Personal Computer (PC), tablet PC, set-top box (STB), Personal Digital Assistant (PDA), cellular telephone, web appliance, server, network router, switch or bridge, or any device capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that device. Moreover, the term "computer" shall include any collection of computers that individually or jointly execute a set (or multiple sets) of instructions to perform any one or more of the methodologies described herein.
In another aspect, computer system 500 may include a processing device 502, volatile memory 504 (e.g., Random Access Memory (RAM)), non-volatile memory 506 (e.g., read-only memory (ROM) or electrically erasable programmable ROM (eeprom)), and a data storage device 516, which may communicate with each other via a bus 508.
The processing device 502 may be provided by one or more processors, such as a general-purpose processor (e.g., a Complex Instruction Set Computing (CISC) microprocessor, a Reduced Instruction Set Computing (RISC) microprocessor, a Very Long Instruction Word (VLIW) microprocessor, a microprocessor implementing other types of instruction sets, or a microprocessor implementing a combined type of instruction set) or a special-purpose processor (e.g., an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), a Digital Signal Processor (DSP), or a network processor).
The computer system 500 may also include a network interface device 522. The computer system 500 may also include a video display unit 510 (e.g., an LCD), an alphanumeric input device 512 (e.g., a keyboard), a cursor control device 514 (e.g., a mouse), and a signal generation device 520.
In some implementations, the data storage device 516 may include a non-transitory computer-readable storage medium 524 on which instructions 526 encoding any one or more of the methods or functions described herein may be stored, including instructions encoding the prediction manager 132 of fig. 1 and used to implement one or more of the methods 300, 320, 340, or 360.
The instructions 526 may also reside, completely or partially, within the volatile memory 504 and/or within the processing device 502 during execution thereof by the computer system 500, the volatile memory 504 and the processing device 502 also constituting machine-readable storage media.
While the computer-readable storage medium 524 is shown in an illustrative example to be a single medium, the term "computer-readable storage medium" should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of executable instructions. The term "computer-readable storage medium" shall also be taken to include any tangible medium that is capable of storing or encoding a set of instructions for execution by the computer to cause the computer to perform any one or more of the methodologies described herein. The term "computer readable storage medium" shall include, but not be limited to, solid-state memories, optical media, and magnetic media.
The methods, components and features described herein may be implemented by discrete hardware components or may be integrated in the functionality of other hardware components such as ASICS, FPGAs, DSPs or similar devices. Additionally, the methods, components and features may be implemented by firmware modules or functional circuits within a hardware device. Furthermore, the methods, components and features may be implemented in any combination of hardware devices and computer program components, or in a computer program.
Unless specifically stated otherwise, terms such as "identifying," "processing," "generating," "calculating," "processing," "determining," "preventing," "allowing," "causing," "adjusting," "training," "tuning," or the like, refer to the actions and processes performed or carried out by a computer system that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices. Furthermore, the terms "first," "second," "third," "fourth," and the like, as used herein, refer to labels used to distinguish between different elements, and may not have an ordinal meaning according to their numerical designation.
Examples described herein also relate to an apparatus for performing the methods described herein. The apparatus may be specially constructed for carrying out the methods described herein, or it may comprise a general-purpose computer system selectively programmed by a computer program stored in the computer system. Such a computer program may be stored in a computer readable tangible storage medium.
The methods and illustrative examples described herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with or it may prove convenient to construct more specialized apparatus to perform the methods 300, 320, 340, and 360 and/or their respective functions, routines, subroutines, or operations in accordance with the teachings described herein. Examples of the structure of various of these systems are set forth in the description above.
The above description is intended to be illustrative and not restrictive. While the present disclosure has been described with reference to specific illustrative examples and implementations, it will be recognized that the present disclosure is not limited to the described examples and implementations. The scope of the disclosure should be determined with reference to the following claims, along with the full scope of equivalents to which such claims are entitled.
Claims (20)
1. A method, comprising:
identifying a current media item to be processed;
processing a plurality of tagged media items to identify a tagged media item that includes at least one respective segment that is similar to one of a plurality of segments of the current media item;
for each of the plurality of segments of the current media item, generating a segment prediction value indicative of a particular attribute associated with a corresponding segment of the current media item based on an attribute associated with the corresponding tagged media item, each tagged media item including a corresponding segment that is similar to the corresponding segment of the current media item;
calculating a media item prediction value for the current media item based on the generated segment prediction value for each of the plurality of segments of the current media item; and
causing the current media item to be processed based on the calculated media item prediction value.
2. The method of claim 1, wherein:
each of the tagged media items is assigned a respective tag; and
each of the plurality of segments of the current media item at least partially matches one or more segments of the tagged media item.
3. The method of claim 1 or 2, wherein generating the segment prediction value for the corresponding segment for each of the plurality of segments of the current media item is based on a plurality of parameters including at least one of: a length of the corresponding segment, a length of the current media item, or a length of the respective tagged media item, each tagged media item including the respective segment that is similar to the corresponding segment of the current media item.
4. The method of any preceding claim, further comprising:
determining that a first segment of the current media item matches a first corresponding segment of a first tagged media item;
determining that a second segment of the current media item matches a second corresponding segment of a second tagged media item;
determining that the first segment is a sub-segment of the second segment, wherein the second segment includes the first segment and a third segment, wherein generating the segment prediction value for each of the plurality of segments comprises:
generating a first segment prediction value indicative of a first label of the first segment based on a first respective label of the first tagged media item and a second respective label of the second tagged media item; and
generating a second segment prediction value indicative of a second tag of the third segment based on the second corresponding tag of the second tagged media item, wherein calculating the media item prediction value is based on the generated first segment prediction value and the generated second segment prediction value.
5. The method of any preceding claim, wherein causing the current media item to be processed comprises one of:
in response to the calculated media item prediction value satisfying a first threshold condition, causing playback of the current media item via the media item platform to be prevented;
in response to the calculated media item prediction value satisfying a second threshold condition, causing the playback of the current media item via the media item platform to be allowed; or
In response to the calculated media item prediction value satisfying a third threshold condition, causing the current media item to be reviewed to generate a tag indicating whether the playback of the current media item via the media item platform is allowed.
6. The method of claim 5, wherein the segment prediction value for each of the plurality of segments is generated based on a plurality of parameters and one or more weights associated with one or more of the plurality of parameters.
7. The method of claim 6, further comprising adjusting the one or more weights based on the generated tag of the current media item.
8. The method of claim 7, wherein:
adjusting the one or more weights comprises training a machine learning model to provide adjusted one or more weights based on a tuning input and a target tuning output of the tuning input;
for each of the plurality of segments of the current media item, the tuning input includes a length of the corresponding segment, a length of the current media item, and a length of the respective tagged media item, each respective tagged media item including the respective segment that is similar to the corresponding segment of the current media item; and
the tuning target output of the tuning input includes the generated tag of the current media item.
9. A non-transitory machine-readable storage medium storing instructions that, when executed, cause a processing device to perform operations comprising:
identifying a current media item to be processed;
processing a plurality of tagged media items to identify a tagged media item that includes at least one respective segment that is similar to one of a plurality of segments of the current media item;
for each of the plurality of segments of the current media item, generating a segment prediction value indicative of a particular attribute associated with a corresponding segment of the current media item based on an attribute associated with the corresponding tagged media item, each tagged media item including a corresponding segment that is similar to the corresponding segment of the current media item;
calculating a media item prediction value for the current media item based on the generated segment prediction value for each of the plurality of segments of the current media item; and
causing the current media item to be processed based on the calculated media item prediction value.
10. The non-transitory machine-readable storage medium of claim 9, wherein:
each of the tagged media items is assigned a respective tag;
each of the plurality of segments of the current media item at least partially matches one or more segments of the tagged media item; and
generating the segment prediction value for the corresponding segment for each of the plurality of segments of the current media item is based on a plurality of parameters including at least one of: a length of the corresponding segment, a length of the current media item, or a length of the respective tagged media item, each tagged media item including the respective segment that is similar to the corresponding segment of the current media item.
11. The non-transitory machine-readable storage medium of claim 9 or 10, wherein the operations further comprise:
determining that a first segment of the current media item matches a first corresponding segment of a first tagged media item;
determining that a second segment of the current media item matches a second corresponding segment of a second tagged media item;
determining that the first segment is a sub-segment of the second segment, wherein the second segment includes the first segment and a third segment, wherein generating the segment prediction value for each of the plurality of segments comprises:
generating a first segment prediction value indicative of a first label of the first segment based on a first respective label of the first tagged media item and a second respective label of the second tagged media item; and
generating a second segment prediction value indicative of a second tag of the third segment based on the second corresponding tag of the second tagged media item, wherein calculating the media item prediction value is based on the generated first segment prediction value and the generated second segment prediction value.
12. The non-transitory machine-readable storage medium of any of claims 9 to 11, wherein causing the current media item to be processed comprises one of:
in response to the calculated media item prediction value satisfying a first threshold condition, causing playback of the current media item via the media item platform to be prevented;
in response to the calculated media item prediction value satisfying a second threshold condition, causing the playback of the current media item via the media item platform to be allowed; or
In response to the calculated media item prediction value satisfying a third threshold condition, causing the current media item to be reviewed to generate a tag indicating whether the playback of the current media item via the media item platform is allowed.
13. The non-transitory machine-readable storage medium of claim 12, wherein:
the segment prediction value for each of the plurality of segments is generated based on a plurality of parameters and one or more weights associated with one or more of the plurality of parameters; and
the operations further include adjusting the one or more weights based on the generated tag of the current media item.
14. The non-transitory machine-readable storage medium of claim 13, wherein:
adjusting the one or more weights comprises training a machine learning model to provide adjusted one or more weights based on a tuning input and a target tuning output of the tuning input;
for each of the plurality of segments of the current media item, the tuning input includes a length of the corresponding segment, a length of the current media item, and a length of the respective tagged media item, each respective tagged media item including the respective segment that is similar to the corresponding segment of the current media item; and
the tuning target output of the tuning input includes the generated tag of the current media item.
15. A system, comprising:
a memory to store instructions; and
a processing device communicatively coupled to the memory, the processing device configured to execute the instructions to:
identifying a current media item to be processed;
processing a plurality of tagged media items to identify a tagged media item that includes at least one respective segment that is similar to one of a plurality of segments of the current media item;
for each of the plurality of segments of the current media item, generating a segment prediction value indicative of a particular attribute associated with a corresponding segment of the current media item based on an attribute associated with the corresponding tagged media item, each tagged media item including a corresponding segment that is similar to the corresponding segment of the current media item;
calculating a media item prediction value for the current media item based on the generated segment prediction value for each of the plurality of segments of the current media item; and
causing the current media item to be processed based on the calculated media item prediction value.
16. The system of claim 15, wherein:
each of the tagged media items is assigned a respective tag;
each of the plurality of segments of the current media item at least partially matches one or more segments of the tagged media item; and
the processing device generating, for each of the plurality of segments of the current media item, the segment prediction value for the corresponding segment is based on a plurality of parameters, the plurality of parameters including at least one of: a length of the corresponding segment, a length of the current media item, or a length of the respective tagged media item, each tagged media item including the respective segment that is similar to the corresponding segment of the current media item.
17. The system of claim 15 or 16, wherein the processing device is further to:
determining that a first segment of the current media item matches a first corresponding segment of a first tagged media item;
determining that a second segment of the current media item matches a second corresponding segment of a second tagged media item;
determining that the first segment is a sub-segment of the second segment, wherein the second segment includes the first segment and a third segment, wherein to generate the segment prediction value for each of the plurality of segments, the processing device:
generating a first segment prediction value indicative of a first label of the first segment based on a first respective label of the first tagged media item and a second respective label of the second tagged media item; and
generating a second segment prediction value indicative of a second tag of the third segment based on the second corresponding tag of the second tagged media item, wherein the processing device calculates the media item prediction value based on the generated first segment prediction value and the generated second segment prediction value.
18. The system of any of claims 15 to 17, wherein to cause the current media item to be processed, the processing device is to one of:
in response to the calculated media item prediction value satisfying a first threshold condition, causing playback of the current media item via the media item platform to be prevented;
in response to the calculated media item prediction value satisfying a second threshold condition, causing the playback of the current media item via the media item platform to be allowed; or
In response to the calculated media item prediction value satisfying a third threshold condition, causing the current media item to be reviewed to generate a tag indicating whether the playback of the current media item via the media item platform is allowed.
19. The system of claim 18, wherein:
the segment prediction value for each of the plurality of segments is generated based on a plurality of parameters and one or more weights associated with one or more of the plurality of parameters; and
the processing device further adjusts the one or more weights based on the generated tag of the current media item.
20. The system of claim 19, wherein:
to adjust the one or more weights, the processing device trains a machine learning model to provide adjusted one or more weights based on a tuning input and a target tuning output of the tuning input;
for each of the plurality of segments of the current media item, the tuning input includes a length of the corresponding segment, a length of the current media item, and a length of the respective tagged media item, each respective tagged media item including the respective segment that is similar to the corresponding segment of the current media item; and
the tuning target output of the tuning input includes the generated tag of the current media item.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862786713P | 2018-12-31 | 2018-12-31 | |
US62/786,713 | 2018-12-31 | ||
PCT/US2019/018622 WO2020142108A1 (en) | 2018-12-31 | 2019-02-19 | Using bayesian inference to predict review decisions in a match graph |
Publications (1)
Publication Number | Publication Date |
---|---|
CN113272800A true CN113272800A (en) | 2021-08-17 |
Family
ID=65686031
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980087180.2A Pending CN113272800A (en) | 2018-12-31 | 2019-02-19 | Predicting review decisions in a matching graph using bayesian inference |
Country Status (6)
Country | Link |
---|---|
US (1) | US20220121975A1 (en) |
EP (1) | EP3891622A1 (en) |
JP (2) | JP7242865B2 (en) |
KR (1) | KR20210104152A (en) |
CN (1) | CN113272800A (en) |
WO (1) | WO2020142108A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20220130544A1 (en) * | 2020-10-23 | 2022-04-28 | Remmie, Inc | Machine learning techniques to assist diagnosis of ear diseases |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6774917B1 (en) * | 1999-03-11 | 2004-08-10 | Fuji Xerox Co., Ltd. | Methods and apparatuses for interactive similarity searching, retrieval, and browsing of video |
WO2002021438A2 (en) * | 2000-09-07 | 2002-03-14 | Koninklijke Philips Electronics N.V. | Image matching |
US20050060350A1 (en) * | 2003-09-15 | 2005-03-17 | Baum Zachariah Journey | System and method for recommendation of media segments |
EP2382791B1 (en) | 2009-01-27 | 2014-12-17 | Telefonaktiebolaget L M Ericsson (PUBL) | Depth and video co-processing |
US10200381B2 (en) | 2015-08-05 | 2019-02-05 | Mcafee, Llc | Systems and methods for phishing and brand protection |
DE212017000015U1 (en) | 2017-03-03 | 2018-02-27 | Google Llc | Systems for detecting inadvertent implementation of presentation of content items by applications running on client devices |
-
2019
- 2019-02-19 EP EP19709244.8A patent/EP3891622A1/en active Pending
- 2019-02-19 US US17/419,228 patent/US20220121975A1/en active Pending
- 2019-02-19 WO PCT/US2019/018622 patent/WO2020142108A1/en unknown
- 2019-02-19 JP JP2021538275A patent/JP7242865B2/en active Active
- 2019-02-19 CN CN201980087180.2A patent/CN113272800A/en active Pending
- 2019-02-19 KR KR1020217024060A patent/KR20210104152A/en not_active Application Discontinuation
-
2023
- 2023-03-07 JP JP2023034730A patent/JP2023065653A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
JP2022516520A (en) | 2022-02-28 |
US20220121975A1 (en) | 2022-04-21 |
JP2023065653A (en) | 2023-05-12 |
EP3891622A1 (en) | 2021-10-13 |
KR20210104152A (en) | 2021-08-24 |
JP7242865B2 (en) | 2023-03-20 |
WO2020142108A1 (en) | 2020-07-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10652605B2 (en) | Visual hot watch spots in content item playback | |
CN111771384B (en) | Method, system and readable storage medium for automatically adjusting playback speed and context information | |
US20210287307A1 (en) | Generating playlists for a content sharing platform based on user actions | |
US20180068232A1 (en) | Expert-assisted online-learning for media similarity | |
KR102066773B1 (en) | Method, apparatus and system for content recommendation | |
US10911384B2 (en) | Staggered notification by affinity to promote positive discussion | |
US9872058B2 (en) | Splitting content channels | |
US10075763B2 (en) | Video channel categorization schema | |
US20230259720A1 (en) | Systems and methods to identify most suitable grammar suggestions among suggestions from a machine translation model | |
JP2023065653A (en) | Use of bayesian inference to predict review determination in match graph | |
Singh et al. | Impact of ratings of content on OTT platforms and prediction of its success rate | |
US20130124624A1 (en) | Enabling preference portability for users of a social networking system | |
WO2024030385A1 (en) | Media item and product pairing | |
US10877982B1 (en) | Detection of popular content with narrow appeal | |
US20230402065A1 (en) | Generating titles for content segments of media items using machine-learning | |
US20230095935A1 (en) | Systems and methods to publish new content | |
KR20200004858A (en) | Identify videos with inappropriate content by processing search logs | |
US20230104187A1 (en) | Systems and methods to publish new content | |
US11490172B2 (en) | Method and system for the classification and categorization of video pathways in interactive videos | |
Zhou et al. | A collaborative filtering method for interactive platforms | |
Bhattacharjee et al. | Low Dimensions and Span of Multiple Years |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |