TW201941047A - Circuit to perform dual input value absolute value and sum operation - Google Patents
Circuit to perform dual input value absolute value and sum operation Download PDFInfo
- Publication number
- TW201941047A TW201941047A TW108128109A TW108128109A TW201941047A TW 201941047 A TW201941047 A TW 201941047A TW 108128109 A TW108128109 A TW 108128109A TW 108128109 A TW108128109 A TW 108128109A TW 201941047 A TW201941047 A TW 201941047A
- Authority
- TW
- Taiwan
- Prior art keywords
- value
- alu
- input
- difference
- execution unit
- Prior art date
Links
- 230000009977 dual effect Effects 0.000 title 1
- 238000000034 method Methods 0.000 claims description 48
- 238000004364 calculation method Methods 0.000 claims description 35
- 238000010977 unit operation Methods 0.000 claims 1
- 230000015654 memory Effects 0.000 description 50
- 238000012545 processing Methods 0.000 description 36
- 230000006870 function Effects 0.000 description 22
- 238000013461 design Methods 0.000 description 15
- 230000008569 process Effects 0.000 description 15
- 230000000694 effects Effects 0.000 description 7
- 238000003860 storage Methods 0.000 description 7
- 238000004891 communication Methods 0.000 description 5
- 230000001186 cumulative effect Effects 0.000 description 5
- 238000007726 management method Methods 0.000 description 5
- 238000005516 engineering process Methods 0.000 description 3
- 230000004927 fusion Effects 0.000 description 3
- 238000009825 accumulation Methods 0.000 description 2
- 238000004422 calculation algorithm Methods 0.000 description 2
- 238000004590 computer program Methods 0.000 description 2
- 238000013500 data storage Methods 0.000 description 2
- 230000001419 dependent effect Effects 0.000 description 2
- 239000000284 extract Substances 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 239000004065 semiconductor Substances 0.000 description 2
- 239000007787 solid Substances 0.000 description 2
- PCTMTFRHKVHKIS-BMFZQQSSSA-N (1s,3r,4e,6e,8e,10e,12e,14e,16e,18s,19r,20r,21s,25r,27r,30r,31r,33s,35r,37s,38r)-3-[(2r,3s,4s,5s,6r)-4-amino-3,5-dihydroxy-6-methyloxan-2-yl]oxy-19,25,27,30,31,33,35,37-octahydroxy-18,20,21-trimethyl-23-oxo-22,39-dioxabicyclo[33.3.1]nonatriaconta-4,6,8,10 Chemical compound C1C=C2C[C@@H](OS(O)(=O)=O)CC[C@]2(C)[C@@H]2[C@@H]1[C@@H]1CC[C@H]([C@H](C)CCCC(C)C)[C@@]1(C)CC2.O[C@H]1[C@@H](N)[C@H](O)[C@@H](C)O[C@H]1O[C@H]1/C=C/C=C/C=C/C=C/C=C/C=C/C=C/[C@H](C)[C@@H](O)[C@@H](C)[C@H](C)OC(=O)C[C@H](O)C[C@H](O)CC[C@@H](O)[C@H](O)C[C@H](O)C[C@](O)(C[C@H](O)[C@H]2C(O)=O)O[C@H]2C1 PCTMTFRHKVHKIS-BMFZQQSSSA-N 0.000 description 1
- 238000012935 Averaging Methods 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000006835 compression Effects 0.000 description 1
- 238000007906 compression Methods 0.000 description 1
- 239000000470 constituent Substances 0.000 description 1
- 238000005265 energy consumption Methods 0.000 description 1
- 238000007667 floating Methods 0.000 description 1
- 230000008570 general process Effects 0.000 description 1
- 238000010801 machine learning Methods 0.000 description 1
- 230000014759 maintenance of location Effects 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 238000007620 mathematical function Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000002093 peripheral effect Effects 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 230000006641 stabilisation Effects 0.000 description 1
- 238000011105 stabilization Methods 0.000 description 1
- 230000002123 temporal effect Effects 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F7/00—Methods or arrangements for processing data by operating upon the order or content of the data handled
- G06F7/38—Methods or arrangements for performing computations using exclusively denominational number representation, e.g. using binary, ternary, decimal representation
- G06F7/48—Methods or arrangements for performing computations using exclusively denominational number representation, e.g. using binary, ternary, decimal representation using non-contact-making devices, e.g. tube, solid state device; using unspecified devices
- G06F7/50—Adding; Subtracting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/3001—Arithmetic instructions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/30036—Instructions to perform operations on packed data, e.g. vector, tile or matrix operations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30098—Register arrangements
- G06F9/3012—Organisation of register space, e.g. banked or distributed register file
- G06F9/30134—Register stacks; shift registers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/38—Concurrent instruction execution, e.g. pipeline, look ahead
- G06F9/3885—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units
- G06F9/3893—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units controlled in tandem, e.g. multiplier-accumulator
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11C—STATIC STORES
- G11C19/00—Digital stores in which the information is moved stepwise, e.g. shift registers
- G11C19/38—Digital stores in which the information is moved stepwise, e.g. shift registers two-dimensional, e.g. horizontal and vertical shift registers
Abstract
Description
本發明之領域大體而言係關於運算科學，且更具體而言係關於用以執行一雙輸入值絕對值及加總運算之一電路。The field of the present invention relates generally to computational science, and more specifically to a circuit for performing an absolute value of two input values and a summing operation.
影像處理通常涉及組織成一陣列之若干像素值之處理。在此，一空間上組織成二維之陣列擷取影像之二維性質(額外維度可包含時間(例如，一個二維影像序列)及資料類型(例如，色彩))。在一典型情境中，陣列式像素值係由已產生一靜止影像或一圖框序列以擷取運動影像之一相機提供。傳統影像處理器通常陷入兩個極端中之任一方面。
一第一極端係以在一個一般用途處理器或類一般用途處理器(例如，具有向量指令增強之一個一般用途處理器)上執行軟體程式之形式來執行影像處理任務。儘管第一極端通常提供一高度多功能之應用程式軟體開發平臺，但其在較精細粒度之資料結構上之使用與相關聯附加項(例如，指令提取及解碼、晶片上及晶片外資料之處置、理論式執行)結合會在程式碼之執行期間最終導致每資料單元消耗更大量能量。
一第二相反極端係將固定功能之固線式電路應用於更大資料區塊。使用直接施加至經定製設計之電路之較大(對比於較精細粒度)資料區塊會極大地減少每資料單元之電力消耗。然而，使用經定製設計之固定功能電路通常會導致處理器能夠執行之任務集係有限的。如此，在第二極端中，缺乏功能廣泛之程式化環境(與第一極端相關聯)。
既提供高度多功能之應用程式軟體開發可能性又結合有經改良之每資料單元電力效率之一技術平臺係一期望但仍缺失之解決方案。Image processing usually involves the processing of several pixel values organized into an array. Here, a space is organized into a two-dimensional array to capture the two-dimensional nature of the image (extra dimensions may include time (for example, a two-dimensional image sequence) and data type (for example, color)). In a typical scenario, the array pixel values are provided by a camera that has generated a still image or a frame sequence to capture a moving image. Traditional image processors often fall into one of two extremes.
A first extreme is to execute image processing tasks in the form of a software program executing on a general-purpose processor or a general-purpose processor-like processor (eg, a general-purpose processor with vector instruction enhancements). Although the first extreme usually provides a highly versatile application software development platform, its use of finer-grained data structures and associated additional items (e.g., instruction fetch and decode, on-chip and off-chip data handling) (Theoretical execution) combination will eventually lead to a greater amount of energy consumption per data unit during the execution of the code.
A second opposite terminal applies a fixed-function fixed-line circuit to a larger data block. Using larger (as opposed to finer-grained) data blocks applied directly to a custom-designed circuit can greatly reduce power consumption per data unit. However, the use of custom-designed fixed-function circuits often results in a limited set of tasks that the processor can perform. As such, in the second extreme, a stylized environment with extensive functions (associated with the first extreme) is lacking.
A technology platform that offers both highly versatile application software development possibilities and an improved power efficiency per data unit is a desired but still missing solution.
闡述一種執行單元。該執行單元包含一算術邏輯單元(ALU)電路，該ALU電路具有用以接收一第一值之一第一輸入及用以接收一第二值之一第二輸入。該ALU電路包含用以判定第一值之一絕對值且將該絕對值與第二值相加之電路。該第一輸入耦合至具有暫存器空間之一第一資料路徑及該執行單元電路之另一ALU之一輸出以作為該第一值之替代源。該第二輸入耦合至具有該暫存器空間之一第二資料路徑以作為該第二值之一源。Describe an execution unit. The execution unit includes an arithmetic logic unit (ALU) circuit having a first input for receiving a first value and a second input for receiving a second value. The ALU circuit includes a circuit for determining an absolute value of a first value and adding the absolute value to a second value. The first input is coupled to a first data path having a register space and an output of another ALU of the execution unit circuit as an alternative source of the first value. The second input is coupled to a second data path having the register space as a source of the second value.
A. 二維影像處理器
如此項技術中已知，用於執行程式碼之基礎電路結構包含一執行級及暫存器空間。執行級含有用於執行指令之執行單元(例如，一或多個算術邏輯單元(ALU)、浮動點單元、記憶體存取單元等)。將一待執行指令之輸入運算元自暫存器空間(或記憶體(若不在暫存器空間中))提供至執行級。將自執行級對一指令之執行而產生之結果寫回至暫存器空間。
一軟體線程在一傳統處理器上之執行需要透過執行級循序執行一系列指令。通常，在一單個結果產生自一單個輸入運算元集之意義上，運算係「純量的」。然而在「向量」處理器之情形中，由執行級進行之一指令之執行將自複數個輸入運算元集產生複數個結果。
圖1展示一獨特影像處理器架構100之一高級視圖，獨特影像處理器架構100包含耦合至一個二維移位暫存器陣列102之一執行分道陣列101。在此，執行分道陣列中之每一執行分道可被視為一離散執行級，該離散執行級含有執行由處理器100支援之指令集所需之執行單元。在各種實施例中，每一執行分道在同一機器循環中接收同一指令，使得總處理器作為一個二維的單指令多資料(SIMD)處理器而操作。
在各種實施例中，每一執行分道在二維移位暫存器陣列102內之一對應部位中具有其自己之專用暫存器空間。舉例而言，隅角執行分道103在隅角移位暫存器部位104中具有其自己之專用暫存器空間，隅角執行分道105在隅角移位暫存器部位106中具有其自己之專用暫存器空間等。在此，每一陣列部位中可存在若干個暫存器，藉此為每一執行分道陣列提供複數個專用暫存器。
舉例而言，若每一執行分道陣列在二維移位暫存器陣列中之其對應部位中具有四個暫存器R0、R1、R2、R3，則可以說二維移位暫存器陣列具有跨越整個陣列的R0暫存器空間之一第一平面、跨越整個陣列的R1暫存器空間之一第二平面、跨越整個陣列的R2暫存器空間之一第三平面及跨越整個陣列的R3暫存器空間之一第四平面。
另外，在各種實施例中，移位暫存器陣列102能夠使其內容移位，使得每一執行分道能夠在一先前機器循環期間自其自己之暫存器空間直接對駐存於另一執行分道之暫存器空間中之一值進行運算。舉例而言，一+1水平移位致使每一執行分道之暫存器空間自其最左側鄰近者之暫存器空間接收一值。由於能夠使值沿著一水平軸在向左及向右兩個方向上移位且使值沿著一垂直軸在向上及向下兩個方向上移位，因此處理器能夠高效地處理影像資料模板。
在此，如此項技術中已知，一模板係一片影像表面區域，該影像表面區域之組成像素值被用作輸入值以判定駐存於影像表面區域之中心中之一X, Y部位之一輸出像素值。作為一實例，一輸出影像中之一特定像素部位之一新值可被計算為以該特定像素部位為中心之一輸入影像之一區域中之像素值之一平均值。因此，若模板具有3個像素×3個像素之一尺寸，則特定像素部位可對應於3 x 3像素陣列之中間像素且可經由3 x 3像素陣列內之全部九個像素計算平均值。
根據圖1之處理器100之各種運算實施例，執行分道陣列101之每一執行分道負責計算一輸出影像中之一特定部位之一像素值。因此，繼續以剛才在上文所述之3 x 3模板求平均值為例，在輸入像素資料之一最初載入及移位暫存器內八次移位操作之一協調移位序列之後，執行分道陣列中之每一執行分道將接收到計算其對應像素部位之平均值所需之全部九個像素值至其本端暫存器空間中。由於圖1之處理器架構特別擅長處理影像模板，因此其亦可稱為一模板處理器。下文在章節F中進一步提供關於可能的模板處理器實施例及包含一或多個此等模板處理器之影像處理器實施例之更多細節。
B. 區塊匹配常式
圖2展示對一區塊匹配常式之一繪示。區塊匹配特定而言用於運動估計(例如，用於視訊壓縮)、影像穩定及影像融合演算法(例如，曝光融合及時間雜訊融合)。在此，在一替代(例如，後來)影像中搜尋一第一基底(例如，先前)影像中之一具體特徵。在圖2之實例中，需要在替代影像中找到基底影像中所存在之區塊ABCD。為簡化起見，假定替代影像中的任一其他像素皆不具有所搜尋區塊(A、B、C、D)值中之任一者。
圖3a至圖3d展示用於經由具有剛才上文關於圖1所闡述之一個二維執行分道陣列及一個二維移位暫存器陣列之一影像處理器執行區塊匹配之一方法。在此，替代影像之像素位於二維移位暫存器陣列中之暫存器空間(R0)之第一平面中。
將基底影像中的正被搜尋特徵之一第一像素值(例如，「A」)廣播至所有執行分道。然後，沿著每一分道，基於R0暫存器空間中之內容及值「A」而計算一絕對差302a (例如，沿著每一分道，絕對差運算計算為|x – y|，其中x = A且y = R0中之內容)。然後，將絕對差結果儲存於R1暫存器空間中。在一實施例中，對於每一分道而言，R1最初被設定成等於0且將絕對差與R1之內容相加。然後，將相加結果儲存回至R1中。在一實施例中，SIMD處理器之指令格式包含一立即運算元，該立即運算元用於將計算絕對差所利用的基底影像之像素值A廣播至執行分道中之每一者。在此，若R0中之替代影像之一像素值與所廣播像素值A匹配(或大致匹配)，則R1中之結果應為(或接近)零(「0」)。R1中之所有其他結果應係實質上非零(「/0」)。
參考圖3b，然後在二維移位暫存器之R0平面中將替代影像移位一個單元，將正被搜尋特徵中之下一像素值「B」廣播至所有執行分道，且再次判定絕對差並將該絕對差與R1中所儲存之內容相加。如此，每一分道執行一「絕對差加總」(SAD)運算。亦即，針對每一反覆，首先，計算新廣播之基底影像值(對於圖3b之反覆而言，係B)與R0中之新移入替代影像內容之間的一絕對差。然後，其次，在R1中將絕對差之結果與先前SAD運算之結果累加(相加) (對於圖3b之反覆而言，在R1中將圖3b中所計算之絕對差與圖3之第一反覆中所計算之絕對差相加)。在此，在完成圖3b之反覆之SAD運算之後，已進行了兩次連續像素匹配之特定執行分道陣列部位301應在其R1暫存器空間中具有最低結果值。更具體而言，在圖3b之反覆之後，圖3b之部位301 (係其中像素值之特定廣播次序與二維移位暫存器陣列之R0中之替代影像之特定掃描/移位運動對準的部位)在其R1暫存器空間中具有係大約零之一值。
如在圖3c及圖3d中所見，程序繼續每下一反覆，從而廣播基底影像之下一像素值，使R0替代影像資料以一特定掃描次序移位，且沿著每一分道執行一SAD運算，該等反覆計算所廣播值與R0移入值之間的一絕對差且然後將絕對差與R1 302c、302d中之先前SAD結果之累加值相加。在充分地廣播基底影像之所有所搜尋影像像素且對應地使R0中之替代影像移位跨越對應於所搜尋影像之大小之一區域的若干次反覆之後，在理想情況下，在每一反覆循環之後執行分道陣列中僅一個部位301將經歷一匹配。如此，在所有反覆已被完成之後，此特定陣列部位301在其R1暫存器空間中應能夠維持一零或近零值(或至少比另一執行分道小之一值)。
然後，在R1暫存器空間上跨越陣列中之所有列執行一「尋找最小值」運算。根據一尋找最小值運算之一項實施例，每一列中之最低對應值位於其列之每一部位處。然後，在R1暫存器空間上跨越陣列中之所有行執行一尋找最小值運算。在每一反覆之後，該結果應識別與基底影像匹配之像素，其繼而可用於在替代陣列中識別所搜尋影像之精確部位。下文在本說明書之章節D中進一步提供尋找最小值運算之一實施例之一論述。
C. 具有兩個 ALU 運算之 SAD 指令
依據上述實例，在替代影像之每一移位及下一基底影像值之廣播之後沿著每一執行分道而發生之絕對差計算302a至302d之加總可表達為：
R1 ＜= |R0 – BB
| + R1
其中R0係最近移位之替代影像值，BB
係基底影像之下一廣播值，且R1含有沿著同一執行分道執行之絕對差計算之所有先前加總之累加值。結果亦被寫回至R1中。如此，更一般而言，每一執行分道重複地執行以下運算：
|x – y| + z
其中結果儲存於提供z輸入運算元之同一暫存器空間(R1)中。為了將此計算之效能最大化，期望每一執行分道利用經減小電路量及/或較少電路運算來執行以上計算。利用較少電路及/或較少電路運算來執行SAD運算可(例如)致使SAD計算之效能提高及/或電力消耗減少。
圖4展示在三個ALU運算中僅能夠執行以上SAD指令之一執行分道ALU執行單元電路400 (後文稱為「執行單元」)之一初始設計。如在圖4中所見，執行單元400包含一第一算術邏輯單元(ALU)電路401及一第二ALU電路402。如此項技術中已知，一ALU電路(後文稱為「ALU」)執行算術運算(例如加、減、除)及邏輯運算(例如AND、OR等)。執行單元400負責執行各種算術及邏輯程式碼指令且可取決於正執行此等指令中之哪一者而使用一個或兩個ALU 401、402。如在圖4中所見，第一ALU 401可自二維移位暫存器陣列之其分道之本端暫存器空間接收一指令之一第一輸入運算元X且可自同一本端暫存器空間接收一指令之一第二輸入運算元Y。
第一ALU 401之輸出可用作第二ALU 402之一輸入值Q。第二ALU 402亦可自本端暫存器空間接收一指令之一第三輸入運算元Z。第二ALU亦可自本端暫存器空間接收被多工至第二ALU 402中之一指令之一第四輸入運算元R而非自第一ALU 401接收Q輸入值。執行單元400可提供直接來自一對ALU 401、402中執行一指令之一最終計算之那一者之該指令之一結果。為便於描繪，執行單元400之若干個各種其他特徵未予以繪示，使得可強調當前論述之相關資料路徑。
在此，執行單元400可執行三輸入ADD指令
x + y + z
在兩個ALU運算中。在此情形中，第一ALU 401內之一第一加法器403執行一第一x + y相加。然後，將來自第一加法器403之x + y結果作為輸入值Q傳遞至第二ALU 402。將輸入值Q在第二ALU 402內部傳遞至一第二加法器404。第二ALU 402內之一多工器405亦經組態以選擇輸入運算元Z，多工器405將Z呈遞至第二加法器404。然後，第二加法器404執行相加(x + y) + z。自執行單元400呈現來自第二加法器404之結果以作為三輸入ADD指令之結果。因此，執行兩個ALU運算(一個運算來自第一ALU 401且一第二運算來自第二ALU 402)以便執行三輸入ADD指令(作為一單個指令)。
遺憾的是，如上文所述，圖4之執行單元400僅能夠執行兩個指令中之三個ALU運算之一SAD運算。在此，SAD運算可表達為：
|x – y| + z
為了執行以上運算，第一ALU 401內之第一加法器403經組態以用作提供x – y作為其結果(而非提供x + y作為其結果)之一減法單元。然後，將含有來自第一加法器403之x – y結果之Q值傳遞至第二ALU 402且呈遞至第二加法器404。第二加法器404判定Q值之絕對值。
對第二加法器404進行組態以執行一絕對值計算包含：1)若Q係正數，則對第二加法器404進行組態以執行計算0 + Q；或2)若Q係負數，則對第二加法器404進行組態以執行計算0 – Q。在此，關於運算2)，如此項技術中已知，一加法器可經組態以藉由(例如)操縱加法器之一進位輸入(例如，自0至1)及/或對其輸入值中之一者執行一邏輯反轉來執行減法。注意，兩次計算皆採用一輸入值= 0。如此，當第二加法器404用於執行一絕對值計算時(如在當前正闡述之SAD運算之情形中)，多工器405經組態以選擇0通道(而非Z通道，就如上文所闡述之三輸入ADD指令而言)。用以執行一絕對值運算的一加法器之此傳統使用可稱為ALU 402之單輸入值運算。亦即，在執行此運算時，第二ALU 402僅接收一個輸入值Q。重要的是，第二ALU 402之運算僅完成|Q| = |x – y| (一絕對差)之計算。在此，將來自第二ALU 402之|Q|結果自執行單元400寫入至外部暫存器空間。
為了完成SAD運算，必須執行另一ALU運算以對|x – y |與z (=|Q| + z)進行加總。如此，執行一以下第二ADD指令：自暫存器空間讀取|Q|項及z值以作為輸入運算元且將|Q|項及z值提供(例如)至第一ALU 401以執行最終|x – y| + z相加。如此，需要三個ALU運算以執行一SAD運算：求x – y差之一第一運算；求|x – y|差之絕對值之一第二運算；及執行|x – y|與z之相加之一第三運算。前兩個運算耗用一第一指令且第三運算耗用一第二指令。在執行三個ALU運算(及兩個指令)以計算一單個SAD運算之情況下，可耗用3N-1個ALU運算，從而對含N個像素之一區塊執行一區塊匹配常式。
圖5展示一經改良ALU執行單元500，其能夠利用一單個指令中之兩個ALU運算來執行SAD運算，而非依據兩個指令利用三個ALU運算來執行SAD運算。在此，回顧對圖4之執行單元400之論述，照傳統，第二加法器404經組態以藉由為第二加法器404自多工器405提供一內部產生0來僅判定一絕對值。相比而言，圖5之經改良設計以係SAD指令之最終加數之輸入運算元z來替換值0。更具體而言，第二ALU 502中之第二加法器504經組態以執行：1)運算z + Q (若Q係正數)；或2)運算z – Q (若Q係負數)。因此，第二加法器504之結果係|Q| + z = |x – y| + z，此對應於SAD指令之結果。注意，在此情形中，與圖4之先前設計不同，第二ALU 502在執行包含一絕對值之一運算時接收兩個輸入值(Q及Z)，而第二ALU 402在執行絕對值運算時僅接收一個輸入值(Q)。
如此，以兩個ALU運算及一單個指令而非以三個ALU運算及兩個指令執行SAD運算。與圖4之執行單元400相比，此對應於大約33%之一ALU計算效率改良(例如，對於含N個像素之一區塊影像而言，可耗用2N個ALU計算(而非就圖4之執行單元400而言之3N-1個計算))。在其中執行分道包含具有兩個ALU之一ALU執行單元(類似於圖5之設計)之一實施例中，可以總共N個ALU計算來執行用於含N個像素之一區塊影像之一區塊匹配演算法。
在各種實施例中，如上文所述，前述第二ALU 502之絕對值功能被實施為一雙輸入值功能而非一單輸入值功能。亦即，當第二加法器執行一絕對值功能時，不將一內部產生之0提供至第二加法器504。相反，為了利用加法器504來執行一類絕對值運算(例如)以執行一絕對值指令(ABS)而非一SAD指令，將一值0自暫存器空間提供至ALU 502以作為ABS指令之一Z輸入運算元(值0亦可在內部產生於機器內且被載入至暫存器空間中，或直接提供至執行單元及/或ALU)。另外，將輸入至ALU 502、由ABS指令判定絕對值之值(例如R，而非Q)自暫存器空間多工至第二ALU 502中以作為ABS指令之一第二輸入運算元。在此，將Z = 0呈遞至第二ALU 502致使加法器504與實施絕對值功能之傳統加法器類似地運行。亦即，加法器504將：1)若R係正數，則執行運算0 + R；或2)若R係負數，則執行0 – R。因此，在此等實施例中，就上文關於圖4所論述之傳統實施方案而言，不論是對於一SAD指令還是一ABS指令，由第二ALU 502執行之絕對值運算天然地實施為一兩輸入值運算而非一單輸入值運算。
在其他實施例中，多工器405可具現化於第二加法器502中，使得(例如)除了用於支援SAD指令(諸如ABS指令)之絕對值運算之外的絕對值運算作為依賴於一內部產生值0之一傳統單輸入運算元值運算而運算。在其他實施例中，多工器405可存在於第二加法器中以(例如)支援單輸入值絕對值運算及雙輸入值絕對值運算兩者(多工器為前者選擇0輸入，但為後者選擇z)。在其他實施例或組合實施例中，如上文所闡述之兩輸入值絕對值功能可用於支援一新型絕對值指令ABS*，其中執行單元500按照一單個指令執行運算|R|+Z，其中z可係任何輸入運算元值(且未必係0)。
在各種實施例中，圖5之執行單元500仍可支援如上文關於圖4所闡述之SAD運算(三個ALU運算，而非兩個)。例如在累加加總可能或將耗用比機器之位元寬度更多之位元的情況下，此運算可係有用的。在此，可以等於機器之位元寬度之一較低精確度計算第一及第二ALU運算(其判定|x-y|)且第三ALU運算將累加值列表顯示於兩個或兩個以上暫存器中以提供機器自然位元寬度之所累加值。
D. 列 / 行尋找最小值運算
圖6以及圖7a至圖7d係關於一列/行尋找最小值運算，該運算亦可經由具有一個二維執行分道陣列及一對應二維移位暫存器之一影像處理器執行。列/行尋找最小值運算對於統計計算及上文在章節B中所闡述之區塊匹配後處理特別有用。
參考圖6，為簡化起見，僅展示執行陣列/暫存器陣列之一單個列。然而，在實際實施方案中，可經由實施一列尋找最小值運算之同一處理器實施一行尋找最小值運算。另外，可同時針對暫存器陣列中之任何數目個列(或行) (包含多達所有列/行)尋找一列(或行)之最小值。另外，列/行之尺寸僅被展示為8個部位寬，而在實際實施方案中執行分道及移位暫存器陣列可係16 x 16或更大。
如在圖6中所見，一列尋找最小值運算之結果對應於同一列及該列中之其部位/位置(亦稱為其索引)內之所有值當中之最小值。同樣地，一行尋找最小值運算之結果對應於同一行及該行內之其部位/位置內之所有值當中之最小值。與先前章節中所詳盡論述之列加總及前置項加總運算一樣，列/行尋找最小值運算採用可往來於陣列邊緣部位701而滾動移位之一個二維移位暫存器。
圖7a至圖7d展示一列前置項運算之機器級運算之一實施例。最初，如在圖7a中所見，在每一執行分道之各別R0暫存器部位中，一列載入有資料值A0至A7。此外，將每一列部位之索引載入至每一執行分道之R1暫存器空間中。
在圖7b中所繪示之機器級運算之一第一反覆中，將R0及R1暫存器部位之內容移位一個單元而移位至一鄰近執行分道暫存器空間之R2及R3暫存器空間中。然後，在每一執行分道內比較R0及R2暫存器之各別值。將比較之最小值及其對應索引儲存至R0及R1暫存器空間中。亦即，若R0值小於R2值，則R0及R1暫存器維持其原始內容。反之，若R2值小於R0值，則將R2值寫入至R0中且將R3值寫入至R1中。此具有在R0中保持比較之最小值且在R1中保持其索引的效應。
在圖7c中所繪示之機器級運算之一第二反覆中，將R0及R1暫存器部位之內容移位兩個單元而移位至一下游執行分道之R2及R3暫存器空間中。因此，下一反覆之移位量再次加倍。然後，在每一執行分道內比較R0及R2暫存器之各別值。將比較之最小值及其對應索引儲存至R0及R1暫存器空間中。此具有在R0中保持自已在每一執行分道中執行之兩次比較而得出之最小值且在R1中保持其索引的效應。
在圖7d中所見之機器級運算之一第三反覆中，將R0及R1暫存器部位之內容移位四個單元而移位至一下游執行分道之R2及R3暫存器空間中。然後，在每一執行分道內比較R0及R2暫存器之各別值。將比較之最小值及其對應索引儲存至R0及R1暫存器空間中。此具有在R0中保持自已在每一執行分道中執行之所有三次比較而得出之最小值且在R1中保持其索引的效應。
在第三反覆之後，尋找最小值運算完成，每一執行分道將在其R0暫存器空間中具有整個列之最小值且在其R1暫存器空間中具有該最小值之對應索引(最初設置有最小值之列部位將在其R1暫存器空間中尋找其自己之所識別列部位)。若列之尺寸係十六，則將僅再需要基於R0及R1暫存器內容在移位暫存器中向下游達八個部位之一移位的一組運算以提供所有十六個執行分道中之所有十六不同部位之最小值。
圖8展示上文所闡述之一方法。該方法包含：在一算術邏輯單元電路之一第一輸入處接收一第一值且在算術邏輯單元電路之一第二輸入處接收一第二值，801。該方法包含將該第一值及該第二值提供至算術邏輯單元電路內之加法器電路，802。該方法包含利用該加法器電路判定第一值之一絕對值，且在該加法器電路之一輸出處提供第二值與該第一值之絕對值之一加總，803。
E. 影像處理器及模板處理器實施例
圖9展示以硬體實施之一影像處理器之一架構900之一實施例。舉例而言，該影像處理器可作為一編譯器之目標，該編譯器將為一模擬環境內之一虛擬處理器撰寫之程式碼轉換成實際上由硬體處理器執行之程式碼。如在圖9中所見，架構900包含複數個線緩衝器單元901_1至901_M，該複數個線緩衝器單元901_1至901_M透過一網路904 (例如，一晶片上網路(NOC)，包含一晶片上交換網路、一晶片上環形網路或其他種類之網路)互連至複數個模板處理器單元902_1至902_N及對應表單產生器單元903_1至903_N。在一實施例中，任何線緩衝器單元可透過網路904連接至任何表單產生器及對應模板處理器。
在一實施例中，程式碼被編譯且被載入至一對應模板處理器902上以執行早前由一軟體開發者定義之影像處理操作(程式碼亦可例如取決於設計及實施方案而被載入至模板處理器之相關聯表單產生器903上)。在至少某些例項中，可藉由以下方式實現一影像處理管線：將用於一第一管線級之一第一內核程式載入至一第一模板處理器902_1中，將用於一第二管線級之一第二內核程式載入至一第二模板處理器902_2中等，其中第一內核執行第一級管線之功能，第二內核執行第二級管線之功能等，且額外控制流方法經設置以將所輸出影像資料自一個管線級傳遞至下一管線級。
在其他組態中，影像處理器可實現為使兩個或兩個以上模板處理器902_1、902_2操作相同內核程式碼之一並行機器。舉例而言，可藉由跨越每一者皆執行相同功能之多個模板處理器分佈圖框來處理一高度密集且高資料速率之影像資料串流。
在其他組態中，在DAG設計中，可藉由以下方式將內核之基本上任何DAG載入至硬體處理器上：藉由將各別模板處理器組態有其自己之各別程式碼內核且將適當控制流勾點(hook)組態至硬體中以將所輸出影像自一個內核引導至下一內核之輸入。
作為一個一般流程，一大型I/O單元905接收影像資料之圖框且將其逐圖框地傳遞至線緩衝器單元901中之一或多者。一特定線緩衝器單元將其影像資料圖框剖析成一較小影像資料區(稱為一「線群組」)，且然後將該線群組透過網路904傳遞至一特定表單產生器。一完整或「全」單數線群組可(舉例而言)由一圖框之多個相連完整列或行之資料組成(為簡化起見，本說明書將主要係指相連列)。表單產生器將影像資料之線群組進一步剖析成一更小影像資料區(稱為一「表單」)，且將表單呈遞至其對應模板處理器。
在具有一單個輸入之一影像處理管線或一DAG流程之情形中，通常，輸入圖框被引導至同一線緩衝器單元901_1，線緩衝器單元901_1將影像資料剖析成線群組且將該等線群組引導至表單產生器903_1，表單產生器903_1之對應模板處理器902_1正在執行管線/DAG中之第一內核之程式碼。在模板處理器902_1完成對其所處理之線群組之操作之後，表單產生器903_1立即將所輸出線群組發送至一「下游」線緩衝器單元901_2 (在某些用例中，可將輸出線群組發送回至早前已發送輸入線群組之同一線緩衝器單元901_1)。
然後，在其自己之各別其他表單產生器及模板處理器(例如，表單產生器903_2及模板處理器902_2)上執行的表示管線/DAG之下一級/運算之一或多個「耗用者」內核自下游線緩衝器單元901_2接收由第一模板處理器902_1產生之影像資料。以此方式，在一第一模板處理器上操作之一「產生者」內核將其輸出資料推進至在一第二模板處理器上操作之一「耗用者」內核，其中在產生者內核之後耗用者內核執行下一組任務，此與總管線或DAG之設計一致。
一模板處理器902經設計以同時對多個重疊影像資料模板進行操作。多個重疊模板及模板處理器之內部硬體處理容量有效地決定一表單之大小。在此，在一模板處理器902內，執行分道陣列一齊操作以同時處理由多個重疊模板覆蓋之影像資料表面區域。
如下文將更詳細地闡述，在各種實施例中，影像資料表單被載入至模板處理器902內之一個二維暫存器陣列結構中。認為，使用表單及二維暫存器陣列結構、藉由以(例如)一單次載入運算之形式將大量資料移動至大量暫存器空間中可有效地提供電力消耗改良，其中此後一執行分道陣列立即直接對資料執行處理任務。另外，一執行分道陣列及對應暫存器陣列之使用提供可容易地程式化/組態之不同模板大小。
圖10a至圖10e在一高層面上圖解說明一線緩衝器單元901之剖析活動、一表單產生器單元903之較精細粒度之剖析活動以及耦合至表單產生器單元903之模板處理器902之模板處理活動的實施例。
圖10a繪示影像資料1001之一輸入圖框之一實施例。圖10a亦繪示被所設計之一模板處理器操作之三個重疊模板1002 (每一者皆具有3個像素x 3個像素之一尺寸)之一略圖。以實心黑色突出含每一模板所分別產生之輸出影像資料之輸出像素。為簡化起見，三個重疊模板1002被繪示為僅在垂直方向上重疊。應認識到，實際上一模板處理器可經設計以在垂直及水平兩個方向上皆具有重疊模板。
由於模板處理器內之垂直重疊模板1002，如在圖10a中所見，在可由一單個模板處理器操作之圖框內存在一寬頻影像資料。如下文將更詳細地論述，在一實施例中，模板處理器以一左側至右側方式跨越影像資料處理其重疊模板內之資料，且然後以頂部至底部次序重複下一線集)。因此，隨著模板處理器繼續推進其操作，實心黑色輸出像素區塊之數目將向右水平地增長。如上文所論述，一線緩衝器單元901負責剖析來自一傳入圖框之輸入影像資料之一線群組，該傳入圖框足夠模板處理器在經延伸數目個即將到來之循環內之操作。對一線群組之一例示性繪示被圖解說明為一陰影區1003。在一實施例中，線緩衝器單元901可包含不同動力學以將一線群組發送至一表單產生器/自一表單產生器接收一線群組。舉例而言，根據稱為「全群組」之一種模式，影像資料之完整全寬度線在一線緩衝器單元與一表單產生器之間傳遞。根據稱為「虛擬高」之一第二模式，最初以一全寬度列子集傳遞一線群組。然後，以較小(小於全寬度)片塊循序地傳遞其餘列。
在輸入影像資料之線群組1003已由線緩衝器單元定義且被傳遞至表單產生器單元之情況下，表單產生器單元進一步將線群組剖析成更精細之表單，該等表單更精確地適於模板處理器之硬體限制。更具體而言，如下文將更詳細地闡述，在一實施例中，每一模板處理器由一個二維移位暫存器陣列組成。二維移位暫存器陣列將影像資料基本上移位於一執行分道陣列「下方」，其中移位圖案致使每一執行分道對其自己之各別模板內之資料進行操作(亦即，每一執行分道處理其自己之資訊模板以產生彼模板之一輸出)。在一實施例中，表單係「填充」或以其他方式載入至二維移位暫存器陣列中之輸入影像資料之表面區域。
如下文將更詳細地闡述，在各種實施例中，實際上存在可在任何循環內被移位之多層二維暫存器資料。為方便起見，本說明將僅使用術語「二維移位暫存器」等來指代具有可被移位之一或多個此等二維暫存器資料層之結構。
因此，如在圖10b中所見，表單產生器剖析來自線群組1003之一初始表單1004且將其提供至模板處理器(在此，資料表單對應於通常由元件符號1004識別之陰影區)。如在圖10c及圖10d中所見，模板處理器藉由以一左側至右側方式在表單上有效地移動重疊模板1002來操作輸入影像資料表單。如圖10d，可依據表單內之資料而被計算一輸出值之像素之數目被窮盡(其他像素位置可皆不具有依據表單內之資訊判定之一輸出值)。為簡化起見，已忽略影像之邊界區。
如在圖10e中所見，然後表單產生器提供下一表單1005以供模板處理器繼續操作。注意，模板開始對下一表單進行操作之初始位置係自第一表單上之窮盡點向右側之下一行進部(如先前在圖10d中所繪示)。針對新表單1005，模板將僅繼續向右側移動，如此模板處理器以與對第一表單之處理相同之方式操作新表單。
注意，由於環繞一輸出像素部位之模板之邊界區，第一表單1004之資料與第二表單1005之資料存在某些重疊。可僅藉由使表單產生器重新傳輸重疊資料兩次來處置該重疊。在替代實施方案中，為了將下一表單饋送至模板處理器，表單產生器可繼續僅將新資料發送至模板處理器且模板處理器重新使用來自先前表單之重疊資料。
圖11展示一模板處理器架構1100之一實施例。如圖11中所見，模板處理器包含一資料運算單元1101、一純量處理器1102及相關聯記憶體1103以及一I/O單元1104。資料運算單元1101包含一執行分道陣列1105、一個二維移位陣列結構1106及與陣列之具體列或行相關聯之單獨隨機存取記憶體1107。
I/O單元1104負責將自表單產生器接收之「輸入」資料表單載入至資料運算單元1101中且將來自模板處理器之「輸出」資料表單儲存至表單產生器中。在一實施例中，將表單資料載入至資料運算單元1101中會致使將一所接收表單剖析成影像資料列/影像資料行，且將影像資料列/影像資料行載入至二維移位暫存器結構1106或執行分道陣列之列/行之各別隨機存取記憶體1107中(下文更詳細地闡述)。若表單最初被載入至記憶體1107中，則執行分道陣列1105內之個別執行分道可然後在適當時將表單資料自隨機存取記憶體1107載入至二維移位暫存器結構1106中(例如，恰在對表單資料進行操作之前，按照一載入指令)。在一資料表單至暫存器結構1106中之載入完成之後(不論是直接自一表單產生器還是自記憶體1107)，執行分道陣列1105之執行分道對資料進行操作且最後將已處理完畢資料以一表單形式直接「寫回」至表單產生器或寫入至隨機存取記憶體1107中。若寫入至隨機存取記憶體1107中，則I/O單元1104自隨機存取記憶體1107提取資料以形成一輸出表單，然後該輸出表單被推進至表單產生器。
純量處理器1102包含一程式控制器1109，程式控制器1109自純量記憶體1103讀取模板處理器程式碼之指令且將指令發出至執行分道陣列1105中之執行分道。在一實施例中，將單個同一指令廣播至陣列1105內之所有執行分道以達成資料運算單元1101之一類SIMD行為。在一實施例中，自純量記憶體1103讀取並發出至執行分道陣列1105之執行分道之指令的指令格式包含每指令包含一個以上運算碼之一極長指令字(VLIW)類型格式。在另一實施例中，VLIW格式包含：一ALU運算碼，其引導由每一執行分道之ALU執行之一數學函數(如下文所闡述，在一實施例中ALU可規定一個以上傳統ALU運算)；及一記憶體運算碼，其引導一具體執行分道或一具體執行分道集合的一記憶體操作)。
術語「執行分道」係指含能夠執行一指令之一或多個執行單元(例如，可執行一指令之邏輯電路)之一集合。然而，在各種實施例中，一執行分道可包含超出執行單元之更多類處理器之功能性。舉例而言，除了一或多個執行單元之外，一執行分道亦可包含解碼一所接收指令之邏輯電路，或在類MIMD設計之情形中可包含提取且解碼一指令之邏輯電路。關於類MIMD方法，儘管本文中已主要闡述了一中心型程式控制方法，但可在各種替代實施例中實施一較分散方法(例如，陣列1105之每一執行分道內皆包含程式碼及一程式控制器)。
一執行分道陣列1105、程式控制器1109及二維移位暫存器結構1106之組合為一寬廣範圍之可程式化功能提供一極具可調適性/可組態性之硬體平臺。舉例而言，鑒於個別執行分道能夠執行各種各樣之功能且能夠在靠近任何輸出陣列部位處輕易地存取輸入影像資料，應用程式軟體開發者能夠將具有一寬廣範圍之不同功能能力以及尺寸(例如，模板大小)之內核程式化。
除了用作由執行分道陣列1105操作之影像資料之一資料儲存裝置之外，隨機存取記憶體1107亦可保存一或多個查找表。在各種實施例中，一或多個純量查找表亦可具現化於純量記憶體1103內。
一純量查找涉及將來自同一查找表之同一資料值依據同一索引傳遞至執行分道陣列1105內之執行分道中之每一者。在各種實施例中，上文所闡述之VLIW指令格式被擴展成亦包含一純量運算碼，該純量運算碼將由純量處理器執行之一查找運算引導至一純量查找表中。經指定與運算碼搭配使用之索引可係一立即運算元或自某些其他資料儲存部位提取而來。無論如何，在一實施例中，在同一時脈循環期間，來自純量記憶體內之一純量查找表之一查找基本上涉及將同一資料值廣播至執行分道陣列1105內之所有執行分道。下文進一步提供關於查找表之使用及運算之額外細節。
圖11b總結上文所論述之VLIW指令字實施例。如在圖11b中所見，VLIW指令字格式包含用於三個單獨指令之域：1)一純量指令1151，其由純量處理器執行；2)一ALU指令1152，其由執行分道陣列內之各別ALU以SIMD方式廣播並執行；及3)一記憶體指令1153，其以一部分SIMD方式被廣播並執行(例如，若沿著執行分道陣列中之同一列之執行分道共用同一隨機存取記憶體，則來自不同列中之每一者之一個執行分道實際上執行該指令(記憶體指令1153之格式可包含識別來自每一列之哪一執行分道執行該指令之一運算元)。
亦包含用於一或多個立即運算元之一域1154。可在指令格式中識別指令1151、1152、1153中之哪一者使用哪一立即運算元資訊。指令1151、1152、1153中之每一者亦包含其自己之各別輸入運算元及結果資訊(例如，用於ALU運算之本端暫存器以及用於記憶體存取指令之一本端暫存器及一記憶體位址)。在一實施例中，純量處理器先執行純量指令1151，然後執行分道陣列內之執行分道再執行另外指令1152、1153中之任一者。亦即，VLIW字之執行包含執行純量指令1151之一第一循環，後續接著可執行另一指令1152、1153之一第二循環(注意，在各種實施例中指令1152及1153可被並行地執行)。
在一實施例中，由純量處理器執行之純量指令包含發出至表單產生器以載入來自資料運算單元之記憶體或2D移位暫存器之表單/將表單儲存至記憶體或2D移位暫存器中的命令。在此，表單產生器之運算可取決於線緩衝器單元之運算或防止在執行階段前包含為完成由純量處理器發出之任何命令而由表達產生器花費之循環數目之其他變數。如此，在一實施例中，其純量指令1151對應於或以其他方式致使一命令被發出至表單產生器之任何VLIW字亦在另外兩個指令域1152、1153中包含非運算(NOOP)指令。然後，程式碼進入指令域1152、1153之NOOP指令之一迴圈直至表單產生器完成其至資料運算單元之載入/自資料運算單元之儲存為止。在此，在將一命令發出至表單產生器之後，純量處理器可旋即設定一聯鎖暫存器之一位元，在命令完成之後表單產生器重設該位元。在NOOP迴圈期間，純量處理器監視該聯鎖位元之位元。當純量處理器偵測到表單產生器已完成其命令之後，再次開始正常執行。
圖12展示一資料運算組件1201之一實施例。如在圖12中所見，資料運算組件1201包含邏輯地定位於一個二維移位暫存器陣列結構1206「上方」之一執行分道陣列1205。如上文所論述，在各種實施例中，將由一表單產生器提供之一影像資料表單載入至二維移位暫存器1206中。然後，執行分道對來自暫存器結構1206之表單資料進行操作。
執行分道陣列1205與移位暫存器結構1206相對於彼此固定於適當位置。然而，移位暫存器陣列1206內之資料以一戰略性且協調之方式移位以致使執行分道陣列中之每一執行分道處理資料內之一不同模板。如此，每一執行分道判定所產生輸出表單中之一不同像素之輸出影像值。依據圖12之架構，應清楚重疊模板不僅垂直地而且水平地配置，正如執行分道陣列1205包含垂直毗鄰執行分道以及水平毗鄰執行分道。
資料運算單元1201之某些值得注意架構特徵包含移位暫存器結構1206具有比執行分道陣列1205更寬之尺寸。亦即，在執行分道陣列1205外存在暫存器1209之一「環」。儘管環1209被展示為存在於執行分道陣列之兩側上，但取決於實施方案，環可存在於執行分道陣列1205之更少(一)或更多(三或四)側上。環1209用於在資料正在移位於執行分道1205「下方」時，為溢出執行分道陣列1205之界限之外的資料提供「外溢」空間。作為一簡單情形，當處理模板之最左側像素時，以執行分道陣列1205之右側邊緣為中心之一5 x 5模板將在右側進一步需要四個環暫存器部位。未繪示簡單起見，當在一標稱實施例中時，圖12將環右側之暫存器展示為僅具有水平移位連接且將環底部側之暫存器展示為僅具有垂直移位連接，任一側(右側、底部)上之暫存器將具有水平及垂直兩種連接。在各種實施例中，環區不包含用以執行影像處理指令之對應執行分道邏輯(例如，不存在ALU)。然而，環區部位中之每一者中皆存在個別記憶體存取單元(M)，使得個別環暫存器部位可個別地載入來自記憶體之資料且將資料儲存至記憶體。
隨機存取記憶體1207提供額外外溢空間，隨機存取記憶體1207耦合至陣列中之每一列及/或每一行或其部分(例如，一隨機存取記憶體可被指派至橫跨4個執行分道列及2個執行分道行之執行分道陣列之一「區」。為簡化起見，本申請案之其餘部分將主要係指基於列及/或行之分配方案)。在此，若一執行分道之內核運算需要其處理二維移位暫存器陣列1206外之像素值(某些影像處理常式可需要)，則影像資料平面能夠進一步(例如)自區1209外溢至隨機存取記憶體1207中。舉例而言，考慮一6 X 6模板，其中硬體在執行分道陣列之右側邊緣上之一執行分道之右側包含僅四個儲存元件之一環區。在此情形中，資料將需要進一步被移位至環1209之右側邊緣之右側以完全處理模板。然後，移位於環區1209之外的資料將外溢至隨機存取記憶體1207。下文進一步提供隨機存取記憶體1207及圖11之模板處理器之其他應用。
圖13a至圖13k說明如上文所提及地影像資料移位於位於執行分道陣列「下方」之二維移位暫存器陣列內之方式之一工作實例。如在圖13a中所見，二維移位陣列之資料內容被繪示成位於一第一陣列1307中且執行分道陣列由一圖框1305繪示。此外，簡化地繪示執行分道陣列內之兩個鄰近執行分道1310。在此簡化繪示1310中，每一執行分道包含一暫存器R1，暫存器R1可自移位暫存器接受資料，自一ALU輸出接受資料(例如，以用作一跨越循環之累加因子)，或將輸出資料寫入至一輸出目的地中。
每一執行分道在一本端暫存器R2中亦具有可用內容，即在二維移位陣列中位於執行分道「下方」之內容。因此，R1係執行分道之一實體暫存器，而R2係二維移位暫存器陣列之一實體暫存器。執行分道包含可對由R1及/或R2提供之運算元進行運算之一ALU。如下文將進一步更詳細地闡述，在一實施例中，移位暫存器每陣列部位實際上實施有多個(一「深度」之)儲存/暫存器元件，但移位活動限於儲存元件之一個平面(例如，每循環僅可移位儲存元件之一個平面)。圖13a至圖13k繪示用於儲存來自各別執行分道之結果X之此等較深暫存器部位中之一者。為易於圖解說明，較深結果暫存器被描繪為在側邊而非在其相對應暫存器R2下方。
圖13a至圖13k聚焦於其中央位置與所繪示的位於執行分道陣列內之執行分道位置對1311對準之兩個模板之計算。為易於圖解說明，執行分道對1311被描繪為水平鄰近者，但事實上根據以下實例其等係垂直鄰近者。
如最初在圖13a中所見，執行分道以其中央模板部位為中心。圖13b展示由兩個執行分道執行之目的碼。如在圖13b中所見，執行分道之程式碼致使移位暫存器陣列內之資料向下移位一個位置且向右側移位一個位置。此將兩個執行分道對準至其各別模板之左上側之隅角。然後，程式碼致使位於其各別部位中(位於R2中)之資料被載入至R1中。
如在圖13c中所見，接下來程式碼致使執行分道對將移位暫存器陣列內之資料向左側移位一個單元，此致使每一執行分道之各別位置右側之值移位至每一執行分道之位置中。然後，將R1中之值(先前值)與已移位至執行分道之位置中(R2中)之新值相加。將結果寫入至R1中。如在圖13d中所見，重複上文針對圖13c所闡述之相同程序，此致使暫存器R1現在在上部執行分道中包含值A+B+C且在下部執行分道中包含值F+G+H。在此時，兩個執行分道已處理其各別模板之上部列。注意至執行分道陣列之左側上之一環區中之外溢(在左側上存在一個環區之情況下)，或在執行分道陣列之左側上不存在一環區之情況下注意至隨機存取記憶體中之外溢。
如在圖13e中所見，在程式碼致使兩個執行分道與其各別模板之中間列之右側邊緣對準之後，程式碼接下來旋即致使移位暫存器陣列內之資料移位一個單元。兩個執行分道之暫存器R1當前包含模板之頂部列與中間列之最右側值之加總值。圖13f及圖13g說明跨越兩個執行分道之模板之中間向左移動之繼續前進。累加繼續，使得在圖13g之處理結束時，兩個執行分道包含其各別模板之頂部列及中間列之值的加總值。
圖13h展示用以對準每一執行分道與其對應模板之最下部列之另一移位。圖13i及圖13j展示繼續移位以在執行分道之模板之過程中完成處理。圖13k展示額外移位以對準每一執行分道與其在資料陣列中之正確位置且將結果寫入至該正確位置。
在圖13a至圖13k之實例中，注意用於移位操作之目的碼可包含識別以(X, Y)座標所表達之移位方向及移位量值之一指令格式。舉例而言，用於向上一個部位之一移位之目的碼在目的碼中可表達為移位0，+1。作為另一實例，向右側一個部位之一移位在目的碼中可表達為移位+1，0。在各種實施例中，亦可在目的碼中指定更大量值之移位(例如，移位0，+2)。在此，若2D移位暫存器硬體每循環僅支援移位一個部位，則指令可由機器解譯為需要多個循環執行，或者2D移位暫存器硬體可經設計以支援每循環移位一個以上部位。下文進一步更詳細地闡述後者之實施例。
圖14展示對一執行分道及對應移位暫存器結構之單位胞元之另一更詳細繪示(在各種實施例中，環區中之暫存器不包含一對應執行分道但包含一記憶體單元)。在一實施例中，藉由在執行分道陣列之每一節點處例示圖14中所見之電路來實施執行分道及與執行分道陣列中之每一部位相關聯之暫存器空間。如在圖14中所見，單位胞元包含耦合至由四個暫存器R2至R5組成之一暫存器檔案1402之一執行分道1401。在任何循環期間，執行分道1401可自暫存器R1至R5中之任一者讀取或寫入至暫存器R1至R5中之任一者。對於需要兩個輸入運算元之指令而言，執行分道可自R1至R5中之任一者擷取兩個運算元。
在一實施例中，藉由以下方式實施二維移位暫存器結構：在一單個循環期間准許暫存器R2至R4中之任一者(僅一者)之內容透過輸出多工器1403 「移出」至其鄰近者之暫存器文檔中，且使暫存器R2至R4中之任一者(僅一者)之內容被透過輸入多工器1404自其鄰近者中之一對應者「移入」之內容替換，使得鄰近者之間的移位在同一方向上(例如，所有執行分道左移位，所有執行分道右移位等)。儘管同一暫存器可能通常在同一循環內使其內容移出且被移入之內容替換，但多工器配置1403、1404准許在同一循環期間有不同移位源及在同一暫存器文檔內之移位目標暫存器。
如在圖14中所繪示，注意在一移位序列期間，一執行分道將自其暫存器檔案1402將內容移出至其左側、右側、頂部及底部鄰近者中之每一者。與同一移位序列相結合，執行分道亦將自其左側、右側、頂部及底部鄰近者中之一特定者將內容移位至其暫存器文檔中。此外，對於所有執行分道而言，移出目標及移入源應與同一移位方向相一致(例如，若移出至右側鄰近者，移入應來自左側鄰近者)。
儘管在一項實施例中，僅准許每循環每執行分道移位一個暫存器之內容，但其他實施例可准許移入/移出一個以上暫存器之內容。舉例而言，若圖14中所見之多工器電路1403、1404之一第二例項併入至圖14之設計中，則兩個暫存器之內容可在同一循環期間被移出/移入。當然，在其中每循環僅准許移位一個暫存器之內容之實施例中，可藉由在數學運算之間移位耗用更多時脈循環而在數學運算之間發生來自多個暫存器之移位(例如，可藉由耗用數學運算之間的兩個移位運算移位兩個暫存器之內容)。
若在一移位序列期間並非一執行分道之暫存器文檔之所有內容皆被移出，則注意每一執行分道之非移出暫存器之內容仍在適當位置(不移位)。如此，跨越移位循環未被移入內容替換之任何非移位內容存留在執行分道本端。在每一執行分道中所見之記憶體單元(「M」)用於自與執行分道陣列內之執行分道列及/或行相關聯之隨機存取記憶體空間載入資料/將資料儲存至該隨機存取記憶體空間。在此，該M單元用作一標準M單元，此乃因其通常用於載入/儲存不可自執行分道自己之暫存器空間載入/不可被儲存至執行分道自己之暫存器空間之資料。在各種實施例中，M單元之主要操作係將資料自一本端暫存器寫入至記憶體中，且自記憶體讀取資料並將其寫入至一本端暫存器中。
關於由硬體執行分道1401之ALU單元支援之ISA運算碼，在各種實施例中，由硬體ALU支援之數學運算碼包含(例如) ADD、SUB、MOV、MUL、MAD、ABS、ABS*、DIV、SHL、SHR、MIN/MAX、SEL、AND、OR、XOR、NOT、CLAZ、FINDMIN及SAD。如上文剛才所闡述，執行分道1401可執行記憶體存取指令，以自其相關聯隨機存取記憶體提取資料/將資料儲存至其相關聯隨機存取記憶體。另外，硬體執行分道1401支援移位運算指令(右、左、上、下)以移位二維移位暫存器結構內之資料。如上文所闡述，程式控制指令主要係由模板處理器之純量處理器執行。
F. 實施方案實施例
應指出，上文所闡述之各種影像處理器架構特徵未必限於傳統意義上之影像處理，且因此可用於可(不可)致使影像處理器被重新特徵化之其他應用。舉例而言，對比於處理實際相機影像，若上文所闡述之各種影像處理器架構特徵中之任一者用於形成及/或產生及/或再現動畫，則影像處理器可被稱為一圖形處理單元。另外，上文所闡述之影像處理器架構特徵可用於其他技術應用，諸如視訊處理、視圖處理、影像辨別及/或機器學習。以此方式應用，影像處理器可與一更一般用途處理器(例如係運算系統之一CPU或係CPU之一部分)整合(例如，作為一共處理器)，或可係一運算系統內之一獨立處理器。
上文所論述之硬體設計實施例可體現於一半導體晶片內及/或體現為最終針對一半導體製造程序之一電路設計之一說明。在係後者之情形中，此等電路說明可採取以下形式：一(例如，VHDL或Verilog)暫存器轉移級(RTL)電路說明、一閘級電路說明、一電晶體級電路說明或遮罩說明或者以上各項之各種組合。電路說明通常體現於一電腦可讀儲存媒體上(諸如一CD-ROM或其他類型之儲存技術)。
依據前述章節，應認識到上文所闡述之一影像處理器可體現為一電腦系統上之硬體(例如，作為處理來自手持式裝置之相機之資料之一手持式裝置之晶片上系統(SOC)之一部分)。在其中影像處理器體現為一硬體電路之情形中，注意可直接自一相機接收由影像處理器處理之影像資料。在此，影像處理器可係一離散相機之一部分，或係具有一整合式相機之一運算系統之一部分。在後者之情形中，可直接自相機或自運算系統之系統記憶體接收影像資料(例如，相機將其影像資料發送至系統記憶體而非影像處理器)。亦注意，前述章節中所闡述之特徵中之諸多特徵可適用於一圖形處理器單元(其再現動畫)。
圖15提供對一運算系統之一例示性繪示。下文所闡述之運算系統之組件中之諸多組件適用於具有一整合式相機及相關聯影像處理器之一運算系統(例如，一手持式裝置，諸如一智慧型電話或平板電腦)。熟習此項技術者將能夠容易地在該兩者之間進行辨別。另外，圖15之運算系統亦包含一高效能運算系統(諸如一工作站或超級電腦)之諸多特徵。
如在圖15中所見，基本運算系統可包含：一中央處理單元1501 (例如，其可包含複數個一般用途處理核心1515_1至1515_N及安置於一多核心處理器或應用處理器上之一主記憶體控制器1517)、系統記憶體1502、一顯示器1503 (例如，觸控螢幕、平板)、一本端有線點對點鏈路(例如，USB)介面1504、各種網路I/O功能1505 (諸如一乙太網介面及/或蜂巢式數據機子系統)、一無線區域網路(例如，WiFi)介面1506、一無線點對點鏈路(例如，藍芽)介面1507及一全球定位系統介面1508、各種感測器1509_1至1509_N、一或多個相機1510、一電池1511、一電力管理控制單元1512、一揚聲器與麥克風1513以及一音訊編碼器/解碼器1514。
一應用處理器或多核心處理器1550可包含位於其CPU 1501內之一或多個一般用途處理核心1515、一或多個圖形處理單元1516、一記憶體管理功能1517 (例如，一記憶體控制器)、一I/O控制功能1518及一影像處理單元1519。一般用途處理核心1515通常執行作業系統及運算系統之應用程式軟體。圖形處理單元1516通常執行圖形密集型功能以(例如)產生呈現於顯示器1503上之圖形資訊。記憶體控制功能1517與系統記憶體1502介接以將資料寫入至系統記憶體1502或自系統記憶體1502讀取資料。電力管理控制單元1512通常控制系統1500之電力消耗。
影像處理單元1519可根據上文在前述章節中詳盡闡述之影像處理單元實施例中任一者而實施。另一選擇係或組合地，IPU 1519可耦合至GPU 1516及CPU 1501中之任一者或兩者以作為其一共同處理器。另外，在各種實施例中，GPU 1516可實施有上文所詳盡闡述之影像處理器特徵中之任一者。此外，一般用途處理核心、影像處理單元及/或GPU中之任一者可利用上文所闡述之算術邏輯單元設計及/或指令。
觸控螢幕顯示器1503、通信介面1504-1507、GPS介面1508、感測器1509、相機1510及揚聲器/麥克風編碼解碼器1513、1514中之每一者全部可被視為相對於在適當情況下亦包含一整合式周邊裝置(例如，一或多個相機1510)之總運算系統之各種形式之I/O (輸入及/或輸出)。取決於實施方案，此等I/O組件中之各個組件可整合於應用處理器/多核心處理器1550上，或可位於晶粒之外或位於應用處理器/多核心處理器1550之封裝之外部。
在一實施例中，一或多個相機1510包含能夠量測相機與其視域中之一物件之間的深度之一深度相機。在一應用處理器或其他處理器之一個一般用途CPU核心(或具有一指令執行管線以執行程式碼之其他功能區塊)上執行之應用程式軟體、作業系統軟體、裝置驅動器軟體及/或韌體可執行上文所闡述之功能中任一者。
本發明之實施例可包含上文所闡述之各種程序。該等程序可體現為機器可執行指令。指令可用於致使一個一般用途或特殊用途處理器執行特定程序。另一選擇係，此等程序可由含有用於執行程序之固線式及/或可程式化邏輯之具體硬體組件或由經程式化電腦組件及定製硬體組件之任何組合執行。
本發明之元件亦可提供為用於儲存機器可執行指令之一機器可讀媒體。機器可讀媒體可包含但不限於：軟式磁片、光碟、CD-ROM及磁光碟、FLASH記憶體、ROM、RAM、EPROM、EEPROM、磁卡或光卡、傳播媒體或適合於儲存電子指令其他類型之媒體/機器可讀媒體。舉例而言，本發明可被下載為一電腦程式，可經由一通信鏈路(例如，一數據機或網路連接)藉由體現於一載波或其他傳播媒介中之資料信號將該電腦程式自一遠端電腦(例如，一伺服器)傳送至一請求電腦(例如，一客戶端)。
在先前說明書中，已參考本發明之具體例示性實施例闡述了本發明。然而，將顯而易見，可在不背離隨附申請專利範圍中所陳述之本發明之較廣泛精神及範疇之情況下對本發明做出各種修改及改變。因此，應將本說明書及圖式視為具有一說明性意義而非一限制性意義。
在以下內容中，闡述某些實例。
實例1：一執行單元電路，其包括：
一算術邏輯單元(ALU)電路，其包括用以接收一第一值之一第一輸入及用以接收一第二值之一第二輸入，該ALU電路包括用以判定該第一值之一絕對值且並將該絕對值與該第二值相加之電路，該第一輸入耦合至包括暫存器空間之一第一資料路徑及該執行單元電路之另一ALU之一輸出以作為該第一值之替代源，該第二輸入耦合至包括該暫存器空間之一第二資料路徑以作為該第二值之一源。
實例2：如實例1之執行單元電路，其中其中該電路包括一加法器電路。
實例3：如實例2之執行單元電路，其中該加法器電路用以：
若該第一值係正數，則將該第一值與該第二值相加；
若該第一值係負數，則自該第二值減去該第一值。
實例4：如先前實例中之至少一者之執行單元電路，其中該ALU電路執行一指令，該指令用以接收一第一輸入運算元及一第二輸入運算元，該指令用以將該第二輸入運算元與該第一輸入運算元之一絕對值相加，該ALU電路沿著該第一資料路徑自該暫存器空間接收該第一輸入運算元以作為該第一值，該ALU電路沿著該第二資料路徑自該暫存器空間接收該第二輸入運算元以作為該第二值。
實例5：如先前實例中之至少一者之執行單元電路，其中該ALU電路亦執行另一指令，該另一指令判定第一輸入運算元與第二輸入運算元之間的一絕對差且將該絕對差與一第三輸入運算元相加，該ALU電路沿著該第一資料路徑自另一ALU電路接收該第一輸入運算元與該第二輸入運算元之間的一差以作為該第一值，該ALU電路沿著該第二資料路徑自該暫存器空間接收該第三輸入運算元以作為該第二值。
實例6：如先前實例中之至少一者之執行單元電路，其中該ALU電路執行一指令，該指令用以判定第一輸入運算元與第二輸入運算元之間的一絕對差且將該絕對差與一第三輸入運算元相加，該ALU電路沿著該第一資料路徑自另一ALU電路接收該第一輸入運算元與該第二輸入運算元之間的一差以作為該第一值，該ALU電路沿著該第二資料路徑自該暫存器空間接收該第三輸入運算元以作為該第二值。
實例7：如先前實例中之至少一者之執行單元電路，其中在該ALU電路完成該第一值與該第二值之該相加時，該指令即被完成。
實例8：如先前實例中之至少一者之執行單元電路，其中該ALU電路係一影像處理器內之一組件。
實例9：如先前實例中之至少一者之執行單元電路，其中一影像處理器架構包括耦合至一個二維移位暫存器陣列之一執行陣列。
實例10：如先前實例中之至少一者之執行單元電路，其中影像處理器經組態以執行像素資料之一區塊匹配。
實例11：如先前實例中之至少一者之執行單元電路，其中影像處理器經組態以執行一列/行尋找最小值運算，特定而言在具有一個二維執行分道陣列及一對應二維移位暫存器之一影像處理器上執行。
實例12：如先前實例中之至少一者之執行單元電路，其中影像處理器之架構包括一線緩衝器、一表單產生器及/或一模板處理器中之至少一者。
實例13：如實例12之執行單元電路，其中該模板處理器經組態以處理重疊模板。
實例14：如先前實例中之至少一者之執行單元電路，其中一資料運算單元包括具有比執行分道陣列更寬之尺寸之一移位暫存器結構，特定而言在該執行分道陣列之外存在暫存器。
實例15：一種由一處理器執行之方法，其包括：
接收一指令；
利用該處理器之一算術邏輯單元電路執行該指令，該指令之該執行包括以下a)、b)及c)：
a)在該算術邏輯單元電路之一第一輸入處接收一第一值且在該算術邏輯單元電路之一第二輸入處接收一第二值；
b)將該第一值及該第二值提供至該算術邏輯單元電路內之一加法器電路；
c)利用該加法器電路判定該第一值之一絕對值，且在該加法器電路之一輸出處提供該第二值與該第一值之該絕對值之一加總。
實例16：如實例15之方法，其中該第一值係接收自該處理器之另一算術邏輯單元電路。
實例17：如實例15或16之方法，其中該指令係絕對差指令之一加總。
實例18：如實例15至17中至少一者之方法，其中該指令係一絕對值指令且該第二值被設定成等於零。
實例19：如實例15至18中至少一者之方法，其中一影像處理器架構在耦合至一個二維移位暫存器陣列之一執行陣列上運算。
實例20：如實例15至19中至少一者之方法，其中影像處理器執行像素資料之一區塊匹配。
實例21：如實例15至20中至少一者之方法，其中影像處理器執行一列/行尋找最小值運算，特定而言在具有一個二維執行分道陣列及一對應二維移位暫存器之一影像處理器上執行。
實例22：如實例15至21中至少一者之方法，其中影像處理器之架構包括一線緩衝器、一表單產生器及/或一模板處理器中之至少一者。
實例23：如實例22之方法，其中該模板處理器處理重疊模板。
實例24：如實例15至23中至少一者之方法，其中一資料運算單元包括具有比執行分道陣列更寬之尺寸之一移位暫存器結構，特定而言在該執行分道陣列之外存在暫存器。
實例25：一種運算系統，其包括：
複數個一般用途處理器；
一系統記憶體；
一記憶體控制器，其耦合至該系統記憶體；
一影像處理器，其包括用以執行一指令之一執行單元電路，該執行單元電路包括一算術邏輯單元(ALU)電路，該ALU電路包括用以接收一第一值之一第一輸入及用以接收一第二值之一第二輸入，該ALU電路包括用以在執行該指令期間判定該第一值之一絕對值且將該絕對值與該第二值相加之電路，該第一輸入耦合至包括暫存器空間之一第一資料路徑及該執行單元電路之另一ALU之一輸出以作為該第一值之替代源，該第二輸入耦合至包括該暫存器空間之一第二資料路徑以作為該第二值之一源。
實例26：如實例25之運算系統，其中該電路包括一加法器電路。
實例27：如實例25或26之運算系統，其中該加法器電路用以：
若該第一值係正數，則將該第一值與該第二值相加；
若該第一值係負數，則自該第二值減去該第一值。
實例28：如實例25至27中至少一者之運算系統，其中該指令接收一第一輸入運算元及一第二輸入運算元，該指令將該第二輸入運算元與該第一輸入運算元之一絕對值相加，該ALU電路接收該第一輸入運算元以作為該第一值，該ALU電路接收該第二輸入運算元以作為該第二值。
實例29：如實例25至28中至少一者之運算系統，其中該執行單元電路亦執行判定第一輸入運算元與第二輸入運算元之間的一絕對差且將該絕對差與一第三輸入運算元相加之另一指令，該ALU電路自該執行單元電路之另一ALU電路接收該第一輸入運算元與該第二輸入運算元之間的一差以作為該第一值，該ALU電路接收該第三輸入運算元以作為該第二值。
實例30：如實例25至29中至少一者之運算系統，其中該指令用以判定第一輸入運算元與第二輸入運算元之間的一絕對差且將該絕對差與一第三輸入運算元相加，該ALU電路自該執行單元電路之另一ALU電路接收該第一輸入運算元與該第二輸入運算元之間的一差以作為該第一值，該ALU電路接收該第三輸入運算元以作為該第二值。
實例31：如實例25至30中至少一者之運算系統，其中在該ALU電路完成該第一值與該第二值之該相加時，該執行單元即完成該指令之執行。
實例32：如實例25至31中至少一者之運算系統，其中該影像處理器包括一執行分道陣列及一個二維移位暫存器陣列。
實例33：如實例25至32中至少一者之運算系統，其中一影像處理器架構包括耦合至一個二維移位暫存器陣列之一執行陣列。
實例34：如實例25至33中至少一者之運算系統，其中該影像處理器經組態以執行像素資料之一區塊匹配。
實例35： 如實例25至34中至少一者之運算系統，其中該影像處理器經組態以執行一列/行尋找最小值運算，特定而言在具有一個二維執行分道陣列及一對應二維移位暫存器之一影像處理器上執行。
實例36：如實例25至35中至少一者之運算系統，其中該影像處理器之架構包括一線緩衝器、一表單產生器及/或一模板處理器中之至少一者。
實例37：如實例36之運算系統，其中該模板處理器經組態以處理重疊模板。
實例38：如實例25至37中至少一者之運算系統，其中一資料運算單元包括具有比執行分道陣列更寬之尺寸之一移位暫存器結構，特定而言在該執行分道陣列之外存在暫存器。 A. 2D image processor
As known in the art, the basic circuit structure for executing code includes an execution stage and a register space. The execution stage contains execution units (eg, one or more arithmetic logic units (ALU), floating point units, memory access units, etc.) for executing instructions. An input operand of an instruction to be executed is provided from the register space (or memory (if not in the register space)) to the execution stage. Writes the result from the execution of an instruction by the execution level back to the register space.
The execution of a software thread on a traditional processor requires a series of instructions to be executed sequentially through an execution level. Generally, operations are "scalar" in the sense that a single result results from a single set of input operands. However, in the case of "vector" processors, execution of an instruction by an execution stage will produce multiple results from a plurality of input operand sets.
FIG. 1 shows a high-level view of a unique image processor architecture 100 that includes an execution lane array 101 coupled to one of a two-dimensional shift register array 102. Here, each execution lane in the execution lane array can be regarded as a discrete execution stage containing the execution units required to execute the instruction set supported by the processor 100. In various embodiments, each execution lane receives the same instruction in the same machine cycle, so that the overall processor operates as a two-dimensional single instruction multiple data (SIMD) processor.
In various embodiments, each execution lane has its own dedicated register space in a corresponding location within the two-dimensional shift register array 102. For example, the corner execution lane 103 has its own dedicated register space in the corner shift register site 104, and the corner execution lane 105 has its own register space in the corner shift register site 106 Your own dedicated register space, etc. Here, there may be several registers in each array part, thereby providing a plurality of dedicated registers for each execution lane array.
For example, if each execution lane array has four registers R0, R1, R2, R3 in its corresponding part in the two-dimensional shift register array, it can be said that the two-dimensional shift register The array has one first plane across the R0 register space across the entire array, one second plane across the R1 register space across the entire array, one third plane across the R2 register space across the entire array, and spanning the entire array The fourth plane of one of the R3 register spaces.
In addition, in various embodiments, the shift register array 102 is capable of shifting its contents so that each execution lane can be directly hosted on another register from its own register space during a previous machine cycle Perform one of the values in the register's register space to perform the operation. For example, a +1 horizontal shift causes the register space of each execution lane to receive a value from the register space of its leftmost neighbor. Since the value can be shifted in both left and right directions along a horizontal axis and the value can be shifted in both up and down directions along a vertical axis, the processor can efficiently process image data template.
Here, it is known in this technology that a template is an image surface area, and the constituent pixel values of the image surface area are used as input values to determine one of X, Y locations residing in the center of the image surface area. Output pixel value. As an example, a new value of a specific pixel portion in an output image can be calculated as an average of pixel values in an area of an input image centered on the specific pixel portion. Therefore, if the template has a size of 3 pixels × 3 pixels, the specific pixel portion can correspond to the middle pixel of the 3 × 3 pixel array and the average value can be calculated through all nine pixels in the 3 × 3 pixel array.
According to various operational embodiments of the processor 100 of FIG. 1, each execution lane of the execution lane array 101 is responsible for calculating a pixel value of a specific part in an output image. Therefore, continue to take the averaging of the 3 x 3 template just described as an example. After one of the input pixel data is initially loaded and one of the eight shift operations in the shift register is coordinated, Each execution lane in the execution lane array will receive all nine pixel values needed to calculate the average of its corresponding pixel portion into its local register space. Since the processor architecture of FIG. 1 is particularly good at processing image templates, it can also be referred to as a template processor. Further details on possible template processor embodiments and image processor embodiments including one or more of these template processors are provided further in section F below.
B. Block matching routine
FIG. 2 shows a drawing of a block matching routine. Block matching is specifically used for motion estimation (e.g., for video compression), image stabilization, and image fusion algorithms (e.g., exposure fusion and temporal noise fusion). Here, an alternative (e.g., later) image is searched for a specific feature in a first base (e.g., previous) image. In the example of FIG. 2, the block ABCD existing in the base image needs to be found in the substitute image. For simplicity, it is assumed that any other pixel in the replacement image does not have any of the searched block (A, B, C, D) values.
3a to 3d show a method for performing block matching via an image processor having a two-dimensional execution lane array and a two-dimensional shift register array just described with respect to FIG. 1 above. Here, the pixels of the substitute image are located in the first plane of the register space (R0) in the two-dimensional shift register array.
A first pixel value (eg, "A") of the feature being searched for in the base image is broadcast to all execution lanes. Then, along each lane, an absolute difference 302a is calculated based on the contents of the R0 register space and the value "A" (for example, along each lane, the absolute difference operation is calculated as | x-y |, Where x = A and y = R0). Then, the absolute difference result is stored in the R1 register space. In one embodiment, for each track, R1 is initially set equal to 0 and the absolute difference is added to the content of R1. Then, the addition result is stored back to R1. In an embodiment, the instruction format of the SIMD processor includes an immediate operand for broadcasting the pixel value A of the base image used to calculate the absolute difference to each of the execution lanes. Here, if a pixel value of the substitute image in R0 matches (or approximately matches) the broadcast pixel value A, the result in R1 should be (or close to) zero ("0"). All other results in R1 shall be substantially non-zero ("/ 0").
Referring to FIG. 3b, the replacement image is shifted by one unit in the R0 plane of the two-dimensional shift register, and the next pixel value “B” in the searched feature is broadcast to all execution lanes, and the absolute is determined again Difference and add the absolute difference to the content stored in R1. In this way, each lane performs an "absolute difference sum" (SAD) operation. That is, for each iteration, first, an absolute difference between the base image value of the new broadcast (for the iteration of FIG. 3b, line B) and the newly moved replacement image content in R0 is calculated. Then, secondly, the result of the absolute difference is added (added) to the result of the previous SAD operation in R1 (for the iteration of FIG. 3b, the absolute difference calculated in FIG. 3b and the first in FIG. 3 are repeated in R1 The absolute differences calculated over and over again are added). Here, after completing the repeated SAD operation of FIG. 3b, the specific execution lane array portion 301 that has performed two consecutive pixel matches should have the lowest result value in its R1 register space. More specifically, after the iteration of FIG. 3b, the part 301 of FIG. 3b (where the specific broadcast order of the pixel values is aligned with the specific scan / shift motion of the replacement image in R0 of the two-dimensional shift register array) ) Has a value of about zero in its R1 register space.
As seen in Figures 3c and 3d, the program continues to iterate each time, thereby broadcasting a pixel value below the base image, shifting R0 instead of image data in a specific scanning order, and performing a SAD along each lane Operations, which repeatedly calculate an absolute difference between the broadcast value and the R0 shift-in value and then add the absolute difference to the cumulative value of the previous SAD results in R1 302c, 302d. After adequately broadcasting all the searched image pixels of the base image and correspondingly shifting the replacement image in R0 several iterations across an area corresponding to one of the size of the searched image, ideally, at each iteration After that, only one part 301 in the lane array will undergo a match. In this way, after all iterations have been completed, this particular array portion 301 should be able to maintain a value of zero or near zero (or at least one value smaller than another execution lane) in its R1 register space.
Then, a "find the minimum" operation is performed across all the columns in the array on the R1 register space. According to one embodiment of finding a minimum operation, the lowest corresponding value in each column is located at each part of its column. Then, perform a find minimum operation across all rows in the array on the R1 register space. After each iteration, the result should identify the pixels that match the base image, which can then be used to identify the exact location of the searched image in the replacement array. A discussion of one of the embodiments of finding a minimum operation is further provided below in Section D of this specification.
C. With two ALU Of operation SAD instruction
According to the above example, the sum of the absolute difference calculations 302a to 302d occurring after each shift of the substitute image and the broadcast of the next base image value along each execution lane can be expressed as:
R1 ＜ = | R0 – BB
| + R1
Where R0 is the most recently shifted substitute image value, BB
Is the broadcast value below the base image, and R1 contains the cumulative value of all previous sums of absolute difference calculations performed along the same execution lane. The result is also written back to R1. As such, more generally, each execution lane repeatedly performs the following operations:
| x – y | + z
The result is stored in the same register space (R1) that provides the z-input operand. In order to maximize the performance of this calculation, it is expected that each execution lane performs the above calculation with a reduced amount of circuitry and / or fewer circuit operations. Performing SAD operations with fewer circuits and / or fewer circuit operations may, for example, result in improved performance and / or reduced power consumption of SAD calculations.
FIG. 4 shows an initial design of one of the above-mentioned SAD instructions that can execute only one of the three ALU operations. The ALU execution unit circuit 400 (hereinafter referred to as “execution unit”) is an initial design. As seen in FIG. 4, the execution unit 400 includes a first arithmetic logic unit (ALU) circuit 401 and a second ALU circuit 402. As is known in the art, an ALU circuit (hereinafter referred to as "ALU") performs arithmetic operations (such as addition, subtraction, division) and logical operations (such as AND, OR, etc.). The execution unit 400 is responsible for executing various arithmetic and logic code instructions and may use one or two ALUs 401, 402 depending on which of these instructions is being executed. As seen in FIG. 4, the first ALU 401 can receive one of the first input operands X of a command from the local register space of its two-way shift register array, and can temporarily retrieve from the same local register. The memory space receives a second input operand Y of an instruction.
The output of the first ALU 401 can be used as one of the input values Q of the second ALU 402. The second ALU 402 may also receive a third input operand Z of an instruction from the local register space. The second ALU may also receive a fourth input operand R that is multiplexed to one of the instructions in the second ALU 402 from the local register space instead of receiving the Q input value from the first ALU 401. The execution unit 400 may provide a result of one of the instructions directly from the one of the pair of ALUs 401, 402 executing one of the final calculations of one of the instructions. For ease of description, several various other features of the execution unit 400 are not shown, so that the relevant data paths of the current discussion can be emphasized.
Here, the execution unit 400 may execute a three-input ADD instruction.
x + y + z
In two ALU operations. In this case, one of the first adders 403 in the first ALU 401 performs a first x + y addition. The x + y result from the first adder 403 is then passed to the second ALU 402 as an input value Q. The input value Q is passed to a second adder 404 inside the second ALU 402. A multiplexer 405 in the second ALU 402 is also configured to select the input operand Z, and the multiplexer 405 presents Z to the second adder 404. Then, the second adder 404 performs addition (x + y) + z. The self-executing unit 400 presents the result from the second adder 404 as the result of the three-input ADD instruction. Therefore, two ALU operations are performed (one operation from the first ALU 401 and a second operation from the second ALU 402) to execute a three-input ADD instruction (as a single instruction).
Unfortunately, as described above, the execution unit 400 of FIG. 4 can only execute one of the three ALU operations of the two instructions, the SAD operation. Here, the SAD operation can be expressed as:
| x – y | + z
To perform the above operations, the first adder 403 within the first ALU 401 is configured to function as a subtraction unit that provides x-y as its result (instead of providing x + y as its result). The Q value containing the x-y result from the first adder 403 is then passed to the second ALU 402 and presented to the second adder 404. The second adder 404 determines the absolute value of the Q value.
Configuring the second adder 404 to perform an absolute value calculation includes: 1) if Q is a positive number, configuring the second adder 404 to perform a calculation of 0 + Q; or 2) if Q is a negative number, then The second adder 404 is configured to perform calculations 0-Q. Here, with regard to operation 2), as is known in the art, an adder can be configured to manipulate (eg, from 0 to 1) and / or enter a value by manipulating a carry input (eg, from 0 to 1) of one of the adders. One of them performs a logical inversion to perform subtraction. Note that both calculations use an input value = 0. Thus, when the second adder 404 is used to perform an absolute value calculation (as in the case of the SAD operation currently being described), the multiplexer 405 is configured to select 0 channel (instead of Z channel, as above) For the three input ADD instructions described). This traditional use of an adder to perform an absolute value operation uses a single input value operation which may be referred to as ALU 402. That is, when performing this operation, the second ALU 402 receives only one input value Q. It is important that the calculation of the second ALU 402 only completes the calculation of | Q | = | x-y | (an absolute difference). Here, the | Q | results from the second ALU 402 are written from the execution unit 400 to the external register space.
To complete the SAD operation, another ALU operation must be performed to sum up | x – y | and z (= | Q | + z). In this way, the following second ADD instruction is executed: the | Q | term and the z value are read from the register space as input operands and the | Q | term and the z value are provided (for example) to the first ALU 401 to execute the final | x – y | + z are added. In this way, three ALU operations are required to perform a SAD operation: find the first operation of the difference between x-y; find the second operation of the absolute value of | x-y | difference; Add one of the third operations. The first two operations consume a first instruction and the third operation consumes a second instruction. In the case of performing three ALU operations (and two instructions) to calculate a single SAD operation, 3N-1 ALU operations can be consumed, thereby performing a block matching routine on a block containing N pixels.
FIG. 5 shows a modified ALU execution unit 500 capable of performing SAD operations using two ALU operations in a single instruction, rather than performing SAD operations using three ALU operations based on two instructions. Here, reviewing the discussion of the execution unit 400 of FIG. 4, according to the tradition, the second adder 404 is configured to determine only an absolute value by providing the second adder 404 with an internally generated 0 from the multiplexer 405. . In contrast, the improved design of FIG. 5 replaces the value 0 with the input operand z, which is the final addend of the SAD instruction. More specifically, the second adder 504 in the second ALU 502 is configured to perform: 1) the operation z + Q (if Q is a positive number); or 2) the operation z-Q (if Q is a negative number). Therefore, the result of the second adder 504 is | Q | + z = | x-y | + z, which corresponds to the result of the SAD instruction. Note that in this case, unlike the previous design of FIG. 4, the second ALU 502 receives two input values (Q and Z) when performing an operation that includes an absolute value, and the second ALU 402 performs an absolute value operation Only one input value (Q) is received.
As such, the SAD operation is performed with two ALU operations and a single instruction instead of three ALU operations and two instructions. Compared with the execution unit 400 of FIG. 4, this corresponds to an improvement of about 33% of the ALU calculation efficiency (for example, for a block image containing N pixels, 2N ALU calculations can be consumed (instead of 3N-1 calculations for the execution unit 400 of 4))). In an embodiment where the execution lane includes an ALU execution unit with one of two ALUs (similar to the design of FIG. 5), a total of N ALU calculations can be performed to perform one of a block image with N pixels Block matching algorithm.
In various embodiments, as described above, the absolute value function of the aforementioned second ALU 502 is implemented as a double input value function instead of a single input value function. That is, when the second adder performs an absolute value function, an internally generated zero is not provided to the second adder 504. In contrast, in order to use the adder 504 to perform a type of absolute value operation (for example) to execute an absolute value instruction (ABS) instead of a SAD instruction, a value 0 is provided from the scratchpad space to the ALU 502 as one of the ABS instructions Z input operand (value 0 can also be generated internally in the machine and loaded into the register space, or provided directly to the execution unit and / or ALU). In addition, a value input to the ALU 502 and an absolute value determined by the ABS instruction (such as R instead of Q) is multiplexed from the register space into the second ALU 502 as a second input operand of the ABS instruction. Here, rendering Z = 0 to the second ALU 502 causes the adder 504 to operate similarly to a conventional adder that implements an absolute value function. That is, the adder 504 will: 1) perform an operation 0 + R if R is a positive number; or 2) perform 0-R if R is a negative number. Therefore, in these embodiments, as far as the conventional implementation discussed above with respect to FIG. 4 is concerned, whether for a SAD instruction or an ABS instruction, the absolute value operation performed by the second ALU 502 is naturally implemented as a Two input value operation instead of a single input value operation.
In other embodiments, the multiplexer 405 may be embodied in the second adder 502 such that, for example, absolute value operations other than absolute value operations used to support SAD instructions (such as ABS instructions) are dependent on a One of the traditional single-input operand-valued operations that internally generates a value of 0. In other embodiments, the multiplexer 405 may exist in the second adder to, for example, support both single-input absolute value operation and dual-input absolute value operation (the multiplexer selects 0 input for the former, but is The latter choose z). In other embodiments or combined embodiments, the two-input absolute value function as described above may be used to support a new type of absolute value instruction ABS *, where the execution unit 500 performs an operation according to a single instruction | R | + Z, where z Can be any input operand value (and not necessarily 0).
In various embodiments, the execution unit 500 of FIG. 5 can still support the SAD operation (three ALU operations instead of two) as explained above with respect to FIG. 4. This operation may be useful, for example, in situations where the cumulative total may or will consume more bits than the bit width of the machine. Here, the first and second ALU operations (its decision | xy |) can be calculated with a lower accuracy equal to one of the bit width of the machine and the third ALU operation displays the cumulative value list in two or more temporary storages To provide the cumulative value of the machine's natural bit width.
D. Column / Row find minimum operation
6 and 7a to 7d are about a column / row finding minimum operation, and the operation can also be performed by an image processor having a two-dimensional execution channel array and a corresponding two-dimensional shift register. The column / row finding minimum operation is particularly useful for statistical calculations and post-block matching processing as explained in Section B above.
Referring to FIG. 6, for simplicity, only a single column of one of the execution array / register array is shown. However, in a practical implementation, a row of finding the minimum operation may be implemented by the same processor that performs a row of finding the minimum operation. In addition, the minimum value of one column (or row) can be found for any number of columns (or rows) (including up to all columns / rows) in the register array at the same time. In addition, the size of the columns / rows is only shown as 8 parts wide, and the lane and shift register array may be 16 x 16 or larger in the actual implementation.
As seen in FIG. 6, the result of the search for the minimum value in one column corresponds to the minimum value among all values in the same column and its location / location (also referred to as its index) in the column. Similarly, the result of the search for the minimum value in one line corresponds to the minimum value among all the values in the same line and its part / position within the line. As with the column sum and preterm sum operations discussed in detail in the previous section, the column / row find minimum operation uses a two-dimensional shift register that can be scrolled to and from the array edge 701.
FIG. 7a to FIG. 7d show an embodiment of a machine-level operation of a list of pre-term operations. Initially, as seen in FIG. 7a, in the respective R0 register locations of each execution lane, a row is loaded with data values A0 to A7. In addition, the index of each row position is loaded into the R1 register space of each execution lane.
In the first iteration of one of the machine-level operations shown in FIG. 7b, the contents of the R0 and R1 register locations are shifted by one unit to the R2 and R3 registers adjacent to the space of the execution register. Memory space. Then, the respective values of the R0 and R2 registers are compared in each execution lane. The minimum value of the comparison and its corresponding index are stored in the R0 and R1 register spaces. That is, if the value of R0 is smaller than the value of R2, the R0 and R1 registers maintain their original contents. Conversely, if the value of R2 is smaller than the value of R0, the value of R2 is written into R0 and the value of R3 is written into R1. This has the effect of keeping the minimum value of the comparison in R0 and its index in R1.
In the second iteration of one of the machine-level operations shown in FIG. 7c, the contents of the R0 and R1 register locations are shifted by two units to the R2 and R3 register space of the downstream execution lane. in. Therefore, the next iteration shift amount doubles again. Then, the respective values of the R0 and R2 registers are compared in each execution lane. The minimum value of the comparison and its corresponding index are stored in the R0 and R1 register spaces. This has the effect of keeping the minimum value obtained by the two comparisons performed by itself in each execution lane in R0 and maintaining its index in R1.
In the third iteration of one of the machine-level operations seen in Fig. 7d, the contents of the R0 and R1 register locations are shifted by four units to the R2 and R3 register spaces of a downstream execution lane. Then, the respective values of the R0 and R2 registers are compared in each execution lane. The minimum value of the comparison and its corresponding index are stored in the R0 and R1 register spaces. This has the effect of keeping the smallest value in R0 from all three comparisons that it has performed in each execution lane and keeping its index in R1.
After the third iteration, the search for the minimum value is completed. Each execution lane will have the corresponding minimum value of the entire column in its R0 register space and its corresponding index in the R1 register space (originally The column part with the minimum value will find its own identified column part in its R1 register space). If the size of the column is sixteen, then only a set of operations based on the contents of the R0 and R1 registers that are shifted downstream to one of the eight locations in the shift register will be required to provide all sixteen execution points. The minimum of all sixteen different parts of the road.
Figure 8 shows one of the methods explained above. The method includes receiving a first value at a first input of an arithmetic logic unit circuit and receiving a second value at a second input of an arithmetic logic unit circuit, 801. The method includes providing the first value and the second value to an adder circuit, 802, within an arithmetic logic unit circuit. The method includes using the adder circuit to determine an absolute value of a first value, and providing a sum of the second value and one of the absolute values of the first value at an output of the adder circuit, 803.
E. Image processor and template processor embodiment
FIG. 9 illustrates an embodiment of an architecture 900 of an image processor implemented in hardware. For example, the image processor may be the target of a compiler that converts code written for a virtual processor in an analog environment into code that is actually executed by a hardware processor. As seen in FIG. 9, the architecture 900 includes a plurality of line buffer units 901_1 to 901_M, the plurality of line buffer units 901_1 to 901_M passing through a network 904 (for example, a network on a chip (NOC) including an on-chip Switching networks, ring networks on a chip, or other types of networks) are interconnected to a plurality of template processor units 902_1 to 902_N and corresponding form generator units 903_1 to 903_N. In one embodiment, any line buffer unit can be connected to any form generator and corresponding template processor through the network 904.
In one embodiment, the code is compiled and loaded onto a corresponding template processor 902 to perform image processing operations previously defined by a software developer (the code may also be, for example, dependent on the design and implementation) Load to the associated form generator 903 of the template processor). In at least some instances, an image processing pipeline can be implemented by loading a first kernel program for a first pipeline stage into a first template processor 902_1 and using it for a first A second kernel program of one of the two pipeline stages is loaded into a second template processor 902_2, etc., wherein the first kernel executes the functions of the first stage pipeline, the second kernel executes the functions of the second stage pipeline, etc., and additionally controls the flow method It is set to pass the output image data from one pipeline stage to the next pipeline stage.
In other configurations, the image processor may be implemented as a parallel machine that enables two or more template processors 902_1, 902_2 to operate the same kernel code. For example, a high-density and high-data-rate image data stream can be processed by distributing frames of multiple template processors that each perform the same function.
In other configurations, in a DAG design, essentially any DAG of the kernel can be loaded onto the hardware processor by configuring each template processor with its own individual code The kernel also configures appropriate control flow hooks into the hardware to direct the output image from one kernel to the input of the next kernel.
As a general process, a large I / O unit 905 receives a frame of image data and passes it to one or more of the line buffer units 901 frame by frame. A specific line buffer unit parses its image data frame into a smaller image data area (referred to as a "line group"), and then passes the line group to a specific form generator through the network 904. A complete or "full" singular line group may (for example) consist of multiple consecutive complete rows or rows of data in a frame (for simplicity, this description will primarily refer to the consecutive rows). The form generator further analyzes the line group of image data into a smaller image data area (referred to as a "form"), and renders the form to its corresponding template processor.
In the case of an image processing pipeline or a DAG process with a single input, usually, the input frame is directed to the same line buffer unit 901_1, which analyzes the image data into line groups and sets these The line group is guided to the form generator 903_1, and the corresponding template processor 902_1 of the form generator 903_1 is executing the code of the first kernel in the pipeline / DAG. After the template processor 902_1 completes the operation of the line group it processes, the form generator 903_1 immediately sends the output line group to a "downstream" line buffer unit 901_2 (in some use cases, the output can be The line group is sent back to the same line buffer unit 901_1) that had previously sent the input line group.
Then, one or more "consumers" of the presentation pipeline / one level / operation below the DAG performed on its own respective other form generator and template processor (e.g., form generator 903_2 and template processor 902_2) The kernel receives the image data generated by the first template processor 902_1 from the downstream buffer unit 901_2. In this way, one of the "producer" kernels operating on a first template processor advances its output data to one of the "consumer" kernels operating on a second template processor, where after the producer kernel The consumer kernel performs the next set of tasks, which is consistent with the design of the main pipeline or DAG.
A template processor 902 is designed to operate on multiple overlapping image data templates simultaneously. The internal hardware processing capacity of multiple overlapping templates and template processors effectively determines the size of a form. Here, in a template processor 902, a lane array uniform operation is performed to simultaneously process the image data surface area covered by multiple overlapping templates.
As will be explained in more detail below, in various embodiments, the image data sheet is loaded into a two-dimensional register array structure in the template processor 902. It is believed that using a form and a two-dimensional register array structure to effectively provide a power consumption improvement by moving a large amount of data into a large number of register spaces in the form of, for example, a single load operation, which is performed thereafter The lane array immediately performs processing tasks directly on the data. In addition, the use of an execution lane array and corresponding register array provides different template sizes that can be easily programmed / configured.
10a to 10e illustrate, on a high level, the parsing activity of a line buffer unit 901, a finer-grained parsing activity of a form generator unit 903, and template processing of a template processor 902 coupled to the form generator unit 903. Examples of activities.
FIG. 10a illustrates an embodiment of an input frame of the image data 1001. FIG. 10a also shows an outline of three overlapping templates 1002 (each of which has a size of 3 pixels x 3 pixels) operated by a designed template processor. The output pixels containing the output image data generated by each template are highlighted in solid black. For simplicity, three overlapping templates 1002 are shown as overlapping only in the vertical direction. It should be recognized that a template processor may actually be designed to have overlapping templates in both vertical and horizontal directions.
Due to the vertically overlapping templates 1002 in the template processor, as seen in FIG. 10a, there is a wide-band image data in a frame that can be operated by a single template processor. As will be discussed in more detail below, in one embodiment, the template processor processes the data in its overlapping templates across the image data in a left-to-right manner, and then repeats the next line set in order from top to bottom). Therefore, as the template processor continues to advance its operations, the number of solid black output pixel blocks will grow horizontally to the right. As discussed above, a line buffer unit 901 is responsible for analyzing a line group of input image data from an incoming frame, which is sufficient for the template processor to operate within an extended number of upcoming cycles. An exemplary drawing of one line group is illustrated as a shaded area 1003. In one embodiment, the line buffer unit 901 may include different dynamics to send / receive a line group to / from a form generator. For example, according to a mode called "full group", a full-width line of image data is passed between a line buffer unit and a form generator. According to a second pattern called "virtual height", a line group is initially delivered in a full-width column subset. The remaining columns are then passed sequentially in smaller (less than full width) tiles.
In the case that the line group 1003 of the input image data has been defined by the line buffer unit and passed to the form generator unit, the form generator unit further parses the line group into finer forms, and these forms are more accurate Suitable for the hardware limitations of the template processor. More specifically, as will be explained in more detail below, in one embodiment, each template processor consists of a two-dimensional shift register array. The two-dimensional shift register array basically moves the image data "below" an execution lane array, where the shift pattern causes each execution lane to operate on its own data in its own template (i.e. Each execution process processes its own information template to produce one of the other templates' output). In one embodiment, the form is "filled" or otherwise loaded into the surface area of the input image data in the two-dimensional shift register array.
As will be explained in more detail below, in various embodiments, there are actually multiple layers of two-dimensional register data that can be shifted in any cycle. For convenience, this description will only use the term "two-dimensional shift register" and the like to refer to a structure having one or more of these two-dimensional register data layers that can be shifted.
Therefore, as seen in FIG. 10b, the form generator parses the initial form 1004 from one of the line groups 1003 and provides it to the template processor (here, the data form corresponds to the shaded area normally identified by the component symbol 1004). As seen in FIG. 10c and FIG. 10d, the template processor operates the input image data form by effectively moving the overlapping template 1002 on the form in a left-to-right manner. As shown in FIG. 10d, the number of pixels that can be calculated for an output value based on the information in the form is exhausted (other pixel positions may not have an output value determined based on the information in the form). For simplicity, the border area of the image has been ignored.
As seen in Figure 10e, the form generator then provides the next form 1005 for the template processor to continue operation. Note that the initial position where the template starts to operate on the next form is the line running from the exhaustion point on the first form to the right and down (as previously shown in Figure 10d). For the new form 1005, the template will only continue to move to the right, so the template processor operates the new form in the same way as the first form is processed.
Note that there is some overlap between the data of the first form 1004 and the data of the second form 1005 due to the boundary area of the template surrounding an output pixel portion. The overlap can only be handled by having the form generator retransmit the overlapping data twice. In an alternative embodiment, in order to feed the next form to the template processor, the form generator may continue to send only new data to the template processor and the template processor reuses the overlapping data from the previous form.
FIG. 11 shows an embodiment of a template processor architecture 1100. As seen in FIG. 11, the template processor includes a data operation unit 1101, a scalar processor 1102 and an associated memory 1103, and an I / O unit 1104. The data operation unit 1101 includes an execution lane array 1105, a two-dimensional shift array structure 1106, and a separate random access memory 1107 associated with a specific column or row of the array.
The I / O unit 1104 is responsible for loading the "input" data form received from the form generator into the data operation unit 1101 and storing the "output" data form from the template processor into the form generator. In an embodiment, loading the form data into the data operation unit 1101 will cause a received form to be parsed into an image data row / image data row, and load the image data row / image data row into a two-dimensional shift Register structures 1106 or individual random access memories 1107 of rows / rows of the execution lane array (explained in more detail below). If the form is initially loaded into the memory 1107, the individual execution lanes in the execution lane array 1105 may then load form data from the random access memory 1107 into the two-dimensional shift register structure when appropriate. 1106 (for example, just before a form data operation, according to a load instruction). After the loading of a data sheet into the register structure 1106 is completed (whether directly from a form generator or from the memory 1107), the execution of the execution array of the lane array 1105 operates on the data and will be processed at the end. The completed data is "written back" directly to the form generator in a form or into the random access memory 1107. If written into the random access memory 1107, the I / O unit 1104 extracts data from the random access memory 1107 to form an output form, and then the output form is pushed to the form generator.
The scalar processor 1102 includes a program controller 1109. The program controller 1109 reads the instructions of the template processor code from the scalar memory 1103 and sends the instructions to the execution lane in the execution lane array 1105. In one embodiment, a single same instruction is broadcast to all execution lanes in the array 1105 to achieve a SIMD-like behavior of the data operation unit 1101. In one embodiment, the instruction format of the instruction for executing the lane read from the scalar memory 1103 and issued to the execution lane array 1105 includes a very long instruction word (VLIW) type format including one or more operation codes per instruction . In another embodiment, the VLIW format includes: an ALU operation code that directs a mathematical function to be performed by each execution ALU (as explained below, in one embodiment the ALU may specify more than one traditional ALU operation) ); And a memory operation code, which guides a specific execution of a lane or a memory operation of a specific set of lanes).
The term "execution lane" refers to a collection containing one or more execution units capable of executing an instruction (e.g., a logic circuit that can execute an instruction). However, in various embodiments, an execution lane may include the functionality of more types of processors beyond the execution unit. For example, in addition to one or more execution units, an execution lane may include logic circuits that decode a received instruction, or in the case of a MIMD-like design, logic circuits that extract and decode an instruction. Regarding the MIMD-like method, although a central program control method has been mainly described in this article, a more decentralized method may be implemented in various alternative embodiments (for example, each execution lane of the array 1105 contains a code and a Program controller).
The combination of an execution lane array 1105, a program controller 1109, and a two-dimensional shift register structure 1106 provides a wide range of programmable functions to provide a highly adaptable / configurable hardware platform. For example, since individual execution lanes can perform a variety of functions and can easily access input image data near any output array location, application software developers can have a wide range of different functional capabilities and sizes (E.g., template size) kernel stylization.
In addition to being used as a data storage device for image data operated by the lane array 1105, the random access memory 1107 can also store one or more lookup tables. In various embodiments, one or more scalar lookup tables can also be embodied in the scalar memory 1103.
A scalar lookup involves passing the same data value from the same lookup table to each of the execution lanes in the execution lane array 1105 according to the same index. In various embodiments, the VLIW instruction format described above is extended to also include a scalar opcode, which directs a lookup operation performed by a scalar processor into a scalar lookup table. An index specified for use with an opcode can be an immediate operand or it can be extracted from some other data storage location. However, in one embodiment, during the same clock cycle, a lookup from one of the scalar lookup tables in the scalar memory basically involves broadcasting the same data value to all execution lanes in the execution lane array 1105. . Additional details on the use and operation of lookup tables are provided below.
Figure 11b summarizes the VLIW instruction word embodiment discussed above. As seen in Figure 11b, the VLIW instruction word format contains fields for three separate instructions: 1) a scalar instruction 1151, which is executed by a scalar processor; 2) an ALU instruction 1152, which is executed by an execution lane array The respective ALUs are broadcast and executed in SIMD mode; and 3) a memory instruction 1153 is broadcast and executed in a part of SIMD mode (for example, if the execution lanes along the same row in the execution lane array share the same Random access memory, one execution lane from each of the different rows actually executes the instruction (the format of the memory instruction 1153 may include identifying which execution lane from each row performs one of the operations of the instruction yuan).
A field 1154 for one or more immediate operands is also included. In the instruction format, it is possible to identify which of the instructions 1151, 1152, 1153 uses which immediate operation meta information. Each of the instructions 1151, 1152, 1153 also contains its own separate input operands and result information (e.g., a local register for ALU operations and a local register for memory access instructions). Register and a memory address). In one embodiment, the scalar processor first executes a scalar instruction 1151, and then executes an execution lane in the lane array before executing any of the other instructions 1152, 1153. That is, the execution of the VLIW word includes executing a first cycle of a scalar instruction 1151, followed by a second cycle of another instruction 1152, 1153 (note that in various embodiments, the instructions 1152 and 1153 may be executed in parallel carried out).
In one embodiment, the scalar instruction executed by the scalar processor includes issuing to the form generator to load the form from the data operation unit's memory or 2D shift register / storing the form to memory or 2D Command in shift register. Here, the operation of the form generator may depend on the operation of the line buffer unit or prevent other variables that include the number of cycles spent by the expression generator before the execution phase to complete any command issued by the scalar processor. Thus, in an embodiment, any scalar instruction 1151 corresponding to or otherwise causes a command to be issued to the form generator also includes a VOPW instruction in the other two instruction fields 1152 and 1153. . Then, the code enters one of the NOOP instructions in the instruction field 1152 and 1153 until the form generator finishes loading / saving to the data operation unit. Here, after sending a command to the form generator, the scalar processor can immediately set a bit of an interlock register, and the form generator resets the bit after the command is completed. During the NOOP loop, the scalar processor monitors the bits of the interlock bit. When the scalar processor detects that the form generator has completed its command, it resumes normal execution.
FIG. 12 shows an embodiment of a data operation component 1201. As seen in FIG. 12, the data operation component 1201 includes an execution lane array 1205 logically positioned on one of the “upper” two-dimensional shift register array structures 1206. As discussed above, in various embodiments, an image data form provided by a form generator is loaded into the two-dimensional shift register 1206. Then, perform a lane operation on the form data from the register structure 1206.
The execution lane array 1205 and the shift register structure 1206 are fixed in place relative to each other. However, the data in the shift register array 1206 is shifted in a strategic and coordinated manner such that each execution lane in the execution lane array processes a different template in the data. In this way, the output image value of a different pixel in the output form generated by each execution of the lane determination. According to the structure of FIG. 12, it should be clear that the overlapping templates are not only arranged vertically but also horizontally, just as the execution lane array 1205 includes vertically adjacent execution lanes and horizontally adjacent execution lanes.
Some notable architectural features of the data operation unit 1201 include the shift register structure 1206 having a wider size than the execution lane array 1205. That is, there is a "ring" of the register 1209 outside the execution lane array 1205. Although the ring 1209 is shown as being present on both sides of the execution lane array, depending on the implementation, the ring may be present on fewer (one) or more (three or four) sides of the execution lane array 1205. The ring 1209 is used to provide "overflow" space for data that overflows the boundaries of the execution lane array 1205 when the data is moving "below" the execution lane 1205. As a simple case, when processing the leftmost pixel of the template, a 5 x 5 template centered on the right edge of the execution lane array 1205 will further require four ring register locations on the right. For simplicity, when in a nominal embodiment, FIG. 12 shows the register on the right side of the ring as having only a horizontal shift connection and the register on the bottom side of the ring as having only a vertical shift. Connection, the registers on either side (right, bottom) will have both horizontal and vertical connections. In various embodiments, the ring zone does not include corresponding execution lane logic for executing image processing instructions (eg, no ALU exists). However, there is an individual memory access unit (M) in each of the ring regions, so that the individual ring register regions can individually load data from the memory and store the data into the memory.
Random access memory 1207 provides additional overflow space, and random access memory 1207 is coupled to each row and / or each row or portion thereof in the array (e.g., a random access memory can be assigned to across four executions The lanes and one "zone" of the execution lane array of the two execution lanes. For simplicity, the rest of this application will mainly refer to the allocation scheme based on ranks and / or rows). Here, if a kernel operation for performing a channel needs to process pixel values outside the two-dimensional shift register array 1206 (some image processing routines may require), the image data plane can be further (for example) from region 1209 Overflow into random access memory 1207. For example, consider a 6 × 6 template in which the hardware on one of the right edges of the execution lane array includes the ring region of only four storage elements on the right side of the execution lane. In this case, the data will need to be further shifted to the right of the right edge of the ring 1209 to fully process the template. Then, the data moved outside the ring area 1209 will overflow to the random access memory 1207. Further applications of the random access memory 1207 and the template processor of FIG. 11 are provided below.
13a to 13k illustrate one working example of a method for moving image data into the two-dimensional shift register array located "below" the execution lane array as mentioned above. As seen in FIG. 13a, the data content of the two-dimensional shift array is shown as being located in a first array 1307 and the execution lane array is shown by a frame 1305. In addition, two adjacent execution lanes 1310 in the execution lane array are simplified shown. In this simplified drawing 1310, each execution lane includes a register R1. The register R1 can receive data from a self-shifting register and receive data from an ALU output (for example, to be used as a spanning loop). Accumulation factor), or write output data to an output destination.
Each execution lane also has available content in the local register R2, that is, the content located "below" the execution lane in the two-dimensional shift array. Therefore, R1 is a physical register that performs a lane division, and R2 is a physical register that is a two-dimensional shift register array. Execution lanes include one of the ALUs that can perform operations on the operands provided by R1 and / or R2. As will be explained in more detail below, in one embodiment, multiple (one "depth") storage / register elements are actually implemented at each array position of the shift register, but the shifting activity is limited to the storage elements One plane (eg, only one plane of the storage element can be shifted per cycle). Figures 13a to 13k show one of these deeper register locations for storing the results X from the respective execution lanes. For ease of illustration, the deeper results register is depicted on the side rather than below its corresponding register R2.
Figures 13a to 13k focus on the calculation of two templates whose central position is aligned with the execution lane position pair 1311 shown in the execution lane array. For ease of illustration, the execution lane pair 1311 is depicted as a horizontal neighbor, but in fact it is a vertical neighbor according to the following example.
As initially seen in Figure 13a, the execution lane is centered on its central template site. Figure 13b shows the destination code executed by the two execution lanes. As seen in FIG. 13b, the code executing the lane shift causes the data in the shift register array to be shifted down one position and to the right by one position. This aligns the two execution lanes to the corners of the upper left side of their respective templates. The code then causes the data located in its various parts (located in R2) to be loaded into R1.
As can be seen in Figure 13c, the next code causes the execution lane pair to shift the data in the shift register array one unit to the left, which causes the values on the right side of the respective positions of each execution lane to be shifted to In the position of each execution lane. Then, the value in R1 (previous value) is added to the new value in the position (in R2) that has been shifted to the execution lane. Write the result to R1. As seen in Figure 13d, the same procedure described above for Figure 13c is repeated, so that register R1 now contains the value A + B + C in the upper execution lane and the value F + G + in the lower execution lane. H. At this point, the two execution lanes have processed the upper columns of their respective templates. Note the overflow in a ring area on the left side of the execution lane array (in the case of a ring area on the left side), or in the case of a ring area on the left side of the execution lane array Body overflow.
As seen in Figure 13e, after the code causes the two execution lanes to align with the right edge of the middle row of their respective templates, the code then immediately shifts the data in the shift register array by one unit. The two registers R1 of the execution lane currently contain the sum of the rightmost values of the top and middle columns of the template. Figures 13f and 13g illustrate moving forward to the left across the middle of the two execution lane templates. The accumulation continues so that at the end of the processing of FIG. 13g, the two execution lanes include the sum of the values of the top and middle columns of their respective templates.
Figure 13h shows another shift to align each execution lane with its lowermost column of the corresponding template. Figures 13i and 13j show continuing shifts to complete processing during the execution of the template for lane division. FIG. 13k shows additional shifts to align each execution lane with its correct position in the data array and write the results to that correct position.
In the examples of FIG. 13a to FIG. 13k, it is noted that the purpose code used for the shift operation may include an instruction format identifying one of a shift direction and a shift magnitude value expressed in (X, Y) coordinates. For example, the destination code for shifting to one of the previous positions can be expressed as a shift of 0, +1 in the destination code. As another example, shifting to one of the right parts can be expressed as shifting +1.0 in the destination code. In various embodiments, a larger number of shifts (eg, a shift of 0, +2) may also be specified in the destination code. Here, if the 2D shift register hardware supports only one shift per cycle, the instructions can be interpreted by the machine as requiring multiple cycles to execute, or the 2D shift register hardware can be designed to support each cycle Shift more than one site. The latter embodiment is explained in further detail below.
FIG. 14 shows another more detailed drawing of a unit cell of an execution lane and a corresponding shift register structure (in various embodiments, the register in the ring zone does not include a corresponding execution lane but includes A memory unit). In one embodiment, execution lanes are implemented by instantiating the circuit seen in FIG. 14 at each node of the execution lane array and the register space associated with each location in the execution lane array. As seen in Figure 14, the unit cell includes an execution lane 1401 coupled to one of the register files 1402 consisting of four registers R2 to R5. During any loop, the execution lane 1401 can be read from or written to any of the registers R1 to R5 or written to any of the registers R1 to R5. For instructions that require two input operands, execution lanes can retrieve two operands from any of R1 to R5.
In one embodiment, the two-dimensional shift register structure is implemented by allowing the contents of any one of the registers R2 to R4 (only one) to pass through the output multiplexer 1403 during a single cycle. "Move out" to the register file of its neighbors, and cause the contents of any one (only one) of the registers R2 to R4 to be input from one of its neighbors through the input multiplexer 1404 The content of "shift in" is replaced, so that the shifts between neighbors are in the same direction (for example, all execution lanes are shifted left, all execution lanes are shifted right, etc.). Although the same register may usually have its content moved out and replaced by the moved content within the same cycle, multiplexer configurations 1403, 1404 allow different sources of shifts and movement within the same register file during the same cycle Bit target register.
As illustrated in FIG. 14, note that during a shift sequence, an execution lane will move content from its register file 1402 to each of its left, right, top, and bottom neighbors. In combination with the same shift sequence, execution lanes will also shift the content from one of its left, right, top, and bottom neighbors to its register file. In addition, for all execution lanes, the move-out target and move-in source should be consistent with the same move direction (for example, if move out to the right neighbor, move in should come from the left neighbor).
Although in one embodiment only the contents of one register are allowed to be shifted per lane per execution, other embodiments may allow the contents of more than one register to be moved in / out. For example, if the second instance of one of the multiplexer circuits 1403, 1404 seen in FIG. 14 is incorporated into the design of FIG. 14, the contents of the two registers can be moved in / out during the same cycle. Of course, in embodiments where only one register is allowed to be shifted per cycle, multiple clock cycles can occur between mathematical operations by shifting between mathematical operations, which consumes more clock cycles. (For example, the contents of two registers can be shifted by consuming two shift operations between mathematical operations).
If all the contents of the register file that is not an execution lane are removed during a shift sequence, note that the contents of the non-removable register of each execution lane are still in place (not shifted). In this way, any non-shifted content that has not been replaced by the shifted-in content across the shift loop remains at the execution end. The memory unit ("M") seen in each execution lane is used to load / store data from the random access memory space associated with the execution lane rows and / or rows within the execution lane array. To the random access memory space. Here, the M unit is used as a standard M unit, because it is usually used to load / store the own register space of the non-executable lane. Load / not be stored into the own register of the execute lane. Information about space. In various embodiments, the main operation of the M unit is to write data from a local register into the memory, and read data from the memory and write it into a local register.
Regarding the ISA operation codes supported by the ALU unit of the hardware execution lane 1401, in various embodiments, the mathematical operation codes supported by the hardware ALU include, for example, ADD, SUB, MOV, MUL, MAD, ABS, ABS * , DIV, SHL, SHR, MIN / MAX, SEL, AND, OR, XOR, NOT, CLAZ, FINDMIN, and SAD. As explained just above, execution lane 1401 can execute a memory access instruction to extract data from its associated random access memory / store data to its associated random access memory. In addition, the hardware execution lane 1401 supports shift operation instructions (right, left, up, down) to shift the data in the two-dimensional shift register structure. As explained above, the program control instructions are mainly executed by the scalar processor of the template processor.
F. 实施 例 例 Implementation Examples
It should be noted that the various image processor architecture features described above are not necessarily limited to image processing in the traditional sense, and therefore can be used in other applications that can (not) cause the image processor to be re-characterized. For example, compared to processing actual camera images, if any of the various image processor architecture features described above are used to form and / or generate and / or reproduce animations, the image processor may be referred to as a Graphics processing unit. In addition, the image processor architecture features described above can be used in other technical applications, such as video processing, view processing, image recognition, and / or machine learning. Applied in this manner, the image processor may be integrated with a more general-purpose processor (eg, a CPU or part of a CPU) (eg, as a co-processor), or may be a stand-alone within a computing system processor.
The hardware design embodiments discussed above may be embodied in a semiconductor wafer and / or embodied as a description of a circuit design ultimately directed to a semiconductor manufacturing process. In the latter case, these circuit descriptions can take the following form: a (for example, VHDL or Verilog) register transfer level (RTL) circuit description, a gate-level circuit description, a transistor-level circuit description, or a mask Explain or various combinations of the above. The circuit description is usually embodied on a computer-readable storage medium (such as a CD-ROM or other type of storage technology).
According to the preceding sections, it should be recognized that one of the image processors described above may be embodied as hardware on a computer system (e.g., a system on a chip (SOC) for a handheld device that processes data from a camera of a handheld device ) Part). In the case where the image processor is embodied as a hardware circuit, it is noted that the image data processed by the image processor can be received directly from a camera. Here, the image processor may be part of a discrete camera or part of a computing system with an integrated camera. In the latter case, the image data can be received directly from the camera or from the system memory of the computing system (for example, the camera sends its image data to the system memory instead of the image processor). It is also noted that many of the features described in the previous sections can be applied to a graphics processor unit (which reproduces animation).
FIG. 15 provides an exemplary drawing of a computing system. Many of the components of the computing system described below are suitable for a computing system (eg, a handheld device such as a smart phone or tablet) with an integrated camera and associated image processor. Those skilled in the art will be able to easily distinguish between the two. In addition, the computing system of FIG. 15 also includes many features of a high-performance computing system, such as a workstation or a supercomputer.
As seen in FIG. 15, the basic computing system may include a central processing unit 1501 (for example, it may include a plurality of general-purpose processing cores 1515_1 to 1515_N and a main memory disposed on a multi-core processor or application processor Controller 1517), system memory 1502, a display 1503 (e.g., touch screen, tablet), a local wired point-to-point link (e.g., USB) interface 1504, various network I / O functions 1505 (such as a Ethernet interface and / or cellular modem subsystem), a wireless local area network (e.g., WiFi) interface 1506, a wireless point-to-point link (e.g., Bluetooth) interface 1507, and a global positioning system interface 1508, various The sensors 1509_1 to 1509_N, one or more cameras 1510, a battery 1511, a power management control unit 1512, a speaker and microphone 1513, and an audio encoder / decoder 1514.
An application processor or multi-core processor 1550 may include one or more general-purpose processing cores 1515, one or more graphics processing units 1516, a memory management function 1517 (e.g., a memory control Device), an I / O control function 1518, and an image processing unit 1519. The general-purpose processing core 1515 usually executes application software of an operating system and a computing system. The graphics processing unit 1516 typically performs graphics-intensive functions to, for example, generate graphics information presented on the display 1503. The memory control function 1517 interfaces with the system memory 1502 to write data to the system memory 1502 or read data from the system memory 1502. The power management control unit 1512 generally controls the power consumption of the system 1500.
The image processing unit 1519 may be implemented according to any one of the image processing unit embodiments described in detail in the foregoing sections. Alternatively or in combination, the IPU 1519 may be coupled to either or both of the GPU 1516 and the CPU 1501 as a co-processor. In addition, in various embodiments, the GPU 1516 may implement any of the image processor features detailed above. In addition, any of the general-purpose processing cores, image processing units, and / or GPUs may utilize the arithmetic logic unit design and / or instructions set forth above.
Each of the touch screen display 1503, the communication interface 1504-1507, the GPS interface 1508, the sensor 1509, the camera 1510, and the speaker / microphone codecs 1513, 1514 can all be considered relative to where appropriate. Various forms of I / O (input and / or output) of a total computing system including an integrated peripheral device (eg, one or more cameras 1510). Depending on the implementation, each of these I / O components may be integrated on the application processor / multi-core processor 1550 or may be located off-die or in the package of the application processor / multi-core processor 1550 external.
In one embodiment, the one or more cameras 1510 include a depth camera capable of measuring the depth between the camera and an object in its field of view. Application software, operating system software, device driver software, and / or firmware running on a general-purpose CPU core (or an instruction execution pipeline to execute other functional blocks of code) of an application processor or other processor The body can perform any of the functions described above.
Embodiments of the invention may include various procedures described above. Such programs may be embodied as machine-executable instructions. Instructions can be used to cause a general-purpose or special-purpose processor to execute a particular program. Alternatively, these procedures may be performed by specific hardware components containing fixed-line and / or programmable logic for executing the procedures or by any combination of programmed computer components and custom hardware components.
Elements of the present invention may also be provided as a machine-readable medium for storing machine-executable instructions. Machine-readable media may include, but are not limited to: floppy disks, optical disks, CD-ROMs and magneto-optical disks, FLASH memory, ROM, RAM, EPROM, EEPROM, magnetic or optical cards, propagation media, or other types suitable for storing electronic instructions Media / machine-readable media. For example, the present invention can be downloaded as a computer program, and the computer program can be downloaded from a data link embodied in a carrier wave or other media via a communication link (for example, a modem or a network connection). A remote computer (for example, a server) is transmitted to a requesting computer (for example, a client).
In the foregoing specification, the invention has been described with reference to specific illustrative embodiments thereof. However, it will be apparent that various modifications and changes can be made to the present invention without departing from the broader spirit and scope of the invention as set forth in the scope of the accompanying patent application. Therefore, the description and drawings should be regarded as illustrative and not restrictive.
In the following, some examples are explained.
Example 1: An execution unit circuit including:
An arithmetic logic unit (ALU) circuit including a first input for receiving a first value and a second input for receiving a second value. The ALU circuit includes one for determining the first value. A circuit that adds the absolute value to the second value, the first input is coupled to a first data path including a register space and an output of another ALU of the execution unit circuit as the As an alternative source of the first value, the second input is coupled to a second data path including the register space as a source of the second value.
Example 2: The execution unit circuit of Example 1, wherein the circuit includes an adder circuit.
Example 3: The execution unit circuit of Example 2, wherein the adder circuit is used to:
If the first value is a positive number, add the first value to the second value;
If the first value is negative, the first value is subtracted from the second value.
Example 4: The execution unit circuit of at least one of the previous examples, wherein the ALU circuit executes an instruction for receiving a first input operand and a second input operand, and the instruction is used for the first input operand The two-input operand is added to one of the absolute values of the first input operand. The ALU circuit receives the first input operand from the register space as the first value along the first data path. The ALU The circuit receives the second input operand from the register space along the second data path as the second value.
Example 5: The execution unit circuit of at least one of the previous examples, wherein the ALU circuit also executes another instruction that determines an absolute difference between the first input operand and the second input operand and The absolute difference is added to a third input operand, and the ALU circuit receives a difference between the first input operand and the second input operand from another ALU circuit along the first data path as the First value, the ALU circuit receives the third input operand from the register space along the second data path as the second value.
Example 6: The execution unit circuit of at least one of the previous examples, wherein the ALU circuit executes an instruction that determines an absolute difference between the first input operand and the second input operand and sets the absolute The difference is added to a third input operand, and the ALU circuit receives a difference between the first input operand and the second input operand from another ALU circuit along the first data path as the first input operand. Value, the ALU circuit receives the third input operand from the register space along the second data path as the second value.
Example 7: The execution unit circuit of at least one of the previous examples, wherein the instruction is completed when the ALU circuit completes the addition of the first value and the second value.
Example 8: The execution unit circuit of at least one of the previous examples, wherein the ALU circuit is a component in an image processor.
Example 9: The execution unit circuit of at least one of the previous examples, wherein an image processor architecture includes an execution array coupled to one of a two-dimensional shift register array.
Example 10: The execution unit circuit of at least one of the previous examples, wherein the image processor is configured to perform a block matching of pixel data.
Example 11: An execution unit circuit as in at least one of the previous examples, wherein the image processor is configured to perform a column / row finding minimum operation, specifically with a two-dimensional execution lane array and a corresponding two-dimensional One of the shift registers is executed on the image processor.
Example 12: The execution unit circuit of at least one of the previous examples, wherein the architecture of the image processor includes at least one of a line buffer, a form generator, and / or a template processor.
Example 13: The execution unit circuit of Example 12, wherein the template processor is configured to process overlapping templates.
Example 14: An execution unit circuit as in at least one of the previous examples, wherein a data operation unit includes a shift register structure having a wider width than the execution lane array, and in particular the execution lane array There are registers outside.
Example 15: A method executed by a processor, comprising:
Receive an instruction;
The instruction is executed using an arithmetic logic unit circuit of the processor, and the execution of the instruction includes the following a), b), and c):
a) receiving a first value at a first input of the arithmetic logic unit circuit and receiving a second value at a second input of the arithmetic logic unit circuit;
b) providing the first value and the second value to an adder circuit in the arithmetic logic unit circuit;
c) using the adder circuit to determine an absolute value of the first value, and providing the sum of the second value and one of the absolute values of the first value at an output of the adder circuit.
Example 16: The method of Example 15, wherein the first value is received from another arithmetic logic unit circuit of the processor.
Example 17: The method of Example 15 or 16, wherein the instruction is a sum of one of the absolute difference instructions.
Example 18: The method of at least one of Examples 15 to 17, wherein the instruction is an absolute value instruction and the second value is set equal to zero.
Example 19: The method of at least one of Examples 15 to 18, wherein an image processor architecture performs an on-array operation coupled to one of a two-dimensional shift register array.
Example 20: The method of at least one of Examples 15 to 19, wherein the image processor performs a block matching of pixel data.
Example 21: The method according to at least one of Examples 15 to 20, wherein the image processor performs a column / row finding minimum operation, specifically, having a two-dimensional execution lane array and a corresponding two-dimensional shift register Run on one of the image processors.
Example 22: The method of at least one of Examples 15 to 21, wherein the architecture of the image processor includes at least one of a line buffer, a form generator, and / or a template processor.
Example 23: The method of Example 22, wherein the template processor processes overlapping templates.
Example 24: The method as in at least one of Examples 15 to 23, wherein a data operation unit includes a shift register structure having a wider width than the execution lane array, and particularly in the execution lane array There are external registers.
Example 25: A computing system including:
Multiple general-purpose processors;
A system memory
A memory controller coupled to the system memory;
An image processor includes an execution unit circuit for executing an instruction. The execution unit circuit includes an arithmetic logic unit (ALU) circuit. The ALU circuit includes a first input for receiving a first value and a first value. To receive a second input of a second value, the ALU circuit includes a circuit for determining an absolute value of the first value and adding the absolute value to the second value during execution of the instruction. The input is coupled to a first data path including a register space and an output of another ALU of the execution unit circuit as an alternative source of the first value, and the second input is coupled to one including the register space. The second data path is used as a source of the second value.
Example 26: The computing system of Example 25, wherein the circuit includes an adder circuit.
Example 27: The computing system of Example 25 or 26, wherein the adder circuit is used to:
If the first value is a positive number, add the first value to the second value;
If the first value is negative, the first value is subtracted from the second value.
Example 28: The computing system of at least one of Examples 25 to 27, wherein the instruction receives a first input operand and a second input operand, and the instruction receives the second input operand and the first input operand Adding an absolute value, the ALU circuit receives the first input operand as the first value, and the ALU circuit receives the second input operand as the second value.
Example 29: The computing system according to at least one of Examples 25 to 28, wherein the execution unit circuit also executes determining an absolute difference between the first input operand and the second input operand and comparing the absolute difference with a third Another instruction of adding input operands, the ALU circuit receives a difference between the first input operand and the second input operand from another ALU circuit of the execution unit circuit as the first value, the The ALU circuit receives the third input operand as the second value.
Example 30: The computing system according to at least one of Examples 25 to 29, wherein the instruction is used to determine an absolute difference between the first input operand and the second input operand and calculate the absolute difference with a third input operand Element addition, the ALU circuit receives a difference between the first input operand and the second input operand from another ALU circuit of the execution unit circuit as the first value, and the ALU circuit receives the third An operand is input as the second value.
Example 31: The computing system of at least one of Examples 25 to 30, wherein when the ALU circuit completes the addition of the first value and the second value, the execution unit completes execution of the instruction.
Example 32: The computing system of at least one of Examples 25 to 31, wherein the image processor includes an execution lane array and a two-dimensional shift register array.
Example 33: The computing system of at least one of Examples 25 to 32, wherein an image processor architecture includes an execution array coupled to one of a two-dimensional shift register array.
Example 34: The computing system of at least one of Examples 25 to 33, wherein the image processor is configured to perform a block matching of pixel data.
Example 35: The computing system of at least one of Examples 25 to 34, wherein the image processor is configured to perform a column / row finding minimum operation, specifically, having a two-dimensional execution lane array and a corresponding two Dimension shift register is executed on one image processor.
Example 36: The computing system of at least one of Examples 25 to 35, wherein the architecture of the image processor includes at least one of a line buffer, a form generator, and / or a template processor.
Example 37: The computing system of Example 36, wherein the template processor is configured to process overlapping templates.
Example 38: The computing system of at least one of Examples 25 to 37, wherein a data operation unit includes a shift register structure having a wider width than the execution lane array, and specifically at the execution lane array There are registers outside.
100‧‧‧獨特影像處理器架構/處理器 100‧‧‧Unique image processor architecture / processor
101‧‧‧執行分道陣列 101‧‧‧Execution lane array
102‧‧‧二維移位暫存器陣列/移位暫存器陣列 102‧‧‧Two-dimensional shift register array / shift register array
103‧‧‧隅角執行分道 103‧‧‧ Corner execution
104‧‧‧隅角移位暫存器部位 104‧‧‧ Corner shift register
105‧‧‧隅角執行分道 105‧‧‧ Corner
106‧‧‧隅角移位暫存器部位 106‧‧‧ Corner shift register
301‧‧‧特定執行分道陣列部位/部位/特定陣列部位 301‧‧‧Specific execution lane array part / part / Specific array part
302a至302d‧‧‧絕對差/絕對差計算 302a to 302d‧‧‧‧Absolute difference / absolute difference calculation
400‧‧‧執行單元電路/執行單元 400‧‧‧ execution unit circuit / execution unit
401‧‧‧第一算術邏輯單元電路/算術邏輯單元電路 401‧‧‧first arithmetic logic unit circuit / arithmetic logic unit circuit
402‧‧‧第二算術邏輯單元電路/算術邏輯單元電路 402‧‧‧Second Arithmetic Logic Unit Circuit / Arithmetic Logic Unit Circuit
403‧‧‧第一加法器 403‧‧‧first adder
404‧‧‧第二加法器 404‧‧‧Second Adder
405‧‧‧多工器 405‧‧‧Multiplexer
500‧‧‧經改良算術邏輯單元執行單元/執行單元 500‧‧‧ Improved arithmetic logic unit execution unit / execution unit
502‧‧‧第二算術邏輯單元/算術邏輯單元 502‧‧‧Second Arithmetic Logic Unit / Arithmetic Logic Unit
504‧‧‧第二加法器/加法器 504‧‧‧Second Adder / Adder
701‧‧‧陣列邊緣部位 701‧‧‧Array edge
901_1至901_M‧‧‧線緩衝器單元 901_1 to 901_M‧‧‧ line buffer unit
902_1至902_N‧‧‧模板處理器單元 902_1 to 902_N‧‧‧ template processor unit
903_1至903_N‧‧‧表單產生器單元 903_1 to 903_N‧‧‧‧form generator unit
904‧‧‧網路 904‧‧‧Internet
905‧‧‧大型輸入/輸出單元 905‧‧‧large input / output unit
1001‧‧‧影像資料 1001‧‧‧Image data
1002‧‧‧重疊模板/垂直重疊模板 1002‧‧‧ Overlap Template / Vertical Overlay Template
1003‧‧‧陰影區/線群組 1003‧‧‧Shaded area / line group
1004‧‧‧初始表單/第一表單 1004‧‧‧Initial Form / First Form
1005‧‧‧表單/新表單/第二表單 1005‧‧‧form / new form / second form
1100‧‧‧模板處理器架構 1100‧‧‧ template processor architecture
1101‧‧‧資料運算單元 1101‧‧‧Data Operation Unit
1102‧‧‧純量處理器 1102‧‧‧ scalar processor
1103‧‧‧相關聯記憶體/純量記憶體 1103‧‧‧Associative memory / scalar memory
1104‧‧‧輸入/輸出單元 1104‧‧‧Input / Output Unit
1105‧‧‧執行分道陣列/陣列 1105‧‧‧Performs lane array / array
1109‧‧‧程式控制器 1109‧‧‧Program Controller
1151‧‧‧純量指令/指令 1151‧‧‧ scalar instruction / instruction
1152‧‧‧算術邏輯單元指令/指令/指令域 1152‧‧‧ Arithmetic Logic Unit Instruction / Instruction / Instruction Field
1153‧‧‧記憶體指令/指令/指令域 1153‧‧‧Memory command / command / command field
1154‧‧‧域 1154‧‧‧domain
1201‧‧‧資料運算組件/資料運算單元 1201‧‧‧Data Operation Unit / Data Operation Unit
1206‧‧‧二維移位暫存器陣列結構/二維移位暫存器/暫存器結構/移位暫存器結構/移位暫存器陣列 1206‧‧‧Two-dimensional shift register array structure / Two-dimensional shift register / register structure / shift register structure / shift register array
1209‧‧‧暫存器/環/區/環區 1209‧‧‧Register / Ring / Zone / Ring Zone
1305‧‧‧圖框 1305‧‧‧Frame
1307‧‧‧第一陣列 1307‧‧‧First Array
1310‧‧‧鄰近執行分道 1310‧‧‧ Adjacent execution lane
1311‧‧‧執行分道位置對 1311 ‧ ‧ ‧ Performed lane alignment
1401‧‧‧執行分道/硬體執行分道 1401‧‧‧Execution lane / hardware execution lane
1402‧‧‧暫存器檔案 1402‧‧‧Register
1403‧‧‧輸出多工器/多工器配置/多工器電路 1403‧‧‧Output Multiplexer / Multiplexer Configuration / Multiplexer Circuit
1404‧‧‧輸入多工器/多工器配置/多工器電路 1404‧‧‧Input Multiplexer / Multiplexer Configuration / Multiplexer Circuit
1500‧‧‧控制系統 1500‧‧‧control system
1501‧‧‧中央處理單元 1501‧‧‧Central Processing Unit
1502‧‧‧系統記憶體 1502‧‧‧System memory
1503‧‧‧顯示器/觸控螢幕顯示器 1503‧‧‧Display / Touch Screen Display
1504‧‧‧本端有線點對點鏈路介面 1504‧‧‧ local wired point-to-point link interface
1505‧‧‧通信介面/網路輸入/輸出功能 1505‧‧‧ communication interface / network input / output function
1506‧‧‧通信介面/無線區域網路介面 1506‧‧‧Communication Interface / Wireless LAN Interface
1507‧‧‧通信介面/無線點對點鏈路介面 1507‧‧‧communication interface / wireless point-to-point link interface
1508‧‧‧全球定位系統介面 1508‧‧‧Global Positioning System Interface
1509_1至1509_N‧‧‧感測器 1509_1 to 1509_N‧‧‧ sensors
1510‧‧‧相機 1510‧‧‧ Camera
1511‧‧‧電池 1511‧‧‧ Battery
1512‧‧‧電力管理控制單元 1512‧‧‧Power Management Control Unit
1515_1至1515_N‧‧‧一般用途處理核心 1515_1 to 1515_N‧‧‧ General-purpose processing core
1516‧‧‧圖形處理單元 1516‧‧‧Graphics Processing Unit
1517‧‧‧主記憶體控制器/記憶體管理功能 1517‧‧‧Main memory controller / memory management function
1518‧‧‧輸入/輸出控制功能 1518‧‧‧ input / output control function
1519‧‧‧影像處理單元 1519‧‧‧Image Processing Unit
1550‧‧‧應用處理器或多核心處理器 1550‧‧‧Application processor or multi-core processor
A‧‧‧所搜尋區塊/區塊/第一像素值/值 A‧‧‧Searched block / block / first pixel value / value
A0至A7‧‧‧資料值 A0 to A7‧‧‧Data value
B‧‧‧所搜尋區塊/區塊/像素值 B‧‧‧Searched block / block / pixel value
C‧‧‧所搜尋區塊/區塊 C‧‧‧Searched block / block
D‧‧‧所搜尋區塊/區塊 D‧‧‧Searched block / block
M‧‧‧記憶體存取單元/記憶體單元 M‧‧‧Memory Access Unit / Memory Unit
Q‧‧‧輸入值/值 Q‧‧‧input value / value
R‧‧‧第四輸入運算元/值 R‧‧‧ fourth input operand / value
R0‧‧‧暫存器/暫存器空間 R0‧‧‧ scratchpad / scratchpad space
R1‧‧‧暫存器/暫存器空間 R1‧‧‧ scratchpad / scratchpad space
R2‧‧‧暫存器/暫存器空間 R2‧‧‧ scratchpad / scratchpad space
R3‧‧‧暫存器/暫存器空間 R3‧‧‧ scratchpad / scratchpad space
R4‧‧‧暫存器 R4‧‧‧Register
R5‧‧‧暫存器 R5‧‧‧Register
X‧‧‧第一輸入運算元/結果 X‧‧‧ the first input operand / result
Y‧‧‧第二輸入運算元 Y‧‧‧ the second input operand
Z‧‧‧輸入值/輸入運算元 Z‧‧‧input value / input operand
以下說明及附圖用於圖解說明本發明之實施例。在圖式中：The following description and accompanying drawings are used to illustrate embodiments of the present invention. In the scheme:
圖1展示一模板處理器之一高級視圖； Figure 1 shows a high-level view of a template processor;
圖2係關於一區塊匹配程序； Figure 2 is about a block matching procedure;
圖3a、圖3b、圖3c及圖3d亦關於一區塊匹配程序； Figures 3a, 3b, 3c and 3d are also related to a block matching process;
圖4展示一先前ALU設計； Figure 4 shows a previous ALU design;
圖5展示一經改良ALU設計； Figure 5 shows an improved ALU design;
圖6展示一FINDMIN運算； Figure 6 shows a FINDMIN operation;
圖7a、圖7b、圖7c、圖7d亦展示一FINDMIN運算； Figures 7a, 7b, 7c, and 7d also show a FINDMIN operation;
圖8展示一經修改計數前導零運算； Figure 8 shows a modified count leading zero operation;
圖9展示一影像處理器硬體架構之一實施例； FIG. 9 shows an embodiment of an image processor hardware architecture;
圖10a、圖10b、圖10c、圖10d及圖10e繪示將影像資料剖析成一線群組、將一線群組剖析成一表單及對具有重疊模板之一表單執行之運算； FIG. 10a, FIG. 10b, FIG. 10c, FIG. 10d, and FIG. 10e illustrate operations of parsing image data into a line group, parsing a line group into a form, and performing operations on a form with overlapping templates;
圖11a展示一模板處理器之一實施例； FIG. 11a shows an embodiment of a template processor;
圖11b展示模板處理器之一指令字之一實施例； 11b shows an embodiment of an instruction word of a template processor;
圖12展示一模板處理器內之一資料運算單元之一實施例； FIG. 12 shows an embodiment of a data operation unit in a template processor;
圖13a、圖13b、圖13c、圖13d、圖13e、圖13f、圖13g、圖13h、圖13i、圖13j及圖13k繪示使用一個二維移位陣列及一執行分道陣列(execution lane array)來判定具有重疊模板之一對鄰近輸出像素值之一實例； 13a, 13b, 13c, 13d, 13e, 13f, 13g, 13h, 13i, 13j, and 13k illustrate the use of a two-dimensional shift array and an execution lane array (execution lane array) to determine an instance of a pair of adjacent output pixel values with overlapping templates;
圖14展示一整合式執行分道陣列及二維移位陣列之一單位胞元之一實施例； 14 shows an embodiment of a unit cell of an integrated execution lane array and a two-dimensional shift array;
圖15展示一例示性運算系統。 FIG. 15 shows an exemplary computing system.
Claims (16)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/594,223 | 2017-05-12 | ||
US15/594,223 US10481870B2 (en) | 2017-05-12 | 2017-05-12 | Circuit to perform dual input value absolute value and sum operation |
Publications (2)
Publication Number | Publication Date |
---|---|
TW201941047A true TW201941047A (en) | 2019-10-16 |
TWI752343B TWI752343B (en) | 2022-01-11 |
Family
ID=61386884
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
TW107103608A TW201901483A (en) | 2017-05-12 | 2018-02-01 | Circuit for performing absolute value of two input values and summing operation |
TW108128109A TWI752343B (en) | 2017-05-12 | 2018-02-01 | Execution unit circuits, image processors, and methods for performing a sum of absolute difference computation |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
TW107103608A TW201901483A (en) | 2017-05-12 | 2018-02-01 | Circuit for performing absolute value of two input values and summing operation |
Country Status (5)
Country | Link |
---|---|
US (2) | US10481870B2 (en) |
EP (1) | EP3622389B1 (en) |
CN (1) | CN110574007B (en) |
TW (2) | TW201901483A (en) |
WO (1) | WO2018208333A1 (en) |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10289732B2 (en) | 2016-06-13 | 2019-05-14 | Google Llc | Server-based conversion of autoplay content to click-to-play content |
US20180007302A1 (en) * | 2016-07-01 | 2018-01-04 | Google Inc. | Block Operations For An Image Processor Having A Two-Dimensional Execution Lane Array and A Two-Dimensional Shift Register |
US10489877B2 (en) * | 2017-04-24 | 2019-11-26 | Intel Corporation | Compute optimization mechanism |
JP6820875B2 (en) * | 2018-03-09 | 2021-01-27 | 株式会社東芝 | Computational device |
GB2590521B (en) * | 2020-06-18 | 2022-02-23 | Imagination Tech Ltd | Multiplexing between different processing channels |
Family Cites Families (28)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4638450A (en) * | 1983-09-30 | 1987-01-20 | Honeywell Information Systems Inc. | Equal nine apparatus for supporting absolute value subtracts on decimal operands of unequal length |
CA1257003A (en) * | 1985-06-19 | 1989-07-04 | Tadayoshi Enomoto | Arithmetic circuit |
US5446651A (en) * | 1993-11-30 | 1995-08-29 | Texas Instruments Incorporated | Split multiply operation |
US5596763A (en) * | 1993-11-30 | 1997-01-21 | Texas Instruments Incorporated | Three input arithmetic logic unit forming mixed arithmetic and boolean combinations |
US6219688B1 (en) | 1993-11-30 | 2001-04-17 | Texas Instruments Incorporated | Method, apparatus and system for sum of plural absolute differences |
US5880979A (en) * | 1995-12-21 | 1999-03-09 | Intel Corporation | System for providing the absolute difference of unsigned values |
US5793655A (en) * | 1996-10-23 | 1998-08-11 | Zapex Technologies, Inc. | Sum of the absolute values generator |
US6421698B1 (en) | 1998-11-04 | 2002-07-16 | Teleman Multimedia, Inc. | Multipurpose processor for motion estimation, pixel processing, and general processing |
US6477683B1 (en) | 1999-02-05 | 2002-11-05 | Tensilica, Inc. | Automated processor generation system for designing a configurable processor and method for the same |
US6473529B1 (en) * | 1999-11-03 | 2002-10-29 | Neomagic Corp. | Sum-of-absolute-difference calculator for motion estimation using inversion and carry compensation with full and half-adders |
US7054895B2 (en) | 2001-06-21 | 2006-05-30 | Ligos Corporation | System and method for parallel computing multiple packed-sum absolute differences (PSAD) in response to a single instruction |
US7685212B2 (en) | 2001-10-29 | 2010-03-23 | Intel Corporation | Fast full search motion estimation with SIMD merge instruction |
US7558947B1 (en) | 2001-12-31 | 2009-07-07 | Apple Inc. | Method and apparatus for computing vector absolute differences |
US7681013B1 (en) | 2001-12-31 | 2010-03-16 | Apple Inc. | Method for variable length decoding using multiple configurable look-up tables |
TWI225640B (en) | 2002-06-28 | 2004-12-21 | Samsung Electronics Co Ltd | Voice recognition device, observation probability calculating device, complex fast fourier transform calculation device and method, cache device, and method of controlling the cache device |
US7376686B2 (en) | 2003-01-31 | 2008-05-20 | Via Technologies, Inc. | Apparatus and method for generating packed sum of absolute differences |
US7424501B2 (en) * | 2003-06-30 | 2008-09-09 | Intel Corporation | Nonlinear filtering and deblocking applications utilizing SIMD sign and absolute value operations |
TWI249685B (en) * | 2004-01-27 | 2006-02-21 | Via Tech Inc | Apparatus and method for generating packed sum of absolute differences |
US7817719B2 (en) * | 2005-05-31 | 2010-10-19 | Atmel Corporation | System for increasing the speed of a sum-of-absolute-differences operation |
US8208553B2 (en) | 2006-05-04 | 2012-06-26 | Altera Corporation | Methods and apparatus for quarter-pel refinement in a SIMD array processor |
US8290044B2 (en) * | 2006-05-10 | 2012-10-16 | Qualcomm Incorporation | Instruction for producing two independent sums of absolute differences |
US8131788B1 (en) | 2007-08-06 | 2012-03-06 | Xilinx, Inc. | Determining sum of absolute differences in parallel |
US8976195B1 (en) | 2009-10-14 | 2015-03-10 | Nvidia Corporation | Generating clip state for a batch of vertices |
US9405535B2 (en) | 2012-11-29 | 2016-08-02 | International Business Machines Corporation | Floating point execution unit for calculating packed sum of absolute differences |
US9449257B2 (en) * | 2012-12-04 | 2016-09-20 | Institute Of Semiconductors, Chinese Academy Of Sciences | Dynamically reconstructable multistage parallel single instruction multiple data array processing system |
US9582273B2 (en) | 2013-07-09 | 2017-02-28 | Texas Instrments Incorporated | Faster and more efficient different precision sum of absolute differences for dynamically configurable block searches for motion estimation |
US10528345B2 (en) | 2015-03-27 | 2020-01-07 | Intel Corporation | Instructions and logic to provide atomic range modification operations |
CN106650923B (en) | 2015-10-08 | 2019-04-09 | 上海兆芯集成电路有限公司 | Neural network unit with neural memory and neural processing unit and sequencer |
-
2017
- 2017-05-12 US US15/594,223 patent/US10481870B2/en active Active
-
2018
- 2018-01-09 WO PCT/US2018/012866 patent/WO2018208333A1/en active Application Filing
- 2018-01-09 EP EP18707778.9A patent/EP3622389B1/en active Active
- 2018-01-09 CN CN201880028582.0A patent/CN110574007B/en active Active
- 2018-02-01 TW TW107103608A patent/TW201901483A/en unknown
- 2018-02-01 TW TW108128109A patent/TWI752343B/en active
-
2019
- 2019-11-18 US US16/687,488 patent/US10719295B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
CN110574007B (en) | 2021-07-20 |
TWI752343B (en) | 2022-01-11 |
EP3622389A1 (en) | 2020-03-18 |
EP3622389B1 (en) | 2022-08-24 |
WO2018208333A1 (en) | 2018-11-15 |
TW201901483A (en) | 2019-01-01 |
CN110574007A (en) | 2019-12-13 |
US20200159494A1 (en) | 2020-05-21 |
US20180329685A1 (en) | 2018-11-15 |
US10481870B2 (en) | 2019-11-19 |
US10719295B2 (en) | 2020-07-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN110149802B (en) | Compiler for translating between virtual image processor Instruction Set Architecture (ISA) and target hardware with two-dimensional shift array architecture | |
TWI656508B (en) | Block operation for image processor with two-dimensional array of arrays and two-dimensional displacement register | |
CN107563952B (en) | Convolutional neural network on programmable two-dimensional image processor | |
CN107533750B (en) | Virtual image processor, and method and system for processing image data thereon | |
KR102278658B1 (en) | Architecture for high performance, power efficient, programmable image processing | |
KR101971657B1 (en) | Energy-efficient processor core architecture for image processors | |
TWI635443B (en) | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform | |
TWI752343B (en) | Execution unit circuits, image processors, and methods for performing a sum of absolute difference computation | |
CN107430760B (en) | Two-dimensional shift array for image processor | |
CN112967169B (en) | Data sheet generator for image generator | |
TWI646501B (en) | Image processor, method for performing the same, and non-transitory machine readable storage medium | |
TW201737201A (en) | Compiler managed memory for image processor | |
KR102278021B1 (en) | Program code transformation to improve image processor runtime efficiency | |
TWI676150B (en) | Image processor with configurable number of active cores and supporting internal network | |
CN110574067A (en) | Image processor I/O unit | |
JP2020519977A (en) | Configuration of application software on multi-core image processor | |
EP3384376A1 (en) | Multi-functional execution lane for image processor |