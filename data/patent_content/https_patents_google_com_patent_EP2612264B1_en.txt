EP2612264B1 - Providing results to parameterless search queries - Google Patents
Providing results to parameterless search queries Download PDFInfo
- Publication number
- EP2612264B1 EP2612264B1 EP11822471.6A EP11822471A EP2612264B1 EP 2612264 B1 EP2612264 B1 EP 2612264B1 EP 11822471 A EP11822471 A EP 11822471A EP 2612264 B1 EP2612264 B1 EP 2612264B1
- Authority
- EP
- European Patent Office
- Prior art keywords
- computing device
- mobile computing
- user
- information
- identified
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000000034 method Methods 0.000 claims description 44
- 230000004044 response Effects 0.000 claims description 18
- 230000000694 effects Effects 0.000 claims description 14
- 230000015654 memory Effects 0.000 description 35
- 238000004891 communication Methods 0.000 description 25
- 230000006399 behavior Effects 0.000 description 22
- 230000007246 mechanism Effects 0.000 description 16
- 238000010586 diagram Methods 0.000 description 10
- 238000004590 computer program Methods 0.000 description 8
- 230000001413 cellular effect Effects 0.000 description 7
- 238000013507 mapping Methods 0.000 description 7
- 230000000007 visual effect Effects 0.000 description 7
- 230000003993 interaction Effects 0.000 description 6
- 230000001755 vocal effect Effects 0.000 description 5
- 238000012544 monitoring process Methods 0.000 description 4
- 230000009471 action Effects 0.000 description 3
- 230000002650 habitual effect Effects 0.000 description 3
- 239000004973 liquid crystal related substance Substances 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000008901 benefit Effects 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 235000013550 pizza Nutrition 0.000 description 2
- 230000008569 process Effects 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 229920001621 AMOLED Polymers 0.000 description 1
- 230000003213 activating effect Effects 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 230000007613 environmental effect Effects 0.000 description 1
- VJYFKVYYMZPMAB-UHFFFAOYSA-N ethoprophos Chemical compound CCCSP(=O)(OCC)SCCC VJYFKVYYMZPMAB-UHFFFAOYSA-N 0.000 description 1
- 230000000977 initiatory effect Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 230000002853 ongoing effect Effects 0.000 description 1
- 238000012545 processing Methods 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/20—Instruments for performing navigational calculations
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/34—Route searching; Route guidance
- G01C21/36—Input/output arrangements for on-board computers
- G01C21/3691—Retrieval, searching and output of information related to real-time traffic, weather, or environmental conditions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24575—Query processing with adaptation to user needs using context
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24578—Query processing with adaptation to user needs using ranking
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/248—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/29—Geographical information databases
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9537—Spatial or temporal dependent retrieval, e.g. spatiotemporal queries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9538—Presentation of query results
Definitions
- This document generally describes techniques, method, systems, and mechanisms for providing results to parameterless search queries on a mobile computing device, such as a mobile telephone.
- Mobile computing devices e.g., mobile telephones, smart telephones, personal digital assistants (PDAs), portable media players, etc.
- a user can submit a search query for directions to a nearby pizzeria to a mobile computing device.
- parameters of the search query include (a) the portion of the request identifying directions as the desired result, and (b) the indication that a nearby pizzeria is the topic of the query.
- the mobile computing device can (alone, or in combination with a remote server system) identify a nearby pizzeria and provide directions to the pizzeria to the user.
- Such mobile computing devices have been configured to receive a search query as text-based input (e.g., a query typed using keys), selection-based input (e.g., touchscreen selection, etc.), and audio-based input (e.g., voice input).
- US-A1-2007/073722 relates to the calculation and presentation of mobile content expected value. Methods are described for receiving data associated with mobile content, calculating an expected value of the mobile content based at least in part on the data received, and presenting the expected value to a sponsor.
- US-B1-7,603,349 relates to user interfaces for search systems using in-line contextual queries.
- Systems and methods, including user interfaces are provided for implementing searches using contextual information associated with a Web page (or other document) that a user is viewing when a query is entered.
- the page includes a contextual search interface that has an associated context vector representing content of the page.
- the query and the context vector are both provided to the query processor and used in responding to the query.
- US-A1-2008/005067 relates to context-based search, retrieval, and awareness.
- a system that incorporates a user context into a computer-based search is provided.
- the innovation can identify information about a user state or context via a variety of sources and sensors.
- the state/context information can be used to filter, arrange and/or rank search results so as to facilitate converging on meaningful searches and results.
- US-A1-2004/267730 relates to systems and methods for performing background queries from content and activity.
- Systems and methods are provided that perform implicit or background queries to one or more information sources based on the ongoing activities of users.
- EP-A2-2,577,524 (published as WO-A2-2011/153079 ) is citeable for novelty only under Article 54(3) EPC.
- Systems, methods, and computer storage media having computer-executable instructions embodied thereon that provide content items selected based on context are provided.
- Contextual indicators associated with a user are identified and utilized to determine one or more content items that the user is likely to desire to access at a particular point in time.
- the identified content items (or references thereto) are presented automatically to the user, that is, without the user having to input any search query terms.
- a parameterless search query is a search query that queries a mobile computing device for information that is relevant to a user, but where the user does not provide any parameters to further specify what is relevant to the user at a given time. Instead, a parameterless search query puts on the mobile computing device the onus of determining what the user is likely to deem relevant.
- a mobile computing device can examine a current context within which the mobile computing device and/or the user of the mobile computing device exist at the time the parameterless search query is received (which, as discussed here, can occur by the computing device acting on its own or in combination with a computer server system).
- a mobile computing device is moving with a user on a highway who is travelling at speed during rush hour on a workday (e.g., Monday - Friday).
- the device can examine its current context (travelling on the highway during rush hour) and infer that the user would like to receive traffic information for the stretch of highway ahead.
- the mobile computing device can infer parameters for the search query (e.g., traffic conditions and highway number), identify results for the search query (e.g., expect to encounter stop-and-go traffic in two miles), and provide the results to the user (e.g., activate a speaker on the mobile device and audibly transmit the traffic conditions to the user).
- an electronic system as set out in claim 13.
- a parameterless search query is a search query that does not contain any parameters for the search query (may also be termed a "zero input" query). Instead, a parameterless search query asks the mobile computing device to infer what a user of the mobile computing device wants to know (infer the parameters for the search query) based upon a current context for the mobile computing device (e.g., time of day, geographic location, calendar appointments, etc.).
- a current context for the mobile computing device e.g., time of day, geographic location, calendar appointments, etc.
- mobile computing devices can provide a user with access to the user's email, the user's electronic calendar (e.g., meetings, appointments, reminders, etc.), up-to-date traffic information, driving directions, location-based searching (e.g., search for hotel near current location), etc.
- the user's electronic calendar e.g., meetings, appointments, reminders, etc.
- up-to-date traffic information e.g., driving directions, location-based searching (e.g., search for hotel near current location), etc.
- a user interface for a mobile computing device
- a location-based search interface e.g., interface for a map application
- a user can obtain the information they are interested in without having to provide a formulated search query. Instead, using a parameterless search query, a user can access the information he/she is interested in by merely providing input to the mobile computing device that indicates a request for a parameterless search query.
- Such input can be simple and easy for a user to perform, such as shaking the mobile computing device a set number of times (e.g., shake one time, shake two times, etc.), pressing a button on the mobile computing device for a period of time (e.g., press and hold button for two seconds), providing a verbal command to the mobile computing device (e.g., commanding the device to "search now”), etc.
- a mobile computing device can infer parameters for the search query based upon a current context for the mobile device.
- a current context for a mobile computing device can include a variety of information associated with the mobile computing device and/or a user of the mobile computing device, such as the time of day and date (e.g., 2:00 pm on May 29, 2010), upcoming and/or recent calendar appointments (e.g., meeting with John at 2:30 pm on May 29, 2010), a direction and rate of speed at which the device is travelling (e.g., northbound at 20 miles per hour), a current geographic location (e.g., on the corner of 10th Street and Marquette Avenue), recent device activity (e.g., emails sent to John regarding the 2:30 meeting), etc.
- time of day and date e.g., 2:00 pm on May 29, 2010
- upcoming and/or recent calendar appointments e.g., meeting with John at 2:30 pm on May 29, 2010
- a direction and rate of speed at which the device is travelling e.g., northbound at 20 miles per
- a mobile computing device can infer parameters for a user's parameterless search query (infer what the user wants to know), perform a search using the inferred parameters, and provide results to the user. For example, if the current context for a mobile computing device includes the mobile device being geographically located on a highway and travelling at speed of 55 miles per hour, the mobile device may infer that the user would like to know current traffic conditions for the surrounding area.
- the mobile computing device can perform a search query for traffic conditions near the device's geographic location and provide the results to the user (e.g., display a map with roads that are color-coded according to traffic conditions, provide the user with a list of expected delay times for various roads nearby, etc.).
- the mobile computing device can infer that the user would like to access information for the conference call (e.g., the telephone number for the conference call).
- the mobile computing device can perform a search query for information related to the conference call and provide the results to the user (e.g., display a telephone number for the conference call to the user and provide an option to automatically initiate a telephone call to the telephone number).
- a mobile computing device can perform a parameterless search query locally on the mobile computing device (e.g., search data stored locally on the mobile computing device) and/or in conjunction with a computer system that is remote to the mobile computing device (e.g., provide search query over a network to a remote server system).
- a mobile computing device can determine its current context, infer parameters for a parameterless search request, and identify and provide results as a standalone device (e.g., without interacting with other devices over a network).
- Results for parameterless search queries can be provided to a user in various manners, such as visually on a display for the mobile device, audibly through a speaker system of the mobile computing device, etc.
- FIG. 1 is a conceptual diagram 100 of an example mobile computing device 102 for providing results to parameterless search queries.
- the example diagram 100 provides an illustrative example of the mobile computing device 102 receiving input that indicates a request for a parameterless search query, inferring parameters for the search query based upon a current context for the device, and providing results for the search query to a user.
- a user is depicted as holding the mobile computing device 102 in his/her hand and shaking 104 the mobile computing device 102.
- the mobile computing device 102 is configured to recognize the shaking 104 as input that indicates a request for a parameterless search query.
- the mobile computing device 102 can be configured to recognize additional (or other) user interactions with mobile computing device 102 as input that indicates a request for a parameterless search query.
- the mobile computing device 102 uses one or more sensors that are configured to measure movement (e.g., accelerometers, gyroscopes, etc.), the mobile computing device 102 receives input 106 from the one or more sensors that indicates that the user shook the device 102.
- sensors that are configured to measure movement (e.g., accelerometers, gyroscopes, etc.)
- the mobile computing device 102 is configured to recognize the input 106 as a request to perform a parameterless search query.
- the mobile computing device 102 In response to the input 106 indicating the user shook 104 the mobile device 102, and without additional input further providing parameters for the search query (further indicating what the user would like to know), the mobile computing device 102 begins performing a parameterless search query by determining a current context for the mobile device and/or for the user of the mobile device (108).
- the current context includes information that describes the present state and/or surroundings of the mobile computing device 102 and/or the user of the mobile computing device at the time the input 106 is received.
- the current context can include a variety of information related to the mobile computing device 102 and the user, such as information regarding the surrounding physical environment (e.g., geographic location, weather conditions, nearby businesses, volume of ambient noise, level of ambient light, image captured by the mobile device's camera, etc.), the present state of the mobile computing device 102 (e.g., rate of speed, touchscreen input activated, audio input activated, ringer on/off, etc.), time and date information (e.g., time of day, date, calendar appointments, day of the week, etc.), user activity (e.g., recent user activity, habitual user activity), etc.
- the current context can be determined by the mobile computing device 102 using data and sensors that are local and/or remote to the mobile computing device 102.
- the current context for the mobile computing device includes time/date information 112a, geographic location information 112b, calendar information 112c, rate of speed information 112d, and device activity information 112e.
- the time/date information 112a lists the time as 8:00 am on a Monday and the geographic information 112b provides that the mobile computing device 102 is currently located at the user's home.
- the calendar information 112c provides that the user has no appointments scheduled for the day and the rate of speed information 112d indicates that the mobile computing device 102 is currently stationary (travelling at 0 miles per hour).
- the device activity information 112e indicates that the device habitually travels on a highway at a high rate of speed to the user's work at 8:05 am on Mondays.
- the mobile computing device 102 can identify information that is likely to be relevant to the user (114). Given that the device 102 is located at the user's home, the current time is 8:00 am on a Monday, the device is currently stationary, and the device typically travels along a highway to the user's work at 8:05 am on Mondays, the mobile computing device 102 can determine that the user is likely to drive from the user's home to the user's work in the near future. Based upon this determination, the mobile computing can infer parameters for the parameterless search query related to driving to the user's work.
- the mobile computing device 102 can determine that it is unlikely that the user would like to receive driving directions from the user's home to work. Instead, the mobile computing device 102 can infer that the user is likely interested in knowing the current traffic conditions for the user's morning commute to work and can select parameters accordingly (e.g., select parameters "traffic" and "from current location to work location").
- the mobile computing device 102 may infer the user is interested in different information. For example, were the user to have a meeting scheduled for 8:30 am out of the office, the mobile computing device 102 may infer that the user would like driving directions to the meeting location and/or information regarding the meeting (e.g., time, subject, participants, etc.). In another example, were the user to have viewed a developing news story using an application (e.g., web browser, news application) on the mobile computing device 102 at 7:30 am, the mobile computing device 102 may infer that the user would like to know if there have been any recent updates to the news story.
- an application e.g., web browser, news application
- the mobile computing device 102 may infer the user is interested in more than one piece of information and may generate parameters for more than one search query. For instance, the mobile computing device 102 may infer that the user wants to know about traffic conditions for the user's work commute and know about updates to the developing news story the user viewed earlier in the morning. The mobile computing device 102 can generate parameters and provide information to the user related to both items identified as being of potential interest to the user.
- the mobile computing device 102 can identify information that is likely to be relevant to the user with the selected parameters.
- the mobile computing device 102 can use various search-related services that are provided locally and/or remotely to obtain the sought-after information.
- the mobile computing device 102 may query a real-time traffic server system provided by a department of transportation for traffic information.
- the mobile computing device 102 may query an application installed on the mobile computing device 102 that is configured to obtain traffic information over traffic message channel (TMC) radio frequency.
- TMC traffic message channel
- the mobile computing device 102 can search traffic information cached locally on the mobile computing device 102.
- the mobile computing device 102 is capable of determining its current context and serving parameterless search requests by itself (e.g., without interacting with other computing devices and/or services over a network).
- the mobile computing device can provide the identified information to the user (116). For example, the mobile computing device can present a message 118 that indicates the current traffic conditions and, if they are unfavorable, suggest that the user take an alternate route.
- the identified information can be provided by the mobile computing device 102 to the user in a variety of manners. For example, in addition to providing the user with a visual message, the mobile computing device 102 may audibly transmit the message to the user with a speaker system that is attached to and/or part-of the mobile computing device 102.
- FIGS. 2A-B are diagrams of an example system 200 for providing results to parameterless search queries on an example mobile computing device 202.
- the mobile computing device 202 can be configured to provide results to a parameterless search query based upon a current context associated with the mobile computing device 202 and/or a user of the mobile computing device, similar to the mobile computing device 102 described above with regard to FIG. 1 .
- the mobile computing device 202 is depicted as including an input subsystem 204 through which a user of the mobile computing device 202 can provide input that indicates a request for a parameterless search query.
- the input subsystem 204 is depicted as including a microphone 206a (configured to receive audio-based input), a keyboard 206b (configured to receive key-based input), a touchscreen 206c (configured to receive screen touch-based input), an accelerometer 206d (configured to receive motion-based input), a trackball 206e (configured to receive GUI pointer-based input), a camera 206f (configured to receive visual input), and a light sensor 206g (configured to receive input based on light intensity).
- the input subsystem 204 also includes a network interface 208 (e.g., wireless network interface, universal serial bus (USB) interface, BLUETOOTH interface, public switched telephone network (PSTN) interface, Ethernet interface, cellular network interface, 3G and/or 4G network interface, etc.) that is configured to receive network-based input and output.
- a network interface 208 e.g., wireless network interface, universal serial bus (USB) interface, BLUETOOTH interface, public switched telephone network (PSTN) interface, Ethernet interface, cellular network interface, 3G and/or 4G network interface, etc.
- PSTN public switched telephone network
- Ethernet interface e.g., Ethernet interface, cellular network interface, 3G and/or 4G network interface, etc.
- Other types of input devices not mentioned may also be part of the input subsystem 204.
- An input parser 210 of the mobile computing device 202 can be configured to receive input from the input subsystem 204 (e.g., input events) and determine whether the received input indicates a request for a parameterless search query.
- the input parser 210 can use input rules 212 to determine whether a particular input indicates a request for a parameterless search query.
- the input rules 212 can stipulate that shaking the mobile computing device 202 once indicates an "undo" command (e.g., undo recent typing) and that shaking the device 202 twice indicates a request for a parameterless search query.
- the input rules 212 can be preconfigured and/or user defined.
- a mobile device context determination unit 214 can determine a current context for the mobile computing device 202.
- the mobile device context determination unit 214 can determine a current context for the mobile device 202 using a variety of context monitoring units of the mobile computing device 202.
- a global positioning system (GPS) unit 216 can provide geographic location information to the mobile device context determination unit 214 and a travel monitor unit 218 (in conjunction with a travel data repository 220) can provide information related to a route currently being travelled and habitual routes travelled by the mobile computing device 202.
- An activity monitor unit 222 (in conjunction with an activity data repository 224) can provide information related to recent and habitual user activity (e.g., applications used, specific information accessed at various times, etc.) on the mobile device 202.
- a location monitor unit 226 can provide information regarding entities (e.g., businesses, parks, festivals, public transportation, etc.) geographically located near the current geographic location for the mobile device 202.
- a time and date unit 228 can provide current time and date information and a calendar unit 230 (in conjunction with a calendar data repository 232) can provide information related to appointments for the user.
- An email unit 234 (in conjunction with an email data repository 236) can provide email-related information (e.g., recent emails sent/received).
- the mobile context determination unit 214 can receive information from other context monitoring units not mentioned or depicted.
- the context monitoring units 216-236 can be implemented in-part, or in-whole, remote from the mobile computing device 202.
- the email unit 234 may be a thin-client that merely displays email-related data that is maintained and provided by a remote server system.
- the email unit 234 can interact with the remote server system to obtain email-related information to provide to the mobile device context determination unit 214.
- a category identification unit 238 can use the current context for the mobile device 202, as determined by the mobile device context determination unit 214, to identify one or more categories of information that the user in which the user is likely to be interested.
- categories of information identified by the category identification unit 238 may include environmental information (e.g., weather information), travel information (e.g, traffic information, driving directions, transportation schedule information, map information), geographic proximity information (e.g., nearby business information), recently updated information (e.g., real-time news updates, blog updates, email/texting conversation updates), and personal information (e.g., calendar appointments for a user, contact information for a user's acquaintances).
- environmental information e.g., weather information
- travel information e.g, traffic information, driving directions, transportation schedule information, map information
- geographic proximity information e.g., nearby business information
- recently updated information e.g., real-time news updates, blog updates, email/texting conversation updates
- personal information e.g., calendar appointments for a user, contact information
- the category identification unit 238 can identify one or more categories of information for the parameterless search query using a category data repository 240, which can define categories of information and provide various contextual factors that may indicate categories of information in which a user is interested (e.g., category-based rules, category scoring techniques, etc.).
- the category data repository 240 can include predefined data and/or user defined data.
- the data stored in the category data repository 240 can be subject to change over time as well (e.g., the mobile computing device 202 can "learn" a user's interests in various contexts and adjust the data stored in the category data repository 240 over time).
- the category identification unit 238 can additionally use data stored in a user behavior data repository 242 to determine one or more categories of information in which a user is likely to be interested.
- the user behavior data repository 242 can log previous requests for a parameterless search query, a context for the mobile device 202 at the time of the requests, categories of information identified as likely to be relevant to the user, and the user's behavior (e.g., user appeared to use the information, user performed follow-up manual search query with defined parameters, etc.) with respect to information provided by the mobile device 202.
- the user behavior data stored in the user behavior data repository 242 can indicate whether a user found the identified category of information to be relevant given the mobile device's 202 current context.
- the associated user behavior data can indicate that the user found the identified category to be relevant given the device's context.
- the user is provided with the list of nearby restaurants and the user immediately opens a calendar application to locate information for an upcoming meeting, then the associated user behavior can indicate that the user found the identified category to not be relevant (e.g., the user wanted calendar information instead of restaurant information).
- the category identification unit 238 can use user behavior data from the user behavior data repository 242 to identify a category of information that is likely to be relevant to the user. For example, the category identification unit 238 can attempt to identify previous contexts that are similar to a current context for the mobile device 202 to receive an indication regarding a category of information that is likely to be relevant to the user.
- a result identification unit 244 can identify one or more results to a parameterless search query by inferring parameters for the parameterless search query and perform the search query. For example, if the category identification unit 238 identified a category of travel information, the result identification unit 244 can determine specific parameters related to travel that are likely to be relevant to the user. For instance, the result identification unit 244 may determine that the user is likely to be interested in traffic condition for the user's commute to work. Like the category identification unit 238, the result identification unit 244 can use user behavior data from the user behavior data repository 242 to assist in determining specific parameters that are likely to be relevant to the user.
- the search query can be performed local and/or remote to the mobile computing device 202.
- the search query can be performed locally on the mobile computing device 202 (e.g., querying the calendar unit 230 for relevant calendar information stored in the calendar data repository 232).
- the mobile computing device 202 can determine its current context and provide results to a parameterless search query as a standalone device (e.g., without interacting with a remote server system over a network).
- the mobile computing device 202 can interact with the remote server system to access the relevant calendar information.
- Parameters for more than one search query can be generated by the result identification unit 244 in response to receiving a request for a parameterless search query.
- the result identification unit 244 can receive results for each of the search queries. For instance, the result identification unit 244 may identify that a user is likely to be interested in current traffic information and a recent update to a blog that the user frequently reads.
- the result identification unit 244 can submit search queries for both pieces of information and provide results for both search queries to a user of the mobile computing device 202. It may be possible to submit a single search query for two or more distinct pieces of information. However, when the two or more distinct pieces of information are maintained by different data sources, it may be more practical to generate separate search queries, as described above.
- An output subsystem 246 of the mobile computing device 202 can provide results obtained by the result identification unit 244 to a user of the device 202.
- the output subsystem 246 can include a variety of output devices, such as a display 248a (e.g., a liquid crystal display (LCD), a touchscreen), a projector 248a (e.g., an image projector capable of projecting an image external to the device 202), a speaker 248c, a headphone jack 248d, etc.
- the network interface 208 can also be part of the output subsystem 246 and may be configured to provide the results obtained by the result identification unit 244 (e.g., transmit results to BLUETOOTH headset).
- the mobile computing device 202 can wirelessly communicate with wireless transmitter 250 (e.g., a cellular network transceiver, a wireless network router, etc.) and obtain access to a network 252 (e.g., the Internet, PSTN, a cellular network, a local area network (LAN), a virtual private network (VPN), etc.).
- a network 252 e.g., the Internet, PSTN, a cellular network, a local area network (LAN), a virtual private network (VPN), etc.
- the mobile computing device 202 can be in communication with a mobile device server system 254 (one or more networked server computers), which can be configured to provide mobile device related services and data to the mobile device 202 (e.g., provide calendar data, email data, connect telephone calls to other telephones, etc.).
- the mobile device 202 can also be in communication with one or more information server systems 256 over the network 252.
- Information server systems 256 can be server systems that provide information that may be relevant to a user's parameterless search query. For instance, a information server systems 256 can provide current traffic conditions, a weather forecast, and information regarding businesses located near the current geographic location for the mobile device 202.
- FIG. 3 is a flowchart of an example technique 300 for providing results to parameterless search queries on a mobile computing device.
- the example technique 300 can be performed by any of a variety of mobile computing devices, such as the mobile computing device 102 described above with regard to FIG. 1 and/or the mobile computing device 202 described above with regard to FIGS. 2A-B .
- the technique 300 starts at step 302 by receiving a parameterless search request.
- the mobile computing device 102 is described above with regard to FIG. 1 as receiving input 106 that indicates a request for a parameterless search query.
- the input parser 210 with regard to FIG. 2B , a variety of inputs (e.g., touch, action, voice, etc.) can be configured to indicate a request for a parameterless search query.
- a current context for the mobile device can be determined (step 304).
- a mobile device context determination unit 214 can determine a current context for the mobile device 202 using the context monitoring units 216-236.
- first data that indicates whether previously identified result categories were relevant to a user are retrieved (step 306).
- the category identification unit 238 described above with regard to FIG. 2B can retrieve user behavior data from the user behavior data repository 242 to determine which previously identified categories of information were relevant to the user.
- Portion of the first data can be selected based upon previous contexts determined to be similar to the current context for the mobile device (step 308). For example, user behavior data associated with contexts that are similar to the current context can be retrieved from the user behavior data repository 242.
- Result categories can be identified based upon the current context for the mobile device (step 310). For example, given the context 110 determined with regard to the example depicted in FIG. 1 , a travel category of identified as being likely to be relevant to the user of the mobile device 102 (e.g., the device is located at home on Monday at 8:00 am and the device habitually travels from home to work on Monday mornings at 8:05 am).
- second data that indicates whether previously identified results were relevant to the user can be retrieved (step 312).
- a result identification unit 244 can access user behavior data from the user behavior data repository 242 to determine which previously provided results the user of the mobile device 202 found to be relevant given the current context of the device. Portions of the second data can be selected based on previous contexts determined to be similar to the current context (step 314). For instance, the result identification unit 244 can select the user behavior data that is associated with previous contexts that are similar to the current context for the mobile computing device 202.
- Results can be identified for the parameterless search request based upon the current context (step 316).
- the result identification unit 244 can infer parameters for the parameterless search request based upon the current context of the mobile device 202 and use the inferred parameters to identify results that are likely to be relevant to the user of the mobile device.
- Results can be identified locally and/or remotely from the mobile device. For instance, if the mobile device 202 infers that a parameterless search request refers to a user's upcoming schedule, the mobile computing device 202 can access the calendar unit 230 locally to obtain the schedule information.
- the mobile device 202 is capable of determining its current context and providing results to a parameterless search request as a standalone device (e.g., without being connected to other devices over a network).
- a subsystem can be selected for providing the results (step 318). For example, one or more of the output devices 248a-d of the output subsystem 246 for the mobile computing device 202 can be selected to provide the identified results to the user.
- the subsystem can be selected based upon a variety for factors, such as the manner in which the input indicating a request for a parameterless search was received (e.g., verbal input, shaking the device, etc.) and the current context for the mobile device. For instance, if the request for parameterless search is received as a verbal request, then the selected subsystem can be an audio output (e.g., the speaker 248c). In another example, if the current context indicates that the user may be in a location where audio output is undesired (e.g., user is in a library), then the selected subsystem can provide a visual output (e.g., the display 248a).
- the results are provided to the user (step 320).
- a response from the user with regard to the provided results can be recorded by a mobile computing device as user behavior data and used to improve the results provided in response to future parameterless search requests. For example, if the user is provided with a recent update to a blog that the user frequently reads and the user sends a link to the updated blog posting to his/her friends, the user sending the link can be recorded as user behavior data in the user behavior data repository 242 of the mobile computing device 202 and used to provide results to future parameterless search requests.
- FIG. 4 is a conceptual diagram of a system that may be used to implement the techniques, systems, mechanisms, and methods described in this document.
- Mobile computing device 410 can wirelessly communicate with base station 440, which can provide the mobile computing device wireless access to numerous services 460 through a network 450.
- the mobile computing device 410 is depicted as a handheld mobile telephone (e.g., a smartphone or an application telephone) that includes a touchscreen display device 412 for presenting content to a user of the mobile computing device 410.
- the mobile computing device 410 includes various input devices (e.g., keyboard 414 and touchscreen display device 412) for receiving user-input that influences the operation of the mobile computing device 410.
- the mobile computing device 410 may be a laptop computer, a tablet computer, a personal digital assistant, an embedded system (e.g., a car navigation system), a desktop computer, or a computerized workstation.
- the mobile computing device 410 may include various visual, auditory, and tactile user-output mechanisms.
- An example visual output mechanism is display device 412, which can visually display video, graphics, images, and text that combine to provide a visible user interface.
- the display device 412 may be a 3.7 inch AMOLED screen.
- Other visual output mechanisms may include LED status lights (e.g., a light that blinks when a voicemail has been received).
- An example tactile output mechanism is a small electric motor that is connected to an unbalanced weight to provide a vibrating alert (e.g., to vibrate in order to alert a user of an incoming telephone call or confirm user contact with the touchscreen 412).
- the mobile computing device 410 may include one or more speakers 420 that convert an electrical signal into sound, for example, music, an audible alert, or voice of an individual in a telephone call.
- An example mechanism for receiving user-input includes keyboard 414, which may be a full qwerty keyboard or a traditional keypad that includes keys for the digits '0-4', '*', and '#.'
- the keyboard 414 receives input when a user physically contacts or depresses a keyboard key.
- User manipulation of a trackball 416 or interaction with a trackpad enables the user to supply directional and rate of rotation information to the mobile computing device 410 (e.g., to manipulate a position of a cursor on the display device 412).
- the mobile computing device 410 may be able to determine a position of physical contact with the touchscreen display device 412 (e.g., a position of contact by a finger or a stylus).
- various "virtual" input mechanisms may be produced, where a user interacts with a graphical user interface element depicted on the touchscreen 412 by contacting the graphical user interface element.
- An example of a “virtual” input mechanism is a "software keyboard,” where a keyboard is displayed on the touchscreen and a user selects keys by pressing a region of the touchscreen 412 that corresponds to each key.
- the mobile computing device 410 may include mechanical or touch sensitive buttons 418a-d. Additionally, the mobile computing device may include buttons for adjusting volume output by the one or more speakers 420, and a button for turning the mobile computing device on or off.
- a microphone 422 allows the mobile computing device 410 to convert audible sounds into an electrical signal that may be digitally encoded and stored in computer-readable memory, or transmitted to another computing device.
- the mobile computing device 410 may also include a digital compass, an accelerometer, proximity sensors, and ambient light sensors.
- An operating system may provide an interface between the mobile computing device's hardware (e.g., the input/output mechanisms and a processor executing instructions retrieved from computer-readable medium) and software.
- Example operating systems include the ANDROID mobile computing device platform; APPLE IPHONE/MAC OS X operating systems; MICROSOFT WINDOWS 7/WINDOWS MOBILE operating systems; SYMBIAN operating system; RIM BLACKBERRY operating system; PALM WEB operating system; a variety of UNIX-flavored operating systems; or a proprietary operating system for computerized devices.
- the operating system may provide a platform for the execution of application programs that facilitate interaction between the computing device and a user.
- the mobile computing device 410 may present a graphical user interface with the touchscreen 412.
- a graphical user interface is a collection of one or more graphical interface elements and may be static (e.g., the display appears to remain the same over a period of time), or may be dynamic (e.g., the graphical user interface includes graphical interface elements that animate without user input).
- a graphical interface element may be text, lines, shapes, images, or combinations thereof.
- a graphical interface element may be an icon that is displayed on the desktop and the icon's associated text.
- a graphical interface element is selectable with user-input.
- a user may select a graphical interface element by pressing a region of the touchscreen that corresponds to a display of the graphical interface element.
- the user may manipulate a trackball to highlight a single graphical interface element as having focus.
- User-selection of a graphical interface element may invoke a pre-defined action by the mobile computing device.
- selectable graphical interface elements further or alternatively correspond to a button on the keyboard 404. User-selection of the button may invoke the pre-defined action.
- the operating system provides a "desktop" user interface that is displayed upon turning on the mobile computing device 410, activating the mobile computing device 410 from a sleep state, upon "unlocking" the mobile computing device 410, or upon receiving user-selection of the "home" button 418c.
- the desktop graphical interface may display several icons that, when selected with user-input, invoke corresponding application programs.
- An invoked application program may present a graphical interface that replaces the desktop graphical interface until the application program terminates or is hidden from view.
- User-input may manipulate a sequence of mobile computing device 410 operations.
- a single-action user input e.g., a single tap of the touchscreen, swipe across the touchscreen, contact with a button, or combination of these at a same time
- an operation that changes a display of the user interface Without the user-input, the user interface may not have changed at a particular time.
- a multi-touch user input with the touchscreen 412 may invoke a mapping application to "zoom-in" on a location, even though the mapping application may have by default zoomed-in after several seconds.
- the desktop graphical interface can also display "widgets."
- a widget is one or more graphical interface elements that are associated with an application program that has been executed, and that display on the desktop content controlled by the executing application program. Unlike an application program, which may not be invoked until a user selects a corresponding icon, a widget's application program may start with the mobile telephone. Further, a widget may not take focus of the full display. Instead, a widget may only "own" a small portion of the desktop, displaying content and receiving touchscreen user-input within the portion of the desktop.
- the mobile computing device 410 may include one or more location-identification mechanisms.
- a location-identification mechanism may include a collection of hardware and software that provides the operating system and application programs an estimate of the mobile telephone's geographical position.
- a location-identification mechanism may employ satellite-based positioning techniques, base station transmitting antenna identification, multiple base station triangulation, internet access point IP location determinations, inferential identification of a user's position based on search engine queries, and user-supplied identification of location (e.g., by "checking in" to a location).
- the mobile computing device 410 may include other application modules and hardware.
- a call handling unit may receive an indication of an incoming telephone call and provide a user capabilities to answer the incoming telephone call.
- a media player may allow a user to listen to music or play movies that are stored in local memory of the mobile computing device 410.
- the mobile telephone 410 may include a digital camera sensor, and corresponding image and video capture and editing software.
- An internet browser may enable the user to view content from a web page by typing in an addresses corresponding to the web page or selecting a link to the web page.
- the mobile computing device 410 may include an antenna to wirelessly communicate information with the base station 440.
- the base station 440 may be one of many base stations in a collection of base stations (e.g., a mobile telephone cellular network) that enables the mobile computing device 410 to maintain communication with a network 450 as the mobile computing device is geographically moved.
- the computing device 410 may alternatively or additionally communicate with the network 450 through a Wi-Fi router or a wired connection (e.g., Ethernet, USB, or FIREWIRE).
- the computing device 410 may also wirelessly communicate with other computing devices using BLUETOOTH protocols, or may employ an ad-hoc wireless network.
- a service provider that operates the network of base stations may connect the mobile computing device 410 to the network 450 to enable communication between the mobile computing device 410 and other computerized devices that provide services 460.
- the services 460 may be provided over different networks (e.g., the service provider's internal network, the Public Switched Telephone Network, and the Internet), network 450 is illustrated as a single network.
- the service provider may operate a server system 452 that routes information packets and voice data between the mobile computing device 410 and computing devices associated with the services 460.
- the network 450 may connect the mobile computing device 410 to the Public Switched Telephone Network (PSTN) 462 in order to establish voice or fax communication between the mobile computing device 410 and another computing device.
- PSTN Public Switched Telephone Network
- the service provider server system 452 may receive an indication from the PSTN 462 of an incoming call for the mobile computing device 410.
- the mobile computing device 410 may send a communication to the service provider server system 452 initiating a telephone call with a telephone number that is associated with a device accessible through the PSTN 462.
- the network 450 may connect the mobile computing device 410 with a Voice over Internet Protocol (VoIP) service 464 that routes voice communications over an IP network, as opposed to the PSTN.
- VoIP Voice over Internet Protocol
- a user of the mobile computing device 410 may invoke a VoIP application and initiate a call using the program.
- the service provider server system 452 may forward voice data from the call to a VoIP service, which may route the call over the internet to a corresponding computing device, potentially using the PSTN for a final leg of the connection.
- An application store 466 may provide a user of the mobile computing device 410 the ability to browse a list of remotely stored application programs that the user may download over the network 450 and install on the mobile computing device 410.
- the application store 466 may serve as a repository of applications developed by third-party application developers.
- An application program that is installed on the mobile computing device 410 may be able to communicate over the network 450 with server systems that are designated for the application program. For example, a VoIP application program may be downloaded from the Application Store 466, enabling the user to communicate with the VoIP service 464.
- the mobile computing device 410 may access content on the internet 468 through network 450.
- a user of the mobile computing device 410 may invoke a web browser application that requests data from remote computing devices that are accessible at designated universal resource locations.
- some of the services 460 are accessible over the internet.
- the mobile computing device may communicate with a personal computer 470.
- the personal computer 470 may be the home computer for a user of the mobile computing device 410.
- the user may be able to stream media from his personal computer 470.
- the user may also view the file structure of his personal computer 470, and transmit selected documents between the computerized devices.
- a voice recognition service 472 may receive voice communication data recorded with the mobile computing device's microphone 422, and translate the voice communication into corresponding textual data.
- the translated text is provided to a search engine as a web query, and responsive search engine search results are transmitted to the mobile computing device 410.
- the mobile computing device 410 may communicate with a social network 474.
- the social network may include numerous members, some of which have agreed to be related as acquaintances.
- Application programs on the mobile computing device 410 may access the social network 474 to retrieve information based on the acquaintances of the user of the mobile computing device. For example, an "address book" application program may retrieve telephone numbers for the user's acquaintances.
- content may be delivered to the mobile computing device 410 based on social network distances from the user to other members. For example, advertisement and news article content may be selected for the user based on a level of interaction with such content by members that are "close” to the user (e.g., members that are "friends" or “friends of friends").
- the mobile computing device 410 may access a personal set of contacts 476 through network 450.
- Each contact may identify an individual and include information about that individual (e.g., a phone number, an email address, and a birthday). Because the set of contacts is hosted remotely to the mobile computing device 410, the user may access and maintain the contacts 476 across several devices as a common set of contacts.
- the mobile computing device 410 may access cloud-based application programs 478.
- Cloud-computing provides application programs (e.g., a word processor or an email program) that are hosted remotely from the mobile computing device 410, and may be accessed by the device 410 using a web browser or a dedicated program.
- Example cloud-based application programs include GOOGLE DOCS word processor and spreadsheet service, GOOGLE GMAIL webmail service, and PICASA picture manager.
- Mapping service 480 can provide the mobile computing device 410 with street maps, route planning information, and satellite images.
- An example mapping service is GOOGLE MAPS.
- the mapping service 480 may also receive queries and return location-specific results. For example, the mobile computing device 410 may send an estimated location of the mobile computing device and a user-entered query for "pizza places" to the mapping service 480.
- the mapping service 480 may return a street map with "markers" superimposed on the map that identify geographical locations of nearby "pizza places.”
- Turn-by-turn service 482 may provide the mobile computing device 410 with turn-by-turn directions to a user-supplied destination. For example, the turn-by-turn service 482 may stream to device 410 a street-level view of an estimated location of the device, along with data for providing audio commands and superimposing arrows that direct a user of the device 410 to the destination.
- streaming media 484 may be requested by the mobile computing device 410.
- computing device 410 may request a stream for a pre-recorded video file, a live television program, or a live radio program.
- Example services that provide streaming media include YOUTUBE and PANDORA.
- a micro-blogging service 486 may receive from the mobile computing device 410 a user-input post that does not identify recipients of the post.
- the micro-blogging service 486 may disseminate the post to other members of the micro-blogging service 486 that agreed to subscribe to the user.
- a search engine 488 may receive user-entered textual or verbal queries from the mobile computing device 410, determine a set of internet-accessible documents that are responsive to the query, and provide to the device 410 information to display a list of search results for the responsive documents.
- the voice recognition service 472 may translate the received audio into a textual query that is sent to the search engine.
- a server system may be a combination of hardware and software that provides a service or a set of services.
- a set of physically separate and networked computerized devices may operate together as a logical server system unit to handle the operations necessary to offer a service to hundreds of individual computing devices.
- operations that are performed "in response" to another operation are not performed if the prior operation is unsuccessful (e.g., if the determination was not performed).
- a determination or an identification e.g., if the determination was not performed.
- Features in this document that are described with conditional language may describe implementations that are optional.
- "transmitting" from a first device to a second device includes the first device placing data into a network, but may not include the second device receiving the data.
- receiving from a first device may include receiving the data from a network, but may not include the first device transmitting the data.
- FIG. 5 is a block diagram of computing devices 500, 550 that may be used to implement the systems and methods described in this document, as either a client or as a server or plurality of servers.
- Computing device 500 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.
- Computing device 550 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices.
- Additionally computing device 500 or 550 can include Universal Serial Bus (USB) flash drives.
- the USB flash drives may store operating systems and other applications.
- the USB flash drives can include input/output components, such as a wireless transmitter or USB connector that may be inserted into a USB port of another computing device.
- the components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations described and/or claimed in this document.
- Computing device 500 includes a processor 502, memory 504, a storage device 506, a high-speed interface 508 connecting to memory 504 and high-speed expansion ports 510, and a low speed interface 512 connecting to low speed bus 514 and storage device 506.
- Each of the components 502, 504, 506, 508, 510, and 512 are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 502 can process instructions for execution within the computing device 500, including instructions stored in the memory 504 or on the storage device 506 to display graphical information for a GUI on an external input/output device, such as display 516 coupled to high speed interface 508.
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 500 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 504 stores information within the computing device 500.
- the memory 504 is a volatile memory unit or units.
- the memory 504 is a non-volatile memory unit or units.
- the memory 504 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 506 is capable of providing mass storage for the computing device 500.
- the storage device 506 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 504, the storage device 506, or memory on processor 502.
- the high speed controller 508 manages bandwidth-intensive operations for the computing device 500, while the low speed controller 512 manages lower bandwidth-intensive operations.
- the high-speed controller 508 is coupled to memory 504, display 516 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 510, which may accept various expansion cards (not shown).
- low-speed controller 512 is coupled to storage device 506 and low-speed expansion port 514.
- the low-speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 500 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 520, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 524. In addition, it may be implemented in a personal computer such as a laptop computer 522. Alternatively, components from computing device 500 may be combined with other components in a mobile device (not shown), such as device 550. Each of such devices may contain one or more of computing device 500, 550, and an entire system may be made up of multiple computing devices 500, 550 communicating with each other.
- Computing device 550 includes a processor 552, memory 564, an input/output device such as a display 554, a communication interface 566, and a transceiver 568, among other components.
- the device 550 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 550, 552, 564, 554, 566, and 568, are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 552 can execute instructions within the computing device 550, including instructions stored in the memory 564.
- the processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. Additionally, the processor may be implemented using any of a number of architectures.
- the processor 410 may be a CISC (Complex Instruction Set Computers) processor, a RISC (Reduced Instruction Set Computer) processor, or a MISC (Minimal Instruction Set Computer) processor.
- the processor may provide, for example, for coordination of the other components of the device 550, such as control of user interfaces, applications run by device 550, and wireless communication by device 550.
- Processor 552 may communicate with a user through control interface 558 and display interface 556 coupled to a display 554.
- the display 554 may be, for example, a TFT (Thin-Film-Transistor Liquid Crystal Display) display or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology.
- the display interface 556 may comprise appropriate circuitry for driving the display 554 to present graphical and other information to a user.
- the control interface 558 may receive commands from a user and convert them for submission to the processor 552.
- an external interface 562 may be provide in communication with processor 552, so as to enable near area communication of device 550 with other devices.
- External interface 562 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
- the memory 564 stores information within the computing device 550.
- the memory 564 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.
- Expansion memory 574 may also be provided and connected to device 550 through expansion interface 572, which may include, for example, a SIMM (Single In Line Memory Module) card interface.
- SIMM Single In Line Memory Module
- expansion memory 574 may provide extra storage space for device 550, or may also store applications or other information for device 550.
- expansion memory 574 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 574 may be provide as a security module for device 550, and may be programmed with instructions that permit secure use of device 550.
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include, for example, flash memory and/or NVRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 564, expansion memory 574, or memory on processor 552 that may be received, for example, over transceiver 568 or external interface 562..
- Device 550 may communicate wirelessly through communication interface 566, which may include digital signal processing circuitry where necessary. Communication interface 566 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 568. In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module 570 may provide additional navigation- and location-related wireless data to device 550, which may be used as appropriate by applications running on device 550.
- GPS Global Positioning System
- Device 550 may also communicate audibly using audio codec 560, which may receive spoken information from a user and convert it to usable digital information. Audio codec 560 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 550. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 550.
- Audio codec 560 may receive spoken information from a user and convert it to usable digital information. Audio codec 560 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 550. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 550.
- the computing device 550 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 580. It may also be implemented as part of a smartphone 582, personal digital assistant, or other similar mobile device.
- implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network ("LAN”), a wide area network (“WAN”), peer-to-peer networks (having ad-hoc or static members), grid computing infrastructures, and the Internet.
- LAN local area network
- WAN wide area network
- peer-to-peer networks having ad-hoc or static members
- grid computing infrastructures and the Internet.
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
Description
- This document generally describes techniques, method, systems, and mechanisms for providing results to parameterless search queries on a mobile computing device, such as a mobile telephone.
- Mobile computing devices (e.g., mobile telephones, smart telephones, personal digital assistants (PDAs), portable media players, etc.) have been configured to provide results to a user in response to search queries with parameters. For example, a user can submit a search query for directions to a nearby pizzeria to a mobile computing device. In such an example, parameters of the search query include (a) the portion of the request identifying directions as the desired result, and (b) the indication that a nearby pizzeria is the topic of the query. In response, the mobile computing device can (alone, or in combination with a remote server system) identify a nearby pizzeria and provide directions to the pizzeria to the user. Such mobile computing devices have been configured to receive a search query as text-based input (e.g., a query typed using keys), selection-based input (e.g., touchscreen selection, etc.), and audio-based input (e.g., voice input).
-
US-A1-2007/073722 relates to the calculation and presentation of mobile content expected value. Methods are described for receiving data associated with mobile content, calculating an expected value of the mobile content based at least in part on the data received, and presenting the expected value to a sponsor. -
US-B1-7,603,349 relates to user interfaces for search systems using in-line contextual queries. Systems and methods, including user interfaces, are provided for implementing searches using contextual information associated with a Web page (or other document) that a user is viewing when a query is entered. The page includes a contextual search interface that has an associated context vector representing content of the page. When the user submits a search query via the contextual search interface, the query and the context vector are both provided to the query processor and used in responding to the query. -
US-A1-2008/005067 relates to context-based search, retrieval, and awareness. A system that incorporates a user context into a computer-based search is provided. To establish the context, the innovation can identify information about a user state or context via a variety of sources and sensors. The state/context information can be used to filter, arrange and/or rank search results so as to facilitate converging on meaningful searches and results. -
US-A1-2004/267730 relates to systems and methods for performing background queries from content and activity. Systems and methods are provided that perform implicit or background queries to one or more information sources based on the ongoing activities of users. -
EP-A2-2,577,524 (published asWO-A2-2011/153079 ) is citeable for novelty only under Article 54(3) EPC. Systems, methods, and computer storage media having computer-executable instructions embodied thereon that provide content items selected based on context are provided. Contextual indicators associated with a user are identified and utilized to determine one or more content items that the user is likely to desire to access at a particular point in time. Upon receiving an indication that the user desires to perform a context-aware search, the identified content items (or references thereto) are presented automatically to the user, that is, without the user having to input any search query terms. - This document describes techniques, methods, and systems for providing results to a parameterless search query on a mobile computing device (e.g., a cellular telephone, smart telephone, a PDA, a portable media player, etc.). A parameterless search query is a search query that queries a mobile computing device for information that is relevant to a user, but where the user does not provide any parameters to further specify what is relevant to the user at a given time. Instead, a parameterless search query puts on the mobile computing device the onus of determining what the user is likely to deem relevant. To provide an indication of relevance to a user, a mobile computing device can examine a current context within which the mobile computing device and/or the user of the mobile computing device exist at the time the parameterless search query is received (which, as discussed here, can occur by the computing device acting on its own or in combination with a computer server system).
- For example, assume that a mobile computing device is moving with a user on a highway who is travelling at speed during rush hour on a workday (e.g., Monday - Friday). If the user submits a parameterless search query to the mobile computing device, the device can examine its current context (travelling on the highway during rush hour) and infer that the user would like to receive traffic information for the stretch of highway ahead. The mobile computing device can infer parameters for the search query (e.g., traffic conditions and highway number), identify results for the search query (e.g., expect to encounter stop-and-go traffic in two miles), and provide the results to the user (e.g., activate a speaker on the mobile device and audibly transmit the traffic conditions to the user).
- According to one aspect, there is provided a computer-implemented method as set out in
claim 1. - According to one aspect, there is provided an electronic system as set out in claim 13.
- The details of one or more embodiments are set forth in the accompanying drawings and the description below. Various advantages can be realized with certain implementations, such as providing information that is relevant to a user of a mobile computing device based upon minimal input from the user. Given that it can be tedious and time consuming to provide input to a mobile computing device (e.g., typing on a smaller keyboard/screen), minimizing the time it takes for a user to receive relevant information can save the user time. Additionally, users of a mobile computing device may want to submit a search query to a mobile computing device while they are occupied with another task that makes providing the input impractical or unsafe, such as driving a car. In such situations, a user can provide a simple input (e.g., press a button on the mobile device, shake the mobile device, etc.) that allows the user to receive relevant information without requiring the user to exhibit impractical or unsafe behavior.
- Other features, objects, and advantages of the invention will be apparent from the description and drawings, and from the claims.
-
-
FIG. 1 is a conceptual diagram of an example mobile computing device for providing results to parameterless search queries. -
FIGS. 2A-B are diagrams of an example system for providing results to parameterless search queries on a mobile computing device. -
FIG. 3 is a flowchart of an example technique for providing results to parameterless search queries on a mobile computing device. -
FIG. 4 is a conceptual diagram of a system that may be used to implement the techniques, systems, mechanisms, and methods described in this document. -
FIG. 5 is a block diagram of computing devices that may be used to implement the systems and methods described in this document, as either a client or as a server or plurality of servers. - Like reference symbols in the various drawings indicate like elements.
- This document describes techniques, method, systems, and mechanisms for providing results to a parameterless search query on a mobile computing device (e.g., mobile telephone, smart telephone (e.g., IPHONE, BLACKBERRY), personal digital assistant (PDA), portable media player (e.g., IPOD), etc.). A parameterless search query is a search query that does not contain any parameters for the search query (may also be termed a "zero input" query). Instead, a parameterless search query asks the mobile computing device to infer what a user of the mobile computing device wants to know (infer the parameters for the search query) based upon a current context for the mobile computing device (e.g., time of day, geographic location, calendar appointments, etc.).
- As the features provided by mobile computing devices have increased, users have become more reliant on mobile computing devices as a source of relevant information. For instance, mobile computing devices can provide a user with access to the user's email, the user's electronic calendar (e.g., meetings, appointments, reminders, etc.), up-to-date traffic information, driving directions, location-based searching (e.g., search for hotel near current location), etc.
- However, depending on the user interface (Ul) for a mobile computing device, it can often take several steps for a user to provide a search query with parameters to a mobile computing device to locate information that is relevant to the user. For example, if a user would like to quickly locate a nearby restaurant, the user may have to navigate through a variety of menus on the mobile computing device to reach a location-based search interface (e.g., interface for a map application) and then may have to type out parameters for the query (e.g., "restaurant," "near current location").
- With parameterless search queries, a user can obtain the information they are interested in without having to provide a formulated search query. Instead, using a parameterless search query, a user can access the information he/she is interested in by merely providing input to the mobile computing device that indicates a request for a parameterless search query. Such input can be simple and easy for a user to perform, such as shaking the mobile computing device a set number of times (e.g., shake one time, shake two times, etc.), pressing a button on the mobile computing device for a period of time (e.g., press and hold button for two seconds), providing a verbal command to the mobile computing device (e.g., commanding the device to "search now"), etc.
- In response to receiving input indicating a request for a parameterless search query, a mobile computing device can infer parameters for the search query based upon a current context for the mobile device. A current context for a mobile computing device can include a variety of information associated with the mobile computing device and/or a user of the mobile computing device, such as the time of day and date (e.g., 2:00 pm on May 29, 2010), upcoming and/or recent calendar appointments (e.g., meeting with John at 2:30 pm on May 29, 2010), a direction and rate of speed at which the device is travelling (e.g., northbound at 20 miles per hour), a current geographic location (e.g., on the corner of 10th Street and Marquette Avenue), recent device activity (e.g., emails sent to John regarding the 2:30 meeting), etc.
- Using a current context, a mobile computing device can infer parameters for a user's parameterless search query (infer what the user wants to know), perform a search using the inferred parameters, and provide results to the user. For example, if the current context for a mobile computing device includes the mobile device being geographically located on a highway and travelling at speed of 55 miles per hour, the mobile device may infer that the user would like to know current traffic conditions for the surrounding area. The mobile computing device can perform a search query for traffic conditions near the device's geographic location and provide the results to the user (e.g., display a map with roads that are color-coded according to traffic conditions, provide the user with a list of expected delay times for various roads nearby, etc.).
- In another example, if the current context for the mobile computing device includes the current time and date being 10:05 am on November 3, and a user of the mobile device having a conference call scheduled in his/her electronic calendar scheduled for 10:00 am on November 3 (the user is 5 minutes late for the conference call), the mobile computing device can infer that the user would like to access information for the conference call (e.g., the telephone number for the conference call). The mobile computing device can perform a search query for information related to the conference call and provide the results to the user (e.g., display a telephone number for the conference call to the user and provide an option to automatically initiate a telephone call to the telephone number).
- As described in further detail below, a mobile computing device can perform a parameterless search query locally on the mobile computing device (e.g., search data stored locally on the mobile computing device) and/or in conjunction with a computer system that is remote to the mobile computing device (e.g., provide search query over a network to a remote server system). For example, a mobile computing device can determine its current context, infer parameters for a parameterless search request, and identify and provide results as a standalone device (e.g., without interacting with other devices over a network). Results for parameterless search queries can be provided to a user in various manners, such as visually on a display for the mobile device, audibly through a speaker system of the mobile computing device, etc.
-
FIG. 1 is a conceptual diagram 100 of an examplemobile computing device 102 for providing results to parameterless search queries. The example diagram 100 provides an illustrative example of themobile computing device 102 receiving input that indicates a request for a parameterless search query, inferring parameters for the search query based upon a current context for the device, and providing results for the search query to a user. - In the example diagram 100, a user is depicted as holding the
mobile computing device 102 in his/her hand and shaking 104 themobile computing device 102. In this example, themobile computing device 102 is configured to recognize the shaking 104 as input that indicates a request for a parameterless search query. Themobile computing device 102 can be configured to recognize additional (or other) user interactions withmobile computing device 102 as input that indicates a request for a parameterless search query. - Using one or more sensors that are configured to measure movement (e.g., accelerometers, gyroscopes, etc.), the
mobile computing device 102 receivesinput 106 from the one or more sensors that indicates that the user shook thedevice 102. - As indicated above, in this example the
mobile computing device 102 is configured to recognize theinput 106 as a request to perform a parameterless search query. In response to theinput 106 indicating the user shook 104 themobile device 102, and without additional input further providing parameters for the search query (further indicating what the user would like to know), themobile computing device 102 begins performing a parameterless search query by determining a current context for the mobile device and/or for the user of the mobile device (108). - The current context includes information that describes the present state and/or surroundings of the
mobile computing device 102 and/or the user of the mobile computing device at the time theinput 106 is received. For instance, the current context can include a variety of information related to themobile computing device 102 and the user, such as information regarding the surrounding physical environment (e.g., geographic location, weather conditions, nearby businesses, volume of ambient noise, level of ambient light, image captured by the mobile device's camera, etc.), the present state of the mobile computing device 102 (e.g., rate of speed, touchscreen input activated, audio input activated, ringer on/off, etc.), time and date information (e.g., time of day, date, calendar appointments, day of the week, etc.), user activity (e.g., recent user activity, habitual user activity), etc. The current context can be determined by themobile computing device 102 using data and sensors that are local and/or remote to themobile computing device 102. - As indicated by the
example context 110 for the mobile device, the current context for the mobile computing device includes time/date information 112a,geographic location information 112b,calendar information 112c, rate ofspeed information 112d, anddevice activity information 112e. In the depicted example, the time/date information 112a lists the time as 8:00 am on a Monday and thegeographic information 112b provides that themobile computing device 102 is currently located at the user's home. Thecalendar information 112c provides that the user has no appointments scheduled for the day and the rate ofspeed information 112d indicates that themobile computing device 102 is currently stationary (travelling at 0 miles per hour). Thedevice activity information 112e indicates that the device habitually travels on a highway at a high rate of speed to the user's work at 8:05 am on Mondays. - Based upon this
example context 110, themobile computing device 102 can identify information that is likely to be relevant to the user (114). Given that thedevice 102 is located at the user's home, the current time is 8:00 am on a Monday, the device is currently stationary, and the device typically travels along a highway to the user's work at 8:05 am on Mondays, themobile computing device 102 can determine that the user is likely to drive from the user's home to the user's work in the near future. Based upon this determination, the mobile computing can infer parameters for the parameterless search query related to driving to the user's work. Since the user has travelled from his/her home to work in the past, as indicated by thedevice activity information 112e, themobile computing device 102 can determine that it is unlikely that the user would like to receive driving directions from the user's home to work. Instead, themobile computing device 102 can infer that the user is likely interested in knowing the current traffic conditions for the user's morning commute to work and can select parameters accordingly (e.g., select parameters "traffic" and "from current location to work location"). - Were the
context 110 to be changed slightly, themobile computing device 102 may infer the user is interested in different information. For example, were the user to have a meeting scheduled for 8:30 am out of the office, themobile computing device 102 may infer that the user would like driving directions to the meeting location and/or information regarding the meeting (e.g., time, subject, participants, etc.). In another example, were the user to have viewed a developing news story using an application (e.g., web browser, news application) on themobile computing device 102 at 7:30 am, themobile computing device 102 may infer that the user would like to know if there have been any recent updates to the news story. - The
mobile computing device 102 may infer the user is interested in more than one piece of information and may generate parameters for more than one search query. For instance, themobile computing device 102 may infer that the user wants to know about traffic conditions for the user's work commute and know about updates to the developing news story the user viewed earlier in the morning. Themobile computing device 102 can generate parameters and provide information to the user related to both items identified as being of potential interest to the user. - Having inferred what the user would like to know and selected parameters based upon the
current context 110, themobile computing device 102 can identify information that is likely to be relevant to the user with the selected parameters. Themobile computing device 102 can use various search-related services that are provided locally and/or remotely to obtain the sought-after information. For example, themobile computing device 102 may query a real-time traffic server system provided by a department of transportation for traffic information. In another example, themobile computing device 102 may query an application installed on themobile computing device 102 that is configured to obtain traffic information over traffic message channel (TMC) radio frequency. In a further example, themobile computing device 102 can search traffic information cached locally on themobile computing device 102. Themobile computing device 102 is capable of determining its current context and serving parameterless search requests by itself (e.g., without interacting with other computing devices and/or services over a network). - Having obtained the traffic information for the user's route to work, the mobile computing device can provide the identified information to the user (116). For example, the mobile computing device can present a
message 118 that indicates the current traffic conditions and, if they are unfavorable, suggest that the user take an alternate route. The identified information can be provided by themobile computing device 102 to the user in a variety of manners. For example, in addition to providing the user with a visual message, themobile computing device 102 may audibly transmit the message to the user with a speaker system that is attached to and/or part-of themobile computing device 102. -
FIGS. 2A-B are diagrams of anexample system 200 for providing results to parameterless search queries on an examplemobile computing device 202. Themobile computing device 202 can be configured to provide results to a parameterless search query based upon a current context associated with themobile computing device 202 and/or a user of the mobile computing device, similar to themobile computing device 102 described above with regard toFIG. 1 . - The
mobile computing device 202 is depicted as including aninput subsystem 204 through which a user of themobile computing device 202 can provide input that indicates a request for a parameterless search query. Referring toFIG. 2B , theinput subsystem 204 is depicted as including amicrophone 206a (configured to receive audio-based input), akeyboard 206b (configured to receive key-based input), atouchscreen 206c (configured to receive screen touch-based input), anaccelerometer 206d (configured to receive motion-based input), a trackball 206e (configured to receive GUI pointer-based input), acamera 206f (configured to receive visual input), and alight sensor 206g (configured to receive input based on light intensity). Theinput subsystem 204 also includes a network interface 208 (e.g., wireless network interface, universal serial bus (USB) interface, BLUETOOTH interface, public switched telephone network (PSTN) interface, Ethernet interface, cellular network interface, 3G and/or 4G network interface, etc.) that is configured to receive network-based input and output. Other types of input devices not mentioned may also be part of theinput subsystem 204. - An
input parser 210 of themobile computing device 202 can be configured to receive input from the input subsystem 204 (e.g., input events) and determine whether the received input indicates a request for a parameterless search query. Theinput parser 210 can useinput rules 212 to determine whether a particular input indicates a request for a parameterless search query. For instance, the input rules 212 can stipulate that shaking themobile computing device 202 once indicates an "undo" command (e.g., undo recent typing) and that shaking thedevice 202 twice indicates a request for a parameterless search query. The input rules 212 can be preconfigured and/or user defined. - In response to the
input parser 210 identifying input that indicates a request for a parameterless search query, a mobile devicecontext determination unit 214 can determine a current context for themobile computing device 202. The mobile devicecontext determination unit 214 can determine a current context for themobile device 202 using a variety of context monitoring units of themobile computing device 202. - For instance, a global positioning system (GPS)
unit 216 can provide geographic location information to the mobile devicecontext determination unit 214 and a travel monitor unit 218 (in conjunction with a travel data repository 220) can provide information related to a route currently being travelled and habitual routes travelled by themobile computing device 202. An activity monitor unit 222 (in conjunction with an activity data repository 224) can provide information related to recent and habitual user activity (e.g., applications used, specific information accessed at various times, etc.) on themobile device 202. Alocation monitor unit 226 can provide information regarding entities (e.g., businesses, parks, festivals, public transportation, etc.) geographically located near the current geographic location for themobile device 202. A time anddate unit 228 can provide current time and date information and a calendar unit 230 (in conjunction with a calendar data repository 232) can provide information related to appointments for the user. An email unit 234 (in conjunction with an email data repository 236) can provide email-related information (e.g., recent emails sent/received). The mobilecontext determination unit 214 can receive information from other context monitoring units not mentioned or depicted. - In some implementations, the context monitoring units 216-236 can be implemented in-part, or in-whole, remote from the
mobile computing device 202. For example, theemail unit 234 may be a thin-client that merely displays email-related data that is maintained and provided by a remote server system. In such an example, theemail unit 234 can interact with the remote server system to obtain email-related information to provide to the mobile devicecontext determination unit 214. - A
category identification unit 238 can use the current context for themobile device 202, as determined by the mobile devicecontext determination unit 214, to identify one or more categories of information that the user in which the user is likely to be interested. For example, categories of information identified by thecategory identification unit 238 may include environmental information (e.g., weather information), travel information (e.g, traffic information, driving directions, transportation schedule information, map information), geographic proximity information (e.g., nearby business information), recently updated information (e.g., real-time news updates, blog updates, email/texting conversation updates), and personal information (e.g., calendar appointments for a user, contact information for a user's acquaintances). Other categories of information not mentioned may be used and identified by thecategory identification unit 238 in response to a parameterless search query request. - The
category identification unit 238 can identify one or more categories of information for the parameterless search query using acategory data repository 240, which can define categories of information and provide various contextual factors that may indicate categories of information in which a user is interested (e.g., category-based rules, category scoring techniques, etc.). Thecategory data repository 240 can include predefined data and/or user defined data. The data stored in thecategory data repository 240 can be subject to change over time as well (e.g., themobile computing device 202 can "learn" a user's interests in various contexts and adjust the data stored in thecategory data repository 240 over time). - The
category identification unit 238 can additionally use data stored in a userbehavior data repository 242 to determine one or more categories of information in which a user is likely to be interested. The userbehavior data repository 242 can log previous requests for a parameterless search query, a context for themobile device 202 at the time of the requests, categories of information identified as likely to be relevant to the user, and the user's behavior (e.g., user appeared to use the information, user performed follow-up manual search query with defined parameters, etc.) with respect to information provided by themobile device 202. The user behavior data stored in the userbehavior data repository 242 can indicate whether a user found the identified category of information to be relevant given the mobile device's 202 current context. - For example, if the user is provided with a list of nearby restaurants (e.g., category regarding entities located geographically near the device's current geographic location) in response to a parameterless search query request and the
mobile device 202 travels to one of the restaurants, then the associated user behavior data can indicate that the user found the identified category to be relevant given the device's context. In another example, if the user is provided with the list of nearby restaurants and the user immediately opens a calendar application to locate information for an upcoming meeting, then the associated user behavior can indicate that the user found the identified category to not be relevant (e.g., the user wanted calendar information instead of restaurant information). - The
category identification unit 238 can use user behavior data from the userbehavior data repository 242 to identify a category of information that is likely to be relevant to the user. For example, thecategory identification unit 238 can attempt to identify previous contexts that are similar to a current context for themobile device 202 to receive an indication regarding a category of information that is likely to be relevant to the user. - Using a category of information identified by the
category identification unit 238, aresult identification unit 244 can identify one or more results to a parameterless search query by inferring parameters for the parameterless search query and perform the search query. For example, if thecategory identification unit 238 identified a category of travel information, theresult identification unit 244 can determine specific parameters related to travel that are likely to be relevant to the user. For instance, theresult identification unit 244 may determine that the user is likely to be interested in traffic condition for the user's commute to work. Like thecategory identification unit 238, theresult identification unit 244 can use user behavior data from the userbehavior data repository 242 to assist in determining specific parameters that are likely to be relevant to the user. - As described above with regard to
FIG. 1 , the search query can be performed local and/or remote to themobile computing device 202. For instance, in implementations where a calendar application is implemented locally on themobile computing device 202, the search query can be performed locally on the mobile computing device 202 (e.g., querying thecalendar unit 230 for relevant calendar information stored in the calendar data repository 232). Additionally, themobile computing device 202 can determine its current context and provide results to a parameterless search query as a standalone device (e.g., without interacting with a remote server system over a network). In another example, in implementations where a calendar data for a calendar application is provided on a remote server system, themobile computing device 202 can interact with the remote server system to access the relevant calendar information. - Parameters for more than one search query can be generated by the
result identification unit 244 in response to receiving a request for a parameterless search query. In such implementations, theresult identification unit 244 can receive results for each of the search queries. For instance, theresult identification unit 244 may identify that a user is likely to be interested in current traffic information and a recent update to a blog that the user frequently reads. Theresult identification unit 244 can submit search queries for both pieces of information and provide results for both search queries to a user of themobile computing device 202. It may be possible to submit a single search query for two or more distinct pieces of information. However, when the two or more distinct pieces of information are maintained by different data sources, it may be more practical to generate separate search queries, as described above. - An
output subsystem 246 of themobile computing device 202 can provide results obtained by theresult identification unit 244 to a user of thedevice 202. Theoutput subsystem 246 can include a variety of output devices, such as adisplay 248a (e.g., a liquid crystal display (LCD), a touchscreen), aprojector 248a (e.g., an image projector capable of projecting an image external to the device 202), aspeaker 248c, aheadphone jack 248d, etc. Thenetwork interface 208 can also be part of theoutput subsystem 246 and may be configured to provide the results obtained by the result identification unit 244 (e.g., transmit results to BLUETOOTH headset). - Referring to
FIG. 2A , themobile computing device 202 can wirelessly communicate with wireless transmitter 250 (e.g., a cellular network transceiver, a wireless network router, etc.) and obtain access to a network 252 (e.g., the Internet, PSTN, a cellular network, a local area network (LAN), a virtual private network (VPN), etc.). Through thenetwork 252, themobile computing device 202 can be in communication with a mobile device server system 254 (one or more networked server computers), which can be configured to provide mobile device related services and data to the mobile device 202 (e.g., provide calendar data, email data, connect telephone calls to other telephones, etc.). - The
mobile device 202 can also be in communication with one or moreinformation server systems 256 over thenetwork 252.Information server systems 256 can be server systems that provide information that may be relevant to a user's parameterless search query. For instance, ainformation server systems 256 can provide current traffic conditions, a weather forecast, and information regarding businesses located near the current geographic location for themobile device 202. -
FIG. 3 is a flowchart of anexample technique 300 for providing results to parameterless search queries on a mobile computing device. Theexample technique 300 can be performed by any of a variety of mobile computing devices, such as themobile computing device 102 described above with regard toFIG. 1 and/or themobile computing device 202 described above with regard toFIGS. 2A-B . - The
technique 300 starts atstep 302 by receiving a parameterless search request. For example, themobile computing device 102 is described above with regard toFIG. 1 as receivinginput 106 that indicates a request for a parameterless search query. As described with regard to theinput parser 210 with regard toFIG. 2B , a variety of inputs (e.g., touch, action, voice, etc.) can be configured to indicate a request for a parameterless search query. - In response to receiving a parameterless search request, a current context for the mobile device can be determined (step 304). For example, a mobile device
context determination unit 214 can determine a current context for themobile device 202 using the context monitoring units 216-236. - In some implementations, first data that indicates whether previously identified result categories were relevant to a user are retrieved (step 306). For example, the
category identification unit 238 described above with regard toFIG. 2B can retrieve user behavior data from the userbehavior data repository 242 to determine which previously identified categories of information were relevant to the user. Portion of the first data can be selected based upon previous contexts determined to be similar to the current context for the mobile device (step 308). For example, user behavior data associated with contexts that are similar to the current context can be retrieved from the userbehavior data repository 242. - Result categories can be identified based upon the current context for the mobile device (step 310). For example, given the
context 110 determined with regard to the example depicted inFIG. 1 , a travel category of identified as being likely to be relevant to the user of the mobile device 102 (e.g., the device is located at home on Monday at 8:00 am and the device habitually travels from home to work on Monday mornings at 8:05 am). - In some implementations, second data that indicates whether previously identified results were relevant to the user can be retrieved (step 312). For example, a
result identification unit 244 can access user behavior data from the userbehavior data repository 242 to determine which previously provided results the user of themobile device 202 found to be relevant given the current context of the device. Portions of the second data can be selected based on previous contexts determined to be similar to the current context (step 314). For instance, theresult identification unit 244 can select the user behavior data that is associated with previous contexts that are similar to the current context for themobile computing device 202. - Results can be identified for the parameterless search request based upon the current context (step 316). For example, the
result identification unit 244 can infer parameters for the parameterless search request based upon the current context of themobile device 202 and use the inferred parameters to identify results that are likely to be relevant to the user of the mobile device. Results can be identified locally and/or remotely from the mobile device. For instance, if themobile device 202 infers that a parameterless search request refers to a user's upcoming schedule, themobile computing device 202 can access thecalendar unit 230 locally to obtain the schedule information. Themobile device 202 is capable of determining its current context and providing results to a parameterless search request as a standalone device (e.g., without being connected to other devices over a network). - In some implementations, a subsystem can be selected for providing the results (step 318). For example, one or more of the
output devices 248a-d of theoutput subsystem 246 for themobile computing device 202 can be selected to provide the identified results to the user. The subsystem can be selected based upon a variety for factors, such as the manner in which the input indicating a request for a parameterless search was received (e.g., verbal input, shaking the device, etc.) and the current context for the mobile device. For instance, if the request for parameterless search is received as a verbal request, then the selected subsystem can be an audio output (e.g., thespeaker 248c). In another example, if the current context indicates that the user may be in a location where audio output is undesired (e.g., user is in a library), then the selected subsystem can provide a visual output (e.g., thedisplay 248a). - The results are provided to the user (step 320). A response from the user with regard to the provided results can be recorded by a mobile computing device as user behavior data and used to improve the results provided in response to future parameterless search requests. For example, if the user is provided with a recent update to a blog that the user frequently reads and the user sends a link to the updated blog posting to his/her friends, the user sending the link can be recorded as user behavior data in the user
behavior data repository 242 of themobile computing device 202 and used to provide results to future parameterless search requests. -
FIG. 4 is a conceptual diagram of a system that may be used to implement the techniques, systems, mechanisms, and methods described in this document.Mobile computing device 410 can wirelessly communicate withbase station 440, which can provide the mobile computing device wireless access tonumerous services 460 through anetwork 450. - In this illustration, the
mobile computing device 410 is depicted as a handheld mobile telephone (e.g., a smartphone or an application telephone) that includes atouchscreen display device 412 for presenting content to a user of themobile computing device 410. Themobile computing device 410 includes various input devices (e.g.,keyboard 414 and touchscreen display device 412) for receiving user-input that influences the operation of themobile computing device 410. In further implementations, themobile computing device 410 may be a laptop computer, a tablet computer, a personal digital assistant, an embedded system (e.g., a car navigation system), a desktop computer, or a computerized workstation. - The
mobile computing device 410 may include various visual, auditory, and tactile user-output mechanisms. An example visual output mechanism isdisplay device 412, which can visually display video, graphics, images, and text that combine to provide a visible user interface. For example, thedisplay device 412 may be a 3.7 inch AMOLED screen. Other visual output mechanisms may include LED status lights (e.g., a light that blinks when a voicemail has been received). - An example tactile output mechanism is a small electric motor that is connected to an unbalanced weight to provide a vibrating alert (e.g., to vibrate in order to alert a user of an incoming telephone call or confirm user contact with the touchscreen 412). Further, the
mobile computing device 410 may include one ormore speakers 420 that convert an electrical signal into sound, for example, music, an audible alert, or voice of an individual in a telephone call. - An example mechanism for receiving user-input includes
keyboard 414, which may be a full qwerty keyboard or a traditional keypad that includes keys for the digits '0-4', '*', and '#.' Thekeyboard 414 receives input when a user physically contacts or depresses a keyboard key. User manipulation of atrackball 416 or interaction with a trackpad enables the user to supply directional and rate of rotation information to the mobile computing device 410 (e.g., to manipulate a position of a cursor on the display device 412). - The
mobile computing device 410 may be able to determine a position of physical contact with the touchscreen display device 412 (e.g., a position of contact by a finger or a stylus). Using thetouchscreen 412, various "virtual" input mechanisms may be produced, where a user interacts with a graphical user interface element depicted on thetouchscreen 412 by contacting the graphical user interface element. An example of a "virtual" input mechanism is a "software keyboard," where a keyboard is displayed on the touchscreen and a user selects keys by pressing a region of thetouchscreen 412 that corresponds to each key. - The
mobile computing device 410 may include mechanical or touchsensitive buttons 418a-d. Additionally, the mobile computing device may include buttons for adjusting volume output by the one ormore speakers 420, and a button for turning the mobile computing device on or off. Amicrophone 422 allows themobile computing device 410 to convert audible sounds into an electrical signal that may be digitally encoded and stored in computer-readable memory, or transmitted to another computing device. Themobile computing device 410 may also include a digital compass, an accelerometer, proximity sensors, and ambient light sensors. - An operating system may provide an interface between the mobile computing device's hardware (e.g., the input/output mechanisms and a processor executing instructions retrieved from computer-readable medium) and software. Example operating systems include the ANDROID mobile computing device platform; APPLE IPHONE/MAC OS X operating systems; MICROSOFT WINDOWS 7/WINDOWS MOBILE operating systems; SYMBIAN operating system; RIM BLACKBERRY operating system; PALM WEB operating system; a variety of UNIX-flavored operating systems; or a proprietary operating system for computerized devices. The operating system may provide a platform for the execution of application programs that facilitate interaction between the computing device and a user.
- The
mobile computing device 410 may present a graphical user interface with thetouchscreen 412. A graphical user interface is a collection of one or more graphical interface elements and may be static (e.g., the display appears to remain the same over a period of time), or may be dynamic (e.g., the graphical user interface includes graphical interface elements that animate without user input). - A graphical interface element may be text, lines, shapes, images, or combinations thereof. For example, a graphical interface element may be an icon that is displayed on the desktop and the icon's associated text. In some examples, a graphical interface element is selectable with user-input. For example, a user may select a graphical interface element by pressing a region of the touchscreen that corresponds to a display of the graphical interface element. In some examples, the user may manipulate a trackball to highlight a single graphical interface element as having focus. User-selection of a graphical interface element may invoke a pre-defined action by the mobile computing device. In some examples, selectable graphical interface elements further or alternatively correspond to a button on the keyboard 404. User-selection of the button may invoke the pre-defined action.
- In some examples, the operating system provides a "desktop" user interface that is displayed upon turning on the
mobile computing device 410, activating themobile computing device 410 from a sleep state, upon "unlocking" themobile computing device 410, or upon receiving user-selection of the "home"button 418c. The desktop graphical interface may display several icons that, when selected with user-input, invoke corresponding application programs. An invoked application program may present a graphical interface that replaces the desktop graphical interface until the application program terminates or is hidden from view. - User-input may manipulate a sequence of
mobile computing device 410 operations. For example, a single-action user input (e.g., a single tap of the touchscreen, swipe across the touchscreen, contact with a button, or combination of these at a same time) may invoke an operation that changes a display of the user interface. Without the user-input, the user interface may not have changed at a particular time. For example, a multi-touch user input with thetouchscreen 412 may invoke a mapping application to "zoom-in" on a location, even though the mapping application may have by default zoomed-in after several seconds. - The desktop graphical interface can also display "widgets." A widget is one or more graphical interface elements that are associated with an application program that has been executed, and that display on the desktop content controlled by the executing application program. Unlike an application program, which may not be invoked until a user selects a corresponding icon, a widget's application program may start with the mobile telephone. Further, a widget may not take focus of the full display. Instead, a widget may only "own" a small portion of the desktop, displaying content and receiving touchscreen user-input within the portion of the desktop.
- The
mobile computing device 410 may include one or more location-identification mechanisms. A location-identification mechanism may include a collection of hardware and software that provides the operating system and application programs an estimate of the mobile telephone's geographical position. A location-identification mechanism may employ satellite-based positioning techniques, base station transmitting antenna identification, multiple base station triangulation, internet access point IP location determinations, inferential identification of a user's position based on search engine queries, and user-supplied identification of location (e.g., by "checking in" to a location). - The
mobile computing device 410 may include other application modules and hardware. A call handling unit may receive an indication of an incoming telephone call and provide a user capabilities to answer the incoming telephone call. A media player may allow a user to listen to music or play movies that are stored in local memory of themobile computing device 410. Themobile telephone 410 may include a digital camera sensor, and corresponding image and video capture and editing software. An internet browser may enable the user to view content from a web page by typing in an addresses corresponding to the web page or selecting a link to the web page. - The
mobile computing device 410 may include an antenna to wirelessly communicate information with thebase station 440. Thebase station 440 may be one of many base stations in a collection of base stations (e.g., a mobile telephone cellular network) that enables themobile computing device 410 to maintain communication with anetwork 450 as the mobile computing device is geographically moved. Thecomputing device 410 may alternatively or additionally communicate with thenetwork 450 through a Wi-Fi router or a wired connection (e.g., Ethernet, USB, or FIREWIRE). Thecomputing device 410 may also wirelessly communicate with other computing devices using BLUETOOTH protocols, or may employ an ad-hoc wireless network. - A service provider that operates the network of base stations may connect the
mobile computing device 410 to thenetwork 450 to enable communication between themobile computing device 410 and other computerized devices that provideservices 460. Although theservices 460 may be provided over different networks (e.g., the service provider's internal network, the Public Switched Telephone Network, and the Internet),network 450 is illustrated as a single network. The service provider may operate aserver system 452 that routes information packets and voice data between themobile computing device 410 and computing devices associated with theservices 460. - The
network 450 may connect themobile computing device 410 to the Public Switched Telephone Network (PSTN) 462 in order to establish voice or fax communication between themobile computing device 410 and another computing device. For example, the serviceprovider server system 452 may receive an indication from thePSTN 462 of an incoming call for themobile computing device 410. Conversely, themobile computing device 410 may send a communication to the serviceprovider server system 452 initiating a telephone call with a telephone number that is associated with a device accessible through thePSTN 462. - The
network 450 may connect themobile computing device 410 with a Voice over Internet Protocol (VoIP)service 464 that routes voice communications over an IP network, as opposed to the PSTN. For example, a user of themobile computing device 410 may invoke a VoIP application and initiate a call using the program. The serviceprovider server system 452 may forward voice data from the call to a VoIP service, which may route the call over the internet to a corresponding computing device, potentially using the PSTN for a final leg of the connection. - An
application store 466 may provide a user of themobile computing device 410 the ability to browse a list of remotely stored application programs that the user may download over thenetwork 450 and install on themobile computing device 410. Theapplication store 466 may serve as a repository of applications developed by third-party application developers. An application program that is installed on themobile computing device 410 may be able to communicate over thenetwork 450 with server systems that are designated for the application program. For example, a VoIP application program may be downloaded from theApplication Store 466, enabling the user to communicate with theVoIP service 464. - The
mobile computing device 410 may access content on theinternet 468 throughnetwork 450. For example, a user of themobile computing device 410 may invoke a web browser application that requests data from remote computing devices that are accessible at designated universal resource locations. In various examples, some of theservices 460 are accessible over the internet. - The mobile computing device may communicate with a
personal computer 470. For example, thepersonal computer 470 may be the home computer for a user of themobile computing device 410. Thus, the user may be able to stream media from hispersonal computer 470. The user may also view the file structure of hispersonal computer 470, and transmit selected documents between the computerized devices. - A
voice recognition service 472 may receive voice communication data recorded with the mobile computing device'smicrophone 422, and translate the voice communication into corresponding textual data. In some examples, the translated text is provided to a search engine as a web query, and responsive search engine search results are transmitted to themobile computing device 410. - The
mobile computing device 410 may communicate with asocial network 474. The social network may include numerous members, some of which have agreed to be related as acquaintances. Application programs on themobile computing device 410 may access thesocial network 474 to retrieve information based on the acquaintances of the user of the mobile computing device. For example, an "address book" application program may retrieve telephone numbers for the user's acquaintances. In various examples, content may be delivered to themobile computing device 410 based on social network distances from the user to other members. For example, advertisement and news article content may be selected for the user based on a level of interaction with such content by members that are "close" to the user (e.g., members that are "friends" or "friends of friends"). - The
mobile computing device 410 may access a personal set ofcontacts 476 throughnetwork 450. Each contact may identify an individual and include information about that individual (e.g., a phone number, an email address, and a birthday). Because the set of contacts is hosted remotely to themobile computing device 410, the user may access and maintain thecontacts 476 across several devices as a common set of contacts. - The
mobile computing device 410 may access cloud-basedapplication programs 478. Cloud-computing provides application programs (e.g., a word processor or an email program) that are hosted remotely from themobile computing device 410, and may be accessed by thedevice 410 using a web browser or a dedicated program. Example cloud-based application programs include GOOGLE DOCS word processor and spreadsheet service, GOOGLE GMAIL webmail service, and PICASA picture manager. -
Mapping service 480 can provide themobile computing device 410 with street maps, route planning information, and satellite images. An example mapping service is GOOGLE MAPS. Themapping service 480 may also receive queries and return location-specific results. For example, themobile computing device 410 may send an estimated location of the mobile computing device and a user-entered query for "pizza places" to themapping service 480. Themapping service 480 may return a street map with "markers" superimposed on the map that identify geographical locations of nearby "pizza places." - Turn-by-
turn service 482 may provide themobile computing device 410 with turn-by-turn directions to a user-supplied destination. For example, the turn-by-turn service 482 may stream to device 410 a street-level view of an estimated location of the device, along with data for providing audio commands and superimposing arrows that direct a user of thedevice 410 to the destination. - Various forms of streaming
media 484 may be requested by themobile computing device 410. For example,computing device 410 may request a stream for a pre-recorded video file, a live television program, or a live radio program. Example services that provide streaming media include YOUTUBE and PANDORA. - A
micro-blogging service 486 may receive from the mobile computing device 410 a user-input post that does not identify recipients of the post. Themicro-blogging service 486 may disseminate the post to other members of themicro-blogging service 486 that agreed to subscribe to the user. - A
search engine 488 may receive user-entered textual or verbal queries from themobile computing device 410, determine a set of internet-accessible documents that are responsive to the query, and provide to thedevice 410 information to display a list of search results for the responsive documents. In examples where a verbal query is received, thevoice recognition service 472 may translate the received audio into a textual query that is sent to the search engine. - These and other services may be implemented in a
server system 490. A server system may be a combination of hardware and software that provides a service or a set of services. For example, a set of physically separate and networked computerized devices may operate together as a logical server system unit to handle the operations necessary to offer a service to hundreds of individual computing devices. - In various implementations, operations that are performed "in response" to another operation (e.g., a determination or an identification) are not performed if the prior operation is unsuccessful (e.g., if the determination was not performed). Features in this document that are described with conditional language may describe implementations that are optional. In some examples, "transmitting" from a first device to a second device includes the first device placing data into a network, but may not include the second device receiving the data. Conversely, "receiving" from a first device may include receiving the data from a network, but may not include the first device transmitting the data.
-
FIG. 5 is a block diagram ofcomputing devices 500, 550 that may be used to implement the systems and methods described in this document, as either a client or as a server or plurality of servers. Computing device 500 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.Computing device 550 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices. Additionally computingdevice 500 or 550 can include Universal Serial Bus (USB) flash drives. The USB flash drives may store operating systems and other applications. The USB flash drives can include input/output components, such as a wireless transmitter or USB connector that may be inserted into a USB port of another computing device. The components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations described and/or claimed in this document. - Computing device 500 includes a
processor 502,memory 504, astorage device 506, a high-speed interface 508 connecting tomemory 504 and high-speed expansion ports 510, and alow speed interface 512 connecting tolow speed bus 514 andstorage device 506. Each of thecomponents processor 502 can process instructions for execution within the computing device 500, including instructions stored in thememory 504 or on thestorage device 506 to display graphical information for a GUI on an external input/output device, such asdisplay 516 coupled tohigh speed interface 508. In other implementations, multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory. Also, multiple computing devices 500 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system). - The
memory 504 stores information within the computing device 500. In one implementation, thememory 504 is a volatile memory unit or units. In another implementation, thememory 504 is a non-volatile memory unit or units. Thememory 504 may also be another form of computer-readable medium, such as a magnetic or optical disk. - The
storage device 506 is capable of providing mass storage for the computing device 500. In one implementation, thestorage device 506 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as thememory 504, thestorage device 506, or memory onprocessor 502. - The
high speed controller 508 manages bandwidth-intensive operations for the computing device 500, while thelow speed controller 512 manages lower bandwidth-intensive operations. Such allocation of functions is exemplary only. In one implementation, the high-speed controller 508 is coupled tomemory 504, display 516 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 510, which may accept various expansion cards (not shown). In the implementation, low-speed controller 512 is coupled tostorage device 506 and low-speed expansion port 514. The low-speed expansion port, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter. - The computing device 500 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a
standard server 520, or multiple times in a group of such servers. It may also be implemented as part of arack server system 524. In addition, it may be implemented in a personal computer such as alaptop computer 522. Alternatively, components from computing device 500 may be combined with other components in a mobile device (not shown), such asdevice 550. Each of such devices may contain one or more ofcomputing device 500, 550, and an entire system may be made up ofmultiple computing devices 500, 550 communicating with each other. -
Computing device 550 includes aprocessor 552,memory 564, an input/output device such as adisplay 554, acommunication interface 566, and atransceiver 568, among other components. Thedevice 550 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage. Each of thecomponents - The
processor 552 can execute instructions within thecomputing device 550, including instructions stored in thememory 564. The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. Additionally, the processor may be implemented using any of a number of architectures. For example, theprocessor 410 may be a CISC (Complex Instruction Set Computers) processor, a RISC (Reduced Instruction Set Computer) processor, or a MISC (Minimal Instruction Set Computer) processor. The processor may provide, for example, for coordination of the other components of thedevice 550, such as control of user interfaces, applications run bydevice 550, and wireless communication bydevice 550. -
Processor 552 may communicate with a user throughcontrol interface 558 anddisplay interface 556 coupled to adisplay 554. Thedisplay 554 may be, for example, a TFT (Thin-Film-Transistor Liquid Crystal Display) display or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology. Thedisplay interface 556 may comprise appropriate circuitry for driving thedisplay 554 to present graphical and other information to a user. Thecontrol interface 558 may receive commands from a user and convert them for submission to theprocessor 552. In addition, anexternal interface 562 may be provide in communication withprocessor 552, so as to enable near area communication ofdevice 550 with other devices.External interface 562 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used. - The
memory 564 stores information within thecomputing device 550. Thememory 564 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.Expansion memory 574 may also be provided and connected todevice 550 throughexpansion interface 572, which may include, for example, a SIMM (Single In Line Memory Module) card interface.Such expansion memory 574 may provide extra storage space fordevice 550, or may also store applications or other information fordevice 550. Specifically,expansion memory 574 may include instructions to carry out or supplement the processes described above, and may include secure information also. Thus, for example,expansion memory 574 may be provide as a security module fordevice 550, and may be programmed with instructions that permit secure use ofdevice 550. In addition, secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner. - The memory may include, for example, flash memory and/or NVRAM memory, as discussed below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the
memory 564,expansion memory 574, or memory onprocessor 552 that may be received, for example, overtransceiver 568 orexternal interface 562.. -
Device 550 may communicate wirelessly throughcommunication interface 566, which may include digital signal processing circuitry where necessary.Communication interface 566 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 568. In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System)receiver module 570 may provide additional navigation- and location-related wireless data todevice 550, which may be used as appropriate by applications running ondevice 550. -
Device 550 may also communicate audibly usingaudio codec 560, which may receive spoken information from a user and convert it to usable digital information.Audio codec 560 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset ofdevice 550. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating ondevice 550. - The
computing device 550 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as acellular telephone 580. It may also be implemented as part of asmartphone 582, personal digital assistant, or other similar mobile device. - Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- These computer programs (also known as programs, software, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine language. As used herein, the terms "machine-readable medium" "computer-readable medium" refers to any computer program product, apparatus and/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
- To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- The systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network ("LAN"), a wide area network ("WAN"), peer-to-peer networks (having ad-hoc or static members), grid computing infrastructures, and the Internet.
- The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- Although a few implementations have been described in detail above, other modifications are possible. Moreover, other mechanisms for providing results to parameterless search queries on a mobile computing device may be used. In addition, the logic flows depicted in the figures do not require the particular order shown, or sequential order, to achieve desirable results. Other steps may be provided, or steps may be eliminated, from the described flows, and other components may be added to, or removed from, the described systems. Accordingly, other implementations are within the scope of the following claims.
Claims (13)
- A computer-implemented method comprising:receiving a parameterless search request, which was provided to a mobile computing device (102,202), for information that is relevant to a user of the mobile computing device;in response to the received parameterless search request, identifying with a digital computer system one or more results that are determined to be relevant to the user of the mobile computing device (102,202) based upon a current context (110) of the mobile computing device; andproviding the results for display to a user of the mobile computing device (102,202),further comprising:identifying one or more result categories that are likely to be relevant to the user of the mobile computing device (102,202) based upon the current context (110) of the mobile computing device, wherein the one or more identified results are associated with the identified one or more result categories;retrieving first data that indicates whether the user found result categories previously identified in response to previously received parameterless search requests to be relevant; andselecting a portion of the retrieved first data associated with previous contexts for the mobile computing device (102,202) that are determined to have a threshold degree of similarity to the current context (110) for the mobile computing device, wherein the one or more result categories are identified based upon the selected portion of the retrieved first data.
- The computer-implemented method of claim 1, wherein the parameterless search request comprises an indication that the user shook the mobile computing device (102,202).
- The computer-implemented method of any of claims 1-2, further comprising determining the current context (110) for the mobile computing device (102,202) in response to the received parameterless search request.
- The computer-implemented method of any of claims 1-3, wherein the current context (110) includes a current geographic location (112b) of the mobile computing device, and wherein the identified one or more results include information regarding one or more entities located within a threshold distance of the current geographic location of the mobile computing device (102,202).
- The computer-implemented method of any of claims 1-4, wherein the current context (110) further includes a current rate of speed (112d) at which the mobile computing device (102,202) is travelling, and wherein, when the current rate of speed is determined to exceed a threshold rate of speed, the identified one or more results include information regarding current traffic conditions for a route along which the mobile computing device is travelling.
- The computer-implemented method of any of claims 1-5, wherein the current context (110) includes a current time of day (112a), a current date, and calendar appointments for the user, and wherein, when one or more of the calendar appointments for the user that are determined to occur within a threshold period of time of the current time of day and the current date, the identified one or more results include information regarding the one or more of the calendar appointments.
- The computer-implemented method of any of claims 1-6, wherein the current context (110) includes the user's recent activity on the mobile computing device (102,202), and wherein, when information associated with at least a portion of the user's recent activity is determined to have been updated since the user's associated activity, the identified one or more results includes at least a portion of the updated information.
- The computer-implemented method of claim 1, wherein the identified one or more result categories are selected from the group consisting of: a travel category, a geographic proximity category, an environment category, a recent updated information category, and a personal information category.
- The computer-implemented method of any of claims 1-8, further comprising:retrieving second data that indicates whether the user found results previously identified in response to previously received parameterless search requests to be relevant;selecting a portion of the retrieved second data associated with previous contexts for the mobile computing device (102,202) that are determined to have a threshold degree of similarity to the current context (110) for the mobile computing device; andwherein the one or more result are identified based upon the selected portion of the retrieved second data.
- The computer-implemented method of any of claims 1-9, further comprising selecting a subsystem (246) of the mobile computing device (102,202) to use for providing the selected information to the user based upon, at least in part, a manner in which the input was received by the mobile computing device; and
wherein the selected information is provided using the selected subsystem (246) of the mobile computing device (102,202). - The computer-implemented method of any of claims 1-10, wherein the digital computer system is remote from the mobile computing device (102,202).
- The computer-implemented method of any of claims 1-10, wherein the digital computer system comprises the mobile computing device (102,202).
- An electronic system comprising:a mobile computing device (102,202);an input subsystem (204) of the mobile computing device (102,202) that is configured to receive a parameterless search request for information that is relevant to a user of the mobile computing device;means (244) for identifying, in response to a parameterless search request received by the input subsystem, one or more results that are determined to be relevant to the user of the mobile computing device (102,202) based upon a current context (110) of the mobile computing device;means (238) for identifying one or more result categories that are likely to be relevant to the user of the mobile computing device (102,202) based upon the current context (110) of the mobile computing device, wherein the one or more identified results are associated with the identified one or more result categories;means for retrieving first data that indicates whether the user found result categories previously identified in response to previously received parameterless search requests to be relevant;means for selecting a portion of the retrieved first data associated with previous contexts for the mobile computing device (102,202) that are determined to have a threshold degree of similarity to the current context (110) for the mobile computing device, wherein the one or more result categories are identified based upon the selected portion of the retrieved first data; andan output subsystem (246) of the mobile computing device (102,202) that is configured to provide the results to the user of the mobile computing device.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
EP19193838.0A EP3591541A1 (en) | 2010-08-30 | 2011-08-30 | Providing results to parameterless search queries |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/871,562 US8478519B2 (en) | 2010-08-30 | 2010-08-30 | Providing results to parameterless search queries |
PCT/US2011/049685 WO2012030793A2 (en) | 2010-08-30 | 2011-08-30 | Providing results to parameterless search queries |
Related Child Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP19193838.0A Division-Into EP3591541A1 (en) | 2010-08-30 | 2011-08-30 | Providing results to parameterless search queries |
EP19193838.0A Division EP3591541A1 (en) | 2010-08-30 | 2011-08-30 | Providing results to parameterless search queries |
Publications (3)
Publication Number | Publication Date |
---|---|
EP2612264A2 EP2612264A2 (en) | 2013-07-10 |
EP2612264A4 EP2612264A4 (en) | 2017-11-15 |
EP2612264B1 true EP2612264B1 (en) | 2019-10-09 |
Family
ID=45698291
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP11822471.6A Active EP2612264B1 (en) | 2010-08-30 | 2011-08-30 | Providing results to parameterless search queries |
EP19193838.0A Pending EP3591541A1 (en) | 2010-08-30 | 2011-08-30 | Providing results to parameterless search queries |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP19193838.0A Pending EP3591541A1 (en) | 2010-08-30 | 2011-08-30 | Providing results to parameterless search queries |
Country Status (5)
Country | Link |
---|---|
US (9) | US8478519B2 (en) |
EP (2) | EP2612264B1 (en) |
KR (2) | KR101539687B1 (en) |
AU (2) | AU2011296121B2 (en) |
WO (1) | WO2012030793A2 (en) |
Families Citing this family (175)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8677377B2 (en) | 2005-09-08 | 2014-03-18 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US10002189B2 (en) | 2007-12-20 | 2018-06-19 | Apple Inc. | Method and apparatus for searching using an active ontology |
US9330720B2 (en) | 2008-01-03 | 2016-05-03 | Apple Inc. | Methods and apparatus for altering audio output signals |
US8996376B2 (en) | 2008-04-05 | 2015-03-31 | Apple Inc. | Intelligent text-to-speech conversion |
US20100030549A1 (en) | 2008-07-31 | 2010-02-04 | Lee Michael M | Mobile device having human language translation capability with positional feedback |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US8682667B2 (en) | 2010-02-25 | 2014-03-25 | Apple Inc. | User profiling for selecting user specific voice input processing information |
KR101116434B1 (en) * | 2010-04-14 | 2012-03-07 | 엔에이치엔(주) | System and method for supporting query using image |
US8195741B2 (en) * | 2010-05-28 | 2012-06-05 | Microsoft Corporation | Cached and server views with automatic caching and smooth scrolling |
US8478519B2 (en) * | 2010-08-30 | 2013-07-02 | Google Inc. | Providing results to parameterless search queries |
US9424002B2 (en) | 2010-12-03 | 2016-08-23 | Microsoft Technology Licensing, Llc | Meta-application framework |
US8612600B2 (en) * | 2010-12-07 | 2013-12-17 | Nec Laboratories America, Inc. | Negotiation tool and method for cloud infrastructure data sharing |
US9398396B2 (en) * | 2011-01-18 | 2016-07-19 | Qualcomm Incorporated | Method and apparatus for characterizing context of a mobile device |
US9262612B2 (en) | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
US10057736B2 (en) | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
US20130018907A1 (en) * | 2011-07-14 | 2013-01-17 | Qualcomm Incorporated | Dynamic Subsumption Inference |
US8683008B1 (en) | 2011-08-04 | 2014-03-25 | Google Inc. | Management of pre-fetched mapping data incorporating user-specified locations |
US9904703B1 (en) * | 2011-09-06 | 2018-02-27 | Google Llc | Determining content of interest based on social network interactions and information |
US8280414B1 (en) | 2011-09-26 | 2012-10-02 | Google Inc. | Map tile data pre-fetching based on mobile device generated event analysis |
KR20130040462A (en) * | 2011-10-14 | 2013-04-24 | 삼성전자주식회사 | Apparatas and method for system restore in a user terminal |
US9146115B2 (en) * | 2011-10-18 | 2015-09-29 | Microsoft Technology Licensing, Llc | Location enhanced meetings and collaboration |
WO2013063088A2 (en) | 2011-10-26 | 2013-05-02 | Google Inc. | Indicating location status |
US9275374B1 (en) | 2011-11-15 | 2016-03-01 | Google Inc. | Method and apparatus for pre-fetching place page data based upon analysis of user activities |
US8711181B1 (en) | 2011-11-16 | 2014-04-29 | Google Inc. | Pre-fetching map data using variable map tile radius |
US8886715B1 (en) | 2011-11-16 | 2014-11-11 | Google Inc. | Dynamically determining a tile budget when pre-fetching data in a client device |
US9063951B1 (en) | 2011-11-16 | 2015-06-23 | Google Inc. | Pre-fetching map data based on a tile budget |
US9305107B2 (en) * | 2011-12-08 | 2016-04-05 | Google Inc. | Method and apparatus for pre-fetching place page data for subsequent display on a mobile computing device |
US9197713B2 (en) | 2011-12-09 | 2015-11-24 | Google Inc. | Method and apparatus for pre-fetching remote resources for subsequent display on a mobile computing device |
US9389088B2 (en) | 2011-12-12 | 2016-07-12 | Google Inc. | Method of pre-fetching map data for rendering and offline routing |
US8803920B2 (en) | 2011-12-12 | 2014-08-12 | Google Inc. | Pre-fetching map tile data along a route |
US10134385B2 (en) | 2012-03-02 | 2018-11-20 | Apple Inc. | Systems and methods for name pronunciation |
US20140108448A1 (en) * | 2012-03-30 | 2014-04-17 | Intel Corporation | Multi-sensor velocity dependent context aware voice recognition and summarization |
WO2013154947A1 (en) | 2012-04-09 | 2013-10-17 | Vivek Ventures, LLC | Clustered information processing and searching with structured-unstructured database bridge |
US10417037B2 (en) | 2012-05-15 | 2019-09-17 | Apple Inc. | Systems and methods for integrating third party services with a digital assistant |
US9721563B2 (en) | 2012-06-08 | 2017-08-01 | Apple Inc. | Name recognition system |
US20140067564A1 (en) | 2012-08-30 | 2014-03-06 | Ebay Inc. | Shopping list creator and optimizer |
US10140372B2 (en) * | 2012-09-12 | 2018-11-27 | Gracenote, Inc. | User profile based on clustering tiered descriptors |
US9111011B2 (en) | 2012-12-10 | 2015-08-18 | Google Inc. | Local query suggestions |
US20140179295A1 (en) * | 2012-12-20 | 2014-06-26 | Enno Luebbers | Deriving environmental context and actions from ad-hoc state broadcast |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
CN103175535B (en) * | 2013-02-27 | 2016-08-24 | 深圳市凯立德科技股份有限公司 | A kind of shake air navigation aid and mobile navigation equipment |
US10652394B2 (en) | 2013-03-14 | 2020-05-12 | Apple Inc. | System and method for processing voicemail |
US10572476B2 (en) * | 2013-03-14 | 2020-02-25 | Apple Inc. | Refining a search based on schedule items |
US9367811B2 (en) * | 2013-03-15 | 2016-06-14 | Qualcomm Incorporated | Context aware localization, mapping, and tracking |
US10748529B1 (en) | 2013-03-15 | 2020-08-18 | Apple Inc. | Voice activated device for use with a voice-based digital assistant |
WO2014197334A2 (en) | 2013-06-07 | 2014-12-11 | Apple Inc. | System and method for user-specified pronunciation of words for speech synthesis and recognition |
WO2014197335A1 (en) | 2013-06-08 | 2014-12-11 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
KR101959188B1 (en) | 2013-06-09 | 2019-07-02 | 애플 인크. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US9715548B2 (en) | 2013-08-02 | 2017-07-25 | Google Inc. | Surfacing user-specific data records in search |
US9773018B2 (en) | 2013-08-13 | 2017-09-26 | Ebay Inc. | Mapping item categories to ambiguous queries by geo-location |
US9234763B1 (en) * | 2013-08-14 | 2016-01-12 | Google Inc. | Systems and methods for identifying and selecting personalized waypoints for presentation on a map |
US9792003B1 (en) * | 2013-09-27 | 2017-10-17 | Audible, Inc. | Dynamic format selection and delivery |
US9485543B2 (en) | 2013-11-12 | 2016-11-01 | Google Inc. | Methods, systems, and media for presenting suggestions of media content |
US9552395B2 (en) * | 2013-11-13 | 2017-01-24 | Google Inc. | Methods, systems, and media for presenting recommended media content items |
US10296160B2 (en) | 2013-12-06 | 2019-05-21 | Apple Inc. | Method for extracting salient dialog usage from live data |
US9800360B2 (en) | 2014-02-06 | 2017-10-24 | Honda Motor Co., Ltd. | Management of stations using preferences from social networking profiles |
US20150242496A1 (en) * | 2014-02-21 | 2015-08-27 | Microsoft Corporation | Local content filtering |
US10474671B2 (en) | 2014-05-12 | 2019-11-12 | Google Llc | Interpreting user queries based on nearby locations |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US9633004B2 (en) | 2014-05-30 | 2017-04-25 | Apple Inc. | Better resolution when referencing to concepts |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
WO2016028695A1 (en) | 2014-08-20 | 2016-02-25 | Google Inc. | Interpreting user queries based on device orientation |
US9818400B2 (en) | 2014-09-11 | 2017-11-14 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US10074360B2 (en) | 2014-09-30 | 2018-09-11 | Apple Inc. | Providing an indication of the suitability of speech recognition |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US20160171122A1 (en) * | 2014-12-10 | 2016-06-16 | Ford Global Technologies, Llc | Multimodal search response |
US11240349B2 (en) * | 2014-12-31 | 2022-02-01 | Ebay Inc. | Multimodal content recognition and contextual advertising and content delivery |
US10152299B2 (en) | 2015-03-06 | 2018-12-11 | Apple Inc. | Reducing response latency of intelligent automated assistants |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US10567477B2 (en) | 2015-03-08 | 2020-02-18 | Apple Inc. | Virtual assistant continuity |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US10460227B2 (en) | 2015-05-15 | 2019-10-29 | Apple Inc. | Virtual assistant in a communication session |
US10200824B2 (en) | 2015-05-27 | 2019-02-05 | Apple Inc. | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US9578173B2 (en) | 2015-06-05 | 2017-02-21 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US11025565B2 (en) | 2015-06-07 | 2021-06-01 | Apple Inc. | Personalized prediction of responses for instant messaging |
US20160371340A1 (en) * | 2015-06-19 | 2016-12-22 | Lenovo (Singapore) Pte. Ltd. | Modifying search results based on context characteristics |
US20160378747A1 (en) | 2015-06-29 | 2016-12-29 | Apple Inc. | Virtual assistant for media playback |
EP3320457B1 (en) * | 2015-07-10 | 2021-04-07 | Whether Or Knot LLC | System and method for electronic data distribution |
US10740384B2 (en) | 2015-09-08 | 2020-08-11 | Apple Inc. | Intelligent automated assistant for media search and playback |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US10069940B2 (en) | 2015-09-10 | 2018-09-04 | Microsoft Technology Licensing, Llc | Deployment meta-data based applicability targetting |
US9965604B2 (en) | 2015-09-10 | 2018-05-08 | Microsoft Technology Licensing, Llc | De-duplication of per-user registration data |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10956666B2 (en) | 2015-11-09 | 2021-03-23 | Apple Inc. | Unconventional virtual assistant interactions |
US10685029B2 (en) * | 2015-11-23 | 2020-06-16 | Google Llc | Information ranking based on properties of a computing device |
US10049668B2 (en) | 2015-12-02 | 2018-08-14 | Apple Inc. | Applying neural network language models to weighted finite state transducers for automatic speech recognition |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
US11227589B2 (en) | 2016-06-06 | 2022-01-18 | Apple Inc. | Intelligent list reading |
US10049663B2 (en) | 2016-06-08 | 2018-08-14 | Apple, Inc. | Intelligent automated assistant for media exploration |
US10586535B2 (en) | 2016-06-10 | 2020-03-10 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
DK201670540A1 (en) | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
DK179415B1 (en) | 2016-06-11 | 2018-06-14 | Apple Inc | Intelligent device arbitration and control |
US10387538B2 (en) | 2016-06-24 | 2019-08-20 | International Business Machines Corporation | System, method, and recording medium for dynamically changing search result delivery format |
CN107545013A (en) * | 2016-06-29 | 2018-01-05 | 百度在线网络技术（北京）有限公司 | Method and apparatus for providing search recommendation information |
US10474753B2 (en) | 2016-09-07 | 2019-11-12 | Apple Inc. | Language identification using recurrent neural networks |
US10043516B2 (en) | 2016-09-23 | 2018-08-07 | Apple Inc. | Intelligent automated assistant |
CN107066472A (en) | 2016-11-30 | 2017-08-18 | 阿里巴巴集团控股有限公司 | Map-indication method and system, terminal and map server |
US11281993B2 (en) | 2016-12-05 | 2022-03-22 | Apple Inc. | Model and ensemble compression for metric learning |
US20180184252A1 (en) * | 2016-12-22 | 2018-06-28 | Yen Hsiang Chew | Technologies for delivering content to a mobile compute device |
US10593346B2 (en) | 2016-12-22 | 2020-03-17 | Apple Inc. | Rank-reduced token representation for automatic speech recognition |
US11204787B2 (en) | 2017-01-09 | 2021-12-21 | Apple Inc. | Application integration with a digital assistant |
DK201770383A1 (en) | 2017-05-09 | 2018-12-14 | Apple Inc. | User interface for correcting recognition errors |
US10417266B2 (en) | 2017-05-09 | 2019-09-17 | Apple Inc. | Context-aware ranking of intelligent response suggestions |
US10395654B2 (en) | 2017-05-11 | 2019-08-27 | Apple Inc. | Text normalization based on a data-driven learning network |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
DK201770439A1 (en) | 2017-05-11 | 2018-12-13 | Apple Inc. | Offline personal assistant |
US10726832B2 (en) | 2017-05-11 | 2020-07-28 | Apple Inc. | Maintaining privacy of personal information |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
US11301477B2 (en) | 2017-05-12 | 2022-04-12 | Apple Inc. | Feedback analysis of a digital assistant |
DK179745B1 (en) | 2017-05-12 | 2019-05-01 | Apple Inc. | SYNCHRONIZATION AND TASK DELEGATION OF A DIGITAL ASSISTANT |
DK179496B1 (en) | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
DK201770411A1 (en) * | 2017-05-15 | 2018-12-20 | Apple Inc. | Multi-modal interfaces |
DK201770431A1 (en) | 2017-05-15 | 2018-12-20 | Apple Inc. | Optimizing dialogue policy decisions for digital assistants using implicit feedback |
DK201770432A1 (en) | 2017-05-15 | 2018-12-21 | Apple Inc. | Hierarchical belief states for digital assistants |
DK179560B1 (en) | 2017-05-16 | 2019-02-18 | Apple Inc. | Far-field extension for digital assistant services |
US10311144B2 (en) | 2017-05-16 | 2019-06-04 | Apple Inc. | Emoji word sense disambiguation |
US10303715B2 (en) | 2017-05-16 | 2019-05-28 | Apple Inc. | Intelligent automated assistant for media exploration |
US10403278B2 (en) | 2017-05-16 | 2019-09-03 | Apple Inc. | Methods and systems for phonetic matching in digital assistant services |
US20180336892A1 (en) | 2017-05-16 | 2018-11-22 | Apple Inc. | Detecting a trigger of a digital assistant |
US10657328B2 (en) | 2017-06-02 | 2020-05-19 | Apple Inc. | Multi-task recurrent neural network architecture for efficient morphology handling in neural language modeling |
US10445429B2 (en) | 2017-09-21 | 2019-10-15 | Apple Inc. | Natural language understanding using vocabularies with compressed serialized tries |
US10755051B2 (en) | 2017-09-29 | 2020-08-25 | Apple Inc. | Rule-based natural language processing |
US10636424B2 (en) | 2017-11-30 | 2020-04-28 | Apple Inc. | Multi-turn canned dialog |
US11023595B1 (en) * | 2018-12-07 | 2021-06-01 | Amazon Technologies, Inc. | System and method for processing encrypted search |
US10733982B2 (en) | 2018-01-08 | 2020-08-04 | Apple Inc. | Multi-directional dialog |
US10733375B2 (en) | 2018-01-31 | 2020-08-04 | Apple Inc. | Knowledge-based framework for improving natural language understanding |
US10789959B2 (en) | 2018-03-02 | 2020-09-29 | Apple Inc. | Training speaker recognition models for digital assistants |
US10592604B2 (en) | 2018-03-12 | 2020-03-17 | Apple Inc. | Inverse text normalization for automatic speech recognition |
US10818288B2 (en) | 2018-03-26 | 2020-10-27 | Apple Inc. | Natural assistant interaction |
US10909331B2 (en) | 2018-03-30 | 2021-02-02 | Apple Inc. | Implicit identification of translation payload with neural machine translation |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
US10984780B2 (en) | 2018-05-21 | 2021-04-20 | Apple Inc. | Global semantic word embeddings using bi-directional recurrent neural networks |
US10892996B2 (en) | 2018-06-01 | 2021-01-12 | Apple Inc. | Variable latency device coordination |
US11386266B2 (en) | 2018-06-01 | 2022-07-12 | Apple Inc. | Text correction |
DK201870355A1 (en) | 2018-06-01 | 2019-12-16 | Apple Inc. | Virtual assistant operation in multi-device environments |
DK179822B1 (en) | 2018-06-01 | 2019-07-12 | Apple Inc. | Voice interaction at a primary device to access call functionality of a companion device |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
US10496705B1 (en) | 2018-06-03 | 2019-12-03 | Apple Inc. | Accelerated task performance |
US11010561B2 (en) | 2018-09-27 | 2021-05-18 | Apple Inc. | Sentiment prediction from textual data |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
US10839159B2 (en) | 2018-09-28 | 2020-11-17 | Apple Inc. | Named entity normalization in a spoken dialog system |
US11170166B2 (en) | 2018-09-28 | 2021-11-09 | Apple Inc. | Neural typographical error modeling via generative adversarial networks |
US11475898B2 (en) | 2018-10-26 | 2022-10-18 | Apple Inc. | Low-latency multi-speaker speech recognition |
US11638059B2 (en) | 2019-01-04 | 2023-04-25 | Apple Inc. | Content playback on multiple devices |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11423908B2 (en) | 2019-05-06 | 2022-08-23 | Apple Inc. | Interpreting spoken requests |
US11475884B2 (en) | 2019-05-06 | 2022-10-18 | Apple Inc. | Reducing digital assistant latency when a language is incorrectly determined |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
US11140099B2 (en) | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
US11289073B2 (en) | 2019-05-31 | 2022-03-29 | Apple Inc. | Device text to speech |
US11496600B2 (en) | 2019-05-31 | 2022-11-08 | Apple Inc. | Remote execution of machine-learned models |
DK180129B1 (en) | 2019-05-31 | 2020-06-02 | Apple Inc. | User activity shortcut suggestions |
DK201970510A1 (en) | 2019-05-31 | 2021-02-11 | Apple Inc | Voice identification in digital assistant systems |
US11227599B2 (en) | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
US11360641B2 (en) | 2019-06-01 | 2022-06-14 | Apple Inc. | Increasing the relevance of new available information |
US11488406B2 (en) | 2019-09-25 | 2022-11-01 | Apple Inc. | Text detection using global geometry estimators |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11043220B1 (en) | 2020-05-11 | 2021-06-22 | Apple Inc. | Digital assistant hardware abstraction |
US11755276B2 (en) | 2020-05-12 | 2023-09-12 | Apple Inc. | Reducing description length based on confidence |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
Family Cites Families (67)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR100767660B1 (en) | 2000-12-14 | 2007-10-17 | 엘지전자 주식회사 | information provide system for location base service and operation method of this system |
US7376640B1 (en) | 2000-11-14 | 2008-05-20 | At&T Delaware Intellectual Property, Inc. | Method and system for searching an information retrieval system according to user-specified location information |
US7225187B2 (en) | 2003-06-26 | 2007-05-29 | Microsoft Corporation | Systems and methods for performing background queries from content and activity |
US7865181B1 (en) * | 2004-03-19 | 2011-01-04 | Single Touch Interactive, Inc. | Searching for mobile content |
WO2006014824A1 (en) | 2004-07-26 | 2006-02-09 | Wireless 5Th Dimensional Networking, Inc. | Context-based search engine residing on a network |
US7603349B1 (en) | 2004-07-29 | 2009-10-13 | Yahoo! Inc. | User interfaces for search systems using in-line contextual queries |
US20070100805A1 (en) | 2005-09-14 | 2007-05-03 | Jorey Ramer | Mobile content cross-inventory yield optimization |
US20070073719A1 (en) | 2005-09-14 | 2007-03-29 | Jorey Ramer | Physical navigation of a mobile search application |
US8660891B2 (en) | 2005-11-01 | 2014-02-25 | Millennial Media | Interactive mobile advertisement banners |
US8195133B2 (en) | 2005-09-14 | 2012-06-05 | Jumptap, Inc. | Mobile dynamic advertisement creation and placement |
US20080215623A1 (en) | 2005-09-14 | 2008-09-04 | Jorey Ramer | Mobile communication facility usage and social network creation |
US8229914B2 (en) | 2005-09-14 | 2012-07-24 | Jumptap, Inc. | Mobile content spidering and compatibility determination |
US20070061245A1 (en) | 2005-09-14 | 2007-03-15 | Jorey Ramer | Location based presentation of mobile content |
US20070061303A1 (en) | 2005-09-14 | 2007-03-15 | Jorey Ramer | Mobile search result clustering |
US20090234711A1 (en) | 2005-09-14 | 2009-09-17 | Jorey Ramer | Aggregation of behavioral profile data using a monetization platform |
US8209344B2 (en) | 2005-09-14 | 2012-06-26 | Jumptap, Inc. | Embedding sponsored content in mobile applications |
US8311888B2 (en) | 2005-09-14 | 2012-11-13 | Jumptap, Inc. | Revenue models associated with syndication of a behavioral profile using a monetization platform |
US8666376B2 (en) | 2005-09-14 | 2014-03-04 | Millennial Media | Location based mobile shopping affinity program |
US20070061198A1 (en) | 2005-09-14 | 2007-03-15 | Jorey Ramer | Mobile pay-per-call campaign creation |
US8364540B2 (en) | 2005-09-14 | 2013-01-29 | Jumptap, Inc. | Contextual targeting of content using a monetization platform |
US10592930B2 (en) | 2005-09-14 | 2020-03-17 | Millenial Media, LLC | Syndication of a behavioral profile using a monetization platform |
US8290810B2 (en) | 2005-09-14 | 2012-10-16 | Jumptap, Inc. | Realtime surveying within mobile sponsored content |
US20110153428A1 (en) | 2005-09-14 | 2011-06-23 | Jorey Ramer | Targeted advertising to specified mobile communication facilities |
US20110145076A1 (en) | 2005-09-14 | 2011-06-16 | Jorey Ramer | Mobile Campaign Creation |
US20100076994A1 (en) | 2005-11-05 | 2010-03-25 | Adam Soroca | Using Mobile Communication Facility Device Data Within a Monetization Platform |
US20080242279A1 (en) | 2005-09-14 | 2008-10-02 | Jorey Ramer | Behavior-based mobile content placement on a mobile communication facility |
US20070073717A1 (en) | 2005-09-14 | 2007-03-29 | Jorey Ramer | Mobile comparison shopping |
US20070100650A1 (en) | 2005-09-14 | 2007-05-03 | Jorey Ramer | Action functionality for mobile content search results |
US20070288427A1 (en) | 2005-09-14 | 2007-12-13 | Jorey Ramer | Mobile pay-per-call campaign creation |
US9076175B2 (en) | 2005-09-14 | 2015-07-07 | Millennial Media, Inc. | Mobile comparison shopping |
US20070061242A1 (en) | 2005-09-14 | 2007-03-15 | Jorey Ramer | Implicit searching for mobile content |
US20100312572A1 (en) | 2005-09-14 | 2010-12-09 | Jump Tap, Inc. | Presentation of Interactive Mobile Sponsor Content |
US8819659B2 (en) | 2005-09-14 | 2014-08-26 | Millennial Media, Inc. | Mobile search service instant activation |
US8302030B2 (en) | 2005-09-14 | 2012-10-30 | Jumptap, Inc. | Management of multiple advertising inventories using a monetization platform |
US20080214148A1 (en) | 2005-11-05 | 2008-09-04 | Jorey Ramer | Targeting mobile sponsored content within a social network |
US8027879B2 (en) | 2005-11-05 | 2011-09-27 | Jumptap, Inc. | Exclusivity bidding for mobile sponsored content |
US8156128B2 (en) | 2005-09-14 | 2012-04-10 | Jumptap, Inc. | Contextual mobile content placement on a mobile communication facility |
US9201979B2 (en) | 2005-09-14 | 2015-12-01 | Millennial Media, Inc. | Syndication of a behavioral profile associated with an availability condition using a monetization platform |
US20070100652A1 (en) | 2005-11-01 | 2007-05-03 | Jorey Ramer | Mobile pay per call |
US20070118533A1 (en) | 2005-09-14 | 2007-05-24 | Jorey Ramer | On-off handset search box |
US20090234745A1 (en) | 2005-11-05 | 2009-09-17 | Jorey Ramer | Methods and systems for mobile coupon tracking |
US20070198485A1 (en) | 2005-09-14 | 2007-08-23 | Jorey Ramer | Mobile search service discovery |
US20080214152A1 (en) | 2005-09-14 | 2008-09-04 | Jorey Ramer | Methods and systems of mobile dynamic content presentation |
US20070073722A1 (en) * | 2005-09-14 | 2007-03-29 | Jorey Ramer | Calculation and presentation of mobile content expected value |
US20090234861A1 (en) | 2005-09-14 | 2009-09-17 | Jorey Ramer | Using mobile application data within a monetization platform |
US8989718B2 (en) | 2005-09-14 | 2015-03-24 | Millennial Media, Inc. | Idle screen advertising |
US7548915B2 (en) | 2005-09-14 | 2009-06-16 | Jorey Ramer | Contextual mobile content placement on a mobile communication facility |
US20070150362A1 (en) | 2005-12-19 | 2007-06-28 | Ranjan Sharma | Location-based comparative shopping service for wireless telecommunications network |
US7813870B2 (en) * | 2006-03-03 | 2010-10-12 | Inrix, Inc. | Dynamic time series prediction of future traffic conditions |
US20080005067A1 (en) | 2006-06-28 | 2008-01-03 | Microsoft Corporation | Context-based search, retrieval, and awareness |
US8626136B2 (en) | 2006-06-29 | 2014-01-07 | Microsoft Corporation | Architecture for user- and context-specific prefetching and caching of information on portable devices |
EP2163077A4 (en) * | 2007-06-27 | 2014-11-05 | Karen Knowles Entpr Pty Ltd | Communication method, system and products |
KR101274388B1 (en) | 2007-10-02 | 2013-06-14 | 엔에이치엔비즈니스플랫폼 주식회사 | Method for advertising local information based on location information and system for executing the method |
US20090125499A1 (en) | 2007-11-09 | 2009-05-14 | Microsoft Corporation | Machine-moderated mobile social networking for managing queries |
US7966304B2 (en) | 2007-11-30 | 2011-06-21 | Yahoo! Inc. | Enabling searching on abbreviated search terms via messaging |
US20100241663A1 (en) * | 2008-02-07 | 2010-09-23 | Microsoft Corporation | Providing content items selected based on context |
US7991896B2 (en) | 2008-04-21 | 2011-08-02 | Microsoft Corporation | Gesturing to select and configure device communication |
US20090319166A1 (en) | 2008-06-20 | 2009-12-24 | Microsoft Corporation | Mobile computing services based on devices with dynamic direction information |
US8060513B2 (en) * | 2008-07-01 | 2011-11-15 | Dossierview Inc. | Information processing with integrated semantic contexts |
US8086275B2 (en) * | 2008-10-23 | 2011-12-27 | Microsoft Corporation | Alternative inputs of a mobile communications device |
KR101737829B1 (en) * | 2008-11-10 | 2017-05-22 | 삼성전자주식회사 | Motion Input Device For Portable Device And Operation Method using the same |
US8260320B2 (en) | 2008-11-13 | 2012-09-04 | Apple Inc. | Location specific content |
US8606242B2 (en) * | 2009-10-30 | 2013-12-10 | Sap Ag | Systems and methods to provide context information for mobile communication devices |
US8396888B2 (en) | 2009-12-04 | 2013-03-12 | Google Inc. | Location-based searching using a search area that corresponds to a geographical location of a computing device |
EP2531969A4 (en) | 2010-02-01 | 2013-12-04 | Jumptap Inc | Integrated advertising system |
US8478519B2 (en) * | 2010-08-30 | 2013-07-02 | Google Inc. | Providing results to parameterless search queries |
US9541652B2 (en) * | 2013-12-06 | 2017-01-10 | Aro, Inc. | Accurate mobile context detection at low sensor cost |
-
2010
- 2010-08-30 US US12/871,562 patent/US8478519B2/en active Active
-
2011
- 2011-08-30 WO PCT/US2011/049685 patent/WO2012030793A2/en active Application Filing
- 2011-08-30 AU AU2011296121A patent/AU2011296121B2/en active Active
- 2011-08-30 KR KR1020147020072A patent/KR101539687B1/en active IP Right Grant
- 2011-08-30 KR KR1020137008209A patent/KR101545302B1/en active IP Right Grant
- 2011-08-30 EP EP11822471.6A patent/EP2612264B1/en active Active
- 2011-08-30 EP EP19193838.0A patent/EP3591541A1/en active Pending
- 2011-09-29 US US13/249,164 patent/US8504286B2/en active Active
-
2013
- 2013-08-05 US US13/959,680 patent/US9212915B2/en active Active
-
2014
- 2014-05-06 US US14/270,902 patent/US9146964B2/en active Active
- 2014-06-26 AU AU2014203476A patent/AU2014203476B2/en active Active
-
2015
- 2015-09-25 US US14/865,670 patent/US9665652B2/en active Active
-
2017
- 2017-04-27 US US15/499,553 patent/US10394824B2/en active Active
-
2019
- 2019-07-26 US US16/523,389 patent/US10803067B2/en active Active
-
2020
- 2020-10-09 US US17/066,988 patent/US11675794B2/en active Active
-
2023
- 2023-06-09 US US18/208,125 patent/US20230401219A1/en active Pending
Non-Patent Citations (1)
Title |
---|
None * |
Also Published As
Publication number | Publication date |
---|---|
US10803067B2 (en) | 2020-10-13 |
US20140244683A1 (en) | 2014-08-28 |
US20120054204A1 (en) | 2012-03-01 |
US20190347264A1 (en) | 2019-11-14 |
EP2612264A4 (en) | 2017-11-15 |
US10394824B2 (en) | 2019-08-27 |
WO2012030793A2 (en) | 2012-03-08 |
KR101539687B1 (en) | 2015-07-27 |
US20210026856A1 (en) | 2021-01-28 |
US11675794B2 (en) | 2023-06-13 |
AU2011296121A1 (en) | 2013-03-07 |
AU2011296121B2 (en) | 2014-04-03 |
US20120053829A1 (en) | 2012-03-01 |
US20170228436A1 (en) | 2017-08-10 |
US9212915B2 (en) | 2015-12-15 |
US9146964B2 (en) | 2015-09-29 |
US8504286B2 (en) | 2013-08-06 |
EP2612264A2 (en) | 2013-07-10 |
WO2012030793A3 (en) | 2012-04-26 |
KR101545302B1 (en) | 2015-08-18 |
US9665652B2 (en) | 2017-05-30 |
KR20130083905A (en) | 2013-07-23 |
US20130325307A1 (en) | 2013-12-05 |
US20230401219A1 (en) | 2023-12-14 |
KR20140095583A (en) | 2014-08-01 |
EP3591541A1 (en) | 2020-01-08 |
US8478519B2 (en) | 2013-07-02 |
US20160012069A1 (en) | 2016-01-14 |
AU2014203476B2 (en) | 2015-07-30 |
AU2014203476A1 (en) | 2014-07-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11675794B2 (en) | Providing results to parameterless search queries | |
AU2013280830B2 (en) | Providing route recommendations | |
AU2011285618B2 (en) | Disambiguating input based on context | |
EP3432303B1 (en) | Automatically monitoring for voice input based on context |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20130218 |
|
AK | Designated contracting states |
Kind code of ref document: A2Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
DAX | Request for extension of the european patent (deleted) | ||
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
A4 | Supplementary search report drawn up and despatched |
Effective date: 20171018 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G01C 21/20 20060101ALN20171012BHEPIpc: G01C 21/36 20060101ALN20171012BHEPIpc: G06F 17/30 20060101AFI20171012BHEP |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R079Ref document number: 602011062655Country of ref document: DEFree format text: PREVIOUS MAIN CLASS: G06F0017300000Ipc: G06F0016000000 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 16/00 20190101AFI20190219BHEPIpc: G01C 21/20 20060101ALN20190219BHEPIpc: G01C 21/36 20060101ALN20190219BHEPIpc: G06F 16/9535 20190101ALN20190219BHEPIpc: G06F 16/2457 20190101ALN20190219BHEPIpc: G06F 16/9537 20190101ALN20190219BHEP |
|
INTG | Intention to grant announced |
Effective date: 20190318 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 16/9535 20190101ALN20190305BHEPIpc: G06F 16/9537 20190101ALN20190305BHEPIpc: G06F 16/2457 20190101ALN20190305BHEPIpc: G01C 21/36 20060101ALN20190305BHEPIpc: G01C 21/20 20060101ALN20190305BHEPIpc: G06F 16/00 20190101AFI20190305BHEP |
|
RIN1 | Information on inventor provided before grant (corrected) |
Inventor name: AGARWAL, SUMITInventor name: GUNDOTRA, VICInventor name: NICOLAOU, ALEXANDER |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE PATENT HAS BEEN GRANTED |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EP |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602011062655Country of ref document: DE |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: REFRef document number: 1189636Country of ref document: ATKind code of ref document: TEffective date: 20191115 |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: MPEffective date: 20191009 |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 1189636Country of ref document: ATKind code of ref document: TEffective date: 20191009 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200110Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200109Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200109Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: NLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200210 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200224Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: RSFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ALFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602011062655Country of ref document: DE |
|
PG2D | Information on lapse in contracting state deleted |
Ref country code: IS |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20200209 |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SMFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009 |
|
26N | No opposition filed |
Effective date: 20200710 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R082Ref document number: 602011062655Country of ref document: DERepresentative=s name: VENNER SHIPLEY GERMANY LLP, DERef country code: DERef legal event code: R082Ref document number: 602011062655Country of ref document: DERepresentative=s name: VENNER SHIPLEY LLP, DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20200830Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20200831Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20200831 |
|
REG | Reference to a national code |
Ref country code: BERef legal event code: MMEffective date: 20200831 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20200831 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: TRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: MTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20191009 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230508 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: IEPayment date: 20230828Year of fee payment: 13Ref country code: GBPayment date: 20230828Year of fee payment: 13 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: FRPayment date: 20230825Year of fee payment: 13Ref country code: DEPayment date: 20230829Year of fee payment: 13 |