CN108351983A - Modification calculates figure - Google Patents
Modification calculates figure Download PDFInfo
- Publication number
- CN108351983A CN108351983A CN201680063358.6A CN201680063358A CN108351983A CN 108351983 A CN108351983 A CN 108351983A CN 201680063358 A CN201680063358 A CN 201680063358A CN 108351983 A CN108351983 A CN 108351983A
- Authority
- CN
- China
- Prior art keywords
- node
- equipment
- output
- calculating
- indicated
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/10—Complex mathematical operations
- G06F17/16—Matrix or vector computation, e.g. matrix-matrix or matrix-vector multiplication, matrix factorization
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5005—Allocation of resources, e.g. of the central processing unit [CPU] to service a request
- G06F9/5027—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals
- G06F9/5038—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals considering the execution order of a plurality of tasks, e.g. taking priority or time dependency constraints into consideration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5061—Partitioning or combining of resources
- G06F9/5066—Algorithms for mapping a plurality of inter-dependent sub-tasks onto a plurality of physical CPUs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/54—Interprogram communication
- G06F9/547—Remote procedure calls [RPC]; Web services
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
Abstract
Include the mthods, systems and devices of the computer program encoded on computer storage media, for changing calculating figure to include sending node and receiving node.By the way that sending node and receiving node to be inserted into each subgraph, the communication between the unique apparatus of the operation for the different subgraphs for executing calculating figure can be effectively handled.Upon being performed, the operation representated by these sending nodes and receiving node can make unique apparatus to can be communicated with each other in a manner of self-centered.This removes the burden of communication for coordination from rear end, this provides the chance that other one or more processes are executed while equipment executes subgraph for the system that this calculation chart of processing shows.
Description
Background technology
This specification is related to modification and indicates that the calculating figure of neural network and/or modified calculating figure are handling mode input
In application.
Neural network is machine learning model, and output is generated for the input received using one or more layers model,
Such as one or more classification.Some neural networks also include one or more hidden layers other than output layer.It is each to hide
The output of layer is used as the input of next layer (i.e. the next hidden layer or output layer of network) in network.Each layer in network
According to the current value of this layer of relevant parameter collection output is generated from the input received.
The layer of neural network can be handled by individual equipment.The equipment, which can have, to be executed such as from the defeated of input generation layer
The processor of the operation gone out, and in memory by the output storage from the operation.Due to usually requiring in neural network
The middle operation for generating output has big quantity and size, so an equipment may take a significant amount of time to handle neural network
Layer.
Invention content
In general, being present specification describes the calculating figure for changing expression neural network and other machines learning model
System.
The specific embodiment of theme described in this specification can be implemented to realize following advantages in one or
It is multiple.Neural network operation (for example, from input generate reasoning or training neural network operation) can be expressed as node and
The calculating figure of directed edge.System handles this calculation chart and shows to efficiently perform the operation of neural network.It, can be with as explanation
The subgraph for calculating figure is assigned to unique equipment, every sub- equipment therein executes operation in corresponding subgraph, to reduce
Execute the overall time needed for neural network operation.It, can be with by the way that sending node and receiving node to be inserted into each subgraph
Effectively processing executes the communication between the unique apparatus of the operation for the different subgraphs for calculating figure.Upon being performed, these send
The operation that node and receiving node indicate can make unique apparatus to can be communicated with each other in a manner of self-centered.This
The burden of communication for coordination is removed from rear end, this is provided to handle the system that this calculation chart shows in equipment execution subgraph
It is performed simultaneously the chance of other one or more processes.Sending node and receiving node are used as dividing subgraph in this way,
Which allows a part for neural network or the neural network indicated by these subgraphs to be trained on one device, and with
After be assigned to another equipment.At least due to these reasons, calculating figure is revised as to include sending node and receiving node pair
The time cost and Internet traffic handled in a distributed way needed for calculating figure can be helped to reduce.
In one aspect, theme described in this specification can embody in one approach, may include acquisition table
Show the action of the data of calculating figure, which includes multiple nodes and directed edge, wherein each node indicates corresponding operation,
And corresponding first node is connected to corresponding second node by wherein each directed edge, which connects
Receive the output operation as input of the operation indicated by corresponding first node；Obtain the calculating figure that multiple equipment is crossed in identification
Distribution data, each node in calculating figure is assigned to the relevant device in multiple equipment by the wherein distribution, identification meter
One or more of nomogram striding equipment directed edge, wherein each striding equipment directed edge is that corresponding first node is connected to phase
The directed edge for the second node answered, corresponding second node are assigned to different with corresponding first node in distribution
Equipment；And for each striding equipment directed edge, in the corresponding first node in calculating figure and between corresponding second node
It is inserted into sending node, receiving node, and modification point are inserted between the sending node and corresponding second node in operation diagram
It is equipped with and sending node is assigned to equipment identical with corresponding first node and is assigned to receiving node and corresponding
The identical equipment of two nodes；It is the multiple with the operation indicated by the node in calculating figure is assigned to according to the distribution changed
Equipment.These methods can be computer implemented method.
In one embodiment, this method further includes：Receive mode input；And shown according to the calculation chart by changing
Operation processing mode input.
On the other hand, theme described in this specification may be embodied in such method, may include providing and pass through
The action of corresponding machine learning model is schemed in the calculating for the modification that the method for first aspect obtains；And using at machine learning model
Manage mode input.Processing may be constructed the training to machine learning model, or may be constructed from mode input and generate inference.
On the other hand, theme described in this specification can embody in such method, may include being held by multiple equipment
The action of the calculating figure for the modification that row is obtained by the method for first aspect.
In these aspects, calculating figure can be the expression of machine learning model, such as, such as neural network.
On the other hand, theme described in this specification may be embodied in such method, may include setting using multiple
Standby to scheme processing mode input according to calculating, the calculating figure includes multiple nodes and directed edge, wherein each node indicates accordingly
Operation, wherein corresponding first node is connected to corresponding second node, corresponding second node by each directed edge
The output operation as input for indicating the operation that reception is indicated by corresponding first node, wherein the method includes for institute
State the first equipment in multiple equipment：Receive the data of the subgraph for the calculating figure for indicating to be assigned to the first equipment, the subgraph packet
Include multiple nodes and directed edge from calculating figure；And the operation indicated by subgraph interior joint is executed, including：(1) execute by
The operation that corresponding first node in subgraph indicates is to generate the first output；Determine that first node is connected to institute by directed edge
State the sending node in subgraph；And execute operation of the operation indicated by sending node will be indicated by corresponding first node
The first output be transmitted to another equipment in multiple equipment；And/or (2) execute the behaviour indicated by the receiving node in subgraph
Make, to obtain the second output of the operation indicated by the second node for another equipment being assigned in multiple equipment；Determination connects
It receives node and is connected to the third node in subgraph by directed edge；And it uses obtained second to export to execute as input
The operation indicated by third node.In this respect, calculate figure can through the invention another aspect method obtain.
In computer memory device, (it can including being configured as execution coding for this and otherwise other embodiment
To be or can not be non-transitory storage device) on method action corresponding system, device and computer program.One
A or multiple system for computer can be configured by software, firmware, hardware or the combination thereof in system,
System is set to execute these actions in operation.One or more computer programs can work as data processing equipment execution by means of having
When, make the instruction that device execution acts to configure.
These other versions can separately include one or more following functions.For example, sending node indicates that execution is following
The operation of step：(i) output of the operation indicated by corresponding first node is received as input, and (ii) will be by corresponding
The output for the operation that first node indicates is supplied to receiving node as output；And receiving node indicates to execute following steps
Operation：(i) output for receiving the operation indicated by sending node is used as input, and the operation that (ii) will be indicated by sending node
Output as output be supplied to corresponding second node.In some embodiments, the operation indicated by receiving node can be into
One step (iii) provides request of the output for the operation that will be indicated by sending node as output to sending node；And by sending
The operation that node indicates can further (ii) be asked in response to the one or more received from receiving node, will be by corresponding the
The output for the operation that one node indicates is supplied to receiving node as output.In some instances, by corresponding first node table
The output for the operation shown may include tensor.
In some embodiments, obtain identification across the data of the distribution of the calculating figure of multiple equipment may include being known
The data of the distribution of the calculating figure for the hardware resource for not including across one or more machines.In these embodiments, it sends
Node and each node of receiving node centering can for example indicate to operate, which receives basis and the sending node and reception
The operation that another node for the centering that node communicates the corresponding agreement of each hardware resource and machine being assigned indicates
Output as input.
In some instances, in the corresponding first node in calculating figure and insertion transmission section between corresponding second node
Putting to include：To each striding equipment directed edge, directed edge is inserted between sending node and corresponding first node.Separately
Outside, receiving node being inserted between the sending node in operation diagram and corresponding second node can also include：To each across setting
Standby directed edge, directed edge is inserted between receiving node and corresponding second node.
In some embodiments, it during executing the operation shown by calculation chart by multiple equipment, is saved by each transmission
Point and receiving node can allow communication between devices of the multiple equipment independently in multiple equipment by it operation of expression
The calculating figure of the operation that his node indicates output and input.In some instances, data can be by sending node and reception
It is independently exchanged between the operation that each node of node centering indicates.
The one or more embodiments of the detail of the theme of this specification are elaborated in the the accompanying drawings and the following description.Theme
Other features, aspect and advantage will be become apparent from specification, drawings and the claims.It will be appreciated that various aspects
It can be combined with embodiment, and the feature in one aspect or described in the context of embodiment can be in its other party
It is realized in the context of face or embodiment.
Description of the drawings
Figure 1A illustrates the example calculations drawing system of the operation for being distributed the neural network shown with calculation chart.
Figure 1B is the concept map of the exemplary architecture of the operation for being distributed the neural network shown with calculation chart in systems.
Fig. 2A-C are example calculations figures.
Fig. 3 is the instantiation procedure provided by being included in exemplary sending node and the receiving node in calculating figure by executing
Flow chart.
Fig. 4 A-B are assigned to the sample portion of the calculating figure of equipment.
Fig. 5 is the flow chart of the instantiation procedure for changing calculating figure.
Identical reference numeral and title indicate identical element in various figures.
Specific implementation mode
This specification generally describes the calculating drawing system for executing the operation shown by calculation chart in a distributed way.Especially
Ground, present specification describes the technologies for that can change calculating figure between to make equipment in a manner of seamless communication.These technologies
It can help to ensure that each calculating figure is executed by multiple equipment jointly in fast and efficient manner.
Calculating figure includes the node connected by directed edge.It calculates each node in figure and indicates an operation.Arrive node
Incoming side indicates the inlet flow to node, i.e., the input of the operation indicated by node.Outflow side from node is indicated by node
The output stream of the operation of expression will be used as the input of the operation indicated by another node.Therefore, the first node in figure is connected
The output that the directed edge instruction for the second node being connected in figure is generated by the operation that first node indicates is used as by second node
The input of the operation of expression.
In general, in calculating figure along directed edge flowing to output and input be tensor.Tensor is numerical value or other values
Multidimensional numerical, for example, the character string with specific rank corresponding with the dimension of array.For example, scalar value is 0 rank tensor, number
Value vector is 1 rank tensor, and matrix is 2 rank tensors.
In some embodiments, the operation indicated in calculating figure is that neural network operates or be used for different types of machine
The operation of learning model.Neural network is a kind of machine learning model, predicts to connect using one or more layers non-linear unit
The output of the input received.Some neural networks are deep neural networks, further include one or more other than output layer
Hidden layer.The output of each hidden layer is used as the input of another layer (i.e. another hidden layer, output layer or both) in network.
Some layers of network generate output according to the current value of relevant parameter collection from the input received, and other layers of network may not
With parameter.
For example, can be the operation needed for neural computing reasoning by the operation that calculation chart shows, that is, processing passes through god
The input of layer through network is exported with the neural network for generating input.As another example, the operation shown by calculation chart can be with
Be by execute neural network training process adjust the operation needed for the parameter value of neural network to train neural network, such as
To determine the trained values of parameter from the initial value of parameter.In some cases, such as during training neural network, schemed by calculating
The operation of expression may include the operation executed by multiple copies of neural network.
As explanation, parameter square can be executed using parameter matrix by receiving the neural net layer of the input from preceding layer
Matrix multiplication between battle array and input.In some cases, this matrix multiplication can be expressed as multiple nodes in calculating figure.
For example, matrix multiplication can be divided into multiple multiplication and add operation, and each operation can be by the different nodes in calculating figure
It indicates.The operation indicated by each node can generate corresponding output, which flows on directed edge to subsequent node.By
After the result for the operation generator matrix multiplication that finish node indicates, another node is as a result flowed on directed edge.As a result equivalent
In the output for the neural net layer for executing matrix multiplication.
In some other cases, matrix multiplication is shown in FIG as a node.The operation indicated by node can connect
Receive the weight tensor on input the second directed edge of tensor sum on the first directed edge as input, such as parameter matrix.The section
Point can handle, for example, execute input and weighted tensor matrix multiplication, on third directed edge output equivalent in nerve net
The output tensor of the output of network layers.
Other neural networks that can be indicated by the node in calculating figure be operated including other mathematical operations, such as subtraction, be removed
Method and gradient calculate；Array operation, such as connection (concatenate), splicing (splice), segmentation (split) or sequence
(rank)；It is operated with neural network structure block, such as SoftMax, Sigmoid, rectification linear unit (ReLU) or convolution.
Neural Networks Representation for calculating figure is provided into a kind of flexible and careful mode efficiently to realize neural network,
Especially if when the operation of neural network is distributed in the multiple equipment with different hardware profile.
Figure 1A illustrates the example calculations drawing system 100 of the operation for being distributed the neural network for being expressed as calculating figure.System
System 100 is the example for the system that computer program is embodied as on one or more of one or more positions computer,
In systems described below, component and technology may be implemented.
The user of client 102 can ask to execute operation on the calculating figure for indicating neural network.Client 102 can be with
It is the application run on computers.
As a part for request, client 102 provides the data that identification calculates figure to system 100, and it is specified will be
The type of the operation executed on calculating figure.
For example, the request can identify the calculating figure for indicating the deduction for specific neural network and can identify should be
The input of reasoning is executed thereon.
As another example, which can identify the calculating figure for the training process for indicating to be used for specific neural network simultaneously
And it can identify and should execute trained input, such as training data on it.In this example, when receive processing indicate training
When the request of the calculating figure of process, system 100 can for example be come using classical back propagation or other neural metwork training technologies
Determine the modified values of the parameter on the one or more sides for calculating figure.The parameter of modification can be stored in depositing for equipment by system 100
In reservoir, and actuator 106 can retrieve at system 100 and store the address of modified weight.From client
When further requests of 102 pairs of reasonings, training or other operations of the modified weight of needs, system 100 can use the ground
Location accesses modified weight.
In some cases, request may specify the response that should be transmitted in response to the request.For example, for nerve net
Network train request, client 102 can ask to have completed the instruction of requested neural metwork training operation, and optionally
The instruction for the storage location that the trained values or trained values of the parameter of request neural network can be accessed by client 102.As
Another example asks ANN Reasoning, and client 102 can ask to indicate that the one or more from calculating figure is special
Determine the output valve of the inference operations of node.
System 100 executes operation and generates spy to divide the operation shown by calculation chart by across multiple equipment 116-122
Fixed output.System 100 is by data communication network 114 (such as LAN (LAN) or wide area network (WAN)) by division of operations to more
A equipment 116-122.Equipment 116-122 executes operation, and if applicable, is by exporting or indicating a return to accordingly
System 100, system 100 can export or indicate a return to client 102 by requested.
Any equipment (such as equipment 116-122) for executing neural network operation may include for storing instruction and data
Memory (for example, random access memory (RAM)) and for execute storage instruction processor.In general, each equipment
All it is independently of the hardware resource that other equipment executes operation.For example, each equipment may have the processing unit of oneself.It should
Equipment can be graphics processing unit (GPU) or central processing unit (CPU).As explanation, a machine can be one with trustship
Or multiple equipment, such as multiple CPU and GPU.This equipment and the example of machine can be found out in fig. ib.
Figure 1B is the general of the exemplary architecture of the operation for being distributed the neural network for being expressed as calculating figure within system 100
Read figure.Referring now to Figure 1B, the example of machine may include computing device 126, personal computer 128, mobile device 130 and service
Device 132.Every machine can be for example including one or more equipment, such as GPU116 and CPU118.
Each equipment can also have corresponding computing capability.That is, equipment can be with the storage of different number
Device, processing speed or other structures feature.Therefore, some equipment can execute the operation that other equipment can not execute.For example, one
A little operations need a certain number of memories or some equipment that only particular device has to be configured to only perform certain kinds
The operation of type, such as reasoning operation.
Refer again to Fig. 1, the session manager 104 in system 100 can since client 102 receive session request,
The operation for calculating figure is executed in the ession for telecommunication.Session manager 104 manages the cluster tool for the operation that can execute calculating figure,
Such as equipment 116-122, and the cluster tool that can be used for executing operation can be provided to layout device 108.
Layout device 108 be the respective objects equipment that each operation determination execution operation is executed in calculation chart
(such as equipment 116), and determine that respective objects equipment executes the time of operation in some embodiments.Some operations can be with
It is parallel to execute, and other prior operations of operation requirement in completing to calculate figure, such as other operation processing prior operations
Output is as input.
After equipment executes the operation distributed by layout device 108 to generate output, actuator 106 can be with search and output.
Actuator 106 can generate the appropriate response to the request, such as export or handle the instruction completed.Then, actuator
106 can return to the response client 102.
Session manager 104 also provides the operation set to be executed in calculating figure to actuator 106.106 period of actuator
Property run time statistics amount is retrieved in related equipment 116-122 from being executed with the figure of operation.Actuator 106 is by run time
Statistic is supplied to layout device 108, can be with the arrangement of re-optimization further operating and scheduling.
In operation, system 100 can receive the request that processing calculates figure from client 102.For example, request can be held
The request that the neural network that row is shown by the calculation chart in specified input is inferred, executes by specifying the calculating figure on training dataset
The request of the neural metwork training operation of expression, execution are operated by other neural networks that calculation chart shows, as described above.
When receiving request, system 100 can obtain the data for indicating calculating figure.In some cases, data and visitor
The request at family end is sent together.In other cases, request identification calculates figure and the retrieval of system 100 indicates to know from memory
The data of other figure.As explanation, the data of expression figure can be the array of figure interior joint.Each node can include specified
The information of list when action type, title and node are passed to while and spread out of.
System 100 can identify multiple available devices for executing requested operation.If equipment is currently being held
Other operate and can not be assigned further operation or can not execute graphics processing operation row, then equipment may be considered as
It is busy.If the equipment can be assigned further operation, which, which may be considered that, is available, for example, should be into one
The operation of step can wait in line the operation of the equipment.
Calculating figure can be divided into multiple subgraphs by system 100.Each subgraph includes to calculate one or more of figure section
Point.In some instances, system 100 can be by node that is adjacent to each other in decomposition computation figure but being assigned to distinct device to coming
Obtain these subgraphs.
System 100 can be that the operation indicated by one or more of subgraph node is assigned to accordingly by each subgraph
Available devices.In some embodiments, each subgraph can be assigned to execution by the node table in subgraph by system 100
The equipment of computing capability necessary to the operation shown.In some embodiments, the request from client includes being referred to by user
Fixed data, the data identify certain types of equipment to execute the operation for specific node.
Therefore, 100 across multiple equipment generation of system calculates the distribution of figure, each node in calculating figure is assigned to more
Relevant device in a equipment.Each subgraph includes the given group of one or more of calculating figure node, as described above, it can
To be assigned to identical equipment.Illustrative subgraph can be seen in fig. ib to device map.In this example, figure is calculated
140 Exemplary Figure 140 A and 140B can be respectively allocated to GPU116 and CPU118.GPU 116 and CPU 118 can be with
It resides in the different or identical machines in machine 126-132.In operation, GPU 116 and CPU 118 can be held
Row is already assigned to the operation that the node that their subgraph includes indicates by system 100.
System 100 can make equipment execute the operation for being included in the node in the subgraph for being individually assigned to equipment.At some
In embodiment, system 100 can send the node for starting to include in the subgraph for being assigned to relevant device to each equipment
The request of operation.In response to receiving such request from system 100, each equipment, which can continue to execute, is being assigned to equipment
The operation for the node that subgraph includes.
In view of there may be various dependences between calculating figure interior joint and node group, therefore will need to cooperate with various set
Communication between standby, so that these equipment can execute calculating figure jointly.For example, indicating the operation just executed on the first device
Node can receive the output of another node as input, what the output of another node indicated be located at remotely second sets
The operation of standby upper execution.In this example, it may be necessary in an efficient way come cooperate with the operation indicated by another node from
Second equipment to the output of the first equipment communication, to ensure the correct of calculating figure and timely to execute.
In some instances, as needed, these equipment can cooperate with the mutual exchange output and input.Show at these
In example, the communication between equipment can occur independently of system 100.That is, system 100 can be sent to each equipment
Execute the request of the operation of its corresponding subgraph, and in response to the request, each equipment can in response to system 100 request after
The continuous operation for executing its corresponding subgraph may include additional intervention of communication of the collaboration with other equipment without system 100.
In some embodiments, in order to allow equipment to be communicated independently of system 100, the modification of system 100 calculates figure,
So that it includes the additional node for indicating the traffic operation between node.Specifically, the corresponding subgraph of equipment may include table
Show the node of operation, which allows equipment seamlessly to be communicated with another equipment that other side operates is executed when being executed by equipment.
Then the mode input received can be handled according to the operation shown by the calculation chart changed.
More specifically, " transmission " and " reception " node can be inserted into calculating figure by system 100.Each sending node generation
A kind of operation of table, wherein the data of such as tensor are relayed to the receiving node for being assigned to the equipment different from sending node.System
System 100 can be inserted into sending node and receiving node pair to determine by any striding equipment directed edge in identification figure in figure
Position.Striding equipment directed edge is the directed edge in calculating figure, it by node to be allocated in calculating figure be connected to two it is different
Equipment.System 100 can identify this striding equipment directed edge when determining the distribution of calculating figure or later.Include in identification figure
Each striding equipment directed edge after, system 100 can by split each striding equipment directed edge and be inserted into sending node and
Receiving node changes calculating figure to replacing striding equipment directed edge.This modification process is further described referring to Fig. 2A-C.
Fig. 2A-C illustrate example calculations figure.As an example, drawing system, such as the system 100 of Figure 1A are calculated, can be received
Request from client gives input set, is inferred using calculating Figure 200 A and calculating.It calculates Figure 200 A and can receive to come from and show
The input in example property source 201 simultaneously provides output to the exemplary stay of two nights (sink) 215.Exemplary source 201 and the stay of two nights 215 can be such as
It is other one or more nodes of calculating figure.
For example, system can be determined calculates Figure 200 A across three distinct device distribution.In order to make the determination, system can be with
Analysis meter nomogram 200A is to identify the one or more nodes that can be divided into subgraph and distribute to available devices.For example, being
System can be determined distributes to the first equipment by the first chain formed by node 204,212 and 214, by node 206,208 and 210 shapes
At the second chain distribute to the second equipment, and node 202 is distributed into third equipment.Although other possible node chains are possible
, but system can select the chain for the quantity minimum for making subgraph.
Under the specific distribution, directed edge 220A and 230A can be identified as striding equipment directed edge by system.That is, being
System can identify that directed edge 220A and 230A are respectively connected to system and have determined the node for distributing to distinct device.For example,
As can be seen that node 202 is connected to node 208 by directed edge 220A, system has determined is respectively allocated to by the node 208
Three and second equipment.Similarly, directed edge 230A is set by being extended to from the node 208 corresponding to the second equipment corresponding to first
Standby node 212 and cross over equipment boundary.
In response to identifying that, in each striding equipment directed edge that calculating Figure 200 A include, system can continue to change calculating figure
200A is to generate modified calculating figure, for example, modified calculating Figure 200 B shown in Fig. 2 B.More specifically, system can be with
Sending node and receiving node are inserted between node 202 and 208 to replacing directed edge 220A.In a similar way, system
Sending node and receiving node can also be inserted between node 208 and 212 to replacing directed edge 230A.It can be seen that
Each it has been also inserted between sending node or receiving node and each node adjacent with such sending node or receiving node
Xiang Bian.
B referring now to Fig. 2, it can be seen that indicate the calculating figure of the modification by the version for calculating Figure 200 A of system modification
200B includes two sending nodes and receiving node pair.Specifically, the first sending node S1 is already inserted into 202 He of node
Between 208, and corresponding first receiving node R1 is already inserted between the first sending node S1 and node 208.Pass through this
A little to be inserted into, system distributes the first sending node S1 to equipment identical with node 202 (that is, third equipment), and first is connect
It receives node R 1 and distributes to equipment (that is, second equipment) identical with node 208.Two-way bridging device 220B is by the first sending node S1
It is connected to the first receiving node R1.Bridge 220B can be counted as indicate the first sending node S1 and the first receiving node R1 it
Between communication channel.
When implemented, the operation indicated by the first sending node S1 and the first receiving node R1 makes second and third equipment
It can be communicated in a predefined manner.For example, the execution of these operations may include the second He in accordance with specific communication protocol
Third equipment.The address of node information insertion that can also be executed by each relevant device by each relevant device and/or
To these operations.In this way, the first sending node S1 and the first receiving node R1, which can be encapsulated, to need in the second He
The each communication process executed between third equipment, satisfactorily to execute their corresponding subgraphs.Referring to Fig. 3 and
4A-B further describes these communication process.
Similarly, it is inserted into the second sending node S2 between node 208 and 212, and sends section second
Corresponding second receiving node R2 is inserted between point S2 and node 212.By these insertions, system divides the second sending node S2
With giving 208 identical equipment of node (that is, second equipment), and the first receiving node R1 distributed to identical as node 208
Equipment (that is, first equipment).Second sending node S2 is connected to the second receiving node R2 by two-way bridging device 230B, and can
To be counted as indicating the communication channel between the second sending node S2 and the second receiving node R2.Just as the first sending node S1 and
First receiving node R1 is the same, and the second sending node S2 and the second receiving node R2 make it possible to easily set in second and first
Communication for coordination between standby.
As shown in calculating Figure 200 C by the modification in Fig. 2 C, system 100 can change distribution so that each sending node
It is assigned to a corresponding subgraph and each receiving node is assigned to another corresponding subgraph.For example, first sends
Node S1 can be assigned to the third equipment being included in machine 130 together with node 202, and is already assigned to as system
A part for the subgraph 240 of three equipment.Similarly, the first receiving node R1 and the second sending node S2 can with node 206,
208 and 210 are assigned to the second equipment being included in machine 126 together, and the son of the second equipment is already assigned to as system
A part of Figure 24 6.In addition, the second receiving node R2 can be together assigned to node 204,212 and 214 is included in machine
The first equipment in 132 is already assigned to a part for the subgraph 242 of the first equipment as system.
When being executed, the operation indicated by the first sending node S1 may include that the output of node 202 is relayed to first
Receiving node R1.For example, this exchange can be on the network 215 that machine 130 and 126 can access in a manner of channel 220B
Occur.Network 215 can be similar to the network 114 described above in conjunction with Fig. 1.The agreement for being utilized to carry out the communication can be anti-
It reflects in the operation indicated S1 and R1 by the first sending node and receiving node, and can depend on and subgraph 240 and 246
The associated equipment of execution, one or more characteristics of machine, node and network.The operation indicated by the first receiving node R1
Then may include being transmitted to the output of the operation indicated by node 202 received from the first sending node S1 as input
Node 208.
Similarly, the operation indicated by the second sending node S2 may include by the output of the operation indicated by node 208
It is relayed to the second receiving node R2.This exchange can be for example on the network 215 that machine 132 and 126 can access with channel
The mode of 230B occurs.Being utilized to carry out the agreement of the communication can be reflected in by the second sending node and receiving node to S2
In the operation indicated with R2, and equipment associated with the execution of subgraph 246 and 242, machine, node and net can be depended on
The one or more features of network.The operation indicated by the second receiving node R2 then may include that will be connect from the second sending node S2
The output of the operation indicated by node 208 received is transmitted to node 212 as input.
Fig. 3 is the instantiation procedure provided by being included in exemplary sending node and the receiving node in calculating figure by executing
300 flow chart.For convenience, process 300 will be described as by one or more computers positioned at one or more positions
System execute.The calculating figure and operation that cohesive process 300 describes can those of be described above.For example, can lead to
Cross one or more parts that the calculating figure provided by system 100 is provided come implementation procedure 300, as above in conjunction with Figure 1.
As described above, the operation indicated by sending node and receiving node can be produced between the equipment that they are assigned to
Raw two-way communication.The operation 330 indicated respectively by sending node and receiving node S3 and R3 and 340 can include initially determining to use
In the communication protocol (332 and 342) of this two-way communication.The operation of expression is utilized by sending node and receiving node logical
Letter agreement may depend on and middle equipment, the one or more features of machine, node and network for executing subgraph at hand.Ginseng below
This determination process is further described according to Fig. 4 A-B.
Then the operation 330 indicated by sending node S3 can be used to determine whether that upstream node 310 has been provided
The output (310) of operation.It includes node 310 and sending node S3 that such output, which may include by the equipment execution by assigning,
Subgraph generate tensor.Once being provided, the operation 330 indicated by sending node S3 can be used for being indicated by node 310
The output of operation be fed as input to the operation 340 indicated by receiving node R3, which can then be used for it
It is fed as input to the operation indicated by node 320.
The execution of the operation 340 indicated by receiving node R3 can be related to sending one or more message to corresponding transmission
Node S3 (344).Such message may be used as the subgraph belonging to receiving node R3 and be ready for by executing corresponding transmission
Node S3 receives the instruction of input.In this way, these message can be counted as receiving by one or more upstreams
Operate the request of the data of output.In the example in figure 3, the operation 340 indicated by receiving node R3 can be from sending node S3
Reception includes the input of the output of the operation indicated by node 310.
When being executed, the operation 330 indicated by sending node S3 may include the data in response to receiving this message
Relaying.In some instances, during the operation 330 indicated by sending node S3 can be not used to before receiving such message
After the output (336) of the operation indicated by node 310.In this way it is possible to the information flow between adjustment equipment, to ensure into
Work(exchange tensor.In these examples, the output of the operation indicated by node 310 can be buffered or be otherwise stored at
In one or more memory areas of the positive equipment local for executing sending node S3 (337).In some embodiments, the behaviour
The output of work can be stored on the machine belonging to equipment elsewhere or on one or more network addressable units.
Once receiving receiving node message, the output of the operation of storage can be communicated by participant associated with receiving node R3
(336 to 338), and then refresh from memory or otherwise delete.It is had been received in determination as input
When coming output (346) for the operation that free sending node S3 is indicated, the operation that is indicated by receiving node R3 can be used for will in this way
Output input (348) as the operation to being indicated by downstream node 320 is provided.
As can be seen that by executing the operation 330 and 340 indicated respectively by sending node and receiving node S3 and R3, hold
All data exchanges needed for the part of row neural network or other machines learning model corresponding to associated son are (for side
Just for the sake of, this will be referred to as " execution of association subgraph ") it can be cooperateed with and executed by the equipment of execution subgraph.It is supplied to execution
The communication autonomy of the equipment pair of operation 330 and 340 can be used to the burden of communication for coordination from rear end call away to.In this way,
The calculating drawing system of such as system 100 can execute other one or more processes while equipment executes subgraph, and
It is not the communication actively adjusted between these equipment.At least for this reason, modification calculating figure is to include sending node and connect
Node is received to that can help to reduce the time cost and Internet traffic that handle in a distributed way needed for calculating figure.
In some embodiments, can using the operation 330 and 340 indicated by sending node and receiving node S3 and R3 come
It handles and transmits to and or from communication to all of locking equipment.For example, the operation 340 indicated by receiving node R3 can be used for receiving
Carry out the incoming communication for the operation 330 that free sending node S3 is indicated and comes what freely other one or more sending nodes indicated
Operation.Similarly, the operation 330 indicated by receiving node S3 can be used for spread out of communication and be fed as input to by receiving node
The operation 340 that R3 is represented and the operation represented by other one or more receiving nodes.In this way, by sending node and
The function of receiving node S3 hubs similar with the equipment offer that 340 can be used for being assigned to it with the operation 330 that R3 is indicated.
Sending node and receiving node S3 and R3 can be used for dividing subgraph in this way, and which allows neural network
Or a part for the neural network indicated by these subgraphs is trained on one device, and be distributed subsequently to another and set
It is standby.Sending node and receiving node S3 and R3 also allow for neural network or the neural network that is indicated by one or more subgraphs
Part is trained or tests in a new way.For example, the operation 340 indicated from receiving node R3 can be indicated to by node 320
Operation input, the tensor of the output for the operation which is indicated by node 310, to train 320 downstream of node are provided
Calculating figure one or more part receiving node R3.In some embodiments, client device can be utilized (all as above
The client device 102 that face describes referring to Fig.1), provide such input for receiving node R3.In these embodiments, objective
Family end equipment can be executed from providing the operation that predetermined tensor is indicated as the dedicated node of output, operation 330 to operation 330
It can execute on a client device.Such dedicated node can be counted as receiving node R3 and node 320 in calculating figure
The replacement of the node of upstream.In this way, user can by its client device execute by dedicated node table
The operation and operation 330 shown, remote testing and/or training neural network or the nerve indicated by one or more downstream subgraphs
The part of network.The tensor of the output of the operation indicated by such dedicated node may, for example, be static state, Yong Huding
It is justice, generating at random or based on one or more of the associated equipment of subgraph, machine, node and network is executed in hand
Determined by a feature.
In some embodiments, the data of exchanged between equipment associated with sending node and receiving node S3 and R3
It can be compressed.That is, the operation 330 indicated by sending node S3 can be used in the operation indicated by node 310
One or more compression processes are executed when output.Similarly, the operation 340 indicated by receiving node R3 can be used to passing through execution
When the compressed data provided as output by operation 330 that sending node S3 is indicated, one or more decompression process are executed.
Performed squeeze operation may include being suitable for any conventional compact algorithm of transmission data between both devices.For example,
The data of exchanged between equipment can be downconverted, block or combinations thereof.Equally, the numerical value conveyed by these data can also carry out
It is probability to round up.This squeeze operation can be based on equipment associated with the execution subgraph in hand, machine, node and net
The one or more features of network select.For example, squeeze operation can be selected based on the noise margin of machine learning model.To the greatest extent
Pipe has been combined operation 330 and 340 and describes compression, it should be appreciated that, such operation can utilize various signal processings
Any one of with regulation technology.
As described above, the communication protocol utilized to the operation of expression by sending node and receiving node may depend on and hand
The associated equipment of execution subgraph, the one or more characteristics of machine, node and network of head.Fig. 4 A-B are depicted including sending
Node and receiving node and the two parts for calculating Figure 40 0A and 400B for being assigned to equipment.As can be seen that calculating Figure 40 0A
The sending node for including has been assigned to equipment 412A (equipment 412A is GPU in this example), and calculates Figure 40 0A
The receiving node for including has been assigned to equipment 414A (equipment 414A is also GPU in this example).In this illustration,
GPU 412A and GPU 414A are resided in uniform machinery 410A.Sending node and receiving node due to calculating Figure 40 0A are all
GPU and dwell in uniform machinery 410A, thus this for their exchange remote procedure call (RPC) or other
It may be advantageous for progress under the request/response protocol on ground.
In some embodiments, special communication protocol to be used can be by executing after subgraph distribution by sending
Operation that node and receiving node indicate determines.For example, can be made in this way based on the known address information of these operations
Determination.In this illustration, GPU412A and GPU 414A can execute behaviour associated with sending node and receiving node
Make, the two equipment of these operation instructions are dwelt in machine 410A, and the then communication for coordination at RPC.In other implementations
In mode, communication protocol can be scheduled, and when each sending node and receiving node are inserted by each sending node
It is indicated in the operation indicated with receiving node.In these embodiments, each communication protocol can be described above with being similar to
Mode determine.
As can be seen that the sending node for including in calculating Figure 40 0B has been assigned to equipment 422B, (it can be CPU
Or GPU), and calculate Figure 40 0B receiving nodes for including be assigned to equipment 442B (its can also be CPU or
GPU).Equipment 422B may reside in machine 420B and equipment 442B may reside in machine 440B.It can be by making
It is that these equipment determine communication protocol with the technology similar with the technology being described above.In this illustration, equipment 422B
Exchange between 442B can be carried out in the case where Remote Direct Memory accesses (RDMA) agreement.The agreement is for two different machines
It may be advantageous for the equipment of device, because it allows to be communicated without regard to operating system associated with each equipment.
In this example, equipment 422B and 442B can execute operation associated with sending node and receiving node, these operations refer to
Show that two equipment reside in distinct device, and the then communication for coordination at RDMA.
Fig. 5 is for changing calculating figure with the flow chart including sending node and the instantiation procedure 500 of receiving node.In order to
Convenient, process 500 will be described as by one or more system for computer execution positioned at one or more positions.For example,
Drawing system, such as the calculating drawing system 100 of Figure 1A are calculated, it is properly programmed, it can be with implementation procedure 500.
The system can obtain the data (502) that expression includes the calculating figure of multiple nodes and directed edge.For example, calculating figure
It can be obtained by calculating drawing system after receiving request from one or more client devices.In some instances, it calculates
Each node in figure is the example of operation.
The system can obtain the data (504) of distribution of the identification across the calculating figure of multiple equipment.For example, calculating drawing system
It can determine how to assign each node for including in the calculating figure obtained across multiple available devices.In some embodiment party
In formula, this may include the data of the distribution for the calculating figure for obtaining the hardware resource that identification includes across one or more machines.
The system can identify that the connection in calculating figure is assigned to one or more directed edges of the node of distinct device
(506).For example, one or more striding equipment directed edges can be identified by calculating drawing system.
The system can be inserted into sending node and receiving node between the node pair that the directed edge by identifying connects
(508).It can be with the sending node and receiving node connected by two-way bridging device to each to replace for example, calculating drawing system
The striding equipment directed edge of identification.When doing so, system can be further inserted between sending node and corresponding first node
Directed edge, and it is inserted into directed edge between receiving node and corresponding second node.
In some embodiments, can by sending node and receiving node pair each node indicate operation it
Between independently exchange data.In some cases, sending node and each node of receiving node centering can indicate an operation,
The operation is received according to agreement corresponding with each hardware resource and machine (this is assigned sending node and receiving node)
The output for the operation that another node of the centering communicated indicates is as input.As described above, such agreement can be such as
Including RPC and RDMA.
For example, each sending node can indicate that the output for receiving the operation indicated by corresponding first node is used as input,
And the output of the operation indicated by corresponding first node is supplied to the operation of receiving node as output.For example, by corresponding
The output of operation that indicates of first node can be tensor.Similarly, each receiving node can be indicated to receive and be saved by sending
Point indicate operation output as input, and using the output of the operation indicated by sending node as output be supplied to accordingly
Second node operation.In some embodiments, the operation indicated from receiving node can also be provided to sending node will
Request of the output of the operation indicated by sending node as output.In these embodiments, in response to being connect from receiving node
The one or more requests received, the operation indicated by sending node can be by the output of the operation indicated by corresponding first node
It is supplied to receiving node as output.
System can change distribution so that sending node and receiving node are assigned to equipment (510).For example, calculating drawing system
Each sending node can be assigned to equipment identical with the node of sending node upstream, and equally will can each be received
Node is assigned to equipment identical with the node in receiving node downstream.
The operation indicated by node can be assigned to multiple equipment (512) by system according to modified distribution.For example, meter
Nomograph system can ask each execution in multiple equipment to be included in the operation in corresponding subgraph.In some embodiments
In, calculating figure can be divided into multiple subgraphs by system.
The embodiment and functional performance of theme described in this specification can be implemented in the following:Digital and electronic electricity
Road, the computer software or firmware of tangible implementation, computer hardware, including structure disclosed in this specification and its structure etc.
Consubstantiality or it is one of above-mentioned more than combination.The embodiment of theme described in this specification may be implemented as one
Or multiple computer programs, that is, encoded on one or more computer-readable program carriers such as tangible non-transitory program carrier
Computer program instructions one or more modules, to execute or control data processing equipment by data processing equipment
Operation.As substituting or adding, program instruction can be coded on manually generated transmitting signal, for example, machine generates
Electric signal, optical signal or electromagnetic signal, above-mentioned signal is generated as coding information and held for delivery to data processing equipment
Capable receiver apparatus appropriate.Computer storage media can be machine-readable storage device, machine readable memory substrate,
One or more combinations in random either serial access memory device or above-mentioned apparatus.However computer storage media
It is not transmitting signal.
Term " data processing equipment " includes the unit and machine for handling data of all kinds, as
Example, including programmable processor, computer either multi-processor or multiplex computer.Equipment may include special logic
Circuit, for example, FPGA (field programmable gate array) or ASIC (application-specific integrated circuit).Equipment other than including hardware,
It can also include the code for the performing environment for creating related computer program, such as constitute processor firmware, protocol stack, database
Management system, operating system or one or more combined codes in them.
Computer program (is also referred to as or is described as program, software, software application, module, software module, foot
This either code) it can be written out including compiler language or interpretative code or statement with any form of programming language
Language or procedural language, and computer program can be unfolded with arbitrary form, including as stand-alone program or conduct
Module, component, subprogram or other units suitable for using in a computing environment.Computer program can with but necessarily correspond to
File in file system.Program can be stored in a part for the file for preserving other programs or data, for example,
It is stored in one or more of following script：In marking language document；In the single file for being exclusively used in relative program；Or
Person is in multiple coordinated files, for example, the file of the one or more modules of storage, subprogram or code section.Computer journey
Sequence can be expanded as executing on a computer or multiple computers, and the computer bit is at one, or distribution is extremely
It multiple places and is interconnected by communication network.
As used in this description, " engine " or " software engine " refers to the software for providing the output different from input
The input/output of realization.Engine can be the functional block of coding, such as library, platform, Software Development Kit (" SDK ")
Or object.Each engine can be realized on the computing device of any appropriate type, such as server, mobile phone, tablet meter
Calculation machine, notebook computer, music player, E-book reader, on knee or desktop computer, PDA, smart phone or packet
Other for including one or more processors and computer-readable medium are fixed or portable device.In addition, two or more draw
Holding up can realize on identical computing device or on different computing devices.
The processing described in the present specification and logic flow can be executed by one or more programmable calculators, the meter
Calculation machine executes one or more computer programs by operation input data and generate output by, to run function.Processing
Can also be by dedicated logic circuit with logic flow, (can field programmable gate array) or ASIC (special integrated electricity for example, FPGA
Road) it executes, and equipment can also be implemented as dedicated logic circuit.
The computer for being adapted for carrying out computer program includes and can illustratively be based on general purpose microprocessor or special
With microprocessor either both above-mentioned processors or arbitrary other kinds of central processing unit.Normally, central processing list
Member will be received from read-only memory either random access memory or the instruction and data of the two.The main member of computer
Part be central processing unit for running or executing instruction and for storing instruction with the one or more storage of data
Device device.Normally, computer will also include either operably coupling, with from one or more for storing data
Mass storage device receives data and either transfers data to mass storage device or receive and transmit the two, the great Rong
It is, for example, disk, magneto-optic disk or CD to measure memory.However, computer necessarily has such device.In addition, computer
It can be embedded in another device, for example, mobile phone, personal digital assistant (PDA), Mobile audio frequency or video playing
Device, game master station, global positioning system (GPS) receiver or movable memory equipment, for example, universal serial bus
(USB) flash disk etc..
Computer-readable medium suitable for storing computer program instructions and data includes the non-volatile memory of form of ownership
Device, medium and memory device, as example, including：Semiconductor memory system, for example, EPROM, EEPROM and flash are deposited
Reservoir device；Disk, for example, built-in hard disk or moveable magnetic disc；Magneto-optic disk；CD-ROM and DVD-ROM disks.It processor and deposits
Reservoir can be supplemented with or be incorporated to dedicated logic circuit.
In order to provide the interaction with user, the embodiment of theme described in this specification may be implemented within computer
On, meter ^ machines have:Display device, for example, CRT (cathode-ray tube) monitor, LCD (liquid crystal display) monitors or
OLED display, for showing information to user；And the input equipment for providing input to computer, such as keyboard, mouse
It marks or there are sensitive display or other surfaces.Other kinds of device can be used for improving the interaction with user；For example, carrying
The feedback for supplying user can be any form of sensory feedback, for example, visual feedback, audio feedback or touch feedback；With
And input from the user can be received with arbitrary form, including sound input, voice input or sense of touch.In addition,
Computer can be handed over by resource is sent to the device used by user and receives the resource from the device with user
Mutually；For example, by the request from web browser in response to receiving, and webpage is sent to the client terminal device of user
On web browser.
The embodiment of theme described in this specification can be implemented in computing systems, which includes for example
Aft-end assembly as data server, either including intermediate module as such as application server or including for example objective
Front end assemblies as the computer of family end, the client computer have graphic user interface or web browser, user can be with
It is interacted with the implementation of theme described in this specification by graphic user interface either web browser or the meter
Calculation machine system includes the arbitrary combination of one or more this aft-end assemblies, intermediate module or front end assemblies.Group in system
Part can be interconnected for example, by the arbitrary form of communication network or the digital data communications of medium.The example of communication network
Including local area network (" LAN ") and Wide Area Network (" WAN "), for example, internet.
Computing system may include client and server.Client and server is generally remote from each other, and usually logical
It crosses communication network and interacts.Relationship between client and server, which is utilized, to be run on respective computer and with each other
Between client-server relation computer program and generate.
Although this specification includes many specific implementation details, these are not construed as to any invention
The limitation of the range of range or the content to that can be claimed, but as the particular implementation that can make specific invention
The explanation of the feature of materialization.Special characteristic described in this specification in the context of independent embodiment can also be with
Single embodiment is implemented in combination.On the contrary, the various features described in the context of single embodiment can also be independent
Ground is implemented in multiple embodiments, or implements in any suitable sub-portfolio.In addition, although feature can be retouched above
It states as compound action and even initially requires in this way, but the one or more features from desired combination are in some cases
Under the combination that can remove from the combination, and require can turn to the deformation of sub-portfolio or sub-portfolio.
Similarly, it although operation has been described in the accompanying drawings with particular order, is not construed as：It is expected to realize
Result it is required that such operation is either executed or the operation of all diagrams in sequential order with the particular order that shows
All it is performed.Under specific circumstances, multitasking and parallel processing can be advantageous.In addition, in the above embodiment
The separation of various system modules and component is not construed as requiring such separation in all embodiments, and should manage
Solution program assembly and system can usually be integrated in single software product or be packed into multiple software product.
The particular implementation of theme has been described.Other embodiment is in the range of following claims.For example,
The activity recorded in the claims can be executed in different order and still realize desired result.As a reality
Example, in order to realize desired as a result, the processing described in attached drawing necessarily requires the particular order shown or sequential order.
In particular implementation, multitasking and parallel processing can be advantageous.
Claims (25)
1. a method of computer implementation, including：
The data for indicating to calculate figure are obtained, the calculating figure includes multiple nodes and directed edge, wherein each node indicates corresponding
Operation, and corresponding first node is connected to corresponding second node by wherein each directed edge, and the corresponding second node indicates
The output of the operation indicated by the corresponding first node is received as input；
The data of distribution of the identification across the calculating figure of multiple equipment are obtained, wherein the distribution will be every in the calculating figure
A node is assigned to the relevant device in the multiple equipment；
Identification one or more of schemes striding equipment directed edge in calculatings, wherein each striding equipment directed edge is by corresponding the
One node is connected to the directed edge of corresponding second node, and the corresponding second node is assigned to and the phase in the distribution
Answer the equipment that first node is different；
For each striding equipment directed edge：
It is inserted into sending node between the corresponding first node and the corresponding second node in the calculating figure,
It is inserted into receiving node between the sending node and the corresponding second node in the operation diagram, and
The distribution is changed the sending node is assigned to equipment identical to the corresponding first node and will be described
Receiving node is assigned to equipment identical to the corresponding second node；And
The operation indicated by the node in the calculating figure is assigned to the multiple equipment according to the distribution changed.
2. according to the method described in claim 1, wherein：
The sending node indicates following operation：(i) output of the operation indicated by the corresponding first node is received as defeated
Enter, and the output of the operation indicated by the corresponding first node is supplied to the receiving node by (ii) as output；With
And
The receiving node indicates following operation：(i) output of the operation indicated by the sending node is received as input, and
And the output of the operation indicated by the sending node is supplied to the corresponding second node by (ii).
3. according to the method described in claim 2, wherein, the output of the operation indicated by the corresponding first node is tensor.
4. according to the method in claim 2 or 3, wherein：
Further (iii) will be indicated to sending node offer by the sending node for the operation indicated from the receiving node
Operation output as export request；And
The operation that is indicated by the sending node further (ii) in response to the one or more that is received from the receiving node
The output of the operation indicated by the corresponding first node is supplied to the receiving node by request as output.
5. method according to claim 1,2,3 or 4, wherein obtain the calculating figure identified across the multiple equipment
The data of the distribution include：
Obtain the data of the distribution for the calculating figure for identifying the hardware resource for including across one or more machines.
6. according to the method described in claim 5, wherein, each node of sending node and receiving node centering indicates operation,
The operation receives basis with the sending node and receiving node to the corresponding agreement of each hardware resource and machine that are assigned to
The output for the operation that another node of the centering communicated indicates is as input.
7. method according to any preceding claims, wherein：
Be inserted between the corresponding first node and the corresponding second node in the calculating figure sending node into
One step includes for each striding equipment directed edge：
It is inserted into directed edge between the sending node and the corresponding first node；And
It is further it to be inserted into the receiving node between the sending node and the corresponding second node in the operation diagram
Including for each striding equipment directed edge：
It is inserted into directed edge between the receiving node and the corresponding second node.
8. method according to any preceding claims, wherein data are by every in sending node and receiving node pair
It is independently exchanged between the operation that a node indicates.
9. method according to any preceding claims, wherein executed by the calculation chart by the multiple equipment
During the operation shown, the multiple equipment is allowed to be set the multiple the operation of expression by each sending node and receiving node
Outputting and inputting for the operation represented by other nodes in calculating figure is independently communicated between equipment in standby.
10. method according to any preceding claims, further comprises：Receive mode input；And according to by being repaiied
The operation that the calculation chart changed shows handles the mode input.
11. a kind of method, including：The meter changed for providing and being obtained by the method described in any one of claim 1 to 9
The corresponding machine learning model of nomogram；And handle mode input using the machine learning model.
12. the method according to any one of the preceding claims, wherein the calculating figure is the table of machine learning model
Show.
13. a kind of system, including：
One or more data processing equipments；And
The computer readable storage devices of instruction are stored thereon with, described instruction is by one or more of data processing equipments
One or more of data processing equipments are made to execute operation when execution, the operation includes：
The data for indicating to calculate figure are obtained, the calculating figure includes multiple nodes and directed edge, wherein each node indicates corresponding
Operation, and corresponding first node is connected to corresponding second node by wherein each directed edge, and the corresponding second node indicates
The output of the operation indicated by the corresponding first node is received as input；
The data of distribution of the identification across the calculating figure of multiple equipment are obtained, wherein the distribution will be every in the calculating figure
A node is assigned to the relevant device in the multiple equipment；
Identification one or more of schemes striding equipment directed edge in calculatings, wherein each striding equipment directed edge is by corresponding the
One node is connected to the directed edge of corresponding second node, and the corresponding second node is assigned to and the phase in the distribution
Answer the equipment that first node is different；
For each striding equipment directed edge：
It is inserted into sending node between the corresponding first node and the corresponding second node in the calculating figure,
It is inserted into receiving node between the sending node and the corresponding second node in the operation diagram, and
The distribution is changed the sending node is assigned to equipment identical to the corresponding first node and will be described
Receiving node is assigned to equipment identical to the corresponding second node；And
The operation indicated by the node in the calculating figure is assigned to the multiple equipment according to the distribution changed.
14. system according to claim 13, wherein：
The sending node indicates following operation：(i) output of the operation indicated by the corresponding first node is received as defeated
Enter, and the output of the operation indicated by the corresponding first node is supplied to the receiving node by (ii) as output；With
And
The receiving node indicates following operation：(i) output of the operation indicated by the sending node is received as input, and
And the output of the operation indicated by the sending node is supplied to the corresponding second node by (ii).
15. system according to claim 14, wherein the output of the operation indicated by the corresponding first node is
Amount.
16. the system according to claims 14 or 15, wherein：
Further (iii) will be indicated to sending node offer by the sending node for the operation indicated from the receiving node
Operation output as export request；And
The operation that is indicated by the sending node further (ii) in response to the one or more that is received from the receiving node
The output of the operation indicated by the corresponding first node is supplied to the receiving node by request as output.
17. the system according to any one of claim 13 to 16, wherein data are by sending node and receiving node
It is independently exchanged between the operation that each node of centering indicates.
18. the system according to any one of claim 13 to 17, wherein executed by described by the multiple equipment
During the operation that calculation chart shows, allow the multiple equipment in institute the operation of expression by each sending node and receiving node
It states and independently communicates outputting and inputting for the operation represented by other nodes in calculating figure between the equipment in multiple equipment.
19. a kind of computer readable storage devices being stored thereon with instruction, described instruction make institute when being executed by computing device
It states computing device and executes operation, the operation includes：
The data for indicating to calculate figure are obtained, the calculating figure includes multiple nodes and directed edge, wherein each node indicates corresponding
Operation, and corresponding first node is connected to corresponding second node by wherein each directed edge, and the corresponding second node indicates
The output of the operation indicated by the corresponding first node is received as input；
The data of distribution of the identification across the calculating figure of multiple equipment are obtained, wherein the distribution will be every in the calculating figure
A node is assigned to the relevant device in the multiple equipment；
Identification one or more of schemes striding equipment directed edge in calculatings, wherein each striding equipment directed edge is by corresponding the
One node is connected to the directed edge of corresponding second node, and the corresponding second node is assigned to and the phase in the distribution
Answer the equipment that first node is different；
For each striding equipment directed edge：
It is inserted into sending node between the corresponding first node and the corresponding second node in the calculating figure,
It is inserted into receiving node between the sending node and the corresponding second node in the operation diagram, and
The distribution is changed the sending node is assigned to equipment identical to the corresponding first node and will be described
Receiving node is assigned to equipment identical to the corresponding second node；And
The operation indicated by the node in the calculating figure is assigned to the multiple equipment according to the distribution changed.
20. storage device according to claim 19, wherein：
The sending node indicates following operation：(i) output of the operation indicated by the corresponding first node is received as defeated
Enter, and the output of the operation indicated by the corresponding first node is supplied to the receiving node by (ii) as output；With
And
The receiving node indicates following operation：(i) output of the operation indicated by the sending node is received as input, and
And the output of the operation indicated by the sending node is supplied to the corresponding second node by (ii).
21. storage device according to claim 20, wherein the output of the operation indicated by the corresponding first node is
Tensor.
22. the storage device according to claim 20 or 21, wherein：
Further (iii) will be indicated to sending node offer by the sending node for the operation indicated from the receiving node
Operation output as export request；And
The operation that is indicated by the sending node further (ii) in response to the one or more that is received from the receiving node
The output of the operation indicated by the corresponding first node is supplied to the receiving node by request as output.
23. the storage device according to any one of claim 19 to 22, wherein by the multiple equipment execute by
During the operation that the calculation chart shows, the multiple equipment is allowed to the operation of expression by each sending node and receiving node
Independently communicated between equipment in the multiple equipment the operation represented by other nodes in calculating figure input and
Output.
24. a kind of method for handling mode input according to calculating figure using multiple equipment, the calculating figure includes multiple
Node and directed edge, wherein each node indicates corresponding operating, wherein corresponding first node is connected to accordingly by each directed edge
Second node, the corresponding second node indicate that the output for receiving the operation indicated by the corresponding first node is as input
Operation, wherein the method includes for the first equipment in the multiple equipment：
The data of the subgraph for the calculating figure for indicating to be assigned to first equipment are received, the subgraph includes coming from the meter
The multiple nodes and directed edge of nomogram；And
The operation indicated by the node in the subgraph is executed, including：
(1) operation indicated by the corresponding first node in the subgraph is executed to generate the first output；
Determine the sending node that the first node is connected to by directed edge in the subgraph；And
The operation indicated by the sending node is executed to pass with the first output of the operation that will be indicated by the corresponding first node
Another equipment being sent in the multiple equipment；And/or
(2) operation indicated by the receiving node in the subgraph is executed, to obtain by being assigned in the multiple equipment
Second output of the operation that the second node of another equipment indicates；
Determine the third node that the receiving node is connected to by directed edge in the subgraph；And
It uses obtained second to export and executes the operation indicated by the third node as input.
25. a kind of system for handling mode input according to calculating figure, the calculating figure includes multiple nodes and directed edge,
Wherein each node indicates corresponding operating, wherein corresponding first node is connected to corresponding second node by each directed edge, it is described
Corresponding second node indicates to receive the output operation as input of the operation indicated by the corresponding first node, wherein described
System includes multiple equipment, and the first equipment in wherein the multiple equipment is configured as executing operation, the operation packet
It includes：
The data of the subgraph for the calculating figure for indicating to be assigned to first equipment are received, the subgraph includes coming from the meter
The multiple nodes and directed edge of nomogram；And
The operation indicated by the node in the subgraph is executed, including：
(1) operation indicated by the corresponding first node in the subgraph is executed to generate the first output；
Determine the sending node that the first node is connected to by directed edge in the subgraph；And
It is defeated with described the first of the operation that will be indicated by the corresponding first node to execute the operation indicated by the sending node
Go out another equipment being transmitted in the multiple equipment；And/or
(2) operation indicated by the receiving node in the subgraph is executed, to obtain by being assigned in the multiple equipment
Second output of the operation that the second node of another equipment indicates；
Determine the third node that the receiving node is connected to by directed edge in the subgraph；And
It uses obtained second to export and executes the operation indicated by the third node as input.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201562247713P | 2015-10-28 | 2015-10-28 | |
US62/247,713 | 2015-10-28 | ||
US201562253029P | 2015-11-09 | 2015-11-09 | |
US62/253,029 | 2015-11-09 | ||
PCT/US2016/059314 WO2017075346A1 (en) | 2015-10-28 | 2016-10-28 | Modifying computational graphs |
Publications (1)
Publication Number | Publication Date |
---|---|
CN108351983A true CN108351983A (en) | 2018-07-31 |
Family
ID=57822015
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680063358.6A Pending CN108351983A (en) | 2015-10-28 | 2016-10-28 | Modification calculates figure |
Country Status (6)
Country | Link |
---|---|
US (4) | US10783435B2 (en) |
EP (2) | EP3353718B1 (en) |
JP (2) | JP6636630B2 (en) |
KR (2) | KR102327615B1 (en) |
CN (1) | CN108351983A (en) |
WO (1) | WO2017075346A1 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110162337A (en) * | 2019-05-31 | 2019-08-23 | 北京中科寒武纪科技有限公司 | Operation method, device and Related product |
CN111832714A (en) * | 2019-04-19 | 2020-10-27 | 上海寒武纪信息科技有限公司 | Operation method and device |
CN112070221A (en) * | 2019-05-31 | 2020-12-11 | 中科寒武纪科技股份有限公司 | Operation method, device and related product |
Families Citing this family (33)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11615285B2 (en) * | 2017-01-06 | 2023-03-28 | Ecole Polytechnique Federale De Lausanne (Epfl) | Generating and identifying functional subnetworks within structural networks |
US11037330B2 (en) * | 2017-04-08 | 2021-06-15 | Intel Corporation | Low rank matrix compression |
US11138494B2 (en) * | 2017-05-02 | 2021-10-05 | International Business Machines Corporation | Storage controller acceleration for neural network training and inference |
US10019668B1 (en) * | 2017-05-19 | 2018-07-10 | Google Llc | Scheduling neural network processing |
US11138516B2 (en) | 2017-06-30 | 2021-10-05 | Visa International Service Association | GPU enhanced graph model build and scoring engine |
EP3682379A1 (en) * | 2017-09-15 | 2020-07-22 | Google LLC | Augmenting neural networks |
JP7074777B2 (en) | 2017-11-20 | 2022-05-24 | シャンハイ カンブリコン インフォメーション テクノロジー カンパニー リミテッド | Tasks Parallel processing methods, appliances, systems, storage media and computer equipment |
US20190286973A1 (en) * | 2018-03-14 | 2019-09-19 | Microsoft Technology Licensing, Llc | Hardware accelerated neural network subgraphs |
FI130232B (en) * | 2018-04-18 | 2023-05-03 | Meeshkan Oy | Method for distributed information processing and distributed information processing system |
US11645493B2 (en) | 2018-05-04 | 2023-05-09 | Microsoft Technology Licensing, Llc | Flow for quantized neural networks |
US11893471B2 (en) | 2018-06-11 | 2024-02-06 | Inait Sa | Encoding and decoding information and artificial neural networks |
US11663478B2 (en) | 2018-06-11 | 2023-05-30 | Inait Sa | Characterizing activity in a recurrent artificial neural network |
US11972343B2 (en) | 2018-06-11 | 2024-04-30 | Inait Sa | Encoding and decoding information |
US10318891B1 (en) * | 2018-07-23 | 2019-06-11 | Google Llc | Geometry encoder |
US10891758B2 (en) | 2018-07-23 | 2021-01-12 | Google Llc | Geometry encoder |
CN110766147B (en) * | 2018-07-25 | 2022-10-11 | 赛灵思公司 | Neural network compiler architecture and compiling method |
US11263529B2 (en) * | 2018-10-10 | 2022-03-01 | Google Llc | Modifying machine learning models to improve locality |
CN111078625B (en) * | 2018-10-18 | 2022-03-29 | 上海寒武纪信息科技有限公司 | Network-on-chip processing system and network-on-chip data processing method |
CN111078624B (en) * | 2018-10-18 | 2022-03-25 | 上海寒武纪信息科技有限公司 | Network-on-chip processing system and network-on-chip data processing method |
KR20200053318A (en) * | 2018-11-08 | 2020-05-18 | 삼성전자주식회사 | System managing calculation processing graph of artificial neural network and method managing calculation processing graph using thereof |
US10922790B2 (en) * | 2018-12-21 | 2021-02-16 | Intel Corporation | Apparatus and method for efficient distributed denoising of a graphics frame |
US20210232969A1 (en) * | 2018-12-24 | 2021-07-29 | Intel Corporation | Methods and apparatus to process a machine learning model in a multi-process web browser environment |
US11652603B2 (en) | 2019-03-18 | 2023-05-16 | Inait Sa | Homomorphic encryption |
US11569978B2 (en) | 2019-03-18 | 2023-01-31 | Inait Sa | Encrypting and decrypting information |
US11231961B2 (en) | 2019-05-22 | 2022-01-25 | Fujitsu Limited | Scheduling operations |
US11694075B2 (en) * | 2019-09-05 | 2023-07-04 | Alibaba Group Holding Limited | Partitioning control dependency edge in computation graph |
US11580401B2 (en) | 2019-12-11 | 2023-02-14 | Inait Sa | Distance metrics and clustering in recurrent neural networks |
US11651210B2 (en) | 2019-12-11 | 2023-05-16 | Inait Sa | Interpreting and improving the processing results of recurrent neural networks |
US11816553B2 (en) | 2019-12-11 | 2023-11-14 | Inait Sa | Output from a recurrent neural network |
US11797827B2 (en) | 2019-12-11 | 2023-10-24 | Inait Sa | Input into a neural network |
WO2021225486A1 (en) * | 2020-05-08 | 2021-11-11 | Telefonaktiebolaget Lm Ericsson (Publ) | Configuring a resource for executing a computational operation |
US11815943B1 (en) * | 2020-06-05 | 2023-11-14 | State Farm Mutual Automobile Insurance Company | Systems and methods for processing using directed acyclic graphs |
CN112070213A (en) * | 2020-08-28 | 2020-12-11 | Oppo广东移动通信有限公司 | Neural network model optimization method, device, equipment and storage medium |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060095722A1 (en) * | 2004-10-20 | 2006-05-04 | Arm Limited | Program subgraph identification |
JP2007164504A (en) * | 2005-12-14 | 2007-06-28 | Fuji Heavy Ind Ltd | Stream data processing method and stream data processor |
CN100468320C (en) * | 2003-12-09 | 2009-03-11 | 微软公司 | Accelerating and optimizing the processing of machine learning techniques using a graphics processing unit |
CN101443733A (en) * | 2006-05-16 | 2009-05-27 | 起元软件有限公司 | Managing computing resources in graph-based computations |
CN102017780A (en) * | 2008-04-30 | 2011-04-13 | 高通股份有限公司 | Apparatus and methods for transmitting data over a wireless mesh network |
US20150007182A1 (en) * | 2013-06-27 | 2015-01-01 | Microsoft Corporation | Iteration support in a heterogeneous dataflow engine |
Family Cites Families (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR101048546B1 (en) * | 2009-03-05 | 2011-07-11 | 엔에이치엔(주) | Content retrieval system and method using ontology |
EP2629247B1 (en) * | 2012-02-15 | 2014-01-08 | Alcatel Lucent | Method for mapping media components employing machine learning |
US9256823B2 (en) * | 2012-07-27 | 2016-02-09 | Qualcomm Technologies Inc. | Apparatus and methods for efficient updates in spiking neuron network |
US11061539B2 (en) | 2013-03-15 | 2021-07-13 | The Mathworks, Inc. | Reference nodes in a computational graph |
JP6007430B2 (en) | 2015-05-20 | 2016-10-12 | 大澤 昇平 | Machine learning model design support device, machine learning model design support method, program for machine learning model design support device |
-
2016
- 2016-10-28 JP JP2018521841A patent/JP6636630B2/en active Active
- 2016-10-28 EP EP16826784.7A patent/EP3353718B1/en active Active
- 2016-10-28 KR KR1020217000978A patent/KR102327615B1/en active IP Right Grant
- 2016-10-28 CN CN201680063358.6A patent/CN108351983A/en active Pending
- 2016-10-28 US US15/338,225 patent/US10783435B2/en active Active
- 2016-10-28 WO PCT/US2016/059314 patent/WO2017075346A1/en active Application Filing
- 2016-10-28 KR KR1020187013806A patent/KR102204887B1/en active IP Right Grant
- 2016-10-28 EP EP23185682.4A patent/EP4242845A1/en active Pending
-
2018
- 2018-04-27 US US15/965,745 patent/US10354186B2/en active Active
-
2019
- 2019-12-17 JP JP2019227507A patent/JP7094262B2/en active Active
-
2020
- 2020-09-09 US US17/015,196 patent/US11087216B2/en active Active
-
2021
- 2021-08-03 US US17/392,690 patent/US20220019896A1/en active Pending
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN100468320C (en) * | 2003-12-09 | 2009-03-11 | 微软公司 | Accelerating and optimizing the processing of machine learning techniques using a graphics processing unit |
US20060095722A1 (en) * | 2004-10-20 | 2006-05-04 | Arm Limited | Program subgraph identification |
JP2007164504A (en) * | 2005-12-14 | 2007-06-28 | Fuji Heavy Ind Ltd | Stream data processing method and stream data processor |
CN101443733A (en) * | 2006-05-16 | 2009-05-27 | 起元软件有限公司 | Managing computing resources in graph-based computations |
CN102017780A (en) * | 2008-04-30 | 2011-04-13 | 高通股份有限公司 | Apparatus and methods for transmitting data over a wireless mesh network |
US20150007182A1 (en) * | 2013-06-27 | 2015-01-01 | Microsoft Corporation | Iteration support in a heterogeneous dataflow engine |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111832714A (en) * | 2019-04-19 | 2020-10-27 | 上海寒武纪信息科技有限公司 | Operation method and device |
CN111832714B (en) * | 2019-04-19 | 2023-11-17 | 上海寒武纪信息科技有限公司 | Operation method and device |
CN110162337A (en) * | 2019-05-31 | 2019-08-23 | 北京中科寒武纪科技有限公司 | Operation method, device and Related product |
CN110162337B (en) * | 2019-05-31 | 2020-07-03 | 中科寒武纪科技股份有限公司 | Operation method, device and related product |
CN112070221A (en) * | 2019-05-31 | 2020-12-11 | 中科寒武纪科技股份有限公司 | Operation method, device and related product |
CN112070221B (en) * | 2019-05-31 | 2024-01-16 | 中科寒武纪科技股份有限公司 | Operation method, device and related product |
Also Published As
Publication number | Publication date |
---|---|
KR102327615B1 (en) | 2021-11-17 |
US10354186B2 (en) | 2019-07-16 |
US10783435B2 (en) | 2020-09-22 |
EP4242845A1 (en) | 2023-09-13 |
WO2017075346A1 (en) | 2017-05-04 |
JP7094262B2 (en) | 2022-07-01 |
US20200401897A1 (en) | 2020-12-24 |
US20220019896A1 (en) | 2022-01-20 |
JP2020057422A (en) | 2020-04-09 |
EP3353718B1 (en) | 2023-07-19 |
KR20180069881A (en) | 2018-06-25 |
KR102204887B1 (en) | 2021-01-19 |
US11087216B2 (en) | 2021-08-10 |
US20180247198A1 (en) | 2018-08-30 |
JP6636630B2 (en) | 2020-01-29 |
US20170124454A1 (en) | 2017-05-04 |
EP3353718A1 (en) | 2018-08-01 |
JP2018533792A (en) | 2018-11-15 |
KR20210008150A (en) | 2021-01-20 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN108351983A (en) | Modification calculates figure | |
CN108292241A (en) | Processing calculates figure | |
WO2022089256A1 (en) | Method, apparatus and device for training federated neural network model, and computer program product and computer-readable storage medium | |
CN108292374A (en) | Training is expressed as the neural network of calculating figure | |
KR20180120240A (en) | Wide and deep machine learning models | |
CN110147882B (en) | Neural network model training method, crowd diffusion method, device and equipment | |
CN113505882B (en) | Data processing method based on federal neural network model, related equipment and medium | |
CN108140075A (en) | User behavior is classified as exception | |
CN106446005A (en) | Factorized models | |
US11763146B1 (en) | Processing loops in computational graphs | |
CN112136109A (en) | Distributed resource allocation | |
CN113469373A (en) | Model training method, system, equipment and storage medium based on federal learning | |
CN108460458A (en) | It is executed in graphics processing unit and calculates figure | |
CN107679625A (en) | The distributed system and its method of machine learning are performed for data record | |
US20210390152A1 (en) | Method, system, and non-transitory computer-readable record medium for providing multiple models of federated learning using personalization | |
CN112136111A (en) | Distributed resource allocation | |
Ben Mahfoudh et al. | Learning-based coordination model for spontaneous self-composition of reliable services in a distributed system | |
CN108733694A (en) | Method and apparatus are recommended in retrieval | |
US20160342899A1 (en) | Collaborative filtering in directed graph | |
CN108289115B (en) | Information processing method and system | |
CN112926090A (en) | Service analysis method and device based on differential privacy | |
Ali et al. | Static heuristics for robust resource allocation of continuously executing applications | |
JP7397212B2 (en) | Using secure MPC and vector computation to protect access to information in content delivery | |
CN112166413A (en) | Distributed resource allocation | |
Maniezzo et al. | Client-side computational optimization |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |