CN107431790A - Convolution color correction - Google Patents
Convolution color correction Download PDFInfo
- Publication number
- CN107431790A CN107431790A CN201680013957.7A CN201680013957A CN107431790A CN 107431790 A CN107431790 A CN 107431790A CN 201680013957 A CN201680013957 A CN 201680013957A CN 107431790 A CN107431790 A CN 107431790A
- Authority
- CN
- China
- Prior art keywords
- input picture
- histogram
- image
- wave filter
- dimensional chromaticity
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000012937 correction Methods 0.000 title description 6
- 239000003086 colorant Substances 0.000 claims abstract description 18
- 238000004040 coloring Methods 0.000 claims abstract description 9
- 238000000034 method Methods 0.000 claims description 30
- 238000012549 training Methods 0.000 claims description 28
- 230000002708 enhancing effect Effects 0.000 claims description 20
- 238000005286 illumination Methods 0.000 claims description 18
- 238000001914 filtration Methods 0.000 claims description 17
- 238000009826 distribution Methods 0.000 claims description 6
- 238000010606 normalization Methods 0.000 claims description 6
- 230000004044 response Effects 0.000 claims description 6
- 230000006870 function Effects 0.000 description 34
- 238000004891 communication Methods 0.000 description 17
- 230000008859 change Effects 0.000 description 11
- 238000005516 engineering process Methods 0.000 description 11
- 238000013500 data storage Methods 0.000 description 9
- 238000010586 diagram Methods 0.000 description 7
- 230000008569 process Effects 0.000 description 7
- 238000012545 processing Methods 0.000 description 7
- 238000003860 storage Methods 0.000 description 6
- 238000003384 imaging method Methods 0.000 description 5
- 230000015654 memory Effects 0.000 description 5
- 239000000203 mixture Substances 0.000 description 5
- 238000005070 sampling Methods 0.000 description 5
- 238000013519 translation Methods 0.000 description 5
- 238000012800 visualization Methods 0.000 description 5
- 241000533901 Narcissus papyraceus Species 0.000 description 4
- 238000006073 displacement reaction Methods 0.000 description 4
- 238000009472 formulation Methods 0.000 description 4
- 238000013507 mapping Methods 0.000 description 4
- 238000005259 measurement Methods 0.000 description 4
- 230000005540 biological transmission Effects 0.000 description 3
- 238000007477 logistic regression Methods 0.000 description 3
- 230000007935 neutral effect Effects 0.000 description 3
- 238000005457 optimization Methods 0.000 description 3
- 238000003825 pressing Methods 0.000 description 3
- 239000000047 product Substances 0.000 description 3
- 238000002310 reflectometry Methods 0.000 description 3
- 238000009416 shuttering Methods 0.000 description 3
- 230000000007 visual effect Effects 0.000 description 3
- 230000003213 activating effect Effects 0.000 description 2
- 239000000654 additive Substances 0.000 description 2
- 230000000996 additive effect Effects 0.000 description 2
- 238000013461 design Methods 0.000 description 2
- 230000007774 longterm Effects 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 210000001525 retina Anatomy 0.000 description 2
- 238000001228 spectrum Methods 0.000 description 2
- 238000012546 transfer Methods 0.000 description 2
- 230000001960 triggered effect Effects 0.000 description 2
- 241000196324 Embryophyta Species 0.000 description 1
- 206010068052 Mosaicism Diseases 0.000 description 1
- 230000009471 action Effects 0.000 description 1
- 230000003466 anti-cipated effect Effects 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 230000000712 assembly Effects 0.000 description 1
- 238000000429 assembly Methods 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 210000004556 brain Anatomy 0.000 description 1
- 239000006227 byproduct Substances 0.000 description 1
- 210000004027 cell Anatomy 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 238000006243 chemical reaction Methods 0.000 description 1
- 230000000295 complement effect Effects 0.000 description 1
- 238000013527 convolutional neural network Methods 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 230000007423 decrease Effects 0.000 description 1
- 238000001514 detection method Methods 0.000 description 1
- 235000013399 edible fruits Nutrition 0.000 description 1
- 230000005611 electricity Effects 0.000 description 1
- 230000008030 elimination Effects 0.000 description 1
- 238000003379 elimination reaction Methods 0.000 description 1
- 230000002349 favourable effect Effects 0.000 description 1
- 238000007667 floating Methods 0.000 description 1
- 238000007689 inspection Methods 0.000 description 1
- 230000002045 lasting effect Effects 0.000 description 1
- 239000007788 liquid Substances 0.000 description 1
- 238000010801 machine learning Methods 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 229910044991 metal oxide Inorganic materials 0.000 description 1
- 150000004706 metal oxides Chemical class 0.000 description 1
- 230000000877 morphologic effect Effects 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 210000004940 nucleus Anatomy 0.000 description 1
- 230000001737 promoting effect Effects 0.000 description 1
- 230000005855 radiation Effects 0.000 description 1
- 238000011084 recovery Methods 0.000 description 1
- 230000002441 reversible effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000035945 sensitivity Effects 0.000 description 1
- 210000003765 sex chromosome Anatomy 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000006467 substitution reaction Methods 0.000 description 1
- 239000013598 vector Substances 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T5/00—Image enhancement or restoration
- G06T5/40—Image enhancement or restoration by the use of histogram techniques
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/10—Cameras or camera modules comprising electronic image sensors; Control thereof for generating image signals from different wavelengths
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T5/00—Image enhancement or restoration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T5/00—Image enhancement or restoration
- G06T5/10—Image enhancement or restoration by non-spatial domain filtering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T5/00—Image enhancement or restoration
- G06T5/20—Image enhancement or restoration by the use of local operators
-
- G06T5/60—
-
- G06T5/77—
-
- G06T5/92—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/90—Determination of colour characteristics
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N1/00—Scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission; Details thereof
- H04N1/46—Colour picture communication systems
- H04N1/56—Processing of colour picture signals
- H04N1/60—Colour correction or control
- H04N1/6027—Correction or control of colour gradation or colour contrast
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N1/00—Scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission; Details thereof
- H04N1/46—Colour picture communication systems
- H04N1/56—Processing of colour picture signals
- H04N1/60—Colour correction or control
- H04N1/6083—Colour correction or control controlled by factors external to the apparatus
- H04N1/6086—Colour correction or control controlled by factors external to the apparatus by scene illuminant, i.e. conditions at the time of picture capture, e.g. flash, optical filter used, evening, cloud, daylight, artificial lighting, white point measurement, colour temperature
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/80—Camera processing pipelines; Components thereof
- H04N23/84—Camera processing pipelines; Components thereof for processing colour signals
- H04N23/88—Camera processing pipelines; Components thereof for processing colour signals for colour balance, e.g. white-balance circuits or colour temperature control
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/10—Image acquisition modality
- G06T2207/10024—Color image
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20081—Training; Learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20084—Artificial neural networks [ANN]
Abstract
Computing device can obtain input picture.Input picture can have the white point represented by limiting the chromatic value of the white colours in input picture.The color of input picture is possibly based on, computing device can produce the two-dimensional chromaticity histogram of input picture.Computing device can make two-dimensional chromaticity histogram with wave filter convolution to create two-dimentional thermal map.Entry in two-dimentional thermal map can represent each color corresponding with each entry how close to input picture white point each estimation.Computing device can select the entry of the particular value in the threshold value of maximum of the expression in thermal map in two-dimentional thermal map, and the entry based on selection, input picture coloring is formed output image.
Description
Background technology
Digital imagery, which can be related to, to be captured the color of scene and light characteristic and is presented on digital picture (for example, photo
Or sport video) in.When capturing the digital picture of special scenes, the true colors of object therein may be by appointing in scene
The color displacement of what illumination.Therefore, can further handle and/or strengthen digital picture has closer to true colors to create
Color new digital picture.However, performed in a manner of independent of the imaging sensor for capturing digital picture this
Color correction is challenging.
The content of the invention
The color of pixel can be represented as the product of two amounts in neutral images, and the two amounts are reflectivity (for example, scene
The color on middle surface) and illumination (color of the light on the surface in irradiation scene).Assign computer and distinguish reflectivity from illuminator
Ability be difficult because problem constraint is very few --- given yellow pixel, it is to represent Yellow luminous not know it generally
Yellow object under white object under body, or white emitter.Infer and the color of the illumination of correction chart picture is commonly referred to as
For " color constancy (color constancy) " or " white balance (white-balance) ".
The embodiments herein discloses a kind of color constancy technology, and it is based on by the Color Channel of zoomed image and the figure
The observation of the translation correlation of the histogram of the logarithm chromaticity (log-chromaticity) of picture.This observation allows to utilize based on volume
Color constancy sex chromosome mosaicism is configured to differentiate Machine Learning Problems by product neutral net and the instrument of structuring prediction.By with this
Mode trains the technology of color constancy with differentiating, the embodiments herein can reduce error rate on standard basis up to 40% it
It is more.
Therefore, the first example embodiment can be related to acquisition input picture.Input picture can have by limiting input figure
The white point that the chromatic value of white colours as in represents.First example embodiment can also relate to the color based on input picture
Produce the two-dimensional chromaticity histogram of input picture.First example embodiment can further to make two-dimensional chromaticity histogram with filter
Ripple device convolution is to create two-dimentional thermal map (heat map).Entry (entry) in two-dimentional thermal map can represent and each entry pair
The each tone (tint) answered how close to input picture white point each estimation.First example embodiment can be extraly
It is related to：The entry of the particular value in the threshold value of maximum of the expression in two-dimentional thermal map in thermal map is selected, and based on selection
Entry, make input picture coloring to form output image.
In the second example embodiment, product can include non-transitory computer-readable medium, and it has program stored therein above
Instruction, the programmed instruction is by causing operation of the computing device according to the first example embodiment during computing device.
In the third example embodiment, a kind of computing device can include at least one processor, and data storage dress
Put and programmed instruction.Programmed instruction can be stored in data storage device, and programmed instruction is by least one computing device
When can cause operation of the computing device according to the first example embodiment.
In the 4th example embodiment, a kind of system can include every in the operation for the first example embodiment of execution
The various devices of one.
Described in detail below by the reading of refer to the attached drawing in appropriate circumstances, those skilled in the art will be seen that these
And other embodiment, aspect, advantage and alternative solution.Additionally, it should it is appreciated that provided herein is the content of the invention and other descriptions
And accompanying drawing is intended to be bound only by the mode of example and carrys out illustrated embodiment, and therefore many changes are possible.For example, it can weigh
New arrangement, combination, distribution, elimination otherwise change structural detail and process steps, and are still being claimed simultaneously
Embodiment in the range of.
Brief description of the drawings
Fig. 1 depict the digital camera devices according to example embodiment before, right side and rearview.
Fig. 2 depicts the block diagram of the computing device with image capture capabilities according to example embodiment.
Fig. 3 depicts the colourity Nogata of the association of the three kinds of tones and each tone according to the image of example embodiment
Figure.
Fig. 4 depicts the function of the illuminating color using during the training period, as proposition according to example embodiment
The visualization figure of cost function (cost function).
Fig. 5 depicts the visualization figure filtered according to the pyramid of example embodiment.
Fig. 6 depicts the visual of the information of four passages associated by the image with enhancing the capture according to example embodiment
Change figure.
Fig. 7 is the flow chart according to example embodiment.
Embodiment
There has been described exemplary method, equipment and system.It should be appreciated that word " example " and " exemplary " are herein
For representing " serving as example, example or signal ".Described herein as " example " or any embodiment of " exemplary " and spy
Sign is not necessarily read as preferably or favourable relative to other embodiment or feature.The scope of theme presented herein is not being departed from
In the case of can utilize other embodiment, and other changes can be carried out.
Therefore, example embodiment described herein is not intended to be restricted.Can be with diversified different configurations
Being arranged to the various aspects of the disclosure for being usually described herein and illustrating in the accompanying drawings, replacing, organizing splitting or integrating
From and design, it is all these to be all susceptible to herein.
In addition, suggesting unless the context otherwise, the feature otherwise illustrated in each accompanying drawing can be with combination with one another.Cause
This, in terms of the composition that accompanying drawing should be usually regarded as to one or more overview embodiments, wherein being appreciated that not all signal
Feature all for needed for each embodiment.
1st, example image capture device
As the image capture device of such as camera becomes more to popularize, they be used as standalone hardware device or
It is integrated into the equipment of various other types.For example, static and video camera is typically now included in wireless computer device (example
Such as, mobile phone), tablet PC, desktop computer, video game interface, home automation device, even in automobile and its
In the vehicle of his type.
The physical assemblies of camera can include light is entered by it one or more apertures, for capture by light representations
One or more recording surfaces of image and be positioned at before each aperture with least a portion image is focused on (one or
It is multiple) lens on recording surface.Aperture can be fixed size or adjustable.In analogue camera, recording surface can
To be photographic film.In digital camera, recording surface can include electronic image sensor (for example, charge coupling device
(CCD) or complementary metal oxide semiconductor (CMOS) sensor), the image of capture is transmitted and/or stored to data and is deposited
In storage unit (for example, memory).
One or more shutters may be coupled to lens or recording surface or near lens or recording surface.It is each fast
Door may be at closed position or open position, and in closed position, shutter intercepts light reaches recording surface, in open position light quilt
Allow to reach recording surface.The position of each shutter can be controlled by shutter release button.For example, shutter can be given tacit consent in closing
Position.When triggering (for example, pressing) shutter release button, shutter can change to open position for a period of time from closed position, this
The section time is referred to as the shutter cycle.During the shutter cycle, can on recording surface capture images.In shutter end cycle,
Shutter can change back to closed position.
Alternatively, shuttering process (shuttering process) can be electronics.For example, in ccd image sensor
Electronic shutter " opening " before, the sensor can be reset to remove any residue signal in its photodiode.
When electronic shutter stays open, photodiode can be with stored charge., can be by these electric charges when shutter close or afterwards
It is sent to longer data storage device.Both mechanically and electrically the combination of shutter is also possible.
Whatsoever type, shutter can be activated and/or controlled by other things in addition to shutter release button.Example
Such as, shutter can be activated by soft key, timer or some other trigger.Herein, term " image capture " can be with
It is related to any machinery for causing one or more images to be recorded and/or electronic shutter process, how is but regardless of shuttering process
It is triggered or controls.
Can the size by aperture, the brightness of the light into aperture and the length in shutter cycle (also referred to as shutter length or
Exposure length) come determine capture image light exposure.Furthermore, it is possible to image application numeral and/or analog gain, so as to shadow
Ring light exposure.In certain embodiments, term " total exposure length " or " total exposure time " can refer to shutter length be multiplied by for
The gain of specific aperture size.Herein, term " total exposure time " or " TET " should be interpreted to be probably shutter length
Any other measurement for the amount that signal caused by degree, time for exposure or control reach recording surface due to light responds.
Each image capture is triggered, and still camera can capture one or more images.As long as image capture keeps quilt
Trigger (for example, when shutter release button is kept and pressed), video camera can is with special speed (for example, 24 images per second
Or frame) continuously capture images.Some Digital Still Cameras can open shutter when activating camera apparatus or application, and soon
Door can be kept in the position until camera apparatus or application are deactivated.When the shutter is opened, camera apparatus or application can be with
The expression of scene is captured and including on view finder.When triggering image capture, one or more of current scene can be captured
The digital picture of individual difference.
Camera (even analogue camera) can include software to control one or more camera functions and/or such as aperture
The setting of size, TET, gain etc..In addition, some cameras are digitally processed these during or after being included in capture images
The software of image.Although above description relates generally to camera, it can be especially relevant with digital camera.
As previously noted, digital camera can be standalone equipment or be integrated with other equipment.As an example, Fig. 1 shows
The form factor (form factor) of digital camera devices of having anticipated 100.Digital camera devices 100 can be such as mobile phone,
Tablet PC or wearable computing devices.However, other embodiment is also possible.Digital camera devices 100 can include
Various elements, such as main body 102, Front camera 104, multicomponent display (multi-element display) 106, shutter
Button 108 and other buttons 110.Digital camera devices 100 can also include rearmounted camera 112.Front camera 104 can position
On side when main body 102 is in operation typically in face of user, or with the identical side of multicomponent display 106.
Rearmounted camera 112 can be positioned on the side opposite with Front camera 104 of main body 102.Camera is referred to as preposition and rearmounted
It is random, and digital camera devices 100 can include being positioned at multiple cameras on the various sides of main body 102.
Multicomponent display 106 can represent cathode-ray tube (CRT) display, light emitting diode (LED) display, liquid
The display of brilliant (LCD) display, plasma scope or any other type as known in the art.In some embodiments
In, multicomponent display 106 can show the digital table of the present image captured by Front camera 104 and/or rearmounted camera 112
Show, or can be by these magazine captures of any one or two or the images being recently captured.Therefore, multicomponent display
106 can serve as the view finder for any one camera.Multicomponent display 106 can also support touch-screen and/or exist quick
Feel the function of (presence-sensitive), touch screen and/or the function of sensitivity being present can adjust digital camera devices
The setting and/or configuration of 100 any aspect.
Front camera 104 can include the association optical element of imaging sensor and such as lens.Front camera 104 can be with
Zoom capabilities are provided or there can be fixed focal length.In other embodiments, Interchangeable lens can be with Front camera 104 1
Rise and use.Front camera 104 can have variable mechanical shutter and machinery and/or electronic shutter.Front camera 104 can also match somebody with somebody
Be set to capture still image, video image or the two.In addition, Front camera 104 can represent monoscopic, solid or more visual field phases
Machine.Rearmounted camera 112 can be arranged similarly or differently.In addition, Front camera 104, rearmounted camera 112 or the two can be one
The array of individual or multiple cameras.
Any one or two in Front camera 104 and rearmounted camera 112 can include light fixture or and light fixture
Association, the light fixture provide light field to be illuminated to destination object.For example, light fixture can provide the flash of light of destination object
Illumination or constant illumination.Light fixture, which is also configured as offer, to be included structure light, polarised light and has special spectrum content
The light field of one or more of light.In the context of the embodiments herein, it is known that and for recovering three-dimensional from object
The other kinds of light field of (3D) model is possible.
Any one or two in Front camera 104 and rearmounted camera 112 can include ambient light sensor or and environment
Optical sensor associates, and the ambient light sensor can determine that the environment for the scene that camera can capture is bright continuously or at intervals
Degree.In some equipment, the display that ambient light sensor can be used for the screen (for example, view finder) that adjustment associates with camera is bright
Degree.When it is determined that ambient brightness it is high when, the gray scale of screen can be increased to make it easier to watch screen.When it is determined that ring
When border brightness is low, the gray scale of screen can be reduced, also to make it easier to watch screen and so that screen potentially saves
Electric power saving.In addition, the input of ambient light sensor is determined for the TET of associated camera, or this determination of auxiliary.
Digital camera devices 100 are configurable to use multicomponent display 106 and Front camera 104 or rearmounted camera
Any one in 112 captures the image of destination object.Captured image can be multiple still image or video flowing.Can be with
By activating shutter release button 108, pressing soft key on multicomponent display 106 or caught by some other mechanism to trigger image
Obtain.Depending on implementation, can with specified time interval automatically capture images, such as when pressing shutter release button 108,
During the suitable lighting condition of destination object, in mobile 100 preset distance of digital camera devices or according to predetermined capture time
Arrange.
As indicated above, the function of digital camera devices 100 (or another type of digital camera) is desirably integrated into
In computing device (wireless computer device, cell phone, tablet PC, laptop computer etc.).For the mesh of example
, Fig. 2 be show can include photomoduel 224 Example Computing Device 200 component in the simplified block diagram of some.
It is not limited by way of example, computing device 200 can be cellular mobile telephone (for example, intelligence electricity
Words), it is still camera, video camera, facsimile machine, computer (such as, desktop computer, notebook, flat board or handheld computer), individual
Personal digital assistant (PDA), home automation components, digital video recorder (DVR), DTV, remote control, wearable computing
Equipment or equipped with least some image captures and/or some other type of equipment of image-capable.It should manage
Solution, computing device 200 can represent the physics camera apparatus of such as digital camera, thereon, camera applications are operated with software
Specific physical hardware platform or be configured to perform camera function hardware and software other combination.
As shown in Fig. 2 computing device 200 can include communication interface 202, user interface (user interface) 204,
Processor 206, data storage device 208 and photomoduel 224, it is all these to pass through system bus, network or other companies
The system of picking communicatedly links together.
Communication interface 202 can allow computing device 200 using analog or digital modulation and other equipment, access network
And/or transport network communication.Therefore, communication interface 202 can promote circuit switching and/or packet switching communication, such as simply
Plain old telephone service (POTS) communicates and/or Internet protocol (IP) or other packetized communications.For example, communication interface 202 can
With including arranging the chipset and antenna that are used for radio access network or access point radio communication.In addition, communication interface 202
The form of Wireline interface (wireline interface) can be taken or including wired line interface, such as Ethernet,
USB (USB) or high-definition media interface (HDMI) port.Communication interface 202 can also take the shape of wave point
Formula or including wave point, such as Wifi,Global positioning system (GPS) or wide area wireless interface (example
Such as, WiMAX or 3GPP Long Term Evolutions (LTE)).However, it is possible to the physical layer interface of other forms is used in communication interface 202
With other kinds of standard or private communication protocol.In addition, communication interface 202 can include multiple physical communication interfaces (for example,
Wifi interfaces,Interface and wide area wireless interface).
User interface 204 can play function to allow computing device 200 and the mankind or non-human user mutual, such as with
Input is received from user and provides a user output.Therefore, user interface 204 can include input module, such as keypad, key
Disk, touch-sensitive or pressure-sensitive panel, computer mouse, trace ball, control-rod, microphone etc..User interface 204 can also include one
Or multiple output precisions, such as display screen, the panel (presence-sensitive that display screen for example can be sensitive with existing
Panel) combine.Display screen can be based on CRT, LCD and/or LED technology, or other technologies that are currently known or developing afterwards.
User interface 204 is also configured as via loudspeaker, loudspeaker socket, audio output port, audio output apparatus, earphone
And/or other similar devices produce (one or more) audible output.
In certain embodiments, user interface 204 can include serving as the still camera for being supported by computing device 200
And/or the display of the view finder of video camera function.In addition, user interface 204 can include the configuration for promoting camera function
With one or more buttons, switch, knob and/or the driver plate of focusing and the capture of image (for example, capture photo).Can also
Some or all of these buttons, switch, knob and/or driver plate are realized by way of it sensitive panel be present.
Processor 206 can include one or more general processors (for example, microprocessor) and/or one or more specially
With processor, for example, digital signal processor (DSP), graphics processing unit (GPU), floating point unit (FPU), network processing unit or
Application specific integrated circuit (ASIC).In some instances, among other possibilities, application specific processor can image procossing,
Image alignment and merging image.Data storage device 208 can include one or more volatibility and/or non-volatile memories group
Part, such as magnetic, light, quick flashing or organic memory device, and can be integrated with processor 206 in whole or in part.Data storage fills
Removable and/or non-removable component can be included by putting 208.
The programmed instruction 218 that processor 206 can be able to carry out being stored in data storage device 208 is (for example, compiled
Or not compiled programmed logic and/or machine code) to perform various functions described herein.Therefore, data storage device
208 can include non-transitory computer-readable medium, be stored thereon with programmed instruction, during 200 execute program instructions of computing device
So that computing device 200 performs any one in method disclosed in this specification and/or accompanying drawing, process or operation.Processor
The execution of 206 pairs of programmed instruction 218 can cause processor 206 to use data 212.
By way of example, programmed instruction 218 can include (the example of operating system 222 being arranged on computing device 200
Such as, operating system nucleus, (one or more) device driver and/or other modules) and one or more application programs 220
(for example, camera function, address book, Email, web page browsing (web browsing), social networking and/or game application).
Similarly, data 212 can include operating system data 216 and application data 214.Operating system data 216 can mainly by
Operating system 222 can access, and application data 214 mainly can access by one or more of application program 220.Using
Data 214 can be arranged in file system, and this document system is visible to the user of computing device 200 or to computing device
200 user hides.
Application program 220 can be communicated by one or more API (API) with operating system 222.These
API can promote such as application program 220 to read and/or write application data 214, transmit or receive via communication interface 202
Information, receive information and/or display information etc. on user interface 204.
In some jargons, application program 220 can referred to as " app ".In addition, application program 220 be able to can pass through
One or more application on site shops or application market can download to computing device 200.However, it is also possible to otherwise should
It is arranged on program on computing device 200, such as, via web browser (web browser) or by computing device 200
Physical interface (for example, USB port).
Photomoduel 224 can include but is not limited to：Aperture, shutter, recording surface are (for example, photographic film and/or image
Sensor), lens and/or shutter release button.Photomoduel 224 can be controlled by the software that processor 206 performs at least in part.
2nd, example color model
This part describes that the mode of color can be represented on the computer screen or in image file from the general extent.
The information can have in the situation of the image processing techniques described in lower part.
The image of capture can be digitally represented using many color model.For example, RGB (RGB) color model can
For image is included on electronic output device (such as, computer screen).RGB is additive color color model (additive
Color model), wherein feux rouges, green glow and blue light are added together to produce color spectrum in a variety of ways.For example, it can lead to
Cross combination green and blueness forms cyan, yellow can be formed by combining red and green, can be red and blue by combining
Color forms magenta, and can form white by combining red, green and blueness.
The specific pixel of RGB image can be expressed as three plane tuples (R, G, B), and each of which plane can change to from 0
Predefined maximum (for example, 255).If all planes are 0, result can be black.If all planes are in maximum,
Then result can be most bright denotable white.(planes of color described herein is alternatively referred to as Color Channel.)
Another color model is YCbCr.In some implementations, the color model may be used as the substitution tables of image
Show.Particularly, Y plane can represent the brightness of pixel, and Cb planes and Cr planes can represent blue yellow chromaticity and red respectively
Greenness.For example, blue yellow can be represented by the green pixel values in the blue pixel value divided by RGB image in RGB image
Degree, and red green degree can be represented by the green pixel values in the red pixel value divided by RGB image in RGB image.This
Sample, YCbCr color model have the relation that is clearly limited with RGB, and can relatively easily be transformed into the RGB and from this
RGB is changed.
3rd, example white balance
White balance is the adjustment that the software of digital camera devices or association can be carried out to the image of capture, to try hard to ensure
White colours in image correctly reflect image from the actual white colours in its captured real-world scene.In order to manage
White balance is solved, the concept for first understanding that colour temperature is useful.
The ratio of the amount of amount and red light of the colour temperature based on blue light in image or scene measures the quality of light.Colour temperature with
The unit of Kelvin (K) degree is expressed.Image or scene ratio with higher color temperature (that is, larger Kelvin's value) have relatively low
The image or scene of colour temperature (that is, less Kelvin's value) have more bluenesss.So, the light of " colder " has higher color
Temperature, and relatively warm light has relatively low colour temperature.
Human eye and brain adapt to different colour temperatures.For example, either under strong daylight or in incandescent lighting
White object is watched in room, people can regard white object as white.Digital camera devices generally have built-in biography
Sensor measures the colour temperature of scene, and the image of the scene of capture can be handled using algorithm, to cause final result to connect
Person of modern times can perceive the mode of scene.This white colours adjustment similar to the white colours in scene caused in image is referred to as
White balance.Current white balance algorithm may be not accurate enough with the white for the scene for causing the white point of each image and its to represent
Point is similar.(white point of image represents to limit the chromatic value of " white " in image).
The embodiments herein provides the white of the high quality that can be operated together with the imaging sensor hardware of broad range
Balancing technique.These technologies with software in real time or near real-time operated.This can be eliminated to will be to various image sensings
Device provides the needs of the white balance algorithm of hardware specific.
In order to realize this purpose, the embodiments herein considers the outward appearance of the image of " output " white balance, and disobeys
(herein, " input " image is to be caught before application white balance algorithm by imaging sensor to the outward appearance of Lai Yu " input " image
The image obtained).This means for example, if camera produces the image of the cyan as one man coloured, and another camera produces one
The image of the purple of ground coloring is caused, then this paper white balance algorithm can produce the output image of identical white balance (it is assumed that two
Individual image all has similar radiation detection characteristic --- have corrected that black level (black level), image are linear
Etc.).If this means trained on the image captured by the hardware of a manufacturer (for example, by a kind of or multiple machines
Device learning art) this paper white balance algorithm, then for by another manufacturer hardware capture image its will be still effective.
Consider that the characteristic of the image of " output " white balance also simplify training.It is, in general, that realize new camera sensor
White balance algorithm be related to big data set with the sensor collection image, and manually explain every in these images
The light colors (illuminant color) of one, the countermeasure that this is slow and cost is high.But use described herein
Method, white balance algorithm can be trained based on publicly obtainable image, to cause white balance algorithm to reproduce these images
White balance.
This paper white balance algorithm not only produces high quality results, its at present also by the 20%-40% of error reduce and
Better than the prior art in academic documents.However, the technology in current state of the art is not designed to blanket different image
Sensor.
In addition, this paper white balance algorithm is designed as (idempotent) of idempotent, it is meant that it is once applied to
Image, it will carry out white balance to image, and if it is applied to the image of white balance again, then it does not enter to advance to image
The appreciable change of one step.This characteristic also mean if the color of input picture by some in photography pipeline, other are white flat
Method change is accounted, algorithm will not fail.
For formal Construct question, ideally light measurement linear image is considered, wherein black level correction has been carried out
And without pixel value saturation (for example, the intensity of color is less than some threshold value in each Color Channel of pixel, such as
255).It can be represented below for convenient with log space.
As indicated above, RBG pixels [Ir, Ig, Ib] can be " true " or white balance color [Wr, Wg, Wb] and
Illuminator [the L of scener, Lg, Lb] product.Correspondingly：
Ir=WrLr (1)
Ig=WgLg (2)
Ib=WbLb (3)
However, equation (1), (2) and (3) is the over-simplification to problem because they have ignored shade (shading),
The illumination etc. of reflectivity Characteristics, spatial variations.In any case, I is given, it is therefore an objective to estimate L and by means of this, produce W=I/
L.Therefore, I and W chrominance representation can be limited：
Iu=log (Ig/Ir) (4)
Iv=log (Ig/Ib) (5)
Wu=log (Wg/Wr) (6)
Wv=log (Wg/Wb) (7)
In addition, easily limit the expression of I and W brightness (luminance)：
Iy=min (Ir, Ig, Ib) (8)
Wy=min (Wr, Wg, Wb) (9)
If confidence level --- any one in r, g or b value of pixel in the expression instruction u and v of brightness estimation
Close to zero, then at least one colourity estimation is likely to be noise or mistake.Due to need not clearly be examined in embodiment here
Consider W absolute temperature scale (absolute scaling), so further it is simplified to estimate L colourity the problem of estimation illuminator L,
It can be only meant as two amounts：
Lu=log (Lg/Lr) (10)
Lv=log (Lg/Lb) (11)
By the characteristic of logarithm, the formulation (formulation) of equation (1), (2) and (3) can be empty in logarithm-colourity
Between in be rewritten as：
Wu=Iu-Lu (12)
Wv=Iv-Lv (13)
As a result, the white balance of correction chart picture is simplified to determine two amounts：LuAnd Lv.Due to absolute temperature scale ambiguity
(absolute scale ambiguity), so (Lu, Lv) indefinite to the inverse mapping in UV spaces from rgb space.Therefore, really
It is fixed：LuAnd Lv, it is possible to it is assumed that L is to allow (Lr, Lg, Lb) recovery unit norm (unit-norm)：
This logarithm-colourity formulation is more easily handled than RGB formulation.It is unknown in the presence of 2 unknown numbers rather than 3
Number, and the linear restriction relevant with W and I rather than multiplication constraint be present.
In order to determine these values (L with true (ground truth) the illumination L of benchmarku, Lv) and finally determine input picture
I (Lr, Lg, Lb), two-dimensional chromaticity histogram N can be constructed.In the histogram, N (u, v) indicate I in its colourity close to (u,
V) quantity of pixel, wherein histogram counts are luminance weighted by wherein respective pixel.This weighting reflects corresponding colourity
Confidence level in value.Form Shangdi：
Wherein square brackets represent indicator function (indicator function), and ∈ is the group of histogram away from (bin-
width).(∈=0.025 and 256- packet histograms (256-bin histogram) in practice, can be used；However, can
Alternatively to use the histogram of ∈ other values and other quantity to be grouped.)
After histogram N is constructed, it can be normalized with constant-quality.Furthermore it is possible to ask for each packet
The square root of middle counting, this can improve the validity of the feature of histogram.As long as however, identical conversion is applied to whole
Histogram, any ad hoc (ad-hoc) normalization are all possible.
Fig. 3 includes three colored versions of identical image, and the corresponding colourity Nogata of each image in a line of top
Figure is in a line of bottom.Fig. 3 depicts describes these images using the brightness of different stage with black and white, not homochromy to present
Adjust.In the color version of image in figure 3, the image colorant during the left side one arranges is with green yellow (greenish
Yellow), the image in the row of centre one is by white balance, and the image colorant during the right one arranges is with red yellow.
Right-hand member is moved to from the left end of the x- axles of each chroma histogram to represent the blue-yellow tone of associated images from mass-tone
Blueness, which changes, arrives mass-tone yellow.Similarly, lower end is moved to from the upper end of the y- axles of each chroma histogram to represent associated diagram
The red-green tone of picture changes to mass-tone green from mass-tone is red.Generally speaking, each chroma histogram represents to draw in the x-y
On in each position have colourity decline pixel relative populations.Therefore, the point in the row chroma histogram of left side one is poly-
Cluster (cluster) instruction green and yellow tone, the neutral (white balance of the instruction that clusters of the point in a middle row chroma histogram
) tone, and cluster instruction red and the yellow tone of the point in the row chroma histogram of right side one.
The center to cluster each put represents the white point of the image of association, and the origin of chroma histogram is for people
White point.By the way that clustering for point is centered in around the origin of chroma histogram, neutralc tint can be obtained.
The chroma histogram of each image is that the translation version of other chroma histograms (is ignored and introduced by histogram manipulation
Sampling), and the shape of histogram does not change.So, make image colorant only by the translation in histogram space
(translation) chroma histogram of image is influenceed.This is the knot that u and v are defined to their modes herein
Fruit --- scaling RGB channel is equivalent to displacement (shift) logarithm-chrominance channel.Brightness does not influence on the translation.
Equivalent it is easier white balance between image colorant and histogram displacement.Especially, white balance algorithm can lead to
Cross the color for considering some or all of possible tones of image, scoring the image of each coloring and then highest scoring being provided
(or more precisely, its is inverse) is adjusted to be operated as the illumination of the estimation of input picture.For example, make and a middle row colourity
It is probably desirable that there is the tone of histogram association highest, which to score so that input picture is colored as neutrality by white balance algorithm,.
Merely, the countermeasure that this scoring looks that seemingly cost is high is carried out, because it is needed in be possible to tone
On exhaustive search, wherein some score function is applied into each tone.However, if score function is histogram packet
Linear combination, then the exhaustive search only actually is N and some wave filter F convolution, and exists and can efficiently carry out
Many modes of convolution algorithm.
So, high-level, white balance algorithm can perform following steps：(i) chroma histogram is constructed from input picture I
N, (ii) make the histogram and some wave filter F convolution, and (iii) use high scoring (for example, highest scoring) illuminationProduceMore formally：
Wherein * is convolution operator.
The program is related to learns some wave filter F to cause the convolution to produce accurately output from training data.In order to instruct
Practice wave filter, multinomial logistic regression (multinomial logistic regression) or knot can be will be similar to that
The model of structureization prediction is applied to convolution framework.Formally, this can be expressed as optimization problem：
Wherein：
In equation (21), F is the wave filter that its weight is learnt, { N(i)And { L(i)It is training set colourity Nogata respectively
Figure and the true illumination of benchmark, and (N(i)* F) (u, v) be position (u, v) place index N(i)With F convolution.For facility, P
(u, v) is flexible maximum (softmax) probability that (u, v) is each grouped in histogram, and it is as N(i) * F function.So,
P (u, v) represents the normalization exponential function of the convolution of each training histogram and wave filter.
By minimize F element square and carry out regularization filter weight, filter weight is by some hyper parameter
(hyper-parameter) λ is adjusted.
High-level, minimizing loss causes such F --- N(i)* F existsPlace is bigger than elsewhere,
Wherein C (u, v, u*, the v*) losses caused by misvaluing at illuminator as defined below：
And：
C is measured by (u, v) and (u*, v*) limit illumination between angle, can assess color constancy by losing measurement
Property algorithm.The visualization to C can be seen in Fig. 4.Especially, Fig. 4 is depicted to the illuminating color (u, v) as proposition
C (u, v, the u of function*, v*) visualization, wherein each draw shows the true illuminating color r (u of benchmark*, v*) different choice
(being circled).Due to carrying out measurement error with regard to the angle between RGB illumination vectors, so depending on benchmark truly illuminates, the error
The shape of function may look different.
During the training period, equation (21) can be solved with Broyden Fletcher Goldfarb Shanno (BFGS)
Technology (such as, limited memory BFGS (L-BFGS)) restrains.Especially, F can be initialised to all zero (regardless of loss letter
Several nonconvex properties is all feasible).This problem is similar with logistic regression, but wherein each (u, v) has by being associated with
The variable loss that limits of C, measure each possible (u, v) colourity on some benchmark true color (u*, v*) cost.Can
Becoming cost causes model to be similar to the process predicted as structuring.
Anyway, through learning distribution of the F reflection colors in the scene of white balance, and it is used as aforementioned colourity
The result of the shift invariant of histogram, and be evaluated together with F as convolution, tones of the F independently of training image.Inferring
Period, F can be used for finding the most possible illumination according to model, but model does not consider the possibility of the illumination actually
Property.In addition to the model of natural color used herein is learnt by discriminative training, Learning from Nature face is similarly to
The generation model (generative model) of the distribution of color.
The dependence for the variable that discrimination model is typically observed to unobservable variable pair is modeled.In contrast to this,
Generation model is the full-probability model of all variables.So, generation model for example can be used for any variable in generation model
Value, and the variable that discrimination model allows pair to have observed that carries out the sampling of conditional unobservable variable.
Advantageously, using the ability of the discriminative training and still only model of Learning from Nature image of model herein, rather than
Study is exclusively used in the model of certain camera or imaging sensor.
A. example filtration efficiency improves
Chroma histogram and wave filter convolution should be used anything to plant by previously described algorithm without definitely specifying
The wave filter of class.Rational selection is to use " complete " wave filter --- size and the histogram identical wave filter filtered.
But the assessment cost of such wave filter completely some high (even using Fast Fourier Transform (FFT) (FFT) optimization convolution
When), and have and make it possible to the very big free parameter of the regularization quantity difficult with training.
The wave filter to do very well in embodiment described above tends to log-polar or " retina topology
(retinotopic) " structure, its median filter change near filter center comprising substantial amounts of high frequency, and away from center
Include low frequency variations.Intuitively, this is reasonable --- when the illuminating color of localzed image, model should be paid close attention to
Colourity change near white point, and only loosely consider that the colourity away from white point changes.
Using the observation, it can use and be based on pyramidal filtering.Pyramid filters the Gauss by constructing input signal
Pyramid (for example, using 3 layers from N (u, v) of bilinearity down-sampling, 5 layers or 7 layers), then with small wave filter (for example, 3
× 3,5 × 5 or 7 × 7 wave filters) each yardstick of filtering, and then filtered pyramid is collapsed (collapse
Down) into image (for example, being up-sampled using bilinearity) come work.The process as by N (u, v) and class retina topology filter
Ripple device convolution typically produces identical or almost identical (ignoring the necessary approximation as caused by down-sampling and up-sampling) output, but
It is more efficiently.In addition to effectively, this wave filter has seldom free parameter, therefore optimization and regularization are easy, and
And it can describe fine detail in center and coarse in deep shape smooth while.Regularization can be with
Carried out by minimizing square 2 norms (squared 2-norm) of filter coefficient at each yardstick, all passed through
Single hyper parameter λ is modulated, as in equation (20).The visualization to pyramid filtering can be seen in Figure 5.
Especially, Fig. 5 top a line depict by histogram with center with strong details and elsewhere with
The wave filter of coarse details carries out convolution.Bottom a line is depicted by alternatively constructing pyramid, with small filtering from histogram
Each yardstick of device Filter Pyramid and filtered histogram is then set to collapse more efficiently to assess same filter.It is logical
Cross and use later approach, reduce filtering speed.
Pyramid filtering is considered computing computer visual signature, and (for example each opening position is in shape in image
Hereafter or geometric unsharpness density), and then classified each feature with linear classifier.However, this paper pyramid is approximate false
The sample pattern for determining feature is rectangle rather than polar, feature yardstick is discretized power for 2 and in each chi
The sample pattern of feature is overlapping at degree.Also by wave filter be applied to pyramidal each yardstick with approximate image spatial function this
Kind technology is also similar to that convolution pyramid.
B. example is summarized
Previously described algorithm can be by filtering the histogram N constructed from the chromatic value of the pixel in image I come from figure
As I estimation illumination L.In fact, the model is a kind of elaborate " grey-world " algorithm, reason is that it tries to normalize
The color of each pixel, but ignore spatial information.However, in order to obtain better performance, color constancy algorithm can make
With extra information source, the color or spatial neighborhood at such as edge.
Therefore, algorithm disclosed herein can be extended.Replacement constructs and the single histogram N that classifies from single image I, can be with
Filtering comes from one group of " enhancing " image { I 'jOne group of histogram { Nj}.Can be to filter before flexible maximum probability is calculated
The response summation of ripple.The image response diagram of these enhancings is as I edge and spatial statisticses, so that model can be in single picture
The source of multiple chrominance informations is also combined outside plain color degree.
Image { the I ' of these enhancings can be constructed by the way that in general image processing operations simply are applied into Ij, it is all
Such as using wave filter group (filter bank), median filter, morphological operation.But construct chroma histogram from it
Scaling colours should be mapped to the passage of input picture by image, to be shifted in chroma histogram space.This means enhancing
Image should retain the characteristic, and every passage scaling is mapped to the identical displacement in histogram space.In that way it is possible to deposit
In the finite aggregate of the possible enhancing image for using.
It can be seen that in order to meet scaling colours/histogram shift characteristics, mapping should retain scalar multiplication --- input
The scaling of passage and then the version of filtering should be equal to the filtering of the passage and then the version of scaling in image I.In addition, mapping
Output should be non-negative, because the logarithm of these values may be asked for.Mapping is as follows as three kinds：
F (I, filt)=max (0, I*filt) (25)
G (I, ρ, w)=blur (Iρ, w)1/ρ (26)
H (I, ρ, w)=(blur (Iρ, w) and-blur (I, w)ρ)1/ρ (27)
Wherein blur (, w) is width w box filter (boxfilter).Usually, the boxlike filtering of image will
Linear filter is applied to input picture, is equal to its phase in input picture to cause each pixel in filtered image to have
The value of the average value of adjacent pixel.For example, the box filters of 3x 3 can be applied to each pixel of input picture with fuzzy, sharp
Change, detect edge and other influences are performed to input picture.
Function f (, filt) is by each passage of image and some wave filter filt convolution, and then filtered value
Clamp down at least 0.Function g () calculates the local norm (local norm) of pixel value in I make it that g (, 1, w) is fuzzy.
Function f (, ∞, w) and it is " maximum " wave filter, and f (,-∞, w) and it is " minimum value " wave filter.Function h () calculates picture
The normalized moments of element value, wherein g (, 2, w) calculate the local standard deviation of pixel value --- a kind of non-directional edge/texture inspection
Survey device.
It can prove that all three operations retain scalar multiplication：
F (α I, filt)=α f (I, filt) (28)
G (α I, ρ, w)=α g (I, ρ, w) (29)
H (α I, ρ, w)=α h (I, ρ, w) (30)
In extended model, four passages have been used：Input picture I is in itself, with " sharpening " filter filtering and correct
Image, big support " maximum filter " matroid and small support local standard deviation matrix：
I′1=I (31)
I′3=blur (I4, 11)1/4 (33)
Fig. 6 depicts the information visuallization to each capture in these passages.During the training period, this four golden words
Tower wave filter is learnt, each one pyramid filter of passage.To single filter before flexible maximum probability is calculated
Response summation.Therefore, can be with although algorithm disclosed herein can input using only input picture I pixel value as it
Set by using " enhancing " image improves performance as input.The model of extension uses the image of four enhancings, its
Local edge and Neighborhood Statistics are also captured in addition to input picture.
4th, exemplary operations
Fig. 7 is the flow chart of illustrative example embodiment.The embodiment of Fig. 7 signals can be by computing device.However, can
To perform the embodiment by other kinds of equipment or equipment subsystem.In addition, the embodiment can with the specification or
Any aspect or combinations of features disclosed in accompanying drawing.
Fig. 7 frame 700 can be related to acquisition input picture.Input picture can have by limiting the white in input picture
The white point that the chromatic value of color represents.Computing device capture input picture can be related to by obtaining input picture.
Frame 702 can be related to：The color for being possibly based on input picture produces the two-dimensional chromaticity histogram of input picture.
In some embodiments, producing two-dimensional chromaticity histogram can be related to：Use the ratio of the pixel value of each dimension of histogram
Logarithm, normalization two-dimensional chromaticity histogram are with square with constant-quality and each packet for asking for two-dimensional chromaticity histogram
Root.
Frame 704, which can be related to, makes two-dimensional chromaticity histogram with wave filter convolution to create two-dimentional thermal map.In two-dimentional thermal map
Entry (entry) can represent how each tone corresponding with each entry is estimated close to each of white point of input picture
Meter.
Frame 706 can be related to the bar of the particular value in the threshold value for selecting maximum of the expression in thermal map in two-dimentional thermal map
Mesh.Threshold value can be in certain percentage (for example, 5%, 10%, 20% etc.) of maximum, or can be in the fixation of maximum
In skew.So, particular value can be maximum or the value close to maximum.
Frame 708 can be related to：The entry of selection is possibly based on, input picture coloring is formed output image.It is somebody's turn to do
Color can be related to is applied to image by wave filter, wherein by the entry parameter wave filter selected.As possible result, output
Image can be than input picture more white balance.
In certain embodiments, the packet (u, v) in two-dimensional chromaticity histogram represents the color in input picture with (u, v)
The quantity of the pixel for the chromatic value spent in threshold value.In these embodiments, u can represent the first business (quotient) logarithm,
And v can represent the logarithm of the second business.First business can be red pixel value divided by input picture Green picture in input picture
Element value.Second business can be blue pixel value divided by input picture Green pixel value in input picture.In addition, two-dimensional chromaticity is straight
The packet of square figure can pass through the luminance weighted of pixel therein.
In certain embodiments, filtering can be trained based on one group of training chroma histogram of corresponding training image
Device, it is each to train chroma histogram to be associated with the corresponding known illumination of corresponding training image.As such, each instruction can be used
Practice the normalization exponential function of the convolution of histogram and wave filter to train wave filter.Alternatively or additionally, after training, filter
Ripple device can represent the distribution of the color in the scene of white balance, and can be independently of the tone of training image.
The color of input picture is possibly based on, the two-dimensional chromaticity that multiple enhancings are produced from the enhancing version of input picture is straight
Fang Tu.Each in the enhancing version of input picture can retain scalar multiplication characteristic when being filtered.Two-dimensional chromaticity is straight
Side's figure can be related to wave filter convolution：To the two-dimensional chromaticity histograms of multiple enhancings before application normalizes exponential function
The response summation of filtering.
5th, conclusion
Unrestricted in terms of the specific embodiment that the disclosure describes in this application, specific embodiment is used as to various aspects
Signal.The skilled person will be apparent that many modifications and variations can be carried out without departing from the disclosure
Scope.According to description above, in addition to the method and apparatus enumerated herein, those skilled in the art will become apparent to
It is the functionally equivalent method and apparatus in scope of disclosure.Such modifications and variations are intended to fall in appended claims
In the range of.
Specific descriptions above have been described with reference to the drawings the various features and function of disclosed system, apparatus and method.This
Text description and example embodiment in the accompanying drawings are not intended to limit.In the case where not departing from the scope of theme presented herein
Other embodiment can be utilized, and other changes can be carried out.It will readily appreciate that, can be with diversified different configurations
Being arranged to the various aspects of the disclosure for being usually described herein and illustrating in the accompanying drawings, replacing, organizing splitting or integrating
From and design, it is all these to be all clearly susceptible to herein.
Any or all in the message flow diagram, scene and the flow chart that are discussed herein is neutralized on accompanying drawing, each step,
Frame and/or communication can represent the processing according to the information of example embodiment and/or the transmission of information.Alternate embodiment is included
In the range of these example embodiments.In these alternate embodiments, for example, be described as step, frame, transmission, communication, please
Ask, respond and/or the function of message can be performed with order different from order show or discussion, including substantially simultaneously
Or in reverse order, this depends on involved function.In addition, more or less frames and/or function can be with begging for herein
Ladder diagram, the scene of opinion are used together with any one in flow chart, and these ladder diagrams, scene and flow chart can parts
Ground is fully combined with each other.
The step of representing processing to information or frame can be with that can be configured to perform method described herein or technology
The circuit of specific logical function is corresponding.Alternatively or additionally, the step of representing the processing to information or frame can be with program generations
Module, section or the part of code (including related data) correspond to.Program code can include one or more instructions, and processor can
One or more instructions are performed with the specific logical function in implementation method or technology or action.Program code and/or dependency number
According to that can be stored in any kind of computer-readable medium, (such as, including disk, hard disk drive or other storage mediums are deposited
Store up equipment) on.
Computer-readable medium can also include non-transitory computer-readable medium, and such as data storage continues short time period
Computer-readable medium, such as register memory, processor cache and random access memory (RAM).Computer
Computer-readable recording medium can also include the non-transitory computer-readable medium of store program codes and/or data last longer section.
So, computer-readable medium can include auxiliary or lasting long-term storage apparatus, such as, for example, read-only storage
(ROM), light or disk, close-coupled disk read-only storage (CD-ROM).Computer-readable medium can also be that any other is volatile
Property or Nonvolatile memory system.Computer-readable medium can be regarded as to such as computer-readable recording medium or tangible deposited
Storage device equipment.
In addition, the step of representing one or more information transfers or frame can be with softwares in same physical device and/or hard
Information transfer between part module is corresponding.However, other information transmission can the software module in different physical equipments and/
Or between hardware module.
The specific arrangements shown in accompanying drawing should not be taken as being limitation.Should be appreciated that other embodiment can include or
The each element shown in more or few given accompanying drawings.Furthermore it is possible to combine or omit some in the element illustrated.It is another again
Outside, example embodiment can include the element do not illustrated in the accompanying drawings.
In addition, any of element, frame or step is enumerated for purposes of clarity in this specification or claims.Cause
This, such enumerate should not be read as requiring or implying that these elements, frame or step depend on specific arrangements or with specific
Order performs.
Although having been disclosed for various aspects and embodiment herein, other aspects and embodiment are to people in the art
Member will be evident.Various aspects disclosed herein and embodiment for illustrative purposes and are not intended to limit, by what is enclosed
Claim indicates real scope.
Claims (20)
1. a kind of method, including：
Input picture is obtained by computing device, wherein input picture has the chromatic value by limiting the white colours in input picture
The white point of expression；
The two-dimensional chromaticity histogram of input picture is produced by color of the computing device based on input picture；
By computing device by two-dimensional chromaticity histogram and wave filter convolution to create two-dimentional thermal map, wherein the entry in two-dimentional thermal map
Represent to respective entries corresponding to corresponding tone how close to input picture white point corresponding estimation；
The entry of the particular value in the threshold value of maximum of the expression in thermal map in two-dimentional thermal map is selected by computing device；And
Entry based on selection, input picture coloring is set to form output image by computing device.
2. according to the method for claim 1, wherein producing two-dimensional chromaticity histogram includes：
For histogram each dimension using pixel value ratio logarithm；
Two-dimensional chromaticity histogram is normalized with constant-quality；And
Ask for the square root of each packet of two-dimensional chromaticity histogram.
3. according to the method for claim 1, wherein the entry based on selection makes input picture coloring include answering in wave filter
Image is used, wherein by the entry parameter wave filter selected.
4. according to the method for claim 1, the packet (u, v) wherein in two-dimensional chromaticity histogram represents have in input picture
There is the quantity of the pixel of the chromatic value in the Chroma threshold of (u, v), wherein u represents the logarithm of the first business, and wherein v represents the
The logarithm of two business, wherein the first business is red pixel value divided by input picture Green pixel value in input picture, and wherein
Second business is blue pixel value divided by input picture Green pixel value in input picture.
5. according to the method for claim 1, the packet of wherein two-dimensional chromaticity histogram is added by the brightness of pixel therein
Power.
6. according to the method for claim 1, wherein obtaining input picture includes computing device capture input picture.
7. according to the method for claim 1, wherein output image is than input picture more white balance.
8. according to the method for claim 1, wherein one group of training chroma histogram based on corresponding training image is instructed
Practice wave filter, it is each to train chroma histogram to be associated with the corresponding known illumination of corresponding training image.
9. according to the method for claim 8, wherein the normalization using each training histogram and the convolution of wave filter refers to
Function is counted to train wave filter.
10. the method according to claim 11, in addition to：
Color based on input picture, the two-dimensional chromaticity histogram of multiple enhancings is produced from the enhancing version of input picture, wherein
The enhancing version of each input picture retains scalar multiplication characteristic when being filtered,
Wherein two-dimensional chromaticity histogram and wave filter convolution are included：To multiple enhancings before application normalizes exponential function
The response summation of the filtering of two-dimensional chromaticity histogram.
11. according to the method for claim 8, wherein, after training, wave filter represents the color in the scene of white balance
Distribution, and independently of the tone of training image.
12. a kind of product, it includes non-transitory computer-readable medium, and its instruction that has program stored therein above, the programmed instruction exists
By causing computing device to include following operation during computing device：
Input picture is obtained, wherein input picture has the white represented by limiting the chromatic value of the white colours in input picture
Point；
Color based on input picture produces the two-dimensional chromaticity histogram of input picture；
By two-dimensional chromaticity histogram and wave filter convolution to create two-dimentional thermal map, wherein entry representation in two-dimentional thermal map with it is corresponding
Corresponding tone corresponding to entry how close to input picture white point corresponding estimation；
Select the entry of the particular value in the threshold value of maximum of the expression in two-dimentional thermal map in thermal map；And
Entry based on selection, input picture coloring is set to form output image.
13. product according to claim 12, wherein producing two-dimensional chromaticity histogram includes：
For histogram each dimension using pixel value ratio logarithm；
Two-dimensional chromaticity histogram is normalized with constant-quality；And
Ask for the square root of each packet of two-dimensional chromaticity histogram.
14. product according to claim 12, wherein the entry based on selection makes input picture coloring include wave filter
Image is applied to, wherein by the entry parameter wave filter selected.
15. the packet (u, v) in product according to claim 12, wherein two-dimensional chromaticity histogram is represented in input picture
The quantity of the pixel of chromatic value in Chroma threshold with (u, v), wherein u represent the logarithm of the first business, and wherein v is represented
The logarithm of second business, wherein the first business is red pixel value divided by input picture Green pixel value in input picture, and its
In the second business be blue pixel value divided by input picture Green pixel value in input picture.
16. the brightness that the packet of product according to claim 12, wherein two-dimensional chromaticity histogram passes through pixel therein
Weighting.
17. product according to claim 12, wherein one based on corresponding training image group of training chroma histogram come
Wave filter is trained, it is each to train chroma histogram to be associated with the corresponding known illumination of corresponding training image.
18. product according to claim 17, wherein the normalization using each training histogram and the convolution of wave filter
Exponential function trains wave filter.
19. product according to claim 18, the operation also includes：
Color based on input picture, the two-dimensional chromaticity histogram of multiple enhancings is produced from the enhancing version of input picture, wherein
The enhancing version of each input picture retains scalar multiplication characteristic when being filtered,
Wherein two-dimensional chromaticity histogram and wave filter convolution are included：To multiple enhancings before application normalizes exponential function
The response summation of the filtering of two-dimensional chromaticity histogram.
20. product according to claim 17, wherein, after training, wave filter represents the face in the scene of white balance
The distribution of color, and independently of the tone of training image.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/689,246 US9336582B1 (en) | 2015-04-17 | 2015-04-17 | Convolutional color correction |
US14/689,246 | 2015-04-17 | ||
PCT/US2016/027031 WO2016168145A1 (en) | 2015-04-17 | 2016-04-12 | Convolutional color correction |
Publications (2)
Publication Number | Publication Date |
---|---|
CN107431790A true CN107431790A (en) | 2017-12-01 |
CN107431790B CN107431790B (en) | 2019-04-02 |
Family
ID=55860033
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680013957.7A Active CN107431790B (en) | 2015-04-17 | 2016-04-12 | Method and non-transitory computer-readable medium for image procossing |
Country Status (6)
Country | Link |
---|---|
US (2) | US9336582B1 (en) |
EP (1) | EP3284060B1 (en) |
JP (1) | JP6724045B2 (en) |
KR (1) | KR101873183B1 (en) |
CN (1) | CN107431790B (en) |
WO (1) | WO2016168145A1 (en) |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108537852A (en) * | 2018-04-17 | 2018-09-14 | 四川大学 | A kind of adaptive color shape constancy method based on Image Warping |
CN111062876A (en) * | 2018-10-17 | 2020-04-24 | 北京地平线机器人技术研发有限公司 | Method and device for correcting model training and image correction and electronic equipment |
CN111448050A (en) * | 2017-12-13 | 2020-07-24 | 惠普发展公司，有限责任合伙企业 | Thermal behavior prediction from continuous tone maps |
CN112204957A (en) * | 2019-09-20 | 2021-01-08 | 深圳市大疆创新科技有限公司 | White balance processing method and device, movable platform and camera |
Families Citing this family (24)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9794540B2 (en) * | 2015-04-17 | 2017-10-17 | Google Inc. | Hardware-based convolutional color correction in digital images |
US9336582B1 (en) * | 2015-04-17 | 2016-05-10 | Google Inc. | Convolutional color correction |
CA2995857C (en) | 2015-11-05 | 2019-02-12 | Google Llc | Edge-aware bilateral image processing |
EP3226203A1 (en) * | 2016-03-30 | 2017-10-04 | Thomson Licensing | Method for detection of saturated pixels in an image |
CN106412547B (en) * | 2016-08-29 | 2019-01-22 | 厦门美图之家科技有限公司 | A kind of image white balance method based on convolutional neural networks, device and calculate equipment |
US10402943B2 (en) | 2016-10-20 | 2019-09-03 | Htc Corporation | Image enhancement device and method for convolutional network apparatus |
CN109983508B (en) * | 2016-11-15 | 2023-07-25 | 谷歌有限责任公司 | Fast fourier color constancy |
US10224004B2 (en) | 2017-02-06 | 2019-03-05 | Mediatek, Inc. | Automatic white balance based on surface reflection decomposition |
WO2018195462A1 (en) * | 2017-04-20 | 2018-10-25 | Hrl Laboratories, Llc | Machine-vision system for discriminant localization of objects |
US10692245B2 (en) * | 2017-07-11 | 2020-06-23 | Datacolor Inc. | Color identification in images |
CN107578390B (en) * | 2017-09-14 | 2020-08-07 | 长沙全度影像科技有限公司 | Method and device for correcting image white balance by using neural network |
CN112272832A (en) | 2018-05-28 | 2021-01-26 | 三星电子株式会社 | Method and system for DNN-based imaging |
RU2709661C1 (en) | 2018-09-19 | 2019-12-19 | Общество с ограниченной ответственностью "Аби Продакшн" | Training neural networks for image processing using synthetic photorealistic containing image signs |
US10931853B2 (en) * | 2018-10-18 | 2021-02-23 | Sony Corporation | Enhanced color reproduction for upscaling |
WO2020098953A1 (en) * | 2018-11-16 | 2020-05-22 | Huawei Technologies Co., Ltd. | Meta-learning for camera adaptive color constancy |
RU2721187C1 (en) | 2019-03-29 | 2020-05-18 | Общество с ограниченной ответственностью "Аби Продакшн" | Teaching language models using text corpuses containing realistic errors of optical character recognition (ocr) |
CN111935892B (en) * | 2019-05-13 | 2022-11-22 | 中科智云科技有限公司 | Method and apparatus for measuring plasma state |
CN110349261B (en) * | 2019-07-15 | 2023-05-09 | 泰华智慧产业集团股份有限公司 | Method for generating three-dimensional thermodynamic diagram based on GIS |
CN112399162B (en) * | 2019-08-16 | 2022-09-16 | 浙江宇视科技有限公司 | White balance correction method, device, equipment and storage medium |
EP3928503B1 (en) | 2019-11-13 | 2024-04-17 | Huawei Technologies Co., Ltd. | Multi-hypothesis classification for color constancy |
CN111968049B (en) * | 2020-08-06 | 2022-11-11 | 中国科学院光电技术研究所 | Light field image hot pixel point removing method based on side window guide filtering |
CN112070791A (en) * | 2020-09-21 | 2020-12-11 | 深圳喜为智慧科技有限公司 | Method and system for improving accuracy and efficiency of animal husbandry individual points |
EP4283558A1 (en) * | 2021-01-22 | 2023-11-29 | Logic and Design Co., Ltd. | Image processing method |
US11606544B2 (en) * | 2021-06-08 | 2023-03-14 | Black Sesame Technologies Inc. | Neural network based auto-white-balancing |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1335581A (en) * | 2000-07-12 | 2002-02-13 | 佳能株式会社 | Image processing apparatus, image processing method and program, and its recording medium |
US20030194125A1 (en) * | 2002-04-10 | 2003-10-16 | Hubel Paul M. | White point estimation using color by convolution |
CN1465175A (en) * | 2001-06-28 | 2003-12-31 | 精工爱普生株式会社 | Image processing device, image processing method, program, and recording medium |
CN1713690A (en) * | 2004-06-15 | 2005-12-28 | 微软公司 | System and method for automated correction of digital images |
CN1941843A (en) * | 2005-09-30 | 2007-04-04 | 三洋电机株式会社 | Image processing apparatus and an image processing program |
CN101706964A (en) * | 2009-08-27 | 2010-05-12 | 北京交通大学 | Color constancy calculating method and system based on derivative structure of image |
CN104469134A (en) * | 2013-09-17 | 2015-03-25 | 奥林巴斯株式会社 | Imaging Device, Electronic Viewfinder, And Display Control Method |
Family Cites Families (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5729691A (en) | 1995-09-29 | 1998-03-17 | Intel Corporation | Two-stage transform for video signals |
US6043909A (en) * | 1996-02-26 | 2000-03-28 | Imagicolor Corporation | System for distributing and controlling color reproduction at multiple sites |
US6075905A (en) | 1996-07-17 | 2000-06-13 | Sarnoff Corporation | Method and apparatus for mosaic image construction |
US6411953B1 (en) * | 1999-01-25 | 2002-06-25 | Lucent Technologies Inc. | Retrieval and matching of color patterns based on a predetermined vocabulary and grammar |
US7113649B2 (en) * | 2002-06-24 | 2006-09-26 | Eastman Kodak Company | Enhancing the tonal characteristics of digital images |
US8155454B2 (en) | 2006-07-20 | 2012-04-10 | Qualcomm Incorporated | Method and apparatus for encoder assisted post-processing |
US8253752B2 (en) | 2006-07-20 | 2012-08-28 | Qualcomm Incorporated | Method and apparatus for encoder assisted pre-processing |
KR100841429B1 (en) * | 2006-11-30 | 2008-06-25 | 삼성전기주식회사 | Apparatus to automatically controlling white balance and method thereof |
US8179402B2 (en) * | 2007-10-31 | 2012-05-15 | Canon Kabushiki Kaisha | Generating colorimetric profiles from spectral data and user input |
US8149459B2 (en) * | 2009-02-24 | 2012-04-03 | Xerox Corporation | Mapping an out-of-gamut color to a surface of a color gamut |
JP5319415B2 (en) | 2009-06-22 | 2013-10-16 | キヤノン株式会社 | Image processing apparatus and image processing method |
US8797414B2 (en) | 2010-12-23 | 2014-08-05 | Samsung Electronics Co., Ltd. | Digital image stabilization device |
US9007484B2 (en) * | 2011-10-12 | 2015-04-14 | Apple Inc. | Alleviating dominant color failure in automatic white balance using histogram trimming |
US8780225B2 (en) * | 2011-10-12 | 2014-07-15 | Apple Inc. | Use of noise-optimized selection criteria to calculate scene white points |
US9336582B1 (en) * | 2015-04-17 | 2016-05-10 | Google Inc. | Convolutional color correction |
-
2015
- 2015-04-17 US US14/689,246 patent/US9336582B1/en active Active
-
2016
- 2016-04-12 EP EP16721546.6A patent/EP3284060B1/en active Active
- 2016-04-12 KR KR1020177033078A patent/KR101873183B1/en active IP Right Grant
- 2016-04-12 CN CN201680013957.7A patent/CN107431790B/en active Active
- 2016-04-12 JP JP2017564324A patent/JP6724045B2/en active Active
- 2016-04-12 US US15/096,770 patent/US9672604B2/en active Active
- 2016-04-12 WO PCT/US2016/027031 patent/WO2016168145A1/en active Application Filing
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1335581A (en) * | 2000-07-12 | 2002-02-13 | 佳能株式会社 | Image processing apparatus, image processing method and program, and its recording medium |
CN1465175A (en) * | 2001-06-28 | 2003-12-31 | 精工爱普生株式会社 | Image processing device, image processing method, program, and recording medium |
US20030194125A1 (en) * | 2002-04-10 | 2003-10-16 | Hubel Paul M. | White point estimation using color by convolution |
CN1713690A (en) * | 2004-06-15 | 2005-12-28 | 微软公司 | System and method for automated correction of digital images |
CN1941843A (en) * | 2005-09-30 | 2007-04-04 | 三洋电机株式会社 | Image processing apparatus and an image processing program |
CN101706964A (en) * | 2009-08-27 | 2010-05-12 | 北京交通大学 | Color constancy calculating method and system based on derivative structure of image |
CN104469134A (en) * | 2013-09-17 | 2015-03-25 | 奥林巴斯株式会社 | Imaging Device, Electronic Viewfinder, And Display Control Method |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111448050A (en) * | 2017-12-13 | 2020-07-24 | 惠普发展公司，有限责任合伙企业 | Thermal behavior prediction from continuous tone maps |
CN111448050B (en) * | 2017-12-13 | 2022-10-11 | 惠普发展公司，有限责任合伙企业 | Thermal behavior prediction from continuous tone maps |
US11669057B2 (en) | 2017-12-13 | 2023-06-06 | Hewlett-Packard Development Company, L.P. | Neural network thermal behavior predictions |
CN108537852A (en) * | 2018-04-17 | 2018-09-14 | 四川大学 | A kind of adaptive color shape constancy method based on Image Warping |
CN111062876A (en) * | 2018-10-17 | 2020-04-24 | 北京地平线机器人技术研发有限公司 | Method and device for correcting model training and image correction and electronic equipment |
CN111062876B (en) * | 2018-10-17 | 2023-08-08 | 北京地平线机器人技术研发有限公司 | Method and device for correcting model training and image correction and electronic equipment |
CN112204957A (en) * | 2019-09-20 | 2021-01-08 | 深圳市大疆创新科技有限公司 | White balance processing method and device, movable platform and camera |
Also Published As
Publication number | Publication date |
---|---|
WO2016168145A1 (en) | 2016-10-20 |
US9672604B2 (en) | 2017-06-06 |
KR20170131704A (en) | 2017-11-29 |
KR101873183B1 (en) | 2018-06-29 |
JP6724045B2 (en) | 2020-07-15 |
US20160350900A1 (en) | 2016-12-01 |
US9336582B1 (en) | 2016-05-10 |
EP3284060B1 (en) | 2019-06-12 |
CN107431790B (en) | 2019-04-02 |
EP3284060A1 (en) | 2018-02-21 |
JP2018515862A (en) | 2018-06-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107431790B (en) | Method and non-transitory computer-readable medium for image procossing | |
US10237527B2 (en) | Convolutional color correction in digital images | |
EP3542347B1 (en) | Fast fourier color constancy | |
CN105578063B (en) | A kind of image processing method and terminal | |
CN108140130A (en) | The bilateral image procossing that edge perceives | |
CN109844804B (en) | Image detection method, device and terminal | |
TWI420405B (en) | System and method for replacement of face images in a portable electronic device | |
CN108322646A (en) | Image processing method, device, storage medium and electronic equipment | |
CN110505411A (en) | Image capturing method, device, storage medium and electronic equipment | |
CN108537155A (en) | Image processing method, device, electronic equipment and computer readable storage medium | |
CN105245863A (en) | Image processing device that performs white balance control, method of controlling the same, and image pickup apparatus | |
CN108024105A (en) | Image color adjusting method, device, electronic equipment and storage medium | |
CN107707789A (en) | Monochromatic color mapping is carried out using monochromatic imager and color mapped sensors | |
Zhang et al. | Improved and robust spectral reflectance estimation | |
CN107920205A (en) | Image processing method, device, storage medium and electronic equipment | |
Kınlı et al. | Modeling the lighting in scenes as style for auto white-balance correction | |
Han et al. | A large-scale image database for benchmarking mobile camera quality and NR-IQA algorithms | |
CN109300186A (en) | Image processing method and device, storage medium, electronic equipment | |
CN106878606A (en) | A kind of image generating method and electronic equipment based on electronic equipment | |
CN110909696B (en) | Scene detection method and device, storage medium and terminal equipment | |
Kim et al. | The infrared lighting system for the efficient photography of the pretreated fingerprint | |
CN116668838B (en) | Image processing method and electronic equipment | |
KR101155992B1 (en) | Detection method of invisible mark on card using mobile phone |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |