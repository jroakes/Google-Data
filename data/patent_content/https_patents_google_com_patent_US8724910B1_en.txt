BACKGROUND
1. Field
This invention relates to selection of images from digital image corpora.
2. Background Art
With the growth of images of persons and various other entities that are available on-line, a user is faced with numerous choices to select an image to represent an entity of interest. For example, the images of almost any celebrity available online through the World Wide Web (WWW) or through other network accessible digital data storage locations are numerous. Applications that require the use of an image of a celebrity can pick an image from among the numerous images available online. The different images of the same celebrity can, for example, represent different expressions, different poses, or other differences. One or more images of the celebrity can be selected manually, by accessing a predetermined image repository, or by randomly selecting an image of the celebrity.
Similar to images of persons, different images that are frequently associated with the same corporate entity or product can also exist in network accessible repositories. These logos and symbols can represent an entity in various view points, angles, and the like. One or more of these images can be chosen to represent the corporate entity o product.
Considering that various images of the same entity are available, known methods can frequently lead to choosing a less than ideal image to represent an image. Therefore, what are needed are methods and systems for improved selection of representative images.
BRIEF SUMMARY
Methods and systems for selecting a representative image of an entity are disclosed. According to one embodiment, a computer-implemented method for selecting a representative image of an entity is disclosed. The method includes: accessing a collection of images of the entity; clustering, based on similarity of one or more similarity features, images of the entity from the collection to form a plurality of similarity clusters; and selecting the representative image from one of said similarity clusters. In another embodiment, popular clusters are determined based on cluster size of said similarity clusters, and the representative image is selected from the popular clusters. In yet another method embodiment, the method further includes assigning a headshot score based upon a portion of the respective image covered by the entity to respective images in said popular clusters, and further selecting the representative image based upon the headshot score.
A system embodiment for finding a representative image of an entity includes a processor, a memory coupled to the processor, a collection of images of the entity, a clusterer, and a representative image selector. The clusterer is configured to cluster images from the collection to form a plurality of similarity clusters based on similarity of one or more features. The representative image selector is configured to select a representative image from the similarity clusters. In another system embodiment, the clusterer is further configured to determine popular clusters based on cluster size of said similarity clusters, and the representative image selector is configured to select the representative image from the popular clusters. According to another system embodiment, the system can also include assigning a headshot score based upon a portion of the respective image covered by the entity to respective images in said popular clusters, and further selecting the representative image based upon the headshot score.
Another embodiment is a computer program product for enabling a processor to select a representative image of an entity. The computer program product comprises first, second, third, and fourth logic modules. The first logic module is configured to access a collection of images of the entity. The second logic module is configured to cluster images from the collection to form a plurality of similarity clusters based on similarity of one or more similarity features, and the third logic module is configured to select the representative image from one of said similarity clusters.
A further embodiment is a client for communicating with a server that selects a representative image of an entity. The server clusters images of the entity from a collection of images to form a plurality of similarity clusters based on similarity of one or more similarity features, and selects the representative image from one of the similarity clusters. The client includes an interface configured to send an identifier associated with the entity to the server, and an interface configured to receive the representative image of the entity from the server.
Yet another embodiment is a method for selecting a representative image of an entity including clustering, based on similarity of one or more similarity features, images of the entity from a collection of images to form a plurality of similarity clusters, and selecting the representative image from one of the similarity cluster. The method includes sending an identifier associated with the entity to the server, and receiving the representative image from the server.
Further features and advantages of the present invention, as well as the structure and operation of various embodiments thereof, are described in detail below with reference to the accompanying drawings. It is noted that the invention is not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to persons skilled in the relevant art(s) based on the teachings contained herein.
BRIEF DESCRIPTION OF THE DRAWINGS/FIGURES
Reference will be made to the embodiments of the invention, examples of which may be illustrated in the accompanying figures. These figures are intended to be illustrative, not limiting. Although the invention is generally described in the context of these embodiments, it should be understood that it is not intended to limit the scope of the invention to these particular embodiments.
FIG. 1 illustrates a system for automatically selecting a representative image of a person, according to an embodiment.
FIG. 2 illustrates a clustering module of a system for automatically selecting a representative image of a person, according to an embodiment.
FIG. 3 illustrates a method for automatically selecting a representative image of a person, according to an embodiment.
FIGS. 4-9 illustrate the method of FIG. 3 in further detail, according to embodiments.
FIGS. 10( a)-10(j) illustrate clusters of images of a celebrity, formed according to an embodiment of the present invention.
DETAILED DESCRIPTION
While the present invention is described herein with reference to illustrative embodiments for particular applications, it should be understood that the invention is not limited thereto. Those skilled in the art with access to the teachings herein will recognize additional modifications, applications, and embodiments within the scope thereof and additional fields in which the invention would be of significant utility.
Overview
Embodiments of the present invention can be used in various applications to select a representative image of an entity. Applications, such as the display of search results to a user, can benefit from having graphical identifiers associated with certain textual content. In the display of search results, for example, the reference to each textual result associated with a person can also be represented with an image of that person. A headshot image of the person can be placed next to the link so that, for example, a quick glance at the results enables the user to distinguish the relevant entries. In another application, an on-line method to maintain a database of images of a person can be enhanced by automating the continual selection of an image that is best representative of the person. In yet another application, for each of a selected list of persons, the most popular image for that person can be selected and continually updated. In still another application, the reference to each textual result associated with a news article, product description etc., can be represented with the logo of the relevant corporation and/or product. Using embodiments of the present invention, a single image or a plurality of images that are most representative of an entity can be returned.
A representative image can be, but is not limited to, that of a person, a corporate logo, or other symbol associated with a person or corporation. According to an embodiment of the present invention, a representative image is selected based on a set of similarity features. For example, a representative image of a person can be selected based on similarity features, such as, but not limited to, facial features, clothing, sunglasses, hair, and backdrop. The representative image can be selected based on the most popular images as defined by the similarity features. The selected representative image of a celebrity, for example, can show the celebrity in a popular pose or in a pose similar to the most popular pose. The measure of popularity of an image can be based, for example, on the frequency of appearance of that image, or images similar to that image as defined by chosen similarity features, in digital image corpora accessible over a network such as the Internet. In addition to popularity, criteria such as quality, size, and the coverage area of the image, can be considered in selecting the representative image.
Images of the same person can enjoy different levels of popularity based on various factors, such as, pose, expression, quality of image, and the ease of obtaining the image. The popularity of the image, according to one or more embodiments of the present invention, can be estimated based on techniques such as the number of unique users who have uploaded that image to a network such as the Internet. Other criteria of popularity, with or without considering the number of unique users that upload the image, are possible and are within the scope of the present invention. In an environment such as the Internet, the present invention leverages the large amount of online content and the large number of online users to determine the most popular image, symbol and/or logo. In addition, the present invention can take advantage of frequent additions of new image of persons and other entities that are added by users in environments such as the Internet. For example, embodiments of the present invention can monitor the Internet for such additions and incorporate the newly added images into its selection process.
Example environments in which embodiments of the present invention can be used include search applications such as Google Search, entity identification applications such as Google Goggles, online-photo sharing environments such as Google Picasa and Google Talk, video sharing environments such as Youtube, and any other application in which a representative image of the person can be usefully associated with returned results. The selected representative image can be used as a quick indication to the user of an associated person or other entity. For example, in Google Goggles, embodiments of the present invention can be used to display an iconic image of a celebrity to the user when that celebrity is recognized. Embodiments of the present invention may be used to select a representative image either in real-time or non real-time. Embodiments of the present invention may also be used in various devices such as server computers, client computers, smartphones, personal digital assistants, photographic cameras, web cameras, video cameras, and other devices in which display of search results or display of entity recognition results can be desirable.
Representative Image Selection System
FIG. 1 illustrates a system 100 for automatically selecting a representative image of an entity according to an embodiment of the present invention. System 100 includes at least one computer 101 and an image database 102. System 100 can also include a communication network 103, one or more image sources 104 coupled to network 103, a display 105, one or more input devices 106, and a first interconnection infrastructure 107.
Computer 101 can comprise one or more a standalone computer, computers in a server, a server farm, a cloud computing server, or computer network. Computer 101 can, in some embodiments, be incorporated in various devices such as smartphones, personal digital assistants, photographic cameras, web cameras, video cameras, and other devices in which display of search results or display of entity recognition results can be desirable. Computer 101 includes a processor 111, a volatile memory 112, a persistent memory 113, an input/output interface 114, and a second interconnection infrastructure 115. Processor 111 can be any processing device, such as, including, a microprocessor, field programmable gate array (FPGA), or digital signal processor (DSP). Volatile memory 112 can include a random access memory (RAM) or like memory. Persistent memory 113 can include a persistent data storage medium such as a hard-disk or flash-memory storage device. Input/output interface 114 communicatively couples various input/output devices and/or computer networks to computer 101. For example, display 105, input devices 106, image database 102, and communication network 103 can be communicatively coupled to computer 101 through input/output interface 114. One or more connection devices, such as, for example, Ethernet or wireless networks, Peripheral Component Interconnect (PCI) interfaces, or Universal Serial Bus (USB) interfaces, can be used in coupling the input/output devices to computer 101. Computer 101 and/or applications implemented in computer 101 can, for example, be configured through input/output interface 114, for example, based on input received from input devices such as keyboard, mouse, or disk drives. Such configuration can include various configuration parameters that may be required to be set in various modules and devices, and the entering of commands and/or scripts to configure the various interfaces. Second interconnection infrastructure 115 interconnects modules internal to computer 101. Second interconnection infrastructure 115 can be based on any suitable interconnection mechanism, such as, PCI, USB, Ethernet, or WIFI.
Computer 101 can also include an automatic representative image selection module 120. Automatic representative image selection module 120 includes logic for selecting one or more representative images of an entity, according to an embodiment of the present invention. Automatic representative image selection module 120 includes an image clusterer 121, a headshot scorer 122, and a representative image selector 123. Image clusterer 121 includes logic to collect images and to cluster the images based on similarity features, according to an embodiment. Headshot scorer 122 includes logic to determine, for each image, a score based on the coverage area of a part of the image that includes desired features. Representative image selector 123 includes logic to select a representative image from the images processed by image clusterer 121 and headshot scorer 122.
Image database 102 can contain the images of entities that are collected from various sources, such as image sources 104. As used herein, the term “database” is not limited to a particular type or implementation of databases such as relational or non-relational databases, and may include any system that yields lookup functionality such as tables, linked lists, and hash implementations. Image database 102 can contain a collection of images structured according to some method or unstructured. Image database 102 can also include indexes to images, scripts, and logic to access the images in image database 102. In an embodiment, logic to access images in image database 102 can also reside in computer 101. Also, in some embodiments, image database 102 can be implemented internally to computer 101, for example, image database 102 can be stored in persistent memory 113. Computer 101 can also include logic (not shown) to access images in image database 102. Image database 102 can also store the results of processing by the representative image selector module 120. For example, cluster information and/or the clustered images output from image clusterer 121 can be stored in image database 102.
Communication network 103 can include one or more communication networks that interconnect computer 101 to sources of images. According to an embodiment, communication network 103 includes one or more of a local area network, wide area network, or the Internet 103 through which image sources 104 are accessible to computer 101. Image sources 104 can include various sources such as publicly-available web sites or databases, subscription access web sites or databases, or any other type of image repository. One or more of the sources may be updated with new images at various intervals. The image source may or may not have the images categorized according to the entity to which the image corresponds.
Display 105 can include any screen or display and/or other output device. Other output devices to which the output of computer 101 can be written to includes printer, and disk drives. Input devices 106 can include a keyboard, mouse, or other input device.
The various logic modules in computer 101, and in particular, representative image selection module 120 and image database 102, can be implemented in software, firmware, hardware, or a combination thereof. In one embodiment, representative image selection representative image selection module 120 is implemented in the C++ programming language. In one embodiment, a computer program product may have logic including the computer program logic of modules 120, recorded on a computer readable medium such as a hard disk, flash disk, or other form of storage. Representative image selection module 120, as well as other software components including input interface software, output interface software and database interface software, if any, execute on processor 111 and utilize volatile memory 112 for temporary storage of data and instructions. Persistent memory 113 may be used for additional temporary storage during the execution of representative image selection module 120.
In an embodiment, system 100 can also include one or more client device, such as client 130, that are communicatively coupled to computer 101 through a communication network 140. Client 130 can be, for example, a mobile phone, smart phone, a mobile computing device, or other computing device that utilizes the services provided by computer 101. Client 130 can include interfaces 131 and 132. Interface 131 includes the functionality to send an identifier associated with an entity to a server, such as computer 101, that provides the service of selecting and returning a representative image of that entity. The identifier can be a name, pseudonym, image or other means of identifying the entity. Interface 132 includes the functionality to receive a representative image of the entity from the server, for example, computer 101. According to an embodiment, the client transmits a request for a representative image of an entity and an identifier for that entity, to a server such as computer 101. The server, upon receiving the request from the client executes one or more methods or applications to select a representative image corresponding to the received identifier, and returns that representative image to the client. Client 130 receives the representative image, and in some embodiments, includes the functionality to display the representative image. Communication network 140 can be any wired or wireless communication network.
FIG. 2 illustrates a block diagram depicting the image clusterer 121, according to an embodiment. As noted above, image clusterer 121 forms one or more clusters of the images of the entity of interest. Image clusterer 121 can include a pivot image selector 201, a feature vector determiner 202, and a similarity comparator 203. Pivot image selector 201 selects a set of pivot images, where it is intended that a cluster will be created for each pivot image. According to an embodiment, each image is considered to be a pivot image. Feature vector determiner 202 generates a feature vector for each image. According to an embodiment, feature vector determiner 202 creates a vector comprising a plurality of predetermined features for each image to be considered. Similarity comparator 203 compares two images based on a set of similarity features. According to an embodiment, similarity comparator 203 determines a similarity score between two images based on the comparison of a plurality of features in the respective feature vectors.
Process for Selecting a Representative Image of an Entity
FIG. 3 is a process 300 for selecting a representative image of an entity, which may be implemented, for example, by representative image selection module 120. In step 301, images to be processed are collected. The collected images can be digital images of the entity of interest. The collected images can also include some images that may not be of the entity of interest. According to an embodiment, images of a known celebrity are collected. The collected images can also include images having other persons or other entities. It should be understood, however, that the process 300 can be executed to find a representative image of any person or other entity. As noted above, embodiments of the present invention can be used to find the representative image of a person, a corporate logo, or any other entity for which images are frequently associated with that entity.
Images can be collected from image sources that are, for example, accessible through a network such as the Internet. As noted above, the image sources can include any type of image repository. The images for processing by process 300 can be received or collected by any known means. For example, images can be obtained from a web-based image management service, such as Google Image Search or PICASA Web Albums. The obtained images can be searched and collected based on previously assigned tags or other previously determined categorizations such as separate folders and the like. When collecting images of a person, such images can also be collected by using face recognition or other image recognition techniques to identify images of the person of interest. For example, any known face recognition method can be used to identify images of a person of interest based on one or more images that are initially identified by the user. Process 400 described below is an example method of collecting images of an entity of interest, according to an embodiment. According to an embodiment of the present invention, collected images of an entity are stored in a database or other image repository such as image database 102.
In step 303 the collected images are clustered, according to an embodiment. The images are clustered based on similarity. According to an embodiment, an initial set of representative images of the entity of interest is selected, and the collection of images is clustered based on the similarity of images to respective images in the initial set of representative images. The clusters resulting from step 303 can be referred to as similarity clusters. Process 500, described below, illustrates clustering the collection of images according to an embodiment.
In step 305, the popular clusters among the set of clusters are determined according to an embodiment. The popular clusters can be determined according to several metrics. According to an embodiment, clusters having a greater number of images than a predetermined threshold are considered popular clusters. Process 600 illustrates a method of determining the popular clusters according to an embodiment of the present invention.
In step 306, it is determined whether the desired representative image is a headshot image. A headshot image is an image in which the area occupied by a desired portion of an entity of interest is optimized. For example, a headshot of a person is an image in which the area of the image that is occupied by the corresponding person's face is optimized. The choice of the type of representative image can be preconfigured. According to an embodiment, the headshot image may be required to be an 80×80 pixel square region. Optimizing the coverage of the entity within the required area enables more clarity in the image even when the image displayed is of small size. Calculation of the headshot score and selecting based on headshot score becomes particularly important when, for example, cropping of images are not allowed.
If no headshot is desired as the representative image, then processing proceeds to step 307. In step 307, the representative image is selected. According to an embodiment, the representative image can be any image in the largest cluster. For example, the largest cluster includes the most popular images as defiled by a set of similarity features. According to another embodiment, the representative image can be selected from any of the popular clusters.
If in step 306, it is determined that the representative image is desired to be a headshot, then processing proceeds to step 309. In step 309, a headshot score is assigned to each image that is clustered. A headshot score, according to an embodiment, is a score assigned based on the area of the image that is covered by a predetermined relevant part of the image. According to an embodiment in which a headshot of a person of interest is the desired representative image, then the headshot score can refer to the area of the image that is covered by the face of the person. For example, if a rectangular area around the face of the person occupies three quarters of the entire image, then the headshot score can be 0.75.
The headshot score of an image can, in addition, be based on other characteristics. According to an embodiment, the clarity of the relevant image characteristics can also be factored into the headshot score. For example, between two images with the same facial coverage area percentage, the image with the better image quality in the facial area can have a higher headshot score. Various characteristics, such as backgrounds, facial accessories, clothing, or other aspects of an image that affects the quality of the image can be factored into the headshot score. In an embodiment, facial images that are encumbered by facial accessories such as sunglasses or caps are assigned a lower headshot score than those without such encumbrances. Process 700, described below, illustrates the headshot score assignment according to an embodiment of the present invention.
In step 311 the representative image of the entity is selected. According to an embodiment, the representative image is selected as the one with the highest headshot score from among all the popular clusters. If more than one image in the popular clusters have the highest headshot score, the tie can be resolved by selecting the image with the highest score that is also from the largest popular cluster that includes images with the highest score.
In step 313, the selected representative image is displayed and/or output as appropriate. For example, the selected representative image can be returned to a calling logic so that the image can be inserted in association with returned search results on web page displayed within a web browser client.
In one embodiment, method 300 can be implemented in a web server to select representative images of persons or other entities that can be meaningfully associated with search results. As noted above, embodiments of the present invention can be used to select headshot images of persons. Embodiments can also be used to select images of other entities such as products, logos and the like. Such selected representative images of persons and other entities can be used to associate with search results, for example, by displaying them alongside the returned search results. Method 300 can be implemented real-time, for example, during the rendering of web-page containing the relevant search results. Method 300 can also be implemented in a non-real time manner to build a database of representative images for persons and/or other entities. In an embodiment, such a database of representative images can be periodically updated to incorporate available new images, for example, by periodically implementing method 300 on the set of images already considered and any newly found images.
In another embodiment, process 300 can be implemented on a client device, for example, in association with a web browser client to associate search results with appropriate images of persons or other entities. In yet another embodiment, process 300 can be implemented in both a web server and associated web client. For example, a web server can have a periodically updated database of selected representative images, and a web client can execute process 300, or parts thereof, to determine a representative image from among those returned by the server and other images that are accessible to the client.
FIG. 4 illustrates process 400 that can be used to collect images of the entity of interest. According to an embodiment, process 400 can be used in the processing for step 301. For example, process 400 can be used to access images of the person of interest from a collection of images based on a set of facial similarity metrics.
In step 401 a set of entity recognition metrics are determined for the entity of interest. For each entity of interest, a feature vector comprising similarity features can be created. For example, in order to obtain a representative image of a person of interest, a set of facial similarity metrics can be determined. Facial similarity metrics are various facial features that aid in the recognition of faces, such as, for example, face shape, shape of forehead, shape of nose, shape of eyes, shape of mouth, area between the eyes, spatial relationships between facial organs, skin-color, and like features. Techniques for determining vectors of facial similarity metrics for an image are known in the relevant arts. According to an embodiment, for each person of interest, a vector of facial features can be constructed based on a set of predetermined facial similarity metrics.
In step 403 images of the entity of interest are collected based on the corresponding feature vector determined in step 401. According to an embodiment, images of the person of interest can be determined based on a vector of facial features using a face recognition technique.
The recognition of faces in images typically involves a face detection stage and a face recognition stage. In the detection stage, faces are detected in the image under investigation. If a face is detected, the boundaries of the face are determined. One approach of face detection that can be used in embodiments of the present invention is described in Paul Viola and Michael Jones, Rapid Object Detection using Boosted Cascade of Simple Features, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001. The detection method described in Viola et al., detects faces in images using a relatively small set of features such as the area between the eyes, the bridge of a nose, etc. In one embodiment, the face detection capability of the OpenCV computer vision library software can be used. OpenCV is available at http://opencvlibrary.sourceforge.net/. The OpenCV software can be configured to use one of many methods, including the method of Viola et. al., supra, to detect faces. The detection module typically returns a region of interest containing the detected face.
In the recognition stage, the detected face in the region of interest can be compared to a set of previously identified images. For example, a feature vector corresponding to the detected face can be compared to feature vectors of known images of the person of interest. In one embodiment, a method of face recognition described in Mathew Turk and Alex Pentland, Eigenfaces for Recognition, J. of Cognitive Neuroscience, Volume 3 Number 1, pp. 71-86 (1991), can be used. In the method described by Turk et al., a set of training images, ideally spanning a wide range of facial and image characteristics, are analyzed to construct a subspace of eigenfaces—faces described as vectors of values for selected characteristics—to which objects suspected to be faces can be mapped. A determination as to whether the object is a recognizable face can be made based on the proximity of the mapping to the predetermined eigenfaces. Another exemplary technique that can be used in an embodiment is to create feature vectors comprising of gabor jets derived from local features of facial images such as that described in U.S. Pat. No. 6,301,370. In another embodiment, feature vectors constructed based on a method such as Turk et al., can also incorporate additional features such as possible image labels, tags, and/or other image related features.
Process 500 illustrates a method of clustering the collected images of the entity of interest. Any central (e.g., K-means) or pairwise (e.g., mean-shift) clustering method can be used to cluster the collected images. According to an embodiment, mean-shift clustering is used to generate the clusters from the collected images by specifying a minimum similarity level that is required for a cluster. In general, it is preferable to cluster collected images without first specifying a predetermined number of clusters.
In step 501, a set of pivot images are selected. The pivot images are images for which a cluster will be generated. According to an embodiment, each of the collected images of the entity of interest is considered a pivot image.
In step 503, a feature vector is generated for each pivot image. The set of similarity features in the feature vector used in the clustering process can be the same as or similar to the feature vector used in face recognition to collect images of the entity of interest. In some embodiments, the feature vector comprising facial similarity features can also include characteristics such as sunglasses or other facial accessories that the person of interest is often associated with.
In step 505, for each image to be considered in clustering, a feature vector is created. According to an embodiment, a feature vector comprising a predetermined set of facial similarity features is created for each image to be considered in the creation of the clusters.
In step 507, considering each pivot image in turn, all the collected images are compared to the pivot image and those found to be sufficiently similar are added to the corresponding cluster. According to an embodiment, for each cluster the feature vectors of the corresponding pivot image and respective collected images are compared and the images that match more than a predetermined minimum threshold of similarity features are considered a match.
Steps 501-507 generates a cluster for each pivot image. At the end of process 500, there exists a plurality of clusters created from the collected images. Each cluster can have a between 1 and the total number of collected images. Each image can belong to one or more of the clusters.
FIG. 6 illustrates process 600 to determine popular clusters. According to an embodiment, process 600 can be used to implement step 305 of process 300 described above. In step 601, the clusters are sorted in order of size. According to an embodiment, the highest ranked cluster is the largest cluster.
In step 603, duplicate images are removed from the clusters. According to an embodiment, starting from the largest cluster, it is determined whether each respective image of the cluster is also contained in any of the lower ranked clusters. Duplicate images are removed from all lower ranked clusters. When step 603 is completed for each of the clusters, each image appears only in the highest ranked cluster in which it originally appeared. In some embodiments, removal of duplicate images can result in the ordering of clusters according to size be affected. In such cases, the affected clusters can be re-ordered according to size.
In step 605, the set of popular clusters is selected based on the size of clusters. According to an embodiment, clusters that are larger than a minimum threshold size are considered as popular clusters. For example, clusters having 10 or more images can be considered popular clusters. If none of the clusters meet the minimum size threshold, then all clusters are considered popular clusters.
FIG. 7 illustrates a process 700 to determine the headshot score of an image. According to an embodiment, process 700 can be used to determine the headshot score in step 309 of process 300 as described above.
In step 701, for each clustered image, the portion of the image that is covered by the entity of interest is calculated. According to an embodiment, the portion of the image covered by the face of the person of interest is calculated. For example, the portion covered by a rectangular region containing the face of the person of interest as returned by a face detector can be determined.
In step 703, the headshot score for the image is determined. According to an embodiment, the headshot score can be determined as a percentage. Determining the headshot score as a normalized score such as a fraction or percentage of the image area enables the direct comparison of headshot scores of different images.
According to another embodiment, the headshot score can be adjusted according to various other characteristics specific to the images, such as, clarity of the facial image. For example, two images having the same portion of the respective images covered by facial features can have different headshot scores so that the image with the clearer facial image is assigned a higher headshot score. Such additional factors to be incorporated into the headshot can be configurable.
FIG. 8 illustrates a process 800 to determine the headshot score when a particular aspect ratio is required in the selected representative image. In step 801, a rectangular area containing a facial image is identified, and the padding required to obtain the required aspect ratio is determined.
In step 803, the horizontal and vertical margins of the image is determined.
According to an embodiment, the following computations are performed to determine the horizontal and vertical face margins:
horizontal face margin=padded image width−face width (1)
vertical face margin=padded image height−face height (2)
where face width and face height refer to the rectangular region containing the face.
In step 805, the headshot score is calculated as a percentage or normalized score.
According to an embodiment, the headshot score can be calculated as follows:
headshot score=1−((horizontal face margin/padded image width)+(vertical face margin/padded image height))/2 (3)
FIG. 9 illustrates a process 900 for selecting the representative image of the entity of interest. According to an embodiment, process 900 is used in performing step 311 of process 300 as described above.
In step 901, the set of images having the highest headshot score is determined. The set of images with the highest headshot score can include images from one or more clusters.
In step 903, the best image is selected from the set of images with the highest headshot score. According to an embodiment, the best image is selected as the image with the highest headshot score that is in the largest cluster having images with the highest headshot score.
FIGS. 10( a)-(j) illustrate clusters generated for “Albert Einstein” according to an embodiment of the present invention. A total of 66 clusters were generated, with the largest cluster having 131 images. FIGS. 10( a)-(b) illustrate the 131 images of cluster 1. FIGS. 10( c)-10(d) illustrate the 102 images of cluster 2. FIGS. 10( e) and 10(f) illustrate clusters 3 and 4, respectively. FIGS. 10( g)-(j) each illustrate images from more than one cluster. Based on a minimum cluster size of 10, seven clusters can be considered as popular clusters. The headshot score is shown below each image. In this example, an image (i.e., the top left image shown in FIG. 10( c)) from cluster 2 was selected as the representative image due to its highest headshot score of 0.88. Although another image in cluster 3 had the same high headshot score, the tie was broken in favor of the larger cluster.
Embodiments of the present invention, as described above, can be used to enhance the appearance of images, including the appearance of faces. The enhancements are based on the characteristics of one or more detected faces in the image. In one application of an embodiment of the present invention, faces can be tanned. In a further example, personalized profiles may be created for each user, so that if the detected face can be identified, the detected face can be transformed according to the target skintone model setup in the profile for the identified person.
Embodiments of the present invention may be practiced to enhance aspects other than the face. For example, once the starting face model and the target face model has been computed, the rest of the image can be processed to have certain effects in addition to any enhancements performed upon the face. In one example, the background may be made into grayscale while the face is maintained in color. In another example, the background may be made blurry while the face is maintained in focus.
As stated previously, embodiments of the present invention can be practiced in various environments. Digital video cameras, digital cameras, mobile devices including mobile phones with cameras are some devices in which embodiments of the present invention are implemented. Also, embodiments of the present invention may be practiced in photograph processing or video processing facilities including web services that perform such services.
The present invention has been described above with the aid of functional building blocks illustrating the implementation of specified functions and relationships thereof. The boundaries of these functional building blocks have been arbitrarily defined herein for the convenience of the description. Alternate boundaries can be defined so long as the specified functions and relationships thereof are appropriately performed.
The foregoing description of the specific embodiments will so fully reveal the general nature of the invention that others can, by applying knowledge within the skill of the art, readily modify and/or adapt for various applications such specific embodiments, without undue experimentation, without departing from the general concept of the present invention. Therefore, such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed embodiments, based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation, such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance.
The breadth and scope of the present invention should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents.