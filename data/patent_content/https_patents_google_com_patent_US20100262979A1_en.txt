US20100262979A1 - Circular command queues for communication between a host and a data storage device - Google Patents
Circular command queues for communication between a host and a data storage device Download PDFInfo
- Publication number
- US20100262979A1 US20100262979A1 US12/756,477 US75647710A US2010262979A1 US 20100262979 A1 US20100262979 A1 US 20100262979A1 US 75647710 A US75647710 A US 75647710A US 2010262979 A1 US2010262979 A1 US 2010262979A1
- Authority
- US
- United States
- Prior art keywords
- command
- host
- storage device
- data storage
- response
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/54—Interprogram communication
- G06F9/544—Buffers; Shared memory; Pipes
Definitions
- This description relates to data storage devices and, in particular, to circular command queues for communication between a host and a data storage device.
- Data storage devices may be used to store data.
- a data storage device may be used with a computing device to provide for the data storage needs of the computing device. In certain instances, it may be desirable to store large amounts of data on a data storage device. Also, it may be desirable to execute commands quickly to read data and to write data to the data storage device.
- a host device configured for storing data on, and retrieving data from, a flash memory data storage device, includes a driver that is arranged and configured to communicate commands to the data storage device, a circular command queue that is populated with commands for retrieval by the data storage device, and a circular response queue that is populated with responses by the data storage device for retrieval by the host device, wherein each response acknowledges the reception of a command from the host by the data storage device.
- the circular command queue can include a command head pointer and a command tail pointer
- the circular response queue can include a response head pointer and a response tail pointer
- the host device can further include a first register configured to store command head pointer values, and a second register configured to store response tail pointer values
- the data storage device can include a third register configured to store command tail pointer values, and a fourth register configured to store response head pointer values.
- the third register can exist in a memory mapped address space of the data storage device, and the driver can be configured to write updated command tail pointer values to the third register.
- the driver can be configured to send commands to the storage device in response to a direct memory access request from the data storage device, and the first register can be configured to receive updated command head pointer values in response to a direct memory access operation received from the data storage device.
- the second register can exist in the address space of the host device, and the second register can be configured to receive updated response tail pointer values from the data storage device into the second register.
- the driver can be configured to receive responses from the storage device through a direct memory access operation sent from the data storage device, and the driver can be configured to send updated response head pointer values to the data storage device via a write to a Memory Mapped register.
- the host device can further include an application that is configured to generate input and output requests, and an operating system that is operably coupled to the driver and to the application and that is configured to communicate the input and output requests between the application and the driver.
- a method for communicating commands between a host and a flash memory data storage device includes populating a circular command queue of a driver on the host with commands for retrieval by the data storage device, transferring commands from the circular command queue to the data storage device via a device initiated direct memory access operation, populating, via a direct memory access operation initiated by the data storage device, a circular response queue of the host with responses by the data storage device for retrieval by the host device, where each response acknowledges the reception of a command from the host by the data storage device, and consuming responses from the circular response queue at the host.
- the circular command queue can include a command head pointer and a command tail pointer
- the circular response queue can include a response head pointer and a response tail pointer
- the method can further include storing command head pointer values in a first register of the host, and storing response tail pointer values in a second register of the host.
- the data storage device can include a third register configured to store command tail pointer values, and a fourth register configured to store response head pointer values.
- the third register can exist in a memory mapped address space of the data storage device, and the method can further include writing updated command tail pointer values to the third register.
- Updated command head pointer values can be received into the first register in response to a direct memory access operation received from the data storage device.
- the second register can exist in the address space of the host device, and the method can further include receiving updated response tail pointer values into the second register from the data storage device.
- Responses from the storage device can be received through a direct memory access operation sent from the data storage device, and updated response head pointer values can be sent to the data storage device via a write to a Memory Mapped register.
- Input and output requests can be generated from an application running on the host, and the input and output requests can be communicated from an application running on the host through an operating system to the driver.
- FIG. 1A is an exemplary block diagram of a host and a data storage device.
- FIG. 1B is an exemplary block diagram of multiple queues on the host of FIG. 1A .
- FIG. 1C is an exemplary block diagram of circular queues used to communicate information between the host and the data storage device of FIG. 1A .
- FIG. 2 is an exemplary block diagram of an interrupt processor.
- FIG. 3 is an exemplary block diagram of a command processor for the data storage device.
- FIG. 4 is an exemplary block diagram of a pending command module.
- FIG. 5 is an exemplary perspective block diagram of the printed circuit boards of the data storage device.
- FIG. 6 is an exemplary block diagram of exemplary computing devices for use with the data storage device of FIG. 1A .
- FIG. 7 is an exemplary flowchart illustrating a process for communicating commands between a host and a data storage device.
- This document describes an apparatus, system(s) and techniques for using one or more pairs of queues at a host to communicate commands and responses between the host and a data storage device.
- Each pair of queues includes a command queue and a response queue.
- the pairs of queues enable the host to communicate with the data storage device using multiple threads or cores in an efficient manner.
- FIG. 1A a block diagram of a system for processing and tracking commands in a group is illustrated.
- FIG. 1A illustrates a block diagram of a data storage device 100 and a host 106 .
- the data storage device 100 may include a controller board 102 and one or more memory boards 104 a and 104 b .
- the data storage device 100 may communicate with the host 106 over an interface 108 .
- the interface 108 may be between the host 106 and the controller board 102 .
- the controller board 102 may include a controller 110 , a DRAM 111 , multiple channels 112 , a power module 114 , and a memory module 116 .
- the controller 110 may include a command processor 122 and an interrupt processor 124 , as well as other components, which are not shown.
- the memory boards 104 a and 104 b may include multiple flash memory chips 118 a and 118 b on each of the memory boards.
- the memory boards 104 a and 104 b also may include a memory device 120 a and 120 b , respectively.
- the host 106 may include a driver 107 , an operating system 109 and one or more applications 113 .
- the host 106 may generate commands to be executed on the data storage device 100 .
- the application 113 may be configured to generate commands for execution on the data storage device 100 .
- the application 113 may be operably coupled to the operating system 109 and/or to the driver 107 .
- the application 113 may generate the commands and communicate the commands to the operating system 109 .
- the operating system 109 may be operably coupled to the driver 107 , where the driver 107 may act as an interface between the host 106 and the data storage device 100 .
- the application 113 may communicate directly with the data storage device 100 , as discussed below with respect to FIG. 1B .
- the data storage device 100 may be configured to store data on the flash memory chips 118 a and 118 b .
- the host 106 may write data to and read data from the flash memory chips 118 a and 118 b , as well as cause other operations to be performed with respect to the flash memory chips 118 a and 118 b .
- the reading and writing of data between the host 106 and the flash memory chips 118 a and 118 b , as well as the other operations, may be processed through and controlled by the controller 110 on the controller board 102 .
- the controller 110 may receive commands from the host 106 and cause those commands to be executed using the command processor 122 and the flash memory chips 118 a and 118 b on the memory boards 104 a and 104 b .
- the communication between the host 106 and the controller 110 may be through the interface 108 .
- the controller 110 may communicate with the flash memory chips 118 a and 118 b using the channels 112 .
- the controller board 102 may include DRAM 111 .
- the DRAM 111 may be operably coupled to the controller 110 and may be used to store information.
- the DRAM 111 may be used to store logical address to physical address maps and bad block information.
- the DRAM 111 also may be configured to function as a buffer between the host 106 and the flash memory chips 118 a and 118 b.
- the controller board 102 and each of the memory boards 104 a and 104 b are physically separate printed circuit boards (PCBs).
- the memory board 104 a may be on one PCB that is operably connected to the controller board 102 PCB.
- the memory board 104 a may be physically and/or electrically connected to the controller board 102 .
- the memory board 104 b may be a separate PCB from the memory board 104 a and may be operably connected to the controller board 102 PCB.
- the memory board 104 b may be physically and/or electrically connected to the controller board 102 .
- the memory boards 104 a and 104 b each may be separately disconnected and removable from the controller board 102 .
- the memory board 104 a may be disconnected from the controller board 102 and replaced with another memory board (not shown), where the other memory board is operably connected to controller board 102 .
- either or both of the memory boards 104 a and 104 b may be swapped out with other memory boards such that the other memory boards may operate with the same controller board 102 and controller 110 .
- the controller board 102 and each of the memory boards 104 a and 104 b may be physically connected in a disk drive form factor.
- the disk drive form factor may include different sizes such as, for example, a 3.5′′ disk drive form factor and a 2.5′′ disk drive form factor.
- the controller board 102 and each of the memory boards 104 a and 104 b may be electrically connected using a high density ball grid array (BGA) connector.
- BGA high density ball grid array
- Other variants of BGA connectors may be used including, for example, a fine ball grid array (FBGA) connector, an ultra fine ball grid array (UBGA) connector and a micro ball grid array (MBGA) connector.
- FBGA fine ball grid array
- UGA ultra fine ball grid array
- MBGA micro ball grid array
- Other types of electrical connection means also may be used.
- the memory chips 118 a - 118 n may include flash memory chips. In another exemplary implementation, the memory chips 118 a - 118 n may include DRAM chips or combinations of flash memory chips and DRAM chips. The memory chips 118 a - 118 n may include other types of memory chips as well.
- the host 106 using the driver 107 and the data storage device 100 may communicate commands and responses using pairs of queues or buffers in host memory.
- buffer and queue are used interchangeably.
- a command buffer 119 may be used for commands and a response buffer 123 may be used for responses or results to the commands.
- the commands and results may be relatively small, fixed size blocks.
- the commands may be 32 bytes and the results or responses may be 8 bytes.
- other sized blocks may be used including variable size blocks.
- Tags may be used to match the results to the commands. In this manner, the data storage device 100 may complete commands out of order.
- FIG. 1A illustrates one command buffer 119 and one response buffer 123
- multiple pairs of buffers may be used, as illustrated in FIG. 1B and discussed in more detail below.
- the data storage device 100 may service the multiple command buffers 119 in a round robin fashion, where the data storage device 100 may retrieve a fixed number of commands at a time from each of the command buffers 119 .
- the response buffer 123 may include its own interrupt and interrupt parameters.
- each command may refer to one memory page (e.g., one flash page), one erase block or one memory chip depending on the command.
- Each command that transfers data may include one 4K direct memory access (DMA) buffer. Larger operations may be implemented by sending multiple commands.
- the driver 107 may be arranged and configured to group together a single operation of multiple commands such that the data storage device 100 processes the commands using the flash memory chips 118 a and 118 b and generates and sends a single interrupt back to the host 106 when the multiple grouped commands have been processed.
- the command buffer 119 can be configured as a circular queue 159 that is used to communicate information from the host 106 and to the data storage device 100 of FIG. 1A .
- the response buffer 123 also can be configured as a circular queue.
- Each of the circular queues 159 of the command buffer 119 and the response buffer 123 include a head pointer and a tail pointer. Values of the head pointer of the circular queue 159 of the command buffer 119 can be stored in a register 163 on the host, and values of the tail pointer can be stored in a register 161 on the data storage device 100 .
- Values of a tail pointer of a circular queue of the response buffer 123 can be stored in a register on the host, and values of the head pointer of the response buffer can be stored in a register on the data storage device 100 .
- Commands and responses may be inserted into the circular queue 159 at the tail pointer and removed at the head pointer.
- the host 106 may be the producer of the command buffer 119 and the consumer of the response buffer 123 .
- the data storage device 100 may be the consumer of the command buffer 119 and the producer of the response buffer 123 .
- the host 106 may write the command tail pointer and the response head pointer and may read the command head pointer and the response tail pointer.
- the data storage device 100 may write the command head pointer and the response tail pointer and may read the command tail pointer and the response head pointer.
- the controller 110 may perform the read and write actions.
- the command processor 122 may be configured to perform the read and write actions for the data storage device 100 . No other synchronization, other than the head and tail pointers, may be needed between the host 106 and the data storage device 100 .
- the command head pointer and the response tail pointer may be stored in register of the host 106 (e.g., in host RAM).
- the command tail pointer and the response head pointer may be stored in registers of the data storage device 100 in memory mapped I/O space within the controller 110 .
- the command buffer 119 and the response buffer 123 may be an arbitrary multiple of the command or response sizes, and the driver 107 and the data storage device 100 may be free to post and process commands and results as needed provided that they do not overrun the command buffer 119 and the response buffer 123 .
- the command buffer 119 and the response buffer 123 are circular queues, which enable flow control between the host 106 and the data storage device 100 .
- the host 106 may determine the size of the command buffer 119 and the response buffer 123 .
- the buffers may be larger than the number of commands that the data storage device 100 can queue internally.
- the host 106 may write a command to the command buffer 119 and update the command tail pointer, which can reside in memory mapped input/output (“MMIO”) space of the data storage device, to indicate to the data storage device 100 (and, in particular, to the command processor 122 within the data storage device 100 ) that a new command is present and ready for communication to the data storage device.
- the writing of the command tail pointer signals the command processor 122 that a new command is present.
- the command processor 122 is configured to read the command out of the command buffer 119 using a DMA operation and is configured to update the head pointer using another DMA operation to indicate to the host 106 that the command processor 122 has received the command.
- writing a command from the host 106 to the data storage device can include just one write operation to memory mapped input/output space (i.e., the updating of the tail pointer in the MMIO space of the data storage device by the host) and two DMA events (i.e., the command processor reading the command out of the command buffer and updating the head pointer of the circular queue 159 ).
- the command processor 122 When the command processor 122 completes the command, the command processor 122 writes a response to the host using a DMA operation and updates the response tail pointer with another DMA operation to indicate that the command is finished.
- the interrupt processor 124 is configured to signal the host 106 with an interrupt when new responses are available in the response buffer 123 .
- the host 106 is configured to read the responses from the response buffer 123 and update the head pointer in the MMIO space of the data storage device to indicate that the host has received the response.
- the interrupt processor 124 may not send another interrupt to the host 106 until the previous interrupt has been acknowledged by the host 106 writing to the response head pointer.
- receiving a response to the writing of a command can include just one write operation to memory mapped input/output space (i.e., the updating of the head pointer by the host) and two DMA events (i.e., the writing of the response by the command processor and the updating of the response tail pointer to indicate that the command is finished).
- a MMIO read event which can take a relatively long time compared to MMIO write events and DMA events, and in this manner the communication between the host and the device is accelerated.
- the host 106 may control when the interrupt processor 124 should generate interrupts.
- the host 106 may use one or more different interrupt mechanisms, including a combination of different interrupt mechanisms, to provide information to the interrupt processor 124 regarding interrupt processing.
- the host 106 through the driver 107 may configure the interrupt processor 124 to use a water mark interrupt mechanism, a timeout interrupt mechanism, a group interrupt mechanism, or a combination of these interrupt mechanisms.
- the host 106 may set a ResponseMark parameter, which determines the water mark, and may set the ResponseDelay parameter, which determines the timeout. The host 106 may communicate these parameters to the interrupt processor 124 . If the count of new responses in the response buffer 123 is equal to or greater than the ResponseMark, then an interrupt is generated by the interrupt processor 124 and the count is zeroed. If the time (e.g., time in microseconds) since the last interrupt is equal to or greater than the ResponseDelay and there are new responses in the response buffer 123 , then the interrupt processor 124 generates an interrupt and the timeout is zeroed. If the host 106 removes the new response from the response buffer 123 , the count of new responses is updated and the timeout is restarted. In this manner, the host 106 may poll ahead and avoid interrupts from the interrupt processor 124 .
- the interrupt processor 124 may poll ahead and avoid interrupts from the interrupt processor 124 .
- the host 106 may use a group interrupt mechanism to determine when the interrupt processor 124 should generate and send interrupts to the host 106 .
- the commands may share a common value, which identifies the commands as part of the same group.
- the driver 107 may group commands together and assign a same group number to the group of commands.
- the driver 107 may use an interrupt group field in the command header to assign a group number to the commands in a group.
- the interrupt processor 124 may generate and send the interrupt to the host 106 .
- the group interrupt mechanism may be used to reduce the time the host 106 needs to spend processing interrupts.
- Each of the interrupt mechanisms may be separately enabled or disabled. Also, any combination of interrupt mechanisms may be used.
- the driver 107 may set interrupt enable and disable flags in a QueueControl register to determine which of the interrupt mechanisms are enabled and which of the interrupt mechanisms are disabled. In this manner, the combination of the interrupts may be used to reduce the time that the host 106 needs to spend processing interrupts. The host 106 may use its resources to perform other tasks.
- all of the interrupt mechanisms may be disabled.
- the driver 107 may be configured to poll the response buffer 123 to determine if there are responses ready for processing. Having all of the interrupt mechanisms disabled may result in a lowest possible latency. It also may result in a high overhead for the driver 107 .
- the group interrupt mechanism may be enabled along with the timeout interrupt mechanism and/or the water mark interrupt mechanism. In this manner, if the number of commands in a designated group is larger than the response buffer 123 , one of the other enabled interrupt mechanisms will function to interrupt the driver 107 to clear the responses from the response buffer 123 to provide space for the command processor 122 to add more responses to the response buffer 123 .
- the use of the different interrupt mechanisms may be used to adjust the latency and/or the overhead with respect to the driver 107 .
- only the timeout interrupt mechanism may be enabled. In this situation, the overhead on the driver 107 may be reduced.
- only the water mark interrupt mechanism may be enabled. In this situation, the latency may be reduced to a lower level.
- a particular type of application being used may factor into the determination of which interrupt mechanisms are enabled.
- a web search application may be latency sensitive and the interrupt mechanisms may be enabled in particular combinations to provide the best latency sensitivity for the web search application.
- a web indexing application may not be as sensitive to latency as a web search application. Instead, processor performance may be a more important parameter.
- the interrupt mechanisms may be enabled in particular combinations to allow low overhead, even at the expense of increased latency.
- the driver 107 may determine a command group based on an input/output (I/O) operation received from an application 113 through the operating system 109 .
- the application 113 may request a read operation of multiple megabytes.
- the application 113 may not be able to use partial responses and the only useful information for the application 113 may be when the entire operation has been completed.
- the read operation may be broken up into many multiple commands.
- the driver 107 may be configured to recognize the read operation as a group of commands and to assign the commands in that group the same group number in each of the command headers.
- An interface between the application 113 and the driver 107 may be used to indicate to the driver 107 that certain operations are to be treated as a group.
- the interface may be configured to group operations based on different criteria including, but not limited to, the type of command, the size of the data request associated with the command, the type of data requested including requests from multiple different applications, the priority of the request, and combinations thereof.
- the application 113 may pass individual command information relating to an operation to the operating system 109 and ultimately to the driver 107 .
- the driver 107 may designate one or more commands to be considered a group.
- the host 106 may include the driver 107 , the operating system 109 and one or more applications 113 .
- the driver includes multiple pairs of buffers 219 a - 219 n and 223 a - 223 n .
- the multiple pairs of buffers include a command buffer 219 a - 219 n and a response buffer 223 a - 223 n in each pair.
- the pairs work together.
- the driver 107 may populate the command buffer 219 a with commands for retrieval by the data storage device 100 through the interface 108 .
- the data storage device 100 generates and communicates responses to those commands, where the responses populate the corresponding response buffer 223 a .
- the following pairs of buffers are illustrated: command buffer 219 a is paired with response buffer 223 a ; command buffer 219 b is paired with response buffer 223 b ; command buffer 219 c is paired with response buffer 223 c ; and command buffer 219 n is paired with response buffer 223 n.
- the driver 107 may be configured to enable multiple instances of the driver 107 to operate simultaneously. For instance, a separate instance of the driver 107 may be configured to operate with each of the pairs of buffers. In this manner, the driver 107 may use multiple different threads of commands to communicate with the data storage device. For example, one thread may be used to communicate commands and associated responses with the command buffer 219 a and the response buffer 223 a . Another thread may be used to communicate commands and associated response with the command buffer 219 b and the response buffer 223 b.
- the command buffers 219 a - 219 n and the response buffers 223 a - 223 n may be configured to operate and function as described above with respect to the command buffer 119 and the response buffer 123 of FIG. 1A .
- Each of the buffer pairs may include its own set of head and tail pointers. The use of the head and tail pointers may be the same as described above with respect to the command buffer 119 and the response buffer 123 of FIG. 1A .
- the multiple different head and tail pointers, each of which corresponds to a buffer pair, may be stored on the host 106 , the data storage device 100 or a combination of the host 106 and the data storage device 100 .
- Each of the response buffers 223 a - 223 n may have an associated interrupt handler 225 a - 225 n . In this manner, each response buffer 223 a - 223 n may process the interrupts received from the data storage device 100 on an individual basis. In some instances, an interrupt may be received by an interrupt handler 225 a - 225 n when a related group of commands has been processed by the data storage device, as discussed in more detail below with respect to FIG. 2 .
- Each of the buffer pairs may be granted access to any address mapping, which may be stored on the host 106 and/or on the data storage device 100 .
- each of the buffer pairs may be granted access to the logical to physical address mapping, which may be stored in DRAM 111 of FIG. 1A .
- any address mapping or tables such as, for example, the logical to physical address mapping may be shared such that each pair of buffers may have access to the mapping.
- each of the one or more applications 113 may use one of the command buffer 219 a - 219 n and response buffer 223 a - 223 n pairs to communicate with the data storage device 100 through the operating system 109 and an associated instance of the driver 107 .
- each of the applications 113 may include its own pair of buffers.
- the application 113 may include an application command buffer 229 and an application response buffer 233 .
- the application 113 may communicate directly with the data storage device 100 through the interface 108 .
- the application 113 may bypass those components and communicate directly with the data storage device 100 . In this manner, input and output requests generated by the application 113 may be processed by the data storage device 100 faster than if the requests were communicated to the data storage device 100 through the operating system 109 and the driver 107 .
- the application command buffer 229 and the application response buffer 233 may be configured to perform and function in the same manner as described above with respect to the command buffer 119 and the response buffer 123 of FIG. 1A , except that the application command buffer 229 and the application response buffer 233 are associated directly with the application 113 and not the driver 107 .
- the application 113 may communicate specific command types and input/output requests directly with the data storage device 100 using its own application command buffer 229 and application response buffer 233 .
- Other command types and input/output requests generated by the application 113 may be process through the operating system 109 and the driver 107 using one of the pairs of buffers associated with the driver 107 .
- the application 113 may be configured to communicate read requests directly to the data storage device 100 using the application command buffer 229 and the application response buffer 233 . In this manner, the overall processing time of read requests may be faster than read requests that are processed through the operating system 109 and the driver 107 to the data storage device 100 .
- read requests may be communicated directly between the application 113 and the data storage device 100
- other requests and command types may be communicated to the data storage device 100 using the operating system 109 and the driver 107 .
- write requests generated by the application 113 and garbage collection commands may be processed through the operating system 109 and the driver 107 using one of the driver buffer pairs.
- the command processor 122 may assign an identifier to the command to indicate to which buffer pair it is associated.
- the command processor 122 may be configured to direct responses to the appropriate response buffer using the assigned identifier.
- the interrupt processor 124 may be configured to generate an interrupt associated with the appropriate response buffer using the assigned identifier.
- the controller 110 may include multiple interrupt processors 124 such that each command buffer and response buffer pair is associated with one of the interrupt processors 124 . In this manner, each buffer pair may have one or more different interrupt mechanisms enabled on a per buffer pair basis.
- the interrupt processor 124 may be configured to generate and send interrupts based on the interrupts mechanism or mechanisms enabled by the host 106 .
- the interrupt processor 124 may include a ResponseNew counter 280 , a last response timer 282 , group counters 284 and interrupt send logic 286 .
- the ResponseNew counter 280 may be enabled by the host 106 when the watermark interrupt mechanism is desired.
- the host 106 may set the ResponseMark 288 , which is a parameter provided as input to the ReponseNew counter 280 , as discussed above.
- the ResponseNew counter 280 receives as inputs information including when a packet is transferred to the host 106 , when the ResponseHead is updated, the number of outstanding responses in the host response buffer 123 and when an interrupt has been sent.
- the ResponseNew counter 280 is configured to track the number of responses transferred to the host 106 that the host has yet to process. Each time a response is transferred to the response buffer 123 the counter is incremented.
- the watermark level i.e., the ResponseMark 288
- the watermark level is the number of new responses in the response buffer 123 needed to generate an interrupt. If the host 106 removes new responses from the response buffer 123 , they do not count toward meeting the watermark level. When an interrupt is generated, the count toward the ResponseMark is reset.
- the interrupt send logic 286 If the watermark interrupt mechanism is the only interrupt enabled, when the watermark is reached, then the interrupt send logic 286 generates and sends an interrupt to the host 106 . No further interrupts will be sent until the host 106 acknowledges the interrupt and updates the ResponseHead. The updated ResponseHead is communicated to the interrupt send logic 286 as a clear interrupt signal. If other interrupt mechanisms also are enabled, then the interrupt send logic 286 may generate and send an interrupt to the host 106 taking into account the other enabled interrupt mechanisms as well.
- the last response timer 282 may be enabled when the timer interrupt mechanism is desired.
- the last response timer 282 may be configured to keep track of time since the last interrupt. For instance, the last response timer 282 may track the amount of time since the last interrupt in microseconds.
- the host 106 may set the amount of time using a parameter, for example, a ResponseDelay parameter 290 .
- the ResponseDelay 290 timeout may be the number of microseconds since the last interrupt, or since the last time that the host 106 removed new responses from the response buffer 123 , before an interrupt is generated.
- the last response timer 282 receives as input a signal indicating when an interrupt is sent.
- the last response timer 282 also may receive a signal when the ResponseHead is updated, which indicates that the host 106 has removed responses from the response buffer 123 .
- An interrupt may be generated only if the response buffer 123 contains outstanding responses.
- the last response timer 282 is configured to generate a timeout trigger when the amount of time being tracked by the last response timer 282 is greater than the ResponseDelay parameter 290 . When this occurs and the response buffer 123 contains new responses, then a timeout trigger signal is sent to the interrupt send logic 286 . If the last response timer 282 is the only interrupt mechanism enabled, then the interrupt send logic 286 generates and sends an interrupt to the host. If other interrupt mechanisms also are enabled, then the interrupt send logic 286 may take into account the other interrupt mechanisms as well.
- Each interrupt mechanism includes an enable bit and the interrupt send logic 286 may be configured to generate an interrupt when an interrupt trigger is asserted for an enabled interrupt mechanism. The logic may be configure not to generate another interrupt until the host 106 acknowledges the interrupt and updates the ResponseHead.
- the Queue Control parameter 292 may provide input to the interrupt send logic 286 to indicate the status of the interrupt mechanisms such as which of the interrupt mechanisms are enabled and which of the interrupt mechanisms are disabled.
- the group counters 284 mechanism may be arranged and configured to track commands that are part of a group as designated by the driver 107 .
- the group counters 284 may be enabled by the host 106 when the host 106 desires to track commands as part of a group such that a single interrupt is generated and sent back to the host 106 only when all of the commands in a group are processed. In this manner, an interrupt is not generated for each of the individual commands but only for the group of commands.
- the group counters 284 may be configured with multiple counters to enable the tracking of multiple different groups of commands.
- the group counters 284 may be configured to track up to and including 128 different groups of commands. In this manner, for each group of commands there is a counter.
- the number of counters may be related to the number of group numbers that may be designated using the interrupt group field in the command header.
- the group counters 284 may be configured to operate to increment the counter for a group when a new command for the group has entered the command processor 122 .
- the group counters 284 may decrement the counter for a group when one of the commands in the group has completed processing. In this manner of incrementing as new commands enter for a group and decrementing when commands are completed for the group, the number of commands in each group is potentially unlimited.
- the counters do not need to be sized to account for the largest number of potential commands in a group. Instead, the counters may be sized based on the number of commands that the data storage device 100 may potentially process at one time, which may be smaller than the unlimited number of commands in a particular group.
- each of the group counters 284 may track the commands in a specific group using the group number assigned by the driver 107 and appearing in the interrupt group field in the command header of each command.
- the group counters 284 receive a signal each time a command having a group number enters the command processor 122 for processing. In response to this signal, the counter increments for that group.
- the group counters 284 also receive a signal each time a command having a group number completes processing. In response to this signal, the counter decrements for that group.
- the last command in the command group may be marked by the driver 107 with a flag to indicate to the group counters 284 that the command is the last command in the group.
- the last bit in the interrupt group field in the command header may be used as the flag.
- the group counters 284 are configured to recognize when the flag is set. In this manner, the group counters 284 keep a counter of the number of commands in a particular group that are in processing in the data storage device 100 . The group counters 284 also track when the end of the group has been seen.
- the counter for its interrupt group is incremented.
- the counter for its interrupt group is decremented.
- the group trigger signal is generated and sent to the interrupt send logic 286 .
- the group trigger signal is received at the interrupt send logic 286 , then an interrupt is sent to the host 106 .
- the group counters 284 then clear the end group flag for that group.
- the driver 107 may be configured to track the groups in use. The driver 107 may not re-use an interrupt group number until the previous commands to use that interrupt group have all completed and the interrupt has been acknowledged.
- the driver 107 may be configured to determine dynamically how many interrupts it wants to have generated. For example, the driver 107 may dynamically determine the size of a command group depending on various criteria including, for instance, volume, latency and other factors on the host 106 .
- the interrupt send logic 286 may be configured to consolidate multiple interrupts for multiple interrupt groups and only send a single interrupt for multiple groups of commands.
- FIG. 3 is a block diagram of a command processor 122 .
- the command processor 122 may include a slot tracker module 302 , a command transfer module 304 , a pending command module 306 , a command packet memory 308 , and a task dispatch module 310 .
- the command processor 122 may be implemented in hardware, software or a combination of hardware and software.
- the command processor 122 may be implemented as a part of a field programmable gate array (FPGA) controller.
- the FPGA controller may be configured using firmware or other instructions to program the FPGA controller to perform the functions discussed herein.
- the command processor 122 may be arranged and configured to retrieve commands from a host and to queue and order the commands from the host for processing by various storage locations. In one exemplary implementation, the command processor 122 may be configured to retrieve commands from each of the command buffers 219 a - 219 n using a round robin scheme. In another exemplary implementation, the command processor 122 may be configured to retrieve commands from each of the command buffers 219 a - 219 n using a priority scheme, where the priority of a particular command buffer may be designated by the host 106 . In other exemplary implementations, the command processor 122 may be configured to retrieve commands from each of the command buffers 219 a - 219 n.
- the command processor 122 may be configured to maximize the availability of the storage locations by attempting to keep all or substantially all of the storage locations busy.
- the command processor 122 may be configured to dispatch commands designated for the same storage location in order such that the order of the commands received from the host is preserved.
- the command processor 122 may be configured to reorder and dispatch commands designated for different storage locations out of order. In this manner, the commands received from the host may be processed in parallel by reordering the commands designated for different storage locations and, at the same time, the order of the commands designated for the same storage location is preserved.
- the command processor 122 may use an ordered list to queue and order the commands from the host.
- the ordered list may be sorted and/or otherwise ordered based on the age of the commands from the host. For instance, as new commands are received from the host, those commands are placed at the bottom of the ordered list in the order that they were received from the host. In this manner, commands that are dependent on order (e.g., commands designated for the same storage location) are maintained in the correct order.
- the storage locations may include multiple flash memory chips.
- the flash memory chips may be arranged and configured into multiple channels with each of the channels including one or more of the flash memory chips.
- the command processor 122 may be arranged and configured to dispatch commands designated for the same channel and/or the same flash memory chip in order based on the ordered list. Also, the command processor 122 may be arranged and configured to dispatch commands designated for different channels and/or different flash memory chips out of order. In this manner, the command processor 122 may, if needed, reorder the commands from the ordered list so that the channels and the flash memory chips may be kept busy at the same time. This enables the commands from the host to be processed in parallel and enables more commands to be processed at the same time on different channels and different flash memory chips.
- the commands from the host may be dispatched and tracked under the control of a driver (e.g., driver 107 of FIG. 1A and FIG. 1B ), where the driver may be a computer program product that is tangibly embodied on a storage medium and may include instructions for generating and dispatching commands from the host (e.g., host 106 of FIG. 1A and FIG. 1B ).
- the commands from the host may designate a specific storage location, for example, a specific flash memory chip and/or a specific channel. From the host perspective, it may be important that commands designated for the same storage location be executed in the order as specified by the host. For example, it may be important that certain operations generated by the host occur in order on a same flash memory chip.
- the host may generate and send an erase command and a write command for a specific flash memory chip, where the host desires that the erase command occurs first. It is important that the erase operation occurs first so that the data associated with the write command doesn't get erased immediately after it is written to the flash memory chip.
- This operation may include multiple commands to perform the operation on the same flash memory chip. In this example, it is necessary to perform these commands for this operation in the order specified by the host. For instance, a single write operation may include more than sixty commands.
- the command processor 122 may be configured to ensure that commands to the same flash memory chip are performed in order using the ordered list.
- the command processor 122 may be configured to track a number of commands being processed.
- the command processor 122 may be configured to track a number of available slots for commands to be received and processed.
- One of the components of the command processor 122 , the slot tracker module 302 may be configured to track available slots for commands from the host.
- the slot tracker module 302 may keep track of the open slots, provide the slots to new commands transferred from the host and designate the slots as open upon completion of the commands.
- the slot tracker module 302 may include a fixed number of slots, where each slot may be designated for a single command.
- the slot tracker module 302 may include 128 slots.
- the slot tracker module 302 may include a different number of fixed slots.
- the number of slots may be variable or configurable.
- the slot tracker module 302 may be implemented as a register or memory module in software, hardware or a combination of hardware and software.
- the slot tracker module 302 may include a list of slots, where each of the slots is associated with a global slot identifier. As commands are received from the host, the commands are assigned to an available slot and associated with the global slot identifier for that slot.
- the slot tracker module 302 may be configured to assign each of the commands a global slot identifier, where the number of global slot identifier is fixed to match the number of slots in the slot tracker module 302 .
- the command is associated with the global slot identifier throughout its processing until the command is completed and the slot is released.
- the global slot identifier is a tag associated with a particular slot that is assigned to a command that fills that particular slot.
- the tag is associated with the command and remains with the command until processing of the command is complete and the slot it occupied is released and made available to receive a new command.
- the commands may not be placed in order of slots, but instead may be placed in any of the available slots and assigned the global slot identifier associated with that slot.
- one of the components of the command processor 122 , the command transfer module 304 may be configured to retrieve new commands from the host based on a number of available slots in the slot tracker module 302 and an availability of new commands at the host.
- the command transfer module 304 may be implemented as a state machine.
- the slot tracker module 302 may provide information to the command transfer module 304 regarding the number of available slots. Also, the command transfer module 304 may query the slot tracker module 302 regarding the number of available slots.
- the command transfer module 304 may use a command tail pointer 312 and a command head pointer 314 to indicate when and how many new commands are available at the host for retrieval.
- the command transfer module 304 may compare the command tail pointer 312 and the command head pointer 314 to determine whether there are commands available for retrieval from the host. If the command tail pointer 312 and the command head pointer 314 are equal, then no commands are available for transfer. If the command tail pointer 312 is greater than the command head pointer 314 , then commands are available for transfer.
- the command tail pointer 312 and the command head pointer 314 may be implemented as registers that are configured to hold a pointer value and may be a part of the command processor 122 .
- the command tail pointer 314 may be written to by the host.
- the driver may use a memory mapped input/output (MMIO) write to update the command tail pointer 312 when commands are available at the host for retrieval.
- MMIO memory mapped input/output
- the command transfer module 304 updates the command head pointer 314 .
- the command transfer module 304 may retrieve some or all of the available commands from the host.
- the command transfer module 304 may retrieve a group of commands in a single access.
- the command transfer module 304 may be configured to retrieve a group of eight commands at a time using a direct memory access (DMA) operation from the host.
- DMA direct memory access
- the command transfer module 304 updates the command head pointer 314 .
- the commands may be retrieved from the host through the bus master 316 .
- the command transfer module 304 also may write to a host command head pointer (not shown) through the bus master 316 using a DMA operation to update the host command head pointer.
- the queue control 318 may be configured to enable and disable the command transfer module 304 .
- the queue control 318 may be implemented as a register that receives instructions from the host through the driver.
- the queue control 318 may be a component of the command processor 122 .
- the driver controls the setting of the queue control 318 so that the command transfer module 304 retrieves commands only when the host is ready and has provided the indication that it is ready.
- the queue control 318 register is set to disable, then the command transfer module 304 may not retrieve and process command from the host.
- the retrieved commands are each assigned to one of the available slots by the slot tracker module 302 and associated with the global slot identifier for that available slot.
- the data for the commands may be stored in the command packet memory 308 .
- the command packet memory 308 may be implemented as a fixed buffer that is indexed by global slot identifier.
- the data for a particular command may be stored in the command packet memory 308 and indexed by its assigned global slot identifier.
- the data for a particular command may remain in the command packet memory 308 until the command is dispatched to the designated storage location by the task dispatch module 310 .
- the command transfer module 304 also may be configured to provide other components of a controller with information related to the commands as indexed by slot. For example, the command transfer module 304 may provide data to a DMA engine. The command transfer module 304 also may provide status packet header data to a status processor. The command transfer module 304 may provide interrupt group data to an interrupt processor. For example, the command transfer module 304 may transfer group information 319 to the interrupt processor (e.g., interrupt processor 124 of FIGS. 1A and 2 ).
- the interrupt processor e.g., interrupt processor 124 of FIGS. 1A and 2 .
- the pending command module 306 may be configured to queue and order the commands using an ordered list that is based on an age of the commands.
- the pending command module 306 may be implemented as a memory module that is configured to store multiple pointers to queue and order the commands.
- the pending command module 306 may include a list of the global slot identifiers for the commands that are pending along with a storage location identifier.
- the storage location identifier may include the designated storage location for where the command is to be processed.
- the storage location identifier may include a channel identifier and/or a flash memory chip identifier.
- the storage location identifier is a part of the command and is assigned by the host through its driver.
- the global slot identifier and storage location information are added to the bottom of the ordered list in the pending command module 306 .
- the data for the commands is stored in the command packet memory 308 and indexed by the global slot identifier.
- a pointer to the previous command is included with the command.
- a pointer to the next command is included with the command.
- each item in the ordered list includes a global task identifier, a storage location identifier, a pointer to the previous command and a pointer to the next command.
- the ordered list may be referred to as a doubly linked list.
- the ordered list is a list of the commands ordered from oldest to newest.
- the task dispatch module 310 is configured to remove commands from the ordered list in the pending command module 306 and to dispatch them to the appropriate storage location for processing.
- the task dispatch module 310 may receive input from the storage locations to indicate that they are ready to accept new commands.
- the task dispatch module 310 may receive one or more signals 320 such as signals indicating that one or more of the storage locations are ready to accept new commands.
- the pending command module 306 may be configured to start at the top of the ordered list with the oldest command first and to make that command available to the task dispatch module 310 .
- the pending command module 306 may continue to make commands available to the task dispatch module 310 in order using the ordered list until a command is removed from the list by the task dispatch module 310 . After a command is removed from the ordered list in the pending command module 306 , the pending command module 306 plays back the commands remaining in the list to the task dispatch module 310 starting again at the top of the ordered list.
- the task dispatch module 310 may be configured to start at the top of the ordered list with the oldest command first and determine whether the storage location is available to receive new commands using the signals 320 . If the storage location is ready, then the task dispatch module 310 retrieves the command data from the command packet memory 308 and communicates the command data and a storage location select signal 322 to the storage location. The pending command module 306 then updates the ordered list and the pointers to reflect that the command was dispatched for processing. Once a command has been dispatched, the task dispatch module 310 starts at the top of the ordered list again.
- the task dispatch module 310 moves to the next command on the ordered list.
- the task dispatch module 310 determines if the next command is to the same or a different storage location than the skipped command. If the next command is to a same storage location as a skipped command, then the task dispatch module 310 also will skip this command. In this manner, the commands designated for the same storage location are dispatched and processed in order, as received from the host.
- the task dispatch module 310 preserves the order of commands designated for the same storage location. If the commands are designated for a different storage location, the task dispatch module 310 again determines if the storage location for the next command on the list is ready to accept the new command.
- the command is dispatched by the task dispatch module 310 from the command packet memory 308 to the storage location along with a storage location select signal 322 .
- the pending command module 306 removes the dispatched command from the ordered list and updates the ordered list including updating the pointers that were associated with the command. In this manner, the remaining pointers are linked together upon removal of the dispatched command.
- the pending command module 306 may include a single memory module 402 having multiple ports, port A and port B.
- the memory module 402 may store information related to the pending commands, including the pointer information for each command, where the pointer information may point to the next command and the previous command.
- the command transfer module 304 of FIG. 3 sends a new entry request 406 for a new command to be added to the ordered list to the pending command module 306 .
- the new entry request 406 is received by a new entry module 408 .
- the new entry module 408 may be implemented as a state machine.
- the new entry module 408 receives the new entry request 406 and adds it to the ordered list at the end of the list as the newest command in memory module 402 . Also, the new entry module 408 requests pointers from the free pointer list module 410 .
- the free pointer list module 410 may be implemented as a first-in, first-out (FIFO) memory that maintains a list of pointers that can be used for new entries.
- FIFO first-in, first-out
- the free pointer list module 410 provides a next entry pointer 412 to the new entry module 408 .
- the next entry pointer 412 is a pointer to where the entry following the current new entry will reside on the ordered list.
- the current new entry in the list points to this address as its next address.
- the new entry pointer 414 is a pointer to where the next new entry will reside on the ordered list, which was the previous entry's next entry pointer 412 .
- the last entry in the list points to this address as its next address.
- the memory module 402 stores the data fields related to the commands and the pointers. When a new entry is added, an end pointer 420 also is updated.
- next entry pointer 412 points to the next entry “Y” and the new entry pointer 414 points to the current entry that is to be added, “X”.
- next entry pointer 412 points to the next entry “Z” and the new entry pointer 414 points to the current entry that is to be added, “Y”.
- the task dispatch module 310 of FIG. 3 determines that an entry is to be removed from the ordered list in the memory module 402 .
- the task dispatch module sends a deletion request 416 .
- the deletion request is received by an entry playback and deletion module 418 .
- the entry playback and deletion module 418 may be configured to start at the top of the ordered list with the oldest command first and to make that command available to the task dispatch module 310 .
- the entry playback and deletion module 418 may continue to make commands available to the task dispatch module 310 in order using the ordered list until a command is removed from the list by the task dispatch module 310 .
- the entry playback and deletion module 418 causes the memory module 402 to dispatch the command and remove it from the ordered list.
- the pointers are then freed up and the entry playback and deletion module 418 provides an indication to the free pointer list module 410 that the pointers for the removed command are free.
- the entry playback and deletion module 418 also updates the pointers in the memory module 402 when the command is removed to maintain the correct order of the list.
- the entry playback and deletion module 418 also plays back the commands remaining in the list to the task dispatch module 310 starting again at the top of the ordered list.
- the entry playback and deletion module 418 may be implemented as a state machine.
- the entry playback and deletion module 418 also receives an input of the end pointer 420 from the new entry module 408 .
- the end pointer 420 may be used when the entry playback and deletion module 418 is making commands available to the task dispatch module 310 and when a last entry in the ordered list is removed from the list. In this manner, the end pointer 420 may be updated to point to the end of the ordered list.
- the controller board 102 which is its own PCB, may be located physically between each of the memory boards 104 a and 104 b , which are on their own separate PCBs.
- the data storage device 100 may include the memory board 104 a on one PCB, the controller board 102 on a second PCB, and the memory board 104 b on a third PCB.
- the memory board 104 a includes multiple flash memory chips 118 a and the memory board 104 b includes multiple flash memory chips 118 b .
- the controller board 102 includes the controller 110 and the interface 108 to the host (not shown), as well as other components (not shown).
- the memory board 104 a may be operably connected to the controller board 102 and located on one side 520 a of the controller board 102 .
- the memory board 104 a may be connected to a top side 520 a of the controller board 102 .
- the memory board 104 b may be operably connected to the controller board 102 and located on a second side 520 b of the controller board 102 .
- the memory board 104 b may be connected to a bottom side 520 b of the controller board 102 .
- FIG. 5 merely illustrates one exemplary arrangement.
- the data storage device 100 may include more than two memory board such as three memory boards, four memory boards or more memory boards, where all of the memory boards are connected to a single controller board. In this manner, the data storage device may still be configured in a disk drive form factor.
- the memory boards may be connected to the controller board in other arrangements such as, for instance, the controller board on the top and the memory cards on the bottom or the controller board on the bottom and the memory cards on the top.
- the data storage device 100 may be arranged and configured to cooperate with a computing device.
- the controller board 102 and the memory boards 104 a and 104 b may be arranged and configured to fit within a drive bay of a computing device.
- FIG. 6 two exemplary computing devices are illustrated, namely a server 630 and a server 640 .
- the servers 630 and 640 may be arranged and configured to provide various different types of computing services.
- the servers 630 and 640 may include a host (e.g., host 106 of FIG. 1A and FIG. 1B ) that includes computer program products having instructions that cause one or more processors in the servers 630 and 640 to provide computing services.
- the type of server may be dependent on one or more application programs (e.g., application(s) 113 of FIG. 1A and FIG. 1B ) that are operating on the server.
- the servers 630 and 640 may be application servers, web servers, email servers, search servers, streaming media servers, e-commerce servers, file transfer protocol (FTP) servers, other types of servers or combinations of these servers.
- the server 630 may be configured to be a rack-mounted server that operates within a server rack.
- the server 640 may be configured to be a stand-alone server that operates independent of a server rack. Even though the server 640 is not within a server rack, it may be configured to operate with other servers and may be operably connected to other servers.
- Servers 630 and 640 are meant to illustrate example computing devices and other computing devices, including other types of servers, may be used.
- the data storage device 100 of FIGS. 1A , 1 B and 5 may be sized to fit within a drive bay 635 of the server 630 or the drive bay 645 of the server 640 to provide data storage functionality for the servers 630 and 640 .
- the data storage device 100 may be sized to a 3.5′′ disk drive form factor to fit in the drive bays 635 and 645 .
- the data storage device 100 also may be configured to other sizes.
- the data storage device 100 may operably connect and communicate with the servers 630 and 560 using the interface 108 . In this manner, the host may communicate commands to the controller board 102 using the interface 108 and the controller 110 may execute the commands using the flash memory chips 118 a and 118 b on the memory boards 104 a and 104 b.
- the interface 108 may include a high speed interface between the controller 110 and the host 106 .
- the high speed interface may enable for fast transfers of data between the host 106 and the flash memory chips 118 a and 118 b .
- the high speed interface may include a PCIe interface.
- the PCIe interface may be a PCIe x4 interface or a PCIe x8 interface.
- the PCIe interface 108 may include a connector to the host 106 such as, for example, a PCIe connector cable assembly. Other high speed interfaces, connectors and connector assemblies also may be used.
- the communication between the controller board 102 and the flash memory chips 118 a and 118 b on the memory boards 104 a and 104 b may be arranged and configured into multiple channels 112 .
- Each of the channels 112 may communicate with one or more flash memory chips 118 a and 118 b and may be controlled by the channel controllers (not shown).
- the controller 110 may be configured such that commands received from the host 106 may be executed by the controller 110 using each of the channels 112 simultaneously or at least substantially simultaneously. In this manner, multiple commands may be executed simultaneously on different channels 112 , which may improve throughput of the data storage device 100 .
- each of the channels 112 may support multiple flash memory chips.
- each of the channels 112 may support up to 32 flash memory chips.
- each of the 20 channels may be configured to support and communicate with 6 flash memory chips.
- each of the memory boards 104 a and 104 b would include 60 flash memory chips each.
- the data storage device 100 may be configured to store up to and including multiple terabytes of data.
- the controller 110 may include a microcontroller, a FPGA controller, other types of controllers, or combinations of these controllers.
- the controller 110 is a microcontroller.
- the microcontroller may be implemented in hardware, software, or a combination of hardware and software.
- the microcontroller may be loaded with a computer program product from memory (e.g., memory module 116 ) including instructions that, when executed, may cause the microcontroller to perform in a certain manner.
- the microcontroller may be configured to receive commands from the host 106 using the interface 108 and to execute the commands.
- the commands may include commands to read, write, copy and erase blocks of data using the flash memory chips 118 a and 118 b , as well as other commands.
- the controller 110 is a FPGA controller.
- the FPGA controller may be implemented in hardware, software, or a combination of hardware and software.
- the FPGA controller may be loaded with firmware from memory (e.g., memory module 116 ) including instructions that, when executed, may cause the FPGA controller to perform in a certain manner.
- the FPGA controller may be configured to receive commands from the host 106 using the interface 108 and to execute the commands.
- the commands may include commands to read, write, copy and erase blocks of data using the flash memory chips 118 a and 118 b , as well as other commands.
- the FPGA controller may support multiple interfaces 108 with the host 106 .
- the FPGA controller may be configured to support multiple PCIe x4 or PCIe x8 interfaces with the host 106 .
- the memory module 116 may be configured to store data, which may be loaded to the controller 110 .
- the memory module 116 may be configured to store one or more images for the FPGA controller, where the images include firmware for use by the FPGA controller.
- the memory module 116 may interface with the host 106 to communicate with the host 106 .
- the memory module 116 may interface directly with the host 106 and/or may interface indirectly with the host 106 through the controller 110 .
- the host 106 may communicate one or more images of firmware to the memory module 116 for storage.
- the memory module 116 includes an electrically erasable programmable read-only memory (EEPROM).
- EEPROM electrically erasable programmable read-only memory
- the memory module 116 also may include other types of memory modules.
- the power module 114 may be configured to receive power (Vin), to perform any conversions of the received power and to output an output power (Vout).
- the power module 114 may receive power (Vin) from the host 106 or from another source.
- the power module 114 may provide power (Vout) to the controller board 102 and the components on the controller board 102 , including the controller 110 .
- the power module 114 also may provide power (Vout) to the memory boards 104 a and 104 b and the components on the memory boards 104 a and 104 b , including the flash memory chips 118 a and 118 b.
- the power module 114 may include one or more direct current (DC) to DC converters.
- the DC to DC converters may be configured to receive a power in (Vin) and to convert the power to one or more different voltage levels (Vout).
- Vin power in
- Vout voltage levels
- the power module 114 may be configured to receive +12 V (Vin) and to convert the power to 3.3 v, 1.2 v, or 1.8 v and to supply the power out (Vout) to the controller board 102 and to the memory boards 104 a and 104 b.
- the memory boards 104 a and 104 b may be configured to handle different types of flash memory chips 118 a and 118 b .
- the flash memory chips 118 a and the flash memory chips 118 b may be the same type of flash memory chips including requiring the same voltage from the power module 114 and being from the same flash memory chip vendor.
- vendor and manufacturer are used interchangeably throughout this document.
- the flash memory chips 118 a on the memory board 104 a may be a different type of flash memory chip from the flash memory chips 118 b on the memory board 104 b .
- the memory board 104 a may include SLC NAND flash memory chips and the memory board 104 b may include MLC NAND flash memory chips.
- the memory board 104 a may include flash memory chips from one flash memory chip manufacturer and the memory board 104 b may include flash memory chips from a different flash memory chip manufacturer. The flexibility to have all the same type of flash memory chips or to have different types of flash memory chips enables the data storage device 100 to be tailored to different application(s) 113 being used by the host 106 .
- the memory boards 104 a and 104 b may include different types of flash memory chips on the same memory board.
- the memory board 104 a may include both SLC NAND chips and MLC NAND chips on the same PCB.
- the memory board 104 b may include both SLC NAND chips and MLC NAND chips. In this manner, the data storage device 100 may be advantageously tailored to meet the specifications of the host 106 .
- the memory boards 104 a and 104 b may include other types of memory devices, including non-flash memory chips.
- the memory boards 104 a and 104 b may include random access memory (RAM) such as, for instance, dynamic RAM (DRAM) and static RAM (SRAM) as well as other types of RAM and other types of memory devices.
- RAM random access memory
- DRAM dynamic RAM
- SRAM static RAM
- the both of the memory boards 104 a and 104 b may include RAM.
- one of the memory boards may include RAM and the other memory board may include flash memory chips.
- one of the memory boards may include both RAM and flash memory chips.
- the memory modules 120 a and 120 b on the memory boards 104 a and 104 b may be used to store information related to the flash memory chips 118 a and 118 b , respectively.
- the memory modules 120 a and 120 b may store device characteristics of the flash memory chips. The device characteristics may include whether the chips are SLC chips or MLC chips, whether the chips are NAND or NOR chips, a number of chip selects, a number of blocks, a number of pages per block, a number of bytes per page and a speed of the chips.
- the memory modules 120 a and 120 b may include serial EEPROMs.
- the EEPROMs may store the device characteristics.
- the device characteristics may be compiled once for any given type of flash memory chip and the appropriate EEPROM image may be generated with the device characteristics.
- the controller board 102 When the memory boards 104 a and 104 b are operably connected to the controller board 102 , then the device characteristics may be read from the EEPROMs such that the controller 110 may automatically recognize the types of flash memory chips 118 a and 118 b that the controller 110 is controlling. Additionally, the device characteristics may be used to configure the controller 110 to the appropriate parameters for the specific type or types of flash memory chips 118 a and 118 b.
- Process 700 may include populating a circular command queue of a driver of the host with commands for retrieval by the data storage device ( 702 ). Commands can be sent from the circular command queue to the data storage device via a direct memory access operation ( 704 ). A direct memory access operation initiated by the data storage device can be used to populate a circular response queue of the host with responses by the data storage device for retrieval by the host device, where each response acknowledges the reception of a command from the host by the data storage device ( 706 ). And responses can be consumed from the circular response queue at the host ( 708 ).
- Implementations of the various techniques described herein may be implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in combinations of them. Implementations may be implemented as a computer program product, i.e., a computer program tangibly embodied in an information carrier, e.g., in a machine-readable storage device, for execution by, or to control the operation of, data processing apparatus, e.g., a programmable processor, a computer, or multiple computers.
- a computer program such as the computer program(s) described above, can be written in any form of programming language, including compiled or interpreted languages, and can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment.
- a computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.
- Method steps may be performed by one or more programmable processors executing a computer program to perform functions by operating on input data and generating output. Method steps also may be performed by, and an apparatus may be implemented as, special purpose logic circuitry, e.g., a FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- a FPGA field programmable gate array
- ASIC application-specific integrated circuit
- processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer.
- a processor will receive instructions and data from a read-only memory or a random access memory or both.
- Elements of a computer may include at least one processor for executing instructions and one or more memory devices for storing instructions and data.
- a computer also may include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- Information carriers suitable for embodying computer program instructions and data include all forms of non-volatile memory, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
- semiconductor memory devices e.g., EPROM, EEPROM, and flash memory devices
- magnetic disks e.g., internal hard disks or removable disks
- magneto-optical disks e.g., CD-ROM and DVD-ROM disks.
- the processor and the memory may be supplemented by, or incorporated in special purpose logic circuitry.
- implementations may be implemented on a computer having a display device, e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor
- keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- Implementations may be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation, or any combination of such back-end, middleware, or front-end components.
- Components may be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.
- LAN local area network
- WAN wide area network
Abstract
A method for communicating commands between a host and a flash memory data storage device includes populating a circular command queue of a driver on the host with commands for retrieval by the data storage device, transferring commands from the circular command queue to the data storage device via a device initiated direct memory access operation, populating, via a direct memory access operation initiated by the data storage device, a circular response queue of the host with responses by the data storage device for retrieval by the host device, where each response acknowledges the reception of a command from the host by the data storage device, and consuming responses from the circular response queue at the host.
Description
- This application is a continuation-in-part application of U.S. patent application Ser. No. 12/537,733, filed on Aug. 7, 2009, entitled “MULTIPLE COMMAND QUEUES HAVING SEPARATE INTERRUPTS,” which in turn, claims the benefit of U.S. Provisional Application No. 61/167,709, filed Apr. 8, 2009, and titled “DATA STORAGE DEVICE” and U.S. Provisional Application No. 61/187,835, filed Jun. 17, 2009, and titled “PARTITIONING AND STRIPING IN A FLASH MEMORY DATA STORAGE DEVICE.” This application claims the benefit of U.S. Provisional Application No. 61/304,469, filed Feb. 14, 2010, and titled “DATA STORAGE DEVICE,” U.S. Provisional Patent Application No. 61/304,468, filed Feb. 14, 2010, and titled “DATA STORAGE DEVICE,” and U.S. Provisional Patent Application No. 61/304,475, filed Feb. 14, 2010, and titled “DATA STORAGE DEVICE,” all of which are hereby incorporated by reference in entirety. Each of the above-referenced applications is hereby incorporated by reference in its entirety.
- This description relates to data storage devices and, in particular, to circular command queues for communication between a host and a data storage device.
- Data storage devices may be used to store data. A data storage device may be used with a computing device to provide for the data storage needs of the computing device. In certain instances, it may be desirable to store large amounts of data on a data storage device. Also, it may be desirable to execute commands quickly to read data and to write data to the data storage device.
- In a first general aspect, a host device configured for storing data on, and retrieving data from, a flash memory data storage device, includes a driver that is arranged and configured to communicate commands to the data storage device, a circular command queue that is populated with commands for retrieval by the data storage device, and a circular response queue that is populated with responses by the data storage device for retrieval by the host device, wherein each response acknowledges the reception of a command from the host by the data storage device.
- Implementations can include one or more of the following features. For example, the circular command queue can include a command head pointer and a command tail pointer, and the circular response queue can include a response head pointer and a response tail pointer, and the host device can further include a first register configured to store command head pointer values, and a second register configured to store response tail pointer values. The data storage device can include a third register configured to store command tail pointer values, and a fourth register configured to store response head pointer values. The third register can exist in a memory mapped address space of the data storage device, and the driver can be configured to write updated command tail pointer values to the third register. The driver can be configured to send commands to the storage device in response to a direct memory access request from the data storage device, and the first register can be configured to receive updated command head pointer values in response to a direct memory access operation received from the data storage device. The second register can exist in the address space of the host device, and the second register can be configured to receive updated response tail pointer values from the data storage device into the second register. The driver can be configured to receive responses from the storage device through a direct memory access operation sent from the data storage device, and the driver can be configured to send updated response head pointer values to the data storage device via a write to a Memory Mapped register. The host device can further include an application that is configured to generate input and output requests, and an operating system that is operably coupled to the driver and to the application and that is configured to communicate the input and output requests between the application and the driver.
- In another general aspect, a method for communicating commands between a host and a flash memory data storage device includes populating a circular command queue of a driver on the host with commands for retrieval by the data storage device, transferring commands from the circular command queue to the data storage device via a device initiated direct memory access operation, populating, via a direct memory access operation initiated by the data storage device, a circular response queue of the host with responses by the data storage device for retrieval by the host device, where each response acknowledges the reception of a command from the host by the data storage device, and consuming responses from the circular response queue at the host.
- Implementations can include one or more of the following features. For example, the circular command queue can include a command head pointer and a command tail pointer, and the circular response queue can include a response head pointer and a response tail pointer, and the method can further include storing command head pointer values in a first register of the host, and storing response tail pointer values in a second register of the host. The data storage device can include a third register configured to store command tail pointer values, and a fourth register configured to store response head pointer values. The third register can exist in a memory mapped address space of the data storage device, and the method can further include writing updated command tail pointer values to the third register. Updated command head pointer values can be received into the first register in response to a direct memory access operation received from the data storage device. The second register can exist in the address space of the host device, and the method can further include receiving updated response tail pointer values into the second register from the data storage device. Responses from the storage device can be received through a direct memory access operation sent from the data storage device, and updated response head pointer values can be sent to the data storage device via a write to a Memory Mapped register. Input and output requests can be generated from an application running on the host, and the input and output requests can be communicated from an application running on the host through an operating system to the driver.
-
FIG. 1A is an exemplary block diagram of a host and a data storage device. -
FIG. 1B is an exemplary block diagram of multiple queues on the host ofFIG. 1A . -
FIG. 1C is an exemplary block diagram of circular queues used to communicate information between the host and the data storage device ofFIG. 1A . -
FIG. 2 is an exemplary block diagram of an interrupt processor. -
FIG. 3 is an exemplary block diagram of a command processor for the data storage device. -
FIG. 4 is an exemplary block diagram of a pending command module. -
FIG. 5 is an exemplary perspective block diagram of the printed circuit boards of the data storage device. -
FIG. 6 is an exemplary block diagram of exemplary computing devices for use with the data storage device ofFIG. 1A . -
FIG. 7 is an exemplary flowchart illustrating a process for communicating commands between a host and a data storage device. - This document describes an apparatus, system(s) and techniques for using one or more pairs of queues at a host to communicate commands and responses between the host and a data storage device. Each pair of queues includes a command queue and a response queue. The pairs of queues enable the host to communicate with the data storage device using multiple threads or cores in an efficient manner.
- Referring to
FIG. 1A , a block diagram of a system for processing and tracking commands in a group is illustrated.FIG. 1A illustrates a block diagram of adata storage device 100 and ahost 106. Thedata storage device 100 may include acontroller board 102 and one ormore memory boards data storage device 100 may communicate with thehost 106 over aninterface 108. Theinterface 108 may be between thehost 106 and thecontroller board 102. - The
controller board 102 may include acontroller 110, aDRAM 111,multiple channels 112, apower module 114, and amemory module 116. Thecontroller 110 may include acommand processor 122 and aninterrupt processor 124, as well as other components, which are not shown. Thememory boards flash memory chips memory boards memory device - The
host 106 may include adriver 107, anoperating system 109 and one ormore applications 113. In general, thehost 106 may generate commands to be executed on thedata storage device 100. For example, theapplication 113 may be configured to generate commands for execution on thedata storage device 100. Theapplication 113 may be operably coupled to theoperating system 109 and/or to thedriver 107. Theapplication 113 may generate the commands and communicate the commands to theoperating system 109. Theoperating system 109 may be operably coupled to thedriver 107, where thedriver 107 may act as an interface between thehost 106 and thedata storage device 100. In other exemplary implementations, theapplication 113 may communicate directly with thedata storage device 100, as discussed below with respect toFIG. 1B . - In general, the
data storage device 100 may be configured to store data on theflash memory chips host 106 may write data to and read data from theflash memory chips flash memory chips host 106 and theflash memory chips controller 110 on thecontroller board 102. Thecontroller 110 may receive commands from thehost 106 and cause those commands to be executed using thecommand processor 122 and theflash memory chips memory boards host 106 and thecontroller 110 may be through theinterface 108. Thecontroller 110 may communicate with theflash memory chips channels 112. - The
controller board 102 may includeDRAM 111. TheDRAM 111 may be operably coupled to thecontroller 110 and may be used to store information. For example, theDRAM 111 may be used to store logical address to physical address maps and bad block information. TheDRAM 111 also may be configured to function as a buffer between thehost 106 and theflash memory chips - In one exemplary implementation, the
controller board 102 and each of thememory boards memory board 104 a may be on one PCB that is operably connected to thecontroller board 102 PCB. For example, thememory board 104 a may be physically and/or electrically connected to thecontroller board 102. Similarly, thememory board 104 b may be a separate PCB from thememory board 104 a and may be operably connected to thecontroller board 102 PCB. For example, thememory board 104 b may be physically and/or electrically connected to thecontroller board 102. Thememory boards controller board 102. For example, thememory board 104 a may be disconnected from thecontroller board 102 and replaced with another memory board (not shown), where the other memory board is operably connected tocontroller board 102. In this example, either or both of thememory boards same controller board 102 andcontroller 110. - In one exemplary implementation, the
controller board 102 and each of thememory boards - In one exemplary implementation, the
controller board 102 and each of thememory boards - In one exemplary implementation, the memory chips 118 a-118 n may include flash memory chips. In another exemplary implementation, the memory chips 118 a-118 n may include DRAM chips or combinations of flash memory chips and DRAM chips. The memory chips 118 a-118 n may include other types of memory chips as well.
- In one exemplary implementation, the
host 106 using thedriver 107 and thedata storage device 100 may communicate commands and responses using pairs of queues or buffers in host memory. Throughout this document, the terms buffer and queue are used interchangeably. For example, acommand buffer 119 may be used for commands and aresponse buffer 123 may be used for responses or results to the commands. In one exemplary implementation, the commands and results may be relatively small, fixed size blocks. For instance, the commands may be 32 bytes and the results or responses may be 8 bytes. In other exemplary implementations, other sized blocks may be used including variable size blocks. Tags may be used to match the results to the commands. In this manner, thedata storage device 100 may complete commands out of order. - Although
FIG. 1A illustrates onecommand buffer 119 and oneresponse buffer 123, multiple pairs of buffers may be used, as illustrated inFIG. 1B and discussed in more detail below. For example, up to and including 32 buffer pairs may be used. In one exemplary implementation, thedata storage device 100 may service themultiple command buffers 119 in a round robin fashion, where thedata storage device 100 may retrieve a fixed number of commands at a time from each of the command buffers 119. Theresponse buffer 123 may include its own interrupt and interrupt parameters. - In one exemplary implementation, each command may refer to one memory page (e.g., one flash page), one erase block or one memory chip depending on the command. Each command that transfers data may include one 4K direct memory access (DMA) buffer. Larger operations may be implemented by sending multiple commands. The
driver 107 may be arranged and configured to group together a single operation of multiple commands such that thedata storage device 100 processes the commands using theflash memory chips host 106 when the multiple grouped commands have been processed. - In one exemplary implementation shown in
FIG. 1C thecommand buffer 119 can be configured as acircular queue 159 that is used to communicate information from thehost 106 and to thedata storage device 100 ofFIG. 1A . Theresponse buffer 123 also can be configured as a circular queue. Each of thecircular queues 159 of thecommand buffer 119 and theresponse buffer 123 include a head pointer and a tail pointer. Values of the head pointer of thecircular queue 159 of thecommand buffer 119 can be stored in aregister 163 on the host, and values of the tail pointer can be stored in aregister 161 on thedata storage device 100. Values of a tail pointer of a circular queue of theresponse buffer 123 can be stored in a register on the host, and values of the head pointer of the response buffer can be stored in a register on thedata storage device 100. Commands and responses may be inserted into thecircular queue 159 at the tail pointer and removed at the head pointer. Thehost 106 may be the producer of thecommand buffer 119 and the consumer of theresponse buffer 123. Thedata storage device 100 may be the consumer of thecommand buffer 119 and the producer of theresponse buffer 123. Thehost 106 may write the command tail pointer and the response head pointer and may read the command head pointer and the response tail pointer. Thedata storage device 100 may write the command head pointer and the response tail pointer and may read the command tail pointer and the response head pointer. In thedata storage device 100, thecontroller 110 may perform the read and write actions. More specifically, thecommand processor 122 may be configured to perform the read and write actions for thedata storage device 100. No other synchronization, other than the head and tail pointers, may be needed between thehost 106 and thedata storage device 100. - In one exemplary implementation, for performance reasons, the command head pointer and the response tail pointer may be stored in register of the host 106 (e.g., in host RAM). The command tail pointer and the response head pointer may be stored in registers of the
data storage device 100 in memory mapped I/O space within thecontroller 110. - The
command buffer 119 and theresponse buffer 123 may be an arbitrary multiple of the command or response sizes, and thedriver 107 and thedata storage device 100 may be free to post and process commands and results as needed provided that they do not overrun thecommand buffer 119 and theresponse buffer 123. In one implementation, as described above, thecommand buffer 119 and theresponse buffer 123 are circular queues, which enable flow control between thehost 106 and thedata storage device 100. - In one exemplary implementation, the
host 106 may determine the size of thecommand buffer 119 and theresponse buffer 123. The buffers may be larger than the number of commands that thedata storage device 100 can queue internally. - The
host 106 may write a command to thecommand buffer 119 and update the command tail pointer, which can reside in memory mapped input/output (“MMIO”) space of the data storage device, to indicate to the data storage device 100 (and, in particular, to thecommand processor 122 within the data storage device 100) that a new command is present and ready for communication to the data storage device. The writing of the command tail pointer signals thecommand processor 122 that a new command is present. Thecommand processor 122 is configured to read the command out of thecommand buffer 119 using a DMA operation and is configured to update the head pointer using another DMA operation to indicate to thehost 106 that thecommand processor 122 has received the command. Thus, writing a command from thehost 106 to the data storage device can include just one write operation to memory mapped input/output space (i.e., the updating of the tail pointer in the MMIO space of the data storage device by the host) and two DMA events (i.e., the command processor reading the command out of the command buffer and updating the head pointer of the circular queue 159). - When the
command processor 122 completes the command, thecommand processor 122 writes a response to the host using a DMA operation and updates the response tail pointer with another DMA operation to indicate that the command is finished. The interruptprocessor 124 is configured to signal thehost 106 with an interrupt when new responses are available in theresponse buffer 123. Thehost 106 is configured to read the responses from theresponse buffer 123 and update the head pointer in the MMIO space of the data storage device to indicate that the host has received the response. In one exemplary implementation, the interruptprocessor 124 may not send another interrupt to thehost 106 until the previous interrupt has been acknowledged by thehost 106 writing to the response head pointer. Thus, receiving a response to the writing of a command can include just one write operation to memory mapped input/output space (i.e., the updating of the head pointer by the host) and two DMA events (i.e., the writing of the response by the command processor and the updating of the response tail pointer to indicate that the command is finished). Neither the writing of the command nor the reception of the response involves a MMIO read event, which can take a relatively long time compared to MMIO write events and DMA events, and in this manner the communication between the host and the device is accelerated. - In one exemplary implementation, the
host 106, through itsdriver 107, may control when the interruptprocessor 124 should generate interrupts. Thehost 106 may use one or more different interrupt mechanisms, including a combination of different interrupt mechanisms, to provide information to the interruptprocessor 124 regarding interrupt processing. For instance, thehost 106 through thedriver 107 may configure the interruptprocessor 124 to use a water mark interrupt mechanism, a timeout interrupt mechanism, a group interrupt mechanism, or a combination of these interrupt mechanisms. - In one exemplary implementation, the
host 106 may set a ResponseMark parameter, which determines the water mark, and may set the ResponseDelay parameter, which determines the timeout. Thehost 106 may communicate these parameters to the interruptprocessor 124. If the count of new responses in theresponse buffer 123 is equal to or greater than the ResponseMark, then an interrupt is generated by the interruptprocessor 124 and the count is zeroed. If the time (e.g., time in microseconds) since the last interrupt is equal to or greater than the ResponseDelay and there are new responses in theresponse buffer 123, then the interruptprocessor 124 generates an interrupt and the timeout is zeroed. If thehost 106 removes the new response from theresponse buffer 123, the count of new responses is updated and the timeout is restarted. In this manner, thehost 106 may poll ahead and avoid interrupts from the interruptprocessor 124. - In another exemplary implementation, the
host 106 may use a group interrupt mechanism to determine when the interruptprocessor 124 should generate and send interrupts to thehost 106. The commands may share a common value, which identifies the commands as part of the same group. For example, thedriver 107 may group commands together and assign a same group number to the group of commands. Thedriver 107 may use an interrupt group field in the command header to assign a group number to the commands in a group. When all of the commands in a command group have completed, and the responses for all of those commands have been transferred from thecommand processor 122 to theresponse buffer 123 and the response tail is updated, then the interruptprocessor 124 may generate and send the interrupt to thehost 106. In this manner, the group interrupt mechanism may be used to reduce the time thehost 106 needs to spend processing interrupts. - Each of the interrupt mechanisms may be separately enabled or disabled. Also, any combination of interrupt mechanisms may be used. For example, the
driver 107 may set interrupt enable and disable flags in a QueueControl register to determine which of the interrupt mechanisms are enabled and which of the interrupt mechanisms are disabled. In this manner, the combination of the interrupts may be used to reduce the time that thehost 106 needs to spend processing interrupts. Thehost 106 may use its resources to perform other tasks. - In one exemplary implementation, all of the interrupt mechanisms may be disabled. In this situation, the
driver 107 may be configured to poll theresponse buffer 123 to determine if there are responses ready for processing. Having all of the interrupt mechanisms disabled may result in a lowest possible latency. It also may result in a high overhead for thedriver 107. - In another exemplary implementation, the group interrupt mechanism may be enabled along with the timeout interrupt mechanism and/or the water mark interrupt mechanism. In this manner, if the number of commands in a designated group is larger than the
response buffer 123, one of the other enabled interrupt mechanisms will function to interrupt thedriver 107 to clear the responses from theresponse buffer 123 to provide space for thecommand processor 122 to add more responses to theresponse buffer 123. - The use of the different interrupt mechanisms, either alone or in combinations, may be used to adjust the latency and/or the overhead with respect to the
driver 107. For example, in one exemplary implementation, only the timeout interrupt mechanism may be enabled. In this situation, the overhead on thedriver 107 may be reduced. In another exemplary implementation, only the water mark interrupt mechanism may be enabled. In this situation, the latency may be reduced to a lower level. - In some exemplary situations, a particular type of application being used may factor into the determination of which interrupt mechanisms are enabled. For example, a web search application may be latency sensitive and the interrupt mechanisms may be enabled in particular combinations to provide the best latency sensitivity for the web search application. In another example, a web indexing application may not be as sensitive to latency as a web search application. Instead, processor performance may be a more important parameter. In this application, the interrupt mechanisms may be enabled in particular combinations to allow low overhead, even at the expense of increased latency.
- In one exemplary implementation, the
driver 107 may determine a command group based on an input/output (I/O) operation received from anapplication 113 through theoperating system 109. For example, theapplication 113 may request a read operation of multiple megabytes. In this instance, theapplication 113 may not be able to use partial responses and the only useful information for theapplication 113 may be when the entire operation has been completed. Typically, the read operation may be broken up into many multiple commands. Thedriver 107 may be configured to recognize the read operation as a group of commands and to assign the commands in that group the same group number in each of the command headers. An interface between theapplication 113 and thedriver 107 may be used to indicate to thedriver 107 that certain operations are to be treated as a group. The interface may be configured to group operations based on different criteria including, but not limited to, the type of command, the size of the data request associated with the command, the type of data requested including requests from multiple different applications, the priority of the request, and combinations thereof. - In some implementations, the
application 113 may pass individual command information relating to an operation to theoperating system 109 and ultimately to thedriver 107. In other exemplary implementations, thedriver 107 may designate one or more commands to be considered a group. - Referring to
FIG. 1B , a block diagram of anexemplary host 106 having multiple queues or buffers. As discussed above with respect toFIG. 1A , thehost 106 may include thedriver 107, theoperating system 109 and one ormore applications 113. In the example ofFIG. 1B , the driver includes multiple pairs of buffers 219 a-219 n and 223 a-223 n. The multiple pairs of buffers include a command buffer 219 a-219 n and a response buffer 223 a-223 n in each pair. - The pairs work together. For example, the
driver 107 may populate thecommand buffer 219 a with commands for retrieval by thedata storage device 100 through theinterface 108. Thedata storage device 100 generates and communicates responses to those commands, where the responses populate thecorresponding response buffer 223 a. The following pairs of buffers are illustrated:command buffer 219 a is paired withresponse buffer 223 a;command buffer 219 b is paired withresponse buffer 223 b;command buffer 219 c is paired withresponse buffer 223 c; andcommand buffer 219 n is paired withresponse buffer 223 n. - The
driver 107 may be configured to enable multiple instances of thedriver 107 to operate simultaneously. For instance, a separate instance of thedriver 107 may be configured to operate with each of the pairs of buffers. In this manner, thedriver 107 may use multiple different threads of commands to communicate with the data storage device. For example, one thread may be used to communicate commands and associated responses with thecommand buffer 219 a and theresponse buffer 223 a. Another thread may be used to communicate commands and associated response with thecommand buffer 219 b and theresponse buffer 223 b. - The command buffers 219 a-219 n and the response buffers 223 a-223 n may be configured to operate and function as described above with respect to the
command buffer 119 and theresponse buffer 123 ofFIG. 1A . Each of the buffer pairs may include its own set of head and tail pointers. The use of the head and tail pointers may be the same as described above with respect to thecommand buffer 119 and theresponse buffer 123 ofFIG. 1A . The multiple different head and tail pointers, each of which corresponds to a buffer pair, may be stored on thehost 106, thedata storage device 100 or a combination of thehost 106 and thedata storage device 100. - Each of the response buffers 223 a-223 n may have an associated interrupt handler 225 a-225 n. In this manner, each response buffer 223 a-223 n may process the interrupts received from the
data storage device 100 on an individual basis. In some instances, an interrupt may be received by an interrupt handler 225 a-225 n when a related group of commands has been processed by the data storage device, as discussed in more detail below with respect toFIG. 2 . - Each of the buffer pairs may be granted access to any address mapping, which may be stored on the
host 106 and/or on thedata storage device 100. For example, each of the buffer pairs may be granted access to the logical to physical address mapping, which may be stored inDRAM 111 ofFIG. 1A . In one exemplary implementation, any address mapping or tables such as, for example, the logical to physical address mapping may be shared such that each pair of buffers may have access to the mapping. - In one exemplary implementation, each of the one or
more applications 113 may use one of the command buffer 219 a-219 n and response buffer 223 a-223 n pairs to communicate with thedata storage device 100 through theoperating system 109 and an associated instance of thedriver 107. - In one exemplary implementation, each of the
applications 113 may include its own pair of buffers. For example, theapplication 113 may include anapplication command buffer 229 and anapplication response buffer 233. By having its own pair ofbuffers application 113 may communicate directly with thedata storage device 100 through theinterface 108. Thus, instead of communicating through theoperating system 109 and thedriver 107 and a pair of buffers associated with the driver, theapplication 113 may bypass those components and communicate directly with thedata storage device 100. In this manner, input and output requests generated by theapplication 113 may be processed by thedata storage device 100 faster than if the requests were communicated to thedata storage device 100 through theoperating system 109 and thedriver 107. - The
application command buffer 229 and theapplication response buffer 233 may be configured to perform and function in the same manner as described above with respect to thecommand buffer 119 and theresponse buffer 123 ofFIG. 1A , except that theapplication command buffer 229 and theapplication response buffer 233 are associated directly with theapplication 113 and not thedriver 107. - In one exemplary implementation, the
application 113 may communicate specific command types and input/output requests directly with thedata storage device 100 using its ownapplication command buffer 229 andapplication response buffer 233. Other command types and input/output requests generated by theapplication 113 may be process through theoperating system 109 and thedriver 107 using one of the pairs of buffers associated with thedriver 107. For example, theapplication 113 may be configured to communicate read requests directly to thedata storage device 100 using theapplication command buffer 229 and theapplication response buffer 233. In this manner, the overall processing time of read requests may be faster than read requests that are processed through theoperating system 109 and thedriver 107 to thedata storage device 100. - In the above example where read requests may be communicated directly between the
application 113 and thedata storage device 100, other requests and command types may be communicated to thedata storage device 100 using theoperating system 109 and thedriver 107. For example, write requests generated by theapplication 113 and garbage collection commands may be processed through theoperating system 109 and thedriver 107 using one of the driver buffer pairs. - In one exemplary implementation, the
command processor 122 may assign an identifier to the command to indicate to which buffer pair it is associated. Thecommand processor 122 may be configured to direct responses to the appropriate response buffer using the assigned identifier. Similarly, the interruptprocessor 124 may be configured to generate an interrupt associated with the appropriate response buffer using the assigned identifier. - In one exemplary implementation, the
controller 110 may include multiple interruptprocessors 124 such that each command buffer and response buffer pair is associated with one of the interruptprocessors 124. In this manner, each buffer pair may have one or more different interrupt mechanisms enabled on a per buffer pair basis. - Referring to
FIG. 2 , a block diagram of an exemplary interruptprocessor 124 is illustrated. The interruptprocessor 124 may be configured to generate and send interrupts based on the interrupts mechanism or mechanisms enabled by thehost 106. The interruptprocessor 124 may include aResponseNew counter 280, alast response timer 282, group counters 284 and interruptsend logic 286. - The
ResponseNew counter 280 may be enabled by thehost 106 when the watermark interrupt mechanism is desired. Thehost 106 may set theResponseMark 288, which is a parameter provided as input to theReponseNew counter 280, as discussed above. TheResponseNew counter 280 receives as inputs information including when a packet is transferred to thehost 106, when the ResponseHead is updated, the number of outstanding responses in thehost response buffer 123 and when an interrupt has been sent. TheResponseNew counter 280 is configured to track the number of responses transferred to thehost 106 that the host has yet to process. Each time a response is transferred to theresponse buffer 123 the counter is incremented. When thecounter 280 reaches or exceed the watermark level set by thehost 106, i.e., theResponseMark 288, then a watermark trigger is generated and sent to the interruptsend logic 286. The watermark level, i.e., theResponseMark 288, is the number of new responses in theresponse buffer 123 needed to generate an interrupt. If thehost 106 removes new responses from theresponse buffer 123, they do not count toward meeting the watermark level. When an interrupt is generated, the count toward the ResponseMark is reset. - If the watermark interrupt mechanism is the only interrupt enabled, when the watermark is reached, then the interrupt
send logic 286 generates and sends an interrupt to thehost 106. No further interrupts will be sent until thehost 106 acknowledges the interrupt and updates the ResponseHead. The updated ResponseHead is communicated to the interruptsend logic 286 as a clear interrupt signal. If other interrupt mechanisms also are enabled, then the interruptsend logic 286 may generate and send an interrupt to thehost 106 taking into account the other enabled interrupt mechanisms as well. - The
last response timer 282 may be enabled when the timer interrupt mechanism is desired. Thelast response timer 282 may be configured to keep track of time since the last interrupt. For instance, thelast response timer 282 may track the amount of time since the last interrupt in microseconds. Thehost 106 may set the amount of time using a parameter, for example, aResponseDelay parameter 290. In one exemplary implementation, theResponseDelay 290 timeout may be the number of microseconds since the last interrupt, or since the last time that thehost 106 removed new responses from theresponse buffer 123, before an interrupt is generated. - The
last response timer 282 receives as input a signal indicating when an interrupt is sent. Thelast response timer 282 also may receive a signal when the ResponseHead is updated, which indicates that thehost 106 has removed responses from theresponse buffer 123. An interrupt may be generated only if theresponse buffer 123 contains outstanding responses. - The
last response timer 282 is configured to generate a timeout trigger when the amount of time being tracked by thelast response timer 282 is greater than theResponseDelay parameter 290. When this occurs and theresponse buffer 123 contains new responses, then a timeout trigger signal is sent to the interruptsend logic 286. If thelast response timer 282 is the only interrupt mechanism enabled, then the interruptsend logic 286 generates and sends an interrupt to the host. If other interrupt mechanisms also are enabled, then the interruptsend logic 286 may take into account the other interrupt mechanisms as well. - Each interrupt mechanism includes an enable bit and the interrupt
send logic 286 may be configured to generate an interrupt when an interrupt trigger is asserted for an enabled interrupt mechanism. The logic may be configure not to generate another interrupt until thehost 106 acknowledges the interrupt and updates the ResponseHead. TheQueue Control parameter 292 may provide input to the interruptsend logic 286 to indicate the status of the interrupt mechanisms such as which of the interrupt mechanisms are enabled and which of the interrupt mechanisms are disabled. - The group counters 284 mechanism may be arranged and configured to track commands that are part of a group as designated by the
driver 107. The group counters 284 may be enabled by thehost 106 when thehost 106 desires to track commands as part of a group such that a single interrupt is generated and sent back to thehost 106 only when all of the commands in a group are processed. In this manner, an interrupt is not generated for each of the individual commands but only for the group of commands. - The group counters 284 may be configured with multiple counters to enable the tracking of multiple different groups of commands. In one exemplary implementation, the group counters 284 may be configured to track up to and including 128 different groups of commands. In this manner, for each group of commands there is a counter. The number of counters may be related to the number of group numbers that may be designated using the interrupt group field in the command header.
- The group counters 284 may be configured to operate to increment the counter for a group when a new command for the group has entered the
command processor 122. The group counters 284 may decrement the counter for a group when one of the commands in the group has completed processing. In this manner of incrementing as new commands enter for a group and decrementing when commands are completed for the group, the number of commands in each group is potentially unlimited. The counters do not need to be sized to account for the largest number of potential commands in a group. Instead, the counters may be sized based on the number of commands that thedata storage device 100 may potentially process at one time, which may be smaller than the unlimited number of commands in a particular group. - In one exemplary implementation, each of the group counters 284 may track the commands in a specific group using the group number assigned by the
driver 107 and appearing in the interrupt group field in the command header of each command. The group counters 284 receive a signal each time a command having a group number enters thecommand processor 122 for processing. In response to this signal, the counter increments for that group. The group counters 284 also receive a signal each time a command having a group number completes processing. In response to this signal, the counter decrements for that group. - The last command in the command group may be marked by the
driver 107 with a flag to indicate to the group counters 284 that the command is the last command in the group. In one exemplary implementation, the last bit in the interrupt group field in the command header may be used as the flag. The group counters 284 are configured to recognize when the flag is set. In this manner, the group counters 284 keep a counter of the number of commands in a particular group that are in processing in thedata storage device 100. The group counters 284 also track when the end of the group has been seen. - When a command is sent from the
host 106 to thedata storage device 100, the counter for its interrupt group is incremented. When a response is sent from thedata storage device 100 to thehost 106, the counter for its interrupt group is decremented. When the last command in the group is received at the groups counters 284 and the count for that group goes to zero, the group trigger signal is generated and sent to the interruptsend logic 286. When the group trigger signal is received at the interruptsend logic 286, then an interrupt is sent to thehost 106. The group counters 284 then clear the end group flag for that group. - The
driver 107 may be configured to track the groups in use. Thedriver 107 may not re-use an interrupt group number until the previous commands to use that interrupt group have all completed and the interrupt has been acknowledged. - In one exemplary implementation, the
driver 107 may be configured to determine dynamically how many interrupts it wants to have generated. For example, thedriver 107 may dynamically determine the size of a command group depending on various criteria including, for instance, volume, latency and other factors on thehost 106. - In one exemplary implementation, the interrupt
send logic 286 may be configured to consolidate multiple interrupts for multiple interrupt groups and only send a single interrupt for multiple groups of commands. -
FIG. 3 is a block diagram of acommand processor 122. Thecommand processor 122 may include aslot tracker module 302, acommand transfer module 304, a pendingcommand module 306, acommand packet memory 308, and atask dispatch module 310. Thecommand processor 122 may be implemented in hardware, software or a combination of hardware and software. In one exemplary implementation, thecommand processor 122 may be implemented as a part of a field programmable gate array (FPGA) controller. The FPGA controller may be configured using firmware or other instructions to program the FPGA controller to perform the functions discussed herein. - The
command processor 122 may be arranged and configured to retrieve commands from a host and to queue and order the commands from the host for processing by various storage locations. In one exemplary implementation, thecommand processor 122 may be configured to retrieve commands from each of the command buffers 219 a-219 n using a round robin scheme. In another exemplary implementation, thecommand processor 122 may be configured to retrieve commands from each of the command buffers 219 a-219 n using a priority scheme, where the priority of a particular command buffer may be designated by thehost 106. In other exemplary implementations, thecommand processor 122 may be configured to retrieve commands from each of the command buffers 219 a-219 n. - The
command processor 122 may be configured to maximize the availability of the storage locations by attempting to keep all or substantially all of the storage locations busy. Thecommand processor 122 may be configured to dispatch commands designated for the same storage location in order such that the order of the commands received from the host is preserved. Thecommand processor 122 may be configured to reorder and dispatch commands designated for different storage locations out of order. In this manner, the commands received from the host may be processed in parallel by reordering the commands designated for different storage locations and, at the same time, the order of the commands designated for the same storage location is preserved. - In one exemplary implementation, the
command processor 122 may use an ordered list to queue and order the commands from the host. In one exemplary implementation, the ordered list may be sorted and/or otherwise ordered based on the age of the commands from the host. For instance, as new commands are received from the host, those commands are placed at the bottom of the ordered list in the order that they were received from the host. In this manner, commands that are dependent on order (e.g., commands designated for the same storage location) are maintained in the correct order. - In one exemplary implementation, the storage locations may include multiple flash memory chips. The flash memory chips may be arranged and configured into multiple channels with each of the channels including one or more of the flash memory chips. The
command processor 122 may be arranged and configured to dispatch commands designated for the same channel and/or the same flash memory chip in order based on the ordered list. Also, thecommand processor 122 may be arranged and configured to dispatch commands designated for different channels and/or different flash memory chips out of order. In this manner, thecommand processor 122 may, if needed, reorder the commands from the ordered list so that the channels and the flash memory chips may be kept busy at the same time. This enables the commands from the host to be processed in parallel and enables more commands to be processed at the same time on different channels and different flash memory chips. - The commands from the host may be dispatched and tracked under the control of a driver (e.g.,
driver 107 ofFIG. 1A andFIG. 1B ), where the driver may be a computer program product that is tangibly embodied on a storage medium and may include instructions for generating and dispatching commands from the host (e.g., host 106 ofFIG. 1A andFIG. 1B ). The commands from the host may designate a specific storage location, for example, a specific flash memory chip and/or a specific channel. From the host perspective, it may be important that commands designated for the same storage location be executed in the order as specified by the host. For example, it may be important that certain operations generated by the host occur in order on a same flash memory chip. For example, the host may generate and send an erase command and a write command for a specific flash memory chip, where the host desires that the erase command occurs first. It is important that the erase operation occurs first so that the data associated with the write command doesn't get erased immediately after it is written to the flash memory chip. - As another example, for flash memory chips, it may be important to write to pages of an erase block in order. This operation may include multiple commands to perform the operation on the same flash memory chip. In this example, it is necessary to perform these commands for this operation in the order specified by the host. For instance, a single write operation may include more than sixty commands. The
command processor 122 may be configured to ensure that commands to the same flash memory chip are performed in order using the ordered list. - In one exemplary implementation, the
command processor 122 may be configured to track a number of commands being processed. Thecommand processor 122 may be configured to track a number of available slots for commands to be received and processed. One of the components of thecommand processor 122, theslot tracker module 302, may be configured to track available slots for commands from the host. Theslot tracker module 302 may keep track of the open slots, provide the slots to new commands transferred from the host and designate the slots as open upon completion of the commands. - In one exemplary implementation, the
slot tracker module 302 may include a fixed number of slots, where each slot may be designated for a single command. For example, theslot tracker module 302 may include 128 slots. In other exemplary implementations, theslot tracker module 302 may include a different number of fixed slots. Also, for example, the number of slots may be variable or configurable. Theslot tracker module 302 may be implemented as a register or memory module in software, hardware or a combination of hardware and software. - The
slot tracker module 302 may include a list of slots, where each of the slots is associated with a global slot identifier. As commands are received from the host, the commands are assigned to an available slot and associated with the global slot identifier for that slot. Theslot tracker module 302 may be configured to assign each of the commands a global slot identifier, where the number of global slot identifier is fixed to match the number of slots in theslot tracker module 302. The command is associated with the global slot identifier throughout its processing until the command is completed and the slot is released. In one exemplary implementation, the global slot identifier is a tag associated with a particular slot that is assigned to a command that fills that particular slot. The tag is associated with the command and remains with the command until processing of the command is complete and the slot it occupied is released and made available to receive a new command. The commands may not be placed in order of slots, but instead may be placed in any of the available slots and assigned the global slot identifier associated with that slot. - In one exemplary implementation, one of the components of the
command processor 122, thecommand transfer module 304, may be configured to retrieve new commands from the host based on a number of available slots in theslot tracker module 302 and an availability of new commands at the host. In one exemplary implementation, thecommand transfer module 304 may be implemented as a state machine. - The
slot tracker module 302 may provide information to thecommand transfer module 304 regarding the number of available slots. Also, thecommand transfer module 304 may query theslot tracker module 302 regarding the number of available slots. - In one exemplary implementation, the
command transfer module 304 may use acommand tail pointer 312 and acommand head pointer 314 to indicate when and how many new commands are available at the host for retrieval. Thecommand transfer module 304 may compare thecommand tail pointer 312 and thecommand head pointer 314 to determine whether there are commands available for retrieval from the host. If thecommand tail pointer 312 and thecommand head pointer 314 are equal, then no commands are available for transfer. If thecommand tail pointer 312 is greater than thecommand head pointer 314, then commands are available for transfer. - In one exemplary implementation, the
command tail pointer 312 and thecommand head pointer 314 may be implemented as registers that are configured to hold a pointer value and may be a part of thecommand processor 122. Thecommand tail pointer 314 may be written to by the host. For example, the driver may use a memory mapped input/output (MMIO) write to update thecommand tail pointer 312 when commands are available at the host for retrieval. As commands are retrieved from the host, thecommand transfer module 304 updates thecommand head pointer 314. - When the conditions of available slots and available commands at the host are met, the
command transfer module 304 may retrieve some or all of the available commands from the host. In one exemplary implementation, thecommand transfer module 304 may retrieve a group of commands in a single access. For example, thecommand transfer module 304 may be configured to retrieve a group of eight commands at a time using a direct memory access (DMA) operation from the host. When the commands are retrieved, thecommand transfer module 304 updates thecommand head pointer 314. The commands may be retrieved from the host through thebus master 316. Thecommand transfer module 304 also may write to a host command head pointer (not shown) through thebus master 316 using a DMA operation to update the host command head pointer. - The
queue control 318 may be configured to enable and disable thecommand transfer module 304. Thequeue control 318 may be implemented as a register that receives instructions from the host through the driver. Thequeue control 318 may be a component of thecommand processor 122. When thequeue control 318 register is set to enable, then thecommand transfer module 304 may retrieve and process commands from the host. The driver controls the setting of thequeue control 318 so that thecommand transfer module 304 retrieves commands only when the host is ready and has provided the indication that it is ready. When thequeue control 318 register is set to disable, then thecommand transfer module 304 may not retrieve and process command from the host. - The retrieved commands are each assigned to one of the available slots by the
slot tracker module 302 and associated with the global slot identifier for that available slot. The data for the commands may be stored in thecommand packet memory 308. For example, thecommand packet memory 308 may be implemented as a fixed buffer that is indexed by global slot identifier. The data for a particular command may be stored in thecommand packet memory 308 and indexed by its assigned global slot identifier. The data for a particular command may remain in thecommand packet memory 308 until the command is dispatched to the designated storage location by thetask dispatch module 310. - The
command transfer module 304 also may be configured to provide other components of a controller with information related to the commands as indexed by slot. For example, thecommand transfer module 304 may provide data to a DMA engine. Thecommand transfer module 304 also may provide status packet header data to a status processor. Thecommand transfer module 304 may provide interrupt group data to an interrupt processor. For example, thecommand transfer module 304 may transfergroup information 319 to the interrupt processor (e.g., interruptprocessor 124 ofFIGS. 1A and 2 ). - The pending
command module 306 may be configured to queue and order the commands using an ordered list that is based on an age of the commands. In one exemplary implementation, the pendingcommand module 306 may be implemented as a memory module that is configured to store multiple pointers to queue and order the commands. The pendingcommand module 306 may include a list of the global slot identifiers for the commands that are pending along with a storage location identifier. For example, the storage location identifier may include the designated storage location for where the command is to be processed. The storage location identifier may include a channel identifier and/or a flash memory chip identifier. The storage location identifier is a part of the command and is assigned by the host through its driver. - When a new command is retrieved, the global slot identifier and storage location information are added to the bottom of the ordered list in the pending
command module 306. As discussed above, the data for the commands is stored in thecommand packet memory 308 and indexed by the global slot identifier. When the command is added to the ordered list, a pointer to the previous command is included with the command. Also included is a pointer to the next command. In this manner, each item in the ordered list includes a global task identifier, a storage location identifier, a pointer to the previous command and a pointer to the next command. In this exemplary implementation, the ordered list may be referred to as a doubly linked list. The ordered list is a list of the commands ordered from oldest to newest. - The
task dispatch module 310 is configured to remove commands from the ordered list in the pendingcommand module 306 and to dispatch them to the appropriate storage location for processing. Thetask dispatch module 310 may receive input from the storage locations to indicate that they are ready to accept new commands. In one exemplary implementation, thetask dispatch module 310 may receive one ormore signals 320 such as signals indicating that one or more of the storage locations are ready to accept new commands. The pendingcommand module 306 may be configured to start at the top of the ordered list with the oldest command first and to make that command available to thetask dispatch module 310. The pendingcommand module 306 may continue to make commands available to thetask dispatch module 310 in order using the ordered list until a command is removed from the list by thetask dispatch module 310. After a command is removed from the ordered list in the pendingcommand module 306, the pendingcommand module 306 plays back the commands remaining in the list to thetask dispatch module 310 starting again at the top of the ordered list. - The
task dispatch module 310 may be configured to start at the top of the ordered list with the oldest command first and determine whether the storage location is available to receive new commands using thesignals 320. If the storage location is ready, then thetask dispatch module 310 retrieves the command data from thecommand packet memory 308 and communicates the command data and a storage locationselect signal 322 to the storage location. The pendingcommand module 306 then updates the ordered list and the pointers to reflect that the command was dispatched for processing. Once a command has been dispatched, thetask dispatch module 310 starts at the top of the ordered list again. - If the storage location is not ready to receive new commands, then the
task dispatch module 310 moves to the next command on the ordered list. Thetask dispatch module 310 determines if the next command is to the same or a different storage location than the skipped command. If the next command is to a same storage location as a skipped command, then thetask dispatch module 310 also will skip this command. In this manner, the commands designated for the same storage location are dispatched and processed in order, as received from the host. Thetask dispatch module 310 preserves the order of commands designated for the same storage location. If the commands are designated for a different storage location, thetask dispatch module 310 again determines if the storage location for the next command on the list is ready to accept the new command. If thetask dispatch module 310 receives asignal 320 that the storage location is ready to accept a new command, then the command is dispatched by thetask dispatch module 310 from thecommand packet memory 308 to the storage location along with a storage locationselect signal 322. The pendingcommand module 306 removes the dispatched command from the ordered list and updates the ordered list including updating the pointers that were associated with the command. In this manner, the remaining pointers are linked together upon removal of the dispatched command. - Referring also to
FIG. 4 , a block diagram of the pendingcommand module 306 is illustrated. The pendingcommand module 306 may include asingle memory module 402 having multiple ports, port A and port B. Thememory module 402 may store information related to the pending commands, including the pointer information for each command, where the pointer information may point to the next command and the previous command. - In operation, the
command transfer module 304 ofFIG. 3 sends anew entry request 406 for a new command to be added to the ordered list to the pendingcommand module 306. Thenew entry request 406 is received by anew entry module 408. In one exemplary implementation, thenew entry module 408 may be implemented as a state machine. - The
new entry module 408 receives thenew entry request 406 and adds it to the ordered list at the end of the list as the newest command inmemory module 402. Also, thenew entry module 408 requests pointers from the freepointer list module 410. The freepointer list module 410 may be implemented as a first-in, first-out (FIFO) memory that maintains a list of pointers that can be used for new entries. When thenew entry module 408 requests pointers from the freepointer list module 410, the freepointer list module 410 provides anext entry pointer 412 to thenew entry module 408. Thenext entry pointer 412 is a pointer to where the entry following the current new entry will reside on the ordered list. The current new entry in the list points to this address as its next address. - The
new entry pointer 414 is a pointer to where the next new entry will reside on the ordered list, which was the previous entry'snext entry pointer 412. The last entry in the list points to this address as its next address. Thememory module 402 stores the data fields related to the commands and the pointers. When a new entry is added, anend pointer 420 also is updated. - For example, if an entry “X” is to be added, the
next entry pointer 412 points to the next entry “Y” and thenew entry pointer 414 points to the current entry that is to be added, “X”. After “X” is entered and an entry “Y” is to be added, thenext entry pointer 412 points to the next entry “Z” and thenew entry pointer 414 points to the current entry that is to be added, “Y”. - When the
task dispatch module 310 ofFIG. 3 determines that an entry is to be removed from the ordered list in thememory module 402, the task dispatch module sends adeletion request 416. The deletion request is received by an entry playback anddeletion module 418. The entry playback anddeletion module 418 may be configured to start at the top of the ordered list with the oldest command first and to make that command available to thetask dispatch module 310. The entry playback anddeletion module 418 may continue to make commands available to thetask dispatch module 310 in order using the ordered list until a command is removed from the list by thetask dispatch module 310. After a command is removed from the ordered list, the entry playback anddeletion module 418 causes thememory module 402 to dispatch the command and remove it from the ordered list. The pointers are then freed up and the entry playback anddeletion module 418 provides an indication to the freepointer list module 410 that the pointers for the removed command are free. The entry playback anddeletion module 418 also updates the pointers in thememory module 402 when the command is removed to maintain the correct order of the list. The entry playback anddeletion module 418 also plays back the commands remaining in the list to thetask dispatch module 310 starting again at the top of the ordered list. - In one exemplary implementation, the entry playback and
deletion module 418 may be implemented as a state machine. The entry playback anddeletion module 418 also receives an input of theend pointer 420 from thenew entry module 408. Theend pointer 420 may be used when the entry playback anddeletion module 418 is making commands available to thetask dispatch module 310 and when a last entry in the ordered list is removed from the list. In this manner, theend pointer 420 may be updated to point to the end of the ordered list. - Referring back to
FIG. 1A , in one exemplary implementation, thecontroller board 102, which is its own PCB, may be located physically between each of thememory boards FIG. 5 , thedata storage device 100 may include thememory board 104 a on one PCB, thecontroller board 102 on a second PCB, and thememory board 104 b on a third PCB. Thememory board 104 a includes multipleflash memory chips 118 a and thememory board 104 b includes multipleflash memory chips 118 b. Thecontroller board 102 includes thecontroller 110 and theinterface 108 to the host (not shown), as well as other components (not shown). - In the example illustrated by
FIG. 5 , thememory board 104 a may be operably connected to thecontroller board 102 and located on oneside 520 a of thecontroller board 102. For instance, thememory board 104 a may be connected to atop side 520 a of thecontroller board 102. Thememory board 104 b may be operably connected to thecontroller board 102 and located on asecond side 520 b of thecontroller board 102. For instance, thememory board 104 b may be connected to abottom side 520 b of thecontroller board 102. - Other physical and/or electrical connection arrangements between the
memory boards controller board 102 are possible.FIG. 5 merely illustrates one exemplary arrangement. For example, thedata storage device 100 may include more than two memory board such as three memory boards, four memory boards or more memory boards, where all of the memory boards are connected to a single controller board. In this manner, the data storage device may still be configured in a disk drive form factor. Also, the memory boards may be connected to the controller board in other arrangements such as, for instance, the controller board on the top and the memory cards on the bottom or the controller board on the bottom and the memory cards on the top. - The
data storage device 100 may be arranged and configured to cooperate with a computing device. In one exemplary implementation, thecontroller board 102 and thememory boards FIG. 6 , two exemplary computing devices are illustrated, namely aserver 630 and aserver 640. Theservers servers FIG. 1A andFIG. 1B ) that includes computer program products having instructions that cause one or more processors in theservers FIG. 1A andFIG. 1B ) that are operating on the server. For instance, theservers server 630 may be configured to be a rack-mounted server that operates within a server rack. Theserver 640 may be configured to be a stand-alone server that operates independent of a server rack. Even though theserver 640 is not within a server rack, it may be configured to operate with other servers and may be operably connected to other servers.Servers - In one exemplary implementation, the
data storage device 100 ofFIGS. 1A , 1B and 5 may be sized to fit within adrive bay 635 of theserver 630 or thedrive bay 645 of theserver 640 to provide data storage functionality for theservers data storage device 100 may be sized to a 3.5″ disk drive form factor to fit in thedrive bays data storage device 100 also may be configured to other sizes. Thedata storage device 100 may operably connect and communicate with theservers 630 and 560 using theinterface 108. In this manner, the host may communicate commands to thecontroller board 102 using theinterface 108 and thecontroller 110 may execute the commands using theflash memory chips memory boards - Referring back to
FIG. 1A , theinterface 108 may include a high speed interface between thecontroller 110 and thehost 106. The high speed interface may enable for fast transfers of data between thehost 106 and theflash memory chips PCIe interface 108 may include a connector to thehost 106 such as, for example, a PCIe connector cable assembly. Other high speed interfaces, connectors and connector assemblies also may be used. - In one exemplary implementation, the communication between the
controller board 102 and theflash memory chips memory boards multiple channels 112. Each of thechannels 112 may communicate with one or moreflash memory chips controller 110 may be configured such that commands received from thehost 106 may be executed by thecontroller 110 using each of thechannels 112 simultaneously or at least substantially simultaneously. In this manner, multiple commands may be executed simultaneously ondifferent channels 112, which may improve throughput of thedata storage device 100. - In the example of
FIG. 1A , twenty (20)channels 112 are illustrated. The completely solid lines illustrate the ten (10) channels between thecontroller 110 and theflash memory chips 118 a on thememory board 104 a. The mixed solid and dashed lines illustrate the ten (10) channels between thecontroller 110 and theflash memory chips 118 b on thememory board 104 b. As illustrated inFIG. 1A , each of thechannels 112 may support multiple flash memory chips. For instance, each of thechannels 112 may support up to 32 flash memory chips. In one exemplary implementation, each of the 20 channels may be configured to support and communicate with 6 flash memory chips. In this example, each of thememory boards flash memory chips data storage device 100 may be configured to store up to and including multiple terabytes of data. - The
controller 110 may include a microcontroller, a FPGA controller, other types of controllers, or combinations of these controllers. In one exemplary implementation, thecontroller 110 is a microcontroller. The microcontroller may be implemented in hardware, software, or a combination of hardware and software. For example, the microcontroller may be loaded with a computer program product from memory (e.g., memory module 116) including instructions that, when executed, may cause the microcontroller to perform in a certain manner. The microcontroller may be configured to receive commands from thehost 106 using theinterface 108 and to execute the commands. For instance, the commands may include commands to read, write, copy and erase blocks of data using theflash memory chips - In another exemplary implementation, the
controller 110 is a FPGA controller. The FPGA controller may be implemented in hardware, software, or a combination of hardware and software. For example, the FPGA controller may be loaded with firmware from memory (e.g., memory module 116) including instructions that, when executed, may cause the FPGA controller to perform in a certain manner. The FPGA controller may be configured to receive commands from thehost 106 using theinterface 108 and to execute the commands. For instance, the commands may include commands to read, write, copy and erase blocks of data using theflash memory chips - In one exemplary implementation, the FPGA controller may support
multiple interfaces 108 with thehost 106. For instance, the FPGA controller may be configured to support multiple PCIe x4 or PCIe x8 interfaces with thehost 106. - The
memory module 116 may be configured to store data, which may be loaded to thecontroller 110. For instance, thememory module 116 may be configured to store one or more images for the FPGA controller, where the images include firmware for use by the FPGA controller. Thememory module 116 may interface with thehost 106 to communicate with thehost 106. Thememory module 116 may interface directly with thehost 106 and/or may interface indirectly with thehost 106 through thecontroller 110. For example, thehost 106 may communicate one or more images of firmware to thememory module 116 for storage. In one exemplary implementation, thememory module 116 includes an electrically erasable programmable read-only memory (EEPROM). Thememory module 116 also may include other types of memory modules. - The
power module 114 may be configured to receive power (Vin), to perform any conversions of the received power and to output an output power (Vout). Thepower module 114 may receive power (Vin) from thehost 106 or from another source. Thepower module 114 may provide power (Vout) to thecontroller board 102 and the components on thecontroller board 102, including thecontroller 110. Thepower module 114 also may provide power (Vout) to thememory boards memory boards flash memory chips - In one exemplary implementation, the
power module 114 may include one or more direct current (DC) to DC converters. The DC to DC converters may be configured to receive a power in (Vin) and to convert the power to one or more different voltage levels (Vout). For example, thepower module 114 may be configured to receive +12 V (Vin) and to convert the power to 3.3 v, 1.2 v, or 1.8 v and to supply the power out (Vout) to thecontroller board 102 and to thememory boards - The
memory boards flash memory chips flash memory chips 118 a and theflash memory chips 118 b may be the same type of flash memory chips including requiring the same voltage from thepower module 114 and being from the same flash memory chip vendor. The terms vendor and manufacturer are used interchangeably throughout this document. - In another exemplary implementation, the
flash memory chips 118 a on thememory board 104 a may be a different type of flash memory chip from theflash memory chips 118 b on thememory board 104 b. For example, thememory board 104 a may include SLC NAND flash memory chips and thememory board 104 b may include MLC NAND flash memory chips. In another example, thememory board 104 a may include flash memory chips from one flash memory chip manufacturer and thememory board 104 b may include flash memory chips from a different flash memory chip manufacturer. The flexibility to have all the same type of flash memory chips or to have different types of flash memory chips enables thedata storage device 100 to be tailored to different application(s) 113 being used by thehost 106. - In another exemplary implementation, the
memory boards memory board 104 a may include both SLC NAND chips and MLC NAND chips on the same PCB. Similarly, thememory board 104 b may include both SLC NAND chips and MLC NAND chips. In this manner, thedata storage device 100 may be advantageously tailored to meet the specifications of thehost 106. - In another exemplary implementation, the
memory boards memory boards memory boards - The
memory modules memory boards flash memory chips memory modules - In one exemplary implementation, the
memory modules memory boards controller board 102, then the device characteristics may be read from the EEPROMs such that thecontroller 110 may automatically recognize the types offlash memory chips controller 110 is controlling. Additionally, the device characteristics may be used to configure thecontroller 110 to the appropriate parameters for the specific type or types offlash memory chips - Referring to
FIG. 7 , aprocess 700 is illustrated for communicating commands between a host and a flash memory data storage device.Process 700 may include populating a circular command queue of a driver of the host with commands for retrieval by the data storage device (702). Commands can be sent from the circular command queue to the data storage device via a direct memory access operation (704). A direct memory access operation initiated by the data storage device can be used to populate a circular response queue of the host with responses by the data storage device for retrieval by the host device, where each response acknowledges the reception of a command from the host by the data storage device (706). And responses can be consumed from the circular response queue at the host (708). - Implementations of the various techniques described herein may be implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in combinations of them. Implementations may be implemented as a computer program product, i.e., a computer program tangibly embodied in an information carrier, e.g., in a machine-readable storage device, for execution by, or to control the operation of, data processing apparatus, e.g., a programmable processor, a computer, or multiple computers. A computer program, such as the computer program(s) described above, can be written in any form of programming language, including compiled or interpreted languages, and can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.
- Method steps may be performed by one or more programmable processors executing a computer program to perform functions by operating on input data and generating output. Method steps also may be performed by, and an apparatus may be implemented as, special purpose logic circuitry, e.g., a FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. Elements of a computer may include at least one processor for executing instructions and one or more memory devices for storing instructions and data. Generally, a computer also may include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. Information carriers suitable for embodying computer program instructions and data include all forms of non-volatile memory, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory may be supplemented by, or incorporated in special purpose logic circuitry.
- To provide for interaction with a user, implementations may be implemented on a computer having a display device, e.g., a cathode ray tube (CRT) or liquid crystal display (LCD) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- Implementations may be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation, or any combination of such back-end, middleware, or front-end components. Components may be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.
- While certain features of the described implementations have been illustrated as described herein, many modifications, substitutions, changes and equivalents will now occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the scope of the embodiments.
Claims (16)
1. A host device configured for storing data on, and retrieving data from, a flash memory data storage device, the host device comprising:
a driver that is arranged and configured to communicate commands to the data storage device; and
a circular command queue that is populated with commands for retrieval by the data storage device, and
a circular response queue that is populated with responses by the data storage device for retrieval by the host device, wherein each response acknowledges the reception of a command from the host by the data storage device.
2. The host device of claim 1 , wherein the circular command queue includes a command head pointer and a command tail pointer and wherein the circular response queue includes a response head pointer and a response tail pointer, the host device further comprising:
a first register configured to store command head pointer values; and
a second register configured to store response tail pointer values.
3. The host device of claim 1 , wherein the data storage device includes:
a third register configured to store command tail pointer values; and
a fourth register configured to store response head pointer values.
4. The host device of claim 3 , wherein the third register exists in a memory mapped address space of the data storage device and wherein the driver is configured to write updated command tail pointer values to the third register.
5. The host device of claim 4 , wherein the driver is configured to send commands to the storage device in response to a direct memory access request from the data storage device, and wherein the first register is configured to receive updated command head pointer values in response to a direct memory access operation received from the data storage device.
6. The host device of claim 2 , wherein the second register exists in the address space of the host device and wherein the second register is configured to receive updated response tail pointer values from the data storage device into the second register.
7. The host device of claim 6 , wherein the driver is configured to receive responses from the storage device through a direct memory access operation sent from the data storage device, and wherein the driver is configured to send updated response head pointer values to the data storage device via a write to a Memory Mapped register.
8. The host device of claim 1 further comprising:
an application that is configured to generate input and output requests; and
an operating system that is operably coupled to the driver and to the application and that is configured to communicate the input and output requests between the application and the driver.
9. A method for communicating commands between a host and a flash memory data storage device, the method comprising:
populating a circular command queue of a driver on the host with commands for retrieval by the data storage device;
transferring commands from the circular command queue to the data storage device via a device initiated direct memory access operation;
populating, via a direct memory access operation initiated by the data storage device, a circular response queue of the host with responses by the data storage device for retrieval by the host device, wherein each response acknowledges the reception of a command from the host by the data storage device; and
consuming responses from the circular response queue at the host.
10. The method of claim 9 , wherein the circular command queue includes a command head pointer and a command tail pointer and wherein the circular response queue includes a response head pointer and a response tail pointer, the method further comprising:
storing command head pointer values in a first register of the host; and
storing response tail pointer values in a second register of the host.
11. The method of claim 9 , wherein the data storage device includes:
a third register configured to store command tail pointer values; and
a fourth register configured to store response head pointer values.
12. The method of claim 11 , wherein the third register exists in a memory mapped address space of the data storage device, the method further comprising writing updated command tail pointer values to the third register.
13. The method of claim 12 , further comprising receiving updated command head pointer values into the first register in response to a direct memory access operation received from the data storage device.
14. The method of claim 10 , wherein the second register exists in the address space of the host device, the method further comprising receiving updated response tail pointer values into the second register from the data storage device.
15. The method of claim 14 , further comprising:
receiving responses from the storage device through a direct memory access operation sent from the data storage device; and
sending updated response head pointer values to the data storage device via a write to a Memory Mapped register.
16. The method of claim 9 further comprising:
generating input and output requests from an application running on the host; and
communicating the input and output requests from an application running on the host through an operating system to the driver.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/756,477 US20100262979A1 (en) | 2009-04-08 | 2010-04-08 | Circular command queues for communication between a host and a data storage device |
Applications Claiming Priority (7)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16770909P | 2009-04-08 | 2009-04-08 | |
US18783509P | 2009-06-17 | 2009-06-17 | |
US12/537,733 US8380909B2 (en) | 2009-04-08 | 2009-08-07 | Multiple command queues having separate interrupts |
US30446810P | 2010-02-14 | 2010-02-14 | |
US30447510P | 2010-02-14 | 2010-02-14 | |
US30446910P | 2010-02-14 | 2010-02-14 | |
US12/756,477 US20100262979A1 (en) | 2009-04-08 | 2010-04-08 | Circular command queues for communication between a host and a data storage device |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/537,733 Continuation-In-Part US8380909B2 (en) | 2009-04-08 | 2009-08-07 | Multiple command queues having separate interrupts |
Publications (1)
Publication Number | Publication Date |
---|---|
US20100262979A1 true US20100262979A1 (en) | 2010-10-14 |
Family
ID=42935370
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/756,477 Abandoned US20100262979A1 (en) | 2009-04-08 | 2010-04-08 | Circular command queues for communication between a host and a data storage device |
Country Status (1)
Country | Link |
---|---|
US (1) | US20100262979A1 (en) |
Cited By (99)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20080313364A1 (en) * | 2006-12-06 | 2008-12-18 | David Flynn | Apparatus, system, and method for remote direct memory access to a solid-state storage device |
US20100262773A1 (en) * | 2009-04-08 | 2010-10-14 | Google Inc. | Data striping in a flash memory data storage device |
US20100287217A1 (en) * | 2009-04-08 | 2010-11-11 | Google Inc. | Host control of background garbage collection in a data storage device |
US20110058440A1 (en) * | 2009-09-09 | 2011-03-10 | Fusion-Io, Inc. | Apparatus, system, and method for power reduction management in a storage device |
US8239713B2 (en) | 2009-04-08 | 2012-08-07 | Google Inc. | Data storage device with bad block scan command |
US20130121341A1 (en) * | 2010-03-17 | 2013-05-16 | Juniper Networks, Inc. | Multi-bank queuing architecture for higher bandwidth on-chip memory buffer |
US20130155080A1 (en) * | 2011-12-15 | 2013-06-20 | Qualcomm Incorporated | Graphics processing unit with command processor |
US8527693B2 (en) | 2010-12-13 | 2013-09-03 | Fusion IO, Inc. | Apparatus, system, and method for auto-commit memory |
US8554968B1 (en) | 2010-08-16 | 2013-10-08 | Pmc-Sierra, Inc. | Interrupt technique for a nonvolatile memory controller |
US8578127B2 (en) | 2009-09-09 | 2013-11-05 | Fusion-Io, Inc. | Apparatus, system, and method for allocating storage |
US8601222B2 (en) | 2010-05-13 | 2013-12-03 | Fusion-Io, Inc. | Apparatus, system, and method for conditional and atomic storage operations |
US20140047167A1 (en) * | 2012-08-08 | 2014-02-13 | Dong-Hun KWAK | Nonvolatile memory device and method of controlling suspension of command execution of the same |
US8719501B2 (en) | 2009-09-08 | 2014-05-06 | Fusion-Io | Apparatus, system, and method for caching data on a solid-state storage device |
US8725934B2 (en) | 2011-12-22 | 2014-05-13 | Fusion-Io, Inc. | Methods and appratuses for atomic storage operations |
US8756375B2 (en) | 2006-12-06 | 2014-06-17 | Fusion-Io, Inc. | Non-volatile cache |
WO2014093222A1 (en) * | 2012-12-10 | 2014-06-19 | Google Inc. | Using a logical to physical map for direct user space communication with a data storage device |
WO2014093220A1 (en) * | 2012-12-10 | 2014-06-19 | Google Inc. | Using a virtual to physical map for direct user space communication with a data storage device |
US8825937B2 (en) | 2011-02-25 | 2014-09-02 | Fusion-Io, Inc. | Writing cached data forward on read |
US20140258675A1 (en) * | 2013-03-08 | 2014-09-11 | Kabushiki Kaisha Toshiba | Memory controller and memory system |
US8874823B2 (en) | 2011-02-15 | 2014-10-28 | Intellectual Property Holdings 2 Llc | Systems and methods for managing data input/output operations |
US8935302B2 (en) | 2006-12-06 | 2015-01-13 | Intelligent Intellectual Property Holdings 2 Llc | Apparatus, system, and method for data block usage information synchronization for a non-volatile storage volume |
US8966191B2 (en) | 2011-03-18 | 2015-02-24 | Fusion-Io, Inc. | Logical interface for contextual storage |
US8972627B2 (en) | 2009-09-09 | 2015-03-03 | Fusion-Io, Inc. | Apparatus, system, and method for managing operations for data storage media |
US20150067291A1 (en) * | 2013-08-30 | 2015-03-05 | Kabushiki Kaisha Toshiba | Controller, memory system, and method |
US8984216B2 (en) | 2010-09-09 | 2015-03-17 | Fusion-Io, Llc | Apparatus, system, and method for managing lifetime of a storage device |
US9003104B2 (en) | 2011-02-15 | 2015-04-07 | Intelligent Intellectual Property Holdings 2 Llc | Systems and methods for a file-level cache |
US9021158B2 (en) | 2009-09-09 | 2015-04-28 | SanDisk Technologies, Inc. | Program suspend/resume for memory |
US9047178B2 (en) | 2010-12-13 | 2015-06-02 | SanDisk Technologies, Inc. | Auto-commit memory synchronization |
US9058123B2 (en) | 2012-08-31 | 2015-06-16 | Intelligent Intellectual Property Holdings 2 Llc | Systems, methods, and interfaces for adaptive persistence |
WO2015123413A1 (en) * | 2014-02-14 | 2015-08-20 | Micron Technology, Inc. | Command queuing |
US9116812B2 (en) | 2012-01-27 | 2015-08-25 | Intelligent Intellectual Property Holdings 2 Llc | Systems and methods for a de-duplication cache |
US9122579B2 (en) | 2010-01-06 | 2015-09-01 | Intelligent Intellectual Property Holdings 2 Llc | Apparatus, system, and method for a storage layer |
US9135192B2 (en) | 2012-03-30 | 2015-09-15 | Sandisk Technologies Inc. | Memory system with command queue reordering |
US9164702B1 (en) * | 2012-09-07 | 2015-10-20 | Google Inc. | Single-sided distributed cache system |
US20150332781A1 (en) * | 2014-05-19 | 2015-11-19 | Samsung Electronics Co., Ltd. | Nonvolatile memory system with improved signal transmission and reception characteristics and method of operating the same |
US9201677B2 (en) | 2011-05-23 | 2015-12-01 | Intelligent Intellectual Property Holdings 2 Llc | Managing data input/output operations |
US9208071B2 (en) | 2010-12-13 | 2015-12-08 | SanDisk Technologies, Inc. | Apparatus, system, and method for accessing memory |
US9218278B2 (en) | 2010-12-13 | 2015-12-22 | SanDisk Technologies, Inc. | Auto-commit memory |
US9223514B2 (en) | 2009-09-09 | 2015-12-29 | SanDisk Technologies, Inc. | Erase suspend/resume for memory |
US9251086B2 (en) | 2012-01-24 | 2016-02-02 | SanDisk Technologies, Inc. | Apparatus, system, and method for managing a cache |
US9274937B2 (en) | 2011-12-22 | 2016-03-01 | Longitude Enterprise Flash S.A.R.L. | Systems, methods, and interfaces for vector input/output operations |
US20160140684A1 (en) * | 2014-11-15 | 2016-05-19 | Intel Corporation | Sort-free threading model for a multi-threaded graphics pipeline |
US9348747B2 (en) | 2013-10-29 | 2016-05-24 | Seagate Technology Llc | Solid state memory command queue in hybrid device |
US9417804B2 (en) | 2014-07-07 | 2016-08-16 | Microsemi Storage Solutions (Us), Inc. | System and method for memory block pool wear leveling |
US9448881B1 (en) | 2013-01-29 | 2016-09-20 | Microsemi Storage Solutions (Us), Inc. | Memory controller and integrated circuit device for correcting errors in data read from memory cells |
US9450610B1 (en) | 2013-03-15 | 2016-09-20 | Microsemi Storage Solutions (Us), Inc. | High quality log likelihood ratios determined using two-index look-up table |
US20160306594A1 (en) * | 2012-09-14 | 2016-10-20 | Samsung Electronics Co., Ltd . | Host for controlling non-volatile memory card, system including the same, and methods operating the host and the system |
US9519540B2 (en) | 2007-12-06 | 2016-12-13 | Sandisk Technologies Llc | Apparatus, system, and method for destaging cached data |
US9563555B2 (en) | 2011-03-18 | 2017-02-07 | Sandisk Technologies Llc | Systems and methods for storage allocation |
US9600184B2 (en) | 2007-12-06 | 2017-03-21 | Sandisk Technologies Llc | Apparatus, system, and method for coordinating storage requests in a multi-processor/multi-thread environment |
US20170090824A1 (en) * | 2015-09-24 | 2017-03-30 | International Business Machines Corporation | Layered queue based coordination of potentially destructive actions in a dispersed storage network memory |
US9612966B2 (en) | 2012-07-03 | 2017-04-04 | Sandisk Technologies Llc | Systems, methods and apparatus for a virtual machine cache |
US20170132035A1 (en) * | 2015-11-10 | 2017-05-11 | Silicon Motion, Inc. | Storage device and task execution method thereof, and host corresponding to the storage device and task execution method thereof |
US9666244B2 (en) | 2014-03-01 | 2017-05-30 | Fusion-Io, Inc. | Dividing a storage procedure |
US9715465B2 (en) | 2014-10-28 | 2017-07-25 | Samsung Electronics Co., Ltd. | Storage device and operating method of the same |
US9753779B2 (en) | 2012-05-24 | 2017-09-05 | Renesas Electronics Corporation | Task processing device implementing task switching using multiple state registers storing processor id and task state |
US9799405B1 (en) | 2015-07-29 | 2017-10-24 | Ip Gem Group, Llc | Nonvolatile memory system with read circuit for performing reads using threshold voltage shift read instruction |
US9813080B1 (en) | 2013-03-05 | 2017-11-07 | Microsemi Solutions (U.S.), Inc. | Layer specific LDPC decoder |
US9824004B2 (en) | 2013-10-04 | 2017-11-21 | Micron Technology, Inc. | Methods and apparatuses for requesting ready status information from a memory |
US9842128B2 (en) | 2013-08-01 | 2017-12-12 | Sandisk Technologies Llc | Systems and methods for atomic storage operations |
US9842053B2 (en) | 2013-03-15 | 2017-12-12 | Sandisk Technologies Llc | Systems and methods for persistent cache logging |
US9886214B2 (en) | 2015-12-11 | 2018-02-06 | Ip Gem Group, Llc | Nonvolatile memory system with erase suspend circuit and method for erase suspend management |
US9892794B2 (en) | 2016-01-04 | 2018-02-13 | Ip Gem Group, Llc | Method and apparatus with program suspend using test mode |
US9899092B2 (en) | 2016-01-27 | 2018-02-20 | Ip Gem Group, Llc | Nonvolatile memory system with program step manager and method for program step management |
US9910777B2 (en) | 2010-07-28 | 2018-03-06 | Sandisk Technologies Llc | Enhanced integrity through atomic writes in cache |
US9933950B2 (en) | 2015-01-16 | 2018-04-03 | Sandisk Technologies Llc | Storage operation interrupt |
US9946607B2 (en) | 2015-03-04 | 2018-04-17 | Sandisk Technologies Llc | Systems and methods for storage error management |
US9977623B2 (en) | 2015-10-15 | 2018-05-22 | Sandisk Technologies Llc | Detection of a sequential command stream |
US10019320B2 (en) | 2013-10-18 | 2018-07-10 | Sandisk Technologies Llc | Systems and methods for distributed atomic storage operations |
US10073630B2 (en) | 2013-11-08 | 2018-09-11 | Sandisk Technologies Llc | Systems and methods for log coordination |
US10102144B2 (en) | 2013-04-16 | 2018-10-16 | Sandisk Technologies Llc | Systems, methods and interfaces for data virtualization |
US10108372B2 (en) | 2014-01-27 | 2018-10-23 | Micron Technology, Inc. | Methods and apparatuses for executing a plurality of queued tasks in a memory |
US10133663B2 (en) | 2010-12-17 | 2018-11-20 | Longitude Enterprise Flash S.A.R.L. | Systems and methods for persistent address space management |
US20180349310A1 (en) * | 2017-05-31 | 2018-12-06 | Hewlett Packard Enterprise Development Lp | HOT PLUGGING PERIPHERAL CONNECTED INTERFACE EXPRESS (PCIe) CARDS |
US10157677B2 (en) | 2016-07-28 | 2018-12-18 | Ip Gem Group, Llc | Background reference positioning and local reference positioning using threshold voltage shift read |
TWI651646B (en) * | 2016-04-21 | 2019-02-21 | 慧榮科技股份有限公司 | Data storage device and task ordering method thereof |
US10228880B2 (en) | 2016-09-06 | 2019-03-12 | HGST Netherlands B.V. | Position-aware primary command queue management |
US10230396B1 (en) | 2013-03-05 | 2019-03-12 | Microsemi Solutions (Us), Inc. | Method and apparatus for layer-specific LDPC decoding |
US10229085B2 (en) | 2015-01-23 | 2019-03-12 | Hewlett Packard Enterprise Development Lp | Fibre channel hardware card port assignment and management method for port names |
US10236915B2 (en) | 2016-07-29 | 2019-03-19 | Microsemi Solutions (U.S.), Inc. | Variable T BCH encoding |
US10291263B2 (en) | 2016-07-28 | 2019-05-14 | Ip Gem Group, Llc | Auto-learning log likelihood ratio |
US10318495B2 (en) | 2012-09-24 | 2019-06-11 | Sandisk Technologies Llc | Snapshots for a non-volatile device |
US10332613B1 (en) | 2015-05-18 | 2019-06-25 | Microsemi Solutions (Us), Inc. | Nonvolatile memory system with retention monitor |
US10339056B2 (en) | 2012-07-03 | 2019-07-02 | Sandisk Technologies Llc | Systems, methods and apparatus for cache transfers |
US10372340B2 (en) * | 2014-12-27 | 2019-08-06 | Huawei Technologies Co., Ltd. | Data distribution method in storage system, distribution apparatus, and storage system |
US10509776B2 (en) | 2012-09-24 | 2019-12-17 | Sandisk Technologies Llc | Time sequence data management |
US10558561B2 (en) | 2013-04-16 | 2020-02-11 | Sandisk Technologies Llc | Systems and methods for storage metadata management |
US20200050397A1 (en) * | 2018-08-08 | 2020-02-13 | Micron Technology, Inc. | Controller Command Scheduling in a Memory System to Increase Command Bus Utilization |
CN111181874A (en) * | 2018-11-09 | 2020-05-19 | 深圳市中兴微电子技术有限公司 | Message processing method, device and storage medium |
US10761880B2 (en) | 2016-04-21 | 2020-09-01 | Silicon Motion, Inc. | Data storage device, control unit thereof, and task sorting method for data storage device |
US10817421B2 (en) | 2010-12-13 | 2020-10-27 | Sandisk Technologies Llc | Persistent data structures |
US10817502B2 (en) | 2010-12-13 | 2020-10-27 | Sandisk Technologies Llc | Persistent memory management |
US10817528B2 (en) * | 2015-12-15 | 2020-10-27 | Futurewei Technologies, Inc. | System and method for data warehouse engine |
CN112114737A (en) * | 2019-06-20 | 2020-12-22 | 群联电子股份有限公司 | Memory control method, memory storage device and memory control circuit unit |
US11048433B2 (en) * | 2019-06-12 | 2021-06-29 | Phison Electronics Corp. | Memory control method with limited data collection operations, memory storage device and memory control circuit unit |
US11392516B2 (en) * | 2014-05-15 | 2022-07-19 | Adesto Technologies Corporation | Memory devices and methods having instruction acknowledgement |
US11537290B2 (en) * | 2014-03-20 | 2022-12-27 | International Business Machines Corporation | Managing high performance storage systems with hybrid storage technologies |
US11630601B2 (en) | 2021-03-02 | 2023-04-18 | Silicon Motion, Inc. | Memory and apparatus for performing access control with aid of multi-phase memory-mapped queue |
US11663008B2 (en) | 2019-03-11 | 2023-05-30 | Samsung Electronics Co., Ltd. | Managing memory device with processor-in-memory circuit to perform memory or processing operation |
Citations (87)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4449182A (en) * | 1981-10-05 | 1984-05-15 | Digital Equipment Corporation | Interface between a pair of processors, such as host and peripheral-controlling processors in data processing systems |
US4777595A (en) * | 1982-05-07 | 1988-10-11 | Digital Equipment Corporation | Apparatus for transferring blocks of information from one node to a second node in a computer network |
US5137118A (en) * | 1989-09-08 | 1992-08-11 | Mitsubishi Denki Kabushiki Kaisha | Apparatus for controlling the opening and closing of electric doors |
US5319754A (en) * | 1991-10-03 | 1994-06-07 | Compaq Computer Corporation | Data transfer system between a computer and a host adapter using multiple arrays |
US5619687A (en) * | 1994-02-22 | 1997-04-08 | Motorola Inc. | Queue system having a time-out feature and method therefor |
US5708814A (en) * | 1995-11-21 | 1998-01-13 | Microsoft Corporation | Method and apparatus for reducing the rate of interrupts by generating a single interrupt for a group of events |
US5802345A (en) * | 1994-03-28 | 1998-09-01 | Matsunami; Naoto | Computer system with a reduced number of command end interrupts from auxiliary memory unit and method of reducing the number of command end interrupts |
US5802546A (en) * | 1995-12-13 | 1998-09-01 | International Business Machines Corp. | Status handling for transfer of data blocks between a local side and a host side |
US5844776A (en) * | 1995-09-29 | 1998-12-01 | Fujitsu Limited | Static memory device having compatibility with a disk drive installed in an electronic apparatus |
US5941998A (en) * | 1997-07-25 | 1999-08-24 | Samsung Electronics Co., Ltd. | Disk drive incorporating read-verify after write method |
US5956743A (en) * | 1997-08-25 | 1999-09-21 | Bit Microsystems, Inc. | Transparent management at host interface of flash-memory overhead-bytes using flash-specific DMA having programmable processor-interrupt of high-level operations |
US6003112A (en) * | 1997-06-30 | 1999-12-14 | Intel Corporation | Memory controller and method for clearing or copying memory utilizing register files to store address information |
US6009478A (en) * | 1997-11-04 | 1999-12-28 | Adaptec, Inc. | File array communications interface for communicating between a host computer and an adapter |
US6134619A (en) * | 1995-06-15 | 2000-10-17 | Intel Corporation | Method and apparatus for transporting messages between processors in a multiple processor system |
US6167338A (en) * | 1997-09-15 | 2000-12-26 | Siemens Aktiengesellschaft | Method for storing and retrieving data in a control system, in particular in a motor vehicle |
US6179489B1 (en) * | 1997-04-04 | 2001-01-30 | Texas Instruments Incorporated | Devices, methods, systems and software products for coordination of computer main microprocessor and second microprocessor coupled thereto |
US20010023472A1 (en) * | 1997-10-21 | 2001-09-20 | Noriko Kubushiro | Data storage control method and apparatus for external storage device using a plurality of flash memories |
US20020005895A1 (en) * | 1997-08-05 | 2002-01-17 | Mitsubishi Electric, Ita | Data storage with overwrite |
US6343660B1 (en) * | 1998-03-26 | 2002-02-05 | Franciscus Hubertus Mutsaers | Front implement control |
US20020053004A1 (en) * | 1999-11-19 | 2002-05-02 | Fong Pong | Asynchronous cache coherence architecture in a shared memory multiprocessor with point-to-point links |
US20020078285A1 (en) * | 2000-12-14 | 2002-06-20 | International Business Machines Corporation | Reduction of interrupts in remote procedure calls |
US20020144066A1 (en) * | 2001-04-03 | 2002-10-03 | Talreja Sanjay S. | Status register architecture for flexible read-while-write device |
US20020178307A1 (en) * | 2001-05-25 | 2002-11-28 | Pua Khein Seng | Multiple memory card adapter |
US20030039140A1 (en) * | 2001-08-23 | 2003-02-27 | Ha Chang Wan | Flash memory having a flexible bank partition |
US20030058689A1 (en) * | 2001-08-30 | 2003-03-27 | Marotta Giulio Giuseppe | Flash memory array structure |
US20030101327A1 (en) * | 2001-11-16 | 2003-05-29 | Samsung Electronics Co., Ltd. | Flash memory management method |
US20030117846A1 (en) * | 2001-12-20 | 2003-06-26 | Kabushiki Kaisha Toshiba | Semiconductor memory system with a data copying function and a data copy method for the same |
US6640290B1 (en) * | 1998-02-09 | 2003-10-28 | Microsoft Corporation | Easily coalesced, sub-allocating, hierarchical, multi-bit bitmap-based memory manager |
US6640274B1 (en) * | 2000-08-21 | 2003-10-28 | Intel Corporation | Method and apparatus for reducing the disk drive data transfer interrupt service latency penalty |
US20030208771A1 (en) * | 1999-10-29 | 2003-11-06 | Debra Hensgen | System and method for providing multi-perspective instant replay |
US20030221092A1 (en) * | 2002-05-23 | 2003-11-27 | Ballard Curtis C. | Method and system of switching between two or more images of firmware on a host device |
US20030225960A1 (en) * | 2002-06-01 | 2003-12-04 | Morris Guu | Method for partitioning memory mass storage device |
US6678463B1 (en) * | 2000-08-02 | 2004-01-13 | Opentv | System and method for incorporating previously broadcast content into program recording |
US20040049649A1 (en) * | 2002-09-06 | 2004-03-11 | Paul Durrant | Computer system and method with memory copy command |
US20040078729A1 (en) * | 2002-06-26 | 2004-04-22 | Siemens Aktiengesellschaft | Method, computer, and computer program for detecting a bad block on a hard disk |
US6742078B1 (en) * | 1999-10-05 | 2004-05-25 | Feiya Technology Corp. | Management, data link structure and calculating method for flash memory |
US6757797B1 (en) * | 1999-09-30 | 2004-06-29 | Fujitsu Limited | Copying method between logical disks, disk-storage system and its storage medium |
US20040193808A1 (en) * | 2003-03-28 | 2004-09-30 | Emulex Corporation | Local emulation of data RAM utilizing write-through cache hardware within a CPU module |
US20040236933A1 (en) * | 2003-05-20 | 2004-11-25 | Dewey Thomas E. | Simplified memory detection |
US6854022B1 (en) * | 2002-02-22 | 2005-02-08 | Western Digital Technologies, Inc. | Disk drive using rotational position optimization algorithm to facilitate write verify operations |
US20050041509A1 (en) * | 2003-08-07 | 2005-02-24 | Renesas Technology Corp. | Memory card and data processing system |
US6901461B2 (en) * | 2002-12-31 | 2005-05-31 | Intel Corporation | Hardware assisted ATA command queuing |
US20050160218A1 (en) * | 2004-01-20 | 2005-07-21 | Sun-Teck See | Highly integrated mass storage device with an intelligent flash controller |
US20050172087A1 (en) * | 2004-01-29 | 2005-08-04 | Klingman Edwin E. | Intelligent memory device with ASCII registers |
US20050172067A1 (en) * | 2004-02-04 | 2005-08-04 | Sandisk Corporation | Mass storage accelerator |
US6938188B1 (en) * | 2002-01-29 | 2005-08-30 | Advanced Digital Information Corporation | Method for verifying functional integrity of computer hardware, particularly data storage devices |
US20050193164A1 (en) * | 2004-02-27 | 2005-09-01 | Royer Robert J.Jr. | Interface for a block addressable mass storage system |
US7000245B1 (en) * | 1999-10-29 | 2006-02-14 | Opentv, Inc. | System and method for recording pushed data |
US20060053308A1 (en) * | 2004-09-08 | 2006-03-09 | Raidy 2 Go Ltd. | Secured redundant memory subsystem |
US20060059295A1 (en) * | 2004-09-13 | 2006-03-16 | Takaya Suda | Memory management device and memory device |
US20060075119A1 (en) * | 2004-09-10 | 2006-04-06 | Hussain Muhammad R | TCP host |
US7028137B2 (en) * | 2003-12-25 | 2006-04-11 | Hitachi, Ltd. | Storage control subsystem for managing logical volumes |
US20060123284A1 (en) * | 2004-11-22 | 2006-06-08 | Samsung Electronics Co., Ltd. | Method of determining defects in information storage medium, recording/reproducing apparatus using the same, and information storage medium |
US7080377B2 (en) * | 2000-06-29 | 2006-07-18 | Eci Telecom Ltd. | Method for effective utilizing of shared resources in computerized system |
US20060184758A1 (en) * | 2005-01-11 | 2006-08-17 | Sony Corporation | Storage device |
US20060200595A1 (en) * | 2005-03-02 | 2006-09-07 | Lsi Logic Corporation | Variable length command pull with contiguous sequential layout |
US20060206653A1 (en) * | 2005-03-14 | 2006-09-14 | Phison Electronics Corp. | [virtual ide storage device with pci express] |
US7158167B1 (en) * | 1997-08-05 | 2007-01-02 | Mitsubishi Electric Research Laboratories, Inc. | Video recording device for a targetable weapon |
US20070008801A1 (en) * | 2005-07-11 | 2007-01-11 | Via Technologies, Inc. | Memory card and control chip capable of supporting various voltage supplies and method of supporting voltages thereof |
US20070101238A1 (en) * | 2003-05-20 | 2007-05-03 | Cray Inc. | Apparatus and method for memory read-refresh, scrubbing and variable-rate refresh |
US20070198796A1 (en) * | 2006-02-22 | 2007-08-23 | Seagate Technology Llc | Enhanced data integrity using parallel volatile and non-volatile transfer buffers |
US20070255890A1 (en) * | 2006-04-06 | 2007-11-01 | Kaoru Urata | Flash memory apparatus and access method to flash memory |
US20070255981A1 (en) * | 2006-03-24 | 2007-11-01 | Fujitsu Limited | Redundancy-function-equipped semiconductor memory device made from ECC memory |
US7296213B2 (en) * | 2002-12-11 | 2007-11-13 | Nvidia Corporation | Error correction cache for flash memory |
US20070288686A1 (en) * | 2006-06-08 | 2007-12-13 | Bitmicro Networks, Inc. | Optimized placement policy for solid state storage devices |
US20070288692A1 (en) * | 2006-06-08 | 2007-12-13 | Bitmicro Networks, Inc. | Hybrid Multi-Tiered Caching Storage System |
US20080010431A1 (en) * | 2006-07-07 | 2008-01-10 | Chi-Tung Chang | Memory storage device and read/write method thereof |
US20080022186A1 (en) * | 2006-07-24 | 2008-01-24 | Kingston Technology Corp. | Fully-Buffered Memory-Module with Error-Correction Code (ECC) Controller in Serializing Advanced-Memory Buffer (AMB) that is transparent to Motherboard Memory Controller |
US20080040531A1 (en) * | 2006-08-14 | 2008-02-14 | Dennis Anderson | Data storage device |
US20080052449A1 (en) * | 2006-08-22 | 2008-02-28 | Jin-Ki Kim | Modular command structure for memory and memory system |
US20080052448A1 (en) * | 2006-07-20 | 2008-02-28 | Stmicroelectronics Pvt. Ltd. | Flash memory interface device |
US20080052451A1 (en) * | 2005-03-14 | 2008-02-28 | Phison Electronics Corp. | Flash storage chip and flash array storage system |
US20080059747A1 (en) * | 2006-08-29 | 2008-03-06 | Erik John Burckart | Load management to reduce communication signaling latency in a virtual machine environment |
US20080065815A1 (en) * | 2006-09-12 | 2008-03-13 | Hiroshi Nasu | Logical volume management method and logical volume management program |
US20080077727A1 (en) * | 2006-09-25 | 2008-03-27 | Baca Jim S | Multithreaded state machine in non-volatile memory devices |
US20080092148A1 (en) * | 2006-10-17 | 2008-04-17 | Moertl Daniel F | Apparatus and Method for Splitting Endpoint Address Translation Cache Management Responsibilities Between a Device Driver and Device Driver Services |
US20080091915A1 (en) * | 2006-10-17 | 2008-04-17 | Moertl Daniel F | Apparatus and Method for Communicating with a Memory Registration Enabled Adapter Using Cached Address Translations |
US7370230B1 (en) * | 2004-01-08 | 2008-05-06 | Maxtor Corporation | Methods and structure for error correction in a processor pipeline |
US20080126658A1 (en) * | 2006-05-28 | 2008-05-29 | Phison Electronics Corp. | Inlayed flash memory module |
US20080209130A1 (en) * | 2005-08-12 | 2008-08-28 | Kegel Andrew G | Translation Data Prefetch in an IOMMU |
WO2008136417A1 (en) * | 2007-04-26 | 2008-11-13 | Elpida Memory, Inc. | Semiconductor device |
US7457897B1 (en) * | 2004-03-17 | 2008-11-25 | Suoer Talent Electronics, Inc. | PCI express-compatible controller and interface for flash memory |
US20080301381A1 (en) * | 2007-05-30 | 2008-12-04 | Samsung Electronics Co., Ltd. | Device and method for controlling commands used for flash memory |
US20090187682A1 (en) * | 2008-01-17 | 2009-07-23 | Arndt Richard L | Method for Detecting Circular Buffer Overrun |
US7610443B2 (en) * | 2005-03-01 | 2009-10-27 | Sunplus Technology Co., Ltd. | Method and system for accessing audiovisual data in a computer |
US20100293420A1 (en) * | 2009-05-15 | 2010-11-18 | Sanjiv Kapil | Cache coherent support for flash in a memory hierarchy |
US7934055B2 (en) * | 2006-12-06 | 2011-04-26 | Fusion-io, Inc | Apparatus, system, and method for a shared, front-end, distributed RAID |
-
2010
- 2010-04-08 US US12/756,477 patent/US20100262979A1/en not_active Abandoned
Patent Citations (112)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4449182B1 (en) * | 1981-10-05 | 1989-12-12 | ||
US4449182A (en) * | 1981-10-05 | 1984-05-15 | Digital Equipment Corporation | Interface between a pair of processors, such as host and peripheral-controlling processors in data processing systems |
US4777595A (en) * | 1982-05-07 | 1988-10-11 | Digital Equipment Corporation | Apparatus for transferring blocks of information from one node to a second node in a computer network |
US5137118A (en) * | 1989-09-08 | 1992-08-11 | Mitsubishi Denki Kabushiki Kaisha | Apparatus for controlling the opening and closing of electric doors |
US5319754A (en) * | 1991-10-03 | 1994-06-07 | Compaq Computer Corporation | Data transfer system between a computer and a host adapter using multiple arrays |
US5619687A (en) * | 1994-02-22 | 1997-04-08 | Motorola Inc. | Queue system having a time-out feature and method therefor |
US5802345A (en) * | 1994-03-28 | 1998-09-01 | Matsunami; Naoto | Computer system with a reduced number of command end interrupts from auxiliary memory unit and method of reducing the number of command end interrupts |
US6134619A (en) * | 1995-06-15 | 2000-10-17 | Intel Corporation | Method and apparatus for transporting messages between processors in a multiple processor system |
US5844776A (en) * | 1995-09-29 | 1998-12-01 | Fujitsu Limited | Static memory device having compatibility with a disk drive installed in an electronic apparatus |
US5708814A (en) * | 1995-11-21 | 1998-01-13 | Microsoft Corporation | Method and apparatus for reducing the rate of interrupts by generating a single interrupt for a group of events |
US5802546A (en) * | 1995-12-13 | 1998-09-01 | International Business Machines Corp. | Status handling for transfer of data blocks between a local side and a host side |
US6179489B1 (en) * | 1997-04-04 | 2001-01-30 | Texas Instruments Incorporated | Devices, methods, systems and software products for coordination of computer main microprocessor and second microprocessor coupled thereto |
US6003112A (en) * | 1997-06-30 | 1999-12-14 | Intel Corporation | Memory controller and method for clearing or copying memory utilizing register files to store address information |
US5941998A (en) * | 1997-07-25 | 1999-08-24 | Samsung Electronics Co., Ltd. | Disk drive incorporating read-verify after write method |
US20020005895A1 (en) * | 1997-08-05 | 2002-01-17 | Mitsubishi Electric, Ita | Data storage with overwrite |
US7012632B2 (en) * | 1997-08-05 | 2006-03-14 | Mitsubishi Electric Research Labs, Inc. | Data storage with overwrite |
US7088387B1 (en) * | 1997-08-05 | 2006-08-08 | Mitsubishi Electric Research Laboratories, Inc. | Video recording device responsive to triggering event |
US7158167B1 (en) * | 1997-08-05 | 2007-01-02 | Mitsubishi Electric Research Laboratories, Inc. | Video recording device for a targetable weapon |
US5956743A (en) * | 1997-08-25 | 1999-09-21 | Bit Microsystems, Inc. | Transparent management at host interface of flash-memory overhead-bytes using flash-specific DMA having programmable processor-interrupt of high-level operations |
US6167338A (en) * | 1997-09-15 | 2000-12-26 | Siemens Aktiengesellschaft | Method for storing and retrieving data in a control system, in particular in a motor vehicle |
US20010023472A1 (en) * | 1997-10-21 | 2001-09-20 | Noriko Kubushiro | Data storage control method and apparatus for external storage device using a plurality of flash memories |
US6009478A (en) * | 1997-11-04 | 1999-12-28 | Adaptec, Inc. | File array communications interface for communicating between a host computer and an adapter |
US6640290B1 (en) * | 1998-02-09 | 2003-10-28 | Microsoft Corporation | Easily coalesced, sub-allocating, hierarchical, multi-bit bitmap-based memory manager |
US6343660B1 (en) * | 1998-03-26 | 2002-02-05 | Franciscus Hubertus Mutsaers | Front implement control |
US6757797B1 (en) * | 1999-09-30 | 2004-06-29 | Fujitsu Limited | Copying method between logical disks, disk-storage system and its storage medium |
US6742078B1 (en) * | 1999-10-05 | 2004-05-25 | Feiya Technology Corp. | Management, data link structure and calculating method for flash memory |
US7000245B1 (en) * | 1999-10-29 | 2006-02-14 | Opentv, Inc. | System and method for recording pushed data |
US20030208771A1 (en) * | 1999-10-29 | 2003-11-06 | Debra Hensgen | System and method for providing multi-perspective instant replay |
US20020053004A1 (en) * | 1999-11-19 | 2002-05-02 | Fong Pong | Asynchronous cache coherence architecture in a shared memory multiprocessor with point-to-point links |
US7080377B2 (en) * | 2000-06-29 | 2006-07-18 | Eci Telecom Ltd. | Method for effective utilizing of shared resources in computerized system |
US6678463B1 (en) * | 2000-08-02 | 2004-01-13 | Opentv | System and method for incorporating previously broadcast content into program recording |
US6640274B1 (en) * | 2000-08-21 | 2003-10-28 | Intel Corporation | Method and apparatus for reducing the disk drive data transfer interrupt service latency penalty |
US20020078285A1 (en) * | 2000-12-14 | 2002-06-20 | International Business Machines Corporation | Reduction of interrupts in remote procedure calls |
US20020144066A1 (en) * | 2001-04-03 | 2002-10-03 | Talreja Sanjay S. | Status register architecture for flexible read-while-write device |
US6931498B2 (en) * | 2001-04-03 | 2005-08-16 | Intel Corporation | Status register architecture for flexible read-while-write device |
US20020178307A1 (en) * | 2001-05-25 | 2002-11-28 | Pua Khein Seng | Multiple memory card adapter |
US20030039140A1 (en) * | 2001-08-23 | 2003-02-27 | Ha Chang Wan | Flash memory having a flexible bank partition |
US6781914B2 (en) * | 2001-08-23 | 2004-08-24 | Winbond Electronics Corp. | Flash memory having a flexible bank partition |
US6697284B2 (en) * | 2001-08-30 | 2004-02-24 | Micron Technology, Inc. | Flash memory array structure |
US20030058689A1 (en) * | 2001-08-30 | 2003-03-27 | Marotta Giulio Giuseppe | Flash memory array structure |
US7127551B2 (en) * | 2001-11-16 | 2006-10-24 | Samsung Electronics Co., Ltd. | Flash memory management method |
US20030101327A1 (en) * | 2001-11-16 | 2003-05-29 | Samsung Electronics Co., Ltd. | Flash memory management method |
US6868007B2 (en) * | 2001-12-20 | 2005-03-15 | Kabushiki Kaisha Toshiba | Semiconductor memory system with a data copying function and a data copy method for the same |
US20030117846A1 (en) * | 2001-12-20 | 2003-06-26 | Kabushiki Kaisha Toshiba | Semiconductor memory system with a data copying function and a data copy method for the same |
US6938188B1 (en) * | 2002-01-29 | 2005-08-30 | Advanced Digital Information Corporation | Method for verifying functional integrity of computer hardware, particularly data storage devices |
US6854022B1 (en) * | 2002-02-22 | 2005-02-08 | Western Digital Technologies, Inc. | Disk drive using rotational position optimization algorithm to facilitate write verify operations |
US7080245B2 (en) * | 2002-05-23 | 2006-07-18 | Hewlett-Packard Development Company, L.P. | Method and system of switching between two or more images of firmware on a host device |
US20030221092A1 (en) * | 2002-05-23 | 2003-11-27 | Ballard Curtis C. | Method and system of switching between two or more images of firmware on a host device |
US20030225960A1 (en) * | 2002-06-01 | 2003-12-04 | Morris Guu | Method for partitioning memory mass storage device |
US20050177698A1 (en) * | 2002-06-01 | 2005-08-11 | Mao-Yuan Ku | Method for partitioning memory mass storage device |
US7114051B2 (en) * | 2002-06-01 | 2006-09-26 | Solid State System Co., Ltd. | Method for partitioning memory mass storage device |
US20040078729A1 (en) * | 2002-06-26 | 2004-04-22 | Siemens Aktiengesellschaft | Method, computer, and computer program for detecting a bad block on a hard disk |
US20040049649A1 (en) * | 2002-09-06 | 2004-03-11 | Paul Durrant | Computer system and method with memory copy command |
US7296213B2 (en) * | 2002-12-11 | 2007-11-13 | Nvidia Corporation | Error correction cache for flash memory |
US6901461B2 (en) * | 2002-12-31 | 2005-05-31 | Intel Corporation | Hardware assisted ATA command queuing |
US20040193808A1 (en) * | 2003-03-28 | 2004-09-30 | Emulex Corporation | Local emulation of data RAM utilizing write-through cache hardware within a CPU module |
US7159104B2 (en) * | 2003-05-20 | 2007-01-02 | Nvidia Corporation | Simplified memory detection |
US20070101238A1 (en) * | 2003-05-20 | 2007-05-03 | Cray Inc. | Apparatus and method for memory read-refresh, scrubbing and variable-rate refresh |
US20070113150A1 (en) * | 2003-05-20 | 2007-05-17 | Cray Inc. | Apparatus and method for memory asynchronous atomic read-correct-write operation |
US20040236933A1 (en) * | 2003-05-20 | 2004-11-25 | Dewey Thomas E. | Simplified memory detection |
US20050041509A1 (en) * | 2003-08-07 | 2005-02-24 | Renesas Technology Corp. | Memory card and data processing system |
US20060062052A1 (en) * | 2003-08-07 | 2006-03-23 | Chiaki Kumahara | Memory card and data processing system |
US6982919B2 (en) * | 2003-08-07 | 2006-01-03 | Renesas Technology Corp. | Memory card and data processing system |
US7161834B2 (en) * | 2003-08-07 | 2007-01-09 | Renesas Technology Corp. | Memory card and data processing system |
US7028137B2 (en) * | 2003-12-25 | 2006-04-11 | Hitachi, Ltd. | Storage control subsystem for managing logical volumes |
US7370230B1 (en) * | 2004-01-08 | 2008-05-06 | Maxtor Corporation | Methods and structure for error correction in a processor pipeline |
US20050160218A1 (en) * | 2004-01-20 | 2005-07-21 | Sun-Teck See | Highly integrated mass storage device with an intelligent flash controller |
US20050172087A1 (en) * | 2004-01-29 | 2005-08-04 | Klingman Edwin E. | Intelligent memory device with ASCII registers |
US7310699B2 (en) * | 2004-02-04 | 2007-12-18 | Sandisk Corporation | Mass storage accelerator |
US20070028040A1 (en) * | 2004-02-04 | 2007-02-01 | Sandisk Corporation | Mass storage accelerator |
US7127549B2 (en) * | 2004-02-04 | 2006-10-24 | Sandisk Corporation | Disk acceleration using first and second storage devices |
US20050172067A1 (en) * | 2004-02-04 | 2005-08-04 | Sandisk Corporation | Mass storage accelerator |
US7328304B2 (en) * | 2004-02-27 | 2008-02-05 | Intel Corporation | Interface for a block addressable mass storage system |
US20050193164A1 (en) * | 2004-02-27 | 2005-09-01 | Royer Robert J.Jr. | Interface for a block addressable mass storage system |
US7457897B1 (en) * | 2004-03-17 | 2008-11-25 | Suoer Talent Electronics, Inc. | PCI express-compatible controller and interface for flash memory |
US20060053308A1 (en) * | 2004-09-08 | 2006-03-09 | Raidy 2 Go Ltd. | Secured redundant memory subsystem |
US20060075119A1 (en) * | 2004-09-10 | 2006-04-06 | Hussain Muhammad R | TCP host |
US20060059295A1 (en) * | 2004-09-13 | 2006-03-16 | Takaya Suda | Memory management device and memory device |
US20060123284A1 (en) * | 2004-11-22 | 2006-06-08 | Samsung Electronics Co., Ltd. | Method of determining defects in information storage medium, recording/reproducing apparatus using the same, and information storage medium |
US20060184758A1 (en) * | 2005-01-11 | 2006-08-17 | Sony Corporation | Storage device |
US7325104B2 (en) * | 2005-01-11 | 2008-01-29 | Sony Corporation | Storage device using interleaved memories to control power consumption |
US7610443B2 (en) * | 2005-03-01 | 2009-10-27 | Sunplus Technology Co., Ltd. | Method and system for accessing audiovisual data in a computer |
US20060200595A1 (en) * | 2005-03-02 | 2006-09-07 | Lsi Logic Corporation | Variable length command pull with contiguous sequential layout |
US7356637B2 (en) * | 2005-03-14 | 2008-04-08 | Phison Electronics Corp. | Virtual IDE storage device with PCI express interface |
US20070208900A1 (en) * | 2005-03-14 | 2007-09-06 | Phison Electronics Corp. | Virtual ide storage device with pci express interface |
US7225289B2 (en) * | 2005-03-14 | 2007-05-29 | Phison Electronics Corporation | Virtual IDE storage with PCI express interface |
US20080052451A1 (en) * | 2005-03-14 | 2008-02-28 | Phison Electronics Corp. | Flash storage chip and flash array storage system |
US20060206653A1 (en) * | 2005-03-14 | 2006-09-14 | Phison Electronics Corp. | [virtual ide storage device with pci express] |
US20070008801A1 (en) * | 2005-07-11 | 2007-01-11 | Via Technologies, Inc. | Memory card and control chip capable of supporting various voltage supplies and method of supporting voltages thereof |
US20080209130A1 (en) * | 2005-08-12 | 2008-08-28 | Kegel Andrew G | Translation Data Prefetch in an IOMMU |
US20070198796A1 (en) * | 2006-02-22 | 2007-08-23 | Seagate Technology Llc | Enhanced data integrity using parallel volatile and non-volatile transfer buffers |
US20070255981A1 (en) * | 2006-03-24 | 2007-11-01 | Fujitsu Limited | Redundancy-function-equipped semiconductor memory device made from ECC memory |
US20070255890A1 (en) * | 2006-04-06 | 2007-11-01 | Kaoru Urata | Flash memory apparatus and access method to flash memory |
US20080126658A1 (en) * | 2006-05-28 | 2008-05-29 | Phison Electronics Corp. | Inlayed flash memory module |
US20070288686A1 (en) * | 2006-06-08 | 2007-12-13 | Bitmicro Networks, Inc. | Optimized placement policy for solid state storage devices |
US20070288692A1 (en) * | 2006-06-08 | 2007-12-13 | Bitmicro Networks, Inc. | Hybrid Multi-Tiered Caching Storage System |
US20080010431A1 (en) * | 2006-07-07 | 2008-01-10 | Chi-Tung Chang | Memory storage device and read/write method thereof |
US20080052448A1 (en) * | 2006-07-20 | 2008-02-28 | Stmicroelectronics Pvt. Ltd. | Flash memory interface device |
US20080022186A1 (en) * | 2006-07-24 | 2008-01-24 | Kingston Technology Corp. | Fully-Buffered Memory-Module with Error-Correction Code (ECC) Controller in Serializing Advanced-Memory Buffer (AMB) that is transparent to Motherboard Memory Controller |
US20080040531A1 (en) * | 2006-08-14 | 2008-02-14 | Dennis Anderson | Data storage device |
US20080052449A1 (en) * | 2006-08-22 | 2008-02-28 | Jin-Ki Kim | Modular command structure for memory and memory system |
US20080059747A1 (en) * | 2006-08-29 | 2008-03-06 | Erik John Burckart | Load management to reduce communication signaling latency in a virtual machine environment |
US20080065815A1 (en) * | 2006-09-12 | 2008-03-13 | Hiroshi Nasu | Logical volume management method and logical volume management program |
US20080077727A1 (en) * | 2006-09-25 | 2008-03-27 | Baca Jim S | Multithreaded state machine in non-volatile memory devices |
US20080091915A1 (en) * | 2006-10-17 | 2008-04-17 | Moertl Daniel F | Apparatus and Method for Communicating with a Memory Registration Enabled Adapter Using Cached Address Translations |
US20080092148A1 (en) * | 2006-10-17 | 2008-04-17 | Moertl Daniel F | Apparatus and Method for Splitting Endpoint Address Translation Cache Management Responsibilities Between a Device Driver and Device Driver Services |
US7934055B2 (en) * | 2006-12-06 | 2011-04-26 | Fusion-io, Inc | Apparatus, system, and method for a shared, front-end, distributed RAID |
WO2008136417A1 (en) * | 2007-04-26 | 2008-11-13 | Elpida Memory, Inc. | Semiconductor device |
US20100131724A1 (en) * | 2007-04-26 | 2010-05-27 | Elpida Memory, Inc. | Semiconductor device |
US20080301381A1 (en) * | 2007-05-30 | 2008-12-04 | Samsung Electronics Co., Ltd. | Device and method for controlling commands used for flash memory |
US20090187682A1 (en) * | 2008-01-17 | 2009-07-23 | Arndt Richard L | Method for Detecting Circular Buffer Overrun |
US20100293420A1 (en) * | 2009-05-15 | 2010-11-18 | Sanjiv Kapil | Cache coherent support for flash in a memory hierarchy |
Cited By (170)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9734086B2 (en) | 2006-12-06 | 2017-08-15 | Sandisk Technologies Llc | Apparatus, system, and method for a device shared between multiple independent hosts |
US11847066B2 (en) | 2006-12-06 | 2023-12-19 | Unification Technologies Llc | Apparatus, system, and method for managing commands of solid-state storage using bank interleave |
US11960412B2 (en) | 2006-12-06 | 2024-04-16 | Unification Technologies Llc | Systems and methods for identifying storage resources that are not in use |
US11640359B2 (en) | 2006-12-06 | 2023-05-02 | Unification Technologies Llc | Systems and methods for identifying storage resources that are not in use |
US8935302B2 (en) | 2006-12-06 | 2015-01-13 | Intelligent Intellectual Property Holdings 2 Llc | Apparatus, system, and method for data block usage information synchronization for a non-volatile storage volume |
US11573909B2 (en) | 2006-12-06 | 2023-02-07 | Unification Technologies Llc | Apparatus, system, and method for managing commands of solid-state storage using bank interleave |
US8762658B2 (en) | 2006-12-06 | 2014-06-24 | Fusion-Io, Inc. | Systems and methods for persistent deallocation |
US8756375B2 (en) | 2006-12-06 | 2014-06-17 | Fusion-Io, Inc. | Non-volatile cache |
US20080313364A1 (en) * | 2006-12-06 | 2008-12-18 | David Flynn | Apparatus, system, and method for remote direct memory access to a solid-state storage device |
US9519540B2 (en) | 2007-12-06 | 2016-12-13 | Sandisk Technologies Llc | Apparatus, system, and method for destaging cached data |
US9600184B2 (en) | 2007-12-06 | 2017-03-21 | Sandisk Technologies Llc | Apparatus, system, and method for coordinating storage requests in a multi-processor/multi-thread environment |
US9244842B2 (en) | 2009-04-08 | 2016-01-26 | Google Inc. | Data storage device with copy command |
US8244962B2 (en) | 2009-04-08 | 2012-08-14 | Google Inc. | Command processor for a data storage device |
US8380909B2 (en) | 2009-04-08 | 2013-02-19 | Google Inc. | Multiple command queues having separate interrupts |
US20100262773A1 (en) * | 2009-04-08 | 2010-10-14 | Google Inc. | Data striping in a flash memory data storage device |
US8433845B2 (en) | 2009-04-08 | 2013-04-30 | Google Inc. | Data storage device which serializes memory device ready/busy signals |
US20100287217A1 (en) * | 2009-04-08 | 2010-11-11 | Google Inc. | Host control of background garbage collection in a data storage device |
US8447918B2 (en) | 2009-04-08 | 2013-05-21 | Google Inc. | Garbage collection for failure prediction and repartitioning |
US8205037B2 (en) | 2009-04-08 | 2012-06-19 | Google Inc. | Data storage device capable of recognizing and controlling multiple types of memory chips operating at different voltages |
US8239724B2 (en) | 2009-04-08 | 2012-08-07 | Google Inc. | Error correction for a data storage device |
US8239713B2 (en) | 2009-04-08 | 2012-08-07 | Google Inc. | Data storage device with bad block scan command |
US8566507B2 (en) | 2009-04-08 | 2013-10-22 | Google Inc. | Data storage device capable of recognizing and controlling multiple types of memory chips |
US8566508B2 (en) | 2009-04-08 | 2013-10-22 | Google Inc. | RAID configuration in a flash memory data storage device |
US8239729B2 (en) | 2009-04-08 | 2012-08-07 | Google Inc. | Data storage device with copy command |
US8578084B2 (en) | 2009-04-08 | 2013-11-05 | Google Inc. | Data storage device having multiple removable memory boards |
US8327220B2 (en) | 2009-04-08 | 2012-12-04 | Google Inc. | Data storage device with verify on write command |
US8595572B2 (en) | 2009-04-08 | 2013-11-26 | Google Inc. | Data storage device with metadata command |
US8250271B2 (en) | 2009-04-08 | 2012-08-21 | Google Inc. | Command and interrupt grouping for a data storage device |
US8639871B2 (en) | 2009-04-08 | 2014-01-28 | Google Inc. | Partitioning a flash memory data storage device |
US8719501B2 (en) | 2009-09-08 | 2014-05-06 | Fusion-Io | Apparatus, system, and method for caching data on a solid-state storage device |
US8289801B2 (en) | 2009-09-09 | 2012-10-16 | Fusion-Io, Inc. | Apparatus, system, and method for power reduction management in a storage device |
US9015425B2 (en) | 2009-09-09 | 2015-04-21 | Intelligent Intellectual Property Holdings 2, LLC. | Apparatus, systems, and methods for nameless writes |
US9223514B2 (en) | 2009-09-09 | 2015-12-29 | SanDisk Technologies, Inc. | Erase suspend/resume for memory |
US8972627B2 (en) | 2009-09-09 | 2015-03-03 | Fusion-Io, Inc. | Apparatus, system, and method for managing operations for data storage media |
US20110058440A1 (en) * | 2009-09-09 | 2011-03-10 | Fusion-Io, Inc. | Apparatus, system, and method for power reduction management in a storage device |
US8578127B2 (en) | 2009-09-09 | 2013-11-05 | Fusion-Io, Inc. | Apparatus, system, and method for allocating storage |
US20110060927A1 (en) * | 2009-09-09 | 2011-03-10 | Fusion-Io, Inc. | Apparatus, system, and method for power reduction in a storage device |
US9305610B2 (en) | 2009-09-09 | 2016-04-05 | SanDisk Technologies, Inc. | Apparatus, system, and method for power reduction management in a storage device |
US9251062B2 (en) | 2009-09-09 | 2016-02-02 | Intelligent Intellectual Property Holdings 2 Llc | Apparatus, system, and method for conditional and atomic storage operations |
US8429436B2 (en) | 2009-09-09 | 2013-04-23 | Fusion-Io, Inc. | Apparatus, system, and method for power reduction in a storage device |
US9021158B2 (en) | 2009-09-09 | 2015-04-28 | SanDisk Technologies, Inc. | Program suspend/resume for memory |
US9122579B2 (en) | 2010-01-06 | 2015-09-01 | Intelligent Intellectual Property Holdings 2 Llc | Apparatus, system, and method for a storage layer |
US20130121341A1 (en) * | 2010-03-17 | 2013-05-16 | Juniper Networks, Inc. | Multi-bank queuing architecture for higher bandwidth on-chip memory buffer |
US8713220B2 (en) * | 2010-03-17 | 2014-04-29 | Juniper Networks, Inc. | Multi-bank queuing architecture for higher bandwidth on-chip memory buffer |
US8601222B2 (en) | 2010-05-13 | 2013-12-03 | Fusion-Io, Inc. | Apparatus, system, and method for conditional and atomic storage operations |
US10013354B2 (en) | 2010-07-28 | 2018-07-03 | Sandisk Technologies Llc | Apparatus, system, and method for atomic storage operations |
US9910777B2 (en) | 2010-07-28 | 2018-03-06 | Sandisk Technologies Llc | Enhanced integrity through atomic writes in cache |
US8554968B1 (en) | 2010-08-16 | 2013-10-08 | Pmc-Sierra, Inc. | Interrupt technique for a nonvolatile memory controller |
US8588228B1 (en) * | 2010-08-16 | 2013-11-19 | Pmc-Sierra Us, Inc. | Nonvolatile memory controller with host controller interface for retrieving and dispatching nonvolatile memory commands in a distributed manner |
US8601346B1 (en) | 2010-08-16 | 2013-12-03 | Pmc-Sierra Us, Inc. | System and method for generating parity data in a nonvolatile memory controller by using a distributed processing technique |
US8656071B1 (en) | 2010-08-16 | 2014-02-18 | Pmc-Sierra Us, Inc. | System and method for routing a data message through a message network |
US8984216B2 (en) | 2010-09-09 | 2015-03-17 | Fusion-Io, Llc | Apparatus, system, and method for managing lifetime of a storage device |
US9047178B2 (en) | 2010-12-13 | 2015-06-02 | SanDisk Technologies, Inc. | Auto-commit memory synchronization |
US9223662B2 (en) | 2010-12-13 | 2015-12-29 | SanDisk Technologies, Inc. | Preserving data of a volatile memory |
US10817421B2 (en) | 2010-12-13 | 2020-10-27 | Sandisk Technologies Llc | Persistent data structures |
US10817502B2 (en) | 2010-12-13 | 2020-10-27 | Sandisk Technologies Llc | Persistent memory management |
US9218278B2 (en) | 2010-12-13 | 2015-12-22 | SanDisk Technologies, Inc. | Auto-commit memory |
US9208071B2 (en) | 2010-12-13 | 2015-12-08 | SanDisk Technologies, Inc. | Apparatus, system, and method for accessing memory |
US8527693B2 (en) | 2010-12-13 | 2013-09-03 | Fusion IO, Inc. | Apparatus, system, and method for auto-commit memory |
US9772938B2 (en) | 2010-12-13 | 2017-09-26 | Sandisk Technologies Llc | Auto-commit memory metadata and resetting the metadata by writing to special address in free space of page storing the metadata |
US9767017B2 (en) | 2010-12-13 | 2017-09-19 | Sandisk Technologies Llc | Memory device with volatile and non-volatile media |
US10133663B2 (en) | 2010-12-17 | 2018-11-20 | Longitude Enterprise Flash S.A.R.L. | Systems and methods for persistent address space management |
US8874823B2 (en) | 2011-02-15 | 2014-10-28 | Intellectual Property Holdings 2 Llc | Systems and methods for managing data input/output operations |
US9003104B2 (en) | 2011-02-15 | 2015-04-07 | Intelligent Intellectual Property Holdings 2 Llc | Systems and methods for a file-level cache |
US8825937B2 (en) | 2011-02-25 | 2014-09-02 | Fusion-Io, Inc. | Writing cached data forward on read |
US9141527B2 (en) | 2011-02-25 | 2015-09-22 | Intelligent Intellectual Property Holdings 2 Llc | Managing cache pools |
US9250817B2 (en) | 2011-03-18 | 2016-02-02 | SanDisk Technologies, Inc. | Systems and methods for contextual storage |
US8966191B2 (en) | 2011-03-18 | 2015-02-24 | Fusion-Io, Inc. | Logical interface for contextual storage |
US9563555B2 (en) | 2011-03-18 | 2017-02-07 | Sandisk Technologies Llc | Systems and methods for storage allocation |
US9201677B2 (en) | 2011-05-23 | 2015-12-01 | Intelligent Intellectual Property Holdings 2 Llc | Managing data input/output operations |
US8842122B2 (en) * | 2011-12-15 | 2014-09-23 | Qualcomm Incorporated | Graphics processing unit with command processor |
US20130155080A1 (en) * | 2011-12-15 | 2013-06-20 | Qualcomm Incorporated | Graphics processing unit with command processor |
US8725934B2 (en) | 2011-12-22 | 2014-05-13 | Fusion-Io, Inc. | Methods and appratuses for atomic storage operations |
US9274937B2 (en) | 2011-12-22 | 2016-03-01 | Longitude Enterprise Flash S.A.R.L. | Systems, methods, and interfaces for vector input/output operations |
US9251086B2 (en) | 2012-01-24 | 2016-02-02 | SanDisk Technologies, Inc. | Apparatus, system, and method for managing a cache |
US9116812B2 (en) | 2012-01-27 | 2015-08-25 | Intelligent Intellectual Property Holdings 2 Llc | Systems and methods for a de-duplication cache |
US9135192B2 (en) | 2012-03-30 | 2015-09-15 | Sandisk Technologies Inc. | Memory system with command queue reordering |
US9753779B2 (en) | 2012-05-24 | 2017-09-05 | Renesas Electronics Corporation | Task processing device implementing task switching using multiple state registers storing processor id and task state |
US9612966B2 (en) | 2012-07-03 | 2017-04-04 | Sandisk Technologies Llc | Systems, methods and apparatus for a virtual machine cache |
US10339056B2 (en) | 2012-07-03 | 2019-07-02 | Sandisk Technologies Llc | Systems, methods and apparatus for cache transfers |
US20140047167A1 (en) * | 2012-08-08 | 2014-02-13 | Dong-Hun KWAK | Nonvolatile memory device and method of controlling suspension of command execution of the same |
US9928165B2 (en) * | 2012-08-08 | 2018-03-27 | Samsung Electronics Co., Ltd. | Nonvolatile memory device and method of controlling suspension of command execution of the same |
JP2014035788A (en) * | 2012-08-08 | 2014-02-24 | Samsung Electronics Co Ltd | Nonvolatile memory device and erase operation control method thereof |
US10359972B2 (en) | 2012-08-31 | 2019-07-23 | Sandisk Technologies Llc | Systems, methods, and interfaces for adaptive persistence |
US10346095B2 (en) | 2012-08-31 | 2019-07-09 | Sandisk Technologies, Llc | Systems, methods, and interfaces for adaptive cache persistence |
US9058123B2 (en) | 2012-08-31 | 2015-06-16 | Intelligent Intellectual Property Holdings 2 Llc | Systems, methods, and interfaces for adaptive persistence |
US9164702B1 (en) * | 2012-09-07 | 2015-10-20 | Google Inc. | Single-sided distributed cache system |
US10108373B2 (en) * | 2012-09-14 | 2018-10-23 | Samsung Electronics Co., Ltd. | Host, system, and methods for transmitting commands to non-volatile memory card |
US20160306594A1 (en) * | 2012-09-14 | 2016-10-20 | Samsung Electronics Co., Ltd . | Host for controlling non-volatile memory card, system including the same, and methods operating the host and the system |
US10509776B2 (en) | 2012-09-24 | 2019-12-17 | Sandisk Technologies Llc | Time sequence data management |
US10318495B2 (en) | 2012-09-24 | 2019-06-11 | Sandisk Technologies Llc | Snapshots for a non-volatile device |
EP2929439A1 (en) * | 2012-12-10 | 2015-10-14 | Google, Inc. | Using a logical to physical map for direct user space communication with a data storage device |
CN104885062A (en) * | 2012-12-10 | 2015-09-02 | 谷歌公司 | Using logical to physical map for direct user space communication with data storage device |
WO2014093220A1 (en) * | 2012-12-10 | 2014-06-19 | Google Inc. | Using a virtual to physical map for direct user space communication with a data storage device |
US9069658B2 (en) | 2012-12-10 | 2015-06-30 | Google Inc. | Using a virtual to physical map for direct user space communication with a data storage device |
US9164888B2 (en) | 2012-12-10 | 2015-10-20 | Google Inc. | Using a logical to physical map for direct user space communication with a data storage device |
WO2014093222A1 (en) * | 2012-12-10 | 2014-06-19 | Google Inc. | Using a logical to physical map for direct user space communication with a data storage device |
EP2929438A1 (en) * | 2012-12-10 | 2015-10-14 | Google, Inc. | Using a virtual to physical map for direct user space communication with a data storage device |
CN104903868A (en) * | 2012-12-10 | 2015-09-09 | 谷歌公司 | Using a virtual to physical map for direct user space communication with a data storage device |
US9448881B1 (en) | 2013-01-29 | 2016-09-20 | Microsemi Storage Solutions (Us), Inc. | Memory controller and integrated circuit device for correcting errors in data read from memory cells |
US10230396B1 (en) | 2013-03-05 | 2019-03-12 | Microsemi Solutions (Us), Inc. | Method and apparatus for layer-specific LDPC decoding |
US9813080B1 (en) | 2013-03-05 | 2017-11-07 | Microsemi Solutions (U.S.), Inc. | Layer specific LDPC decoder |
US10579267B2 (en) | 2013-03-08 | 2020-03-03 | Toshiba Memory Corporation | Memory controller and memory system |
US20140258675A1 (en) * | 2013-03-08 | 2014-09-11 | Kabushiki Kaisha Toshiba | Memory controller and memory system |
US9514041B2 (en) * | 2013-03-08 | 2016-12-06 | Kabushiki Kaisha Toshiba | Memory controller and memory system |
US9450610B1 (en) | 2013-03-15 | 2016-09-20 | Microsemi Storage Solutions (Us), Inc. | High quality log likelihood ratios determined using two-index look-up table |
US9842053B2 (en) | 2013-03-15 | 2017-12-12 | Sandisk Technologies Llc | Systems and methods for persistent cache logging |
US10558561B2 (en) | 2013-04-16 | 2020-02-11 | Sandisk Technologies Llc | Systems and methods for storage metadata management |
US10102144B2 (en) | 2013-04-16 | 2018-10-16 | Sandisk Technologies Llc | Systems, methods and interfaces for data virtualization |
US9842128B2 (en) | 2013-08-01 | 2017-12-12 | Sandisk Technologies Llc | Systems and methods for atomic storage operations |
US20150067291A1 (en) * | 2013-08-30 | 2015-03-05 | Kabushiki Kaisha Toshiba | Controller, memory system, and method |
US9824004B2 (en) | 2013-10-04 | 2017-11-21 | Micron Technology, Inc. | Methods and apparatuses for requesting ready status information from a memory |
US11151027B2 (en) | 2013-10-04 | 2021-10-19 | Micron Technology, Inc. | Methods and apparatuses for requesting ready status information from a memory |
US10445228B2 (en) | 2013-10-04 | 2019-10-15 | Micron Technology, Inc. | Methods and apparatuses for requesting ready status information from a memory |
US10019320B2 (en) | 2013-10-18 | 2018-07-10 | Sandisk Technologies Llc | Systems and methods for distributed atomic storage operations |
US9348747B2 (en) | 2013-10-29 | 2016-05-24 | Seagate Technology Llc | Solid state memory command queue in hybrid device |
US10073630B2 (en) | 2013-11-08 | 2018-09-11 | Sandisk Technologies Llc | Systems and methods for log coordination |
US11023167B2 (en) | 2014-01-27 | 2021-06-01 | Micron Technology, Inc. | Methods and apparatuses for executing a plurality of queued tasks in a memory |
US10108372B2 (en) | 2014-01-27 | 2018-10-23 | Micron Technology, Inc. | Methods and apparatuses for executing a plurality of queued tasks in a memory |
US10884661B2 (en) | 2014-02-14 | 2021-01-05 | Micron Technology, Inc. | Command queuing |
US11494122B2 (en) | 2014-02-14 | 2022-11-08 | Micron Technology, Inc. | Command queuing |
EP3105675A4 (en) * | 2014-02-14 | 2017-10-18 | Micron Technology, INC. | Command queuing |
US9454310B2 (en) * | 2014-02-14 | 2016-09-27 | Micron Technology, Inc. | Command queuing |
US10146477B2 (en) * | 2014-02-14 | 2018-12-04 | Micron Technology, Inc. | Command queuing |
US11954370B2 (en) | 2014-02-14 | 2024-04-09 | Lodestar Licensing Group Llc | Command queuing |
US20150234601A1 (en) * | 2014-02-14 | 2015-08-20 | Micron Technology, Inc. | Command queuing |
WO2015123413A1 (en) * | 2014-02-14 | 2015-08-20 | Micron Technology, Inc. | Command queuing |
US9666244B2 (en) | 2014-03-01 | 2017-05-30 | Fusion-Io, Inc. | Dividing a storage procedure |
US11537290B2 (en) * | 2014-03-20 | 2022-12-27 | International Business Machines Corporation | Managing high performance storage systems with hybrid storage technologies |
US11392516B2 (en) * | 2014-05-15 | 2022-07-19 | Adesto Technologies Corporation | Memory devices and methods having instruction acknowledgement |
US20150332781A1 (en) * | 2014-05-19 | 2015-11-19 | Samsung Electronics Co., Ltd. | Nonvolatile memory system with improved signal transmission and reception characteristics and method of operating the same |
US9396805B2 (en) * | 2014-05-19 | 2016-07-19 | Samsung Electronics Co., Ltd. | Nonvolatile memory system with improved signal transmission and reception characteristics and method of operating the same |
US9417804B2 (en) | 2014-07-07 | 2016-08-16 | Microsemi Storage Solutions (Us), Inc. | System and method for memory block pool wear leveling |
US9715465B2 (en) | 2014-10-28 | 2017-07-25 | Samsung Electronics Co., Ltd. | Storage device and operating method of the same |
US9824413B2 (en) * | 2014-11-15 | 2017-11-21 | Intel Corporation | Sort-free threading model for a multi-threaded graphics pipeline |
US20160140684A1 (en) * | 2014-11-15 | 2016-05-19 | Intel Corporation | Sort-free threading model for a multi-threaded graphics pipeline |
WO2016077036A1 (en) * | 2014-11-15 | 2016-05-19 | Intel Corporation | Sort-free threading model for a multi-threaded graphics pipeline |
US10372340B2 (en) * | 2014-12-27 | 2019-08-06 | Huawei Technologies Co., Ltd. | Data distribution method in storage system, distribution apparatus, and storage system |
US9933950B2 (en) | 2015-01-16 | 2018-04-03 | Sandisk Technologies Llc | Storage operation interrupt |
US10229085B2 (en) | 2015-01-23 | 2019-03-12 | Hewlett Packard Enterprise Development Lp | Fibre channel hardware card port assignment and management method for port names |
US9946607B2 (en) | 2015-03-04 | 2018-04-17 | Sandisk Technologies Llc | Systems and methods for storage error management |
US10332613B1 (en) | 2015-05-18 | 2019-06-25 | Microsemi Solutions (Us), Inc. | Nonvolatile memory system with retention monitor |
US9799405B1 (en) | 2015-07-29 | 2017-10-24 | Ip Gem Group, Llc | Nonvolatile memory system with read circuit for performing reads using threshold voltage shift read instruction |
US11907566B1 (en) | 2015-09-24 | 2024-02-20 | Pure Storage, Inc. | Coordination of task execution in a distributed storage network |
US20170090824A1 (en) * | 2015-09-24 | 2017-03-30 | International Business Machines Corporation | Layered queue based coordination of potentially destructive actions in a dispersed storage network memory |
US9977623B2 (en) | 2015-10-15 | 2018-05-22 | Sandisk Technologies Llc | Detection of a sequential command stream |
US10248455B2 (en) * | 2015-11-10 | 2019-04-02 | Silicon Motion, Inc. | Storage device and task execution method thereof, and host corresponding to the storage device and task execution method thereof |
US20170132035A1 (en) * | 2015-11-10 | 2017-05-11 | Silicon Motion, Inc. | Storage device and task execution method thereof, and host corresponding to the storage device and task execution method thereof |
US9886214B2 (en) | 2015-12-11 | 2018-02-06 | Ip Gem Group, Llc | Nonvolatile memory system with erase suspend circuit and method for erase suspend management |
US10152273B2 (en) | 2015-12-11 | 2018-12-11 | Ip Gem Group, Llc | Nonvolatile memory controller and method for erase suspend management that increments the number of program and erase cycles after erase suspend |
US10817528B2 (en) * | 2015-12-15 | 2020-10-27 | Futurewei Technologies, Inc. | System and method for data warehouse engine |
US9892794B2 (en) | 2016-01-04 | 2018-02-13 | Ip Gem Group, Llc | Method and apparatus with program suspend using test mode |
US9899092B2 (en) | 2016-01-27 | 2018-02-20 | Ip Gem Group, Llc | Nonvolatile memory system with program step manager and method for program step management |
TWI651646B (en) * | 2016-04-21 | 2019-02-21 | 慧榮科技股份有限公司 | Data storage device and task ordering method thereof |
US10761880B2 (en) | 2016-04-21 | 2020-09-01 | Silicon Motion, Inc. | Data storage device, control unit thereof, and task sorting method for data storage device |
US10291263B2 (en) | 2016-07-28 | 2019-05-14 | Ip Gem Group, Llc | Auto-learning log likelihood ratio |
US10157677B2 (en) | 2016-07-28 | 2018-12-18 | Ip Gem Group, Llc | Background reference positioning and local reference positioning using threshold voltage shift read |
US10283215B2 (en) | 2016-07-28 | 2019-05-07 | Ip Gem Group, Llc | Nonvolatile memory system with background reference positioning and local reference positioning |
US10236915B2 (en) | 2016-07-29 | 2019-03-19 | Microsemi Solutions (U.S.), Inc. | Variable T BCH encoding |
US10228880B2 (en) | 2016-09-06 | 2019-03-12 | HGST Netherlands B.V. | Position-aware primary command queue management |
US10223318B2 (en) * | 2017-05-31 | 2019-03-05 | Hewlett Packard Enterprise Development Lp | Hot plugging peripheral connected interface express (PCIe) cards |
US20180349310A1 (en) * | 2017-05-31 | 2018-12-06 | Hewlett Packard Enterprise Development Lp | HOT PLUGGING PERIPHERAL CONNECTED INTERFACE EXPRESS (PCIe) CARDS |
US20200050397A1 (en) * | 2018-08-08 | 2020-02-13 | Micron Technology, Inc. | Controller Command Scheduling in a Memory System to Increase Command Bus Utilization |
US11099778B2 (en) * | 2018-08-08 | 2021-08-24 | Micron Technology, Inc. | Controller command scheduling in a memory system to increase command bus utilization |
CN111181874A (en) * | 2018-11-09 | 2020-05-19 | 深圳市中兴微电子技术有限公司 | Message processing method, device and storage medium |
US11663008B2 (en) | 2019-03-11 | 2023-05-30 | Samsung Electronics Co., Ltd. | Managing memory device with processor-in-memory circuit to perform memory or processing operation |
US11048433B2 (en) * | 2019-06-12 | 2021-06-29 | Phison Electronics Corp. | Memory control method with limited data collection operations, memory storage device and memory control circuit unit |
CN112114737A (en) * | 2019-06-20 | 2020-12-22 | 群联电子股份有限公司 | Memory control method, memory storage device and memory control circuit unit |
TWI820603B (en) * | 2021-03-02 | 2023-11-01 | 慧榮科技股份有限公司 | Method for performing access control with aid of multi-phase memory-mapped queue, system-on-chip integrated circuit, memory device, and controller of memory device |
US11630601B2 (en) | 2021-03-02 | 2023-04-18 | Silicon Motion, Inc. | Memory and apparatus for performing access control with aid of multi-phase memory-mapped queue |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8380909B2 (en) | Multiple command queues having separate interrupts | |
US20100262979A1 (en) | Circular command queues for communication between a host and a data storage device | |
US8433845B2 (en) | Data storage device which serializes memory device ready/busy signals | |
US8683126B2 (en) | Optimal use of buffer space by a storage controller which writes retrieved data directly to a memory | |
US9898341B2 (en) | Adjustable priority ratios for multiple task queues | |
US8635412B1 (en) | Inter-processor communication | |
US20150169244A1 (en) | Storage processor managing nvme logically addressed solid state disk array | |
US20150186068A1 (en) | Command queuing using linked list queues | |
US20150095554A1 (en) | Storage processor managing solid state disk array | |
CN102073461B (en) | Input-output request scheduling method, memory controller and memory array | |
EP3062232B1 (en) | Method and device for automatically exchanging signals between embedded multi-cpu boards | |
US11243716B2 (en) | Memory system and operation method thereof | |
EP3647932A1 (en) | Storage device processing stream data, system including the same, and operation method thereof | |
US8583890B2 (en) | Disposition instructions for extended access commands | |
US20220121581A1 (en) | Controller and operation method thereof | |
US20220083274A1 (en) | Memory system and data processing system | |
CN108932112B (en) | Data read-write method, device, equipment and medium for solid particles | |
US9558112B1 (en) | Data management in a data storage device | |
US10740029B2 (en) | Expandable buffer for memory transactions | |
US20070162651A1 (en) | Data transfer control | |
US10324915B2 (en) | Information processing apparatus, processing apparatus, data search method | |
US8719542B2 (en) | Data transfer apparatus, data transfer method and processor | |
US8966133B2 (en) | Determining a mapping mode for a DMA data transfer | |
US20180336147A1 (en) | Application processor including command controller and integrated circuit including the same | |
US20160098306A1 (en) | Hardware queue automation for hardware engines |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BORCHERS, ALBERT T.;SWING, ANDREW T.;SPRINKLE, ROBERT S.;AND OTHERS;REEL/FRAME:025911/0888Effective date: 20100405 |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044142/0357Effective date: 20170929 |