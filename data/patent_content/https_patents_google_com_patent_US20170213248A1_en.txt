US20170213248A1 - Placing sponsored-content associated with an image - Google Patents
Placing sponsored-content associated with an image Download PDFInfo
- Publication number
- US20170213248A1 US20170213248A1 US11/966,429 US96642907A US2017213248A1 US 20170213248 A1 US20170213248 A1 US 20170213248A1 US 96642907 A US96642907 A US 96642907A US 2017213248 A1 US2017213248 A1 US 2017213248A1
- Authority
- US
- United States
- Prior art keywords
- image
- interest
- region
- local features
- content item
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0241—Advertisements
- G06Q30/0251—Targeted advertisements
- G06Q30/0255—Targeted advertisements based on user history
- G06Q30/0256—User search
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/30—Determination of transform parameters for the alignment of images, i.e. image registration
Definitions
- Interactive media e.g., the Internet
- advertisements have great potential for improving the targeting of advertisements (“ads”) to receptive audiences.
- some websites provide information search functionality that is based on keywords entered by the user seeking information. This user query can be an indicator of the type of information of interest to the user. By comparing the user query to a list of keywords specified by an advertiser, it is possible to provide targeted ads to the user.
- Another form of online advertising is ad syndication, which allows advertisers to extend their marketing reach by distributing ads to additional partners.
- third party online publishers can place an advertiser's text or image ads on web properties with desirable content to drive online customers to the advertiser's website.
- AdSenseTM offered by Google, Inc.
- selecting an advertisement includes storage for images and storage for advertisements.
- a first image for which an advertisement is to be selected is matched with a second image stored in the storage for images.
- An advertisement to be presented is selected from the storage for advertisements and based on an association between the advertisement and the second image stored in storage for images.
- Implementations may include one or more of the following features.
- presentation of the advertisement may be enabled in response to receiving the first image.
- Matching may include identifying a first image that is identical to the second image or identifying a first image that is substantially similar to the second image.
- the storage for images may include sub-images.
- the first image may be analyzed to identify a sub-image.
- Matching may include matching the identified sub-image of the first image with a second sub-image stored in the storage for images.
- Matching the identified sub-image of the first image may include using object recognition techniques to generate a likelihood that the stored sub-image includes the identified sub-image of the first image.
- Selecting an advertisement may include selecting an advertisement to be presented based on a comparison between the likelihood and a threshold.
- a sub-image may correspond to a region-of-interest of an image and may include one or more local features.
- the storage for images may include storage for regions-of-interest, local features and associations between local features and regions-of-interest.
- the first image may be analyzed to identify a region-of-interest.
- the region-of-interest may be analyzed to identify one or more local features included in the region-of-interest.
- Matching a first image may include matching the identified region-of-interest with a region-of-interest stored in the storage for regions-of-interest, where the matching is based on a comparison of local features included in the identified region of interest with one or more local features associated with at least one region-of-interest stored in the storage for regions-of-interest.
- Matching the identified sub-image of the first image may include using object recognition techniques to generate a likelihood that the stored region-of-interest matches the identified region-of-interest.
- Selecting an advertisement may include selecting an advertisement to be presented based on a comparison between the likelihood and a threshold.
- Matching the identified sub-image of the first image may include using object recognition techniques to generate a likelihood that the stored local features match the local features included in the identified region-of-interest.
- Selecting an advertisement may include selecting an advertisement to be presented based on a comparison between the likelihood and a threshold.
- the first image may be associated with search results to be presented over a network of computers.
- Presentation of the advertisement may be enabled with the search results over the network of computers.
- the first image may be associated with document content to be presented over a network of computers.
- Presentation of the advertisement may be enabled with presentation of the document content over the network of computers.
- selecting an advertisement includes storage for reference images and storage for sponsored-content items.
- a first image for which a sponsored-content item is to be selected is matched with a reference image stored in the storage for images.
- a sponsored-content item to be presented is selected from the storage for sponsored-content and based on an association between the sponsored-content item to be presented and the reference image.
- Implementations may include one or more of the features noted above and one or more of the following features.
- the storage for reference images may include reference sub-images.
- the first image may be analyzed to identify a sub-image.
- Matching a first image may include matching the identified sub-image of the first image with a reference sub-image stored in the storage for reference images.
- a first image for which a sponsored-content item is to be selected is matched with a reference image.
- a sponsored-content item to be presented is selected based on an association between the reference image with the sponsored-content item to be presented.
- Implementations may include one or more of the features noted above and one or more of the following features.
- the first image may be analyzed to identify a sub-image.
- Matching a first image may include matching the identified sub-image of the first image with a reference sub-image.
- Implementations of the techniques discussed above may include a method or process, a system or apparatus, or execution of computer software embodied in a computer-readable medium.
- the details of one or more of the implementations are set forth in the accompanying drawings and description below. Other features will be apparent from the description and drawings, and from the claims.
- FIGS. 1-3 are block diagrams of example user interfaces in imaged-based ad targeting systems.
- FIG. 4 is a block diagram of an example image-based ad targeting system.
- FIGS. 5 and 7 are flow diagrams of example process flows for image-based ad targeting.
- FIG. 6 illustrates an example of an environment for implementing an image-based ad targeting system.
- FIG. 8 is a flow diagram of an example process flow for image-based ad targeting.
- FIGS. 9A and 9B are block diagrams of example user interfaces from an image-based ad targeting system.
- FIG. 10 is a flow diagram of an example process flow for presenting images for bidding for an image with which to present ads.
- FIG. 11 is a block diagram of an example user interface for bidding in an image-based ad targeting system.
- FIG. 12 illustrates an example of an environment for providing advertisements for video content items.
- FIG. 13 is a flow diagram of an example process flow for preprocessing video content items for images and retrieving associated ads.
- FIGS. 14 and 16 are block diagrams of example user interfaces illustrating advertising content displayed on a screen with video content.
- FIG. 15 is a flow diagram of an example process flow for retrieving ads associated with images in a video content item.
- FIG. 17 shows an example environment for the presentation of advertisements associated with a digital photograph.
- FIG. 18 is a flow diagram of an example process flow for the presentation of advertisements associated with a digital photograph.
- FIG. 19 is a block diagram illustrating an example generic computer and an example generic mobile computer device.
- FIGS. 1-3 depicts example user interfaces in image-based ad targeting systems.
- FIG. 1 shows an example user interface 100 in a search service that receives a query from a user, retrieves and presents relevant search results from an index of content, and presents advertisements based on the search results. More particularly, the presented advertisements are based on an image included in the search results.
- the user interface 100 includes a title 110 showing a search query 110 A entered by a user for which search results 120 are presented.
- the search results 120 include two search results 120 A and 120 B for the search query 110 A.
- Each search result 120 A and 120 B includes a hypertext link 125 A or 125 B, respectively, to the web pages identified in the search index used by the search service.
- Each search result 120 A and 120 B includes a snippet of text extracted from those web pages (i.e., text descriptions 130 A or 130 B, respectively).
- Search result 120 A also includes an image 135 A returned with the search result 120 A.
- the image 135 A may be, for example, a graphic image, a digital photograph or a frame from a video.
- the user interface 100 also includes advertisements 150 identified based on the search results 120 .
- An advertisement or an “ad” refers to any form of communication in which one or more products, services, ideas, messages, people, organizations or other items are identified and promoted (or otherwise communicated). Ads are not limited to commercial promotions or other communications.
- An ad may be a public service announcement or any other type of notice, such as a public notice published in electronic press or a broadcast.
- An ad may be referred to or include sponsored content.
- the ads 150 include ads 150 A and 150 B. Each ad 150 A and 150 B includes a hypertext link 155 A or 155 B, respectively, to the advertiser's web page. Each ad 150 A and 150 B includes ad text 160 A or 160 B, respectively. Ad 150 A also includes an ad image 165 A.
- the image 165 A may be, for example, a graphic image, a digital photograph or a frame from a video.
- the ad image 165 A may be substantially similar to or the same as the search result image 135 A returned with the search results 120 , though the ad image 165 A need not necessarily be similar to or the same as the image 135 A.
- the ads 150 A and 150 B are identified and presented based on the search result image 135 A, as described more fully later.
- FIG. 2 depicts an example user interface 200 presented by a content provider that presents content to users.
- the user interface 200 includes a title 210 and a list 220 of content items 220 A and 220 B.
- the content items 220 A and 220 B may be, for example, articles, discussion threads, music, audio, video, graphics, search results and webpage listings.
- Each content item 220 A and 220 B includes a hypertext link 225 A or 225 B, respectively, to an associated content item (such as a web page, a music file, or a video file).
- Each content item 220 A and 220 B includes descriptions 230 A or 230 B.
- Content item 220 A also includes an image 235 A.
- the image 235 A may be, for example, a graphic image, a digital photograph or a frame from a video.
- the user interface 200 also includes an ad 250 identified based on the image 235 A included in the content item 220 A.
- the ad 250 includes a hypertext link 255 to the advertiser's web page, ad text 260 and an ad image 265 , which may be, for example, a graphic image, a digital photograph or a frame from a video.
- the ad 250 is identified and presented based on the content image 235 A, as described more fully later.
- FIG. 3 depicts an example user interface 300 presented by a provider of an online photograph application.
- the user interface 300 includes a title 310 and a list 320 of photograph items 320 A and 320 B for a user who is a subscriber of the online photograph application.
- Each photograph item 320 A and 320 B includes a hypertext link 325 A or 325 B, respectively, to an associated photograph.
- Each photograph item 320 A and 320 B includes a small representation (e.g., a thumbnail) 330 A and 330 B of the associated photograph and a description 335 A or 335 B.
- the user interface 300 also includes an ad 350 identified based on the photograph item 320 A and/or photograph item 320 B, as described more fully later.
- the ad 350 includes a hypertext link 355 to the advertiser's web page, and ad text 360 .
- FIG. 4 illustrates an example image-based ad targeting system 400 .
- the image-based ad targeting system 400 is a computer system including one or more processors (not shown), software 420 for an executable image matching process, and three persistent data stores: a sub-image data store 430 for storing sub-images, an associations data store 440 for storing associations between ads and sub-images, and an ads data store 450 for storing ads.
- the data stores 430 , 440 and 450 may be one or more databases, a collection of files (such as XML files or a file in any picture storage format, such as .emz, .gif, .jpg or .mpg), or another type of data collection.
- the ad targeting system 400 is configured to receive an image 455 for which an ad 460 is to identified and execute the matching process 420 that accesses the data stores 430 - 450 to identify ad 460 based on the received image 455 .
- a process 500 for matching an ad to an image may be an implementation of image matching process 420 of FIG. 4 .
- the ad targeting system 400 receives and parses the image 455 ( 510 ).
- the ad targeting system 400 may use computer vision techniques to identify a portion of the image 455 to be used for ad targeting.
- the identified portion of the image 455 may be referred to, for example, as a sub-image, which may be a region-of-interest, a patch, a local feature, or another portion of an image.
- the ad targeting system 400 searches the sub-image data store 430 for a sub-image that matches the sub-image parsed from the received image (“parsed sub-image”) ( 520 ).
- the ad targeting system 400 identifies, in the association data store 440 , an association between the sub-image found in the sub-image data store 430 and an advertisement stored in the ads data store 450 ( 530 ).
- the ad targeting system 400 retrieves the identified ad from the ads data store 450 and enables presentation of the identified ad ( 550 ).
- FIG. 6 illustrates an example of an environment 600 for implementing an image-based ad targeting system.
- one or more advertisers 602 can directly, or indirectly, enter, maintain, and track ad information in an advertising management system 604 .
- the advertising management system 604 may be an implementation of the ad targeting system 400 of FIG. 4 .
- the advertising management system 604 is configured to identify an ad based on an image.
- the advertising management system 604 is configured to store sub-images used to match a portion of a received image, ads, and associations between ads and sub-images.
- the ads may be in the form of graphical ads, such as banner ads, text only ads, image ads, audio ads, video ads, ads combining one of more of any of such components, etc.
- the ads may also include embedded information, such as a links, meta-information, and/or machine executable instructions.
- One or more publishers 606 may submit requests for ads to the system 604 .
- the system 604 responds by sending ads to the requesting publisher 606 for placement on one or more of the publisher's media properties (e.g., websites video content, or other content) based on one or more images.
- Other entities can provide usage information to the system 604 , such as, for example, whether or not a conversion or click-through related to an ad has occurred.
- usage information such as, for example, whether or not a conversion or click-through related to an ad has occurred.
- a “click-through” may be said to occur when a user selects a presented ad by clicking on the ad, embedded hypertext links, executable code, and any type of user selection related to the presented ad, where the click or another type of selection typically directs the user to the advertiser's web site or the advertiser's online or real world presence.
- a conversion may be said to occur when a user consummates a transaction related to a previously served ad. What constitutes a conversion may vary from case to case and may be determined in a variety of ways. For example, it may be the case that a conversion occurs when a user clicks on an ad, is referred to the advertiser's web page, and consummates a purchase there before leaving that web page. Alternatively, a conversion may be defined as a user being shown an ad, and making a purchase on the advertiser's web page within a predetermined time (e.g., a seven days). Many other definitions of what constitutes a conversion are possible.
- This usage information can include measured or observed user behavior related to ads that have been served.
- the system 604 performs financial transactions, such as crediting the publishers 606 and charging the advertisers 602 based on the usage information.
- the system 604 also may use the usage information, in lieu of or in addition to, impression information to select ads for presentation.
- a computer network 610 such as a local area network (LAN), wide area network (WAN), the Internet, or a combination thereof, connects the advertisers 602 , the system 604 , the publishers 606 , and the users 608 .
- LAN local area network
- WAN wide area network
- the Internet or a combination thereof, connects the advertisers 602 , the system 604 , the publishers 606 , and the users 608 .
- a publisher 606 is a general content server that receives requests for content (e.g., articles, discussion threads, music, video, graphics, search results, web page listings, information feeds, etc.), and retrieves the requested content in response to the request.
- the content server may submit a request for ads to an advertising management system 604 .
- the ad request may include a number of ads desired.
- the ad request may also include content request information that identifies an image for which an ad is to be returned. This content request information can include the image itself, a storage location or retrieval mechanism for the image, or another type of information that identifies the image.
- the content request information also can include identification of content itself (e.g., image, page, video, or other content document), a category corresponding to the content or the content request (e.g., arts, business, computers, arts-movies, arts-music, etc.), part or all of the content request, content age, content type (e.g., text, graphics, video, audio, mixed media, etc.), geo-location information, etc.
- identification of content itself e.g., image, page, video, or other content document
- a category corresponding to the content or the content request e.g., arts, business, computers, arts-movies, arts-music, etc.
- content age e.g., text, graphics, video, audio, mixed media, etc.
- geo-location information e.g., geo-location information, etc.
- the content server can combine the requested content with one or more of the ads provided by the system 604 .
- This combined content and ads can be sent to the user 608 that requested the content for presentation in a viewer (e.g., a browser or other content display system).
- the content server can transmit information about the ads back to the advertising management system, including information describing how, when, and/or where the ads are to be rendered (e.g., in HTML or JavaScriptTM).
- a search service can receive queries for search results.
- the queries may include images.
- the search service can retrieve relevant search results from an index of documents (e.g., from an index of web pages).
- An exemplary search service is described in the article S. Brin and L. Page, “The Anatomy of a Large-Scale Hypertextual Search Engine,” Seventh International World Wide Web Conference, Brisbane, Australia and in U.S. Pat. No. 6,285,999, both of which are incorporated herein by reference each in their entirety.
- Search results can include, for example, lists of web page titles, snippets of text extracted from those web pages, hypertext links to those web pages, images, videos, and may be grouped into a predetermined number of (e.g., ten) search results.
- the search service can submit a request for ads to the system 604 .
- the request may include, or identify an image to be used for ad targeting.
- the request may also include a number of ads desired. This number may depend on the search results, the amount of screen or page space occupied by the search results, the size and shape of the ads, etc. In some implementations, the number of desired ads will be from one to ten, or from three to five.
- the request for ads may also include the query (as entered or parsed), information based on the query (such as geo-location information, whether the query came from an affiliate and an identifier of such an affiliate, or whether the query was an image), and/or information associated with, or based on, the search results.
- Such information may include, for example, identifiers related to the search results (e.g., document identifiers or “docIDs”), images or videos included in the search results, scores related to the search results (e.g., information retrieval (“IR”) scores), snippets of text extracted from identified documents (e.g., web pages), full text of identified documents, feature vectors of identified documents, etc.
- IR scores can be computed from, for example, dot products of feature vectors corresponding to a query and a document, page rank scores, and/or combinations of IR scores and page rank scores, etc.
- the search service can combine the search results with one or more of the ads provided by the system 604 . This combined information can then forwarded to the user 608 that requested the content.
- the search results can be maintained as distinct from the ads, so as not to confuse the user between paid advertisements and presumably neutral search results.
- the search service can transmit information about the ad and when, where, and/or how the ad was to be rendered back to the system 604 .
- the advertising management system 604 can serve publishers 606 , such as content servers and search services.
- the system 604 permits serving of ads targeted to documents served by content servers.
- a network or inter-network may include an advertising management system serving targeted ads in response to requests from a search service with ad spots for sale.
- the search service crawls much or all of the content.
- Some of this content will include ad spots (also referred to as “inventory”) available.
- one or more content servers may include one or more documents. Documents may include images, videos, web pages, email, content, embedded information (e.g., embedded media), meta-information and machine executable instructions, and ad spots available.
- the ads inserted into ad spots in a document can vary each time the document is served or, alternatively, can have a static association with a given document.
- FIG. 7 is a flow diagram of an example process 700 for image-based ad targeting for a content publisher.
- the process 700 may be executed, for example, by an ad targeting system, such as the ad targeting system 400 of FIG. 4 or the ad management system 604 of FIG. 6 .
- a publisher of a webpage may enroll in an ad syndication program to increase revenue by receiving and displaying ads targeted to content on the webpage.
- the publisher sends to the ad targeting system a request for ads to be targeted based on an image.
- an image to be included in the content web page to be displayed may be used to target an ad that is displayed along with the content including the image.
- the ad targeting system uses the received image to select targeted ads for the webpage.
- the ad targeting processes 700 and 800 each match an image for which ads are to be identified (which may be referred to as a received image) to a reference image based on local features.
- the received image includes one or more regions-of-interest and each of the regions-of-interest includes one or more local features.
- a received image may include a logo and an image background where the logo is identified as a region-of-interest, which, in turn, includes local features, such as various portions of the logo.
- the reference image may correspond to the logo (i.e., the reference region-of-interest in this example), which may be decomposed into various local features.
- an image may be received that includes the Eiffel Tower.
- the Eiffel Tower may be identified as a region-of-interest, and the tip of the Eiffel Tower may be identified as one or many local features of the region-of-interest (i.e., the Eiffel Tower in this example).
- an ad targeting process may select an ad by matching a target image to a reference image based on identification of the region-of-interest in the target image, decomposing the region-of-interest into local features, matching local features of the target image with reference local features, identifying a reference image corresponding to the reference local features that match the local features of the target image, and identifying an ad associated with the identified reference image.
- the ad targeting process 700 begins when an ad request is received by the ad targeting system from a content publisher, such publisher system 606 of FIG. 6 ( 710 ).
- the ad request includes context information that is used to select targeted ads. While the content information can include a variety of content types, for the purposes of illustration only, this example describes content information including one or more image files.
- the ad targeting system analyzes the received image (here, the image file included in the ad request) to identify one or more regions-of-interest ( 720 ).
- Regions-of-interest are portions or sections of the image file that are visually distinguishable and stable. Regions-of-interest are visually distinguishable and stable are likely to be, or relate to, the subject or subjects of the image.
- an image of a chair in a room may be analyzed to identify the chair as a region-of-interest where the background (such as a floor, ceiling and walls of the room in which the chair is depicted) is not included in the region-of-interest.
- a chair and a person standing in the room each may be identified as a region-of-interest.
- the ad targeting system identifies local features associated with identified region-of-interest(s) ( 730 ).
- local features may be identified for each identified region-of-interest, although not all regions-of-interest need necessarily be decomposed into one or more local features.
- the ad targeting system identifies matching regions-of-interest ( 740 ). This may be accomplished, for example, by comparing the local features identified for the received or target image with stored local features associated with regions-of-interest .
- the local features, associations with regions-of-interest, and/or regions-of-interest may be stored in an image repository, such as sub-image data store 430 of FIG. 4 , for example.
- the matching may be performed by computer vision techniques or another type of pattern matching process. For example, image matching may be performed based on image matching techniques described by Patent Cooperative Treaty Patent Application WO 2005/114476 and titled MOBILE IMAGE-BASED INFORMATION RETRIEVAL SYSTEM, which is incorporated in its entirety herein.
- the image repository may contain regions-of-interest that advertisers have selected, or bid on, to associate with one or more ads, as described more fully later.
- the ad targeting system identifies ads corresponding to regions-of-interest in the image repository that indirectly are matched, based on matching local features, to the target regions-of-interest from the received image ( 750 ). For example, the ad targeting system may search for an association between an identified sub-image and an ad.
- a sub-image may include a pointer, a link, or otherwise identify one or more advertisements to be presented based on the sub-image.
- an association data stored such as associations 440 of FIG. 4 , may be searched to identify ad(s) to be presented with the sub-image.
- usage information such as whether or not a conversion or click-through has occurred may be collected, stored and used based on a region-of-interest or sub-image. For example, information for the number of times a region-of-interest or sub-image has been clicked-through by users may be used to determine relevancy of an ad, such as, by weighing a region-of-interest or sub-image based on the number of times the region-of-interest or sub-image.
- the ad targeting system enables presentation of the ad(s) associated with the sub-images that match the received image for which ads are to be identified ( 760 ). This may be accomplished, for example, by transmitting or otherwise delivering the ad to the requesting publisher system. Alternatively or additionally, the ad targeting system may combine ads with content provided by the publisher system and presented to a user of the publisher system.
- FIG. 8 is a flow diagram of another example process 800 for image-based ad targeting.
- the process 800 may be executed, for example, by an ad targeting system, such as the ad targeting system 400 of FIG. 4 or the ad management system 604 of FIG. 6 .
- the process 800 is performed to provide ads based on search results returned by a search service and, similarly to the process 700 described previously with respect to FIG. 7 , decompose an image into one or more regions-of-interest and further decompose one or more regions-of-interest into one or more local features, which, in turn, are used to match reference local features.
- search engine providers may desire to present search results along with ads targeted to the search results.
- ads may be targeted to the images, rather than, or in addition to, ads targeted to the textual search results.
- the steps of process 800 do not have to occur in a specific order and at least some steps can occur in parallel.
- Search results including an image are received ( 810 ).
- a request for ads that includes search results or an image for which ads are to be identified may be received from a provider of a search service.
- process 800 may be performed by a search service.
- the ad targeting system analyzes the image to identify one or more regions-of-interest ( 820 ), identify one or more local features included in one or more regions-of-interest by decomposing a region-of-interest into local features ( 830 ), identify matching one or more regions-of-interest based on local features shared by, or similar to, reference local features ( 840 ), identify one or more ads associated with one or more of the matched regions-of-interest ( 850 ), and enable presentation of the one or more ads associated with the one or more region-of-interest found to match the target image for which ads are to be identified ( 860 ). This may be accomplished, for example, by techniques described previously with respect to FIG. 7 ( 720 - 750 ).
- FIGS. 9A and 9B are example user interfaces 900 A and 900 B that display ads based on images.
- the user interface 900 A is from a photography website.
- the user interface 900 A includes a window 404 displaying a photograph of a computer.
- a publisher of the photography website may be participating in an ad syndication program.
- the publisher of the photography website requests ads targeted to the contents of the window 904 and presents the targeted ads in the window 908 .
- a request including the computer image is sent to an ad targeting system.
- the image of the computer displayed in window 904 is sent along with the request for ads to an ad targeting system, such as the ad targeting system 400 of FIG. 4 or the advertising management system 604 of FIG. 6 .
- the ad targeting system analyzes the image to identify the sub-image of the computer, identifies a matching sub-image in stored images what that associated with ads, and identifies the ads that are associated with the stored image of a computer found to match the computer image.
- the ad targeting system may analyze the image to identify one or more regions-of-interest, decompose one or more regions-of-interest into one or more local features, match the decomposed local features to reference local features to identify a matching reference region-of-interest, which, in turn, is associated with one or more ads to be presented.
- ads are selected from the identified ads based on advertiser bids. For example, ads that have the highest associated bid are retrieved and returned to the publisher to be provided with the displayed web page.
- the ads shown in window 908 are hyperlinks to web pages of corresponding advertisers.
- FIG. 9B a user of the photography website has continued to a different photograph illustrated by the image of the dog and a tree in window 904 .
- the ads in window 908 have been updated to reflect the change.
- a new ad request was made by the publisher to the advertising management system 604 .
- the request included the image of the dog and tree shown in window 904 .
- the image was analyzed to locate regions-of-interest. In this example, there are two regions-of-interest, a dog and a tree.
- the ad targeting system decomposes both regions-of-interest into local features, which, in turn, are compared with the local features stored in the image database.
- Ads associated with the regions-of-interest corresponding to local features found to match the target local features were retrieved and used to populate the window 908 according to the amount bid on each image. Because the dog and the tree were identified as regions-of-interest, the ads displayed in the window 908 are both pet and tree related, reflecting the type of ad that may have been associated with an image of a dog or an image of a tree.
- FIG. 10 depicts an example process 1000 for presenting images for bidding for an image with which to present ads.
- the example process 1000 is described with respect to a region-of-interest, though different granularities of images may be used. Also, the process 1000 is described with respect to bidding on a single region-of-interest and a single ad, the process 1000 may be used to receive bids for multiple regions-of-interest and/or advertisements. The steps of process 1000 do not have to occur in a specific order and at least some steps can occur in parallel. As described with respect to FIG. 6 , advertisers may bid on a particular image in an image database to associate with a desired ad.
- an advertiser may determine what an appropriate bid for a particular image is or may otherwise desire to know what bids have been placed on similar images.
- the particular image that an advertiser is interested in may be compared against the database of images to locate similar reference images. Bids associated with these reference images may then be presented to the advertiser as suggested bids.
- an image-based ad targeting system may present ads based on images and associated bids placed by advertisers.
- the ad targeting system executing process 1000 receives an image (or indication thereof) on which an advertiser may place a bid ( 1010 ).
- the advertiser may select an image from an a repository of images available to be associated with an ad. For example, an advertiser may wish to have an advertisement for a shoe store appear when a particular shoe image is displayed. The advertiser may browse a repository to locate available images of shoes. When the advertiser has found a suitable shoe image or images the advertiser may select them for bidding.
- an advertiser submit, upload or otherwise provide an image or images to be associated with an ad and a bid.
- the advertiser may wish to have a particular ad display when an image of the advertiser's logo is displayed. Accordingly, the advertiser may submit one or more images of the logo to be associated with one or more ads.
- an advertiser may provide more than one images to be matched, and perhaps many more than one. In some instances, an advertiser may provide tens or hundreds of image variations of a logo or product to increase the likelihood of an image of the logo or product being matched.
- the advertiser may annotate the image to highlight a desired region-of-interest. Because an image may contain several regions-of-interest that may not be germane to the advertiser's business, the advertiser may wish to specify the particular feature that the advertiser wishes to associate with a desired ad. Continuing the example given above, the advertiser may have one or more images of the desired logo. Many of the images may feature the logo on cars, or t-shirts, or may also include objects that the advertiser is not interested in associating the ad with. Accordingly, the advertiser may annotate the image to point out, highlight or otherwise identify the desired region-of-interest of the image. In some implementations, advertisers may circle, highlight or otherwise identify the desired regions-of-interest on the image using a selection tool included in a user interface, for example.
- the ad targeting system searches for one or more similar regions-of-interest associated with bids ( 1020 ).
- the ad targeting system may decompose a region-of-interest and search into one or more local features and search an image repository for reference local features similar to the target local features decomposed from the target region-of-interest .
- the image repository may be searched for reference local features using image and object recognition techniques, for example. Because the reference local features may not be identical to the decomposed local features, a particular statistical threshold used to locate the reference local features may be lower than the threshold used to match database local features when locating associated advertisements.
- the received image may be used to identify local features. Additionally or alternatively, regions-of-interest or another type of sub-image of the received image may be used to identify similar regions-of-interest or sub-images in the repository. In some implementations, regions-of-interest may be categorized or classified to indicate the contents of the image or to generally describe the subject of the image. These categories may be used to locate reference images instead of, or in addition to, searching the image database using image and object recognition techniques as described above.
- the ad targeting system presents suggested bid for received image based on bids associated with similar regions-of-interest ( 1030 ). For example, the ad targeting system may present the advertiser with the identified reference regions-of-interest along with associated bids.
- the suggested bid may be computed by averaging the maximum bids of the reference regions-of-interest identified, or using a weighted average of the maximum bids of the reference regions-of-interest where more popular regions-of-interest are given a higher weight, for example. Any number of statistical methods may be used to calculate the suggested bid.
- the bids may be presented using a user interface 1100 as illustrated by FIG. 11 , for example.
- the ad targeting system receives from the advertiser a bid to be associated with the received region-of-interest ( 1040 ) and identify an advertisement to be presented based on the regions-of-interest ( 1050 ).
- the received region-of-interest, bid and advertisement are stored for later use in identifying an advertisement based on the image ( 1060 ).
- the ad may be stored in the sub-image data store 430
- the association may be stored in the associations data store 440
- the ad may be stored in the ads data store 450 of FIG. 4 .
- the advertiser may bid on one or more of the presented reference sub-images.
- the advertiser may provide an additional advertisement to associate with the reference image, or may use the same advertisement used for the desired image.
- FIG. 11 illustrates an example user interface 1100 for bidding in an image-based ad targeting system.
- an advertiser may bid to have an ad or ads associated with a selected image.
- the associated ad may be presented when the selected image appears in the contents of a webpage or search engine results and the bid is the highest bid or among the highest bids for the image, for example.
- An image of a computer to bid on is displayed in image window 1110 .
- the advertiser presents or uploads the image.
- the advertiser may have selected the image from a repository of images.
- the user interface 1100 also displays in reference window 1120 reference images that are identified based on image shown in image window 1110 .
- Each of the reference images in image window 1110 includes an associate maximum bid that have been entered by another advertiser for the reference image, though the reference images need not necessarily be presented with associated bids.
- As shown in window 1120 three images of computers have been displayed as reference images.
- the displayed reference images have received maximum bids of five, seven, and nine dollars.
- the reference images may be determined using object or image recognition techniques to identify reference images with similar features, referencing categories or classifications associated with the images, or a combination of both.
- the advertiser may determine an appropriate bid for the selected image.
- the advertiser may enter the bid in the text box displayed in window 1110 , and submit the entered bid by activating the associated button labeled “Bid”, for example.
- the user interface 1100 enables an advertiser to make additional bids on one or more of the displayed reference images.
- the advertiser may place bids on the displayed reference images instead of, or in addition to, the selected image. Accordingly, the advertiser may enter the bids in the text boxes (i.e., labeled “Your bid”) underneath each of the reference images in window 1120 .
- Video content may include multiple frames, with each frame including an image which are displayed in rapid succession to create the illusion of motion to a viewer.
- FIG. 12 shows an example of an environment 1200 for providing advertisements for video content items.
- a “video content item” is an item of content that includes content that may be perceived visually when played, rendered, or decoded.
- a video content item includes video data, and optionally audio data and metadata.
- Video data includes content in the video content item that may be perceived visually when the video content item is played, rendered, or decoded.
- Audio data includes content in the video content item that may be perceived aurally when the video content item is played, decoded, or rendered.
- a video content item may include video data and any accompanying audio data regardless of whether or not the video content item is ultimately stored on a tangible medium.
- a video content item may include, for example, a live or recorded television program, a live or recorded theatrical or dramatic work, a music video, a televised event (e.g., a sports event, a political event, a news event, etc.), video voicemail, etc.
- a live or recorded television program e.g., a live or recorded theatrical or dramatic work
- a music video e.g., a sports event, a political event, a news event, etc.
- a televised event e.g., a sports event, a political event, a news event, etc.
- video voicemail e.g., a televised event
- Each of different forms or formats of the same video data and accompanying audio data may be considered to be a video content item (e.g., the same video content item, or different video content items).
- a video content item may also include many types of associated data.
- types of associated data include video data, audio data, closed-caption or subtitle data, a transcript, content descriptions (e.g., title, actor list, genre information, first performance or release date, etc.), related still images, user-supplied tags and ratings, etc.
- content descriptions e.g., title, actor list, genre information, first performance or release date, etc.
- related still images e.g., title, actor list, genre information, first performance or release date, etc.
- user-supplied tags and ratings e.g., text, etc.
- Some of this data, such as the description may refer to the entire video content item, while other data (e.g., the closed-caption data) may be temporally-based or time-coded.
- the environment 1200 includes, or is communicably coupled with, an advertisement provider system 1205 (having access to advertisement repository 1210 ), a content provider system 1215 , and one or more user devices 1220 , at least some of which communicate across network 1225 .
- the advertisement provider system 1205 may provide relevant advertising content (“ad content”) or other relevant content to a video content item.
- the advertisement provider system 1205 may be an implementation of the advertising management system 604 of FIG. 6 .
- reference is made to delivering ad content though other forms of content (e.g., other content item types) may be delivered.
- the presented content may be provided by the content provider system 1215 through the network 1225 .
- the ad content may be distributed, through network 1225 , to one or more user devices 1220 before, during, or after presentation of the material.
- advertisement provider system 1205 may be coupled with an advertising repository 1210 .
- the ad repository stores advertisements that may be presented with various types of content, including audio and/or video content.
- the selection of advertisements for presentment with the video content item is determined based on images. For example, an ad may be targeted for presentation in a video content item based on an image in one or more frames of the video content item.
- Video content may be consumed at various client locations, using various devices.
- the various devices include customer premises equipment which is used at a residence or place of business (e.g., computers, video players, video-capable game consoles, televisions or television set-top boxes, etc.), a mobile telephone with video functionality, a video player, a laptop computer, a set top box, a game console, a car video player, etc.
- Video content may be transmitted from various sources including, for example, terrestrial television (or data) transmission stations, cable television (or data) transmission stations, satellite television (or data) transmission stations, via satellites, and video content servers (e.g., Webcasting servers, podcasting servers, video streaming servers, video download Websites, etc.), via a network such as the Internet for example, and a video phone service provider network such as the Public Switched Telephone Network (“PSTN”) and the Internet, for example.
- PSTN Public Switched Telephone Network
- Ad content may include text, graphics, still-images, video, audio, audio and video, banners, links (such as advertising providing a hyperlink to an advertiser's website), and other web or television programming related data.
- ad content may be formatted differently, based on whether the ad content is primarily directed to websites, media players, email, television programs, closed captioning, etc.
- ad content directed to a website may be formatted for display in a frame within a web browser.
- ad content may be delivered in an RSS (Real Simple Syndication) feed, or ad content may be delivered relative to a radio item (such as before, during or after a radio item).
- ad content directed to a video player may be presented “in-stream” as video content is played in the video player.
- in-stream ad content may replace the video or audio content in a video or audio player for some period of time or may be inserted between portions of the video or audio content.
- An in-stream advertisement may include video, audio, text, animated images, still images, or some combination thereof.
- the content provider system 1215 may present video content to users (e.g., user device 1220 ) through the network 1225 .
- the content provider system 1215 may be an implementation of the publisher system 606 of FIG. 6 .
- the content provider system 1215 may include web servers where the content includes webpages or other content written in the Hypertext Markup Language (HTML), or any language suitable for authoring webpages.
- HTML Hypertext Markup Language
- content provider system 1215 may include users, web publishers, and other entities capable of distributing video content over a network. For example, a web publisher may post a video file on a publicly available web server for download and playing by other users.
- the content provider system 1215 may make the content accessible through a known Uniform Resource Locator (URL).
- URL Uniform Resource Locator
- the content provider system 1215 may receive requests for video content.
- the content provider system 1215 may retrieve the requested video content in response to, or otherwise service, the request.
- the content provider system 1215 may broadcast video content as well (e.g., providing content though not necessarily responsive to a request).
- Content provided by content provider system 1215 may include news, weather, entertainment, or other consumable textual, audio, or video media. More particularly, the content may include various resources, such as documents (e.g., webpages, plain text documents, Portable Document Format (PDF) documents, and images), video or audio clips, etc. In some implementations, the content may be graphic-intensive, media-rich data, such as, for example, Flash-based content that presents video and sound media.
- documents e.g., webpages, plain text documents, Portable Document Format (PDF) documents, and images
- PDF Portable Document Format
- the content may be graphic-intensive, media-rich data, such as, for example, Flash-based content that presents video and sound media.
- the environment 1200 includes one or more user devices 1220 .
- the user device 1220 may include a desktop computer, laptop computer, a media player (e.g., an MP3 player, a streaming audio player, a streaming video player, a television, a computer, a mobile device, a DVD player, etc.), a mobile phone, a browser facility (e.g., a web browser application), an e-mail facility, telephony means, a set top box, a television device, a radio device or other device that may access advertisements and other content via network 1225 .
- One or more of the user devices 1220 may be implementations of user devices 608 of FIG. 6 .
- the content provider system 1215 may permit user device 1220 to access content (e.g., video files for downloading or streaming).
- the network 1225 facilitates wireless or wireline communication between the advertisement provider system 1205 , the content provider system 1215 , and any other local or remote computers (e.g., user device 1220 ).
- the network 1225 may be all or a portion of an enterprise or secured network.
- the network 1225 may be a virtual private network (VPN) between the content provider system 1215 and the user device 1220 across a wireline or a wireless link.
- VPN virtual private network
- the network 1225 may be logically divided into various sub-nets or virtual networks without departing from the scope of this disclosure, so long as at least a portion of the network 1225 may facilitate communications between the advertisement provider system 1205 , content provider system 1215 , and at least one client (e.g., user device 1220 ).
- the network 1225 may be a secure network associated with the enterprise and certain local or remote clients 1220 .
- Examples of network 1225 include a local area network (LAN), a wide area network (WAN), a wireless phone network, a Wi-Fi network, a WiMax network, a broadband network, and the Internet.
- LAN local area network
- WAN wide area network
- wireless phone network a Wi-Fi network
- WiMax wireless wide area network
- broadband network a broadband network
- Internet the Internet
- a video content item is combined with one or more of the ads provided by the advertisement provider system 1205 , for example, based on an image appearing in the video content item.
- This combined information including the content of the content item and ad(s) is then forwarded toward a user device 1220 that requested the content item or that configured itself to receive the content item, for presentation to a user.
- the content provider system 1215 may transmit information about the ads and how, where or when the ads are to be rendered based on an image in the video content item back to the advertisement provider system 1205 through the network 1225 . Alternatively, or in addition, such information may be provided back to the advertisement provider system 1205 by some other means.
- the content provider system 1215 includes advertisement media as well as other content.
- the advertisement provider system 1205 may determine and inform the content provider system 1215 which advertisements to send to the user device 1220 , for example.
- FIG. 13 is an example process 1300 for processing video content items for images and retrieving associated ads.
- the process 1300 may be performed such that the video content item is preprocessed to associate ads with images prior to enabling viewing of the video. Additionally or alternatively, the process 1300 may be used to identify ads based on images in the video while the video is being viewed or streamed for viewing.
- the video content item may be preprocessed to identify images in the video content item and the ads may be associated with the images at a later time, such as while the video is being viewed or streamed for viewing.
- the steps of process 1300 do not have to occur in a specific order and at least some steps can occur in parallel.
- a video content item is received for processing ( 1310 ).
- the video content item may be preprocessed to locate images in the various frames that may have associated advertisements.
- the video content item may be processed as the video is being viewed or streamed for viewing.
- a user or advertiser may have bid to have an ad displayed with a particular image. It may be desirable to also display the ad when the image, or a similar image, appears in a video content item.
- the ad may be displayed in the same window as the video content item, or may be displayed in a separate window.
- the frames of the video content item are analyzed to find regions-of-interest ( 1320 ).
- each frame of the video content item is analyzed to identify regions-of-interest.
- some sampling rate may be chosen for frame analysis. For example, every 24 frames may be selected for analysis.
- the identified regions-of-interest are decomposed into local features ( 1325 ), which are used to search against the reference local features associated with one or more reference regions-of-interest ( 1330 ).
- the target local features images may be matched against reference local features using image or object recognition techniques.
- a local feature may be considered a match, if the one or more identified local features match with a confidence level greater than a selected threshold, for example.
- Stored one or more region(s)-of-interest that match local features are identified, and the ads associated with the one or more regions-of-interest are retrieved ( 1340 ).
- the retrieved ads are associated with the video content item ( 1350 ).
- the ads may be associated with the video content item such that when a frame of the video content item is displayed that contains one or more images with associated ads, the ads are retrieved and displayed at the same time that the video content item is played.
- the ads may be displayed in an overlay on top of a media player currently processing the video content item, or in a separate window, for example.
- the ads or references to the ads may be embedded into the video content item and decoded or retrieved by a media player capable of recognizing the embedded ads.
- the ads or references to the ads may be stored in a separate file that indicates where and how the ads may be presented to the user during video content item playback.
- FIG. 14 is an example user interface 1400 illustrating advertising content displayed on a screen with video content where the displayed ads are based on an image.
- the user interface 1400 illustrates an example web browser user interface.
- the content shown in the user interface 1400 can be presented in a webpage, an MP3 player, a streaming audio player, a streaming video player, a television, a computer, a mobile device, etc.
- the content shown in the user interface 1400 may be provided by an advertisement provider 1205 , a content provider 1215 , another networked device, or some combination of those providers.
- the user interface 1400 includes a video player region 1410 including an image 1415 on which an ad presented in ad region 1420 is based.
- the video display region 1410 may include a media player for presenting text, images, video, or audio, or any combination thereof.
- the ad region 1420 displays advertisements (e.g., banner ads, flash-based video/audio ads, scrolling ads, etc.) based on an image shown in the video player region.
- the ad displayed in ad region 1420 may be associated with an image in the video player region 1410 , for example, based on the process 1300 of FIG. 13 .
- FIG. 15 is an example process 1500 for retrieving ads associated with images in a video content item.
- the process 1500 may be used to present ads in ad region 1320 of FIG. 13 .
- the frames of the video content item may be analyzed for images with associated ads as the video frames are presented.
- the steps of process 1500 do not have to occur in a specific order and at least some steps can occur in parallel.
- a video content item is played for viewing ( 1510 ).
- a video content item may be played on a media player and the video content item may be displayed, for example, in a video player region, such as region 1410 of FIG. 14 .
- a buffer may be utilized to allow some time for the processing of the video content item frame and the retrieval and display of the associated ads.
- the particular size of the buffer may vary depending on the resources of the computer performing the processing, and other factors such as the complexity of the video content item frame, and the rate at which the video frames are processed.
- a selected, or current, frame of the video content item is analyzed for one or more region(s)-of-interest ( 1520 ).
- the frame may be selected from a buffer or frame queue.
- Each frame in the video content item may be analyzed, or some sampling rate may be selected for the video content item to reduce the number of frames that are analyzed, such as every 24 frames for example.
- the particular sampling rate chosen may be a function of the available computing resources, for example. Further, the sampling rate may be dynamic and change depending upon how many frames are in the buffer, or the number of local features being located.
- a current video content item frame may be compared with a previously analyzed video content item frame to determine relative differences between before analyzing the current frame. Because video content items frames are often very similar to proceeding video content item frames, the identified local features in the two frames may be identical or near identical. Thus, processing resources may be saved by determining the relative similarities or differences between two frames using a relatively low computationally intensive comparison process before undertaking the high computationally intensive process of locating local features and matching them against stored images. If a frame is statistically similar enough to a previously analyzed frame it can be assigned the same local features as the previous frame, for example.
- the identified one or more region(s)-of-interest are used to search a database of images ( 1530 ).
- a region-of-interest may be decomposed to identify target local features, which are compared against the reference local features using object recognition techniques, for example.
- Ads associated with any matching region-of-interest are retrieved and displayed along with the current video frame in video content item ( 1540 ).
- the ads are displayed in a window separate from the window displaying the video content item, such as illustrated in ad region 1420 and video player region 1410 of FIG. 14 .
- the ads may be displayed on or near the associated regions-of-interest in the current frame of the video stream in an overlay, for example.
- FIG. 16 depicts an example user interface 1600 for providing ads associated with images in a video content item.
- the user interface 1600 includes media control window 1605 that may contain the various icons that are used to control the playback of a video content item.
- the user interface 1600 also includes a video content region 1610 where frames of a currently playing video content are displayed.
- the region 1610 may also display ads associated with one or more images displayed in a current frame of the video content item.
- the ads are displayed in ad regions 1620 and 1630 , each of which are separate from the region 1610 so as to not interfere with viewing of the video content item.
- a video content item is being played in the user interface 1600 .
- the current frame of the video content item is shown in the region 1610 and shows a man standing next to a personal computer.
- the displayed frame in the video content item is analyzed for regions-of-interest.
- the regions-of-interest are decomposed to identify local features, which are used to query a database of reference local features corresponding to reference regions-of-interest associated with ads.
- Ads associated with matching regions-of-interest are displayed along with the current video content item frame.
- ad regions 1620 and 1630 the regions-of-interest of a computer and a man.
- Various ads related to the computer image are shown in ad regions 1620 and 1630 .
- Ad region 1620 shows a banner ad
- ad region 1630 includes hyperlink ads by which web pages of corresponding advertisers may be accessed.
- the box 1635 displays an ad inside the current frame of the video content item.
- no ads were displayed related to the man sub-image displayed in video region 1610 .
- FIG. 17 shows an example environment 1700 for the presentation of advertisements associated with a digital photograph.
- the environment 1700 allows a user to submit a digital photograph from a user device and in return receive advertisements related to the submitted photograph as well as well as other non-advertisement content such as search engine results, for example.
- the environment 1700 includes a user device 1701 adapted to take a digital photograph and submit it to a server 1725 via a network 1713 .
- the server 1725 is adapted to receive the digital photograph through the network 1713 , analyze the image to identify one or more stored matching representations of objects that have associated advertisements, and provide the associated advertisements, and other content, to the user device 1701 via the network 1713 .
- the user device 1701 may comprise a mobile phone capable of taking digital photographs.
- the user device 1701 is not limited to mobile phones, and may comprise any device capable of taking digital pictures including, but not limited to, a personal digital assistant, a smart phone, a laptop computer, a digital camera, a portable media player, and a portable video game console, for example.
- a user of the user device 1701 takes a picture of an object 1715 (here, a book) for which the user or operator of the user device 1701 would like to receive additional information.
- the object 1715 may including anything capable of being photographed including people, automobiles, buildings, products, advertisements, text, etc.
- a user may take a photograph of an automobile, an advertisement or a billboard featuring a movie, a restaurant or a hotel about which the user desires more information.
- the digital photograph is transmitted by the user device 1701 to the server 1725 .
- the user device 1701 and the server 1725 are wirelessly connected through a network 1713 .
- the network 1713 may comprise a variety of networks including, but not limited to, a public network (e.g., the internet), a private network (e.g., corporate LAN), and cellular telephone network (e.g., CDMA, GSM, 2G, 2.5G and 3G).
- the server 1725 receives the image of the object and compares the image of the object to stored representations of objects using a variety of object recognition techniques.
- the server 1725 may compare the received image of the book with one or more stored representations of objects using various object recognition techniques. Because different object recognition systems or engines are often suitable for different object types, it may be desirable to process the received image with a variety of object recognition engines. For example, certain characteristics and assumptions about a human face may be utilized by a face recognition engine to improve performance. However, those assumptions may not apply to the recognition of rigid textured objects, such as a building, for example. Thus, the server 1725 may compare the received image with the stored representations of objects using a variety of object recognition engines.
- These engines may include: an optical character recognition engine 1726 ; a rigid textured object recognition engine 1727 ; a face recognition engine 1728 ; and an articulate object recognition engine 1729 .
- the particular object recognition engines used are discussed further in U.S. Patent Application No. 61/129,034, titled “Image-based Search Engine for Mobile Phones With Camera.” The contents of the application are hereby incorporated by reference in its entirety.
- the server 1725 may further retrieve any advertisements associated with the matching representation of an object.
- an advertiser such as a book store owner or a book publisher, may have bid to have an advertisement associated with the book object 1715 .
- the advertisement may be combined with search engine results or other non-advertisement content produced in response to receiving the image and returned to the user device 1701 , for example.
- a person may receive advertisements or information about objects by sending an image of an object to an information retrieval system.
- FIG. 18 is a flow diagram of an example process flow 1800 for the presentation of advertisements associated with a digital photograph.
- the steps of process 6100 do not have to occur in a specific order and at least some steps can occur in parallel.
- An image is received from a user device capable of taking digital photographs ( 1810 ).
- the user device may be any device capable of taking digital pictures, such as a mobile phone, a digital camera, or a portable media device.
- a user of a mobile phone may have taken a digital image of a particular object about which more information is desired.
- Additional image content information may be optionally received ( 1820 ).
- additional classification data may be received from the user device. This additional data may allow the object recognition engines that process the received image to narrow the number of objects that are searched or provide more accurate results.
- the additional data may be user supplied. The user may be prompted after taking the image to select a general category for the image or provide a description. For example, after taking a picture of a restaurant, the user may indicate that that the picture is of a restaurant. This additional data may allow the object recognition engines to narrow the objects that are searched to those objects associated with restaurants.
- the additional data may be automatically supplied by the user device.
- the user device may provide the coordinates of the location where the image was taken. This location data may then be used by the object recognition engines to restrict their image search to images of objects that are associated with provided coordinates.
- the received image is processed using various object recognition engines ( 1830 ). As described above, matching objects may be located in the received image by comparing stored object representations with the received image.
- the object recognition engines may include, but are not limited to, an optical character recognition engine, a rigid textured object recognition engine, a face recognition engine, and an articulate object recognition engine.
- Each engine may compare the received image of an object with one or more stored representations of objects.
- the stored representations of objects may comprise images, for example.
- Each object recognition engine may, as an output, indicate which of the stored representations of objects it matched with the image, along with a confidence value.
- the stored representation of an object that is found to match the received image with the highest confidence value is selected.
- a minimum confidence value may be selected such that no representation of an object is selected as a match unless it exceeds the minimum confidence value. Where no representation of an object meets the minimum confidence value, an error may be sent to the submitting user device, or the user may be asked to provide another image, for example.
- Advertisements associated with the recognized objects are returned to the user device along with any additional content ( 1840 ).
- One or more of the stored representations of objects may have associated advertisements.
- the advertisements may have been provided by advertisers who bid on having an advertisement displayed when an image matching the particular representation of an object is received.
- the advertisements may be stored with each advertisement's associated representation of an object, or may be stored separately.
- the advertisements may be provided to the user device along with any additional non-advertisement content related to the received image.
- an online merchant may bid to have an advertisement for a particular DVD displayed when an image matching the stored representation of that DVD is received. Later, a user may see the DVD at a store and take a picture of the DVD using a mobile phone in order to receive more information about the DVD.
- the associated advertisement is retrieved.
- the received image may have also been used as a query to a search engine to produce non-advertisement search engine results related to the DVD.
- the associated advertisement may be combined with the non-advertisement search engine results and sent to the user device.
- FIGS. 17 and 18 have been described with respect to receiving an analyzing a digital photograph, the techniques are also applicable to other devices and media, such as digitized hand-drawn sketches, graphic images, and one or more frames in a video.
- FIG. 19 shows an example of a generic computer device 1900 and a generic mobile computer device 1950 , which may be used with the techniques described above.
- Computing device 1900 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, television set-top boxes, servers, blade servers, mainframes, and other appropriate computers.
- Computing device 1950 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices.
- the components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit the implementations described and/or the claims.
- Computing device 1900 includes a processor 1902 , memory 1904 , a storage device 1906 , a high-speed interface 1908 connecting to memory 1904 and high-speed expansion ports 1910 , and a low speed interface 1912 connecting to low speed bus 1914 and storage device 1906 .
- Each of the components 1902 , 1904 , 1906 , 1908 , 1910 , and 1912 are interconnected using various buses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 1902 can process instructions for execution within the computing device 1900 , including instructions stored in the memory 1904 or on the storage device 1906 to display graphical information for a GUI on an external input/output device, such as display 1916 coupled to high speed interface 1908 .
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 1900 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 1904 stores information within the computing device 1900 .
- the memory 1904 is a volatile memory unit or units.
- the memory 1904 is a non-volatile memory unit or units.
- the memory 1904 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 1906 is capable of providing mass storage for the computing device 1900 .
- the storage device 1906 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 1904 , the storage device 1906 , memory on processor 1902 , or a propagated signal.
- the high speed controller 1908 manages bandwidth-intensive operations for the computing device 1900 , while the low speed controller 1912 manages lower bandwidth-intensive operations.
- the high-speed controller 1908 is coupled to memory 1904 , display 1916 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 1910 , which may accept various expansion cards (not shown).
- low-speed controller 1912 is coupled to storage device 1906 and low-speed expansion port 1914 .
- the low-speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a pointing device 1930 , a printer 1932 , a keyboard 1934 , a scanner 1936 , or a networking device 1937 such as a switch or router, e.g., through a network adapter.
- input/output devices such as a pointing device 1930 , a printer 1932 , a keyboard 1934 , a scanner 1936 , or a networking device 1937 such as a switch or router, e.g., through a network adapter.
- the computing device 1900 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 1920 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system 1924 . In addition, it may be implemented in a personal computer such as a laptop computer 1922 . Alternatively, components from computing device 1900 may be combined with other components in a mobile device (not shown), such as device 1950 . Each of such devices may contain one or more of computing device 1900 , 1950 , and an entire system may be made up of multiple computing devices 1900 , 1950 communicating with each other.
- Computing device 1950 includes a processor 1952 , memory 1964 , an input/output device such as a display 1954 , a communication interface 1966 , and a transceiver 1968 , among other components.
- the device 1950 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 1950 , 1952 , 1964 , 1954 , 1966 , and 1968 are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 1952 can execute instructions within the computing device 1950 , including instructions stored in the memory 1964 .
- the processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors.
- the processor may provide, for example, for coordination of the other components of the device 1950 , such as control of user interfaces, applications run by device 1950 , and wireless communication by device 1950 .
- Processor 1952 may communicate with a user through control interface 1958 and display interface 1956 coupled to a display 1954 .
- the display 1954 may be, for example, a TFT (Thin-Film-Transistor Liquid Crystal Display) display or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology.
- the display interface 1956 may comprise appropriate circuitry for driving the display 1954 to present graphical and other information to a user.
- the control interface 1958 may receive commands from a user and convert them for submission to the processor 1952 .
- an external interface 1962 may be provide in communication with processor 1952 , so as to enable near area communication of device 1950 with other devices.
- External interface 1962 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
- the memory 1964 stores information within the computing device 1950 .
- the memory 1964 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.
- Expansion memory 1974 may also be provided and connected to device 1950 through expansion interface 1972 , which may include, for example, a SIMM (Single In Line Memory Module) card interface.
- SIMM Single In Line Memory Module
- expansion memory 1974 may provide extra storage space for device 1950 , or may also store applications or other information for device 1950 .
- expansion memory 1974 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 1974 may be provide as a security module for device 1950 , and may be programmed with instructions that permit secure use of device 1950 .
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include, for example, flash memory and/or NVRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 1964 , expansion memory 1974 , memory on processor 1952 , or a propagated signal that may be received, for example, over transceiver 1968 or external interface 1962 .
- Device 1950 may communicate wirelessly through communication interface 1966 , which may include digital signal processing circuitry where necessary. Communication interface 1966 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 1968 . In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module 1970 may provide additional navigation- and location-related wireless data to device 1950 , which may be used as appropriate by applications running on device 1950 .
- GPS Global Positioning System
- Device 1950 may also communicate audibly using audio codec 1960 , which may receive spoken information from a user and convert it to usable digital information. Audio codec 1960 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 1950 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 1950 .
- Audio codec 1960 may receive spoken information from a user and convert it to usable digital information. Audio codec 1960 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 1950 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 1950 .
- the computing device 1950 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 1980 . It may also be implemented as part of a smartphone 1982 , personal digital assistant, or other similar mobile device.
- implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- the techniques and concepts generally have been described using a sub-image of an image, the techniques and concepts are applicable to an image. Also, the decomposition of an image into sub-images may be based on various image features, including, for example, color, shape, texture, in lieu of or in addition to decomposing a region-of-interest into local features.
Abstract
Techniques are described for placing sponsored-content associated with an image. The techniques may include matching a first image for which a sponsored-content item is to be selected with a reference image. A sponsored-content item to be presented may be selected based on an association between the reference image with the sponsored-content item to be presented.
Description
- The subject matter of this application is generally related to advertising.
- Interactive media (e.g., the Internet) has great potential for improving the targeting of advertisements (“ads”) to receptive audiences. For example, some websites provide information search functionality that is based on keywords entered by the user seeking information. This user query can be an indicator of the type of information of interest to the user. By comparing the user query to a list of keywords specified by an advertiser, it is possible to provide targeted ads to the user.
- Another form of online advertising is ad syndication, which allows advertisers to extend their marketing reach by distributing ads to additional partners. For example, third party online publishers can place an advertiser's text or image ads on web properties with desirable content to drive online customers to the advertiser's website. An example of such a system is AdSense™ offered by Google, Inc.
- In one general aspect, selecting an advertisement includes storage for images and storage for advertisements. A first image for which an advertisement is to be selected is matched with a second image stored in the storage for images. An advertisement to be presented is selected from the storage for advertisements and based on an association between the advertisement and the second image stored in storage for images.
- Implementations may include one or more of the following features. For example, presentation of the advertisement may be enabled in response to receiving the first image. Matching may include identifying a first image that is identical to the second image or identifying a first image that is substantially similar to the second image.
- The storage for images may include sub-images. The first image may be analyzed to identify a sub-image. Matching may include matching the identified sub-image of the first image with a second sub-image stored in the storage for images. Matching the identified sub-image of the first image may include using object recognition techniques to generate a likelihood that the stored sub-image includes the identified sub-image of the first image. Selecting an advertisement may include selecting an advertisement to be presented based on a comparison between the likelihood and a threshold.
- A sub-image may correspond to a region-of-interest of an image and may include one or more local features. The storage for images may include storage for regions-of-interest, local features and associations between local features and regions-of-interest. The first image may be analyzed to identify a region-of-interest. The region-of-interest may be analyzed to identify one or more local features included in the region-of-interest. Matching a first image may include matching the identified region-of-interest with a region-of-interest stored in the storage for regions-of-interest, where the matching is based on a comparison of local features included in the identified region of interest with one or more local features associated with at least one region-of-interest stored in the storage for regions-of-interest.
- Matching the identified sub-image of the first image may include using object recognition techniques to generate a likelihood that the stored region-of-interest matches the identified region-of-interest. Selecting an advertisement may include selecting an advertisement to be presented based on a comparison between the likelihood and a threshold.
- Matching the identified sub-image of the first image may include using object recognition techniques to generate a likelihood that the stored local features match the local features included in the identified region-of-interest. Selecting an advertisement may include selecting an advertisement to be presented based on a comparison between the likelihood and a threshold.
- At least some of the stored advertisements may be associated with a bid and an association with a stored image. Selecting an advertisement may include selecting an advertisement to be presented based on both the bid associated with the advertisement and an association between the second image stored in storage for images with the advertisement.
- At least some of the stored advertisements may be associated with a bid and an image stored in the storage for images. Selecting an advertisement may include selecting an advertisement to be presented based on both the bid associated with the advertisement and an association between the second image stored in storage for images with the advertisement.
- At least some of the stored advertisements may be associated with a maximum bid and an image stored in the storage for images. Selecting an advertisement may include selecting an advertisement to be presented based on both the maximum bid associated with the advertisement and an association between the second image stored in storage for images with the advertisement.
- The first image may be associated with search results to be presented over a network of computers. Presentation of the advertisement may be enabled with the search results over the network of computers.
- The first image may be associated with document content to be presented over a network of computers. Presentation of the advertisement may be enabled with presentation of the document content over the network of computers.
- In another general aspect, selecting an advertisement includes storage for reference images and storage for sponsored-content items. A first image for which a sponsored-content item is to be selected is matched with a reference image stored in the storage for images. A sponsored-content item to be presented is selected from the storage for sponsored-content and based on an association between the sponsored-content item to be presented and the reference image.
- Implementations may include one or more of the features noted above and one or more of the following features. For example, the storage for reference images may include reference sub-images. The first image may be analyzed to identify a sub-image. Matching a first image may include matching the identified sub-image of the first image with a reference sub-image stored in the storage for reference images.
- In yet another general aspect, a first image for which a sponsored-content item is to be selected is matched with a reference image. A sponsored-content item to be presented is selected based on an association between the reference image with the sponsored-content item to be presented.
- Implementations may include one or more of the features noted above and one or more of the following features. For example, the first image may be analyzed to identify a sub-image. Matching a first image may include matching the identified sub-image of the first image with a reference sub-image.
- Object recognition techniques may be used to generate a likelihood that the stored sub-image includes the identified sub-image of the first image. Selecting a sponsored-content item may include selecting a sponsored-content item to be presented based on a comparison between the likelihood and a threshold.
- At least some of the stored sponsored-content items may be associated with a bid and an association with a stored image. Selecting a sponsored-content item may include selecting a sponsored-content item to be presented based on both the bid associated with the sponsored-content item and an association between the second image stored in storage for images with the a sponsored-content item.
- Implementations of the techniques discussed above may include a method or process, a system or apparatus, or execution of computer software embodied in a computer-readable medium. The details of one or more of the implementations are set forth in the accompanying drawings and description below. Other features will be apparent from the description and drawings, and from the claims.
-
FIGS. 1-3 are block diagrams of example user interfaces in imaged-based ad targeting systems. -
FIG. 4 is a block diagram of an example image-based ad targeting system. -
FIGS. 5 and 7 are flow diagrams of example process flows for image-based ad targeting. -
FIG. 6 illustrates an example of an environment for implementing an image-based ad targeting system. -
FIG. 8 is a flow diagram of an example process flow for image-based ad targeting. -
FIGS. 9A and 9B are block diagrams of example user interfaces from an image-based ad targeting system. -
FIG. 10 is a flow diagram of an example process flow for presenting images for bidding for an image with which to present ads. -
FIG. 11 is a block diagram of an example user interface for bidding in an image-based ad targeting system. -
FIG. 12 illustrates an example of an environment for providing advertisements for video content items. -
FIG. 13 is a flow diagram of an example process flow for preprocessing video content items for images and retrieving associated ads. -
FIGS. 14 and 16 are block diagrams of example user interfaces illustrating advertising content displayed on a screen with video content. -
FIG. 15 is a flow diagram of an example process flow for retrieving ads associated with images in a video content item. -
FIG. 17 shows an example environment for the presentation of advertisements associated with a digital photograph. -
FIG. 18 is a flow diagram of an example process flow for the presentation of advertisements associated with a digital photograph. -
FIG. 19 is a block diagram illustrating an example generic computer and an example generic mobile computer device. -
FIGS. 1-3 depicts example user interfaces in image-based ad targeting systems. In general,FIG. 1 shows anexample user interface 100 in a search service that receives a query from a user, retrieves and presents relevant search results from an index of content, and presents advertisements based on the search results. More particularly, the presented advertisements are based on an image included in the search results. - As depicted in
FIG. 1 , theuser interface 100 includes atitle 110 showing asearch query 110A entered by a user for which searchresults 120 are presented. The search results 120 include twosearch results search query 110A. Eachsearch result hypertext link search result text descriptions image 135A returned with thesearch result 120A. Theimage 135A may be, for example, a graphic image, a digital photograph or a frame from a video. - The
user interface 100 also includesadvertisements 150 identified based on the search results 120. An advertisement or an “ad” refers to any form of communication in which one or more products, services, ideas, messages, people, organizations or other items are identified and promoted (or otherwise communicated). Ads are not limited to commercial promotions or other communications. An ad may be a public service announcement or any other type of notice, such as a public notice published in electronic press or a broadcast. An ad may be referred to or include sponsored content. - The
ads 150 includeads ad hypertext link ad ad text Ad 150A also includes anad image 165A. Theimage 165A may be, for example, a graphic image, a digital photograph or a frame from a video. Thead image 165A may be substantially similar to or the same as thesearch result image 135A returned with the search results 120, though thead image 165A need not necessarily be similar to or the same as theimage 135A. Theads search result image 135A, as described more fully later. -
FIG. 2 depicts anexample user interface 200 presented by a content provider that presents content to users. As illustrated inFIG. 1 , theuser interface 200 includes atitle 210 and alist 220 ofcontent items content items - Each
content item hypertext link content item descriptions Content item 220A also includes animage 235A. Theimage 235A may be, for example, a graphic image, a digital photograph or a frame from a video. - The
user interface 200 also includes anad 250 identified based on theimage 235A included in thecontent item 220A. Thead 250 includes ahypertext link 255 to the advertiser's web page,ad text 260 and anad image 265, which may be, for example, a graphic image, a digital photograph or a frame from a video. Thead 250 is identified and presented based on thecontent image 235A, as described more fully later. -
FIG. 3 depicts anexample user interface 300 presented by a provider of an online photograph application. As illustrated inFIG. 3 , theuser interface 300 includes atitle 310 and alist 320 ofphotograph items - Each
photograph item hypertext link photograph item description - The
user interface 300 also includes anad 350 identified based on thephotograph item 320A and/orphotograph item 320B, as described more fully later. Thead 350 includes ahypertext link 355 to the advertiser's web page, andad text 360. -
FIG. 4 illustrates an example image-basedad targeting system 400. In the example ofFIG. 4 , the image-basedad targeting system 400 is a computer system including one or more processors (not shown),software 420 for an executable image matching process, and three persistent data stores: asub-image data store 430 for storing sub-images, anassociations data store 440 for storing associations between ads and sub-images, and anads data store 450 for storing ads. Thedata stores ad targeting system 400 is configured to receive animage 455 for which anad 460 is to identified and execute thematching process 420 that accesses the data stores 430-450 to identifyad 460 based on the receivedimage 455. - Also referring to
FIG. 5 , aprocess 500 for matching an ad to an image may be an implementation ofimage matching process 420 ofFIG. 4 . Thead targeting system 400 receives and parses the image 455 (510). For example, thead targeting system 400 may use computer vision techniques to identify a portion of theimage 455 to be used for ad targeting. The identified portion of theimage 455 may be referred to, for example, as a sub-image, which may be a region-of-interest, a patch, a local feature, or another portion of an image. - The
ad targeting system 400 searches thesub-image data store 430 for a sub-image that matches the sub-image parsed from the received image (“parsed sub-image”) (520). Thead targeting system 400 identifies, in theassociation data store 440, an association between the sub-image found in thesub-image data store 430 and an advertisement stored in the ads data store 450 (530). Based on the association between the sub-image in thesub-image data store 430 and the advertisement in theads data store 450, thead targeting system 400 retrieves the identified ad from theads data store 450 and enables presentation of the identified ad (550). -
FIG. 6 illustrates an example of anenvironment 600 for implementing an image-based ad targeting system. In some implementations, one ormore advertisers 602 can directly, or indirectly, enter, maintain, and track ad information in anadvertising management system 604. Theadvertising management system 604 may be an implementation of thead targeting system 400 ofFIG. 4 . Theadvertising management system 604 is configured to identify an ad based on an image. Theadvertising management system 604 is configured to store sub-images used to match a portion of a received image, ads, and associations between ads and sub-images. - The ads may be in the form of graphical ads, such as banner ads, text only ads, image ads, audio ads, video ads, ads combining one of more of any of such components, etc. The ads may also include embedded information, such as a links, meta-information, and/or machine executable instructions. One or
more publishers 606 may submit requests for ads to thesystem 604. Thesystem 604 responds by sending ads to the requestingpublisher 606 for placement on one or more of the publisher's media properties (e.g., websites video content, or other content) based on one or more images. - Other entities, such as users 608 and the
advertisers 602, can provide usage information to thesystem 604, such as, for example, whether or not a conversion or click-through related to an ad has occurred. In contrast to an impression which occurs when a user views one of the ads (such as when a page of content including the ad is displayed and/or rendered to the audience member), a “click-through” may be said to occur when a user selects a presented ad by clicking on the ad, embedded hypertext links, executable code, and any type of user selection related to the presented ad, where the click or another type of selection typically directs the user to the advertiser's web site or the advertiser's online or real world presence. - A conversion may be said to occur when a user consummates a transaction related to a previously served ad. What constitutes a conversion may vary from case to case and may be determined in a variety of ways. For example, it may be the case that a conversion occurs when a user clicks on an ad, is referred to the advertiser's web page, and consummates a purchase there before leaving that web page. Alternatively, a conversion may be defined as a user being shown an ad, and making a purchase on the advertiser's web page within a predetermined time (e.g., a seven days). Many other definitions of what constitutes a conversion are possible.
- This usage information can include measured or observed user behavior related to ads that have been served. The
system 604 performs financial transactions, such as crediting thepublishers 606 and charging theadvertisers 602 based on the usage information. Thesystem 604 also may use the usage information, in lieu of or in addition to, impression information to select ads for presentation. - A
computer network 610, such as a local area network (LAN), wide area network (WAN), the Internet, or a combination thereof, connects theadvertisers 602, thesystem 604, thepublishers 606, and the users 608. - One example of a
publisher 606 is a general content server that receives requests for content (e.g., articles, discussion threads, music, video, graphics, search results, web page listings, information feeds, etc.), and retrieves the requested content in response to the request. The content server may submit a request for ads to anadvertising management system 604. The ad request may include a number of ads desired. The ad request may also include content request information that identifies an image for which an ad is to be returned. This content request information can include the image itself, a storage location or retrieval mechanism for the image, or another type of information that identifies the image. The content request information also can include identification of content itself (e.g., image, page, video, or other content document), a category corresponding to the content or the content request (e.g., arts, business, computers, arts-movies, arts-music, etc.), part or all of the content request, content age, content type (e.g., text, graphics, video, audio, mixed media, etc.), geo-location information, etc. - In some implementations, the content server can combine the requested content with one or more of the ads provided by the
system 604. This combined content and ads can be sent to the user 608 that requested the content for presentation in a viewer (e.g., a browser or other content display system). The content server can transmit information about the ads back to the advertising management system, including information describing how, when, and/or where the ads are to be rendered (e.g., in HTML or JavaScript™). - Another
example publisher 606 is a search service. A search service can receive queries for search results. In some implementations, the queries may include images. In response to a query, the search service can retrieve relevant search results from an index of documents (e.g., from an index of web pages). An exemplary search service is described in the article S. Brin and L. Page, “The Anatomy of a Large-Scale Hypertextual Search Engine,” Seventh International World Wide Web Conference, Brisbane, Australia and in U.S. Pat. No. 6,285,999, both of which are incorporated herein by reference each in their entirety. Search results can include, for example, lists of web page titles, snippets of text extracted from those web pages, hypertext links to those web pages, images, videos, and may be grouped into a predetermined number of (e.g., ten) search results. - The search service can submit a request for ads to the
system 604. The request may include, or identify an image to be used for ad targeting. The request may also include a number of ads desired. This number may depend on the search results, the amount of screen or page space occupied by the search results, the size and shape of the ads, etc. In some implementations, the number of desired ads will be from one to ten, or from three to five. The request for ads may also include the query (as entered or parsed), information based on the query (such as geo-location information, whether the query came from an affiliate and an identifier of such an affiliate, or whether the query was an image), and/or information associated with, or based on, the search results. Such information may include, for example, identifiers related to the search results (e.g., document identifiers or “docIDs”), images or videos included in the search results, scores related to the search results (e.g., information retrieval (“IR”) scores), snippets of text extracted from identified documents (e.g., web pages), full text of identified documents, feature vectors of identified documents, etc. In some implementations, IR scores can be computed from, for example, dot products of feature vectors corresponding to a query and a document, page rank scores, and/or combinations of IR scores and page rank scores, etc. - The search service can combine the search results with one or more of the ads provided by the
system 604. This combined information can then forwarded to the user 608 that requested the content. The search results can be maintained as distinct from the ads, so as not to confuse the user between paid advertisements and presumably neutral search results. - Finally, the search service can transmit information about the ad and when, where, and/or how the ad was to be rendered back to the
system 604. - As can be appreciated from the foregoing, the
advertising management system 604 can servepublishers 606, such as content servers and search services. Thesystem 604 permits serving of ads targeted to documents served by content servers. For example, a network or inter-network may include an advertising management system serving targeted ads in response to requests from a search service with ad spots for sale. Suppose that the inter-network is the World Wide Web. The search service crawls much or all of the content. Some of this content will include ad spots (also referred to as “inventory”) available. More specifically, one or more content servers may include one or more documents. Documents may include images, videos, web pages, email, content, embedded information (e.g., embedded media), meta-information and machine executable instructions, and ad spots available. The ads inserted into ad spots in a document can vary each time the document is served or, alternatively, can have a static association with a given document. -
FIG. 7 is a flow diagram of anexample process 700 for image-based ad targeting for a content publisher. Theprocess 700 may be executed, for example, by an ad targeting system, such as thead targeting system 400 ofFIG. 4 or thead management system 604 ofFIG. 6 . In general, a publisher of a webpage may enroll in an ad syndication program to increase revenue by receiving and displaying ads targeted to content on the webpage. The publisher sends to the ad targeting system a request for ads to be targeted based on an image. For example, an image to be included in the content web page to be displayed may be used to target an ad that is displayed along with the content including the image. The ad targeting system uses the received image to select targeted ads for the webpage. These ads are then returned to the publisher who may combine them with the webpage content, or alternatively, the webpage content may be combined with the ads by ad targeting system and sent directly to a user for whom the content is to be displayed. The steps ofprocess 700 do not have to occur in a specific order and at least some steps can occur in parallel. - Referring to
FIGS. 7 and 8 , and in contrast with theprocess 500 describe previously with respect toFIG. 5 , the ad targeting processes 700 and 800 each match an image for which ads are to be identified (which may be referred to as a received image) to a reference image based on local features. The received image includes one or more regions-of-interest and each of the regions-of-interest includes one or more local features. For example, a received image may include a logo and an image background where the logo is identified as a region-of-interest, which, in turn, includes local features, such as various portions of the logo. The reference image may correspond to the logo (i.e., the reference region-of-interest in this example), which may be decomposed into various local features. In a more particular example, an image may be received that includes the Eiffel Tower. The Eiffel Tower may be identified as a region-of-interest, and the tip of the Eiffel Tower may be identified as one or many local features of the region-of-interest (i.e., the Eiffel Tower in this example). - In general, an ad targeting process may select an ad by matching a target image to a reference image based on identification of the region-of-interest in the target image, decomposing the region-of-interest into local features, matching local features of the target image with reference local features, identifying a reference image corresponding to the reference local features that match the local features of the target image, and identifying an ad associated with the identified reference image. More particularly, the
ad targeting process 700 begins when an ad request is received by the ad targeting system from a content publisher,such publisher system 606 ofFIG. 6 (710). As described with respect toFIG. 6 , the ad request includes context information that is used to select targeted ads. While the content information can include a variety of content types, for the purposes of illustration only, this example describes content information including one or more image files. - The ad targeting system analyzes the received image (here, the image file included in the ad request) to identify one or more regions-of-interest (720). Regions-of-interest are portions or sections of the image file that are visually distinguishable and stable. Regions-of-interest are visually distinguishable and stable are likely to be, or relate to, the subject or subjects of the image. For example, an image of a chair in a room may be analyzed to identify the chair as a region-of-interest where the background (such as a floor, ceiling and walls of the room in which the chair is depicted) is not included in the region-of-interest. In another example, a chair and a person standing in the room each may be identified as a region-of-interest.
- The ad targeting system identifies local features associated with identified region-of-interest(s) (730). In some implementations, local features may be identified for each identified region-of-interest, although not all regions-of-interest need necessarily be decomposed into one or more local features.
- The ad targeting system identifies matching regions-of-interest (740). This may be accomplished, for example, by comparing the local features identified for the received or target image with stored local features associated with regions-of-interest . The local features, associations with regions-of-interest, and/or regions-of-interest may be stored in an image repository, such as
sub-image data store 430 ofFIG. 4 , for example. The matching may be performed by computer vision techniques or another type of pattern matching process. For example, image matching may be performed based on image matching techniques described by Patent Cooperative Treaty Patent Application WO 2005/114476 and titled MOBILE IMAGE-BASED INFORMATION RETRIEVAL SYSTEM, which is incorporated in its entirety herein. The image repository may contain regions-of-interest that advertisers have selected, or bid on, to associate with one or more ads, as described more fully later. - The ad targeting system identifies ads corresponding to regions-of-interest in the image repository that indirectly are matched, based on matching local features, to the target regions-of-interest from the received image (750). For example, the ad targeting system may search for an association between an identified sub-image and an ad. In one example, a sub-image may include a pointer, a link, or otherwise identify one or more advertisements to be presented based on the sub-image. In another example, an association data stored, such as
associations 440 ofFIG. 4 , may be searched to identify ad(s) to be presented with the sub-image. - In some implementations, usage information, such as whether or not a conversion or click-through has occurred may be collected, stored and used based on a region-of-interest or sub-image. For example, information for the number of times a region-of-interest or sub-image has been clicked-through by users may be used to determine relevancy of an ad, such as, by weighing a region-of-interest or sub-image based on the number of times the region-of-interest or sub-image.
- The ad targeting system enables presentation of the ad(s) associated with the sub-images that match the received image for which ads are to be identified (760). This may be accomplished, for example, by transmitting or otherwise delivering the ad to the requesting publisher system. Alternatively or additionally, the ad targeting system may combine ads with content provided by the publisher system and presented to a user of the publisher system.
-
FIG. 8 is a flow diagram of anotherexample process 800 for image-based ad targeting. Theprocess 800 may be executed, for example, by an ad targeting system, such as thead targeting system 400 ofFIG. 4 or thead management system 604 ofFIG. 6 . Theprocess 800 is performed to provide ads based on search results returned by a search service and, similarly to theprocess 700 described previously with respect toFIG. 7 , decompose an image into one or more regions-of-interest and further decompose one or more regions-of-interest into one or more local features, which, in turn, are used to match reference local features. As described above with respect toFIG. 6 , search engine providers may desire to present search results along with ads targeted to the search results. Because images may be presented along with, or as part of, search results, ads may be targeted to the images, rather than, or in addition to, ads targeted to the textual search results. The steps ofprocess 800 do not have to occur in a specific order and at least some steps can occur in parallel. - Search results including an image are received (810). For example, a request for ads that includes search results or an image for which ads are to be identified may be received from a provider of a search service. In another example,
process 800 may be performed by a search service. - The ad targeting system analyzes the image to identify one or more regions-of-interest (820), identify one or more local features included in one or more regions-of-interest by decomposing a region-of-interest into local features (830), identify matching one or more regions-of-interest based on local features shared by, or similar to, reference local features (840), identify one or more ads associated with one or more of the matched regions-of-interest (850), and enable presentation of the one or more ads associated with the one or more region-of-interest found to match the target image for which ads are to be identified (860). This may be accomplished, for example, by techniques described previously with respect to
FIG. 7 (720-750). -
FIGS. 9A and 9B areexample user interfaces FIG. 9A , theuser interface 900A is from a photography website. Theuser interface 900A includes a window 404 displaying a photograph of a computer. A publisher of the photography website may be participating in an ad syndication program. The publisher of the photography website requests ads targeted to the contents of the window 904 and presents the targeted ads in thewindow 908. As described with respect toFIG. 6 , when the publisher system generates a webpage including the computer in window 904 for display, a request including the computer image is sent to an ad targeting system. In the example shown inFIG. 9A , the image of the computer displayed in window 904 is sent along with the request for ads to an ad targeting system, such as thead targeting system 400 ofFIG. 4 or theadvertising management system 604 ofFIG. 6 . - As described with respect to
FIGS. 4 , the ad targeting system analyzes the image to identify the sub-image of the computer, identifies a matching sub-image in stored images what that associated with ads, and identifies the ads that are associated with the stored image of a computer found to match the computer image. The ad targeting system, for example, may analyze the image to identify one or more regions-of-interest, decompose one or more regions-of-interest into one or more local features, match the decomposed local features to reference local features to identify a matching reference region-of-interest, which, in turn, is associated with one or more ads to be presented. In some implementations, ads are selected from the identified ads based on advertiser bids. For example, ads that have the highest associated bid are retrieved and returned to the publisher to be provided with the displayed web page. - In the example shown in
FIG. 9A , five ads related to the computer image shown in window 904 have been returned and used to populate thewindow 908. However, any number of targeted ads may be supported. The ads shown inwindow 908 are hyperlinks to web pages of corresponding advertisers. - Turning to
FIG. 9B , a user of the photography website has continued to a different photograph illustrated by the image of the dog and a tree in window 904. As a result, the ads inwindow 908 have been updated to reflect the change. When the new page was requested by the user a new ad request was made by the publisher to theadvertising management system 604. The request included the image of the dog and tree shown in window 904. The image was analyzed to locate regions-of-interest. In this example, there are two regions-of-interest, a dog and a tree. The ad targeting system decomposes both regions-of-interest into local features, which, in turn, are compared with the local features stored in the image database. Ads associated with the regions-of-interest corresponding to local features found to match the target local features were retrieved and used to populate thewindow 908 according to the amount bid on each image. Because the dog and the tree were identified as regions-of-interest, the ads displayed in thewindow 908 are both pet and tree related, reflecting the type of ad that may have been associated with an image of a dog or an image of a tree. -
FIG. 10 depicts anexample process 1000 for presenting images for bidding for an image with which to present ads. Theexample process 1000 is described with respect to a region-of-interest, though different granularities of images may be used. Also, theprocess 1000 is described with respect to bidding on a single region-of-interest and a single ad, theprocess 1000 may be used to receive bids for multiple regions-of-interest and/or advertisements. The steps ofprocess 1000 do not have to occur in a specific order and at least some steps can occur in parallel. As described with respect toFIG. 6 , advertisers may bid on a particular image in an image database to associate with a desired ad. However, it may be difficult for an advertiser to determine what an appropriate bid for a particular image is or may otherwise desire to know what bids have been placed on similar images. In general, to help establish an appropriate bid, the particular image that an advertiser is interested in may be compared against the database of images to locate similar reference images. Bids associated with these reference images may then be presented to the advertiser as suggested bids. - More particularly, an image-based ad targeting system may present ads based on images and associated bids placed by advertisers. The ad targeting
system executing process 1000 receives an image (or indication thereof) on which an advertiser may place a bid (1010). In some implementations, the advertiser may select an image from an a repository of images available to be associated with an ad. For example, an advertiser may wish to have an advertisement for a shoe store appear when a particular shoe image is displayed. The advertiser may browse a repository to locate available images of shoes. When the advertiser has found a suitable shoe image or images the advertiser may select them for bidding. - Additionally or alternatively, an advertiser submit, upload or otherwise provide an image or images to be associated with an ad and a bid. For example, the advertiser may wish to have a particular ad display when an image of the advertiser's logo is displayed. Accordingly, the advertiser may submit one or more images of the logo to be associated with one or more ads. To increase the likelihood of a match, an advertiser may provide more than one images to be matched, and perhaps many more than one. In some instances, an advertiser may provide tens or hundreds of image variations of a logo or product to increase the likelihood of an image of the logo or product being matched.
- Further, in some implementations, the advertiser may annotate the image to highlight a desired region-of-interest. Because an image may contain several regions-of-interest that may not be germane to the advertiser's business, the advertiser may wish to specify the particular feature that the advertiser wishes to associate with a desired ad. Continuing the example given above, the advertiser may have one or more images of the desired logo. Many of the images may feature the logo on cars, or t-shirts, or may also include objects that the advertiser is not interested in associating the ad with. Accordingly, the advertiser may annotate the image to point out, highlight or otherwise identify the desired region-of-interest of the image. In some implementations, advertisers may circle, highlight or otherwise identify the desired regions-of-interest on the image using a selection tool included in a user interface, for example.
- The ad targeting system searches for one or more similar regions-of-interest associated with bids (1020). For example, the ad targeting system may decompose a region-of-interest and search into one or more local features and search an image repository for reference local features similar to the target local features decomposed from the target region-of-interest . The image repository may be searched for reference local features using image and object recognition techniques, for example. Because the reference local features may not be identical to the decomposed local features, a particular statistical threshold used to locate the reference local features may be lower than the threshold used to match database local features when locating associated advertisements.
- In some implementations, the received image (rather than a region-of-interest) may be used to identify local features. Additionally or alternatively, regions-of-interest or another type of sub-image of the received image may be used to identify similar regions-of-interest or sub-images in the repository. In some implementations, regions-of-interest may be categorized or classified to indicate the contents of the image or to generally describe the subject of the image. These categories may be used to locate reference images instead of, or in addition to, searching the image database using image and object recognition techniques as described above.
- The ad targeting system presents suggested bid for received image based on bids associated with similar regions-of-interest (1030). For example, the ad targeting system may present the advertiser with the identified reference regions-of-interest along with associated bids. The suggested bid may be computed by averaging the maximum bids of the reference regions-of-interest identified, or using a weighted average of the maximum bids of the reference regions-of-interest where more popular regions-of-interest are given a higher weight, for example. Any number of statistical methods may be used to calculate the suggested bid. The bids may be presented using a
user interface 1100 as illustrated byFIG. 11 , for example. - The ad targeting system receives from the advertiser a bid to be associated with the received region-of-interest (1040) and identify an advertisement to be presented based on the regions-of-interest (1050). The received region-of-interest, bid and advertisement are stored for later use in identifying an advertisement based on the image (1060). For example, the ad may be stored in the
sub-image data store 430, the association may be stored in theassociations data store 440 and the ad may be stored in theads data store 450 ofFIG. 4 . - In addition, the advertiser may bid on one or more of the presented reference sub-images. The advertiser may provide an additional advertisement to associate with the reference image, or may use the same advertisement used for the desired image.
-
FIG. 11 illustrates anexample user interface 1100 for bidding in an image-based ad targeting system. Using theuser interface 1100, an advertiser may bid to have an ad or ads associated with a selected image. The associated ad may be presented when the selected image appears in the contents of a webpage or search engine results and the bid is the highest bid or among the highest bids for the image, for example. - An image of a computer to bid on is displayed in
image window 1110. In some implementations, the advertiser presents or uploads the image. In other implementations, the advertiser may have selected the image from a repository of images. - The
user interface 1100 also displays inreference window 1120 reference images that are identified based on image shown inimage window 1110. Each of the reference images inimage window 1110 includes an associate maximum bid that have been entered by another advertiser for the reference image, though the reference images need not necessarily be presented with associated bids. As shown inwindow 1120, three images of computers have been displayed as reference images. The displayed reference images have received maximum bids of five, seven, and nine dollars. The reference images may be determined using object or image recognition techniques to identify reference images with similar features, referencing categories or classifications associated with the images, or a combination of both. - Using the displayed maximum bids as guidance, the advertiser may determine an appropriate bid for the selected image. The advertiser may enter the bid in the text box displayed in
window 1110, and submit the entered bid by activating the associated button labeled “Bid”, for example. - Further, the
user interface 1100 enables an advertiser to make additional bids on one or more of the displayed reference images. After viewing one or more of the reference images displayed inwindow 1120, the advertiser may place bids on the displayed reference images instead of, or in addition to, the selected image. Accordingly, the advertiser may enter the bids in the text boxes (i.e., labeled “Your bid”) underneath each of the reference images inwindow 1120. - Referring to
FIGS. 12-15 , techniques described previously with respect to still images may be applied to video to enable presentation of ads associated with an image presented in video content. Video content may include multiple frames, with each frame including an image which are displayed in rapid succession to create the illusion of motion to a viewer. -
FIG. 12 shows an example of anenvironment 1200 for providing advertisements for video content items. A “video content item” is an item of content that includes content that may be perceived visually when played, rendered, or decoded. A video content item includes video data, and optionally audio data and metadata. Video data includes content in the video content item that may be perceived visually when the video content item is played, rendered, or decoded. Audio data includes content in the video content item that may be perceived aurally when the video content item is played, decoded, or rendered. A video content item may include video data and any accompanying audio data regardless of whether or not the video content item is ultimately stored on a tangible medium. A video content item may include, for example, a live or recorded television program, a live or recorded theatrical or dramatic work, a music video, a televised event (e.g., a sports event, a political event, a news event, etc.), video voicemail, etc. Each of different forms or formats of the same video data and accompanying audio data (e.g., original, compressed, packetized, streamed, etc.) may be considered to be a video content item (e.g., the same video content item, or different video content items). - A video content item may also include many types of associated data. Examples of types of associated data include video data, audio data, closed-caption or subtitle data, a transcript, content descriptions (e.g., title, actor list, genre information, first performance or release date, etc.), related still images, user-supplied tags and ratings, etc. Some of this data, such as the description, may refer to the entire video content item, while other data (e.g., the closed-caption data) may be temporally-based or time-coded.
- The
environment 1200 includes, or is communicably coupled with, an advertisement provider system 1205 (having access to advertisement repository 1210), acontent provider system 1215, and one ormore user devices 1220, at least some of which communicate acrossnetwork 1225. In general, theadvertisement provider system 1205 may provide relevant advertising content (“ad content”) or other relevant content to a video content item. Theadvertisement provider system 1205 may be an implementation of theadvertising management system 604 ofFIG. 6 . By way of example, reference is made to delivering ad content, though other forms of content (e.g., other content item types) may be delivered. The presented content may be provided by thecontent provider system 1215 through thenetwork 1225. The ad content may be distributed, throughnetwork 1225, to one ormore user devices 1220 before, during, or after presentation of the material. In some implementations,advertisement provider system 1205 may be coupled with anadvertising repository 1210. The ad repository stores advertisements that may be presented with various types of content, including audio and/or video content. The selection of advertisements for presentment with the video content item is determined based on images. For example, an ad may be targeted for presentation in a video content item based on an image in one or more frames of the video content item. - Video content may be consumed at various client locations, using various devices. Examples of the various devices include customer premises equipment which is used at a residence or place of business (e.g., computers, video players, video-capable game consoles, televisions or television set-top boxes, etc.), a mobile telephone with video functionality, a video player, a laptop computer, a set top box, a game console, a car video player, etc. Video content may be transmitted from various sources including, for example, terrestrial television (or data) transmission stations, cable television (or data) transmission stations, satellite television (or data) transmission stations, via satellites, and video content servers (e.g., Webcasting servers, podcasting servers, video streaming servers, video download Websites, etc.), via a network such as the Internet for example, and a video phone service provider network such as the Public Switched Telephone Network (“PSTN”) and the Internet, for example.
- Ad content may include text, graphics, still-images, video, audio, audio and video, banners, links (such as advertising providing a hyperlink to an advertiser's website), and other web or television programming related data. As such, ad content may be formatted differently, based on whether the ad content is primarily directed to websites, media players, email, television programs, closed captioning, etc. For example, ad content directed to a website may be formatted for display in a frame within a web browser. In other examples, ad content may be delivered in an RSS (Real Simple Syndication) feed, or ad content may be delivered relative to a radio item (such as before, during or after a radio item). As yet another example, ad content directed to a video player may be presented “in-stream” as video content is played in the video player. In some implementations, in-stream ad content may replace the video or audio content in a video or audio player for some period of time or may be inserted between portions of the video or audio content. An in-stream advertisement may include video, audio, text, animated images, still images, or some combination thereof.
- The
content provider system 1215 may present video content to users (e.g., user device 1220) through thenetwork 1225. Thecontent provider system 1215 may be an implementation of thepublisher system 606 ofFIG. 6 . In some implementations, thecontent provider system 1215 may include web servers where the content includes webpages or other content written in the Hypertext Markup Language (HTML), or any language suitable for authoring webpages. In general,content provider system 1215 may include users, web publishers, and other entities capable of distributing video content over a network. For example, a web publisher may post a video file on a publicly available web server for download and playing by other users. In some implementations, thecontent provider system 1215 may make the content accessible through a known Uniform Resource Locator (URL). - The
content provider system 1215 may receive requests for video content. Thecontent provider system 1215 may retrieve the requested video content in response to, or otherwise service, the request. Thecontent provider system 1215 may broadcast video content as well (e.g., providing content though not necessarily responsive to a request). - Content provided by
content provider system 1215 may include news, weather, entertainment, or other consumable textual, audio, or video media. More particularly, the content may include various resources, such as documents (e.g., webpages, plain text documents, Portable Document Format (PDF) documents, and images), video or audio clips, etc. In some implementations, the content may be graphic-intensive, media-rich data, such as, for example, Flash-based content that presents video and sound media. - The
environment 1200 includes one ormore user devices 1220. Theuser device 1220 may include a desktop computer, laptop computer, a media player (e.g., an MP3 player, a streaming audio player, a streaming video player, a television, a computer, a mobile device, a DVD player, etc.), a mobile phone, a browser facility (e.g., a web browser application), an e-mail facility, telephony means, a set top box, a television device, a radio device or other device that may access advertisements and other content vianetwork 1225. One or more of theuser devices 1220 may be implementations of user devices 608 ofFIG. 6 . Thecontent provider system 1215 may permituser device 1220 to access content (e.g., video files for downloading or streaming). - The
network 1225 facilitates wireless or wireline communication between theadvertisement provider system 1205, thecontent provider system 1215, and any other local or remote computers (e.g., user device 1220). Thenetwork 1225 may be all or a portion of an enterprise or secured network. In another example, thenetwork 1225 may be a virtual private network (VPN) between thecontent provider system 1215 and theuser device 1220 across a wireline or a wireless link. While illustrated as a single or continuous network, thenetwork 1225 may be logically divided into various sub-nets or virtual networks without departing from the scope of this disclosure, so long as at least a portion of thenetwork 1225 may facilitate communications between theadvertisement provider system 1205,content provider system 1215, and at least one client (e.g., user device 1220). In certain implementations, thenetwork 1225 may be a secure network associated with the enterprise and certain local orremote clients 1220. - Examples of
network 1225 include a local area network (LAN), a wide area network (WAN), a wireless phone network, a Wi-Fi network, a WiMax network, a broadband network, and the Internet. - In some implementations, a video content item is combined with one or more of the ads provided by the
advertisement provider system 1205, for example, based on an image appearing in the video content item. This combined information including the content of the content item and ad(s) is then forwarded toward auser device 1220 that requested the content item or that configured itself to receive the content item, for presentation to a user. - The
content provider system 1215 may transmit information about the ads and how, where or when the ads are to be rendered based on an image in the video content item back to theadvertisement provider system 1205 through thenetwork 1225. Alternatively, or in addition, such information may be provided back to theadvertisement provider system 1205 by some other means. - In some implementations, the
content provider system 1215 includes advertisement media as well as other content. In such a case, theadvertisement provider system 1205 may determine and inform thecontent provider system 1215 which advertisements to send to theuser device 1220, for example. - More particularly,
FIG. 13 is anexample process 1300 for processing video content items for images and retrieving associated ads. In some implementations, theprocess 1300 may be performed such that the video content item is preprocessed to associate ads with images prior to enabling viewing of the video. Additionally or alternatively, theprocess 1300 may be used to identify ads based on images in the video while the video is being viewed or streamed for viewing. In some implementations, the video content item may be preprocessed to identify images in the video content item and the ads may be associated with the images at a later time, such as while the video is being viewed or streamed for viewing. The steps ofprocess 1300 do not have to occur in a specific order and at least some steps can occur in parallel. - A video content item is received for processing (1310). The video content item may be preprocessed to locate images in the various frames that may have associated advertisements. Alternatively or additionally, the video content item may be processed as the video is being viewed or streamed for viewing. As described above, a user or advertiser may have bid to have an ad displayed with a particular image. It may be desirable to also display the ad when the image, or a similar image, appears in a video content item. The ad may be displayed in the same window as the video content item, or may be displayed in a separate window.
- The frames of the video content item are analyzed to find regions-of-interest (1320). In some implementations, each frame of the video content item is analyzed to identify regions-of-interest. Alternatively, because video content items may contain a large number of frames for each second of video content, and regions-of-interest typically remain visible in a video content item for one or more seconds, some sampling rate may be chosen for frame analysis. For example, every 24 frames may be selected for analysis.
- The identified regions-of-interest are decomposed into local features (1325), which are used to search against the reference local features associated with one or more reference regions-of-interest (1330). The target local features images may be matched against reference local features using image or object recognition techniques. A local feature may be considered a match, if the one or more identified local features match with a confidence level greater than a selected threshold, for example. Stored one or more region(s)-of-interest that match local features are identified, and the ads associated with the one or more regions-of-interest are retrieved (1340).
- The retrieved ads are associated with the video content item (1350). The ads may be associated with the video content item such that when a frame of the video content item is displayed that contains one or more images with associated ads, the ads are retrieved and displayed at the same time that the video content item is played. The ads may be displayed in an overlay on top of a media player currently processing the video content item, or in a separate window, for example.
- In some implementations, the ads or references to the ads may be embedded into the video content item and decoded or retrieved by a media player capable of recognizing the embedded ads. In other implementations, the ads or references to the ads may be stored in a separate file that indicates where and how the ads may be presented to the user during video content item playback.
-
FIG. 14 is anexample user interface 1400 illustrating advertising content displayed on a screen with video content where the displayed ads are based on an image. Theuser interface 1400 illustrates an example web browser user interface. However, the content shown in theuser interface 1400 can be presented in a webpage, an MP3 player, a streaming audio player, a streaming video player, a television, a computer, a mobile device, etc. The content shown in theuser interface 1400 may be provided by anadvertisement provider 1205, acontent provider 1215, another networked device, or some combination of those providers. - As shown, the
user interface 1400 includes avideo player region 1410 including animage 1415 on which an ad presented inad region 1420 is based. Thevideo display region 1410 may include a media player for presenting text, images, video, or audio, or any combination thereof. Thead region 1420 displays advertisements (e.g., banner ads, flash-based video/audio ads, scrolling ads, etc.) based on an image shown in the video player region. The ad displayed inad region 1420 may be associated with an image in thevideo player region 1410, for example, based on theprocess 1300 ofFIG. 13 . -
FIG. 15 is anexample process 1500 for retrieving ads associated with images in a video content item. For example, theprocess 1500 may be used to present ads inad region 1320 ofFIG. 13 . In addition to or in lieu of preprocessing a video content item as described above with respect to process 1300 ofFIG. 13 , the frames of the video content item may be analyzed for images with associated ads as the video frames are presented. The steps ofprocess 1500 do not have to occur in a specific order and at least some steps can occur in parallel. - A video content item is played for viewing (1510). For example, a video content item may be played on a media player and the video content item may be displayed, for example, in a video player region, such as
region 1410 ofFIG. 14 . In some implementations, a buffer may be utilized to allow some time for the processing of the video content item frame and the retrieval and display of the associated ads. The particular size of the buffer may vary depending on the resources of the computer performing the processing, and other factors such as the complexity of the video content item frame, and the rate at which the video frames are processed. - A selected, or current, frame of the video content item is analyzed for one or more region(s)-of-interest (1520). The frame may be selected from a buffer or frame queue. Each frame in the video content item may be analyzed, or some sampling rate may be selected for the video content item to reduce the number of frames that are analyzed, such as every 24 frames for example. The particular sampling rate chosen may be a function of the available computing resources, for example. Further, the sampling rate may be dynamic and change depending upon how many frames are in the buffer, or the number of local features being located.
- In some implementations, a current video content item frame may be compared with a previously analyzed video content item frame to determine relative differences between before analyzing the current frame. Because video content items frames are often very similar to proceeding video content item frames, the identified local features in the two frames may be identical or near identical. Thus, processing resources may be saved by determining the relative similarities or differences between two frames using a relatively low computationally intensive comparison process before undertaking the high computationally intensive process of locating local features and matching them against stored images. If a frame is statistically similar enough to a previously analyzed frame it can be assigned the same local features as the previous frame, for example.
- The identified one or more region(s)-of-interest are used to search a database of images (1530). A region-of-interest may be decomposed to identify target local features, which are compared against the reference local features using object recognition techniques, for example.
- Ads associated with any matching region-of-interest are retrieved and displayed along with the current video frame in video content item (1540). In some implementations, the ads are displayed in a window separate from the window displaying the video content item, such as illustrated in
ad region 1420 andvideo player region 1410 ofFIG. 14 . Additionally or alternatively, the ads may be displayed on or near the associated regions-of-interest in the current frame of the video stream in an overlay, for example. -
FIG. 16 depicts anexample user interface 1600 for providing ads associated with images in a video content item. Theuser interface 1600 includesmedia control window 1605 that may contain the various icons that are used to control the playback of a video content item. - The
user interface 1600 also includes avideo content region 1610 where frames of a currently playing video content are displayed. In some implementations, theregion 1610 may also display ads associated with one or more images displayed in a current frame of the video content item. As illustrated, the ads are displayed inad regions region 1610 so as to not interfere with viewing of the video content item. - In the example shown in
FIG. 16 , a video content item is being played in theuser interface 1600. The current frame of the video content item is shown in theregion 1610 and shows a man standing next to a personal computer. - As described with respect to
FIG. 14 , the displayed frame in the video content item is analyzed for regions-of-interest. The regions-of-interest are decomposed to identify local features, which are used to query a database of reference local features corresponding to reference regions-of-interest associated with ads. Ads associated with matching regions-of-interest are displayed along with the current video content item frame. - In the example shown in
FIG. 16 , the regions-of-interest of a computer and a man. Various ads related to the computer image are shown inad regions Ad region 1620 shows a banner ad, whereasad region 1630 includes hyperlink ads by which web pages of corresponding advertisers may be accessed. Similarly, thebox 1635 displays an ad inside the current frame of the video content item. In the example ofuser interface 1600, no ads were displayed related to the man sub-image displayed invideo region 1610. -
FIG. 17 shows anexample environment 1700 for the presentation of advertisements associated with a digital photograph. In general, theenvironment 1700 allows a user to submit a digital photograph from a user device and in return receive advertisements related to the submitted photograph as well as well as other non-advertisement content such as search engine results, for example. - More particularly, the
environment 1700 includes auser device 1701 adapted to take a digital photograph and submit it to aserver 1725 via anetwork 1713. Theserver 1725 is adapted to receive the digital photograph through thenetwork 1713, analyze the image to identify one or more stored matching representations of objects that have associated advertisements, and provide the associated advertisements, and other content, to theuser device 1701 via thenetwork 1713. - The
user device 1701 may comprise a mobile phone capable of taking digital photographs. However, theuser device 1701 is not limited to mobile phones, and may comprise any device capable of taking digital pictures including, but not limited to, a personal digital assistant, a smart phone, a laptop computer, a digital camera, a portable media player, and a portable video game console, for example. - In the example shown in
FIG. 17 , a user of theuser device 1701 takes a picture of an object 1715 (here, a book) for which the user or operator of theuser device 1701 would like to receive additional information. Theobject 1715 may including anything capable of being photographed including people, automobiles, buildings, products, advertisements, text, etc. For example, a user may take a photograph of an automobile, an advertisement or a billboard featuring a movie, a restaurant or a hotel about which the user desires more information. - The digital photograph is transmitted by the
user device 1701 to theserver 1725. Theuser device 1701 and theserver 1725 are wirelessly connected through anetwork 1713. Thenetwork 1713 may comprise a variety of networks including, but not limited to, a public network (e.g., the internet), a private network (e.g., corporate LAN), and cellular telephone network (e.g., CDMA, GSM, 2G, 2.5G and 3G). - The
server 1725 receives the image of the object and compares the image of the object to stored representations of objects using a variety of object recognition techniques. In the example shown, theserver 1725 may compare the received image of the book with one or more stored representations of objects using various object recognition techniques. Because different object recognition systems or engines are often suitable for different object types, it may be desirable to process the received image with a variety of object recognition engines. For example, certain characteristics and assumptions about a human face may be utilized by a face recognition engine to improve performance. However, those assumptions may not apply to the recognition of rigid textured objects, such as a building, for example. Thus, theserver 1725 may compare the received image with the stored representations of objects using a variety of object recognition engines. These engines may include: an opticalcharacter recognition engine 1726; a rigid texturedobject recognition engine 1727; aface recognition engine 1728; and an articulateobject recognition engine 1729. The particular object recognition engines used are discussed further in U.S. Patent Application No. 61/129,034, titled “Image-based Search Engine for Mobile Phones With Camera.” The contents of the application are hereby incorporated by reference in its entirety. - The
server 1725 may further retrieve any advertisements associated with the matching representation of an object. In the example shown, an advertiser, such as a book store owner or a book publisher, may have bid to have an advertisement associated with thebook object 1715. The advertisement may be combined with search engine results or other non-advertisement content produced in response to receiving the image and returned to theuser device 1701, for example. - In this manner, a person may receive advertisements or information about objects by sending an image of an object to an information retrieval system.
-
FIG. 18 is a flow diagram of anexample process flow 1800 for the presentation of advertisements associated with a digital photograph. The steps of process 6100 do not have to occur in a specific order and at least some steps can occur in parallel. - An image is received from a user device capable of taking digital photographs (1810). The user device may be any device capable of taking digital pictures, such as a mobile phone, a digital camera, or a portable media device. In one example, a user of a mobile phone may have taken a digital image of a particular object about which more information is desired.
- Additional image content information may be optionally received (1820). For example, additional classification data may be received from the user device. This additional data may allow the object recognition engines that process the received image to narrow the number of objects that are searched or provide more accurate results. In some implementations the additional data may be user supplied. The user may be prompted after taking the image to select a general category for the image or provide a description. For example, after taking a picture of a restaurant, the user may indicate that that the picture is of a restaurant. This additional data may allow the object recognition engines to narrow the objects that are searched to those objects associated with restaurants.
- In some implementations, the additional data may be automatically supplied by the user device. For example, where the user device is equipped with a global positioning system, the user device may provide the coordinates of the location where the image was taken. This location data may then be used by the object recognition engines to restrict their image search to images of objects that are associated with provided coordinates.
- The received image is processed using various object recognition engines (1830). As described above, matching objects may be located in the received image by comparing stored object representations with the received image. The object recognition engines may include, but are not limited to, an optical character recognition engine, a rigid textured object recognition engine, a face recognition engine, and an articulate object recognition engine.
- Each engine may compare the received image of an object with one or more stored representations of objects. The stored representations of objects may comprise images, for example. Each object recognition engine may, as an output, indicate which of the stored representations of objects it matched with the image, along with a confidence value. The stored representation of an object that is found to match the received image with the highest confidence value is selected. In some implementations a minimum confidence value may be selected such that no representation of an object is selected as a match unless it exceeds the minimum confidence value. Where no representation of an object meets the minimum confidence value, an error may be sent to the submitting user device, or the user may be asked to provide another image, for example.
- Advertisements associated with the recognized objects are returned to the user device along with any additional content (1840). One or more of the stored representations of objects may have associated advertisements. The advertisements may have been provided by advertisers who bid on having an advertisement displayed when an image matching the particular representation of an object is received. The advertisements may be stored with each advertisement's associated representation of an object, or may be stored separately. The advertisements may be provided to the user device along with any additional non-advertisement content related to the received image.
- For example, an online merchant may bid to have an advertisement for a particular DVD displayed when an image matching the stored representation of that DVD is received. Later, a user may see the DVD at a store and take a picture of the DVD using a mobile phone in order to receive more information about the DVD. When the image matching the representation of the DVD is received, the associated advertisement is retrieved. The received image may have also been used as a query to a search engine to produce non-advertisement search engine results related to the DVD. The associated advertisement may be combined with the non-advertisement search engine results and sent to the user device.
- Although the image retrieval concepts in
FIGS. 17 and 18 have been described with respect to receiving an analyzing a digital photograph, the techniques are also applicable to other devices and media, such as digitized hand-drawn sketches, graphic images, and one or more frames in a video. -
FIG. 19 shows an example of ageneric computer device 1900 and a genericmobile computer device 1950, which may be used with the techniques described above.Computing device 1900 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, television set-top boxes, servers, blade servers, mainframes, and other appropriate computers.Computing device 1950 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices. The components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit the implementations described and/or the claims. -
Computing device 1900 includes aprocessor 1902,memory 1904, astorage device 1906, a high-speed interface 1908 connecting tomemory 1904 and high-speed expansion ports 1910, and alow speed interface 1912 connecting tolow speed bus 1914 andstorage device 1906. Each of thecomponents processor 1902 can process instructions for execution within thecomputing device 1900, including instructions stored in thememory 1904 or on thestorage device 1906 to display graphical information for a GUI on an external input/output device, such asdisplay 1916 coupled tohigh speed interface 1908. In other implementations, multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory. Also,multiple computing devices 1900 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system). - The
memory 1904 stores information within thecomputing device 1900. In one implementation, thememory 1904 is a volatile memory unit or units. In another implementation, thememory 1904 is a non-volatile memory unit or units. Thememory 1904 may also be another form of computer-readable medium, such as a magnetic or optical disk. - The
storage device 1906 is capable of providing mass storage for thecomputing device 1900. In one implementation, thestorage device 1906 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as thememory 1904, thestorage device 1906, memory onprocessor 1902, or a propagated signal. - The
high speed controller 1908 manages bandwidth-intensive operations for thecomputing device 1900, while thelow speed controller 1912 manages lower bandwidth-intensive operations. Such allocation of functions is exemplary only. In one implementation, the high-speed controller 1908 is coupled tomemory 1904, display 1916 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 1910, which may accept various expansion cards (not shown). In the implementation, low-speed controller 1912 is coupled tostorage device 1906 and low-speed expansion port 1914. The low-speed expansion port, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as apointing device 1930, aprinter 1932, akeyboard 1934, ascanner 1936, or anetworking device 1937 such as a switch or router, e.g., through a network adapter. - The
computing device 1900 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as astandard server 1920, or multiple times in a group of such servers. It may also be implemented as part of arack server system 1924. In addition, it may be implemented in a personal computer such as alaptop computer 1922. Alternatively, components fromcomputing device 1900 may be combined with other components in a mobile device (not shown), such asdevice 1950. Each of such devices may contain one or more ofcomputing device multiple computing devices -
Computing device 1950 includes aprocessor 1952,memory 1964, an input/output device such as adisplay 1954, acommunication interface 1966, and atransceiver 1968, among other components. Thedevice 1950 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage. Each of thecomponents - The
processor 1952 can execute instructions within thecomputing device 1950, including instructions stored in thememory 1964. The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. The processor may provide, for example, for coordination of the other components of thedevice 1950, such as control of user interfaces, applications run bydevice 1950, and wireless communication bydevice 1950. -
Processor 1952 may communicate with a user throughcontrol interface 1958 anddisplay interface 1956 coupled to adisplay 1954. Thedisplay 1954 may be, for example, a TFT (Thin-Film-Transistor Liquid Crystal Display) display or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology. Thedisplay interface 1956 may comprise appropriate circuitry for driving thedisplay 1954 to present graphical and other information to a user. Thecontrol interface 1958 may receive commands from a user and convert them for submission to theprocessor 1952. In addition, anexternal interface 1962 may be provide in communication withprocessor 1952, so as to enable near area communication ofdevice 1950 with other devices.External interface 1962 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used. - The
memory 1964 stores information within thecomputing device 1950. Thememory 1964 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.Expansion memory 1974 may also be provided and connected todevice 1950 throughexpansion interface 1972, which may include, for example, a SIMM (Single In Line Memory Module) card interface.Such expansion memory 1974 may provide extra storage space fordevice 1950, or may also store applications or other information fordevice 1950. Specifically,expansion memory 1974 may include instructions to carry out or supplement the processes described above, and may include secure information also. Thus, for example,expansion memory 1974 may be provide as a security module fordevice 1950, and may be programmed with instructions that permit secure use ofdevice 1950. In addition, secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner. - The memory may include, for example, flash memory and/or NVRAM memory, as discussed below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the
memory 1964,expansion memory 1974, memory onprocessor 1952, or a propagated signal that may be received, for example, overtransceiver 1968 orexternal interface 1962. -
Device 1950 may communicate wirelessly throughcommunication interface 1966, which may include digital signal processing circuitry where necessary.Communication interface 1966 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 1968. In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System)receiver module 1970 may provide additional navigation- and location-related wireless data todevice 1950, which may be used as appropriate by applications running ondevice 1950. -
Device 1950 may also communicate audibly usingaudio codec 1960, which may receive spoken information from a user and convert it to usable digital information.Audio codec 1960 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset ofdevice 1950. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating ondevice 1950. - The
computing device 1950 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as acellular telephone 1980. It may also be implemented as part of asmartphone 1982, personal digital assistant, or other similar mobile device. - Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- These computer programs (also known as programs, software, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine language. As used herein, the terms “machine-readable medium” “computer-readable medium” refers to any computer program product, apparatus and/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term “machine-readable signal” refers to any signal used to provide machine instructions and/or data to a programmable processor.
- To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- The systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- Although the techniques and concepts generally have been described using a sub-image of an image, the techniques and concepts are applicable to an image. Also, the decomposition of an image into sub-images may be based on various image features, including, for example, color, shape, texture, in lieu of or in addition to decomposing a region-of-interest into local features.
- A number of implementations have been described. Nevertheless, it will be understood that various modifications may be made. For example, various forms of the flows shown above may be used, with steps re-ordered, added, or removed. Other implementations are within the scope of the following claims.
Claims (30)
1. A computer system for selecting a content item, the computer system comprising:
one or more computer storage devices storing images, storing content items, and storing instructions that are executable by one or more processing devices; and
the one or more processing devices to execute the instructions to perform operations comprising:
receiving data representing a first image from a content server of a publisher and over a computer network, the first image being part of a media property of the publisher;
analyzing the first image to identify, based on at least one attribute of the first image, a region of interest of the first image that relates to a subject of the image and that is visually-distinguishable from a background of the image;
decomposing the region of interest of the first image into one or more local features, wherein a local feature comprises an element of the region of interest;
comparing the first image and a second image stored in the one or more computer storage devices by comparing the one or more local features included in the region of interest of the first image with one or more local features included in a region of interest of the second image to generate a match score indicating a likelihood of a match between the first image and the second image;
identifying a content item associated with the second image based on an association between the second image and the content item in an association data store;
selecting, from the one or more computer storage devices, the identified content item based on a comparison between the match score and a predetermined threshold; and
outputting over the computer network, data representing the content item to at least one of the content server of the publisher and a client device.
2. The computer system of claim 1 , wherein the one or more local features of the first image comprises an image element specific to the publisher.
3. The computer system of claim 1 , wherein comparing comprises identifying a one or more local features of the first image that are identical to one or more local features of the second image.
4. The computer system of claim 1 , wherein the one or more local features of the first image comprises part of a subject of the first image.
5. (canceled)
6. The computer system of claim 1 , wherein
comparing the first image and the second image comprises comparing the region of interest of the first image with the region of interest of the second image.
7. (canceled)
8. (canceled)
9. (canceled)
10. The computer system of claim 1 , wherein
comparing the first image and the second image includes comparing the first image and the second image using computer-implemented object recognition techniques that include at least one of optical character recognition, rigid textured object recognition, face recognition, and articulate object recognition.
11-12. (canceled)
13. The computer system of claim 1 , wherein the first image is associated with search results to be presented over the computer network.
14. The computer system of claim 1 , wherein the first image is associated with document content to be presented over the computer network.
15. The computer system of claim 1 , wherein the second image is a reference image comprising content relating to the publisher.
16-19. (canceled)
20. A computer implemented method comprising:
receiving, by one or more processing devices, data representing a first image from a content server of a publisher and over a computer network, the first image being part of a media property of the publisher;
analyzing, by one or more processing devices, the first image to identify, based on at least one attribute of the first image, a region of interest of the first image that relates to a subject of the image and that is visually-distinguishable from a background of the image;
decomposing, by one or more processing devices, the region of interest of the first image into one or more local features, wherein a local feature comprises an element of the region of interest;
comparing the first image and a second image stored in the one or more computer storage devices by comparing the one or more local features included in the region of interest of the first image with one or more local features included in a region of interest of the second image to generate a match score indicating a likelihood of a match between the first image and the second image;
identifying, by one or more processing devices, a content item associated with the second image based on an association between the second image and the content item in an association data store;
selecting, from the one or more computer storage devices and by one or more processing devices, the identified content item based on a comparison between the match score and a predetermined threshold; and
outputting, over the computer network, data representing the content item to at least one of the content server of the publisher and a client device.
21-25. (canceled)
26. One or more non-transitory machine-readable storage media storing instructions that are executable by one or more processing devices to perform operations comprising:
receiving data representing a first image from a content server of a publisher and over a computer network, the first image being part of a media property of the publisher;
analyzing the first image to identify, based on at least one attribute of the first image, a region of interest of the first image that relates to a subject of the image and that is visually-distinguishable from a background of the image;
decomposing the region of interest of the first image into one or more local features, wherein a local feature comprises an element of the region of interest;
comparing the first image and a second image stored in the one or more computer storage devices by comparing the one or more local features included in the region of interest of the first image with one or more local features included in a region of interest of the second image to generate a match score indicating a likelihood of a match between the first image and the second image;
identifying a content item associated with the second image based on an association between the second image and the content item in an association data store;
selecting, from the one or more computer storage devices, the identified content item based on a comparison between the match score and a predetermined threshold; and
outputting, over the computer network, data representing the content item to at least one of the content server of the publisher and a client device.
27. The one or more non-transitory machine-readable storage media of claim 26 , wherein the one or more local features of the first image comprises an image element specific to the publisher.
28. The one or more non-transitory machine-readable storage media of claim 26 , wherein comparing comprises identifying one or more local features of the first image that are identical to one or more local features of the second image.
29. The one or more non-transitory machine-readable storage media of claim 26 , wherein the one or more local features of the first image comprises part of a subject of the first image.
30. The one or more non-transitory machine-readable storage media of claim 26 , wherein
comparing the first image and a second image comprises comparing the region of interest of the first image with a region of interest of the second image.
31. (canceled)
32. (canceled)
33. (canceled)
34. The one or more non-transitory machine-readable storage media of claim 26 , wherein:
the computer-implemented object recognition techniques include at least one of optical character recognition, rigid textured object recognition, face recognition, and articulate object recognition.
35-36. (canceled)
38. The one or more non-transitory machine-readable storage media of claim 26 , wherein the first image is associated with search results to be presented over the computer network.
39. The one or more non-transitory machine-readable storage media of claim 26 , wherein the first image is associated with document content to be presented over the computer network.
40. The one or more non-transitory machine-readable storage media of claim 26 , wherein the second image is a reference image comprising content relating to the publisher.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/966,429 US20170213248A1 (en) | 2007-12-28 | 2007-12-28 | Placing sponsored-content associated with an image |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/966,429 US20170213248A1 (en) | 2007-12-28 | 2007-12-28 | Placing sponsored-content associated with an image |
Publications (1)
Publication Number | Publication Date |
---|---|
US20170213248A1 true US20170213248A1 (en) | 2017-07-27 |
Family
ID=59360798
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US11/966,429 Abandoned US20170213248A1 (en) | 2007-12-28 | 2007-12-28 | Placing sponsored-content associated with an image |
Country Status (1)
Country | Link |
---|---|
US (1) | US20170213248A1 (en) |
Cited By (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10768891B2 (en) * | 2010-01-26 | 2020-09-08 | Touchtunes Music Corporation | Digital jukebox device with improved user interfaces, and associated methods |
US10922350B2 (en) * | 2010-04-29 | 2021-02-16 | Google Llc | Associating still images and videos |
US11164219B1 (en) * | 2009-08-06 | 2021-11-02 | 2Kdirect, Inc. | Automatic generation of electronic advertising messages |
US11373230B1 (en) * | 2018-04-19 | 2022-06-28 | Pinterest, Inc. | Probabilistic determination of compatible content |
US20220237249A1 (en) * | 2014-05-23 | 2022-07-28 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US11574343B2 (en) | 2009-10-01 | 2023-02-07 | 2Kdirect, Inc. | Automatic generation of electronic advertising messages containing one or more automatically selected stock photography images |
US11676180B1 (en) * | 2022-08-05 | 2023-06-13 | Samsung Electronics Co., Ltd. | AI-based campaign and creative target segment recommendation on shared and personal devices |
US11687576B1 (en) | 2021-09-03 | 2023-06-27 | Amazon Technologies, Inc. | Summarizing content of live media programs |
US11785299B1 (en) | 2021-09-30 | 2023-10-10 | Amazon Technologies, Inc. | Selecting advertisements for media programs and establishing favorable conditions for advertisements |
US11785272B1 (en) | 2021-12-03 | 2023-10-10 | Amazon Technologies, Inc. | Selecting times or durations of advertisements during episodes of media programs |
US11791920B1 (en) | 2021-12-10 | 2023-10-17 | Amazon Technologies, Inc. | Recommending media to listeners based on patterns of activity |
US11792467B1 (en) * | 2021-06-22 | 2023-10-17 | Amazon Technologies, Inc. | Selecting media to complement group communication experiences |
US11792143B1 (en) | 2021-06-21 | 2023-10-17 | Amazon Technologies, Inc. | Presenting relevant chat messages to listeners of media programs |
US11916981B1 (en) | 2021-12-08 | 2024-02-27 | Amazon Technologies, Inc. | Evaluating listeners who request to join a media program |
-
2007
- 2007-12-28 US US11/966,429 patent/US20170213248A1/en not_active Abandoned
Cited By (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11164219B1 (en) * | 2009-08-06 | 2021-11-02 | 2Kdirect, Inc. | Automatic generation of electronic advertising messages |
US11574343B2 (en) | 2009-10-01 | 2023-02-07 | 2Kdirect, Inc. | Automatic generation of electronic advertising messages containing one or more automatically selected stock photography images |
US11477866B2 (en) * | 2010-01-26 | 2022-10-18 | Touchtunes Music Corporation | Digital jukebox device with improved user interfaces, and associated methods |
US11252797B2 (en) * | 2010-01-26 | 2022-02-15 | Touchtunes Music Corporation | Digital jukebox device with improved user interfaces, and associated methods |
US11700680B2 (en) * | 2010-01-26 | 2023-07-11 | Touchtunes Music Company, Llc | Digital jukebox device with improved user interfaces, and associated methods |
US10768891B2 (en) * | 2010-01-26 | 2020-09-08 | Touchtunes Music Corporation | Digital jukebox device with improved user interfaces, and associated methods |
US10922350B2 (en) * | 2010-04-29 | 2021-02-16 | Google Llc | Associating still images and videos |
US20220237249A1 (en) * | 2014-05-23 | 2022-07-28 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US11734370B2 (en) * | 2014-05-23 | 2023-08-22 | Samsung Electronics Co., Ltd. | Method for searching and device thereof |
US11373230B1 (en) * | 2018-04-19 | 2022-06-28 | Pinterest, Inc. | Probabilistic determination of compatible content |
US11792143B1 (en) | 2021-06-21 | 2023-10-17 | Amazon Technologies, Inc. | Presenting relevant chat messages to listeners of media programs |
US11792467B1 (en) * | 2021-06-22 | 2023-10-17 | Amazon Technologies, Inc. | Selecting media to complement group communication experiences |
US11687576B1 (en) | 2021-09-03 | 2023-06-27 | Amazon Technologies, Inc. | Summarizing content of live media programs |
US11785299B1 (en) | 2021-09-30 | 2023-10-10 | Amazon Technologies, Inc. | Selecting advertisements for media programs and establishing favorable conditions for advertisements |
US11785272B1 (en) | 2021-12-03 | 2023-10-10 | Amazon Technologies, Inc. | Selecting times or durations of advertisements during episodes of media programs |
US11916981B1 (en) | 2021-12-08 | 2024-02-27 | Amazon Technologies, Inc. | Evaluating listeners who request to join a media program |
US11791920B1 (en) | 2021-12-10 | 2023-10-17 | Amazon Technologies, Inc. | Recommending media to listeners based on patterns of activity |
US11676180B1 (en) * | 2022-08-05 | 2023-06-13 | Samsung Electronics Co., Ltd. | AI-based campaign and creative target segment recommendation on shared and personal devices |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8315423B1 (en) | Providing information in an image-based information retrieval system | |
US9043828B1 (en) | Placing sponsored-content based on images in video content | |
US8346604B2 (en) | Facilitating bidding on images | |
US20170213248A1 (en) | Placing sponsored-content associated with an image | |
US8732766B2 (en) | Video object tag creation and processing | |
US8433611B2 (en) | Selection of advertisements for placement with content | |
US10299015B1 (en) | Time-based content presentation | |
AU2008343242B2 (en) | Video quality measures | |
US20160253715A1 (en) | Hashtags and Content Presentation | |
US20090172727A1 (en) | Selecting advertisements to present | |
US20110078718A1 (en) | Targeting videos for advertisements by audience or content | |
US20080077952A1 (en) | Dynamic Association of Advertisements and Digital Video Content, and Overlay of Advertisements on Content | |
US11138210B2 (en) | Augmenting a content item using search results content | |
US20160165314A1 (en) | Systems and methods for displaying and interacting with interaction opportunities associated with media content | |
US20100023397A1 (en) | Video Promotion In A Video Sharing Site | |
US10397661B2 (en) | Video frame selection for targeted content | |
US20160036939A1 (en) | Selecting Content for Simultaneous Viewing by Multiple Users | |
US11657850B2 (en) | Virtual product placement | |
US20100250371A1 (en) | Advertisement customization system and method | |
US10089635B1 (en) | Presenting video view data | |
US20150199718A1 (en) | Selecting content items using entities of search results | |
Jing et al. | Placing Sponsored-Content Associated With An Image | |
US20190286745A1 (en) | Community-based recommendations | |
US10346519B1 (en) | Selecting content based on entities |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:JING, YUSHI;BALUJA, SHUMEET;SIGNING DATES FROM 20080222 TO 20080225;REEL/FRAME:020594/0829 |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044142/0357Effective date: 20170929 |