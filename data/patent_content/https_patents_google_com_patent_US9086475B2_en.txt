US9086475B2 - Self-localization for a set of microphones - Google Patents
Self-localization for a set of microphones Download PDFInfo
- Publication number
- US9086475B2 US9086475B2 US13/746,333 US201313746333A US9086475B2 US 9086475 B2 US9086475 B2 US 9086475B2 US 201313746333 A US201313746333 A US 201313746333A US 9086475 B2 US9086475 B2 US 9086475B2
- Authority
- US
- United States
- Prior art keywords
- sensors
- events
- algorithm
- criterion
- localization
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01S—RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
- G01S3/00—Direction-finders for determining the direction from which infrasonic, sonic, ultrasonic, or electromagnetic waves, or particle emission, not having a directional significance, are being received
- G01S3/80—Direction-finders for determining the direction from which infrasonic, sonic, ultrasonic, or electromagnetic waves, or particle emission, not having a directional significance, are being received using ultrasonic, sonic or infrasonic waves
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01S—RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
- G01S5/00—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations
- G01S5/18—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations using ultrasonic, sonic, or infrasonic waves
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01S—RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
- G01S5/00—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations
- G01S5/02—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations using radio waves
- G01S5/0278—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations using radio waves involving statistical or probabilistic considerations
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01S—RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
- G01S5/00—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations
- G01S5/02—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations using radio waves
- G01S5/0284—Relative positioning
- G01S5/0289—Relative positioning of multiple transceivers, e.g. in ad hoc networks
Definitions
- the present disclosure generally relates to methods and systems for signal processing. More specifically, aspects of the present disclosure relate to determining locations of sensors based on their observation of a set of events.
- ⁇ For various applications it is useful to determine the relative localization of a number of sensors. In the case of sensors, this allows the determination of spatial information about the sensed signal.
- Useful information can also be obtained from determining the location of a set of microphones. For example, such information can be used to determine the location of sound sources producing the audio being captured by the microphones. The information can also be used to separate sound signals produced by different sounds sources, such as talking persons or musical instruments. In such a scenario, knowledge of the location of the microphones facilitates the usage of physical models, likely providing an advantage over separation methods that do not require the scenario to be physically plausible.
- At least one embodiment of the present disclosure relates to a method comprising: measuring observation times of a set of events at a set of sensors; generating initial estimates for internal delays of the sensors and event times of the events; performing an iterative approximation algorithm to find a rank-3 approximation of the internal delays and event times using a criterion; and computing locations of the sensors using the rank-3 approximation of the internal delays and event times.
- Another embodiment relates to the method further comprising using the locations of the sensors to determine locations of one or more mobile telephones.
- Another embodiment relates to the method further comprising computing locations of the acoustic events using the rank-3 approximation of the internal delays and event times.
- Yet another embodiment relates to the method further comprising using the global solution as an initial value for an iterative maximum-likelihood algorithm to find a global minimum.
- Still another embodiment relates to the method further comprising using the global solution as an initial value for an iterative maximum-likelihood algorithm to minimize a squared error criterion.
- the method may optionally include one or more of the following additional features: the set of events is a set of acoustic events, and the set of sensors is a set of microphones; one or more of the acoustic events is generated by human with hand claps or speech; one or more of the acoustic events is generated by a device with a loudspeaker; the device is a telephone; one or more of the sensors are microphones located on mobile telephones; the localization of the sensors is for the purpose of near-field beam-forming; the localization of the sensors is used to identify talkers in a conference call; the localization of the sensors is used as a basis for the enhancement of recorded audio signals; the iterative approximation algorithm converges to a global solution for the internal delays and the event times; the criterion is selected to facilitate finding a global solution; the criterion is the Frobenius norm; and/or each step of the iterative approximation algorithm minimizes the criterion
- FIG. 1 is a schematic diagram illustrating an example application for self-localization of sensors in a signaling environment according to one or more embodiments described herein.
- FIG. 2 is a flowchart illustrating an example of a method for finding the location of sensors with unknown internal delays based on a set of events with unknown event times according to one or more embodiments described herein.
- FIG. 3 is a block diagram illustrating an example computing device arranged for finding the location of a set of sensors with unknown internal delays based on a set of events with unknown event times according to one or more embodiments described herein.
- Embodiments of the present disclosure relate to methods and systems for finding the location of sensors (e.g., microphones) with unknown internal delays based on a set of events (e.g., acoustic events) with unknown event time.
- a localization algorithm is provided for a set of sensors with unknown internal delays, based on acoustic events with unknown time of occurrence.
- the algorithm has an iterative character, and the iterations are guaranteed to converge.
- the present disclosure rewrites the basic equations for travel time between event location and microphone location to got a set of equations for which it is known that the left-hand side is of rank three.
- the algorithm then iteratively salves for the unknown delay and event-time parameters. The method is guaranteed to converge to the global solution.
- sensors such as microphones in mobile telephones (e.g., Smartphones) and laptop computers
- the methods and systems presented herein may be used to self-localize such sensors and the self-localization information may then be used for near-field beam-forming, which allows for selecting between different talkers and reducing environmental acoustic noise.
- Example applications of the methods and systems described herein include ad-hoc conference calling, group video chat, and the like.
- FIG. 1 illustrates an example application for self-localization of sensors (e.g., microphones) in a signaling environment according to one or more embodiments described herein.
- a plurality of signal sources 105 e.g., talkers, loudspeakers, etc.
- Self-localization of microphones can use modalities other than sound, such as global positioning systems (GPS) and radio-based systems.
- GPS global positioning systems
- radio-based systems are insufficiently accurate for many applications.
- Acoustic self-localization promises high accuracy and low cost, and thus offers an attractive approach.
- a first approach makes a “farfield” approximation to render a set of equations that can be solved using a singular value decomposition, leaving a nonlinear problem with only four unknowns (it should be noted that this first approach considers a two-dimensional space only). The method of this first approach is accurate only if the sound events are located far from the microphones.
- the methods and systems of present disclosure exploit the structure of the localization problem in a manner similar to first and second approaches described above.
- the methods and systems described herein formulate the equations and solutions to include the observation delay. This complicates the problem and leads to an iterative procedure that is guaranteed to converge as will be further described below.
- the methods and systems provided herein allow for computing the event times (e.g., acoustic event times), the observation delays, and the relative locations of the acoustic events and the sensors.
- acoustic event j occurring at time ⁇ j at location a j and a sensor (e.g., a microphone) i located at x i with fixed observation delay d i .
- the objective is to compute the x i and the d i from a set of equations generated by a number of acoustic events.
- the coordinates of a sensor may be computed relative to a selected set of coordinates.
- the first sensor can be selected to have three zero coordinates (e.g., 0, 0, 0 (being the origin)), the second sensor selected to have two zero coordinates, and the third sensor selected to have one zero coordinate.
- the first acoustic event may arbitrarily be set to happen at time zero. As a result, six fewer coordinates need to be computed. In other words, assuming I sensors,
- any additional acoustic event introduces four more unknowns (e.g., time of the event and three coordinates), and that means such an event should introduce at least five equations to help in determining other variables.
- Five sensors lead to five equations of the type shown in equation (2). Since in practice there are often estimation errors, more acoustic events than the minimum (e.g., more than thirteen acoustic events) will lead to greater accuracy.
- the acoustic events which must be spatially diverse, are generated without knowledge of absolute or relative occurrence time. If some or all of the acoustic events are generated with one device with a single clock by physically moving this device, or with multiple devices that share a clock, then the relative time of occurrence of at least some of the acoustic events will be known. The number of events and devices required can then be reduced from that in the above example. This corresponds to a straightforward modification of equation (3) that is simple to derive for a person skilled in the art. It also leads to straightforward changes in the algorithms below.
- G(p) is a nonlinear matrix function of p.
- the aim is to determine a rank-three approximation of T+G(p).
- This problem is generally referred to as a structured low-rank approximation (SLRA) problem.
- SLRA structured low-rank approximation
- the process of deriving an iterative approximation algorithm may begin by constructing a straightforward algorithm based on the Eckart-Young-Mirsky theorem. This theorem states that, if the Frobenius norm is used as criterion, the best N ⁇ M matrix B rank r approximation is U 1 ⁇ 1 V 1 where
- the localization algorithm derived herein which is referred to as “Algorithm A,” may proceed as follows:
- FIG. 2 illustrates the process of Algorithm A described above.
- the algorithm measures the arrival times of a sufficient set of acoustic events at the sensors (e.g., sensors 120 as shown in FIG. 1 ).
- initial estimates for the internal delays and the acoustic event times may be generated.
- a matrix may be constructed at block 210 , where the matrix is a trial right-hand side for equation (11), presented above.
- Equation (11) It is known that a good version of the right-hand side of equation (11) would be rank-3 (that is, the column space can be described by three vectors only, and the same holds for the row space). Therefore, at block 215 , the closest rank-3 matrix (e.g., according to the Frobenius norm) to the trial matrix may be found. This closest rank-3 matrix may be identified as B (3) (n) .
- the initial estimates for the internal delays and the acoustic event times may be adjusted such that the right-hand side of equation (11) approximates B (3) (n) as well as possible using, for example, the Frobenius norm.
- the final result of the iterative process involving blocks 210 through 225 is a set of reasonable internal delays and acoustic event times.
- the internal delays and acoustic event times produced from the iterative process of blocks 210 through 225 may be used to compute the locations of the sensors and the locations of the acoustic events.
- Step 10 of Algorithm A, described above, may be performed with a gradient algorithm that minimizes the error in a Frobenius norm. As there are only nine variables, the probability of getting stuck in a local minimum is relatively small.
- Algorithm A is guaranteed to converge. For each step the algorithm tries to minimize the criterion ⁇ B (n) ⁇ B (3) (n) ⁇ . It follows from the optimization that ⁇ C (n) ⁇ G ( p (n+1) ) ⁇ F 2 ⁇ C (n) ⁇ G ( p (n) ) ⁇ F 2 (12) and, therefore, ⁇ B (3) (n) ⁇ B (n+1) ⁇ F 2 ⁇ B (3) (n) ⁇ B (n) ⁇ F 2 (13) The Eckart-Young-Mirsky theorem dictates that ⁇ B (3) (n+1) ⁇ B (n+1) ⁇ F 2 ⁇ B (3) (n) ⁇ B (n+1) ⁇ F 2 , and so Algorithm A must converge.
- the criterion ⁇ B (n) ⁇ B (3) (n) ⁇ F 2 + ⁇ T+G(p) ⁇ F 2 may be minimized at each step of the algorithm.
- Algorithm B the revised version of the localization algorithm is provided below as “Algorithm B.” It should be noted that some of the steps of Algorithm B parallel those of Algorithm A, described above. The details of such steps are omitted in the following description of Algorithm B for purposes of brevity.
- Algorithm B converges quickly for reasonable settings of ⁇ .
- Algorithm B may be run by itself. However, it should be noted that the criterion does not minimize a natural squared error criterion, but rather a criterion that was selected to facilitate finding a global optimum. In a scenario where more accurate localization is needed, the global solution obtained with Algorithm B may be used (or with Algorithm A) as an initial value for certain iterative maximum-likelihood approaches that minimize a squared error criterion. As such, the overall algorithm may proceed as follows:
- FIG. 3 is a block diagram illustrating an example computing device 300 that is arranged for finding the location of sensors (e.g., microphones) with unknown internal delays based on a set of events (e.g., acoustic events) with unknown event time in accordance with one or more embodiments of the present disclosure.
- computing device 300 may be configured to iteratively run a localization algorithm that converges on the global solution for the unknown delay and event-time parameters, as described above.
- computing device 300 typically includes one or more processors 310 and system memory 320 .
- a memory bus 330 may be used for communicating between the processor 310 and the system memory 320 .
- processor 310 can be of any type including but not limited to a microprocessor ( ⁇ P), a microcontroller ( ⁇ C), a digital signal processor (DSP), or any combination thereof.
- Processor 310 may include one or more levels of caching, such as a level one cache 311 and a level two cache 312 , a processor core 313 , and registers 314 .
- the processor core 313 may include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof.
- a memory controller 315 can also be used with the processor 310 , or in some embodiments the memory controller 315 can be an internal part of the processor 310 .
- system memory 320 can be of any type including but not limited to volatile memory (e.g., RAM), non-volatile memory (e.g., ROM, flash memory, etc.) or any combination thereof.
- System memory 320 typically includes an operating system 321 , one or more applications 322 , and program data 324 .
- application 322 includes a localization algorithm 323 that is configured to determine locations of a set of microphones with unknown internal delays based on a set of acoustic events with unknown event time.
- the localization algorithm 323 may be configured to iteratively solve for the unknown delay and event-time parameters, and thereby converge to the global solution.
- Program Data 324 may include audio data 325 that is useful for measuring the arrival times of a sufficient set of acoustic events at a set of devices audio input devices 120 as shown in FIG. 1 ).
- application 322 can be arranged to operate with program data 324 on an operating system 321 such that the localization algorithm 323 uses the audio data 325 to generate estimates for the internal delays and the acoustic event times, which may be used to construct a matrix representative of a trial right-hand side for equation (11), and then iteratively run to converge to the global solution, as described above.
- Computing device 300 can have additional features and/or functionality, and additional interfaces to facilitate communications between the basic configuration 301 and any required devices and interfaces.
- a bus/interface controller 340 can be used to facilitate communications between the basic configuration 301 and one or more data storage devices 350 via a storage interface bus 341 .
- the data storage devices 350 can be removable storage devices 351 , non-removable storage devices 352 , or any combination thereof.
- removable storage and non-removable storage devices include magnetic disk devices such as flexible disk drives and hard-disk drives (HDD), optical disk drives such as compact disk (CD) drives or digital versatile disk (DVD) drives, solid state drives (SSD), tape drives and the like.
- Example computer storage media can include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, and/or other data.
- Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 300 . Any such computer storage media can be part of computing device 300 .
- Computing device 300 can also include an interface bus 342 for facilitating communication from various interface devices (e.g., output interfaces, peripheral interfaces, communication interfaces, etc.) to the basic configuration 301 via the bus/interface controller 340 .
- Example output devices 360 include a graphics processing unit 361 and an audio processing unit 362 , either or both of which can be configured to communicate to various external devices such as a display or speakers via one or more A/V ports 363 .
- Example peripheral interfaces 370 include a serial interface controller 371 or a parallel interface controller 372 , which can be configured to communicate with external devices such as input devices (e.g., keyboard, mouse, pen, voice input device, touch input device, etc.) or other peripheral devices (e.g., printer, scanner, etc.) via one or more I/O ports 373 .
- input devices e.g., keyboard, mouse, pen, voice input device, touch input device, etc.
- other peripheral devices e.g., printer, scanner, etc.
- An example communication device 380 includes a network controller 381 , which can be arranged to facilitate communications with one or more other computing devices 390 over a network communication (not shown) via one or more communication ports 382 .
- the communication connection is one example of a communication media.
- Communication media may typically be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media.
- a “modulated data signal” can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.
- communication media can include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared (IR) and other wireless media.
- RF radio frequency
- IR infrared
- computer readable media can include both storage media and communication media.
- Computing device 300 can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
- a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
- PDA personal data assistant
- Computing device 300 can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.
- ASICs Application Specific Integrated Circuits
- FPGAs Field Programmable Gate Arrays
- DSPs digital signal processors
- ASICs Application Specific Integrated Circuits
- FPGAs Field Programmable Gate Arrays
- DSPs digital signal processors
- some aspects of the embodiments described herein, in whole or in part, can be equivalently implemented in integrated circuits, as one or more computer programs running on one or more computers (e.g., as one or more programs running on one or more computer systems), as one or more programs running on one or more processors (e.g., as one or more programs running on one or more microprocessors), as firmware, or as virtually any combination thereof.
- processors e.g., as one or more programs running on one or more microprocessors
- firmware e.g., as one or more programs running on one or more microprocessors
- designing the circuitry and/or writing the code for the software and/or firmware would be well within the skill of one of skilled in the art in light of the present disclosure.
- Examples of a signal-bearing medium include, but are not limited to, the following; a recordable-type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission-type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).
- a recordable-type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.
- a transmission-type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).
- a typical data processing system generally includes one or more of a system unit housing, a video display device, a memory such as volatile and non-volatile memory, processors such as microprocessors and digital signal processors, computational entities such as operating systems, drivers, graphical user interfaces, and applications programs, one or more interaction devices, such as a touch pad or screen, and/or control systems including feedback loops and control motors (e.g., feedback for sensing position and/or velocity; control motors for moving and/or adjusting components and/or quantities).
- a typical data processing system may be implemented utilizing any suitable commercially available components, such as those typically found in data computing/communication and/or network computing/communication systems.
Abstract
Description
∥x i −a j ∥=t ij −d i−τj, (1)
where tij is the measured time of arrival of acoustic event j at sensor i. The objective is to compute the xi and the di from a set of equations generated by a number of acoustic events. For a sufficient number of acoustic events and a sufficient number of sensors, the system is overdetermined. In practice there are measurement errors. Therefore, it is natural to minimize the sum of the squared errors, Σi,jεij, where the scalar error εij is defined as
∥x i −a j ∥=t ij −d i−τj+εij. (2)
By stacking all εij into a vector ε, and if ε is assumed to have a Gaussian distribution, then minimizing the squared error is the same as maximizing the likelihood of ε.
acoustic events are needed.
x i T x i−2x i T a j +a j T a j =t ij 2 +d i 2+τj 2−2t ij d i−2t ijτj+2d iτj (4)
x i T x i −x 1 T x 1−2(x i −x 1)T a j =t ij 2 −t 1j 2 +d i 2 −d 1 2−2t ij d i+2t 1j d 1−2τj(t ij −t 1j)+2τj(d i −d 1) (5)
Subtracting equation (5) for j=1 from the general form of equation (5) gives:
Simplifying gives the following:
the (I−1)×3 matrix
and the (I−1)×(J−1) matrix
−2XA T =T+G(p) (11)
where G(p) is a nonlinear matrix function of p. As the (I−1)×(J−1) matrix XAT has rank three, the right-hand side T+G(p) must also have rank three, and this can be used to determine the unknown di and τj: the aim is to determine a rank-three approximation of T+G(p). This problem is generally referred to as a structured low-rank approximation (SLRA) problem. The particular example presented above is a non-linear SLRA problem, which implies that a limited amount of theory exists. However, as will be described in greater detail below, the present disclosure provides an iterative approximation algorithm.
is the singular-value decomposition of B.
-
- 1. Measure {tij}iε1 . . . J, jε1 . . . J;
where d(n+1) is an I+1 vector of di and τ(n+1) is a (J−1)×1 vector of τj (e.g., τ=[τ2 (n+1), . . . , τJ (n+1)]), and where γ is the stacking of the (I−1)(J−1)×1 matrix dτT in a vector.
∥C (n) −G(p (n+1))∥F 2 ≦∥C (n) −G(p (n))∥F 2 (12)
and, therefore,
∥B (3) (n) −B (n+1)∥F 2 ≦∥B (3) (n) −B (n)∥F 2 (13)
The Eckart-Young-Mirsky theorem dictates that ∥B(3) (n+1)−B(n+1)∥F 2≦∥B(3) (n)−B(n+1)∥F 2, and so Algorithm A must converge.
∥B (n) −B (3) (n)∥F 2 =∥T+G(p)−B (3) (n)∥F 2 (14)
Another term that moves the p(n) vector into the region where the solution is known to be. From the left-hand side of equation (11) it is clear that components of B(n)=T+G(p) must be reasonably small: the solution should be near the origin. This implies that the Frobenius norm ∥T+G(p)∥F 2 should be reasonably small. Therefore, the criterion ∥B(n)−B(3) (n)∥F 2+λ∥T+G(p)∥F 2 may be minimized at each step of the algorithm. The criterion at each step is then
η(n) =∥T+G(p)−B (3) (n)∥F 2+λ∥F 2 +λ∥T+G(p)∥F 2 (15)
and stack the elements of T in t.
Claims (18)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/746,333 US9086475B2 (en) | 2013-01-22 | 2013-01-22 | Self-localization for a set of microphones |
PCT/US2014/012458 WO2014116645A1 (en) | 2013-01-22 | 2014-01-22 | Self-localization of a set of microphones |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/746,333 US9086475B2 (en) | 2013-01-22 | 2013-01-22 | Self-localization for a set of microphones |
Publications (2)
Publication Number | Publication Date |
---|---|
US20140204716A1 US20140204716A1 (en) | 2014-07-24 |
US9086475B2 true US9086475B2 (en) | 2015-07-21 |
Family
ID=50102208
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/746,333 Active 2033-04-10 US9086475B2 (en) | 2013-01-22 | 2013-01-22 | Self-localization for a set of microphones |
Country Status (2)
Country | Link |
---|---|
US (1) | US9086475B2 (en) |
WO (1) | WO2014116645A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11968268B2 (en) | 2019-07-30 | 2024-04-23 | Dolby Laboratories Licensing Corporation | Coordination of audio devices |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9086475B2 (en) * | 2013-01-22 | 2015-07-21 | Google Inc. | Self-localization for a set of microphones |
JP6488492B2 (en) * | 2014-08-01 | 2019-03-27 | 本田技研工業株式会社 | Sound processing apparatus and sound processing method |
WO2018064410A1 (en) * | 2016-09-29 | 2018-04-05 | Dolby Laboratories Licensing Corporation | Automatic discovery and localization of speaker locations in surround sound systems |
JP6916130B2 (en) * | 2018-03-02 | 2021-08-11 | 株式会社日立製作所 | Speaker estimation method and speaker estimation device |
CN111060875B (en) * | 2019-12-12 | 2022-07-15 | 北京声智科技有限公司 | Method and device for acquiring relative position information of equipment and storage medium |
US11774540B2 (en) * | 2021-04-09 | 2023-10-03 | LouStat Technologies, LLC | Systems and methods for enhancing location of game in the field |
CN114779168A (en) * | 2022-04-21 | 2022-07-22 | 上海炉石信息科技有限公司 | Automatic positioning method and device for equipment array and storage medium |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20080170717A1 (en) * | 2007-01-16 | 2008-07-17 | Microsoft Corporation | Energy-based sound source localization and gain normalization |
US20140204716A1 (en) * | 2013-01-22 | 2014-07-24 | Google Inc. | Self-localization for a set of microphones |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DE102007051615B4 (en) * | 2007-10-24 | 2012-09-13 | Gesellschaft zur Förderung angewandter Informatik e.V. | Method and arrangement for determining the relative position of microphones and a corresponding computer program and a corresponding computer-readable storage medium |
-
2013
- 2013-01-22 US US13/746,333 patent/US9086475B2/en active Active
-
2014
- 2014-01-22 WO PCT/US2014/012458 patent/WO2014116645A1/en active Application Filing
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20080170717A1 (en) * | 2007-01-16 | 2008-07-17 | Microsoft Corporation | Energy-based sound source localization and gain normalization |
US20140204716A1 (en) * | 2013-01-22 | 2014-07-24 | Google Inc. | Self-localization for a set of microphones |
WO2014116645A1 (en) * | 2013-01-22 | 2014-07-31 | Google Inc. | Self-localization of a set of microphones |
Non-Patent Citations (8)
Title |
---|
M. Crocco et al., "A Bilinear Approach to the Position Self-Calibration of Multiple Sensors", IEEE Transactions on Signal Processing, vol. 60, No. 2, Feb. 2012. |
M. Crocco et al., "A Closed Form Solution to the Microphone Position Self-Calibration Problem", IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Mar. 2012. |
Pasi Pertila et al., "Closed-Form Self-Localization of Asynchronous Microphone Arrays", 2011 Joint Workshop on Hands-Free Speech Communication and Microphone Arrays, IEEE, May 30, 2011-Jun. 1, 2011, pp. 139-144. |
Pertila et al.; Closed-Form Self-Localization of Asynchronous Microphone Arrays; Jun. 2011; pp. 139-144. * |
R. Biswas et al. "A Passive Approach to Sensor Network Localization", IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), vol. 2, Sep. 2004. |
Raykar et al.; Position Calibration of Microphones and Loudspeakers in Distributed Computing Platforms; Jan. 2005; pp. 70-83. * |
V. C. Raykar et al., "Position Calibration of Microphones and Loudspeakers in Distributed Computing Platforms", IEEE Transactions on Speech and Audio Processing, vol. 13, No. 1, Jan. 2005. |
Y. Weiss et al., "Affine Structure From Sound", Advances in Neural Information Processing Systems 18, pp. 1353-1360, (2006). |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11968268B2 (en) | 2019-07-30 | 2024-04-23 | Dolby Laboratories Licensing Corporation | Coordination of audio devices |
Also Published As
Publication number | Publication date |
---|---|
US20140204716A1 (en) | 2014-07-24 |
WO2014116645A1 (en) | 2014-07-31 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9086475B2 (en) | Self-localization for a set of microphones | |
US9488716B2 (en) | Microphone autolocalization using moving acoustic source | |
Hennecke et al. | Towards acoustic self-localization of ad hoc smartphone arrays | |
EP3210391B1 (en) | Reverberation estimator | |
Velasco et al. | TDOA matrices: Algebraic properties and their application to robust denoising with missing data | |
Schwartz et al. | Speaker tracking using recursive EM algorithms | |
US8553904B2 (en) | Systems and methods for performing sound source localization | |
US20160073198A1 (en) | Spatial audio apparatus | |
Dorfan et al. | Tree-based recursive expectation-maximization algorithm for localization of acoustic sources | |
US8682144B1 (en) | Method for synchronizing multiple audio signals | |
CN105794226A (en) | Estimating a room impulse response for acoustic echo cancelling | |
Ampeliotis et al. | Low complexity multiple acoustic source localization in sensor networks based on energy measurements | |
Larsson et al. | Optimal trilateration is an eigenvalue problem | |
Yang et al. | Personalizing head related transfer functions for earables | |
Yan et al. | TDOA-based source collaborative localization via semidefinite relaxation in sensor networks | |
Åström et al. | Extension of time-difference-of-arrival self calibration solutions using robust multilateration | |
Cobos et al. | Wireless acoustic sensor networks and applications | |
Astapov et al. | Simplified acoustic localization by linear arrays for wireless sensor networks | |
US9307335B2 (en) | Device for estimating placement of physical objects | |
US10136235B2 (en) | Method and system for audio quality enhancement | |
Hu et al. | Geometry calibration for acoustic transceiver networks based on network newton distributed optimization | |
Khalaf-Allah | An extended closed-form least-squares solution for three-dimensional hyperbolic geolocation | |
EP4354904A1 (en) | Interpolation of finite impulse response filters for generating sound fields | |
Tegler et al. | Sensor node calibration in presence of a dominant reflective plane | |
CN114375038B (en) | Positioning method, apparatus, base station, storage medium and computer program product |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:KLEIJN, WILLEM BASTIAAN;GAUBITCH, NIKOLAY D.;HEUSDENS, RICHARD;SIGNING DATES FROM 20140123 TO 20140124;REEL/FRAME:032107/0341 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044334/0466Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |