JP2021536067A - Biased data rejection using machine learning models - Google Patents
Biased data rejection using machine learning models Download PDFInfo
- Publication number
- JP2021536067A JP2021536067A JP2021513193A JP2021513193A JP2021536067A JP 2021536067 A JP2021536067 A JP 2021536067A JP 2021513193 A JP2021513193 A JP 2021513193A JP 2021513193 A JP2021513193 A JP 2021513193A JP 2021536067 A JP2021536067 A JP 2021536067A
- Authority
- JP
- Japan
- Prior art keywords
- weight
- data set
- training
- training data
- cluster
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/23—Clustering techniques
- G06F18/232—Non-hierarchical techniques
- G06F18/2321—Non-hierarchical techniques using statistics or function optimisation, e.g. modelling of probability density functions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/24—Classification techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
Abstract
機械学習モデル（３００）を使用して偏りのあるデータを拒否するための方法（５００）は、偏りのない既知のデータ母集団を含むクラスタ訓練データセット（１３０）を受信するステップと、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセットをクラスタ（２１２）に分割するように、クラスタ化モデル（２１１）を訓練するステップとを含む。クラスタ訓練データセットの各クラスタはクラスタ重み（２１４）を含む。方法はまた、機械学習モデルのための訓練データセット（３０２）を受信するステップと、クラスタ化モデルに基づいて、機械学習モデルのための訓練データセットに対応する訓練データセット重み（２１８）を生成するステップとを含む。方法はまた、訓練データセット重みの各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節するステップと、調節された訓練データセットを、偏りのない訓練データセット（２０６）として、機械学習モデルに提供するステップとを含む。The method (500) for rejecting biased data using the machine learning model (300) is a step of receiving a cluster training dataset (130) containing a known unbiased data population and a biased method. It involves training the clustering model (211) to divide the received cluster training dataset into clusters (212) based on the data characteristics of no known data population. Each cluster in the cluster training dataset contains a cluster weight (214). The method also generates a training data set weight (218) corresponding to the training data set for the machine learning model based on the step of receiving the training data set (302) for the machine learning model and the clustering model. Including steps to do. The method also includes steps to adjust each training data set weight of the training data set weights to match their respective cluster weights, and the adjusted training data set as an unbiased training data set (206). Includes steps to provide for the training model.
Description
技術分野
この開示は、機械学習モデルを使用して偏りのあるデータを拒否することに関する。
Technical Area This disclosure relates to rejecting biased data using machine learning models.
背景
一般的に言えば、偏りとは、パラメータを過大評価または過小評価する統計値の傾向である。この点で、データの収集およびデータの分析は典型的には、何らかの固有の偏りを含む。これらの偏りは、収集および分析の方法、または、当該収集および分析を行なうエンティティ（主体）に起因する場合がある。たとえば、人間によって設計され行なわれたデータ研究が、特定の仮説、人間の設計制約（たとえば人間の能力）、サンプリング制約などを提供する場合がある。これらの要素を提供することにより、当該研究のデータ結果は、さまざまなサンプリング誤差、測定誤差、または、当該研究のための目標母集団を表わしていないサンプルにより広範に基づいた誤差を含む可能性がある。コンピュータ処理は、技術が人間の活動とは比べものにならない速度でデータを収集および分析することを可能にするため、データ処理手法は、偏りの問題を同等に克服しなければならない。さもなければ、特にバルクデータのためのデータ処理は、偏りの問題を増幅して、人間の活動によって生じる偏りとは同様に比べものにならない結果を生み出すおそれがある。
Background Generally speaking, bias is the tendency of statistics to overestimate or underestimate a parameter. In this regard, data collection and analysis typically involves some inherent bias. These biases may be due to the method of collection and analysis or the entity (subject) performing the collection and analysis. For example, data studies designed and performed by humans may provide specific hypotheses, human design constraints (eg, human capabilities), sampling constraints, and so on. By providing these factors, the data results of the study may contain various sampling errors, measurement errors, or errors based more extensively on samples that do not represent the target population for the study. be. Data processing techniques must overcome the problem of bias equally, as computer processing allows technology to collect and analyze data at speeds that are unmatched by human activity. Otherwise, data processing, especially for bulk data, can amplify the problem of bias and produce results that are as incomparable to the bias caused by human activity.
概要
この開示の１つの局面は、機械学習モデルを使用して偏りのあるデータを拒否するための方法を提供する。方法は、データ処理ハードウェアで、クラスタ訓練データセットを受信するステップを含み、クラスタ訓練データセットは偏りのない既知のデータ母集団（known unbiased population of data）を含む。方法はまた、データ処理ハードウェアが、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセットをクラスタに分割するように、クラスタ化モデルを訓練するステップを含む。クラスタ訓練データセットの各クラスタはクラスタ重みを含む。方法はさらに、データ処理ハードウェアで、機械学習モデルのための訓練データセットを受信するステップと、データ処理ハードウェアが、クラスタ化モデルに基づいて、機械学習モデルのための訓練データセットに対応する訓練データセット重みを生成するステップとを含む。方法はまた、データ処理ハードウェアが、訓練データセット重みの各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節するステップと、データ処理ハードウェアが、調節された訓練データセットを、偏りのない訓練データセットとして、機械学習モデルに提供するステップとを含む。
Summary One aspect of this disclosure provides a way to reject biased data using machine learning models. The method comprises the steps of receiving a cluster training dataset on data processing hardware, the cluster training dataset comprising an unbiased known population of data. The method also includes training the clustering model so that the data processing hardware divides the received cluster training dataset into clusters based on the data characteristics of a known, unbiased data population. Each cluster in the cluster training dataset contains a cluster weight. The method further corresponds to the step of receiving the training dataset for the machine learning model in the data processing hardware and the data processing hardware corresponding to the training dataset for the machine learning model based on the clustered model. Includes steps to generate training dataset weights. The method also includes steps in which the data processing hardware adjusts each training dataset weight of the training dataset weights to match their respective cluster weights, and the data processing hardware adjusts the adjusted training dataset. Includes steps to provide to the machine learning model as an unbiased training data set.
この開示の実現化例は、以下のオプションの機能のうちの１つ以上を含んでいてもよい。いくつかの実現化例では、調節された訓練データセットを偏りのない訓練データセットとして機械学習モデルに提供するステップは、偏りのない訓練データセットを用いて機械学習モデルを訓練するステップを含む。方法は、データ処理ハードウェアが、偏りのない訓練データセットを用いて機械学習モデルを訓練するステップを含んでいてもよく、または、データ処理ハードウェアで、少なくとも１つのそれぞれのデータ特性を含むサンプルデータセットを受信するステップを含んでいてもよい。ここで、方法はまた、データ処理ハードウェアが、訓練された機械学習モデルを使用して、受信されたサンプルデータセットに基づいた、偏りのない予測値を生成するステップを含んでいてもよい。 The embodiment of this disclosure may include one or more of the following optional features. In some implementations, the step of providing a tuned training data set to the machine learning model as an unbiased training data set comprises training the machine learning model with the unbiased training data set. The method may include steps in which the data processing hardware trains the machine learning model with an unbiased training dataset, or in the data processing hardware, a sample containing at least one of the respective data characteristics. It may include a step of receiving a data set. Here, the method may also include a step in which the data processing hardware uses a trained machine learning model to generate unbiased predictions based on the sample dataset received.
いくつかの例では、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節するステップは、各訓練データセット重みについて、共通のデータ特性に基づいて、訓練データセット重みをそれぞれのクラスタ重みと整合させるステップと、訓練データセット重みがそれぞれのクラスタ重みと整合するまで、訓練データセットからデータを除去するステップとを含む。他の例では、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節するステップは、各訓練データセット重みについて、共通のデータ特性に基づいて、訓練データセット重みをそれぞれのクラスタ重みと整合させるステップと、各訓練データセット重みがそれぞれのクラスタ重みと整合するまで、訓練データセットからデータを複製するステップとを含む。 In some examples, the step of adjusting each training data set weight to match its own cluster weight is that for each training data set weight, the training data set weight is based on common data characteristics for each cluster. It includes a step to match the weights and a step to remove the data from the training data set until the training data set weights match the respective cluster weights. In another example, the step of adjusting each training data set weight to match its own cluster weight is that for each training data set weight, the training data set weight is based on the common data characteristics of each cluster weight. Includes a step of matching with and a step of replicating data from the training data set until each training data set weight matches its own cluster weight.
いくつかの構成では、各訓練データセット重みについて、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節するステップは、共通のデータ特性に基づいて、訓練データセット重みをクラスタ重みと整合させるステップを含む。訓練データセット重みがそれぞれのクラスタ重みよりも小さい場合、方法は、訓練データセット重みに対応する訓練データに対する機械学習モデルの訓練を増加させることを示す重要性重みを関連付けるステップを含んでいてもよい。それに加えて、またはそれに代えて、各訓練データセット重みについて、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節するステップは、共通のデータ特性に基づいて、訓練データセット重みをクラスタ重みと整合させるステップを含んでいてもよい。ここで、訓練データセット重みがそれぞれのクラスタ重みよりも大きい場合、方法は、訓練データセット重みに対応する訓練データに対する機械学習モデルの訓練を減少させることを示す重要性重みを関連付けるステップを含んでいてもよい。 In some configurations, for each training dataset weight, the step of adjusting each training dataset weight to match its own cluster weight is based on common data characteristics, and the training dataset weight is called the cluster weight. Includes matching steps. If the training data set weights are less than the respective cluster weights, the method may include associating importance weights that indicate increased training of the machine learning model for the training data corresponding to the training data set weights. .. In addition to or instead, for each training dataset weight, the step of adjusting each training dataset weight to be consistent with its respective cluster weight is based on common data characteristics. It may include a step to match the cluster weight. Here, if the training data set weights are greater than the respective cluster weights, the method includes associating a materiality weight indicating that the training of the machine learning model is reduced for the training data corresponding to the training data set weights. You may.
いくつかの実現化例では、訓練データセット重みの各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節するステップは、各訓練データセット重みについて、共通のデータ特性に基づいて、訓練データセット重みをそれぞれのクラスタ重みと整合させるステップを含む。訓練データセット重みがそれぞれのクラスタ重みよりも小さい場合、方法は、訓練データセット重みに対応する訓練データに対する機械学習モデルの訓練を増加させることを示す重要性重みを関連付けるステップを含み、訓練データセット重みがそれぞれのクラスタ重みよりも大きい場合、方法は、訓練データセット重みに対応する訓練データに対する機械学習モデルの訓練を減少させることを示す重要性重みを関連付けるステップを含む。 In some implementations, the step of adjusting each training dataset weight to match its cluster weight is training for each training dataset weight based on common data characteristics. Includes steps to match the dataset weights with their respective cluster weights. If the training data set weights are less than the respective cluster weights, the method includes associating a materiality weight that indicates that the training of the machine training model is increased for the training data corresponding to the training data set weights. If the weights are greater than the respective cluster weights, the method involves associating a materiality weight that indicates that the training of the machine training model is reduced for the training data corresponding to the training data set weights.
いくつかの例では、クラスタ化モデルを訓練する場合、方法は、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセットをクラスタに分割するステップを含む。この例では、偏りのない既知のデータ母集団のデータ特性に基づいたクラスタの各クラスタについて、方法は、偏りのない既知のデータ母集団のサイズに対するそれぞれのクラスタのサイズの比に基づいて、クラスタ化モデルの各クラスタについてのクラスタ重みを判定するステップを含む。いくつかの実現化例では、教師なし機械学習アルゴリズムが、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセットをクラスタに分割する。 In some examples, when training a clustering model, the method involves splitting the received cluster training dataset into clusters based on the data characteristics of a known, unbiased data population. In this example, for each cluster of clusters based on the data characteristics of the known unbiased data population, the method is based on the ratio of the size of each cluster to the size of the known unbiased data population. Includes a step to determine the cluster weight for each cluster in the model. In some implementations, an unsupervised machine learning algorithm divides the received cluster training dataset into clusters based on the data characteristics of a known, unbiased data population.
この開示の別の局面は、機械学習モデルを使用して偏りのあるデータを拒否するためのシステムを提供する。システムは、データ処理ハードウェアと、データ処理ハードウェアと通信しているメモリハードウェアとを含む。メモリハードウェアは、データ処理ハードウェア上で実行されるとデータ処理ハードウェアに動作を行なわせる命令を格納している。動作は、クラスタ訓練データセットを受信することを含み、クラスタ訓練データセットは偏りのない既知のデータ母集団を含む。動作はまた、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセットをクラスタに分割するように、クラスタ化モデルを訓練することを含み、クラスタ訓練データセットの各クラスタはクラスタ重みを含む。動作はさらに、機械学習モデルのための訓練データセットを受信することと、クラスタ化モデルに基づいて、機械学習モデルのための訓練データセットに対応する訓練データセット重みを生成することとを含む。動作はまた、訓練データセット重みの各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節することと、調節された訓練データセットを、偏りのない訓練データセットとして、機械学習モデルに提供することとを含む。 Another aspect of this disclosure provides a system for rejecting biased data using machine learning models. The system includes data processing hardware and memory hardware communicating with the data processing hardware. The memory hardware stores instructions that cause the data processing hardware to perform operations when executed on the data processing hardware. The operation involves receiving a cluster training dataset, which includes a known unbiased data population. Behavior also includes training a clustering model to divide the received cluster training data set into clusters based on the data characteristics of a known, unbiased data population, each of the cluster training data sets. The cluster contains the cluster weight. The behavior further includes receiving the training dataset for the machine learning model and generating the training dataset weights corresponding to the training dataset for the machine learning model based on the clustered model. The behavior also adjusts each training data set weight of the training data set weights to match their respective cluster weights, and turns the adjusted training data set into a machine learning model as an unbiased training data set. Including providing.
この局面は、以下のオプションの機能のうちの１つ以上を含んでいてもよい。いくつかの構成では、調節された訓練データセットを偏りのない訓練データセットとして機械学習モデルに提供する動作は、偏りのない訓練データセットを用いて機械学習モデルを訓練することを含む。動作はまた、偏りのない訓練データセットを用いて機械学習モデルを訓練することと、少なくとも１つのそれぞれのデータ特性を含むサンプルデータセットを受信することと、機械学習モデルを使用して、受信されたサンプルデータセットに基づいた、偏りのない予測値を生成することとを含んでいてもよい。 This aspect may include one or more of the following optional features: In some configurations, the behavior of providing a tuned training data set to a machine learning model as an unbiased training data set involves training the machine learning model with an unbiased training data set. Behavior is also received using a machine learning model, training a machine learning model with an unbiased training dataset, and receiving a sample dataset containing at least one of each data characteristic. It may include generating unbiased predictions based on the sample data set.
いくつかの実現化例では、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節する動作はさらに、各訓練データセット重みについて、共通のデータ特性に基づいて、訓練データセット重みをそれぞれのクラスタ重みと整合させることと、訓練データセット重みがそれぞれのクラスタ重みと整合するまで、訓練データセットからデータを除去することとを含む。他の例では、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節する動作は、各訓練データセット重みについて、共通のデータ特性に基づいて、訓練データセット重みをそれぞれのクラスタ重みと整合させることと、各訓練データセット重みがそれぞれのクラスタ重みと整合するまで、訓練データセットからデータを複製することとを含む。 In some implementations, the action of adjusting each training data set weight to be consistent with its respective cluster weights also sets the training data set weights for each training data set weight based on common data characteristics. It involves aligning with each cluster weight and removing data from the training data set until the training data set weight is consistent with each cluster weight. In another example, the action of adjusting each training data set weight to match its own cluster weight is that for each training data set weight, the training data set weight is based on common data characteristics, and each cluster weight. Containing with and replicating data from the training data set until each training data set weight is consistent with each cluster weight.
いくつかの例では、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節する動作は、各訓練データセット重みについて、共通のデータ特性に基づいて、訓練データセット重みをクラスタ重みと整合させることを含む。この例では、それぞれの訓練データセット重みがそれぞれのクラスタ重みよりも小さい場合、動作は、訓練データセット重みに対応する訓練データに対する機械学習モデルの訓練を増加させることを示す重要性重みを関連付けることを含む。他の例では、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節する動作は、共通のデータ特性に基づいて、訓練データセット重みをクラスタ重みと整合させることを含んでいてもよい。この例では、それぞれの訓練データセット重みが対応するクラスタ重みよりも大きい場合、動作は、訓練データセット重みに対応する訓練データに対する機械学習モデルの訓練を減少させることを示す重要性重みを関連付けることを含む。 In some examples, the action of adjusting each training dataset weight to match its own cluster weight is based on common data characteristics for each training dataset weight, with the training dataset weight being the cluster weight. Includes matching. In this example, if each training data set weight is less than each cluster weight, the behavior correlates an importance weight that indicates that it increases the training of the machine learning model for the training data corresponding to the training data set weight. including. In another example, the action of adjusting each training dataset weight to match its own cluster weight may include aligning the training dataset weight with the cluster weight based on common data characteristics. good. In this example, if each training data set weight is greater than the corresponding cluster weight, the behavior correlates an importance weight that indicates that the training of the machine learning model is reduced for the training data corresponding to the training data set weight. including.
それに加えて、またはそれに代えて、各訓練データセット重みを、それぞれのクラスタ重みと整合するように調節する動作は、各訓練データセット重みについて、共通のデータ特性に基づいて、訓練データセット重みをそれぞれのクラスタ重みと整合させることを含んでいてもよい。ここで、それぞれの訓練データセット重みがそれぞれのクラスタ重みよりも小さい場合、訓練データセット重みに対応する訓練データに対する機械学習モデルの訓練を増加させることを示す重要性重みを関連付け、訓練データセット重みがそれぞれのクラスタ重みよりも大きい場合、訓練データセット重みに対応する訓練データに対する機械学習モデルの訓練を減少させることを示す重要性重みを関連付ける。 In addition to or instead, the action of adjusting each training dataset weight to be consistent with its respective cluster weight is that for each training dataset weight, the training dataset weight is based on common data characteristics. It may include matching with each cluster weight. Here, if each training data set weight is smaller than each cluster weight, we correlate the importance weights that indicate that the training of the machine training model is increased for the training data corresponding to the training data set weight, and the training data set weight. If is greater than each cluster weight, we correlate the importance weights that indicate that the training of the machine learning model is reduced for the training data corresponding to the training data set weights.
いくつかの構成では、クラスタ化モデルを訓練する動作は、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセットをクラスタに分割することと、偏りのない既知のデータ母集団のデータ特性に基づいたクラスタの各クラスタについて、偏りのない既知のデータ母集団のサイズに対するそれぞれのクラスタのサイズの比に基づいて、クラスタ化モデルの各クラスタについてのクラスタ重みを判定することとを含んでいてもよい。いくつかの例では、教師なし機械学習アルゴリズムが、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセットをクラスタに分割する。 In some configurations, the behavior of training a clustered model is to divide the received cluster training data set into clusters based on the data characteristics of a known, unbiased data population, and known, unbiased. For each cluster of clusters based on the data characteristics of the data population, determine the cluster weight for each cluster in the clustering model based on the ratio of the size of each cluster to the size of the known data population without bias. It may include things. In some examples, an unsupervised machine learning algorithm divides a received cluster training dataset into clusters based on the data characteristics of a known, unbiased data population.
この開示の１つ以上の実現化例の詳細が、添付図面および以下の説明において述べられる。他の局面、特徴、および利点は、説明および図面から、および請求項から明らかになるであろう。 Details of one or more implementations of this disclosure are given in the accompanying drawings and in the following description. Other aspects, features, and advantages will be apparent from the description and drawings, and from the claims.
図面の説明 Description of the drawing
さまざまな図面における同じ参照符号は、同じ要素を示す。 The same reference numerals in different drawings indicate the same elements.
詳細な説明
図１は、機械学習環境１０の一例である。機械学習環境１０は一般に、ネットワーク１２０を介してアクセス可能なリソース１１０を有する分散型システム１００（たとえば、クラウド環境などのリモートシステム）と、偏り拒否モデル２００と、機械学習モデル３００とを含む。リソース１１０は、偏り拒否モデル２００および／または機械学習モデル３００を訓練する際に使用するために、ならびに、ここに開示される機械学習機能を行なうために、偏り拒否モデル２００および／または機械学習モデル３００にアクセス可能である。分散型システム１００は、偏り拒否モデル２００および／または機械学習モデル３００を動作させることができるコンピューティングリソース（たとえばリソース１１０）を有する任意のコンピュータ処理システムであってもよい。いくつかの例では、偏り拒否モデル２００および／または機械学習モデル３００は、ネットワーク１２０を介して分散型システム１００にアクセス可能である、または他の態様で分散型システム１００と通信しているデバイス上で動作する。たとえば、デバイスは、分散型システム１００に関連付けられたウェブベースのアプリケーションを実行してもよい。
Detailed Explanation FIG. 1 is an example of a
一般に、分散型システム１００のリソース１１０は、ハードウェアリソース１１０ｈ、１１０ｈ１−ｉと、ソフトウェアリソース１１０ｓ、１１０ｓ１−ｉとを含んでいてもよい。ハードウェアリソース１１０ｈは、データ処理ハードウェア１１２と、メモリハードウェア１１４とを含む。ソフトウェアリソース１１０ｓは、ソフトウェアアプリケーション、ソフトウェアサービス、アプリケーションプログラミングインターフェイス（application programming interface：ＡＰＩ）などを含んでいてもよい。ソフトウェアリソース１１０ｓは、ハードウェアリソース１１０ｈ上に存在して（たとえば、メモリハードウェア１１４に格納されて）いてもよく、または、データ処理ハードウェア１１２上で実行される命令を含んでいてもよい。
In general, the
ソフトウェアアプリケーション（すなわち、ソフトウェアリソース１１０ｓ）とは、コンピューティングデバイスにタスクを行なわせるコンピュータソフトウェアを指していてもよい。いくつかの例では、ソフトウェアアプリケーションは、「アプリケーション」、「アプリ」、または「プログラム」と呼ばれてもよい。例示的なアプリケーションは、システム診断アプリケーション、システム管理アプリケーション、システム保守アプリケーション、文書処理アプリケーション、表計算アプリケーション、メッセージングアプリケーション、メディアストリーミングアプリケーション、ソーシャルネットワーキングアプリケーション、およびゲーミングアプリケーションを含むものの、それらに限定されない。 The software application (ie, software resource 110s) may refer to computer software that causes a computing device to perform a task. In some examples, software applications may be referred to as "applications," "apps," or "programs." Exemplary applications include, but are not limited to, system diagnostic applications, system management applications, system maintenance applications, document processing applications, table computing applications, messaging applications, media streaming applications, social networking applications, and gaming applications.
メモリハードウェア１１４は、プログラム（たとえば命令のシーケンス）またはデータ（たとえばプログラム状態情報）を、データ処理ハードウェア１１２による使用のために一時的または永続的に格納するために使用される物理デバイスであり得る非一時的メモリである。メモリハードウェア１１４は、揮発性および／または不揮発性アドレス可能半導体メモリであってもよい。不揮発性メモリの例は、フラッシュメモリおよび読出専用メモリ（read-only memory：ＲＯＭ）／プログラマブル読出専用メモリ（programmable read-only memory：ＰＲＯＭ）／消去可能プログラマブル読出専用メモリ（erasable programmable read-only memory：ＥＰＲＯＭ）／電子的消去可能プログラマブル読出専用メモリ（electronically erasable programmable read-only memory：ＥＥＰＲＯＭ）（たとえば、典型的にはブートプログラムなどのファームウェアのために使用される）、およびディスクまたはテープを含むものの、それらに限定されない。揮発性メモリの例は、ランダムアクセスメモリ（random access memory：ＲＡＭ）、ダイナミックランダムアクセスメモリ（dynamic random access memory：ＤＲＡＭ）、スタティックランダムアクセスメモリ（static random access memory：ＳＲＡＭ）、および相変化メモリ（phase change memory：ＰＣＭ）を含むものの、それらに限定されない。
図示された例では、偏り拒否モデル２００は、機械学習モデル３００に悪影響を及ぼさないように偏りの問題に対処するために、リソース１１０とともに動作する。言い換えれば、偏り拒否モデル２００は、偏りのあるデータを含む機械学習（machine learning：ＭＬ）訓練データセット３０２に基づいて機械学習モデル３００を訓練するのを防止するように構成される。これは、ＭＬ訓練データセット３０２に関連付けられているものの、当該偏りのあるデータが除去された、偏りのない訓練データセット２０６を、ＭＬモデル３００を訓練する際に使用するために生成／出力することによる。ＭＬ訓練データセット３０２内の偏りのあるデータに基づいて機械学習モデル３００を訓練するのを防止することによって、機械学習モデル３００は、当該偏りのあるデータによって影響されず、したがって、推論中に偏りのない予測値３１０（図３）を生成することができる。このため、偏り拒否モデル２００は、ＭＬモデル３００を訓練する際に使用するための偏りのない訓練データセット２０６を出力／生成することによって、ＭＬモデル３００を訓練する前にＭＬ訓練データセット３０２内の偏りのあるデータを除去／調節するフィルタに対応する。
In the illustrated example, the
図２Ａは、１番目の訓練段階２０２と、１番目の訓練段階２０２に続く２番目の偏り防止段階２０４との実行中の偏り拒否モデル２００を示す。訓練段階２０２中、偏り拒否モデル２００は、クラスタ訓練データセット１３０を受信し、クラスタ重み２１４を出力する。偏り防止段階２０４中、偏り拒否モデル２００は、ＭＬ訓練データセット３０２を受信し、訓練段階２０２から出力されたクラスタ重み２１４を使用して、ＭＬ訓練データセット３０２から偏りのあるデータが除去された、偏りのない訓練データセット２０６を出力する。
FIG. 2A shows a running
ここで、「重み」（たとえば、偏りクラスタ重み２１４、２１４ａ〜ｎ、および訓練データセット重み２１８、２１８ａ〜ｎ）という用語は、クラスタ化のプロセスから形成された独自のクラスタにマッピングする、比などの値を指す。母集団については、各クラスタは、母集団の一部に関していてもよく、このため、その一部の値は、クラスタ（たとえば、母集団のサブセット）に関連付けられた重みであってもよい。言い換えれば、母集団をサブセットにクラスタ化することによって、各サブセットは、母集団に対する特性（たとえば重み）を本質的に有する。より一般的には、偏りクラスタ２１２または訓練クラスタ２１６などのクラスタとは、人々に関する訓練データをグループ化するために使用され得る、当該人々のグループ化を指す。人々のグループ化は、自分の訓練データにおける連続的な範囲の変数値を共有する人々を含んでいてもよい（たとえば、２５〜２７才のアジア系女性についてのクラスタは、１人の２５才のアジア系女性での１つの訓練例と、１人の２６才のアジア系女性での別の訓練例と、この一組の値を共有する他の訓練例とを含み得る）。
Here, the term "weights" (eg,
他の実現化例では、クラスタは、自分の訓練データがクラスタ化アルゴリズム（たとえばクラスタ化モデル）によってクラスタ化される人々を含む。クラスタ化アルゴリズムは、人々（または人々の特性）の間の距離がより短いことに基づいて類似しているとアルゴリズムが考えるグループに、人々を入れる。より短い距離によってグループ化することは、多くの変数値がそれぞれの母集団において増加するにつれてクラスタの数が指数関数的に増加することを回避し得る。クラスタ化は、訓練データ（たとえば人々）間の距離を判定するために、重要な変数（たとえば偏り変数）および／または他の変数にしたがって行なわれてもよい。たとえば、クラスタ化は他の変数に基づいて行なわれるが、データをクラスタ化するための最終判定は、重要な変数（たとえば偏り変数）に基づいている。一例として、クラスタ化プロセスは、１８才および１９才の男性のオーストリア人およびドイツ人をともに単一のクラスタにグループ化する。なぜなら、それは、規定された測定基準（たとえば、使用言語、関連する関心事、ソーシャルネットワークでつながるかまたは同じ組織のメンバーである頻度）に基づいて、類似性（たとえば、互いの間のより短い距離）を認識するためである。広範囲の潜在的なクラスタ化アプローチを示す別の例として、クラスタ化プロセスは、（１）１８才のオーストリア人、（２）１８才のドイツ人、（３）１９才のオーストリア人、および（４）１９才のドイツ人というカテゴリーをカバーする４つの別個のグループを有し得る。 In another implementation example, a cluster includes people whose training data is clustered by a clustering algorithm (eg, a clustering model). A clustering algorithm puts people in a group that the algorithm considers to be similar based on the shorter distance between people (or their characteristics). Grouping by shorter distances can avoid an exponential increase in the number of clusters as many variable values increase in each population. Clustering may be performed according to important variables (eg, biased variables) and / or other variables to determine the distance between training data (eg, people). For example, clustering is based on other variables, but the final decision to cluster the data is based on important variables (eg, biased variables). As an example, the clustering process groups both Austrian and German men aged 18 and 19 into a single cluster. Because it is based on defined metrics (eg language used, related concerns, frequency of being connected by social networks or members of the same organization), similarities (eg shorter distances between each other). ). As another example of a wide range of potential clustering approaches, the clustering process consists of (1) 18-year-old Austrians, (2) 18-year-old Germans, (3) 19-year-old Austrians, and (4). ) You may have four separate groups covering the category of 19 year old Germans.
図２Ａをさらに参照して、訓練段階２０２中、偏り拒否モデル２００は、偏りのない既知のデータ母集団に対応するクラスタ訓練データセット１３０を受信する。偏りのない既知のデータ母集団は、偏りに敏感な変数（bias sensitive variable）の正確な確率分布を有する目標母集団であってもよい。偏りのない既知のデータ母集団を用いて、偏り拒否モデル２００は、偏りに敏感な変数に関連する不釣り合いなデータ量を有するデータを用いた訓練を回避する。偏りに敏感な変数とは、目標母集団のデータサンプルにおいて過大表現または過小表現されると、目標母集団のサンプリングからの偏りのある予測の可能性の増加をもたらす変数を指す。言い換えれば、偏りに敏感な変数の正確な表現からの若干のずれが、歪んだ予測分析をもたらす可能性がある。したがって、機械学習モデル３００などの機械学習モデルが、偏りに敏感な変数の正確な訓練データセットなしで構成される（すなわち訓練される）場合、機械学習モデルは、偏りのある予測、および偏りのあるコンピューティング分析論を本質的に生成するかもしれない。偏りに敏感な変数のいくつかの例は、人種、ジェンダー、性別、年齢、国籍、信仰している宗教、所属する政党、豊かさなどを含む。
Further referring to FIG. 2A, during the
いくつかの例では、目標母集団は、所与の変数または一組の変数についてのデータセット全体である。ここで、偏り拒否モデル２００および／または機械学習モデル３００は、目標母集団（たとえば、クラスタ訓練データセット１３０に対応する母集団）に対応して訓練されても、および／または予測を行なってもよい。基本的な一例として、機械学習モデル３００は、カリフォルニアの人口である目標母集団についての値を予測するように構成されてもよい。カリフォルニアの人口に関する予測を正確に行なうために、各モデル２００、３００は、カリフォルニアの人口に関連付けられたデータに基づいて訓練する。
In some examples, the target population is the entire data set for a given variable or set of variables. Here, the
受信されたクラスタ訓練データセット１３０に基づいて偏り拒否モデル２００を訓練した後で、偏り拒否モデル２００は、偏り防止段階２０４中に、ＭＬモデル３００を訓練する際に使用するために意図されたＭＬ訓練データセット３０２を調節するように構成される。ＭＬモデル３００を訓練する前にＭＬ訓練データセット３０２を調節することによって、偏り拒否モデル２００は、偏りのない訓練データセット２０６を生成し、偏りのない訓練データセット２０６をＭＬモデル３００に提供する。言い換えれば、偏り防止段階２０４中、偏り拒否モデル２００は、訓練段階２０２中のクラスタ訓練データセット１３０に基づく偏り拒否モデル２００の訓練に基づいて、（たとえば偏りのあるデータを潜在的に含み得る）ＭＬ訓練データセット３０２を、偏りのない訓練データセット２０６に変換する。いくつかの例では、偏り拒否モデル２００は、２つ以上のクラスタ訓練データセット１３０を用いて訓練する。たとえば、偏り拒否モデル２００は、新しいまたは更新されたクラスタ訓練データセット１３０への経時変化を連続的に勘案するように、当該クラスタ訓練データセット１３０に基づいて動的に訓練する。訓練段階２０２および偏り防止段階２０４は、連続的にまたは同時に実行されてもよく、またはそれら双方の何らかの組合せであってもよい。
After training the
図２Ｂは、訓練段階２０２中の偏り拒否モデル２００の一例を示す。ここで、偏り拒否モデル２００は、偏りのない既知のデータ母集団を含むクラスタ訓練データセット１３０を受信する。しかしながら、いくつかの実現化例では、偏り拒否モデル２００のアドミニストレータ、または偏り拒否モデル２００へのアクセスを有するユーザ（たとえば、特定の一組の偏り特徴を懸念するユーザ）などのエンティティが、偏りに敏感な変数に対応する偏り特徴を規定してもよい。ここで、偏り拒否モデル２００のエンティティまたは設計者は、偏り特徴および／または偏りに敏感な変数を偏り拒否モデル２００に供給しない。むしろ、偏り拒否モデル２００は、偏りのあるデータ、または偏りのないデータを認識するために、分割器２１０を介してクラスタモデル２１１を使用してクラスタ訓練データセット１３０をモデル化する。いくつかの構成では、クラスタ訓練データセット１３０は、目標母集団データセット全体を含む。たとえば、偏り拒否モデル２００は、米国についての人口統計データの完全なデータセットを、クラスタ訓練データセット１３０として受信してもよい。
FIG. 2B shows an example of the
偏り拒否モデル２００は、分割器２１０と、調節器２２０とを含む。分割器２１０は、クラスタモデル２１１（「クラスタ化モデル２１１」とも呼ばれる）を使用してデータセットをクラスタ２１２、２１２ａ〜ｎに分割するように構成される。訓練段階２０２中、分割器２１０は、偏りのない既知のデータ母集団のデータ特性（図２Ｂに「ＤＣａ〜ｎ」として示す）に基づいて、受信されたクラスタ訓練データセット１３０をクラスタ２１２、２１２ａ〜ｎに分割するように、クラスタ化モデル２１１を訓練する。簡潔にするために、これらのデータ特性は、クラスタ訓練データセット１３０に関連する目標母集団の少なくとも１つのそれぞれの偏りに敏感な変数を含む。言い換えれば、いくつかのクラスタ２１２は、データ特性としての少なくとも１つのそれぞれの偏りに敏感な変数に関連付けられた偏りクラスタであるかもしれず、一方、他のクラスタ２１２は、偏りに敏感な変数に関連していないデータ特性を識別する。いくつかの実現化例では、クラスタモデル２１１は、クラスタモデル２１１が訓練段階２０２中に受信されたクラスタ訓練データセット１３０に基づいて教師なし学習を行なうように、クラスタ化アルゴリズムを含む。教師なし学習とは、データに関連付けられたラベル（たとえば、予めラベル付けされた偏りに敏感な変数）をまったく含まないデータを使用して、学習が生じるプロセスを指す。受信されたクラスタ訓練データセット１３０に基づいて教師なし学習を行なうことによって、クラスタモデル２１１は、データ特性の点で（偏りのない既知のデータ母集団によって）偏りのないデータセットについての確率分布を識別するように訓練されるようになる。たとえば、クラスタモデル２１１は、偏りに敏感な変数および／または偏りに敏感な変数の組合せを表わすデータ特性を用いて、少なくとも１つのクラスタ２１２を生成するように訓練される。
The
一例として、クラスタモデル２１１は、人種、ジェンダー、および年齢という偏りに敏感な変数の各々を、偏りのない既知の母集団のデータ特性としてクラスタ化する。ここで、各クラスタ２１２はしたがって、対応する偏りに敏感な変数の組合せに対応していてもよい。一例として、人種、ジェンダー、および年齢というデータ特性を用いて、少なくとも１つのクラスタ２１２は、１つのタイプの人種（たとえば黒人、白人、ヒスパニック系など）、１つのタイプのジェンダー（たとえば男性、女性、トランスジェンダー）、および１つのタイプの年齢層（たとえば１９〜３０才、３１〜４４才、４５〜５９才、６０才以上など）に対応する。分割器２１０がクラスタモデル２１１を使用してクラスタ訓練データセット１３０をクラスタ２１２に分割する場合、分割器２１０はまた、クラスタ２１２、２１２ａ〜ｎが、関連付けられたクラスタ重み２１４、２１４ａ〜ｎを有するように、各クラスタ２１２について対応するクラスタ重み２１４を判定するように構成される。いくつかの例では、クラスタ重み２１４は、目標母集団（たとえば、クラスタ訓練データセット１３０の母集団）に対する、クラスタ２１２についての母集団比率（population fraction）を表わす。たとえば、クラスタ重み２１４は、クラスタ訓練データセット１３０の目標母集団のサイズに対するそれぞれのクラスタ２１２のサイズの比を表わしていてもよい。いくつかの例では、各クラスタ重み２１４を判定するために、分割器２１０は、各クラスタ２１２の母集団比率を判定し、各母集団比率を全クラスタ２１２の最大母集団比率で除算する（たとえば、各クラスタ重み２１４は１よりも小さい）。他の例では、各クラスタ重み２１４を判定するために、分割器２１０は、各クラスタ２１２の母集団比率を判定し、各母集団比率を全クラスタ２１２の最小母集団比率で除算する（たとえば、各クラスタ重み２１４は１よりも大きい）。
As an example, the
いくつかの構成では、分割器２１０は、訓練段階２０２中、クラスタ２１２についてのクラスタ重み２１４を調節器２２０に通信する。たとえば、調節器２２０は、クラスタ重み２１４のデータストア２２２を含む。他の例では、分割器２１０は、偏り防止段階２０４中に調節器２２０がアクセスするために、クラスタ重み２１４を（たとえば分割器２１０のデータストアに）格納する。
In some configurations, the divider 210 communicates the
図２Ｃは、偏り防止段階２０４中の偏り拒否モデル２００の一例を示す。偏り防止段階２０４中、偏り拒否モデル２００は、ＭＬモデル３００を訓練する際に使用するために意図されたＭＬ訓練データセット３０２を受信する。たとえば、訓練データセット３０２は、潜在的に偏りがあるかもしれない（たとえば、偏りのあるデータを含むかもしれない）未処理の訓練データセットを含むかもしれない。いくつかの実現化例では、訓練データセット３０２は、目標母集団のサンプルであり、そのため、目標母集団の偏りに敏感な変数１３２を不正確に反映するかもしれない。たとえば、目標母集団は、白人が２５％という人種構成を有するかもしれず、一方、訓練データセット３０２は、白人が４５％というサンプリング人種構成を示すかもしれない。このため、目標母集団の偏りに敏感な変数を不正確に反映するＭＬ訓練データ３０２に基づいてＭＬモデル３００を訓練するのを防止するために、偏り拒否モデル２００は、偏り防止段階２０４中に分割器２１０および調節器２２０を用いてこの偏り（たとえば２０％の差）を調節しようと努める。
FIG. 2C shows an example of the
分割器２１０が図２Ｂの訓練段階２０２中に偏り訓練データセット１３０を偏りクラスタ２１２に分割する方法と同様に、分割器２１０は、偏り防止段階２０４中に、受信されたＭＬ訓練データセット３０２を訓練クラスタ２１６に分割するように構成される。分割器２１０は、訓練データセット３０２を訓練されたクラスタモデル２１１に提供することによって、訓練データセット３０２を分割する。訓練段階２０２からの訓練に基づいて、クラスタモデル２１１は、訓練データセット３０２などのデータセットをクラスタ（たとえば、クラスタ２１２ａ〜ｎ、または訓練クラスタ２１６ａ〜ｎ）に分割する方法を学習済みである。偏り防止段階２０４中、クラスタモデル２１１は、機械学習モデル３００のために意図された、受信された訓練データセット３０２に基づいて、訓練クラスタ２１６、２１６ａ〜ｎを生成する。ここで、少なくとも１つの訓練クラスタ２１６は、目標母集団の少なくとも１つの対応する偏りに敏感な変数に関連付けられる。分割器２１０はさらに、分割された訓練クラスタ２１６が、関連付けられた訓練データセット重み２１８を含むように、分割された各訓練クラスタ２１６について、対応する訓練データセット重み２１８、２１８ａ〜ｎを生成するように構成される。いくつかの例では、それぞれの訓練データセット重み２１８は、訓練データセット３０２に関連付けられたサンプル母集団に対する、訓練クラスタ２１６についての母集団比率を表わす。たとえば、訓練データセット重み２１８は、訓練データセット３０２のサンプル母集団のサイズに対するそれぞれの訓練クラスタ２１６のサイズの比を表わしていてもよい。いくつかの例では、各訓練データセット重み２１８を判定するために、分割器２１０は、各訓練クラスタ２１６の母集団比率を判定し、各母集団比率を訓練クラスタ２１６の最大母集団比率で除算する（たとえば、各訓練データセット重み２１８は１よりも小さい）。他の例では、各訓練データセット重み２１８を判定するために、分割器２１０は、各訓練クラスタ２１６の母集団比率を判定し、各母集団比率を訓練クラスタ２１６ａ〜ｎの最小母集団比率で除算する（たとえば、各訓練データセット重み２１８は１よりも大きい）。
Similar to how the divider 210 divides the biased
調節器２２０は、目標母集団のデータ特性（すなわち、偏りに敏感な変数）の確率分布と整合するために、訓練データセット重み２１８を調節するように構成される。いくつかの実現化例では、調節器２２０は、訓練データセット重み２１８をクラスタ重み２１４と比較することによって訓練データセット重み２１８を調節するプロセス２２６を実行する。たとえば、図２Ｃ〜２Ｅは、調節器２２０が、クラスタ重みデータストア２２２からのクラスタ重み２１８と、訓練重みデータストア２２４からの訓練データセット重み２１８とを検索して比較し、比較に基づいて訓練データセット重み２１８を調節するために、プロセス２２６を実行することを示す。たとえば、それぞれの訓練データセット重み２１８とクラスタ重み２１４との相対的な差に基づいて、調節器２２０は、それぞれの訓練データセット重み２１８を、対応するクラスタ重み２１４と整合するように調節してもよい。したがって、訓練データセット重み２１８を調節するために調節器２２０によって実行されるプロセス２２６は、調節された訓練データセット重みを生成／出力し、または、より一般的には、ＭＬモデル３００を訓練するための偏りのない訓練データセット２０６を形成する調節された訓練データセット２０８を生成／出力する。
The regulator 220 is configured to adjust the
いくつかの実現化例では、調節器２２０は、まず、偏りに敏感な変数などの整合するデータ特性に基づいて、１つ以上の訓練データセット重み２１８ａ〜ｎを１つ以上のクラスタ重み２１４ａ〜ｎと整合させることによって、プロセス２２６を実行する。たとえば、訓練データセット重み２１８とクラスタ重み２１４とが各々、共通のデータ特性（たとえば、偏りに敏感な変数）またはデータ特性の組合せを共有する場合、調節器２２０は、訓練データセット重み２１８を、整合する（すなわち、対応する）クラスタ重み２１４を用いて調節し、対応する調節された訓練データセット重みおよび／または調節された訓練データセット２０８を出力してもよい。
In some implementations, the controller 220 first has one or more training dataset weights 218a-n and one or more cluster weights 214a-n based on matching data characteristics such as bias-sensitive variables.
図２Ｄを参照して、調節器２２０は、共通のデータ特性（たとえば、偏りに敏感な変数）またはデータ特性の組合せを共有する訓練データセット重み２１８と偏りクラスタ重み２１４とを比較する。ＭＬ訓練データセット３０２が偏りに敏感な変数を過大表現する場合、訓練データセット重み２１８は、偏りに敏感な変数に対応するデータ特性について、クラスタ重み２１４を上回る（たとえば、クラスタ重み２１４よりも大きい）（たとえば、訓練データセット３０２は、白人が２０％多い人種構成を示す）。この過大表現に応答して、調節器２２０によって実行されるプロセス２２６は、訓練データセット重み２１８がクラスタ重み２１４と整合するまで訓練データセット３０２からデータを除去することによって訓練データセット重み２１８を調節するデータ除去調節プロセスに対応してもよい。一方、訓練データセット３０２が偏りに敏感な変数を過小表現する場合、訓練データセット重み２１８は、偏りに敏感な変数に対応するデータ特性について、クラスタ重み２１４よりも小さい（たとえば、訓練データセット３０２は、黒人が２０％少ない人種構成を示す）。この過小表現に応答して、調節器２２０上で実行されるプロセス２２６は、訓練データセット重み２１８がクラスタ重み２１４と整合するまで訓練データセット３０２からデータを複製することによって訓練データセット重み２１８を調節するデータ複製プロセスに対応してもよい。いくつかの実現化例では、調節器２２０は、訓練データセット３０２の完全性を維持するために、訓練データセット３０２からデータをランダムに複製または除去する。これは、ランダムではない選択的な複製または除去に関連付けられたさらなる偏りを回避し得る。
With reference to FIG. 2D, the controller 220 compares a
訓練データセット重み２１８が偏りクラスタ重み２１４と整合するまで訓練データセット３０２からデータを除去するかまたは訓練データセット３０２にデータを追加する図２Ｃのプロセス２２６とは対照的に、図２Ｅは、各訓練データセット重み２１８に関連付けられた重要性重み２２８を調節する調節器２２０上で実行されるプロセス２２６を示す。具体的には、プロセスは、重要性重み２２８を、関連付けられた訓練データセット重み２１８に対応する訓練データセット３０２のデータに関連付ける。重要性重み２２８は、機械学習モデル３００を訓練しながら、訓練データセット重み２１８に対応する基礎的データを提供するための重みがどれぐらいかを理解するために、機械学習モデル３００の訓練段階３０４（図３）への表示を提供する。いくつかの例では、訓練データセット重み２１８がクラスタ重み２１４よりも大きい場合、調節器２２０は、それぞれの訓練データセット重み２１８に対応する訓練データに対する機械学習モデル３００の訓練を減少させることを示す重要性重み２２８を関連付ける。他の例では、訓練データセット重み２１８がクラスタ重み２１４よりも小さい場合、調節器２２０は、それぞれの訓練データセット重み２１８に対応する訓練データに対する機械学習モデル３００の訓練を増加させることを示す重要性重み２２８を関連付ける。
FIG. 2E shows each, in contrast to process 226 in FIG. 2C, which either removes data from the
図２Ａ〜２Ｅによって示すように、偏り拒否モデル２００は、機械学習モデル３００を訓練するための偏りのない訓練データセット２０６を生成する。図３は、機械学習モデル３００が偏りのない訓練データセット２０６に基づいて訓練する一例である。機械学習モデル３００などの機械学習モデルは一般に、データセットおよび結果セットに基づいて教えられ（または訓練され）、当該データセットに類似した入力データに基づいてそれ自体の出力を予測する。いくつかの実現化例では、偏り拒否モデル２００と同様に、機械学習モデル３００はまず、訓練段階３０４中に訓練を受け、次に、サンプルデータセット３０８を入力として受信し、偏りのない予測値３１０を出力する予測段階（たとえば推論）３０６を経る。予測段階３０６中、機械学習モデル３００は、少なくとも１つの偏りに敏感な変数を含むサンプルデータセットなどのサンプルデータセット３０８を受信し、偏りのない訓練データセット２０６に基づいて訓練された関連付けられた機械学習機能性を利用して、受信されたサンプルデータセット３０８に基づいた、偏りのない予測値３１０を生成する。
As shown by FIGS. 2A-2E, the
いくつかの例では、機械学習モデル３００は、偏りのない２つ以上の訓練データセット２０６を用いて訓練する。たとえば、機械学習モデル３００は、動作中、動的に変化するデータセットを連続的に勘案するように動的に訓練する。言い換えれば、訓練段階３０４および予測段階３０６は、連続的にまたは同時に実行されてもよく、またはそれら双方の何らかの組合せであってもよい。
In some examples, the
図４は、偏り採点モデル４００の一例である。偏り採点モデル４００は、偏り拒否モデル２００とともに、または偏り拒否モデル２００とは別々に使用されてもよい。たとえば、偏り採点モデル４００は、機械学習モデル３００を訓練するよう意図された訓練データセット３０２を、当該訓練データセット３０２を偏り拒否モデル２００に提供する前に評価してもよい（すなわち、これらのモデル２００、３００は、偏り採点モデル４００に相談する）。これらの例では、偏り採点モデル４００が、訓練データセット３０２は偏りがあり過ぎて機械学習モデル３００の訓練を始められないことを示して、訓練データセット３０２を拒否した場合、偏り採点モデル４００は、２Ａ〜２Ｅを参照して上述されたように、拒否された訓練データセット４２６の偏りを防止し、偏りのない訓練データセット２０６を形成するために、拒否された訓練データセット３０２を偏り拒否モデル２００に通信してもよい。
FIG. 4 is an example of the
偏り拒否モデル２００、クラスタモデル２１１、および／または機械学習モデル３００と同様に、偏り採点モデル４００は、データセットを採点するように偏り採点モデル４００を訓練するための訓練段階４０２を経る。そして、いったん訓練されると、採点段階４０４中に、訓練段階４０２からの訓練に基づいてデータセットを採点する。訓練段階４０２中、偏り採点モデル４００は、１つ以上の偏り採点訓練データセット４１０を受信する。各偏り採点訓練データセット４１０は、偏りのあるデータ４１２および／または偏りのないデータ４１４などのデータと、偏りスコア４１６とを含む。たとえば、偏りスコア４１６は、データセット内の偏りの数値表現である。いくつかの例では、偏りスコア４１６および／または偏り採点訓練データセット４１０は、採点者１４０から生じる。採点者１４０は、機械学習環境１０内のアドミニストレータ（たとえば、モデル２００、２１１、３００のアドミニストレータ）、または、機械学習モデル３００での偏りを懸念するユーザであってもよい。いくつかの例では、採点者１４０は、２つ以上のエンティティ／ソース（すなわちコミッティ）、あるいは、データセットをコンパイルおよび／または採点するように訓練された別の機械学習モデルである。訓練段階４０２中、偏り採点モデル４００は、１つ以上の偏り採点訓練データセット４１０を受信し、データセットについての偏りスコア４１６を生成することを学習する。
Similar to the
いったん訓練されると、または、偏り採点モデル４００が採点段階４０４と並行して絶えず訓練する場合、偏り採点モデル４００は、機械学習モデル３００のために意図された訓練データセット３０２を受信する（たとえば傍受する）。その訓練に基づいて、偏り採点モデル４００は、偏り採点モデル４００が訓練データセット３０２についての偏りスコア４１６を生成する採点プロセス４２０を行なう。採点プロセス４２０の一環として、偏り採点モデル４００は、訓練データセット３０２についての偏りスコア４１６がスコアしきい値４２２を満たすかどうかを判定する。ここで、スコアしきい値４２２は、機械学習モデル３００での予測のために、データセットには偏りがないかまたは無視できるほど小さいという信頼度を示す。たとえば、スコアしきい値４２２は、受け入れ可能な偏りスコア値である。
Once trained, or if the
訓練データセット３０２の偏りスコア４１６がスコアしきい値４２２を満たす（たとえば、受け入れ可能な偏りスコア値を上回る）場合、偏り採点モデル４００は、訓練データセット３０２を、承認された訓練データセット４２４として承認する。いくつかの例では、承認された訓練データセット４２４は、機械学習モデルが（たとえば図３に示す）偏りのない予測値３１０を生成し始めるように、機械学習モデル３００によって認識可能な承認指標を含む。訓練データセット３０２の偏りスコア４１６がスコアしきい値４２２を満たさない（たとえば、受け入れ可能な偏りスコア値よりも小さい）場合、偏り採点モデル４００は、訓練データセット３０２を拒否する。拒否された訓練データセット４２６は、拒否された訓練データセット３０２を用いて訓練しないように機械学習モデル３００に通知するための拒否指標を含んでいてもよい。図４に点線のボックスおよび矢印によって示すように、偏り採点モデル４００は、２Ａ〜２Ｅを参照して上述されたように、偏り拒否モデル２００が拒否された訓練データセット３０２を偏りのない訓練データセット２０６に変換するように、拒否された訓練データセット３０２を偏り拒否モデル２００に通信（すなわち提供）してもよい。
If the
偏り拒否モデル２００、機械学習モデル３００、および／または偏り採点モデル４００は、ここに説明される任意のモデル２００、３００、４００の機能性を実行するために少なくとも１つの機械学習アルゴリズムを採用する任意のタイプの機械学習モデル（たとえば、教師あり、教師なし、強化、アンサンブル／決定木、ディープラーニング、ニューラルネットワーク、再帰的、線形など）であってもよい。おおまかに言えば、機械学習アルゴリズムは、教師あり学習、教師なし学習、アクティブラーニング、または、これらのタイプの学習アルゴリズムのいくつかのハイブリッドの組合せに関連していてもよい。これらの広範なアルゴリズムのいくつかの具体例は、線形回帰アルゴリズム、ロジスティック回帰アルゴリズム、決定木ベースのアルゴリズム、サポートベクトルマシンアルゴリズム、単純ベイズ分類器、ｋ最近傍アルゴリズム、次元縮小アルゴリズム、勾配ブースティングアルゴリズムなどといった機械学習アルゴリズムを含む。
The
図５は、機械学習環境１０内の機械学習モデル３００の偏りを防止するための動作を有する例示的な方法５００である。動作５０２で、方法５００は、クラスタ訓練データセット１３０を受信する。クラスタ訓練データセット１３０は、偏りのない既知のデータ母集団を含む。動作５０４で、方法５００は、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセット１３０セットをクラスタ２１２に分割するように、クラスタ化モデル２１１を訓練する。クラスタ２１２ａ〜ｎの各クラスタ２１２は、クラスタ重み２１４を含む。動作５０６で、方法５００は、機械学習モデル３００のための訓練データセット３０２を受信する。動作５０８で、方法５００は、クラスタ化モデル２１１に基づいて、機械学習モデル３００のための訓練データセット３０２に対応する訓練データセット重み２１８ａ〜ｎを生成する。動作５１０で、方法５００は、訓練データセット重み２１８ａ〜ｎの各訓練データセット重み２１８を、それぞれのクラスタ重み２１４と整合するように調節する。動作５１２で、方法５００は、調節された訓練データセット２０８を、偏りのない訓練データセット２０６として、機械学習モデル３００に提供する。
FIG. 5 is an
図６は、この文書で説明されるシステムおよび方法（たとえば、偏り拒否モデル２００および／または機械学習モデル３００）を実現するために使用され得る例示的なコンピューティングデバイス６００の概略図である。コンピューティングデバイス６００は、ラップトップ、デスクトップ、ワークステーション、携帯情報端末、サーバ、ブレードサーバ、メインフレーム、および他の適切なコンピュータといった、さまざまな形態のデジタルコンピュータを表わすよう意図されている。ここに示すコンポーネント、それらの接続および関係、ならびにそれらの機能は単なる例示であることが意図されており、この文書で説明される、および／または請求項に記載のこの発明の実現化例を限定するよう意図されてはいない。
FIG. 6 is a schematic representation of an
コンピューティングデバイス６００は、プロセッサ６１０と、メモリ６２０と、記憶装置６３０と、メモリ６２０および高速拡張ポート６５０に接続している高速インターフェイス／コントローラ６４０と、低速バス６７０および記憶装置６３０に接続している低速インターフェイス／コントローラ６６０とを含む。コンポーネント６１０、６２０、６３０、６４０、６５０、および６６０の各々は、さまざまなバスを使用して相互接続されており、共通のマザーボード上にまたは他の態様で適宜搭載されてもよい。プロセッサ６１０は、コンピューティングデバイス６００内で実行される命令を処理可能であり、これらの命令は、グラフィカルユーザインターフェイス（graphical user interface：ＧＵＩ）のためのグラフィック情報を、高速インターフェイス６４０に結合されたディスプレイ６８０などの外部入出力デバイス上に表示するために、メモリ６２０内または記憶装置６３０上に格納された命令を含む。他の実現化例では、複数のプロセッサおよび／または複数のバスが、複数のメモリおよび複数のタイプのメモリとともに適宜使用されてもよい。また、複数のコンピューティングデバイス６００が接続されてもよく、各デバイスは（たとえば、サーババンク、ブレードサーバのグループ、またはマルチプロセッサシステムとして）必要な動作の部分を提供する。
The
メモリ６２０は、情報をコンピューティングデバイス６００内に非一時的に格納する。メモリ６２０は、コンピュータ読取可能媒体、揮発性メモリユニット、または不揮発性メモリユニットであってもよい。非一時的メモリ６２０は、プログラム（たとえば命令のシーケンス）またはデータ（たとえばプログラム状態情報）を、コンピューティングデバイス６００による使用のために一時的または永続的に格納するために使用される物理デバイスであってもよい。不揮発性メモリの例は、フラッシュメモリおよび読出専用メモリ（ＲＯＭ）／プログラマブル読出専用メモリ（ＰＲＯＭ）／消去可能プログラマブル読出専用メモリ（ＥＰＲＯＭ）／電子的消去可能プログラマブル読出専用メモリ（ＥＥＰＲＯＭ）（たとえば、典型的にはブートプログラムなどのファームウェアのために使用される）を含むものの、それらに限定されない。揮発性メモリの例は、ランダムアクセスメモリ（ＲＡＭ）、ダイナミックランダムアクセスメモリ（ＤＲＡＭ）、スタティックランダムアクセスメモリ（ＳＲＡＭ）、相変化メモリ（ＰＣＭ）、およびディスクまたはテープを含むものの、それらに限定されない。
The
記憶装置６３０は、コンピューティングデバイス６００のための大容量記憶を提供可能である。いくつかの実現化例では、記憶装置６３０は、コンピュータ読取可能媒体である。さまざまな異なる実現化例では、記憶装置６３０は、フロッピー（登録商標）ディスクデバイス、ハードディスクデバイス、光ディスクデバイス、もしくはテープデバイス、フラッシュメモリまたは他の同様のソリッドステートメモリデバイス、もしくは、ストレージエリアネットワークまたは他の構成におけるデバイスを含むデバイスのアレイであってもよい。追加の実現化例では、コンピュータプログラム製品が情報担体において有形に具現化され得る。コンピュータプログラム製品は、実行されると上述のような１つ以上の方法を行なう命令を含む。情報担体は、メモリ６２０、記憶装置６３０、またはプロセッサ６１０上のメモリといった、コンピュータ読取可能媒体または機械読取可能媒体である。
The
高速コントローラ６４０はコンピューティングデバイス６００のための帯域幅集約的な動作を管理し、一方、低速コントローラ６６０はより低い帯域幅集約的な動作を管理する。役目のそのような割当ては例示に過ぎない。いくつかの実現化例では、高速コントローラ６４０は、メモリ６２０、ディスプレイ６８０に（たとえば、グラフィックスプロセッサまたはアクセラレータを介して）結合されるとともに、さまざまな拡張カード（図示せず）を受け付け得る高速拡張ポート６５０に結合される。いくつかの実現化例では、低速コントローラ６６０は、記憶装置６３０および低速拡張ポート６９０に結合される。さまざまな通信ポート（たとえば、ＵＳＢ、ブルートゥース（登録商標）、イーサネット（登録商標）、無線イーサネット）を含み得る低速拡張ポート６９０は、キーボード、ポインティングデバイス、スキャナなどの１つ以上の入出力デバイスに、もしくは、スイッチまたはルータなどのネットワーキングデバイスに、たとえばネットワークアダプタを介して結合されてもよい。
The
コンピューティングデバイス６００は、図に示すように多くの異なる形態で実現されてもよい。たとえばそれは、標準サーバ６００ａとして、またはそのようなサーバ６００ａのグループで複数回実現されてもよく、ラップトップコンピュータ６００ｂとして、またはラックサーバシステム６００ｃの一部として実現されてもよい。
The
ここに説明されるシステムおよび手法のさまざまな実現化例は、デジタル電子および／または光学回路、集積回路、特別に設計されたＡＳＩＣ（application specific integrated circuit：特定用途向け集積回路）、コンピュータハードウェア、ファームウェア、ソフトウェア、および／またはそれらの組合せにおいて実現され得る。これらのさまざまな実現化例は、データおよび命令を記憶システムとの間で送受信するように結合された、専用または汎用であり得る少なくとも１つのプログラマブルプロセッサと、少なくとも１つの入力デバイスと、少なくとも１つの出力デバイスとを含むプログラマブルシステム上で実行可能および／または解釈可能である１つ以上のコンピュータプログラムにおける実現を含み得る。 Various implementations of the systems and methods described herein include digital electronic and / or optical circuits, integrated circuits, specially designed application specific integrated circuits (ASICs), computer hardware, and more. It can be achieved in firmware, software, and / or a combination thereof. These various implementations include at least one programmable processor, which may be dedicated or general purpose, and at least one input device, coupled to send and receive data and instructions to and from the storage system. It may include implementations in one or more computer programs that are executable and / or interpretable on programmable systems, including output devices.
これらのコンピュータプログラム（プログラム、ソフトウェア、ソフトウェアアプリケーション、またはコードとしても知られている）は、プログラマブルプロセッサのための機械命令を含み、高レベルの手続き型および／またはオブジェクト指向プログラミング言語で、および／またはアセンブリ／機械語で実現され得る。ここに使用されるように、「機械読取可能媒体」および「コンピュータ読取可能媒体」という用語は、機械命令および／またはデータをプログラマブルプロセッサに提供するために使用される任意のコンピュータプログラム製品、非一時的コンピュータ読取可能媒体、機器および／またはデバイス（たとえば磁気ディスク、光ディスク、メモリ、プログラマブルロジックデバイス（Programmable Logic Device：ＰＬＤ））を指し、機械命令を機械読取可能信号として受信する機械読取可能媒体を含む。「機械読取可能信号」という用語は、機械命令および／またはデータをプログラマブルプロセッサに提供するために使用される任意の信号を指す。 These computer programs (also known as programs, software, software applications, or code) include machine instructions for programmable processors, in high-level procedural and / or object-oriented programming languages, and / or. Can be realized in assembly / machine language. As used herein, the terms "machine readable medium" and "computer readable medium" are any computer program products used to provide machine instructions and / or data to programmable processors, non-temporary. A computer-readable medium, device and / or device (eg, magnetic disk, optical disk, memory, Programmable Logic Device (PLD)), including machine-readable media that receives machine instructions as machine-readable signals. .. The term "machine readable signal" refers to any signal used to provide machine instructions and / or data to a programmable processor.
この明細書で説明されるプロセスおよび論理フローは、１つ以上のプログラマブルプロセッサが、入力データに基づいて動作することおよび出力を生成することによって機能を行なうために１つ以上のコンピュータプログラムを実行することによって行なわれ得る。プロセスおよび論理フローはまた、たとえばＦＰＧＡ（field programmable gate array：フィールドプログラマブルゲートアレイ）またはＡＳＩＣ（特定用途向け集積回路）といった専用論理回路によって行なわれ得る。コンピュータプログラムの実行にとって好適であるプロセッサは、一例として、汎用および専用マイクロプロセッサと、任意の種類のデジタルコンピュータの任意の１つ以上のプロセッサとを含む。一般に、プロセッサは、命令およびデータを、読出専用メモリまたはランダムアクセスメモリまたはそれら双方から受信するであろう。コンピュータの本質的要素は、命令を行なうためのプロセッサと、命令およびデータを格納するための１つ以上のメモリデバイスとである。一般に、コンピュータはまた、たとえば磁気ディスク、光磁気ディスク、または光ディスクといった、データを格納するための１つ以上の大容量記憶装置を含むであろう。もしくは、当該大容量記憶装置からデータを受信し、または当該大容量記憶装置にデータを転送し、またはそれら双方を行なうように動作可能に結合されるであろう。しかしながら、コンピュータは、そのようなデバイスを有する必要はない。コンピュータプログラム命令およびデータを格納するのに好適であるコンピュータ読取可能媒体は、あらゆる形態の不揮発性メモリ、媒体、およびメモリデバイスを含み、一例として、半導体メモリ装置、たとえばＥＰＲＯＭ、ＥＥＰＲＯＭ、およびフラッシュメモリデバイス；磁気ディスク、たとえば内部ハードディスクまたはリムーバブルディスク；光磁気ディスク；ならびに、ＣＤ ＲＯＭおよびＤＶＤ−ＲＯＭディスクを含む。プロセッサおよびメモリは、専用論理回路によって補足され、または専用論理回路に組込まれ得る。 In the processes and logical flows described herein, one or more programmable processors execute one or more computer programs to perform functions by operating on input data and producing outputs. Can be done by Processes and logic flows can also be performed by dedicated logic circuits such as FPGAs (field programmable gate arrays) or ASICs (application specific integrated circuits). Suitable processors for running computer programs include, for example, general purpose and dedicated microprocessors and any one or more processors of any type of digital computer. In general, the processor will receive instructions and data from read-only memory and / or random access memory. An essential element of a computer is a processor for performing instructions and one or more memory devices for storing instructions and data. In general, a computer will also include one or more mass storage devices for storing data, such as magnetic disks, magneto-optical disks, or optical disks. Alternatively, it will be operably coupled to receive data from the mass storage device, transfer data to the mass storage device, or both. However, the computer does not need to have such a device. Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media, and memory devices, such as semiconductor memory devices such as EPROM, EEPROM, and flash memory devices. Includes magnetic discs such as internal hard disks or removable discs; magneto-optical discs; as well as CD ROM and DVD-ROM discs. Processors and memory can be supplemented by dedicated logic or incorporated into dedicated logic.
ユーザとの対話を提供するために、この開示の１つ以上の局面は、情報をユーザに表示するためのディスプレイデバイス、たとえばＣＲＴ（cathode ray tube：陰極線管）、ＬＣＤ（liquid crystal display：液晶ディスプレイ）モニター、またはタッチスクリーンと、オプションで、ユーザがコンピュータへの入力を提供できるようにするキーボードおよびポインティングデバイス、たとえばマウスまたはトラックボールとを有するコンピュータ上で実現され得る。他の種類のデバイスも同様に、ユーザとの対話を提供するために使用され得る。たとえば、ユーザに提供されるフィードバックは、任意の形態の感覚フィードバック、たとえば視覚フィードバック、聴覚フィードバック、または触覚フィードバックであり得る。また、ユーザからの入力は、音響入力、音声入力、または触覚入力を含む任意の形態で受信され得る。加えて、コンピュータは、ユーザによって使用されるデバイスに文書を送信し、当該デバイスから文書を受信することによって、たとえば、ユーザのクライアントデバイス上のウェブブラウザから受信された要求に応答してウェブページを当該ウェブブラウザに送信することによって、ユーザと対話することができる。 To provide user interaction, one or more aspects of this disclosure are display devices for displaying information to the user, such as CRTs (cathode ray tubes), LCDs (liquid crystal displays). It can be implemented on a computer with a monitor, or touch screen, and optionally a keyboard and pointing device that allows the user to provide input to the computer, such as a mouse or trackball. Other types of devices can be used to provide user interaction as well. For example, the feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback. Also, the input from the user may be received in any form including acoustic input, voice input, or tactile input. In addition, the computer sends a document to the device used by the user and receives the document from that device, for example, in response to a request received from a web browser on the user's client device. You can interact with the user by sending to the web browser.
多くの実現化例が説明されてきた。にもかかわらず、この開示の精神および範囲から逸脱することなく、さまざまな変更を行なってもよいということが理解されるであろう。したがって、他の実現化例は、請求の範囲内にある。 Many realization examples have been explained. Nevertheless, it will be understood that various changes may be made without departing from the spirit and scope of this disclosure. Therefore, other realization examples are within the claims.
調節器２２０は、目標母集団のデータ特性（すなわち、偏りに敏感な変数）の確率分布と整合するために、訓練データセット重み２１８を調節するように構成される。いくつかの実現化例では、調節器２２０は、訓練データセット重み２１８をクラスタ重み２１４と比較することによって訓練データセット重み２１８を調節するプロセス２２６を実行する。たとえば、図２Ｃ〜２Ｅは、調節器２２０が、クラスタ重みデータストア２２２からのクラスタ重み２１４と、訓練重みデータストア２２４からの訓練データセット重み２１８とを検索して比較し、比較に基づいて訓練データセット重み２１８を調節するために、プロセス２２６を実行することを示す。たとえば、それぞれの訓練データセット重み２１８とクラスタ重み２１４との相対的な差に基づいて、調節器２２０は、それぞれの訓練データセット重み２１８を、対応するクラスタ重み２１４と整合するように調節してもよい。したがって、訓練データセット重み２１８を調節するために調節器２２０によって実行されるプロセス２２６は、調節された訓練データセット重みを生成／出力し、または、より一般的には、ＭＬモデル３００を訓練するための偏りのない訓練データセット２０６を形成する調節された訓練データセット２０８を生成／出力する。
The regulator 220 is configured to adjust the
訓練データセット重み２１８が偏りクラスタ重み２１４と整合するまで訓練データセット３０２からデータを除去するかまたは訓練データセット３０２にデータを追加する図２Ｄのプロセス２２６とは対照的に、図２Ｅは、各訓練データセット重み２１８に関連付けられた重要性重み２２８を調節する調節器２２０上で実行されるプロセス２２６を示す。具体的には、プロセスは、重要性重み２２８を、関連付けられた訓練データセット重み２１８に対応する訓練データセット３０２のデータに関連付ける。重要性重み２２８は、機械学習モデル３００を訓練しながら、訓練データセット重み２１８に対応する基礎的データを提供するための重みがどれぐらいかを理解するために、機械学習モデル３００の訓練段階３０４（図３）への表示を提供する。いくつかの例では、訓練データセット重み２１８がクラスタ重み２１４よりも大きい場合、調節器２２０は、それぞれの訓練データセット重み２１８に対応する訓練データに対する機械学習モデル３００の訓練を減少させることを示す重要性重み２２８を関連付ける。他の例では、訓練データセット重み２１８がクラスタ重み２１４よりも小さい場合、調節器２２０は、それぞれの訓練データセット重み２１８に対応する訓練データに対する機械学習モデル３００の訓練を増加させることを示す重要性重み２２８を関連付ける。
In contrast to FIG. 2
図４は、偏り採点モデル４００の一例である。偏り採点モデル４００は、偏り拒否モデル２００とともに、または偏り拒否モデル２００とは別々に使用されてもよい。たとえば、偏り採点モデル４００は、機械学習モデル３００を訓練するよう意図された訓練データセット３０２を、当該訓練データセット３０２を偏り拒否モデル２００に提供する前に評価してもよい（すなわち、これらのモデル２００、３００は、偏り採点モデル４００に相談する）。これらの例では、偏り採点モデル４００が、訓練データセット３０２は偏りがあり過ぎて機械学習モデル３００の訓練を始められないことを示して、訓練データセット３０２を拒否した場合、偏り採点モデル４００は、図２Ａ〜２Ｅを参照して上述されたように、拒否された訓練データセット４２６の偏りを防止し、偏りのない訓練データセット２０６を形成するために、拒否された訓練データセット３０２を偏り拒否モデル２００に通信してもよい。
FIG. 4 is an example of the
訓練データセット３０２の偏りスコア４１６がスコアしきい値４２２を満たす（たとえば、受け入れ可能な偏りスコア値を上回る）場合、偏り採点モデル４００は、訓練データセット３０２を、承認された訓練データセット４２４として承認する。いくつかの例では、承認された訓練データセット４２４は、機械学習モデルが（たとえば図３に示す）偏りのない予測値３１０を生成し始めるように、機械学習モデル３００によって認識可能な承認指標を含む。訓練データセット３０２の偏りスコア４１６がスコアしきい値４２２を満たさない（たとえば、受け入れ可能な偏りスコア値よりも小さい）場合、偏り採点モデル４００は、訓練データセット３０２を拒否する。拒否された訓練データセット４２６は、拒否された訓練データセット３０２を用いて訓練しないように機械学習モデル３００に通知するための拒否指標を含んでいてもよい。図４に点線のボックスおよび矢印によって示すように、偏り採点モデル４００は、図２Ａ〜２Ｅを参照して上述されたように、偏り拒否モデル２００が拒否された訓練データセット３０２を偏りのない訓練データセット２０６に変換するように、拒否された訓練データセット３０２を偏り拒否モデル２００に通信（すなわち提供）してもよい。
If the
図５は、機械学習環境１０内の機械学習モデル３００の偏りを防止するための動作を有する例示的な方法５００である。動作５０２で、方法５００は、クラスタ訓練データセット１３０を受信する。クラスタ訓練データセット１３０は、偏りのない既知のデータ母集団を含む。動作５０４で、方法５００は、偏りのない既知のデータ母集団のデータ特性に基づいて、受信されたクラスタ訓練データセット１３０をクラスタ２１２に分割するように、クラスタ化モデル２１１を訓練する。クラスタ２１２ａ〜ｎの各クラスタ２１２は、クラスタ重み２１４を含む。動作５０６で、方法５００は、機械学習モデル３００のための訓練データセット３０２を受信する。動作５０８で、方法５００は、クラスタ化モデル２１１に基づいて、機械学習モデル３００のための訓練データセット３０２に対応する訓練データセット重み２１８ａ〜ｎを生成する。動作５１０で、方法５００は、訓練データセット重み２１８ａ〜ｎの各訓練データセット重み２１８を、それぞれのクラスタ重み２１４と整合するように調節する。動作５１２で、方法５００は、調節された訓練データセット２０８を、偏りのない訓練データセット２０６として、機械学習モデル３００に提供する。
FIG. 5 is an
Claims (20)
データ処理ハードウェア（１１２）で、クラスタ訓練データセット（１３０）を受信するステップを含み、前記クラスタ訓練データセット（１３０）は偏りのない既知のデータ母集団を含み、前記方法はさらに、
前記データ処理ハードウェア（１１２）が、前記偏りのない既知のデータ母集団のデータ特性に基づいて、受信された前記クラスタ訓練データセット（１３０）をクラスタ（２１２）に分割するように、クラスタ化モデル（２１１）を訓練するステップを含み、前記クラスタ訓練データセット（１３０）の各クラスタ（２１２）はクラスタ重み（２１４）を含み、前記方法はさらに、
前記データ処理ハードウェア（１１２）で、機械学習モデル（３００）のための訓練データセット（３０２）を受信するステップと、
前記データ処理ハードウェア（１１２）が、前記クラスタ化モデル（２１１）に基づいて、前記機械学習モデル（３００）のための前記訓練データセット（３０２）に対応する訓練データセット重み（２１８）を生成するステップと、
前記データ処理ハードウェア（１１２）が、前記訓練データセット重み（２１８）の各訓練データセット重み（２１８）を、それぞれのクラスタ重み（２１４）と整合するように、および、調節された訓練データセット（２０８）を形成するように調節するステップと、
前記データ処理ハードウェア（１１２）が、前記調節された訓練データセット（２０８）を、偏りのない訓練データセット（２０６）として、前記機械学習モデル（３００）に提供するステップとを含む、方法。 Method (500)
The data processing hardware (112) comprises the step of receiving a cluster training data set (130), the cluster training data set (130) comprising a known unbiased data population, and the method further comprises the method.
The data processing hardware (112) is clustered so that the received cluster training data set (130) is divided into clusters (212) based on the data characteristics of the known unbiased data population. Each cluster (212) of the cluster training data set (130) includes a cluster weight (214), the method further comprising a step of training the model (211).
In the data processing hardware (112), the step of receiving the training data set (302) for the machine learning model (300), and
The data processing hardware (112) generates a training dataset weight (218) corresponding to the training dataset (302) for the machine learning model (300) based on the clustered model (211). Steps to do and
The data processing hardware (112) has adjusted the training data set so that each training data set weight (218) of the training data set weight (218) is consistent with the respective cluster weight (214). Steps to adjust to form (208),
A method comprising the step of providing the adjusted training data set (208) to the machine learning model (300) as an unbiased training data set (206) by the data processing hardware (112).
前記データ処理ハードウェア（１１２）で、少なくとも１つのそれぞれのデータ特性を含むサンプルデータセットを受信するステップと、
前記データ処理ハードウェア（１１２）が、訓練された前記機械学習モデル（３００）を使用して、受信された前記サンプルデータセットに基づいた、偏りのない予測値（３１０）を生成するステップとをさらに含む、請求項１または２に記載の方法（５００）。 A step in which the data processing hardware (112) trains the machine learning model (300) using the unbiased training data set (206).
A step of receiving a sample dataset containing at least one of the respective data characteristics in the data processing hardware (112).
The data processing hardware (112) uses the trained machine learning model (300) to generate an unbiased prediction (310) based on the received sample data set. The method (500) according to claim 1 or 2, further comprising.
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記それぞれのクラスタ重み（２１４）と整合させるステップと、
前記訓練データセット重み（２１８）が前記それぞれのクラスタ重み（２１４）と整合するまで、前記訓練データセットからデータを除去するステップとを含む、請求項１〜３のいずれか１項に記載の方法（５００）。 The step of adjusting each training data set weight (218) to be consistent with the respective cluster weight (214) is for each training data set weight (218).
A step of matching the training dataset weight (218) with the respective cluster weight (214) based on common data characteristics.
The method of any one of claims 1-3, comprising the step of removing data from the training data set until the training data set weight (218) is consistent with the respective cluster weight (214). (500).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記それぞれのクラスタ重み（２１４）と整合させるステップと、
前記訓練データセット重み（２１８）が前記それぞれのクラスタ重み（２１４）と整合するまで、前記訓練データセットからデータを複製するステップとを含む、請求項１〜４のいずれか１項に記載の方法（５００）。 The step of adjusting each training data set weight (218) to be consistent with the respective cluster weight (214) is for each training data set weight (218).
A step of matching the training dataset weight (218) with the respective cluster weight (214) based on common data characteristics.
The method of any one of claims 1-4, comprising the step of replicating data from the training data set until the training data set weight (218) is consistent with the respective cluster weight (214). (500).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記クラスタ重み（２１４）と整合させるステップと、
前記訓練データセット重み（２１８）が前記それぞれのクラスタ重み（２１４）よりも小さい場合、前記訓練データセット重み（２１８）に対応する訓練データに対する前記機械学習モデル（３００）の訓練を増加させることを示す重要性重み（２２８）を関連付けるステップとを含む、請求項１〜５のいずれか１項に記載の方法（５００）。 The step of adjusting each training data set weight (218) to be consistent with the respective cluster weight (214) is for each training data set weight (218).
A step of matching the training dataset weight (218) with the cluster weight (214) based on common data characteristics.
If the training data set weight (218) is smaller than the respective cluster weight (214), the training of the machine learning model (300) on the training data corresponding to the training data set weight (218) may be increased. The method (500) of any one of claims 1-5, comprising the step of associating the indicated materiality weight (228).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記クラスタ重み（２１４）と整合させるステップと、
前記訓練データセット重み（２１８）が前記それぞれのクラスタ重み（２１４）よりも大きい場合、前記訓練データセット重み（２１８）に対応する訓練データに対する前記機械学習モデル（３００）の訓練を減少させることを示す重要性重み（２２８）を関連付けるステップとを含む、請求項１〜６のいずれか１項に記載の方法（５００）。 The step of adjusting each training data set weight (218) to be consistent with the respective cluster weight (214) is for each training data set weight (218).
A step of matching the training dataset weight (218) with the cluster weight (214) based on common data characteristics.
If the training data set weight (218) is greater than the respective cluster weight (214), then reducing the training of the machine learning model (300) on the training data corresponding to the training data set weight (218). The method (500) of any one of claims 1-6, comprising the step of associating the indicated materiality weight (228).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記対応するクラスタ重み（２１４）と整合させるステップと、
前記訓練データセット重み（２１８）が前記対応するクラスタ重み（２１４）よりも小さい場合、前記訓練データセット重み（２１８）に対応する訓練データに対する前記機械学習モデル（３００）の訓練を増加させることを示す重要性重み（２２８）を関連付けるステップと、
前記訓練データセット重み（２１８）が前記対応するクラスタ重み（２１４）よりも大きい場合、前記訓練データセット重み（２１８）に対応する訓練データに対する前記機械学習モデル（３００）の訓練を減少させることを示す重要性重み（２２８）を関連付けるステップとを含む、請求項１〜７のいずれか１項に記載の方法（５００）。 The step of adjusting each training data set weight (218) of the training data set weight (218) to be consistent with the respective cluster weight (214) is further for each training data set weight (218).
A step of matching the training dataset weight (218) with the corresponding cluster weight (214) based on common data characteristics.
If the training data set weight (218) is smaller than the corresponding cluster weight (214), increasing the training of the machine learning model (300) on the training data corresponding to the training data set weight (218). With the step of associating the importance weight (228) shown,
If the training data set weight (218) is greater than the corresponding cluster weight (214), the training of the machine learning model (300) on the training data corresponding to the training data set weight (218) may be reduced. The method (500) of any one of claims 1-7, comprising the step of associating the indicated materiality weight (228).
前記偏りのない既知のデータ母集団のデータ特性に基づいて、受信された前記クラスタ訓練データセット（１３０）をクラスタ（２１２）に分割するステップと、
前記偏りのない既知のデータ母集団の前記データ特性に基づいた前記クラスタ（２１２）の各クラスタ（２１２）について、前記偏りのない既知のデータ母集団のサイズに対するそれぞれのクラスタ（２１２）のサイズの比に基づいて、前記クラスタ化モデル（２１１）の各クラスタ（２１２）についての前記クラスタ重み（２１４）を判定するステップとを含む、請求項１〜８のいずれか１項に記載の方法（５００）。 Further steps are taken to train the clustering model (211).
A step of dividing the received cluster training data set (130) into clusters (212) based on the data characteristics of the known unbiased data population.
For each cluster (212) of the cluster (212) based on the data characteristics of the known unbiased data population, the size of each cluster (212) relative to the size of the known unbiased data population. The method (500) of any one of claims 1-8, comprising the step of determining the cluster weight (214) for each cluster (212) of the clustering model (211) based on the ratio. ).
データ処理ハードウェア（１１２）と、
前記データ処理ハードウェア（１１２）と通信しているメモリハードウェア（１１４）とを含み、前記メモリハードウェア（１１４）は、前記データ処理ハードウェア（１１２）上で実行されると前記データ処理ハードウェア（１１２）に動作を行なわせる命令を格納しており、前記動作は、
クラスタ訓練データセット（１３０）を受信することを含み、前記クラスタ訓練データセット（１３０）は偏りのない既知のデータ母集団を含み、前記動作はさらに、
前記偏りのない既知のデータ母集団のデータ特性に基づいて、受信された前記クラスタ訓練データセット（１３０）をクラスタ（２１２）に分割するように、クラスタ化モデル（２１１）を訓練することを含み、前記クラスタ訓練データセット（１３０）の各クラスタ（２１２）はクラスタ重み（２１４）を含み、前記動作はさらに、
機械学習モデル（３００）のための訓練データセット（３０２）を受信することと、
前記クラスタ化モデル（２１１）に基づいて、前記機械学習モデル（３００）のための前記訓練データセット（３０２）に対応する訓練データセット重み（２１８）を生成することと、
前記訓練データセット重み（２１８）の各訓練データセット重み（２１８）を、それぞれのクラスタ重み（２１４）と整合するように、および、調節された訓練データセット（２０８）を形成するように調節することと、
前記調節された訓練データセット（２０８）を、偏りのない訓練データセット（２０６）として、前記機械学習モデル（３００）に提供することとを含む、システム。 System (100)
Data processing hardware (112) and
The data processing hardware includes the memory hardware (114) communicating with the data processing hardware (112), and the memory hardware (114) is the data processing hardware when executed on the data processing hardware (112). It stores an instruction to cause the hardware (112) to perform an operation, and the operation is
The cluster training data set (130) comprises receiving a cluster training data set (130), the cluster training data set (130) comprising a known unbiased data population, and the operation further comprises.
It involves training the clustering model (211) to divide the received cluster training data set (130) into clusters (212) based on the data characteristics of the known unbiased data population. , Each cluster (212) of the cluster training data set (130) includes a cluster weight (214), and the operation further comprises.
Receiving the training data set (302) for the machine learning model (300) and
To generate a training dataset weight (218) corresponding to the training dataset (302) for the machine learning model (300) based on the clustered model (211).
Each training data set weight (218) of the training data set weight (218) is adjusted to be consistent with the respective cluster weight (214) and to form an adjusted training data set (208). That and
A system comprising providing the adjusted training data set (208) as an unbiased training data set (206) to the machine learning model (300).
前記偏りのない訓練データセット（２０６）を用いて前記機械学習モデル（３００）を訓練することと、
少なくとも１つのそれぞれのデータ特性を含むサンプルデータセットを受信することと、
訓練された前記機械学習モデル（３００）を使用して、受信された前記サンプルデータセットに基づいた、偏りのない予測値（３１０）を生成することとを含む、請求項１１または１２に記載のシステム（１００）。 The above operation further
Training the machine learning model (300) with the unbiased training data set (206) and
Receiving a sample dataset containing at least one of the respective data characteristics,
22. System (100).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記それぞれのクラスタ重み（２１４）と整合させることと、
前記訓練データセット重み（２１８）が前記それぞれのクラスタ重み（２１４）と整合するまで、前記訓練データセットからデータを除去することとを含む、請求項１１〜１３のいずれか１項に記載のシステム（１００）。 Adjusting each training data set weight (218) to be consistent with the respective cluster weight (214) is described for each training data set weight (218).
Matching the training dataset weights (218) with their respective cluster weights (214) based on common data characteristics.
The system of any one of claims 11-13, comprising removing data from the training data set until the training data set weight (218) is consistent with the respective cluster weight (214). (100).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記それぞれのクラスタ重み（２１４）と整合させることと、
前記訓練データセット重み（２１８）が前記それぞれのクラスタ重み（２１４）と整合するまで、前記訓練データセットからデータを複製することとを含む、請求項１１〜１４のいずれか１項に記載のシステム（１００）。 Adjusting each training data set weight (218) to be consistent with the respective cluster weight (214) is described for each training data set weight (218).
Matching the training dataset weights (218) with their respective cluster weights (214) based on common data characteristics.
The system of any one of claims 11-14, comprising replicating data from the training data set until the training data set weight (218) is consistent with the respective cluster weight (214). (100).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記クラスタ重み（２１４）と整合させることと、
前記訓練データセット重み（２１８）が前記それぞれのクラスタ重み（２１４）よりも小さい場合、前記訓練データセット重み（２１８）に対応する訓練データに対する前記機械学習モデル（３００）の訓練を増加させることを示す重要性重み（２２８）を関連付けることとを含む、請求項１１〜１５のいずれか１項に記載のシステム（１００）。 Adjusting each training data set weight (218) to be consistent with the respective cluster weight (214) is described for each training data set weight (218).
To match the training dataset weight (218) with the cluster weight (214) based on common data characteristics.
If the training data set weight (218) is smaller than the respective cluster weight (214), the training of the machine learning model (300) on the training data corresponding to the training data set weight (218) may be increased. The system (100) according to any one of claims 11-15, comprising associating the indicated materiality weights (228).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記クラスタ重み（２１４）と整合させることと、
前記訓練データセット重み（２１８）が前記それぞれのクラスタ重み（２１４）よりも大きい場合、前記訓練データセット重み（２１８）に対応する訓練データに対する前記機械学習モデル（３００）の訓練を減少させることを示す重要性重み（２２８）を関連付けることとを含む、請求項１１〜１６のいずれか１項に記載のシステム（１００）。 Adjusting each training data set weight (218) to be consistent with the respective cluster weight (214) is described for each training data set weight (218).
To match the training dataset weight (218) with the cluster weight (214) based on common data characteristics.
If the training data set weight (218) is greater than the respective cluster weight (214), then reducing the training of the machine learning model (300) on the training data corresponding to the training data set weight (218). The system (100) according to any one of claims 11-16, comprising associating the indicated materiality weight (228).
共通のデータ特性に基づいて、前記訓練データセット重み（２１８）を前記対応するクラスタ重み（２１４）と整合させることと、
前記訓練データセット重み（２１８）が前記対応するクラスタ重み（２１４）よりも小さい場合、前記訓練データセット重み（２１８）に対応する訓練データに対する前記機械学習モデル（３００）の訓練を増加させることを示す重要性重み（２２８）を関連付けることと、
前記訓練データセット重み（２１８）が前記対応するクラスタ重み（２１４）よりも大きい場合、前記訓練データセット重み（２１８）に対応する訓練データに対する前記機械学習モデル（３００）の訓練を減少させることを示す重要性重み（２２８）を関連付けることとを含む、請求項１１〜１７のいずれか１項に記載のシステム（１００）。 Adjusting each training data set weight (218) of the training data set weight (218) to be consistent with the respective cluster weight (214) further for each training data set weight (218).
Matching the training dataset weight (218) with the corresponding cluster weight (214) based on common data characteristics.
If the training data set weight (218) is smaller than the corresponding cluster weight (214), increasing the training of the machine learning model (300) on the training data corresponding to the training data set weight (218). Associating the indicated importance weight (228) with
If the training data set weight (218) is greater than the corresponding cluster weight (214), the training of the machine learning model (300) on the training data corresponding to the training data set weight (218) may be reduced. The system (100) according to any one of claims 11-17, comprising associating the indicated materiality weight (228).
前記偏りのない既知のデータ母集団のデータ特性に基づいて、受信された前記クラスタ訓練データセット（１３０）をクラスタ（２１２）に分割することと、
前記偏りのない既知のデータ母集団の前記データ特性に基づいた前記クラスタ（２１２）の各クラスタ（２１２）について、前記偏りのない既知のデータ母集団のサイズに対するそれぞれのクラスタ（２１２）のサイズの比に基づいて、前記クラスタ化モデル（２１１）の各クラスタ（２１２）についての前記クラスタ重み（２１４）を判定することとを含む、請求項１１〜１８のいずれか１項に記載のシステム（１００）。 The operation of training the clustering model (211) is further enhanced.
Dividing the received cluster training data set (130) into clusters (212) based on the data characteristics of the known unbiased data population.
For each cluster (212) of the cluster (212) based on the data characteristics of the known unbiased data population, the size of each cluster (212) relative to the size of the known unbiased data population. The system (100) of any one of claims 11-18, comprising determining the cluster weight (214) for each cluster (212) of the clustering model (211) based on the ratio. ).
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
JP2022130108A JP7405919B2 (en) | 2018-09-10 | 2022-08-17 | Reject biased data using machine learning models |
JP2023211190A JP2024028987A (en) | 2018-09-10 | 2023-12-14 | Reject biased data using machine learning models |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/126,860 | 2018-09-10 | ||
US16/126,860 US11250346B2 (en) | 2018-09-10 | 2018-09-10 | Rejecting biased data using a machine learning model |
PCT/US2019/048121 WO2020055581A1 (en) | 2018-09-10 | 2019-08-26 | Rejecting biased data using a machine learning model |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022130108A Division JP7405919B2 (en) | 2018-09-10 | 2022-08-17 | Reject biased data using machine learning models |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2021536067A true JP2021536067A (en) | 2021-12-23 |
JP7127211B2 JP7127211B2 (en) | 2022-08-29 |
Family
ID=67876099
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021513193A Active JP7127211B2 (en) | 2018-09-10 | 2019-08-26 | Rejecting Biased Data Using Machine Learning Models |
JP2022130108A Active JP7405919B2 (en) | 2018-09-10 | 2022-08-17 | Reject biased data using machine learning models |
JP2023211190A Pending JP2024028987A (en) | 2018-09-10 | 2023-12-14 | Reject biased data using machine learning models |
Family Applications After (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022130108A Active JP7405919B2 (en) | 2018-09-10 | 2022-08-17 | Reject biased data using machine learning models |
JP2023211190A Pending JP2024028987A (en) | 2018-09-10 | 2023-12-14 | Reject biased data using machine learning models |
Country Status (6)
Country | Link |
---|---|
US (3) | US11250346B2 (en) |
EP (1) | EP3834140A1 (en) |
JP (3) | JP7127211B2 (en) |
KR (3) | KR20240013898A (en) |
CN (1) | CN112639842A (en) |
WO (1) | WO2020055581A1 (en) |
Families Citing this family (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10783535B2 (en) * | 2016-05-16 | 2020-09-22 | Cerebri AI Inc. | Business artificial intelligence management engine |
US11537876B2 (en) * | 2018-11-28 | 2022-12-27 | Bank Of America Corporation | Targeted variation of machine learning input data |
US11343144B2 (en) * | 2019-03-12 | 2022-05-24 | Cisco Technology, Inc. | Downlink performance optimizations in wireless networks |
US11416500B2 (en) | 2019-05-22 | 2022-08-16 | Oracle International Corporation | Control system for learning to rank fairness |
US11775863B2 (en) * | 2019-05-22 | 2023-10-03 | Oracle International Corporation | Enforcing fairness on unlabeled data to improve modeling performance |
US11062234B1 (en) * | 2019-12-31 | 2021-07-13 | Capital One Services, Llc | System and method for managing classification outcomes of data inputs classified into bias categories |
KR102542451B1 (en) * | 2020-11-04 | 2023-06-12 | 서울대학교산학협력단 | Method and apparatus for performing fair clustering through estimating fair distribution |
JP7322918B2 (en) * | 2021-03-29 | 2023-08-08 | 横河電機株式会社 | Program, information processing device, and learning model generation method |
CN113077057B (en) * | 2021-04-20 | 2022-09-06 | 中国科学技术大学 | Unbiased machine learning method |
KR20230034762A (en) * | 2021-09-03 | 2023-03-10 | 주식회사 뷰노 | Machine learning training method and apparatus using same |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2009282688A (en) * | 2008-05-21 | 2009-12-03 | Mitomo Shoji Kk | Radio ic tag |
US20170330058A1 (en) * | 2016-05-16 | 2017-11-16 | Cerebri AI Inc. | Detecting and reducing bias (including discrimination) in an automated decision making process |
JP2018513461A (en) * | 2015-03-03 | 2018-05-24 | ナントミクス，エルエルシー | Ensemble-based research and recommendation system and method |
US20180165697A1 (en) * | 2016-12-08 | 2018-06-14 | App Annie Inc. | Determining usage data of mobile applications for a population |
US20180197105A1 (en) * | 2017-01-06 | 2018-07-12 | Accenture Global Solutions Limited | Security classification by machine learning |
JP2018109906A (en) * | 2017-01-05 | 2018-07-12 | 住友電気工業株式会社 | Image data creation program, image data creation device, and image data creation method |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7437334B2 (en) | 2004-12-03 | 2008-10-14 | Hewlett-Packard Development Company, L.P. | Preparing data for machine learning |
WO2009135076A1 (en) * | 2008-05-02 | 2009-11-05 | The Regents Of The University Of California | Estimation based on case-control designs |
JP5243888B2 (en) | 2008-08-18 | 2013-07-24 | 日本放送協会 | Data classification apparatus and data classification program |
JP2010204966A (en) | 2009-03-03 | 2010-09-16 | Nippon Telegr & Teleph Corp <Ntt> | Sampling device, sampling method, sampling program, class distinction device and class distinction system |
US20110289025A1 (en) | 2010-05-19 | 2011-11-24 | Microsoft Corporation | Learning user intent from rule-based training data |
US9852019B2 (en) | 2013-07-01 | 2017-12-26 | Agent Video Intelligence Ltd. | System and method for abnormality detection |
JP2017076289A (en) | 2015-10-15 | 2017-04-20 | キヤノン株式会社 | Parameter decision device, parameter decision method and program |
-
2018
- 2018-09-10 US US16/126,860 patent/US11250346B2/en active Active
-
2019
- 2019-08-26 WO PCT/US2019/048121 patent/WO2020055581A1/en unknown
- 2019-08-26 JP JP2021513193A patent/JP7127211B2/en active Active
- 2019-08-26 KR KR1020247002451A patent/KR20240013898A/en active Application Filing
- 2019-08-26 EP EP19765595.4A patent/EP3834140A1/en active Pending
- 2019-08-26 KR KR1020237023811A patent/KR102629553B1/en active IP Right Grant
- 2019-08-26 CN CN201980057266.0A patent/CN112639842A/en active Pending
- 2019-08-26 KR KR1020217003605A patent/KR102556896B1/en active IP Right Grant
-
2022
- 2022-01-31 US US17/649,510 patent/US20220156646A1/en active Pending
- 2022-08-17 JP JP2022130108A patent/JP7405919B2/en active Active
-
2023
- 2023-12-14 JP JP2023211190A patent/JP2024028987A/en active Pending
-
2024
- 2024-01-05 US US18/406,073 patent/US20240144095A1/en active Pending
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2009282688A (en) * | 2008-05-21 | 2009-12-03 | Mitomo Shoji Kk | Radio ic tag |
JP2018513461A (en) * | 2015-03-03 | 2018-05-24 | ナントミクス，エルエルシー | Ensemble-based research and recommendation system and method |
US20170330058A1 (en) * | 2016-05-16 | 2017-11-16 | Cerebri AI Inc. | Detecting and reducing bias (including discrimination) in an automated decision making process |
US20180165697A1 (en) * | 2016-12-08 | 2018-06-14 | App Annie Inc. | Determining usage data of mobile applications for a population |
JP2018109906A (en) * | 2017-01-05 | 2018-07-12 | 住友電気工業株式会社 | Image data creation program, image data creation device, and image data creation method |
US20180197105A1 (en) * | 2017-01-06 | 2018-07-12 | Accenture Global Solutions Limited | Security classification by machine learning |
Also Published As
Publication number | Publication date |
---|---|
CN112639842A (en) | 2021-04-09 |
KR20240013898A (en) | 2024-01-30 |
US20200082300A1 (en) | 2020-03-12 |
KR102629553B1 (en) | 2024-01-25 |
JP7405919B2 (en) | 2023-12-26 |
US20240144095A1 (en) | 2024-05-02 |
EP3834140A1 (en) | 2021-06-16 |
US11250346B2 (en) | 2022-02-15 |
JP7127211B2 (en) | 2022-08-29 |
JP2024028987A (en) | 2024-03-05 |
US20220156646A1 (en) | 2022-05-19 |
WO2020055581A1 (en) | 2020-03-19 |
KR102556896B1 (en) | 2023-07-18 |
KR20210025108A (en) | 2021-03-08 |
JP2022169657A (en) | 2022-11-09 |
KR20230110830A (en) | 2023-07-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7241862B2 (en) | Rejecting Biased Data Using Machine Learning Models | |
JP7405919B2 (en) | Reject biased data using machine learning models | |
US11475161B2 (en) | Differentially private dataset generation and modeling for knowledge graphs | |
Hegde et al. | Aspect based feature extraction and sentiment classification of review data sets using Incremental machine learning algorithm | |
WO2023103527A1 (en) | Access frequency prediction method and device | |
US11037073B1 (en) | Data analysis system using artificial intelligence | |
Purbolaksono et al. | Implementation of mutual information and bayes theorem for classification microarray data | |
US11928017B2 (en) | Point anomaly detection | |
US20220138585A1 (en) | Systems and methods for applying a lens function generated using supervised learning techniques to segment data provided to an unsupervised learning model | |
Straton et al. | Big social data analytics for public health: Comparative methods study and performance indicators of health care content on Facebook | |
Raj et al. | Is dynamic rumor detection on social media viable? an unsupervised perspective | |
Jabin | Predicting lung cancer survivability: A machine learning regression model | |
Annapoorna et al. | Streaming data classification | |
Jayabharathi | Comparative Analysis of Social Media Analytics in Bigdata Using Fuzzy C Mean (Fcm), K-Nearest Neighbour (Knn) And K-Means Algorithms | |
Gour et al. | Trending Topics Detection using Machine Learning Approach | |
Liu et al. | Building Fair Predictive Models | |
Raj | ANALYSIS OF CLUSTERING ALGORITHMS FOR TEXT CLASSIFICATION | |
Nong et al. | Clustering of subsample means based on pairwise L1 regularized empirical likelihood | |
CN114120040A (en) | Data classification method and device, electronic equipment and storage medium | |
KR20230015009A (en) | System for prediction of early dropping out in outpatients with alcohol use disorders and method thereof | |
Huang | A Picture Is Worth a Thousand Words: Rethinking Graph Neural Networks for Text Classification | |
Heinrich | The Missing Link–Predictive Models based on Textual and Dynamic Network Data | |
Reddy et al. | A Novel Weighted Probabilistic Based Gene-Disease Document Classification Model Using Hadoop Framework for Distributed Biomedical Repositories |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210531 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20210531 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20220719 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20220817 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7127211Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |