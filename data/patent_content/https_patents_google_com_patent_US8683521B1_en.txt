US8683521B1 - Feature-based video suggestions - Google Patents
Feature-based video suggestions Download PDFInfo
- Publication number
- US8683521B1 US8683521B1 US12/415,923 US41592309A US8683521B1 US 8683521 B1 US8683521 B1 US 8683521B1 US 41592309 A US41592309 A US 41592309A US 8683521 B1 US8683521 B1 US 8683521B1
- Authority
- US
- United States
- Prior art keywords
- videos
- video
- ranker
- feature vectors
- watched
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 239000013598 vector Substances 0.000 claims abstract description 72
- 238000012549 training Methods 0.000 claims description 39
- 238000000034 method Methods 0.000 claims description 29
- 238000001914 filtration Methods 0.000 description 8
- 239000011159 matrix material Substances 0.000 description 8
- 238000010586 diagram Methods 0.000 description 6
- 238000005516 engineering process Methods 0.000 description 5
- 238000010606 normalization Methods 0.000 description 4
- 238000004590 computer program Methods 0.000 description 3
- 230000008569 process Effects 0.000 description 3
- 238000012546 transfer Methods 0.000 description 3
- 230000000694 effects Effects 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 238000012545 processing Methods 0.000 description 2
- 230000004044 response Effects 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 1
- 235000014510 cooky Nutrition 0.000 description 1
- 230000003203 everyday effect Effects 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 238000010801 machine learning Methods 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/251—Learning process for intelligent management, e.g. learning user preferences for recommending movies
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/482—End-user interface for program selection
- H04N21/4826—End-user interface for program selection using recommendation lists, e.g. of programs or channels sorted out according to their score
Definitions
- This invention generally relates to item suggestions and more specifically to generating suggestions for videos based on features of the videos.
- Operators of video sharing websites have a general desire to improve the experiences of the viewers of the shared videos. For example, the viewer experience can be improved by providing the viewer with suggestions for videos the viewer might find interesting. Such suggestions can be provided while a current video is playing and/or upon completion of a played video.
- suggestions are generated based on a variety of techniques that seek to identify related videos.
- One such technique is to assume that videos watched by a user in response to a search query are related. If a user submits a query for videos matching specific criteria, the videos the user selects and watches from the search results can be treated as related. Similarly, videos watched by a user during a given time interval can be treated as related.
- Another technique for generating suggestions is examining metadata associated with the videos, such as tags specified by the videos' providers. Videos with similar metadata are treated as related.
- Another similar technique is to identify the vertical categories associated with the videos (e.g., “Sports
- Embodiments of the method comprise determining co-watchedness of videos served by a video server to produce co-watch data and creating feature vectors for the videos based at least in part on the co-watch data.
- a feature vector for a video describes other videos co-watched with the video.
- Embodiments of the method further comprise training a ranker for the given video based at least in part on the feature vectors, identifying a set of suggested videos for the given video using the ranker, and providing the set of suggested videos to the viewer.
- Embodiments of the computer-readable storage medium contain executable computer code for suggesting videos to a viewer of a given video, the computer code comprising code for determining co-watchedness of videos served by a video server to produce co-watch data and for creating feature vectors for the videos based at least in part on the co-watch data.
- the computer code further comprises code for training a ranker for the given video based at least in part on the feature vectors, identifying a set of suggested videos for the given video using the ranker, and providing the set of suggested videos to the viewer.
- Embodiments of the computer comprise a computer-readable storage medium containing executable computer code for suggesting videos to a viewer of a given video, the computer code comprising code for determining co-watchedness of videos served by a video server to produce co-watch data and for creating feature vectors for the videos based at least in part on the co-watch data.
- the computer code further comprises code for training a ranker for the given video based at least in part on the feature vectors, identifying a set of suggested videos for the given video using the ranker, and providing the set of suggested videos to the viewer.
- the computer further comprises a processor for executing the computer code.
- FIG. 1 is a high-level block diagram of a computing environment according to one embodiment.
- FIG. 2 is a high-level block diagram illustrating an example of a computer for use as a video server, suggestion server, and/or client.
- FIG. 3 is a high-level block diagram illustrating modules within the suggestion server according to one embodiment.
- FIG. 4 illustrates the operation of the video server to provide suggestions according to one embodiment.
- FIG. 5 illustrates the operation of the suggestion server to provide suggestions according to one embodiment.
- FIG. 6 illustrates a graph representing co-watchedness of videos.
- FIG. 1 is a high-level block diagram of a computing environment 100 according to one embodiment.
- FIG. 1 illustrates a video server 110 , a suggestion server 112 , and a client 114 connected by a network 116 . Only one client 114 is shown in FIG. 1 in order to simplify and clarify the description.
- Embodiments of the computing environment 100 can have thousands or millions of clients 114 , as well as multiple video 110 and suggestion servers 112 .
- the video server 110 serves video content (referred to herein as “videos”) to clients 114 via the network 116 .
- the video server 110 is located at a website provided by YOUTUBE, LLC of San Bruno, Calif., although the video server can also be provided by another entity.
- the video server 110 includes a database storing multiple videos and a web server for interacting with clients 114 .
- the video server 110 receives requests from users of clients 114 for the videos in the database and serves the videos in response.
- the video server 110 can receive, store, and serve videos posted by users of the clients 114 and by other entities.
- An embodiment of the video server 110 maintains one or more logs indicating which users viewed which videos, and when the videos were viewed.
- the video server 110 can collected the log data by using cookies to anonymously identify and track the activities of unique users (or clients 114 ).
- the log data thus allows one to determine what videos were watched by a user within a given time period, or “session.” Any two videos that are watched by a user within the same session are said to be “co-watched.”
- a session is defined as a 24-hour period, but different embodiments can define sessions using different time periods.
- the video server 110 also suggests videos to the users of the clients 114 .
- the suggested videos include other videos in which the user might be interested. At least some of the suggestions are context-sensitive, meaning that the suggestions are based on the users' interactions with the video server 110 .
- the suggestions made to a user are based on one or more other videos viewed by the user. For example, after the user completes viewing of a video, the video server 110 can suggest one or more other videos related to that video. These suggestions can appear, for example, in the same display area in which the video appeared.
- the video server 110 can also provide a list of suggested videos in a separate display area that is displayed while the user watches a video.
- the suggestion server 112 generates the suggestions that are provided by video server 110 .
- An embodiment of the suggestion server 112 analyzes the log data collected by the video server 110 to identify pairs of co-watched videos and generate values representing the number of times the pairs of videos were co-watched. The suggestion server 112 uses this information to create feature vectors for the co-watched videos.
- the suggestion server 112 uses the feature vectors to train a ranker for each co-watched video.
- a ranker is trained using positive and negative samples.
- the positive samples include the feature vectors of videos that were co-watched with the video for which the ranker is being trained.
- the negative samples can include, for example, feature vectors for random, non-co-watched videos.
- the ranker can be applied to a feature vector for a video to produce a ranking score.
- a set of candidate videos is defined.
- the suggestion server 112 applies the feature vectors for the candidates to the ranker for the given video to produce ranking scores.
- the candidate videos are ranked based on their ranking scores, and the highest-ranked candidates are provided to the video server 110 as suggestions for the given video.
- Using the log data, feature vectors, and rankers in this manner allows for a broad set of candidate videos to be ranked and provided as suggestions.
- the client 114 is a computer or other electronic device used by one or more users to perform activities including viewing videos received from the video server 110 .
- the client 114 can be a personal computer executing a web browser 118 that allows the user to browse and search for videos available at the video server web site.
- the client 114 is a network-capable device other than a computer, such as a personal digital assistant (PDA), a mobile telephone, a pager, a television “set-top box,” etc.
- PDA personal digital assistant
- the network 116 enables communications among the entities connected to it.
- the network 116 is the Internet and uses standard communications technologies and/or protocols.
- the network 116 can include links using technologies such as Ethernet, 802.11, worldwide interoperability for microwave access (WiMAX), 3 G, digital subscriber line (DSL), asynchronous transfer mode (ATM), InfiniBand, PCI Express Advanced Switching, etc.
- the networking protocols used on the network 116 can include multiprotocol label switching (MPLS), the transmission control protocol/Internet protocol (TCP/IP), the User Datagram Protocol (UDP), the hypertext transport protocol (HTTP), the simple mail transfer protocol (SMTP), the file transfer protocol (FTP), etc.
- MPLS multiprotocol label switching
- TCP/IP transmission control protocol/Internet protocol
- UDP User Datagram Protocol
- HTTP hypertext transport protocol
- SMTP simple mail transfer protocol
- FTP file transfer protocol
- the data exchanged over the network 116 can be represented using technologies and/or formats including the hypertext markup language (HTML), the extensible markup language (XML), etc.
- HTML hypertext markup language
- XML extensible markup language
- all or some of links can be encrypted using conventional encryption technologies such as the secure sockets layer (SSL), transport layer security (TLS), virtual private networks (VPNs), Internet Protocol security (IPsec), etc.
- SSL secure sockets layer
- TLS transport layer security
- VPNs virtual private networks
- IPsec Internet Protocol security
- the entities use custom and/or dedicated data communications technologies instead of, or in addition to, the ones described above.
- FIG. 2 is a high-level block diagram illustrating an example of a computer 200 for use as a video server 110 , suggestion server 112 , and/or client 114 . Illustrated are at least one processor 202 coupled to a chipset 204 .
- the chipset 204 includes a memory controller hub 220 and an input/output (I/O) controller hub 222 .
- a memory 206 and a graphics adapter 212 are coupled to the memory controller hub 220 , and a display device 218 is coupled to the graphics adapter 212 .
- a storage device 208 , keyboard 210 , pointing device 214 , and network adapter 216 are coupled to the I/O controller hub 222 .
- Other embodiments of the computer 200 have different architectures.
- the memory 206 is directly coupled to the processor 202 in some embodiments.
- the storage device 208 is a computer-readable storage medium such as a hard drive, compact disk read-only memory (CD-ROM), DVD, or a solid-state memory device.
- the memory 206 holds instructions and data used by the processor 202 .
- the pointing device 214 is a mouse, track ball, or other type of pointing device, and is used in combination with the keyboard 210 to input data into the computer system 200 .
- the graphics adapter 212 displays images and other information on the display device 218 .
- the network adapter 216 couples the computer system 200 to the network 116 . Some embodiments of the computer 200 have different and/or other components than those shown in FIG. 2 .
- the computer 200 is adapted to execute computer program modules for providing functionality described herein.
- module refers to computer program code and other logic used to provide the specified functionality.
- a module can be implemented in hardware, firmware, and/or software.
- program modules formed of executable computer program code are stored on the storage device 208 , loaded into the memory 206 , and executed by the processor 202 .
- the types of computers 200 used by the entities of FIG. 1 can vary depending upon the embodiment and the processing power used by the entity.
- a client 114 that is a mobile telephone typically has limited processing power, a small display 218 , and might lack a pointing device 214 .
- the video server 110 may comprise multiple blade servers working together to provide the functionality described herein.
- FIG. 3 is a high-level block diagram illustrating modules within the suggestion server 112 according to one embodiment. Some embodiments of the suggestion server 112 have different and/or additional modules than the ones described here. Similarly, the functions can be distributed among the modules in a different manner. Certain modules and functions can be incorporated into other modules of the suggestion server 112 and/or other entities on the network 116 , including the video server 110 and client 114 .
- a co-watch identification module 310 (the “co-watch module”) identifies videos served by the video server 110 that are co-watched.
- the co-watch module 310 analyzes the log data collected by the video server 110 in order to identify the videos that were watched by the users during their sessions. A pair of videos watched by a given user within a given session are said to be “co-watched.”
- the co-watch module 310 can analyze the log data for a given time period, such as a day, week, or month, to identify the users and user sessions described therein. Then, the co-watch module 310 can identify all of the pairs of videos that were co-watched by individual users within the time period.
- the co-watch module 310 can also evaluate co-watchedness based on the amount of video watched by the user. For example, the co-watch module 310 can treat only videos where the user watched more than 75% of the total video (or some other threshold amount) as co-watched.
- the co-watch module 310 aggregates pairs of co-watched videos. In other words, for every pair of co-watched videos [v 1 , v 2 ], the co-watch module 310 maintains a count of how many times the videos were co-watched across all users.
- the co-watch module 310 can represent the aggregate data as a matrix, with all of the videos identified in the log data listed along both the X and Y axes, and the intersection of two videos (e.g., [v 1 , v 2 ]) holding a value, called the “co-watch data,” indicating the number of times the pair of videos was co-watched across all users.
- the matrix is merely a convenient way to conceptually represent the co-watch data, and embodiments of the co-watch module 310 can represent the aggregate data in other ways.
- a normalization module 312 normalizes the co-watch data to discount the influence of popular videos.
- the most popular videos at any given point in time are watched by many users within their sessions. For example, many people will watch the latest music video for a popular musician within their sessions. As a result, these popular videos become co-watched with a wide variety of videos with which the popular videos are not intrinsically related. The normalization prevents these popular videos from skewing the suggestions.
- the normalization module 312 performs the normalization using a term frequency-inverse document frequency (TF-IDF)-based technique applied in the video domain.
- TF-IDF term frequency-inverse document frequency
- the TF-IDF technique is applied to each pair of co-watched videos to transform the value indicating the number of times the pair was co-watched into a value that down-weights popular videos.
- the TF-IDF technique is performed as follows:
- NV i , j Num ⁇ ( v i , v j ) Num ⁇ ( v i ) ⁇ log ⁇ V ⁇ k ⁇ ( v k , v j )
- NV i,j is the normalized value (i.e., the normalized co-watch data) for the pair of co-watched videos (v i , v j ).
- Num(v i , v j ) is the number of times the pair of videos was co-watched, and Num(v i ) is the number of times Video v i was watched overall.
- V is the total number of unique videos identified in the log data, and
- ⁇ k ⁇ ( v k , v j ) is the number of times video v j was co-watched with all videos.
- the normalized co-watch data are stored in the matrix in place of the value indicating the non-normalized co-watch data.
- a filtering module 314 uses the normalized co-watch data to identify the videos most frequently co-watched with a given video. In one embodiment, for each video, the filtering module 314 selects the N-highest normalized co-watch values for that video in the matrix. Said another way, the filtering module 314 filters out all but the N-highest normalized co-watch values for each video. “N” in one embodiment is 1,000. Different embodiments can use different values of N. Moreover, the filtering module 314 is absent in some embodiments.
- the filtering module 314 One way to understand the operation of the filtering module 314 is to visualize the matrix. If the log data identify 200 million co-watched videos, then the matrix has dimensions of 200 million by 200 million. The filtering module 314 analyzes a row (or column) of the matrix to identify the N (e.g., 1000) highest co-watch values and removes the other co-watch values from the row. Thus, the end result is a sparse 200 million by 200 million matrix, where each row or column has no more than N values.
- N e.g. 1000
- a feature vector creation module 316 (the “FV creation module”) creates feature vectors describing the co-watchedness of the videos served by the video server 110 .
- the FV creation module 316 creates a feature vector for each co-watched video. Thus, if there are 200 million co-watched videos, the FV creation module 316 creates 200 million feature vectors.
- a feature vector for a given video includes a list of the videos that were co-watched with the given video, and the associated normalized co-watch values.
- the feature vector for a video v i is ([v i0 , c i0 ], [v i1 , c i1 ], . . . ), where v in is the normalized co-watch value and c in is an identifier of the other video in the pair with which the co-watch value is associated.
- v in is the normalized co-watch value
- c in is an identifier of the other video in the pair with which the co-watch value is associated.
- each feature vector will have no more than 1,000 features.
- a training module 318 uses the feature vectors to create and train classifiers for the videos.
- the training module 318 trains a classifier for each video.
- the training module 318 trains a form of classifier called a “ranker” using both positive and negative samples.
- the training module 318 performs machine learning using the positive and negative samples and produces a model (the ranker) that has weights assigned to the various features.
- the ranker for a first video when applied to a feature vector of a second video, produces a score that can be used to rank the relatedness (i.e., the co-watchedness) of the second video to the first video.
- the positive samples in one embodiment include the feature vectors for the first order co-watched videos of the video for which the ranker is being trained.
- the negative samples in one embodiment include the feature vectors for videos that are in opposition to the positive samples. That is, for a ranker for a given video, the training module 318 trains using the feature vectors of the 1,000 videos that were co-watched with the given video (as identified by the filtering module 314 ) as positive samples.
- the negative samples can include feature vectors for videos that are known or suspected to be not related to the video for which the ranker is being trained, e.g., feature vectors for random videos (filtered to exclude first order co-watched videos) and feature vectors of second order co-watched videos (i.e., the co-watched videos of the videos that were co-watched with the given video), etc.
- the training module 318 can train on other and/or additional positive and negative samples than the ones described herein.
- the training module 318 applies one or more constraints to guide the training process.
- the training module 318 can apply a neighbor-consistency constraint to guide the training toward learning a model that is consistent with that of its neighbors. This constraint can be applied by providing positive samples for neighbors during the training process and penalizing a model that generates very negative scores for the samples.
- the training module 318 can also apply a neighbor-diversity constraint to guide the training toward learning a model where suggestions for neighboring videos are sufficiently diverse. Neighbor-diversity can be achieved by using the positive samples of neighbors as negative samples while training the model.
- a suggestion generation module 320 suggests videos.
- the suggestion module 320 provides suggestions for one or more given videos.
- the suggestion module 320 identifies a set of suggestion candidate videos, and applies the ranker for the given video to the feature vectors for the candidates videos in the set to produce a set of ranking scores.
- the suggestion module 320 ranks the candidate videos by the videos' associated ranking scores, and presents the highest-scoring videos as a set of suggestions.
- the number of videos within the suggestion set can vary depending upon the embodiment. If there are multiple given videos for which suggestions are being provided, the suggestion module 320 can merge the suggestion sets for the two videos by, for example, providing the intersection or union of the sets or using another technique.
- the suggestion generation module 320 can generate the suggestions in real-time, as videos are identified as needing suggestions, or can generate suggestions in an advance as part of an offline process.
- the suggestion module 320 can use a variety of techniques to identify the set of suggestion candidate videos.
- the set of suggestion candidates includes other videos in the same co-watch “neighborhood” as the video for which suggestions are being provided.
- the “neighborhood” includes videos within a specified order of co-watchedness as the video for which the suggestions are being provided.
- the set can include first and second order co-watched videos.
- the neighborhood can also include videos having metadata similar to the metadata of the video for which the suggestions are being provided.
- Other embodiments can include additional and/or different videos in the set of suggestion candidates.
- FIG. 4 illustrates the operation of the video server 110 to provide suggestions according to one embodiment.
- Other embodiments can perform additional and/or different steps, and perform the steps in different orders.
- the video server 110 serves 410 a video to a client 114 .
- the video server 110 identifies 412 an opportunity to provide a suggestion to the client 114 .
- the opportunity can occur, for example, while populating a list of suggested videos that is displayed contemporaneously with playback of the initial video Likewise, the opportunity can occur when the initial video completes its playback and a suggested video can be displayed in the same region in which the initial video played.
- the video server 110 obtains 414 one or more suggested videos based on the initial video.
- the video server 110 can obtain the suggested videos by providing an identifier of the initial video to the suggestion server 112 along with other parameters, such as a number of suggestions required.
- the video server 110 then receives identifiers of the suggested videos from the suggestion server 112 .
- the video server 110 provides 416 the suggestions to the client 114 by, for example, causing thumbnail images of the suggested videos to display at the client.
- the suggestions can be based on multiple videos.
- the suggestions can be based on multiple videos watched by the user within the user's current session, or on videos recently watched by the user.
- the user need not watch an initial video in order to receive the suggestions; the video server 110 can identify the user, determine a set of videos previously viewed by the user, and provide suggestions based on the set of previously-viewed videos.
- FIG. 5 illustrates the operation of the suggestion server 112 to provide suggestions according to one embodiment.
- Other embodiments can perform additional and/or different steps, and perform the steps in different orders. Likewise, the steps can be performed at different times.
- the suggestion server 112 identifies 510 co-watched videos. This identification can be performed by analyzing log data to identify videos that were co-watched within user sessions.
- the suggestion server 112 normalizes 512 the co-watch data to discount the influence of popular videos.
- the suggestion server 112 filters 514 the normalized data by identifying, for each video, the videos most frequently co-watched with the video.
- the suggestion server 112 creates 516 feature vectors for the videos.
- the feature vector for a video describes the co-watchedness of the video.
- the suggestion server 112 uses the feature vectors to train 518 rankers for the videos.
- a ranker for a video is trained 518 using positive and negative samples.
- Positive samples can include the feature vectors of videos that were co-watched with the video while negative samples can include feature vectors for videos in opposition to the positive samples, such as random, non-co-watched videos.
- the training might also incorporate one or more constraints, such as neighbor-consistency and/or neighbor-diversity constraints.
- the suggestion server 112 defines a set of candidate videos and applies the feature vectors for the candidates to the ranker for the one or more videos for which suggestions are being provided.
- the suggestion server 112 ranks the candidates based on their ranking scores, and provides the highest-ranking videos as suggestions. If suggestions are being provided for multiple videos, the suggestion server 112 can generate a separate result set for each video, and then merge the result set to produce the suggestions.
- FIG. 6 illustrates a graph 600 representing co-watchedness of videos.
- a node 610 representing a video served by the video server 110 .
- the graph 600 also contains two additional nodes 612 that are each directly connected to the first node 610 via an edge. These additional nodes 612 represent videos that were co-watched with the first node 610 and are said to be first order co-watched with the first node 610 .
- Each of the additional nodes 612 has further nodes 614 connected to it. These latter nodes 614 were co-watched with the additional nodes 612 but not co-watched with the first node 610 .
- the further nodes 614 are said to be second order co-watched with the first node 610 .
- the video server 110 can serve more than 200 million videos, the overall co-watchedness graph can be much larger than the small segment illustrated in FIG. 6 .
- the relationships shown by the graph 600 are useful for understanding how the positive and negative features are selected for training a ranker.
- the feature vectors for the videos of the first order nodes 612 are used as positive features when training the ranker for the video of the first node 610
- the feature vectors for the videos of the second order nodes 614 can be used as negative features.
- the graph 600 is also useful for understanding the co-watch “neighborhood” for a video. The graph 600 is centered on the first node 610 , and the other nodes are in the same neighborhood as the first node because they are near that node in the graph.
- the techniques described herein can also be applied to other items or types of content.
- the techniques can be used to generate suggestions for audio content and still images.
Abstract
Description
is the number of times video vj was co-watched with all videos. The normalized co-watch data are stored in the matrix in place of the value indicating the non-normalized co-watch data.
Claims (23)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/415,923 US8683521B1 (en) | 2009-03-31 | 2009-03-31 | Feature-based video suggestions |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/415,923 US8683521B1 (en) | 2009-03-31 | 2009-03-31 | Feature-based video suggestions |
Publications (1)
Publication Number | Publication Date |
---|---|
US8683521B1 true US8683521B1 (en) | 2014-03-25 |
Family
ID=50289023
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/415,923 Active 2031-03-22 US8683521B1 (en) | 2009-03-31 | 2009-03-31 | Feature-based video suggestions |
Country Status (1)
Country | Link |
---|---|
US (1) | US8683521B1 (en) |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9715641B1 (en) * | 2010-12-08 | 2017-07-25 | Google Inc. | Learning highlights using event detection |
US10210462B2 (en) * | 2010-11-11 | 2019-02-19 | Google Llc | Video content analysis for automatic demographics recognition of users and videos |
CN109684510A (en) * | 2018-10-31 | 2019-04-26 | 北京达佳互联信息技术有限公司 | Video sequencing method, device, electronic equipment and storage medium |
US10779029B1 (en) * | 2018-10-11 | 2020-09-15 | Facebook, Inc. | Video creation at scale |
CN114041179A (en) * | 2019-07-08 | 2022-02-11 | 威尔乌集团 | Custom collection video |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020112239A1 (en) * | 2000-05-08 | 2002-08-15 | Goldman Phillip Y. | Modifying an electronic program guide based on viewer statistics |
US20040025180A1 (en) | 2001-04-06 | 2004-02-05 | Lee Begeja | Method and apparatus for interactively retrieving content related to previous query results |
US7072846B1 (en) * | 1999-11-16 | 2006-07-04 | Emergent Music Llc | Clusters for rapid artist-audience matching |
US20060161952A1 (en) * | 1994-11-29 | 2006-07-20 | Frederick Herz | System and method for scheduling broadcast of an access to video programs and other data using customer profiles |
US20070136753A1 (en) * | 2005-12-13 | 2007-06-14 | United Video Properties, Inc. | Cross-platform predictive popularity ratings for use in interactive television applications |
US20090172730A1 (en) | 2007-12-27 | 2009-07-02 | Jeremy Schiff | System and method for advertisement delivery optimization |
US7853071B2 (en) | 2006-11-16 | 2010-12-14 | Tandent Vision Science, Inc. | Method and system for learning object recognition in images |
-
2009
- 2009-03-31 US US12/415,923 patent/US8683521B1/en active Active
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060161952A1 (en) * | 1994-11-29 | 2006-07-20 | Frederick Herz | System and method for scheduling broadcast of an access to video programs and other data using customer profiles |
US7072846B1 (en) * | 1999-11-16 | 2006-07-04 | Emergent Music Llc | Clusters for rapid artist-audience matching |
US20020112239A1 (en) * | 2000-05-08 | 2002-08-15 | Goldman Phillip Y. | Modifying an electronic program guide based on viewer statistics |
US20040025180A1 (en) | 2001-04-06 | 2004-02-05 | Lee Begeja | Method and apparatus for interactively retrieving content related to previous query results |
US20070136753A1 (en) * | 2005-12-13 | 2007-06-14 | United Video Properties, Inc. | Cross-platform predictive popularity ratings for use in interactive television applications |
US7853071B2 (en) | 2006-11-16 | 2010-12-14 | Tandent Vision Science, Inc. | Method and system for learning object recognition in images |
US20090172730A1 (en) | 2007-12-27 | 2009-07-02 | Jeremy Schiff | System and method for advertisement delivery optimization |
Non-Patent Citations (4)
Title |
---|
Aggarwal, C., et al., "Horting Hatches an Egg: A New Graph-Theoretic Approach to Collaborative Filtering," In Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge discovery and data mining, 1999, 12 Pages. |
Baluja, S., et al., Video Suggestion and Discovery for YouTube: Taking Random Walks Through the View Graph, International World Wide Web Conference Committee (IW3C2) 2008, Apr. 21-25, 2008, Beijing, China, 10 Pages. |
Herlocker, J., et al., "Explaining Collaborative Filtering Recommendations," CSCW'00, Dec. 2-6, 2000, 10 Pages. |
Vallet, D., et al., "Use of Implicit Graph for Recommending Relevant Videos: A Simulated Evaluation," Lecture Notes in Computer Science, 2008, pp. 199-210. |
Cited By (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10210462B2 (en) * | 2010-11-11 | 2019-02-19 | Google Llc | Video content analysis for automatic demographics recognition of users and videos |
US9715641B1 (en) * | 2010-12-08 | 2017-07-25 | Google Inc. | Learning highlights using event detection |
US10867212B2 (en) | 2010-12-08 | 2020-12-15 | Google Llc | Learning highlights using event detection |
US11556743B2 (en) * | 2010-12-08 | 2023-01-17 | Google Llc | Learning highlights using event detection |
US10779029B1 (en) * | 2018-10-11 | 2020-09-15 | Facebook, Inc. | Video creation at scale |
CN109684510A (en) * | 2018-10-31 | 2019-04-26 | 北京达佳互联信息技术有限公司 | Video sequencing method, device, electronic equipment and storage medium |
CN109684510B (en) * | 2018-10-31 | 2020-01-31 | 北京达佳互联信息技术有限公司 | Video sequencing method and device, electronic equipment and storage medium |
CN114041179A (en) * | 2019-07-08 | 2022-02-11 | 威尔乌集团 | Custom collection video |
US11977594B2 (en) | 2019-07-08 | 2024-05-07 | Valve Corporation | Custom compilation videos |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11210304B2 (en) | Predicting a type of a record searched for by a user | |
US9704185B2 (en) | Product recommendation using sentiment and semantic analysis | |
US8151194B1 (en) | Visual presentation of video usage statistics | |
US10277696B2 (en) | Method and system for processing data used by creative users to create media content | |
RU2636702C1 (en) | Method and device for selecting network resource as source of content in recommendations system | |
US10387115B2 (en) | Method and apparatus for generating a recommended set of items | |
US9430553B2 (en) | Application representation for application editions | |
US10037538B2 (en) | Selection and presentation of news stories identifying external content to social networking system users | |
US20170098165A1 (en) | Method and Apparatus for Establishing and Using User Recommendation Model in Social Network | |
US11244022B2 (en) | System and methods for user curated media | |
US20160321261A1 (en) | System and method of providing a content discovery platform for optimizing social network engagements | |
US20160188997A1 (en) | Selecting a High Valence Representative Image | |
US11061990B2 (en) | Generating feedback for a target content item based on published content items | |
US20130124653A1 (en) | Searching, retrieving, and scoring social media | |
KR20160057475A (en) | System and method for actively obtaining social data | |
US10740415B2 (en) | Content recommendation | |
WO2013067210A1 (en) | Integrated social network and stream playback | |
US10204170B2 (en) | News feed | |
US20170155939A1 (en) | Method and System for Processing Data Used By Creative Users to Create Media Content | |
RU2714594C1 (en) | Method and system for determining parameter relevance for content items | |
US8683521B1 (en) | Feature-based video suggestions | |
US20150302109A1 (en) | Integrated media, publication and interactive discussion engine driven by user-specified topic | |
US20180302761A1 (en) | Recommendation System for Multi-party Communication Sessions | |
He et al. | Predicting the popularity of danmu-enabled videos: A multi-factor view | |
US20150302448A1 (en) | Sponsored content system and method for publication and interactive discussion engine |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:GARGI, ULLAS;YAGNIK, JAY;REEL/FRAME:022498/0792Effective date: 20090331 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551)Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0299Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |